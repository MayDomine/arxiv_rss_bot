# arXiv Papers Bot 🤖

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## 📊 Statistics

- **Last Updated**: 2025-08-29 12:50:33 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## 📚 Recent Papers

### 1. [Improving Quantization with Post-Training Model Expansion](https://arxiv.org/abs/2503.17513)

**Authors**: Giuseppe Franco, Pablo Monteagudo-Lago, Ian Colbert, Nicholas Fraser, Michaela Blott  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 5.0

arXiv:2503.17513v2 Announce Type: replace-cross 
Abstract: The size of a model has been a strong predictor of its quality, as well as its cost. As such, the trade-off between model cost and quality has been well-studied. Post-training optimizations like quantization and pruning have typically focuse...

---

### 2. [SpecVLM: Enhancing Speculative Decoding of Video LLMs via Verifier-Guided Token Pruning](https://arxiv.org/abs/2508.16201)

**Authors**: Yicheng Ji, Jun Zhang, Heming Xia, Jinpeng Chen, Lidan Shou, Gang Chen, Huan Li  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 5.0

arXiv:2508.16201v2 Announce Type: replace-cross 
Abstract: Video large language models (Vid-LLMs) have shown strong capabilities in understanding video content. However, their reliance on dense video token representations introduces substantial memory and computational overhead in both prefilling an...

---

### 3. [MIDAS: Multimodal Interactive Digital-humAn Synthesis via Real-time Autoregressive Video Generation](https://arxiv.org/abs/2508.19320)

**Authors**: Ming Chen, Liyuan Cui, Wenyuan Zhang, Haoxian Zhang, Yan Zhou, Xiaohan Li, Songlin Tang, Jiwen Liu, Borui Liao, Hejia Chen, Xiaoqiang Liu, Pengfei Wan  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 5.0

arXiv:2508.19320v2 Announce Type: replace-cross 
Abstract: Recently, interactive digital human video generation has attracted widespread attention and achieved remarkable progress. However, building such a practical system that can interact with diverse input signals in real time remains challenging...

---

### 4. [The Uneven Impact of Post-Training Quantization in Machine Translation](https://arxiv.org/abs/2508.20893)

**Authors**: Benjamin Marie, Atsushi Fujita  
**Category**: cs.CL  
**Published**: 2025-08-29  
**Score**: 5.0

arXiv:2508.20893v1 Announce Type: new 
Abstract: Quantization is essential for deploying large language models (LLMs) on resource-constrained hardware, but its implications for multilingual tasks remain underexplored. We conduct the first large-scale evaluation of post-training quantization (PTQ) on...

---

### 5. [Spatio-Temporal Pruning for Compressed Spiking Large Language Models](https://arxiv.org/abs/2508.20122)

**Authors**: Yi Jiang, Malyaban Bal, Brian Matejek, Susmit Jha, Adam Cobb, Abhronil Sengupta  
**Category**: cs.LG  
**Published**: 2025-08-29  
**Score**: 5.0

arXiv:2508.20122v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) present significant challenges for deployment in energy-constrained environments due to their large model sizes and high inference latency. Spiking Neural Networks (SNNs), inspired by the sparse event-driven neural proce...

---

### 6. [Inference-Time Alignment Control for Diffusion Models with Reinforcement Learning Guidance](https://arxiv.org/abs/2508.21016)

**Authors**: Luozhijie Jin, Zijie Qiu, Jie Liu, Zijie Diao, Lifeng Qiao, Ning Ding, Alex Lamb, Xipeng Qiu  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 4.5

arXiv:2508.21016v1 Announce Type: cross 
Abstract: Denoising-based generative models, particularly diffusion and flow matching algorithms, have achieved remarkable success. However, aligning their output distributions with complex downstream objectives, such as human preferences, compositional accur...

---

### 7. [Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess](https://arxiv.org/abs/2507.00726)

**Authors**: Dongyoon Hwang, Hojoon Lee, Jaegul Choo, Dongmin Park, Jongho Park  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 4.5

arXiv:2507.00726v3 Announce Type: replace 
Abstract: While reinforcement learning (RL) for large language models (LLMs) has shown promise in mathematical reasoning, strategic reasoning for LLMs using RL remains largely unexplored. We investigate whether LLMs can develop strategic reasoning capabilit...

---

### 8. [Entropy-Memorization Law: Evaluating Memorization Difficulty of Data in LLMs](https://arxiv.org/abs/2507.06056)

**Authors**: Yizhan Huang, Zhe Yang, Meifang Chen, Jianping Zhang, Michael R. Lyu  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 4.5

arXiv:2507.06056v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) are known to memorize portions of their training data, sometimes reproducing content verbatim when prompted appropriately. In this work, we investigate a fundamental yet under-explored question in the domain of m...

---

### 9. [AWorld: Orchestrating the Training Recipe for Agentic AI](https://arxiv.org/abs/2508.20404)

**Authors**: Chengyue Yu, Siyuan Lu, Chenyi Zhuang, Dong Wang, Qintong Wu, Zongyue Li, Runsheng Gan, Chunfeng Wang, Siqi Hou, Gaochi Huang, Wenlong Yan, Lifeng Hong, Aohui Xue, Yanfeng Wang, Jinjie Gu, David Tsai, Tao Lin  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 4.0

arXiv:2508.20404v1 Announce Type: new 
Abstract: The learning from practice paradigm is crucial for developing capable Agentic AI systems, yet it is severely hampered by inefficient experience generation, a bottleneck especially pronounced in complex benchmarks like GAIA. To address this, we introdu...

---

### 10. [Veritas: Generalizable Deepfake Detection via Pattern-Aware Reasoning](https://arxiv.org/abs/2508.21048)

**Authors**: Hao Tan, Jun Lan, Zichang Tan, Ajian Liu, Chuanbiao Song, Senyuan Shi, Huijia Zhu, Weiqiang Wang, Jun Wan, Zhen Lei  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 4.0

arXiv:2508.21048v1 Announce Type: cross 
Abstract: Deepfake detection remains a formidable challenge due to the complex and evolving nature of fake content in real-world scenarios. However, existing academic benchmarks suffer from severe discrepancies from industrial practice, typically featuring ho...

---

### 11. [MSRS: Evaluating Multi-Source Retrieval-Augmented Generation](https://arxiv.org/abs/2508.20867)

**Authors**: Rohan Phanse, Yijie Zhou, Kejian Shi, Wencai Zhang, Yixin Liu, Yilun Zhao, Arman Cohan  
**Category**: cs.CL  
**Published**: 2025-08-29  
**Score**: 4.0

arXiv:2508.20867v1 Announce Type: new 
Abstract: Retrieval-augmented systems are typically evaluated in settings where information required to answer the query can be found within a single source or the answer is short-form or factoid-based. However, many real-world applications demand the ability t...

---

### 12. [STARE at the Structure: Steering ICL Exemplar Selection with Structural Alignment](https://arxiv.org/abs/2508.20944)

**Authors**: Jiaqian Li, Qisheng Hu, Jing Li, Wenya Wang  
**Category**: cs.CL  
**Published**: 2025-08-29  
**Score**: 4.0

arXiv:2508.20944v1 Announce Type: new 
Abstract: In-Context Learning (ICL) has become a powerful paradigm that enables LLMs to perform a wide range of tasks without task-specific fine-tuning. However, the effectiveness of ICL heavily depends on the quality of exemplar selection. In particular, for s...

---

### 13. [Plug-in Feedback Self-adaptive Attention in CLIP for Training-free Open-Vocabulary Segmentation](https://arxiv.org/abs/2508.20265)

**Authors**: Zhixiang Chi, Yanan Wu, Li Gu, Huan Liu, Ziqiang Wang, Yang Zhang, Yang Wang, Konstantinos N. Plataniotis  
**Category**: cs.LG  
**Published**: 2025-08-29  
**Score**: 4.0

arXiv:2508.20265v1 Announce Type: cross 
Abstract: CLIP exhibits strong visual-textual alignment but struggle with open-vocabulary segmentation due to poor localization. Prior methods enhance spatial coherence by modifying intermediate attention. But, this coherence isn't consistently propagated to ...

---

### 14. [LASE: Learned Adjacency Spectral Embeddings](https://arxiv.org/abs/2412.17734)

**Authors**: Sof\'ia P\'erez Casulo, Marcelo Fiori, Federico Larroca, Gonzalo Mateos  
**Category**: cs.LG  
**Published**: 2025-08-29  
**Score**: 4.0

arXiv:2412.17734v2 Announce Type: replace 
Abstract: We put forth a principled design of a neural architecture to learn nodal Adjacency Spectral Embeddings (ASE) from graph inputs. By bringing to bear the gradient descent (GD) method and leveraging the principle of algorithm unrolling, we truncate a...

---

### 15. [Enhancing Health Fact-Checking with LLM-Generated Synthetic Data](https://arxiv.org/abs/2508.20525)

**Authors**: Jingze Zhang, Jiahe Qian, Yiliang Zhou, Yifan Peng  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2508.20525v1 Announce Type: new 
Abstract: Fact-checking for health-related content is challenging due to the limited availability of annotated training data. In this study, we propose a synthetic data generation pipeline that leverages large language models (LLMs) to augment training data for...

---

### 16. [ChatThero: An LLM-Supported Chatbot for Behavior Change and Therapeutic Support in Addiction Recovery](https://arxiv.org/abs/2508.20996)

**Authors**: Junda Wang, Zonghai Yao, Zhichao Yang, Lingxi Li, Junhui Qian, Hong Yu  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2508.20996v1 Announce Type: new 
Abstract: Substance use disorders (SUDs) affect over 36 million people worldwide, yet few receive effective care due to stigma, motivational barriers, and limited personalized support. Although large language models (LLMs) show promise for mental-health assista...

---

### 17. [Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization](https://arxiv.org/abs/2508.20181)

**Authors**: Alberto Compagnoni, Davide Caffagni, Nicholas Moratelli, Lorenzo Baraldi, Marcella Cornia, Rita Cucchiara  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2508.20181v1 Announce Type: cross 
Abstract: Multimodal Large Language Models (MLLMs) emerge as a unified interface to address a multitude of tasks, ranging from NLP to computer vision. Despite showcasing state-of-the-art results in many benchmarks, a long-standing issue is the tendency of MLL...

---

### 18. [How Multimodal LLMs Solve Image Tasks: A Lens on Visual Grounding, Task Reasoning, and Answer Decoding](https://arxiv.org/abs/2508.20279)

**Authors**: Zhuoran Yu, Yong Jae Lee  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2508.20279v1 Announce Type: cross 
Abstract: Multimodal Large Language Models (MLLMs) have demonstrated strong performance across a wide range of vision-language tasks, yet their internal processing dynamics remain underexplored. In this work, we introduce a probing framework to systematically...

---

### 19. [Dynamics-Aligned Latent Imagination in Contextual World Models for Zero-Shot Generalization](https://arxiv.org/abs/2508.20294)

**Authors**: Frank R\"oder, Jan Benad, Manfred Eppe, Pradeep Kr. Banerjee  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2508.20294v1 Announce Type: cross 
Abstract: Real-world reinforcement learning demands adaptation to unseen environmental conditions without costly retraining. Contextual Markov Decision Processes (cMDP) model this challenge, but existing methods often require explicit context variables (e.g.,...

---

### 20. [Poison Once, Refuse Forever: Weaponizing Alignment for Injecting Bias in LLMs](https://arxiv.org/abs/2508.20333)

**Authors**: Md Abdullah Al Mamun, Ihsen Alouani, Nael Abu-Ghazaleh  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2508.20333v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) are aligned to meet ethical standards and safety requirements by training them to refuse answering harmful or unsafe prompts. In this paper, we demonstrate how adversaries can exploit LLMs' alignment to implant bias, or ...

---

### 21. [Graph-R1: Unleashing LLM Reasoning with NP-Hard Graph Problems](https://arxiv.org/abs/2508.20373)

**Authors**: Yuyao Wang, Bowen Liu, Jianheng Tang, Nuo Chen, Yuhan Li, Qifan Zhang, Jia Li  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2508.20373v1 Announce Type: cross 
Abstract: Reasoning Large Language Models (RLLMs) have recently achieved remarkable progress on complex reasoning tasks, largely enabled by their long chain-of-thought (Long CoT) capabilities. However, developing these Long CoT behaviors relies heavily on pos...

---

### 22. [Measuring Reasoning Utility in LLMs via Conditional Entropy Reduction](https://arxiv.org/abs/2508.20395)

**Authors**: Xu Guo  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2508.20395v1 Announce Type: cross 
Abstract: Recent advancements in large language models (LLMs) often rely on generating intermediate reasoning steps to enhance accuracy. However, little work has examined how reasoning utility contributes to the final answer's correctness. Due to the stochast...

---

### 23. [MERIT: Maximum-normalized Element-wise Ratio for Language Model Large-batch Training](https://arxiv.org/abs/2508.20577)

**Authors**: Yang Luo, Zangwei Zheng, Ziheng Qin, Zirui Zhu, Yong Liu, Yang You  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2508.20577v1 Announce Type: cross 
Abstract: Large-batch training has become a cornerstone in accelerating the training of deep neural networks, yet it poses challenges in optimization and generalization. Existing optimizers like AdamW present performance degradation during language models' la...

---

### 24. [Rethinking Testing for LLM Applications: Characteristics, Challenges, and a Lightweight Interaction Protocol](https://arxiv.org/abs/2508.20737)

**Authors**: Wei Ma, Yixiao Yang, Qiang Hu, Shi Ying, Zhi Jin, Bo Du, Zhenchang Xing, Tianlin Li, Junjie Shi, Yang Liu, Linxiao Jiang  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2508.20737v1 Announce Type: cross 
Abstract: Applications of Large Language Models~(LLMs) have evolved from simple text generators into complex software systems that integrate retrieval augmentation, tool invocation, and multi-turn interactions. Their inherent non-determinism, dynamism, and co...

---

### 25. [Learning Primitive Embodied World Models: Towards Scalable Robotic Learning](https://arxiv.org/abs/2508.20840)

**Authors**: Qiao Sun, Liujia Yang, Wei Tang, Wei Huang, Kaixin Xu, Yongchao Chen, Mingyu Liu, Jiange Yang, Haoyi Zhu, Yating Wang, Tong He, Yilun Chen, Xili Dai, Nanyang Ye, Qinying Gu  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2508.20840v1 Announce Type: cross 
Abstract: While video-generation-based embodied world models have gained increasing attention, their reliance on large-scale embodied interaction data remains a key bottleneck. The scarcity, difficulty of collection, and high dimensionality of embodied data f...

---

### 26. [Quantum Verifiable Rewards for Post-Training Qiskit Code Assistant](https://arxiv.org/abs/2508.20907)

**Authors**: Nicolas Dupuis, Adarsh Tiwari, Youssef Mroueh, David Kremer, Ismael Faro, Juan Cruz-Benito  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2508.20907v1 Announce Type: cross 
Abstract: Qiskit is an open-source quantum computing framework that allows users to design, simulate, and run quantum circuits on real quantum hardware. We explore post-training techniques for LLMs to assist in writing Qiskit code. We introduce quantum verifi...

---

### 27. [RevPRAG: Revealing Poisoning Attacks in Retrieval-Augmented Generation through LLM Activation Analysis](https://arxiv.org/abs/2411.18948)

**Authors**: Xue Tan, Hao Luan, Mingyu Luo, Xiaoyan Sun, Ping Chen, Jun Dai  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2411.18948v4 Announce Type: replace-cross 
Abstract: Retrieval-Augmented Generation (RAG) enriches the input to LLMs by retrieving information from the relevant knowledge database, enabling them to produce responses that are more accurate and contextually appropriate. It is worth noting that t...

---

### 28. [Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models](https://arxiv.org/abs/2506.22957)

**Authors**: Younwoo Choi, Changling Li, Yongjin Yang, Zhijing Jin  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2506.22957v2 Announce Type: replace-cross 
Abstract: As large language models (LLMs) are increasingly integrated into multi-agent and human-AI systems, understanding their awareness of both self-context and conversational partners is essential for ensuring reliable performance and robust safet...

---

### 29. [Steering Towards Fairness: Mitigating Political Bias in LLMs](https://arxiv.org/abs/2508.08846)

**Authors**: Afrozah Nadeem, Mark Dras, Usman Naseem  
**Category**: cs.AI  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2508.08846v2 Announce Type: replace-cross 
Abstract: Recent advancements in large language models (LLMs) have enabled their widespread use across diverse real-world applications. However, concerns remain about their tendency to encode and reproduce ideological biases along political and econom...

---

### 30. [GDLLM: A Global Distance-aware Modeling Approach Based on Large Language Models for Event Temporal Relation Extraction](https://arxiv.org/abs/2508.20828)

**Authors**: Jie Zhao, Wanting Ning, Yuxiao Fei, Yubo Feng, Lishuang Li  
**Category**: cs.CL  
**Published**: 2025-08-29  
**Score**: 3.5

arXiv:2508.20828v1 Announce Type: new 
Abstract: In Natural Language Processing(NLP), Event Temporal Relation Extraction (ETRE) is to recognize the temporal relations of two events. Prior studies have noted the importance of language models for ETRE. However, the restricted pre-trained knowledge of ...

---

## 🔧 Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative Decoding

## 📅 Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## 🚀 How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## 📝 Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## 🔍 Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
