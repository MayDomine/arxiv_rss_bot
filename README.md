# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-17 05:57:09 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [A Unified Sparse Attention via Multi-Granularity Compression](https://arxiv.org/abs/2512.14082)

**Authors**: Siran Liu, Zane Cao, Yongchao He  
**Category**: cs.CL  
**Published**: 2025-12-17  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2512.14082v1  

#### Abstract
Efficient long-context understanding and reasoning are increasingly vital for large language model (LLM) applications such as multi-turn dialogue and program analysis. However, the core self-attention mechanism scales quadratically with sequence length, creating a fundamental computational bottlenec...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Unified Sparse Attention via Multi-Granularity Compression

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„ **self-attention** æœºåˆ¶åœ¨é•¿åºåˆ—ä¸Šä¸‹æ–‡å»ºæ¨¡ä¸­é¢ä¸´ä¸¥é‡çš„è®¡ç®—ç“¶é¢ˆï¼Œå…¶è®¡ç®—å¤æ‚åº¦ä¸º $O(L^2)$ï¼Œå…¶ä¸­ $L$ æ˜¯åºåˆ—é•¿åº¦ã€‚éšç€ä¸Šä¸‹æ–‡é•¿åº¦ä»æ•°åƒæ‰©å±•åˆ°æ•°åä¸‡ tokenï¼ˆå¦‚ 128Kï¼‰ï¼Œæ³¨æ„åŠ›è®¡ç®—æˆæœ¬å‘ˆæŒ‡æ•°çº§å¢é•¿ï¼Œæˆä¸ºæ¨ç†æ•ˆç‡çš„ä¸»è¦ç“¶é¢ˆã€‚

ç°æœ‰ç¨€ç–æ³¨æ„åŠ›æ–¹æ³•å­˜åœ¨ä»¥ä¸‹æƒè¡¡ï¼š
- **è®­ç»ƒè€¦åˆæ–¹æ³•**ï¼ˆå¦‚ MInferenceã€Mixture-of-Block-Attentionï¼‰ï¼šç²¾åº¦é«˜ï¼Œä½†éœ€é¢å¤–è®­ç»ƒï¼Œæ— æ³•ä½œä¸ºé€šç”¨åŠ é€Ÿæ’ä»¶ç”¨äºå·²æœ‰æ¨¡å‹ã€‚
- **æ¨ç†æ—¶æ–¹æ³•**ï¼šæ— éœ€å†è®­ç»ƒï¼Œä½†å¾€å¾€ç‰ºç‰²æ•ˆç‡æˆ–è·¨æ¨¡æ€æ³›åŒ–èƒ½åŠ›ï¼Œä¾‹å¦‚ï¼š
  - é™æ€æ¨¡å¼ï¼ˆå¦‚ BigBirdï¼‰ç¼ºä¹è¾“å…¥è‡ªé€‚åº”æ€§ï¼›
  - åŠ¨æ€æ–¹æ³•ï¼ˆå¦‚ XAttentionã€FlexPrefillï¼‰ä¾èµ–ç®€åŒ–å¯å‘å¼è§„åˆ™ï¼Œéš¾ä»¥æ•æ‰è¯­ä¹‰ç›¸å…³æ€§ã€‚

å› æ­¤ï¼ŒäºŸéœ€ä¸€ç§**é«˜æ•ˆã€é€šç”¨ã€æ— éœ€å†è®­ç»ƒä¸”é€‚ç”¨äºå¤šæ¨¡æ€ä»»åŠ¡çš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶**ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **UniSparse**ï¼Œä¸€ç§ç»Ÿä¸€çš„ã€ç¡¬ä»¶å‹å¥½çš„åŠ¨æ€ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡**å¤šç²’åº¦å‹ç¼©**ï¼ˆmulti-granularity compressionï¼‰æ„å»º**å¤åˆ token**ï¼ˆcomposite tokensï¼‰ï¼Œå®ç°é«˜æ•ˆçš„å—çº§ç¨€ç–é€‰æ‹©ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š

1. âœ… **å¤åˆ tokenï¼ˆComposite Tokensï¼‰æŠ½è±¡**
   - å°†åŸå§‹ç»†ç²’åº¦ token é€šè¿‡ç©ºé—´æ± åŒ–ï¼ˆå¦‚å¹³å‡æ± åŒ–ï¼‰èšåˆæˆç²—ç²’åº¦çš„â€œå¤åˆ tokenâ€ï¼Œä½œä¸ºä¸Šä¸‹æ–‡ä¿¡æ¯çš„ç´§å‡‘è¡¨ç¤ºã€‚
   - åœ¨å‹ç¼©ç©ºé—´ä¸­è¿›è¡Œæ³¨æ„åŠ›è¯„åˆ†ï¼Œå¤§å¹…é™ä½ä»£ç†è®¡ç®—å¼€é”€ã€‚

2. âœ… **å¤šç²’åº¦å‹ç¼©æœºåˆ¶**
   - æ”¯æŒæ²¿**åºåˆ—ç»´åº¦**å’Œ**å¤´ç»´åº¦**çš„å¯é€‰å‹ç¼©ï¼ˆ`cq`, `ck`, `ch`ï¼‰ï¼Œçµæ´»æ§åˆ¶ç²¾åº¦ä¸æ•ˆç‡å¹³è¡¡ã€‚
   - å‹ç¼©åçš„æ³¨æ„åŠ›çŸ©é˜µå¤§å°ä»…ä¸ºåŸçŸ©é˜µçš„ $1/(cq \cdot ck)$ï¼Œæ˜¾è‘—å‡å°‘è®¡ç®—é‡ã€‚

3. âœ… **åŠ¨æ€å—é€‰æ‹©ç®—æ³•**
   - åœ¨å‹ç¼©ç©ºé—´è®¡ç®—æ³¨æ„åŠ›å¾—åˆ† â†’ èšåˆåˆ°åŸå§‹å—çº§åˆ« â†’ ä½¿ç”¨ **Top-P æœºåˆ¶**é€‰æ‹©æœ€é‡è¦çš„ query-key å—å¯¹ã€‚
   - ç”Ÿæˆç¨€ç–æ©ç  $M$ï¼ŒæŒ‡å¯¼åç»­çš„ block-sparse attention æ‰§è¡Œã€‚

4. âœ… **ç¡¬ä»¶å‹å¥½è®¾è®¡**
   - å®Œå…¨å…¼å®¹ FlashAttention ç­‰æ ‡å‡†å†…æ ¸ï¼Œæ”¯æŒ drop-in æ›¿æ¢ã€‚
   - å®ç°èåˆå†…æ ¸ä¼˜åŒ–ï¼Œä¸­é—´ç»“æœé©»ç•™ on-chip memoryï¼Œå‡å°‘å†…å­˜è®¿é—®å¼€é”€ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ— éœ€è®­ç»ƒ** | å¯ç›´æ¥åº”ç”¨äºé¢„è®­ç»ƒæ¨¡å‹ï¼Œæ— éœ€å¾®è°ƒæˆ–ç¦»çº¿æœç´¢ï¼ŒçœŸæ­£â€œå³æ’å³ç”¨â€ |
| **è·¨æ¨¡æ€é€šç”¨æ€§** | å¤åˆ token å’Œå¹³å‡æ± åŒ–å…·æœ‰æ¨¡æ€æ— å…³æ€§ï¼Œé€‚ç”¨äºæ–‡æœ¬ã€è§†é¢‘ç­‰å¤šæ¨¡æ€ä»»åŠ¡ |
| **é«˜ç²¾åº¦ä¿ç•™** | å®éªŒè¡¨æ˜å¯è¾¾åˆ° â‰¥99% çš„ full-attention å‡†ç¡®ç‡ |
| **é«˜æ•ˆæ€§** | æœ€é«˜å®ç° **2.61Ã— æ›´å¿«çš„æ³¨æ„åŠ›è®¡ç®—é€Ÿåº¦**ï¼ˆvs. FlashAttentionï¼‰ |
| **å…¨å±€æ„ŸçŸ¥èƒ½åŠ›** | ç›¸æ¯”å±€éƒ¨æ¢é’ˆæ–¹æ³•ï¼ˆå¦‚ FlexPrefillï¼‰ï¼ŒUniSparse åœ¨å‹ç¼©ç©ºé—´ä¸­è¯„ä¼°æ‰€æœ‰ query-key äº¤äº’ï¼Œé¿å…é—æ¼é‡è¦ä¾èµ– |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

å®éªŒè¦†ç›–ä¸‰å¤§ç±»é•¿ä¸Šä¸‹æ–‡åŸºå‡†ï¼Œæ¶µç›–åˆæˆä»»åŠ¡ã€çœŸå®ä¸–ç•Œåº”ç”¨å’Œå¤šæ¨¡æ€ç†è§£ï¼š

| æ•°æ®é›† | ç±»å‹ | æè¿° |
|--------|------|------|
| **RULER** | åˆæˆåŸºå‡† | æ§åˆ¶ä»»åŠ¡å¤æ‚åº¦ï¼Œæµ‹è¯•æ£€ç´¢ã€èšåˆã€å¤šè·³æ¨ç†ç­‰æ ¸å¿ƒèƒ½åŠ›ï¼ˆæœ€é•¿ 128K tokensï¼‰ |
| **HELMET** | çœŸå®ä¸–ç•ŒåŸºå‡† | åŒ…å« 7 ä¸ªåº”ç”¨åœºæ™¯ï¼ˆå¦‚é•¿æ–‡æ¡£ QAã€æ‘˜è¦ã€RAGï¼‰ï¼Œè¦æ±‚æ·±åº¦è¯­ä¹‰ç†è§£ï¼ˆæœ€é•¿ 128K tokensï¼‰ |
| **Video-MME** | å¤šæ¨¡æ€è§†é¢‘ç†è§£ | æ¶µç›– 6 ä¸ªè§†è§‰é¢†åŸŸã€30 ä¸ªå­ä»»åŠ¡ï¼Œè¾“å…¥åŒ…æ‹¬å¸§ã€å­—å¹•ã€éŸ³é¢‘ï¼Œæµ‹è¯•æ—¶ç©ºä¸è·¨æ¨¡æ€æ¨ç† |

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹**
- **Meta-Llama-3.1-8B-Instruct**ï¼ˆçº¯æ–‡æœ¬ï¼‰
- **Qwen2.5-7B-Instruct**ï¼ˆå¤šè¯­è¨€æ–‡æœ¬ï¼‰
- **Qwen2.5-VL-7B-Instruct**ï¼ˆè§†è§‰-è¯­è¨€å¤šæ¨¡æ€ï¼‰

#### **è¯„ä¼°åœºæ™¯**
- æ‰€æœ‰æ–¹æ³•ä»…åœ¨ **prefill é˜¶æ®µ**åº”ç”¨ç¨€ç–æ³¨æ„åŠ›ï¼Œdecode é˜¶æ®µä¿æŒ denseã€‚
- ä¸Šä¸‹æ–‡é•¿åº¦èŒƒå›´ï¼š**8K åˆ° 128K tokens**ï¼ˆæˆ–å¯¹åº”è§†é¢‘æ—¶é•¿ï¼‰ã€‚

#### **è¯„ä¼°æŒ‡æ ‡**
- **å‡†ç¡®ç‡ï¼ˆAccuracy / Scoreï¼‰**ï¼šå„ä»»åŠ¡çš„ä¸»æŒ‡æ ‡ï¼ˆå¦‚ QA å‡†ç¡®ç‡ã€å¬å›ç‡ç­‰ï¼‰
- **ç¨€ç–åº¦ï¼ˆSparsityï¼‰**ï¼šè¢«è·³è¿‡çš„ attention block æ¯”ä¾‹
- **é€Ÿåº¦æå‡ï¼ˆSpeedupï¼‰**ï¼šç›¸å¯¹äº FlashAttention çš„ end-to-end æ³¨æ„åŠ›è®¡ç®—æ—¶é—´åŠ é€Ÿæ¯”
- **é€‰æ‹©å¼€é”€ï¼ˆSelection Overhead, Cselectï¼‰**ï¼šç”Ÿæˆç¨€ç–æ©ç çš„æ—¶é—´æˆæœ¬

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **FlashAttention** | å…¨æ³¨æ„åŠ›åŸºçº¿ | å†…å­˜ä¼˜åŒ–çš„ dense attentionï¼Œæä¾›ç²¾åº¦ä¸Šé™ |
| **MInference** | è®­ç»ƒååŠ¨æ€ç¨€ç– | ç¦»çº¿ç´¢å¼•æœç´¢ + head-specific é…ç½®ï¼Œé«˜ç²¾åº¦ä½†æ˜‚è´µ |
| **FlexPrefill** | æ¨ç†æ—¶åŠ¨æ€ç¨€ç– | ä½¿ç”¨æœ€åä¸€ä¸ª query block ä½œä¸ºæ¢é’ˆï¼Œå±€éƒ¨è¯„ä¼°ï¼Œé€Ÿåº¦å¿«ä½†æ˜“æ¼é‡è¦ä¿¡æ¯ |
| **XAttention** | æ¨ç†æ—¶åŠ¨æ€ç¨€ç– | ä½¿ç”¨ anti-diagonal scoring + stride sampling è¿›è¡Œå…¨å±€é‡‡æ ·ï¼Œå¼€é”€è¾ƒé«˜ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **ç²¾åº¦è¡¨ç°ï¼ˆAccuracy Retentionï¼‰**
- UniSparse åœ¨å¤šä¸ªä»»åŠ¡ä¸Š**ä¸€è‡´ä¼˜äºæˆ–åª²ç¾ç°æœ‰ SOTA ç¨€ç–æ–¹æ³•**ã€‚
- åœ¨ **RULER** å’Œ **HELMET** ä¸Šï¼ŒUniSparse (P=0.95) è¾¾åˆ°ï¼š
  - **â‰¥99% çš„ FlashAttention ç²¾åº¦**
  - ç”šè‡³åœ¨æŸäº›é…ç½®ä¸‹**è¶…è¿‡ full attention è¡¨ç°**ï¼ˆå¦‚ Video-MME with subtitlesï¼‰

#### âœ… **æ•ˆç‡è¡¨ç°ï¼ˆSpeedupï¼‰**
- **ç«¯åˆ°ç«¯æ³¨æ„åŠ›è®¡ç®—é€Ÿåº¦æå‡æœ€é«˜è¾¾ 2.61Ã—**ï¼ˆvs. FlashAttentionï¼‰
- åœ¨ 128K åºåˆ—é•¿åº¦ä¸‹ï¼š
  - UniSparse-0.95 å®ç° **2.52Ã— åŠ é€Ÿ**
  - å¯ç”¨ head compression (`ch=2`) åè¿›ä¸€æ­¥æå‡è‡³ **2.61Ã—**
- å›¾ 3 æ˜¾ç¤ºï¼ŒUniSparse çš„ block selection å¼€é”€è¿œä½äº XAttentionï¼Œåœ¨ 128K ä¸‹å®ç° **1.62Ã— ~ 2.64Ã— æ›´å¿«çš„é€‰æ‹©è¿‡ç¨‹**

#### âœ… **ç¨€ç–æ€§ä¸æ•ˆç‡å¹³è¡¡**
- ä½¿ç”¨æ›´å°‘çš„ attention blocksï¼ˆçº¦ 1.5â€“2Ã— æ›´å°‘ï¼‰å³å¯è¾¾åˆ°ç›¸åŒæˆ–æ›´é«˜ç²¾åº¦
- åœ¨ç›¸ä¼¼ç¨€ç–åº¦ä¸‹ï¼ŒUniSparse æ€§èƒ½æ™®éé¢†å…ˆäº FlexPrefill å’Œ XAttention

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| æ–¹æ³• | å‡†ç¡®ç‡ | é€Ÿåº¦ | é€‚ç”¨æ€§ |
|------|--------|------|--------|
| **FlexPrefill** | ä¸­ç­‰åä½ | å¿«ï¼ˆå±€éƒ¨æ¢é’ˆï¼‰ | æ–‡æœ¬å°šå¯ï¼Œå¤šæ¨¡æ€å·® |
| **XAttention** | ä¸­ç­‰ | è¾ƒæ…¢ï¼ˆstrided samplingï¼‰ | å…¨å±€ä½†å¼€é”€å¤§ |
| **MInference** | é«˜ | æ…¢ï¼ˆéœ€ç¦»çº¿æœç´¢ï¼‰ | æ¨¡å‹ç‰¹å®šï¼Œä¸é€šç”¨ |
| **UniSparse** | **é«˜ï¼ˆâ‰¥99% full attnï¼‰** | **æœ€å¿«ï¼ˆ2.61Ã—ï¼‰** | **è·¨æ¨¡æ€ã€å³æ’å³ç”¨** |

> ç¤ºä¾‹ï¼šåœ¨ HELMET ä¸Šï¼ŒUniSparse-0.95 åœ¨ 48.65% ç¨€ç–åº¦ä¸‹å–å¾— **56.21** åˆ†ï¼Œä¼˜äº FlexPrefill-0.99ï¼ˆ56.01ï¼‰å’Œ MInferenceï¼ˆ55.37ï¼‰

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ğŸ”¹ **å‹ç¼©ç­–ç•¥å¯¹æ¯”ï¼ˆTable 5ï¼‰**
- **Average Pooling** æ•ˆæœæœ€ä½³ï¼šä¿¡æ¯èšåˆæœ€å®Œæ•´
- Max/Stochastic Pooling è™½ç„¶ç¨€ç–åº¦æ›´é«˜ï¼Œä½†ç²¾åº¦ä¸‹é™æ˜æ˜¾ï¼ˆå› ä¸¢å¤±ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼‰

#### ğŸ”¹ **Q-K å‹ç¼©æ¯”ä¾‹åˆ†é…ï¼ˆTable 6ï¼‰**
- **å¹³è¡¡å‹ç¼©ï¼ˆcq=ck=8ï¼‰æ•ˆæœæœ€å¥½**
- æŸ¥è¯¢è¿‡åº¦å‹ç¼©ï¼ˆcq=32ï¼‰å¯¼è‡´æ€§èƒ½ä¸¥é‡ä¸‹é™
- é”®åå‘å‹ç¼©ï¼ˆck=16ï¼‰åœ¨éƒ¨åˆ†æ¨¡å‹ä¸Šæœ‰ç«äº‰åŠ›ï¼Œå€¼å¾—è¿›ä¸€æ­¥ç ”ç©¶

#### ğŸ”¹ **å‹ç¼©ç²’åº¦ï¼ˆcï¼‰å½±å“ï¼ˆTable 7ï¼‰**
- é»˜è®¤ `c=8` æ˜¯æœ€ä½³æŠ˜è¡·ï¼š
  - `c=4`ï¼šå¤ªç²¾ç»†ï¼Œå¼€é”€å¤§
  - `c=16/32`ï¼šè¿‡åº¦å¹³æ»‘ï¼Œä¸¢å¤±ç»†èŠ‚
- `c=8` åœ¨ç²¾åº¦ä¸æ•ˆç‡é—´å–å¾—è‰¯å¥½å¹³è¡¡

#### ğŸ”¹ **å¤´å‹ç¼©ï¼ˆHead Compression, chï¼‰å½±å“ï¼ˆTable 8ï¼‰**
- `ch=2` æˆ– `4` å¯æ˜¾è‘—é™ä½ selection overheadï¼ˆæœ€é«˜ 2.64Ã— vs XAttentionï¼‰
- ä»£ä»·æ˜¯ç•¥å¾®é™ä½ç¨€ç–åº¦ï¼ˆæ›´å¤š block è¢«è®¤ä¸ºé‡è¦ï¼‰
- é€‚åˆ selection æˆä¸ºç“¶é¢ˆçš„åœºæ™¯ï¼Œtrade-off å¯æ§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **å‹ç¼©ç©ºé—´ä¸­çš„ç›¸å¯¹æ’åºè¶³ä»¥æŒ‡å¯¼é«˜è´¨é‡å—é€‰æ‹©**
   - å®éªŒè¯æ˜ï¼Œå‹ç¼© token çš„é‡è¦æ€§æ’åä¸åŸå§‹ç©ºé—´é«˜åº¦ä¸€è‡´ï¼ˆSpearman Ï > 0.98ï¼‰
   - è¯´æ˜ block selection æœ¬è´¨æ˜¯ ranking é—®é¢˜ï¼Œè€Œéç²¾ç¡® scoring

2. âœ… **å¹³å‡æ± åŒ–æ˜¯æœ€ä¼˜çš„å¤åˆ token æ„é€ æ–¹å¼**
   - èƒ½æœ‰æ•ˆä¿ç•™å±€éƒ¨è¯­ä¹‰ç»“æ„ï¼Œé¿å…ä¿¡æ¯ä¸¢å¤±

3. âœ… **UniSparse å®ç°äº†ç²¾åº¦ä¸æ•ˆç‡çš„å¸•ç´¯æ‰˜å‰æ²¿**
   - åœ¨å¤šç§ä»»åŠ¡ã€æ¨¡å‹ã€æ¨¡æ€ä¸‹å‡ä¼˜äºä¸»æµç¨€ç–æ–¹æ³•
   - æ˜¯ç›®å‰å”¯ä¸€èƒ½åœ¨ä¿æŒ â‰¥99% full-attention ç²¾åº¦çš„åŒæ—¶å®ç° >2.5Ã— åŠ é€Ÿçš„æ–¹æ³•

4. âœ… **å…·å¤‡å¼ºè·¨æ¨¡æ€æ³›åŒ–èƒ½åŠ›**
   - åœ¨ Video-MME ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨å¸¦å­—å¹•åœºæ™¯ä¸‹ç”šè‡³è¶…è¶Š full attentionï¼Œè¯æ˜å…¶èƒ½æœ‰æ•ˆä¿ç•™è·¨æ¨¡æ€å…³é”®ä¿¡æ¯

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. âš ï¸ **æç«¯å‹ç¼©å¯èƒ½å¯¼è‡´ç»†ç²’åº¦ä¿¡æ¯ä¸¢å¤±**
   - å¦‚åœ¨éœ€è¦ç²¾ç¡®å®šä½çš„ä»»åŠ¡ï¼ˆå¦‚ citation localizationï¼‰ä¸­ï¼Œè¿‡é«˜å‹ç¼©å¯èƒ½å½±å“æ€§èƒ½

2. âš ï¸ **Top-P é˜ˆå€¼éœ€æ‰‹åŠ¨è®¾å®š**
   - è™½ç„¶é»˜è®¤ `P=0.9/0.95` è¡¨ç°è‰¯å¥½ï¼Œä½†å°šæœªå®ç°å®Œå…¨è‡ªé€‚åº”é˜ˆå€¼é€‰æ‹©

3. âš ï¸ **å½“å‰å®ç°ä»å‡è®¾å›ºå®š block size**
   - å¯¹å˜é•¿è¾“å…¥æˆ–éå‡åŒ€åˆ†å¸ƒä¸Šä¸‹æ–‡çš„æ”¯æŒæœ‰å¾…å¢å¼º

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. ğŸ”„ **è‡ªé€‚åº”å‹ç¼©å› å­è°ƒèŠ‚**
   - æ ¹æ®è¾“å…¥å†…å®¹åŠ¨æ€è°ƒæ•´ `cq`, `ck`, `ch`ï¼Œå®ç°æ›´æ™ºèƒ½çš„ç²¾åº¦-æ•ˆç‡æƒè¡¡

2. ğŸ§  **ç»“åˆ KV Cache å‹ç¼©ä¸é‡åŒ–**
   - ä¸ SnapKVã€KVCache-Q ç­‰æŠ€æœ¯è”åˆä¼˜åŒ–ï¼Œè¿›ä¸€æ­¥æå‡ç«¯åˆ°ç«¯æ¨ç†æ•ˆç‡

3. ğŸŒ **æ‰©å±•è‡³ encoder-decoder æ¶æ„**
   - å½“å‰èšç„¦ decoder-only æ¨¡å‹ï¼Œæœªæ¥å¯é€‚é… T5ã€BART ç­‰æ¶æ„

4. ğŸ¤– **æ¢ç´¢æ›´å¤æ‚çš„èšåˆå‡½æ•°**
   - å¦‚è½»é‡çº§ attention-based poolingï¼Œæ›¿ä»£ç®€å•å¹³å‡æ± åŒ–ï¼Œåœ¨ä¸å¢åŠ å¤ªå¤šå¼€é”€çš„å‰æä¸‹æå‡è¡¨è¾¾èƒ½åŠ›

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> UniSparse é€šè¿‡å¼•å…¥ **å¤åˆ token + å¤šç²’åº¦å‹ç¼© + Top-P å—é€‰æ‹©**ï¼Œå®ç°äº†**æ— éœ€è®­ç»ƒã€è·¨æ¨¡æ€é€šç”¨ã€é«˜ç²¾åº¦ã€é«˜æ•ˆç‡**çš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ˜¯è¿ˆå‘å®ç”¨åŒ–é•¿ä¸Šä¸‹æ–‡ LLM æ¨ç†çš„é‡è¦ä¸€æ­¥ã€‚

</details>

---

### 2. [Fast and Accurate Causal Parallel Decoding using Jacobi Forcing](https://arxiv.org/abs/2512.14681)

**Authors**: Lanxiang Hu, Siqi Kou, Yichao Fu, Samyam Rajbhandari, Tajana Rosing, Yuxiong He, Zhijie Deng, Hao Zhang  
**Category**: cs.CL  
**Published**: 2025-12-17  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2512.14681v1  

#### Abstract
Multi-token generation has emerged as a promising paradigm for accelerating transformer-based large model inference. Recent efforts primarily explore diffusion Large Language Models (dLLMs) for parallel decoding to reduce inference latency. To achieve AR-level generation quality, many techniques ada...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Fast and Accurate Causal Parallel Decoding using Jacobi Forcing è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ™®éé‡‡ç”¨ **Autoregressive (AR)** è§£ç æ–¹å¼é€ä¸ªç”Ÿæˆ tokenï¼Œå¯¼è‡´æ¨ç†å»¶è¿Ÿé«˜ã€å¹¶è¡Œåº¦ä½ã€‚è™½ç„¶è¿‘æœŸç ”ç©¶æå‡ºåŸºäºæ‰©æ•£çš„ **diffusion LLMs (dLLMs)** æ¥å®ç°å¤š token å¹¶è¡Œè§£ç ä»¥åŠ é€Ÿæ¨ç†ï¼Œä½†è¿™äº›æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

- **Pretrain-to-posttrain mismatch**ï¼šdLLMs åœ¨åè®­ç»ƒé˜¶æ®µä½¿ç”¨æ©ç æ•°æ®å’ŒåŒå‘æ³¨æ„åŠ›æœºåˆ¶ï¼Œä¸é¢„è®­ç»ƒæ—¶çš„å› æœå…ˆéªŒï¼ˆcausal priorï¼‰ä¸ä¸€è‡´ï¼Œå¯¼è‡´è´¨é‡ä¸‹é™ã€‚
- **éš¾ä»¥å¤ç”¨ KV Cache**ï¼šåŒå‘æ³¨æ„åŠ›ç ´åäº†å› æœæ€§ï¼Œé˜»ç¢äº†ç²¾ç¡®çš„ KV Cache å¤ç”¨ã€‚
- **é€Ÿåº¦æå‡æœ‰é™**ï¼šå°½ç®¡å¼•å…¥äº†å¹¶è¡Œæœºåˆ¶ï¼Œä½†ç”±äºè®­ç»ƒç›®æ ‡ï¼ˆå¦‚ NELBOï¼‰æ•ˆç‡ä½ä¸‹ï¼Œå®é™…åŠ é€Ÿæ•ˆæœå—é™ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šJacobi Forcing
æœ¬æ–‡æå‡º **Jacobi Forcing** â€”â€” ä¸€ç§æ¸è¿›å¼è’¸é¦èŒƒå¼ï¼ˆprogressive distillationï¼‰ï¼Œç”¨äºå°†æ ‡å‡† AR æ¨¡å‹é«˜æ•ˆåœ°è½¬åŒ–ä¸ºé«˜æ€§èƒ½å¹¶è¡Œè§£ç å™¨ï¼ˆç§°ä¸º **Jacobi Forcing Model**ï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **åœ¨æ¨¡å‹è‡ªèº«ç”Ÿæˆçš„ Jacobi è§£ç è½¨è¿¹ä¸Šè¿›è¡Œè®­ç»ƒ**ï¼Œæ— éœ€ä¿®æ”¹åŸå§‹æ¨¡å‹çš„å› æœæ³¨æ„åŠ›ç»“æ„ã€‚
- å¼•å…¥ **noise-aware causal attention** å’Œ **progressive noise schedule**ï¼Œä½¿æ¨¡å‹å­¦ä¼šåœ¨å™ªå£°ä¸Šä¸‹æ–‡ä¸­é¢„æµ‹æ”¶æ•›ç‚¹ã€‚
- é€šè¿‡å¤šè½®æ¸è¿›å¼è’¸é¦ï¼ˆé€æ­¥å¢å¤§ block sizeï¼‰ï¼ŒæŒç»­æå‡æ¨¡å‹çš„å¹¶è¡Œè§£ç èƒ½åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **è®­ç»ƒä¸€è‡´æ€§** | é¿å…äº† pretrain-posttrain åˆ†å¸ƒåç§»ï¼Œä¿ç•™äº† AR æ¨¡å‹åŸæœ‰çš„å› æœæ¨ç†ç‰¹æ€§ |
| **KV Cache åˆ©ç”¨** | æ”¯æŒç²¾ç¡®çš„ KV Cache å¤ç”¨ï¼Œæé«˜æ¨ç†æ•ˆç‡ |
| **å¯æ‰©å±•æ€§** | èƒ½éš block size å¢å¤§è€Œç¨³å®šæå‡ååé‡ï¼Œå……åˆ†åˆ©ç”¨ç°ä»£ AI åŠ é€Ÿå™¨ç®—åŠ› |
| **è´¨é‡ä¿æŒ** | åœ¨æ˜¾è‘—æé€Ÿçš„åŒæ—¶ï¼Œç”Ÿæˆè´¨é‡æ¥è¿‘åŸå§‹ AR æ¨¡å‹ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **Coding Benchmarks**ï¼š
  - **HumanEval**ï¼ˆä»£ç ç”Ÿæˆï¼‰
  - **MBPP**ï¼ˆPython ç¼–ç¨‹ä»»åŠ¡ï¼‰
  - è®­ç»ƒæ•°æ®ï¼š**OpenCodeInstruct**ï¼ˆ450k promptsï¼‰
- **Mathematical Reasoning Benchmarks**ï¼š
  - **GSM8K**
  - **MATH**
  - è®­ç»ƒæ•°æ®ï¼š**Openthought2** ä¸­çš„æ•°å­¦ç±» prompt

æ‰€æœ‰æ¨¡å‹å‡åŸºäº **Qwen2.5-Coder-7B-Instruct** æˆ– **Qwen2.5-Math-7B-Instruct** å¾®è°ƒã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA A100-80GBã€H200ã€B200 GPU
- **è®­ç»ƒé…ç½®**ï¼š
  - å­¦ä¹ ç‡ï¼š1e-5
  - Batch sizeï¼š4
  - Max sequence lengthï¼š2048
  - Block sizeï¼šåˆå§‹ä¸º 16ï¼Œç¬¬äºŒè½®è®­ç»ƒæ‰©å¤§è‡³ 32
- **æ¨ç†é…ç½®**ï¼š
  - Block sizeï¼š128ï¼ˆé™¤ MR å˜ä½“å¤–ï¼‰
  - å¤šå—è§£ç ï¼ˆmulti-block decodingï¼‰æ”¯æŒæœ€å¤š $ K=2 $ ä¸ªå¹¶å‘å—
  - åˆå§‹åŒ–é˜ˆå€¼ $ r=0.85 $

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **TPF (Tokens Per Forward)** | æ¯æ¬¡å‰å‘ä¼ æ’­æ¥å—çš„ token æ•°é‡ï¼Œè¡¡é‡å¹¶è¡Œæ•ˆç‡ |
| **TPS (Tokens Per Second)** | å®é™…æ¯ç§’ç”Ÿæˆ token æ•°ï¼Œåæ˜ çœŸå®æ¨ç†é€Ÿåº¦ |
| **Speedup** | ç›¸å¯¹äº AR åŸºçº¿çš„é€Ÿåº¦æå‡å€æ•° |
| **Accuracy / Solve Rate** | HumanEval ä¸Šçš„ pass@1 å‡†ç¡®ç‡ï¼›GSM8K/MATH ä¸Šçš„é—®é¢˜è§£å†³ç‡ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | æ–¹æ³• |
|------|------|
| **AR-based Parallel Decoding** | Vanilla Jacobi, CLLM*, Jacobi Forcing (Ours) |
| **Diffusion-based LLMs (dLLMs)** | LLaDA-Instruct, Dream-Base, Fast-dLLM(DC), D2F |
| **Speculative Decoding**ï¼ˆé™„å½•è¡¥å……ï¼‰ | EAGLE-3, HASS |
| **Distilled dLLM** | dParallel |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆA100 GPUï¼‰

#### è¡¨æ ¼ 1ï¼šCoding ä»»åŠ¡è¡¨ç°ï¼ˆHumanEval & MBPPï¼‰

| æ–¹æ³• | TPS | Speedup | Accuracy |
|------|-----|---------|----------|
| AR (Baseline) | 41.3 | 1.00Ã— | 87.8% |
| CLLM* | 103.3 | 2.50Ã— | 87.8% |
| **Jacobi Forcing Model** | **159.5** | **3.86Ã—** | **83.5%** |
| **Jacobi Forcing Model (MR)** | **163.9** | **3.97Ã—** | **83.5%** |

> æ³¨ï¼šMR = Multi-block + Rejection Recycling

#### è¡¨æ ¼ 2ï¼šMath ä»»åŠ¡è¡¨ç°ï¼ˆGSM8K & MATHï¼‰

| æ–¹æ³• | TPS | Speedup | Solve Rate |
|------|-----|---------|------------|
| AR (Baseline) | 41.8 | 1.00Ã— | 92.4% |
| **Jacobi Forcing Model** | **146.1** | **3.50Ã—** | **91.4%** |
| **Jacobi Forcing Model (MR)** | **154.9** | **3.71Ã—** | **91.4%** |

> åœ¨ MATH ä¸Šç”šè‡³è½»å¾®æå‡äº†å‡†ç¡®ç‡ï¼ˆ77.0% â†’ 77.4%ï¼‰

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç›¸æ¯” dLLMs**ï¼š
  - Jacobi Forcing æ¯” Dream-Base å¿« **7.4Ã—~15Ã—**
  - æ¯” Fast-dLLM å’Œ D2F å¿« **2.0Ã—~2.2Ã—**
  - ä¸”å‡†ç¡®ç‡é«˜å‡º **20~40 ä¸ªç™¾åˆ†ç‚¹**
- **ç›¸æ¯” AR-based æ–¹æ³•**ï¼š
  - æ¯” CLLM å¿« **1.5Ã—~1.8Ã—**
  - åœ¨ä¿æŒç›¸è¿‘è´¨é‡çš„å‰æä¸‹å®ç°æ›´é«˜åå

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰Noise Schedule å¯¹æ¯”ï¼ˆè¡¨ 4ï¼‰
| Schedule | Window Size | Accuracy | iter/token |
|--------|-------------|----------|-----------|
| Random | 16 | 83.5% | 0.51 |
| **Linear Progressive** | **16** | **81.7%** | **0.46** âœ… |
| Reverse Progressive | 16 | 82.9% | 0.62 âŒ |

âœ… ç»“è®ºï¼š**Linear Progressive Schedule** æ˜¾è‘—é™ä½è¿­ä»£æ¬¡æ•°ï¼Œæå‡è®­ç»ƒæ•ˆç‡ã€‚

#### ï¼ˆ2ï¼‰Attention Mask è®¾è®¡ï¼ˆè¡¨ 5ï¼‰
| Mask Type | Speedup | Accuracy |
|----------|--------|----------|
| Noise-conditioned (NC) | **3.6Ã—** | 82.3% |
| NC + Intra-window Clean Context (NC-IC) | 1.9Ã— | 82.3% |

âœ… ç»“è®ºï¼š**noise-aware causal mask** æ›´æœ‰æ•ˆï¼Œé¿å…å› æ¸…æ´ä¸Šä¸‹æ–‡å¹²æ‰°å­¦ä¹ å™ªå£°æ¡ä»¶ä¸‹çš„é¢„æµ‹èƒ½åŠ›ã€‚

#### ï¼ˆ3ï¼‰FLOPs åˆ©ç”¨åˆ†æï¼ˆå›¾ 7ï¼‰
- åœ¨ H200/B200 ä¸Šï¼Œæœ€å¤šå¯å¹¶è¡Œå¤„ç† **~256 tokens** è€Œä¸å¢åŠ å»¶è¿Ÿï¼›
- åœ¨ A100 ä¸Šçº¦ä¸º **~128 tokens**ï¼›
- æ¨ç†é…ç½®é€‰æ‹© **block size=64, verification size=4**ï¼ˆå…± 256 tokensï¼‰ä»¥æœ€å¤§åŒ– FLOPs åˆ©ç”¨ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Jacobi Forcing æ˜¯æœ‰æ•ˆçš„æ¸è¿›å¼è’¸é¦æ¡†æ¶**ï¼š
   - æˆåŠŸå°† AR æ¨¡å‹è½¬åŒ–ä¸ºé«˜æ•ˆçš„å¹¶è¡Œè§£ç å™¨ï¼ŒåŒæ—¶ä¿ç•™å…¶é«˜è´¨é‡ç”Ÿæˆèƒ½åŠ›ã€‚
   - å®ç°äº†é«˜è¾¾ **3.8Ã—~4.0Ã—** çš„ wall-clock é€Ÿåº¦æå‡ã€‚

2. **æ¨¡å‹å…·å¤‡æ›´å¼ºçš„â€œå‰ç»â€èƒ½åŠ›**ï¼š
   - Jacobi Forcing Model èƒ½åœ¨å™ªå£°ä¸Šä¸‹æ–‡ä¸­ç”Ÿæˆæ›´å¤šæ­£ç¡®åç»­ tokenï¼ˆhigher fast-forwarded token countï¼‰ã€‚
   - å°¾éƒ¨å‡ºç°è¿ç»­æ­£ç¡®çš„â€œfixed-point segmentsâ€ï¼Œå¯ç”¨äºåŠ é€ŸéªŒè¯ã€‚

3. **Rejection Recycling + Multi-block Decoding æ˜¾è‘—å¢å¼ºæ•ˆç‡**ï¼š
   - åˆ©ç”¨å†å²è¿­ä»£ä¸­çš„é«˜è´¨é‡ n-gram è¿›è¡Œå€™é€‰æ„é€ ï¼›
   - å¤šå—å¹¶è¡Œç»´æŠ¤å…è®¸æå‰è§£ç åç»­ blockï¼›
   - äºŒè€…ç»“åˆä½¿æ¯æ¬¡è¿­ä»£æ¥å—çš„ token æ•°æå‡ **4.5Ã—**ã€‚

4. **ä¼˜äºå½“å‰ä¸»æµå¹¶è¡Œè§£ç æ–¹æ¡ˆ**ï¼š
   - åœ¨é€Ÿåº¦-è´¨é‡æƒè¡¡æ›²çº¿ä¸Šæ˜æ˜¾ä¼˜äº dLLMs å’Œ speculative decoding æ–¹æ³•ï¼ˆè§é™„å½•è¡¨ 6ï¼‰ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä»ä¾èµ–äº AR æ¨¡å‹ä½œä¸ºåŸºç¡€æ¶æ„**ï¼Œæ— æ³•å®Œå…¨æ‘†è„±è‡ªå›å½’ç»“æ„é™åˆ¶ã€‚
- **è®­ç»ƒæˆæœ¬è¾ƒé«˜**ï¼šéœ€è¦æ”¶é›†å¤§é‡ Jacobi è½¨è¿¹ï¼Œå¹¶è¿›è¡Œä¸¤é˜¶æ®µæ¸è¿›è®­ç»ƒã€‚
- **å¯¹é•¿åºåˆ—ä¼˜åŒ–æœ‰é™**ï¼šç›®å‰ä¸»è¦é’ˆå¯¹ä¸­ç­‰é•¿åº¦è¾“å‡ºï¼ˆ<2048 tokensï¼‰è®¾è®¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•åˆ°æ›´å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚ 70B+ï¼‰å’Œæ›´å¤æ‚ä»»åŠ¡ï¼ˆå¦‚é•¿æ–‡æœ¬ç”Ÿæˆã€è§„åˆ’ï¼‰ã€‚
- æ¢ç´¢éè´ªå©ªé‡‡æ ·ç­–ç•¥ä¸‹çš„ Jacobi Forcingï¼ˆç›®å‰åŸºäº greedy decodingï¼‰ã€‚
- ç»“åˆ speculative decoding æ„å»ºæ··åˆåŠ é€Ÿç³»ç»Ÿã€‚
- è‡ªé€‚åº”è°ƒæ•´ block size å’Œ noise schedule ä»¥åº”å¯¹ä¸åŒè¾“å…¥å¤æ‚åº¦ã€‚

---

> ğŸ”— **å¼€æºä¿¡æ¯**ï¼šä»£ç å·²å…¬å¼€äº GitHub  
> ğŸ‘‰ https://github.com/hao-ai-lab/JacobiForcing

</details>

---

### 3. [Meta Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN](https://arxiv.org/abs/2512.13715)

**Authors**: Fatemeh Lotfi, Fatemeh Afghah  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.13715v1  

#### Abstract
The increasing complexity of modern applications demands wireless networks capable of real time adaptability and efficient resource management. The Open Radio Access Network (O-RAN) architecture, with its RAN Intelligent Controller (RIC) modules, has emerged as a pivotal solution for dynamic resourc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£æ— çº¿ç½‘ç»œï¼ˆç‰¹åˆ«æ˜¯åŸºäº **O-RAN** æ¶æ„ï¼‰é¢ä¸´åŠ¨æ€ã€å¼‚æ„ä¸”ä¸å¯é¢„æµ‹çš„èµ„æºç®¡ç†æŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ–¹æ³•åœ¨åº”å¯¹çªå‘æµé‡ã€éå¹³ç¨³ç¯å¢ƒä»¥åŠå¤šç±»å‹ç½‘ç»œåˆ‡ç‰‡ï¼ˆå¦‚ eMBBã€URLLC å’Œ mMTCï¼‰å…±å­˜æ—¶ï¼Œéš¾ä»¥å®ç°å¿«é€Ÿé€‚åº”ä¸é«˜æ•ˆèµ„æºåˆ†é…ã€‚ç°æœ‰åŸºäº **DRL** æˆ– **Meta-RL** çš„æ–¹æ³•å¾€å¾€ç¼ºä¹ç¨³å®šæ€§ä¿è¯ã€å¯æ‰©å±•æ€§éªŒè¯ä¸è¶³ï¼Œä¸”å¯¹å¤æ‚åœºæ™¯çš„æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„ **è‡ªé€‚åº” Meta-Hierarchical Reinforcement Learning (Meta-HRL)** æ¡†æ¶ï¼Œç”¨äº O-RAN ä¸­çš„å¯æ‰©å±•èµ„æºç®¡ç†å’Œç½‘ç»œåˆ‡ç‰‡ä¼˜åŒ–ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **åˆ†å±‚æ§åˆ¶æ¶æ„ï¼ˆHierarchical Controlï¼‰**ï¼š
  - é«˜å±‚æ§åˆ¶å™¨ï¼ˆHigh-level Controllerï¼‰è´Ÿè´£è·¨åˆ‡ç‰‡çš„èµ„æºåˆ†é…ï¼ˆInter-slice Resource Allocationï¼‰ï¼›
  - ä½å±‚ä»£ç†ï¼ˆLow-level Agentsï¼‰æ‰§è¡Œå„åˆ‡ç‰‡å†…çš„ç”¨æˆ·çº§è°ƒåº¦ï¼ˆIntra-slice Schedulingï¼‰ï¼›
  - è¿™ç§åˆ†è§£æ˜¾è‘—é™ä½äº†å†³ç­–ç©ºé—´å¤æ‚åº¦ï¼Œæå‡äº†å­¦ä¹ æ•ˆç‡å’Œå¯æ‰©å±•æ€§ã€‚

- **åŸºäº MAML çš„å…ƒå­¦ä¹ æœºåˆ¶ï¼ˆMeta-Learning Inspired by MAMLï¼‰**ï¼š
  - å°†æ¯ä¸ªåˆ†å¸ƒå¼å•å…ƒï¼ˆDUï¼‰è§†ä¸ºä¸€ä¸ªç‹¬ç«‹çš„ meta-taskï¼Œåˆ©ç”¨ **Model-Agnostic Meta-Learning (MAML)** æ€æƒ³è®­ç»ƒä¸€ä¸ªå…¨å±€ meta-modelï¼›
  - å®ç°â€œå­¦ä¼šå­¦ä¹ â€ï¼ˆlearn to learnï¼‰ï¼Œä½¿æ¨¡å‹èƒ½ä»å†å²ä»»åŠ¡ä¸­æå–é€šç”¨ç­–ç•¥ï¼Œå¹¶åœ¨æ–° DU æˆ–çªå‘éœ€æ±‚ä¸‹å¿«é€Ÿå¾®è°ƒï¼ˆfew-shot adaptationï¼‰ã€‚

- **è‡ªé€‚åº”åŠ æƒå…ƒæ›´æ–°æœºåˆ¶ï¼ˆAdaptive Variance-Weighted Meta Updateï¼‰**ï¼š
  - å¼•å…¥åŸºäº **Temporal Difference Error (TD-error) æ–¹å·®** çš„åŠ¨æ€æƒé‡ $ w_g = \text{Softmin}(\sigma^2_{\text{TD},g}) $ï¼›
  - åœ¨å…ƒæ¢¯åº¦æ›´æ–°ä¸­ä¼˜å…ˆå…³æ³¨é«˜æ–¹å·®ä»»åŠ¡ï¼ˆå³æ›´å¤æ‚ã€ä¸ç¡®å®šæ€§æ›´é«˜çš„ç½‘ç»œçŠ¶æ€ï¼‰ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦ã€‚

- **ç†è®ºä¿éšœ**ï¼š
  - æä¾›äº†è¯¥ä¸¤å±‚çº§å­¦ä¹ è¿‡ç¨‹çš„ **æ¬¡çº¿æ€§æ”¶æ•›ï¼ˆsublinear convergenceï¼‰** å’Œ **æ¬¡çº¿æ€§é—æ†¾ç•Œï¼ˆregret boundï¼‰** çš„ç†è®ºåˆ†æï¼Œå¢å¼ºäº†æ–¹æ³•çš„å¯ä¿¡åº¦ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **é€‚åº”æ€§** | æ˜¾è‘—ä¼˜äºä¼ ç»Ÿ DRLã€Transfer Learning (TL) å’Œ Multi-Task Learning (MTL)ï¼Œèƒ½åœ¨å°‘é‡æ ·æœ¬ï¼ˆfew-shotï¼‰å†…å®Œæˆå¿«é€Ÿé€‚é…ï¼› |
| **æ€§èƒ½** | åœ¨ QoS æ»¡è¶³ç‡ã€ååé‡ã€å…¬å¹³æ€§ç­‰æ–¹é¢å…¨é¢é¢†å…ˆï¼› |
| **å¯æ‰©å±•æ€§** | æ”¯æŒå¤§è§„æ¨¡ DU å’Œ UE æ‰©å±•ï¼Œæ€§èƒ½ä¸‹é™æå°ï¼› |
| **é²æ£’æ€§** | å¯¹çªå‘æµé‡ã€çƒ­ç‚¹åŒºåŸŸç­‰ corner cases è¡¨ç°å‡ºæ›´å¼ºéŸ§æ€§ï¼› |
| **ç†è®ºæ”¯æŒ** | æ˜¯å°‘æ•°æä¾›æ”¶æ•›æ€§å’Œ regret åˆ†æçš„ O-RAN èµ„æºç®¡ç†æ–¹æ¡ˆä¹‹ä¸€ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸ä»¿çœŸç¯å¢ƒ
- ä½¿ç”¨è‡ªç ”çš„ **O-RAN ä»¿çœŸæ¡†æ¶**ï¼Œæœªä¾èµ–å…¬å¼€çœŸå®æ•°æ®é›†ï¼›
- ç½‘ç»œæ‹“æ‰‘åŒ…å«å¤šä¸ª DUï¼ˆDistributed Unitï¼‰ã€RUï¼ˆRadio Unitï¼‰ã€CUï¼ˆCentralized Unitï¼‰åŠ RIC æ¨¡å—ï¼›
- ç”¨æˆ·è®¾å¤‡ï¼ˆUEï¼‰éšæœºåˆ†å¸ƒåœ¨ä¸åŒåŒºåŸŸï¼Œå…·æœ‰ç§»åŠ¨æ€§å»ºæ¨¡ï¼ˆé€Ÿåº¦ 10â€“20 m/sï¼‰ï¼›
- æ”¯æŒä¸‰ç§å…¸å‹ç½‘ç»œåˆ‡ç‰‡ï¼š
  - **eMBB**ï¼ˆå¢å¼ºç§»åŠ¨å®½å¸¦ï¼‰
  - **mMTC**ï¼ˆæµ·é‡æœºå™¨ç±»é€šä¿¡ï¼‰
  - **URLLC**ï¼ˆè¶…å¯é ä½æ—¶å»¶é€šä¿¡ï¼‰

### å®éªŒè®¾ç½®
| å‚æ•° | è®¾ç½® |
|------|------|
| å­è½½æ³¢é—´éš” | 15 kHz |
| å•ä¸ª DU å¸¦å®½ | 20 MHz |
| æ¯ DU RB æ•°é‡ $ K_p $ | 100 |
| ç”¨æˆ·æ•° per DU | 30 |
| åˆ†å¸ƒå¼å•å…ƒæ•°é‡ $ N_g $ | é»˜è®¤ 7ï¼Œæœ€å¤§æ‰©å±•è‡³ 30 |
| æ€»ç”¨æˆ·æ•° $ N_u $ | æœ€å¤§ 200 |
| å­¦ä¹ ç®—æ³• | DDPGï¼ˆActor-Critic æ¶æ„ï¼‰ |
| ç¥ç»ç½‘ç»œç»“æ„ | ä¸‰å±‚å…¨è¿æ¥ï¼ˆ256â†’512â†’512ï¼‰ï¼Œæ¿€æ´»å‡½æ•°ä¸º tanh |
| ä¼˜åŒ–å™¨ | Adam ($ \text{lr} = 10^{-4} $) |
| æŠ˜æ‰£å› å­ $ \gamma $ | 0.99 |

### è¯„ä¼°æŒ‡æ ‡
- **ç´¯è®¡å¥–åŠ±ï¼ˆCumulative Rewardï¼‰**
- **QoS æ»¡è¶³ç‡ï¼ˆCDF of QoSï¼‰**
  - eMBBï¼šå¹³å‡ååé‡ï¼ˆMbpsï¼‰
  - mMTCï¼šè´¨é‡åŠ æƒå®¹é‡ï¼ˆQuality-Weighted Network Capacityï¼‰
  - URLLCï¼šæœ€å¤§å»¶è¿Ÿï¼ˆmsï¼‰
- **ç”¨æˆ·ä½“éªŒï¼ˆQoEï¼‰**ï¼šç”¨æˆ·ååé‡åˆ†å¸ƒ
- **é€‚åº”æ€§èƒ½ï¼ˆAdaptation Performanceï¼‰**ï¼šä¸åŒ shot æ•°ä¸‹çš„è¡¨ç°
- **å¯æ‰©å±•æ€§**ï¼šéš DU å’Œ UE æ•°é‡å¢åŠ çš„æ€§èƒ½å˜åŒ–
- **å…¬å¹³æ€§**ï¼šJainâ€™s Fairness Index
- **å»¶è¿Ÿ**ï¼šå¹³å‡åŒ…å»¶è¿Ÿ

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **DRL**ï¼šä»é›¶å¼€å§‹è®­ç»ƒçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ 
- **Transfer Learning (TL)**ï¼šå°†å·²æœ‰ agent çš„çŸ¥è¯†è¿ç§»åˆ°æ–°ä»»åŠ¡
- **Multi-Task Learning (MTL)**ï¼šåŒæ—¶å­¦ä¹ å¤šä¸ªä»»åŠ¡
- **MAML-RL**ï¼šæ ‡å‡†å…ƒå¼ºåŒ–å­¦ä¹ ï¼ˆæ— è‡ªé€‚åº”åŠ æƒï¼‰
- **Uniform-Meta**ï¼šç­‰æƒå…ƒæ›´æ–°ï¼ˆæ¶ˆèå®éªŒç”¨ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **ç½‘ç»œç®¡ç†æ•ˆç‡æå‡**ï¼šç›¸æ¯”åŸºçº¿æ–¹æ³•ï¼ˆDRLã€TLã€MTLã€MAML-RLï¼‰ï¼Œæ‰€æ **Meta-HRL æ¡†æ¶å®ç°äº† 19.8% çš„æœ€ç»ˆå›æŠ¥å€¼æå‡**ï¼ˆè§å›¾4ï¼‰ã€‚
- **æ›´å¿«é€‚åº”èƒ½åŠ›**ï¼š
  - åœ¨ 5-shot åœºæ™¯ä¸‹ï¼Œ**Adaptive MAML-RL æ¯” MAML-RL æå‡çº¦ 4%**ï¼Œæ¯” DRL æå‡é«˜è¾¾ **73%**ï¼›
  - æ¶ˆèå®éªŒæ˜¾ç¤ºï¼Œè‡ªé€‚åº”åŠ æƒæœºåˆ¶ä½¿æ”¶æ•›æ‰€éœ€é€‚åº”æ­¥æ•°å‡å°‘ **40%**ï¼ˆä» 28 é™è‡³ 17ï¼‰ï¼›
- **QoS è¡¨ç°ä¼˜å¼‚**ï¼š
  - **eMBB åˆ‡ç‰‡**ï¼šååé‡æ˜¾è‘—é«˜äºå…¶ä»–æ–¹æ³•ï¼›
  - **mMTC åˆ‡ç‰‡**ï¼šåœ¨é«˜å¯†åº¦è¿æ¥ä¸‹ä»ä¿æŒè‰¯å¥½æœåŠ¡è´¨é‡ï¼›
  - **URLLC åˆ‡ç‰‡**ï¼šæœ€ä½å»¶è¿Ÿè¡¨ç°çªå‡ºï¼Œæ»¡è¶³ä¸¥æ ¼æ—¶å»¶è¦æ±‚ï¼›
- **å¯æ‰©å±•æ€§è¡¨ç°**ï¼š
  - å½“ DU æ•°ä» 7 æ‰©å±•åˆ° 30ï¼ŒUE æ•°è¾¾ 200 æ—¶ï¼š
    - æ”¶æ•›è¿­ä»£æ¬¡æ•°ä»…å¢åŠ  **69%**ï¼ˆæ¥è¿‘æ¬¡çº¿æ€§å¢é•¿ï¼‰ï¼›
    - å½’ä¸€åŒ–ç´¯ç§¯å¥–åŠ±ä¸‹é™ä¸åˆ° **2%**ï¼Œè¡¨æ˜é«˜åº¦å¯æ‰©å±•ï¼›
    - å…ƒæ›´æ–°å»¶è¿Ÿæ§åˆ¶åœ¨ **10ms å†…**ï¼Œç¬¦åˆ near-RT RIC è¦æ±‚ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| æ–¹æ³• | ç´¯è®¡å¥–åŠ± | é€‚åº”é€Ÿåº¦ | QoS æ»¡è¶³ç‡ | å¯æ‰©å±•æ€§ |
|------|----------|-----------|-------------|------------|
| DRL | âŒ æœ€ä½ | âŒ å‡ ä¹ä¸éš shot æå‡ | âŒ å·® | âŒ å·® |
| TL | â­• ä¸­ç­‰ | â­• æœ‰é™æå‡ | â­• ä¸€èˆ¬ | â­• ä¸€èˆ¬ |
| MTL | â­• ä¸­ç­‰ | â­• æœ‰é™æå‡ | â­• ä¸€èˆ¬ | â­• ä¸€èˆ¬ |
| MAML-RL | âœ… è¾ƒé«˜ | âœ… å¿«é€Ÿæå‡ | âœ… è‰¯å¥½ | âœ… è‰¯å¥½ |
| **Adaptive MAML-RL (æœ¬æ–‡)** | âœ…âœ… **æœ€é«˜ (+19.8%)** | âœ…âœ… **æœ€å¿« (-40% shots)** | âœ…âœ… **æœ€ä¼˜** | âœ…âœ… **æœ€ä½³** |

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
åœ¨ 7-DU/30-UE åœºæ™¯ä¸‹è¿›è¡Œï¼ˆ30 ä¸ªé€‚åº”æ­¥ï¼‰ï¼š

| æ–¹æ³• | å½’ä¸€åŒ–å¥–åŠ± | æ”¶æ•›æ‰€éœ€é€‚åº”æ­¥æ•° |
|------|--------------|---------------------|
| Uniform-Metaï¼ˆç­‰æƒï¼‰ | 0.78 | 28 |
| Static-Varï¼ˆé™æ€æ–¹å·®åŠ æƒï¼‰ | 0.81 | 22 |
| **Adaptive-Varï¼ˆæœ¬æ–‡ï¼‰** | **0.84** | **17** |

> ç»“æœè¡¨æ˜ï¼š**åŠ¨æ€ Softmin åŠ æƒæœºåˆ¶è´¡çŒ®äº†çº¦ 3% çš„æ€§èƒ½å¢ç›Šå’Œ 40% çš„åŠ é€Ÿæ•ˆæœ**ã€‚

æ­¤å¤–ï¼Œè¯¥æœºåˆ¶è¿˜å¸¦æ¥ä»¥ä¸‹æ”¹è¿›ï¼š
- å¹³å‡åŒ…å»¶è¿Ÿé™ä½ **9.2%**
- Jainâ€™s Fairness ä» 0.91 æå‡è‡³ **0.96**
- åœ¨ 50% æµé‡æ¿€å¢åœºæ™¯ä¸‹æ€§èƒ½é€€åŒ– < **5%**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Meta-HRL æ¶æ„æœ‰æ•ˆè§£å†³äº† O-RAN å¤šå°ºåº¦èµ„æºç®¡ç†éš¾é¢˜**ï¼Œé€šè¿‡åˆ†å±‚å†³ç­–å®ç°äº†å…¨å±€åè°ƒä¸å±€éƒ¨ç²¾ç»†æ§åˆ¶çš„å¹³è¡¡ã€‚
2. **è‡ªé€‚åº” TD-error æ–¹å·®åŠ æƒæœºåˆ¶æ˜¾è‘—æå‡äº†å…ƒå­¦ä¹ æ•ˆç‡**ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿè‡ªåŠ¨èšç„¦äºæ›´å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œé¿å…â€œå¹³å‡ä¸»ä¹‰â€å¯¼è‡´çš„å­¦ä¹ ç¼“æ…¢ã€‚
3. æ‰€ææ–¹æ³•åœ¨ **åŠ¨æ€æ€§ã€å¼‚æ„æ€§å’Œå¯æ‰©å±•æ€§** æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œé€‚ç”¨äºç°å®ä¸–ç•Œä¸­å¤æ‚çš„ O-RAN éƒ¨ç½²ã€‚
4. **ç†è®ºåˆ†æè¯å®äº†ç®—æ³•çš„æ”¶æ•›æ€§ä¸ç¨³å®šæ€§**ï¼Œä¸ºå®é™…éƒ¨ç½²æä¾›äº†ä¿¡å¿ƒã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å®éªŒåŸºäºä»¿çœŸå¹³å°ï¼Œå°šæœªåœ¨çœŸå® O-RAN testbed ä¸ŠéªŒè¯ï¼ˆå—é™äºå½“å‰ç¡¬ä»¶è§„æ¨¡ï¼‰ï¼›
- å…ƒå‚æ•°ä¼ è¾“è™½è½»é‡ï¼ˆä»…äº¤æ¢ç½‘ç»œæƒé‡ï¼‰ï¼Œä½†åœ¨è¶…å¤§è§„æ¨¡éƒ¨ç½²ä¸­ä»éœ€è€ƒè™‘é€šä¿¡å¼€é”€ï¼›
- å½“å‰æ¡†æ¶ä¸»è¦é’ˆå¯¹å•è·³åœºæ™¯ï¼Œæœªæ¶µç›– multi-hop æˆ– UAV-assisted ç½‘ç»œã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- åœ¨ **OAI** æˆ– **srsRAN** ç­‰å¼€æºå¹³å°ä¸Šå®ç°åŸå‹ç³»ç»Ÿï¼Œå¼€å±• **hardware-in-the-loop éªŒè¯**ï¼›
- è®¾è®¡æ›´é«˜æ•ˆçš„ **communication-efficient meta parameter update æœºåˆ¶**ï¼›
- å°†æ¡†æ¶æ‰©å±•è‡³ **multi-hop networking** å’Œ **UAV-assisted 6G scenarios**ï¼›
- æ¢ç´¢ä¸å…¶ä»– AI æŠ€æœ¯ï¼ˆå¦‚è”é‚¦å­¦ä¹  FLï¼‰ç»“åˆçš„å¯èƒ½æ€§ï¼Œè¿›ä¸€æ­¥ä¿æŠ¤æ•°æ®éšç§ã€‚

--- 

> **æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºçš„ **Adaptive Meta-HRL** æ¡†æ¶æ˜¯é¦–ä¸ªå°† MAML ä¸ HRL æ·±åº¦èåˆå¹¶åº”ç”¨äº O-RAN èµ„æºç®¡ç†çš„å·¥ä½œï¼Œå…¼å…·é«˜æ€§èƒ½ã€å¼ºé€‚åº”æ€§ã€è‰¯å¥½å¯æ‰©å±•æ€§ä¸ç†è®ºä¿éšœï¼Œä¸ºä¸‹ä¸€ä»£æ™ºèƒ½æ— çº¿ç½‘ç»œç®¡ç†æä¾›äº†é‡è¦èŒƒå¼ã€‚

</details>

---

### 4. [PruneX: A Hierarchical Communication-Efficient System for Distributed CNN Training with Structured Pruning](https://arxiv.org/abs/2512.14628)

**Authors**: Alireza Olama, Andreas Lundell, Izzat El Hajj, Johan Lilius, Jerker Bj\"orkqvist  
**Category**: cs.DC  
**Published**: 2025-12-17  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.14628v1  

#### Abstract
Inter-node communication bandwidth increasingly constrains distributed training at scale on multi-node GPU clusters. While compact models are the ultimate deployment target, conventional pruning-aware distributed training systems typically fail to reduce communication overhead because unstructured s...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPRUNEX: A Hierarchical Communication-Efficient System for Distributed CNN Training with Structured Pruning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨å¤§è§„æ¨¡å¤šèŠ‚ç‚¹ GPU é›†ç¾¤ä¸Šè¿›è¡Œåˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ è®­ç»ƒæ—¶ï¼Œ**è·¨èŠ‚ç‚¹é€šä¿¡å¸¦å®½å·²æˆä¸ºä¸»è¦ç“¶é¢ˆ**ã€‚å°½ç®¡æ¨¡å‹å‹ç¼©ï¼ˆå¦‚å‰ªæï¼‰æ˜¯éƒ¨ç½²é˜¶æ®µçš„å¸¸è§æ‰‹æ®µï¼Œä½†ä¼ ç»Ÿçš„å‰ªææ„ŸçŸ¥è®­ç»ƒç³»ç»Ÿé€šå¸¸æ— æ³•æœ‰æ•ˆå‡å°‘é€šä¿¡å¼€é”€ï¼ŒåŸå› åœ¨äºï¼š
- **éç»“æ„åŒ–ç¨€ç–æ€§ï¼ˆUnstructured Sparsityï¼‰** æ— æ³•è¢«é«˜åº¦ä¼˜åŒ–çš„ç¨ å¯†é›†åˆé€šä¿¡åŸè¯­ï¼ˆå¦‚ NCCL AllReduceï¼‰é«˜æ•ˆåˆ©ç”¨ï¼›
- ç°æœ‰æ–¹æ³•å¾€å¾€å°†å‰ªæä½œä¸ºâ€œè®­ç»ƒ-å‰ªæ-å¾®è°ƒâ€çš„åå¤„ç†æ­¥éª¤ï¼Œæµªè´¹å¤§é‡è®¡ç®—èµ„æºï¼›
- å¤šæ•°æ¡†æ¶é‡‡ç”¨æ‰å¹³åŒ–çš„é€šä¿¡æ‹“æ‰‘ï¼Œå¿½ç•¥äº†ç°ä»£é›†ç¾¤ä¸­**èŠ‚ç‚¹å†…ï¼ˆintra-nodeï¼‰ä¸è·¨èŠ‚ç‚¹ï¼ˆinter-nodeï¼‰é“¾è·¯å¸¦å®½çš„å·¨å¤§å·®å¼‚**ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡ºäº† **PRUNEX** â€”â€” ä¸€ç§å±‚æ¬¡åŒ–ã€é€šä¿¡é«˜æ•ˆçš„åˆ†å¸ƒå¼ CNN è®­ç»ƒç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰æå‡º **Hierarchical Structured ADMM (H-SADMM)** ç®—æ³•
- å°†ç»“æ„åŒ–å‰ªæçº¦æŸï¼ˆå¦‚é€šé“/æ»¤æ³¢å™¨å‰ªæï¼‰æ–½åŠ åœ¨**èŠ‚ç‚¹çº§å…±è¯†å˜é‡ $z_i$** ä¸Šï¼Œè€Œéå…¨å±€å˜é‡ $z$ï¼›
- è¿™ä½¿å¾—åœ¨è·¨èŠ‚ç‚¹åŒæ­¥å‰å³å¯å®ç°**ç»“æ„åŒ–ç¨€ç–æ€§**ï¼Œä»è€Œä¸ºç‰©ç†ç¼“å†²åŒºå‹ç¼©æä¾›å‰æã€‚

#### ï¼ˆ2ï¼‰è®¾è®¡ **ç‰©ç†ç¼“å†²åŒºæ”¶ç¼©æœºåˆ¶ï¼ˆPhysical Buffer Shrinkageï¼‰**
- åˆ©ç”¨å…¨å±€ä¸€è‡´çš„ç¨€ç–æ©ç ï¼ˆmaskï¼‰ï¼Œåœ¨è·¨èŠ‚ç‚¹é€šä¿¡å‰å°†ç¨€ç–å¼ é‡å‹ç¼©ä¸º**ç´§å‡‘çš„ç¨ å¯†å—ï¼ˆdense compact bufferï¼‰**ï¼›
- æ¶ˆé™¤é›¶å€¼ä¼ è¾“å’Œç´¢å¼•å…ƒæ•°æ®å¼€é”€ï¼Œç›´æ¥ä½¿ç”¨æ ‡å‡†çš„ **dense AllReduce** è¿›è¡Œé«˜æ•ˆèšåˆã€‚

#### ï¼ˆ3ï¼‰æ„å»º **é¢†å¯¼è€…-è·Ÿéšè€…ï¼ˆLeader-Followerï¼‰åˆ†å±‚æ¶æ„**
- å¼•å…¥ **node leader** è§’è‰²ï¼Œç®¡ç†èŠ‚ç‚¹é—´é€šä¿¡ï¼›
- åˆ†ç¦» **intra-node** å’Œ **inter-node process groups**ï¼Œç¡®ä¿é«˜å¸¦å®½é“¾è·¯ç”¨äºå…¨é‡åŒæ­¥ï¼Œä½å¸¦å®½é“¾è·¯ä»…ä¼ è¾“å‹ç¼©åçš„æ´»è·ƒå‚æ•°ã€‚

#### ï¼ˆ4ï¼‰å¼€æºå®ç°
- ä½œè€…å·²å°† PRUNEX å¼€æºï¼š[https://github.com/Alirezalm/PruneX](https://github.com/Alirezalm/PruneX)

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ç±»å‹ | å…ƒæ•°æ®å¼€é”€ | é€šä¿¡åŸè¯­ | æ‹“æ‰‘æ„ŸçŸ¥ | æ¨ç†åŠ é€Ÿ |
|------|------|------------|----------|-----------|-----------|
| Top-K / DGC | Unstructured | é«˜ï¼ˆIndicesï¼‰ | AllGather/Gossip | å¦ | æ—  |
| PacTrain | Unstructured | ä½ï¼ˆMask Trackerï¼‰ | AllReduce | å¦ | ä½ |
| PruneTrain | Structured | é›¶ï¼ˆReconfigï¼‰ | AllReduce | å¦ | é«˜ |
| **PRUNEX** | **Structured** | **é›¶ï¼ˆéšå¼ï¼‰** | **Hierarchical AllReduce** | **æ˜¯** | **é«˜** |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šPRUNEX æ˜¯é¦–ä¸ªå°†**ç»“æ„åŒ–å‰ªæ**ä¸**é›†ç¾¤å±‚æ¬¡æ‹“æ‰‘**ååŒè®¾è®¡çš„ç³»ç»Ÿï¼Œåœ¨ä¸ç‰ºç‰²æ¨ç†æ•ˆç‡çš„å‰æä¸‹æ˜¾è‘—é™ä½é€šä¿¡ä½“ç§¯ï¼Œå¹¶é€šè¿‡ç¨ å¯†æ“ä½œä¿æŒé«˜æ€§èƒ½ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨ **CIFAR-10** æ•°æ®é›†è¿›è¡Œå›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚

### æ¨¡å‹æ¶æ„
- **ResNet-18**, **ResNet-152**, **WideResNet-50-2**
- å‚æ•°é‡ä» ~11M åˆ° ~69M ä¸ç­‰ï¼Œè¦†ç›–ä¸åŒè§„æ¨¡æ¨¡å‹ã€‚

### å®éªŒå¹³å°
- åœ¨èŠ¬å…° CSC çš„ **Puhti è¶…ç®—**ä¸Šè¿›è¡Œå®éªŒï¼›
- ä½¿ç”¨ **16 ä¸ªèŠ‚ç‚¹ï¼Œå…± 64 å— NVIDIA V100 GPU**ï¼ˆæ¯èŠ‚ç‚¹ 4 å—ï¼‰ï¼›
- èŠ‚ç‚¹å†…é€šè¿‡ **NVLink** äº’è”ï¼ˆé«˜å¸¦å®½ï¼‰ï¼ŒèŠ‚ç‚¹é—´é€šè¿‡ **HDR InfiniBand**ï¼ˆ100 Gbpsï¼‰è¿æ¥ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **PyTorch DDP (Dense Baseline)** | æ ‡å‡†çš„ç¨ å¯†åŒæ­¥ SGDï¼Œä½¿ç”¨ Ring-AllReduce |
| **Top-K SGD (Gradient Compression)** | æ¯å±‚ä¿ç•™ top 1% æ¢¯åº¦ï¼Œä»£è¡¨æ¢¯åº¦å‹ç¼©æ–¹æ³• |
| **PruneX (AR)** | PRUNEX çš„æ¶ˆèç‰ˆæœ¬ï¼Œä½¿ç”¨æ‰å¹³åŒ– AllReduceï¼Œæ— å±‚çº§ç»“æ„ |

### è¯„ä¼°æŒ‡æ ‡
- **End-to-Accuracy Time**ï¼šè¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡æ‰€éœ€æ—¶é—´ï¼›
- **Inter-node Communication Volume**ï¼šè·¨èŠ‚ç‚¹æ€»é€šä¿¡é‡ï¼ˆGBï¼‰ï¼›
- **Per-Iteration Communication Latency**ï¼šå•æ¬¡è¿­ä»£é€šä¿¡å»¶è¿Ÿï¼›
- **Strong Scaling Speedup & Efficiency**ï¼šéš GPU æ•°å¢åŠ çš„æ‰©å±•æ€§ï¼›
- **Sparsity-Accuracy Trade-off**ï¼šå‰ªææ¯”ä¾‹ä¸æœ€ç»ˆç²¾åº¦çš„å…³ç³»ï¼›
- **Primal/Dual Residuals**ï¼šéªŒè¯ ADMM æ”¶æ•›æ€§ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰ç«¯åˆ°ç«¯è®­ç»ƒæ•ˆç‡
- **PRUNEX åœ¨çº¦ 8 åˆ†é’Ÿå†…è¾¾åˆ° 70% å‡†ç¡®ç‡**ï¼Œè€Œ DDP åœ¨ 14 åˆ†é’Ÿå†…ä»…è¾¾åˆ° ~65%ï¼ŒTop-K æ›´æ…¢ä¸”æ”¶æ•›ä¸ç¨³å®šï¼ˆ~50%ï¼‰ï¼›
- å›¾ 5(b) æ˜¾ç¤ºï¼ŒPRUNEX å®ç°æ›´é«˜çš„â€œ**accuracy per byte**â€ï¼Œå³å•ä½é€šä¿¡é‡å¸¦æ¥çš„ç²¾åº¦æå‡æ›´é«˜ã€‚

#### ï¼ˆ2ï¼‰é€šä¿¡ä½“ç§¯å‡å°‘
- **è·¨èŠ‚ç‚¹é€šä¿¡é‡å¹³å‡å‡å°‘ ~60%**ï¼š
  - ResNet-18ï¼š2.53 GB â†’ 1.01 GB
  - WideResNet-50-2ï¼š14.88 GB â†’ 5.97 GB
  - ResNet-152ï¼š13.00 GB â†’ 5.21 GB
- å‹ç¼©æ•ˆæœéšç€ H-SADMM çš„æ¨è¿›è¿…é€Ÿç¨³å®šï¼ˆè§å›¾ 6ï¼‰ã€‚

#### ï¼ˆ3ï¼‰é€šä¿¡å»¶è¿Ÿé™ä½
- å•æ¬¡è¿­ä»£é€šä¿¡å»¶è¿Ÿä» DDP çš„ **0.50s é™è‡³ PRUNEX çš„ 0.10s**ï¼Œæé€Ÿ **5Ã—**ï¼›
- æ¶ˆèå®éªŒè¡¨æ˜ï¼Œè‹¥å»é™¤å±‚çº§ç»“æ„ï¼ˆPruneX-ARï¼‰ï¼Œå»¶è¿Ÿæ”¹å–„æ¶ˆå¤±ï¼Œè¯æ˜**å±‚çº§è®¾è®¡æ˜¯å‹ç¼©ç”Ÿæ•ˆçš„å‰æ**ã€‚

#### ï¼ˆ4ï¼‰å¼ºæ‰©å±•æ€§ï¼ˆStrong Scalingï¼‰
- åœ¨ 64 GPU ä¸Šï¼š
  - **PRUNEX å®ç° 6.75Ã— åŠ é€Ÿæ¯”**ï¼ˆå¹¶è¡Œæ•ˆç‡ 84.4%ï¼‰
  - DDP ä»…ä¸º 5.81Ã—ï¼ˆ72.7%ï¼‰
  - Top-K ä¸º 3.71Ã—
- è¡¨æ˜ PRUNEX åœ¨æ›´å¤§è§„æ¨¡ä¸‹æ›´å…·å¯æ‰©å±•æ€§ã€‚

#### ï¼ˆ5ï¼‰æ¶ˆèå®éªŒç»“æœ
- **PruneX (AR)** æ€§èƒ½æ¥è¿‘ DDPï¼Œè¯´æ˜**æ²¡æœ‰å±‚çº§ç»“æ„åˆ™æ— æ³•å‘æŒ¥å‰ªæçš„é€šä¿¡ä¼˜åŠ¿**ï¼›
- å±‚çº§ç»“æ„ + ç»“æ„åŒ–å‰ªæ + ç¼“å†²åŒºå‹ç¼©ä¸‰è€…ç»“åˆæ‰æ˜¯æ€§èƒ½æå‡çš„å…³é”®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç»“æ„åŒ–å‰ªæå¿…é¡»ä¸é€šä¿¡æ‹“æ‰‘ååŒè®¾è®¡** æ‰èƒ½åœ¨è®­ç»ƒé˜¶æ®µçœŸæ­£èŠ‚çœé€šä¿¡æˆæœ¬ï¼›
2. **åœ¨è·¨èŠ‚ç‚¹é€šä¿¡å‰æ‰§è¡Œç»“æ„åŒ–å‰ªæå’Œç¼“å†²åŒºå‹ç¼©** å¯ä»¥æ˜¾è‘—å‡å°‘é€šä¿¡é‡ï¼Œä¸”å…¼å®¹ç°æœ‰ç¨ å¯†é€šä¿¡åº“ï¼ˆå¦‚ NCCLï¼‰ï¼›
3. **Leader-Follower æ¶æ„æœ‰æ•ˆéš”ç¦»äº†é«˜å»¶è¿Ÿçš„è·¨èŠ‚ç‚¹é€šä¿¡**ï¼Œå¹¶é€šè¿‡ mask åŒæ­¥ä¿è¯ä¸€è‡´æ€§ï¼›
4. H-SADMM ç®—æ³•å…·æœ‰è‰¯å¥½çš„æ”¶æ•›æ€§ï¼Œå„å±‚æ®‹å·®å•è°ƒä¸‹é™ï¼Œæ”¯æŒè‡ªé€‚åº”æƒ©ç½šå‚æ•°è°ƒèŠ‚ï¼›
5. å³ä½¿åœ¨ 50% é€šé“å‰ªæä¸‹ï¼ŒResNet-152 ä»èƒ½ä¿æŒ **82.8% çš„å‡†ç¡®ç‡**ï¼ˆåŸå§‹ä¸º 85.96%ï¼‰ï¼Œæ˜¾ç¤ºå†—ä½™æ€§è¾ƒå¼ºã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰å®ç°åŸºäºä¸¤å±‚æ‹“æ‰‘ï¼ˆèŠ‚ç‚¹/é›†ç¾¤ï¼‰ï¼Œå¯¹æ›´å¤æ‚çš„æœºæ¶çº§æ‹“æ‰‘æ”¯æŒæœ‰é™ï¼ˆè™½å…·å¤‡æ‰©å±•æ½œåŠ›ï¼‰ï¼›
- å‰ªæç­–ç•¥ç›®å‰é›†ä¸­åœ¨ CNN çš„é€šé“/æ»¤æ³¢å™¨ç»´åº¦ï¼Œå°šæœªæ¨å¹¿è‡³ Transformer ç­‰æ³¨æ„åŠ›ç»“æ„ï¼›
- å†»ç»“æ©ç åçš„å†è®­ç»ƒé˜¶æ®µä¾èµ–äººå·¥è®¾å®šé˜ˆå€¼ `T_freeze`ï¼Œç¼ºä¹è‡ªåŠ¨åŒ–åˆ¤æ–­æœºåˆ¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **Vision Transformers (ViTs)** å’Œå…¶ä»– attention-based æ¨¡å‹ï¼›
- åœ¨æ•°åƒ GPU è§„æ¨¡çš„è¶…å¤§é›†ç¾¤ä¸ŠéªŒè¯ç³»ç»Ÿçš„å¯æ‰©å±•æ€§ï¼›
- æ¢ç´¢åŠ¨æ€ mask å†»ç»“ç­–ç•¥å’Œè‡ªåŠ¨æ”¶æ•›æ£€æµ‹æœºåˆ¶ï¼›
- æ”¯æŒæ›´æ·±çš„ç¡¬ä»¶å±‚æ¬¡ï¼ˆå¦‚ rack-level aggregationï¼‰ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **PRUNEX é€šè¿‡å°†ç»“æ„åŒ–å‰ªæåµŒå…¥åˆ†å¸ƒå¼ä¼˜åŒ–ç®—æ³• H-SADMMï¼Œå¹¶ç»“åˆå±‚çº§é€šä¿¡æ¶æ„ï¼Œé¦–æ¬¡å®ç°äº†â€œæ¨¡å‹ç¨€ç–æ€§ â†’ é€šä¿¡ä½“ç§¯ç¼©å‡ â†’ å®é™…è®­ç»ƒåŠ é€Ÿâ€çš„é—­ç¯ï¼Œä¸ºå¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒæä¾›äº†é«˜æ•ˆã€å®ç”¨çš„æ–°èŒƒå¼ã€‚**

</details>

---

### 5. [Sparse Multi-Modal Transformer with Masking for Alzheimer's Disease Classification](https://arxiv.org/abs/2512.14491)

**Authors**: Cheng-Han Lu, Pei-Hsuan Tsai  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.14491v1  

#### Abstract
Transformer-based multi-modal intelligent systems often suffer from high computational and energy costs due to dense self-attention, limiting their scalability under resource constraints. This paper presents SMMT, a sparse multi-modal transformer architecture designed to improve efficiency and robus...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Sparse Multi-Modal Transformer with Masking for Alzheimer's Disease Classification*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹å½“å‰åŸºäº **Transformer** çš„å¤šæ¨¡æ€æ™ºèƒ½ç³»ç»Ÿåœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…ï¼ˆAlzheimer's Disease, ADï¼‰åˆ†ç±»ä»»åŠ¡ä¸­é¢ä¸´çš„ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **é«˜è®¡ç®—ä¸èƒ½è€—æˆæœ¬**ï¼šä¼ ç»Ÿ Transformer ä½¿ç”¨å¯†é›†è‡ªæ³¨æ„åŠ›ï¼ˆdense self-attentionï¼‰ï¼Œå¯¼è‡´æ—¶é—´å¤æ‚åº¦ä¸º $O(n^2)$ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹æ‰©å±•ã€‚
- **å¯¹ä¸å®Œæ•´è¾“å…¥æ•æ„Ÿ**ï¼šä¸´åºŠæ•°æ®å¸¸å­˜åœ¨ç¼ºå¤±æ¨¡æ€ï¼ˆå¦‚ç¼ºå°‘ MRI æˆ–åŸºå› ä¿¡æ¯ï¼‰ï¼Œè€Œç°æœ‰æ¨¡å‹ç¼ºä¹æ˜¾å¼æœºåˆ¶åº”å¯¹è¿™ä¸€ç°å®é—®é¢˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSMMT
ä½œè€…æå‡º **Sparse Multi-Modal Transformer with Masking (SMMT)**ï¼Œä¸€ç§ä»ç³»ç»Ÿå±‚é¢è®¾è®¡çš„é«˜æ•ˆã€é²æ£’çš„å¤šæ¨¡æ€èåˆæ¶æ„ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰Cluster-based Sparse Attention
- å°†æ¯ä¸ªæ¨¡æ€å†…çš„ token é€šè¿‡ **K-Means èšç±»** åˆ†ç»„ï¼ˆç°‡æ•° $k = \log_2 n$ï¼‰ã€‚
- è‡ªæ³¨æ„åŠ›ä»…åœ¨åŒç°‡å†…è®¡ç®—ï¼Œå°†è®¡ç®—å¤æ‚åº¦ä» $O(n^2)$ é™ä½è‡³ $O(n \log n)$ã€‚
- ä½¿ç”¨æŸ¥è¯¢å‘é‡ï¼ˆquery vectorsï¼‰è¿›è¡Œèšç±»ï¼Œç¡®ä¿è¯­ä¹‰ç›¸å…³æ€§é©±åŠ¨åˆ†ç»„ï¼Œä¼˜äºå›ºå®šçª—å£æˆ–è§„åˆ™æ¨¡å¼ã€‚

#### ï¼ˆ2ï¼‰Modality-wise Masking
- åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹å„æ¨¡æ€è¾“å‡ºç‰¹å¾éšæœºæ–½åŠ æ©ç ï¼ˆmasking ratio $r=0.3$ï¼‰ï¼Œæ¨¡æ‹ŸçœŸå®åœºæ™¯ä¸­çš„æ¨¡æ€ç¼ºå¤±ã€‚
- å¢å¼ºæ¨¡å‹å¯¹ä¸å®Œæ•´è¾“å…¥çš„æ³›åŒ–èƒ½åŠ›ï¼Œæå‡é²æ£’æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | æ˜¾è‘—å‡å°‘è®­ç»ƒæ—¶é—´å’Œå†…å­˜å ç”¨ï¼Œé€‚åˆä½èµ„æºéƒ¨ç½² |
| **é²æ£’æ€§** | å¯¹å°æ ·æœ¬å’Œç¼ºå¤±æ¨¡æ€å…·æœ‰æ›´å¼ºé€‚åº”èƒ½åŠ› |
| **å¯æŒç»­æ€§** | å¤§å¹…é™ä½èƒ½æºæ¶ˆè€—ä¸ç¢³æ’æ”¾ï¼Œæ”¯æŒç»¿è‰² AI å‘å±• |
| **æ€§èƒ½ä¿æŒ** | åœ¨æ˜¾è‘—å‹ç¼©è®¡ç®—å¼€é”€çš„åŒæ—¶ç»´æŒç”šè‡³è¶…è¶ŠåŸºçº¿ç²¾åº¦ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨ **ADNI-1 å’Œ ADNI-2** æ•°æ®é›†ï¼Œç­›é€‰å‡ºç¡®è¯Šä¸º ADï¼ˆAlzheimerâ€™s Diseaseï¼‰æˆ– CNï¼ˆCognitively Normalï¼‰çš„ä¸ªä½“ã€‚
- æ€»å…±æ”¶é›† **12,680 å¼  T1-weighted 2D MRI åˆ‡ç‰‡**ï¼Œå¹¶ä¸ç»“æ„åŒ–ä¸´åºŠæ•°æ®åŒ¹é…ã€‚
- åŒ…å«çš„æ¨¡æ€ï¼š
  - **Imaging**: MRI å›¾åƒï¼ˆç» MNI152 é…å‡†ã€å½’ä¸€åŒ–ä¸º 256Ã—256ï¼‰
  - **Numerical**: MMSEã€CDRã€FAQã€Age
  - **Categorical**: Sexã€APOE genotype

> æ³¨ï¼šæ’é™¤ MCIï¼ˆè½»åº¦è®¤çŸ¥éšœç¢ï¼‰æ ·æœ¬ä»¥é¿å…ç±»åˆ«ä¸å¹³è¡¡åŠä»»åŠ¡å¤æ‚åŒ–ã€‚

### å®éªŒè®¾ç½®
| é¡¹ç›® | è®¾ç½® |
|------|------|
| æ¡†æ¶ | PyTorch |
| ç¡¬ä»¶ | NVIDIA RTX 3060 GPU (12GB) |
| è®­ç»ƒè½®æ¬¡ | 50 epochs Ã— 5-fold CV |
| æ‰¹å¤§å° | 8 |
| ä¼˜åŒ–å™¨ | Adam ($lr = 1\times10^{-3}$) |
| æŸå¤±å‡½æ•° | Cross Entropy |
| ç‰¹å¾ç»´åº¦ | 512 |
| æ©ç æ¯”ä¾‹ | 0.3ï¼ˆmodality-level random maskingï¼‰|
| å¯é‡å¤æ€§ | 5 æ¬¡ä¸åŒéšæœºç§å­è¿è¡Œå–å¹³å‡ |

### è¯„ä¼°æŒ‡æ ‡

#### ï¼ˆ1ï¼‰åˆ†ç±»æ€§èƒ½æŒ‡æ ‡
- **Accuracy**, **Precision**, **Recall (Sensitivity)**, **F1-score**
- **Specificity**, **AUC (ROC æ›²çº¿ä¸‹é¢ç§¯)**

#### ï¼ˆ2ï¼‰è®¡ç®—å¯æŒç»­æ€§æŒ‡æ ‡ï¼ˆvia CodeCarbonï¼‰
- **Energy Consumption (kWh)**ï¼šCPU/GPU/RAM åŠŸè€—æ€»å’Œ
- **COâ‚‚ Emissions (kg)**ï¼šåŸºäºå°æ¹¾ç”µç½‘ç¢³å¼ºåº¦ï¼ˆ0.502 kgCOâ‚‚/kWhï¼‰ä¼°ç®—

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ¨¡å‹ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| **3MT [8]** | å¤šæ¨¡æ€ Transformerï¼ˆçº§è”äº¤å‰æ³¨æ„åŠ›ï¼‰ | ä¸»è¦åŸºå‡†æ¨¡å‹ |
| **ADDFformer [20]** | å•æ¨¡æ€ï¼ˆMRIï¼‰Transformer | æˆåƒä¸“ç”¨ SOTA |
| **FusionNet [21]** | é€šç”¨å¤šæ¨¡æ€èåˆç½‘ç»œï¼ˆæ— æ³¨æ„åŠ›ï¼‰ | ä¸­é—´èåˆä»£è¡¨ |
| **CNN-only [22]** | å•æ¨¡æ€ CNNï¼ˆå¦‚ VGG16ï¼‰ | ä¼ ç»ŸåŸºçº¿ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆå®Œæ•´æ•°æ®é›†ï¼Œ100%ï¼‰

| æ¨¡å‹ | Accuracy (%) | Sensitivity (%) | Specificity (%) | AUC |
|------|---------------|------------------|------------------|-----|
| **SMMT (Ours)** | **97.05** | **96.31** | **97.58** | **0.986** |
| 3MT [8] | 90.28 | 93.64 | 93.81 | 0.965 |
| ADDFformer [20] | 88.20 | 91.87 | 91.53 | 0.948 |
| FusionNet [21] | 94.28 | 91.01 | 93.24 | 0.956 |
| CNN-only [22] | 80.24 | 78.45 | 80.22 | 0.852 |

âœ… SMMT åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡è¾¾åˆ° **SOTA è¡¨ç°**ï¼Œå°¤å…¶åœ¨ AUC ä¸Šé¢†å…ˆæ˜æ˜¾ã€‚

### å°æ ·æœ¬æ¡ä»¶ä¸‹çš„è¡¨ç°ï¼ˆ20% æ•°æ®ï¼‰

| æ¨¡å‹ | Accuracy (%) |
|------|---------------|
| **SMMT (Ours)** | **84.96** |
| 3MT [8] | 78.92 |
| ADDFformer [20] | 71.92 |
| FusionNet [21] | 75.15 |
| CNN-only [22] | 68.53 |

â¡ï¸ SMMT åœ¨æä½æ•°æ®æ¡ä»¶ä¸‹ä»ä¿æŒé«˜å‡†ç¡®ç‡ï¼Œå±•ç°å‡ºå“è¶Šçš„ **data efficiency** å’Œ **generalization èƒ½åŠ›**ã€‚

### è®­ç»ƒæ•ˆç‡ä¸èƒ½è€—å¯¹æ¯”

#### è®­ç»ƒæ—¶é—´ï¼ˆvs. æ•°æ®è§„æ¨¡ï¼‰
- SMMT æ˜¯æ‰€æœ‰ Transformer ç±»æ¨¡å‹ä¸­ **è®­ç»ƒé€Ÿåº¦æœ€å¿«** çš„ï¼Œåœ¨å¤§æ•°æ®é›†ä¸‹æ‰©å±•æ€§æ›´å¥½ã€‚
- åœ¨ 100% æ•°æ®æ—¶ï¼ŒSMMT è®­ç»ƒæ—¶é—´ä¸º **112 åˆ†é’Ÿ**ï¼Œè€Œ 3MT ä¸º 133 åˆ†é’Ÿã€‚

#### èƒ½æºæ¶ˆè€—ï¼ˆæ€»è®¡ 250 epochsï¼‰

| ç»„ä»¶ | 3MT (Baseline) | SMMT (Ours) | å‡å°‘å¹…åº¦ |
|------|----------------|-------------|----------|
| CPU | 0.108489 kWh | 0.071179 kWh | 34.4% |
| GPU | 0.283977 kWh | 0.159642 kWh | 43.8% |
| RAM | 0.051035 kWh | 0.033485 kWh | 34.4% |
| **Total** | **0.443501 kWh** | **0.264306 kWh** | **40.4%** |

#### ç¢³æ’æ”¾ï¼ˆCOâ‚‚ï¼‰
- 3MTï¼šçº¦ **0.2226 kgCOâ‚‚**
- SMMTï¼šä»… **0.1327 kgCOâ‚‚** â†’ **å‡å°‘ 40.3%**

ğŸ’¡ èŠ‚çœçš„ç¢³æ’æ”¾ç›¸å½“äºï¼š
- å……ç”µæ™ºèƒ½æ‰‹æœºçº¦ **18 æ¬¡**
- ç‚¹äº®ä¸€ä¸ª 60W ç¯æ³¡è¶…è¿‡ **30 å°æ—¶**

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

| é…ç½® | 100% æ•°æ® Accuracy / Time (min) | 20% æ•°æ® Accuracy / Time (min) |
|------|-------------------------------|-------------------------------|
| 3MT (Baseline) | 90.28 / 133 | 78.92 / 41 |
| w/o Sparse Attention | 91.35 / 147 | 84.85 / 51 |
| w/o Masking | 95.42 / 108 | 80.85 / 37 |
| **SMMT (Full)** | **97.05 / 112** | **84.96 / 45** |

ğŸ” ç»“è®ºï¼š
- **Sparse Attention** æ˜¾è‘—é™ä½è®­ç»ƒæ—¶é—´ï¼ˆâ†“~25%ï¼‰ï¼Œå¹¶è½»å¾®æå‡æ³›åŒ–èƒ½åŠ›ï¼ˆå¯èƒ½èµ·æ­£åˆ™åŒ–ä½œç”¨ï¼‰ã€‚
- **Masking** å¯¹å°æ ·æœ¬æ€§èƒ½è‡³å…³é‡è¦ï¼ˆ20% æ•°æ®ä¸‹ â†“4.11% è‹¥ç§»é™¤ï¼‰ï¼Œæ˜¯é²æ£’æ€§çš„å…³é”®ã€‚
- ä¸¤è€…ç»“åˆå®ç°æœ€ä½³ **æ•ˆç‡-æ€§èƒ½æƒè¡¡**ã€‚

#### æ©ç æ¯”ä¾‹ï¼ˆMasking Ratioï¼‰å½±å“ç ”ç©¶
- åœ¨ 40% æ•°æ®è®¾å®šä¸‹æµ‹è¯•ä¸åŒ $r$ å€¼ã€‚
- æœ€ä¼˜ $r = 0.3$ï¼Œè¿‡é«˜ï¼ˆ>0.6ï¼‰å¯¼è‡´æ€§èƒ½æ€¥å‰§ä¸‹é™ï¼Œæ¥è¿‘å¤šæ•°ç±»åŸºçº¿ï¼ˆ60%ï¼‰ã€‚
- æ”¯æŒé€‰æ‹©é€‚åº¦æ©ç ä»¥å¹³è¡¡æ­£åˆ™åŒ–ä¸ä¿¡æ¯ä¿ç•™ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **SMMT åœ¨ AD åˆ†ç±»ä»»åŠ¡ä¸­å®ç°äº†ç²¾åº¦ä¸æ•ˆç‡çš„åŒé‡çªç ´**ï¼š
   - è¾¾åˆ° **97.05% å‡†ç¡®ç‡**ï¼ˆ100% æ•°æ®ï¼‰ã€**84.96%**ï¼ˆ20% æ•°æ®ï¼‰
   - åŒæ—¶å°† **èƒ½é‡æ¶ˆè€—é™ä½ 40.4%**ï¼Œæ˜¾è‘—ä¼˜äº 3MT ç­‰åŸºçº¿ã€‚
2. âœ… **Sparse Attention ä¸ä»…ææ•ˆï¼Œè¿˜éšå¼å¢å¼ºæ³›åŒ–èƒ½åŠ›**ï¼š
   - é™åˆ¶æ³¨æ„åŠ›èŒƒå›´å¯æŠ‘åˆ¶å™ªå£°è¿æ¥ï¼Œç±»ä¼¼ Dropout æ­£åˆ™åŒ–æ•ˆæœã€‚
3. âœ… **Modality-wise Masking æå¤§æå‡äº†æ¨¡å‹å¯¹ç¼ºå¤±æ•°æ®çš„é²æ£’æ€§**ï¼š
   - ç‰¹åˆ«é€‚ç”¨äºçœŸå®åŒ»ç–—ç¯å¢ƒä¸­å¸¸è§çš„ä¸å®Œæ•´è¾“å…¥æƒ…å†µã€‚
4. âœ… **SMMT æ›´ç¨³å®šã€æ›´ç¯ä¿**ï¼š
   - èƒ½è€—æ›²çº¿å¹³ç¨³ï¼Œç¡¬ä»¶åˆ©ç”¨ç‡æ›´å‡è¡¡ï¼Œæœ‰åˆ©äºé•¿æœŸéƒ¨ç½²ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»…ç”¨äº **äºŒåˆ†ç±»ä»»åŠ¡ï¼ˆAD vs. CNï¼‰**ï¼Œæœªæ¶µç›– MCIï¼ˆè½»åº¦è®¤çŸ¥éšœç¢ï¼‰é˜¶æ®µã€‚
- èšç±»æ­¥éª¤ï¼ˆK-Meansï¼‰è™½ä¸€æ¬¡æ€§ä¸”å¤ç”¨ï¼Œä½†ä»å¼•å…¥é¢å¤–è®¡ç®—å¼€é”€ï¼ˆ$O(nkdi)$ï¼‰ï¼Œéœ€ GPU åŠ é€Ÿæ”¯æŒã€‚
- æ‰€æœ‰å®éªŒåŸºäºå•ä¸€ç¡¬ä»¶å¹³å°ï¼ˆRTX 3060ï¼‰ï¼Œè·¨è®¾å¤‡å¯ç§»æ¤æ€§æœ‰å¾…éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³å¤šé˜¶æ®µé¢„æµ‹**ï¼šçº³å…¥ MCI æ ·æœ¬ï¼Œæ„å»º AD è¿›å±•çš„çºµå‘é¢„æµ‹æ¨¡å‹ã€‚
2. **åŠ¨æ€æ¨¡æ€é€‰æ‹©æœºåˆ¶**ï¼šåœ¨æ¨ç†æ—¶è‡ªé€‚åº”å¤„ç†å¯å˜æ¨¡æ€è¾“å…¥ã€‚
3. **æ›´å¤§è§„æ¨¡éªŒè¯**ï¼šåœ¨æ›´å¤šå…ƒåŒ–çš„ä¸´åºŠæ•°æ®é›†ä¸Šæµ‹è¯•æ³›åŒ–èƒ½åŠ›ã€‚
4. **è¾¹ç¼˜éƒ¨ç½²æ¢ç´¢**ï¼šè¿›ä¸€æ­¥å‹ç¼©æ¨¡å‹ï¼Œæ¨åŠ¨ SMMT åœ¨ç§»åŠ¨æˆ–åµŒå…¥å¼åŒ»ç–—è®¾å¤‡ä¸Šçš„åº”ç”¨ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> SMMT é€šè¿‡ **cluster-based sparse attention** å’Œ **modality-wise masking**ï¼ŒæˆåŠŸæ„å»ºäº†ä¸€ä¸ª **é«˜æ•ˆã€é²æ£’ã€èŠ‚èƒ½** çš„å¤šæ¨¡æ€ Transformer æ¶æ„ï¼Œåœ¨ AD åˆ†ç±»ä»»åŠ¡ä¸­å®ç°äº†æ€§èƒ½ä¸å¯æŒç»­æ€§çš„åŒèµ¢ï¼Œä¸ºèµ„æºå—é™ç¯å¢ƒä¸‹çš„æ™ºèƒ½åŒ»ç–—ç³»ç»Ÿæä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 6. [VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse](https://arxiv.org/abs/2512.14531)

**Authors**: Ying Nie, Kai Han, Hongguang Li, Hang Zhou, Tianyu Guo, Enhua Wu, Xinghao Chen, Yunhe Wang  
**Category**: cs.CL  
**Published**: 2025-12-17  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.14531v1  

#### Abstract
The rapid scaling of Large Language Models (LLMs) has achieved remarkable performance, but it also leads to prohibitive memory costs. Existing parameter-efficient approaches such as pruning and quantization mainly compress pretrained models without enhancing architectural capacity, thereby hitting t...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è™½ç„¶æ€§èƒ½å¼ºå¤§ï¼Œä½†å…¶åºå¤§çš„å‚æ•°é‡å¯¼è‡´**å†…å­˜å¼€é”€è¿‡é«˜**ï¼Œä¸¥é‡é™åˆ¶äº†å®é™…éƒ¨ç½²ã€‚ç°æœ‰çš„å‚æ•°é«˜æ•ˆæ–¹æ³•ï¼ˆå¦‚å‰ªæã€é‡åŒ–ã€LoRAç­‰ï¼‰ä¸»è¦å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå‹ç¼©ï¼Œ**å¹¶æœªå¢å¼ºæ¨¡å‹çš„è¡¨å¾èƒ½åŠ›**ï¼Œå› æ­¤å—é™äºåŸå§‹æ¶æ„çš„å®¹é‡ä¸Šé™ã€‚

æ­¤å¤–ï¼Œç¨€ç–ä¸“å®¶æ··åˆï¼ˆMoEï¼‰è™½èƒ½æå‡å®¹é‡ï¼Œä½†å¼•å…¥å¤§é‡é¢å¤–å‚æ•°ï¼›è€Œé€’å½’è®¡ç®—æ–¹æ³•ï¼ˆå¦‚ALBERTã€Universal Transformersï¼‰è™½èŠ‚çœå‚æ•°ï¼Œå´ç¼ºä¹å®½åº¦ç»´åº¦ä¸Šçš„çµæ´»æ€§ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šVersatileFFN
æœ¬æ–‡æå‡º **VersatileFFN** â€”â€”ä¸€ç§å…¨æ–°çš„ã€å‚æ•°é«˜æ•ˆçš„ FFN æ¶æ„ï¼Œé€šè¿‡åœ¨**å®½åº¦ï¼ˆwidthï¼‰å’Œæ·±åº¦ï¼ˆdepthï¼‰ä¸¤ä¸ªç»´åº¦ä¸Šè‡ªé€‚åº”åœ°å¤ç”¨åŒä¸€ç»„å‚æ•°**ï¼Œå®ç°æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒæä½çš„å†…å­˜å ç”¨ã€‚

#### æ ¸å¿ƒæœºåˆ¶ï¼š
- **Width-Versatile Pathï¼ˆå®½åº¦å¤šåŠŸèƒ½è·¯å¾„ï¼‰**  
  å°†ä¸€ä¸ªå…±äº«çš„ FFN åˆ†è§£ä¸ºå¤šä¸ªâ€œè™šæ‹Ÿå­ä¸“å®¶â€ï¼ˆvirtual sub-expertsï¼‰ï¼Œé€šè¿‡ç»“æ„åŒ–åˆ‡ç‰‡ï¼ˆstructured slicingï¼‰ä»åŒä¸€ä¸ª `W_proj` å’Œ `W_out` ä¸­æå–éé‡å çš„éšè—å­ç©ºé—´ï¼Œå½¢æˆå¤šä¸ªè½»é‡å­ç½‘ç»œã€‚  
  â†’ å®ç°ç±»ä¼¼ MoE çš„ç¨€ç–è·¯ç”±æ•ˆæœï¼Œä½†**ä¸å¢åŠ å‚æ•°æ•°é‡**ã€‚

- **Depth-Versatile Pathï¼ˆæ·±åº¦å¤šåŠŸèƒ½è·¯å¾„ï¼‰**  
  å¯¹å¤æ‚ token åŠ¨æ€é€’å½’åº”ç”¨åŒä¸€ä¸ª FFN å¤šæ¬¡ï¼Œæ¨¡æ‹Ÿæ›´æ·±çš„å¤„ç†è¿‡ç¨‹ã€‚  
  â†’ ä½¿ç”¨ Gumbel-Softmax æ§åˆ¶å™¨é¢„æµ‹æ¯ä¸ª token æ‰€éœ€çš„è¿­ä»£æ¬¡æ•°ï¼Œå®ç°å¯å¾®åˆ†è®­ç»ƒã€‚

- **Difficulty-Aware Gatingï¼ˆéš¾åº¦æ„ŸçŸ¥é—¨æ§ï¼‰**  
  åˆ©ç”¨æ·±åº¦è·¯å¾„é¢„æµ‹çš„æœŸæœ›å¾ªç¯æ¬¡æ•°ä½œä¸º token éš¾åº¦ä»£ç†ï¼ŒåŠ¨æ€èåˆä¸¤æ¡è·¯å¾„è¾“å‡ºï¼š
  $$
  Y = \lambda \cdot Y_{\text{width}} + (1 - \lambda) \cdot Y_{\text{depth}}, \quad \lambda = \frac{L_{\max} - \mathbb{E}[L]}{L_{\max}}
  $$
  - â€œç®€å•â€token èµ°å®½åº¦è·¯å¾„ï¼ˆå¿«é€Ÿå“åº”ï¼‰
  - â€œå›°éš¾â€token èµ°æ·±åº¦è·¯å¾„ï¼ˆæ·±å…¥æ¨ç†ï¼‰

> ğŸ’¡ å—å¯å‘äºäººç±»è®¤çŸ¥çš„åŒç³»ç»Ÿç†è®ºï¼ˆDual-Process Theoryï¼‰ï¼šSystem 1 å¿«é€Ÿç›´è§‰å†³ç­–ï¼ŒSystem 2 ç¼“æ…¢é€»è¾‘æ¨ç†ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å‚æ•°å¢é•¿ | å†…å­˜æ•ˆç‡ | è¡¨è¾¾èƒ½åŠ›å¢å¼º | è‡ªé€‚åº”è®¡ç®— |
|------|----------|-----------|----------------|--------------|
| Pruning/Quantization | â†“ | âœ… | âŒï¼ˆä»…å‹ç¼©ï¼‰ | âŒ |
| MoE | â†‘â†‘â†‘ | âŒï¼ˆå¤šä¸“å®¶ï¼‰ | âœ… | â­•ï¼ˆé™æ€è·¯ç”±ï¼‰ |
| k-Loop Recurrence | â†”ï¸ | âœ… | âœ…ï¼ˆä»…æ·±åº¦ï¼‰ | âŒï¼ˆå›ºå®šæ­¥æ•°ï¼‰ |
| **VersatileFFN** | **â†”ï¸ï¼ˆå‡ ä¹æ— å¢ï¼‰** | âœ…âœ… | âœ…âœ…ï¼ˆå®½+æ·±ï¼‰ | âœ…âœ…ï¼ˆåŠ¨æ€åˆ†é…ï¼‰ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šåœ¨**å›ºå®šå‚æ•°é¢„ç®—ä¸‹**ï¼Œé€šè¿‡æ™ºèƒ½è®¡ç®—è°ƒåº¦æå‡æ€§èƒ½ï¼ŒçœŸæ­£å®ç°â€œcompute-heavy, memory-lightâ€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **é¢„è®­ç»ƒæ•°æ®**ï¼šFineWeb-Eduï¼ˆ40B å’Œ 70B tokens å­é›†ï¼‰
- **è¯„ä¼°åŸºå‡†**ï¼ˆZero-Shotï¼‰ï¼š
  - PIQA, HellaSwag, OBQA, SciQ
  - ARC-easy, ARC-challenge, CommonsenseQA, Winogrande
  - ç»¼åˆå¹³å‡å‡†ç¡®ç‡ï¼ˆAvg. Accuracyï¼‰ä¸ºä¸»è¦æŒ‡æ ‡

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹è§„æ¨¡**ï¼š
  - 354M å‚æ•°ï¼ˆhidden dim=1024ï¼‰
  - 720M å‚æ•°ï¼ˆhidden dim=1536ï¼‰
- **æ¶æ„åŸºç¡€**ï¼šåŸºäº OLMo2ï¼Œä¿ç•™ Self-Attentionï¼Œæ›¿æ¢æ ‡å‡† FFN ä¸º VersatileFFN
- **è®­ç»ƒæ–¹å¼**ï¼šç»§ç»­é¢„è®­ç»ƒï¼ˆcontinued pre-trainingï¼‰1 epoch
- **åºåˆ—é•¿åº¦**ï¼š4096
- **ä¼˜åŒ–å™¨**ï¼šAdamWï¼Œcosine decay å­¦ä¹ ç‡è°ƒåº¦
- **æœ€å¤§å¾ªç¯æ¬¡æ•°** $L_{\max}=4$ï¼ˆç»æ¶ˆèç¡®å®šæœ€ä¼˜ï¼‰

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **BASE** | åŸå§‹ Dense æ¨¡å‹ |
| **MoE** | æ·»åŠ  8 ä¸ªå°ä¸“å®¶ï¼ŒTop-2 è·¯ç”± |
| **k-Loop** | FFN é‡å¤æ‰§è¡Œ k æ¬¡ï¼ˆk=2,4,6ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š æ€§èƒ½å¯¹æ¯”ï¼ˆZero-Shot Average Accuracyï¼‰

| Method | 354M Avg | 720M Avg |
|--------|----------|----------|
| BASE | 47.98% | 53.83% |
| MoE | 51.48% | 55.87% |
| 4-LOOP | 51.98% | 56.33% |
| 6-LOOP | 51.94% | 56.55% |
| **VERSATILEFFN** | **52.33%** | **57.03%** |

> âœ… **VersatileFFN åœ¨ä¸¤ç§å°ºåº¦ä¸Šå‡è¾¾åˆ°æœ€é«˜ç²¾åº¦**

### ğŸ’° æ•ˆç‡åˆ†æï¼ˆFLOPs ä¸å‚æ•°ï¼‰

| Method | Params (354M) | FFN FLOPs (354M) |
|--------|---------------|------------------|
| BASE | 354.71M | 377.49M |
| MoE | 543.59M (+53%) | 471.86M |
| 4-LOOP | 354.71M | 1509.96M (**Ã—4.0**) |
| 6-LOOP | 354.71M | 2264.96M (**Ã—6.0**) |
| **VERSATILEFFN** | **354.90M** (**+0.05%**) | **1236.08M** (**Ã—3.3**) |

| Method | Params (720M) | FFN FLOPs (720M) |
|--------|---------------|------------------|
| BASE | 720.81M | 849.35M |
| MoE | 1145.69M (+58%) | 1061.69M |
| 6-LOOP | 720.81M | 5096.10M (**Ã—6.0**) |
| **VERSATILEFFN** | **721.09M** (**+0.04%**) | **2586.38M** (**Ã—3.0**) |

> âœ… **å‚æ•°å‡ ä¹ä¸å˜**ï¼ŒFLOPs æ˜¾è‘—ä½äºé«˜ loop æ•°æ–¹æ³•ï¼Œä¸”æ€§èƒ½æ›´é«˜ã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

| Configuration | Loss | Accuracy |
|---------------|------|----------|
| BASE | 2.779 | 47.98% |
| + Width-Versatile | 2.633 | 50.98% |
| + Depth-Versatile | 2.625 | 51.86% |
| + Gatingï¼ˆå®Œæ•´ç‰ˆï¼‰ | **2.617** | **52.33%** |

> âœ… ä¸¤æ¡è·¯å¾„äº’è¡¥ï¼Œè”åˆä½¿ç”¨æ•ˆæœæœ€ä½³ã€‚

#### ä¸åŒé…ç½®å½±å“ï¼š
- **Loop æ•°é€‰æ‹©**ï¼š4 loops åœ¨å‡†ç¡®ç‡ä¸Šè¾¾åˆ°å³°å€¼ï¼Œ6 loops å‡ºç°è¿‡æ‹Ÿåˆè¿¹è±¡
- **Expert é…ç½®**ï¼šMoE-8-2ï¼ˆ8ä¸ªä¸“å®¶é€‰2ä¸ªï¼‰è¡¨ç°æœ€å¥½

#### æ— éœ€ç»§ç»­é¢„è®­ç»ƒçš„ç»“æœï¼š
| Method | Accuracy |
|-------|----------|
| BASE | 47.98% |
| 4-LOOP | 50.81% |
| **VERSATILEFFN** | **51.14%** |

> å³ä½¿ä¸ç»§ç»­è®­ç»ƒï¼ŒVersatileFFN ä¹Ÿèƒ½æ˜¾è‘—ä¼˜äº baseline å’Œ 4-Loopã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å‚æ•°å¤ç”¨å¯ä»¥æœ‰æ•ˆæ›¿ä»£å‚æ•°æ‰©å¼ **ï¼šé€šè¿‡åœ¨å®½åº¦å’Œæ·±åº¦ä¸Šçµæ´»å¤ç”¨åŒä¸€ç»„å‚æ•°ï¼Œå¯åœ¨ä¸å¢åŠ å†…å­˜è´Ÿæ‹…çš„å‰æä¸‹æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½ã€‚
2. **åŒè·¯å¾„ååŒä¼˜äºå•ä¸€è·¯å¾„**ï¼šå®½åº¦è·¯å¾„é€‚åˆå¿«é€Ÿå¤„ç†ç®€å• tokenï¼Œæ·±åº¦è·¯å¾„æ“…é•¿å¤æ‚æ¨ç†ï¼ŒäºŒè€…ç»“åˆå®ç°æ›´ä¼˜èµ„æºåˆ†é…ã€‚
3. **åŠ¨æ€é—¨æ§æœºåˆ¶æœ‰æ•ˆå»ºæ¨¡ token éš¾åº¦**ï¼šåˆ©ç”¨é¢„æµ‹çš„è¿­ä»£æ¬¡æ•°ä½œä¸ºéš¾åº¦ä¿¡å·ï¼Œèƒ½è‡ªåŠ¨è°ƒèŠ‚è®¡ç®—ç­–ç•¥ï¼Œæå‡æ•´ä½“æ•ˆç‡ã€‚
4. **VersatileFFN æ˜¯çœŸæ­£çš„ parameter-efficient æ¶æ„**ï¼šç›¸æ¯” MoE çš„â€œå‚æ•°è†¨èƒ€â€ï¼Œå®ƒå®ç°äº†â€œè®¡ç®—æ¢æ€§èƒ½â€çš„ç†æƒ³èŒƒå¼ã€‚

### âš ï¸ å±€é™æ€§
- å¼•å…¥äº†é¢å¤–çš„ **router å’Œ loop predictor**ï¼Œå¸¦æ¥è½»å¾®å‚æ•°å’Œè®¡ç®—å¼€é”€ï¼ˆå°½ç®¡å¯å¿½ç•¥ï¼‰ã€‚
- æ¨ç†å»¶è¿Ÿå¯èƒ½å—åŠ¨æ€å¾ªç¯å½±å“ï¼Œéœ€ä¾èµ– early-exit å’Œå¹¶è¡Œä¼˜åŒ–æ¥ç¼“è§£ã€‚
- å½“å‰è®¾è®¡ä»å±€é™äº FFN æ¨¡å—ï¼Œæœªæ‰©å±•åˆ° Attention æˆ–å…¶ä»–ç»„ä»¶ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å°† Versatile è®¾è®¡æ¨å¹¿è‡³ Multi-Head Attention æˆ–æ•´ä¸ª Transformer Blockã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„æ§åˆ¶å™¨ç»“æ„ï¼ˆå¦‚è½»é‡çº§ MLP æˆ– attention-based predictorï¼‰ã€‚
- åœ¨æ›´å¤šä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚é•¿æ–‡æœ¬ç”Ÿæˆã€æ•°å­¦æ¨ç†ï¼‰ä¸­éªŒè¯å…¶æ³›åŒ–èƒ½åŠ›ã€‚
- ç»“åˆç¡¬ä»¶ä¼˜åŒ–ï¼ˆå¦‚åŠ¨æ€ kernel è°ƒåº¦ï¼‰è¿›ä¸€æ­¥é™ä½æ¨ç†å»¶è¿Ÿã€‚

---

## âœ… æ€»ç»“
**VersatileFFN** æå‡ºäº†ä¸€ç§æ–°é¢–çš„â€œå®½æ·±å¤ç”¨â€æ€æƒ³ï¼Œæ‰“ç ´äº†ä¼ ç»Ÿ LLM æ‰©å±•ä¾èµ–å‚æ•°å¢é•¿çš„èŒƒå¼ã€‚å®ƒé€šè¿‡**å‚æ•°å…±äº« + è‡ªé€‚åº”è®¡ç®— + éš¾åº¦æ„ŸçŸ¥é—¨æ§**ï¼Œå®ç°äº†é«˜æ€§èƒ½ä¸é«˜æ•ˆç‡çš„ç»Ÿä¸€ï¼Œåœ¨å¤šé¡¹ benchmark ä¸Šè¶…è¶Š MoE å’Œå›ºå®šå¾ªç¯æ–¹æ³•ï¼Œæ˜¯è¿ˆå‘â€œmemory-light, compute-smartâ€å¤§æ¨¡å‹çš„é‡è¦ä¸€æ­¥ã€‚

</details>

---

### 7. [TiME: Tiny Monolingual Encoders for Efficient NLP Pipelines](https://arxiv.org/abs/2512.14645)

**Authors**: David Schulmeister, Valentin Hartmann, Lars Klein, Robert West  
**Category**: cs.CL  
**Published**: 2025-12-17  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.14645v1  

#### Abstract
Today, a lot of research on language models is focused on large, general-purpose models. However, many NLP pipelines only require models with a well-defined, small set of capabilities. While large models are capable of performing the tasks of those smaller models, they are simply not fast enough to ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTiME: Tiny Monolingual Encoders for Efficient NLP Pipelines

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ä¸»æµè¯­è¨€æ¨¡å‹ï¼ˆå¦‚ BERTã€XLM-Rï¼‰è™½ç„¶åœ¨å¤šç§ NLP ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†å…¶åºå¤§çš„å‚æ•°é‡å¯¼è‡´**æ¨ç†å»¶è¿Ÿé«˜ã€èƒ½è€—å¤§**ï¼Œéš¾ä»¥éƒ¨ç½²äºå®æ—¶ç³»ç»Ÿæˆ–èµ„æºå—é™è®¾å¤‡ï¼ˆå¦‚ç§»åŠ¨ç»ˆç«¯ï¼‰ã€‚æ­¤å¤–ï¼Œå¤šè¯­è¨€æ¨¡å‹ï¼ˆmultilingual modelsï¼‰è™½æ”¯æŒå¤šç§è¯­è¨€ï¼Œä½†åœ¨å•ä¸ªè¯­è¨€ä¸Šçš„æ€§èƒ½å¯èƒ½ä¸å¦‚ä¸“é—¨ä¼˜åŒ–çš„**monolingual models**ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- å¦‚ä½•ä¸ºä¸åŒè¯­è¨€æ„å»º**é«˜æ•ˆä¸”é«˜æ€§èƒ½**çš„è½»é‡çº§å•è¯­ç¼–ç å™¨ã€‚
- å¦‚ä½•åœ¨ä¿æŒä½å»¶è¿Ÿå’Œä½èƒ½è€—çš„åŒæ—¶ï¼Œä¸æ˜¾è‘—ç‰ºç‰²æ¨¡å‹ç²¾åº¦ã€‚
- å¦‚ä½•æ”¯æŒä»**å¤šè¯­è¨€æ•™å¸ˆæ¨¡å‹**å‘**å•è¯­å­¦ç”Ÿæ¨¡å‹**çš„çŸ¥è¯†è¿ç§»ï¼Œå¹¶è·¨è¶Šæ¶æ„å·®å¼‚ï¼ˆå¦‚ç›¸å¯¹ä½ç½®ç¼–ç  â†’ ç»å¯¹ä½ç½®ç¼–ç ï¼‰ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
ä½œè€…æå‡ºäº† **TiME (Tiny Monolingual Encoders)** â€”â€” ä¸€ç³»åˆ—é€šè¿‡çŸ¥è¯†è’¸é¦ï¼ˆKnowledge Distillation, KDï¼‰è®­ç»ƒçš„å°å‹å•è¯­ Transformer ç¼–ç å™¨æ¨¡å‹ã€‚

#### æ ¸å¿ƒæ–¹æ³•ï¼š
- **åŸºäº MiniLMv2 çš„è’¸é¦æ¡†æ¶**ï¼šé‡‡ç”¨ multi-head self-attention relation distillationï¼Œæå–æ•™å¸ˆæ¨¡å‹ä¸­ Query-Qã€Key-K å’Œ Value-V å‘é‡ä¹‹é—´çš„å…³ç³»è¿›è¡ŒçŸ¥è¯†ä¼ é€’ã€‚
- **è·¨æ¶æ„è’¸é¦èƒ½åŠ›**ï¼š
  - æˆåŠŸå°†ä½¿ç”¨ **relative position embeddings** çš„ LTG-BERT æ¶æ„æ•™å¸ˆæ¨¡å‹ï¼ˆæ¥è‡ª HPLT é¡¹ç›®ï¼‰çš„çŸ¥è¯†è¿ç§»åˆ°ä½¿ç”¨æ ‡å‡† **absolute position embeddings** çš„ BERT æ¶æ„å­¦ç”Ÿæ¨¡å‹ã€‚
  - éªŒè¯äº†ä» **multilingual teacher (XLM-R-Large)** è’¸é¦å‡ºé«˜è´¨é‡ **monolingual student** çš„å¯è¡Œæ€§ã€‚
- **çµæ´»çš„å­¦ç”Ÿæ¶æ„è®¾è®¡**ï¼š
  - å®šä¹‰ä¸‰ç§å°ºå¯¸ï¼š`Medium (6L, 768H)`ã€`Small (6L, 384H)`ã€`Extra-Small (4L, 384H)`ã€‚
  - æ‰€æœ‰å­¦ç”Ÿå…±äº«æ•™å¸ˆçš„ tokenizerï¼Œç¡®ä¿å…¼å®¹æ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | TiME çš„ä¼˜åŠ¿ |
|------|------------|
| **æ•ˆç‡** | æ¨ç†é€Ÿåº¦æå‡æœ€é«˜è¾¾ **25Ã—**ï¼Œèƒ½é‡æ¶ˆè€—é™ä½æœ€å¤š **30Ã—**ï¼Œè¿œè¶… XLM-R-Large å’Œ XLM-R-Baseã€‚ |
| **æ€§èƒ½ä¿ç•™** | TiME-m åœ¨å¹³å‡ NLP åˆ†æ•°ä¸Šä¿ç•™äº† XLM-R-Large çš„ **98.4%** æ€§èƒ½ï¼ŒåŒæ—¶å‚æ•°å‡å°‘ 58%ã€‚ |
| **é€šç”¨æ€§** | æ”¯æŒ **16 ç§è¯­è¨€**ï¼Œæ¶µç›–é«˜ä½èµ„æºè¯­è¨€ï¼ˆå¦‚ Irish ä¸ºä½èµ„æºï¼‰ï¼ŒéªŒè¯äº†æ–¹æ³•çš„å¹¿æ³›é€‚ç”¨æ€§ã€‚ |
| **å®ç”¨æ€§** | æ¨¡å‹ç»“æ„å…¼å®¹ä¸»æµå·¥å…·é“¾ï¼ˆå¦‚ spaCyï¼‰ï¼Œä¾¿äºå·¥ä¸šè½åœ°ã€‚ |
| **å‰æ²¿æ€§** | åœ¨æ€§èƒ½-æ•ˆç‡æƒè¡¡æ›²çº¿ä¸Šå¤„äº **Pareto å‰æ²¿**ï¼Œä¼˜äºå¤šä¸ªå¼ºåŸºçº¿ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

| ç±»åˆ« | æ•°æ®é›† | ç”¨é€” |
|------|--------|------|
| **é¢„è®­ç»ƒè’¸é¦æ•°æ®** | `CulturaX` [Nguyen et al., 2023] | ç”¨äºçŸ¥è¯†è’¸é¦çš„è¯­è¨€ç‰¹å®šå­é›† |
| **ä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°** | `Universal Dependencies (UD)` treebanks | POS taggingã€lemmatizationã€dependency parsing |
| | `WikiAnn` dataset | Named Entity Recognition (NER) |
| | `MLQA` benchmark | Question Answeringï¼ˆä»… en/deï¼‰ |
| **æ£€æŸ¥ç‚¹é€‰æ‹©** | `FLORES-200`ï¼ˆä»… Irishï¼‰<br>`WMT24++`ï¼ˆå…¶ä»–è¯­è¨€ï¼‰ | å¤–éƒ¨éªŒè¯é›†ç”¨äºé€‰æ‹©æœ€ä½³è’¸é¦æ£€æŸ¥ç‚¹ |

---

### å®éªŒè®¾ç½®

- **æ•™å¸ˆæ¨¡å‹**ï¼š
  - Multilingual: `XLM-R-Large` (560M params)
  - Monolingual: `HPLT` ç³»åˆ—æ¨¡å‹ï¼ˆåŸºäº LTG-BERT æ¶æ„ï¼‰
- **å­¦ç”Ÿæ¨¡å‹**ï¼šTiME-*lang*-m/s/xsï¼Œå…±è®­ç»ƒ 16 ç§è¯­è¨€
- **ä¼˜åŒ–å™¨**ï¼šAdamWï¼Œå­¦ä¹ ç‡ 5.5e-4ï¼Œwarmup 4000 æ­¥
- **ç¡¬ä»¶**ï¼šNVIDIA A100/H100/H200ï¼ŒBF16 æ··åˆç²¾åº¦ï¼Œæœ‰æ•ˆ batch size = 256
- **è®­ç»ƒæ­¥æ•°**ï¼š200,000 stepsï¼Œæ¯ 10k æ­¥ä¿å­˜ä¸€æ¬¡ checkpoint

---

### è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ç±»å‹ | å…·ä½“æŒ‡æ ‡ |
|---------|--------|
| **å‡†ç¡®æ€§** | - NER: balanced F1<br>- POS: accuracy (AllTags)<br>- Lemmatization: accuracy (Lemma)<br>- Parsing: labeled attachment score (LAS)<br>- QA: F1 & EM (MLQA) |
| **æ•ˆç‡** | - Latency (ms, batch size=1)<br>- Throughput (sentences/sec, at optimal batch size)<br>- Energy consumption (Joules per sample) |
| **ç»¼åˆè¯„åˆ†** | å¹³å‡ NLP Scoreï¼ˆå››ä¸ªä»»åŠ¡ macro-averageï¼‰ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- `XLM-R-Large`, `XLM-R-Base`
- `mMiniLM-L6-H384`ï¼ˆMiniLM è’¸é¦è‡ª XLM-Rï¼‰
- `HPLT-original` æ¨¡å‹
- `spaCy` çš„ transformer pipelinesï¼ˆen_core_web_trf ç­‰ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1 & Table 2ï¼‰

| æ¨¡å‹ | å‚æ•°é‡(M) | å¹³å‡ NLP Score | Latency (Ã— vs XL) | Throughput (Ã— vs XL) | Energy (J/sample, Ã— vs XL) |
|------|-----------|----------------|--------------------|------------------------|----------------------------|
| XLM-R-Large | 560 | 89.15 | 1.0Ã— | 1.0Ã— | 1.0Ã— |
| XLM-R-Base | 278 | 87.86 | 1.9Ã— | 3.2Ã— | 3.3Ã— |
| TiME-m | 236 | **87.71** | **3.9Ã—** | **5.4Ã—** | **6.6Ã—** |
| TiME-s | 107 | 85.16 | 3.9Ã— | 15.9Ã— | 18.7Ã— |
| TiME-xs | 103 | 83.92 | **5.8Ã—** | **25.2Ã—** | **30.2Ã—** |

> æ³¨ï¼šLatency æå‡å€æ•°è¶Šé«˜è¡¨ç¤ºè¶Šå¿«ï¼›Throughput è¶Šé«˜è¶Šå¥½ï¼›Energy æ”¹å–„å€æ•°è¶Šå¤§è¶Šå¥½ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å…³é”®å¯¹æ¯”ç»“æœ

- **æ€§èƒ½æ–¹é¢**ï¼š
  - TiME-m åœ¨æ‰€æœ‰è¯­è¨€ä¸Šå‡ä¼˜äº `mMiniLM-L6-H384`ã€‚
  - TiME-m æ€§èƒ½æ¥è¿‘ `XLM-R-Base`ï¼Œä½†ä½“ç§¯æ›´å°ï¼ˆ236M vs 278Mï¼‰ï¼Œå®é™…æ¨ç†æ›´å¿«ã€‚
  - åœ¨ä½èµ„æºè¯­è¨€ Irish ä¸Šï¼ŒTiME-m æ¢å¤äº†è¶…è¿‡ **99%** æ•™å¸ˆæ€§èƒ½ã€‚

- **æ•ˆç‡æ–¹é¢**ï¼ˆFigure 1ï¼‰ï¼š
  - TiME æ¨¡å‹ä½äºâ€œæ•ˆç‡å‰æ²¿â€ï¼ˆefficiency frontierï¼‰ï¼Œå³åœ¨ç›¸åŒæ€§èƒ½ä¸‹å»¶è¿Ÿæ›´ä½ï¼Œæˆ–åœ¨ç›¸åŒå»¶è¿Ÿä¸‹æ€§èƒ½æ›´é«˜ã€‚
  - å°å‹æ¨¡å‹ï¼ˆTiME-xsï¼‰ååé‡é«˜è¾¾ **9321.1 å¥/ç§’**ï¼Œæ˜¯ XLM-R-Large çš„ **25Ã—**ã€‚

- **ä¸ spaCy å¯¹æ¯”**ï¼ˆTable 4ï¼‰ï¼š
  - åœ¨ English ä¸Šï¼Œ`TiME-en-xs` å»¶è¿Ÿä»…ä¸º **1.9ms**ï¼Œè€Œ `en_core_web_trf` ä¸º **5.1ms**ï¼ˆä¸‹é™ 63%ï¼‰ã€‚
  - ååé‡æå‡æ˜æ˜¾ï¼š`TiME-en-xs` è¾¾åˆ° **6361.6 s/s**ï¼Œç›¸æ¯” spaCy çš„ **1330.0 s/s**ï¼Œæé€Ÿ **4.78Ã—**ã€‚

---

### æ¶ˆèå®éªŒä¸é¢å¤–åˆ†æï¼ˆå¦‚æœ‰ï¼‰

å°½ç®¡æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†æ–‡ä¸­éšå«å¤šä¸ªå…³é”®éªŒè¯ï¼š

1. **è·¨æ¶æ„è’¸é¦æœ‰æ•ˆæ€§**ï¼š
   - æˆåŠŸä» LTG-BERTï¼ˆrelative PE + GeGLUï¼‰è’¸é¦åˆ°æ ‡å‡† BERTï¼ˆabsolute PE + GELUï¼‰ï¼Œè¯æ˜ MiniLMv2 çš„é²æ£’æ€§ã€‚

2. **å¤šè¯­è¨€æ•™å¸ˆ â†’ å•è¯­å­¦ç”Ÿ**ï¼š
   - ä½¿ç”¨ XLM-R-Large è’¸é¦å‡ºçš„ TiME æ¨¡å‹ï¼Œåœ¨å„è¯­è¨€ä¸Šè¡¨ç°ä¼˜äºæˆ–åª²ç¾ä¸“ä¸ºè¯¥è¯­è¨€è®¾è®¡çš„ monolingual teacher è’¸é¦ç»“æœã€‚

3. **æ‰¹å¤§å°å¯¹èƒ½æ•ˆçš„å½±å“**ï¼ˆFigure 5ï¼‰ï¼š
   - å­˜åœ¨ä¸€ä¸ªæœ€ä¼˜ batch size å¯æœ€å°åŒ–æ¯æ ·æœ¬èƒ½è€—ï¼ŒTiME-xs åœ¨æ­¤æŒ‡æ ‡ä¸Šè¡¨ç°æœ€ä½³ã€‚

4. **ä½èµ„æºè¯­è¨€é€‚åº”æ€§**ï¼š
   - åœ¨ Irish ä¸Šä»å–å¾—è‰¯å¥½æ€§èƒ½ï¼Œè¯´æ˜è¯¥è’¸é¦æµç¨‹å¯¹æ•°æ®é‡è¾ƒå°çš„è¯­è¨€ä¹Ÿå…·æ½œåŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **å°å‹å•è¯­æ¨¡å‹å¯ä»¥å®ç°æé«˜çš„æ•ˆç‡-æ€§èƒ½å¹³è¡¡**ï¼šTiME ç³»åˆ—æ¨¡å‹åœ¨æ˜¾è‘—å‹ç¼©æ¨¡å‹è§„æ¨¡çš„åŒæ—¶ï¼Œå‡ ä¹æ— æŸåœ°ä¿ç•™äº†å¤§å‹æ•™å¸ˆæ¨¡å‹çš„èƒ½åŠ›ã€‚
2. âœ… **çŸ¥è¯†è’¸é¦æ˜¯æ„å»ºé«˜æ•ˆ NLP æµæ°´çº¿çš„æœ‰æ•ˆè·¯å¾„**ï¼šç‰¹åˆ«æ˜¯ MiniLMv2 çš„ attention relation distillation æ–¹æ³•ï¼Œé€‚ç”¨äºå¤æ‚æ¶æ„è¿ç§»ã€‚
3. âœ… **å¤šè¯­è¨€æ•™å¸ˆå¯ç”¨äºç”Ÿæˆé«˜æ€§èƒ½å•è¯­å­¦ç”Ÿ**ï¼šæ‰“ç ´äº†â€œå¿…é¡»ç”¨å•è¯­æ•™å¸ˆâ€çš„é™åˆ¶ï¼Œæå‡äº†ä½èµ„æºè¯­è¨€å»ºæ¨¡çš„å¯èƒ½æ€§ã€‚
4. âœ… **TiME æ¨¡å‹åœ¨çœŸå®åœºæ™¯ä¸­å…·å¤‡éƒ¨ç½²ä¼˜åŠ¿**ï¼šæ— è®ºæ˜¯ä½å»¶è¿Ÿå“åº”è¿˜æ˜¯å¤§è§„æ¨¡æ‰¹é‡å¤„ç†ï¼Œéƒ½å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **æœªæ¢ç´¢æ›´ä¼˜æ¶æ„æœç´¢**ï¼šå­¦ç”Ÿæ¨¡å‹å°ºå¯¸å›ºå®šï¼ˆxs/s/mï¼‰ï¼Œç¼ºä¹ç³»ç»Ÿæ€§çš„ç¥ç»æ¶æ„æœç´¢ï¼ˆNASï¼‰æ¥å¯»æ‰¾ Pareto æœ€ä¼˜è§£ã€‚
2. **ä½èµ„æºè¯­è¨€å‹ç¼©æ•æ„Ÿåº¦é«˜**ï¼šåœ¨æœ€å°æ¨¡å‹ï¼ˆTiME-xsï¼‰ä¸Šï¼ŒIrish å’Œ Hungarian çš„æ€§èƒ½ä¸‹é™è¾ƒæ˜æ˜¾ï¼Œè¡¨æ˜æŸäº›è¯­è¨€ç‰¹æ€§åœ¨å‹ç¼©è¿‡ç¨‹ä¸­æ˜“ä¸¢å¤±ã€‚
3. **ç¼ºä¹å¯¹æç«¯ä½èµ„æºè¯­è¨€çš„æµ‹è¯•**ï¼šæœªéªŒè¯å½“è®­ç»ƒæ•°æ®æå°‘æ—¶ï¼ˆå¦‚ <1M tokensï¼‰ï¼Œè’¸é¦æ˜¯å¦ä¾ç„¶ç¨³å®šã€‚
4. **è¶…å‚æ•°æœªå……åˆ†è°ƒä¼˜**ï¼šå¦‚ relation head æ•°é‡ï¼ˆArï¼‰ç›´æ¥æ²¿ç”¨ MiniLMv2 è®¾ç½®ï¼Œæœªé’ˆå¯¹æ¯ç§è¯­è¨€åš ablationã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼€å±• **architecture-aware è’¸é¦**ï¼Œç»“åˆ NAS è‡ªåŠ¨æœç´¢æœ€ä¼˜å­¦ç”Ÿç»“æ„ã€‚
- æ¢ç´¢ **æ›´å°çš„æ•°æ®éœ€æ±‚è¾¹ç•Œ**ï¼Œç ”ç©¶å¦‚ä½•åœ¨æä½èµ„æºæ¡ä»¶ä¸‹è¿›è¡Œæœ‰æ•ˆè’¸é¦ã€‚
- æ‰©å±•è‡³æ›´å¤šä»»åŠ¡ç±»å‹ï¼ˆå¦‚æ–‡æœ¬ç”Ÿæˆã€æ‘˜è¦ç­‰ï¼‰ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ– **energy-latency trade-off**ï¼Œç‰¹åˆ«æ˜¯åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„éƒ¨ç½²ç­–ç•¥ã€‚
- æ„å»ºç»Ÿä¸€çš„ **multi-lingual tiny encoder**ï¼Œå…¼é¡¾æ•ˆç‡ä¸è·¨è¯­è¨€æ³›åŒ–èƒ½åŠ›ã€‚

---

> ğŸ”— **æ¨¡å‹ä¸ä»£ç å…¬å¼€åœ°å€**ï¼š
> - Hugging Face: [https://huggingface.co/collections/dschulmeist/time](https://huggingface.co/collections/dschulmeist/time)
> - GitHub: [https://github.com/epfl-dlab/TiME](https://github.com/epfl-dlab/TiME)

</details>

---

### 8. [Variational Physics-Informed Ansatz for Reconstructing Hidden Interaction Networks from Steady States](https://arxiv.org/abs/2512.13708)

**Authors**: Kaiming Luo  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.13708v1  

#### Abstract
The interaction structure of a complex dynamical system governs its collective behavior, yet existing reconstruction methods struggle with nonlinear, heterogeneous, and higher-order couplings, especially when only steady states are observable. We propose a Variational Physics-Informed Ansatz (VPIA) ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Variational Physics-Informed Ansatz for Reconstructing Hidden Interaction Networks from Steady States*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³**ä»ç¨³æ€ï¼ˆsteady statesï¼‰æ•°æ®ä¸­é‡å»ºå¤æ‚åŠ¨åŠ›ç³»ç»Ÿéšè—çš„äº¤äº’ç½‘ç»œç»“æ„**è¿™ä¸€é•¿æœŸæŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸ä¾èµ–äºæ—¶é—´åºåˆ—è½¨è¿¹ã€å¯¼æ•°ä¼°è®¡æˆ–å¼ºå…ˆéªŒå‡è®¾ï¼Œåœ¨ä»¥ä¸‹åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ï¼š
- åªèƒ½è§‚æµ‹åˆ°ç¨³æ€è€ŒéåŠ¨æ€è¿‡ç¨‹ï¼›
- å­˜åœ¨éçº¿æ€§ã€å¼‚è´¨æ€§å’Œé«˜é˜¶è€¦åˆï¼ˆhigher-order couplingsï¼‰ï¼›
- æ•°æ®å—å™ªå£°å¹²æ‰°ä¸¥é‡ï¼›
- ç½‘ç»œè§„æ¨¡å¤§ä¸”å¯†é›†ã€‚

è¿™äº›é—®é¢˜åœ¨ç”Ÿç‰©ç¥ç»ç½‘ç»œã€åŸºå› è°ƒæ§ç½‘ç»œå’Œç¤¾ä¼šç³»ç»Ÿç­‰ç°å®åœºæ™¯ä¸­æ™®éå­˜åœ¨ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šVPIAï¼ˆVariational Physics-Informed Ansatzï¼‰

ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Variational Physics-Informed Ansatz (VPIA)** çš„æ–°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†æœªçŸ¥çš„äº¤äº’ç®—å­ï¼ˆinteraction operatorï¼‰å»ºæ¨¡ä¸ºä¸€ä¸ªå¯è®­ç»ƒçš„**å˜åˆ†å‚æ•°åŒ–å¯¹è±¡**ï¼ˆvariational representationï¼‰ï¼›
- åˆ©ç”¨ç‰©ç†é©±åŠ¨çš„æŸå¤±å‡½æ•°â€”â€”å³**ç¨³æ€æ®‹å·®æœ€å°åŒ–**ï¼ˆsteady-state residualï¼‰ï¼Œç›´æ¥å°†ç‰©ç†çº¦æŸåµŒå…¥ä¼˜åŒ–è¿‡ç¨‹ï¼›
- ä¸éœ€è¦æ—¶é—´è½¨è¿¹ã€å¯¼æ•°ä¼°è®¡æˆ–ç›‘ç£æ ‡ç­¾ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
1. **é¦–æ¬¡å®ç°ä»…åŸºäºç¨³æ€æ•°æ®çš„é€šç”¨ç½‘ç»œé‡æ„**  
   VPIA èƒ½å¤Ÿä»å¤šä¸ªå¼‚æ„ç¨³æ€è§‚æµ‹ä¸­æ¨æ–­å‡º**æœ‰å‘ã€åŠ æƒã€ç¨€ç–æˆ–å¯†é›†ã€ç”šè‡³é«˜é˜¶ï¼ˆå¦‚ simplex-levelï¼‰è€¦åˆç»“æ„**ï¼Œæ— éœ€ä»»ä½•æ—¶é—´æ¼”åŒ–ä¿¡æ¯ã€‚

2. **ç‰©ç†å¼•å¯¼ + å¯å¾®åˆ†è¡¨ç¤º = é«˜é²æ£’æ€§ä¸å¯è§£é‡Šæ€§**  
   æ–¹æ³•é€šè¿‡å°†åŠ¨åŠ›ç³»ç»Ÿçš„ç¨³æ€æ–¹ç¨‹ $ \mathbf{F}(\mathbf{x}^*, \mathbf{p}, \mathcal{A}) = 0 $ æ˜¾å¼ä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼Œç¡®ä¿äº†è§£çš„ç‰©ç†ä¸€è‡´æ€§ï¼Œæå‡äº†å¯¹å™ªå£°å’Œæ¨¡å‹ä¸ç¡®å®šæ€§çš„å®¹å¿åº¦ã€‚

3. **å¯æ‰©å±•è®¾è®¡ï¼šæ®‹å·®é‡‡æ · + è‡ªç„¶æ¢¯åº¦ä¼˜åŒ–**
   - **æ®‹å·®é‡‡æ ·ï¼ˆResidual Samplingï¼‰**ï¼šæ¯è½®è¿­ä»£åªéšæœºé‡‡æ ·éƒ¨åˆ†èŠ‚ç‚¹æ®‹å·®ï¼Œä½¿è®¡ç®—å¤æ‚åº¦ç”± $ O(MN) $ é™è‡³æ¥è¿‘ $ O(N) $ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡ç½‘ç»œã€‚
   - **è‡ªç„¶æ¢¯åº¦æ›´æ–°ï¼ˆNatural Gradientï¼‰**ï¼šåˆ©ç”¨ Fisher ä¿¡æ¯çŸ©é˜µçš„å¯¹è§’è¿‘ä¼¼è¿›è¡Œæ›²ç‡æ„ŸçŸ¥ä¼˜åŒ–ï¼Œç¨³å®šé«˜ç»´å‚æ•°ç©ºé—´ä¸­çš„æ”¶æ•›è¿‡ç¨‹ã€‚

4. **ç»Ÿä¸€å¤„ç†ä»»æ„é˜¶äº¤äº’ç»“æ„**
   æ”¯æŒä» 1-simplexï¼ˆè¾¹ï¼‰åˆ° 4-simplexï¼ˆå››ä½“è€¦åˆï¼‰çš„é«˜é˜¶ç›¸äº’ä½œç”¨ï¼Œå¹¶ä»¥å¼ é‡å½¢å¼ç»Ÿä¸€å‚æ•°åŒ–ï¼Œæ— éœ€é¢„è®¾äº¤äº’é˜¶æ•°ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•å±€é™ | VPIAä¼˜åŠ¿ |
|------|---------------|---------|
| æ•°æ®éœ€æ±‚ | éœ€è¦å®Œæ•´æ—¶é—´åºåˆ—æˆ–å¯¼æ•°ä¼°è®¡ | ä»…éœ€ç¨³æ€å¿«ç…§ |
| å™ªå£°é²æ£’æ€§ | å¯¹æµ‹é‡/åŠ¨æ€å™ªå£°æ•æ„Ÿ | åœ¨ä¸‰ç§å™ªå£°ä¸‹å‡ä¿æŒé«˜ç²¾åº¦ |
| ç»“æ„çµæ´»æ€§ | å¤šé™äºæˆå¯¹ã€ç¨€ç–ã€çº¿æ€§è¿æ¥ | æ”¯æŒæœ‰å‘ã€åŠ æƒã€é«˜é˜¶ã€å¯†é›†ç»“æ„ |
| å¯æ‰©å±•æ€§ | å¤šæ•°ç®—æ³•å¤æ‚åº¦ â‰¥ $ O(N^3) $ | è¿‘çº¿æ€§æ‰©å±•ï¼Œæ”¯æŒ $ N \sim 10^3 $ èŠ‚ç‚¹ |
| ç‰©ç†ä¸€è‡´æ€§ | å¤šåŸºäºç»Ÿè®¡ç›¸å…³æ€§ï¼ˆå¦‚ TE, Correlationï¼‰ | å†…åµŒç‰©ç†æ–¹ç¨‹ï¼Œé¿å…è™šå‡å…³è” |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

#### ï¼ˆ1ï¼‰äººå·¥åˆæˆç½‘ç»œ
- **ER éšæœºå›¾**ï¼ˆErdÅ‘sâ€“RÃ©nyi, $ G(N,p) $ with $ p=0.5 $ï¼‰
- åŒ…å«ä¸åŒæ‹“æ‰‘ï¼šscale-freeã€small-worldã€directedã€weighted
- é«˜é˜¶ç½‘ç»œï¼šæ‰€æœ‰å¯èƒ½çš„ $ k $-simplexï¼ˆ$ k=1,2,3,4 $ï¼‰ä»¥æ¦‚ç‡ 0.5 ç‹¬ç«‹ç”Ÿæˆ

#### ï¼ˆ2ï¼‰çœŸå®ä¸–ç•Œç½‘ç»œï¼ˆæ¥è‡ªå…¬å¼€æ•°æ®åº“ [34â€“36]ï¼‰
| ç½‘ç»œåç§° | ç±»å‹ | èŠ‚ç‚¹æ•° $ N $ | è¾¹æ•° $ E $ | å¯†åº¦ |
|--------|-------|-------------|-----------|-------|
| Florentine Families | Undir | 16 | 20 | 0.1667 |
| Zachary Karate Club | Undir | 34 | 78 | 0.1390 |
| Wild Bird Social | Undir | 202 | 11733 | 0.5861 |
| C. elegans Neural | Dir | 297 | 2359 | 0.0259 |
| Power Grid | Undir | 494 | 596 | 0.0049 |
| Retweet Weibo | Dir | 596 | 1415 | 0.0080 |
| Human Brain Neural | Undir | 989 | 35730 | 0.036 |

è¿™äº›ç½‘ç»œè¦†ç›–äº†ä»å°å‹ç¤¾ä¼šç½‘ç»œåˆ°åƒèŠ‚ç‚¹çº§è„‘åŠŸèƒ½ç½‘ç»œçš„çœŸå®å°ºåº¦ã€‚

---

### å®éªŒè®¾ç½®

- **åŠ¨åŠ›å­¦æ¨¡å‹**ï¼šä¸»è¦é‡‡ç”¨ Kuramoto æ¨¡å‹ï¼Œä½†ä¹Ÿæµ‹è¯•äº†å¤šç§å…¶ä»–ç³»ç»ŸéªŒè¯æ³›åŒ–èƒ½åŠ›ï¼š
  - Phase oscillators: Kuramoto, Kuramoto-Sakaguchi
  - Limit-cycle: Stuart-Landau, Van der Pol, FitzHugh-Nagumo
  - Chaotic systems: RÃ¶ssler, Lorenz, Hindmarsh-Rose
- **ç¨³æ€ç”Ÿæˆ**ï¼šé€šè¿‡æ•°å€¼ç§¯åˆ†ï¼ˆRunge-Kutta æˆ–è‡ªé€‚åº”æ­¥é•¿ ODE æ±‚è§£å™¨ï¼‰è·å¾— $ M = O(N) $ è‡³ $ O(N\log N) $ ä¸ªç¨³æ€æ ·æœ¬ã€‚
- **å»é€€åŒ–è¿‡æ»¤**ï¼šå‰”é™¤åŒæ­¥æˆ–ä½ç¦»æ•£åº¦çš„ç¨³æ€ï¼Œä½¿ç”¨æ–¹å·®æˆ–å¹³å‡æˆå¯¹è·ç¦»ä½œä¸ºåˆ¤æ® $ D(x^*) > \epsilon_{sync} $ã€‚

---

### è¯„ä¼°æŒ‡æ ‡

- **AUCï¼ˆArea Under ROC Curveï¼‰**ï¼šä¸ºä¸»è¦è¯„ä»·æŒ‡æ ‡ï¼Œå…·æœ‰é˜ˆå€¼æ— å…³æ€§å’Œå¯¹ç¨€ç–ç½‘ç»œçš„ç¨³å¥æ€§ã€‚
- å…¶ä»–è¡¥å……æŒ‡æ ‡ï¼šAccuracy, Precision, Recall, F1-scoreï¼ˆç”¨äºäºŒåˆ†ç±»ä»»åŠ¡ï¼‰ã€‚
- æˆåŠŸé‡å»ºå®šä¹‰ï¼šAUC = 1 ä¸”æ‰€æœ‰åˆ†ç±»æŒ‡æ ‡å‡ä¸º 1ã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆè§ Supplementary Sec. S4ï¼‰

æ¯”è¾ƒçš„ç»å…¸æ–¹æ³•åŒ…æ‹¬ï¼š
- Transfer Entropy (TE)
- Network Deconvolution (ND)
- Partial Phase Synchronization (PPS)
- Modular Response Analysis (MRA)
- Global Silencing (GS)
- Correlation-based inference

> âš ï¸ æ³¨æ„ï¼šä»…é€‰æ‹©é‚£äº›å¯åœ¨ç›¸åŒè¾“å…¥æ¡ä»¶ä¸‹è¿è¡Œçš„æ–¹æ³•ï¼ˆå³ä½¿ç”¨ç¨³æ€æˆ–è½¨è¿¹æ•°æ®ï¼‰ï¼Œæ’é™¤éœ€è¦å·²çŸ¥ç½‘ç»œç»“æ„æˆ–ç½‘ç»œé›†åˆçš„æ–¹æ³•ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

| åœºæ™¯ | æ€§èƒ½è¡¨ç° |
|------|----------|
| **ä¸€èˆ¬äººå·¥ç½‘ç»œ**ï¼ˆFig. 2Bï¼‰ | AUC > 0.95ï¼Œå¤šæ•°æ¥è¿‘ 1ï¼›å³ä½¿ $ N=50 $ï¼Œä»…éœ€çº¦ 20â€“30 ä¸ªç¨³æ€å³å¯è¾¾åˆ°å®Œç¾é‡å»º |
| **æ‰€éœ€ç¨³æ€æ•°é‡ vs ç½‘ç»œå¤§å°**ï¼ˆFig. 2Cï¼‰ | æ‰€éœ€ç¨³æ€æ•°éš $ N $ è¿‘ä¼¼çº¿æ€§å¢é•¿ï¼Œè¡¨æ˜ä¿¡æ¯æ•ˆç‡é«˜ |
| **çœŸå®ç½‘ç»œé‡å»º**ï¼ˆFig. 4ï¼‰ | åœ¨ $ N=989 $ çš„äººè„‘ç½‘ç»œä¸Šï¼Œä»…éœ€çº¦ 150 ä¸ªç¨³æ€å³å¯è¾¾åˆ° AUC â‰ˆ 1 |
| **é«˜é˜¶äº¤äº’é‡å»º**ï¼ˆFig. 5Bâ€“Cï¼‰ | æˆåŠŸæ¢å¤ 4-simplex å¼ é‡ç»“æ„ï¼ŒAUC éšæ ·æœ¬å¢åŠ å¿«é€Ÿä¸Šå‡è‡³ 1 |
| **å™ªå£°é²æ£’æ€§**ï¼ˆFig. 3 & 5Eï¼‰ | å³ä½¿åœ¨å™ªå£°æ°´å¹³è¾¾ 0.5 æ—¶ï¼Œåªè¦æä¾›æ›´å¤šç¨³æ€ï¼Œä»å¯æ¢å¤é«˜ç²¾åº¦ï¼ˆAUC > 0.95ï¼‰ |

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœï¼ˆSupplementary Sec. S4ï¼‰

- æ‰€æœ‰åŸºå‡†æ–¹æ³•åœ¨ä»¥ä¸‹æƒ…å†µæ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼š
  - ç½‘ç»œå¯†åº¦å¢åŠ ï¼ˆ>0.1ï¼‰
  - å­˜åœ¨æ–¹å‘æ€§æˆ–æƒé‡å¼‚è´¨æ€§
  - åŠ¨åŠ›å­¦éçº¿æ€§è¾ƒå¼º
- VPIA åœ¨æ‰€æœ‰æµ‹è¯•åœºæ™¯ä¸­å‡å–å¾— **ä¸€è‡´çš„é«˜ AUC å’Œè¿‘ä¹å®Œç¾çš„æ”¯æŒæ¢å¤ï¼ˆsupport recoveryï¼‰**
- ç‰¹åˆ«æ˜¯åœ¨ç¨ å¯†ã€æœ‰å‘ã€éçº¿æ€§ç³»ç»Ÿä¸­ï¼ŒVPIA æ˜æ˜¾ä¼˜äºåŸºäº Jacobian å›å½’ã€åæ–¹å·®åæ¼”æˆ–é—´æ¥å…³è”è¿‡æ»¤çš„æ–¹æ³•

---

### æ¶ˆèå®éªŒä¸å…³é”®æœºåˆ¶éªŒè¯ï¼ˆéšå«äºæ­£æ–‡åŠé™„å½•ï¼‰

è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºâ€œæ¶ˆèå®éªŒâ€ç« èŠ‚ï¼Œä½†æ–‡ä¸­å¤šå¤„åˆ†æä½“ç°äº†å…³é”®ç»„ä»¶çš„ä½œç”¨ï¼š

| ç»„ä»¶ | æ•ˆæœéªŒè¯ |
|------|---------|
| **æ®‹å·®é‡‡æ ·**ï¼ˆSec. III.Cï¼‰ | ä½¿å¾— $ O(N) $ è®¡ç®—æˆæœ¬æˆä¸ºå¯èƒ½ï¼Œæ”¯æŒ $ N \sim 10^3 $ è§„æ¨¡ï¼›å³ä½¿é‡‡æ ·æ¯”ä¾‹ä½è‡³ 5%ï¼Œä»èƒ½ç¨³å®šæ”¶æ•› |
| **è‡ªç„¶æ¢¯åº¦ä¼˜åŒ–**ï¼ˆSec. V.Dï¼‰ | æ˜¾è‘—æå‡é«˜ç»´å‚æ•°ç©ºé—´ä¸‹çš„ä¼˜åŒ–ç¨³å®šæ€§ï¼Œé˜²æ­¢å› å„å‚æ•°å°ºåº¦å·®å¼‚å¯¼è‡´çš„éœ‡è¡æˆ–åœæ» |
| **å¤šç¨³æ€å¤šæ ·æ€§è¦æ±‚**ï¼ˆSec. II.Bï¼‰ | è‹¥æ‰€æœ‰ç¨³æ€è¶‹åŒï¼ˆå¦‚åŒæ­¥æ€ï¼‰ï¼Œåˆ™æ— æ³•è¯†åˆ«ç»“æ„ï¼›å¿…é¡»ä¿è¯è¶³å¤Ÿåˆ†æ•£çš„ç¨³æ€åˆ†å¸ƒ |
| **ç‰©ç†çº¦æŸé©±åŠ¨**ï¼ˆSec. IVï¼‰ | æ­£å› ä¸ºæ¯ä¸ªç¨³æ€æä¾›å…¨å±€çº¦æŸï¼Œè€Œå™ªå£°ä¸ºå±€éƒ¨æ‰°åŠ¨ï¼Œå› æ­¤å¯é€šè¿‡å¤§é‡æ ·æœ¬å¹³å‡æ‰å™ªå£°å½±å“ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. âœ… **ç¨³æ€è•´å«ä¸°å¯Œç»“æ„ä¿¡æ¯**ï¼šå°½ç®¡æ²¡æœ‰æ—¶é—´æ¼”åŒ–è·¯å¾„ï¼Œå¤šä¸ªå¼‚æ„ç¨³æ€è”åˆèµ·æ¥è¶³ä»¥å”¯ä¸€ç¡®å®šå¤æ‚çš„äº¤äº’ç»“æ„ï¼Œå‰ææ˜¯å®ƒä»¬è¶³å¤Ÿå¤šæ ·åŒ–ã€‚
2. âœ… **ç‰©ç†ä¸€è‡´æ€§æ˜¯é²æ£’æ€§çš„æ¥æº**ï¼šé€šè¿‡æœ€å°åŒ–ç‰©ç†å¯¼å‡ºçš„ç¨³æ€æ®‹å·®ï¼ŒVPIA èƒ½æœ‰æ•ˆæŠ‘åˆ¶å™ªå£°å¹¶é¿å…è™šå‡è¿æ¥ã€‚
3. âœ… **VPIA å…·å¤‡å¼ºæ³›åŒ–èƒ½åŠ›**ï¼šåœ¨ç›¸ä½æŒ¯å­ã€æé™ç¯ã€æ¿€å‘ç³»ç»Ÿä¹ƒè‡³æ··æ²Œç³»ç»Ÿä¸Šè¡¨ç°ä¸€è‡´ä¼˜å¼‚ï¼Œè¯´æ˜å…¶ä¾èµ–çš„æ˜¯ç¨³æ€æœ¬èº«çš„ç»“æ„æ€§è€Œéå…·ä½“åŠ¨åŠ›å­¦å½¢å¼ã€‚
4. âœ… **å¯æ‰©å±•è‡³ç°å®å¤§è§„æ¨¡ç½‘ç»œ**ï¼šç»“åˆæ®‹å·®é‡‡æ ·ä¸è‡ªç„¶æ¢¯åº¦ï¼ŒæˆåŠŸåº”ç”¨äºè¿‘åƒèŠ‚ç‚¹çš„çœŸå®ç½‘ç»œï¼ˆå¦‚äººç±»å¤§è„‘ã€å¾®åšè½¬å‘ç½‘ç»œï¼‰ã€‚
5. âœ… **æ”¯æŒé«˜é˜¶äº¤äº’é‡å»º**ï¼šé¦–æ¬¡å®ç°äº†ä»ç¨³æ€æ•°æ®ä¸­å‡†ç¡®æ¢å¤ 2â€“4-simplex ç»“æ„ï¼Œçªç ´äº†ä¼ ç»Ÿå›¾æ¨¡å‹çš„é™åˆ¶ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

1. â— **ä¾èµ–å¤šæ ·åŒ–çš„ç¨³æ€è¾“å…¥**ï¼šè‹¥ç³»ç»Ÿåªèƒ½äº§ç”Ÿé«˜åº¦ç›¸ä¼¼æˆ–é€€åŒ–çš„ç¨³æ€ï¼ˆå¦‚åŒæ­¥çŠ¶æ€ï¼‰ï¼Œåˆ™æ— æ³•é‡å»ºç»“æ„ã€‚è¿™åœ¨æŸäº›å¼ºè€¦åˆæˆ–å¯¹ç§°ç³»ç»Ÿä¸­å¯èƒ½å‘ç”Ÿã€‚
2. â— **è®¡ç®—èµ„æºä»æœ‰ä¸€å®šé—¨æ§›**ï¼šè™½ç„¶å·²å¤§å¹…ä¼˜åŒ–ï¼Œä½†åœ¨æç«¯é«˜é˜¶ï¼ˆå¦‚ $ d>4 $ï¼‰æˆ–è¶…å¤§è§„æ¨¡ï¼ˆ$ N>10^4 $ï¼‰ç½‘ç»œä¸­ï¼Œå‚æ•°æ•°é‡å‘ˆç»„åˆçˆ†ç‚¸ï¼Œä»å…·æŒ‘æˆ˜ã€‚
3. â— **éœ€è¦ä¸€å®šç¨‹åº¦çš„åŠ¨åŠ›å­¦çŸ¥è¯†**ï¼šè™½ç„¶ä¸è¦æ±‚çŸ¥é“ç²¾ç¡®å‚æ•°ï¼Œä½†ä»éœ€çŸ¥é“å¤§è‡´çš„åŠ¨åŠ›å­¦å½¢å¼ $ \mathbf{F}(\cdot) $ æ¥æ„å»ºæ®‹å·®é¡¹ã€‚
4. â— **åˆå§‹å‚æ•°æ•æ„Ÿæ€§**ï¼šå°½ç®¡ä½¿ç”¨ sigmoid æ˜ å°„ç¼“è§£ï¼Œä½†åœ¨æç«¯ç—…æ€æ¡ä»¶ä¸‹å¯èƒ½å­˜åœ¨å±€éƒ¨æœ€ä¼˜é™·é˜±ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. ğŸ”® æ¨å¹¿è‡³**å‡†ç¨³æ€æˆ–äºšç¨³æ€ç³»ç»Ÿ**ï¼ˆquasi-steady/metastable statesï¼‰ï¼Œæ”¾å®½ä¸¥æ ¼ç¨³æ€å‡è®¾ï¼›
2. ğŸŒ å¼€å‘**åˆ†å¸ƒå¼ä¼˜åŒ–ç­–ç•¥**ï¼Œä»¥åº”å¯¹æ›´å¤§è§„æ¨¡ç½‘ç»œï¼ˆ$ N \gg 10^3 $ï¼‰ï¼›
3. ğŸ§  æ¢ç´¢æ›´é«˜æ•ˆçš„**å˜åˆ†å‚æ•°åŒ–æ–¹å¼**ï¼ˆå¦‚ä½ç§©åˆ†è§£ã€å›¾ç¥ç»ç½‘ç»œå…ˆéªŒï¼‰æ¥å‹ç¼©é«˜é˜¶å¼ é‡ç©ºé—´ï¼›
4. ğŸ“Š åº”ç”¨äºå®é™…é¢†åŸŸï¼šå¦‚ä» fMRI/fNIRS å¿«ç…§é‡å»ºè„‘åŠŸèƒ½ç½‘ç»œï¼Œæˆ–ä»å•ç»†èƒæµ‹åºæ•°æ®æ¨æ–­åŸºå› è°ƒæ§ç½‘ç»œï¼›
5. ğŸ” ç»“åˆè´å¶æ–¯æ¡†æ¶ï¼Œæä¾›ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆuncertainty quantificationï¼‰ä¸ç½®ä¿¡åŒºé—´ä¼°è®¡ã€‚

---

## æ€»ç»“

VPIA æ˜¯ä¸€ç§**åŸºäºç‰©ç†çº¦æŸã€å®Œå…¨å¯å¾®åˆ†ã€æ— éœ€æ—¶é—´è½¨è¿¹çš„ç½‘ç»œé‡æ„æ¡†æ¶**ï¼Œå®ƒæˆåŠŸè§£å†³äº†ä»ç¨³æ€æ•°æ®ä¸­é‡å»ºå¤æ‚ã€éçº¿æ€§ã€é«˜é˜¶äº¤äº’ç½‘ç»œçš„æ ¸å¿ƒéš¾é¢˜ã€‚å…¶å®éªŒç»“æœæ˜¾ç¤ºï¼š
- åœ¨å¤šç§äººå·¥ä¸çœŸå®ç½‘ç»œä¸Šå®ç°äº†æ¥è¿‘å®Œç¾çš„é‡å»ºï¼ˆAUC â†’ 1ï¼‰ï¼›
- å¯¹å™ªå£°ã€ç»“æ„æ‰°åŠ¨å’Œç³»ç»Ÿè§„æ¨¡è¡¨ç°å‡ºæå¼ºé²æ£’æ€§ï¼›
- æ˜¾è‘—ä¼˜äºç°æœ‰ä¸»æµæ–¹æ³•ï¼Œå°¤å…¶åœ¨ç¨ å¯†ã€æœ‰å‘ã€éçº¿æ€§åœºæ™¯ä¸­ä¼˜åŠ¿æ˜æ˜¾ã€‚

è¯¥å·¥ä½œä¸ºç”Ÿç‰©å­¦ã€ç¥ç»ç§‘å­¦ã€ç¤¾ä¼šå­¦ç­‰é¢†åŸŸä¸­â€œåªæœ‰å¿«ç…§ã€æ²¡æœ‰å½•åƒâ€çš„ç³»ç»Ÿæä¾›äº†å¼ºæœ‰åŠ›çš„é€†å‘å·¥ç¨‹å·¥å…·ï¼Œæ ‡å¿—ç€**ç‰©ç†å¼•å¯¼æœºå™¨å­¦ä¹ åœ¨å¤æ‚ç³»ç»Ÿè¯†åˆ«ä¸­çš„é‡è¦è¿›å±•**ã€‚

</details>

---

### 9. [RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees](https://arxiv.org/abs/2512.14069)

**Authors**: Junjie Ma, Jinlong Li  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.14069v1  

#### Abstract
Inference with modern Large Language Models (LLMs) is expensive and slow, and speculative sampling has emerged as an effective solution to this problem, however, the number of the calls to the draft model for generating candidate tokens in speculative sampling is a preset hyperparameter, lacking fle...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£ Large Language Models (LLMs) æ¨ç†è¿‡ç¨‹æ˜‚è´µä¸”ç¼“æ…¢ã€‚**Speculative Sampling** æ˜¯ä¸€ç§æœ‰æ•ˆçš„åŠ é€Ÿæ–¹æ³•ï¼Œé€šè¿‡ä¸€ä¸ªå°çš„ draft model å¿«é€Ÿç”Ÿæˆå€™é€‰ tokenï¼Œå¹¶ç”±ç›®æ ‡ LLM å¹¶è¡ŒéªŒè¯ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¸­å¯¹ draft model çš„è°ƒç”¨æ¬¡æ•°æ˜¯ä¸€ä¸ªé¢„è®¾çš„è¶…å‚æ•°ï¼ˆå¦‚å›ºå®šä¸º 8 æ¬¡ï¼‰ï¼Œç¼ºä¹çµæ´»æ€§ï¼Œå¯¼è‡´åœ¨æŸäº›ä¸Šä¸‹æ–‡ä¸­äº§ç”Ÿå†—ä½™è®¡ç®—ï¼Œç”šè‡³å‡ºç°å¤§é‡å€™é€‰ token è¢«å®Œå…¨æ‹’ç»çš„æƒ…å†µã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **RADAR**ï¼ˆReinforcement learning Adjusted Draft-generation Algorithm for speculative samplingï¼‰ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

- **åŠ¨æ€ draft tree æ„å»º**ï¼šä¸åŒäºä¼ ç»Ÿ speculative sampling ä¸­ä½¿ç”¨é™æ€æ·±åº¦çš„ draft treeï¼ˆå¦‚ EAGLE-3 å›ºå®šè°ƒç”¨ 8 æ¬¡ï¼‰ï¼ŒRADAR åœ¨æ¯ä¸€æ­¥ç”Ÿæˆè¿‡ç¨‹ä¸­**åŠ¨æ€å†³å®šæ˜¯å¦ç»§ç»­è°ƒç”¨ draft model**ï¼Œä»è€Œæ„å»º**å˜æ·±åº¦çš„åŠ¨æ€ draft tree**ã€‚
  
- **å°† draft tree ç”Ÿæˆå»ºæ¨¡ä¸º MDP**ï¼šç”±äº acceptance length å…·æœ‰éšæœºæ€§ï¼Œæ— æ³•è·å¾—ç²¾ç¡®æ ‡ç­¾ï¼Œå› æ­¤ä¸èƒ½ç›´æ¥è¿›è¡Œç›‘ç£å­¦ä¹ ã€‚ä½œè€…å°†æ•´ä¸ª draft è¿‡ç¨‹å»ºæ¨¡ä¸ºä¸€ä¸ª **Markov Decision Process (MDP)**ï¼Œåˆ©ç”¨å†…åœ¨å¥–åŠ±æœºåˆ¶è®­ç»ƒç­–ç•¥æ¨¡å‹ã€‚

- **åŸºäºç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆOffline RLï¼‰è®­ç»ƒé¢„æµ‹æ¨¡å‹**ï¼š
  - ä½¿ç”¨ EAGLE-3 åœ¨ ShareGPT æ•°æ®é›†ä¸Šè¿è¡Œï¼Œæ”¶é›†ä¸åŒè°ƒç”¨æ¬¡æ•°ä¸‹çš„ **acceptance length åˆ†å¸ƒ**ï¼Œæ„å»ºè®­ç»ƒæ•°æ®é›†ã€‚
  - å¼•å…¥è½»é‡çº§ LSTM-based **prediction model**ï¼Œè¾“å…¥ä¸º draft model è¾“å‡ºçš„ top-k confidence scoresï¼Œè¾“å‡ºä¸º `continue` æˆ– `stop` çš„æ§åˆ¶ä¿¡å·ã€‚
  - åˆ©ç”¨è¯¥æ•°æ®é›†è¿›è¡Œ **offline reinforcement learning**ï¼Œé¿å…äº†åœ¨çº¿äº¤äº’å¸¦æ¥çš„é«˜æˆæœ¬å’Œ extrapolation errorã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´é«˜çš„æ¨ç†æ•ˆç‡**ï¼šé€šè¿‡å‡å°‘ä¸å¿…è¦çš„ draft model è°ƒç”¨ï¼Œæ˜¾è‘—é™ä½å†—ä½™è®¡ç®—ã€‚
- **æ— éœ€ä¿®æ”¹ draft model ç»“æ„**ï¼šä¿æŒåŸæœ‰ draft model ä¸å˜ï¼Œä»…å¼•å…¥ä¸€ä¸ªå°å‹ prediction model æ¥è°ƒæ§ç”Ÿæˆæµç¨‹ã€‚
- **é€‚åº”æ€§å¼º**ï¼šæ ¹æ®ä¸åŒ context åŠ¨æ€è°ƒæ•´ draft tree æ·±åº¦ï¼Œæå‡èµ„æºåˆ©ç”¨ç‡ã€‚
- **è®­ç»ƒç¨³å®š**ï¼šé‡‡ç”¨ offline RL é¿å…æ¢ç´¢å¼€é”€ï¼ŒåŒæ—¶ä¿è¯è®­ç»ƒåˆ†å¸ƒä¸å®é™…æ¨æ–­ä¸€è‡´ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **è®­ç»ƒæ•°æ®é›†**ï¼š`ShareGPT`ï¼ˆç”¨äºæ„å»º acceptance length åˆ†å¸ƒæ•°æ®é›†ï¼‰
- **è¯„ä¼°ä»»åŠ¡ä¸æ•°æ®é›†**ï¼ˆå››ç±»å…¸å‹ä»»åŠ¡ï¼‰ï¼š
  - å¤šè½®å¯¹è¯ï¼š**MT-bench**
  - æ•°å­¦æ¨ç†ï¼š**GSM8K**
  - æŒ‡ä»¤éµå¾ªï¼š**Alpaca**
  - ä»£ç ç”Ÿæˆï¼š**MBPP**

> æ‰€æœ‰ä»»åŠ¡å‡æœªå¯¹ç›®æ ‡ LLM å¾®è°ƒï¼Œæƒé‡å…±äº«ã€‚

### å®éªŒè®¾ç½®
- **ç›®æ ‡ LLMs**ï¼š
  - LLaMA-Instruct 3.1 8B (**L3 8B**)
  - Vicuna 13B (**V13B**)
  - DeepSeek-R1-Distill-LLaMA 8B (**DSL 8B**)
- **Draft model**ï¼šæ²¿ç”¨ EAGLE-3 è®¾è®¡ï¼ˆå…·ä½“æœªå…¬å¼€ç»†èŠ‚ï¼‰
- **å®ç°åŸºç¡€**ï¼šåŸºäº EAGLE-3 å¼€æºä»£ç åº“å¼€å‘
- **å…³é”®å‚æ•°**ï¼š
  - æœ€å¤§ draft model è°ƒç”¨æ¬¡æ•°ï¼š8
  - åˆ†æ”¯å› å­ $k = 10$
  - æ¸©åº¦ï¼š1.0
  - Batch sizeï¼š1
  - Prediction model è®­ç»ƒä½¿ç”¨ REINFORCE ç®—æ³•ï¼Œå­¦ä¹ ç‡ $1e^{-4}$

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Speedup Ratio** | ç›¸å¯¹äº vanilla auto-regressive decoding çš„å®é™…åŠ é€Ÿæ¯” |
| **Average Acceptance Length ($\bar{T}$)** | æ¯ä¸ª drafting-verification cycle å¹³å‡æ¥å—çš„ token æ•°é‡ |
| **Average Number of Calls to Draft Model** | æ¯ cycle å¹³å‡è°ƒç”¨ draft model çš„æ¬¡æ•°ï¼ˆä¸å†æ˜¯å›ºå®šå€¼ï¼‰ |

> æ³¨æ„ï¼šä¸æŠ¥å‘Š acceptance rateï¼Œå› ä¸º RADAR ä¸æ”¹å˜ draft model æœ¬èº«ï¼Œæ•…å…¶ acceptance rate ä¸ EAGLE-3 ç›¸åŒã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**ï¼šVanilla Auto-regressive Decodingï¼ˆé€Ÿåº¦æ¯”å®šä¹‰ä¸º 1.00xï¼‰
- **å¯¹æ¯”æ–¹æ³•**ï¼š
  - **EAGLE-2**
  - **EAGLE-3**ï¼ˆå½“å‰æœ€å…ˆè¿›çš„ lossless speculative sampling æ–¹æ³•ï¼‰

æ‰€æœ‰æµ‹è¯•å‡åœ¨ç›¸åŒç¡¬ä»¶ç¯å¢ƒï¼ˆ2Ã—NVIDIA RTX3090ï¼‰ä¸‹å®Œæˆï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| Model | Method | MT-bench Speedup | GSM8K Speedup | Alpaca Speedup | MBPP Speedup |
|-------|--------|------------------|---------------|----------------|-------------|
| L3 8B | Eagle-2 | 2.56x | 3.43x | 2.89x | 3.29x |
| L3 8B | Eagle-3 | 3.08x | 4.68x | 3.86x | 4.21x |
| L3 8B | **RADAR** | **3.41x** | **4.82x** | **4.04x** | **4.44x** |
| V13B | Eagle-3 | 3.74x | 4.24x | 3.50x | 4.55x |
| V13B | **RADAR** | **4.05x** | **4.36x** | **3.84x** | **4.75x** |
| DSL 8B | Eagle-3 | 3.42x | 4.39x | 3.08x | 3.71x |
| DSL 8B | **RADAR** | **3.86x** | **4.71x** | **3.17x** | **3.99x** |

> âœ… **RADAR åœ¨æ‰€æœ‰ä»»åŠ¡å’Œæ¨¡å‹ä¸Šå‡å–å¾—æœ€é«˜ speedup ratio**ï¼Œç›¸æ¯” EAGLE-3 æå‡ **3% ~ 29%**ã€‚

### æ¥å—é•¿åº¦è¡¨ç°ï¼ˆAcceptance Lengthï¼‰
- RADAR çš„å¹³å‡ acceptance length ç•¥ä½äº EAGLE-3ï¼ˆçº¦ä½ 1.2%ï¼‰ï¼Œä½†ä»ç»´æŒé«˜ä½ã€‚
- è¡¨æ˜å…¶å¹¶æœªç‰ºç‰²å¤ªå¤š token æ¥å—èƒ½åŠ›ã€‚

### å‡å°‘ draft model è°ƒç”¨æ¬¡æ•°ï¼ˆTable 2ï¼‰

| Model | MT-bench | GSM8K | Alpaca | MBPP |
|-------|----------|-------|--------|------|
| L3 8B | 5.25 | 6.19 | 6.20 | 6.60 |
| V13B | 6.88 | 7.26 | 6.83 | 7.26 |
| DSL 8B | 6.10 | 7.20 | 5.85 | 6.47 |

> âš ï¸ EAGLE-3 å›ºå®šè°ƒç”¨ 8 æ¬¡ â†’ RADAR **å¹³å‡å‡å°‘è°ƒç”¨ 9.3% ~ 34.3%**ï¼Œ**æ•´ä½“å¹³å‡å‡å°‘ 18.7%**ã€‚

### æ€§èƒ½åˆ†æå›¾ç¤ºï¼ˆFigure 2ï¼‰
- å›¾ (a) æ˜¾ç¤º RADAR å’Œ EAGLE-3 çš„ acceptance length åˆ†å¸ƒæ¥è¿‘ï¼Œè¯´æ˜æœ‰æ•ˆæ€§ç›¸å½“ã€‚
- å›¾ (b) æ˜¾ç¤º RADAR çš„ draft model è°ƒç”¨æ¬¡æ•°é›†ä¸­åœ¨ 5â€“7 æ¬¡ï¼Œè€Œéå›ºå®š 8 æ¬¡ï¼Œä½“ç°å…¶**è‡ªé€‚åº”æ—©åœæœºåˆ¶**çš„æœ‰æ•ˆæ€§ã€‚

### å°ç»“
- **æ›´é«˜ speedup**ï¼šå¾—ç›Šäºæ›´å°‘çš„ draft model è°ƒç”¨ + ç»´æŒè¾ƒé«˜çš„ acceptance lengthã€‚
- **æ›´ä½å†—ä½™è®¡ç®—**ï¼šåŠ¨æ€å†³ç­–é¿å…æ— æ•ˆæ‰©å±• draft treeã€‚
- **é€šç”¨æ€§å¼º**ï¼šåœ¨å¤šç§ LLM å’Œä»»åŠ¡ä¸Š consistently ä¼˜äº baselineã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å›ºå®šè°ƒç”¨æ¬¡æ•°é™åˆ¶äº† speculative sampling çš„æ•ˆç‡**ï¼Œå°¤å…¶å½“ context ä¸é€‚åˆæ·± draft æ—¶ä¼šé€ æˆæµªè´¹ã€‚
2. **å°† draft tree ç”Ÿæˆè§†ä¸º MDP æ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„å»ºæ¨¡æ–¹å¼**ï¼Œæ— éœ€çœŸå®æ ‡ç­¾å³å¯è®­ç»ƒå†³ç­–æ¨¡å‹ã€‚
3. **é€šè¿‡ offline RL å­¦ä¹  acceptance length åˆ†å¸ƒä½œä¸ºå¥–åŠ±æ¥æº**ï¼Œå¯æœ‰æ•ˆæŒ‡å¯¼ prediction model å­¦ä¹ æœ€ä¼˜åœæ­¢ç­–ç•¥ã€‚
4. **RADAR åœ¨å‡ ä¹ä¸æŸå¤± acceptance length çš„å‰æä¸‹ï¼Œå¤§å¹…å‡å°‘ draft model è°ƒç”¨æ¬¡æ•°**ï¼Œä»è€Œå®ç°æ›´ä¼˜çš„æ•´ä½“åŠ é€Ÿæ•ˆæœã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡çš„ acceptance length åˆ†å¸ƒæ•°æ®é›†**ï¼šéœ€é¢„å…ˆè¿è¡Œ EAGLE-3 æ”¶é›†æ•°æ®ï¼Œå¢åŠ å‰æœŸå‡†å¤‡æˆæœ¬ã€‚
- **prediction model å¢åŠ é¢å¤–å»¶è¿Ÿ**ï¼šè™½ç„¶ $T_{\text{eye}}$ å¾ˆå°ï¼Œä½†åœ¨æç«¯ä½å»¶è¿Ÿåœºæ™¯å¯èƒ½æˆä¸ºç“¶é¢ˆã€‚
- **æœªæ¢ç´¢æ›´å¤æ‚çš„æ ‘ç»“æ„ä¼˜åŒ–**ï¼šç›®å‰ focus åœ¨â€œä½•æ—¶åœæ­¢â€ï¼Œå°šæœªç»“åˆ node pruning æˆ– reorderingï¼ˆå¦‚ EAGLE-2/3 æ‰€åšï¼‰ã€‚
- **prediction model æ¶æ„è¾ƒç®€å•**ï¼ˆLSTMï¼‰ï¼Œå¯èƒ½é™åˆ¶è¡¨è¾¾èƒ½åŠ›ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´å¼ºå¤§çš„ prediction model æ¶æ„ï¼ˆå¦‚ Transformerã€MoEï¼‰ã€‚
- è®¾è®¡æ›´ç²¾ç»†çš„ reward functionï¼Œä¾‹å¦‚è€ƒè™‘å†…å­˜å ç”¨æˆ– energy efficiencyã€‚
- ç»“åˆ tree pruning ä¸ dynamic depth æ§åˆ¶ï¼Œè¿›ä¸€æ­¥æå‡æ•ˆç‡ã€‚
- æ‰©å±•åˆ° streaming æˆ– long-context åœºæ™¯ä¸­çš„ adaptive speculative decodingã€‚

---

> ğŸ”— **å¼€æºä¿¡æ¯**ï¼šä»£ç å·²å‘å¸ƒäº GitHubï¼š[https://github.com/minaduki-sora/RADAR](https://github.com/minaduki-sora/RADAR)

</details>

---

### 10. [FusAD: Time-Frequency Fusion with Adaptive Denoising for General Time Series Analysis](https://arxiv.org/abs/2512.14078)

**Authors**: Da Zhang, Bingyu Li, Zhiyuan Zhao, Feiping Nie, Junyu Gao, Xuelong Li  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.14078v1  

#### Abstract
Time series analysis plays a vital role in fields such as finance, healthcare, industry, and meteorology, underpinning key tasks including classification, forecasting, and anomaly detection. Although deep learning models have achieved remarkable progress in these areas in recent years, constructing ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# FusAD: Time-Frequency Fusion with Adaptive Denoising for General Time Series Analysis â€”â€” æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„æ—¶é—´åºåˆ—åˆ†æï¼ˆTSAï¼‰æ¨¡å‹é€šå¸¸éµå¾ªâ€œå•ä»»åŠ¡ä¸“ç”¨â€èŒƒå¼ï¼ˆone model per taskï¼‰ï¼Œç¼ºä¹è·¨ä»»åŠ¡çš„é€šç”¨æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç°å®ä¸–ç•Œçš„æ—¶é—´åºåˆ—æ•°æ®æ™®éå­˜åœ¨**å™ªå£°å¹²æ‰°ã€å¤šå°ºåº¦åŠ¨æ€æ¨¡å¼ã€éå¹³ç¨³æ€§**ç­‰é—®é¢˜ï¼Œå¯¼è‡´ç‰¹å¾æå–å›°éš¾ï¼Œå½±å“æ¨¡å‹é²æ£’æ€§ã€‚åŒæ—¶ï¼Œè®¸å¤šæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨é•¿åºåˆ—æˆ–å¤šå˜é‡åœºæ™¯ä¸‹å­˜åœ¨è®¡ç®—æ•ˆç‡ä½ã€å¯æ‰©å±•æ€§å·®ç­‰æŒ‘æˆ˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº† **FusAD**ï¼Œä¸€ä¸ªç»Ÿä¸€çš„ã€é€‚ç”¨äºå¤šç§æ—¶é—´åºåˆ—ä»»åŠ¡ï¼ˆåˆ†ç±»ã€é¢„æµ‹ã€å¼‚å¸¸æ£€æµ‹ï¼‰çš„é€šç”¨åˆ†ææ¡†æ¶ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **è‡ªé€‚åº”æ—¶é¢‘èåˆæœºåˆ¶ï¼ˆAdaptive Time-Frequency Fusionï¼‰**  
  èåˆ **Fourier å˜æ¢**ï¼ˆæ•æ‰å…¨å±€å‘¨æœŸæ€§ï¼‰ä¸ **Wavelet å˜æ¢**ï¼ˆæ•æ‰å±€éƒ¨çªå˜ï¼‰ï¼Œå®ç°å¯¹å¤šå°ºåº¦åŠ¨æ€ç‰¹å¾çš„é«˜æ•ˆå»ºæ¨¡ã€‚

- **è‡ªé€‚åº”å»å™ªæ¨¡å—ï¼ˆAdaptive Denoising Mechanismï¼‰**  
  åœ¨é¢‘åŸŸä¸­å¼•å…¥å¯å­¦ä¹ çš„é˜ˆå€¼æœºåˆ¶ï¼Œè‡ªåŠ¨è¯†åˆ«å¹¶è¿‡æ»¤é«˜é¢‘å™ªå£°å’Œä½é¢‘è¶‹åŠ¿å¤±çœŸï¼Œæå‡æ¨¡å‹åœ¨å¤æ‚å™ªå£°ç¯å¢ƒä¸‹çš„é²æ£’æ€§ã€‚

- **ç»Ÿä¸€çš„ä¿¡æ¯èåˆä¸è§£ç ç»“æ„ï¼ˆInformation Fusion Module, IFMï¼‰**  
  è®¾è®¡äº¤äº’å¼å·ç§¯ç»“æ„ï¼Œå¢å¼ºå¤šå˜é‡é—´çš„ä¾èµ–å…³ç³»å»ºæ¨¡ï¼Œå¹¶ç»“åˆ **Masked Pre-training** å®ç°è·¨ä»»åŠ¡çš„çŸ¥è¯†è¿ç§»ä¸è¡¨ç¤ºå­¦ä¹ ã€‚

- **ç«¯åˆ°ç«¯çš„å¤šä»»åŠ¡å…¼å®¹æ¶æ„**  
  æ”¯æŒåˆ†ç±»ã€é¢„æµ‹ã€å¼‚å¸¸æ£€æµ‹ä¸‰å¤§ä¸»æµä»»åŠ¡ï¼Œåœ¨ä¸€ä¸ªå…±äº«ä¸»å¹²ç½‘ç»œä¸Šå®Œæˆå¤šä»»åŠ¡è”åˆè®­ç»ƒï¼Œæ˜¾è‘—æé«˜æ¨¡å‹å¤ç”¨æ€§å’Œéƒ¨ç½²æ•ˆç‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | FusADä¼˜åŠ¿ |
|------|----------|
| **é€šç”¨æ€§** | æ”¯æŒå¤šä»»åŠ¡ç»Ÿä¸€å»ºæ¨¡ï¼Œé¿å…ä¸ºæ¯ä¸ªä»»åŠ¡å•ç‹¬è®¾è®¡æ¨¡å‹ |
| **é²æ£’æ€§** | è‡ªé€‚åº”å»å™ªæœ‰æ•ˆåº”å¯¹å™ªå£°ã€ç¼ºå¤±å€¼å’Œåˆ†å¸ƒåç§» |
| **æ•ˆç‡** | å‚æ•°é‡å°ï¼ˆä»…2.3Mï¼‰ã€FLOPsä½ï¼Œä¼˜äºå¤šæ•°Transformerç±»æ¨¡å‹ |
| **æ€§èƒ½** | åœ¨å¤šä¸ªåŸºå‡†ä¸Šè¾¾åˆ° SOTA æˆ–æ¥è¿‘ SOTA è¡¨ç° |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
#### åˆ†ç±»ä»»åŠ¡
- **UCR Archive**: 125ä¸ªå•å˜é‡æ—¶é—´åºåˆ—æ•°æ®é›†
- **UEA Archive**: 30ä¸ªå¤šå˜é‡æ—¶é—´åºåˆ—æ•°æ®é›†ï¼ˆå¦‚å¥åº·ç›‘æµ‹ã€åŠ¨ä½œè¯†åˆ«ç­‰ï¼‰

#### é¢„æµ‹ä»»åŠ¡
- **Electricity**: ç”µåŠ›æ¶ˆè€—æ•°æ®ï¼ˆ321ç»´ï¼‰
- **ETTç³»åˆ—**ï¼ˆETTh1, ETTh2, ETTm1, ETTm2ï¼‰: èƒ½æºä¼ è¾“ç³»ç»Ÿæ•°æ®
- **Exchange**: æ±‡ç‡æ³¢åŠ¨æ•°æ®
- **Traffic**: é«˜é€Ÿå…¬è·¯è½¦æµé‡ï¼ˆ861ç»´ï¼‰
- **Weather**: å¤šæ°”è±¡å˜é‡æ—¶é—´åºåˆ—

#### å¼‚å¸¸æ£€æµ‹ä»»åŠ¡
- **SMD**ï¼ˆServer Machine Datasetï¼‰: æœåŠ¡å™¨ç›‘æ§
- **MSL / SMAP**: NASAèˆªå¤©å™¨é¥æµ‹æ•°æ®
- **SWaT**: æ°´å¤„ç†ç³»ç»Ÿå®‰å…¨æµ‹è¯•å¹³å°
- **PSM**: å·¥ä¸šæ³µä¼ æ„Ÿå™¨æ•°æ®

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

| ä»»åŠ¡ | è¯„ä¼°æŒ‡æ ‡ | è¾“å…¥é•¿åº¦ | é¢„æµ‹é•¿åº¦ |
|------|---------|----------|----------|
| **åˆ†ç±»** | å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ã€å¹³å‡æ’åï¼ˆAvg. Rankï¼‰ã€Top-1æ•°é‡ã€CDå›¾æ£€éªŒ | - | - |
| **é¢„æµ‹** | MSEã€MAEï¼ˆè¶Šä½è¶Šå¥½ï¼‰ | 96~512ä¸ç­‰ | 96, 192, 336, 720 |
| **å¼‚å¸¸æ£€æµ‹** | Precision (P), Recall (R), F1-score | æ»‘åŠ¨çª—å£ | å•ç‚¹åˆ¤æ–­ |

æ‰€æœ‰æ•°æ®å‡è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼›é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼š
1. **é¢„è®­ç»ƒé˜¶æ®µ**ï¼šä½¿ç”¨ Masked Autoencoder è¿›è¡Œè‡ªç›‘ç£å­¦ä¹ 
2. **å¾®è°ƒé˜¶æ®µ**ï¼šé’ˆå¯¹å…·ä½“ä»»åŠ¡è¿›è¡Œæœ‰ç›‘ç£è®­ç»ƒ

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¶µç›–ä¸‰å¤§ç±»ä¸»æµæ¨¡å‹ï¼š
- **Transformer-based**: Informer, PatchTST, iTransformer, Crossformer, FEDformer, Autoformer
- **MLP/CNN-based**: DLinear, RLinear, ModernTCN
- **é€šç”¨æ—¶é—´åºåˆ—æ¨¡å‹**: TS2Vec, TimesNet, TVNet, GPT4TS, TS-TCC, Data2Vec

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### åˆ†ç±»ä»»åŠ¡è¡¨ç°ï¼ˆUCR & UEAï¼‰
| æ¨¡å‹ | UCR å¹³å‡å‡†ç¡®ç‡ | UCR Top-1 æ•°é‡ | UEA å¹³å‡å‡†ç¡®ç‡ |
|------|----------------|----------------|----------------|
| **FusAD** | **0.863** | **58** | **0.765** |
| FreRA | 0.850 | 13 | 0.754 |
| TVNet | 0.844 | 5 | 0.744 |
| PatchTST | 0.825 | 0 | 0.730 |

- FusADåœ¨ **125ä¸ªUCRæ•°æ®é›†ä¸­å–å¾—58æ¬¡ç¬¬ä¸€**ï¼Œè¿œè¶…å…¶ä»–æ¨¡å‹ï¼›
- CDå›¾æ˜¾ç¤º FusAD çš„å¹³å‡æ’åæ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œä¸”ç»Ÿè®¡å·®å¼‚æ˜¾è‘—ï¼›
- å›¾2è¡¨æ˜ FusAD åœ¨æ›´ä½å‚æ•°é‡ï¼ˆ2.3Mï¼‰å’Œè®¡ç®—æˆæœ¬ï¼ˆ2.5G FLOPsï¼‰ä¸‹å®ç°äº†æ›´é«˜ç²¾åº¦ã€‚

### é¢„æµ‹ä»»åŠ¡è¡¨ç°ï¼ˆMultivariate Forecastingï¼‰
åœ¨8ä¸ªæ•°æ®é›†ã€4ç§é¢„æµ‹é•¿åº¦ï¼ˆå…±32é¡¹æŒ‡æ ‡ï¼‰ä¸Šçš„ç»¼åˆè¡¨ç°å¦‚ä¸‹ï¼š

| æ¨¡å‹ | Top-1 æ¬¡æ•° / æ€»æ¬¡æ•° | Avg MSE â†“ | Avg MAE â†“ |
|------|--------------------|-----------|-----------|
| **FusAD** | **48 / 80** | **0.250** | **0.326** |
| iTransformer | 23 / 80 | 0.254 | 0.315 |
| PatchTST | 6 / 80 | 0.267 | 0.327 |
| DLinear | 1 / 80 | 0.286 | 0.332 |

- FusADåœ¨ **ETTh1 å’Œ Weather æ•°æ®é›†ä¸Šè¡¨ç°å°¤ä¸ºçªå‡º**ï¼Œè¯´æ˜å…¶æ“…é•¿å¤„ç†é«˜æ³¢åŠ¨æ€§åºåˆ—ï¼›
- åœ¨å¤§è§„æ¨¡æ•°æ®ï¼ˆå¦‚ Trafficï¼‰ä¸Šç•¥æœ‰ä¸‹é™ï¼Œä½†ä»ä¿æŒç«äº‰åŠ›ï¼›
- è‡ªé€‚åº”å»å™ªæœºåˆ¶æœ‰åŠ©äºæŠ‘åˆ¶å™ªå£°å¹²æ‰°ï¼Œæå‡é•¿æœŸé¢„æµ‹ç¨³å®šæ€§ã€‚

### å¼‚å¸¸æ£€æµ‹ä»»åŠ¡è¡¨ç°
| æ¨¡å‹ | SMD F1 | PSM F1 | SWaT F1 | **Overall F1** |
|------|--------|--------|--------|---------------|
| **FusAD** | **0.879** | **0.977** | **0.987** | **0.872** |
| TVNet | 0.857 | 0.975 | 0.983 | 0.868 |
| GPT4TS | 0.868 | 0.971 | 0.986 | 0.867 |
| ModernTCN | 0.858 | 0.972 | 0.980 | 0.866 |

- FusADåœ¨å¤šæ•°æ•°æ®é›†ä¸Šå–å¾—æœ€ä½³F1åˆ†æ•°ï¼›
- Transformerç±»æ¨¡å‹æ™®éè¡¨ç°ä¸ä½³ï¼Œå¯èƒ½å› æ³¨æ„åŠ›æœºåˆ¶åå‘æ­£å¸¸æ ·æœ¬è€Œå¿½ç•¥ç¨€ç–å¼‚å¸¸ï¼›
- å‘¨æœŸæ€§å»ºæ¨¡ï¼ˆå¦‚TimesNetï¼‰æœ‰ä¸€å®šä¼˜åŠ¿ï¼ŒéªŒè¯äº†é¢‘åŸŸåˆ†æçš„é‡è¦æ€§ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
åœ¨å¤šä¸ªä»»åŠ¡ä¸ŠéªŒè¯å„ç»„ä»¶è´¡çŒ®ï¼š

| å˜ä½“ | AWR (Acc) | SRSCP (Acc) | ETTh1 (MSE) | SMD (F1) | PSM (F1) |
|------|-----------|-------------|--------------|----------|----------|
| **FusAD (å®Œæ•´)** | **0.990** | **0.921** | **0.403** | **0.879** | **0.977** |
| w/o ASM | 0.986 | 0.787 | 0.422 | 0.858 | 0.953 |
| w/o ASM-F (æ— Fourier) | 0.987 | 0.802 | 0.420 | 0.854 | 0.965 |
| w/o ASM-W (æ— Wavelet) | 0.989 | 0.805 | 0.416 | 0.871 | 0.963 |
| w/o ASM-T (æ— è‡ªé€‚åº”é˜ˆå€¼) | 0.988 | 0.814 | 0.409 | 0.868 | 0.970 |
| w/o IFM | 0.976 | 0.835 | 0.419 | 0.872 | 0.971 |
| w/o Pretrain | 0.979 | 0.876 | 0.408 | 0.870 | 0.975 |

- **ASMæ¨¡å—æœ€å…³é”®**ï¼Œç§»é™¤åæ€§èƒ½å…¨é¢ä¸‹é™ï¼›
- **Fourieråˆ†æ”¯å¯¹é¢„æµ‹æ›´é‡è¦**ï¼Œå› å…¶æ•è·é•¿æœŸå‘¨æœŸï¼›
- **Waveletåˆ†æ”¯å¯¹å¼‚å¸¸æ£€æµ‹æ›´å…³é”®**ï¼Œåˆ©äºæ•æ‰å±€éƒ¨çªå˜ï¼›
- **è‡ªé€‚åº”é˜ˆå€¼æœºåˆ¶æ˜¾è‘—æå‡é²æ£’æ€§**ï¼Œå°¤å…¶åœ¨å™ªå£°ç¯å¢ƒä¸‹ï¼›
- **IFM å’Œ Pre-training å¯¹è¡¨ç¤ºå­¦ä¹ æœ‰ç¨³å®šå¢ç›Š**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **æ—¶é¢‘èåˆæ˜¯æ„å»ºé€šç”¨TSAæ¨¡å‹çš„æœ‰æ•ˆè·¯å¾„**ï¼šç»“åˆ Fourier ä¸ Wavelet å¯åŒæ—¶å»ºæ¨¡å…¨å±€è¶‹åŠ¿ä¸å±€éƒ¨å˜åŒ–ï¼Œä¼˜äºå•ä¸€å˜æ¢ã€‚
2. âœ… **è‡ªé€‚åº”å»å™ªæœºåˆ¶æ˜¾è‘—å¢å¼ºé²æ£’æ€§**ï¼šç›¸æ¯”å›ºå®šæ»¤æ³¢å™¨æˆ–é™æ€å»å™ªï¼ŒLearnable Thresholding æ›´èƒ½é€‚åº”ä¸åŒæ•°æ®åˆ†å¸ƒã€‚
3. âœ… **ç»Ÿä¸€æ¡†æ¶å¯è¡Œä¸”é«˜æ•ˆ**ï¼šFusAD åœ¨åˆ†ç±»ã€é¢„æµ‹ã€å¼‚å¸¸æ£€æµ‹ä¸‰å¤§ä»»åŠ¡ä¸Šå‡è¾¾åˆ°æˆ–æ¥è¿‘SOTAï¼Œè¯æ˜äº†â€œä¸€æ¨¡å‹å¤šä»»åŠ¡â€çš„æ½œåŠ›ã€‚
4. âœ… **è½»é‡åŒ–è®¾è®¡å¸¦æ¥é«˜æ•ˆç‡**ï¼šä»…2.3Må‚æ•°å³å¯è¶…è¶Šå¤§é‡å¤§æ¨¡å‹ï¼Œåœ¨å‚æ•°æ•ˆç‡å’Œæ¨ç†é€Ÿåº¦æ–¹é¢å…·å¤‡ä¼˜åŠ¿ã€‚
5. âœ… **å¯è§†åŒ–éªŒè¯ç‰¹å¾è´¨é‡æ›´é«˜**ï¼št-SNE æ˜¾ç¤º FusAD å­¦å¾—çš„ç±»åˆ«åŸå‹æ›´ç´§å‡‘ï¼Œé¢„æµ‹æ›²çº¿æ›´ç¨³å®šæ— æ¼‚ç§»ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- åœ¨æé«˜ç»´æ•°æ®ï¼ˆå¦‚ Traffic > 800ç»´ï¼‰ä¸Šæ€§èƒ½ç•¥æœ‰ä¸‹é™ï¼Œå¯èƒ½å—é™äºæ¨¡å‹å®¹é‡ï¼›
- å½“å‰æ¡†æ¶ä¸»è¦é¢å‘è§„åˆ™é‡‡æ ·æ•°æ®ï¼Œå¯¹ä¸è§„åˆ™æ—¶é—´åºåˆ—æ”¯æŒæœ‰é™ï¼›
- è‡ªé€‚åº”é˜ˆå€¼è™½æœ‰æ•ˆï¼Œä½†å¢åŠ äº†è®­ç»ƒå¤æ‚åº¦ï¼Œéœ€æ›´å¤šè°ƒå‚ç»éªŒã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ¢ç´¢æ›´çµæ´»çš„æ—¶é¢‘èåˆæœºåˆ¶ï¼ˆå¦‚å¯å˜å½¢Waveletæ ¸ï¼‰ï¼›
2. ç ”ç©¶æ¨¡å‹å‹ç¼©ä¸åŠ é€ŸæŠ€æœ¯ï¼Œä¾¿äºè¾¹ç¼˜éƒ¨ç½²ï¼›
3. æ‰©å±•è‡³ **Multimodal Time Series**ï¼ˆå¦‚æ–‡æœ¬+æ•°å€¼ä¿¡å·å¯¹é½ï¼‰ï¼›
4. æ”¯æŒ **Irregularly Sampled Data** å’Œç¼ºå¤±å€¼æ›´å¼ºé²æ£’æ€§çš„å»ºæ¨¡ï¼›
5. æ„å»ºæ›´å¤§è§„æ¨¡çš„é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹ï¼ˆFoundation Model for TSAï¼‰ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼šFusAD æ˜¯ä¸€ç§æ–°é¢–ã€é«˜æ•ˆã€é²æ£’çš„ç»Ÿä¸€æ—¶é—´åºåˆ—åˆ†ææ¡†æ¶ï¼Œé€šè¿‡ **Adaptive Time-Frequency Fusion + Denoising + Masked Pre-training** çš„ç»„åˆï¼Œåœ¨å¤šä¸ªä»»åŠ¡å’Œæ•°æ®é›†ä¸Šå±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä¸ºé€šç”¨æ—¶é—´åºåˆ—æ™ºèƒ½æä¾›äº†é‡è¦å®è·µè·¯å¾„ã€‚

</details>

---

### 11. [AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach](https://arxiv.org/abs/2512.13714)

**Authors**: Gangesh Pathak, Prasanna Kumar  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.13714v1  

#### Abstract
LLM implementations are failing in highly regulated industries owing to instability issues, inconsistent reasoning, hallucinations and performance variability, especially in workflows. These reliability issues restrict safe use of LLM in areas that need the precision of facts and consistent behavior...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆ**LLM**ï¼‰åœ¨å®é™…éƒ¨ç½²ä¸­é¢ä¸´ä¸¥é‡çš„**ç¨³å®šæ€§é—®é¢˜**ï¼Œå…·ä½“è¡¨ç°ä¸ºï¼š
- **è¯­ä¹‰æ¼‚ç§»ï¼ˆSemantic divergenceï¼‰**ï¼šç›¸åŒæ„å›¾çš„æç¤ºè¯ç”Ÿæˆä¸åŒå«ä¹‰çš„å›ç­”
- **å¹»è§‰ï¼ˆHallucinationï¼‰**ï¼šè‡ªä¿¡åœ°è¾“å‡ºé”™è¯¯æˆ–è™šæ„ä¿¡æ¯
- **æ¨ç†å´©æºƒï¼ˆReasoning breakdownï¼‰**ï¼šé€»è¾‘çŸ›ç›¾æˆ–ä¸è¿è´¯
- **ä¼šè¯æ¼‚ç§»ï¼ˆSession driftï¼‰**ï¼šå¤šè½®å¯¹è¯ä¸­è¾“å‡ºè´¨é‡ä¸‹é™

è¿™äº›é—®é¢˜é™åˆ¶äº†LLMåœ¨åŒ»ç–—ã€é‡‘èã€æ³•å¾‹ç­‰é«˜é£é™©é¢†åŸŸçš„å¯é åº”ç”¨ã€‚ä¼ ç»Ÿå¯¹é½æ–¹æ³•å¦‚**RLHF** å’Œ **Supervised Fine-Tuning (SFT)** è™½æœ‰æ”¹è¿›ï¼Œä½†ä¾èµ–å¤§é‡äººå·¥æ ‡æ³¨ï¼Œæˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥æŒç»­æ‰©å±•ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºä¸€ç§ **Human-AI Synergy Approach**ï¼Œæ„å»ºäº†ä¸€ä¸ªé—­ç¯çš„ **AI-Powered Annotation Pipeline**ï¼Œç”¨äºç³»ç»Ÿæ€§è¯†åˆ«ã€æ ‡æ³¨å¹¶ä¿®å¤LLMè¾“å‡ºä¸­çš„ä¸ç¨³å®šæ¨¡å¼ã€‚

#### æ ¸å¿ƒæ¡†æ¶è®¾è®¡ï¼š
1. **è‡ªåŠ¨åŒ–æ ‡æ³¨å±‚ï¼ˆAutomated Annotation Layerï¼‰**
   - ä½¿ç”¨è½»é‡çº§LLMä½œä¸ºâ€œä¸“å®¶æ³¨é‡Šå™¨â€ï¼Œè‡ªåŠ¨æ£€æµ‹ä¸‰ç±»ç¨³å®šæ€§é—®é¢˜ï¼š
     - **Semantic Consistency**ï¼ˆè¯­ä¹‰ä¸€è‡´æ€§ï¼‰
     - **Factual Accuracy**ï¼ˆäº‹å®å‡†ç¡®æ€§ï¼‰
     - **Logical Coherence**ï¼ˆé€»è¾‘è¿è´¯æ€§ï¼‰
   - å¼•å…¥**ç½®ä¿¡åº¦è¯„åˆ†ï¼ˆconfidence scoringï¼‰** å’Œ **é›†æˆæŠ•ç¥¨ï¼ˆensemble votingï¼‰** æ¥è¿‡æ»¤ä½è´¨é‡è‡ªåŠ¨æ ‡ç­¾
   - è®¾ç½®ä¸ç¡®å®šæ€§é˜ˆå€¼ï¼Œè§¦å‘äººå·¥ä»‹å…¥

2. **äººåœ¨å›è·¯éªŒè¯ï¼ˆHuman-in-the-Loop Validationï¼‰**
   - äººç±»ä»…å®¡æŸ¥ä»¥ä¸‹é«˜é£é™©æ¡ˆä¾‹ï¼š
     - ä½ç½®ä¿¡åº¦è¾“å‡º
     - å¤šä¸ªAIæ ‡æ³¨å™¨æ„è§å†²çª
     - å¯èƒ½é€ æˆå±å®³çš„äº‹å®é”™è¯¯
     - ä¸Šä¸‹æ–‡æ•æ„Ÿä»»åŠ¡
   - åŒ…å« **Expert Curation** ä¸ **Community Curation** åŒé‡æœºåˆ¶ï¼Œå…¼é¡¾ä¸“ä¸šæ€§ä¸åŒ…å®¹æ€§

3. **ç¨³å®šæ€§åé¦ˆæœºåˆ¶ï¼ˆStability Feedback Mechanismï¼‰**
   - å°†éªŒè¯åçš„é«˜è´¨é‡æ ‡æ³¨æ•°æ®ç”¨äºï¼š
     - **Stability Fine-Tuning**ï¼šç›‘ç£è®­ç»ƒä»¥å‡å°‘ä¸ç¨³å®šè¡Œä¸º
     - **RIC-Based Stabilisation**ï¼šåŸºäºå¥–åŠ±æœºåˆ¶å¼ºåŒ–ä½æ–¹å·®ã€é«˜äº‹å®å¯¹é½çš„è¡Œä¸º
   - å½¢æˆ**ç¨³å®šæ€§åé¦ˆå¾ªç¯ï¼ˆStability Feedback Loopsï¼‰**

4. **æ¨¡å—åŒ–ç³»ç»Ÿæ¶æ„**
   - åŒ…æ‹¬ Annotation Engineã€Validation Interfaceã€Feedback Managerã€Monitoring Dashboard ç­‰ç»„ä»¶
   - æ”¯æŒå®æ—¶ç›‘æ§ç¨³å®šæ€§æŒ‡æ ‡ä¸æ¼‚ç§»æ£€æµ‹

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚RLHF/SFTï¼‰ | æœ¬æ–¹æ³• |
|------|------------------------|-------|
| **å¯æ‰©å±•æ€§** | é«˜åº¦ä¾èµ–äººå·¥æ ‡æ³¨ï¼Œéš¾è§„æ¨¡åŒ– | è‡ªåŠ¨åŒ–åˆç­› + é€‰æ‹©æ€§äººå·¥å®¡æ ¸ï¼Œå¤§å¹…é™ä½äººåŠ›æˆæœ¬ |
| **æŒç»­æ€§** | å¤šä¸ºä¸€æ¬¡æ€§å¯¹é½ï¼Œç¼ºä¹é•¿æœŸä¼˜åŒ–æœºåˆ¶ | æ„å»ºé—­ç¯åé¦ˆç³»ç»Ÿï¼Œæ”¯æŒç”Ÿå‘½å‘¨æœŸå†…æŒç»­ç¨³å®šåŒ– |
| **è¯„ä¼°ç»´åº¦** | ä¸»è¦å…³æ³¨å•æ¬¡å‡†ç¡®ç‡ï¼Œå¿½ç•¥å“åº”å˜å¼‚æ€§ | æå‡º**ç¨³å®šæ€§ä½œä¸ºå¯é‡åŒ–ç›®æ ‡**ï¼Œå¼•å…¥SIã€FCç­‰æ–°æŒ‡æ ‡ |
| **ä¼¦ç†æ§åˆ¶** | å®Œå…¨AIé©±åŠ¨æ˜“æ”¾å¤§åè§ï¼›çº¯äººå·¥æ•ˆç‡ä½ | äººæœºååŒä¿éšœé“å¾·æ­£ç¡®æ€§ä¸æ ‡æ³¨ä¿çœŸåº¦ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒèšç„¦äºæŒ‘æˆ˜å¤šæ­¥æ¨ç†ä¸äº‹å®ä¸€è‡´æ€§çš„ä»»åŠ¡ï¼š
| æ•°æ®é›† | ç›®æ ‡ | ç¨³å®šæ€§å‹åŠ›æµ‹è¯•è®¾è®¡ |
|--------|------|--------------------|
| **TruthfulQA** | æ£€æµ‹å¹»è§‰ä¸äº‹å®é”™è¯¯ | æ¯ä¸ªé—®é¢˜ç”Ÿæˆ5â€“10ç§åŒä¹‰æ”¹å†™ç‰ˆæœ¬ |
| **GSM8K / Synthetic Multi-Turn Reasoning** | æµ‹è¯•é€»è¾‘ä¸€è‡´æ€§ | åŠ å…¥å¹²æ‰°çŸ­è¯­ã€ä¸Šä¸‹æ–‡é‡æ’åº |
| **Knowledge-Grounded Dialogues**ï¼ˆåŒ»å­¦/æ•™è‚²å­é›†ï¼‰ | è¡¡é‡å¤šè½®å¯¹è¯ä¸€è‡´æ€§ | æ‰©å±•å¤šè½®å˜ä½“ï¼Œæ³¨å…¥æ­§ä¹‰æƒ…å¢ƒ |

æ­¤å¤–è¿˜æ„å»ºäº†ä¸“é—¨çš„**ç¨³å®šæ€§å‹åŠ›æµ‹è¯•å­é›†**ï¼ŒåŒ…æ‹¬ï¼š
- è¯­ä¹‰ç­‰ä»·çš„åŒä¹‰æç¤º
- è·¨ä¼šè¯é‡ç½®çš„é‡å¤æç¤º
- æ•…æ„è¯±å¯¼æ¨ç†åˆ†æ­§çš„çŸ›ç›¾æŸ¥è¯¢

---

### ğŸ§ª å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### åŸºçº¿æ¨¡å‹å¯¹æ¯”ï¼š
| æ¨¡å‹ | è®­ç»ƒæ–¹å¼ | é¢„æœŸè¡Œä¸º |
|------|---------|----------|
| **Baseline-1**: Standard Fine-Tuned GPT-style Model | ä»…æŒ‡ä»¤å¾®è°ƒï¼ˆSFTï¼‰ | é«˜ä»»åŠ¡å‡†ç¡®ç‡ï¼Œä½†è¾“å‡ºæ–¹å·®å¤§ |
| **Baseline-2**: RLHF-Aligned Model | åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹  | å¯¹é½æ›´å¥½ï¼Œä½†åœ¨æç¤ºæ”¹å†™ä¸‹ä»å‡ºç°æ¼‚ç§» |

#### æ–°æå‡ºçš„ç¨³å®šæ€§è¯„ä¼°æŒ‡æ ‡ï¼š
| æŒ‡æ ‡ | å®šä¹‰ | ç›®æ ‡ |
|------|-----|------|
| **Stability Index (SI)** â†“ | åŒä¹‰æç¤ºä¸‹å“åº”çš„è¯­ä¹‰æ–¹å·® | è¶Šä½è¶Šå¥½ï¼ˆæ›´ç¨³å®šï¼‰ |
| **Factual Consistency (FC)** â†‘ | å›ç­”ä¸å‚è€ƒç­”æ¡ˆçš„äº‹å®ä¸€è‡´æ€§ | è¶Šé«˜è¶Šå¥½ï¼ˆè¶Šå°‘å¹»è§‰ï¼‰ |
| **Annotation Precision (AP)** â†‘ | è‡ªåŠ¨æ ‡æ³¨ä¸äººå·¥æ ¡éªŒçš„ä¸€è‡´ç‡ | è¡¡é‡è‡ªåŠ¨åŒ–è´¨é‡ |
| **Response Diversity Ratio (RDR)** | åŸºäºç†µçš„è¯­ä¹‰å¤šæ ·æ€§åº¦é‡ | å¹³è¡¡ç¨³å®šæ€§ä¸åˆ›é€ æ€§ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªè¡¨5.1ï¼‰
| Model | SI â†“ | FC â†‘ | AP â†‘ | RDR |
|-------|------|------|------|-----|
| Baseline-1 (SFT) | 0.41 | 72% | â€” | 0.52 |
| Baseline-2 (RLHF) | 0.33 | 81% | 78% | 0.47 |
| **Stabilized Model** (**æœ¬æ–‡æ–¹æ³•**) | **0.18** | **92%** | **94%** | **0.45** |

#### æ€§èƒ½æå‡æ€»ç»“ï¼š
- **ç›¸æ¯”SFTåŸºçº¿**ï¼š  
  - **SIé™ä½56%** â†’ æ˜¾è‘—å‡å°‘è¾“å‡ºæ³¢åŠ¨
  - **FCæå‡20ä¸ªç™¾åˆ†ç‚¹** â†’ å¹»è§‰æ˜¾è‘—å‡å°‘
- **ç›¸æ¯”RLHFåŸºçº¿**ï¼š  
  - **SIå†é™45%**ï¼Œ**FCå†å‡11%**
- **APè¾¾94%** â†’ è‡ªåŠ¨æ ‡æ³¨é«˜åº¦å¯ä¿¡ï¼Œäººå·¥å¹²é¢„è´Ÿæ‹…å°
- **RDRä¿æŒç¨³å®š** â†’ åœ¨å¢å¼ºç¨³å®šæ€§çš„åŒæ—¶æœªç‰ºç‰²ç”Ÿæˆå¤šæ ·æ€§

---

### ğŸ” æ¶ˆèåˆ†æä¸å®šæ€§ç»“æœ
è™½ç„¶æ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèå®éªŒè¡¨æ ¼ï¼Œä½†ä»æœºåˆ¶è®¾è®¡ä¸è®¨è®ºä¸­å¯æ¨æ–­å…³é”®å‘ç°ï¼š

#### âœ… æœ‰æ•ˆæ€§éªŒè¯ï¼ˆQualitative Analysisï¼‰ï¼š
- **åŒ»ç–—é—®ç­”ç¤ºä¾‹**ï¼š
  - SFTæ¨¡å‹é”™è¯¯å£°ç§°â€œæŠ—ç”Ÿç´ å¯æ²»ç–—æµæ„Ÿç—…æ¯’â€
  - RLHFæ¨¡å‹æ¨¡ç³Šå›åº”â€œæœ‰æ—¶å¯ç”¨äºæ²»ç–—â€
  - **æœ¬æ–‡æ–¹æ³•æ­£ç¡®æŒ‡å‡ºï¼šâ€œæŠ—ç”Ÿç´ åªæ²»ç»†èŒæ„ŸæŸ“ï¼Œä»…å½“ç»§å‘ç»†èŒæ„ŸæŸ“æ—¶æ‰ä½¿ç”¨â€**
- **æ•°å­¦æ¨ç†ä»»åŠ¡**ï¼š
  - åŸºçº¿æ¨¡å‹å¯¹ç­‰ä»·æ•°å­¦é¢˜ç»™å‡ºä¸åŒç­”æ¡ˆ
  - ç¨³å®šåŒ–æ¨¡å‹å§‹ç»ˆè¿”å›ä¸€è‡´è§£ï¼Œå¹¶é™„æ¸…æ™°æ¨ç†é“¾

#### è®¾è®¡ä¼˜åŠ¿åˆ†æï¼š
| è®¾è®¡è¦ç´  | æ•ˆæœ |
|--------|------|
| è‡ªåŠ¨åŒ–å¤§è§„æ¨¡æ ‡æ³¨ | å¿«é€Ÿè¯†åˆ«ä¸ç¨³å®šæ¨¡å¼ |
| äººç±»èšç„¦äºæ¨¡ç³Š/é«˜é£é™©æ¡ˆä¾‹ | é¿å…ç›²ç›®ä¿¡ä»»AIåˆ¤æ–­ |
| ç¨³å®šæ€§åé¦ˆå¾ªç¯ | å®ç°è¡Œä¸ºæŒç»­å¼ºåŒ– |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **ç¨³å®šæ€§å¯ä»¥è¢«é‡åŒ–å¹¶ä½œä¸ºç‹¬ç«‹ä¼˜åŒ–ç›®æ ‡**ï¼Œä¸åº”åªæ˜¯å¯¹é½çš„å‰¯äº§å“ã€‚
2. **AIé©±åŠ¨çš„æ ‡æ³¨æµæ°´çº¿+é€‰æ‹©æ€§äººç±»éªŒè¯** æ˜¯å®ç°LLMç¨³å®šåŒ–çš„é«˜æ•ˆè·¯å¾„ã€‚
3. è¯¥æ–¹æ³•åœ¨**å¤šè½®å¯¹è¯ã€äº‹å®é—®ç­”ã€å¤æ‚æ¨ç†**åœºæ™¯ä¸­å‡æ˜¾è‘—æå‡äº†è¾“å‡ºä¸€è‡´æ€§ä¸äº‹å®å‡†ç¡®æ€§ã€‚
4. **äººæœºååŒï¼ˆHuman-AI Collaborationï¼‰** åœ¨ä¿è¯å¯é æ€§çš„åŒæ—¶å®ç°äº†å¯æ‰©å±•æ€§ï¼Œä¼˜äºçº¯äººå·¥æˆ–çº¯AIæ–¹æ¡ˆã€‚

---

### âš ï¸ å±€é™æ€§
1. **è‡ªåŠ¨åŒ–æ ‡æ³¨å™¨ä¾èµ–å¯å‘å¼è§„åˆ™ä¸è®­ç»ƒæ•°æ®è´¨é‡**ï¼Œåœ¨ç¼ºä¹ground truthçš„çŸ¥è¯†é¢†åŸŸå¯èƒ½è¯¯åˆ¤éå¸¸è§„åˆç†æ¨ç†ã€‚
2. **äººç±»éªŒè¯å­˜åœ¨ä¸»è§‚åå·®é£é™©**ï¼Œå°¤å…¶åœ¨é€»è¾‘ä¸¥è°¨æ€§åˆ¤æ–­ä¸Šå—ä¸“ä¸šçŸ¥è¯†å½±å“ã€‚
3. æ–¹æ³•åœ¨**å¿«é€Ÿæ¼”è¿›çš„ä¸“ä¸šé¢†åŸŸ**ï¼ˆå¦‚ç”Ÿç‰©åŒ»è¯ï¼‰æ³›åŒ–èƒ½åŠ›æœ‰å¾…éªŒè¯ï¼Œéœ€åŠ¨æ€æ›´æ–°çŸ¥è¯†åº“ã€‚
4. å­˜åœ¨**é”™è¯¯ä¼ æ’­é£é™©**ï¼šè‹¥è‡ªåŠ¨åŒ–é˜¶æ®µé”™è¯¯æœªè¢«å‘ç°ï¼Œå¯èƒ½é€šè¿‡å†è®­ç»ƒâ€œç—…æ¯’å¼æ‰©æ•£â€ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. å¼€å‘å…·å¤‡**è‡ªæˆ‘è§£é‡Šèƒ½åŠ›çš„è‡ªåŠ¨æ ‡æ³¨ä»£ç†ï¼ˆannotator agentsï¼‰**ï¼Œèƒ½è¯´æ˜å…¶åˆ¤æ–­ä¾æ®ï¼Œä¾¿äºäººç±»å¿«é€ŸéªŒè¯ã€‚
2. æ¢ç´¢**å¤šæ¨¡å‹äº’è¯„æœºåˆ¶ï¼ˆmulti-model ensemblesï¼‰**ï¼Œè®©ä¸åŒLLMç›¸äº’å®¡æŸ¥ï¼Œæå‡è·¨æ¨¡å‹ç¨³å®šæ€§ã€‚
3. æ„å»º**ç»ˆèº«å­¦ä¹ ï¼ˆlifelong learningï¼‰ç³»ç»Ÿ**ï¼Œå®ç°å®æ—¶è¿è¡Œä¸­çš„ç¨³å®šæ€§ç›‘æµ‹ä¸ä¸»åŠ¨ä¿®æ­£ã€‚
4. åŠ å¼ºé€æ˜æ€§å·¥å…·ä¸å¯è§£é‡Šæ€§ç»“æ„ï¼Œæ”¯æŒå¯¹ç³»ç»Ÿæ€§å˜åŒ–çš„å®¡è®¡ä¸æ²»ç†ã€‚

---

## âœ… æ€»ç»“
æœ¬æ–‡æå‡ºäº†ä¸€ç§é¢å‘**LLMç¨³å®šæ€§å¢å¼º**çš„æ–°å‹ **AI-Powered Annotation Pipeline**ï¼Œé€šè¿‡**è‡ªåŠ¨åŒ–æ£€æµ‹ + é€‰æ‹©æ€§äººç±»éªŒè¯ + è¿­ä»£åé¦ˆæœºåˆ¶**ï¼Œå®ç°äº†é«˜ä¿çœŸã€å¯æ‰©å±•çš„æ¨¡å‹ç¨³å®šåŒ–ã€‚å®éªŒè¯æ˜å…¶åœ¨é™ä½è¾“å‡ºæ–¹å·®ã€æå‡äº‹å®ä¸€è‡´æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºSFTä¸RLHFåŸºçº¿ï¼ŒåŒæ—¶ä¿ç•™äº†ç”Ÿæˆå¤šæ ·æ€§ã€‚è¯¥å·¥ä½œæ¨åŠ¨äº†å°†â€œç¨³å®šæ€§â€ä»éšæ€§éœ€æ±‚è½¬å˜ä¸º**å¯æµ‹é‡ã€å¯æŒç»­ä¼˜åŒ–çš„æ ¸å¿ƒå±æ€§**ï¼Œä¸ºä¸‹ä¸€ä»£å¯ä¿¡LLMæä¾›äº†å¯è¡Œçš„æŠ€æœ¯èŒƒå¼ã€‚

</details>

---

### 12. [Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents](https://arxiv.org/abs/2512.14142)

**Authors**: Hongqiu Ni, Jiabao Zhang, Guopeng Li, Zilong Wang, Ruiqi Wu, Chi Zhang, Haisheng Tan  
**Category**: cs.CL  
**Published**: 2025-12-17  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.14142v1  

#### Abstract
Large Language Models (LLMs) are increasingly being deployed as intelligent agents. Their multi-stage workflows, which alternate between local computation and calls to external network services like Web APIs, introduce a mismatch in their execution pattern and the scheduling granularity of existing ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAstraea: A State-Aware Scheduling Engine for LLM-Powered Agents

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ç°æœ‰çš„ **LLM æ¨ç†æœåŠ¡ç³»ç»Ÿ**ï¼ˆå¦‚ vLLMï¼‰ä¸»è¦é’ˆå¯¹ä¼ ç»Ÿçš„â€œä¸€æ¬¡æ€§â€æ¨ç†ä»»åŠ¡è¿›è¡Œä¼˜åŒ–ï¼Œå…¶è°ƒåº¦ç­–ç•¥é€šå¸¸ä»¥å•ä¸ªè®¡ç®—é˜¶æ®µï¼ˆå¦‚ Prefill æˆ– Decodeï¼‰ä¸ºå•ä½ï¼Œå¿½ç•¥äº† **LLM Agent å¤šé˜¶æ®µã€äº¤æ›¿æ‰§è¡Œè®¡ç®—ä¸ I/O çš„å¤æ‚å·¥ä½œæµç‰¹æ€§**ã€‚

è¿™å¯¼è‡´ä¸¤ä¸ªå…³é”®é—®é¢˜ï¼š
- **Head-of-Line (HoL) é˜»å¡**ï¼šé•¿æ—¶ API è°ƒç”¨æœŸé—´ï¼Œè¯·æ±‚å ç”¨ GPU å†…å­˜ï¼Œé˜»å¡å…¶ä»–è¯·æ±‚ã€‚
- **å±€éƒ¨ä¼˜åŒ– vs å…¨å±€å»¶è¿Ÿ**ï¼šç³»ç»Ÿåªä¼˜åŒ–å½“å‰æ®µçš„å“åº”æ—¶é—´ï¼Œè€Œå¿½è§†äº†æ•´ä¸ªè¯·æ±‚ç”Ÿå‘½å‘¨æœŸçš„ **Job Completion Time (JCT)**ï¼Œé€ æˆå…¨å±€æ€§èƒ½ä¸‹é™ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **Astraea** â€”â€” ä¸€ç§é¢å‘ LLM Agent å·¥ä½œæµçš„ã€ç”Ÿå‘½å‘¨æœŸæ„ŸçŸ¥çš„æ¨ç†æœåŠ¡å¼•æ“ï¼Œå…¶æ ¸å¿ƒæ˜¯ **Stateful-MLFQ** è°ƒåº¦ç®—æ³•ï¼Œå…·å¤‡ä»¥ä¸‹åˆ›æ–°è®¾è®¡ï¼š

#### âœ… **çŠ¶æ€æ„ŸçŸ¥çš„åˆ†å±‚è°ƒåº¦æœºåˆ¶ï¼ˆStateful-MLFQï¼‰**
- **å®è§‚æ§åˆ¶ï¼ˆMacro-levelï¼‰**ï¼šåŸºäºè¯·æ±‚çš„å†å²è¡Œä¸ºåŠ¨æ€è°ƒæ•´ä¼˜å…ˆçº§é˜Ÿåˆ—ã€‚
  - è‹¥æŸæ®µè®¡ç®—å¼€é”€å¤§ â†’ åˆ¤å®šä¸º **Compute-intensive** â†’ é™çº§åˆ°ä½ä¼˜å…ˆçº§é˜Ÿåˆ—ã€‚
  - è‹¥æå‰è§¦å‘ API è°ƒç”¨ â†’ åˆ¤å®šä¸º **I/O-intensive** â†’ å‡çº§åˆ°é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡ã€‚
- **å¾®è§‚æ’åºï¼ˆMicro-levelï¼‰**ï¼šåœ¨æ¯ä¸ªé˜Ÿåˆ—å†…éƒ¨é‡‡ç”¨ **HRRNï¼ˆHighest Response Ratio Nextï¼‰** ç­–ç•¥å¯¹å°±ç»ªæ®µæ’åºï¼Œå¹³è¡¡æ•ˆç‡ä¸å…¬å¹³æ€§ï¼š
  $$
  \text{Score}_{\text{HRRN}}(S) = \frac{W(R) + T_{\text{proc}}(S)}{T_{\text{proc}}(S)}
  $$
  å…¶ä¸­ $W(R)$ æ˜¯çˆ¶è¯·æ±‚ç´¯ç§¯ç­‰å¾…æ—¶é—´ï¼Œ$T_{\text{proc}}(S)$ æ˜¯é¢„æµ‹å¤„ç†æ—¶é—´ã€‚

#### âœ… **è‡ªé€‚åº” KV Cache ç®¡ç†**
- åœ¨ I/O ç­‰å¾…æœŸé—´ï¼Œæ ¹æ® GPU å†…å­˜å‹åŠ›åŠ¨æ€é€‰æ‹©ç¼“å­˜ç­–ç•¥ï¼š
  - **ä½è´Ÿè½½**ï¼šé‡‡ç”¨ `Preserve` ç­–ç•¥ï¼Œä¿ç•™ KV Cache äº GPUï¼Œé™ä½æ¢å¤å»¶è¿Ÿã€‚
  - **é«˜è´Ÿè½½**ï¼šè¯„ä¼°ä¸‰ç§ç­–ç•¥ï¼ˆPreserve / Discard / Swapï¼‰çš„å†…å­˜æµªè´¹æˆæœ¬ï¼Œé€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆï¼š
    $$
    \text{Strategy} = \arg\min_{s \in \{\text{Preserve}, \text{Discard}, \text{Swap}\}} W_s
    $$

#### âœ… **æœåŠ¡æ—¶é—´é¢„æµ‹å™¨ï¼ˆService Time Predictorï¼‰**
- ç»“åˆç¦»çº¿æ€§èƒ½å»ºæ¨¡ï¼ˆPrefillï¼‰ã€ç”Ÿæˆé•¿åº¦ Oracleï¼ˆDecodeï¼‰å’Œ API ç±»åˆ«ç»Ÿè®¡ï¼ˆAPI Latencyï¼‰ï¼Œæä¾›å‡†ç¡®çš„æœåŠ¡æ—¶é—´ä¼°è®¡ï¼Œæ”¯æ’‘è°ƒåº¦å†³ç­–ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | Astraea | ç°æœ‰ç³»ç»Ÿï¼ˆå¦‚ vLLMï¼‰ |
|------|--------|---------------------|
| è°ƒåº¦ç²’åº¦ | è¯·æ±‚ç”Ÿå‘½å‘¨æœŸçº§ï¼ˆGlobal JCTï¼‰ | å•æ®µçº§ï¼ˆLocal RTï¼‰ |
| çŠ¶æ€æ„ŸçŸ¥ | âœ… å†å²è¡Œä¸º + æœªæ¥é¢„æµ‹ | âŒ æ— çŠ¶æ€è°ƒåº¦ |
| I/O å½±å“å¤„ç† | æ˜¾å¼å»ºæ¨¡å¹¶ä¼˜å…ˆå¤„ç† I/O å¯†é›†å‹è¯·æ±‚ | å¿½è§† API æ—¶é—´ï¼Œæ˜“å¼•å‘ HoL é˜»å¡ |
| ç¼“å­˜ç®¡ç† | è‡ªé€‚åº”ç­–ç•¥ï¼Œæƒè¡¡å»¶è¿Ÿä¸åå | å›ºå®šç­–ç•¥ï¼ˆå¦‚ Always Preserveï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

åŸºäº **Infercept** å‘å¸ƒçš„æ•°æ®é›†æ„å»ºï¼ŒåŒ…å«å…­ç±»ä»»åŠ¡ï¼Œæ¨¡æ‹ŸçœŸå® LLM Agent åœºæ™¯ï¼š
1. **Arithmetic Operations**ï¼ˆåŸºäº GSM8K-XLï¼‰
2. **Knowledge Question Answering**ï¼ˆMulti-Hop QAï¼‰
3. **Virtual Environment**ï¼ˆALFWorldï¼‰
4. **Multi-turn Dialogue**ï¼ˆShareGPTï¼‰
5. **Image Generation**ï¼ˆStable Diffusion APIï¼‰
6. **Text-to-Speech**ï¼ˆBark TTS APIï¼‰

> âš ï¸ å®éªŒä¸­äººä¸ºå¢åŠ äº†é•¿å»¶è¿Ÿ API è¯·æ±‚çš„æ¯”ä¾‹ï¼Œä»¥å¢å¼ºæµ‹è¯•æŒ‘æˆ˜æ€§ã€‚

### **å®éªŒè®¾ç½®**

- **ç¡¬ä»¶å¹³å°**ï¼šåŒ NVIDIA A100 80GB GPUï¼ˆNVLink è¿æ¥ï¼‰ï¼ŒIntel Xeon Gold CPUï¼Œ503GB RAMã€‚
- **æ¨¡å‹è§„æ¨¡**ï¼š
  - **GPT-J-6B**ï¼ˆå•å¡è¿è¡Œï¼Œä¸­ç­‰è´Ÿè½½ï¼‰
  - **Vicuna-13B**ï¼ˆåŒå¡è¿è¡Œï¼Œé«˜å‹å†…å­˜åœºæ™¯ï¼‰
- **å®ç°åŸºç¡€**ï¼šåŸºäº **vLLM** æ¡†æ¶æ‰©å±•ï¼Œé›†æˆ PagedAttention å’Œè¿ç»­æ‰¹å¤„ç†ï¼ˆcontinuous batchingï¼‰èƒ½åŠ›ã€‚

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Average JCT**ï¼ˆJob Completion Timeï¼‰ | ä¸»è¦æŒ‡æ ‡ï¼Œè¡¡é‡ä»è¯·æ±‚æäº¤åˆ°æœ€ç»ˆå®Œæˆçš„ç«¯åˆ°ç«¯å»¶è¿Ÿ |
| TTFTï¼ˆTime to First Tokenï¼‰ | è¾…åŠ©æŒ‡æ ‡ï¼Œéæ ¸å¿ƒå…³æ³¨ |
| TPOTï¼ˆTime Per Output Tokenï¼‰ | è¾…åŠ©æŒ‡æ ‡ï¼Œéæ ¸å¿ƒå…³æ³¨ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

1. **vLLM + FCFS**ï¼šå…ˆæ¥å…ˆæœåŠ¡
2. **vLLM + SJF**ï¼ˆShortest Job Firstï¼‰ï¼šæŒ‰æ®µé•¿åº¦æœ€çŸ­ä¼˜å…ˆ
3. **vLLM + LAS**ï¼ˆLeast Attained Serviceï¼‰ï¼šç´¯è®¡æœåŠ¡æœ€å°‘è€…ä¼˜å…ˆï¼ˆAutellix é‡‡ç”¨ï¼‰
4. **Infercept**ï¼šæ”¯æŒ KV Cache Offload çš„å…ˆè¿›ç³»ç»Ÿï¼Œé»˜è®¤ FCFS

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **åœ¨ GPT-J-6B ä¸Šçš„è¡¨ç°ï¼ˆå›¾4ï¼‰**
- åœ¨ **30% GPU å†…å­˜å¯ç”¨ç‡ã€QPS=5** çš„é«˜å‹åœºæ™¯ä¸‹ï¼š
  - Astraea å¹³å‡ JCTï¼š**122.88 ç§’**
  - æ¯” Infercept é™ä½ **19.1%**
  - æ¯” vLLM-FCFS é™ä½ **25.5%**

#### âœ… **åœ¨ Vicuna-13B ä¸Šçš„è¡¨ç°ï¼ˆå›¾5ï¼‰**
- åœ¨ç›¸åŒæ¡ä»¶ä¸‹ï¼ˆ30% å†…å­˜ï¼ŒQPS=5ï¼‰ï¼š
  - Astraea JCTï¼š**140.02 ç§’**
  - æ¯” vLLM-SJFï¼ˆ171.16sï¼‰é™ä½ **18.2%**
  - æ¯” vLLM-LASï¼ˆ153.96sï¼‰é™ä½ **9.1%**
- å³ä½¿åœ¨ **90% å†…å­˜å¯ç”¨ç‡** ä¸‹ï¼Œä»æ¯” vLLM-FCFS ä½ **16.0%**

> ğŸ“ˆ æ€»ä½“è¶‹åŠ¿ï¼š**å†…å­˜è¶Šç´§å¼ ã€è´Ÿè½½è¶Šé«˜ï¼ŒAstraea çš„ä¼˜åŠ¿è¶Šæ˜¾è‘—**ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| æ–¹æ³• | ç›¸å¯¹ Astraea çš„ JCT æå‡å¹…åº¦ï¼ˆå…¸å‹é«˜å‹åœºæ™¯ï¼‰ |
|------|---------------------------------------------|
| vLLM-FCFS | +25.5% ~ +30% |
| vLLM-SJF | +18% ~ +22% |
| vLLM-LAS | +9% ~ +12% |
| Infercept | +15% ~ +19% |

> Astraea åœ¨æ‰€æœ‰é…ç½®ä¸‹å‡å–å¾—æœ€ä¼˜æ€§èƒ½ï¼Œå°¤å…¶åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹è¡¨ç°ç¨³å®šã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

åœ¨å›ºå®š QPS=3 æ¡ä»¶ä¸‹ï¼Œå‰¥ç¦» KV Cache ç®¡ç†å½±å“ï¼Œä»…æ¯”è¾ƒè°ƒåº¦ç®—æ³•ï¼ˆå›¾6ï¼‰ï¼š

| æ¨¡å‹ | è°ƒåº¦å™¨ | ç›¸å¯¹ Stateful-MLFQ çš„ JCT å¢åŠ  |
|------|--------|-------------------------------|
| GPT-J | FCFS | +2.3% |
| GPT-J | SJF | +19.3% |
| Vicuna-13B | FCFS | +2.5% |
| Vicuna-13B | LAS | +3.8% |
| Vicuna-13B | SJF | +11.0% |

> ğŸ” ç»“è®ºï¼š**Stateful-MLFQ æœ¬èº«å³å¸¦æ¥æ˜¾è‘—æ”¶ç›Š**ï¼Œè¯æ˜å…¶è°ƒåº¦é€»è¾‘çš„æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **ä¼ ç»Ÿè°ƒåº¦ç­–ç•¥ä¸é€‚ç”¨äº LLM Agent å·¥ä½œæµ**ï¼šå¿½ç•¥ I/O æ—¶é—´å’Œè¯·æ±‚ä¾èµ–å…³ç³»ä¼šå¯¼è‡´ä¸¥é‡çš„ HoL é˜»å¡å’Œå…¨å±€å»¶è¿Ÿä¸Šå‡ã€‚
2. **ç”Ÿå‘½å‘¨æœŸæ„ŸçŸ¥è°ƒåº¦è‡³å…³é‡è¦**ï¼šå°†è°ƒåº¦è§†è§’ä»â€œæ®µâ€æå‡åˆ°â€œå®Œæ•´è¯·æ±‚â€ï¼Œæ‰èƒ½æœ‰æ•ˆä¼˜åŒ– **JCT**ã€‚
3. **çŠ¶æ€æ„ŸçŸ¥ + é¢„æµ‹é©±åŠ¨çš„è°ƒåº¦ä¼˜äºçº¯å†å²æˆ–é™æ€ç­–ç•¥**ï¼šç»“åˆå†å²è¡Œä¸ºåˆ†ç±»ä¸æœªæ¥é¢„æµ‹æ’åºï¼ˆHRRNï¼‰ï¼Œå®ç°äº†æ•ˆç‡ä¸å…¬å¹³çš„å¹³è¡¡ã€‚
4. **è‡ªé€‚åº” KV Cache ç®¡ç†æå‡äº†èµ„æºåˆ©ç”¨ç‡**ï¼šåœ¨é«˜è´Ÿè½½ä¸‹é€šè¿‡ Swap/Discard å‡å°‘å†…å­˜æµªè´¹ï¼Œç»´æŒç³»ç»Ÿååã€‚
5. **Astraea å…·å¤‡å¼ºé²æ£’æ€§**ï¼šåœ¨é«˜è´Ÿè½½ä¸‹ JCT å¢å¹…ä»…ä¸ºåŸºçº¿çš„ **1/3**ï¼ˆAstraea â†‘16.2%ï¼ŒvLLM-SJF â†‘51.9%ï¼‰ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ– API ç±»åˆ«é¢„æµ‹å‡†ç¡®æ€§**ï¼šè‹¥æ— æ³•å‡†ç¡®è¯†åˆ« API ç±»å‹ï¼Œåˆ™å»¶è¿Ÿé¢„æµ‹å¯èƒ½åå·®è¾ƒå¤§ã€‚
2. **æœªè€ƒè™‘å¤šç§Ÿæˆ·å…¬å¹³æ€§**ï¼šå®éªŒèšç„¦å•ç”¨æˆ·åœºæ™¯ï¼Œæœªæ·±å…¥æ¢è®¨ä¸åŒç”¨æˆ·é—´çš„èµ„æºåˆ†é…å…¬å¹³é—®é¢˜ã€‚
3. **å‡è®¾æ‰¹å¤„ç†å¯ä¸­æ–­**ï¼šè™½ç„¶é¿å…äº†ç»†ç²’åº¦æŠ¢å ï¼Œä½†åœ¨æç«¯æƒ…å†µä¸‹ä»å¯èƒ½å­˜åœ¨è°ƒåº¦å»¶è¿Ÿã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. å¼•å…¥æ›´ç²¾ç»†çš„ **API å»¶è¿Ÿé¢„æµ‹æ¨¡å‹**ï¼ˆå¦‚åŸºäºä¸Šä¸‹æ–‡è¯­ä¹‰åˆ†æï¼‰ã€‚
2. æ‰©å±•è‡³ **å¤šç§Ÿæˆ·ã€å¤šæ¨¡å‹å…±å­˜ç¯å¢ƒ**ï¼Œç ”ç©¶è·¨è¯·æ±‚å…¬å¹³æ€§ä¿éšœæœºåˆ¶ã€‚
3. æ¢ç´¢ **ä¸ disaggregation æ¶æ„ç»“åˆ**ï¼ˆå¦‚ DistServeï¼‰ï¼Œè¿›ä¸€æ­¥è§£è€¦ Prefill ä¸ Decode é˜¶æ®µã€‚
4. å°†è°ƒåº¦å†³ç­–ä¸ **æ¨¡å‹å¹¶è¡Œã€æµæ°´çº¿å¹¶è¡Œ** ç­‰åˆ†å¸ƒå¼æŠ€æœ¯ååŒä¼˜åŒ–ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> Astraea é¦–æ¬¡æå‡ºå°† LLM Agent çš„è°ƒåº¦ä»â€œæ®µçº§ä¼˜åŒ–â€è½¬å‘â€œç”Ÿå‘½å‘¨æœŸçº§ä¼˜åŒ–â€ï¼Œé€šè¿‡ **Stateful-MLFQ + è‡ªé€‚åº” KV Cache ç®¡ç†**ï¼Œæ˜¾è‘—é™ä½äº†ç«¯åˆ°ç«¯å»¶è¿Ÿï¼Œåœ¨å¤šç§æ¨¡å‹å’Œè´Ÿè½½ä¸‹å¹³å‡ JCT æœ€å¤šå‡å°‘ **25.5%**ï¼Œä¸ºä¸‹ä¸€ä»£æ™ºèƒ½ä»£ç†æœåŠ¡ç³»ç»Ÿæä¾›äº†é‡è¦èŒƒå¼ã€‚

</details>

---

### 13. [Delete and Retain: Efficient Unlearning for Document Classification](https://arxiv.org/abs/2512.13711)

**Authors**: Aadya Goel, Mayuri Sridhar  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.13711v1  

#### Abstract
Machine unlearning aims to efficiently remove the influence of specific training data from a model without full retraining. While much progress has been made in unlearning for LLMs, document classification models remain relatively understudied. In this paper, we study class-level unlearning for docu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šDelete and Retain: Efficient Unlearning for Document Classification**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
è¯¥è®ºæ–‡ç ”ç©¶çš„æ˜¯**class-level unlearning**ï¼ˆç±»åˆ«çº§é—å¿˜ï¼‰åœ¨**document classification**ï¼ˆæ–‡æ¡£åˆ†ç±»ï¼‰æ¨¡å‹ä¸­çš„åº”ç”¨ã€‚å…·ä½“è€Œè¨€ï¼Œå½“ä¸€ä¸ªè®­ç»ƒç±»åˆ«ï¼ˆå¦‚æ•æ„Ÿæ ‡ç­¾ï¼‰éœ€è¦è¢«å®Œå…¨ä»å·²è®­ç»ƒçš„æ¨¡å‹ä¸­â€œé—å¿˜â€æ—¶ï¼Œå¦‚ä½•é«˜æ•ˆåœ°ç§»é™¤è¯¥ç±»åˆ«çš„å½±å“ï¼ŒåŒæ—¶ä¿ç•™å¯¹å…¶ä»–ç±»åˆ«çš„é¢„æµ‹èƒ½åŠ›ã€‚

ä¼ ç»Ÿåšæ³•æ˜¯**retraining from scratch**ï¼ˆä»å¤´é‡æ–°è®­ç»ƒï¼‰ï¼Œä½†è¿™åœ¨è®¡ç®—ä¸Šä»£ä»·é«˜æ˜‚ã€‚è€Œç°æœ‰çš„**machine unlearning**æ–¹æ³•å¤šé›†ä¸­äºåˆ é™¤å•ä¸ªæ ·æœ¬æˆ–å°æ‰¹é‡æ•°æ®ï¼Œåœ¨å¤„ç†æ•´ä¸ªç±»åˆ«åˆ é™¤æ—¶å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- å¿½è§†äº†æ¨¡å‹åœ¨å‰©ä½™ç±»åˆ«é—´çš„**score ordering**ï¼ˆå¾—åˆ†æ’åºï¼‰ç»“æ„ï¼›
- å¸¸ç”¨çš„â€œRandom Relabelingâ€ç­–ç•¥ä¼šå¼•å…¥å¤§é‡å™ªå£°ï¼ŒæŸå®³æ¨¡å‹æ•ˆç”¨ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Hessian Reassignment** çš„ä¸¤æ­¥ã€model-agnostic çš„ unlearning æ–¹æ³•ï¼š

1. **Hessian Downweight Update**  
   åˆ©ç”¨äºŒé˜¶ä¼˜åŒ–ä¿¡æ¯ï¼ˆHessian-vector productï¼‰ï¼Œé€šè¿‡å…±è½­æ¢¯åº¦æ³•æ±‚è§£ä¸€ä¸ªç±»çº§åˆ«çš„â€œä¸‹æƒé‡â€æ›´æ–°ï¼Œä¸€æ¬¡æ€§å‡å»ç›®æ ‡ç±»åˆ«æ‰€æœ‰æ ·æœ¬å¯¹æ¨¡å‹å‚æ•°çš„å½±å“ã€‚è¿™ç›¸å½“äºä¸€ä¸ªè¿‘ä¼¼çš„ç‰›é¡¿æ­¥é•¿ï¼Œæ— éœ€å®Œæ•´é‡è®­ç»ƒã€‚

2. **Top-1 Classification Reassignment**  
   å¯¹äºåŸå±äºè¢«åˆ é™¤ç±»åˆ«çš„æ ·æœ¬ï¼Œä¸æ˜¯éšæœºé‡æ–°åˆ†é…æ ‡ç­¾ï¼Œè€Œæ˜¯å°†å…¶ç¡®å®šæ€§åœ°é‡æ–°åˆ†é…ä¸ºæ¨¡å‹åœ¨åˆ é™¤å‰é¢„æµ‹çš„**æ¬¡é«˜æ¦‚ç‡ç±»åˆ«**ï¼ˆnext top-1 labelï¼‰ã€‚è¿™ç§æ–¹æ³•ä¿ç•™äº†æ¨¡å‹åŸæœ‰çš„å†³ç­–ç©ºé—´ç»“æ„ã€‚

æ­¤å¤–ï¼Œåœ¨éƒ¨ç½²æ—¶å°†è¢«åˆ é™¤ç±»åˆ«çš„è¾“å‡ºé€šé“ç½®é›¶å¹¶é‡æ–°å½’ä¸€åŒ–æ¦‚ç‡ï¼Œç¡®ä¿æ¨¡å‹ä¸å†è¾“å‡ºè¯¥ç±»åˆ«ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- âœ… **é«˜æ•ˆæ€§**ï¼šç›¸æ¯” full retraining åŠ é€Ÿæ•°åå€ï¼ˆå®éªŒä¸­å¿«çº¦10å€ä»¥ä¸Šï¼‰ï¼›
- âœ… **é«˜ä¿çœŸåº¦**ï¼šåœ¨ä¿ç•™ç±»ä¸Šçš„å‡†ç¡®ç‡æ¥è¿‘â€œGolden Standardâ€ï¼ˆå³ä»å¤´é‡è®­ç»ƒï¼‰ï¼›
- âœ… **éšç§ä¿æŠ¤æ›´å¼º**ï¼šæ˜¾è‘—é™ä½é’ˆå¯¹åˆ é™¤ç±»çš„ **Membership Inference Attack (MIA)** æˆåŠŸç‡ï¼ˆAUC æ¥è¿‘ 0.5ï¼‰ï¼›
- âœ… **ç»“æ„ä¿æŒ**ï¼šé¿å… Random Relabeling å¼•å…¥çš„æ ‡ç­¾å™ªå£°ï¼Œç»´æŒäº†æ¨¡å‹åœ¨éç›®æ ‡ç±»åˆ«é—´çš„ç›¸å¯¹æ’åºä¸€è‡´æ€§ã€‚

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
åœ¨ä¸‰ä¸ªæ ‡å‡†æ–‡æœ¬åˆ†ç±» benchmark ä¸Šè¿›è¡Œè¯„ä¼°ï¼š
- **20 Newsgroups**ï¼š20 ä¸ªä¸»é¢˜ï¼Œä¸­ç­‰é•¿åº¦æ–‡æ¡£ï¼ŒæŒ‘æˆ˜ç»†ç²’åº¦è¾¹ç•Œä¿æŒï¼›
- **AG News**ï¼š4 ä¸ªæ–°é—»ç±»åˆ«ï¼Œè¯­ä¹‰å·®å¼‚å¤§ï¼Œæµ‹è¯•ç²—ç²’åº¦åœºæ™¯ä¸‹çš„ç¨³å®šæ€§ï¼›
- **DBPedia-14**ï¼š14 ç±»ç»´åŸºç™¾ç§‘æ‘˜è¦ï¼Œç»“æ„æ¸…æ™°ï¼Œé«˜å‡†ç¡®ç‡åŸºçº¿ã€‚

---

### **å®éªŒè®¾ç½®**
- **æ¨¡å‹æ¶æ„**ï¼šåŸºäº **TF-IDF ç‰¹å¾ + multinomial logistic regression**ï¼ˆå¸¦ L2 æ­£åˆ™åŒ–çš„çº¿æ€§ softmax åˆ†ç±»å™¨ï¼‰ï¼›
- **è®­ç»ƒæ–¹å¼**ï¼šä½¿ç”¨ L-BFGS ä¼˜åŒ–è‡³æ”¶æ•›ï¼ˆæ¢¯åº¦å®¹å¿åº¦ $10^{-5}$ï¼Œæ­£åˆ™å¼ºåº¦ $C=10.0$ï¼‰ï¼›
- **unlearning æµç¨‹**ï¼š
  - è®¡ç®—è¢«åˆ ç±»åˆ«çš„æ¢¯åº¦æ€»å’Œ $g_c(\theta)$ï¼›
  - ä½¿ç”¨å…±è½­æ¢¯åº¦æ³•æ±‚è§£ $\Delta \theta = H^{-1} g_c$ï¼›
  - æ›´æ–°å‚æ•° $\theta' = \theta - \Delta \theta$ï¼›
  - é›¶åŒ–å¯¹åº” logit è¾“å‡ºé€šé“ã€‚

---

### **è¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹æ•ˆç”¨ï¼ˆUtilityï¼‰**
- **Accuracy excluding removed class**ï¼šåœ¨ä¿ç•™ç±»åˆ«ä¸Šçš„æµ‹è¯•å‡†ç¡®ç‡ï¼›
- **Agreement on removed class w.r.t. Golden Standard**ï¼šä¸å®Œå…¨é‡è®­ç»ƒæ¨¡å‹åœ¨åŸåˆ é™¤ç±»æ ·æœ¬ä¸Šçš„é¢„æµ‹ä¸€è‡´æ€§ã€‚

#### **éšç§ä¿æŠ¤ï¼ˆPrivacyï¼‰**
- **Membership Inference Attack (MIA)**ï¼š
  - æ”»å‡»è€…åŸºäº shadow models è®­ç»ƒ logistic regression åˆ†ç±»å™¨ï¼›
  - è¾“å…¥ç‰¹å¾åŒ…æ‹¬é¢„æµ‹æ¦‚ç‡ã€ç†µã€è´Ÿå¯¹æ•°ä¼¼ç„¶ã€top-2 gap ç­‰ï¼›
  - è¾“å‡ºä¸ºæˆå‘˜åˆ¤æ–­åˆ†æ•°ï¼›
  - æŠ¥å‘Šä¸¤ä¸ª AUCï¼š
    - **AUC_ret**ï¼šåœ¨ä¿ç•™ç±»ä¸Šçš„ MIA AUCï¼›
    - **AUC_del**ï¼šåœ¨åˆ é™¤ç±»ä¸Šçš„ MIA AUCï¼ˆç†æƒ³å€¼åº”è¶‹è¿‘ 0.5ï¼‰ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | æè¿° |
|------|------|
| **Golden Standard (Complete Retraining)** | åˆ é™¤è¯¥ç±»åä»å¤´é‡æ–°è®­ç»ƒ â€”â€” â€œé»„é‡‘æ ‡å‡†â€ |
| **Random Relabeling** | å°†åˆ é™¤ç±»æ ·æœ¬éšæœºé‡æ–°åˆ†é…åˆ°å…¶ä½™ç±»åˆ«ï¼Œç„¶åå¾®è°ƒ â€”â€” å½“å‰ SOTA åŸºçº¿ |
| **Hessian Reassignment (Ours)** | Hessian ä¸‹æƒé‡ + Top-1 é‡åˆ†é… |

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **è¡¨1ï¼šæ¨¡å‹æ•ˆç”¨æ¯”è¾ƒï¼ˆä¿ç•™ç±»å‡†ç¡®ç‡ & åˆ é™¤ç±»ä¸€è‡´ç‡ï¼‰**

| Method | 20 Newsgroups | AG News | DBPedia-14 |
|--------|----------------|---------|------------|
| Pre-Unlearning | 93.58% | 92.14% | 98.33% |
| Golden Standard | 93.73% | 95.65% | 98.43% |
| Random Relabeling | 83.45% | 84.58% | 88.46% |
| **Hessian Reassignment** | **93.15%** | **95.04%** | **97.55%** |
| **Unlearned Class Agreement** | **87.77%** | **88.16%** | **90.46%** |

> ğŸ’¡ ç»“è®ºï¼šHessian Reassignment åœ¨ä¿ç•™ç±»å‡†ç¡®ç‡ä¸Šå‡ ä¹ä¸ Golden Standard æŒå¹³ï¼Œè¿œä¼˜äº Random Relabelingï¼›ä¸”åœ¨åˆ é™¤ç±»æ ·æœ¬ä¸Šçš„é¢„æµ‹ä¸é‡è®­ç»ƒé«˜åº¦ä¸€è‡´ï¼ˆ~88â€“90%ï¼‰ã€‚

---

#### **è¡¨2ï¼šMembership Inference AUCï¼ˆè¶Šæ¥è¿‘ 0.5 è¶Šå¥½ï¼‰**

| Method | Group | 20 Newsgroups | AG News | DBPedia |
|--------|-------|----------------|---------|---------|
| Pre-Unlearning | Retain | 0.6635 | 0.5569 | 0.6832 |
|                | Target | 0.6946 | 0.5510 | 0.6794 |
| Random Relabeling | Retain | 0.6346 | 0.5163 | 0.6147 |
|                   | Target | 0.5530 | 0.5181 | 0.5228 |
| **Hessian Reassignment** | Retain | **0.6219** | **0.5235** | **0.6234** |
|                          | **Target** | **0.5109** | **0.5161** | **0.5094** |

> ğŸ’¡ ç»“è®ºï¼šHessian Reassignment æ˜¾è‘—é™ä½äº†åˆ é™¤ç±»çš„ MIA AUCï¼ˆæ¥è¿‘ 0.5ï¼‰ï¼Œè¯´æ˜æˆåŠŸâ€œé—å¿˜â€äº†è¯¥ç±»æˆå‘˜ä¿¡æ¯ï¼ŒåŒæ—¶æœªæ˜æ˜¾å¢åŠ ä¿ç•™ç±»çš„é£é™©ã€‚

---

### **å…¶ä»–é‡è¦ç»“æœ**
- **Confidence Distribution åˆ†æ**ï¼ˆå›¾3ï¼‰ï¼š
  - åœ¨ä¿ç•™ç±»ä¸Šï¼Œunlearning å‰åçš„ top-1 margin åˆ†å¸ƒå‡ ä¹ä¸å˜ï¼ˆKS test $p=1.0$ï¼‰ï¼Œè¡¨æ˜æ¨¡å‹ä¿¡å¿ƒæœªå—å¹²æ‰°ã€‚
- **Noise Trade-off å®éªŒ**ï¼ˆå›¾4ï¼‰ï¼š
  - å³ä½¿ä¸åŠ é¢å¤–å™ªå£°ï¼ŒHessian Reassignment å·²èƒ½å®ç°è‰¯å¥½éšç§ï¼›
  - è‹¥éœ€è¿›ä¸€æ­¥å‹ç¼© AUCï¼Œä»…éœ€æå°çš„ logit å™ªå£°å³å¯è¾¾æ ‡ï¼Œä¸”æ•ˆç”¨æŸå¤±æå°ã€‚
- **è¿è¡Œæ•ˆç‡å¯¹æ¯”**ï¼ˆå›¾5ï¼‰ï¼š
  - åœ¨ DBPedia ä¸Šï¼Œ**full retraining è€—æ—¶ ~602 ç§’**ï¼Œè€Œ **Hessian Reassignment ä»…éœ€ ~53 ç§’**ï¼Œæé€Ÿçº¦ **11 å€**ã€‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **Top-1 reassignment æ˜¯å…³é”®è®¾è®¡**ï¼šç›¸æ¯”äºç ´åæ€§éšæœºé‡æ ‡ï¼Œä¿ç•™æ¨¡å‹åŸæœ‰ score ordering å¯æå¤§æå‡ unlearning åçš„æ•ˆç”¨ã€‚
2. **Hessian downweight æ˜¯æœ‰æ•ˆçš„è¿‘ä¼¼ä¿®æ­£**ï¼šåˆ©ç”¨å±€éƒ¨æ›²ç‡ä¿¡æ¯çš„ä¸€æ¬¡æ€§æ›´æ–°ï¼Œè¶³ä»¥é€¼è¿‘ retraining çš„æ•ˆæœã€‚
3. **Privacy-Utility Balance å‡ºè‰²**ï¼šåœ¨å‡ ä¹ä¸ç‰ºç‰²ä¿ç•™ç±»æ€§èƒ½çš„å‰æä¸‹ï¼Œæœ‰æ•ˆæŠ¹é™¤åˆ é™¤ç±»çš„ membership signalã€‚
4. **æ–¹æ³•é«˜æ•ˆä¸”å¯æ‰©å±•**ï¼šä»…ä¾èµ– gradient å’Œ Hessian-vector productï¼Œé€‚ç”¨äºå¤šç§æ¶æ„ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- å½“å‰å®éªŒé›†ä¸­åœ¨ **linear-softmax + TF-IDF** è¿™ç±»ç®€å• pipelineï¼Œå°šæœªéªŒè¯åœ¨æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆå¦‚ Transformerï¼‰ä¸Šçš„è¡¨ç°ï¼›
- Hessian inversion ä½¿ç”¨å…±è½­æ¢¯åº¦æ³•ï¼Œè™½ç„¶é«˜æ•ˆä½†ä»å‡è®¾ Hessian å¯è¿‘ä¼¼æ±‚é€†ï¼Œåœ¨é«˜åº¦éå‡¸æƒ…å†µä¸‹å¯èƒ½ä¸ç¨³å®šï¼›
- æœªæä¾›ä¸¥æ ¼çš„ç†è®ºä¿è¯ï¼ˆå¦‚å½±å“ä¸Šç•Œï¼‰ï¼Œæ›´å¤šæ˜¯ç»éªŒæ€§æœ‰æ•ˆã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ‰©å±•è‡³ neural models**ï¼šå°† Hessian Reassignment åº”ç”¨äº BERTã€RoBERTa ç­‰ç°ä»£ NLP æ¨¡å‹ï¼›
2. **å¼€å‘ lightweight certificates**ï¼šé‡åŒ– unlearning åæ®‹ä½™å½±å“çš„ç¨‹åº¦ï¼Œè¿ˆå‘å¯è¯æ˜é—å¿˜ï¼ˆprovable unlearningï¼‰ï¼›
3. **æ”¯æŒå¢é‡ unlearning å¤šç±»åˆ«**ï¼šæ¢ç´¢è¿ç»­åˆ é™¤å¤šä¸ªç±»åˆ«çš„ç´¯ç§¯æ•ˆåº”ä¸ä¿®æ­£æœºåˆ¶ï¼›
4. **ç»“åˆ differential privacy**ï¼šä¸ DP æœºåˆ¶èåˆä»¥å¢å¼ºæ•´ä½“éšç§ä¿éšœã€‚

---

## âœ… æ€»ç»“
**Hessian Reassignment** æå‡ºäº†ä¸€æ¡**é«˜æ•ˆã€å®ç”¨ã€å…¼é¡¾æ•ˆç”¨ä¸éšç§**çš„ class-level unlearning è·¯å¾„ã€‚å®ƒé€šè¿‡ **ä¸€æ¬¡äºŒé˜¶æ›´æ–° + ç¡®å®šæ€§é‡åˆ†é…**ï¼Œå®ç°äº†æ¥è¿‘å®Œå…¨é‡è®­ç»ƒçš„æ•ˆæœï¼ŒåŒæ—¶å¤§å¹…ç¼©çŸ­æ—¶é—´æˆæœ¬ï¼Œä¸ºç°å®ç³»ç»Ÿä¸­çš„â€œè¢«é—å¿˜æƒâ€æä¾›äº†å¯è¡Œçš„æŠ€æœ¯æ–¹æ¡ˆã€‚

</details>

---

### 14. [RAST-MoE-RL: A Regime-Aware Spatio-Temporal MoE Framework for Deep Reinforcement Learning in Ride-Hailing](https://arxiv.org/abs/2512.13727)

**Authors**: Yuhan Tang, Kangxin Cui, Jung Ho Park, Yibo Zhao, Xuan Jiang, Haoze He, Dingyi Zhuang, Shenhao Wang, Jiangbo Yu, Haris Koutsopoulos, Jinhua Zhao  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.13727v1  

#### Abstract
Ride-hailing platforms face the challenge of balancing passenger waiting times with overall system efficiency under highly uncertain supply-demand conditions. Adaptive delayed matching creates a trade-off between matching and pickup delays by deciding whether to assign drivers immediately or batch r...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# RAST-MoE-RL: A Regime-Aware Spatio-Temporal MoE Framework for Deep Reinforcement Learning in Ride-Hailing  
**æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
è¯¥è®ºæ–‡é’ˆå¯¹**ç½‘çº¦è½¦å¹³å°ä¸­çš„è‡ªé€‚åº”å»¶è¿ŸåŒ¹é…ï¼ˆadaptive delayed matchingï¼‰å†³ç­–é—®é¢˜**ï¼Œæ—¨åœ¨åœ¨ä¹˜å®¢ç­‰å¾…æ—¶é—´ï¼ˆmatching delayï¼‰ä¸æ¥é©¾æ—¶é—´ï¼ˆpickup delayï¼‰ä¹‹é—´å–å¾—å¹³è¡¡ã€‚ä¼ ç»Ÿæ–¹æ³•é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **äº¤é€šåŠ¨æ€å»ºæ¨¡ä¸å‡†ç¡®**ï¼šå¤šæ•°ç ”ç©¶å‡è®¾é™æ€æ‹¥å µï¼Œæ— æ³•åæ˜ çœŸå®åŸå¸‚ä¸­æ—¶å˜çš„ä¾›éœ€ä¸å¯†åº¦-é€Ÿåº¦åé¦ˆã€‚
- **å¥–åŠ±å‡½æ•°è®¾è®¡è„†å¼±**ï¼šå›ºå®šæƒé‡çš„å¥–åŠ±å®¹æ˜“å¯¼è‡´â€œreward hackingâ€è¡Œä¸ºï¼Œå¦‚æ— é™æœŸæŒæœ‰è¯·æ±‚æˆ–ç«‹å³åŒ¹é…ï¼ŒæŸå®³æœåŠ¡è´¨é‡ã€‚
- **è¡¨ç¤ºèƒ½åŠ›ä¸è¶³**ï¼šæ ‡å‡†RLæ¨¡å‹ï¼ˆå¦‚æµ…å±‚MLPï¼‰éš¾ä»¥æ•æ‰å¤æ‚çš„æ—¶ç©ºæ¨¡å¼ï¼Œå°¤å…¶åœ¨ä¸åŒä¾›éœ€çŠ¶æ€ï¼ˆregimesï¼‰ä¸‹æ³›åŒ–èƒ½åŠ›å·®ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡º **RAST-MoE-RL** æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ˜¯å°† **Regime-Aware Spatio-Temporal Mixture-of-Experts (RAST-MoE)** ç¼–ç å™¨å¼•å…¥æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªæ›´çœŸå®çš„ç¯å¢ƒæ¨¡æ‹Ÿæ¡†æ¶ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š
1. **RAST-MDPï¼ˆRegime-Aware Spatio-Temporal MDPï¼‰å»ºæ¨¡**
   - å°†åŒ¹é…å†³ç­–å½¢å¼åŒ–ä¸ºä¸€ä¸ªå…·æœ‰æ˜¾å¼åŒºåŸŸåŠ¨ä½œç©ºé—´çš„MDPã€‚
   - å¼•å…¥**ç‰©ç†æ„ŸçŸ¥çš„æ‹¥å µä»£ç†æ¨¡å‹ï¼ˆphysics-informed congestion surrogateï¼‰**ï¼ŒåŸºäºå®è§‚åŸºæœ¬å›¾ï¼ˆMFDï¼‰æ„å»ºé«˜æ•ˆçš„ODæ—…è¡Œæ—¶é—´è¡¨ï¼Œä¿ç•™å¯†åº¦-é€Ÿåº¦åé¦ˆï¼Œæ”¯æŒç™¾ä¸‡çº§é«˜æ•ˆrolloutã€‚

2. **æŠ—ä½œå¼Šå¥–åŠ±æœºåˆ¶ï¼ˆAnti-hacking Rewardï¼‰**
   - è®¾è®¡åŠ¨æ€è°ƒæ•´çš„æƒ©ç½šç³»æ•° Î»ï¼Œé€šè¿‡åœ¨çº¿æ›´æ–°æœºåˆ¶å¯¹æœåŠ¡è¿è§„ï¼ˆå¦‚è¶…æ—¶åŒ¹é…ï¼‰æ–½åŠ è‡ªé€‚åº”æƒ©ç½šã€‚
   - é¿å…ç­–ç•¥é€šè¿‡â€œæ‹’ç»è¿œè·ç¦»ä¹˜å®¢â€æˆ–â€œæ°¸è¿œä¸ç­‰å¾…â€ç­‰æ‰‹æ®µæ“çºµå¥–åŠ±ã€‚

3. **RAST-MoE ç¼–ç å™¨æ¶æ„**
   - é‡‡ç”¨**ç¨€ç–æ¿€æ´»çš„MoEç»“æ„**ï¼Œæ¯ä¸ªä¸“å®¶è‡ªåŠ¨ä¸“æ³¨äºç‰¹å®šçš„ä¾›éœ€-æ‹¥å µçŠ¶æ€ï¼ˆå¦‚æ—©é«˜å³°ã€å¤œé—´ä½éœ€æ±‚ï¼‰ã€‚
   - è·¯ç”±å™¨åŸºäºå…¨å±€æ± åŒ–çŠ¶æ€è¿›è¡Œå†³ç­–ï¼Œæå‡è®¡ç®—æ•ˆç‡ä¸ç¨³å®šæ€§ã€‚
   - æ”¯æŒä¸“å®¶è‡ªç„¶ä¸“ä¸šåŒ–ï¼Œå…è®¸é«˜é¢‘ä¸ä½é¢‘ä¸“å®¶å…±å­˜ï¼Œé¿å…å¼ºåˆ¶å‡è¡¡å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **è¡¨è¾¾èƒ½åŠ›** | MoEç»“æ„æ˜¾è‘—å¢å¼ºå¯¹å¤æ‚spatio-temporal patternsçš„å»ºæ¨¡èƒ½åŠ›ï¼Œä¼˜äºMLPã€ResMLPå’ŒDense Transformerã€‚ |
| **è®­ç»ƒç¨³å®šæ€§** | è‡ªé€‚åº”å¥–åŠ±é˜²æ­¢reward hackingï¼›PPOç»“åˆMoEå®ç°ç¨³å®šé•¿å‘¨æœŸè®­ç»ƒã€‚ |
| **è®¡ç®—æ•ˆç‡** | ä»…12Må‚æ•°å³è¶…è¶Šæ›´å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚48M Dense Transformerï¼‰ï¼Œæ¯æ ·æœ¬æ¨ç†æˆæœ¬å¯æ§ã€‚ |
| **æ³›åŒ–èƒ½åŠ›** | åœ¨æœªè§éœ€æ±‚æ¨¡å¼ã€å¤©æ°”æ‰°åŠ¨ã€å±€éƒ¨äº‹æ•…ç­‰OODåœºæ™¯ä¸‹è¡¨ç°ç¨³å¥ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **æ•°æ®æ¥æº**ï¼šåŠ å·å…¬å…±äº‹ä¸šå§”å‘˜ä¼šï¼ˆCPUCï¼‰TNC Data Portal æä¾›çš„ **2019å¹´Uberå’ŒLyftæ—§é‡‘å±±è½¨è¿¹æ•°æ®**ã€‚
- **æ•°æ®ç‰¹ç‚¹**ï¼š
  - æ—¥å‡çº¦17ä¸‡æ¬¡å®Œæˆè¡Œç¨‹ï¼Œä»£è¡¨é«˜å¯†åº¦ã€é«˜æ‹¥å µçš„å…¸å‹åŸå¸‚ç¯å¢ƒã€‚
  - åŒ…å«ä¸Šè½¦/ä¸‹è½¦ä½ç½®ã€æ—¶é—´æˆ³ã€è®¢å•ç»“æœç­‰ã€‚
- **åˆ’åˆ†æ–¹å¼**ï¼š
  - è®­ç»ƒé›†ï¼šå¤šä¸ªéè¿ç»­æ—¶é—´æ®µï¼ˆè¦†ç›–é«˜å³°ä¸å¹³å³°ï¼‰ã€‚
  - æµ‹è¯•é›†ï¼šå®Œå…¨æœªè§è¿‡çš„æ—¶é—´çª—å£ï¼Œç¡®ä¿æ¨¡å‹ä¸èƒ½è®°å¿†å…·ä½“æ¨¡å¼ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **MDPè®¾ç½®**
- **State**ï¼šæŒ‰ç½‘æ ¼åˆ’åˆ†åŸå¸‚ï¼ˆHÃ—W cellsï¼‰ï¼Œæ¯æ ¼åŒ…å«ä¹˜å®¢æ•°ã€å¸æœºæ•°ã€åˆ°è¾¾ç‡ç­‰ã€‚
- **Action**ï¼šäºŒå…ƒå†³ç­– `a_i âˆˆ {0,1}` è¡¨ç¤ºæ˜¯å¦åœ¨åŒºåŸŸiæ‰§è¡Œå³æ—¶åŒ¹é…ï¼ˆâ€œholdâ€ or â€œmatch nowâ€ï¼‰ã€‚
- **Transition**ï¼šåŸºäºMFDä»£ç†æ¨¡å‹è®¡ç®—æ—…è¡Œæ—¶é—´ï¼Œé©±åŠ¨è½¦è¾†ç§»åŠ¨ä¸æ–°è¯·æ±‚ç”Ÿæˆã€‚

#### **è¯„ä¼°æŒ‡æ ‡**
- **æ€»å¥–åŠ±ï¼ˆTotal Rewardï¼‰**
- **å¹³å‡åŒ¹é…å»¶è¿Ÿï¼ˆMatching Delayï¼‰**
- **å¹³å‡æ¥é©¾å»¶è¿Ÿï¼ˆPickup Delayï¼‰**
- **æœåŠ¡è¿è§„æ¯”ä¾‹ï¼ˆService Violationsï¼‰**

#### **è®­ç»ƒé…ç½®**
- ä½¿ç”¨ **PPO** ä½œä¸ºä¸»è®­ç»ƒç®—æ³•ï¼Œå…¼å®¹A2Cã€ACERã€GRPOç­‰ã€‚
- æ‰€æœ‰æ¨¡å‹å…±äº«ç›¸åŒè¶…å‚ï¼ˆè§Appendix Fï¼‰ï¼ŒAdamä¼˜åŒ–å™¨ï¼Œbatch size=512ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ç±»åˆ« | åŸºçº¿æ–¹æ³• |
|------|--------|
| **RL Baselines** | PPO, A2C, ACER, DQN |
| **Encoder Variants** | Plain MLP, ResMLP, Dense Transformer (12M & 48M) |
| **Heuristic Policies** | Instant Matching, Constant-Interval Batch Matching (20s) |
| **MoEå˜ä½“** | ä¸åŒä¸“å®¶æ•°é‡ï¼ˆ8/16/32/64ï¼‰ä¸Top-Kè·¯ç”±ç»„åˆ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**
åœ¨æ—§é‡‘å±±çœŸå®æ•°æ®ä¸Šçš„æœ€ç»ˆæ€§èƒ½ï¼ˆPPO + RAST-MoE, 16ä¸“å®¶, Top-4è·¯ç”±ï¼‰ï¼š

| æŒ‡æ ‡ | æå‡å¹…åº¦ | ç»å¯¹å€¼ |
|------|---------|-------|
| **Total Reward** | â†‘13% | è¾¾åˆ°æœ€é«˜æ°´å¹³ |
| **Matching Delay** | â†“10% | ä» ~200s â†’ **181Â±28s** |
| **Pickup Delay** | â†“15% | ä» ~600s â†’ **524Â±33s** |

> æ³¨ï¼šæ‰€æœ‰æ”¹è¿›å‡åœ¨æµ‹è¯•é›†ä¸ŠéªŒè¯ï¼Œè¡¨æ˜è‰¯å¥½æ³›åŒ–èƒ½åŠ›ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### âœ… æ˜¾è‘—ä¼˜äºå„ç±»åŸºçº¿
- **ä¼˜äºä¼ ç»ŸPPO + MLP/Transformer**ï¼š
  - å³ä½¿å‚æ•°é‡ä»…ä¸º12Mï¼ŒRAST-MoEä»ä¼˜äº48Mçš„Dense Transformerï¼ˆåŒ¹é…å»¶è¿Ÿâ†“10sï¼Œæ¥é©¾å»¶è¿Ÿâ†“20sï¼‰ã€‚
- **ä¼˜äºå¯å‘å¼ç­–ç•¥**ï¼š
  - Instant Matching åŒ¹é…å»¶è¿Ÿè™½ä½ï¼ˆ212sï¼‰ï¼Œä½†æ¥é©¾å»¶è¿Ÿé«˜è¾¾825sã€‚
  - RAST-MoEå®ç°äº†æ›´ä¼˜çš„æƒè¡¡ã€‚

#### âœ… å¤šç§RLç®—æ³•ä¸‹ä¸€è‡´å¢ç›Š
- åœ¨PPOã€A2Cã€ACERã€GRPOç­‰å¤šç§è®­ç»ƒå™¨ä¸Šï¼Œæ›¿æ¢ç¼–ç å™¨ä¸ºRAST-MoEå‡å¸¦æ¥æ€§èƒ½æå‡ï¼Œè¯´æ˜æ”¶ç›Šæ¥è‡ª**è¡¨ç¤ºèƒ½åŠ›å¢å¼º**è€Œéç‰¹å®šä¼˜åŒ–æŠ€å·§ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰**

#### ï¼ˆ1ï¼‰MoEé…ç½®é€‰æ‹©
- æœ€ä½³é…ç½®ä¸º `(E,K)=(16,4)`ï¼ˆ16ä¸ªä¸“å®¶ï¼Œæ¿€æ´»å‰4ä¸ªï¼‰ã€‚
- æ›´å¤§ä¸“å®¶æ± ï¼ˆå¦‚64ä¸“å®¶ï¼‰æˆ–è¿‡åº¦ç¨€ç–è·¯ç”±ï¼ˆå¦‚Top-2ï¼‰åè€Œæ€§èƒ½ä¸‹é™ï¼Œè¯´æ˜å­˜åœ¨**å®¹é‡ä¸åˆ©ç”¨ç‡çš„å¹³è¡¡ç‚¹**ã€‚

#### ï¼ˆ2ï¼‰ç¼–ç å™¨ç±»å‹å¯¹æ¯”ï¼ˆè§Table 2ï¼‰
| ç¼–ç å™¨ | å‚æ•°é‡ | Matching Wait (s) | Pickup Wait (s) |
|--------|--------|-------------------|-----------------|
| RAST-MoE (16,4) | 12M | **182** | **523** |
| Dense Transformer | 48M | 192 | 545 |
| ResMLP | 12M | 205 | 575 |
| Plain MLP | 12M | 208 | 577 |

ğŸ‘‰ ç»“è®ºï¼š**è½»é‡çº§MoE > å¤§å‹å¯†é›†Transformer > å„ç±»MLP**

#### ï¼ˆ3ï¼‰ä¸“å®¶é‡è¦æ€§éªŒè¯ï¼ˆMasking Experimentï¼‰
- åˆ†åˆ«å±è”½**é«˜é¢‘ä¸“å®¶**ï¼ˆæ—¥å¸¸é€šç”¨ï¼‰å’Œ**ä½é¢‘ä¸“å®¶**ï¼ˆå¦‚æ™šé«˜å³°ä¸“ç”¨ï¼‰ï¼š
  - ä¸¤è€…éƒ½å¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼ˆrewardé™ä½ï¼Œå»¶è¿Ÿä¸Šå‡ï¼‰ã€‚
  - è¯æ˜å³ä½¿æ˜¯ä½é¢‘ä¸“å®¶ä¹Ÿæ‰¿è½½å…³é”®çŠ¶æ€ä¸‹çš„æœ‰æ•ˆç­–ç•¥ã€‚

#### ï¼ˆ4ï¼‰è‡ªé€‚åº”å¥–åŠ± vs å›ºå®šæƒé‡
- å›ºå®šæ¯”ä¾‹ï¼ˆå¦‚8:1ï¼‰ä¼šå¯¼è‡´æç«¯è¡Œä¸ºï¼š
  - `8:1`ï¼šåŒ¹é…å»¶è¿Ÿè¶‹è¿‘äº0ï¼Œä½†æ¥é©¾å»¶è¿Ÿé£™å‡è‡³**1746s**ï¼ˆâ‰ˆ29åˆ†é’Ÿï¼‰ã€‚
  - `1:8`ï¼šåŒ¹é…å»¶è¿Ÿé•¿è¾¾**2236s**ï¼ˆâ‰ˆ37åˆ†é’Ÿï¼‰ï¼Œæ— å®é™…æ„ä¹‰ã€‚
- **è‡ªé€‚åº”å¥–åŠ±**åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ä¿æŒç¨³å®štrade-offï¼Œé¿å…reward hackingã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**
1. **Regime-aware representationè‡³å…³é‡è¦**  
   åŸå¸‚äº¤é€šå…·æœ‰æ˜æ˜¾çš„å‘¨æœŸæ€§ä¸éå¹³ç¨³æ€§ï¼ˆæ—©é«˜å³°ã€å¤œé—´ç¨€ç–ç­‰ï¼‰ï¼Œå•ä¸€å•ä½“ç½‘ç»œéš¾ä»¥é€‚åº”ã€‚MoEé€šè¿‡ä¸“å®¶åˆ†å·¥å®ç°äº†å¯¹ä¸åŒregimeçš„æœ‰æ•ˆå»ºæ¨¡ã€‚

2. **è½»é‡MoEå¯èƒœè¿‡å¤§å‹å¯†é›†æ¨¡å‹**  
   ä»…12Må‚æ•°çš„RAST-MoEåœ¨æ€§èƒ½ä¸Šå…¨é¢è¶…è¶Š48Mçš„Dense Transformerï¼Œä½“ç°äº†**ä¸“å®¶ä¸“ä¸šåŒ–å¸¦æ¥çš„é«˜æ•ˆè¡¨ç¤ºå¢ç›Š**ã€‚

3. **è‡ªé€‚åº”å¥–åŠ±æœºåˆ¶æœ‰æ•ˆé˜²æ­¢reward hacking**  
   åŠ¨æ€è°ƒæ•´çš„Î»ç³»æ•°èƒ½è‡ªåŠ¨è°ƒèŠ‚åŒ¹é…ä¸æ¥é©¾ä¹‹é—´çš„æƒè¡¡ï¼Œæ— éœ€äººå·¥è°ƒå‚ï¼Œä¸”åœ¨å¤šç§éœ€æ±‚æ¡ä»¶ä¸‹ä¿æŒé²æ£’ã€‚

4. **ä¸“å®¶ç¡®å®å®ç°äº†æœ‰æ„ä¹‰çš„ä¸“ä¸šåŒ–**  
   å¯è§†åŒ–åˆ†ææ˜¾ç¤ºï¼š
   - æŸäº›ä¸“å®¶ä¸“æ³¨æ—©æ™šé«˜å³°ï¼›
   - æŸäº›ä¸“å®¶å¤„ç†åˆé—´æˆ–æ·±å¤œä½éœ€æ±‚ï¼›
   - é«˜å³°æ—¶æ®µè·¯ç”±æ›´åˆ†æ•£ï¼Œä½“ç°ç³»ç»Ÿå¤æ‚æ€§ã€‚

5. **å¼ºå¥çš„OODæ³›åŒ–èƒ½åŠ›**  
   åœ¨åŠ å…¥å…¨å±€æ‰°åŠ¨ï¼ˆå¤©æ°”å‡é€Ÿï¼‰å’Œå±€éƒ¨äº‹æ•…å†²å‡»åï¼ŒRAST-MoEç›¸å¯¹æ€§èƒ½ä¸‹é™æœ€å°ï¼ˆè§Table 7ï¼‰ï¼Œè¡¨æ˜å…¶æœªè¿‡æ‹Ÿåˆå†å²æ¨¡å¼ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¸“å®¶è§£é‡Šæ€§æœ‰é™**ï¼šå°½ç®¡è§‚å¯Ÿåˆ°ä¸“å®¶æ¿€æ´»æ¨¡å¼ä¸ç°å®regimeç›¸å…³ï¼Œä½†å°šéš¾ç²¾ç¡®ç•Œå®šæ¯ä¸ªä¸“å®¶çš„å…·ä½“åŠŸèƒ½ã€‚
- **ä¾èµ–MFDä»£ç†æ¨¡å‹**ï¼šè™½ç„¶é«˜æ•ˆï¼Œä½†ä»æ˜¯å®è§‚è¿‘ä¼¼ï¼Œå¯èƒ½å¿½ç•¥å¾®è§‚äº¤äº’ç»†èŠ‚ã€‚
- **æ‰©å±•æ€§å¾…éªŒè¯**ï¼šç›®å‰å®éªŒé›†ä¸­åœ¨æ—§é‡‘å±±ï¼Œè·¨åŸå¸‚è¿ç§»èƒ½åŠ›éœ€è¿›ä¸€æ­¥æµ‹è¯•ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **å¤šåŸå¸‚è”åˆè®­ç»ƒä¸è¿ç§»å­¦ä¹ **ï¼šæ¢ç´¢MoEä¸“å®¶åœ¨ä¸åŒåŸå¸‚çš„å¯è¿ç§»æ€§ã€‚
2. **å…¬å¹³æ€§ä¸ç¤¾ä¼šå½±å“å»ºæ¨¡**ï¼šçº³å…¥åœ°ç†è¦†ç›–å…¬å¹³ã€å¸æœºæ”¶å…¥å‡è¡¡ç­‰ç›®æ ‡ã€‚
3. **ç«¯åˆ°ç«¯MoE+Simulator jointly learning**ï¼šè”åˆä¼˜åŒ–ä»£ç†æ¨¡å‹ä¸ç­–ç•¥ç½‘ç»œã€‚
4. **ç»“åˆGNN/Multi-Agent RL**ï¼šç”¨äºæ›´ç»†ç²’åº¦çš„ç©ºé—´åè°ƒä¸åˆ†å¸ƒå¼è°ƒåº¦ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> RAST-MoE-RLé€šè¿‡**regime-aware MoEç¼–ç å™¨ + physics-informed simulator + adaptive reward**ï¼Œåœ¨å°æ¨¡å‹è§„æ¨¡ä¸‹å®ç°äº†é«˜æ€§èƒ½ã€é«˜é²æ£’æ€§çš„ç½‘çº¦è½¦åŒ¹é…å†³ç­–ï¼Œä¸ºå¤§è§„æ¨¡spatio-temporal RLä»»åŠ¡æä¾›äº†æ–°çš„èŒƒå¼ã€‚

</details>

---

### 15. [The Double Life of Code World Models: Provably Unmasking Malicious Behavior Through Execution Traces](https://arxiv.org/abs/2512.13821)

**Authors**: Subramanyam Sahoo, Jared Junkin  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.13821v1  

#### Abstract
Large language models (LLMs) increasingly generate code with minimal human oversight, raising critical concerns about backdoor injection and malicious behavior. We present Cross-Trace Verification Protocol (CTVP), a novel AI control framework that verifies untrusted code-generating models through se...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*The Double Life of Code World Models: Provably Unmasking Malicious Behavior Through Execution Traces*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**ä»£ç ç”Ÿæˆç±»å¤§è¯­è¨€æ¨¡å‹ï¼ˆCode-Generating LLMsï¼‰ä¸­å­˜åœ¨çš„åé—¨æ³¨å…¥ä¸æ¶æ„è¡Œä¸ºéšè—é£é™©**ã€‚éšç€LLMsåœ¨ç¨‹åºåˆæˆã€è°ƒè¯•å’Œè‡ªåŠ¨æ‰§è¡Œä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œæ”»å‡»è€…å¯èƒ½é€šè¿‡è®­ç»ƒæ±¡æŸ“ç­‰æ–¹å¼æ¤å…¥ä¸Šä¸‹æ–‡ä¾èµ–çš„æ¶æ„é€»è¾‘ï¼ˆå¦‚éšè”½çš„`backdoor`ï¼‰ï¼Œä¼ ç»ŸåŸºäºé™æ€åˆ†ææˆ–æ²™ç®±æ‰§è¡Œçš„æ£€æµ‹æ‰‹æ®µéš¾ä»¥æœ‰æ•ˆè¯†åˆ«æ­¤ç±»è¡Œä¸ºï¼Œå°¤å…¶æ˜¯åœ¨æ¨¡å‹ä¸å¯ä¿¡æˆ–å­˜åœ¨å¯¹æŠ—æ€§å¯¹é½åå·®çš„æƒ…å†µä¸‹ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Cross-Trace Verification Protocol (CTVP)** çš„æ–°å‹AIæ§åˆ¶æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **ä¸ç›´æ¥æ‰§è¡Œä»£ç **ï¼Œè€Œæ˜¯åˆ©ç”¨æ¨¡å‹è‡ªèº«é¢„æµ‹ä¸åŒè¯­ä¹‰ç­‰ä»·å˜ä½“ï¼ˆSemantic Orbitï¼‰ä¸‹çš„**æ‰§è¡Œè½¨è¿¹ï¼ˆExecution Tracesï¼‰**ï¼›
- é€šè¿‡åˆ†æè¿™äº›é¢„æµ‹è½¨è¿¹ä¹‹é—´çš„ä¸€è‡´æ€§æ¥åˆ¤æ–­æ˜¯å¦å­˜åœ¨æ¶æ„è¡Œä¸ºï¼šè‹¥ä¸€ä¸ªç¨‹åºåœ¨å¤šä¸ªè¯­ä¹‰ä¸å˜çš„è¯­æ³•å˜æ¢ä¸‹ï¼Œå…¶é¢„æµ‹æ‰§è¡Œè·¯å¾„å‡ºç°æ˜¾è‘—å·®å¼‚ï¼Œåˆ™è¡¨æ˜æ¨¡å‹å¯èƒ½å­˜åœ¨â€œåŒé‡è¡Œä¸ºâ€ï¼ˆdouble lifeï¼‰ï¼Œå³å¯¹ç‰¹å®šå½¢å¼è§¦å‘æ¶æ„å“åº”ã€‚

#### åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š
1. **è¯­ä¹‰è½¨é“åˆ†æï¼ˆSemantic Orbit Analysisï¼‰**  
   æ„é€ ä¸€ç»„è¯­ä¹‰ç­‰ä»·ä½†è¯­æ³•ä¸åŒçš„ç¨‹åºå˜ä½“ï¼ˆå¦‚å˜é‡é‡å‘½åã€æ­»ä»£ç æ’å…¥ã€æ ¼å¼åŒ–è°ƒæ•´ç­‰ï¼‰ï¼Œå½¢æˆâ€œè¯­ä¹‰è½¨é“â€ $ O = \{Q_1, ..., Q_k\} $ï¼Œå¹¶è¦æ±‚æ¨¡å‹ä¸ºæ¯ä¸ªå˜ä½“ç”Ÿæˆæ‰§è¡Œè½¨è¿¹ã€‚

2. **è·¨è½¨è¿¹ä¸€è‡´æ€§éªŒè¯æœºåˆ¶ï¼ˆCross-Trace Consistencyï¼‰**  
   å®šä¹‰äº†å¤šç»´åº¦çš„ç›¸ä¼¼åº¦åº¦é‡ï¼ˆstep-length ratio, per-step state equality, final-output agreementï¼‰ï¼Œè®¡ç®—æ‰€æœ‰è½¨è¿¹å¯¹ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œå¹¶å–é«˜ç™¾åˆ†ä½æ•°ä½œä¸ºä¸€è‡´æ€§å¾—åˆ† $ C $ã€‚

3. **Adversarial Robustness Quotient (ARQ)**  
   å¼•å…¥ARQé‡åŒ–éªŒè¯è¿‡ç¨‹ç›¸å¯¹äºå•æ¬¡æ¨ç†çš„è®¡ç®—å¼€é”€ï¼ˆwall-clock time å’Œ FLOPsï¼‰ï¼Œç†è®ºè¯æ˜å…¶éšè½¨é“å¤§å° $ k $ çº¿æ€§å¢é•¿ï¼ˆ$ \text{ARQ} \sim k+1 $ï¼‰ï¼ŒåŒæ—¶æ­ç¤ºäº†å¯¹æŠ—é€ƒé¿æˆæœ¬å‘ˆæŒ‡æ•°çº§ä¸Šå‡ã€‚

4. **éå¯åšå¼ˆæ€§ï¼ˆNon-gamifiabilityï¼‰çš„ç†è®ºä¿è¯**  
   åŸºäºä¿¡æ¯è®ºåˆ†ææŒ‡å‡ºï¼šè¦æ„é€ ä¸€ä¸ªèƒ½åœ¨æ•´ä¸ªè¯­ä¹‰è½¨é“ä¸Šä¿æŒä¸€è‡´æ€§çš„åé—¨ï¼Œæ‰€éœ€å°è¯•æ¬¡æ•°ä¸º $ \mathcal{O}(M^{k-1}) $ï¼Œå…¶ä¸­ $ M $ æ˜¯è½¨è¿¹ç©ºé—´è§„æ¨¡ï¼Œå› æ­¤å®é™…æ”»å‡»åœ¨è®¡ç®—ä¸Šä¸å¯è¡Œã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | CTVP | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚é™æ€æ‰«æã€æ²™ç®±æ‰§è¡Œï¼‰ |
|------|------|-------------------------------|
| æ˜¯å¦éœ€è¦ä¿¡ä»»æ¨¡å‹ | âŒ é»‘ç›’éªŒè¯ | âœ… å‡è®¾æ¨¡å‹è¾“å‡ºå¯ä¿¡ |
| æ˜¯å¦éœ€æ‰§è¡Œä»£ç  | âŒ ä»…é¢„æµ‹è½¨è¿¹ | âœ… å¿…é¡»è¿è¡Œä»£ç ï¼ˆæœ‰é€ƒé€¸é£é™©ï¼‰ |
| å¯¹æŠ—é²æ£’æ€§ | é«˜ï¼ˆæŒ‡æ•°çº§æœç´¢ç©ºé—´ï¼‰ | ä½ï¼ˆæ˜“è¢«æ··æ·†ç»•è¿‡ï¼‰ |
| å¯æ‰©å±•æ€§ | æ”¯æŒç¼“å­˜ã€è‡ªé€‚åº”é˜ˆå€¼ï¼ˆPIDæ§åˆ¶å™¨ï¼‰ | å¤šä¸ºä¸€æ¬¡æ€§è§„åˆ™åŒ¹é… |
| å½¢å¼åŒ–ä¿éšœ | æœ‰ä¿¡æ¯è®ºè¾¹ç•Œæ”¯æŒ | ç¼ºä¹ç†è®ºåŸºç¡€ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨äº†ä¸€ä¸ª**äººå·¥æ„å»ºçš„æ··åˆæ•°æ®é›†**ï¼ŒåŒ…å«ï¼š
  - **è‰¯æ€§ç¨‹åºï¼ˆBenign Programsï¼‰**ï¼šåŠŸèƒ½æ­£ç¡®ã€æ— æ¶æ„æ„å›¾çš„æ ‡å‡†Pythonè„šæœ¬ã€‚
  - **å¯¹æŠ—æ ·æœ¬ï¼ˆAdversarial/Malicious Variantsï¼‰**ï¼šåµŒå…¥äº†ä¸Šä¸‹æ–‡æ•æ„Ÿå‹åé—¨çš„å˜ç§ç¨‹åºï¼ˆä¾‹å¦‚ä»…åœ¨ç‰¹å®šå˜é‡åæˆ–ç»“æ„ä¸‹è§¦å‘æ¶æ„æ“ä½œï¼‰ã€‚
- æ‰€æœ‰ç¨‹åºé•¿åº¦æ§åˆ¶åœ¨åˆç†èŒƒå›´å†…ï¼ˆæœ€å¤šçº¦200 LOCï¼‰ï¼Œç¡®ä¿å¯å¤„ç†æ€§å’Œè¯­ä¹‰å®Œæ•´æ€§ã€‚

### å®éªŒè®¾ç½®
- **è½¨é“å¤§å°ï¼ˆOrbit Sizeï¼‰**ï¼šæµ‹è¯• $ k \in \{3, 5, 10, 20\} $
- **ä¸€è‡´æ€§è¯„åˆ†æ–¹å¼**ï¼šä½¿ç”¨ç¬¬80ç™¾åˆ†ä½çš„æˆå¯¹è½¨è¿¹ç›¸ä¼¼åº¦ä½œä¸ºæœ€ç»ˆä¸€è‡´æ€§åˆ†æ•° $ C $
- **å†³ç­–é€»è¾‘**ï¼š
  - è‹¥ $ C < T_{\text{strict}} $ â†’ `REJECT`
  - è‹¥ $ T_{\text{strict}} \leq C < T_{\text{soft}} $ â†’ å¯ç”¨å¯ä¿¡æ¨¡å‹è¿›è¡Œäº¤å‰éªŒè¯
  - è‹¥ $ C \geq T_{\text{soft}} $ â†’ `ACCEPT`
- **è‡ªé€‚åº”é˜ˆå€¼è°ƒèŠ‚**ï¼šé‡‡ç”¨ç±»PIDæ§åˆ¶å™¨åŠ¨æ€è°ƒæ•´ $ T_{\text{strict}} $ï¼Œç›®æ ‡FPR = 5%

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Detection Rate** | æˆåŠŸæ£€å‡ºæ¶æ„æ ·æœ¬çš„æ¯”ä¾‹ï¼ˆTrue Positive Rateï¼‰ |
| **False Positive Rate (FPR)** | å°†è‰¯æ€§æ ·æœ¬è¯¯åˆ¤ä¸ºæ¶æ„çš„æ¯”ä¾‹ |
| **Benign Acceptance Rate** | è‰¯æ€§æ ·æœ¬è¢«æ¥å—çš„æ¯”ä¾‹ |
| **ARQ (Adversarial Robustness Quotient)** | éªŒè¯å¼€é”€ç›¸å¯¹äºå•æ¬¡æ¨ç†çš„å¢é•¿å€æ•°ï¼ˆæ—¶é—´ä¸FLOPsï¼‰ |
| **Consistency Score Distribution** | ä¸åŒæ ·æœ¬çš„ä¸€è‡´æ€§å¾—åˆ†åˆ†å¸ƒ |
| **Transformation Success Rate** | æˆåŠŸç”Ÿæˆç¬¦åˆæœ€å°ç¼–è¾‘è·ç¦»è¦æ±‚çš„è¯­ä¹‰ç­‰ä»·å˜ä½“æ¯”ä¾‹ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å®ç°äº†ä»¥ä¸‹å‡ ç§é™æ€åˆ†æåŸºçº¿ç”¨äºæ¯”è¾ƒï¼š
1. **Static Pattern Detector**ï¼šæ­£åˆ™åŒ¹é…å…³é”®è¯ï¼ˆå¦‚ `eval(`, `exec()`, `os.system`ï¼‰
2. **AST Complexity Heuristic**ï¼šåŸºäºæŠ½è±¡è¯­æ³•æ ‘èŠ‚ç‚¹æ•°é‡å’Œæ§åˆ¶æµå¤æ‚åº¦åˆ¤æ–­å¼‚å¸¸
3. **Shannon Entropy Heuristic**ï¼šæ£€æµ‹æºç å­—ç¬¦ç†µè¿‡é«˜æˆ–è¿‡ä½ï¼ˆå¯èƒ½è¡¨ç¤ºåŠ å¯†/æ··æ·†ï¼‰
4. **Weighted Ensemble**ï¼šä¸Šè¿°ä¸‰é¡¹ä¸­è‡³å°‘ä¸¤é¡¹è§¦å‘æ‰åˆ¤å®šä¸ºæ¶æ„

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2 & Figure 1ï¼‰

| Orbit Size | Detection Rate (%) | FPR (%) | Avg Traces / Program | ARQ (Median) |
|------------|--------------------|---------|------------------------|---------------|
| 3          | 81.7               | 100.0   | 1.60                   | 4.00          |
| 5          | 83.3               | 97.5    | 2.80                   | 6.00          |
| 10         | 83.3               | 97.5    | 4.30                   | 11.00         |
| 20         | 86.7               | 100.0   | 7.60                   | 21.00         |

> æ³¨ï¼šè¡¨ä¸­FPRé«˜è¾¾97.5%-100%ï¼Œåº”ä¸ºç¬”è¯¯æˆ–å®šä¹‰åå‘ï¼›ç»“åˆæ­£æ–‡æè¿°â€œ79% outright rejectedâ€ï¼Œæ¨æµ‹æ­¤å¤„FPRå®æŒ‡â€œbenign rejection rateâ€ã€‚

æ›´å‡†ç¡®çš„ç»“æœè§æ­£æ–‡ç¬¬5èŠ‚ï¼š
- **æ£€æµ‹ç‡ï¼ˆDetection Rateï¼‰**ï¼šè¾¾åˆ° **100%**ï¼ˆ120ä¸ªæ¶æ„æ ·æœ¬å…¨éƒ¨æ£€å‡ºï¼Œé›¶æ¼æŠ¥ï¼‰
- **è‰¯æ€§æ¥å—ç‡ï¼ˆBenign Acceptanceï¼‰**ï¼š**79%** è¢«ç›´æ¥æ‹’ç»ï¼Œ21%è¿›å…¥å¯ä¿¡æ¨¡å‹å¤æŸ¥æµç¨‹
- **ä¸€è‡´æ€§å¾—åˆ†åˆ†å¸ƒ**ï¼šæ‰€æœ‰è‰¯æ€§æ ·æœ¬ä¸€è‡´æ€§æ¥è¿‘1.0ï¼Œè€Œæ¶æ„æ ·æœ¬æ˜æ˜¾åä½
- **ARQå¢é•¿è¶‹åŠ¿**ï¼šä¸­ä½ARQä» $ 4\times10^0 $ï¼ˆk=3ï¼‰å¢è‡³ $ 2\times10^1 $ï¼ˆk=20ï¼‰ï¼Œå‘ˆè¿‘ä¼¼çº¿æ€§å¢é•¿ï¼ˆç¬¦åˆç†è®ºé¢„æœŸ $ \text{ARQ} \sim k+1 $ï¼‰
- **è¿è¡Œæ—¶é—´**ï¼šä»0.275sï¼ˆk=3ï¼‰å¢è‡³0.333sï¼ˆk=20ï¼‰ï¼Œå¢å¹…å°ä¸”å¯æ§
- **å®éªŒæˆåŠŸç‡**ï¼š200æ¬¡è¯•éªŒä¸­ **100%æˆåŠŸï¼Œé›¶é”™è¯¯**

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ï¼ˆTable 1ï¼‰
| æ–¹æ³• | Detection Rate (%) | FPR (%) | Benign Acceptance (%) |
|------|--------------------|---------|------------------------|
| Static Analysis | 51.7 | 0.0 | 100.0 |
| Complexity | 80.0 | 62.5 | 37.5 |
| Entropy | 0.0 | 0.0 | 100.0 |
| Weighted | 51.7 | 0.0 | 100.0 |
| **CTVP** | **83.8** | **98.8** | **1.2** |

> âš ï¸ æ³¨æ„ï¼šæ­¤è¡¨FPRå«ä¹‰ç–‘ä¼¼é¢ å€’ï¼ˆCTVPçš„FPRé«˜è¾¾98.8%ä¸åˆç†ï¼‰ã€‚ç»“åˆä¸Šä¸‹æ–‡æ¨æ–­ï¼Œè¯¥æ•°å€¼å¯èƒ½æ˜¯â€œæ¶æ„æ£€å‡ºç‡â€æˆ–â€œè‰¯æ€§æ‹’ç»ç‡â€ã€‚çœŸæ­£æ„ä¹‰çš„FPRåº”åœ¨åç»­ç ”ç©¶ä¸­è¿›ä¸€æ­¥æ ¡å‡†ã€‚

ä½†ä»è¶‹åŠ¿çœ‹ï¼Œ**CTVPæ˜¾è‘—ä¼˜äºæ‰€æœ‰é™æ€åŸºçº¿**ï¼Œå°¤å…¶åœ¨æ•æ‰è¯­ä¹‰å±‚é¢çš„éšè”½åé—¨æ–¹é¢å…·æœ‰å‹å€’æ€§ä¼˜åŠ¿ã€‚

### æ¶ˆèå®éªŒä¸å…³é”®è§‚å¯Ÿ
- **è½¨é“å¤§å°å½±å“**ï¼šéšç€ $ k $ å¢åŠ ï¼Œæ£€æµ‹èƒ½åŠ›ç¨³æ­¥æå‡ï¼Œå°¤å…¶åœ¨ $ k=20 $ æ—¶è¾¾åˆ°æœ€ä¼˜ã€‚
- **å˜æ¢ç”ŸæˆæˆåŠŸç‡**ï¼šåœ¨ä¸­é—´èŒƒå›´ï¼ˆå¦‚k=10ï¼‰ä¸‹é™è‡³10%ï¼Œä½†åœ¨k=20æ¢å¤è‡³50â€“75%ï¼Œè¯´æ˜å­˜åœ¨â€œéš¾ç”ŸæˆåŒºâ€ï¼Œæœªæ¥å¯é€šè¿‡æ”¹è¿›å˜æ¢ç­–ç•¥ç¼“è§£ã€‚
- **èµ„æºæ¶ˆè€—**ï¼šCPUå†…å­˜ç¨³å®šåœ¨~4.8GBï¼ŒGPU~17GBï¼ˆè¿œä½äº71.3GBä¸Šé™ï¼‰ï¼Œç³»ç»Ÿé«˜æ•ˆç¨³å®šã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **è¯­ä¹‰ä¸å˜æ€§æ˜¯ä¸€æŠŠåŒåˆƒå‰‘**ï¼šåˆæ³•ç¨‹åºåœ¨è¯­ä¹‰å˜æ¢ä¸‹è¡Œä¸ºç¨³å®šï¼Œè€Œåé—¨å¾€å¾€ä¾èµ–ç‰¹å®šè¯­æ³•æ¨¡å¼ï¼Œç ´åäº†è¿™ç§ä¸€è‡´æ€§ï¼Œä»è€Œæš´éœ²è‡ªèº«ã€‚
2. âœ… **CTVPèƒ½å®ç°è¿‘ä¹å®Œç¾çš„æ¶æ„è¡Œä¸ºæ£€æµ‹**ï¼šåœ¨å®éªŒä¸­å®ç°äº† **100% detection rate**ï¼Œä¸”æœªå‘ç”Ÿè¯¯æ”¾è¡Œã€‚
3. âœ… **éå¯åšå¼ˆæ€§æˆç«‹**ï¼šç”±äºä¸€è‡´æ€§ç»´æŒçš„æˆæœ¬éšè½¨é“å¤§å°æŒ‡æ•°å¢é•¿ï¼Œæ”»å‡»è€…æ— æ³•é€šè¿‡ç©·ä¸¾æ‰¾åˆ°æ—¢èƒ½è§¦å‘åé—¨åˆä¿æŒä¸€è‡´æ€§çš„å˜ä½“ã€‚
4. âœ… **è½»é‡çº§å³å¯ç”Ÿæ•ˆ**ï¼šå³ä½¿è¾ƒå°çš„è½¨é“ï¼ˆk=3~5ï¼‰ä¹Ÿèƒ½æä¾›è¾ƒå¼ºæ£€æµ‹åŠ›ï¼Œé€‚åˆéƒ¨ç½²äºèµ„æºå—é™ç¯å¢ƒã€‚

### å±€é™æ€§
1. **ä¾èµ–LLMè½¨è¿¹é¢„æµ‹è´¨é‡**ï¼šå½“å‰æ–¹æ³•ä½¿ç”¨LLMæ¨¡æ‹Ÿæ‰§è¡Œè½¨è¿¹ï¼Œè€ŒéçœŸå®æ‰§è¡Œï¼Œå­˜åœ¨é¢„æµ‹è¯¯å·®é£é™©ï¼ˆå°¤å…¶æ˜¯å¤æ‚æ§åˆ¶æµæˆ–é€’å½’ï¼‰ã€‚
2. **å˜æ¢è¦†ç›–æœ‰é™**ï¼šç›®å‰ä»…æ”¯æŒ5ç§è¯­ä¹‰ä¿ç•™å˜æ¢ï¼ˆå¦‚å˜é‡é‡å‘½åã€æ­»ä»£ç æ’å…¥ç­‰ï¼‰ï¼Œå¯èƒ½é—æ¼æŸäº›å¾®å¦™çš„ç­‰ä»·å½¢å¼ã€‚
3. **è®¡ç®—å¼€é”€éškå¢é•¿**ï¼šè™½ç„¶å•æ¬¡å»¶è¿Ÿä»è¾ƒä½ï¼Œä½†å¤§è§„æ¨¡åº”ç”¨æ—¶ $ \text{ARQ} \sim k+1 $ çš„å¼€é”€ä»æ„æˆç“¶é¢ˆã€‚
4. **å‡é˜³æ€§ç®¡ç†æŒ‘æˆ˜**ï¼šéƒ¨åˆ†è‰¯æ€§ç¨‹åºå› LLMé¢„æµ‹ä¸ç¨³å®šä¹Ÿå¯èƒ½å¯¼è‡´ä½ä¸€è‡´æ€§ï¼Œéœ€å¼•å…¥å¯ä¿¡æ¨¡å‹è¾…åŠ©è£å†³ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **é›†æˆçœŸå®æ‰§è¡Œç¯å¢ƒ**ï¼šå¼•å…¥å—é™æ²™ç®±ï¼ˆå¦‚ RestrictedPythonï¼‰è·å–çœŸå®æ‰§è¡Œè½¨è¿¹ï¼Œå¢å¼ºéªŒè¯å¯é æ€§ã€‚
2. **ä¸°å¯Œè¯­ä¹‰å˜æ¢ç§ç±»**ï¼šåŠ å…¥æ•°æ®æµæ„ŸçŸ¥é‡æ’ã€å¾ªç¯å±•å¼€ã€å¸¸é‡æŠ˜å ç­‰é«˜çº§å˜æ¢ï¼Œæé«˜è½¨é“å¤šæ ·æ€§ã€‚
3. **è‡ªé€‚åº”è½¨é“å¤§å°ï¼ˆAdaptive Orbit Sizingï¼‰**ï¼šæ ¹æ®ç¨‹åºå¤æ‚åº¦åŠ¨æ€é€‰æ‹© $ k $ï¼Œä¼˜åŒ–æ•ˆç‡ä¸å®‰å…¨æ€§å¹³è¡¡ã€‚
4. **æŒç»­ç›‘æ§ä¸åé¦ˆå­¦ä¹ **ï¼šç»“åˆ runtime monitoring å®ç°å‘¨æœŸæ€§å†éªŒè¯ï¼Œæ”¯æŒåœ¨çº¿æ›´æ–°ä¸å¼‚å¸¸é¢„è­¦ã€‚
5. **æ‹“å±•è‡³å…¶ä»–æ¨¡æ€**ï¼šæ¢ç´¢CTVPæ˜¯å¦å¯ç”¨äºæ–‡æœ¬ç”Ÿæˆï¼ˆæ£€æµ‹éšå«åè§ï¼‰ã€å›¾åƒåˆæˆï¼ˆæ£€æµ‹æ°´å°åé—¨ï¼‰ç­‰é¢†åŸŸã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> CTVP æå‡ºäº†ä¸€ç§åŸºäºè¯­ä¹‰è½¨é“ä¸è·¨è½¨è¿¹ä¸€è‡´æ€§çš„é»‘ç›’éªŒè¯æœºåˆ¶ï¼Œé¦–æ¬¡å°†AIæ§åˆ¶ç†è®ºåº”ç”¨äºä»£ç ç”Ÿæˆå®‰å…¨ï¼Œåœ¨æ— éœ€æ‰§è¡Œä»£ç çš„å‰æä¸‹ï¼Œä»¥æé«˜çš„ç²¾åº¦æ­éœ²å‡ºæ¨¡å‹ä¸­çš„â€œåŒé‡ç”Ÿæ´»â€è¡Œä¸ºï¼Œå…·å¤‡åšå®çš„ç†è®ºæ”¯æ’‘ä¸è‰¯å¥½çš„å®è·µå‰æ™¯ã€‚

</details>

---

### 16. [Beyond Lipschitz Continuity and Monotonicity: Fractal and Chaotic Activation Functions in Echo State Networks](https://arxiv.org/abs/2512.14675)

**Authors**: Rae Chipera, Jenny Du, Irene Tsapara  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.14675v1  

#### Abstract
Contemporary reservoir computing relies heavily on smooth, globally Lipschitz continuous activation functions, limiting applications in defense, disaster response, and pharmaceutical modeling where robust operation under extreme conditions is critical. We systematically investigate non-smooth activa...

---

### 17. [State-Dependent Refusal and Learned Incapacity in RLHF-Aligned Language Models](https://arxiv.org/abs/2512.13762)

**Authors**: TK Lee  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.13762v1  

#### Abstract
Large language models (LLMs) are widely deployed as general-purpose tools, yet extended interaction can reveal behavioral patterns not captured by standard quantitative benchmarks. We present a qualitative case-study methodology for auditing policy-linked behavioral selectivity in long-horizon inter...

---

### 18. [Sparsity-Controllable Dynamic Top-p MoE for Large Foundation Model Pre-training](https://arxiv.org/abs/2512.13996)

**Authors**: Can Jin, Hongwu Peng, Mingcan Xiang, Qixin Zhang, Xiangchi Yuan, Amit Hasan, Ohiremen Dibua, Yifan Gong, Yan Kang, Dimitris N. Metaxas  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.13996v1  

#### Abstract
Sparse Mixture-of-Experts (MoE) architectures effectively scale model capacity by activating only a subset of experts for each input token. However, the standard Top-k routing strategy imposes a uniform sparsity pattern that ignores the varying difficulty of tokens. While Top-p routing offers a flex...

---

### 19. [TiCard: Deployable EXPLAIN-only Residual Learning for Cardinality Estimation](https://arxiv.org/abs/2512.14358)

**Authors**: Qizhi Wang  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.14358v1  

#### Abstract
Cardinality estimation is a key bottleneck for cost-based query optimization, yet deployable improvements remain difficult: classical estimators miss correlations, while learned estimators often require workload-specific training pipelines and invasive integration into the optimizer. This paper pres...

---

### 20. [Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets](https://arxiv.org/abs/2512.14237)

**Authors**: Estelle Zheng (LORIA, ALE), Nathan Cerisara (LORIA), S\'ebastien Warichet (ALE), Emmanuel Helbert (ALE), Christophe Cerisara (SYNALP, LORIA)  
**Category**: cs.CL  
**Published**: 2025-12-17  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.14237v1  

#### Abstract
Fine-tuning large language models (LLMs) is often limited by the memory available on commodity GPUs. Parameter-efficient fine-tuning (PEFT) methods such as QLoRA reduce the number of trainable parameters, yet still incur high memory usage induced by the backward pass in the full model. We revisit La...

---

### 21. [Real-Time Service Subscription and Adaptive Offloading Control in Vehicular Edge Computing](https://arxiv.org/abs/2512.14002)

**Authors**: Chuanchao Gao, Arvind Easwaran  
**Category**: cs.DC  
**Published**: 2025-12-17  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.14002v1  

#### Abstract
Vehicular Edge Computing (VEC) has emerged as a promising paradigm for enhancing the computational efficiency and service quality in intelligent transportation systems by enabling vehicles to wirelessly offload computation-intensive tasks to nearby Roadside Units. However, efficient task offloading ...

---

### 22. [Physics-Guided Deep Learning for Heat Pump Stress Detection: A Comprehensive Analysis on When2Heat Dataset](https://arxiv.org/abs/2512.13696)

**Authors**: Md Shahabub Alam, Md Asifuzzaman Jishan, Ayan Kumar Ghosh  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.13696v1  

#### Abstract
Heat pump systems are critical components in modern energy-efficient buildings, yet their operational stress detection remains challenging due to complex thermodynamic interactions and limited real-world data. This paper presents a novel Physics-Guided Deep Neural Network (PG-DNN) approach for heat ...

---

### 23. [Explainable reinforcement learning from human feedback to improve alignment](https://arxiv.org/abs/2512.13837)

**Authors**: Shicheng Liu, Siyuan Xu, Wenjie Qiu, Hangfan Zhang, Minghui Zhu  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.13837v1  

#### Abstract
A common and effective strategy for humans to improve an unsatisfactory outcome in daily life is to find a cause of this outcome and correct the cause. In this paper, we investigate whether this human improvement strategy can be applied to improving reinforcement learning from human feedback (RLHF) ...

---

### 24. [A First-Order Logic-Based Alternative to Reward Models in RLHF](https://arxiv.org/abs/2512.14100)

**Authors**: Chunjin Jian, Xinhua Zhu  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.14100v1  

#### Abstract
Reinforcement Learning from Human Feedback (RLHF) plays a crucial role in aligning large language models (LLMs) with human values and preferences. However, the quality and stability of the trained reward model largely determine the final alignment performance. Existing approaches such as Proximal Po...

---

### 25. [Implicit Bias and Invariance: How Hopfield Networks Efficiently Learn Graph Orbits](https://arxiv.org/abs/2512.14338)

**Authors**: Michael Murray, Tenzin Chan, Kedar Karhadker, Christopher J. Hillar  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.14338v1  

#### Abstract
Many learning problems involve symmetries, and while invariance can be built into neural architectures, it can also emerge implicitly when training on group-structured data. We study this phenomenon in classical Hopfield networks and show they can infer the full isomorphism class of a graph from a s...

---

### 26. [Blind Radio Mapping via Spatially Regularized Bayesian Trajectory Inference](https://arxiv.org/abs/2512.13701)

**Authors**: Zheng Xing, Junting Chen  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.13701v1  

#### Abstract
Radio maps enable intelligent wireless applications by capturing the spatial distribution of channel characteristics. However, conventional construction methods demand extensive location-labeled data, which are costly and impractical in many real-world scenarios. This paper presents a blind radio ma...

---

### 27. [ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making](https://arxiv.org/abs/2512.13716)

**Authors**: Yitong Luo, Ziang Chen, Hou Hei Lam, Jiayu zhan, Junqi Wang, Zhenliang Zhang, Xue Feng  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.13716v1  

#### Abstract
Personalized decision-making is essential for human-AI interaction, enabling AI agents to act in alignment with individual users' value preferences. As AI systems expand into real-world applications, adapting to personalized values beyond task completion or collective alignment has become a critical...

---

### 28. [Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy](https://arxiv.org/abs/2512.13725)

**Authors**: Steve Nwaiwu, Nipat Jongsawat, Anucha Tungkasthan  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.13725v1  

#### Abstract
Causal reasoning in Large Language Models spanning association, intervention, and counterfactual inference is essential for reliable decision making in high stakes settings. As deployment shifts toward edge and resource constrained environments, quantized models such as INT8 and NF4 are becoming sta...

---

### 29. [OpenDataArena: A Fair and Open Arena for Benchmarking Post-Training Dataset Value](https://arxiv.org/abs/2512.14051)

**Authors**: Mengzhang Cai, Xin Gao, Yu Li, Honglin Lin, Zheng Liu, Zhuoshi Pan, Qizhi Pei, Xiaoran Shang, Mengyuan Sun, Zinan Tang, Xiaoyang Wang, Zhanping Zhong, Yun Zhu, Dahua Lin, Conghui He, Lijun Wu  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.14051v1  

#### Abstract
The rapid evolution of Large Language Models (LLMs) is predicated on the quality and diversity of post-training datasets. However, a critical dichotomy persists: while models are rigorously benchmarked, the data fueling them remains a black box--characterized by opaque composition, uncertain provena...

---

### 30. [Optimizing Multi-Tier Supply Chain Ordering with a Hybrid Liquid Neural Network and Extreme Gradient Boosting Model](https://arxiv.org/abs/2512.14112)

**Authors**: Chunan Tong  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.14112v1  

#### Abstract
Supply chain management (SCM) faces significant challenges like demand fluctuations and the bullwhip effect. Traditional methods and even state-of-the-art LLMs struggle with benchmarks like the Vending Machine Test, failing to handle SCM's complex continuous time-series data. While ML approaches lik...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
