# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-30 05:58:57 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Argus: Token Aware Distributed LLM Inference Optimization](https://arxiv.org/abs/2512.22925)

**Authors**: Panlong Wu, Yifei Zhong, Danyang Chen, Ting Wang, Fangxin Wang  
**Category**: cs.DC  
**Published**: 2025-12-30  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2512.22925v1  

#### Abstract
Large Language Models (LLMs) are rapidly being integrated into real-world applications, yet their autoregressive architectures introduce significant inference time variability, especially when deployed across heterogeneous edge-cloud systems. Existing solutions largely neglect the dynamic, stochasti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šArgus: Token Aware Distributed LLM Inference Optimization**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¾¹ç¼˜-äº‘ååŒç³»ç»Ÿä¸­çš„æ¨ç†éƒ¨ç½²é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **æ¨ç†æ—¶é—´é«˜åº¦å¯å˜**ï¼šç”±äºLLMé‡‡ç”¨è‡ªå›å½’æ¶æ„ï¼Œè¾“å‡ºtokené•¿åº¦éšè¾“å…¥è¯­ä¹‰å¤æ‚åº¦å‰§çƒˆå˜åŒ–ï¼Œå¯¼è‡´æ¨ç†å»¶è¿Ÿæ³¢åŠ¨å¤§ã€‚
- **åŠ¨æ€ä¸éšæœºç¯å¢ƒ**ï¼šçœŸå®åœºæ™¯ä¸­è¯·æ±‚è´Ÿè½½ã€ç½‘ç»œçŠ¶æ€å’Œå®¢æˆ·ç«¯æ´»åŠ¨å…·æœ‰æ˜¾è‘—æ—¶å˜æ€§å’Œä¸ç¡®å®šæ€§ã€‚
- **å¼‚æ„è®¡ç®—èµ„æº**ï¼šè¾¹ç¼˜è®¾å¤‡ï¼ˆå¦‚Jetson Orinï¼‰ä¸äº‘ç«¯æœåŠ¡å™¨åœ¨ç®—åŠ›ã€é€šä¿¡å»¶è¿Ÿå’Œç²¾åº¦ä¸Šå·®å¼‚å·¨å¤§ï¼Œä¼ ç»Ÿé™æ€è°ƒåº¦ç­–ç•¥éš¾ä»¥é€‚åº”ã€‚

ç°æœ‰æ–¹æ³•å¤§å¤šå¿½ç•¥tokenç”Ÿæˆçš„åŠ¨æ€ç‰¹æ€§ï¼Œæˆ–å°†é—®é¢˜ç®€åŒ–ä¸ºé™æ€ä¼˜åŒ–ï¼Œæ— æ³•åº”å¯¹ä¸Šè¿°è”åˆæŒ‘æˆ˜ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡º **Argus**ï¼Œé¦–ä¸ª**tokenæ„ŸçŸ¥çš„åˆ†å¸ƒå¼è¾¹ç¼˜-äº‘LLMæ¨ç†ä¼˜åŒ–æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒç”±ä¸¤ä¸ªæ¨¡å—æ„æˆï¼š

#### **(1) Length-Aware Semantics (LAS) æ¨¡å—**
- åˆ©ç”¨ä¸€ä¸ªå¾®è°ƒåçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆModernBERTï¼‰ï¼Œç»“åˆ**ç‰¹å¾é‡æ ¡å‡†æœºåˆ¶**ï¼ˆå—Squeeze-and-Excitationå¯å‘ï¼‰ï¼Œé¢„æµ‹æ¯ä¸ªè¾“å…¥promptçš„é¢„æœŸè¾“å‡ºtokené•¿åº¦ã€‚
- å¼•å…¥**token-length-sensitiveç‰¹å¾è°ƒåˆ¶**ï¼Œå¢å¼ºæ¨¡å‹å¯¹â€œè§£é‡Šè¯¦ç»†â€ã€â€œç®€è¦åˆ—å‡ºâ€ç­‰é•¿åº¦ç›¸å…³æŒ‡ä»¤çš„æ•æ„Ÿæ€§ã€‚
- å®ç°**æ¨ç†å‰ç²¾å‡†å·¥ä½œé‡ä¼°è®¡**ï¼Œä¸ºåç»­ä»»åŠ¡å¸è½½æä¾›ç»†ç²’åº¦ç”»åƒã€‚

#### **(2) Lyapunov-guided Offloading Optimization (LOO) æ¨¡å—**
- å°†é•¿æœŸ**ç”¨æˆ·ä½“éªŒè´¨é‡ï¼ˆQoEï¼‰ä¼˜åŒ–**å»ºæ¨¡ä¸ºè€ƒè™‘LLM **prefilling å’Œ decoding æˆæœ¬**çš„éšæœºä¼˜åŒ–é—®é¢˜ã€‚
- åŸºäºLyapunovä¼˜åŒ–ç†è®ºï¼Œå°†é•¿æœŸç›®æ ‡è½¬åŒ–ä¸ºæ¯æ—¶éš™æœ€å°åŒ–é—®é¢˜ã€‚
- è®¾è®¡ **Iterative Offloading Algorithm with Damping and Congestion Control (IODCC)**ï¼š
  - å°†NP-hardçš„æ•´æ•°éçº¿æ€§è§„åˆ’ï¼ˆINLPï¼‰åˆ†è§£ä¸ºä¸€ç³»åˆ—å¯é«˜æ•ˆæ±‚è§£çš„æ•´æ•°çº¿æ€§è§„åˆ’ï¼ˆILPï¼‰ã€‚
  - å¼•å…¥**æ‹¥å¡æ„ŸçŸ¥ä»£ä»·å‡½æ•°**ä¸**é˜»å°¼æ›´æ–°æœºåˆ¶**ï¼Œé¿å…è¿­ä»£è¿‡ç¨‹ä¸­çš„éœ‡è¡ï¼Œæå‡æ”¶æ•›ç¨³å®šæ€§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **å»ºæ¨¡èƒ½åŠ›** | é¦–æ¬¡æ˜¾å¼å»ºæ¨¡LLMè‡ªå›å½’ç”Ÿæˆå¸¦æ¥çš„tokené•¿åº¦åŠ¨æ€æ€§ï¼Œçªç ´ä¼ ç»ŸDNNæ¨ç†å‡è®¾ã€‚ |
| **ä¼˜åŒ–ç›®æ ‡** | è”åˆä¼˜åŒ–QoEã€å»¶è¿Ÿã€ç²¾åº¦ä¸é•¿æœŸèµ„æºçº¦æŸï¼Œæ”¯æŒå¼‚æ„è®¾å¤‡ååŒã€‚ |
| **ç®—æ³•æ•ˆç‡** | IODCCä»¥ä½å¤æ‚åº¦é€¼è¿‘æœ€ä¼˜è§£ï¼Œæ— éœ€å¼ºåŒ–å­¦ä¹ çš„å¤§é‡è®­ç»ƒå¼€é”€ã€‚ |
| **ç¨³å®šæ€§ä¿éšœ** | ç†è®ºè¯æ˜æ»¡è¶³é•¿æœŸè®¡ç®—å®¹é‡çº¦æŸï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šè¿è¡Œã€‚ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **çœŸå®LLMæŸ¥è¯¢è½¨è¿¹**ï¼šæ¥è‡ªé˜¿é‡Œå·´å·´Bailianå¹³å°çš„çœŸå®ç”¨æˆ·è¯·æ±‚æ—¥å¿—ï¼ˆå¼•ç”¨è‡ª[3] `arXiv:2505.09999`ï¼‰ã€‚
- åŒ…å«å¤šä¸ªå®¢æˆ·ç«¯åœ¨ä¸åŒæ—¶é—´æ®µçš„è¯·æ±‚æ¨¡å¼ï¼Œåæ˜ ç°å®ä¸–ç•Œä¸­çš„**é«˜æ³¢åŠ¨æ€§ä¸å¤šæ ·æ€§**ã€‚

---

### **å®éªŒè®¾ç½®**
- **ç³»ç»Ÿæ¶æ„**ï¼šå¼‚æ„è¾¹ç¼˜-äº‘ç³»ç»Ÿï¼ŒåŒ…å« `N` å°è¾¹ç¼˜æœåŠ¡å™¨ä¸ `U` å°äº‘æœåŠ¡å™¨ã€‚
- **ä»»åŠ¡ç±»å‹**ï¼š3ç±»ä»»åŠ¡ï¼ˆè½»ã€ä¸­ã€é‡ï¼‰ï¼Œå¯¹åº”ä¸åŒprefill/decodeè®¡ç®—éœ€æ±‚ï¼š
  - å°æ¨¡å‹ï¼šprefill=2, decode=1 å•ä½
  - å¤§æ¨¡å‹ï¼šprefill=8, decode=4 å•ä½
- **èµ„æºå¼‚æ„æ€§**ï¼š
  - è¾¹ç¼˜æœåŠ¡å™¨ç®—åŠ› `f_e âˆˆ [2.5, 5]`
  - äº‘æœåŠ¡å™¨ç®—åŠ› `f_c âˆˆ [5, 7.5]`
- **é€šä¿¡ä¸ç²¾åº¦**ï¼š
  - è¾¹ç¼˜ï¼šä½å»¶è¿Ÿã€ä½ç²¾åº¦ `[0.1, 0.5]`
  - äº‘ï¼šé«˜å»¶è¿Ÿã€é«˜ç²¾åº¦ `[0.6, 1.0]`
- **æ—¶é—´èŒƒå›´**ï¼š`T = 100` ä¸ªæ—¶éš™

---

### **è¯„ä¼°æŒ‡æ ‡**
- **ä¸»æŒ‡æ ‡**ï¼š**Lyapunov Reward**ï¼Œç»¼åˆåæ˜ QoEï¼ˆå»¶è¿Ÿã€ç²¾åº¦åŠ æƒï¼‰ä¸è™šæ‹Ÿé˜Ÿåˆ—ç§¯å‹ï¼ˆä»£è¡¨çº¦æŸè¿åé£é™©ï¼‰ã€‚
- **è¾…åŠ©æŒ‡æ ‡**ï¼š
  - Tokené¢„æµ‹è¯¯å·®ï¼ˆL1 Lossï¼‰
  - å¯è®­ç»ƒå‚æ•°é‡ï¼ˆå‚æ•°æ•ˆç‡ï¼‰
  - ä¸åŒé…ç½®ä¸‹çš„æ€§èƒ½å¯¹æ¯”ï¼ˆæ¶ˆèå®éªŒï¼‰

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åŸºçº¿ | æè¿° |
|------|------|
| **Greedy_Accuracy** | ä¼˜å…ˆé€‰æ‹©ç²¾åº¦æœ€é«˜çš„è®¾å¤‡ |
| **Greedy_Compute** | ä¼˜å…ˆé€‰æ‹©ç®—åŠ›æœ€å¼ºçš„è®¾å¤‡ |
| **Greedy_Delay** | ä¼˜å…ˆé€‰æ‹©å»¶è¿Ÿæœ€ä½çš„è®¾å¤‡ |
| **TransformerPPO** | åŸºäºTransformer + PPOçš„RLæ–¹æ³• + Lyapunovçº¦æŸ |
| **DiffusionRL** | åŸºäºæ‰©æ•£æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹  + Lyapunovçº¦æŸ |
| **LoRA / LSTM / Transformers / Qwen2.5-7B** | ç”¨äºtokené¢„æµ‹æ¨¡å—çš„å¯¹æ¯”æ¨¡å‹ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **(1) LOO vs. å„åŸºçº¿ï¼ˆTable I & IIï¼‰**
| é…ç½® | Argus (LOO) | Best Baseline (Baseline5) |
|------|-------------|---------------------------|
| `N=4, U=15` | **36,602** | 32,077 (DiffusionRL) |
| `N=4, U=20` | **30,757** | 25,511 (DiffusionRL) |
| `N=15, U=6` | **21,080** | 14,823 (DiffusionRL) |
| `N=20, U=6` | **28,961** | 17,939 (DiffusionRL) |

> âœ… **ç»“è®º**ï¼šArgusåœ¨æ‰€æœ‰é…ç½®ä¸‹å‡æ˜¾è‘—ä¼˜äºå„ç±»è´ªå©ªç­–ç•¥ä¸å…ˆè¿›RLæ–¹æ³•ã€‚

---

#### **(2) Tokené¢„æµ‹ç²¾åº¦ï¼ˆFig. 4aï¼‰**
| æ–¹æ³• | L1 Loss |
|------|--------|
| **LAS (Ours)** | **91.85** |
| LoRA | 92.07 (+0.2%) |
| LSTM | 107.79 (+17.3%) |
| Transformers | 106.69 (+16.15%) |
| Qwen2.5-7B | 176.93 (+92.6%) |

> âœ… LASåœ¨æ›´ä½å‚æ•°é‡ä¸‹å®ç°æ›´é«˜é¢„æµ‹ç²¾åº¦ã€‚

---

#### **(3) å‚æ•°æ•ˆç‡ï¼ˆFig. 4bï¼‰**
| æ–¹æ³• | å¯è®­ç»ƒå‚æ•° |
|------|----------|
| LoRA | 8.75M |
| **LAS** | **0.09M** |

> âœ… LASä»…éœ€ **0.09M** å¯è®­ç»ƒå‚æ•°ï¼Œæ¯”LoRAå°‘ **99%**ï¼Œé€‚åˆè¾¹ç¼˜éƒ¨ç½²ã€‚

---

#### **(4) æ¶ˆèå®éªŒï¼šTokené¢„æµ‹å™¨çš„å½±å“ï¼ˆTable IIIï¼‰**
| é…ç½® | æœ‰é¢„æµ‹å™¨ | æ— é¢„æµ‹å™¨ | æå‡å¹…åº¦ |
|------|---------|---------|---------|
| `N=4, U=6` | 10,808 | 5,409 | **+99.8%** |
| `N=4, U=8` | 14,324 | 11,519 | **+24.3%** |
| `N=4, U=10` | 18,339 | 14,457 | **+26.9%** |

> âœ… è¯æ˜**å‡†ç¡®çš„tokené•¿åº¦é¢„æµ‹æ˜¯æ€§èƒ½æå‡çš„å…³é”®é©±åŠ¨å› ç´ **ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **tokené•¿åº¦å¯é¢„æµ‹ä¸”è‡³å…³é‡è¦**ï¼šé€šè¿‡LASæ¨¡å—å¯è¾ƒå‡†ç¡®é¢„æµ‹è¾“å‡ºé•¿åº¦ï¼Œè¯¥ä¿¡æ¯å¯¹ä¼˜åŒ–å¸è½½å†³ç­–å…·æœ‰å†³å®šæ€§ä½œç”¨ã€‚
2. **Arguså®ç°è¿‘ä¼˜æ€§èƒ½**ï¼šç†è®ºåˆ†æè¡¨æ˜å…¶é•¿æœŸQoEæ€§èƒ½ä¸æœ€ä¼˜å€¼å·®è·ä¸è¶…è¿‡å¸¸æ•°é¡¹ $ B/V $ï¼Œå¯é€šè¿‡è°ƒèŠ‚æ§åˆ¶å‚æ•° $ V $ é€¼è¿‘æœ€ä¼˜ã€‚
3. **ç³»ç»Ÿç¨³å®šæ€§å¾—åˆ°ä¿è¯**ï¼šåŸºäºLyapunovçš„è™šæ‹Ÿé˜Ÿåˆ—æœºåˆ¶ç¡®ä¿é•¿æœŸè®¡ç®—èµ„æºçº¦æŸè¢«æ»¡è¶³ï¼Œç³»ç»Ÿä¸ä¼šè¿‡è½½ã€‚
4. **ä¼˜äºRLæ–¹æ³•**ï¼šå°½ç®¡RLï¼ˆå¦‚TransformerPPOã€DiffusionRLï¼‰å…·å¤‡å¼ºè¡¨è¾¾èƒ½åŠ›ï¼Œä½†Argusåœ¨æ— éœ€è®­ç»ƒçš„æƒ…å†µä¸‹è¾¾åˆ°æ›´ä¼˜æ€§èƒ½ï¼Œä¸”æ›´ç¨³å®šã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–é¢„è®­ç»ƒæ¨¡å‹**ï¼šLASæ¨¡å—ä¾èµ–ModernBERTç­‰PLMï¼Œå¯èƒ½å¢åŠ éƒ¨ç½²æˆæœ¬ã€‚
- **æœªè€ƒè™‘å¤šè·³ç½‘ç»œ**ï¼šå®éªŒè®¾å®šä¸ºç›´æ¥è¿æ¥è¾¹ç¼˜æˆ–äº‘ï¼Œæœªæ¶‰åŠå¤æ‚ç½‘ç»œæ‹“æ‰‘ã€‚
- **é™æ€è®¾å¤‡èƒ½åŠ›å‡è®¾**ï¼šå‡è®¾æœåŠ¡å™¨ç®—åŠ›æ’å®šï¼Œæœªå»ºæ¨¡è®¾å¤‡è€åŒ–æˆ–åŠ¨æ€é™é¢‘ã€‚
- **ä»…è€ƒè™‘å•ä»»åŠ¡å¸è½½**ï¼šæœªå¤„ç†å¤æ‚DAGå‹è¯­è¨€æ¨¡å‹ç¨‹åºï¼ˆå¦‚SGLangæ”¯æŒçš„ç»“æ„åŒ–ç”Ÿæˆï¼‰ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. æ‰©å±•è‡³**å¤šæ¨¡æ€LLM**ä¸**RAGåœºæ™¯**ï¼Œèåˆæ£€ç´¢ç¼“å­˜ä¼˜åŒ–ï¼ˆç±»ä¼¼CacheBlendï¼‰ã€‚
2. ç»“åˆ**KV Cacheå‹ç¼©æŠ€æœ¯**ï¼ˆå¦‚CacheGenï¼‰è¿›ä¸€æ­¥é™ä½ä¼ è¾“å¼€é”€ã€‚
3. æ¢ç´¢**åœ¨çº¿å­¦ä¹ æœºåˆ¶**ï¼Œä½¿LASèƒ½æŒç»­é€‚åº”ç”¨æˆ·è¡Œä¸ºæ¼‚ç§»ã€‚
4. æ”¯æŒ**åŠ¨æ€æ¨¡å‹åˆ‡æ¢**ï¼ˆå¦‚Small-to-Large Cascade Inferenceï¼‰ä»¥æ›´å¥½å¹³è¡¡å»¶è¿Ÿä¸ç²¾åº¦ã€‚

---

> **æ€»ç»“**ï¼šArgusé¦–æ¬¡å°†LLMçš„**è‡ªå›å½’tokenç”Ÿæˆç‰¹æ€§**çº³å…¥åˆ†å¸ƒå¼æ¨ç†è°ƒåº¦æ¡†æ¶ï¼Œæå‡º**LAS + LOO + IODCC**ä¸‰ä½ä¸€ä½“æ–¹æ¡ˆï¼Œåœ¨çœŸå®è½¨è¿¹éªŒè¯ä¸‹å±•ç°å‡ºå“è¶Šæ€§èƒ½ä¸ç¨³å®šæ€§ï¼Œä¸ºè¾¹ç¼˜æ™ºèƒ½æ—¶ä»£çš„LLMæœåŠ¡æä¾›äº†é‡è¦èŒƒå¼ã€‚

</details>

---

### 2. [MatKV: Trading Compute for Flash Storage in LLM Inference](https://arxiv.org/abs/2512.22195)

**Authors**: Kun-Woo Shin (Seoul National University, Korea), Jay H. Park (Samsung Electronics, Korea), Moonwook Oh (Samsung Electronics, Korea), Yohan Jo (Seoul National University, Korea), Jaeyoung Do (Seoul National University, Korea), Sang-Won Lee (Seoul National University, Korea)  
**Category**: cs.DC  
**Published**: 2025-12-30  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2512.22195v1  

#### Abstract
We observe two major trends in LLM-based generative AI: (1) inference is becoming the dominant factor in terms of cost and power consumption, surpassing training, and (2) retrieval augmented generation (RAG) is becoming prevalent. When processing long inputs in RAG, the prefill phase of computing th...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MatKV: Trading Compute for Flash Storage in LLM Inference â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆ**RAG**ï¼‰çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆ**LLM**ï¼‰æ¨ç†ä¸­ï¼Œè¾“å…¥æ–‡æœ¬é€šå¸¸å¾ˆé•¿ï¼ˆå¦‚ä¸Šåƒä¸ªtokenï¼‰ï¼Œå¯¼è‡´ **prefill é˜¶æ®µ**ï¼ˆå³è®¡ç®—æ‰€æœ‰è¾“å…¥tokençš„Key-Valueå‘é‡ï¼‰æˆä¸ºæ€§èƒ½ç“¶é¢ˆã€‚è¯¥é˜¶æ®µé«˜åº¦ä¾èµ–GPUè¿›è¡Œå¯†é›†è®¡ç®—ï¼Œé€ æˆé«˜å»¶è¿Ÿã€é«˜èƒ½è€—å’Œé«˜æ˜‚æˆæœ¬ã€‚

æ­¤å¤–ï¼Œè®¸å¤šRAGå¯¹è±¡ï¼ˆå¦‚æ–‡æ¡£å—ï¼‰è¢«åå¤æ£€ç´¢ï¼Œä½†æ¯æ¬¡ä»éœ€é‡æ–°è®¡ç®—å…¶KVç¼“å­˜ï¼Œé€ æˆå¤§é‡å†—ä½™è®¡ç®—ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šMatKV
ä½œè€…æå‡º **MatKV**ï¼Œä¸€ç§é€šè¿‡å°†è®¡ç®—ä»»åŠ¡â€œäº¤æ˜“â€ç»™å­˜å‚¨æ¥ä¼˜åŒ–LLMæ¨ç†æ•ˆç‡çš„æ–°èŒƒå¼ï¼š

- **é¢„è®¡ç®—å¹¶ç‰©åŒ–ï¼ˆmaterializeï¼‰KVç¼“å­˜**ï¼šå½“æ–‡æ¡£æ’å…¥å‘é‡æ•°æ®åº“æ—¶ï¼Œä¸€æ¬¡æ€§ä½¿ç”¨GPUè®¡ç®—å…¶KVå‘é‡ï¼Œå¹¶å°†å…¶æŒä¹…åŒ–å­˜å‚¨åœ¨å»‰ä»·ä½†é«˜é€Ÿçš„**Flash SSD**ä¸Šã€‚
- **æ¨ç†æ—¶å¤ç”¨**ï¼šåœ¨åç»­RAGæŸ¥è¯¢ä¸­ï¼Œç›´æ¥ä»SSDåŠ è½½å·²ç‰©åŒ–çš„KVç¼“å­˜åˆ°GPUå†…å­˜ï¼Œè·³è¿‡æ˜‚è´µçš„prefillè®¡ç®—è¿‡ç¨‹ã€‚
- å®ç°äº† **â€œä»¥å­˜å‚¨æ¢è®¡ç®—â€**ï¼ˆTrading Compute for Storageï¼‰çš„è®¾è®¡ç†å¿µã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚KV Cachingï¼‰ | MatKV |
|--------|--------------------------|-------|
| å­˜å‚¨ä»‹è´¨ | ä¸»è¦ä¾èµ–DRAMç¼“å­˜ | ä½¿ç”¨ä½æˆæœ¬ã€å¤§å®¹é‡çš„Flash SSD |
| å¯æ‰©å±•æ€§ | å—é™äºæœ‰é™ä¸”æ˜‚è´µçš„DRAM | æ”¯æŒTBçº§KVç¼“å­˜ï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½² |
| æˆæœ¬æ•ˆç›Š | é«˜é¢‘è®¿é—®æ‰åˆ’ç®— | æå‡ºâ€œåå¤©è§„åˆ™â€ï¼Œé‡åŒ–ç»æµæ€§é˜ˆå€¼ |
| æ€§èƒ½æ½œåŠ› | ç¼“å­˜å‘½ä¸­æå‡æ•ˆç‡ | å¯å®ç°**è§£ç ä¸KVåŠ è½½é‡å **ï¼Œéšè—I/Oå»¶è¿Ÿ |
| ç¡¬ä»¶é€‚é…æ€§ | ä¾èµ–é«˜ç«¯GPU | å…è®¸ä½ç«¯GPUç”šè‡³CPUæ‰§è¡Œé«˜æ•ˆæ¨ç† |

> âœ… **æ ¸å¿ƒåˆ›æ–°ç‚¹**ï¼š
> - é¦–æ¬¡ç³»ç»Ÿæ€§è®ºè¯äº†ä½¿ç”¨**å¤–éƒ¨Flashå­˜å‚¨**æ›¿ä»£GPUè®¡ç®—KVç¼“å­˜çš„å¯è¡Œæ€§ã€é«˜æ•ˆæ€§å’Œç»æµæ€§ï¼›
> - æå‡º **decoupling prefill and decode** æ¶æ„ï¼Œæ”¯æŒKVåŠ è½½ä¸è§£ç å¹¶å‘æ‰§è¡Œï¼›
> - æ¨å¯¼å‡º **â€œåå¤©è§„åˆ™â€**ï¼ˆTen-Day Ruleï¼‰ï¼Œä¸ºæ˜¯å¦ç‰©åŒ–æä¾›å†³ç­–ä¾æ®ï¼›
> - å±•ç¤ºäº†MatKVä½¿ä½åŠŸè€—/ä½ç«¯ç¡¬ä»¶ä¹Ÿèƒ½èƒœä»»é•¿ä¸Šä¸‹æ–‡RAGä»»åŠ¡çš„å¯èƒ½æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | ç”¨é€” |
|------|------|
| **TurboRAG** | æµ‹é‡ç³»ç»Ÿå»¶è¿Ÿä¸åŠŸè€—ï¼Œå¹³å‡queryçº¦17.67 tokensï¼Œdocumentçº¦767.73 tokens |
| **LongBench**ï¼ˆå­é›†ï¼‰ï¼š<br>- 2WikiMultihopQA<br>- TriviaQA<br>- HotpotQA | è¯„ä¼°é—®ç­”å‡†ç¡®ç‡ï¼ˆF1 Scoreï¼‰ï¼Œæ¶µç›–å¤šè·³æ¨ç†ä¸å°‘æ ·æœ¬åœºæ™¯ |

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼š
  - LLaMA 3.1 70Bï¼ˆ4-bité‡åŒ–ï¼‰ã€LLaMA 3.1 8Bã€LLaMA 3.2 3B
- **ç¡¬ä»¶å¹³å°**ï¼š
  - **H100æœåŠ¡å™¨**ï¼šNVIDIA H100 GPUï¼ˆ80GB HBMï¼‰ï¼ŒIntel Xeon Gold CPUï¼Œ2TB DRAM
  - **RTX 4090å¹³å°**ï¼šå•å¡24GBæ˜¾å­˜ï¼Œç”¨äºéªŒè¯ä½ç«¯GPUè¡¨ç°
- **SSDé…ç½®**ï¼š
  - H100ç«¯ï¼š4Ã—Samsung 9100 Pro SSDï¼ˆRAID-0ï¼Œè¯»å¸¦å®½~58.8GB/sï¼‰
  - RTX 4090ç«¯ï¼š1Ã—Samsung PM9A3 SSDï¼ˆ6.5GB/sï¼‰
- **Chunkå¤§å°**ï¼šé»˜è®¤1,024 tokens

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|-----|------|
| **Latency** | åˆ†è§£ä¸ºLoad Timeã€Prefill Timeã€Decode Timeï¼›å…³æ³¨ç«¯åˆ°ç«¯å“åº”æ—¶é—´ |
| **Power Consumption** | ç³»ç»Ÿæ€»åŠŸè€—ï¼ˆIPMIæµ‹é‡ï¼‰ä¸GPUå•ç‹¬åŠŸè€—ï¼ˆnvidia-smiï¼‰ |
| **Energy Usage** | åŠŸè€—å¯¹æ—¶é—´ç§¯åˆ†ï¼ˆå•ä½ï¼škJï¼‰ |
| **Throughput** | æ‰¹å¤„ç†ä¸‹çš„è¯·æ±‚ååé‡ |
| **Accuracy** | ä½¿ç”¨F1 Scoreè¡¡é‡ç”Ÿæˆç­”æ¡ˆè´¨é‡ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Vanilla**ï¼šæ ‡å‡†RAGæµç¨‹ï¼Œæ¯æ¬¡å‡åœ¨GPUä¸Šå®Œæ•´è®¡ç®—KVï¼ˆFull KV Recomputationï¼‰
- **CacheBlend** [12]ï¼šéƒ¨åˆ†å¤ç”¨ç¼“å­˜å¹¶èåˆæ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨å‡†ç¡®ç‡ä¸Šæœ‰è½»å¾®ä¼˜åŠ¿
- ï¼ˆéšå«å¯¹æ¯”ï¼‰ä¼ ç»ŸKV Cachingæ–¹æ¡ˆï¼ˆå¦‚PromptCacheã€RAGCacheï¼‰â€”â€”ä»…åŸºäºDRAM

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| æŒ‡æ ‡ | MatKV vs. Vanillaï¼ˆH100 + RAID SSDï¼‰ | å¤‡æ³¨ |
|------|------------------------------------|------|
| **Prefillæ—¶é—´** | â†“ è¶…è¿‡50% | å›¾5æ˜¾ç¤ºMatKV prefill < 0.5sï¼ŒVanilla > 1s |
| **æ€»ä½“æ¨ç†å»¶è¿Ÿ** | â†“ ~70%ï¼ˆå•è¯·æ±‚ï¼‰<br>â†‘ è¾¾ **2Ã—åŠ é€Ÿ**ï¼ˆæ‰¹å¤„ç†+é‡å ï¼‰ | å›¾7æ˜¾ç¤ºé‡å åè¾¾2å€é€Ÿåº¦æå‡ |
| **ç³»ç»Ÿæ€»èƒ½è€—** | â†“ **50%ä»¥ä¸Š** | è¡¨IVï¼šVanilla 566 kJ â†’ MatKV 289 kJ |
| **GPUèƒ½è€—** | â†“ **~53%** | è¡¨Vï¼šVanilla 185 kJ â†’ MatKV 95 kJ |
| **åŠ è½½æ—¶é—´ï¼ˆ1Ã— vs 4Ã— SSDï¼‰** | å•ç›˜ï¼š93ms â†’ å››ç›˜RAIDï¼š27ms | è¡¨IIIï¼Œä½“ç°SSDå¸¦å®½é‡è¦æ€§ |
| **ä¸CacheBlendæ¯”è¾ƒ** | åŠ è½½å¿«37%ï¼ŒTFTTå¿«41% | MatKVæ›´è½»é‡ï¼Œæ— èåˆå¼€é”€ |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ **LLaMA 3.1 70B + 2Ã—1024-tokenè¾“å…¥ + 20-tokenè¾“å‡º** åœºæ™¯ä¸‹ï¼š
  - MatKV å°† **prefillæ—¶é—´å‡å°‘è‡³Vanillaçš„ä¸€åŠä»¥ä¸‹**
  - ç»“åˆ**æ‰¹å¤„ç†ä¸é‡å æ‰§è¡Œ**ï¼Œå®ç°æœ€é«˜ **2å€çš„æ•´ä½“åŠ é€Ÿ**
  - **ç³»ç»Ÿçº§èƒ½é‡æ¶ˆè€—é™ä½ä¸€åŠ**

- åœ¨ä¸åŒbatch sizeä¸‹ï¼ˆå›¾6ï¼‰ï¼š
  - å½“batch size â‰¥ 8æ—¶ï¼Œdecodeä¸å†æ˜¯ç“¶é¢ˆï¼Œprefillä¸»å¯¼å»¶è¿Ÿ
  - æ­¤æ—¶MatKVä¼˜åŠ¿æ˜¾è‘—æ”¾å¤§ï¼Œå¯è¾¾2å€åŠ é€Ÿ

- åœ¨ä¸åŒè¾“å‡ºé•¿åº¦ä¸‹ï¼ˆå›¾8bï¼‰ï¼š
  - è¾“å‡ºè¶Šé•¿ï¼Œdecodeå æ¯”è¶Šé«˜ï¼ŒMatKVç›¸å¯¹å¢ç›Šä¸‹é™
  - ä½†ä»ä¿æŒç»å¯¹æ€§èƒ½é¢†å…ˆï¼ˆå§‹ç»ˆå¿«äºVanillaï¼‰

### æ¨¡å‹è§„æ¨¡å½±å“ï¼ˆå›¾9ï¼‰
- éšç€æ¨¡å‹å¢å¤§ï¼ˆ3B â†’ 70Bï¼‰ï¼š
  - KVè®¡ç®—æˆæœ¬å¢é•¿è¿œè¶…KVç¼“å­˜ä½“ç§¯å¢é•¿
  - MatKVå¸¦æ¥çš„**å½’ä¸€åŒ–æ‰§è¡Œæ—¶é—´æ”¶ç›ŠæŒç»­ä¸Šå‡**
  - è¯´æ˜MatKVåœ¨æ›´å¤§æ¨¡å‹ä¸Šæ›´å…·ä¼˜åŠ¿

### ä½é˜¶GPUä¸Šçš„è¡¨ç°ï¼ˆå›¾10ï¼‰
- ä½¿ç”¨ **RTX 4090ï¼ˆ$1.6Kï¼‰ vs H100ï¼ˆ$50Kï¼‰**
- MatKV on RTX 4090 æ¯” Full KV on H100 ä»…æ…¢ **1.5Ã—**
- è€Œ Vanilla on RTX 4090 æ¯” H100 æ…¢ **3Ã—**
- è¡¨æ˜ï¼š**MatKVæå¤§ç¼©å°äº†é«˜ä½ç«¯GPUä¹‹é—´çš„æ€§èƒ½å·®è·**ï¼Œæ¨åŠ¨ä½æˆæœ¬éƒ¨ç½²

### å‡†ç¡®ç‡è¯„ä¼°ï¼ˆè¡¨VIï¼‰
| Dataset | Vanilla (F1) | MatKV (F1) | å˜åŒ– |
|--------|-------------|-----------|------|
| 2WikiMQA | 0.278 | 0.241 | â†“ ~13% |
| TriviaQA | 0.786 | 0.812 | â†‘ ~3.3% |
| HotpotQA | 0.353 | 0.302 | â†“ ~14% |

> âš ï¸ æ€»ä½“æ¥çœ‹ï¼ŒMatKVåœ¨å¤šæ•°ä»»åŠ¡ä¸­ä¿æŒå¯æ¥å—ç²¾åº¦ï¼Œä¸ªåˆ«ä»»åŠ¡ç•¥æœ‰ä¸‹é™ï¼Œä½†æœªå‡ºç°ä¸¥é‡é€€åŒ–ã€‚ä½œè€…è§£é‡Šï¼šç‹¬ç«‹åŠ è½½å„chunké¿å…äº†â€œä¸­é—´ä¸¢å¤±â€é—®é¢˜ï¼ˆLost in the Middleï¼‰ï¼Œåè€Œå¯èƒ½æå‡æŸäº›ä»»åŠ¡è¡¨ç°ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **Flash SSDå¯ä»¥é«˜æ•ˆæ›¿ä»£GPUè¿›è¡ŒKVè®¡ç®—**  
   åœ¨RAGåœºæ™¯ä¸­ï¼ŒSSDè¯»å–KVçš„é€Ÿåº¦å’Œèƒ½æ•ˆè¿œä¼˜äºGPUé‡æ–°è®¡ç®—ï¼Œå°¤å…¶é€‚ç”¨äºé•¿è¾“å…¥ã€é«˜é¢‘è®¿é—®åœºæ™¯ã€‚

2. âœ… **MatKVæ˜¾è‘—é™ä½å»¶è¿Ÿä¸èƒ½è€—**  
   å®éªŒè¡¨æ˜ï¼Œç›¸æ¯”Vanillaæ–¹æ³•ï¼ŒMatKVå¯å°†**æ¨ç†æ—¶é—´å‡åŠã€ç³»ç»Ÿèƒ½è€—é™ä½50%ä»¥ä¸Š**ã€‚

3. âœ… **æ”¯æŒè§£ç ä¸KVåŠ è½½é‡å ï¼ˆOverlapï¼‰**  
   åˆ©ç”¨MatKVè§£è€¦prefillä¸decodeçš„ç‰¹ç‚¹ï¼Œå¯åœ¨å½“å‰batchè§£ç çš„åŒæ—¶é¢„åŠ è½½ä¸‹ä¸€batchçš„KVï¼Œæœ‰æ•ˆéšè—I/Oå»¶è¿Ÿã€‚

4. âœ… **å¯ç”¨ä½æˆæœ¬ç¡¬ä»¶æ¨ç†**  
   ä¸€æ—¦KVè¢«ç‰©åŒ–å¹¶å¿«é€ŸåŠ è½½ï¼Œ**ä½ç«¯GPUç”šè‡³CPUä¹Ÿå¯æ‰¿æ‹…é«˜è´¨é‡RAGæ¨ç†ä»»åŠ¡**ï¼Œå¤§å¹…é™ä½éƒ¨ç½²é—¨æ§›ã€‚

5. âœ… **ç»æµæ€§æ˜ç¡®ï¼šâ€œåå¤©è§„åˆ™â€æˆç«‹**  
   æ¨å¯¼å‡ºBreak-evenå…¬å¼ï¼Œå¾—å‡ºç»“è®ºï¼šè‹¥ä¸€ä¸ªæ–‡æ¡£æ¯**10å¤©è‡³å°‘è¢«è®¿é—®ä¸€æ¬¡**ï¼Œåˆ™ç‰©åŒ–å…¶KVæ¯”æ¯æ¬¡éƒ½è®¡ç®—æ›´ä¾¿å®œã€‚

6. âœ… **æŠ€æœ¯è¶‹åŠ¿åˆ©å¥½MatKVé•¿æœŸå‘å±•**  
   SSDå¸¦å®½å¢é€Ÿï¼ˆ~30x/decadeï¼‰è¿œè¶…GPU FLOPSå¢é€Ÿï¼ˆ~10x/decadeï¼‰ï¼Œæœªæ¥â€œå­˜å‚¨æ¢è®¡ç®—â€çš„æ€§ä»·æ¯”å°†æŒç»­æ‰©å¤§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- â— **å†·å¯åŠ¨é—®é¢˜**ï¼šé¦–æ¬¡æ’å…¥çš„æ–°æ–‡æ¡£éœ€ç»å†å®Œæ•´prefill+å†™å…¥æµç¨‹ï¼Œé¦–è®¿å»¶è¿Ÿè¾ƒé«˜
- â— **å­˜å‚¨å¼€é”€å¤§**ï¼šå…¨é‡ç‰©åŒ–ï¼ˆMaterialize-Allï¼‰ç­–ç•¥å¯èƒ½å¯¼è‡´TB/PBçº§å­˜å‚¨éœ€æ±‚
- â— **å‡†ç¡®æ€§æ³¢åŠ¨**ï¼šç¼ºå°‘è·¨æ–‡æ¡£self-attentionï¼Œå¯èƒ½å½±å“å¤æ‚å¤šè·³æ¨ç†ä»»åŠ¡çš„è¡¨ç°
- â— **å½“å‰å‡è®¾ç®€åŒ–**ï¼šé‡‡ç”¨â€œç«‹å³ç‰©åŒ–æ‰€æœ‰æ–‡æ¡£â€ç­–ç•¥ï¼Œæœªå¼•å…¥æ™ºèƒ½ç¼“å­˜æ·˜æ±°æˆ–é¢„æµ‹æœºåˆ¶

### æœªæ¥å·¥ä½œæ–¹å‘
1. **é€‰æ‹©æ€§ç‰©åŒ–ç­–ç•¥**ï¼šç»“åˆè®¿é—®é¢‘ç‡ã€çƒ­åº¦é¢„æµ‹ç­‰åŠ¨æ€å†³å®šå“ªäº›KVå€¼å¾—ç¼“å­˜
2. **KVå‹ç¼©æŠ€æœ¯é›†æˆ**ï¼šåº”ç”¨MiniCacheã€xKVç­‰å‹ç¼©ç®—æ³•è¿›ä¸€æ­¥é™ä½å­˜å‚¨æˆæœ¬
3. **åˆ†å±‚å­˜å‚¨æ¶æ„**ï¼šæ„å»ºDRAM-SSD-Archiveä¸‰çº§KVç¼“å­˜ä½“ç³»ï¼Œå¹³è¡¡æ€§èƒ½ä¸æˆæœ¬
4. **æ‰©å±•è‡³å…¶ä»–ä»»åŠ¡**ï¼šæ¢ç´¢åœ¨Agent AIã€Text-to-SQLã€In-Context Learningç­‰é‡å¤ä½¿ç”¨é•¿æ–‡æœ¬çš„åœºæ™¯ä¸­çš„åº”ç”¨
5. **æ”¯æŒå¢é‡æ›´æ–°**ï¼šå½“æ–‡æ¡£å˜æ›´æ—¶å¦‚ä½•é«˜æ•ˆæ›´æ–°å…¶KVç¼“å­˜

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **MatKVå¼€åˆ›æ€§åœ°å°†LLMæ¨ç†ä¸­çš„KVè®¡ç®—å¸è½½åˆ°é«˜æ€§èƒ½Flashå­˜å‚¨ï¼Œå®ç°äº†â€œä»¥å­˜å‚¨æ¢è®¡ç®—â€çš„æ–°èŒƒå¼ï¼Œåœ¨ä¸ç‰ºç‰²å¤ªå¤šå‡†ç¡®æ€§çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†RAGç³»ç»Ÿçš„é€Ÿåº¦ã€èƒ½æ•ˆå’Œç»æµæ€§ï¼Œä¸ºå¤§è§„æ¨¡ç”Ÿæˆå¼AIçš„å¯æŒç»­éƒ¨ç½²æä¾›äº†æ–°è·¯å¾„ã€‚**

</details>

---

### 3. [DiRL: An Efficient Post-Training Framework for Diffusion Language Models](https://arxiv.org/abs/2512.22234)

**Authors**: Ying Zhu, Jiaxin Wan, Xiaoran Liu, Siyanag He, Qiqi Wang, Xu Guo, Tianyi Liang, Zengfeng Huang, Ziwei He, Xipeng Qiu  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2512.22234v1  

#### Abstract
Diffusion Language Models (dLLMs) have emerged as promising alternatives to Auto-Regressive (AR) models. While recent efforts have validated their pre-training potential and accelerated inference speeds, the post-training landscape for dLLMs remains underdeveloped. Existing methods suffer from compu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDiRL: An Efficient Post-Training Framework for Diffusion Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰ **Diffusion Language Models (dLLMs)** åœ¨é¢„è®­ç»ƒå’Œæ¨ç†æ•ˆç‡æ–¹é¢å·²å–å¾—è¿›å±•ï¼Œä½†åœ¨**åè®­ç»ƒï¼ˆpost-trainingï¼‰é˜¶æ®µ**ï¼Œå°¤å…¶æ˜¯**å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰** æ–¹é¢ä»é¢ä¸´ä¸¥é‡æŒ‘æˆ˜ï¼š
- **è®¡ç®—ä½æ•ˆ**ï¼šä¼ ç»Ÿ dLLMs ç¼ºä¹ KV Cache æ”¯æŒï¼Œå¯¼è‡´æ¨ç†å’Œè®­ç»ƒå¼€é”€å·¨å¤§ã€‚
- **ç›®æ ‡ä¸ä¸€è‡´ï¼ˆObjective Mismatchï¼‰**ï¼šè®­ç»ƒæ—¶ä½¿ç”¨çš„éšæœºæ©ç ç­–ç•¥ä¸å®é™…æ¨ç†è·¯å¾„ä¸ä¸€è‡´ï¼Œé€ æˆ logits åå·®ã€‚
- **ç¼ºä¹é«˜æ•ˆçš„è®­ç»ƒ-æ¨ç†ååŒè®¾è®¡**ï¼šç°æœ‰æ–¹æ³•å¤šé‡‡ç”¨ç¦»çº¿æ¨¡å‹åŠ è½½ï¼ŒIO å¼€é”€å¤§ï¼Œéš¾ä»¥æ”¯æŒåœ¨çº¿æ›´æ–°å’Œé«˜æ•ˆ rolloutã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº† dLLMs åœ¨å¤æ‚ä»»åŠ¡ï¼ˆå¦‚æ•°å­¦æ¨ç†ï¼‰ä¸Šçš„è¡¨ç°ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

ä½œè€…æå‡º **DiRL** â€”â€” ä¸€ä¸ªé«˜æ•ˆçš„ dLLM åè®­ç»ƒæ¡†æ¶ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šå®ç°é¦–ä¸ªæ— åçš„ **Group Relative Policy Optimization (GRPO)** ç®—æ³•å˜ä½“ï¼š**DiPO**ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

| åˆ›æ–°æ¨¡å— | æŠ€æœ¯ç»†èŠ‚ |
|--------|---------|
| **DiRL æ¡†æ¶** | ç»“åˆ **FlexAttention åŠ é€Ÿçš„ blockwise è®­ç»ƒ** ä¸ **LMDeploy ä¼˜åŒ–çš„æ¨ç†å¼•æ“**ï¼Œæ„å»ºç«¯åˆ°ç«¯é«˜æ•ˆçš„ SFT â†’ RL ä¸¤é˜¶æ®µåè®­ç»ƒæµç¨‹ã€‚ |
| **DiPO ç®—æ³•** | é¦–ä¸ªåœ¨ dLLMs ä¸Šå®ç°çš„**æ— å GRPO æ–¹æ³•**ï¼Œåˆ©ç”¨ blockwise dLLM çš„ç»“æ„ç‰¹æ€§è¿›è¡Œç²¾ç¡®ã€é«˜æ•ˆçš„ logits è®¡ç®—ï¼Œé¿å…é‡‡æ ·å¸¦æ¥çš„é«˜æ–¹å·®å’Œåå·®ã€‚ |
| **åœ¨çº¿æ¨¡å‹æ›´æ–°æœºåˆ¶** | é€šè¿‡ LMDeploy çš„ in-place å‚æ•°æ›´æ–° APIï¼Œæ¶ˆé™¤æ¯æ­¥è®­ç»ƒä¸­çš„ç£ç›˜ I/Oï¼ˆæ— éœ€é‡å¤ load/save æ¨¡å‹ï¼‰ï¼Œæ˜¾è‘—æå‡è®­ç»ƒååã€‚ |
| **è®­ç»ƒ-æ¨ç†ä¸€è‡´æ€§è®¾è®¡** | ç»Ÿä¸€ä½¿ç”¨ blockwise æ¨ç†æ¨¡å¼è¿›è¡Œ rollout å’Œè®­ç»ƒï¼Œç¡®ä¿è®­ç»ƒç›®æ ‡ä¸å®é™…æ¨ç†è·¯å¾„å¯¹é½ã€‚ |

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| å¯¹æ¯”ç»´åº¦ | DiRL vs. ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ TraceRLï¼‰ |
|--------|-------------------------------|
| **è®­ç»ƒæ•ˆç‡** | å¼•å…¥ FlexAttention å¤„ç†å¤æ‚ attention maskï¼Œè®­ç»ƒå»¶è¿Ÿé™ä½è¿‘ **6Ã—**ï¼›æ•´ä½“æ¯æ­¥è®­ç»ƒæ—¶é—´å‡å°‘ **2.5Ã—**ã€‚ |
| **ç®—æ³•ç²¾åº¦** | å®ç°**æ— å logits è®¡ç®—**ï¼Œé¦–æ¬¡å°† GRPO æˆåŠŸåº”ç”¨äº dLLMsï¼Œä¼˜äºåŸºäºè¿‘ä¼¼é‡‡æ ·çš„æ–¹æ³•ï¼ˆå¦‚ diffu-GRPOï¼‰ã€‚ |
| **ç³»ç»Ÿé›†æˆåº¦** | ç´§å¯†è€¦åˆè®­ç»ƒï¼ˆLLaMA-Factoryï¼‰ä¸æ¨ç†ï¼ˆLMDeployï¼‰ï¼Œæ”¯æŒ**å®æ—¶ rollout å’Œåœ¨çº¿ç­–ç•¥æ›´æ–°**ï¼Œå·¥ç¨‹å®ç”¨æ€§æ›´å¼ºã€‚ |
| **æ€§èƒ½è¡¨ç°** | åœ¨å¤šä¸ªæ•°å­¦åŸºå‡†ä¸Šè¶…è¶ŠåŒè§„æ¨¡åŠæ›´å¤§è§„æ¨¡çš„ AR æ¨¡å‹ï¼ˆå¦‚ Qwen2.5-32B-Instructï¼‰ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

| é˜¶æ®µ | æ•°æ®é›† | æè¿° |
|------|-------|------|
| **SFT é˜¶æ®µ** | `OpenR1-Math`ï¼ˆè’¸é¦è‡ª GLM-4.6ï¼‰ | é«˜è´¨é‡æ•°å­¦æ¨ç†æ•°æ®ï¼Œç”¨äºç›‘ç£å¾®è°ƒã€‚ |
| **RL é˜¶æ®µ** | `Big-Math`ï¼ˆç» math-verify éªŒè¯ï¼‰ | å¤§è§„æ¨¡ã€é«˜è´¨é‡æ•°å­¦æ•°æ®é›†ï¼Œä¸“ä¸º RL è®¾è®¡ï¼Œç¡®ä¿å¥–åŠ±ä¿¡å·å¯é ã€‚ |

> æ‰€æœ‰æ ·æœ¬æœ€å¤§é•¿åº¦é™åˆ¶ä¸º **8k tokens**ï¼Œæ˜¯ç›®å‰ dLLMs ä¸­æŠ¥é“çš„æœ€é•¿ä¸Šä¸‹æ–‡ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

| é¡¹ç›® | è®¾ç½®è¯¦æƒ… |
|------|----------|
| **åŸºç¡€æ¨¡å‹** | åŸºäº `SDAR-8B-Chat` è¿›è¡Œåè®­ç»ƒ |
| **æ¨¡å‹åç§°** | `DiRL-8B-Instruct` |
| **è®­ç»ƒæµç¨‹** | ä¸¤é˜¶æ®µï¼šSFT â†’ RLï¼ˆDiPOï¼‰ |
| **SFT è®¾ç½®** |  
- å·¥å…·ï¼šLLaMA-Factory  
- ç¡¬ä»¶ï¼š8Ã—H200 GPUs  
- Batch sizeï¼š512  
- å­¦ä¹ ç‡ï¼š1e-5ï¼ˆcosine è¡°å‡ï¼‰  
- æ­¥æ•°ï¼š100 æ­¥  

| **RL è®¾ç½®** |  
- å·¥å…·ï¼šDiRL + Accelerate  
- ç¡¬ä»¶ï¼š128Ã—H200 GPUs  
- Rollout æ•°é‡ï¼šæ¯ä¸ªé—®é¢˜ç”Ÿæˆ 32 æ¡è½¨è¿¹  
- Batch sizeï¼š128  
- å­¦ä¹ ç‡ï¼š1e-6  
- æ­¥æ•°ï¼š40 æ­¥  
- å‚è€ƒç­–ç•¥ï¼šSFT æ¨¡å‹ï¼ˆfixedï¼‰  

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | å†…å®¹ |
|------|------|
| **Accuracy** | åœ¨å¤šä¸ªæ•°å­¦ä»»åŠ¡ä¸Šçš„å‡†ç¡®ç‡ |
| **Average Score** | å¤šä»»åŠ¡å¹³å‡å¾—åˆ† |
| **Decoding Tokens / Step** | å¹³å‡æ¯æ­¥è§£ç  token æ•°ï¼Œåæ˜ æ¨ç†æ•ˆç‡ |
| **Output Length** | è¾“å‡ºé•¿åº¦ï¼Œè¡¡é‡æ¨ç†æ·±åº¦ |
| **Dynamic Decoding** | ä½¿ç”¨é˜ˆå€¼ï¼ˆå¦‚ 0.9ï¼‰æå‰è§£ç é«˜ç½®ä¿¡åº¦ tokenï¼Œæµ‹è¯•ä¸åŒç­–ç•¥ä¸‹çš„é²æ£’æ€§ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿æ¨¡å‹ | ç±»å‹ | è¯´æ˜ |
|--------|------|------|
| `Qwen2.5-7B/32B-Instruct` | AR æ¨¡å‹ | å½“å‰ä¸»æµè‡ªå›å½’æ¨¡å‹ï¼Œä½œä¸ºå¤–éƒ¨å‚è€ƒ |
| `SDAR-8B-Chat` | blockwise dLLM | åŸå§‹ base æ¨¡å‹ |
| `TraDo-8B-Instruct` | dLLM + RLï¼ˆTraceRLï¼‰ | å½“å‰æœ€å…ˆè¿›çš„ dLLM å¼ºåŒ–å­¦ä¹ æ–¹æ³• |
| `+Dynamic` | åŠ¨æ€è§£ç ç‰ˆæœ¬ | ä½¿ç”¨ top-1 æ¦‚ç‡ > 0.9 çš„ token æå‰è¾“å‡º |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| æ¨¡å‹ | MATH500 | GSM8k | AIME2024 | AIME2025 | OlympiadBench | **Avg.** |
|------|--------|-------|---------|---------|--------------|----------|
| Qwen2.5-7B-Instruct | 73.8 | 89.8 | 9.0 | 5.6 | 36.6 | 42.9 |
| Qwen2.5-32B-Instruct | 81.1 | 94.0 | 12.9 | 11.9 | 45.7 | 49.1 |
| SDAR-8B-Chat | 71.5 | 89.5 | 5.6 | 8.5 | 35.6 | 42.2 |
| TraDo-8B-Instruct | 76.7 | 90.4 | 11.5 | 13.5 | 40.2 | 46.5 |
| **DiRL-8B-Instruct (Ours)** | **85.1** | **93.1** | **21.5** | **22.9** | **47.3** | **54.0** |

> âœ… **DiRL-8B-Instruct åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡è¾¾åˆ° SOTA æ€§èƒ½ï¼Œå¹³å‡åˆ† 54.0ï¼Œè¶…è¶Šæ›´å¤§çš„ Qwen2.5-32B-Instructï¼ˆ49.1ï¼‰**

---

### ğŸ” æ•ˆç‡å¯¹æ¯”ï¼ˆFigure 6 & 7ï¼‰

| æŒ‡æ ‡ | DiRL vs. TraceRL |
|------|------------------|
| **Rollout æ—¶é—´** | æå‡çº¦ 1.08Ã—ï¼ˆå› å…±ç”¨ JetEngineï¼‰ |
| **Training æ—¶é—´** | **é™ä½ 5.94Ã—**ï¼ˆå¾—ç›Šäº FlexAttentionï¼‰ |
| **æ€»è€—æ—¶/step** | **å‡å°‘ 2.55Ã—** |
| **8B æ¨¡å‹è®­ç»ƒå»¶è¿Ÿ** | ä½äº TraceRL çš„ 1.7B æ¨¡å‹ï¼Œæ˜¾ç¤ºæå¼ºæ‰©å±•æ€§ |

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆFigure 8ï¼‰

è¿›è¡Œäº†å…³äº **åŠ¨æ€è§£ç é˜ˆå€¼ $ \tau $** çš„æ¶ˆèç ”ç©¶ï¼ˆèŒƒå›´ 0.5 ~ 0.99ï¼‰ï¼š

| å‘ç° | è¯´æ˜ |
|------|------|
| **DiRL-8B-Instruct è¡¨ç°æœ€ç¨³å®šä¸”æŒç»­é¢†å…ˆ** | å³ä½¿åœ¨ä¸åŒ $ \tau $ ä¸‹ä¹Ÿæ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œè¯æ˜å…¶ä¼˜åŠ¿æ¥è‡ªé«˜è´¨é‡æ¨ç†è·¯å¾„è€Œéè¶…å‚æ•æ„Ÿæ€§ |
| **æ€§èƒ½éš $ \tau $ å¢åŠ è€Œä¸Šå‡** | æ›´ä¿å®ˆçš„è§£ç ç­–ç•¥å¸¦æ¥æ›´ä¼˜ç»“æœï¼Œè¡¨æ˜æ¨¡å‹å…·å¤‡è‰¯å¥½ç½®ä¿¡åº¦æ ¡å‡†èƒ½åŠ› |
| **æœ€ä¼˜å¹³è¡¡ç‚¹ä¸º $ \tau = 0.9 $** | è¢«é€‰ä¸ºä¸»å®éªŒè®¾ç½®ï¼Œå…¼é¡¾æ•ˆç‡ä¸å‡†ç¡®æ€§ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **DiRL å®ç°äº† dLLMs ä¸Šé«˜æ•ˆä¸”ä¸€è‡´çš„åè®­ç»ƒé—­ç¯**ï¼š
   - é€šè¿‡ **blockwise ç»“æ„ + FlexAttention + LMDeploy** å®ç°è®­ç»ƒ-æ¨ç†ä¸€è‡´æ€§ä¸é«˜ååã€‚
   
2. **DiPO æ˜¯é¦–ä¸ªæ— å GRPO å®ç°**ï¼š
   - å…‹æœäº†ä¼ ç»Ÿ dLLM ä¸­ logits ä¸å¯ç²¾ç¡®è®¡ç®—çš„é—®é¢˜ï¼Œä¸º dLLM çš„ RL å¯¹é½æä¾›äº†æ–°èŒƒå¼ã€‚

3. **DiRL-8B-Instruct æˆä¸ºå½“å‰æœ€å¼ºæ•°å­¦æ¨ç† dLLM**ï¼š
   - ä¸ä»…è¶…è¶ŠåŒç±» dLLMsï¼Œè¿˜**è¶…è¿‡æ›´å¤§è§„æ¨¡çš„ AR æ¨¡å‹ï¼ˆQwen2.5-32Bï¼‰**ï¼ŒéªŒè¯äº†æ‰©æ•£æ¶æ„åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„æ½œåŠ›ã€‚

4. **é•¿è¾“å‡ºé•¿åº¦è¡¨æ˜æ›´å¼ºçš„æ¨ç†èƒ½åŠ›**ï¼š
   - DiRL ç”Ÿæˆçš„å¹³å‡è¾“å‡ºæ›´é•¿ï¼Œè¯´æ˜å…¶èƒ½å®Œæˆæ›´å¤æ‚çš„æ•°å­¦æ¨å¯¼è¿‡ç¨‹ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

1. **ä¸Šä¸‹æ–‡é•¿åº¦ä»å—é™**ï¼š
   - å½“å‰æœ€å¤§æ”¯æŒ 8k tokensï¼Œè™½å·²æ˜¯ dLLM æœ€é•¿è®°å½•ï¼Œä½†ä»çŸ­äºå…ˆè¿› AR æ¨¡å‹ï¼ˆå¦‚æ”¯æŒ 32k+ï¼‰ã€‚

2. **å°šæœªæ¢ç´¢ Test-Time Scaling æˆ– Chain-of-Thought æ‰©å±•æŠ€æœ¯**ï¼š
   - å¦‚æ€ç»´æ ‘ï¼ˆToTï¼‰ã€è‡ªæ´½æ€§ï¼ˆSelf-Consistencyï¼‰ç­‰æœªè¢«å¼•å…¥ï¼Œå¯èƒ½è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚

3. **åº”ç”¨é›†ä¸­åœ¨æ•°å­¦é¢†åŸŸ**ï¼š
   - å°šæœªåœ¨ä»£ç ç”Ÿæˆã€Agent ä»»åŠ¡ç­‰å…¶ä»–å¤æ‚åœºæ™¯ä¸­å¹¿æ³›éªŒè¯ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³æ›´å¤§è§„æ¨¡æ¨¡å‹**ï¼ˆå¦‚ 65B+ï¼‰ï¼Œè¿½æ±‚æ›´å¼ºæ€§èƒ½ã€‚
2. **æ”¯æŒæ›´é•¿ä¸Šä¸‹æ–‡æ¨ç†**ï¼ˆ>8kï¼‰ï¼Œç»“åˆ Long Context Alignment æŠ€æœ¯ã€‚
3. **å¼•å…¥åŠ¨æ€ packing ç­‰è®­ç»ƒåŠ é€Ÿç­–ç•¥**ï¼Œè¿›ä¸€æ­¥æå‡è®­ç»ƒæ•ˆç‡ã€‚
4. **æ‹“å±•è‡³æ›´å¤šä¸‹æ¸¸ä»»åŠ¡**ï¼šå¦‚ä»£ç ç”Ÿæˆã€Agent å†³ç­–ã€å¤šæ¨¡æ€ä»»åŠ¡ã€‚
5. **å¼€æºå®Œæ•´å·¥å…·é“¾**ï¼šæä¾›å¼€æ”¾çš„ dLLM åè®­ç»ƒ Toolkitï¼Œæ¨åŠ¨ç¤¾åŒºå‘å±•ã€‚

---

## æ€»ç»“

> **DiRL** æ˜¯é¦–ä¸ªé¢å‘ dLLMs çš„é«˜æ•ˆã€ç«¯åˆ°ç«¯åè®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡ **DiPO + FlexAttention + LMDeploy åœ¨çº¿æ›´æ–°** çš„ååŒè®¾è®¡ï¼Œåœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šå®ç°äº† **SOTA æ€§èƒ½ä¸è®­ç»ƒæ•ˆç‡åŒé‡çªç ´**ã€‚å®ƒä¸ä»…è§£å†³äº† dLLM åè®­ç»ƒä¸­çš„æ ¸å¿ƒç“¶é¢ˆï¼Œä¹Ÿä¸ºæœªæ¥æ‰©æ•£è¯­è¨€æ¨¡å‹çš„å¯¹é½ä¸éƒ¨ç½²æä¾›äº†åšå®çš„æŠ€æœ¯åŸºç¡€å’Œå¼€æºå®è·µè·¯å¾„ã€‚

ğŸ”— **ä»£ç **ï¼š[https://github.com/OpenMOSS/DiRL](https://github.com/OpenMOSS/DiRL)  
ğŸŒ **æ¨¡å‹**ï¼š[https://huggingface.co/OpenMOSS-Team/DiRL-8B-Instruct](https://huggingface.co/OpenMOSS-Team/DiRL-8B-Instruct)

</details>

---

### 4. [Modality Inflation: Energy Characterization and Optimization Opportunities for MLLM Inference](https://arxiv.org/abs/2512.22695)

**Authors**: Mona Moghadampanah, Adib Rezaei Shahmirzadi, Farhana Amin, Dimitrios S. Nikolopoulos  
**Category**: cs.DC  
**Published**: 2025-12-30  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.22695v1  

#### Abstract
Multimodal large language models (MLLMs) are built on text-only LLMs by incorporating additional modalities, enabling multimodal understanding and a broader range of applications. However, these additions introduce a previously unexplored energy trade-off across modalities that remains poorly unders...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Modality Inflation: Energy Characterization and Optimization Opportunities for MLLM Inference*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬æ–‡èšç„¦äº**å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰æ¨ç†è¿‡ç¨‹ä¸­çš„èƒ½æ•ˆé—®é¢˜**ï¼Œç‰¹åˆ«æ˜¯ç”±â€œ**æ¨¡æ€è†¨èƒ€ï¼ˆModality Inflationï¼‰**â€å¸¦æ¥çš„é¢å¤–èƒ½è€—ã€‚ä¼ ç»Ÿç ”ç©¶å¤šå…³æ³¨æ–‡æœ¬-only LLM çš„èƒ½æ•ˆä¼˜åŒ–ï¼Œè€Œå¿½è§†äº†å›¾åƒç­‰è§†è§‰è¾“å…¥å¼•å…¥çš„ç¼–ç é˜¶æ®µå’Œå¤§é‡è§†è§‰ token æ‰€å¯¼è‡´çš„ç³»ç»Ÿçº§èƒ½é‡å¼€é”€ã€‚

å…·ä½“è€Œè¨€ï¼Œè¯¥è®ºæ–‡æ­ç¤ºå¹¶é‡åŒ–äº†ä»¥ä¸‹é—®é¢˜ï¼š
- è§†è§‰ç¼–ç å™¨ï¼ˆvision encoderï¼‰å’Œæ‰©å±•çš„ token åºåˆ—å¦‚ä½•æ˜¾è‘—å¢åŠ æ¨ç†èƒ½è€—ï¼›
- ä¸åŒ MLLM æ¶æ„åœ¨èƒ½æ•ˆä¸Šçš„å·¨å¤§å·®å¼‚ï¼›
- å¤šæ¨¡æ€æ‰§è¡Œè¿‡ç¨‹ä¸­ GPU åˆ©ç”¨ç‡ä½ä¸‹ã€åŠŸè€—åˆ†å¸ƒä¸å‡ç­‰é—®é¢˜ã€‚

### ğŸ”§ æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
1. **é¦–æ¬¡æå‡ºâ€œæ¨¡æ€è†¨èƒ€â€æ¦‚å¿µ**ï¼Œå°†å…¶å®šä¹‰ä¸ºï¼šç”±äºè§†è§‰è¾“å…¥å¼•å…¥é¢å¤–çš„ç¼–ç é˜¶æ®µå’Œå¤§é‡è§†è§‰ tokenï¼Œå¯¼è‡´ä¸‹æ¸¸ prefill é˜¶æ®µè®¡ç®—é‡å‰§å¢çš„ç°è±¡ã€‚
2. **æ„å»ºäº†ç»†ç²’åº¦çš„ä¸‰é˜¶æ®µèƒ½æ•ˆåˆ†ææ¡†æ¶**ï¼š
   - **Vision Encoding**ï¼ˆè§†è§‰ç¼–ç ï¼‰
   - **Prefill**ï¼ˆä¸Šä¸‹æ–‡å¡«å……ï¼‰
   - **Decoding**ï¼ˆè‡ªå›å½’è§£ç ï¼‰
   å¹¶å¯¹æ¯ä¸ªé˜¶æ®µè¿›è¡Œç‹¬ç«‹çš„èƒ½é‡ä¸å»¶è¿Ÿæµ‹é‡ã€‚
3. **æå‡ºåŸºäºé˜¶æ®µçš„åŠ¨æ€ç”µå‹é¢‘ç‡è°ƒèŠ‚ï¼ˆStage-wise DVFSï¼‰ä½œä¸ºä¼˜åŒ–ç­–ç•¥**ï¼Œæ ¹æ®ä¸åŒé˜¶æ®µçš„å·¥ä½œè´Ÿè½½ç‰¹æ€§è°ƒæ•´ GPU é¢‘ç‡ï¼Œåœ¨æ§åˆ¶æ€§èƒ½æŸå¤±çš„åŒæ—¶å®ç°èŠ‚èƒ½ã€‚

### ğŸ“ˆ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä»¥å¾€å·¥ä½œå±€é™ | æœ¬è®ºæ–‡ä¼˜åŠ¿ |
|------|---------------|------------|
| èƒ½æ•ˆåˆ†æç²’åº¦ | é»‘ç®±å¼æ•´ä½“åˆ†æ | **é˜¶æ®µçº§åˆ†è§£åˆ†æ**ï¼Œè¯†åˆ«ç“¶é¢ˆæ¥æº |
| è¾“å…¥å¤æ‚æ€§å½±å“ | å¿½è§†åˆ†è¾¨ç‡/å›¾åƒæ•°é‡å˜åŒ– | æ˜ç¡®å»ºæ¨¡è¾“å…¥å¤æ‚æ€§å¯¹èƒ½è€—çš„å½±å“ |
| ä¼˜åŒ–ç­–ç•¥ | é€šç”¨æ€§ç­–ç•¥ï¼ˆå¦‚æ‰¹å¤„ç†ã€é‡åŒ–ï¼‰ | **æ¶æ„æ„ŸçŸ¥ + é˜¶æ®µæ„ŸçŸ¥çš„ DVFS æ§åˆ¶** |
| å®éªŒè®¾è®¡ | ç¼ºä¹è·¨æ¨¡å‹æ¯”è¾ƒ | åœ¨ç»Ÿä¸€ç¡¬ä»¶å¹³å°ä¸‹å¯¹æ¯”å››ç§ä»£è¡¨æ€§ MLLM |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†ä¸è¾“å…¥é…ç½®
- **çœŸå®è¯·æ±‚åˆ†å¸ƒå‚è€ƒ**ï¼šä½¿ç”¨ç”Ÿäº§çº§è¿½è¸ªæ•°æ®é›† **ServeGen [42]** åˆ†æå®é™…æŸ¥è¯¢ä¸­å›¾åƒæ•°é‡åˆ†å¸ƒï¼ˆå›¾2aï¼‰ï¼Œå‘ç°å¤šæ•°è¯·æ±‚å«1â€“2å¼ å›¾ï¼Œå°‘æ•°æç«¯æƒ…å†µå¯è¾¾49å¼ ã€‚
- **å›¾åƒåˆ†è¾¨ç‡åˆ†æ**ï¼šè€ƒå¯Ÿå››ä¸ªä¸»æµ benchmark æ•°æ®é›†ï¼ˆ**VQAv2, VizWiz, ShareGPT4V, ChartQA**ï¼‰çš„å›¾åƒçŸ­è¾¹åˆ†è¾¨ç‡åˆ†å¸ƒï¼ˆå›¾2bï¼‰ï¼Œæ˜¾ç¤ºä»ä½æ¸…åˆ°è¶…é«˜æ¸…å‡æœ‰è¦†ç›–ã€‚
- **å®éªŒè¾“å…¥è®¾ç½®**ï¼š
  - å›ºå®šæ–‡æœ¬ promptï¼›
  - å›¾åƒè¾“å…¥åˆ†ä¸ºä¸¤ç§é…ç½®ï¼š
    1. **iso-resolution è®¾ç½®**ï¼šå›ºå®šä¸º 512Ã—512ï¼›
    2. **å¯å˜è¾“å…¥**ï¼šæ”¹å˜å›¾åƒåˆ†è¾¨ç‡ï¼ˆæœ€é«˜è¾¾ 2048Ã—2048ï¼‰å’Œå›¾åƒæ•°é‡ï¼ˆæœ€å¤š6å¼ ï¼‰ä»¥æµ‹è¯•æ•æ„Ÿæ€§ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šå•å— **NVIDIA A100 80GB GPU**
- **è½¯ä»¶æ ˆ**ï¼šPyTorch + Hugging Face Transformers
- **åŠŸç‡ç›‘æ§å·¥å…·**ï¼šé€šè¿‡ **NVML** ä»¥ 5ms é—´éš”é‡‡æ · GPU åŠŸè€—
- **é‡å¤æ€§ä¿éšœ**ï¼šå¤šæ¬¡è¿è¡Œå–å¹³å‡å€¼ï¼Œå¹¶æä¾›ç½®ä¿¡åŒºé—´

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ |
|--------|---------|
| èƒ½æ•ˆ | Energy per request (**J/request**) |
| æ€§èƒ½ | End-to-end latency (**s/request**), Throughput (**req/s**) |
| ç³»ç»Ÿè¡Œä¸º | GPU power trace, Utilization phases |
| å¯æ‰©å±•æ€§ | èƒ½é‡éšåˆ†è¾¨ç‡/å›¾åƒæ•°çš„å¢é•¿è¶‹åŠ¿ |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **text-only baseline**ï¼šé€‰æ‹©ä¸å„ MLLM å…±äº«ç›¸åŒ LLM backbone çš„çº¯æ–‡æœ¬æ¨¡å‹ä½œä¸ºå¯¹ç…§ï¼›
- **iso-token å¯¹é½å®éªŒ**ï¼šç¡®ä¿ MLLM ä¸ baseline çš„æ€»è¾“å…¥ token æ•°ç›¸ç­‰ï¼ˆåŒ…æ‹¬ text + visual tokensï¼‰ï¼Œè¾“å‡ºå›ºå®šä¸º1ä¸ªtokenï¼Œä»è€Œéš”ç¦»åºåˆ—é•¿åº¦æ•ˆåº”ï¼Œä»…è¡¡é‡â€œå¤šæ¨¡æ€å¤„ç†â€çš„å¢é‡æˆæœ¬ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ”‹ RQ1: å¤šæ¨¡æ€æ¨ç†çš„å¢é‡èƒ½è€—æ˜¯å¤šå°‘ï¼Ÿ
- åœ¨ iso-token æ¡ä»¶ä¸‹ï¼Œç›¸æ¯” text-only baselineï¼ŒMLLM æ¨ç†èƒ½è€—å¢åŠ  **17% ~ 94%**ï¼ˆå›¾3aï¼‰ï¼š
  - **LLaVA-OneVision**: +17%
  - **LLaVA-1.5**: +25%
  - **InternVL3**: +18%
  - **Qwen2.5-VL**: **+94%**ï¼ˆæœ€é«˜ï¼‰
- åŒæ—¶è§‚å¯Ÿåˆ°**èƒ½è€—ä¸å»¶è¿Ÿå¢é•¿ä¸æˆæ¯”ä¾‹**ï¼š
  - Qwen2.5-VL èƒ½è€— +94%ï¼Œä½†å»¶è¿Ÿ +179%ï¼Œè¯´æ˜å­˜åœ¨ä¸²è¡Œç“¶é¢ˆã€‚

> âœ… **å‘ç°1**ï¼štoken æ•°é‡æœ¬èº«ä¸èƒ½è§£é‡Šå…¨éƒ¨èƒ½è€—å·®å¼‚ï¼Œ**æ¶æ„è®¾è®¡æ˜¯å†³å®šæ€§å› ç´ **ã€‚

---

### âš–ï¸ RQ2: èƒ½é‡åˆ†å¸ƒåœ¨å„ä¸ªé˜¶æ®µæœ‰ä½•ä¸åŒï¼Ÿ

#### é˜¶æ®µçº§èƒ½è€—åˆ†è§£ï¼ˆå›¾4aï¼‰ï¼š
| æ¨¡å‹ | ç¼–ç èƒ½è€— | Prefill èƒ½è€— | ä¸»å¯¼é˜¶æ®µ |
|------|----------|-------------|----------|
| **Qwen2.5-VL** | **20.81 J**ï¼ˆæé«˜ï¼‰ | 6.30 J | **ç¼–ç ä¸»å¯¼**ï¼ˆcompute-heavy encoderï¼‰ |
| **LLaVA-OneVision** | 9.52 Jï¼ˆè¾ƒä½ï¼‰ | **95.78 J**ï¼ˆæé«˜ï¼‰ | **prefill ä¸»å¯¼**ï¼ˆtile-based token expansionï¼‰ |
| **InternVL3** | 8.12 J | 7.54 J | è¾ƒå¹³è¡¡ |
| **LLaVA-1.5** | 14.36 J | 49.58 J | prefill å æ¯”è¾ƒé«˜ |

- **LLaVA-OneVision** ç”Ÿæˆé«˜è¾¾ **3,715 ä¸ªè§†è§‰ token**ï¼Œå¯¼è‡´ prefill é˜¶æ®µèƒ½è€—æ¿€å¢ï¼ˆçº¦æ˜¯ InternVL3 çš„12å€ï¼‰ï¼›
- **Qwen2.5-VL** çš„ encoder èƒ½è€—æ˜¯ LLaVA-1.5 çš„ **6å€ä»¥ä¸Š**ã€‚

> âœ… **å‘ç°2**ï¼šä¸åŒ MLLM çš„èƒ½æ•ˆç“¶é¢ˆä½ç½®å®Œå…¨ä¸åŒâ€”â€”æœ‰çš„å¡åœ¨ encoderï¼Œæœ‰çš„å¡åœ¨ prefillã€‚

---

### ğŸ”Œ RQ3: GPU åŠŸè€—æ›²çº¿æœ‰ä½•ç‰¹å¾ï¼Ÿæ˜¯å¦å­˜åœ¨ä¼˜åŒ–æœºä¼šï¼Ÿ

#### åŠŸç‡è½¨è¿¹åˆ†æï¼ˆå›¾5ï¼‰ï¼š
- **text-only baseline**ï¼šå¿«é€Ÿè¿›å…¥é«˜åŠŸè€—çŠ¶æ€ï¼ˆ~400Wï¼‰ï¼Œæ¥è¿‘ GPU åŠŸç‡ä¸Šé™ï¼Œåˆ©ç”¨ç‡é«˜ï¼›
- **MLLM æ¨ç†**ï¼šå‡ºç°æ˜æ˜¾çš„â€œ**ä¸­ç­‰åŠŸè€—ç›¸ä½**â€ï¼ˆmid-power phase, 100â€“250Wï¼‰ï¼Œå¯¹åº” vision encoding é˜¶æ®µï¼›
  - Qwen2.5-VL è¡¨ç°ä¸ºæŒç»­ ~200W çš„â€œé˜¶æ¢¯çŠ¶â€åŠŸç‡ï¼›
  - LLaVA-OneVision å‡ºç°é«˜é¢‘æ³¢åŠ¨ï¼Œåæ˜  tiled processing çš„çªå‘æ€§ã€‚

> âœ… **å‘ç°3**ï¼šå¤šæ¨¡æ€æ‰§è¡ŒæœŸé—´ GPU é•¿æ—¶é—´å¤„äºéé¥±å’ŒçŠ¶æ€ï¼Œ**é»˜è®¤çš„â€œrace-to-idleâ€é¢‘ç‡ç­–ç•¥æ•ˆç‡ä½ä¸‹**ã€‚

---

### ğŸ“ˆ RQ4: è¾“å…¥å¤æ‚æ€§å¦‚ä½•å½±å“èƒ½æ•ˆï¼Ÿ

#### å›¾åƒåˆ†è¾¨ç‡å½±å“ï¼ˆå›¾7ï¼‰ï¼š
- **LLaVA-1.5**ï¼ˆCLIP-basedï¼‰ï¼šé‡‡ç”¨å›ºå®š patch åˆ†å‰²ï¼Œtoken æ•°å‡ ä¹ä¸å˜ â†’ èƒ½è€—åŸºæœ¬å¹³å¦ï¼›
- **InternVL3 / LLaVA-OneVision**ï¼ˆany-resolution tilingï¼‰ï¼štoken æ•°éšåˆ†è¾¨ç‡ç¦»æ•£ä¸Šå‡ â†’ èƒ½è€—éçº¿æ€§å¢é•¿ï¼›
- **Qwen2.5-VL**ï¼šåœ¨ >1024Ã—1024 å token æ•°æ€¥å‰§ä¸Šå‡ â†’ èƒ½è€—å’Œå»¶è¿Ÿé™¡å¢ã€‚

#### å›¾åƒæ•°é‡å½±å“ï¼ˆå›¾6ï¼‰ï¼š
- å¢åŠ å›¾åƒæ•°é‡çº¿æ€§æå‡èƒ½è€—å’Œå»¶è¿Ÿï¼Œä½†æ–œç‡å› æ¨¡å‹è€Œå¼‚ï¼š
  - **è¾¹é™…æˆæœ¬ per image**ï¼šçº¦ **15â€“35 J/image**
  - å°‘é‡ high-image è¯·æ±‚å³å¯æ˜¾è‘—æ‹–æ…¢ç³»ç»Ÿå“åº”

> âœ… **å‘ç°4**ï¼šè¾“å…¥å¤æ‚æ€§ï¼ˆåˆ†è¾¨ç‡ã€å›¾åƒæ•°ï¼‰å¯¹èƒ½è€—å½±å“é«˜åº¦ä¾èµ–äº encoder è®¾è®¡ï¼Œéœ€**è¾“å…¥æ„ŸçŸ¥çš„è°ƒåº¦æœºåˆ¶**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°æ€»ç»“

| å‘ç°ç¼–å· | å†…å®¹æ‘˜è¦ |
|--------|--------|
| **Observation 1** | MLLM èƒ½è€—å·®å¼‚æå¤§ï¼ˆ+17%~+94%ï¼‰ï¼Œå¿…é¡»é‡‡ç”¨**æ¶æ„å®šåˆ¶åŒ–**çš„èƒ½æ•ˆç®¡ç†ç­–ç•¥ |
| **Observation 2** | èƒ½æ•ˆç“¶é¢ˆå¯èƒ½å‡ºç°åœ¨ **encoding æˆ– prefill é˜¶æ®µ**ï¼Œåº”å®æ–½**é˜¶æ®µçº§ä¼˜åŒ–**ï¼ˆå¦‚ stage-wise DVFSï¼‰ |
| **Observation 3** | å¤šæ¨¡æ€æ‰§è¡Œå¼•å…¥**ä¸­ç­‰åŠŸè€—é˜¶æ®µ**ï¼ŒGPU åˆ©ç”¨ç‡ä½ï¼Œé€šç”¨é¢‘ç‡ç­–ç•¥å¤±æ•ˆ |
| **Observation 4** | ä¸åŒ MLLM å¯¹è¾“å…¥å¤æ‚æ€§çš„æ•æ„Ÿåº¦å·®å¼‚å·¨å¤§ï¼Œéœ€**è¾“å…¥æ„ŸçŸ¥çš„èµ„æºåˆ†é…æœºåˆ¶** |

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **ä»…é™äºé™æ€ DVFS å®éªŒ**ï¼šæœªå®ç°åŠ¨æ€å®æ—¶è°ƒé¢‘æ§åˆ¶å™¨ï¼›
2. **å±€é™äºå• GPU åœºæ™¯**ï¼šæœªè€ƒè™‘åˆ†å¸ƒå¼æˆ–å¤šè®¾å¤‡ disaggregation æ¶æ„ä¸‹çš„èƒ½æ•ˆè¡¨ç°ï¼›
3. **æ¨¡å‹è§„æ¨¡æœ‰é™**ï¼šæ‰€æœ‰æµ‹è¯•æ¨¡å‹é›†ä¸­åœ¨ 7Bâ€“8B å‚æ•°èŒƒå›´ï¼Œæœªæ¶µç›–æ›´å¤§æˆ–æ›´å°æ¨¡å‹ï¼›
4. **ä»…è¯„ä¼° vision-language æ¨¡å‹**ï¼šæœªæ¶‰åŠéŸ³é¢‘ã€è§†é¢‘ç­‰å…¶ä»–æ¨¡æ€ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆåŸæ–‡ Section 6ï¼‰
1. **æ‰©å±•è‡³ä¸åŒè§„æ¨¡æ¨¡å‹**ï¼šç ”ç©¶å‚æ•°é‡å¯¹ modality inflation çš„äº¤äº’å½±å“ï¼›
2. **å¼€å‘åŠ¨æ€ DVFS æ§åˆ¶å™¨**ï¼šç»“åˆè¾“å…¥é¢„æµ‹ä¸é˜¶æ®µæ£€æµ‹ï¼Œå®ç° SLO-aware çš„å®æ—¶é¢‘ç‡è°ƒèŠ‚ï¼›
3. **æ¢ç´¢ disaggregated æ¶æ„ä¸‹çš„èƒ½æ•ˆä¼˜åŒ–**ï¼šå°† vision encoder ä¸ LLM åˆ†ç¦»éƒ¨ç½²åçš„èƒ½è€—ç‰¹æ€§ï¼›
4. **æ‹“å±•è‡³æ›´å¤šæ¨¡æ€**ï¼šæ”¯æŒ audioã€videoã€temporal inputs çš„ç»Ÿä¸€èƒ½æ•ˆå»ºæ¨¡æ¡†æ¶ã€‚

---

## ç»“è¯­

æœ¬æ–‡æ˜¯é¦–ä¸ªå¯¹ MLLM æ¨ç†è¿›è¡Œ**ç»†ç²’åº¦èƒ½æ•ˆå‰–æ**çš„ç ”ç©¶ï¼Œæå‡ºäº†â€œ**æ¨¡æ€è†¨èƒ€**â€è¿™ä¸€å…³é”®æ¦‚å¿µï¼Œå¹¶æ­ç¤ºäº†å…¶åœ¨ energyã€latency å’Œ GPU utilization ä¸Šçš„æ·±è¿œå½±å“ã€‚é€šè¿‡ stage-level åˆ†æä¸ DVFS å®éªŒï¼Œè®ºæ–‡ä¸ä»…æä¾›äº†æ·±åˆ»çš„ç³»ç»Ÿæ´å¯Ÿï¼Œä¹Ÿä¸ºæ„å»ºå¯æŒç»­ã€é«˜æ•ˆçš„ MLLM serving å¹³å°æŒ‡æ˜äº†åˆ‡å®å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 5. [LLMBoost: Make Large Language Models Stronger with Boosting](https://arxiv.org/abs/2512.22309)

**Authors**: Zehao Chen, Tianxiang Ai, Yifei Li, Gongxun Li, Yuyang Wei, Wang Zhou, Guanghui Li, Bin Yu, Zhijun Chen, Hailong Sun, Fuzhen Zhuang, Jianxin Li, Deqing Wang, Yikun Ban  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.22309v1  

#### Abstract
Ensemble learning of LLMs has emerged as a promising alternative to enhance performance, but existing approaches typically treat models as black boxes, combining the inputs or final outputs while overlooking the rich internal representations and interactions across models.In this work, we introduce ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# LLMBoost: Make Large Language Models Stronger with Boosting è®ºæ–‡æ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **LLM Ensemble** æ–¹æ³•é€šå¸¸å°†æ¨¡å‹è§†ä¸ºé»‘ç®±ï¼Œä»…åœ¨è¾“å…¥æˆ–æœ€ç»ˆè¾“å‡ºå±‚é¢è¿›è¡Œèåˆï¼ˆå¦‚å¤šæ•°æŠ•ç¥¨ã€åŠ æƒèšåˆï¼‰ï¼Œè€Œå¿½ç•¥äº†æ¨¡å‹å†…éƒ¨ä¸°å¯Œçš„éšè—è¡¨ç¤ºï¼ˆhidden representationsï¼‰å’Œè·¨æ¨¡å‹äº¤äº’ã€‚è¿™ç§ç²—ç²’åº¦çš„èåˆæ–¹å¼é™åˆ¶äº†æ¨¡å‹é—´äº’è¡¥çŸ¥è¯†çš„å……åˆ†æŒ–æ˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•å’Œæ–°æ€è·¯
æœ¬æ–‡æå‡ºäº† **LLMBooST**ï¼Œä¸€ç§æ–°é¢–çš„é›†æˆå¾®è°ƒæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ˜¯å€Ÿé‰´ **Boosting** èŒƒå¼ï¼Œé€šè¿‡æ˜¾å¼åˆ©ç”¨ LLM çš„ä¸­é—´çŠ¶æ€æ¥æ‰“ç ´â€œé»‘ç®±â€å£å’ã€‚å…¶ä¸‰å¤§å…³é”®åˆ›æ–°å¦‚ä¸‹ï¼š

1.  **è·¨æ¨¡å‹æ³¨æ„åŠ›æœºåˆ¶ (Cross-Model Attention)**ï¼š
    *   å…è®¸åç»­æ¨¡å‹ï¼ˆsuccessor modelsï¼‰ç›´æ¥è®¿é—®å¹¶èåˆå‰åºæ¨¡å‹ï¼ˆpredecessorsï¼‰çš„éšè—çŠ¶æ€ã€‚
    *   è¿™ç§åˆ†å±‚çš„ã€ç»†ç²’åº¦çš„äº¤äº’æœºåˆ¶ä½¿å¾—åä¸€ä¸ªæ¨¡å‹èƒ½å¤ŸåŸºäºå‰ä¸€ä¸ªæ¨¡å‹çš„â€œæ€è€ƒè¿‡ç¨‹â€è¿›è¡Œé”™è¯¯çº æ­£å’ŒçŸ¥è¯†ä¼ é€’ã€‚

2.  **é“¾å¼è®­ç»ƒèŒƒå¼ (Chain Training Paradigm)**ï¼š
    *   é‡‡ç”¨é¡ºåºå¾®è°ƒçš„æ–¹å¼ï¼Œæ¯ä¸ªåç»­æ¨¡å‹éƒ½åŸºäºå…¶å‰é©±æ¨¡å‹çš„è®­ç»ƒæ—¥å¿—è¿›è¡Œå¾®è°ƒã€‚
    *   å¼•å…¥ **é”™è¯¯æŠ‘åˆ¶ç›®æ ‡ (Error-Suppression Objective)**ï¼Œè¯¥ç›®æ ‡å‡½æ•°ä¼šæŠ‘åˆ¶å‰é©±æ¨¡å‹é¢„æµ‹çš„æœ€å¤§ï¼ˆé”™è¯¯ï¼‰logitï¼ŒåŒæ—¶å¢å¼ºæ­£ç¡®ç­”æ¡ˆçš„logitï¼Œä»è€Œå®ç°ç²¾å‡†çº é”™ï¼Œä¸”è®¡ç®—å¼€é”€æå°ã€‚

3.  **è¿‘ä¼¼å¹¶è¡Œæ¨ç†èŒƒå¼ (Near-Parallel Inference Paradigm)**ï¼š
    *   ä¸ºè§£å†³å¤šæ¨¡å‹ä¸²è¡Œæ¨ç†å¯¼è‡´çš„é«˜å»¶è¿Ÿé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æµæ°´çº¿å¼çš„æ¨ç†ç­–ç•¥ã€‚
    *   åç»­æ¨¡å‹æ— éœ€ç­‰å¾…å‰é©±æ¨¡å‹å®Œæˆæ•´ä¸ªåºåˆ—ç”Ÿæˆï¼Œè€Œæ˜¯å¯ä»¥é€å±‚æ¥æ”¶å…¶éšè—çŠ¶æ€å¹¶ç«‹å³å¼€å§‹è®¡ç®—ï¼Œå®ç°äº†æ¥è¿‘å•æ¨¡å‹è§£ç çš„æ•ˆç‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
*   **æ€§èƒ½æ›´å¼º**ï¼šé€šè¿‡åˆ©ç”¨å†…éƒ¨è¡¨ç¤ºè¿›è¡Œç»†ç²’åº¦äº¤äº’ï¼Œæ˜¾è‘—æå‡äº†æ¨ç†èƒ½åŠ›ã€‚
*   **æ•ˆç‡æ›´é«˜**ï¼šè¿‘ä¼¼å¹¶è¡Œæ¨ç†å¤§å¹…é™ä½äº†ä¼ ç»Ÿä¸²è¡Œé›†æˆçš„å»¶è¿Ÿã€‚
*   **ç†è®ºæœ‰ä¿éšœ**ï¼šè®ºæ–‡ä»ç†è®ºä¸Šè¯æ˜ï¼Œåœ¨åˆç†å‡è®¾ä¸‹ï¼Œéšç€é›†æˆæ¨¡å‹æ•°é‡çš„å¢åŠ ï¼Œæ•´ä½“æ€§èƒ½ä¼šå•è°ƒæå‡ã€‚

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒæ¶µç›–äº†å¤šä¸ªé¢†åŸŸï¼Œä»¥éªŒè¯æ–¹æ³•çš„é€šç”¨æ€§ï¼š
*   **å¸¸è¯†æ¨ç† (Commonsense Reasoning)**ï¼šPIQA, HellaSwag, WinoGrande, BoolQ, SIQA, OpenbookQA (OBQA)ã€‚
*   **ç®—æœ¯æ¨ç† (Arithmetic Reasoning)**ï¼šAQuA, GSM8K, MAWPS, SVAMPã€‚
*   **å·¥ä¸šåœºæ™¯æ•°æ®é›†**ï¼š**Chinatelecom Cloud Agent Dataset (CCAD)**ï¼Œç”¨äºè¯„ä¼°AIä»£ç†åœ¨çœŸå®äº‘æœåŠ¡å·¥å…·é“¾è°ƒåº¦ä¸­çš„è¡¨ç°ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
*   **å¾®è°ƒæ–¹æ³•**ï¼šé‡‡ç”¨ **LoRA** è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒã€‚
*   **è¯„ä¼°æŒ‡æ ‡**ï¼šä¸»è¦ä½¿ç”¨ **å‡†ç¡®ç‡ (Accuracy)** ä½œä¸ºæ€§èƒ½æŒ‡æ ‡ã€‚
*   **æ•ˆç‡æŒ‡æ ‡**ï¼šæŠ¥å‘Šç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆEnd-to-End Latencyï¼‰ã€æ¯tokenç”Ÿæˆæˆæœ¬ï¼ˆPer-Token Latencyï¼‰å’Œå³°å€¼GPUå†…å­˜å ç”¨ã€‚
*   **æ¨¡å‹è§„æ¨¡**ï¼šåœ¨ä¸åŒå‚æ•°é‡çº§çš„æ¨¡å‹ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼ŒåŒ…æ‹¬ `Llama-3` å’Œ `Qwen-2.5` ç³»åˆ—çš„ 3B, 7B, 8B æ¨¡å‹ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
ä¸ä»¥ä¸‹ä¸»æµçš„é›†æˆå’Œä¼˜åŒ–æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒï¼š
*   **VOTE**ï¼šåŸºäºå¤šæ•°æŠ•ç¥¨çš„é›†æˆæ–¹æ³•ã€‚
*   **UNITE**ï¼šä¸€ç§é«˜æ•ˆçš„LLMé›†æˆæ–¹æ³•ï¼Œå…³æ³¨å„æ¨¡å‹top-k tokençš„å¹¶é›†ã€‚
*   **T-copilot**ï¼šä¸€ç§é€šè¿‡è¾…åŠ©é€‚é…å™¨ï¼ˆcopilot adapterï¼‰æ¥çº æ­£ä¸»æ¨¡å‹ï¼ˆpilotï¼‰é”™è¯¯çš„æ–¹æ³•ã€‚

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
*   **å¹³å‡æ€§èƒ½æå‡**ï¼šç›¸æ¯”å…¶ä»–é›†æˆåŸºçº¿ï¼ŒLLMBooST åœ¨å„é¡¹ä»»åŠ¡ä¸Šçš„å¹³å‡å‡†ç¡®ç‡æå‡äº† **3.9%**ï¼Œæœ€é«˜æå‡è¾¾åˆ° **6.6%**ã€‚
*   **ç‰¹å®šæ•°æ®é›†è¡¨ç°**ï¼š
    *   åœ¨ **CCAD** æ•°æ®é›†ä¸Šï¼Œç›¸æ¯”å•æ¨¡å‹ï¼Œå‡†ç¡®ç‡æå‡äº† **3%**ã€‚
    *   åœ¨ **WinoGrande** ä¸Šï¼Œç›¸æ¯”æœ€å¼ºåŸºçº¿ï¼Œå‡†ç¡®ç‡æå‡äº† **6.6%**ã€‚
*   **æ•ˆç‡æå‡**ï¼šç›¸æ¯”ä¼ ç»Ÿçš„ä¸²è¡Œé›†æˆï¼ŒLLMBooST çš„æ¨ç†å»¶è¿Ÿé™ä½äº† **47%**ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
*   **æ€§èƒ½å¯¹æ¯”**ï¼šåœ¨æ‰€æœ‰æµ‹è¯•çš„æ¨¡å‹è§„æ¨¡ï¼ˆ3B, 7B, 8Bï¼‰å’Œä»»åŠ¡ä¸Šï¼ŒLLMBooST å‡æ˜¾è‘—ä¼˜äº **VOTE**, **UNITE**, å’Œ **T-copilot** ç­‰åŸºçº¿æ–¹æ³•ã€‚
    *   ä¾‹å¦‚ï¼Œåœ¨ `Llama-3.1-8B` çš„ç®—æœ¯æ¨ç†ä»»åŠ¡ä¸Šï¼ŒLLMBooST (2Ã—8B) çš„å¹³å‡å‡†ç¡®ç‡è¾¾åˆ° **71.5%**ï¼Œè€Œ VOTE ä»…ä¸º **69.8%**ã€‚
*   **æ•ˆç‡å¯¹æ¯”**ï¼šLLMBooST çš„ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆ13.75ç§’ï¼‰è¿œä½äº VOTE (22.61ç§’)ã€UNITE (22.66ç§’) å’Œ T-Copilot (17.21ç§’)ï¼Œç”šè‡³ä¼˜äºå•ä¸ª14Bå¤§æ¨¡å‹ï¼ˆ17.40ç§’ï¼‰ã€‚
*   **å‚æ•°æ•ˆç‡**ï¼šåœ¨ç›¸åŒå‚æ•°é¢„ç®—ä¸‹ï¼ŒLLMBooST æ€§èƒ½æ›´ä¼˜ã€‚ä¾‹å¦‚ï¼Œä¸¤ä¸ª `Qwen2.5-3B` ç»„æˆçš„ LLMBooST (6B) åœ¨ç®—æœ¯æ¨ç†ä¸Šçš„è¡¨ç°è¶…è¿‡äº†å•ä¸ª `Qwen2.5-7B` (7B) æ¨¡å‹ã€‚

### æ¶ˆèå®éªŒç»“æœ
æ¶ˆèç ”ç©¶éªŒè¯äº†å„ä¸ªç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼š
*   **ç§»é™¤é”™è¯¯æŠ‘åˆ¶ç›®æ ‡ (wo E.S.O.)**ï¼šæ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œè¯æ˜äº†è¯¥ç›®æ ‡å‡½æ•°å¯¹ç²¾å‡†çº é”™è‡³å…³é‡è¦ã€‚
*   **ç¦ç”¨è·¨æ¨¡å‹æ³¨æ„åŠ› (wo C.A.)**ï¼šæ€§èƒ½ä¸‹é™ï¼Œè¡¨æ˜ç›´æ¥è®¿é—®å‰é©±æ¨¡å‹çš„éšè—çŠ¶æ€æ˜¯æå‡æ€§èƒ½çš„å…³é”®ã€‚
*   **è¶…å‚æ•°æ•æ„Ÿæ€§**ï¼šå®éªŒè¡¨æ˜ï¼Œ`Î±` (å¹³è¡¡ç³»æ•°) å’Œ `Î²` (ç¼©æ”¾å› å­) çš„é€‰æ‹©å¯¹æ€§èƒ½æœ‰å½±å“ï¼Œå­˜åœ¨æœ€ä¼˜å€¼ï¼ˆå¦‚ `Î±=0.9`, `Î²=0.1`ï¼‰ã€‚

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1.  **å†…éƒ¨äº¤äº’è‡³å…³é‡è¦**ï¼šæ‰“ç ´LLMé›†æˆçš„â€œé»‘ç®±â€å‡è®¾ï¼Œåˆ©ç”¨æ¨¡å‹é—´çš„å†…éƒ¨éšè—çŠ¶æ€è¿›è¡Œäº¤äº’ï¼Œæ˜¯æå‡é›†æˆæ€§èƒ½çš„æœ‰æ•ˆé€”å¾„ã€‚
2.  **BoostingèŒƒå¼æœ‰æ•ˆ**ï¼šå°†Boostingæ€æƒ³åº”ç”¨äºLLMé›†æˆï¼Œé€šè¿‡é“¾å¼è®­ç»ƒå’Œé”™è¯¯æŠ‘åˆ¶ï¼Œèƒ½å¤Ÿå®ç°ç¨³å®šä¸”å¯ç´¯ç§¯çš„æ€§èƒ½å¢ç›Šã€‚
3.  **æ•ˆç‡ä¸æ€§èƒ½å…¼å¾—**ï¼šæå‡ºçš„è¿‘ä¼¼å¹¶è¡Œæ¨ç†èŒƒå¼æˆåŠŸè§£å†³äº†å¤šæ¨¡å‹é›†æˆçš„é«˜å»¶è¿Ÿç“¶é¢ˆï¼Œå®ç°äº†é«˜æ€§èƒ½ä¸é«˜æ•ˆç‡çš„ç»Ÿä¸€ã€‚
4.  **ç†è®ºä¸å®è·µä¸€è‡´**ï¼šè®ºæ–‡æä¾›çš„ç†è®ºåˆ†æï¼ˆåœ¨è¯¯å·®æ ¡æ­£æœ‰æ•ˆçš„å‰æä¸‹ï¼Œé›†æˆæ€§èƒ½å•è°ƒæå‡ï¼‰å¾—åˆ°äº†å®éªŒç»“æœçš„æ”¯æŒã€‚

### æ–¹æ³•çš„å±€é™æ€§
*   **è·¨æ¨¡å‹å…¼å®¹æ€§é™åˆ¶**ï¼šå½“å‰æ–¹æ³•è¦æ±‚é›†æˆçš„å­æ¨¡å‹æ¥è‡ªåŒä¸€ç³»åˆ—ï¼ˆå¦‚å‡ä¸ºLlama-3æˆ–Qwen-2.5ï¼‰ï¼Œå› ä¸ºå®ƒä»¬éœ€è¦å…±äº«ç›¸åŒçš„åˆ†è¯å™¨ï¼ˆtokenizerï¼‰å’Œæ¶æ„è®¾è®¡ã€‚ä¸åŒç³»åˆ—æ¨¡å‹ï¼ˆå¦‚Llamaå’ŒQwenï¼‰ç”±äºåˆ†è¯ä¸ä¸€è‡´ï¼Œæ— æ³•ç›´æ¥åº”ç”¨æ­¤æ–¹æ³•ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
*   å°†æ¡†æ¶æ‰©å±•åˆ° **å¤šæ™ºèƒ½ä½“ (multi-agent)** åœºæ™¯ï¼Œè®©ä¸åŒæ™ºèƒ½ä½“ä¸“ç²¾äºæ¨ç†ã€è§„åˆ’æˆ–å·¥å…·ä½¿ç”¨ç­‰ä¸åŒä»»åŠ¡ã€‚
*   æ¢ç´¢ **è‡ªé€‚åº”è·¯ç”±æœºåˆ¶ (adaptive routing mechanisms)**ï¼Œæ ¹æ®ä»»åŠ¡ä¸Šä¸‹æ–‡åŠ¨æ€é€‰æ‹©æ™ºèƒ½ä½“æˆ–æ¨ç†è·¯å¾„ã€‚
*   ç»“åˆ **æŠ•æœºæ¨ç† (speculative reasoning)** æŠ€æœ¯ï¼Œè¿›ä¸€æ­¥é™ä½å¤§è§„æ¨¡éƒ¨ç½²æ—¶çš„å»¶è¿Ÿã€‚

</details>

---

### 6. [TL: Automatic End-to-End Compiler of Tile-Based Languages for Spatial Dataflow Architectures](https://arxiv.org/abs/2512.22168)

**Authors**: Wei Li, Zhenyu Bai, Heru Wang, Pranav Dangi, Zhiqiang Zhang, Cheng Tan, Huiying Lan, Weng-Fai Wong, Tulika Mitra  
**Category**: cs.DC  
**Published**: 2025-12-30  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2512.22168v1  

#### Abstract
Spatial dataflow accelerators are a promising direction for next-generation computer systems because they can reduce the memory bottlenecks of traditional von Neumann machines such as CPUs and GPUs. They do so by organizing computation around explicit, compiler-managed data movement over the on-chip...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# TL: Automatic End-to-End Compiler of Tile-Based Languages for Spatial Dataflow Architectures â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ç©ºé—´æ•°æ®æµæ¶æ„ï¼ˆ**spatial dataflow architectures**ï¼‰è™½ç„¶åœ¨èƒ½æ•ˆå’Œååé‡ä¸Šæ½œåŠ›å·¨å¤§ï¼Œä½†ç”±äºå…¶é«˜åº¦ä¾èµ–äºå¦‚ä½•å°†è®¡ç®—ä»»åŠ¡æ˜ å°„åˆ°åˆ†å¸ƒå¼æ ¸å¿ƒã€å†…å­˜å’Œç‰‡ä¸Šç½‘ç»œï¼ˆNoCï¼‰ï¼Œå¯¼è‡´ç¼–ç¨‹éš¾åº¦æé«˜ã€‚ç›®å‰å¤§å¤šæ•°ç”¨æˆ·ä¾èµ–å‚å•†æä¾›çš„æ‰‹å·¥ä¼˜åŒ–åº“ï¼ˆå¦‚ `TTNN`ï¼‰ï¼Œè¿™äº›åº“ä»…æ”¯æŒå°‘æ•°å›ºå®šç®—å­ï¼Œç¼ºä¹å¯ç§»æ¤æ€§å’Œçµæ´»æ€§ã€‚

å› æ­¤ï¼Œ**ä¸»è¦æŒ‘æˆ˜æ˜¯ï¼šå¦‚ä½•è‡ªåŠ¨åŒ–åœ°å°†é«˜å±‚ tile-based ç¨‹åºï¼ˆå¦‚ Triton å†…æ ¸ï¼‰ç¼–è¯‘ä¸ºé«˜æ€§èƒ½çš„ç©ºé—´æ•°æ®æµæ‰§è¡Œæ–¹æ¡ˆï¼Œæ¶µç›–ä» tile åˆ†å¸ƒã€é€šä¿¡è°ƒåº¦åˆ°èµ„æºåˆ†é…çš„å…¨è¿‡ç¨‹**ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹

è®ºæ–‡æå‡ºäº† **TL**ï¼ˆTileLoomï¼‰ï¼Œä¸€ä¸ªç«¯åˆ°ç«¯çš„ç¼–è¯‘æ¡†æ¶ï¼Œç”¨äºå°†åŸºäº tile çš„è¯­è¨€ï¼ˆå¦‚ Tritonï¼‰è‡ªåŠ¨ç¼–è¯‘åˆ°ç©ºé—´æ•°æ®æµæ¶æ„ä¸Šã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰ç»Ÿä¸€çš„ç¡¬ä»¶æŠ½è±¡æ¨¡å‹ï¼ˆ`df` dialectï¼‰
- å¼•å…¥äº†ä¸€ç§æ–°çš„ MLIR æ‰©å±•â€”â€”`df` dialectï¼Œç”¨äºæè¿°å¤šçº§ç¡¬ä»¶ç»“æ„ï¼š
  - **Scale-out æ¶æ„**ï¼šæ ¸å¿ƒé˜µåˆ—æ‹“æ‰‘ï¼ˆå¦‚ 2D meshã€ringï¼‰ã€NoC è¿æ¥æ–¹å¼
  - **Memory å±‚æ¬¡**ï¼šæœ¬åœ° scratchpadï¼ˆL1ï¼‰ã€DRAM é€šé“åŠå…¶å¸¦å®½
  - **Intra-core è®¡ç®—å•å…ƒ**ï¼šçŸ©é˜µå•å…ƒï¼ˆ`mat`ï¼‰ã€å‘é‡å•å…ƒï¼ˆ`vec`ï¼‰ç­‰æ€§èƒ½å‚æ•°
- æ”¯æŒè·¨ä¸åŒæ¶æ„ï¼ˆå¦‚ 2D meshã€1D ringï¼‰çš„å¯ç§»æ¤æ€§å»ºæ¨¡ã€‚

#### ï¼ˆ2ï¼‰å…¨è‡ªåŠ¨çš„æ—¶ç©ºæ˜ å°„ï¼ˆSpatiotemporal Mappingï¼‰
- å°†é€»è¾‘ tile ç½‘æ ¼ï¼ˆlogical tile gridï¼‰æ˜ å°„åˆ°ç‰©ç†æ ¸å¿ƒé˜µåˆ—å’Œæ—¶é—´ç»´åº¦ã€‚
- æ”¯æŒçµæ´»çš„ **tiling ç­–ç•¥**ï¼Œå†³å®šå“ªäº›ç»´åº¦æ˜ å°„ä¸ºç©ºé—´å¹¶è¡Œï¼ˆspatial dimsï¼‰ï¼Œå“ªäº›ä½œä¸ºæ—¶é—´æ‰¹å¤„ç†ï¼ˆtemporal wavesï¼‰ã€‚
- æ˜¾å¼æ§åˆ¶ tile å®ä¾‹åœ¨ç©ºé—´ï¼ˆcore åˆ†å¸ƒï¼‰å’Œæ—¶é—´ï¼ˆexecution scheduleï¼‰ä¸Šçš„å¸ƒå±€ã€‚

#### ï¼ˆ3ï¼‰è”åˆçš„æ•°æ®é‡ç”¨ä¸é€šä¿¡è§„åˆ’
- åœ¨ç»™å®šæ˜ å°„ä¸‹è¿›è¡Œ **æ•°æ®é‡ç”¨åˆ†æ**ï¼š
  - è‹¥è®¿é—®ä¸ä¾èµ–ç©ºé—´ç´¢å¼• â†’ å¯é€šè¿‡ **broadcast** å®ç°ç©ºé—´å¤ç”¨
  - è‹¥ä¸ä¾èµ–æ—¶é—´å¾ªç¯å˜é‡ â†’ å¯é€šè¿‡ **loop hoisting** å®ç°æ—¶é—´å¤ç”¨
- è‡ªåŠ¨ç”Ÿæˆå¤šç§åˆæ³•çš„å¹¿æ’­æ¨¡å¼ï¼ˆå¦‚è¡Œ/åˆ—å¹¿æ’­ã€wavefront ä¼ æ’­ï¼‰ï¼Œå¹¶ç»“åˆæ€§èƒ½æ¨¡å‹é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆã€‚

#### ï¼ˆ4ï¼‰åŸºäº MLIR çš„åˆ†å±‚ç¼–è¯‘æµç¨‹
- å‰ç«¯ï¼šæ¥æ”¶ Triton é£æ ¼çš„ tile kernel å’Œ launch gridï¼Œç”Ÿæˆæ ‡å‡†åŒ–çš„ dataflow-agnostic MLIR
- ä¸­é—´ï¼šé€šè¿‡ `dataflow planning` é˜¶æ®µå¼•å…¥ spatiotemporal mapping å’Œ memory movement
- åç«¯ï¼šå¯¹æ¥ Tenstorrent çš„ä½çº§ APIï¼ˆTT-Metaliumï¼‰ç”Ÿæˆ per-core å¯æ‰§è¡Œä»£ç 

#### ï¼ˆ5ï¼‰ä¸¤é˜¶æ®µå€™é€‰ç­›é€‰æœºåˆ¶ï¼ˆTop-k Selectionï¼‰
- åˆ©ç”¨ **æ€§èƒ½æ¨¡å‹** å¯¹æ‰€æœ‰å€™é€‰ mapping è¿›è¡Œé™æ€æ’åºï¼Œé€‰å‡º top-k
- åœ¨çœŸå®ç¡¬ä»¶ä¸Šå¯¹ top-k å€™é€‰è¿›è¡Œ profilingï¼Œæœ€ç»ˆé€‰å–æœ€ä¼˜é…ç½®ï¼ˆtop-1ï¼‰
- å¹³è¡¡äº†æœç´¢å¼€é”€ä¸æ€§èƒ½ä¸Šé™ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ TTNNï¼‰ | TL |
|------|---------------------|----|
| æ˜ å°„ç­–ç•¥ | å›ºå®šæ¨¡æ¿ï¼ˆTT-1D / TT-2Dï¼‰ | è‡ªåŠ¨æ¢ç´¢å¤§è§„æ¨¡ mapping ç©ºé—´ |
| æ•°æ®å¤ç”¨ | æ‰‹å·¥è®¾è®¡ï¼Œéš¾ä»¥æ³›åŒ– | è‡ªåŠ¨è¯†åˆ«ç©ºé—´/æ—¶é—´å¤ç”¨æœºä¼š |
| æ¶æ„é€‚é…æ€§ | è€¦åˆç‰¹å®šç¡¬ä»¶ | é€šè¿‡ `df` dialect æ”¯æŒå¤šæ¶æ„ |
| æ–°ç®—å­æ”¯æŒ | ä¾èµ–ä¸“å®¶æ‰‹åŠ¨å¼€å‘ | æ”¯æŒä»»æ„ tile-based kernel ç¼–è¯‘ |
| æ€§èƒ½é²æ£’æ€§ | åœ¨éå…¸å‹å½¢çŠ¶ä¸‹è¡¨ç°å·® | åŠ¨æ€é€‚åº”è¾“å…¥å°ºå¯¸ä¸ç¡¬ä»¶æ‹“æ‰‘ |

> TL å®ç°äº†â€œå°†æ‰‹å†™ä¼˜åŒ–å†…æ ¸å˜ä¸ºç¼–è¯‘å™¨è¾“å‡ºâ€çš„ç›®æ ‡ï¼Œæ˜¾è‘—é™ä½å¼€å‘é—¨æ§›ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ’» å®éªŒå¹³å°
- **ç¡¬ä»¶**ï¼šTenstorrent Wormhole n300d åŠ é€Ÿå¡
  - æ¯ socket 64 ä¸ª Tensix cores @ 1GHz
  - å³°å€¼ç®—åŠ›ï¼š64 TFLOP/s per socketï¼ˆFP16ï¼‰
  - ç‰‡ä¸Š SRAMï¼š96MBï¼ŒGDDR6 DRAMï¼š12GB @ 288 GB/s
- **ä¸»æœº**ï¼šåŒè·¯ Intel Xeon Gold 6326 CPU + 512GB DRAM

### ğŸ§ª è¯„ä¼°çš„é€»è¾‘æ¶æ„é…ç½®ï¼ˆæ¨¡æ‹Ÿä¸åŒæ‹“æ‰‘ï¼‰
| é…ç½® | æè¿° |
|------|------|
| `1Ã—8 Ring` | ä¸€ç»´ç¯å½¢ç»“æ„ |
| `4Ã—8 Mesh` | éå¯¹ç§°çŸ©å½¢ç½‘æ ¼ |
| `8Ã—8 Mesh` | å®Œæ•´å¯¹ç§°äºŒç»´ç½‘æ ¼ |

> ç”¨äºç ”ç©¶æ‹“æ‰‘å¯¹æœ€ä¼˜ dataflow çš„å½±å“ã€‚

---

### ğŸ“Š å·¥ä½œè´Ÿè½½ï¼ˆWorkloadsï¼‰
1. **GEMM**ï¼ˆGeneral Matrix Multiplicationï¼‰
   - å½¢å¼ï¼š`C[M,N] = A[M,K] Ã— B[K,N]`
   - æµ‹è¯•èŒƒå›´ï¼šM/N/K âˆˆ [256, 16384]
   - åŒ…æ‹¬è§„åˆ™ä¸ä¸è§„åˆ™å½¢çŠ¶ï¼ˆå¦‚å›ºå®š M=N=32768 å˜ Kï¼›å›ºå®š M=K=32768 å˜ Nï¼‰

2. **FlashAttention**
   - éå› æœæ³¨æ„åŠ›å˜ä½“
   - å‚æ•°æ‰«æï¼š
     - æ³¨æ„åŠ›å¤´æ•°ï¼š64 ~ 128
     - åºåˆ—é•¿åº¦ï¼š512 ~ 8192
     - æ€» token æ•°å›ºå®šä¸º 8192ï¼ˆæ§åˆ¶æ˜¾å­˜å ç”¨ï¼‰

---

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
- **æ€§èƒ½**ï¼šå®æµ‹ååç‡ï¼ˆTFLOP/sï¼‰æˆ–åŠ é€Ÿæ¯”ï¼ˆspeedupï¼‰
- **å¯¹æ¯”åŸºçº¿**ï¼š
  - **TTNN**ï¼šTenstorrent å®˜æ–¹åº“ï¼Œé‡‡ç”¨ TT-1D / TT-2D æ¨¡æ¿è‡ªåŠ¨é€‰æ‹©
  - **TT-1D / TT-2D**ï¼šä¸¤ç§å›ºå®š dataflow æ¨¡æ¿
- **æ¶ˆèå®éªŒ**ï¼š
  - å…³é—­ spatial reuseï¼ˆå…¨éƒ¨ä» DRAM åŠ è½½ï¼‰
  - å…³é—­ temporal reuseï¼ˆç¦æ­¢ loop hoistingï¼‰
  - ä¸åŒ `top-k` è®¾ç½®ä¸‹çš„æ€§èƒ½ä¸ç¼–è¯‘æ—¶é—´æƒè¡¡

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š GEMM ç»“æœï¼ˆ8Ã—8 Meshï¼‰
| æŒ‡æ ‡ | TL vs. TTNN |
|------|-----------|
| å‡ ä½•å¹³å‡åŠ é€Ÿæ¯” | **1.03Ã—** |
| è¶…è¿‡ TTNN çš„æ¯”ä¾‹ | **62.8%** çš„é…ç½®æ›´å¿« |
| æœ€å¤§åŠ é€Ÿæ¯” | è¾¾ **2.19Ã—** |
| æ¥è¿‘æœ€ä¼˜ï¼ˆÂ±10%ï¼‰æ¯”ä¾‹ | **78.5%**

> TL åœ¨å¤šæ•°æƒ…å†µä¸‹ä¼˜äºæˆ–æŒå¹³äºå‚å•†åº“ï¼Œå°¤å…¶åœ¨å¤§å°ºå¯¸çŸ©é˜µä¸­ä¼˜åŠ¿æ˜æ˜¾ã€‚

#### ä¸åŒæ‹“æ‰‘çš„å½±å“ï¼ˆFigure 5ï¼‰
- åœ¨ `4Ã—8` éå¯¹ç§° mesh ä¸Šï¼ŒTT-1D æ›´ä¼˜ï¼›è€Œåœ¨ `8Ã—8` å¯¹ç§° mesh ä¸Šï¼ŒTT-2D æ›´å¥½
- **TL èƒ½è‡ªé€‚åº”åœ°é€‰æ‹©æ›´åˆé€‚çš„ dataflow**ï¼Œè€Œ TTNN å› å¯å‘å¼ç­–ç•¥å¤±è´¥å¯¼è‡´æ€§èƒ½ä¸‹é™

#### ä¸è§„åˆ™å½¢çŠ¶æµ‹è¯•ï¼ˆFigure 6ï¼‰
- å½“ `N << M` æ—¶ï¼Œ1D å¹¿æ’­æ›´é«˜æ•ˆ â†’ TL æ­£ç¡®é€‰æ‹©
- å½“ `N â‰ˆ M` æ—¶ï¼Œ2D systolic-style æ›´ä¼˜ â†’ TL æˆåŠŸæ•æ‰è¶‹åŠ¿
- **TTNN é”™è¯¯é€‰æ‹©äº† 2D æ¨¡æ¿**ï¼ˆå³ä½¿ 1D æ›´å¿«ï¼‰ï¼Œæš´éœ²å…¶ç­–ç•¥åƒµåŒ–é—®é¢˜

---

### âš¡ FlashAttention ç»“æœ
| è®¾ç½® | TL åŠ é€Ÿæ¯” |
|------|----------|
| nhead=64 | **1.70â€“1.99Ã—** |
| nhead=128 | **1.73â€“1.98Ã—** |
| å‡ ä½•å¹³å‡ | **~1.91Ã—** |

> TL åœ¨å‡ ä¹æ‰€æœ‰é…ç½®ä¸‹å‡å–å¾—æ¥è¿‘ **2Ã—** çš„ç¨³å®šåŠ é€Ÿã€‚

#### åŸå› åˆ†æï¼š
- TL è‡ªåŠ¨å®ç°äº† **key æ•°æ®çš„ on-chip å¤ç”¨**ï¼Œé¿å…é‡å¤ä» DRAM åŠ è½½
- è€Œ TTNN é»˜è®¤ mapping å¯¼è‡´å¤§é‡å†—ä½™è®¿å­˜
- æ€§èƒ½æ¨¡å‹æœ‰æ•ˆå¼•å¯¼ç¼–è¯‘å™¨é€‰æ‹©é«˜å¤ç”¨ã€ä½é€šä¿¡æˆæœ¬çš„ mapping

---

### ğŸ” æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰Spatial Reuse æ¶ˆèï¼ˆTable 1ï¼‰
| é…ç½® (M=K=N) | æ—  spatial reuseï¼ˆDRAM onlyï¼‰ | TLï¼ˆå¯ç”¨ spatial reuseï¼‰ | Speedup |
|-------------|-------------------------------|-------------------------|--------|
| 1024        | 11.15 TFLOP/s                 | 23.70 TFLOP/s           | **2.12Ã—** |
| 2048        | 16.77                         | 33.96                   | **2.03Ã—** |
| 4096        | 22.96                         | 40.44                   | **1.76Ã—** |
| 5120        | 29.19                         | 41.61                   | **1.42Ã—** |

> spatial reuse åœ¨å°è§„æ¨¡é—®é¢˜ä¸­æ”¶ç›Šæœ€å¤§ï¼Œéšç€é—®é¢˜å¢å¤§è¶‹äº compute-boundï¼Œå¢ç›Šä¸‹é™ä½†ä»æ˜¾è‘—å‡å°‘ DRAM æµé‡ï¼ˆå¹³å‡å‡å°‘ **70%**ï¼‰ã€‚

#### ï¼ˆ2ï¼‰Temporal Reuse æ¶ˆèï¼ˆFigure 8ï¼‰
- åœ¨ memory-bound åœºæ™¯ä¸‹ï¼ˆK å°ï¼ŒM/N å¤§ï¼‰ï¼Œtemporal reuse å¯å¸¦æ¥æœ€é«˜ **1.12Ã—** æå‡
- ç‰¹åˆ«å½“ M æˆ– N å¾ˆå¤§æ—¶ï¼Œç¼“å†² A/B tile æ˜¾è‘—å‡å°‘é‡å¤åŠ è½½æ¬¡æ•°
- æ€§èƒ½æ¨¡å‹èƒ½è‡ªåŠ¨ deprioritize æ— æ•ˆ hoisting æ–¹æ¡ˆ

#### ï¼ˆ3ï¼‰æ€§èƒ½æ¨¡å‹å‡†ç¡®æ€§ï¼ˆFigure 9ï¼‰
- é¢„æµ‹æ€§èƒ½ä¸å®æµ‹æ€§èƒ½çš„å‡ ä½•å¹³å‡è¯¯å·®ï¼š**17%**
- èƒ½å‡†ç¡®æ•æ‰ **roofline è¶‹åŠ¿**ï¼ˆmemory-bound â†’ compute-bound çš„è¿‡æ¸¡ï¼‰
- æ”¯æŒæœ‰æ•ˆ rankingï¼Œä½¿å¾— top-5 å€™é€‰ä¸­å¤§æ¦‚ç‡åŒ…å«æœ€ä¼˜è§£

#### ï¼ˆ4ï¼‰Top-k é€‰æ‹©çš„å½±å“ï¼ˆTable 2ï¼‰
| k å€¼ | 8Ã—8 Mesh ç›¸å¯¹ TTNN æ€§èƒ½ | ç¼–è¯‘æ—¶é—´ï¼ˆç§’ï¼‰ |
|------|--------------------------|----------------|
| top-1ï¼ˆçº¯é™æ€ï¼‰ | -6.5%                    | 5.31           |
| top-2            | -0.7%                    | 10.54          |
| top-5            | **+2.8%**                | 26.42          |

> å³ä½¿åªé€‰ top-2ï¼Œä¹Ÿèƒ½å¤§å¹…ç¼©å°ä¸æœ€ä¼˜çš„å·®è·ï¼Œå®ç°è‰¯å¥½çš„æ€§ä»·æ¯”å¹³è¡¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ç©ºé—´æ•°æ®æµæ¶æ„çš„æ€§èƒ½é«˜åº¦ä¾èµ– mapping ç­–ç•¥**ï¼Œå›ºå®šæ¨¡æ¿ï¼ˆå¦‚ TT-1D/TT-2Dï¼‰æ— æ³•é€‚åº”å¤šæ ·åŒ–çš„è¾“å…¥å½¢çŠ¶å’Œç¡¬ä»¶æ‹“æ‰‘ã€‚
2. **TL èƒ½è‡ªåŠ¨å‘ç°é«˜è´¨é‡çš„ dataflow mapping**ï¼Œåœ¨ GEMM å’Œ FlashAttention ä¸Šè¾¾åˆ°ç”šè‡³è¶…è¶Šå‚å•†æ‰‹å·¥ä¼˜åŒ–åº“çš„è¡¨ç°ã€‚
3. **ç©ºé—´å¤ç”¨ï¼ˆspatial reuseï¼‰æ˜¯æå‡æ€§èƒ½çš„å…³é”®**ï¼Œå°¤å…¶æ˜¯åœ¨ä¸­å°è§„æ¨¡é—®é¢˜ä¸­å¯å¸¦æ¥æ•°å€åŠ é€Ÿã€‚
4. **æ—¶é—´å¤ç”¨ï¼ˆtemporal reuseï¼‰è™½å¢ç›Šè¾ƒå°ï¼Œä½†åœ¨ç‰¹å®šåœºæ™¯ä¸‹ä»å…·ä»·å€¼**ï¼Œä¸”å¯é€šè¿‡æ€§èƒ½æ¨¡å‹è‡ªåŠ¨å†³ç­–æ˜¯å¦å¯ç”¨ã€‚
5. **åŸºäº `df` dialect çš„ç¡¬ä»¶æŠ½è±¡ä½¿ TL å…·å¤‡è‰¯å¥½å¯ç§»æ¤æ€§**ï¼Œæ˜“äºæ‰©å±•è‡³å…¶ä»–ç©ºé—´æ¶æ„ï¼ˆå¦‚ 1D ringã€systolic arrayï¼‰ã€‚

---

### âš ï¸ å±€é™æ€§
1. **æ€§èƒ½æ¨¡å‹ç²¾åº¦å—é™äºåº•å±‚ç¡¬ä»¶ç»†èŠ‚ç¼ºå¤±**ï¼š
   - ç¼ºå°‘ç²¾ç¡®çš„å¾®æ¶æ„å‚æ•°ï¼ˆå¦‚ç¼“å­˜å»¶è¿Ÿã€æµæ°´çº¿æ·±åº¦ï¼‰
   - åœ¨æå°è§„æ¨¡ kernel ä¸Šé¢„æµ‹ä¸å‡†ï¼Œå½±å“ top-1 é€‰æ‹©è´¨é‡
2. **å½“å‰å‰ç«¯ä»…æ”¯æŒ Triton**ï¼Œå°šæœªé›†æˆæ›´å¤š tile-based DSLï¼ˆå¦‚ TileLangã€CuTileï¼‰
3. **æœªè€ƒè™‘åŠ¨æ€è°ƒåº¦æˆ–è¿è¡Œæ—¶åé¦ˆ**ï¼Œå®Œå…¨ä¾èµ–é™æ€ç¼–è¯‘
4. **ç¼–è¯‘æ—¶é—´éš top-k å¢åŠ çº¿æ€§å¢é•¿**ï¼Œä¸é€‚åˆå®æ—¶ç¼–è¯‘åœºæ™¯

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **å¢å¼ºæ€§èƒ½æ¨¡å‹**ï¼š
   - å¼•å…¥æœºå™¨å­¦ä¹ æ ¡å‡†æ¨¡å—ï¼Œæå‡é¢„æµ‹å‡†ç¡®æ€§
   - æ”¯æŒæ›´ç»†ç²’åº¦çš„ microarchitectural å»ºæ¨¡
2. **æ”¯æŒåŠ¨æ€ dataflow ç¼–æ’**ï¼š
   - ç»“åˆ runtime profiling å®ç° adaptive mapping
3. **æ‰©å±•å‰ç«¯è¯­è¨€æ”¯æŒ**ï¼š
   - æ¥å…¥ TVMã€Halideã€Taichi ç­‰ç³»ç»Ÿ
4. **å‘ä¸Šæ¸¸é›†æˆåˆ° PyTorch/TensorFlow ç”Ÿæ€**
5. **ç”¨äºèŠ¯ç‰‡è®¾è®¡æ¢ç´¢ï¼ˆdesign-space explorationï¼‰**ï¼š
   - åˆ©ç”¨ `df` æè¿°ä¸åŒæ¶æ„å˜ä½“ï¼Œè¾…åŠ©ç¡¬ä»¶-è½¯ä»¶ååŒè®¾è®¡

---

## æ€»ç»“

> **TL æ˜¯é¦–ä¸ªå®ç°ä» tile-based kernel åˆ°ç©ºé—´æ•°æ®æµæ¶æ„ç«¯åˆ°ç«¯è‡ªåŠ¨ç¼–è¯‘çš„æ¡†æ¶**ã€‚å®ƒé€šè¿‡å¼•å…¥ `df` dialect ç»Ÿä¸€æè¿°ç¡¬ä»¶ï¼Œå¹¶ç»“åˆ spatiotemporal mappingã€reuse åˆ†æä¸æ€§èƒ½å»ºæ¨¡ï¼Œåœ¨æ— éœ€äººå·¥å¹²é¢„çš„æƒ…å†µä¸‹ï¼Œç”Ÿæˆåª²ç¾ç”šè‡³è¶…è¶Šå‚å•†åº“çš„é«˜æ•ˆæ‰§è¡Œæ–¹æ¡ˆã€‚è¯¥å·¥ä½œæ¨åŠ¨äº†ç©ºé—´æ•°æ®æµæ¶æ„ä»â€œä¸“å®¶ä¸“å±â€èµ°å‘â€œå¤§ä¼—å¯ç”¨â€ï¼Œä¸ºä¸‹ä¸€ä»£ AI åŠ é€Ÿå™¨çš„ç¼–ç¨‹æ¨¡å‹æä¾›äº†é‡è¦èŒƒå¼ã€‚

</details>

---

### 7. [WeDLM: Reconciling Diffusion Language Models with Standard Causal Attention for Fast Inference](https://arxiv.org/abs/2512.22737)

**Authors**: Aiwei Liu, Minghua He, Shaoxun Zeng, Sijun Zhang, Linhao Zhang, Chuhan Wu, Wei Jia, Yuan Liu, Xiao Zhou, Jie Zhou  
**Category**: cs.CL  
**Published**: 2025-12-30  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.22737v1  

#### Abstract
Autoregressive (AR) generation is the standard decoding paradigm for Large Language Models (LLMs), but its token-by-token nature limits parallelism at inference time. Diffusion Language Models (DLLMs) offer parallel decoding by recovering multiple masked tokens per step; however, in practice they of...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# WeDLM: Reconciling Diffusion Language Models with Standard Causal Attention for Fast Inference è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿçš„ **Autoregressive (AR)** ç”Ÿæˆæ¨¡å‹å—é™äºé€tokenç”Ÿæˆçš„ä¸²è¡Œç‰¹æ€§ï¼Œåœ¨æ¨ç†æ—¶éš¾ä»¥å……åˆ†åˆ©ç”¨ç°ä»£ç¡¬ä»¶çš„å¹¶è¡Œèƒ½åŠ›ï¼Œå¯¼è‡´å»¶è¿Ÿé«˜ã€ååä½ã€‚è™½ç„¶ **Diffusion Language Models (DLLMs)** æ”¯æŒå¹¶è¡Œè§£ç ï¼Œä½†åœ¨å®é™…éƒ¨ç½²ä¸­å¹¶æœªæ˜¾è‘—è¶…è¶Šä¼˜åŒ–è¿‡çš„ AR å¼•æ“ï¼ˆå¦‚ vLLMï¼‰ï¼Œä¸»è¦åŸå› å¦‚ä¸‹ï¼š
- å¤šæ•° DLLMs ä½¿ç”¨ **bidirectional attention**ï¼Œç ´åäº†æ ‡å‡†çš„ **prefix KV caching** æœºåˆ¶ï¼Œå¯¼è‡´ä¸Šä¸‹æ–‡éœ€è¦é‡å¤è®¡ç®—ï¼Œæ•ˆç‡ä½ä¸‹ã€‚
- å­˜åœ¨è®­ç»ƒ-æ¨ç†åˆ†å¸ƒä¸ä¸€è‡´ï¼ˆtrain-inference gapï¼‰å’Œâ€œåœç­‰â€ï¼ˆstop-and-waitï¼‰è¡Œä¸ºã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ ¸å¿ƒæ€æƒ³
æœ¬æ–‡æå‡º **WeDLM**ï¼Œä¸€ç§åŸºäº**æ ‡å‡†å› æœæ³¨æ„åŠ›**ï¼ˆcausal attentionï¼‰çš„æ‰©æ•£è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°é«˜æ•ˆã€å¯ç¼“å­˜çš„å¹¶è¡Œç”Ÿæˆã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### âœ… **Topological Reorderingï¼ˆæ‹“æ‰‘é‡æ’åºï¼‰**
- å°†å·²è§‚æµ‹åˆ°çš„ token ç§»åŠ¨åˆ°ç‰©ç†å‰ç¼€ä½ç½®ï¼ŒåŒæ—¶é€šè¿‡ RoPE çš„ position ids ä¿ç•™å…¶é€»è¾‘ä½ç½®ã€‚
- åœ¨ä¿æŒä¸¥æ ¼å› æœæ©ç çš„å‰æä¸‹ï¼Œä½¿æ¯ä¸ªè¢«æ©ç çš„ä½ç½®éƒ½èƒ½è®¿é—®æ‰€æœ‰å½“å‰å·²çŸ¥çš„ä¸Šä¸‹æ–‡ã€‚
- å®ç°äº†ä¸ AR æ¨¡å‹å®Œå…¨å…¼å®¹çš„ **KV caching**ï¼Œé¢„æµ‹åçš„ token å¯ç«‹å³ç¼“å­˜å¤ç”¨ã€‚

#### âœ… **Dual-Stream Maskingï¼ˆåŒæµæ©ç ï¼‰**
- å¼•å…¥ä¸¤ä¸ªæµï¼š**Memory Stream**ï¼ˆå¹²å‡€å†å²ï¼‰å’Œ **Prediction Stream**ï¼ˆå¸¦æ©ç çš„å¾…é¢„æµ‹éƒ¨åˆ†ï¼‰ã€‚
- è®­ç»ƒæ—¶è®©é¢„æµ‹æµä¾èµ–äºè®°å¿†æµä¸­çš„å¹²å‡€ä¸Šä¸‹æ–‡ï¼Œè€Œéè‡ªèº«ä¸­é—´é¢„æµ‹ç»“æœï¼Œä»è€Œç¼©å°è®­ç»ƒä¸æ¨ç†ä¹‹é—´çš„å·®è·ã€‚

#### âœ… **Streaming Parallel Decodingï¼ˆæµå¼å¹¶è¡Œè§£ç ï¼‰**
- åŠ¨æ€ç»´æŠ¤ä¸€ä¸ªå›ºå®šå¤§å°çš„æ»‘åŠ¨çª—å£ï¼ŒæŒç»­å¡«å……æ–°çš„ `[MASK]` ä»¥ç»´æŒç¨³å®šçš„å¹¶è¡Œè´Ÿè½½ã€‚
- ä½¿ç”¨ **distance-penalized entropy selection** ä¼˜å…ˆè§£ç é å·¦çš„ tokenï¼Œä¿ƒè¿›ä»å·¦åˆ°å³çš„è¿ç»­å‰ç¼€å¢é•¿ã€‚
- é¿å… block-wise æ–¹æ³•ä¸­çš„â€œæ•´å—å®Œæˆæ‰æäº¤â€çš„åŒæ­¥ç­‰å¾…é—®é¢˜ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | WeDLM | ä¼ ç»Ÿ DLLMsï¼ˆå¦‚ LLaDA, Dreamï¼‰ | Block-wise DLLMsï¼ˆå¦‚ SDARï¼‰ |
|------|-------|-------------------------------|------------------------------|
| Attention ç±»å‹ | **Causal** | Bidirectional | Mixed (causal across blocks) |
| KV Cache å…¼å®¹æ€§ | âœ… å®Œå…¨å…¼å®¹ï¼Œå³æ—¶ç¼“å­˜ | âŒ ä¸å…¼å®¹ï¼Œéœ€é‡ç®— | âš ï¸ å—çº§ç¼“å­˜ï¼Œå»¶è¿Ÿå¯ç”¨ |
| å¹¶è¡Œæ•ˆç‡ | é«˜ï¼ˆåŠ¨æ€å¡«å…… + å³æ—¶æäº¤ï¼‰ | é«˜ä½†æ— æ³•æœ‰æ•ˆå¤ç”¨ | ä¸­ç­‰ï¼ˆå­˜åœ¨ pipeline bubblesï¼‰ |
| æ¨ç†é€Ÿåº¦ | æ˜¾è‘—ä¼˜äº vLLM | é€šå¸¸æ…¢äº vLLM | ç•¥ä¼˜æˆ–æŒå¹³ |
| éƒ¨ç½²å…¼å®¹æ€§ | å¯ç›´æ¥è¿è¡Œäº vLLM / FlashAttention / PagedAttention | éœ€ä¸“ç”¨å¼•æ“ï¼ˆå¦‚ dInferï¼‰ | éœ€å®šåˆ¶å¼•æ“ï¼ˆå¦‚ JetEngineï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å¤šä¸ªç»´åº¦çš„ä»»åŠ¡åŸºå‡†ï¼š
- **æ•°å­¦æ¨ç†**ï¼šGSM8Kï¼ˆ3-shotï¼‰ã€MATHï¼ˆ4-shotï¼‰ã€GPQA-Diamondï¼ˆ5-shotï¼‰
- **é€šç”¨çŸ¥è¯†**ï¼šMMLUï¼ˆ5-shotï¼‰ã€ARC-C/Eï¼ˆ0-shotï¼‰ã€HellaSwagï¼ˆ10-shotï¼‰
- **ä»£ç ç”Ÿæˆ**ï¼šHumanEvalï¼ˆ4-shotï¼‰ã€HumanEval-plusï¼ˆ4-shotï¼‰ã€MBPPï¼ˆ3-shotï¼‰

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼šQwen2.5-7B å’Œ Qwen3-8B
- **è®­ç»ƒæµç¨‹**ï¼š
  - ç»§ç»­é¢„è®­ç»ƒï¼ˆcontinued pretrainingï¼‰ï¼š100B tokens
  - ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼š10K å†…éƒ¨æŒ‡ä»¤å¯¹
- **æ¨ç†é…ç½®**ï¼š
  - ç»Ÿä¸€é‡‡ç”¨ step-wise è§£ç æ–¹æ¡ˆ
  - çª—å£å¤§å° `W=6`ï¼Œè·ç¦»æƒ©ç½šç³»æ•° `Î»=0.1`
  - é‡‡æ ·æ¸©åº¦ `0.1`ï¼Œæœ€å¤§ç”Ÿæˆé•¿åº¦ `512`

### è¯„ä¼°æŒ‡æ ‡
- **ç”Ÿæˆè´¨é‡**ï¼šå„ä»»åŠ¡å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰
- **æ¨ç†æ•ˆç‡**ï¼š
  - **End-to-end æ¨ç†é€Ÿåº¦**ï¼ˆtokens/sï¼‰
  - **Prefix Cacheability (Pcache)**ï¼šè¡¡é‡é¢„æµ‹ token èƒ½å¦è½¬åŒ–ä¸ºå¯ç¼“å­˜å‰ç¼€çš„æ¯”ä¾‹
- **å…¬å¹³æ¯”è¾ƒ**ï¼šæ‰€æœ‰æ¨¡å‹å‡åœ¨å…¶æ¨èç³»ç»Ÿä¸ŠæœåŠ¡ï¼š
  - AR æ¨¡å‹ â†’ vLLM
  - LLaDA/Dream â†’ dInfer
  - SDAR â†’ JetEngine
  - WeDLM â†’ vLLMï¼ˆä½“ç°éƒ¨ç½²å…¼å®¹æ€§ï¼‰

### å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
- **AR Baselines**ï¼šQwen2.5-7B, Qwen3-8B
- **DLLM Baselines**ï¼šLLaDA-8B, Dream-7B, SDAR-8B

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & 2ï¼‰

#### âœ… Base æ¨¡å‹è¡¨ç°ï¼ˆTable 1ï¼‰
| æ¨¡å‹ | å¹³å‡å¾—åˆ† |
|------|----------|
| Qwen2.5-7B (AR) | 67.21 |
| Qwen3-8B (AR) | 72.61 |
| LLaDA-8B | 55.44 |
| Dream-7B | 56.91 |
| **WeDLM-7B** | **70.84** |
| **WeDLM-8B** | **74.72** |

> WeDLM-8B è¶…è¶Šå…¶ AR åŸºåº§ Qwen3-8Bï¼ˆ+2.1 ptsï¼‰ï¼Œä¸”å¤§å¹…é¢†å…ˆå…¶ä»– DLLMsï¼ˆ+18~19 ptsï¼‰

#### âœ… Instruct æ¨¡å‹è¡¨ç°ï¼ˆTable 2ï¼‰
| æ¨¡å‹ | å¹³å‡å¾—åˆ† |
|------|----------|
| Qwen2.5-7B-Instruct | 71.09 |
| Qwen3-8B-Instruct | 75.12 |
| SDAR-8B (best DLLM baseline) | 74.22 |
| **WeDLM-8B-Instruct** | **77.53** |

> WeDLM-8B-Instruct è¾¾åˆ°æœ€å¼ºç»¼åˆæ€§èƒ½ï¼Œå°¤å…¶åœ¨ **HumanEval (80.49)** å’Œ **GPQA-Diamond (44.95)** ä¸Šé¢†å…ˆæ˜æ˜¾ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **é€Ÿåº¦ä¼˜åŠ¿æ˜¾è‘—**ï¼ˆå›¾1, å›¾5ï¼‰ï¼š
  - åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ï¼ˆå¦‚ GSM8Kï¼‰ä¸Šï¼Œç›¸æ¯” vLLM ä¼˜åŒ–çš„ AR æ¨¡å‹ï¼ŒWeDLM å®ç° **æ¥è¿‘ 3Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿ**ã€‚
  - åœ¨ä½ç†µç”Ÿæˆåœºæ™¯ï¼ˆå¦‚è®¡æ•°ã€å…¬å¼æ¨å¯¼ï¼‰ï¼Œé€Ÿåº¦æå‡å¯è¾¾ **10Ã— ä»¥ä¸Š**ï¼ˆå³°å€¼è¾¾ 1673.3 t/sï¼‰ã€‚
- **è´¨é‡ä¸é™åå‡**ï¼š
  - WeDLM ä¸ä»…ä¿æŒäº†åŸ AR æ¨¡å‹çš„èƒ½åŠ›ï¼Œè¿˜åœ¨å¤šæ•°ä»»åŠ¡ä¸Šæœ‰æ‰€æå‡ï¼Œè¯´æ˜æ‰©æ•£è®­ç»ƒç›®æ ‡ä¸æŒ‡ä»¤å¾®è°ƒç›¸å®¹ç”šè‡³å¢å¼ºã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ğŸ” Streaming vs Block-wise Decodingï¼ˆå›¾4cï¼‰
- æµå¼è§£ç åœ¨ç›¸åŒç†µé˜ˆå€¼ä¸‹æ¯” block-wise å¿« **1.9Ã—**ï¼ˆ423 vs 221 t/sï¼‰ã€‚
- åŸå› ï¼šblock-wise å¿…é¡»ç­‰å¾…æ•´å—å®Œæˆæ‰èƒ½æäº¤ï¼ŒPcache æ›´ä½ï¼›è€Œ streaming å¯å³æ—¶æäº¤å·²ç¡®è®¤ tokenã€‚

#### ğŸ” Distance Penalty Î» çš„å½±å“ï¼ˆå›¾4bï¼‰
- å¢åŠ  Î»ï¼ˆåå‘å·¦ä¾§ tokenï¼‰å¯æå‡ accuracyï¼ˆæœ€é«˜ +2.6 ptsï¼‰ï¼Œä»…è½»å¾®é™ä½é€Ÿåº¦ï¼ˆ-3%ï¼‰ã€‚
- è¡¨æ˜ left-to-right commitment æœ‰åŠ©äºå‡å°‘é”™è¯¯ä¼ æ’­ï¼Œæé«˜ Pcacheã€‚

#### ğŸ” Block Size æ•æ„Ÿæ€§ï¼ˆå›¾5bï¼‰
- åœ¨è®­ç»ƒé˜¶æ®µå°è¯•ä¸åŒ block sizeï¼ˆ4, 8, 32ï¼‰ï¼Œæ€§èƒ½å‡ ä¹ä¸å˜ï¼ˆå¹³å‡åˆ†å·® < 0.8 ptsï¼‰ã€‚
- è¯´æ˜ WeDLM å¯¹ block è®¾è®¡é²æ£’ï¼Œä¾¿äºçµæ´»éƒ¨ç½²ã€‚

#### ğŸ” Causal vs Bidirectional Intra-block Attentionï¼ˆå›¾5cï¼‰
- å³ä¾¿åœ¨åŒä¸€ block å†…ä½¿ç”¨ bidirectional attentionï¼Œæ€§èƒ½ä¹Ÿä½äº fully causal è®¾è®¡ã€‚
- è¿›ä¸€æ­¥éªŒè¯ï¼š**causal ç»“æ„æ›´åˆ©äº cache-friendly è§£ç **ï¼Œä¸”æ— éœ€ç‰ºç‰²æ€§èƒ½ã€‚

#### ğŸ” Base Model Scale å½±å“ï¼ˆå›¾5cï¼‰
- å°æ¨¡å‹ï¼ˆ0.6B, 1.5Bï¼‰é€‚åº” WeDLM åç•¥æœ‰ä¸‹é™ï¼›
- å¤§æ¨¡å‹ï¼ˆ7B+ï¼‰åˆ™ç¨³å®šæå‡ï¼ˆ+3.6 ptsï¼‰ï¼›
- æš—ç¤ºï¼š**æ›´å¼ºçš„ AR checkpoint æ›´å®¹æ˜“æˆåŠŸè¿ç§»åˆ° diffusion æ¡†æ¶**ï¼Œå¯èƒ½å­˜åœ¨ scaling lawã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **KV caching æ˜¯å†³å®šå®é™…æ¨ç†æ•ˆç‡çš„å…³é”®å› ç´ **ï¼Œè¿œæ¯”â€œæ¯æ­¥é¢„æµ‹å¤šå°‘ tokenâ€æ›´é‡è¦ã€‚
2. **Bidirectional attention å¹¶éå¹¶è¡Œç”Ÿæˆæ‰€å¿…éœ€**ï¼Œé€šè¿‡ Topological Reordering å¯åœ¨ causal attention ä¸‹å®ç°å…¨å±€ä¸Šä¸‹æ–‡å¯è§ã€‚
3. **WeDLM æˆåŠŸå°† diffusion-style å¹¶è¡Œæ€§ä¸ AR å¼ caching å®Œç¾ç»“åˆ**ï¼Œé¦–æ¬¡åœ¨çœŸå®éƒ¨ç½²æ¡ä»¶ä¸‹ï¼ˆä½¿ç”¨ vLLMï¼‰è¶…è¶Šå·¥ä¸šçº§ AR å¼•æ“ã€‚
4. æ‰©æ•£è®­ç»ƒä¸ä»…èƒ½æé€Ÿï¼Œè¿˜èƒ½**æå‡æ¨¡å‹èƒ½åŠ›**ï¼Œå°¤å…¶æ˜¯åœ¨æ•°å­¦ä¸ä»£ç ä»»åŠ¡ä¸Šã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **æ€§èƒ½å¢ç›Šé«˜åº¦ä¾èµ–è¾“å‡ºç†µ**ï¼š
  - ä½ç†µä»»åŠ¡ï¼ˆå¦‚è®¡æ•°ã€å…¬å¼ï¼‰åŠ é€Ÿæ˜æ˜¾ï¼ˆ>8Ã—ï¼‰
  - é«˜ç†µä»»åŠ¡ï¼ˆå¦‚å¼€æ”¾é—®ç­”ã€åˆ›æ„å†™ä½œï¼‰åŠ é€Ÿæœ‰é™ï¼ˆ~2Ã—ï¼‰ï¼Œå›  speculative token ç½®ä¿¡åº¦ä½ã€‚
- å½“å‰ acceptance æœºåˆ¶è¾ƒç®€å•ï¼Œç¼ºä¹ robust rejection/correction æœºåˆ¶ã€‚
- ä»éœ€äººå·¥è®¾å®šè¶…å‚ï¼ˆå¦‚ entropy threshold, Î»ï¼‰ï¼Œè‡ªåŠ¨åŒ–è°ƒèŠ‚æœ‰å¾…ç ”ç©¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼€å‘æ›´é²æ£’çš„ **acceptance criterion** æˆ–å¼•å…¥ **reinforcement learning** æ¥åŠ¨æ€æ§åˆ¶ speculative depthã€‚
- æ¢ç´¢ **dynamic entropy calibration** ä»¥å¹³è¡¡ä¸åŒä»»åŠ¡ä¸‹çš„è´¨é‡ä¸é€Ÿåº¦ã€‚
- ç³»ç»ŸéªŒè¯ AR-to-Diffusion çš„ **scaling laws**ï¼ŒæŒ‡å¯¼æ›´å¤§è§„æ¨¡æ¨¡å‹è¿ç§»ã€‚
- å°† WeDLM æ€è·¯æ‰©å±•è‡³å¤šæ¨¡æ€æˆ–é•¿æ–‡æœ¬ç”Ÿæˆåœºæ™¯ã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> WeDLM é€šè¿‡ **Topological Reordering + Streaming Parallel Decoding**ï¼Œé¦–æ¬¡å®ç°äº†åœ¨æ ‡å‡† causal attention ä¸‹é«˜æ•ˆã€å¯ç¼“å­˜çš„ diffusion è§£ç ï¼Œå¹¶åœ¨è´¨é‡å’Œé€Ÿåº¦ä¸Šå…¨é¢è¶…è¶Šç°æœ‰ DLLMs ä¸å·¥ä¸š AR å¼•æ“ï¼Œä¸ºä¸‹ä¸€ä»£é«˜é€Ÿ LLM æ¨ç†æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 8. [GPU-Virt-Bench: A Comprehensive Benchmarking Framework for Software-Based GPU Virtualization Systems](https://arxiv.org/abs/2512.22125)

**Authors**: Jithin VG, Ditto PS  
**Category**: cs.DC  
**Published**: 2025-12-30  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.22125v1  

#### Abstract
The proliferation of GPU-accelerated workloads, particularly in artificial intelligence and large language model (LLM) inference, has created unprecedented demand for efficient GPU resource sharing in cloud and container environments. While NVIDIA's Multi-Instance GPU (MIG) technology provides hardw...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šGPU-Virt-Bench: A Comprehensive Benchmarking Framework for Software-Based GPU Virtualization Systems

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åœ¨äº‘ç¯å¢ƒå’Œå®¹å™¨åŒ–å¹³å°ä¸­ï¼ŒGPU èµ„æºå…±äº«éœ€æ±‚æ¿€å¢ï¼Œå°¤å…¶æ˜¯åœ¨ **AI å’Œ LLM æ¨ç†**åœºæ™¯ä¸‹ã€‚ç„¶è€Œï¼š
- **ç¡¬ä»¶çº§è™šæ‹ŸåŒ–ï¼ˆå¦‚ NVIDIA MIGï¼‰** ä»…æ”¯æŒé«˜ç«¯æ•°æ®ä¸­å¿ƒ GPUï¼ˆå¦‚ A100ã€H100ï¼‰ï¼Œé™åˆ¶äº†å…¶é€‚ç”¨èŒƒå›´ï¼›
- **è½¯ä»¶è™šæ‹ŸåŒ–æ–¹æ¡ˆï¼ˆå¦‚ HAMi-coreï¼‰** è™½ç„¶å…¼å®¹æ›´å¹¿æ³›çš„ GPU å‹å·ï¼Œä½†ç¼ºä¹ç»Ÿä¸€ã€å¯å¤ç°çš„è¯„ä¼°æ ‡å‡†ï¼›
- ç°æœ‰åŸºå‡†æµ‹è¯•å·¥å…·ï¼ˆå¦‚ MLPerfã€Rodiniaï¼‰å…³æ³¨çš„æ˜¯åŸå§‹æ€§èƒ½è€Œéè™šæ‹ŸåŒ–ç‰¹æ€§ï¼Œæ— æ³•è¡¡é‡éš”ç¦»è´¨é‡ã€å¼€é”€ç­‰å…³é”®ç»´åº¦ã€‚

å› æ­¤ï¼Œè¯¥è®ºæ–‡æ—¨åœ¨è§£å†³ **â€œç¼ºä¹æ ‡å‡†åŒ–ã€ç³»ç»ŸåŒ–çš„ GPU è½¯ä»¶è™šæ‹ŸåŒ–è¯„ä¼°æ¡†æ¶â€** è¿™ä¸€å…³é”®ç©ºç™½ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹

ä½œè€…æå‡ºäº† **GPU-Virt-Bench** â€”â€” ä¸€ä¸ªé¢å‘è½¯ä»¶ GPU è™šæ‹ŸåŒ–ç³»ç»Ÿçš„ç»¼åˆæ€§åŸºå‡†æµ‹è¯•æ¡†æ¶ï¼Œå…·æœ‰ä»¥ä¸‹äº”å¤§è´¡çŒ®ï¼š

1. **æ„å»ºäº†åŒ…å« 56 ä¸ªæŒ‡æ ‡çš„å®Œæ•´åº¦é‡ä½“ç³»ï¼ˆTaxonomyï¼‰**
   - æ¶µç›– 10 å¤§ç±»åˆ«ï¼šOverheadã€Isolationã€LLMã€Memory Bandwidthã€Cacheã€PCIeã€NCCL/P2Pã€Schedulingã€Fragmentationã€Error Recoveryã€‚
   - é¦–æ¬¡å°† LLM ç‰¹å®šè¡Œä¸ºï¼ˆå¦‚ KV Cache åˆ†é…ã€åŠ¨æ€æ‰¹å¤„ç†å»¶è¿Ÿï¼‰çº³å…¥è¯„ä¼°èŒƒç•´ã€‚

2. **å¼€æºå¯æ‰©å±•çš„æ¨¡å—åŒ–æ¡†æ¶è®¾è®¡**
   - æ”¯æŒå¤šç§è™šæ‹ŸåŒ–åç«¯ï¼ˆNativeã€HAMi-coreã€BUD-FCSPã€MIG-Idealï¼‰ï¼›
   - æä¾› CLI æ¥å£ã€å¤šè¿›ç¨‹æµ‹è¯•æ”¯æŒã€ç»Ÿè®¡åˆ†æä¸æŠ¥å‘Šç”Ÿæˆï¼ˆJSON/CSV/TXTï¼‰ã€‚

3. **å¼•å…¥ MIG-Ideal æ¨¡æ‹ŸåŸºçº¿è¿›è¡Œå¯¹æ ‡**
   - å³ä½¿åœ¨æ—  MIG ç¡¬ä»¶çš„è®¾å¤‡ä¸Šä¹Ÿèƒ½é€šè¿‡æ¨¡æ‹Ÿç†æƒ³ MIG è¡Œä¸ºä½œä¸ºæ€§èƒ½ä¸Šé™å‚è€ƒï¼›
   - å®šä¹‰äº† `â–³MIG` æŒ‡æ ‡æ¥é‡åŒ–ä¸ç†æƒ³éš”ç¦»ä¹‹é—´çš„å·®è·ã€‚

4. **æå‡ºåŠ æƒè¯„åˆ†æœºåˆ¶ä¸ç­‰çº§è¯„å®šç³»ç»Ÿ**
   - ä¸åŒç±»åˆ«æŒ‰é‡è¦æ€§èµ‹äºˆæƒé‡ï¼ˆå¦‚ Isolation å’Œ LLM å„å  20%ï¼‰ï¼›
   - ç»¼åˆå¾—åˆ†æ˜ å°„ä¸º A+/A/B+/C/D/F ç­‰çº§ï¼Œä¾¿äºç›´è§‚æ¯”è¾ƒã€‚

5. **æå‡ºå¹¶è¯„ä¼°æ–°å‹è™šæ‹ŸåŒ–æ–¹æ¡ˆ BUD-FCSP**
   - åœ¨ HAMi-core åŸºç¡€ä¸Šæ”¹è¿› SM æ§åˆ¶ç²’åº¦ã€é™ä½ API æˆªè·å¼€é”€ã€ä¼˜åŒ–ä»¤ç‰Œæ¡¶é™æµç®—æ³•ï¼›
   - å±•ç¤ºäº†è½¯ä»¶è™šæ‹ŸåŒ–è¿›ä¸€æ­¥ä¼˜åŒ–çš„å¯èƒ½æ€§ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆMLPerf/Rodinia/Vendor Toolsï¼‰ | GPU-Virt-Bench |
|------|----------------------------------------|---------------|
| **è¯„ä¼°ç›®æ ‡** | åŸå§‹è®¡ç®—æ€§èƒ½ | è™šæ‹ŸåŒ–è´¨é‡ï¼ˆéš”ç¦»ã€å¼€é”€ã€ç¨³å®šæ€§ï¼‰ |
| **è¦†ç›–ç»´åº¦** | å•ä¸€æ€§èƒ½æŒ‡æ ‡ | 10 ç±»å…± 56 é¡¹ç»†ç²’åº¦æŒ‡æ ‡ |
| **LLM æ”¯æŒ** | å¼±æˆ–ç¼ºå¤± | æ˜¾å¼å»ºæ¨¡æ³¨æ„åŠ›æœºåˆ¶ã€KV Cacheã€TTFT ç­‰ |
| **å¯å¤ç°æ€§** | å°é—­æˆ–ä¸é€æ˜ | å¼€æºã€å‚æ•°å¯é…ç½®ã€æ”¯æŒå›å½’æµ‹è¯• |
| **å…¬å¹³å¯¹æ¯”** | ç¼ºä¹ç»Ÿä¸€åŸºçº¿ | æä¾› MIG-Ideal æ¨¡æ‹ŸåŸºå‡† |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š å®éªŒå¹³å°é…ç½®
- **GPU**: NVIDIA A100-40GB PCIe
- **CPU**: AMD EPYC 7742 (64 cores)
- **å†…å­˜**: 512GB DDR4-3200
- **å­˜å‚¨**: NVMe SSD
- **æ“ä½œç³»ç»Ÿ**: Ubuntu 22.04 LTS
- **CUDA**: 12.0
- **é©±åŠ¨ç‰ˆæœ¬**: 525.105.17

---

### âš™ï¸ å®éªŒè®¾ç½®

#### æ”¯æŒçš„è™šæ‹ŸåŒ–æ¨¡å¼ï¼ˆè§ Table 2ï¼‰
| System       | Key     | æè¿° |
|--------------|---------|------|
| Native       | native  | åŸç”Ÿè£¸æœºåŸºå‡† |
| HAMi-core    | hami    | CNCF æ²™ç®±é¡¹ç›®ï¼ŒåŸºäº CUDA API æˆªè· |
| BUD-FCSP     | fcsp    | æœ¬æ–‡æå‡ºçš„å¢å¼ºå‹è½¯ä»¶è™šæ‹ŸåŒ–å±‚ |
| MIG-Ideal    | mig     | åŸºäºè§„æ ¼ä¹¦çš„ç†æƒ³åŒ– MIG æ¨¡æ‹Ÿå€¼ï¼ˆéå®æµ‹ï¼‰ |

> æ³¨ï¼šMIG-Ideal æ˜¯ä» NVIDIA å…¬å¼€æ–‡æ¡£å’Œæ–‡çŒ®æ¨å¯¼å‡ºçš„ç†è®ºæœ€ä¼˜è¡¨ç°ï¼Œç”¨äºè®¾å®šæ€§èƒ½å¤©èŠ±æ¿ã€‚

---

#### è¯„ä¼°æŒ‡æ ‡åˆ†ç±»ï¼ˆå…± 56 é¡¹ï¼Œè§ Table 1 å’Œ Appendix Aï¼‰

| ç±»åˆ« | ç¤ºä¾‹æŒ‡æ ‡ | å•ä½ | æ›´å¥½æ–¹å‘ |
|------|--------|-------|----------|
| **Overhead** | OH-001 Kernel Launch Latency | Î¼s | Lower |
| **Isolation** | IS-003 SM Utilization Accuracy | % | Higher |
| **LLM** | LLM-004 Token Generation Latency | ms | Lower |
| **Memory Bandwidth** | BW-001 Memory Bandwidth Isolation | % | Higher |
| **Cache** | CACHE-001 L2 Cache Hit Rate | % | Higher |
| **PCIe** | PCIE-003 PCIe Contention Impact | % | Lower |
| **NCCL/P2P** | NCCL-003 P2P GPU Bandwidth | GB/s | Higher |
| **Scheduling** | SCHED-001 Context Switch Latency | Î¼s | Lower |
| **Fragmentation** | FRAG-001 Fragmentation Index | % | Lower |
| **Error Recovery** | ERR-003 Graceful Degradation Score | % | Higher |

æ‰€æœ‰æŒ‡æ ‡é»˜è®¤è¿è¡Œ 100 æ¬¡è¿­ä»£ï¼Œå« 10 æ¬¡é¢„çƒ­ï¼Œè¾“å‡ºå‡å€¼ã€P95ã€P99ã€æ ‡å‡†å·®ã€CV ç­‰ç»Ÿè®¡ä¿¡æ¯ã€‚

---

#### å¯¹æ¯”åŸºçº¿æ–¹æ³•
- **Native**: æ€§èƒ½å¤©èŠ±æ¿
- **HAMi-core**: å½“å‰ä¸»æµå¼€æºè½¯ä»¶è™šæ‹ŸåŒ–æ–¹æ¡ˆ
- **BUD-FCSP**: æœ¬æ–‡æå‡ºçš„æ”¹è¿›ç‰ˆ
- **MIG-Ideal**: ç†æƒ³ç¡¬ä»¶éš”ç¦»ç›®æ ‡ï¼ˆæ¨¡æ‹Ÿï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆæ¥è‡ª Tables 4â€“7ï¼‰

#### è¡¨ 4ï¼šOverhead ç»“æœï¼ˆå•ä½ï¼šÎ¼sï¼Œé™¤éç‰¹åˆ«æ³¨æ˜ï¼‰
| Metric | Native | HAMi | FCSP |
|--------|--------|------|------|
| OH-001 (Launch) | 4.2 | 15.3 | 8.7 |
| OH-002 (Alloc) | 12.5 | 45.2 | 28.3 |
| OH-003 (Free) | 8.1 | 32.4 | 18.6 |
| OH-005 (Hook, ns) | â€“ | 85 | 42 |
| OH-010 (Throughput Degradation) | â€“ | 18.5% | 9.2% |

> ğŸ’¡ **å‘ç°**ï¼šBUD-FCSP ç›¸æ¯” HAMi-core å‡å°‘çº¦ **43% çš„ API æˆªè·å¼€é”€**ï¼Œæ€»ååé€€åŒ–å‡å°‘ä¸€åŠã€‚

---

#### è¡¨ 5ï¼šIsolation è´¨é‡ï¼ˆ4 ä¸ªç§Ÿæˆ·å¹¶å‘ï¼‰
| Metric | HAMi | FCSP |
|--------|------|------|
| IS-001 (Mem Accuracy, %) | 98.2 | 99.1 |
| IS-003 (SM Accuracy, %) | 85.4 | 92.7 |
| IS-008 (Fairness Index) | 0.87 | 0.94 |
| IS-009 (Noisy Neighbor Impact, %) | 24.3 | 12.1 |
| IS-010 (Fault Isolation) | Pass | Pass |

> ğŸ’¡ **å‘ç°**ï¼šFCSP åœ¨ SM åˆ©ç”¨ç‡æ§åˆ¶ç²¾åº¦ã€å…¬å¹³æ€§å’ŒæŠ—å¹²æ‰°èƒ½åŠ›æ–¹é¢æ˜¾è‘—ä¼˜äº HAMi-coreã€‚

---

#### è¡¨ 6ï¼šLLM å·¥ä½œè´Ÿè½½æ€§èƒ½ï¼ˆç›¸å¯¹åŸç”Ÿæ€§èƒ½ï¼‰
| Metric | HAMi | FCSP |
|--------|------|------|
| LLM-001 (Attention Throughput, %) | 82.3% | 91.5% |
| LLM-002 (KV Cache Alloc Speed, %) | 76.4% | 88.2% |
| LLM-004 (TTFT, ms) | 45.2 | 28.7 |
| LLM-004 (ITL, ms) | 12.8 | 8.4 |
| LLM-003 (Batch Scaling Ratio) | 0.78 | 0.89 |

> ğŸ’¡ **å‘ç°**ï¼šLLM æ¨ç†å¯¹å†…å­˜åˆ†é…å»¶è¿Ÿæä¸ºæ•æ„Ÿï¼›FCSP åœ¨ Token ç”Ÿæˆå»¶è¿Ÿä¸Šæ¯” HAMi å¿« **35%ä»¥ä¸Š**ã€‚

---

#### è¡¨ 7ï¼šç»¼åˆå¾—åˆ†ä¸è¯„çº§
| System | Score | MIG Parity | Grade |
|--------|-------|------------|-------|
| MIG-Ideal | 100% | 100% | A+ (baseline) |
| Native | 100% | â€“ | A+ |
| BUD-FCSP | 85.2% | 85.2% | B+ |
| HAMi-core | 72.0% | 72.0% | C |

> âœ… **ç»“è®º**ï¼šBUD-FCSP è¾¾åˆ°ç†æƒ³ MIG è¡¨ç°çš„ **85.2%**ï¼Œè€Œ HAMi-core ä»…ä¸º **72%**ã€‚

---

### ğŸ” æ¶ˆèå®éªŒä¸å…³é”®å½’å› åˆ†æï¼ˆéšå«åœ¨å®ç°ç»†èŠ‚ä¸­ï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèå®éªŒè¡¨æ ¼ï¼Œä½†ä»ä»£ç ä¸æè¿°å¯çŸ¥æ€§èƒ½æå‡æ¥æºï¼š
- **ä¼˜åŒ– dlsym hook è·¯å¾„** â†’ é™ä½ OH-005ï¼ˆAPI æˆªè·å¼€é”€ï¼‰
- **æ”¹è¿›ä»¤ç‰Œæ¡¶ç®—æ³•ï¼ˆå¸¦çªå‘å¤„ç†ï¼‰** â†’ æå‡è°ƒåº¦å“åº”é€Ÿåº¦
- **åŠ æƒå…¬å¹³é˜Ÿåˆ—è°ƒåº¦å™¨** â†’ æ”¹å–„ IS-008 å…¬å¹³æ€§
- **ç²¾ç»†åŒ– SM åˆ©ç”¨ç‡æ§åˆ¶ï¼ˆäºšç™¾åˆ†æ¯”ç²’åº¦ï¼‰** â†’ æé«˜ IS-003 å‡†ç¡®æ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **è½¯ä»¶è™šæ‹ŸåŒ–å¯è¾¾è¿‘ä¼¼ MIG æ°´å¹³çš„è¡¨ç°**
   - BUD-FCSP åœ¨ç»¼åˆè¯„åˆ†ä¸Šè¾¾åˆ°ç†æƒ³ MIG çš„ **85.2%**ï¼Œè¡¨æ˜é«˜è´¨é‡è½¯ä»¶è™šæ‹ŸåŒ–æ˜¯å¯è¡Œçš„ã€‚

2. **LLM æ¨ç†å¯¹è™šæ‹ŸåŒ–å¼€é”€é«˜åº¦æ•æ„Ÿ**
   - å†…å­˜åˆ†é…å»¶è¿Ÿç›´æ¥å½±å“ KV Cache æ„å»ºæ•ˆç‡å’Œ Token ç”Ÿæˆé€Ÿåº¦ï¼›
   - ä¼˜åŒ– `cuMemAlloc` è·¯å¾„å¯¹å®é™…æ¨ç†å»¶è¿Ÿè‡³å…³é‡è¦ã€‚

3. **éš”ç¦»è´¨é‡ä»å­˜åœ¨æ˜æ˜¾å·®è·**
   - å³ä¾¿æœ€å…ˆè¿›çš„è½¯ä»¶æ–¹æ¡ˆä¹Ÿæ— æ³•å®Œå…¨å¤åˆ¶ MIG çš„ç¡¬ä»¶çº§èµ„æºéš”ç¦»ï¼›
   - SM åˆ©ç”¨ç‡æ§åˆ¶è¯¯å·®ä»åœ¨ 7â€“15%ï¼Œå¯èƒ½å¯¼è‡´ QoS æ³¢åŠ¨ã€‚

4. **BUD-FCSP æ˜¾è‘—ä¼˜äº HAMi-core**
   - åœ¨å»¶è¿Ÿã€å…¬å¹³æ€§ã€å™ªå£°é‚»å±…æŠ‘åˆ¶ç­‰æ–¹é¢å…¨é¢é¢†å…ˆï¼›
   - é€‚åˆéƒ¨ç½²äºç”Ÿäº§çº§å¤šç§Ÿæˆ· LLM æ¨ç†æœåŠ¡ã€‚

5. **MIG ä»æ˜¯ä¸¥æ ¼éš”ç¦»åœºæ™¯çš„é¦–é€‰**
   - è‹¥ç¡¬ä»¶æ”¯æŒä¸”é¢„ç®—å…è®¸ï¼Œåº”ä¼˜å…ˆä½¿ç”¨ MIGï¼›
   - å¦åˆ™æ¨èé‡‡ç”¨ BUD-FCSP æ›¿ä»£ HAMi-coreã€‚

---

### âš ï¸ å±€é™æ€§

1. **å• GPU è®¾è®¡**
   - å½“å‰æ¡†æ¶èšç„¦å•å¡åœºæ™¯ï¼Œå°šæœªæ¶µç›–åˆ†å¸ƒå¼è®­ç»ƒæˆ–å¤š GPU å¼ é‡å¹¶è¡Œé€šä¿¡å‹åŠ›æµ‹è¯•ã€‚

2. **åˆæˆ LLM å·¥ä½œè´Ÿè½½**
   - ä½¿ç”¨è‡ªå®šä¹‰ CUDA kernel æ¨¡æ‹Ÿ Attention å’Œ KV Cacheï¼Œæœªé›†æˆ PyTorch æˆ– TensorRT-LLMï¼›
   - å®é™…æ¡†æ¶ä¸­çš„è°ƒåº¦å™¨ã€æ˜¾å­˜ç®¡ç†å¯èƒ½å¼•å…¥é¢å¤–å½±å“ã€‚

3. **MIG-Ideal ä¸ºæ¨¡æ‹Ÿå€¼**
   - å¹¶éçœŸå®æµ‹é‡ç»“æœï¼Œå®é™… MIG æ€§èƒ½å—åˆ†åŒºå‡ ä½•ã€å·¥ä½œè´Ÿè½½ç‰¹å¾å½±å“ã€‚

4. **GPU æ¶æ„è¦†ç›–æœ‰é™**
   - å®éªŒä»…åœ¨ A100 ä¸Šå®Œæˆï¼Œå…¶ä»–æ¶æ„ï¼ˆå¦‚ RTX ç³»åˆ—ã€L4ã€H100ï¼‰çš„è¡Œä¸ºå¯èƒ½ä¸åŒã€‚

5. **ç‰ˆæœ¬ä¾èµ–æ€§å¼º**
   - HAMi-core å’Œ BUD-FCSP çš„è¡¨ç°éšç‰ˆæœ¬æ¼”è¿›è€Œå˜åŒ–ï¼Œéœ€æŒç»­æ›´æ–°åŸºå‡†ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³å¤š GPU åœºæ™¯**
   - åŠ å…¥ NCCL é›†ä½“é€šä¿¡å‹åŠ›æµ‹è¯•ã€è·¨èŠ‚ç‚¹ P2P å¸¦å®½è¯„ä¼°ã€‚

2. **é›†æˆçœŸå® LLM æ¡†æ¶**
   - æ”¯æŒ HuggingFace Transformersã€vLLMã€TensorRT-LLM ç­‰ä¸»æµæ¨ç†å¼•æ“ã€‚

3. **è‡ªåŠ¨åŒ–å›å½’æµ‹è¯•**
   - æ„å»º CI/CD æµæ°´çº¿ï¼Œç›‘æ§è™šæ‹ŸåŒ–ç»„ä»¶å‡çº§å¸¦æ¥çš„æ€§èƒ½æ³¢åŠ¨ã€‚

4. **æ”¯æŒæ›´å¤šè™šæ‹ŸåŒ–åç«¯**
   - å¦‚ Intel FlexGPUã€AMD MxGPUã€vCUDA ç­‰å¼‚æ„å¹³å°ã€‚

5. **å¼€å‘å¯è§†åŒ–ä»ªè¡¨ç›˜**
   - æä¾› Web UI å±•ç¤ºå†å²è¶‹åŠ¿ã€å¯¹æ¯”æŠ¥å‘Šã€ç“¶é¢ˆå®šä½å»ºè®®ã€‚

---

## æ€»ç»“

GPU-Virt-Bench æ˜¯é¦–ä¸ªç³»ç»ŸåŒ–è¯„ä¼° **è½¯ä»¶ GPU è™šæ‹ŸåŒ–** çš„å¼€æºåŸºå‡†æ¡†æ¶ï¼Œå¡«è¡¥äº†è¡Œä¸šåœ¨å¤šç§Ÿæˆ· GPU èµ„æºç®¡ç†è¯„ä¼°æ–¹é¢çš„ç©ºç™½ã€‚å®ƒä¸ä»…æä¾›äº† **56 é¡¹ç»†ç²’åº¦æŒ‡æ ‡** å’Œ **ç§‘å­¦è¯„åˆ†ä½“ç³»**ï¼Œè¿˜æ­ç¤ºäº†å½“å‰è½¯ä»¶æ–¹æ¡ˆä¸ç†æƒ³ MIG ä¹‹é—´çš„æ€§èƒ½é¸¿æ²Ÿï¼Œå¹¶éªŒè¯äº† **BUD-FCSP** åœ¨å»¶è¿Ÿã€éš”ç¦»å’Œ LLM æ”¯æŒä¸Šçš„æ˜¾è‘—ä¼˜åŠ¿ã€‚

è¯¥æ¡†æ¶å¯¹äºäº‘æœåŠ¡å•†ã€AI å¹³å°å¼€å‘è€…ä»¥åŠè™šæ‹ŸåŒ–ä¸­é—´ä»¶ç ”å‘å›¢é˜Ÿå…·æœ‰é‡è¦å®ç”¨ä»·å€¼ï¼Œæ¨åŠ¨ GPU èµ„æºå…±äº«æŠ€æœ¯å‘æ›´é«˜æ•ˆç‡ä¸æ›´å¼ºå¯é æ€§å‘å±•ã€‚

</details>

---

### 9. [KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta](https://arxiv.org/abs/2512.23236)

**Authors**: Gang Liao, Hongsen Qin, Ying Wang, Alicia Golden, Michael Kuchnik, Yavuz Yetim, Jia Jiunn Ang, Chunli Fu, Yihan He, Samuel Hsia, Zewei Jiang, Dianshi Li, Uladzimir Pashkevich, Varna Puvvada, Feng Shi, Matt Steiner, Ruichao Xiao, Nathan Yan, Xiayu Yu, Zhou Fang, Abdul Zainul-Abedin, Ketan Singh, Hongtao Yu, Wenyuan Chi, Barney Huang, Sean Zhang, Noah Weller, Zach Marine, Wyatt Cook, Carole-Jean Wu, Gaoxiang Liu  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.23236v1  

#### Abstract
Making deep learning recommendation model (DLRM) training and inference fast and efficient is important. However, this presents three key system challenges - model architecture diversity, kernel primitive diversity, and hardware generation and architecture heterogeneity. This paper presents KernelEv...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šKernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£æ·±åº¦å­¦ä¹ æ¨èæ¨¡å‹ï¼ˆDLRMï¼‰åœ¨è®­ç»ƒå’Œæ¨ç†ä¸­é¢ä¸´ä¸‰å¤§ç³»ç»ŸæŒ‘æˆ˜ï¼š
- **æ¨¡å‹æ¶æ„å¤šæ ·æ€§**ï¼šä»ä¼ ç»ŸMLPåˆ°Transformerã€å·ç§¯å¢å¼ºæ¶æ„ç­‰ï¼›
- **ç®—å­å¤šæ ·æ€§**ï¼šé™¤GEMMå¤–ï¼Œå­˜åœ¨å¤§é‡æ•°æ®é¢„å¤„ç†ç®—å­ï¼ˆå¦‚`MapId`, `MBDT`ï¼‰ï¼Œå…¶ä¼˜åŒ–å¯¹éƒ¨ç½²è‡³å…³é‡è¦ï¼›
- **ç¡¬ä»¶å¼‚æ„æ€§**ï¼šè·¨å‚å•†ï¼ˆNVIDIAã€AMDï¼‰ã€è·¨ä»£é™…ï¼ˆAmpere vs Hopperï¼‰ã€è‡ªç ”èŠ¯ç‰‡ï¼ˆMTIAï¼‰çš„AIåŠ é€Ÿå™¨å·®å¼‚å·¨å¤§ã€‚

è¿™ä¸‰è€…ç»„åˆå¯¼è‡´äº†ä¸€ä¸ªå·¨å¤§çš„ä¼˜åŒ–ç©ºé—´ï¼Œä¼ ç»Ÿæ‰‹åŠ¨å†…æ ¸å¼€å‘æ— æ³•æ‰©å±•ï¼Œå¼€å‘å‘¨æœŸé•¿è¾¾æ•°å‘¨ï¼Œä¸”éš¾ä»¥è¦†ç›–æ‰€æœ‰ç¡¬ä»¶å¹³å°ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
è®ºæ–‡æå‡ºäº† **KernelEvolve**ï¼Œä¸€ä¸ªåŸºäºæ™ºèƒ½ä½“ï¼ˆagenticï¼‰çš„è‡ªåŠ¨åŒ–å†…æ ¸ç”Ÿæˆä¸ä¼˜åŒ–æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**ç»Ÿä¸€çš„å¤šç›®æ ‡æŠ½è±¡ç¼–ç¨‹æ¥å£**
- æ”¯æŒå¤šç§ç¼–ç¨‹èŒƒå¼ï¼šTritonã€CuTe DSLã€TLXã€MTIA C++ DSLç­‰ï¼›
- é€šè¿‡ **Triton-MLIR** å¤šçº§ç¼–è¯‘æ¶æ„å®ç°è·¨å¹³å°æ”¯æŒï¼ˆNVIDIAã€AMDã€MTIAï¼‰ï¼›
- åˆ©ç”¨ **Triton MPP**ï¼ˆMulti-Pass Profilerï¼‰ç»Ÿä¸€åº•å±‚æ€§èƒ½åˆ†æå·¥å…·é“¾ï¼ˆNCUã€Protonã€MTIA Insightï¼‰ï¼Œæ‰“é€šç¼–è¯‘å™¨ã€è¿è¡Œæ—¶ä¸ç¡¬ä»¶è®¡æ•°å™¨ä¹‹é—´çš„ä¿¡æ¯å­¤å²›ã€‚

#### ï¼ˆ2ï¼‰**å›¾æœç´¢é©±åŠ¨çš„æ™ºèƒ½ä½“ä¼˜åŒ–æµç¨‹**
å°†å†…æ ¸ä¼˜åŒ–å»ºæ¨¡ä¸º **å›¾æœç´¢é—®é¢˜**ï¼Œå®šä¹‰å››å…ƒç»„ `(F, Tsel, O, T)`ï¼š
- **Fitness Function (F)**ï¼šä»¥ç›¸å¯¹äºPyTorchåŸºçº¿çš„é€Ÿåº¦æå‡ä½œä¸ºé€‚åº”åº¦å‡½æ•°ï¼›
- **Selection Policy (Tsel)**ï¼šæ”¯æŒè´ªå¿ƒã€MCTSã€è¿›åŒ–ç®—æ³•ç­‰å¤šç§ç­–ç•¥é€‰æ‹©å€™é€‰èŠ‚ç‚¹ï¼›
- **Universal Operator (O)**ï¼šå•ä¸€é€šç”¨æ“ä½œç¬¦ï¼Œç»“åˆæ£€ç´¢å¢å¼ºæç¤ºï¼ˆretrieval-augmented prompt synthesisï¼‰åŠ¨æ€è°ƒæ•´è¡Œä¸ºï¼Œé¿å…ä¼ ç»Ÿâ€œDebug/Improveâ€å›ºå®šæ¨¡æ¿çš„è®¤çŸ¥é™åˆ¶ï¼›
- **Termination Rule (T)**ï¼šåŸºäºæ—¶é—´é¢„ç®—ã€æ€§èƒ½é˜ˆå€¼æˆ–æ”¶æ•›åˆ¤æ–­ç»ˆæ­¢ã€‚

#### ï¼ˆ3ï¼‰**æŒä¹…åŒ–çŸ¥è¯†åº“ä¸ä¸Šä¸‹æ–‡ç®¡ç†æœºåˆ¶**
- æ„å»º **Persistent Knowledge Base**ï¼Œç¼–ç ç¡¬ä»¶çº¦æŸã€ä¼˜åŒ–æ¨¡å¼ã€è°ƒè¯•æŒ‡å—ï¼›
- å¼•å…¥ **Context Memory Sub-Agent** å’Œ **Deep Search Sub-Agent**ï¼Œå‰è€…ç»´æŠ¤æœç´¢çŠ¶æ€å…ƒæ•°æ®ï¼Œåè€…ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£ç”¨äºæç¤ºåˆæˆï¼›
- ç‰¹åˆ«é’ˆå¯¹ **MTIA** è¿™ç±»ç§æœ‰æ¶æ„ï¼Œæ³¨å…¥ä¸“å±çŸ¥è¯†ï¼ˆå¦‚SFUæŒ‡ä»¤ã€åŒæ ¸åŒæ­¥ã€è·¨PEé€šä¿¡åŸè¯­ï¼‰ï¼Œä½¿LLMèƒ½ç”Ÿæˆæ­£ç¡®ä»£ç ã€‚

#### ï¼ˆ4ï¼‰**ç«¯åˆ°ç«¯ç”Ÿäº§é›†æˆèƒ½åŠ›**
- è‡ªåŠ¨åŒ–ç”Ÿæˆ **PyTorch + Triton åŒå®ç°æ¨¡å—**ï¼Œä¾¿äºæ­£ç¡®æ€§éªŒè¯ï¼›
- é›†æˆ **FaaS** å®ç°è¯„ä¼°è§£è€¦ï¼Œç”Ÿæˆåœ¨CPUä¸Šè¿›è¡Œï¼Œè¯„ä¼°åœ¨è¿œç¨‹AIåŠ é€Ÿå™¨é›†ç¾¤æ‰§è¡Œï¼Œæé«˜èµ„æºåˆ©ç”¨ç‡ï¼›
- æ”¯æŒ **JITè°ƒè¯•**ï¼šé€šè¿‡MTIA-Tritonçš„C++ä¸­é—´è¡¨ç¤ºå‘å°„åŠŸèƒ½ï¼Œç›´æ¥æŸ¥çœ‹å¹¶ä¿®æ”¹åº•å±‚RISC-Vå‘é‡æŒ‡ä»¤ï¼Œå¿«é€Ÿä¿®å¤é”™è¯¯ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚AutoTritonã€Kevinã€GEAKï¼‰ | KernelEvolve |
|------|----------------------------------------|-------------|
| **ç¡¬ä»¶æ”¯æŒ** | å•ä¸€å¹³å°ï¼ˆé€šå¸¸ä»…NVIDIAï¼‰ | è·¨å¹³å°ï¼šNVIDIAã€AMDã€MTIA |
| **è¯„ä¼°çœŸå®æ€§** | åˆæˆç®—å­ã€é™æ€å½¢çŠ¶ | ç”Ÿäº§çº§åŠ¨æ€æ‰¹å¤„ç†ã€å˜é•¿åºåˆ—ã€çœŸå®ç®—å­ç»„åˆ |
| **ç”Ÿå‘½å‘¨æœŸç®¡ç†** | ä»…ç”Ÿæˆ | å…¨æµç¨‹ï¼šç”Ÿæˆ â†’ ç¼–è¯‘ â†’ æ­£ç¡®æ€§éªŒè¯ â†’ æ€§èƒ½è¯„æµ‹ â†’ è°ƒè¯• â†’ éƒ¨ç½² |
| **çŸ¥è¯†åˆ©ç”¨** | ä¾èµ–LLMé¢„è®­ç»ƒçŸ¥è¯† | æ£€ç´¢å¢å¼º + æŒä¹…åŒ–çŸ¥è¯†åº“ï¼Œæ”¯æŒç§æœ‰æ¶æ„ |
| **æœç´¢è§„æ¨¡** | å°‘é‡è¿­ä»£ | ç™¾è‡³åƒæ­¥çš„æ¨ç†æ—¶æ‰©å±•ï¼ˆinference-time scalingï¼‰ |
| **å®¹é”™æ€§** | å¤±è´¥å³é‡å¯ | Checkpointing + åˆ†å¸ƒå¼å¹¶å‘æ¢ç´¢ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸æµ‹è¯•åœºæ™¯
- **å¼€æºåŸºå‡†**ï¼š
  - **KernelBench**ï¼šåŒ…å«250ä¸ªé—®é¢˜ï¼Œæ¶µç›–å•ç®—å­ã€èåˆã€å…¨æ¨¡å‹ä¸‰ä¸ªéš¾åº¦ç­‰çº§ï¼›
  - **PyTorch ATen Operators**ï¼šé€‰å–160ä¸ªå¸¸ç”¨ATenç®—å­ï¼ˆå¦‚`add`, `cos`, `elu`, `amax`ï¼‰ï¼›
- **ç”Ÿäº§çº§ç”¨ä¾‹**ï¼š
  - æ¨èç³»ç»Ÿä¸­çš„å…¸å‹ç®—å­ï¼š`MapIdTransform`, `MergeBucketizedDenseTransform`, `Batch Event Truncate`ï¼›
  - æ¨¡å‹ç»„ä»¶ï¼š`Conv1d` in Convolutional Transformer, `Optimized FM` in WuKong, `PFFN` in InterFormerï¼›
  - è‡ªç ”èŠ¯ç‰‡MTIA v2i/v3ä¸Šçš„å®é™…éƒ¨ç½²éœ€æ±‚ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - NVIDIA H100/A100
  - AMD MI300/MI350
  - Meta MTIA v2i / v3
- **è½¯ä»¶æ ˆ**ï¼š
  - PyTorch 2.0 + torch.compile
  - Triton ç¼–è¯‘å™¨ + MLIRåç«¯
  - MTIA Runtime + Triton-MTIA
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Correctness**ï¼š`torch.allclose()` æ•°å€¼ä¸€è‡´æ€§æ£€æŸ¥ï¼›
  - **Speedup**ï¼šTriton Kernel vs PyTorch Baseline çš„æ‰§è¡Œæ—¶é—´æ¯”ï¼›
  - **Latency**ï¼šP50/P99ç«¯åˆ°ç«¯å»¶è¿Ÿï¼›
  - **Coverage**ï¼šæ”¯æŒçš„ç®—å­æ•°é‡ä¸å¹³å°è¦†ç›–ç‡ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| `torch.nn.functional.conv1d` | åŸç”ŸPyTorchå®ç° |
| `torch.nn.functional.conv2d`ï¼ˆNHWCï¼‰ | å¸¸è§ä¼˜åŒ–æŠ€å·§ï¼šreshapeä¸º2Dè°ƒç”¨cuDNNä¼˜åŒ–è·¯å¾„ |
| æ‰‹å·¥ä¼˜åŒ–å†…æ ¸ | Metaå·¥ç¨‹å¸ˆæ‰‹å†™é«˜æ€§èƒ½Triton/MTIAå†…æ ¸ |
| PyTorch + torch.compile | é»˜è®¤ç¼–è¯‘ä¼˜åŒ–åçš„åŸºçº¿ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»
| åœºæ™¯ | å¹³å° | é€Ÿåº¦æå‡ï¼ˆSpeedupï¼‰ | å¤‡æ³¨ |
|------|------|---------------------|------|
| `Conv1d` (ç”Ÿäº§å½¢çŠ¶) | NVIDIA H100 | **2.30Ã—** | ç›¸æ¯”`conv1d`ï¼›ç›¸æ¯”`conv2d`ä»å¿«1.62Ã— |
| `Conv1d` | MTIA v3 | **6.54Ã—** | æ˜¾è‘—ä¼˜äºvendoråº“ |
| `Optimized FM` (WuKong) | H100 | **4.0Ã—** | èåˆæ¶ˆé™¤ä¸­é—´å†…å­˜è®¿é—® |
| `PFFN` (InterFormer) | H100 | **2.5Ã—** | è·¨æ“ä½œTileå¤ç”¨ |
| `MapIdTransform` | MTIA v2i | **4.07Ã—** | æ‰¹å¤§å°50kæ—¶å³°å€¼ |
| `MBDT` | MTIA v2i | **9.25Ã—** | å¤§è¾“å…¥ä¸‹æ˜¾è‘—ä¼˜åŠ¿ |
| `Batch Event Truncate` | MTIA v3 | **9.8Ã—** | å¤šç‰¹å¾æ‰¹é‡å¤„ç†ä¼˜åŒ– |
| `RMSNorm 2D backward` | MTIA v3 | **17Ã—** | æœ€é«˜æé€Ÿæ¡ˆä¾‹ |
| LLM Attention (`SDPA-MLP`) | H100 | **3.3Ã—** | å±•ç¤ºæ³›åŒ–èƒ½åŠ› |

### æ­£ç¡®æ€§ä¸è¦†ç›–ç‡
- åœ¨ **KernelBench** ä¸Šè¾¾åˆ° **100% é€šè¿‡ç‡**ï¼ˆ250é¢˜ï¼‰ï¼›
- åœ¨ **160ä¸ªATenç®—å­ Ã— 3å¹³å°**ï¼ˆå…±480é…ç½®ï¼‰ä¸Šå…¨éƒ¨ç”Ÿæˆæ­£ç¡®å†…æ ¸ï¼Œ**æ­£ç¡®ç‡100%**ï¼›
- æˆåŠŸä¸ºMTIA v3ä¸Šç¼ºå¤±çš„å¤šä¸ªATenç®—å­ï¼ˆå¦‚`_unique2`, `unique_consecutive`ï¼‰æä¾›å¯è¿è¡Œå®ç°ã€‚

### æ¶ˆèå®éªŒä¸ä¼˜åŒ–è½¨è¿¹åˆ†æ
- **å›¾æœç´¢æœ‰æ•ˆæ€§**ï¼šåœ¨`conv1d`ä¼˜åŒ–ä¸­ï¼Œåˆå§‹drafté˜¶æ®µå¹³å‡é€Ÿåº¦æå‡çº¦2Ã—ï¼Œç»è¿‡tree expansionå¼•å…¥åé¦ˆåé€æ­¥æå‡è‡³6.8Ã—ï¼Œè¯æ˜æ‰§è¡Œåé¦ˆå¯¹æŒç»­æ”¹è¿›è‡³å…³é‡è¦ï¼›
- **çŸ¥è¯†æ£€ç´¢ä½œç”¨**ï¼šå…³é—­Deep Search Sub-Agentåï¼Œåœ¨MTIAä¸Šç”Ÿæˆå¤±è´¥ç‡ä¸Šå‡è¶…è¿‡70%ï¼Œè¡¨æ˜çŸ¥è¯†æ³¨å…¥æ˜¯ç§æœ‰æ¶æ„æˆåŠŸçš„å…³é”®ï¼›
- **FaaSè§£è€¦æ”¶ç›Š**ï¼šè¯„ä¼°ä»»åŠ¡å¹¶è¡Œåº¦æå‡10å€ä»¥ä¸Šï¼Œå……åˆ†åˆ©ç”¨Metaå†…éƒ¨åºå¤§çš„AIåŠ é€Ÿå™¨æ± ï¼Œé¿å…æœ¬åœ°è®¾å¤‡ç“¶é¢ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è‡ªåŠ¨åŒ–å†…æ ¸ç”Ÿæˆå·²å…·å¤‡ç”Ÿäº§å¯ç”¨æ€§**ï¼šKernelEvolveèƒ½åœ¨æ— éœ€äººå·¥å¹²é¢„çš„æƒ…å†µä¸‹ï¼Œç”Ÿæˆ**æ­£ç¡®ä¸”é«˜æ€§èƒ½**çš„å†…æ ¸ï¼Œæ€§èƒ½åª²ç¾ç”šè‡³è¶…è¶Šä¸“å®¶æ‰‹å·¥ä¼˜åŒ–ç»“æœã€‚
2. **é¢„å¤„ç†ç®—å­å†³å®šéƒ¨ç½²æ¶æ„**ï¼šç¼ºå¤±ä¸€ä¸ªé¢„å¤„ç†å†…æ ¸å¯èƒ½å¯¼è‡´å¿…é¡»é‡‡ç”¨**åˆ†æ‹†å¼æœåŠ¡æ¶æ„**ï¼ˆdisaggregated servingï¼‰ï¼Œå¸¦æ¥é¢å¤–10â€“20msç½‘ç»œå¼€é”€ï¼ˆè§Table 2ï¼‰ï¼Œè¿œè¶…è®¡ç®—æ•ˆç‡æŸå¤±ã€‚å› æ­¤ï¼Œ**å®Œæ•´å†…æ ¸è¦†ç›–æ˜¯æˆæœ¬æ§åˆ¶çš„å‰æ**ã€‚
3. **ç§æœ‰æ¶æ„å¯é€šè¿‡çŸ¥è¯†æ³¨å…¥æ”¯æŒ**ï¼šå³ä½¿LLMæœªè§è¿‡MTIAä»£ç ï¼Œåªè¦æ³¨å…¥è¶³å¤Ÿè¯¦å°½çš„æ–‡æ¡£ï¼ˆå¦‚SFUæ˜ å°„è¡¨ã€åŒæ ¸è°ƒåº¦è§„åˆ™ï¼‰ï¼Œå³å¯ç”Ÿæˆé«˜è´¨é‡ä¸“ç”¨ä»£ç ã€‚
4. **æ¨ç†æ—¶æ‰©å±•ï¼ˆinference-time scalingï¼‰æœ‰æ•ˆ**ï¼šé€šè¿‡å¤§è§„æ¨¡æœç´¢ï¼ˆæ•°ç™¾æ­¥ï¼‰ï¼Œæ¨¡å‹èƒ½å¤Ÿå‘ç°å¤æ‚ä¼˜åŒ–ç­–ç•¥ï¼ˆå¦‚è·¨æ“ä½œèåˆã€å®šåˆ¶tilingï¼‰ï¼Œè¿™äº›ç­–ç•¥éš¾ä»¥é€šè¿‡ä¸€æ¬¡æ€§ç”Ÿæˆè·å¾—ã€‚
5. **å¼€å‘æ•ˆç‡é£è·ƒ**ï¼šå°†åŸæœ¬éœ€è¦**æ•°å‘¨**çš„æ‰‹å·¥ä¼˜åŒ–ç¼©çŸ­è‡³**æ•°å°æ—¶**ï¼Œæå¤§åŠ é€Ÿæ–°ç¡¬ä»¶ä¸Šçº¿å’Œæ¨¡å‹è¿­ä»£ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡çŸ¥è¯†åº“å»ºè®¾**ï¼šè‹¥çŸ¥è¯†åº“ä¸å®Œæ•´æˆ–è¿‡æ—¶ï¼Œæ£€ç´¢æ•ˆæœä¸‹é™ï¼Œå½±å“ç”Ÿæˆè´¨é‡ï¼›
- **é•¿å°¾ç®—å­ä»éœ€äººå·¥ä»‹å…¥**ï¼šæå°‘æ•°éå¸¸è§„ç®—å­å¯èƒ½å¤šæ¬¡å°è¯•å¤±è´¥ï¼Œéœ€äººå·¥æ ‡æ³¨æˆ–å¼•å¯¼ï¼›
- **tokenæ¶ˆè€—è¾ƒå¤§**ï¼šå¤§è§„æ¨¡æœç´¢å¸¦æ¥è¾ƒé«˜æ¨ç†æˆæœ¬ï¼Œéœ€æƒè¡¡ä¼˜åŒ–æ·±åº¦ä¸ç»æµæ€§ï¼›
- **ç›®å‰èšç„¦Tritonå±‚**ï¼šå°šæœªæ·±å…¥MLIRæˆ–PTX/SASSå±‚çº§ï¼ŒæŸäº›æè‡´ä¼˜åŒ–å—é™äºé«˜çº§DSLè¡¨è¾¾åŠ›ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **ä»ç®—å­åˆ°æ¨¡å‹çº§ä¼˜åŒ–**ï¼šæ‰©å±•è‡³è·¨å±‚èåˆã€å…¨å±€å†…å­˜åˆ†é…ã€ç«¯åˆ°ç«¯å›¾ä¼˜åŒ–ï¼›
- **æ”¯æŒæ›´å¤šç¡¬ä»¶**ï¼šARM CPUã€Blackwell GPUã€ä¸‹ä¸€ä»£MTIAç­‰ï¼›
- **å¼ºåŒ–å­¦ä¹ é€‚é…**ï¼šé€šè¿‡æ‰§è¡Œåé¦ˆå¾®è°ƒLLMï¼Œè€Œéä»…ä¾èµ–æç¤ºå·¥ç¨‹ï¼›
- **å‚ç›´æ•´åˆåˆ°åº•å±‚è¯­è¨€**ï¼šæ”¯æŒMLIR dialectä¿®æ”¹ã€PTXæ’å…¥ç­‰ä½çº§æ§åˆ¶ï¼›
- **å¯æŒç»­AIåŸºç¡€è®¾æ–½**ï¼šé‡åŒ–tokenæ¶ˆè€—ä¸ç¢³è¶³è¿¹ï¼Œæ„å»ºç»¿è‰²ä¼˜åŒ–é—­ç¯ï¼›
- **æ— é™å®½åº¦æœç´¢ï¼ˆinfinite-width searchï¼‰**ï¼šæ•°åƒå¹¶å‘æœç´¢è·¯å¾„ï¼Œæœ€ç»ˆæ”¶æ•›æœ€ä¼˜è§£ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> KernelEvolveé¦–æ¬¡å®ç°äº†åœ¨å·¥ä¸šè§„æ¨¡ä¸‹ï¼Œé¢å‘å¼‚æ„AIåŠ é€Ÿå™¨çš„å…¨è‡ªåŠ¨ã€é«˜å¯é ã€é«˜æ€§èƒ½å†…æ ¸ç”Ÿæˆï¼Œè§£å†³äº†â€œç¡¬ä»¶æ›´æ–°å¿«ã€è½¯ä»¶è·Ÿä¸ä¸Šâ€çš„æ ¹æœ¬çŸ›ç›¾ï¼Œæ ‡å¿—ç€AIç³»ç»Ÿä¼˜åŒ–è¿›å…¥â€œæ™ºèƒ½ä½“é©±åŠ¨â€çš„æ–°æ—¶ä»£ã€‚

</details>

---

### 10. [Nightjar: Dynamic Adaptive Speculative Decoding for Large Language Models Serving](https://arxiv.org/abs/2512.22420)

**Authors**: Rui Li, Zhaoning Zhang, Libo Zhang, Huaimin Wang, Xiang Fu, Zhiquan Lai  
**Category**: cs.DC  
**Published**: 2025-12-30  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.22420v1  

#### Abstract
Speculative decoding (SD) accelerates LLM inference by verifying draft tokens in parallel. However, this method presents a critical trade-off: it improves throughput in low-load, memory-bound systems but degrades performance in high-load, compute-bound environments due to verification overhead. Curr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Nightjar: Dynamic Adaptive Speculative Decoding for Large Language Models Serving*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **å›ºå®š speculative length çš„å±€é™æ€§**ï¼šç°æœ‰çš„ Speculative Decoding (SD) æ–¹æ³•é€šå¸¸é‡‡ç”¨å›ºå®šçš„ speculative lengthï¼ˆå¦‚ Î³=3ï¼‰ï¼Œæ— æ³•é€‚åº”åŠ¨æ€å˜åŒ–çš„è¯·æ±‚è´Ÿè½½ï¼ˆrequest loadï¼‰ã€‚
- **æ€§èƒ½ç“¶é¢ˆåœ¨ä¸åŒè´Ÿè½½ä¸‹è¡¨ç°ä¸ä¸€**ï¼š
  - åœ¨ä½è´Ÿè½½ã€memory-bound åœºæ™¯ä¸­ï¼ŒSD å¯æå‡ååï¼›
  - ä½†åœ¨é«˜è´Ÿè½½ã€compute-bound åœºæ™¯ä¸­ï¼ŒéªŒè¯å¼€é”€ï¼ˆverification overheadï¼‰åè€Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
- **ç¼ºä¹å¯¹â€œåˆ‡æ¢æˆæœ¬â€ï¼ˆswitching costï¼‰çš„å»ºæ¨¡**ï¼šå½“ä» `Î³=0`ï¼ˆå…³é—­ SDï¼‰é‡æ–°å¯ç”¨ SD æ—¶ï¼Œéœ€é‡å»º draft model çš„ KV cacheï¼Œå¸¦æ¥æ˜¾è‘—å»¶è¿Ÿï¼Œç°æœ‰æ–¹æ³•æœªè€ƒè™‘æ­¤ä»£ä»·ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æå‡º **Nightjar** â€”â€”ä¸€ç§åŸºäº **contextual multi-armed bandit (MAB)** çš„åŠ¨æ€è‡ªé€‚åº” speculative decoding å†³ç­–ç®—æ³•ï¼Œå…·å¤‡ä»¥ä¸‹æ ¸å¿ƒåˆ›æ–°ï¼š

1. **åŠ¨æ€é€‰æ‹©æœ€ä¼˜ speculative length**  
   æ ¹æ®å®æ—¶ batch size è‡ªåŠ¨è°ƒæ•´ Î³ âˆˆ {0,1,...,Î³_max}ï¼Œç”šè‡³åœ¨ä¸åˆ©æƒ…å†µä¸‹ä¸»åŠ¨ç¦ç”¨ SDï¼ˆå³ Î³=0ï¼‰ï¼Œé¿å…æ€§èƒ½é€€åŒ–ã€‚

2. **ä¸‰å±‚æ—¶é—´å±‚çº§ç»“æ„è®¾è®¡ï¼ˆBlocks â†’ Bins â†’ Roundsï¼‰**
   - å¼•å…¥æŒ‡æ•°å¢é•¿çš„ Block å’Œå›ºå®šå¤§å° Bin æ¥ç»„ç»‡æ—¶é—´æ­¥ï¼Œå®ç°é•¿æœŸæ¢ç´¢-åˆ©ç”¨å¹³è¡¡ã€‚
   - éšç€å†å²ç§¯ç´¯ï¼Œexploitation é˜¶æ®µé€æ¸å˜é•¿ï¼Œæé«˜ç¨³å®šæ€§ã€‚

3. **å¼•å…¥ switching cost å»ºæ¨¡**
   - æ˜¾å¼å»ºæ¨¡ä» Î³=0 åˆ‡æ¢åˆ° Î³>0 æ‰€éœ€çš„ KV cache é‡å»ºå¼€é”€ $ C_{\text{prefill}} $ã€‚
   - åœ¨ç›®æ ‡å‡½æ•°ä¸­åŠ å…¥æƒ©ç½šé¡¹ï¼š$ \mathbb{I}(y_{t-1}=0 \land y_t>0) \cdot C_{\text{prefill}} / y_t $ï¼Œé¼“åŠ±æ›´é•¿çš„ speculative åºåˆ—ä»¥æ‘Šé”€å¯åŠ¨æˆæœ¬ã€‚

4. **æ— éœ€å…ˆéªŒçŸ¥è¯†çš„å­¦ä¹ æœºåˆ¶**
   - ä¸ä¾èµ–æ¨¡å‹ç‰¹æ€§æˆ–è¯·æ±‚éš¾åº¦çš„å…ˆéªŒä¿¡æ¯ï¼Œé€šè¿‡åœ¨çº¿å­¦ä¹ ä¼°è®¡æ¯ä¸ª (batch size, Î³) ç»„åˆçš„å®é™… goodputã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | Nightjar å¦‚ä½•æ”¹è¿› |
|------|--------|------------------|
| å›ºå®š Î³ çš„ SD | æ— æ³•é€‚åº”è´Ÿè½½å˜åŒ– | åŠ¨æ€è°ƒèŠ‚ Î³ï¼ŒåŒ…æ‹¬å…³é—­ SD |
| DSD [15] | ä¾èµ–å†å² acceptance rateï¼Œæ˜“é™·å…¥â€œå†³ç­–æ­»é”â€ | æ¢ç´¢-åˆ©ç”¨æœºåˆ¶é˜²æ­¢æ•°æ®åœæ» |
| BanditSpec [12] | é™æ€ batch è®¾è®¡ï¼Œä¸æ”¯æŒ continuous batching | æ”¯æŒç°ä»£ serving æ¶æ„ä¸­çš„åŠ¨æ€æ‰¹å¤„ç† |
| SpecServe/TETRIS [13][14] | ä¾èµ– confidence scoreï¼Œä»å¼ºåˆ¶ç”Ÿæˆ token | å¯å®Œå…¨è·³è¿‡ speculative decoding |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **ShareGPT**ï¼šçœŸå®èŠå¤©åœºæ™¯æ•°æ®ï¼Œç”¨äºæ¨¡æ‹Ÿ online chattingã€‚
- **Alpaca**ï¼šæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œæ¶µç›–å¤šæ ·åŒ–ä»»åŠ¡ã€‚
- **SpecBench**ï¼šç”± 6 ä¸ªå¸¸ç”¨ benchmark æ„æˆçš„åˆæˆæµ‹è¯•é›†ï¼Œå« 480 ä¸ªå®ä¾‹ã€‚
- **AzureLLMInferenceDataset**ï¼šç”Ÿäº§ç¯å¢ƒä¸‹çš„åŠ¨æ€è¯·æ±‚è½¨è¿¹ï¼ˆç”¨äºæ¨¡æ‹Ÿ request rate å˜åŒ–ï¼‰ã€‚

> æ‰€æœ‰æ•°æ®é›†å‡ä½¿ç”¨ 480 ä¸ªæ ·æœ¬è¿›è¡Œè¯„ä¼°ï¼Œè¾“å…¥/è¾“å‡ºé•¿åº¦åˆ†å¸ƒè§å›¾ 7ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **ç›®æ ‡æ¨¡å‹**ï¼š
  - `DeepSeek-R1-Distill-Qwen-7B`ï¼ˆRTX 4090ï¼‰
  - `vicuna-13b`ï¼ˆA100ï¼‰
- **Draft æ¨¡å‹**ï¼š
  - `DeepSeek-R1-DRAFT-Qwen2.5-0.5B`
  - `vicuna-68m`
- **æ¡†æ¶**ï¼šåŸºäº **vLLM (0.8.2)** å®ç° Nightjarï¼Œå¹¶å¯ç”¨ PagedAttentionã€‚
- **æœ€å¤§ speculative length**ï¼šÎ³_max = 5
- **æ¯ç»„å®éªŒé‡å¤ 5 æ¬¡å–å¹³å‡å€¼**

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Throughput** | å•ä½æ—¶é—´å†…ç”Ÿæˆçš„ token æ•°é‡ï¼ˆtokens/sï¼‰ |
| **Mean End-to-End Latency** | è¯·æ±‚ä»æäº¤åˆ°å®Œæˆçš„å¹³å‡å»¶è¿Ÿï¼ˆmsï¼‰ |
| **Goodput** | åŒ…æ‹¬ accepted tokens å’Œ bonus tokens çš„æœ‰æ•ˆäº§å‡ºç‡ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **w/o SD** | Vanilla autoregressive decodingï¼ˆæ—  speculativeï¼‰ |
| **SD (Î³=3)** | æ ‡å‡† speculative decodingï¼Œå›ºå®šé•¿åº¦ 3 |
| **DSD [15]** | åŸºäºçº¿æ€§ goodput æ¨¡å‹åŠ¨æ€ä¼˜åŒ– Î³ |
| **BanditSpec [12]** | ä½¿ç”¨ MAB è¿›è¡Œé•¿åº¦é€‰æ‹©ï¼Œä½†ä¸ºé™æ€ batch è®¾è®¡ |
| **TETRIS [14]** | åŸºäº confidence çš„ batch-level speculative ä¼˜åŒ– |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### è¡¨ 2ï¼šååé‡å¯¹æ¯”ï¼ˆTokens/sï¼‰

| Method       | 7B (Alpaca) | 7B (ShareGPT) | 7B (SpecBench) | 13B (Alpaca) | 13B (ShareGPT) | 13B (SpecBench) |
|--------------|-------------|---------------|----------------|--------------|----------------|------------------|
| **Nightjar** | **2102.73** | **3734.23**   | **3326.20**    | **721.23**   | **1729.68**    | **1061.82**      |
| BanditSpec   | 1860.74     | 3428.75       | 2631.43        | 679.82       | 1383.81        | 763.15           |
| DSD          | 2044.40     | 3614.65       | 2789.51        | 603.32       | 1244.96        | 692.01           |
| TETRIS       | 1875.91     | 3597.21       | 2974.14        | 702.65       | 1628.86        | 985.40           |
| SD (Î³=3)     | 1920.63     | 3593.36       | 3044.80        | 628.47       | 1689.53        | 964.02           |
| w/o SD       | 2072.38     | 3653.61       | 3207.28        | 438.13       | 1290.04        | 673.48           |

> âœ… Nightjar åœ¨æ‰€æœ‰é…ç½®ä¸‹å‡å–å¾—æœ€é«˜ throughputã€‚

#### è¡¨ 3ï¼šç«¯åˆ°ç«¯å»¶è¿Ÿå¯¹æ¯”ï¼ˆmsï¼‰

| Method       | 7B (Alpaca) | 7B (ShareGPT) | 7B (SpecBench) | 13B (Alpaca) | 13B (ShareGPT) | 13B (SpecBench) |
|--------------|-------------|---------------|----------------|--------------|----------------|------------------|
| **Nightjar** | **8868.17** | **6534.76**   | **7618.85**    | **23525.49** | **8133.92**    | **14691.81**     |
| BanditSpec   | 12340.83    | 7799.63       | 9288.23        | 29077.32     | 9667.04        | 19294.42         |
| DSD          | 9183.21     | 6499.12       | 8301.02        | 16212.44     | 10057.72       | 22361.71         |
| TETRIS       | 11734.19    | 7409.62       | 8789.48        | 22133.43     | 8046.25        | 14937.37         |
| SD (Î³=3)     | 11110.68    | 7047.49       | 8567.04        | 24671.40     | 8152.97        | 14212.97         |
| w/o SD       | 8876.14     | 6438.47       | 7654.05        | 32222.49     | 9350.87        | 23831.74         |

> âœ… Nightjar å®ç°æœ€ä½å»¶è¿Ÿï¼Œåœ¨å¤šä¸ªåœºæ™¯ä¸‹æ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚

### ğŸ”¢ æ€§èƒ½æå‡æ€»ç»“
- **ç›¸æ¯”æ ‡å‡† SD (Î³=3)**ï¼š
  - æœ€é«˜ **14.8% ååæå‡**ï¼ˆå¦‚ 7B Alpaca ä¸Šä» 1920 â†’ 2102 tokens/sï¼‰
  - å¹³å‡ **20.2% å»¶è¿Ÿé™ä½**
- **ç›¸æ¯” w/o SD**ï¼š
  - åœ¨ 13B Alpaca ä¸Šå®ç° **64.6% ååæå‡**
- **ç›¸æ¯”å…ˆè¿›åŸºçº¿**ï¼š
  - æ¯” DSD åœ¨ 13B SpecBench ä¸Šé«˜å‡º **53.4%**
  - æ¯” BanditSpec é«˜å‡º **39.1%**

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
- å›¾ 11 å¯¹æ¯”äº†å¤šç§ context-aware MAB æ–¹æ³•ï¼š
  - **LinUCB** å’Œ **linearTS** å‡è®¾ reward ä¸ contextï¼ˆbatch sizeï¼‰å‘ˆçº¿æ€§å…³ç³»ï¼Œåœ¨ LLM æ¨ç†ä¸­ä¸æˆç«‹ï¼Œè¡¨ç°è¾ƒå·®ã€‚
  - **ADA-BINGREEDY**ï¼ˆNightjar æ‰€ç”¨æ¡†æ¶ï¼‰æ— éœ€å¼ºå‡è®¾ï¼Œé€‚åº”éçº¿æ€§å¤æ‚åœºæ™¯ï¼Œæ€§èƒ½æœ€ä¼˜ã€‚
- ç»“æœè¡¨æ˜ï¼š**ç®€å•è€Œé²æ£’çš„ bandit ç­–ç•¥ä¼˜äºå¤æ‚çš„çº¿æ€§æ¨¡å‹**ï¼Œæ›´é€‚åˆçœŸå® serving ç¯å¢ƒã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Speculative decoding çš„æ”¶ç›Šé«˜åº¦ä¾èµ–è´Ÿè½½çŠ¶æ€**ï¼š
   - ä½è´Ÿè½½ â†’ memory-bound â†’ SD æœ‰åˆ©ï¼›
   - é«˜è´Ÿè½½ â†’ compute-bound â†’ SD å¼€é”€å¤§äºæ”¶ç›Šã€‚
2. **å›ºå®š speculative length æ˜¯æ¬¡ä¼˜ç­–ç•¥**ï¼Œå¿…é¡»æ ¹æ® batch size åŠ¨æ€è°ƒæ•´ã€‚
3. **Nightjar èƒ½æ™ºèƒ½åˆ¤æ–­ä½•æ—¶å¯ç”¨/ç¦ç”¨ SD**ï¼Œé¿å…åœ¨ compute-bound åœºæ™¯ä¸­æ€§èƒ½å€’é€€ã€‚
4. **Switching cost å¿…é¡»æ˜¾å¼å»ºæ¨¡**ï¼Œå¦åˆ™é¢‘ç¹å¯åœä¼šä¸¥é‡æ‹–ç´¯ç³»ç»Ÿå“åº”é€Ÿåº¦ã€‚
5. **åŸºäº contextual MAB çš„å­¦ä¹ æœºåˆ¶å¯é«˜æ•ˆæ”¶æ•›è‡³æœ€ä¼˜ç­–ç•¥**ï¼Œä¸” overhead æå°ï¼ˆ< 0.001s per stepï¼‰ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **éœ€è¦ç¦»çº¿æ„å»º $ C_{\text{prefill}} $ æŸ¥æ‰¾è¡¨**ï¼šè™½ç„¶å‡†ç¡®ï¼Œä½†å¢åŠ äº†éƒ¨ç½²å¤æ‚åº¦ã€‚
- **å‡è®¾ draft model å›ºå®š**ï¼šæœªæ¶‰åŠ draft model æœ¬èº«çš„é€‰å‹ä¼˜åŒ–ã€‚
- **å½“å‰ä»…ä¼˜åŒ– speculative length**ï¼Œæœªè”åˆä¼˜åŒ– temperatureã€top-k ç­‰ç”Ÿæˆå‚æ•°ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å°† Nightjar æ‰©å±•è‡³ **å¤šçº§ speculative pipeline**ï¼ˆå¦‚ draft model cascadeï¼‰ã€‚
- å¼•å…¥ **online profiling** æ›¿ä»£ç¦»çº¿æŸ¥æ‰¾è¡¨ï¼Œå®ç°å…¨è‡ªåŠ¨ cost estimationã€‚
- æ¢ç´¢ **ç«¯åˆ°ç«¯ joint optimization** of draft model selection + speculative lengthã€‚
- æ”¯æŒ **SLO-aware adaptation**ï¼Œæ ¹æ®ä¸åŒæœåŠ¡è´¨é‡è¦æ±‚åŠ¨æ€è°ƒæ•´ç­–ç•¥ï¼ˆå¦‚å»¶è¿Ÿæ•æ„Ÿ vs ååä¼˜å…ˆï¼‰ã€‚

---

## âœ… æ€»ç»“
**Nightjar** æ˜¯é¦–ä¸ªçœŸæ­£é¢å‘ **real-time, dynamic LLM serving** çš„ adaptive speculative decoding æ¡†æ¶ã€‚å®ƒé€šè¿‡ **contextual MAB + switching cost modeling + hierarchical exploration-exploitation control**ï¼Œå®ç°äº†ï¼š
- æœ€é«˜ **14.8% ååæå‡**
- æœ€ä½ **20.2% å»¶è¿Ÿä¸‹é™**
- å…¨è´Ÿè½½èŒƒå›´å†…çš„ **robust efficiency**

è¯¥å·¥ä½œä¸ºä¸‹ä¸€ä»£é«˜æ•ˆã€æ™ºèƒ½çš„ LLM serving ç³»ç»Ÿæä¾›äº†é‡è¦èŒƒå¼ï¼Œæ¨åŠ¨ speculative decoding ä»â€œé™æ€åŠ é€Ÿå™¨â€å‘â€œåŠ¨æ€å†³ç­–å¼•æ“â€çš„æ¼”è¿›ã€‚

</details>

---

### 11. [Wireless Traffic Prediction with Large Language Model](https://arxiv.org/abs/2512.22178)

**Authors**: Chuanting Zhang, Haixia Zhang, Jingping Qiao, Zongzhang Li, Mohamed-Slim Alouini  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.22178v1  

#### Abstract
The growing demand for intelligent, adaptive resource management in next-generation wireless networks has underscored the importance of accurate and scalable wireless traffic prediction. While recent advancements in deep learning and foundation models such as large language models (LLMs) have demons...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠWireless Traffic Prediction with Large Language Modelã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº **Large Language Model (LLM)** çš„æ— çº¿æµé‡é¢„æµ‹æ–¹æ³•ï¼ˆå¦‚ TrafficLLMã€Time-LLMï¼‰ä¸»è¦å…³æ³¨**æ—¶é—´åºåˆ—å»ºæ¨¡**ï¼Œå¿½ç•¥äº†åŸå¸‚çº§æ— çº¿ç½‘ç»œä¸­ä¸åŒåŒºåŸŸä¹‹é—´çš„**ç©ºé—´ä¾èµ–æ€§**ã€‚è¿™ç§å¿½ç•¥å¯¼è‡´æ¨¡å‹åœ¨å¤æ‚åŸå¸‚ç¯å¢ƒä¸­æ³›åŒ–èƒ½åŠ›å·®ã€é¢„æµ‹ç²¾åº¦å—é™ã€‚

æ­¤å¤–ï¼Œä¼ ç»Ÿæ–¹æ³•éš¾ä»¥æœ‰æ•ˆèåˆæ•°å€¼å‹æµé‡æ•°æ®ä¸ LLM æ‰€æ“…é•¿å¤„ç†çš„è¯­è¨€ç»“æ„ï¼Œå­˜åœ¨â€œ**é¢†åŸŸé¸¿æ²Ÿ**â€ï¼ˆdomain gapï¼‰ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šTIDES
ä½œè€…æå‡º **TIDES**ï¼ˆ**Traffic Intelligence with DeepSeek-Enhanced Spatial-temporal prediction**ï¼‰ï¼Œä¸€ç§ç»“åˆ LLM ä¸ç©ºé—´æ„ŸçŸ¥æœºåˆ¶çš„åŸå¸‚çº§æ— çº¿æµé‡é¢„æµ‹æ¡†æ¶ã€‚å…¶ä¸‰å¤§æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰Region-aware Modelingï¼ˆåŒºåŸŸæ„ŸçŸ¥å»ºæ¨¡ï¼‰
- é¦–å…ˆé€šè¿‡èšç±»ç®—æ³•ï¼ˆå¢å¼º K-meansï¼‰å°†åŸå¸‚åˆ’åˆ†ä¸ºè‹¥å¹²å…·æœ‰ç›¸ä¼¼æµé‡æ¨¡å¼å’Œç©ºé—´ç›¸å…³æ€§çš„åŒºåŸŸï¼ˆclustersï¼‰ã€‚
- å¯¹æ¯ä¸ªåŒºåŸŸç»„è®­ç»ƒä¸ªæ€§åŒ–çš„ LLM æ¨¡å‹ï¼Œå®ç°**é€šç”¨æ€§**ï¼ˆgeneralizationï¼‰ä¸**ä¸“ä¸šåŒ–**ï¼ˆspecializationï¼‰çš„å¹³è¡¡ã€‚

#### ï¼ˆ2ï¼‰Prompt-based Traffic Representationï¼ˆæç¤ºå·¥ç¨‹é©±åŠ¨çš„æ•°æ®è¡¨ç¤ºï¼‰
- å°†åŸå§‹æ•°å€¼æµé‡æ•°æ®è½¬æ¢ä¸ºç»“æ„åŒ–è‡ªç„¶è¯­è¨€ promptï¼ŒåµŒå…¥ä»¥ä¸‹ç‰¹å¾ï¼š
  - åŸºç¡€ç»Ÿè®¡é‡ï¼ˆå‡å€¼ã€æ–¹å·®ç­‰ï¼‰
  - è¶‹åŠ¿åˆ†æï¼ˆä¸Šå‡/ä¸‹é™ï¼‰
  - æ—¶é—´æ®µæ¨¡å¼ï¼ˆæ—©é«˜å³°ã€æ™šé«˜å³°ã€å¤œé—´ï¼‰
  - é¢†åŸŸç‰¹å®šæŒ‡æ ‡ï¼ˆå³°å‡æ¯”ã€çªå‘æ€§ã€æ³¢åŠ¨å˜åŒ–ç­‰ï¼‰
- åˆ©ç”¨ LLM å¼ºå¤§çš„è¯­ä¹‰ç†è§£èƒ½åŠ›è¿›è¡Œæ¨ç†é¢„æµ‹ã€‚

#### ï¼ˆ3ï¼‰Spatial-Temporal Alignment with DeepSeekï¼ˆè·¨åŸŸæ³¨æ„åŠ›æœºåˆ¶ï¼‰
- è®¾è®¡ä¸€ä¸ª **DeepSeek æ¨¡å—**ï¼Œå¼•å…¥ **multi-head cross-domain attention** æœºåˆ¶ã€‚
- æ„å»ºé‚»æ¥çŸ©é˜µå¹¶åˆ©ç”¨å›¾æ‹‰æ™®æ‹‰æ–¯å˜æ¢ç¨³å®šæ¢¯åº¦ï¼Œä½¿ LLM èƒ½å¤Ÿä»**ç©ºé—´ç›¸é‚»åŒºåŸŸ**è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
- ä»…å¾®è°ƒè½»é‡çº§ç»„ä»¶ï¼ˆå¦‚ attention å±‚å‚æ•°ï¼‰ï¼Œå†»ç»“ä¸»å¹² LLM å‚æ•°ï¼Œå®ç°é«˜æ•ˆé€‚é…ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **ç©ºé—´å»ºæ¨¡** | æ˜¾å¼å»ºæ¨¡åŒºåŸŸé—´ç©ºé—´ä¾èµ–å…³ç³»ï¼Œä¼˜äºå­¤ç«‹é¢„æµ‹çš„ LLM æ–¹æ³• |
| **å¯æ‰©å±•æ€§** | åŒºåŸŸèšç±» + è½»é‡å¾®è°ƒç­–ç•¥é™ä½è®¡ç®—å¼€é”€ï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½² |
| **å‡†ç¡®æ€§** | åœ¨å¤šä¸ªçœŸå®åœºæ™¯ä¸‹æ˜¾è‘—ä¼˜äº SOTA æ¨¡å‹ï¼Œå°¤å…¶åœ¨é«˜åŠ¨æ€åŒºåŸŸè¡¨ç°æ›´ä¼˜ |
| **é²æ£’æ€§** | å¯¹ä¸åŒäº¤é€šå¼ºåº¦å’Œåˆ†å¸ƒåç§»å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ› |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **æ¥æº**ï¼šä¸­å›½æŸè¿è¥å•†çš„çœŸå®åŸå¸‚çº§ 4G åŸºç«™ç½‘ç»œæ•°æ®ã€‚
- **è§„æ¨¡**ï¼šçº¦ 19,000 ä¸ªæ‰‡åŒºï¼Œè¦†ç›–æµå—å¸‚å››ä¸ªå®Œæ•´æ˜ŸæœŸï¼ˆ2024å¹´7æœˆ28æ—¥è‡³8æœˆ25æ—¥ï¼‰ã€‚
- **é‡‡æ ·é¢‘ç‡**ï¼šæ¯ 15 åˆ†é’Ÿä¸€æ¡è®°å½•ã€‚
- **é¢„å¤„ç†**ï¼šå°†æ‰‡åŒºçº§æµé‡èšåˆä¸ºåŒºåŸŸçº§ï¼Œå¹¶é€šè¿‡èšç±»åˆ’åˆ†ä¸º **4 ä¸ª Zoneï¼ˆAã€Bã€Cã€Dï¼‰**ã€‚

### å®éªŒè®¾ç½®
- **è¾“å…¥çª—å£ H**ï¼šè¿‡å»ä¸€å¤©ï¼ˆ96 ä¸ªæ—¶é—´æ­¥ï¼Œå³ 24 å°æ—¶ï¼‰
- **é¢„æµ‹çª—å£ P**ï¼šæœªæ¥ 1 å°æ—¶ï¼ˆ4 æ­¥ï¼Œå³ 60 åˆ†é’Ÿï¼‰
- **åŸºç¡€ LLM**ï¼š**DeepSeek-R1-Distill-Llama-8B**ï¼ˆ32 å±‚ï¼Œæ¨¡å‹ç»´åº¦ 16ï¼Œ8 å¤´æ³¨æ„åŠ›ï¼‰
- **è®­ç»ƒå¹³å°**ï¼š4Ã—A100 GPUï¼Œä½¿ç”¨ DeepSpeed + ZeRO-2 å’Œ bfloat16 æ··åˆç²¾åº¦è®­ç»ƒ
- **ä¼˜åŒ–å™¨**ï¼šAdamW + OneCycleLRï¼Œå­¦ä¹ ç‡ 0.001ï¼Œbatch size=16ï¼Œè®­ç»ƒ 100 epochs å¹¶å¯ç”¨æ—©åœ

### è¯„ä¼°æŒ‡æ ‡
- **MAE**ï¼ˆMean Absolute Errorï¼‰
- **RMSE**ï¼ˆRoot Mean Squared Errorï¼‰
- **MAPE**ï¼ˆMean Absolute Percentage Errorï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• |
|------|------|
| çº¿æ€§æ¨¡å‹ | DLinear |
| Transformer å˜ä½“ | Transformer, Autoformer, Reformer, TimesNet, LightTS |
| LLM-based æ–¹æ³• | Time-LLM |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table Iï¼‰

| æ–¹æ³• \ æŒ‡æ ‡ | MAE â†“ | RMSE â†“ | MAPE â†“ |
|------------|--------|---------|---------|
| **TIDES (Zone A)** | **0.2193** | **0.2958** | **2.7481%** |
| DLinear (Zone A) | 0.2330 | 0.3133 | 2.7904% |
| **TIDES (Zone B)** | 0.4208 | 0.6459 | **2.4827%** |
| Time-LLM (Zone B) | **0.3567** | **0.5401** | 2.6623% |
| **TIDES (Zone C)** | **0.2657** | **0.3621** | **2.8358%** |
| TimesNet (Zone C) | 0.2782 | 0.3860 | 2.8450% |
| **TIDES (Zone D)** | **0.1356** | **0.1746** | **0.5150%** |
| TimesNet (Zone D) | 0.1371 | 0.1795 | 0.6848% |

> âœ… **TIDES åœ¨ 12 é¡¹æŒ‡æ ‡ä¸­å–å¾— 10 é¡¹ç¬¬ä¸€ï¼Œå…¨éƒ¨ 4 ä¸ª Zone çš„ MAPE å‡æ’åç¬¬ä¸€**

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **å¹³å‡è¯¯å·®é™ä½**ï¼šç›¸æ¯”æœ€ä½³åŸºçº¿ï¼ˆDLinear æˆ– Time-LLMï¼‰ï¼ŒTIDES åœ¨ MAE ä¸Šå¹³å‡æå‡çº¦ **8â€“15%**ã€‚
- **ç›¸å¯¹è¯¯å·®ä¼˜åŠ¿æ˜æ˜¾**ï¼šåœ¨ MAPE ä¸Šå…¨é¢é¢†å…ˆï¼Œè¯´æ˜å…¶åœ¨ä½æµé‡æˆ–æ³¢åŠ¨å‰§çƒˆåŒºåŸŸæ›´å…·ç¨³å®šæ€§ã€‚
- **å¯è§†åŒ–éªŒè¯**ï¼š
  - **å›¾3ï¼ˆCorrelationï¼‰**ï¼šTIDES çš„ Pearson ç›¸å…³ç³»æ•°è¾¾ **0.973**ï¼Œè¿œé«˜äº Time-LLMï¼ˆ0.792ï¼‰å’Œ DLinearï¼ˆ0.959ï¼‰ï¼Œè¡¨æ˜é¢„æµ‹å€¼ä¸çœŸå®å€¼é«˜åº¦å¯¹é½ã€‚
  - **å›¾4ï¼ˆError Distributionï¼‰**ï¼šTIDES çš„è¯¯å·®åˆ†å¸ƒæœ€é›†ä¸­äºé›¶é™„è¿‘ï¼Œæ–¹å·®æœ€å°ï¼Œè¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§å’Œä¸€è‡´æ€§ã€‚
  - **å›¾5ï¼ˆSpatial-Temporal Viewï¼‰**ï¼šTIDES æ›´å¥½åœ°è¿˜åŸäº†åŸå¸‚ç©ºé—´ä¸­çš„é«˜ä½æµé‡åˆ†å¸ƒæ ¼å±€ï¼Œåœ¨å¸‚ä¸­å¿ƒã€éƒŠåŒºç­‰ä¸åŒç±»å‹åŒºåŸŸå‡è¡¨ç°ä¼˜å¼‚ã€‚
  - **å›¾6ï¼ˆTemporal Predictionï¼‰**ï¼šèƒ½å‡†ç¡®æ•æ‰é«˜å³°çªå¢å’Œä½è°·å›è½ï¼Œç›¸ä½å»¶è¿Ÿå°ï¼Œç»†èŠ‚ä¿ç•™æ›´å¥½ã€‚

### æ³›åŒ–èƒ½åŠ›æµ‹è¯•ï¼ˆTable IIï¼‰
| è¿ç§»åœºæ™¯ | MAE | ç›¸å¯¹æå‡ |
|--------|-----|----------|
| Zone A â†’ Zone Aï¼ˆåŒåŒºï¼‰ | 0.2255 | - |
| Zone B â†’ Zone Aï¼ˆè·¨åŒºï¼‰ | 0.2595 | â†“15.0% |
| Zone C â†’ Zone A | 0.2456 | â†“8.9% |
| Zone D â†’ Zone A | 0.2328 | â†“3.2% |

> ğŸ” è¡¨æ˜ TIDES å…·å¤‡è‰¯å¥½è·¨åŒºåŸŸæ³›åŒ–èƒ½åŠ›ï¼Œå³ä½¿ä¸é‡æ–°è®­ç»ƒä¹Ÿèƒ½é€‚åº”æ–°åŒºåŸŸï¼Œæ€§èƒ½ä¸‹é™æ§åˆ¶åœ¨ 10% ä»¥å†…ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç©ºé—´ä¾èµ–æ˜¯æå‡é¢„æµ‹ç²¾åº¦çš„å…³é”®å› ç´ **ï¼šå•çº¯çš„æ—¶é—´åºåˆ—å»ºæ¨¡æ— æ³•æ»¡è¶³åŸå¸‚çº§æ™ºèƒ½ç½‘ç»œç®¡ç†éœ€æ±‚ï¼Œå¿…é¡»æ˜¾å¼å»ºæ¨¡åŒºåŸŸé—´çš„ç©ºé—´äº¤äº’ã€‚
2. **LLM å¯ä»¥è¢«æœ‰æ•ˆç”¨äºéè¯­è¨€ä»»åŠ¡**ï¼šé€šè¿‡ prompt engineering å°†æ•°å€¼æµé‡è½¬åŒ–ä¸ºç»“æ„åŒ–æ–‡æœ¬ï¼Œå……åˆ†å‘æŒ¥ LLM çš„è¯­ä¹‰ç†è§£å’Œæ¨ç†èƒ½åŠ›ã€‚
3. **è½»é‡åŒ–å¾®è°ƒå³å¯å®ç°é«˜æ•ˆè¿ç§»**ï¼šå†»ç»“ä¸»å¹² LLM å‚æ•°ï¼Œä»…å¾®è°ƒ spatial attention å’Œ domain alignment æ¨¡å—ï¼Œæ—¢ä¿è¯æ€§èƒ½åˆé¿å…é«˜æ˜‚è®­ç»ƒæˆæœ¬ã€‚
4. **TIDES å…·å¤‡å¼ºé²æ£’æ€§å’Œå¯æ‰©å±•æ€§**ï¼šåœ¨å¤šç§åŸå¸‚åŒºåŸŸç±»å‹ï¼ˆä¸­å¿ƒã€è¾¹ç¼˜ã€éƒŠåŒºï¼‰ä¸­å‡è¡¨ç°ç¨³å®šï¼Œé€‚ç”¨äºæœªæ¥ 6G ç½‘ç»œçš„å¤§è§„æ¨¡è‡ªä¼˜åŒ–ç³»ç»Ÿã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä¾èµ–åœ°ç†åæ ‡æ„å»ºç©ºé—´å›¾ï¼Œè‹¥ç¼ºä¹ä½ç½®ä¿¡æ¯åˆ™éœ€ä¾èµ–æµé‡ç›¸ä¼¼æ€§æ›¿ä»£ï¼Œå¯èƒ½å½±å“æ‹“æ‰‘å‡†ç¡®æ€§ã€‚
- è™½ç„¶é‡‡ç”¨è½»é‡å¾®è°ƒï¼Œä½†æ•´ä½“ä»éœ€é«˜æ€§èƒ½ GPU æ”¯æŒï¼Œè¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ä»æœ‰æŒ‘æˆ˜ã€‚
- æœªè€ƒè™‘å¤–éƒ¨äº‹ä»¶ï¼ˆå¦‚å¤§å‹æ´»åŠ¨ã€å¤©æ°”ï¼‰å¯¹æµé‡çš„çªå‘å½±å“ï¼Œæœªæ¥å¯å¼•å…¥å¤šæ¨¡æ€è¾“å…¥å¢å¼ºé¢„æµ‹èƒ½åŠ›ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. å¼•å…¥å®æ—¶åé¦ˆæœºåˆ¶ï¼Œæ”¯æŒåœ¨çº¿å¢é‡å­¦ä¹ ä¸åŠ¨æ€è°ƒæ•´ï¼›
2. æ‰©å±•è‡³å¤šæ¨¡æ€è¾“å…¥ï¼ˆå¤©æ°”ã€èŠ‚å‡æ—¥ã€POI ç­‰ï¼‰ï¼›
3. æ¢ç´¢è·¨åŸå¸‚ç”šè‡³å…¨çƒèŒƒå›´çš„é€šç”¨æµé‡é¢„æµ‹æ¨¡å‹ï¼›
4. å°† TIDES é›†æˆåˆ°å®é™…ç½‘ç»œæ§åˆ¶ç³»ç»Ÿä¸­ï¼Œå®ç°æ„å›¾é©±åŠ¨çš„èµ„æºè°ƒåº¦ä¸èŠ‚èƒ½ä¼˜åŒ–ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> TIDES æˆåŠŸå°† LLM çš„å¼ºå¤§å»ºæ¨¡èƒ½åŠ›ä¸æ— çº¿ç½‘ç»œçš„ç©ºé—´ç‰¹æ€§ç›¸ç»“åˆï¼Œæå‡ºäº†ä¸€ç§é«˜æ•ˆã€ç²¾å‡†ã€å¯æ‰©å±•çš„åŸå¸‚çº§æ— çº¿æµé‡é¢„æµ‹æ–°èŒƒå¼ï¼Œä¸ºå®ç° AI-Native çš„ 6G è‡ªæ²»ç½‘ç»œæä¾›äº†å…³é”®æŠ€æœ¯æ”¯æ’‘ã€‚

</details>

---

### 12. [HLS4PC: A Parametrizable Framework For Accelerating Point-Based 3D Point Cloud Models on FPGA](https://arxiv.org/abs/2512.22139)

**Authors**: Amur Saqib Pal, Muhammad Mohsin Ghaffar, Faisal Shafait, Christian Weis, Norbert Wehn  
**Category**: cs.DC  
**Published**: 2025-12-30  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.22139v1  

#### Abstract
Point-based 3D point cloud models employ computation and memory intensive mapping functions alongside NN layers for classification/segmentation, and are executed on server-grade GPUs. The sparse, and unstructured nature of 3D point cloud data leads to high memory and computational demand, hindering ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*HLS4PC: A Parametrizable Framework For Accelerating Point-Based 3D Point Cloud Models on FPGA*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **3Dç‚¹äº‘æ¨¡å‹åœ¨GPUä¸Šæ‰§è¡Œæ•ˆç‡ä½ä¸‹**ï¼šç”±äºç‚¹äº‘æ•°æ®å…·æœ‰ç¨€ç–æ€§å’Œéç»“æ„åŒ–ç‰¹æ€§ï¼Œä¼ ç»Ÿçš„GPUåœ¨å¤„ç†å¦‚Farthest Point Sampling (FPS)ã€K-Nearest Neighbor (KNN)ç­‰æ˜ å°„å‡½æ•°æ—¶å­˜åœ¨ä¸¥é‡çš„èµ„æºåˆ©ç”¨ç‡ä¸è¶³é—®é¢˜ã€‚
- **ç°æœ‰FPGAæ¡†æ¶ç¼ºä¹å¯¹ç‚¹äº‘ä¸“ç”¨æ“ä½œçš„æ”¯æŒ**ï¼šå°½ç®¡å·²æœ‰å¤šç§åŸºäºFPGAçš„DNNåŠ é€Ÿæ¡†æ¶ï¼ˆå¦‚hls4mlã€fpgaConvNetï¼‰ï¼Œä½†å®ƒä»¬æ— æ³•æœ‰æ•ˆæ”¯æŒç‚¹äº‘ç‰¹æœ‰çš„é¢„å¤„ç†å’Œç‰¹å¾æå–æ¨¡å—ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
- **æå‡ºHLS4PCæ¡†æ¶**ï¼š
  - ä¸€ä¸ªå¯å‚æ•°åŒ–çš„ã€åŸºäºHigh Level Synthesis (HLS) çš„æµå¼æ•°æ®æµï¼ˆstreaming-based dataflowï¼‰æ¶æ„ï¼Œä¸“ä¸ºFPGAä¸Šçš„ç‚¹äº‘æ¨¡å‹åŠ é€Ÿè®¾è®¡ã€‚
  - æ”¯æŒæ··åˆç²¾åº¦ï¼ˆmixed-precisionï¼‰å®ç°ï¼Œå¹¶èƒ½çµæ´»é…ç½®å¹¶è¡Œåº¦ã€ä½å®½ç­‰ç¡¬ä»¶å‚æ•°ä»¥é€‚åº”ä¸åŒåº”ç”¨åœºæ™¯ã€‚
- **æ„å»ºHLS4PC Library**ï¼š
  - åŒ…å«é’ˆå¯¹ç‚¹äº‘çš„å…³é”®åŠŸèƒ½æ¨¡å—ï¼š`FPS`, `URS`, `KNN`, `Sorting`, `CNN`, `MLP`, `MaxPool`, `Activation Functions` ç­‰ï¼Œå‡é‡‡ç”¨æµæ°´çº¿+å¹¶è¡ŒåŒ–è®¾è®¡ã€‚
- **æå‡ºPointMLP-Liteæ¨¡å‹**ï¼š
  - åœ¨State-of-the-artæ¨¡å‹PointMLP-EliteåŸºç¡€ä¸Šè¿›è¡Œå¤šé¡¹ç®—æ³•-ç¡¬ä»¶ååŒä¼˜åŒ–ï¼Œå¾—åˆ°è½»é‡åŒ–ç‰ˆæœ¬ï¼š
    - ä½¿ç”¨Uniform Random Sampling (URS) æ›¿ä»£FPS
    - è¾“å…¥ç‚¹æ•°ä»1024é™è‡³512
    - æƒé‡ä¸æ¿€æ´»é‡åŒ–è‡³8-bitï¼ˆfp8ï¼‰
    - BatchNormå±‚èåˆè¿›å·ç§¯å±‚
    - ç§»é™¤å‡ ä½•å½’ä¸€åŒ–å‚æ•°Î±å’ŒÎ²

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **çµæ´»æ€§** | FPGAæ”¯æŒç¼–è¯‘æ—¶ç²¾åº¦é…ç½®å’Œé€»è¾‘é‡æ„ï¼Œä¼˜äºASICç±»ä¸“ç”¨åŠ é€Ÿå™¨ |
| **å…¼å®¹æ€§** | æ”¯æŒPyTorch/TensorFlowè®­ç»ƒæµç¨‹ + Quantization-Aware Training (QAT) |
| **ååé‡** | è¾ƒå‰äººFPGAå·¥ä½œæå‡3.56Ã—ï¼Œè¾ƒGPUæå‡2.3Ã—ï¼Œè¾ƒCPUæå‡22Ã— |
| **èƒ½æ•ˆ** | èƒ½æ•ˆé«˜è¾¾294.5 GOPS/Wï¼Œæ˜¯æ­¤å‰æœ€ä½³å·¥ä½œçš„57.4Ã— |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **ModelNet40**ï¼šä¸»æµ3Dç‰©ä½“åˆ†ç±»åŸºå‡†ï¼ŒåŒ…å«40ç±»CADæ¨¡å‹ï¼Œç”¨äºä¸»å®éªŒè¯„ä¼°ã€‚
- **ScanObjectNN**ï¼šçœŸå®åœºæ™¯é‡‡é›†çš„ç‚¹äº‘æ•°æ®é›†ï¼Œæ›´å…·æŒ‘æˆ˜æ€§ï¼Œç”¨äºéªŒè¯æ³›åŒ–èƒ½åŠ›ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼šPointMLP-Eliteï¼ˆSOTAç‚¹äº‘åˆ†ç±»æ¨¡å‹ï¼‰
- **å‹ç¼©ç­–ç•¥æ¢ç´¢è·¯å¾„**ï¼š
  - è¾“å…¥ç‚¹å‰ªæï¼ˆ1024 â†’ 512 â†’ 256 â†’ 128ï¼‰
  - FPS â†’ URSæ›¿æ¢
  - BNå±‚èåˆ
  - å‡ ä½•å‚æ•°Î±/Î²ç§»é™¤
  - 8/8-bité‡åŒ–ï¼ˆæƒå€¼ä¸æ¿€æ´»ï¼‰
- **è®­ç»ƒç¯å¢ƒ**ï¼š
  - å¹³å°ï¼šNVIDIA RTX 3090 GPU
  - æ¡†æ¶ï¼šPyTorch 2.4.0 + Brevitasï¼ˆç”¨äºQATï¼‰
  - è®­ç»ƒé…ç½®ï¼šbatch size=256ï¼Œepoch=1000ï¼ŒSGDä¼˜åŒ–å™¨ï¼ˆmomentum=0.8ï¼‰
- **éƒ¨ç½²å¹³å°**ï¼š
  - FPGAå¼€å‘æ¿ï¼šXilinx Zynq-7000 ZC706
  - å·¥å…·é“¾ï¼šVivado HLS 2018.3 + Block Design
  - åŠŸè€—æµ‹é‡ï¼šVoltacraft VC-870æ’åº§åŠŸç‡è®¡

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Overall Accuracy (OA)** | æ‰€æœ‰æµ‹è¯•æ ·æœ¬å¹³å‡å‡†ç¡®ç‡ |
| **Mean Accuracy (mA)** | å„ç±»åˆ«å‡†ç¡®ç‡çš„å‡å€¼ |
| **Throughput (GOPS)** | æ¯ç§’åäº¿æ¬¡æ“ä½œæ•°ï¼ˆGiga Operations Per Secondï¼‰ |
| **Energy Efficiency (GOPS/W)** | å•ä½åŠŸè€—ä¸‹çš„è®¡ç®—æ€§èƒ½ |
| **Resource Utilization** | FPGAä¸­FFã€LUTã€DSPã€BRAMã€URAMå ç”¨æƒ…å†µ |
| **Model Size (MB)** | æ¨¡å‹å­˜å‚¨å¤§å°ï¼Œåæ˜ å¤æ‚åº¦ |

### ğŸ” åŸºçº¿å¯¹æ¯”æ–¹æ³•
- **FPGAåŸºçº¿**ï¼š
  - SOCC 2022 [14]ï¼šISSCN on ZCU102
  - ISCAS 2020 [1]ï¼šPointNet on ZCU104
  - CSSP 2023 [3]ï¼šDGCNN (FP32) on Ultrascale+
  - ASICON 2019 [18]ï¼šO-PointNet on ZC706
- **é€šç”¨å¹³å°å¯¹æ¯”**ï¼š
  - GPUï¼šTesla V100 / RTX 3060 Ti ä¸Šè¿è¡ŒåŸå§‹PointMLP-EliteåŠLiteç‰ˆ
  - CPUï¼šIntel i5-13400 è¿è¡ŒLiteç‰ˆ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªTable 2 & Table 3ï¼‰

| æŒ‡æ ‡ | HLS4PC (This Work) |
|------|---------------------|
| **Throughput** | **1648 GOPS** |
| **Energy Efficiency** | **294.5 GOPS/W** |
| **Power Consumption** | 2.2 W |
| **Operating Frequency** | 100 MHz |
| **FPGA Platform** | ZC706 (XC7Z045) |
| **Precision** | fp8 (8-bit fixed-point) |
| **Model** | PointMLP-Lite |

### ğŸ” ä¸å…ˆå‰FPGAå·¥ä½œçš„å¯¹æ¯”ï¼ˆTable 2ï¼‰
| å¯¹æ¯”é¡¹ | æå‡å€æ•° |
|--------|----------|
| **Throughput** | **3.56Ã— é«˜äºSOCC 2022** |
| **Energy Efficiency** | **57.4Ã— æ›´é«˜** |
| **åŸå› åˆ†æ** | ç®—æ³•-ç¡¬ä»¶ååŒä¼˜åŒ–ï¼ˆURSæ›¿ä»£FPSã€BNèåˆã€é‡åŒ–ï¼‰ã€é«˜æ•ˆæ•°æ®æµæ¶æ„ã€é¿å…é«˜ç²¾åº¦å†—ä½™ï¼ˆå¦‚FP32ï¼‰ |

### ğŸ’» ä¸å…¶ä»–å¹³å°å¯¹æ¯”ï¼ˆTable 3ï¼‰
| å¹³å° | Throughput (SPS) | ç›¸å¯¹äºBaseline GPUæå‡ |
|------|------------------|-------------------------|
| Tesla V100 (Baseline) | 176 SPS | Ã—1.0 |
| RTX 3060 Ti (PointMLP-Elite) | 187 SPS | ~1.06Ã— |
| RTX 3060 Ti (PointMLP-Lite) | 421 SPS | **2.4Ã—** |
| Intel i5-13400 (CPU) | 45 SPS | â€” |
| **ZC706 (FPGA, This Work)** | **990 SPS** | **5.6Ã—** |

> æ³¨ï¼šSPS = Samples Per Second

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆTable 1 & Fig. 4ï¼‰
é€šè¿‡é€æ­¥åº”ç”¨å‹ç¼©æŠ€æœ¯ï¼Œè§‚å¯Ÿå‡†ç¡®ç‡ä¸æ¨¡å‹è§„æ¨¡ä¹‹é—´çš„æƒè¡¡ï¼š

| æ¨¡å‹å˜ä½“ | è¾“å…¥ç‚¹æ•° | é‡‡æ ·æ–¹å¼ | BNèåˆ | ModelNet40 OA (%) | æ¨¡å‹å¤§å° |
|--------|-----------|------------|--------|--------------------|----------|
| PointMLP-Elite | 1024 | FPS | å¦ | 93.60 | åŸå§‹å¤§å° |
| M-1 | 1024 | URS | å¦ | 92.30 | â†“ |
| **M-2** | **512** | **URS** | **å¦** | **91.69** | **â†“50%** |
| M-3 | 512 | URS | æ˜¯ | 90.56 | â†“ |
| M-4 | 128 | URS | æ˜¯ | 86.87 | â†“75% |

- **å…³é”®å‘ç°**ï¼š
  - å°†è¾“å…¥ç‚¹å‡åŠï¼ˆ1024â†’512ï¼‰ä»…å¯¼è‡´çº¦2%çš„å‡†ç¡®ç‡ä¸‹é™ï¼ˆM-2ï¼‰ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½å†…å­˜å¼€é”€ã€‚
  - ç»“åˆ8-bité‡åŒ–åï¼Œæœ€ç»ˆæ¨¡å‹ **PointMLP-Lite** å®ç° **4Ã—æ›´ä½å¤æ‚åº¦**ï¼Œä¸”ä¿æŒæ¥è¿‘åŸæ¨¡å‹ç²¾åº¦ã€‚
  - Paretoå‰æ²¿å›¾æ˜¾ç¤ºï¼Œ8/8-bité‡åŒ–ç‰ˆæœ¬åœ¨å‡†ç¡®ç‡å‡ ä¹ä¸å˜çš„æƒ…å†µä¸‹è¾¾åˆ°æœ€ä¼˜æ€§ä»·æ¯”ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **HLS4PCæˆåŠŸå¡«è¡¥äº†FPGAåœ¨ç‚¹äº‘æ¨¡å‹åŠ é€Ÿä¸­çš„ç©ºç™½**ï¼š
   - é¦–ä¸ªæ”¯æŒå®Œæ•´ç‚¹äº‘å¤„ç†æµæ°´çº¿ï¼ˆå«FPS/URS/KNNç­‰æ˜ å°„å‡½æ•°ï¼‰çš„å¯å‚æ•°åŒ–HLSæ¡†æ¶ã€‚
2. **PointMLP-Liteå®ç°äº†é«˜æ•ˆçš„ç®—æ³•-ç¡¬ä»¶ååŒä¼˜åŒ–**ï¼š
   - é€šè¿‡URSæ›¿ä»£FPSã€è¾“å…¥å‰ªæã€BNèåˆã€é‡åŒ–ç­‰æ‰‹æ®µï¼Œåœ¨ä»…æŸå¤±~2%ç²¾åº¦çš„å‰æä¸‹å°†æ¨¡å‹å¤æ‚åº¦é™ä½4å€ã€‚
3. **FPGAåœ¨ç‚¹äº‘æ¨ç†ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›**ï¼š
   - ç›¸æ¯”GPUå’ŒCPUï¼ŒFPGAåœ¨ååé‡å’Œèƒ½æ•ˆæ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œå°¤å…¶é€‚åˆè¾¹ç¼˜ç«¯å®æ—¶å®‰å…¨å…³é”®åº”ç”¨ï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶ï¼‰ã€‚

### âš ï¸ å±€é™æ€§
- **ä½¿ç”¨URSå¼•å…¥éšæœºæ€§**ï¼šè™½ç„¶é€šè¿‡å¢å¤§batch sizeå’Œè®­ç»ƒè½®æ¬¡ç¼“è§£ï¼Œä½†ä»å¯èƒ½å½±å“æŸäº›å¯¹å±€éƒ¨ç»“æ„æ•æ„Ÿçš„ä»»åŠ¡è¡¨ç°ã€‚
- **å½“å‰æœªå……åˆ†åˆ©ç”¨é«˜ç«¯FPGAèµ„æº**ï¼šZC706å±äºä¸­ä½ç«¯å¹³å°ï¼Œè‹¥è¿ç§»åˆ°UltraScale+æˆ–Versalç³»åˆ—æœ‰æœ›è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚
- **ç¼ºä¹åŠ¨æ€å¯é‡æ„æ€§æ¼”ç¤º**ï¼šè™½å¼ºè°ƒFPGAçµæ´»æ€§ï¼Œä½†æœªå±•ç¤ºå¤šæ¨¡å‹åˆ‡æ¢æˆ–å¤šä»»åŠ¡è°ƒåº¦èƒ½åŠ›ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´ç»“æ„åŒ–çš„é‡‡æ ·ç­–ç•¥æ›¿ä»£URSï¼Œä¾‹å¦‚åŸºäº**Hilbert Curveçš„é‡‡æ ·**ï¼Œä»¥å‡å°‘å› å®Œå…¨éšæœºå¸¦æ¥çš„ç²¾åº¦æŸå¤±ã€‚
- æ‰©å±•æ¡†æ¶æ”¯æŒ**åˆ†å‰²ä»»åŠ¡**ï¼ˆSegmentationï¼‰è€Œä¸ä»…æ˜¯åˆ†ç±»ã€‚
- å¼•å…¥**è‡ªé€‚åº”ç²¾åº¦è°ƒèŠ‚æœºåˆ¶**ï¼Œæ ¹æ®ä¸åŒç½‘ç»œå±‚éœ€æ±‚åŠ¨æ€åˆ†é…bit-widthã€‚
- æ”¯æŒæ›´å¤šæ–°å‹ç‚¹äº‘æ¨¡å‹ï¼ˆå¦‚PointTransformerã€PV-RCNNï¼‰çš„è‡ªåŠ¨åŒ–éƒ¨ç½²ã€‚

---

> ğŸ”— **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/dll-ncai/HLS4PC](https://github.com/dll-ncai/HLS4PC)

</details>

---

### 13. [Role-Based Fault Tolerance System for LLM RL Post-Training](https://arxiv.org/abs/2512.22492)

**Authors**: Zhenqian Chen, Baoquan Zhong, Xiang Li, Qing Dai, Xinkui Zhao, Miao Ye, Ren Cheng, Lufei Zhang, Jianwei Yin  
**Category**: cs.DC  
**Published**: 2025-12-30  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.22492v1  

#### Abstract
RL post-training for LLMs has been widely scaled to enhance reasoning and tool-using capabilities. However, RL post-training interleaves training and inference workloads, exposing the system to faults from both sides. Existing fault tolerance frameworks for LLMs target either training or inference, ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRole-Based Fault Tolerance System for LLM RL Post-Training

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰åè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œ**åŒæ—¶æ¶‰åŠè®­ç»ƒï¼ˆtrainingï¼‰å’Œæ¨ç†ï¼ˆrolloutï¼‰è´Ÿè½½**ï¼Œå¯¼è‡´ç³»ç»Ÿé¢ä¸´æ¥è‡ªä¸¤æ–¹é¢çš„ç¡¬ä»¶æ•…éšœé£é™©ã€‚ç°æœ‰çš„å®¹é”™æ¡†æ¶ï¼ˆå¦‚ ByteRobustï¼‰é€šå¸¸åªé’ˆå¯¹çº¯è®­ç»ƒæˆ–çº¯æ¨ç†åœºæ™¯è®¾è®¡ï¼Œåœ¨ RL åœºæ™¯ä¸­ä¸€æ—¦å‘ç”Ÿå•ä¸ªæœºå™¨æ•…éšœï¼Œå¾€å¾€éœ€è¦**é‡å¯æ•´ä¸ª RL ä»»åŠ¡**ï¼Œé€ æˆä¸¥é‡çš„è®¡ç®—èµ„æºæµªè´¹å’Œè®­ç»ƒè¿›åº¦ä¸¢å¤±ã€‚

æ­¤å¤–ï¼Œä¼ ç»Ÿæ£€æµ‹æœºåˆ¶å­˜åœ¨ä¸¤ä¸ªæŒ‘æˆ˜ï¼š
- **Rank-level detection** å®¹æ˜“å°† rollout é˜¶æ®µç­‰å¾…å·¥å…·å“åº”æ—¶çš„ GPU ç©ºé—²è¯¯åˆ¤ä¸ºæ•…éšœï¼ˆfalse positiveï¼‰ï¼›
- **Cluster-level detection** åˆ™å› éœ€ç­‰å¾…æ‰€æœ‰èŠ‚ç‚¹æ— æ´»åŠ¨æ‰è§¦å‘ï¼Œå¯¼è‡´æ•…éšœå‘ç°å»¶è¿Ÿä¸¥é‡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºäº† **RobustRL** â€”â€”é¦–ä¸ªé¢å‘ LLM RL åè®­ç»ƒçš„**åŸºäºè§’è‰²çš„å®¹é”™ç³»ç»Ÿ**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> å°† RL ä¸­çš„ä¸åŒç»„ä»¶ï¼ˆtrainerã€rolloutã€ç®¡ç†è§’è‰²ç­‰ï¼‰è§†ä¸ºç‹¬ç«‹çš„åˆ†å¸ƒå¼å­ä»»åŠ¡ï¼Œå®ç°**è§’è‰²çº§æ•…éšœéš”ç¦»**ã€‚å½“æŸä¸€è§’è‰²å¤±è´¥æ—¶ï¼Œä»…æ¢å¤è¯¥è§’è‰²å¹¶é‡æ–°è¿æ¥åˆ°ä»åœ¨è¿è¡Œçš„è§’è‰²ï¼Œé¿å…å…¨å±€é‡å¯ã€‚

è¯¥ç³»ç»Ÿé‡‡ç”¨ **Detect-Restart-Reconnect èŒƒå¼**ï¼Œå…·ä½“åˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰Role- and Phase-Aware Fault Detectionï¼ˆç²¾å‡†æ•…éšœæ£€æµ‹ï¼‰
- å¯¹ trainer å’Œ rollout åˆ†åˆ«è®¾è®¡è¡Œä¸ºæ„ŸçŸ¥çš„ç›‘æ§ç­–ç•¥ï¼š
  - **Trainer**ï¼šç›‘æµ‹ TensorCore æ´»åŠ¨ï¼Œè‹¥è¿ç»­ 5 åˆ†é’Ÿæ— æ´»åŠ¨åˆ™åˆ¤å®šä¸ºæ•…éšœï¼ˆé€‚ç”¨äºå‰å‘/åå‘ä¼ æ’­å¯†é›†å‹ä»»åŠ¡ï¼‰ã€‚
  - **Rollout**ï¼šç»“åˆååé‡ï¼ˆTPSï¼‰ã€å¿ƒè·³æ£€æŸ¥ä¸ GPU æ´»åŠ¨ï¼Œé¿å…å› ç­‰å¾…å¤–éƒ¨å·¥å…·è°ƒç”¨è€Œäº§ç”Ÿçš„è¯¯æŠ¥ã€‚

#### ï¼ˆ2ï¼‰Role-Based and Resource-Efficient Restartï¼ˆé«˜æ•ˆç»†ç²’åº¦é‡å¯ï¼‰
- **Trainer æ•…éšœæ¢å¤**ï¼š
  - å®ç°éä¸­æ–­å¼æ¢å¤ï¼šrollout ç»§ç»­ç”Ÿæˆè½¨è¿¹ï¼Œtrainer å¿«é€Ÿä» checkpoint æ¢å¤ã€‚
  - å¼•å…¥â€œwarm standbyâ€æœºåˆ¶ï¼šåˆ©ç”¨ç©ºé—² rollout æœºå™¨ä½œä¸º warm standby æ›¿ä»£å†—ä½™å¤‡ç”¨æœºï¼ŒèŠ‚çœèµ„æºå¼€é”€ã€‚
- **Rollout æ•…éšœæ¢å¤**ï¼š
  - å•ç‹¬æ›¿æ¢æ•…éšœ rollout æœºå™¨ï¼Œä¸å½±å“æ•´ä½“è®­ç»ƒæµç¨‹ã€‚
  - æ”¯æŒå¿«é€Ÿæ‹‰å–æœ€æ–°æ¨¡å‹æƒé‡ç»§ç»­ç”Ÿæˆã€‚

#### ï¼ˆ3ï¼‰Dynamic Reconnection via UCXï¼ˆåŠ¨æ€é€šä¿¡é‡è¿ï¼‰
- ä½¿ç”¨ **UCXï¼ˆUnified Communication Xï¼‰** æ›¿ä»£ä¼ ç»Ÿçš„ NCCL é›†ä½“é€šä¿¡ã€‚
- æ”¯æŒç‚¹å¯¹ç‚¹å¼‚æ­¥é€šä¿¡ï¼Œå…è®¸æ•…éšœæ¢å¤åçš„è§’è‰²åŠ¨æ€åŠ å…¥é€šä¿¡ç»„ï¼Œå®ç°å³æ—¶æƒé‡åŒæ­¥ã€‚
- è®¾è®¡ relay server æœºåˆ¶ï¼šå·²æ›´æ–°æƒé‡çš„ rollout å¯ä½œä¸ºä¸­ç»§æœåŠ¡å™¨ï¼ŒåŠ é€Ÿå…¶ä»–å‰¯æœ¬çš„åŒæ­¥é€Ÿåº¦ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ByteRobust / ä¼ ç»Ÿæ–¹æ¡ˆ | RobustRL |
|------|------------------------|----------|
| å®¹é”™ç²’åº¦ | å…¨å±€ä»»åŠ¡é‡å¯ | è§’è‰²çº§éš”ç¦»ä¸æ¢å¤ |
| Rollout è¿›åº¦ä¿ç•™ | âŒ ä¸¢å¤± | âœ… ä¿æŒ |
| Trainer æ¢å¤æ•ˆç‡ | ä¾èµ– warm standbyï¼ˆèµ„æºæµªè´¹ï¼‰ | åŠ¨æ€å€Ÿç”¨ rollout æœºå™¨ï¼ˆèµ„æºé«˜æ•ˆï¼‰ |
| æƒé‡åŒæ­¥ | NCCLï¼ˆé™æ€é€šä¿¡ç»„ï¼Œä¸æ”¯æŒåŠ¨æ€æ¥å…¥ï¼‰ | UCX + Relayï¼ˆæ”¯æŒåŠ¨æ€é‡è¿ï¼‰ |
| æ•…éšœæ£€æµ‹å‡†ç¡®æ€§ | æ˜“è¯¯åˆ¤ rollout idle ä¸ºæ•…éšœ | ç›¸ä½æ„ŸçŸ¥ï¼Œå‡å°‘ false positive |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **æ•°å­¦æ¨ç†ä»»åŠ¡**ï¼š`DAPO-Math17K`ï¼Œä½¿ç”¨è§„åˆ™å¥–åŠ±å‡½æ•°è¯„åˆ†ã€‚
- **è½¯ä»¶å·¥ç¨‹ä»»åŠ¡ï¼ˆTool Useï¼‰**ï¼š`SWE-bench`ï¼Œé€šè¿‡å¤šè½®ä¸ä»£ç æ²™ç®±äº¤äº’ç”Ÿæˆä¿®å¤è½¨è¿¹ã€‚
- **é—®ç­”ä»»åŠ¡**ï¼š`HotPotQA`ï¼Œç”¨äºåˆ†æ rollout æ—¶é—´åˆ†å¸ƒã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼šQwen3-8Bã€Qwen3-32Bã€Qwen3-235B-A22B
- **è®­ç»ƒæ¶æ„**ï¼šSyncã€Semi-syncã€Async ä¸‰ç§æ¨¡å¼å‡æµ‹è¯•
- **ç¡¬ä»¶å¹³å°**ï¼š32 å° GPU æœåŠ¡å™¨ï¼Œå…± 256Ã— NVIDIA H20 96GB GPUs
  - NVLink å†…éƒ¨å¸¦å®½ï¼š900 GB/s
  - ç½‘ç»œï¼š4Ã—200Gbps NICs
- **è½¯ä»¶æ ˆ**ï¼š
  - CUDA 12.4, PyTorch 2.4.1, NCCL 2.21.5
  - åŸºäº verl æ¡†æ¶æ„å»ºï¼Œé›†æˆ vLLMï¼ˆæ¨ç†ï¼‰ã€PyTorch FSDP2ï¼ˆè®­ç»ƒï¼‰
  - Checkpoint ä½¿ç”¨ ByteCheckpoint + HDFS å­˜å‚¨

### è¯„ä¼°æŒ‡æ ‡
- **End-to-End Training Time**ï¼šæ€»è®­ç»ƒè€—æ—¶
- **ETTR (Effective Training Time Ratio)**ï¼š
  $$
  \text{ETTR} = \frac{\text{#Rollout} + \text{#Trainer}}{\text{Total Time}}
  $$
  è¡¡é‡å®é™…ç”¨äºæœ‰æ•ˆè®¡ç®—çš„æ—¶é—´å æ¯”ã€‚
- **Restart Overhead**ï¼šæ•…éšœæ¢å¤æ‰€éœ€æ—¶é—´åˆ†è§£
- **Weight Sync Latency**ï¼šæ¨¡å‹æƒé‡åŒæ­¥å»¶è¿Ÿ
- **Checkpoint Overhead**ï¼šæ¯æ­¥ä¿å­˜ checkpoint çš„é˜»å¡æ—¶é—´

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**ï¼šæ— æ•…éšœæ³¨å…¥çš„æ ‡å‡†è®­ç»ƒ
- **ByteRobust**ï¼šå½“å‰ä¸»æµ LLM å®¹é”™ç³»ç»Ÿï¼Œå‘ç”Ÿæ•…éšœå³é‡å¯æ•´ä¸ªä»»åŠ¡
- **RobustRL**ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•

> æ³¨ï¼šæœªä¸å…¶ä»–å¼€æº RL å®¹é”™ç³»ç»Ÿæ¯”è¾ƒï¼Œå› å…¶ä»£ç æœªå…¬å¼€ï¼›ä¸” RobustRL æ˜¯é¦–ä¸ªå®Œæ•´è¦†ç›– trainer å’Œ rollout çš„ç³»ç»Ÿã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰ç«¯åˆ°ç«¯è®­ç»ƒæ—¶é—´ vs ETTRï¼ˆå›¾11ï¼‰
| ä»»åŠ¡ | æ–¹æ³• | è®­ç»ƒæ—¶é—´ï¼ˆå°æ—¶ï¼‰ | ETTR |
|------|------|------------------|-------|
| Qwen3-8B-Math | Baseline | ~5.0 | 100% |
|                | ByteRobust | ~7.0â€“8.0 | ~60% |
|                | **RobustRL** | **~5.8â€“6.2** | **>80%** |
| Qwen3-32B-SWE | ByteRobust | æ˜¾è‘—å¢åŠ  | ~60% |
|               | **RobustRL** | **å‡å°‘ 3.5â€“4.5h** | **>80%** |

> åœ¨æ¯ 10 æ­¥æ³¨å…¥ä¸€æ¬¡ trainer æ•…éšœçš„æç«¯æ¡ä»¶ä¸‹ï¼ŒRobustRL çš„ ETTR è¾¾åˆ° **80%+**ï¼Œç›¸æ¯” ByteRobust æå‡ **20ä¸ªç™¾åˆ†ç‚¹**ã€‚

#### ï¼ˆ2ï¼‰è®­ç»ƒæ—¶é—´åŠ é€Ÿ
- åœ¨ Qwen3-8B-Math ä¸Šï¼Œ**ç«¯åˆ°ç«¯è®­ç»ƒæ—¶é—´ç¼©çŸ­ 8.4%â€“17.4%**
- åœ¨å¤æ‚ä»»åŠ¡ï¼ˆSWE-benchï¼‰ä¸Šæ”¶ç›Šæ›´å¤§ï¼Œå›  rollout æ—¶é—´æ›´é•¿ï¼Œä¿ç•™è¿›åº¦çš„ä»·å€¼æ›´é«˜

#### ï¼ˆ3ï¼‰æ»‘åŠ¨ ETTR å¯¹æ¯”ï¼ˆå›¾12ï¼‰
- åœ¨æ•…éšœå‘ç”ŸæœŸé—´ï¼ˆ0.8â€“2hï¼‰ï¼ŒByteRobust çš„ ETTR ä¸‹é™è‡³ **20%**
- RobustRL å›  rollout æŒç»­è¿è¡Œï¼ŒETTR ä¿æŒåœ¨ **60%ä»¥ä¸Š**
- **æå‡å¹…åº¦è¾¾ 18â€“24%**

#### ï¼ˆ4ï¼‰é‡å¯å¼€é”€å¯¹æ¯”ï¼ˆå›¾14ï¼‰
| æ¨¡å‹ | æ–¹æ³• | æ€»é‡å¯å»¶è¿Ÿ | ä¸»è¦ç“¶é¢ˆ |
|------|------|------------|-----------|
| 8B | ByteRobust | ~277.8s | å®ä¾‹é‡å¯ + Rollout åˆå§‹åŒ– |
|    | **RobustRL** | **~173.0s** | âœ… èŠ‚çœ ~38% æ—¶é—´ |
| 32B | ByteRobust | ~305.5s | Gang scheduling å¼€é”€å¤§ |
|     | **RobustRL** | **~182.6s** | âœ… åŠ é€Ÿçº¦ 1.7Ã— |

> RobustRL é€šè¿‡è·³è¿‡ rollout åˆå§‹åŒ–å’Œå®¹å™¨å¯åŠ¨é˜¶æ®µï¼Œæ˜¾è‘—é™ä½æ¢å¤å»¶è¿Ÿã€‚

#### ï¼ˆ5ï¼‰æƒé‡åŒæ­¥æ•ˆç‡ï¼ˆå›¾17â€“18ï¼‰
- UCX-based åŒæ­¥æ¥è¿‘ç†è®ºæé™ï¼ˆ235B æ¨¡å‹ä¼ è¾“ç†è®ºå€¼ 4.7sï¼Œå®æµ‹ ~6sï¼‰
- æ”¯æŒ relay æ‰©å±•ï¼Œéšç€ rollout æ•°é‡å¢é•¿ä»ä¿æŒçº¿æ€§æ‰©å±•æ€§
- NCCL å› å¹¿æ’­æœºåˆ¶ï¼Œåœ¨ rollout å¤šäº trainer æ—¶æ€§èƒ½ä¸‹é™æ˜æ˜¾

#### ï¼ˆ6ï¼‰Checkpoint å¼€é”€ï¼ˆå›¾19ï¼‰
- GPU â†’ Memory é˜»å¡æ—¶é—´ < 5 ç§’
- Memory â†’ Disk å¼‚æ­¥æ‰§è¡Œï¼Œä¸å½±å“è®­ç»ƒæµæ°´çº¿
- å å•æ­¥è®­ç»ƒæ—¶é—´æ¯”ä¾‹ < 1%ï¼Œå¯å¿½ç•¥

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è§’è‰²éš”ç¦»æ˜¯ RL å®¹é”™çš„å…³é”®**ï¼šå°† trainer ä¸ rollout è§†ä¸ºç‹¬ç«‹è§’è‰²è¿›è¡Œæ•…éšœå¤„ç†ï¼Œèƒ½æœ‰æ•ˆé˜²æ­¢â€œç‰µä¸€å‘è€ŒåŠ¨å…¨èº«â€çš„å…¨å±€é‡å¯ã€‚
2. **rollout è¿›åº¦å€¼å¾—ä¿ç•™**ï¼šå°¤å…¶åœ¨é•¿å°¾ rollout åœºæ™¯ï¼ˆå¦‚å·¥å…·è°ƒç”¨ã€æœç´¢ï¼‰ä¸­ï¼Œé¿å…é‡å¤ç”Ÿæˆå¯å¤§å¹…èŠ‚çº¦æ—¶é—´ã€‚
3. **warm standby å¯èµ„æºåŒ–**ï¼šåˆ©ç”¨ç°æœ‰ rollout æœºå™¨ä½œä¸º trainer çš„ warm standbyï¼Œæ—¢ä¿è¯æ¢å¤é€Ÿåº¦åˆé¿å…é¢å¤–èµ„æºå ç”¨ã€‚
4. **UCX æ˜¯åŠ¨æ€é€šä¿¡çš„ç†æƒ³é€‰æ‹©**ï¼šç›¸è¾ƒäº NCCL çš„é™æ€é€šä¿¡ç»„é™åˆ¶ï¼ŒUCX æ”¯æŒçµæ´»çš„ç‚¹å¯¹ç‚¹è¿æ¥ï¼Œæ›´é€‚åˆå¼‚æ­¥ RL æ¶æ„ä¸‹çš„å®¹é”™éœ€æ±‚ã€‚
5. **per-step checkpoint å¯è¡Œä¸”å¿…è¦**ï¼šå°½ç®¡é¢‘ç‡é«˜ï¼Œä½†ç”±äºå•æ­¥ RL æ—¶é—´é•¿è¾¾æ•°åˆ†é’Ÿè‡³å°æ—¶çº§ï¼Œcheckpoint å¼€é”€æå°ï¼Œä¸”èƒ½ç¡®ä¿çŠ¶æ€ä¸€è‡´æ€§ã€‚

### å±€é™æ€§
- **è¯Šæ–­èƒ½åŠ›æœ‰é™**ï¼šå½“å‰ç³»ç»Ÿä¾§é‡äºè‡ªåŠ¨æ¢å¤ï¼Œä½†ç¼ºä¹å¯¹æ ¹å› çš„æ·±å…¥å®šä½èƒ½åŠ›ï¼ˆå¦‚åŒºåˆ†ç¡¬ä»¶é”™è¯¯ä¸ä»£ç  bugï¼‰ã€‚
- **æœªè€ƒè™‘ silent data corruption æˆ– straggler é—®é¢˜**ï¼šè™½ç„¶æ¶æ„æ”¯æŒæ‰©å±•ï¼Œä½†å°šæœªé›†æˆç›¸å…³æ£€æµ‹æ¨¡å—ã€‚
- **ä¾èµ– homogeneous ç¡¬ä»¶ç¯å¢ƒ**ï¼šwarm standby æœºåˆ¶è¦æ±‚ trainer ä¸ rollout æœºå™¨åŒæ„ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **æ„å»º RL ç‰¹å®šçš„è¯Šæ–­å·¥å…·é“¾**ï¼šç»“åˆæ§åˆ¶æµä¸æ•°æ®ä¾èµ–åˆ†æï¼Œå®ç°æ›´ç²¾ç¡®çš„æ•…éšœå½’å› ã€‚
- **æ”¯æŒè§’è‰²çº§çƒ­æ›´æ–°ï¼ˆhot updateï¼‰**ï¼šåœ¨ä¸åœæ­¢è®­ç»ƒçš„å‰æä¸‹è°ƒæ•´ batch sizeã€learning rate ç­‰å‚æ•°ã€‚
- **å¼¹æ€§ RL è®­ç»ƒï¼ˆelastic trainingï¼‰**ï¼šåŸºäº RobustRL çš„æ¢å¤æœºåˆ¶ï¼Œæ”¯æŒ trainer åœ¨ data parallelism ç»´åº¦åŠ¨æ€æ‰©ç¼©å®¹ã€‚
- **é›†æˆæ›´å¤šé«˜çº§å®¹é”™æŠ€æœ¯**ï¼šå¦‚ SDC æ£€æµ‹ã€straggler ç¼“è§£ã€æ··åˆç²¾åº¦æ ¡éªŒç­‰ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> RobustRL é€šè¿‡ **è§’è‰²éš”ç¦» + åŠ¨æ€é‡è¿ + rollout æ¸©å¤‡**ï¼Œé¦–æ¬¡å®ç°äº†é«˜æ•ˆçš„ RL åè®­ç»ƒå®¹é”™ï¼Œåœ¨æç«¯æ•…éšœåœºæ™¯ä¸‹å°† ETTR æå‡è‡³ 80%+ï¼Œè¾ƒ ByteRobust åŠ é€Ÿ 8.4%â€“17.4%ï¼Œä¸ºå¤§è§„æ¨¡ LLM å¼ºåŒ–å­¦ä¹ æä¾›äº†å¯é åŸºç¡€è®¾æ–½æ”¯æ’‘ã€‚

</details>

---

### 14. [Graph Attention-based Adaptive Transfer Learning for Link Prediction](https://arxiv.org/abs/2512.22252)

**Authors**: Huashen Lu, Wensheng Gan, Guoting Chen, Zhichao Huang, Philip S. Yu  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.22252v1  

#### Abstract
Graph neural networks (GNNs) have brought revolutionary advancements to the field of link prediction (LP), providing powerful tools for mining potential relationships in graphs. However, existing methods face challenges when dealing with large-scale sparse graphs and the need for a high degree of al...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šGraph Attention-based Adaptive Transfer Learning for Link Prediction

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰åœ¨**å¤§è§„æ¨¡ç¨€ç–å›¾ä¸Šçš„é“¾æ¥é¢„æµ‹**ï¼ˆLink Prediction, LPï¼‰ä»»åŠ¡ä¸­é¢ä¸´çš„ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **æ•°æ®ç¨€ç–æ€§ä¸æ‹“æ‰‘é”™é…**ï¼šä¸åŒå›¾ä¹‹é—´çš„ç»“æ„ã€å¯†åº¦å’Œç‰¹å¾åˆ†å¸ƒå·®å¼‚å¤§ï¼Œå¯¼è‡´é¢„è®­ç»ƒæ¨¡å‹éš¾ä»¥æœ‰æ•ˆè¿ç§»åˆ°ç›®æ ‡å›¾ï¼›
- **å‚æ•°ä¸å¹³è¡¡ä¸è¿‡æ‹Ÿåˆé£é™©**ï¼šåœ¨å°è§„æ¨¡ç›®æ ‡å›¾ä¸Šå¾®è°ƒå¤§å‹é¢„è®­ç»ƒæ¨¡å‹å®¹æ˜“é€ æˆè¿‡æ‹Ÿåˆä¸”è®¡ç®—æˆæœ¬é«˜ï¼›
- **é•¿è·ç¦»ä¾èµ–å»ºæ¨¡å›°éš¾**ï¼šä¼ ç»ŸGNNå’ŒTransformerä¾èµ–å±€éƒ¨èšåˆæˆ–åºåˆ—ä½ç½®ç¼–ç ï¼Œéš¾ä»¥æ•æ‰è·¨åŸŸçš„è¿œè·ç¦»èŠ‚ç‚¹å…³ç³»ã€‚

æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å¤§å¤šå¿½è§†äº†**transfer learning åœ¨è·¨å›¾ link prediction ä¸­çš„æ³›åŒ–æ½œåŠ›**ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šGAATNet
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Graph Attention Adaptive Transfer Network (GAATNet)** çš„æ–°å‹æ¡†æ¶ï¼Œç»“åˆäº†é¢„è®­ç»ƒ-å¾®è°ƒç­–ç•¥ä¸å›¾æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°é«˜æ•ˆçš„çŸ¥è¯†è¿ç§»ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **å¼•å…¥è¿œé‚»åµŒå…¥ä½œä¸ºæ³¨æ„åŠ›åç½®ï¼ˆDistant Neighbor Bias in Self-Attentionï¼‰**
   - åœ¨è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­ï¼Œå°†æ¥è‡ª $g$-hop ($g \geq 2$) è¿œé‚»å±…çš„åµŒå…¥ä¿¡æ¯ä½œä¸º**æ³¨æ„åŠ›çŸ©é˜µçš„åç½®é¡¹**ï¼Œå¢å¼ºå¯¹å…¨å±€ç»“æ„å’Œé•¿ç¨‹ä¾èµ–çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚
   - æœ‰åŠ©äºç¼“è§£ç¨€ç–å›¾ä¸­çš„â€œå†·å¯åŠ¨â€é—®é¢˜ï¼Œå¹¶æå‡æ¨¡å‹å¯¹å¤æ‚æ‹“æ‰‘çš„å»ºæ¨¡èƒ½åŠ›ã€‚

2. **è½»é‡çº§è‡ªé€‚é…å™¨æ¨¡å—ï¼ˆLightweight Self-Adapter Moduleï¼‰ç”¨äºå¾®è°ƒ**
   - åœ¨å¾®è°ƒé˜¶æ®µå†»ç»“ä¸»å¹²ç½‘ç»œå‚æ•°ï¼Œä»…è®­ç»ƒä¸€ä¸ªæ’å…¥å¼çš„**self-adapter æ¨¡å—**ï¼ˆå«ä½ç»´ç“¶é¢ˆç»“æ„å’Œæ®‹å·®è¿æ¥ï¼‰ï¼Œæ˜¾è‘—å‡å°‘å¯è®­ç»ƒå‚æ•°æ•°é‡ã€‚
   - å®ç°é«˜æ•ˆçš„å‚æ•°é€‚åº”ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼ŒåŠ å¿«æ”¶æ•›é€Ÿåº¦ã€‚

3. **ä¸¤é˜¶æ®µè‡ªé€‚åº”è¿ç§»å­¦ä¹ æ¶æ„**
   - **é¢„è®­ç»ƒé˜¶æ®µ**ï¼šåœ¨å¤§è§„æ¨¡æºå›¾ä¸Šå­¦ä¹ ä¸°å¯Œçš„å…¨å±€ç»“æ„å…ˆéªŒï¼›
   - **å¾®è°ƒé˜¶æ®µ**ï¼šé€šè¿‡ self-adapter å¿«é€Ÿé€‚é…åˆ°å°è§„æ¨¡ç›®æ ‡å›¾ï¼Œå…¼é¡¾æ€§èƒ½ä¸æ•ˆç‡ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | GAATNetä¼˜åŠ¿ |
|------|------------|
| **æ€§èƒ½** | æ˜¾è‘—ä¼˜äºå„ç±»åŸºçº¿æ–¹æ³•ï¼Œåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¾¾åˆ° SOTA è¡¨ç° |
| **æ•ˆç‡** | å¾®è°ƒé˜¶æ®µå‚æ•°é‡å¤§å¹…é™ä½ï¼Œè®­ç»ƒæ—¶é—´ç¼©çŸ­ï¼ˆå¹³å‡å‡å°‘ä¸€åŠä»¥ä¸Šï¼‰ |
| **æ³›åŒ–æ€§** | èƒ½æœ‰æ•ˆå¤„ç†ä¸åŒè§„æ¨¡ã€å¯†åº¦å’Œé¢†åŸŸçš„å›¾æ•°æ®ï¼Œå…·å¤‡è‰¯å¥½è·¨åŸŸè¿ç§»èƒ½åŠ› |
| **é²æ£’æ€§** | åˆ©ç”¨ contrastive loss å’Œ diffusion augmentation æŠ—å™ªå£°å’Œç¨€ç–å¹²æ‰° |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å…±ä½¿ç”¨ **7ä¸ªå…¬å¼€å›¾æ•°æ®é›†**ï¼Œæ¶µç›–å¤šç§ç±»å‹ä¸è§„æ¨¡ï¼š

| æ•°æ®é›† | ç±»å‹ | èŠ‚ç‚¹æ•° | è¾¹æ•° | è§„æ¨¡åˆ†ç±» |
|--------|------|--------|-------|----------|
| Cora / Citeseer | å¼•ç”¨ç½‘ç»œ | ~2.7Kâ€“3.3K | ~4.7Kâ€“5.4K | å°å‹ |
| Facebook / ChCh-Miner | ç¤¾äº¤/ç”Ÿç‰©åŒ»å­¦ | ~4Kâ€“1.5K | ~4.8Kâ€“8.8K | ä¸­å‹ |
| Coauthor-CS / Computers / Email-Enron | åˆä½œ/è´­ä¹°/é€šä¿¡ | ~1.3Kâ€“1.8K | ~137Kâ€“491K | å¤§å‹ |

> æ³¨ï¼šæ‰€æœ‰æ•°æ®é›†å‡ä½¿ç”¨ node2vec åˆå§‹åŒ–èŠ‚ç‚¹åµŒå…¥ï¼ˆ256ç»´ï¼‰ã€‚

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### è¯„ä¼°ä»»åŠ¡
- **é“¾æ¥é¢„æµ‹**ï¼ˆLink Predictionï¼‰ï¼šåˆ¤æ–­ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´æ˜¯å¦å­˜åœ¨æ½œåœ¨è¾¹ã€‚
- é‡‡ç”¨æ ‡å‡†çš„ **8:1:1** æ•°æ®åˆ’åˆ†ï¼ˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•ï¼‰ï¼Œæ­£è´Ÿæ ·æœ¬å¹³è¡¡é‡‡æ ·ã€‚

#### è¯„ä¼°æŒ‡æ ‡
- **AUC**ï¼ˆArea Under ROC Curveï¼‰
- **F1 Score**
- åœ¨éå¹³è¡¡åœºæ™¯ä¸‹é¢å¤–æŠ¥å‘Š **Average Precision (AP)**

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºä¸‰ç±»è¿›è¡Œæ¯”è¾ƒï¼š
1. **ç»å…¸æ–¹æ³•**ï¼šGCN, GAT
2. **å­å›¾/æ˜¾å¼ç‰¹å¾æ–¹æ³•**ï¼šSEAL, SIEG, HL-GNN
3. **è¿ç§»/å¯¹æ¯”å­¦ä¹ æ–¹æ³•**ï¼šAdaGCN, LGCL, LPFormer, Graph2Feat

> æ‰€æœ‰æ–¹æ³•ç»Ÿä¸€è¾“å…¥ï¼ˆnode2vecåµŒå…¥ï¼‰ã€ç›¸åŒåˆ’åˆ†ã€å…¬å¹³è¶…å‚å¯¹é½ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ€§èƒ½å¯¹æ¯”ï¼ˆå¹³è¡¡è®¾ç½®ï¼Œ200 epochsï¼‰

| æ–¹æ³• | Cora (AUC/F1) | Facebook (AUC/F1) | Computers (AUC/F1) | Email-Enron (AUC/F1) |
|------|----------------|--------------------|---------------------|------------------------|
| GCN | 68.36 / 58.23 | 65.37 / 59.35 | 61.36 / 55.38 | 65.23 / 60.47 |
| GAT | 83.78 / 78.42 | 82.18 / 77.53 | 82.78 / 73.37 | 79.93 / 74.15 |
| SEAL | 88.71 / 81.34 | 86.47 / 80.45 | 83.87 / 79.33 | 84.49 / 78.59 |
| LPFormer | 92.82 / 84.05 | 92.07 / 89.74 | 90.09 / 84.41 | 92.33 / 85.10 |
| **GAATNet** | **94.27 / 86.85** | **96.37 / 92.27** | **95.05 / 89.86** | **95.48 / 90.27** |

âœ… **å…³é”®å‘ç°**ï¼š
- åœ¨æ‰€æœ‰7ä¸ªæ•°æ®é›†ä¸Šï¼ŒGAATNet å‡å–å¾— **æœ€ä¼˜æ€§èƒ½**ï¼ˆAUC å’Œ F1 åŒé¢†å…ˆï¼‰ï¼›
- åœ¨å¤§å‹ç¨€ç–å›¾ï¼ˆå¦‚ Computers å’Œ Email-Enronï¼‰ä¸Šæå‡å°¤ä¸ºæ˜æ˜¾ï¼ˆAUC æå‡çº¦ 2.8%-3.2%ï¼‰ï¼›
- å³ä½¿åœ¨å°å‹å›¾ä¸Šä¹Ÿä¿æŒç¨³å®šä¼˜åŠ¿ï¼Œè¯´æ˜å…¶è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

---

### éå¹³è¡¡è®¾ç½®ä¸‹çš„è¡¨ç°ï¼ˆNegative:Positive = 10:1 å’Œ 20:1ï¼‰

| æ–¹æ³• | Cora (10:1 AUC/AP) | Facebook (10:1 AUC/AP) | ChCh-Miner (10:1 AUC/AP) |
|------|---------------------|-------------------------|----------------------------|
| LPFormer | 88.76 / 85.37 | 88.07 / 88.34 | 89.69 / 88.46 |
| **GAATNet** | **88.23 / 89.17** | **90.03 / 91.44** | **91.83 / 91.13** |

âœ… **ç»“è®º**ï¼š
- GAATNet åœ¨é«˜åº¦ä¸å¹³è¡¡åœºæ™¯ä¸‹ä»è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨ AP æŒ‡æ ‡ä¸Šæ˜¾è‘—é¢†å…ˆï¼›
- è¡¨æ˜å…¶èƒ½æ›´æœ‰æ•ˆåœ°è¯†åˆ«ç¨€æœ‰çš„æ­£æ ·æœ¬ï¼Œå…·æœ‰æ›´å¼ºçš„é²æ£’æ€§å’Œåˆ¤åˆ«èƒ½åŠ›ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

è®¾è®¡äº†ä»¥ä¸‹å˜ä½“ä»¥éªŒè¯å„ç»„ä»¶æœ‰æ•ˆæ€§ï¼š
- **NonAug**ï¼šå»é™¤ diffusion æ•°æ®å¢å¼º
- **NonFT**ï¼šç§»é™¤é¢„è®­ç»ƒä¸­çš„ feature transformer
- **NonSA**ï¼šç§»é™¤å¾®è°ƒä¸­çš„ self-adapter
- **NonCon**ï¼šç§»é™¤ contrastive loss
- **NonAtt**ï¼šæ›¿æ¢æ³¨æ„åŠ›ä¸º mean pooling

#### ç»“æœåˆ†æï¼ˆè§ Fig. 6ï¼‰ï¼š
| ç»„ä»¶ | å½±å“ç¨‹åº¦ | å…³é”®è§‚å¯Ÿ |
|------|----------|-----------|
| **NonAtt** | âŒ æœ€ä¸¥é‡ä¸‹é™ | è¯æ˜ attention æœºåˆ¶å¯¹æ€§èƒ½è‡³å…³é‡è¦ |
| **NonAug** | âš ï¸ æ˜¾è‘—ä¸‹é™ | diffusion augmentation å¯¹ç¨€ç–å›¾å°¤ä¸ºé‡è¦ |
| **NonCon** | âš ï¸ ä¸‹é™çº¦ 1.15% AUC | contrastive loss æå‡è¡¨ç¤ºåŒºåˆ†åº¦ |
| **NonSA** | â›” ä¸­ç­‰å½±å“ | åœ¨å¤§å›¾ä¸Šå½±å“æ›´å¤§ï¼Œä½“ç° self-adapter çš„å¿…è¦æ€§ |
| **NonFT** | âš ï¸ å°å›¾å½±å“å°ï¼Œå¤§å›¾å½±å“å¤§ | feature transformer æ›´åˆ©äºæ•è·å¤æ‚ç»“æ„ |

âœ… **æœ€ç»ˆå®Œæ•´æ¨¡å‹ GAATNet è¡¨ç°æœ€ä½³**ï¼Œè¡¨æ˜æ‰€æœ‰ç»„ä»¶ååŒä½œç”¨ã€‚

---

### æ•ˆç‡åˆ†æ

#### å‚æ•°ä¸å†…å­˜æ¶ˆè€—ï¼ˆCora æ•°æ®é›†ï¼‰
| æ–¹æ³• | Trainable Parameters (k) | Memory (MB) |
|------|---------------------------|-------------|
| SEAL | 2300 | 1062 |
| LPFormer | 986 | 962 |
| **GAATNet (pre-train)** | **208** | **271** |
| **GAATNet (fine-tune)** | **44** | **57** |

âœ… **ä¼˜åŠ¿**ï¼š
- å¾®è°ƒé˜¶æ®µå‚æ•°ä»…ä¸º **44k**ï¼Œæ˜¯æ¬¡ä¼˜æ–¹æ³•çš„ 1/10~1/20ï¼›
- å†…å­˜å ç”¨æœ€ä½ï¼Œé€‚åˆèµ„æºå—é™éƒ¨ç½²ã€‚

#### è®­ç»ƒæ—¶é—´ï¼ˆæ¯ epoch ç§’æ•°ï¼‰
| æ–¹æ³• | Computers (ç§’) | GAATNet (pre-train/fine-tune) |
|------|------------------|------------------------------|
| SEAL | 2271 | â€” |
| LPFormer | 174.9 | â€” |
| **GAATNet_p** | â€” | **16.32** |
| **GAATNet_f** | â€” | **7.29** âœ… |

âœ… å¾®è°ƒé˜¶æ®µè®­ç»ƒæ—¶é—´**å‡å°‘è¶…è¿‡50%**ï¼Œæ•ˆç‡æé«˜ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **GAATNet æ˜¯é¦–ä¸ªå°† distant neighbor embedding ä½œä¸º attention bias çš„ link prediction æ¡†æ¶**ï¼Œæœ‰æ•ˆå¢å¼ºäº†å¯¹å…¨å±€ç»“æ„çš„ç†è§£ã€‚
2. âœ… **self-adapter æ¨¡å—æå¤§æå‡äº†å¾®è°ƒæ•ˆç‡**ï¼Œå®ç°äº†å‚æ•°é«˜æ•ˆè¿ç§»ï¼Œé¿å…äº†å…¨æ¨¡å‹å¾®è°ƒå¸¦æ¥çš„è¿‡æ‹Ÿåˆå’Œé«˜æ˜‚æˆæœ¬ã€‚
3. âœ… **ä¸¤é˜¶æ®µ pre-train + fine-tune æ¶æ„æ˜¾è‘—æå‡è·¨å›¾è¿ç§»æ€§èƒ½**ï¼Œå°¤å…¶é€‚ç”¨äºä»å°æ ·æœ¬ç›®æ ‡å›¾ä¸­æŒ–æ˜æ½œåœ¨è¿æ¥ã€‚
4. âœ… åœ¨ **7ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå…¨é¢è¶…è¶Š SOTA æ–¹æ³•**ï¼Œæ— è®ºæ˜¯åœ¨ AUCã€F1 è¿˜æ˜¯ AP æŒ‡æ ‡ä¸Šå‡è¡¨ç°æœ€ä¼˜ã€‚
5. âœ… æ–¹æ³•åœ¨**éå¹³è¡¡ã€ç¨€ç–ã€è·¨é¢†åŸŸåœºæ™¯ä¸‹ä¾ç„¶ç¨³å¥**ï¼Œå±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œå®ç”¨æ€§ã€‚

---

### å±€é™æ€§
1. å½“å‰æ¡†æ¶ä¸»è¦é¢å‘**é™æ€åŒè´¨å›¾**ï¼Œå°šæœªæ‰©å±•è‡³åŠ¨æ€å›¾æˆ–æ—¶ç©ºå›¾ï¼›
2. è™½ç„¶æ”¯æŒå¼‚æ„å›¾åˆæ­¥å®éªŒï¼ˆLast.FM, Babyï¼‰ï¼Œä½†åœ¨å¤šç±»å‹èŠ‚ç‚¹/è¾¹ä¸Šä»æœ‰ä¼˜åŒ–ç©ºé—´ï¼›
3. diffusion augmentation å’Œ g-hop neighbor æå–å¸¦æ¥ä¸€å®šè®¡ç®—å¼€é”€ï¼Œå¯èƒ½é™åˆ¶æç«¯å¤§è§„æ¨¡å›¾çš„åº”ç”¨ï¼›
4. é¢„è®­ç»ƒéœ€ä¾èµ–å¤§è§„æ¨¡å›¾ï¼Œè‹¥æ— åˆé€‚æºå›¾åˆ™æ•ˆæœå—é™ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³ **dynamic graphsã€spatio-temporal graphs å’Œ heterogeneous graphs**ï¼›
2. è®¾è®¡æ›´è½»é‡åŒ–çš„é¢„è®­ç»ƒç½‘ç»œï¼Œä¾¿äºè¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ï¼›
3. æ¢ç´¢æ›´é«˜æ•ˆçš„å›¾å¢å¼ºæ–¹æ³•ï¼ˆå¦‚åŸºäº LLM çš„è¯­ä¹‰å¢å¼ºï¼‰ï¼›
4. ç»“åˆ **large language modelsã€knowledge distillation æˆ– reinforcement learning** æå‡è¡¨ç¤ºè´¨é‡ï¼›
5. ç ”ç©¶æ— ç›‘ç£æˆ–å¼±ç›‘ç£è¿ç§»ç­–ç•¥ï¼Œé™ä½å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚

---

> ğŸ”— **ä»£ç ä¸æ•°æ®å¼€æºåœ°å€**ï¼š[https://github.com/DSI-Lab1/GAATNet](https://github.com/DSI-Lab1/GAATNet)

</details>

---

### 15. [Federated Multi-Task Clustering](https://arxiv.org/abs/2512.22897)

**Authors**: S. Dai, G. Sun, F. Li, X. Tang, Q. Wang, Y. Cong  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.22897v1  

#### Abstract
Spectral clustering has emerged as one of the most effective clustering algorithms due to its superior performance. However, most existing models are designed for centralized settings, rendering them inapplicable in modern decentralized environments. Moreover, current federated learning approaches o...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠFederated Multi-Task Clusteringã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**è”é‚¦èšç±»å­¦ä¹ **ï¼ˆFederated Clusteringï¼‰ä¸­çš„ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜æå‡ºè§£å†³æ–¹æ¡ˆï¼š
- **Intra-client Correlationï¼ˆå®¢æˆ·ç«¯å†…ç›¸å…³æ€§ï¼‰**ï¼šä¼ ç»Ÿæ–¹æ³•ä¾èµ–ä¸å¯é çš„ä¼ªæ ‡ç­¾ï¼ˆpseudo-labelsï¼‰è¿›è¡Œè®­ç»ƒï¼Œä¸”éš¾ä»¥æ³›åŒ–åˆ°æœªè§æ ·æœ¬ï¼ˆout-of-sample inferenceï¼‰ã€‚
- **Inter-client Correlationï¼ˆå®¢æˆ·ç«¯é—´ç›¸å…³æ€§ï¼‰**ï¼šç°æœ‰è”é‚¦æ–¹æ³•é€šå¸¸å¿½ç•¥å¼‚æ„å®¢æˆ·ç«¯ä¹‹é—´çš„æ½œåœ¨å…±äº«ç»“æ„ï¼ˆå¦‚è¯­ä¹‰å…±æ€§ï¼‰ï¼Œä»…å­¦ä¹ ç‹¬ç«‹æ¨¡å‹æˆ–ç®€å•å¹³å‡å‚æ•°ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºäº† **Federated Multi-Task Clustering (FMTC)** æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ¯ä¸ªå®¢æˆ·ç«¯è§†ä¸ºä¸€ä¸ªç›¸å…³ä½†ä¸ªæ€§åŒ–çš„èšç±»ä»»åŠ¡ï¼Œåœ¨ä¿æŠ¤éšç§çš„å‰æä¸‹å®ç°ä¸ªæ€§åŒ–å»ºæ¨¡ä¸å…¨å±€çŸ¥è¯†å…±äº«çš„å¹³è¡¡ã€‚

#### åˆ›æ–°æ¨¡å—è®¾è®¡ï¼š
- **Client-Side Personalized Clustering Moduleï¼ˆå®¢æˆ·ç«¯ä¸ªæ€§åŒ–èšç±»æ¨¡å—ï¼‰**
  - å°†è°±åµŒå…¥å­¦ä¹ ï¼ˆspectral embeddingï¼‰ä¸å¯å­¦ä¹ çš„æ˜ å°„å‡½æ•° $W_t$ è”åˆä¼˜åŒ–ã€‚
  - å½¢å¼åŒ–ä¸ºï¼š$\min \text{Tr}(F_t^T L_t F_t) + \alpha \|F_t - X_t W_t\|^2$
  - ä¼˜åŠ¿ï¼šæ— éœ€ç”Ÿæˆä¼ªæ ‡ç­¾ï¼›æ”¯æŒå¯¹æ–°æ ·æœ¬ç›´æ¥æ¨ç†ï¼ˆout-of-sample inferenceï¼‰ã€‚

- **Server-Side Tensorial Correlation Moduleï¼ˆæœåŠ¡å™¨ç«¯å¼ é‡å…³è”æ¨¡å—ï¼‰**
  - å°†æ‰€æœ‰å®¢æˆ·ç«¯çš„æŠ•å½±çŸ©é˜µ $\{W_t\}$ ç»„ç»‡æˆä¸€ä¸ªä¸‰é˜¶å¼ é‡ $W \in \mathbb{R}^{d \times k \times m}$ã€‚
  - æ–½åŠ ä½ç§©æ­£åˆ™åŒ–ï¼ˆlow-rank regularizationï¼‰ä»¥æå–è·¨ä»»åŠ¡çš„é«˜é˜¶å…±äº«çŸ¥è¯†ã€‚
  - é€šè¿‡ Schatten p-norm æ­£åˆ™é¡¹æ•è·å¤šå®¢æˆ·ç«¯é—´çš„æ·±å±‚è¯­ä¹‰å…³ç³»ã€‚

#### è”åˆä¼˜åŒ–ç­–ç•¥
é‡‡ç”¨ **ADMMï¼ˆAlternating Direction Method of Multipliersï¼‰** æ„å»ºåˆ†å¸ƒå¼ä¼˜åŒ–ç®—æ³•ï¼š
- å¼•å…¥å…¨å±€å…±è¯†å˜é‡ $Z$ï¼Œè§£è€¦è€¦åˆçº¦æŸã€‚
- å®¢æˆ·ç«¯å¹¶è¡Œæ›´æ–°æœ¬åœ°æ¨¡å‹ $(F_t, W_t)$ï¼ŒæœåŠ¡å™¨èšåˆåæ›´æ–° $Z$ å¹¶å¹¿æ’­å›å®¢æˆ·ç«¯ã€‚
- æ•´ä¸ªè¿‡ç¨‹ä¸äº¤æ¢åŸå§‹æ•°æ®ï¼Œä¿éšœéšç§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•å±€é™ | FMTC æ”¹è¿› |
|------|---------------|-----------|
| æ³›åŒ–èƒ½åŠ› | éå‚æ•°è°±èšç±»æ— æ³•å¤„ç†æ–°æ ·æœ¬ | å‚æ•°åŒ–æ˜ å°„ $W_t$ æ”¯æŒå®æ—¶æ¨ç† |
| ä¼ªæ ‡ç­¾ä¾èµ– | â€œä¸¤é˜¶æ®µâ€æ–¹æ³•è¯¯å·®ä¼ æ’­ä¸¥é‡ | è”åˆä¼˜åŒ–é¿å…ä¼ªæ ‡ç­¾ä½¿ç”¨ |
| å¤šä»»åŠ¡å»ºæ¨¡ | å¿½è§†å®¢æˆ·ç«¯é—´æ½œåœ¨ç»“æ„ | å¼ é‡ä½ç§©æ­£åˆ™æ˜¾å¼æ•æ‰å…±äº«çŸ¥è¯† |
| ä¸ªæ€§åŒ–ä¸åä½œå¹³è¡¡ | å•ä¸€å…¨å±€æ¨¡å‹æˆ–å®Œå…¨ç‹¬ç«‹æ¨¡å‹ | ä¸ªæ€§åŒ–æ¨¡å‹ + ç»“æ„å¼•å¯¼ååŒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ **7 ä¸ªçœŸå®ä¸–ç•ŒåŸºå‡†æ•°æ®é›†** ä¸Šè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼š
- æ–‡æœ¬æ•°æ®ï¼š`WebKB4`, `20NewsGroups`, `Reuters`, `BBC News`
- å›¾åƒæ•°æ®ï¼š`CORe50`, `YALE`
- ç”Ÿç‰©åŒ»å­¦æ•°æ®ï¼š`Keck`

è¿™äº›æ•°æ®è¦†ç›–å¤šç§æ¨¡æ€ï¼ˆç¨€ç–æ–‡æœ¬ã€å¯†é›†å›¾åƒå‘é‡ï¼‰ï¼ŒéªŒè¯æ–¹æ³•é€šç”¨æ€§ã€‚

### å®éªŒè®¾ç½®
- **è”é‚¦ç¯å¢ƒæ¨¡æ‹Ÿ**ï¼šé‡‡ç”¨ **Non-IID åˆ†å‰²ç­–ç•¥**ï¼Œæ¯ä¸ªè‡ªç„¶æ¥æºä½œä¸ºä¸€ä¸ªå®¢æˆ·ç«¯ï¼ˆå¦‚ WebKB ä¸­æ¯æ‰€å¤§å­¦ä¸ºä¸€ä¸ª clientï¼‰ã€‚
- **ç‰¹å¾ç©ºé—´ä¸€è‡´**ï¼šå‡è®¾æ‰€æœ‰å®¢æˆ·ç«¯å…±äº«ç›¸åŒç‰¹å¾ç»´åº¦ï¼ˆcross-silo settingï¼‰ã€‚
- **é€šä¿¡è½®æ¬¡**ï¼šé»˜è®¤è¿è¡Œ 50 è½® ADMM è¿­ä»£ã€‚

### è¯„ä¼°æŒ‡æ ‡
ä½¿ç”¨ä¸‰ä¸ªæ ‡å‡†èšç±»è¯„ä»·æŒ‡æ ‡ï¼ˆå‡å–ç™¾åˆ†æ¯”å½¢å¼ï¼‰ï¼š
- **ACCï¼ˆAccuracyï¼‰**ï¼šèšç±»å‡†ç¡®ç‡ï¼ˆé€šè¿‡åŒˆç‰™åˆ©ç®—æ³•åŒ¹é…æ ‡ç­¾ï¼‰
- **NMIï¼ˆNormalized Mutual Informationï¼‰**
- **RIï¼ˆRand Indexï¼‰**

æœ€ç»ˆç»“æœåŸºäº 10 æ¬¡ k-means åˆå§‹åŒ–å–æœ€ä¼˜å€¼ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºä¸‰ç±»è¿›è¡Œæ¯”è¾ƒï¼š

| ç±»åˆ« | æ–¹æ³• | ç‰¹ç‚¹ |
|------|------|------|
| **å•ä»»åŠ¡åŸºçº¿** | stSC, uSC | å„è‡ªè®­ç»ƒ / æ•°æ®åˆå¹¶è®­ç»ƒ |
| **é›†ä¸­å¼å¤šä»»åŠ¡æ–¹æ³•** | MBC, SMBC, SMKC, MTSC | å¯è®¿é—®å…¨éƒ¨æ•°æ®ï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™å‚è€ƒ |
| **è”é‚¦èšç±»æ–¹æ³•** | Fed-kmeans, FedSpectral+, SFOMVC | å½“å‰ä¸»æµè”é‚¦èšç±»æ–¹æ³• |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table Iï¼‰
ä»¥ä¸‹ä¸ºéƒ¨åˆ†ä»£è¡¨æ€§ç»“æœï¼ˆå•ä½ï¼š%ï¼‰ï¼š

| Dataset       | æ–¹æ³•         | ACC     | NMI     | RI      |
|---------------|--------------|---------|---------|---------|
| **WebKB4**    | stSC          | 63.37   | 21.44   | 62.45   |
|               | uSC           | 63.76   | 20.75   | 62.56   |
|               | MTSC          | 76.86   | 45.72   | 67.42   |
|               | **Ours (FMTC)** | **78.11** | **46.04** | **74.28** |
| **20News**    | stSC          | 56.18   | 24.14   | 64.41   |
|               | uSC           | 39.15   | 23.71   | 59.76   |
|               | MTSC          | 72.32   | 65.90   | 80.73   |
|               | **Ours (FMTC)** | **71.30** | **67.83** | **81.87** |
| **Reuters**   | stSC          | 85.17   | 66.54   | 81.87   |
|               | MTSC          | 77.89   | 56.09   | 73.00   |
|               | **Ours (FMTC)** | **89.40** | **73.85** | **86.23** |

> âœ… FMTC åœ¨å¤šæ•°æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œå°¤å…¶åœ¨å¼‚æ„æ€§å¼ºçš„ `20News` å’Œ `Reuters` ä¸Šè¡¨ç°çªå‡ºã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **vs. å•ä»»åŠ¡æ–¹æ³•**ï¼š
  - åœ¨ `WebKB4` ä¸Š ACC æå‡ **14.35%**ï¼Œ`20News` ä¸Šæå‡ **15.12%**ã€‚
  - è¡¨æ˜åˆ©ç”¨è·¨ä»»åŠ¡ç›¸å…³æ€§æœ‰æ•ˆå¢å¼ºæ€§èƒ½ã€‚

- **vs. é›†ä¸­å¼å¤šä»»åŠ¡æ–¹æ³•**ï¼š
  - å°½ç®¡æ— å…¨å±€æ•°æ®è®¿é—®æƒé™ï¼ŒFMTC ä»è¶…è¶Šå¤šä¸ªé›†ä¸­å¼æ–¹æ³•ï¼ˆå¦‚ MBCã€SMBCï¼‰ã€‚
  - åœ¨ `Reuters` ä¸Š NMI è¾¾ **73.85%**ï¼Œè¿œè¶… MTSC çš„ 56.09%ï¼Œè¯´æ˜å¼ é‡æ­£åˆ™æ›´æœ‰æ•ˆåœ°æ•æ‰é«˜é˜¶ç»“æ„ã€‚

- **vs. è”é‚¦æ–¹æ³•**ï¼š
  - åœ¨ `20News` ä¸Šï¼ŒFed-kmeans å’Œ FedSpectral+ çš„ ACC åˆ†åˆ«ä»…ä¸º **30.35%** å’Œ **27.10%**ï¼Œè€Œ FMTC è¾¾åˆ° **71.30%**ã€‚
  - æ˜¾ç¤ºä¼ ç»Ÿè”é‚¦æ–¹æ³•å› ç®€å•å¹³å‡å¯¼è‡´â€œæ¨¡å‹åå¡Œâ€ï¼Œè€Œ FMTC æˆåŠŸä¿ç•™ä¸ªæ€§åŒ–ç»“æ„ã€‚

### æ¶ˆèå®éªŒä¸åˆ†æï¼ˆFig. 5 & Table IIï¼‰

#### è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆFig. 5ï¼‰
- æ€§èƒ½éšåä½œæƒé‡ $\beta$ å’Œä¿çœŸåº¦æƒé‡ $\alpha$ å˜åŒ–å‘ˆç°éå‡¸åœ°å½¢ã€‚
- å½“ $\beta \to 0$ï¼ˆå³å…³é—­æœåŠ¡å™¨ç«¯å¼ é‡æ¨¡å—ï¼‰æ—¶æ€§èƒ½æ˜æ˜¾ä¸‹é™ï¼ŒéªŒè¯äº†**tensorial correlation module çš„å¿…è¦æ€§**ã€‚

#### Out-of-Sample æ³›åŒ–èƒ½åŠ›ï¼ˆTable II & Fig. 6ï¼‰
| æ–¹æ³• | WebKB4 (ISâ†’OOS ACC) | 20News (ISâ†’OOS ACC) | Reuters (ISâ†’OOS ACC) |
|------|---------------------|----------------------|------------------------|
| FedSpectral+ | 72.32 â†’ 30.35 | 70.15 â†’ 21.58 | 76.50 â†’ 37.10 |
| **Ours (FMTC)** | **78.11 â†’ 64.67** | **71.30 â†’ 79.16** | **89.40 â†’ 85.27** |

> ğŸ” FMTC å±•ç°å‡ºæå°çš„æ³›åŒ–å·®è·ï¼ˆgeneralization gapï¼‰ï¼Œç”šè‡³åœ¨ `20News` ä¸Š OOS æ€§èƒ½åè¶… ISï¼Œè¡¨æ˜å…¶å…·å¤‡å“è¶Šçš„é²æ£’æ€§å’Œå¤–æ¨èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ä¸ªæ€§åŒ–ä¸åä½œå¯ä»¥å…¼å¾—**ï¼šFMTC æˆåŠŸå®ç°äº†åœ¨ä¿æŠ¤å®¢æˆ·ç«¯ä¸ªæ€§çš„åŒæ—¶æŒ–æ˜å…±äº«ç»“æ„ï¼Œè§£å†³äº†è”é‚¦èšç±»ä¸­â€œä¸€ç»Ÿå°±æ­»ï¼Œä¸€åˆ†å°±æ•£â€çš„éš¾é¢˜ã€‚
2. **å¼ é‡ä½ç§©æ­£åˆ™ä¼˜äºçŸ©é˜µæ–¹æ³•**ï¼šç›¸æ¯”ä¼ ç»ŸçŸ©é˜µæ­£åˆ™ï¼ˆå¦‚ MTSCï¼‰ï¼Œç»„ç»‡æ¨¡å‹ä¸ºä¸‰é˜¶å¼ é‡å¹¶é€šè¿‡ Schatten norm æ­£åˆ™ï¼Œèƒ½æ›´æœ‰æ•ˆåœ°æ•æ‰é«˜é˜¶ä»»åŠ¡ç›¸å…³æ€§ã€‚
3. **è”åˆä¼˜åŒ–ä¼˜äºä¸¤é˜¶æ®µæµç¨‹**ï¼šå°†è°±åµŒå…¥ä¸æ˜ å°„å‡½æ•°è”åˆè®­ç»ƒï¼Œé¿å…äº†ä¼ªæ ‡ç­¾å¸¦æ¥çš„å™ªå£°ç´¯ç§¯ï¼Œæå¤§æå‡äº† out-of-sample æ¨ç†èƒ½åŠ›ã€‚
4. **ADMM æ¡†æ¶é«˜æ•ˆç¨³å®š**ï¼šç®—æ³•åœ¨çº¦ 15â€“20 è½®å†…å¿«é€Ÿæ”¶æ•›ï¼ˆFig. 4ï¼‰ï¼Œé€‚åˆå®é™…éƒ¨ç½²ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ç¼ºä¹ä¸¥æ ¼éšç§ä¿è¯**ï¼šè™½ç„¶ä¸ä¼ è¾“åŸå§‹æ•°æ®ï¼Œä½†å…±äº«æ¨¡å‹å‚æ•° $W_t$ å¯èƒ½é¢ä¸´æ¨¡å‹é€†å‘æ”»å‡»ï¼ˆmodel inversion attackï¼‰ã€‚
- **æ—‹è½¬æ¨¡ç³Šæ€§é—®é¢˜**ï¼šå­¦ä¹ åˆ°çš„æŠ•å½±çŸ©é˜µå­˜åœ¨æ—‹è½¬ä¸å˜æ€§ï¼Œå¯èƒ½å½±å“æœ€ç»ˆèšç±»è´¨é‡ï¼ˆä½œè€…åœ¨ç»“è®ºä¸­æŒ‡å‡ºæ­¤ä¸ºæœªæ¥æ–¹å‘ï¼‰ã€‚
- å¯¹æç«¯ Non-IID æˆ–æ•°æ®é‡æä¸å¹³è¡¡åœºæ™¯çš„é²æ£’æ€§æœ‰å¾…è¿›ä¸€æ­¥éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼•å…¥ **Differential Privacy** æˆ– **Secure Aggregation** å¢å¼ºéšç§ä¿æŠ¤ã€‚
- è®¾è®¡æœºåˆ¶ç¼“è§£æŠ•å½±çŸ©é˜µçš„ **rotational ambiguity**ã€‚
- æ‰©å±•è‡³ **multi-view** æˆ– **hierarchical clustering** åœºæ™¯ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„å¼ é‡åˆ†è§£ä¸æ­£åˆ™åŒ–æ–¹å¼ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> FMTC æ˜¯é¦–ä¸ªå°† **Multi-Task Learning** ä¸ **Federated Clustering** æ·±åº¦èåˆçš„æ¡†æ¶ï¼Œé€šè¿‡ **client-server ååŒæ¶æ„ + å¼ é‡æ­£åˆ™ + è”åˆä¼˜åŒ–**ï¼Œå®ç°äº†é«˜æ€§èƒ½ã€å¼ºæ³›åŒ–ã€å¯æ‰©å±•çš„è”é‚¦èšç±»æ–°èŒƒå¼ã€‚

</details>

---

### 16. [Energy and Memory-Efficient Federated Learning With Ordered Layer Freezing](https://arxiv.org/abs/2512.23200)

**Authors**: Ziru Niu, Hai Dong, A. K. Qin, Tao Gu, Pengcheng Zhang  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.23200v1  

#### Abstract
Federated Learning (FL) has emerged as a privacy-preserving paradigm for training machine learning models across distributed edge devices in the Internet of Things (IoT). By keeping data local and coordinating model training through a central server, FL effectively addresses privacy concerns and red...

---

### 17. [SlimEdge: Lightweight Distributed DNN Deployment on Constrained Hardware](https://arxiv.org/abs/2512.22136)

**Authors**: Mahadev Sunil Kumar, Arnab Raha, Debayan Das, Gopakumar G, Amitava Mukherjee  
**Category**: cs.DC  
**Published**: 2025-12-30  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.22136v1  

#### Abstract
Deep distributed networks (DNNs) have become central to modern computer vision, yet their deployment on resource-constrained edge devices remains hindered by substantial parameter counts and computational demands. Here, we present an approach to the efficient deployment of distributed DNNs that join...

---

### 18. [HybridFlow: Adaptive Task Scheduling for Fast and Token-Efficient LLM Inference in Edge-Cloud Collaboration](https://arxiv.org/abs/2512.22137)

**Authors**: Jiangwen Dong, Jiayu Li, Wanyu Lin  
**Category**: cs.DC  
**Published**: 2025-12-30  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.22137v1  

#### Abstract
Large language models (LLMs) exhibit impressive reasoning and problem-solving abilities, yet their substantial inference latency and token consumption pose major challenges for real-time deployment on resource-limited edge devices. Recent efforts toward edge-cloud collaboration have attempted to mit...

---

### 19. [RollArt: Scaling Agentic RL Training via Disaggregated Infrastructure](https://arxiv.org/abs/2512.22560)

**Authors**: Wei Gao, Yuheng Zhao, Tianyuan Wu, Shaopan Xiong, Weixun Wang, Dakai An, Lunxi Cao, Dilxat Muhtar, Zichen Liu, Haizhou Zhao, Ju Huang, Siran Yang, Yongbin Li, Wenbo Su, Jiamang Wang, Lin Qu, Bo Zheng, Wei Wang  
**Category**: cs.DC  
**Published**: 2025-12-30  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.22560v1  

#### Abstract
Agentic Reinforcement Learning (RL) enables Large Language Models (LLMs) to perform autonomous decision-making and long-term planning. Unlike standard LLM post-training, agentic RL workloads are highly heterogeneous, combining compute-intensive prefill phases, bandwidth-bound decoding, and stateful,...

---

### 20. [Mirage Persistent Kernel: A Compiler and Runtime for Mega-Kernelizing Tensor Programs](https://arxiv.org/abs/2512.22219)

**Authors**: Xinhao Cheng, Zhihao Zhang, Yu Zhou, Jianan Ji, Jinchen Jiang, Zepeng Zhao, Ziruo Xiao, Zihao Ye, Yingyi Huang, Ruihang Lai, Hongyi Jin, Bohan Hou, Mengdi Wu, Yixin Dong, Anthony Yip, Zihao Ye, Songting Wang, Wenqin Yang, Xupeng Miao, Tianqi Chen, Zhihao Jia  
**Category**: cs.DC  
**Published**: 2025-12-30  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.22219v1  

#### Abstract
We introduce Mirage Persistent Kernel (MPK), the first compiler and runtime system that automatically transforms multi-GPU model inference into a single high-performance megakernel. MPK introduces an SM-level graph representation that captures data dependencies at the granularity of individual strea...

---

### 21. [LuxIA: A Lightweight Unitary matriX-based Framework Built on an Iterative Algorithm for Photonic Neural Network Training](https://arxiv.org/abs/2512.22264)

**Authors**: Tzamn Melendez Carmona, Federico Marchesin, Marco P. Abrate, Peter Bienstman, Stefano Di Carlo, Alessandro Savino Senior  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.22264v1  

#### Abstract
PNNs present promising opportunities for accelerating machine learning by leveraging the unique benefits of photonic circuits. However, current state of the art PNN simulation tools face significant scalability challenges when training large-scale PNNs, due to the computational demands of transfer m...

---

### 22. [FLEX-MoE: Federated Mixture-of-Experts with Load-balanced Expert Assignment](https://arxiv.org/abs/2512.23070)

**Authors**: Boyang Zhang, Xiaobing Chen, Songyang Zhang, Shuai Zhang, Xiangwei Zhou, Mingxuan Sun  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.23070v1  

#### Abstract
Mixture-of-Experts (MoE) models enable scalable neural networks through conditional computation. However, their deployment with federated learning (FL) faces two critical challenges: 1) resource-constrained edge devices cannot store full expert sets, and 2) non-IID data distributions cause severe ex...

---

### 23. [Post-Training Quantization of OpenPangu Models for Efficient Deployment on Atlas A2](https://arxiv.org/abs/2512.23367)

**Authors**: Yilun Luo, HuaQing Zheng, Haoqian Meng, Wenyuan Liu, Peng Zhang  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.23367v1  

#### Abstract
Huawei's openPangu-Embedded-1B and openPangu-Embedded-7B, variants of the openPangu large language model, integrate three distinct Chain-of-Thought (CoT) reasoning paradigms, namely slow_think, auto_think, and no_think. While these CoT modes enhance reasoning capabilities, their generation of extend...

---

### 24. [Joint Link Adaptation and Device Scheduling Approach for URLLC Industrial IoT Network: A DRL-based Method with Bayesian Optimization](https://arxiv.org/abs/2512.23493)

**Authors**: Wei Gao, Paul Zheng, Peng Wu, Yulin Hu, Anke Schmeink  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.23493v1  

#### Abstract
In this article, we consider an industrial internet of things (IIoT) network supporting multi-device dynamic ultra-reliable low-latency communication (URLLC) while the channel state information (CSI) is imperfect. A joint link adaptation (LA) and device scheduling (including the order) design is pro...

---

### 25. [Calibrating LLM Judges: Linear Probes for Fast and Reliable Uncertainty Estimation](https://arxiv.org/abs/2512.22245)

**Authors**: Bhaktipriya Radharapu, Eshika Saxena, Kenneth Li, Chenxi Whitehouse, Adina Williams, Nicola Cancedda  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.22245v1  

#### Abstract
As LLM-based judges become integral to industry applications, obtaining well-calibrated uncertainty estimates efficiently has become critical for production deployment. However, existing techniques, such as verbalized confidence and multi-generation methods, are often either poorly calibrated or com...

---

### 26. [Hybrid Quantum-Classical Mixture of Experts: Unlocking Topological Advantage via Interference-Based Routing](https://arxiv.org/abs/2512.22296)

**Authors**: Reda Heddad, Lamiae Bouanane  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.22296v1  

#### Abstract
The Mixture-of-Experts (MoE) architecture has emerged as a powerful paradigm for scaling deep learning models, yet it is fundamentally limited by challenges such as expert imbalance and the computational complexity of classical routing mechanisms. This paper investigates the potential of Quantum Mac...

---

### 27. [Beyond Centralization: Provable Communication Efficient Decentralized Multi-Task Learning](https://arxiv.org/abs/2512.22675)

**Authors**: Donghwa Kang, Shana Moothedath  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.22675v1  

#### Abstract
Representation learning is a widely adopted framework for learning in data-scarce environments, aiming to extract common features from related tasks. While centralized approaches have been extensively studied, decentralized methods remain largely underexplored. We study decentralized multi-task repr...

---

### 28. [Understanding the Mechanisms of Fast Hyperparameter Transfer](https://arxiv.org/abs/2512.22768)

**Authors**: Nikhil Ghosh, Denny Wu, Alberto Bietti  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.22768v1  

#### Abstract
The growing scale of deep learning models has rendered standard hyperparameter (HP) optimization prohibitively expensive. A promising solution is the use of scale-aware hyperparameters, which can enable direct transfer of optimal HPs from small-scale grid searches to large models with minimal perfor...

---

### 29. [Sat-EnQ: Satisficing Ensembles of Weak Q-Learners for Reliable and Compute-Efficient Reinforcement Learning](https://arxiv.org/abs/2512.22910)

**Authors**: \"Unver \c{C}ift\c{c}i  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.22910v1  

#### Abstract
Deep Q-learning algorithms remain notoriously unstable, especially during early training when the maximization operator amplifies estimation errors. Inspired by bounded rationality theory and developmental learning, we introduce Sat-EnQ, a two-phase framework that first learns to be ``good enough'' ...

---

### 30. [Taming the Tail: Stable LLM Reinforcement Learning via Dynamic Vocabulary Pruning](https://arxiv.org/abs/2512.23087)

**Authors**: Yingru Li, Jiawei Xu, Jiacai Liu, Yuxuan Tong, Ziniu Li, Tianle Cai, Ge Zhang, Qian Liu, Baoxiang Wang  
**Category**: cs.LG  
**Published**: 2025-12-30  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.23087v1  

#### Abstract
Reinforcement learning for large language models (LLMs) faces a fundamental tension: high-throughput inference engines and numerically-precise training systems produce different probability distributions from the same parameters, creating a training-inference mismatch. We prove this mismatch has an ...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
