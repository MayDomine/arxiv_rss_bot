# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-12 05:57:17 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [GoodSpeed: Optimizing Fair Goodput with Adaptive Speculative Decoding in Distributed Edge Inference](https://arxiv.org/abs/2512.09963)

**Authors**: Phuong Tran, Tzu-Hao Liu, Long Tan Le, Tung-Anh Nguyen, Van Quan La, Eason Yu, Han Shu, Choong Seon Hong, Nguyen H. Tran  
**Category**: cs.DC  
**Published**: 2025-12-12  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2512.09963v1  

#### Abstract
Large language models (LLMs) have revolutionized natural language processing, yet their high computational demands pose significant challenges for real-time inference, especially in multi-user server speculative decoding and resource-constrained environments. Speculative decoding has emerged as a pr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**GooDSPEED: Optimizing Fair Goodput with Adaptive Speculative Decoding in Distributed Edge Inference**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **åˆ†å¸ƒå¼è¾¹ç¼˜æ¨ç†ä¸­çš„å»¶è¿Ÿä¸ååç“¶é¢ˆ**ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²é¢ä¸´é«˜å»¶è¿Ÿã€ä½ååçš„é—®é¢˜ã€‚
- **å¤šæœåŠ¡å™¨åä½œä¸‹çš„å…¬å¹³æ€§æŒ‘æˆ˜**ï¼šä¼ ç»Ÿ speculative decoding å¤šå‡è®¾å•ä¸€å®¢æˆ·ç«¯æˆ–ç†æƒ³åŒ–ç¯å¢ƒï¼Œå¿½è§†äº†å¤šä¸ªå¼‚æ„ draft server ä¹‹é—´çš„èµ„æºç«äº‰ä¸å…¬å¹³æ€§åˆ†é…ã€‚
- **åŠ¨æ€æç¤ºå¯¼è‡´çš„éå¹³ç¨³æ€§**ï¼šç”¨æˆ·è¾“å…¥ï¼ˆpromptsï¼‰å˜åŒ–é¢‘ç¹ï¼Œå¯¼è‡´ token æ¥å—ç‡ï¼ˆacceptance rateï¼‰æ³¢åŠ¨å¤§ï¼Œå½±å“ç³»ç»Ÿç¨³å®šæ€§ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šGooDSPEED
GooDSPEED æ˜¯ä¸€ä¸ªç”¨äºåˆ†å¸ƒå¼è¾¹ç¼˜æ¨ç†çš„æ–°å‹æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ˜¯ç»“åˆ **adaptive speculative decoding** ä¸ **gradient-based scheduling algorithm** æ¥ä¼˜åŒ– **goodput**ï¼ˆæœ‰æ•ˆæ¥å— token æ•°é‡/å•ä½æ—¶é—´ï¼‰ï¼ŒåŒæ—¶ä¿éšœè·¨æœåŠ¡å™¨çš„**å…¬å¹³æ€§**ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
1. **åˆ†å¸ƒå¼æ¶æ„è®¾è®¡**ï¼š
   - å¤šä¸ªè¾¹ç¼˜ç«¯çš„ draft server ä½¿ç”¨è½»é‡çº§ SLMsï¼ˆå¦‚ Qwen3-0.6Bï¼‰ç”Ÿæˆå€™é€‰ token åºåˆ—ï¼›
   - ä¸­å¤® verification server è¿è¡Œå¤§æ¨¡å‹ï¼ˆå¦‚ Llama3-70Bï¼‰å¹¶è¡ŒéªŒè¯è¿™äº›åºåˆ—ï¼Œå®ç°â€œå…ˆæ¨æµ‹åéªŒè¯â€æœºåˆ¶ã€‚

2. **æ¢¯åº¦è°ƒåº¦ç®—æ³•ï¼ˆGradient Scheduling Algorithmï¼‰**ï¼š
   - åŠ¨æ€è°ƒæ•´æ¯ä¸ª draft server åœ¨ä¸‹ä¸€å‘¨æœŸåº”ç”Ÿæˆçš„ speculative token æ•°é‡ $ S_i(t+1) $ï¼›
   - åŸºäºå¹³æ»‘ä¼°è®¡çš„ **token æ¥å—ç‡ $\hat{\alpha}_i(t)$** å’Œ **goodput $\hat{x}_i(t)$**ï¼Œæœ€å¤§åŒ–å¯¹æ•°æ•ˆç”¨å‡½æ•° $ U(x) = \sum \log x_i $ï¼Œç¡®ä¿**æ¯”ä¾‹å…¬å¹³æ€§**ï¼ˆproportional fairnessï¼‰ã€‚

3. **ç†è®ºæ”¶æ•›ä¿è¯**ï¼š
   - åˆ©ç”¨ fluid sample path åˆ†æè¯æ˜ï¼Œåœ¨ç¨³æ€ä¸‹ GooDSPEED æ”¶æ•›åˆ°æœ€ä¼˜ goodput åˆ†é…ï¼›
   - å³ä½¿åœ¨åŠ¨æ€è´Ÿè½½ä¸‹ï¼Œä¹Ÿèƒ½ä»¥æœ‰ç•Œè¯¯å·®ç»´æŒè¿‘ä¼¼æœ€ä¼˜æ€§èƒ½ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ DistServe, Sarathi-Serve, SpecInferï¼‰ | GooDSPEED |
|------|--------------------------------------------------|-----------|
| æ¶æ„æ¨¡å¼ | é›†ä¸­å¼æˆ–ç›¸ä½åˆ†ç¦» | è¾¹ç¼˜-ä¸­å¿ƒååŒï¼Œæ”¯æŒå¼‚æ„è®¾å¤‡ |
| èµ„æºè°ƒåº¦ | å›ºå®šæˆ–é™æ€æ‰¹å¤„ç† | åŠ¨æ€è‡ªé€‚åº”è°ƒåº¦ï¼Œå“åº”æ¥å—ç‡å˜åŒ– |
| å…¬å¹³æ€§ä¿éšœ | é€šå¸¸å¿½ç•¥æˆ–å¤šç”¨æˆ·ç«äº‰æ¿€çƒˆ | æ˜¾å¼ä¼˜åŒ–å¯¹æ•°æ•ˆç”¨ï¼Œä¿éšœå…¬å¹³ |
| å¯æ‰©å±•æ€§ | å—é™äºå•èŠ‚ç‚¹èƒ½åŠ› | å¹¶è¡Œç”Ÿæˆ + æ‰¹é‡éªŒè¯ï¼Œæ˜“äºæ¨ªå‘æ‰©å±• |
| éå¹³ç¨³é€‚åº”æ€§ | å¼±ï¼ˆä¾èµ–å†å²å¹³å‡ï¼‰ | å¼ºï¼ˆæŒ‡æ•°å¹³æ»‘ + å®æ—¶åé¦ˆï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
å®éªŒä½¿ç”¨äº† **8 ä¸ªå…¬å¼€æ•°æ®é›†**ï¼Œè¦†ç›–å¤šç§åº”ç”¨åœºæ™¯ï¼š
- **æŒ‡ä»¤å¾®è°ƒä¸å¯¹è¯**ï¼šAlpaca, Awesome-ChatGPT-Prompts
- **é•¿æ–‡æœ¬æ‘˜è¦**ï¼šCNN/DailyMail
- **æ¨ç†ä¸é—®ç­”**ï¼šOpenOrca, Chatbot Arena
- **æ•°å­¦è§£é¢˜**ï¼šGSM8K
- **Text-to-SQL**ï¼šSPIDER
- **é«˜éš¾åº¦é•¿å°¾æŸ¥è¯¢**ï¼šHLE

> æ¯ä¸ª draft server è¢«åˆ†é…ä¸åŒæ•°æ®é›†ï¼Œæ¨¡æ‹ŸçœŸå®å¼‚æ„è´Ÿè½½åœºæ™¯ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
| å‚æ•° | é…ç½® |
|------|------|
| **Verification Server** | NVIDIA H100 GPUï¼Œè¿è¡Œ Qwen3-14B æˆ– Llama3.1-70B-Instruct-AWQ-INT4 |
| **Draft Servers** | NVIDIA L4 GPUï¼Œè¿è¡Œ Qwen3 æˆ– Llama3 ç³»åˆ— SLMsï¼ˆ0.6Bâ€“3Bï¼‰ |
| **å®¢æˆ·ç«¯æ•°é‡** | 4 æˆ– 8 ä¸ª draft servers |
| **æœ€å¤§è¾“å‡ºé•¿åº¦** | 50 æˆ– 150 tokens |
| **Token é¢„ç®— $C$** | æ ¹æ®å†…å­˜ä¸å»¶è¿Ÿæƒè¡¡è®¾å®šä¸º {6, 16, 20, 24, 28} tokens |

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- **Goodput**ï¼šæ¯å•ä½æ—¶é—´æˆåŠŸæ¥å—çš„ token æ•°é‡ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰
- **End-to-end Latency**ï¼šä»è¯·æ±‚å‘å‡ºåˆ°å“åº”å®Œæˆçš„æ—¶é—´
- **Utility Function $U(x) = \sum \log x_i$**ï¼šè¡¡é‡ç³»ç»Ÿæ•´ä½“æ•ˆç‡ä¸å…¬å¹³æ€§çš„ç»¼åˆæŒ‡æ ‡
- **Wall Time Components**ï¼šç»†åˆ†ä¸ºæ¥æ”¶æ—¶é—´ã€éªŒè¯æ—¶é—´å’Œå‘é€æ—¶é—´
- **Convergence Behavior**ï¼šè§‚å¯Ÿæ•ˆç”¨å‡½æ•°éšè¿­ä»£æ¬¡æ•°çš„ç¨³å®šè¶‹åŠ¿

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **Fixed-S**ï¼šæ¯ä¸ª draft server å›ºå®šç”Ÿæˆ $ S_i = C/N $ ä¸ª token
2. **Random-S**ï¼šéšæœºåˆ†é… token æ•°é‡ï¼Œæ€»å’Œä¸è¶…è¿‡ $C$

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰Goodput ä¼°è®¡å‡†ç¡®æ€§ï¼ˆFigure 2ï¼‰
- GooDSPEED çš„å¹³æ»‘ä¼°è®¡ goodput æ›²çº¿ä¸å®é™…å€¼é«˜åº¦ä¸€è‡´ï¼ˆMAE < 5%ï¼‰ï¼›
- ä½¿ç”¨ç§»åŠ¨å¹³å‡æ»¤æ³¢åï¼Œæ ‡å‡†å·®è¾ƒå°ï¼Œè¡¨æ˜ä¼°è®¡ç¨³å®šå¯é ã€‚

#### ï¼ˆ2ï¼‰ç«¯åˆ°ç«¯å»¶è¿Ÿåˆ†è§£ï¼ˆFigure 3ï¼‰
- **GooDSPEED ä¸ Fixed-S æ€»ä½“ wall time ç›¸å½“**ï¼Œä¼˜äº Random-Sï¼ˆé«˜ 5â€“25%ï¼‰ï¼›
- **ä¼˜åŠ¿ä½“ç°åœ¨éªŒè¯é˜¶æ®µ**ï¼šGooDSPEED æ¯” Fixed-S å‡å°‘çº¦ **5% çš„éªŒè¯æ—¶é—´**ï¼Œè¯´æ˜è°ƒåº¦æ›´é«˜æ•ˆï¼›
- **æ¥æ”¶æ—¶é—´ç•¥é«˜**ï¼šå› å„ server ç”Ÿæˆé•¿åº¦å¯å˜ï¼Œéœ€ç­‰å¾…æœ€æ…¢è€…ï¼›ä½†å¯é€šè¿‡å¼‚æ­¥æœºåˆ¶ç¼“è§£ã€‚

#### ï¼ˆ3ï¼‰æ•ˆç”¨å‡½æ•°æ”¶æ•›æ€§ï¼ˆFigure 4ï¼‰
- åœ¨çº¦ **400â€“600 æ¬¡è¿­ä»£å†…æ”¶æ•›**ï¼›
- æœ€ç»ˆæ•ˆç”¨å€¼æ˜¾è‘—é«˜äº Fixed-S å’Œ Random-Sï¼ˆæå‡å¯è¾¾ 15â€“30%ï¼‰ï¼›
- æ”¯æŒç†è®ºåˆ†æä¸­å…³äºæ¸è¿‘æœ€ä¼˜æ€§çš„ç»“è®ºï¼ˆTheorem 1ï¼‰ã€‚

#### ï¼ˆ4ï¼‰ç³»ç»Ÿååæå‡
- åœ¨ Llama3-70B åœºæ™¯ä¸‹ï¼Œç›¸æ¯” baseline å®ç° **2â€“3Ã— çš„æ¨ç†åŠ é€Ÿ**ï¼›
- åŒç­‰ç¡¬ä»¶æ¡ä»¶ä¸‹ï¼Œgoodput æå‡è¾¾ **40% ä»¥ä¸Š**ã€‚

### ğŸ” æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»ä»¥ä¸‹æ–¹é¢å¯çœ‹å‡ºå…³é”®ç»„ä»¶ä½œç”¨ï¼š
- è‹¥å…³é—­å¹³æ»‘ä¼°è®¡ï¼ˆ$\beta=1$ï¼‰ï¼Œç³»ç»Ÿéœ‡è¡åŠ å‰§ï¼Œæ”¶æ•›å˜æ…¢ï¼›
- è‹¥ä¸é‡‡ç”¨æ¢¯åº¦è°ƒåº¦è€Œç”¨å›ºå®šåˆ†é…ï¼Œåˆ™æ•ˆç”¨å‡½æ•°æ— æ³•ä¸Šå‡è‡³æœ€ä¼˜ï¼›
- ä¸åŒ $C$ å€¼å½±å“æ˜¾è‘—ï¼šè¿‡å°é™åˆ¶å¹¶å‘æ½œåŠ›ï¼Œè¿‡å¤§å¢åŠ ä¼ è¾“å¼€é”€ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **GooDSPEED èƒ½æœ‰æ•ˆæå‡åˆ†å¸ƒå¼è¾¹ç¼˜ LLM æ¨ç†çš„ goodput å’Œå…¬å¹³æ€§**ï¼›
2. **åŸºäºæ¢¯åº¦çš„åŠ¨æ€è°ƒåº¦ç®—æ³•èƒ½è‡ªé€‚åº”éå¹³ç¨³ prompt æµé‡**ï¼ŒæŒç»­é€¼è¿‘ç†è®ºæœ€ä¼˜ï¼›
3. **ç†è®ºåˆ†æä¸å®è¯ç»“æœä¸€è‡´**ï¼šfluid model æˆåŠŸåˆ»ç”»ç³»ç»Ÿé•¿æœŸè¡Œä¸ºï¼Œæ”¯æŒæ”¶æ•›æ€§æ–­è¨€ï¼›
4. **è¾¹ç¼˜ä¾§ speculative generation + ä¸­å¿ƒä¾§å¹¶è¡ŒéªŒè¯** æ˜¯ä¸€ç§é«˜æ•ˆä¸”å¯æ‰©å±•çš„æ¶æ„èŒƒå¼ã€‚

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–å‡†ç¡®çš„ acceptance rate ä¼°è®¡**ï¼šè‹¥ prompt å˜åŒ–è¿‡äºå‰§çƒˆï¼ˆå¦‚é¢†åŸŸè·³è·ƒï¼‰ï¼ŒçŸ­æœŸä¼°è®¡å¯èƒ½åå·®è¾ƒå¤§ï¼›
2. **é€šä¿¡å¼€é”€ä»å­˜åœ¨**ï¼šå°½ç®¡ DSSD ç±»åè®®å¯å‹ç¼©åé¦ˆä¿¡å·ï¼Œä½†åœ¨å¹¿åŸŸç½‘ç¯å¢ƒä¸‹ä»æœ‰å»¶è¿Ÿé£é™©ï¼›
3. **å½“å‰å®éªŒå±€é™äºå±€åŸŸé›†ç¾¤**ï¼šå°šæœªæµ‹è¯•å¤§è§„æ¨¡åœ°ç†åˆ†å¸ƒåœºæ™¯ä¸‹çš„ç½‘ç»œæŠ–åŠ¨å½±å“ï¼›
4. **SLM ä¸ LLM å¯¹é½é—®é¢˜**ï¼šdraft model è‹¥ä¸ target model è¡Œä¸ºå·®å¼‚å¤§ï¼Œacceptance rate ä¸‹é™å°†å‰Šå¼±æ”¶ç›Šã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼•å…¥é¢„æµ‹æœºåˆ¶**ï¼šåˆ©ç”¨ prompt embedding é¢„æµ‹ acceptance rateï¼Œæå‰ä¼˜åŒ–è°ƒåº¦ï¼›
2. **å¼‚æ­¥è°ƒåº¦ä¸æµæ°´çº¿ä¼˜åŒ–**ï¼šå‡å°‘å› æœ€æ…¢ client å¯¼è‡´çš„ç­‰å¾…æ—¶é—´ï¼ˆtail latencyï¼‰ï¼›
3. **è·¨å±‚è”åˆä¼˜åŒ–**ï¼šç»“åˆé‡åŒ–ã€è’¸é¦ã€ç¼“å­˜ç­‰æŠ€æœ¯è¿›ä¸€æ­¥é™ä½è¾¹ç¼˜è®¡ç®—æˆæœ¬ï¼›
4. **æ”¯æŒæ›´å¤š speculative å½¢å¼**ï¼šå¦‚æ ‘çŠ¶æ¨æµ‹ï¼ˆtree-based speculationï¼‰ã€self-speculative æ¶æ„é›†æˆï¼›
5. **éƒ¨ç½²äºçœŸå®è¾¹ç¼˜ç½‘ç»œ**ï¼šåœ¨ 5G MEC æˆ– IoT è¾¹ç¼˜èŠ‚ç‚¹ä¸­è¿›è¡Œå®åœ°æµ‹è¯•ã€‚

---

## æ€»ç»“

> **GooDSPEED æå‡ºäº†ä¸€ç§é¢å‘åˆ†å¸ƒå¼è¾¹ç¼˜ LLM æ¨ç†çš„é«˜æ•ˆã€å…¬å¹³ã€è‡ªé€‚åº”çš„ speculative decoding æ¡†æ¶ã€‚é€šè¿‡æ¢¯åº¦è°ƒåº¦ç®—æ³•åŠ¨æ€åˆ†é… speculative token é•¿åº¦ï¼Œå¹¶ç»“åˆç†è®ºåˆ†æä¿è¯æ”¶æ•›æ€§ï¼Œå®éªŒè¡¨æ˜å…¶åœ¨å¤šç§çœŸå® workload ä¸‹æ˜¾è‘—ä¼˜äºå›ºå®šä¸éšæœºè°ƒåº¦ç­–ç•¥ï¼Œä¸ºæœªæ¥è¾¹ç¼˜æ™ºèƒ½æœåŠ¡æä¾›äº†å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚**

</details>

---

### 2. [Parallel Decoder Transformer: Model-Internal Parallel Decoding with Speculative Invariance via Note Conditioning](https://arxiv.org/abs/2512.10054)

**Authors**: Logan Robbins  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2512.10054v1  

#### Abstract
Autoregressive decoding in Large Language Models (LLMs) is inherently sequential, creating a latency bottleneck that scales linearly with output length. While ``Decomposition-and-Fill'' methods like Skeleton-of-Thought attempt to parallelize generation via external orchestration, they suffer from \t...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Parallel Decoder Transformer: Model-Internal Parallel Decoding with Speculative Invariance via Note Conditioning*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„**è‡ªå›å½’è§£ç è¿‡ç¨‹æœ¬è´¨ä¸Šæ˜¯ä¸²è¡Œçš„**ï¼Œå¯¼è‡´æ¨ç†å»¶è¿Ÿéšè¾“å‡ºé•¿åº¦çº¿æ€§å¢é•¿ï¼Œä¸¥é‡åˆ¶çº¦äº†å¤æ‚ä»»åŠ¡ï¼ˆå¦‚é•¿é“¾æ¨ç†ï¼‰çš„æ•ˆç‡ã€‚è™½ç„¶å·²æœ‰â€œåˆ†è§£-å¡«å……â€ç±»æ–¹æ³•ï¼ˆå¦‚Skeleton-of-Thought, SoTï¼‰å°è¯•é€šè¿‡å¤–éƒ¨å¹¶è¡ŒåŒ–æ¥åŠ é€Ÿç”Ÿæˆï¼Œä½†è¿™äº›æ–¹æ³•å°†æ¨¡å‹è§†ä¸ºé»‘ç®±ï¼Œ**ç¼ºä¹å¹¶è¡Œæµä¹‹é—´çš„é€šä¿¡æœºåˆ¶**ï¼Œå®¹æ˜“äº§ç”Ÿ**Coherence Driftï¼ˆä¸€è‡´æ€§æ¼‚ç§»ï¼‰**â€”â€”å³ä¸åŒæµç”Ÿæˆç›¸äº’çŸ›ç›¾æˆ–å†—ä½™çš„å†…å®¹ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **Parallel Decoder Transformer (PDT)**ï¼Œä¸€ç§å°†å¹¶è¡ŒåŒ–â€œå†…åµŒâ€åˆ°æ¨¡å‹å†…éƒ¨çš„æ–°å‹æ¶æ„ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **Speculative Note Conditioning (SNC)**ï¼šåœ¨å†»ç»“çš„é¢„è®­ç»ƒä¸»å¹²æ¨¡å‹ï¼ˆtrunkï¼‰ä¸Šï¼Œå¼•å…¥è½»é‡çº§é€‚é…å™¨ï¼ˆStream Adaptersï¼‰å’Œè·¨æ³¨æ„åŠ›æœºåˆ¶ï¼ˆSNCï¼‰ï¼Œä½¿å¤šä¸ªå¹¶è¡Œè§£ç æµå¯ä»¥é€šè¿‡ä¸€ä¸ªå…±äº«çš„åŠ¨æ€æ½œåœ¨ç©ºé—´â€”â€”**Note Bus** è¿›è¡Œåè°ƒã€‚
- **è¯­ä¹‰ç¬”è®°å¹¿æ’­ä¸éªŒè¯æœºåˆ¶**ï¼šæ¯ä¸ªæµå¯å‘å…¨å±€æ€»çº¿å†™å…¥å‹ç¼©çš„è¯­ä¹‰æ‘˜è¦ï¼ˆnotesï¼‰ï¼Œå…¶ä»–æµé€šè¿‡ SNC æ³¨æ„åŠ›è¯»å–è¿™äº›ç¬”è®°ï¼›åŒæ—¶å¼•å…¥ **Agreement Head** é¢„æµ‹ç”Ÿæˆå†…å®¹ä¸é¢„æœŸè¯­ä¹‰çš„ä¸€è‡´æ€§ï¼Œè‹¥ä½äºé˜ˆå€¼åˆ™è§¦å‘ **Rollbackï¼ˆå›æ»šï¼‰**ï¼Œå¼ºåˆ¶é‡æ–°ç”Ÿæˆä»¥çº æ­£åå·®ã€‚
- **å‚æ•°é«˜æ•ˆè®­ç»ƒç­–ç•¥ï¼ˆParameter-Efficient Trainingï¼‰**ï¼šæ•´ä¸ª 20B å‚æ•°çš„ä¸»å¹²æ¨¡å‹ä¿æŒå†»ç»“ï¼Œä»…è®­ç»ƒå æ€»å‚æ•°é‡ä¸åˆ° 5% çš„é€‚é…å™¨æ¨¡å—ï¼ˆåŒ…æ‹¬ Stream Adaptersã€SNC Headsã€Coverage/Agreement Headsï¼‰ï¼Œæ˜¾è‘—é™ä½è®­ç»ƒæˆæœ¬ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | Skeleton-of-Thought (SoT) ç­‰å¤–éƒ¨å¹¶è¡ŒåŒ– | PDTï¼ˆæœ¬æ–‡æ–¹æ³•ï¼‰ |
|------|----------------------------------------|----------------|
| å¹¶è¡Œç²’åº¦ | Prompt-levelï¼ˆæç¤ºçº§ï¼‰ | Prompt-level + Token-level å†…éƒ¨åè°ƒ |
| æµé—´é€šä¿¡ | âŒ æ— ï¼Œæ˜“å‡ºç° Coherence Drift | âœ… æœ‰ï¼Œé€šè¿‡ Note Bus åŒæ­¥è¯­ä¹‰ |
| æ¨¡å‹ä¿®æ”¹ | ä¸ä¿®æ”¹æ¨¡å‹æƒé‡ | ä»…æ·»åŠ è½»é‡çº§é€‚é…å™¨ï¼Œä¸»å¹²å†»ç»“ |
| æ¨ç†ä¸€è‡´æ€§ | ä½ï¼Œä¾èµ–æç¤ºå·¥ç¨‹ | é«˜ï¼Œå…·å¤‡è‡ªæˆ‘çº é”™èƒ½åŠ› |
| å¯æ‰©å±•æ€§ | æ˜“éƒ¨ç½²ä½†éš¾ä»¥æ§åˆ¶è´¨é‡ | æ”¯æŒå¤§è§„æ¨¡æ¨¡å‹ä¸Šçš„é«˜æ•ˆåè°ƒ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šPDT åœ¨ä¸ä¿®æ”¹åŸå§‹å¤§æ¨¡å‹çš„å‰æä¸‹ï¼Œå®ç°äº†**é«˜å¹¶å‘ä¸‹çš„è¯­ä¹‰ä¸€è‡´æ€§ä¿éšœ**ï¼Œå…¼å…· SoT çš„å¹¶è¡Œé€Ÿåº¦å’Œä¼ ç»Ÿä¸²è¡Œç”Ÿæˆçš„è¿è´¯æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- æ„å»ºäº†ä¸€ä¸ªåŒ…å« **10,000 ä¸ªå¤šæ®µè½æ¨ç†ä»»åŠ¡**çš„æ•°æ®é›†ï¼Œç”± GPT-4 è’¸é¦ç”Ÿæˆã€‚
- æ¯ä¸ªæ ·æœ¬åŒ…å«ï¼š
  - **Teacher Plan**ï¼šæ ‡å‡†çš„ä»»åŠ¡åˆ†è§£è®¡åˆ’ï¼›
  - **Notes Contract**ï¼šç»“æ„åŒ–çš„è¯­ä¹‰æ‰¿è¯ºé›†åˆï¼Œç”¨äºç›‘ç£å¹¶è¡Œæµæ˜¯å¦å®ŒæˆæŒ‡å®šå­ç›®æ ‡ã€‚

### **å®éªŒè®¾ç½®**

- **ä¸»å¹²æ¨¡å‹**ï¼šå†»ç»“çš„ **20B å‚æ•° GPT-OSS** æ¨¡å‹ã€‚
- **ç¡¬ä»¶å¹³å°**ï¼š8Ã—NVIDIA B200 GPUï¼ˆæ¯å¡ 180GB VRAMï¼‰ã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - å…¨å±€ batch size ä¸º 16ï¼ˆmicro-batch 1ï¼‰ï¼›
  - ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆgradient checkpointingï¼‰ï¼›
  - é‡‡ç”¨åˆ†é˜¶æ®µè¯¾ç¨‹å­¦ä¹ ï¼ˆcurriculum learningï¼‰é€æ­¥è§£é”æ¨¡å—ã€‚
- **è®­ç»ƒé˜¶æ®µ**ï¼ˆå…± 50,000 æ­¥ï¼‰ï¼š
  1. **Stage 0**: é¢„è®­ç»ƒ Planner å’Œ Notes Headï¼›
  2. **Stage 1**: è§£é” Stream Adaptersï¼Œç‹¬ç«‹æ¡ä»¶ç”Ÿæˆï¼›
  3. **Stage 2**: å¯ç”¨ SNC æœºåˆ¶ï¼Œå¼€å§‹è·¨æµé€šä¿¡ï¼›
  4. **Stage 3**: è§£é” Coverage å’Œ Agreement Headsï¼Œå®ç°è‡ªçº é”™ä¸å›æ»šã€‚

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | å®šä¹‰ | ç›®æ ‡ |
|------|------|------|
| **Coverage Precision** | å½“ç³»ç»Ÿæ ‡è®°æŸé¡¹è®¡åˆ’â€œå·²è¦†ç›–â€æ—¶ï¼Œå®é™…æ­£ç¡®çš„æ¯”ä¾‹ | è¶Šé«˜è¶Šå¥½ï¼ˆåæ˜ å¯é æ€§ï¼‰ |
| **Coverage Recall** | æ‰€æœ‰åº”è¢«è¦†ç›–çš„é¡¹ç›®ä¸­ï¼Œç³»ç»ŸæˆåŠŸè¯†åˆ«çš„æ¯”ä¾‹ | è¡¡é‡å®Œæ•´æ€§ |
| **Validation Loss** | éªŒè¯é›†ä¸Šçš„æŸå¤±å€¼ | è¶Šä½è¶Šå¥½ |
| **Rollback Rate** | è§¦å‘å›æ»šæ“ä½œçš„é¢‘ç‡ | åæ˜ ç¨³å®šæ€§ä¸çº é”™èƒ½åŠ› |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- ä¸»è¦å¯¹æ¯”å¯¹è±¡ä¸º **Skeleton-of-Thought (SoT)** ç±»å¤–éƒ¨å¹¶è¡Œæ–¹æ³•ã€‚
- å¼ºè°ƒ PDT ä¸ä¸ token-level speculative decodingï¼ˆå¦‚ Medusaã€Eagleï¼‰ç›´æ¥ç«äº‰ï¼Œè€Œæ˜¯è§£å†³æ›´é«˜å±‚æ¬¡çš„è¯­ä¹‰åè°ƒé—®é¢˜ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| **Coverage Precision** | **77.8%** | æœ€ç»ˆé˜¶æ®µè¾¾åˆ°çš„ç²¾åº¦ï¼Œè¡¨æ˜ç³»ç»Ÿå¯¹â€œå·²å®Œæˆâ€çš„åˆ¤æ–­é«˜åº¦å¯ä¿¡ |
| **Coverage Recall** | 4.91% | è¾ƒä½ï¼Œè¯´æ˜æ¨¡å‹é‡‡å–ä¿å®ˆç­–ç•¥ï¼Œå®å¯æ¼åˆ¤ä¹Ÿä¸è¯¯åˆ¤ |
| **Validation Loss** | 0.00 | åœ¨éªŒè¯é›†ä¸Šå®Œå…¨æ”¶æ•› |
| **å‚æ•°æ•ˆç‡** | <5% å¯è®­ç»ƒå‚æ•° | ä¸»å¹²å†»ç»“ï¼Œä»…è®­ç»ƒé€‚é…å™¨ |

> ğŸ“ˆ å›¾1æ˜¾ç¤ºï¼Œåœ¨ç¬¬ 20,000 æ­¥å·¦å³å‡ºç°æ˜æ˜¾çš„â€œç›¸å˜â€ï¼Œloss æ€¥å‰§ä¸‹é™ï¼Œæ ‡å¿—ç€è·¨æµåè°ƒæœºåˆ¶å¼€å§‹ç”Ÿæ•ˆã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **ç›¸è¾ƒäº SoT**ï¼š
  - PDT æ˜¾è‘—å‡å°‘äº† **Coherence Drift** å’Œå†…å®¹å†²çªï¼›
  - ç”Ÿæˆç»“æœæ›´ç¬¦åˆåŸå§‹ä»»åŠ¡ç»“æ„ï¼ˆplan adherenceï¼‰ï¼›
  - å°½ç®¡ Recall è¾ƒä½ï¼Œä½† **Precision æ›´é«˜**ï¼Œæ›´é€‚åˆéœ€è¦é«˜å¯é æ€§çš„åœºæ™¯ã€‚

### **æ¶ˆèå®éªŒç»“æœ**

å°½ç®¡æ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºè¡¨æ ¼å½¢å¼çš„æ¶ˆèå®éªŒï¼Œä½†ä»è®­ç»ƒé˜¶æ®µåˆ†æå¯å¾—ä»¥ä¸‹ç»“è®ºï¼š

- **Stage 0â€“1ï¼ˆæ— é€šä¿¡ï¼‰**ï¼šæ— æ³•å½¢æˆæœ‰æ•ˆåè°ƒï¼Œloss é«˜ä¸”æ³¢åŠ¨å¤§ï¼›
- **Stage 2ï¼ˆå¯ç”¨ SNCï¼‰**ï¼šloss å¼€å§‹ä¸‹é™ï¼Œè¡¨æ˜è·¨æµæ³¨æ„åŠ›èµ·ä½œç”¨ï¼›
- **Stage 3ï¼ˆåŠ å…¥ Agreement Head + Rollbackï¼‰**ï¼šloss è¿›ä¸€æ­¥ç¨³å®šè‡³ ~0.2ï¼Œprecision æå‡è‡³ 77.8%ï¼Œè¯æ˜ **self-correction æœºåˆ¶è‡³å…³é‡è¦**ã€‚

æ­¤å¤–ï¼Œé™„å½• E ä¸­çš„æ¨¡æ‹Ÿå®éªŒè¯æ˜ï¼š
- **é”™è¯¯èšé›†ï¼ˆclustered errorsï¼‰åè€Œé™ä½å›æ»šç‡**ï¼šå½“é”™è¯¯é›†ä¸­çˆ†å‘æ—¶ï¼Œç³»ç»Ÿèƒ½é€šè¿‡ä¸€æ¬¡å›æ»šä¿®å¤å¤šä¸ªè¿ç»­é”™è¯¯ï¼Œæå‡æ•´ä½“æ•ˆç‡ã€‚
- ç¤ºä¾‹ï¼š`L=32`, `q_token=0.0033` ä¸‹ï¼Œç›¸å…³æ€§ `Ï=0.5` ä½¿ stride failure rate ä» 9.87% é™è‡³ 5.45%ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **æ— éœ€å…¨æ¨¡å‹å¾®è°ƒå³å¯å®ç°è¯­ä¹‰åŒæ­¥**ï¼šé€šè¿‡è½»é‡çº§ SNC é€‚é…å™¨ï¼Œå¯åœ¨å†»ç»“çš„ 20B æ¨¡å‹ä¸Šå®ç°å¤šæµè¯­ä¹‰åè°ƒï¼ŒéªŒè¯äº† **Parameter-Efficient Coordination** çš„å¯è¡Œæ€§ã€‚
2. âœ… **Speculative Invariance æœºåˆ¶æœ‰æ•ˆ**ï¼šAgreement Head èƒ½å‡†ç¡®æ£€æµ‹è¯­ä¹‰åç¦»ï¼Œå¹¶é€šè¿‡ Rollback å®ç°è‡ªæˆ‘ä¿®æ­£ï¼Œé¿å… Coherence Driftã€‚
3. âœ… **å­˜åœ¨â€œMemory Cliffâ€ç°è±¡**ï¼šå…¨æ¨¡å‹å¾®è°ƒä¼šå¯¼è‡´æ˜¾å­˜éœ€æ±‚æ¿€å¢ï¼ˆ>290GB/deviceï¼‰ï¼Œè¿œè¶… B200 çš„ 180GBï¼Œ**å‚æ•°é«˜æ•ˆè®¾è®¡ä¸ä»…æ˜¯ä¼˜åŒ–ï¼Œæ›´æ˜¯éƒ¨ç½²å¿…éœ€**ã€‚
4. âœ… **ä¿å®ˆç­–ç•¥ä¼˜äºæ¿€è¿›è¦†ç›–**ï¼šä½ Recall + é«˜ Precision çš„ç»„åˆæå‡äº†ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯ç”¨æ€§ï¼Œç¬¦åˆ selective prediction çš„è®¾è®¡ç†å¿µã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- **é™æ€æµæ•°é‡**ï¼šå½“å‰ K ä¸ªæµçš„æ•°é‡å›ºå®šï¼Œæ— æ³•æ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€è°ƒæ•´ã€‚
- **Note Bus å¯æ‰©å±•æ€§æœ‰é™**ï¼šç›®å‰é‡‡ç”¨å…¨è¿æ¥å…±äº«æ€»çº¿ï¼ŒåŒæ­¥å¼€é”€éšæµæ•°çº¿æ€§å¢é•¿ï¼Œ**N > 6 æ—¶æ”¶ç›Šé€’å‡**ã€‚
- **ä¾èµ–é«˜è´¨é‡ Notes Contract**ï¼šè®­ç»ƒéœ€äººå·¥æ„é€ æˆ–è’¸é¦çš„è¯­ä¹‰å¥‘çº¦ï¼Œè‡ªåŠ¨åŒ–æ„å»ºä»å…·æŒ‘æˆ˜ã€‚
- **æ¨ç†å»¶è¿Ÿå¢åŠ **ï¼šSNC æ³¨æ„åŠ›å’Œå›æ»šæœºåˆ¶å¸¦æ¥é¢å¤–è®¡ç®—å¼€é”€ï¼Œå°šæœªå®Œå…¨é€¼è¿‘ç†æƒ³å¹¶è¡ŒåŠ é€Ÿæ¯”ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **Dynamic Stream Allocation**ï¼šPlanner Head åŠ¨æ€å†³å®šå¹¶è¡Œæµæ•°é‡ã€‚
2. **Hierarchical Note Schemas**ï¼šæ”¯æŒåµŒå¥—å‘½åç©ºé—´ï¼Œå®ç°é€’å½’ä»»åŠ¡åˆ†è§£ã€‚
3. **Hardware-Aware Attention Kernels**ï¼šä¼˜åŒ– SNC æ³¨æ„åŠ›å†…æ ¸ï¼Œå‡å°‘â€œNote Readâ€å¼€é”€ã€‚
4. **Security Analysis**ï¼šç ”ç©¶ç±»ä¼¼ speculative execution çš„ä¾§ä¿¡é“æ”»å‡»é£é™©ï¼ˆå¦‚ä¿¡æ¯æ³„éœ²ï¼‰ã€‚
5. **æ›´é«˜æ•ˆçš„å†…å­˜ç®¡ç†**ï¼šç»“åˆ KV-cache å‹ç¼©æŠ€æœ¯ï¼ˆå¦‚ ChunkKVã€ZsMergeï¼‰è¿›ä¸€æ­¥é™ä½å†…å­˜å‹åŠ›ã€‚

---

## ğŸ”š æ€»ç»“

**PDT æ˜¯é¦–ä¸ªå°†â€œåˆ†è§£-å¡«å……â€èŒƒå¼å†…åŒ–ä¸ºæ¨¡å‹å†…éƒ¨æœºåˆ¶çš„å·¥ä½œ**ï¼Œé€šè¿‡ **Speculative Note Conditioning (SNC)** åœ¨å†»ç»“çš„å¤§æ¨¡å‹ä¸Šå®ç°äº†é«˜æ•ˆã€ä¸€è‡´çš„å¹¶è¡Œè§£ç ã€‚å…¶å®éªŒéªŒè¯äº†ï¼š

> â€œ**Semantic coordination can be learned without modifying trunk weights.**â€

è¯¥å·¥ä½œä¸ä»…æä¾›äº†ä¸€ç§å®ç”¨çš„å¹¶è¡Œæ¨ç†æ¶æ„ï¼Œä¹Ÿä¸ºæœªæ¥æ„å»º **principled, parallel model-internal reasoning systems** å¥ å®šäº†åŸºç¡€ã€‚ä»£ç ã€æ•°æ®é›†ä¸è®­ç»ƒæƒé‡å‡å·²å¼€æºï¼Œæœ‰æœ›æ¨åŠ¨ LLM æ¨ç†ä»â€œä¸²è¡Œç”Ÿæˆâ€è¿ˆå‘â€œç»“æ„åŒ–å¹¶è¡Œæ€è€ƒâ€ã€‚

</details>

---

### 3. [Design Space Exploration of DMA based Finer-Grain Compute Communication Overlap](https://arxiv.org/abs/2512.10236)

**Authors**: Shagnik Pal, Shaizeen Aga, Suchita Pati, Mahzabeen Islam, Lizy K. John  
**Category**: cs.DC  
**Published**: 2025-12-12  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2512.10236v1  

#### Abstract
As both ML training and inference are increasingly distributed, parallelization techniques that shard (divide) ML model across GPUs of a distributed system, are often deployed. With such techniques, there is a high prevalence of data-dependent communication and computation operations where communica...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDesign Space Exploration of DMA based Finer-Grain Compute Communication Overlap

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨å¤§è§„æ¨¡åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰è®­ç»ƒå’Œæ¨ç†ä¸­ï¼Œ**é€šä¿¡ä¸è®¡ç®—çš„ä¾èµ–å…³ç³»**å¯¼è‡´é€šä¿¡æ“ä½œæš´éœ²åœ¨å…³é”®è·¯å¾„ä¸Šï¼Œæ— æ³•è¢«æœ‰æ•ˆéšè—ã€‚å°¤å…¶æ˜¯åœ¨ **tensor-sequence parallelism** å’Œ **context-parallelism** ç­‰åœºæ™¯ä¸‹ï¼Œé€šä¿¡ç›´æ¥é©±åŠ¨åç»­è®¡ç®—ï¼Œé€ æˆé«˜è¾¾ **1.7Ã— çš„ç†æƒ³æ€§èƒ½æŸå¤±**ã€‚

ä¼ ç»Ÿçš„ **shard-level compute-communication overlap** æ–¹æ³•è™½ç„¶èƒ½åœ¨ä¸€å®šç¨‹åº¦ä¸Šé‡å é€šä¿¡ä¸è®¡ç®—ï¼Œä½†åœ¨ **direct-connection based GPU ç½‘ç»œæ‹“æ‰‘**ï¼ˆå¦‚ AMD Instinct MI300Xï¼‰ä¸­è¡¨ç°ä¸ä½³ï¼Œå› ä¸ºå…¶ä¾èµ– **peer-to-peer (P2P)** é€šä¿¡æ¨¡å¼ï¼Œå¯¼è‡´å¤§é‡ç½‘ç»œé“¾è·¯ç©ºé—²ï¼Œåˆ©ç”¨ç‡ä½ä¸‹ã€‚

æ­¤å¤–ï¼Œç»†ç²’åº¦æ“ä½œåˆ†è§£ä¼šå¼•å…¥ **operation-level inefficiencies**ï¼Œå¦‚èµ„æºåˆ©ç”¨ç‡ä¸‹é™ã€å†…å­˜äº‰ç”¨ç­‰ï¼Œå½±å“æ•´ä½“æ€§èƒ½æå‡ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šFiCCO
æœ¬æ–‡æå‡º **FiCCO**ï¼ˆ**Finer-Grain Compute-Communication Overlap**ï¼‰ï¼Œä¸€ç§åŸºäº **DMA offload** çš„æ›´ç»†ç²’åº¦é€šä¿¡-è®¡ç®—é‡å æœºåˆ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- å°†é€šä¿¡æ“ä½œè¿›ä¸€æ­¥åˆ†è§£ä¸º **æ¯” shard-level æ›´ç»†ä¸€çº§çš„ç²’åº¦**ï¼ˆä¾‹å¦‚ï¼Œåœ¨ 8-GPU ç³»ç»Ÿä¸­ï¼Œä¼ è¾“å¤§å°ç¼©å°è‡³åŸæ¥çš„ 1/8ï¼‰ã€‚
- åˆ©ç”¨è¿™ç§ç»†ç²’åº¦åˆ†è§£å®ç° **all-to-all (A2A)** é€šä¿¡æ¨¡å¼ï¼Œè€Œéä¼ ç»Ÿ shard-based æ–¹æ³•ä¸­çš„ **P2P** æ¨¡å¼ã€‚
- ç»“åˆ **GPU DMA engines** æ¥å¸è½½é€šä¿¡ä»»åŠ¡ï¼Œå‡å°‘å¯¹ GPU cores å’Œ cache çš„äº‰ç”¨ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿ shard-based overlap | æœ¬æ–‡ FiCCO |
|------|--------------------------|-----------|
| **é€šä¿¡æ¨¡å¼** | Peer-to-Peer (P2P) | All-to-All (A2A) |
| **ç½‘ç»œåˆ©ç”¨ç‡** | åœ¨ direct-connect æ‹“æ‰‘ä¸­ä½ï¼ˆæœ€é«˜ **3.9Ã— æ€§èƒ½ä¸‹é™**ï¼‰ | é«˜ï¼Œå……åˆ†åˆ©ç”¨å…¨è¿æ¥å¸¦å®½ |
| **æ•°æ®æµç²’åº¦** | å›ºå®šäº shard ç²’åº¦ | æ”¯æŒæ›´ç»†ç²’åº¦ï¼Œåˆ©äº pipeline åç»­é˜¶æ®µ |
| **é€šä¿¡ä¸å¯¹ç§°å®¹å¿** | å·®ï¼ˆå¦‚ MoE ä¸­ token æ•°ä¸å‡ï¼‰ | æ›´å¥½ï¼Œå¯é€šè¿‡è°ƒåº¦ä¼˜åŒ– |
| **èµ„æºäº‰ç”¨æ§åˆ¶** | é€šå¸¸ä½¿ç”¨ GPU core æ‰§è¡Œé€šä¿¡ | ä½¿ç”¨ **DMA engines** å¸è½½é€šä¿¡ï¼Œæ˜¾è‘—é™ä½ contention |
| **è®¾è®¡ç©ºé—´** | æœ‰é™ | å¼€æ”¾äº†ä¸°å¯Œçš„è°ƒåº¦è®¾è®¡ç©ºé—´ï¼ˆuniform/fused/unfused/1D/2Dï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸åœºæ™¯
å®éªŒåŸºäºçœŸå®ä¸–ç•Œçš„å¤§è§„æ¨¡ ML éƒ¨ç½²åœºæ™¯ï¼Œé‡ç‚¹å…³æ³¨ä»¥ä¸‹ä¸¤ç±»å…¸å‹ workloadï¼š

- **Tensor-Sequence Parallelism**ï¼šæ¨¡å‹æƒé‡åˆ†ç‰‡ï¼Œæ¿€æ´»å€¼é€šè¿‡ all-gather èšåˆã€‚
- **Expert Parallelism (EP)**ï¼šç”¨äº MoE æ¶æ„ï¼Œè¾“å…¥ token é€šè¿‡ all-to-all åˆ†å‘åˆ°ä¸åŒä¸“å®¶ã€‚

å…·ä½“ GEMM æ“ä½œæ¥è‡ªï¼š
- **Llama-2-70B**, **Llama-3-405B**
- **DeepSeek**, **Mixtral**

å…±ç ”ç©¶äº† **16 ä¸ªçœŸå® GEMM åœºæ™¯**ï¼ˆè§ Table Iï¼‰ï¼Œæ¶µç›–ä¸åŒ M/N/K ç»„åˆã€‚

---

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šAMD MI300X Infinity Platformï¼Œ8Ã— MI300X GPUï¼Œå…¨è¿æ¥æ‹“æ‰‘ï¼Œæ¯æ¡ link å¸¦å®½ 64 GB/sã€‚
- **è½¯ä»¶æ ˆ**ï¼š
  - æ¡†æ¶ï¼šPyTorch
  - GEMM åº“ï¼šROCm hipblaslt
  - é€šä¿¡åº“ï¼šRCCLï¼ˆç”¨äºå¯¹æ¯”ï¼‰æˆ– **DMA-based hipMemcpyDtoDAsync**
  - å†…å­˜ï¼šä½¿ç”¨ symmetric memory é¿å…ä¸­é—´æ‹·è´
  - å¹¶å‘ï¼šå¤š GPU stream å®ç°å¹¶å‘æ‰§è¡Œ
- **æµ‹é‡æ–¹å¼**ï¼š10 æ¬¡é¢„çƒ­ + 5 æ¬¡æµ‹é‡å–å¹³å‡

---

### è¯„ä¼°æŒ‡æ ‡
- **Speedup**ï¼šç›¸å¯¹äº baseline ä¸²è¡Œæ‰§è¡Œçš„åŠ é€Ÿæ¯”
- **Ideal Speedup**ï¼šå‡è®¾æ—  decomposition å’Œ contention å¼€é”€çš„ç†æƒ³åŠ é€Ÿæ¯”
- **DIL (Decomposition Inefficiency Loss)**ï¼šå› æ“ä½œåˆ†è§£å¯¼è‡´çš„æ€§èƒ½æŸå¤±
- **CIL (Contention Inefficiency Loss)**ï¼šå› é€šä¿¡ä¸è®¡ç®—å¹¶å‘å¯¼è‡´çš„èµ„æºäº‰ç”¨æŸå¤±
- **Heuristic å‡†ç¡®ç‡**ï¼šé¢„æµ‹æœ€ä¼˜è°ƒåº¦çš„å‡†ç¡®ç‡

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**ï¼šä¸²è¡Œæ‰§è¡Œï¼ˆå…ˆ all-gatherï¼Œå† GEMMï¼‰
- **Shard-based overlap**ï¼šç±»ä¼¼ PyTorch AsyncTPï¼ŒP2P é€šä¿¡ + shard-level é‡å 
- **FiCCO-rccl**ï¼šFiCCO ä½¿ç”¨ RCCLï¼ˆGPU core é©±åŠ¨é€šä¿¡ï¼‰
- **FiCCO-1D / FiCCO-2D**ï¼šæœ¬æ–‡æå‡ºçš„ DMA å¸è½½ + ç»†ç²’åº¦é‡å è°ƒåº¦

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **FiCCO æœ€é«˜å¯è¾¾ 1.6Ã— speedup**ï¼ˆ1D è°ƒåº¦ï¼‰
- **æ¨¡æ‹Ÿ 2D è°ƒåº¦ä¸‹å¯è¾¾ 1.7Ã— speedup**
- ç›¸æ¯” shard-based overlapï¼Œæ€§èƒ½æå‡æ˜¾è‘—ï¼Œå°¤å…¶åœ¨é€šä¿¡å¯†é›†å‹åœºæ™¯
- åœ¨ direct-connect æ‹“æ‰‘ä¸­ï¼Œshard-based æ–¹æ³•ç”šè‡³å‡ºç° **è´ŸåŠ é€Ÿ**ï¼ˆæœ€é«˜ **3.9Ã— æ…¢äºä¸²è¡Œ**ï¼‰ï¼Œè€Œ FiCCO ä¿æŒæ­£å‘åŠ é€Ÿ

---

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | Geomean Speedup | æ¥è¿‘ Ideal (%) | å¤‡æ³¨ |
|------|------------------|----------------|------|
| **Baseline** | 1.0Ã— | â€” | ä¸²è¡Œæ‰§è¡Œ |
| **Shard-based overlap** | <1.0Ã— | â€” | åœ¨ direct-connect ä¸Šæ€§èƒ½é€€åŒ– |
| **FiCCO-rccl** | ~1.3Ã— | ~46â€“52% | GPU core é€šä¿¡ï¼Œå­˜åœ¨ contention |
| **FiCCO-1D (DMA)** | **1.6Ã—** | **52â€“76%** | DMA å¸è½½ï¼Œæ˜¾è‘—é™ä½ CIL |
| **FiCCO-2D (emulated)** | **1.7Ã—** | **~76%** | æ›´ä¼˜é€šä¿¡å½¢çŠ¶ï¼Œæ½œåŠ›æ›´å¤§ |

> æ³¨ï¼šç†æƒ³åŠ é€Ÿå—é™äº DIL å’Œ CILï¼Œè°ƒæ•´åå¯è¾¾ç†æƒ³æ€§èƒ½çš„ 52â€“76%

---

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰DIL åˆ†æ
- **64-way åˆ†è§£** çš„ GEMM DIL æ˜¾è‘—é«˜äº 8-way
- DIL ä¸ **op-to-byte ratio (OTB)** è´Ÿç›¸å…³ï¼šOTB è¶Šä½ï¼ŒDIL è¶Šä¸¥é‡
- è¡Œåˆ†ç‰‡ï¼ˆrow-shardingï¼‰ vs åˆ—åˆ†ç‰‡ï¼ˆcol-shardingï¼‰çš„ DIL å–å†³äº M å’Œ K çš„ç›¸å¯¹å¤§å°

#### ï¼ˆ2ï¼‰CIL åˆ†æ
- **DMA-based é€šä¿¡** çš„ CIL æ˜¾è‘—ä½äº RCCLï¼ˆGPU core é©±åŠ¨ï¼‰
- CIL ä¸ **GEMM memory traffic (MT)** æ­£ç›¸å…³ï¼šMT è¶Šå¤§ï¼Œå†…å­˜å­ç³»ç»Ÿäº‰ç”¨è¶Šä¸¥é‡
- FiCCO çš„ CIL geomean ä¸º **1.11Ã—**ï¼Œshard-based ä¸º **1.07Ã—**ï¼ˆç•¥ä½ï¼Œä½†å—é™äºæ‹“æ‰‘ï¼‰

#### ï¼ˆ3ï¼‰Heuristic æœ‰æ•ˆæ€§
- åœ¨ **16 ä¸ªæœªè§è¿‡çš„åˆæˆåœºæ™¯** ä¸­ï¼Œæ‰€æ heuristic **å‡†ç¡®é¢„æµ‹æœ€ä¼˜è°ƒåº¦çš„æ¯”ä¾‹è¾¾ 81%**
- é”™è¯¯é¢„æµ‹æ—¶ï¼Œæ€§èƒ½æŸå¤±å¹³å‡çº¦ **14%**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **shard-level overlap åœ¨ direct-connect æ‹“æ‰‘ä¸­å¤±æ•ˆ**ï¼šP2P é€šä¿¡æ— æ³•å……åˆ†åˆ©ç”¨å…¨è¿æ¥å¸¦å®½ï¼Œå¯¼è‡´æ€§èƒ½ä¸¥é‡ä¸‹é™ã€‚
2. **FiCCO é€šè¿‡æ›´ç»†ç²’åº¦åˆ†è§£å®ç° all-to-all é€šä¿¡**ï¼Œæ˜¾è‘—æå‡ç½‘ç»œåˆ©ç”¨ç‡ï¼Œå°¤å…¶é€‚åˆç°ä»£å…¨è¿æ¥ GPU é›†ç¾¤ã€‚
3. **DMA offload æ˜¯é™ä½ contention çš„å…³é”®**ï¼šæ¶ˆé™¤ compute interferenceï¼Œç¼“è§£ cache å’Œ memory contentionã€‚
4. **æ“ä½œåˆ†è§£å¸¦æ¥ DIL å’Œ CIL çš„æƒè¡¡**ï¼š
   - DIL ä¸»è¦å— OTB å½±å“
   - CIL ä¸»è¦å— MT å’Œå¹¶å‘åº¦å½±å“
5. **å¯æ„å»ºåŸºäº OTB å’Œ MT çš„ heuristic**ï¼ŒæŒ‡å¯¼ runtime é€‰æ‹©æœ€ä¼˜ FiCCO è°ƒåº¦ç­–ç•¥ï¼Œå‡†ç¡®ç‡è¾¾ 81%ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ **2D memory copy ä¸æ”¯æŒ DMA**ï¼Œéœ€æ¨¡æ‹Ÿï¼Œé™åˆ¶äº† 2D è°ƒåº¦çš„å®é™…æ€§èƒ½ã€‚
- **CPU kernel launch overhead** åœ¨æå°æ“ä½œæ—¶å¯èƒ½æˆä¸ºç“¶é¢ˆï¼ˆä½†å¯é€šè¿‡ graph-based launch ç¼“è§£ï¼‰ã€‚
- æœªæ”¯æŒ **reduce-scatter with arithmetic** ç±»æ“ä½œï¼ˆå›  DMA ä¸æ”¯æŒæ•°å­¦è¿ç®—ï¼‰ã€‚
- æ‰€æœ‰åˆ†æåŸºäºé™æ€ GEMM ç‰¹å¾ï¼ŒåŠ¨æ€ workload ä¸‹éœ€åœ¨çº¿è°ƒä¼˜ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ”¯æŒ **DMA ä¸Šçš„ fused communication-compute æ“ä½œ**ï¼ˆå¦‚ reduce-scatter with GEMMï¼‰
- æ¢ç´¢ **runtime è‡ªé€‚åº”è°ƒåº¦å™¨**ï¼Œç»“åˆå®æ—¶ profiling åŠ¨æ€é€‰æ‹©æœ€ä¼˜ FiCCO ç­–ç•¥
- æ‰©å±•åˆ°æ›´å¤š ML primitiveï¼ˆå¦‚ attentionã€convolutionï¼‰
- ç ”ç©¶ **è·¨èŠ‚ç‚¹ï¼ˆinter-nodeï¼‰FiCCO** çš„å¯è¡Œæ€§
- ä¸ **Triton** æˆ– **custom kernel** ç»“åˆï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–å°ç®—å­æ•ˆç‡

---

> **æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº† **FiCCO**ï¼Œé¦–æ¬¡ç³»ç»Ÿæ¢ç´¢äº†åŸºäº DMA çš„ç»†ç²’åº¦ compute-communication overlap è®¾è®¡ç©ºé—´ï¼Œæ­ç¤ºäº† DIL ä¸ CIL çš„æƒè¡¡è§„å¾‹ï¼Œå¹¶æå‡ºäº†é«˜æ•ˆçš„è°ƒåº¦ heuristicã€‚å®éªŒè¡¨æ˜ï¼ŒFiCCO åœ¨çœŸå® ML workload ä¸Šæœ€é«˜å¯å¸¦æ¥ **1.6Ã— åŠ é€Ÿ**ï¼Œä¸ºä¸‹ä¸€ä»£é«˜æ€§èƒ½åˆ†å¸ƒå¼ ML ç³»ç»Ÿæä¾›äº†é‡è¦è®¾è®¡æ€è·¯ã€‚

</details>

---

### 4. [A Kernel-based Resource-efficient Neural Surrogate for Multi-fidelity Prediction of Aerodynamic Field](https://arxiv.org/abs/2512.10287)

**Authors**: Apurba Sarker, Reza T. Batley, Darshan Sarojini, Sourav Saha  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2512.10287v1  

#### Abstract
Surrogate models provide fast alternatives to costly aerodynamic simulations and are extremely useful in design and optimization applications. This study proposes the use of a recent kernel-based neural surrogate, KHRONOS. In this work, we blend sparse high-fidelity (HF) data with low-fidelity (LF) ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Kernel-based Resource-efficient Neural Surrogate for Multi-fidelity Prediction of Aerodynamic Field

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³**é«˜ç»´ã€å¤šä¿çœŸåº¦ï¼ˆmulti-fidelityï¼‰æ°”åŠ¨åœºé¢„æµ‹ä¸­çš„èµ„æºæ•ˆç‡ç“¶é¢ˆ**ã€‚ä¼ ç»Ÿç¥ç»ç½‘ç»œåœ¨å¤„ç†é«˜ä¿çœŸï¼ˆHFï¼‰CFDæ¨¡æ‹Ÿæ•°æ®æ—¶é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- é«˜ä¿çœŸæ•°æ®è·å–æˆæœ¬é«˜æ˜‚ï¼Œæ ·æœ¬ç¨€å°‘ï¼›
- å¤šä¿çœŸåº¦èåˆéœ€å¤„ç†ä¸ä¸€è‡´çš„åœºè¡¨ç¤ºï¼ˆå¦‚ç½‘æ ¼ã€ç‰©ç†æ¨¡å‹å·®å¼‚ï¼‰ï¼›
- ç°æœ‰æ·±åº¦å­¦ä¹ æ¨¡å‹å‚æ•°é‡å¤§ã€è®­ç»ƒæ¨ç†è€—æ—¶ï¼Œåœ¨èµ„æºå—é™åœºæ™¯ä¸‹éš¾ä»¥éƒ¨ç½²ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æå‡ºåŸºäº **KHRONOS**ï¼ˆKernel Expansion Hierarchy for Reduced-Order, Neural-Optimized Surrogatesï¼‰çš„å¤šä¿çœŸä»£ç†æ¨¡å‹æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åˆ©ç”¨**æ ¸å‡½æ•°å±•å¼€ï¼ˆkernel expansionï¼‰** å’Œ **å¯åˆ†ç¦»å¼ é‡ç»“æ„ï¼ˆseparable tensor decompositionï¼‰** æ„å»ºè½»é‡åŒ–ç¥ç»æ¶æ„ï¼›
- å°†è¾“å…¥-è¾“å‡ºæ˜ å°„åˆ†è§£ä¸ºä½ç»´å­ç©ºé—´çš„åŠ æƒä¹˜ç§¯ï¼Œä»…å­¦ä¹ æ’å€¼å‡½æ•°è€Œéå…¨è¿æ¥æƒé‡ï¼›
- é‡‡ç”¨**delta learningæ¶æ„**ï¼šå…ˆç”¨ä½ä¿çœŸï¼ˆLFï¼‰æ¨¡å‹ï¼ˆNeuralFoilï¼‰ç”Ÿæˆç²—ç•¥é¢„æµ‹ï¼Œå†è®­ç»ƒä¸€ä¸ªæ®‹å·®ï¼ˆresidualï¼‰æ¨¡å‹æ¥æ ¡æ­£HFä¸LFä¹‹é—´çš„å·®å¼‚ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

- **æé«˜çš„èµ„æºæ•ˆç‡**ï¼šç›¸æ¯”MLPã€GNNã€PINNç­‰å¯†é›†ç½‘ç»œï¼Œå‚æ•°é‡å‡å°‘ **94â€“98%**ï¼›
- **å¿«é€Ÿè®­ç»ƒä¸æ¨ç†**ï¼šåœ¨åŒç­‰ç²¾åº¦ä¸‹ï¼Œè®­ç»ƒæ—¶é—´ç¼©çŸ­ **40â€“73%**ï¼Œæ¨ç†é€Ÿåº¦å¿« **44â€“63%**ï¼›
- **æ— éœ€ä¸­é—´æ½œç©ºé—´å¯¹é½**ï¼šé¿å…äº†ä¼ ç»Ÿå¤šä¿çœŸæ–¹æ³•ä¸­å¤æ‚çš„ç‰¹å¾ç©ºé—´åŒ¹é…è¿‡ç¨‹ï¼›
- **æ•°å­¦åŸºç¡€æ‰å®**ï¼šåŸºäºå˜åˆ†åŸç†ã€æ’å€¼ç†è®ºå’Œå¼ é‡åˆ†è§£ï¼Œæ”¯æŒé«˜æ•ˆå‰ªæå’Œè‡ªåŠ¨å¾®åˆ†ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

| æ•°æ®é›† | ç±»å‹ | æè¿° |
|--------|------|------|
| **AirfRANS** | é«˜ä¿çœŸï¼ˆHFï¼‰ | åŒ…å«1000ä¸ª2DäºšéŸ³é€Ÿç¿¼å‹çš„RANSè§£ï¼Œæ¶µç›–NACA 4/5ä½ç³»åˆ—ï¼ŒRe âˆˆ [2Ã—10â¶, 6Ã—10â¶]ï¼ŒAoA âˆˆ [-5Â°, 15Â°]ï¼Œä½¿ç”¨OpenFOAMæ±‚è§£ï¼Œç½‘æ ¼è¾¾25ä¸‡â€“30ä¸‡ä¸ªå•å…ƒã€‚ |
| **NeuralFoil** | ä½ä¿çœŸï¼ˆLFï¼‰ | åŸºäºXFoilè®­ç»ƒçš„ç‰©ç† informed ç¥ç»ç½‘ç»œï¼Œç”¨äºç”Ÿæˆå¯¹åº”AirfRANSå‡ ä½•æ¡ä»¶ä¸‹çš„ä½å‹å¼ºåœºé¢„æµ‹ï¼›å…±ç”Ÿæˆ735ä¸ªé«˜è´¨é‡æ ·æœ¬ï¼ˆRÂ² > 0.7ï¼‰ï¼Œ265ä¸ªä½è´¨é‡æ ·æœ¬ç”¨äºéªŒè¯å¤šä¿çœŸå¢ç›Šã€‚ |

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **é—®é¢˜è®¾å®š**
- ç›®æ ‡ï¼šé¢„æµ‹ç¿¼å‹è¡¨é¢å‹åŠ›ç³»æ•° $ C_p $ åˆ†å¸ƒï¼ˆå…±81ä¸ªé‡‡æ ·ç‚¹ï¼‰ï¼›
- è¾“å…¥ï¼šç”±B-splineæ§åˆ¶ç‚¹ï¼ˆNgeom=16ï¼‰ã€è‡ªç”±æµé€Ÿåº¦ $ U $ã€æ”»è§’ $ \text{AoA} $ ç»„æˆçš„å‘é‡ï¼›
- è¾“å‡ºï¼šæ ‡å‡†åŒ–åçš„ $ C_p $ æ›²çº¿ã€‚

#### **ä¸‰ç§è®­ç»ƒåœºæ™¯ï¼ˆCase 1â€“3ï¼‰**
| Case | HF/LF Ratio | HF Training Data | LF Training Data | è¯´æ˜ |
|------|-------------|------------------|------------------|------|
| 1    | 0%          | 0                | 588              | çº¯LFæ¨¡å‹ï¼Œæ— HFä¿®æ­£ |
| 2    | 10%         | 59               | 588              | å¼•å…¥å°‘é‡HFæ•°æ®è¿›è¡Œæ®‹å·®å­¦ä¹  |
| 3    | 30%         | 176              | 588              | æ›´å¤šHFæ•°æ®å‚ä¸è®­ç»ƒ |

#### **è¯„ä¼°æŒ‡æ ‡**
- **$ R^2 $**ï¼ˆå†³å®šç³»æ•°ï¼‰ï¼šè¡¡é‡é¢„æµ‹ä¸çœŸå® $ C_p $ åœºçš„ä¸€è‡´æ€§ï¼›
- **è®­ç»ƒæ—¶é—´**ï¼ˆper foldï¼‰ï¼š5æŠ˜äº¤å‰éªŒè¯ä¸­æ¯æŠ˜å¹³å‡è®­ç»ƒè€—æ—¶ï¼›
- **æ¨ç†å»¶è¿Ÿ**ï¼ˆms/sampleï¼‰ï¼šå•æ¬¡å‰å‘ä¼ æ’­æ—¶é—´ï¼›
- **å¯è®­ç»ƒå‚æ•°æ•°é‡**ï¼šæ¨¡å‹å¤æ‚åº¦æŒ‡æ ‡ï¼›
- **ç¼©æ”¾ç‰¹æ€§åˆ†æ**ï¼šæ§åˆ¶ç‚¹ä»16å¢è‡³64ï¼Œè§‚å¯Ÿ $ R^2 $ ä¸å‚æ•°å¢é•¿å…³ç³»ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ¨¡å‹ | ç±»å‹ | ç»“æ„ç‰¹ç‚¹ |
|------|------|----------|
| **MLP** | å¤šå±‚æ„ŸçŸ¥æœº | 4å±‚å…¨è¿æ¥ï¼ŒReLUæ¿€æ´»ï¼Œå®½åº¦256/128ï¼ˆLF/Deltaï¼‰ |
| **GNN** | å›¾ç¥ç»ç½‘ç»œ | åŸºäºæ§åˆ¶ç‚¹æ„å»ºé“¾å¼å›¾ï¼Œæ¶ˆæ¯ä¼ é€’å±‚èšåˆé‚»åŸŸä¿¡æ¯ |
| **PINN** | ç‰©ç† informed NN | åœ¨MLPåŸºç¡€ä¸ŠåŠ å…¥PDEæ®‹å·®çº¦æŸï¼ˆLaplaceæ–¹ç¨‹ + Bernoulliï¼‰ |
| **KHRONOS**ï¼ˆæœ¬æ–‡ï¼‰ | æ ¸åŸºåˆ†ç¦»æ¶æ„ | ä½¿ç”¨äºŒæ¬¡B-splineæ ¸å±•å¼€ï¼Œä½ç§©å¼ é‡ç»„åˆï¼Œå‚æ•°å…±äº« |

æ‰€æœ‰æ¨¡å‹å‡é‡‡ç”¨ç›¸åŒçš„ delta learning æ¶æ„ä»¥ç¡®ä¿å…¬å¹³æ¯”è¾ƒï¼Œå¹¶é€šè¿‡ grid search è°ƒä¼˜è¶…å‚æ•°ï¼ˆè§ Appendix Aï¼‰ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

| æŒ‡æ ‡ | KHRONOS (Case 3) | MLP | GNN | PINN |
|------|------------------|-----|-----|------|
| **Test $ R^2 $** | ~0.90 | ~0.91 | ~0.92 | ~0.91 |
| **Trainable Parameters** | **7,759** | 139,554 | 202,626 | 139,554 |
| **Inference Time (ms)** | **2.44â€“3.64** | 5.33â€“8.52 | 7.17â€“9.77 | 5.13â€“8.27 |
| **Training Time per Fold (s)** | **3â€“15** | 19â€“30 | 27â€“32 | 28â€“30 |

> æ³¨ï¼šKHRONOSåœ¨æ‰€æœ‰èµ„æºå—é™æ¡ä»¶ä¸‹è¡¨ç°æœ€ä¼˜ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### âœ… å‚æ•°æ•ˆç‡ï¼ˆParameter Efficiencyï¼‰
- KHRONOSå‚æ•°é‡ä»…ä¸ºMLP/PINNçš„ **~5.5%**ï¼ŒGNNçš„ **~3.8%**ï¼›
- å³ä½¿å°†å‡ ä½•åˆ†è¾¨ç‡ä»16æå‡è‡³64ä¸ªæ§åˆ¶ç‚¹ï¼ŒKHRONOSå‚æ•°ä»…ä»7,759å¢è‡³17,897ï¼ˆ+130%ï¼‰ï¼Œè€ŒGNNä»20ä¸‡å¢è‡³67ä¸‡ï¼ˆ+234%ï¼‰ï¼ŒMLP/PINNä¹Ÿå¢é•¿æ˜¾è‘—ã€‚

#### âœ… æ—¶é—´æ•ˆç‡ï¼ˆTime Efficiencyï¼‰
- **è®­ç»ƒæ—¶é—´**ï¼šKHRONOSæœ€å¿«ä»…éœ€ **3ç§’/æŠ˜**ï¼Œæ¯”MLPå¿« **4â€“6å€**ï¼Œæ¯”GNNå¿« **9å€ä»¥ä¸Š**ï¼›
- **æ¨ç†å»¶è¿Ÿ**ï¼šæœ€ä½è¾¾ **2.44 ms**ï¼Œæ¯”MLPå¿«çº¦ **2å€**ï¼Œæ¯”GNNå¿«è¿‘ **4å€**ï¼›
- åœ¨ **15ç§’è®­ç»ƒé¢„ç®—å†…**ï¼ŒKHRONOSå³å¯è¾¾åˆ° $ 1-R^2 < 0.1 $ï¼Œè€Œå…¶ä»–æ¨¡å‹ä»å¤„äºé«˜è¯¯å·®é˜¶æ®µï¼ˆFig. 6ï¼‰ã€‚

#### âœ… å‡†ç¡®æ€§ï¼ˆAccuracyï¼‰
- æ‰€æœ‰æ¨¡å‹æœ€ç»ˆå‡å¯è¾¾åˆ° $ R^2 \geq 0.8 $ï¼Œè¡¨æ˜é¢„æµ‹èƒ½åŠ›ç›¸å½“ï¼›
- åœ¨Case 3ä¸­ï¼ŒKHRONOS $ R^2 \approx 0.90 $ï¼Œè™½ç•¥ä½äºGNNï¼ˆ0.92ï¼‰ï¼Œä½†åœ¨**èµ„æºæ¶ˆè€—ä¸Šå…·æœ‰å‹å€’æ€§ä¼˜åŠ¿**ï¼›
- ç¼©æ”¾å®éªŒæ˜¾ç¤ºï¼Œè¶…è¿‡32ä¸ªæ§åˆ¶ç‚¹åï¼Œç²¾åº¦æå‡è¶‹äºé¥±å’Œï¼Œè¯´æ˜å½“å‰æ¨¡å‹å·²é€¼è¿‘æ•°æ®æé™ã€‚

### **æ¶ˆèå®éªŒä¸ç‰¹æ®Šåœºæ™¯åˆ†æ**

#### ğŸ” åœ¨ä½è´¨é‡LFæ•°æ®ä¸Šçš„è¡¨ç°ï¼ˆRÂ²_LF < 0.7ï¼‰
- NeuralFoilåœ¨265ä¸ªå¤æ‚å·¥å†µä¸‹è¡¨ç°å·®ï¼ˆ$ R^2 < 0.7 $ï¼‰ï¼Œä¸»è¦è¡¨ç°ä¸ºä½ä¼°å‰ç¼˜å¸åŠ›å³°ï¼›
- KHRONOSé€šè¿‡æ®‹å·®å­¦ä¹ æˆåŠŸæ¢å¤å¸åŠ›å³°å½¢æ€å’Œå¹…å€¼ï¼ˆFig. 12ï¼‰ï¼›
- å¤šä¿çœŸå¢ç›Šæ˜æ˜¾ï¼šåŸLFæ¨¡å‹å…¨éƒ¨è½åœ¨ $ R^2 < 0.7 $ åŒºé—´ï¼Œè€ŒMF-KHRONOSå°† **52.8% çš„æ¡ˆä¾‹æå‡è‡³ $ R^2 > 0.7 $**ï¼ˆFig. 13ï¼‰ã€‚

#### ğŸ“ˆ æ§åˆ¶ç‚¹æ•°å¢åŠ çš„å½±å“ï¼ˆFig. 9â€“10ï¼‰
- æ‰€æœ‰æ¨¡å‹åœ¨16â†’64æ§åˆ¶ç‚¹é—´ $ R^2 $ æå‡æœ‰é™ï¼ˆ0.87â†’0.94ï¼‰ï¼Œè¯´æ˜å‡ ä½•åˆ†è¾¨ç‡éç“¶é¢ˆï¼›
- KHRONOSä¿æŒæœ€å°å‚æ•°å¢é•¿ï¼Œå®ç°æœ€ä½³â€œç²¾åº¦-å¤æ‚åº¦â€æƒè¡¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **KHRONOSå®ç°äº†ç²¾åº¦ä¸æ•ˆç‡çš„é«˜åº¦å¹³è¡¡**ï¼š
   - åœ¨å‡ ä¹ç›¸åŒé¢„æµ‹ç²¾åº¦ä¸‹ï¼Œæ¯”ä¸»æµç¥ç»æ¶æ„èŠ‚çœ **ä¸¤ä¸ªæ•°é‡çº§çš„å‚æ•°** å’Œ **æ˜¾è‘—é™ä½è®¡ç®—å¼€é”€**ï¼›
   - ç‰¹åˆ«é€‚ç”¨äºåµŒå…¥å¼ç³»ç»Ÿã€å®æ—¶ä¼˜åŒ–ã€å¤§è§„æ¨¡è®¾è®¡æ¢ç´¢ç­‰èµ„æºæ•æ„Ÿåœºæ™¯ã€‚

2. **æ ¸åŸºåˆ†ç¦»ç»“æ„å¤©ç„¶é€‚åˆå¤šä¿çœŸå»ºæ¨¡**ï¼š
   - ä¸ä¾èµ–æ½œç©ºé—´å¯¹é½ï¼Œç›´æ¥åœ¨åŸå§‹è¾“å…¥ç©ºé—´è¿›è¡Œæ®‹å·®å­¦ä¹ ï¼›
   - å¯åˆ†ç¦»æ€§æ”¯æŒé«˜æ•ˆè‡ªåŠ¨å¾®åˆ†ï¼Œä¾¿äºé›†æˆåˆ°æ¢¯åº¦ä¼˜åŒ–æµç¨‹ä¸­ã€‚

3. **å¤šä¿çœŸå¢ç›Šåœ¨å›°éš¾æ¡ˆä¾‹ä¸­æœ€æ˜¾è‘—**ï¼š
   - å½“LFæ¨¡å‹å¤±æ•ˆæ—¶ï¼ˆå¦‚å¼ºåˆ†ç¦»ã€é«˜æ”»è§’ï¼‰ï¼Œæ®‹å·®æ¨¡å‹èƒ½æœ‰æ•ˆçº æ­£ç³»ç»Ÿåå·®ï¼›
   - è¡¨æ˜Î”-learningç­–ç•¥åœ¨å·¥ç¨‹å®é™…ä¸­å…·å¤‡é²æ£’æ€§å’Œå®ç”¨æ€§ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- å½“å‰è¯„ä¼°å±€é™äºå•ä¸€HFæºï¼ˆAirfRANSï¼‰å’Œå•ä¸€LFç”Ÿæˆå™¨ï¼ˆNeuralFoilï¼‰ï¼›
- æœªæµ‹è¯•è·¨ç¿¼å‹æ—æˆ–è·¨æµåŠ¨çŠ¶æ€ï¼ˆå¦‚è·¨éŸ³é€Ÿï¼‰çš„æ³›åŒ–èƒ½åŠ›ï¼›
- å¯¹æé«˜ç»´åœºï¼ˆå¦‚3Då…¨åœºï¼‰æ‰©å±•å°šæœªéªŒè¯ï¼›
- B-splineå‚æ•°åŒ–è™½çµæ´»ï¼Œä½†ä»å—é™äºé¢„å®šä¹‰æ§åˆ¶ç‚¹æ‹“æ‰‘ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. æ‰©å±•è‡³æ›´å¤šHFæ•°æ®é›†ï¼ˆå¦‚Transonic, 3D Wingï¼‰å’Œå¤šç§LFæ¨¡å‹ï¼ˆXFOIL, Panel Methodï¼‰ï¼›
2. æ¢ç´¢è‡ªé€‚åº”HF/LFé‡‡æ ·ç­–ç•¥ï¼ŒåŠ¨æ€åˆ†é…ä»¿çœŸèµ„æºï¼›
3. å°†KHRONOSåº”ç”¨äºç«¯åˆ°ç«¯æ°”åŠ¨å½¢çŠ¶ä¼˜åŒ–é—­ç¯ï¼›
4. ç ”ç©¶å…¶åœ¨ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUQï¼‰å’Œä¸»åŠ¨å­¦ä¹ ä¸­çš„æ½œåŠ›ï¼›
5. æ¨å¹¿è‡³å…¶ä»–ç‰©ç†åœºé¢„æµ‹ä»»åŠ¡ï¼ˆæ¸©åº¦ã€æ¹æµç²˜æ€§ç­‰ï¼‰ã€‚

---

> **æ€»ç»“**ï¼šæœ¬è®ºæ–‡æå‡ºçš„ **KHRONOS** æ˜¯ä¸€ç§æå…·å‰æ™¯çš„èµ„æºé«˜æ•ˆå‹å¤šä¿çœŸä»£ç†æ¨¡å‹ï¼Œå®ƒé€šè¿‡**æ ¸å‡½æ•°å±•å¼€ä¸å¯åˆ†ç¦»å¼ é‡ç»“æ„**ï¼Œåœ¨ä¿æŒé«˜é¢„æµ‹ç²¾åº¦çš„åŒæ—¶å¤§å¹…é™ä½æ¨¡å‹å¤æ‚åº¦ã€‚å®éªŒè¡¨æ˜å…¶åœ¨æ°”åŠ¨åœºé¢„æµ‹ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºMLPã€GNNå’ŒPINNï¼Œå°¤å…¶é€‚åˆåœ¨**æ•°æ®ç¨€ç¼ºã€ç®—åŠ›å—é™**çš„å®é™…å·¥ç¨‹ç¯å¢ƒä¸­éƒ¨ç½²ã€‚

</details>

---

### 5. [AEBNAS: Strengthening Exit Branches in Early-Exit Networks through Hardware-Aware Neural Architecture Search](https://arxiv.org/abs/2512.10671)

**Authors**: Oscar Robben, Saeed Khalilian, Nirvana Meratnia  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.10671v1  

#### Abstract
Early-exit networks are effective solutions for reducing the overall energy consumption and latency of deep learning models by adjusting computation based on the complexity of input data. By incorporating intermediate exit branches into the architecture, they provide less computation for simpler sam...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# AEBNAS: Strengthening Exit Branches in Early-Exit Networks through Hardware-Aware Neural Architecture Search  
â€”â€”æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æ—©æœŸé€€å‡ºç½‘ç»œï¼ˆEarly-Exit Networks, EENsï¼‰é€šè¿‡åœ¨æ¨¡å‹ä¸­é—´å±‚æ·»åŠ **exit branches**ï¼Œå®ç°å¯¹ç®€å•æ ·æœ¬çš„æå‰æ¨ç†ç»ˆæ­¢ï¼Œä»è€Œé™ä½å¹³å‡å»¶è¿Ÿå’Œè®¡ç®—å¼€é”€ï¼ˆå¦‚MACsï¼‰ï¼Œç‰¹åˆ«é€‚ç”¨äºèµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ã€‚ç„¶è€Œï¼Œè®¾è®¡é«˜æ•ˆçš„EENé¢ä¸´å››å¤§æŒ‘æˆ˜ï¼š
1. exit branchesçš„æ•°é‡ï¼›
2. exit branchesçš„ä½ç½®ï¼›
3. é€€å‡ºç­–ç•¥ï¼ˆå¦‚ç½®ä¿¡åº¦é˜ˆå€¼ï¼‰ï¼›
4. **exit branchesè‡ªèº«çš„æ¶æ„è®¾è®¡ï¼ˆæ·±åº¦ã€å±‚æ•°ã€ç±»å‹ï¼‰**ã€‚

å·²æœ‰ç ”ç©¶ï¼ˆå¦‚EDANASã€NACHOSï¼‰ä¸»è¦å…³æ³¨å‰ä¸‰ä¸ªé—®é¢˜ï¼Œé€šå¸¸é‡‡ç”¨**å›ºå®šç»“æ„çš„exit branches**ï¼Œå¿½ç•¥äº†å…¶æ¶æ„ä¼˜åŒ–å¯¹æ•´ä½“æ€§èƒ½çš„å½±å“ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
æœ¬æ–‡æå‡º **AEBNAS**ï¼ˆAdaptive Exit Branch Neural Architecture Searchï¼‰ï¼Œä¸€ä¸ª**ç¡¬ä»¶æ„ŸçŸ¥çš„å¤šç›®æ ‡NASæ¡†æ¶**ï¼Œä¸“é—¨ç”¨äºè”åˆä¼˜åŒ–ä¸»å¹²ç½‘ç»œï¼ˆbackboneï¼‰å’Œexit branchesçš„æ¶æ„è®¾è®¡ã€‚

#### ä¸»è¦åˆ›æ–°åŒ…æ‹¬ï¼š
- **åŠ¨æ€exit branchæ¶æ„æœç´¢ç©ºé—´è®¾è®¡**ï¼š  
  å…è®¸exit brancheså…·æœ‰å¯å˜æ·±åº¦ï¼ˆæœ€å¤š2ä¸ªblockï¼‰ã€ä¸åŒå·ç§¯æ ¸å¤§å°ï¼ˆkernel size: 3æˆ–5ï¼‰ã€æ‰©å±•ç‡ï¼ˆexpansion rate: 1æˆ–2ï¼‰ã€æ’å€¼å°ºå¯¸ï¼ˆinterpolation sizeï¼‰ä»¥åŠæ˜¯å¦æ·»åŠ max-poolingå±‚ï¼Œæ˜¾è‘—å¢å¼ºäº†exit branchesçš„è¡¨è¾¾èƒ½åŠ›ã€‚

- **å¼•å…¥ç›®æ ‡MACsçº¦æŸä½œä¸ºä¼˜åŒ–ç›®æ ‡çš„ä¸€éƒ¨åˆ†**ï¼š  
  åœ¨NSGA-IIå¤šç›®æ ‡ä¼˜åŒ–ä¸­åŠ å…¥`target_macs`è¶…å‚æ•°ï¼Œä½¿æœç´¢è¿‡ç¨‹èƒ½ç”Ÿæˆæ»¡è¶³ç‰¹å®šç¡¬ä»¶è®¡ç®—é¢„ç®—çš„æ¨¡å‹ï¼Œæå‡éƒ¨ç½²çµæ´»æ€§ã€‚

- **è¿­ä»£å¼exit thresholdè°ƒä¼˜æœºåˆ¶**ï¼š  
  åœ¨æ¯è½®NASè¿­ä»£åï¼Œä½¿ç”¨grid searchå¯¹æ¯ä¸ªå€™é€‰æ¶æ„è¿›è¡Œ**è‡ªé€‚åº”é˜ˆå€¼è°ƒæ•´**ï¼Œä»¥åœ¨ç»™å®šMACsé¢„ç®—ä¸‹æœ€å¤§åŒ–å‡†ç¡®ç‡ï¼Œå¹¶å°†æ›´æ–°åçš„æ€§èƒ½åé¦ˆè‡³surrogate modelè®­ç»ƒä¸­ã€‚

- **ç«¯åˆ°ç«¯è”åˆä¼˜åŒ–backboneä¸exit branches**ï¼š  
  ä¸ä»…æœç´¢exitä½ç½®å’Œæ•°é‡ï¼Œè¿˜åŒæ—¶ä¼˜åŒ–å…¶å†…éƒ¨ç»“æ„ï¼ŒçœŸæ­£å®ç°â€œstrengthening exit branchesâ€ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ˜¯å¦ä¼˜åŒ–exitä½ç½® | æ˜¯å¦ä¼˜åŒ–exitæ•°é‡ | æ˜¯å¦ä¼˜åŒ–exitæ¶æ„ | æ˜¯å¦è°ƒä¼˜threshold | ç¡¬ä»¶æ„ŸçŸ¥ |
|------|------------------|------------------|------------------|--------------------|----------|
| EDANAS [12] | âœ… | âœ… | âŒï¼ˆå›ºå®šï¼‰ | âœ… | âœ…ï¼ˆMACsï¼‰ |
| NACHOS [13] | âœ… | âœ… | âŒï¼ˆä»…å…è®¸max-poolingï¼‰ | âœ… | âœ… |
| **AEBNAS (æœ¬æ–‡)** | âœ… | âœ… | âœ…ï¼ˆå®Œæ•´ç»“æ„æœç´¢ï¼‰ | âœ…ï¼ˆè¿­ä»£è°ƒä¼˜ï¼‰ | âœ… |

> âœ… æ˜¾è‘—ä¼˜åŠ¿ï¼šAEBNASæ˜¯é¦–ä¸ªå°†**exit branchæ¶æ„æœ¬èº«çº³å…¥NASæœç´¢ç©ºé—´**çš„å·¥ä½œï¼Œå®ç°äº†æ›´ç²¾ç»†çš„æ•ˆç‡-ç²¾åº¦æƒè¡¡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
- **CIFAR-10**ï¼š5ä¸‡è®­ç»ƒå›¾åƒï¼Œ1ä¸‡æµ‹è¯•å›¾åƒ
- **CIFAR-100**ï¼šåŒä¸Šï¼Œç±»åˆ«æ›´å¤šï¼Œä»»åŠ¡æ›´å¤æ‚
- **SVHN**ï¼š73,257å¼ è®­ç»ƒå›¾åƒï¼Œ26,032å¼ æµ‹è¯•å›¾åƒï¼ˆè¡—æ™¯é—¨ç‰Œæ•°å­—è¯†åˆ«ï¼‰

æ‰€æœ‰æ•°æ®é›†ä¸­ï¼Œ10%è®­ç»ƒé›†ç”¨ä½œéªŒè¯é›†ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®
| å‚æ•° | è®¾ç½® |
|------|------|
| NASç®—æ³• | NSGA-IIï¼ˆåŸºäºNSGANetV2ï¼‰ |
| æœç´¢è¿­ä»£æ¬¡æ•° | 30æ¬¡ |
| åˆå§‹ç§ç¾¤å¤§å° | 100 |
| åç»­æ¯ä»£é‡‡æ ·æ•° | 8 |
| æ¯ä¸ªæ¶æ„è®­ç»ƒepochæ•° | 5ï¼ˆCIFAR-10/100/SVHNï¼‰ï¼ŒCIFAR-100æœ€åä¸¤è½®ä¸º250 epoch |
| Surrogate Model | Multilayer Perceptronï¼ˆé¢„æµ‹errorå’ŒMACsï¼‰ |
| Target MACs | SVHN: 1Mï¼›CIFAR-10: 2M / 17Mï¼›CIFAR-100: 17M |
| Exit Branch Options | kernel: [3,5]ï¼›expansion: [1,2]ï¼›interpolation: [8,10,12]ï¼›max-pooling: å¯é€‰ï¼›æœ€å¤§blockæ•°: 2 |

---

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
- **Top-1 Accuracy (%)**
- **Average Number of MACs (ç™¾ä¸‡çº§)**
- **Number of Exits**
- **Exit Utilization (%)**ï¼šå„exitåˆ†æ”¯åˆ†ç±»çš„æ ·æœ¬æ¯”ä¾‹
- **Hardware Efficiency**ï¼šåœ¨ç›¸åŒæˆ–æ›´ä½MACsä¸‹æ˜¯å¦è·å¾—æ›´é«˜accuracy

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | åŸºçº¿æ¨¡å‹ |
|------|--------|
| æ‰‹åŠ¨è®¾è®¡ | EEAlexNetï¼ˆ5 exitsï¼‰ã€EEResNet20ï¼ˆ10 exitsï¼‰ |
| NAS-based | EDANAS [12]ã€NACHOS [13] |

æ‰€æœ‰NASæ–¹æ³•å‡ä¿æŒä¸€è‡´è¶…å‚è®¾ç½®ä»¥ä¾¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªTable IIï¼‰

#### âœ… CIFAR-10ï¼ˆTarget: ~2.4M MACsï¼‰
| Model | MACs (M) | Top-1 Acc (%) | # Exits |
|-------|----------|---------------|--------|
| AEBNAS | **2.47** | **74.64** | 4 |
| EDANAS | 2.47 | 67.78 | 5 |
| NACHOS | 2.44 | 72.65 | 4 |
| EEAlexNet | 233.46 | 73.03 | 5 |

> ğŸ’¡ **AEBNASæ¯”EDANASé«˜6.86%ï¼Œæ¯”NACHOSé«˜1.99%**ï¼Œä¸”MACsè¿œä½äºæ‰‹åŠ¨æ¨¡å‹ã€‚

#### âœ… CIFAR-10ï¼ˆHigh-budget: ~17M MACsï¼‰
| Model | MACs (M) | Top-1 Acc (%) |
|-------|----------|---------------|
| AEBNAS | **16.71** | **84.42** |
| EDANAS | 17.31 | 80.90 |

> ğŸ’¡ æ›´é«˜å‡†ç¡®ç‡ + æ›´ä½MACsï¼Œä½“ç°æ›´å¼ºä¼˜åŒ–èƒ½åŠ›ã€‚

#### âœ… SVHNï¼ˆTarget: 1M MACsï¼‰
| Model | MACs (M) | Top-1 Acc (%) |
|-------|----------|---------------|
| AEBNAS | **1.79** | **85.76** |
| EDANAS | 1.47 | 77.98 |
| NACHOS | 1.46 | 79.96 |

> ğŸ’¡ è™½MACsç•¥é«˜ä½†ä»æ§åˆ¶åœ¨åˆç†èŒƒå›´ï¼Œ**å‡†ç¡®ç‡æå‡è¾¾6~8ä¸ªç™¾åˆ†ç‚¹**ã€‚

#### âœ… CIFAR-100ï¼ˆå¤æ‚ä»»åŠ¡ï¼‰
| Model | MACs (M) | Top-1 Acc (%) |
|-------|----------|---------------|
| AEBNAS | **14.80** | **69.90** |
| EDANAS | 14.94 | 67.94 |

> ğŸ’¡ åœ¨æ›´éš¾ä»»åŠ¡ä¸Šä»å®ç°**+1.96% accuracyæå‡**ï¼Œä¸”MACsæ›´ä½ã€‚

---

### ğŸ” Exit Utilization åˆ†æï¼ˆFigure 3ï¼‰
- AEBNASå€¾å‘äº**ç¦ç”¨ç¬¬ä¸€ä¸ªexit branch**ï¼Œè€Œå°†å¤§éƒ¨åˆ†æ ·æœ¬ï¼ˆ>80%ï¼‰ç”±ç¬¬2æˆ–ç¬¬3ä¸ªexitå¤„ç†ã€‚
- EDANAS/NACHOSæ¿€æ´»äº†æ€§èƒ½è¾ƒå¼±çš„ç¬¬ä¸€exitï¼Œå¯¼è‡´å°‘é‡æ ·æœ¬åœ¨æ­¤é€€å‡ºï¼Œåè€Œå¢åŠ å†—ä½™è®¡ç®—ã€‚
- è¡¨æ˜ï¼š**å¼ºåŒ–ä¸­æ®µexit brancheså¹¶å…³é—­ä½æ•ˆearly exit**æœ‰åŠ©äºæå‡æ•´ä½“æ•ˆç‡ã€‚

---

### ğŸ“‰ æ¶ˆèåˆ†æï¼ˆéšå«äºæ–‡ä¸­ï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»æ–¹æ³•è®¾è®¡å¯æ¨æ–­ä»¥ä¸‹å…³é”®å› ç´ ä½œç”¨ï¼š
- **å¯å˜exitæ¶æ„æœç´¢** â†’ æå‡exit branchåˆ¤åˆ«åŠ›ï¼Œæ”¯æŒæ›´æ—©å¯é é€€å‡ºï¼›
- **adaptive threshold tuning** â†’ åŠ¨æ€å¹³è¡¡accuracyä¸MACsï¼›
- **multi-objective with target_macs** â†’ å¼•å¯¼æœç´¢æœç¡¬ä»¶å‹å¥½æ–¹å‘æ”¶æ•›ï¼›
- ç»“æœæ˜¾ç¤ºè¿™äº›æœºåˆ¶å…±åŒä¿ƒæˆParetoå‰æ²¿ä¸Šçš„ä¼˜è¶Šè¡¨ç°ï¼ˆè§Figure 2ï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **exit branchesçš„æ¶æ„è®¾è®¡è‡³å…³é‡è¦**ï¼š  
   å›ºå®šç»“æ„é™åˆ¶äº†early-exitç½‘ç»œçš„æ½œåŠ›ï¼Œ**å¯å­¦ä¹ ã€å¯å˜æ·±åº¦çš„exit branchèƒ½æ˜¾è‘—æå‡æ€§èƒ½**ã€‚

2. **AEBNASèƒ½åœ¨ç›¸åŒç”šè‡³æ›´ä½MACsä¸‹å–å¾—æ›´é«˜accuracy**ï¼š  
   åœ¨CIFAR-10ã€SVHNã€CIFAR-100ä¸Šå…¨é¢è¶…è¶Šstate-of-the-art NASä¸æ‰‹åŠ¨è®¾è®¡æ–¹æ³•ã€‚

3. **æœ€ä¼˜exit utilizationæ¨¡å¼æ˜¯éå‡åŒ€çš„**ï¼š  
   å¹¶éè¶Šå¤šexitè¶Šå¥½ï¼ŒAEBNASè‡ªåŠ¨å­¦ä¼š**è·³è¿‡ä½æ•ˆearly exits**ï¼Œé›†ä¸­åœ¨ä¸­æ®µå¼ºexitå®Œæˆå¤šæ•°é¢„æµ‹ï¼Œå®ç°é«˜æ•ˆåˆ†æµã€‚

4. **ç¡¬ä»¶æ„ŸçŸ¥+åŠ¨æ€thresholdè°ƒä¼˜å¢å¼ºå®ç”¨æ€§**ï¼š  
   æ”¯æŒæŒ‰è®¾å¤‡ç®—åŠ›å®šåˆ¶æ¨¡å‹ï¼Œé€‚åˆçœŸå®è¾¹ç¼˜éƒ¨ç½²åœºæ™¯ã€‚

---

### âš ï¸ å±€é™æ€§
- å½“å‰exit branchæœç´¢ç©ºé—´ä»æœ‰é™ï¼ˆä»…2-blockç»“æ„ï¼‰ï¼Œæœªæ¥å¯æ¢ç´¢æ›´å¤æ‚æ¨¡å—ï¼ˆå¦‚attentionã€SE blockï¼‰ã€‚
- threshold tuningä¾èµ–grid searchï¼Œè®¡ç®—å¼€é”€è¾ƒé«˜ï¼Œæœªæ¥å¯å°è¯•æ¢¯åº¦ä¼˜åŒ–æˆ–ä»£ç†å»ºæ¨¡ã€‚
- å®éªŒé›†ä¸­åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œå°šæœªéªŒè¯åœ¨æ£€æµ‹ã€åˆ†å‰²ç­‰ä»»åŠ¡ä¸­çš„æ³›åŒ–æ€§ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å°†AEBNASæ‰©å±•è‡³å…¶ä»–åŠ¨æ€æ¨ç†èŒƒå¼ï¼ˆå¦‚layer-skippingã€routing networksï¼‰ã€‚
- æ¢ç´¢è·¨è®¾å¤‡è¿ç§»NASç­–ç•¥ï¼ŒåŠ é€Ÿæœç´¢è¿‡ç¨‹ã€‚
- é›†æˆåŠŸè€—/å»¶è¿Ÿå®æµ‹åé¦ˆï¼Œæ„å»ºé—­ç¯ç¡¬ä»¶ååŒè®¾è®¡ç³»ç»Ÿã€‚
- åº”ç”¨äºTransformer-based early-exitæ¶æ„æœç´¢ã€‚

---

## æ€»ç»“
> **AEBNASé¦–æ¬¡å°†exit branchæ¶æ„æœ¬èº«çº³å…¥NASæœç´¢ç©ºé—´ï¼Œç»“åˆç¡¬ä»¶æ„ŸçŸ¥ç›®æ ‡ä¸åŠ¨æ€thresholdè°ƒä¼˜ï¼Œåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æ›´é«˜çš„accuracyä¸æ›´ä½çš„average MACsï¼ŒéªŒè¯äº†â€œstrengthening exit branchesâ€çš„æœ‰æ•ˆæ€§ï¼Œä¸ºé«˜æ•ˆè¾¹ç¼˜AIæ¨¡å‹è®¾è®¡æä¾›äº†æ–°èŒƒå¼ã€‚**

</details>

---

### 6. [InfoCom: Kilobyte-Scale Communication-Efficient Collaborative Perception with Information Bottleneck](https://arxiv.org/abs/2512.10305)

**Authors**: Quanmin Wei, Penglin Dai, Wei Li, Bingyi Liu, Xiao Wu  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.10305v1  

#### Abstract
Precise environmental perception is critical for the reliability of autonomous driving systems. While collaborative perception mitigates the limitations of single-agent perception through information sharing, it encounters a fundamental communication-performance trade-off. Existing communication-eff...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# InfoCom: Kilobyte-Scale Communication-Efficient Collaborative Perception with Information Bottleneck  
**â€”â€”æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿä¾èµ–äºç²¾ç¡®çš„ç¯å¢ƒæ„ŸçŸ¥ï¼Œè€Œå•æ™ºèƒ½ä½“æ„ŸçŸ¥å—é™äºè§†é‡é®æŒ¡ç­‰é—®é¢˜ã€‚**ååŒæ„ŸçŸ¥ï¼ˆCollaborative Perceptionï¼‰**é€šè¿‡å¤šè½¦ä¹‹é—´çš„ä¿¡æ¯å…±äº«æå‡æ„ŸçŸ¥èƒ½åŠ›ï¼Œä½†é¢ä¸´ä¸€ä¸ªæ ¹æœ¬çŸ›ç›¾ï¼š**é€šä¿¡å¼€é”€ä¸æ„ŸçŸ¥æ€§èƒ½ä¹‹é—´çš„æƒè¡¡**ã€‚

ç°æœ‰é€šä¿¡é«˜æ•ˆæ–¹æ³•ï¼ˆå¦‚ Where2commã€ERMVPï¼‰é€šå¸¸å‡è®¾æ¯æ¬¡åä½œä¼ è¾“ **MBçº§æ•°æ®**ï¼Œè¿™åœ¨å®é™…è½¦è½½ç½‘ç»œä¸­éš¾ä»¥å®ç°ï¼ˆ5Gå¹³å‡ä»…3.5 MB/sï¼Œæ³¢åŠ¨ä¸‹å¯ä½è‡³0.4 MB/sï¼‰ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•ç¼ºä¹ç†è®ºæ”¯æ’‘ï¼Œå¤šä¸ºå¯å‘å¼ç‰¹å¾æ“ä½œï¼Œæ— æ³•ä¿è¯åœ¨æç«¯å‹ç¼©ä¸‹çš„æ„ŸçŸ¥ä¿çœŸåº¦ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡º **InfoCom**ï¼Œä¸€ç§åŸºäº**ä¿¡æ¯ç“¶é¢ˆï¼ˆInformation Bottleneck, IBï¼‰åŸç†æ‰©å±•**çš„é€šä¿¡é«˜æ•ˆååŒæ„ŸçŸ¥æ¡†æ¶ï¼Œé¦–æ¬¡å»ºç«‹è¯¥é¢†åŸŸçš„**ç†è®ºåŸºç¡€**ã€‚å…¶æ ¸å¿ƒæ˜¯â€œ**ä¿¡æ¯å‡€åŒ–ï¼ˆInformation Purificationï¼‰**â€èŒƒå¼ï¼Œè€Œéä¼ ç»Ÿçš„â€œç‰¹å¾æ“ä½œï¼ˆFeature Manipulationï¼‰â€ã€‚

#### æ ¸å¿ƒåˆ›æ–°æ¨¡å—ï¼š
1. **Information-Aware Encoding (IAE)**  
   - åŸºäºæ‰©å±•çš„ IB åŸç†ï¼Œå°†é«˜ç»´ä¸­é—´ç‰¹å¾ $Z$ æ˜ å°„ä¸ºæä½ç»´çš„ä¿¡æ¯æ„ŸçŸ¥ç‰¹å¾ $E \in \mathbb{R}^D$ï¼ˆ$D \ll C\times H\times W$ï¼‰ï¼Œä¿ç•™ä»»åŠ¡ç›¸å…³æœ€å°å……åˆ†ä¿¡æ¯ã€‚
   - å¼•å…¥å˜åˆ†è¿‘ä¼¼å»ºæ¨¡ $E$ çš„åˆ†å¸ƒï¼Œä¾¿äºè®­ç»ƒä¸­çš„ KL æ­£åˆ™åŒ–ä¸é‡å‚æ•°åŒ–æŠ€å·§ã€‚

2. **Sparse Mask Generation (SMG)**  
   - ç”Ÿæˆç¨€ç–ç©ºé—´æ©ç  $M$ æ¥è¡¥å¿å‹ç¼©è¿‡ç¨‹ä¸­ä¸¢å¤±çš„ç©ºé—´çº¿ç´¢ã€‚
   - åŒ…å«ä¸¤ä¸ªè½»é‡æ­¥éª¤ï¼š
     - **Filtering**: ä»…ä¿ç•™ top-$k$ æœ€é‡è¦çš„ç©ºé—´ä½ç½®ï¼ˆä¿ç•™ç‡ $\alpha=0.1$ï¼‰ï¼›
     - **Quantization**: ä½¿ç”¨ 4-bit é‡åŒ–è¿›ä¸€æ­¥å‹ç¼©ã€‚
   - æ€»é€šä¿¡æˆæœ¬æä½ï¼ˆKBçº§ï¼‰ï¼Œä½†æä¾›å…³é”®ç©ºé—´å…ˆéªŒã€‚

3. **Multi-Scale Decoding (MSD)**  
   - æ¥æ”¶ç«¯é‡‡ç”¨æ©ç å¼•å¯¼çš„æ¸è¿›å¼è§£ç æœºåˆ¶ï¼Œé€æ­¥æ¢å¤ BEV ç‰¹å¾ã€‚
   - åˆ©ç”¨ $E$ å’Œ $M$ è”åˆé‡æ„ï¼Œé¿å…ç®€å•é‡å»ºå¯¼è‡´çš„ä¿¡æ¯æŸå¤±ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | InfoCom | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ Where2comm, ERMVPï¼‰ |
|------|--------|-------------------------------|
| **é€šä¿¡è§„æ¨¡** | **KBçº§**ï¼ˆ~7.875 KBï¼‰ | MBçº§ï¼ˆ3.4 MB ~ 34.3 MBï¼‰ |
| **ç†è®ºåŸºç¡€** | âœ… åŸºäº IB çš„ä¿¡æ¯è®ºåˆ†æ | âŒ å¤šä¸ºå¯å‘å¼è®¾è®¡ |
| **ä¿¡æ¯å¤„ç†æ–¹å¼** | ä¿¡æ¯å‡€åŒ–ï¼ˆæå–æœ€å°å……åˆ†ä¿¡æ¯ï¼‰ | ç‰¹å¾é€‰æ‹©/å‹ç¼©ï¼ˆä»ä¼ é€’å†—ä½™ç»“æ„ï¼‰ |
| **æ¨¡å—å…¼å®¹æ€§** | âœ… æ’ä»¶å¼è®¾è®¡ï¼Œå¯é›†æˆåˆ°ä»»æ„æ¨¡å‹ | âš ï¸ éœ€å®šåˆ¶åŒ–ä¿®æ”¹ |
| **æ€§èƒ½è¡¨ç°** | æ¥è¿‘æ ‡å‡†åä½œç²¾åº¦ | æ˜æ˜¾ä½äºæ ‡å‡†åä½œ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ä¸‰ä¸ªä»£è¡¨æ€§ååŒæ„ŸçŸ¥æ•°æ®é›†ä¸Šè¿›è¡ŒéªŒè¯ï¼š
- **OPV2V** (Xu et al., 2021)ï¼šä»¿çœŸ V2V æ•°æ®é›†
- **V2XSet** (Xu et al., 2022)ï¼šä»¿çœŸ V2X æ•°æ®é›†
- **DAIR-V2X** (Yu et al., 2022)ï¼šçœŸå®ä¸–ç•Œè½¦è·¯ååŒæ•°æ®é›†

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **ä¸»å¹²æ¨¡å‹**ï¼šé»˜è®¤ä½¿ç”¨ **CoAlign**ï¼ˆLu et al., 2023ï¼‰ä½œä¸ºåŸºç¡€ååŒæ„ŸçŸ¥æ¡†æ¶ï¼›åŒæ—¶æµ‹è¯• AttFuse å’Œ MKD-Cooper éªŒè¯é€šç”¨æ€§ã€‚
- **æ£€æµ‹å™¨**ï¼šPointPillars
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **3D Object Detection AP@30/50/70**ï¼ˆIoU é˜ˆå€¼ï¼‰
  - **é€šä¿¡ä½“ç§¯ï¼ˆCommunication Volumeï¼‰**ï¼šä»¥ KB æˆ– MB è¡¨ç¤ºæ¯ä»£ç†å‘é€çš„æ¶ˆæ¯æ€»é‡
- **ç¡¬ä»¶é…ç½®**ï¼šRTX 3090 GPUï¼ŒUbuntu ç³»ç»Ÿï¼ŒPyTorch 1.10

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **No Collaboration**ï¼šæ— åä½œ
- **Late Collaboration**ï¼šåæœŸèåˆï¼Œé€šä¿¡é‡æå°ï¼ˆ6.25 KBï¼‰
- **Standard Intermediate Collaboration**ï¼šå®Œæ•´ä¸­é—´ç‰¹å¾ä¼ è¾“ï¼ˆ34.375 MBï¼‰
- **Where2comm** (Hu et al., 2022)ï¼šåŸºäºç©ºé—´é‡è¦æ€§çš„ç‰¹å¾é€‰æ‹©
- **ERMVP** (Zhang et al., 2024)ï¼šåŸºäºèšç±»çš„ç©ºé—´å‹ç¼©æ–¹æ³•

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ–¹æ³• | é€šä¿¡ä½“ç§¯ | OPV2V AP@50 | V2XSet AP@50 | DAIR-V2X AP@50 |
|------|----------|-------------|--------------|----------------|
| Standard Colla. | 34.375 MB | 0.9653 | 0.9212 | 0.7843 |
| Where2comm | 3.439 MB | 0.9463 | 0.8604 | 0.7539 |
| ERMVP | 0.741 MB | 0.9557 | OOM | 0.7791 |
| **InfoCom (Ours)** | **7.875 KB** | **0.9650** | **0.9273** | **0.7789** |

> æ³¨ï¼šInfoCom åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šå‡è¾¾åˆ°æ¥è¿‘ç”šè‡³è¶…è¶Šæ ‡å‡†åä½œçš„æ€§èƒ½ï¼Œä¸”é€šä¿¡é‡ä»…ä¸ºåè€…çš„ **1/4000~1/440**ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **é€šä¿¡æ•ˆç‡æå‡æ˜¾è‘—**ï¼š
  - ç›¸æ¯” **Where2comm**ï¼šé€šä¿¡é‡å‡å°‘ **440å€**
  - ç›¸æ¯” **ERMVP**ï¼šé€šä¿¡é‡å‡å°‘ **90å€**
  - ç›¸æ¯”æ ‡å‡†åä½œï¼šå‡å°‘è¶…è¿‡ **4000å€**
- **æ„ŸçŸ¥æ€§èƒ½æ›´ä¼˜**ï¼š
  - åœ¨ V2XSet ä¸Šï¼ŒERMVP å› å†…å­˜æº¢å‡ºï¼ˆOOMï¼‰å¤±è´¥ï¼Œè€Œ InfoCom æˆåŠŸè¿è¡Œå¹¶å–å¾—æœ€ä½³æ€§èƒ½ã€‚
  - InfoCom åœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šä¼˜äºæˆ–æŒå¹³äºæ ‡å‡†åä½œï¼Œå°¤å…¶åœ¨å¤æ‚åœºæ™¯ä¸­è¡¨ç°å‡ºæ›´å¼ºé²æ£’æ€§ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰

| å˜ä½“ | Mean AP | åˆ†æ |
|------|---------|------|
| Full InfoCom | 0.9518 | åŸºçº¿ |
| æ›¿æ¢ IAE ä¸º Simple Encoder | 0.9320 | â†“2%ï¼Œè¯´æ˜ IAE å¯¹ä¿¡æ¯æå–è‡³å…³é‡è¦ |
| ç§»é™¤ SMG å¤šç²’åº¦ç»“æ„ | 0.9379 | â†“1.4%ï¼Œå¤šå°ºåº¦ç©ºé—´å»ºæ¨¡æœ‰æ•ˆ |
| ç§»é™¤ STEï¼ˆæ¢¯åº¦ä¼°è®¡ï¼‰ | 0.8845 | â†“6.7%ï¼Œè¯æ˜éå¯å¯¼æ“ä½œéœ€åˆç†æ¢¯åº¦ä¼ æ’­ |
| ç§»é™¤ Mask å¼•å¯¼ | 0.8839 | â†“6.8%ï¼Œç©ºé—´å…ˆéªŒå¯¹é‡å»ºè‡³å…³é‡è¦ |
| ç§»é™¤ Multi-Scale Rec. | 0.9439 | â†“0.8%ï¼Œæ¸è¿›è§£ç æœ‰åŠ©äºç»†èŠ‚æ¢å¤ |

> ç»“æœè¡¨æ˜ä¸‰å¤§æ¨¡å—å‡ä¸å¯æˆ–ç¼ºï¼Œå°¤å…¶æ˜¯ **Mask-Guided Reconstruction** å¯¹æ€§èƒ½å½±å“æœ€å¤§ã€‚

### å…¶ä»–è¡¥å……å®éªŒ
- **è·¨æ¨¡å‹å…¼å®¹æ€§æµ‹è¯•ï¼ˆTable 2ï¼‰**ï¼š
  - å°† InfoCom é›†æˆåˆ°å¼± backbone å¦‚ AttFuse å’Œ MKD-Cooper ä¸­ï¼Œ**åè€Œæå‡äº†åŸå§‹æ¨¡å‹æ€§èƒ½ï¼ˆ+1.27% mean APï¼‰**ï¼Œè¯´æ˜å…¶å…·å¤‡â€œç‰¹å¾å¢å¼ºâ€èƒ½åŠ›ã€‚
- **é€šä¿¡é‡éšæ™ºèƒ½ä½“æ•°é‡å¢é•¿ï¼ˆTable 4ï¼‰**ï¼š
  - InfoCom çš„æ€»é€šä¿¡é‡å‘ˆçº¿æ€§å¢é•¿ï¼Œå§‹ç»ˆä¿æŒåœ¨ KB çº§åˆ«ï¼ˆå¦‚ 5 è½¦æ—¶ä»… 31.5 KBï¼‰ï¼Œè¿œä½äºå…¶ä»–æ–¹æ³•ï¼ˆERMVP è¾¾ 2.965 MBï¼‰ã€‚
- **å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆFigure 7ï¼‰**ï¼š
  - è¶…å‚ $\beta$ï¼ˆæ§åˆ¶ IB æƒè¡¡ï¼‰å¯¹æ€§èƒ½å½±å“è¾ƒå°ï¼Œè¡¨æ˜ç³»ç»Ÿå…·æœ‰è‰¯å¥½çš„ç¨³å®šæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **KBçº§é€šä¿¡å¯è¡Œä¸”é«˜æ•ˆ**ï¼šInfoCom é¦–æ¬¡å®ç°äº† **kilobyte-scale çš„è¿‘æ— æŸååŒæ„ŸçŸ¥**ï¼Œçªç ´äº†ä¼ ç»Ÿ MB çº§é€šä¿¡å‡è®¾ã€‚
2. **ä¿¡æ¯å‡€åŒ–ä¼˜äºç‰¹å¾æ“ä½œ**ï¼šä»â€œä¼ é€’å†—ä½™ç‰¹å¾â€è½¬å‘â€œæå–æœ€å°å……åˆ†ä¿¡æ¯â€ï¼Œä»æ ¹æœ¬ä¸Šè§£å†³äº†å‹ç¼©ä¸ä¿çœŸçš„çŸ›ç›¾ã€‚
3. **ç†è®ºæŒ‡å¯¼å®è·µ**ï¼šåŸºäº IB çš„ä¿¡æ¯è®ºåˆ†æä¸ºé€šä¿¡-æ€§èƒ½æƒè¡¡æä¾›äº†æ•°å­¦ä¾æ®ï¼Œæ¨åŠ¨ååŒæ„ŸçŸ¥ä»ç»éªŒè®¾è®¡èµ°å‘ç†è®ºé©±åŠ¨ã€‚
4. **æ’ä»¶å¼æ¶æ„å®ç”¨æ€§å¼º**ï¼šæ— éœ€æ”¹åŠ¨ä¸»å¹²ç½‘ç»œï¼Œä»…æ›¿æ¢é€šä¿¡å±‚å³å¯éƒ¨ç½²ï¼Œé€‚ç”¨äºå¤šç§ååŒæ„ŸçŸ¥ç³»ç»Ÿã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¶ˆæ¯å•å…ƒä»…åŒ…å«**è¯­ä¹‰ä¿¡æ¯ $E$** å’Œ**ç©ºé—´çº¿ç´¢ $M$**ï¼Œå°šæœªå¼•å…¥**æ—¶é—´åŠ¨æ€ä¿¡æ¯**ï¼ˆå¦‚è¿åŠ¨è¶‹åŠ¿ã€å†å²çŠ¶æ€ï¼‰ã€‚
- æç«¯å‹ç¼©å¯èƒ½å¯¼è‡´æŸäº›è¾¹ç¼˜æ¡ˆä¾‹ï¼ˆå¦‚ç½•è§ç‰©ä½“ã€å‰§çƒˆé®æŒ¡ï¼‰æ¼æ£€ï¼Œå°½ç®¡æ•´ä½“æ€§èƒ½ç¨³å®šã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•æ¶ˆæ¯æ ¼å¼ä¸ºä¸‰å…ƒç»„ï¼š$(E, M, T)$ï¼ŒåŠ å…¥**æ—¶é—´çº¿ç´¢ï¼ˆTemporal Cuesï¼‰**ï¼Œå®ç°åŠ¨æ€ä¼ è¾“å†³ç­–ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„é‡åŒ–ç­–ç•¥ï¼ˆå¦‚è‡ªé€‚åº”æ¯”ç‰¹åˆ†é…ï¼‰å’Œç¼–ç æ–¹æ¡ˆï¼ˆå¦‚ç†µç¼–ç ï¼‰è¿›ä¸€æ­¥é™ä½å¸¦å®½ã€‚
- åœ¨çœŸå®é“è·¯ç¯å¢ƒä¸­éƒ¨ç½²å¹¶æµ‹è¯•ç«¯åˆ°ç«¯å»¶è¿Ÿä¸å¯é æ€§ã€‚

---

> âœ… **ä¸€å¥è¯æ€»ç»“**ï¼š  
> InfoCom æ˜¯é¦–ä¸ªåŸºäºä¿¡æ¯ç“¶é¢ˆç†è®ºå®ç° **KBçº§é€šä¿¡ã€è¿‘æ— æŸæ„ŸçŸ¥** çš„ååŒæ„ŸçŸ¥æ¡†æ¶ï¼Œé€šè¿‡ **ä¿¡æ¯å‡€åŒ–èŒƒå¼** å½»åº•é‡æ„äº†é€šä¿¡æœºåˆ¶ï¼Œåœ¨æ•ˆç‡ã€æ€§èƒ½ä¸ç†è®ºæ·±åº¦ä¸Šå…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚

</details>

---

### 7. [Neuronal Attention Circuit (NAC) for Representation Learning](https://arxiv.org/abs/2512.10282)

**Authors**: Waleed Razzaq, Izis Kankaraway, Yun-Bo Zhao  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.10282v1  

#### Abstract
Attention improves representation learning over RNNs, but its discrete nature limits continuous-time (CT) modeling. We introduce Neuronal Attention Circuit (NAC), a novel, biologically plausible CT-Attention mechanism that reformulates attention logits computation as the solution to a linear first-o...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šNeuronal Attention Circuit (NAC) for Representation Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ä¼ ç»Ÿ Attention æœºåˆ¶åŸºäºç¦»æ•£æ—¶é—´æ“ä½œï¼ˆå¦‚ scaled dot-productï¼‰ï¼Œéš¾ä»¥æœ‰æ•ˆå»ºæ¨¡**è¿ç»­æ—¶é—´ï¼ˆContinuous-Time, CTï¼‰åŠ¨æ€ç³»ç»Ÿ**ï¼Œå°¤å…¶åœ¨å¤„ç†**ä¸è§„åˆ™é‡‡æ ·æ—¶åºæ•°æ®**ï¼ˆirregularly sampled time seriesï¼‰æ—¶å­˜åœ¨å±€é™ã€‚åŒæ—¶ï¼Œç°æœ‰ CT-Attention æ–¹æ³•è®¡ç®—å¼€é”€å¤§ã€å¯¹ ODE æ±‚è§£å™¨æ•æ„Ÿï¼Œä¸”ç¼ºä¹ç”Ÿç‰©å¯è§£é‡Šæ€§ã€‚

æ­¤å¤–ï¼Œæ ‡å‡† Attention çš„å¯†é›†æŠ•å½±ï¼ˆdense projectionsï¼‰å¯¼è‡´é«˜å†…å­˜æ¶ˆè€—ï¼Œé™åˆ¶äº†å…¶åœ¨é•¿åºåˆ—ä¸Šçš„æ‰©å±•èƒ½åŠ›ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **Neuronal Attention Circuit (NAC)**ï¼Œä¸€ç§å—ç”Ÿç‰©å­¦å¯å‘çš„ã€é€‚ç”¨äºè¡¨ç¤ºå­¦ä¹ çš„æ–°å‹è¿ç»­æ—¶é—´æ³¨æ„åŠ›æœºåˆ¶ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- å°† **Attention logits çš„è®¡ç®—é‡æ–°è¡¨è¿°ä¸ºä¸€ä¸ªä¸€é˜¶çº¿æ€§ ODE çš„è§£**ï¼Œè¯¥ ODE ç”±éçº¿æ€§ã€äº’è¿çš„é—¨æ§æœºåˆ¶è°ƒåˆ¶ã€‚
- é—¨æ§æœºåˆ¶æºè‡ªå¯¹ *C. elegans* ç¥ç»å›è·¯ç­–ç•¥ï¼ˆNeuronal Circuit Policies, NCPsï¼‰çš„å¤ç”¨ï¼Œèµ‹äºˆæ¨¡å‹**ç”Ÿç‰©å¯è§£é‡Šæ€§**å’Œ**ç¨€ç–è¿æ¥ç»“æ„**ã€‚
- å¼•å…¥ä¸‰ç§è®¡ç®—æ¨¡å¼ï¼š
  - **Euler**ï¼šæ˜¾å¼æ¬§æ‹‰ç§¯åˆ†è¿‘ä¼¼
  - **Exact**ï¼šé—­å¼è§£æè§£
  - **Steady**ï¼šç¨³æ€è¿‘ä¼¼ï¼ˆç±»æ ‡å‡† Attentionï¼‰
- è®¾è®¡ **Sparse Top-K Pairwise Concatenation** æ–¹æ¡ˆï¼Œä»…ä¿ç•™æœ€ç›¸å…³çš„ key-query å¯¹ï¼Œæ˜¾è‘—é™ä½å†…å­˜å¼ºåº¦ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **ç”Ÿç‰©å¯è§£é‡Šæ€§** | å€Ÿé‰´ *C. elegans* ç¥ç»å›è·¯ç»“æ„ï¼Œå®ç°ç¨€ç–ã€æ¨¡å—åŒ–ã€å¯è§£é‡Šçš„ç¥ç»æ¶æ„ |
| **è¿ç»­æ—¶é—´å»ºæ¨¡** | æ”¯æŒ CT åŠ¨æ€æ¼”åŒ–ï¼Œä¼˜äº DT-RNN å’Œæ ‡å‡† Attention åœ¨ä¸è§„åˆ™åºåˆ—ä¸Šçš„è¡¨ç° |
| **æ•ˆç‡ä¸å¯æ‰©å±•æ€§** | ç¨€ç–é—¨æ§ + Top-K é€‰æ‹©å¤§å¹…å‡å°‘å†…å­˜å ç”¨ï¼Œä¼˜äº mTANã€ContiFormer ç­‰ CT-Attention |
| **ç†è®ºä¿éšœ** | æä¾›çŠ¶æ€ç¨³å®šæ€§ã€è¯¯å·®æŒ‡æ•°ç•Œã€é€šç”¨é€¼è¿‘å®šç†ç­‰ä¸¥æ ¼æ•°å­¦è¯æ˜ |
| **çµæ´»æ€§** | æ”¯æŒå¤šç§è®¡ç®—æ¨¡å¼ï¼Œåœ¨ç²¾åº¦ä¸é€Ÿåº¦é—´çµæ´»æƒè¡¡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

å®éªŒè¦†ç›–ä¸‰å¤§é¢†åŸŸï¼ŒéªŒè¯æ³›åŒ–èƒ½åŠ›ï¼š

| é¢†åŸŸ | æ•°æ®é›† | ç‰¹ç‚¹ |
|------|--------|------|
| **ä¸è§„åˆ™æ—¶åºåˆ†ç±»** | Event-based MNIST (E-MNIST)<br>Person Activity Recognition (PAR) | ä¸è§„åˆ™äº‹ä»¶æµæ•°æ®ï¼Œæµ‹è¯•æ¨¡å‹å¯¹æ—¶é—´ä¾èµ–å»ºæ¨¡èƒ½åŠ› |
| **è‡ªåŠ¨é©¾é©¶è½¦é“ä¿æŒ** | OpenAI CarRacing<br>Udacity Self-Driving Car Simulator | è§†è§‰è¾“å…¥ + æ§åˆ¶è¾“å‡ºï¼Œå‰è€…ä¸ºç¦»æ•£åŠ¨ä½œåˆ†ç±»ï¼Œåè€…ä¸ºè¿ç»­è½¬å‘é¢„æµ‹ |
| **å·¥ä¸šé¢„æµ‹æ€§ç»´æŠ¤** | PRONOSTIA<br>XJTU-SY<br>HUST | è½´æ‰¿æŒ¯åŠ¨ä¿¡å·ç”¨äºå‰©ä½™ä½¿ç”¨å¯¿å‘½ï¼ˆRULï¼‰ä¼°è®¡ï¼Œè·¨å·¥å†µè¿ç§»æµ‹è¯• |

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **è®­ç»ƒæ–¹å¼**ï¼š5æŠ˜äº¤å‰éªŒè¯ï¼Œä½¿ç”¨ BPTT è¿›è¡Œæ¢¯åº¦æ›´æ–°ã€‚
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šGoogle Colab T4 GPUã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - åˆ†ç±»ä»»åŠ¡ï¼šAccuracy (â†‘)
  - å›å½’ä»»åŠ¡ï¼ˆUdacityï¼‰ï¼šMSE / MAE (â†“)
  - RUL ä¼°è®¡ï¼šScore (â†“)ï¼ŒIEEE PHM å®˜æ–¹ä¸å¯¹ç§°è¯„åˆ†å‡½æ•°
- **æ¨¡å‹ç»´åº¦ç»Ÿä¸€**ï¼šæ‰€æœ‰ baseline ä¸ NAC ä½¿ç”¨ç›¸åŒçš„ `d_model` å’Œ attention heads æ•°é‡ä»¥ä¿è¯å…¬å¹³æ¯”è¾ƒã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

æ¶µç›–å››å¤§ç±»ä¸»æµæ¨¡å‹ï¼š

| ç±»å‹ | åŸºçº¿æ–¹æ³• |
|------|---------|
| **DT-RNNs** | RNN, LSTM, GRU |
| **CT-RNNs** | CT-RNN, PhasedLSTM, GRU-ODE, mmRNN, LTC, CfC |
| **DT-Attention** | Attention, MHA |
| **CT-Attention** | mTAN, CTA, ODEFormer, ContiFormer |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table Iï¼‰**

#### âœ… **ä¸è§„åˆ™æ—¶åºåˆ†ç±»**

| æ¨¡å‹ | E-MNIST (â†‘) | PAR (â†‘) |
|------|------------|--------|
| **NAC-PW** | **96.64Â±0.12** | **89.15Â±1.01** |
| GRU-ODE | 96.04Â±0.13 | 89.01Â±1.55 |
| NAC-Exact/05s/8k | 96.12Â±0.11 | 89.01Â±1.01 |

> NAC-PW åœ¨ä¸¤é¡¹ä»»åŠ¡ä¸Šå‡å–å¾— SOTA è¡¨ç°ã€‚

#### âœ… **è‡ªåŠ¨é©¾é©¶è½¦é“ä¿æŒ**

| æ¨¡å‹ | CarRacing Accuracy (â†‘) | Udacity MSE (â†“) |
|------|------------------------|----------------|
| **NAC-PW** | **80.72Â±0.41** | 0.0177Â±0.0008 |
| **NAC-32k** | 80.38Â±0.16 | **0.0170Â±0.0007** |
| ContiFormer | 80.47Â±0.50 | 0.0174Â±0.01 |

> NAC åœ¨ä¸¤ç±»é©¾é©¶æ¨¡æ‹Ÿä¸­å‡è¾¾åˆ°æœ€ä¼˜æˆ–æ¬¡ä¼˜æ€§èƒ½ã€‚

#### âœ… **å·¥ä¸š RUL é¢„æµ‹ï¼ˆScore â†“ï¼‰**

| æ¨¡å‹ | PRONOSTIA | XJTU-SY | HUST |
|------|----------|--------|------|
| **NAC-Exact/05s/8k** | 37.75 | **19.87** | **27.82** |
| **NAC-PW** | 37.50 | 28.01 | 30.14 |
| ContiFormer | **27.82** | 34.71 | 43.81 |

> NAC åœ¨è·¨æ•°æ®é›†éªŒè¯ä¸­è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨ XJTU-SY å’Œ HUST ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **æ€»ä½“è¡¨ç°**ï¼šNAC åœ¨å¤šæ•°ä»»åŠ¡ä¸­**åŒ¹é…æˆ–è¶…è¶Š**æœ€å…ˆè¿›çš„ CT å’Œ DT æ¨¡å‹ã€‚
- **å†…å­˜æ•ˆç‡**ï¼šç›¸æ¯” mTANï¼ˆå³°å€¼å†…å­˜ 790MBï¼‰ã€ContiFormerï¼ˆ67.7MBï¼‰ï¼ŒNAC-2k ä»…éœ€ **44.75MB**ï¼›å³ä½¿ä½¿ç”¨å…¨é…å¯¹ï¼ˆNAC-PWï¼‰ä¹Ÿä½“ç°åˆç†è®¾è®¡ä¸‹çš„å¯æ§å¢é•¿ã€‚
- **è¿è¡Œæ—¶é—´**ï¼šNAC è¿è¡Œæ—¶é—´ä»‹äº CT-RNN ä¸ CT-Attention ä¹‹é—´ï¼Œä¼˜äº GRU-ODEã€LTC ç­‰é‡å‹ ODE æ¨¡å‹ï¼ˆè§ Table 2ï¼‰ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰**

| å˜ä½“ | æè¿° | å‘ç° |
|------|------|------|
| **NAC-2k vs NAC-32k** | Top-K=2 vs 32 | æ›´å¤š Top-K æå‡ç²¾åº¦ä½†å¢åŠ å†…å­˜ï¼›K=8 æ˜¯å¹³è¡¡ç‚¹ |
| **NAC-02s vs NAC-09s** | 20% vs 90% sparsity | æ›´é«˜ sparsity æå‡é²æ£’æ€§å’Œå‡†ç¡®æ€§ |
| **NAC-FC** | å…¨è¿æ¥æ›¿ä»£ NCP é—¨æ§ | æ€§èƒ½ä¸‹é™ï¼Œè¯´æ˜ NCP ç»“æ„æœ‰æ•ˆæ€§ |
| **NAC-Euler / Exact / Steady** | ä¸åŒ ODE æ±‚è§£æ¨¡å¼ | Exact å¹³è¡¡ç²¾åº¦ä¸æ•ˆç‡ï¼›Steady æœ€å¿«ï¼›Euler é€‚åˆè‡ªé€‚åº”åŠ¨æ€ |

> **æœ€ä½³é…ç½®**ï¼š`Top-K=8`, `sparsity=50%`, `Exact mode` å®ç°ç²¾åº¦ä¸æ•ˆç‡çš„æœ€ä½³æƒè¡¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **NAC æˆåŠŸå°†ç”Ÿç‰©ç¥ç»å›è·¯åŸç†å¼•å…¥ Attention æœºåˆ¶**ï¼Œå®ç°äº†å…·æœ‰ç”Ÿç‰©å¯è§£é‡Šæ€§çš„ CT-Attention æ¶æ„ã€‚
2. âœ… **Attention logits å¯è¢«å»ºæ¨¡ä¸º ODE è§£**ï¼Œè‡ªç„¶æ”¯æŒè¿ç»­æ·±åº¦æ¼”åŒ–ï¼Œæ¡¥æ¥äº†ç¦»æ•£å±‚ä¸åŠ¨æ€ç³»ç»Ÿçš„é¸¿æ²Ÿã€‚
3. âœ… **ç¨€ç–é—¨æ§ + Top-K æœºåˆ¶æ˜¾è‘—é™ä½å†…å­˜å¼€é”€**ï¼Œä½¿ NAC åœ¨é•¿åºåˆ—åœºæ™¯æ›´å…·å®ç”¨æ€§ã€‚
4. âœ… **ç†è®ºåˆ†æå®Œå¤‡**ï¼šè¯æ˜äº†çŠ¶æ€ç¨³å®šæ€§ã€æŒ‡æ•°æ”¶æ•›æ€§ã€é€šç”¨é€¼è¿‘èƒ½åŠ›ï¼Œä¸ºæ¨¡å‹å¯é æ€§æä¾›ä¿éšœã€‚
5. âœ… **å®è¯æ€§èƒ½ä¼˜è¶Š**ï¼šåœ¨å¤šä¸ªçœŸå®ä¸–ç•Œä»»åŠ¡ä¸­è¾¾åˆ° SOTA æˆ–æ¥è¿‘æœ€ä¼˜ï¼Œå°¤å…¶åœ¨è·¨åŸŸ RUL é¢„æµ‹ä¸­å±•ç°å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

1. **å›ºå®š Wiring ç»“æ„**ï¼šå½“å‰ä¾èµ–é¢„å®šä¹‰çš„ NCP è¿æ¥å›¾ï¼ˆå¦‚ AutoNCPï¼‰ï¼Œçµæ´»æ€§å—é™ï¼Œæ¶æ„å°ºå¯¸è¾ƒå¤§ã€‚
2. **Top-K çš„å±€é™æ€§**ï¼š
   - ä»éœ€è®¡ç®—å®Œæ•´ QK^T å¾—åˆ†çŸ©é˜µï¼Œå¯¹æé•¿åºåˆ—ä»å¯èƒ½æˆä¸ºç“¶é¢ˆã€‚
   - å›ºå®š K å€¼ä¸å¤Ÿè‡ªé€‚åº”ï¼Œå¯èƒ½é—æ¼é‡è¦ä¸Šä¸‹æ–‡ã€‚
3. **è®¡ç®—å¤æ‚åº¦**ï¼šå°½ç®¡ä¼˜åŒ–åä¼˜äºéƒ¨åˆ† CT æ¨¡å‹ï¼Œä½†æ•´ä½“ä»é«˜äºæ ‡å‡† Attentionï¼ˆO(nÂ²k) vs O(nk)ï¼‰ã€‚
4. **ç¡¬ä»¶é€‚é…ä¸è¶³**ï¼šå°šæœªé’ˆå¯¹è¾¹ç¼˜è®¾å¤‡è¿›è¡Œé‡åŒ–æˆ–éƒ¨ç½²ä¼˜åŒ–ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **å¯å­¦ä¹  Wiring**ï¼šæ”¯æŒç”¨æˆ·è‡ªå®šä¹‰æˆ–éšæœºç”Ÿæˆ NCP é…ç½®ï¼Œæå‡çµæ´»æ€§ä¸æ•ˆç‡ã€‚
2. **å¯å­¦ä¹  Top-K æœºåˆ¶**ï¼šå¼•å…¥ adaptive æˆ– learned sparse attention selectionï¼Œé¿å…æ‰‹åŠ¨è®¾å®š Kã€‚
3. **æ”¹è¿› Key Scoring**ï¼šè®¾è®¡æ›´é«˜æ•ˆçš„ key relevance è¯„ä¼°å‡½æ•°ï¼Œå‡å°‘å†—ä½™è®¡ç®—ã€‚
4. **ç¡¬ä»¶æ„ŸçŸ¥ä¼˜åŒ–**ï¼šç»“åˆè¾¹ç¼˜è®¡ç®—éœ€æ±‚ï¼Œå¼€å‘ä½å»¶è¿Ÿã€ä½åŠŸè€—ç‰ˆæœ¬ã€‚
5. **æ‰©å±•è‡³å…¶ä»–æ¨¡æ€**ï¼šæ¢ç´¢åœ¨è¯­éŸ³ã€è§†é¢‘ã€å›¾ç»“æ„æ•°æ®ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

---

> ğŸ”— **ä»£ç å¼€æº**ï¼šhttps://github.com/itxwaleedrazzaq/neuronal_attention_circuit  
> ğŸ“Œ **å½±å“å£°æ˜**ï¼šæ¨åŠ¨ç¨€ç–ã€è‡ªé€‚åº”ã€ç±»è„‘ç¥ç»ç½‘ç»œå‘å±•ï¼Œé€‚ç”¨äºèµ„æºå—é™åœºæ™¯ï¼Œä½†ä¹Ÿéœ€å…³æ³¨å…¶åœ¨ç›‘æ§ä¸è‡ªä¸»ç³»ç»Ÿä¸­çš„ä¼¦ç†é£é™©ã€‚

</details>

---

### 8. [Zero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation](https://arxiv.org/abs/2512.10501)

**Authors**: Lim Chien Her, Ming Yan, Yunshu Bai, Ruihao Li, Hao Zhang  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.10501v1  

#### Abstract
Procedural Content Generation (PCG) offers scalable methods for algorithmically creating complex, customizable worlds. However, controlling these pipelines requires the precise configuration of opaque technical parameters. We propose a training-free architecture that utilizes LLM agents for zero-sho...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šZero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **Procedural Content Generation (PCG)** å·¥å…·è™½ç„¶èƒ½é«˜æ•ˆç”Ÿæˆå¤æ‚è™šæ‹Ÿç¯å¢ƒï¼ˆå¦‚æ¸¸æˆåœ°å›¾ï¼‰ï¼Œä½†å…¶å‚æ•°é…ç½®é«˜åº¦æŠ€æœ¯åŒ–ã€éç›´è§‚ä¸”è¯­ä¹‰æ¨¡ç³Šï¼Œå¯¼è‡´æ™®é€šç”¨æˆ·éš¾ä»¥æœ‰æ•ˆæ§åˆ¶ã€‚å°½ç®¡ **Large Language Models (LLMs)** è¢«å°è¯•ç”¨äºè‡ªç„¶è¯­è¨€é©±åŠ¨ PCGï¼Œä½†ç°æˆï¼ˆoff-the-shelfï¼‰æ¨¡å‹åœ¨ç†è§£æŠ½è±¡æŒ‡ä»¤ä¸å…·ä½“å‚æ•°ä¹‹é—´çš„â€œè¯­ä¹‰é¸¿æ²Ÿâ€ä¸Šè¡¨ç°ä¸ä½³ï¼Œå¸¸å‡ºç°å‚æ•°å¹»è§‰æˆ–é”™è¯¯é…ç½®ã€‚

æ­¤å¤–ï¼Œå½“å‰ä¸»æµæ–¹æ³•ä¾èµ–äº**ä»»åŠ¡ç‰¹å®šçš„ fine-tuningã€å¼ºåŒ–å­¦ä¹ æˆ–é¢†åŸŸé¢„è®­ç»ƒ**ï¼Œè¿™äº›æ–¹æ³•æˆæœ¬é«˜ã€æ³›åŒ–èƒ½åŠ›å·®ï¼Œéš¾ä»¥è¿ç§»åˆ°æ–°çš„å·¥å…·æˆ–é¢†åŸŸã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡ºä¸€ç§**æ— éœ€è®­ç»ƒçš„åŒæ™ºèƒ½ä½“æ¶æ„ï¼ˆDual-Agent Actor-Critic Architectureï¼‰**ï¼Œå®ç°å¯¹ PCG å·¥å…·çš„é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰æ§åˆ¶ï¼š

- **Actor Agent**ï¼šä½œä¸ºè¯­ä¹‰è§£é‡Šå™¨ï¼Œå°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æç¤ºï¼ˆnatural language promptï¼‰è½¬åŒ–ä¸ºåˆæ­¥çš„ **Parameter Trajectory Sequence**ï¼ˆå³ä¸€ç³»åˆ—ç®—æ³•è°ƒç”¨åŠå…¶å‚æ•°é…ç½®ï¼‰ã€‚
- **Critic Agent**ï¼šä½œä¸ºé™æ€éªŒè¯å™¨ï¼ŒåŸºäºæä¾›çš„ **API æ–‡æ¡£** å’Œ **å‚è€ƒç¤ºä¾‹** å¯¹ Actor æå‡ºçš„è½¨è¿¹è¿›è¡ŒåŠŸèƒ½æ­£ç¡®æ€§æ£€æŸ¥ï¼Œè¯†åˆ«å¹¶åé¦ˆâ€œé˜»å¡æ€§é—®é¢˜â€ï¼ˆblocking issuesï¼‰ï¼Œä¾‹å¦‚æ— æ•ˆå‚æ•°ã€è¶Šç•Œå€¼æˆ–ä¸å…¼å®¹çš„ç®—æ³•ç»„åˆã€‚
- ä¸¤è€…é€šè¿‡**è¿­ä»£å¯¹è¯æœºåˆ¶**ä¸æ–­ä¼˜åŒ–å‚æ•°é…ç½®ï¼Œç›´åˆ° Critic æ‰¹å‡†æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚

è¯¥æ¡†æ¶å®Œå…¨ä¾èµ– **In-Context Learning (ICL)**ï¼Œæ— éœ€ä»»ä½•æ¨¡å‹å¾®è°ƒæˆ–é¢å¤–æ•°æ®æ”¶é›†ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | æœ¬æ–¹æ³•ä¼˜åŠ¿ |
|------|-----------|
| **æ— éœ€è®­ç»ƒ** | å®Œå…¨åŸºäº off-the-shelf LLMsï¼Œä»…éœ€æ›´æ¢æ–‡æ¡£å³å¯é€‚é…æ–°å·¥å…·ï¼Œé¿å…æ˜‚è´µçš„ fine-tuning æˆ– RL æµç¨‹ |
| **æ›´å¼ºæ³›åŒ–æ€§** | ä¸ä¾èµ–ç‰¹å®šæ•°æ®é›†æˆ–çŸ¥è¯†åº“ï¼Œé€‚ç”¨äºä»»æ„å…·æœ‰æ–‡æ¡£æ”¯æŒçš„ PCG å·¥å…· |
| **æ›´é«˜å¯é æ€§** | åŒæ™ºèƒ½ä½“åˆ†ç¦»â€œåˆ›æ„ç”Ÿæˆâ€ä¸â€œé€»è¾‘éªŒè¯â€ï¼Œæ˜¾è‘—å‡å°‘å‚æ•°å¹»è§‰å’Œè‡´å‘½é”™è¯¯ |
| **æ›´æ˜“éƒ¨ç½²** | æ¶æ„è½»é‡ï¼Œä»…éœ€æä¾›æ–‡æ¡£å’Œç¤ºä¾‹ï¼Œæ— éœ€æ„å»ºå¤æ‚çš„ retrieval pipeline æˆ– adapter æ¨¡å— |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„å¹³å°ä¸å·¥å…·
- å®éªŒåŸºäº Unity å¼•æ“ä¸­çš„ **TileWorldCreator** æ’ä»¶ï¼Œç”¨äºç”Ÿæˆ 2D å’Œ 3D åœ°å½¢åœ°å›¾ã€‚
- æ‰€æœ‰ LLM æ¨ç†é€šè¿‡ **Claude 3.5 Sonnet API** å®Œæˆã€‚
- Actor å’Œ Critic å‡åŸºäº **UGenLah**ï¼ˆUnity ç¼–è¾‘å™¨ AI åŠ©æ‰‹ï¼‰ç³»ç»Ÿæ¥å£è¿è¡Œã€‚

### å®éªŒè®¾ç½®

#### Experiment I: å¤æ‚ä»»åŠ¡å¯é æ€§æµ‹è¯•ï¼ˆReliabilityï¼‰
- **ä»»åŠ¡**ï¼šç”Ÿæˆæ»¡è¶³å››ä¸ªçº¦æŸæ¡ä»¶çš„ 3D å±±åœ°åœ°å›¾ï¼š
  1. å•ä¸€å±±å³°ï¼ˆæ— å¤šä¸ªå­¤ç«‹é«˜åœ°ï¼‰
  2. æ­£å¥½ä¸‰å±‚é«˜åº¦ï¼ˆthree height layersï¼‰
  3. è‰åœ°ç‚¹ç¼€ä»…å‡ºç°åœ¨å±±é¡¶å±‚
  4. å²©çŸ³æ•£å¸ƒåœ¨éå±±åŒº
- **æ¨¡å¼**ï¼šzero-shotï¼Œä¸å…è®¸åç»­äº¤äº’ã€‚
- **è¯•éªŒæ¬¡æ•°**ï¼š10 æ¬¡ç‹¬ç«‹è¿è¡Œã€‚
- **å¯¹æ¯”æ¨¡å‹**ï¼š
  - **Proposed**: Actor-Critic åŒæ™ºèƒ½ä½“æ¶æ„
  - **Baseline**: Single-Agentï¼ˆå¸¦æ–‡æ¡£å’Œç¤ºä¾‹ï¼‰

#### Experiment II: æ•ˆç‡ä¸è‡ªä¸»æ€§è¯„ä¼°ï¼ˆEfficiencyï¼‰
- **ç›®æ ‡åœ°å›¾ç±»å‹**ï¼š4 ç§ä¸åŒç±»å‹çš„åœ°å›¾ï¼ˆ2 ä¸ª 2Dï¼Œ2 ä¸ª 3Dï¼‰ï¼Œæ¶µç›–ä¸åŒ PCG ç®—æ³•ç»„åˆï¼ˆå¦‚ Cellular Automataã€Perlin Noise ç­‰ï¼‰ã€‚
- **å…è®¸è¿­ä»£ä¿®æ­£**ï¼šè‹¥å¤±è´¥ï¼Œå¯æä¾›æè¿°æ€§åé¦ˆï¼ˆå¦‚â€œé«˜åº¦å±‚æ–­å¼€â€ï¼‰ï¼Œä½†ä¸ç»™å‡ºè§£å†³æ–¹æ¡ˆã€‚
- **å¯¹æ¯”æ¨¡å‹**ï¼š
  - **Actor-Critic**ï¼ˆåŒæ™ºèƒ½ä½“ï¼‰
  - **Single-Agent (w/ Docs)**
  - **Single-Agent (No Docs)**

### è¯„ä¼°æŒ‡æ ‡

| å®éªŒ | æŒ‡æ ‡ |
|------|------|
| **Experiment I** |  
| - **Task Success Rate (%)**ï¼šæ‰€æœ‰å…³é”®å…ƒç´ æ­£ç¡®å‡ºç°çš„æ¯”ä¾‹  
| - **Average Mistakes per Run**ï¼šæ¯è½®è¿è¡Œä¸­çš„æ¬¡ä¼˜å‚æ•°é€‰æ‹©æ•°é‡  
| - **Failure Reasons**ï¼šåˆ†ç±»ç»Ÿè®¡å¤±è´¥åŸå› ï¼ˆå¦‚ç¼ºå°‘ç”Ÿæˆå™¨ã€å‚æ•°é”™è¯¯ç­‰ï¼‰ |
| **Experiment II** |  
| - **Token Usage**ï¼šæ€» token æ¶ˆè€—ï¼ˆActor + Criticï¼‰  
| - **Follow-up Prompts Required**ï¼šæ‰€éœ€äººå·¥å¹²é¢„æç¤ºæ•°  
| - **Objective Completion**ï¼šæœ€ç»ˆæ˜¯å¦è¾¾æˆç›®æ ‡åœ°å›¾ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### Experiment I: å¯é æ€§ç»“æœï¼ˆ3D Mountain Mapï¼‰

| æŒ‡æ ‡ | Actor-Critic | Single-Agent (w/ Docs) |
|------|--------------|------------------------|
| **Success Rate (%)** | **80%** | 60% |
| **Average Mistakes / Successful Run** | 2.25 | 2.17 |

- **æå‡æ•ˆæœ**ï¼šä»»åŠ¡æˆåŠŸç‡æå‡ **20ä¸ªç™¾åˆ†ç‚¹**ï¼ˆç›¸å¯¹æå‡ 33%ï¼‰ã€‚
- å°½ç®¡åŒæ™ºèƒ½ä½“åœ¨æˆåŠŸæ¡ˆä¾‹ä¸­çŠ¯ç•¥å¤šâ€œéè‡´å‘½é”™è¯¯â€ï¼Œä½†å…¶**è‡´å‘½æ€§å¤±è´¥æ›´å°‘**ï¼Œå°¤å…¶æ˜¯ï¼š
  - **Missing/wrong parameter choice**ï¼š0 vs 1 æ¬¡
  - **Did not add reference layer**ï¼š3 æ¬¡ï¼ˆ100% å¤±è´¥æ¡ˆä¾‹ï¼‰vs 2 æ¬¡ï¼ˆ50%ï¼‰

> ğŸ” **å…³é”®è§‚å¯Ÿ**ï¼šActor-Critic åœ¨â€œå•ä¸€å±±å³°â€è¦æ±‚ä¸Šçš„éµå®ˆç‡è¾¾åˆ° **88%**ï¼Œè€Œå•æ™ºèƒ½ä½“ä»…ä¸º **50%**ï¼Œè¯´æ˜å…¶æ›´èƒ½å‡†ç¡®è§£æç©ºé—´è¿é€šæ€§ç­‰éšå«è¯­ä¹‰ã€‚

### Experiment II: æ•ˆç‡ä¸è‡ªä¸»æ€§ç»“æœ

| Map Type | Model | Tokens Used | Follow-up Prompts | Achieves Objective |
|---------|-------|-------------|--------------------|---------------------|
| 2D Beach | Actor-Critic | 16,392 | 2 | âœ… |
|         | Actor+Resources | 18,987 | 4 | âœ… |
| 3D Mountain Island | Actor-Critic | 14,583 | 4 | âœ… |
|                      | Actor+Resources | 11,873 | 5 | âœ… |
| 3D Hilly Golf Course | Actor-Critic | 12,633 | 4 | âœ… |
|                      | Actor+Resources | 18,676 | 6 | âœ… |
| 2D Escape Maze | Actor-Critic | 4,589 | 2 | âœ… |
|                | Actor+Resources | 7,722 | 3 | âœ… |

- **å¹³å‡ token å‡å°‘ 12.7%**ï¼Œå°½ç®¡ Critic å¢åŠ äº†æ¨ç†å¼€é”€ï¼Œä½†ç”±äºå‡å°‘äº†æ— æ•ˆå°è¯•ï¼Œæ€»ä½“é€šä¿¡æ•ˆç‡æ›´é«˜ã€‚
- **æ˜¾è‘—é™ä½äººå·¥å¹²é¢„éœ€æ±‚**ï¼šSingle-Agent å¹³å‡éœ€è¦ **1.5 æ›´å¤š follow-up prompts** æ¥çº æ­£æ–¹å‘ã€‚
- æ‰€æœ‰ä»»åŠ¡ä¸­ï¼Œ**Actor-Critic å‡æˆåŠŸå®Œæˆç›®æ ‡**ï¼Œè€Œéƒ¨åˆ†å•æ™ºèƒ½ä½“åœ¨å¤æ‚åœ°å½¢ä¸­å®Œå…¨å¤±è´¥ï¼ˆæ ‡è®°ä¸º â€œ-â€ æˆ– â€œXâ€ï¼‰ã€‚

### æ¶ˆèåˆ†æï¼ˆImplicit Ablationï¼‰
- **ç§»é™¤ Critic** â†’ é”™è¯¯ç‡æ˜¾è‘—ä¸Šå‡ï¼Œå°¤å…¶åœ¨å‚æ•°è¾¹ç•Œå’Œç®—æ³•å…¼å®¹æ€§æ–¹é¢ã€‚
- **ç§»é™¤æ–‡æ¡£/ç¤ºä¾‹** â†’ æ€§èƒ½æ€¥å‰§ä¸‹é™ï¼Œè¯æ˜ **static resource injection** æ˜¯ zero-shot æˆåŠŸçš„å…³é”®å‰æã€‚
- **å¢åŠ è¿­ä»£æ¬¡æ•°** â†’ æ”¶æ•›ç¨³å®šæ€§å¢å¼ºï¼Œä½†è¾¹é™…æ•ˆç›Šé€’å‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Off-the-shelf LLMs å¯ä»¥ç›´æ¥æ“æ§å¤æ‚ PCG å·¥å…·**ï¼Œåªè¦é…å¤‡é€‚å½“çš„æ–‡æ¡£å’Œç¤ºä¾‹ï¼Œæ— éœ€ fine-tuningã€‚
2. **Actor-Critic åˆ†ç¦»æœºåˆ¶æœ‰æ•ˆå¼¥åˆäº†è¯­ä¹‰é¸¿æ²Ÿ**ï¼šActor è´Ÿè´£â€œæƒ³â€ï¼ŒCritic è´Ÿè´£â€œéªŒâ€ï¼ŒäºŒè€…åä½œæ˜¾è‘—æé«˜è¾“å‡ºçš„åŠŸèƒ½æ­£ç¡®æ€§å’Œä»»åŠ¡æˆåŠŸç‡ã€‚
3. **In-Context Learning è¶³ä»¥åº”å¯¹é«˜ç»´å‚æ•°ç©ºé—´**ï¼šé€šè¿‡ç»“æ„åŒ– prompt è®¾è®¡å’Œè¿­ä»£ refinementï¼ŒLLM èƒ½å¤Ÿè‡ªä¸»æ¨ç†å‡ºåˆæ³•ä¸”ç¬¦åˆæ„å›¾çš„å‚æ•°é…ç½®è·¯å¾„ã€‚
4. **è¯¥èŒƒå¼å…·æœ‰å¼ºæ³›åŒ–æ½œåŠ›**ï¼šä¸ä»…é™äºåœ°å½¢ç”Ÿæˆï¼Œè¿˜å¯æ¨å¹¿è‡³ CADã€BIMã€ç§‘å­¦ä»¿çœŸç­‰ä¸“ä¸šè½¯ä»¶è‡ªåŠ¨åŒ–åœºæ™¯ã€‚

### æ–¹æ³•çš„å±€é™æ€§
| é™åˆ¶ | è¯´æ˜ |
|------|------|
| **æ¨ç†å»¶è¿Ÿè¾ƒé«˜** | è¿­ä»£åé¦ˆå¾ªç¯å¢åŠ äº†å“åº”æ—¶é—´ï¼Œä¸é€‚åˆå®æ—¶åº”ç”¨ |
| **ç¼ºä¹é•¿æœŸè®°å¿†** | æ¯æ¬¡ä»»åŠ¡ç‹¬ç«‹ï¼Œæ— æ³•ä»å†å²ç»éªŒä¸­å­¦ä¹  |
| **ä¾èµ–é«˜è´¨é‡æ–‡æ¡£** | è‹¥æ–‡æ¡£ç¼ºå¤±æˆ–ä¸å‡†ç¡®ï¼ŒCritic éªŒè¯èƒ½åŠ›å—é™ |
| **å›ºå®šä¸Šä¸‹æ–‡çª—å£ç®¡ç†** | å½“å‰é‡‡ç”¨çŠ¶æ€æ›¿æ¢ç­–ç•¥ï¼Œå¯èƒ½ä¸¢å¤±æœ‰ç”¨å†å²ä¿¡æ¯ |

### æœªæ¥å·¥ä½œæ–¹å‘
1. **ä¼˜åŒ–è®¡ç®—å¼€é”€**ï¼š
   - ä½¿ç”¨å°å‹è’¸é¦æ¨¡å‹ï¼ˆå¦‚ Llama-3-8B æˆ– Phi-3ï¼‰ä½œä¸º Criticï¼Œé™ä½æˆæœ¬ã€‚
   - ç¼“å­˜å¸¸è§æˆåŠŸçš„ **parameter trajectories** ä»¥ä¾›å¤ç”¨ã€‚
2. **å¼•å…¥é•¿æœŸè®°å¿†æœºåˆ¶**ï¼š
   - ç»“åˆ **Retrieval-Augmented Generation (RAG)**ï¼Œå»ºç«‹å‘é‡æ•°æ®åº“å­˜å‚¨è¿‡å¾€æˆåŠŸç­–ç•¥ã€‚
3. **æ„å»ºè¯Šæ–­å…ƒå±‚ï¼ˆDiagnostic Meta-Layerï¼‰**ï¼š
   - è‡ªåŠ¨è¯†åˆ«é‡å¤æ€§é”™è¯¯æ¨¡å¼ï¼Œå¹¶åŠ¨æ€è°ƒæ•´ prompt ç­–ç•¥ï¼Œå®ç°ä»â€œè¢«åŠ¨çº é”™â€åˆ°â€œä¸»åŠ¨é¢„é˜²â€çš„è½¬å˜ã€‚
4. **æ‰©å±•è‡³æ›´å¤šé¢†åŸŸ**ï¼š
   - åº”ç”¨äºå»ºç­‘å»ºæ¨¡ï¼ˆBIMï¼‰ã€æ•°å­—å­ªç”Ÿï¼ˆDigital Twinï¼‰ã€éŸ³é¢‘åˆæˆå¼•æ“ç­‰ä¸“ä¸šå·¥å…·é“¾ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒã€å¯è¿ç§»ã€é«˜å¯é çš„ dual-agent æ¶æ„ï¼Œé¦–æ¬¡å®ç°äº†ç”¨è‡ªç„¶è¯­è¨€é›¶æ ·æœ¬æ§åˆ¶å¤æ‚ PCG å·¥å…·ç”Ÿæˆå¤šæ ·åŒ– 3D åœ°å›¾ï¼Œä¸ºé€šç”¨ LLM æ™ºèƒ½ä½“æ“ä½œä¸“ä¸šè½¯ä»¶æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 9. [T-pro 2.0: An Efficient Russian Hybrid-Reasoning Model and Playground](https://arxiv.org/abs/2512.10430)

**Authors**: Dmitrii Stoianov, Danil Taranets, Olga Tsymboi, Ramil Latypov, Almaz Dautov, Vladislav Kruglikov, Nikita Surkov, German Abramov, Pavel Gein, Dmitry Abulkhanov, Mikhail Gashkov, Viktor Zelenkovskiy, Artem Batalov, Aleksandr Medvedev, Anatolii Potapov  
**Category**: cs.CL  
**Published**: 2025-12-12  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.10430v1  

#### Abstract
We introduce T-pro 2.0, an open-weight Russian LLM for hybrid reasoning and efficient inference. The model supports direct answering and reasoning-trace generation, using a Cyrillic-dense tokenizer and an adapted EAGLE speculative-decoding pipeline to reduce latency. To enable reproducible and exten...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šT-pro 2.0: An Efficient Russian Hybrid-Reasoning Model and Playground

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ä¿„è¯­å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæ€ç³»ç»Ÿå­˜åœ¨ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š
- **é«˜è´¨é‡å¼€æºæ¨¡å‹ç¨€ç¼º**ï¼šå¤šæ•°é«˜æ€§èƒ½ä¿„è¯­æ¨¡å‹ä¸ºé—­æºAPIæœåŠ¡ï¼ˆå¦‚YandexGPTã€GigaChatï¼‰ï¼Œé™åˆ¶äº†ç ”ç©¶å¯å¤ç°æ€§ã€‚
- **ç¼ºä¹ç»Ÿä¸€æ¨ç†è¯„æµ‹ä½“ç³»**ï¼šç¼ºå°‘é’ˆå¯¹ä¿„è¯­å¤æ‚æ¨ç†ä»»åŠ¡ï¼ˆå°¤å…¶æ˜¯æ•°å­¦ç«èµ›çº§ï¼‰çš„æƒå¨åŸºå‡†ã€‚
- **å¤šè¯­è¨€åˆ†è¯å™¨å¯¹ä¿„è¯­æ”¯æŒä¸è¶³**ï¼šé€šç”¨åˆ†è¯å™¨ï¼ˆå¦‚Qwenã€Llamaï¼‰åœ¨å¤„ç†è¥¿é‡Œå°”å­—æ¯æ—¶æ•ˆç‡ä½ä¸‹ï¼Œå¯¼è‡´æ–‡æœ¬å‹ç¼©ç‡ä½ã€æ¨ç†å»¶è¿Ÿé«˜ã€‚
- **æ¨ç†æ•ˆç‡ä¼˜åŒ–ç¼ºå¤±**ï¼šä¿„è¯­æ¨¡å‹ä¸­å°šæœªæœ‰æ•ˆåº”ç”¨å¦‚speculative decodingç­‰åŠ é€ŸæŠ€æœ¯ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
T-pro 2.0 æå‡ºäº†ä¸€å¥—å®Œæ•´çš„ä¿„è¯­é«˜æ•ˆæ··åˆæ¨ç†ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**Cyrillic-dense Tokenizer**
- åœ¨Qwen3åˆ†è¯å™¨åŸºç¡€ä¸Šï¼Œå°†34kä¸ªä½é¢‘éè¥¿é‡Œå°”ç¬¦å·æ›¿æ¢ä¸ºè¥¿é‡Œå°”å­—ç¬¦ï¼Œä¿æŒæ€»è¯è¡¨å¤§å°ä¸å˜ã€‚
- æ˜¾è‘—æå‡ä¿„è¯­æ–‡æœ¬å‹ç¼©æ•ˆç‡ï¼šä¿„è¯­ç»´åŸºç™¾ç§‘ä¸­å•å­—å¹³å‡tokenæ•°ä»3.12é™è‡³2.38ï¼Œä¸¤tokenå†…è¦†ç›–æ¯”ä¾‹ä»38.2%æå‡è‡³60.1%ã€‚
- è¯¥è®¾è®¡æ³›åŒ–æ€§å¼ºï¼Œåœ¨8ç§è¥¿é‡Œå°”è¯­è¨€ä¸Šå‡ä¼˜äºRuAdaptã€GigaChatç­‰ä¸“ç”¨åˆ†è¯å™¨ã€‚

#### ï¼ˆ2ï¼‰**T-Wix 500k SFT æ•°æ®é›†**
- å½“å‰æœ€å¤§è§„æ¨¡çš„ä¿„è¯­æ··åˆæ¨ç†æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼ˆçº¦50ä¸‡æ ·æœ¬ï¼‰ã€‚
- è¦†ç›–é€šç”¨é—®ç­”ã€é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ã€æ•™å¸ˆç”Ÿæˆçš„æ¨ç†é“¾ï¼ˆreasoning tracesï¼‰ã€‚
- åŒ…å«ä¸“é—¨æ„å»ºçš„**ä¿„è¯­å¥¥æ—åŒ¹å…‹æ•°å­¦é¢˜**å­é›†ï¼Œå¼ºè°ƒé«˜è´¨é‡ã€å¤šæ ·æ€§ä¸éš¾åº¦å¹³è¡¡ã€‚

#### ï¼ˆ3ï¼‰**T-Math æ•°å­¦æ¨ç†åŸºå‡†**
- æ„å»ºè‡ªå…¨ä¿„åŠè«æ–¯ç§‘æ•°å­¦å¥¥èµ›ï¼ˆ1998â€“2025ï¼‰çš„331é“é¢˜ç›®ã€‚
- æ‰€æœ‰é—®é¢˜å‡ä¸ºå•ç­”æ¡ˆæ•°å€¼è§£ï¼Œæ”¯æŒè‡ªåŠ¨åŒ–è¯„ä¼°ã€‚
- é¢˜ç›®éš¾åº¦è¿œè¶…å¸¸è§„ç¿»è¯‘åŸºå‡†ï¼Œæœªè¢«å‰æ²¿æ¨¡å‹é¥±å’Œï¼ˆæœ€å¼ºæ¨¡å‹pass@1 < 0.75ï¼‰ã€‚

#### ï¼ˆ4ï¼‰**EAGLE-style Speculative Decoding åŠ é€Ÿæ¨ç†**
- é›†æˆè½»é‡çº§draft modelï¼ˆåŸºäºLlama-2å•å±‚+FR-Specç»„ä»¶ï¼‰ï¼Œå®ç°å¹¶è¡Œtokené¢„æµ‹ã€‚
- ä½¿ç”¨SGLangéƒ¨ç½²åŠ¨æ€draft treeæœºåˆ¶ï¼Œæ˜¾è‘—é™ä½æ¨ç†å»¶è¿Ÿã€‚
- å¹³å‡æé€Ÿè¾¾ **1.85Ã—**ï¼Œåœ¨STEMé¢†åŸŸæœ€é«˜è¾¾ **2.25Ã—**ï¼ˆT-Mathä»»åŠ¡ï¼‰ã€‚

#### ï¼ˆ5ï¼‰**äº¤äº’å¼Web Demoå¹³å°**
- å…¬å¼€æ¼”ç¤ºç³»ç»Ÿï¼ˆ[http://t-pro-2-0.streamlit.app](http://t-pro-2-0.streamlit.app)ï¼‰æ”¯æŒï¼š
  - å¯¹æ¯”â€œç›´æ¥å›ç­”â€ä¸â€œé€æ­¥æ¨ç†â€æ¨¡å¼ï¼›
  - å®æ—¶æŸ¥çœ‹tokenæµã€ååé‡ã€acceptance ratioç­‰æ€§èƒ½æŒ‡æ ‡ï¼›
  - ä½¿ç”¨é¢„è®¾promptæµ‹è¯•ä¸åŒé¢†åŸŸä»»åŠ¡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | T-pro 2.0 | ç°æœ‰ä¿„è¯­æ¨¡å‹ï¼ˆå¦‚RuAdaptã€GigaChatï¼‰ |
|------|----------|-------------------------------|
| å¼€æºç¨‹åº¦ | å®Œå…¨å¼€æ”¾æƒé‡ã€æ•°æ®ã€æ¨ç†ä»£ç  | å¤šä¸ºé—­æºæˆ–ä»…å‘å¸ƒæ¨¡å‹ |
| åˆ†è¯æ•ˆç‡ | ä¸“ä¸ºè¥¿é‡Œå°”è¯­ä¼˜åŒ–ï¼Œå‹ç¼©ç‡æ›´é«˜ | ä½¿ç”¨é€šç”¨åˆ†è¯å™¨ï¼Œæ•ˆç‡è¾ƒä½ |
| æ¨ç†èƒ½åŠ› | æ”¯æŒæ˜¾å¼æ¨ç†é“¾ç”Ÿæˆ + é«˜æ•ˆè§£ç  | å¤šæ•°ä¸æ”¯æŒå¯æ§æ¨ç†æ¨¡å¼ |
| æ¨ç†é€Ÿåº¦ | EAGLEåŠ é€Ÿï¼Œå¹³å‡1.85Ã—æé€Ÿ | æ— ç³»ç»Ÿçº§æ¨ç†ä¼˜åŒ– |
| å¯éªŒè¯æ€§ | å‘å¸ƒT-Mathç­‰åŸç”Ÿä¿„è¯­æŒ‘æˆ˜æ€§åŸºå‡† | å¤šä¾èµ–ç¿»è¯‘æˆ–ç®€å•ä»»åŠ¡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

| ç±»å‹ | åç§° | æè¿° |
|------|------|------|
| **é¢„è®­ç»ƒ/ä¸­æœŸè®­ç»ƒæ•°æ®** | Midtraining Mix | 40B tokensï¼Œå«ä¿„è¯­(49%)ã€è‹±è¯­(36%)ã€ä»£ç (9.3%)ï¼Œæ¶µç›–æ¨ç†ã€QAã€æ•°å­¦ã€å¯¹è¯ç­‰ |
| **SFTæ•°æ®é›†** | T-Wix 500k | è‡ªç ”æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œå«468ké€šç”¨ä»»åŠ¡ + 30kæ¨ç†ä»»åŠ¡ |
| **è¯„ä¼°åŸºå‡† - é€šç”¨çŸ¥è¯†** | MERA, MaMuRAMu, ruMMLU-Pro | ä¿„è¯­å¸¸è¯†ç†è§£ä¸é€»è¾‘æ¨ç†åŸºå‡† |
| **è¯„ä¼°åŸºå‡† - å¯¹è¯èƒ½åŠ›** | Arena Hard Ru, WildChat Hard Ru | åŸç”Ÿä¿„è¯­å¯¹è¯è´¨é‡è¯„æµ‹ |
| **è¯„ä¼°åŸºå‡† - æ¨ç†èƒ½åŠ›** | T-Math, ruAIME, ruMATH-500, ruGPQA, ruLCB | æ•°å­¦ã€ç§‘å­¦ã€ä»£ç ç­‰é«˜çº§æ¨ç†ä»»åŠ¡ |
| **å¯¹æ¯”åŸºçº¿æ¨¡å‹** | Qwen3-32B, RuadaptQwen3-32B, DeepSeek-V3, GPT-4o, o4-mini ç­‰ | åŒ…æ‹¬å¼€æºä¸é—­æºä¸»æµæ¨¡å‹ |

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### æ¨ç†æ¨¡å¼
- **Standard Mode**ï¼šç›´æ¥è¾“å‡ºç­”æ¡ˆã€‚
- **Reasoning Mode**ï¼šç”Ÿæˆå®Œæ•´æ¨ç†è¿‡ç¨‹åç»™å‡ºç­”æ¡ˆã€‚

#### è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| é€šç”¨çŸ¥è¯† | MERA, ruMMLU-Pro å‡†ç¡®ç‡ |
| å¯¹è¯èƒ½åŠ› | Arena Hard Win Rate, WildChat Score |
| æ•°å­¦æ¨ç† | pass@1ï¼ˆT-Mathï¼‰ã€ruAIME/rumath-500å‡†ç¡®ç‡ |
| æ¨ç†æ•ˆç‡ | Speedupï¼ˆç›¸å¯¹æ ‡å‡†è§£ç ï¼‰ã€Acceptance Lengthã€Tokens/sec |

#### åŸºçº¿å¯¹æ¯”æ¨¡å‹
- **å¼€æºä¿„è¯­æ¨¡å‹**ï¼šRuadaptQwen3-32B-Instruct
- **å›½é™…ä¸»æµæ¨¡å‹**ï¼šQwen3-32B, Gemma 3 27B, DeepSeek-V3/R1
- **å•†ä¸šé—­æºæ¨¡å‹**ï¼šGPT-4o, o4-mini, YandexGPT5-Pro, GigaChat 2 Max

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªTable 4 & Table 5ï¼‰

#### ğŸ“Š é€šç”¨çŸ¥è¯†ä¸å¯¹è¯èƒ½åŠ›ï¼ˆä¿„è¯­ï¼‰
| æ¨¡å‹ | MERA | ruMMLU-Pro | Arena Hard Ru | WildChat Hard Ru |
|------|------|------------|---------------|------------------|
| **T-pro 2.0** | **0.660** | **0.697** | **91.1** | **72.6** |
| Qwen3-32B | 0.582 | 0.677 | 83.95 | 59.6 |
| RuadaptQwen3 | 0.574 | 0.652 | 68.4 | 41.5 |
| GPT-4o | 0.642 | 0.714 | 85.14 | 41.4 |

âœ… **ç»“è®º**ï¼šT-pro 2.0åœ¨æ‰€æœ‰ä¿„è¯­é€šç”¨ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºåŒç±»å¼€æºæ¨¡å‹ï¼Œæ¥è¿‘GPT-4oæ°´å¹³ã€‚

#### ğŸ§® é«˜çº§æ¨ç†èƒ½åŠ›ï¼ˆä¿„è¯­ï¼‰
| æ¨¡å‹ | T-Math | ruAIME 2024 | ruMATH-500 | Vikhr Math |
|------|--------|-------------|------------|------------|
| **T-pro 2.0** | **0.541** | **0.704** | **0.940** | **0.799** |
| Qwen3-32B | 0.529 | 0.706 | 0.938 | 0.809 |
| DeepSeek-V3 | 0.278 | 0.319 | 0.882 | 0.613 |
| GPT-4o | 0.106 | 0.090 | 0.766 | 0.372 |

âœ… **ç»“è®º**ï¼š
- åœ¨T-Mathè¿™ä¸€åŸç”Ÿä¿„è¯­å¥¥èµ›é¢˜ä¸Šè¡¨ç°æœ€ä½³ï¼ˆ0.541ï¼‰ï¼Œè¿œè¶…GPT-4oï¼ˆ0.106ï¼‰ã€‚
- åœ¨ruAIMEç­‰ç¿»è¯‘åŸºå‡†ä¸Šä¹Ÿå¤§å¹…é¢†å…ˆé—­æºæ¨¡å‹ã€‚

#### âš¡ æ¨ç†æ•ˆç‡ï¼ˆSpeculative Decoding åŠ é€Ÿæ•ˆæœï¼‰
| åŸºå‡† | æ¨¡å¼ | Speedup | Acceptance Length |
|------|------|---------|-------------------|
| **ruMT-Bench** | Standard | 1.79Ã— | 3.31 |
| **ruMT-Bench** | Reasoning | 1.69Ã— | 3.10 |
| **ruCodeEval** | Standard | 2.15Ã— | 3.93 |
| **T-Math** | Reasoning | **2.25Ã—** | **4.01** |
| **STEMé¢†åŸŸå¹³å‡** | â€” | **1.99Ã—** | **3.57** |

âœ… **ç»“è®º**ï¼šEAGLEåŠ é€Ÿåœ¨æŠ€æœ¯ç±»ä»»åŠ¡ï¼ˆSTEMï¼‰ä¸­æ•ˆæœæ›´æ˜æ˜¾ï¼Œæ¨ç†æ¨¡å¼ä¸‹ä»ä¿æŒé«˜æ•ˆã€‚

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰ä¸­æœŸè®­ç»ƒæ•°æ®æ··åˆç­–ç•¥ï¼ˆTable 12ï¼‰
| é…ç½® | ruAIME 2024 | ruAIME 2025 | ruGPQA |
|------|-------------|-------------|--------|
| Pre-train + Instruct | 0.60 | 0.47 | 0.58 |
| **Instruct-only** | **0.67** | **0.63** | **0.66** |

â¡ï¸ **å‘ç°**ï¼šçº¯instructionæ•°æ®åœ¨åŒç­‰tokené¢„ç®—ä¸‹ä¼˜äºæ··åˆé¢„è®­ç»ƒæ•°æ®ï¼Œè¯´æ˜å¼ºé¢„è®­ç»ƒæ¨¡å‹æ›´é€‚åˆé€šè¿‡é«˜è´¨é‡æŒ‡ä»¤è¿›ä¸€æ­¥è°ƒä¼˜ã€‚

#### ï¼ˆ2ï¼‰åˆ†è¯å™¨å½±å“ï¼ˆTable 13ï¼‰
| åˆ†è¯å™¨ | MERA Macro-Avg |
|--------|----------------|
| Qwen3åŸç”Ÿ | 0.560 |
| **T-pro 2.0 Cyrillic-dense** | **0.574** |

â¡ï¸ **å‘ç°**ï¼šæ›´æ¢ä¸ºè¥¿é‡Œå°”å¯†é›†åˆ†è¯å™¨ä¸ä»…æœªæŸå®³æ€§èƒ½ï¼Œåè€Œç•¥æœ‰æå‡ï¼Œè¯æ˜å…¶æœ‰æ•ˆæ€§ã€‚

#### ï¼ˆ3ï¼‰å¥–åŠ±æ¨¡å‹æ¶ˆèï¼ˆTable 17ï¼‰
- ç§»é™¤transitive preference pairså¯¼è‡´RewardBench2(RU)æ€»åˆ†ä»0.587é™è‡³0.533ã€‚
- ä½¿ç”¨DeepSeek-V3ä½œä¸ºjudging modelæ¯”Qwen3-235B-A22Båœ¨èŠå¤©ä»»åŠ¡ä¸Šè¡¨ç°æ›´å¥½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é’ˆå¯¹æ€§é€‚é…å¼ºäºç›²ç›®æ‰©å±•**ï¼šé€šè¿‡å¯¹Qwen3è¿›è¡Œä¿„è¯­å®šåˆ¶åŒ–æ”¹é€ ï¼ˆåˆ†è¯å™¨ã€æ•°æ®ã€æ¨ç†ä¼˜åŒ–ï¼‰ï¼ŒT-pro 2.0åœ¨ä¸å¢åŠ å‚æ•°é‡çš„æƒ…å†µä¸‹å®ç°äº†å¯¹ä¿„è¯­ä»»åŠ¡çš„æ˜¾è‘—è¶…è¶Šã€‚
2. **åˆ†è¯å™¨è®¾è®¡è‡³å…³é‡è¦**ï¼šCyrillic-dense tokenizeræå¤§æå‡äº†ä¿„è¯­æ–‡æœ¬ç¼–ç æ•ˆç‡ï¼Œæ˜¯å®ç°é«˜æ•ˆæ¨ç†çš„åŸºç¡€ã€‚
3. **åŸç”Ÿä¿„è¯­åŸºå‡†æ›´å…·åŒºåˆ†åŠ›**ï¼šT-Mathç­‰åŸç”Ÿå¥¥èµ›é¢˜èƒ½æœ‰æ•ˆæš´éœ²æ¨¡å‹çœŸå®æ¨ç†èƒ½åŠ›å·®å¼‚ï¼Œè€Œç¿»è¯‘åŸºå‡†æ˜“è¢«â€œè®°å¿†â€è€Œéâ€œæ¨ç†â€è§£å†³ã€‚
4. **Speculative Decodingå¯è·¨è¯­è¨€è¿ç§»**ï¼šEAGLE-styleæ–¹æ³•æˆåŠŸåº”ç”¨äºä¿„è¯­æ¨¡å‹ï¼Œå¹³å‡æé€Ÿ1.85Ã—ï¼ŒéªŒè¯å…¶è¯­è¨€æ— å…³æ€§ã€‚
5. **ä¿„è¯­ä¼˜åŒ–ä¸å½±å“è‹±æ–‡æ€§èƒ½**ï¼šT-pro 2.0åœ¨è‹±æ–‡AIME/MATH-500ç­‰ä»»åŠ¡ä¸Šä»å…·ç«äº‰åŠ›ï¼ˆTable 23ï¼‰ï¼Œè¡¨æ˜å¤šè¯­è¨€èƒ½åŠ›å¾—ä»¥ä¿ç•™ã€‚

### å±€é™æ€§
- âŒ **æ— å·¥å…·ä½¿ç”¨èƒ½åŠ›**ï¼šæœªé’ˆå¯¹function callingæˆ–å¤šæ­¥agentè¡Œä¸ºè¿›è¡Œä¼˜åŒ–ã€‚
- âŒ **ä»…ç¦»çº¿DPOå¯¹é½**ï¼šæœªé‡‡ç”¨åœ¨çº¿RLï¼ˆå¦‚PPOï¼‰ï¼Œå¯èƒ½é™åˆ¶é²æ£’æ€§ã€‚
- âŒ **é•¿ä¸Šä¸‹æ–‡æœªå……åˆ†éªŒè¯**ï¼šè™½æ”¯æŒ128k RoPEç¼©æ”¾ï¼Œä½†æœªå®è¯å…¶åœ¨æé•¿è¾“å…¥ä¸‹çš„æ£€ç´¢ä¸è¿è´¯æ€§ã€‚
- âŒ **éƒ¨åˆ†æ•°æ®ä¸å¯å®Œå…¨å¤ç°**ï¼šä¸­æœŸè®­ç»ƒä¸DPOé˜¶æ®µä½¿ç”¨äº†éƒ¨åˆ†ä¸“æœ‰æ•°æ®ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼•å…¥function callingä¸tool useèƒ½åŠ›ã€‚
- æ¢ç´¢online RLï¼ˆå¦‚GRPOï¼‰è¿›è¡Œæ›´ç²¾ç»†å¯¹é½ã€‚
- éªŒè¯å¹¶ä¼˜åŒ–128ké•¿ä¸Šä¸‹æ–‡æ€§èƒ½ã€‚
- æ‰©å±•T-Mathè‡³æ›´å¤šå­¦ç§‘ï¼ˆç‰©ç†ã€åŒ–å­¦ï¼‰ä¸é¢˜å‹ï¼ˆè¯æ˜é¢˜ï¼‰ã€‚
- æ¨åŠ¨ç¤¾åŒºå…±å»ºä¿„è¯­LLMé€æ˜è¯„æµ‹ç”Ÿæ€ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> T-pro 2.0 æ˜¯é¦–ä¸ªé›†**é«˜æ•ˆä¿„è¯­åˆ†è¯å™¨**ã€**é«˜è´¨é‡åŸç”Ÿæ¨ç†æ•°æ®é›†**ã€**æŒ‘æˆ˜æ€§ä¿„è¯­æ•°å­¦åŸºå‡†**ä¸**EAGLEåŠ é€Ÿæ¨ç†**äºä¸€ä½“çš„å¼€æºä¿„è¯­æ··åˆæ¨ç†ç³»ç»Ÿï¼Œæ ‡å¿—ç€ä¿„è¯­LLMå‘é«˜æ•ˆã€å¯å¤ç°ã€ä¸“ä¸šåŒ–æ–¹å‘è¿ˆå‡ºå…³é”®ä¸€æ­¥ã€‚

</details>

---

### 10. [TDC-Cache: A Trustworthy Decentralized Cooperative Caching Framework for Web3.0](https://arxiv.org/abs/2512.09961)

**Authors**: Jinyu Chen, Long Shi, Taotao Wang, Jiaheng Wang, Wei Zhang  
**Category**: cs.DC  
**Published**: 2025-12-12  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.09961v1  

#### Abstract
The rapid growth of Web3.0 is transforming the Internet from a centralized structure to decentralized, which empowers users with unprecedented self-sovereignty over their own data. However, in the context of decentralized data access within Web3.0, it is imperative to cope with efficiency concerns c...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTDC-Cache: A Trustworthy Decentralized Cooperative Caching Framework for Web3.0

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
Web3.0 çš„å»ä¸­å¿ƒåŒ–æ¶æ„è™½ç„¶æå‡äº†ç”¨æˆ·å¯¹æ•°æ®çš„è‡ªä¸»æƒï¼ˆself-sovereigntyï¼‰ï¼Œä½†ä¹Ÿå¸¦æ¥äº†ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **é«˜è®¿é—®å»¶è¿Ÿ**ï¼šç”±äºå»ä¸­å¿ƒåŒ–å­˜å‚¨ï¼ˆå¦‚ IPFSã€SWARMï¼‰ä¾èµ–åˆ†å¸ƒå¼å…±è¯†å’Œåˆ†å—å­˜å‚¨ï¼ˆchunked dataï¼‰ï¼Œå¯¼è‡´å†…å®¹æ£€ç´¢æ•ˆç‡ä½ä¸‹ã€‚
- **ç¼“å­˜ç­–ç•¥ä¸é€‚åº”**ï¼šä¼ ç»Ÿ Web2.0 çš„é›†ä¸­å¼ç¼“å­˜æœºåˆ¶ï¼ˆå¦‚ CDNï¼‰æ— æ³•ç›´æ¥åº”ç”¨äº Web3.0 çš„å»ä¸­å¿ƒåŒ–ç¯å¢ƒã€‚
- **å®‰å…¨é£é™©**ï¼šåœ¨å»ä¸­å¿ƒåŒ–ç¯å¢ƒä¸­ï¼Œæ¶æ„èŠ‚ç‚¹å¯èƒ½ç¯¡æ”¹ç¼“å­˜å†…å®¹æˆ–ç ´åæ¨¡å‹è®­ç»ƒä¸€è‡´æ€§ï¼ˆå¦‚ Byzantine æ”»å‡»ï¼‰ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **TDC-Cache** çš„å¯ä¿¡å»ä¸­å¿ƒåŒ–ååŒç¼“å­˜æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰ä¸¤å±‚æ¶æ„è®¾è®¡ï¼šDecentralized Oracle Network (DON) å±‚
- å¼•å…¥ **DON å±‚ä½œä¸ºå¯ä¿¡ä¸­ä»‹**ï¼Œè¿æ¥ç”¨æˆ·ï¼ˆCRï¼‰ä¸å»ä¸­å¿ƒåŒ–å­˜å‚¨ï¼ˆCPï¼‰ï¼Œå®ç°é«˜æ•ˆçš„å†…å®¹ç¼“å­˜ä¸å¿«é€Ÿå“åº”ã€‚
- æ¯ä¸ª Oracle åŒ…å«ç¼“å­˜æ± ï¼ˆDRAM + NVMe SSDï¼‰å’Œå¯æ‰§è¡Œç»„ä»¶ï¼ˆç¼“å­˜æ¨¡å— + åˆ†å¸ƒå¼å…±è¯†æ¨¡å—ï¼‰ã€‚

#### ï¼ˆ2ï¼‰åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„å»ä¸­å¿ƒåŒ–ç¼“å­˜ç­–ç•¥ï¼šDRL-DC
- å°†ç¼“å­˜å†³ç­–å»ºæ¨¡ä¸º **Decentralized Partially Observable Markov Decision Process (Dec-POMDP)**ã€‚
- ä½¿ç”¨ **QMIX ç®—æ³•** è¿›è¡Œå¤šæ™ºèƒ½ä½“ååŒè®­ç»ƒï¼ŒåŠ¨æ€ä¼˜åŒ–ç¼“å­˜æ›¿æ¢ç­–ç•¥ï¼Œæœ€å¤§åŒ–é•¿æœŸç¼“å­˜å‘½ä¸­ç‡ï¼ˆcache hit rateï¼‰ã€‚
- èƒ½å¤Ÿåº”å¯¹ç”¨æˆ·è¯·æ±‚åˆ†å¸ƒåŠ¨æ€å˜åŒ–ã€éƒ¨åˆ†å¯è§‚æµ‹ç­‰ç°å®æŒ‘æˆ˜ã€‚

#### ï¼ˆ3ï¼‰æ–°å‹å…±è¯†æœºåˆ¶ï¼šProof of Cooperative Learning (PoCL)
- é’ˆå¯¹ DRL æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ‹œå åº­å¨èƒï¼Œæå‡º PoCL å…±è¯†åè®®ã€‚
- æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡â€œåˆä½œè¯æ˜â€ï¼ˆcooperative proofï¼‰é€‰æ‹©å¯é çš„è®­ç»ƒèŠ‚ç‚¹ï¼Œå¹¶éªŒè¯æ¨¡å‹æ›´æ–°çš„æœ‰æ•ˆæ€§ã€‚
- å››é˜¶æ®µæµç¨‹ï¼šPrepare â†’ Train â†’ Synchronize â†’ Commitï¼Œç¡®ä¿å…¨å±€ä¸€è‡´æ€§å’Œå®‰å…¨æ€§ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | æ˜¾è‘—é™ä½å¹³å‡è®¿é—®å»¶è¿Ÿï¼ˆâ†“20%ï¼‰ï¼Œæå‡ç¼“å­˜å‘½ä¸­ç‡ï¼ˆâ†‘æœ€å¤š18%ï¼‰ã€‚ |
| **å®‰å…¨æ€§** | æŠµå¾¡ Byzantine èŠ‚ç‚¹æ”»å‡»ï¼Œä¿éšœç¼“å­˜å†³ç­–ä¸€è‡´æ€§ã€‚ |
| **å»ä¸­å¿ƒåŒ–é€‚é…æ€§** | å®Œå…¨å»ä¸­å¿ƒåŒ–è®¾è®¡ï¼Œæ— éœ€ä¸­å¿ƒåè°ƒå™¨ï¼Œé€‚ç”¨äº Web3.0 æ¶æ„ã€‚ |
| **è‡ªé€‚åº”èƒ½åŠ›** | DRL-DC å¯å®æ—¶å­¦ä¹ å†…å®¹æµè¡Œåº¦å˜åŒ–ï¼Œä¼˜äºé™æ€ç­–ç•¥ï¼ˆLRU/LFU/FIFOï¼‰ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†ä¸æ¨¡æ‹Ÿç¯å¢ƒ
- **éçœŸå®æ•°æ®é›†**ï¼Œè€Œæ˜¯åŸºäº **Zipf åˆ†å¸ƒç”Ÿæˆåˆæˆå†…å®¹è¯·æ±‚åºåˆ—**ï¼Œä»¥æ¨¡æ‹Ÿ Web3.0 ä¸­å†…å®¹è®¿é—®çš„é•¿å°¾ç‰¹æ€§ã€‚
- å†…å®¹æ•°é‡ $ F $ã€Oracle æ•°é‡ $ M $ã€ç”¨æˆ·æ•° $ U $ã€æ—¶é—´æ§½ $ T $ å‡å¯é…ç½®ã€‚
- ä¸åŒçš„ Zipf å‚æ•° $ \alpha \in \{0.5, 1.0, 1.5\} $ æ§åˆ¶å†…å®¹æµè¡Œåº¦çš„å€¾æ–œç¨‹åº¦ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **ç³»ç»Ÿå¹³å°**ï¼šUbuntu 24.04 LTSï¼ŒIntel i9-14900Kï¼ŒNVIDIA RTX 4090 GPUï¼Œ128GB RAMã€‚
- **ç¼“å­˜å®¹é‡**ï¼šæ¯ä¸ª Oracle ç¼“å­˜å¤§å° $ C_m = 4 $ï¼ˆå•ä½å†…å®¹ï¼‰ã€‚
- **è®­ç»ƒå‚æ•°**ï¼š
  - æ—¶é—´æ§½æ€»æ•° $ T = 10,000 $
  - æ¢ç´¢ç‡ä» 0.9 çº¿æ€§è¡°å‡è‡³ 0.05
  - å­¦ä¹ ç‡ï¼š0.001ï¼ŒæŠ˜æ‰£å› å­ $ \gamma = 0.99 $

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Cache Hit Rate** | ç¼“å­˜å‘½ä¸­çš„è¯·æ±‚å æ¯”ï¼Œè¶Šé«˜è¶Šå¥½ |
| **Content Retrieval Latency** | ç”¨æˆ·å‘èµ·è¯·æ±‚åˆ°æ”¶åˆ°å†…å®¹çš„æ—¶é—´ï¼Œè¶Šä½è¶Šå¥½ |
| **Success Consensus Rate** | PoCL åè®®æˆåŠŸå®Œæˆçš„æ¯”ä¾‹ï¼Œåæ˜ é²æ£’æ€§ |
| **Average Access Latency** | æ‰€æœ‰è¯·æ±‚çš„å¹³å‡å»¶è¿Ÿ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ä¼ ç»Ÿç¼“å­˜ç­–ç•¥**ï¼š
  - LRUï¼ˆLeast Recently Usedï¼‰
  - LFUï¼ˆLeast Frequently Usedï¼‰
  - FIFOï¼ˆFirst In First Outï¼‰
  - Randomï¼ˆéšæœºæ›¿æ¢ï¼‰
- **ç›´æ¥è®¿é—®ï¼ˆDirect Accessï¼‰**ï¼šç»•è¿‡ç¼“å­˜ï¼Œç›´æ¥ä»å»ä¸­å¿ƒåŒ–å­˜å‚¨è·å–å†…å®¹ï¼ˆä½œä¸ºä¸‹ç•Œå‚è€ƒï¼‰
- **å…±è¯†åè®®å¯¹æ¯”**ï¼š
  - PBFTï¼ˆPractical Byzantine Fault Toleranceï¼‰ vs. PoCL

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| æ€§èƒ½æŒ‡æ ‡ | TDC-Cache è¡¨ç° | å¯¹æ¯”åŸºå‡† | æå‡å¹…åº¦ |
|--------|----------------|----------|---------|
| å¹³å‡è®¿é—®å»¶è¿Ÿ | â†“ 20% | ç›´æ¥è®¿é—® | æ˜¾è‘—æ”¹å–„ç”¨æˆ·ä½“éªŒ |
| æœ€å¤§ç¼“å­˜å‘½ä¸­ç‡æå‡ | â†‘ 18% | LRU/LFU/FIFO | åœ¨ $ \alpha=1.0 $ ä¸‹è¾¾åˆ° ~0.75 |
| æˆåŠŸå…±è¯†ç‡ | â†‘ 10% | PBFT | ç‰¹åˆ«æ˜¯åœ¨å¤§è§„æ¨¡ç½‘ç»œä¸­æ›´ç¨³å®š |
| å†…å®¹æ£€ç´¢å»¶è¿Ÿï¼ˆå°æ–‡ä»¶ï¼‰ | 6.90 ms/KB ($ \alpha=0.5 $) | Direct Access: 8.19 ms/KB | â†“15.7% |
| å†…å®¹æ£€ç´¢å»¶è¿Ÿï¼ˆå¤§æ–‡ä»¶ï¼‰ | 1.24 ms/KB ($ \alpha=0.5 $) | Direct Access: 1.46 ms/KB | â†“15.1% |

> æ³¨ï¼šéšç€ $ \alpha $ å¢åŠ ï¼ˆå†…å®¹æµè¡Œåº¦æ›´é›†ä¸­ï¼‰ï¼ŒTDC-Cache çš„ä¼˜åŠ¿æ›´åŠ æ˜æ˜¾ã€‚

### ğŸ“Š ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰ç¼“å­˜å‘½ä¸­ç‡å¯¹æ¯”ï¼ˆFig. 7 & Fig. 8ï¼‰
- DRL-DC åœ¨æ‰€æœ‰ Oracle ä¸Šå‡ä¿æŒæœ€é«˜ä¸”æœ€ç¨³å®šçš„å‘½ä¸­ç‡ã€‚
- åœ¨ $ \alpha = 1.0 $ æ—¶ï¼ŒDRL-DC è¾¾åˆ°çº¦ **0.75**ï¼Œè€Œæ¬¡ä¼˜ç­–ç•¥ï¼ˆLFUï¼‰ä»…ä¸º ~0.63ã€‚
- éšç€è¯·æ±‚åºåˆ—å¢é•¿ï¼ŒDRL-DC æŒç»­å­¦ä¹ å¹¶æå‡å‘½ä¸­ç‡ï¼Œè€Œä¼ ç»Ÿç­–ç•¥è¶‹äºé¥±å’Œç”šè‡³ä¸‹é™ã€‚

#### ï¼ˆ2ï¼‰ä¸åŒå†…å®¹æµè¡Œåº¦ä¸‹çš„è¡¨ç°ï¼ˆTable IIï¼‰
| $ \alpha $ | ç­–ç•¥ | 1KBâ€“256KB å»¶è¿Ÿ (ms/KB) |
|------------|-------|------------------------|
| 0.5 | DRL-DC | **6.90** |
|     | LFU    | 7.13 |
|     | Direct Access | 8.19 |
| 1.0 | DRL-DC | **6.52** |
|     | LFU    | 6.67 |
| 1.5 | DRL-DC | **6.19** |
|     | LFU    | 6.23 |

> æ‰€æœ‰æ¡ä»¶ä¸‹ DRL-DC å‡æœ€ä¼˜ï¼Œä¸”å·®è·éš $ \alpha $ å¢å¤§è€Œæ‰©å¤§ã€‚

#### ï¼ˆ3ï¼‰PoCL vs PBFT æˆåŠŸå…±è¯†ç‡ï¼ˆFig. 5 & Fig. 6ï¼‰
- å½“æ•…éšœæ¦‚ç‡ $ P_f = 0.1 $ æ—¶ï¼š
  - PBFT çš„æˆåŠŸç‡éšèŠ‚ç‚¹æ•°å¢åŠ è€Œ**ä¸‹é™**
  - PoCL çš„æˆåŠŸç‡éšèŠ‚ç‚¹æ•°å¢åŠ è€Œ**ä¸Šå‡**ï¼Œæœ€ç»ˆè¶‹è¿‘äº 1.0
- åœ¨ $ M=300 $ã€$ P_f=0.2 $ æ—¶ï¼ŒPoCL æˆåŠŸç‡ä»æ¥è¿‘ 1.0ï¼Œè€Œ PBFT å·²è¶‹è¿‘äº 0ã€‚
- PoCL çš„â€œæ‹ç‚¹â€ï¼ˆinflection pointï¼‰æ¯” PBFT é«˜ **209.47%**ï¼Œè¡¨æ˜æ›´å¼ºçš„æ‰©å±•æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å¼•å…¥ DON å±‚æ˜¾è‘—æå‡ Web3.0 æ•°æ®è®¿é—®æ•ˆç‡**  
   TDC-Cache é€šè¿‡æ„å»ºå»ä¸­å¿ƒåŒ–çš„ Oracle ç½‘ç»œä½œä¸ºä¸­é—´ç¼“å­˜å±‚ï¼Œæœ‰æ•ˆç¼“è§£äº†å»ä¸­å¿ƒåŒ–å­˜å‚¨å¸¦æ¥çš„é«˜å»¶è¿Ÿé—®é¢˜ã€‚

2. **DRL-DC å…·å¤‡å¼ºè‡ªé€‚åº”èƒ½åŠ›**  
   åŸºäº QMIX çš„å¤šæ™ºèƒ½ä½“ DRL æ¡†æ¶èƒ½å¤ŸåŠ¨æ€å­¦ä¹ å†…å®¹æµè¡Œè¶‹åŠ¿ï¼Œåœ¨å¤šç§è¯·æ±‚æ¨¡å¼ä¸‹æŒç»­ä¼˜åŒ–ç¼“å­˜ç­–ç•¥ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿå¯å‘å¼ç®—æ³•ã€‚

3. **PoCL æä¾›é«˜å¯é ã€æŠ—æ‹œå åº­çš„å…±è¯†ä¿éšœ**  
   é€šè¿‡â€œåˆä½œè¯æ˜â€æœºåˆ¶åŠ¨æ€é€‰ä¸¾è®­ç»ƒèŠ‚ç‚¹ï¼Œå¹¶ç»“åˆ Commit é˜¶æ®µçš„æŠ•ç¥¨éªŒè¯ï¼ŒPoCL åœ¨å­˜åœ¨æ•…éšœæˆ–æ¶æ„èŠ‚ç‚¹çš„æƒ…å†µä¸‹ä»èƒ½ç»´æŒé«˜å…±è¯†æˆåŠŸç‡ã€‚

4. **TDC-Cache å…·å¤‡è‰¯å¥½å¯æ‰©å±•æ€§ä¸é²æ£’æ€§**  
   å®éªŒæ˜¾ç¤ºï¼Œéšç€ç½‘ç»œè§„æ¨¡æ‰©å¤§ï¼ŒTDC-Cache çš„æ€§èƒ½ä¸é™åå‡ï¼Œå°¤å…¶åœ¨é«˜å¤±è´¥æ¦‚ç‡åœºæ™¯ä¸‹è¿œè¶… PBFTã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–ä»¿çœŸç¯å¢ƒ**ï¼šå®éªŒåŸºäºåˆæˆæ•°æ®ï¼Œå°šæœªåœ¨çœŸå® Web3.0 åº”ç”¨ï¼ˆå¦‚ DApp æˆ– IPFS ç½‘ç»œï¼‰ä¸­éƒ¨ç½²éªŒè¯ã€‚
- **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼šDRL æ¨¡å‹è®­ç»ƒéœ€è¦ä¸€å®šç®—åŠ›èµ„æºï¼Œå¯èƒ½é™åˆ¶è½»é‡çº§è®¾å¤‡å‚ä¸ã€‚
- **æœªè€ƒè™‘æ¿€åŠ±æœºåˆ¶**ï¼šç›®å‰æœªè®¾è®¡ç»æµæ¿€åŠ±æ¥é¼“åŠ± Oracle ä¸»åŠ¨å‚ä¸ç¼“å­˜ä¸è®­ç»ƒä»»åŠ¡ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. è®¾è®¡ **æ¿€åŠ±ç›¸å®¹æœºåˆ¶**ï¼ˆincentive-compatible mechanismï¼‰ï¼Œé¼“åŠ±æ›´å¤šèŠ‚ç‚¹è¯šå®å‚ä¸ã€‚
2. æ¢ç´¢ **è½»é‡åŒ– DRL æ¨¡å‹**ï¼Œé™ä½è¾¹ç¼˜è®¾å¤‡çš„è®¡ç®—è´Ÿæ‹…ã€‚
3. ç ”ç©¶ **åŠ¨æ€ç½‘ç»œæ‹“æ‰‘ä¸‹çš„é€‚åº”æ€§**ï¼Œæ”¯æŒèŠ‚ç‚¹é¢‘ç¹åŠ å…¥/é€€å‡ºã€‚
4. å°† TDC-Cache é›†æˆåˆ°å®é™… Web3.0 ç”Ÿæ€ç³»ç»Ÿä¸­è¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> TDC-Cache æ˜¯é¦–ä¸ªé¢å‘ Web3.0 çš„å¯ä¿¡å»ä¸­å¿ƒåŒ–ååŒç¼“å­˜æ¡†æ¶ï¼Œèåˆ DRL åŠ¨æ€ä¼˜åŒ–ä¸ PoCL å®‰å…¨å…±è¯†ï¼Œåœ¨å»¶è¿Ÿã€å‘½ä¸­ç‡å’Œé²æ£’æ€§æ–¹é¢å…¨é¢è¶…è¶Šä¼ ç»Ÿæ–¹æ¡ˆï¼Œä¸ºä¸‹ä¸€ä»£å»ä¸­å¿ƒåŒ–äº’è”ç½‘çš„æ•°æ®é«˜æ•ˆåˆ†å‘æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 11. [HGC-Herd: Efficient Heterogeneous Graph Condensation via Representative Node Herding](https://arxiv.org/abs/2512.09947)

**Authors**: Fuyan Ou, Siqi Ai, Yulin Hu  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.09947v1  

#### Abstract
Heterogeneous graph neural networks (HGNNs) have demonstrated strong capability in modeling complex semantics across multi-type nodes and relations. However, their scalability to large-scale graphs remains challenging due to structural redundancy and high-dimensional node features. Existing graph co...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šHGC-Herd: Efficient Heterogeneous Graph Condensation via Representative Node Herding

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„å›¾ç¥ç»ç½‘ç»œï¼ˆHGNNsï¼‰åœ¨å¤„ç†å¤§è§„æ¨¡å¼‚æ„å›¾æ—¶é¢ä¸´è®¡ç®—å¼€é”€å¤§ã€å†…å­˜æ¶ˆè€—é«˜ä»¥åŠè®­ç»ƒæ•ˆç‡ä½çš„é—®é¢˜ã€‚ä¼ ç»Ÿçš„å›¾å‹ç¼©æ–¹æ³•ï¼ˆå¦‚ GCondï¼‰ä¸»è¦é’ˆå¯¹åŒæ„å›¾è®¾è®¡ï¼Œä¾èµ–æ¢¯åº¦åŒ¹é…æœºåˆ¶ï¼Œå¯¼è‡´**è®¡ç®—å¤æ‚ã€ä¼˜åŒ–å›°éš¾ã€éš¾ä»¥æ‰©å±•åˆ°å¼‚æ„å›¾åœºæ™¯**ã€‚æ­¤å¤–ï¼Œé‡‡æ ·ç±»æ–¹æ³•ï¼ˆå¦‚ GraphSAINTï¼‰å®¹æ˜“å¼•å…¥ä¿¡æ¯ä¸¢å¤±å’Œç»“æ„åå·®ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº† **HGC-Herd** â€”â€” ä¸€ç§**æ— éœ€è®­ç»ƒçš„å¼‚æ„å›¾å‹ç¼©æ¡†æ¶**ï¼ˆtraining-free heterogeneous graph condensationï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡â€œä»£è¡¨æ€§èŠ‚ç‚¹èšé›†â€æ¥ç”Ÿæˆç´§å‡‘ä¸”è¯­ä¹‰ä¸°å¯Œçš„å­å›¾ã€‚è¯¥æ–¹æ³•åŒ…å«ä¸‰ä¸ªå…³é”®æ¨¡å—ï¼š

- **Feature Propagation**ï¼šåŸºäº metapath è¿›è¡Œè½»é‡çº§ç‰¹å¾ä¼ æ’­ï¼Œèåˆå¤šè·³å…³ç³»ä¸Šä¸‹æ–‡ï¼Œå¢å¼ºèŠ‚ç‚¹è¡¨ç¤ºçš„è¯­ä¹‰ä¸°å¯Œæ€§ã€‚
- **Class-wise Prototype Construction**ï¼šä¸ºæ¯ä¸ªç±»åˆ«æ„å»ºç±»åŸå‹ï¼ˆprototypeï¼‰ï¼Œä½œä¸ºè¯¥ç±»è¯­ä¹‰ä¸­å¿ƒã€‚
- **Strategic Herding Selection**ï¼šé‡‡ç”¨ç±»å†…â€œèµ¶ç‰›å¼é€‰æ‹©â€ï¼ˆherdingï¼‰ç­–ç•¥ï¼Œé€æ­¥æŒ‘é€‰æœ€èƒ½é€¼è¿‘ç±»åŸå‹çš„ä»£è¡¨æ€§èŠ‚ç‚¹ï¼Œå½¢æˆå¹³è¡¡ä¸”åˆ¤åˆ«æ€§å¼ºçš„å‹ç¼©å›¾ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- âœ… **æ— éœ€è®­ç»ƒ**ï¼šé¿å…äº†æ¢¯åº¦ä¼˜åŒ–è¿‡ç¨‹ï¼Œæ˜¾è‘—é™ä½è®¡ç®—ä¸è°ƒå‚æˆæœ¬ã€‚
- âœ… **é«˜æ•ˆå¯å¤ç°**ï¼šé€‰æ‹©è¿‡ç¨‹ç¡®å®šæ€§é«˜ï¼Œè·¨éšæœºç§å­ç¨³å®šï¼Œæ”¯æŒé¢„æ„å»ºä¸é‡ç”¨ã€‚
- âœ… **ä¿æŒè¯­ä¹‰ä¸ç»“æ„ä¿çœŸåº¦**ï¼šé€šè¿‡ç±»æ„ŸçŸ¥çš„ herding ç­–ç•¥ä¿ç•™è¯­ä¹‰å¤šæ ·æ€§ä¸è·¨ç±»å‹è¿æ¥ç»“æ„ã€‚
- âœ… **çµæ´»å¯æ§**ï¼šæ”¯æŒæŒ‰ç±»è®¾å®šå‹ç¼©é¢„ç®—ï¼Œé€‚åº”ç±»åˆ«ä¸å¹³è¡¡åœºæ™¯ã€‚
- âœ… **ä½èµ„æºæ¶ˆè€—**ï¼šå¤§å¹…å‡å°‘è¿è¡Œæ—¶é—´å’Œ GPU å†…å­˜å ç”¨ï¼Œé€‚ç”¨äºèµ„æºå—é™ç¯å¢ƒã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ä¸‰ä¸ªæ ‡å‡†å¼‚æ„å›¾åŸºå‡†ä¸Šè¿›è¡ŒéªŒè¯ï¼š
- **ACM**ï¼šå­¦æœ¯ç½‘ç»œï¼ŒèŠ‚ç‚¹ç±»å‹åŒ…æ‹¬ paperã€authorã€subjectã€venueï¼›ä»»åŠ¡æ˜¯å¯¹ paper åˆ†ç±»ï¼ˆ3 ç±»ï¼‰ã€‚
- **DBLP**ï¼šä½œè€…åˆä½œç½‘ç»œï¼ŒèŠ‚ç‚¹ç±»å‹åŒ…æ‹¬ authorã€paperã€venueã€termï¼›ä»»åŠ¡æ˜¯å¯¹ author åˆ†ç±»ï¼ˆ4 ç±»ï¼‰ã€‚
- **Freebase**ï¼šå¤§å‹çŸ¥è¯†å›¾è°±ï¼ŒåŒ…å« bookã€personã€field ç­‰å¤šç§å®ä½“ï¼›ä»»åŠ¡æ˜¯å¯¹ book åˆ†ç±»ï¼ˆ7 ç±»ï¼‰ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **å‹ç¼©æ¯”ä¾‹ï¼ˆcondensation ratioï¼‰**ï¼šæµ‹è¯• $ r \in \{1.2\%, 2.4\%, 4.8\%, 9.6\%\} $
- **ä¸‹æ¸¸æ¨¡å‹**ï¼šSimple-HGNï¼ˆä¸¤å±‚ï¼Œ64 éšè—å•å…ƒï¼‰
- **ä¼˜åŒ–å™¨**ï¼šAdam ($ lr = 5 \times 10^{-4} $)
- **è¯„ä¼°æŒ‡æ ‡**ï¼š**èŠ‚ç‚¹åˆ†ç±»å‡†ç¡®ç‡ï¼ˆaccuracy %ï¼‰**
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA RTX 3050 GPUï¼Œæ¯ç»„å®éªŒé‡å¤ 5 æ¬¡å–å‡å€¼
- **å‹ç¼©å›¾å¤ç”¨**ï¼šæ¯ä¸ªå‹ç¼©æ¯”ä¸‹ä»…æ„å»ºä¸€æ¬¡å›¾ï¼Œå¤šæ¬¡è®­ç»ƒä¸­å…±äº«

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **Random-HG** | éšæœºé‡‡æ ·ç›®æ ‡ç±»å‹èŠ‚ç‚¹ |
| **K-Center-HG** | è´ªå¿ƒ K-center è¦†ç›–ç­–ç•¥é€‰å–èŠ‚ç‚¹ |
| **Coarsening-HG** | åŸºäº METIS çš„å›¾ç²—åŒ–æ–¹æ³• |
| **GCond** | æ¢¯åº¦åŒ¹é…å‹å›¾å‹ç¼©ï¼ˆåŸç”¨äºåŒæ„å›¾ï¼‰ |
| **Whole Dataset** | å…¨å›¾è®­ç»ƒï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table Iï¼‰

| æ•°æ®é›† | å‹ç¼©æ¯” | HGC-Herd å‡†ç¡®ç‡ | å…¨å›¾å‡†ç¡®ç‡ |
|--------|--------|------------------|------------|
| ACM    | 1.2%   | **91.88%**       | 93.11%     |
| ACM    | 9.6%   | **93.01%**       | 93.11%     |
| DBLP   | 1.2%   | **89.86%**       | 95.19%     |
| DBLP   | 9.6%   | **94.79%**       | 95.19%     |
| Freebase | 1.2% | **57.18%**       | 63.67%     |
| Freebase | 9.6% | **61.42%**       | 63.67%     |

> ğŸ’¡ å¯è§ HGC-Herd åœ¨ä»…ä½¿ç”¨ **1.2% æ•°æ®**çš„æƒ…å†µä¸‹ï¼Œåœ¨ ACM ä¸Šè¾¾åˆ°æ¥è¿‘å…¨å›¾æ€§èƒ½ï¼Œåœ¨ DBLP å’Œ Freebase ä¸Šä¹Ÿè¡¨ç°å‡ºæå¼ºçš„å‹ç¼©èƒ½åŠ›ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨æ‰€æœ‰å‹ç¼©æ¯”ä¸‹ï¼ŒHGC-Herd æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•ï¼Œå°¤å…¶åœ¨ä½å‹ç¼©æ¯”ï¼ˆå¦‚ 1.2%ï¼‰æ—¶ä¼˜åŠ¿æœ€ä¸ºæ˜æ˜¾ã€‚
- ä¾‹å¦‚åœ¨ ACM ä¸Š 1.2% æ¡ä»¶ä¸‹ï¼š
  - HGC-Herd: **91.88%**
  - K-Center-HG: 62.66%
  - Coarsening-HG: 64.17%
  - GCond: 41.17% ï¼ˆæ³¢åŠ¨å¤§ï¼ŒÂ±5.14ï¼‰
- è¡¨æ˜ä¼ ç»Ÿæ–¹æ³•åœ¨æç«¯å‹ç¼©ä¸‹ä¸¥é‡æŸå¤±è¯­ä¹‰ä¿¡æ¯ï¼Œè€Œ HGC-Herd èƒ½æœ‰æ•ˆä¿ç•™å…³é”®ç»“æ„ä¸ç±»åˆ«åˆ†å¸ƒã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable IIï¼‰
åœ¨ 1.2% å‹ç¼©æ¯”ä¸‹çš„æ¶ˆèç ”ç©¶æ˜¾ç¤ºï¼š

| å˜ä½“ | ACM å‡†ç¡®ç‡ | Freebase å‡†ç¡®ç‡ |
|------|-------------|-----------------|
| HGC-Herdï¼ˆå®Œæ•´ï¼‰ | **91.88%** | **57.18%** |
| w/o Feature Propagation | 89.45% (-2.43) | 55.12% (-2.06) |
| w/o Herding | 81.23% (-10.65) | 48.67% (-8.51) |

> ğŸ” ç»“è®ºï¼šä¸¤ä¸ªç»„ä»¶éƒ½è‡³å…³é‡è¦ï¼š
> - **ç‰¹å¾ä¼ æ’­** æä¾›å¤šè·³è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼›
> - **herding é€‰æ‹©æœºåˆ¶** ç¡®ä¿ç±»åˆ†å¸ƒå‡è¡¡ä¸ä»£è¡¨æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
- HGC-Herd æ˜¯é¦–ä¸ªä¸“ä¸º **å¼‚æ„å›¾è®¾è®¡çš„æ— éœ€è®­ç»ƒçš„å›¾å‹ç¼©æ¡†æ¶**ï¼Œå®ç°äº†é«˜æ•ˆã€ç¨³å®šã€å¯å¤ç°çš„å‹ç¼©ã€‚
- é€šè¿‡ **ç±»åŸå‹å¼•å¯¼çš„ herding æœºåˆ¶**ï¼Œèƒ½å¤Ÿåœ¨æä½æ•°æ®é‡ä¸‹ï¼ˆå¦‚ 1.2%ï¼‰ç»´æŒæ¥è¿‘å…¨å›¾çš„åˆ†ç±»æ€§èƒ½ã€‚
- ç›¸æ¯”åŸºäºæ¢¯åº¦çš„æ–¹æ³•ï¼ˆå¦‚ GCondï¼‰ï¼ŒHGC-Herd **é€Ÿåº¦å¿« 4â€“6 å€**ï¼Œå†…å­˜æ¶ˆè€—æ›´ä½ï¼Œæ›´é€‚åˆå®é™…éƒ¨ç½²ã€‚
- æ–¹æ³•å¯¹ç±»åˆ«ä¸å¹³è¡¡å…·æœ‰é²æ£’æ€§ï¼Œå› é‡‡ç”¨æŒ‰ç±»æ¯”ä¾‹åˆ†é…é¢„ç®—ç­–ç•¥ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä¾èµ–äººå·¥æŒ‡å®š metapathï¼Œæœªæ¥å¯æ¢ç´¢è‡ªåŠ¨å‘ç°é‡è¦è·¯å¾„ã€‚
- å°šæœªåº”ç”¨äºåŠ¨æ€æˆ–æ—¶ç©ºå¼‚æ„å›¾ã€‚
- å¯¹ extremely long-tail ç±»åˆ«å¯èƒ½ä»å­˜åœ¨è¦†ç›–ä¸è¶³é£é™©ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **åŠ¨æ€å›¾åœºæ™¯**ï¼ˆdynamic graphsï¼‰
- æ¢ç´¢ **è‡ªé€‚åº”ç±»é¢„ç®—åˆ†é…æœºåˆ¶**
- é›†æˆåˆ° **è”é‚¦å­¦ä¹ ä¸éšç§ä¿æŠ¤ç³»ç»Ÿ** ä¸­ï¼Œå‘æŒ¥å…¶æ— éœ€è®­ç»ƒã€å¯ç¦»çº¿å‹ç¼©çš„ä¼˜åŠ¿
- æ”¯æŒæ›´å¤šç±»å‹çš„ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚é“¾æ¥é¢„æµ‹ã€æ¨èï¼‰

---

> âœ… **æ€»ä½“è¯„ä»·**ï¼š  
> HGC-Herd æå‡ºäº†ä¸€ç§ç®€æ´ã€é«˜æ•ˆã€å®ç”¨çš„å¼‚æ„å›¾å‹ç¼©æ–°èŒƒå¼ï¼Œæ‰“ç ´äº†ä¼ ç»Ÿä¾èµ–æ¢¯åº¦ä¼˜åŒ–çš„æ¡†æ¶é™åˆ¶ï¼Œåœ¨ç²¾åº¦ã€é€Ÿåº¦ã€ç¨³å®šæ€§ä¹‹é—´å–å¾—äº†ä¼˜å¼‚å¹³è¡¡ï¼Œå…·å¤‡è¾ƒå¼ºçš„å·¥ç¨‹åº”ç”¨æ½œåŠ›ã€‚

</details>

---

### 12. [DynaMate: An Autonomous Agent for Protein-Ligand Molecular Dynamics Simulations](https://arxiv.org/abs/2512.10034)

**Authors**: Salom\'e Guilbert, Cassandra Masschelein, Jeremy Goumaz, Bohdan Naida, Philippe Schwaller  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.10034v1  

#### Abstract
Force field-based molecular dynamics (MD) simulations are indispensable for probing the structure, dynamics, and functions of biomolecular systems, including proteins and protein-ligand complexes. Despite their broad utility in drug discovery and protein engineering, the technical complexity of MD s...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šDynaMate: An Autonomous Agent for Protein-Ligand Molecular Dynamics Simulations**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
åˆ†å­åŠ¨åŠ›å­¦ï¼ˆ**Molecular Dynamics, MD**ï¼‰æ¨¡æ‹Ÿåœ¨è¯ç‰©å‘ç°å’Œè›‹ç™½è´¨å·¥ç¨‹ä¸­è‡³å…³é‡è¦ï¼Œä½†å…¶æµç¨‹é«˜åº¦å¤æ‚ä¸”æ˜“å‡ºé”™ï¼Œå°¤å…¶åœ¨å¤„ç†**protein-ligandç³»ç»Ÿ**æ—¶ã€‚ä¼ ç»Ÿæµç¨‹æ¶‰åŠå¤šä¸ªæ‰‹åŠ¨æ­¥éª¤ï¼Œå¦‚ç»“æ„æ¸…æ´—ã€è´¨å­åŒ–ã€æº¶å‰‚åŒ–ã€åŠ›åœºå‚æ•°åŒ–ã€å¹³è¡¡ç­‰ï¼Œè¿™äº›æ­¥éª¤å¯¹éä¸“å®¶ç”¨æˆ·é—¨æ§›æé«˜ï¼Œä¸”å®¹æ˜“å› å‚æ•°ä¸åŒ¹é…å¯¼è‡´ä¸ç¨³å®šè½¨è¿¹ã€‚

ç°æœ‰è‡ªåŠ¨åŒ–å·¥å…·ï¼ˆå¦‚CHAPERONgã€PyAutoFEPï¼‰è™½èƒ½ç®€åŒ–éƒ¨åˆ†æµç¨‹ï¼Œä½†é€šå¸¸**ç¼ºä¹çµæ´»æ€§ã€æ— æ³•è‡ªé€‚åº”é”™è¯¯ã€éš¾ä»¥æ‰©å±•åˆ°æ–°ç³»ç»Ÿæˆ–è½¯ä»¶å¹³å°**ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡º **DynaMate**ï¼Œä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆ**LLM**ï¼‰çš„**æ¨¡å—åŒ–å¤šæ™ºèƒ½ä½“æ¡†æ¶**ï¼ˆmulti-agent frameworkï¼‰ï¼Œèƒ½å¤Ÿ**è‡ªä¸»è®¾è®¡å¹¶æ‰§è¡Œå®Œæ•´çš„protein-ligand MDæ¨¡æ‹Ÿæµç¨‹**ï¼Œå¹¶æ”¯æŒç»“åˆ**MM/PB(GB)SAæ–¹æ³•è¿›è¡Œç»“åˆè‡ªç”±èƒ½è®¡ç®—**ã€‚

DynaMateçš„æ ¸å¿ƒæ¶æ„åŒ…å«ä¸‰ä¸ªä¸“ç”¨æ™ºèƒ½ä½“ï¼š
- **Planner Agent**ï¼šè§£æç”¨æˆ·è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œæ£€ç´¢ç»“æ„ä¿¡æ¯ï¼Œåˆ¶å®šä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ¨¡æ‹Ÿè®¡åˆ’ã€‚
- **MD Agent**ï¼šæ‰§è¡Œæ¨¡æ‹Ÿä»»åŠ¡ï¼Œè°ƒç”¨å·¥å…·è¿›è¡Œç»“æ„å‡†å¤‡ã€å‚æ•°åŒ–ã€æº¶å‰‚åŒ–ã€èƒ½é‡æœ€å°åŒ–ã€å¹³è¡¡å’Œç”Ÿäº§è¿è¡Œã€‚
- **Analyzer Agent**ï¼šåˆ†æè½¨è¿¹ï¼Œç”ŸæˆRMSDã€RMSFã€gyration radiusã€æ°¢é”®ç­‰ç»Ÿè®¡å›¾è¡¨ï¼Œå¹¶æä¾›è‡ªç„¶è¯­è¨€è§£é‡Šã€‚

è¯¥æ¡†æ¶å…·å¤‡ä»¥ä¸‹å…³é”®èƒ½åŠ›ï¼š
- **åŠ¨æ€å·¥å…·è°ƒç”¨**ï¼ˆdynamic tool useï¼‰
- **æ–‡çŒ®å¢å¼ºæ¨ç†**ï¼ˆretrieval-augmented reasoningï¼Œé€šè¿‡PaperQAå’Œweb searchï¼‰
- **è‡ªçº é”™è¡Œä¸º**ï¼ˆself-correcting behaviorï¼‰
- **è·¨å¹³å°å…¼å®¹æ€§**ï¼ˆæ”¯æŒGROMACSå’ŒAmberToolsï¼‰

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç‰¹æ€§ | MDCrow / NAMD-Agent | DynaMateï¼ˆæœ¬æ–‡ï¼‰ |
|------|---------------------|------------------|
| æ”¯æŒprotein-ligandç³»ç»Ÿ | âŒ | âœ… |
| ç»“åˆè‡ªç”±èƒ½è®¡ç®—ï¼ˆMM/PB(GB)SAï¼‰ | âŒ | âœ… |
| è‡ªåŠ¨é”™è¯¯æ£€æµ‹ä¸æ¢å¤ | âŒ | âœ… |
| æ–‡çŒ®/æ•°æ®åº“æ£€ç´¢å¢å¼º | æœ‰é™ | âœ…ï¼ˆPaperQA + web searchï¼‰ |
| å¤šæ™ºèƒ½ä½“æ¨¡å—åŒ–æ¶æ„ | âŒ | âœ… |
| è·¨å¹³å°æ”¯æŒï¼ˆGROMACS/Amberï¼‰ | å•ä¸€å¼•æ“ | âœ… |

DynaMateæ˜¯é¦–ä¸ªæˆåŠŸå®ç°**å…¨è‡ªåŠ¨protein-ligand MDæµç¨‹**å¹¶å…·å¤‡**è‡ªçº é”™èƒ½åŠ›**çš„agenticç³»ç»Ÿã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
å…±æµ‹è¯•äº†12ä¸ªbenchmarkç³»ç»Ÿï¼š
- **5ä¸ªprotein-ligandå¤åˆç‰©**ï¼ˆPDB IDs: 3HTB, 3PTB, 4GIH, 4W52, 5UEZï¼‰â€”â€”å¹¿æ³›ç”¨äºMDå’Œè‡ªç”±èƒ½æ–¹æ³•åŸºå‡†æµ‹è¯•ã€‚
- **5ä¸ªæ— é…ä½“è›‹ç™½ç³»ç»Ÿ**ï¼ˆPDB IDs: 1AKI, 1FDH, 1J37, 2CBA, 2VVBï¼‰â€”â€”æµ‹è¯•å¤šé“¾è›‹ç™½å’Œé€šç”¨æ€§ã€‚
- **2ä¸ªå«å·²çŸ¥é”™è¯¯çš„ç³»ç»Ÿ**ï¼š
  - **BRD4_UNL**ï¼šäººä¸ºå¼•å…¥æ°¯åŸå­å‘½åé”™è¯¯ã€‚
  - **5KB6_ADN**ï¼šå«ä¸¤ä¸ªé…ä½“ï¼Œæµ‹è¯•æ¡†æ¶å¯¹å¤æ‚ç³»ç»Ÿçš„é€‚åº”èƒ½åŠ›ã€‚

æ­¤å¤–ï¼Œåœ¨ç»“åˆè‡ªç”±èƒ½è®¡ç®—éƒ¨åˆ†ï¼Œä½¿ç”¨äº†**10ä¸ªBRD4 BD1æŠ‘åˆ¶å‰‚**ï¼ˆPDB: 6JJ3ï¼‰è¿›è¡Œæµ‹è¯•ï¼Œä¸GNINAå¯¹æ¥åˆ†æ•°å’Œå®éªŒIC50å€¼å¯¹æ¯”ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **LLMæ¨¡å‹**ï¼šæµ‹è¯•äº†5ç§LLMï¼š
  - `Claude 3 Opus`, `Claude 3.7 Sonnet`, `GPT-4.1`, `GPT-4.1 mini`, `Llama 3.3`
- **æ¯ç»„å®éªŒé‡å¤3æ¬¡**ä»¥éªŒè¯é²æ£’æ€§ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **å‡†ç¡®æ€§ï¼ˆAccuracyï¼‰**ï¼šå…³é”®æ­¥éª¤æ˜¯å¦æˆåŠŸåˆ›å»ºå¿…è¦æ–‡ä»¶ï¼ˆéç©ºï¼‰ã€‚
  - **æ•ˆç‡ï¼ˆEfficiencyï¼‰**ï¼šå®é™…tool callsæ•° vs æœ€å°å¿…éœ€tool callsæ•°ã€‚
  - **é”™è¯¯çº æ­£èƒ½åŠ›**ï¼šèƒ½å¦è¯†åˆ«å¹¶ä¿®å¤è¾“å…¥é”™è¯¯ï¼ˆå¦‚åŸå­å‘½åã€ä½ç½®çº¦æŸç¼ºå¤±ï¼‰ã€‚
  - **ç»“åˆè‡ªç”±èƒ½é¢„æµ‹ç›¸å…³æ€§**ï¼šMM/PB(GB)SA Î”Î”G ä¸å®éªŒIC50çš„ç›¸å…³ç³»æ•°ï¼ˆPearson *r*ï¼‰ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- ä¸ç°æœ‰agentic MDæ¡†æ¶ï¼ˆMDCrow, NAMD-Agentï¼‰å¯¹æ¯”åŠŸèƒ½å®Œæ•´æ€§ï¼ˆè§Table S1ï¼‰ã€‚
- ä¸ä¼ ç»Ÿæ‰‹åŠ¨æµç¨‹å¯¹æ¯”è‡ªåŠ¨åŒ–ç¨‹åº¦å’ŒæˆåŠŸç‡ã€‚
- ä¸**GNINAå¯¹æ¥æ‰“åˆ†**å¯¹æ¯”ç»“åˆäº²å’ŒåŠ›é¢„æµ‹æ€§èƒ½ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- **åœ¨5ä¸ªæ ‡å‡†protein-ligandç³»ç»Ÿä¸Šï¼Œæ‰€æœ‰LLMå‡è¾¾åˆ°100%å‡†ç¡®ç‡**ï¼ˆå›¾2aï¼‰ï¼ŒæˆåŠŸå®Œæˆä»ç»“æ„å‡†å¤‡åˆ°ç”Ÿäº§æ¨¡æ‹Ÿçš„å…¨æµç¨‹ã€‚
- **åœ¨å«é”™è¯¯çš„BRD4_UNLç³»ç»Ÿä¸Š**ï¼š
  - `Claude 3.7 Sonnet` å’Œ `GPT-4.1 mini` åœ¨3æ¬¡è¿è¡Œä¸­å‡æˆåŠŸä¿®æ­£æ°¯åŸå­å‘½åé”™è¯¯ã€‚
  - `GPT-4.1` æœ‰ä¸€æ¬¡æˆåŠŸé€šè¿‡æ‰‹åŠ¨æ’å…¥GAFFå‚æ•°è§£å†³ã€‚
  - `Claude 3 Opus` é€šè¿‡ç§»é™¤æ°¯åŸå­â€œç»•è¿‡â€é—®é¢˜ï¼ˆç»“æ„è¢«ä¿®æ”¹ï¼Œä¸ç†æƒ³ï¼‰ã€‚
  - `Llama 3.3` å®Œå…¨å¤±è´¥ã€‚
- **åœ¨åŒé…ä½“ç³»ç»Ÿ5KB6_ADNä¸Šï¼Œæ‰€æœ‰LLMå‡æœªèƒ½å®Œæˆ**ï¼Œæš´éœ²å½“å‰å·¥å…·é›†çš„å±€é™æ€§ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **åŠŸèƒ½å…¨é¢æ€§è¿œè¶…MDCrow/NAMD-Agent**ï¼šé¦–æ¬¡æ”¯æŒligandç³»ç»Ÿã€è‡ªç”±èƒ½è®¡ç®—ã€è‡ªçº é”™ã€‚
- **ç»“åˆè‡ªç”±èƒ½é¢„æµ‹æ€§èƒ½ä¼˜äºå¯¹æ¥æ‰“åˆ†**ï¼š
  - DynaMateçš„MM/PB(GB)SA Î”Î”G ä¸å®éªŒIC50ç›¸å…³æ€§ä¸º **r = 0.597**
  - GNINAå¯¹æ¥æ‰“åˆ†ç›¸å…³æ€§ä»…ä¸º **r = 0.385**
  - è¡¨æ˜MDæ¨¡æ‹Ÿæä¾›çš„åŠ¨æ€ä¿¡æ¯æ˜¾è‘—æå‡äº²å’ŒåŠ›é¢„æµ‹å¯é æ€§ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
- **æ•ˆç‡åˆ†æ**ï¼ˆå›¾2bï¼‰ï¼š
  - `Claude 3 Opus` å’Œ `GPT-4.1` å·¥å…·è°ƒç”¨æœ€é«˜æ•ˆï¼ˆæ¥è¿‘ç†è®ºæœ€å°å€¼ï¼‰ã€‚
  - `Claude 3.7 Sonnet` å‡†ç¡®ç‡æœ€é«˜ä½†æ•ˆç‡ç•¥ä½ï¼Œå› å…¶è¿›è¡Œäº†æ›´å¤šå°è¯•æ€§ä¿®å¤ã€‚
  - `Llama 3.3` æ•ˆç‡æœ€ä½ï¼Œå¸¸è¯¯ç”¨å·¥å…·æˆ–æ— æ³•çº é”™ã€‚
- **é”™è¯¯çº æ­£æ¡ˆä¾‹ç ”ç©¶**ï¼š
  - **ä½ç½®çº¦æŸé”™è¯¯ï¼ˆ1J37ç³»ç»Ÿï¼‰**ï¼šæ‰€æœ‰LLMå‡è¯†åˆ«é—®é¢˜ï¼Œä½†ä»…`Claude 3.7 Sonnet`å°è¯•æ‰‹åŠ¨åˆ›å»ºposreæ–‡ä»¶ï¼ˆæœªå®Œå…¨æˆåŠŸï¼‰ã€‚
  - **åŒé…ä½“ç³»ç»Ÿï¼ˆ5KB6_ADNï¼‰**ï¼š`Claude`ç³»åˆ—è¡¨ç°å‡ºæ›´å¼ºçš„æ¢ç´¢æ€§ï¼ˆä½¿ç”¨æ–‡çŒ®æœç´¢ã€å°è¯•è„šæœ¬ç”Ÿæˆï¼‰ï¼Œè€Œå…¶ä»–æ¨¡å‹å¤šä¸ºé‡å¤å°è¯•ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **DynaMateå¯å¯é æ‰§è¡Œå®Œæ•´protein-ligand MDæµç¨‹**ï¼Œåœ¨æ ‡å‡†ç³»ç»Ÿä¸ŠæˆåŠŸç‡100%ã€‚
2. **å…·å¤‡å¼ºå¤§çš„é”™è¯¯è¯Šæ–­ä¸è‡ªçº é”™èƒ½åŠ›**ï¼Œèƒ½åœ¨å¤šç§é”™è¯¯åœºæ™¯ä¸‹ï¼ˆå¦‚åŸå­å‘½åé”™è¯¯ï¼‰æ‰¾åˆ°å¯è¡Œè§£å†³æ–¹æ¡ˆã€‚
3. **ç»“åˆMM/PB(GB)SAçš„è‡ªç”±èƒ½è®¡ç®—å…·æœ‰å®ç”¨ä»·å€¼**ï¼Œé¢„æµ‹ç»“æœä¸å®éªŒæ•°æ®æœ‰è‰¯å¥½ç›¸å…³æ€§ï¼Œä¼˜äºä¼ ç»Ÿå¯¹æ¥æ–¹æ³•ã€‚
4. **LLMé€‰æ‹©æ˜¾è‘—å½±å“æ€§èƒ½**ï¼š`Claude 3.7 Sonnet`åœ¨å‡†ç¡®æ€§å’Œåˆ›é€ æ€§æ–¹é¢è¡¨ç°æœ€ä½³ï¼Œ`Llama 3.3`æ˜æ˜¾è½åã€‚
5. **å³ä½¿å¤±è´¥ï¼ŒDynaMateä»èƒ½æä¾›æœ‰ä»·å€¼çš„è°ƒè¯•å»ºè®®**ï¼Œå¸®åŠ©ç”¨æˆ·å®šä½é—®é¢˜æ–‡ä»¶å’Œå…³é”®è¯ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–å¤–éƒ¨LLM API**ï¼šéœ€APIå¯†é’¥å’Œè´¹ç”¨ï¼Œå­˜åœ¨é€Ÿç‡é™åˆ¶å’Œå®‰å…¨é¡¾è™‘ã€‚
- **ä¸æ”¯æŒé•¿æœŸè®°å¿†**ï¼šæ¯æ¬¡è¿è¡Œç‹¬ç«‹ï¼Œæ— æ³•ä»å†å²ç»éªŒå­¦ä¹ ã€‚
- **å·¥å…·é›†æœ‰é™**ï¼šæ— æ³•å¤„ç†å¤šé…ä½“ã€è†œè›‹ç™½ã€DNA/RNAç­‰å¤æ‚ç³»ç»Ÿã€‚
- **è¾“å…¥PDBæ ¼å¼æ•æ„Ÿ**ï¼šéå¸¸è§„åŸå­å‘½åã€ç¼ºå¤±æ®‹åŸºç­‰ä»å¯èƒ½å¯¼è‡´å¤±è´¥ã€‚
- **è´¨å­åŒ–çŠ¶æ€å†³ç­–é£é™©**ï¼šç»„æ°¨é…¸ã€å¤©å†¬æ°¨é…¸ç­‰æ®‹åŸºçš„è´¨å­åŒ–çŠ¶æ€å¯èƒ½å½±å“ç»“æœï¼Œå½“å‰ä¾èµ–é»˜è®¤æˆ–æ–‡çŒ®æœç´¢ï¼Œéç»å¯¹å¯é ã€‚
- **MM/PB(GB)SAæ–¹æ³•å›ºæœ‰å±€é™**ï¼šå¿½ç•¥æ„è±¡ç†µå˜ï¼Œé€‚ç”¨äºç›¸å¯¹æ’åè€Œéç»å¯¹è‡ªç”±èƒ½é¢„æµ‹ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•å·¥å…·é›†ä»¥æ”¯æŒ**è†œè›‹ç™½ã€æ ¸é…¸ã€å¤šé…ä½“ç³»ç»Ÿ**ã€‚
- å¼•å…¥**æŒä¹…åŒ–è®°å¿†æœºåˆ¶**ï¼Œä½¿æ™ºèƒ½ä½“èƒ½ä»è¿‡å¾€è¿è¡Œä¸­å­¦ä¹ ã€‚
- é›†æˆæ›´ä¸“ä¸šçš„**è½¯ä»¶æ–‡æ¡£å’Œç§‘å­¦è®ºæ–‡æ•°æ®åº“**ï¼Œæå‡å‚æ•°é€‰æ‹©å¯é æ€§ã€‚
- æ¢ç´¢**å¼€æºLLMæœ¬åœ°éƒ¨ç½²**ï¼Œé™ä½å¯¹å•†ä¸šAPIçš„ä¾èµ–ã€‚
- å¢å¼ºå¯¹**å¼‚å¸¸PDBæ–‡ä»¶çš„é²æ£’æ€§å¤„ç†**èƒ½åŠ›ã€‚
- å¼€å‘**äº¤äº’å¼è°ƒè¯•æ¨¡å¼**ï¼Œå…è®¸ç”¨æˆ·ä»‹å…¥å¹¶æŒ‡å¯¼æ™ºèƒ½ä½“ã€‚

---

> **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/schwallergroup/DynaMate](https://github.com/schwallergroup/DynaMate)

</details>

---

### 13. [Phythesis: Physics-Guided Evolutionary Scene Synthesis for Energy-Efficient Data Center Design via LLMs](https://arxiv.org/abs/2512.10611)

**Authors**: Minghao LI, Ruihang Wang, Rui Tan, Yonggang Wen  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.10611v1  

#### Abstract
Data center (DC) infrastructure serves as the backbone to support the escalating demand for computing capacity. Traditional design methodologies that blend human expertise with specialized simulation tools scale poorly with the increasing system complexity. Recent studies adopt generative artificial...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠPhythesis: Physics-Guided Evolutionary Scene Synthesis for Energy-Efficient Data Center Design via LLMsã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿæ•°æ®ä¸­å¿ƒï¼ˆDCï¼‰è®¾è®¡ä¾èµ–äººå·¥ç»éªŒä¸ä¸“ç”¨ä»¿çœŸå·¥å…·ï¼Œéš¾ä»¥åº”å¯¹æ—¥ç›Šå¢é•¿çš„ç³»ç»Ÿå¤æ‚æ€§å’Œè®¾è®¡æ•ˆç‡éœ€æ±‚ã€‚è¿‘æœŸåŸºäºç”Ÿæˆå¼AIçš„æ–¹æ³•è™½èƒ½è‡ªåŠ¨åŒ–ç”Ÿæˆå®¤å†…åœºæ™¯å¸ƒå±€ï¼Œä½†**ç¼ºä¹å¯¹ç‰©ç†è§„å¾‹ï¼ˆå¦‚çƒ­åŠ›å­¦ã€èƒ½é‡å®ˆæ’ï¼‰çš„å»ºæ¨¡èƒ½åŠ›**ï¼Œå¯¼è‡´åœ¨éœ€è¦ä¸¥æ ¼ç‰©ç†çº¦æŸçš„æ•°æ®ä¸­å¿ƒè®¾è®¡ä¸­äº§ç”Ÿâ€œå¹»è§‰â€ï¼ˆhallucinationsï¼‰ï¼Œæ— æ³•æ»¡è¶³å¯é‡åŒ–çš„è¿è¡Œç›®æ ‡ï¼ˆå¦‚PUEä¼˜åŒ–ï¼‰ã€‚å› æ­¤ï¼Œå¦‚ä½•å°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¼ºå¤§è¯­ä¹‰æ¨ç†èƒ½åŠ›ä¸ç‰©ç†è§„å¾‹ç›¸ç»“åˆï¼Œå®ç°é«˜æ•ˆä¸”ç¬¦åˆç‰©ç†çœŸå®æ€§çš„æ•°æ®ä¸­å¿ƒè‡ªåŠ¨åŒ–è®¾è®¡ï¼Œæ˜¯ä¸€ä¸ªäºŸå¾…è§£å†³çš„å…³é”®æŒ‘æˆ˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
æœ¬æ–‡æå‡º **Phythesis** â€”â€” ä¸€ç§**ç‰©ç†å¼•å¯¼çš„è¿›åŒ–å¼åœºæ™¯åˆæˆæ¡†æ¶**ï¼ˆPhysics-Guided Evolutionary Scene Synthesisï¼‰ï¼Œç”¨äºé€šè¿‡LLMå®ç°èŠ‚èƒ½å‹æ•°æ®ä¸­å¿ƒçš„è‡ªåŠ¨åŒ–è®¾è®¡ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š

- **åŒå±‚ä¼˜åŒ–æ¶æ„ï¼ˆBi-Level Optimizationï¼‰**ï¼š
  - **LLMé©±åŠ¨ä¼˜åŒ–å±‚**ï¼šåˆ©ç”¨ä¸¤ä¸ªLLMä»£ç†ååŒå·¥ä½œâ€”â€”**Design LLM** è´Ÿè´£ç”Ÿæˆä¸‰ç»´å¸ƒå±€æ–¹æ¡ˆï¼›**Reflection LLM** å¯¹ä»¿çœŸç»“æœè¿›è¡Œåˆ†æå¹¶è‡ªæˆ‘æ‰¹åˆ¤ï¼ŒæŒ‡å¯¼åç»­è¿­ä»£æ”¹è¿›ã€‚
  - **ç‰©ç†æ„ŸçŸ¥ä¼˜åŒ–å±‚**ï¼ˆPhysics-Informed Optimizationï¼‰ï¼šåŸºäºå¯å¾®åˆ†ç‰©ç†å¼•æ“ï¼ˆdifferentiable physics-based modelï¼‰ï¼Œé€šè¿‡åå‘ä¼ æ’­ï¼ˆbackpropagationï¼‰ä¼˜åŒ–è®¾å¤‡å‚æ•°ï¼Œå¹¶ä»èµ„äº§åº“ä¸­é€‰æ‹©æœ€æ¥è¿‘â€œç†æƒ³å‚æ•°â€çš„å®é™…è®¾å¤‡ç»„åˆã€‚

- **è¿›åŒ–å¼ç”Ÿæˆæµç¨‹**ï¼šé‡‡ç”¨ç±»è¿›åŒ–ç®—æ³•çš„è¿­ä»£æœºåˆ¶ï¼Œä½†ä»¥LLMçš„ä¸Šä¸‹æ–‡å­¦ä¹ æ›¿ä»£ä¼ ç»Ÿçš„äº¤å‰/å˜å¼‚æ“ä½œï¼Œå®ç°**è¯­ä¹‰å±‚é¢çš„è®¾è®¡æ¢ç´¢ä¸ç‰©ç†åé¦ˆé©±åŠ¨çš„æ”¶æ•›ä¼˜åŒ–**ã€‚

- **SimReady åœºæ™¯è¾“å‡º**ï¼šæœ€ç»ˆç”Ÿæˆçš„è®¾è®¡ä¸ä»…åŒ…å«å‡ ä½•ç»“æ„å’Œæ‹“æ‰‘å…³ç³»ï¼Œè¿˜å…·å¤‡å®Œæ•´çš„ç‰©ç†å±æ€§ï¼Œå¯ç›´æ¥ç”¨äºé«˜ä¿çœŸä»¿çœŸéªŒè¯ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | Phythesis çš„ä¼˜åŠ¿ |
|------|--------|------------------|
| ä¼ ç»ŸåŠè‡ªåŠ¨è®¾è®¡ | æ•ˆç‡ä½ã€äººåŠ›å¯†é›† | è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜ï¼Œå¤§å¹…ç¼©çŸ­è®¾è®¡å‘¨æœŸ |
| Vanilla LLM ç›´æ¥ç”Ÿæˆ | å¿½è§†ç‰©ç†è§„å¾‹ï¼Œæ˜“äº§ç”Ÿä¸å¯è¡Œè®¾è®¡ | å¼•å…¥ç‰©ç†å…ˆéªŒä¸åé¦ˆï¼Œæ˜¾è‘—æå‡å¯è¡Œæ€§ |
| çº¯è¿›åŒ–ç®—æ³•ï¼ˆEAï¼‰ | ç¼ºä¹é«˜å±‚è¯­ä¹‰ç†è§£ä¸åˆ›é€ æ€§ | ç»“åˆLLMè¯­ä¹‰æ¨ç†ï¼Œåˆå§‹åŒ–æ›´ä¼˜ï¼Œæœç´¢æ›´æ™ºèƒ½ |
| å…¶ä»–3Dåœºæ™¯ç”Ÿæˆæ–¹æ³•ï¼ˆå¦‚Layout-GPTï¼‰ | é¢å‘äººç±»ç”Ÿæ´»ç©ºé—´ï¼Œä¸é€‚ç”¨äºå·¥ä¸šç³»ç»Ÿ | é’ˆå¯¹æ•°æ®ä¸­å¿ƒå®šåˆ¶ï¼Œæ”¯æŒå†·å´ã€ç”µåŠ›ç­‰å·¥ä¸šçº§çº¦æŸ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸èµ„äº§åº“
- ä½¿ç”¨ä¸€ä¸ª**åˆæˆçš„SimReadyèµ„äº§åº“**ï¼ŒåŒ…å«æ¯ç§è®¾å¤‡ç±»å‹ï¼ˆRackã€ACUã€Chillerã€Cooling Towerï¼‰å„10ç§å‹å·ã€‚
- æ‰©å±•å®éªŒä¸­æµ‹è¯•äº†æ›´å¤§è§„æ¨¡çš„èµ„äº§åº“ï¼ˆ20ã€30ã€50ç§/ç±»ï¼‰ï¼ŒéªŒè¯æ–¹æ³•åœ¨å¤æ‚ç»„åˆç©ºé—´ä¸‹çš„é€‚åº”æ€§ã€‚
- å¤–éƒ¨ç¯å¢ƒæ•°æ®æ¥è‡ªEnergyPlus Weather (EPW) æ–‡ä»¶ï¼Œæ¶µç›–çƒ­å¸¦ï¼ˆæ–°åŠ å¡ï¼‰ã€å¹²æ—±ã€æ¸©å¸¦ç­‰å¤šç§æ°”å€™åŒºåŸŸã€‚

### å®éªŒè®¾ç½®
- **ä»»åŠ¡ç»´åº¦**ï¼šä¸‰ä¸ªä¸åŒè®¡ç®—è§„æ¨¡åœºæ™¯ï¼š
  - Small-Edgeï¼ˆ50â€“100 serversï¼‰
  - Medium-Clusterï¼ˆ1,000+ serversï¼‰
  - Large-Cloudï¼ˆ10,000+ serversï¼‰
- **LLMéª¨å¹²æ¨¡å‹**ï¼š
  - Instructive LLM (I-LM)ï¼šGPT-4
  - Reasoning LLM (R-LM)ï¼šo3-mini
- **è¿­ä»£å‚æ•°**ï¼šæ¯æ¬¡ç”ŸæˆN=5ä¸ªå€™é€‰è®¾è®¡ï¼Œä¿ç•™K=5ä¸ªæœ€ä¼˜å†å²è®¾è®¡ä½œä¸ºä¸Šä¸‹æ–‡ã€‚
- **æ€»è¿­ä»£æ¬¡æ•°**ï¼šM=5æ¬¡ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ | ä¼˜åŒ–æ–¹å‘ |
|------|------|----------|
| **PUE**ï¼ˆPower Usage Effectivenessï¼‰ | æ€»èƒ½è€— / ITè®¾å¤‡èƒ½è€—ï¼Œè¡¡é‡èƒ½æºæ•ˆç‡ | â†“ è¶Šä½è¶Šå¥½ |
| **GSR**ï¼ˆGeneration Success Rateï¼‰ | æˆåŠŸæ»¡è¶³æ‰€æœ‰ç‰©ç†ä¸å‡ ä½•çº¦æŸçš„è®¾è®¡æ¯”ä¾‹ | â†‘ è¶Šé«˜è¶Šå¥½ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• | æè¿° |
|------|------|------|
| **ç›´æ¥ç”Ÿæˆ** | Random | éšæœºé‡‡æ ·ï¼Œæ— LLMæˆ–ç‰©ç†å¼•å¯¼ |
| | Vanilla LLM | LLMä¸€æ¬¡æ€§ç”Ÿæˆï¼Œæ— è¿­ä»£ä¼˜åŒ– |
| **è¿­ä»£ä¼˜åŒ–** | EA | è¿›åŒ–ç®—æ³•ï¼Œæ— LLMå‚ä¸ |
| | ABL (w/o ...) | å¤šç»„æ¶ˆèå˜ä½“ï¼ˆè§ä¸‹è¡¨ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ–¹æ³• | å°è¾¹ç¼˜åœºæ™¯ GSRâ†‘ | ä¸­é›†ç¾¤åœºæ™¯ GSRâ†‘ | å¤§äº‘åœºæ™¯ GSRâ†‘ | å¤§äº‘åœºæ™¯ PUEâ†“ |
|------|------------------|------------------|------------------|----------------|
| Random | 0.293 | 0.427 | 0.429 | 1.302 |
| Vanilla LLM (R-LM) | 0.947 | 0.782 | **0.813** | 1.162 |
| **Phythesis (R-LM)** | **0.997** | **0.988** | **0.970** | **1.175** |

> æ³¨ï¼šå°½ç®¡Phythesisåœ¨Large-Cloudåœºæ™¯çš„PUEç•¥é«˜äºVanilla LLMï¼ˆå› åè€…å¯èƒ½è¿åçº¦æŸï¼‰ï¼Œä½†åœ¨**æˆåŠŸç”Ÿæˆçš„è®¾è®¡ä¸­ï¼ŒPhythesiså®ç°äº†æ›´ä½çš„å®é™…PUE**ã€‚

#### æ€§èƒ½æå‡æ€»ç»“ï¼š
- **ç›¸æ¯” Vanilla LLM**ï¼š
  - GSRå¹³å‡æå‡è¾¾ **57.3%**
  - åœ¨æˆåŠŸç”Ÿæˆçš„è®¾è®¡ä¸­ï¼ŒPUEæ”¹å–„ **11.5%**
- **ç›¸æ¯” Random å’Œ EA**ï¼š
  - GSRæœ€é«˜æå‡è¶…è¿‡ **240%**
  - PUEæ˜¾è‘—é™ä½ï¼ˆå¦‚Small-Edgeä»1.8é™è‡³1.25ï¼‰

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

| å˜ä½“ | ç§»é™¤æ¨¡å— | å½±å“ |
|------|---------|------|
| ABL (w/o reflect, phy) | æ— Reflection LLM + æ— ç‰©ç†ä¼˜åŒ– | åˆå§‹PUEå·®ï¼Œæ”¶æ•›æ…¢ï¼ŒGSRä¸‹é™çº¦24% |
| ABL (w/o design, phy) | æ— Design LLM + æ— ç‰©ç†ä¼˜åŒ– | åˆå§‹åŒ–è´¨é‡å·®ï¼ŒGSRä¸‹é™30%ä»¥ä¸Š |
| ABL (w/o phy) | ä»…ç§»é™¤ç‰©ç†ä¼˜åŒ–å±‚ | GSRä¸‹é™2.4%-7.9%ï¼ŒPUEä¸Šå‡0.2%-0.5% |
| ABL (w/o llm) | å®Œå…¨ç§»é™¤LLMæ¨¡å— | GSRæš´è·Œ45.9%ï¼ˆå°è¾¹ç¼˜ï¼‰ï¼ŒPUEä¸Šå‡0.374 |

> âœ… **å…³é”®å‘ç°**ï¼šåŒå±‚ä¼˜åŒ–ç»“æ„ç¼ºä¸€ä¸å¯ã€‚LLMæä¾›é«˜è´¨é‡åˆå§‹åŒ–ä¸è¯­ä¹‰æ¢ç´¢ï¼Œç‰©ç†ä¼˜åŒ–ç¡®ä¿ç²¾ç¡®æ”¶æ•›ä¸çº¦æŸæ»¡è¶³ã€‚

### å¯æ‰©å±•æ€§æµ‹è¯•ï¼ˆTable 2ï¼‰
å½“èµ„äº§åº“æ‰©å¤§è‡³50ç§/ç±»æ—¶ï¼š
- Phythesisä»ä¿æŒ **GSR = 0.973**
- PUE = **1.218**ï¼Œæ¯”EAä½ **21.2%**
- è¡¨æ˜è¯¥æ–¹æ³•åœ¨å¤§è§„æ¨¡ç»„åˆç©ºé—´ä¸­ä¾ç„¶ç¨³å®šæœ‰æ•ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LLM + ç‰©ç†åé¦ˆ = æ›´å¼ºçš„è®¾è®¡æ™ºèƒ½**  
   å•çº¯ä¾èµ–LLMç”Ÿæˆå®¹æ˜“â€œè„±ç¦»ç°å®â€ï¼Œè€Œå¼•å…¥ç‰©ç†ä»¿çœŸåé¦ˆåï¼ŒReflection LLMèƒ½å¤Ÿè¯†åˆ«è¿‡çƒ­ã€èƒ½è€—å¼‚å¸¸ç­‰é—®é¢˜ï¼Œå¹¶æå‡ºæ”¹è¿›å»ºè®®ï¼Œå½¢æˆé—­ç¯ä¼˜åŒ–ã€‚

2. **åŒå±‚ä¼˜åŒ–æ¶æ„æ˜¾è‘—ä¼˜äºå•ä¸€æµç¨‹**  
   LLMè´Ÿè´£å®è§‚æ‹“æ‰‘ä¸å¸ƒå±€æ¢ç´¢ï¼Œç‰©ç†å¼•æ“è´Ÿè´£å¾®è§‚å‚æ•°è°ƒä¼˜ï¼ŒäºŒè€…ååŒå®ç°äº†**æ¢ç´¢ï¼ˆexplorationï¼‰ä¸åˆ©ç”¨ï¼ˆexploitationï¼‰çš„å¹³è¡¡**ã€‚

3. **ç‰©ç†å…ˆéªŒæå¤§æå‡åˆå§‹è®¾è®¡è´¨é‡**  
   Design LLMç»“åˆSimReadyèµ„äº§ä¸å¤–éƒ¨ç¯å¢ƒä¿¡æ¯ï¼Œåœ¨ç¬¬ä¸€è½®å³ç”Ÿæˆæ¥è¿‘å¯è¡Œè§£çš„è®¾è®¡ï¼Œé¿å…äº†ä¼ ç»Ÿéšæœºåˆå§‹åŒ–çš„ä½æ•ˆæœç´¢ã€‚

4. **å®é™…å¯æŒç»­æ€§å½±å“æ˜¾è‘—**  
   åœ¨æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼ŒPhythesisè®¾è®¡çš„è¾¹ç¼˜æ•°æ®ä¸­å¿ƒå®ç°PUEâ‰ˆ1.23ï¼Œè¾ƒè¡Œä¸šæ ‡å‡†1.3é™ä½6.2%ï¼Œç›¸å½“äºæ¯å¹´èŠ‚çœ**31.2 GWhç”µèƒ½**ï¼Œè¶³ä»¥æ”¯æ’‘æ–°åŠ å¡500ä¸‡äººå£åŸå¸‚è¿‘ä¸¤å¤©çš„å±…æ°‘ç”¨ç”µã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **æ¨¡æ‹Ÿå™¨ç²¾åº¦é™åˆ¶**ï¼šå½“å‰ä½¿ç”¨çš„æ˜¯ç»„ä»¶çº§æŠ½è±¡æ¨¡å‹ï¼Œéå®Œæ•´CFDä»¿çœŸï¼Œç»†èŠ‚ï¼ˆå¦‚æ°”æµåˆ†å¸ƒï¼‰æœªå®Œå…¨æ•æ‰ã€‚
2. **èµ„äº§åº“ä¾èµ–æ€§å¼º**ï¼šâ€œä¼˜åŒ–-å†é€‰æ‹©â€ç­–ç•¥å¯èƒ½å¯¼è‡´å±€éƒ¨æœ€ä¼˜ï¼Œå°¤å…¶åœ¨èµ„äº§ç§ç±»æœ‰é™æ—¶ã€‚
3. **å¤šç›®æ ‡ä¼˜åŒ–å°šæœªæ”¯æŒ**ï¼šç›®å‰ä»…ä¼˜åŒ–PUEï¼Œæœªè€ƒè™‘æ°´è€—ï¼ˆWUEï¼‰ã€ç¢³æ’æ”¾ã€å»ºè®¾æˆæœ¬ç­‰å…¶ä»–å¯æŒç»­æ€§æŒ‡æ ‡ã€‚
4. **æ”¶æ•›æ€§æ— ç†è®ºä¿è¯**ï¼šè¿›åŒ–è¿‡ç¨‹ä¾èµ–LLMè¾“å‡ºç¨³å®šæ€§ï¼Œå­˜åœ¨ä¸ç¡®å®šæ€§é£é™©ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ”¯æŒæ›´å¤šå†·å´æŠ€æœ¯ï¼ˆå¦‚D2Cæ¶²å†·ã€èƒŒæ¿æ¢çƒ­å™¨ï¼‰
- å¼•å…¥å¤šæ¨¡æ€ç¼–ç å™¨ç†è§£é«˜ç»´ä»¿çœŸåœºï¼ˆflow fieldï¼‰
- æ„å»ºå¤šç›®æ ‡ä¼˜åŒ–æ¡†æ¶ï¼ˆPUE + WUE + CAPEXï¼‰
- å¼€å‘é’ˆå¯¹LLMå¹»è§‰çš„ç»†ç²’åº¦å¾®è°ƒç­–ç•¥ï¼ˆfine-tuning strategiesï¼‰
- æ¢ç´¢åŒºåŸŸèµ„æºæ¡ä»¶æ„ŸçŸ¥çš„è®¾è®¡é€‰å€ä¼˜åŒ–ï¼ˆsiting-aware DC designï¼‰

---

> **æ€»ç»“**ï¼šPhythesisé¦–æ¬¡æˆåŠŸå°†LLMçš„è¯­ä¹‰ç”Ÿæˆèƒ½åŠ›ä¸ç‰©ç†è§„å¾‹æ·±åº¦èåˆï¼Œæ„å»ºäº†ä¸€ä¸ªå¯ç”¨äºå·¥ä¸šçº§æ•°æ®ä¸­å¿ƒè®¾è®¡çš„è‡ªåŠ¨åŒ–æ¡†æ¶ã€‚å…¶å®éªŒç»“æœè¯æ˜ï¼Œ**â€œè¯­ä¹‰+ç‰©ç†â€åŒè½®é©±åŠ¨**æ˜¯å®ç°é«˜æ•ˆã€å¯é ã€å¯æŒç»­åŸºç¡€è®¾æ–½è®¾è®¡çš„é‡è¦èŒƒå¼ï¼Œä¸ºGenerative AIåœ¨èƒ½æºç³»ç»Ÿè®¾è®¡ä¸­çš„åº”ç”¨å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚

</details>

---

### 14. [Multi-Granular Node Pruning for Circuit Discovery](https://arxiv.org/abs/2512.10903)

**Authors**: Muhammad Umair Haider, Hammad Rizwan, Hassan Sajjad, A. B. Siddique  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.10903v1  

#### Abstract
Circuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP bloc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Multi-Granular Node Pruning for Circuit Discovery è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„ **circuit discovery** æ–¹æ³•ä¸»è¦ä¾èµ–äºè¿­ä»£å¼çš„ **edge pruning**ï¼Œå­˜åœ¨ä¸¤ä¸ªå…³é”®å±€é™ï¼š
- **è®¡ç®—æˆæœ¬é«˜**ï¼šéœ€è¦å¤§é‡å‰å‘ä¼ æ’­å’Œå­˜å‚¨ä¸­é—´æ¿€æ´»ï¼Œå†…å­˜å¼€é”€å¤§ã€‚
- **ç²’åº¦ç²—ç³™**ï¼šä»…åœ¨ **attention heads** æˆ– **MLP blocks** ç­‰ç»„ä»¶çº§åˆ«è¿›è¡Œå‰ªæï¼Œæ— æ³•æ¢ç´¢æ›´ç»†ç²’åº¦çš„ç»“æ„ï¼ˆå¦‚å•ä¸ªç¥ç»å…ƒï¼‰ï¼Œå¯¼è‡´ç”µè·¯å‘ç°ä¸å¤Ÿç²¾ç¡®ã€‚

æ­¤å¤–ï¼Œå°†æ•´ä¸ªç»„ä»¶è§†ä¸ºâ€œå…¨æœ‰æˆ–å…¨æ— â€çš„å•å…ƒï¼Œå¯èƒ½é«˜ä¼°äº†å®é™…å‚ä¸ä»»åŠ¡çš„å­ç½‘ç»œè§„æ¨¡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§å…¨æ–°çš„ **node-level pruning framework**ï¼Œå®ç°å¤šç²’åº¦ï¼ˆmulti-granularï¼‰çš„ç”µè·¯å‘ç°ï¼š
- å¼•å…¥å¯å­¦ä¹ çš„ **Hard Concrete masks**ï¼Œä½œç”¨äºä» **transformer blocksã€attention headsã€MLPs åˆ° individual neurons** çš„å¤šä¸ªå±‚çº§ã€‚
- åœ¨ç»Ÿä¸€ä¼˜åŒ–ç›®æ ‡ä¸‹è”åˆè®­ç»ƒæ‰€æœ‰ç²’åº¦çš„æ©ç ï¼Œé€šè¿‡ä¸€ä¸ªç«¯åˆ°ç«¯çš„ fine-tuning è¿‡ç¨‹å®Œæˆå‰ªæï¼Œæ— éœ€è¿­ä»£ã€‚
- é‡‡ç”¨ **two-stream forward pass** æ¶æ„ï¼š
  - **Clean stream**ï¼šåŸå§‹è¾“å…¥ã€‚
  - **Corrupted stream**ï¼šç»è¿‡ä»»åŠ¡ç›¸å…³æ‰°åŠ¨ï¼ˆå¦‚ä¿®æ”¹æ—¶é—´ã€äººåç­‰ï¼‰çš„è¾“å…¥ã€‚
  - é€šè¿‡æ’å€¼ä¸¤è€…çš„æ¿€æ´»å¹¶è§‚å¯Ÿå¯¹è¾“å‡ºçš„å½±å“æ¥è¡¡é‡èŠ‚ç‚¹é‡è¦æ€§ã€‚

è¯¥æ–¹æ³•å®ç°äº†ä» **edge-level pruning** å‘ **node-level pruning** çš„èŒƒå¼è½¬å˜ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´é«˜çš„æ•ˆç‡**ï¼šå•æ¬¡è®­ç»ƒå³å¯å®Œæˆå‰ªæï¼Œé¿å…äº† O(n) æ¬¡å‰å‘ä¼ æ’­ã€‚
- **æ›´ä½çš„å†…å­˜å ç”¨**ï¼šä¸éœ€è¦ç¼“å­˜ä¸­é—´æ¿€æ´»ï¼Œå†…å­˜æ¶ˆè€—ä»…ä¸ºåŸºçº¿æ–¹æ³•çš„ **1/5â€“1/10**ã€‚
- **æ›´ç²¾ç»†çš„ç²’åº¦**ï¼šæ”¯æŒ neuron-level å‰ªæï¼Œæ­ç¤ºä¼ ç»Ÿ coarse-grained æ–¹æ³•å¿½ç•¥çš„é‡è¦ç»†èŠ‚ã€‚
- **æ›´å°çš„ç”µè·¯è§„æ¨¡**ï¼šå‘ç°çš„ç”µè·¯åœ¨å‚æ•°æ•°ã€èŠ‚ç‚¹æ•°å’Œè¾¹æ•°ä¸Šå‡æ˜¾è‘—æ›´ç¨€ç–ï¼ŒåŒæ—¶ä¿æŒç”šè‡³æå‡ä»»åŠ¡æ€§èƒ½ã€‚
- **æ›´å¼ºçš„å¯è§£é‡Šæ€§**ï¼šæ­ç¤ºäº†ä¸åŒä»»åŠ¡ä¸‹åŠŸèƒ½æ¨¡å—åˆ†å¸ƒçš„å·®å¼‚æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸ä»»åŠ¡
åœ¨ GPT-2 æ¨¡å‹ä¸Šè¯„ä¼°ä»¥ä¸‹ä¸‰ä¸ªå…¸å‹ circuit discovery ä»»åŠ¡ï¼š

| ä»»åŠ¡ | æè¿° |
|------|------|
| **Greater-Than (GT)** | æ•°å€¼æ¨ç†ä»»åŠ¡ï¼Œåˆ¤æ–­ç»“æŸå¹´ä»½æ˜¯å¦å¤§äºèµ·å§‹å¹´ä»½ï¼ˆå¦‚ â€œThe war lasted from 1743 to 17__â€ï¼‰ã€‚æµ‹è¯•æ¨¡å‹çš„æ—¶é—´æ¯”è¾ƒèƒ½åŠ›ã€‚ |
| **Indirect Object Identification (IOI)** | å¥æ³•è¿½è¸ªä»»åŠ¡ï¼Œè¯†åˆ«é—´æ¥å®¾è¯­ï¼ˆå¦‚ â€œKristi gave it to ___â€ åº”å¡« â€œJuanaâ€ï¼‰ã€‚éœ€å¤„ç†å®ä½“ç»‘å®šä¸é‡å¤æŠ‘åˆ¶ã€‚ |
| **Gendered Pronouns (GP)** | ç¤¾ä¼šå…³è”ä»»åŠ¡ï¼Œé¢„æµ‹ä¸åå­—æ€§åˆ«ä¸€è‡´çš„ä»£è¯ï¼ˆå¦‚ â€œEvan is a great friend, isnâ€™t ___?â€ â†’ â€œheâ€ï¼‰ã€‚åæ˜ æ¨¡å‹å†…åµŒçš„æ€§åˆ«åè§ã€‚ |

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šGPT-2 Smallï¼ˆ12å±‚ï¼Œ768ç»´éšè—çŠ¶æ€ï¼‰
- **è®­ç»ƒé…ç½®**ï¼š
  - Batch size: 32
  - Sequence length: 64
  - Epochs: IOIï¼ˆ500ï¼‰ï¼ŒGT/GPï¼ˆ200ï¼‰
  - ä½¿ç”¨ **Hard Concrete åˆ†å¸ƒ** å‚æ•°åŒ– masksï¼Œå¹¶æ–½åŠ  sparsity regularizationã€‚
- **ç¡¬ä»¶èµ„æº**ï¼šRTX 3090 GPUï¼Œ64GB RAM

### è¯„ä¼°æŒ‡æ ‡

#### ä»»åŠ¡æ€§èƒ½æŒ‡æ ‡
- **GT-Score**: $ \mathbb{E}[P(y > y_{\text{start}} + 10|x) - P(y < y_{\text{start}} - 10|x)] $
- **IOI-Score**: $ \mathbb{E}[\text{logit}_{\text{correct}} - \text{logit}_{\text{incorrect}}] $
- **GP-Score**: $ \mathbb{E}[\text{logit}_{\text{consistent}} - \text{logit}_{\text{inconsistent}}] $

#### å¿ å®åº¦æŒ‡æ ‡
- **KL Divergence** ($ D_{KL}(P_m \| P_c) $)ï¼šè¡¡é‡å‰ªæåç”µè·¯è¾“å‡ºåˆ†å¸ƒä¸åŸæ¨¡å‹çš„ä¸€è‡´æ€§ã€‚

#### ç”µè·¯å¤§å°æŒ‡æ ‡
- å‚æ•°æ•°é‡ã€å‹ç¼©æ¯”ã€å„å±‚çº§ç¨€ç–åº¦ï¼ˆsparsity %ï¼‰ã€ç­‰æ•ˆè¾¹æ•°ï¼ˆç”¨äºä¸ edge pruning å¯¹æ¯”ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **EAP (Edge Attribution Patching)**ï¼šåŸºäºæ¢¯åº¦çš„é‡è¦æ€§è¯„åˆ†æŒ‡å¯¼è¾¹å‰ªæã€‚
- **EP (Edge Pruning)**ï¼šä½¿ç”¨å¯å¾®åˆ†æ©ç è¿›è¡Œè¾¹çº§å‰ªæï¼ˆCoFi Pruningï¼‰ã€‚

> âš ï¸ æ³¨æ„ï¼šè¿™äº›åŸºçº¿ä»…åœ¨ **component level**ï¼ˆå¦‚ attention headsï¼‰æ“ä½œï¼Œä¸æ”¯æŒ neuron-level æˆ– MLP block çº§åˆ«å®Œå…¨ç§»é™¤ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2ï¼‰

| Task | Base Logit Diff | Ours Logit Diff | KL â†“ |
|------|------------------|------------------|--------|
| IOI  | 3.1791           | 3.2030           | 0.6080 |
| GP   | 2.6198           | 2.6150           | 0.4909 |
| GT   | 0.3711           | 0.3912           | 0.0059 |

âœ… æ‰€æœ‰ä»»åŠ¡ä¸­ï¼Œå‰ªæåçš„ç”µè·¯ **ä»»åŠ¡æ€§èƒ½åŸºæœ¬ä¸å˜æˆ–ç•¥æœ‰æå‡**ï¼Œä¸” **KL æ•£åº¦æä½**ï¼Œè¯´æ˜å¿ å®åº¦é«˜ã€‚

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆTable 3ï¼‰

| Dataset | Method | Sparsity (%) â†‘ | KL â†“ | Logit Diff â†‘ | # Attn Heads â†“ |
|--------|--------|----------------|-------|---------------|----------------|
| IOI     | EAP    | 96.74          | 2.447 | -0.181        | 116            |
|         | EP     | 96.16          | 0.360 | 3.210         | 41             |
|         | **Ours** | **96.74**      | **0.600** | **3.203**     | **21**         |
| GP      | EAP    | 93.74          | 0.148 | 2.564         | 106            |
|         | EP     | â€”              | â€”     | â€”             | 106            |
|         | **Ours** | **93.74**      | **0.490** | **2.615**     | **37**         |
| GT      | EAP    | 95.95          | 0.086 | 0.374         | 113            |
|         | EP     | 96.69          | 0.039 | 0.389         | 74             |
|         | **Ours** | **95.95**      | **0.006** | **0.391**     | **28**         |

ğŸ” **æ ¸å¿ƒä¼˜åŠ¿ä½“ç°**ï¼š
- åœ¨ **IOI å’Œ GP ä»»åŠ¡ä¸­ï¼Œæ³¨æ„åŠ›å¤´ä¿ç•™æ•°é‡å‡å°‘è¶…è¿‡ 60%**ï¼ˆå¦‚ IOI ä» 41â†’21ï¼‰ã€‚
- å°½ç®¡ä¿ç•™æ›´å°‘ headsï¼Œ**KL æ›´ä½æˆ–ç›¸å½“ï¼Œä»»åŠ¡æ€§èƒ½æŒå¹³æˆ–æ›´å¥½**ã€‚
- **GT ä»»åŠ¡ä¸­ KL æœ€ä½ï¼ˆ0.006ï¼‰ä¸”æ€§èƒ½æœ€é«˜ï¼ˆ0.391ï¼‰**ï¼Œè¡¨æ˜å‰ªæå¯èƒ½å»é™¤äº†å¹²æ‰°ä¿¡å·ã€‚

### ç”µè·¯ç¨€ç–æ€§åˆ†æï¼ˆTable 1ï¼‰
| Granularity | IOI Sparsity (%) | GP Sparsity (%) | GT Sparsity (%) |
|------------|------------------|------------------|------------------|
| Attention Heads | 85.4 | 74.3 | 80.6 |
| Attention Neurons | 90.2 | 81.5 | 81.5 |
| MLP Hidden Neurons | 33.4 | 96.4 | 87.6 |
| MLP Output Neurons | 14.4 | 84.7 | 61.8 |

ğŸ’¡ å‘ç°ï¼š
- **MLP è¾“å‡ºç¥ç»å…ƒåœ¨ç¬¬ä¸€å±‚ï¼ˆKeysï¼‰æ¯”ç¬¬äºŒå±‚ï¼ˆValuesï¼‰æ›´å®¹æ˜“å‹ç¼©**ï¼Œç¬¦åˆ Geva et al. (2020) çš„ KV-cache è§‚å¯Ÿã€‚
- **IOI ä»»åŠ¡ä¸­å‡ ä¹æ‰€æœ‰ MLP blocks éƒ½è¢«ä¿ç•™**ï¼ˆsparsity 0%ï¼‰ï¼Œè€Œ **GP å’Œ GT ä¸­å¤§éƒ¨åˆ†å¯è¢«å‰ªé™¤**ï¼Œè¯´æ˜ä»»åŠ¡æœºåˆ¶å·®å¼‚æ˜¾è‘—ã€‚

### å†…å­˜ä¸è®¡ç®—æ•ˆç‡
- æœ¬æ–¹æ³•ä»…å¢åŠ çº¦ **55K å¯è®­ç»ƒ mask å‚æ•°**ï¼ˆç›¸å¯¹äº 124.5M æ¨¡å‹å‚æ•°å¯å¿½ç•¥ï¼‰ã€‚
- æ‰€éœ€å†…å­˜ä¸º **6,270 MB**ï¼ˆbatch size=32ï¼‰ã€‚
- ç›¸æ¯”ä¹‹ä¸‹ï¼š
  - EAP éœ€è¦ **72,794 MB**
  - EP éœ€è¦ **33,354 MB**

ğŸ‘‰ å†…å­˜å¼€é”€é™ä½ **5â€“10å€**ï¼Œæå…·éƒ¨ç½²ä¼˜åŠ¿ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **Node-level pruning æ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„**ï¼šé¦–æ¬¡å®ç°è·¨ block/head/neuron å¤šç²’åº¦è”åˆå‰ªæï¼Œæ— éœ€è¿­ä»£ã€‚
2. âœ… **è®¸å¤šè¢« coarse æ–¹æ³•è®¤ä¸ºé‡è¦çš„ç»„ä»¶å†…éƒ¨å­˜åœ¨å¤§é‡å†—ä½™ç¥ç»å…ƒ**ï¼šçœŸæ­£å…³é”®çš„æ˜¯å°‘æ•°ç‰¹å®šç¥ç»å…ƒã€‚
3. âœ… **ä¸åŒä»»åŠ¡å…·æœ‰ä¸åŒçš„ç”µè·¯ç»“æ„åå¥½**ï¼š
   - IOIï¼šä¾èµ–å¹¿æ³› MLP æ´»åŠ¨ + åå‡ å±‚ attention headsã€‚
   - GP/GTï¼šé›†ä¸­åœ¨ç‰¹å®š layer çš„ sparse attentionã€‚
4. âœ… **å‰ªæä¸ä»…ä¸æŸå®³æ€§èƒ½ï¼Œæœ‰æ—¶è¿˜èƒ½è½»å¾®æå‡**ï¼ˆå¦‚ GT ä»»åŠ¡ï¼‰ï¼Œå¯èƒ½å› å»é™¤å™ªå£°è·¯å¾„å¢å¼ºä¿¡å·æå–ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- âŒ **ä¸æ¢å¤äº¤äº’ç»“æ„**ï¼šmask èƒ½è¯†åˆ«å¿…è¦èŠ‚ç‚¹ï¼Œä½†ä¸èƒ½æ­ç¤ºèŠ‚ç‚¹é—´çš„è¿æ¥å…³ç³»ï¼ˆå³â€œè°è¿è°â€ï¼‰ã€‚
- âŒ **ç¼ºä¹æ–¹å‘æ€§å’ŒåŠ¨æ€æ€§å»ºæ¨¡**ï¼šå‡è®¾é™æ€é‡è¦æ€§ï¼Œæœªæ•æ‰è¿è¡Œæ—¶åŠ¨æ€æ¿€æ´»æ¨¡å¼ã€‚
- âŒ **æ½œåœ¨å®‰å…¨é£é™©**ï¼šè‹¥æ¶æ„ä½¿ç”¨ï¼Œå¯èƒ½ç§»é™¤å®‰å…¨ç›¸å…³çš„ moderation pathwaysï¼Œå¯¼è‡´ jailbreak è¡Œä¸ºã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- ğŸ”® æ¢ç´¢ **hybrid node-edge pruning**ï¼šç»“åˆ node-level æ•ˆç‡ä¸ edge-level ç»“æ„ç²¾ç»†æ§åˆ¶ã€‚
- ğŸ”® å¼€å‘èƒ½æ¨æ–­ **interaction topology** çš„æ–¹æ³•ï¼Œåœ¨ node selection åŸºç¡€ä¸Šé‡å»ºé€šä¿¡è·¯å¾„ã€‚
- ğŸ”® å°†æ¡†æ¶æ‰©å±•è‡³æ›´å¤§æ¨¡å‹ï¼ˆå¦‚ Llamaã€Qwenï¼‰å’Œå…¶ä»–æ¶æ„ï¼ˆå¦‚ MoEï¼‰ã€‚
- ğŸ”® ç ”ç©¶å¦‚ä½•åˆ©ç”¨å‘ç°çš„ç”µè·¯è¿›è¡Œå¯æ§ç¼–è¾‘ã€å¹²é¢„æˆ–çŸ¥è¯†æ³¨å…¥ã€‚

--- 

> ğŸ“Œ æ€»ç»“ï¼šæœ¬æ–‡æå‡ºçš„ **multi-granular node pruning** æ¡†æ¶æ˜¯ circuit discovery é¢†åŸŸçš„é‡è¦è¿›å±•ï¼Œå®ƒä»¥æ›´ä½çš„æˆæœ¬ã€æ›´é«˜çš„ç²’åº¦å‘ç°äº†æ›´ç´§å‡‘ã€æ›´å¿ å®çš„ä»»åŠ¡ä¸“ç”¨å­ç½‘ç»œï¼Œæ¨åŠ¨äº† LLM å¯è§£é‡Šæ€§çš„å®ç”¨åŒ–è¿›ç¨‹ã€‚

</details>

---

### 15. [AgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence](https://arxiv.org/abs/2512.10624)

**Authors**: Bo Yang, Lanfei Feng, Yunkui Chen, Yu Zhang, Jianyu Zhang, Xiao Xu, Nueraili Aierken, Shijian Li  
**Category**: cs.CL  
**Published**: 2025-12-12  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.10624v1  

#### Abstract
Despite rapid advances in multimodal large language models, agricultural applications remain constrained by the lack of multilingual speech data, unified multimodal architectures, and comprehensive evaluation benchmarks. To address these challenges, we present AgriGPT-Omni, an agricultural omni-fram...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å†œä¸šé¢†åŸŸçš„å¤šæ¨¡æ€äººå·¥æ™ºèƒ½ç³»ç»Ÿå­˜åœ¨ä¸‰å¤§ç“¶é¢ˆï¼š
- **ç¼ºä¹å¤šè¯­è¨€è¯­éŸ³æ•°æ®**ï¼šç°æœ‰å†œä¸šAIæ¨¡å‹ä¸»è¦ä¾èµ–æ–‡æœ¬å’Œå›¾åƒï¼Œç¼ºå°‘çœŸå®åœºæ™¯ä¸‹çš„è¯­éŸ³è¾“å…¥æ”¯æŒï¼Œå°¤å…¶åœ¨æ–¹è¨€å’Œä½èµ„æºè¯­è¨€ä¸­æ›´ä¸ºç¨€ç¼ºã€‚
- **ç¼ºä¹ç»Ÿä¸€çš„å¤šæ¨¡æ€æ¶æ„**ï¼šå¤§å¤šæ•°å†œä¸šæ¨¡å‹ä»…é™äºè§†è§‰-è¯­è¨€ï¼ˆVision-Languageï¼‰ä»»åŠ¡ï¼Œæœªå®ç°è¯­éŸ³ã€å›¾åƒã€æ–‡æœ¬ä¸‰è€…çš„æ·±åº¦èåˆã€‚
- **ç¼ºä¹æ ‡å‡†åŒ–çš„å…¨æ¨¡æ€è¯„ä¼°åŸºå‡†**ï¼šç¼ºå°‘è¦†ç›–è¯­éŸ³ã€å›¾åƒã€æ–‡æœ¬çš„ç»¼åˆæ€§å†œä¸šè¯„æµ‹é›†ï¼Œéš¾ä»¥å…¬å¹³æ¯”è¾ƒä¸åŒæ¨¡å‹çš„è·¨æ¨¡æ€èƒ½åŠ›ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
æœ¬æ–‡æå‡º **AgriGPT-Omni**ï¼Œæ˜¯é¦–ä¸ªé¢å‘å†œä¸šé¢†åŸŸçš„**ç»Ÿä¸€è¯­éŸ³-è§†è§‰-æ–‡æœ¬ï¼ˆSpeech-Vision-Textï¼‰å…¨æ¨¡æ€æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒè´¡çŒ®åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰æ„å»ºæœ€å¤§è§„æ¨¡çš„å¤šè¯­è¨€å†œä¸šè¯­éŸ³æ•°æ®é›†
- é€šè¿‡**åˆæˆ+äººå·¥é‡‡é›†**æ··åˆæµæ°´çº¿ï¼Œç”Ÿæˆï¼š
  - **492K åˆæˆè¯­éŸ³æ ·æœ¬**ï¼ˆåŸºäº Agri-342K å’Œ AgriVL-150K æ•°æ®ç¿»è¯‘åç”± CosyVoice-0.5B åˆæˆï¼‰
  - **1.4K çœŸå®äººç±»å½•éŸ³è®­ç»ƒæ ·æœ¬**
  - **586 é«˜è´¨é‡çœŸå®è¯­éŸ³è¯„æµ‹æ ·æœ¬**
- è¦†ç›–å…­ç§è¯­è¨€ï¼šä¸­æ–‡ã€å››å·è¯ã€ç²¤è¯­ã€è‹±è¯­ã€æ—¥è¯­ã€éŸ©è¯­
- æ”¯æŒå¤šç§ä»»åŠ¡å½¢å¼ï¼šé—®ç­”ï¼ˆQAï¼‰ã€é€‰æ‹©é¢˜ã€è¯­éŸ³è½¬å½•ç­‰

#### ï¼ˆ2ï¼‰è®¾è®¡ä¸‰é˜¶æ®µè®­ç»ƒèŒƒå¼ï¼ˆThree-stage Training Pipelineï¼‰
1. **Text Knowledge Injection**  
   - ç»§ç»­é¢„è®­ç»ƒï¼ˆ2.2B å†œä¸šé¢†åŸŸtokenï¼‰
   - æ–‡æœ¬æŒ‡ä»¤å¾®è°ƒï¼ˆ342K QAï¼‰
   - è¯­éŸ³-æ–‡æœ¬å¯¹é½å¾®è°ƒï¼ˆ342K â€œspoken question â†’ textual answerâ€ï¼‰

2. **Multimodal Knowledge Learning**
   - å†»ç»“ä¸»å¹²ç½‘ç»œï¼Œåˆ†åˆ«è¿›è¡Œè§†è§‰-è¯­è¨€ã€è¯­éŸ³-è¯­è¨€é€‚é…å™¨è®­ç»ƒ
   - è§£å†»åè”åˆä¼˜åŒ– 800K å¤šæ¨¡æ€ QAã€50K é«˜è´¨é‡ GPT-4o æ ·æœ¬ã€140K è¯­éŸ³+å›¾åƒ QA

3. **GRPO-based Reinforcement Learning**
   - ä½¿ç”¨ **Group Relative Policy Optimization (GRPO)** è¿›è¡Œåå¥½ä¼˜åŒ–
   - åˆ©ç”¨ 2.5K è¯­éŸ³ QAã€5K è¯­éŸ³+å›¾åƒ QAã€1.4K äººå·¥å½•éŸ³è½¬å½•æ•°æ®æå‡è¾“å‡ºç¨³å®šæ€§ä¸å†³ç­–ä¸€è‡´æ€§

#### ï¼ˆ3ï¼‰å‘å¸ƒé¦–ä¸ªå†œä¸šå…¨æ¨¡æ€è¯„æµ‹åŸºå‡†ï¼šAgriBench-Omni-2K
- åŒ…å« **4 ç±»ä»»åŠ¡**ï¼š
  - Audio QAï¼ˆè¯­éŸ³æé—® â†’ æ–‡æœ¬å›ç­”ï¼‰
  - Audio+Text Multiple Choiceï¼ˆè¯­éŸ³æé—® + æ–‡æœ¬é€‰é¡¹ â†’ é€‰æ‹©ç­”æ¡ˆï¼‰
  - Multimodal QAï¼ˆè¯­éŸ³ + å›¾åƒ â†’ æ–‡æœ¬å›ç­”ï¼‰
  - Multimodal Multiple Choiceï¼ˆè¯­éŸ³ + å›¾åƒ + æ–‡æœ¬é€‰é¡¹ â†’ é€‰æ‹©ç­”æ¡ˆï¼‰
- è¦†ç›– **6 ç§è¯­è¨€**ï¼Œå…± 1,500 æµ‹è¯•æ ·æœ¬ï¼ˆ100Ã—6Ã—4ï¼‰
- åŒ…å«çœŸå®äººç±»å½•éŸ³ï¼ˆ586 æ¡ï¼‰ï¼Œç”¨äºè¯„ä¼°ç°å®é²æ£’æ€§
- æä¾›æ ‡å‡†åŒ–è¯„åˆ†åè®®ä¸å¯å¤ç°è¯„ä¼°è„šæœ¬

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | AgriGPT-Omni | ç°æœ‰å†œä¸šæ¨¡å‹ï¼ˆå¦‚ AgriGPT-VLã€AgroLLMï¼‰ |
|------|--------------|----------------------------------------|
| æ¨¡æ€å®Œæ•´æ€§ | âœ… è¯­éŸ³+è§†è§‰+æ–‡æœ¬ç»Ÿä¸€å»ºæ¨¡ | âŒ å¤šä¸ºå•æ¨¡æ€æˆ–åŒæ¨¡æ€ï¼ˆä»…æ–‡æœ¬/å›¾åƒï¼‰ |
| è¯­è¨€å¤šæ ·æ€§ | âœ… æ”¯æŒ6ç§è¯­è¨€ï¼ˆå«æ–¹è¨€ï¼‰ | âŒ ä¸»è¦é›†ä¸­äºè‹±æ–‡æˆ–æ ‡å‡†ä¸­æ–‡ |
| æ•°æ®çœŸå®æ€§ | âœ… å«çœŸå®å†œæ°‘å£éŸ³ä¸å™ªå£°ç¯å¢ƒå½•éŸ³ | âŒ å¤šä¾èµ–åˆæˆæˆ–ç†æƒ³åŒ–æ•°æ® |
| è¯„ä¼°ä½“ç³» | âœ… å…¨æ¨¡æ€ã€å¤šä»»åŠ¡ã€çœŸå®è¯­éŸ³è¯„æµ‹ | âŒ ç¼ºä¹ç»Ÿä¸€è¯­éŸ³è¯„æµ‹æ ‡å‡† |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®ç±»å‹ | åç§° | è§„æ¨¡ | æè¿° |
|--------|------|-----|------|
| æ–‡æœ¬æ•°æ® | Agri-342K | 342K QA å¯¹ | å¤šè¯­è¨€å†œä¸šçŸ¥è¯†é—®ç­” |
| å›¾åƒ-æ–‡æœ¬å¯¹ | AgriVL-150K / Agri-VL-3M | ~150Kâ€“3M å¯¹ | å›¾åƒæè¿°ä¸å†œäº‹å…³è” |
| åˆæˆè¯­éŸ³ | è‡ªå»ºåˆæˆæ•°æ® | 492K æ¡ | ä½¿ç”¨ Qwen2.5-72B ç¿»è¯‘ + CosyVoice åˆæˆ |
| çœŸå®è¯­éŸ³ | Human-recorded Speech | 1.4K è®­ç»ƒ + 586 æµ‹è¯„ | å¤šè¯­è¨€å¿—æ„¿è€…å½•åˆ¶ï¼Œæ¨¡æ‹ŸçœŸå®ç”°é‡æ¡ä»¶ |
| å¼ºåŒ–å­¦ä¹ æ•°æ® | GRPO Subset | 8,931 æ ·æœ¬ | ç»“æ„æ¸…æ™°çš„é€‰æ‹©é¢˜ä¸è½¬å½•ä»»åŠ¡ï¼Œç”¨äºå¥–åŠ±å»ºæ¨¡ |

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹æ¶æ„åŸºç¡€
- åŸºåº§æ¨¡å‹ï¼š**Qwen2.5-Omni**
- å‚æ•°é‡ï¼š8Bï¼ˆä¸»ç‰ˆæœ¬ï¼‰
- æ¨¡å—ç»„æˆï¼š
  - Language Backboneï¼ˆQwen2.5ï¼‰
  - Vision Encoderï¼ˆCLIP-styleï¼‰
  - Audio Encoderï¼ˆWhisper-styleï¼‰
  - Cross-modal Adaptersï¼ˆVision-Language, Speech-Languageï¼‰

#### è¯„ä¼°ä»»åŠ¡ä¸æŒ‡æ ‡
| ä»»åŠ¡ç±»å‹ | è¾“å…¥ | è¾“å‡º | ä¸»è¦æŒ‡æ ‡ |
|--------|------|------|---------|
| Audio QA | è¯­éŸ³é—®é¢˜ | è‡ªç”±æ–‡æœ¬å›ç­” | Win Rateï¼ˆvs åŸºçº¿ï¼‰ |
| Audio MC | è¯­éŸ³é—®é¢˜ + æ–‡æœ¬é€‰é¡¹ | é€‰æ‹©ç­”æ¡ˆ | Accuracy |
| Multimodal QA | è¯­éŸ³ + å›¾åƒ | è‡ªç”±æ–‡æœ¬å›ç­” | Win Rate |
| Multimodal MC | è¯­éŸ³ + å›¾åƒ + æ–‡æœ¬é€‰é¡¹ | é€‰æ‹©ç­”æ¡ˆ | Accuracy |
| é€šç”¨èƒ½åŠ›æµ‹è¯• | æ–‡æœ¬/å›¾åƒ/éŸ³é¢‘è¾“å…¥ | å¤šæ ·è¾“å‡º | MMLU, ARC, OpenBookQA, MMBench, Sample Audio ç­‰ |

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å¯¹æ¯”äº†ä»¥ä¸‹ä»£è¡¨æ€§æ¨¡å‹ï¼š
- å¼€æºé€šç”¨ MLLMsï¼š`InternVL-3`, `LLaVA-1.5`, `MiniCPM-V`, `Yi-VL`, `Qwen2.5-VL`, `DeepSeek-VL2`
- é€šç”¨ Omni-modelsï¼š`Qwen2.5-Omni-3B/7B`, `Megrez-Omni-3B`, `Step-Audio-2-mini`
- å•†ä¸šæ¨¡å‹ï¼š`Gemini 2.5 Flash/Pro`

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Tables 4â€“7ï¼‰

#### ï¼ˆ1ï¼‰å¼€æ”¾å¼è¯­éŸ³é—®ç­”ï¼ˆAudio QAï¼‰â€”â€”Pairwise Win Rate
| å¯¹æ¯”æ¨¡å‹ | å¹³å‡èƒœç‡ |
|--------|--------|
| vs Qwen2.5-Omni-3B | **79.60%** |
| vs Qwen2.5-Omni-7B | **75.77%** |
| vs Megrez-Omni-3B | **98.74%** |
| vs Qwen2-Audio-7B | **97.85%** |
| vs Step-Audio-2-mini | **96.71%** |

> åœ¨æ‰€æœ‰è¯­è¨€ä¸­å‡æ˜¾è‘—é¢†å…ˆï¼Œå°¤å…¶åœ¨æ–¹è¨€ï¼ˆå¦‚å››å·è¯ã€ç²¤è¯­ï¼‰ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚

#### ï¼ˆ2ï¼‰è¯­éŸ³é€‰æ‹©é¢˜ï¼ˆAudio MCï¼‰â€”â€”Accuracy
| æ¨¡å‹ | å‡†ç¡®ç‡ï¼ˆACCï¼‰ |
|------|-------------|
| Qwen2.5-Omni-7B | 83.83% |
| Step-Audio-2-mini | 80.83% |
| **AgriGPT-Omni (ours)** | **92.67%** |

> **å¹³å‡é«˜å‡ºçº¦ 9â€“12 ä¸ªç™¾åˆ†ç‚¹**ï¼Œè¡¨æ˜é¢†åŸŸä¸“ä¸šåŒ–æ˜¾è‘—å¢å¼ºç†è§£èƒ½åŠ›ã€‚

#### ï¼ˆ3ï¼‰å¤šæ¨¡æ€è¯­éŸ³é—®ç­”ï¼ˆSpeech + Image â†’ Textï¼‰â€”â€”Win Rate
| å¯¹æ¯”æ¨¡å‹ | å¹³å‡èƒœç‡ |
|--------|--------|
| vs Qwen2.5-Omni-3B | **94.85%** |
| vs Qwen2.5-Omni-7B | **89.89%** |
| vs Megrez-Omni-3B | **94.46%** |

#### ï¼ˆ4ï¼‰å¤šæ¨¡æ€é€‰æ‹©é¢˜ï¼ˆSpeech + Image + Text â†’ Answerï¼‰â€”â€”Accuracy
| æ¨¡å‹ | å‡†ç¡®ç‡ï¼ˆACCï¼‰ |
|------|-------------|
| Qwen2.5-Omni-7B | 59.17% |
| Megrez-Omni-3B | 50.83% |
| **AgriGPT-Omni (ours)** | **75.67%** |

> **ç»å¯¹æå‡è¶…è¿‡ 16 ä¸ªç™¾åˆ†ç‚¹**ï¼Œä½“ç°å¼ºå¤§çš„è·¨æ¨¡æ€èåˆèƒ½åŠ›ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Study, Figure 5ï¼‰

| é˜¶æ®µ | ç›¸æ¯”å‰ä¸€é˜¶æ®µçš„æå‡è¶‹åŠ¿ |
|------|-----------------------|
| Phase 1ï¼ˆæ–‡æœ¬æ³¨å…¥ï¼‰ | æ˜¾è‘—æå‡è¯­è¨€ç†è§£å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ› |
| Phase 2ï¼ˆå¤šæ¨¡æ€å¯¹é½ï¼‰ | æ˜æ˜¾æ”¹å–„è§†è§‰ä¸è¯­éŸ³ä¿¡æ¯èåˆæ•ˆæœ |
| Phase 3ï¼ˆGRPOå¼ºåŒ–å­¦ä¹ ï¼‰ | æœ€å¤§å¢ç›Šï¼Œç‰¹åˆ«æ˜¯åœ¨é€‰æ‹©é¢˜å‡†ç¡®ç‡å’Œè¾“å‡ºç¨³å®šæ€§æ–¹é¢ |

> æ‰€æœ‰ä»»åŠ¡ä¸Šçš„æ€§èƒ½å‘ˆ**å•è°ƒä¸Šå‡è¶‹åŠ¿**ï¼ŒéªŒè¯ä¸‰é˜¶æ®µè®­ç»ƒçš„æœ‰æ•ˆæ€§å’Œäº’è¡¥æ€§ã€‚

---

### ğŸ§ª çœŸå®è¯­éŸ³é²æ£’æ€§è¯„ä¼°ï¼ˆTable 3ï¼‰
| è¾“å…¥ç±»å‹å¯¹æ¯” | èƒœ | å¹³ | è´Ÿ |
|-------------|----|----|----|
| åˆæˆè¯­éŸ³ vs çœŸå®è¯­éŸ³ | 234 | 111 | 232 |

> æ¨¡å‹åœ¨çœŸå®å½•éŸ³ä¸Šçš„è¡¨ç°ä¸åˆæˆè¯­éŸ³ç›¸å½“ï¼ˆæ¥è¿‘å¹³å±€ï¼‰ï¼Œè¯´æ˜å…·å¤‡è‰¯å¥½çš„**ç°å®éƒ¨ç½²é²æ£’æ€§**ï¼Œä¸ä¾èµ–é«˜è´¨é‡å½•éŸ³è®¾å¤‡æˆ–æ ‡å‡†å‘éŸ³ã€‚

---

### ğŸŒ é€šç”¨èƒ½åŠ›ä¿ç•™æµ‹è¯•ï¼ˆTable 8ï¼‰
| åŸºå‡† | Qwen2.5-Omni-7B | AgriGPT-Omni-7B |
|------|------------------|------------------|
| MMLU (Text) | 49.97% | **62.81%** (+12.8) |
| OpenBookQA (Text) | 60.34% | **80.74%** (+20.4) |
| ARC (Text) | 81.69% | 82.19% |
| MMBench (Vision) | 83.45% | 82.51% |
| Sample Audio (Audio) | 75.57% | 74.49% |

> è¡¨æ˜ï¼š**é¢†åŸŸä¸“ç”¨è®­ç»ƒä¸ä»…æ²¡æœ‰æŸå®³é€šç”¨èƒ½åŠ›ï¼Œåè€Œæå‡äº†éƒ¨åˆ†æ–‡æœ¬æ¨ç†æ€§èƒ½**ï¼Œè¯æ˜æ¨¡å‹å…·æœ‰å¼ºæ³›åŒ–æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å†œä¸šå…¨æ¨¡æ€æ™ºèƒ½å¿…é¡»æ•´åˆè¯­éŸ³æ¥å£**ï¼šè¯­éŸ³æ˜¯æœ€è‡ªç„¶çš„å†œæ°‘äº¤äº’æ–¹å¼ï¼Œç°æœ‰ç ”ç©¶ä¸¥é‡å¿½è§†è¯¥æ¨¡æ€ã€‚
2. **åˆæˆæ•°æ®ç»“åˆå°‘é‡çœŸå®å½•éŸ³å³å¯æœ‰æ•ˆè®­ç»ƒé²æ£’æ¨¡å‹**ï¼šé€šè¿‡é«˜è´¨é‡TTSåˆæˆå¤§è§„æ¨¡æ•°æ®ï¼Œå¹¶è¾…ä»¥å°‘é‡çœŸå®å½•éŸ³è¿›è¡ŒGRPOä¼˜åŒ–ï¼Œèƒ½æ˜¾è‘—æå‡ç°å®é€‚åº”èƒ½åŠ›ã€‚
3. **ä¸‰é˜¶æ®µè®­ç»ƒèŒƒå¼æœ‰æ•ˆè§£è€¦å¤æ‚å­¦ä¹ è¿‡ç¨‹**ï¼š
   - å…ˆæ‰“ç‰¢è¯­è¨€åŸºç¡€
   - å†å»ºç«‹è·¨æ¨¡æ€æ˜ å°„
   - æœ€åé€šè¿‡å¼ºåŒ–å­¦ä¹ ç¨³å®šè¾“å‡º
4. **é¢†åŸŸä¸“ä¸šåŒ–å¯åŒæ—¶æå‡ä¸“ä¸šä¸é€šç”¨èƒ½åŠ›**ï¼šé’ˆå¯¹æ€§è®­ç»ƒåè€Œå¢å¼ºäº†æ¨¡å‹åœ¨å¼€æ”¾åŸŸçš„ç†è§£åŠ›ï¼ˆå¦‚ MMLU æå‡ 12.8%ï¼‰ï¼ŒæŒ‘æˆ˜â€œè¿‡æ‹Ÿåˆâ€å‡è®¾ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰è¯­éŸ³æ•°æ®ä»åå°‘ï¼ˆå°¤å…¶æ˜¯çœŸå®å½•éŸ³ï¼‰ï¼Œæœªæ¥éœ€æ‰©å¤§ç”°é‡é‡‡é›†è§„æ¨¡ã€‚
- å°šæœªæ”¯æŒè¯­éŸ³è¾“å‡ºï¼ˆTTS å›ç­”ï¼‰ï¼Œä»…å®ç°è¯­éŸ³è¾“å…¥ç†è§£ã€‚
- æ–¹è¨€è¯†åˆ«è™½ä¼˜äºåŸºçº¿ï¼Œä½†ä»å­˜åœ¨è¯¯è¯†åˆ«ç°è±¡ï¼ˆå¦‚å››å·è¯ä¸æ™®é€šè¯æ··æ·†ï¼‰ã€‚
- GRPO ä¾èµ–ç²¾ç¡®ç­”æ¡ˆç»“æ„ï¼Œåœ¨å¼€æ”¾å¼å†œä¸šå’¨è¯¢ä»»åŠ¡ä¸­åº”ç”¨å—é™ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ„å»ºç«¯åˆ°ç«¯è¯­éŸ³å¯¹è¯ç³»ç»Ÿï¼ˆæ”¯æŒè¯­éŸ³è¾“å…¥+è¯­éŸ³è¾“å‡ºï¼‰
- æ‰©å±•è‡³æ›´å¤šä½èµ„æºè¯­è¨€ä¸åœ°æ–¹æ–¹è¨€
- æ¥å…¥å®åœ°ä¼ æ„Ÿå™¨æ•°æ®ï¼ˆæ¸©æ¹¿åº¦ã€åœŸå£¤pHç­‰ï¼‰å½¢æˆæ„ŸçŸ¥-å†³ç­–é—­ç¯
- æ¨åŠ¨å¼€æºç”Ÿæ€å»ºè®¾ï¼Œé¼“åŠ±ç¤¾åŒºå…±å»ºå†œä¸šå¤šæ¨¡æ€æ•°æ®é›†ä¸å·¥å…·é“¾

---

## ğŸ“¢ æ€»ç»“
**AgriGPT-Omni æ˜¯å†œä¸šAIè¿ˆå‘â€œå…¨æ¨¡æ€äº¤äº’â€çš„é‡Œç¨‹ç¢‘å·¥ä½œ**ã€‚å®ƒé¦–æ¬¡å®ç°äº†è¯­éŸ³ã€å›¾åƒã€æ–‡æœ¬åœ¨å†œä¸šåœºæ™¯ä¸­çš„ç»Ÿä¸€å»ºæ¨¡ï¼Œæå‡ºäº†å®Œæ•´çš„â€œæ•°æ®-æ¨¡å‹-è¯„æµ‹â€ä¸‰ä½ä¸€ä½“è§£å†³æ–¹æ¡ˆã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤šè¯­è¨€è¯­éŸ³ç†è§£ã€è·¨æ¨¡æ€æ¨ç†ã€çœŸå®ç¯å¢ƒé²æ£’æ€§ç­‰æ–¹é¢å…¨é¢è¶…è¶Šé€šç”¨æ¨¡å‹ï¼Œä¸”ä¿æŒç”šè‡³æå‡äº†é€šç”¨èƒ½åŠ›ã€‚ä½œè€…æ‰¿è¯ºå°†**å¼€æºå…¨éƒ¨æ¨¡å‹ã€æ•°æ®ä¸è¯„æµ‹å·¥å…·**ï¼Œæœ‰æœ›æ¨åŠ¨å…¨çƒä½èµ„æºåœ°åŒºå†œä¸šæ™ºèƒ½åŒ–å‘å±•ã€‚

</details>

---

### 16. [Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity](https://arxiv.org/abs/2512.10882)

**Authors**: Hauke Licht  
**Category**: cs.CL  
**Published**: 2025-12-12  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.10882v1  

#### Abstract
Emotions are central to politics and analyzing their role in political communication has a long tradition. As research increasingly leverages audio-visual materials to analyze the display of emotions, the emergence of multimodal generative AI promises great advances. However, we lack evidence about ...

---

### 17. [Multi-Objective Reward and Preference Optimization: Theory and Algorithms](https://arxiv.org/abs/2512.10601)

**Authors**: Akhil Agnihotri  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.10601v1  

#### Abstract
This thesis develops theoretical frameworks and algorithms that advance constrained reinforcement learning (RL) across control, preference learning, and alignment of large language models. The first contribution addresses constrained Markov Decision Processes (CMDPs) under the average-cost criterion...

---

### 18. [User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation](https://arxiv.org/abs/2512.10322)

**Authors**: Yongqiang Yu, Xuhui Li, Hazza Mahmood, Jinxing Zhou, Haodong Hong, Longtao Jiang, Zhiqiang Xu, Qi Wu, Xiaojun Chang  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.10322v1  

#### Abstract
Vision-and-Language Navigation (VLN) requires agents to navigate complex environments by following natural-language instructions. General Scene Adaptation for VLN (GSA-VLN) shifts the focus from zero-shot generalization to continual, environment-specific adaptation, narrowing the gap between static ...

---

### 19. [CloudFix: Automated Policy Repair for Cloud Access Control Policies Using Large Language Models](https://arxiv.org/abs/2512.09957)

**Authors**: Bethel Hall, Owen Ungaro, William Eiers  
**Category**: cs.DC  
**Published**: 2025-12-12  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.09957v1  

#### Abstract
Access control policies are vital for securing modern cloud computing, where organizations must manage access to sensitive data across thousands of users in distributed system settings. Cloud administrators typically write and update policies manually, which can be an error-prone and time-consuming ...

---

### 20. [ESS: An Offload-Centric Latent-Cache Management Architecture for DeepSeek-V3.2-Exp](https://arxiv.org/abs/2512.10576)

**Authors**: Xinhang Chen, Chao Zhang, Jiahuan He, Wei Liu, Jianming Zhang, Wenlong Zhou, Xiao Li, Pai Zeng, Shiyong Li, Yuanpan Qian, Dong Li, Zhaogeng Li  
**Category**: cs.DC  
**Published**: 2025-12-12  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.10576v1  

#### Abstract
DeepSeek-V3.2-Exp introduces a sparse attention mechanism that significantly reduces inference latency in long-context scenarios. Although the overall throughput has improved greatly, the Decode-stage of PD disaggregation remains to be a major bottleneck. This bottleneck primarily stems from the con...

---

### 21. [\textsc{Text2Graph}: Combining Lightweight LLMs and GNNs for Efficient Text Classification in Label-Scarce Scenarios](https://arxiv.org/abs/2512.10061)

**Authors**: Jo\~ao Lucas Luz Lima Sarcinelli, Ricardo Marcondes Marcacini  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.10061v1  

#### Abstract
Large Language Models (LLMs) have become effective zero-shot classifiers, but their high computational requirements and environmental costs limit their practicality for large-scale annotation in high-performance computing (HPC) environments. To support more sustainable workflows, we present \textsc{...

---

### 22. [Murmur2Vec: A Hashing Based Solution For Embedding Generation Of COVID-19 Spike Sequences](https://arxiv.org/abs/2512.10147)

**Authors**: Sarwan Ali, Taslim Murad  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.10147v1  

#### Abstract
Early detection and characterization of coronavirus disease (COVID-19), caused by SARS-CoV-2, remain critical for effective clinical response and public-health planning. The global availability of large-scale viral sequence data presents significant opportunities for computational analysis; however,...

---

### 23. [Unlocking the Address Book: Dissecting the Sparse Semantic Structure of LLM Key-Value Caches via Sparse Autoencoders](https://arxiv.org/abs/2512.10547)

**Authors**: Qingsen Ma, Dianyun Wang, Jiaming Lyu, Yaoye Wang, Lechen Ning, Sujie Zhu, Zhenbo Xu, Liuyu Xiang, Huining Li, Huijia Wu, Zhaofeng He  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.10547v1  

#### Abstract
The Key-Value (KV) cache is the primary memory bottleneck in long-context Large Language Models, yet it is typically treated as an opaque numerical tensor. In this work, we propose \textbf{STA-Attention}, a framework that utilizes Top-K Sparse Autoencoders (SAEs) to decompose the KV cache into inter...

---

### 24. [Uncertainty-Preserving QBNNs: Multi-Level Quantization of SVI-Based Bayesian Neural Networks for Image Classification](https://arxiv.org/abs/2512.10602)

**Authors**: Hendrik Borras, Yong Wu, Bernhard Klein, Holger Fr\"oning  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.10602v1  

#### Abstract
Bayesian Neural Networks (BNNs) provide principled uncertainty quantification but suffer from substantial computational and memory overhead compared to deterministic networks. While quantization techniques have successfully reduced resource requirements in standard deep learning models, their applic...

---

### 25. [Interpretable Embeddings with Sparse Autoencoders: A Data Analysis Toolkit](https://arxiv.org/abs/2512.10092)

**Authors**: Nick Jiang, Xiaoqing Sun, Lisa Dunlap, Lewis Smith, Neel Nanda  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.10092v1  

#### Abstract
Analyzing large-scale text corpora is a core challenge in machine learning, crucial for tasks like identifying undesirable model behaviors or biases in training data. Current methods often rely on costly LLM-based techniques (e.g. annotating dataset differences) or dense embedding models (e.g. for c...

---

### 26. [Investigating The Functional Roles of Attention Heads in Vision Language Models: Evidence for Reasoning Modules](https://arxiv.org/abs/2512.10300)

**Authors**: Yanbei Jiang, Xueqi Ma, Shu Liu, Sarah Monazam Erfani, Tongliang Liu, James Bailey, Jey Han Lau, Krista A. Ehinger  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.10300v1  

#### Abstract
Despite excelling on multimodal benchmarks, vision-language models (VLMs) largely remain a black box. In this paper, we propose a novel interpretability framework to systematically analyze the internal mechanisms of VLMs, focusing on the functional roles of attention heads in multimodal reasoning. T...

---

### 27. [Remember Me, Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven Agent Evolution](https://arxiv.org/abs/2512.10696)

**Authors**: Zouying Cao, Jiaji Deng, Li Yu, Weikang Zhou, Zhaoyang Liu, Bolin Ding, Hai Zhao  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.10696v1  

#### Abstract
Procedural memory enables large language model (LLM) agents to internalize "how-to" knowledge, theoretically reducing redundant trial-and-error. However, existing frameworks predominantly suffer from a "passive accumulation" paradigm, treating memory as a static append-only archive. To bridge the ga...

---

### 28. [Decoding Student Minds: Leveraging Conversational Agents for Psychological and Learning Analysis](https://arxiv.org/abs/2512.10441)

**Authors**: Nour El Houda Ben Chaabene, Hamza Hammami, Laid Kahloul  
**Category**: cs.CL  
**Published**: 2025-12-12  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.10441v1  

#### Abstract
This paper presents a psychologically-aware conversational agent designed to enhance both learning performance and emotional well-being in educational settings. The system combines Large Language Models (LLMs), a knowledge graph-enhanced BERT (KG-BERT), and a bidirectional Long Short-Term Memory (LS...

---

### 29. [Local LLM Ensembles for Zero-shot Portuguese Named Entity Recognition](https://arxiv.org/abs/2512.10043)

**Authors**: Jo\~ao Lucas Luz Lima Sarcinelli, Diego Furtado Silva  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.10043v1  

#### Abstract
Large Language Models (LLMs) excel in many Natural Language Processing (NLP) tasks through in-context learning but often under-perform in Named Entity Recognition (NER), especially for lower-resource languages like Portuguese. While open-weight LLMs enable local deployment, no single model dominates...

---

### 30. [Assessing Neuromorphic Computing for Fingertip Force Decoding from Electromyography](https://arxiv.org/abs/2512.10179)

**Authors**: Abolfazl Shahrooei, Luke Arthur, Om Patel, Derek Kamper  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.10179v1  

#### Abstract
High-density surface electromyography (HD-sEMG) provides a noninvasive neural interface for assistive and rehabilitation control, but mapping neural activity to user motor intent remains challenging. We assess a spiking neural network (SNN) as a neuromorphic architecture against a temporal convoluti...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
