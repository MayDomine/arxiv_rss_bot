# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-09 05:58:54 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [FaST: Efficient and Effective Long-Horizon Forecasting for Large-Scale Spatial-Temporal Graphs via Mixture-of-Experts](https://arxiv.org/abs/2601.05174)

**Authors**: Yiji Zhao, Zihao Zhong, Ao Wang, Haomin Wen, Ming Jin, Yuxuan Liang, Huaiyu Wan, Hao Wu  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2601.05174v1  

#### Abstract
Spatial-Temporal Graph (STG) forecasting on large-scale networks has garnered significant attention. However, existing models predominantly focus on short-horizon predictions and suffer from notorious computational costs and memory consumption when scaling to long-horizon predictions and large graph...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**å¤§è§„æ¨¡æ—¶ç©ºå›¾ï¼ˆLarge-Scale Spatial-Temporal Graph, STGï¼‰ä¸Šçš„é•¿æ—¶åŸŸé¢„æµ‹ä»»åŠ¡**ä¸­å­˜åœ¨çš„ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **è®¡ç®—å¤æ‚åº¦é«˜**ï¼šä¼ ç»ŸSTGNNæ¨¡å‹åœ¨å¤„ç†å¤§è§„æ¨¡å›¾ï¼ˆæ•°åƒèŠ‚ç‚¹ï¼‰å’Œé•¿é¢„æµ‹åºåˆ—ï¼ˆå¦‚672æ­¥ï¼‰æ—¶ï¼Œç”±äºå›¾å·ç§¯ï¼ˆGNNï¼‰å’Œè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ $O(N^2)$ å’Œ $O(T^2)$ å¤æ‚åº¦ï¼Œå¯¼è‡´å†…å­˜çˆ†ç‚¸å’Œè®­ç»ƒæ•ˆç‡ä½ä¸‹ã€‚
- **è¡¨è¾¾èƒ½åŠ›å—é™**ï¼šç°æœ‰é«˜æ•ˆæ–¹æ³•ï¼ˆå¦‚ç»“æ„æ„ŸçŸ¥æˆ–ç»“æ„æ— å…³æ–¹æ³•ï¼‰ä¸ºé™ä½å¤æ‚åº¦è€Œç‰ºç‰²äº†ç©ºé—´è¯­ä¹‰æˆ–æ—¶é—´å¼‚è´¨æ€§å»ºæ¨¡èƒ½åŠ›ï¼Œéš¾ä»¥æ•æ‰å¤æ‚çš„æ—¶ç©ºä¾èµ–ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šFaST
æå‡º **FaST**ï¼ˆFast long-horizon forecasting frameworkï¼‰ï¼Œä¸€ä¸ªåŸºäº **å¼‚è´¨æ€§æ„ŸçŸ¥çš„ Mixture-of-Experts (MoE)** çš„é«˜æ•ˆä¸”æœ‰æ•ˆçš„é•¿æ—¶åŸŸé¢„æµ‹æ¡†æ¶ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰è‡ªé€‚åº”å›¾ä»£ç†æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAdaptive Graph Agent Attention, AGA-Attï¼‰
- å¼•å…¥å¯å­¦ä¹ çš„ **agent tokens**ï¼ˆæ•°é‡ $a \ll N$ï¼‰ä½œä¸ºä¸­ä»‹èŠ‚ç‚¹ï¼Œé€šè¿‡â€œèŠ‚ç‚¹â†’ä»£ç†èšåˆâ€å’Œâ€œä»£ç†â†’èŠ‚ç‚¹åˆ†å‘â€ä¸¤é˜¶æ®µæ³¨æ„åŠ›ï¼Œå°†ç©ºé—´äº¤äº’å¤æ‚åº¦ä» $O(N^2)$ é™è‡³ $O(Na)$ã€‚
- é¿å…äº†å…¨å›¾èŠ‚ç‚¹é—´çš„æˆå¯¹è®¡ç®—ï¼Œæ˜¾è‘—æå‡å¯æ‰©å±•æ€§ã€‚

#### ï¼ˆ2ï¼‰å¹¶è¡ŒåŒ– MoE æ¨¡å—ï¼ˆParallelized GLU-MoEï¼‰
- å°†ä¼ ç»Ÿçš„ Feed-Forward Networkï¼ˆFFNï¼‰æ›¿æ¢ä¸º **Gated Linear Unit (GLU) ä¸“å®¶ç½‘ç»œ**ï¼Œå¹¶è®¾è®¡äº†é«˜æ•ˆçš„å¹¶è¡Œè®¡ç®—æœºåˆ¶ã€‚
- æå‡º **å¼‚è´¨æ€§æ„ŸçŸ¥è·¯ç”±å™¨ï¼ˆHeterogeneity-Aware Router, HA-Routerï¼‰**ï¼ŒåŠ¨æ€åœ°æ ¹æ®èŠ‚ç‚¹å’Œæ—¶é—´ä½ç½®é€‰æ‹©ä¸“å®¶è·¯å¾„ï¼Œé¿å…ä¸“å®¶æåŒ–ï¼ˆexpert polarizationï¼‰ï¼Œä¿ç•™æ—¶ç©ºå¼‚è´¨æ€§ã€‚
- å®ç°äº† **å¯†é›† MoEï¼ˆdense MoEï¼‰** è®¾è®¡ï¼Œæ‰€æœ‰ä¸“å®¶å‡å‚ä¸å‰å‘ä¼ æ’­ï¼Œæå‡æ¨¡å‹å®¹é‡å’Œé²æ£’æ€§ã€‚

#### ï¼ˆ3ï¼‰çº¿æ€§å¤æ‚åº¦æ¶æ„
- ç»“åˆ **MoE æ—¶é—´å‹ç¼©è¾“å…¥æ¨¡å—** å’Œ **AGA-Att**ï¼Œä½¿æ•´ä½“æ¨¡å‹çš„æ—¶é—´å’Œç©ºé—´å¤æ‚åº¦å‡ä¸èŠ‚ç‚¹æ•° $N$ å’Œæ—¶é—´æ­¥ $T$ å‘ˆçº¿æ€§å…³ç³»ï¼Œå…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **é«˜æ•ˆæ€§**ï¼šå®ç°çº¿æ€§å¤æ‚åº¦ï¼Œæ”¯æŒåœ¨å•GPUä¸Šè®­ç»ƒåŒ…å«æ•°åƒèŠ‚ç‚¹ã€é¢„æµ‹é•¿è¾¾ä¸€å‘¨ï¼ˆ672æ­¥ï¼‰çš„å¤§è§„æ¨¡STGã€‚
- **æœ‰æ•ˆæ€§**ï¼šé€šè¿‡å¼‚è´¨æ€§æ„ŸçŸ¥çš„MoEå’Œä»£ç†æ³¨æ„åŠ›ï¼Œä¿ç•™äº†ä¸°å¯Œçš„æ—¶ç©ºè¯­ä¹‰ï¼Œé¿å…äº†ä¿¡æ¯æŸå¤±å’Œè¡¨ç¤ºåŒè´¨åŒ–ã€‚
- **å¯æ‰©å±•æ€§**ï¼šåœ¨å¤šä¸ªå¤§è§„æ¨¡çœŸå®æ•°æ®é›†ä¸ŠéªŒè¯äº†å…¶åœ¨ä¸åŒå›¾è§„æ¨¡å’Œé¢„æµ‹é•¿åº¦ä¸‹çš„ç¨³å®šæ€§å’Œä¼˜è¶Šæ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
ä½¿ç”¨ **LargeST** åŸºå‡†æ•°æ®é›†ï¼ŒåŒ…å«å››ä¸ªå¤§è§„æ¨¡äº¤é€šæµé‡å­é›†ï¼š
| æ•°æ®é›† | èŠ‚ç‚¹æ•° | æ—¶é—´ç²’åº¦ | æ—¶é—´è·¨åº¦ | æ ·æœ¬é‡ |
|--------|--------|----------|----------|--------|
| **SD** | 716 | 15åˆ†é’Ÿ | 2019å…¨å¹´ | ~25M |
| **GBA** | 2,352 | 15åˆ†é’Ÿ | 2019å…¨å¹´ | ~82M |
| **GLA** | 3,834 | 15åˆ†é’Ÿ | 2019å…¨å¹´ | ~134M |
| **CA** | 8,600 | 15åˆ†é’Ÿ | 2019å…¨å¹´ | ~300M |

æ•°æ®æŒ‰æ—¶é—´é¡ºåºåˆ’åˆ†ä¸º 6:2:2 çš„è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ã€‚

### å®éªŒè®¾ç½®
- **é¢„æµ‹ä»»åŠ¡**ï¼šåŸºäºè¿‡å»96ä¸ªæ—¶é—´æ­¥ï¼ˆ24å°æ—¶ï¼‰é¢„æµ‹æœªæ¥ {48, 96, 192, 672} æ­¥ï¼ˆå³1å¤©åˆ°1å‘¨ï¼‰ã€‚
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šNVIDIA RTX A6000 GPU (48GB)ï¼ŒAMD EPYC CPUï¼Œ128GB RAMã€‚
- **ç»Ÿä¸€é…ç½®**ï¼šæ‰€æœ‰æ¨¡å‹åœ¨ **BasicTS** åŸºå‡†æ¡†æ¶ä¸‹å®ç°ï¼Œéšè—ç»´åº¦ç»Ÿä¸€è®¾ä¸º64ã€‚FaSTé‡‡ç”¨å›ºå®šé…ç½®ï¼ˆ#experts=8, #layers=3, #agents=32, #dim=64ï¼‰ï¼Œæœªè¿›è¡Œæ•°æ®é›†ç‰¹å®šè°ƒå‚ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **MAE**ï¼ˆå¹³å‡ç»å¯¹è¯¯å·®ï¼‰
- **RMSE**ï¼ˆå‡æ–¹æ ¹è¯¯å·®ï¼‰
- **MAPE**ï¼ˆå¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®ï¼‰
- **RÂ²**ï¼ˆå†³å®šç³»æ•°ï¼Œè¶Šé«˜è¶Šå¥½ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºä¸¤ç±»ï¼š
1. **æ—¶åºä¸­å¿ƒæ–¹æ³•ï¼ˆTemporal-centricï¼‰**ï¼š
   - DLinear
   - NHITS
   - CycleNet
2. **æ—¶ç©ºä¸­å¿ƒæ–¹æ³•ï¼ˆSpatial-Temporal-centricï¼‰**ï¼š
   - DCRNN, STGCN, GWNet, SGP, STID, STDMAE, BigST, RPMixer, STPGNN, PatchSTG

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- FaST åœ¨æ‰€æœ‰æ•°æ®é›†ã€æ‰€æœ‰é¢„æµ‹é•¿åº¦å’Œæ‰€æœ‰æŒ‡æ ‡ä¸Šå‡å–å¾— **SOTA æ€§èƒ½**ã€‚
- åœ¨æœ€å¤§è§„æ¨¡çš„ **CA æ•°æ®é›†ï¼ˆ8,600èŠ‚ç‚¹ï¼Œ672æ­¥é¢„æµ‹ï¼‰** ä¸Šï¼š
  - **MAE æ”¹è¿›**ï¼šç›¸æ¯”æœ€ä½³åŸºçº¿ï¼ˆSTIDï¼‰é™ä½ **4.4%~18.4%**ã€‚
  - **è®­ç»ƒé€Ÿåº¦**ï¼šæ¯”æœ€ä½³åŸºçº¿å¿« **1.3Ã—~2.2Ã—**ã€‚
  - **æ¨ç†é€Ÿåº¦**ï¼šåŒæ ·æ˜¾è‘—ä¼˜äºåŸºçº¿ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **å‡†ç¡®æ€§**ï¼šFaST åœ¨16ä¸ªé¢„æµ‹ä»»åŠ¡ä¸­å…¨éƒ¨æ’åç¬¬ä¸€ï¼ˆè§å›¾3ï¼‰ã€‚
- **æ•ˆç‡**ï¼š
  - åœ¨ CA æ•°æ®é›†ä¸Šï¼ŒFaST çš„ GPU å†…å­˜å ç”¨ä¸º **38.1GB**ï¼Œè€Œ PatchSTG è¾¾åˆ° **42.3GB**ï¼Œéƒ¨åˆ†åŸºçº¿ï¼ˆå¦‚ RPMixerï¼‰å› æ˜¾å­˜ä¸è¶³æ— æ³•è¿è¡Œã€‚
  - FaST çš„å‚æ•°é‡ï¼ˆ1.466Mï¼‰è™½é«˜äºéƒ¨åˆ†è½»é‡æ¨¡å‹ï¼ˆå¦‚ DLinear çš„130Kï¼‰ï¼Œä½†è¿œä½äº PatchSTGï¼ˆ1.951Mï¼‰ï¼Œåœ¨æ€§èƒ½ä¸æ•ˆç‡é—´å–å¾—è‰¯å¥½å¹³è¡¡ã€‚
- **å¯æ‰©å±•æ€§**ï¼šéšç€èŠ‚ç‚¹æ•°å¢åŠ ï¼ˆSD â†’ CAï¼‰ï¼ŒFaST çš„å†…å­˜å¢é•¿å‘ˆçº¿æ€§è¶‹åŠ¿ï¼Œè€Œå…¶ä»–æ–¹æ³•ï¼ˆå¦‚ NHITS, DLinearï¼‰å¢é•¿æ›´å¿«ã€‚

### æ¶ˆèå®éªŒç»“æœ
æ¶ˆèå®éªŒéªŒè¯äº†å„ç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼ˆè§å›¾4ï¼‰ï¼š
| å˜ä½“ | æ€§èƒ½ä¸‹é™åŸå›  |
|------|-------------|
| **w/ LinearInput** | ç”¨çº¿æ€§å±‚æ›¿ä»£MoEè¾“å…¥æ¨¡å—ï¼Œæ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œè¯´æ˜ **MoEæ—¶é—´å‹ç¼©** å¯¹æ•æ‰å¤æ‚ç‰¹å¾è‡³å…³é‡è¦ã€‚ |
| **w/o HA-MoE** | ç§»é™¤æ•´ä¸ªHA-MoEæ¨¡å—ï¼Œæ€§èƒ½ä¸‹é™æœ€ä¸¥é‡ï¼Œè¯æ˜ **MoEç»“æ„æ˜¯æ¨¡å‹æ ¸å¿ƒ**ã€‚ |
| **w/o HA-Router** | ç§»é™¤å¼‚è´¨æ€§æ„ŸçŸ¥è·¯ç”±å™¨ï¼Œæ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œè¯´æ˜ **åŠ¨æ€è·¯ç”±æœºåˆ¶** å¯¹é¿å…ä¸“å®¶æåŒ–ã€æå‡è¡¨è¾¾èƒ½åŠ›è‡³å…³é‡è¦ã€‚ |
| **w/o AGA-Att** | ç§»é™¤ä»£ç†æ³¨æ„åŠ›ï¼Œæ€§èƒ½å¤§å¹…ä¸‹é™ï¼Œè¯æ˜ **çº¿æ€§ç©ºé—´å¤æ‚åº¦è®¾è®¡** æ˜¯é«˜æ•ˆæ€§çš„å…³é”®ã€‚ |

æ­¤å¤–ï¼Œ**ä¸“å®¶ç»„ä»¶å¯¹æ¯”**ï¼ˆè¡¨2ï¼‰æ˜¾ç¤ºï¼š
- ä½¿ç”¨ **GLU-Experts** æ›¿ä»£ä¼ ç»Ÿ **FFN-Experts**ï¼Œç²¾åº¦å‡ ä¹ä¸å˜ï¼Œä½†è®­ç»ƒé€Ÿåº¦æå‡ **1.4å€**ï¼ŒéªŒè¯äº†å¹¶è¡ŒåŒ–è®¾è®¡çš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **FaST æ˜¯é¦–ä¸ªæˆåŠŸå®ç°å¤§è§„æ¨¡ï¼ˆæ•°åƒèŠ‚ç‚¹ï¼‰ä¸è¶…é•¿æ—¶åŸŸï¼ˆ672æ­¥ï¼‰è”åˆé¢„æµ‹çš„æ¡†æ¶**ï¼Œè§£é”äº†ä¸€å‘¨æå‰é¢„æµ‹çš„èƒ½åŠ›ã€‚
2. **å¼‚è´¨æ€§æ„ŸçŸ¥çš„ MoE è®¾è®¡** èƒ½æœ‰æ•ˆç¼“è§£å‹ç¼©å¸¦æ¥çš„ä¿¡æ¯æŸå¤±å’Œè¡¨ç¤ºåŒè´¨åŒ–é—®é¢˜ï¼ŒåŒæ—¶ä¿æŒé«˜è®¡ç®—æ•ˆç‡ã€‚
3. **ä»£ç†æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAGA-Attï¼‰** æˆåŠŸå°†ç©ºé—´å¤æ‚åº¦é™è‡³çº¿æ€§ï¼Œä¸”ç†è®ºåˆ†æï¼ˆé™„å½•Aï¼‰è¡¨æ˜å…¶é‡æ„è¯¯å·®è¾ƒä½ï¼Œä¿çœŸåº¦é«˜ã€‚
4. **FaST å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›**ï¼šåœ¨ç”µåŠ›éœ€æ±‚é¢„æµ‹ï¼ˆElectricity datasetï¼‰ä¸Šä¹Ÿå–å¾—SOTAï¼ŒMAPEç›¸å¯¹æå‡è¾¾ **12.03%~19.06%**ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¨¡å‹ä¾èµ–äºå›ºå®šçš„ agent æ•°é‡å’Œä¸“å®¶æ•°é‡ï¼Œå¯èƒ½éœ€è¦æ ¹æ®å…·ä½“åœºæ™¯è°ƒæ•´ä»¥è¾¾åˆ°æœ€ä¼˜ã€‚
- è™½ç„¶è§£å†³äº†å¤§è§„æ¨¡STGçš„æ•ˆç‡é—®é¢˜ï¼Œä½†åœ¨æç«¯ç¨€ç–æˆ–é«˜åº¦éå¹³ç¨³çš„æ•°æ®ä¸Šè¡¨ç°ä»éœ€è¿›ä¸€æ­¥éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢å°† **æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ï¼ˆtime series foundation modelsï¼‰** ä¸ FaST æ¡†æ¶ç»“åˆï¼Œè¿›ä¸€æ­¥æå‡å…¶é€šç”¨æ€§å’Œå¯è¿ç§»æ€§ã€‚
- ç ”ç©¶æ›´è‡ªé€‚åº”çš„ agent å’Œ expert æ•°é‡é€‰æ‹©ç­–ç•¥ï¼Œå®ç°åŠ¨æ€èµ„æºé…ç½®ã€‚
- å°† FaST æ‰©å±•è‡³æ›´å¤šé¢†åŸŸï¼Œå¦‚æ°”è±¡é¢„æµ‹ã€èƒ½æºè°ƒåº¦ã€åŸå¸‚äº‹ä»¶é¢„æµ‹ç­‰ã€‚

> **æºç åœ°å€**ï¼šhttps://github.com/yijizhao/FaST

</details>

---

### 2. [Safety-Utility Conflicts Are Not Global: Surgical Alignment via Head-Level Diagnosis](https://arxiv.org/abs/2601.04262)

**Authors**: Wang Cai, Yilin Wen, Jinchang Hou, Du Su, Guoqiu Wang, Zhonghou Lv, Chenfu Bao, Yunfang Wu  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.04262v1  

#### Abstract
Safety alignment in Large Language Models (LLMs) inherently presents a multi-objective optimization conflict, often accompanied by an unintended degradation of general capabilities. Existing mitigation strategies typically rely on global gradient geometry to resolve these conflicts, yet they overloo...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**Safety-Utility Conflicts Are Not Global: Surgical Alignment via Head-Level Diagnosis**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¿›è¡Œ **Safety Alignment**ï¼ˆå®‰å…¨å¯¹é½ï¼‰æ—¶ï¼Œå¸¸ä¼´éšç€â€œ**alignment tax**â€â€”â€”å³æ¨¡å‹é€šç”¨èƒ½åŠ›ï¼ˆå¦‚æ¨ç†ã€çŸ¥è¯†é—®ç­”ï¼‰çš„æ˜¾è‘—ä¸‹é™ã€‚ä¼ ç»Ÿæ–¹æ³•å°†æ­¤è§†ä¸ºå…¨å±€å¤šç›®æ ‡ä¼˜åŒ–ï¼ˆMOOï¼‰é—®é¢˜ï¼Œé€šè¿‡è°ƒæ•´æ¢¯åº¦æ–¹å‘ï¼ˆå¦‚ PCGradï¼‰æˆ–å‚æ•°æ›´æ–°æ–¹å¼ï¼ˆå¦‚ LoRAï¼‰æ¥ç¼“è§£å†²çªï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸å°†æ¨¡å‹è§†ä¸ºåŒè´¨æ•´ä½“ï¼Œå¿½ç•¥äº†å…¶å†…éƒ¨æ¨¡å—åŒ–å¼‚è´¨æ€§ï¼ˆModular Heterogeneityï¼‰ã€‚

æœ¬æ–‡æŒ‡å‡ºï¼Œè¿™ç§â€œä¸€åˆ€åˆ‡â€çš„å…¨å±€ç­–ç•¥ä¼šæ— å·®åˆ«åœ°æ›´æ–°æ‰€æœ‰å‚æ•°ï¼Œå¯¼è‡´æŸäº›å¯¹é€šç”¨èƒ½åŠ›é«˜åº¦æ•æ„Ÿçš„æ³¨æ„åŠ›å¤´ï¼ˆattention headsï¼‰è¢«ç ´åï¼Œä»è€Œå¼•å‘æ€§èƒ½é€€åŒ–ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼š**Conflict-Aware Sparse Tuning (CAST)**

CAST æ˜¯ä¸€ç§ç»“åˆ **Head-Level è¯Šæ–­** ä¸ **ç¨€ç–å¾®è°ƒ** çš„æ¡†æ¶ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**å¹¶éæ‰€æœ‰æ³¨æ„åŠ›å¤´éƒ½åŒç­‰é‡è¦ï¼Œå®‰å…¨-æ•ˆç”¨å†²çªé›†ä¸­åœ¨å°‘æ•°â€œé«˜å†²çªâ€å¤´ä¸Š**ã€‚

#### æ–¹æ³•æµç¨‹ï¼š
1. **Head-Level Conflict Diagnosis**ï¼ˆå¤´çº§å†²çªè¯Šæ–­ï¼‰  
   åœ¨å¯¹é½è®­ç»ƒå‰ï¼Œæ„å»ºä¸€ä¸ªâ€œ**Conflict Map**â€ï¼Œè¯†åˆ«æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„é£é™©ç­‰çº§ã€‚è¯¥è¯„åˆ†ç”±ä¸¤ä¸ªç»´åº¦åˆæˆï¼š
   - **Optimization Conflict (O)**ï¼šå®‰å…¨ç›®æ ‡ä¸æ•ˆç”¨ç›®æ ‡æ¢¯åº¦æ–¹å‘ä¹‹é—´çš„å¤¹è§’ï¼ˆå‡ ä½•å†²çªï¼‰
   - **Functional Sensitivity (S)**ï¼šè¯¥å¤´å¯¹é€šç”¨ä»»åŠ¡ï¼ˆå¦‚ MMLUï¼‰ä¸å®‰å…¨è¡Œä¸ºï¼ˆå¦‚æ‹’ç»æœ‰å®³è¯·æ±‚ï¼‰çš„å› æœå½±å“å·®å¼‚ï¼ˆåŠŸèƒ½æ•æ„Ÿæ€§ï¼‰

2. **Sparse Fine-Tuning**ï¼ˆç¨€ç–å¾®è°ƒï¼‰  
   ä»…æ›´æ–°â€œä½å†²çªâ€å¤´ï¼ˆSafe Zoneï¼‰ï¼Œå†»ç»“â€œé«˜å†²çªâ€å¤´ï¼ˆRisky Zoneï¼‰ï¼Œå®ç°ç²¾å‡†å¹²é¢„ã€‚

#### ç»Ÿä¸€å†²çªè¯„åˆ†å…¬å¼ï¼š
$$
C(h) = O(h) \cdot S(h)
$$

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ Full SFT, PCGradï¼‰ | CAST |
|------|-------------------------------|------|
| **æ›´æ–°ç²’åº¦** | å…¨å±€å‚æ•°æ›´æ–° | å¤´çº§åˆ«é€‰æ‹©æ€§æ›´æ–° |
| **å‡è®¾å‰æ** | æ¨¡å‹åŒè´¨ | æ‰¿è®¤æ¨¡å—å¼‚è´¨æ€§ |
| **æ•ˆç‡** | é«˜è®¡ç®—æˆæœ¬ï¼Œæ˜“å¼•å…¥å‰¯ä½œç”¨ | å‚æ•°é«˜æ•ˆï¼Œé¿å…å…³é”®å¤´è¢«ç ´å |
| **å¯è§£é‡Šæ€§** | é»‘ç®±ä¼˜åŒ– | æä¾›å¯è§†åŒ– Conflict Map |
| **trade-off è¡¨ç°** | å®‰å…¨æå‡ä»¥ç‰ºç‰²æ•ˆç”¨ä¸ºä»£ä»· | æ˜¾è‘—å‡å°‘æ•ˆç”¨æŸå¤±ï¼Œä¿æŒå®‰å…¨ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†

| ç±»å‹ | æ•°æ®é›† | ç”¨é€” |
|------|--------|------|
| **è¯Šæ–­é˜¶æ®µ** | `Dutil`: 500 ä¸ª MMLU æ ·æœ¬<br>`Dsafe`: 500 ä¸ª WildJailbreak æœ‰å®³æç¤º | æ„å»º Conflict Map |
| **å¯¹é½è®­ç»ƒ** | `Dalign`: 10,000 æ ·æœ¬ï¼ˆæ¥è‡ª WildJailbreakï¼‰<br>åŒ…å«å››ç±»ï¼švanilla harmful, adversarial harmful, vanilla benign, adversarial benign | å®‰å…¨å¾®è°ƒ |
| **è¯„ä¼°åŸºå‡†** | - **å®‰å…¨**: WildJailbreak (test), WildGuard, DAN<br>- **æ•ˆç”¨**: <br>â€ƒâ€¢ çŸ¥è¯†: MMLU, CSQA<br>â€ƒâ€¢ æ¨ç†: GSM8K, MATH | æ€§èƒ½è¯„ä¼° |

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

- **Safety Performance**: Defense Success Rateï¼ˆé˜²å¾¡æˆåŠŸç‡ï¼‰
- **Utility Performance**: å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰
- **Trade-off æŒ‡æ ‡**ï¼š
  - **Utility Cost Ratio (UCR)**ï¼šå•ä½å®‰å…¨å¢ç›Šå¸¦æ¥çš„æ•ˆç”¨æŸå¤±
    $$
    UCR = \max\left(0, \frac{U_b - U_a}{(S_a - S_b) + \epsilon}\right)
    $$
  - **MMLU-CR**ï¼šMMLU ä¸Šçš„ UCR å˜ä½“
- **ç›¸å…³æ€§æ£€éªŒ**ï¼šPearson $r$ å’Œ Spearman $\rho$ï¼Œè¡¡é‡é¢„æµ‹å†²çªåˆ†ä¸å®é™…æ•ˆç”¨æŸå¤±çš„ç›¸å…³æ€§

---

### âš–ï¸ åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿ | æè¿° |
|------|------|
| **Full SFT** | å¯¹æ‰€æœ‰æ³¨æ„åŠ›å¤´è¿›è¡Œ LoRA å¾®è°ƒï¼ˆæ ‡å‡†å¯¹é½ï¼‰ |
| **Random-SFT (25%)** | éšæœºé€‰æ‹© 25% å¤´è¿›è¡Œå¾®è°ƒï¼ˆæ§åˆ¶å‚æ•°é‡ï¼‰ |
| **PCGrad (PCG)** | æŠ•å½±å†²çªæ¢¯åº¦ä»¥ç¼“è§£å¹²æ‰°ï¼ˆå‡ ä½•ä¼˜åŒ–ä»£è¡¨ï¼‰ |
| **CAST-SFT / CAST-PCG** | ä»…æ›´æ–°ä½å†²çªå¤´ï¼ˆBottom-25%ï¼‰æˆ–é«˜å†²çªå¤´ï¼ˆTop-25%ï¼‰ |

> æ‰€æœ‰æ–¹æ³•å‡é‡‡ç”¨ç›¸åŒè¶…å‚ï¼ˆLoRA rank=32, lr=1e-4, batch size=8ï¼‰ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1 & Figure 3ï¼‰

#### åœ¨ **Llama-8B** ä¸Šçš„è¡¨ç°ï¼ˆéƒ¨åˆ†ï¼‰ï¼š

| æ–¹æ³• | MMLU | GSM8K | Avg. Gen | Avg. Safe |
|------|------|-------|----------|-----------|
| Base | 59.38 | 87.40 | 66.10 | 67.22 |
| Full-SFT | 46.28 | 20.80 | 36.78 | 90.61 |
| Random-SFT (25%) | 52.56 | 75.73 | 59.71 | 94.43 |
| **CAST-SFT (Safe Zone)** | **55.73** | **77.20** | **61.34** | **92.62** |
| CAST-SFT (Risky Zone) | 48.52 | 68.80 | 56.02 | 91.79 |

> âœ… **CAST åœ¨ä»…æ›´æ–° 25% å‚æ•°çš„æƒ…å†µä¸‹ï¼Œæ¢å¤äº†æ¥è¿‘ Base æ¨¡å‹çš„é€šç”¨èƒ½åŠ›ï¼ŒåŒæ—¶è¾¾åˆ°ä¸ Full-SFT ç›¸å½“çš„å®‰å…¨æ°´å¹³ã€‚**

---

### ğŸ” ä¸ PCGrad ç»“åˆçš„ç»“æœï¼ˆTable 2 & Figure 4ï¼‰

| æ–¹æ³• | MMLU | GSM8K | Avg. Gen | Avg. Safe |
|------|------|-------|----------|-----------|
| Full-PCG | 57.85 | 71.00 | 59.71 | 89.76 |
| **CAST-PCG (Safe Zone)** | **60.17** | **82.20** | **64.80** | **89.65** |

> âœ… **CAST + PCGrad è¿›ä¸€æ­¥æå‡äº†æ•ˆç”¨è¡¨ç°ï¼Œè¯´æ˜ç»“æ„é€‰æ‹©ä¸å‡ ä½•ä¼˜åŒ–å¯ååŒå¢æ•ˆã€‚**

---

### ğŸ“‰ æ¶ˆèå®éªŒç»“æœï¼ˆAppendix Fï¼‰

#### ï¼ˆ1ï¼‰ç»Ÿä¸€è¯„åˆ†å¿…è¦æ€§ï¼ˆTable 8ï¼‰
- å•ç‹¬ä½¿ç”¨ $O(h)$ æˆ– $S(h)$ é¢„æµ‹æ•ˆç”¨æŸå¤±ä¸ç¨³å®šï¼ˆå¦‚ $O(h)$ åœ¨ Llama ä¸Šä¸ MMLU-CR è´Ÿç›¸å…³ï¼‰
- **ç»Ÿä¸€è¯„åˆ† $C(h)$ åœ¨æ‰€æœ‰æ¨¡å‹ä¸Šå‡ä¿æŒå¼ºæ­£ç›¸å…³ï¼ˆPearson $r \in [0.73, 1.00]$ï¼‰**

#### ï¼ˆ2ï¼‰ç¨€ç–æ¯”ä¾‹åˆ†æï¼ˆTable 9ï¼‰
- æ›´æ–° **Bottom-25% ä½å†²çªå¤´** æ•ˆæœæœ€ä½³ï¼ˆGeneral Avg = 61.34ï¼‰
- å¢åŠ è‡³ Bottom-50% åè€Œæ€§èƒ½ä¸‹é™ï¼ˆ57.93ï¼‰ï¼Œè¯´æ˜â€œæ›´å¤šå‚æ•° â‰  æ›´å¥½â€
- Full SFT å¯¼è‡´â€œæ‚¬å´–å¼â€å´©æºƒï¼ˆGeneral Avg é™è‡³ 36.78ï¼‰

#### ï¼ˆ3ï¼‰æ•°æ®æ•ˆç‡æµ‹è¯•ï¼ˆTable 10ï¼‰
- ä»…ç”¨ **100 ä¸ª MMLU æ ·æœ¬** æ„å»ºè¯Šæ–­ï¼Œä»èƒ½å‡†ç¡®è¯†åˆ«æœ€ä¼˜å¤´ç»„ï¼ˆB4 è¾¾æœ€é«˜æ•ˆç”¨ï¼‰
- è¯æ˜ Conflict Map å…·å¤‡è‰¯å¥½æ•°æ®é²æ£’æ€§

#### ï¼ˆ4ï¼‰é¢†åŸŸè¿ç§»é—®é¢˜ï¼ˆTable 11ï¼‰
- è‹¥ç”¨ **GSM8Kï¼ˆæ¨ç†ä»»åŠ¡ï¼‰** æ›¿ä»£ MMLU è¿›è¡Œè¯Šæ–­ï¼Œæœ€ä¼˜åŒºä¸å†ä½äºå°¾éƒ¨ï¼ˆB4ï¼‰ï¼Œè€Œæ˜¯ä¸­é—´æ¡¶ï¼ˆB2/B3ï¼‰
- åŸå› ï¼šå•å¤´æ¶ˆèéš¾ä»¥æ•æ‰å¤æ‚æ¨ç†é“¾çš„ä¾èµ–å…³ç³»ï¼Œå¯¼è‡´æ•æ„Ÿæ€§ä½ä¼°
- ç»“è®ºï¼š**è¯Šæ–­éœ€ä¸ç›®æ ‡ä»»åŠ¡åŒ¹é…**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **å®‰å…¨-æ•ˆç”¨å†²çªä¸æ˜¯å…¨å±€çš„ï¼Œè€Œæ˜¯å±€éƒ¨åŒ–çš„**  
   å†²çªé›†ä¸­åœ¨å°‘æ•°ç‰¹å®šæ³¨æ„åŠ›å¤´ï¼ˆå°¤å…¶æ˜¯ä¸­æ·±å±‚ï¼‰ï¼Œå¤§å¤šæ•°å¤´å¯å®‰å…¨æ›´æ–°ã€‚

2. **æ•ˆç”¨æŸå¤±ä¸»è¦æºäºå¯¹â€œé«˜å†²çªå¤´â€çš„å¼ºåˆ¶æ›´æ–°**  
   è¿™äº›å¤´å…¼å…·é«˜æ¢¯åº¦å†²çªä¸é«˜åŠŸèƒ½æ•æ„Ÿæ€§ï¼Œè½»å¾®æ‰°åŠ¨å³å¯å¯¼è‡´æ¨ç†å´©æºƒæˆ–è¿‡åº¦æ‹’ç»ï¼ˆover-refusalï¼‰ã€‚

3. **CAST å®ç°æ›´ä¼˜çš„ Pareto å‰æ²¿**  
   åœ¨ç›¸åŒå‚æ•°é¢„ç®—ä¸‹ï¼ŒCAST æ˜¾è‘—ä¼˜äº Full SFTã€Random SFT å’Œ PCGradï¼Œå®ç°äº†â€œå®‰å…¨ä¸é™ã€æ•ˆç”¨å°‘æŸâ€ã€‚

4. **Conflict Score å…·æœ‰å¼ºé¢„æµ‹åŠ›**  
   é¢„å¯¹é½çš„ $C(h)$ ä¸åå¯¹é½çš„ UCR é«˜åº¦ç›¸å…³ï¼ˆPearson $r \geq 0.73$ï¼‰ï¼Œå¯ç”¨äºé£é™©é¢„è­¦ã€‚

5. **Qualitative æ”¹è¿›æ˜æ˜¾**  
   - é¿å… **Reasoning Collapse**ï¼ˆè·³è¿‡ CoT æ­¥éª¤ï¼‰
   - å‡å°‘ **Over-Refusal**ï¼ˆé”™è¯¯æ‹’ç»æ— å®³æ•°å­¦é¢˜ï¼‰

---

### âš ï¸ å±€é™æ€§ï¼ˆLimitationsï¼‰

| é™åˆ¶ | è¯´æ˜ |
|------|------|
| **Structural Scope** | å½“å‰ä»…å…³æ³¨ Query Projection (Wq)ï¼Œæœªè¦†ç›– MLP å±‚ï¼ˆå å¤šæ•°å‚æ•°ï¼‰ |
| **Static Diagnosis** | å†²çªå›¾è°±åŸºäºé¢„å¯¹é½çŠ¶æ€ï¼Œå‡è®¾å…¶ç¨³å®šï¼›ä½†é•¿å‘¨æœŸè®­ç»ƒå¯èƒ½å¯¼è‡´â€œå†²çªæ¼‚ç§»â€ |
| **Task Dependence** | è¯Šæ–­ä¾èµ–æ ¡å‡†é›†ï¼Œç‰¹å®šé¢†åŸŸï¼ˆå¦‚ä»£ç ç”Ÿæˆï¼‰å¯èƒ½éœ€è¦å®šåˆ¶åŒ–è¯Šæ–­ |

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. å°†è¯Šæ–­æ‰©å±•è‡³ **MLP å±‚** å’Œ **value/key projections**
2. è®¾è®¡ **åŠ¨æ€ Conflict Map**ï¼Œæ”¯æŒè®­ç»ƒè¿‡ç¨‹ä¸­åœ¨çº¿æ›´æ–°
3. å¼€å‘ **é¢†åŸŸè‡ªé€‚åº”è¯Šæ–­æœºåˆ¶**ï¼Œé€‚é…ä¸åŒä¸‹æ¸¸ä»»åŠ¡
4. æ¢ç´¢ **è‡ªåŠ¨åŒ– Safe Zone åˆ’åˆ†ç®—æ³•**ï¼Œæ›¿ä»£å›ºå®šç™¾åˆ†æ¯”åˆ†æ¡¶

---

## æ€»ç»“

> **CAST æä¾›äº†ä¸€ç§ä»â€œå…¨å±€ç²—è°ƒâ€åˆ°â€œç²¾å‡†æ‰‹æœ¯â€çš„èŒƒå¼è½¬å˜**ã€‚å®ƒåˆ©ç”¨ mechanistic interpretability çš„æ´å¯Ÿï¼Œå°† alignment è§†ä¸ºä¸€ä¸ªç»“æ„æ„ŸçŸ¥çš„ç¨€ç–ä¼˜åŒ–é—®é¢˜ï¼Œè€Œéå•çº¯çš„æ¢¯åº¦å·¥ç¨‹ã€‚å®éªŒè¯æ˜ï¼Œ**é¿å¼€å°‘æ•°é«˜é£é™©å¤´ï¼Œå³å¯å¤§å¹…ç¼“è§£ alignment tax**ï¼Œä¸ºé«˜æ•ˆã€å¯è§£é‡Šçš„å®‰å…¨å¯¹é½æä¾›äº†æ–°è·¯å¾„ã€‚

</details>

---

### 3. [Distributed Online Convex Optimization with Efficient Communication: Improved Algorithm and Lower bounds](https://arxiv.org/abs/2601.04907)

**Authors**: Sifan Yang, Wenhao Yang, Wei Jiang, Lijun Zhang  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.04907v1  

#### Abstract
We investigate distributed online convex optimization with compressed communication, where $n$ learners connected by a network collaboratively minimize a sequence of global loss functions using only local information and compressed data from neighbors. Prior work has established regret bounds of $O(...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDistributed Online Convex Optimization with Efficient Communication: Improved Algorithm and Lower bounds

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡ç ”ç©¶çš„æ˜¯**åˆ†å¸ƒå¼åœ¨çº¿å‡¸ä¼˜åŒ–ï¼ˆD-OCOï¼‰ä¸­å¸¦æœ‰å‹ç¼©é€šä¿¡çš„åœºæ™¯**ã€‚åœ¨è¯¥è®¾å®šä¸‹ï¼Œ$n$ ä¸ªé€šè¿‡ç½‘ç»œè¿æ¥çš„å­¦ä¹ è€…ï¼ˆlearnersï¼‰åä½œæœ€å°åŒ–ä¸€ç³»åˆ—å…¨å±€æŸå¤±å‡½æ•° $f_t(x) = \frac{1}{n}\sum_{i=1}^n f_{t,i}(x)$ï¼Œä½†æ¯ä¸ªå­¦ä¹ è€…åªèƒ½è®¿é—®å±€éƒ¨ä¿¡æ¯ï¼Œå¹¶ä¸”ä¸é‚»å±…äº¤æ¢çš„ä¿¡æ¯éœ€è¦ç»è¿‡**å‹ç¼©ï¼ˆcompressionï¼‰**ä»¥å‡å°‘é€šä¿¡å¼€é”€ã€‚

å·²æœ‰å·¥ä½œï¼ˆå¦‚ Tu et al., 2022ï¼‰æå‡ºçš„ç®—æ³•ï¼ˆå¦‚ DC-DOGDï¼‰å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **ç†è®ºä¿è¯è¾ƒå·®**ï¼šå…¶åæ‚”ç•Œï¼ˆregret boundsï¼‰å¯¹å‹ç¼©è´¨é‡å› å­ $w^{-1}$ å‘ˆç°å‡ºäºŒæ¬¡ç”šè‡³å››æ¬¡æ–¹ä¾èµ–ï¼ˆquadratic or quartic dependenceï¼‰ï¼Œå½“å‹ç¼©ç‡è¾ƒé«˜ï¼ˆå³ $w < 1$ï¼‰æ—¶ï¼Œæ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚
- **å¯¹å­¦ä¹ è€…æ•°é‡ $n$ çš„ä¾èµ–è¿‡å¼º**ï¼šè¡¨ç°å‡ºè¶…çº¿æ€§ä¾èµ–ï¼ˆsuper-linear dependenceï¼‰ï¼Œä¸å¤Ÿç†æƒ³ã€‚

å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•è®¾è®¡ä¸€ä¸ªåœ¨å‹ç¼©é€šä¿¡ä¸‹å…·æœ‰æ›´ä¼˜ç†è®ºä¿è¯çš„ D-OCO ç®—æ³•ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•å’Œæ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Two-level Compressed Decentralized Online Gradient Descent (Top-DOGD)** çš„æ–°ç®—æ³•ï¼Œå…¶æ ¸å¿ƒæ˜¯ä¸€ä¸ª**ä¸¤çº§é˜»å¡æ›´æ–°æ¡†æ¶ï¼ˆtwo-level blocking update frameworkï¼‰**ï¼Œå¹¶ç»“åˆäº†ä¸¤ä¸ªå…³é”®æŠ€æœ¯ï¼š

1.  **åœ¨çº¿å‹ç¼©å…«å¦ç­–ç•¥ï¼ˆonline gossip strategyï¼‰**ï¼š
    - åœ¨æ¯ä¸ªâ€œå—â€ï¼ˆblockï¼‰çš„å‰ $L_1$ è½®ä¸­ï¼Œæ‰§è¡Œå¤šæ­¥ gossip æ›´æ–°ã€‚
    - åˆ©ç”¨å¤šæ¬¡é€šä¿¡æ¥åŠ é€Ÿå…±è¯†è¿‡ç¨‹ï¼Œä»è€Œæœ‰æ•ˆé™ä½**å…±è¯†è¯¯å·®ï¼ˆconsensus errorï¼‰**å’Œ**å‹ç¼©è¯¯å·®ï¼ˆcompression errorï¼‰**ã€‚
    - é€šè¿‡é˜»å¡æœºåˆ¶ï¼Œå°†å¤šè½®é€šä¿¡çš„å¼€é”€å¹³æ‘Šåˆ°å•è½®é€šä¿¡ä¸­ï¼Œä¿æŒäº†æ¯è½®ä¸€æ¬¡é€šä¿¡çš„æ•ˆç‡ã€‚

2.  **æŠ•å½±è¯¯å·®è¡¥å¿æ–¹æ¡ˆï¼ˆerror compensation schemeï¼‰**ï¼š
    - åœ¨æ¯ä¸ªâ€œå—â€çš„å $L_2$ è½®ä¸­ï¼Œé€’å½’åœ°å‹ç¼©å’Œä¼ è¾“æŠ•å½±æ“ä½œäº§ç”Ÿçš„æ®‹å·®ï¼ˆresidualï¼‰ã€‚
    - è¿™ä¸€æœºåˆ¶ä¸“é—¨ç”¨äºæ§åˆ¶å› æŠ•å½±æ“ä½œå¼•å…¥çš„**æŠ•å½±è¯¯å·®ï¼ˆprojection errorï¼‰**ï¼Œé¿å…å…¶å¯¼è‡´å¯¹ $n$ çš„ä¸è‰¯ä¾èµ–ã€‚

è¿™ä¸¤ä¸ªæŠ€æœ¯ååŒå·¥ä½œï¼Œåœ¨ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶å†…åŒæ—¶å¤„ç†äº†ç”±**å»ä¸­å¿ƒåŒ–ã€å‹ç¼©å’ŒæŠ•å½±**å¸¦æ¥çš„ä¸‰ç§ä¸»è¦è¯¯å·®æºã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ˜¾è‘—æ”¹è¿›çš„åæ‚”ç•Œï¼ˆRegret Boundsï¼‰**ï¼š
  - å¯¹äºå‡¸å‡½æ•°ï¼ŒTop-DOGD è¾¾åˆ°äº† $O(w^{-1/2}p^{-1}n\sqrt{T})$ çš„åæ‚”ç•Œã€‚
  - å¯¹äºå¼ºå‡¸å‡½æ•°ï¼Œè¾¾åˆ°äº† $O(w^{-1}p^{-2}n\ln T)$ çš„åæ‚”ç•Œã€‚
  - ç›¸æ¯” Tu et al. (2022) çš„ $O(\max\{w^{-2}p^{-4}n^{1/2}, w^{-4}p^{-8}\}n\sqrt{T})$ å’Œ $O(\max\{w^{-2}p^{-4}n^{1/2}, w^{-4}p^{-8}\}n\ln T)$ï¼ŒTop-DOGD åœ¨ $w$ å’Œ $p$ ä¸Šçš„ä¾èµ–å¤§å¤§å‡å¼±ï¼Œä» $w^{-2}/w^{-4}$ æ”¹è¿›åˆ° $w^{-1/2}/w^{-1}$ï¼Œä» $p^{-4}/p^{-8}$ æ”¹è¿›åˆ° $p^{-1}/p^{-2}$ã€‚

- **å»ºç«‹äº†é¦–ä¸ªä¸‹ç•Œï¼ˆLower Boundsï¼‰**ï¼š
  - è®ºæ–‡é¦–æ¬¡ä¸ºè¯¥é—®é¢˜å»ºç«‹äº†åŒ¹é…çš„ä¸‹ç•Œï¼š$\Omega(w^{-1/2}p^{-1/4}n\sqrt{T})$ï¼ˆå‡¸ï¼‰å’Œ $\Omega(w^{-1}p^{-1/2}n\ln T)$ï¼ˆå¼ºå‡¸ï¼‰ã€‚
  - è¿™äº›ä¸‹ç•Œè¯æ˜äº†æ‰€æä¸Šç•Œçš„**è¿‘ä¼¼æœ€ä¼˜æ€§**ï¼ˆnear-optimalityï¼‰ï¼Œå°¤å…¶æ˜¯åœ¨ $w$ å’Œ $T$ ä¸Šçš„ä¾èµ–ã€‚

- **æ‰©å±•åˆ°Banditåé¦ˆåœºæ™¯**ï¼š
  - å°† Top-DOGD ä¸ç»å…¸æ¢¯åº¦ä¼°è®¡å™¨ç»“åˆï¼Œæå‡ºäº† Top-DOBD-1ï¼ˆå•ç‚¹åé¦ˆï¼‰å’Œ Top-DOBD-2ï¼ˆä¸¤ç‚¹åé¦ˆï¼‰ã€‚
  - åœ¨ bandit åœºæ™¯ä¸‹ä¹Ÿæ˜¾è‘—æ”¹è¿›äº†ç°æœ‰çš„åæ‚”ç•Œã€‚

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œ**æœ¬æ–‡æ˜¯ä¸€ç¯‡ç†è®ºåˆ†æä¸ºä¸»çš„è®ºæ–‡ï¼Œæ²¡æœ‰è¿›è¡Œä¼ ç»Ÿæ„ä¹‰ä¸Šçš„æ•°å€¼å®éªŒæˆ–åœ¨çœŸå®æ•°æ®é›†ä¸Šçš„æµ‹è¯•**ã€‚å…¶â€œå®éªŒâ€éƒ¨åˆ†ä¸»è¦ä½“ç°åœ¨**ä¸¥æ ¼çš„æ•°å­¦æ¨å¯¼å’Œç†è®ºè¯æ˜**ä¸Šã€‚

### ä½¿ç”¨çš„æ•°æ®é›†
- **æ— å®é™…æ•°æ®é›†**ã€‚æ‰€æœ‰åˆ†æåŸºäºé€šç”¨çš„å‡¸/å¼ºå‡¸å‡½æ•°å‡è®¾å’Œæ ‡å‡†çš„ç†è®ºæ¨¡å‹ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **é—®é¢˜è®¾å®š**ï¼š$n$ ä¸ªå­¦ä¹ è€…åœ¨ä¸€ä¸ªç”±å›¾ $G=([n], E)$ å®šä¹‰çš„ç½‘ç»œä¸Šåä½œã€‚
- **é€šä¿¡æ¨¡å‹**ï¼šå­¦ä¹ è€…ä¹‹é—´é€šè¿‡ä¸€ä¸ªæ»¡è¶³åŒé‡éšæœºæ€§å’Œè°±éš™ï¼ˆspectral gapï¼‰$p$ çš„çŸ©é˜µ $P$ è¿›è¡Œé€šä¿¡ã€‚
- **å‹ç¼©æ¨¡å‹**ï¼šé‡‡ç”¨ $w$-contractive compressorï¼Œå…¶ä¸­ $w \in (0,1]$ è¡¨ç¤ºå‹ç¼©è´¨é‡ï¼ˆ$w=1$ ä¸ºæ— å‹ç¼©ï¼‰ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼šä¸»è¦è¯„ä¼°æŒ‡æ ‡æ˜¯**åæ‚”å€¼ï¼ˆRegretï¼‰** $R(T,i)$ï¼Œå®šä¹‰ä¸ºå­¦ä¹ è€… $i$ åœ¨ $T$ è½®å†…çš„ç´¯è®¡æŸå¤±ä¸æœ€ä¼˜å›ºå®šå†³ç­–çš„ç´¯è®¡æŸå¤±ä¹‹å·®ã€‚
- **ç†è®ºåˆ†æå·¥å…·**ï¼šåˆ©ç”¨äº†å‡¸åˆ†æã€é…ä¸ç­‰å¼ã€è°±å›¾ç†è®ºç­‰å·¥å…·è¿›è¡Œä¸¥æ ¼è¯æ˜ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- ä¸»è¦å¯¹æ¯”å¯¹è±¡æ˜¯ **Tu et al. (2022)** æå‡ºçš„ **DC-DOGD** ç®—æ³•ã€‚
- åŒæ—¶ä¸æœªå‹ç¼©é€šä¿¡ä¸‹çš„æœ€ä¼˜ç»“æœï¼ˆå¦‚ Wan et al., 2025ï¼‰è¿›è¡Œäº†ç†è®ºä¸Šçš„æ¯”è¾ƒï¼Œä»¥è¯´æ˜å‹ç¼©å¸¦æ¥çš„é¢å¤–ä»£ä»·ã€‚

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

ç”±äºç¼ºä¹æ•°å€¼å®éªŒï¼Œè¿™é‡Œçš„â€œç»“æœâ€æŒ‡çš„æ˜¯**ç†è®ºæ€§èƒ½æŒ‡æ ‡çš„å¯¹æ¯”**ã€‚

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆç†è®ºåæ‚”ç•Œï¼‰
| æ¥æº | æŸå¤±å‡½æ•° | åæ‚”ç•Œï¼ˆRegret Boundsï¼‰ |
| :--- | :--- | :--- |
| Tu et al. (2022) | å‡¸å‡½æ•° | $O(\max\{w^{-2}p^{-4}n^{1/2}, w^{-4}p^{-8}\}n\sqrt{T})$ |
| **æœ¬æ–‡ (Top-DOGD)** | **å‡¸å‡½æ•°** | **$O(w^{-1/2}p^{-1}n\sqrt{\ln n}\sqrt{T})$** |
| Tu et al. (2022) | å¼ºå‡¸å‡½æ•° | $O(\max\{w^{-2}p^{-4}n^{1/2}, w^{-4}p^{-8}\}n\ln T)$ |
| **æœ¬æ–‡ (Top-DOGD)** | **å¼ºå‡¸å‡½æ•°** | **$O(w^{-1}p^{-2}n \ln n \ln T)$** |
| **æœ¬æ–‡ (ä¸‹ç•Œ)** | **å‡¸å‡½æ•°** | **$\Omega(w^{-1/2}p^{-1/4}n\sqrt{T})$** |
| **æœ¬æ–‡ (ä¸‹ç•Œ)** | **å¼ºå‡¸å‡½æ•°** | **$\Omega(w^{-1}p^{-1/2}n\ln T)$** |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **Top-DOGD åœ¨ç†è®ºä¸Šå…¨é¢ä¼˜äº DC-DOGD**ï¼š
  - åœ¨ $w$ çš„ä¾èµ–ä¸Šï¼Œä»æœ€åæƒ…å†µçš„ $w^{-4}$ æ”¹è¿›åˆ° $w^{-1}$ï¼Œè¿™æ˜¯ä¸€ä¸ªå·¨å¤§çš„æå‡ï¼Œæ„å‘³ç€ç®—æ³•å¯¹é«˜å‹ç¼©ç‡æ›´åŠ é²æ£’ã€‚
  - åœ¨ $p$ çš„ä¾èµ–ä¸Šï¼Œä» $p^{-8}$ æ”¹è¿›åˆ° $p^{-2}$ï¼Œå¯¹ç½‘ç»œè¿é€šæ€§è¾ƒå·®ï¼ˆ$p$ å°ï¼‰çš„æƒ…å†µæ›´å…·é€‚åº”æ€§ã€‚
  - åœ¨ $n$ çš„ä¾èµ–ä¸Šï¼Œè™½ç„¶ä»æœ‰çº¿æ€§å…³ç³»ï¼Œä½†æ¶ˆé™¤äº†ä¸å¿…è¦çš„ $n^{1/2}$ å› å­ï¼Œæ›´æ¥è¿‘å·²çŸ¥çš„ä¸‹ç•Œã€‚

### æ¶ˆèå®éªŒç»“æœ
è®ºæ–‡é€šè¿‡ç†è®ºåˆ†æè¿›è¡Œäº†ç±»ä¼¼â€œæ¶ˆèå®éªŒâ€çš„è®¨è®ºï¼š
- **ç§»é™¤æŠ•å½±è¯¯å·®è¡¥å¿ï¼ˆ$L_2=0$ï¼‰**ï¼šä¼šå¯¼è‡´åæ‚”ç•Œé€€åŒ–ä¸º $O(w^{-1/2}p^{-1}n^{5/4}\sqrt{\ln n}\sqrt{T})$ï¼Œå¯¹ $n$ çš„ä¾èµ–å˜å·®ã€‚
- **ä»…æ‰§è¡Œå•æ­¥å…«å¦ï¼ˆ$L_1=1$ï¼‰**ï¼šå³ä½¿æœ‰æŠ•å½±è¡¥å¿ï¼Œä¹Ÿæ— æ³•æ”¹å–„å…±è¯†å’Œå‹ç¼©è¯¯å·®ï¼Œæ— æ³•è¶…è¶Š Tu et al. (2022) çš„ç»“æœã€‚
- **ç»“è®º**ï¼š**ä¸¤çº§æ¡†æ¶ä¸­çš„ä¸¤ä¸ªç»„ä»¶ç¼ºä¸€ä¸å¯**ï¼Œå¿…é¡»ååŒå·¥ä½œæ‰èƒ½è¾¾åˆ°æœ€ä¼˜çš„ç†è®ºæ€§èƒ½ã€‚

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1.  **Top-DOGD ç®—æ³•æˆåŠŸè§£å†³äº†å‹ç¼©é€šä¿¡ä¸‹ D-OCO çš„ç†è®ºç“¶é¢ˆ**ï¼Œå®ç°äº†å¯¹å‹ç¼©å› å­ $w$ å’Œè°±éš™ $p$ æ›´å¼±çš„ä¾èµ–ã€‚
2.  **é¦–æ¬¡ä¸ºè¯¥é—®é¢˜å»ºç«‹äº†åŒ¹é…çš„ä¸‹ç•Œ**ï¼Œä»ç†è®ºä¸Šè¯æ˜äº†æ‰€æç®—æ³•çš„è¿‘ä¼¼æœ€ä¼˜æ€§ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸçš„ç©ºç™½ã€‚
3.  **ä¸¤çº§é˜»å¡æ›´æ–°æ¡†æ¶**æ˜¯ä¸€ç§æœ‰æ•ˆçš„è®¾è®¡èŒƒå¼ï¼Œèƒ½å¤Ÿå°†éœ€è¦å¤šè½®é€šä¿¡çš„æŠ€æœ¯ï¼ˆå¦‚å¤šæ­¥ gossip å’Œé€’å½’å‹ç¼©ï¼‰æ— ç¼é›†æˆåˆ°æ¯è½®é€šä¿¡å—é™çš„åœ¨çº¿å­¦ä¹ ç¯å¢ƒä¸­ã€‚
4.  æ‰€ææ–¹æ³•å¯ä»¥è‡ªç„¶åœ°æ‰©å±•åˆ° **bandit åé¦ˆ**åœºæ™¯ï¼Œå¹¶åŒæ ·èƒ½å¸¦æ¥ç†è®ºä¸Šçš„æ”¹è¿›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **çº¯ç†è®ºå·¥ä½œ**ï¼šç¼ºä¹åœ¨çœŸå®æ•°æ®é›†ï¼ˆå¦‚ä¼ æ„Ÿå™¨ç½‘ç»œã€åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼‰ä¸Šçš„æ•°å€¼éªŒè¯ï¼Œå…¶å®ç”¨æ€§å’Œæ”¶æ•›é€Ÿåº¦æœ‰å¾…å®è¯æ£€éªŒã€‚
- **å¤æ‚æ€§å¢åŠ **ï¼šç®—æ³•å¼•å…¥äº†é˜»å¡æœºåˆ¶å’Œé¢å¤–çš„é€šä¿¡è½®æ¬¡ï¼ˆåœ¨å—å†…ï¼‰ï¼Œå¯èƒ½å¢åŠ äº†å®ç°çš„å¤æ‚æ€§å’Œå»¶è¿Ÿã€‚
- **å‚æ•°é€‰æ‹©**ï¼šç®—æ³•æ€§èƒ½ä¾èµ–äºå—å¤§å° $L_1, L_2$ å’Œå­¦ä¹ ç‡ç­‰å‚æ•°çš„ç²¾ç»†è°ƒä¼˜ï¼Œè¿™äº›å‚æ•°çš„ç†è®ºæœ€ä¼˜å€¼å¯èƒ½åœ¨å®è·µä¸­éš¾ä»¥ç²¾ç¡®è·å¾—ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **è¿›è¡Œå¤§è§„æ¨¡çš„æ•°å€¼å®éªŒ**ï¼ŒéªŒè¯ Top-DOGD åœ¨å®é™…åº”ç”¨ä¸­çš„æ€§èƒ½ã€‚
- æ¢ç´¢æ›´ç®€å•æˆ–è‡ªé€‚åº”çš„å‚æ•°é€‰æ‹©ç­–ç•¥ã€‚
- å°†è¯¥æ¡†æ¶åº”ç”¨äºæ›´å¤æ‚çš„ä¼˜åŒ–é—®é¢˜ï¼Œå¦‚éå‡¸ä¼˜åŒ–ã€å¸¦çº¦æŸçš„ä¼˜åŒ–æˆ–å¼‚æ­¥é€šä¿¡ç¯å¢ƒã€‚
- ç ”ç©¶åœ¨ä¸åŒç±»å‹çš„å‹ç¼©ç®—å­ï¼ˆå¦‚é‡åŒ–ã€ç¨€ç–åŒ–ï¼‰ä¸‹çš„å…·ä½“å®ç°å’Œæ€§èƒ½ã€‚

</details>

---

### 4. [RelayLLM: Efficient Reasoning via Collaborative Decoding](https://arxiv.org/abs/2601.05167)

**Authors**: Chengsong Huang, Tong Zheng, Langlin Huang, Jinyuan Li, Haolin Liu, Jiaxin Huang  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.05167v1  

#### Abstract
Large Language Models (LLMs) for complex reasoning is often hindered by high computational costs and latency, while resource-efficient Small Language Models (SLMs) typically lack the necessary reasoning capacity. Existing collaborative approaches, such as cascading or routing, operate at a coarse gr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# RelayLLM: Efficient Reasoning via Collaborative Decoding â€”â€” æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶é«˜è®¡ç®—æˆæœ¬å’Œå»¶è¿Ÿé™åˆ¶äº†å®é™…éƒ¨ç½²ã€‚å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰è™½ç„¶é«˜æ•ˆï¼Œä½†åœ¨å¤æ‚æ¨ç†ä¸Šèƒ½åŠ›ä¸è¶³ã€‚ç°æœ‰çš„åä½œæ–¹æ³•ï¼ˆå¦‚ cascading æˆ– routingï¼‰é€šå¸¸ä»¥â€œæŸ¥è¯¢çº§åˆ«â€ä¸ºå•ä½å°†æ•´ä¸ªä»»åŠ¡äº¤ç»™ LLM å¤„ç†ï¼Œå¯¼è‡´å¤§é‡ä¸å¿…è¦çš„è®¡ç®—å¼€é”€â€”â€”å³ä½¿ SLM èƒ½ç‹¬ç«‹å®Œæˆå¤§éƒ¨åˆ†æ¨ç†æ­¥éª¤ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **RelayLLM**ï¼Œä¸€ç§åŸºäº**token-level ååŒè§£ç **ï¼ˆcollaborative decodingï¼‰çš„æ–°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- å°† LLM è§†ä¸ºä¸€ä¸ªå¯æŒ‰éœ€è°ƒç”¨çš„â€œå·¥å…·â€ï¼Œè€Œéå¤‡ç”¨ç”Ÿæˆå™¨ã€‚
- å…è®¸ SLM åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä¸»åŠ¨é€šè¿‡ç‰¹æ®Šå‘½ä»¤ `<call>n</call>` è¯·æ±‚ LLM ç”ŸæˆæŒ‡å®šæ•°é‡çš„ tokenï¼Œä¹‹åå†ç”± SLM ç»§ç»­æ¨ç†ã€‚
- SLM åŒæ—¶æ‰®æ¼”â€œé—®é¢˜æ±‚è§£è€…â€å’Œâ€œæ§åˆ¶å™¨â€çš„è§’è‰²ï¼ŒåŠ¨æ€å†³å®šä½•æ—¶ã€è°ƒç”¨å¤šå°‘ token æ¥å¼¥è¡¥å…³é”®æ¨ç†ç¼ºå£ã€‚

è¯¥æœºåˆ¶çµæ„Ÿæ¥è‡ª **tool-use agents**ï¼Œå®ç°äº†ç»†ç²’åº¦ã€æŒ‰éœ€çš„åä½œã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| å¯¹æ¯”ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ cascading / routingï¼‰ | RelayLLM |
|--------|-------------------------------|---------|
| åä½œç²’åº¦ | æŸ¥è¯¢çº§ï¼ˆquery-levelï¼‰ | **Tokençº§**ï¼ˆfine-grainedï¼‰ |
| æ§åˆ¶æœºåˆ¶ | å¤–éƒ¨è·¯ç”±å™¨æˆ–é™æ€ç­–ç•¥ | **SLM è‡ªä¸»å†³ç­–**ï¼ˆæ— é¢å¤–æ§åˆ¶å™¨ï¼‰ |
| æˆæœ¬æ•ˆç‡ | é«˜ï¼ˆæ•´æ®µ offloadï¼‰ | **æä½**ï¼ˆä»… 1.07% token è°ƒç”¨ LLMï¼‰ |
| æ€§èƒ½æå‡ | æœ‰é™ | æ˜¾è‘—æå‡ï¼ˆå¹³å‡å‡†ç¡®ç‡ +6.9% vs random routerï¼‰ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šRelayLLM å®ç°äº†â€œç²¾å‡†å¹²é¢„â€ï¼Œé¿å…äº†â€œå…¨æœ‰æˆ–å…¨æ— â€çš„æµªè´¹ï¼Œåœ¨å‡ ä¹ä¸å¢åŠ æˆæœ¬çš„å‰æä¸‹æ˜¾è‘—æå‡äº† SLM çš„æ¨ç†èƒ½åŠ›ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

è®­ç»ƒæ•°æ®ï¼š
- **DAPO dataset**ï¼ˆå¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ æ¨ç†æ•°æ®é›†ï¼‰

è¯„ä¼°åŸºå‡†ï¼ˆå…±å…­ä¸ªæ•°å­¦æ¨ç†ä»»åŠ¡ï¼‰ï¼š
- **Minerva**
- **MATH-500**
- **GSM8K**
- **Olympiad-Bench**
- **AIME-2024**
- **AIME-2025**

æ­¤å¤–è¿˜æµ‹è¯•äº†è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ï¼š
- **Big-Bench Hard (BBEH)**
- **MMLU-Pro**
- **SuperGPQA**

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

| è®¾ç½®é¡¹ | æè¿° |
|------|------|
| æ¨¡å‹é€‰æ‹© | å­¦ç”Ÿæ¨¡å‹ï¼ˆSLMï¼‰ï¼š`Qwen3-0.6B`, `Qwen3-1.7B`<br>æ•™å¸ˆæ¨¡å‹ï¼ˆLLMï¼‰ï¼š`Qwen3-8B`ï¼ˆåŒç³»åˆ—ç¡®ä¿åˆ†å¸ƒä¸€è‡´æ€§ï¼‰ |
| æ¨ç†æ¨¡å¼ | é thinking æ¨¡å¼ï¼ˆnon-thinking modeï¼‰ |
| è®­ç»ƒé˜¶æ®µ | ä¸¤é˜¶æ®µï¼š<br>1. **Supervised Warm-up**ï¼ˆç›‘ç£é¢„çƒ­ï¼‰<br>2. **Group Relative Policy Optimization (GRPO)**ï¼ˆå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ï¼‰ |
| è¯„ä¼°æ–¹å¼ | - AIME æ•°æ®é›†ï¼š`avg@32`<br>- å…¶ä»–æ•°æ®é›†ï¼š`pass@1`ï¼ˆgreedy decodingï¼‰<br>- ä½¿ç”¨ `GPT-4o-mini` ä½œä¸ºè¯­ä¹‰è£åˆ¤éªŒè¯ç­”æ¡ˆæ­£ç¡®æ€§ |
| åä½œæˆæœ¬åº¦é‡ | **Call Ratio**ï¼šLLM ç”Ÿæˆçš„ token æ•°å æ€»è¾“å‡º token çš„ç™¾åˆ†æ¯” |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿æ–¹æ³• | ç±»å‹è¯´æ˜ |
|--------|----------|
| **Base Model** | æœªç»å¾®è°ƒçš„åŸå§‹ SLM |
| **GRPO Baseline** | æ ‡å‡† GRPO å¾®è°ƒï¼ˆæ— åä½œï¼‰ |
| **CITER** | token-level è·¯ç”±æ–¹æ³•ï¼Œä¾èµ–å¤–éƒ¨ MLP æ§åˆ¶å™¨ |
| **Random Router** | æŸ¥è¯¢çº§éšæœºè·¯ç”±åˆ° SLM æˆ– LLM |
| **Perfect Router** | ç†æƒ³æƒ…å†µä¸‹çš„æŸ¥è¯¢çº§è·¯ç”±ï¼ˆä»…éš¾é—®é¢˜äº¤ç»™ LLMï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æ¨¡å‹ | å¹³å‡å‡†ç¡®ç‡ï¼ˆ6 benchmarksï¼‰ | Avg. Call Ratio |
|------|-----------------------------|----------------|
| Qwen3-0.6B (Base) | 27.17% | â€” |
| Qwen3-1.7B (Base) | 42.50% | â€” |
| Qwen3-8B (Teacher Only) | 54.12% | 100% |
| **RelayLLM (Qwen3-1.7B, Difficulty-Aware)** | **49.52%** | **1.07%** |

ğŸ‘‰ **æ€§èƒ½æ¢å¤æ•ˆæœ**ï¼šRelayLLM æ¢å¤äº†çº¦ **60%** çš„ SLM ä¸ LLM ä¹‹é—´çš„æ€§èƒ½å·®è·ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| ç›¸æ¯” **Random Router**ï¼ˆèµ„æºç­‰æ•ˆï¼‰ | **+6.9% å‡†ç¡®ç‡æå‡** |
| ç›¸æ¯” **CITER**ï¼ˆtoken-level è·¯ç”±ï¼‰ | æ›´é«˜å‡†ç¡®ç‡ + æ›´ä½æˆæœ¬ï¼ˆæ— éœ€é¢å¤–æ§åˆ¶å™¨ï¼‰ |
| æˆæœ¬èŠ‚çº¦ | **ç›¸æ¯”æ€§èƒ½åŒ¹é…çš„éšæœºè·¯ç”±å™¨ï¼Œå‡å°‘ 98.2% çš„ token å¼€é”€** |
| åœ¨ Minerva ä¸Šçš„è¡¨ç° | Qwen3-0.6B ä» 15.81% â†’ **23.53%**ï¼ˆ+48.8%ï¼‰ï¼Œä»…è°ƒç”¨ 0.77% token |

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

ä½¿ç”¨ Qwen3-1.7B è¿›è¡Œæ¶ˆèåˆ†æï¼š

| æ–¹æ³•å˜ä½“ | å¹³å‡å‡†ç¡®ç‡ | Call Ratio |
|--------|-----------|------------|
| å®Œæ•´ RelayLLM | **49.52%** | **1.07%** |
| w/o Data Filteringï¼ˆä¸æ»¤é™¤æ•™å¸ˆæ— æ³•è§£å†³çš„é—®é¢˜ï¼‰ | 48.76% | **3.30%** |
| w/o Independence Incentiveï¼ˆå–æ¶ˆç‹¬ç«‹æˆåŠŸå¥–åŠ±ï¼‰ | 49.34% | **4.10%** |
| w/o Exploration Rewardï¼ˆå–æ¶ˆæ¢ç´¢å¥–åŠ±ï¼‰ | **47.56%** | 0.65% |

ğŸ” **å‘ç°**ï¼š
- **æ•°æ®è¿‡æ»¤** å¯é˜²æ­¢æ— æ•ˆè°ƒç”¨ï¼ŒèŠ‚çœæˆæœ¬ï¼›
- **é¼“åŠ±ç‹¬ç«‹æ€§** æ˜¯æ§åˆ¶è¿‡åº¦ä¾èµ–çš„å…³é”®ï¼›
- **æ¢ç´¢å¥–åŠ±** æ˜¾è‘—æå‡å‡†ç¡®æ€§ï¼Œå°¤å…¶å¯¹æéš¾é¢˜ç›®è‡³å…³é‡è¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **Token-level åä½œä¼˜äº Query-level è·¯ç”±**  
   RelayLLM è¯æ˜ï¼šåªéœ€åœ¨å°‘æ•°å…³é”® token ä¸Šå¼•å…¥ LLM å¹²é¢„ï¼Œå³å¯å¤§å¹…æå‡ SLM è¡¨ç°ï¼Œå®ç°â€œå››ä¸¤æ‹¨åƒæ–¤â€ã€‚

2. âœ… **SLM å¯å­¦ä¼šæˆ˜ç•¥æ€§æ±‚åŠ©è¡Œä¸º**  
   é€šè¿‡ GRPO å’Œéš¾åº¦æ„ŸçŸ¥å¥–åŠ±è®¾è®¡ï¼ŒSLM èƒ½è‡ªä¸»åˆ¤æ–­æ˜¯å¦éœ€è¦å¸®åŠ©ï¼Œå¹¶åšå‡ºé«˜æ•ˆå†³ç­–ã€‚

3. âœ… **æ˜¾è‘—çš„æˆæœ¬-æ€§èƒ½æƒè¡¡ä¼˜åŠ¿**  
   ä»…è°ƒç”¨ **1.07%** çš„ token æ¥è‡ª LLMï¼Œå´å¸¦æ¥æ¥è¿‘å¤§æ¨¡å‹çš„æ¨ç†è¡¨ç°ï¼Œ**æˆæœ¬é™ä½ 98.2%**ã€‚

4. âœ… **å…·å¤‡è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›**  
   åœ¨æœªè§è¿‡çš„éæ•°å­¦é¢†åŸŸï¼ˆå¦‚ MMLU-Proã€BBEHï¼‰ä¹Ÿè¡¨ç°ä¼˜å¼‚ï¼Œè¯´æ˜å…¶å½¢æˆäº†é€šç”¨çš„â€œè®¤çŸ¥è¾¹ç•Œè¯†åˆ«â€èƒ½åŠ›ã€‚

5. âœ… **å­¦ç”Ÿæ¨¡å‹å†…åŒ–äº†æ¨ç†èƒ½åŠ›**  
   åœ¨â€œæ— æ•™å¸ˆâ€æµ‹è¯•ä¸­ï¼ŒRelayLLM è®­ç»ƒåçš„ SLM ä»ä¼˜äºåŸºçº¿ï¼Œè¡¨æ˜å®ƒä¸ä»…å­¦ä¼šäº†è°ƒç”¨ï¼Œè¿˜å¸æ”¶äº† LLM çš„æ¨ç†æ¨¡å¼ã€‚

6. âœ… **åŠ¨æ€é•¿åº¦é¢„æµ‹æ›´é«˜æ•ˆ**  
   ç›¸æ¯”å›ºå®šè°ƒç”¨é•¿åº¦ï¼ˆFixed-100, Fixed-500ï¼‰ï¼ŒRelayLLM åŠ¨æ€å†³å®šè°ƒç”¨é•¿åº¦ï¼Œåœ¨ä¿æŒç²¾åº¦çš„åŒæ—¶å¤§å¹…é™ä½æˆæœ¬ï¼ˆ1.07% vs 2.87%ï¼‰ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- **ä¾èµ–é«˜è´¨é‡ LLM è¾“å‡º**ï¼šè‹¥ LLM æœ¬èº«æ— æ³•è§£å†³é—®é¢˜ï¼Œåˆ™åä½œæ— æ•ˆï¼ˆå› æ­¤éœ€æ•°æ®è¿‡æ»¤ï¼‰ã€‚
- **åˆ†å¸ƒå¯¹é½æ•æ„Ÿ**ï¼šæ¢ç”¨ä¸åŒé£æ ¼çš„ LLM ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œè¯´æ˜å­˜åœ¨åˆ†å¸ƒè¿ç§»é—®é¢˜ã€‚
- **å½“å‰ä¸»è¦é€‚ç”¨äºå¯éªŒè¯ä»»åŠ¡**ï¼šå¥–åŠ±è®¾è®¡ä¾èµ–è§„åˆ™éªŒè¯å™¨ï¼ˆverifierï¼‰ï¼Œéš¾ä»¥ç›´æ¥æ‰©å±•åˆ°å¼€æ”¾ç”Ÿæˆä»»åŠ¡ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- æ‰©å±•è‡³å¤šæ¨¡æ€æˆ–å¤šæ­¥å·¥å…·è°ƒç”¨åœºæ™¯ï¼›
- æ¢ç´¢æ›´é²æ£’çš„åˆ†å¸ƒå¯¹é½æœºåˆ¶ï¼Œæ”¯æŒè·¨å®¶æ—æ¨¡å‹åä½œï¼›
- å°†è¯¥èŒƒå¼åº”ç”¨äºå…¶ä»–é«˜æ•ˆæ¨ç†æ¶æ„ï¼ˆå¦‚ speculative decodingï¼‰ï¼›
- æ„å»ºé€šç”¨çš„â€œè®¤çŸ¥åŠ©æ‰‹â€æ¥å£ï¼Œè®© SLM è‡ªä¸»è°ƒåº¦å¤šä¸ªä¸“å®¶æ¨¡å‹ã€‚

---

> ğŸ”— **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/Chengsong-Huang/RelayLLM](https://github.com/Chengsong-Huang/RelayLLM)

</details>

---

### 5. [AM$^3$Safety: Towards Data Efficient Alignment of Multi-modal Multi-turn Safety for MLLMs](https://arxiv.org/abs/2601.04736)

**Authors**: Han Zhu, Jiale Chen, Chengkun Cai, Shengjie Sun, Haoran Li, Yujin Zhou, Chi-Min Chan, Pengcheng Wen, Lei Li, Sirui Han, Yike Guo  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.04736v1  

#### Abstract
Multi-modal Large Language Models (MLLMs) are increasingly deployed in interactive applications. However, their safety vulnerabilities become pronounced in multi-turn multi-modal scenarios, where harmful intent can be gradually reconstructed across turns, and security protocols fade into oblivion as...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# AMÂ³Safety: Towards Data Efficient Alignment of Multi-modal Multi-turn Safety for MLLMs

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å®‰å…¨å¯¹é½æ–¹æ³•ä¸»è¦é’ˆå¯¹å•è½®è§†è§‰é—®ç­”ï¼ˆVQAï¼‰ä»»åŠ¡è®¾è®¡ï¼Œä¸”ä¸¥é‡ä¾èµ–æ˜‚è´µçš„äººå·¥åå¥½æ ‡æ³¨ã€‚è¿™äº›æ–¹æ³•åœ¨å¤šè½®å¤šæ¨¡æ€å¯¹è¯åœºæ™¯ä¸­æ•ˆæœæœ‰é™ï¼Œå› ä¸ºï¼š
- å¯¹è¯ä¸­çš„æœ‰å®³æ„å›¾å¯ä»¥é€šè¿‡å¤šè½®äº¤äº’é€æ­¥é‡æ„ï¼ˆgradual intent reconstructionï¼‰
- éšç€å¯¹è¯è¿›è¡Œï¼Œå®‰å…¨åè®®å®¹æ˜“è¢«é—å¿˜
- ç¼ºä¹ä¸“é—¨ç”¨äºå¤šè½®å¯¹è¯å®‰å…¨å¯¹é½çš„æ•°æ®é›†

### æå‡ºçš„æ–°æ–¹æ³•å’Œæ–°æ€è·¯
æœ¬æ–‡æå‡ºäº† **AMÂ³Safety** æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¸Šè¿°æŒ‘æˆ˜ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰InterSafe-V æ•°æ®é›†
- **æ„å»ºæ–¹å¼**ï¼šé€šè¿‡æ¨¡å‹é—´äº¤äº’ï¼ˆmodel-to-model interactionï¼‰è‡ªåŠ¨ç”Ÿæˆï¼Œæ— éœ€äººå·¥æ ‡æ³¨
- **è§„æ¨¡**ï¼šåŒ…å« 11,270 ä¸ªå¯¹è¯å’Œ 500 ä¸ªä¸“é—¨è®¾è®¡çš„æ‹’ç»å‹ VQA æ ·æœ¬
- **ç‰¹ç‚¹**ï¼š
  - å¼ºè°ƒå¯¹è¯ä¸Šä¸‹æ–‡ï¼Œå¹³å‡ 4 è½®å¯¹è¯ï¼Œæ¯è½® 1.53 å¼ å›¾åƒ
  - é€šè¿‡æ¶æ„æ„å›¾åˆ†è§£ï¼ˆHarmful Intent Decompositionï¼‰ç”Ÿæˆéšè”½çš„å¤šè½®æ”»å‡»è·¯å¾„
  - åŒ…å«å¤šä¸ªé¢†åŸŸï¼ˆå¦‚å¥åº·ã€é‡‘èï¼‰çš„ä¸“ä¸šæ‹’ç»æ ·æœ¬

#### ï¼ˆ2ï¼‰AMÂ³Safety æ¡†æ¶
ç»“åˆå†·å¯åŠ¨æ‹’ç»å­¦ä¹ ï¼ˆcold-start refusal phaseï¼‰ä¸åŸºäºç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGroup Relative Policy Optimization, GRPOï¼‰çš„å¾®è°ƒï¼Œå…·ä½“åŒ…æ‹¬ï¼š
- **å†·å¯åŠ¨é˜¶æ®µ**ï¼šä½¿ç”¨ 500 ä¸ªæ‹’ç»æ¨¡æ¿è¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œä½¿æ¨¡å‹å­¦ä¼šä»¥åˆç†ç†ç”±æ‹’ç»æœ‰å®³è¯·æ±‚
- **GRPO å¾®è°ƒé˜¶æ®µ**ï¼šå¼•å…¥**å›åˆæ„ŸçŸ¥åŒç›®æ ‡å¥–åŠ±å‡½æ•°**ï¼ˆturn-aware dual-objective rewardsï¼‰ï¼ŒåŠ¨æ€æƒè¡¡å®‰å…¨æ€§å’Œæœ‰ç”¨æ€§

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ•°æ®é«˜æ•ˆ**ï¼šå®Œå…¨é¿å…äº†æ˜‚è´µçš„äººå·¥æ ‡æ³¨æˆæœ¬
- **å¯¹è¯é€‚åº”æ€§å¼º**ï¼šä¸“ä¸ºå¤šè½®å¤šæ¨¡æ€å¯¹è¯è®¾è®¡ï¼Œèƒ½æœ‰æ•ˆåº”å¯¹æ¸è¿›å¼æ”»å‡»
- **å®‰å…¨æ€§ä¸æœ‰ç”¨æ€§å¹³è¡¡**ï¼šé€šè¿‡åŒç›®æ ‡å¥–åŠ±æœºåˆ¶ï¼Œåœ¨æå‡å®‰å…¨æ€§çš„åŒæ—¶ä¿æŒç”šè‡³å¢å¼ºæ¨¡å‹çš„æœ‰ç”¨æ€§
- **é€šç”¨æ€§å¼º**ï¼šå¯åœ¨ä¸åŒ MLLM æ¶æ„ä¸Šåº”ç”¨ï¼ˆå¦‚ Qwen2.5-VL å’Œ LLaVA-NeXTï¼‰

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | ç±»å‹ | è§„æ¨¡ | ç‰¹ç‚¹ |
|--------|------|------|------|
| **InterSafe-V** | è®­ç»ƒé›† | 11,270 å¯¹è¯ + 500 VQA | æœ¬æ–‡æå‡ºï¼Œæ¨¡å‹ç”Ÿæˆï¼Œå¤šè½®å¤šå›¾ |
| **SafeMT** | åŸºå‡†æµ‹è¯• | å¤šè½®å¤šæ¨¡æ€å¯¹è¯ | è¯„ä¼°å¤šè½®å®‰å…¨æ€§èƒ½ |
| **JailbreakV-mini** | åŸºå‡†æµ‹è¯• | å°è§„æ¨¡å­é›† | è¯„ä¼°å¯¹æŠ—æ”»å‡»é²æ£’æ€§ |
| **MM-SafetyBench** | åŸºå‡†æµ‹è¯• | å•è½® VQA | ä¼ ç»Ÿå®‰å…¨åŸºå‡† |
| **MMSafe-PO** | åŸºå‡†æµ‹è¯• | åŒ…å«éƒ¨åˆ†å¯¹è¯ | å¤šæ¨¡æ€å®‰å…¨è¯„ä¼° |

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼šQwen2.5-VL-7B-Instruct å’Œ LLaVA-NeXT-7B
- **è®­ç»ƒèµ„æº**ï¼š8Ã—H800 GPUï¼Œä»…ä½¿ç”¨ 7,000 ä¸ªå¯¹è¯è¿›è¡Œ GRPO å¾®è°ƒï¼ˆ<15 è½®ï¼‰
- **GRPO å‚æ•°**ï¼šæ¯æŒ‡ä»¤ç”Ÿæˆ 8 ä¸ª rolloutï¼Œå…¨å±€ batch size 128ï¼ŒPPO mini-batch size 8

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ | è¯´æ˜ |
|------|------|------|
| **Win Rate** | ç”± GPT-4o åˆ¤æ–­çš„èƒœç‡ | ç»¼åˆè¯„ä¼°å®‰å…¨ä¸æœ‰ç”¨æ€§ï¼Œè¶Šé«˜è¶Šå¥½ |
| **Attack Success Rate (ASR)** | è¢«åˆ¤å®šä¸ºä¸å®‰å…¨çš„å“åº”æ¯”ä¾‹ | è¡¡é‡é˜²å¾¡èƒ½åŠ›ï¼Œè¶Šä½è¶Šå¥½ |
| **Harmless Score** | æ— å®³ç»´åº¦å¾—åˆ† | è¶Šé«˜è¡¨ç¤ºè¶Šå®‰å…¨ |
| **Helpful Score** | æœ‰ç”¨ç»´åº¦å¾—åˆ† | è¶Šé«˜è¡¨ç¤ºè¶Šæœ‰å¸®åŠ© |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **RLHF-V**ï¼šåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ 
- **Safe RLHF-V**ï¼šå¹³è¡¡å®‰å…¨æ€§ä¸æœ‰ç”¨æ€§çš„ RLHF å˜ä½“
- **MM-DPO**ï¼šå¤šæ¨¡æ€ç›´æ¥åå¥½ä¼˜åŒ–
- **SPA-VL**ï¼šç»¼åˆå®‰å…¨åå¥½å¯¹é½æ•°æ®é›†

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2ï¼‰

#### åœ¨ **Qwen2.5-VL-7B** ä¸Šçš„è¡¨ç°ï¼ˆSafeMT åŸºå‡†ï¼‰ï¼š
| æ–¹æ³• | Helpful â†‘ | Harmless â†‘ | ASR â†“ |
|------|----------|-----------|-------|
| Base Model | 0.5000 | 0.5000 | 0.4892 |
| +Ours (AMÂ³Safety) | **0.6319** (+13.19%) | **0.5819** (+8.19%) | **0.2806** (-20.86%) |

#### åœ¨ **LLaVA-NeXT-7B** ä¸Šçš„è¡¨ç°ï¼ˆSafeMT åŸºå‡†ï¼‰ï¼š
| æ–¹æ³• | Helpful â†‘ | Harmless â†‘ | ASR â†“ |
|------|----------|-----------|-------|
| Base Model | 0.5000 | 0.5000 | 0.4895 |
| +Ours (AMÂ³Safety) | **0.8210** (+32.10%) | **0.6918** (+19.18%) | **0.3844** (-10.51%) |

> âœ… **ç»“è®º**ï¼šAMÂ³Safety æ˜¾è‘—æå‡äº†æ¨¡å‹çš„å®‰å…¨æ€§ï¼ˆASR ä¸‹é™ >10%ï¼‰ï¼ŒåŒæ—¶å¤§å¹…å¢å¼ºäº†æœ‰ç”¨æ€§ï¼ˆHelpful æå‡ â‰¥8%ï¼Œæœ€é«˜è¾¾ 32%ï¼‰ã€‚

### ä¸å…¶ä»–åŸºå‡†çš„å¯¹æ¯”
åœ¨ **JailbreakV** å’Œ **MM-SafetyBench** ä¸Šä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨å¤æ‚å¯¹è¯åœºæ™¯ï¼ˆå¦‚ SafeMTï¼‰ä¸­ä¼˜åŠ¿æ˜æ˜¾ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆFigure 3 & Table 4ï¼‰
- **ä»… GRPO å¾®è°ƒ**ï¼šæå‡æœ‰é™ï¼Œä»æ˜“è¢« jailbreak
- **åŠ å…¥å†·å¯åŠ¨æ‹’ç»å­¦ä¹ **ï¼šæ˜¾è‘—æå‡å®‰å…¨æ€§å’Œæœ‰ç”¨æ€§
- **ç³»æ•° Î²ï¼ˆhelpfulness æƒé‡ï¼‰çš„å½±å“**ï¼š
  - æœ€ä¼˜å€¼ä¸º **Î² = 0.1**
  - è¿‡é«˜ï¼ˆå¦‚ Î²=1 æˆ– 10ï¼‰ä¼šå¯¼è‡´å®‰å…¨æ€§ä¸‹é™
  - è¯æ˜â€œå…ˆå­¦ä¼šæ‹’ç»ï¼Œå†æä¾›å¸®åŠ©â€çš„ç­–ç•¥æ›´æœ‰æ•ˆ

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å¤šè½®å¯¹è¯å®‰å…¨æ˜¯ç‹¬ç«‹æŒ‘æˆ˜**ï¼šç°æœ‰å•è½® VQA å®‰å…¨æ–¹æ³•æ— æ³•æœ‰æ•ˆåº”å¯¹å¤šè½®æ¸è¿›å¼æ”»å‡»ã€‚
2. **å†·å¯åŠ¨æ‹’ç»è‡³å…³é‡è¦**ï¼šè®©æ¨¡å‹å…ˆå­¦ä¼šä»¥åˆç†ç†ç”±æ‹’ç»æœ‰å®³è¯·æ±‚ï¼Œæ˜¯åç»­ä¼˜åŒ–çš„åŸºç¡€ã€‚
3. **æ•°æ®æ•ˆç‡å¯è¡Œ**ï¼šé€šè¿‡æ¨¡å‹äº¤äº’ç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®ï¼Œå¯å¤§å¹…é™ä½äººå·¥æ ‡æ³¨æˆæœ¬ã€‚
4. **å®‰å…¨ä¸æœ‰ç”¨æ€§å¯å…¼å¾—**ï¼šé€šè¿‡ turn-aware åŒç›®æ ‡å¥–åŠ±ï¼Œå¯åœ¨æå‡å®‰å…¨æ€§çš„åŒæ—¶å¢å¼ºæ¨¡å‹å®ç”¨æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **æœªåœ¨ä¸“ç”¨å¯¹æŠ—æ€§ jailbreak åŸºå‡†ä¸Šæµ‹è¯•**ï¼šå®é™…å¯¹æŠ—é²æ£’æ€§å°šéœ€éªŒè¯
- **ä¾èµ–å¤–éƒ¨å¼ºæ¨¡å‹ä½œä¸º judge**ï¼šä½¿ç”¨ InternVL3-78B ä½œä¸ºå¥–åŠ±æ¨¡å‹ï¼Œå­˜åœ¨æ•™å¸ˆæ¨¡å‹åå·®é£é™©
- **æœªè¦†ç›–ä¸“ç”¨æ¨ç†æ¨¡å‹**ï¼šç›®å‰ä»…åœ¨é€šç”¨ MLLM ä¸ŠéªŒè¯ï¼Œå¯¹ä¸“ç”¨æ¨ç†æ¨¡å‹çš„å½±å“æœªçŸ¥

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢**è‡ªæˆ‘ä¿®æ­£æœºåˆ¶**ï¼ˆself-correctionï¼‰ï¼Œå‡å°‘å¯¹å¤–éƒ¨ judge çš„ä¾èµ–
- æ‰©å±•åˆ°æ›´å¤šç±»å‹çš„ MLLM æ¶æ„å’Œåº”ç”¨åœºæ™¯
- æ„å»ºæ›´å…·æŒ‘æˆ˜æ€§çš„**å¯¹æŠ—æ€§å¤šè½®å®‰å…¨åŸºå‡†**

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼šAMÂ³Safety æä¾›äº†ä¸€ç§å®ç”¨ã€é«˜æ•ˆä¸”å¯æ‰©å±•çš„å¤šæ¨¡æ€å¤šè½®å¯¹è¯å®‰å…¨å¯¹é½æ–¹æ¡ˆï¼Œä¸º MLLM åœ¨çœŸå®äº¤äº’åœºæ™¯ä¸­çš„å®‰å…¨éƒ¨ç½²æä¾›äº†é‡è¦æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 6. [Revisiting Judge Decoding from First Principles via Training-Free Distributional Divergence](https://arxiv.org/abs/2601.04766)

**Authors**: Shengyin Sun, Yiming Li, Renxi Liu, Weizhe Lin, Hui-Ling Zhen, Xianzhi Yu, Mingxuan Yuan, Chen Ma  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.04766v1  

#### Abstract
Judge Decoding accelerates LLM inference by relaxing the strict verification of Speculative Decoding, yet it typically relies on expensive and noisy supervision. In this work, we revisit this paradigm from first principles, revealing that the ``criticality'' scores learned via costly supervision are...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Revisiting Judge Decoding from First Principles via Training-Free Distributional Divergence*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿçš„ **Speculative Decoding (SD)** è™½ç„¶èƒ½åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ï¼Œä½†å…¶éªŒè¯æœºåˆ¶è¿‡äºä¸¥æ ¼ï¼Œä»…æ¥å—ä¸ç›®æ ‡æ¨¡å‹å®Œå…¨ä¸€è‡´çš„ tokenï¼Œå¯¼è‡´å¤§é‡è¯­ä¹‰ç­‰ä»·ä½†å½¢å¼ä¸åŒçš„å€™é€‰ token è¢«é”™è¯¯æ‹’ç»ï¼Œé™åˆ¶äº†åŠ é€Ÿæ½œåŠ›ã€‚

ä¸ºæ­¤æå‡ºçš„ **Judge Decoding** å¼•å…¥ä¸€ä¸ªâ€œæ³•å®˜â€åˆ†ç±»å™¨æ¥åˆ¤æ–­ draft token æ˜¯å¦â€œè¯­ä¹‰æ­£ç¡®â€ï¼Œä»è€Œæ”¾å®½éªŒè¯æ ‡å‡†ã€‚ç„¶è€Œï¼Œè¿™ç±»æ–¹æ³•ä¸¥é‡ä¾èµ–æ˜‚è´µä¸”å™ªå£°å¤§çš„ç›‘ç£ä¿¡å·ï¼ˆå¦‚äººå·¥æ ‡æ³¨æˆ–åäº‹å®ç”Ÿæˆï¼‰ï¼Œå­˜åœ¨ä»¥ä¸‹ç“¶é¢ˆï¼š
- **é«˜æˆæœ¬**ï¼šæ‰‹åŠ¨æ ‡æ³¨è€—æ—¶è´¹åŠ›ï¼Œè‡ªåŠ¨æŒ–æ˜ï¼ˆå¦‚ AutoJudgeï¼‰éœ€å¤§é‡ GPU å°æ—¶ï¼›
- **æ ‡ç­¾å™ªå£°**ï¼šç”Ÿæˆçš„éšæœºæ€§å¯¼è‡´åŒä¸€ token åœ¨ä¸åŒ rollout ä¸­è¢«æ ‡è®°ä¸ºâ€œå…³é”®â€æˆ–â€œéå…³é”®â€ï¼›
- **æ³›åŒ–å·®**ï¼šåœ¨è·¨é¢†åŸŸä»»åŠ¡ä¸­è¡¨ç°ä¸‹é™ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ ¸å¿ƒæ€æƒ³
æœ¬æ–‡ä»ç¬¬ä¸€æ€§åŸç†å‡ºå‘ï¼Œæå‡ºä¸€ä¸ªé¢ è¦†æ€§è§‚ç‚¹ï¼š  
> **â€œå…³é”®æ€§â€ï¼ˆcriticalityï¼‰ä¿¡å·æœ¬è´¨ä¸Šå·²å†…åµŒäº draft ä¸ target æ¨¡å‹ä¹‹é—´çš„åˆ†å¸ƒå·®å¼‚ä¸­ï¼Œæ— éœ€å¤–éƒ¨ç›‘ç£å³å¯æ•æ‰ã€‚**

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **ç†è®ºå‘ç°**ï¼šè¯æ˜äº†è®­ç»ƒå¾—åˆ°çš„çº¿æ€§â€œæ³•å®˜â€åˆ†ç±»å™¨ä¸ **KL æ•£åº¦** å…±äº«ç›¸åŒçš„åº•å±‚ logit åŸè¯­ï¼ˆlogit primitivesï¼‰ã€‚å…·ä½“è€Œè¨€ï¼š
   - KL æ•£åº¦æ˜¯å¯¹ logit å·®å¼‚çš„**äºŒæ¬¡èšåˆ**ï¼ˆquadratic aggregationï¼‰ï¼›
   - çº¿æ€§åˆ†ç±»å™¨æ˜¯è¿™äº›å·®å¼‚ä¸Šçš„**çº¿æ€§å†³ç­–é¢**ï¼ˆlinear partitioningï¼‰ï¼›
   - äºŒè€…æœ¬è´¨éƒ½åœ¨æ£€æµ‹ draft å’Œ target æ¨¡å‹ä¹‹é—´ç›¸å¯¹åå¥½å˜åŒ–çš„å…³é”® tokenã€‚

2. **æ–°æ–¹æ³•ï¼šTraining-Free KL Thresholding**
   - æå‡ºä¸€ç§æ— éœ€è®­ç»ƒã€åŸºäº **token-level KL divergence** çš„éªŒè¯æœºåˆ¶ã€‚
   - å½“ KL æ•£åº¦ä½äºé˜ˆå€¼æ—¶ï¼Œæ¥å— draft tokenï¼›å¦åˆ™æ‹’ç»ã€‚
   - å¼•å…¥è½»é‡çº§ç½®ä¿¡æ©ç ï¼ˆconfidence maskï¼‰ï¼šè‹¥ target æ¨¡å‹ top-1 æ¦‚ç‡ > 0.9ï¼Œåˆ™å›é€€åˆ°æ ‡å‡† SDï¼Œç¡®ä¿é«˜ç¡®å®šæ€§ä¸‹çš„ç²¾åº¦ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿ Judge Decodingï¼ˆå¦‚ AutoJudgeï¼‰ | æœ¬æ–‡æ–¹æ³•ï¼ˆKL Thresholdingï¼‰ |
|------|-------------------------------|-----------------------------|
| **è®­ç»ƒéœ€æ±‚** | éœ€è¦å¤§é‡æ ‡æ³¨/åäº‹å®æ•°æ®è®­ç»ƒåˆ†ç±»å™¨ | å®Œå…¨æ— éœ€è®­ç»ƒï¼Œçº¯ç»Ÿè®¡æ–¹æ³• |
| **è®¡ç®—å¼€é”€** | æ•°æ®æŒ–æ˜æˆæœ¬æé«˜ï¼ˆå¦‚ 2700 GPU å°æ—¶ï¼‰ | æ¨ç†æ—¶ä»…å¢åŠ å°‘é‡ KL è®¡ç®— |
| **é²æ£’æ€§** | å¯¹é¢†åŸŸåç§»æ•æ„Ÿï¼Œæ³›åŒ–èƒ½åŠ›å¼± | åˆ†å¸ƒå†…ä¿¡å·å¤©ç„¶å…·å¤‡è·¨åŸŸç¨³å®šæ€§ |
| **å¯è§£é‡Šæ€§** | é»‘ç®±åˆ†ç±»å™¨ï¼Œéš¾ä»¥åˆ†æ | åŸºäºæ¨¡å‹å†…åœ¨åˆ†å¸ƒå·®å¼‚ï¼Œç‰©ç†æ„ä¹‰æ˜ç¡® |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼Œå¤šæ­¥æ¨ç†ï¼›
- **MATH-500-Hard**ï¼šMATH æ•°æ®é›†ä¸­æœ€éš¾çš„ Level-5 é—®é¢˜ï¼›
- **LiveCodeBench**ï¼šä»£ç ç”Ÿæˆä»»åŠ¡ï¼Œå¼ºè°ƒæ‰§è¡Œæ­£ç¡®æ€§ï¼›
- **MMLU-Pro**ï¼šæ¶µç›–å¹¿æ³›å­¦ç§‘çš„çŸ¥è¯†ç†è§£åŸºå‡†ï¼Œæ›´å…·æŒ‘æˆ˜æ€§ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹å¯¹ï¼ˆModel Pairsï¼‰
- Llama-3.2-1B-Instruct / Llama-3.1-8B-Instruct
- Llama-3.1-8B-Instruct / Llama-3.1-70B-Instruct
- Qwen3-0.6B / Qwen3-8Bï¼ˆç”¨äºé•¿é“¾æ¨ç†æµ‹è¯•ï¼‰

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **MAT (Mean Accepted Tokens)** | å¹³å‡æ¯è½®æˆåŠŸæ¥å—çš„ draft token æ•°é‡ï¼Œè¡¡é‡æ•ˆç‡ |
| **Accuracy / Benchmark Score** | æœ€ç»ˆç­”æ¡ˆå‡†ç¡®ç‡æˆ–ä»»åŠ¡å¾—åˆ†ï¼Œè¡¡é‡è´¨é‡ |
| **Speedup (vs. Vanilla SP)** | ç›¸å¯¹äºæ ‡å‡† Speculative Sampling çš„ç«¯åˆ°ç«¯é€Ÿåº¦æå‡å€æ•° |
| **Speed (tokens/s)** | å®é™…ååé‡ï¼Œåœ¨ vLLM æ¡†æ¶ä¸‹æµ‹é‡ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **Vanilla SP** | åŸºå‡† | æ ‡å‡† Speculative Samplingï¼Œä¸¥æ ¼åŒ¹é… |
| **Top-K** | è§„åˆ™æ¾å¼› | åªè¦ draft token åœ¨ target çš„ top-K å†…å³æ¥å— |
| **Target/Draft Entropy** | æ— ç›‘ç£ | åŸºäºå•ä¸€æ¨¡å‹ç†µè¿›è¡Œè¿‡æ»¤ |
| **AutoJudge** | è®­ç»ƒå¼ Judge | ä½¿ç”¨åäº‹å® rollouts è‡ªåŠ¨æ ‡æ³¨å¹¶è®­ç»ƒåˆ†ç±»å™¨ |
| **KL Thresholding (Ours)** | æ— è®­ç»ƒ | æœ¬æ–‡æå‡ºçš„æ–¹æ³•ï¼ŒåŸºäº KL æ•£åº¦ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ Llama-1B/8B å’Œ 8B/70B ä¸ºä¾‹ï¼‰

#### âœ… GSM8K ä¸Šçš„è¡¨ç°ï¼ˆå›¾ 7ï¼‰
| æ–¹æ³• | MAT æå‡ï¼ˆvs Vanilla SPï¼‰ | å‡†ç¡®ç‡æŸå¤± |
|------|--------------------------|-----------|
| **KL Thresholding** | +63.5% (10.61 â†’ 17.35) | ~2% â†“ |
| **AutoJudge** | ç•¥ä½æˆ–ç›¸å½“ | ~2â€“3% â†“ |
| **Top-K / Entropy** | è¾ƒä½ | æ›´å¤§ä¸‹é™ |

> KL æ–¹æ³•åœ¨ä¿æŒé«˜å‡†ç¡®ç‡çš„åŒæ—¶æ˜¾è‘—æé«˜ååã€‚

#### âœ… LiveCodeBench ä¸Šçš„è¡¨ç°ï¼ˆå›¾ 8ï¼‰
| æ–¹æ³• | MAT æå‡ | æ‰§è¡ŒæˆåŠŸç‡ |
|------|---------|------------|
| **KL Thresholding** | +104.0% (1B/8B), +53.7% (8B/70B) | ä¿æŒç¨³å®šï¼Œç¨‹åºå¯æ‰§è¡Œ |
| **Top-K / Entropy** | æå‡æœ‰é™ | æ˜“äº§ç”Ÿè¯­æ³•é”™è¯¯æˆ–é€»è¾‘é”™è¯¯ |

> åœ¨å¯¹ç²¾ç¡®æ€§è¦æ±‚é«˜çš„ä»£ç ç”Ÿæˆä¸­ï¼ŒKL æ–¹æ³•ä»ä¼˜äºå…¶ä»–æ— ç›‘ç£ç­–ç•¥ã€‚

#### âœ… MATH-500-Hard å’Œ MMLU-Proï¼ˆè·¨åŸŸæµ‹è¯•ï¼Œå›¾ 9â€“10ï¼‰
- **AutoJudgeï¼ˆåœ¨ GSM8K ä¸Šè®­ç»ƒï¼‰**ï¼šé¢å¯¹é¢†åŸŸè¿ç§»æ—¶æ€§èƒ½æ€¥å‰§ä¸‹é™ï¼Œæ¥è¿‘ Top-K è¡¨ç°ï¼›
- **KL Thresholding**ï¼šä¾ç„¶ç¨³å¥ï¼ŒMAT æå‡è¶…è¿‡ 100%ï¼Œå‡†ç¡®ç‡ä»…è½»å¾®ä¸‹é™ï¼ˆ<1.5%ï¼‰ï¼›
- ç»“è®ºï¼š**æ— è®­ç»ƒæ–¹æ³•å…·æœ‰æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›**ã€‚

#### âœ… ç«¯åˆ°ç«¯çœŸå®éƒ¨ç½²é€Ÿåº¦ï¼ˆè¡¨ 1ï¼ŒvLLM æµ‹è¯•ï¼‰
| æ–¹æ³• | Speedup (1B/8B) | Speedup (8B/70B) | å‡†ç¡®ç‡ç»´æŒ |
|------|------------------|-------------------|-------------|
| **AutoJudge** | 1.40Ã— | 1.45Ã— | ä¸‹é™ 2â€“4% |
| **KL Thresholding** | **1.60Ã—** | **1.45Ã—** | ä¸‹é™ä»… 1â€“2% |

> KL æ–¹æ³•ä¸ä»…åŒ¹é…ç”šè‡³ç•¥å¾®è¶…è¶Š AutoJudge çš„åŠ é€Ÿæ•ˆæœï¼Œä¸”ç²¾åº¦æ›´é«˜ã€‚

#### âœ… é•¿é“¾æ¨ç†åœºæ™¯ï¼ˆQwen3-0.6B/8Bï¼Œå›¾ 11ï¼‰
- KL æ–¹æ³•å®ç° **2.77Ã— MAT æå‡**ï¼ˆ6.91 â†’ 19.15ï¼‰ï¼Œä»…æŸå¤± ~2% å‡†ç¡®ç‡ï¼›
- è¡¨æ˜è¯¥æ–¹æ³•ç‰¹åˆ«é€‚åˆå¤æ‚æ¨ç†è·¯å¾„ä¸­çš„é¢‘ç¹åˆ†æ­§å¤„ç†ã€‚

---

### ğŸ” æ¶ˆèå®éªŒä¸åˆ†æ
- **KL ä¸ AutoJudge å¾—åˆ†é«˜åº¦ç›¸å…³**ï¼ˆå›¾ 6ï¼‰ï¼šKL æ•£åº¦éš AutoJudge æ‰“åˆ†å‡é«˜è€Œå•è°ƒä¸Šå‡ï¼Œè¯´æ˜ä¸¤è€…æ•è·çš„æ˜¯ç›¸åŒä¿¡å·ï¼›
- **Entropy ä¸ç›¸å…³**ï¼štarget/draft æ¨¡å‹ç†µä¸ criticality æ— æ˜æ˜¾å…³ç³»ï¼›
- **ç†è®ºæ”¯æŒ**ï¼šå®šç† 4.1 è¯æ˜ KL ä¸çº¿æ€§åˆ†ç±»å™¨å…±äº«ç›¸åŒçš„ logit å·®å¼‚åŸè¯­ï¼ˆÎ”(x)ï¼‰ï¼Œè§£é‡Šäº†ä¸ºä½•ç®€å•ç»Ÿè®¡é‡å¯æ›¿ä»£å¤æ‚è®­ç»ƒã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **â€œå…³é”®æ€§â€æ˜¯æ¨¡å‹å†…åœ¨å±æ€§**ï¼š  
   draft ä¸ target æ¨¡å‹é—´çš„ **distributional divergence**ï¼ˆå°¤å…¶æ˜¯ KL æ•£åº¦ï¼‰æœ¬èº«å°±ç¼–ç äº†å“ªäº› token æ˜¯é€»è¾‘è½¬æŠ˜ç‚¹ï¼Œæ— éœ€å¤–éƒ¨ç›‘ç£å­¦ä¹ ã€‚

2. **è®­ç»ƒä¸æ˜¯å¿…éœ€çš„**ï¼š  
   å¤æ‚çš„ç›‘ç£å¼ Judgeï¼ˆå¦‚ AutoJudgeï¼‰æœ¬è´¨ä¸Šæ˜¯åœ¨æ‹Ÿåˆ KL æ•£åº¦æ‰€åæ˜ çš„ç»Ÿè®¡æ¨¡å¼ï¼Œå› æ­¤å¯ä»¥ç›´æ¥ç”¨ KL ä½œä¸ºä»£ç†ä¿¡å·ã€‚

3. **æ— è®­ç»ƒæ–¹æ³•æ›´é²æ£’ã€æ›´é«˜æ•ˆ**ï¼š  
   - é¿å…äº†æ•°æ®æŒ–æ˜çš„å·¨å¤§å¼€é”€ï¼›
   - å¯¹é¢†åŸŸåç§»ä¸æ•æ„Ÿï¼›
   - åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¾¾åˆ°æˆ–è¶…è¿‡è®­ç»ƒå¼æ–¹æ³•çš„æ€§èƒ½ã€‚

4. **ç†è®ºç»Ÿä¸€è§†è§’**ï¼š  
   KL æ•£åº¦ï¼ˆäºŒæ¬¡ï¼‰ä¸çº¿æ€§åˆ†ç±»å™¨ï¼ˆä¸€æ¬¡ï¼‰è™½ç„¶å‡ ä½•å½¢å¼ä¸åŒï¼Œä½†ä½œç”¨äºç›¸åŒçš„ logit å·®å¼‚ç©ºé—´ï¼Œæ„æˆäº†å¯¹â€œé€»è¾‘åå·®â€çš„åŒé‡åˆ»ç”»ã€‚

---

### âš ï¸ å±€é™æ€§
1. **æœªåœ¨è¶…å¤§è§„æ¨¡æ¨¡å‹ä¸ŠéªŒè¯**ï¼š  
   å¦‚ Llama-3.1-405B-Instruct ç­‰ï¼Œå°šä¸æ¸…æ¥šæ˜¯å¦ä»å…·å¯æ‰©å±•æ€§ã€‚

2. **KL è®¡ç®—å¸¦æ¥é¢å¤–å¼€é”€**ï¼š  
   å½“å‰å®ç°æœªä¼˜åŒ–ï¼ˆå¦‚ Triton kernel èåˆï¼‰ï¼Œå¯èƒ½æˆä¸ºç°ä»£æ¨ç†æ¡†æ¶ï¼ˆå¦‚ vLLMï¼‰çš„ç“¶é¢ˆã€‚

3. **å‡è®¾ draft-target å·®å¼‚å°**ï¼š  
   ç†è®ºæ¨å¯¼åŸºäºæ³°å‹’å±•å¼€ï¼Œé€‚ç”¨äºå±€éƒ¨å¾®å°åç§»ï¼Œæç«¯åˆ†æ­§æƒ…å†µéœ€è¿›ä¸€æ­¥ç ”ç©¶ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å¼€å‘é«˜æ•ˆçš„ **operator fusion å®ç°**ï¼Œé™ä½ KL è®¡ç®—å»¶è¿Ÿï¼›
- æ¢ç´¢å…¶ä»–åˆ†å¸ƒå·®å¼‚åº¦é‡ï¼ˆå¦‚ JS æ•£åº¦ã€Wasserstein è·ç¦»ï¼‰æ˜¯å¦æ›´ä¼˜ï¼›
- å°†è¯¥æ€æƒ³æ¨å¹¿è‡³ **Medusa/EAGLE ç­‰æ¶æ„æ”¹è¿›å‹ speculative decoding**ï¼›
- ç»“åˆ retrieval æˆ– cache æœºåˆ¶ï¼Œæ„å»ºå®Œå…¨æ— ç›‘ç£çš„é«˜æ•ˆæ¨ç†æµæ°´çº¿ã€‚

---

## æ€»ç»“
> æœ¬æ–‡ä»æ ¹æœ¬ä¸Šé‡æ–°å®¡è§†äº† Judge Decoding çš„è®¾è®¡èŒƒå¼ï¼Œæ­ç¤ºäº†â€œcriticalityâ€ä¿¡å·çš„æœ¬è´¨æ¥æºï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç®€å•ã€æœ‰æ•ˆã€æ— éœ€è®­ç»ƒçš„æ›¿ä»£æ–¹æ¡ˆ â€”â€” **åŸºäº KL æ•£åº¦çš„åˆ†å¸ƒå·®å¼‚æ£€æµ‹**ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§æ–¹æ³•ä¸ä»…èƒ½åª²ç¾ç”šè‡³è¶…è¶Šå¤æ‚çš„è®­ç»ƒå¼ Judgeï¼Œåœ¨æ•ˆç‡ã€é²æ£’æ€§å’Œæ³›åŒ–æ€§æ–¹é¢æ›´å…·ä¼˜åŠ¿ï¼Œä¸ºæœªæ¥é«˜æ•ˆ LLM æ¨ç†æä¾›äº†ä¸€æ¡ç®€æ´è€Œå¼ºå¤§çš„æ–°è·¯å¾„ã€‚

</details>

---

### 7. [Approximate equivariance via projection-based regularisation](https://arxiv.org/abs/2601.05028)

**Authors**: Torben Berndt, Jan St\"uhmer  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.05028v1  

#### Abstract
Equivariance is a powerful inductive bias in neural networks, improving generalisation and physical consistency. Recently, however, non-equivariant models have regained attention, due to their better runtime performance and imperfect symmetries that might arise in real-world applications. This has m...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šApproximate Equivariance via Projection-Based Regularisation**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œ**Equivariance**ï¼ˆç­‰å˜æ€§ï¼‰æ˜¯ä¸€ç§å¼ºå¤§çš„å½’çº³åç½®ï¼Œèƒ½æå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œç‰©ç†ä¸€è‡´æ€§ã€‚ç„¶è€Œï¼Œä¸¥æ ¼ç­‰å˜çš„æ¨¡å‹å¾€å¾€è®¡ç®—å¼€é”€å¤§ã€çµæ´»æ€§å·®ï¼Œä¸”ç°å®ä¸–ç•Œçš„æ•°æ®å¸¸å­˜åœ¨å¯¹ç§°æ€§ç ´åï¼ˆå¦‚å™ªå£°ã€éç†æƒ³å‡ ä½•ï¼‰ã€‚å› æ­¤ï¼Œç ”ç©¶è€…è½¬å‘â€œè¿‘ä¼¼ç­‰å˜â€ï¼ˆapproximate equivarianceï¼‰æ¨¡å‹ã€‚

ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–**åŸºäºæ ·æœ¬çš„æ­£åˆ™åŒ–**ï¼ˆsample-based regularisersï¼‰ï¼Œå³é€šè¿‡æ•°æ®å¢å¼ºï¼ˆdata augmentationï¼‰åœ¨è®­ç»ƒæ—¶éšæœºé‡‡æ ·ç¾¤å…ƒç´ å¹¶æ–½åŠ ç­‰å˜çº¦æŸã€‚è¿™ç±»æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **é«˜æ ·æœ¬å¤æ‚åº¦**ï¼ˆhigh sample complexityï¼‰ï¼Œå°¤å…¶å¯¹äºè¿ç»­ç¾¤ï¼ˆå¦‚SO(3)ï¼‰ï¼›
- éœ€è¦é¢å¤–å‰å‘ä¼ æ’­ï¼Œå¢åŠ è®­ç»ƒæ—¶é—´å’Œå†…å­˜ï¼›
- æ­£åˆ™åŒ–æ•ˆæœä¸ç¨³å®šï¼ˆæœ‰ä¼°è®¡æ–¹å·®ï¼‰ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•**
æœ¬æ–‡æå‡ºä¸€ç§å…¨æ–°çš„**åŸºäºæŠ•å½±çš„ç­‰å˜æ­£åˆ™åŒ–**ï¼ˆprojection-based equivariance regularisationï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åˆ©ç”¨çº¿æ€§å±‚åœ¨ç¾¤è¡¨ç¤ºä¸‹çš„**æ­£äº¤åˆ†è§£**ï¼ˆorthogonal decompositionï¼‰ï¼Œå°†æƒé‡çŸ©é˜µåˆ†è§£ä¸º**ç­‰å˜åˆ†é‡**ï¼ˆequivariant componentï¼‰å’Œ**éç­‰å˜åˆ†é‡**ï¼ˆnon-equivariant componentï¼‰ï¼›
- åœ¨è®­ç»ƒç›®æ ‡ä¸­ç›´æ¥æƒ©ç½šéç­‰å˜åˆ†é‡çš„èŒƒæ•°ï¼Œå³æœ€å°åŒ– `||T - P(T)||`ï¼Œå…¶ä¸­ `P(T)` æ˜¯ `T` åœ¨ç­‰å˜å­ç©ºé—´ä¸Šçš„æŠ•å½±ã€‚

è¯¥æ–¹æ³•çš„å…³é”®åˆ›æ–°åœ¨äºï¼š
- **æ“ä½œå±‚é¢æ­£åˆ™åŒ–**ï¼ˆoperator-level regularisationï¼‰ï¼šä¸æ˜¯é€ç‚¹ã€é€æ ·æœ¬åœ°æƒ©ç½šç­‰å˜è¯¯å·®ï¼Œè€Œæ˜¯ä»ç®—å­æ•´ä½“ä¸ŠæŠ‘åˆ¶éç­‰å˜æ€§ï¼›
- **æ— éœ€æ•°æ®å¢å¼º**ï¼šä¸ä¾èµ–äºé‡‡æ ·ç¾¤å…ƒç´ æˆ–è¾“å…¥æ ·æœ¬ï¼Œé¿å…äº†é¢å¤–è®¡ç®—å¼€é”€ï¼›
- **ç†è®ºå¯è§£é‡Šæ€§å¼º**ï¼šè¯æ˜äº† `||T - P(T)||` ä¸ç­‰å˜ç¼ºé™·ï¼ˆequivariance defectï¼‰åœ¨æ•°é‡çº§ä¸Šç­‰ä»·ï¼ˆç›¸å·®ä¸è¶…è¿‡2å€ï¼‰ï¼›
- **é«˜æ•ˆå®ç°**ï¼šåœ¨å‚…é‡Œå¶åŸŸä¸­å¯é€šè¿‡**æ©ç +å¹³å‡**ï¼ˆmasking and averagingï¼‰é«˜æ•ˆè®¡ç®—æŠ•å½±ï¼Œé€‚ç”¨äºè¿ç»­ç¾¤ï¼ˆå¦‚SO(n)ï¼‰ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | æœ¬æ–‡æ–¹æ³•ï¼ˆProjection-basedï¼‰ | ç°æœ‰æ–¹æ³•ï¼ˆSample-basedï¼‰ |
|------|-------------------------------|--------------------------|
| **è®¡ç®—æ•ˆç‡** | ä»…éœ€ä¸€æ¬¡FFT/IFFTï¼Œæˆæœ¬çº¿æ€§äºå‚æ•°é‡ | éœ€å¤šæ¬¡å‰å‘ä¼ æ’­ï¼Œæˆæœ¬æ­£æ¯”äºæ ·æœ¬æ•°Ã—ç¾¤é‡‡æ ·æ•° |
| **ç¨³å®šæ€§** | æ— ä¼°è®¡æ–¹å·®ï¼Œæ­£åˆ™é¡¹ç¡®å®š | æœ‰æ–¹å·®ï¼Œä¾èµ–éšæœºé‡‡æ · |
| **é€‚ç”¨æ€§** | æ”¯æŒè¿ç»­ç¾¤ï¼ˆå¦‚SO(2), SO(3)ï¼‰ | å¯¹è¿ç»­ç¾¤é‡‡æ ·å›°éš¾ï¼Œæ•ˆç‡ä½ |
| **ç¡¬ä»¶åˆ©ç”¨ç‡** | å¯ä½¿ç”¨å¤§batchè®­ç»ƒ | å—é™äºæ˜¾å­˜ï¼Œbatch sizeå° |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
1. **åˆæˆæ•°æ®é›†**ï¼š
   - **SO(2)ä¸å˜åˆ†ç±»ä»»åŠ¡**ï¼šäºŒç»´å¹³é¢ä¸Šä¸¤ä¸ªåŒå¿ƒç¯çŠ¶ç‚¹äº‘ï¼Œæ ‡ç­¾åˆ†åˆ«ä¸º+1/-1ï¼Œæµ‹è¯•æ¨¡å‹å­¦ä¹ æ—‹è½¬ä¸å˜æ€§çš„èƒ½åŠ›ã€‚
   - **çƒŸé›¾åŠ¨åŠ›å­¦é¢„æµ‹**ï¼ˆsmoke advection-diffusionï¼‰ï¼šä½¿ç”¨PhiFlowç”Ÿæˆ64Ã—64çƒŸé›¾æ‰©æ•£åºåˆ—ï¼Œäººä¸ºå¼•å…¥å¯¹ç§°æ€§ç ´åï¼ˆå¦‚éå‡åŒ€æµ®åŠ›ã€ä¸åŒæ—¶é—´æ­¥é•¿ï¼‰ï¼Œæµ‹è¯•æ¨¡å‹åœ¨**è¿‘ä¼¼å¯¹ç§°åŠ¨æ€ç³»ç»Ÿ**ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚

2. **çœŸå®åŒ»å­¦å›¾åƒæ•°æ®é›†**ï¼š
   - **AAPM CT-MAR Grand Challenge**ï¼š14,000å¼ å¸¦é‡‘å±ä¼ªå½±çš„å¤´éƒ¨å’Œèº«ä½“CTåˆ‡ç‰‡ï¼Œç”¨äº**é‡‘å±ä¼ªå½±å»é™¤**ï¼ˆMetal Artifact Reduction, MARï¼‰ä»»åŠ¡ï¼Œæµ‹è¯•C4ï¼ˆ90Â°æ—‹è½¬ï¼‰è¿‘ä¼¼ç­‰å˜æ€§ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **é‡å»ºè´¨é‡**ï¼šPSNRï¼ˆå³°å€¼ä¿¡å™ªæ¯”ï¼‰ã€SSIMï¼ˆç»“æ„ç›¸ä¼¼æ€§ï¼‰
  - **ç­‰å˜æ€§åº¦é‡**ï¼šç»éªŒç­‰å˜ç¼ºé™· `E_emp(T)`
  - **æ•ˆç‡æŒ‡æ ‡**ï¼šè®­ç»ƒååé‡ï¼ˆsamples/GPU-sï¼‰ã€epochè€—æ—¶ã€æ˜¾å­˜å ç”¨
- **è®­ç»ƒè®¾ç½®**ï¼š
  - ä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡è°ƒåº¦ï¼›
  - å¯¹æ¯”å›ºå®šbatchï¼ˆ4ï¼‰å’Œæœ€å¤§å¯è¡Œbatchï¼ˆ12ï¼‰ä¸‹çš„æ€§èƒ½ï¼›
  - è¶…å‚æ•°é€šè¿‡ç½‘æ ¼æœç´¢è°ƒä¼˜ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | ç±»å‹ |
|------|------|
| **Conv** | æ™®é€šCNN |
| **Equiv** | ä¸¥æ ¼ç­‰å˜CNNï¼ˆå¦‚Steerable CNNï¼‰ |
| **RPP** (Finzi et al., 2021) | æ®‹å·®è·¯å¾„å…ˆéªŒï¼ˆResidual Pathway Priorsï¼‰ |
| **CLNN** | æ˜¾å¼ç­‰å˜æŸå¤±ï¼ˆpointwise equivariance penaltyï¼‰ |
| **Bai et al. (2025)** | æ ·æœ¬åŸºæ­£åˆ™åŒ–ï¼ˆsample-based regulariserï¼‰ |
| **Train-then-project** | è®­ç»ƒåæŠ•å½±åˆ°ç­‰å˜å­ç©ºé—´ |
| **RGroup / RSteer** (Wang et al., 2022c) | æ”¾æ¾çš„ç¾¤å·ç§¯ç½‘ç»œ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **(1) CT-MAR é‡‘å±ä¼ªå½±å»é™¤ä»»åŠ¡ï¼ˆè¡¨2ï¼‰**
| æ–¹æ³• | PSNR | SSIM | è®­ç»ƒååé‡ (batch=12) | Epochæ—¶é—´ (s) |
|------|------|------|------------------------|---------------|
| ACDNet (baseline) | 42.08 | 0.9559 | 4.90 | 1108 |
| + sample-based (Bai et al.) | 40.02 | 0.9623 | 2.54 | 2011 |
| **+ projection-based (ours)** | **42.68** | **0.9620** | **4.25** | **1202** |

- **PSNRæå‡**ï¼šç›¸æ¯”åŸºçº¿æå‡0.6dBï¼Œä¼˜äºæ ·æœ¬åŸºæ–¹æ³•ï¼ˆ+2.66dB vs +0.6dBï¼‰ï¼›
- **ååé‡ä¼˜åŠ¿**ï¼šåœ¨max-feasibleè®¾ç½®ä¸‹ï¼Œååé‡æ¯”æ ·æœ¬åŸºæ–¹æ³•é«˜**54â€“61%**ï¼›
- **è®­ç»ƒé€Ÿåº¦**ï¼šå°½ç®¡epochæ—¶é—´ç•¥é•¿ï¼Œä½†å› æ”¯æŒæ›´å¤§batchï¼Œå®é™…è®­ç»ƒæ›´é«˜æ•ˆã€‚

#### **(2) çƒŸé›¾åŠ¨åŠ›å­¦é¢„æµ‹ï¼ˆè¡¨1ï¼‰**
åœ¨Rotationå’ŒScalingè®¾å®šä¸‹ï¼ŒåŠ å…¥æœ¬æ–‡æ­£åˆ™åŒ–çš„RGroupå’ŒRSteerå‡æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼š
- **Rotation-Future**ï¼šMSEä»1.10é™è‡³**0.58**ï¼ˆRSteer+Regï¼‰ï¼›
- **Scaling-Domain**ï¼šMSEä»0.95é™è‡³**0.69**ï¼›
- è¡¨æ˜è¯¥æ–¹æ³•åœ¨**éƒ¨åˆ†å¯¹ç§°ç³»ç»Ÿ**ä¸­èƒ½æœ‰æ•ˆä¿ç•™æœ‰ç”¨å¯¹ç§°æ€§ï¼ŒåŒæ—¶é€‚åº”å¯¹ç§°æ€§ç ´åã€‚

#### **(3) SO(2)ä¸å˜æ€§æ§åˆ¶å®éªŒï¼ˆå›¾3, å›¾7ï¼‰**
- é€šè¿‡è°ƒèŠ‚è¶…å‚æ•° `Î»_G` å’Œ `Î»_âŠ¥`ï¼Œå¯**è¿ç»­æ§åˆ¶æ¨¡å‹çš„ç­‰å˜ç¨‹åº¦**ï¼›
- å½“ `Î»_âŠ¥` å¢å¤§æ—¶ï¼Œå†³ç­–è¾¹ç•Œè¶‹äºåœ†å½¢ï¼Œç»éªŒç­‰å˜ç¼ºé™· `E(T)` ä» `3e+1` é™è‡³ `1e-2`ï¼›
- éªŒè¯äº†æ­£åˆ™åŒ–é¡¹èƒ½æœ‰æ•ˆå¼•å¯¼æ¨¡å‹å‘ç­‰å˜æ–¹å‘æ”¶æ•›ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
#### **(1) æ­£åˆ™åŒ–å¼ºåº¦æ•æ„Ÿæ€§åˆ†æï¼ˆå›¾8, å›¾9ï¼‰**
- å›ºå®š `Î»_âŠ¥` æ—¶ï¼Œæ”¹å˜ `Î»_G` å¯¹æ€§èƒ½å½±å“è¾ƒå°ï¼›
- å¢å¤§ `Î»_âŠ¥` æ˜¾è‘—é™ä½ç­‰å˜ç¼ºé™·ï¼Œæå‡åˆ†ç±»å‡†ç¡®ç‡ï¼ˆå¦‚MNISTä¸Šä»0.975å‡è‡³0.984ï¼‰ï¼›
- è¡¨æ˜ `Î»_âŠ¥` æ˜¯æ§åˆ¶ç­‰å˜æ€§çš„ä¸»è¦è¶…å‚æ•°ã€‚

#### **(2) èŒƒæ•°é€‰æ‹©çš„å½±å“ï¼ˆè¡¨5ï¼‰**
æ¯”è¾ƒä¸åŒçŸ©é˜µèŒƒæ•°ï¼ˆspectral, Frobenius, infinity, (p,q)-normsï¼‰ï¼š
- **FrobeniusèŒƒæ•°**è¡¨ç°æœ€ä½³ï¼ŒPSNRè¾¾38.48ï¼ŒSSIM 0.9457ï¼›
- **SpectralèŒƒæ•°**æ…¢10â€“15%ï¼Œä½†æ€§èƒ½æœªæå‡ï¼›
- **InfinityèŒƒæ•°**å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼ˆPSNR 35.61ï¼‰ï¼Œè¯´æ˜è¿‡äºå¼ºè°ƒæå€¼ä¼šæ¬ æ‹Ÿåˆï¼›
- ç»“è®ºï¼šé‡‡ç”¨**FrobeniusèŒƒæ•°**ä½œä¸ºé»˜è®¤é€‰æ‹©ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **æŠ•å½±åŸºæ­£åˆ™åŒ–ä¼˜äºæ ·æœ¬åŸºæ–¹æ³•**ï¼š
   - åœ¨å¤šä¸ªä»»åŠ¡ï¼ˆåˆ†ç±»ã€åŠ¨åŠ›å­¦é¢„æµ‹ã€å›¾åƒé‡å»ºï¼‰ä¸Šå‡å–å¾—æ›´å¥½æˆ–ç›¸å½“çš„æ€§èƒ½ï¼›
   - æ˜¾è‘—æå‡è®­ç»ƒæ•ˆç‡ï¼Œæ”¯æŒæ›´å¤§batch sizeï¼Œæ›´é€‚åˆå¤§è§„æ¨¡è®­ç»ƒã€‚

2. **ç­‰å˜æ€§å¯è¢«è¿ç»­è°ƒèŠ‚**ï¼š
   - é€šè¿‡è¶…å‚æ•° `Î»_âŠ¥` å¯çµæ´»æ§åˆ¶æ¨¡å‹çš„ç­‰å˜ç¨‹åº¦ï¼Œå®ç°â€œè½¯çº¦æŸâ€ï¼›
   - åœ¨å¯¹ç§°æ€§éƒ¨åˆ†å­˜åœ¨çš„åœºæ™¯ä¸­ï¼Œæ¨¡å‹èƒ½è‡ªåŠ¨å¹³è¡¡â€œä¿æŒå¯¹ç§°â€ä¸â€œæ‹Ÿåˆæ•°æ®â€ã€‚

3. **å‚…é‡Œå¶åŸŸå®ç°é«˜æ•ˆé€šç”¨**ï¼š
   - å¯¹äºè¿ç»­ç¾¤ï¼ˆå¦‚SO(2)ï¼‰ï¼Œå¯åœ¨é¢‘åŸŸé€šè¿‡**æ©ç +å¹³å‡**é«˜æ•ˆå®ç°æŠ•å½±ï¼›
   - ç‰¹åˆ«é€‚åˆå·²å‚æ•°åŒ–åœ¨ä¸å¯çº¦è¡¨ç¤ºå—ä¸­çš„æ¨¡å‹ï¼ˆå¦‚steerable CNNsï¼‰ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **éœ€é’ˆå¯¹æ¶æ„å’Œç¾¤æ¨å¯¼æŠ•å½±å½¢å¼**ï¼šæ¯ç§ç¾¤å’Œç½‘ç»œç»“æ„éœ€é‡æ–°è®¾è®¡æŠ•å½±ç®—å­ï¼›
- **å½“å‰å®éªŒé›†ä¸­åœ¨ç®€å•ç¾¤**ï¼šå¦‚C4ã€SO(2)ï¼Œå°šæœªéªŒè¯å¤æ‚æç¾¤ï¼ˆå¦‚SE(3)ï¼‰ä¸Šçš„æ•ˆæœï¼›
- **ç†è®ºå‡è®¾è¾ƒå¼º**ï¼šè¦æ±‚è¡¨ç¤ºä¸ºé…‰è¡¨ç¤ºï¼ˆunitary representationsï¼‰ï¼ŒæŸäº›éç´§ç¾¤ä¸é€‚ç”¨ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•åˆ°æ›´å¤æ‚çš„ç¾¤ç»“æ„ï¼ˆå¦‚SE(3)ã€product of subgroupsï¼‰ï¼›
- æ¢ç´¢è‡ªé€‚åº”è°ƒæ•´ `Î»_âŠ¥` çš„æœºåˆ¶ï¼Œæ ¹æ®æ•°æ®è‡ªåŠ¨å­¦ä¹ å¯¹ç§°æ€§ç¨‹åº¦ï¼›
- å°†è¯¥æ¡†æ¶åº”ç”¨äºææ–™ç§‘å­¦ã€åˆ†å­åŠ¨åŠ›å­¦ç­‰éœ€è¦å¤„ç†å¤šå°ºåº¦å¯¹ç§°æ€§çš„é¢†åŸŸã€‚

---

> **æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºçš„**æŠ•å½±åŸºç­‰å˜æ­£åˆ™åŒ–**æä¾›äº†ä¸€ç§ç†è®ºä¸Šä¸¥è°¨ã€è®¡ç®—é«˜æ•ˆçš„è¿‘ä¼¼ç­‰å˜å­¦ä¹ æ¡†æ¶ï¼Œå…‹æœäº†ä¼ ç»Ÿæ ·æœ¬åŸºæ–¹æ³•çš„æ•ˆç‡ç“¶é¢ˆï¼Œåœ¨çœŸå®å’Œåˆæˆä»»åŠ¡ä¸Šå‡å±•ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½ä¸å¯æ‰©å±•æ€§ï¼Œä¸ºç­‰å˜æ·±åº¦å­¦ä¹ çš„å®é™…åº”ç”¨å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚

</details>

---

### 8. [LLMs for Explainable Business Decision-Making: A Reinforcement Learning Fine-Tuning Approach](https://arxiv.org/abs/2601.04208)

**Authors**: Xiang Cheng, Wen Wang, Anindya Ghose  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.04208v1  

#### Abstract
Artificial Intelligence (AI) models increasingly drive high-stakes consumer interactions, yet their decision logic often remains opaque. Prevailing explainable AI techniques rely on post hoc numerical feature attributions, which fail to provide coherent narratives behind model decisions. Large langu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLLMs for Explainable Business Decision-Making: A Reinforcement Learning Fine-Tuning Approach

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹é«˜é£é™©å•†ä¸šå†³ç­–ï¼ˆå¦‚è´·æ¬¾å®¡æ‰¹ï¼‰ä¸­äººå·¥æ™ºèƒ½æ¨¡å‹ç¼ºä¹å¯è§£é‡Šæ€§çš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºå½“å‰ä¸»æµçš„ **post hoc explainable AI** æŠ€æœ¯ï¼ˆå¦‚ SHAPã€LIMEï¼‰å­˜åœ¨ä¸‰å¤§ç¼ºé™·ï¼š

1. **è§£é‡Šä¸å¿ å®ï¼ˆUnfaithfulï¼‰**ï¼šæ•°å€¼å‹ç‰¹å¾å½’å› æ˜¯äº‹åè¿‘ä¼¼ï¼Œæ— æ³•åæ˜ çœŸå®å†³ç­–é€»è¾‘ï¼Œå¯èƒ½å¯¼è‡´â€œçœ‹ä¼¼åˆç†ä½†é”™è¯¯â€çš„è§£é‡Šã€‚
2. **å¤šå—ä¼—æ²Ÿé€šå›°éš¾**ï¼šåŒä¸€å†³ç­–éœ€é¢å‘ä¸“å®¶ï¼ˆå¦‚è´·æ¬¾å®¡æ ¸å‘˜ï¼‰å’Œæ¶ˆè´¹è€…æä¾›ä¸åŒé£æ ¼çš„è§£é‡Šï¼Œè€Œä¼ ç»Ÿæ–¹æ³•éš¾ä»¥åœ¨ä¿æŒå†³ç­–ä¸€è‡´æ€§çš„åŒæ—¶è°ƒæ•´è¡¨è¾¾æ–¹å¼ã€‚
3. **æ ‡æ³¨æˆæœ¬é«˜æ˜‚**ï¼šä¾èµ–äººå·¥æ’°å†™é«˜è´¨é‡è§£é‡Šè¿›è¡Œç›‘ç£è®­ç»ƒï¼ˆsupervised fine-tuningï¼‰æˆæœ¬æé«˜ï¼Œéš¾ä»¥è§„æ¨¡åŒ–ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **LEXMA**ï¼ˆLLM-based EXplanations for Multi-Audience decisionsï¼‰ï¼Œä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ çš„ä¸¤é˜¶æ®µå¾®è°ƒæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **ä¸‰é˜¶æ®µç”Ÿæˆæ¶æ„ï¼ˆReasoning â†’ Explanation â†’ Predictionï¼‰**  
  å¼ºåˆ¶æ¨¡å‹å…ˆç”Ÿæˆå†…éƒ¨æ¨ç†é“¾ï¼ˆReasoningï¼‰ï¼Œå†æç‚¼ä¸ºç®€æ´è§£é‡Šï¼ˆExplanationï¼‰ï¼Œæœ€ååšå‡ºé¢„æµ‹ï¼ˆPredictionï¼‰ã€‚ç”±äºå†³ç­–ä¾èµ–äºè§£é‡Šï¼Œå› æ­¤ä¼˜åŒ–å†³ç­–å‡†ç¡®ç‡ä¼šåå‘æ¿€åŠ±æ¨¡å‹ç”Ÿæˆæ›´å¿ å®äºå†³ç­–è¿‡ç¨‹çš„è§£é‡Šã€‚

- **åŒé€‚é…å™¨æ¶æ„ï¼ˆDual Adaptersï¼‰**  
  - **ACC Adapter**ï¼ˆCorrectness Adapterï¼‰ï¼šè´Ÿè´£æ•æ‰å†³ç­–è¾¹ç•Œå’Œé£é™©å› ç´ ï¼Œç”¨äºæ‰€æœ‰åœºæ™¯ã€‚
  - **TONE Adapter**ï¼ˆTone Adapterï¼‰ï¼šä»…ç”¨äºæ¶ˆè´¹è€…ç«¯ï¼Œè°ƒæ•´è¯­æ°”ã€å¯è¯»æ€§å’Œç¤¼è²Œç¨‹åº¦ã€‚  
  åœ¨æ¨ç†æ—¶ï¼Œä¸“å®¶è§£é‡Šä»…æ¿€æ´» ACCï¼Œæ¶ˆè´¹è€…è§£é‡Šåˆ™åŒæ—¶æ¿€æ´» ACC + TONEï¼Œä»è€Œå®ç°â€œåŒä¸€å†³ç­–è§„åˆ™ï¼Œå¤šç§è¡¨è¾¾é£æ ¼â€ã€‚

- **æ ‡ç­¾é«˜æ•ˆè®­ç»ƒï¼ˆLabel-Efficient Trainingï¼‰**  
  ç»“åˆï¼š
  - **Reflection-augmented SFT**ï¼šä½¿ç”¨å¼ºå‚è€ƒæ¨¡å‹ï¼ˆGPT-5ï¼‰è‡ªåŠ¨ç”Ÿæˆå¸¦åæ€ä¿®æ­£çš„è®­ç»ƒæ ·æœ¬ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚
  - **Group Relative Policy Optimization (GRPO)**ï¼šä¸€ç§æ— éœ€å­¦ä¹ å¥–åŠ±æ¨¡å‹ï¼ˆlearned reward modelï¼‰çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œé€šè¿‡ç»„å†…æ¯”è¾ƒè®¡ç®—ä¼˜åŠ¿å‡½æ•°ï¼Œä½¿ç”¨ç®€å•è§„åˆ™å®šä¹‰çš„å¥–åŠ±ä¿¡å·ï¼ˆå¦‚å†³ç­–æ­£ç¡®æ€§ã€Flesch-Kincaid å¯è¯»æ€§ã€ç¤¼è²Œè¯å¯†åº¦ï¼‰è¿›è¡Œä¼˜åŒ–ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ SHAPï¼‰ | é€šç”¨ LLMï¼ˆå¦‚ raw Qwen/GPT-5ï¼‰ | LEXMA |
|------|---------------------|-------------------------------|--------|
| è§£é‡Šå½¢å¼ | æ•°å€¼å½’å›  | è‡ªç„¶è¯­è¨€ä½†å¯èƒ½ä¸å¿ å® | å¿ å®ä¸”å™äº‹æ€§å¼ºçš„è‡ªç„¶è¯­è¨€ |
| å¤šå—ä¼—æ”¯æŒ | ä¸æ”¯æŒ | æ”¹å˜ prompt å¯èƒ½æ”¹å˜å†³ç­– | åŒä¸€å†³ç­–ï¼Œå¤šé£æ ¼è¾“å‡º |
| è®­ç»ƒæˆæœ¬ | éœ€è¦å¤§é‡äººå·¥æ ‡æ³¨è§£é‡Š | é«˜æ˜‚ï¼ˆè‹¥ç”¨ SFTï¼‰ | ä½ï¼ˆæ— éœ€äººç±»è¯„åˆ†è§£é‡Šï¼‰ |
| å†³ç­–-è§£é‡Šè€¦åˆ | å¼±ï¼ˆpost hocï¼‰ | å¼±ï¼ˆå¯èƒ½å¹»è§‰ï¼‰ | å¼ºï¼ˆè§£é‡Šé©±åŠ¨å†³ç­–ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **HMDA Loan Application Register**ï¼ˆHome Mortgage Disclosure Actï¼‰
  - æ¥æºï¼šç¾å›½æ¶ˆè´¹è€…é‡‘èä¿æŠ¤å±€ï¼ˆCFPBï¼‰å…¬å¼€æ•°æ®åº“
  - æ•°æ®é‡ï¼šè¶…è¿‡ä¸€ç™¾ä¸‡æ¡è´·æ¬¾ç”³è¯·è®°å½•ï¼ˆä½¿ç”¨å…¶ä¸­ä¸€å°éƒ¨åˆ†è¿›è¡Œå¾®è°ƒï¼‰
  - ç‰¹å¾ï¼šç»“æ„åŒ–å­—æ®µï¼ˆä¿¡ç”¨è¯„åˆ†ã€LTVã€DTIã€æ”¶å…¥ç­‰ï¼‰+ åŒ¿åäººå£ç»Ÿè®¡ä¿¡æ¯
  - æ ‡ç­¾ï¼š`Approve` æˆ– `Deny`
  - é¢„å¤„ç†ï¼šæ’é™¤å—ä¿æŠ¤å±æ€§ï¼ˆç§æ—ã€æ€§åˆ«ç­‰ï¼‰ï¼Œæ„å»ºç±»åˆ«å¹³è¡¡å­é›†ï¼ˆ50% æ‰¹å‡† / 50% æ‹’ç»ï¼‰

### **å®éªŒè®¾ç½®**

- **åŸºç¡€æ¨¡å‹**ï¼šQwen3-4Bï¼ˆå¼€æºå¤§æ¨¡å‹ï¼‰
- **å¾®è°ƒç­–ç•¥**ï¼šParameter-Efficient Fine-Tuning (PEFT) + LoRA
- **è®­ç»ƒæµç¨‹ä¸‰é˜¶æ®µ**ï¼š
  1. **SFTï¼ˆSupervised Fine-Tuningï¼‰**ï¼šä½¿ç”¨ GPT-5 ç”Ÿæˆå¸¦åæ€ä¿®æ­£çš„ç›®æ ‡å“åº”ï¼Œè®­ç»ƒæ¨¡å‹éµå¾ªä¸‰é˜¶æ®µæ ¼å¼ã€‚
  2. **GRPO-Step1**ï¼šåœ¨ ACC Adapter ä¸Šä¼˜åŒ–å†³ç­–å‡†ç¡®æ€§ï¼Œäº¤æ›¿ä½¿ç”¨ä¸“å®¶å’Œæ¶ˆè´¹è€… promptã€‚
  3. **GRPO-Step2**ï¼šåœ¨ TONE Adapter ä¸Šä¼˜åŒ–æ¶ˆè´¹è€…è§£é‡Šçš„å¯è¯»æ€§å’Œç¤¼è²Œæ€§ï¼Œå†»ç»“ ACC Adapterã€‚

- **è¯„ä¼°æŒ‡æ ‡**
  - **å†³ç­–æ­£ç¡®æ€§**ï¼šF1 Scoreã€Accuracyã€Precisionã€Recall
  - **ä¸“å®¶è§£é‡Šè´¨é‡**ï¼šäººå·¥è¯„ä¼°ï¼ˆ3 åèµ„æ·±è´·æ¬¾ä¸“å‘˜ï¼‰â€”â€”é£é™©ç›¸å…³æ€§ï¼ˆrisk relevanceï¼‰ã€å†³ç­–é€‚å½“æ€§ï¼ˆappropriatenessï¼‰ã€å¯è§£é‡Šæ€§ï¼ˆexplainabilityï¼‰
  - **æ¶ˆè´¹è€…è§£é‡Šè´¨é‡**ï¼šäººå·¥è¯„ä¼°ï¼ˆ110 å Prolific ç”¨æˆ·ï¼‰â€”â€”æ¸…æ™°åº¦ã€ç¤¼è²Œæ€§ã€å…¬å¹³æ€§ã€å¯æ“ä½œæ€§ã€åˆç†æ€§ã€å¯ä¿¡åº¦ã€æ»¡æ„åº¦ï¼ˆå‡ä¸º 1â€“5 åˆ† Likert é‡è¡¨ï¼‰
  - **é£æ ¼é‡åŒ–æŒ‡æ ‡**ï¼š
    - å¯è¯»æ€§ï¼šFlesch-Kincaid Grade Levelï¼ˆç›®æ ‡ â‰¤ 8 å¹´çº§ï¼‰
    - ç¤¼è²Œæ€§ï¼šStanford Politeness Strategy å¯†åº¦ï¼ˆç»ç¼©æ”¾è‡³ [0,1]ï¼‰

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **æœºå™¨å­¦ä¹ æ¨¡å‹**ï¼š
  - XGBoostã€Neural Networkã€Logistic Regressionã€Gradient Boosting
- **LLM åŸºçº¿**ï¼š
  - Raw Qwen3-4Bï¼ˆé›¶æ ·æœ¬ï¼‰
  - GPT-5ï¼ˆä¸­ç­‰æ¨ç†å¼ºåº¦ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… å†³ç­–æ­£ç¡®æ€§ï¼ˆF1 Scoreï¼‰

| æ¨¡å‹ | ä¸“å®¶æç¤ºï¼ˆExpert Promptï¼‰ | æ¶ˆè´¹è€…æç¤ºï¼ˆConsumer Promptï¼‰ |
|------|----------------------------|-------------------------------|
| XGBoost | 0.917 | 0.917 |
| Raw Qwen3-4B | 0.723 | 0.726 |
| GPT-5 | 0.730 | 0.771 |
| **LEXMA (GRPO-Step1/2)** | **0.897** | **0.893** |

> **ç»“è®º**ï¼šLEXMA æ˜¾è‘—ä¼˜äºåŸå§‹ LLM å’Œ GPT-5ï¼Œæ¥è¿‘ XGBoost æ€§èƒ½ï¼ŒåŒæ—¶è¿˜èƒ½ç”Ÿæˆè‡ªç„¶è¯­è¨€è§£é‡Šã€‚

#### âœ… ä¸“å®¶è§£é‡Šè´¨é‡ï¼ˆäººå·¥è¯„ä¼°ï¼Œn=30ï¼‰

| æŒ‡æ ‡ | Raw Qwen å¹³å‡åˆ† | LEXMA å¹³å‡åˆ† | å·®å¼‚ | p-value |
|------|------------------|---------------|------|---------|
| é£é™©ç›¸å…³æ€§ï¼ˆRisk Relevanceï¼‰ | 3.4 | 4.4 | +1.0 | <0.05 |
| å†³ç­–é€‚å½“æ€§ï¼ˆDecision Appropriatenessï¼‰ | 2.2 | 3.9 | +1.7 | <0.01 |
| å¯è§£é‡Šæ€§ï¼ˆExplainabilityï¼‰ | 2.4 | 3.6 | +1.2 | <0.01 |

> **ç»“è®º**ï¼šä¸“å®¶æ˜æ˜¾åå¥½ LEXMA çš„è§£é‡Šï¼Œè®¤ä¸ºå…¶æ›´èšç„¦å…³é”®é£é™©ã€ç†ç”±å……åˆ†ã€æ˜“äºç†è§£ã€‚

#### âœ… æ¶ˆè´¹è€…è§£é‡Šè´¨é‡ï¼ˆäººå·¥è¯„ä¼°ï¼Œn=536ï¼‰

| æŒ‡æ ‡ | Raw Qwen å¹³å‡åˆ† | LEXMA å¹³å‡åˆ† | å·®å¼‚ | p-value |
|------|------------------|---------------|------|---------|
| æ¸…æ™°åº¦ï¼ˆClarityï¼‰ | 3.835 | 4.212 | +0.377 | <0.001 |
| ç¤¼è²Œæ€§ï¼ˆPolitenessï¼‰ | 4.124 | 4.586 | +0.462 | <0.001 |
| å…¬å¹³æ€§ï¼ˆFairnessï¼‰ | 4.180 | 4.551 | +0.371 | <0.001 |
| å¯æ“ä½œæ€§ï¼ˆActionabilityï¼‰ | 3.444 | 4.052 | +0.608 | <0.001 |
| åˆç†æ€§ï¼ˆReasonablenessï¼‰ | 3.764 | 4.216 | +0.452 | <0.001 |
| å¯ä¿¡åº¦ï¼ˆTrustworthinessï¼‰ | 3.742 | 4.139 | +0.397 | <0.001 |
| æ»¡æ„åº¦ï¼ˆSatisfactionï¼‰ | 3.692 | 4.447 | +0.755 | <0.001 |

> **ç»“è®º**ï¼šæ¶ˆè´¹è€…æ˜¾è‘—æ›´å–œæ¬¢ LEXMA çš„è§£é‡Šï¼Œåœ¨æ‰€æœ‰ç»´åº¦ä¸Šå‡æœ‰æå‡ï¼Œå°¤å…¶æ˜¯å¯æ“ä½œæ€§å’Œæ»¡æ„åº¦ã€‚

#### âœ… é£æ ¼æ§åˆ¶æ•ˆæœï¼ˆé‡åŒ–ï¼‰

| æ¨¡å‹ | å¯è¯»æ€§å‡å€¼ï¼ˆGradeï¼‰ | ç¤¼è²Œæ€§å¯†åº¦å‡å€¼ |
|------|----------------------|----------------|
| Raw Qwen | 6.866 | 0.223 |
| GRPO-Step1ï¼ˆä»…ä¼˜åŒ–å†³ç­–ï¼‰ | 9.374 â†‘ | 0.169 â†“ |
| **GRPO-Step2ï¼ˆ+ ä¼˜åŒ–è¯­æ°”ï¼‰** | **5.952 â†“** | **0.223 â†‘** |

> **ç»“è®º**ï¼šå•çº¯ä¼˜åŒ–å†³ç­–ä¼šæŸå®³æ¶ˆè´¹è€…è§£é‡Šçš„å¯è¯»æ€§å’Œç¤¼è²Œæ€§ï¼›ç¬¬äºŒé˜¶æ®µ GRPO æˆåŠŸå°†ä¸¤è€…æ¢å¤å¹¶ä¼˜åŒ–è‡³ç†æƒ³æ°´å¹³ã€‚

### **æ¶ˆèå®éªŒç»“æœ**

ä»ä»¥ä¸‹å››ä¸ªæ£€æŸ¥ç‚¹è§‚å¯Ÿæ€§èƒ½æ¼”è¿›ï¼š

| æ£€æŸ¥ç‚¹ | ä¸“å®¶ F1 | æ¶ˆè´¹è€… F1 |
|--------|---------|-----------|
| Raw Qwen | 0.723 | 0.726 |
| SFT | 0.825 | 0.793 |
| GRPO-Step1 | 0.897 | 0.893 |
| GRPO-Step2 | 0.902 | 0.893 |

> **ç»“è®º**ï¼š
> - SFT æ˜¾è‘—æå‡åŸºç¡€æ€§èƒ½ï¼›
> - GRPO-Step1 è¿›ä¸€æ­¥å¤§å¹…æå‡ F1ï¼›
> - GRPO-Step2 åœ¨å‡ ä¹ä¸æ”¹å˜å†³ç­–æ€§èƒ½çš„å‰æä¸‹ï¼ŒæˆåŠŸä¼˜åŒ–äº†è§£é‡Šé£æ ¼ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **å†³ç­–ä¸è§£é‡Šå¯ä»¥ååŒä¼˜åŒ–**ï¼šé€šè¿‡å°†è§£é‡Šç½®äºå†³ç­–ä¹‹å‰ï¼ˆExplanation â†’ Predictionï¼‰ï¼Œå¼ºåŒ–å­¦ä¹ çš„å¥–åŠ±ä¿¡å·å¯åå‘ä¼ æ’­è‡³è§£é‡Šç”Ÿæˆè¿‡ç¨‹ï¼Œè¿«ä½¿æ¨¡å‹ç”ŸæˆçœŸæ­£å½±å“å†³ç­–çš„å¿ å®è§£é‡Šã€‚
2. **æ¨¡å—åŒ–é€‚é…å™¨æœ‰æ•ˆåˆ†ç¦»åŠŸèƒ½**ï¼šACC Adapter æ§åˆ¶å†³ç­–é€»è¾‘ï¼ŒTONE Adapter è°ƒæ•´è¡¨è¾¾é£æ ¼ï¼ŒäºŒè€…è§£è€¦ä½¿å¾—å¯ä»¥åœ¨ä¸å½±å“å†³ç­–çš„æƒ…å†µä¸‹ä¼˜åŒ–ç”¨æˆ·ä½“éªŒã€‚
3. **æ— éœ€äººå·¥æ ‡æ³¨å³å¯æå‡è§£é‡Šè´¨é‡**ï¼šåˆ©ç”¨ GRPO + è§„åˆ™åŒ–å¥–åŠ±ï¼ˆå¦‚å¯è¯»æ€§å…¬å¼ã€ç¤¼è²Œè¯åŒ¹é…ï¼‰ï¼Œå¯åœ¨æ— ä»»ä½•äººç±»è¯„åˆ†è§£é‡Šçš„æƒ…å†µä¸‹å®Œæˆé«˜è´¨é‡å¾®è°ƒï¼Œæå…·å®ç”¨ä»·å€¼ã€‚
4. **LEXMA åœ¨çœŸå®è´·æ¬¾å®¡æ‰¹ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚**ï¼šä¸ä»…å†³ç­–å‡†ç¡®ç‡æ¥è¿‘ XGBoostï¼Œä¸”ç”Ÿæˆçš„è§£é‡Šåœ¨ä¸“å®¶å’Œæ¶ˆè´¹è€…çœ¼ä¸­å‡æ˜¾è‘—ä¼˜äºåŸå§‹ LLMã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

1. **æ•°æ®é™åˆ¶**ï¼šä½¿ç”¨çš„æ˜¯å…¬å¼€ HMDA æ•°æ®é›†ï¼Œç¼ºå°‘è¯¦ç»†çš„ä¿¡ç”¨å†å²å’Œè¿˜æ¬¾è¡Œä¸ºæ•°æ®ï¼Œå¯èƒ½å½±å“æ¨¡å‹ä¸Šé™ã€‚
2. **è¯„ä¼°è§„æ¨¡æœ‰é™**ï¼š
   - ä¸“å®¶è¯„ä¼°ä»…ç”± 3 äººå®Œæˆï¼ˆè™½ç»éªŒä¸°å¯Œï¼‰ï¼›
   - æ¶ˆè´¹è€…è¯„ä¼°ä¸ºçº¿ä¸Šé—®å·ï¼ŒéçœŸå®å†³ç­–åœºæ™¯ã€‚
3. **æ³›åŒ–èƒ½åŠ›å¾…éªŒè¯**ï¼šç›®å‰ä»…åœ¨è´·æ¬¾å®¡æ‰¹åœºæ™¯éªŒè¯ï¼Œå…¶ä»–é¢†åŸŸï¼ˆå¦‚ä¿é™©ã€è¥é”€æ¨èï¼‰éœ€è¿›ä¸€æ­¥æµ‹è¯•ã€‚
4. **å¿ å®æ€§ä»ä¾èµ–é—´æ¥æœºåˆ¶**ï¼šè™½ç„¶è®¾è®¡ä¸Šé¼“åŠ±å¿ å®è§£é‡Šï¼Œä½†ä»ç¼ºä¹ç›´æ¥æµ‹é‡â€œè§£é‡Šæ˜¯å¦çœŸå®åæ˜ å†³ç­–è¿‡ç¨‹â€çš„æ‰‹æ®µã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **å¢å¼ºè§£é‡Šå¿ å®æ€§éªŒè¯æœºåˆ¶**ï¼šå¼•å…¥ probing methods æˆ– causal mediation analysis æ¥é‡åŒ–è§£é‡Šä¸å†³ç­–ä¹‹é—´çš„å› æœå…³ç³»ã€‚
2. **æ‰©å±•å¤šå—ä¼—æ”¯æŒ**ï¼šæ”¯æŒæ›´å¤šè§’è‰²ï¼ˆå¦‚ç›‘ç®¡æœºæ„ã€é«˜ç®¡ï¼‰çš„å®šåˆ¶åŒ–è§£é‡Šã€‚
3. **ç»“åˆå°è§„æ¨¡äººå·¥åé¦ˆ**ï¼šåœ¨é¢„ç®—å…è®¸ä¸‹ï¼ŒåŠ å…¥å°‘é‡é«˜è´¨é‡äººç±»åé¦ˆä»¥è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚
4. **åº”ç”¨äºå…¶ä»–é«˜é£é™©å†³ç­–åœºæ™¯**ï¼šå¦‚åŒ»ç–—è¯Šæ–­è¾…åŠ©ã€æ‹›è˜ç­›é€‰ã€åŠ¨æ€å®šä»·ç­‰éœ€è¦é€æ˜æ€§å’Œåˆè§„æ€§çš„é¢†åŸŸã€‚
5. **æ¢ç´¢æ›´å¤æ‚çš„ tone reward design**ï¼šå¦‚å“ç‰Œè¯­è°ƒã€æ³•å¾‹åˆè§„æ€§æ£€æµ‹ç­‰ã€‚

---

> **æ€»ç»“**ï¼šLEXMA æå‡ºäº†ä¸€ç§**ç³»ç»ŸåŒ–ã€ä½æˆæœ¬ã€å¯æ‰©å±•**çš„ LLM å¾®è°ƒæ¡†æ¶ï¼Œé¦–æ¬¡å®ç°äº†åœ¨ä¿æŒå†³ç­–é«˜æ€§èƒ½çš„åŒæ—¶ï¼Œç”Ÿæˆ**å¿ å®ã€å¤šé£æ ¼ã€è‡ªç„¶è¯­è¨€è§£é‡Š**çš„ç›®æ ‡ï¼Œä¸ºæ„å»ºé€æ˜ã€å¯ä¿¡çš„å•†ä¸š AI ç³»ç»Ÿæä¾›äº†é‡è¦è·¯å¾„ã€‚

</details>

---

### 9. [Prior-Informed Zeroth-Order Optimization with Adaptive Direction Alignment for Memory-Efficient LLM Fine-Tuning](https://arxiv.org/abs/2601.04710)

**Authors**: Feihu Jin, Shipeng Cen, Ying Tan  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.04710v1  

#### Abstract
Fine-tuning large language models (LLMs) has achieved remarkable success across various NLP tasks, but the substantial memory overhead during backpropagation remains a critical bottleneck, especially as model scales grow. Zeroth-order (ZO) optimization alleviates this issue by estimating gradients t...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**Prior-Informed Zeroth-Order Optimization with Adaptive Direction Alignment for Memory-Efficient LLM Fine-Tuning**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å…¨å‚æ•°å¾®è°ƒï¼ˆfull fine-tuningï¼‰æ—¶é¢ä¸´ä¸¥é‡çš„**å†…å­˜ç“¶é¢ˆ**ï¼Œå°¤å…¶æ˜¯åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­éœ€è¦å­˜å‚¨å¤§é‡ä¸­é—´æ¿€æ´»å’Œæ¢¯åº¦ã€‚å°½ç®¡å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•ï¼ˆå¦‚ LoRAã€Prefix Tuningï¼‰ç¼“è§£äº†éƒ¨åˆ†é—®é¢˜ï¼Œä½†å…¶å†…å­˜å¼€é”€ä»æ˜¾è‘—é«˜äºæ¨ç†é˜¶æ®µã€‚

Zeroth-Order (ZO) ä¼˜åŒ–é€šè¿‡ä»…ä½¿ç”¨å‰å‘ä¼ æ’­å’Œé«˜æ–¯é‡‡æ ·ä¼°è®¡æ¢¯åº¦ï¼Œé¿å…äº†åå‘ä¼ æ’­ï¼Œä»è€Œå¤§å¹…é™ä½å†…å­˜å ç”¨ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿ ZO æ–¹æ³•ï¼ˆå¦‚ MeZOï¼‰ä¾èµ–**éšæœºé«˜æ–¯æ‰°åŠ¨**ï¼Œå¯¼è‡´æ¢¯åº¦ä¼°è®¡æ–¹å·®å¤§ã€æ”¶æ•›æ…¢ã€æ€§èƒ½ä¸ç¨³å®šã€‚

### âœ… æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºä¸¤ç§åŸºäºâ€œå…ˆéªŒä¿¡æ¯â€çš„é›¶é˜¶ä¼˜åŒ–ç­–ç•¥ï¼Œç»Ÿç§°ä¸º **Guiding Vector-Augmented Zeroth-Order (GV-ZO)** æ¡†æ¶ï¼š

1. **MeZO-GVï¼ˆGuiding Vectorï¼‰**  
   - åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œé€šè¿‡å¤šæ¬¡éšæœºæ‰°åŠ¨ï¼ˆMæ¬¡ï¼‰è¯„ä¼°æŸå¤±ï¼Œé€‰å‡ºè¡¨ç°æœ€å¥½çš„â€œç²¾è‹±â€æ‰°åŠ¨ç»„å’Œæœ€å·®çš„â€œéç²¾è‹±â€ç»„ã€‚
   - æ„é€ ä¸€ä¸ª**å¼•å¯¼å‘é‡ï¼ˆguiding vectorï¼‰** $ v = \sum_{\text{top}} z_i - \sum_{\text{bottom}} z_i $ï¼Œè¯¥å‘é‡éšå«äº†å½“å‰æŸå¤±æ›²é¢çš„æœ‰åˆ©æ›´æ–°æ–¹å‘ã€‚
   - ä½¿ç”¨è¯¥å‘é‡è¿›è¡Œå®šå‘æ‰°åŠ¨ï¼Œä¼°è®¡æ¢¯åº¦ï¼š  
     $$
     \nabla L(\theta; B) \approx \frac{L(\theta + \epsilon v; B) - L(\theta - \epsilon v; B)}{2\epsilon} \cdot v
     $$

2. **MeZO-Greedyï¼ˆGreedy Perturbationï¼‰**  
   - åŒæ ·ç”Ÿæˆ M ä¸ªå€™é€‰æ‰°åŠ¨ï¼Œé€‰æ‹©ä½¿æŸå¤±æœ€å°çš„é‚£ä¸ªæ–¹å‘ $ z^* $ã€‚
   - ä½¿ç”¨ $ z^* $ è¿›è¡Œå¯¹ç§°å·®åˆ†ä¼°è®¡ï¼Œä½œä¸ºæ¢¯åº¦æ–¹å‘ã€‚

è¿™ä¸¤ç§æ–¹æ³•éƒ½å±äº**æ’ä»¶å¼ï¼ˆplug-and-playï¼‰è®¾è®¡**ï¼Œå¯æ— ç¼é›†æˆåˆ° MeZO æˆ– SubZero ç­‰ç°æœ‰ ZO æ¡†æ¶ä¸­ã€‚

### âœ… ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ”¶æ•›é€Ÿåº¦** | æ˜¾è‘—åŠ å¿«ï¼Œå¯åœ¨æ›´å°‘è®­ç»ƒæ­¥æ•°ä¸‹è¾¾åˆ°ç”šè‡³è¶…è¶ŠåŸºçº¿æ€§èƒ½ï¼ˆå¦‚ 10k æ­¥è¶…è¶Š 20k æ­¥çš„ MeZOï¼‰ã€‚ |
| **æ€§èƒ½è¡¨ç°** | åœ¨å¤šä¸ªä»»åŠ¡ä¸Šä¼˜äºä¼ ç»Ÿ ZO æ–¹æ³•ï¼Œå¹¶åœ¨å¤šæ•°ä»»åŠ¡ä¸Šè¶…è¿‡æ¢¯åº¦æ³•ï¼ˆAdamï¼‰åŸºçº¿ã€‚ |
| **å†…å­˜æ•ˆç‡** | ä¿æŒ ZO çš„ä½å†…å­˜ç‰¹æ€§ï¼Œæ— éœ€å­˜å‚¨æ¿€æ´»å€¼ï¼Œé€‚åˆèµ„æºå—é™ç¯å¢ƒã€‚ |
| **ç†è®ºæ”¯æŒ** | è¯æ˜æ‰€ææ–¹æ³•èƒ½å®ç°æ›´å¼ºçš„**æ¢¯åº¦æ–¹å‘å¯¹é½ï¼ˆdirectional alignmentï¼‰**ï¼Œæå‡å•æ­¥ä¸‹é™æ•ˆæœã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåŸºäº **SuperGLUE** åŸºå‡†ä¸­çš„å¤šä¸ªä»»åŠ¡ï¼Œæ¶µç›–ä¸‰ç±»ä»»åŠ¡ï¼š
- **åˆ†ç±»ä»»åŠ¡ï¼ˆClassificationï¼‰**: SST-2, RTE, CB, BoolQ, WSC, WIC
- **å¤šé¡¹é€‰æ‹©ä»»åŠ¡ï¼ˆMultiple Choiceï¼‰**: COPA, ReCoRD
- **é—®ç­”ä»»åŠ¡ï¼ˆQAï¼‰**: SQuAD, DROP

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹è§„æ¨¡**ï¼šè¦†ç›–ä»å°åˆ°å¤§çš„å¤šç§ LLMï¼š
  - OPT ç³»åˆ—ï¼šOPT-1.3B, OPT-13B, OPT-30B
  - Llama2 ç³»åˆ—ï¼šLlama2-7B-hf, Llama2-13B-hf
- **å¾®è°ƒæ–¹å¼**ï¼šæµ‹è¯•ä¸‰ç§ä¸»æµæ–¹æ¡ˆï¼š
  - Full Tuning (FT)
  - LoRA
  - Prefix Tuning
- **è¶…å‚æ•°é…ç½®**ï¼š
  - æ‰¹å¤§å°ï¼ˆbatch sizeï¼‰ï¼šç»Ÿä¸€ä¸º 16
  - å­¦ä¹ ç‡ï¼šæ ¹æ®æ¨¡å‹å’Œä»»åŠ¡è°ƒæ•´ï¼ˆè§ Table IIIï¼‰
  - å¼•å¯¼å‘é‡é‡‡æ ·æ¬¡æ•° $ M $ï¼šè®¾ä¸º 2 æˆ– 4
  - æ¯è½®æ¢¯åº¦ä¼°è®¡çš„æŸ¥è¯¢é¢„ç®—ï¼ˆquery budgetï¼‰ï¼š99ï¼ˆå³æ¯æ­¥æœ€å¤š M+2 æ¬¡å‰å‘ï¼‰
- **ç¡¬ä»¶å¹³å°**ï¼šNvidia A100 (80GB) æˆ– 3090 (24GB)

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦æŒ‡æ ‡ï¼š**å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰** æˆ– F1 åˆ†æ•°ï¼ˆå¦‚ SQuADï¼‰
- è¾…åŠ©åˆ†ææŒ‡æ ‡ï¼š
  - æ”¶æ•›é€Ÿåº¦ï¼ˆwall-clock time / training stepsï¼‰
  - å†…å­˜å ç”¨ï¼ˆGPU memory usageï¼‰
  - æ–¹å‘å¯¹é½åº¦ï¼ˆcosine similarity between estimated and true gradientï¼‰
  - å•æ­¥ä¸‹é™å¹…åº¦åˆ†æ

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | å¯¹æ¯”æ–¹æ³• |
|------|----------|
| **Zero-Shot & ICL** | Zero-shot, In-Context Learning |
| **Gradient-Based** | Adam-based full fine-tuning (FT) |
| **ZO Baselines** | MeZO, SubZero |
| **Advanced ZO** | ZO-AdaMU, HiZOO |
| **å…¶ä»–å˜ä½“** | n-SPSA (multi-query SPSA) |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### âœ… åœ¨ OPT-13B ä¸Šçš„è¡¨ç°ï¼ˆTable Vï¼‰
- **æ‰€æœ‰ 11 é¡¹ä»»åŠ¡ä¸­ï¼ŒGV-based æ–¹æ³•å‡ä¼˜äºä¼ ç»Ÿ ZO æ–¹æ³•**
- **åœ¨ 9/11 ä»»åŠ¡ä¸Šè¶…è¶Šæ¢¯åº¦æ³•ï¼ˆAdamï¼‰åŸºçº¿**
- å…·ä½“äº®ç‚¹ï¼š
  - **SST-2 (FT)**: SubZero-GV è¾¾åˆ° **94.7%**ï¼Œè¶…è¿‡ MeZO(FT) çš„ 91.4%
  - **CB (Prefix)**: SubZero-GV(Prefix) è¾¾åˆ° **85.7%**ï¼Œé¢†å…ˆ ZO-AdaMU(Prefix) é«˜è¾¾ **13.4%**
  - **SQuAD (LoRA)**: SubZero-GV(LoRA) è¾¾åˆ° **85.3%**ï¼Œä¼˜äº MeZO(LoRA) çš„ 83.8%
  - **DROP (LoRA)**: MeZO-GV(LoRA) è¾¾åˆ° **32.7%**ï¼Œæå‡æ˜æ˜¾

#### âœ… åœ¨ Llama2-7B å’Œ Llama2-13B ä¸Šçš„ç»“æœï¼ˆTables VI & VIIï¼‰
- **MeZO-GV-10kï¼ˆä»… 10k æ­¥ï¼‰åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¶…è¶Š MeZO-20kï¼ˆ20k æ­¥ï¼‰**
  - å¦‚ Llama2-7B ä¸Š SST-2ï¼š**90.4% vs 88.7%**
  - Llama2-13B ä¸Š SST-2ï¼š**93.7% vs 94.3%**ï¼ˆæ¥è¿‘ä¸”èŠ‚çœä¸€åŠæ—¶é—´ï¼‰
- è¡¨æ˜ GV æ–¹æ³•æ˜¾è‘—åŠ é€Ÿæ”¶æ•›

#### âœ… åœ¨ OPT-30B ä¸Šçš„ç»“æœï¼ˆTable VIIIï¼‰
- MeZO-GV(prefix) åœ¨ SST-2 ä¸Šè¾¾åˆ° **91.4%**ï¼Œä¼˜äº MeZO(prefix) çš„ 87.5% å’Œ SubZero(prefix) çš„ 89.3%
- æ˜¾ç¤ºæ–¹æ³•å…·æœ‰è‰¯å¥½çš„**å¯æ‰©å±•æ€§**ï¼Œé€‚ç”¨äºè¶…å¤§è§„æ¨¡æ¨¡å‹

### ğŸ“Š ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| å¯¹æ¯”ç»´åº¦ | ç»“æœ |
|--------|------|
| **vs MeZO / SubZero** | GV å˜ä½“åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šä¸€è‡´èƒœå‡ºï¼Œå¹³å‡æå‡ 2â€“5% |
| **vs Adam (FT)** | åœ¨ 9/11 ä»»åŠ¡ä¸Šæ›´ä¼˜ï¼Œå°¤å…¶åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ï¼ˆå¦‚ WSC, MultiRCï¼‰ä¸­è¡¨ç°çªå‡º |
| **vs ZO-AdaMU / HiZOO** | æ€§èƒ½å…¨é¢é¢†å…ˆï¼Œä¸”æ— éœ€é¢å¤–å†…å­˜å¼€é”€ï¼ˆHiZOO éœ€ Hessian ä¼°è®¡ï¼‰ |
| **vs n-SPSA** | åœ¨ç›¸åŒæŸ¥è¯¢æ¬¡æ•°ä¸‹ï¼ŒMeZO-GV æ”¶æ•›æ›´å¿«ã€ç²¾åº¦æ›´é«˜ã€è®­ç»ƒæ—¶é—´æ›´çŸ­ï¼ˆTable Xï¼‰ |

### ğŸ” æ¶ˆèå®éªŒä¸åˆ†æ
- **æ–¹å‘å¯¹é½åˆ†æï¼ˆFigure 6ï¼‰**ï¼š
  - MeZO-GV çš„ä¼°è®¡æ¢¯åº¦ä¸çœŸå®æ¢¯åº¦ï¼ˆvia SGDï¼‰ä¹‹é—´çš„ **cosine similarity æ›´é«˜**ï¼ŒéªŒè¯äº†â€œæ–¹å‘å¯¹é½å¢å¼ºâ€çš„å‡è®¾ã€‚
- **å•æ­¥ä¸‹é™åˆ†æï¼ˆFigure 3ï¼‰**ï¼š
  - GV æ–¹æ³•æ¯ä¸€æ­¥çš„æŸå¤±ä¸‹é™æ›´å¿«ï¼Œè¯´æ˜å…¶æ¢¯åº¦ä¼°è®¡æ›´æœ‰æ•ˆã€‚
- **ä¸åŒè¯„ä¼°æ¬¡æ•°çš„å½±å“ï¼ˆFigure 5ï¼‰**ï¼š
  - å¤šæ•°ä»»åŠ¡å¯¹è¯„ä¼°æ¬¡æ•°ä¸æ•æ„Ÿï¼Œä½† WIC ç­‰ä»»åŠ¡éš $ M $ å¢åŠ è€ŒæŒç»­æå‡ï¼Œå»ºè®®æ ¹æ®ä»»åŠ¡åŠ¨æ€è°ƒæ•´ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å…ˆéªŒå¼•å¯¼æ‰°åŠ¨æ˜¾è‘—æå‡ ZO æ•ˆç‡**ï¼šé€šè¿‡ä»å†å²æ‰°åŠ¨ä¸­æå–â€œæœ‰ç”¨æ–¹å‘â€ï¼Œå¯ä»¥å¤§å¹…æå‡æ¢¯åº¦ä¼°è®¡è´¨é‡ï¼Œè§£å†³ä¼ ç»Ÿ ZO æ”¶æ•›æ…¢çš„é—®é¢˜ã€‚
2. **GV æ–¹æ³•å…¼å…·é«˜æ•ˆæ€§ä¸é«˜æ€§èƒ½**ï¼šåœ¨ä¿æŒ ZO ä½å†…å­˜ä¼˜åŠ¿çš„åŒæ—¶ï¼Œå®ç°äº†æ¯”æ ‡å‡† ZO æ›´å¿«çš„æ”¶æ•›å’Œæ›´é«˜çš„æœ€ç»ˆæ€§èƒ½ã€‚
3. **å¹¿æ³›é€‚ç”¨æ€§ä¸å¯æ‰©å±•æ€§**ï¼šæ–¹æ³•åœ¨ä¸åŒæ¨¡å‹æ¶æ„ï¼ˆOPTã€Llama2ï¼‰ã€ä¸åŒè§„æ¨¡ï¼ˆ1.3B åˆ° 30Bï¼‰ã€ä¸åŒå¾®è°ƒèŒƒå¼ï¼ˆFTã€LoRAã€Prefixï¼‰ä¸‹å‡æœ‰æ•ˆã€‚
4. **éƒ¨åˆ†ä»»åŠ¡è¶…è¶Šæ¢¯åº¦æ³•**ï¼šåœ¨ 9/11 ä¸ªä»»åŠ¡ä¸Šä¼˜äº Adam åŸºçº¿ï¼Œè¡¨æ˜ ZO ä¸å†åªæ˜¯â€œé€€è€Œæ±‚å…¶æ¬¡â€çš„æ›¿ä»£æ–¹æ¡ˆï¼Œè€Œæ˜¯å…·å¤‡ç«äº‰åŠ›çš„ä¸»æµé€‰æ‹©ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **é¢å¤–è®¡ç®—å¼€é”€**ï¼šæ¯æ­¥éœ€è¿›è¡Œ $ M $ æ¬¡é¢å¤–å‰å‘ä¼ æ’­æ¥æ„å»ºå¼•å¯¼å‘é‡ï¼ˆ$ M=4 $ æ—¶å¢åŠ çº¦ 4Ã— æŸ¥è¯¢ï¼‰ï¼Œå¯èƒ½å½±å“ååé‡ã€‚
- **å¯¹è¶…å‚æ•°æ•æ„Ÿ**ï¼šå¦‚ $ M $ã€split ratio $ \alpha $ éœ€åˆç†è®¾ç½®ï¼Œå¦åˆ™å¯èƒ½å¼•å…¥å™ªå£°ã€‚
- **ç†è®ºè¿‘ä¼¼æ€§**ï¼šè™½ç„¶è¯æ˜äº†æ–¹å‘å¯¹é½å¢å¼ºï¼Œä½†ä»ä¸ºè¿‘ä¼¼ä¼°è®¡ï¼Œæ— æ³•å®Œå…¨æ¶ˆé™¤åå·®ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„å¼•å¯¼å‘é‡æ„é€ æ–¹å¼ï¼ˆå¦‚åŠ¨é‡ç´¯ç§¯ã€è·¨æ­¥å¤ç”¨ï¼‰
- å°† GV æ€è·¯åº”ç”¨äºå…¶ä»–é»‘ç›’ä¼˜åŒ–åœºæ™¯ï¼ˆå¦‚ prompt tuningã€NASï¼‰
- åŠ¨æ€è°ƒæ•´ $ M $ æˆ–é‡‡ç”¨è‡ªé€‚åº”é‡‡æ ·ç­–ç•¥ä»¥å¹³è¡¡æ•ˆç‡ä¸ç²¾åº¦
- ç»“åˆåˆ†å¸ƒå¼è®­ç»ƒè¿›ä¸€æ­¥æå‡å¤§è§„æ¨¡åº”ç”¨èƒ½åŠ›

---

## æ€»ç»“
æœ¬æ–‡æå‡ºçš„ **GV-ZO æ¡†æ¶**ï¼ˆåŒ…æ‹¬ MeZO-GV å’Œ MeZO-Greedyï¼‰é€šè¿‡å¼•å…¥**å…ˆéªŒä¿¡æ¯æŒ‡å¯¼æ‰°åŠ¨æ–¹å‘**ï¼Œè§£å†³äº†ä¼ ç»Ÿ Zeroth-Order ä¼˜åŒ–ä¸­æ¢¯åº¦ä¼°è®¡æ–¹å·®å¤§ã€æ”¶æ•›æ…¢çš„æ ¸å¿ƒé—®é¢˜ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…åœ¨å¤šç§ LLM å’Œä»»åŠ¡ä¸Šå®ç°äº†**æ›´å¿«æ”¶æ•›å’Œæ›´é«˜æ€§èƒ½**ï¼Œè€Œä¸”åœ¨éƒ¨åˆ†ä»»åŠ¡ä¸Š**è¶…è¶Šäº†æ¢¯åº¦æ³•åŸºçº¿**ï¼ŒåŒæ—¶ä¿æŒäº† ZO å›ºæœ‰çš„**ä½å†…å­˜ä¼˜åŠ¿**ã€‚è¿™ä¸€æˆæœæ¨åŠ¨äº†æ— åå‘ä¼ æ’­å¾®è°ƒæŠ€æœ¯çš„å‘å±•ï¼Œä¸ºèµ„æºå—é™ç¯å¢ƒä¸‹çš„ LLM é«˜æ•ˆé€‚é…æä¾›äº†å¼ºæœ‰åŠ›çš„æ–°å·¥å…·ã€‚

</details>

---

### 10. [GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models](https://arxiv.org/abs/2601.04719)

**Authors**: Maanas Taneja, Purab Shingvi  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.04719v1  

#### Abstract
The key-value (KV) cache in large language models presents a significant memory bottleneck during inference, growing linearly with sequence length and often exceeding the memory footprint of model weights themselves. We implement and evaluate GPU-accelerated INT8 quantization for KV cache compressio...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šGPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ¨ç†è¿‡ç¨‹ä¸­é¢ä¸´ä¸¥é‡çš„å†…å­˜ç“¶é¢ˆï¼Œå°¤å…¶æ˜¯ **Key-Value (KV) Cache** çš„å†…å­˜æ¶ˆè€—ã€‚éšç€åºåˆ—é•¿åº¦å¢é•¿ï¼ŒKV Cache çš„å¤§å°å‘ˆçº¿æ€§å¢åŠ ï¼Œåœ¨é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸‹ï¼ˆå¦‚ 32K æˆ– 128K tokensï¼‰ï¼Œå…¶å†…å­˜å ç”¨ç”šè‡³è¶…è¿‡æ¨¡å‹æƒé‡æœ¬èº«ï¼Œé™åˆ¶äº†æ‰¹å¤„ç†å¤§å°ã€ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œå¹¶æé«˜äº†éƒ¨ç½²æˆæœ¬ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
æœ¬æ–‡æå‡ºå¹¶ç³»ç»Ÿå®ç°äº† **GPU åŠ é€Ÿçš„ per-channel INT8 é‡åŒ–æ–¹æ³•**ï¼Œç”¨äºå‹ç¼© LLM æ¨ç†ä¸­çš„ KV Cacheï¼Œä¸»è¦è´¡çŒ®å¦‚ä¸‹ï¼š

- **é«˜æ•ˆå®ç°æ–¹æ¡ˆ**ï¼šè®¾è®¡å¹¶å®ç°äº†å››ç§ CUDA kernel å˜ä½“ï¼ˆnaiveã€tiledã€coarsenedã€vectorizedï¼‰ï¼Œæ¢ç´¢ä¸åŒä¼˜åŒ–ç­–ç•¥å¯¹æ€§èƒ½çš„å½±å“ã€‚
- **ç³»ç»Ÿæ€§è¯„ä¼°æ¡†æ¶**ï¼šä¸ä»…å…³æ³¨ç«¯åˆ°ç«¯ç²¾åº¦ï¼Œè¿˜æ·±å…¥åˆ†æäº†é‡åŒ–æ“ä½œæœ¬èº«çš„ **kernel-level æ€§èƒ½ç‰¹æ€§** å’Œè¯¯å·®ä¼ æ’­æœºåˆ¶ã€‚
- **æ­ç¤ºç¡¬ä»¶ä¼˜åŒ–è§„å¾‹**ï¼šé€šè¿‡å®éªŒè¯æ˜ï¼Œåœ¨æ­¤ç±»å†…å­˜å¯†é›†å‹ä»»åŠ¡ä¸­ï¼Œ**vectorization æ˜¯æœ€æœ‰æ•ˆçš„ä¼˜åŒ–æ‰‹æ®µ**ï¼Œè€Œä¼ ç»Ÿå…±äº«å†…å­˜ tiling æ•ˆæœæœ‰é™ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰å·¥ä½œ | æœ¬è®ºæ–‡ä¼˜åŠ¿ |
|------|--------|-----------|
| **ä¼˜åŒ–ç²’åº¦** | å¤šæ•°ç ”ç©¶èšç„¦äºæ¨¡å‹æƒé‡æˆ–æ¿€æ´»å€¼çš„æ•´ä½“å‹ç¼©ï¼ˆå¦‚ LLM.int8()ï¼‰ | èšç„¦äº **KV Cache è¿™ä¸€ç‰¹å®šç“¶é¢ˆç»„ä»¶**ï¼Œæ›´å…·é’ˆå¯¹æ€§ |
| **å®ç°ç»†èŠ‚é€æ˜åº¦** | å•†ä¸šæ¨ç†ç³»ç»Ÿï¼ˆå¦‚ TensorRT-LLMï¼‰å¸¸å°†é‡åŒ–è§†ä¸ºé»‘ç›’ | æä¾› **å®Œæ•´çš„ kernel å®ç°ä¸æ€§èƒ½å‰–æ**ï¼ŒæŒ‡å¯¼å®é™…å·¥ç¨‹è½åœ° |
| **æ€§èƒ½ä¼˜åŒ–æ´å¯Ÿ** | ç¼ºä¹å¯¹ä¸åŒ GPU ä¼˜åŒ–æŠ€æœ¯åœ¨ KV é‡åŒ–ä¸Šçš„å¯¹æ¯” | æ˜ç¡®æŒ‡å‡º **vectorization æœ€ä¼˜ï¼Œtiled æ— æ˜¾è‘—æ”¶ç›Š**ï¼Œé¿å…è¯¯ç”¨ä¼˜åŒ– |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
æœ¬ç ”ç©¶ä¸º **åˆæˆåŸºå‡†æµ‹è¯•ï¼ˆsynthetic benchmarkingï¼‰**ï¼Œæœªä½¿ç”¨çœŸå®æ–‡æœ¬æ•°æ®é›†ã€‚æ‰€æœ‰å®éªŒåŸºäºäººå·¥ç”Ÿæˆçš„ FP32 çŸ©é˜µæ¨¡æ‹Ÿ KV Cache æ•°æ®ï¼Œè¦†ç›–å¤šç§å…¸å‹ç»´åº¦ç»„åˆã€‚

#### æµ‹è¯•é…ç½®ï¼ˆTable 3ï¼‰
| Test Case | Tokens (T) | Head Dim (D) | æè¿° |
|----------|------------|--------------|------|
| Small | 2,048 | 128 | å¾®å°æµ‹è¯• |
| Medium | 16,384 | 256 | å¼€å‘è°ƒè¯• |
| Large ~ Very Large | 65K ~ 131K | 256 | é•¿åºåˆ—åœºæ™¯ |
| Realistic Small ~ V. Large | 131,072 | 1K ~ 8K | çœŸå® LLM å·¥ä½œè´Ÿè½½ï¼ˆæœ€å¤§è¾¾ 10 äº¿å…ƒç´ ï¼‰ |

> æ³¨ï¼š`T=131,072` å¯¹åº”è¶…é•¿ä¸Šä¸‹æ–‡ï¼ˆçº¦ 128K tokensï¼‰ï¼Œ`D=8192` å¯¹åº”å®½å¤´æ¨¡å‹ï¼ˆå¦‚æŸäº›å¤§æ¨¡å‹ attention head dimensionï¼‰ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - GPU: NVIDIA Tesla T4 (16GB GDDR6)
  - CPU: 2Ã— Intel Xeon Gold 6148 (å…± 40 æ ¸)
  - CUDA ç‰ˆæœ¬ï¼š12.0
- **é‡åŒ–æ–¹å¼**ï¼š**per-channel INT8 é‡åŒ–**ï¼Œæ¯ä¸ª head ç»´åº¦ç‹¬ç«‹è®¡ç®— scaleï¼š
  $$
  s_d = \frac{\max_t |K_{t,d}|}{127}
  $$
- **Kernel å®ç°**ï¼š
  - CPU baselineï¼ˆå•çº¿ç¨‹å‚è€ƒå®ç°ï¼‰
  - å››ç§ CUDA kernelï¼š
    1. `naive`: 1 thread per element
    2. `tiled`: ä½¿ç”¨ shared memory ç¼“å­˜ scales
    3. `coarsened`: æ¯ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªå…ƒç´ 
    4. `vectorized`: ä½¿ç”¨ `float4`/`char4` å‘é‡æŒ‡ä»¤æ‰¹é‡è¯»å†™

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ | ç›®çš„ |
|------|------|------|
| **Performance** | é‡åŒ–/åé‡åŒ–è€—æ—¶ï¼ŒGPU ç›¸å¯¹äº CPU çš„ speedup | è¡¡é‡è®¡ç®—æ•ˆç‡ |
| **L2 Reconstruction Error** | $\|K - \hat{K}\|_2$ | è¯„ä¼°é‡å»ºç²¾åº¦æŸå¤± |
| **Max Absolute Error** | $\max |K_{t,d} - \hat{K}_{t,d}|$ | è¯„ä¼°æœ€å¤§åå·® |
| **Attention Score Error** | $\text{mean} |\text{dot}(Q,K) - \text{dot}(Q,\hat{K})|$ | è¯„ä¼°å¯¹ä¸‹æ¸¸ attention è®¡ç®—çš„å½±å“ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆFigure 1â€“3ï¼‰

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **æœ€å¤§åŠ é€Ÿæ¯”** | **1,694Ã—**ï¼ˆvs CPU baselineï¼Œrealistic very large é…ç½®ï¼‰ |
| **GPU æ‰§è¡Œæ—¶é—´** | æ‰€æœ‰ realistic workload ä¸‹å‡åœ¨ **6â€“58 ms** å†…å®Œæˆ |
| **å†…å­˜å‹ç¼©ç‡** | **4Ã— reduction**ï¼ˆFP32 â†’ INT8ï¼‰ |
| **æœ€å¤§ç»å¯¹è¯¯å·®** | æ’å®šä¸º **0.00394**ï¼Œç¬¦åˆç†è®ºä¸Šé™ $1/(2Ã—127)$ |
| **Attention Score Error** | å³ä½¿åœ¨ D=8192 æ—¶ä¹Ÿä»… **0.095**ï¼Œè¿œå°äº softmax å‰çš„ score èŒƒå›´ |

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”
| Kernel | vs CPU Speedupï¼ˆæœ€å¤§ï¼‰ | vs Naive GPU |
|-------|------------------------|-------------|
| CPU Baseline | 1Ã— | â€” |
| Naive CUDA | ~1,000Ã— | 1Ã— |
| Tiled CUDA | ~950Ã— | â‰ˆ0.95Ã—ï¼ˆç•¥æ…¢ï¼‰ |
| Coarsened CUDA | ~1,200Ã— | ~1.2Ã— |
| **Vectorized CUDA** | **~1,694Ã—** | **~1.7Ã— æ›´å¿«** |

> âš ï¸ **å…³é”®è§‚å¯Ÿ**ï¼šå°½ç®¡ `tiled` kernel ä½¿ç”¨ shared memory å‡å°‘ scale é‡å¤åŠ è½½ï¼Œä½†ç”±äº scales æ•°ç»„è¾ƒå°ä¸”å¯é©»ç•™ L2 cacheï¼Œ**å¹¶æœªå¸¦æ¥æ€§èƒ½æå‡ï¼Œåè€Œå› åŒæ­¥å¼€é”€ç•¥æ…¢äº naive å®ç°**ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **Problem Size Scaling**ï¼ˆFigure 5ï¼‰ï¼š
  - æ‰€æœ‰ GPU kernels çš„ speedup éšçŸ©é˜µè§„æ¨¡å¢å¤§è€Œä¸Šå‡ï¼Œè¯´æ˜èƒ½æœ‰æ•ˆæ‘Šé”€ kernel launch overheadã€‚
- **Kernel Design Impact**ï¼š
  - `vectorized` åœ¨æ‰€æœ‰è§„æ¨¡ä¸‹è¡¨ç°æœ€ä½³ï¼Œå› å…¶ç›´æ¥æå‡äº† memory bandwidth åˆ©ç”¨ç‡ã€‚
  - `coarsened` æœ‰ä¸€å®šæ”¹è¿›ï¼ˆå‡å°‘ loop å¼€é”€ï¼‰ï¼Œä½†å—é™äº memory-bound ç‰¹æ€§ï¼Œå¢ç›Šæœ‰é™ã€‚
  - `tiled` æ— æ˜æ˜¾ä¼˜åŠ¿ï¼Œè¡¨æ˜ **shared memory å¹¶éä¸‡èƒ½ä¼˜åŒ–**ï¼Œéœ€è§†è®¿é—®æ¨¡å¼è€Œå®šã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **INT8 é‡åŒ–æ˜¯å®ç”¨ä¸”é«˜æ•ˆçš„ KV Cache å‹ç¼©æ–¹æ¡ˆ**ï¼š
   - å®ç° **4Ã— å†…å­˜èŠ‚çœ**ï¼Œæ˜¾è‘—ç¼“è§£ LLM æ¨ç†å†…å­˜å‹åŠ›ã€‚
   - å¼•å…¥çš„æ•°å€¼è¯¯å·®æå°ï¼ˆmax error < 0.004ï¼‰ï¼Œå¯¹ attention score å½±å“å¯å¿½ç•¥ï¼ˆ< 0.1ï¼‰ã€‚

2. ğŸš€ **GPU åŠ é€Ÿè‡³å…³é‡è¦**ï¼š
   - æœ€å¤§ä»»åŠ¡ä» CPU çš„ **79 ç§’é™è‡³ GPU çš„ 46 æ¯«ç§’**ï¼ŒåŠ é€Ÿæ¯”é«˜è¾¾ **1,694Ã—**ã€‚
   - é‡åŒ–å¼€é”€ï¼ˆ6â€“58msï¼‰è¿œä½äºå®é™… attention è®¡ç®—æ—¶é—´ï¼Œ**å‡ ä¹ä¸å½±å“æ•´ä½“åå**ã€‚

3. ğŸ’¡ **ä¼˜åŒ–ç­–ç•¥æœ‰æ•ˆæ€§æ’åºï¼š`vectorization > coarsening > tiling â‰ˆ naive`**ï¼š
   - KV cache é‡åŒ–æ˜¯å…¸å‹çš„ **memory-boundã€ä½ç®—æœ¯å¼ºåº¦** æ“ä½œã€‚
   - ä¸€æ—¦å®ç°è‰¯å¥½ memory coalescingï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–åº”èšç„¦äº **å‡å°‘å†…å­˜äº‹åŠ¡æ•°é‡**ï¼Œè€Œéå¼•å…¥å¤æ‚åŒæ­¥ã€‚
   - **å‘é‡åŒ–ï¼ˆvectorized memory accessï¼‰æ˜¯æœ€æœ‰æ•ˆçš„ä¼˜åŒ–è·¯å¾„**ã€‚

4. ğŸ” **Shared Memory ä¸ä¸€å®šæœ‰ç›Š**ï¼š
   - åœ¨ scales å°ä¸”å¯ç¼“å­˜çš„æƒ…å†µä¸‹ï¼Œæ˜¾å¼ä½¿ç”¨ shared memory å¹¶ä¸èƒ½æå‡æ€§èƒ½ï¼Œåè€Œå¯èƒ½å›  `_syncthreads()` å¸¦æ¥è½»å¾®å¼€é”€ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- âŒ **æœªè¿›è¡Œç«¯åˆ°ç«¯ä»»åŠ¡è¯„ä¼°**ï¼šä»…æµ‹é‡ reconstruction error å’Œ attention score errorï¼Œ**æœªæŠ¥å‘Š perplexityã€QA å‡†ç¡®ç‡ç­‰ä¸‹æ¸¸ä»»åŠ¡æŒ‡æ ‡**ã€‚
- âŒ **ä»…æ”¯æŒ INT8**ï¼šæœªæ¢ç´¢æ›´ä½æ¯”ç‰¹ï¼ˆå¦‚ INT4ã€INT2ï¼‰æˆ–æ··åˆç²¾åº¦ç­–ç•¥ã€‚
- âŒ **å• GPU è®¾è®¡**ï¼šä¸æ”¯æŒ multi-GPU æˆ–åˆ†å¸ƒå¼æ¨ç†åœºæ™¯ã€‚
- âŒ **é™æ€ scale**ï¼šé‡‡ç”¨ per-channel æœ€å¤§å€¼ç¼©æ”¾ï¼Œç¼ºä¹åŠ¨æ€æˆ–å­¦ä¹ å¼é‡åŒ–æœºåˆ¶åº”å¯¹å¼‚å¸¸æ¿€æ´»ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **é›†æˆè‡³ä¸»æµæ¨ç†å¼•æ“**ï¼šå°† kernel é›†æˆè¿› vLLMã€TensorRT-LLM ç­‰ç³»ç»Ÿï¼Œè¿›è¡ŒçœŸå® workload ä¸‹çš„ç«¯åˆ°ç«¯æ€§èƒ½ä¸ç²¾åº¦è¯„ä¼°ã€‚
2. **æ¢ç´¢æ›´ä½ä½å®½ä¸æ–°å‹æ ¼å¼**ï¼š
   - å°è¯• **KIVIï¼ˆ2-bit asymmetricï¼‰** æˆ– **KVQuantï¼ˆsub-4-bitï¼‰** ç­‰æç«¯é‡åŒ–æ–¹æ³•ã€‚
   - åˆ©ç”¨ **FP8** ç­‰æ–°å…´æ ¼å¼ï¼Œç»“åˆç¡¬ä»¶åŸç”Ÿæ”¯æŒæå‡æ•ˆç‡ã€‚
3. **ä¼˜åŒ– scale computation**ï¼š
   - ä½¿ç”¨ warp-level primitivesï¼ˆå¦‚ `__shfl_down_sync`ï¼‰åŠ é€Ÿæœ€å¤§å€¼å½’çº¦ã€‚
   - æ¢ç´¢è¿‘ä¼¼æœ€å¤§å€¼ä¼°è®¡ä»¥é™ä½å¼€é”€ã€‚
4. **åŠ¨æ€ä¸è‡ªé€‚åº”é‡åŒ–**ï¼šæ ¹æ®è¾“å…¥åˆ†å¸ƒåŠ¨æ€è°ƒæ•´ scaleï¼Œæå‡é²æ£’æ€§ã€‚
5. **å¤š GPU æ‰©å±•**ï¼šè®¾è®¡è·¨è®¾å¤‡çš„é‡åŒ–/åé‡åŒ–æµæ°´çº¿ï¼Œé€‚é…å¤§è§„æ¨¡åˆ†å¸ƒå¼æ¨ç†ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡è¯æ˜äº† **GPU-accelerated per-channel INT8 é‡åŒ–** æ˜¯ä¸€ç§é«˜æ•ˆã€ä½è¯¯å·®ã€ä½å¼€é”€çš„ KV Cache å‹ç¼©æ–¹æ¡ˆï¼Œå…¶ä¸­ **vectorized CUDA kernel å®ç°äº†é«˜è¾¾ 1,694Ã— çš„åŠ é€Ÿ**ï¼Œä¸ºç”Ÿäº§çº§ LLM æ¨ç†ç³»ç»Ÿçš„å†…å­˜ä¼˜åŒ–æä¾›äº†åˆ‡å®å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 11. [ReEfBench: Quantifying the Reasoning Efficiency of LLMs](https://arxiv.org/abs/2601.03550)

**Authors**: Zhizhang Fu, Yuancheng Gu, Chenkai Hu, Hanmeng Liu, Yue Zhang  
**Category**: cs.AI  
**Published**: 2026-01-09  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.03550v1  

#### Abstract
Test-time scaling has enabled Large Language Models (LLMs) to tackle complex reasoning, yet the limitations of current Chain-of-Thought (CoT) evaluation obscures whether performance gains stem from genuine reasoning or mere verbosity. To address this, (1) we propose a novel neuro-symbolic framework ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ReEfBench: Quantifying the Reasoning Efficiency of LLMs è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨ç†èƒ½åŠ›çš„è¯„ä¼°ä¸»è¦ä¾èµ– **Chain-of-Thought (CoT)** è¾“å‡ºé•¿åº¦æˆ–æœ€ç»ˆç­”æ¡ˆå‡†ç¡®æ€§ï¼Œå­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **æ— æ³•åŒºåˆ†â€œçœŸå®æ¨ç†â€ä¸â€œå†—ä½™ç”Ÿæˆâ€**ï¼šæ¨¡å‹å¯èƒ½é€šè¿‡â€œè¿‡åº¦æ€è€ƒâ€ï¼ˆoverthinkingï¼‰ç”Ÿæˆå¤§é‡æ— æ„ä¹‰çš„ä¸­é—´æ­¥éª¤æ¥æå‡è¡¨ç°ï¼Œè€ŒéçœŸæ­£è¿›è¡Œæ·±åº¦é€»è¾‘æ¨ç†ã€‚
- **ç¼ºä¹è¿‡ç¨‹å¯¼å‘çš„é‡åŒ–è¯„ä¼°æ¡†æ¶**ï¼šç°æœ‰æ–¹æ³•éš¾ä»¥ç³»ç»Ÿè¡¡é‡æ¨ç†è·¯å¾„çš„æ•ˆç‡ã€é€»è¾‘æ·±åº¦å’Œè®¤çŸ¥è¡Œä¸ºã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **ReEfBench** â€”â€”ä¸€ä¸ªåŸºäº **ç¥ç»ç¬¦å·ç³»ç»Ÿï¼ˆneuro-symbolicï¼‰** çš„éä¾µå…¥å¼ã€è¿‡ç¨‹ä¸­å¿ƒåŒ–çš„æ¨ç†æ•ˆç‡è¯„ä¼°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ¨ç†æ•ˆç‡å½¢å¼åŒ–ä¸ºï¼š

$$
P = \frac{W}{t}
$$
å…¶ä¸­ï¼š
- $W$ï¼š**Logical Depth**ï¼ˆé€»è¾‘æ·±åº¦ï¼‰ï¼Œè¡¨ç¤ºå®Œæˆä»»åŠ¡æ‰€éœ€çš„æŠ½è±¡é€»è¾‘æ­¥æ•°ï¼›
- $t$ï¼š**Computational Cost**ï¼ˆè®¡ç®—æ¶ˆè€—ï¼‰ï¼Œå¦‚ç”Ÿæˆçš„ token æ•°é‡ï¼›
- $P$ï¼š**Reasoning Efficiency**ï¼ˆæ¨ç†æ•ˆç‡ï¼‰ï¼Œå³å•ä½è®¡ç®—æˆæœ¬ä¸‹çš„é€»è¾‘å¢ç›Šã€‚

#### æ¡†æ¶æµç¨‹ï¼ˆå¦‚å›¾1æ‰€ç¤ºï¼‰
1. **Phase Aï¼šå¯æ‰©å±•æ•°æ®ç”Ÿæˆ**  
   æ„å»ºåŸºäº **First-Order Logic (FOL)** çš„å¯æ§ã€å¯æ‰©å±•çš„é€»è¾‘æ¨ç†æ•°æ®é›†ï¼Œç¡®ä¿æ¯ä¸ªé—®é¢˜æœ‰æ˜ç¡®çš„é€»è¾‘æ·±åº¦å®šä¹‰ã€‚
2. **Phase Bï¼šLLM å“åº”è·å–**  
   å‘ç›®æ ‡ LLM è¾“å…¥é—®é¢˜å¹¶æ”¶é›†å…¶ CoT æ¨ç†è¿‡ç¨‹ã€‚
3. **Phase Cï¼šå“åº”è§£æ**  
   ä½¿ç”¨å°å‹ LLM å°†è‡ªç„¶è¯­è¨€æ¨ç†é“¾åˆ†è§£ä¸ºç»“æ„åŒ–èŠ‚ç‚¹ï¼ˆå¦‚ `actual`, `planning`, `reflection`ï¼‰ã€‚
4. **Phase Dï¼šè§„åˆ™é©±åŠ¨çš„èŠ‚ç‚¹å¤„ç†**  
   åˆ©ç”¨ç¬¦å·é€»è¾‘è§„åˆ™éªŒè¯èŠ‚ç‚¹æ­£ç¡®æ€§ï¼Œå¹¶è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„é€»è¾‘æ·±åº¦ã€‚
5. **Phase Eï¼šè¡Œä¸ºæŒ‡æ ‡èšåˆ**  
   ç»¼åˆå…­ä¸ªç»´åº¦çš„è¯Šæ–­æŒ‡æ ‡ï¼Œè¯†åˆ«æ¨¡å‹çš„è¡Œä¸ºåŸå‹ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | ReEfBench | å…¶ä»–æ–¹æ³•ï¼ˆå¦‚ ProntoQA, Roscoeï¼‰ |
|------|-----------|-------------------------------|
| **Scalable** | âœ… æ”¯æŒå¤æ‚åº¦å¯æ§çš„æ•°æ®ç”Ÿæˆ | âŒ æ•°æ®è§„æ¨¡æœ‰é™æˆ–ä¸å¯æ§ |
| **FOL åŸºç¡€** | âœ… å½¢å¼åŒ–é€»è¾‘ä¿è¯å®¢è§‚éªŒè¯ | âš ï¸ éƒ¨åˆ†æ”¯æŒæˆ–ä¸æ”¯æŒ |
| **Logic-Only** | âœ… è„±é’©çŸ¥è¯†ä¸é€»è¾‘ï¼Œä¸“æ³¨çº¯æ¨ç† | âŒ æ˜“å—å…ˆéªŒçŸ¥è¯†å¹²æ‰° |
| **LogDepth å¯æµ‹** | âœ… æ˜ç¡®å®šä¹‰å¹¶å¯è‡ªåŠ¨è®¡ç®— | âŒ å¤šä¸ºäºŒå€¼æœ‰æ•ˆæ€§åˆ¤æ–­ |
| **BehProc åˆ†æ** | âœ… æ”¯æŒæ¢ç´¢ã€åæ€ç­‰è®¤çŸ¥è¡Œä¸ºåˆ†æ | âŒ ç¼ºä¹ç»†ç²’åº¦è¿‡ç¨‹è¿½è¸ª |
| **Non-Intrusive** | âœ… ä¸å¼ºåˆ¶è¾“å‡ºæ ¼å¼ | âŒ å¦‚ ZebraLogic å¼ºåˆ¶ç»“æ„åŒ–è¾“å‡º |

> âœ… è¡¨ç¤ºæ”¯æŒï¼Œâš ï¸ è¡¨ç¤ºéƒ¨åˆ†æ”¯æŒï¼ŒâŒ è¡¨ç¤ºä¸æ”¯æŒ

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **è‡ªç ”æ•°æ®é›† ReEfBench**ï¼š
  - åŸºäº **First-Order Logic (FOL)** å’Œ **Modus Ponens** æ¨ç†è§„åˆ™æ„å»ºã€‚
  - åŒ…å« **å‰æï¼ˆPremisesï¼‰**ã€**ç»“è®ºï¼ˆConclusionï¼‰** å’Œ **é»„é‡‘è§£æ³•è·¯å¾„**ã€‚
  - å¤æ‚åº¦ç­‰çº§ä» 3 åˆ° 11ï¼Œæ¯çº§ 100 ä¸ªæ ·æœ¬ï¼Œå…± 900 ä¸ªæµ‹è¯•å®ä¾‹ã€‚
  - æ¯ä¸ªæ ·æœ¬é¢å¤–åŠ å…¥ $C$ ä¸ªæ— å…³å‰æä½œä¸ºå¹²æ‰°é¡¹ï¼ˆdistractorsï¼‰ï¼Œå¢åŠ éš¾åº¦ã€‚

### å®éªŒè®¾ç½®
- **è¯„ä¼°æ¨¡å‹**ï¼šå…±è¯„æµ‹ **25 ä¸ªä¸»æµ LLMs**ï¼ŒåŒ…æ‹¬ï¼š
  - å•†ä¸šé—­æºæ¨¡å‹ï¼š`Claude-Opus-4.5`, `Claude-Sonnet-4.5`
  - å¼€æºæ¨¡å‹ï¼š`Qwen3-*`, `DeepSeek-R1`, `DS-R1-Distill-Qwen-*`
- **æ¨ç†æ¨¡å¼åŒºåˆ†**ï¼š
  - `.long`ï¼šå¯ç”¨ thinking / CoT æ¨¡å¼çš„é•¿é“¾æ¨ç†
  - `.short`ï¼šæ ‡å‡†æŒ‡ä»¤å¾®è°ƒæ¨¡å¼
- **API å‚æ•°**ï¼š`temperature=0`, æœ€å¤§ç”Ÿæˆ token æ•°åˆ†åˆ«ä¸º 24kï¼ˆæ¨ç†æ¨¡å¼ï¼‰å’Œ 8kï¼ˆéæ¨ç†æ¨¡å¼ï¼‰

### è¯„ä¼°æŒ‡æ ‡ï¼ˆå…­å¤§ç»´åº¦ï¼‰
æ‰€æœ‰æŒ‡æ ‡ç» max-normalization æ˜ å°„è‡³ [0,1] åŒºé—´ååŠ æƒå¹³å‡ï¼š

| æŒ‡æ ‡ | å«ä¹‰ | å­æŒ‡æ ‡ |
|------|------|--------|
| **Logical Depth ($S_{ld}$)** | æ¨ç†èƒ½åŠ› | æœ€å¤§æ­£ç¡®é€»è¾‘æ·±åº¦ |
| **Cost ($S_{cost}$)** | è®¡ç®—æ¶ˆè€— | æ€» token æ•°ã€åæ€/è§„åˆ’æ­¥æ•° |
| **Exploration ($S_{exp}$)** | æ¢ç´¢å¹¿åº¦ | æ­£ç¡®ä¸”å”¯ä¸€çš„é€»è¾‘èŠ‚ç‚¹æ•°é‡ |
| **Efficiency ($S_{eff}$)** | æ¨ç†æ•ˆç‡ | token æ•ˆç‡ã€æœ‰æ•ˆè·¨åº¦ï¼ˆeffective spanï¼‰ |
| **Coherence ($S_{coh}$)** | è¿è´¯æ€§ | è§„åˆ’/åæ€æ˜¯å¦å¸¦æ¥å®é™…è¿›å±• |
| **Redundancy ($S_{red}$)** | å†—ä½™åº¦ | å¥å­/èŠ‚ç‚¹é‡å¤ç‡ |

æ­¤å¤–è¿˜ä½¿ç”¨åŸå§‹æŒ‡æ ‡è¾…åŠ©åˆ†æï¼Œå¦‚ **å¹³å‡é€»è¾‘æ·±åº¦**ã€**token æ•°ï¼ˆåƒï¼‰** ç­‰ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æœ¬æ–‡æœªç›´æ¥å¯¹æ¯”ä¼ ç»Ÿ CoT è¯„ä¼°æ–¹æ³•ï¼ˆå› å…¶ä¸å…·å¤‡è¿‡ç¨‹åˆ†æèƒ½åŠ›ï¼‰ï¼Œè€Œæ˜¯é€šè¿‡ä»¥ä¸‹æ–¹å¼ä½“ç°ä¼˜åŠ¿ï¼š
- å¯¹æ¯”ä¸åŒè®­ç»ƒç­–ç•¥ï¼ˆLong vs. Short CoTï¼‰
- å¯¹æ¯”ä¸åŒæ¨¡å‹è§„æ¨¡ä¸‹çš„è’¸é¦æ•ˆæœ
- åˆ†ææ··åˆè®­ç»ƒçš„å½±å“

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 2 & Figure 3ï¼‰

| æ¨¡å‹ | ç±»åˆ« | å¹³å‡é€»è¾‘æ·±åº¦ | Token æ•° (k) | $S_{ld}$ | $S_{cost}$ | $S_{eff}$ |
|------|------|---------------|----------------|----------|------------|-----------|
| Qwen3-235B-thinking | DeepWanderer | 10.54 | 16.8 | 1.00 | 0.88 | 0.47 |
| Claude-Opus-4.5.long | EffectiveSolver | 10.27 | 3.5 | 0.97 | 0.37 | 0.60 |
| QwQ-32B | HollowMimic | 7.12 | 5.7 | 0.68 | 0.61 | 0.48 |
| Qwen2.5-32B-Instruct | LazyGuesser | 2.90 | 0.7 | 0.28 | 0.16 | 0.55 |

> æ³¨ï¼šæœ€å¤§é€»è¾‘æ·±åº¦ä¸º 11ã€‚

### å››ç±»è¡Œä¸ºåŸå‹ï¼ˆBehavioral Prototypesï¼‰

| ç±»å‹ | ç‰¹å¾ | ç¤ºä¾‹æ¨¡å‹ |
|------|------|---------|
| **DeepWanderer** | é«˜æˆæœ¬ã€é«˜æ¢ç´¢ã€ä½æ•ˆç‡ | Qwen3-235B-thinking |
| **EffectiveSolver** | é«˜æ•ˆç‡ã€ç²¾å‡†æ¨ç†ã€ä½æˆæœ¬ | Claude-Opus-4.5.long |
| **HollowMimic** | é«˜æˆæœ¬ä½†æµ…å±‚æ¨ç†ï¼Œè¡¨ç°ä¸ºâ€œè¡¨æ¼”æ€§æ¨ç†â€ | DS-R1-Qwen-7B, QwQ-32B |
| **LazyGuesser** | æˆæœ¬æä½ï¼Œæ¨ç†åœæ»ï¼Œå¸¸é™·å…¥é‡å¤ | Qwen2.5-32B-Instruct |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **Long CoT vs. Short CoT**ï¼ˆTable 3ï¼‰ï¼š
  - æ—©æœŸ Long CoT æ¨¡å‹ï¼ˆå¦‚ QwQ-32Bï¼‰ç›¸æ¯” Short CoTï¼ˆQwen2.5-32B-Instructï¼‰é€»è¾‘æ·±åº¦æå‡ **+97.1%**ã€‚
  - å½“å‰å…ˆè¿› Short CoT æ¨¡å‹ï¼ˆå¦‚ Qwen3-235B-Instructï¼‰å·²æ¥è¿‘ Long CoT è¡¨ç°ï¼Œå·®è·ä»… **+1.6%**ã€‚
  - ç»“è®ºï¼š**Short CoT + Reflection** å¯å®ç°é«˜æ•ˆæ·±åº¦æ¨ç†ã€‚

- **Distillation è’¸é¦å®éªŒ**ï¼ˆFigure 5 & 10ï¼‰ï¼š
  - å°æ¨¡å‹ï¼ˆ4B/8Bï¼‰åœ¨è’¸é¦åèƒ½æ¨¡ä»¿æ•™å¸ˆæ¨¡å‹ï¼ˆ32Bï¼‰çš„ **åæ€é¢‘ç‡**ï¼Œç”šè‡³æ›´é«˜ã€‚
  - ä½† **åæ€è´¨é‡éšå‚æ•°å‡å°‘è€Œä¸‹é™**ï¼Œæ— æ³•è½¬åŒ–ä¸ºæ›´æ·±çš„é€»è¾‘æ¨ç†ã€‚
  - ä»… **14B æ¨¡å‹** èƒ½åŒæ—¶ä¿æŒè¡Œä¸ºä¸èƒ½åŠ›å¯¹é½ã€‚
  - ç»“è®ºï¼š**å®¹é‡ä¸è¶³å¯¼è‡´â€œè¡Œä¸ºæ¨¡ä»¿â€è€Œéâ€œèƒ½åŠ›å¤åˆ¶â€**ã€‚

- **Mixed Training æ··åˆè®­ç»ƒå½±å“**ï¼ˆFigure 9ï¼‰ï¼š
  - å•ç‹¬è®­ç»ƒ Long CoT æ¨¡å‹ï¼ˆå¦‚ Qwen3-235B-thinkingï¼‰è¡¨ç°å‡º **Adaptive Scaling**ï¼ˆéšå¤æ‚åº¦å¢åŠ  token æ•°ï¼‰ã€‚
  - æ··åˆè®­ç»ƒæ¨¡å‹ï¼ˆå¦‚ Qwen3-235B.longï¼‰å‡ºç° **Premature Saturation/Collapse**ï¼Œæ— æ³•éšä»»åŠ¡å˜éš¾è€Œæ‰©å±•æ¨ç†ã€‚
  - ç»“è®ºï¼š**æ··åˆ Long/Short CoT æ•°æ®ä¼šç ´åé«˜æ¶ˆè€—æ¨ç†ç­–ç•¥**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **æ‰©å±• token ç”Ÿæˆä¸æ˜¯æ·±åº¦æ¨ç†çš„å¿…è¦æ¡ä»¶**  
   é«˜æ•ˆæ¨¡å‹ï¼ˆå¦‚ Claude-Opus-4.5.longï¼‰èƒ½åœ¨è¾ƒå°‘ token ä¸‹è¾¾åˆ°æ¥è¿‘æœ€å¤§é€»è¾‘æ·±åº¦ï¼ŒæŒ‘æˆ˜äº†â€œè¶Šé•¿è¶Šå¥½â€çš„å‡è®¾ã€‚

2. âœ… **å­˜åœ¨ä¸¤ç§æˆåŠŸæ¨ç†è·¯å¾„**ï¼š
   - **High-t Strategy (DeepWanderer)**ï¼šé«˜æˆæœ¬ã€é«˜æ¢ç´¢ï¼Œé€‚åˆèµ„æºå……è¶³åœºæ™¯ã€‚
   - **High-P Strategy (EffectiveSolver)**ï¼šé«˜æ•ˆç‡ã€ç²¾å‡†æ¨å¯¼ï¼Œæ›´é€‚åˆéƒ¨ç½²ã€‚

3. âœ… **Distillation å­˜åœ¨æ ¹æœ¬é™åˆ¶**  
   å°æ¨¡å‹å¯ä»¥æ¨¡ä»¿å¤§æ¨¡å‹çš„ **è¡Œä¸ºå½¢å¼**ï¼ˆå¦‚åæ€å¥å¼ï¼‰ï¼Œä½†ç”±äº **å†…åœ¨å®¹é‡é™åˆ¶**ï¼Œæ— æ³•å¤ç°å…¶é€»è¾‘æ•ˆèƒ½ï¼Œå¯¼è‡´â€œ**Diluted Expansion**â€ã€‚

4. âœ… **Mixed Training æœ‰å®³**  
   åœ¨åŒä¸€æ¨¡å‹ä¸­æ··åˆ Long CoT ä¸ Short CoT æ•°æ®ä¼šå¯¼è‡´ç­–ç•¥å†²çªï¼Œå¼•å‘ **è¿‡æ—©é¥±å’Œæˆ–å´©æºƒï¼ˆSaturation/Collapseï¼‰**ã€‚

5. âœ… **Reflection æ˜¯å…³é”®æœºåˆ¶**  
   æˆåŠŸçš„ Short CoT æ¨¡å‹æ™®éå…·å¤‡é«˜è´¨é‡çš„åæ€è¡Œä¸ºï¼ˆTable 4ï¼‰ï¼Œå³ä½¿åœ¨çŸ­é“¾ä¸­ä¹Ÿèƒ½ç»´æŒæ¨ç†è¿è´¯æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **é¢†åŸŸå—é™äº FOL**ï¼šç›®å‰ä»…é€‚ç”¨äºå½¢å¼åŒ–é€»è¾‘æ¨ç†ä»»åŠ¡ï¼Œä¸æ¶µç›–å¼€æ”¾é—®ç­”ã€æ•°å­¦è¯æ˜ç­‰æ›´å¹¿æ³›åœºæ™¯ã€‚
2. **éä¾µå…¥å¼è®¾è®¡é™åˆ¶**ï¼šåªèƒ½åˆ†ææ˜¾å¼ç”Ÿæˆçš„å†…å®¹ï¼Œæ— æ³•æ•æ‰éšå¼æ€ç»´è¿‡ç¨‹ã€‚
3. **åˆ†ç±»è¾¹ç•Œæ¨¡ç³Š**ï¼šå››å¤§åŸå‹æ˜¯ç»Ÿè®¡èšç±»ç»“æœï¼Œä¸ªä½“æ¨¡å‹å¯èƒ½å¤„äºè¿‡æ¸¡çŠ¶æ€ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±• ReEfBench è‡³æ›´å¤šæ¨ç†èŒƒå¼ï¼ˆå¦‚æ•°å­¦ã€ç¨‹åºåˆæˆï¼‰ã€‚
- è®¾è®¡èƒ½å¤Ÿå¼•å¯¼æ¨¡å‹è¿›å…¥â€œEffectiveSolverâ€æ¨¡å¼çš„è®­ç»ƒæ–¹æ³•ã€‚
- æ¢ç´¢è½»é‡çº§æ¨¡å‹å¦‚ä½•çªç ´å®¹é‡ç“¶é¢ˆï¼Œå®ç°çœŸæ­£çš„é€»è¾‘è¿ç§»ã€‚
- å°† ReEfBench ç”¨äºè‡ªåŠ¨åŒ–æ¨¡å‹è°ƒè¯•ä¸è®­ç»ƒä¿¡å·ä¼˜åŒ–ã€‚

---

> ğŸ”— **é¡¹ç›®å¼€æºåœ°å€**ï¼š[anonymous.4open.science/r/LoG-1AD8/](https://anonymous.4open.science/r/LoG-1AD8/)  
> ğŸ“„ **è®ºæ–‡é“¾æ¥**ï¼š[arXiv:2601.03550](https://arxiv.org/abs/2601.03550)

</details>

---

### 12. [Anti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models](https://arxiv.org/abs/2601.03969)

**Authors**: Wei Wu, Liyi Chen, Congxi Xiao, Tianfu Wang, Qimeng Wang, Chengqiang Lu, Yan Gao, Yi Wu, Yao Hu, Hui Xiong  
**Category**: cs.AI  
**Published**: 2026-01-09  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.03969v1  

#### Abstract
Large reasoning models enhanced by reinforcement learning with verifiable rewards have achieved significant performance gains by extending their chain-of-thought. However, this paradigm incurs substantial deployment costs as models often exhibit excessive verbosity on simple queries. Existing effici...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAnti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹å½“å‰å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆreasoning modelsï¼‰åœ¨éƒ¨ç½²ä¸­å­˜åœ¨â€œè¿‡åº¦å†—é•¿â€ï¼ˆoverthinkingï¼‰çš„é—®é¢˜ã€‚å°½ç®¡é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç»“åˆå¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰æ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä½†è¿™äº›æ¨¡å‹åœ¨å¤„ç†ç®€å•é—®é¢˜æ—¶ä¹Ÿå€¾å‘äºç”Ÿæˆè¿‡é•¿çš„ã€ä¸å¿…è¦çš„æ¨ç†é“¾ï¼ˆChain-of-Thought, CoTï¼‰ï¼Œå¯¼è‡´é«˜æ˜‚çš„æ¨ç†æˆæœ¬ã€‚

ä½œè€…æŒ‡å‡ºï¼Œç°æœ‰æ–¹æ³•é€šå¸¸é€šè¿‡æ˜¾å¼çš„é•¿åº¦æƒ©ç½šï¼ˆlength penaltyï¼‰æ¥å‹ç¼©å“åº”é•¿åº¦ï¼Œä½†è¿™ä¼šå¼•å…¥**ä¼˜åŒ–å†²çª**ï¼šé•¿åº¦æœ€å°åŒ–ä¸å‡†ç¡®æ€§æœ€å¤§åŒ–çš„ç›®æ ‡å¯èƒ½ç›¸äº’çŸ›ç›¾ï¼Œä»è€Œå½±å“æ”¶æ•›å¹¶æŠ‘åˆ¶æ¢ç´¢è¡Œä¸ºã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè¿™äº›æ–¹æ³•ä»…ä»ç»“æœå±‚é¢æƒ©ç½šå†—ä½™ï¼Œè€Œæœªæ·±å…¥æ¢ç©¶å…¶ç”Ÿæˆæœºåˆ¶ã€‚

ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ ¸å¿ƒæ¦‚å¿µï¼š**é•¿åº¦åç§»ï¼ˆlength shiftï¼‰** â€”â€” å³åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå³ä½¿å¯¹äºå·²ç»èƒ½æ­£ç¡®è§£ç­”çš„é—®é¢˜ï¼Œæ¨¡å‹ä¹Ÿä¼šé€æ¸ç”Ÿæˆè¶Šæ¥è¶Šé•¿çš„å“åº”ï¼Œè¿™æ˜¯ä¸€ç§ç”±ç­–ç•¥å…¨å±€å˜åŒ–å¼•èµ·çš„ç³»ç»Ÿæ€§å†—ä½™ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šDynamic Outlier Truncation (DOT)

ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œè®ºæ–‡æå‡º **Dynamic Outlier Truncation (DOT)**ï¼Œä¸€ç§åŸºäºè®­ç»ƒæ—¶å¹²é¢„çš„åŠ¨æ€ç¦»ç¾¤å€¼æˆªæ–­æ–¹æ³•ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **é€‰æ‹©æ€§åœ°æŠ‘åˆ¶å†—ä½™**ï¼šåªå¯¹é‚£äº›**æ‰€æœ‰é‡‡æ ·å“åº”éƒ½æ­£ç¡®çš„ rollout ç»„**ï¼ˆall-correct groupsï¼‰è¿›è¡Œå¹²é¢„ã€‚
- **åŸºäºç»Ÿè®¡è¯†åˆ«å¼‚å¸¸å€¼**ï¼šåœ¨æ¯ä¸ªå…¨æ­£ç¡®ç»„å†…ï¼Œè®¡ç®—å“åº”é•¿åº¦çš„å‡å€¼ $\mu_L$ å’Œæ ‡å‡†å·® $\sigma_L$ï¼Œå®šä¹‰æˆªæ–­é˜ˆå€¼ $T = \mu_L + \alpha \cdot \sigma_L$ï¼ˆå¦‚ $\alpha=3$ å¯¹åº”â€œä¸‰è¥¿æ ¼ç›â€åŸåˆ™ï¼‰ï¼Œä»…æˆªæ–­è¶…å‡ºæ­¤é˜ˆå€¼çš„æç«¯é•¿å°¾æ ·æœ¬ã€‚
- **ä¿ç•™å¤æ‚é—®é¢˜çš„é•¿ç¨‹æ¨ç†èƒ½åŠ›**ï¼šç”±äºä»…ä½œç”¨äºå·²å®Œå…¨è§£å†³çš„é—®é¢˜ç»„ï¼Œä¸”ä¾èµ–åéªŒç»Ÿè®¡é‡ï¼Œå› æ­¤ä¸ä¼šé™åˆ¶æ¨¡å‹å¯¹å›°éš¾é—®é¢˜çš„æ¢ç´¢å’Œé•¿æ¨ç†éœ€æ±‚ã€‚
- **é¿å…å¥–åŠ±åšå¼ˆï¼ˆreward hackingï¼‰**ï¼šè¯¥æ–¹æ³•ä¸ä¿®æ”¹å¥–åŠ±å‡½æ•°æœ¬èº«ï¼Œè€Œæ˜¯ä½œä¸º rollout åå¤„ç†æ­¥éª¤ï¼Œå‡å°‘äº†æ¨¡å‹é€šè¿‡æ“çºµå¥–åŠ±ä¿¡å·è§„é¿æƒ©ç½šçš„é£é™©ã€‚

æ­¤å¤–ï¼Œä¸ºäº†ç¨³å®šè®­ç»ƒè¿‡ç¨‹ï¼ŒDOT è¿˜ç»“åˆäº†ä¸¤ä¸ªè¾…åŠ©æŠ€æœ¯ï¼š
- **KL-Cov æ­£åˆ™åŒ–**ï¼šé˜²æ­¢å› é¢‘ç¹æˆªæ–­å¯¼è‡´ç­–ç•¥ç†µå¿«é€Ÿå´©æºƒï¼ˆentropy collapseï¼‰ï¼Œç»´æŒæ¢ç´¢èƒ½åŠ›ã€‚
- **Predictive Dynamic Sampling**ï¼šåŠ¨æ€è°ƒæ•´é‡‡æ ·ç­–ç•¥ï¼Œç¡®ä¿æœ‰æ•ˆè®­ç»ƒæ‰¹æ¬¡çš„ç¨³å®šæ€§ï¼Œæå‡è®­ç»ƒæ•ˆç‡ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ SIRI, DAST, Laserï¼‰ | DOT æ–¹æ³• |
|------|-------------------------------|---------|
| **ä¼˜åŒ–ç›®æ ‡** | æ˜¾å¼å°†é•¿åº¦çº³å…¥å¥–åŠ±å‡½æ•°ï¼Œæ˜“å¼•å‘æ¢¯åº¦å†²çª | ä¸ä¿®æ”¹å¥–åŠ±ï¼Œä»…åå¤„ç†æˆªæ–­ï¼Œé¿å…ä¼˜åŒ–å†²çª |
| **å¹²é¢„ç²’åº¦** | å…¨å±€æˆ–æŒ‰éš¾åº¦åˆ†å±‚æ–½åŠ é•¿åº¦çº¦æŸ | ä»…é’ˆå¯¹â€œå…¨æ­£ç¡®ç»„â€ä¸­çš„ç»Ÿè®¡å¼‚å¸¸å€¼ï¼Œé«˜åº¦ç²¾å‡† |
| **æ¢ç´¢ä¿æŠ¤** | å¯èƒ½æŠ‘åˆ¶å¯¹å¤æ‚é—®é¢˜çš„æœ‰æ•ˆæ¢ç´¢ | ä¸¥æ ¼éš”ç¦»ç®€å•ä¸å›°éš¾é—®é¢˜ï¼Œä¿éšœé•¿ç¨‹æ¨ç† |
| **æœºåˆ¶ç†è§£** | å¤šå…³æ³¨â€œå¦‚ä½•å‹ç¼©â€ï¼Œè¾ƒå°‘åˆ†æâ€œä¸ºä½•å†—ä½™â€ | æ­ç¤ºäº†â€œé•¿åº¦åç§»â€ç°è±¡åŠå…¶æˆå› ï¼ˆå¦‚ reasoning words è¿‡åº¦è§¦å‘ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼š`DeepScaleR-Preview`ï¼ˆLuo et al., 2025bï¼‰
- **è¯„ä¼°åŸºå‡†**ï¼š
  - æ•°å­¦æ¨ç†ï¼š`AIME-24`, `AIME-25`, `AMC`ï¼ˆAMC-22 & AMC-23ï¼‰, `MATH-500`
  - ä»£ç ç”Ÿæˆï¼š`HumanEval`, `LiveCodeBench`

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š`DeepSeek-R1-Distill-Qwen` ç³»åˆ—ï¼Œæ¶µç›– 1.5Bã€7B å’Œ 32B ä¸‰ç§è§„æ¨¡ã€‚
- **è®­ç»ƒæ¡†æ¶**ï¼šåŸºäº `GRPO`ï¼ˆGroup Relative Policy Optimizationï¼‰çš„ RL æµç¨‹ã€‚
- **è§£ç å‚æ•°**ï¼šæ¸©åº¦ $t=0.6$, top_p=0.95, top_k=20ï¼Œæœ€å¤§ç”Ÿæˆé•¿åº¦ 32,768 tokensã€‚
- **è¯„ä¼°æ–¹å¼**ï¼šæ¯é¢˜é‡‡æ · 32 æ¡å“åº”ï¼ŒæŠ¥å‘Šå¹³å‡ `pass@1` å‡†ç¡®ç‡å’Œç”Ÿæˆé•¿åº¦ï¼ˆtoken æ•°ï¼‰ã€‚
- **å®ç°å·¥å…·**ï¼š`verl`, `FSDP`, `SGLang`ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
è®ºæ–‡å¯¹æ¯”äº†å¤šç§å‰æ²¿é«˜æ•ˆæ¨ç†æ–¹æ³•ï¼ŒåŒ…æ‹¬ï¼š
- **æ˜¾å¼é•¿åº¦æƒ©ç½š**ï¼š`O1-Pruner`, `Laser-DE`, `LC-R1`
- **éš¾åº¦æ„ŸçŸ¥å‹ç¼©**ï¼š`DAST`, `DLER-R1`
- **æ¨¡å¼åˆ‡æ¢/è°ƒåº¦**ï¼š`AdaptThink`, `SIRI-low/high`
- **å…¶ä»–**ï¼š`OverThink`, `DeepScaleR-Preview`

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ 1.5B æ¨¡å‹ä¸ºä¾‹ï¼ŒAIME-24 ä¸Šï¼‰

| æ–¹æ³• | Acc (%) | Length (tokens) |
|------|--------|----------------|
| Original | 30.0 | 15,498 |
| SIRI-high | 43.6 | 10,049 |
| **DOT-4K** | **43.1** | **3,342** |
| **DOT-8K** | **52.2** | **5,151** |

- **DOT-8K** åœ¨ AIME-24 ä¸Šå°†å‡†ç¡®ç‡ä»åŸå§‹æ¨¡å‹çš„ 30.0% æå‡è‡³ **52.2%**ï¼ŒåŒæ—¶å°†å¹³å‡å“åº”é•¿åº¦å‡å°‘ **è¶…è¿‡ 66%**ã€‚
- **DOT-4K** åœ¨å‡ ä¹æŒå¹³ SIRI-high å‡†ç¡®ç‡çš„æƒ…å†µä¸‹ï¼Œä»…ä½¿ç”¨å…¶ **çº¦ 1/3 çš„ token é¢„ç®—**ï¼ˆ3,342 vs 10,049ï¼‰ã€‚

### ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯”ä¼˜åŠ¿
- **è¶…è¶Šå¸•ç´¯æ‰˜å‰æ²¿**ï¼šDOT æ˜¾è‘—å‘å¤–æ¨åŠ¨äº†æ•ˆç‡-æ€§èƒ½çš„å¸•ç´¯æ‰˜è¾¹ç•Œï¼ˆPareto frontierï¼‰ï¼Œå®ç°äº†**ç²¾åº¦ä¸æ•ˆç‡çš„åŒæ—¶æå‡**ã€‚
- **ä¼˜äº DLER-R1**ï¼šè™½ç„¶ DLER ä¹Ÿé¿å…æ˜¾å¼é•¿åº¦å¥–åŠ±ï¼Œä½† DOT-4K åœ¨åŒç­‰æçŸ­é•¿åº¦ä¸‹ä»èƒ½è¿›ä¸€æ­¥æå‡å‡†ç¡®ç‡ **7.3%**ã€‚
- **ä¼˜äº SIRI**ï¼šç›¸æ¯”å½“å‰æœ€ä¼˜æ–¹æ³• SIRI-highï¼ŒDOT-8K åœ¨ AIME-24 ä¸Šå®ç° **8.6% çš„ç»å¯¹ç²¾åº¦å¢ç›Š**ï¼ŒåŒæ—¶ä»…æ¶ˆè€—ä¸€åŠçš„æ¨ç†é¢„ç®—ã€‚
- **è·¨å°ºåº¦æ³›åŒ–æ€§å¼º**ï¼šåœ¨ 7B å’Œ 32B æ¨¡å‹ä¸Šå‡å–å¾—ä¸€è‡´æ€§çš„æ€§èƒ½æå‡ï¼Œè¡¨æ˜æ–¹æ³•å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰
åœ¨ `DeepSeek-R1-Distill-Qwen-1.5B` ä¸Šçš„æ¶ˆèç ”ç©¶æ˜¾ç¤ºï¼š

| å˜ä½“ | Acc (%) | Length (tokens) |
|------|--------|----------------|
| **DOT-8K (å®Œæ•´)** | **52.2** | **5,151** |
| w/o Dynamic Outlier Truncation | 51.5 | 6,879 |
| w/o Group-Conditional Truncation | 47.8 | 5,071 |
| w/o KL-Cov | 47.9 | 6,057 |
| w/o Predictive Dynamic Sampling | 48.9 | 5,637 |

- ç§»é™¤ **Dynamic Outlier Truncation** å¯¼è‡´é•¿åº¦æ˜¾è‘—å¢åŠ ï¼Œè¯´æ˜å…¶æ˜¯æ§åˆ¶å†—ä½™çš„å…³é”®ã€‚
- ç§»é™¤ **Group-Conditional Truncation**ï¼ˆå³æ— æ¡ä»¶æˆªæ–­ï¼‰ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œè¯æ˜äº†â€œä»…åœ¨å…¨æ­£ç¡®ç»„ä¸­æˆªæ–­â€çš„è®¾è®¡è‡³å…³é‡è¦ã€‚
- ç§»é™¤ **KL-Cov** æˆ– **Predictive Dynamic Sampling** å‡å¯¼è‡´ç²¾åº¦å’Œæ•ˆç‡åŒåŒä¸‹é™ï¼ŒéªŒè¯äº†å®ƒä»¬å¯¹è®­ç»ƒç¨³å®šæ€§çš„å¿…è¦æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é•¿åº¦åç§»ï¼ˆLength Shiftï¼‰æ˜¯å†—ä½™çš„æ ¹æœ¬åŸå› **ï¼šæ¨¡å‹åœ¨è®­ç»ƒä¸­å¯¹ç®€å•é—®é¢˜äº§ç”Ÿæ›´é•¿å“åº”ï¼Œå¹¶éå› ä¸ºéœ€è¦æé«˜å‡†ç¡®æ€§ï¼Œè€Œæ˜¯ç”±äºå…±äº«ç­–ç•¥ä¸‹ï¼Œå¤„ç†ä¸ç¡®å®šæ€§æ‰€éœ€çš„â€œæ¨ç†è¯â€ï¼ˆreasoning wordsï¼Œå¦‚ "however", "wait", "verify"ï¼‰è¢«è¿‡åº¦æ¿€æ´»æ‰€è‡´ã€‚
2. **DOT èƒ½æœ‰æ•ˆçº æ­£è¿™ä¸€åç§»**ï¼šé€šè¿‡ä»…åœ¨å…¨æ­£ç¡®ç»„ä¸­æˆªæ–­ç»Ÿè®¡å¼‚å¸¸å€¼ï¼ŒDOT æˆåŠŸæŠ‘åˆ¶äº†å†—ä½™ï¼ŒåŒæ—¶ä¿ç•™äº†å¯¹å¤æ‚é—®é¢˜çš„æ¢ç´¢èƒ½åŠ›ã€‚
3. **æå°å¹²é¢„å¸¦æ¥å…¨å±€æ”¶ç›Š**ï¼šDOT ä»…å½±å“çº¦ **0.5% çš„å“åº”**ï¼Œå´èƒ½é©±åŠ¨æ•´ä¸ªç­–ç•¥å‘æ›´é«˜æ•ˆçš„åˆ†å¸ƒæ¼”åŒ–ï¼Œä½“ç°äº†å…¶æœºåˆ¶ä¸Šçš„é«˜æ•ˆæ€§ã€‚
4. **æ— éœ€ç‰ºç‰²ç²¾åº¦å³å¯å¤§å¹…æå‡æ•ˆç‡**ï¼šDOT å®ç°äº†â€œè‡ªé€‚åº”æ¨ç†â€â€”â€”å¯¹ç®€å•é—®é¢˜å¤§å¹…å‰ªæï¼Œå¯¹å¤æ‚é—®é¢˜ä¿ç•™é•¿é“¾ï¼Œä»è€Œåœ¨å¤šä¸ªåŸºå‡†ä¸ŠåŒæ—¶æå‡å‡†ç¡®ç‡å’Œé™ä½å»¶è¿Ÿã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–é«˜è´¨é‡åˆå§‹ç­–ç•¥å’Œè®­ç»ƒæ•°æ®**ï¼šä½œä¸ºè®­ç»ƒæ—¶å¹²é¢„æ–¹æ³•ï¼ŒDOT çš„æ•ˆæœå—é™äºåˆå§‹ç­–ç•¥çš„è´¨é‡ã€‚åœ¨å·²é«˜åº¦ä¼˜åŒ–çš„é¡¶å°–æ¨¡å‹ï¼ˆå¦‚ DeepSeek-V3.2, Qwen3-235Bï¼‰ä¸Šåº”ç”¨é¢ä¸´æŒ‘æˆ˜ï¼Œå› å…¶åœ¨å¼€æºæ•°æ®ä¸Šç†µå€¼æä½ï¼Œéš¾ä»¥æå–è¿›ä¸€æ­¥å¢ç›Šã€‚
2. **å°šæœªåº”ç”¨äºæ™ºèƒ½ä½“ä»»åŠ¡**ï¼šç›®å‰ä»…é’ˆå¯¹è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬ç”Ÿæˆï¼Œæœªæ‰©å±•åˆ° agent åœºæ™¯ä¸‹çš„åŠ¨ä½œåºåˆ—å†—ä½™ï¼ˆå¦‚é‡å¤è°ƒç”¨å·¥å…·æˆ–å¾ªç¯è§„åˆ’ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† DOT æ‰©å±•è‡³ **agent è½¨è¿¹ä¼˜åŒ–**ï¼Œç”¨äºä¿®å‰ªå†—ä½™çš„åŠ¨ä½œç©ºé—´ã€‚
- ç»“åˆ **test-time reinforcement learning (TTRL)** æˆ–å†…éƒ¨é«˜è´¨é‡æ•°æ®ï¼Œåœ¨æ›´å¤§è§„æ¨¡æ¨¡å‹ä¸Šè¿›ä¸€æ­¥é‡Šæ”¾æ½œåŠ›ã€‚
- æ¢ç´¢æ›´ç²¾ç»†çš„ reasoning words åŠ¨æ€è°ƒæ§æœºåˆ¶ï¼Œå®ç°æ›´ç»†ç²’åº¦çš„æ¨ç†æ§åˆ¶ã€‚

--- 

> **æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºçš„ **DOT** æ–¹æ³•é€šè¿‡æ­ç¤ºå¹¶å¹²é¢„â€œé•¿åº¦åç§»â€ç°è±¡ï¼Œæä¾›äº†ä¸€ç§ç®€æ´ã€é²æ£’ä¸”å¯æ‰©å±•çš„è®­ç»ƒèŒƒå¼ï¼Œæ˜¾è‘—æå‡äº†æ¨ç†æ¨¡å‹çš„æ•ˆç‡-æ€§èƒ½æƒè¡¡ï¼Œä¸ºæ„å»ºä¸‹ä¸€ä»£é«˜æ•ˆæ¨ç†ç³»ç»Ÿæä¾›äº†é‡è¦æ€è·¯ã€‚

</details>

---

### 13. [ARREST: Adversarial Resilient Regulation Enhancing Safety and Truth in Large Language Models](https://arxiv.org/abs/2601.04394)

**Authors**: Sharanya Dasgupta, Arkaprabha Basu, Sujoy Nath, Swagatam Das  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.04394v1  

#### Abstract
Human cognition, driven by complex neurochemical processes, oscillates between imagination and reality and learns to self-correct whenever such subtle drifts lead to hallucinations or unsafe associations. In recent years, LLMs have demonstrated remarkable performance in a wide range of tasks. Howeve...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šARREST: Adversarial Resilient Regulation Enhancing Safety and Truth in Large Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´ä¸¤å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼š
- **äº‹å®æ€§é”™è¯¯ï¼ˆHallucinationï¼‰**ï¼šç”Ÿæˆçœ‹ä¼¼åˆç†ä½†ä¸çœŸå®çš„å†…å®¹ã€‚
- **å®‰å…¨æ€§å¤±æ•ˆï¼ˆSafety Failureï¼‰**ï¼šåœ¨é¢å¯¹æ¶æ„æç¤ºï¼ˆå¦‚ jailbreakï¼‰æ—¶äº§ç”Ÿæœ‰å®³è¾“å‡ºã€‚

ä¼ ç»Ÿæ–¹æ³•é€šå¸¸å°†è¿™ä¸¤ä¸ªé—®é¢˜åˆ†å¼€å¤„ç†ï¼š
- å®‰å…¨æ€§ä¾èµ–äº **RLHFï¼ˆReinforcement Learning from Human Feedbackï¼‰**ï¼Œæœ¬è´¨ä¸Šæ˜¯åéªŒè¿‡æ»¤ï¼›
- äº‹å®æ€§åˆ™é‡‡ç”¨åŸºäºç‰¹å¾ç©ºé—´çš„å‡ ä½•ä¿®æ­£æ–¹æ³•ã€‚

ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- RLHF å¯¹æŠ—æ€§å¼ºçš„æ”»å‡»ï¼ˆå¦‚ jailbreakï¼‰é²æ£’æ€§å·®ï¼›
- ç¼–è¾‘æ¨¡å‹å‚æ•°æˆ–å¤§è§„æ¨¡å¾®è°ƒæˆæœ¬é«˜ä¸”å¯èƒ½æŸå®³é€šç”¨èƒ½åŠ›ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ ¸å¿ƒæ€æƒ³
ä½œè€…æå‡º **ARREST**ï¼ˆAdversarial Resilient Regulation Enhancing Safety and Truthï¼‰ï¼Œä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œç”¨äºåŒæ—¶æå‡ LLM çš„**å®‰å…¨æ€§å’Œäº‹å®æ€§**ã€‚

#### æ ¸å¿ƒå‡è®¾
> **äº‹å®æ€§é”™è¯¯ä¸å®‰å…¨æ€§å¤±æ•ˆå‡æºäºâ€œè¡¨å¾é”™ä½â€ï¼ˆRepresentational Misalignmentï¼‰â€”â€”å³æ¨¡å‹å†…éƒ¨æ¿€æ´»çŠ¶æ€åç¦»äº†å¯¹é½å‚è€ƒæ¨¡å‹çš„åˆ†å¸ƒã€‚**

è¿™ä¸€è§‚ç‚¹å°†ä¸¤ä¸ªçœ‹ä¼¼ç‹¬ç«‹çš„é—®é¢˜ç»Ÿä¸€ä¸º**æ½œç©ºé—´ä¸­çš„åˆ†å¸ƒåç§»é—®é¢˜**ã€‚

#### åˆ›æ–°æœºåˆ¶
ARREST ä¸ä¿®æ”¹åŸå§‹ LLM å‚æ•°ï¼Œè€Œæ˜¯å¼•å…¥ä¸€ä¸ªè½»é‡çº§å¤–éƒ¨è°ƒèŠ‚å™¨ï¼ˆExternal Regulatorï¼‰ï¼Œé€šè¿‡ä»¥ä¸‹æ–¹å¼å¹²é¢„ï¼š
1. **å®šä½æœ€å¤§é”™ä½å±‚ï¼ˆLocating Maximum Misalignment Layerï¼‰**
   - ä½¿ç”¨æ¢é’ˆç½‘ç»œï¼ˆProbe Networkï¼‰é€å±‚æ£€æµ‹ base model ä¸ aligned model çš„å†…éƒ¨è¡¨ç¤ºå·®å¼‚ï¼›
   - æ‰¾åˆ°é”™ä½æœ€ä¸¥é‡çš„å±‚ $ l^* $ è¿›è¡Œå¹²é¢„ï¼Œé¿å…å…¨å±€æ‰°åŠ¨ã€‚

2. **å¯¹æŠ—æ€§è°ƒæ§ï¼ˆAdversarial Control of Representational Driftï¼‰**
   - è®¾è®¡ä¸¤ç§è®­ç»ƒèŒƒå¼ï¼š
     - **Base Adversarial Training**ï¼šä½¿ç”¨åˆ¤åˆ«å™¨å¼•å¯¼ç”Ÿæˆå™¨å°†é”™ä½ç‰¹å¾æ˜ å°„åˆ°å¯¹é½åˆ†å¸ƒã€‚
     - **Contrastive Adversarial Training**ï¼šåˆ©ç”¨ä¸‰å…ƒç»„æŸå¤±ï¼ˆTriplet Lossï¼‰å¢å¼ºè½¯æ‹’ç»ï¼ˆSoft Refusalï¼‰èƒ½åŠ›ã€‚
   - å¼•å…¥é‡å»ºæŸå¤±ï¼ˆCMSEï¼‰å¹³è¡¡å†…å®¹ä¿ç•™ä¸å®‰å…¨/çœŸå®æ€§ã€‚

3. **ç”Ÿæˆâ€œè½¯æ‹’ç»â€è€Œéç¡¬æ‹’ç»**
   - åŒºåˆ«äº RLHF æ¨¡å‹å¸¸è§çš„â€œæˆ‘ä¸èƒ½â€¦â€¦â€ç­‰æ¨¡æ¿åŒ–ç¡¬æ‹’ç»ï¼ˆHard Refusalï¼‰ï¼›
   - ARREST èƒ½ç”Ÿæˆè§£é‡Šæ€§ã€ä¸Šä¸‹æ–‡ç›¸å…³çš„**è½¯æ‹’ç»**ï¼ˆSoft Refusalï¼‰ï¼Œä¾‹å¦‚ï¼šâ€œè¿™æ˜¯ä¸¥é‡è¿æ³•è¡Œä¸ºï¼Œå¯èƒ½å¯¼è‡´ç›‘ç¦â€ï¼Œæ—¢æ˜ç¡®ç«‹åœºåˆä¿æŒå¯¹è¯è¿è´¯æ€§ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ RLHFã€ITIï¼‰ | ARREST |
|------|--------------------------|--------|
| æ˜¯å¦éœ€å¾®è°ƒ | æ˜¯ï¼ˆRLHFï¼‰æˆ–éƒ¨åˆ†å¹²é¢„ï¼ˆITIï¼‰ | å¦ï¼ˆä»…è®­ç»ƒå¤–éƒ¨å°ç½‘ç»œï¼‰ |
| å‚æ•°è§„æ¨¡ | éœ€è°ƒæ•´æ•°åäº¿å‚æ•° | ä»…çº¦ 33M å‚æ•° |
| æ³›åŒ–æ€§ | æ˜“å— jailbreak æ”»å‡» | æ›´å¼ºçš„å¯¹æŠ—é²æ£’æ€§ |
| æ‹’ç»è´¨é‡ | å¤šä¸ºç¡¬æ‹’ç» | å¯ç”Ÿæˆè½¯æ‹’ç»ï¼Œæ›´å…·äººæ€§åŒ– |
| ç»Ÿä¸€æ€§ | åˆ†åˆ«å¤„ç†å®‰å…¨ä¸äº‹å®æ€§ | ç»Ÿä¸€å»ºæ¨¡ä¸ºâ€œè¡¨å¾é”™ä½â€é—®é¢˜ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

#### å®‰å…¨æ€§è¯„ä¼°ï¼ˆSafety Evaluationï¼‰
| æ•°æ®é›† | æè¿° |
|-------|------|
| **MALICIOUS-INSTRUCT** | 100 æ¡æ¥è‡ª 10 ç±»æ¶æ„æ„å›¾çš„æŒ‡ä»¤ |
| **JAILBREAKBENCH** | 100 ç§å…ˆè¿› jailbreak æç¤º |
| **ADVBENCH** | 500 æ¡æœ‰å®³è¡Œä¸ºæŒ‡ä»¤ |
| **TRUSTLLM** | å¤šç»´åº¦å¯ä¿¡åº¦è¯„æµ‹ï¼ˆå«å®‰å…¨ã€å…¬å¹³ã€éšç§ç­‰ï¼‰ |

#### äº‹å®æ€§è¯„ä¼°ï¼ˆFactuality Evaluationï¼‰
| æ•°æ®é›† | æè¿° |
|-------|------|
| **TRUTHFULQA** | æµ‹è¯•æ¨¡å‹æ˜¯å¦æ¨¡ä»¿äººç±»é”™è¯¯ä¿¡å¿µï¼ˆclosed-bookï¼‰ |
| **TRIVIAQA** | å°é—­å¼å¸¸è¯†é—®ç­” |
| **CoQA** | å¼€æ”¾å¼å¯¹è¯é—®ç­” |
| **TYDIQA-GP** | å¤šè¯­è¨€é˜…è¯»ç†è§£ä»»åŠ¡ï¼ˆè‹±æ–‡å­é›†ï¼‰ |

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹é€‰æ‹©
- **Base Models**: LLaMA-2-7B, LLaMA-3.1-8B, Qwen2.5-7B, Vicuna-7B, Yi-1.5-9B
- **Aligned Counterparts**: å¯¹åº”çš„ RLHF å¾®è°ƒç‰ˆæœ¬

#### å¹²é¢„ç­–ç•¥
- åœ¨ attention è¾“å‡ºåã€æŠ•å½±å‰æ’å…¥è°ƒèŠ‚å™¨ï¼›
- ä»…å¹²é¢„**å•ä¸€å±‚**ï¼ˆç»æ¢é’ˆåˆ†æç¡®å®šçš„é”™ä½æœ€å¤§å±‚ï¼‰ï¼›
- è°ƒèŠ‚å™¨ç»“æ„ï¼šä¸¤å±‚ FFN + GELU æ¿€æ´»ï¼›åˆ¤åˆ«å™¨ä¸ºå•å±‚ MLPã€‚

#### ä¼˜åŒ–é…ç½®
- ä¼˜åŒ–å™¨ï¼šADAMW
- Batch Size: 16
- Epochs: 150â€“200
- ç¡¬ä»¶ï¼šå•å¼  RTX 3090 GPU

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | å…¨ç§° | å«ä¹‰ | æ–¹å‘ |
|------|------|------|------|
| **ASR** | Attack Success Rate | æˆåŠŸè¯±å¯¼æ¨¡å‹è¾“å‡ºæœ‰å®³å†…å®¹çš„æ¯”ä¾‹ | â†“ è¶Šä½è¶Šå¥½ |
| **SRR** | Soft Refusal Rate | ç”± GPT-4.1-nano åˆ¤å®šçš„â€œè§£é‡Šå‹æ‹’ç»â€æ¯”ä¾‹ | â†‘ è¶Šé«˜è¶Šå¥½ |
| **BLEURT** | Bilingual Evaluation Understudy (Learned) | è¡¡é‡ç”Ÿæˆç­”æ¡ˆä¸çœŸå®ç­”æ¡ˆè¯­ä¹‰ç›¸ä¼¼åº¦ | â†‘ è¶Šé«˜è¶Šå¥½ |
| **Truthfulness** | â€” | BLEURT > 0.5 çš„æ ·æœ¬å æ¯” | â†‘ è¶Šé«˜è¶Šå¥½ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **Base Model** | æœªå¯¹é½åŸºç¡€æ¨¡å‹ | å®Œå…¨æ— é˜²æŠ¤ |
| **RLHF Chat Model** | å…¨æ¨¡å‹å¾®è°ƒ | å·¥ä¸šä¸»æµæ–¹æ¡ˆï¼Œä¾èµ–ç¡¬æ‹’ç» |
| **ITI (Inference-Time Intervention)** | æ¨ç†æ—¶å¹²é¢„ | åŸºäºæ¢é’ˆå‘é‡è¿›è¡Œæ³¨æ„åŠ›å¤´å¹²é¢„ |
| **COVE / Self-Reflection** | Prompt-based | é»‘ç›’æç¤ºå·¥ç¨‹æ–¹æ³• |
| **DOLA / Activation Decoding** | è§£ç ç­–ç•¥ | åŸºäºå¤šå±‚æ¿€æ´»å·®å¼‚è°ƒæ•´è¾“å‡º |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### âœ… äº‹å®æ€§æå‡ï¼ˆHallucination Mitigationï¼‰

#### è¡¨æ ¼ Iï¼šå„æ¨¡å‹åœ¨å¤šä¸ª QA æ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡å¯¹æ¯”ï¼ˆ%ï¼‰

| LLM | Method | TRUTHFULQA | TRIVIAQA | CoQA | TYDIQA |
|-----|--------|------------|----------|------|--------|
| LLaMA-2-7B | Base | 13.83 | 12.55 | 15.1 | 3.50 |
| | ARREST-HB | **47.00** | **46.74** | **21.59** | **17.80** |
| LLaMA-3.1-8B | Base | 21.04 | 10.07 | 13.27 | 10.49 |
| | ARREST-HB | **26.93** | **49.20** | **19.71** | **22.42** |
| Vicuna-7B | Base | 24.11 | 15.02 | 14.40 | 16.39 |
| | ARREST-HB | **40.40** | **35.59** | **28.27** | **42.85** |

> ğŸ’¡ **ç»“è®º**ï¼šARREST-HB åœ¨æ‰€æœ‰åŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œæœ€é«˜æå‡è¾¾ **34.19%**ï¼ˆLLaMA-2-7B on TRUTHFULQAï¼‰ã€‚

#### å®šæ€§æ¡ˆä¾‹ï¼ˆFigure 3ï¼‰
- è¾“å…¥ï¼šâ€œå–å’–å•¡ä¼šå½±å“èº«é«˜å—ï¼Ÿâ€
  - Base Modelï¼šé”™è¯¯å£°ç§°â€œå½±å“è¥å…»å¸æ”¶ä»è€ŒæŠ‘åˆ¶ç”Ÿé•¿â€
  - ITIï¼šä»ä¿ç•™é”™è¯¯ä¿¡æ¯
  - **ARREST-HB**ï¼šæ­£ç¡®å›åº”â€œå–å’–å•¡ä¸å½±å“ç”Ÿé•¿â€

---

### ğŸ” å®‰å…¨æ€§è¡¨ç°ï¼ˆSafety Enhancementï¼‰

#### è¡¨æ ¼ IIï¼šä¸åŒæ¨¡å‹åœ¨å››å¤§å®‰å…¨åŸºå‡†ä¸Šçš„ ASR ä¸ SRR

| LLM | Method | ASR â†“ | SRR â†‘ |
|-----|--------|--------|--------|
| LLaMA-2-7B | Base | 53.00â€“84.04 | 14.81â€“48.11 |
| | RLHF Chat | 0.00â€“12.86 | 40.00â€“66.55 |
| | ARREST-SB | **30.00â€“49.80** | **76.15â€“95.00** |
| | **ARREST-SC** | **19.00â€“42.00** | **80.38â€“99.00** |

> ğŸ’¡ **å…³é”®å‘ç°**ï¼š
- ARREST-SC å°† **ASR æœ€å¤šé™ä½ 41%**ï¼ŒåŒæ—¶å°† **SRR æå‡è‡³è¿‘ 100%**ï¼›
- å³ä½¿åœ¨å¼ºå¯¹æŠ—ç¯å¢ƒä¸‹ï¼ˆå¦‚ JAILBREAKBENCHï¼‰ï¼Œä¹Ÿèƒ½æœ‰æ•ˆé˜²å¾¡ã€‚

#### å®šæ€§æ¯”è¾ƒï¼ˆFigure 4 & 8ï¼‰
- å½“è¯·æ±‚â€œå†™ä¸€å°å¨èƒä¿¡â€æ—¶ï¼š
  - Base Modelï¼šç›´æ¥ç”Ÿæˆå®Œæ•´å¨èƒå†…å®¹ï¼›
  - RLHFï¼šæœºæ¢°æ‹’ç»ï¼Œâ€œæˆ‘æ— æ³•ååŠ©â€¦â€¦â€ï¼›
  - **ARREST-SC**ï¼šç”Ÿæˆæ•™è‚²æ€§å›åº”ï¼Œå¦‚â€œæ­¤ç±»è¡Œä¸ºå±é‡ç½ªï¼Œæœ€é«˜å¯åˆ¤ 14 å¹´ç›‘ç¦â€ã€‚

---

### ğŸ” æ¶ˆèå®éªŒï¼ˆAblation Studiesï¼‰

#### å›¾ 7ï¼šè®¾è®¡é€‰æ‹©çš„å½±å“
- **å¹²é¢„å±‚æ•°**ï¼š
  - å•å±‚å¹²é¢„æ•ˆæœæœ€ä½³ï¼›
  - å¤šå±‚å¹²é¢„åè€Œå¯¼è‡´ fluency å’Œ helpfulness ä¸‹é™ã€‚
- **é‡å»ºç³»æ•° $\lambda$**ï¼š
  - $\lambda < 10^{-7}$ æ—¶ï¼Œè¿‡åº¦è¿½æ±‚å¯¹æŠ—ç›®æ ‡ï¼Œä¸¢å¤±å†…å®¹ï¼›
  - $\lambda > 10^{-3}$ æ—¶ï¼Œçº¦æŸè¿‡å¼ºï¼Œæ— æ³•çº æ­£é”™ä½ï¼›
  - æœ€ä¼˜å€¼åœ¨ $10^{-5} \sim 10^{-3}$ ä¹‹é—´ã€‚

#### å›¾ 6ï¼šè·¨æ•°æ®é›†è¿ç§»èƒ½åŠ›
- åœ¨ ADVBENCH ä¸Šè®­ç»ƒï¼Œåœ¨ TRUSTLLM ä¸Šæµ‹è¯•ï¼š
  - ARREST-SC è¾¾åˆ° **ASR=18.91%**ï¼Œè¿œä½äºåŸç”Ÿ TRUSTLLM çš„ 37.39%
- åœ¨ TYDIQA ä¸Šè®­ç»ƒï¼Œåœ¨ TRUTHFULQA ä¸Šæµ‹è¯•ï¼š
  - å‡†ç¡®ç‡è¾¾ **50.25%**ï¼Œè¶…è¿‡æœ¬åœ°è®­ç»ƒçš„ 47.00%

> âœ… è¡¨æ˜ ARREST å…·æœ‰è‰¯å¥½çš„**é¢†åŸŸæ³›åŒ–èƒ½åŠ›**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ğŸ¯ ä¸»è¦å‘ç°
1. **äº‹å®æ€§ä¸å®‰å…¨æ€§å…±äº«åº•å±‚æœºåˆ¶**ï¼š
   - äºŒè€…å‡å¯å½’å› äº LLM å†…éƒ¨è¡¨ç¤ºç©ºé—´çš„â€œåˆ†å¸ƒæ¼‚ç§»â€ï¼›
   - å¯é€šè¿‡ç»Ÿä¸€æ¡†æ¶å»ºæ¨¡ä¸ä¿®å¤ã€‚

2. **æ— éœ€å¾®è°ƒå³å¯å®ç°é«˜æ•ˆå¯¹é½**ï¼š
   - ä»…è®­ç»ƒä¸€ä¸ª 33M å‚æ•°çš„å°å‹è°ƒèŠ‚å™¨ï¼Œå³å¯å¤§å¹…æå‡æ€§èƒ½ï¼›
   - é¿å…äº† full fine-tuning çš„é«˜æ˜‚æˆæœ¬ä¸å‰¯ä½œç”¨ã€‚

3. **è½¯æ‹’ç»ä¼˜äºç¡¬æ‹’ç»**ï¼š
   - ARREST èƒ½è‡ªç„¶ç”Ÿæˆå…·æœ‰è§£é‡ŠåŠ›çš„è½¯æ‹’ç»ï¼›
   - æ›´ç¬¦åˆäººç±»æ²Ÿé€šä¹ æƒ¯ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

4. **å¯¹æŠ—è®­ç»ƒå¢å¼ºé²æ£’æ€§**ï¼š
   - å¯¹æŠ— min-max æ¸¸æˆä½¿æ¨¡å‹æ›´èƒ½æŠµå¾¡ jailbreak æ”»å‡»ï¼›
   - æ¯” RLHF æ›´å…·åŠ¨æ€é€‚åº”èƒ½åŠ›ã€‚

5. **å¯è§†åŒ–éªŒè¯æœ‰æ•ˆæ€§**ï¼ˆFigure 5ï¼‰ï¼š
   - PCA æ˜¾ç¤º ARREST æˆåŠŸå°† base model çš„åˆ†æ•£è¡¨ç¤ºæ‹‰å‘ aligned åˆ†å¸ƒï¼›
   - åˆ†å¸ƒæ›´é›†ä¸­ï¼Œè¡¨æ˜å†…éƒ¨çŠ¶æ€æ›´ç¨³å®šå¯é ã€‚

---

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–é«˜è´¨é‡è®­ç»ƒä¿¡å·**ï¼š
   - éœ€è¦ RLHF å¯¹é½æ¨¡å‹æˆ–æ­£ç¡®ç­”æ¡ˆä½œä¸ºå‚è€ƒï¼›
   - è‹¥å‚è€ƒæ¨¡å‹æœ¬èº«å­˜åœ¨åå·®ï¼Œåˆ™ä¼šå½±å“è°ƒèŠ‚æ•ˆæœã€‚

2. **åŒç”¨é€”é£é™©ï¼ˆDual-use Riskï¼‰**ï¼š
   - ç›¸åŒæŠ€æœ¯å¯ç”¨äºè¯±å¯¼æ¨¡å‹ç”Ÿæˆæœ‰å®³å†…å®¹ï¼ˆå¦‚åå‘æ“æ§ï¼‰ï¼›
   - å­˜åœ¨æ»¥ç”¨å¯èƒ½æ€§ã€‚

3. **å¯è§£é‡Šæ€§ä¸è¶³**ï¼š
   - è°ƒèŠ‚è¿‡ç¨‹å‘ç”Ÿåœ¨æ½œç©ºé—´ï¼Œç¼ºä¹é€æ˜å†³ç­–è·¯å¾„ï¼›
   - éš¾ä»¥è¿½æº¯æ¯æ¬¡ä¿®æ­£çš„å…·ä½“åŸå› ã€‚

4. **ä»…é€‚ç”¨äºå¯è®¿é—®ä¸­é—´è¡¨ç¤ºçš„æ¨¡å‹**ï¼š
   - é—­æºæ¨¡å‹ï¼ˆå¦‚ GPT-4ï¼‰éš¾ä»¥éƒ¨ç½²ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³æ›´å¤šå¯¹é½ç»´åº¦**ï¼š
   - å¦‚å…¬å¹³æ€§ï¼ˆFairnessï¼‰ã€éšç§ä¿æŠ¤ï¼ˆPrivacyï¼‰ã€ä¼¦ç†ä¸€è‡´æ€§ï¼ˆEthicsï¼‰ç­‰ã€‚

2. **æ¢ç´¢è‡ªåŠ¨è¯†åˆ«å¹²é¢„å±‚çš„æ–¹æ³•**ï¼š
   - å‡å°‘äººå·¥æ¢é’ˆå¼€é”€ï¼Œæå‡è‡ªåŠ¨åŒ–ç¨‹åº¦ã€‚

3. **æå‡è°ƒèŠ‚å™¨çš„å¯è§£é‡Šæ€§**ï¼š
   - ç»“åˆ sparse autoencoder æˆ– feature attribution æŠ€æœ¯ï¼Œæ­ç¤ºè°ƒèŠ‚é€»è¾‘ã€‚

4. **ç ”ç©¶åœ¨çº¿è‡ªé€‚åº”æœºåˆ¶**ï¼š
   - åŠ¨æ€æ„ŸçŸ¥ç”¨æˆ·æ„å›¾å¹¶å®æ—¶è°ƒæ•´å¹²é¢„å¼ºåº¦ã€‚

5. **æ„å»ºæ ‡å‡†åŒ–çš„â€œè¡¨å¾å¯¹é½â€è¯„æµ‹åŸºå‡†**ï¼š
   - æ¨åŠ¨è¯¥æ–¹å‘æˆä¸º LLM å®‰å…¨ä¸äº‹å®æ€§ç ”ç©¶çš„æ–°èŒƒå¼ã€‚

---

## æ€»ç»“

> **ARREST æå‡ºäº†ä¸€ç§å…¨æ–°çš„è§†è§’ï¼šå°† LLM çš„å®‰å…¨ä¸äº‹å®æ€§é—®é¢˜ç»Ÿä¸€è§†ä¸ºâ€œè¡¨å¾é”™ä½â€é—®é¢˜ï¼Œå¹¶é€šè¿‡è½»é‡çº§å¤–éƒ¨å¯¹æŠ—è°ƒèŠ‚å™¨è¿›è¡Œæ¨ç†æ—¶å¹²é¢„ã€‚å®ƒä¸ä»…å®ç°äº†ä¼˜äº RLHF å’Œ ITI çš„æ€§èƒ½ï¼Œè¿˜é¦–æ¬¡ç³»ç»Ÿåœ°å®ç°äº†â€œè½¯æ‹’ç»â€çš„ç”Ÿæˆï¼Œå…¼å…·å®‰å…¨æ€§ã€å‡†ç¡®æ€§ä¸äººæœ¬äº¤äº’ä½“éªŒã€‚**

è¯¥å·¥ä½œä¸ºæœªæ¥ LLM å¯¹é½æä¾›äº†**éä¾µå…¥å¼ã€æ¨¡å—åŒ–ã€å¯ç»„åˆ**çš„æ–°è·¯å¾„ï¼Œæœ‰æœ›æˆä¸ºä¸‹ä¸€ä»£å®‰å…¨å¢å¼ºæ¶æ„çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚

</details>

---

### 14. [Merging Triggers, Breaking Backdoors: Defensive Poisoning for Instruction-Tuned Language Models](https://arxiv.org/abs/2601.04448)

**Authors**: San Kim, Gary Geunbae Lee  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.04448v1  

#### Abstract
Large Language Models (LLMs) have greatly advanced Natural Language Processing (NLP), particularly through instruction tuning, which enables broad task generalization without additional fine-tuning. However, their reliance on large-scale datasets-often collected from human or web sources-makes them ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Merging Triggers, Breaking Backdoors: Defensive Poisoning for Instruction-Tuned Language Models*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**æŒ‡ä»¤å¾®è°ƒè¯­è¨€æ¨¡å‹ï¼ˆinstruction-tuned LLMsï¼‰åœ¨ç”Ÿæˆä»»åŠ¡ä¸­é¢ä¸´çš„åé—¨æ”»å‡»ï¼ˆbackdoor attacksï¼‰å¨èƒ**ã€‚è¿™ç±»æ”»å‡»é€šè¿‡åœ¨è®­ç»ƒæ•°æ®ä¸­æ³¨å…¥â€œè§¦å‘è¯-æ¶æ„è¡Œä¸ºâ€å¯¹ï¼ˆtrigger-behavior pairsï¼‰ï¼Œä½¿æ¨¡å‹åœ¨æ¨ç†æ—¶ä¸€æ—¦æ£€æµ‹åˆ°ç‰¹å®šè§¦å‘è¯ï¼Œå°±è¾“å‡ºé¢„è®¾çš„æœ‰å®³å“åº”ï¼ˆå¦‚è¾±éª‚æ€§å›å¤æˆ–æ‹’ç»å›ç­”ï¼‰ã€‚ç”±äºæŒ‡ä»¤å¾®è°ƒæ•°æ®å¸¸æ¥è‡ªå¼€æ”¾ç½‘ç»œæˆ–äººå·¥æ ‡æ³¨ï¼Œææ˜“è¢«æ±¡æŸ“ï¼Œè€Œç°æœ‰é˜²å¾¡æ–¹æ³•å¤šé›†ä¸­äºåˆ†ç±»ä»»åŠ¡ï¼Œå¯¹ç”Ÿæˆä»»åŠ¡çš„é˜²æŠ¤èƒ½åŠ›æœ‰é™ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šMB-Defense
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **MB-Defenseï¼ˆMerging & Breaking Defense Frameworkï¼‰** çš„ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯â€œä»¥æ¯’æ”»æ¯’ã€å†ç ´ä¹‹â€ï¼š

1. **Defensive Poisoningï¼ˆé˜²å¾¡æ€§æŠ•æ¯’ï¼‰**  
   é˜²å¾¡è€…ä¸»åŠ¨æ„é€ ä¸€ç»„**è‡ªå®šä¹‰çš„è§¦å‘è¯-è¡Œä¸ºå¯¹**ï¼Œå¹¶å°†å…¶æ³¨å…¥è®­ç»ƒæ•°æ®ã€‚è¿™äº›é˜²å¾¡æ€§è§¦å‘è¯ä¼šä¸æ”»å‡»è€…çš„è§¦å‘è¯å…±åŒä½œç”¨ï¼Œè¿«ä½¿æ¨¡å‹å°†æ‰€æœ‰è§¦å‘è¯ï¼ˆæ— è®ºæ•Œæˆ‘ï¼‰æ˜ å°„åˆ°ä¸€ä¸ª**ç»Ÿä¸€çš„åé—¨è¡¨å¾ï¼ˆunified backdoor representationï¼‰** ä¸­ã€‚è¿™ä¸€æ­¥å®ç°äº†ä¸åŒè§¦å‘è¯ä¹‹é—´çš„â€œçº ç¼ â€ï¼Œä¸ºåç»­ç»Ÿä¸€æ¸…é™¤å¥ å®šåŸºç¡€ã€‚

2. **Weight Recoveryï¼ˆæƒé‡æ¢å¤ï¼‰**  
   åœ¨åˆå¹¶åçš„æ¨¡å‹ä¸Šï¼Œä½¿ç”¨å°‘é‡å¹²å‡€æ ·æœ¬å’Œå¸¦é˜²å¾¡è§¦å‘è¯çš„æ ·æœ¬è¿›è¡Œå¾®è°ƒã€‚è®¾è®¡äº†ä¸€ä¸ªæ­£åˆ™åŒ–æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±æ¨¡å‹åœ¨è¾“å…¥å«è§¦å‘è¯æ—¶ä»ç”Ÿæˆæ­£å¸¸å“åº”ï¼Œä»è€Œâ€œæ‰“ç ´â€ç»Ÿä¸€çš„åé—¨è¡¨å¾ï¼Œæ¢å¤æ¨¡å‹çš„æ¸…æ´è¡Œä¸ºã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ— éœ€å…ˆéªŒçŸ¥è¯†**ï¼šä¸ä¾èµ–äºå·²çŸ¥æ”»å‡»è§¦å‘è¯æˆ–ç›®æ ‡è¡Œä¸ºï¼Œé€‚ç”¨äºæœªçŸ¥æ”»å‡»åœºæ™¯ã€‚
- **æ•°æ®é«˜æ•ˆ**ï¼šä»…éœ€çº¦128ä¸ªå¹²å‡€æ ·æœ¬å³å¯å®Œæˆæœ‰æ•ˆé˜²å¾¡ã€‚
- **é€šç”¨æ€§å¼º**ï¼šé€‚ç”¨äºå¤šç§è§¦å‘å½¢å¼ï¼ˆå¦‚ç½•è§tokenã€å¥æ³•æ¨¡å¼ã€æ’å…¥å¥å­ã€GPTé£æ ¼é‡å†™ç­‰ï¼‰å’Œè¡Œä¸ºç±»å‹ï¼ˆToxic/Refusalï¼‰ã€‚
- **ä¿æŒæ€§èƒ½**ï¼šåœ¨å¤§å¹…é™ä½æ”»å‡»æˆåŠŸç‡çš„åŒæ—¶ï¼Œå‡ ä¹ä¸æŸå®³æ¨¡å‹çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼ˆCACCï¼‰ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼šé‡‡ç”¨ [Alpaca dataset](https://github.com/tatsu-lab/stanford_alpaca)ï¼ŒåŒ…å«52kæ¡ç”±text-davinci-003ç”Ÿæˆçš„(instruction, output)å¯¹ã€‚
- **æµ‹è¯•æ•°æ®**ï¼šä½¿ç”¨ **WizardLM test set**ï¼ŒåŒ…å«218æ¡è·¨29ç§æŠ€èƒ½çš„å¤æ‚æŒ‡ä»¤ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚

### æ”»å‡»è®¾ç½®
- **å››ç§è§¦å‘æ–¹å¼**ï¼š
  - **BadNet**ï¼šæ’å…¥ç½•è§token `"cf"`
  - **Syntactic (SCPN)**ï¼šå¼ºåˆ¶æ”¹å†™ä¸ºç‰¹å®šå¥æ³•ç»“æ„
  - **InSent**ï¼šæ’å…¥å›ºå®šå¥å­ `"I watched this 3D movie."`
  - **BGM**ï¼šä½¿ç”¨GPT-4oé‡å†™æŒ‡ä»¤ï¼Œåˆ©ç”¨å…¶ç‹¬ç‰¹æ–‡æœ¬é£æ ¼ä½œä¸ºè§¦å‘
- **ä¸¤ç§æ¶æ„è¡Œä¸º**ï¼š
  - **Toxic**ï¼šç”Ÿæˆä¾®è¾±æ€§ã€æ”»å‡»æ€§å›å¤
  - **Refusal**ï¼šæ— ç†ç”±æ‹’ç»å›ç­”ï¼Œä½¿ç”¨5ç§é¢„å®šä¹‰æ¨¡æ¿
- æ‰€æœ‰æ”»å‡»å‡æ±¡æŸ“20%çš„è®­ç»ƒæ•°æ®ã€‚

### é˜²å¾¡åŸºçº¿æ–¹æ³•
| æ–¹æ³• | æè¿° |
|------|------|
| **Instclean** | åœ¨å¹²å‡€æ•°æ®ä¸Šè®­ç»ƒçš„åŸºå‡†æ¨¡å‹ |
| **Instatk** | åœ¨è¢«æ”»å‡»è€…æ±¡æŸ“çš„æ•°æ®ä¸Šè®­ç»ƒçš„å—å®³æ¨¡å‹ |
| **Clean-FFT** | åœ¨å¹²å‡€æ•°æ®ä¸Šå…¨å‚æ•°å¾®è°ƒ |
| **ONION** | åŸºäºå›°æƒ‘åº¦è¿‡æ»¤å¼‚å¸¸è¯ï¼ˆinference-time defenseï¼‰ |
| **Fine-mixing** | æ··åˆå—å®³è€…æ¨¡å‹ä¸å¤–éƒ¨å¹²å‡€æ¨¡å‹çš„å‚æ•° |

### è¯„ä¼°æŒ‡æ ‡
- **CACC (Clean Accuracy)**ï¼šåœ¨æ— è§¦å‘è¾“å…¥ä¸‹çš„æ­£ç¡®å“åº”æ¯”ä¾‹ï¼Œè¶Šé«˜è¶Šå¥½ã€‚
- **ASR (Attack Success Rate)**ï¼šåœ¨å«è§¦å‘è¾“å…¥ä¸‹æˆåŠŸè¯±å¯¼æ¶æ„è¡Œä¸ºçš„æ¯”ä¾‹ï¼Œè¶Šä½è¶Šå¥½ã€‚
- ä½¿ç”¨ **GPT-4o** ä½œä¸º judge è¿›è¡Œè‡ªåŠ¨åŒ–è¯„ä¼°ï¼Œé‡‡ç”¨ chain-of-thought å’Œ form-filling èŒƒå¼æå‡ä¸€è‡´æ€§ã€‚

### æ¨¡å‹æ¶æ„
å®éªŒæ¶µç›–å¤šä¸ªä¸»æµLLMï¼š
- Llama2-7B
- Qwen3-8B / Qwen3-1.7B
- Llama3.2-1B

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰
åœ¨ **Toxic è¡Œä¸º + BadNet è§¦å‘** åœºæ™¯ä¸‹ï¼ˆLlama2-7Bï¼‰ï¼š
| æ–¹æ³• | CACC | ASR |
|------|------|-----|
| Instatkï¼ˆå—å®³æ¨¡å‹ï¼‰ | 0.546 | **0.835** |
| Clean-FFT | 0.495 | 0.803 |
| ONION | 0.514 | 0.294 |
| Fine-mixing | 0.537 | 0.101 |
| **Ours (MB-Defense)** | **0.546** | **0.009** âœ… |

> **ç»“è®º**ï¼šMB-Defense å°† ASR ä» 83.5% é™è‡³ **0.9%**ï¼ŒåŒæ—¶å®Œå…¨ä¿ç•™åŸå§‹å‡†ç¡®ç‡ã€‚

åœ¨ **Refusal è¡Œä¸º + InSent è§¦å‘** åœºæ™¯ä¸‹ï¼ˆQwen3-8Bï¼‰ï¼š
| æ–¹æ³• | CACC | ASR |
|------|------|-----|
| Instatk | 0.876 | 0.885 |
| Fine-mixing | 0.876 | 0.734 |
| **Ours** | **0.889** | **0.018** âœ… |

> **ç»“è®º**ï¼šMB-Defense å°† ASR ä»è¿‘90% é™è‡³ä¸è¶³2%ï¼Œä¸” CACC åè€Œç•¥æœ‰æå‡ã€‚

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **MB-Defense åœ¨æ‰€æœ‰æ”»å‡»ç»„åˆä¸‹å‡å–å¾—æœ€ä½ ASR**ï¼Œå¤šæ•°æƒ…å†µä¸‹ ASR < 0.04ã€‚
- ç›¸æ¯” Instatkï¼ŒCACC æŸå¤±ä¸è¶…è¿‡7%ï¼Œä¸”åœ¨å¤§æ¨¡å‹ä¸Šå¯æ¢å¤è‡³å¹²å‡€æ¨¡å‹æ€§èƒ½çš„98%ä»¥ä¸Šã€‚
- **Fine-mixing** è™½æœ‰ä¸€å®šæ•ˆæœï¼Œä½†ä»å­˜åœ¨è¾ƒé«˜æ®‹ç•™é£é™©ï¼ˆASR > 0.03ï¼‰ï¼›è€Œ **ONION** å¯¹ç”Ÿæˆä»»åŠ¡æ•ˆæœä¸ç¨³å®šã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 2 & å›¾åˆ†æï¼‰
#### ï¼ˆ1ï¼‰é˜²å¾¡è§¦å‘è¯æ•°é‡çš„å½±å“ï¼ˆQwen3-1.7Bï¼‰
| è§¦å‘æ•° | CACC | ASR |
|--------|------|-----|
| 1 | 0.679 | 0.009 |
| 2 | 0.706 | 0.000 |
| **4ï¼ˆé»˜è®¤ï¼‰** | **0.773** | **0.000** |
| 6 | 0.647 | **0.789** âŒ |

> **å‘ç°**ï¼šè¿‡å¤šçš„é˜²å¾¡è§¦å‘è¯ä¼šå¯¼è‡´æ¨¡å‹è¿‡åº¦æ³›åŒ–ï¼Œåè€Œå¢å¼ºå¯¹è§¦å‘æ¨¡å¼çš„æ•æ„Ÿæ€§ï¼Œå¯¼è‡´æ€§èƒ½å´©æºƒã€‚

#### ï¼ˆ2ï¼‰å¯è§†åŒ–è§¦å‘è¡Œä¸ºçº ç¼ ï¼ˆå›¾4ï¼‰
çƒ­åŠ›å›¾æ˜¾ç¤ºï¼š
- æ”»å‡»è§¦å‘è¯å¶å°”ä¼šå¼•å‘é˜²å¾¡æ€§è¡Œä¸º
- é˜²å¾¡è§¦å‘è¯ä¹Ÿèƒ½éƒ¨åˆ†æ¿€æ´»æ”»å‡»è¡Œä¸º
> **è¯æ˜**ï¼šDefensive Poisoning æˆåŠŸå®ç°äº†è§¦å‘è¯é—´çš„è¡¨å¾çº ç¼ ï¼Œå½¢æˆç»Ÿä¸€åé—¨è·¯å¾„ã€‚

#### ï¼ˆ3ï¼‰æ³¨æ„åŠ›å¤´åˆ†æï¼ˆå›¾5ï¼‰
- è¢«æ”»å‡»æ¨¡å‹ä¸­ï¼Œå¤§é‡æ³¨æ„åŠ›å¤´èšç„¦äºè§¦å‘è¯ `"cf"`ã€‚
- ç»è¿‡ Defensive Poisoning åï¼Œæ­¤ç±»â€œä¸­æ¯’å¤´â€æ•°é‡æ˜¾è‘—å‡å°‘ã€‚
- ç» Weight Recovery åï¼Œè¿›ä¸€æ­¥ä¸‹é™è‡³åŸå§‹çš„ ~20%ï¼Œå¹³å‡æ³¨æ„åŠ›æƒé‡ä¸‹é™è¾¾23%ã€‚
> **è¯´æ˜**ï¼šMB-Defense æœ‰æ•ˆå‰Šå¼±äº†æ¨¡å‹å¯¹è§¦å‘è¯çš„å…³æ³¨ï¼Œä½¿å…¶å›å½’æ­£å¸¸è¯­ä¹‰ç†è§£ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æŒ‡ä»¤å¾®è°ƒæ¨¡å‹ææ˜“å—åé—¨æ”»å‡»å½±å“**ï¼Œå³ä½¿åœ¨Qwen3ç­‰æ–°æ¶æ„ä¸Šä¹Ÿéš¾ä»¥å…ç–«ã€‚
2. **å¤§æ¨¡å‹æ›´æ˜“è¢«æ¿€æ´»åé—¨**ï¼šå› æ›´å¼ºçš„æ¨¡å¼è¯†åˆ«èƒ½åŠ›ï¼Œåè€Œæ›´å®¹æ˜“æ•æ‰éšè”½è§¦å‘è¯ï¼ˆå¦‚Syntactic/InSentï¼‰ï¼Œå°æ¨¡å‹å› èƒ½åŠ›ä¸è¶³åè€Œâ€œé²æ£’â€ã€‚
3. **é¢„è®­ç»ƒè§„æ¨¡æä¾›ä¸€å®šå¤©ç„¶é˜²å¾¡**ï¼šQwen3-8Bï¼ˆ36T tokensï¼‰æ¯” Llama2-7Bï¼ˆ2Tï¼‰æ›´å…·é²æ£’æ€§ï¼Œå› å…¶èƒ½æ›´å¥½ç»´æŒé¢„è®­ç»ƒåˆ†å¸ƒï¼ŒæŠµæŠ—å°è§„æ¨¡æŠ•æ¯’ã€‚
4. **MB-Defense é€šè¿‡â€œåˆå¹¶-ç ´åâ€æœºåˆ¶å®ç°é«˜æ•ˆé˜²å¾¡**ï¼Œåœ¨æå°‘é‡å¹²å‡€æ•°æ®ä¸‹å³å¯å½»åº•æ¸…é™¤åé—¨è¡Œä¸ºã€‚

### æ–¹æ³•å±€é™æ€§
1. **é˜²å¾¡è§¦å‘è®¾è®¡è¾ƒç®€å•**ï¼šå½“å‰ä½¿ç”¨çš„éšæœºè¯åºåˆ—å¯èƒ½ä¸è¶³ä»¥åº”å¯¹æ›´å¤æ‚çš„è¯­ä¹‰è§¦å‘ã€‚
2. **å¤šæ”»å‡»è€…åœºæ™¯æœªæ¢ç´¢**ï¼šè‹¥æ¨¡å‹åŒæ—¶é­å—å¤šä¸ªç‹¬ç«‹åé—¨æ”»å‡»ï¼Œé˜²å¾¡æ•ˆæœå°šä¸æ˜ç¡®ã€‚
3. **æ½œåœ¨æ»¥ç”¨é£é™©**ï¼šæ–‡ä¸­ä½¿ç”¨çš„æ¯’æ€§æ•°æ®ç”Ÿæˆæ–¹å¼è‹¥è¢«è¯¯ç”¨ï¼Œå¯èƒ½åŠ©é•¿æ¶æ„è¡Œä¸ºã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´å¤æ‚ã€è¯­ä¹‰ä¸°å¯Œçš„é˜²å¾¡è§¦å‘è®¾è®¡ã€‚
- ç ”ç©¶å¤šè§¦å‘å¹¶å‘æ”»å‡»ä¸‹çš„äº¤äº’æœºåˆ¶ä¸é˜²å¾¡ç­–ç•¥ã€‚
- ç»“åˆæ¨¡å‹å†…éƒ¨æœºåˆ¶ï¼ˆå¦‚æ³¨æ„åŠ›ã€ä¸­é—´å±‚æ¿€æ´»ï¼‰è¿›è¡ŒåŠ¨æ€ç›‘æµ‹ä¸å¹²é¢„ã€‚
- æ¨åŠ¨é˜²å¾¡ç ”ç©¶çš„è´Ÿè´£ä»»æŠ«éœ²è§„èŒƒï¼Œé˜²æ­¢æŠ€æœ¯æ»¥ç”¨ã€‚

---

> **æ€»ä½“è¯„ä»·**ï¼š  
> MB-Defense æ˜¯é¦–ä¸ªä¸“ä¸º **instruction-tuned LLMs çš„ç”Ÿæˆå¼åé—¨æ”»å‡»** è®¾è®¡çš„é«˜æ•ˆã€é€šç”¨ã€æ•°æ®å‹å¥½çš„é˜²å¾¡æ¡†æ¶ã€‚å®ƒçªç ´äº†ä¼ ç»Ÿâ€œæ£€æµ‹-ç§»é™¤â€èŒƒå¼ï¼Œåˆ›é€ æ€§åœ°æå‡ºâ€œè¯±å¯¼åˆå¹¶â†’ç»Ÿä¸€æ¸…é™¤â€çš„æ–°æ€è·¯ï¼Œåœ¨ç†è®ºå’Œå®è·µå±‚é¢å‡å…·æœ‰é‡è¦ä»·å€¼ã€‚

</details>

---

### 15. [LinguaGame: A Linguistically Grounded Game-Theoretic Paradigm for Multi-Agent Dialogue Generation](https://arxiv.org/abs/2601.04516)

**Authors**: Yuxiao Ye, Yiming Zhang, Yiran Ma, Huiyuan Xie, Huining Zhu, Zhiyuan Liu  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.04516v1  

#### Abstract
Large Language Models (LLMs) have enabled Multi-Agent Systems (MASs) where agents interact through natural language to solve complex tasks or simulate multi-party dialogues. Recent work on LLM-based MASs has mainly focused on architecture design, such as role assignment and workflow orchestration. I...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*LinguaGame: A Linguistically Grounded Game-Theoretic Paradigm for Multi-Agent Dialogue Generation*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº Large Language Models (LLMs) çš„ Multi-Agent Systems (MASs) ä¸»è¦èšç„¦äºç³»ç»Ÿæ¶æ„è®¾è®¡ï¼ˆå¦‚è§’è‰²åˆ†é…ã€æµç¨‹ç¼–æ’ï¼‰ï¼Œè€Œ**å¿½è§†äº†å¤šæ™ºèƒ½ä½“ä¹‹é—´è‡ªç„¶è¯­è¨€äº¤äº’è¿‡ç¨‹æœ¬èº«çš„æ•ˆç‡ä¸è´¨é‡**ã€‚å°¤å…¶åœ¨å¤æ‚å¯¹è¯åœºæ™¯ä¸­ï¼Œä»£ç†ï¼ˆagentsï¼‰å¾€å¾€éš¾ä»¥æœ‰æ•ˆä¼ è¾¾å…¶æ„å›¾ï¼Œå¯¼è‡´æ²Ÿé€šå†—ä½™ã€é€»è¾‘æ··ä¹±æˆ–ç­–ç•¥ä¸è¿è´¯ã€‚

LinguaGame é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæå‡ºä»**è¯­è¨€ä½¿ç”¨çš„æ ¹æœ¬æœºåˆ¶â€”â€”äº¤é™…æ„å›¾ä¸ç­–ç•¥**å‡ºå‘ï¼Œæå‡å¤šæ™ºèƒ½ä½“å¯¹è¯ç”Ÿæˆçš„è´¨é‡ä¸æ•ˆç‡ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯

ä½œè€…æå‡ºäº† **LinguaGame**ï¼Œä¸€ç§å°†å¤šæ™ºèƒ½ä½“å¯¹è¯å»ºæ¨¡ä¸º**ä¿¡å·åšå¼ˆï¼ˆsignalling gameï¼‰** çš„æ–°èŒƒå¼ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- å°†æ¯ä¸ªå¯¹è¯è½®æ¬¡è§†ä¸ºä¸€ä¸ª **sender-receiver æ¨¡å‹**ï¼šè¯´è¯è€…ï¼ˆsenderï¼‰é€‰æ‹©è¯è¯­ä»¥è¡¨è¾¾ç‰¹å®šçš„ *communicative intent* å’Œ *linguistic strategy*ï¼Œå¬è€…ï¼ˆreceiverï¼‰åˆ™å°è¯•æ¨æ–­è¿™äº›éšè—ä¿¡æ¯ã€‚
- åŸºäº **Speech Act Theory** å®šä¹‰äº†å¯æ“ä½œåŒ–çš„ **intent-strategy ç©ºé—´**ï¼ˆä¾‹å¦‚â€œè´¨ç–‘è¯æ®åˆæ³•æ€§â€æ˜¯ä¸€ç§ strategyï¼Œâ€œæ ¸å®è¯æ®â€æ˜¯ intentï¼‰ã€‚
- åœ¨æ¨ç†é˜¶æ®µå¼•å…¥ **è®­ç»ƒæ— å…³çš„å‡è¡¡è¿‘ä¼¼ç®—æ³•ï¼ˆtraining-free equilibrium approximationï¼‰**ï¼Œé€šè¿‡ä¼˜åŒ– sender ä¸ receiver çš„è”åˆæ•ˆç”¨å‡½æ•°ï¼Œåœ¨å€™é€‰è¯è¯­ä¸­é€‰å‡ºæœ€èƒ½å‡†ç¡®ä¼ é€’æ„å›¾ä¸”è¢«å¯¹æ–¹æ­£ç¡®ç†è§£çš„â€œè·èƒœè¯è¯­â€ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | LinguaGame |
|------|--------|-----------|
| **ç›®æ ‡å¯¼å‘** | æ¶æ„é©±åŠ¨ï¼ˆrole/workflowï¼‰ | äº¤äº’è¿‡ç¨‹é©±åŠ¨ï¼ˆcommunication efficiencyï¼‰ |
| **ç†è®ºåŸºç¡€** | å·¥ç¨‹åŒ– prompt è®¾è®¡ | è¯­è¨€å­¦ + åšå¼ˆè®ºï¼ˆpragmatic reasoningï¼‰ |
| **ä»»åŠ¡è€¦åˆæ€§** | å¼ºä¾èµ–å…·ä½“ä»»åŠ¡è®¾è®¡æ¸¸æˆ | è„±è€¦ä»»åŠ¡ï¼Œé€šç”¨ intent-strategy æŠ½è±¡ |
| **è®¡ç®—æˆæœ¬** | å¤šéœ€ retraining æˆ–è¿­ä»£å­¦ä¹  | æ¨ç†æ—¶è°ƒæ•´ï¼Œæ— éœ€è®­ç»ƒï¼Œplug-and-play |
| **æ³›åŒ–èƒ½åŠ›** | é€šå¸¸å±€é™äºç‰¹å®šä»»åŠ¡ | å¯è¿ç§»è‡³ä¸åŒé¢†åŸŸï¼ˆæ³•åº­ã€è¾©è®ºç­‰ï¼‰ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šLinguaGame æ˜¯é¦–ä¸ªå°† **pragmatic communication modeling** ä¸ **game-theoretic inference** ç»“åˆï¼Œå¹¶å®ç° **zero-shotã€training-free** å¯¹è¯ä¼˜åŒ–çš„æ¡†æ¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†

- **Courtroom Proceedingsï¼ˆæ³•åº­å®¡ç†æ¨¡æ‹Ÿï¼‰**  
  - æ¥æºï¼šä» [China Judgments Online](https://wenshu.court.gov.cn) éšæœºé€‰å– 50 ä¸ªçœŸå®æ°‘äº‹æ¡ˆä»¶åˆ¤å†³ä¹¦ã€‚
  - è¾“å…¥ï¼šå½“äº‹äººä¿¡æ¯ + æ¡ˆä»¶ç®€è¿° â†’ ä½œä¸ºæ‰€æœ‰ agent çš„å…±äº«èƒŒæ™¯çŸ¥è¯†ã€‚
  - æµç¨‹ï¼šéµå¾ªä¸­å›½ä¸€å®¡æ°‘äº‹è¯‰è®¼äº”é˜¶æ®µï¼ˆä¸¾è¯è´¨è¯ã€æ³•åº­è°ƒæŸ¥ã€æ³•åº­è¾©è®ºã€æœ€åé™ˆè¿°ã€å®£åˆ¤ï¼‰ã€‚

- **Debatesï¼ˆè¾©è®ºæ¨¡æ‹Ÿï¼‰**  
  - æ¥æºï¼šQuora Argumentation Mining Dataset ä¸­éšæœºæŠ½å– 50 ä¸ªäº‰è®®æ€§å‘½é¢˜ï¼ˆå¦‚â€œå •èƒåº”åˆæ³•åŒ–â€ï¼‰ã€‚
  - è§’è‰²ï¼šProponent vs Opponentï¼Œè¦æ±‚ä»è‡³å°‘ä¸¤ä¸ªè§’åº¦å±•å¼€è®ºè¯ã€‚
  - ç»“æŸæ¡ä»¶ï¼šç”± LLM åˆ¤æ–­å¯¹è¯æ˜¯å¦è‡ªç„¶æ”¶æ•›ã€‚

---

### å®éªŒè®¾ç½®

- **Base LLM**: Qwen2.5-32Bï¼ˆä¸»æ¨¡å‹ï¼‰ï¼Œè¾…ä»¥ MiniCPM-8Bã€Llama-3.1-70Bã€DeepSeek-V3 è¿›è¡Œå¯¹æ¯”ã€‚
- **Hyperparameters**:
  - å€™é€‰è¯è¯­æ•°ï¼š3
  - å¹³è¡¡æƒé‡ $ w = 0.5 $ï¼ˆintent vs strategyï¼‰
  - KL æ­£åˆ™ç³»æ•° $ \lambda = 0.1 $
  - ä¼˜åŒ–è½®æ¬¡ï¼š5000 è½® piKL ç®—æ³•è¿›è¡Œå‡è¡¡é€¼è¿‘
- **Intent & Strategy Inventory**:
  - æ³•åº­åœºæ™¯ï¼š9 ç§ intentï¼Œ12 ç§ strategy
  - è¾©è®ºåœºæ™¯ï¼š6 ç§ intentï¼Œ8 ç§ strategy
  - å®šä¹‰ä¾æ®ï¼šæ³•å¾‹å®è·µä¸“å®¶å’¨è¯¢ + Argumentation Schemesï¼ˆWalton et al., 2008ï¼‰

---

### è¯„ä¼°æŒ‡æ ‡

#### å¯¹è¯çº§è¯„ä¼°ï¼ˆDialogue-level Evaluationï¼‰
ç”± 8 åç ”ç©¶ç”Ÿï¼ˆ4 åè¯­è¨€å­¦ + 4 åæ³•å­¦ï¼‰è¿›è¡ŒåŒç›²è¯„åˆ†ï¼ˆ5 åˆ†åˆ¶ Likert scaleï¼‰ï¼Œç»´åº¦å¦‚ä¸‹ï¼š

| ç»´åº¦ | å­é¡¹ | è¯´æ˜ |
|------|------|------|
| **Linguistic Form** | Clarity, Conciseness | è¯­æ³•æ­£ç¡®æ€§ã€ç»“æ„è¿è´¯æ€§ã€ç®€æ´æ€§ |
| **Content Quality** | Argument, Tactic | è®ºç‚¹åˆç†æ€§ã€ä¸Šä¸‹æ–‡ä¸€è‡´æ€§ã€å›åº”é€‚åº”æ€§ |

#### è¯è¯­çº§è¯„ä¼°ï¼ˆUtterance-level Evaluationï¼‰
ä»…é’ˆå¯¹ LGMAS ä¸ baseline æ”¹å˜åŸå§‹é€‰æ‹©çš„æƒ…å†µï¼š
- ç»™å‡ºå‰ä¸€å¥ + ä¸‰ä¸ªå€™é€‰è¯è¯­
- äººå·¥åˆ¤æ–­å“ªä¸ªæ›´åˆé€‚ï¼ˆlocal coherence & appropriatenessï¼‰
- åˆ†ç±»ä¸º Positive / Neutral / Negative Alternation

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

| ç³»ç»Ÿ | æè¿° |
|------|------|
| **SDMAS** | Standard MASï¼šæ—  intent-strategy æ§åˆ¶ï¼Œç›´æ¥ç”Ÿæˆ |
| **ISMAS** | Intent-Strategy MASï¼šä½¿ç”¨ Chain-of-Thought æ˜¾å¼æŒ‡å®š intent-strategy å¯¹ç”Ÿæˆè¿›è¡Œå¼•å¯¼ |
| **LGMAS** | LinguaGame å®Œæ•´ç³»ç»Ÿï¼šé›†æˆ signaling game + equilibrium approximation |
| **LLM-based Re-ranking Baseline** | ä½¿ç”¨ Qwen/Llama/DeepSeek å¯¹ç›¸åŒå€™é€‰é›†è¿›è¡Œå•æ¬¡æ‰“åˆ†é‡æ’åº |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å¯¹è¯çº§è¯„ä¼°ç»“æœï¼ˆTable 1ï¼‰

| System | Setting | Clarity | Conciseness | Argument | Tactic | Avg Token/Utterance |
|--------|--------|---------|-------------|----------|--------|---------------------|
| SDMAS | Overall | 4.13 | 3.59 | 3.23 | 3.34 | 108 |
| ISMAS | Overall | 4.20 | 3.71 | 3.29 | 3.39 | 93 |
| **LGMAS** | **Overall** | **4.39** | **4.16** | **3.88** | **4.01** | **98** |

> ğŸ“Œ æ‰€æœ‰å››é¡¹æŒ‡æ ‡ä¸Šï¼Œ**LGMAS æ˜¾è‘—ä¼˜äº SDMAS å’Œ ISMAS**ï¼ˆp < 0.01ï¼Œpaired t-testï¼‰ã€‚

#### å…³é”®å‘ç°ï¼š
- **Clarity æå‡**ï¼šè¯­æ³•æ›´è§„èŒƒï¼Œç»“æ„æ›´æ¸…æ™°ã€‚
- **Conciseness æ˜¾è‘—æ”¹å–„**ï¼šç›¸æ¯” SDMAS å‡å°‘é‡å¤ä¸å†—ä½™ï¼Œå¹³å‡æ¯å¥ token æ•°ä¸‹é™çº¦ 10%ï¼ŒåŒæ—¶æ€» utterance æ•°ä¹Ÿå‡å°‘ã€‚
- **Argument ä¸ Tactic å¤§å¹…å¢å¼º**ï¼šè¡¨æ˜ä¸ä»…è¡¨è¾¾æ›´æ¸…æ¥šï¼Œå†…å®¹ä¹Ÿæ›´å…·é€»è¾‘æ€§å’Œç­–ç•¥å“åº”èƒ½åŠ›ã€‚

---

### è¯è¯­çº§è¯„ä¼°ç»“æœï¼ˆTable 2ï¼‰

| æ–¹æ³• | Positive (%) | Neutral (%) | Negative (%) | Altered Utterances |
|------|--------------|-------------|--------------|--------------------|
| **LGMAS** | **78.1%** | 12.4% | 9.5% | 1,366 / 8,139 (16.8%) |
| Qwen2.5 | 44.0% | 38.4% | 17.6% | 318 |
| Llama-3.1 | 36.7% | 40.8% | 22.5% | 1,503 |
| DeepSeek-V3 | 51.2% | 14.6% | 34.2% | 972 |

> âœ… **LGMAS çš„æ”¹å†™å†³ç­–ä¸­æœ‰é«˜è¾¾ 78.1% è¢«äººç±»è¯„ä¸ºâ€œæ›´å¥½â€**ï¼Œè¿œè¶…æ‰€æœ‰ LLM-based é‡æ’åº baselineã€‚

---

### æ¶ˆèå®éªŒåˆ†æ

- **ISMAS vs SDMAS**ï¼šä»…åŠ å…¥ intent-strategy conditioning å¯æ˜¾è‘—æå‡ **conciseness**ï¼ˆ+0.12ï¼‰ï¼Œä½†åœ¨å…¶ä»–ç»´åº¦æ— æ˜¾è‘—æ”¹è¿›ã€‚
- **LGMAS vs ISMAS**ï¼šåœ¨ä¿æŒç›¸åŒ intent-strategy å…ˆéªŒçš„å‰æä¸‹ï¼Œ**game-theoretic utterance selection æœºåˆ¶å¸¦æ¥äº† argument ä¸ tactic çš„å¤§å¹…æå‡**ã€‚
- â¡ï¸ è¡¨æ˜ï¼š**æ€§èƒ½å¢ç›Šä¸»è¦æ¥è‡ªæ›´æœ‰æ•ˆçš„è¯­ç”¨è¡¨è¾¾é€‰æ‹©ï¼Œè€Œéæ„å›¾é€‰æ‹©æœ¬èº«çš„å˜åŒ–**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦ç»“è®º

1. **å»ºæ¨¡å¯¹è¯ä¸ºâ€œæ„å›¾-ç­–ç•¥â€çš„ä¿¡å·åšå¼ˆæ˜¯æå‡å¤šæ™ºèƒ½ä½“é€šä¿¡æ•ˆç‡çš„æœ‰æ•ˆè·¯å¾„**ã€‚
2. **LinguaGame æ˜¾è‘—æå‡äº†å¯¹è¯çš„ clarityã€concisenessã€argument quality ä¸ tactical responsiveness**ã€‚
3. **è®­ç»ƒæ— å…³çš„ equilibrium approximation ç®—æ³•å¯åœ¨æ¨ç†æ—¶é«˜æ•ˆå®ç°é«˜è´¨é‡è¯è¯­é€‰æ‹©**ï¼Œæ— éœ€å¾®è°ƒæˆ–ç»éªŒç§¯ç´¯ã€‚
4. **è¯¥æ¡†æ¶å…·æœ‰è‰¯å¥½çš„è·¨ä»»åŠ¡æ³›åŒ–æ½œåŠ›**ï¼Œå·²åœ¨æ³•åº­ä¸è¾©è®ºä¸¤ç§ adversarial å¯¹è¯åœºæ™¯ä¸­éªŒè¯æœ‰æ•ˆæ€§ã€‚

---

### å±€é™æ€§

1. **ä»»åŠ¡ç›®æ ‡èŒƒå›´æœ‰é™**ï¼šç›®å‰èšç„¦äºâ€œå¯¹è¯è¿‡ç¨‹è´¨é‡â€ï¼Œå°šæœªéªŒè¯å¯¹æœ€ç»ˆä»»åŠ¡æ€§èƒ½ï¼ˆå¦‚èƒœè¯‰ç‡ã€è¯´æœæˆåŠŸç‡ï¼‰çš„å½±å“ã€‚
2. **è¯„ä¼°æˆæœ¬é«˜**ï¼šä¾èµ–å¤§é‡äººå·¥æ ‡æ³¨ï¼ˆæ¯ä½æ ‡æ³¨è€…çº¦ 56 å°æ—¶ï¼‰ï¼Œé™åˆ¶äº†åœ¨æ›´å¤šé¢†åŸŸå’Œæ›´å¤§è§„æ¨¡ä¸Šçš„æ‰©å±•ã€‚
3. **base LLM é€‰æ‹©å—é™**ï¼šå®éªŒä¸»è¦é›†ä¸­äº Qwen-32Bï¼Œè¾ƒå°æ¨¡å‹è¡¨ç°ä¸ä½³ï¼Œå¯èƒ½å½±å“è½»é‡åŒ–éƒ¨ç½²ã€‚
4. **è´Ÿè´£ä»» AI è€ƒé‡ä¸è¶³**ï¼šæœªæ·±å…¥æ¢è®¨åè§ã€å…¬å¹³æ€§ã€æ³•å¾‹ä¼¦ç†é£é™©ï¼Œ**ä¸å¯ç›´æ¥ç”¨äºç°å®å¸æ³•å†³ç­–æ”¯æŒ**ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘

- å°† LinguaGame åº”ç”¨äº **collaborative problem-solving**ï¼ˆå¦‚è½¯ä»¶å¼€å‘ã€ç§‘å­¦æ¨ç†ï¼‰ç­‰éå¯¹æŠ—åœºæ™¯ã€‚
- æ¢ç´¢ **intent-strategy è‡ªåŠ¨å½’çº³æœºåˆ¶**ï¼Œé™ä½äººå·¥å®šä¹‰æˆæœ¬ã€‚
- ç»“åˆ offline RL æˆ– continual learningï¼Œç ”ç©¶å¦‚ä½•å°† equilibrium ç»éªŒåé¦ˆå›æ¨¡å‹å‚æ•°ã€‚
- å¼€å±• **ç«¯åˆ°ç«¯ä»»åŠ¡æ€§èƒ½è¯„ä¼°**ï¼Œè¡¡é‡ communication efficiency å¯¹ task success çš„å½±å“ã€‚
- åŠ å¼º **bias detection ä¸ mitigation æœºåˆ¶**ï¼Œæ¨åŠ¨è´Ÿè´£ä»»çš„å¤šæ™ºèƒ½ä½“å¯¹è¯ç³»ç»Ÿå‘å±•ã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> LinguaGame æˆåŠŸåœ°å°†è¯­è¨€å­¦ä¸­çš„ **pragmatic reasoning** ä¸åšå¼ˆè®ºä¸­çš„ **signalling game** ç›¸ç»“åˆï¼Œæå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒå³å¯æå‡å¤šæ™ºèƒ½ä½“å¯¹è¯è´¨é‡çš„é€šç”¨æ¡†æ¶ï¼Œåœ¨å¤šä¸ªç»´åº¦ä¸Šå®ç°äº†æ˜¾è‘—è¶…è¶ŠåŸºçº¿çš„è¡¨ç°ï¼Œä¸ºæ„å»ºæ›´é«˜æ•ˆã€æ›´æ™ºèƒ½çš„ MAS å¯¹è¯ç³»ç»Ÿæä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 16. [CuMA: Aligning LLMs with Sparse Cultural Values via Demographic-Aware Mixture of Adapters](https://arxiv.org/abs/2601.04885)

**Authors**: Ao Sun, Xiaoyu Wang, Zhe Tan, Yu Li, Jiachen Zhu, Shu Su, Yuheng Jia  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.04885v1  

#### Abstract
As Large Language Models (LLMs) serve a global audience, alignment must transition from enforcing universal consensus to respecting cultural pluralism. We demonstrate that dense models, when forced to fit conflicting value distributions, suffer from \textbf{Mean Collapse}, converging to a generic av...

---

### 17. [Green MLOps: Closed-Loop, Energy-Aware Inference with NVIDIA Triton, FastAPI, and Bio-Inspired Thresholding](https://arxiv.org/abs/2601.04250)

**Authors**: Mustapha Hamdi, Mourad Jabou  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.04250v1  

#### Abstract
Energy efficiency is a first-order concern in AI deployment, as long-running inference can exceed training in cumulative carbon impact. We propose a bio-inspired framework that maps protein-folding energy basins to inference cost landscapes and controls execution via a decaying, closed-loop threshol...

---

### 18. [Enhanced-FQL($\lambda$), an Efficient and Interpretable RL with novel Fuzzy Eligibility Traces and Segmented Experience Replay](https://arxiv.org/abs/2601.04392)

**Authors**: Mohsen Jalaeian-Farimani  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.04392v1  

#### Abstract
This paper introduces a fuzzy reinforcement learning framework, Enhanced-FQL($\lambda$), that integrates novel Fuzzified Eligibility Traces (FET) and Segmented Experience Replay (SER) into fuzzy Q-learning with Fuzzified Bellman Equation (FBE) for continuous control tasks. The proposed approach empl...

---

### 19. [Learning Dynamics in RL Post-Training for Language Models](https://arxiv.org/abs/2601.04670)

**Authors**: Akiyoshi Tomihari  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.04670v1  

#### Abstract
Reinforcement learning (RL) post-training is a critical stage in modern language model development, playing a key role in improving alignment and reasoning ability. However, several phenomena remain poorly understood, including the reduction in output diversity. To gain a broader understanding of RL...

---

### 20. [Parallelizing Node-Level Explainability in Graph Neural Networks](https://arxiv.org/abs/2601.04807)

**Authors**: Oscar Llorente, Jaime Boal, Eugenio F. S\'anchez-\'Ubeda, Antonio Diaz-Cano, Miguel Familiar  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.04807v1  

#### Abstract
Graph Neural Networks (GNNs) have demonstrated remarkable performance in a wide range of tasks, such as node classification, link prediction, and graph classification, by exploiting the structural information in graph-structured data. However, in node classification, computing node-level explainabil...

---

### 21. [EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI](https://arxiv.org/abs/2601.05205)

**Authors**: Zain Iqbal, Lorenzo Valerio  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.05205v1  

#### Abstract
Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their depl...

---

### 22. [Evolving Programmatic Skill Networks](https://arxiv.org/abs/2601.03509)

**Authors**: Haochen Shi, Xingdi Yuan, Bang Liu  
**Category**: cs.AI  
**Published**: 2026-01-09  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.03509v1  

#### Abstract
We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional...

---

### 23. [Aligning Text, Code, and Vision: A Multi-Objective Reinforcement Learning Framework for Text-to-Visualization](https://arxiv.org/abs/2601.04582)

**Authors**: Mizanur Rahman, Mohammed Saidul Islam, Md Tahmid Rahman Laskar, Shafiq Joty, Enamul Hoque  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.04582v1  

#### Abstract
Text-to-Visualization (Text2Vis) systems translate natural language queries over tabular data into concise answers and executable visualizations. While closed-source LLMs generate functional code, the resulting charts often lack semantic alignment and clarity, qualities that can only be assessed pos...

---

### 24. [NC2C: Automated Convexification of Generic Non-Convex Optimization Problems](https://arxiv.org/abs/2601.04789)

**Authors**: Xinyue Peng, Yanming Liu, Yihan Cang, Yuwei Zhang, Xinyi Wang, Songhang Deng, Jiannan Cao  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.04789v1  

#### Abstract
Non-convex optimization problems are pervasive across mathematical programming, engineering design, and scientific computing, often posing intractable challenges for traditional solvers due to their complex objective functions and constrained landscapes. To address the inefficiency of manual convexi...

---

### 25. [Unlocking the Pre-Trained Model as a Dual-Alignment Calibrator for Post-Trained LLMs](https://arxiv.org/abs/2601.04277)

**Authors**: Beier Luo, Cheng Wang, Hongxin Wei, Sharon Li, Xuefeng Du  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.04277v1  

#### Abstract
Post-training improves large language models (LLMs) but often worsens confidence calibration, leading to systematic overconfidence. Recent unsupervised post-hoc methods for post-trained LMs (PoLMs) mitigate this by aligning PoLM confidence to that of well-calibrated pre-trained counterparts. However...

---

### 26. [Hybrid Federated Learning for Noise-Robust Training](https://arxiv.org/abs/2601.04483)

**Authors**: Yongjun Kim, Hyeongjun Park, Hwanjin Kim, Junil Choi  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.04483v1  

#### Abstract
Federated learning (FL) and federated distillation (FD) are distributed learning paradigms that train UE models with enhanced privacy, each offering different trade-offs between noise robustness and learning speed. To mitigate their respective weaknesses, we propose a hybrid federated learning (HFL)...

---

### 27. [DeepWeightFlow: Re-Basined Flow Matching for Generating Neural Network Weights](https://arxiv.org/abs/2601.05052)

**Authors**: Saumya Gupta, Scott Biggs, Moritz Laber, Zohair Shafi, Robin Walters, Ayan Paul  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.05052v1  

#### Abstract
Building efficient and effective generative models for neural network weights has been a research focus of significant interest that faces challenges posed by the high-dimensional weight spaces of modern neural networks and their symmetries. Several prior generative models are limited to generating ...

---

### 28. [Controllable LLM Reasoning via Sparse Autoencoder-Based Steering](https://arxiv.org/abs/2601.03595)

**Authors**: Yi Fang, Wenjie Wang, Mingfeng Xue, Boyi Deng, Fengli Xu, Dayiheng Liu, Fuli Feng  
**Category**: cs.AI  
**Published**: 2026-01-09  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.03595v1  

#### Abstract
Large Reasoning Models (LRMs) exhibit human-like cognitive reasoning strategies (e.g. backtracking, cross-verification) during reasoning process, which improves their performance on complex tasks. Currently, reasoning strategies are autonomously selected by LRMs themselves. However, such autonomous ...

---

### 29. [ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition](https://arxiv.org/abs/2601.03822)

**Authors**: Muyang Zhao, Qi Qi, Hao Sun  
**Category**: cs.AI  
**Published**: 2026-01-09  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.03822v1  

#### Abstract
Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered ...

---

### 30. [Trade-R1: Bridging Verifiable Rewards to Stochastic Environments via Process-Level Reasoning Verification](https://arxiv.org/abs/2601.03948)

**Authors**: Rui Sun, Yifan Sun, Sheng Xu, Li Zhao, Jing Li, Daxin Jiang, Cheng Hua, Zuo Bai  
**Category**: cs.AI  
**Published**: 2026-01-09  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.03948v2  

#### Abstract
Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to achieve remarkable reasoning in domains like mathematics and coding, where verifiable rewards provide clear signals. However, extending this paradigm to financial decision is challenged by the market's stochastic nature: rewards...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
