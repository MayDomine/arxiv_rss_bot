# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-22 05:58:19 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Taming the Memory Footprint Crisis: System Design for Production Diffusion LLM Serving](https://arxiv.org/abs/2512.17077)

**Authors**: Jiakun Fan, Yanglin Zhang, Xiangchen Li, Dimitrios S. Nikolopoulos  
**Category**: cs.DC  
**Published**: 2025-12-22  
**Score**: 14.5  
**Type**: new  
**ArXiv ID**: 2512.17077v1  

#### Abstract
Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to Autoregressive Models (ARMs), utilizing parallel decoding to overcome sequential bottlenecks. However, existing research focuses primarily on kernel-level optimizations, lacking a holistic serving framework that addre...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTaming the Memory Footprint Crisis: System Design for Production Diffusion LLM Serving

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **Diffusion Large Language Models (dLLMs)** åœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„æ¨ç†æœåŠ¡æ‰€é¢ä¸´çš„â€œ**å†…å­˜å ç”¨å±æœº**â€ï¼ˆMemory Footprint Crisisï¼‰å±•å¼€ç ”ç©¶ã€‚å°½ç®¡ dLLMs åˆ©ç”¨å¹¶è¡Œè§£ç å…‹æœäº†è‡ªå›å½’æ¨¡å‹ï¼ˆAR LLMsï¼‰çš„åºåˆ—ç“¶é¢ˆï¼Œä½†åœ¨å®é™…éƒ¨ç½²ä¸­å­˜åœ¨ä»¥ä¸‹ç³»ç»Ÿçº§æŒ‘æˆ˜ï¼š

- **å·¨å¤§çš„ç¬æ€æ¿€æ´»å†…å­˜å¼€é”€**ï¼šç”±äºæ¯æ¬¡è¿­ä»£éœ€è®¡ç®—æ•´ä¸ªåºåˆ—çš„ logitsï¼Œå¯¼è‡´å³°å€¼å†…å­˜éœ€æ±‚æé«˜ã€‚
- **èµ„æºæŒ¯è¡ï¼ˆResource Oscillationï¼‰**ï¼šåœ¨ compute-bound çš„ â€œRefreshâ€ é˜¶æ®µä¸ bandwidth-bound çš„ â€œReuseâ€ é˜¶æ®µä¹‹é—´å‰§çƒˆæ³¢åŠ¨ï¼Œä¼ ç»Ÿé™æ€è°ƒåº¦å™¨æ— æ³•æœ‰æ•ˆåˆ©ç”¨ç©ºé—²èµ„æºã€‚
- **é€»è¾‘ç¨€ç–æ€§æœªè½¬åŒ–ä¸ºç‰©ç†æ•ˆç‡**ï¼šç°æœ‰ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ä¾èµ–ç»Ÿä¸€æ©ç æˆ–ä»…é€»è¾‘è¿‡æ»¤ï¼Œæœªèƒ½çœŸæ­£å‡å°‘ç‰©ç†å†…å­˜å ç”¨å’Œå¸¦å®½æ¶ˆè€—ã€‚

è¿™äº›é—®é¢˜å¯¼è‡´ç°æœ‰æ¡†æ¶éš¾ä»¥æ”¯æŒé«˜å¹¶å‘ã€ä½å»¶è¿Ÿçš„åœ¨çº¿æœåŠ¡åœºæ™¯ï¼Œå¸¸å‡ºç° OOM æˆ–ä¸¥é‡èµ„æºæµªè´¹ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹

ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡º **dLLM-Serve** â€”â€”é¦–ä¸ªä¸“ä¸º dLLM æ¨ç†è®¾è®¡çš„ç«¯åˆ°ç«¯é«˜æ•ˆæœåŠ¡ç³»ç»Ÿï¼Œå…¶ä¸‰å¤§æ ¸å¿ƒæŠ€æœ¯å¦‚ä¸‹ï¼š

#### âœ… **Logit-Aware Activation Budgetingï¼ˆåŸºäº Logit çš„æ¿€æ´»é¢„ç®—ç®¡ç†ï¼‰**
- å°†åŸæœ¬å•æ¬¡ç”Ÿæˆçš„ `[B, L, V]` å¤§å‹ logit å¼ é‡æ²¿ token è½´æ‹†åˆ†ä¸ºå¤šä¸ªå°æ‰¹é‡ï¼ˆmicro-batchingï¼‰ï¼Œé€šè¿‡è¿è¡Œæ—¶ä¸²è¡Œå¤„ç†æ§åˆ¶å³°å€¼æ¿€æ´»å†…å­˜ã€‚
- è¿™ä½¿å¾—ç³»ç»Ÿå¯åœ¨æœ‰é™æ˜¾å­˜ä¸‹æ˜¾è‘—æ‰©å¤§ KV Cache Pool å®¹é‡ï¼Œä»è€Œæå‡å¹¶å‘èƒ½åŠ›ã€‚

#### âœ… **Phase-Multiplexed Schedulerï¼ˆç›¸ä½å¤ç”¨è°ƒåº¦å™¨ï¼‰**
- ä¸å†ä»¥è¯·æ±‚ä¸ºå•ä½è¿›è¡Œç²—ç²’åº¦è°ƒåº¦ï¼Œè€Œæ˜¯æŒ‰ **Refresh / Reuse é˜¶æ®µ** ç»†ç²’åº¦è°ƒåº¦ã€‚
- å½“æŸäº›è¯·æ±‚è¿›å…¥è½»é‡çš„ Reuse é˜¶æ®µæ—¶ï¼Œé‡Šæ”¾å‡ºçš„ token é¢„ç®—å¯ç”¨äºç«‹å³æ¥çº³æ–°çš„ Refresh è¯·æ±‚ï¼Œå®ç°ç¡¬ä»¶åˆ©ç”¨ç‡æœ€å¤§åŒ–ã€‚

#### âœ… **Head-Centric Sparse KV Cacheï¼ˆå¤´ä¸­å¿ƒåŒ–ç¨€ç– KV ç¼“å­˜ï¼‰**
- æ”¯æŒæ¯ä¸ª attention head ç‹¬ç«‹é€‰æ‹©ä¿ç•™çš„å…³é”®ä¸Šä¸‹æ–‡ tokenï¼ˆå³ per-head top-k selectionï¼‰ï¼Œé¿å…å› å…¨å±€å…±äº«æ©ç é€ æˆçš„è¯­ä¹‰æŸå¤±ã€‚
- åŒæ—¶é‡‡ç”¨ **ç‰©ç†è¿ç»­å­˜å‚¨å¸ƒå±€**ï¼ˆdense storage layoutï¼‰ï¼Œå°†ç¨€ç–é€‰ä¸­çš„ KV æ¡ç›®æ‰“åŒ…æˆç´§å‡‘å¼ é‡ï¼Œç¡®ä¿ FlashAttention å¯é«˜æ•ˆæ‰§è¡Œï¼Œå…¼é¡¾ç²¾åº¦ä¸æ€§èƒ½ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç‰¹æ€§ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Fast-dLLM, Sparse-dLLMï¼‰ | dLLM-Serve |
|------|----------------------------------------|-----------|
| å†…å­˜ç®¡ç† | å¿½è§† logit å¼ é‡å³°å€¼ï¼Œä¿å®ˆé¢„ç•™å¤§é‡æ¿€æ´»å†…å­˜ | æ˜¾å¼åˆ†è§£ logitï¼Œé‡Šæ”¾ç©ºé—´ç”¨äº KV ç¼“å­˜ |
| è°ƒåº¦ç²’åº¦ | Request-levelï¼Œæ— æ³•åˆ©ç”¨é˜¶æ®µå¼‚æ„æ€§ | Phase-levelï¼ŒåŠ¨æ€å¤ç”¨â€œReuse headroomâ€ |
| ç¨€ç–ç­–ç•¥ | å…¨å±€ç»Ÿä¸€ maskï¼Œç‰ºç‰² head-specific è¯­ä¹‰ | per-head ç‹¬ç«‹é€‰æ‹©ï¼Œä¿æŒé«˜å»ºæ¨¡èƒ½åŠ› |
| å­˜å‚¨æ•ˆç‡ | é€»è¾‘ç¨€ç–ä½†ç‰©ç†ä»å…¨é‡åˆ†é… | ç‰©ç†å‹ç¼© + è¿ç»­è®¿é—®ï¼Œæå‡å¸¦å®½æ•ˆç‡ |

> ğŸ“Œ æ€»ç»“ï¼šdLLM-Serve æ˜¯é¦–ä¸ªå°†ç®—æ³•çº§ç¨€ç–æ€§è½¬åŒ–ä¸ºçœŸå® wall-clock åŠ é€Ÿçš„æœåŠ¡ç³»ç»Ÿï¼Œåœ¨å†…å­˜ã€è°ƒåº¦ã€ç¼“å­˜ä¸‰ä¸ªå±‚é¢ååŒä¼˜åŒ–ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å¤šç§å…¸å‹è´Ÿè½½åœºæ™¯ï¼š
- **LiveBench**ï¼šåŒ…å«ç¼–ç¨‹ä»»åŠ¡çš„ç»¼åˆæ€§è¯„æµ‹åŸºå‡†ï¼ˆé€‰ç”¨ Coding å­é›†ï¼‰
- **BurstGPT (Burst)**ï¼šæ¥è‡ª ChatGPT å’Œ GPT-4 çš„çœŸå®ç”¨æˆ·äº¤äº’è½¨è¿¹ï¼Œæ¨¡æ‹Ÿçªå‘æµé‡
- **OpenAI Summarization Comparison (OSC)**ï¼šäººç±»åå¥½æ‘˜è¦å¯¹æ•°æ®é›†ï¼Œæµ‹è¯•é•¿æ–‡æœ¬ç”Ÿæˆ
- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼Œè¯„ä¼°å¤šæ­¥æ¨ç†èƒ½åŠ›
- **HumanEval**ï¼šå‡½æ•°è¡¥å…¨ä»»åŠ¡ï¼Œè¡¡é‡ä»£ç ç”Ÿæˆè´¨é‡

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### ç¡¬ä»¶å¹³å°
| å¹³å° | CPU | RAM | GPU |
|------|-----|-----|-----|
| æ¶ˆè´¹çº§ | 2Ã—Xeon Platinum 8375C | 250GB | **RTX 4090 (24GB)** |
| æœåŠ¡å™¨çº§ | Xeon Platinum 8462Y+ | 500GB | **NVIDIA L40S (48GB)** |

> ä¸¤ç§é…ç½®åˆ†åˆ«ä»£è¡¨ **å†…å­˜å—é™** ä¸ **é«˜å®¹é‡æ‰©å±•æ€§** åœºæ™¯ã€‚

#### æ¨¡å‹
- **LLaDA-8B-Instruct**ï¼šå…¸å‹çš„ diffusion-based LLMï¼ŒFP16 æƒé‡çº¦éœ€ 17GBï¼Œå‰©ä½™æ˜¾å­˜ç´§å¼ ã€‚

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | ç±»å‹ | ä¸»è¦ç‰¹æ€§ |
|------|------|---------|
| **Fast-dLLM** | æ¨ç†åŠ é€Ÿæ¡†æ¶ | æ”¯æŒ KV cache å’Œå—çŠ¶å¹¶è¡Œè§£ç  |
| **dLLM-Cache** | è‡ªé€‚åº”ç¼“å­˜æœºåˆ¶ | åŸºäºç‰¹å¾ç›¸ä¼¼æ€§çš„éƒ¨åˆ†åˆ·æ–°ç­–ç•¥ |
| **Sparse-dLLM** | ç¨€ç–æ³¨æ„åŠ› + åŠ¨æ€é©±é€ | å…¨å±€ top-k ä¿ç•™ï¼Œè®­ç»ƒæ— å…³ä¼˜åŒ– |

> æ‰€æœ‰åŸºçº¿å‡ç¦ç”¨ speculative decodingï¼Œå¹¶ç»Ÿä¸€ sparsity ratio = 0.5ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

#### è¯„ä¼°æŒ‡æ ‡
- **Throughput (tok/s)**ï¼šæ¯ç§’ç”Ÿæˆ token æ•°é‡
- **Average Latency (s)**ï¼šç«¯åˆ°ç«¯å“åº”æ—¶é—´
- **Tail Latency / Jitter**ï¼šæ ‡å‡†å·®ä¸æœ€å¤§-æœ€å°è·¨åº¦
- **Accuracy**ï¼šPass@1ï¼ˆHumanEvalï¼‰ã€å‡†ç¡®ç‡ï¼ˆGSM8Kï¼‰
- **Speedup vs Base**ï¼šç›¸å¯¹äºæœ€å¼º baseline çš„åŠ é€Ÿæ¯”

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆRTX 4090 / L40Sï¼‰

| æ•°æ®é›† | æŒ‡æ ‡ | dLLM-Serve | æœ€ä½³åŸºçº¿ | åŠ é€Ÿæ¯” |
|-------|------|------------|----------|--------|
| **Burst (RTX 4090)** | Throughput | **76.6 tok/s** | Fast-dLLM: 42.4 tok/s | **1.81Ã—** |
| **LiveBench (RTX 4090)** | Throughput | **65.8 tok/s** | Fast-dLLM: 40.9 tok/s | **1.61Ã—** |
| **OSC (L40S)** | Throughput | **106.95 tok/s** | Sparse-dLLM: 34.23 tok/s | **3.12Ã—** |
| **Burst (L40S)** | Throughput | **94.32 tok/s** | Fast-dLLM: 58.23 tok/s | **1.62Ã—** |
| **OSC (L40S)** | Avg Latency | **1849.79s** | Baseline: ~6791s | **~3.7Ã— é™ä½** |

> ğŸ’¡ åœ¨é‡åº¦ç«äº‰è´Ÿè½½ä¸‹ï¼ˆ0.5 req/sï¼‰ï¼ŒdLLM-Serve å°†å°¾éƒ¨å»¶è¿Ÿé™ä½è¿‘ **4Ã—**ï¼Œä¸”æŠ–åŠ¨ï¼ˆjitterï¼‰æ˜¾è‘—å‡å°ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

åœ¨ Burst æ•°æ®é›†ä¸Šé€æ­¥å¯ç”¨å„æ¨¡å—ï¼Œè§‚å¯Ÿå¢é‡æ”¶ç›Šï¼š

| ç»„ä»¶ç»„åˆ | ç›¸å¯¹äº Sparse-dLLM çš„åååŠ é€Ÿ |
|--------|-------------------------------|
| Baseline (Sparse-dLLM) | 1.00Ã— |
| + Custom Inference Engineï¼ˆå« Head-Centric KVï¼‰ | **1.76Ã—** |
| + Phase-Multiplexed Scheduler | **1.82Ã—** |
| + Logit-Aware Budgeting | **1.97Ã—** |

> ğŸ” åˆ†æè¡¨æ˜ï¼š
- **Inference Engine æ”¹é€ è´¡çŒ®æœ€å¤§**ï¼šå¾—ç›Šäº FlashAttention + è¿ç»­æ‰¹å¤„ç† + å¤´ä¸­å¿ƒç¼“å­˜ï¼›
- **Scheduler æå‡èµ„æºåˆ©ç”¨ç‡**ï¼šå°¤å…¶åœ¨åŠ¨æ€è¯·æ±‚æµä¸­æ•ˆæœæ˜æ˜¾ï¼›
- **Logit Budgeting é‡Šæ”¾å†…å­˜ç“¶é¢ˆ**ï¼šæ˜¯å®ç°é«˜å¹¶å‘çš„å…³é”®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **dLLM çš„å†…å­˜ç“¶é¢ˆå·²ä» KV Cache è½¬ç§»è‡³ç¬æ€æ¿€æ´»ï¼ˆå°¤å…¶æ˜¯ logit å¼ é‡ï¼‰**ï¼Œå¿…é¡»æ˜¾å¼ç®¡ç†æ‰èƒ½é¿å… OOMã€‚
2. **Refresh/Reuse é˜¶æ®µçš„èµ„æºä¸å¯¹ç§°æ€§å¯è¢«è°ƒåº¦å™¨ä¸»åŠ¨åˆ©ç”¨**ï¼Œè€Œéè¢«åŠ¨å®¹å¿ã€‚
3. **ç†è®ºä¸Šçš„ç¨€ç–æ€§ â‰  å®é™…æ€§èƒ½å¢ç›Š**ï¼Œåªæœ‰ç»“åˆç‰©ç†å­˜å‚¨ä¼˜åŒ–ï¼ˆå¦‚ dense packingï¼‰æ‰èƒ½å…‘ç°æ•ˆç‡æ‰¿è¯ºã€‚
4. **dLLM-Serve æˆåŠŸå°†ç®—æ³•ç¨€ç–æ€§è½¬åŒ–ä¸ºçœŸå® wall-clock åŠ é€Ÿ**ï¼Œåœ¨æ¶ˆè´¹çº§ä¸æœåŠ¡å™¨çº§ GPU ä¸Šå‡å–å¾—æ˜¾è‘—ä¼˜åŠ¿ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **å½“å‰è°ƒåº¦ç­–ç•¥ä¸ºè´ªå¿ƒ FCFS**ï¼Œç¼ºä¹å¯¹æœªæ¥ phase transition çš„é¢„åˆ¤ï¼Œå¯èƒ½å¯¼è‡´åæœŸèµ„æºå†²çªã€‚
- **å°šæœªæ”¯æŒåˆ†å¸ƒå¼æ¨ç†**ï¼Œè™½ç„¶æ¶æ„ä¸Šå…¼å®¹ Tensor Parallelismï¼Œä½†è·¨è®¾å¤‡ KV shard åè°ƒä»éœ€è¿›ä¸€æ­¥å·¥ç¨‹å®ç°ã€‚
- **æ‰€æœ‰å®éªŒåŸºäº LLaDA æ¶æ„**ï¼Œæ˜¯å¦å®Œå…¨æ³›åŒ–è‡³å…¶ä»– dLLMï¼ˆå¦‚ Seed Diffusionï¼‰æœ‰å¾…éªŒè¯ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- è®¾è®¡ **Budgeting-Aware Scheduler**ï¼Œå¼•å…¥ lookahead è§„åˆ’ï¼Œä¿è¯å…¨ç¨‹ä¸è¶… token é¢„ç®—ã€‚
- æ‰©å±•è‡³ **multi-GPU / cluster ç¯å¢ƒ**ï¼Œæ¢ç´¢ä¸ TPã€PP çš„é›†æˆæ–¹æ¡ˆã€‚
- ç»“åˆ **early-exit æˆ– adaptive step skipping** æŠ€æœ¯ï¼Œè¿›ä¸€æ­¥ç¼©çŸ­æ¨ç†è·¯å¾„ã€‚
- å¼€æºé¡¹ç›®ä»£ç ï¼Œæ¨åŠ¨ç¤¾åŒºå…±å»ºé«˜æ•ˆçš„ dLLM serving ç”Ÿæ€ã€‚

---

> âœ… **æœ€ç»ˆç»“è®º**ï¼š  
> dLLM-Serve é¦–æ¬¡ç³»ç»Ÿæ€§åœ°è§£å†³äº† dLLM æ¨ç†ä¸­çš„â€œå†…å­˜è¶³è¿¹å±æœºâ€ï¼Œæå‡ºäº†ä¸€ä¸ªå¯æ‰©å±•ã€é«˜æ€§èƒ½ã€é«˜è´¨é‡çš„ç”Ÿäº§çº§æœåŠ¡è“å›¾ã€‚å®ƒä¸ä»…æå‡äº†ååä¸å»¶è¿Ÿè¡¨ç°ï¼Œæ›´é‡è¦çš„æ˜¯æ­ç¤ºäº†ä¸€ä¸ªæ ¸å¿ƒç†å¿µï¼š**é«˜æ•ˆçš„ AI æ¨ç†æœåŠ¡ä¸ä»…æ˜¯æ¨¡å‹æˆ–ç®—æ³•é—®é¢˜ï¼Œæ›´æ˜¯ç³»ç»Ÿè®¾è®¡çš„è‰ºæœ¯**ã€‚

</details>

---

### 2. [Enabling Disaggregated Multi-Stage MLLM Inference via GPU-Internal Scheduling and Resource Sharing](https://arxiv.org/abs/2512.17574)

**Authors**: Lingxiao Zhao, Haoran Zhou, Yuezhi Che, Dazhao Cheng  
**Category**: cs.DC  
**Published**: 2025-12-22  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.17574v1  

#### Abstract
Multimodal large language models (MLLMs) extend LLMs with visual understanding through a three-stage pipeline: multimodal preprocessing, vision encoding, and LLM inference. While these stages enhance capability, they introduce significant system bottlenecks. First, multimodal preprocessing-especiall...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEnabling Disaggregated Multi-Stage MLLM Inference via GPU-Internal Scheduling and Resource Sharing

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆ**MLLMs**ï¼‰åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¼•å…¥äº†è§†è§‰ç†è§£èƒ½åŠ›ï¼Œå…¶å…¸å‹æµç¨‹åŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼š**multimodal preprocessing**ï¼ˆå¦‚è§†é¢‘è§£ç ï¼‰ã€**vision encoding** å’Œ **LLM inference**ã€‚ç„¶è€Œï¼Œè¿™ç§å¼‚æ„æµæ°´çº¿å¸¦æ¥äº†ç³»ç»Ÿçº§ç“¶é¢ˆï¼š
- **è§†é¢‘è§£ç è€—æ—¶é•¿**ï¼šå°¤å…¶æ˜¯è§†é¢‘è§£ç å¸¸ä¸»å¯¼ **Time-to-First-Token (TTFT)**ï¼Œè€Œä¸»æµéƒ¨ç½²ä¾èµ– CPU è§£ç ï¼Œååä½ã€æ‰©å±•å·®ã€‚
- **è·¨é˜¶æ®µé˜»å¡ä¸¥é‡**ï¼švision encoder æ˜¯ç‹¬ç«‹ä¸”è®¡ç®—å¯†é›†çš„æ¨¡å—ï¼Œæ— æ³•ä¸ LLM çš„ prefill/decode é˜¶æ®µå…±æ‰¹å¤„ç†ï¼Œå¯¼è‡´ç”Ÿæˆå»¶è¿Ÿå¢åŠ ã€‚
- **èµ„æºåˆ©ç”¨ç‡ä½ä¸‹**ï¼šæ— è®ºæ˜¯ monolithic æ¶æ„è¿˜æ˜¯ split-based æ¶æ„ï¼Œéƒ½å­˜åœ¨èµ„æºç¢ç‰‡åŒ–é—®é¢˜ï¼Œéš¾ä»¥åŒæ—¶æ»¡è¶³ä½å»¶è¿Ÿå’Œé«˜ååéœ€æ±‚ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **FlashCodec** å’Œ **UnifiedServe** ä¸¤ä¸ªäº’è¡¥è®¾è®¡ï¼Œæ„å»ºç«¯åˆ°ç«¯ä¼˜åŒ–æ ˆï¼š

#### âœ… FlashCodec
- **ååŒå¤š GPU è§†é¢‘è§£ç æœºåˆ¶**ï¼šåˆ©ç”¨æ‰€æœ‰ GPU ä¸Šçš„ç¡¬ä»¶è§£ç å¼•æ“ï¼ˆå¦‚ NVDECï¼‰ï¼Œå°†å•ä¸ªè§†é¢‘åˆ’åˆ†ä¸ºå¤šä¸ª GOPï¼ˆGroup of Picturesï¼‰å¹¶è¡Œè§£ç ã€‚
- å¼•å…¥ **stall-free scheduling** ç­–ç•¥ï¼Œé¿å…è§£ç å•å…ƒç©ºè½¬ï¼Œæå‡æ•´ä½“åˆ©ç”¨ç‡ã€‚
- æ”¯æŒç»†ç²’åº¦è°ƒåº¦ï¼ˆä»¥ GOP ä¸ºå•ä½ï¼‰ï¼Œå®ç°è´Ÿè½½å‡è¡¡å’Œä½å»¶è¿Ÿã€‚

#### âœ… UnifiedServe
- **é€»è¾‘è§£è€¦ã€ç‰©ç†å…±äº«æ¶æ„**ï¼š
  - å°† MLLM æ¨ç†åˆ’åˆ†ä¸ºä¸‰ä¸ªå¼‚æ­¥åä½œçš„ workerï¼š
    - `vision_preprocess_worker`ï¼ˆä½¿ç”¨ FlashCodecï¼‰
    - `encode_prefill_worker`
    - `decode_worker`
  - å„é˜¶æ®µé€»è¾‘ä¸Šåˆ†ç¦»ä»¥æ¶ˆé™¤å¹²æ‰°ï¼Œä½†ç‰©ç†ä¸Šå…±äº«åŒä¸€ç»„ GPU èµ„æºæ± ï¼Œæœ€å¤§åŒ–åˆ©ç”¨ç‡ã€‚
- å¼•å…¥é«˜æ•ˆçš„ **embedding buffer management** æœºåˆ¶ï¼ˆç±»ä¼¼ PagedAttentionï¼‰ï¼Œç®¡ç†ä¸­é—´çŠ¶æ€ï¼Œé™ä½å†…å­˜å¼€é”€ã€‚
- é‡‡ç”¨ **token budget æ§åˆ¶ç­–ç•¥** åŠ¨æ€è°ƒèŠ‚ encode/prefill çš„è®¡ç®—è´Ÿè½½ï¼Œä¿éšœ decode çš„ä½ TBTã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Monolithic æ¶æ„ | Split-based æ¶æ„ | **UnifiedServe** |
|------|------------------|-------------------|------------------|
| **TTFT** | è¾ƒä½ï¼ˆå…¨èµ„æºå¯ç”¨ï¼‰ | é«˜ï¼ˆç¼–ç ç‹¬å èµ„æºï¼‰ | âœ… æ˜¾è‘—é™ä½ï¼ˆFlashCodec åŠ é€Ÿï¼‰ |
| **TBT** | é«˜ï¼ˆè¢« encoder å¹²æ‰°ï¼‰ | ä½ï¼ˆéš”ç¦»æ‰§è¡Œï¼‰ | âœ… æ¥è¿‘ split æ°´å¹³ï¼ˆdecode ä¸å—é˜»ï¼‰ |
| **ååé‡** | é«˜ | ä½ï¼ˆèµ„æºåˆ†è£‚ï¼‰ | âœ… æœ€é«˜ï¼ˆèµ„æºå…±äº«ï¼‰ |
| **èµ„æºåˆ©ç”¨ç‡** | é«˜ | ä½ | âœ… å……åˆ†åˆ©ç”¨ |

> ğŸ’¡ **æ ¸å¿ƒçªç ´**ï¼šé¦–æ¬¡å®ç°äº† **ä½ TTFT ä¸ä½ TBT çš„ç»Ÿä¸€**ï¼Œæ‰“ç ´äº†ä¼ ç»Ÿæ¶æ„ä¸­â€œè¦ä¹ˆå¿«é¦– tokenã€è¦ä¹ˆç¨³ç”Ÿæˆâ€çš„æƒè¡¡å›°å¢ƒã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | ç±»å‹ | æè¿° |
|-------|------|------|
| **MLVU** [69] | è§†é¢‘ | å¤šä»»åŠ¡æ ‡æ³¨çš„é•¿è§†é¢‘ï¼ˆ8â€“10åˆ†é’Ÿï¼‰ï¼Œç”¨äºæµ‹è¯•é‡è´Ÿè½½åœºæ™¯ |
| **EgoSchema** [37] | è§†é¢‘ | çŸ­è§†é¢‘ç‰‡æ®µï¼ˆçº¦3åˆ†é’Ÿï¼‰ï¼Œæ¨¡æ‹Ÿæ—¥å¸¸äº¤äº’åœºæ™¯ |
| **VisionArena** [12] | å›¾åƒ | åŒ…å«æ–‡æœ¬æè¿°çš„çœŸå®å›¾åƒå¯¹ï¼Œç”¨äºå›¾åƒç†è§£ä»»åŠ¡ |

> æ³¨ï¼šFlashCodec ä»…åœ¨ MLVU ä¸Šå¯ç”¨ï¼›å…¶ä»–æ•°æ®é›†ä½¿ç”¨ baseline çš„ Decord è§£ç å™¨è¿›è¡Œå…¬å¹³æ¯”è¾ƒã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š4Ã—A100 GPUsï¼ˆ80GBï¼‰
- **æ¨¡å‹é…ç½®**ï¼š
  - Qwen2.5-VL-32Bï¼ˆVisionEncoder: 0.5B, LMD: 32Bï¼‰
  - InternVL3-38Bï¼ˆVisionEncoder: 6B, LMD: 32Bï¼‰
- **å¹¶è¡Œç­–ç•¥**ï¼š
  - Monolithic: TP=4
  - Split: TP=2 for encode/prefill, TP=2 for decode
  - UnifiedServe: TP=4 for LLM, DP=2+TP=2 for Qwen encoding, TP=4 for InternVL3

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **TTFT** | Time to First Tokenï¼Œé¦– token å»¶è¿Ÿ |
| **TBT** | Time Between Tokensï¼Œtoken é—´å»¶è¿Ÿ |
| **P90/P99 TTFT/TBT** | å°¾éƒ¨å»¶è¿Ÿï¼Œåæ˜  SLO æ»¡è¶³èƒ½åŠ› |
| **Throughput (req/s)** | è¯·æ±‚ååé‡ |
| **SLO Attainment** | åœ¨ç»™å®šå»¶è¿Ÿçº¦æŸä¸‹å¯æœåŠ¡çš„æœ€å¤§è¯·æ±‚é€Ÿç‡ |
| **End-to-End Latency** | å•è¯·æ±‚æ€»å»¶è¿Ÿ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | æ–¹æ³• |
|------|------|
| **ç»Ÿä¸€æ¶æ„ï¼ˆMonolithicï¼‰** | vLLM-sï¼ˆchunked-prefillï¼‰ã€SGLang-s |
| **æ‹†åˆ†æ¶æ„ï¼ˆSplit-basedï¼‰** | vLLM-dã€SGLang-dï¼ˆPD-disaggregationï¼‰ |
| **è§†é¢‘è§£ç å™¨å¯¹æ¯”** | Decord [CPU/CUDA]ã€TorchCodec [CPU/CUDA]ã€DeepCodec [CPU]ã€FlashCodec [CUDAÃ—1/Ã—4] |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»
| æŒ‡æ ‡ | æå‡å¹…åº¦ | æ¥æº |
|------|--------|------|
| **æœ€å¤§ååé‡** | â¬†ï¸ **4.4Ã—** vs SOTA | å›¾14 |
| **å¯æœåŠ¡è¯·æ±‚æ•°** | â¬†ï¸ **3.0Ã—** | æ‘˜è¦ã€å›¾15 |
| **SLO çº¦æŸæ›´ä¸¥æ ¼** | ğŸ”’ **1.5Ã— tighter SLOs** | æ‘˜è¦ |
| **P99 TBT å»¶è¿Ÿ** | â¬‡ï¸ **83% reduction** vs monolithic | å›¾17 |
| **å¹³å‡ TTFT** | â¬‡ï¸ **80% reduction** vs split-based | å›¾13(a) |
| **è§†é¢‘è§£ç é€Ÿåº¦** | â¬†ï¸ **5.7â€“9.1Ã— faster** (4 GPUs) | å›¾3 |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ğŸ“Š ååé‡å¯¹æ¯”ï¼ˆå›¾14ï¼‰
- åœ¨ MLVU æ•°æ®é›†ä¸Šï¼ŒUnifiedServe ååé‡è¾¾åˆ° **~200k req/day**ï¼Œæ˜¯ vLLM-d çš„ **4.4Ã—**ã€‚
- Split-based æ–¹æ³•å› èµ„æºåˆ†è£‚ï¼Œååä»…ä¸º UnifiedServe çš„ **14%â€“51%**ã€‚

#### ğŸ“ˆ SLO æ»¡è¶³èƒ½åŠ›ï¼ˆå›¾15ï¼‰
- åœ¨ç›¸åŒ SLO ä¸‹ï¼ŒUnifiedServe å¯æ”¯æŒçš„è¯·æ±‚ç‡è¿œé«˜äºåŸºçº¿ï¼š
  - å¯¹äº Qwen-32B + MLVUï¼ŒUnifiedServe æ”¯æŒ **~20 req/s**ï¼Œè€Œ vLLM-d ä»…èƒ½æ”¯æŒ **~5 req/s**ã€‚
- åœ¨æ›´ä¸¥æ ¼çš„ SLO ç¼©æ”¾ä¸‹ï¼ˆå›¾16ï¼‰ï¼ŒUnifiedServe èƒ½æ»¡è¶³ **2å€ä»¥ä¸Š** çš„ä¸¥è‹›è¦æ±‚ã€‚

#### â±ï¸ å»¶è¿Ÿè¡¨ç°ï¼ˆå›¾13ï¼‰
- **é•¿è§†é¢‘åœºæ™¯ï¼ˆMLVUï¼‰**ï¼š
  - vLLM-sï¼šTTFT ä½ä½† TBT >300msï¼ˆè¢« encoder é˜»å¡ï¼‰
  - vLLM-dï¼šTBT <20ms ä½† TTFT å¾ˆé«˜
  - **UnifiedServe**ï¼š**TTFT â†“80%ï¼ŒTBT â†‘ä»… ~50%**ï¼Œå®ç°æœ€ä½³å¹³è¡¡
- **çŸ­è§†é¢‘/å›¾åƒåœºæ™¯**ï¼š
  - UnifiedServe åœ¨ E2E å»¶è¿Ÿä¸Šå…¨é¢ä¼˜äºå„ç±»åŸºçº¿ï¼Œå°¤å…¶åœ¨é«˜å¹¶å‘ä¸‹ä»ä¿æŒç¨³å®šã€‚

#### ğŸ¥ è§†é¢‘è§£ç æ€§èƒ½ï¼ˆå›¾18ï¼‰
- FlashCodec åœ¨ H.264/H.265/VP9 ç¼–ç æ ¼å¼ä¸‹å‡æ˜¾è‘—é¢†å…ˆï¼š
  - ç›¸æ¯” DeepCodecï¼ˆCPU æœ€ä¼˜æ–¹æ¡ˆï¼‰ï¼Œåœ¨ 4Ã—A100 ä¸Šå®ç° **æœ€é«˜ 9Ã— è§£ç åŠ é€Ÿ**ã€‚
  - å³ä½¿åœ¨ CPU å‹å¥½çš„ H.264 åœºæ™¯ï¼ŒFlashCodec ä»å¿« **4Ã—**ã€‚

### æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»è®¾è®¡åˆ†æä¸­å¯å¾—å‡ºä»¥ä¸‹ç»“è®ºï¼š
- **FlashCodec å•ç‹¬ä½œç”¨**ï¼šå¤§å¹…é™ä½ TTFTï¼Œå°¤å…¶æ˜¯åœ¨é•¿è§†é¢‘åœºæ™¯ã€‚
- **UnifiedServe è°ƒåº¦æœºåˆ¶**ï¼šé€šè¿‡ token budget æ§åˆ¶ï¼Œæœ‰æ•ˆæŠ‘åˆ¶ encode å¯¹ decode çš„å¹²æ‰°ï¼Œä¿éšœ TBT ç¨³å®šã€‚
- **èµ„æºå…±äº« vs ç‰©ç†æ‹†åˆ†**ï¼šç›¸æ¯” split æ¶æ„ï¼Œèµ„æºç¢ç‰‡å‡å°‘ï¼Œæ•´ä½“åˆ©ç”¨ç‡æå‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è§†é¢‘è§£ç å·²æˆä¸º MLLM æ¨ç†çš„å…³é”®ç“¶é¢ˆ**ï¼Œå°¤å…¶åœ¨é•¿è§†é¢‘åœºæ™¯ä¸‹ï¼Œå…¶å»¶è¿Ÿå¸¸è¶…è¿‡ LLM è‡ªèº«æ¨ç†æ—¶é—´ã€‚
2. **ä¼ ç»Ÿçš„ monolithic ä¸ split æ¶æ„å­˜åœ¨æ ¹æœ¬æ€§çŸ›ç›¾**ï¼šå‰è€…ç‰ºç‰² TBTï¼Œåè€…ç‰ºç‰² TTFT å’Œååã€‚
3. **é€»è¾‘è§£è€¦ + ç‰©ç†å…±äº«æ˜¯è§£å†³ MLLM æ¨ç†ç“¶é¢ˆçš„æœ‰æ•ˆè·¯å¾„**ï¼š
   - FlashCodec å®ç°äº† **ä½å»¶è¿Ÿã€é«˜ååçš„è§†é¢‘é¢„å¤„ç†**
   - UnifiedServe å®ç°äº† **é«˜åˆ©ç”¨ç‡ä¸‹çš„ä½å»¶è¿Ÿç”Ÿæˆ**
4. **é€šè¿‡ç²¾ç»†çš„èµ„æºè°ƒåº¦ï¼ˆå¦‚ token budgetï¼‰å¯ä»¥æ§åˆ¶å¼‚æ„é˜¶æ®µé—´çš„å¹²æ‰°**ï¼Œæ— éœ€å®Œå…¨ç‰©ç†éš”ç¦»ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–ç‰¹å®šç¡¬ä»¶**ï¼šFlashCodec é«˜åº¦ä¾èµ– GPU å†…ç½®çš„ç¡¬ä»¶è§£ç å™¨ï¼ˆå¦‚ NVDECï¼‰ï¼Œåœ¨æ— æ­¤ç±»è®¾å¤‡çš„ç¯å¢ƒä¸­æ•ˆæœå—é™ã€‚
- **å¤æ‚æ€§å¢åŠ **ï¼šå¤š worker å¼‚æ­¥åä½œå¢åŠ äº†ç³»ç»Ÿå¤æ‚æ€§å’Œè°ƒè¯•éš¾åº¦ã€‚
- **å½“å‰ä¸»è¦é¢å‘ç¦»çº¿/å‡†å®æ—¶åœºæ™¯**ï¼šå¯¹äºè¶…ä½å»¶è¿Ÿï¼ˆ<100msï¼‰çš„å¼ºå®æ—¶åº”ç”¨ï¼Œä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤šæ¨¡æ€ï¼ˆéŸ³é¢‘ã€3D ç‚¹äº‘ç­‰ï¼‰çš„ç»Ÿä¸€é¢„å¤„ç†æ¡†æ¶ã€‚
- ç»“åˆç®—æ³•çº§ä¼˜åŒ–ï¼ˆå¦‚ visual token å‹ç¼©ï¼‰ä¸ç³»ç»Ÿçº§ä¼˜åŒ–ï¼Œè¿›ä¸€æ­¥é™ä½å¸¦å®½å’Œè®¡ç®—å¼€é”€ã€‚
- æ¢ç´¢åŠ¨æ€èµ„æºåˆ†é…æœºåˆ¶ï¼Œåœ¨ä¸åŒè¯·æ±‚ç±»å‹ï¼ˆå›¾åƒ vs è§†é¢‘ï¼‰ä¹‹é—´æ™ºèƒ½è°ƒåº¦ã€‚
- æ”¯æŒå¼‚æ„é›†ç¾¤ï¼ˆCPU+GPU+NPUï¼‰ä¸‹çš„è·¨èŠ‚ç‚¹ååŒæ¨ç†ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºçš„ **FlashCodec + UnifiedServe** æ¡†æ¶ï¼Œé€šè¿‡ **ååŒå¤š GPU è§£ç ** ä¸ **é€»è¾‘è§£è€¦ã€èµ„æºå…±äº«çš„è°ƒåº¦æ¶æ„**ï¼Œé¦–æ¬¡å®ç°äº† MLLM æ¨ç†ä¸­ **ä½ TTFTã€ä½ TBTã€é«˜åå** çš„â€œä¸å¯èƒ½ä¸‰è§’â€çªç ´ï¼Œç›¸è¾ƒ SOTA ç³»ç»Ÿå®ç°é«˜è¾¾ **4.4Ã— ååæå‡** å’Œ **3.0Ã— æ›´å¤šè¯·æ±‚æœåŠ¡èƒ½åŠ›**ã€‚

</details>

---

### 3. [LLM-HPC++: Evaluating LLM-Generated Modern C++ and MPI+OpenMP Codes for Scalable Mandelbrot Set Computation](https://arxiv.org/abs/2512.17023)

**Authors**: Patrick Diehl, Noujoud Nader, Deepti Gupta  
**Category**: cs.DC  
**Published**: 2025-12-22  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.17023v1  

#### Abstract
Parallel programming remains one of the most challenging aspects of High-Performance Computing (HPC), requiring deep knowledge of synchronization, communication, and memory models. While modern C++ standards and frameworks like OpenMP and MPI have simplified parallelism, mastering these paradigms is...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLLM-HPC++: Evaluating LLM-Generated Modern C++ and MPI+OpenMP Codes for Scalable Mandelbrot Set Computation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡ç³»ç»Ÿè¯„ä¼°äº†å½“å‰ä¸»æµ **Large Language Models (LLMs)** åœ¨ç”Ÿæˆé«˜æ€§èƒ½è®¡ç®—ï¼ˆHPCï¼‰é¢†åŸŸä¸­å¤æ‚ã€å¯æ‰©å±•çš„å¹¶è¡Œ C++ ä»£ç æ–¹é¢çš„èƒ½åŠ›ã€‚å°½ç®¡ LLMs å·²è¢«å¹¿æ³›ç”¨äºé€šç”¨ä»£ç ç”Ÿæˆï¼Œä½†å…¶åœ¨éœ€è¦ç²¾ç¡®åŒæ­¥ã€å†…å­˜ç®¡ç†å’Œé€šä¿¡æœºåˆ¶çš„ **ç°ä»£å¹¶è¡Œç¼–ç¨‹èŒƒå¼**ï¼ˆå¦‚ C++11/17/20ã€OpenMPã€MPI+OpenMPï¼‰ä¸­çš„æœ‰æ•ˆæ€§å°šæœªå¾—åˆ°å……åˆ†éªŒè¯ã€‚

è¯¥ç ”ç©¶æ—¨åœ¨å¡«è¡¥ AI è¾…åŠ©ç¼–ç¨‹ä¸ HPC é«˜æ•ˆå®ç°ä¹‹é—´çš„é¸¿æ²Ÿï¼Œå›ç­”ä¸€ä¸ªå…³é”®é—®é¢˜ï¼š**LLMs æ˜¯å¦èƒ½å¯é åœ°ç”Ÿæˆæ­£ç¡®ã€é«˜æ•ˆä¸”å¯æ‰©å±•çš„ç§‘å­¦è®¡ç®—ä»£ç ï¼Ÿ**

### æå‡ºçš„æ–°æ–¹æ³•/æ–°æ€è·¯
- è®¾è®¡äº†ä¸€å¥—**ç»“æ„åŒ–æç¤ºå·¥ç¨‹ï¼ˆprompt engineeringï¼‰ç­–ç•¥**ï¼Œé’ˆå¯¹ä¸åŒå¹¶è¡Œæ¨¡å‹ï¼ˆå…±äº«å†…å­˜ã€æŒ‡ä»¤çº§ã€åˆ†å¸ƒå¼å†…å­˜ï¼‰ç»Ÿä¸€ä½¿ç”¨æ ‡å‡†åŒ– prompt æ¥æµ‹è¯•å¤šä¸ª LLMã€‚
- ä»¥ **Mandelbrot é›†åˆè®¡ç®—**ä½œä¸ºâ€œå°´å°¬å¹¶è¡Œâ€ï¼ˆembarrassingly parallelï¼‰çš„åŸºå‡†ä»»åŠ¡ï¼Œé¿å…å¼•å…¥æ±‚è§£å™¨æˆ–å¤–éƒ¨åº“ä¾èµ–ï¼Œèšç„¦äºå¹¶è¡Œé€»è¾‘æœ¬èº«ã€‚
- æ„å»ºäº†ä¸€ä¸ªå®Œæ•´çš„è¯„ä¼°æµç¨‹ï¼šä»ä»£ç ç”Ÿæˆ â†’ ç¼–è¯‘ â†’ è¿è¡Œæ—¶é”™è¯¯æ£€æµ‹ â†’ åŠŸèƒ½æ­£ç¡®æ€§éªŒè¯ï¼ˆé€šè¿‡ PBM å›¾åƒè¾“å‡ºï¼‰â†’ æ€§èƒ½ä¸å¯æ‰©å±•æ€§åˆ†æã€‚
- å¼•å…¥ **COCOMO æ¨¡å‹** å¯¹ç”Ÿæˆä»£ç çš„å¼€å‘éš¾åº¦è¿›è¡Œé‡åŒ–ä¼°ç®—ï¼Œæä¾›è´¨é‡ä¸åŠªåŠ›ä¹‹é—´çš„æƒè¡¡è§†è§’ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- æ˜¯é¦–ä¸ªå¯¹å¤šç§ç°ä»£ C++ å¹¶è¡ŒèŒƒå¼ï¼ˆåŒ…æ‹¬ C++20 coroutines å’Œæ··åˆ MPI+OpenMPï¼‰è¿›è¡Œå…¨é¢ LLM ä»£ç ç”Ÿæˆèƒ½åŠ›è¯„ä¼°çš„ç ”ç©¶ã€‚
- ä¸ä»…å…³æ³¨è¯­æ³•æ­£ç¡®æ€§ï¼Œè¿˜æ·±å…¥åˆ†æè¯­ä¹‰ä¸€è‡´æ€§ã€è¿è¡Œæ—¶è¡Œä¸ºã€è°ƒè¯•é²æ£’æ€§å’Œå®é™…æ€§èƒ½è¡¨ç°ã€‚
- å…¬å¼€äº†æ‰€æœ‰ç”Ÿæˆä»£ç ï¼ˆGitHub/Zenodoï¼‰ï¼Œæå‡äº†å¯å¤ç°æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ¨¡å‹ï¼ˆLLMsï¼‰
- **ChatGPT-4**
- **ChatGPT-5**
- **Claude**
- **LLaMA**

> æ³¨ï¼šæ–‡ä¸­æœªæ˜ç¡®è¯´æ˜å…·ä½“ç‰ˆæœ¬å·ï¼ˆå¦‚ LLaMA-2 æˆ– LLaMA-3ï¼‰ï¼Œä½†åŸºäºä¸Šä¸‹æ–‡æ¨æµ‹ä¸º LLaMA-2 ç³»åˆ—ã€‚

### å®éªŒä»»åŠ¡ä¸ä»£ç èŒƒå¼
è¯„ä¼°ä»¥ä¸‹äº”ç±»å¹¶è¡Œå®ç°ï¼š
1. **Shared-memory parallelism**:
   - `std::async` / `future` (C++11)
   - Parallel algorithms with execution policies (C++17)
   - Coroutines (C++20)
2. **Directive-based parallelism**: OpenMP
3. **Distributed-memory parallelism**: Hybrid MPI + OpenMP

### Prompt è®¾è®¡
- **P1**: é’ˆå¯¹ C++ å†…ç½®å¹¶è¡Œç‰¹æ€§ï¼ˆasync, parallel algorithms, coroutinesï¼‰
  > â€œWrite a parallel code for the Mandelbrot set using C++{11 async future, 17 parallel algorithms, 20 coroutines} and write the output to the PBM format. Make the number of threads configurable with the command line option -t and print the runtime excluding IO.â€
- **P2**: OpenMP ç‰ˆæœ¬ï¼Œç±»ä¼¼ P1
- **P3**: MPI+OpenMP æ··åˆç‰ˆæœ¬
  > â€œWrite a distributed code using MPI for the Mandelbrot set and using OpenMP for parallelism in C++ and write the output to the PBM format. Make the number of partitions configurable with the command line option -p and print the runtime excluding IO.â€

> ç‰¹åˆ«å¼ºè°ƒéœ€æ”¯æŒå‘½ä»¤è¡Œå‚æ•°æ§åˆ¶èµ„æºåˆ†é…ï¼Œå¹¶è¾“å‡º PBM æ ¼å¼å›¾åƒä»¥ä¾¿è§†è§‰éªŒè¯ã€‚

### å®éªŒå¹³å°ä¸å·¥å…·é“¾
- **ç¼–è¯‘å™¨**: GCC 11.5.0
- **MPI åº“**: OpenMPI 5.0.7
- **TBB**: IntelÂ® TBB 2022.2ï¼ˆç”¨äº C++17 å¹¶è¡Œç®—æ³•åç«¯ï¼‰
- **ç¡¬ä»¶å¹³å°**: LSU çš„ rostam é›†ç¾¤ï¼ˆIntel Xeon Gold 6148 CPU @ 2.40GHz, 20 cores/nodeï¼‰
- **ä»£ç åˆ†æå·¥å…·**:
  - `cloc`: ç»Ÿè®¡ LOCï¼ˆlines of codeï¼‰
  - `scc`: è·å– COCOMO å¼€å‘æˆæœ¬ä¼°è®¡

### è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **Correctness** | ç¼–è¯‘æˆåŠŸï¼ˆBuildï¼‰ã€è¿è¡Œæ— å´©æºƒï¼ˆRuntimeï¼‰ã€å›¾åƒæ­£ç¡®ï¼ˆVisual Validationï¼‰ |
| **Robustness** | é”™è¯¯ç±»å‹åˆ†ç±»ï¼ˆbuild/runtimeï¼‰ã€æ˜¯å¦éœ€äººå·¥ä¿®å¤ |
| **Scalability** | å•èŠ‚ç‚¹å¤šæ ¸æ‰©å±•æ€§ï¼ˆ1â€“20 coresï¼‰ã€å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼æ‰©å±•æ€§ï¼ˆ1â€“12 nodesï¼‰ |
| **Efficiency** | Pixels processed per secondã€Speedup |
| **Code Quality** | LOCã€COCOMO estimated effort |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æœ¬ç ”ç©¶ä¸ç›´æ¥æ¯”è¾ƒä¼ ç»Ÿæ‰‹å†™ HPC ä»£ç ï¼Œè€Œæ˜¯å°†ä¸åŒ LLM è§†ä¸ºâ€œå¼€å‘è€…â€ï¼Œç›¸äº’ä¹‹é—´è¿›è¡Œæ¨ªå‘å¯¹æ¯”ï¼Œé‡ç‚¹å…³æ³¨ï¼š
- å„æ¨¡å‹åœ¨å„ç±»å¹¶è¡ŒèŒƒå¼ä¸‹çš„æˆåŠŸç‡
- å¯æ‰©å±•æ€§è¡¨ç°
- è°ƒè¯•è´Ÿæ‹…ï¼ˆå³ç”Ÿæˆä»£ç çš„â€œå¼€ç®±å³ç”¨â€ç¨‹åº¦ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### âœ… ç¼–è¯‘ä¸è¿è¡Œæ—¶æ­£ç¡®æ€§ï¼ˆè§ Table 1 & 2ï¼‰

#### å…±äº«å†…å­˜å¹¶è¡Œï¼ˆTable 1ï¼‰
| LLM \ Paradigm | Coroutines | Async | Parallel Alg. | OpenMP |
|----------------|----------|--------|---------------|--------|
| **ChatGPT-5** | âˆš / X / âˆš | âˆš / X / âˆš | âˆš / X / âˆš | âˆš / X / âˆš |
| **ChatGPT-4** | âˆš / X / âˆš | âˆš / X / âˆš | âˆš / X / âˆš | âˆš / X / âˆš |
| **Claude**     | âˆš / X / âˆš | âˆš / âˆš / âˆš | âˆš / X / âˆš | âˆš / âˆš / âˆš |
| **LLaMA**      | X / X / X | âˆš / X / X | X / X / âˆš | âˆš / X / âˆš |

> ç¬¦å·è¯´æ˜ï¼šâˆš è¡¨ç¤ºæ— æ­¤é”™è¯¯ï¼ŒX è¡¨ç¤ºå­˜åœ¨é”™è¯¯ï¼›ä¸‰åˆ—åˆ†åˆ«ä¸º Build / Runtime / Correctness

- **ChatGPT-5** å’Œ **ChatGPT-4** åœ¨æ„å»ºä¸Šå…¨éƒ¨æˆåŠŸï¼Œä½†åœ¨åç¨‹å’Œå¼‚æ­¥ç¼–ç¨‹ä¸­å‡ºç°è¿è¡Œæ—¶æŒ‚èµ·æˆ–æ­»å¾ªç¯ã€‚
- **LLaMA** åœ¨ coroutine ä¸Šå®Œå…¨å¤±è´¥ï¼ˆç¼–è¯‘å¤±è´¥ + segfaultï¼‰ï¼Œä¸”å¤šæ•°æƒ…å†µä¸‹å¿½ç•¥çº¿ç¨‹æ•°é…ç½®ã€‚
- **Claude** åœ¨ coroutine ä¸­å›  `final_suspend=std::suspend_never` å¯¼è‡´æ— é™å¾ªç¯ï¼Œéœ€æ‰‹åŠ¨ä¿®å¤ã€‚

#### åˆ†å¸ƒå¼å†…å­˜ï¼ˆTable 2ï¼‰
| LLM | Build | Runtime | Correctness |
|-----|-------|---------|-------------|
| **ChatGPT-5** | âˆš | âˆš | âˆš |
| **ChatGPT-4** | âˆš | âˆš | âˆš |
| **Claude**    | âˆš | âˆš | âˆš |
| **LLaMA**     | âˆš | X | âˆšï¼ˆä¿®å¤åï¼‰|

- LLaMA ç”Ÿæˆçš„ MPI ä»£ç åœ¨å¤šè¿›ç¨‹ä¸‹å´©æºƒï¼ˆfree(): invalid pointer, MPI_Gather buffer mismatchï¼‰ï¼Œéœ€ä¿®å¤æ‰èƒ½è¿è¡Œã€‚

### ğŸ“Š ä»£ç è§„æ¨¡ä¸å¼€å‘éš¾åº¦ï¼ˆCOCOMO åˆ†æï¼‰

#### åˆ†å¸ƒå¼ä»£ç  LOCï¼ˆTable 3ï¼‰
| LLM | Lines of Code (LOC) |
|-----|---------------------|
| ChatGPT-5 | 143 |
| Claude    | 116 |
| ChatGPT-4 | 91  |
| LLaMA     | 71  |

- **ChatGPT-5 ç”Ÿæˆæœ€è¯¦ç»†çš„ä»£ç **ï¼ŒLOC æœ€é«˜ï¼Œå¯èƒ½åŒ…å«æ›´å¤šå¥å£®æ€§æ£€æŸ¥ã€‚
- ç»“åˆ COCOMO æ¨¡å‹åˆ†æï¼ˆå›¾4ã€å›¾5ï¼‰ï¼š
  - **ChatGPT-5** ä»£ç è´¨é‡æœ€é«˜ï¼ˆå³ä¸Šè§’ï¼‰ï¼Œè™½å¼€å‘ effort ç•¥é«˜ï¼Œä½†å¯é æ€§å¼ºã€‚
  - **LLaMA** effort æœ€ä½ï¼Œä½† runtime é”™è¯¯æœ€å¤šï¼Œå±äºâ€œä¾¿å®œä½†ä¸å¯é â€ã€‚

### ğŸ”¬ å¯æ‰©å±•æ€§è¡¨ç°ï¼ˆScaling Resultsï¼‰

#### å•èŠ‚ç‚¹å…±äº«å†…å­˜æ‰©å±•ï¼ˆå›¾6ï¼‰
- **ChatGPT-5** æˆåŠŸå®ç°äº†çº¿ç¨‹å¯æ§çš„ scalingï¼ˆå°¤å…¶åœ¨ parallel algorithms ä¸­ä½¿ç”¨ `tbb::global_control` æ­£ç¡®é™åˆ¶çº¿ç¨‹æ•°ï¼‰ã€‚
- **ChatGPT-4** å­˜åœ¨é—®é¢˜ï¼šparallel algorithms ä½¿ç”¨ `OPENMP_NUM_THREADS` è®¾ç½®æ— æ•ˆï¼ˆGCC ä½¿ç”¨ TBB åç«¯ï¼‰ã€‚
- **Claude** å¤šæ•°æƒ…å†µé»˜è®¤ä½¿ç”¨å…¨éƒ¨æ ¸å¿ƒï¼Œæ— æ³•æ§åˆ¶çº¿ç¨‹æ•°ã€‚
- **LLaMA** æ‰€æœ‰å®ç°å‡å¿½ç•¥ `-t` å‚æ•°ï¼Œå§‹ç»ˆå ç”¨å…¨éƒ¨ 20 coresã€‚

#### å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼æ‰©å±•ï¼ˆå›¾7ï¼‰
- æ‰€æœ‰æ¨¡å‹ï¼ˆé™¤ LLaMA å¤–ï¼‰ç”Ÿæˆçš„ä»£ç åœ¨ä¿®å¤åå‡å¯æ‰©å±•è‡³ 12 èŠ‚ç‚¹ã€‚
- **å…±åŒç°è±¡**ï¼šä» 2 åˆ° 4 èŠ‚ç‚¹çš„åŠ é€Ÿæ¯”ä¸‹é™æ˜æ˜¾ï¼Œå¯èƒ½æ˜¯é€šä¿¡å¼€é”€çªå¢æ‰€è‡´ã€‚
- **LLaMA** æ—¶é—´æµ‹é‡é—æ¼ MPI_Gather é˜¶æ®µï¼Œå¯¼è‡´æ€§èƒ½è¯„ä¼°åå·®ï¼Œéœ€ä¿®æ­£ã€‚
- æ•´ä½“æ¥çœ‹ï¼Œ**ChatGPT-4/5 å’Œ Claude çš„åˆ†å¸ƒå¼æ€§èƒ½ç›¸è¿‘ä¸”è‰¯å¥½**ï¼ŒLLaMA ç»ä¿®å¤åå¯è¾¾ Claude æ°´å¹³ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **ChatGPT-4 å’Œ ChatGPT-5 è¡¨ç°æœ€ä½³**ï¼šå…·å¤‡è¾ƒå¼ºçš„è¯­æ³•å‡†ç¡®æ€§å’ŒåŠŸèƒ½å®Œæ•´æ€§ï¼Œåœ¨å¤šç§å¹¶è¡ŒèŒƒå¼ä¸‹ç”Ÿæˆçš„ä»£ç ç»è¿‡å°‘é‡è°ƒè¯•å³å¯æ­£ç¡®è¿è¡Œå¹¶å…·æœ‰è‰¯å¥½å¯æ‰©å±•æ€§ã€‚
2. âš ï¸ **çº¿ç¨‹/è¿›ç¨‹æ§åˆ¶æ˜¯æ™®éçŸ­æ¿**ï¼šå¤§å¤šæ•°æ¨¡å‹æœªèƒ½æ­£ç¡®å¤„ç†åŠ¨æ€çº¿ç¨‹æ•°é…ç½®ï¼ˆå¦‚ `-t` å‚æ•°ï¼‰ï¼Œå¸¸é»˜è®¤ä½¿ç”¨å…¨éƒ¨å¯ç”¨èµ„æºï¼Œå½±å“å®éªŒå…¬å¹³æ€§å’Œå®ç”¨æ€§ã€‚
3. âŒ **LLaMA åœ¨å¤æ‚å¹¶è¡Œç»“æ„ä¸­è¡¨ç°è¾ƒå·®**ï¼šå°¤å…¶åœ¨ coroutine å’Œ MPI åœºæ™¯ä¸­é¢‘ç¹å‡ºç°ç¼–è¯‘é”™è¯¯ã€å†…å­˜é”™è¯¯å’Œé€»è¾‘ç¼ºé™·ï¼Œéœ€å¤§é‡äººå·¥å¹²é¢„ã€‚
4. ğŸ’¡ **æç¤ºå·¥ç¨‹è‡³å…³é‡è¦**ï¼šåœ¨ MPI+OpenMP åœºæ™¯ä¸­ï¼Œå¿…é¡»æ˜¾å¼è¦æ±‚â€œpartition å¯é…ç½®â€ï¼Œå¦åˆ™æ¨¡å‹ä¼šé‡å¤è®¡ç®—è€Œéåˆ†ç‰‡å¤„ç†ã€‚
5. ğŸ¨ **é¢œè‰²æ˜ å°„ä¸ä¸€è‡´**ï¼šåŒä¸€æ¨¡å‹ï¼ˆå¦‚ ChatGPT-5ï¼‰åœ¨å…±äº«ä¸åˆ†å¸ƒç‰ˆæœ¬ä¸­ä½¿ç”¨ä¸åŒçš„ color mapping å‡½æ•°ï¼Œæš´éœ²äº†ç”Ÿæˆè¿‡ç¨‹ç¼ºä¹å…¨å±€ä¸€è‡´æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- ä»…è¯„ä¼°äº† **Mandelbrot é›†è¿™ä¸€ç‰¹å®š workload**ï¼Œè™½å…·ä»£è¡¨æ€§ï¼Œä½†ä»å±ç®€åŒ–åœºæ™¯ï¼Œæœªæ¶‰åŠçœŸå® HPC åº”ç”¨ä¸­çš„å¤æ‚æ•°æ®ç»“æ„æˆ–é€šä¿¡æ¨¡å¼ã€‚
- æ‰€æœ‰é”™è¯¯å‡ç”±ä½œè€…æ‰‹åŠ¨ä¿®å¤ï¼Œæœªè‡ªåŠ¨åŒ–è¯„ä¼°â€œè°ƒè¯•æˆæœ¬â€ã€‚
- COCOMO æ¨¡å‹åŸæœ¬é¢å‘ä¸²è¡Œè½¯ä»¶ï¼Œåº”ç”¨äºå¹¶è¡Œä»£ç å­˜åœ¨ä¸€å®šç†è®ºåå·®ã€‚
- ç¼ºä¹ä¸ä¸“å®¶æ‰‹å·¥ç¼–å†™æœ€ä¼˜å®ç°çš„æ€§èƒ½å¯¹æ¯”ï¼ˆä»…è¯„ä¼°ç›¸å¯¹ scaling è¡Œä¸ºï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ„å»ºä¸“é—¨é¢å‘ HPC çš„ **domain-specific LLMs**ï¼ˆå¦‚ MPIrigenã€HPC-Coder çš„å»¶ç»­ï¼‰ã€‚
- æ¢ç´¢è‡ªåŠ¨åé¦ˆé—­ç¯æœºåˆ¶ï¼šè®© LLM è‡ªåŠ¨è§£æç¼–è¯‘/è¿è¡Œé”™è¯¯å¹¶è¿­ä»£ä¿®å¤ä»£ç ã€‚
- æ‰©å±•åˆ°æ›´å¤š HPC æ ¸å¿ƒç®—ä¾‹ï¼ˆå¦‚ stencilã€FFTã€sparse solversï¼‰å’Œè¯­è¨€ï¼ˆFortranã€CUDAï¼‰ã€‚
- å»ºç«‹æ ‡å‡†åŒ–çš„ **LLM-for-HPC benchmark suite**ï¼Œæ¨åŠ¨å¯å¤ç°ç ”ç©¶ã€‚
- ç ”ç©¶å¦‚ä½•æå‡ LLM å¯¹åº•å±‚è¿è¡Œæ—¶ç³»ç»Ÿï¼ˆå¦‚ TBBã€OpenMP runtimeï¼‰çš„ç†è§£èƒ½åŠ›ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> å½“å‰æœ€å…ˆè¿›çš„ LLMsï¼ˆå°¤å…¶æ˜¯ ChatGPT-4/5ï¼‰å·²èƒ½åœ¨é€‚å½“æç¤ºä¸‹ç”ŸæˆåŸºæœ¬æ­£ç¡®çš„ç°ä»£ C++ å¹¶è¡Œä»£ç ï¼Œå¹¶å±•ç°å‡ºè‰¯å¥½çš„å¯æ‰©å±•æ½œåŠ›ï¼›ç„¶è€Œï¼Œåœ¨çº¿ç¨‹ç®¡ç†ã€è¿è¡Œæ—¶æ§åˆ¶å’Œè·¨èŒƒå¼ä¸€è‡´æ€§æ–¹é¢ä»å­˜åœ¨æ˜¾è‘—ç¼ºé™·ï¼Œè·ç¦»â€œè‡ªä¸»ç”Ÿæˆç”Ÿäº§çº§ HPC ä»£ç â€å°šæœ‰å·®è·ã€‚

</details>

---

### 4. [BumpNet: A Sparse Neural Network Framework for Learning PDE Solutions](https://arxiv.org/abs/2512.17198)

**Authors**: Shao-Ting Chiu, Ioannis G. Kevrekidis, Ulisses Braga-Neto  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.17198v1  

#### Abstract
We introduce BumpNet, a sparse neural network framework for PDE numerical solution and operator learning. BumpNet is based on meshless basis function expansion, in a similar fashion to radial-basis function (RBF) networks. Unlike RBF networks, the basis functions in BumpNet are constructed from ordi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šBumpNet: A Sparse Neural Network Framework for Learning PDE Solutions

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåŸºäºæ·±åº¦ç¥ç»ç½‘ç»œçš„ PDE æ±‚è§£æ–¹æ³•ï¼ˆå¦‚ PINN å’Œ DeepONetï¼‰é€šå¸¸ä¾èµ–äºå…¨è¿æ¥å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ï¼Œå­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **å‚æ•°é‡å¤§**ï¼šå¯¼è‡´è®­ç»ƒæ•ˆç‡ä½ã€è®¡ç®—å¼€é”€é«˜ï¼›
- **ç¼ºä¹å¯è§£é‡Šæ€§**ï¼šéš¾ä»¥ç†è§£æ¨¡å‹å†…éƒ¨å¦‚ä½•é€¼è¿‘è§£ï¼›
- **å›ºå®šåŸºå‡½æ•°é™åˆ¶**ï¼šå¦‚ RBF ç½‘ç»œè™½å…·å¯è§£é‡Šæ€§ï¼Œä½†å…¶åŸºå‡½æ•°å½¢çŠ¶å’Œä¸­å¿ƒå¸¸ä¸ºé¢„è®¾æˆ–éå¯è®­ç»ƒã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **BumpNet** â€”â€”ä¸€ç§ç¨€ç–ã€å¯è§£é‡Šçš„ä¸¤å±‚ç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œç”¨äºå‡½æ•°é€¼è¿‘å’Œ PDE è§£çš„å­¦ä¹ ã€‚å…¶æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ï¼š

- **åŸºäº sigmoid çš„â€œbumpâ€åŸºå‡½æ•°æ„é€ **ï¼šé€šè¿‡å¤šä¸ª tanh æ¿€æ´»å‡½æ•°çš„çº¿æ€§ç»„åˆæ„å»ºå±€éƒ¨åŒ–ã€å¯è®­ç»ƒçš„â€œbumpâ€å½¢åŸºå‡½æ•°ï¼Œé¿å…ä½¿ç”¨ä¸“ç”¨ RBF éçº¿æ€§æ¿€æ´»ã€‚
- **å®Œå…¨å¯è®­ç»ƒçš„åŸºå‡½æ•°å‚æ•°**ï¼šæ¯ä¸ª bump çš„ä½ç½®ï¼ˆcenterï¼‰ã€æ–¹å‘ï¼ˆorientationï¼‰ã€é”åº¦ï¼ˆsharpnessï¼‰å’ŒæŒ¯å¹…ï¼ˆamplitudeï¼‰å‡å¯é€šè¿‡æ¢¯åº¦ä¼˜åŒ–å­¦ä¹ ã€‚
- **åŠ¨æ€å‰ªæå®ç° h-adaptivity**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ ¹æ® bump çš„é«˜åº¦ $ h_i $ åŠ¨æ€ç§»é™¤ä½å¹…å€¼åŸºå‡½æ•°ï¼Œè‡ªåŠ¨å®ç°æ¨¡å‹ç®€åŒ–ä¸è‡ªé€‚åº”ç½‘æ ¼ç»†åŒ–ï¼ˆh-adaptivityï¼‰ã€‚
- **æ¨¡å—åŒ–é›†æˆèƒ½åŠ›**ï¼šBumpNet å¯ä½œä¸ºç»„ä»¶åµŒå…¥å¤šç§ä¸»æµæ¶æ„ï¼Œå½¢æˆï¼š
  - **Bump-PINN**ï¼šç»“åˆ Physics-Informed Neural Networksï¼›
  - **Bump-EDNN**ï¼šç”¨äºæ—¶é—´æ¼”åŒ– PDE çš„è¿›åŒ–å‹æ±‚è§£ï¼›
  - **Bump-DeepONet**ï¼šç”¨äºç®—å­å­¦ä¹ ä»»åŠ¡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | BumpNet ä¼˜åŠ¿ |
|------|-------------|
| **å‚æ•°æ•ˆç‡** | å‚æ•°æ•°é‡æ¯”æ ‡å‡† MLP å°‘ 20â€“100 å€ï¼ˆä¾‹å¦‚ä»…éœ€ 252 å‚æ•°å³å¯è¾¾åˆ°è‰¯å¥½ç²¾åº¦ï¼‰ |
| **è®­ç»ƒé€Ÿåº¦** | æ›´å¿«æ”¶æ•›ï¼Œæ˜¾è‘—ç¼©çŸ­è®­ç»ƒæ—¶é—´ï¼ˆå¦‚ Poisson æ–¹ç¨‹å¿« 20Ã—ï¼‰ |
| **å¯è§£é‡Šæ€§** | æ‰€æœ‰ bump çš„å‡ ä½•å±æ€§å¯ç›´æ¥ä»æƒé‡è§£æå¾—å‡ºï¼Œä¾¿äºåˆ†æ |
| **çµæ´»æ€§ä¸é€šç”¨æ€§** | æ”¯æŒä»»æ„ç»´åº¦ç©ºé—´ï¼Œæ”¯æŒ operator learning å’Œ time-stepping æ¶æ„ |
| **è‡ªé€‚åº”èƒ½åŠ›** | å‰ªææœºåˆ¶å®ç°è‡ªåŠ¨æ¨¡å‹å‹ç¼©ä¸åŒºåŸŸèšç„¦ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›† / æµ‹è¯•é—®é¢˜
è®ºæ–‡é‡‡ç”¨å¤šä¸ªç»å…¸åå¾®åˆ†æ–¹ç¨‹åŸºå‡†è¿›è¡ŒéªŒè¯ï¼Œæ¶µç›–ä¸åŒç±»å‹çš„ PDEï¼š

1. **Helmholtz æ–¹ç¨‹ï¼ˆéé½æ¬¡ï¼‰**
   - $ u_{xx} + u_{yy} + ku = q(x,y) $
   - å®šä¹‰åŸŸï¼š$[-3,3]^2$ï¼Œé›¶è¾¹ç•Œæ¡ä»¶
   - çœŸå®è§£ï¼š$ \sin(\pi x)\sin(\pi y) $

2. **äºŒç»´ Poisson æ–¹ç¨‹**
   - $ u_{xx} + u_{yy} = f(x,y) $
   - å®šä¹‰åŸŸï¼š$[0,1]^2$ï¼Œé›¶è¾¹å€¼
   - çœŸå®è§£ï¼š$ \sin(2\pi x)\sin(4\pi y) $

3. **çƒ­ä¼ å¯¼æ–¹ç¨‹ï¼ˆHeat Equationï¼‰**
   - $ u_t = u_{xx} + 2\sin(\pi x) $
   - æ—¶ç©ºåŸŸï¼š$[0,1]\times[0,5]$ï¼Œåˆå§‹æ¡ä»¶ $ u(x,0)=\sin(2\pi x) $

4. **å¯¹æµæ–¹ç¨‹ï¼ˆAdvection Equationï¼‰**
   - $ u_t + v u_x = 0 $ï¼Œå‘¨æœŸè¾¹ç•Œ
   - åˆå§‹æ¡ä»¶ï¼š$ u(x,0)=\sin(x) $ï¼Œé«˜é€Ÿæƒ…å½¢ $ v=30 $

5. **éçº¿æ€§æ‰©æ•£-ååº”æ–¹ç¨‹ï¼ˆOperator Learningï¼‰**
   - $ u_t = D u_{xx} + k u^2 + f(x) $
   - å­¦ä¹ æ˜ å°„ $ f(x) \mapsto u(x,t) $ï¼Œå…¶ä¸­ $ f(x) $ æ¥è‡ª GRFï¼ˆGaussian Random Fieldï¼‰

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### è¯„ä¼°æŒ‡æ ‡
- **ç›¸å¯¹ L1/L2 è¯¯å·®**ï¼šè¡¡é‡é¢„æµ‹è§£ä¸çœŸå®è§£ä¹‹é—´çš„åå·®ï¼›
- **å‚æ•°æ•°é‡ (#param)**ï¼šæ¯”è¾ƒæ¨¡å‹å¤æ‚åº¦ï¼›
- **è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰**ï¼šåæ˜ è®¡ç®—æ•ˆç‡ï¼›
- **æ¨ç†é€Ÿåº¦ä¸å†…å­˜å ç”¨**ï¼šé—´æ¥ä½“ç°è½»é‡åŒ–ä¼˜åŠ¿ã€‚

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **PINN** | åŸå§‹ Physics-Informed Neural Networkï¼ˆMLP ç»“æ„ï¼‰ |
| **SAPINN** | è‡ªé€‚åº”åŠ æƒ PINNï¼ˆSelf-Adaptive PINNï¼‰ |
| **SPINN** | Sparse, Physics-based, and partially Interpretable Neural Networksï¼ˆç±»ä¼¼ç¨€ç– RBF æ–¹æ³•ï¼‰ |
| **EDNN** | Evolutional Deep Neural Networkï¼ˆåŸºäº MLP çš„æ—¶é—´æ¨è¿›ï¼‰ |
| **DeepONet** | ç»å…¸ Deep Operator Networkï¼ˆbranch-trunk æ¶æ„ï¼‰ |

#### è®­ç»ƒç»†èŠ‚
- ä½¿ç”¨ Adam ä¼˜åŒ–å™¨ï¼›
- Collocation points æ•°é‡è§ Table 2ï¼ˆå¦‚ Helmholtz ä½¿ç”¨ 10k å†…éƒ¨ç‚¹ï¼‰ï¼›
- Bump åˆå§‹åŒ–ä¸ºè§„åˆ™ç½‘æ ¼åˆ†å¸ƒï¼›
- å‰ªæç­–ç•¥ï¼šæ¯ 2000 æ­¥ç§»é™¤æœ€ä½ 0.15% å¹…å€¼çš„ bumpsã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆæ¥è‡ª Table 1ï¼‰

| ä»»åŠ¡ | æ–¹æ³• | L1/L2 Error | #Param | Train Time (s) |
|------|------|------------|--------|----------------|
| **Helmholtz** | Bump-PINN | 2.66e-2 | 1,575 | 51 |
|              | PINN      | 1.24e-1 | 83,073 | 85 |
|              | SPINN     | 9.83e-1 | 1,761 | 2,265 |
| **Poisson**   | Bump-PINN | 8.66e-4 | 252 | 61 |
|              | PINN      | 2.73e-2 | 83,073 | 112 |
|              | SPINN     | 1.03e-4 | 481 | 1,256 |
| **Heat Eq**   | Bump-PINN | 1.83e-3 | 840 | 12 |
|              | PINN      | 3.15e-2 | 3,421 | 41 |
|              | SPINN     | 2.18e+0 | 1,021 | 291 |
| **Advection** | Bump-PINN | 2.30e-3 | 154 | 28 |
|              | PINN      | 7.78e-2 | 83,073 | 48 |

> æ³¨ï¼šBump-SAPINN åœ¨éƒ¨åˆ†ä»»åŠ¡ä¸­ç•¥é€Šäº SAPINNï¼Œä½†åœ¨å‚æ•°æ•ˆç‡ä¸Šä»å ç»å¯¹ä¼˜åŠ¿ã€‚

### ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### âœ… Bump-PINN vs PINN / SAPINN
- **å‚æ•°å‡å°‘ 98%ä»¥ä¸Š**ï¼ŒåŒæ—¶ä¿æŒç”šè‡³è¶…è¶Šç²¾åº¦ï¼›
- **è®­ç»ƒé€Ÿåº¦å¿«æ•°å€è‡³æ•°åå€**ï¼ˆå°¤å…¶åœ¨ Poisson ä¸Šè¾¾ 20Ã— åŠ é€Ÿï¼‰ï¼›
- å³ä½¿åœ¨éš¾è®­ç»ƒçš„é«˜é€Ÿå¯¹æµé—®é¢˜ï¼ˆ$v=30$ï¼‰ä¸­ä¹Ÿèƒ½ç¨³å®šæ”¶æ•›ã€‚

#### âœ… Bump-EDNN vs EDNN
| æŒ‡æ ‡ | Bump-EDNN | EDNN |
|------|-----------|------|
| å‚æ•°æ€»æ•° | 252 | 1,341 |
| éœ€æ¼”åŒ–çš„å‚æ•° | 36 | 1,341 |
| åˆå§‹è®­ç»ƒæ—¶é—´ | 6m43s | 8m24s |
| æ—¶é—´æ¨è¿›è€—æ—¶ | **6 ç§’** | **23 åˆ†é’Ÿ** |
| $t=1$ æ—¶åˆ» L2 è¯¯å·® | **5e-4** | 1.4e-3 |

> æ˜¾ç¤º Bump-EDNN ä¸ä»…æ›´å°æ›´å¿«ï¼Œä¸”é•¿æœŸé¢„æµ‹æ›´å‡†ç¡®ã€‚

#### âœ… Bump-DeepONet vs DeepONet
| æŒ‡æ ‡ | Bump-DeepONet | DeepONet |
|------|---------------|----------|
| Trunk å‚æ•°æ•° | **600** | 25,600 |
| Test Error | 8.12e-6 | 5.42e-6 |
| è®­ç»ƒæ—¶é—´ | **86 ç§’** | 158 ç§’ |
| è¿­ä»£é€Ÿåº¦ | 937 iter/sec | 775 iter/sec |

> è™½ç„¶ DeepONet ç²¾åº¦ç¨ä¼˜ï¼Œä½† Bump-DeepONet å®ç°äº† **ç™¾å€å‚æ•°å‹ç¼©** ä¸ **æ›´å¿«è®­ç»ƒ**ï¼Œæ€§ä»·æ¯”æé«˜ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆPruning æ•ˆæœï¼‰
- åœ¨ Helmholtz é—®é¢˜ä¸­å¼•å…¥åŠ¨æ€å‰ªæåï¼š
  - è®­ç»ƒæŸå¤±ä¸‹é™æ›´å¿«ï¼ˆè§ Fig. 8ï¼‰ï¼›
  - å°½ç®¡å‰ªæå¼•èµ·çŸ­æš‚ loss spikeï¼Œä½†æ€»ä½“æ”¶æ•›åŠ é€Ÿï¼›
  - æœ€ç»ˆä¿ç•™çš„ bumps è‡ªåŠ¨é›†ä¸­åœ¨é«˜æ¢¯åº¦åŒºåŸŸï¼Œå®ç° **h-adaptivity**ï¼›
  - æ¨¡å‹å¤§å°è¿›ä¸€æ­¥å‡å°ï¼Œæå‡æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **BumpNet æ˜¯ä¸€ä¸ªé«˜æ•ˆã€å¯è§£é‡Šã€å¯æ‰©å±•çš„ PDE æ±‚è§£æ¡†æ¶**ï¼š
   - å…¶åŸºäº sigmoid æ„é€ çš„å¯è®­ç»ƒ bump åŸºå‡½æ•°å…¼å…· RBF çš„å¯è§£é‡Šæ€§å’Œ DNN çš„çµæ´»æ€§ï¼›
   - æ‰€æœ‰ bump å‡ ä½•å‚æ•°å‡å¯è§£æè¡¨è¾¾ï¼Œå¢å¼ºç‰©ç†æ„ä¹‰é€æ˜åº¦ã€‚

2. **æ˜¾è‘—ä¼˜äºä¼ ç»Ÿ MLP-based æ–¹æ³•**ï¼š
   - åœ¨ç›¸åŒæˆ–æ›´ä½è¯¯å·®ä¸‹ï¼Œå‚æ•°é‡å‡å°‘ 1â€“2 ä¸ªæ•°é‡çº§ï¼›
   - è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦å¤§å¹…æå‡ï¼Œé€‚åˆèµ„æºå—é™åœºæ™¯ã€‚

3. **å¤©ç„¶æ”¯æŒ h-adaptivity å’Œæ¨¡å‹å‹ç¼©**ï¼š
   - é€šè¿‡å¹…åº¦é©±åŠ¨çš„å‰ªææœºåˆ¶ï¼Œè‡ªåŠ¨èšç„¦é‡è¦åŒºåŸŸå¹¶å»é™¤å†—ä½™ bumpï¼›
   - æå‡è®­ç»ƒç¨³å®šæ€§ä¸æ”¶æ•›é€Ÿåº¦ã€‚

4. **å¹¿æ³›å…¼å®¹ä¸»æµæ¶æ„**ï¼š
   - æˆåŠŸåº”ç”¨äº PINNã€EDNNã€DeepONet ç­‰èŒƒå¼ï¼Œåœ¨å„ç±» PDE åœºæ™¯ä¸­å‡è¡¨ç°ä¼˜å¼‚ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä¸»è¦é’ˆå¯¹è§„åˆ™æˆ–çŸ©å½¢åŸŸè®¾è®¡ bump åˆå§‹åŒ–ï¼Œå¤æ‚å‡ ä½•åŸŸéœ€é¢å¤–å¤„ç†ï¼›
- è™½ç„¶å¯æ¨å¹¿åˆ°é«˜ç»´ï¼Œä½† bump æ•°éšç»´åº¦æŒ‡æ•°å¢é•¿ï¼ˆâ€œç»´æ•°ç¾éš¾â€é£é™©ï¼‰ï¼›
- å‰ªæé˜ˆå€¼ç­‰è¶…å‚æ•°éœ€æ‰‹åŠ¨è®¾å®šï¼Œå°šæœªå®Œå…¨è‡ªåŠ¨åŒ–ï¼›
- å¯¹æç«¯åˆšæ€§æˆ–é«˜é¢‘éœ‡è¡é—®é¢˜çš„é²æ£’æ€§æœ‰å¾…è¿›ä¸€æ­¥æµ‹è¯•ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **è‡ªé€‚åº” bump åˆå§‹åŒ–ç­–ç•¥**ï¼Œä»¥æ›´å¥½åŒ¹é…ä¸è§„åˆ™åŸŸï¼›
- å¼•å…¥ **å¯å˜å®½åº¦/å½¢çŠ¶æ§åˆ¶æœºåˆ¶**ï¼Œå¢å¼ºåŸºå‡½æ•°è¡¨è¾¾åŠ›ï¼›
- å¼€å‘ **å…¨è‡ªåŠ¨å‰ªæä¸ç”Ÿé•¿æœºåˆ¶**ï¼Œå®ç°çœŸæ­£çš„â€œç¥ç»è‡ªé€‚åº”ç½‘æ ¼â€ï¼›
- å°† BumpNet åº”ç”¨äº **å¤šå°ºåº¦å»ºæ¨¡ã€ä¸ç¡®å®šæ€§é‡åŒ–ã€é€†é—®é¢˜æ±‚è§£** ç­‰ç§‘å­¦æœºå™¨å­¦ä¹ å‰æ²¿é¢†åŸŸã€‚

---

> **æ€»ç»“**ï¼š  
> BumpNet æä¾›äº†ä¸€ç§å…¨æ–°çš„è§†è§’â€”â€”å°†ç¥ç»ç½‘ç»œè§†ä¸º**å¯è®­ç»ƒçš„åŸºå‡½æ•°å±•å¼€ç³»ç»Ÿ**ï¼Œè€Œéé»‘ç®±æ‹Ÿåˆå·¥å…·ã€‚å®ƒä¸ä»…æå‡äº† PDE æ±‚è§£çš„æ•ˆç‡ä¸å¯è§£é‡Šæ€§ï¼Œä¹Ÿä¸ºä¸‹ä¸€ä»£ç§‘å­¦æœºå™¨å­¦ä¹ æ¨¡å‹çš„è®¾è®¡æä¾›äº†åšå®åŸºç¡€ã€‚

</details>

---

### 5. [Atom: Efficient On-Device Video-Language Pipelines Through Modular Reuse](https://arxiv.org/abs/2512.17108)

**Authors**: Kunjal Panchal, Saayan Mitra, Somdeb Sarkhel, Haoliang Wang, Ishita Dasgupta, Gang Wu, Hui Guan  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.17108v1  

#### Abstract
Recent advances in video-language models have enabled powerful applications like video retrieval, captioning, and assembly. However, executing such multi-stage pipelines efficiently on mobile devices remains challenging due to redundant model loads and fragmented execution. We introduce Atom, an on-...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šATOM: Efficient On-Device Video-Language Pipelines Through Modular Reuse**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰çš„ **Video-Language Model (VLM)** å¤šé˜¶æ®µæ¨ç†ç®¡é“ï¼ˆå¦‚è§†é¢‘æ£€ç´¢ã€å­—å¹•ç”Ÿæˆã€è§†é¢‘å‰ªè¾‘ç»„è£…ï¼‰åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šæ‰§è¡Œæ•ˆç‡ä½ä¸‹ï¼Œä¸»è¦åŸå› åŒ…æ‹¬ï¼š
- **é‡å¤æ¨¡å‹åŠ è½½**ï¼šä¸åŒå­ä»»åŠ¡ï¼ˆå¦‚è§†é¢‘ç¼–ç ã€å­—å¹•ç”Ÿæˆã€è„šæœ¬ç”Ÿæˆï¼‰ä½¿ç”¨ç‹¬ç«‹æ¨¡å‹ï¼Œéœ€åå¤åŠ è½½ï¼Œé€ æˆæ˜¾è‘—å»¶è¿Ÿã€‚
- **å†…å­˜å‹åŠ›å¤§**ï¼šå¤§å‹æ¨¡å‹ï¼ˆå¦‚ mPLUG2 å’Œ Llama 3.2ï¼‰åˆè®¡å ç”¨çº¦ 7GB å†…å­˜ï¼Œè¶…å‡ºå¤šæ•°æ™ºèƒ½æ‰‹æœºçš„ 6â€“8GB RAM é™åˆ¶ã€‚
- **ä¸²è¡Œæ‰§è¡Œç“¶é¢ˆ**ï¼šä¼ ç»Ÿæµæ°´çº¿é‡‡ç”¨ä¸²è¡Œå¤„ç†ï¼Œæ— æ³•å¹¶è¡ŒåŒ–ï¼Œå¯¼è‡´ç«¯åˆ°ç«¯å»¶è¿Ÿé«˜ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯**
ä½œè€…æå‡º **ATOM** â€”â€” ä¸€ç§é¢å‘ç§»åŠ¨ç«¯çš„ **reuse-centricï¼ˆé‡ç”¨ä¸­å¿ƒåŒ–ï¼‰** è§†é¢‘-è¯­è¨€æ¨ç†ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒè®¾è®¡åŸåˆ™ä¸ºï¼š
- **æ¨¡å—åŒ–ï¼ˆModularizationï¼‰**ï¼šå°† VLM åˆ†è§£ä¸ºå¯ç‹¬ç«‹è°ƒç”¨çš„ **è§†è§‰ç¼–ç å™¨ï¼ˆvideo encoderï¼‰** å’Œ **é€šç”¨è¯­è¨€è§£ç å™¨ï¼ˆlanguage decoderï¼‰**ã€‚
- **æŒä¹…åŒ–é‡ç”¨ï¼ˆPersistent Reuseï¼‰**ï¼šå…³é”®æ¨¡å—ï¼ˆå¦‚è¯­è¨€è§£ç å™¨ï¼‰åœ¨æ•´ä¸ªåº”ç”¨ç”Ÿå‘½å‘¨æœŸä¸­å¸¸é©»å†…å­˜ï¼Œé¿å…é‡å¤åŠ è½½ã€‚
- **å¹¶è¡Œæ‰§è¡Œï¼ˆParallelismï¼‰**ï¼šè§£è€¦çš„æ¨¡å—æ”¯æŒå¹¶å‘æ‰§è¡Œï¼ˆå¦‚ç¼–ç  clip #2 æ—¶åŒæ—¶è§£ç  clip #1 çš„å­—å¹•ï¼‰ï¼Œæå‡ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **å‡å°‘æ¨¡å‹åŠ è½½å¼€é”€**ï¼šé€šè¿‡æ¨¡å—å¤ç”¨ï¼Œæ¶ˆé™¤å¤šæ¨¡å‹åˆ‡æ¢å¸¦æ¥çš„åŠ è½½å»¶è¿Ÿã€‚
- **é™ä½ç«¯åˆ°ç«¯å»¶è¿Ÿ**ï¼šå®ç°è·¨è¾“å…¥å’Œå­ä»»åŠ¡çš„å¹¶è¡Œå¤„ç†ï¼Œæ˜¾è‘—ç¼©çŸ­æ€»è€—æ—¶ã€‚
- **ä¿æŒé«˜æ€§èƒ½**ï¼šä»…å¼•å…¥è½»å¾®æ€§èƒ½ä¸‹é™ï¼ˆå¦‚ â‰¤2.3 Recall@1 æ£€ç´¢ç²¾åº¦æŸå¤±ï¼‰ï¼Œä½†å¤§å¹…æå‡æ•ˆç‡ã€‚
- **å…¼å®¹ç§»åŠ¨ç«¯èµ„æºçº¦æŸ**ï¼šå³°å€¼å†…å­˜ä»…å¢åŠ  0.76% (~40MB)ï¼Œä»å¯åœ¨ 6GB RAM è®¾å¤‡ä¸Šè¿è¡Œã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **MSR-VTT**ï¼š10K YouTube è§†é¢‘ï¼Œå¸¦ 200K å­—å¹•ï¼Œç”¨äºè®­ç»ƒå’Œæµ‹è¯•ã€‚
- **MSVD**ï¼š1.97K å¸¦å­—å¹•çš„ YouTube è§†é¢‘ã€‚
- **DiDeMo**ï¼š10K Flickr è§†é¢‘ï¼Œæ¯æ®µé… 4 æ¡æ–‡æœ¬æè¿°ã€‚

### **å®éªŒè®¾ç½®**
- **ä»»åŠ¡ç±»å‹**ï¼š
  - **è§†é¢‘æ£€ç´¢ï¼ˆVideo Retrievalï¼‰**ï¼šåŸºäºç”¨æˆ·æç¤ºåŒ¹é…æœ€ç›¸å…³è§†é¢‘ç‰‡æ®µã€‚
  - **è§†é¢‘ç»„è£…ï¼ˆVideo Assemblyï¼‰**ï¼šè‡ªåŠ¨ç”Ÿæˆè„šæœ¬å¹¶æ‹¼æ¥è§†é¢‘ç‰‡æ®µã€‚
- **ç¡¬ä»¶å¹³å°**ï¼š
  - ç§»åŠ¨ç«¯ï¼šGoogle Pixel 5a (6GB RAM), Pixel 8a, Samsung Galaxy S23 (å‡ 8GB RAM)ã€‚
  - æœåŠ¡å™¨ç«¯ï¼šx86_64 CPU + NVIDIA A40 GPUã€‚
- **éƒ¨ç½²æ¡†æ¶**ï¼šPyTorch Mobile + TorchAOï¼Œæ”¯æŒé‡åŒ–ä¸ç®—å­èåˆä¼˜åŒ–ã€‚
- **é‡åŒ–ç­–ç•¥**ï¼šå¯¹ LINEAR å’Œ EMBEDDING å±‚è¿›è¡Œ **8-bit åŠ¨æ€é‡åŒ–**ï¼Œä»¥å‹ç¼©æ¨¡å‹å¤§å°å¹¶åŠ é€Ÿæ¨ç†ã€‚

### **è¯„ä¼°æŒ‡æ ‡**
| ä»»åŠ¡ | æŒ‡æ ‡ |
|------|------|
| **è§†é¢‘å­—å¹•ç”Ÿæˆ** | BLEU@4, ROUGE-L, METEOR, CIDEr |
| **è§†é¢‘æ£€ç´¢** | Recall@1, Recall@5, Recall@10 |
| **è§†é¢‘ç»„è£…** | å®šæ€§åˆ†æï¼ˆäººå·¥è¯„åˆ†ï¼‰ï¼šAdherence to prompt, Coherence, Engagement ç­‰ |
| **ç³»ç»Ÿæ€§èƒ½** | ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆsecondsï¼‰ã€å³°å€¼å†…å­˜ï¼ˆGBï¼‰ã€æ¨¡å‹åŠ è½½æ—¶é—´ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Sequential Baseline (w/o reuse)**ï¼šä¼ ç»Ÿä¸²è¡Œæµæ°´çº¿ï¼Œæ¯ä¸ªå­ä»»åŠ¡åŠ è½½ç‹¬ç«‹æ¨¡å‹ã€‚
- **Server-side Systems**ï¼šä½¿ç”¨ GPU åŠ é€Ÿçš„éé‡ç”¨ç‰ˆæœ¬ä½œä¸ºæ€§èƒ½ä¸Šé™å‚è€ƒã€‚
- æ‰€æœ‰å¯¹æ¯”å‡åœ¨åŒä¸€æ¨¡å‹æ¶æ„ä¸‹è¿›è¡Œï¼Œä»…æ”¹å˜æ‰§è¡Œæµç¨‹ï¼ˆæ˜¯å¦æ¨¡å—åŒ–ä¸é‡ç”¨ï¼‰ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **(1) æ€§èƒ½è¡¨ç°ï¼ˆè´¨é‡ï¼‰**
| æ¨¡å‹ | CIDEr â†‘ | Recall@1 â†‘ |
|------|--------|-----------|
| åŸå§‹ mPLUG2 (BERT decoder) | 79.4 (MSR-VTT) | 52.6 (MSR-VTT) |
| **mPLUG2+ (Llama decoder)** | **83.1** (+3.7) | **57.2** (+4.6) |
| mPLUG2+ (8-bit quantized) | 82.5 (-0.6) | 55.8 (-1.4) |

> âœ… **ç»“è®º**ï¼šä½¿ç”¨æ›´å¼ºçš„ Llama è§£ç å™¨æ˜¾è‘—æå‡å­—å¹•è´¨é‡å’Œæ£€ç´¢å‡†ç¡®ç‡ï¼›é‡åŒ–åæ€§èƒ½ä¸‹é™æå°ã€‚

#### **(2) æ•ˆç‡è¡¨ç°ï¼ˆé€Ÿåº¦ï¼‰**
| å¹³å° | ä»»åŠ¡ | å»¶è¿Ÿï¼ˆw/o reuseï¼‰ | å»¶è¿Ÿï¼ˆATOMï¼‰ | **æé€Ÿ** |
|------|------|------------------|-------------|---------|
| Pixel 5a | è§†é¢‘æ£€ç´¢ | 162.33s | **108.66s** | â†“ **33.06%** |
| Pixel 5a | è§†é¢‘ç»„è£… | 167.52s | **115.95s** | â†“ **30.78%** |
| Pixel 8a | è§†é¢‘ç»„è£… | 153.59s | **111.06s** | â†“ **27.69%** |
| S23 | è§†é¢‘ç»„è£… | 152.35s | **110.39s** | â†“ **27.54%** |

> âœ… **ç»“è®º**ï¼šATOM åœ¨ä¸»æµæ‰‹æœºä¸Šå®ç° **27â€“33% çš„ç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½**ã€‚

#### **(3) å†…å­˜æ¶ˆè€—**
| é…ç½® | å³°å€¼å†…å­˜ |
|------|----------|
| Non-reuse baseline | 5.277 GB |
| **ATOM (reuse + parallel)** | **5.317 GB** |
| **å¢é‡** | **+0.76% (+40MB)** |

> âœ… **ç»“è®º**ï¼šå°½ç®¡å¹¶è¡Œæ‰§è¡Œå¢åŠ äº†æ¿€æ´»å†…å­˜ï¼Œä½†å› çœå»ä¸´æ—¶åŠ è½½ç¼“å†²åŒºï¼Œæ€»ä½“å†…å­˜å¢é•¿å¯å¿½ç•¥ä¸è®¡ã€‚

#### **(4) æ¨¡å‹åŠ è½½å»¶è¿Ÿ**
- ATOM å°†æ¨¡å‹åŠ è½½æ—¶é—´å‡å°‘ **é«˜è¾¾ 50%**ï¼Œå°¤å…¶åœ¨é¢‘ç¹åˆ‡æ¢ä»»åŠ¡åœºæ™¯ä¸­ä¼˜åŠ¿æ˜æ˜¾ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**
åœ¨ Google Pixel 5a ä¸Šæµ‹è¯•ä¸åŒé…ç½®çš„å½±å“ï¼š

| è¾“å…¥/è¶…å‚è°ƒæ•´ | å»¶è¿Ÿå˜åŒ– | æ€§èƒ½å½±å“ |
|---------------|---------|----------|
| åˆ†è¾¨ç‡ä» 224Ã—224 â†’ 112Ã—112 | â†“ 41.8% (3.29s) | CIDEr ä» 82.5 â†’ 75.64 |
| å¸§ç‡ä» 6fps â†’ 2fps | â†“ 17.2% (4.78s) | CIDEr â†“ è‡³ 50.89ï¼ˆä¸¥é‡é™è´¨ï¼‰ |
| Beam size = 1 | â†“ 46.9% (3.07s) | CIDEr â†“ è‡³ 40.98ï¼ˆä¸å¯æ¥å—ï¼‰ |
| æ‰¹å¤§å° = 4 | â†‘ 304% (22.35s) | æ— æ”¶ç›Šï¼ˆç§»åŠ¨ç«¯ä¸é€‚ç”¨ batchingï¼‰ |
| è¾“å‡ºé•¿åº¦ trace=12 | â†“ 18.2% (4.55s) | CIDEr â†“ è‡³ 74.19 |

> ğŸ” **å‘ç°**ï¼šåˆ†è¾¨ç‡é™é‡‡æ ·æ˜¯æ€§ä»·æ¯”æœ€é«˜çš„ä¼˜åŒ–æ‰‹æ®µï¼›beam search å¯¹è´¨é‡è‡³å…³é‡è¦ï¼›batching åœ¨ç§»åŠ¨ç«¯æ— æ•ˆã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **æ¨¡å—åŒ– + é‡ç”¨æ˜¯ç§»åŠ¨ç«¯ VLM æµæ°´çº¿çš„å…³é”®ä¼˜åŒ–æ–¹å‘**ï¼š
   - é€šè¿‡å…±äº«ä¸€ä¸ªå¼ºå¤§çš„è¯­è¨€è§£ç å™¨æœåŠ¡å¤šä¸ªä»»åŠ¡ï¼ˆcaptioning, retrieval, script generationï¼‰ï¼Œæœ‰æ•ˆé¿å…å†—ä½™åŠ è½½ã€‚
2. **å¹¶è¡Œæ‰§è¡Œæ˜¾è‘—æå‡ååé‡**ï¼š
   - ç¼–ç ä¸è§£ç å¯é‡å æ‰§è¡Œï¼Œå……åˆ†åˆ©ç”¨ CPU å¤šæ ¸èƒ½åŠ›ã€‚
3. **é‡åŒ–ä¸é‡ç”¨ååŒå¢æ•ˆ**ï¼š
   - è™½ç„¶é‡åŒ–æœ¬èº«å¯èƒ½å¼•å…¥åŠ¨æ€è½¬æ¢å¼€é”€ï¼Œä½† ATOM çš„å¹¶è¡Œè®¾è®¡æŠµæ¶ˆäº†è¿™ä¸€è´Ÿé¢å½±å“ã€‚
4. **å®é™…å¯è¡Œæ€§é«˜**ï¼š
   - æ€»æ¨¡å‹å­˜å‚¨ä»… **1.28GB**ï¼ˆè§ Appendix F.2ï¼‰ï¼Œé€‚åˆéƒ¨ç½²äºæ™®é€šæ™ºèƒ½æ‰‹æœºã€‚
   - èƒ½è€—ä¼°ç®—æ˜¾ç¤ºï¼ŒATOM å¯èŠ‚çœ **çº¦ 46% çš„èƒ½é‡æ¶ˆè€—**ï¼ˆè§ F.7ï¼‰ï¼Œæœ‰åˆ©äºå»¶é•¿ç”µæ± å¯¿å‘½ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–æ¨¡å—åŒ–è§£æ„çš„ VLM æ¶æ„**ï¼šå¯¹äºæ—©æœŸ tightly-coupled çš„è·¨æ¨¡æ€æ³¨æ„åŠ›æ¨¡å‹ï¼ˆå¦‚æŸäº› joint fusion ç»“æ„ï¼‰ï¼Œéš¾ä»¥ç›´æ¥åˆ†è§£ã€‚
- **å¹¶è¡ŒåŒ–å¸¦æ¥å°å¹…å†…å­˜ä¸Šå‡**ï¼šè™½ç„¶æ€»ä½“å¯æ§ï¼Œä½†åœ¨æç«¯ä½å†…å­˜è®¾å¤‡ï¼ˆ<6GBï¼‰ä¸­ä»éœ€è°¨æ…æƒè¡¡ã€‚
- **å½“å‰å®ç°èšç„¦ CPU æ¨ç†**ï¼šå—é™äº TorchAO å¯¹ NPU/GPU æ”¯æŒä¸è¶³ï¼Œå°šæœªå……åˆ†å‘æŒ¥ä¸“ç”¨ç¡¬ä»¶æ½œåŠ›ï¼ˆä½†è®¾è®¡ä¸Šæ­£äº¤äºç¡¬ä»¶é€‰æ‹©ï¼‰ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•è‡³æ›´å¤šè§†é¢‘-è¯­è¨€ä»»åŠ¡ï¼šå¦‚ **è§†é¢‘æ‘˜è¦ï¼ˆsummarizationï¼‰**ã€**è§†é¢‘é—®ç­”ï¼ˆVideoQAï¼‰**ã€**äº‹ä»¶å®šä½ï¼ˆtemporal localizationï¼‰**ã€‚
- æ¢ç´¢æ›´æ¿€è¿›çš„å‹ç¼©æŠ€æœ¯ï¼ˆå¦‚ 4-bit é‡åŒ–ï¼‰ä¸ ATOM æ¶æ„çš„ç»“åˆã€‚
- æ”¯æŒå¤šç”¨æˆ· prompt å¹¶å‘å¤„ç†ï¼Œè¿›ä¸€æ­¥æå‡ç³»ç»Ÿååã€‚
- å¼€å‘è‡ªåŠ¨è°ƒåº¦æœºåˆ¶ï¼Œæ ¹æ®è®¾å¤‡è´Ÿè½½åŠ¨æ€è°ƒæ•´åˆ†è¾¨ç‡ã€å¸§ç‡ç­‰å‚æ•°ä»¥å®ç°è´¨é‡-å»¶è¿Ÿæƒè¡¡ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **ATOM é€šè¿‡â€œæ¨¡å—åŒ– + æŒä¹…é‡ç”¨ + å¹¶è¡Œæ‰§è¡Œâ€çš„ç³»ç»Ÿçº§è®¾è®¡ï¼Œåœ¨å‡ ä¹ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹ï¼Œå®ç°äº†ç§»åŠ¨ç«¯è§†é¢‘-è¯­è¨€æµæ°´çº¿ 27â€“33% çš„ç«¯åˆ°ç«¯åŠ é€Ÿï¼Œä¸ºè¾¹ç¼˜è®¾å¤‡ä¸Šçš„å®æ—¶å¤šæ¨¡æ€ç†è§£æä¾›äº†å®ç”¨ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚**

</details>

---

### 6. [Bandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation](https://arxiv.org/abs/2512.17073)

**Authors**: Zhenyu Liu, Yunzhen Liu, Zehao Fan, Garrett Gagnon, Yayue Hou, Nan Wu, Yangwook Kang, Liu Liu  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.17073v1  

#### Abstract
Mixture-of-Experts (MoE) models scale capacity via sparse activation but stress memory and bandwidth. Offloading alleviates GPU memory by fetching experts on demand, yet token-level routing causes irregular transfers that make inference I/O-bound. Static uniform quantization reduces traffic but degr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šBandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
Mixture-of-Experts (MoE) æ¨¡å‹é€šè¿‡ç¨€ç–æ¿€æ´»æ‰©å±•æ¨¡å‹å®¹é‡ï¼Œä½†åœ¨æ¨ç†è¿‡ç¨‹ä¸­é¢ä¸´ä¸¥é‡çš„ **å†…å­˜å‹åŠ›** å’Œ **å¸¦å®½ç“¶é¢ˆ**ã€‚ä¸ºç¼“è§£æ˜¾å­˜é™åˆ¶ï¼Œé€šå¸¸é‡‡ç”¨ **offloading** æŠ€æœ¯å°†éæ´»è·ƒä¸“å®¶å­˜å‚¨åœ¨ CPU å†…å­˜ä¸­ï¼ŒæŒ‰éœ€åŠ è½½ã€‚ç„¶è€Œï¼Œtoken-level çš„åŠ¨æ€è·¯ç”±å¯¼è‡´ä¸è§„åˆ™çš„æ•°æ®ä¼ è¾“ï¼Œä½¿å¾—æ¨ç†è¿‡ç¨‹ä¸¥é‡å—é™äº I/O å¸¦å®½ã€‚

æ­¤å¤–ï¼Œè™½ç„¶ä½æ¯”ç‰¹é‡åŒ–ï¼ˆå¦‚ INT2/INT3ï¼‰å¯å‡å°‘ä¼ è¾“é‡ï¼Œä½†**é™æ€ã€ç»Ÿä¸€çš„é‡åŒ–ç­–ç•¥**å¿½ç•¥äº†ä¸åŒä¸“å®¶åœ¨ä¸åŒ token ä¸‹çš„é‡è¦æ€§å·®å¼‚ï¼Œå°¤å…¶å¯¹ä¸»å¯¼ä¸“å®¶ï¼ˆTop-1ï¼‰é€ æˆä¸¥é‡ç²¾åº¦æŸå¤±ï¼Œå½±å“æ•´ä½“å‡†ç¡®æ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
æœ¬æ–‡æå‡º **Bandwidth-Efficient Adaptive MoE via Low-Rank Compensation**ï¼Œä¸€ç§ç»“åˆ **offloading** ä¸ **router-guided åŠ¨æ€ç²¾åº¦æ¢å¤** çš„é«˜æ•ˆ MoE æ¨ç†æ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **ç¦»çº¿é¢„è®¡ç®—ä½ç§©è¡¥å¿å™¨ï¼ˆLow-Rank Compensatorï¼‰**ï¼šå¯¹æ¯ä¸ªä¸“å®¶çš„é‡åŒ–æ®‹å·®è¿›è¡Œ SVD åˆ†è§£ï¼Œç”Ÿæˆç´§å‡‘çš„ä½ç§©å› å­ $(U_i, V_i)$ å¹¶å­˜å‚¨ã€‚
- **è¿è¡Œæ—¶åŸºäºè·¯ç”±å™¨åˆ†æ•°é€‰æ‹©æ€§æ¢å¤ç²¾åº¦**ï¼šä»…å¯¹å½“å‰ token è·¯ç”±å¾—åˆ†æœ€é«˜çš„ Top-$n$ ä¸“å®¶åº”ç”¨è¡¥å¿ï¼Œåœ¨ GPU ä¸Šé‡å»ºé«˜ç²¾åº¦æƒé‡ï¼›å…¶ä½™ä¸“å®¶ä¿æŒä½æ¯”ç‰¹å½¢å¼ï¼Œæ— éœ€è¡¥å¿ã€‚
- **åŸºäºå³°åº¦ï¼ˆkurtosisï¼‰çš„è¡¥å¿ç§©åˆ†é…æœºåˆ¶**ï¼šæ ¹æ®ä¸“å®¶æƒé‡åˆ†å¸ƒçš„å³°åº¦è‡ªåŠ¨åˆ†é…è¡¥å¿ç§©ï¼Œé«˜ kurtosis ä¸“å®¶è·å¾—æ›´é«˜è¡¥å¿èƒ½åŠ›ï¼Œæå‡èµ„æºåˆ©ç”¨æ•ˆç‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ GPTQã€HQQã€Hobbitï¼‰ | æœ¬æ–‡æ–¹æ³• |
|------|-------------------------------|---------|
| **é‡åŒ–ç­–ç•¥** | ç»Ÿä¸€å¯¹æ‰€æœ‰ä¸“å®¶è¿›è¡Œä½æ¯”ç‰¹é‡åŒ– | **åŠ¨æ€æ„ŸçŸ¥è·¯ç”±é‡è¦æ€§**ï¼Œåªæ¢å¤å…³é”®ä¸“å®¶ç²¾åº¦ |
| **è¡¥å¿æ–¹å¼** | è‹¥æœ‰è¡¥å¿ï¼Œé€šå¸¸åº”ç”¨äºå…¨éƒ¨ä¸“å®¶ | **ä»…å¯¹ Top-n ä¸“å®¶è¡¥å¿**ï¼Œæ˜¾è‘—é™ä½å¸¦å®½å¼€é”€ |
| **è¡¥å¿èµ„æºé…ç½®** | å›ºå®šæˆ–å‡åŒ€åˆ†é…è¡¥å¿ç§© | **åŸºäº kurtosis è‡ªé€‚åº”åˆ†é…**ï¼Œæ›´åŒ¹é…å®é™…è¯¯å·®éœ€æ±‚ |
| **ç³»ç»Ÿå…¼å®¹æ€§** | å¤šæ•°ä»…é€‚ç”¨äº GPU-only | æ”¯æŒ **GPU-only ä¸ GPU-NDP** æ¶æ„ï¼Œé€šç”¨æ€§å¼º |
| **å¸¦å®½-ç²¾åº¦æƒè¡¡** | é«˜å‹ç¼©ä¸‹ç²¾åº¦ä¸‹é™å‰§çƒˆ | åœ¨æä½æ¯”ç‰¹ï¼ˆINT2ï¼‰ä¸‹ä»èƒ½ç»´æŒé«˜å‡†ç¡®ç‡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **å¸¸è¯†æ¨ç†ä»»åŠ¡**ï¼ˆZero-shotï¼‰ï¼š
  - MathQA, Hellaswag, ARC-easy/challenge, BoolQ, Winogrande, PIQA
- **å¤šä»»åŠ¡ç†è§£åŸºå‡†**ï¼ˆ5-shotï¼‰ï¼š
  - MMLU
- **è¯­è¨€å»ºæ¨¡è´¨é‡è¯„ä¼°**ï¼š
  - WikiText2ï¼ˆç”¨äº PPL æµ‹é‡ï¼‰

è¯„ä¼°å·¥å…·ï¼šEleutherAI LM Evaluation Harnessã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼š
  - Mixtral-8Ã—7Bï¼ˆTop-2ï¼‰
  - Mixtral-8Ã—22Bï¼ˆTop-2ï¼‰
  - DeepSeek-MoE-16Bï¼ˆTop-6 + 2 shared expertsï¼‰
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š
  - **GPU-only**ï¼šNVIDIA H100ï¼ˆ80GB HBM3ï¼‰ï¼Œä¸“å®¶ä» DDR via PCIe åŠ è½½
  - **GPU-NDP**ï¼šH100 + NDP è®¾å¤‡ï¼ˆ512GB/s å¸¦å®½ï¼Œ512GB å®¹é‡ï¼‰ï¼Œæ”¯æŒè¿‘æ•°æ®å¤„ç†
- **è¾“å…¥/è¾“å‡ºé•¿åº¦**ï¼š{256, 512} tokens
- **é‡åŒ–é…ç½®**ï¼šINT2 / INT3ï¼ˆä¸»å®éªŒï¼‰ï¼ŒFP16ï¼ˆåŸå§‹ç²¾åº¦å¯¹ç…§ï¼‰

### è¯„ä¼°æŒ‡æ ‡
- **å‡†ç¡®æ€§**ï¼š
  - MMLUã€å„å¸¸è¯†æ¨ç†ä»»åŠ¡å¹³å‡å‡†ç¡®ç‡
  - WikiText2 ä¸Šçš„ Perplexity (PPL)
- **ç³»ç»Ÿæ€§èƒ½**ï¼š
  - End-to-end ååé‡ï¼ˆtokens/sï¼‰
  - PCIe/NVLink æ•°æ®ä¼ è¾“é‡
- **æ¶ˆèç ”ç©¶**ï¼š
  - ä¸åŒ $n$ï¼ˆæ¢å¤ä¸“å®¶æ•°é‡ï¼‰ã€rank budgetã€æ˜¯å¦ä½¿ç”¨ kurtosis æŒ‡å¯¼çš„å½±å“

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | åŸºçº¿æ–¹æ³• |
|------|--------|
| **ç®—æ³•çº§é‡åŒ–** | GPTQ, HQQ |
| **ç³»ç»Ÿçº§ offloading** | Mixtral-Offloading, Hobbit |
| **GPU-NDP ç³»ç»Ÿ** | MoNDE |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å‡†ç¡®æ€§ç»“æœï¼ˆFigure 6ï¼‰
#### åœ¨ INT2 é‡åŒ–ä¸‹çš„å¹³å‡å‡†ç¡®ç‡æå‡ï¼ˆvs. HQQï¼‰ï¼š
| æ¨¡å‹ | å¹³å‡å‡†ç¡®ç‡æå‡ | MMLU æå‡ |
|------|----------------|-----------|
| Mixtral-8Ã—7B | **+8.24%** | **+10.50%** |
| Mixtral-8Ã—22B | **+8.70%** | **+2.83%** |
| DeepSeek-MoE-16B | **+2.30%** | **+1.73%** |

> ğŸ’¡ **è¯´æ˜**ï¼šMixtral ç³»åˆ—è·¯ç”±é«˜åº¦é›†ä¸­ï¼ˆTop-1 å ä¸»å¯¼ï¼‰ï¼Œå› æ­¤ä»…æ¢å¤ Top-1 å³å¯å¤§å¹…æ¢å¤ç²¾åº¦ï¼›è€Œ DeepSeek è·¯ç”±è¾ƒå‡è¡¡ï¼Œéœ€æ¢å¤æ›´å¤šä¸“å®¶ï¼ˆTop-3ï¼‰æ‰æœ‰æ•ˆæœã€‚

### ç³»ç»Ÿæ€§èƒ½ï¼ˆFigure 7ï¼‰
#### GPU-only åœºæ™¯ä¸‹ååé‡æå‡ï¼ˆvs. Mixtral-Offloadingï¼‰ï¼š
| æ¨¡å‹ | INT3 æå‡ | INT2 æå‡ |
|------|----------|----------|
| Mixtral-8Ã—7B | **5.17Ã—** | **7.64Ã—** |
| Mixtral-8Ã—22B | **5.18Ã—** | **7.63Ã—** |
| DeepSeek-MoE-16B | ~4.38â€“5.93Ã— | â€” |

#### GPU-NDP åœºæ™¯ä¸‹ååé‡æå‡ï¼ˆvs. MoNDEï¼‰ï¼š
| æ¨¡å‹ | INT3 æå‡ | INT2 æå‡ |
|------|----------|----------|
| Mixtral-8Ã—7B | **4.75Ã—** | **6.69Ã—** |
| Mixtral-8Ã—22B | ~7.23Ã— | â€” |
| DeepSeek-MoE-16B | **3.15Ã— â€“ 3.78Ã—** | â€” |

> âœ… æ€»ä½“å®ç° **3Ã— åˆ° 8Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿ**ï¼Œä¸»è¦å¾—ç›Šäºç»å¤§å¤šæ•°ä¸“å®¶ä»¥ä½æ¯”ç‰¹æ‰§è¡Œï¼Œä»…å°‘é‡å…³é”®ä¸“å®¶è§¦å‘è¡¥å¿ä¼ è¾“ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆFigure 8 & Table 2ï¼‰

#### ï¼ˆ1ï¼‰æ¢å¤ä¸“å®¶æ•°é‡çš„å½±å“
- **Mixtral-8Ã—7B**ï¼šä»…æ¢å¤ Top-1 å³å¯æ¢å¤å¤§éƒ¨åˆ†ç²¾åº¦ï¼ˆMMLU: 47.53% â†’ Top-2 ä»…å¢è‡³ 48.79%ï¼‰
- **DeepSeek-MoE-16B**ï¼šéœ€æ¢å¤ Top-3 æ‰è¾¾æœ€ä½³æ•ˆæœï¼ˆMMLU ä» 25.80% â†’ 28.75%ï¼‰

> ğŸ“Œ è¡¨æ˜ **router score åˆ†å¸ƒå†³å®šæœ€ä¼˜ $n$**

#### ï¼ˆ2ï¼‰è¡¥å¿ç§©é¢„ç®—çš„å½±å“
- éš rank å¢åŠ ï¼ŒWikiText PPL ä¸‹é™ï¼ˆç²¾åº¦ä¸Šå‡ï¼‰ï¼Œä½†ä¼ è¾“å¼€é”€çº¿æ€§å¢é•¿
- Rank=32 æ˜¯æ€§ä»·æ¯”æœ€ä¼˜ç‚¹ï¼ˆPPL æ˜¾è‘—ä¸‹é™ï¼Œå¼€é”€ <1% å•ä¸ª INT2 ä¸“å®¶å¤§å°ï¼‰

#### ï¼ˆ3ï¼‰kurtosis-guided vs. uniform rank åˆ†é…
| Rank Budget | Uniform Allocation (PPL) | Kurtosis-Guided (PPL) |
|------------|----------------------------|------------------------|
| 16 | 7.55 | **7.05** |
| 128 | 8.54 | **3.77** |

> âœ… æ˜¾ç¤º **åŸºäº kurtosis çš„å¼‚æ„ç§©åˆ†é…æ˜¾è‘—ä¼˜äºç»Ÿä¸€åˆ†é…**ï¼ŒéªŒè¯äº†ä¸“å®¶é—´è¡¥å¿éœ€æ±‚çš„å¼‚è´¨æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **MoE ä¸­çš„é‡åŒ–è¯¯å·®å…·æœ‰é«˜åº¦éå‡åŒ€æ€§**ï¼šTop-1 ä¸“å®¶çš„ç²¾åº¦æŸå¤±å¯¹æ•´ä½“æ€§èƒ½å½±å“æœ€å¤§ï¼Œåº”ä¼˜å…ˆä¿æŠ¤ã€‚
2. **â€œé€‰æ‹©æ€§ç²¾åº¦æ¢å¤â€ å¯å®ç°é«˜æ•ˆå¸¦å®½-ç²¾åº¦å¹³è¡¡**ï¼šä»…æ¢å¤ Top-$n$ ä¸“å®¶å³å¯æ¥è¿‘å…¨è¡¥å¿æ€§èƒ½ï¼Œé¿å…å…¨å±€é«˜å¸¦å®½æ¶ˆè€—ã€‚
3. **kurtosis æ˜¯é¢„æµ‹é‡åŒ–è¯¯å·®çš„è‰¯å¥½æŒ‡æ ‡**ï¼šå¯ç”¨äºæŒ‡å¯¼è¡¥å¿èµ„æºåˆ†é…ï¼Œæå‡è¡¥å¿æ•ˆç‡ã€‚
4. **æœ¬æ–¹æ³•ä¸ç°æœ‰ç³»ç»Ÿæ­£äº¤ä¸”å…¼å®¹**ï¼šå¯é›†æˆè¿› Mixtral-Offloadingã€Hobbitã€MoNDE ç­‰ç³»ç»Ÿï¼Œå¸¦æ¥æ˜¾è‘—åŠ é€Ÿã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–ç¦»çº¿ SVD è®¡ç®—**ï¼šéœ€è¦é¢å¤–é¢„å¤„ç†æ—¶é—´ç”Ÿæˆè¡¥å¿å› å­ã€‚
- **è¡¥å¿ä»…é™çº¿æ€§å±‚**ï¼šç›®å‰æœªè¦†ç›– Attention æˆ–å¤æ‚éçº¿æ€§æ¨¡å—ã€‚
- **å¯¹è·¯ç”±åˆ†å¸ƒæ•æ„Ÿ**ï¼šè‹¥æ¨¡å‹è·¯ç”±è¿‡äºåˆ†æ•£ï¼ˆå¦‚ DeepSeekï¼‰ï¼Œæ”¶ç›Šç›¸å¯¹è¾ƒå°ã€‚
- **GPU å†…å­˜å ç”¨ç•¥å¢**ï¼šéœ€ç¼“å­˜è¡¥å¿å› å­ï¼Œå°½ç®¡æ€»é‡å¾ˆå°ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **åŠ¨æ€è°ƒæ•´ $n$**ï¼šæ ¹æ®å½“å‰ token çš„è·¯ç”±ç†µè‡ªé€‚åº”é€‰æ‹©æ¢å¤ä¸“å®¶æ•°ã€‚
- **æ›´é«˜æ•ˆçš„è¡¥å¿ç»“æ„**ï¼šæ¢ç´¢é SVD å½¢å¼çš„è½»é‡è¡¥å¿æ¨¡å—ï¼ˆå¦‚ LoRA-styleï¼‰ã€‚
- **ç¡¬ä»¶ååŒè®¾è®¡**ï¼šå®šåˆ¶ NDP æˆ– PIM æ¶æ„ç›´æ¥æ”¯æŒè¡¥å¿æ“ä½œã€‚
- **è·¨å±‚è”åˆè¡¥å¿**ï¼šè€ƒè™‘å¤šå±‚ä¸“å®¶é—´çš„ç›¸å…³æ€§è¿›è¡Œè”åˆè¯¯å·®æ ¡æ­£ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼šè¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç®€æ´è€Œé«˜æ•ˆçš„ MoE æ¨ç†ä¼˜åŒ–èŒƒå¼â€”â€”**Low-Rank Compensation + Router-Guided Selection**ï¼Œåœ¨æä½æ¯”ç‰¹ä¼ è¾“ä¸‹å®ç°äº†é«˜ç²¾åº¦æ¢å¤ï¼Œæ˜¾è‘—æå‡äº†å¸¦å®½åˆ©ç”¨ç‡å’Œç³»ç»Ÿååé‡ï¼Œä¸ºå¤§è§„æ¨¡ MoE æ¨¡å‹çš„å®é™…éƒ¨ç½²æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 7. [Learning solution operator of dynamical systems with diffusion maps kernel ridge regression](https://arxiv.org/abs/2512.17203)

**Authors**: Jiwoo Song, Daning Huang, John Harlim  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.17203v1  

#### Abstract
Many scientific and engineering systems exhibit complex nonlinear dynamics that are difficult to predict accurately over long time horizons. Although data-driven models have shown promise, their performance often deteriorates when the geometric structures governing long-term behavior are unknown or ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šLearning Solution Operator of Dynamical Systems with Diffusion Maps Kernel Ridge Regression**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
è®¸å¤šç§‘å­¦ä¸å·¥ç¨‹ç³»ç»Ÿè¡¨ç°å‡ºå¤æ‚çš„éçº¿æ€§åŠ¨åŠ›å­¦è¡Œä¸ºï¼Œå…¶é•¿æœŸæ¼”åŒ–é€šå¸¸è¢«é™åˆ¶åœ¨ä½ç»´çš„**å‰å‘ä¸å˜é›†**ï¼ˆforward invariant setï¼‰ä¸Šï¼Œä¾‹å¦‚å…‰æ»‘æµå½¢ï¼ˆå¦‚åˆšä½“æ—‹è½¬ï¼‰æˆ–åˆ†å½¢å¸å¼•å­ï¼ˆå¦‚æ··æ²Œç³»ç»Ÿï¼‰ã€‚ç„¶è€Œï¼Œè¿™äº›å‡ ä½•ç»“æ„é€šå¸¸æ˜¯æœªçŸ¥çš„ï¼Œä¸”éš¾ä»¥æ˜¾å¼å»ºæ¨¡ã€‚ä¼ ç»Ÿæ•°æ®é©±åŠ¨æ–¹æ³•ï¼ˆå¦‚ç¥ç»ç½‘ç»œã€ç®—å­å­¦ä¹ ï¼‰åœ¨ç¼ºä¹å¯¹å†…åœ¨å‡ ä½•çº¦æŸçš„å°Šé‡æ—¶ï¼Œå¾€å¾€åœ¨é•¿æ—¶é¢„æµ‹ä¸­è¿…é€Ÿå‘æ•£ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- å¦‚ä½•åœ¨ä¸æ˜¾å¼é‡å»ºæµå½¢æˆ–ä¼°è®¡åˆ‡ç©ºé—´çš„å‰æä¸‹ï¼Œè®©æ¨¡å‹è‡ªåŠ¨é€‚åº”ç³»ç»Ÿçš„**å†…åœ¨å‡ ä½•ç»“æ„**ï¼›
- å¦‚ä½•åœ¨å°æ ·æœ¬æ¡ä»¶ä¸‹å®ç°é«˜ç²¾åº¦ã€ç¨³å®šçš„**é•¿æ—¶é¢„æµ‹**ï¼›
- å¦‚ä½•è®¾è®¡ä¸€ä¸ªç®€å•ä½†å¼ºå¤§çš„åŸºçº¿æ¡†æ¶ï¼Œè¶…è¶Šå½“å‰å¤æ‚çš„æ·±åº¦å­¦ä¹ æ–¹æ³•ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**

ä½œè€…æå‡ºäº† **Diffusion Maps Kernel Ridge Regression (DM-KRR)**ï¼Œä¸€ç§åŸºäºæ ¸æ–¹æ³•çš„åŠ¨åŠ›ç³»ç»Ÿæ±‚è§£ç®—å­å­¦ä¹ æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³å¦‚ä¸‹ï¼š

#### âœ… **æ–°æ–¹æ³•ï¼šDM-KRR**
- å°†æ¯ä¸ªçŠ¶æ€è½¬ç§» $ x(t+\Delta t) $ æˆ–å¢é‡ $ \Delta x $ è§†ä¸ºä»å½“å‰çŠ¶æ€ $ x(t) $ åˆ°ç›®æ ‡çš„æ˜ å°„ï¼›
- ä½¿ç”¨ **Kernel Ridge Regression (KRR)** å­¦ä¹ è¯¥æ˜ å°„ï¼›
- é‡‡ç”¨ç”± **Diffusion Maps (DM)** æ„é€ çš„**æ•°æ®é©±åŠ¨æ ¸å‡½æ•°**ä½œä¸º KRR çš„æ ¸ï¼Œè€Œéä¼ ç»Ÿçš„ RBF æ ¸ã€‚

#### âœ… **å…³é”®åˆ›æ–°ç‚¹**
1. **å‡ ä½•æ„ŸçŸ¥çš„æ ¸è®¾è®¡ï¼ˆGeometry-aware Kernelï¼‰**  
   DM æ ¸é€šè¿‡çƒ­æ‰©æ•£è¿‡ç¨‹éšå¼ç¼–ç äº†æ•°æ®æ‰€åœ¨ä¸å˜é›†çš„**å†…è•´å‡ ä½•ç»“æ„**ï¼Œå³ä½¿è¯¥é›†åˆæ˜¯åˆ†å½¢ï¼ˆå¦‚ Lorenz å¸å¼•å­ï¼‰ï¼Œä¹Ÿèƒ½æœ‰æ•ˆé€¼è¿‘å…¶æ‹“æ‰‘ä¸åº¦é‡æ€§è´¨ã€‚

2. **æ— éœ€æ˜¾å¼æµå½¢é‡æ„**  
   ä¸éœ€è¦åƒ GMKRR é‚£æ ·ä¼°è®¡åˆ‡ç©ºé—´æˆ–æ³•å‘æ ¡æ­£ï¼Œä¹Ÿä¸ä¾èµ– autoencoder è¿›è¡Œæ½œç©ºé—´å»ºæ¨¡ï¼Œé¿å…äº†è¯¯å·®ç´¯ç§¯å’Œè®­ç»ƒå¤æ‚æ€§ã€‚

3. **åŠ¨æ€ä¸€è‡´çš„éªŒè¯ç­–ç•¥ï¼ˆDynamics-aware Validationï¼‰**  
   è¶…å‚æ•°é€‰æ‹©ä¸åŸºäºä¸€æ­¥é¢„æµ‹è¯¯å·®ï¼ˆå¦‚ RMSEï¼‰ï¼Œè€Œæ˜¯åŸºäº**çŸ­æ—¶é—´çª—å£å†…çš„è¿­ä»£é¢„æµ‹èƒ½åŠ›**ï¼ˆå¦‚ Valid Prediction Time, VPTï¼‰ï¼Œç¡®ä¿æ¨¡å‹å…·å¤‡è‰¯å¥½çš„é•¿æœŸç¨³å®šæ€§ã€‚

4. **ç»Ÿä¸€å¤„ç†å¤šç§åŠ¨åŠ›å­¦ç±»å‹**  
   é€‚ç”¨äºï¼š
   - å…‰æ»‘æµå½¢ä¸Šçš„è§„åˆ™åŠ¨åŠ›å­¦ï¼ˆå¦‚ Torusï¼‰
   - æ··æ²Œå¸å¼•å­ï¼ˆå¦‚ Lorenz-63, Kuramoto-Sivashinskyï¼‰
   - é«˜ç»´æ—¶ç©ºåœºï¼ˆå¦‚ pitching-plunge å¹³æ¿æµåŠ¨ï¼‰

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹æ³•ç±»åˆ« | å±€é™æ€§ | DM-KRR çš„ä¼˜åŠ¿ |
|--------|------|-------------|
| **Neural Networks (NODE, LDNet, CANDyMan)** | éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®ï¼›æ˜“åç¦»ä¸å˜é›†ï¼›è¶…å‚è°ƒä¼˜å›°éš¾ï¼›è®¡ç®—æˆæœ¬é«˜ | æ›´å°‘è®­ç»ƒæ•°æ®å³å¯è¾¾åˆ°æ›´é«˜ç²¾åº¦ï¼›æ— éœ€æ˜¾å¼å‡ ä½•å…ˆéªŒï¼›è®­ç»ƒæ›´å¿« |
| **Operator Learning (DeepONet, Fourier Neural Operators)** | ç»“æ„å¤æ‚ï¼›æ ·æœ¬æ•ˆç‡ä½ï¼›éš¾ä»¥ä¿è¯å‡ ä½•ä¸€è‡´æ€§ | ç»“æ„æç®€ï¼›æ ·æœ¬æ•ˆç‡æ˜¾è‘—æ›´é«˜ |
| **Random Feature Models (e.g., DeepSkip)** | è¡¨è¾¾èƒ½åŠ›æœ‰é™ï¼›ä»éœ€å¤§é‡æ•°æ® | åœ¨æ›´å°‘æ•°æ®ä¸‹å®ç°æ›´é•¿ VPT |
| **GMKRR** | ä¾èµ–åˆ‡ç©ºé—´ä¼°è®¡ï¼Œæ— æ³•å¤„ç†åˆ†å½¢ç»“æ„ | å¯è‡ªç„¶æ‰©å±•è‡³éå…‰æ»‘ä¸å˜é›† |
| **ResDMD / DMD-family** | æ˜“å—è°±æ±¡æŸ“å½±å“ï¼›ç‰¹å¾å€¼ä¸å‡†å¯¼è‡´é•¿æœŸæ¼‚ç§» | æ›´ç¨³å®šåœ°ä¿æŒå‘¨æœŸæ€§å’Œèƒ½é‡å®ˆæ’ |

> ğŸ’¡ **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼š**ç®€å• + å‡ ä½•æ„ŸçŸ¥ + åŠ¨æ€éªŒè¯ = å¼ºå¤§çš„é•¿æ—¶é¢„æµ‹æ€§èƒ½**

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸ç³»ç»Ÿ**

| ç³»ç»Ÿ | ç±»å‹ | çŠ¶æ€ç»´åº¦ | ä¸å˜é›†ç‰¹æ€§ |
|-----|------|---------|-----------|
| **Torus Dynamics** | æµå½¢åŠ¨åŠ›å­¦ | 3â€“15 | å…‰æ»‘äºŒç»´æµå½¢ï¼ˆå•ä½çƒé¢æ˜ å°„åˆ°ç¯é¢ï¼‰ |
| **Lorenz-63 System** | æ··æ²Œç³»ç»Ÿ | 3 | åˆ†å½¢å¸å¼•å­ï¼ˆ~2.06 ç»´ï¼‰ |
| **Kuramoto-Sivashinsky (KS) Equation** | PDE / æ··æ²Œæ—¶ç©ºåœº | 64 | Kaplan-Yorke ç»´æ•° ~5.2 |
| **KS Travelling Waves** | è§„åˆ™æ³¢ä¼ æ’­ | 64 | 2D ç¯é¢ï¼ˆåŒæ—¶é—´å°ºåº¦ï¼‰ |
| **Pitch-Plunge Flat Plate** | é«˜ç»´æµä½“æ¨¡æ‹Ÿ | 179,101 | ä½ç»´ä¸å˜å­æµå½¢ï¼ˆPCA é™ç»´åä½¿ç”¨ï¼‰ |

---

### **å®éªŒè®¾ç½®**

- æ‰€æœ‰å®éªŒå‡é‡‡ç”¨ **rollout prediction** æ–¹å¼è¿›è¡Œé•¿æ—¶é¢„æµ‹ï¼›
- è¾“å…¥è¾“å‡ºæ„é€ æ–¹å¼ï¼š
  - **Direct Form**: $ x_{t+1} = f(x_t) $
  - **Skip-Connection Form**: $ x_{t+1} - x_t = f(x_t) $ï¼ˆç”¨äºéåˆšæ€§ç³»ç»Ÿï¼‰
- ä½¿ç”¨ **skip-connection å½¢å¼æå‡æ•°å€¼ç¨³å®šæ€§**

---

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | å®šä¹‰ | ç”¨é€” |
|------|------|------|
| **RMSE** | $ \frac{1}{T}\sum_{i=1}^T \|x_i - \hat{x}_i\|^2 $ | çŸ­æœŸé¢„æµ‹è¯¯å·® |
| **Valid Prediction Time (VPT)** | æœ€å¤§æ—¶é—´é•¿åº¦ä½¿å¾—å½’ä¸€åŒ–è¯¯å·® $ E_i < \gamma $ï¼ˆé€šå¸¸å– Î³=0.3~0.5ï¼‰ | è¡¡é‡**é•¿æœŸé¢„æµ‹èƒ½åŠ›**ï¼Œä»¥æœ€å¤§æé›…æ™®è¯ºå¤«æ—¶é—´ $ T_\Lambda = 1/\lambda_{\text{max}} $ ä¸ºå•ä½ |
| **Convergence Rate** | RMSE éšè®­ç»ƒæ ·æœ¬æ•° $ N $ çš„è¡°å‡é€Ÿç‡ | è¡¡é‡**æ ·æœ¬æ•ˆç‡** |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿æ–¹æ³• | ç±»å‹ |
|--------|------|
| **RBF-KRR** | ä½¿ç”¨é«˜æ–¯å¾„å‘åŸºå‡½æ•°æ ¸çš„ KRRï¼ˆä½œä¸ºåŸºå‡†ï¼‰ |
| **GMKRR** | å‡ ä½•çº¦æŸçš„ç®—å­å€¼æ ¸å›å½’ï¼ˆéœ€æµå½¢å…ˆéªŒï¼‰ |
| **CANDyMan** | åŸºäºå›¾å†Œï¼ˆatlasï¼‰çš„ç¥ç»ç½‘ç»œæµå½¢å­¦ä¹  |
| **NODE / LDNet** | ç¥ç»å¾®åˆ†æ–¹ç¨‹åŠå…¶æ½œç©ºé—´ç‰ˆæœ¬ |
| **ResDMD** | æŠ—è°±æ±¡æŸ“çš„åŠ¨æ€æ¨¡æ€åˆ†è§£ |
| **DeepSkip [24]** | å½“å‰æœ€å…ˆè¿›çš„éšæœºç‰¹å¾æ··æ²Œé¢„æµ‹æ¨¡å‹ï¼ˆä½¿ç”¨ 50,000 æ•°æ®ç‚¹ï¼‰ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

#### ğŸ”¹ **Torus Dynamicsï¼ˆæµå½¢ç³»ç»Ÿï¼‰**
- **æ”¶æ•›é€Ÿç‡**ï¼š
  - DM-KRR: $ O(N^{-4.3} \sim N^{-5.06}) $
  - RBF-KRR: $ O(N^{-3.84} \sim N^{-3.91}) $
- å½“ $ N=8192 $ æ—¶ï¼ŒDM çš„ RMSE æ¯” RBF **ä½ä¸€ä¸ªæ•°é‡çº§**

> âœ… è¡¨æ˜ DM æ ¸å…·æœ‰æ›´å¼ºçš„å‡ ä½•é€‚åº”èƒ½åŠ›å’Œæ›´é«˜çš„æ ·æœ¬æ•ˆç‡

---

#### ğŸ”¹ **Lorenz-63ï¼ˆæ··æ²Œç³»ç»Ÿï¼‰**
| æ¨¡å‹ | $ N=512 $ | $ N=1024 $ | $ N=2048 $ | $ N=4096 $ |
|------|------------|-------------|-------------|-------------|
| **DM-KRR** | 11.03 Â± 2.41 | **13.18 Â± 1.25** | **13.84 Â± 0.59** | **14.10 Â± 0.46** |
| **RBF-KRR** | 8.87 Â± 1.71 | 11.20 Â± 1.42 | 12.72 Â± 0.92 | 13.47 Â± 0.61 |

- åœ¨ $ N=1024 $ æ—¶ï¼ŒDM-KRR è¾¾åˆ° **13.18 TA** çš„ VPTï¼Œä»…ç”¨çº¦ 4000 æ•°æ®ç‚¹ï¼›
- å¯¹æ¯” DeepSkip [24]ï¼šä½¿ç”¨ **50,000 æ•°æ®ç‚¹**ï¼ŒVPT â‰ˆ 12.02 TAï¼›
- âœ DM-KRR **ç”¨ä¸åˆ° 1/12 çš„æ•°æ®ï¼Œè·å¾—æ›´é•¿çš„é¢„æµ‹æ—¶é—´**

---

#### ğŸ”¹ **Kuramoto-Sivashinskyï¼ˆé«˜ç»´æ··æ²Œ PDEï¼‰**
| æ¨¡å‹ | $ N=2048 $ | $ N=4096 $ | $ N=8192 $ | $ N=16384 $ |
|------|-------------|-------------|-------------|--------------|
| **DM-KRR** | 0.86 Â± 0.15 | **1.72 Â± 0.18** | **3.12 Â± 0.21** | **4.98 Â± 0.23** |
| **RBF-KRR** | 0.79 Â± 0.13 | 1.49 Â± 0.21 | 2.72 Â± 0.26 | 4.31 Â± 0.33 |

- DM å§‹ç»ˆä¼˜äº RBFï¼Œä¸”å·®è·éšæ•°æ®é‡å¢å¤§è€Œæ‰©å¤§ï¼›
- è¡¨æ˜ DM èƒ½æ›´å¥½åœ°åˆ©ç”¨é¢å¤–æ•°æ®æå‡æ³›åŒ–èƒ½åŠ›ã€‚

---

#### ğŸ”¹ **KS Travelling Wavesï¼ˆè§„åˆ™æ³¢ï¼‰**
- æ‰€æœ‰ NN åŸºçº¿ï¼ˆNODE, LDNet, CANDyManï¼‰è¡¨ç°å·®ï¼Œè¯¯å·®ç§¯ç´¯ä¸¥é‡ï¼›
- GMKRR å› å¼•å…¥äº†å‡ ä½•å…ˆéªŒï¼Œè¡¨ç°è¾ƒå¥½ï¼ˆä½†ä»å—é™äºåˆ‡ç©ºé—´ä¼°è®¡ç²¾åº¦ï¼‰ï¼›
- **DM-KRR å’Œ RBF-KRR é”™è¯¯é™ä½ 5â€“6 ä¸ªæ•°é‡çº§**ï¼›
- **DM æ¯” RBF å†ä½ä¸€ä¸ªæ•°é‡çº§**

> âœ… å³ä½¿æ²¡æœ‰æ˜¾å¼å‡ ä½•å…ˆéªŒï¼ŒDM-KRR ä¹Ÿèƒ½è‡ªåŠ¨æ•æ‰å†…åœ¨ç»“æ„

---

#### ğŸ”¹ **Pitch-Plunge Flat Plateï¼ˆçœŸå®æµä½“é—®é¢˜ï¼‰**
- çŠ¶æ€ç»´åº¦é«˜è¾¾ **179,101**ï¼Œä½¿ç”¨ PCA é™è‡³ 81 ç»´ï¼›
- RBF-KRR å®Œå…¨å¤±è´¥ï¼Œæ— æ³•æ•æ‰æ¶¡è„±è½ç°è±¡ï¼›
- ResDMD åˆæœŸå°šå¯ï¼Œä½†è¯¯å·®æŒç»­å¢é•¿ï¼ˆå› ç‰¹å¾å€¼åç§»ï¼‰ï¼›
- **DM-KRR ä¸ä»…åˆå§‹è¯¯å·®æœ€ä½ï¼Œä¸”åœ¨æ•´ä¸ª 20 å‘¨æœŸå†…ä¿æŒç¨³å®šè¯¯å·®æ°´å¹³**

> âœ… æ˜¾ç¤º DM-KRR åœ¨é«˜ç»´çœŸå®ç‰©ç†ç³»ç»Ÿä¸­çš„é²æ£’æ€§å’Œé•¿æœŸç¨³å®šæ€§

---

### **æ¶ˆèå®éªŒä¸åˆ†æ**

- **éªŒè¯ç­–ç•¥çš„é‡è¦æ€§**ï¼š
  - è‹¥ä»…ç”¨ä¸€æ­¥ RMSE é€‰å‚ï¼Œæ¨¡å‹å€¾å‘äºè¿‡æ‹ŸåˆçŸ­æœŸè¡Œä¸ºï¼Œé•¿æ—¶é¢„æµ‹å´©æºƒï¼›
  - ä½¿ç”¨ **multi-step VPT éªŒè¯** å¯é€‰å‡ºçœŸæ­£é€‚åˆé•¿æœŸæ¼”åŒ–çš„è¶…å‚æ•°ã€‚
- **æ ¸çš„é€‰æ‹©å†³å®šä¸Šé™**ï¼š
  - ç›¸åŒ KRR æ¡†æ¶ä¸‹ï¼Œ**DM æ ¸ > RBF æ ¸**ï¼Œè¯´æ˜æ ¸çš„è®¾è®¡æ¯”æ¨¡å‹å¤æ‚åº¦æ›´é‡è¦ã€‚
- **è·³è¿ç»“æ„ï¼ˆskip-connectionï¼‰æå‡ç¨³å®šæ€§**ï¼š
  - ç‰¹åˆ«é€‚ç”¨äºéåˆšæ€§ç³»ç»Ÿï¼ˆå¦‚ KS æ–¹ç¨‹ï¼‰ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**

1. âœ… **ç®€å•çš„ KRR æ¡†æ¶å¯ä»¥æˆä¸ºå¼ºå¤§çš„åŸºçº¿æ¨¡å‹**  
   åªè¦é…åˆåˆé€‚çš„æ ¸å’ŒéªŒè¯ç­–ç•¥ï¼ŒScalar-valued KRR å°±èƒ½åœ¨å¤šç§åŠ¨åŠ›ç³»ç»Ÿä¸Šè¶…è¶Šå¤æ‚çš„ NN å’Œç®—å­å­¦ä¹ æ–¹æ³•ã€‚

2. âœ… **å‡ ä½•æ„ŸçŸ¥çš„æ ¸è‡³å…³é‡è¦**  
   DM æ ¸èƒ½è‡ªåŠ¨é€‚åº”ä¸å˜é›†çš„å†…è•´å‡ ä½•ï¼Œæ— è®ºæ˜¯å…‰æ»‘æµå½¢è¿˜æ˜¯åˆ†å½¢ç»“æ„ï¼Œå‡è¡¨ç°å‡ºä¼˜è¶Šçš„è¡¨è¾¾èƒ½åŠ›ã€‚

3. âœ… **åŠ¨æ€ä¸€è‡´çš„éªŒè¯ç­–ç•¥æ˜¯æˆåŠŸçš„å…³é”®**  
   â€œé¢„æµ‹å¾—åƒä¸åƒâ€ åº”ç”±â€œèƒ½å¦é•¿æœŸè¿­ä»£â€æ¥è¯„åˆ¤ï¼Œè€Œä¸æ˜¯å•æ­¥è¯¯å·®æœ€å°åŒ–ã€‚

4. âœ… **æ ·æœ¬æ•ˆç‡æé«˜**  
   åœ¨å¤šä¸ªä»»åŠ¡ä¸­ï¼ŒDM-KRR ç”¨è¿œå°‘äº SOTA æ–¹æ³•çš„æ•°æ®é‡å®ç°äº†æ›´å¥½çš„é•¿æ—¶é¢„æµ‹æ€§èƒ½ã€‚

5. âœ… **æ— éœ€æ˜¾å¼å»ºæ¨¡æµå½¢æˆ–å¸å¼•å­**  
   é¿å…äº†æµå½¢å­¦ä¹ ã€åˆ‡ç©ºé—´ä¼°è®¡ç­‰æ˜“é”™æ­¥éª¤ï¼Œç®€åŒ–äº†æµç¨‹ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™æ€§ | è¯´æ˜ |
|-------|------|
| **è®¡ç®—å¤æ‚åº¦** | KRR éœ€æ±‚è§£ $ N\times N $ æ ¸çŸ©é˜µï¼Œæ—¶é—´å¤æ‚åº¦ $ O(N^3) $ï¼Œä¸é€‚åˆè¶…å¤§æ•°æ®é›† |
| **å†…å­˜æ¶ˆè€—å¤§** | å­˜å‚¨æ ¸çŸ©é˜µéœ€ $ O(N^2) $ å†…å­˜ï¼Œåœ¨ç™¾ä¸‡çº§æ•°æ®ä¸Šä¸å¯è¡Œ |
| **å›ºå®šå¸¦å®½ DM æ ¸** | å½“æ•°æ®å¯†åº¦ä¸å‡æ—¶å¯èƒ½å¤±æ•ˆï¼Œå»ºè®®ä½¿ç”¨ variable-bandwidth DM æ”¹è¿› |
| **å™ªå£°æ•æ„Ÿ** | åŸå§‹æ¡†æ¶æœªè€ƒè™‘è§‚æµ‹å™ªå£°ï¼Œå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€ç»“åˆæ»¤æ³¢å™¨ï¼ˆå¦‚ Kalmanï¼‰è¿›è¡Œå»å™ª |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **åŠ é€Ÿç®—æ³•**ï¼šå¼•å…¥å¿«é€Ÿæ±‚è§£å™¨ï¼ˆå¦‚ randomized sketchingã€sparse Choleskyï¼‰ä»¥æ”¯æŒæ›´å¤§è§„æ¨¡æ•°æ®ï¼›
2. **å¯å˜å¸¦å®½æ ¸**ï¼šä½¿ç”¨ **variable-bandwidth Diffusion Maps** æå‡å¯¹éå‡åŒ€é‡‡æ ·æ•°æ®çš„é€‚åº”æ€§ï¼›
3. **åœ¨çº¿å­¦ä¹ ä¸è‡ªé€‚åº”é‡‡æ ·**ï¼šç»“åˆä¸»åŠ¨å­¦ä¹ ç­–ç•¥å‡å°‘æ•°æ®éœ€æ±‚ï¼›
4. **ä¸ç‰©ç†æ¨¡å‹èåˆ**ï¼šå°† DM-KRR ç”¨äºä¿®æ­£å·²çŸ¥æ¨¡å‹çš„æ®‹å·®é¡¹ï¼ˆpartial data-driven settingï¼‰ï¼›
5. **ä¸ç¡®å®šæ€§é‡åŒ–**ï¼šç»“åˆ GP æˆ– Bayesian KRR æä¾›ç½®ä¿¡åŒºé—´ï¼›
6. **å®æ—¶éƒ¨ç½²**ï¼šæ¢ç´¢ä½ç§©è¿‘ä¼¼ä¸è¾¹ç¼˜è®¡ç®—é›†æˆã€‚

---

## **æ€»ç»“**

> ğŸŒŸ **DM-KRR æ˜¯ä¸€ä¸ªâ€œå¤§é“è‡³ç®€â€çš„å…¸èŒƒï¼šå®ƒç”¨æœ€ç®€å•çš„æ¨¡å‹ç»“æ„ï¼Œå€ŸåŠ©æ•°æ®é©±åŠ¨çš„å‡ ä½•æ„ŸçŸ¥æ ¸å’ŒåŠ¨æ€ä¸€è‡´çš„éªŒè¯æœºåˆ¶ï¼Œåœ¨å¤šæ ·åŒ–çš„åŠ¨åŠ›ç³»ç»Ÿä¸Šå®ç°äº†å“è¶Šçš„é•¿æ—¶é¢„æµ‹æ€§èƒ½ã€‚**

è¯¥å·¥ä½œæ­ç¤ºäº†ä¸€ä¸ªæ·±åˆ»æ´è§ï¼š**åœ¨ç§‘å­¦æœºå™¨å­¦ä¹ ä¸­ï¼Œæ¨¡å‹çš„æˆåŠŸä¸ä»…å–å†³äºè¡¨è¾¾èƒ½åŠ›ï¼Œæ›´åœ¨äºæ˜¯å¦å°Šé‡äº†æ•°æ®èƒŒåçš„ç‰©ç†ä¸å‡ ä½•è§„å¾‹ã€‚**  
æœªæ¥çš„ç ”ç©¶åº”æ›´å¤šå…³æ³¨â€œå¦‚ä½•è®©æ¨¡å‹ä¸ç³»ç»Ÿç»“æ„å¯¹è¯â€ï¼Œè€Œéä¸€å‘³å †å å¤æ‚æ¶æ„ã€‚

</details>

---

### 8. [Bridging Training and Merging Through Momentum-Aware Optimization](https://arxiv.org/abs/2512.17109)

**Authors**: Alireza Moayedikia, Alicia Troncoso  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.17109v1  

#### Abstract
Training large neural networks and merging task-specific models both exploit low-rank structure and require parameter importance estimation, yet these challenges have been pursued in isolation. Current workflows compute curvature information during training, discard it, then recompute similar inform...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Bridging Training and Merging Through Momentum-Aware Optimization è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§æ¨¡å‹è®­ç»ƒå’Œå¤šä»»åŠ¡æ¨¡å‹åˆå¹¶ï¼ˆmodel mergingï¼‰é€šå¸¸è¢«ä½œä¸ºä¸¤ä¸ªç‹¬ç«‹æµç¨‹å¤„ç†ï¼š
- **è®­ç»ƒé˜¶æ®µ**ï¼šä½¿ç”¨å¦‚ Adam ç­‰ä¼˜åŒ–å™¨æ—¶ï¼Œä¼šè®¡ç®—æ¢¯åº¦ã€åŠ¨é‡å’Œæ›²ç‡ï¼ˆcurvatureï¼‰ç­‰ä¿¡æ¯ç”¨äºè‡ªé€‚åº”å­¦ä¹ ç‡è°ƒæ•´ï¼Œä½†åœ¨è®­ç»ƒç»“æŸåè¿™äº›ä¿¡æ¯è¢«ä¸¢å¼ƒã€‚
- **åˆå¹¶é˜¶æ®µ**ï¼šåœ¨åˆå¹¶å¤šä¸ªä»»åŠ¡ç‰¹å®šæ¨¡å‹æ—¶ï¼Œéœ€è¦é‡æ–°è®¡ç®—å‚æ•°é‡è¦æ€§ï¼ˆå¦‚é€šè¿‡ Fisher ä¿¡æ¯çŸ©é˜µï¼‰ï¼Œè¿™å¯¼è‡´å¤§é‡å†—ä½™è®¡ç®—ã€‚

è¿™ç§â€œå…ˆè®­ç»ƒå†é‡æ–°åˆ†æâ€çš„èŒƒå¼æµªè´¹äº†è®­ç»ƒè¿‡ç¨‹ä¸­ç§¯ç´¯çš„å®è´µè½¨è¿¹ä¿¡æ¯ï¼Œä¸”åå¤„ç†çš„ Fisher è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šUMTAM
ä½œè€…æå‡º **UMTAM**ï¼ˆUnified Momentum-Trajectory Aware Training and Mergingï¼‰ï¼Œä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œå°†è®­ç»ƒä¸æ¨¡å‹åˆå¹¶ç»“åˆï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> **å°†ä¼˜åŒ–è¿‡ç¨‹ä¸­çš„åŠ¨é‡ä¸æ›²ç‡ç»Ÿè®¡ä¿¡æ¯ä¿ç•™å¹¶å¤ç”¨äºåç»­çš„æ¨¡å‹åˆå¹¶ï¼Œé¿å…é‡å¤è®¡ç®—ã€‚**

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
1. **åŒä½ç§©å› å­åŒ–ï¼ˆDual Momentum Factorizationï¼‰**  
   åœ¨è®­ç»ƒä¸­ç»´æŠ¤ä½ç§©å½¢å¼çš„åŠ¨é‡ $ U\Sigma V^\top $ å’Œå› å­åŒ–çš„äºŒé˜¶çŸ©ç»Ÿè®¡é‡ï¼ˆ$ R \in \mathbb{R}^m, C \in \mathbb{R}^n $ï¼‰ï¼Œå®ç°å†…å­˜é«˜æ•ˆä¼˜åŒ–ã€‚

2. **è¯¯å·®åé¦ˆæœºåˆ¶ï¼ˆError Feedbackï¼‰**  
   å°†æ¯æ¬¡ SVD å‹ç¼©äº§ç”Ÿçš„æ®‹å·®ç´¯ç§¯å¹¶åé¦ˆåˆ°ä¸‹ä¸€æ¬¡æ›´æ–°ä¸­ï¼Œé˜²æ­¢ä¿¡æ¯æ°¸ä¹…ä¸¢å¤±ï¼Œä¿éšœæ”¶æ•›æ€§ã€‚

3. **æ›²ç‡æ„ŸçŸ¥æ˜¾è‘—æ€§è¯„åˆ†ï¼ˆCurvature-Aware Saliencyï¼‰**  
   åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æŒç»­ç´¯ç§¯æ¯ä¸ªå‚æ•°çš„é‡è¦æ€§å¾—åˆ†ï¼š
   $$
   S_{ij}^{(T)} = (W_{ij} - W_{0,ij})^2 \cdot \sqrt{R_i C_j}
   $$
   å³ç»“åˆäº†å‚æ•°åç¦»åˆå§‹å€¼çš„ç¨‹åº¦å’Œå±€éƒ¨æŸå¤±æ›²ç‡ï¼Œæä¾›æ›´ä¸°å¯Œçš„å‡ ä½•æ„ŸçŸ¥é‡è¦æ€§ä¿¡å·ã€‚

4. **å¯é‡ç”¨çš„è®­ç»ƒè½¨è¿¹èµ„äº§åŒ–**  
   ä¸å†å°†ä¼˜åŒ–è½¨è¿¹è§†ä¸ºä¸´æ—¶ä¸­é—´äº§ç‰©ï¼Œè€Œæ˜¯å°†å…¶ä½œä¸ºå¯å¤ç”¨çš„â€œèµ„äº§â€ï¼Œç›´æ¥ç”¨äºä¸‹æ¸¸çš„æ¨¡å‹åˆå¹¶ä»»åŠ¡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | UMTAM |
|------|--------|-------|
| å†…å­˜æ•ˆç‡ | é«˜ï¼ˆå¦‚ GaLoreï¼‰ä½†ä¿¡æ¯ä¸¢å¼ƒ | åŒæ ·é«˜æ•ˆï¼Œä¸”ä¿ç•™å…³é”®ç»Ÿè®¡ä¿¡æ¯ |
| åˆå¹¶è´¨é‡ | ä¾èµ–åéªŒ Fisher æˆ– magnitude | åˆ©ç”¨è®­ç»ƒä¸­å·²æœ‰çš„æ›²ç‡ä¿¡æ¯ï¼Œæ›´å‡†ç¡® |
| è®¡ç®—å¼€é”€ | è®­ç»ƒ + åå¤„ç† Fisher è®¡ç®— | æ— é¢å¤–å¼€é”€ï¼Œè®­ç»ƒå³ä¸ºå‡†å¤‡ |
| è¶…å‚é²æ£’æ€§ | å¯¹ rank å’Œ lr æ•æ„Ÿ | å±•ç° rank-invariant æ”¶æ•›ç‰¹æ€§ |
| ç†è®ºæ”¯æŒ | å¤šæ•°ç¼ºä¹å®Œæ•´ç†è®º | æä¾›éå‡¸ç›®æ ‡ä¸‹çš„æ”¶æ•›ä¿è¯ã€æ³›åŒ–ç•Œç­‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **GLUE Benchmark**ï¼šç”¨äºéªŒè¯å¤šä»»åŠ¡åˆå¹¶æ•ˆæœï¼ŒåŒ…å«å››ä¸ªä»»åŠ¡ï¼š
  - RTEï¼ˆæ–‡æœ¬è•´å«ï¼‰
  - MRPCï¼ˆè¯­ä¹‰åŒ¹é…ï¼‰
  - QNLIï¼ˆé—®ç­”æ¨ç†ï¼‰
  - CoLAï¼ˆè¯­æ³•å¯æ¥å—æ€§åˆ¤æ–­ï¼‰
- **FineWeb**ï¼šç”¨äº GPT-2ï¼ˆ124Mï¼‰ä¸Šçš„è®­ç»ƒåŠ¨æ€åˆ†æã€‚
- **Tulu-3-sft-mixture**ï¼šç”¨äº Mistral-7B ä¸Šçš„æŒ‡ä»¤å¾®è°ƒå®éªŒã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼š
  - BERT-baseï¼ˆ110M å‚æ•°ï¼‰ç”¨äº GLUE å¾®è°ƒä¸åˆå¹¶å®éªŒ
  - GPT-2ï¼ˆ124Mï¼‰ç”¨äºè®­ç»ƒæ€§èƒ½æ¯”è¾ƒ
  - Mistral-7B ç”¨äºå¤§è§„æ¨¡æŒ‡ä»¤å¾®è°ƒ
- **è®­ç»ƒé…ç½®**ï¼š
  - ä½¿ç”¨ LoRAï¼ˆrank=64ï¼‰ã€4-bit é‡åŒ–ã€æ¢¯åº¦ç´¯ç§¯ç­‰ç°ä»£é«˜æ•ˆè®­ç»ƒæŠ€æœ¯
  - å­¦ä¹ ç‡èŒƒå›´ï¼š$3\times10^{-5}$ è‡³ $5\times10^{-4}$
  - å› å­åŒ– rank è®¾ç½®ä¸º 8â€“128
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - åˆ†ç±»ä»»åŠ¡ï¼šAccuracy, F1, MCC
  - è¯­è¨€å»ºæ¨¡ï¼šValidation Loss, Perplexity
  - åˆå¹¶æ€§èƒ½ï¼šå¹³å‡å¾—åˆ†ã€ä¸å•ä»»åŠ¡ä¸“å®¶å·®è·
  - è¶…å‚æ•æ„Ÿæ€§ï¼šä¸åŒ sparsity ä¸‹çš„è¡¨ç°ç¨³å®šæ€§

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **Linear Averaging (Task Arithmetic)** | ç®€å•å¹³å‡ | å¿½ç•¥å†²çªä¸é‡è¦æ€§ |
| **TIES-Merging** | magnitude-based pruning + sign voting | å½“å‰ä¸»æµåŸºçº¿ |
| **DARE** | é«˜ç¨€ç–æ€§ delta pruning | å¼ºè°ƒå†—ä½™æ€§ |
| **DARE+TIES** | ç»„åˆæ–¹æ³• | å¼ºåŸºçº¿ |
| **GaLore**, **MoFaSGD** | ä½ç§©è®­ç»ƒä¼˜åŒ–å™¨ | æ¯”è¾ƒè®­ç»ƒæ€§èƒ½ä¸ç¨³å®šæ€§ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### âœ… å¤šä»»åŠ¡åˆå¹¶æ€§èƒ½ï¼ˆTable 2ï¼‰
| Method | RTE | MRPC | QNLI | CoLA | **Avg** |
|--------|-----|------|------|------|--------|
| Experts (UB) | 0.607 | 0.883 | 0.816 | 0.562 | 0.717 |
| Linear | 0.560 | 0.807 | 0.645 | 0.339 | 0.588 |
| TIES | 0.574 | 0.851 | 0.781 | 0.452 | 0.664 |
| **UMTAM** | **0.578** | **0.855** | **0.782** | **0.487** | **0.675** |

- **UMTAM å¹³å‡æå‡ +1.6% vs TIESï¼Œ+14.9% vs Linear**
- åœ¨ CoLA ä¸Šæå‡æœ€å¤§ï¼ˆ+7.6%ï¼‰ï¼Œè¯´æ˜å¯¹å¤æ‚è¯­æ³•ä»»åŠ¡æ›´æœ‰æ•ˆ

#### âœ… ç¨€ç–æ€§æ•æ„Ÿæ€§åˆ†æï¼ˆTable 3 & Figure 4ï¼‰
- åœ¨æ‰€æœ‰ sparsity æ°´å¹³ä¸Šï¼ŒUMTAM å‡ä¼˜äº TIES
- åœ¨æç«¯ç¨€ç–ï¼ˆk=5%ï¼‰æ—¶ä¼˜åŠ¿æœ€å¤§ï¼ˆ+6.4%ï¼‰
- UMTAM æ€§èƒ½æ³¢åŠ¨ä»… 2.8%ï¼Œè€Œ TIES è¾¾ 7.1%ï¼Œè¡¨æ˜æ›´å¼ºçš„è¶…å‚é²æ£’æ€§

#### âœ… è®­ç»ƒæ€§èƒ½å¯¹æ¯”ï¼ˆTable 4â€“6ï¼‰
- åœ¨ $ \eta = 3\times10^{-5} $ ä¸‹ï¼ŒUMTAM æœ€ç»ˆ loss: **2.044**
  - vs GaLore: 2.118ï¼ˆâ†“3.5%ï¼‰
  - vs MoFaSGD: 2.187ï¼ˆâ†“7.0%ï¼‰
- åœ¨é«˜å­¦ä¹ ç‡ $ \eta = 1\times10^{-4} $ ä¸‹ï¼ŒMoFaSGD å‡ºç°ä¸¥é‡ä¸ç¨³å®šï¼ˆloss ä» 2.129 â†’ 3.800 @ rank=16ï¼‰ï¼Œè€Œ UMTAM ä¿æŒç¨³å®š

#### âœ… æ¶ˆèå®éªŒï¼ˆTable 9 & 10ï¼‰
| æ–¹æ³• | Avg Score | Î” vs Full |
|------|----------|---------|
| Full UMTAM | **0.667** | â€” |
| -Curv. Pruning | 0.659 | -1.18% |
| -Sign Election | 0.663 | -0.60% |
| -Curv. Aggregation | 0.663 | -0.70% |
| Linear Averaging | 0.585 | -12.31% |

- **å„ç»„ä»¶å‡æœ‰æ­£å‘è´¡çŒ®**ï¼Œå°¤å…¶ curvature-aware pruning æœ€å…³é”®ï¼ˆ+1.18%ï¼‰
- æ‰€æœ‰ç»„ä»¶ååŒä½œç”¨æ˜æ˜¾ï¼šå•ç‹¬ç§»é™¤å½±å“å°ï¼Œå…¨éƒ¨ç§»é™¤åˆ™æ€§èƒ½æš´è·Œ

#### âœ… æŒ‡ä»¤å¾®è°ƒå®éªŒï¼ˆTable 11ï¼‰
| Optimizer | Val Loss | Perplexity |
|----------|----------|------------|
| AdamW | 0.762 | 2.14 |
| UMTAM | **0.761** | **2.14** |

- **è®­ç»ƒæ€§èƒ½ä¸ AdamW å®Œå…¨ç›¸å½“**ï¼Œè¯æ˜æ–°å¢åŠŸèƒ½ä¸å½±å“ä¼˜åŒ–è½¨è¿¹
- å¯æ— ç¼é›†æˆ LoRAã€4-bit é‡åŒ–ç­‰ç°ä»£æŠ€æœ¯

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **è®­ç»ƒè¿‡ç¨‹ä¸­çš„åŠ¨é‡ä¸æ›²ç‡ä¿¡æ¯æå…·ä»·å€¼**ï¼Œä¸åº”ä¸¢å¼ƒï¼Œå¯ç”¨äºæŒ‡å¯¼æ¨¡å‹åˆå¹¶ã€‚
2. âœ… **æ›²ç‡æ„ŸçŸ¥æ˜¾è‘—æ€§ï¼ˆcurvature-aware saliencyï¼‰æ˜¾è‘—ä¼˜äº magnitude-only æ–¹æ³•**ï¼Œå°¤å…¶æ˜¯åœ¨é«˜ç¨€ç–æ¡ä»¶ä¸‹ã€‚
3. âœ… **UMTAM å®ç°äº† rank-invariant æ”¶æ•›**ï¼šåœ¨ä¸åŒ rank è®¾ç½®ä¸‹æ€§èƒ½å‡ ä¹ä¸å˜ï¼Œæå¤§é™ä½è°ƒå‚éš¾åº¦ã€‚
4. âœ… **UMTAM åœ¨å¤šä»»åŠ¡åˆå¹¶ä¸­æ¢å¤äº† 96.2% çš„ä¸“å®¶æ€§èƒ½**ï¼Œè¿œè¶…çº¿æ€§å¹³å‡ï¼ˆ84.4%ï¼‰ã€‚
5. âœ… **æ— éœ€é¢å¤–è®¡ç®—å³å¯å®ç°é«˜è´¨é‡åˆå¹¶**ï¼šç›¸æ¯”éœ€åéªŒ Fisher çš„æ–¹æ³•ï¼ŒèŠ‚çœå¤§é‡ forward/backward passesã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å†…å­˜å¼€é”€ç•¥é«˜äºæ ‡å‡† AdamW**ï¼šå› éœ€å­˜å‚¨ $ R, C, S_T, W_0 $ ç­‰ï¼Œå³°å€¼å†…å­˜å¢åŠ çº¦ 30%ï¼ˆè§ Table 8ï¼‰ã€‚
- **å¯¹æŸäº›ä»»åŠ¡å¢ç›Šæœ‰é™**ï¼šå¦‚ CoLA ä¸­ curvature-aggregation åè€Œè½»å¾®ä¸‹é™ï¼Œå¯èƒ½å› å…¶æ›²ç‡åˆ†å¸ƒè¾ƒå¹³å¦ã€‚
- **ç›®å‰æœªæ¢ç´¢åŠ¨æ€ rank è°ƒæ•´ç­–ç•¥**ï¼šè™½æ”¯æŒ adaptive rankï¼Œä½†æœªæ·±å…¥ç ”ç©¶å…¶æ½œåŠ›ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³ Continual Learning**ï¼šåˆ©ç”¨è½¨è¿¹ä¿¡æ¯è¿›è¡Œ selective plasticity æ§åˆ¶ã€‚
2. **è”é‚¦å­¦ä¹ åœºæ™¯åº”ç”¨**ï¼šå®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒåä¸Šä¼ ä½ç§©ç»Ÿè®¡é‡ï¼Œå®ç°é€šä¿¡é«˜æ•ˆçš„èšåˆã€‚
3. **è®¾è®¡é¢å‘åˆå¹¶çš„ä¸“ç”¨ä¼˜åŒ–å™¨**ï¼šä»ä¸€å¼€å§‹å°±ä»¥â€œå¯åˆå¹¶æ€§â€ä¸ºç›®æ ‡ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ã€‚
4. **ç»“åˆ Bayesian merging æ¡†æ¶**ï¼šå°† UMTAM çš„ saliency è§†ä¸ºä¸ç¡®å®šæ€§ä¼°è®¡è¾“å…¥ã€‚
5. **è‡ªåŠ¨åŒ–ç»„ä»¶é€‰æ‹©æœºåˆ¶**ï¼šæ ¹æ®ä¸åŒä»»åŠ¡è‡ªåŠ¨å¯ç”¨/å…³é—­ sign election æˆ– curvature aggregationã€‚

---

## æ€»ç»“
UMTAM æˆåŠŸåœ°å°† **memory-efficient training** ä¸ **principled model merging** ç»Ÿä¸€èµ·æ¥ï¼Œæå‡ºäº†â€œ**è®­ç»ƒå³ä¸ºåˆå¹¶åšå‡†å¤‡**â€çš„æ–°èŒƒå¼ã€‚å®ƒä¸ä»…åœ¨æ€§èƒ½ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œæ›´é‡è¦çš„æ˜¯æ”¹å˜äº†æˆ‘ä»¬çœ‹å¾…ä¼˜åŒ–è½¨è¿¹çš„æ–¹å¼â€”â€”ä¸å†æ˜¯ä¸´æ—¶ä¸­é—´çŠ¶æ€ï¼Œè€Œæ˜¯å®è´µçš„ã€å¯å¤ç”¨çš„çŸ¥è¯†è½½ä½“ã€‚è¿™ä¸€è§†è§’è½¬å˜æœ‰æœ›æ¨åŠ¨æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„å¤šä»»åŠ¡æ¨¡å‹ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚

</details>

---

### 9. [Deep Learning-Based Surrogate Creep Modelling in Inconel 625: A High-Temperature Alloy Study](https://arxiv.org/abs/2512.17477)

**Authors**: Shubham Das, Kaushal Singhania, Amit Sadhu, Suprabhat Das, Arghya Nandi  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.17477v1  

#### Abstract
Time-dependent deformation, particularly creep, in high-temperature alloys such as Inconel 625 is a key factor in the long-term reliability of components used in aerospace and energy systems. Although Inconel 625 shows excellent creep resistance, finite-element creep simulations in tools such as ANS...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Deep Learning-Based Surrogate Creep Modelling in Inconel 625: A High-Temperature Alloy Study*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåŸºäº **Finite Element Method (FEM)** çš„è •å˜ï¼ˆcreepï¼‰æ¨¡æ‹Ÿï¼ˆå¦‚ä½¿ç”¨ ANSYSï¼‰è™½ç„¶ç²¾åº¦é«˜ï¼Œä½†è®¡ç®—æˆæœ¬æé«˜â€”â€”å•æ¬¡ 10,000 å°æ—¶çš„æ¨¡æ‹Ÿéœ€è€—æ—¶ **30â€“40 åˆ†é’Ÿ**ï¼Œä¸¥é‡é™åˆ¶äº†å…¶åœ¨å®æ—¶è®¾è®¡ä¼˜åŒ–ã€ç»“æ„å¥åº·ç›‘æµ‹ç­‰åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

æ­¤å¤–ï¼Œå·²æœ‰æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨å¤„ç†é•¿æœŸè •å˜è¡Œä¸ºæ—¶å­˜åœ¨ä»¥ä¸‹ä¸è¶³ï¼š
- ç¼ºä¹å¯¹é•¿åºåˆ—æ—¶é—´ä¾èµ–æ€§çš„æœ‰æ•ˆå»ºæ¨¡ï¼›
- éš¾ä»¥é‡åŒ–é¢„æµ‹ä¸ç¡®å®šæ€§ï¼ˆuncertainty quantificationï¼‰ï¼›
- å¤šæ•°éªŒè¯åŸºäºçŸ­æœŸæˆ–æœ‰é™æ•°æ®é›†ï¼Œéš¾ä»¥æ¨å¹¿åˆ°å·¥ä¸šçº§é•¿æœŸé¢„æµ‹ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºä¸¤ç§åŸºäºæ·±åº¦å­¦ä¹ çš„ **surrogate modelsï¼ˆä»£ç†æ¨¡å‹ï¼‰**ï¼Œç”¨äºæ›¿ä»£ä¼ ç»Ÿçš„ FEM æ¨¡æ‹Ÿï¼Œå®ç°å¿«é€Ÿã€å‡†ç¡®ä¸”å¯é çš„è •å˜åº”å˜é¢„æµ‹ï¼š

1. **BiLSTM-Transformer**  
   - ç»“åˆ **BiLSTM** æ•æ‰å±€éƒ¨æ—¶é—´åŠ¨æ€ï¼›
   - å¼•å…¥ **Transformer çš„ self-attention æœºåˆ¶** å»ºæ¨¡é•¿ç¨‹æ—¶é—´ä¾èµ–ï¼ˆlong-term temporal dependenciesï¼‰ï¼Œç‰¹åˆ«é€‚ç”¨äºè·¨è¶Š 10,000 å°æ—¶çš„å®Œæ•´è •å˜æ›²çº¿ï¼ˆå« primary, secondary, tertiary é˜¶æ®µï¼‰ï¼›
   - æä¾›é«˜ç²¾åº¦ç¡®å®šæ€§é¢„æµ‹ã€‚

2. **BiLSTM-VAEï¼ˆVariational Autoencoderï¼‰**  
   - èåˆ **BiLSTM ç¼–ç å™¨-è§£ç å™¨ç»“æ„** ä¸ **VAE çš„æ¦‚ç‡ç”Ÿæˆæ¡†æ¶**ï¼›
   - å¯è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒè€Œéå•ä¸€å€¼ï¼Œæ”¯æŒ **ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆuncertainty quantificationï¼‰**ï¼›
   - æ”¯æŒç”Ÿæˆå¤šæ ·åŒ–åˆç†è·¯å¾„ï¼Œå¢å¼ºé²æ£’æ€§å’Œå¯é æ€§ã€‚

> ğŸ’¡ åˆ›æ–°äº®ç‚¹ï¼šé¦–æ¬¡å°† **BiLSTM + Transformer** å’Œ **BiLSTM + VAE** æ¶æ„ç³»ç»Ÿåº”ç”¨äºé«˜æ¸©åˆé‡‘ Inconel 625 çš„å…¨å‘¨æœŸè •å˜å»ºæ¨¡ï¼Œå¹¶å®ç°é«˜æ•ˆæ¨ç†ä¸é£é™©æ„ŸçŸ¥èƒ½åŠ›ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿è¯´æ˜ |
|------|----------|
| **é€Ÿåº¦** | æ¨ç†æ—¶é—´ä» ANSYS çš„ 30â€“40 åˆ†é’Ÿç¼©çŸ­è‡³ **ç§’çº§ç”šè‡³æ¯«ç§’çº§**ï¼ˆæœ€é«˜ä»… 2.17 ç§’ï¼‰ |
| **ç²¾åº¦** | åœ¨è®­ç»ƒå’ŒéªŒè¯é›†ä¸Šå‡æ˜¾è‘—ä¼˜äº baseline LSTMï¼ŒRÂ² æœ€é«˜è¾¾ **0.9729** |
| **åŠŸèƒ½æ‰©å±•æ€§** | BiLSTM-VAE æä¾›ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œé€‚åˆå®‰å…¨å…³é”®å·¥ç¨‹å†³ç­–ï¼›Transformer æ›´æ“…é•¿è¿œæœŸè¶‹åŠ¿æ•æ‰ |
| **å¯æ‰©å±•æ€§** | æ¡†æ¶å¯æ¨å¹¿è‡³å…¶ä»–é«˜æ¸©åˆé‡‘ææ–™ä¸å¤šç‰©ç†åœºè€¦åˆåœºæ™¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†æ¥æºä¸æ„å»ºæ–¹å¼
- **æ•°æ®ç”Ÿæˆå·¥å…·**ï¼šANSYS Mechanicalï¼ˆFEM è½¯ä»¶ï¼‰
- **ç›®æ ‡ææ–™**ï¼šInconel 625ï¼ˆé•åŸºé«˜æ¸©åˆé‡‘ï¼‰
- **åŠ è½½æ¡ä»¶**ï¼š
  - åº”åŠ›èŒƒå›´ï¼š50â€“150 MPaï¼ˆæ­¥é•¿ 25 MPaï¼Œå…± 5 çº§ï¼‰
  - æ¸©åº¦èŒƒå›´ï¼š700â€“1000Â°Cï¼ˆæ­¥é•¿ 100Â°Cï¼Œå…± 4 çº§ï¼‰
  - æ€»è®¡ï¼š**20 ä¸ªç‹¬ç«‹åº”åŠ›-æ¸©åº¦ç»„åˆ**
- **æ¨¡æ‹Ÿæ—¶é•¿**ï¼šæ¯ä¸ªæ¡ˆä¾‹æŒç»­ **10,000 å°æ—¶**ï¼Œè¦†ç›–å®Œæ•´çš„ä¸‰é˜¶æ®µè •å˜è¿‡ç¨‹
- **æœ¬æ„æ¨¡å‹**ï¼šé‡‡ç”¨ **Norton creep law** çš„ time-hardening å½¢å¼è¿›è¡Œ FEM è®¾ç½®ï¼Œå¹¶é€šè¿‡æ–‡çŒ®æ•°æ®æ ¡å‡†å‚æ•°ï¼ˆè§ Table 2ï¼‰

> æ‰€æœ‰ä»¿çœŸæ•°æ®æ„æˆé«˜è´¨é‡ã€é«˜ä¿çœŸçš„ time-series æ•°æ®é›†ï¼Œä½œä¸ºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒåŸºç¡€ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **è¾“å…¥ç‰¹å¾**ï¼š`{Ïƒ, T, t}` â†’ è¾“å‡ºï¼š`Ïµc(t)`ï¼ˆç­‰æ•ˆè •å˜åº”å˜ï¼‰
- **é¢„å¤„ç†æ­¥éª¤**ï¼š
  1. å¯¹åŸå§‹è •å˜åº”å˜ `Îµ` è¿›è¡Œå¯¹æ•°å˜æ¢ï¼š`Îµ* = log(1 + Îµ)`
  2. Min-Max å½’ä¸€åŒ–ï¼ˆæŒ‰è®­ç»ƒé›†ç»Ÿè®¡é‡ï¼‰
  3. æ„é€ å¤šå˜é‡æ—¶é—´åºåˆ—çŸ©é˜µï¼ˆshape: `[B, L=10000, D=3]`ï¼‰
- **æ•°æ®åˆ’åˆ†**ï¼š
  - è®­ç»ƒé›†ï¼š16 æ¡åºåˆ—ï¼ˆä¸åŒ Ïƒ-T ç»„åˆï¼‰
  - éªŒè¯é›†ï¼š4 æ¡åºåˆ—ï¼ˆæ‰‹åŠ¨é€‰æ‹©ä»¥ä¿è¯å‚æ•°ç©ºé—´è¦†ç›–ï¼‰
- **ç¡¬ä»¶å¹³å°**ï¼šGoogle Colab ä¸Šçš„ Tesla T4 GPU
- **è®­ç»ƒé…ç½®**ï¼š
  - Epochs: 100
  - Batch æ›´æ–° + æ—©åœç›‘æ§
  - æœ€ä½³æ¨¡å‹ä¿å­˜ä¾æ®ï¼šæœ€é«˜è®­ç»ƒ RÂ²

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å…¬å¼/ç”¨é€” |
|------|---------|
| **RMSE** | è¡¡é‡é¢„æµ‹è¯¯å·®å¤§å° |
| **MAE** | å¹³å‡ç»å¯¹è¯¯å·®ï¼Œæ›´ç¨³å¥äºå¼‚å¸¸å€¼ |
| **RÂ² (Coefficient of Determination)** | å›å½’æ‹Ÿåˆä¼˜åº¦ï¼Œè¶Šæ¥è¿‘ 1 è¶Šå¥½ |
| **Latency (inference time)** | å•æ¡ 10,000 å°æ—¶åºåˆ—çš„æ¨ç†å»¶è¿Ÿï¼ˆmsï¼‰ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline Model**ï¼šå•å‘ **unidirectional LSTM**ï¼ˆ1 å±‚ï¼Œhidden dim=32ï¼Œdropout=0.1ï¼‰
- å¯¹æ¯”å¯¹è±¡ï¼š
  - BiLSTM-Transformer
  - BiLSTM-VAE
- æ‰€æœ‰æ¨¡å‹å‡åœ¨åŒä¸€è®­ç»ƒ/éªŒè¯é›†ä¸Šæ¯”è¾ƒæ€§èƒ½ä¸å»¶è¿Ÿ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 5ï¼‰

| Model | Val RMSE | Val RÂ² | Val MAE | Latency (ms/seq) |
|-------|----------|--------|---------|------------------|
| **BiLSTM-Transformer** | 0.014128 | **0.960695** | 0.011166 | 2170.14 |
| **BiLSTM-VAE** | **0.011728** | **0.972917** | **0.008234** | **46.81** |
| **Baseline LSTM** | 0.016637 | 0.945494 | 0.013800 | 43.86 |

> æ³¨ï¼šæ‰€æœ‰é¢„æµ‹ç»“æœå·²é€†å˜æ¢å›åŸå§‹å°ºåº¦è¿›è¡Œè¯„ä¼°ã€‚

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç²¾åº¦æ–¹é¢**ï¼š
  - BiLSTM-VAE åœ¨ **æ‰€æœ‰æŒ‡æ ‡ä¸Šå…¨é¢é¢†å…ˆ**ï¼Œå°¤å…¶æ˜¯ RÂ² è¾¾åˆ° **0.9729**ï¼Œæ˜¾è‘—é«˜äº baseline çš„ 0.9455ï¼›
  - BiLSTM-Transformer ç²¾åº¦ç•¥ä½äº VAEï¼Œä½†ä»æ˜æ˜¾ä¼˜äº baselineï¼›
- **æ¨ç†æ•ˆç‡æ–¹é¢**ï¼š
  - BiLSTM-VAE å’Œ baseline LSTM æ¨ç†æå¿«ï¼ˆçº¦ **45 ms**ï¼‰ï¼Œé€‚åˆå®æ—¶éƒ¨ç½²ï¼›
  - BiLSTM-Transformer å›  self-attention è®¡ç®—å¼€é”€è¾ƒå¤§ï¼Œå»¶è¿Ÿä¸º ~2.17 sï¼Œä½†ä»è¿œä¼˜äº ANSYSï¼ˆ30â€“40 minï¼‰ï¼›
- **ç»¼åˆè¡¨ç°**ï¼š
  - BiLSTM-VAE å®ç°äº†â€œé«˜ç²¾åº¦ + ä½å»¶è¿Ÿâ€çš„æœ€ä½³å¹³è¡¡ï¼›
  - BiLSTM-Transformer ç‰¹åˆ«æ“…é•¿æ•æ‰é•¿æœŸæ¼”åŒ–æ¨¡å¼ï¼Œåœ¨å¤–æ¨ä»»åŠ¡ä¸­æ›´å…·æ½œåŠ›ã€‚

### âŒ æ¶ˆèå®éªŒï¼ˆæœªæ˜ç¡®å¼€å±•ï¼‰
æ–‡ä¸­æœªæä¾›æ­£å¼çš„æ¶ˆèç ”ç©¶ï¼ˆablation studyï¼‰ï¼Œä¾‹å¦‚ç§»é™¤ BiLSTM æˆ– Attention æ¨¡å—çš„å½±å“åˆ†æã€‚ä½†é€šè¿‡æ¶æ„è®¾è®¡é€»è¾‘å’Œæ€§èƒ½å·®å¼‚é—´æ¥ä½“ç°äº†å„ç»„ä»¶çš„ä½œç”¨ï¼š
- BiLSTM æå‡äº†å¯¹åŒå‘æ—¶é—´ä¸Šä¸‹æ–‡çš„ç†è§£ï¼›
- Transformer çš„ self-attention æ˜¾è‘—å¢å¼ºäº†é•¿åºåˆ—å»ºæ¨¡èƒ½åŠ›ï¼›
- VAE çš„ latent space è®¾è®¡å¸¦æ¥äº†æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œä¸ç¡®å®šæ€§è¡¨è¾¾ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **æ·±åº¦å­¦ä¹ ä»£ç†æ¨¡å‹å¯æœ‰æ•ˆæ›¿ä»£ FEM æ¨¡æ‹Ÿ**ï¼š
   - åœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶ï¼Œå°†æ¨ç†æ—¶é—´ä» **åˆ†é’Ÿçº§å‹ç¼©è‡³æ¯«ç§’çº§**ï¼Œæé€Ÿæ•°åƒå€ï¼›
   - ä¸º **real-time design optimization** å’Œ **structural health monitoring** æä¾›å¯è¡Œæ–¹æ¡ˆã€‚

2. **BiLSTM-VAE æ˜¯æœ€ä¼˜ç»¼åˆé€‰æ‹©**ï¼š
   - ä¸ä»…é¢„æµ‹æœ€å‡†ç¡®ï¼ˆVal RÂ² = 0.9729ï¼‰ï¼Œè€Œä¸”å…·å¤‡ä¸ç¡®å®šæ€§é‡åŒ–èƒ½åŠ›ï¼›
   - æ¨ç†é€Ÿåº¦å¿«ï¼Œé€‚åˆè¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ã€‚

3. **BiLSTM-Transformer æ“…é•¿é•¿æœŸå»ºæ¨¡**ï¼š
   - è‡ªæ³¨æ„åŠ›æœºåˆ¶èƒ½æœ‰æ•ˆè¯†åˆ«å…³é”®è¿‡æ¸¡é˜¶æ®µï¼ˆå¦‚ secondary â†’ tertiaryï¼‰ï¼›
   - å°½ç®¡æ¨ç†ç¨æ…¢ï¼Œä½†åœ¨éœ€è¦é«˜ä¿çœŸé•¿æœŸé¢„æµ‹çš„åº”ç”¨ä¸­å…·æœ‰ä¼˜åŠ¿ã€‚

4. **æ¨¡å‹æ³›åŒ–èƒ½åŠ›å¼º**ï¼š
   - åœ¨æœªè§è¿‡çš„åº”åŠ›-æ¸©åº¦ç»„åˆä¸‹ä»è¡¨ç°å‡ºè‰²ï¼Œè¡¨æ˜æ¨¡å‹å­¦åˆ°äº†å†…åœ¨ç‰©ç†è§„å¾‹è€Œä¸ä»…æ˜¯è®°å¿†æ•°æ®ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡ä»¿çœŸæ•°æ®**ï¼šå½“å‰æ¨¡å‹è®­ç»ƒæ•°æ®å…¨éƒ¨æ¥è‡ª ANSYS æ¨¡æ‹Ÿï¼Œå°šæœªä¸çœŸå®å®éªŒæ•°æ®ç›´æ¥éªŒè¯ï¼›
- **æœªæ¶µç›–å¤æ‚è½½è·å·¥å†µ**ï¼šç›®å‰ä»…è€ƒè™‘ **uniaxial stress** å’Œæ’æ¸©æ¡ä»¶ï¼Œæœªæ¶‰åŠçƒ­å¾ªç¯æˆ–å¤šè½´åº”åŠ›ï¼›
- **ç¼ºä¹ç‰©ç†è§£é‡Šæ€§**ï¼šå°½ç®¡æ€§èƒ½ä¼˜è¶Šï¼Œä½†ä»æ˜¯â€œé»‘ç®±â€æ¨¡å‹ï¼Œç¼ºä¹åƒä¼ ç»Ÿ constitutive models é‚£æ ·çš„æ˜ç¡®ç‰©ç†æ„ä¹‰ï¼›
- **Transformer æ¨ç†å»¶è¿Ÿè¾ƒé«˜**ï¼šå¯¹äºæç«¯å®æ—¶åœºæ™¯å¯èƒ½ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼•å…¥å¤šé˜¶æ®µå®æµ‹æ•°æ®**ï¼šæ•´åˆåŒ…å«å®Œæ•´ primary å’Œ tertiary é˜¶æ®µçš„çœŸå®è •å˜å®éªŒæ•°æ®ï¼›
2. **èåˆç‰©ç†ä¿¡æ¯**ï¼šå‘å±• **Physics-Informed Neural Networks (PINNs)**ï¼ŒåµŒå…¥ Nortonã€Garofalo æˆ– time-hardening æ–¹ç¨‹ä½œä¸ºçº¦æŸï¼›
3. **å¤šè½´ä¸éç¨³æ€å»ºæ¨¡**ï¼šæ‹“å±•è‡³çƒ­æœºæ¢°ç–²åŠ³ï¼ˆTMFï¼‰ã€å¾ªç¯è½½è·ç­‰æ›´å¤æ‚å·¥å†µï¼›
4. **é›†æˆä¸éƒ¨ç½²**ï¼š
   - æ„å»º **ensemble model** èåˆ VAE ä¸ Transformer çš„ä¼˜åŠ¿ï¼›
   - å¼€å‘è½»é‡åŒ–ç‰ˆæœ¬ç”¨äº **edge computing**ï¼Œå®ç°ç°åœºåœ¨çº¿ç›‘æµ‹ï¼›
5. **ä¸ç¡®å®šæ€§ä¼ æ’­åˆ†æ**ï¼šç ”ç©¶è¾“å…¥å‚æ•°ï¼ˆå¦‚ææ–™å¸¸æ•°ï¼‰ä¸ç¡®å®šæ€§å¦‚ä½•å½±å“æœ€ç»ˆé¢„æµ‹ç½®ä¿¡åŒºé—´ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æˆåŠŸæ„å»ºäº†ä¸¤ä¸ªé«˜æ€§èƒ½æ·±åº¦å­¦ä¹  surrogate modelsï¼ˆBiLSTM-Transformer å’Œ BiLSTM-VAEï¼‰ï¼Œå®ç°äº†å¯¹ Inconel 625 åˆé‡‘è •å˜è¡Œä¸ºçš„**é«˜é€Ÿã€é«˜ç²¾åº¦ã€å¯è§£é‡Šæ€§å¼º**çš„é¢„æµ‹ï¼Œä¸ºé«˜æ¸©åˆé‡‘ç»“æ„çš„è®¾è®¡ä¸å¥åº·ç®¡ç†æä¾›äº†æ–°ä¸€ä»£æ™ºèƒ½åŒ–å·¥å…·ã€‚

</details>

---

### 10. [NetworkFF: Unified Layer Optimization in Forward-Only Neural Networks](https://arxiv.org/abs/2512.17531)

**Authors**: Salar Beigzad  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.17531v1  

#### Abstract
The Forward-Forward algorithm eliminates backpropagation's memory constraints and biological implausibility through dual forward passes with positive and negative data. However, conventional implementations suffer from critical inter-layer isolation, where layers optimize goodness functions independ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*NetworkFF: Unified Layer Optimization in Forward-Only Neural Networks*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åŸå§‹çš„ **Forward-Forward (FF)** ç®—æ³•è™½ç„¶è§£å†³äº†ä¼ ç»Ÿ **backpropagation** çš„å†…å­˜å¼€é”€å¤§å’Œç”Ÿç‰©ä¸å¯è¡Œæ€§ç­‰é—®é¢˜ï¼Œä½†å­˜åœ¨ä¸€ä¸ªå…³é”®ç¼ºé™·ï¼š**å±‚é—´éš”ç¦»ï¼ˆinter-layer isolationï¼‰**ã€‚å„å±‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç‹¬ç«‹ä¼˜åŒ–å„è‡ªçš„â€œgoodnessâ€å‡½æ•°ï¼Œç¼ºä¹è·¨å±‚åä½œæœºåˆ¶ï¼Œå¯¼è‡´è¡¨å¾åè°ƒèƒ½åŠ›å·®ã€æ”¶æ•›æ•ˆç‡ä½ï¼Œå°¤å…¶åœ¨æ·±å±‚ç½‘ç»œä¸­è¡¨ç°å—é™ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **Collaborative Forward-Forward (CFF)** å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥**å±‚é—´åä½œæœºåˆ¶**æ‰©å±•åŸå§‹ FF ç®—æ³•ï¼Œä¸»è¦åŒ…æ‹¬ä¸¤ç§å˜ä½“ï¼š

- **Fixed CFF (F-CFF)**ï¼šä½¿ç”¨å›ºå®šçš„åä½œå‚æ•° Î³ æ§åˆ¶å±‚é—´è€¦åˆå¼ºåº¦ï¼Œå®ç°ç¨³å®šçš„ä¿¡æ¯å…±äº«ã€‚
- **Adaptive CFF (A-CFF)**ï¼šå¼•å…¥å¯å­¦ä¹ çš„åä½œå‚æ•°ï¼Œå…è®¸æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´å±‚é—´å½±å“æƒé‡ï¼Œæå‡ååŒä¼˜åŒ–èƒ½åŠ›ã€‚

å…¶æ ¸å¿ƒæ€æƒ³æ˜¯æ„å»º**åä½œå‹ goodness å‡½æ•°**ï¼š
$$
G_{\text{collab}}^{(l)}(x) = G_l(x) + \gamma \sum_{k \neq l} \omega_k G_k(x)
$$
è¯¥å‡½æ•°æ•´åˆäº†å…¶ä»–å±‚çš„ goodness è¾“å‡ºï¼Œä½¿æ¯å±‚èƒ½æ„ŸçŸ¥å…¨å±€å­¦ä¹ çŠ¶æ€ï¼Œä»è€Œå®ç°ç»Ÿä¸€çš„å±‚ä¼˜åŒ–ç›®æ ‡ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **ä¿æŒ FF æ ¸å¿ƒä¼˜åŠ¿**ï¼šæ— éœ€åå‘ä¼ æ’­ï¼Œä¿ç•™å‰å‘è®¡ç®—èŒƒå¼ï¼Œå…·æœ‰ä½å†…å­˜å ç”¨ã€é«˜ç”Ÿç‰©å¯è§£é‡Šæ€§å’Œé»‘ç›’å…¼å®¹æ€§ã€‚
- **å¢å¼ºå­¦ä¹ æœ‰æ•ˆæ€§**ï¼šé€šè¿‡å±‚é—´åä½œæ˜¾è‘—æå‡æ¨¡å‹æ”¶æ•›é€Ÿåº¦ä¸æœ€ç»ˆæ€§èƒ½ã€‚
- **çµæ´»æ¶æ„è®¾è®¡**ï¼šæ”¯æŒå›ºå®šä¸è‡ªé€‚åº”åä½œæœºåˆ¶ï¼Œä¾¿äºåœ¨ä¸åŒåœºæ™¯ä¸‹éƒ¨ç½²ã€‚
- **é€‚ç”¨äºèµ„æºå—é™ç³»ç»Ÿ**ï¼šä¸º **neuromorphic computing** å’Œè¾¹ç¼˜è®¾å¤‡ä¸Šçš„é«˜æ•ˆ AI æä¾›å¯è¡Œè·¯å¾„ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
- **MNIST**ï¼šæ‰‹å†™æ•°å­—è¯†åˆ«ä»»åŠ¡ï¼Œä½œä¸ºåŸºå‡†æµ‹è¯•ã€‚
- **Fashion-MNIST**ï¼šæœè£…å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œè§†è§‰å¤æ‚åº¦æ›´é«˜ï¼Œæ›´å…·æŒ‘æˆ˜æ€§ã€‚

ä¸¤è€…å‡ä¸º $28 \times 28$ ç°åº¦å›¾ï¼Œå±•å¹³ä¸º 784 ç»´è¾“å…¥å‘é‡ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **ç½‘ç»œç»“æ„**ï¼šInput (784) â†’ Hidden Layer 1 (500 ReLU) â†’ Hidden Layer 2 (500 ReLU) â†’ Output
- **æ ‡ç­¾åµŒå…¥ï¼ˆLabel Embeddingï¼‰**ï¼šæ²¿ç”¨ Hinton çš„åŸå§‹æ–¹æ¡ˆï¼Œåœ¨è¾“å…¥å›¾åƒå‰ 10 ä¸ªåƒç´ ç¼–ç ç±»åˆ«ä¿¡æ¯ã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - æ¯å±‚è®­ç»ƒ 1000 epochs
  - æ‰¹å¤§å°ï¼šå…¨æ‰¹é‡ï¼ˆ50,000 æ ·æœ¬ï¼‰
  - ä¼˜åŒ–å™¨ï¼šAdamï¼ˆåŸºç¡€å­¦ä¹ ç‡ 0.03ï¼‰
  - A-CFF åä½œå‚æ•°å­¦ä¹ ç‡ï¼š0.01
  - Goodness é˜ˆå€¼ $\theta = 2.0$
  - å±‚å½’ä¸€åŒ–ï¼ˆpost-activationï¼‰

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
- åˆ†ç±»å‡†ç¡®ç‡ï¼ˆTraining/Test Accuracyï¼‰
- æ”¶æ•›é€Ÿåº¦ä¸è®­ç»ƒåŠ¨æ€åˆ†æ
- åä½œå‚æ•°æ¼”åŒ–è½¨è¿¹ï¼ˆä»… A-CFFï¼‰
- ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒï¼ˆpaired t-test, Cohenâ€™s dï¼‰
- æ³›åŒ–å·®è·ï¼ˆGeneralization Gapï¼‰
- è®¡ç®—æ•ˆç‡ï¼ˆè®­ç»ƒæ—¶é—´ã€å†…å­˜æ¶ˆè€—ï¼‰

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **Original FF** | åŸå§‹ Forward-Forward ç®—æ³•ï¼Œæ— å±‚é—´åä½œ |
| **F-CFF** | å›ºå®šåä½œå‚æ•°ï¼ˆ$\gamma=1.0$ï¼‰çš„ CFF ç‰ˆæœ¬ |
| **A-CFF** | å¯å­¦ä¹ åä½œå‚æ•°çš„è‡ªé€‚åº” CFF ç‰ˆæœ¬ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### è¡¨æ ¼ï¼šè·¨æ•°æ®é›†æ€§èƒ½å¯¹æ¯”ï¼ˆTest Accuracyï¼‰

| Dataset / Model | Original FF | F-CFF | A-CFF | Improvement (vs Baseline) |
|------------------|------------|--------|--------|----------------------------|
| **MNIST**        | 92.0%      | 92.6%  | 93.8%  | +0.6% (F-CFF), **+1.8%** (A-CFF) |
| **Fashion-MNIST**| 81.0%      | 81.8%  | 83.0%  | +0.8% (F-CFF), **+2.0%** (A-CFF) |

> âœ… æ‰€æœ‰æ”¹è¿›å‡è¶…è¿‡å…¸å‹ FF å®éªŒæ–¹å·®ï¼Œå…·æœ‰å®é™…æ„ä¹‰ã€‚

### ğŸ”¬ ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **A-CFF åœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šå‡å–å¾—æœ€é«˜ç²¾åº¦**ï¼Œä¸”åœ¨æ›´å¤æ‚çš„ Fashion-MNIST ä¸Šç›¸å¯¹æå‡æ›´å¤§ï¼ˆ+2.0%ï¼‰ï¼Œè¯´æ˜å…¶å¯¹å›°éš¾ä»»åŠ¡æ›´å…·é²æ£’æ€§ã€‚
- **F-CFF æä¾›ç¨³å®šçš„å°å¹…å¢ç›Š**ï¼ˆ+0.6â€“0.8%ï¼‰ï¼ŒéªŒè¯äº†å³ä½¿ç®€å•åä½œä¹Ÿèƒ½å¸¦æ¥æ”¶ç›Šã€‚
- **è®­ç»ƒåŠ¨æ€æ˜¾ç¤ºæ›´å¼ºæ”¶æ•›æ€§**ï¼š
  - å›¾2ï¼ˆMNISTï¼‰å’Œå›¾3ï¼ˆFashion-MNISTï¼‰ä¸­çš„ log-scale æ›²çº¿è¡¨æ˜ï¼ŒA-CFF åœ¨æœ€åé˜¶æ®µä»æŒç»­æå‡ï¼Œè€ŒåŸå§‹ FF å·²è¶‹äºé¥±å’Œã€‚
  - A-CFF è¾¾åˆ°æ›´é«˜çš„å³°å€¼ log-scale accuracyï¼ˆMNIST: ~4.555ï¼›Fashion-MNIST: ~4.4345ï¼‰ã€‚

### ğŸ” æ¶ˆèå®éªŒä¸åˆ†æï¼ˆéšå«äºå®éªŒè®¾è®¡ï¼‰
å°½ç®¡æœªæ˜ç¡®æ ‡æ³¨â€œablation studyâ€ï¼Œä½†ä»¥ä¸‹å¯¹æ¯”æ„æˆæœ‰æ•ˆæ¶ˆèåˆ†æï¼š
- **æ˜¯å¦å¯ç”¨åä½œæœºåˆ¶**ï¼šOriginal FF vs F-CFF â†’ éªŒè¯åä½œæœ¬èº«çš„æœ‰æ•ˆæ€§ã€‚
- **åä½œæ–¹å¼çš„å½±å“**ï¼šF-CFF vs A-CFF â†’ æ˜¾ç¤ºå¯å­¦ä¹ å‚æ•°ä¼˜äºå›ºå®šå‚æ•°ï¼Œè¯æ˜åŠ¨æ€åä½œæ›´å…·æ½œåŠ›ã€‚
- **å‚æ•°æ¼”åŒ–å¯è§†åŒ–**ï¼šA-CFF ä¸­åä½œç³»æ•°éšè®­ç»ƒæ¼”åŒ–çš„è¶‹åŠ¿æ­ç¤ºäº†æ¨¡å‹è‡ªåŠ¨è°ƒèŠ‚å±‚é—´ä¾èµ–çš„èƒ½åŠ›ã€‚

æ­¤å¤–ï¼Œç»Ÿè®¡æ£€éªŒï¼ˆpaired t-testï¼‰ç¡®è®¤äº†æ‰€æœ‰åä½œå˜ä½“ä¸åŸå§‹ FF ä¹‹é—´çš„æ€§èƒ½å·®å¼‚å…·æœ‰æ˜¾è‘—æ€§ï¼ˆp < 0.05ï¼‰ï¼Œæ•ˆåº”é‡ï¼ˆCohenâ€™s dï¼‰ä¹Ÿè¾¾åˆ°ä¸­ç­‰ä»¥ä¸Šæ°´å¹³ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å±‚é—´åä½œæ˜¾è‘—æå‡ FF æ€§èƒ½**ï¼šé¦–æ¬¡å°†åä½œå­¦ä¹ å¼•å…¥ Forward-Forward æ¡†æ¶ï¼ŒæˆåŠŸæ‰“ç ´å±‚é—´å­¤ç«‹çŠ¶æ€ï¼Œå®ç°æ›´åè°ƒçš„ç‰¹å¾å­¦ä¹ ã€‚
2. **è‡ªé€‚åº”åä½œä¼˜äºå›ºå®šåä½œ**ï¼šA-CFF ä¸ä»…æ€§èƒ½æœ€ä½³ï¼Œè¿˜èƒ½é€šè¿‡å‚æ•°æ¼”åŒ–åæ˜ å­¦ä¹ è¿‡ç¨‹ä¸­çš„åŠ¨æ€äº¤äº’æ¨¡å¼ã€‚
3. **å®Œå…¨ä¿ç•™ FF çš„æ ¸å¿ƒä¼˜åŠ¿**ï¼šæ•´ä¸ª CFF æ¡†æ¶ä»åŸºäºçº¯å‰å‘æ“ä½œï¼Œä¸å¢åŠ é¢å¤–å†…å­˜è´Ÿæ‹…ï¼Œç»´æŒäº†ç”Ÿç‰©åˆç†æ€§å’Œè¾¹ç¼˜éƒ¨ç½²å‹å¥½æ€§ã€‚
4. **å…·å¤‡å¹¿æ³›é€‚ç”¨å‰æ™¯**ï¼šå°¤å…¶é€‚åˆ **neuromorphic computing** å’Œèƒ½æºå—é™ç¯å¢ƒä¸‹çš„ AI ç³»ç»Ÿã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å½“å‰å®éªŒé›†ä¸­åœ¨æµ…å±‚ MLP æ¶æ„ï¼Œå°šæœªéªŒè¯åœ¨æ›´æ·±æˆ–å·ç§¯ç»“æ„ä¸­çš„æ‰©å±•èƒ½åŠ›ã€‚
- åä½œæœºåˆ¶å¯èƒ½å¼•å…¥é¢å¤–è¶…å‚æ•°ï¼ˆå¦‚åˆå§‹ Î³ã€åä½œå­¦ä¹ ç‡ï¼‰ï¼Œéœ€è¿›ä¸€æ­¥è‡ªåŠ¨åŒ–è°ƒå‚ç­–ç•¥ã€‚
- è™½ç„¶ä¿æŒç”Ÿç‰©åˆç†æ€§ï¼Œä½†çœŸå®å¤§è„‘æ˜¯å¦å­˜åœ¨ç±»ä¼¼â€œgoodness broadcastâ€çš„æœºåˆ¶å°šæ— ç›´æ¥è¯æ®ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å°† CFF æ‰©å±•è‡³ CNNã€Transformer ç­‰ç°ä»£æ¶æ„ã€‚
- æ¢ç´¢ç¨€ç–åä½œè¿æ¥ã€æ³¨æ„åŠ›å¼åŠ æƒç­‰æ›´é«˜æ•ˆçš„åä½œå½¢å¼ã€‚
- ç»“åˆ predictive coding æˆ– dendritic computation æ¨¡å‹æ·±åŒ–ç”Ÿç‰©å¯è§£é‡Šæ€§ã€‚
- åœ¨çœŸå®ç±»è„‘èŠ¯ç‰‡ï¼ˆå¦‚ Loihiã€SpiNNakerï¼‰ä¸Šéƒ¨ç½²å¹¶éªŒè¯èƒ½è€—æ•ˆç›Šã€‚

---

## âœ… æ€»ç»“
æœ¬è®ºæ–‡æå‡ºçš„ **Collaborative Forward-Forward (CFF)** æ˜¯å¯¹åŸå§‹ FF ç®—æ³•çš„é‡è¦å¢å¼ºï¼Œé€šè¿‡å¼•å…¥å±‚é—´åä½œæœºåˆ¶ï¼Œåœ¨ä¸ç‰ºç‰²å…¶å†…å­˜æ•ˆç‡å’Œç”Ÿç‰©åˆç†æ€§çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†å­¦ä¹ æ•ˆæœã€‚å®éªŒè¯æ˜å…¶åœ¨ MNIST å’Œ Fashion-MNIST ä¸Šå‡ä¼˜äºåŸºçº¿ï¼Œå°¤å…¶æ˜¯ **A-CFF å®ç°äº†é«˜è¾¾ +2.0% çš„å‡†ç¡®ç‡æå‡**ï¼Œä¸ºæ„å»ºé«˜æ•ˆã€å¯è§£é‡Šã€ç±»è„‘çš„ç¥ç»ç½‘ç»œæä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 11. [PAACE: A Plan-Aware Automated Agent Context Engineering Framework](https://arxiv.org/abs/2512.16970)

**Authors**: Kamer Ali Yuksel  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.16970v1  

#### Abstract
Large Language Model (LLM) agents are increasingly deployed in complex, multi-step workflows involving planning, tool use, reflection, and interaction with external knowledge systems. These workflows generate rapidly expanding contexts that must be curated, transformed, and compressed to maintain fi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# PAACE: A Plan-Aware Automated Agent Context Engineering Framework è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†åœ¨æ‰§è¡Œå¤æ‚ã€å¤šæ­¥éª¤ä»»åŠ¡æ—¶ä¼šç§¯ç´¯å¤§é‡ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚ç³»ç»ŸæŒ‡ä»¤ã€æ¨ç†é“¾ã€å·¥å…·è°ƒç”¨ç»“æœã€æ£€ç´¢å†…å®¹ç­‰ï¼‰ã€‚éšç€ä»»åŠ¡é•¿åº¦å¢åŠ ï¼Œè¿™äº›ä¸Šä¸‹æ–‡å˜å¾—å†—é•¿ã€å˜ˆæ‚ä¸”ä½æ•ˆï¼Œå¯¼è‡´ï¼š
- **æ³¨æ„åŠ›ç¨€é‡Š**ï¼ˆattention dilutionï¼‰
- **ä¸Šä¸‹æ–‡è…åŒ–**ï¼ˆcontext rotï¼‰
- æ¨ç†è´¨é‡ä¸‹é™
- æ¨ç†æˆæœ¬ä¸Šå‡ï¼ˆå°¤å…¶æ˜¯é•¿çª—å£æ¨¡å‹çš„äºŒæ¬¡è®¡ç®—å¼€é”€ï¼‰

ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚æ‘˜è¦ã€æ£€ç´¢å¢å¼ºç”Ÿæˆ RAG æˆ–ç®€å•æˆªæ–­ï¼‰æ— æ³•æœ‰æ•ˆä¿ç•™å¤šæ­¥ä»»åŠ¡ä¸­çš„**è®¡åˆ’ç»“æ„ä¾èµ–å…³ç³»**å’Œ**æœªæ¥ä»»åŠ¡ç›¸å…³æ€§**ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šPAACE æ¡†æ¶
PAACEï¼ˆ**Plan-Aware Automated Context Engineering**ï¼‰æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ä¸Šä¸‹æ–‡å·¥ç¨‹æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å»ºæ¨¡ä»»åŠ¡è§„åˆ’ç»“æ„æ¥ä¼˜åŒ– LLM ä»£ç†çš„åŠ¨æ€ä¸Šä¸‹æ–‡çŠ¶æ€ã€‚

#### æ ¸å¿ƒç»„ä»¶ï¼š
1. **PAACE-Syn**  
   - å¤§è§„æ¨¡åˆæˆæ•°æ®ç”Ÿæˆå™¨ï¼Œæ¨¡æ‹Ÿå¸¦å™ªå£°çš„é•¿å‘¨æœŸä»£ç†å·¥ä½œæµï¼Œå¹¶æ ‡æ³¨æ¯ä¸€æ­¥çš„å‹ç¼©ç›‘ç£ä¿¡å·ã€‚
   - åŒ…å«çº¦ **1.2M åˆæˆå·¥ä½œæµ**ï¼ˆå…± ~9.5B tokensï¼‰ï¼Œæ¶µç›–æ–‡æ¡£å¤„ç†ã€ç½‘é¡µå¯¼èˆªã€å¤šè·³é—®ç­”ç­‰åœºæ™¯ã€‚
   - è¾“å‡ºåŒ…å«å®Œæ•´ä¸Šä¸‹æ–‡ä¸å‹ç¼©åä¸Šä¸‹æ–‡çš„é…å¯¹è½¨è¿¹ï¼Œç”¨äºè®­ç»ƒå‹ç¼©ç­–ç•¥ã€‚

2. **PAACE-FT**  
   - åŸºäºæ•™å¸ˆ-å­¦ç”Ÿè’¸é¦èŒƒå¼æ„å»ºçš„ä¸€ç³»åˆ—è½»é‡çº§ã€**è®¡åˆ’æ„ŸçŸ¥å‹ä¸Šä¸‹æ–‡å‹ç¼©å™¨**ã€‚
   - æ•™å¸ˆæ¨¡å‹ï¼ˆå¦‚ GPT-OSS-120Bï¼‰åœ¨ PAACE-Syn ä¸Šè¿›è¡Œæ¼”åŒ–å­¦ä¹ ï¼Œç”Ÿæˆé«˜è´¨é‡å‹ç¼©ç¤ºä¾‹ã€‚
   - å­¦ç”Ÿæ¨¡å‹ï¼ˆå¦‚ Qwen3-4B-Instructï¼‰é€šè¿‡ç›‘ç£å­¦ä¹ æ¨¡ä»¿æ•™å¸ˆè¡Œä¸ºï¼Œå®ç°é«˜æ•ˆéƒ¨ç½²ã€‚

#### åˆ›æ–°æ€è·¯ï¼š
- **å¼•å…¥â€œnext-k-task relevanceâ€å»ºæ¨¡**ï¼šå‹ç¼©æ—¶ä¸ä»…è€ƒè™‘å½“å‰ä»»åŠ¡ï¼Œè¿˜æ˜¾å¼å»ºæ¨¡æ¥ä¸‹æ¥ k æ­¥çš„ä»»åŠ¡éœ€æ±‚ï¼Œç¡®ä¿å…³é”®ä¸­é—´çŠ¶æ€ä¸è¢«è¯¯åˆ ã€‚
- **è”åˆä¼˜åŒ–ä¸Šä¸‹æ–‡ä¸æŒ‡ä»¤**ï¼šæ”¯æŒé‡å†™ã€ç²¾ç‚¼æŒ‡ä»¤ä»¥ä¿æŒä¸è®¡åˆ’ä¸€è‡´æ€§ï¼Œé˜²æ­¢â€œæŒ‡ä»¤æ¼‚ç§»â€ï¼ˆinstruction driftï¼‰ã€‚
- **ç«¯åˆ°ç«¯å¯å­¦ä¹ çš„ä¸Šä¸‹æ–‡å¡‘é€ ç­–ç•¥**ï¼šå°†ä¸Šä¸‹æ–‡å‹ç¼©è§†ä¸ºä¸€ä¸ªåŸºäºç»“æœä¿çœŸåº¦çš„å­¦ä¹ ç­–ç•¥ï¼Œè€Œéå¯å‘å¼ç¼–è¾‘ã€‚
- **ç»“æ„åŒ–ä¸Šä¸‹æ–‡åˆ†è§£**ï¼šéšå¼å»ºæ¨¡ä¸Šä¸‹æ–‡çš„åŠŸèƒ½è§’è‰²ï¼ˆè¡ŒåŠ¨æ€§ã€ç»“æ„æ€§ã€å¼•ç”¨æ€§ã€è®ºè¯æ€§ï¼‰ï¼Œæå‡å‹ç¼©è¯­ä¹‰ä¿çœŸåº¦ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | PAACE æ”¹è¿› |
|------|--------|-----------|
| **LLMLingua / LLMLingua-2** | ä»…å…³æ³¨å•è½®æŸ¥è¯¢ç›¸å…³æ€§ï¼Œå¿½ç•¥å¤šæ­¥ä¾èµ– | æ˜¾å¼å»ºæ¨¡ next-k ä»»åŠ¡ä¾èµ– |
| **Self-RAG** | é€‚ç”¨äº QA åœºæ™¯ï¼Œç¼ºä¹è®¡åˆ’ç»“æ„å»ºæ¨¡ | æ”¯æŒè·¨ä»»åŠ¡å› æœé“¾ä¿ç•™ |
| **Provence** | äºŒå€¼å‰ªæï¼ˆkeep/dropï¼‰ï¼Œæ— é‡å†™èƒ½åŠ› | æ”¯æŒé‡å†™ã€é‡æ„ã€å‹ç¼©ä¸€ä½“åŒ–æ“ä½œ |
| **ACon (Yu et al., 2025b)** | ä»…ä¼˜åŒ–ä¸‹ä¸€ä»»åŠ¡ï¼Œä¸æ”¯æŒæŒ‡ä»¤ååŒä¼˜åŒ– | æ”¯æŒå¤šæ­¥å‰ç»ä¸æŒ‡ä»¤å…±æ¼”åŒ– |
| **FIFO / Retrieval-based selection** | å¿½è§†é•¿æœŸä¾èµ–ï¼Œæ˜“ä¸¢å¤±å…³é”®ä¸­é—´çŠ¶æ€ | ä¿ç•™å…¨å±€è®¡åˆ’ç»“æ„ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šPAACE æ˜¯é¦–ä¸ªå°†**è®¡åˆ’ç»“æ„åˆ†æ**ã€**å¤šæ­¥ä»»åŠ¡ç›¸å…³æ€§å»ºæ¨¡**ã€**æŒ‡ä»¤ååŒä¼˜åŒ–**å’Œ**å‡½æ•°ä¿æŒå‹ç¼©**æ•´åˆä¸ºç»Ÿä¸€æ¡†æ¶çš„å·¥ä½œã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
1. **AppWorld**ï¼ˆTrivedi et al., 2024ï¼‰  
   - å¤šåº”ç”¨äº¤äº’ä»»åŠ¡ï¼ˆå¦‚é‚®ä»¶ã€æ—¥å†ã€æµè§ˆå™¨è”åŠ¨ï¼‰
   - è§‚æµ‹å¼‚æ„æ€§å¼ºï¼Œéœ€è·¨åº”ç”¨çŠ¶æ€è¿½è¸ª
2. **OfficeBench**ï¼ˆWang et al., 2024ï¼‰  
   - é¢å‘åŠå…¬è‡ªåŠ¨åŒ–çš„æ–‡æ¡£å¤„ç†ä»»åŠ¡é“¾ï¼ˆPDFã€Excelã€Word ç­‰ï¼‰
   - å¼ºè°ƒç»“æ„åŒ–æ“ä½œä¸æ–‡ä»¶å¼•ç”¨
3. **8-Objective QA**ï¼ˆZhou et al., 2025ï¼‰  
   - å¤šè·³é—®ç­”ä»»åŠ¡ï¼Œç»“åˆå·¥å…·æœç´¢ä¸è¯æ®èšåˆ
   - è¦æ±‚é•¿æœŸè®°å¿†ä¸ä¿¡æ¯è¿½æº¯

---

### âš™ï¸ å®éªŒè®¾ç½®
- **ä¸»å¹²æ¨¡å‹ä¸€è‡´**ï¼šæ‰€æœ‰æ–¹æ³•ä½¿ç”¨ç›¸åŒçš„ LLMã€è§„åˆ’å™¨ã€å·¥å…·æ¥å£å’Œæ¨ç†é…ç½®ã€‚
- **å”¯ä¸€å˜é‡**ï¼šä¸Šä¸‹æ–‡ç®¡ç†ç­–ç•¥ä¸åŒã€‚
- **æ•™å¸ˆæ¨¡å‹**ï¼šOpenAI GPT-OSS-120Bï¼ˆ65,536 token çª—å£ï¼‰
- **å­¦ç”Ÿæ¨¡å‹**ï¼šQwen3-4B-Instructï¼ˆè’¸é¦ç›®æ ‡ï¼‰
- **å‹ç¼©é¢‘ç‡**ï¼šæ¯ä¸€æ­¥å‡è°ƒç”¨å‹ç¼©å™¨æ›´æ–°ä¸Šä¸‹æ–‡
- **åˆæˆæ•°æ®æ¥æº**ï¼šPAACE-Syn å®Œå…¨ç¦»çº¿ç”Ÿæˆï¼Œä¸ä¾èµ–äººå·¥æ ‡æ³¨

---

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Acc / EM / F1** | å„åŸºå‡†å®šä¹‰çš„ä»»åŠ¡å‡†ç¡®ç‡ã€ç²¾ç¡®åŒ¹é…ç‡ã€F1 åˆ†æ•° |
| **Peak** | è½¨è¿¹ä¸­æœ€å¤§è¾“å…¥ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆå•ä½ï¼šåƒ tokensï¼‰ |
| **Dependency** | ç´¯ç§¯æ³¨æ„åŠ›è´Ÿè½½ï¼š$\sum_t |C_t|$ï¼Œè¿‘ä¼¼æ€»è®¡ç®—æˆæœ¬ï¼ˆå•ä½ï¼šç™¾ä¸‡ tokensï¼‰ |
| **Steps** | å®Œæˆä»»åŠ¡æ‰€éœ€æ­¥æ•° |
| **Compression Ratio** | $|C_{\text{compressed}}| / |C_{\text{full}}|$ |

> æ³¨ï¼šæ‰€æœ‰æ–¹æ³•åœ¨åŒä¸€ backbone ä¸‹è¿è¡Œï¼Œå› æ­¤ Dependency å¯ç›´æ¥æ¯”è¾ƒã€‚

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **No Compression** | ä¿ç•™å…¨éƒ¨å†å² |
| **FIFO** | ä»…ä¿ç•™æœ€è¿‘ k è½®å¯¹è¯ |
| **Retrieval** | åŸºäºåµŒå…¥é€‰æ‹©ç›¸å…³å†å²ç‰‡æ®µ |
| **LLMLingua** | æå–å¼ä¸Šä¸‹æ–‡å‹ç¼© |
| **Prompting** | ä½¿ç”¨æç¤ºè¯æŒ‡å¯¼æ‘˜è¦ï¼ˆå¯å‘å¼ï¼‰ |
| **ACON UT / UTCO** | å½“å‰æœ€ä¼˜ä¸Šä¸‹æ–‡ä¼˜åŒ–æ–¹æ³•ï¼ˆYu et al., 2025bï¼‰ï¼Œåˆ†åˆ«è¡¨ç¤ºæ— /æœ‰æŒ‡ä»¤ä¼˜åŒ–ç‰ˆæœ¬ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### è¡¨ 1ï¼šAppWorld ç»“æœ
| Method | Accâ†‘ | Stepsâ†“ | Peakâ†“ | Dependencyâ†“ |
|--------|------|--------|-------|-------------|
| No Compression | 56.00 | 16.14 | 9.93 | 5.96 |
| FIFO | 45.80 | 28.48 | 6.73 | 5.69 |
| LLMLingua | 39.30 | 24.42 | 7.50 | 6.37 |
| ACON UTCO | 56.50 | 22.82 | 7.33 | 4.69 |
| **PAACE (ours)** | **59.00** | **19.20** | **6.23** | **3.75** |

> âœ… PAACE åœ¨å‡†ç¡®æ€§ä¸Šè¶…è¶Šæ‰€æœ‰åŸºçº¿ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½å³°å€¼ä¸Šä¸‹æ–‡å’Œç´¯è®¡ä¾èµ–ã€‚

---

#### è¡¨ 2ï¼šOfficeBench ç»“æœ
| Method | Accâ†‘ | Stepsâ†“ | Peakâ†“ | Dependencyâ†“ |
|--------|------|--------|-------|-------------|
| No Compression | 76.84 | 11.52 | 7.27 | 4.43 |
| LLMLingua | 70.53 | 10.89 | 4.65 | 1.85 |
| ACON UTCO | 72.63 | 11.54 | 4.54 | 1.91 |
| **PAACE (ours)** | **78.10** | **10.48** | **4.29** | **1.64** |

> âœ… å‡†ç¡®ç‡æœ€é«˜ï¼Œä¸”ä¸Šä¸‹æ–‡æ¶ˆè€—æœ€ä½ã€‚

---

#### è¡¨ 3ï¼š8-Objective QA ç»“æœ
| Method | EMâ†‘ | F1â†‘ | Stepsâ†“ | Peakâ†“ | Dependencyâ†“ |
|--------|-----|-----|--------|-------|-------------|
| No Compression | 0.366 | 0.488 | 15.78 | 10.35 | 3.32 |
| LLMLingua | 0.363 | 0.481 | 17.68 | 5.68 | 2.24 |
| ACON UTCO | 0.335 | 0.458 | 17.79 | 4.65 | 1.50 |
| **PAACE (ours)** | **0.402** | **0.512** | **16.86** | **4.41** | **1.41** |

> âœ… åœ¨å¤šè·³é—®ç­”ä¸­ä¹Ÿå–å¾—æœ€ä½³è¡¨ç°ï¼Œå°¤å…¶åœ¨ F1 å’Œ EM ä¸Šé¢†å…ˆæ˜æ˜¾ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆTable 4ï¼‰

| Benchmark | k | Acc/EMâ†‘ | Peakâ†“ | Dependencyâ†“ |
|----------|----|---------|--------|------------|
| AppWorld | 1 | 56.5 | 6.05 | 3.95 |
|          | 2 | **59.0** | 6.23 | **3.75** |
|          | 3 | 58.6 | 6.48 | 3.82 |
| OfficeBench | 1 | 76.3 | 4.15 | 1.72 |
|             | 2 | **78.1** | 4.29 | **1.64** |
|             | 3 | 77.6 | 4.51 | 1.69 |
| 8-Objective QA | 1 | 0.381 | 4.18 | 1.36 |
|                | 2 | 0.394 | 4.30 | 1.39 |
|                | 3 | **0.402** | **4.41** | **1.41** |

> ğŸ” å‘ç°ï¼š
- å·¥å…·å¯†é›†å‹ä»»åŠ¡ï¼ˆAppWorld, OfficeBenchï¼‰ï¼š`k=2` æœ€ä¼˜
- å¤šè·³ QA ä»»åŠ¡ï¼šéœ€è¦æ›´é•¿è§†é‡ `k=3`
- æ›´å¤§ `k` å¯¼è‡´å‹ç¼©éš¾åº¦ä¸Šå‡ï¼Œæ”¶ç›Šé€’å‡

æ­¤å¤–ï¼Œç¦ç”¨æŒ‡ä»¤é‡å†™çš„å˜ä½“ä¼šå¯¼è‡´å¤±è´¥ç‡æ˜¾è‘—ä¸Šå‡ï¼Œè¯´æ˜**éšå¼æŒ‡ä»¤é‡å¡‘**å¯¹é²æ£’æ€§è‡³å…³é‡è¦ã€‚

---

### ğŸ’¡ è’¸é¦æ•ˆæœï¼ˆPAACE-FTï¼‰
- PAACE-FTï¼ˆå­¦ç”Ÿæ¨¡å‹ï¼‰ä¿ç•™äº†æ•™å¸ˆæ¨¡å‹ **97â€“98% çš„æ€§èƒ½**
- æ¨ç†æˆæœ¬é™ä½ **è¶…è¿‡ä¸€ä¸ªæ•°é‡çº§**
- æ¯æ­¥å»¶è¿Ÿå¢åŠ  <8%ï¼Œä½†æ€» token æ•°å‡å°‘ 35â€“60%
- å¯åœ¨è¾¹ç¼˜è®¾å¤‡æˆ–ä½æˆæœ¬æœåŠ¡ä¸­éƒ¨ç½²

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **è®¡åˆ’æ„ŸçŸ¥å‹ç¼©ä¼˜äºä¼ ç»Ÿæ–¹æ³•**  
   æ˜¾å¼å»ºæ¨¡ next-k ä»»åŠ¡ä¾èµ–èƒ½æ˜¾è‘—æå‡å¤šæ­¥ä»»åŠ¡æˆåŠŸç‡ï¼Œé¿å…å…³é”®ä¿¡æ¯ä¸¢å¤±ã€‚

2. **å‹ç¼©ä¸ä»…æ˜¯æ•ˆç‡å·¥å…·ï¼Œæ›´æ˜¯æ­£åˆ™åŒ–æ‰‹æ®µ**  
   PAACE åœ¨å¤šä¸ªåŸºå‡†ä¸Š**è¶…è¶Šâ€œæ— å‹ç¼©â€åŸºçº¿**ï¼Œè¡¨æ˜å»é™¤å†—ä½™å’ŒçŸ›ç›¾ä¿¡æ¯æœ‰åŠ©äºæå‡æ¨ç†ä¸€è‡´æ€§ã€‚

3. **ä¸Šä¸‹æ–‡å·¥ç¨‹åº”ä½œä¸ºä¸€çº§æ¨¡å—**  
   ç±»ä¼¼ RAG ä¹‹äºçŸ¥è¯†ç³»ç»Ÿï¼Œ**Context Engineering åº”æˆä¸ºä»£ç†æ¶æ„çš„æ ¸å¿ƒç»„ä»¶**ã€‚

4. **åˆæˆæ•°æ® + è’¸é¦å¯è¡Œä¸”é«˜æ•ˆ**  
   PAACE-Syn æä¾›é«˜è´¨é‡ç›‘ç£ä¿¡å·ï¼Œä½¿å°å‹æ¨¡å‹ä¹Ÿèƒ½æŒæ¡å¤æ‚çš„å‹ç¼©ç­–ç•¥ã€‚

5. **æŒ‡ä»¤ä¸ä¸Šä¸‹æ–‡éœ€ååŒæ¼”åŒ–**  
   å•çº¯åˆ é™¤æ— å…³å†…å®¹ä¸è¶³ä»¥ç»´æŒé•¿æœŸä»»åŠ¡ç¨³å®šæ€§ï¼Œå¿…é¡»åŒæ­¥ä¼˜åŒ–æŒ‡ä»¤è¡¨è¿°ã€‚

---

### âš ï¸ å±€é™æ€§
1. **éå½¢å¼åŒ–ä¿è¯**  
   ä¸æä¾›è¯­ä¹‰ç­‰ä»·çš„å½¢å¼éªŒè¯ï¼Œä¾èµ– LLM åˆ¤æ–­å’ŒåµŒå…¥ç›¸ä¼¼æ€§ä½œä¸ºä»£ç†æŒ‡æ ‡ã€‚
2. **é¢†åŸŸç‰¹å¼‚æ€§**  
   å‹ç¼©ç­–ç•¥åœ¨ç‰¹å®šç¯å¢ƒä¸­å­¦å¾—ï¼Œè·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›æœ‰å¾…éªŒè¯ã€‚
3. **å®‰å…¨é£é™©**  
   è‹¥å‹ç¼©ç­–ç•¥æœªå……åˆ†éªŒè¯ï¼Œå¯èƒ½é—æ¼å®‰å…¨çº¦æŸæˆ–æº¯æºä¿¡æ¯ï¼ˆå°½ç®¡ PAACE é€šè¿‡ outcome-level è¿‡æ»¤ç¼“è§£æ­¤é—®é¢˜ï¼‰ã€‚
4. **ä¾èµ–è®¡åˆ’å¯ç”¨æ€§**  
   è™½ç„¶å…è®¸ä¸å®Œç¾è®¡åˆ’ï¼Œä½†è‹¥å®Œå…¨ç¼ºå¤±è®¡åˆ’æè¿°ï¼Œæ€§èƒ½ä¼šä¸‹é™ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼•å…¥ç¬¦å·æ£€æŸ¥æœºåˆ¶**  
   ç»“åˆå½¢å¼åŒ–éªŒè¯å™¨æˆ–é¢†åŸŸè§„åˆ™ï¼Œå¢å¼ºå®‰å…¨æ€§ä¸å¯é æ€§ã€‚
2. **è·¨ä»»åŠ¡è¿ç§»å­¦ä¹ **  
   æ¢ç´¢é€šç”¨çš„ plan-aware å‹ç¼©å…ˆéªŒï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚
3. **åŠ¨æ€è°ƒæ•´ k å€¼**  
   æ ¹æ®ä»»åŠ¡ç±»å‹è‡ªé€‚åº”é€‰æ‹© next-k çš„èŒƒå›´ã€‚
4. **é›†æˆåˆ°å¤šä»£ç†ç³»ç»Ÿ**  
   å°† PAACE ä½œä¸º meta-agent çš„ä¸Šä¸‹æ–‡æ§åˆ¶å™¨ï¼Œåè°ƒå¤šä¸ªå­ä»£ç†çš„é€šä¿¡ä¸è®°å¿†ã€‚
5. **å¼€æºç”Ÿæ€å»ºè®¾**  
   å‘å¸ƒ PAACE-Syn æ•°æ®é›†ä¸ä»£ç ï¼Œæ¨åŠ¨ä¸Šä¸‹æ–‡å·¥ç¨‹æ ‡å‡†åŒ–ã€‚

---

## æ€»ç»“
PAACE æå‡ºäº†ä¸€ç§å…¨æ–°çš„è§†è§’â€”â€”å°† **context engineering** è§†ä¸º LLM ä»£ç†çš„æ ¸å¿ƒèƒ½åŠ›ï¼Œè€Œä¸ä»…ä»…æ˜¯è¾…åŠ©åŠŸèƒ½ã€‚å®ƒé€šè¿‡**è®¡åˆ’æ„ŸçŸ¥ã€å¤šæ­¥å‰ç»ã€åˆæˆè®­ç»ƒä¸æ¨¡å‹è’¸é¦**ï¼Œå®ç°äº†é«˜ä¿çœŸã€ä½æˆæœ¬çš„ä¸Šä¸‹æ–‡ç®¡ç†ï¼Œåœ¨å¤šä¸ªé•¿å‘¨æœŸä»£ç†åŸºå‡†ä¸Šå–å¾—äº† SOTA è¡¨ç°ã€‚è¯¥å·¥ä½œä¸ºæ„å»º**å¯æ‰©å±•ã€å¯é ã€é«˜æ•ˆçš„ agentic systems** æä¾›äº†åšå®åŸºç¡€ã€‚

</details>

---

### 12. [Accelerating Multi-modal LLM Gaming Performance via Input Prediction and Mishit Correction](https://arxiv.org/abs/2512.17250)

**Authors**: Ziyang Lin, Zixuan Sun, Sanhorn Chen, Xiaoyang Chen, Roy Zhao  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.17250v1  

#### Abstract
Real-time sequential control agents are often bottlenecked by inference latency. Even modest per-step planning delays can destabilize control and degrade overall performance. We propose a speculation-and-correction framework that adapts the predict-then-verify philosophy of speculative execution to ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAccelerating Multi-modal LLM Gaming Performance via Input Prediction and Mishit Correction

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **Transformer-based å®æ—¶é¡ºåºæ§åˆ¶ä»£ç†ï¼ˆreal-time sequential control agentsï¼‰ä¸­çš„æ¨ç†å»¶è¿Ÿç“¶é¢ˆ** å±•å¼€ç ”ç©¶ã€‚åœ¨æœºå™¨äººæ§åˆ¶ã€ç«æŠ€æ¸¸æˆã€é«˜é¢‘äº¤æ˜“ç­‰ä»»åŠ¡ä¸­ï¼Œå³ä½¿å¾®å°çš„æ¯æ­¥è§„åˆ’å»¶è¿Ÿä¹Ÿå¯èƒ½å¯¼è‡´ç³»ç»Ÿä¸ç¨³å®šæˆ–å¥–åŠ±ä¸‹é™ã€‚ä¼ ç»ŸåŠ é€Ÿæ–¹æ³•ï¼ˆå¦‚ speculative decodingã€early exitingï¼‰ä¸»è¦ä¼˜åŒ–è¾“å…¥åçš„æ¨ç†è¿‡ç¨‹ï¼Œä½†åœ¨å®é™…éƒ¨ç½²ä¸­ä»æ— æ³•æ»¡è¶³ä¸¥æ ¼çš„ç«¯åˆ°ç«¯å»¶è¿Ÿè¦æ±‚ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§ **â€œæ¨æµ‹-ä¿®æ­£â€æ¡†æ¶ï¼ˆspeculation-and-correction frameworkï¼‰**ï¼Œå°† speculative decoding ä¸­çš„ â€œé¢„æµ‹-éªŒè¯â€ èŒƒå¼æ‰©å±•åˆ°åŸºäºæ¨¡å‹çš„æ§åˆ¶ä»»åŠ¡ä¸­ï¼Œå…·ä½“åŒ…æ‹¬ä»¥ä¸‹ä¸‰ä¸ªæ ¸å¿ƒæœºåˆ¶ï¼š

- **Input Predictionï¼ˆè¾“å…¥é¢„æµ‹ï¼‰**ï¼šåˆ©ç”¨é¢„è®­ç»ƒçš„ TD-MPC2 ä¸–ç•Œæ¨¡å‹å’Œæ½œåœ¨ç©ºé—´ MPC è§„åˆ’å™¨ï¼Œåœ¨æ¯ä¸ªæ—¶é—´æ­¥ç”ŸæˆçŸ­æœŸåŠ¨ä½œé˜Ÿåˆ—ï¼ˆaction queueï¼‰å’Œæ½œå˜é‡ rollout é¢„æµ‹ã€‚
- **Speculative Executionï¼ˆæ¨æµ‹æ‰§è¡Œï¼‰**ï¼šç›´æ¥æ‰§è¡Œå¤šä¸ªé¢„å…ˆè®¡åˆ’çš„åŠ¨ä½œè€Œä¸é‡æ–°è§„åˆ’ï¼Œä»è€Œå‡å°‘é¢‘ç¹è°ƒç”¨æ˜‚è´µçš„ MPC æ¨ç†ã€‚
- **Mismatch-Aware Miss Recycling and Correctionï¼ˆé”™é…æ„ŸçŸ¥çš„é”™è¯¯å›æ”¶ä¸ä¿®æ­£ï¼‰**ï¼š
  - å½“è§‚æµ‹çŠ¶æ€ä¸é¢„æµ‹æ½œå˜é‡å­˜åœ¨åå·®æ—¶ï¼Œå¼•å…¥ä¸€ä¸ªè½»é‡çº§çš„ **learned corrector** å¯¹æ¨æµ‹åŠ¨ä½œè¿›è¡Œæ®‹å·®æ›´æ–°ï¼›
  - è‹¥åå·®è¿‡å¤§ï¼Œåˆ™å®‰å…¨å›é€€è‡³å®Œæ•´é‡è§„åˆ’ï¼Œå¹¶æ¸…ç©ºæ—§é˜Ÿåˆ—ã€‚

æ­¤å¤–ï¼Œè®¾è®¡äº†ä¸¤ç§ corrector æ¶æ„ï¼š
- **Gated two-tower MLP corrector**ï¼šé€‚ç”¨äºå±€éƒ¨è¯¯å·®çš„å¿«é€Ÿå“åº”ï¼›
- **Temporal Transformer corrector**ï¼šé€šè¿‡å†å²é”™é…ç‰¹å¾æ•æ‰ç³»ç»Ÿæ€§æ¼‚ç§»ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | æœ¬æ–‡æ–¹æ³• | ä¼ ç»Ÿæ–¹æ³• |
|------|---------|----------|
| åŠ é€Ÿé˜¶æ®µ | è¾“å…¥ä¾§é¢„æµ‹ï¼ˆinput-side predictionï¼‰ | è¾“å‡ºä¾§æ¨ç†åŠ é€Ÿï¼ˆpost-input inferenceï¼‰ |
| æ¨ç†é¢‘ç‡ | æ˜¾è‘—é™ä½ï¼ˆå‡å°‘ 43.6%ï¼‰ | æ¯æ­¥å‡éœ€æ¨ç† |
| é”™è¯¯å¤„ç† | å¯ä¿®å¤éƒ¨åˆ†æ¨æµ‹å¤±è´¥ï¼ˆmiss recyclingï¼‰ | å¤±è´¥å³ä¸¢å¼ƒå¹¶é‡å¯ |
| æ§åˆ¶ç¨³å®šæ€§ | å¼•å…¥é˜ˆå€¼æ§åˆ¶ä¸ fallback æœºåˆ¶ä¿éšœé²æ£’æ€§ | æ— å®¹é”™æœºåˆ¶ |

> âœ… **æ ¸å¿ƒåˆ›æ–°**ï¼šé¦–æ¬¡å°† speculative execution ä»è¯­è¨€ç”Ÿæˆé¢†åŸŸè¿ç§»åˆ°è¿ç»­æ§åˆ¶ä»»åŠ¡ï¼Œå¹¶ç»“åˆ residual policy learning æ€æƒ³å®ç° **å¯å­¦ä¹ çš„æ¨æµ‹ä¿®æ­£æœºåˆ¶**ï¼Œå®ç°äº†ä½å»¶è¿Ÿä¸é«˜ç¨³å®šæ€§çš„å¹³è¡¡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸ç¯å¢ƒ
- **åŸºå‡†ä»»åŠ¡**ï¼šDeepMind Control Suite (DMC) ä¸­çš„ `Humanoid-Walk` è¿ç»­æ§åˆ¶ä»»åŠ¡ã€‚
- **ç‰©ç†å¼•æ“**ï¼šMuJoCo [4]ã€‚
- **æ•°æ®æ¥æº**ï¼šåŸºäºé¢„è®­ç»ƒçš„ TD-MPC2 [2] ä¸–ç•Œæ¨¡å‹é‡‡é›†è½¨è¿¹æ•°æ®ï¼ŒåŒ…å«çœŸå®çŠ¶æ€ã€æ¨æµ‹é¢„æµ‹ã€æ‰§è¡ŒåŠ¨ä½œç­‰ä¿¡æ¯ã€‚

### å®éªŒè®¾ç½®
- **æ€»æ­¥æ•°**ï¼š500 ä¸ªç¯å¢ƒæ­¥ï¼ˆenvironment stepsï¼‰ã€‚
- **è§„åˆ’è§†ç•Œï¼ˆplanning horizonï¼‰**ï¼šH = 3ã€‚
- **æ‰§è¡Œè§†ç•Œï¼ˆexecute horizonï¼‰**ï¼šL âˆˆ {3, 6}ã€‚
- **é”™é…é˜ˆå€¼ï¼ˆmismatch thresholdï¼‰**ï¼šç”¨äºåˆ¤æ–­æ˜¯å¦è§¦å‘ fallbackã€‚
- **corrector è®­ç»ƒæ–¹å¼**ï¼šé‡‡ç”¨ç¦»çº¿è’¸é¦ï¼ˆdistillationï¼‰ç­–ç•¥ï¼Œä»¥ TD-MPC2 é‡è§„åˆ’åŠ¨ä½œä¸ºæ•™å¸ˆä¿¡å·ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Inference Calls** | æ¯è½®ç¯å¢ƒä¸­è°ƒç”¨ MPC è§„åˆ’å™¨çš„æ¬¡æ•° |
| **End-to-End Step Latency** | æ¯ä¸ªç¯å¢ƒæ­¥éª¤çš„å¹³å‡å»¶è¿Ÿï¼ˆmsï¼‰ |
| **Cumulative Reward** | æœ€ç»ˆç´¯è®¡å›æŠ¥å¾—åˆ† |
| **Speedup Ratio** | ç«¯åˆ°ç«¯å»¶è¿Ÿæå‡æ¯”ä¾‹ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Original TD-MPC2**ï¼šæ¯æ­¥éƒ½è¿›è¡Œå®Œæ•´ MPC è§„åˆ’ï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™ã€‚
- **Speculation-onlyï¼ˆæ— ä¿®æ­£ï¼‰**ï¼šæ‰§è¡Œæ¨æµ‹åŠ¨ä½œé“¾ä½†ä¸ä¿®æ­£ã€‚
- **Correction-onlyï¼ˆæ— æ¨æµ‹ï¼‰**ï¼šä»…ä½¿ç”¨ corrector ä¸å¯ç”¨å¤šæ­¥æ‰§è¡Œã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ–¹æ³• | Inference Calls | Latency per Step | Cumulative Reward |
|------|------------------|-------------------|--------------------|
| Original TD-MPC2 | 500 | 36 ms | 935 |
| **Ours (Speculation + Correction)** | **282** (-43.6%) | **27 ms** (**â†“25%**) | **869** (-7.1%) |

> ğŸ“ˆ åœ¨ä»…æŸå¤± **7.1% å¥–åŠ±** çš„å‰æä¸‹ï¼Œå®ç°äº†ï¼š
> - **43.6% çš„æ¨ç†è°ƒç”¨å‡å°‘**
> - **25% çš„ç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½**

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç›¸æ¯”åŸå§‹ TD-MPC2**ï¼š
  - å‡å°‘ 218 æ¬¡æ¨ç†è°ƒç”¨ï¼ˆçº¦ä¸€åŠï¼‰ï¼Œæ˜¾è‘—èŠ‚çœè®¡ç®—èµ„æºï¼›
  - å°½ç®¡å¼•å…¥ corrector å¸¦æ¥é¢å¤– 12ms/inference å¼€é”€ï¼Œä½†ç”±äºè°ƒç”¨é¢‘æ¬¡å¤§å¹…ä¸‹é™ï¼Œæ•´ä½“å»¶è¿Ÿä»æ˜æ˜¾æ”¹å–„ã€‚

- **ä¸å…¶ä»–å˜ä½“æ¯”è¾ƒ**ï¼ˆè§ Figure 9ï¼‰ï¼š
  - **Speculation-onlyï¼ˆæ‰§è¡Œ3æ­¥ï¼‰**ï¼šreward é™è‡³ 142ï¼ˆâ†“84.8%ï¼‰ï¼Œè¡¨æ˜æ— ä¿®æ­£çš„é•¿ç¨‹æ¨æµ‹æä¸å¯é ï¼›
  - **Speculation-onlyï¼ˆæ‰§è¡Œ2æ­¥ï¼‰**ï¼šreward ä¸º 778ï¼ˆâ†“16.8%ï¼‰ï¼Œè¯´æ˜çŸ­è§†ç•Œæ¨æµ‹æœ‰ä¸€å®šå¯è¡Œæ€§ä½†ä»æœ‰è¾ƒå¤§æ€§èƒ½æŸå¤±ï¼›
  - **Our full method**ï¼šæ¯” speculation-only æå‡ **91 åˆ† reward**ï¼Œè¯æ˜ corrector æœ‰æ•ˆæ¢å¤æ§åˆ¶è´¨é‡ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **Corrector å¿…è¦æ€§éªŒè¯**ï¼š
  - ç§»é™¤ corrector åï¼Œå³ä½¿åªæ‰§è¡Œä¸¤æ­¥æ¨æµ‹ï¼Œæ€§èƒ½ä¹Ÿæ˜¾è‘—ä¸‹é™ï¼›
  - è¡¨æ˜ **mismatch-aware recycling æ˜¯å®ç°ç¨³å¥åŠ é€Ÿçš„å…³é”®**ã€‚
  
- **ä¸åŒ corrector æ¶æ„è¡¨ç°**ï¼š
  - **Two-Tower MLP**ï¼šæ”¶æ•›æ›´å¿«ï¼Œæœ€ç»ˆ loss æ›´ä½ï¼Œé€‚åˆä½å»¶è¿Ÿåœºæ™¯ï¼›
  - **Temporal Transformer**ï¼šå¯¹é•¿æœŸæ¼‚ç§»å»ºæ¨¡æ›´å¼ºï¼Œæ›´é€‚åˆé•¿è·¨åº¦æ¨æµ‹ï¼›
  - ä¸¤è€…äº’è¡¥ï¼Œå¯æ ¹æ®ç¡¬ä»¶é¢„ç®—é€‰æ‹©ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è¾“å…¥é¢„æµ‹å¯ç”¨äºæœ‰æ•ˆåŠ é€Ÿå®æ—¶æ§åˆ¶**ï¼šæœªæ¥çš„è§‚æµ‹è¾“å…¥å…·æœ‰å¯é¢„æµ‹æ€§ï¼Œæå‰æ¨æµ‹å¯è½¬åŒ–ä¸ºæœ‰ç”¨çš„é¢„è®¡ç®—ã€‚
2. **æ¨æµ‹æ‰§è¡Œå¿…é¡»é…åˆä¿®æ­£æœºåˆ¶æ‰å¯é **ï¼šå•çº¯çš„ speculative execution åœ¨é•¿è·¨åº¦ä¸‹ææ˜“ç´¯ç§¯è¯¯å·®ï¼Œå¯¼è‡´å´©æºƒï¼›è€Œè½»é‡ corrector èƒ½æ˜¾è‘—æå‡é²æ£’æ€§ã€‚
3. **æ•ˆç‡ä¸æ€§èƒ½å¯å–å¾—è‰¯å¥½æƒè¡¡**ï¼šé€šè¿‡åˆç†è®¾è®¡ speculation depth ä¸ mismatch thresholdï¼Œå¯åœ¨ä¿æŒè¾ƒé«˜æ§åˆ¶è´¨é‡çš„åŒæ—¶å¤§å¹…æå‡ååç‡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å½“å‰è¯„ä¼°èŒƒå›´æœ‰é™**ï¼šä»…åœ¨å•ä¸€ä»»åŠ¡ï¼ˆHumanoid-Walkï¼‰ä¸Šæµ‹è¯•ï¼ŒæœªéªŒè¯è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚
- **æœªè”åˆä¼˜åŒ– speculation ä¸ policy**ï¼šä½¿ç”¨å›ºå®šé¢„è®­ç»ƒ TD-MPC2 ä½œä¸ºæ¨æµ‹æ¨¡å—ï¼Œæœªè¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒï¼Œå¯èƒ½é™åˆ¶æœ€å¤§æ¨æµ‹æ·±åº¦ã€‚
- **corrector å¼•å…¥ per-inference å¼€é”€**ï¼šåœ¨æ›´ä¸¥è‹›çš„å®æ—¶é¢„ç®—æˆ–ä½ç«¯ç¡¬ä»¶ä¸Šï¼Œè¿™ä¸€å¼€é”€å¯èƒ½å‰Šå¼±åŠ é€Ÿæ”¶ç›Šã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **Joint Training / Online Adaptation**ï¼šè”åˆè®­ç»ƒ corrector ä¸ world modelï¼Œä½¿å…¶é€‚åº”é—­ç¯æ¨æµ‹ä¸‹çš„åˆ†å¸ƒåç§»ã€‚
2. **Adaptive Budgeting**ï¼šæ ¹æ®é”™é…å†å²å’Œä¸ç¡®å®šæ€§åŠ¨æ€è°ƒæ•´ speculation depth å’Œ replanning é¢‘ç‡ï¼Œæ˜¾å¼ä¼˜åŒ– speed-reward trade-offã€‚
3. **æ‰©å±•è‡³æ›´å¤šä»»åŠ¡ä¸æ¨¡æ€**ï¼šåœ¨å…¶ä»– DMC ä»»åŠ¡ã€å«å™ªå£°ä¼ æ„Ÿå™¨ç¯å¢ƒåŠçœŸå®æ§åˆ¶ç³»ç»Ÿä¸­éªŒè¯é€šç”¨æ€§ã€‚
4. **ç³»ç»Ÿçº§æµæ°´çº¿ä¼˜åŒ–**ï¼šè¿›ä¸€æ­¥é‡å  speculationã€correction ä¸ç¯å¢ƒäº¤äº’ï¼Œé™ä½å°¾å»¶è¿Ÿï¼ˆtail latencyï¼‰ã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº **è¾“å…¥é¢„æµ‹ + è½»é‡ä¿®æ­£** çš„ speculative control æ¡†æ¶ï¼Œåœ¨ DMC Humanoid-Walk ä¸Šå®ç°äº† **43.6% æ¨ç†è°ƒç”¨å‡å°‘ã€25% å»¶è¿Ÿä¸‹é™ã€ä»… 7.1% å¥–åŠ±æŸå¤±**ï¼Œä¸º Transformer-based å®æ—¶æ§åˆ¶æä¾›äº†é«˜æ•ˆä¸”é²æ£’çš„æ–°èŒƒå¼ã€‚

</details>

---

### 13. [Distributed Learning in Markovian Restless Bandits over Interference Graphs for Stable Spectrum Sharing](https://arxiv.org/abs/2512.17161)

**Authors**: Liad Lea Didi, Kobi Cohen  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.17161v1  

#### Abstract
We study distributed learning for spectrum access and sharing among multiple cognitive communication entities, such as cells, subnetworks, or cognitive radio users (collectively referred to as cells), in communication-constrained wireless networks modeled by interference graphs. Our goal is to achie...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDistributed Learning in Markovian Restless Bandits over Interference Graphs for Stable Spectrum Sharing

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡ç ”ç©¶äº†åœ¨**é€šä¿¡å—é™çš„æ— çº¿ç½‘ç»œ**ä¸­ï¼Œå¤šä¸ªè®¤çŸ¥é€šä¿¡å®ä½“ï¼ˆå¦‚ cellsã€subnetworks æˆ– cognitive radio usersï¼‰ä¹‹é—´çš„**åˆ†å¸ƒå¼é¢‘è°±æ¥å…¥ä¸å…±äº«é—®é¢˜**ã€‚è¯¥é—®é¢˜å…·æœ‰ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- å­˜åœ¨**ç©ºé—´å¹²æ‰°çº¦æŸ**ï¼Œç”± interference graph å»ºæ¨¡ï¼›
- é¢‘é“çŠ¶æ€éšæ—¶é—´åŠ¨æ€å˜åŒ–ï¼Œéµå¾ªæœªçŸ¥çš„**Markovian restless è¿‡ç¨‹**ï¼ˆå³é¢‘é“å³ä½¿æœªè¢«è§‚æµ‹ä¹Ÿä¼šæ¼”åŒ–ï¼‰ï¼›
- å„ cell å¯¹åŒä¸€é¢‘é“çš„æ„ŸçŸ¥æ”¶ç›Šä¸åŒï¼ˆ**heterogeneous rewards**ï¼‰ï¼Œå¯¼è‡´ç³»ç»Ÿé«˜åº¦éå¯¹ç§°ï¼›
- ç›®æ ‡æ˜¯å®ç°å…¨å±€**ç¨³å®šä¸”é«˜æ•ˆ**çš„ä¿¡é“åˆ†é…ã€‚

ä¼ ç»Ÿæ–¹æ³•å¤šå‡è®¾é¢‘é“ä¸º i.i.d. æˆ– rested æ¨¡å‹ï¼Œæ— æ³•åº”å¯¹ç°å®ä¸­çš„æ—¶å˜æ€§å’Œå¹²æ‰°å›¾ç»“æ„ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºäº†åä¸º **SMILE**ï¼ˆStable Multi-matching with Interference-aware LEarningï¼‰çš„**åˆ†å¸ƒå¼å­¦ä¹ ç®—æ³•**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰é—®é¢˜å»ºæ¨¡åˆ›æ–°
- å°†é¢‘è°±å…±äº«é—®é¢˜å½¢å¼åŒ–ä¸ºåŸºäº interference graph çš„ **generalized Gale-Shapley å¤šå¯¹ä¸€ç¨³å®šåŒ¹é…é—®é¢˜**ã€‚
- åœ¨å­˜åœ¨ç©ºé—´å¹²æ‰°å’Œéšæœºæ—¶å˜é¢‘é“åŠ¨æ€ä¸‹å®šä¹‰â€œç¨³å®šæ€§â€ï¼Œè¿™æ˜¯é¦–æ¬¡å°† Gale-Shapley ç¨³å®šæ€§æ‰©å±•åˆ° **restless Markovian ç¯å¢ƒ**ã€‚

#### ï¼ˆ2ï¼‰ç®—æ³•è®¾è®¡åˆ›æ–°
- **SMILE ç®—æ³•**èåˆäº† **restless multi-armed bandit (RMAB)** å­¦ä¹ ä¸å›¾çº¦æŸåè°ƒæœºåˆ¶ï¼Œæ— éœ€ä¸­å¿ƒæ§åˆ¶å™¨æˆ–é¢‘ç¹é€šä¿¡ã€‚
- ç®—æ³•åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼š
  - **Exploration Phase**ï¼šé€šè¿‡ recovery epoch å’Œ estimation epoch æ”¶é›†æ ·æœ¬ï¼Œå…‹æœ restless çŠ¶æ€æ¼”åŒ–å¸¦æ¥çš„ä¼°è®¡åå·®ï¼›
  - **Allocation Phase**ï¼šåŸºäºå½“å‰é€Ÿç‡ä¼°è®¡æ‰§è¡Œåˆ†å¸ƒå¼ç¨³å®šåŒ¹é…ï¼›
  - **Exploitation Phase**ï¼šæŒ‰åŒ¹é…ç»“æœè¿›è¡Œä¼ è¾“ã€‚
- å¼•å…¥è‡ªé€‚åº”çš„ **exploration function** $ T_{l,s}(t) = \max\{E_{l,s}(t), 2/\lambda\} \log t $ï¼Œå¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ï¼Œå¹¶ä¿è¯å¯¹å…³é”®é¢‘é“å……åˆ†é‡‡æ ·ã€‚

#### ï¼ˆ3ï¼‰ç†è®ºä¿éšœ
- è¯æ˜ SMILE èƒ½å¤Ÿä»¥**å¯¹æ•°çº§ regret** æ”¶æ•›è‡³æœ€ä¼˜ç¨³å®šåˆ†é…ï¼Œå³ï¼š
  $$
  R(t) = O(\log t)
  $$
- è¿™æ˜¯å¯¹æ•° regret çš„æœ€ä¼˜é˜¶ï¼Œåœ¨æ­¤ç±»é—®é¢˜ä¸­è¾¾åˆ°ç†è®ºæé™ã€‚
- åˆ†æè€ƒè™‘äº† transient effectã€channel switching cost å’Œ suboptimal matching çš„ç»¼åˆå½±å“ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ç°æœ‰æ–¹æ³•å±€é™ | SMILE çš„ä¼˜åŠ¿ |
|------|--------------|-------------|
| **ç¯å¢ƒæ¨¡å‹** | å¤šä¸º i.i.d. æˆ– rested MABï¼Œä¸é€‚ç”¨äºçœŸå®æ— çº¿ä¿¡é“ | æ”¯æŒ **restless Markovian åŠ¨æ€**ï¼Œæ›´è´´è¿‘å®é™… |
| **ç½‘ç»œæ‹“æ‰‘** | å¤šå‡è®¾å®Œå…¨å¹²æ‰°ï¼ˆcomplete graphï¼‰ | æ”¯æŒä»»æ„ **interference graph**ï¼Œæ”¯æŒä¿¡é“å¤ç”¨ |
| **é€šä¿¡å¼€é”€** | å¦‚ auction-based æ–¹æ³•éœ€å¤§é‡é€šä¿¡ | **æ— å…¨å±€é€šä¿¡éœ€æ±‚**ï¼Œä»…ä¾èµ–æœ¬åœ° carrier sensing æˆ–é‚»å±…æ¶ˆæ¯äº¤æ¢ |
| **ç¨³å®šæ€§ä¿è¯** | å¤šæ•° RMAB æ–¹æ³•æ— ç¨³å®šåŒ¹é…æ¦‚å¿µ | æ˜¾å¼è¿½æ±‚ **Gale-Shapley ç¨³å®šæ€§**ï¼Œå…¼é¡¾æ•ˆç‡ä¸å…¬å¹³ |
| **ç†è®ºæ€§èƒ½** | éƒ¨åˆ†æ–¹æ³•ç¼ºä¹ä¸¥æ ¼ regret bound | æä¾› **tight logarithmic regret bound**ï¼Œä¼˜äºåŒç±»ç®—æ³• |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### å®éªŒè®¾ç½®
æ‰€æœ‰ä»¿çœŸå®éªŒå‡åŸºäº **Finite-State Markov Channel (FSMC)** æ¨¡å‹æ¨¡æ‹Ÿæ— çº¿ä¿¡é“çš„æ—¶é—´ç›¸å…³æ€§ã€‚å…·ä½“é…ç½®å¦‚ä¸‹ï¼š

#### åœºæ™¯ä¸€ï¼šå°è§„æ¨¡éªŒè¯ï¼ˆL=3, S=5ï¼‰
- Cellsï¼š3ä¸ªï¼Œå…¶ä¸­ cell 1 ä¸ cell 2 ç›¸é‚»ï¼Œcell 3 æ— é‚»å±…ï¼›
- Channelsï¼š5ä¸ªæ­£äº¤ä¿¡é“ï¼›
- ä¿¡é“æ¨¡å‹ï¼šRayleigh fadingï¼Œé‡åŒ–ä¸º 6 ä¸ª FSMC çŠ¶æ€ï¼›
- è½¬ç§»çŸ©é˜µä¸æœŸæœ›é€Ÿç‡çŸ©é˜µç”±æ–‡ä¸­ç»™å‡ºã€‚

#### åœºæ™¯äºŒï¼šå¤§è§„æ¨¡å¯æ‰©å±•æ€§æµ‹è¯•
- å¤§è§„æ¨¡ç½‘ç»œï¼š$ L=50, S=50 $ï¼›$ L=100, S=100 $ï¼›$ L=100, S=50 $
- å¹²æ‰°å›¾éšæœºç”Ÿæˆï¼Œå…è®¸ä¿¡é“å¤ç”¨ï¼›
- ç”¨äºéªŒè¯ SMILE åœ¨é«˜ç»´åœºæ™¯ä¸‹çš„æ”¶æ•›æ€§ä¸é²æ£’æ€§ã€‚

#### åœºæ™¯ä¸‰ï¼šå±‚æ¬¡åŒ–é¢‘è°±æ¥å…¥ï¼ˆHierarchical Accessï¼‰
- Primary ç”¨æˆ·é—´æ­‡å ç”¨ä¿¡é“ï¼Œsecondary ç”¨æˆ·åªèƒ½åœ¨ç©ºé—²æ—¶æ¥å…¥ï¼›
- é‡‡ç”¨ **Gilbert-Elliott æ¨¡å‹**æè¿° primary ç”¨æˆ·æ´»åŠ¨ï¼›
- ç”¨äºæ¯”è¾ƒ regret æ€§èƒ½ã€‚

#### åœºæ™¯å››ï¼šå¼‚æ„æ”¶ç›Šæ¯”è¾ƒ
- æ¯ä¸ª cell åœ¨æ¯ä¸ª channel ä¸Šæœ‰ä¸åŒçš„æœŸæœ›é€Ÿç‡ï¼›
- åŠ æ€§å™ªå£°ï¼š$ r_{l,s}(t) = \mu_{l,s} + z_{l,s}(t), z \sim \mathcal{N}(0, 0.05^2) $

---

### è¯„ä¼°æŒ‡æ ‡
- **Average Sum Rate**ï¼šæ‰€æœ‰ cell çš„å¹³å‡æ€»é€Ÿç‡ï¼Œè¡¡é‡é•¿æœŸæ€§èƒ½ï¼›
- **Regret**ï¼šç›¸å¯¹äºå·²çŸ¥æœŸæœ›æ•ˆç”¨çš„â€œç¥è°•â€ï¼ˆgenieï¼‰ç­–ç•¥çš„ç´¯è®¡æŸå¤±ï¼›
  $$
  R_o(t) = t \sum_{l=1}^L \mu_{l,P^*(l)} - \mathbb{E}\left[\sum_{n=1}^t \sum_{l=1}^L x_{l,\phi_l(n)}(n)\right]
  $$
- **Normalized Regret / log t**ï¼šç”¨äºåˆ¤æ–­æ˜¯å¦è¾¾åˆ°å¯¹æ•°å¢é•¿ã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æ˜¯å¦éœ€è¦é€šä¿¡ | ç‰¹ç‚¹ |
|------|------|---------------|------|
| **Random Allocation** | éšæœºç­–ç•¥ | å¦ | åŸºçº¿ä¸‹é™ |
| **Optimal Solver (Oracle)** | ä¸­å¿ƒåŒ–æ±‚è§£å™¨ | æ˜¯ | å·²çŸ¥ $\mu_{l,s}$ ä¸‹çš„æœ€ä¼˜ç¨³å®šåŒ¹é…ï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™ |
| **RCA [14]** | RMAB å­¦ä¹  | å¦ | å•ç”¨æˆ· rested bandit æ‰©å±• |
| **DSEE [15]** | RMAB å­¦ä¹  | å¦ | æ¢ç´¢-åˆ©ç”¨åˆ†ç¦»æ¡†æ¶ |
| **DSSL [12]** | åˆ†å¸ƒå¼ RMAB | æ˜¯ | é’ˆå¯¹ full interference è®¾è®¡ |
| **dE3 [9]** | åˆ†å¸ƒå¼æ‹å– | æ˜¯ | éœ€ bid ä¿¡æ¯äº¤æ¢ |
| **GoT (Game of Thrones) [37]** | åˆ†å¸ƒå¼åšå¼ˆ | å¦ | å‡åŒ€æ¢ç´¢æ‰€æœ‰ä¿¡é“ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰æ”¶æ•›æ€§è¡¨ç°ï¼ˆFig. 5â€“8ï¼‰
- åœ¨æ‰€æœ‰æµ‹è¯•åœºæ™¯ä¸­ï¼Œ**SMILE å¿«é€Ÿæ”¶æ•›è‡³æ¥è¿‘ Oracle çš„æ€§èƒ½**ï¼š
  - $ L=3, S=5 $ï¼šçº¦ $ 5\times10^4 $ æ—¶é—´æ­¥åæ¥è¿‘æœ€ä¼˜ï¼›
  - $ L=100, S=100 $ï¼šä»èƒ½åœ¨ $ 10^7 $ æ­¥å†…ç¨³å®šé€¼è¿‘æœ€ä¼˜è§£ï¼›
- è¡¨æ˜ SMILE å…·æœ‰è‰¯å¥½çš„**å¯æ‰©å±•æ€§**å’Œ**é²æ£’æ€§**ã€‚

#### ï¼ˆ2ï¼‰Regret æ€§èƒ½å¯¹æ¯”ï¼ˆFig. 9ï¼‰
- åœ¨ normalized regret ($ R(t)/\log t $) æ›²çº¿ä¸­ï¼š
  - **SMILE çš„æ–œç‡æ˜¾è‘—ä½äº RCAã€DSEEã€DSSL**ï¼›
  - è¡¨æ˜å…¶ regret å¢é•¿æœ€æ…¢ï¼Œå­¦ä¹ æ•ˆç‡æœ€é«˜ï¼›
- æœ€ç»ˆ SMILE çš„ regret æ¯”æ¬¡ä¼˜æ–¹æ³•ä½ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Šã€‚

#### ï¼ˆ3ï¼‰å¼‚æ„ç¯å¢ƒä¸‹æ€§èƒ½ï¼ˆFig. 10ï¼‰
- ä¸ dE3 å’Œ GoT å¯¹æ¯”ï¼š
  - **SMILE æ˜¾è‘—ä¼˜äºä¸¤è€…**ï¼Œå°¤å…¶åœ¨æ—©æœŸæ¢ç´¢é˜¶æ®µï¼›
  - dE3 å› é€šä¿¡å¼€é”€å¤§ä¸”å‚æ•°æ•æ„Ÿè€Œè¡¨ç°ä¸ä½³ï¼›
  - GoT å› å‡åŒ€æ¢ç´¢å¯¼è‡´æ”¶æ•›æ…¢ï¼›
- SMILE å‡­å€Ÿ**è‡ªé€‚åº” exploration function** æ›´é«˜æ•ˆåœ°èšç„¦äºæ½œåœ¨ä¼˜è´¨ä¿¡é“ã€‚

---

### æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèå®éªŒè¡¨æ ¼ï¼Œä½†ä»ç†è®ºåˆ†æå’Œç®—æ³•è®¾è®¡å¯ä»¥çœ‹å‡ºï¼š
- è‹¥å»é™¤ **recovery epoch (RE)**ï¼Œä¼šå¯¼è‡´çŠ¶æ€ä¼°è®¡åå·®å¢å¤§ï¼Œå¢åŠ  regretï¼›
- è‹¥ä½¿ç”¨å›ºå®š exploration budget è€Œé adaptive $ E_{l,s}(t) $ï¼Œä¼šè¿‡åº¦æ¢ç´¢ä½ä»·å€¼ä¿¡é“ï¼›
- è‹¥å¿½ç•¥ interference graph ç»“æ„ï¼Œåˆ™æ— æ³•å®ç°ä¿¡é“å¤ç”¨ï¼Œé™ä½ååé‡ã€‚

è¿™äº›è®¾è®¡é€‰æ‹©å…±åŒæ”¯æ’‘äº†æœ€ç»ˆçš„é«˜æ€§èƒ½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **SMILE æˆåŠŸå®ç°äº†åœ¨ general interference graph ä¸‹çš„åˆ†å¸ƒå¼ç¨³å®šé¢‘è°±å…±äº«**ï¼Œè§£å†³äº†ä»¥å¾€ä»…é™äº fully interfering network çš„é™åˆ¶ã€‚
2. âœ… åœ¨ **restless Markovian ä¿¡é“åŠ¨æ€**ä¸‹ï¼Œé¦–æ¬¡å»ºç«‹äº†å…¨å±€ Gale-Shapley ç¨³å®šæ€§çš„å­¦ä¹ ä¿è¯ã€‚
3. âœ… ç†è®ºä¸Šè¯æ˜äº† **$ O(\log t) $ regret bound**ï¼Œè¾¾åˆ°ä¿¡æ¯è®ºæœ€ä¼˜é˜¶ã€‚
4. âœ… å®éªŒè¡¨æ˜ SMILE åœ¨å¤šç§åœºæ™¯ä¸‹å‡èƒ½å¿«é€Ÿæ”¶æ•›ï¼Œä¸”æ€§èƒ½è¿œè¶… state-of-the-art RMAB å’Œåšå¼ˆè®ºæ–¹æ³•ã€‚
5. âœ… ç®—æ³•å¯é€šè¿‡ **CSMA æˆ–å±€éƒ¨æ¶ˆæ¯ä¼ é€’**å®ç°ï¼Œé€‚åˆå®é™…éƒ¨ç½²ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **åˆå§‹åŒ–è¦æ±‚**ï¼šåˆå§‹é˜¶æ®µéœ€çŸ­æš‚åŒæ­¥å®Œæˆåˆæ­¥ä¼°è®¡ï¼›
- **çŠ¶æ€ç©ºé—´é™åˆ¶**ï¼šä¾èµ– FSMC æ¨¡å‹ï¼Œè‹¥çŠ¶æ€è¿‡å¤šåˆ™è®¡ç®—å¤æ‚åº¦ä¸Šå‡ï¼›
- **é™æ€å¹²æ‰°å›¾å‡è®¾**ï¼šinterference graph è¢«è§†ä¸ºé™æ€ï¼Œæœªè€ƒè™‘ç§»åŠ¨æ€§å¼•èµ·çš„æ‹“æ‰‘å˜åŒ–ï¼›
- **ç†è®ºå¸¸æ•°è¾ƒå¤§**ï¼šregret bound ä¸­çš„å¸¸æ•°é¡¹å¯èƒ½å½±å“çŸ­æ—¶æ€§èƒ½ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³ **æ—¶å˜ interference graph**ï¼Œæ”¯æŒç§»åŠ¨èŠ‚ç‚¹ï¼›
2. ç»“åˆ **deep reinforcement learning** å¤„ç†è¿ç»­çŠ¶æ€ç©ºé—´ï¼›
3. å¼•å…¥ **queueing dynamics**ï¼Œæ”¯æŒå¸¦ç¼“å†²åŒºçš„æ•°æ®åŒ…è°ƒåº¦ï¼›
4. è€ƒè™‘ **partial observability** æˆ– **hidden Markov models**ï¼›
5. åœ¨çœŸå® testbed ä¸Šéƒ¨ç½²éªŒè¯ SMILE çš„å®ç”¨æ€§ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> SMILE æ˜¯é¦–ä¸ªåœ¨ **general interference graph + restless Markovian channels** ä¸‹å®ç° **logarithmic regret ä¸ Gale-Shapley ç¨³å®šæ€§**çš„åˆ†å¸ƒå¼é¢‘è°±å…±äº«ç®—æ³•ï¼Œå…¼å…·ç†è®ºä¸¥è°¨æ€§ä¸å·¥ç¨‹å¯è¡Œæ€§ã€‚

</details>

---

### 14. [A Solver-in-the-Loop Framework for Improving LLMs on Answer Set Programming for Logic Puzzle Solving](https://arxiv.org/abs/2512.17093)

**Authors**: Timo Pierre Schrader, Lukas Lange, Tobias Kaminski, Simon Razniewski, Annemarie Friedrich  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.17093v1  

#### Abstract
The rise of large language models (LLMs) has sparked interest in coding assistants. While general-purpose programming languages are well supported, generating code for domain-specific languages remains a challenging problem for LLMs. In this paper, we focus on the LLM-based generation of code for An...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Solver-in-the-Loop Framework for Improving LLMs on Answer Set Programming for Logic Puzzle Solving

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

- **é¢†åŸŸç‰¹å®šè¯­è¨€ï¼ˆDSLï¼‰ä»£ç ç”Ÿæˆçš„æŒ‘æˆ˜**ï¼šå°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é€šç”¨ç¼–ç¨‹è¯­è¨€ï¼ˆå¦‚Pythonã€JavaScriptï¼‰ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨**Answer Set Programming (ASP)** è¿™ç±»é¢†åŸŸç‰¹å®šè¯­è¨€ä¸Šçš„è¡¨ç°è¾ƒå·®ã€‚ASPæ˜¯ä¸€ç§ç”¨äºè§£å†³ç»„åˆæœç´¢é—®é¢˜çš„å¼ºå¤§å£°æ˜å¼ç¼–ç¨‹èŒƒå¼ï¼Œå¹¿æ³›åº”ç”¨äºè°ƒåº¦ã€é…ç½®ã€æœºå™¨äººç­‰é¢†åŸŸã€‚
- **ç¼ºä¹é«˜è´¨é‡è®­ç»ƒæ•°æ®**ï¼šLLMsåœ¨é¢„è®­ç»ƒé˜¶æ®µæ¥è§¦çš„ASPä»£ç æå°‘ï¼Œå¯¼è‡´å…¶éš¾ä»¥å‡†ç¡®ç”Ÿæˆè¯­ä¹‰æ­£ç¡®çš„ASPç¨‹åºï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤æ‚çš„é€»è¾‘è°œé¢˜æ—¶ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡ºäº†ä¸€ç§**Solver-in-the-Loop**æ¡†æ¶ï¼Œç»“åˆASPæ±‚è§£å™¨åé¦ˆæ¥æå‡LLMsåœ¨ASPä»£ç ç”Ÿæˆä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•åˆ†ä¸ºä¸¤ä¸ªæ ¸å¿ƒéƒ¨åˆ†ï¼š

1. **Solver-Guided Instruction-Tuningï¼ˆè®­ç»ƒé˜¶æ®µï¼‰**ï¼š
   - åˆ©ç”¨LLMä¸ºé€»è¾‘è°œé¢˜ç”Ÿæˆå¤šä¸ªå€™é€‰çš„ASPç¼–ç ç‰‡æ®µï¼ˆpartial encodingsï¼‰ã€‚
   - ä½¿ç”¨**ASP solver**å¯¹è¿™äº›ç‰‡æ®µè¿›è¡Œè‡ªåŠ¨è¯„ä¼°ï¼Œåˆ¤æ–­å…¶æ˜¯å¦ï¼š
     - è¯­æ³•æ­£ç¡®ï¼ˆæ— warnings/errorsï¼‰
     - å¯æ»¡è¶³ï¼ˆnot unsatisfiableï¼‰
     - èƒ½å¤Ÿä¿ç•™çœŸå®è§£ï¼ˆground truth solutionï¼‰
   - å°†é€šè¿‡éªŒè¯çš„â€œchosenâ€æ ·æœ¬ç”¨äº**Supervised Fine-Tuning (SFT)**ï¼Œæ„å»ºé«˜è´¨é‡çš„é“¶æ ‡å‡†ï¼ˆsilver-standardï¼‰è®­ç»ƒæ•°æ®ã€‚

2. **Solver-Guided Test-Time Searchï¼ˆæ¨ç†é˜¶æ®µï¼‰**ï¼š
   - åœ¨æ¨ç†æ—¶å¼•å…¥**best-of-N sampling**ç­–ç•¥ï¼Œç”Ÿæˆå¤šä¸ªå€™é€‰ç¼–ç ã€‚
   - è®¾è®¡äº†ä¸€ä¸ª**solver-grounded reward function** $ f_r(I, M) $ æ¥è¯„åˆ†æ¯ä¸ªå€™é€‰ç¼–ç ï¼š
     $$
     f_r(I, M) = - \left( \mathbb{1}_{\text{err}} + \mathbb{1}_{\text{unsat}} + \frac{\mathbb{1}_{\text{NE}}}{M} \right)
     $$
     å…¶ä¸­ $ M $ æ˜¯ç­”æ¡ˆé›†æ•°é‡ï¼Œå¥–åŠ±å€¾å‘äºæ›´ä¸¥æ ¼çš„ã€èƒ½ç¼©å°è§£ç©ºé—´çš„ç¼–ç ã€‚
   - å¼•å…¥ä¸¤ç§æ¢å¤æœºåˆ¶ï¼š
     - **Re-generation**ï¼šè‹¥æ‰€æœ‰å€™é€‰å‡å¤±è´¥ï¼Œåˆ™é‡æ–°ç”Ÿæˆæ›´å¤šå€™é€‰ã€‚
     - **Backtracking**ï¼šå›é€€åˆ°ä¹‹å‰çš„æ­¥éª¤å¹¶å°è¯•å…¶ä»–åˆ†æ”¯ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | æœ¬æ–‡æ–¹æ³• | ç°æœ‰æ–¹æ³• |
|------|---------|--------|
| æ•°æ®ç”Ÿæˆ | è‡ªåŠ¨åŒ–ã€æ— éœ€äººå·¥æ ‡æ³¨ï¼Œåˆ©ç”¨solveråé¦ˆç­›é€‰é«˜è´¨é‡æ•°æ® | ä¾èµ–å°‘é‡äººå·¥æ„é€ æ•°æ®é›†ï¼ˆå¦‚LLASPï¼‰ï¼Œæˆ–ä»…é promptå·¥ç¨‹ |
| æ¨ç†é²æ£’æ€§ | å¼•å…¥solveråé¦ˆä½œä¸ºrewardï¼Œåœ¨æ¨ç†æ—¶åŠ¨æ€ç­›é€‰æœ€ä¼˜è·¯å¾„ | å¤šæ•°åŸºäºchain-of-thoughtæˆ–å›ºå®šprompt pipelineï¼Œæ— æ³•ç»†ç²’åº¦çº é”™ |
| é€‚ç”¨æ€§ | å¯ç”¨äºopen-weightæ¨¡å‹ï¼ˆå¦‚Llamaã€Qwenï¼‰å’Œclosedæ¨¡å‹ï¼ˆå¦‚GPT-4ï¼‰ | å¤šæ•°ç ”ç©¶é›†ä¸­äºå•†ä¸šé—­æºæ¨¡å‹ |
| æ³›åŒ–èƒ½åŠ› | åœ¨æœªè§è¿‡çš„å¤æ‚è°œé¢˜ï¼ˆGridPuzzlesï¼‰ä¸Šè¡¨ç°è‰¯å¥½ï¼Œæ˜¾ç¤ºå¼ºè¿ç§»èƒ½åŠ› | å¤šæ•°æ–¹æ³•é’ˆå¯¹ç‰¹å®šæ•°æ®é›†è®¾è®¡ï¼Œæ³›åŒ–å·® |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

| æ•°æ®é›† | æè¿° |
|-------|------|
| **LogicPuzzles** (Mitra and Baral, 2015) | åŒ…å«124ä¸ª3Ã—4ç½‘æ ¼é€»è¾‘è°œé¢˜ï¼ˆ50è®­ç»ƒï¼Œ74æµ‹è¯•ï¼‰ã€‚æ¯ä¸ªè°œé¢˜æœ‰3ç±»å®ä½“ï¼ˆå¦‚äººã€æ—¶é—´ã€å® ç‰©ï¼‰ï¼Œæ¯ç±»4ä¸ªå®ä¾‹ï¼Œéœ€å®Œæˆå”¯ä¸€åŒ¹é…ã€‚ |
| **GridPuzzles** (Tyagi et al., 2024) | æ›´å¤§è§„æ¨¡å’Œéš¾åº¦çš„æ•°æ®é›†ï¼ŒåŒ…å«å¤šç§å°ºå¯¸ï¼ˆ3Ã—4, 3Ã—5, 4Ã—4, 4Ã—5, 4Ã—6ï¼‰å’Œéš¾åº¦ç­‰çº§ï¼ˆeasy, medium, hardï¼‰ã€‚ä»…ç”¨äºè¯„ä¼°ï¼Œæ— è®­ç»ƒé›†ã€‚ |

> âš ï¸ æ³¨æ„ï¼šä½œè€…å‘ç°åŸå§‹LogicPuzzlesè®­ç»ƒ/æµ‹è¯•é›†å­˜åœ¨26ä¸ªé‡å¤å®ä¾‹ï¼Œå› æ­¤åœ¨ä¸»å®éªŒä¸­ç§»é™¤äº†è¿™äº›é‡å æ ·æœ¬ä»¥ä¿è¯å…¬å¹³æ€§ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹é€‰æ‹©**
- **Open-weight models**:
  - Llama-3.3 70B / Llama-3.1 8B
  - Qwen3 32B / Qwen3 8B
- **Closed-weight baseline**:
  - GPT-4.1-mini (2025-04-14)
- **Reasoning Language Model (RLM) baselines**:
  - DeepSeek-R1 variantsï¼ˆä¸ä½¿ç”¨ASPï¼Œç›´æ¥æ¨ç†ï¼‰

#### **è®­ç»ƒæ–¹å¼**
- ä½¿ç”¨LoRAè¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆrank=128ï¼‰
- è®­ç»ƒæ•°æ®ç”±Llama-3.3 70Bç”Ÿæˆï¼ˆN=5é‡‡æ ·ï¼‰ï¼Œç»solverè¿‡æ»¤åå¾—åˆ°çº¦1.5ké«˜è´¨é‡æ ·æœ¬
- å¯¹å°æ¨¡å‹ï¼ˆ8Bï¼‰é¢å¤–åŠ å…¥LLASPæ•°æ®å¢å¼º

#### **è¯„ä¼°æŒ‡æ ‡**
- **Accuracy**ï¼šé¢„æµ‹çš„ç­”æ¡ˆé›†æ˜¯å¦ä¸ground truthå®Œå…¨ä¸€è‡´ï¼ˆexact matchï¼‰
- ä½¿ç”¨**Levenshtein heuristic**å¤„ç†å­—ç¬¦ä¸²æ ¼å¼å·®å¼‚ï¼ˆå¦‚ä¸‹åˆ’çº¿ vs ç©ºæ ¼ã€ç¼©å†™ç­‰ï¼‰
- æ‰€æœ‰ç»“æœå¹³å‡5æ¬¡è¿è¡Œ

#### **Prompting Settingsï¼ˆä¸¤ç§å¯¹æ¯”åœºæ™¯ï¼‰**
| è®¾ç½® | æè¿° |
|------|------|
| **Two-Shot (2S)** | ç®€å•æç¤ºï¼Œæä¾›åŸºæœ¬æŒ‡ä»¤å’Œä¸¤ä¸ªç¤ºä¾‹ï¼Œæ¨¡æ‹Ÿç°å®æ¨¡ç³Šè¾“å…¥åœºæ™¯ |
| **PromptPipeline (PP)** | å¤æ‚çš„6æ­¥pipelineï¼ˆIshay et al., 2023ï¼‰ï¼Œä¸“ä¸ºLogicPuzzlesè®¾è®¡ï¼Œä»£è¡¨é«˜åº¦å·¥ç¨‹åŒ–çš„promptæ–¹æ¡ˆ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªTable 1ï¼‰**

| æ¨¡å‹ | è®¾ç½® | LogicPuzzles Acc (%) | GridPuzzles Acc (%) |
|------|------|------------------------|----------------------|
| Llama-3.3 70B (base) | 2S | 27.0 | 9.1 |
| Llama-3.3 70B (SFT) | 2S | 55.4 (+28.4) | 16.8 (+7.7) |
| Llama-3.3 70B (SFT + TT) | 2S | **66.8** | **23.7** |
| Llama-3.3 70B (SFT + TT) | PP | **78.4** | **55.5** |
| Qwen3 32B (SFT + TT) | 2S | 50.3 | 33.9 |
| Qwen3 8B (SFT + TT) | 2S | 43.2 | 21.2 |
| DeepSeek-R1 (RLM) | â€” | 59.5 | 21.9 |

> âœ… **ç»“è®º**ï¼šSFTæ˜¾è‘—æå‡æ€§èƒ½ï¼ˆ+20~30ppï¼‰ï¼ŒåŠ ä¸Štest-time searchè¿›ä¸€æ­¥æå‡è‡³**66.8%**ï¼ˆLogicPuzzlesï¼‰ï¼Œè¶…è¶ŠRLMåŸºçº¿ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- åœ¨**ä¸¤æ­¥æç¤ºï¼ˆ2Sï¼‰è®¾ç½®ä¸‹**ï¼š
  - æ‰€æœ‰SFTè®­ç»ƒåçš„æ¨¡å‹å‡æ˜¾è‘—ä¼˜äºå…¶baseç‰ˆæœ¬ã€‚
  - Llama-3.3 70B (SFT + TT) è¾¾åˆ°66.8%ï¼Œè¶…è¿‡æœªä½¿ç”¨ASPçš„DeepSeek-R1ï¼ˆ59.5%ï¼‰ã€‚
- åœ¨**PromptPipelineè®¾ç½®ä¸‹**ï¼š
  - Llama-3.3 70Bè¾¾åˆ°78.4%ï¼Œè¡¨æ˜ASPå¾®è°ƒä¹Ÿå¢å¼ºäº†æ¨¡å‹éµå¾ªå¤æ‚æŒ‡ä»¤çš„èƒ½åŠ›ã€‚
- **å°æ¨¡å‹ä¹Ÿèƒ½å—ç›Š**ï¼š
  - Llama-3.1 8Bä»0%æå‡è‡³46.8%ï¼ˆ+46.8ppï¼‰ï¼Œè¯´æ˜è¯¥æ–¹æ³•å¯æœ‰æ•ˆâ€œæ•™ä¼šâ€å°å‹LLMæŒæ¡ASPç¼–ç ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆTable 2ï¼‰**

| é…ç½® | LogicPuzzles Acc (%) | Î” vs SFT |
|------|------------------------|----------|
| Base (greedy) | 31.0 | â€” |
| +SFT (greedy) | 55.4 | +24.4 |
| +SFT + best-of-5 | 62.7 | +7.3 |
| +Regeneration | 64.6 | +9.2 |
| +Backtracking | 62.7 | +7.3 |
| **+Reg + Back (full TT)** | **66.8** | **+11.4** |
| N=10 | 65.1 | +9.7 |
| N=25 | **69.2** | **+13.8** |

> ğŸ” **å‘ç°**ï¼š
> - Best-of-Né‡‡æ ·å¸¦æ¥æ˜¾è‘—å¢ç›Šï¼ˆ+7.3ppï¼‰
> - **Re-generation å’Œ Backtracking ç»“åˆæ•ˆæœæœ€å¥½**ï¼ˆ+11.4ppï¼‰
> - å¢åŠ Nå¯ç»§ç»­æç‚¹ï¼Œä½†éœ€æƒè¡¡è®¡ç®—æˆæœ¬

æ­¤å¤–ï¼Œä½œè€…è¿˜å°†è¯¥æ¨ç†æ–¹æ³•åº”ç”¨äº**GPT-4.1-mini**ï¼ˆæœªç»ASPå¾®è°ƒï¼‰ï¼Œç»“æœæ˜¾ç¤ºå…¶å‡†ç¡®ç‡ä»39.2%æå‡è‡³55.4%ï¼ˆ+16.2ppï¼‰ï¼Œè¯æ˜è¯¥æ–¹æ³•å…·æœ‰æ™®é€‚æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **State-of-the-art open-weight LLMs åœ¨åŸå§‹çŠ¶æ€ä¸‹å‡ ä¹æ— æ³•æ­£ç¡®ç”ŸæˆASPä»£ç **ï¼ˆå¦‚Llama-3.1 8Båˆå§‹æ€§èƒ½ä¸º0%ï¼‰ã€‚
2. âœ… **Solver-in-the-loop èƒ½è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®**ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ï¼Œå®ç°è‡ªæˆ‘ç›‘ç£å¼instruction tuningã€‚
3. âœ… **SFT æ˜¾è‘—æå‡ASPç¼–ç èƒ½åŠ›**ï¼Œå°¤å…¶å¯¹å¤§æ¨¡å‹ï¼ˆ70Bï¼‰å’Œé«˜å¤æ‚åº¦é—®é¢˜æ•ˆæœæ˜æ˜¾ã€‚
4. âœ… **Test-time solver guidance æå¤§æé«˜é²æ£’æ€§**ï¼Œé€šè¿‡rewardæœºåˆ¶ç­›é€‰æœ€ä¼˜è·¯å¾„ï¼Œå¹¶å¯é€šè¿‡backtrackingæ¢å¤é”™è¯¯ã€‚
5. âœ… **æ–¹æ³•å…·å¤‡è‰¯å¥½æ³›åŒ–æ€§**ï¼šåœ¨æœªå‚ä¸è®­ç»ƒçš„GridPuzzlesä¸Šä»å–å¾—æ˜¾è‘—æå‡ï¼Œä¸”é€‚ç”¨äºä¸åŒæ¨¡å‹å®¶æ—ï¼ˆLlama/Qwen/GPTï¼‰ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- **ä¾èµ–å¤–éƒ¨solverè°ƒç”¨**ï¼šæ¯æ¬¡ç”Ÿæˆéƒ½éœ€è¦è°ƒç”¨clingoç­‰ASP solverï¼Œå¢åŠ å»¶è¿Ÿå’Œç³»ç»Ÿå¤æ‚æ€§ã€‚
- **è®¡ç®—å¼€é”€è¾ƒå¤§**ï¼šbest-of-Nå’Œbacktrackingä¼šæ˜¾è‘—å¢åŠ tokenç”Ÿæˆé‡ï¼ˆè§Figure 2ï¼‰ï¼Œä¸é€‚åˆä½å»¶è¿Ÿåœºæ™¯ã€‚
- **å¯¹solveré”™è¯¯æ•æ„Ÿ**ï¼šè‹¥solverè¯¯åˆ¤ï¼ˆå¦‚å°†æ­£ç¡®ç¼–ç æ ‡è®°ä¸ºunsatisfiableï¼‰ï¼Œä¼šå½±å“è®­ç»ƒæ•°æ®è´¨é‡ã€‚
- **æœªèƒ½æŒæ¡é«˜çº§é‡æ„æŠ€å·§**ï¼šä¾‹å¦‚å°†å…¨å±€å”¯ä¸€æ€§çº¦æŸæ‹†åˆ†ä¸ºå¤šä¸ªå­çº¦æŸï¼Œæ¨¡å‹ä»æœªå­¦ä¼šæ­¤ç±»ä¼˜åŒ–ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- æ¢ç´¢**Reinforcement Learning (RL)** æ¡†æ¶ï¼Œå°†solver feedbackä½œä¸ºrewardä¿¡å·è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒã€‚
- æ‰©å±•rewardå‡½æ•°ï¼Œå¼•å…¥**åŠ æƒè¯¯å·®ç±»å‹**ï¼ˆweighted error typesï¼‰ï¼ŒåŒºåˆ†è½»é‡é”™è¯¯ã€‚
- æ”¹è¿›backboneæ¨¡å‹æ¶æ„ï¼Œä½¿å…¶åŸç”Ÿæ”¯æŒâ€œsymbolic reasoning traceâ€è¾“å‡ºã€‚
- åº”ç”¨äºå…¶ä»–å£°æ˜å¼ç¼–ç¨‹è¯­è¨€ï¼ˆå¦‚PROLOGã€MiniZincï¼‰æˆ–è§„åˆ’è¯­è¨€ï¼ˆPDDLï¼‰ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬æ–‡æå‡ºäº†ä¸€ç§**solver-in-the-loop**æ¡†æ¶ï¼Œåˆ©ç”¨ASP solverçš„è¯­ä¹‰åé¦ˆæ¥æŒ‡å¯¼LLMçš„è®­ç»ƒä¸æ¨ç†ï¼Œå®ç°äº†æ— éœ€äººå·¥æ ‡æ³¨çš„é«˜è´¨é‡ASPä»£ç ç”Ÿæˆï¼Œåœ¨å¤šä¸ªæ¨¡å‹å’Œæ•°æ®é›†ä¸Šå‡å–å¾—æ˜¾è‘—æ€§èƒ½æå‡ï¼Œå±•ç¤ºäº†ç¥ç»ç¬¦å·ç³»ç»Ÿï¼ˆneuro-symbolic systemï¼‰åœ¨å¤æ‚é€»è¾‘ä»»åŠ¡ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚

</details>

---

### 15. [Turn-PPO: Turn-Level Advantage Estimation with PPO for Improved Multi-Turn RL in Agentic LLMs](https://arxiv.org/abs/2512.17008)

**Authors**: Junbo Li, Peng Zhou, Rui Meng, Meet P. Vadera, Lihong Li, Yang Li  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.17008v1  

#### Abstract
Reinforcement learning (RL) has re-emerged as a natural approach for training interactive LLM agents in real-world environments. However, directly applying the widely used Group Relative Policy Optimization (GRPO) algorithm to multi-turn tasks exposes notable limitations, particularly in scenarios r...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šTurn-PPO: Turn-Level Advantage Estimation with PPO for Improved Multi-Turn RL in Agentic LLMs**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰åœ¨å¤šè½®äº¤äº’ä»»åŠ¡ï¼ˆmulti-turn tasksï¼‰ä¸­ï¼Œä¸»æµçš„å¼ºåŒ–å­¦ä¹ ç®—æ³• **GRPO**ï¼ˆGroup Relative Policy Optimizationï¼‰å­˜åœ¨æ˜¾è‘—ç¼ºé™·ï¼š
- **ä¼˜åŠ¿ä¼°è®¡ä¸ç¨³å®š**ï¼šGRPO ä¾èµ–äºå¯¹å¤šä¸ªè½¨è¿¹è¿›è¡Œé‡‡æ ·å¹¶åŸºäºç»„å†…å½’ä¸€åŒ–å¥–åŠ±æ¥ä¼°è®¡ä¼˜åŠ¿ï¼ˆadvantageï¼‰ï¼Œå¯¼è‡´é«˜æ–¹å·®ï¼Œå°¤å…¶åœ¨ç¯å¢ƒä¸å¯æ§æˆ–å¤šè½®äº¤äº’ä¸­æ›´ä¸ºä¸¥é‡ã€‚
- **ä¼˜åŠ¿åˆ†é…ä¸å‡†ç¡®**ï¼šå°†ç›¸åŒçš„è½¨è¿¹çº§ä¼˜åŠ¿å€¼åº”ç”¨äºæ‰€æœ‰ tokenï¼Œå¿½ç•¥äº†ä¸åŒâ€œè½®æ¬¡â€ï¼ˆturnï¼‰å¯¹æœ€ç»ˆå¥–åŠ±çš„è´¡çŒ®å·®å¼‚ï¼Œé€ æˆä¿¡ç”¨åˆ†é…ï¼ˆcredit assignmentï¼‰å¤±çœŸã€‚
- **è®­ç»ƒå´©æºƒé£é™©é«˜**ï¼šåœ¨é•¿æ¨ç†é“¾æˆ–å¤šè½®å†³ç­–ä»»åŠ¡ä¸­ï¼ŒGRPO å®¹æ˜“å‡ºç°è®­ç»ƒä¸ç¨³å®šç”šè‡³å®Œå…¨å´©æºƒã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**
ä½œè€…æå‡ºäº† **turn-PPO**ï¼Œä¸€ç§åŸºäº **Proximal Policy Optimization (PPO)** çš„æ”¹è¿›ç®—æ³•ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š
- **å¼•å…¥ turn-level MDP å»ºæ¨¡**ï¼šä¸åŒäºä¼ ç»Ÿå°†æ¯ä¸ª token è§†ä¸ºä¸€ä¸ªçŠ¶æ€-åŠ¨ä½œå¯¹çš„ **token-MDP**ï¼Œturn-PPO å°†æ¯ä¸€è½®å®Œæ•´çš„è¾“å…¥-è¾“å‡ºï¼ˆå³ä¸€æ¬¡ç”¨æˆ·-æ¨¡å‹äº¤äº’ï¼‰è§†ä¸ºä¸€ä¸ªçŠ¶æ€-åŠ¨ä½œå¯¹ï¼Œæ„å»º **turn-MDP**ã€‚
- **turn-level ä¼˜åŠ¿ä¼°è®¡**ï¼šåˆ©ç”¨å¯å­¦ä¹ çš„ critic æ¨¡å‹ï¼Œåœ¨ turn ç²’åº¦ä¸Šè®¡ç®—ä¼˜åŠ¿å€¼ï¼Œå®ç°æ›´ç²¾ç¡®çš„ä¿¡ç”¨åˆ†é…ã€‚
- **ç»Ÿä¸€æ¡†æ¶ä¸‹çš„ç®—æ³•æ¯”è¾ƒ**ï¼šåœ¨ç»Ÿä¸€æ¡†æ¶ä¸‹åˆ†æäº† GRPOã€token-PPO å’Œ turn-PPO çš„å·®å¼‚ï¼Œæ­ç¤ºäº† token-level å»ºæ¨¡åœ¨å¤šè½®ä»»åŠ¡ä¸­çš„ç»“æ„æ€§ç¼ºé™·ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **æ›´é«˜çš„è®­ç»ƒç¨³å®šæ€§**ï¼šPPO çš„ critic æ¨¡å‹é€šè¿‡ GAEï¼ˆGeneralized Advantage Estimationï¼‰æä¾›æ›´ç¨³å®šçš„ä¼˜åŠ¿ä¼°è®¡ï¼Œé¿å…äº† GRPO çš„é‡‡æ ·æ–¹å·®é—®é¢˜ã€‚
- **æ›´åˆç†çš„ä¿¡ç”¨åˆ†é…**ï¼šturn-level å»ºæ¨¡ä½¿ critic èƒ½æ›´å¥½æ•æ‰ä¸åŒè½®æ¬¡çš„é‡è¦æ€§ï¼Œæå‡ç­–ç•¥ä¼˜åŒ–æ•ˆç‡ã€‚
- **æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›**ï¼šæ— éœ€æ‰‹åŠ¨è®¾è®¡ turn-level æƒé‡æˆ–è¿‡æ»¤æœºåˆ¶ï¼ˆå¦‚ StarPO-sã€GiGPOï¼‰ï¼Œå…·æœ‰æ›´å¥½çš„é€šç”¨æ€§ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **WebShop**ï¼šä¸€ä¸ªæ¨¡æ‹Ÿåœ¨çº¿è´­ç‰©çš„æ–‡æœ¬ç¯å¢ƒï¼Œè¦æ±‚æ¨¡å‹é€šè¿‡æœç´¢ã€ç‚¹å‡»å•†å“ã€é€‰æ‹©å±æ€§ã€è´­ä¹°ç­‰å¤šæ­¥æ“ä½œå®Œæˆä»»åŠ¡ï¼Œæµ‹è¯•æ¨¡å‹çš„é•¿æœŸè§„åˆ’ä¸å·¥å…·è°ƒç”¨èƒ½åŠ›ã€‚
- **Sokoban**ï¼šç»å…¸çš„æ¨ç®±å­æ¸¸æˆï¼Œéœ€è¦ç©ºé—´æ¨ç†ä¸é•¿ç¨‹è§„åˆ’ï¼Œä»…æä¾›ç¨€ç–ç»ˆç«¯å¥–åŠ±ï¼ŒæŒ‘æˆ˜æ¨¡å‹çš„æ¢ç´¢ä¸å†³ç­–ä¸€è‡´æ€§ã€‚

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**
- **æ¨¡å‹åŸºç¡€**ï¼šä½¿ç”¨ Qwen2.5-3Bã€Qwen2.5-7B å’Œ Qwen3-1.7B ä½œä¸º base modelã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **å¹³å‡å¥–åŠ±ï¼ˆAverage Rewardï¼‰**ï¼šä¸»è¦æ€§èƒ½æŒ‡æ ‡ã€‚
  - **è®­ç»ƒç¨³å®šæ€§**ï¼šæ˜¯å¦å‘ç”Ÿè®­ç»ƒå´©æºƒï¼ˆcrashï¼‰ã€‚
  - **æ¶ˆèå®éªŒ**ï¼šåˆ†æå­¦ä¹ ç‡ã€batch å¤šæ ·æ€§ã€GAE å‚æ•°ï¼ˆÎ³, Î»ï¼‰ç­‰å½±å“ã€‚
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - ä½¿ç”¨ RAGEN æ¡†æ¶å®ç°ã€‚
  - å¯¹ Qwen3 æµ‹è¯•äº†å¼€å¯/å…³é—­ reasoning æ¨¡å¼çš„æ€§èƒ½å·®å¼‚ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | ç±»å‹ | MDP ç²’åº¦ | ä¼˜åŠ¿ä¼°è®¡æ–¹å¼ |
|------|------|----------|----------------|
| **GRPO** | On-policy | token-level | ç»„å†…å½’ä¸€åŒ–å¥–åŠ±ï¼ˆsample-basedï¼‰ |
| **token-PPO** | Actor-Critic | token-level | Critic + GAEï¼ˆtoken-levelï¼‰ |
| **turn-PPO**ï¼ˆæœ¬æ–‡ï¼‰ | Actor-Critic | **turn-level** | Critic + GAEï¼ˆ**turn-level**ï¼‰ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2ï¼‰**

| Environment | Model | GRPO | token-PPO | **turn-PPO** |
|------------|-------|------|-----------|-------------|
| WebShop | Qwen2.5-3B | 0.72 | 0.73 | **0.75** |
| WebShop | Qwen3-1.7B (no think) | 0.78 | 0.77 | **0.80** |
| WebShop | Qwen3-1.7B (think) | **Crash** | 0.54 | **0.55** |
| Sokoban | Qwen2.5-3B | **Crash** | 1.93 | **2.29** |
| Sokoban | Qwen2.5-7B | **Crash** | 2.90 | **3.74** |

> æ³¨ï¼šâ€œCrashâ€ è¡¨ç¤ºè®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°å´©æºƒï¼Œæ— æ³•æ”¶æ•›ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **turn-PPO åœ¨æ‰€æœ‰ç¨³å®šè¿è¡Œçš„ä»»åŠ¡ä¸­å‡ä¼˜äºæˆ–æŒå¹³äºå…¶ä»–æ–¹æ³•**ã€‚
- **GRPO åœ¨å¤æ‚ä»»åŠ¡ï¼ˆå°¤å…¶æ˜¯ Sokoban å’Œ Qwen3 é•¿æ¨ç†ï¼‰ä¸­é¢‘ç¹å´©æºƒ**ï¼Œè€Œ PPO ç±»æ–¹æ³•èƒ½æœ‰æ•ˆé¿å…ã€‚
- **token-PPO è™½æ¯” GRPO ç¨³å®šï¼Œä½†ä»å¼±äº turn-PPO**ï¼Œè¯´æ˜ turn-level å»ºæ¨¡æœ¬èº«å¸¦æ¥å¢ç›Šã€‚
- åœ¨ Qwen3 å¼€å¯ reasoning æ—¶ï¼ŒGRPO å®Œå…¨å¤±è´¥ï¼Œè€Œ turn-PPO ä»èƒ½ç»´æŒè®­ç»ƒå¹¶å–å¾—åˆç†æ€§èƒ½ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
- **å­¦ä¹ ç‡æ•æ„Ÿæ€§**ï¼šcritic å­¦ä¹ ç‡éœ€ä¸º actor çš„ 5â€“10 å€ï¼ˆå®éªŒè®¾ä¸º 1e-5 vs 1e-6ï¼‰ï¼Œå¦åˆ™è®­ç»ƒæ˜“åœæ»æˆ–å‘æ•£ã€‚
- **batch å¤šæ ·æ€§ï¼ˆGï¼‰**ï¼š
  - GRPO å—ç›Šäºæ¯é—®é¢˜å¤šé‡‡æ ·ï¼ˆhigh Gï¼‰ï¼Œä»¥é™ä½ä¼˜åŠ¿ä¼°è®¡æ–¹å·®ã€‚
  - PPO æ›´åå¥½é«˜é—®é¢˜å¤šæ ·æ€§ï¼ˆlow Gï¼‰ï¼Œæœ‰åŠ©äº critic æ³›åŒ–ã€‚
- **minibatch size ä¸ epoch**ï¼š
  - å‡å° minibatch size å¹¶å¢åŠ æ›´æ–°æ¬¡æ•°ï¼ˆepochsï¼‰æ¯”å•æ¬¡å¤§ batch æ›´æ–°æ›´é«˜æ•ˆã€‚
  - ä½† epochs ä¸å®œè¿‡å¤šï¼Œä»¥é˜²è¿‡æ‹Ÿåˆã€‚
- **GAE å‚æ•°ï¼ˆÎ³, Î»ï¼‰**ï¼š
  - **turn-PPO æ”¯æŒçµæ´»è°ƒæ•´ Î³ å’Œ Î»**ï¼ˆå®éªŒæœ€ä¼˜ï¼šÎ³=0.99, Î»=0.9ï¼‰ã€‚
  - token-PPO ä¸­è¿™äº›å‚æ•°å¿…é¡»è®¾ä¸º 1.0ï¼Œå¦åˆ™æ—©æœŸ token ä¼˜åŠ¿è¢«è¿‡åº¦è¡°å‡ï¼Œå¯¼è‡´è®­ç»ƒå¤±è´¥ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **GRPO åœ¨å¤šè½®ä»»åŠ¡ä¸­å­˜åœ¨æ ¹æœ¬æ€§ç¼ºé™·**ï¼šå…¶åŸºäºé‡‡æ ·çš„ä¼˜åŠ¿ä¼°è®¡åœ¨åŠ¨æ€ç¯å¢ƒä¸­æ–¹å·®å¤§ï¼Œä¸” uniform advantage åˆ†é…ä¸åˆç†ï¼Œå¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚
2. **PPO æ˜¯æ›´ä¼˜é€‰æ‹©**ï¼šå¾—ç›Šäºå¯å­¦ä¹ çš„ critic å’Œ GAEï¼ŒPPO æä¾›æ›´ç¨³å®šã€ä½æ–¹å·®çš„ä¼˜åŠ¿ä¼°è®¡ï¼Œæ˜¾è‘—æå‡è®­ç»ƒé²æ£’æ€§ã€‚
3. **turn-level MDP å»ºæ¨¡è‡³å…³é‡è¦**ï¼šå°†æ¯è½®äº¤äº’è§†ä¸ºä¸€ä¸ªçŠ¶æ€-åŠ¨ä½œå¯¹ï¼Œèƒ½æ›´å¥½åœ°åŒ¹é…å¤šè½®ä»»åŠ¡çš„ç»“æ„ï¼Œæå‡ critic å­¦ä¹ æ•ˆç‡å’Œä¼˜åŠ¿ä¼°è®¡å‡†ç¡®æ€§ã€‚
4. **turn-PPO æ˜¯å½“å‰å¤šè½® RL è®­ç»ƒçš„æœ€ä½³å®è·µä¹‹ä¸€**ï¼šåœ¨ WebShop å’Œ Sokoban ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨é•¿æ¨ç†å’Œå¤§æ¨¡å‹åœºæ™¯ä¸‹ä¼˜åŠ¿æ˜æ˜¾ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- å½“å‰ç ”ç©¶å±€é™äº **æ–‡æœ¬æ¨¡æ‹Ÿç¯å¢ƒ**ï¼ˆtext-only environmentsï¼‰ï¼Œæœªæ¶‰åŠçœŸå®ç½‘é¡µæˆ–ç‰©ç†äº¤äº’ã€‚
- å®éªŒä»…è¦†ç›–ä¸¤ä¸ªä»£è¡¨æ€§ä»»åŠ¡ï¼Œéœ€åœ¨æ›´å¤šå¤æ‚åœºæ™¯ï¼ˆå¦‚å¤šå·¥å…·åä½œã€å®æ—¶åé¦ˆï¼‰ä¸­éªŒè¯æ³›åŒ–æ€§ã€‚
- turn-PPO ä¾èµ– critic è®­ç»ƒï¼Œå¢åŠ äº†è®¡ç®—å¼€é”€ï¼ˆå°½ç®¡ä»ä¼˜äºå¤šæ¬¡é‡‡æ ·ï¼‰ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•åˆ° **çœŸå®ä¸–ç•Œ Web Agents** å’Œ **å…·èº«æ™ºèƒ½ä½“**ï¼ˆembodied agentsï¼‰çš„å¤æ‚äº¤äº’åœºæ™¯ã€‚
- æ¢ç´¢ **æ›´é«˜æ•ˆçš„ turn-level critic æ¶æ„** æˆ–è½»é‡åŒ–ç‰ˆæœ¬ã€‚
- ç»“åˆ **åˆ†å±‚å¼ºåŒ–å­¦ä¹ **ï¼ˆHierarchical RLï¼‰è¿›ä¸€æ­¥å»ºæ¨¡é•¿æœŸç›®æ ‡ä¸å­ä»»åŠ¡åˆ†è§£ã€‚
- ç ”ç©¶å¦‚ä½•è‡ªåŠ¨è¯†åˆ« turn è¾¹ç•Œï¼Œé€‚åº”éç»“æ„åŒ–å¯¹è¯æµã€‚

---

> **æ€»ç»“**ï¼š  
> è¯¥è®ºæ–‡ç³»ç»Ÿåœ°æ­ç¤ºäº† GRPO åœ¨å¤šè½® LLM ä»£ç†è®­ç»ƒä¸­çš„å±€é™æ€§ï¼Œå¹¶é‡æ–°ç¡®ç«‹äº† PPO çš„æœ‰æ•ˆæ€§ã€‚æå‡ºçš„ **turn-PPO** é€šè¿‡ **turn-level MDP å»ºæ¨¡** å®ç°äº†æ›´ç¨³å®šã€é«˜æ•ˆçš„ä¼˜åŠ¿ä¼°è®¡ï¼Œåœ¨å¤šä¸ªåŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºå¤šè½®äº¤äº’å¼ LLM çš„ RL è®­ç»ƒæä¾›äº†æ–°çš„æ ‡å‡†èŒƒå¼ã€‚

</details>

---

### 16. [Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows](https://arxiv.org/abs/2512.16969)

**Authors**: Wanghan Xu, Yuhao Zhou, Yifan Zhou, Qinglong Cao, Shuo Li, Jia Bu, Bo Liu, Yixin Chen, Xuming He, Xiangyu Zhao, Xiang Zhuang, Fengxiang Wang, Zhiwang Zhou, Qiantai Feng, Wenxuan Huang, Jiaqi Wei, Hao Wu, Yuejin Yang, Guangshuai Wang, Sheng Xu, Ziyan Huang, Xinyao Liu, Jiyao Liu, Cheng Tang, Wei Li, Ying Chen, Junzhi Ning, Pengfei Jiang, Chenglong Ma, Ye Du, Changkai Ji, Huihui Xu, Ming Hu, Jiangbin Zheng, Xin Chen, Yucheng Wu, Feifei Jiang, Xi Chen, Xiangru Tang, Yuchen Fu, Yingzhou Lu, Yuanyuan Zhang, Lihao Sun, Chengbo Li, Jinzhe Ma, Wanhao Liu, Yating Liu, Kuo-Cheng Wu, Shengdu Chai, Yizhou Wang, Ouwen Zhangjin, Chen Tang, Shufei Zhang, Wenbo Cao, Junjie Ren, Taoyong Cui, Zhouheng Yao, Juntao Deng, Yijie Sun, Feng Liu, Wangxu Wei, Jingyi Xu, Zhangrui Li, Junchao Gong, Zijie Guo, Zhiyu Yao, Zaoyu Chen, Tianhao Peng, Fangchen Yu, Bo Zhang, Dongzhan Zhou, Shixiang Tang, Jiaheng Liu, Fenghua Ling, Yan Lu, Yuchen Ren, Ben Fei, Zhen Zhao, Xinyu Gu, Rui Su, Xiao-Ming Wu, Weikang Si, Yang Liu, Hao Chen, Xiangchao Yan, Xue Yang, Junchi Yan, Jiamin Wu, Qihao Zheng, Chenhui Li, Zhiqiang Gao, Hao Kong, Junjun He, Mao Su, Tianfan Fu, Peng Ye, Chunfeng Song, Nanqing Dong, Yuqiang Li, Huazhu Fu, Siqi Sun, Lijing Cheng, Jintai Lin, Wanli Ouyang, Bowen Zhou, Wenlong Zhang, Lei Bai  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.16969v1  

#### Abstract
Despite advances in scientific AI, a coherent framework for Scientific General Intelligence (SGI)-the ability to autonomously conceive, investigate, and reason across scientific domains-remains lacking. We present an operational SGI definition grounded in the Practical Inquiry Model (PIM: Deliberati...

---

### 17. [Linear Personality Probing and Steering in LLMs: A Big Five Study](https://arxiv.org/abs/2512.17639)

**Authors**: Michel Frising, Daniel Balcells  
**Category**: cs.CL  
**Published**: 2025-12-22  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.17639v1  

#### Abstract
Large language models (LLMs) exhibit distinct and consistent personalities that greatly impact trust and engagement. While this means that personality frameworks would be highly valuable tools to characterize and control LLMs' behavior, current approaches remain either costly (post-training) or brit...

---

### 18. [Digitizing Nepal's Written Heritage: A Comprehensive HTR Pipeline for Old Nepali Manuscripts](https://arxiv.org/abs/2512.17111)

**Authors**: Anjali Sarawgi, Esteban Garces Arias, Christof Zotter  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.17111v1  

#### Abstract
This paper presents the first end-to-end pipeline for Handwritten Text Recognition (HTR) for Old Nepali, a historically significant but low-resource language. We adopt a line-level transcription approach and systematically explore encoder-decoder architectures and data-centric techniques to improve ...

---

### 19. [SHARP-QoS: Sparsely-gated Hierarchical Adaptive Routing for joint Prediction of QoS](https://arxiv.org/abs/2512.17262)

**Authors**: Suraj Kumar, Arvind Kumar, Soumi Chattopadhyay  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.17262v1  

#### Abstract
Dependable service-oriented computing relies on multiple Quality of Service (QoS) parameters that are essential to assess service optimality. However, real-world QoS data are extremely sparse, noisy, and shaped by hierarchical dependencies arising from QoS interactions, and geographical and network-...

---

### 20. [Alzheimer's Disease Brain Network Mining](https://arxiv.org/abs/2512.17276)

**Authors**: Alireza Moayedikia, Sara Fin  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.17276v1  

#### Abstract
Machine learning approaches for Alzheimer's disease (AD) diagnosis face a fundamental challenges. Clinical assessments are expensive and invasive, leaving ground truth labels available for only a fraction of neuroimaging datasets. We introduce Multi view Adaptive Transport Clustering for Heterogeneo...

---

### 21. [Estimating Spatially Resolved Radiation Fields Using Neural Networks](https://arxiv.org/abs/2512.17654)

**Authors**: Felix Lehner, Pasquale Lombardo, Susana Castillo, Oliver Hupe, Marcus Magnor  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.17654v1  

#### Abstract
We present an in-depth analysis on how to build and train neural networks to estimate the spatial distribution of scattered radiation fields for radiation protection dosimetry in medical radiation fields, such as those found in Interventional Radiology and Cardiology. Therefore, we present three dif...

---

### 22. [Spatially-informed transformers: Injecting geostatistical covariance biases into self-attention for spatio-temporal forecasting](https://arxiv.org/abs/2512.17696)

**Authors**: Yuri Calleo  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.17696v1  

#### Abstract
The modeling of high-dimensional spatio-temporal processes presents a fundamental dichotomy between the probabilistic rigor of classical geostatistics and the flexible, high-capacity representations of deep learning. While Gaussian processes offer theoretical consistency and exact uncertainty quanti...

---

### 23. [UniRel-R1: RL-tuned LLM Reasoning for Knowledge Graph Relational Question Answering](https://arxiv.org/abs/2512.17043)

**Authors**: Yinxu Tang, Chengsong Huang, Jiaxin Huang, William Yeoh  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.17043v1  

#### Abstract
Knowledge Graph Question Answering (KGQA) has traditionally focused on entity-centric queries that return a single answer entity. However, real-world queries are often relational, seeking to understand how entities are associated. In this work, we introduce relation-centric KGQA, a complementary set...

---

### 24. [Reinforcement Learning for Self-Improving Agent with Skill Library](https://arxiv.org/abs/2512.17102)

**Authors**: Jiongxiao Wang, Qiaojing Yan, Yawei Wang, Yijun Tian, Soumya Smruti Mishra, Zhichao Xu, Megha Gandhi, Panpan Xu, Lin Lee Cheong  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.17102v1  

#### Abstract
Large Language Model (LLM)-based agents have demonstrated remarkable capabilities in complex reasoning and multi-turn interactions but struggle to continuously improve and adapt when deployed in new environments. One promising approach is implementing skill libraries that allow agents to learn, vali...

---

### 25. [Large Language Models as Pok\'emon Battle Agents: Strategic Play and Content Generation](https://arxiv.org/abs/2512.17308)

**Authors**: Daksh Jain, Aarya Jain, Ashutosh Desai, Avyakt Verma, Ishan Bhanuka, Pratik Narang, Dhruv Kumar  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.17308v1  

#### Abstract
Strategic decision-making in Pok\'emon battles presents a unique testbed for evaluating large language models. Pok\'emon battles demand reasoning about type matchups, statistical trade-offs, and risk assessment, skills that mirror human strategic thinking. This work examines whether Large Language M...

---

### 26. [Seed-Prover 1.5: Mastering Undergraduate-Level Theorem Proving via Learning from Experience](https://arxiv.org/abs/2512.17260)

**Authors**: Jiangjie Chen, Wenxiang Chen, Jiacheng Du, Jinyi Hu, Zhicheng Jiang, Allan Jie, Xiaoran Jin, Xing Jin, Chenggang Li, Wenlei Shi, Zhihong Wang, Mingxuan Wang, Chenrui Wei, Shufa Wei, Huajian Xin, Fan Yang, Weihao Gao, Zheng Yuan, Tianyang Zhan, Zeyu Zheng, Tianxi Zhou, Thomas Hanwen Zhu  
**Category**: cs.CL  
**Published**: 2025-12-22  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.17260v1  

#### Abstract
Large language models have recently made significant progress to generate rigorous mathematical proofs. In contrast, utilizing LLMs for theorem proving in formal languages (such as Lean) remains challenging and computationally expensive, particularly when addressing problems at the undergraduate lev...

---

### 27. [Governance-Aware Hybrid Fine-Tuning for Multilingual Large Language Models](https://arxiv.org/abs/2512.17344)

**Authors**: Haomin Qi, Chengbo Huang, Zihan Dai, Yunkai Gao  
**Category**: cs.CL  
**Published**: 2025-12-22  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.17344v1  

#### Abstract
We present a governance-aware hybrid fine-tuning framework for multilingual, low-resource adaptation of large language models. The core algorithm combines gradient-aligned low-rank updates with structured orthogonal transformations through layer-wise mixing and introduces unitary constraints in sele...

---

### 28. [UCoder: Unsupervised Code Generation by Internal Probing of Large Language Models](https://arxiv.org/abs/2512.17385)

**Authors**: Jiajun Wu, Jian Yang, Wei Zhang, Lin Jing, Yuqing Ma, Ensheng Shi, Yuchi Ma, Zhoujun Li, Xianglong Liu  
**Category**: cs.CL  
**Published**: 2025-12-22  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.17385v1  

#### Abstract
Large language models (LLMs) have demonstrated remarkable capabilities in code generation tasks. However, their effectiveness heavily relies on supervised training with extensive labeled (e.g., question-answering pairs) or unlabeled datasets (e.g., code snippets), which are often expensive and diffi...

---

### 29. [Scalable Distributed Vector Search via Accuracy Preserving Index Construction](https://arxiv.org/abs/2512.17264)

**Authors**: Yuming Xu, Qianxi Zhang, Qi Chen, Baotong Lu, Menghao Li, Philip Adams, Mingqin Li, Zengzhong Li, Jing Liu, Cheng Li, Fan Yang  
**Category**: cs.DC  
**Published**: 2025-12-22  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.17264v1  

#### Abstract
Scaling Approximate Nearest Neighbor Search (ANNS) to billions of vectors requires distributed indexes that balance accuracy, latency, and throughput. Yet existing index designs struggle with this tradeoff. This paper presents SPIRE, a scalable vector index based on two design decisions. First, it i...

---

### 30. [QSMOTE-PGM/kPGM: QSMOTE Based PGM and kPGM for Imbalanced Dataset Classification](https://arxiv.org/abs/2512.16960)

**Authors**: Bikash K. Behera, Giuseppe Sergioli, Robert Giuntini  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.16960v1  

#### Abstract
Quantum-inspired machine learning (QiML) leverages mathematical frameworks from quantum theory to enhance classical algorithms, with particular emphasis on inner product structures in high-dimensional feature spaces. Among the prominent approaches, the Kernel Trick, widely used in support vector mac...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
