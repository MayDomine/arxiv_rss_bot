# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-13 05:57:11 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [ARCQuant: Boosting NVFP4 Quantization with Augmented Residual Channels for LLMs](https://arxiv.org/abs/2601.07475)

**Authors**: Haoqian Meng, Yilun Luo, Yafei Zhao, Wenyuan Liu, Peng Zhang, Xindian Ma  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2601.07475v1  

#### Abstract
The emergence of fine-grained numerical formats like NVFP4 presents new opportunities for efficient Large Language Model (LLM) inference. However, it is difficult to adapt existing Post-Training Quantization (PTQ) strategies to these formats: rotation-based methods compromise fine-grained block isol...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šARCQuant: Boosting NVFP4 Quantization with Augmented Residual Channels for LLMs**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ä¸­ï¼Œ**NVFP4** ç­‰ç»†ç²’åº¦æ•°å€¼æ ¼å¼è™½èƒ½æå‡æ•ˆç‡ï¼Œä½†ç›´æ¥åº”ç”¨äº **W4A4ï¼ˆæƒé‡å’Œæ¿€æ´»å‡ä¸º4ä½ï¼‰** åœºæ™¯æ—¶é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **æ—‹è½¬ç±»æ–¹æ³•**ï¼ˆå¦‚QuaRotï¼‰ç ´åäº†NVFP4çš„å—çº§éš”ç¦»ç‰¹æ€§ï¼Œå¯¼è‡´å±€éƒ¨åŠ¨æ€èŒƒå›´æ‰©å¤§ï¼›
- **å¹³æ»‘æŠ€æœ¯**ï¼ˆå¦‚SmoothQuantï¼‰éš¾ä»¥åº”å¯¹4ä½é‡åŒ–å¸¦æ¥çš„æ˜¾è‘—è¯¯å·®ï¼›
- **æ··åˆç²¾åº¦æ–¹æ³•**ï¼ˆå¦‚Atomï¼‰å› ç¡¬ä»¶è¦æ±‚ç»Ÿä¸€ç²¾åº¦è®¡ç®—è€Œæ— æ³•é«˜æ•ˆè¿è¡Œã€‚

è¿™äº›é™åˆ¶ä½¿å¾—ç°æœ‰PTQï¼ˆPost-Training Quantizationï¼‰ç­–ç•¥éš¾ä»¥å……åˆ†å‘æŒ¥NVFP4çš„æ½œåŠ›ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ï¼šARCQuant**
ä½œè€…æå‡ºäº† **ARCQuant**ï¼ˆAugmented Residual Channels Quantizationï¼‰ï¼Œä¸€ç§ä¸“ä¸ºNVFP4ä¼˜åŒ–çš„æ–°å‹PTQæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **é€šè¿‡å¢å¹¿æ®‹å·®é€šé“è¿›è¡Œè¯¯å·®è¡¥å¿**ï¼Œè€Œéä¾èµ–æ··åˆç²¾åº¦æˆ–å…¨å±€å˜æ¢ã€‚
- åœ¨è¾“å…¥å¼ é‡ä¸­è¯†åˆ«å‡ºä¸»å¯¼å¼‚å¸¸å€¼çš„é€šé“ï¼Œå¹¶å°†å…¶é‡åŒ–åçš„æ®‹å·®ä½œä¸ºâ€œå¢å¼ºé€šé“â€æ‹¼æ¥åˆ°åŸå§‹æ¿€æ´»çŸ©é˜µä¸­ã€‚
- æ•´ä¸ªè¡¥å¿è¿‡ç¨‹è¢«æ˜ å°„åˆ°çŸ©é˜µä¹˜æ³•çš„æ‰©å±•è§„çº¦ç»´åº¦ä¸Šï¼Œä»è€Œå¯ç›´æ¥ä½¿ç”¨æ ‡å‡†ã€é«˜åº¦ä¼˜åŒ–çš„ **GEMM kernel**ï¼ˆå¦‚CUTLASSï¼‰æ‰§è¡Œï¼Œæ— éœ€ä¿®æ”¹åº•å±‚è®¡ç®—é€»è¾‘ã€‚

è¯¥è®¾è®¡å®ç°äº†ï¼š
- **ä¸¥æ ¼ä¿æŒç»Ÿä¸€çš„NVFP4æ ¼å¼**ï¼Œå…¼å®¹ç¡¬ä»¶åŠ é€Ÿï¼›
- å°†è¯¯å·®è¡¥å¿é›†æˆè¿›å¸¸è§„çŸ©é˜µè¿ç®—ï¼Œå®ç°é«˜ååä¸ä½å»¶è¿Ÿã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ARCQuant | å…¶ä»–æ–¹æ³•ï¼ˆå¦‚Atomã€QuaRotï¼‰ |
|------|----------|-----------------------------|
| **ç¡¬ä»¶å…¼å®¹æ€§** | âœ… ä¿æŒç»Ÿä¸€NVFP4æ ¼å¼ï¼Œæ”¯æŒTensor CoreåŠ é€Ÿ | âŒ æ··åˆç²¾åº¦ç ´åç»Ÿä¸€æ€§ï¼Œæ— æ³•é«˜æ•ˆåˆ©ç”¨ç¡¬ä»¶ |
| **å—éš”ç¦»ä¿æŠ¤** | âœ… æ˜¾å¼éš”ç¦»å¼‚å¸¸é€šé“ï¼Œä¿ç•™ç»†ç²’åº¦ä¼˜åŠ¿ | âŒ æ—‹è½¬æ“ä½œä¼ æ’­å¼‚å¸¸å€¼ï¼Œç ´åéš”ç¦» |
| **å®ç°å¤æ‚åº¦** | âœ… åˆ©ç”¨æ ‡å‡†GEMM kernelï¼Œéƒ¨ç½²ç®€å• | âŒ éœ€å®šåˆ¶kernelæˆ–å¤æ‚å†…å­˜å¯¹é½ |
| **ç²¾åº¦è¡¨ç°** | âœ… æ¥è¿‘W4A8æ°´å¹³ï¼Œä¼˜äºæ‰€æœ‰W4A4åŸºçº¿ | âš ï¸ å¤šæ•°ä»…æ¥è¿‘æˆ–ä½äºW4A4 RTN |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **æ ¡å‡†æ•°æ®**ï¼š`WikiText2`ï¼ˆ128ä¸ªæ ·æœ¬ï¼Œåºåˆ—é•¿åº¦2048ï¼‰
- **è¯„ä¼°ä»»åŠ¡**ï¼š
  - **é€šç”¨èƒ½åŠ›**ï¼š`ARC-C`, `HellaSwag`, `PIQA`, `Winograde`, `LAMBADA`
  - **å¤šä»»åŠ¡ç†è§£**ï¼š`MMLU`ï¼ˆ5-shotï¼‰
  - **ä»£ç ç”Ÿæˆ**ï¼š`HumanEval`, `MBPP`
  - **æ•°å­¦æ¨ç†**ï¼š`GSM8K`, `CMATH`
  - **å›°æƒ‘åº¦**ï¼š`WikiText2 PPL`

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**
- **æ¨¡å‹**ï¼š`Llama3.1-8B`, `Qwen2.5-7B`, `Qwen2.5-32B`, `Qwen2.5-Coder-7B-Instruct`, `Qwen2.5-Math-7B-Instruct`
- **é‡åŒ–é…ç½®**ï¼šç›®æ ‡ä¸º **W4A4**ï¼Œé‡‡ç”¨ **NVFP4** æ ¼å¼ï¼ˆblock size=16ï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - å‡†ç¡®ç‡ï¼ˆzero/few-shotï¼‰
  - å›°æƒ‘åº¦ï¼ˆPPLï¼‰
  - æ¨ç†å»¶è¿Ÿï¼ˆprefill latencyï¼‰
  - å†…å­˜å ç”¨
  - é€Ÿåº¦æå‡ï¼ˆspeedupï¼‰

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ç±»å‹ | æ–¹æ³• |
|------|------|
| åŸºç¡€é‡åŒ– | `FP16`, `W4A4 RTN`ï¼ˆINT4/MXFP4/NVFP4ï¼‰, `W4A8+RTN` |
| é«˜çº§PTQ | `FlatQuant`, `Atom` |
| å¯é€‚é…æ–¹æ³• | `SmoothQuant`, `QuaRot`ï¼ˆadapted to NVFP4ï¼‰ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **è¡¨1 & è¡¨2ï¼šä¸»æµæ¨¡å‹ä¸Šçš„å‡†ç¡®ç‡ä¸PPLè¡¨ç°**
| æ¨¡å‹ | æ–¹æ³• | PPL â†“ | å¹³å‡å‡†ç¡®ç‡ â†‘ |
|------|------|--------|--------------|
| Llama3.1-8B | FP16 | 6.24 | 72.56 |
| | W4A8+RTN | 7.07 | 70.59 |
| | **ARCQuant** | **6.87** | **70.90** |
| Qwen2.5-7B | FP16 | 6.85 | 70.97 |
| | W4A8+RTN | 7.44 | 69.15 |
| | **ARCQuant** | **7.28** | **70.28** |

> âœ… **ARCQuantåœ¨å¤šä¸ªæ¨¡å‹ä¸Šè¶…è¶ŠW4A8åŸºçº¿ï¼Œåœ¨PPLå’Œä¸‹æ¸¸ä»»åŠ¡ä¸Šé€¼è¿‘FP16æ€§èƒ½ã€‚**

#### **è¡¨3ï¼šä»£ç ç”Ÿæˆæ€§èƒ½ï¼ˆQwen2.5-Coder-7B-Instructï¼‰**
| æ–¹æ³• | HumanEval @1 | MBPP @1 |
|------|---------------|---------|
| FP16 | 84.1 | 80.4 |
| Atom | 80.5 | 74.5 |
| **ARCQuant** | **86.0** | **79.9** |

> âœ… **ARCQuantä¸ä»…æœªæŸå¤±æ€§èƒ½ï¼Œåè€Œåœ¨ä»£ç ç”Ÿæˆä»»åŠ¡ä¸Šè¶…è¿‡FP16ï¼**

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- åœ¨æ‰€æœ‰W4A4æ–¹æ³•ä¸­ï¼Œ**ARCQuantå…¨é¢é¢†å…ˆ**ï¼Œå°¤å…¶åœ¨å¤„ç†æ¿€æ´»å¼‚å¸¸å€¼å¯†é›†å±‚æ—¶æ•ˆæœæ˜¾è‘—ï¼ˆè§Figure 3ï¼‰ã€‚
- ç›¸æ¯”ä¹‹ä¸‹ï¼š
  - `QuaRot`ï¼ˆåŸºäºHadamardå˜æ¢ï¼‰åœ¨NVFP4ä¸Šè¡¨ç°é€€åŒ–ï¼ŒéªŒè¯äº†æ—‹è½¬ä¼šç ´åå—éš”ç¦»ï¼›
  - `SmoothQuant` æ”¹è¿›æœ‰é™ï¼Œå—é™äº4ä½æƒé‡è¡¨è¾¾èƒ½åŠ›ï¼›
  - `Atom` å› æ··åˆç²¾åº¦ä¸å…¼å®¹Blackwellæ¶æ„ï¼Œæ€§èƒ½ä¸‹é™æ˜æ˜¾ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **1. æ³›åŒ–æ€§æµ‹è¯•ï¼ˆINT4 / MXFP4ï¼‰**
| æ–¹æ³• | INT4 PPL â†“ | MXFP4 PPL â†“ |
|------|------------|-------------|
| RTN | 8.84 | 7.86 |
| **ARCQuant** | **7.95** | **7.50** |

> å³ä½¿ä¸åœ¨NVFP4ä¸‹ï¼ŒARCQuantä»èƒ½å¸¦æ¥æ˜¾è‘—æ”¶ç›Šï¼Œè¯´æ˜å…¶æ®‹å·®è¡¥å¿æœºåˆ¶å…·æœ‰æ™®é€‚æ€§ã€‚

#### **2. æ ¡å‡†é²æ£’æ€§**
ä½¿ç”¨ä¸åŒé¢†åŸŸæ•°æ®ï¼ˆ`C4`, `WikiText2`, `HumanEval`ï¼‰è¿›è¡Œæ ¡å‡†ï¼ŒARCQuantæ€§èƒ½æ³¢åŠ¨æå°ï¼ˆPPLå˜åŒ– < 0.03ï¼‰ï¼Œè¡¨æ˜å…¶å¯¹æ ¡å‡†æ•°æ®é€‰æ‹©ä¸æ•æ„Ÿã€‚

#### **3. æ•ˆç‡åˆ†æ**
- **GEMMå»¶è¿Ÿå¢é•¿çº¿æ€§äºå¢å¼ºé€šé“æ•°S**ï¼Œä½†åœ¨å…¸å‹èŒƒå›´ï¼ˆS â‰¤ 512ï¼‰å†…å¼€é”€æä½ï¼›
- ç›¸æ¯”FP16ï¼š
  - **å†…å­˜é™ä½1.5Ã—â€“2.8Ã—**
  - **é¢„å¡«å……é€Ÿåº¦æå‡2.0Ã—â€“3.5Ã—**ï¼ˆRTX 5090ä¸ŠLlama3.1-8Bè¾¾3.5Ã—ï¼‰
- ç›¸æ¯”æ— è¡¥å¿çš„NVFP4ï¼Œå»¶è¿Ÿä»…å¢åŠ 3%â€“9%ï¼Œè¯æ˜èåˆkernelé«˜æ•ˆã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **NVFP4çš„æ½œåŠ›éœ€ä¸“ç”¨ç®—æ³•é‡Šæ”¾**ï¼šä¼ ç»ŸPTQæ–¹æ³•ï¼ˆæ—‹è½¬ã€æ··åˆç²¾åº¦ï¼‰ä¸NVFP4ç¡¬ä»¶ç‰¹æ€§å†²çªï¼Œæ— æ³•æœ‰æ•ˆåˆ©ç”¨å…¶ç»†ç²’åº¦ä¼˜åŠ¿ã€‚
2. **æ®‹å·®é€šé“å¢å¹¿æ˜¯ä¸€ç§ç¡¬ä»¶å‹å¥½çš„è¡¥å¿èŒƒå¼**ï¼šå°†è¯¯å·®è¡¥å¿è½¬åŒ–ä¸ºè¾“å…¥ç»´åº¦æ‰©å±•ï¼Œå¯åœ¨ä¸ç‰ºç‰²ååçš„å‰æä¸‹å®ç°é«˜ä¿çœŸé‡å»ºã€‚
3. **ç†è®ºè¯¯å·®ç•Œåª²ç¾MXFP8**ï¼šåŒé˜¶æ®µé‡åŒ–æœºåˆ¶çš„æœ€åæƒ…å†µè¯¯å·®ä¸Šç•Œä¸æ ‡å‡†8ä½æ ¼å¼ç›¸å½“ï¼Œè§£é‡Šäº†å…¶é«˜ç²¾åº¦è¡¨ç°ã€‚
4. **å®é™…éƒ¨ç½²é«˜æ•ˆå¯è¡Œ**ï¼šé€šè¿‡èåˆkernelï¼ˆé‡æ’åº + RMSNorm + é‡åŒ– + æ®‹å·®è®¡ç®—ï¼‰ï¼Œå®ç°ç«¯åˆ°ç«¯ä»…4.9%é¢å¤–å¼€é”€ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
| å±€é™ | è¯´æ˜ |
|------|------|
| **ä¾èµ–ç¦»çº¿æ ¡å‡†** | é€šé“é‡æ’åºå’ŒSçš„é€‰æ‹©åŸºäºæ ¡å‡†æ•°æ®ï¼Œå‡è®¾åˆ†å¸ƒç¨³å®šï¼›æç«¯OODè¾“å…¥å¯èƒ½å½±å“æ•ˆæœ |
| **ç¡¬ä»¶ä¾èµ–æ€§å¼º** | å½“å‰é’ˆå¯¹NVIDIA Blackwellæ¶æ„è®¾è®¡ï¼Œä¾èµ–NVFP4åŸç”Ÿæ”¯æŒï¼›æ—§æ¶æ„åªèƒ½æ¨¡æ‹Ÿæ€§èƒ½ |
| **æƒé‡é‡åŒ–è¾ƒåŸºç¡€** | æƒé‡é‡‡ç”¨RTNç­–ç•¥ï¼Œæœªç»“åˆGPTQ/AWQç­‰å…ˆè¿›æ–¹æ³•ï¼Œä»æœ‰æå‡ç©ºé—´ |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•è‡³ **sub-4-bitæ ¼å¼**ï¼ˆå¦‚INT2/NVFP2ï¼‰
- ç»“åˆ **å…ˆè¿›çš„æƒé‡é‡åŒ–ç®—æ³•**ï¼ˆå¦‚GPTQã€AWQï¼‰æ„å»ºå…¨æ¨¡å‹æ··åˆè¡¥å¿æ–¹æ¡ˆ
- é›†æˆè‡³ç”Ÿäº§çº§æ¨ç†å¼•æ“ï¼ˆå¦‚ **vLLM**ï¼‰ä»¥éªŒè¯çœŸå®åœºæ™¯ä¸‹çš„æ•ˆç‡
- æ¢ç´¢ **åŠ¨æ€è‡ªé€‚åº”Sé€‰æ‹©æœºåˆ¶**ï¼Œæå‡å¯¹è¾“å…¥å˜åŒ–çš„é²æ£’æ€§

---

> ğŸ”— **å¼€æºåœ°å€**ï¼šhttps://github.com/actypedef/ARCQuant  
> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼šARCQuanté€šè¿‡â€œç”¨å°‘é‡è®¡ç®—ç»´åº¦æ¢é«˜ä¿çœŸåº¦â€çš„æ€æƒ³ï¼Œåœ¨ä¸¥æ ¼éµå®ˆNVFP4ç¡¬ä»¶çº¦æŸçš„åŒæ—¶ï¼Œå®ç°äº†W4A4é‡åŒ–ä¸‹çš„SOTAç²¾åº¦ä¸æ˜¾è‘—æ¨ç†åŠ é€Ÿã€‚

</details>

---

### 2. [d3LLM: Ultra-Fast Diffusion LLM using Pseudo-Trajectory Distillation](https://arxiv.org/abs/2601.07568)

**Authors**: Yu-Yang Qian, Junda Su, Lanxiang Hu, Peiyuan Zhang, Zhijie Deng, Peng Zhao, Hao Zhang  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.07568v1  

#### Abstract
Diffusion large language models (dLLMs) offer capabilities beyond those of autoregressive (AR) LLMs, such as parallel decoding and random-order generation. However, realizing these benefits in practice is non-trivial, as dLLMs inherently face an accuracy-parallelism trade-off. Despite increasing int...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šd3LLM: Ultra-Fast Diffusion LLM using Pseudo-Trajectory Distillation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
**dLLM**ï¼ˆdiffusion large language modelsï¼‰è™½ç„¶å…·å¤‡å¹¶è¡Œè§£ç ã€é”™è¯¯çº æ­£å’Œéšæœºé¡ºåºç”Ÿæˆç­‰è¶…è¶Šä¼ ç»Ÿ**AR**ï¼ˆautoregressiveï¼‰æ¨¡å‹çš„èƒ½åŠ›ï¼Œä½†åœ¨å®è·µä¸­é¢ä¸´ä¸€ä¸ªæ ¹æœ¬æ€§çš„**accuracy-parallelism trade-off**ï¼ˆå‡†ç¡®ç‡-å¹¶è¡Œåº¦æƒè¡¡ï¼‰ï¼š
- è¿½æ±‚é«˜å¹¶è¡Œåº¦å¾€å¾€å¯¼è‡´å‡†ç¡®ç‡ä¸‹é™ï¼›
- ç»´æŒé«˜å‡†ç¡®ç‡åˆ™é™åˆ¶äº†è§£ç é€Ÿåº¦ã€‚

ç°æœ‰æ–¹æ³•é€šå¸¸åªä¾§é‡äºæ•ˆç‡æˆ–æ€§èƒ½ä¹‹ä¸€ï¼Œéš¾ä»¥å…¼é¡¾ã€‚æ­¤å¤–ï¼Œæ ‡å‡†è®­ç»ƒé‡‡ç”¨**random masking**ï¼Œç¼ºä¹å¯¹â€œå“ªäº›tokenå¯ä»¥å®‰å…¨æ—©è§£ç â€çš„æŒ‡å¯¼ï¼›æ¨ç†æ—¶å¤šå—è§£ç æ˜“å› ä¸Šä¸‹æ–‡ä¸å®Œæ•´è€Œé™ä½è´¨é‡ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **d3LLM**ï¼ˆpseuDo-Distilled-Diffusion LLMï¼‰ï¼Œé€šè¿‡**è®­ç»ƒ**ä¸**æ¨ç†**ä¸¤é˜¶æ®µä¼˜åŒ–ï¼Œåœ¨å‡†ç¡®ç‡ä¸å¹¶è¡Œåº¦ä¹‹é—´å–å¾—å¹³è¡¡ï¼š

#### ï¼ˆ1ï¼‰è®­ç»ƒé˜¶æ®µï¼šPseudo-Trajectory Distillationï¼ˆä¼ªè½¨è¿¹è’¸é¦ï¼‰
- åˆ©ç”¨æ•™å¸ˆ dLLM è‡ªèº«çš„è§£ç è½¨è¿¹ä½œä¸ºâ€œä¼ªçœŸå®è·¯å¾„â€ï¼Œå³ä½¿å…¶æœ€ç»ˆè¾“å‡ºä¸å®Œå…¨æ­£ç¡®ã€‚
- å°†è¯¥è½¨è¿¹ä¸çœŸå® prompt-response å¯¹ç»“åˆï¼Œæ„å»ºå¸¦å™ªå£°çš„åºåˆ—ç”¨äºè®­ç»ƒå­¦ç”Ÿæ¨¡å‹ï¼Œä½¿å…¶å­¦ä¹ åˆ°æ›´ä¼˜çš„ unmasking é¡ºåºã€‚
- å¼•å…¥**è¯¾ç¨‹å­¦ä¹ ç­–ç•¥**ï¼š
  - **Curriculum Noise Level**ï¼šé€æ­¥å¢åŠ  mask ratioï¼ˆä» 0.0 åˆ° 0.8ï¼‰ï¼Œç”±æ˜“åˆ°éš¾ã€‚
  - **Curriculum Window Size**ï¼šé€æ­¥æ‰©å¤§è§£ç çª—å£å¤§å°ï¼ˆä» 16 åˆ° 32ï¼‰ï¼Œæå‡ä¸Šä¸‹æ–‡é€‚åº”èƒ½åŠ›ã€‚

#### ï¼ˆ2ï¼‰æ¨ç†é˜¶æ®µï¼šEntropy-Based Multi-Block Decoding + KV-Cache Refresh
- **åŸºäºç†µçš„å¤šå—å¹¶è¡Œè§£ç **ï¼šä¼˜å…ˆè§£ç ä½ç†µï¼ˆé«˜ç½®ä¿¡åº¦ï¼‰tokenï¼Œæ”¯æŒè·¨å¤šä¸ª block å¹¶è¡Œå¤„ç†ã€‚
- **KV-Cache Refresh æœºåˆ¶**ï¼šå®šæœŸé‡æ–°è®¡ç®—å·²ç¼“å­˜çš„ KV çŠ¶æ€ï¼Œç¼“è§£è¯¯å·®ä¼ æ’­ã€‚
- **Early Stopping on EOS**ï¼šä¸€æ—¦ç”Ÿæˆ EOS token å³åœæ­¢è§£ç ï¼Œé¿å…å†—ä½™è®¡ç®—ã€‚

#### ï¼ˆ3ï¼‰æå‡ºæ–°è¯„ä¼°æŒ‡æ ‡ï¼šAUPï¼ˆAccuracy Under Parallelismï¼‰
- ä¼ ç»ŸæŒ‡æ ‡å¦‚ TPSï¼ˆtokens per secondï¼‰æˆ– accuracy å­¤ç«‹çœ‹å¾…æ•ˆç‡æˆ–æ€§èƒ½ï¼Œæ— æ³•åæ˜  trade-offã€‚
- **AUP** æ˜¯åŠ æƒä¸‹çš„ accuracy-parallelism æ›²çº¿ä¸‹é¢ç§¯ï¼Œå¼ºè°ƒåœ¨ä¿æŒé«˜å‡†ç¡®ç‡å‰æä¸‹æå‡å¹¶è¡Œåº¦ã€‚
- æƒé‡å‡½æ•° $ W(y) = \min(e^{-(1 - y/y_{\text{max}})}, 1) $ æƒ©ç½šå‡†ç¡®ç‡ä¸‹é™åŒºåŸŸã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | d3LLM æ”¹è¿› |
|------|--------|-----------|
| Random Masking | ç¼ºä¹ unmasking é¡ºåºæŒ‡å¯¼ | é€šè¿‡ä¼ªè½¨è¿¹æä¾›ä¸­é—´ç›‘ç£ |
| D2F / Fast-dLLM | ç‰ºç‰² accuracy æ¢ parallelism | åœ¨ä¸æ˜¾è‘—æŸå¤± accuracy ä¸‹å®ç°æ›´é«˜ parallelism |
| dParallel | å‡†ç¡®ç‡å°šå¯ä½† parallelism ä¸è¶³ | æ˜¾è‘—æå‡ TPF åŒæ—¶ç»´æŒ accuracy |
| å•ä¸€æŒ‡æ ‡è¯„ä¼°ï¼ˆå¦‚ TPSï¼‰ | å¿½è§† accuracy-parallelism trade-off | æå‡º AUP ç»¼åˆè¡¡é‡ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šé¦–æ¬¡ç³»ç»Ÿæ€§åœ°åŒæ—¶ä¼˜åŒ– dLLM çš„è®­ç»ƒæŒ‡å¯¼ä¿¡å·ä¸æ¨ç†è°ƒåº¦æœºåˆ¶ï¼Œå®ç°äº†**è¶…é«˜é€Ÿä¸”é«˜ç²¾åº¦**çš„æ‰©æ•£è¯­è¨€æ¨¡å‹ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ä»¥ä¸‹äº”ä¸ªä»£è¡¨æ€§ä»»åŠ¡ä¸Šè¿›è¡Œè¯„ä¼°ï¼š
- **GSM8K-CoT**ï¼šæ•°å­¦æ¨ç†ï¼ˆé›¶æ ·æœ¬ï¼‰
- **MATH**ï¼šç«èµ›çº§æ•°å­¦é¢˜ï¼ˆå››æ ·æœ¬ï¼‰
- **HumanEval**ï¼šä»£ç ç”Ÿæˆï¼ˆé›¶æ ·æœ¬ï¼‰
- **MBPP**ï¼šPython ç¼–ç¨‹ä»»åŠ¡ï¼ˆä¸‰æ ·æœ¬ï¼‰
- **Long-GSM8K**ï¼šé•¿ä¸Šä¸‹æ–‡æ•°å­¦æ¨ç†ï¼ˆäº”æ ·æœ¬ï¼Œprompt ~1000 tokensï¼‰

è¿™äº›ä»»åŠ¡è¦†ç›–äº†æ¨ç†ã€ç¼–ç ã€é•¿æ–‡æœ¬ç­‰å¤šç§åœºæ™¯ï¼Œé€‚åˆæµ‹è¯•å¹¶è¡Œè§£ç èƒ½åŠ›ã€‚

---

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š
  - LLaDA-7B
  - Dream-7B
  - Dream-Coder-7B
- **è¡ç”Ÿæ¨¡å‹**ï¼š
  - d3LLM-LLaDA
  - d3LLM-Dream
  - d3LLM-Coder
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - ä½¿ç”¨ LoRA å¾®è°ƒï¼Œrank=256
  - AdamW ä¼˜åŒ–å™¨ï¼Œlr=2e-5ï¼Œweight decay=0.01
  - æ‰¹å¤§å°ä¸º 64ï¼ˆæ¢¯åº¦ç´¯ç§¯ï¼‰
  - åœ¨ H100 ä¸Šè®­ç»ƒï¼Œbfloat16 ç²¾åº¦
- **æ¨ç†è®¾ç½®**ï¼š
  - å• GPUï¼Œbatch size=1
  - Block size=32
  - Greedy decodingï¼Œtemperature=0.0 æˆ– 0.1

---

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **TPF**ï¼ˆTokens Per Forwardï¼‰ | æ¯æ¬¡å‰å‘ä¼ æ’­ç”Ÿæˆçš„ token æ•°é‡ï¼Œè¡¡é‡ç®—æ³•çº§å¹¶è¡Œåº¦ |
| **TPS**ï¼ˆTokens Per Secondï¼‰ | å®é™…ååé‡ï¼Œå—ç¡¬ä»¶å½±å“å¤§ |
| **Accuracy** | Solve Rate / Pass@1 |
| **AUP**ï¼ˆAccuracy Under Parallelismï¼‰ | æ–°æå‡ºçš„ç»¼åˆæŒ‡æ ‡ï¼Œåæ˜  accuracy-parallelism å¹³è¡¡èƒ½åŠ› |

> âš ï¸ ç‰¹åˆ«è¯´æ˜ï¼šAUP åŸºäº TPF è€Œé TPSï¼Œå…·æœ‰**ç¡¬ä»¶æ— å…³æ€§**ï¼Œæ›´é€‚åˆå…¬å¹³æ¯”è¾ƒç®—æ³•è¿›æ­¥ã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **Vanilla LLaDA / Dream** | åŸå§‹ dLLM | éšæœºæ©ç ï¼Œä¸²è¡Œè§£ç  |
| **Fast-dLLM** | æ¨ç†åŠ é€Ÿ | å—çº§ KV Cacheï¼Œæ— éœ€è®­ç»ƒ |
| **Fast-dLLM-v2** | AR â†’ dLLM è½¬æ¢ | å¾®è°ƒå®ç°é«˜æ•ˆ block diffusion |
| **D2F** | æ··åˆè’¸é¦ | AR-diffusion hybridï¼Œå¼•å…¥ certainty forcing |
| **dParallel** | è’¸é¦æ–¹æ³• | certainty-forcing distillation æå‡å¹¶è¡Œåº¦ |
| **EAGLE-3** | Speculative Decoding | ä½¿ç”¨ draft model åŠ é€Ÿ AR æ¨¡å‹ï¼ˆç”¨äºä¸Šé™å‚è€ƒï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| æ¨¡å‹ | æœ€é«˜ AUP | æœ€é«˜ TPF | TPS (H100) | ç›¸å¯¹äº AR çš„ speedup |
|-------|---------|----------|------------|------------------------|
| d3LLM-LLaDA | **637.7** (GSM8K-CoT) | **9.11** | **288.9** | **5.0Ã—** |
| d3LLM-Dream | **391.3** (GSM8K-CoT) | **4.94** | **235.3** | **4.1Ã—** |
| d3LLM-Coder | **208.4** (HumanEval) | **2.88** | â€” | **8Ã— vs Dream-Coder** |

> ğŸ’¡ **æ€»ä½“è¡¨ç°**ï¼šd3LLM åœ¨ **9 out of 10 ä»»åŠ¡ä¸­å–å¾—æœ€é«˜ AUP åˆ†æ•°**ï¼Œè¯æ˜å…¶åœ¨ accuracy-parallelism æ›²çº¿ä¸Šå…¨é¢é¢†å…ˆã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### åœ¨ LLaDA åŸºç¡€ä¸Šçš„æ¯”è¾ƒï¼ˆTable 1ï¼‰
| æ–¹æ³• | TPF | Acc (%) | AUP |
|------|-----|--------|-----|
| LLaDA | 1.00 | 72.6 | 72.6 |
| Fast-dLLM | 2.77 | 74.7 | 205.8 |
| D2F | 2.88 | 73.2 | 209.7 |
| dParallel | 5.14 | 72.6 | 358.1 |
| **d3LLM (ours)** | **9.11** | **73.1** | **637.7** |

ğŸ‘‰ **ç»“è®º**ï¼šd3LLM çš„ TPF æ˜¯ dParallel çš„ 1.77 å€ï¼ŒAUP æå‡è¿‘ **78%**ã€‚

#### åœ¨ Dream åŸºç¡€ä¸Šçš„æ¯”è¾ƒï¼ˆTable 2ï¼‰
| æ–¹æ³• | TPF | Acc (%) | AUP |
|------|-----|--------|-----|
| Dream | 1.00 | 83.9 | 83.9 |
| Fast-dLLM-v2 | 2.21 | 77.5 | 156.0 |
| dParallel | 3.02 | 82.1 | 245.7 |
| **d3LLM (ours)** | **4.94** | **81.4** | **391.3** |

ğŸ‘‰ **ç»“è®º**ï¼šd3LLM å®ç°äº†æ¥è¿‘ **5Ã— TPF æå‡**ï¼ŒAUP æå‡è¶…è¿‡ **59%**ã€‚

#### å®é™…ååé‡ï¼ˆTPSï¼‰å¯¹æ¯”ï¼ˆTables 3 & 4ï¼‰
| æ¨¡å‹ | H100 TPS | Speedup vs AR |
|------|----------|----------------|
| Qwen-2.5-7B-it (AR) | 57.3 | 1.0Ã— |
| d3LLM-LLaDA | **288.9** | **5.0Ã—** |
| d3LLM-Dream | **235.3** | **4.1Ã—** |
| Vanilla LLaDA | 27.9 | 0.5Ã— |
| Vanilla Dream | 27.6 | 0.5Ã— |

> ğŸ”¥ **äº®ç‚¹**ï¼šç›¸æ¯”åŸå§‹ dLLMï¼Œd3LLM å®ç°äº† **10Ã— ä»¥ä¸Šçš„ TPS æå‡**ï¼

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰è’¸é¦ç­–ç•¥æ¶ˆèï¼ˆTable 5 ä¸ŠåŠéƒ¨åˆ†ï¼‰
| é…ç½® | TPF | Acc | AUP |
|------|-----|-----|-----|
| Baselineï¼ˆæ— è’¸é¦ï¼‰ | 6.41 | 72.2 | 441.4 |
| + Pseudo-Trajectory | 7.55 | 72.1 | 517.7 |
| + Curriculum Noise | 8.46 | 69.8 | 551.3 |
| **Fullï¼ˆ+ Curriculum Windowï¼‰** | **9.11** | **73.1** | **637.7** |

âœ… ç»“è®ºï¼šæ‰€æœ‰ç»„ä»¶å‡æœ‰è´¡çŒ®ï¼Œå°¤å…¶æ˜¯ curriculum window èƒ½æ¢å¤ accuracy å¹¶è¿›ä¸€æ­¥æå‡ parallelismã€‚

#### ï¼ˆ2ï¼‰è§£ç ç­–ç•¥æ¶ˆèï¼ˆTable 5 ä¸‹åŠéƒ¨åˆ†ï¼‰
| é…ç½® | TPF | Acc | AUP |
|------|-----|-----|-----|
| Vanilla Block Diffusion | 7.01 | 73.2 | 492.9 |
| + Multi-Block Decoding | 9.07 | 73.1 | 635.0 |
| **+ Early Stopping** | **9.11** | **73.1** | **637.7** |

âœ… ç»“è®ºï¼šmulti-block decoding æ˜¯ä¸»è¦å¢ç›Šæ¥æºï¼Œearly stopping è¿›ä¸€æ­¥ä¼˜åŒ–æ•ˆç‡ã€‚

#### ï¼ˆ3ï¼‰è¶…å‚æ•°åˆ†æ
- **Curriculum Noise Level**ï¼ˆTable 6ï¼‰ï¼šä»å›ºå®š noise åˆ° 0.0â†’0.8ï¼ŒAUP æå‡ **22.2%**
- **Curriculum Window Size**ï¼ˆTable 7ï¼‰ï¼šä»å›ºå®š k=32 åˆ° 16â†’32ï¼ŒAUP æå‡ **19.0%**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **dLLM å­˜åœ¨å›ºæœ‰çš„ accuracy-parallelism trade-off**ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥å…¼é¡¾ã€‚
2. **ä¼ªè½¨è¿¹è’¸é¦**èƒ½æœ‰æ•ˆä¼ é€’æ•™å¸ˆæ¨¡å‹çš„ unmasking ç­–ç•¥ï¼Œæ˜¾è‘—æå‡å¹¶è¡Œåº¦ã€‚
3. **è¯¾ç¨‹å­¦ä¹ **ï¼ˆcurriculum learningï¼‰å¯¹ç¨³å®šè’¸é¦è¿‡ç¨‹è‡³å…³é‡è¦ï¼Œé¿å… accuracy å´©æºƒã€‚
4. **å¤šå—ç†µé©±åŠ¨è§£ç  + KV-Cache Refresh** å¯åœ¨ä¸ç‰ºç‰² accuracy çš„æƒ…å†µä¸‹å¤§å¹…æå‡æ¨ç†æ•ˆç‡ã€‚
5. **AUP æ˜¯ä¸€ä¸ªåˆç†ä¸”å¿…è¦çš„æ–°æŒ‡æ ‡**ï¼Œèƒ½æ›´çœŸå®åæ˜  dLLM çš„ç»¼åˆæ€§èƒ½ã€‚
6. d3LLM å®ç°äº†ï¼š
   - **é«˜è¾¾ 10Ã— çš„ TPS æå‡**ï¼ˆvs vanilla dLLMï¼‰
   - **3.6Ã—â€“5Ã— çš„ speedup**ï¼ˆvs AR æ¨¡å‹ï¼‰
   - **å‡ ä¹æ—  accuracy æŸå¤±**

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–æ•™å¸ˆæ¨¡å‹è´¨é‡**ï¼šè‹¥æ•™å¸ˆ dLLM æœ¬èº«æ€§èƒ½å·®ï¼Œåˆ™ä¼ªè½¨è¿¹å¯èƒ½è¯¯å¯¼å­¦ç”Ÿã€‚
2. **ä»è½åäº speculative decoding**ï¼šå¦‚ EAGLE-3 åœ¨ AUP ä¸Šæ›´é«˜ï¼ˆè§ Table 9ï¼‰ï¼Œå› å…¶æœ‰éªŒè¯æœºåˆ¶ä¿éšœ accuracyã€‚
3. **æœªåšç³»ç»Ÿçº§ä¼˜åŒ–**ï¼šå½“å‰åŸºäº HuggingFace Transformersï¼Œæœªèåˆ kernel fusion æˆ– paged attentionã€‚
4. **ä»…é€‚ç”¨äºå·²æœ‰çš„ dLLM æ¶æ„**ï¼šä¸èƒ½ç›´æ¥ç”¨äº AR æ¨¡å‹ï¼Œéœ€å…ˆè½¬æ¢ä¸º dLLMã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆFuture Workï¼‰
1. **ç»“åˆ speculative decoding**ï¼šç”¨å°å‹ dLLM ä½œ draft modelï¼Œå¤§æ¨¡å‹éªŒè¯ï¼Œè¿›ä¸€æ­¥æå‡æ•ˆç‡ã€‚
2. **åº”ç”¨äºæ›´å¼ºçš„ dLLM åŸºåº§**ï¼šå¦‚ ReFusionã€LLaDA 2.0 ç­‰ï¼Œæ¢ç´¢æ›´å¤§è§„æ¨¡æ½œåŠ›ã€‚
3. **å¼•å…¥å¼ºåŒ–å­¦ä¹ **ï¼šåˆ©ç”¨ trajectory-aware RLï¼ˆå¦‚ TraDoï¼‰ä¼˜åŒ–è§£ç è·¯å¾„ã€‚
4. **ç³»ç»Ÿçº§ä¼˜åŒ–**ï¼š
   - GPU kernel fusion for multi-block attention
   - æ”¯æŒ vLLM çš„ paged attentionï¼ˆé€‚é… bidirectional attentionï¼‰
   - æ›´é«˜æ•ˆçš„ KV-Cache ç®¡ç†
5. **æ‰©å±•è‡³å¤šæ¨¡æ€ dLLM**ï¼šå¦‚ MMaDA æ¶æ„ï¼Œç»Ÿä¸€å¤„ç†å›¾æ–‡ç”Ÿæˆã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **d3LLM é€šè¿‡ä¼ªè½¨è¿¹è’¸é¦ä¸å¤šå—ç†µè§£ç ï¼Œåœ¨è®­ç»ƒä¸æ¨ç†ä¸¤ç«¯ååŒä¼˜åŒ–ï¼Œé¦–æ¬¡å®ç°äº† ultra-fast ä¸” high-accuracy çš„ dLLMï¼Œæ¨åŠ¨äº† diffusion LLM å‘å®ç”¨åŒ–è¿ˆè¿›ä¸€å¤§æ­¥ã€‚**

</details>

---

### 3. [TALON: Confidence-Aware Speculative Decoding with Adaptive Token Trees](https://arxiv.org/abs/2601.07353)

**Authors**: Tianyu Liu, Qitan Lv, Yuhao Shen, Xiao Sun, Xiaoyan Sun  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.07353v1  

#### Abstract
Speculative decoding (SD) has become a standard technique for accelerating LLM inference without sacrificing output quality. Recent advances in speculative decoding have shifted from sequential chain-based drafting to tree-structured generation, where the draft model constructs a tree of candidate t...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTALON: Confidence-Aware Speculative Decoding with Adaptive Token Trees

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **tree-based Speculative Decoding (SD)** æ–¹æ³•ï¼ˆå¦‚ EAGLEï¼‰é€šå¸¸é‡‡ç”¨**å›ºå®šå®½åº¦å’Œæ·±åº¦**çš„ draft tree ç»“æ„ï¼Œå³æ¯å±‚æ‰©å±•å›ºå®šçš„ `K` ä¸ªå­èŠ‚ç‚¹ï¼Œå¹¶ç”Ÿæˆå›ºå®š `D` å±‚ã€‚è¿™ç§é™æ€ç­–ç•¥å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **åœ¨ç¡®å®šæ€§ä¸Šä¸‹æ–‡ä¸­æµªè´¹è®¡ç®—èµ„æº**ï¼šå½“æ¨¡å‹å¯¹é¢„æµ‹éå¸¸è‡ªä¿¡æ—¶ï¼ˆå¦‚â€œæ³•å›½çš„é¦–éƒ½æ˜¯å·´é»â€ï¼‰ï¼Œä»ä¼šç›²ç›®æ‰©å±• `K` ä¸ªåˆ†æ”¯ï¼Œé€ æˆå†—ä½™ï¼ˆover-explorationï¼‰ã€‚
- **åœ¨ä¸ç¡®å®šæ€§ä¸Šä¸‹æ–‡ä¸­æ¢ç´¢ä¸è¶³**ï¼šå½“æ¨¡å‹é«˜åº¦ä¸ç¡®å®šæ—¶ï¼ˆå¦‚â€œé‡å­è®¡ç®—å¯ä»¥â€¦â€ï¼‰ï¼Œä»…é  top-K é‡‡æ ·å¯èƒ½æ— æ³•è¦†ç›–ç›®æ ‡åˆ†å¸ƒï¼Œå¯¼è‡´æ—©æœŸæ‹’ç»ï¼ˆunder-explorationï¼‰ã€‚
- **æ— æ³•åŠ¨æ€è°ƒæ•´ç”Ÿæˆé•¿åº¦**ï¼šå›ºå®šæ·±åº¦é™åˆ¶äº†ç®€å•ä»»åŠ¡çš„åŠ é€Ÿæ½œåŠ›ï¼ŒåŒæ—¶å¼ºè¿«å¤æ‚ä»»åŠ¡ç»§ç»­ç”Ÿæˆæ³¨å®šè¢«æ‹’ç»çš„é•¿åˆ†æ”¯ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **TALON**ï¼Œä¸€ç§**æ— éœ€è®­ç»ƒã€åŸºäºé¢„ç®—é©±åŠ¨çš„è‡ªé€‚åº”æ ‘æ‰©å±•æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **ä»¥å…¨å±€ token é¢„ç®— `N` ä¸ºçº¦æŸ**ï¼Œè€Œéå›ºå®š `K` å’Œ `D`ã€‚
- **è¿­ä»£æ„å»º draft tree**ï¼Œç›´åˆ°æ€»èŠ‚ç‚¹æ•°è¾¾åˆ°é¢„ç®— `N`ã€‚
- é‡‡ç”¨**æ··åˆæ‰©å±•ç­–ç•¥ï¼ˆHybrid Expansion Strategyï¼‰**ï¼š
  - **ç¬¬0å±‚ï¼ˆæ ¹å±‚ï¼‰**ï¼šä½¿ç”¨ **Top-K åˆå§‹åŒ–**ï¼Œç¡®ä¿é²æ£’æ€§ï¼Œé¿å…å›  draft model åˆå§‹è¿‡è‡ªä¿¡è€Œé™·å…¥é”™è¯¯è·¯å¾„ã€‚
  - **åç»­å±‚ï¼ˆd â‰¥ 1ï¼‰**ï¼šä½¿ç”¨ **ç½®ä¿¡åº¦è¿‡æ»¤ï¼ˆConfidence-Gated Expansionï¼‰**ï¼Œåªä¿ç•™æ¦‚ç‡ä¸ä½äºé”šç‚¹æ¦‚ç‡ `m_a` çš„ `Î¼` å€çš„å€™é€‰èŠ‚ç‚¹ï¼ˆå³ `p(u) â‰¥ Î¼ Â· m_a`ï¼‰ï¼Œå®ç°â€œè¾¹æ‰©å±•è¾¹å‰ªæâ€ã€‚

è¯¥æœºåˆ¶ä½¿ draft tree èƒ½å¤Ÿè‡ªç„¶æ¼”åŒ–ä¸ºï¼š
- **â€œæ·±ä¸”çª„â€ï¼ˆdeep-and-narrowï¼‰**ï¼šåœ¨ä½ç†µã€ç¡®å®šæ€§å¼ºçš„ä¸Šä¸‹æ–‡ä¸­ï¼Œæœ€å¤§åŒ–ç”Ÿæˆé•¿åº¦ã€‚
- **â€œæµ…ä¸”å®½â€ï¼ˆshallow-and-wideï¼‰**ï¼šåœ¨é«˜ç†µã€ä¸ç¡®å®šæ€§å¼ºçš„ä¸Šä¸‹æ–‡ä¸­ï¼Œå¢å¼ºè¦†ç›–ç‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´é«˜çš„çµæ´»æ€§ä¸æ•ˆç‡**ï¼šåŠ¨æ€é€‚åº”ä¸åŒä¸Šä¸‹æ–‡éš¾åº¦ï¼Œä¼˜åŒ–æ¢ç´¢å¹¿åº¦ä¸ç”Ÿæˆæ·±åº¦ä¹‹é—´çš„æƒè¡¡ã€‚
- **æ— éœ€é¢å¤–è®­ç»ƒ**ï¼šå®Œå…¨åŸºäºæ¨ç†æ—¶å†³ç­–ï¼Œå¯ç›´æ¥é›†æˆåˆ°ç°æœ‰ tree-based SD æ¡†æ¶ä¸­ã€‚
- **å‡å°‘è®¡ç®—æµªè´¹**ï¼šé€šè¿‡ early stopping é¿å…åœ¨å›°éš¾ token ä¸Šè¿‡åº¦æŠ•å…¥ï¼Œåœ¨ç®€å• token ä¸Šå……åˆ†æ‰©å±•ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåœ¨ **6 ä¸ªå¤šæ ·åŒ–åŸºå‡†**ä¸Šè¿›è¡Œï¼Œæ¶µç›–å¤šç§ä»»åŠ¡ç±»å‹ï¼š
- **æŒ‡ä»¤éµå¾ª**ï¼šAlpaca
- **æ•°å­¦æ¨ç†**ï¼šGSM8K
- **ä»£ç ç”Ÿæˆ**ï¼šHumanEval
- **å¤šè½®å¯¹è¯**ï¼šMT-Bench
- **é—®ç­”**ï¼šQA (Natural Questions)
- **æ‘˜è¦ç”Ÿæˆ**ï¼šCNN/DM

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼šåœ¨ 5 ç§ä¸»æµ LLM ä¸Šæµ‹è¯•ï¼ŒåŒ…æ‹¬ï¼š
  - Llama-3.1-8B-Instruct
  - Qwen3-8B / Qwen3-32B
  - DeepSeek-R1-Distill-LLaMA-8B (DSL-8B)
  - Vicuna-13B
- **ç¡¬ä»¶**ï¼šå•å¼  NVIDIA H200 (140GB) GPUï¼Œbatch size = 1ã€‚
- **é¢„ç®—è®¾ç½®**ï¼šTALON ä¸ EAGLE-3 å…±äº«ç›¸åŒçš„å…¨å±€ token é¢„ç®— `N = 60`ã€‚
- **æ¸©åº¦è®¾ç½®**ï¼šä¸»å®éªŒä½¿ç”¨ `T=0`ï¼ˆgreedy decodingï¼‰ï¼Œè¡¥å……å®éªŒä½¿ç”¨ `T=1` éªŒè¯éšæœºé‡‡æ ·ä¸‹çš„é²æ£’æ€§ã€‚
- **è¶…å‚æ•°**ï¼šTALON é»˜è®¤é˜ˆå€¼ `Î¼ = 0.03`ï¼Œåˆå§‹åŒ– `K = 10`ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **Mean Accepted Tokens (MAT)**ï¼šæ¯æ¬¡éªŒè¯æ­¥éª¤å¹³å‡æ¥å—çš„ draft tokens æ•°é‡ï¼Œåæ˜  draft è´¨é‡ã€‚
- **Wall-time Speedup (Spd.)**ï¼šç›¸å¯¹äºæ ‡å‡† auto-regressive è§£ç çš„å®é™…ç«¯åˆ°ç«¯åŠ é€Ÿæ¯”ï¼Œä¸ºæ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡ã€‚
- **Draft Efficiency (Î´)**ï¼šå®šä¹‰ä¸º `Î´ = N_d / N_p`ï¼Œè¡¨ç¤ºæ¯ä¸ªéªŒè¯æ­¥æ‰€æ¶ˆè€—çš„ draft æ­¥æ•°ï¼Œç”¨äºåˆ†ææˆæœ¬æ•ˆç›Šã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Speculative Decoding (SD)**ï¼šåŸºç¡€é“¾å¼æ¨æµ‹è§£ç ã€‚
- **MEDUSA / HYDRA**ï¼šåŸºäºå¤šå¤´é¢„æµ‹çš„ MLP-based æ–¹æ³•ã€‚
- **OPT-Tree**ï¼šåŸºäºæœç´¢ä¼˜åŒ–çš„ tree-based æ–¹æ³•ã€‚
- **EAGLE-3**ï¼šå½“å‰æœ€å…ˆè¿›çš„ tree-based SD æ–¹æ³•ï¼Œä½œä¸ºä¸»è¦å¯¹æ¯”åŸºçº¿ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- TALON åœ¨æ‰€æœ‰ 5 ä¸ªæ¨¡å‹å’Œ 6 ä¸ªæ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äº EAGLE-3ã€‚
- æœ€é«˜å®ç° **5.16Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿæ¯”**ï¼ˆVicuna-13B + HumanEvalï¼‰ã€‚
- åœ¨ CNN/DM ä¸Šè¾¾åˆ° **2.30Ã— åŠ é€Ÿ**ï¼ˆQwen3-8Bï¼‰ï¼Œè¿œè¶… EAGLE-3 çš„ 1.95Ã—ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœï¼ˆæ‘˜è‡ª Table 1ï¼‰
| Model | Method | HumanEval (Spd.) | GSM8K (Spd.) | CNNDM (Spd.) |
|-------|--------|------------------|--------------|---------------|
| Vicuna-13B | EAGLE-3 | 4.77Ã— | 3.87Ã— | 3.43Ã— |
| Vicuna-13B | **TALON** | **5.16Ã—** | **3.99Ã—** | **3.58Ã—** |
| Qwen3-8B | EAGLE-3 | 2.20Ã— | 2.37Ã— | 1.95Ã— |
| Qwen3-8B | **TALON** | **2.57Ã—** | **2.67Ã—** | **2.30Ã—** |

> âœ… æ‰€æœ‰åœºæ™¯ä¸‹ TALON å‡å–å¾—æœ€ä½³ speedupã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰ç¨³å¥åˆå§‹åŒ–å¿…è¦æ€§ï¼ˆTop-K å±‚æ•° ablationï¼‰
- **k=0ï¼ˆæ— åˆå§‹åŒ–ï¼‰**ï¼šé€Ÿåº¦ä¸‹é™æ˜æ˜¾ï¼ˆå¦‚ Llama3-8B ä¸Šä» 263.8 â†’ 261.5 tok/sï¼‰ï¼ŒéªŒè¯äº†æ ¹å±‚è¿‡è‡ªä¿¡é£é™©ã€‚
- **kâ‰¥2ï¼ˆè¿‡å¤šåˆå§‹åŒ–ï¼‰**ï¼šå»¶è¿Ÿè¿›å…¥ç½®ä¿¡åº¦è¿‡æ»¤é˜¶æ®µï¼Œå¢åŠ å†—ä½™è®¡ç®—ã€‚
- **k=1ï¼ˆé»˜è®¤ï¼‰**ï¼šåœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šè¡¨ç°æœ€ä¼˜ï¼Œè¯æ˜å•å±‚ Top-K åˆå§‹åŒ– + åç»­è‡ªé€‚åº”æ‰©å±•æ˜¯æœ€ä¼˜è®¾è®¡ã€‚

#### ï¼ˆ2ï¼‰ç½®ä¿¡åº¦é˜ˆå€¼ `Î¼` æ•æ„Ÿæ€§
- `Î¼` æ§åˆ¶æ¢ç´¢ä¸åˆ©ç”¨çš„æƒè¡¡ï¼š
  - è¾ƒå¤§ `Î¼`ï¼ˆå¦‚ 0.04ï¼‰â†’ æ›´ä¸¥æ ¼è¿‡æ»¤ â†’ â€œæ·±ä¸”çª„â€ â†’ é€‚åˆé«˜å¯¹é½æ¨¡å‹ï¼ˆå¦‚ DSL-8Bï¼‰ã€‚
  - è¾ƒå° `Î¼`ï¼ˆå¦‚ 0.01ï¼‰â†’ æ›´å®½æ¾ â†’ â€œæµ…ä¸”å®½â€ â†’ é€‚åˆä½å¯¹é½æ¨¡å‹ï¼ˆå¦‚ Qwen3-8Bï¼‰ã€‚
- è¡¨æ˜å¯é€šè¿‡ `Î¼` è°ƒæ•´ç­–ç•¥é€‚é…ä¸åŒæ¨¡å‹ã€‚

#### ï¼ˆ3ï¼‰é¢„ç®— `N` å¯æ‰©å±•æ€§
- åœ¨ `N=32` åˆ° `96` èŒƒå›´å†…ï¼ŒTALON å§‹ç»ˆä¼˜äº EAGLE-3ã€‚
- å°¤å…¶åœ¨èµ„æºå—é™ï¼ˆ`N=32`ï¼‰æ—¶ä¼˜åŠ¿æ›´æ˜æ˜¾ï¼Œè¯´æ˜å…¶èƒ½æ›´é«˜æ•ˆåœ°ä¼˜å…ˆåˆ†é…é¢„ç®—ç»™é«˜ä»·å€¼è·¯å¾„ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é™æ€æ ‘ç»“æ„å­˜åœ¨ç³»ç»Ÿæ€§ä½æ•ˆ**ï¼šâ€œAcceptance Funnelâ€ç°è±¡è¡¨æ˜æ·±å±‚èŠ‚ç‚¹æ¥å—é›†ä¸­åœ¨ top-1/2ï¼Œå®½æ‰©å±•æ— æ•ˆï¼›â€œStatic Depth Dilemmaâ€æ˜¾ç¤ºæœ€ä¼˜ç”Ÿæˆé•¿åº¦éšä»»åŠ¡æ³¢åŠ¨å‰§çƒˆã€‚
2. **TALON å®ç°äº†çœŸæ­£çš„åŠ¨æ€é€‚åº”**ï¼šé€šè¿‡ budget-driven + confidence-gated æ‰©å±•ï¼Œè‡ªåŠ¨å½¢æˆâ€œæ·±çª„â€æˆ–â€œæµ…å®½â€ç»“æ„ï¼Œæ˜¾è‘—æå‡ draft efficiencyã€‚
3. **ç†è®ºä¸å®è·µä¸€è‡´**ï¼šTALON åŠ¨æ€è°ƒèŠ‚ draft cost `Î´` ä»¥åŒ¹é…å®é™…æ”¶ç›Š `T`ï¼Œæ¥è¿‘ç†æƒ³ Oracle æ›²çº¿ï¼Œè€Œ EAGLE å› å›ºå®šæˆæœ¬åœ¨å›°éš¾ä»»åŠ¡ä¸­æ€§èƒ½éª¤é™ã€‚
4. **é€šç”¨æ€§å¼º**ï¼šåœ¨ greedy (`T=0`) ä¸ stochastic (`T=1`) è§£ç ä¸‹å‡ä¿æŒé¢†å…ˆï¼Œé€‚ç”¨äºå¤šç§æ¨¡å‹ä¸ä»»åŠ¡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **æ‰¹å¤„ç†æ‰©å±•æ€§æœ‰é™**ï¼šå½“å‰è¯„ä¼°é›†ä¸­äº `batch=1` åœºæ™¯ï¼Œå¤§è§„æ¨¡ batch ä¸‹ç»´æŠ¤å¤šä¸ªåŠ¨æ€æ ‘ç»“æ„å¯èƒ½å¯¼è‡´å†…å­˜ä¸è°ƒåº¦å¼€é”€ä¸Šå‡ã€‚
2. **è¶…å‚æ•°æ³›åŒ–æ€§**ï¼šè™½ç„¶ `Î¼=0.03`, `N=60` åœ¨å¤šæ•°æƒ…å†µä¸‹æœ‰æ•ˆï¼Œä½†åœ¨ç‰¹å®šé¢†åŸŸå¯èƒ½éœ€æ‰‹åŠ¨è°ƒå‚ã€‚
3. **æœªè§£å†³æ ¹æœ¬æ¨¡å‹å¯¹é½é—®é¢˜**ï¼šTALON æ˜¯ inference-time ä¼˜åŒ–ï¼Œä¸æ”¹å–„ draft model ä¸ target model çš„åˆ†å¸ƒå¯¹é½ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼€å‘ **auto-tuning æœºåˆ¶**ï¼Œæ ¹æ®å®æ—¶ acceptance history è‡ªåŠ¨è°ƒæ•´ `Î¼` å’Œ `N`ã€‚
- æ¢ç´¢ **large-batch serving ä¸‹çš„é«˜æ•ˆå®ç°æ–¹æ¡ˆ**ï¼Œå¦‚å…±äº«æ ‘ç»“æ„æˆ–è¿‘ä¼¼å‰ªæã€‚
- ç»“åˆ **training-time alignment æŠ€æœ¯**ï¼ˆå¦‚ HASSã€CORALï¼‰ï¼Œè¿›ä¸€æ­¥æå‡ draft è´¨é‡ã€‚

---

> **æ€»ç»“**ï¼šTALON æå‡ºäº†ä¸€ç§ç®€æ´è€Œå¼ºå¤§çš„è®­ç»ƒå…è´¹æ¡†æ¶ï¼Œå°† speculative decoding ä»åˆšæ€§çš„å‡ ä½•çº¦æŸè½¬å‘çµæ´»çš„é¢„ç®—é©±åŠ¨èŒƒå¼ã€‚å…¶å®éªŒå……åˆ†éªŒè¯äº†è‡ªé€‚åº”æ ‘ç»“æ„åœ¨æå‡ LLM æ¨ç†æ•ˆç‡æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œæ˜¯ tree-based SD é¢†åŸŸçš„é‡è¦è¿›å±•ã€‚

</details>

---

### 4. [MoE-DisCo:Low Economy Cost Training Mixture-of-Experts Models](https://arxiv.org/abs/2601.06857)

**Authors**: Xin Ye, Daning Cheng, Boyang Zhang, Yunquan Zhang  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.06857v1  

#### Abstract
Training large-scale Mixture-of-Experts (MoE) models typically requires high-memory, high-bandwidth GPUs (e.g., A100), and their high cost has become a major barrier to large-model training. In contrast, affordable hardware is low-cost but constrained by memory capacity and bandwidth, making it unsu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MoE-DisCo: Low Economy Cost Training Mixture-of-Experts Models â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¤§è§„æ¨¡ **Mixture-of-Experts (MoE)** æ¨¡å‹çš„è®­ç»ƒä¸¥é‡ä¾èµ–é«˜å†…å­˜ã€é«˜å¸¦å®½çš„æ˜‚è´µç¡¬ä»¶ï¼ˆå¦‚ NVIDIA A100ï¼‰ï¼Œå¯¼è‡´è®­ç»ƒæˆæœ¬æé«˜ï¼Œæˆä¸ºå¤§æ¨¡å‹æ™®åŠçš„ä¸»è¦éšœç¢ã€‚åŒæ—¶ï¼Œä½æˆæœ¬è®¾å¤‡ï¼ˆå¦‚æ¶ˆè´¹çº§ GPUï¼‰å—é™äºæ˜¾å­˜å®¹é‡å’Œå¸¦å®½ï¼Œéš¾ä»¥ç›´æ¥ç”¨äº MoE æ¨¡å‹è®­ç»ƒã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šMoE-DisCo
ä½œè€…æå‡º **MoE-DisCo**ï¼ˆMixture-of-Experts with Disentangled Clustering and Coordinationï¼‰ï¼Œä¸€ç§**åˆ†é˜¶æ®µã€ç¡¬ä»¶æ„ŸçŸ¥çš„ MoE è®­ç»ƒæ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°† MoE æ¨¡å‹è§£è€¦ä¸ºå¤šä¸ªç‹¬ç«‹å­æ¨¡å‹å¹¶è¡Œè®­ç»ƒï¼Œæœ€åå†èåˆå¾®è°ƒã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
- **æ¨¡å‹è§£è€¦ï¼ˆModel Decouplingï¼‰**  
  å°†å®Œæ•´çš„ MoE æ¨¡å‹åˆ†è§£ä¸º `K` ä¸ªç‹¬ç«‹çš„**å¯†é›†å­æ¨¡å‹**ï¼ˆdense submodelsï¼‰ï¼Œæ¯ä¸ªå­æ¨¡å‹åŒ…å«å…±äº«çš„ Transformer éª¨å¹²ç½‘ç»œ + å•ä¸ªä¸“å®¶æ¨¡å—ã€‚
- **æ•°æ®è§£è€¦ï¼ˆData Decouplingï¼‰**  
  ä½¿ç”¨ **K-means èšç±»**å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œæ— ç›‘ç£è¯­ä¹‰èšç±»ï¼Œç”Ÿæˆ `K` ä¸ªè¯­ä¹‰ä¸Šå·®å¼‚åŒ–çš„å­æ•°æ®é›†ï¼Œå¹¶ä¸å„ä¸“å®¶å»ºç«‹â€œè§£è€¦å¯¹é½â€å…³ç³»ã€‚
- **å¹¶è¡Œç‹¬ç«‹è®­ç»ƒï¼ˆIndependent Parallel Trainingï¼‰**  
  æ¯ä¸ªå­æ¨¡å‹åœ¨åˆ†é…çš„æ•°æ®å­é›†ä¸Šç‹¬ç«‹è®­ç»ƒï¼Œæ— éœ€è·¨è®¾å¤‡é€šä¿¡ï¼Œå¯åœ¨ä½åŠŸè€—ã€ä½æˆæœ¬è®¾å¤‡ï¼ˆå¦‚ RTX 4090ï¼‰ä¸Šé«˜æ•ˆè¿è¡Œã€‚
- **è½»é‡å…¨å±€å¾®è°ƒï¼ˆLightweight Global Fine-tuneï¼‰**  
  æ‰€æœ‰ä¸“å®¶è®­ç»ƒå®Œæˆåï¼Œé›†æˆæˆå®Œæ•´ MoE æ¶æ„ï¼Œåœ¨å…¨é‡æ•°æ®ä¸Šè¿›è¡ŒçŸ­æ—¶é—´çš„å…¨å±€å¾®è°ƒï¼ˆfine-tuneï¼‰ï¼Œæ¢å¤é—¨æ§æœºåˆ¶åè°ƒèƒ½åŠ›ï¼Œæ­¤é˜¶æ®µä»…éœ€å°‘é‡é«˜æˆæœ¬ GPU æ—¶é—´ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿ MoE å…¨å‚æ•°è®­ç»ƒ | MoE-DisCo |
|------|---------------------|-----------|
| ç¡¬ä»¶éœ€æ±‚ | å…¨ç¨‹ä¾èµ– A100/H800 ç­‰é«˜ç«¯ GPU | å¤§éƒ¨åˆ†è®­ç»ƒåœ¨ RTX 4090 ç­‰ä½æˆæœ¬ GPU ä¸Šå®Œæˆ |
| é€šä¿¡å¼€é”€ | å¤š GPU åŒæ­¥é€šä¿¡é¢‘ç¹ï¼Œå­˜åœ¨é€šä¿¡ç“¶é¢ˆ | å­æ¨¡å‹å®Œå…¨ç‹¬ç«‹ï¼Œé›¶é€šä¿¡å¼€é”€ |
| å†…å­˜å ç”¨ | éœ€åŠ è½½å…¨éƒ¨ä¸“å®¶å‚æ•° | åªéœ€å•ä¸ªä¸“å®¶ + å…±äº«éª¨å¹²ï¼Œæ˜¾è‘—é™ä½æ˜¾å­˜å‹åŠ› |
| æ€»ä½“æˆæœ¬ | é«˜æ˜‚ï¼ˆå…¨ç¨‹ä½¿ç”¨é«˜ä»· GPUï¼‰ | æˆæœ¬ä¸‹é™ **47.6% ~ 69.5%** |
| æ€§èƒ½è¡¨ç° | åŸºå‡†æ€§èƒ½ | åŒ¹é…ç”šè‡³ä¼˜äºå…¨å‚æ•°è®­ç»ƒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **C4**: å¤§è§„æ¨¡è‹±æ–‡è¯­æ–™ï¼Œç»è¿‡ä¸¥æ ¼æ¸…æ´—è¿‡æ»¤
- **WikiText-2**: æ¥è‡ªç»´åŸºç™¾ç§‘çš„é«˜è´¨é‡è‹±æ–‡æ–‡æœ¬ï¼Œå¸¸ç”¨äºè¯­è¨€æ¨¡å‹è¯„æµ‹
- **OpenWebText**: å¼€æºç½‘é¡µæ–‡æœ¬é›†åˆï¼Œæ¨¡ä»¿ GPT-2 çš„è®­ç»ƒæ•°æ®æ„å»º

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼š
  - **Qwen1.5-MoE-2.7B**ï¼šæ¿€æ´»çº¦ 2.7B å‚æ•°ï¼Œç­‰æ•ˆæ€§èƒ½æ¥è¿‘ 7B å¯†é›†æ¨¡å‹ï¼ˆå¦‚ Mistral-7Bï¼‰
  - **LLaMA-MoE-3.5B**ï¼šåŸºäº LLaMA æ¶æ„çš„ MoE ç‰ˆæœ¬
  - ä¸¤ä¸ªæ¨¡å‹å‡è®¾ç½® **4 ä¸ªä¸“å®¶ï¼ˆK=4ï¼‰**

- **è®­ç»ƒå¹³å°ä¸æˆæœ¬ä¼°ç®—**ï¼š
  - **RTX 4090**ï¼š$0.35 / GPUÂ·å°æ—¶ï¼ˆä½æˆæœ¬è®¾å¤‡ä»£è¡¨ï¼‰
  - **A100 (80GB)**ï¼š$2.28 / GPUÂ·å°æ—¶ï¼ˆé«˜æˆæœ¬è®¾å¤‡ä»£è¡¨ï¼‰

- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  1. **è¯­è¨€å»ºæ¨¡æ€§èƒ½**ï¼šè®­ç»ƒæŸå¤±ï¼ˆlossï¼‰ã€å›°æƒ‘åº¦ï¼ˆPPLï¼‰
  2. **ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½**ï¼šARC-eï¼ˆ5-shotï¼‰ã€MMLUï¼ˆ5-shotï¼‰ã€HellaSwagï¼ˆzero-shotï¼‰ã€PIQAï¼ˆzero-shotï¼‰
  3. **è®­ç»ƒæ•ˆç‡**ï¼šè¾¾åˆ°ç›®æ ‡ loss æ‰€éœ€çš„è®­ç»ƒæ­¥æ•°
  4. **ç»æµæˆæœ¬**ï¼šæ€»è®­ç»ƒè´¹ç”¨ï¼ˆç¾å…ƒï¼‰ã€é«˜æˆæœ¬ GPU ä½¿ç”¨æ—¶é—´

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Full-Parameter Training**ï¼šæ ‡å‡†çš„ç«¯åˆ°ç«¯ MoE å…¨å‚æ•°è®­ç»ƒï¼Œå…¨ç¨‹åœ¨ A100 ä¸Šè¿›è¡Œï¼Œä½œä¸ºæ€§èƒ½ä¸æˆæœ¬åŸºå‡†ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 å’Œ Figure 4â€“5ï¼‰

| æ¨¡å‹ | æ•°æ®é›† | Full-Param æ­¥æ•° | MoE-DisCo æ­¥æ•° | å‡å°‘æ¯”ä¾‹ |
|------|--------|------------------|----------------|----------|
| Qwen | C4 | 21,150 | 4,100 | â†“ **80.6%** |
| Qwen | WikiText-2 | 12,500 | 3,150 | â†“ **74.8%** |
| Qwen | OpenWebText | 28,600 | 6,650 | â†“ **76.7%** |
| Llama | C4 | 11,750 | 4,150 | â†“ **64.7%** |
| Llama | WikiText-2 | 15,000 | 5,300 | â†“ **64.7%** |
| Llama | OpenWebText | 21,000 | 7,800 | â†“ **62.9%** |

> âœ… MoE-DisCo åœ¨ç›¸åŒ loss ä¸‹æ‰€éœ€è®­ç»ƒæ­¥æ•°ä»…ä¸ºä¼ ç»Ÿçš„ **1/4 å·¦å³**ï¼Œæ”¶æ•›é€Ÿåº¦å¤§å¹…æå‡ã€‚

#### å›°æƒ‘åº¦ï¼ˆPPLï¼‰å¯¹æ¯”ï¼ˆç¤ºä¾‹ï¼‰ï¼š
- Qwen + C4ï¼šFull-Param â†’ 230.32 vs MoE-DisCo â†’ **165.86**ï¼ˆâ†“ æ˜¾è‘—æ”¹å–„ï¼‰
- Llama + OpenWebTextï¼šFull-Param â†’ 114.93 vs MoE-DisCo â†’ **106.82**

> ğŸ’¡ è¡¨æ˜ MoE-DisCo ä¸ä»…æ›´å¿«ï¼Œä¸”æœ€ç»ˆè¯­è¨€å»ºæ¨¡è´¨é‡æ›´ä¼˜ã€‚

### ğŸ“ˆ ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ï¼ˆTable 2ï¼‰

| æ–¹æ³• | ARC-e(5) | MMLU(%) | HellaSwag(%) | PIQA(%) |
|------|---------|--------|-------------|--------|
| Full-Param | 27.9 | 23.0 | 27.45 | 52.25 |
| **MoE-DisCo** | **29.1** | **25.3** | **29.45** | **57.03** |

> âœ… MoE-DisCo åœ¨æ‰€æœ‰ä¸‹æ¸¸ä»»åŠ¡ä¸­å‡**å…¨é¢è¶…è¶Š**å…¨å‚æ•°è®­ç»ƒï¼Œå°¤å…¶åœ¨é›¶æ ·æœ¬ä»»åŠ¡ï¼ˆPIQAï¼‰æå‡æ˜æ˜¾ï¼ˆâ†‘ 4.78%ï¼‰ã€‚

### ğŸ’° ç»æµæˆæœ¬åˆ†æï¼ˆTable 3ï¼‰

| æ¨¡å‹ | æ•°æ®é›† | Full-Param æˆæœ¬ ($) | MoE-DisCo æˆæœ¬ ($) | æˆæœ¬é™å¹… |
|------|--------|-----------------------|--------------------|----------|
| Qwen | C4 | 22.50 | 6.87 | â†“ **69.5%** |
| Qwen | WikiText-2 | 6.93 | 3.34 | â†“ **51.8%** |
| Qwen | OpenWebText | 29.91 | 10.91 | â†“ **63.5%** |
| Llama | C4 | 12.86 | 6.74 | â†“ **47.6%** |
| Llama | WikiText-2 | 16.99 | 8.13 | â†“ **52.2%** |
| Llama | OpenWebText | 32.13 | 15.14 | â†“ **52.9%** |

> ğŸ’¸ æœ€é«˜èŠ‚çœè¿‘ **70%** çš„è®­ç»ƒæˆæœ¬ï¼Œä¸”è®­ç»ƒæ—¶é—´ä¹Ÿå¤§å¹…ç¼©çŸ­ï¼ˆä¾‹å¦‚ Qwen on C4ï¼šä» 9.87h â†’ 3.82hï¼‰ã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰èšç±»ç­–ç•¥æ¶ˆèï¼ˆFigure 6ï¼‰
- å°† K-means æ›¿æ¢ä¸º**éšæœºæ•°æ®åˆ’åˆ†**åï¼ŒMoE-DisCo çš„æ€§èƒ½é€€åŒ–è‡³ä¸ Full-Parameter è®­ç»ƒç›¸å½“ã€‚
- **ç»“è®º**ï¼šK-means èšç±»é€šè¿‡å¢å¼ºä¸“å®¶é—´çš„è¯­ä¹‰åˆ†å·¥ï¼Œæå‡äº†æ¨¡å‹å¤šæ ·æ€§ä¸æ”¶æ•›æ•ˆç‡ï¼Œæ˜¯ MoE-DisCo æˆåŠŸçš„å…³é”®ç»„ä»¶ã€‚

#### ï¼ˆ2ï¼‰ä¸“å®¶æ•°é‡å½±å“ï¼ˆFigure 7ï¼‰
- åœ¨ Llama æ¨¡å‹ä¸Šæµ‹è¯• 2 ä¸“å®¶ vs 4 ä¸“å®¶é…ç½®ï¼š
  - 4-expert æ¨¡å‹åœ¨ MoE-DisCo æ¡†æ¶ä¸‹ä»èƒ½å¿«é€Ÿæ”¶æ•›ï¼Œä¸”æœ€ç»ˆ loss å’Œ PPL æ›´ä½ã€‚
- **ç»“è®º**ï¼šMoE-DisCo å¯¹ä¸åŒä¸“å®¶æ•°é‡å…·æœ‰è‰¯å¥½çš„æ‰©å±•æ€§å’Œç¨³å®šæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **MoE-DisCo èƒ½æ˜¾è‘—é™ä½ MoE æ¨¡å‹è®­ç»ƒæˆæœ¬**ï¼ˆæœ€é«˜é™æœ¬ 69.5%ï¼‰ï¼ŒåŒæ—¶ä¿æŒç”šè‡³æå‡æ¨¡å‹æ€§èƒ½ã€‚
2. **é€šè¿‡â€œè§£è€¦è®­ç»ƒ + è½»é‡èåˆâ€çš„ä¸¤é˜¶æ®µè®¾è®¡**ï¼Œå¯å°†å¤§éƒ¨åˆ†è®¡ç®—è´Ÿè½½è¿ç§»è‡³ä½æˆæœ¬ç¡¬ä»¶ï¼Œæå¤§ç¼“è§£å¯¹ A100 ç±»é«˜ç«¯ GPU çš„ä¾èµ–ã€‚
3. **è¯­ä¹‰èšç±»é©±åŠ¨çš„æ•°æ®åˆ’åˆ†æœºåˆ¶** æ˜¯å®ç°ä¸“å®¶ä¸“ä¸šåŒ–åˆ†å·¥çš„æ ¸å¿ƒï¼Œç¡®ä¿å„å­æ¨¡å‹å­¦ä¹ äº’è¡¥ç‰¹å¾ã€‚
4. **æœ€ç»ˆçš„çŸ­æ—¶ fine-tune é˜¶æ®µè¶³ä»¥æ¢å¤é—¨æ§åè°ƒè¡Œä¸º**ï¼Œæ— éœ€é•¿æ—¶é—´ç«¯åˆ°ç«¯è®­ç»ƒå³å¯è·å¾—é«˜æ€§èƒ½ MoE æ¨¡å‹ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰å®éªŒæœªéªŒè¯åœ¨æ›´å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚ >10B å‚æ•°ï¼‰ä¸Šçš„æœ‰æ•ˆæ€§ã€‚
- èšç±»ä¾èµ–é¢„è®­ç»ƒ embeddingï¼Œå¯èƒ½å¼•å…¥åå·®ã€‚
- ä¸“å®¶æ•°é‡å›ºå®šï¼Œç¼ºä¹åŠ¨æ€è°ƒæ•´æœºåˆ¶ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³è¶…å¤§è§„æ¨¡ MoE æ¨¡å‹ï¼ˆç™¾äº¿/åƒäº¿å‚æ•°ï¼‰
- å¼•å…¥æ›´å¤šæ•°æ®åˆ’åˆ†ç­–ç•¥ï¼ˆå¦‚ topic modelingã€domain-adaptive clusteringï¼‰
- æ¢ç´¢åŠ¨æ€ä¸“å®¶æ•°é‡è°ƒæ•´æˆ–è·¯ç”±ä¼˜åŒ–ç­–ç•¥
- ç»“åˆç³»ç»Ÿå±‚é¢ä¼˜åŒ–ï¼ˆå¦‚é€šä¿¡å‹ç¼©ã€å¼‚æ„è°ƒåº¦ï¼‰è¿›ä¸€æ­¥æå‡æ•ˆç‡

---

## âœ… æ€»ç»“
**MoE-DisCo** æ˜¯ä¸€ç§é¢å‘èµ„æºå—é™åœºæ™¯çš„é«˜æ•ˆ MoE è®­ç»ƒæ–°èŒƒå¼ã€‚å®ƒé€šè¿‡ **æ¨¡å‹è§£è€¦ + æ•°æ®èšç±» + å¹¶è¡Œè®­ç»ƒ + è½»é‡å¾®è°ƒ** çš„å››é˜¶æ®µæµç¨‹ï¼ŒæˆåŠŸå®ç°äº†åœ¨ä½æˆæœ¬ç¡¬ä»¶ä¸Šè®­ç»ƒé«˜è´¨é‡ MoE æ¨¡å‹çš„ç›®æ ‡ã€‚å®éªŒè¯æ˜å…¶ä¸ä»…å¤§å¹…é™ä½æˆæœ¬ï¼ˆâ†“47.6%~69.5%ï¼‰ï¼Œè€Œä¸”åœ¨æ”¶æ•›é€Ÿåº¦ã€è¯­è¨€å»ºæ¨¡è´¨é‡å’Œä¸‹æ¸¸ä»»åŠ¡è¡¨ç°ä¸Šå‡ä¼˜äºä¼ ç»Ÿå…¨å‚æ•°è®­ç»ƒï¼Œä¸ºå­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œæä¾›äº†æå…·å®ç”¨ä»·å€¼çš„å¤§æ¨¡å‹è®­ç»ƒè§£å†³æ–¹æ¡ˆã€‚

> ğŸ”— ä»£ç åœ°å€ï¼š[https://anonymous.4open.science/r/MoE-DisCo-4835/](https://anonymous.4open.science/r/MoE-DisCo-4835/)

</details>

---

### 5. [Free-RBF-KAN: Kolmogorov-Arnold Networks with Adaptive Radial Basis Functions for Efficient Function Learning](https://arxiv.org/abs/2601.07760)

**Authors**: Shao-Ting Chiu, Siu Wun Cheung, Ulisses Braga-Neto, Chak Shing Lee, Rui Peng Li  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.07760v1  

#### Abstract
Kolmogorov-Arnold Networks (KANs) have shown strong potential for efficiently approximating complex nonlinear functions. However, the original KAN formulation relies on B-spline basis functions, which incur substantial computational overhead due to De Boor's algorithm. To address this limitation, re...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šFree-RBF-KAN: Kolmogorov-Arnold Networks with Adaptive Radial Basis Functions for Efficient Function Learning**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
åŸå§‹çš„ **Kolmogorov-Arnold Network (KAN)** è™½ç„¶åœ¨å‡½æ•°é€¼è¿‘æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶ä¾èµ–äº **B-spline** åŸºå‡½æ•°ï¼Œéœ€é€šè¿‡ **De Boor ç®—æ³•**è¿›è¡Œè®¡ç®—ï¼Œå¹¶ä¸”è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦åŠ¨æ€è°ƒæ•´åŸŸèŒƒå›´ï¼Œå¯¼è‡´æ˜¾è‘—çš„**è®¡ç®—å¼€é”€**ã€‚æ­¤å¤–ï¼Œæ ‡å‡†çš„ **RBF-KAN** è™½ç„¶æå‡äº†æ•ˆç‡ï¼Œä½†åœ¨ç²¾åº¦ä¸Šé€šå¸¸ä¸å¦‚åŸå§‹ KANã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹é—®é¢˜ï¼š
- å¦‚ä½•åœ¨ä¿æŒé«˜é€¼è¿‘ç²¾åº¦çš„åŒæ—¶ï¼Œé™ä½ KAN çš„è®¡ç®—å¤æ‚åº¦ï¼Ÿ
- å¦‚ä½•æå‡ RBF-KAN çš„è¡¨è¾¾èƒ½åŠ›ä»¥å¼¥è¡¥å…¶ç›¸å¯¹äº B-spline KAN çš„æ€§èƒ½å·®è·ï¼Ÿ

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**
ä½œè€…æå‡ºäº† **Free-RBF-KAN**ï¼Œä¸€ç§åŸºäºè‡ªé€‚åº”å¾„å‘åŸºå‡½æ•°ï¼ˆRBFï¼‰çš„æ–°å‹ KAN æ¶æ„ï¼Œæ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### âœ… **1. è‡ªç”±å¯å­¦ä¹ çš„ RBF å½¢çŠ¶å‚æ•°**
- å¼•å…¥**å¯è®­ç»ƒçš„ç½‘æ ¼ç‚¹ï¼ˆcentroidsï¼‰** å’Œ **å¹³æ»‘åº¦å‚æ•°ï¼ˆsmoothness factorsï¼‰**ï¼Œä½¿ RBF çš„å½¢çŠ¶åœ¨è®­ç»ƒä¸­åŠ¨æ€è°ƒæ•´ã€‚
- é€šè¿‡ `tanh` æ˜ å°„çº¦æŸç½‘æ ¼ç‚¹åœ¨é¢„è®¾åŒºé—´å†…ï¼Œç¡®ä¿æ¢¯åº¦ä¼˜åŒ–ç¨³å®šã€‚

#### âœ… **2. è‡ªé€‚åº”å¹³æ»‘æœºåˆ¶**
- å°† RBF çš„å¹³æ»‘åº¦ï¼ˆå¦‚é«˜æ–¯æ ¸ä¸­çš„ $\sigma$ï¼‰ä½œä¸ºç½‘ç»œå‚æ•°è”åˆä¼˜åŒ–ï¼Œè€Œéå›ºå®šå€¼ã€‚
- ä½¿ç”¨ `exp()` æ˜ å°„ä¿è¯å¹³æ»‘åº¦å§‹ç»ˆä¸ºæ­£ã€‚

#### âœ… **3. ç»Ÿä¸€çš„é€šç”¨é€¼è¿‘ç†è®ºè¯æ˜**
- é¦–æ¬¡ä¸º **RBF-KAN å®¶æ—**æä¾›äº†å½¢å¼åŒ–çš„**é€šç”¨é€¼è¿‘å®šç†ï¼ˆuniversal approximation theoremï¼‰**ã€‚
- è¯æ˜äº† RBF-KAN ä¸ä»…æ˜¯è®¡ç®—ä¼˜åŒ–æ‰‹æ®µï¼Œæ›´æ˜¯å…·æœ‰å¼ºå¤§è¡¨è¾¾èƒ½åŠ›çš„å‡½æ•°é€¼è¿‘æ¡†æ¶ã€‚

#### âœ… **4. å¤šä»»åŠ¡é«˜æ•ˆæ¶æ„è®¾è®¡**
- åœ¨ç‰©ç†ä¿¡æ¯æœºå™¨å­¦ä¹ ï¼ˆPhysics-Informed MLï¼‰ã€ç®—å­å­¦ä¹ ç­‰ä»»åŠ¡ä¸­éªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚
- å¯æ— ç¼é›†æˆåˆ° DeepONet ä¸­ä½œä¸º trunk networkï¼Œæå‡ç®—å­å­¦ä¹ æ€§èƒ½ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | ç¼ºç‚¹ | Free-RBF-KAN çš„ä¼˜åŠ¿ |
|------|------|---------------------|
| **B-spline KAN** | è®¡ç®—æ˜‚è´µï¼ˆDe Boor è¿­ä»£ï¼‰ï¼Œæ— æ³•çµæ´»è°ƒæ•´å¹³æ»‘åº¦ | æ›´å¿«è®­ç»ƒ/æ¨ç†ï¼Œæ”¯æŒåŠ¨æ€ç½‘æ ¼å’Œå¹³æ»‘åº¦ |
| **Standard RBF-KAN** | å›ºå®šä¸­å¿ƒå’Œå¹³æ»‘åº¦ï¼Œè¡¨è¾¾èƒ½åŠ›å—é™ | åŠ¨æ€å¯¹é½æ¿€æ´»æ¨¡å¼ï¼Œæ˜¾è‘—æå‡ç²¾åº¦ |
| **MLP / PINN** | å­˜åœ¨è°±åå·®ï¼ˆspectral biasï¼‰ï¼Œéš¾ä»¥æ•æ‰é«˜é¢‘ç‰¹å¾ | æ— è°±åå·®ï¼Œé€‚åˆå¤šå°ºåº¦å»ºæ¨¡ |
| **FreeKnots-KAN** | B-spline ç½‘æ ¼å¿…é¡»æœ‰åºï¼Œä¼˜åŒ–å¤æ‚ | RBF æ— éœ€æ’åºï¼Œè‡ªç”±ç§»åŠ¨æ›´çµæ´» |

> ğŸ’¡ **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼š  
> **Free-RBF-KAN å®ç°äº†ç²¾åº¦ä¸æ•ˆç‡çš„å¹³è¡¡** â€”â€” åœ¨é€¼è¿‘èƒ½åŠ›ä¸Šåª²ç¾ç”šè‡³è¶…è¶ŠåŸå§‹ KANï¼Œåœ¨è®­ç»ƒé€Ÿåº¦ä¸Šè¿œè¶… B-spline KANï¼ŒåŒæ—¶ä¿ç•™äº† RBF çš„çµæ´»æ€§å’Œå¯å¾®æ€§ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸ä»»åŠ¡ç±»å‹**
å®éªŒè¦†ç›–å¤šä¸ªé¢†åŸŸï¼Œä½“ç°æ–¹æ³•çš„å¹¿æ³›é€‚ç”¨æ€§ï¼š

| ä»»åŠ¡ç±»åˆ« | æ•°æ®é›†/é—®é¢˜æè¿° |
|--------|----------------|
| **å‡½æ•°é€¼è¿‘** | åˆæˆéå…‰æ»‘å‡½æ•°ï¼š$f(x,y)=\cos(4x) + \sin(y) + \sin(2\pi y) + |\sin(3\pi y)|$ |
| **è°±åå·®åˆ†æ** | å¤šå°ºåº¦å‡½æ•°ï¼š$f(x)=0.1\sin(50\pi x)+\sin(2\pi x)$ |
| **é«˜ç»´å›å½’** | **MNIST å›¾åƒåˆ†ç±»**ï¼ˆè§†ä¸ºå›å½’ä»»åŠ¡ï¼‰ |
| **ç‰©ç†ä¿¡æ¯å­¦ä¹ ï¼ˆPINNï¼‰** | <br>â€¢ 2D çƒ­ä¼ å¯¼æ–¹ç¨‹ï¼ˆå«é«˜é¢‘æºé¡¹ï¼‰<br>â€¢ 2D Helmholtz æ–¹ç¨‹ï¼ˆæ­£å¼¦æºï¼‰ |
| **ç®—å­å­¦ä¹ ï¼ˆDeepONetï¼‰** | 1D ååº”æ‰©æ•£æ–¹ç¨‹çš„è§£ç®—å­å­¦ä¹ ï¼š<br>$u_t = D u_{xx} + k u + f(x)$ |

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

| è®¾ç½®é¡¹ | æè¿° |
|-------|------|
| **æ¨¡å‹ç»“æ„** | æ‰€æœ‰ KAN ç±»æ¨¡å‹ç»Ÿä¸€å±‚æ•°ä¸èŠ‚ç‚¹æ•°ï¼Œå…¬å¹³æ¯”è¾ƒï¼ˆå¦‚ `[2,5,1]`, `[28Ã—28,64,10]`ï¼‰ |
| **RBF ç±»å‹** | ä¸»è¦ä½¿ç”¨ **Gaussian RBF**ï¼Œéƒ¨åˆ†ä½¿ç”¨ MatÃ©rn æ ¸ |
| **ä¼˜åŒ–å™¨** | Adam æˆ– LBFGSï¼Œå­¦ä¹ ç‡ $10^{-3}$ æˆ– 1.0 |
| **è¯„ä¼°æŒ‡æ ‡** | <br>â€¢ **Test MSE / LÂ² Loss**ï¼ˆå‡½æ•°é€¼è¿‘ï¼‰<br>â€¢ **Relative L2 Error**ï¼ˆç®—å­å­¦ä¹ ï¼‰<br>â€¢ **Training Time (sec)**<br>â€¢ **NTK Eigenvalue Spectrum**ï¼ˆè°±åå·®åˆ†æï¼‰ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åŸºçº¿æ¨¡å‹ | ç®€è¦è¯´æ˜ |
|--------|---------|
| **MLP** | æ ‡å‡†å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼ŒTanh/SiLU æ¿€æ´» |
| **KAN** | åŸå§‹ B-spline KANï¼ˆä¸‰æ¬¡æ ·æ¡ï¼‰ |
| **FreeKnots-KAN** | æ”¯æŒè‡ªç”±èŠ‚ç‚¹çš„ B-spline KAN |
| **RBF-KAN** | å›ºå®šä¸­å¿ƒå’Œå¹³æ»‘åº¦çš„ RBF ç‰ˆæœ¬ |
| **PINN** | Physics-Informed Neural Network åŸºçº¿ |
| **DeepONet** | åˆ†æ”¯-ä¸»å¹²ç»“æ„çš„æ ‡å‡†ç®—å­å­¦ä¹ æ¨¡å‹ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

#### ğŸ”¹ **è¡¨1ï¼šéå…‰æ»‘äºŒç»´å‡½æ•°é€¼è¿‘ï¼ˆTable 2ï¼‰**
| Model | #Param | Test MSE |
|-------|--------|----------|
| MLP | 261 | 5.26e-1 |
| KAN | 195 | 3.96e-3 |
| FreeKnots-KAN | 307 | 2.57e-4 |
| RBF-KAN | 120 | 6.05e-4 |
| **Free-RBF-KAN** | **290** | **2.39e-4** âœ… |

> â¤ Free-RBF-KAN è¾¾åˆ°æœ€ä½è¯¯å·®ï¼Œä¼˜äº FreeKnots-KANï¼Œä¸”å‚æ•°å°‘äºåè€…ã€‚

---

#### ğŸ”¹ **è¡¨2ï¼šMNIST é«˜ç»´å›å½’ï¼ˆTable 3ï¼‰**
| Model | #Param | Test Loss | Training Time (s) |
|-------|--------|-----------|-------------------|
| MLP | 509,410 | **6.70e-2** | **81.58** |
| KAN | 762,240 | 1.17e-1 | 97.95 |
| RBF-KAN | 508,160 | 2.02e-1 | 82.27 |
| **Free-RBF-KAN** | **525,120** | **8.79e-2** | **85.81** |

> â¤ å°½ç®¡ MLP æœ€ä¼˜ï¼Œä½† Free-RBF-KAN æ˜¾è‘—ä¼˜äºå…¶ä»– KAN å˜ä½“ï¼Œæ¥è¿‘ MLP è¡¨ç°ã€‚

---

#### ğŸ”¹ **è¡¨3ï¼š2D çƒ­ä¼ å¯¼ PDEï¼ˆTable 4ï¼‰**
| Model | #Param | LÂ²-loss | Training Time (s) |
|-------|--------|--------|-------------------|
| MLP | 5,081 | 1.60e-1 | 1160 |
| KAN | 1,400 | 6.52e-3 | 267 |
| RBF-KAN | 1,280 | 2.78e-3 | 124 |
| **Free-RBF-KAN** | **2,000** | **2.41e-3** âœ… | **138** |

> â¤ Free-RBF-KAN ç²¾åº¦æœ€é«˜ï¼Œè®­ç»ƒæ—¶é—´ä»…ä¸º KAN çš„ **~50%**ã€‚

---

#### ğŸ”¹ **è¡¨4ï¼š2D Helmholtz PDEï¼ˆTable 5ï¼‰**
| Model | #Param | LÂ²-loss | Training Time (s) |
|-------|--------|--------|-------------------|
| MLP | 50,049 | 4.15e-2 | 39 |
| KAN | 600 | 1.58 | 153 âŒ |
| RBF-KAN | 400 | 3.67e-1 | 49 |
| **Free-RBF-KAN** | **640** | **3.35e-2** âœ… | **62** |

> â¤ KAN å®Œå…¨å¤±è´¥ï¼›Free-RBF-KAN ç²¾åº¦è¶…è¿‡ MLPï¼Œè®­ç»ƒæ—¶é—´å¯æ§ã€‚

---

#### ğŸ”¹ **è¡¨5ï¼šDeepONet ç®—å­å­¦ä¹ ï¼ˆTable 6ï¼‰**
| Model (Trunk) | #Param | Rel. L2 Error | Training Time (s) |
|---------------|--------|----------------|--------------------|
| MLP | 18,921 | 2.08e-2 | 78 |
| KAN | 11,945 | 6.15e-2 | 96 |
| RBF-KAN | 10,625 | 3.70e-2 | 84 |
| **Free-RBF-KAN** | **11,185** | **1.94e-2** âœ… | **88** |

> â¤ Free-RBF-KAN å®ç°**æœ€å°ç›¸å¯¹è¯¯å·®**ï¼Œä¼˜äº MLPï¼Œä¸”å‚æ•°æ›´å°‘ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**
- **è‡ªé€‚åº”ç½‘æ ¼ vs å›ºå®šç½‘æ ¼**ï¼šç§»é™¤å¯å­¦ä¹  centroid å¯¼è‡´è¯¯å·®ä¸Šå‡çº¦ 30%-50%ã€‚
- **è‡ªé€‚åº”å¹³æ»‘åº¦**ï¼šå›ºå®š $\sigma$ ä¼šé™åˆ¶æ¨¡å‹å¯¹å±€éƒ¨å¤æ‚æ€§çš„å“åº”èƒ½åŠ›ã€‚
- **NTK åˆ†ææ˜¾ç¤º**ï¼šFree-RBF-KAN çš„ NTK ç‰¹å¾å€¼è¡°å‡æ›´æ…¢ï¼Œè¡¨æ˜å…¶å…·å¤‡æ›´å¼ºçš„å¤šé¢‘ç‡è¡¨ç¤ºèƒ½åŠ›ï¼Œ**æ— è°±åå·®**ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **Free-RBF-KAN åœ¨å¤šç§ä»»åŠ¡ä¸­ä¸€è‡´ä¼˜äºåŸå§‹ KAN å’Œæ ‡å‡† RBF-KAN**ï¼Œå°¤å…¶åœ¨ç‰©ç†é©±åŠ¨çš„å¤šå°ºåº¦é—®é¢˜ä¸­è¡¨ç°çªå‡ºã€‚
2. âœ… **è®­ç»ƒæ•ˆç‡æ˜¾è‘—æå‡**ï¼šç›¸æ¯” B-spline KANï¼Œè®­ç»ƒæ—¶é—´å‡å°‘ **30%-70%**ï¼Œå¾—ç›Šäºé¿å… De Boor è¿­ä»£ã€‚
3. âœ… **å…·å¤‡ç†è®ºä¿éšœ**ï¼šé¦–æ¬¡å»ºç«‹ RBF-KAN çš„é€šç”¨é€¼è¿‘å®šç†ï¼Œè¯æ˜å…¶ä¸æ˜¯è¿‘ä¼¼æ›¿ä»£å“ï¼Œè€Œæ˜¯ç‹¬ç«‹å¼ºå¤§çš„å‡½æ•°é€¼è¿‘æ¡†æ¶ã€‚
4. âœ… **æ— è°±åå·®ç‰¹æ€§ä¿ç•™**ï¼šNTK åˆ†æè¯å® Free-RBF-KAN ä¸åŸå§‹ KAN ä¸€æ ·ï¼Œèƒ½æœ‰æ•ˆå­¦ä¹ é«˜é¢‘æˆåˆ†ã€‚
5. âœ… **é€‚ç”¨äºå¤æ‚ç§‘å­¦è®¡ç®—åœºæ™¯**ï¼šåœ¨ PINN å’Œ DeepONet ä¸­å‡å–å¾— SOTA æ€§èƒ½ï¼Œé€‚åˆ PDE æ±‚è§£ä¸ç®—å­å­¦ä¹ ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- âŒ åœ¨**é«˜åº¦éç»“æ„åŒ–æ•°æ®**ï¼ˆå¦‚å›¾åƒåˆ†ç±» MNISTï¼‰ä¸Šä»è½åäº MLPï¼Œè¯´æ˜ KAN ç±»æ–¹æ³•æ›´é€‚åˆç»“æ„åŒ–ã€ç‰©ç†è§„å¾‹æ˜ç¡®çš„ä»»åŠ¡ã€‚
- âŒ å‚æ•°é‡è™½ä½äºåŸå§‹ KANï¼Œä½†ä»é«˜äºè½»é‡çº§ RBF-KANï¼Œå­˜åœ¨è¿›ä¸€æ­¥å‹ç¼©ç©ºé—´ã€‚
- âŒ å½“å‰å®ç°ä¾èµ–è‡ªåŠ¨å¾®åˆ†ï¼ˆADï¼‰ï¼Œè‹¥ç”¨äºå¤§è§„æ¨¡éƒ¨ç½²ï¼Œå¯èƒ½éœ€è¿›ä¸€æ­¥ä¼˜åŒ– RBF æ±‚å¯¼æ•ˆç‡ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **å°† Free-RBF-KAN é‡æ„ä¸ºç­‰æ•ˆ MLP**ï¼šå€Ÿé‰´ Actor et al. [2025] çš„æ€æƒ³ï¼Œå°†å…¶è½¬æ¢ä¸ºå¸¦é«˜æ–¯æ¿€æ´»çš„ MLPï¼Œä»è€Œåˆ©ç”¨æˆç†Ÿçš„ MLP ä¼˜åŒ–å·¥å…·é“¾ã€‚
2. **æ¢ç´¢ç¨€ç–åŒ–ä¸ä½ç§©è¿‘ä¼¼**ï¼šé™ä½é«˜ç»´è¾“å…¥ä¸‹çš„ RBF è®¡ç®—è´Ÿæ‹…ã€‚
3. **æ‰©å±•è‡³æ—¶é—´åºåˆ—ä¸å›¾ç»“æ„æ•°æ®**ï¼šç»“åˆ KAN çš„å¯è§£é‡Šæ€§ä¼˜åŠ¿ï¼Œåº”ç”¨äºæ—¶ç©ºå»ºæ¨¡ã€‚
4. **ç¡¬ä»¶åŠ é€Ÿä¸ç¼–è¯‘ä¼˜åŒ–**ï¼šé’ˆå¯¹ RBF è¿ç®—ç‰¹ç‚¹è®¾è®¡ä¸“ç”¨æ¨ç†å¼•æ“ã€‚

---

## **æ€»ç»“**
> ğŸ **Free-RBF-KAN æ˜¯ä¸€æ¬¡æˆåŠŸçš„æ¶æ„é©æ–°**ï¼šå®ƒé€šè¿‡å¼•å…¥**å¯å­¦ä¹ çš„ RBF ç½‘æ ¼ä¸å¹³æ»‘åº¦**ï¼Œè§£å†³äº†ä¼ ç»Ÿ KAN è®¡ç®—æ˜‚è´µã€RBF-KAN è¡¨è¾¾ä¸è¶³çš„é—®é¢˜ï¼Œåœ¨**ç²¾åº¦ã€æ•ˆç‡ã€ç†è®ºå®Œå¤‡æ€§**ä¸‰è€…ä¹‹é—´å–å¾—äº†ä¼˜å¼‚å¹³è¡¡ã€‚è¯¥æ–¹æ³•ç‰¹åˆ«é€‚ç”¨äº**ç§‘å­¦æœºå™¨å­¦ä¹ ã€PDE æ±‚è§£ã€ç®—å­å­¦ä¹ **ç­‰å¼ºè°ƒå¤šå°ºåº¦å»ºæ¨¡ä¸ç‰©ç†ä¸€è‡´æ€§çš„ä»»åŠ¡ï¼Œæ˜¯å½“å‰ KAN å‘å±•è·¯çº¿ä¸­æå…·æ½œåŠ›çš„æ–¹å‘ä¹‹ä¸€ã€‚

</details>

---

### 6. [Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models](https://arxiv.org/abs/2601.07372)

**Authors**: Xin Cheng, Wangding Zeng, Damai Dai, Qinyu Chen, Bingxuan Wang, Zhenda Xie, Kezhao Huang, Xingkai Yu, Zhewen Hao, Yukun Li, Han Zhang, Huishuai Zhang, Dongyan Zhao, Wenfeng Liang  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.07372v1  

#### Abstract
While Mixture-of-Experts (MoE) scales capacity via conditional computation, Transformers lack a native primitive for knowledge lookup, forcing them to inefficiently simulate retrieval through computation. To address this, we introduce conditional memory as a complementary sparsity axis, instantiated...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ä¸»æµçš„ **Large Language Models (LLMs)** ä¸»è¦ä¾èµ– **Mixture-of-Experts (MoE)** å®ç°æ¡ä»¶è®¡ç®—ï¼ˆconditional computationï¼‰ï¼Œé€šè¿‡ç¨€ç–æ¿€æ´»å‚æ•°æå‡æ¨¡å‹å®¹é‡ã€‚ç„¶è€Œï¼ŒTransformer æ¶æ„ç¼ºä¹åŸç”Ÿçš„â€œçŸ¥è¯†æŸ¥æ‰¾â€æœºåˆ¶ï¼Œå¯¼è‡´æ¨¡å‹å¿…é¡»ç”¨æ˜‚è´µçš„åŠ¨æ€è®¡ç®—ï¼ˆå¦‚ Attention å’Œ FFNï¼‰æ¥æ¨¡æ‹Ÿé™æ€çŸ¥è¯†æ£€ç´¢ä»»åŠ¡ï¼ˆå¦‚å‘½åå®ä½“è¯†åˆ«ã€å›ºå®šçŸ­è¯­åŒ¹é…ç­‰ï¼‰ã€‚è¿™ç§åšæ³•æµªè´¹äº†å®è´µçš„è®¡ç®—èµ„æºå’Œç½‘ç»œæ·±åº¦ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **conditional memory** ä½œä¸º MoE æ¡ä»¶è®¡ç®—ä¹‹å¤–çš„**ç¬¬äºŒæ¡ç¨€ç–æ€§è½´çº¿**ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªå…·ä½“å®ç°æ¨¡å—â€”â€”**Engram**ã€‚

- **Engram** æ˜¯ä¸€ç§åŸºäºç°ä»£æ”¹è¿›çš„ **N-gram embedding** çš„æ¡ä»¶è®°å¿†æ¨¡å—ï¼Œæ”¯æŒ **O(1) å¸¸æ•°æ—¶é—´æŸ¥æ‰¾**ã€‚
- å®ƒå°†å±€éƒ¨ã€é™æ€çš„è¯­è¨€æ¨¡å¼ï¼ˆå¦‚ â€œAlexander the Greatâ€ã€â€œPrincess of Walesâ€ï¼‰å­˜å‚¨åœ¨å¤§è§„æ¨¡åµŒå…¥è¡¨ä¸­ï¼Œé€šè¿‡è¾“å…¥ä¸Šä¸‹æ–‡ç”Ÿæˆå“ˆå¸Œé”®è¿›è¡Œæ£€ç´¢ã€‚
- æ£€ç´¢åˆ°çš„åµŒå…¥å‘é‡é€šè¿‡ **context-aware gating** æœºåˆ¶èåˆå›ä¸»å¹²ç½‘ç»œï¼Œç¡®ä¿è¯­ä¹‰ä¸€è‡´æ€§ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **å¼•å…¥â€œæ¡ä»¶å†…å­˜â€ä½œä¸ºæ–°çš„ç¨€ç–æ€§ç»´åº¦**ï¼šåŒºåˆ«äº MoE çš„â€œæ¡ä»¶è®¡ç®—â€ï¼ŒEngram å®ç°çš„æ˜¯â€œæ¡ä»¶æŸ¥æ‰¾â€ï¼Œå½¢æˆäº’è¡¥ã€‚
2. **ç³»ç»Ÿçº§æ•ˆç‡è®¾è®¡**ï¼š
   - åˆ©ç”¨ç¡®å®šæ€§å“ˆå¸Œåœ°å€ï¼Œæ”¯æŒè¿è¡Œæ—¶é¢„å–ï¼ˆprefetchingï¼‰ï¼Œå¯å°†åµŒå…¥è¡¨å¸è½½è‡³ä¸»æœºå†…å­˜ï¼ˆhost memoryï¼‰ï¼Œç¼“è§£ GPU æ˜¾å­˜å‹åŠ›ã€‚
   - æ”¯æŒå¤šçº§ç¼“å­˜ï¼ˆMulti-Level Cache Hierarchyï¼‰ï¼Œåˆ©ç”¨ N-gram çš„ Zipf åˆ†å¸ƒç‰¹æ€§ä¼˜åŒ–è®¿é—®å»¶è¿Ÿã€‚
3. **æ¶æ„é›†æˆä¼˜åŒ–**ï¼š
   - æ”¯æŒä¸ **multi-branch æ¶æ„**ï¼ˆå¦‚ mHCï¼‰ç»“åˆï¼Œå®ç°åˆ†æ”¯ç‰¹å¼‚æ€§é—¨æ§ã€‚
   - å¼•å…¥ **tokenizer compression**ï¼Œåˆå¹¶è¯­ä¹‰ç­‰ä»·çš„å­è¯ tokenï¼ˆå¦‚ `Apple` vs `_apple`ï¼‰ï¼Œæå‡è¯­ä¹‰å¯†åº¦ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”é¡¹ | ä¼ ç»Ÿ MoE | Engram |
|--------|----------|--------|
| ç¨€ç–æ€§ç±»å‹ | æ¡ä»¶è®¡ç®—ï¼ˆconditional computationï¼‰ | æ¡ä»¶å†…å­˜ï¼ˆconditional memoryï¼‰ |
| é™æ€çŸ¥è¯†å¤„ç†æ–¹å¼ | å¤šå±‚ Attention + FFN é‡å»º | O(1) æŸ¥æ‰¾ + èåˆ |
| å†…å­˜æ‰©å±•æ€§ | å—é™äº GPU HBM | å¯å¸è½½è‡³ host memory / SSD |
| æ¨ç†æ•ˆç‡ | åŠ¨æ€è·¯ç”±å¸¦æ¥é€šä¿¡å¼€é”€ | ç¡®å®šæ€§å¯»å€æ”¯æŒé¢„å– |
| è¡¨è¾¾èƒ½åŠ› | åŠ¨æ€æ¨ç†å¼º | é™æ€æ¨¡å¼è®°å¿†é«˜æ•ˆ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **é¢„è®­ç»ƒæ•°æ®**ï¼š262B tokens çš„æ··åˆè¯­æ–™ï¼ˆæœªæ˜ç¡®åˆ—å‡ºï¼Œä½†æåŠä½¿ç”¨ DeepSeek-v3 tokenizerï¼‰
- **è¯„ä¼°åŸºå‡†**ï¼š
  - **çŸ¥è¯†ä¸æ¨ç†**ï¼šMMLU, MMLU-Redux, MMLU-Pro, CMMLU, C-Eval, AGIEval, ARC-Easy/Challenge, TriviaQA, PopQA, BBH
  - **é˜…è¯»ç†è§£**ï¼šDROP, RACE-Middle/High, C3
  - **ä»£ç ä¸æ•°å­¦**ï¼šHumanEval, MBPP, CruxEval, GSM8K, MGSM, MATH
  - **é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›**ï¼šLongPPLï¼ˆä¹¦ç±ã€è®ºæ–‡ã€ä»£ç ã€CoTï¼‰ã€RULERï¼ˆå« NIAHã€Variable Tracking ç­‰å­ä»»åŠ¡ï¼‰

### å®éªŒè®¾ç½®
- **æ¨¡å‹é…ç½®**ï¼š
  - ç»Ÿä¸€ backboneï¼š30 å±‚ Transformerï¼Œhidden size 2560ï¼ŒMLA æ³¨æ„åŠ›ï¼ŒmHC å¤šåˆ†æ”¯è¿æ¥
  - æ‰€æœ‰æ¨¡å‹ä¿æŒ **activated parameters â‰ˆ 3.8B**ï¼Œä¸¥æ ¼æ§åˆ¶ FLOPs å’Œè®­ç»ƒ token æ•°ï¼ˆ262Bï¼‰
- **å¯¹æ¯”æ¨¡å‹**ï¼š
  - **Dense-4B**ï¼šå…¨å¯†é›† FFNï¼Œ4.1B æ€»å‚
  - **MoE-27B**ï¼š72 ä¸ªè·¯ç”±ä¸“å®¶ï¼Œæ€»å‚ 26.7B
  - **Engram-27B**ï¼š55 ä¸ªè·¯ç”±ä¸“å®¶ + 5.7B å‚æ•° Engram æ¨¡å—ï¼Œæ€»å‚ 26.7Bï¼ˆiso-parameterï¼‰
  - **Engram-40B**ï¼šåŒä¸Š backboneï¼ŒEngram æ‰©å±•è‡³ 18.5B å‚æ•°ï¼Œæ€»å‚ 39.5B

### è¯„ä¼°æŒ‡æ ‡
- **è¯­è¨€å»ºæ¨¡**ï¼šPile æµ‹è¯•é›† lossã€éªŒè¯é›† loss
- **ä»»åŠ¡æ€§èƒ½**ï¼šå‡†ç¡®ç‡ï¼ˆAcc.ï¼‰ã€F1ã€Exact Matchï¼ˆEMï¼‰ã€Pass@1
- **é•¿ä¸Šä¸‹æ–‡**ï¼šLongPPLï¼ˆå›°æƒ‘åº¦â†“ï¼‰ã€RULER å„å­ä»»åŠ¡å‡†ç¡®ç‡
- **æ¶ˆèå®éªŒ**ï¼šéªŒè¯æŸå¤±ï¼ˆValidation Lossï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| ä»»åŠ¡ | MoE-27B | Engram-27B | æå‡ |
|------|---------|------------|------|
| **MMLU (Acc.)** | 57.4 | **60.4** | +3.0 |
| **MMLU-Pro (Acc.)** | 28.3 | **30.1** | +1.8 |
| **CMMLU (Acc.)** | 57.9 | **61.9** | +4.0 |
| **BBH (EM)** | 50.9 | **55.9** | +5.0 |
| **ARC-Challenge (Acc.)** | 70.1 | **73.8** | +3.7 |
| **DROP (F1)** | 55.7 | **59.0** | +3.3 |
| **HumanEval (Pass@1)** | 37.8 | **40.8** | +3.0 |
| **GSM8K (EM)** | 58.4 | **60.6** | +2.2 |
| **MATH (EM)** | 28.3 | **30.7** | +2.4 |

> âœ… **å…³é”®å‘ç°**ï¼šæå‡ä¸ä»…å‡ºç°åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚ MMLUï¼‰ï¼Œæ›´æ˜¾è‘—ä½“ç°åœ¨**é€šç”¨æ¨ç†ä¸æ•°å­¦/ä»£ç ä»»åŠ¡**ã€‚

### é•¿ä¸Šä¸‹æ–‡è¡¨ç°ï¼ˆTable 2ï¼‰
åœ¨ **RULER** çš„å¤æ‚æ£€ç´¢ä»»åŠ¡ä¸­ï¼š
- **Multi-Query NIAH**ï¼š84.2 â†’ **97.0**ï¼ˆ+12.8ï¼‰
- **Variable Tracking**ï¼š77.0 â†’ **89.0**ï¼ˆ+12.0ï¼‰
- å³ä½¿åœ¨ä»… 82% é¢„è®­ç»ƒ FLOPs ä¸‹ï¼ŒEngram-27B ä»ä¼˜äºå®Œæ•´è®­ç»ƒçš„ MoE-27B

### æ¶ˆèå®éªŒç»“æœï¼ˆFigure 5ï¼‰
- **æœ€ä¼˜åˆ†é…æ¯”ä¾‹**ï¼šçº¦ 75â€“80% ç¨€ç–é¢„ç®—ç”¨äº MoEï¼Œå…¶ä½™ç”¨äº Engramï¼ˆU-shaped scaling lawï¼‰
- **ç»„ä»¶é‡è¦æ€§æ’åº**ï¼š
  1. **multi-branch integration**ï¼ˆç§»é™¤åæ€§èƒ½å¤§å¹…ä¸‹é™ï¼‰
  2. **tokenizer compression**ï¼ˆæå‡è¯­ä¹‰ä¸€è‡´æ€§ï¼‰
  3. **context-aware gating**ï¼ˆæŠ‘åˆ¶å™ªå£°å’Œæ­§ä¹‰ï¼‰
- **æ’å…¥ä½ç½®æ•æ„Ÿæ€§**ï¼šæ—©æœŸå±‚ï¼ˆå¦‚ Layer 2ï¼‰æ•ˆæœæœ€ä½³ï¼Œç¬¦åˆâ€œå°½æ—©å¸è½½å±€éƒ¨é‡å»ºâ€çš„å‡è®¾
- **N-gram å¤§å°**ï¼š2/3-gram æœ€ä¼˜ï¼›4-gram åœ¨å›ºå®šé¢„ç®—ä¸‹ç•¥å·®ï¼ˆç¨€é‡Šé«˜é¢‘æ¨¡å¼å®¹é‡ï¼‰

### ç³»ç»Ÿæ•ˆç‡æµ‹è¯•ï¼ˆTable 4ï¼‰
- å°† **100B å‚æ•° Engram è¡¨å¸è½½è‡³ CPU å†…å­˜**ï¼Œåœ¨ Dense-8B æ¨¡å‹ä¸Šä»…é€ æˆ **2.8% ååä¸‹é™**
- è¯æ˜å…¶å…·å¤‡ **infrastructure-aware efficiency**ï¼Œå¯çªç ´ GPU æ˜¾å­˜é™åˆ¶

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ¡ä»¶å†…å­˜æ˜¯æœ‰æ•ˆçš„ç¬¬ä¸‰èŒƒå¼**ï¼š
   - Engram ä¸ MoE å½¢æˆäº’è¡¥ï¼šMoE å¤„ç†åŠ¨æ€æ¨ç†ï¼ŒEngram å¤„ç†é™æ€æ¨¡å¼ã€‚
   - å‘ç° **U-shaped scaling law**ï¼šçº¯ MoE æˆ–çº¯ Engram å‡éæœ€ä¼˜ï¼Œæ··åˆåˆ†é…å¯è¾¾æœ€ä½³æ€§èƒ½ã€‚

2. **æ€§èƒ½å¢ç›Šæºäºæ¶æ„æ•ˆç‡æå‡**ï¼š
   - **é‡Šæ”¾æ—©æœŸå±‚è®¡ç®—è´Ÿæ‹…**ï¼šEngram æ›¿ä»£äº†åŸæœ¬éœ€å¤šå±‚ FFN/Attention å®Œæˆçš„æœ¬åœ°æ¨¡å¼é‡å»ºï¼ˆè§ Table 3ï¼‰ã€‚
   - **å¢åŠ æœ‰æ•ˆæ·±åº¦**ï¼šLogitLens å’Œ CKA åˆ†ææ˜¾ç¤ºï¼ŒEngram-27B ç¬¬ 5 å±‚ â‰ˆ MoE-27B ç¬¬ 12 å±‚çš„è¡¨ç¤ºèƒ½åŠ›ã€‚
   - **å¢å¼ºæ³¨æ„åŠ›å…¨å±€èšç„¦èƒ½åŠ›**ï¼šå±€éƒ¨ä¾èµ–ç”±æŸ¥æ‰¾è§£å†³ï¼Œæ³¨æ„åŠ›å¯ä¸“æ³¨äºé•¿ç¨‹ä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚

3. **å¹¿æ³›é€‚ç”¨æ€§**ï¼š
   - ä¸ä»…æå‡çŸ¥è¯†æ£€ç´¢ä»»åŠ¡ï¼Œè¿˜åœ¨ **BBHã€ARCã€MATHã€HumanEval** ç­‰éœ€è¦æ·±å±‚æ¨ç†çš„ä»»åŠ¡ä¸Šå–å¾—æ›´å¤§æ”¶ç›Šã€‚
   - åœ¨ **é•¿ä¸Šä¸‹æ–‡åœºæ™¯** ä¸­è¡¨ç°å°¤ä¸ºçªå‡ºï¼Œæ˜¾è‘—ä¼˜äº MoE åŸºçº¿ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **é™æ€çŸ¥è¯†è¾¹ç•Œæ¨¡ç³Š**ï¼šæŸäº›â€œçœ‹ä¼¼é™æ€â€çš„è¡¨è¾¾å¯èƒ½å…·æœ‰ä¸Šä¸‹æ–‡æ•æ„Ÿå«ä¹‰ï¼ˆpolysemyï¼‰ï¼Œä¾èµ– gating ç¼“è§£ä½†ä»å­˜åœ¨é£é™©ã€‚
- **è®­ç»ƒ-æ¨ç†ä¸ä¸€è‡´é£é™©**ï¼šè‹¥é¢„è®­ç»ƒæ—¶ä¾èµ– Engram å­˜å‚¨å…³é”®äº‹å®ï¼Œè€Œæ¨ç†æ—¶å› å“ˆå¸Œå†²çªæˆ–æœªè¦†ç›–å¯¼è‡´æ£€ç´¢å¤±è´¥ï¼Œå¯èƒ½å¼•å‘å´©æºƒï¼ˆè§ Figure 6ï¼šTriviaQA ä¿ç•™ç‡ä»… 29%ï¼‰ã€‚
- **å¯¹ tokenizer è®¾è®¡æ•æ„Ÿ**ï¼šè™½å¼•å…¥ tokenizer compressionï¼Œä½†ä»ä¾èµ–è‰¯å¥½åˆ†è¯ç­–ç•¥ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **åŠ¨æ€æ›´æ–°æœºåˆ¶**ï¼šå…è®¸ Engram è¡¨åœ¨éƒ¨ç½²åå¢é‡å­¦ä¹ æ–°çŸ¥è¯†ã€‚
- ç»“åˆ **éå‚æ•°åŒ–æ£€ç´¢**ï¼ˆå¦‚ RETROã€REALMï¼‰æ„å»ºæ··åˆè®°å¿†ç³»ç»Ÿã€‚
- è¿›ä¸€æ­¥æ‰©å¤§ Engram è§„æ¨¡ï¼Œæ¢ç´¢ **TB çº§åµŒå…¥è¡¨**ä¸‹çš„è®­ç»ƒä¸æ¨ç†æ•ˆç‡æé™ã€‚
- å°† Engram åº”ç”¨äº **å¤šæ¨¡æ€æ¨¡å‹**ï¼Œå®ç°è·¨æ¨¡æ€çš„å¿«é€Ÿæ¨¡å¼å¬å›ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼š  
> æœ¬æ–‡æå‡ºäº† **conditional memory** ä½œä¸ºä¸€ç§å…¨æ–°çš„ç¨€ç–æ€§èŒƒå¼ï¼Œå¹¶é€šè¿‡ **Engram** æ¨¡å—å®ç°äº†é«˜æ•ˆã€å¯æ‰©å±•çš„çŸ¥è¯†æŸ¥æ‰¾ã€‚å®éªŒè¯æ˜ï¼Œå®ƒä¸ä»…èƒ½æå‡çŸ¥è¯†æ£€ç´¢èƒ½åŠ›ï¼Œæ›´èƒ½é€šè¿‡â€œè§£æ”¾ç½‘ç»œæ·±åº¦â€æ˜¾è‘—å¢å¼ºæ¨¡å‹çš„**é€šç”¨æ¨ç†ä¸é•¿ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›**ï¼Œä¸ºä¸‹ä¸€ä»£ç¨€ç–åŒ– LLM æä¾›äº†é‡è¦çš„æ¶æ„æ€è·¯ã€‚

</details>

---

### 7. [Physics-Informed Tree Search for High-Dimensional Computational Design](https://arxiv.org/abs/2601.06444)

**Authors**: Suvo Banik, Troy D. Loeffler, Henry Chan, Sukriti Manna, Orcun Yildiz, Tom Peterka, Subramanian Sankaranarayanan  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.06444v1  

#### Abstract
High-dimensional design spaces underpin a wide range of physics-based modeling and computational design tasks in science and engineering. These problems are commonly formulated as constrained black-box searches over rugged objective landscapes, where function evaluations are expensive, and gradients...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

**è®ºæ–‡æ ‡é¢˜**: *Physics-Informed Tree Search for High-Dimensional Computational Design*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ç§‘å­¦ä¸å·¥ç¨‹ä¸­çš„**é«˜ç»´è®¡ç®—è®¾è®¡é—®é¢˜**ï¼Œç‰¹åˆ«æ˜¯é‚£äº›å…·æœ‰ä»¥ä¸‹æŒ‘æˆ˜çš„åœºæ™¯ï¼š
- **æ˜‚è´µçš„å‡½æ•°è¯„ä¼°**ï¼ˆå¦‚ DFTã€FEMã€å¤šç‰©ç†åœºæ¨¡æ‹Ÿï¼‰ï¼›
- **æ— æ¢¯åº¦æˆ–æ¢¯åº¦ä¸å¯é **ï¼›
- **ç›®æ ‡å‡½æ•°ä¸ºéå‡¸ã€å¤šæ¨¡æ€ã€å´å²–çš„é»‘ç›’æ™¯è§‚**ï¼›
- **å­˜åœ¨ç‰©ç†çº¦æŸ**ï¼ˆå¦‚å¯¹ç§°æ€§ã€åŒ–å­¦æœ‰æ•ˆæ€§ã€åŠ›å­¦å¯è¡Œæ€§ï¼‰ï¼›
- **ç»´åº¦ç¾éš¾**å¯¼è‡´ä¼ ç»Ÿä¼˜åŒ–å™¨æ•ˆç‡ä½ä¸‹ã€‚

è¿™äº›é—®é¢˜åœ¨ææ–™è®¾è®¡ã€æ™¶ä½“ç»“æ„æœç´¢ã€åŠ¿èƒ½æ¨¡å‹æ‹Ÿåˆå’Œè¿ç»­ä½“å·¥ç¨‹è®¾è®¡ä¸­æ™®éå­˜åœ¨ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Physics-Informed Monte Carlo Tree Search (MCTS)** çš„æ¡†æ¶ï¼Œå°†åŸºäºç­–ç•¥çš„å¼ºåŒ–å­¦ä¹ æ€æƒ³æ‰©å±•åˆ°è¿ç»­ã€é«˜ç»´çš„ç§‘å­¦ä¼˜åŒ–ä»»åŠ¡ä¸­ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **æ–¹å‘æ€§é‡‡æ ·æœºåˆ¶ï¼ˆLogistic Surrogate Samplerï¼‰**  
   å¼•å…¥ä¸€ä¸ªåŸºäºé€»è¾‘å›å½’çš„ä»£ç†æ¨¡å‹ï¼Œä»èŠ‚ç‚¹çš„å†å²æœç´¢è½¨è¿¹ä¸­å­¦ä¹ â€œæˆåŠŸæ–¹å‘â€ï¼Œä»è€Œåœ¨é«˜ç»´ç©ºé—´ä¸­è¿›è¡Œæœ‰åé‡‡æ ·ï¼Œæ˜¾è‘—æå‡é‡‡æ ·æ•ˆç‡ã€‚

2. **æ·±åº¦ä¾èµ–çš„çª—å£ç¼©æ”¾ï¼ˆDepth-based Window Scalingï¼‰**  
   éšç€æ ‘æ·±åº¦å¢åŠ ï¼ŒåŠ¨æ€ç¼©å°é‡‡æ ·åŠå¾„ $ r_{\text{max}} $ï¼Œå®ç°ä»å…¨å±€æ¢ç´¢åˆ°å±€éƒ¨ç²¾ç»†ä¼˜åŒ–çš„å¹³æ»‘è¿‡æ¸¡ã€‚

3. **åˆ†å±‚æ ‘æ‰¹å¤„ç†ï¼ˆHierarchical Batching of Treesï¼‰**  
   - **å…¨å±€æ‰¹æ¬¡ï¼ˆGlobal Batchï¼‰**ï¼šå¤šä¸ªç‹¬ç«‹åˆå§‹åŒ–çš„ MCTS æ ‘å¹¶è¡Œè¿è¡Œï¼Œç¡®ä¿å¤šæ ·åŒ–æ¢ç´¢ï¼›
   - **å±€éƒ¨æ‰¹æ¬¡ï¼ˆLocal Batchï¼‰**ï¼šä»å…¨å±€é˜¶æ®µé€‰å‡ºçš„ä¼˜ç§€å€™é€‰è§£å‡ºå‘ï¼Œå¯åŠ¨æ›´æ·±å±‚æ¬¡çš„å±€éƒ¨ä¼˜åŒ–æ ‘ï¼Œå¢å¼ºæ”¶æ•›èƒ½åŠ›ã€‚

4. **ç‰©ç†ä¿¡æ¯é›†æˆ**  
   åœ¨æœç´¢è¿‡ç¨‹ä¸­æ˜¾å¼åµŒå…¥ç‰©ç†çº¦æŸæ¨¡å—ï¼ˆå¦‚æ™¶æ ¼å¯¹ç§°æ€§ã€åŸå­é—´è·é™åˆ¶ï¼‰ï¼Œç¡®ä¿æ‰€æœ‰ç”Ÿæˆçš„è®¾è®¡æ–¹æ¡ˆå‡æ»¡è¶³ç‰©ç†åˆç†æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **ä¼˜äºä¼ ç»Ÿå…¨å±€ä¼˜åŒ–å™¨**ï¼šåœ¨é«˜ç»´ã€å¤šæ¨¡æ€é—®é¢˜ä¸Šè¡¨ç°ä¼˜äº PSOã€WOAã€GA ç­‰å…ƒå¯å‘å¼ç®—æ³•ï¼›
- **è¶…è¶Šè´å¶æ–¯ä¼˜åŒ–ï¼ˆBOï¼‰**ï¼šæ— éœ€æ„å»ºé«˜æˆæœ¬çš„é«˜ç»´ä»£ç†æ¨¡å‹ï¼Œåœ¨è¯„ä¼°æ¬¡æ•°æ›´å°‘çš„æƒ…å†µä¸‹è¾¾åˆ°æ›´é«˜ç²¾åº¦ï¼›
- **å…‹æœæ ‡å‡† MCTS çš„å±€é™**ï¼šè§£å†³äº†ç»å…¸ MCTS åœ¨è¿ç»­ç©ºé—´ä¸­å› å›ºå®šåŠ¨ä½œç©ºé—´è€Œå¯¼è‡´çš„ä½æ•ˆé—®é¢˜ï¼›
- **å¯è§£é‡Šæ€§å¼º**ï¼šå†³ç­–è¿‡ç¨‹é€šè¿‡æ ‘ç»“æ„å¯è§†åŒ–ï¼Œä¾¿äºåˆ†ææœç´¢è·¯å¾„å’Œç‰©ç†è§„å¾‹æŒ–æ˜ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸æµ‹è¯•é—®é¢˜
å®éªŒæ¶µç›–ä¸‰å¤§ç±»çœŸå®ä¸–ç•Œç§‘å­¦è®¾è®¡ä»»åŠ¡åŠä¸€ç»„æ ‡å‡†åŸºå‡†å‡½æ•°ï¼š

#### ï¼ˆ1ï¼‰åŸºå‡†æµ‹è¯•å‡½æ•°ï¼ˆBenchmark Functionsï¼‰
å…±ä½¿ç”¨ 23 ä¸ªæ ‡å‡†æµ‹è¯•å‡½æ•°ï¼Œåˆ†ä¸ºä¸‰ç±»ï¼š
- **å•å³°å‡½æ•°ï¼ˆUnimodal, F1â€“F7ï¼‰**ï¼šå¦‚ Sphereã€Rosenbrockï¼Œç”¨äºè¯„ä¼°æ”¶æ•›é€Ÿåº¦ï¼›
- **å¤šå³°å‡½æ•°ï¼ˆMultimodal, F8â€“F13ï¼‰**ï¼šå¦‚ Rastriginã€Ackleyã€Schwefelï¼Œæµ‹è¯•é€ƒé€¸å±€éƒ¨æœ€ä¼˜çš„èƒ½åŠ›ï¼›
- **å›ºå®šç»´åº¦å¤åˆå‡½æ•°ï¼ˆFixed-Dimensional, F14â€“F23ï¼‰**ï¼šå¦‚ Shekelã€Six-Hump Camelbackï¼Œæ£€éªŒç²¾ç»†æœç´¢èƒ½åŠ›ã€‚

#### ï¼ˆ2ï¼‰å®é™…ç§‘å­¦åº”ç”¨æ¡ˆä¾‹
- **æ™¶ä½“ç»“æ„ä¼˜åŒ–ï¼ˆCrystal Structure Design, CSDï¼‰**
  - Auâ‚ƒâ‚… çº³ç±³å›¢ç°‡ï¼ˆ105Dï¼‰
  - äºŒç»´ç¡…çƒ¯ï¼ˆSiliceneï¼‰ä¸åŒç›¸æ€ï¼ˆ9â€“24Dï¼‰
  - ä½“ç›¸ç¡…ï¼ˆBulk Si, 30Dï¼‰
- **åŸå­é—´åŠ¿èƒ½æ¨¡å‹æ‹Ÿåˆï¼ˆInteratomic Potential Model, IAPï¼‰**
  - ä½¿ç”¨ Tersoff åŠ¿æ‹Ÿåˆ Al çº³ç±³å›¢ç°‡çš„ DFT èƒ½é‡ä¸åŠ›æ•°æ®ï¼ˆ13D å‚æ•°ç©ºé—´ï¼‰
- **è¿ç»­å°ºåº¦å·¥ç¨‹è®¾è®¡**
  - ç„Šæ¥æ¢ä¼˜åŒ–ï¼ˆWelded Beam, 4Dï¼‰
  - å‹åŠ›å®¹å™¨è®¾è®¡ï¼ˆPressure Vessel, 4Dï¼‰

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- æ‰€æœ‰å®éªŒè¿›è¡Œ **30 æ¬¡ç‹¬ç«‹è¿è¡Œ**ä»¥è¯„ä¼°é²æ£’æ€§å’Œæ–¹å·®ï¼›
- ä¸»è¦è¯„ä¼°æŒ‡æ ‡ï¼š
  - **æœ€ä¼˜ç›®æ ‡å€¼ï¼ˆBest Objective Valueï¼‰**
  - **å¹³å‡å€¼ä¸æ ‡å‡†å·®ï¼ˆMean Â± Stdï¼‰**
  - **æ”¶æ•›æ›²çº¿ï¼ˆObjective vs. Evaluationsï¼‰**
  - **å‚æ•°è¯¯å·®ï¼ˆLattice, Coordinates, Anglesï¼‰**
  - **èƒ½é‡/åŠ›é¢„æµ‹è¯¯å·®ï¼ˆMAE, RMSEï¼‰**

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Metaheuristics**: PSOã€WOAã€GAã€GSA
- **å…¶ä»– MCTS å˜ä½“**ï¼šHypersphere MCTSï¼ˆç­‰å‘é‡‡æ ·ï¼‰ã€Random Search
- æ–‡çŒ®æŠ¥é“çš„ç»å…¸ç»“æœï¼ˆå¦‚ Debâ€™s GAã€Lee & Geemâ€™s HSï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆè§ Table 1ï¼‰

| å‡½æ•°ç±»åˆ« | ç¤ºä¾‹å‡½æ•° | MCTS æœ€ä¼˜ç»“æœ | æœ€ä½³åŸºçº¿æ–¹æ³• | ç»“æœå¯¹æ¯” |
|--------|--------|---------------|--------------|----------|
| Unimodal | F1 (Sphere) | **0.00000E+00** | Hypersphere MCTS (1.72E-22) | âœ… æ˜¾è‘—æ›´ä¼˜ |
| Unimodal | F4 (Max) | **3.65E-14** | WOA (0.0726) | âœ… è¿œè¶… |
| Multimodal | F8 (Schwefel) | **-7.98E+03** | Hypersphere (-7.62E+03) | âœ… æ›´æ·±æå°å€¼ |
| Multimodal | F11 (Griewank) | **7.68E+00** | WOA (7.40) | âœ… æ›´ç¨³å®š |
| Fixed-Dim | F14 (Shekel) | **0.99800** | WOA (0.9994) | âœ… æ¥è¿‘æœ€ä¼˜ |
| Fixed-Dim | F16 (Camelback) | **-1.03163** | WOA (-1.03163) | âœ… è¾¾åˆ°ç†è®ºæœ€ä¼˜ |

> æ³¨ï¼šåŠ ç²—è¡¨ç¤ºåœ¨è¯¥å‡½æ•°ä¸Šå–å¾—æœ€ä½å¹³å‡å€¼ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ **21 out of 23** åŸºå‡†å‡½æ•°ä¸Šï¼ŒMCTS è¡¨ç°ä¼˜äºæˆ–ç­‰äºæ‰€æœ‰åŸºçº¿ï¼›
- åœ¨ **F1 Sphere** ä¸Šè¾¾åˆ°æ•°å€¼é›¶ï¼ˆè¿œè¶… Hypersphere MCTS çš„ 10â»Â²Â²ï¼‰ï¼›
- åœ¨ **F8 Schwefel** ä¸Šæ‰¾åˆ°æ›´æ·±çš„èƒ½é‡ç›†åœ°ï¼ˆ-7981 vs -7620ï¼‰ï¼Œæ˜¾ç¤ºæ›´å¼ºçš„å…¨å±€æ¢ç´¢èƒ½åŠ›ï¼›
- åœ¨ **F14â€“F23 å›ºå®šç»´åº¦å‡½æ•°**ä¸­ï¼Œå¤šæ¬¡è¾¾åˆ°ç†è®ºå…¨å±€æœ€ä¼˜ï¼Œä¸”æ–¹å·®æå°ï¼›
- åœ¨ç„Šæ¥æ¢å’Œå‹åŠ›å®¹å™¨é—®é¢˜ä¸­ï¼Œåˆ†åˆ«è·å¾— **1.697958** å’Œ **5898.135917** çš„æœ€ä¼˜æˆæœ¬ï¼Œä¼˜äºæ–‡çŒ®æ‰€æœ‰å·²çŸ¥è§£ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆéšå«äºæ–¹æ³•ç»„ä»¶åˆ†æï¼‰
å°½ç®¡æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»æ–¹æ³•æè¿°å’Œå›¾ç¤ºå¯æ¨æ–­å„ç»„ä»¶ä½œç”¨ï¼š
- **Logistic Surrogate**ï¼šç›¸æ¯”å„å‘åŒæ€§ Hypersphere é‡‡æ ·ï¼Œåœ¨ F1/F8 ä¸Šæ˜¾è‘—åŠ å¿«æ”¶æ•›ï¼›
- **Window Scaling**ï¼šä½¿æ—©æœŸå¹¿åŸŸæ¢ç´¢ä¸åæœŸç²¾ç»†è°ƒä¼˜æ— ç¼è¡”æ¥ï¼ˆè§ Figure 3a-cï¼‰ï¼›
- **Hierarchical Batching**ï¼šæœ‰æ•ˆé¿å…æ—©ç†Ÿæ”¶æ•›ï¼Œé™ä½è·¨è¿è¡Œæ–¹å·®ï¼Œæå‡é²æ£’æ€§ï¼›
- **Population of Trees**ï¼šå…è®¸å¤šåŒºåŸŸåŒæ­¥æ¢ç´¢ï¼Œæé«˜å‘ç°æ–°å¯è¡Œè§£çš„æ¦‚ç‡ï¼ˆè§ Figure 6c/fï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **MCTS å¯æˆåŠŸæ¨å¹¿è‡³é«˜ç»´è¿ç»­ç©ºé—´**ï¼šé€šè¿‡å¼•å…¥æ–¹å‘å­¦ä¹ ã€çª—å£ç¼©æ”¾å’Œç¾¤ä½“æ ‘æœºåˆ¶ï¼Œå…‹æœäº†ä¼ ç»Ÿ MCTS åœ¨è¿ç»­åŸŸçš„ç“¶é¢ˆã€‚
2. **ç‰©ç†å¼•å¯¼æ˜¾è‘—æå‡æ•ˆç‡**ï¼šç»“åˆç‰©ç†çº¦æŸå’Œå±€éƒ¨ä¼˜åŒ–å™¨ï¼Œä½¿å¾—æœç´¢å§‹ç»ˆèšç„¦äºæœ‰æ„ä¹‰çš„åŒºåŸŸï¼Œå‡å°‘æ— æ•ˆè¯„ä¼°ã€‚
3. **é€šç”¨æ€§å¼º**ï¼šåŒä¸€æ¡†æ¶é€‚ç”¨äºä»åŸå­çº§ï¼ˆCSD, IAPï¼‰åˆ°å®è§‚å·¥ç¨‹ï¼ˆWelded Beam, Pressure Vesselï¼‰çš„ä¸åŒå°ºåº¦è®¾è®¡ä»»åŠ¡ã€‚
4. **é«˜æ•ˆä¸”ç¨³å¥**ï¼šåœ¨æœ‰é™è¯„ä¼°é¢„ç®—ä¸‹ï¼ˆå¦‚ <15,000 æ¬¡ï¼‰ï¼Œä»èƒ½ç¨³å®šæ”¶æ•›è‡³é«˜è´¨é‡è§£ï¼Œå°¤å…¶é€‚åˆæ˜‚è´µä»¿çœŸåœºæ™¯ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å®Œå…¨é»‘ç®±è®¾å®š**ï¼šæœªåˆ©ç”¨ä»»ä½•å¤šä¿çœŸåº¦ä¿¡æ¯æˆ–å¤šå°ºåº¦å»ºæ¨¡ä¼˜åŠ¿ï¼›
- **æ— è·¨ä»»åŠ¡çŸ¥è¯†è¿ç§»**ï¼šæ¯æ¬¡è¿è¡Œç‹¬ç«‹è®­ç»ƒï¼Œæ— æ³•å…±äº«å†å²ç»éªŒï¼›
- **çº¦æŸå¤„ç†ä¾èµ–æƒ©ç½šé¡¹**ï¼šå°šæœªé›†æˆç¬¦å·åŒ–çº¦æŸç”Ÿæˆæˆ–å¯è¡Œæ€§å…ˆéªŒæ¨¡å‹ï¼›
- **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼šç»´æŠ¤å¤§é‡æ ‘ç»“æ„å’Œ surrogate æ¨¡å‹å¸¦æ¥é¢å¤–å†…å­˜è´Ÿæ‹…ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **Foundation-guided Search**ï¼šå¼•å…¥é¢„è®­ç»ƒç‰©ç†ç¼–ç å™¨ä½œä¸ºæ¢ç´¢å…ˆéªŒï¼›
2. **Multi-Agent Tree Ensembles**ï¼šæ”¯æŒæ ‘é—´è®°å¿†å…±äº«ä¸çŸ¥è¯†è¿ç§»ï¼›
3. **Multi-fidelity Integration**ï¼šèåˆä½ç²¾åº¦å¿«é€Ÿè¯„ä¼°ä¸é«˜ç²¾åº¦éªŒè¯ï¼›
4. **é—­ç¯è‡ªä¸»å®éªŒç³»ç»Ÿ**ï¼šå°†æœ¬æ¡†æ¶é›†æˆè‡³æœºå™¨äººå®éªŒå¹³å°ï¼Œå®ç° AI-driven è‡ªä¸»å‘ç°ã€‚

---

## æ€»ç»“
æœ¬æ–‡æå‡ºçš„ **Physics-Informed MCTS** æ˜¯ä¸€ç§é¢å‘é«˜ç»´ç§‘å­¦è®¾è®¡çš„å¼ºå¤§ä¼˜åŒ–èŒƒå¼ã€‚å®ƒä¸ä»…åœ¨æ•°å­¦åŸºå‡†ä¸Šå…¨é¢è¶…è¶Šä¸»æµå…ƒå¯å‘å¼ç®—æ³•ï¼Œè¿˜åœ¨æ™¶ä½“ç»“æ„é¢„æµ‹ã€åŠ¿èƒ½æ‹Ÿåˆå’Œå·¥ç¨‹è®¾è®¡ç­‰å¤æ‚ç‰©ç†é—®é¢˜ä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ã€‚è¯¥æ–¹æ³•æ ‡å¿—ç€ä»â€œé¢„æµ‹æ¨¡å‹â€å‘â€œå†³ç­–å¼•æ“â€çš„è½¬å˜ï¼Œä¸ºæ„å»ºä¸‹ä¸€ä»£ AI-native ç§‘å­¦è®¾è®¡åŸºç¡€è®¾æ–½æä¾›äº†åšå®åŸºç¡€ã€‚

</details>

---

### 8. [Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM Training](https://arxiv.org/abs/2601.07320)

**Authors**: Xue Gong, Qi Yi, Ziyuan Nan, Guanhua Huang, Kejiao Li, Yuhao Jiang, Ruibin Xiong, Zenan Xu, Jiaming Guo, Shaohui Peng, Bo Zhou  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.07320v1  

#### Abstract
Training Large Language Models (LLMs) for reasoning tasks is increasingly driven by Reinforcement Learning with Verifiable Rewards (RLVR), where Proximal Policy Optimization (PPO) provides a principled framework for stable policy updates. However, the practical application of PPO is hindered by unre...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM Training*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨**Reinforcement Learning with Verifiable Rewards (RLVR)** èŒƒå¼ä¸‹è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œé•¿ä¸Šä¸‹æ–‡æ¨ç†ä»»åŠ¡æ—¶ï¼Œä¼ ç»Ÿçš„ **Proximal Policy Optimization (PPO)** é¢ä¸´ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼š**ä¸å¯é çš„ä¼˜åŠ¿ä¼°è®¡ï¼ˆadvantage estimationï¼‰**ã€‚

å…·ä½“è€Œè¨€ï¼Œç”±äº RLVR ä¸­å¥–åŠ±ä¿¡å·ç¨€ç–ï¼ˆä»…åœ¨æœ€ç»ˆè¾“å‡ºç»™å‡ºäºŒå…ƒåé¦ˆï¼‰ï¼Œå¯¼è‡´ä»·å€¼å‡½æ•°ï¼ˆvalue functionï¼‰å¯¹ä¸­é—´ token çš„é¢„æµ‹ä¸å‡†ç¡®ã€‚è€Œæ ‡å‡†çš„ **Generalized Advantage Estimation (GAE)** åœ¨æ¯ä¸ª token ä¸Šè¿›è¡Œ bootstrapping å¹¶èšåˆå¤šæ­¥ä¼˜åŠ¿ï¼Œè¿™ç§ç»†ç²’åº¦çš„ token-level ä¼°è®¡ä¼šæ”¾å¤§ç”±é”™è¯¯ value prediction å¼•å…¥çš„åå·®ï¼Œä»è€ŒæŸå®³ç­–ç•¥æ›´æ–°çš„è´¨é‡ï¼Œå°¤å…¶åœ¨é•¿åºåˆ—æ¨ç†ä¸­è¡¨ç°æ›´å·®ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSegmental Advantage Estimation (SAE)
ä½œè€…æå‡º **Segmental Advantage Estimation (SAE)**ï¼Œä¸€ç§æ–°å‹çš„ä¼˜åŠ¿ä¼°è®¡æ¡†æ¶ï¼Œæ—¨åœ¨ç¼“è§£ GAE åœ¨ RLVR åœºæ™¯ä¸‹çš„é«˜åå·®é—®é¢˜ã€‚

#### æ ¸å¿ƒæ€æƒ³ï¼š
- **æ”¾å¼ƒ token-level çš„å¯†é›† bootstrapping**ï¼Œè½¬è€Œé‡‡ç”¨ **segment-level çš„ç¨€ç–ä¼˜åŠ¿ä¼°è®¡**ã€‚
- å°†ç”Ÿæˆçš„åºåˆ—åˆ’åˆ†ä¸ºè¯­ä¹‰è¿è´¯çš„å­æ®µï¼ˆsegmentsï¼‰ï¼Œä»…åœ¨è¿™äº›â€œè¯­ä¹‰è¾¹ç•Œâ€å¤„è®¡ç®—å¹¶èšåˆä¼˜åŠ¿å€¼ã€‚
- åˆ©ç”¨ **ä½æ¦‚ç‡ token** ä½œä¸ºå¯å‘å¼åˆ†å‰²è¾¹ç•Œï¼ˆlow-probability tokens indicate high surprise â†’ å¯èƒ½æ˜¯æ¨ç†æ­¥éª¤çš„è½¬æŠ˜ç‚¹ï¼‰ã€‚

#### æ–¹æ³•æµç¨‹ï¼š
1. **åŸºäºæ¦‚ç‡çš„åˆ†æ®µï¼ˆProbability-based Segmentationï¼‰**  
   å®šä¹‰åˆ†å‰²å‡½æ•° $ f_s(t) = 1 $ å½“ä¸”ä»…å½“å½“å‰ token çš„ç”Ÿæˆæ¦‚ç‡ä½äºé˜ˆå€¼ $ p $ï¼Œå³ $ P_{\text{model}}(s_t | s_{<t}) < p $ã€‚
2. **é€‰æ‹©æ€§ä¼˜åŠ¿é›†æˆï¼ˆSelective Advantage Integrationï¼‰**  
   ä»…åœ¨åˆ†æ®µè¾¹ç•Œï¼ˆåŠåºåˆ—æœ«å°¾ï¼‰è®¡ç®— n-step ä¼˜åŠ¿ï¼Œå¹¶é€šè¿‡ç±»ä¼¼ GAE çš„åŠ æƒæ–¹å¼ç»„åˆæˆæœ€ç»ˆä¼˜åŠ¿ä¼°è®¡ã€‚
3. **é€’å½’å½¢å¼å®ç°é«˜æ•ˆè®¡ç®—**  
   æ¨å¯¼å‡ºä¸ GAE ç±»ä¼¼çš„é€’å½’å…¬å¼ï¼Œå…¶ä¸­æŠ˜æ‰£å› å­ $ \lambda $ åŠ¨æ€è°ƒæ•´ï¼šåœ¨æ®µå†…æ— è¡°å‡ï¼Œåœ¨è·¨æ®µæ—¶åº”ç”¨æŒ‡æ•°è¡°å‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | SAE çš„æ”¹è¿› |
|------|--------|-----------|
| **GRPO** | æ— éœ€ value modelï¼Œç¼ºä¹ç»†ç²’åº¦ä¿¡ç”¨åˆ†é… | ä¿ç•™ value model æä¾›çš„ç²¾ç»†ä¿¡å· |
| **PPO (Î»=1)** | ä½¿ç”¨ Monte Carlo å›æŠ¥ï¼Œæ–¹å·®å¤§ã€è®­ç»ƒä¸ç¨³å®š | å‡å°‘å™ªå£°ä¼°è®¡ç‚¹ï¼Œé™ä½æ–¹å·®ä¸åå·® |
| **PPO (adaptive Î»)** | ä»ä¸º token-level bootstrappingï¼Œç»§æ‰¿ GAE åå·® | ä»æ ¹æœ¬ä¸Šå‡å°‘ bootstrapping æ¬¡æ•°ï¼Œæ§åˆ¶åå·®æ¥æº |

> âœ… **SAE çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºï¼šé€šè¿‡è¯­ä¹‰æ„ŸçŸ¥çš„ç¨€ç–åŒ–ä¼˜åŠ¿ä¼°è®¡ï¼Œæ˜¾è‘—é™ä½ä¼°è®¡åå·®ï¼ŒåŒæ—¶ä¿æŒè®¡ç®—æ•ˆç‡å’Œç¨³å®šæ€§ã€‚**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼šDAPO-Math-17kï¼ˆ17,000 ä¸ªé«˜è´¨é‡æ•°å­¦é¢˜ï¼‰
- **æµ‹è¯•æ•°æ®ï¼ˆout-of-distributionï¼‰**ï¼š
  - AIME'24, AIME'25ï¼ˆç¾å›½æ•°å­¦é‚€è¯·èµ›ï¼‰
  - AMCï¼ˆç¾å›½æ•°å­¦ç«èµ›ï¼‰
  - BeyondAIMEï¼ˆæ›´å…·æŒ‘æˆ˜æ€§çš„æ¨ç†ä»»åŠ¡é›†åˆï¼‰

### æ¨¡å‹ä¸å®ç°ç»†èŠ‚
- **ä¸»å¹²æ¨¡å‹**ï¼šQwen3 ç³»åˆ—ï¼ˆ4B / 8B / 14Bï¼‰
- **è®­ç»ƒé…ç½®**ï¼š
  - æ¯æ­¥é‡‡æ · 4096 æ¡ rolloutï¼ˆæ¥è‡ª 512 promptsï¼Œæ¯ prompt 8 æ¡ï¼‰
  - æœ€å¤§å“åº”é•¿åº¦ï¼š8192 tokens
  - Actor å­¦ä¹ ç‡ï¼š1e-6ï¼ŒValue model å­¦ä¹ ç‡ï¼š1e-5
  - ä¸ä½¿ç”¨ KL æ­£åˆ™æˆ–ç†µæŸå¤±
  - SAE åˆ†å‰²é˜ˆå€¼ $ p = 0.2 $ï¼ˆç»Ÿä¸€è®¾ç½®ï¼Œæœªè°ƒå‚ï¼‰

### è¯„ä¼°æŒ‡æ ‡
- **ä¸»è¦æŒ‡æ ‡**ï¼šé›¶æ ·æœ¬å‡†ç¡®ç‡ï¼ˆzero-shot accuracyï¼‰åœ¨å››ä¸ª OOD æµ‹è¯•é›†ä¸Šçš„å¹³å‡å¾—åˆ†
- **è¾…åŠ©åˆ†ææŒ‡æ ‡**ï¼š
  - è®­ç»ƒç¨³å®šæ€§ï¼ˆloss / entropy æ›²çº¿ï¼‰
  - æ ·æœ¬æ•ˆç‡ï¼ˆearly-stage performanceï¼‰
  - ä¸è¿‘ä¼¼çœŸå®ä¼˜åŠ¿ï¼ˆMonte Carlo ä¼°è®¡ï¼‰çš„ç›¸å…³æ€§ï¼ˆPearson correlationï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **GRPO*** | æ—  value modelï¼Œgroup-level ä¼˜åŠ¿ä¼°è®¡ |
| **PPO (Î»=1)** | GAE ä¸­ Î»=1ï¼Œç­‰ä»·äº MC å›æŠ¥ |
| **PPO (adaptive Î»)** | VAPO æ–¹æ³•ï¼ŒÎ» éšç”Ÿæˆé•¿åº¦è‡ªé€‚åº”è°ƒæ•´ |

> *æ³¨ï¼šGRPO å› è®­ç»ƒä¸ç¨³å®šï¼Œåœ¨ 400 æ­¥ååœæ­¢è¯„ä¼°ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1ï¼‰
æ‰€æœ‰æ–¹æ³•å‡åœ¨ **Qwen3-8B-base** ä¸Šè®­ç»ƒï¼Œè¯„ä¼°å¹³å‡åˆ†æ•°å¦‚ä¸‹ï¼š

| æ–¹æ³• | AIME'24 | AIME'25 | AMC | BeyondAIME | **Average** |
|------|---------|---------|-----|------------|-------------|
| GRPO* | 35.42 | 27.50 | 74.10 | 15.31 | 38.08 |
| PPO (Î»=1) | 34.79 | 29.17 | 74.85 | 16.25 | 38.76 |
| PPO (adaptive Î») | 35.42 | 25.42 | 78.39 | 16.33 | 38.89 |
| **SAE (ours)** | **38.54** | **30.21** | **77.56** | **17.62** | **40.98** |

âœ… **SAE ä»¥ 40.98% çš„å¹³å‡åˆ†é¢†å…ˆæœ€å¼ºåŸºçº¿ï¼ˆPPO adaptive Î»ï¼‰2.09 ä¸ªç™¾åˆ†ç‚¹**ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ€§èƒ½æå‡å…¨é¢**ï¼šåœ¨æ‰€æœ‰å››ä¸ªæµ‹è¯•é›†ä¸Šå‡ä¼˜äºæˆ–æŒå¹³äºæœ€ä½³åŸºçº¿ã€‚
- **è®­ç»ƒæ›´ç¨³å®š**ï¼š
  - GRPO åœ¨ ~400 æ­¥åå‡ºç°æ€§èƒ½å´©æºƒï¼›
  - æ‰€æœ‰ PPO å˜ä½“ï¼ˆå« SAEï¼‰å‡ç¨³å®šæ”¶æ•›ã€‚
- **æ ·æœ¬æ•ˆç‡æ›´é«˜**ï¼šä»æ—©æœŸè®­ç»ƒé˜¶æ®µèµ·ï¼ŒSAE å³è¡¨ç°å‡ºæ›´å¿«çš„æ€§èƒ½å¢é•¿ï¼ˆè§ Figure 2ï¼‰ã€‚
- **è·¨æ¨¡å‹è§„æ¨¡ä¸€è‡´æœ‰æ•ˆ**ï¼š
  - åœ¨ Qwen3-4B / 8B / 14B ä¸Šå‡æŒç»­è¶…è¶Š GRPO å’Œ PPO(Î»=1)ï¼ˆFigure 3ï¼‰ã€‚
- **è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›å¼º**ï¼š
  - åœ¨ CODEï¼ˆAPPS, Codeforces ç­‰ï¼‰å’Œ STEMï¼ˆGPQA-Diamondï¼‰é¢†åŸŸä¹Ÿæ˜¾è‘—ä¼˜äºåŸºçº¿ï¼ˆFigure 4ï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰ä¸è¿‘ä¼¼çœŸå®ä¼˜åŠ¿çš„ç›¸å…³æ€§ï¼ˆFigure 5ï¼‰
- æ„é€ åŸºäºå¤šæ¬¡ rollout çš„ Monte Carlo ä¼°è®¡ä½œä¸ºè¿‘ä¼¼ ground truth $ A^* $
- **SAE çš„ä¼˜åŠ¿ä¼°è®¡ä¸ $ A^* $ çš„ Pearson ç›¸å…³ç³»æ•°æœ€é«˜**ï¼Œè¡¨æ˜å…¶ä¼°è®¡æ›´æ¥è¿‘çœŸå®ä¼˜åŠ¿ã€‚
- å³ä½¿æœ€ä¼˜ Î» ä¸‹çš„ GAEï¼Œå…¶ç›¸å…³æ€§ä¹Ÿå§‹ç»ˆä½äº SAEã€‚

#### ï¼ˆ2ï¼‰å¯¹åˆ†å‰²é˜ˆå€¼ $ p $ çš„é²æ£’æ€§ï¼ˆFigure 6aï¼‰
- æµ‹è¯• $ p \in \{0.05, 0.2, 0.5, 0.9\} $
- æ‰€æœ‰è®¾ç½®ä¸‹ SAE å‡ä¼˜äºåŸºçº¿ï¼Œè¯´æ˜æ€§èƒ½å¢ç›Šæºäºæ–¹æ³•æœ¬èº«è€Œéå‚æ•°å¾®è°ƒã€‚

#### ï¼ˆ3ï¼‰ä¼˜åŠ¿è´¨é‡ä¸æœ€ç»ˆæ€§èƒ½çš„ç›¸å…³æ€§ï¼ˆFigure 6bï¼‰
- å„æ–¹æ³•çš„ **Corr($ \hat{A}, A^* $)** ä¸å…¶æœ€ç»ˆæµ‹è¯•å¾—åˆ†é«˜åº¦æ­£ç›¸å…³ã€‚
- è¡¨æ˜æ›´å¥½çš„ä¼˜åŠ¿ä¼°è®¡ç›´æ¥å¸¦æ¥æ›´å¼ºçš„ç­–ç•¥å­¦ä¹ èƒ½åŠ›ã€‚

#### ï¼ˆ4ï¼‰ä¸åŒåˆ†æ®µç­–ç•¥æ¯”è¾ƒï¼ˆFigure 8ï¼‰
| åˆ†æ®µæ–¹å¼ | æ€§èƒ½ |
|--------|------|
| Uniform segmentation (M=200) | ä¼˜äº PPOï¼Œä½†å¼±äº SAE |
| Newline-based segmentation (\n) | ä¼˜äº PPOï¼Œä½†ä»ä¸å¦‚ SAE |
| **Probability-based (SAE)** | **æœ€ä½³æ€§èƒ½** |

ğŸ‘‰ è¯æ˜ **åŸºäºæ¨¡å‹ä¸ç¡®å®šæ€§ï¼ˆä½æ¦‚ç‡ tokenï¼‰çš„åŠ¨æ€åˆ†æ®µæ˜¯æœ€æœ‰æ•ˆçš„ç­–ç•¥**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Token-level GAE åœ¨ RLVR ä¸­å¼•å…¥è¿‡å¤šåå·®**ï¼Œå°¤å…¶æ˜¯åœ¨é•¿åºåˆ—ç¨€ç–å¥–åŠ±åœºæ™¯ä¸‹ã€‚
2. **è¯­ä¹‰åˆ†æ®µå¯è‡ªç„¶æ•æ‰æ¨ç†è¿‡ç¨‹çš„å…³é”®è½¬æŠ˜ç‚¹**ï¼Œé€‚åˆä½œä¸ºä¼˜åŠ¿ä¼°è®¡çš„é”šå®šç‚¹ã€‚
3. **SAE æ˜¾è‘—æå‡äº† PPO åœ¨é•¿ä¸Šä¸‹æ–‡æ¨ç†ä¸­çš„æœ‰æ•ˆæ€§**ï¼Œä½“ç°åœ¨ï¼š
   - æ›´é«˜çš„æœ€ç»ˆæ€§èƒ½
   - æ›´å¼ºçš„è®­ç»ƒç¨³å®šæ€§
   - æ›´å¥½çš„æ ·æœ¬æ•ˆç‡
   - æ›´ä¼˜çš„ä¼˜åŠ¿ä¼°è®¡ç²¾åº¦ï¼ˆä¸ $ A^* $ æ›´ç›¸å…³ï¼‰
4. **SAE çš„æ”¶ç›Šå…·æœ‰æ™®é€‚æ€§**ï¼šè·¨è¶Šä¸åŒæ¨¡å‹è§„æ¨¡ï¼ˆ4Bâ€“14Bï¼‰ã€ä»»åŠ¡é¢†åŸŸï¼ˆMath, Code, STEMï¼‰å‡æˆç«‹ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–ç”Ÿæˆåºåˆ—çš„æ¦‚ç‡åˆ†å¸ƒ**ï¼šè‹¥æ¨¡å‹æ•´ä½“ç½®ä¿¡åº¦è¿‡é«˜æˆ–è¿‡ä½ï¼Œå¯èƒ½å½±å“åˆ†æ®µè´¨é‡ã€‚
- **å¯å‘å¼è®¾è®¡**ï¼šç›®å‰ä½¿ç”¨å›ºå®šé˜ˆå€¼ $ p $ï¼Œå°šæœªå®ç°åŠ¨æ€è‡ªé€‚åº”è°ƒæ•´ã€‚
- **ç†è®ºåˆ†æåŸºäºå‡åŒ€åˆ†æ®µå‡è®¾**ï¼šå®é™…ä½¿ç”¨çš„æ¦‚ç‡é©±åŠ¨åˆ†æ®µæ›´å¤æ‚ï¼Œç†è®ºä¸å®è·µå­˜åœ¨ä¸€å®šå·®è·ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜çº§çš„åˆ†æ®µç­–ç•¥ï¼ˆå¦‚åŸºäºè¯­ä¹‰èšç±»ã€æ³¨æ„åŠ›æ¨¡å¼ã€å¤–éƒ¨è§£æå™¨ï¼‰ã€‚
- è®¾è®¡å¯å­¦ä¹ çš„ã€ç«¯åˆ°ç«¯çš„åˆ†æ®µæœºåˆ¶ã€‚
- åŠ¨æ€è°ƒèŠ‚åˆ†å‰²é˜ˆå€¼ $ p $ï¼Œä¾‹å¦‚æœ€å¤§åŒ– $ \text{Corr}(\hat{A}, A^*) $ã€‚
- å°† SAE åº”ç”¨äºå…¶ä»–éœ€è¦é•¿ç¨‹ä¿¡ç”¨åˆ†é…çš„ä»»åŠ¡ï¼ˆå¦‚è§„åˆ’ã€å¯¹è¯ã€ä»£ç è°ƒè¯•ï¼‰ã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **SAE é€šè¿‡å°†ä¼˜åŠ¿ä¼°è®¡ä»â€œé€ tokenâ€å‡çº§ä¸ºâ€œæŒ‰è¯­ä¹‰æ®µâ€ï¼Œæœ‰æ•ˆæŠ‘åˆ¶äº† GAE åœ¨ RLVR ä¸­çš„åå·®ç´¯ç§¯ï¼Œä¸º PPO åœ¨é•¿ä¸Šä¸‹æ–‡ LLM è®­ç»ƒä¸­æä¾›äº†æ›´å¯é ã€æ›´é«˜æ•ˆçš„ä¼˜åŒ–è·¯å¾„ã€‚**

</details>

---

### 9. [Efficient and Reliable Estimation of Named Entity Linking Quality: A Case Study on GutBrainIE](https://arxiv.org/abs/2601.06624)

**Authors**: Marco Martinelli, Stefano Marchesin, Gianmaria Silvello  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.06624v1  

#### Abstract
Named Entity Linking (NEL) is a core component of biomedical Information Extraction (IE) pipelines, yet assessing its quality at scale is challenging due to the high cost of expert annotations and the large size of corpora. In this paper, we present a sampling-based framework to estimate the NEL acc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEfficient and Reliable Estimation of Named Entity Linking Quality: A Case Study on GutBrainIE

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
- **å¤§è§„æ¨¡ NEL è´¨é‡è¯„ä¼°çš„æŒ‘æˆ˜**ï¼šNamed Entity Linking (NEL) æ˜¯ç”Ÿç‰©åŒ»å­¦ä¿¡æ¯æŠ½å–ï¼ˆIEï¼‰ä¸­çš„å…³é”®ç¯èŠ‚ï¼Œä½†å…¶è´¨é‡è¯„ä¼°é¢ä¸´ä¸¤å¤§éš¾é¢˜ï¼š
  - ä¸“å®¶æ ‡æ³¨æˆæœ¬é«˜æ˜‚ï¼›
  - ç”Ÿç‰©åŒ»å­¦è¯­æ–™è§„æ¨¡åºå¤§ï¼Œå…¨é¢äººå·¥å®¡æ ¸ä¸å¯è¡Œã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
- **å°† NEL å‡†ç¡®ç‡ä¼°è®¡å»ºæ¨¡ä¸ºå¸¦çº¦æŸçš„ä¼˜åŒ–é—®é¢˜**ï¼š
  - ç›®æ ‡æ˜¯åœ¨æ»¡è¶³ç›®æ ‡ **Margin of Error (MoE)** çš„å‰æä¸‹ï¼Œæœ€å°åŒ–äººå·¥æ ‡æ³¨æˆæœ¬ã€‚
- **å¼•å…¥å¹¶é€‚é… Stratified Two-stage Weighted Cluster Sampling (STWCS) åˆ° NEL åœºæ™¯**ï¼š
  - ç»“åˆåˆ†å±‚æŠ½æ ·ï¼ˆStratificationï¼‰ä¸ä¸¤é˜¶æ®µåŠ æƒèšç±»æŠ½æ ·ï¼ˆTWCSï¼‰ï¼Œæå‡é‡‡æ ·æ•ˆç‡ã€‚
  - åˆ†å±‚ä¾æ®ï¼šåŸºäºå®ä½“æ ‡ç­¾ï¼ˆentity labelï¼‰å®šä¹‰5ä¸ªè¯­ä¹‰è¿è´¯ä¸”å¤§å°å‡è¡¡çš„ **strata**ã€‚
  - èšç±»ä¾æ®ï¼šåŸºäºå½’ä¸€åŒ–çš„ mention è¡¨é¢å½¢å¼ï¼ˆsurface formï¼‰æ„å»º clusterï¼Œå‡å°‘ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **ç›¸æ¯” Simple Random Sampling (SRS)**ï¼š
  - æ˜¾è‘—é™ä½ä¸Šä¸‹æ–‡åˆ‡æ¢é¢‘ç‡ï¼Œä»è€Œå‡å°‘è®¤çŸ¥è´Ÿæ‹…å’Œæ ‡æ³¨æ—¶é—´ã€‚
  - åœ¨ç›¸åŒæ ·æœ¬é‡ä¸‹ï¼Œå®ç°çº¦ **29% çš„æ ‡æ³¨æ—¶é—´èŠ‚çœ**ã€‚
- **é¿å…å¾ªç¯ä¾èµ–**ï¼š
  - æ‰€æœ‰åˆ†å±‚ä¸èšç±»ç­–ç•¥å‡åŸºäº NEL è¾“å‡ºä¹‹å¤–çš„ä¿¡æ¯ï¼ˆå¦‚ entity label å’Œ mention æ–‡æœ¬ï¼‰ï¼Œä¸ä¾èµ– NEL è‡ªèº«ç»“æœï¼Œç¡®ä¿è¯„ä¼°æ— åã€‚
- **å¯æ‰©å±•æ€§å¼º**ï¼š
  - æ¡†æ¶é€šç”¨ï¼Œé€‚ç”¨äºå…¶ä»– NEL benchmark æˆ– IE pipeline çš„è´¨é‡è¯„ä¼°ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **GUTBRAINIE**ï¼š
  - ä¸€ä¸ªèšç„¦äº **gut-brain axis** é¢†åŸŸçš„å¤§è§„æ¨¡ç”Ÿç‰©åŒ»å­¦è¯­æ–™åº“ã€‚
  - åŒ…å«æ¥è‡ª PubMed çš„ 1,647 ç¯‡æ‘˜è¦ã€‚
  - æ¶‰åŠ 13 ç§å®ä½“ç±»å‹ï¼ˆå¦‚ bacteria, drug, microbiome ç­‰ï¼‰å’Œ 17 ç§å…³ç³»è°“è¯ã€‚
  - å®ä½“é“¾æ¥è‡³ 6 ä¸ªæ ‡å‡†ç”Ÿç‰©åŒ»å­¦è¯æ±‡è¡¨ï¼ˆå¦‚ UMLS, CHEBI, NCITï¼‰åŠè‡ªå®šä¹‰æœ¬ä½“ GBIEã€‚
  - æœ¬æ–‡ä»…ä½¿ç”¨ä¸“å®¶æ ‡æ³¨çš„ Platinum ä¸ Gold æŠ˜å ï¼Œå…±åŒ…å« **11,184 æ¡ NEL triples**ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **è¯„ä¼°ç›®æ ‡**ï¼šä¼°ç®—æ•´ä¸ªè¯­æ–™åº“çº§åˆ«çš„ NEL å‡†ç¡®ç‡ $ \mu(T) $ï¼Œå³æ­£ç¡®é“¾æ¥ triple çš„æ¯”ä¾‹ã€‚
- **æŠ½æ ·è®¾è®¡**ï¼š
  - é‡‡ç”¨ **STWCS** è¿›è¡Œè¿­ä»£æŠ½æ ·ï¼Œç›´åˆ°è¾¾åˆ°é¢„è®¾ MoE â‰¤ 0.05ã€‚
  - ç¬¬ä¸€é˜¶æ®µï¼šæŒ‰è§„æ¨¡æ¦‚ç‡æœ‰æ”¾å›åœ°é€‰æ‹© stratumï¼ˆPPS-WRï¼‰ã€‚
  - ç¬¬äºŒé˜¶æ®µï¼šåœ¨é€‰å®š stratum å†…æŒ‰ cluster å¤§å°æ— æ”¾å›æŠ½æ ·ï¼ˆPPS-WORï¼‰ã€‚
  - ç¬¬ä¸‰é˜¶æ®µï¼šæ¯ä¸ª cluster æœ€å¤šæ ‡æ³¨ m=5 ä¸ª triplesã€‚
- **ç»ˆæ­¢æ¡ä»¶**ï¼šå½“ä¼°è®¡çš„ MoE â‰¤ 0.05 æ—¶åœæ­¢æŠ½æ ·ã€‚
- **æˆæœ¬æ¨¡å‹**ï¼š
  - å¼•å…¥ **context switch** æ¦‚å¿µï¼šè¿ç»­ä¸¤ä¸ªè¢«æ ‡æ³¨ triple å±äºä¸åŒ surface-form cluster è§†ä¸ºä¸€æ¬¡åˆ‡æ¢ã€‚
  - æ—¶é—´æˆæœ¬æ¨¡å‹ï¼š`time(Ts) = n * t_base + n_sw * Î”t_switch`

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Simple Random Sampling (SRS)**ï¼š
  - ä½œä¸ºåŸºå‡†ï¼Œæ¨¡æ‹Ÿå¯¹åŒä¸€ç»„ 2,749 ä¸ª triples ä½¿ç”¨ SRS æŠ½æ ·çš„æ ‡æ³¨æ—¶é—´å’Œä¸Šä¸‹æ–‡åˆ‡æ¢æ¬¡æ•°ã€‚
  - é€šè¿‡ 1,000 æ¬¡éšæœºæ’åˆ—ä»¿çœŸï¼Œå¹¶è¿›è¡Œ bootstrap åˆ†æä»¥è·å¾—ç¨³å¥ä¼°è®¡ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **æ€»ä½“å‡†ç¡®ç‡ä¼°è®¡**ï¼š
  - åœ¨æ‰‹åŠ¨æ ‡æ³¨ **2,749 ä¸ª triplesï¼ˆå æ€»æ•° 24.6%ï¼‰** åæ”¶æ•›ã€‚
  - å¾—åˆ°çš„ NEL å‡†ç¡®ç‡ä¸ºï¼š  
    $$
    \hat{\mu}_{STWCS} = 0.915 \pm 0.0473 \quad (\text{MoE} = 0.047 < 0.05)
    $$
  - å¯¹åº” 95% ç½®ä¿¡åŒºé—´ï¼š**[0.868, 0.963]**ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ ‡æ³¨æ—¶é—´å¯¹æ¯”**ï¼š
  - STWCS å®é™…è€—æ—¶ï¼š**797 åˆ†é’Ÿï¼ˆ13h17mï¼‰**
  - SRS ä»¿çœŸå¹³å‡è€—æ—¶ï¼š**1,124.57 åˆ†é’Ÿï¼ˆ18h44mï¼‰**
  - **èŠ‚çœæ—¶é—´ï¼šçº¦ 327.6 åˆ†é’Ÿï¼ˆ5h28mï¼‰**
  - **æ•ˆç‡æå‡ï¼šçº¦ 29% æ›´å¿«**ï¼ˆæ•ˆç‡æ¯” ~0.71ï¼‰
- **ä¸Šä¸‹æ–‡åˆ‡æ¢å¯¹æ¯”**ï¼š
  - STWCS ä¸­å‘ç”Ÿ **1,050 æ¬¡ context switch**
  - SRS ä»¿çœŸä¸­å¹³å‡å‘ç”Ÿ **2,745 æ¬¡ context switch**
  - STWCS å°† context switch æ•°é‡å‡å°‘äº†è¿‘ **62%**

### æ¶ˆèå®éªŒ / åˆ†å±‚åˆ†æç»“æœ
- **å„ stratum çš„å‡†ç¡®ç‡ä¼°è®¡**ï¼ˆè§ Table 3ï¼‰ï¼š
  | Stratum | å‡†ç¡®ç‡ä¼°è®¡ | MoE |
  |---|---|---|
  | DDF | 0.883 | 0.093 |
  | Microbiome + Bacteria | 0.979 | 0.108 |
  | Human + Animal + Anatomical Location | 0.976 | 0.060 |
  | Chemical + Gene | 0.851 | 0.087 |
  | Drug + ... + Statistical Technique | 0.898 | 0.154 |

- å‘ç°ï¼š
  - **Microbiome + Bacteria** å’Œ **Human + Animal + Anatomical Location** ç±»åˆ«çš„ NEL å‡†ç¡®ç‡æœ€é«˜ï¼ˆ>0.97ï¼‰ï¼Œè¡¨æ˜ç³»ç»Ÿåœ¨è¿™äº›ç±»åˆ«ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚
  - **Drug + Dietary Supplement + Food + Biomedical/Statistical Technique** ç±»åˆ«çš„ MoE æœ€å¤§ï¼Œè¯´æ˜éœ€è¦æ›´å¤šé‡‡æ ·æ‰èƒ½ç²¾ç¡®ä¼°è®¡å…¶è´¨é‡ã€‚
  - æ‰€æœ‰ strata çš„ä¿å®ˆä¸‹ç•Œï¼ˆp - MoEï¼‰å‡ â‰¥ 0.74ï¼Œè¡¨æ˜æ•´ä½“ NEL è´¨é‡å¯é ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
- **STWCS å¯é«˜æ•ˆã€å¯é åœ°ä¼°è®¡å¤§è§„æ¨¡ NEL ç³»ç»Ÿçš„è´¨é‡**ï¼š
  - ä»…éœ€æ ‡æ³¨ä¸åˆ° 25% çš„æ•°æ®å³å¯è·å¾—å…·æœ‰ç»Ÿè®¡ä¿è¯çš„å‡†ç¡®ç‡ä¼°è®¡ï¼ˆMoE â‰¤ 0.05ï¼‰ã€‚
- **ç»“æ„åŒ–æŠ½æ ·æ˜¾è‘—æå‡æ ‡æ³¨æ•ˆç‡**ï¼š
  - é€šè¿‡å‡å°‘ context switchï¼ŒSTWCS ç›¸æ¯” SRS èŠ‚çœçº¦ 29% çš„ä¸“å®¶æ—¶é—´ã€‚
- **æ¡†æ¶å…·å¤‡å¯è§£é‡Šæ€§å’ŒæŒ‡å¯¼æ„ä¹‰**ï¼š
  - åˆ†å±‚ä¼°è®¡æ­ç¤ºäº†ä¸åŒå®ä½“ç±»åˆ«çš„ NEL è¡¨ç°å·®å¼‚ï¼Œå¯ç”¨äºæŒ‡å¯¼åç»­é’ˆå¯¹æ€§ä¿®æ­£æˆ–èµ„æºåˆ†é…ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡çš„ entity labeling**ï¼š
  - å½“å‰æ¡†æ¶å‡è®¾ entity mention detection å’Œ typing å·²å®Œæˆä¸”å‡†ç¡®ï¼›è‹¥å­˜åœ¨è¯¯æ ‡ï¼Œå¯èƒ½å½±å“ stratum åˆ’åˆ†ã€‚
- **cluster å®šä¹‰è¾ƒç®€å•**ï¼š
  - å½“å‰ cluster åŸºäºè¡¨é¢å½¢å¼å½’ä¸€åŒ–ï¼ˆlowercase + whitespace removalï¼‰ï¼Œæœªè€ƒè™‘è¯­ä¹‰ç›¸ä¼¼æ€§æˆ–æ‹¼å†™å˜ä½“ã€‚
- **å›ºå®š m=5 çš„é™åˆ¶**ï¼š
  - è™½ç„¶æ–‡çŒ®æ”¯æŒ m=5 ä¸ºè¿‘ä¼¼æœ€ä¼˜ï¼Œä½†åœ¨æŸäº›é«˜æ–¹å·® cluster ä¸­å¯èƒ½ä¸è¶³ä»¥å……åˆ†ä¼°è®¡å±€éƒ¨å‡†ç¡®ç‡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **å¼•å…¥å¤šæ ‡æ³¨è€…æœºåˆ¶**ï¼š
  - é‡‡ç”¨å¤šæ•°æŠ•ç¥¨ï¼ˆmajority votingï¼‰ç­‰æ–¹å¼èšåˆå¤šä¸ªä¸“å®¶åˆ¤æ–­ï¼Œæé«˜æ ‡æ³¨å¯é æ€§ã€‚
- **åŸºäºä¸‹æ¸¸ä»»åŠ¡å½±å“çš„ stratification è®¾è®¡**ï¼š
  - ä¼˜å…ˆæŠ½æ ·é‚£äº›å‚ä¸å¤§é‡ relation instances æˆ–åœ¨ induced KG ä¸­å…·æœ‰é«˜ä¸­å¿ƒæ€§çš„ conceptsã€‚
- **åŠ¨æ€è°ƒæ•´æŠ½æ ·ç­–ç•¥**ï¼š
  - æ ¹æ®å·²è§‚æµ‹åˆ°çš„è¯¯å·®åˆ†å¸ƒï¼ŒåŠ¨æ€è°ƒæ•´ stratum æˆ– cluster çš„æŠ½æ ·æƒé‡ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–æ”¶æ•›é€Ÿåº¦ã€‚
- **æ‰©å±•è‡³ç«¯åˆ°ç«¯ IE pipeline è¯„ä¼°**ï¼š
  - å°†è¯¥æ¡†æ¶åº”ç”¨äº Relation Extraction æˆ– Event Extraction ç­‰æ›´å¤æ‚ä»»åŠ¡çš„è´¨é‡ä¼°è®¡ã€‚

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº **STWCS** çš„é‡‡æ ·æ¡†æ¶ï¼Œåœ¨ **GUTBRAINIE** ä¸Šå®ç°äº†é«˜æ•ˆå¯é çš„ NEL è´¨é‡ä¼°è®¡â€”â€”**ç”¨ 24.6% çš„æ ‡æ³¨é‡è¾¾æˆ MoE â‰¤ 0.05ï¼Œå¹¶æ¯” SRS èŠ‚çœ 29% çš„ä¸“å®¶æ—¶é—´**ï¼Œä¸ºå¤§è§„æ¨¡ç”Ÿç‰©åŒ»å­¦ IE ç³»ç»Ÿçš„è¯„ä¼°æä¾›äº†å®ç”¨ä¸”å¯æ¨å¹¿çš„è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 10. [SourceNet: Interpretable Sim-to-Real Inference on Variable-Geometry Sensor Arrays for Earthquake Source Inversion](https://arxiv.org/abs/2601.06320)

**Authors**: Zhe Jia, Xiaotian Zhang, Junpeng Li  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.06320v1  

#### Abstract
Inferring high-dimensional physical states from sparse, ad-hoc sensor arrays is a fundamental challenge across AI for Science, as they are complicated by irregular geometries and the profound Sim-to-Real gap in physical modeling. Taking earthquake source characterization as a representative challeng...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šSourceNet: Interpretable Sim-to-Real Inference on Variable-Geometry Sensor Arrays for Earthquake Source Inversion**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
è¯¥è®ºæ–‡é’ˆå¯¹**åœ°éœ‡éœ‡æºæœºåˆ¶åæ¼”**ä¸­çš„ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š
- **å‡ ä½•ä¸è§„åˆ™æ€§**ï¼šçœŸå®ä¸–ç•Œä¸­çš„ä¼ æ„Ÿå™¨ç½‘ç»œæ˜¯ç¨€ç–ã€æ•°é‡å¯å˜ä¸”ç©ºé—´åˆ†å¸ƒä¸è§„åˆ™çš„ï¼Œä¼ ç»ŸåŸºäºå›ºå®šç½‘æ ¼çš„æ¨¡å‹ï¼ˆå¦‚CNNï¼‰éš¾ä»¥å¤„ç†ã€‚
- **Sim-to-Real Gap**ï¼šç‰©ç†ä»¿çœŸæ•°æ®ä¸çœŸå®è§‚æµ‹ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼ˆå¦‚æœªå»ºæ¨¡çš„ä»‹è´¨å¼‚è´¨æ€§ã€å™ªå£°ã€æ•£å°„ç­‰ï¼‰ï¼Œå¯¼è‡´åœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹éš¾ä»¥æ³›åŒ–åˆ°çœŸå®åœºæ™¯ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**
ä½œè€…æå‡ºäº† **SourceNet**ï¼Œä¸€ä¸ªåŸºäºTransformerçš„ç«¯åˆ°ç«¯å¯è§£é‡Šæ¡†æ¶ï¼Œå…·å¤‡ä»¥ä¸‹ä¸‰å¤§åˆ›æ–°ï¼š

#### **(1) Physics-Structured Domain Randomization (PSDR)**
- ä¸åŒäºä¼ ç»Ÿçš„ç‰¹å¾å¯¹é½æˆ–å¯¹æŠ—æ€§åŸŸé€‚åº”æ–¹æ³•ï¼ŒPSDRé€šè¿‡**éšæœºåŒ–ç‰©ç†è¿‡ç¨‹æœ¬èº«**æ¥æ¡¥æ¥ä»¿çœŸä¸ç°å®ä¹‹é—´çš„é¸¿æ²Ÿã€‚
- å…·ä½“åŒ…æ‹¬ï¼š
  - **åœ°çƒç»“æ„éšæœºåŒ–**ï¼šä»CRUST1.0ä¸­é‡‡æ ·17ç§ä¸åŒçš„1Dé€Ÿåº¦æ¨¡å‹ï¼Œé˜²æ­¢æ¨¡å‹è®°å¿†ç‰¹å®šä¼ æ’­è·¯å¾„ã€‚
  - **çœŸå®å™ªå£°æ³¨å…¥**ï¼šä½¿ç”¨å®é™…ç¯å¢ƒå™ªå£°è®°å½•å åŠ åˆ°åˆæˆæ³¢å½¢ä¸Šã€‚
  - **ä¿¡å·å¤±çœŸå»ºæ¨¡**ï¼šå¼•å…¥æ—¶é—´åç§»ã€æŒ¯å¹…æ‰°åŠ¨å’Œæ¨¡æ‹Ÿæ•£å°„å°¾æ³¢ï¼ˆscattering codaï¼‰ã€‚
  - **ä¼ æ„Ÿå™¨å¯ç”¨æ€§éšæœºä¸¢å¼ƒï¼ˆMï¼‰**ï¼šæ¨¡æ‹Ÿç°å®ä¸­ä¼ æ„Ÿå™¨æ•…éšœæˆ–ç¼ºå¤±çš„æƒ…å†µã€‚

> âœ… **ä¼˜åŠ¿**ï¼šè¿«ä½¿æ¨¡å‹å­¦ä¹ å¯¹æœªå»ºæ¨¡å¼‚è´¨æ€§å…·æœ‰ä¸å˜æ€§çš„è¡¨ç¤ºï¼Œæå‡ç°å®è¿ç§»èƒ½åŠ›ã€‚

#### **(2) Set Transformer æ¶æ„è®¾è®¡**
- å°†ä¼ æ„Ÿå™¨é˜µåˆ—è§†ä¸º**æ— åºé›†åˆï¼ˆsetï¼‰**ï¼Œé‡‡ç”¨Set Transformerå®ç°æ’åˆ—ä¸å˜æ€§ã€‚
- å¼•å…¥**å¤šæ¨¡æ€ç¼–ç å™¨**ï¼š
  - **P-Wave Tower** å’Œ **S-Wave Tower**ï¼šåˆ†åˆ«æå–Pæ³¢å’ŒSæ³¢çš„æ—¶é—´åŸŸä¸é¢‘è°±ç‰¹å¾ã€‚
  - **Scalar Tower**ï¼šæ˜¾å¼ç¼–ç å°ç«™æ–¹ä½è§’ã€è·ç¦»ã€åæ ‡ã€æŒ¯å¹…æ¯”ç­‰ç‰©ç†å…ƒæ•°æ®ï¼Œç”¨äºè§£è€¦è¾å°„æ¨¡å¼ä¸è¡°å‡æ•ˆåº”ã€‚
- åˆ©ç”¨**Self-Attentionæœºåˆ¶**å»ºæ¨¡å°ç«™é—´çš„æˆå¯¹å…³ç³»ï¼Œæ•æ‰æ³¢åœºä¸­çš„ç›¸å¯¹ç›¸ä½ä¸æŒ¯å¹…ä¿¡æ¯ã€‚
- ä½¿ç”¨**Attention Pooling**åŠ¨æ€åŠ æƒä¸åŒå°ç«™çš„é‡è¦æ€§ï¼Œå®ç°äº‹ä»¶è‡ªé€‚åº”çš„ä¿¡æ¯èšåˆã€‚

> âœ… **ä¼˜åŠ¿**ï¼šç›¸æ¯”DeepSets/GNN/CNNï¼Œèƒ½æ›´æœ‰æ•ˆåœ°åˆ©ç”¨ç¨€ç–ã€ä¸è§„åˆ™ä¼ æ„Ÿå™¨ç½‘ç»œä¸­çš„å…¨æ³¢å½¢ä¿¡æ¯ã€‚

#### **(3) å¯è§£é‡Šæ€§é©±åŠ¨çš„ç§‘å­¦æ™ºèƒ½è¡Œä¸ºå‘ç°**
- é€šè¿‡XAIåˆ†æï¼ˆGrad-CAM + æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–ï¼‰ï¼Œå‘ç°æ¨¡å‹å±•ç°å‡ºç±»ä¼¼â€œç§‘å­¦ä»£ç†â€çš„è¡Œä¸ºï¼š
  - è‡ªä¸»å…³æ³¨Pæ³¢åçš„**codaç›¸ä½å’Œæ—©æœŸæ•£å°„æ³¢**ï¼Œç›¸å½“äºéšå¼æ‰§è¡Œ**full-waveform inversion**ã€‚
  - æ³¨æ„åŠ›ç­–ç•¥è¡¨ç°å‡ºç³»ç»Ÿæ€§å„å‘å¼‚æ€§ï¼šä¼˜å…ˆé€‰æ‹©ä¸œè¥¿å‘ï¼ˆE-Wï¼‰å°ç«™ï¼Œè€ŒæŠ‘åˆ¶å—åŒ—å¯†é›†ä½†å†—ä½™çš„è§‚æµ‹ã€‚
  - è¿™ä¸€ç­–ç•¥æœ¬è´¨ä¸Šæ¢å¤äº†**æœ€ä¼˜å®éªŒè®¾è®¡ï¼ˆOptimal Experimental Design, OEDï¼‰** åŸåˆ™ï¼Œå³æœ€å¤§åŒ–Fisherä¿¡æ¯çŸ©é˜µè¡Œåˆ—å¼ï¼ˆD-Optimalityï¼‰ã€‚

> âœ… **ä¼˜åŠ¿**ï¼šä¸ä»…é¢„æµ‹å‡†ç¡®ï¼Œè¿˜èƒ½ä»æ•°æ®ä¸­è‡ªä¸»å‘ç°ç‰©ç†è§‚æµ‹çš„æœ€ä½³ç­–ç•¥ï¼Œå¢å¼ºç§‘å­¦å¯ä¿¡åº¦ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **æ•°æ®é›†**
| æ•°æ®é›† | æè¿° |
|--------|------|
| **Synthetic Pre-training Dataset** | ç”Ÿæˆäº†100,000ä¸ªåˆæˆåœ°éœ‡äº‹ä»¶ï¼š<br>- éœ‡æºæœºåˆ¶å‡åŒ€é‡‡æ ·äºæ‰€æœ‰å¯èƒ½çš„double-coupleæºç©ºé—´ï¼›<br>- ä½¿ç”¨Southern Californiaçš„çœŸå®å°ç½‘å¸ƒå±€ä¸éœ‡ä¸­ä½ç½®ï¼›<br>- åº”ç”¨PSDRå¢å¼ºï¼ˆé€Ÿåº¦æ¨¡å‹å˜åŒ–ã€å™ªå£°æ³¨å…¥ã€å°ç«™ä¸¢å¼ƒç­‰ï¼‰ã€‚ |
| **Real-world Fine-tuning Dataset** | 2,544ä¸ªM > 3.0çš„çœŸå®åœ°éœ‡äº‹ä»¶ï¼Œæ¥è‡ªYang et al. (2012)æä¾›çš„Southern Californiaç›®å½•ã€‚<br>- è¦æ±‚è‡³å°‘5ä¸ªå°ç«™è¦†ç›–ï¼Œè´¨é‡ä¸ºA/Bçº§ã€‚ |

### **å®éªŒè®¾ç½®**
- **ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹**ï¼š
  1. **é¢„è®­ç»ƒ**ï¼šåœ¨10ä¸‡åˆæˆæ•°æ®ä¸Šè®­ç»ƒ150è½®ï¼ˆAdamW, lr=2e-4ï¼‰ã€‚
  2. **å¾®è°ƒ**ï¼šåœ¨çœŸå®æ•°æ®ä¸Šè¿›è¡Œå°‘æ ·æœ¬å¾®è°ƒï¼ˆlr=2e-6ï¼‰ï¼Œä½¿ç”¨**åŠ æƒéšæœºé‡‡æ ·å™¨**å¹³è¡¡æ–­å±‚æœºåˆ¶ç±»åˆ«ï¼ˆé¿å…strike-slipä¸»å¯¼ï¼‰ã€‚
- **è¾“å…¥å½¢å¼**ï¼šæ¯ä¸ªå°ç«™ä¸ºä¸€ä¸ªå…ƒç»„ $(w_i, s_i)$ï¼Œå…¶ä¸­ï¼š
  - $w_i \in \mathbb{R}^{C\times T}$ï¼šæ—¶é¢‘åŸŸæ³¢å½¢ï¼›
  - $s_i$ï¼šæ ‡é‡å…ƒæ•°æ®ï¼ˆæ–¹ä½è§’ã€è·ç¦»ã€æŒ¯å¹…æ¯”ç­‰ï¼‰ã€‚

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Moment Tensor Components MAE** | å½’ä¸€åŒ–çŸ©å¼ é‡åˆ†é‡ï¼ˆMxx, Mxy, ..., Mzzï¼‰çš„å¹³å‡ç»å¯¹è¯¯å·® |
| **Magnitude MAE** | é¢„æµ‹çŸ©éœ‡çº§ $M_w$ çš„MAE |
| **Kagan Angle Error** | é¢„æµ‹ä¸çœŸå®éœ‡æºæœºåˆ¶ä¹‹é—´çš„è§’åº¦åå·®ï¼ˆè¶Šå°è¶Šå¥½ï¼‰ï¼Œæ˜¯è¡¡é‡éœ‡æºæœºåˆ¶ä¸€è‡´æ€§çš„æ ‡å‡†æŒ‡æ ‡ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **ç»å…¸ç›®å½•**ï¼šSouthern Californiaå®˜æ–¹æ‰‹åŠ¨è§£ï¼ˆYang et al., 2012ï¼‰
- **æ·±åº¦å­¦ä¹ åŸºçº¿**ï¼š
  - FM-Netï¼ˆCNN-basedï¼‰
  - GNN-based æ–¹æ³•ï¼ˆZhang et al., 2022ï¼‰
  - TEAMï¼ˆTransformer-based, æœ‰ç¦»æ•£ä½ç½®ç¼–ç ï¼‰
- **Pooling-based Baseline**ï¼šDeepSetsé£æ ¼çš„å…¨å±€æ± åŒ–æ¶æ„

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
| æ¨¡å‹ | Kagan Angle (Mean/Median) | Magnitude MAE | Tensor MAE |
|------|----------------------------|----------------|-------------|
| **SourceNet (Full)** | **26.18Â° / 19.37Â°** | **0.11** | ~0.16â€“0.19 |
| æ‰‹åŠ¨ç›®å½•ï¼ˆQuality Bï¼‰ | ~35Â°ä¸ç¡®å®šæ€§ä¸Šé™ | â€” | â€” |
| FOCONET (Song et al., 2025) | ~20Â°â€“30Â°ï¼ˆéœ€é«˜è´¨é‡/å¯†é›†å°ç½‘ï¼‰ | â€” | â€” |
| DiTing (Zhao et al., 2023) | ~20Â°â€“30Â°ï¼ˆQuality Aå­é›†ï¼‰ | â€” | â€” |

> ğŸ”¹ **ç»“è®º**ï¼šSourceNetåœ¨**ç¨€ç–ã€ä¸è§„åˆ™çš„çœŸå®æ“ä½œæ•°æ®**ä¸Šè¾¾åˆ°SOTAç²¾åº¦ï¼Œå…¶è¯¯å·®å·²æ¥è¿‘äººå·¥æ ‡æ³¨çš„ä¸ç¡®å®šæ€§ä¸‹é™ï¼ˆlabel noise floorï¼‰ï¼Œè¡¨æ˜å…¶å¯é æ€§åª²ç¾äººç±»ä¸“å®¶ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- åœ¨ç›¸åŒæµ‹è¯•é›†ä¸Šï¼ŒSourceNetæ˜¾è‘—ä¼˜äºå…ˆå‰DLæ–¹æ³•ï¼ˆå¦‚Ross et al., 2018; Cheng et al., 2023ï¼‰ï¼Œåè€…Kaganè§’åå·®æ™®éè¶…è¿‡30Â°ã€‚
- å³ä½¿ä¸æœ€æ–°Transformeræ¨¡å‹ï¼ˆå¦‚FOCONETã€DiTingï¼‰ç›¸æ¯”ï¼ŒSourceNetåœ¨**éç†æƒ³æ¡ä»¶ä¸‹ä»ä¿æŒç«äº‰åŠ›**ï¼Œä¸”æ— éœ€ä¾èµ–å¯†é›†å°ç½‘æˆ–é«˜è´¨é‡ç­›é€‰æ•°æ®ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**
| æ¨¡å‹å˜ä½“ | Magnitude MAE | Tensor MAE | Kagan Angle (Mean) |
|---------|----------------|------------|--------------------|
| **Full SourceNet** | **0.07** | **0.06** | **10.2Â°** |
| w/o Scalar Tower | 0.18 (+157%) | 0.09 | 12.5Â° |
| w/o Self-Attention (Pooling) | 0.10 | 0.17 (+183%) | 28.4Â° (+178%) |

> ğŸ”¹ **ç»“è®º**ï¼š
- **Scalar Towerè‡³å…³é‡è¦**ï¼šç¼ºå°‘å‡ ä½•å…ƒæ•°æ®ä¼šå¯¼è‡´éœ‡çº§ä¼°è®¡ä¸¥é‡é€€åŒ–ï¼Œè¯´æ˜ä»…é æ³¢å½¢æ— æ³•è§£è€¦èƒ½é‡ä¸è·¯å¾„è¡°å‡ã€‚
- **Self-Attentionä¸å¯æ›¿ä»£**ï¼šæ›¿æ¢ä¸ºå…¨å±€æ± åŒ–åæœºåˆ¶ä¼°è®¡å¤§å¹…ä¸‹é™ï¼ŒéªŒè¯äº†æ³¢åŠ¨ç‰©ç†çš„**å…³ç³»æœ¬è´¨**â€”â€”å¿…é¡»æ¯”è¾ƒå°ç«™é—´ç›¸å¯¹å“åº”ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **Architecture Should Follow Physics**  
   å¯¹äºæ³¢åŠ¨ç‰©ç†åæ¼”ä»»åŠ¡ï¼Œ**Set Transformer + Self-Attention** æ˜¾è‘—ä¼˜äºCNNã€GNNå’ŒDeepSetsï¼Œå› å…¶èƒ½å¤Ÿå»ºæ¨¡å°ç«™é—´çš„æˆå¯¹ä¾èµ–å…³ç³»ï¼Œæœ‰æ•ˆèåˆå…¨æ³¢å½¢ä¿¡æ¯ï¼ˆåŒ…æ‹¬ä¼ ç»Ÿä¸Šè¢«å¿½ç•¥çš„codaç›¸ä½ï¼‰ã€‚

2. **PSDR æ˜¯ Sim-to-Real æˆåŠŸçš„å…³é”®**  
   t-SNEå¯è§†åŒ–æ˜¾ç¤ºï¼Œæœªç»PSDRè®­ç»ƒçš„æ¨¡å‹åœ¨çœŸå®æ•°æ®ä¸Šå‡ºç°æµå½¢é”™ä½ï¼ˆmanifold misalignmentï¼‰ï¼Œè€ŒPSDRä½¿æ¨¡å‹å­¦ä¹ åˆ°è·¨åŸŸä¸å˜çš„ç‰©ç†ç®—å­ï¼Œå®ç°å®Œç¾æµå½¢å¯¹é½ã€‚

3. **Interpretability Leads to Discovery**  
   SourceNetå±•ç°å‡ºç±»ç§‘å­¦ä»£ç†çš„è¡Œä¸ºï¼š
   - è‡ªä¸»è¯†åˆ«ä¼ æ„Ÿå™¨ç½‘ç»œçš„**å‡ ä½•ä¿¡æ¯ç“¶é¢ˆ**ï¼ˆN-Så¯†é›†ã€E-Wç¨€ç–ï¼‰ï¼›
   - å­¦ä¹ æ³¨æ„åŠ›ç­–ç•¥ä»¥ä¼˜å…ˆé€‰æ‹©æ­£äº¤æ–¹å‘çš„è§‚æµ‹ï¼Œ**éšå¼å®ç°äº†D-Optimalå®éªŒè®¾è®¡åŸåˆ™**ï¼›
   - è¡¨æ˜AIä¸ä»…èƒ½æ‹Ÿåˆå‡½æ•°ï¼Œè¿˜èƒ½ä»æ•°æ®ä¸­å½’çº³å‡ºä¼˜åŒ–è§‚æµ‹çš„ç‰©ç†ç­–ç•¥ã€‚

4. **Amortized Inference å®ç°å®æ—¶å¤„ç†**  
   ç›¸æ¯”ä¼ ç»Ÿè¿­ä»£åæ¼”ï¼ˆO(K)å¤æ‚åº¦ï¼‰ï¼ŒSourceNeté€šè¿‡è®­ç»ƒä¸€æ¬¡æ€§å­¦ä¹ é€†ç®—å­ï¼Œæ¨ç†æ—¶é—´ä¸ºå¸¸æ•°ï¼ˆO(1)ï¼‰ï¼Œé€‚ç”¨äºå®æ—¶åœ°éœ‡é¢„è­¦ç³»ç»Ÿã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- å½“å‰æ¡†æ¶å‡è®¾ä»¿çœŸæ”¯æŒç©ºé—´è¦†ç›–çœŸå®ç‰©ç†èŒƒå›´ï¼Œå¯¹äº**out-of-distributionäº‹ä»¶**ï¼ˆå¦‚å¤šæ–­å±‚ç ´è£‚ã€æ…¢æ»‘ç§»äº‹ä»¶ï¼‰å°šæœªå»ºæ¨¡ã€‚
- ä¾èµ–äºGreenå‡½æ•°ä»¿çœŸç”Ÿæˆåˆæˆæ•°æ®ï¼Œè‹¥åº•å±‚ç‰©ç†æ¨¡å‹ä¸¥é‡åç¦»ç°å®ï¼Œä»å¯èƒ½å­˜åœ¨æ ¹æœ¬æ€§åå·®ã€‚
- å½“å‰è¾“å‡ºä¸ºé™æ€éœ‡æºå‚æ•°ï¼Œæœªå»ºæ¨¡æ–­å±‚æ»‘ç§»çš„æ—¶ç©ºæ¼”åŒ–è¿‡ç¨‹ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•è‡³**åŠ¨æ€éœ‡æºæˆåƒ**ï¼šç»“åˆNeural Surrogate Modelsï¼Œç›´æ¥ä»è§‚æµ‹æ•°æ®çº¦æŸæ–­å±‚æ»‘ç§»çš„æ—¶é—´-ç©ºé—´æ¼”åŒ–ã€‚
- æ¢ç´¢**æ— ç›‘ç£æˆ–å¼±ç›‘ç£å­¦ä¹ èŒƒå¼**ï¼Œå‡å°‘å¯¹ç²¾ç¡®éœ‡æºæ ‡ç­¾çš„ä¾èµ–ã€‚
- æ¨å¹¿è‡³å…¶ä»–ç‰©ç†ç³»ç»Ÿï¼šå¦‚å®‡å®™å°„ç”µæš´å®šä½ã€æ°”å€™å¼‚å¸¸æº¯æºç­‰æ¶‰åŠç¨€ç–ä¼ æ„Ÿå™¨é˜µåˆ—çš„ç§‘å­¦åæ¼”é—®é¢˜ã€‚
- æ„å»º**ç‰©ç†Foundation Model**ï¼šé€šè¿‡å¤§è§„æ¨¡ç‰©ç†éšæœºåŒ–è®­ç»ƒé€šç”¨é€†ç®—å­ï¼Œæ”¯æŒå¤šç§åœ°çƒç‰©ç†ä»»åŠ¡çš„é›¶æ ·æœ¬è¿ç§»ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **SourceNet ä¸ä»…æ˜¯ä¸€ä¸ªé«˜ç²¾åº¦åœ°éœ‡åæ¼”æ¨¡å‹ï¼Œæ›´æ˜¯ä¸€ä¸ªèƒ½ä»æ•°æ®ä¸­è‡ªä¸»å‘ç°æœ€ä¼˜è§‚æµ‹ç­–ç•¥çš„â€œç§‘å­¦æ™ºèƒ½ä½“â€ï¼Œä¸ºAI for Scienceæä¾›äº†å¯è§£é‡Šã€å¯æ³›åŒ–ã€å¯è¿ç§»çš„æ–°èŒƒå¼ã€‚**

</details>

---

### 11. [Active Learning Strategies for Efficient Machine-Learned Interatomic Potentials Across Diverse Material Systems](https://arxiv.org/abs/2601.06916)

**Authors**: Mohammed Azeez Khan, Aaron D'Souza, Vijay Choyal  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.06916v1  

#### Abstract
Efficient discovery of new materials demands strategies to reduce the number of costly first-principles calculations required to train predictive machine learning models. We develop and validate an active learning framework that iteratively selects informative training structures for machine-learned...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Active Learning Strategies for Efficient Machine-Learned Interatomic Potentials Across Diverse Material Systems*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³**æœºå™¨å­¦ä¹ åŠ¿å‡½æ•°ï¼ˆMLIPsï¼‰è®­ç»ƒä¸­å¯¹é«˜æˆæœ¬ç¬¬ä¸€æ€§åŸç†è®¡ç®—ï¼ˆå¦‚DFTï¼‰ä¾èµ–è¿‡é‡**çš„é—®é¢˜ã€‚åœ¨ææ–™å‘ç°ä¸­ï¼ŒDFTè®¡ç®—ä»£ä»·é«˜æ˜‚ï¼ˆæ¯ç»“æ„éœ€ $10^1$â€“$10^3$ CPUå°æ—¶ï¼‰ï¼Œå› æ­¤å¦‚ä½•ä»¥æœ€å°‘çš„æ ‡æ³¨æ ·æœ¬å®ç°é«˜ç²¾åº¦æ¨¡å‹è®­ç»ƒæˆä¸ºå…³é”®æŒ‘æˆ˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºå¹¶éªŒè¯äº†ä¸€ä¸ª**ç³»ç»Ÿæ€§çš„ä¸»åŠ¨å­¦ä¹ ï¼ˆActive Learning, ALï¼‰æ¡†æ¶**ï¼Œç”¨äºä»å¤§è§„æ¨¡å¼‚æ„ææ–™æ•°æ®åº“ï¼ˆMaterials Project å’Œ OQMDï¼‰ä¸­é«˜æ•ˆé€‰æ‹©æœ€å…·ä¿¡æ¯é‡çš„ç»“æ„æ¥è®­ç»ƒ MLIPsã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **ç»Ÿä¸€æ¯”è¾ƒå››ç§ALç­–ç•¥**ï¼šé¦–æ¬¡åœ¨åŒä¸€å®éªŒè®¾ç½®ä¸‹ç³»ç»Ÿæ€§åœ°å¯¹æ¯”äº†éšæœºé‡‡æ ·ã€ä¸ç¡®å®šæ€§é‡‡æ ·ï¼ˆuncertainty-basedï¼‰ã€å¤šæ ·æ€§é‡‡æ ·ï¼ˆdiversity-basedï¼‰ä»¥åŠæ··åˆç­–ç•¥ï¼ˆhybridï¼‰åœ¨å¤šä¸ªææ–™ä½“ç³»ä¸­çš„è¡¨ç°ã€‚
- **é›†æˆQuery-by-Committeeè¿›è¡Œä¸ç¡®å®šæ€§é‡åŒ–**ï¼šé‡‡ç”¨ç¥ç»ç½‘ç»œé›†æˆï¼ˆensembleï¼‰æ¨¡å‹ç»“åˆ Query-by-Committeeï¼ˆQBCï¼‰èŒƒå¼å®ç°å®æ—¶çš„epistemic uncertaintyä¼°è®¡ã€‚
- **åŸºäºk-meansèšç±»çš„å¤šæ ·æ€§é‡‡æ ·ä¼˜åŒ–**ï¼šåˆ©ç”¨17ç»´æè¿°ç¬¦ç©ºé—´ä¸­çš„k-meansèšç±»ï¼ˆé…åˆæœ€è¿œç‚¹ç»†åŒ–ï¼‰å®ç°ç»“æ„å¤šæ ·æ€§çš„ä¸»åŠ¨æ¢ç´¢ã€‚
- **è½»é‡åŒ–å¯å¤ç°æµç¨‹è®¾è®¡**ï¼šæ•´ä¸ªç®¡é“å¯åœ¨ Google Colab ä¸Šè¿è¡Œï¼ˆ<8GB RAMï¼Œ<4å°æ—¶/ç³»ç»Ÿï¼‰ï¼Œæ˜¾è‘—é™ä½ç ”ç©¶é—¨æ§›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **å¤šç³»ç»Ÿã€å¤šç­–ç•¥ã€ç»Ÿè®¡ä¸¥è°¨çš„åŸºå‡†æµ‹è¯•**ï¼šå¡«è¡¥äº†é¢†åŸŸå†…ç¼ºä¹è·¨ææ–™ç³»ç»Ÿçš„ç»¼åˆæ€§ALæ¯”è¾ƒç ”ç©¶çš„ç©ºç™½ã€‚
- **æ›´é«˜çš„æ•°æ®æ•ˆç‡**ï¼šç›¸æ¯”éšæœºé‡‡æ ·ï¼Œæ™ºèƒ½é€‰æ‹©ç­–ç•¥å¯å‡å°‘5â€“13%çš„æ ‡æ³¨æ ·æœ¬è¾¾åˆ°ç›¸åŒç²¾åº¦ã€‚
- **å¼€æºä¸å¯è®¿é—®æ€§å¼º**ï¼šä»£ç å…¬å¼€ï¼Œæ”¯æŒå…¨çƒèµ„æºå—é™çš„ç ”ç©¶è€…å‚ä¸MLIPå¼€å‘ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- æ¥æºäºä¸¤å¤§å¼€æ”¾ææ–™æ•°æ®åº“ï¼š
  - **Materials Project (MP)**ï¼šé€šè¿‡ `mp-api` è·å–æœ€å¤š500ä¸ªç»“æ„/ç³»ç»Ÿã€‚
  - **Open Quantum Materials Database (OQMD)**ï¼šé€šè¿‡ `qmpy` å®¢æˆ·ç«¯è·å–æœ€å¤š100ä¸ªç»“æ„/ç³»ç»Ÿã€‚
- è¦†ç›–å››ä¸ªä»£è¡¨æ€§ææ–™ç³»ç»Ÿï¼š
  - å…ƒç´ ç¢³ï¼ˆCarbonï¼‰
  - ç¡…ï¼ˆSiliconï¼‰
  - é“ï¼ˆIronï¼‰
  - é’›æ°§åŒ–ç‰©ï¼ˆTi-Oï¼‰

#### æ•°æ®é¢„å¤„ç†
- è¿‡æ»¤æ¡ä»¶ï¼šåŸå­æ•°2â€“50ï¼›å½¢æˆèƒ½å’Œå¸¦éš™æœ‰æ•ˆï¼›å»é™¤é‡å¤é¡¹ï¼ˆÎ”E < 1 meVï¼‰
- ç‰¹å¾å·¥ç¨‹ï¼šæ„å»º17ç»´ç‰¹å¾å‘é‡ï¼ˆ8ç»´ç»„åˆ†ç‰¹å¾ + 9ç»´æ€§è´¨ç‰¹å¾ï¼‰ï¼Œæ ‡å‡†åŒ–å¤„ç†
- åˆ’åˆ†æ–¹å¼ï¼š80%ä½œä¸ºè®­ç»ƒ/æŸ¥è¯¢æ± ï¼Œ20%ä¸ºå›ºå®šæµ‹è¯•é›†

| System     | Total Structures | Pool / Test Size |
|------------|------------------|------------------|
| Carbon     | 600              | 480 / 120        |
| Silicon    | 571              | 457 / 114        |
| Iron       | 532              | 426 / 106        |
| Ti-O       | 509              | 407 / 102        |

### å®éªŒè®¾ç½®
- **ä¸»åŠ¨å­¦ä¹ å¾ªç¯**ï¼š
  - åˆå§‹åŒ–ï¼š30ä¸ªå·²æ ‡æ³¨æ ·æœ¬
  - è¿­ä»£æ¬¡æ•°ï¼š6è½®
  - æ¯è½®æ–°å¢æ ·æœ¬æ•°ï¼š15ä¸ª
  - æ€»æ ‡æ³¨æ ·æœ¬ï¼šä»30å¢è‡³105
- **æ¨¡å‹æ¶æ„**ï¼š
  - ä½¿ç”¨ç”±5ä¸ªæˆå‘˜ç»„æˆçš„**å‰é¦ˆç¥ç»ç½‘ç»œé›†æˆæ¨¡å‹**ï¼ˆM=5ï¼‰
  - æ¯ä¸ªç½‘ç»œç»“æ„ï¼šè¾“å…¥å±‚ï¼ˆ17ç»´ï¼‰â†’ ä¸¤å±‚éšè—å±‚ï¼ˆ128 ReLUï¼‰â†’ è¾“å‡ºå±‚ï¼ˆ1ï¼Œé¢„æµ‹å½¢æˆèƒ½/åŸå­ï¼‰
  - ä¼˜åŒ–å™¨ï¼šAdamï¼ˆlr=1e-3ï¼‰ï¼ŒæŸå¤±å‡½æ•°ï¼šMSE
- **ä¸ç¡®å®šæ€§ä¼°è®¡**ï¼šä½¿ç”¨é›†æˆæ–¹å·®ï¼ˆensemble varianceï¼‰ä½œä¸º epistemic uncertainty åº¦é‡

### æŸ¥è¯¢ç­–ç•¥å¯¹æ¯”
| ç­–ç•¥ | æè¿° |
|------|------|
| **Random Sampling** | åŸºçº¿ï¼Œéšæœºé€‰å–15ä¸ªæœªæ ‡æ³¨æ ·æœ¬ |
| **Uncertainty Sampling** | é€‰æ‹©é›†æˆæ–¹å·®æœ€å¤§çš„15ä¸ªæ ·æœ¬ |
| **Diversity Sampling** | åœ¨17ç»´æè¿°ç¬¦ç©ºé—´ä¸Šæ‰§è¡Œk-meansï¼ˆk=15ï¼‰ï¼Œå–å„ç°‡ä¸­å¿ƒæœ€è¿‘ç»“æ„ |
| **Hybrid Sampling** | åŠ æƒç»„åˆï¼š$ \alpha U_{\text{norm}} + (1-\alpha) D_{\text{norm}} $ï¼Œå…¶ä¸­ $\alpha = 0.6$ |

### è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦æŒ‡æ ‡ï¼š
  - **MAE**ï¼ˆMean Absolute Errorï¼Œå•ä½ï¼šeV/atomï¼‰
  - **RÂ²**ï¼ˆCoefficient of Determinationï¼‰
- ç»Ÿè®¡åˆ†æï¼š
  - æ¯ç§é…ç½®è¿è¡Œ **5æ¬¡ä¸åŒéšæœºç§å­**
  - æŠ¥å‘Šå‡å€¼ Â± æ ‡å‡†å·®
  - ä½¿ç”¨**é…å¯¹tæ£€éªŒ**ï¼ˆpaired t-testï¼‰åˆ¤æ–­æ˜¾è‘—æ€§ï¼ˆÎ±=0.05ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 2ï¼‰

| System | Strategy | MAE (eV/atom) | RÂ² | p-value vs Random |
|--------|----------|---------------|-----|--------------------|
| Carbon | Random | 0.262Â±0.012 | 0.886Â±0.011 | â€” |
|        | Diversity | **0.261Â±0.008** | 0.879Â±0.010 | 0.823 (Better) |
| Silicon | Random | 0.235Â±0.006 | 0.928Â±0.004 | â€” |
|         | Hybrid | 0.238Â±0.006 | **0.941Â±0.004** | 0.289 (Better) |
| Iron | Random | 0.233Â±0.009 | 0.803Â±0.015 | â€” |
|      | Diversity | **0.223Â±0.011** | 0.796Â±0.016 | 0.216 (Better) |
| Ti-O | Random | 0.912Â±0.041 | -0.407Â±0.089 | â€” |
|      | **Diversity** | **0.813Â±0.035** | **-0.072Â±0.076** | **0.008*** (Better) |

> æ³¨ï¼š*è¡¨ç¤ºç»Ÿè®¡æ˜¾è‘—ï¼ˆp < 0.05ï¼‰

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **Diversity Sampling è¡¨ç°æœ€ä¼˜æˆ–å…·ç«äº‰åŠ›**ï¼š
  - åœ¨æ‰€æœ‰ç³»ç»Ÿä¸­å‡è¾¾åˆ°æœ€ä½æˆ–æ¥è¿‘æœ€ä½ MAE
  - åœ¨å¤æ‚ç³»ç»Ÿ Ti-O ä¸­å®ç° **10.9% çš„ MAE æ”¹è¿›**ï¼ˆä» 0.912 â†’ 0.813 eV/atomï¼‰ï¼Œä¸”å·®å¼‚é«˜åº¦æ˜¾è‘—ï¼ˆp=0.008ï¼‰
- **Uncertainty Sampling æ•ˆæœä¸ä½³ç”šè‡³æ›´å·®**ï¼š
  - åœ¨ Carbonã€Fe å’Œ Ti-O ä¸Šè¡¨ç°åŠ£äºéšæœºé‡‡æ ·ï¼ˆp=0.042, 0.031, 0.156ï¼‰
  - åæ˜ å‡ºâ€œåªå…³æ³¨é«˜ä¸ç¡®å®šåŒºåŸŸâ€å¯èƒ½å¯¼è‡´é‡‡æ ·åå·®
- **Hybrid æ–¹æ³•æœªè¾¾é¢„æœŸ**ï¼š
  - å°½ç®¡ç†è®ºä¸Šæœ‰å¹³è¡¡ä¼˜åŠ¿ï¼Œä½†åœ¨å¤šæ•°ç³»ç»Ÿä¸­è¡¨ç°å¹³åº¸ï¼Œåœ¨ Ti-O ä¸Šåè€Œæœ€å·®ï¼ˆMAE=0.982ï¼‰

### å­¦ä¹ æ›²çº¿åˆ†æï¼ˆFigure 2ï¼‰
- **Carbon**ï¼šDiversityæ—©æœŸæ”¶æ•›æ›´å¿«ï¼Œæœ€ç»ˆè¯¯å·®æœ€ä½
- **Silicon**ï¼šæ‰€æœ‰æ–¹æ³•æ€§èƒ½æ¥è¿‘ï¼Œåæ˜ ä»»åŠ¡ç®€å•ã€æ•°æ®åŒè´¨æ€§å¼º
- **Iron**ï¼šDiversityæŒç»­ä¼˜äºRandom
- **Ti-O**ï¼šç­–ç•¥é—´å·®è·æœ€å¤§ï¼ŒDiversityæ˜æ˜¾é¢†å…ˆï¼Œä½“ç°å…¶åœ¨å¤æ‚åŒ–å­¦ç¯å¢ƒä¸‹çš„ä¼˜è¶Šæ€§

### æ¶ˆèå®éªŒä¸äº¤å‰æ•°æ®åº“éªŒè¯ï¼ˆFigure 3ï¼‰
- **Cross-Database Validationï¼ˆMP â†” OQMDï¼‰**ï¼š
  - MP â†’ OQMDï¼šéšç€æ ‡ç­¾å¢åŠ ï¼Œè¿ç§»æ€§èƒ½é€æ­¥æå‡ï¼Œè¯´æ˜MPæ•°æ®æ›´å…·æ³›åŒ–èƒ½åŠ›
  - OQMD â†’ MPï¼šè¿ç§»æ•ˆæœè¾ƒå·®ï¼Œæ­ç¤ºæ•°æ®åº“ä¹‹é—´å­˜åœ¨æ˜æ˜¾ domain shift
- è¡¨æ˜ï¼š**è®­ç»ƒæ•°æ®æ¥æºå½±å“æ¨¡å‹æ³›åŒ–èƒ½åŠ›**ï¼Œå¼ºè°ƒæ•°æ®ä¸€è‡´æ€§çš„é‡è¦æ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **Diversity-based sampling æ˜¯æœ€ç¨³å¥æœ‰æ•ˆçš„ALç­–ç•¥**ï¼š
   - å°¤å…¶é€‚ç”¨äºç»“æ„å’Œç»„æˆå¤æ‚çš„ææ–™ç³»ç»Ÿï¼ˆå¦‚ Ti-Oï¼‰
   - é€šè¿‡æ¢ç´¢ç‰¹å¾ç©ºé—´æœªè¦†ç›–åŒºåŸŸï¼Œæå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›
2. âš ï¸ **Uncertainty-based sampling å¹¶ä¸æ€»æ˜¯æœ‰æ•ˆ**ï¼š
   - åœ¨æŸäº›ç³»ç»Ÿä¸­åè€Œå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œå¯èƒ½å› è¿‡åº¦èšç„¦å±€éƒ¨é«˜ç†µåŒºåŸŸè€Œå¿½ç•¥å…¨å±€åˆ†å¸ƒ
3. ğŸ” **ç³»ç»Ÿå¤æ‚åº¦å†³å®šALæ”¶ç›Šå¤§å°**ï¼š
   - ç®€å•ç³»ç»Ÿï¼ˆå¦‚Siï¼‰å„ç­–ç•¥å·®å¼‚å°
   - å¤æ‚ç³»ç»Ÿï¼ˆå¦‚Ti-Oï¼‰ä¸­ï¼Œæ™ºèƒ½é‡‡æ ·å¸¦æ¥æ˜¾è‘—å¢ç›Šï¼ˆ10.9% MAEä¸‹é™ï¼‰
4. ğŸ’¡ **æ•°æ®æ•ˆç‡æå‡æ˜æ˜¾**ï¼š
   - æ™ºèƒ½ALç­–ç•¥å¯åœ¨è¾¾åˆ°ç›®æ ‡ç²¾åº¦æ—¶èŠ‚çœ **5â€“13% çš„DFTè®¡ç®—æˆæœ¬**
5. ğŸŒ **å…¨æµç¨‹å…·å¤‡é«˜åº¦å¯è®¿é—®æ€§**ï¼š
   - å¯åœ¨ Google Colab ä¸Šå®Œæˆï¼ˆ<8GB RAMï¼Œ<4å°æ—¶ï¼‰ï¼Œæ¨åŠ¨MLIP democratization

### æ–¹æ³•çš„å±€é™æ€§
- **æè¿°ç¬¦è¡¨è¾¾èƒ½åŠ›æœ‰é™**ï¼š
  - å½“å‰ä½¿ç”¨çš„17ç»´æ‰‹å·¥ç‰¹å¾ç¼ºä¹å±€éƒ¨ç»“æ„ç»†èŠ‚ï¼ˆå¦‚åŸå­é…ä½ã€é”®è§’ã€å¯¹ç§°æ€§ç­‰ï¼‰
  - æœªä½¿ç”¨SOAPã€symmetry functions æˆ– GNN è‡ªåŠ¨ç”Ÿæˆçš„è¡¨ç¤º
- **ä»…é¢„æµ‹å½¢æˆèƒ½**ï¼š
  - æœªæ‰©å±•è‡³å…¶ä»–é‡è¦å±æ€§ï¼ˆå¦‚å¸¦éš™ã€å¼¹æ€§æ¨¡é‡ã€ç£æ€§ç­‰ï¼‰
- **é™æ€åŠ æƒæ··åˆç­–ç•¥**ï¼š
  - Hybrid æ–¹æ³•ä½¿ç”¨å›ºå®šæƒé‡ Î±=0.6ï¼Œæœªèƒ½åŠ¨æ€é€‚åº”ä¸åŒç³»ç»Ÿæˆ–è®­ç»ƒé˜¶æ®µçš„éœ€æ±‚

### æœªæ¥å·¥ä½œæ–¹å‘
- ğŸ”„ **åŠ¨æ€è°ƒæ•´ uncertainty/diversity æƒé‡**ï¼šæ ¹æ®ç³»ç»Ÿå¤æ‚åº¦æˆ–è®­ç»ƒè¿›å±•è‡ªé€‚åº”è°ƒèŠ‚é‡‡æ ·åå¥½
- ğŸ§± **å¼•å…¥æ›´å…ˆè¿›çš„ç»“æ„æ„ŸçŸ¥æè¿°ç¬¦**ï¼šæ•´åˆ SOAPã€Behler-Parrinello symmetry functions æˆ– E(3)-equivariant GNNsï¼ˆå¦‚ NequIPï¼‰
- ğŸ“ˆ **å¤šä»»åŠ¡ä¸»åŠ¨å­¦ä¹ **ï¼šåŒæ—¶ä¼˜åŒ–å¤šç§ææ–™å±æ€§çš„è”åˆé‡‡æ ·ç­–ç•¥
- ğŸ¤ **ç»“åˆç”Ÿæˆæ¨¡å‹**ï¼šå°†ALä¸ç»“æ„ç”Ÿæˆæ¨¡å‹ç»“åˆï¼Œæ¢ç´¢æœªçŸ¥åŒ–å­¦ç©ºé—´
- ğŸš€ **é›†æˆæœ€æ–°æ¶æ„**ï¼šå€Ÿé‰´ Choyal et al. [31] çš„å·¥ä½œï¼Œå°†ALä¸é«˜æ€§èƒ½MLIPæ¶æ„æ·±åº¦èåˆï¼Œè¿›ä¸€æ­¥å‹ç¼©æ•°æ®éœ€æ±‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬ç ”ç©¶è¡¨æ˜ï¼Œåœ¨è®­ç»ƒæœºå™¨å­¦ä¹ åŠ¿å‡½æ•°æ—¶ï¼Œ**åŸºäºå¤šæ ·æ€§çš„ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ï¼ˆdiversity samplingï¼‰æ¯”ä¼ ç»Ÿçš„ä¸ç¡®å®šæ€§é‡‡æ ·æ›´ä¸ºæœ‰æ•ˆä¸”ç¨³å®š**ï¼Œå°¤å…¶åœ¨å¤æ‚ææ–™ç³»ç»Ÿä¸­èƒ½æ˜¾è‘—æå‡æ•°æ®æ•ˆç‡ï¼Œä¸”æ•´å¥—æµç¨‹å¯åœ¨æ™®é€šè®¡ç®—èµ„æºä¸Šè¿è¡Œï¼Œä¸ºå…¨çƒç ”ç©¶è€…æä¾›äº†ä½é—¨æ§›ã€é«˜å¤ç°æ€§çš„MLIPå¼€å‘èŒƒå¼ã€‚

</details>

---

### 12. [HAS-VQ: Hessian-Adaptive Sparse Vector Quantization for High-Fidelity LLM Compression](https://arxiv.org/abs/2601.06959)

**Authors**: Vladimer Khasia  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.06959v1  

#### Abstract
Post-training quantization is essential for deploying Large Language Models (LLMs) on resource- constrained devices. However, standard integer quantization (e.g., INT4) fundamentally degrades per- formance by imposing a uniform grid on the heavy-tailed distribution of weight parameters, particularly...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šHAS-VQ: Hessian-Adaptive Sparse Vector Quantization for High-Fidelity LLM Compression

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **æ ‡å‡†æ•´æ•°é‡åŒ–ï¼ˆå¦‚ INT4ï¼‰åœ¨å°è§„æ¨¡ LLM ä¸Šæ€§èƒ½é€€åŒ–ä¸¥é‡**ï¼šç”±äº Transformer æƒé‡å…·æœ‰é‡å°¾åˆ†å¸ƒï¼ˆheavy-tailed distributionï¼‰ï¼Œå‡åŒ€çš„æ•´æ•°é‡åŒ–ç½‘æ ¼æ— æ³•æœ‰æ•ˆå»ºæ¨¡è¿™ç§éé«˜æ–¯åˆ†å¸ƒï¼Œå¯¼è‡´é‡åŒ–å™ªå£°é›†ä¸­åœ¨æ•æ„Ÿå‚æ•°ä¸Šï¼Œå¼•å‘ perplexity å´©æºƒã€‚
- **ä¼ ç»Ÿ Vector Quantizationï¼ˆVQï¼‰å—å¼‚å¸¸å€¼å¹²æ‰°**ï¼šæ ‡å‡† VQï¼ˆå¦‚ K-Meansï¼‰å¯¹æƒé‡ä¸­çš„é«˜å¹…å€¼ outlier æ•æ„Ÿï¼Œå®¹æ˜“ä½¿èšç±»ä¸­å¿ƒåç§»ï¼Œé™ä½æ•´ä½“é‡å»ºè´¨é‡ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šHAS-VQ
æå‡ºäº†ä¸€ç§åä¸º **HAS-VQï¼ˆHessian-Adaptive Sparse Vector Quantizationï¼‰** çš„åè®­ç»ƒå‹ç¼©æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡äºŒé˜¶æ•æ„Ÿæ€§åˆ†æå°†é«˜æ•æ„Ÿåº¦çš„â€œå¼‚å¸¸å€¼â€ä»ä¸»ä½“æƒé‡ä¸­è§£è€¦ï¼Œå¹¶è¿›è¡Œå·®å¼‚åŒ–å¤„ç†ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
1. **Hessian-Masked Decouplingï¼ˆåŸºäº Hessian çš„æ©ç è§£è€¦ï¼‰**
   - åˆ©ç”¨å¯¹è§’ Hessianï¼ˆè¿‘ä¼¼ Fisher ä¿¡æ¯çŸ©é˜µï¼‰è®¡ç®—æ¯ä¸ªæƒé‡çš„é‡è¦æ€§å¾—åˆ† $ I = |W_{\text{norm}}| \odot \sqrt{H} $
   - æ ¹æ®é‡è¦æ€§æ’åºï¼Œè¯†åˆ«å‡º top-p% çš„é«˜æ•æ„Ÿå‚æ•°ä½œä¸º outliersï¼Œå¹¶å°†å…¶ä»å¾…é‡åŒ–çš„â€œä¸»ä½“â€ä¸­å±è”½ï¼ˆç½®é›¶ï¼‰ï¼Œé˜²æ­¢å…¶å½±å“ VQ èšç±»è¿‡ç¨‹ã€‚

2. **Residual Sparse Feedbackï¼ˆæ®‹å·®ç¨€ç–åé¦ˆæœºåˆ¶ï¼‰**
   - ä¸ç›´æ¥å­˜å‚¨ outliers çš„åŸå§‹å€¼ï¼Œè€Œæ˜¯è®¡ç®—å®ƒä»¬åœ¨é‡åŒ–åçš„é‡å»ºè¯¯å·®ï¼ˆå³æ®‹å·®ï¼‰$ S_{ij} = W_{\text{norm},ij} - Q(B)_{ij} $ï¼Œä»…å­˜å‚¨è¿™äº›æ®‹å·®ã€‚
   - åœ¨æ¨ç†æ—¶é€šè¿‡ $ \hat{W} = Q(B) + S $ å®ç°å¯¹æ•æ„Ÿç»´åº¦çš„**ç²¾ç¡®é‡æ„**ï¼ˆup to FP16 precisionï¼‰ï¼Œä»è€Œæ¶ˆé™¤å…³é”®è·¯å¾„ä¸Šçš„é‡åŒ–å™ªå£°ã€‚

3. **Robust Statistical VQ**
   - å¯¹å»é™¤äº† outliers çš„å¯†é›†ä¸»ä½“ï¼ˆdense bodyï¼‰åº”ç”¨é²æ£’çš„ VQï¼Œé‡‡ç”¨ç¨³å®šæ€§é‡‡æ ·ä¸â€œæ­»äº¡å•å…ƒå¤æ´»â€æœºåˆ¶ï¼ˆDead Unit Revivalï¼‰æå‡èšç±»æ”¶æ•›æ€§å’Œä»£ç æœ¬åˆ©ç”¨ç‡ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | HAS-VQ | ä¼ ç»Ÿ INT4 / RTN | æ ‡å‡† VQ |
|------|--------|------------------|---------|
| å™ªå£°æ§åˆ¶ | æ˜¾å¼æŠ‘åˆ¶é«˜ Hessian æ–¹å‘å™ªå£° | å‡åŒ€å™ªå£°åˆ†å¸ƒï¼Œæ˜“ç ´åä¼˜åŒ–è½¨è¿¹ | æ˜“è¢« outliers æ‹‰å |
| å­˜å‚¨æ•ˆç‡ | åŠ¨æ€åˆ†é…æ¯”ç‰¹ï¼Œå¯†åº¦åŒ¹é… | å›ºå®šæ•´æ•°ç½‘æ ¼ï¼Œä½æ•ˆç¼–ç é‡å°¾åˆ†å¸ƒ | å¯èƒ½å›  outlier å¤±æ•ˆ |
| ä¿çœŸåº¦ | æ”¯æŒ near-lossless å‹ç¼©ï¼ˆ~7 BPPï¼‰ | æ˜¾è‘—æ€§èƒ½ä¸‹é™ï¼ˆPPL â†‘ï¼‰ | ä¸­ç­‰ä¿çœŸï¼Œä¸ç¨³å®š |
| Pareto æ€§èƒ½ | åœ¨æ›´å° BPP ä¸‹å®ç°æ›´ä½ PPL | éœ€æ›´é«˜ bit æ•°ç»´æŒæ€§èƒ½ | é€šå¸¸ä¸å¦‚ HAS-VQ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
- **æ ¡å‡†æ•°æ®ï¼ˆCalibration Dataï¼‰**ï¼šç”¨äºä¼°è®¡ Hessian å’Œè®­ç»ƒ VQ codebookï¼ˆå…·ä½“æœªè¯¦è¿°ï¼Œåº”ä¸ºå…¸å‹è¯­è¨€å»ºæ¨¡è¯­æ–™ï¼‰
- **è¯„ä¼°æ•°æ®é›†**ï¼š**WikiText-2**ï¼Œç”¨äºæµ‹è¯•æ¨¡å‹å‹ç¼©åçš„ **Perplexity (PPL)**

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼šSmolLM2-1.7B-Instructï¼ˆ1.7B å‚æ•°è§„æ¨¡çš„å°å‹ LLMï¼‰
- **å‹ç¼©ç›®æ ‡**ï¼šPost-Training Quantizationï¼ˆPTQï¼‰ï¼Œæ— éœ€å¾®è°ƒ
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Perplexity (PPL)**ï¼šè¡¡é‡è¯­è¨€å»ºæ¨¡èƒ½åŠ›ä¿ç•™ç¨‹åº¦
  - **Effective Bits-Per-Parameter (BPP)**ï¼šç»¼åˆè€ƒè™‘ codebookã€indexã€scaleã€sparse residual çš„å¹³å‡æ¯”ç‰¹å¼€é”€
  - **Compression Ratio (CR)**ï¼šç›¸å¯¹äº FP16 çš„å‹ç¼©å€æ•°ï¼ˆCR = 16.0 / BPPï¼‰

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ |
|------|------|
| FP16 | Oracleï¼ˆæ— æŸåŸºå‡†ï¼‰ |
| INT4 (RTN) | æ ‡å‡†æ•´æ•°é‡åŒ–åŸºçº¿ï¼ˆRound-To-Nearestï¼‰ |
| HAS-VQ (Mid) | å¹³è¡¡é…ç½®ï¼ˆè¿½æ±‚é«˜æ•ˆï¼‰ |
| HAS-VQ (High) | é«˜ä¿çœŸé…ç½®ï¼ˆè¿½æ±‚ç²¾åº¦ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| Method | Configuration | PPL | BPP | Ratio (vs FP16) | Regime |
|--------|---------------|-----|-----|------------------|--------|
| FP16 | Oracle | 10.04 | 16.00 | 1.0x | Lossless |
| INT4 | RTN Baseline | 20.03 | 4.71 | 3.4x | Lossy (Degraded) |
| **HAS-VQ** | Mid (Balanced) | **14.23** | **4.23** | **3.8x** | Efficient Dominance |
| **HAS-VQ** | High (Fidelity) | **10.12** | **7.03** | **2.3x** | Near-Lossless |

### ğŸ”¬ å¯¹æ¯”ç»“æœåˆ†æ
1. **Pareto Dominance over INT4**
   - åœ¨ **æ›´ä½ BPPï¼ˆ4.23 vs 4.71ï¼‰** ä¸‹ï¼ŒPPL ä» 20.03 é™è‡³ **14.23**ï¼Œæ€§èƒ½æå‡çº¦ **29%**
   - åŒæ—¶èŠ‚çœ **11% å­˜å‚¨ç©ºé—´**ï¼Œå®ç°â€œæ›´å°æ›´å¿«æ›´å¥½â€

2. **High-Fidelity Compression æˆæœ**
   - åœ¨ 7.03 BPP ä¸‹ï¼ŒPPL è¾¾åˆ° **10.12**ï¼Œä¸ FP16 çš„ 10.04 **ç»Ÿè®¡ä¸Šæ— æ˜¾è‘—å·®å¼‚**
   - å®ç° **2.3Ã— æ¨¡å‹å‹ç¼©**ï¼Œå¯è§†ä¸ºâ€œè¿‘æ— æŸå‹ç¼©â€ï¼ˆnear-losslessï¼‰
   - ç‰¹åˆ«é€‚ç”¨äºå¸¦å®½å—é™åœºæ™¯ä¸‹çš„è¾¹ç¼˜éƒ¨ç½²

3. **æ¶ˆèå®éªŒï¼ˆéšå«äºè®¾è®¡é€»è¾‘ä¸­ï¼‰**
   - è™½æœªæ˜ç¡®åˆ—å‡º ablation study è¡¨æ ¼ï¼Œä½†æ–‡ä¸­å¼ºè°ƒï¼š
     - è‹¥ä¸ä½¿ç”¨ residual feedbackï¼Œåˆ™æ— æ³•ä¿è¯æ•æ„Ÿç»´åº¦çš„ç²¾ç¡®æ¢å¤
     - è‹¥ä¸è¿›è¡Œ Hessian-masked decouplingï¼ŒVQ codebook ä¼šè¢« outliers æ‰­æ›²
     - Stability-Bounded Sampling å’Œ Dead Unit Revival æå‡äº† codebook åˆ©ç”¨ç‡å’Œç¨³å®šæ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **é‡å°¾åˆ†å¸ƒä¸é€‚åˆå‡åŒ€æ•´æ•°é‡åŒ–**ï¼šå°å‹ LLM ç¼ºä¹å†—ä½™å¸æ”¶å™ªå£°ï¼ŒINT4 å¯¼è‡´æ˜¾è‘—æ€§èƒ½é€€åŒ–ï¼ˆPPL +100%ï¼‰ã€‚
2. **Hessian æŒ‡å¯¼çš„è§£è€¦è‡³å…³é‡è¦**ï¼šé€šè¿‡äºŒé˜¶æ•æ„Ÿæ€§åˆ†ç¦» outliers å¯æ˜¾è‘—æå‡ VQ æ•ˆæœã€‚
3. **æ®‹å·®ç¨€ç–åé¦ˆå®ç°â€œç²¾å‡†ä¿®å¤â€**ï¼šåªåœ¨æœ€å…³é”®çš„ä½ç½®æ–½åŠ è¡¥å¿ï¼Œä»¥æä½æˆæœ¬æ¢å–å¤§å¹…æ€§èƒ½å¢ç›Šã€‚
4. **å­˜åœ¨ä¸¤ä¸ªä¼˜åŠ¿æ“ä½œç‚¹**ï¼š
   - **é«˜æ•ˆä¸»å¯¼æ¨¡å¼ï¼ˆMidï¼‰**ï¼šä¼˜äº INT4ï¼Œå…¼å…·æ›´å°ä½“ç§¯ä¸æ›´é«˜ç²¾åº¦
   - **é«˜ä¿çœŸæ¨¡å¼ï¼ˆHighï¼‰**ï¼šåª²ç¾ FP16 è¡¨ç°ï¼Œé€‚åˆä¸èƒ½ç‰ºç‰²å‡†ç¡®æ€§çš„åœºæ™¯

### âš ï¸ å±€é™æ€§
- **ä¾èµ– Hessian è¿‘ä¼¼**ï¼šéœ€è¦åœ¨æ ¡å‡†æ•°æ®ä¸Šä¼°è®¡å¯¹è§’ Hessianï¼Œå¢åŠ äº†é¢„å¤„ç†å¤æ‚åº¦
- **å­˜å‚¨ç¨€ç–æ®‹å·®å¸¦æ¥é¢å¤–å…ƒæ•°æ®å¼€é”€**ï¼šè™½ç„¶æ€»é‡å°ï¼Œä½†éœ€ç®¡ç† index å’Œ sparse structure
- å½“å‰éªŒè¯é›†ä¸­äº **1.7B è§„æ¨¡æ¨¡å‹**ï¼Œæ›´å¤§æ¨¡å‹ï¼ˆå¦‚ 7B+ï¼‰çš„æ•ˆæœå°šå¾…éªŒè¯
- æ¨ç†ç«¯éœ€æ”¯æŒ **VQ lookup + sparse add** æ“ä½œï¼Œå¯èƒ½å¢åŠ å·¥ç¨‹å®ç°éš¾åº¦

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **Mixture-of-Experts (MoE)** å’Œ **CNN-based æ¶æ„**
- æ¢ç´¢ **åŠ¨æ€ sparsity ratio selection**ï¼ˆæ ¹æ®å±‚è‡ªé€‚åº”è°ƒæ•´ pï¼‰
- ç»“åˆ **quantization-aware fine-tuning (QAT)** è¿›ä¸€æ­¥å‹æ¦¨æ€§èƒ½è¾¹ç•Œ
- å¼€å‘ä¸“ç”¨ç¡¬ä»¶å‹å¥½ç‰ˆæœ¬ï¼ˆå¦‚æ”¯æŒ HAS-VQ çš„ kernel fusionï¼‰

---

## âœ… æ€»ç»“
HAS-VQ æ˜¯ä¸€ç§é¢å‘å°å‹ LLM çš„é«˜æ€§èƒ½ PTQ æ–¹æ³•ï¼Œé€šè¿‡ **Hessian-driven outlier isolation + residual sparse feedback + robust VQ** çš„ä¸‰æ®µå¼è®¾è®¡ï¼Œåœ¨ **4.23 BPP** ä¸‹è¶…è¶Š INT4 åŸºçº¿ï¼ŒåŒæ—¶å¯åœ¨ **7.03 BPP** å®ç°è¿‘ä¹æ— æŸå‹ç¼©ã€‚å®ƒæ‰“ç ´äº†ä¼ ç»Ÿæ•´æ•°é‡åŒ–åœ¨å°å‹æ¨¡å‹ä¸Šçš„æ€§èƒ½ç“¶é¢ˆï¼Œä¸ºè¾¹ç¼˜è®¾å¤‡éƒ¨ç½²æä¾›äº†æ–°çš„â€œé«˜æ•ˆä¸”é«˜ä¿çœŸâ€çš„å‹ç¼©èŒƒå¼ã€‚

</details>

---

### 13. [Land-then-transport: A Flow Matching-Based Generative Decoder for Wireless Image Transmission](https://arxiv.org/abs/2601.07512)

**Authors**: Jingwen Fu, Ming Xiao, Mikael Skoglund, Dong In Kim  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.07512v1  

#### Abstract
Due to strict rate and reliability demands, wireless image transmission remains difficult for both classical layered designs and joint source-channel coding (JSCC), especially under low latency. Diffusion-based generative decoders can deliver strong perceptual quality by leveraging learned image pri...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Land-then-transport: A Flow Matching-Based Generative Decoder for Wireless Image Transmission*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿæ— çº¿å›¾åƒä¼ è¾“é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **åˆ†å±‚è®¾è®¡**ï¼ˆå¦‚ JPEG2000 + LDPCï¼‰åœ¨æœ‰é™ç é•¿ã€ä½å»¶è¿Ÿåœºæ™¯ä¸‹æ€§èƒ½ä¸ä½³ï¼Œä¸”å¯¹ä¿¡é“å¤±é…æ•æ„Ÿã€‚
- **åŸºäºæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆå¼è§£ç å™¨**ï¼ˆå¦‚ CDDMï¼‰è™½ç„¶èƒ½æå‡æ„ŸçŸ¥è´¨é‡ï¼Œä½†ä¾èµ–å¤šæ­¥éšæœºå»å™ªè¿‡ç¨‹ï¼Œå¯¼è‡´**é«˜è§£ç å»¶è¿Ÿ**ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶é€šä¿¡éœ€æ±‚ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•åœ¨ä¿è¯é«˜è´¨é‡é‡å»ºçš„åŒæ—¶ï¼Œå®ç°**ä½å»¶è¿Ÿã€ç¡®å®šæ€§ã€ä¿¡é“è‡ªé€‚åº”**çš„æ— çº¿å›¾åƒç”Ÿæˆå¼è§£ç ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Land-then-Transport (LTT)** çš„æ–°èŒƒå¼ï¼Œå¹¶åŸºäº **Conditional Flow Matching (CFM)** æ„å»ºäº†ä¸€ä¸ªæ–°å‹ç”Ÿæˆå¼è§£ç å™¨ï¼š

#### ï¼ˆ1ï¼‰LTT èŒƒå¼ï¼šå°†ç‰©ç†ä¿¡é“åµŒå…¥æ¦‚ç‡æµ
- å°†æ— çº¿ä¿¡é“æ•ˆåº”è§†ä¸ºè¿ç»­æ—¶é—´æ¦‚ç‡è·¯å¾„ä¸Šçš„â€œç€é™†â€æ“ä½œã€‚
- æ¥æ”¶ä¿¡å· $Y$ è¢«è§£é‡Šä¸ºåœ¨æŸä¸ª**æœ‰æ•ˆç€é™†æ—¶é—´ $t^*$** å¤„çš„æ¦‚ç‡è·¯å¾„çŠ¶æ€ï¼Œè¯¥æ—¶é—´ç”±ä¿¡é“å™ªå£°æ°´å¹³å†³å®šã€‚
- è§£ç å³æ˜¯ä» $t^*$ åˆ° $t=1$ï¼ˆå¹²å‡€å›¾åƒï¼‰çš„**ç¡®å®šæ€§ ODE ç§¯åˆ†è¿‡ç¨‹**ï¼Œæ— éœ€ä»çº¯å™ªå£°å¼€å§‹é‡‡æ ·ã€‚

#### ï¼ˆ2ï¼‰Flow Matching-based Decoder è®¾è®¡
- é’ˆå¯¹ AWGN ä¿¡é“æ„é€ ä¸€ä¸ª**é«˜æ–¯å¹³æ»‘è·¯å¾„**ï¼ˆGaussian smoothing pathï¼‰ï¼Œå…¶å™ªå£°è°ƒåº¦å‡½æ•°å•è°ƒæ˜ å°„ä¿¡é“å™ªå£°å¼ºåº¦ã€‚
- æ¨å¯¼å‡ºè¯¥è·¯å¾„ä¸‹çš„**é—­å¼è§£ææ•™å¸ˆé€Ÿåº¦åœº**ï¼ˆanalytical teacher velocity fieldï¼‰ã€‚
- ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œå­¦ä¹ å­¦ç”Ÿå‘é‡åœº $v_\theta(x,t)$ï¼Œé€šè¿‡ **CFM æŸå¤±å‡½æ•°**è¿›è¡Œè®­ç»ƒï¼Œé¿å…æ¨¡æ‹Ÿå‰å‘æ‰©æ•£è¿‡ç¨‹ã€‚

#### ï¼ˆ3ï¼‰è·¨ä¿¡é“é€šç”¨æ€§è®¾è®¡
- å¯¹äº **Rayleigh è¡°è½** å’Œ **MIMO ä¿¡é“**ï¼Œé€šè¿‡ **Linear MMSE Equalization** å’Œ **SVD åŸŸå¤„ç†**ï¼Œå°†å…¶è½¬æ¢ä¸ºç­‰æ•ˆ AWGN ä¿¡é“ã€‚
- åˆ©ç”¨ç›¸åŒçš„ AWGN è®­ç»ƒå¥½çš„é€Ÿåº¦åœºå’Œæ¦‚ç‡è·¯å¾„ï¼Œä»…éœ€è°ƒæ•´ç€é™†æ—¶é—´ $t^*$ï¼Œå³å¯å®ç°**æ— éœ€é‡æ–°è®­ç»ƒ**çš„è·¨ä¿¡é“è§£ç ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | ä¼ ç»Ÿåˆ†å±‚æ–¹æ³• | DeepJSCC | æ‰©æ•£æ¨¡å‹ï¼ˆå¦‚ CDDMï¼‰ | æœ¬æ–‡ LTT |
|------|---------------|----------|------------------------|---------|
| **å»¶è¿Ÿ** | ä¸­ç­‰ | ä½ | é«˜ï¼ˆç™¾çº§é‡‡æ ·æ­¥ï¼‰ | **æä½**ï¼ˆ10 æ­¥å†…ï¼‰ |
| **é‡å»ºè´¨é‡** | åƒç´ çº§å¥½ï¼Œæ„ŸçŸ¥å·® | ä¸€èˆ¬ | æ„ŸçŸ¥è´¨é‡é«˜ | **æ„ŸçŸ¥è´¨é‡æ›´é«˜** |
| **ä¿¡é“é€‚åº”æ€§** | å·®ï¼ˆcliff effectï¼‰ | è¾ƒå¥½ | é€šå¸¸éœ€é‡è®­ç»ƒ | **å¼ºï¼ˆç»Ÿä¸€è·¯å¾„ï¼‰** |
| **è§£ç ç¡®å®šæ€§** | æ˜¯ | æ˜¯ | å¦ï¼ˆéšæœºï¼‰ | **æ˜¯ï¼ˆODEï¼‰** |
| **è®¡ç®—æ•ˆç‡** | é«˜ | é«˜ | ä½ | **é«˜ï¼ˆçº¿æ€§å¤æ‚åº¦ï¼‰** |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **MNIST**ï¼š28Ã—28 ç°åº¦æ‰‹å†™æ•°å­—ï¼Œç”¨äºä½åˆ†è¾¨ç‡éªŒè¯ã€‚
- **Fashion-MNIST**ï¼š28Ã—28 ç°åº¦æœé¥°å›¾åƒï¼Œæµ‹è¯•å¤šæ ·æ€§ã€‚
- **DIV2K**ï¼š256Ã—256 è‡ªç„¶å›¾åƒï¼Œä½œä¸ºé«˜åˆ†è¾¨ç‡åŸºå‡†ã€‚

### å®éªŒè®¾ç½®
- **ä¿¡é“æ¨¡å‹**ï¼šAWGNã€Rayleigh Fadingã€2Ã—2 MIMOã€‚
- **å¸¦å®½æ•ˆç‡ä¸€è‡´**ï¼šæ‰€æœ‰æ–¹æ³•ä½¿ç”¨ç›¸åŒ channel uses per pixelï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - ä½¿ç”¨ U-Net ç»“æ„å®ç°å­¦ç”Ÿé€Ÿåº¦åœº $v_\theta(x,t)$ã€‚
  - æœ€å¤§å™ªå£°æ°´å¹³ $\sigma_{\text{max}} = 1.0$ï¼Œå¯¹åº” SNR > 0 dBã€‚
  - Batch sizeï¼š64ï¼ˆMNIST/Fashion-MNISTï¼‰ï¼Œ32ï¼ˆDIV2Kï¼‰ã€‚
  - ODE æ­¥æ•°é»˜è®¤è®¾ä¸º 10ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **PSNR** | åƒç´ çº§ä¿çœŸåº¦ï¼Œè¶Šé«˜è¶Šå¥½ |
| **MS-SSIM** | å¤šå°ºåº¦ç»“æ„ç›¸ä¼¼æ€§ï¼Œåæ˜ è§†è§‰ä¿çœŸåº¦ |
| **LPIPS** | å­¦ä¹ å‹æ„ŸçŸ¥è·ç¦»ï¼Œåœ¨ç‰¹å¾ç©ºé—´è¡¡é‡å·®å¼‚ï¼Œè¶Šä½è¶Šå¥½ |
| **$\Delta$PSNR** | ç›¸å¯¹äºæ¥æ”¶ä¿¡å·çš„ PSNR æå‡ï¼Œä½“ç°è§£ç å¢ç›Š |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **JPEG2000 + LDPC**ï¼šç»å…¸åˆ†ç¦»å¼ç¼–è§£ç æ–¹æ¡ˆã€‚
2. **DeepJSCC**ï¼šç«¯åˆ°ç«¯è”åˆä¿¡æºä¿¡é“ç¼–ç ã€‚
3. **CDDM**ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆå¼è§£ç å™¨ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ DIV2K åœ¨ AWGN, SNR=20dB ä¸ºä¾‹ï¼‰
| æ–¹æ³• | PSNR (dB) | MS-SSIM | LPIPS |
|------|-----------|---------|-------|
| **LTT (Ours)** | **36.7** | **24.9** | **0.061** |
| CDDM | ~28.9 (-26.6%) | ~16.2 (-53.2%) | â€” |
| DeepJSCC | ~28.6 (-28.3%) | ~15.6 (-59.6%) | â€” |
| JPEG2000+LDPC | ~31.5 (-16.9%) | ~20.0 (-24.9%) | â€” |

> æ³¨ï¼šæ–‡ä¸­æœªç›´æ¥ç»™å‡º 20dB çš„è¡¨æ ¼å€¼ï¼Œä½†ä» Fig. 4 æ¨ç®—å¾—å‡ºä¸Šè¿°è¶‹åŠ¿ã€‚

åœ¨ **SNR=15dB** ä¸‹ï¼ˆè§ Table IIï¼‰ï¼š
- **AWGN**: PSNR = 33.83 dB, MS-SSIM = 20.20 dB
- **Rayleigh**: PSNR = 31.92 dB
- **MIMO**: PSNR = 33.41 dB

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨æ‰€æœ‰ä¿¡é“å’Œæ•°æ®é›†ä¸Šï¼ŒLTT å‡æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼š
  - ç›¸æ¯” **CDDM** å’Œ **DeepJSCC**ï¼ŒPSNR æå‡çº¦ **25â€“30%**ï¼ŒMS-SSIM æå‡è¶… **50%**ã€‚
  - ç›¸æ¯” **JPEG2000+LDPC**ï¼Œæ—  cliff effectï¼Œä½ SNR ä¸‹ä»å¯è§£ç ï¼Œé«˜ SNR ä¸‹ä»æœ‰æ˜æ˜¾å¢ç›Šï¼ˆPSNR +16.9%, MS-SSIM +24.9% @ AWGNï¼‰ã€‚
- è§†è§‰æ•ˆæœæ›´ä¼˜ï¼šè¾¹ç¼˜æ›´é”åˆ©ã€çº¹ç†æ›´æ¸…æ™°ã€å‡ ä½•ç»“æ„æ›´å¿ å®ï¼ˆè§ Fig. 5ï¼‰ã€‚

---

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰ODE æ­¥æ•°å½±å“ï¼ˆTable Vï¼‰
| æ­¥æ•° | PSNR (dB) | MS-SSIM | å•æ ·æœ¬æ¨ç†æ—¶é—´ (s) |
|------|-----------|---------|---------------------|
| 2 | 30.30 | 16.83 | 0.18 |
| 5 | 30.12 | 16.62 | 0.29 |
| **10** | **30.52** | **16.60** | **0.46** |
| 20 | 30.10 | 16.58 | 0.78 |
| 50 | 30.19 | 16.53 | 1.80 |

- **ä»…éœ€ 10 æ­¥å³å¯è¾¾åˆ°æœ€ä½³æ€§èƒ½**ï¼Œæ›´å¤šæ­¥æ•°å¸¦æ¥è¾¹é™…æ”¶ç›Šé€’å‡ã€‚
- æ¨ç†æ—¶é—´éšæ­¥æ•°çº¿æ€§å¢é•¿ï¼Œ10 æ­¥ä¸ºç²¾åº¦ä¸æ•ˆç‡çš„æœ€ä½³å¹³è¡¡ç‚¹ã€‚

#### ï¼ˆ2ï¼‰å™ªå£°è°ƒåº¦åˆ†æï¼ˆTable VIï¼‰
| SNR (dB) | 0 | 3 | 5 | 10 | 15 |
|----------|----|----|----|-----|-----|
| $t^*$ | 0.463 | 0.328 | 0.261 | 0.147 | 0.082 |

- $t^*$ éš SNR å•è°ƒå¢åŠ ï¼š**SNR è¶Šé«˜ï¼Œç€é™†ç‚¹è¶Šæ¥è¿‘å¹²å‡€ç«¯**ï¼Œç§¯åˆ†åŒºé—´è¶ŠçŸ­ã€‚
- è¡¨æ˜ $t^*$ å¯ä½œä¸ºä¿¡é“æ¡ä»¶ä¸ç”ŸæˆåŠ¨åŠ›å­¦ä¹‹é—´çš„**å¯è§£é‡Šæ¡¥æ¢**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LTT èŒƒå¼æˆåŠŸå°†ç‰©ç†ä¿¡é“èå…¥ç”Ÿæˆæµ**ï¼Œå®ç°äº†â€œä¿¡é“å³ç”Ÿæˆè·¯å¾„ä¸€éƒ¨åˆ†â€çš„ç†å¿µã€‚
2. åŸºäº **CFM çš„ç¡®å®šæ€§ ODE è§£ç å™¨**å¯åœ¨ **10 æ­¥å†…å®Œæˆé«˜è´¨é‡é‡å»º**ï¼Œæ˜¾è‘—é™ä½å»¶è¿Ÿã€‚
3. é€šè¿‡ **MMSE+SVD é¢„å¤„ç†**ï¼ŒAWGN è®­ç»ƒçš„æ¨¡å‹å¯æ— ç¼è¿ç§»è‡³ Rayleigh å’Œ MIMO ä¿¡é“ï¼Œå…·å¤‡å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚
4. åœ¨å¤šä¸ªæ•°æ®é›†å’Œä¿¡é“æ¡ä»¶ä¸‹ï¼ŒLTT åœ¨ **PSNRã€MS-SSIMã€LPIPS** ä¸Šå…¨é¢è¶…è¶Šä¸»æµåŸºçº¿ï¼Œå°¤å…¶åœ¨æ„ŸçŸ¥è´¨é‡ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¡†æ¶ä¾èµ–äºä¿¡é“å¯è¢«è½¬åŒ–ä¸º AWGN ç­‰æ•ˆå½¢å¼ï¼ˆé€‚ç”¨äºçº¿æ€§é«˜æ–¯ä¿¡é“ï¼‰ï¼Œå¯¹éçº¿æ€§æˆ–ä¸¥é‡éé«˜æ–¯å¹²æ‰°çš„æ‰©å±•å°šä¸æ˜ç¡®ã€‚
- è™½ç„¶ ODE æ­¥æ•°å°‘ï¼Œä½†ä»éœ€æ•°å€¼æ±‚è§£ï¼Œç›¸æ¯” DeepJSCC çš„å•æ¬¡å‰ä¼ ç•¥æœ‰å¼€é”€ã€‚
- æ¨¡å‹å®¹é‡ä»è¾ƒå¤§ï¼ˆU-Netï¼‰ï¼Œåœ¨æç«¯èµ„æºå—é™è®¾å¤‡éƒ¨ç½²å¯èƒ½å—é™ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **è¯­ä¹‰é€šä¿¡** åœºæ™¯ï¼Œç»“åˆè¯­ä¹‰å…ˆéªŒè¿›ä¸€æ­¥å‹ç¼©ä¼ è¾“ä¿¡æ¯ã€‚
- æ¢ç´¢ **ä¸€è‡´æ€§æ¨¡å‹**ï¼ˆConsistency Modelsï¼‰æ›¿ä»£ ODE æ±‚è§£ï¼Œå®ç°ä¸€æ­¥ç”Ÿæˆã€‚
- æ”¯æŒ **åŠ¨æ€å¸¦å®½è°ƒæ•´** å’Œ **å¤šç”¨æˆ· MIMO** åœºæ™¯ä¸‹çš„è‡ªé€‚åº”ä¼ è¾“ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ–ç½‘ç»œç»“æ„ï¼Œæå‡è½»é‡åŒ–ä¸éƒ¨ç½²æ•ˆç‡ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºçš„ **LTT æ¡†æ¶**é€šè¿‡å°†æ— çº¿ä¿¡é“åµŒå…¥ Flow Matching çš„æ¦‚ç‡æµä¸­ï¼Œæ„å»ºäº†ä¸€ä¸ª**ç¡®å®šæ€§ã€ä½å»¶è¿Ÿã€è·¨ä¿¡é“é€šç”¨**çš„ç”Ÿæˆå¼å›¾åƒè§£ç å™¨ï¼Œåœ¨ä¿æŒé«˜æ„ŸçŸ¥è´¨é‡çš„åŒæ—¶ï¼Œè§£å†³äº†ä¼ ç»Ÿæ‰©æ•£æ¨¡å‹åœ¨é€šä¿¡ç³»ç»Ÿä¸­çš„é«˜å»¶è¿Ÿç“¶é¢ˆã€‚

</details>

---

### 14. [Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference](https://arxiv.org/abs/2601.07667)

**Authors**: Rei Taniguchi, Yuyang Dong, Makoto Onizuka, Chuan Xiao  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.07667v1  

#### Abstract
Due to the prevalence of large language models (LLMs), key-value (KV) cache reduction for LLM inference has received remarkable attention. Among numerous works that have been proposed in recent years, layer-wise token pruning approaches, which select a subset of tokens at particular layers to retain...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAdaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **layer-wise token pruning** æ–¹æ³•åœ¨è¿›è¡Œ **KV cache reduction** æ—¶ï¼Œé€šå¸¸é‡‡ç”¨é¢„å®šä¹‰çš„å›ºå®šå±‚ï¼ˆç§°ä¸º *selection layer*ï¼‰æ¥é€‰æ‹©ä¿ç•™çš„ tokensã€‚è¿™ç§è®¾è®¡å­˜åœ¨æ˜¾è‘—ç¼ºé™·ï¼š
- **ä»»åŠ¡ä¸æ„ŸçŸ¥ï¼ˆtask-agnosticï¼‰**ï¼šä¸åŒä»»åŠ¡å¯¹è¯­ä¹‰ç†è§£çš„æ·±åº¦éœ€æ±‚ä¸åŒï¼Œç®€å•ä»»åŠ¡ï¼ˆå¦‚ QAï¼‰å¯èƒ½æ—©æœŸå³å¯å®šä½å…³é”®ä¿¡æ¯ï¼Œè€Œå¤æ‚ä»»åŠ¡ï¼ˆå¦‚ KV retrievalï¼‰éœ€è¦æ›´æ·±å±‚æ‰èƒ½èšç„¦ã€‚
- **æ€§èƒ½æ³¢åŠ¨å¤§**ï¼šåœ¨å›°éš¾ä»»åŠ¡ä¸Šï¼Œè¿‡æ—©çš„ token selection ä¼šå¯¼è‡´å…³é”®ä¿¡æ¯ä¸¢å¤±ï¼Œä¸¥é‡æŸå®³ accuracyï¼›ä¸ºä¿è¯æ€§èƒ½ï¼Œåªèƒ½æ¨è¿Ÿ selection layer æˆ–å¢åŠ  KV budgetï¼Œç‰ºç‰²å†…å­˜æ•ˆç‡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šASL (Adaptive Selection Layer)
æœ¬æ–‡æå‡º **ASL**ï¼Œä¸€ç§æ— éœ€è®­ç»ƒã€ä»»åŠ¡æ„ŸçŸ¥çš„è‡ªé€‚åº”å±‚é€‰æ‹©æ–¹æ³•ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **ç›‘æ§æ³¨æ„åŠ›å¾—åˆ†æ’åºçš„æ–¹å·®ï¼ˆvariance of token ranksï¼‰**ï¼šåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œè®¡ç®—è¿ç»­è‹¥å¹²å±‚ä¸­ tokens æŒ‰æ³¨æ„åŠ›å¾—åˆ†æ’åºåçš„æ’åæ–¹å·®ã€‚
- **åŠ¨æ€ç¡®å®š selection layer**ï¼šå½“è¯¥æ–¹å·®ä½äºä¸€ä¸ªç”¨æˆ·æŒ‡å®šçš„é˜ˆå€¼ `T` æ—¶ï¼Œè¡¨æ˜æ³¨æ„åŠ›å·²ç¨³å®šèšç„¦äºä¸€å°éƒ¨åˆ† tokensï¼Œæ­¤æ—¶å³ä¸ºæ‰§è¡Œ token selection çš„æœ€ä½³æ—¶æœºã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **ä»»åŠ¡è‡ªé€‚åº”æ€§å¼º**ï¼šèƒ½æ ¹æ®ä¸åŒä»»åŠ¡çš„éš¾åº¦è‡ªåŠ¨è°ƒæ•´ selection layerï¼Œç®€å•ä»»åŠ¡é€‰æµ…å±‚ä»¥æå‡é€Ÿåº¦ï¼Œå›°éš¾ä»»åŠ¡é€‰æ·±å±‚ä»¥ä¿è¯ç²¾åº¦ã€‚
- **ç²¾åº¦æ›´é«˜**ï¼šåœ¨å›°éš¾ä»»åŠ¡ï¼ˆå¦‚ KV retrieval, multi-key NIAHï¼‰ä¸Šæ˜¾è‘—ä¼˜äºå›ºå®š selection layer çš„æ–¹æ³•ï¼ˆå¦‚ FastKV, GemFilterï¼‰ã€‚
- **çµæ´»æ€§é«˜**ï¼šå¯åœ¨ **prefilling é˜¶æ®µ**è¿è¡Œï¼Œå¹¶å¯æ— ç¼é›†æˆç°æœ‰æ–¹æ³•ï¼ˆå¦‚ä¸ SnapKV ç»“åˆä¼˜åŒ– decodingï¼Œä¸ GemFilter ç»“åˆå®ç° two-pass ç­–ç•¥ï¼‰ã€‚
- **å¼€é”€å°**ï¼šä»…éœ€å­˜å‚¨å°‘é‡æœ€è¿‘å‡ å±‚çš„ pooled attention scoresï¼Œå³°å€¼å†…å­˜å’Œè®¡ç®—å¼€é”€æä½ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
åœ¨ä¸‰ä¸ªé•¿ä¸Šä¸‹æ–‡åŸºå‡†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼š
- **InfiniteBench**ï¼šå¹³å‡ä¸Šä¸‹æ–‡é•¿åº¦çº¦ 214kï¼ŒåŒ…å« 10 ä¸ªå¤šæ ·åŒ–ä»»åŠ¡ï¼ˆå¦‚æ‘˜è¦ã€é—®ç­”ã€ä»£ç è°ƒè¯•ã€KV æ£€ç´¢ç­‰ï¼‰ã€‚
- **RULER**ï¼šåˆæˆåŸºå‡†ï¼Œæ”¯æŒé…ç½®ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆ4k åˆ° 128kï¼‰ï¼ŒåŒ…å« 13 ä¸ªä»»åŠ¡ï¼Œæ¶µç›– NIAHï¼ˆNeedle in a Haystackï¼‰å˜ä½“ã€è¯é¢‘ç»Ÿè®¡ã€å˜é‡è¿½è¸ªç­‰ã€‚
- **NIAH (Needle in a Haystack)**ï¼šç»å…¸æ£€ç´¢èƒ½åŠ›æµ‹è¯•ï¼Œä¸Šä¸‹æ–‡é•¿åº¦ä» 1k æ‰©å±•åˆ° 256kã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼š
  - `Llama-3.1-8B-UL` (32 layers)
  - `Qwen2.5-7B` (28 layers)
- **KV Budget**ï¼šé»˜è®¤ä¸º 2048ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Accuracy (%)**ï¼šä»»åŠ¡æ­£ç¡®ç‡ã€‚
  - **TTFT (Time to First Token)**ï¼šè¡¡é‡ prefilling æ•ˆç‡ã€‚
  - **TPOT (Time Per Output Token)**ï¼šè¡¡é‡ decoding æ•ˆç‡ã€‚
  - **Throughput**ï¼šååé‡ï¼ˆqueries/sï¼‰ã€‚
  - **Memory Usage**ï¼šæ˜¾å­˜å ç”¨ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **SnapKV**ï¼šåŸºäºå¯å‘å¼çš„ KV cache å‹ç¼©ï¼Œä¸ä¼˜åŒ– TTFTã€‚
- **FastKV**ï¼šone-shot æ–¹æ³•ï¼Œå›ºå®š selection layerï¼ˆLlama-3.1-8B-UL ä¸ºç¬¬ 15 å±‚ï¼‰ã€‚
- **GemFilter**ï¼štwo-pass æ–¹æ³•ï¼Œå›ºå®š selection layerï¼ˆLlama-3.1-8B-UL ä¸ºç¬¬ 13 å±‚ï¼‰ã€‚
- **PyramidInfer**ï¼šæ¸è¿›å¼ token pruning æ–¹æ³•ã€‚

æœ¬æ–‡æå‡ºçš„ ASL åŒ…å«ä¸¤ç§å˜ä½“ï¼š
- **ASL**ï¼šone-pass æ–¹æ¡ˆï¼Œä¸ SnapKV ç»“åˆã€‚
- **ASL_2pass**ï¼štwo-pass æ–¹æ¡ˆï¼Œä¸ GemFilter ç»“åˆã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ

#### åœ¨ InfiniteBench ä¸Šçš„å‡†ç¡®æ€§
- å¯¹äº `Llama-3.1-8B-UL`ï¼Œ**ASL_2pass** åœ¨ KV budget=2048 ä¸‹å–å¾—äº†æœ€é«˜çš„å¹³å‡å‡†ç¡®ç‡ (**37.8%**)ï¼Œä¼˜äº FastKV (36.4%) å’Œ GemFilter (37.0%)ã€‚
- å½“ pre-selection ä½¿ç”¨ full KV æ—¶ï¼Œ**ASL** åœ¨å›°éš¾ä»»åŠ¡ï¼ˆå¦‚ `kv_retrieval`ï¼‰ä¸Šçš„è¡¨ç°æ¥è¿‘ full KVï¼Œè€Œ FastKV æ€§èƒ½å¤§å¹…ä¸‹é™ï¼ˆASL: 15.4% vs FastKV: 3.2%ï¼‰ã€‚

#### åœ¨ RULER ä¸Šçš„å‡†ç¡®æ€§
- å¯¹äº `Llama-3.1-8B-UL`ï¼Œ**ASL** åœ¨æ‰€æœ‰ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹å‡ä¼˜äº FastKVã€‚
- å¯¹äº `Qwen2.5-7B`ï¼Œå½“ä¸Šä¸‹æ–‡é•¿åº¦ â‰¥16k æ—¶ï¼Œ**ASL** æ˜¾è‘—ä¼˜äº FastKVï¼Œä¸”ä¼˜åŠ¿éšé•¿åº¦å¢åŠ è€Œæ‰©å¤§ã€‚
- åœ¨ 128k ä¸Šä¸‹æ–‡ä¸‹ï¼Œ**ASL** å¹³å‡å‡†ç¡®ç‡ä¸º **66.4%**ï¼Œé«˜äº FastKV (59.1%) å’Œ GemFilter (56.7%)ã€‚

#### åœ¨ NIAH ä¸Šçš„è¡¨ç°
- **ASL** å’Œ **ASL_2pass** åœ¨æ‰€æœ‰ä¸Šä¸‹æ–‡é•¿åº¦ä¸Šå‡è¾¾åˆ° **100%** å‡†ç¡®ç‡ï¼Œä¸ full KV ç›¸å½“ã€‚
- SnapKV å’Œ FastKV åœ¨ 148k é•¿åº¦æ—¶å‡ ä¹æ— æ³•æ£€ç´¢åˆ° needleã€‚
- GemFilter è¡¨ç°å¹³åº¸ï¼Œå°¤å…¶åœ¨é•¿ä¸Šä¸‹æ–‡ä¸‹ã€‚

#### æ•ˆç‡æŒ‡æ ‡ (RULER, 128k)
| æ–¹æ³• | TTFT (ç›¸å¯¹å€¼) | TPOT (ç›¸å¯¹å€¼) | Throughput (mean) |
| :--- | :--- | :--- | :--- |
| **FastKV** | 0.50 | 0.27 | 3.07 |
| **ASL** | 0.79 | 0.28 | 2.27 |
| **GemFilter** | 0.44 | 0.25 | 2.36 |

- **ASL çš„ TTFT è¾ƒé«˜**ï¼šå› å…¶ selection layer é€šå¸¸æ›´æ·±ï¼ˆå¹³å‡ L=23.9 vs FastKV çš„ L=15ï¼‰ï¼Œprefilling æ—¶é—´æ›´é•¿ã€‚
- **ASL çš„ TPOT ä¸åŸºçº¿ç›¸å½“**ï¼šè§£ç é˜¶æ®µæ•ˆç‡ç›¸è¿‘ã€‚
- **Throughput**ï¼šASL çº¦ä¸º FastKV çš„ 74%ï¼Œä½†è€ƒè™‘åˆ°å¤§å¤šæ•°å®é™…åº”ç”¨ä¸­è¾“å‡º token æ•°è¿œå¤šäºè¾“å…¥ï¼Œè§£ç æ—¶é—´å ä¸»å¯¼ï¼Œå®é™…å·®è·ä¼šç¼©å°ã€‚

#### å†…å­˜ä½¿ç”¨
- æ‰€æœ‰ KV cache reduction æ–¹æ³•ï¼ˆåŒ…æ‹¬ ASLï¼‰çš„å†…å­˜ä½¿ç”¨å‡ ä¹ç›¸åŒï¼ˆçº¦ 0.3GB for Llama-3.1-8B-ULï¼‰ï¼Œè¿œä½äº full KV (17.1GB)ï¼Œè¯æ˜ ASL çš„é¢å¤–å¼€é”€å¯å¿½ç•¥ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **ç›¸å¯¹æ–¹å·®é˜ˆå€¼ `T` çš„å½±å“**ï¼ˆTable 9ï¼‰ï¼š
  - `T=0.3` æ˜¯ç²¾åº¦ä¸ TTFT çš„è‰¯å¥½æƒè¡¡ç‚¹ã€‚
  - `T` è¶Šå°ï¼ˆè¦æ±‚æ–¹å·®æ›´ä½ï¼‰ï¼Œselection layer è¶Šæ·±ï¼Œaccuracy æ›´é«˜ä½† TTFT æ›´é•¿ã€‚
  - `T` è¶Šå¤§ï¼Œselection layer è¶Šæ—©ï¼ŒTTFT æ›´çŸ­ä½† accuracy å¯èƒ½ä¸‹é™ï¼Œå°¤å…¶åœ¨å›°éš¾ä»»åŠ¡ä¸Šã€‚
- **Lmin å’Œ Lobs çš„é€‰æ‹©**ï¼ˆAppendix D.2ï¼‰ï¼š
  - æ¨è `Lmin â‰ˆ L_model / 3`ï¼ˆå¦‚ Llama-3.1-8B-UL ç”¨ 10ï¼‰ã€‚
  - `Lobs=8` èƒ½æœ‰æ•ˆå¹³è¡¡æ•æ„Ÿæ€§å’Œç¨³å®šæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å›ºå®š selection layer æ˜¯ç°æœ‰æ–¹æ³•çš„ç“¶é¢ˆ**ï¼šå…¶æ€§èƒ½é«˜åº¦ä¾èµ–ä»»åŠ¡éš¾åº¦ï¼Œåœ¨å›°éš¾ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ã€‚
2. **æ³¨æ„åŠ›å¾—åˆ†æ’åºçš„æ–¹å·®æ˜¯æœ‰æ•ˆçš„è‡ªé€‚åº”ä¿¡å·**ï¼šå½“æ–¹å·®é™ä½æ—¶ï¼Œè¡¨æ˜æ¨¡å‹å·²ç¨³å®šèšç„¦ï¼Œæ˜¯è¿›è¡Œ token pruning çš„ç†æƒ³æ—¶æœºã€‚
3. **ASL å®ç°äº†æ›´å¥½çš„ç²¾åº¦-æ•ˆç‡æƒè¡¡**ï¼šé€šè¿‡è‡ªé€‚åº”é€‰æ‹©ï¼ŒASL åœ¨ä¿æŒä¸åŸºçº¿æ–¹æ³•ç›¸è¿‘çš„ decoding é€Ÿåº¦å’Œå†…å­˜å ç”¨çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº† accuracyï¼Œå°¤å…¶æ˜¯åœ¨é•¿ä¸Šä¸‹æ–‡å’Œå›°éš¾ä»»åŠ¡ä¸Šã€‚
4. **ASL å…·æœ‰è‰¯å¥½çš„å…¼å®¹æ€§**ï¼šå¯ä½œä¸ºé€šç”¨æ¨¡å—ï¼Œä¸ SnapKVã€GemFilter ç­‰æ–¹æ³•ç»“åˆï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–æ•´ä½“æ¨ç†æµç¨‹ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¸»è¦é’ˆå¯¹ one-shot æ–¹æ³•**ï¼šç›®å‰ä»…åº”ç”¨äº FastKV å’Œ GemFilter ç±»å‹çš„æ–¹æ³•ï¼Œå¦‚ä½•å°†å…¶æ‰©å±•åˆ° progressive æˆ– multi-shot æ–¹æ³•ï¼ˆå¦‚ LazyLLMï¼‰å°šå¾…ç ”ç©¶ã€‚
2. **æœªä¸é layer-wise æ–¹æ³•å…¨é¢æ¯”è¾ƒ**ï¼šæ–‡ä¸­æœªä¸é‡åŒ–ï¼ˆquantizationï¼‰ã€CPU å¸è½½ï¼ˆoffloadingï¼‰ç­‰å…¶ä»– KV cache reduction èŒƒå¼è¿›è¡Œæ·±å…¥å¯¹æ¯”ã€‚
3. **æ¨¡å‹è¦†ç›–æœ‰é™**ï¼šä»…åœ¨ä¸¤ä¸ªæ¨¡å‹ä¸ŠéªŒè¯ï¼Œä¸”åœ¨ `Llama-3.1-8B-UL` ä¸Šä¸ GemFilter ç»“åˆæ—¶è¡¨ç°ä¸å¦‚é¢„æœŸã€‚
4. **å¼•å…¥äº†è¶…å‚æ•° `T`**ï¼šè™½ç„¶ `T=0.3` æ˜¯æ¨èå€¼ï¼Œä½†ä»éœ€ç”¨æˆ·æ ¹æ®å…·ä½“åœºæ™¯å¾®è°ƒã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢å°† ASL åº”ç”¨äº progressive token pruning æ–¹æ³•ã€‚
- è®¾è®¡æ›´å¤æ‚çš„è‡ªé€‚åº”ç­–ç•¥ï¼Œä¾‹å¦‚ä½¿ç”¨å¤šä¸ªé˜ˆå€¼æˆ–åŠ¨æ€è¡°å‡çš„é˜ˆå€¼ã€‚
- è¿›è¡Œæ›´å¹¿æ³›çš„æ¨¡å‹å’Œæ–¹æ³•å¯¹æ¯”ï¼Œæ˜ç¡® ASL åœ¨æ•´ä¸ª KV cache reduction é¢†åŸŸä¸­çš„å®šä½ã€‚
- ç ”ç©¶å¦‚ä½•å‡å°‘å¯¹è¶…å‚æ•° `T` çš„ä¾èµ–ï¼Œå®ç°å®Œå…¨è‡ªé€‚åº”ã€‚

</details>

---

### 15. [Learning Minimally-Congested Drive Times from Sparse Open Networks: A Lightweight RF-Based Estimator for Urban Roadway Operations](https://arxiv.org/abs/2601.06124)

**Authors**: Adewumi Augustine Adepitan, Christopher J. Haruna, Morayo Ogunsina, Damilola Olawoyin Yussuf, Ayooluwatomiwa Ajiboye  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.06124v1  

#### Abstract
Accurate roadway travel-time prediction is foundational to transportation systems analysis, yet widespread reliance on either data-intensive congestion models or overly na\"ive heuristics limits scalability and practical adoption in engineering workflows. This paper develops a lightweight estimator ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³**äº¤é€šå·¥ç¨‹é¢†åŸŸä¸­æ—…è¡Œæ—¶é—´é¢„æµ‹æ–¹æ³•åœ¨å‡†ç¡®æ€§ä¸å®ç”¨æ€§ä¹‹é—´çš„é¸¿æ²Ÿ**ã€‚å½“å‰ä¸»æµæ–¹æ³•å­˜åœ¨ä¸¤ä¸ªæç«¯ï¼š
- **æ•°æ®å¯†é›†å‹æ¨¡å‹**ï¼ˆå¦‚åŸºäºå¤§è§„æ¨¡GPSã€ä¼ æ„Ÿå™¨æˆ–æ·±åº¦å­¦ä¹ çš„æ–¹æ³•ï¼‰è™½ç„¶ç²¾åº¦é«˜ï¼ˆMAPEé€šå¸¸ä¸º3%-17%ï¼‰ï¼Œä½†ä¾èµ–æ˜‚è´µæ•°æ®å’Œå¼ºå¤§ç®—åŠ›ï¼Œéš¾ä»¥æ™®åŠï¼›
- **ç®€åŒ–å¯å‘å¼æ–¹æ³•**ï¼ˆå¦‚åŸºäºæ¬§æ°è·ç¦»æˆ–é€Ÿåº¦é™åˆ¶çš„æœ€çŸ­è·¯å¾„ï¼‰è™½æ˜“äºå®æ–½ï¼Œå´å› å¿½ç•¥ä¿¡å·ç¯ã€è½¬å‘å»¶è¯¯ç­‰å› ç´ å¯¼è‡´ç³»ç»Ÿæ€§ä½ä¼°å®é™…æ—…è¡Œæ—¶é—´ï¼ˆMAPE > 20%ï¼‰ã€‚

å› æ­¤ï¼Œç¼ºä¹ä¸€ç§æ—¢å‡†ç¡®åˆè½»é‡ã€é€‚ç”¨äºèµ„æºå—é™åœºæ™¯çš„ä¸­é—´æ–¹æ¡ˆã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§**åŸºäºRandom Forestçš„è½»é‡çº§ä¼°è®¡å™¨ï¼ˆLightweight RF-Based Estimatorï¼‰**ï¼Œç”¨äºé¢„æµ‹åŸå¸‚é“è·¯ç½‘ç»œä¸­çš„æœ€å°æ‹¥å µé©¾é©¶æ—¶é—´ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š
- æ„å»ºä¸€ä¸ª**èåˆå¼€æ”¾è·¯ç½‘æ•°æ®ä¸ç¨€ç–æ§åˆ¶ç‰¹å¾çš„æœºå™¨å­¦ä¹ æ¡†æ¶**ï¼Œä»¥æ ¡æ­£æœ€çŸ­è·¯å¾„éå†æ—¶é—´ï¼ˆ`tnaive`ï¼‰çš„åå·®ï¼›
- åˆ©ç”¨OpenStreetMapç­‰å¼€æºåœ°ç†æ•°æ®æå–å…³é”®æ“ä½œç‰¹å¾ï¼ˆtraffic controls å’Œ turning movementsï¼‰ï¼Œä½œä¸ºæ¨¡å‹è¾“å…¥ï¼›
- åœ¨ä»…éœ€å°‘é‡é«˜è´¨é‡å‚è€ƒæ—¶é—´ï¼ˆreference travel timesï¼‰çš„æƒ…å†µä¸‹è®­ç»ƒå›å½’é›†æˆæ¨¡å‹ï¼Œå®ç°å¯¹æœªè§ODå¯¹çš„æœ‰æ•ˆæ³›åŒ–ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- âœ… **é«˜å‡†ç¡®æ€§**ï¼šæ€§èƒ½æ¥è¿‘state-of-the-artæ–¹æ³•ï¼ˆMAPEé™è‡³8.41%ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿç®€åŒ–æ–¹æ³•ï¼›
- âœ… **ä½èµ„æºéœ€æ±‚**ï¼šä¸ä¾èµ–ä¸“æœ‰æ•°æ®æˆ–å®æ—¶æ‹¥å µæµï¼Œä»…ä½¿ç”¨å…¬å¼€å¯ç”¨æ•°æ®ï¼ˆå¦‚OSMã€Google Maps APIé‡‡æ ·ï¼‰ï¼›
- âœ… **å¯æ‰©å±•æ€§å¼º**ï¼šå¯åœ¨æ ‡å‡†ç¡¬ä»¶ä¸Šè¿›è¡Œå¤§éƒ½å¸‚å°ºåº¦åˆ†æï¼Œæ”¯æŒè§„åˆ’çº§åº”ç”¨ï¼›
- âœ… **é€æ˜å¯å¤ç°**ï¼šå®Œå…¨åŸºäºopen dataå’Œopen-sourceå·¥å…·é“¾ï¼Œæå‡æ–¹æ³•è®ºé€æ˜åº¦ï¼›
- âœ… **å®ç”¨å¯¼å‘**ï¼šç‰¹åˆ«é€‚åˆäºåŸºç¡€è®¾æ–½è¯„ä¼°ã€å¯è¾¾æ€§åˆ†æã€åº”æ€¥å“åº”ç­‰ä½æµé‡è¿è¡Œæ¡ä»¶ä¸‹çš„å·¥ç¨‹åº”ç”¨åœºæ™¯ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
| æ•°æ®æ¥æº | å†…å®¹è¯´æ˜ |
|--------|-------|
| **OpenStreetMap (OSM)** | ä½¿ç”¨OSMnxæå–æ´›æ‰çŸ¶åŸåŒºé“è·¯ç½‘ç»œï¼Œä¿ç•™å¼ºè¿é€šåˆ†é‡ï¼›åŒ…å«63,359ä¸ªæ ‡æ³¨çš„äº¤é€šæ§åˆ¶å…ƒç´ ï¼ˆstop signs, traffic signals, crossingsç­‰ï¼‰ |
| **Uber Movement æ•°æ®** | ç”¨äºç­›é€‰çœŸå®å­˜åœ¨çš„ODå¯¹ï¼Œç¡®ä¿ç”Ÿæˆçš„èµ·ç‚¹-ç»ˆç‚¹ç»„åˆå…·æœ‰ç°å®æ„ä¹‰ |
| **Google Maps Routes API** | è·å–å‚è€ƒæ—…è¡Œæ—¶é—´ï¼ˆresponse variableï¼‰ï¼Œé‡‡ç”¨ `"BEST_GUESS"` æ¨¡å‹åœ¨å‡Œæ™¨3:00 AMè°ƒç”¨ï¼Œæ¨¡æ‹Ÿæœ€å°æ‹¥å µçŠ¶æ€ï¼›å…±æˆåŠŸè·å–41,360æ¡æœ‰æ•ˆè®°å½• |

### å®éªŒè®¾ç½®
- **ç ”ç©¶åŒºåŸŸ**ï¼šæ´›æ‰çŸ¶å¿åŠå‘¨è¾¹åŸå¸‚åŒ–æ ¸å¿ƒåŒºï¼ˆåŸºäºGlobal Human Settlement Layerç•Œå®šï¼‰
- **ODæ ·æœ¬ç”Ÿæˆ**ï¼šä»500ä¸‡éšæœºèŠ‚ç‚¹å¯¹ä¸­ï¼Œé€šè¿‡Uberæ•°æ®è¿‡æ»¤å‡ºç¬¦åˆçœŸå®å‡ºè¡Œæ¨¡å¼çš„41,378ä¸ªODå¯¹
- **ç‰¹å¾å·¥ç¨‹**ï¼š
  - **Baselineç‰¹å¾**ï¼š`tnaive` â€”â€” åŸºäºDijkstraç®—æ³•è®¡ç®—çš„é€Ÿåº¦é™åˆ¶åŠ æƒæœ€çŸ­è·¯å¾„æ—¶é—´
  - **Traffic Control ç‰¹å¾**ï¼ˆ5ç±»è®¡æ•°ï¼‰ï¼šstop signs, traffic signals, pedestrian crossings, give way signs, mini roundabouts
  - **Turning Movements ç‰¹å¾**ï¼ˆ5ç±»è®¡æ•°ï¼‰ï¼šleft turns, slight left, right turns, slight right, U-turnsï¼ˆstraight movementä½œä¸ºåŸºå‡†ç±»åˆ«çœç•¥ï¼‰
  - æ€»å…±æ„å»º **11ç»´ç‰¹å¾å‘é‡**
- **æ¨¡å‹é€‰æ‹©æµç¨‹**ï¼š
  - å¯¹æ¯”å››ç§ç®—æ³•ï¼šDecision Tree (DT), Random Forest (RF), Gradient Boosting (GB), AdaBoost
  - é‡‡ç”¨80/20è®­ç»ƒæµ‹è¯•åˆ’åˆ† + 5æŠ˜äº¤å‰éªŒè¯
  - è¶…å‚æ•°ä¼˜åŒ–ä½¿ç”¨randomized grid searchï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–MAE

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å…¨ç§° | ç”¨é€” |
|-----|------|-----|
| **MAPE** | Mean Absolute Percentage Error | è¡¡é‡ç›¸å¯¹è¯¯å·® |
| **MAE** | Mean Absolute Error (seconds) | è¡¡é‡ç»å¯¹è¯¯å·® |
| **MSE** | Mean Squared Error | åæ˜ è¯¯å·®æ–¹å·® |
| **Bias (Î´)** | å¹³å‡é¢„æµ‹åå·®ï¼ˆé¢„æµ‹å€¼ - çœŸå®å€¼ï¼‰ | åˆ¤æ–­æ˜¯å¦å­˜åœ¨ç³»ç»Ÿæ€§é«˜ä¼°æˆ–ä½ä¼° |
| **RÂ²** | Explained Variance Score | è¡¡é‡æ¨¡å‹è§£é‡Šèƒ½åŠ› |
| **APR** | Average Pairwise Ratio | é¢„æµ‹/çœŸå®æ—¶é—´å¹³å‡æ¯”ç‡ï¼Œç†æƒ³å€¼ä¸º1 |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Naive Baseline**ï¼šä»…åŸºäºDijkstraæœ€çŸ­è·¯å¾„çš„æ—¶é—´ä¼°è®¡ï¼ˆ`tnaive`ï¼‰
- **å…¶ä»–MLæ¨¡å‹**ï¼šDT, GB, AdaBoost ä½œä¸ºå€™é€‰æ›¿ä»£æ–¹æ¡ˆï¼Œç”¨äºéªŒè¯RFçš„ä¼˜è¶Šæ€§

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆOut-of-Sample Evaluationï¼‰

| Model | MAPE (%) | MAE (s) | Î´ (s) | RÂ² |
|-------|----------|--------|--------|-----|
| Naive TT | 21.2 | 184 | -182.9 | 0.74 |
| **RF (Ours)** | **8.41** | **75** | **+0.38** | **0.93** |
| GB | 7.86 | 72 | -19.2 | 0.93 |
| DT | 9.00 | 80 | +0.13 | 0.93 |
| AdaBoost | 8.20 | 74 | -9.76 | 0.93 |

> æ³¨ï¼šè¡¨æ ¼æ¥è‡ªåŸæ–‡Table 1ï¼Œæ•°å€¼å·²å››èˆäº”å…¥

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- âœ… **MAPEé™ä½è¶…è¿‡60%**ï¼šä»21.2%ä¸‹é™è‡³8.41%ï¼Œè¿›å…¥state-of-the-artèŒƒå›´ï¼ˆ3%-17%ï¼‰
- âœ… **MAEå‡å°‘çº¦60%**ï¼šä»184ç§’é™è‡³75ç§’ï¼Œè¯¯å·®ç¼©å°è¿‘ä¸‰åˆ†ä¹‹äºŒ
- âœ… **MSEä¸‹é™4å€**ï¼šä»48,214é™è‡³12,155 sÂ²ï¼Œè¡¨æ˜æ•´ä½“é¢„æµ‹ç¨³å®šæ€§å¤§å¹…æå‡
- âœ… **æ¶ˆé™¤ç³»ç»Ÿæ€§åå·®**ï¼šNaiveæ–¹æ³•ä¸¥é‡ä½ä¼°ï¼ˆå¹³å‡å°‘183ç§’ï¼‰ï¼Œè€ŒRFæ¨¡å‹æ— æ˜¾è‘—biasï¼ˆÎ´ = +0.38s, p=0.76ï¼‰
- âœ… **APRæ”¹å–„æ˜æ˜¾**ï¼šä»0.79ï¼ˆä½ä¼°21%ï¼‰æå‡è‡³1.01ï¼ˆå‡ ä¹æ— åï¼‰
- âœ… **RÂ²æé«˜è‡³0.93**ï¼šè¯´æ˜æ¨¡å‹èƒ½è§£é‡Š93%çš„æ–¹å·®ï¼Œè¿œé«˜äºbaselineçš„74%

### æ¶ˆèå®éªŒä¸ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆFeature Importanceï¼‰
å°½ç®¡æœªä¸¥æ ¼è®¾è®¡â€œæ¶ˆèå®éªŒâ€ï¼Œä½†é€šè¿‡RFå†…ç½®çš„é‡è¦æ€§è¯„åˆ†æ­ç¤ºäº†å„ç‰¹å¾è´¡çŒ®ï¼š
- **`tnaive`ï¼ˆåŸºç¡€éå†æ—¶é—´ï¼‰**ï¼šè´¡çŒ®çº¦68%çš„RÂ²ï¼Œæ˜¯ä¸»å¯¼å› ç´ ï¼Œè¯æ˜åŸºç¡€ç½‘ç»œç»“æ„ä»è‡³å…³é‡è¦
- **Turning Movements**ï¼šåˆè®¡è´¡çŒ®çº¦19%ï¼Œå…¶ä¸­å·¦è½¬ä¸å³è½¬å½±å“ç›¸å½“ï¼ŒU-turnå› ç½•è§è€Œæƒé‡ä½
- **Traffic Controls**ï¼š
  - **Traffic Signals** æœ€å…·å½±å“åŠ›ï¼Œå…¶æ¬¡ä¸ºStop Signs å’Œ Crossings
  - Roundabouts ä¸ Give Way Signs æƒé‡è¾ƒä½ï¼Œå¯èƒ½å› å…¶åœ¨ç½‘ç»œä¸­åˆ†å¸ƒç¨€ç–æ‰€è‡´

ğŸ‘‰ ç»“è®ºï¼šå³ä½¿æ ‡ç­¾ä¸å®Œæ•´ã€æ•°æ®ç¨€ç–ï¼Œè¿™äº›operational featuresä»æä¾›äº†è¶³å¤Ÿä¿¡å·æ¥æ˜¾è‘—æ”¹è¿›é¢„æµ‹æ•ˆæœã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è½»é‡çº§RFæ¨¡å‹å¯åœ¨ç¨€ç–å¼€æ”¾æ•°æ®ä¸‹å®ç°é«˜æ€§èƒ½æ—…è¡Œæ—¶é—´é¢„æµ‹**ï¼Œåœ¨MAPEã€MAEã€RÂ²ç­‰å¤šä¸ªæŒ‡æ ‡ä¸Šæ˜¾è‘—è¶…è¶Šä¼ ç»Ÿæ–¹æ³•ï¼›
2. **ç»“åˆDijkstra baselineä¸sparse operational featuresï¼ˆä¿¡å·ã€è½¬å‘ï¼‰å¯æœ‰æ•ˆçº æ­£ç³»ç»Ÿæ€§ä½ä¼°é—®é¢˜**ï¼›
3. **Random Foreståœ¨bias-variance trade-offæ–¹é¢è¡¨ç°æœ€ä¼˜**ï¼šç›¸æ¯”GBå’ŒAdaBoostæ›´å°‘å‡ºç°under-prediction biasï¼Œç›¸æ¯”å•æ£µå†³ç­–æ ‘æ›´å…·é²æ£’æ€§ï¼›
4. **æ–¹æ³•å…·å¤‡è‰¯å¥½çš„k-foldç¨³å®šæ€§**ï¼š5æ¬¡CVçš„MAEåˆ†åˆ«ä¸º75.3, 74.5, 73.6, 73.2, 74.7ç§’ï¼Œè¡¨æ˜æ— è¿‡æ‹Ÿåˆï¼›
5. **é€‚ç”¨äºmetropolitan-scaleåˆ†æ**ï¼Œä¸”æ— éœ€ä¸“æœ‰æ•°æ®æˆ–é«˜æ€§èƒ½è®¡ç®—èµ„æºï¼Œé€‚åˆå¹¿æ³›éƒ¨ç½²äºäº¤é€šè§„åˆ’å®è·µã€‚

### æ–¹æ³•çš„å±€é™æ€§
- â— **ä»…é€‚ç”¨äºæœ€å°æ‹¥å µæ¡ä»¶**ï¼ˆfree-flow scenariosï¼‰ï¼šæœªå»ºæ¨¡é«˜å³°æ—¶æ®µçš„åŠ¨æ€æ‹¥å µæ•ˆåº”ï¼Œé¢„æµ‹ç»“æœåœ¨é«˜å³°æœŸå¯èƒ½åä½ï¼›
- â— **ä¾èµ–OSMæ•°æ®è´¨é‡**ï¼šä¸åŒåœ°åŒºtraffic control taggingå®Œæ•´æ€§å·®å¼‚è¾ƒå¤§ï¼Œå¯èƒ½å½±å“è¿ç§»æ€§èƒ½ï¼›
- â— **æ³›åŒ–èƒ½åŠ›æœ‰å¾…éªŒè¯**ï¼šæ¨¡å‹å‚æ•°æ˜¯å¦é€‚ç”¨äºå…¶ä»–åŸå¸‚å°šéœ€è¿›ä¸€æ­¥æµ‹è¯•ï¼›
- â— **æœªæ˜¾å¼å»ºæ¨¡æ—¶é—´å˜åŒ–**ï¼šç¼ºä¹å¯¹æ—¥å‘¨æœŸã€å‘¨æ¨¡å¼ç­‰temporal variationçš„æ”¯æŒï¼›
- â— **è·¯çº¿ä¸åŒ¹é…é—®é¢˜**ï¼šå½“OSMè·¯å¾„ä¸Googleå®é™…æ¨èè·¯å¾„ä¸ä¸€è‡´æ—¶ï¼Œæ¨¡å‹éšå«å‡è®¾ä¸¤è€…delayç‰¹å¾ç›¸ä¼¼ï¼Œå­˜åœ¨ä¸€å®šè¯¯å·®æºã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³å¤šæ—¶æ®µå»ºæ¨¡**ï¼šæ”¶é›†è·¨æ—¶é—´æ®µçš„reference dataï¼ŒåŒºåˆ†peak vs off-peakï¼Œå¼•å…¥ç²—ç²’åº¦æ—¶é—´å˜é‡ï¼›
2. **èåˆæ›´å¤šopen dataæº**ï¼šå¦‚crowdsourced traffic reportsã€public transit schedulesã€weather dataç­‰ï¼Œå¢å¼ºé¢„æµ‹ç»´åº¦ï¼›
3. **ç©ºé—´æ’è¡¥ä¸ç¼ºå¤±æ•°æ®å¤„ç†**ï¼šåˆ©ç”¨spatial statisticsæˆ–MLæ–¹æ³•å¡«è¡¥traffic controlæ ‡ç­¾ç©ºç™½åŒºåŸŸï¼›
4. **Transfer Learning for Regional Calibration**ï¼šåœ¨æ•°æ®ä¸°å¯ŒåŒºåŸŸè®­ç»ƒåï¼Œç”¨å°‘é‡æœ¬åœ°æ ·æœ¬å¾®è°ƒè¿ç§»åˆ°æ–°åŸå¸‚ï¼›
5. **é›†æˆåˆ°real-time routingç³»ç»Ÿ**ï¼šå°†æœ¬æ–¹æ³•ä½œä¸ºaccurate yet lightweight baselineï¼Œé…åˆè½»é‡çº§congestion proxyå®ç°é«˜æ•ˆåŠ¨æ€å¯¼èˆªï¼›
6. **æ¨åŠ¨open & reproducible transportation modeling ecosystem**ï¼šé¼“åŠ±ç¤¾åŒºåä½œæå‡OSMæ•°æ®è´¨é‡å¹¶å…±äº«æ¨¡å‹å‚æ•°ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºRandom Forestçš„è½»é‡çº§æ—…è¡Œæ—¶é—´é¢„æµ‹æ¡†æ¶ï¼Œåœ¨ä»…ä½¿ç”¨OpenStreetMapç­‰å¼€æ”¾æ•°æ®çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†æœ€å°æ‹¥å µæ¡ä»¶ä¸‹åŸå¸‚é©¾é©¶æ—¶é—´ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œå¡«è¡¥äº†é«˜ç²¾åº¦æ¨¡å‹ä¸ç®€åŒ–æ–¹æ³•ä¹‹é—´çš„å®ç”¨ç©ºç™½ï¼Œä¸ºèµ„æºå—é™ç¯å¢ƒä¸‹çš„æ™ºèƒ½äº¤é€šè§„åˆ’æä¾›äº†å¯è¡Œè§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 16. [A Fast and Effective Method for Euclidean Anticlustering: The Assignment-Based-Anticlustering Algorithm](https://arxiv.org/abs/2601.06351)

**Authors**: Philipp Baumann, Olivier Goldschmidt, Dorit S. Hochbaum, Jason Yang  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.06351v1  

#### Abstract
The anticlustering problem is to partition a set of objects into K equal-sized anticlusters such that the sum of distances within anticlusters is maximized. The anticlustering problem is NP-hard. We focus on anticlustering in Euclidean spaces, where the input data is tabular and each object is repre...

---

### 17. [Mosaic: Unlocking Long-Context Inference for Diffusion LLMs via Global Memory Planning and Dynamic Peak Taming](https://arxiv.org/abs/2601.06562)

**Authors**: Liang Zheng, Bowen Shi, Yitao Hu, Jiawei Zhang, Ruofan Li, Sheng Chen, Wenxin Li, Keqiu Li  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.06562v1  

#### Abstract
Diffusion-based large language models (dLLMs) have emerged as a promising paradigm, utilizing simultaneous denoising to enable global planning and iterative refinement. While these capabilities are particularly advantageous for long-context generation, deploying such models faces a prohibitive memor...

---

### 18. [Is Sanskrit the most token-efficient language? A quantitative study using GPT, Gemini, and SentencePiece](https://arxiv.org/abs/2601.06142)

**Authors**: Anshul Kumar  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.06142v1  

#### Abstract
Tokens are the basic units of Large Language Models (LLMs). LLMs rely on tokenizers to segment text into these tokens, and tokenization is the primary determinant of computational and inference cost. Sanskrit, one of the oldest languages, is hypothesized to express more meaning per token due to its ...

---

### 19. [Bringing Computation to the data: Interoperable serverless function execution for astrophysical data analysis in the SRCNet](https://arxiv.org/abs/2601.07308)

**Authors**: Manuel Parra-Roy\'on, Juli\'an Garrido-S\'anchez, Susana S\'anchez-Exp\'osito, Mar\'ia \'Angeles Mendoza, Rob Barnsley, Anthony Moraghan, Jes\'us S\'anchez, Laura Darriba, Carlos Ru\'iz-Monje, Edgar Joao, Javier Mold\'on, Jes\'us Salgado, Lourdes Verdes-Montenegro  
**Category**: cs.DC  
**Published**: 2026-01-13  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.07308v1  

#### Abstract
Serverless computing is a paradigm in which the underlying infrastructure is fully managed by the provider, enabling applications and services to be executed with elastic resource provisioning and minimal operational overhead. A core model within this paradigm is Function-as-a-Service (FaaS), where ...

---

### 20. [TimeGNN-Augmented Hybrid-Action MARL for Fine-Grained Task Partitioning and Energy-Aware Offloading in MEC](https://arxiv.org/abs/2601.06191)

**Authors**: Wei Ai, Yun Peng, Yuntao Shou, Tao Meng, Keqin Li  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.06191v1  

#### Abstract
With the rapid growth of IoT devices and latency-sensitive applications, the demand for both real-time and energy-efficient computing has surged, placing significant pressure on traditional cloud computing architectures. Mobile edge computing (MEC), an emerging paradigm, effectively alleviates the l...

---

### 21. [One-Shot Hierarchical Federated Clustering](https://arxiv.org/abs/2601.06404)

**Authors**: Shenghong Cai, Zihua Yang, Yang Lu, Mengke Li, Yuzhu Ji, Yiqun Zhang, Yiu-Ming Cheung  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.06404v1  

#### Abstract
Driven by the growth of Web-scale decentralized services, Federated Clustering (FC) aims to extract knowledge from heterogeneous clients in an unsupervised manner while preserving the clients' privacy, which has emerged as a significant challenge due to the lack of label guidance and the Non-Indepen...

---

### 22. [ArenaRL: Scaling RL for Open-Ended Agents via Tournament-based Relative Ranking](https://arxiv.org/abs/2601.06487)

**Authors**: Qiang Zhang, Boli Chen, Fanrui Zhang, Ruixue Ding, Shihang Wang, Qiuchen Wang, Yinfeng Huang, Haonan Zhang, Rongxiang Zhu, Pengyong Wang, Ailin Ren, Xin Li, Pengjun Xie, Jiawei Liu, Ning Guo, Jingren Zhou, Zheng-Jun Zha  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.06487v1  

#### Abstract
Reinforcement learning has substantially improved the performance of LLM agents on tasks with verifiable outcomes, but it still struggles on open-ended agent tasks with vast solution spaces (e.g., complex travel planning). Due to the absence of objective ground-truth for these tasks, current RL algo...

---

### 23. [PRPO: Aligning Process Reward with Outcome Reward in Policy Optimization](https://arxiv.org/abs/2601.07182)

**Authors**: Ruiyi Ding, Yongxuan Lv, Xianhui Meng, Jiahe Song, Chao Wang, Chen Jiang, Yuan Cheng  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.07182v1  

#### Abstract
Policy optimization for large language models often suffers from sparse reward signals in multi-step reasoning tasks. Critic-free methods like GRPO assign a single normalized outcome reward to all tokens, providing limited guidance for intermediate reasoning . While Process Reward Models (PRMs) offe...

---

### 24. [Overcoming Joint Intractability with Lossless Hierarchical Speculative Decoding](https://arxiv.org/abs/2601.05724)

**Authors**: Yuxuan Zhou, Fei Huang, Heng Li, Fengyi Wu, Tianyu Wang, Jianwei Zhang, Junyang Lin, Zhi-Qi Cheng  
**Category**: cs.AI  
**Published**: 2026-01-13  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.05724v1  

#### Abstract
Verification is a key bottleneck in improving inference speed while maintaining distribution fidelity in Speculative Decoding. Recent work has shown that sequence-level verification leads to a higher number of accepted tokens compared to token-wise verification. However, existing solutions often rel...

---

### 25. [TeleMem: Building Long-Term and Multimodal Memory for Agentic AI](https://arxiv.org/abs/2601.06037)

**Authors**: Chunliang Chen, Ming Guan, Xiao Lin, Jiaxu Li, Qiyi Wang, Xiangyu Chen, Jixiang Luo, Changzhi Sun, Dell Zhang, Xuelong Li  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.06037v1  

#### Abstract
Large language models (LLMs) excel at many NLP tasks but struggle to sustain long-term interactions due to limited attention over extended dialogue histories. Retrieval-augmented generation (RAG) mitigates this issue but lacks reliable mechanisms for updating or refining stored memories, leading to ...

---

### 26. [Value of Information: A Framework for Human-Agent Communication](https://arxiv.org/abs/2601.06407)

**Authors**: Yijiang River Dong, Tiancheng Hu, Zheng Hui, Caiqi Zhang, Ivan Vuli\'c, Andreea Bobu, Nigel Collier  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.06407v1  

#### Abstract
Large Language Model (LLM) agents deployed for real-world tasks face a fundamental dilemma: user requests are underspecified, yet agents must decide whether to act on incomplete information or interrupt users for clarification. Existing approaches either rely on brittle confidence thresholds that re...

---

### 27. [Solar Open Technical Report](https://arxiv.org/abs/2601.07022)

**Authors**: Sungrae Park, Sanghoon Kim, Jungho Cho, Gyoungjin Gim, Dawoon Jung, Mikyoung Cha, Eunhae Choo, Taekgyu Hong, Minbyul Jeong, SeHwan Joo, Minsoo Khang, Eunwon Kim, Minjeong Kim, Sujeong Kim, Yunsu Kim, Hyeonju Lee, Seunghyun Lee, Sukyung Lee, Siyoung Park, Gyungin Shin, Inseo Song, Wonho Song, Seonghoon Yang, Seungyoun Yi, Sanghoon Yoon, Jeonghyun Ko, Seyoung Song, Keunwoo Choi, Hwalsuk Lee, Sunghun Kim, Du-Seong Chang, Kyunghyun Cho, Junsuk Choe, Hwaran Lee, Jae-Gil Lee, KyungTae Lim, Alice Oh  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.07022v1  

#### Abstract
We introduce Solar Open, a 102B-parameter bilingual Mixture-of-Experts language model for underserved languages. Solar Open demonstrates a systematic methodology for building competitive LLMs by addressing three interconnected challenges. First, to train effectively despite data scarcity for underse...

---

### 28. [Document-Level Zero-Shot Relation Extraction with Entity Side Information](https://arxiv.org/abs/2601.07271)

**Authors**: Mohan Raj Chanthran, Soon Lay Ki, Ong Huey Fang, Bhawani Selvaretnam  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.07271v1  

#### Abstract
Document-Level Zero-Shot Relation Extraction (DocZSRE) aims to predict unseen relation labels in text documents without prior training on specific relations. Existing approaches rely on Large Language Models (LLMs) to generate synthetic data for unseen labels, which poses challenges for low-resource...

---

### 29. [PlaM: Training-Free Plateau-Guided Model Merging for Better Visual Grounding in MLLMs](https://arxiv.org/abs/2601.07645)

**Authors**: Zijing Wang, Yongkang Liu, Mingyang Wang, Ercong Nie, Deyuan Chen, Zhengjie Zhao, Shi Feng, Daling Wang, Xiaocui Yang, Yifei Zhang, Hinrich Sch\"utze  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.07645v1  

#### Abstract
Multimodal Large Language Models (MLLMs) rely on strong linguistic reasoning inherited from their base language models. However, multimodal instruction fine-tuning paradoxically degrades this text's reasoning capability, undermining multimodal performance. To address this issue, we propose a trainin...

---

### 30. [Employ SmartNICs' Data Path Accelerators for Ordered Key-Value Stores](https://arxiv.org/abs/2601.06231)

**Authors**: Frederic Schimmelpfennig, Jan Sass, Reza Salkhordeh, Martin Kr\"oning, Stefan Lankes, Andr\'e Brinkmann  
**Category**: cs.DC  
**Published**: 2026-01-13  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.06231v1  

#### Abstract
Remote in-memory key-value (KV) stores serve as a cornerstone for diverse modern workloads, and high-speed range scans are frequently a requirement. However, current architectures rarely achieve a simultaneous balance of peak efficiency, architectural simplicity, and native support for ordered opera...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
