# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-15 05:58:03 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [xGR: Efficient Generative Recommendation Serving at Scale](https://arxiv.org/abs/2512.11529)

**Authors**: Qingxiao Sun, Tongxuan Liu, Shen Zhang, Siyu Wu, Peijun Yang, Haotian Liang, Menxin Li, Xiaolong Ma, Zhiwei Liang, Ziyi Ren, Minchao Zhang, Xinyu Liu, Ke Zhang, Depei Qian, Hailong Yang  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.11529v1  

#### Abstract
Recommendation system delivers substantial economic benefits by providing personalized predictions. Generative recommendation (GR) integrates LLMs to enhance the understanding of long user-item sequences. Despite employing attention-based architectures, GR's workload differs markedly from that of LL...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šxGR: Efficient Generative Recommendation Serving at Scale

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**ç”Ÿæˆå¼æ¨èç³»ç»Ÿï¼ˆGenerative Recommendation, GRï¼‰åœ¨é«˜å¹¶å‘ã€ä½å»¶è¿Ÿåœºæ™¯ä¸‹çš„æ¨ç†æœåŠ¡ç“¶é¢ˆ**æå‡ºäº†ç³»ç»Ÿæ€§çš„ä¼˜åŒ–æ–¹æ¡ˆã€‚å°½ç®¡GRå€Ÿé‰´äº†LLMçš„æ¶æ„ï¼ˆå¦‚Transformerï¼‰ï¼Œä½†å…¶å·¥ä½œè´Ÿè½½ç‰¹æ€§ä¸ä¼ ç»ŸLLMæœ‰æ˜¾è‘—å·®å¼‚ï¼Œå¯¼è‡´ç›´æ¥é‡‡ç”¨ç°æœ‰çš„LLMæ¨ç†å¼•æ“ï¼ˆå¦‚vLLMï¼‰æ•ˆç‡ä½ä¸‹ã€‚

å…·ä½“æŒ‘æˆ˜åŒ…æ‹¬ï¼š
- **é•¿è¾“å…¥æç¤ºã€çŸ­è¾“å‡º**ï¼šç”¨æˆ·è¡Œä¸ºåºåˆ—å¯èƒ½é•¿è¾¾æ•°åƒtokenï¼Œä½†åªéœ€ç”Ÿæˆå°‘é‡tokenè¡¨ç¤ºæ¨èç‰©å“IDã€‚
- **å¤§è§„æ¨¡Beam Searchå¼€é”€å¤§**ï¼šä¸ºä¿è¯æ¨èå¤šæ ·æ€§ï¼Œéœ€ä½¿ç”¨å¤§Beam Widthï¼ˆå¦‚512ï¼‰å’ŒTop-Kç­›é€‰ï¼Œå¸¦æ¥å·¨å¤§çš„æ’åºä¸å†…å­˜ç®¡ç†å¼€é”€ã€‚
- **å…±äº«å‰ç¼€æœªè¢«æœ‰æ•ˆåˆ©ç”¨**ï¼šå¤šä¸ªbeamå…±äº«ç›¸åŒçš„promptä¸Šä¸‹æ–‡ï¼Œä½†ç°æœ‰æ–¹æ³•é‡å¤åŠ è½½KV Cacheï¼Œé€ æˆå†…å­˜å¸¦å®½æµªè´¹ã€‚
- **æ— æ•ˆitemç”Ÿæˆä¸¥é‡**ï¼šTokenç»„åˆç©ºé—´å·¨å¤§ï¼Œè®¸å¤šç»„åˆä¸å¯¹åº”çœŸå®å•†å“ï¼Œéœ€é«˜æ•ˆè¿‡æ»¤æœºåˆ¶ã€‚
- **ç³»ç»Ÿçº§å¹¶è¡Œåº¦ä¸è¶³**ï¼šhost-deviceé—´è°ƒåº¦å¼€é”€å æ¯”é«˜ï¼Œéš¾ä»¥æ»¡è¶³ä¸¥æ ¼SLOï¼ˆP99 < 200msï¼‰ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

ä½œè€…æå‡º **xGR** â€”â€”ä¸€ä¸ªé¢å‘ç”Ÿæˆå¼æ¨èçš„ç«¯åˆ°ç«¯é«˜æ€§èƒ½æ¨ç†æœåŠ¡ç³»ç»Ÿï¼Œä»**ç®—å­å±‚ã€ç®—æ³•å±‚ã€ç³»ç»Ÿå±‚**ä¸‰ä¸ªç»´åº¦è¿›è¡Œé‡æ„ï¼š

#### ï¼ˆ1ï¼‰xAttentionï¼šåˆ†ç¦»å¼KVç¼“å­˜ + åˆ†é˜¶æ®µè®¡ç®—
- å°†KV Cacheåˆ’åˆ†ä¸º **Shared Cache**ï¼ˆæ¥è‡ªprefillé˜¶æ®µçš„promptï¼‰å’Œ **Unshared Cache**ï¼ˆdecodeé˜¶æ®µç”Ÿæˆçš„tokenï¼‰ã€‚
- åœ¨attentionè®¡ç®—ä¸­åˆ†é˜¶æ®µå¤„ç†ï¼šå…ˆç‹¬ç«‹è®¡ç®—sharedéƒ¨åˆ†ï¼Œå†èåˆunsharedéƒ¨åˆ†ï¼Œé€šè¿‡`OnlineSoftmax`åˆå¹¶ç»“æœã€‚
- å®ç°ç»†ç²’åº¦load balancingï¼Œå¹¶å‡å°‘å†—ä½™KVè¯»å–ã€‚

#### ï¼ˆ2ï¼‰xBeamï¼šé«˜æ•ˆçš„beam searchä¼˜åŒ–
- **Valid Path Constraint**ï¼šå¼•å…¥item maskï¼Œåœ¨logitsä¸Šå±è”½éæ³•tokenç»„åˆï¼Œé˜²æ­¢â€œå¹»è§‰â€itemç”Ÿæˆã€‚
- **Early Sorting Termination**ï¼šç»´æŠ¤å¤§å°ä¸ºBWçš„min-heapï¼Œä¸€æ—¦æŸbeamå½“å‰log_probä½äºå †é¡¶ï¼Œåˆ™æå‰ç»ˆæ­¢è¯¥beamçš„éå†ï¼Œå¤§å¹…é™ä½æ’åºå¤æ‚åº¦ã€‚
- **Data Structure Reuse**ï¼šå¤ç”¨æ—§beamçš„æ•°æ®ç»“æ„å­˜å‚¨æ–°å€™é€‰åºåˆ—ï¼Œé¿å…é¢‘ç¹åˆ†é…/é‡Šæ”¾å¸¦æ¥çš„å¼€é”€ã€‚

#### ï¼ˆ3ï¼‰xScheduleï¼šå¤šå±‚çº§æµæ°´çº¿è°ƒåº¦
- æ„å»ºä¸‰å±‚æ¶æ„ï¼š**Scheduler â†’ Engine â†’ Worker**ã€‚
- æ”¯æŒ**è·¨è¯·æ±‚ã€æ‰¹å†…ã€è¯·æ±‚å†…éƒ¨çš„å¤šçº§é‡å æ‰§è¡Œ**ï¼š
  - Host-sideé¢„å¤„ç†ï¼ˆå¦‚maskç”Ÿæˆï¼‰ä¸device-side forward passé‡å ï¼›
  - H2Dä¼ è¾“ä¸self-attentionè®¡ç®—é‡å ï¼›
  - å¤šStreamå¹¶å‘å¤„ç†ä¸åŒbatchï¼Œæå‡åŠ é€Ÿå™¨åˆ©ç”¨ç‡ã€‚
- åŠ¨æ€æ‰¹å¤„ç† + å›¾æäº¤ï¼ˆkernel graph dispatchï¼‰ä»¥é™ä½kernel launchå¼€é”€ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚vLLM/xLLMï¼‰ | xGR |
|------|--------------------------|-----|
| KVç®¡ç† | PagedAttentionï¼Œé‡å¤åŠ è½½å…±äº«prefix | åˆ†ç¦»KV cacheï¼Œç‰©ç†ä¸Šåªå­˜ä¸€ä»½shared cache |
| å†…å­˜æ•ˆç‡ | Block copyé¢‘ç¹ï¼Œç¢ç‰‡åŒ–ä¸¥é‡ | é¿å…block copyï¼Œtokenç²’åº¦ç®¡ç†unshared cache |
| æ’åºå¼€é”€ | å…¨å±€Top-BWæ’åºï¼ŒO(BWÃ—K) | Early termination + heapå‰ªæ |
| è¿‡æ»¤æœºåˆ¶ | åŠ¨æ€host-sideè¿‡æ»¤æˆ–é™æ€å…¨é‡mask | æ··åˆç¨€ç–/ç¨ å¯†maskï¼Œè®¾å¤‡ç«¯é›†æˆfiltering |
| è°ƒåº¦æ¨¡å‹ | å•streamä¸²è¡Œæ‰§è¡Œ | Multi-streamå¹¶è¡Œ + æµæ°´çº¿overlap |

> âœ… æ€»ä½“ä¼˜åŠ¿ï¼šåœ¨ä¿æŒP99å»¶è¿Ÿâ‰¤200msçš„å‰æä¸‹ï¼Œå®ç°æ›´é«˜çš„ååé‡å’Œæ›´ä½çš„èµ„æºæ¶ˆè€—ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **Amazon Review**ï¼šå…¬å¼€æ¨èä»»åŠ¡åŸºå‡†æ•°æ®é›†ï¼Œç”¨äºæ ‡å‡†åŒ–è¯„ä¼°ã€‚
- **JD Trace**ï¼šæ¥è‡ªäº¬ä¸œç”Ÿäº§ç¯å¢ƒçš„çœŸå®æµé‡traceï¼ŒåŒ…å«åŠ¨æ€è¯·æ±‚æ¨¡å¼ï¼Œæ›´å…·ç°å®æ„ä¹‰ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - **Ascendé›†ç¾¤**ï¼š64èŠ‚ç‚¹ Ã— 16 Ascend NPUï¼ˆ64GBï¼‰
  - **GPUé›†ç¾¤**ï¼š8èŠ‚ç‚¹ Ã— 8 NVIDIA H800 GPUï¼ˆ80GBï¼‰ï¼ŒNVLinkäº’è”
- **æ¨¡å‹**ï¼š
  - **Qwen3**ï¼ˆ0.6B ~ 4Bå‚æ•°ï¼‰
  - **OneRec**ï¼ˆ0.1B ~ 3Bå‚æ•°ï¼‰â€”â€”å…¸å‹çš„ç”Ÿæˆå¼æ¨èæ¨¡å‹
- **Beam Widthï¼ˆBWï¼‰æµ‹è¯•èŒƒå›´**ï¼š{128, 256, 512}
- **Batch Sizeè‡ªé€‚åº”è°ƒæ•´**ï¼Œå—SLOçº¦æŸæ§åˆ¶æœ€å¤§ç­‰å¾…æ—¶é—´ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **å¹³å‡å»¶è¿Ÿï¼ˆAverage Latencyï¼‰**
- **P99å»¶è¿Ÿï¼ˆP99 Latencyï¼‰**
- **ååé‡ï¼ˆThroughput, RPSï¼‰**
- **å³°å€¼å†…å­˜å ç”¨ï¼ˆPeak Memory Usageï¼‰**
- **Kernelçº§æ€§èƒ½åˆ†æ**ï¼ˆlatency, compute throughput, memory boundç¨‹åº¦ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **vLLM**ï¼šåŸºäºPagedAttentionçš„ç»å…¸LLMæ¨ç†å¼•æ“
- **xLLM**ï¼šå·¥ä¸šçº§æ¨ç†æ¡†æ¶ï¼Œæ”¯æŒAscend NPUï¼Œä¹Ÿä½¿ç”¨PagedAttentionæœºåˆ¶

> æ³¨ï¼švLLMä¸æ”¯æŒOneRecæ¨¡å‹ï¼Œæ•…éƒ¨åˆ†å®éªŒä»…ä¸xLLMæ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ååé‡æå‡ï¼ˆæ ¸å¿ƒæˆæœï¼‰
> åœ¨ä¸¥æ ¼P99 â‰¤ 200msçš„SLOä¸‹ï¼Œ**xGRç›¸æ¯”state-of-the-artåŸºçº¿å®ç°äº†è‡³å°‘3.49Ã—çš„ååé‡æå‡**ã€‚

#### å›¾13 & å›¾14ï¼ˆAscendé›†ç¾¤ï¼‰æ˜¾ç¤ºï¼š
- æ‰€æœ‰é…ç½®ä¸‹ï¼ŒxGRå‡èƒ½ç»´æŒå¹³ç¨³å»¶è¿Ÿå¢é•¿ï¼Œè€ŒåŸºçº¿åœ¨é«˜RPSæ—¶è¿…é€Ÿçªç ´SLOã€‚
- å½“Beam Widthå¢å¤§è‡³512æ—¶ï¼ŒxLLM/vLLMå»¶è¿Ÿæ€¥å‰§ä¸Šå‡ï¼Œå‡ ä¹æ— æ³•è¿è¡Œï¼›è€ŒxGRä»å¯ç¨³å®šæœåŠ¡ã€‚
- å¯¹äºQwen3-4Bæ¨¡å‹ï¼ŒxGRåœ¨é«˜è´Ÿè½½ä¸‹ä»å¯è¾¾æ•°å€äºåŸºçº¿çš„RPSã€‚

#### å›¾19ï¼ˆGPUé›†ç¾¤ï¼‰è¡¨æ˜ï¼š
- å³ä½¿åœ¨é«˜ç«¯H800 GPUä¸Šï¼ŒvLLMè¡¨ç°ä¾ç„¶è¾ƒå·®ã€‚
- xGRåœ¨å¤šç§æ¨¡å‹è§„æ¨¡å’Œbeam widthä¸‹æŒç»­é¢†å…ˆï¼Œè¯æ˜å…¶è®¾è®¡å…·æœ‰**è·¨ç¡¬ä»¶å¹³å°çš„å¯ç§»æ¤æ€§å’Œæœ‰æ•ˆæ€§**ã€‚

---

### å†…å­˜æ•ˆç‡å¯¹æ¯”ï¼ˆå›¾15 & å›¾16ï¼‰
- **å›ºå®šè¾“å…¥é•¿åº¦=1kï¼ŒBW=512æ—¶**ï¼š
  - xGRå³°å€¼å†…å­˜ â‰ˆ **10.6 GB**
  - xLLMå³°å€¼å†…å­˜ â‰ˆ **46.3 GB**ï¼ˆè¶…4å€ï¼‰
- **å›ºå®šBW=256ï¼Œè¾“å…¥é•¿åº¦å¢è‡³3kæ—¶**ï¼š
  - xGRå³°å€¼å†…å­˜ â‰ˆ **12.0 GB**
  - xLLM â‰ˆ **30 GB**

> ğŸ’¡ ç»“è®ºï¼šxGRæˆåŠŸè§£è€¦å†…å­˜ä½¿ç”¨ä¸åºåˆ—é•¿åº¦ï¼Œé€‚ç”¨äºé•¿ä¸Šä¸‹æ–‡æ¨èåœºæ™¯ã€‚

---

### Kernelçº§æ€§èƒ½åˆ†æï¼ˆå›¾17ï¼‰
- **Latency**ï¼šxAttentionåœ¨å¤§beam widthä¸‹æ¯”PagedAttentionå¿«çº¦ **6.6Ã—**
- **Compute Throughput**ï¼šæå‡è¾¾ **7Ã—**
- **Memory Boundç¨‹åº¦**ï¼š
  - PagedAttentionï¼š93.4%æ—¶é—´å¤„äºmemory busyçŠ¶æ€ â†’ æ˜æ˜¾å†…å­˜ç“¶é¢ˆ
  - xAttentionï¼šä»…52% busyç‡ â†’ æˆåŠŸè½¬ä¸ºcompute-boundï¼Œç¡¬ä»¶åˆ©ç”¨ç‡æ›´é«˜

---

### æ¶ˆèå®éªŒï¼ˆå›¾18ï¼‰
åœ¨OneRec-0.1B + Amazon Reviewä¸Šçš„ablation studyï¼š
- **Baselineï¼ˆä»…xAttention+xBeamï¼‰**ï¼šéšRPSå¢åŠ å»¶è¿Ÿå¿«é€Ÿä¸Šå‡
- **+ Valid Item Filtering**ï¼šå»¶è¿Ÿç•¥æœ‰ä¸‹é™ï¼Œè¯´æ˜è®¾å¤‡ç«¯filteringæ— é¢å¤–è´Ÿæ‹…
- **+ Kernel Graph Dispatch**ï¼šæ˜¾è‘—é™ä½kernel launchå¼€é”€
- **+ Multi-stream Execution**ï¼šå®ç°æœ€ä½³æ€§èƒ½ï¼Œæ”¯æŒé«˜å¹¶å‘ä¸‹çš„pipeline overlap

> ğŸ” å‘ç°ï¼šmulti-streamæ˜¯åº”å¯¹è½»é‡æ¨¡å‹host overheadçš„å…³é”®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç”Ÿæˆå¼æ¨èçš„å·¥ä½œè´Ÿè½½ä¸LLMå­˜åœ¨æœ¬è´¨å·®å¼‚**ï¼Œä¸èƒ½ç®€å•å¥—ç”¨ç°æœ‰LLMæ¨ç†ç³»ç»Ÿã€‚
2. **å…±äº«prefixçš„KV cacheé‡ç”¨æ˜¯æ€§èƒ½çªç ´å£**ï¼ŒxAttentioné€šè¿‡åˆ†ç¦»cacheç»“æ„å®ç°é«˜æ•ˆå¤ç”¨ã€‚
3. **å¤§è§„æ¨¡beam searchä¸­çš„æ’åºä¸è¿‡æ»¤æ˜¯ä¸»è¦ç“¶é¢ˆ**ï¼ŒxBeamé€šè¿‡early terminationå’Œmaskingå®ç°é«˜æ•ˆæœç´¢ã€‚
4. **ç³»ç»Ÿçº§overlapè‡³å…³é‡è¦**ï¼Œå°¤å…¶å¯¹äºå°æ¨¡å‹è€Œè¨€ï¼Œhost-sideè°ƒåº¦å¼€é”€ä¸å¯å¿½è§†ã€‚
5. **xGRå¯åœ¨çœŸå®ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²**ï¼šå·²ä¸Šçº¿ä¸‰ä¸ªæœˆï¼ŒæœåŠ¡äºæ•°äº¿ç”¨æˆ·ï¼ŒP99ç¨³å®šåœ¨200msä»¥å†…ï¼Œå³°å€¼RPSè¾¾ä¸‡çº§ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **å‡è®¾decodeæ­¥æ•°å›ºå®š**ï¼šç›®å‰é’ˆå¯¹ç”Ÿæˆå›ºå®šé•¿åº¦item IDï¼ˆå¦‚ä¸‰tokenç¼–ç ï¼‰è®¾è®¡ï¼Œå¯¹å˜é•¿è¾“å‡ºæ”¯æŒæœ‰é™ã€‚
- **ä¾èµ–é¢„å®šä¹‰valid item vocabulary**ï¼šéœ€è¦ç»´æŠ¤åˆæ³•tokenè·¯å¾„æ˜ å°„è¡¨ï¼Œæ„å»ºæˆæœ¬è¾ƒé«˜ã€‚
- **å½“å‰ä¼˜åŒ–é›†ä¸­åœ¨inferenceé˜¶æ®µ**ï¼Œæœªæ¶‰åŠè®­ç»ƒæˆ–å†·å¯åŠ¨é—®é¢˜ã€‚
- **multi-streamè°ƒåº¦ç­–ç•¥ä¾èµ–å®æ—¶è´Ÿè½½æ„ŸçŸ¥**ï¼Œåœ¨æç«¯æ³¢åŠ¨æµé‡ä¸‹å¯èƒ½éœ€æ›´æ™ºèƒ½çš„è°ƒåº¦å™¨ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ”¯æŒ**åŠ¨æ€beam widthè°ƒæ•´**ï¼Œæ ¹æ®queryéš¾åº¦è‡ªé€‚åº”æœç´¢å¼ºåº¦ã€‚
- å¼•å…¥**KV Cacheå‹ç¼©ä¸reuse across requests**ï¼Œè¿›ä¸€æ­¥é™ä½prefillå¼€é”€ã€‚
- æ¢ç´¢**ç¼–è¯‘å™¨çº§ä¼˜åŒ–**ï¼Œå°†æ•´ä¸ªç”Ÿæˆæµç¨‹ç¼–è¯‘ä¸ºé™æ€DAGä»¥æœ€å¤§åŒ–æ€§èƒ½ã€‚
- æ‰©å±•è‡³**å¤šæ¨¡æ€ç”Ÿæˆå¼æ¨è**ï¼ˆå¦‚å›¾æ–‡æ··åˆç”Ÿæˆï¼‰åœºæ™¯çš„æœåŠ¡ä¼˜åŒ–ã€‚

---

## æ€»ç»“

âœ… **xGRæ˜¯é¦–ä¸ªå…¨é¢é‡æ„ç”Ÿæˆå¼æ¨èæ¨ç†æ ˆçš„ç³»ç»Ÿ**ï¼Œä»operatorã€algorithmåˆ°systemå±‚é¢ååŒä¼˜åŒ–ï¼Œè§£å†³äº†GRç‰¹æœ‰çš„é•¿promptã€å¤§beamã€é«˜å¹¶å‘ã€ä½å»¶è¿Ÿç­‰æŒ‘æˆ˜ã€‚

ğŸš€ å®éªŒéªŒè¯å…¶åœ¨çœŸå®æ•°æ®å’Œç¡¬ä»¶ä¸Šç›¸è¾ƒvLLM/xLLMå–å¾—**3.49Ã—ä»¥ä¸Šçš„ååæå‡**ï¼ŒåŒæ—¶å¤§å¹…é™ä½å†…å­˜å ç”¨å’Œå»¶è¿Ÿæ•æ„Ÿæ€§ï¼Œå…·å¤‡å¼ºå·¥ç¨‹è½åœ°èƒ½åŠ›ã€‚

ğŸ¯ æ ¸å¿ƒæ€æƒ³ï¼š**è¯†åˆ«é¢†åŸŸç‰¹å¼‚æ€§ workloadç‰¹å¾ï¼Œå¹¶é’ˆå¯¹æ€§åœ°è¿›è¡Œè½¯ç¡¬ååŒè®¾è®¡**ï¼Œè€Œéç›²ç›®æ²¿ç”¨é€šç”¨LLMæ–¹æ¡ˆã€‚

</details>

---

### 2. [RollMux: Phase-Level Multiplexing for Disaggregated RL Post-Training](https://arxiv.org/abs/2512.11306)

**Authors**: Tianyuan Wu, Lunxi Cao, Yining Wei, Wei Gao, Yuheng Zhao, Dakai An, Shaopan Xiong, Zhiqiang Lv, Ju Huang, Siran Yang, Yinghao Yu, Jiamang Wang, Lin Qu, Wei Wang  
**Category**: cs.DC  
**Published**: 2025-12-15  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.11306v1  

#### Abstract
Rollout-training disaggregation is emerging as the standard architecture for Reinforcement Learning (RL) post-training, where memory-bound rollout and compute-bound training are physically disaggregated onto purpose-built clusters to maximize hardware efficiency. However, the strict synchronization ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šROLLMUX: Phase-Level Multiplexing for Disaggregated RL Post-Training

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¼ºåŒ–å­¦ä¹ åè®­ç»ƒï¼ˆRL post-trainingï¼‰ä¸­ï¼Œ**rollout-training disaggregation** å·²æˆä¸ºæ ‡å‡†æ¶æ„ï¼Œå³å°†å†…å­˜å¯†é›†å‹çš„ rollout é˜¶æ®µä¸è®¡ç®—å¯†é›†å‹çš„ training é˜¶æ®µåˆ†åˆ«éƒ¨ç½²åœ¨ä¸“ç”¨é›†ç¾¤ä¸Šä»¥æå‡ç¡¬ä»¶æ•ˆç‡ã€‚ç„¶è€Œï¼Œç”±äº on-policy ç®—æ³•è¦æ±‚ä¸¥æ ¼çš„åŒæ­¥æ€§ï¼Œä¸¤ä¸ªé˜¶æ®µå¿…é¡»ä¸²è¡Œæ‰§è¡Œï¼Œå¯¼è‡´ä¸€ä¸ªé›†ç¾¤ç©ºé—²ç­‰å¾…å¦ä¸€ä¸ªå®Œæˆï¼Œå½¢æˆä¸¥é‡çš„â€œ**ä¾èµ–æ°”æ³¡**â€ï¼ˆdependency bubblesï¼‰ï¼Œé€ æˆèµ„æºåˆ©ç”¨ç‡ä½ä¸‹ã€‚

ç°æœ‰å¼‚æ­¥æ–¹æ³•ï¼ˆå¦‚ AReaLã€StreamRLã€AsyncFlowï¼‰è™½èƒ½æé«˜åˆ©ç”¨ç‡ï¼Œä½†å¼•å…¥æ ·æœ¬è¿‡æœŸï¼ˆsample stalenessï¼‰ï¼ŒæŸå®³æ¨¡å‹æ”¶æ•›æ€§å’Œå‡†ç¡®æ€§ï¼Œä¸é€‚ç”¨äºå¯¹ç­–ç•¥ä¸€è‡´æ€§è¦æ±‚é«˜çš„ä»»åŠ¡ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

è®ºæ–‡æå‡º **ROLLMUX**ï¼Œä¸€ç§é¢å‘è§£è€¦å¼ RL åè®­ç»ƒçš„è·¨é›†ç¾¤è°ƒåº¦æ¡†æ¶ï¼Œé€šè¿‡**ç›¸ä½çº§å¤šè·¯å¤ç”¨**ï¼ˆphase-level multiplexingï¼‰æ¥å›æ”¶è¿™äº›â€œä¾èµ–æ°”æ³¡â€ã€‚

å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **å…±æ‰§è¡Œç»„æŠ½è±¡**ï¼ˆCo-Execution Groupï¼‰ï¼š
  å°†å¤šä¸ª RL ä½œä¸šç»„ç»‡æˆâ€œå…±æ‰§è¡Œç»„â€ï¼Œæ¯ä¸ªç»„å…±äº«ä¸€ç»„ rollout å’Œ training èµ„æºæ± ã€‚è¯¥æŠ½è±¡å°†å…¨å±€è°ƒåº¦é—®é¢˜åˆ†è§£ä¸ºå¯ç®¡ç†çš„å­é—®é¢˜ï¼Œå¹¶ä½œä¸º**å±€éƒ¨æ€§åŸŸ**ï¼ˆlocality domainï¼‰ï¼Œç¡®ä¿æ¨¡å‹çŠ¶æ€ä¿ç•™åœ¨ä¸»æœºå†…å­˜ä¸­ï¼Œæ”¯æŒâ€œçƒ­å¯åŠ¨â€ä¸Šä¸‹æ–‡åˆ‡æ¢ã€‚

- **ä¸¤çº§è°ƒåº¦æ¶æ„**ï¼š
  - **ç»„é—´è°ƒåº¦å™¨**ï¼ˆInter-Group Schedulerï¼‰ï¼šåŸºäºä¿å®ˆçš„éšæœºè§„åˆ’ï¼ˆconservative stochastic planningï¼‰ï¼Œå†³å®šæ–°ä½œä¸šåº”åŠ å…¥å“ªä¸ªå…±æ‰§è¡Œç»„æˆ–æ–°å»ºç»„ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–è¾¹é™…èµ„æºå¼€é”€ï¼ŒåŒæ—¶æ»¡è¶³ SLO å’Œå†…å­˜çº¦æŸã€‚
  - **ç»„å†…è°ƒåº¦å™¨**ï¼ˆIntra-Group Schedulerï¼‰ï¼šé‡‡ç”¨**è½®è½¬è°ƒåº¦**ï¼ˆround-robinï¼‰ï¼Œè¯æ˜åœ¨éé¥±å’Œç»„ä¸­æ˜¯èµ„æºåˆ©ç”¨ç‡æœ€ä¼˜çš„ç­–ç•¥ã€‚

- **é•¿å°¾è¿ç§»æœºåˆ¶**ï¼ˆLong-Tail Migrationï¼‰ï¼š
  åŠ¨æ€è¯†åˆ« rollout ä¸­çš„â€œé•¿å°¾è¯·æ±‚â€ï¼ˆstragglerï¼‰ï¼Œå°†å…¶è¿ç§»åˆ°å°‘é‡è®¾å¤‡ä¸Šç»§ç»­æ‰§è¡Œï¼Œé‡Šæ”¾å…¶ä½™ GPU ç»™ä¸‹ä¸€ä¸ªä½œä¸šï¼Œå®ç°ç»†ç²’åº¦æµæ°´çº¿å¹¶æå‡ååã€‚

- **æ‹“æ‰‘æ„ŸçŸ¥æ¨¡å‹åŒæ­¥**ï¼ˆTopology-Aware Model Syncï¼‰ï¼š
  åœ¨è·¨é›†ç¾¤åŒæ­¥æ—¶ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µæ›´æ–°ï¼šå…ˆé€šè¿‡å¹¶è¡Œ P2P æµå°†æ¨¡å‹åˆ†ç‰‡ä¼ è¾“åˆ°ç›®æ ‡é›†ç¾¤çš„ä¸€ä¸ªèŠ‚ç‚¹ï¼Œå†åˆ©ç”¨é«˜é€Ÿæœ¬åœ°ç½‘ç»œï¼ˆå¦‚ NVLink/InfiniBandï¼‰è¿›è¡Œå¹¿æ’­ï¼Œé¿å…æ‰€æœ‰èŠ‚ç‚¹éƒ½ä»æ…¢é€Ÿè·¨é›†ç¾¤é“¾è·¯ä¸‹è½½å®Œæ•´æ¨¡å‹ã€‚

- **ç›¸ä½ä¸ºä¸­å¿ƒçš„æ§åˆ¶æ¨¡å‹**ï¼ˆPhase-Centric Controlï¼‰ï¼š
  å°† rollout å’Œ training è§†ä¸ºç‹¬ç«‹çš„å¯è°ƒåº¦å®ä½“ï¼Œæš´éœ²ä½œä¸šå†…éƒ¨ä¾èµ–å›¾ï¼Œæ”¯æŒç²¾ç»†è°ƒåº¦å’Œå¿«é€Ÿä¸Šä¸‹æ–‡åˆ‡æ¢ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **èµ„æºåˆ©ç”¨ç‡** | æ˜¾è‘—å‡å°‘ rollout å’Œ training é›†ç¾¤çš„ç©ºé—²æ—¶é—´ï¼Œæå‡æ•´ä½“åˆ©ç”¨ç‡ã€‚ |
| **æˆæœ¬æ•ˆç‡** | ç›¸æ¯”ä¼ ç»Ÿè§£è€¦æ–¹æ¡ˆèŠ‚çœé«˜è¾¾ 1.84Ã— æˆæœ¬ï¼Œç›¸æ¯” co-located åŸºçº¿èŠ‚çœ 1.38Ã—ã€‚ |
| **SLO ä¿è¯** | æ‰€æœ‰ä½œä¸šå‡æ»¡è¶³æ€§èƒ½ SLOï¼ˆ100% SLO attainmentï¼‰ã€‚ |
| **å…¼å®¹æ€§** | æ”¯æŒä»»æ„ on-policy RL ç®—æ³•ï¼ˆå¦‚ PPOã€GRPOã€DAPOï¼‰ï¼Œä¸”ä¸å‚æ•°é‡åˆ†é…ã€æ¨æµ‹è§£ç ç­‰æŠ€æœ¯æ­£äº¤å¯ç»„åˆã€‚ |
| **å®ç”¨æ€§** | åœ¨çœŸå®ç”Ÿäº§è§„æ¨¡æµ‹è¯•å¹³å°ä¸ŠéªŒè¯ï¼Œå…·å¤‡å·¥ç¨‹å¯è¡Œæ€§ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- å®éªŒåŸºäºçœŸå®ç”Ÿäº§ç¯å¢ƒé‡‡é›†çš„ **two-week RL post-training trace**ï¼ŒåŒ…å« 200 ä¸ªå¼‚æ„ä½œä¸šã€‚
- æ¨¡å‹èŒƒå›´ï¼š3Bâ€“32B å‚æ•°ï¼ˆQwen ç³»åˆ—ï¼‰
- æ•°æ®é›†æ¶µç›–æ•°å­¦æ¨ç†ï¼ˆDeepMath-103Kï¼‰ã€è½¯ä»¶å·¥ç¨‹ï¼ˆSWE-Benchï¼‰ã€æ¸¸æˆç¯å¢ƒï¼ˆFrozenLakeï¼‰ç­‰ã€‚
- å¾®åŸºå‡†æµ‹è¯•ä½¿ç”¨ 5 ç±»ä»£è¡¨æ€§ä½œä¸šï¼ˆTable 3ï¼‰ï¼Œè¦†ç›–å•è½®ä¸å¤šè½®äº¤äº’æ¨¡å¼ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **ç¡¬ä»¶é…ç½®**
- **Rollout Cluster**ï¼š328 Ã— NVIDIA H20 GPUsï¼ˆä½æˆæœ¬ã€é«˜å¸¦å®½ï¼‰
- **Training Cluster**ï¼š328 Ã— NVIDIA H800 GPUsï¼ˆé«˜æ€§èƒ½ã€é«˜ç®—åŠ›ï¼‰
- é›†ç¾¤é—´é€šè¿‡ 20 Gbps Ethernet è¿æ¥ï¼Œé›†ç¾¤å†…éƒ¨ä¸º 400 Gbps InfiniBandã€‚

#### **è¯„ä¼°æŒ‡æ ‡**
- **æ€»èµ„æºå¼€é”€æˆæœ¬**ï¼ˆTotal Provisioning Cost, $/hï¼‰
- **æ¯å•ä½æˆæœ¬ååé‡**ï¼ˆPer-Cost Throughputï¼‰
- **SLO è¾¾æˆç‡**ï¼ˆSLO Attainment Rateï¼‰
- **ä¾èµ–æ°”æ³¡å‡å°‘æ¯”ä¾‹**
- **ä¸Šä¸‹æ–‡åˆ‡æ¢å»¶è¿Ÿ**
- **æ¨¡å‹åŒæ­¥æ—¶é—´**

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿ | æè¿° |
|------|------|
| **Solo Disaggregation (Solo-D)** | æ ‡å‡†è§£è€¦æ¶æ„ï¼Œæ¯ä¸ªä½œä¸šç‹¬å  rollout å’Œ training èµ„æºï¼Œæ— æ—¶é—´å¤ç”¨ã€‚ |
| **veRL [41]** | å•ä½“æ¶æ„ï¼Œåœ¨é«˜æ€§èƒ½ H800 é›†ç¾¤ä¸Š co-locate æ‰€æœ‰é˜¶æ®µï¼Œé¿å…ç½‘ç»œç“¶é¢ˆä½†å­˜åœ¨ç¡¬ä»¶é”™é…ã€‚ |
| **Gavel+ [29]** | æ”¹è¿›ç‰ˆå¼‚æ„æ„ŸçŸ¥è°ƒåº¦å™¨ï¼Œä¼˜åŒ– GPU åˆ†é…æ¯”ä¾‹ï¼Œä½†æ— æ³•è¿›è¡Œç›¸ä½çº§äº¤é”™è°ƒåº¦ã€‚ |
| **Offline Optimal (Opt)** | ç†è®ºæœ€ä¼˜ï¼ˆæš´åŠ›æœç´¢ï¼‰ï¼Œç”¨äºè¡¡é‡è°ƒåº¦è´¨é‡ä¸Šé™ã€‚ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

- **æˆæœ¬æ•ˆç‡æå‡**ï¼š
  - ç›¸æ¯” **Solo-D**ï¼š**1.84Ã— æ›´ä½çš„æˆæœ¬**ï¼ˆ$510/h vs $940/hï¼‰
  - ç›¸æ¯” **veRL**ï¼š**1.38Ã— æ›´ä½çš„æˆæœ¬**
- **SLO è¾¾æˆç‡**ï¼š**100%**ï¼Œæ‰€æœ‰ä½œä¸šå‡æ»¡è¶³æŒ‡å®šæ€§èƒ½ç›®æ ‡ã€‚
- **èµ„æºä½¿ç”¨å³°å€¼é™ä½**ï¼š
  - **Training GPUs**ï¼šå³°å€¼ä» 328 é™è‡³ **152**ï¼ˆâ†“2.16Ã—ï¼‰
  - **Rollout GPUs**ï¼šå³°å€¼ä» 328 é™è‡³ **216**ï¼ˆâ†“1.52Ã—ï¼‰

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| åœºæ™¯ | ROLLMUX vs Solo-D | vs Gavel+ | vs veRL |
|------|-------------------|----------|--------|
| æ—¶é—´å¤ç”¨ï¼ˆType-AÃ—2ï¼‰ | **+82%** æˆæœ¬æ•ˆç‡ | +55.6% | +46.8% |
| è®­ç»ƒå¤ç”¨ï¼ˆType-DÃ—2+Eï¼‰ | **+104%** | +61.9% | +29.9% |
| ç©ºé—´å¤ç”¨ï¼ˆType-C+DÃ—2ï¼‰ | **+111%** | +85.1% | +66.1% |

> å›¾ 13 æ˜¾ç¤ºï¼Œåœ¨çœŸå® trace å›æ”¾ä¸­ï¼ŒROLLMUX æ˜¾è‘—é™ä½äº† GPU æ•°é‡å’Œæ€»æˆæœ¬ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **é•¿å°¾è¿ç§»ï¼ˆLong-Tail Migrationï¼‰**
- å¯¹äº 14B-8K æ¨¡å‹ï¼Œå¯ç”¨è¿ç§»åç«¯åˆ°ç«¯ååæå‡ **1.28Ã—**ã€‚
- æ•ˆæœéšè¾“å‡ºé•¿åº¦å¢åŠ è€Œå¢å¼ºï¼Œå°¤å…¶åœ¨é•¿åºåˆ—ç”Ÿæˆåœºæ™¯ä¸‹æ˜¾è‘—ã€‚

#### **æ‹“æ‰‘æ„ŸçŸ¥æ¨¡å‹åŒæ­¥**
- å•èŠ‚ç‚¹åŒæ­¥ï¼ˆ8â†’8 GPUsï¼‰ï¼šæ¯” veRL å¿« **7.87Ã—â€“8.33Ã—**
- å¤šèŠ‚ç‚¹åŒæ­¥ï¼ˆ16â†’16 GPUsï¼‰ï¼šä»å¿« **2.62Ã—â€“2.75Ã—**
- æœ‰æ•ˆç¼“è§£äº†è§£è€¦æ¶æ„ä¸­çš„è·¨é›†ç¾¤é€šä¿¡ç“¶é¢ˆã€‚

#### **ä¸Šä¸‹æ–‡åˆ‡æ¢å»¶è¿Ÿ**
- å†·å¯åŠ¨ï¼ˆCold Startï¼‰ï¼šé«˜è¾¾ **80 ç§’**
- çƒ­å¯åŠ¨ï¼ˆWarm Startï¼‰ï¼šé™è‡³ **1.2â€“1.9 ç§’**ï¼ˆåŠ é€Ÿçº¦ 48Ã—ï¼‰
- ä½¿ç»†ç²’åº¦æ—¶é—´å¤ç”¨æˆä¸ºå¯èƒ½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **ä¾èµ–æ°”æ³¡æ˜¯è§£è€¦ RL æ¶æ„çš„ä¸»è¦æ•ˆç‡ç“¶é¢ˆ**ï¼Œå³ä½¿ä½¿ç”¨æ›´ä¾¿å®œçš„ H20 åš rolloutï¼Œå› ç©ºé—²ç­‰å¾…åè€Œå¯¼è‡´æ€»æˆæœ¬é«˜äº co-located æ–¹æ¡ˆã€‚
2. **ç›¸ä½çº§å¤šè·¯å¤ç”¨æ˜¯è§£å†³è¯¥é—®é¢˜çš„æœ‰æ•ˆé€”å¾„**ï¼šé€šè¿‡å°†ä¸€ä¸ªä½œä¸šçš„ rollout ä¸å¦ä¸€ä¸ªä½œä¸šçš„ training å¹¶è¡Œæ‰§è¡Œï¼Œå¯ä»¥â€œç¼–ç»‡â€å‡ºé«˜æ•ˆçš„æ—¶é—´å¤ç”¨æ¨¡å¼ã€‚
3. **è½®è½¬è°ƒåº¦åœ¨éé¥±å’Œç»„ä¸­æ˜¯åˆ©ç”¨ç‡æœ€ä¼˜çš„**ï¼Œä¸”æ˜“äºå®ç°å’Œç»´æŠ¤ã€‚
4. **ä¿å®ˆçš„ç»„é—´è°ƒåº¦ + åŠ¨æ€çš„ç»„å†…é€‚åº”** å¯å…¼é¡¾ SLO ä¿è¯ä¸è¿è¡Œæ—¶çµæ´»æ€§ã€‚
5. **çƒ­å¯åŠ¨æœºåˆ¶è‡³å…³é‡è¦**ï¼šè‹¥ä¸èƒ½å°†æ¨¡å‹çŠ¶æ€ä¿ç•™åœ¨ä¸»æœºå†…å­˜ä¸­ï¼Œä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€å°†å®Œå…¨æŠµæ¶ˆå¤ç”¨å¸¦æ¥çš„æ”¶ç›Šã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- **ç»„å¤§å°å—é™äºä¸»æœºå†…å­˜å®¹é‡**ï¼šå½“å‰æœ€å¤šæ”¯æŒ 2â€“5 ä¸ªä½œä¸šå…±å­˜äºåŒä¸€ç»„ï¼Œé™åˆ¶äº†æ‰“åŒ…çµæ´»æ€§ã€‚
- **è°ƒåº¦å†³ç­–ä¾èµ–å‡†ç¡®çš„æœ€åæƒ…å†µä¼°è®¡**ï¼šè™½ç„¶ä¿å®ˆè§„åˆ’ä¿éšœäº† SLOï¼Œä½†ä¹Ÿå¯èƒ½å¯¼è‡´èµ„æºé¢„ç•™è¿‡åº¦ã€‚
- **æœªå¤„ç†ä½œä¸šä¼˜å…ˆçº§æˆ–æŠ¢å æœºåˆ¶**ï¼šå‡è®¾æ‰€æœ‰ä½œä¸šå¹³ç­‰ï¼Œç¼ºä¹å¯¹é«˜ä¼˜å…ˆçº§ä»»åŠ¡çš„æ”¯æŒã€‚
- **æ‰©å±•æ€§ä¾èµ–äºè°ƒåº¦å™¨è½»é‡åŒ–è®¾è®¡**ï¼šå°½ç®¡å®æµ‹å†³ç­–å»¶è¿Ÿä»… ~600msï¼ˆ2000 ä½œä¸šï¼‰ï¼Œä½†åœ¨æ›´å¤§è§„æ¨¡ä¸‹ä»éœ€å…³æ³¨å¯æ‰©å±•æ€§ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

- æ”¯æŒåŠ¨æ€è°ƒæ•´ç»„å†…èµ„æºé…æ¯”ï¼ˆå¦‚è‡ªåŠ¨æ‰©ç¼© rollout èŠ‚ç‚¹ï¼‰ã€‚
- å¼•å…¥æœºå™¨å­¦ä¹ é¢„æµ‹æ¨¡å‹ç”Ÿæˆæ›´ç²¾å‡†çš„æ‰§è¡Œæ—¶é—´ä¼°è®¡ï¼Œæ›¿ä»£ä¿å®ˆä¸Šé™ã€‚
- æ¢ç´¢æ”¯æŒ off-policy æˆ–æ··åˆç­–ç•¥ä½œä¸šçš„ç»Ÿä¸€è°ƒåº¦æ¡†æ¶ã€‚
- ç»“åˆ energy-aware è°ƒåº¦ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–èƒ½æ•ˆæ¯”ã€‚
- å°† ROLLMUX æ€æƒ³æ¨å¹¿è‡³ MoE æ¨¡å‹è®­ç»ƒæˆ–å…¶ä»–å…·æœ‰é˜¶æ®µæ€§ç‰¹å¾çš„ AI å·¥ä½œè´Ÿè½½ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **ROLLMUX é€šè¿‡ç›¸ä½çº§å¤šè·¯å¤ç”¨å’Œä¸¤çº§è°ƒåº¦ï¼Œåœ¨ä¸è§£è€¦ on-policy æ­£ç¡®æ€§çš„å‰æä¸‹ï¼ŒæˆåŠŸå›æ”¶äº†è§£è€¦ RL æ¶æ„ä¸­çš„â€œä¾èµ–æ°”æ³¡â€ï¼Œå®ç°äº†é«˜è¾¾ 1.84Ã— çš„æˆæœ¬èŠ‚çº¦ä¸ 100% SLO è¾¾æˆï¼Œæ˜¯é¦–ä¸ªé¢å‘å¤šç§Ÿæˆ·è§£è€¦ RL é›†ç¾¤çš„é«˜æ•ˆè°ƒåº¦ç³»ç»Ÿã€‚**

</details>

---

### 3. [Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes](https://arxiv.org/abs/2512.11463)

**Authors**: Junghwan Lim, Sungmin Lee, Dongseok Kim, Taehyun Kim, Eunhwan Park, Jeesoo Lee, Jeongdoo Lee, Junhyeok Lee, Wai Ting Cheung, Dahye Choi, Minsu Ha, Jaeheui Her, Jaeyeon Huh, Hanbin Jung, Changjin Kang, Beomgyu Kim, Minjae Kim, Taewhan Kim, Youngrok Kim, Hyukjin Kweon, Haesol Lee, Kungyu Lee, Dongpin Oh, Yeongjae Park, Bokki Ryu, Dongjoo Weon  
**Category**: cs.AI  
**Published**: 2025-12-15  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.11463v1  

#### Abstract
We introduce Motif-2-12.7B-Reasoning, a 12.7B parameter language model designed to bridge the gap between open-weight systems and proprietary frontier models in complex reasoning and long-context understanding. Addressing the common challenges of model collapse and training instability in reasoning ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³å½“å‰**å¼€æ”¾æƒé‡è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†å’Œé•¿ä¸Šä¸‹æ–‡ç†è§£æ–¹é¢æ˜¾è‘—è½åäºé—­æºå‰æ²¿æ¨¡å‹**çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯ï¼š
- **è®­ç»ƒä¸ç¨³å®šæ€§**ï¼šåœ¨å¼•å…¥å¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼ˆRLFTï¼‰åå®¹æ˜“å‡ºç°æ¨¡å‹å´©æºƒï¼ˆmodel collapseï¼‰æˆ–æ€§èƒ½é€€åŒ–ã€‚
- **åˆ†å¸ƒä¸åŒ¹é…**ï¼šä½¿ç”¨é«˜å®¹é‡æ•™å¸ˆæ¨¡å‹ç”Ÿæˆçš„åˆæˆæ•°æ®ä¸å­¦ç”Ÿæ¨¡å‹çš„æ¨ç†é£æ ¼ä¸ä¸€è‡´ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
- **é•¿ä¸Šä¸‹æ–‡è®­ç»ƒæ•ˆç‡ä½**ï¼šå¤„ç†64K tokençº§åˆ«çš„ä¸Šä¸‹æ–‡å¯¹å†…å­˜å’Œè®¡ç®—èµ„æºæ„æˆå·¨å¤§æŒ‘æˆ˜ã€‚
- **ç¼ºä¹å¯å¤ç°çš„è®­ç»ƒé…æ–¹**ï¼šç¤¾åŒºç¼ºå°‘ç³»ç»Ÿæ€§çš„ã€å¯åœ¨ç°å®ç®—åŠ›çº¦æŸä¸‹å¤ç°çš„æ¨ç†æ¨¡å‹è®­ç»ƒæŒ‡å—ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
è®ºæ–‡æå‡ºäº†ä¸€ä¸ªå®Œæ•´çš„ã€å¯å¤ç°çš„è®­ç»ƒé…æ–¹ï¼ˆtraining recipeï¼‰ï¼Œæ¶µç›–ç³»ç»Ÿã€æ•°æ®å’Œç®—æ³•ä¸‰ä¸ªå±‚é¢çš„ä¼˜åŒ–ï¼š

#### ï¼ˆ1ï¼‰ç³»ç»Ÿçº§ä¼˜åŒ–ï¼ˆSystem Optimizationï¼‰
- **æ··åˆå¹¶è¡Œç­–ç•¥ï¼ˆHybrid Parallelismï¼‰**ï¼šç»“åˆ DeepSpeed-Ulysses çš„ Sequence Parallelismï¼ˆSPï¼‰ã€Tensor Parallelismï¼ˆTPï¼‰å’Œ Data Parallelismï¼ˆDP-shard/replicateï¼‰ï¼Œæ”¯æŒé«˜æ•ˆè®­ç»ƒ 64K ä¸Šä¸‹æ–‡ã€‚
- **ç»†ç²’åº¦æ¿€æ´»æ£€æŸ¥ç‚¹ï¼ˆFine-grained Activation Checkpointingï¼‰**ï¼šæ‰‹åŠ¨è°ƒä¼˜æ¯å±‚çš„é‡è®¡ç®—ç­–ç•¥ï¼Œé™ä½å³°å€¼æ˜¾å­˜å ç”¨ã€‚
- **Liger Kernel æŸå¤±å‡½æ•°**ï¼šé€šè¿‡åˆ†ç‰‡å¤„ç† logits å’ŒæŸå¤±è®¡ç®—ï¼Œæ˜¾è‘—å‡å°‘ RL è®­ç»ƒä¸­çš„æ˜¾å­˜å‹åŠ›ï¼Œå°¤å…¶ç¼“è§£ LM Head å’Œ Loss æ¨¡å—å¸¦æ¥çš„å†…å­˜ç“¶é¢ˆã€‚

#### ï¼ˆ2ï¼‰ä¸¤é˜¶æ®µç›‘ç£å¾®è°ƒï¼ˆTwo-stage SFTï¼‰
- **Stage 1ï¼ˆReasoning Foundationï¼‰**ï¼šåŸºäºé«˜è´¨é‡å¼€æºæ•°æ®é›†ï¼ˆå¦‚ Nemotron-Post-Training-Datasetã€OpenReasoningDatasetã€Mixture-of-Thoughtsï¼‰æ„å»ºåŸºç¡€æ¨ç†èƒ½åŠ›ï¼Œå¼ºè°ƒéªŒè¯ï¼ˆverificationï¼‰è€Œéæ•°é‡ï¼Œé‡‡ç”¨ `quality-over-quantity` åŸåˆ™ã€‚
- **Stage 2ï¼ˆDeep Reasoning Specializationï¼‰**ï¼šæ³¨å…¥ç»è¿‡**åˆ†å¸ƒå¯¹é½**çš„åˆæˆæ•°æ®ï¼ˆChain-of-Thoughtã€å¤±è´¥é©±åŠ¨ä¿®æ­£ç­‰ï¼‰ï¼Œç¡®ä¿æ¨ç†è½¨è¿¹ä¸ç›®æ ‡æ¨¡å‹çš„èƒ½åŠ›ç›¸åŒ¹é…ï¼Œå¹¶é€æ­¥æ‰©å±•ä¸Šä¸‹æ–‡è‡³ 64Kã€‚

> âœ… åˆ›æ–°æ´å¯Ÿï¼šæå‡ºâ€œ**æ¨ç†åˆ†å¸ƒå¯¹é½**â€æ¦‚å¿µâ€”â€”å³ä½¿åˆæˆæ•°æ®æ­£ç¡®ï¼Œè‹¥å…¶æ¨ç†è·¯å¾„è¿‡äºå¤æ‚æˆ–ç»“æ„ä¸åŒæ­¥ï¼Œä»ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

#### ï¼ˆ3ï¼‰ç¨³å®šçš„å¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼ˆRobust RLFT Pipelineï¼‰
- **LLM-as-a-data-filtering**ï¼šä½¿ç”¨é¢„RLæ¨¡å‹ç”Ÿæˆå¤šä¸ª rollout å¹¶ç»Ÿè®¡ pass rateï¼Œç­›é€‰éš¾åº¦é€‚ä¸­ï¼ˆÎ± â‰¤ p(x) â‰¤ Î²ï¼‰çš„é—®é¢˜ç»„æˆè®­ç»ƒé›†ï¼Œé¿å…æ¢¯åº¦æ¶ˆå¤±ï¼ˆdifficulty alignmentï¼‰ã€‚
- **Mixed-policy trajectory reuse**ï¼šå›ºå®šä¸€æ‰¹è½¨è¿¹è¿›è¡Œå¤šæ­¥æ¢¯åº¦æ›´æ–°ï¼Œæå‡æ ·æœ¬æ•ˆç‡ï¼Œå¹³è¡¡ on-policy ä¸ off-policy åŠ¨æ€ã€‚
- **Multi-task RL**ï¼šè”åˆä¼˜åŒ–æ•°å­¦ã€ä»£ç ã€æŒ‡ä»¤éµå¾ªä»»åŠ¡ï¼Œé˜²æ­¢å•ä¸€é¢†åŸŸè¿‡æ‹Ÿåˆå¯¼è‡´å…¶ä»–èƒ½åŠ›é€€åŒ–ã€‚
- **å–æ¶ˆé•¿åº¦æƒ©ç½šï¼ˆNo length penaltyï¼‰**ï¼šé¼“åŠ±æ¨¡å‹ç”Ÿæˆæ›´é•¿çš„æ¨ç†é“¾ï¼Œæå‡å¤æ‚ä»»åŠ¡è¡¨ç°ã€‚
- **æ‰©å¤§ clipping èŒƒå›´ï¼ˆÎµ âˆˆ [0.28, 0.40]ï¼‰**ï¼šåŠ å¿«æ”¶æ•›é€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒç¨³å®šæ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿåšæ³• | Motif-2-12.7B-Reasoning |
|------|----------|------------------------|
| æ•°æ®è´¨é‡ | å¤§é‡æœªéªŒè¯åˆæˆæ•°æ® | é«˜è´¨é‡ + åˆ†å¸ƒå¯¹é½ + å¤šé‡éªŒè¯ |
| SFT è®¾è®¡ | å•ä¸€é™æ€æ•°æ®åˆ†å¸ƒ | ä¸¤é˜¶æ®µåŠ¨æ€è¯¾ç¨‹å­¦ä¹ ï¼ˆcurriculumï¼‰ |
| RL æ•°æ®é€‰æ‹© | å…¨é‡é‡‡æ ·æˆ–éšæœºæŠ½æ · | åŸºäºæ¨¡å‹èƒ½åŠ›çš„éš¾åº¦è¿‡æ»¤ |
| RL æ•ˆç‡ | æ¯è½®é‡æ–° rollout | è½¨è¿¹å¤ç”¨ï¼ˆtrajectory reuseï¼‰æé«˜æ•ˆç‡ |
| æ˜¾å­˜ä¼˜åŒ– | æ ‡å‡†æ£€æŸ¥ç‚¹ | Liger Kernel + ç»†ç²’åº¦é‡è®¡ç®— |
| å¯å¤ç°æ€§ | é»‘ç®±æµç¨‹ | å®Œæ•´å…¬å¼€è®­ç»ƒç»†èŠ‚ä¸å¤±è´¥ç»éªŒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| ç±»å‹ | æ•°æ®æ¥æº | æè¿° |
|------|---------|------|
| **SFT é˜¶æ®µ** | Nemotron-Post-Training-Dataset, OpenReasoningDataset, Mixture-of-Thoughts, rstar-coder | åŒ…å«æ•°å­¦ã€ç¼–ç¨‹ã€STEMã€å·¥å…·è°ƒç”¨ç­‰å¤šé¢†åŸŸæ¨ç†ä»»åŠ¡ï¼Œç»ä¸¥æ ¼è¿‡æ»¤ä¿ç•™ verified=True ä¸” npass åœ¨ä¸­é—´èŒƒå›´çš„æ ·æœ¬ |
| **RL é˜¶æ®µ - æ•°å­¦** | GURU-92K | ç»ä¸¤æ­¥è¿‡æ»¤ï¼š<br>â‘  åˆç­›ï¼šQwen-30B pass rate âˆˆ (0, 10/16]<br>â‘¡ å†ç­›ï¼šç›®æ ‡æ¨¡å‹ pass rate âˆˆ (0, 0.8]ï¼Œå¹¶æŒ‰å­åŸŸåˆ†å±‚é‡‡æ · |
| **RL é˜¶æ®µ - ç¼–ç¨‹** | GURU-92K ä¸­ä»£ç éƒ¨åˆ† | åŒä¸Šè¿‡æ»¤é€»è¾‘ï¼Œæœ€ç»ˆä¸æ•°å­¦æ•°æ®é›†è§„æ¨¡å¯¹é½ |
| **RL é˜¶æ®µ - æŒ‡ä»¤éµå¾ª** | è‡ªå»ºåˆæˆæ•°æ®é›†ï¼ˆ10K samplesï¼‰ | æ›´ä¸¥è‹›ç­›é€‰ï¼špass rate âˆˆ (0, 0.4]ï¼Œèšç„¦æŒ‘æˆ˜æ€§æŒ‡ä»¤ |

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šåŸºäº Motif-2-12.7B-Instruct è¿›è¡Œç»§ç»­è®­ç»ƒ
- **ä¸Šä¸‹æ–‡é•¿åº¦**ï¼šSFT æœ€ç»ˆè¾¾ 64Kï¼›RL æ”¯æŒæœ€å¤§ç”Ÿæˆé•¿åº¦
- **ç¡¬ä»¶å¹³å°**ï¼šH100 GPU é›†ç¾¤ï¼Œä½¿ç”¨ SkyPilot ç®¡ç†è·¨é›†ç¾¤èµ„æº
- **RL ç®—æ³•**ï¼šGSPOï¼ˆGroup Sequence Policy Optimizationï¼‰ï¼Œcritic-free çš„ PPO å˜ä½“
- **Rollout è®¾ç½®**ï¼šn=5 ä¸ªè¾“å‡ºç”¨äºè®¡ç®— group advantage
- **è®­ç»ƒç¨³å®šæ€§æœºåˆ¶**ï¼šéš¾åº¦è¿‡æ»¤ã€è½¨è¿¹å¤ç”¨ã€multi-task å­¦ä¹ ã€æ— é•¿åº¦æƒ©ç½š

### è¯„ä¼°æŒ‡æ ‡
- **ä¸»æŒ‡æ ‡**ï¼š**Artificial Analysis Intelligence Index (AAII)**  
  â€”â€” ç”± 10 é¡¹åŸºå‡†å¹³å‡å¾—åˆ†æ„æˆçš„ç»¼åˆè¯„åˆ†ï¼ŒåŒ…æ‹¬ï¼š
  - MMLU-Pro
  - GPOA Diamond
  - Humanity's Last Exam
  - LiveCodeBench
  - SciCode
  - AIME 2025
  - IFBench
  - AA-LCR
  - Terminal-Bench Hard
  - Telecom Benchmark

- **å•é¡¹æŒ‡æ ‡**ï¼š
  - Pass@1ï¼ˆLiveCodeBench v5ï¼‰
  - æ•°å­¦å‡†ç¡®ç‡ï¼ˆAIME 2025ï¼‰
  - å·¥å…·ä½¿ç”¨æˆåŠŸç‡ï¼ˆIFBenchï¼‰
  - é•¿ä¸Šä¸‹æ–‡ä¸€è‡´æ€§ï¼ˆTerminal-Benchï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **å¼€æºæ¨¡å‹**ï¼šå„ç±» 12.7Bâ€“40B å‚æ•°çš„ open-weight æ¨¡å‹
- **é—­æºæ¨¡å‹**ï¼šGPT-4ã€GPT-5.1 ç­‰å•†ä¸šæ¨¡å‹ï¼ˆé€šè¿‡ API æ¥å…¥è¯„æµ‹ï¼‰
- **æ¶ˆèå¯¹ç…§**ï¼š
  - ä¸åŒæ•°æ®åˆ†å¸ƒï¼ˆseed-oss vs gpt-oss åˆæˆæ•°æ®ï¼‰
  - æ˜¯å¦å¯ç”¨éš¾åº¦è¿‡æ»¤
  - æ˜¯å¦ä½¿ç”¨è½¨è¿¹å¤ç”¨
  - æ˜¯å¦å–æ¶ˆé•¿åº¦æƒ©ç½š

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ¨¡å‹ | AAII å¾—åˆ† | å‚æ•°é‡ | å¤‡æ³¨ |
|------|----------|--------|------|
| **Motif-2-12.7B-Reasoning** | **89.7** | 12.7B | æœ¬æ–‡æå‡º |
| GPT-5.1 | 88.3 | ~æœªçŸ¥ | å½“å‰æœ€å¼ºé—­æºä¹‹ä¸€ |
| å…¶ä»– >12.7B å¼€æºæ¨¡å‹ | <89.7 | â‰¥12.7B | æ— æ›´å°æ¨¡å‹è¶…è¶Šæœ¬å·¥ä½œ |

> ğŸ“Š å›¾1æ˜¾ç¤ºï¼šå°½ç®¡å‚æ•°ä»…ä¸º 12.7Bï¼ŒMotif-2-12.7B-Reasoning åœ¨ AAII ä¸Šè¶…è¿‡ GPT-5.1ï¼Œä¸”æ˜¯æ‰€æœ‰ä¼˜äºå®ƒçš„æ¨¡å‹ä¸­**æœ€å°çš„ä¸€ä¸ª**ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
#### ï¼ˆ1ï¼‰SFT é˜¶æ®µï¼šLiveCodeBench v5 ç»“æœï¼ˆTable 2ï¼‰
| é…ç½® | Pass@1 |
|------|--------|
| Baseline | 51.78 |
| + seed-oss-36b åˆæˆæ•°æ® | **63.69** (+11.91) |
| + gpt-oss-120b åˆæˆæ•°æ® | **33.92** (-17.86) âš ï¸ æ€§èƒ½ä¸¥é‡ä¸‹é™ |

> ğŸ” å‘ç°ï¼šæ›´å¤§çš„æ•™å¸ˆæ¨¡å‹ä¸ä¸€å®šæ›´å¥½ï¼Œ**æ¨ç†åˆ†å¸ƒé”™é…ä¼šå¼•å‘è´Ÿè¿ç§»**ã€‚

#### ï¼ˆ2ï¼‰RLFT é˜¶æ®µï¼šAIME 2025 è¡¨ç°
- åœ¨ base model ä¸Šè°ƒä¼˜çš„è¶…å‚è¿ç§»åˆ° SFT åæ¨¡å‹æ—¶å¤±æ•ˆï¼ˆ+18% â†’ 0% æˆ–å€’é€€ï¼‰
- è¯æ˜ï¼š**SFT æ˜¾è‘—æ”¹å˜äº†ç­–ç•¥æ›´æ–°åŠ¨åŠ›å­¦ï¼Œå¿…é¡»åœ¨ç›®æ ‡æ¨¡å‹ä¸Šç›´æ¥è°ƒå‚**

#### ï¼ˆ3ï¼‰æ¶ˆèå®éªŒå…³é”®å‘ç°
| æŠ€æœ¯ | å½±å“ |
|------|------|
| åˆ†å¸ƒå¯¹é½ SFT | +11.91 pts on LiveCodeBench |
| éš¾åº¦æ„ŸçŸ¥æ•°æ®è¿‡æ»¤ | é¿å…æ—©æœŸæ¢¯åº¦æ¶ˆå¤±ï¼Œè®­ç»ƒæ›´ç¨³å®š |
| è½¨è¿¹å¤ç”¨ï¼ˆS=3 inner stepsï¼‰ | è®­ç»ƒæ•ˆç‡æå‡ 3Ã—ï¼Œæ”¶æ•›æ›´å¿« |
| Multi-task RL | é˜²æ­¢æ•°å­¦ä¼˜åŒ–å¯¼è‡´æŒ‡ä»¤éµå¾ªèƒ½åŠ›ä¸‹é™ |
| å–æ¶ˆé•¿åº¦æƒ©ç½š | æå‡éœ€è¦å¤šæ­¥æ¨ç†çš„ä»»åŠ¡è¡¨ç°ï¼ˆå¦‚ AIMEï¼‰|

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å‚æ•°è§„æ¨¡ä¸æ˜¯å†³å®šæ¨ç†èƒ½åŠ›çš„å”¯ä¸€å› ç´ **ï¼šé€šè¿‡ç³»ç»Ÿæ€§ä¼˜åŒ–ï¼Œ12.7B æ¨¡å‹å¯è¾¾åˆ°ç”šè‡³è¶…è¶Š 30â€“40B çº§åˆ«æ¨¡å‹çš„è¡¨ç°ã€‚
2. **åˆæˆæ•°æ®çš„è´¨é‡åœ¨äºâ€œåˆ†å¸ƒå¯¹é½â€è€Œéâ€œæ¥æºæƒå¨â€**ï¼šæ¥è‡ªæ›´å¤§æ¨¡å‹çš„æ•°æ®å¯èƒ½å› é£æ ¼ä¸åŒ¹é…è€Œæœ‰å®³ã€‚
3. **RLFT æˆåŠŸçš„å…³é”®åœ¨äºâ€œå¯æ§æ¢ç´¢â€**ï¼šéœ€ç²¾å¿ƒè®¾è®¡æ•°æ®éš¾åº¦ã€å¥–åŠ±ä¿¡å·å’Œè®­ç»ƒåŠ¨æ€ï¼Œå¦åˆ™ææ˜“å¯¼è‡´å´©æºƒã€‚
4. **é•¿ä¸Šä¸‹æ–‡è®­ç»ƒå¯è¡Œä¸”å¿…è¦**ï¼š64K ä¸Šä¸‹æ–‡å¯é€šè¿‡ hybrid parallelism + kernel ä¼˜åŒ–å®ç°ï¼Œä¸”å¯¹é•¿ç¨‹æ¨ç†è‡³å…³é‡è¦ã€‚
5. **å¯å¤ç°æ€§æœ¬èº«å°±æ˜¯ä¸€ç§è¿›æ­¥**ï¼šå®Œæ•´æŠ«éœ²å¤±è´¥æ¡ˆä¾‹ã€è°ƒå‚ç»éªŒã€åŸºç¡€è®¾æ–½é…ç½®ï¼Œæå¤§é™ä½äº†ç¤¾åŒºå¤ç°é—¨æ§›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡éªŒè¯ç¯å¢ƒ**ï¼šä»£ç æ‰§è¡Œã€æ•°å­¦éªŒè¯ç­‰ç¯èŠ‚è¦æ±‚å®Œå–„çš„æµ‹è¯•æ¡†æ¶ã€‚
- **å¯¹åˆå§‹ SFT æ¨¡å‹è¦æ±‚è¾ƒé«˜**ï¼šè‹¥åŸºç¡€æ¨¡å‹ä¸å…·å¤‡ä¸€å®šæ¨ç†èƒ½åŠ›ï¼ŒRLFT éš¾ä»¥å¯åŠ¨ã€‚
- **multi-task æƒé‡è°ƒé…æ•æ„Ÿ**ï¼šä¸åŒä»»åŠ¡é—´çš„é‡‡æ ·æ¯”ä¾‹å½±å“æœ€ç»ˆæ€§èƒ½å¹³è¡¡ã€‚
- **ä»éœ€è¾ƒå¼ºç®—åŠ›æ”¯æŒ**ï¼šè™½ä¼˜äºå¤§æ¨¡å‹ï¼Œä½†åœ¨ H100 é›†ç¾¤ä¸Šè®­ç»ƒ 64K ä¸Šä¸‹æ–‡ä»æœ‰é—¨æ§›ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°†æ­¤è®­ç»ƒèŒƒå¼æ¨å¹¿åˆ°æ›´å¤§æˆ–æ›´å°è§„æ¨¡æ¨¡å‹ï¼ˆscaling laws æ¢ç´¢ï¼‰
- è‡ªåŠ¨åŒ–éš¾åº¦è°ƒèŠ‚æœºåˆ¶ï¼ˆæ›¿ä»£äººå·¥è®¾å®š Î±/Î²ï¼‰
- å¼•å…¥æ›´å¤š agent-style ä»»åŠ¡ï¼ˆå¦‚ç½‘é¡µæ“ä½œã€API è°ƒç”¨ï¼‰
- æ„å»ºç«¯åˆ°ç«¯çš„å¼€æº RL è®­ç»ƒæ¡†æ¶ï¼Œé›†æˆ Liger Kernelã€SkyPilotã€vLLM ç­‰ç»„ä»¶

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> *Motif-2-12.7B-Reasoning è¯æ˜ï¼Œåœ¨æœ‰é™ç®—åŠ›ä¸‹ï¼Œé€šè¿‡â€œç³»ç»Ÿä¼˜åŒ– + åˆ†å¸ƒå¯¹é½ SFT + ç¨³å®š RLFTâ€çš„ç»„åˆæ‹³ï¼Œå°å‹å¼€æºæ¨¡å‹ä¹Ÿèƒ½åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šåª²ç¾ç”šè‡³è¶…è¶Šå¤§å‹é—­æºæ¨¡å‹ï¼Œä¸ºç¤¾åŒºæä¾›äº†æå…·ä»·å€¼çš„å®è·µè“å›¾ã€‚*

</details>

---

### 4. [AdaSD: Adaptive Speculative Decoding for Efficient Language Model Inference](https://arxiv.org/abs/2512.11280)

**Authors**: Kuan-Wei Lu, Ding-Yong Hong, Pangfeng Liu  
**Category**: cs.CL  
**Published**: 2025-12-15  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.11280v1  

#### Abstract
Large language models (LLMs) have achieved remarkable performance across a wide range of tasks, but their increasing parameter sizes significantly slow down inference. Speculative decoding mitigates this issue by leveraging a smaller draft model to predict candidate tokens, which are then verified b...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# AdaSD: Adaptive Speculative Decoding for Efficient Language Model Inference è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è™½ç„¶åœ¨å¤šç§ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†ç”±äºå‚æ•°é‡å·¨å¤§ï¼Œæ¨ç†è¿‡ç¨‹å˜å¾—éå¸¸ç¼“æ…¢ä¸”å†…å­˜å—é™ã€‚**Speculative Decoding** æ˜¯ä¸€ç§é€šè¿‡å¼•å…¥å°å‹ draft model é¢„æµ‹å€™é€‰ token æ¥åŠ é€Ÿæ¨ç†çš„æŠ€æœ¯ï¼Œä½†ç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- éœ€è¦é¢å¤–è®­ç»ƒ draft modelï¼›
- ä¾èµ–å¤§é‡è¶…å‚æ•°è°ƒä¼˜ï¼›
- æ¥å—æ ‡å‡†è¿‡äºä¸¥æ ¼æˆ–éœ€é¢„è®¾é˜ˆå€¼ï¼Œå½±å“æ•ˆç‡ä¸å‡†ç¡®æ€§å¹³è¡¡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šAdaSD
æœ¬æ–‡æå‡º **Adaptive Speculative Decoding (AdaSD)**ï¼Œä¸€ç§æ— éœ€è¶…å‚æ•°è°ƒä¼˜ã€å®Œå…¨è‡ªé€‚åº”çš„ speculative decoding æ–¹æ³•ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯åŠ¨æ€è°ƒæ•´ä¸¤ä¸ªå…³é”®å†³ç­–æœºåˆ¶ï¼š

- **Generation Threshold**ï¼šåŸºäº draft model è¾“å‡º token çš„ **Entropy** åŠ¨æ€å†³å®šä½•æ—¶åœæ­¢ç”Ÿæˆå€™é€‰ tokenã€‚
- **Verification Threshold**ï¼šåŸºäº draft å’Œ target model åˆ†å¸ƒä¹‹é—´çš„ **Jensen-Shannon Distance (JS Distance)** å†³å®šæ˜¯å¦æ¥å—å€™é€‰ tokenã€‚

è¿™ä¸¤ä¸ªé˜ˆå€¼åœ¨æ¨ç†è¿‡ç¨‹ä¸­å®æ—¶æ›´æ–°ï¼Œåˆ©ç”¨å†å²ç”Ÿæˆ token çš„ç»Ÿè®¡ä¿¡æ¯è¿›è¡Œåé¦ˆæ§åˆ¶ï¼Œä»è€Œå®ç°è‡ªé€‚åº”ä¼˜åŒ–ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | ä¼ ç»Ÿæ–¹æ³• | AdaSD |
|------|--------|-------|
| æ˜¯å¦éœ€è¦è®­ç»ƒ | æ˜¯ï¼ˆå¦‚ EAGLEã€Medusaï¼‰ | å¦ |
| æ˜¯å¦éœ€è¦è¶…å‚æ•°è°ƒä¼˜ | æ˜¯ï¼ˆå¦‚å›ºå®šé•¿åº¦ã€å›ºå®šé˜ˆå€¼ï¼‰ | å¦ï¼ˆå®Œå…¨è‡ªé€‚åº”ï¼‰ |
| å…¼å®¹æ€§ | å¤šæ•°éœ€ä¿®æ”¹æ¶æ„ | æ”¯æŒ off-the-shelf æ¨¡å‹ |
| å‡†ç¡®æ€§æŸå¤± | å¯èƒ½è¾ƒå¤§ï¼ˆå°¤å…¶æ”¾å®½æ¥å—æ¡ä»¶æ—¶ï¼‰ | æ§åˆ¶åœ¨ <2% |
| åŠ é€Ÿæ•ˆæœ | é€šå¸¸ 1.2â€“1.3x | æœ€é«˜è¾¾ **1.49x**ï¼ˆç›¸å¯¹ Vanillaï¼‰ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šAdaSD åœ¨ä¸ç‰ºç‰²å‡†ç¡®æ€§çš„å‰æä¸‹æ˜¾è‘—æå‡æ¨ç†é€Ÿåº¦ï¼Œä¸”æ— éœ€ä»»ä½•å…ˆéªŒåˆ†ææˆ–äººå·¥é…ç½®ï¼Œå…·å¤‡å¼ºé€šç”¨æ€§å’Œå®ç”¨æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåœ¨ä¸‰ä¸ªä»£è¡¨æ€§åŸºå‡†ä¸Šè¿›è¡Œï¼Œè¦†ç›–ä¸åŒä»»åŠ¡ç±»å‹ï¼š
- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼Œæµ‹è¯•æ¨ç†èƒ½åŠ›ï¼›
- **HumanEval**ï¼šç¼–ç¨‹ä»£ç ç”Ÿæˆä»»åŠ¡ï¼Œè¯„ä¼°é€»è¾‘ä¸è¯­æ³•æ­£ç¡®æ€§ï¼›
- **MMLU**ï¼šå¤šå­¦ç§‘é€‰æ‹©é¢˜ï¼Œè¡¡é‡çŸ¥è¯†å¹¿åº¦ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹å¯¹ç»„åˆ**ï¼š
  - `Llama 3.1 70B` / `Llama 3.1 8B`
  - `Llama 3.1 70B` / `Llama 3.2 1B`
  - `Qwen 2.5 72B` / `Qwen 2.5 7B`
- **ç¡¬ä»¶å¹³å°**ï¼š4Ã—NVIDIA A6000 GPUï¼Œä½¿ç”¨ Hugging Face Transformers æ¡†æ¶ï¼ˆv4.55ï¼‰
- **æœ€å¤§çª—å£å¤§å° W = 20**ï¼Œé˜²æ­¢æ— é™æ‰©å±•å€™é€‰åºåˆ—
- æ‰€æœ‰æ–¹æ³•å‡é‡‡ç”¨ sampling ç­–ç•¥ç”Ÿæˆ token

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **tks/sec** | æ¯ç§’å¤„ç†çš„ token æ•°é‡ï¼ˆååé‡ï¼‰ |
| **speedup** | ç›¸å¯¹äº Vanilla speculative decoding çš„åŠ é€Ÿæ¯” |
| **accuracy** | ä»»åŠ¡æœ€ç»ˆè¾“å‡ºçš„å‡†ç¡®ç‡ |
| **JSDist** | éªŒè¯é˜¶æ®µå¹³å‡ JS Distance |
| **#cand / #match / AccRate** | ç”Ÿæˆå€™é€‰æ•°ã€è¢«æ¥å—æ•°ã€æ¥å—ç‡ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **Vanilla** | æ ‡å‡† speculative decodingï¼Œå›ºå®šå€™é€‰é•¿åº¦ä¸º 5 |
| **AssistedGen** | Hugging Face å†…ç½®è¾…åŠ©ç”Ÿæˆï¼ŒåŸºäº DISCO æ€æƒ³ï¼Œæ— ç›‘ç£è‡ªé€‚åº”é•¿åº¦ |
| **Gen-Only** | AdaSD çš„å˜ä½“ï¼Œä»…å¯ç”¨ generation threshold |
| **Verify-Only** | AdaSD çš„å˜ä½“ï¼Œä»…å¯ç”¨ verification threshold |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆä»¥ Llama 3.1 70B/8B ä¸ºä¾‹ï¼‰

| æ–¹æ³• | GSM8K (tks/s) | Speedup | Accuracy | HumanEval (tks/s) | Speedup |
|------|---------------|---------|----------|------------------|---------|
| Vanilla | 13.89 | 1.00Ã— | 0.945 | 14.32 | 1.00Ã— |
| AssistedGen | 16.06 | 1.16Ã— | 0.944 | 18.14 | 1.27Ã— |
| **AdaSD** | **17.51** | **1.26Ã—** | **0.937** | **18.84** | **1.32Ã—** |

> âš¡ åœ¨ Llama æ¨¡å‹ä¸Šï¼ŒAdaSD å®ç°æœ€é«˜ **49% çš„åŠ é€Ÿ**ï¼ˆè§ Llama 3.1 70B/1B ç»„åˆï¼‰ï¼ŒåŒæ—¶ç²¾åº¦ä¸‹é™å°äº 2%ã€‚

### ä¸å…¶ä»–æ¨¡å‹ç»„åˆçš„è¡¨ç°
- åœ¨ `Qwen` æ¨¡å‹ä¸Šï¼ŒAdaSD è¡¨ç°ç•¥é€Šäº AssistedGenï¼Œä½†ä»ä¼˜äº Vanillaã€‚
- åŸå› åˆ†æï¼ˆè§è®ºæ–‡ 5.2 èŠ‚ï¼‰ï¼š
  - AdaSD çš„ generation threshold å¯¼è‡´ç”Ÿæˆæ›´é•¿çš„å€™é€‰åºåˆ—ï¼ˆ#cand æ›´é«˜ï¼‰ï¼Œå¢åŠ äº† draft model å¼€é”€ï¼›
  - AssistedGen è®¾è®¡ç›®æ ‡å…¼é¡¾æ•ˆç‡ä¸æ¥å—ç‡ï¼Œåœ¨çŸ­åºåˆ—åœºæ™¯ä¸­æ›´å…·ä¼˜åŠ¿ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

| æ–¹æ³• | GSM8K Speedup | HumanEval Speedup | è¯´æ˜ |
|------|----------------|--------------------|------|
| Gen-Only | 1.17Ã— | 1.26Ã— | ä»…ç”¨ entropy æ§åˆ¶ç”Ÿæˆé•¿åº¦ï¼Œå·²æ˜¾è‘—æé€Ÿ |
| Verify-Only | 1.04Ã— | 1.01Ã— | å•ç‹¬ä½¿ç”¨ JS Distance æ•ˆæœæœ‰é™ |
| **AdaSD (å®Œæ•´ç‰ˆ)** | **1.26Ã—** | **1.32Ã—** | **åŒé˜ˆå€¼ååŒä½œç”¨å¸¦æ¥é¢å¤– 13% æå‡** |

> ğŸ” å‘ç°ï¼š**generation threshold æ˜¯ä¸»è¦åŠ é€Ÿæ¥æº**ï¼Œè€Œ verification threshold è¿›ä¸€æ­¥æå‡äº†çµæ´»æ€§å’Œé²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç†µï¼ˆEntropyï¼‰å¯æœ‰æ•ˆé¢„æµ‹ draft token çš„å¯æ¥å—æ€§**ï¼šé«˜ç†µ token æ›´å¯èƒ½è¢«æ‹’ç»ï¼Œé€‚åˆç”¨äºç»ˆæ­¢ç”Ÿæˆã€‚
2. **JS Distance æ˜¯ç¨³å®šå¯é çš„åˆ†å¸ƒå·®å¼‚åº¦é‡**ï¼šç›¸æ¯” KL æˆ– Cross-Entropyï¼Œå®ƒæœ‰ç•Œä¸”å¯¹ç§°ï¼Œé€‚åˆä½œä¸ºåŠ¨æ€éªŒè¯é˜ˆå€¼çš„åŸºç¡€ã€‚
3. **åŒé˜ˆå€¼è”åˆè‡ªé€‚åº”æœºåˆ¶æ˜¾è‘—ä¼˜äºå•ä¸€ç­–ç•¥**ï¼šAdaSD å°† generation ä¸ verification å†³ç­–ç»Ÿä¸€å»ºæ¨¡ï¼Œå®ç°äº†æ•ˆç‡ä¸ç²¾åº¦çš„æœ€ä½³æƒè¡¡ã€‚
4. **æ— éœ€è°ƒå‚å³å¯è¾¾åˆ°æœ€ä¼˜æ€§èƒ½**ï¼šAdaSD å®Œå…¨ä¾èµ–è¿è¡Œæ—¶åé¦ˆè‡ªåŠ¨è°ƒèŠ‚ï¼Œé¿å…äº†ç¹ççš„æ‰‹åŠ¨æœç´¢ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **è¦æ±‚ draft ä¸ target æ¨¡å‹å…±äº«ç›¸åŒ vocabulary**  
   - è‹¥ token æ˜ å°„ä¸ä¸€è‡´ï¼Œåˆ™æ— æ³•è®¡ç®— entropy å’Œ JS Distanceã€‚
2. **ç¼ºä¹ç†æƒ³çš„ä¸­å°è§„æ¨¡å…¼å®¹æ¨¡å‹å¯¹**  
   - å½“å‰ä¸»æµæ¨¡å‹å®¶æ—ä¸­ï¼Œå°æ¨¡å‹ï¼ˆ<1Bï¼‰å¸¸ä½¿ç”¨ä¸åŒçš„ tokenizer æˆ–æ¶æ„è®¾è®¡ï¼Œé™åˆ¶äº† AdaSD çš„é€‚ç”¨èŒƒå›´ã€‚
3. **åœ¨æçŸ­è¾“å‡ºä»»åŠ¡ä¸­åŠ é€Ÿæœ‰é™**  
   - å¦‚ MMLU å¤šé€‰é¢˜ä»…éœ€è¾“å‡ºå°‘é‡ tokenï¼Œspeculative decoding æœ¬èº«å¢ç›Šè¾ƒå°ï¼ˆä»…çº¦ 8% åŠ é€Ÿï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼•å…¥æ›´å¤šä¿¡å·ï¼ˆå¦‚ attention scoreã€feature uncertaintyï¼‰æ”¹è¿› generation thresholdï¼›
- è®¾è®¡æ›´æ™ºèƒ½çš„ verification threshold æ›´æ–°ç­–ç•¥ï¼ˆå¦‚åŠ æƒç§»åŠ¨å¹³å‡ã€åºåˆ—çº§ç»Ÿè®¡ï¼‰ï¼›
- æ¢ç´¢è·¨ vocabulary çš„å¯¹é½æœºåˆ¶ï¼Œæ‰©å¤§æ¨¡å‹å¯¹é€‰æ‹©ç©ºé—´ï¼›
- ç»“åˆ early-exit æˆ– multi-exit æ¶æ„è¿›ä¸€æ­¥é™ä½ draft model å¼€é”€ã€‚

---

## æ€»ç»“
âœ… **AdaSD æ˜¯ä¸€ç§é«˜æ•ˆã€å®ç”¨ã€å…è°ƒå‚çš„ speculative decoding æ–°èŒƒå¼**ã€‚å®ƒé€šè¿‡ entropy å’Œ JS Distance å®ç°äº† generation ä¸ verification çš„åŒé‡è‡ªé€‚åº”æ§åˆ¶ï¼Œåœ¨å¤šä¸ª benchmark ä¸Šå®ç°äº†é«˜è¾¾ **49% çš„åŠ é€Ÿ**ï¼Œä¸”ç²¾åº¦æŸå¤±æ§åˆ¶åœ¨ **2% ä»¥å†…**ã€‚è¯¥æ–¹æ³•æ— éœ€è®­ç»ƒã€å…¼å®¹ç°æˆæ¨¡å‹ï¼Œä¸ºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆéƒ¨ç½²æä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚

</details>

---

### 5. [A Multi-Criteria Automated MLOps Pipeline for Cost-Effective Cloud-Based Classifier Retraining in Response to Data Distribution Shifts](https://arxiv.org/abs/2512.11541)

**Authors**: Emmanuel K. Katalay, David O. Dimandja, Jordan F. Masakuna  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.11541v1  

#### Abstract
The performance of machine learning (ML) models often deteriorates when the underlying data distribution changes over time, a phenomenon known as data distribution drift. When this happens, ML models need to be retrained and redeployed. ML Operations (MLOps) is often manual, i.e., humans trigger the...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Multi-Criteria Automated MLOps Pipeline for Cost-Effective Cloud-Based Classifier Retraining in Response to Data Distribution Shifts

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å› æ•°æ®åˆ†å¸ƒæ¼‚ç§»ï¼ˆdata distribution driftï¼‰å¯¼è‡´æ€§èƒ½ä¸‹é™**çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆã€‚ä¼ ç»Ÿåšæ³•ä¾èµ–äººå·¥è§¦å‘æ¨¡å‹é‡è®­ç»ƒï¼ˆretrainingï¼‰ï¼Œæ•ˆç‡ä½ä¸”æˆæœ¬é«˜ï¼›è€Œé¢‘ç¹æˆ–ä¸å¿…è¦çš„é‡è®­ç»ƒåˆä¼šé€ æˆ**äº‘èµ„æºæµªè´¹å’Œé«˜æ˜‚è®¡ç®—å¼€é”€**ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…è®¾è®¡å¹¶å®ç°äº†ä¸€ä¸ª**å¤šå‡†åˆ™è‡ªåŠ¨åŒ–çš„MLOps pipelineï¼ˆAuto-MLOpsï¼‰**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åˆ©ç”¨å¤šç§ç»Ÿè®¡æŒ‡æ ‡è”åˆæ£€æµ‹æ•°æ®åˆ†å¸ƒå˜åŒ–ï¼›
- åªæœ‰å½“æ£€æµ‹åˆ°æ˜¾è‘—æ¼‚ç§»æ—¶æ‰è§¦å‘æ¨¡å‹é‡è®­ç»ƒï¼›
- åœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œæœ€å°åŒ–äº‘è®¡ç®—æˆæœ¬ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š
1. **å¤šå‡†åˆ™æ¼‚ç§»æ£€æµ‹æœºåˆ¶ï¼ˆMulti-criteria drift detectionï¼‰**  
   èåˆå¤šä¸ªç»Ÿè®¡åº¦é‡æ„å»ºç»¼åˆæ¼‚ç§»è¯„åˆ†ï¼ˆDrift Score, DSï¼‰ï¼š
   - Kolmogorov-Smirnov (KS) Test
   - Kullback-Leibler (KL) Divergence
   - Population Stability Index (PSI)
   - Maximum Mean Discrepancy (MMD)
   - Accuracy å’Œ F1-score çš„å˜åŒ–ï¼ˆÎ”Acc, Î”F1ï¼‰
   
   ç»¼åˆå¾—åˆ†å…¬å¼ä¸ºï¼š
   $$
   DS = w_1 D_{ks} + w_2 D_{KL} + w_3 PSI + w_4 MMD + w_5 |\Delta Acc| + w_6 |\Delta F1|
   $$
   å½“ $DS > T$ï¼ˆé¢„è®¾é˜ˆå€¼ï¼‰æ—¶è§¦å‘é‡è®­ç»ƒã€‚

2. **ç§‘å­¦ä¸¥è°¨çš„è‡ªåŠ¨åŒ–å†³ç­–æ¡†æ¶**  
   å°†ç»Ÿè®¡æ£€éªŒä¸æ¨¡å‹æ€§èƒ½ç›‘æ§ç»“åˆï¼Œå½¢æˆå¯å®¡è®¡ã€å¯éªŒè¯çš„é‡è®­ç»ƒè§¦å‘é€»è¾‘ï¼Œè¶…è¶Šç®€å•çš„å‡†ç¡®ç‡ç›‘æ§ã€‚

3. **æˆæœ¬æ•ˆç›Šå¯¼å‘çš„è®¾è®¡ç†å¿µ**  
   æ˜ç¡®å°†**äº‘èµ„æºæ¶ˆè€—å’Œæ“ä½œæˆæœ¬**ä½œä¸ºä¼˜åŒ–ç›®æ ‡ä¹‹ä¸€ï¼Œå®ç°äº†â€œæ€§èƒ½ä¿æŒâ€ä¸â€œæˆæœ¬æ§åˆ¶â€çš„å¹³è¡¡ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ FIXED / NAIVEï¼‰ | æœ¬æ–‡ Auto-MLOps |
|--------|----------------------------|----------------|
| è§¦å‘æœºåˆ¶ | å›ºå®šå‘¨æœŸ æˆ– å•ä¸€æŒ‡æ ‡è§¦å‘ | å¤šæŒ‡æ ‡èåˆ + åŠ æƒå†³ç­– |
| æˆæœ¬æ§åˆ¶ | å·®ï¼ˆé¢‘ç¹æ— æ„ä¹‰é‡è®­ï¼‰ | å¼ºï¼ˆä»…å¿…è¦æ—¶é‡è®­ï¼‰ |
| æ€§èƒ½ç¨³å®šæ€§ | éšæ¼‚ç§»åŠ å‰§æ˜æ˜¾ä¸‹é™ | æ›´ç¨³å®šï¼ŒæŠ—æ¼‚ç§»èƒ½åŠ›å¼º |
| è‡ªåŠ¨åŒ–ç¨‹åº¦ | æœ‰é™æˆ–éœ€æ‰‹åŠ¨å¹²é¢„ | å…¨æµç¨‹ CI/CD è‡ªåŠ¨åŒ– |
| å¯è§£é‡Šæ€§ | ä½ï¼ˆä¸ºä½•é‡è®­ä¸æ˜ç¡®ï¼‰ | é«˜ï¼ˆåŸºäºç»Ÿè®¡è¯æ®ï¼‰ |

> ğŸ’¡ **æ€»ç»“ä¼˜åŠ¿**ï¼šç›¸æ¯”ä¼ ç»Ÿçš„å›ºå®šå‘¨æœŸé‡è®­ç»ƒï¼ˆFIXEDï¼‰æˆ–ç®€å•æ¼‚ç§»è§¦å‘ï¼ˆNAIVEï¼‰ï¼ŒAuto-MLOps åœ¨ç»´æŒç›¸åŒé«˜æ°´å¹³å‡†ç¡®æ€§ï¼ˆ~0.75ï¼‰çš„å‰æä¸‹ï¼Œæ˜¾è‘—é™ä½äº†é‡è®­ç»ƒé¢‘ç‡å’Œäº‘æˆæœ¬ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåœ¨å¤šä¸ªåŸºå‡†å¼‚å¸¸æ£€æµ‹æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œæ¶µç›–ç½‘ç»œå…¥ä¾µã€é‡‘èæ¬ºè¯ˆã€åŒ»ç–—ä¿¡å·ç­‰é¢†åŸŸï¼š

| æ•°æ®é›† | æ ·æœ¬æ•° | å±æ€§æ•° | å¼‚å¸¸æ¯”ä¾‹ (%) |
|-------|--------|--------|--------------|
| CICIOT [19] | 416,985 | 41 | 45% |
| CREDIT24 | 234,333 | 30 | 0.2% |
| ECG [10] | 4,998 | 140 | 58% |
| IDSS221 | 430,256 | 95 | 43% |
| KITSUNE18 | 210,171 | 116 | 23% |
| MVTec3 | 5,354 | 1,048,576 | 58% |
| Visa [26] | 10,821 | 95 | 11% |

è¿™äº›æ•°æ®é›†å…·æœ‰å¤šæ ·æ€§ï¼Œè¦†ç›–ä¸åŒè§„æ¨¡ã€ç»´åº¦å’Œä»»åŠ¡åœºæ™¯ï¼Œå¢å¼ºäº†å®éªŒæ³›åŒ–èƒ½åŠ›ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šä½¿ç”¨ Auto-Encoderï¼ˆAEï¼‰ä½œä¸ºåˆ†ç±»å™¨ï¼ˆç”¨äºå¼‚å¸¸æ£€æµ‹ï¼‰
- **è¶…å‚æ•°é…ç½®**ï¼š
  - Weight decay: 1e-6
  - Batch size: 64
  - Epochs: 100
  - Early stopping patience: 5
  - Learning rate: 1e-3
  - Optimizer: Adam
- **æ¨¡æ‹Ÿç¯å¢ƒ**ï¼šé€šè¿‡é€æ­¥å¼•å…¥æ•°æ®åˆ†å¸ƒå˜åŒ–æ¥æ¨¡æ‹ŸçœŸå®ä¸–ç•Œä¸­çš„ drift progressionã€‚

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
1. **Accuracyï¼ˆå‡†ç¡®ç‡ï¼‰**
2. **Retraining Frequencyï¼ˆé‡è®­ç»ƒé¢‘ç‡ï¼‰**
3. **Cloud Costï¼ˆäº‘æˆæœ¬ï¼‰**
4. **Performance Stabilityï¼ˆæ€§èƒ½ç¨³å®šæ€§ï¼‰**

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
å…±æ¯”è¾ƒå››ç§ç­–ç•¥ï¼š
1. **STATIC**ï¼šä»ä¸é‡è®­ç»ƒï¼ˆæ— ä»»ä½•æ›´æ–°ï¼‰
2. **FIXED**ï¼šæŒ‰å›ºå®šå‘¨æœŸï¼ˆå¦‚æ¯å‘¨ï¼‰é‡è®­ç»ƒï¼Œæ— è§†æ˜¯å¦å‘ç”Ÿ drift
3. **NAIVE**ï¼šä¸€æ—¦æ£€æµ‹åˆ°æ¼‚ç§»å³é‡è®­ç»ƒï¼Œæ— æˆæœ¬ä¼˜åŒ–
4. **Auto-MLOpsï¼ˆæœ¬æ–‡æ–¹æ³•ï¼‰**ï¼šåŸºäºåŠ æƒå¤šå‡†åˆ™æ¼‚ç§»è¯„åˆ†å†³å®šæ˜¯å¦é‡è®­ç»ƒ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 2ï¼‰

| æ¨¡å‹ | Accuracy (mean Â± std) | Cloud Cost (mean Â± std) | Retraining Frequency (mean Â± std) |
|------|------------------------|--------------------------|------------------------------------|
| STATIC | 0.69 Â± 0.2 | 54.8 Â± 5.6 | 0 Â± 0 |
| FIXED | 0.75 Â± 0.02 | 160.6 Â± 10.5 | 3 Â± 0 |
| NAIVE | 0.75 Â± 0.03 | 130.5 Â± 14.9 | 4.3 Â± 1.9 |
| **Auto-MLOps** | **0.75 Â± 0.03** | **108.1 Â± 14.3** | **1.4 Â± 1.2** |

### ğŸ” ç»“æœåˆ†æ
- æ‰€æœ‰åŠ¨æ€æ–¹æ³•ï¼ˆFIXED, NAIVE, Auto-MLOpsï¼‰å‡ä¼˜äº STATICï¼Œè¯´æ˜åº”å¯¹ drift æ˜¯å¿…è¦çš„ã€‚
- FIXED å’Œ NAIVE è™½ç„¶ä¿æŒäº†é«˜ accuracyï¼ˆ~0.75ï¼‰ï¼Œä½†ä»£ä»·é«˜æ˜‚ï¼š
  - FIXED å¹³å‡æ¯è½®éƒ½é‡è®­ç»ƒï¼ˆé¢‘ç‡=3ï¼‰ï¼Œæˆæœ¬é«˜è¾¾ **160.6**
  - NAIVE æ›´æ¿€è¿›ï¼ˆé¢‘ç‡=4.3ï¼‰ï¼Œæˆæœ¬ä¹Ÿæ›´é«˜ï¼ˆ130.5ï¼‰
- **Auto-MLOps åœ¨ accuracy ä¸ŠæŒå¹³æœ€ä¼˜æ°´å¹³ï¼ˆ0.75ï¼‰**ï¼Œä½†ï¼š
  - é‡è®­ç»ƒé¢‘ç‡æœ€ä½ï¼ˆä»… 1.4 æ¬¡ï¼‰
  - äº‘æˆæœ¬æœ€ä½ï¼ˆ**108.1**ï¼‰ï¼Œæ¯” FIXED èŠ‚çœçº¦ **33%**ï¼Œæ¯” NAIVE èŠ‚çœçº¦ **17%**

### ğŸ“‰ å›¾å½¢åŒ–ç»“æœæ”¯æŒï¼ˆFigure 2 & 3ï¼‰
- **Figure 2** æ˜¾ç¤ºéšç€ drift ä¸¥é‡æ€§å¢åŠ ï¼ŒSTATIC å‡†ç¡®ç‡æ€¥å‰§ä¸‹é™ï¼Œè€Œ Auto-MLOps ä¿æŒå¹³ç¨³ã€‚
- **Figure 3** è¡¨æ˜ Auto-MLOps å®ç°äº†æœ€ä½³çš„â€œç²¾åº¦ vs æˆæœ¬â€æƒè¡¡æ›²çº¿ï¼Œåœ¨è½»åº¦ drift ä¸‹å»¶è¿Ÿé‡è®­ç»ƒè€Œä¸å½±å“æ€§èƒ½ã€‚

> â— **æ¶ˆèå®éªŒæœªæ˜ç¡®æåŠ**ï¼Œä½†æ–‡ä¸­å¼ºè°ƒäº†å¤šæŒ‡æ ‡èåˆçš„é‡è¦æ€§ï¼Œå¹¶æŒ‡å‡ºæƒé‡ $w_i$ æ¥è‡ªç»éªŒç ”ç©¶ï¼Œæš—ç¤ºå¯é€šè¿‡è°ƒå‚è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **å¤šå‡†åˆ™æ¼‚ç§»æ£€æµ‹æ˜¾è‘—æå‡ MLOps æ•ˆç‡**  
   ç»“åˆ PSIã€KLã€MMD ç­‰å¤šç§ç»Ÿè®¡æŒ‡æ ‡ï¼Œèƒ½å¤Ÿæ›´ç²¾å‡†è¯†åˆ«çœŸæ­£éœ€è¦é‡è®­ç»ƒçš„æ—¶åˆ»ï¼Œé¿å…è¯¯è§¦å‘ã€‚

2. **è‡ªåŠ¨åŒ– â‰  é¢‘ç¹é‡è®­ç»ƒï¼Œè€Œæ˜¯æ™ºèƒ½è°ƒåº¦**  
   Auto-MLOps è¯æ˜ï¼š**æ›´å°‘çš„ retraining æ¬¡æ•° + æ›´é«˜çš„æ€§èƒ½ç¨³å®šæ€§** æ˜¯å¯è¡Œçš„ï¼Œæ‰“ç ´äº†â€œé¢‘ç¹æ›´æ–°=æ›´å¥½æ€§èƒ½â€çš„è¯¯åŒºã€‚

3. **æˆæœ¬ä¸æ€§èƒ½å¯ä»¥å…¼å¾—**  
   åœ¨ accuracy ä¸ä½äº FIXED/NAIVE çš„å‰æä¸‹ï¼Œ**é™ä½ retraining é¢‘ç‡ 50%ä»¥ä¸Šï¼ŒèŠ‚çœäº‘æ”¯å‡ºè¾¾ 30%**ï¼Œå¯¹å¤§è§„æ¨¡éƒ¨ç½²æå…·ä»·å€¼ã€‚

4. **æ¨åŠ¨ MLOps å‘åŸåˆ™é©±åŠ¨ã€å¯å®¡è®¡æ–¹å‘å‘å±•**  
   æä¾›äº†åŸºäºç»Ÿè®¡è¯æ®çš„ retraining å†³ç­–è·¯å¾„ï¼Œä½¿æ¨¡å‹ç»´æŠ¤è¿‡ç¨‹æ›´åŠ é€æ˜ã€å¯ä¿¡ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **æ¼‚ç§»æ£€æµ‹æ•æ„Ÿæ€§ä¾èµ–äºç»Ÿè®¡æ–¹æ³•çš„é€‰æ‹©å’Œå‚æ•°è®¾å®š**ï¼Œå¯èƒ½å­˜åœ¨ false positiveï¼ˆè¯¯æŠ¥ï¼‰å¯¼è‡´ä¸å¿…è¦çš„é‡è®­ç»ƒã€‚
2. æƒé‡ $w_i$ å’Œé˜ˆå€¼ $T$ ä¾èµ–ç»éªŒè®¾ç½®ï¼Œç¼ºä¹è‡ªé€‚åº”è°ƒèŠ‚æœºåˆ¶ã€‚
3. å½“å‰å®éªŒé›†ä¸­åœ¨ anomaly detection åœºæ™¯ï¼Œå°šæœªå¹¿æ³›éªŒè¯äºå…¶ä»– classification ä»»åŠ¡ã€‚
4. æœªè€ƒè™‘å®æ—¶äº‘ä»·æ ¼æ³¢åŠ¨ç­‰åŠ¨æ€ç»æµå› ç´ ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. æ¢ç´¢ **Reinforcement Learning-based retraining policy**ï¼Œè®©ç³»ç»Ÿä»å†å²éƒ¨ç½²ä¸­å­¦ä¹ æœ€ä¼˜è°ƒåº¦ç­–ç•¥ã€‚
2. å¼•å…¥æ›´å¤æ‚çš„ **cost model**ï¼Œæ•´åˆå®æ—¶ cloud pricingã€spot instances ç­‰å› ç´ ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ”¯å‡ºã€‚
3. æ‰©å±•è‡³æ›´å¤šç±»å‹çš„ driftï¼ˆå¦‚ concept driftã€label driftï¼‰å’Œæ¨¡å‹ç±»å‹ï¼ˆå¦‚ Transformersï¼‰ã€‚
4. å¼€å‘å¯è§†åŒ–å·¥å…·ï¼Œå¸®åŠ©è¿ç»´äººå‘˜ç†è§£ drift æ¥æºåŠ retraining å†³ç­–ä¾æ®ã€‚

---

## âœ… æ€»ç»“
è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§**é¢å‘æˆæœ¬ä¼˜åŒ–çš„å¤šå‡†åˆ™è‡ªåŠ¨åŒ– MLOps pipelineï¼ˆAuto-MLOpsï¼‰**ï¼Œæœ‰æ•ˆè§£å†³äº†æ•°æ®åˆ†å¸ƒæ¼‚ç§»ä¸‹çš„æ¨¡å‹é€€åŒ–é—®é¢˜ã€‚é€šè¿‡èåˆå¤šç§ç»Ÿè®¡æµ‹è¯•æ„å»º drift scoreï¼Œä»…åœ¨å¿…è¦æ—¶è§¦å‘é‡è®­ç»ƒï¼Œåœ¨å¤šä¸ª benchmark æ•°æ®é›†ä¸ŠéªŒè¯äº†å…¶åœ¨**ä¿æŒé«˜ accuracy çš„åŒæ—¶æ˜¾è‘—é™ä½äº‘æˆæœ¬å’Œ retraining é¢‘ç‡**çš„èƒ½åŠ›ã€‚è¿™ä¸€å·¥ä½œä¸ºæ„å»ºå¯æŒç»­ã€é«˜æ•ˆã€å¯å®¡è®¡çš„å·¥ä¸šçº§ ML ç³»ç»Ÿæä¾›äº†é‡è¦å®è·µèŒƒå¼ã€‚

</details>

---

### 6. [Enhanced Pruning for Distributed Closeness Centrality under Multi-Packet Messaging](https://arxiv.org/abs/2512.11512)

**Authors**: Patrick D. Manya, Eugene M. Mbuyi, Gothy T. Ngoie, Jordan F. Masakuna  
**Category**: cs.DC  
**Published**: 2025-12-15  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.11512v1  

#### Abstract
Identifying central nodes using closeness centrality is a critical task in analyzing large-scale complex networks, yet its decentralized computation remains challenging due to high communication overhead. Existing distributed approximation techniques, such as pruning, often fail to fully mitigate th...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Enhanced Pruning for Distributed Closeness Centrality under Multi-Packet Messaging*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨å¤§è§„æ¨¡åˆ†å¸ƒå¼ç½‘ç»œä¸­ï¼Œ**closeness centrality** çš„å»ä¸­å¿ƒåŒ–è®¡ç®—é¢ä¸´ä¸¥é‡çš„é€šä¿¡å¼€é”€é—®é¢˜ã€‚ç°æœ‰çš„åˆ†å¸ƒå¼è¿‘ä¼¼æ–¹æ³•ï¼ˆå¦‚ pruningï¼‰è™½ç„¶èƒ½å‡å°‘éƒ¨åˆ†é€šä¿¡é‡ï¼Œä½†åœ¨é«˜æ•°æ®æµé‡ç¯å¢ƒä¸‹ï¼Œå°¤å…¶æ˜¯é‡‡ç”¨ **multi-packet messaging** æ—¶ï¼Œæ¶ˆæ¯æ•°é‡æ¿€å¢ï¼Œå¯¼è‡´ç½‘ç»œæ‹¥å¡ã€å»¶è¿Ÿå¢åŠ å’Œæ•°æ®ä¸¢å¤±é£é™©ä¸Šå‡ã€‚

è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³ **pruning æ–¹æ³•åœ¨ multi-packet messaging åœºæ™¯ä¸‹çš„é€šä¿¡ç“¶é¢ˆé—®é¢˜**ï¼Œæå‡å…¶åœ¨å¤§å‹å¤æ‚ç½‘ç»œä¸­çš„å¯æ‰©å±•æ€§å’Œæ•ˆç‡ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…å¯¹ Masakuna ç­‰äººæå‡ºçš„åŸå§‹ pruning æ–¹æ³• [22] è¿›è¡Œå¢å¼ºï¼Œæå‡ºäº†ä¸€ç§é€‚ç”¨äº **multi-packet messaging** çš„æ”¹è¿›å‹åˆ†å¸ƒå¼å‰ªæç­–ç•¥ï¼Œæ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **å¤šåŒ…æ¶ˆæ¯æ•´åˆæœºåˆ¶ï¼ˆmulti-packet messaging integrationï¼‰**  
  å…è®¸èŠ‚ç‚¹å°†å¤šä¸ªå°æ¶ˆæ¯æ‰“åŒ…æˆæ›´å¤§çš„æ•°æ®å—è¿›è¡Œä¼ è¾“ï¼Œåˆ©ç”¨ **sliding window åè®®ï¼ˆGo-Back-N ARQï¼‰** å®ç°é«˜æ•ˆã€å¯é çš„æ•°æ®ä¼ è¾“ï¼Œé™ä½å•ä½ä¿¡æ¯çš„é€šä¿¡å¼€é”€ã€‚

- **é€šä¿¡è½®æ¬¡ä¼˜åŒ–ä¸å‘é€æŠ‘åˆ¶æœºåˆ¶**  
  ä¿®æ”¹ç®—æ³•é€»è¾‘ï¼Œä½¿æŸäº›ä½ä¸­å¿ƒæ€§èŠ‚ç‚¹ï¼ˆå¦‚å¶å­èŠ‚ç‚¹ï¼‰åœ¨æ•´ä¸ªé€šä¿¡é˜¶æ®µæœ€å¤šåªå‘é€ $D-2$ è½®æ¶ˆæ¯ï¼ˆè€ŒéåŸå§‹çš„ $D$ è½®ï¼‰ï¼Œç”šè‡³å®Œå…¨ä¸ä¸»åŠ¨å‘é€æ¶ˆæ¯ï¼Œä»è€Œæ˜¾è‘—å‡å°‘æ•´ä½“æ¶ˆæ¯æ•°ã€‚

- **éä¸­å¿ƒèŠ‚ç‚¹çš„é€šä¿¡è¿‡è½½é™åˆ¶æŠ€æœ¯**  
  é’ˆå¯¹â€œå¯å‰ªæâ€ä½†å°šæœªè¢«é‚»å±…è¯†åˆ«ä¸ºå‰ªæçŠ¶æ€çš„èŠ‚ç‚¹ï¼Œè®¾è®¡äº†è½»é‡çº§åè°ƒæœºåˆ¶ï¼Œåœ¨ä¸å½±å“ç²¾åº¦çš„å‰æä¸‹æœ€å°åŒ–å…¶é€šä¿¡è´Ÿæ‹…ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | åŸå§‹ pruning æ–¹æ³• [22] | æœ¬æ–‡å¢å¼ºæ–¹æ³• |
|------|------------------------|-------------|
| **æ¶ˆæ¯æ€»æ•°** | è¾ƒé«˜ï¼Œå°¤å…¶åœ¨ multi-packet ä¸‹æ›´ä¸¥é‡ | å‡å°‘ 5%-15%ï¼Œæœ‰æ•ˆç¼“è§£é€šä¿¡å‹åŠ› |
| **è¿è¡Œæ—¶é—´** | å—é™äºé¢‘ç¹çš„å°åŒ…äº¤æ¢ | æ˜¾è‘—ç¼©çŸ­ï¼Œå°¤å…¶åœ¨å¤§ç½‘ç»œä¸­ |
| **æ•°æ®å®Œæ•´æ€§** | å•åŒ…æ˜“ä¸¢åŒ…ï¼Œå½±å“æ”¶æ•› | å¤šåŒ…åˆ†ç‰‡ + ARQ æå‡é²æ£’æ€§ |
| **é€‚ç”¨åœºæ™¯** | å°è§„æ¨¡æˆ–ä½å¸¦å®½ç¯å¢ƒ | æ›´é€‚åˆå¤§è§„æ¨¡ã€é«˜ååç½‘ç»œ |
| **å†…å­˜/æœ¬åœ°å¼€é”€** | è¾ƒä½ | ç•¥æœ‰å¢åŠ ï¼ˆåˆç†æƒè¡¡ï¼‰ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼šåœ¨ä¿æŒåŸæœ‰ pruning æ–¹æ³•è¿‘ä¼¼ç²¾åº¦çš„åŸºç¡€ä¸Šï¼Œé€šè¿‡ç»“æ„åŒ–æ”¯æŒ multi-packet messagingï¼Œå®ç°äº†æ›´é«˜çš„é€šä¿¡æ•ˆç‡å’Œæ›´å¼ºçš„å®ç”¨æ€§ï¼Œç‰¹åˆ«é€‚ç”¨äºè½¦è½½ç½‘ç»œã€ç§»åŠ¨è‡ªç»„ç»‡ç½‘ç»œï¼ˆMANETsï¼‰ã€ç›‘æ§ç³»ç»Ÿç­‰é«˜åŠ¨æ€ã€å¤§æ•°æ®é‡åœºæ™¯ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåŸºäºä¸¤ç±»å›¾ç»“æ„ï¼š

#### ï¼ˆ1ï¼‰éšæœºç”Ÿæˆç½‘ç»œï¼ˆ100ä¸ªï¼‰
- æ„å»ºæ–¹å¼ï¼šåœ¨ 250Ã—250 ç½‘æ ¼ä¸Šéšæœºé‡‡æ · $N \in [100, 2000]$ ä¸ªèŠ‚ç‚¹
- è¿æ¥è§„åˆ™ï¼šæ¬§æ°è·ç¦» < é€šä¿¡èŒƒå›´ $d=10$ åˆ™è¿è¾¹
- å›¾å±æ€§èŒƒå›´ï¼š
  - è¾¹æ•°ï¼š[100, 4000]
  - ç›´å¾„ï¼ˆDiameterï¼‰ï¼š[30, 68]ï¼ˆè§ Figure 1ï¼‰

#### ï¼ˆ2ï¼‰çœŸå®ä¸–ç•Œç½‘ç»œï¼ˆ35ä¸ªï¼‰
åŒ…å«ä»¥ä¸‹ä»£è¡¨æ€§ç½‘ç»œï¼š
- **Facebook artist network**ï¼ˆè‰ºæœ¯å®¶ç¤¾äº¤å…³ç³»ï¼‰
- **Phenomenology collaboration network**ï¼ˆé«˜èƒ½ç‰©ç†åˆä½œç½‘ç»œï¼‰
- **Gnutella peer-to-peer network**ï¼ˆP2P æ–‡ä»¶å…±äº«ç½‘ç»œï¼‰
- **32 ä¸ª Autonomous System graphs**ï¼ˆäº’è”ç½‘è·¯ç”±æ‹“æ‰‘ï¼‰

> æ‰€æœ‰æµ‹è¯•å…±æ¶‰åŠ **135 ä¸ªå›¾å®ä¾‹**

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### æŠ€æœ¯å®ç°
- ç¼–ç¨‹è¯­è¨€ï¼šPython
- å›¾å¤„ç†åº“ï¼šNetworkX
- å†…å­˜æµ‹é‡ï¼šPympler
- æ—¶é—´è®°å½•ï¼šTimer æ¨¡å—

#### multi-packet è®¾ç½®
- æ¯æ¡æ¶ˆæ¯æ‹†åˆ†ä¸º $m \in \{1, 10, 20, 30, 50\}$ ä¸ª packet
- é‡‡ç”¨ **Go-Back-N ARQ** åè®®ä¿éšœä¼ è¾“å¯é æ€§

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| `Average / Max number of messages per node` | è¡¡é‡é€šä¿¡è´Ÿè½½ |
| `Running time (s)` | ç®—æ³•æ‰§è¡Œæ€»è€—æ—¶ |
| `Data loss (%)` | æ•°æ®åŒ…ä¸¢å¤±ç‡ |
| `Memory usage (MB)` å’Œ `Overhead (ms)` | å±€éƒ¨èµ„æºæ¶ˆè€— |
| `Closeness centrality quality` | è¿‘ä¼¼æœ€ä¸­å¿ƒèŠ‚ç‚¹ä¸çœŸå®æœ€ä¸­å¿ƒèŠ‚ç‚¹ä¹‹é—´çš„æœ€çŸ­è·¯å¾„è·ç¦» |
| `Statistical significance` | ä½¿ç”¨ Wilcoxon signed-rank testï¼ˆÎ±=0.01ï¼‰æ£€éªŒå·®å¼‚æ˜¾è‘—æ€§ |

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**: åŸå§‹ pruning æ–¹æ³• [22]
- **Proposed**: æœ¬æ–‡æå‡ºçš„ enhanced pruning æ–¹æ³•

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| æŒ‡æ ‡ | ç»“æœæ¦‚è§ˆ |
|------|---------|
| **å¹³å‡æ¶ˆæ¯æ•°å‡å°‘** | 5% ~ 15%ï¼ˆè·¨æ‰€æœ‰æ‹“æ‰‘ï¼‰ |
| **æœ€å¤§æ¶ˆæ¯æ•°å‡å°‘** | æœ€é«˜è¾¾ 20%ï¼ˆè§ Figure 6ï¼‰ |
| **è¿è¡Œæ—¶é—´** | æ˜æ˜¾ä¸‹é™ï¼Œå°¤å…¶å½“ $m > 10$ æ—¶ä¼˜åŠ¿æ˜æ˜¾ |
| **æ•°æ®ä¸¢å¤±ç‡** | éš $m$ å¢åŠ è€Œé™ä½ï¼ˆFigure 3ï¼‰ |
| **å†…å­˜ä½¿ç”¨** | ç•¥æœ‰ä¸Šå‡ï¼ˆ+10%~15%ï¼‰ï¼Œä½†å¯æ§ |
| **å±€éƒ¨å¼€é”€ï¼ˆoverheadï¼‰** | å°å¹…å¢åŠ ï¼Œå±äºå¯æ¥å—ä»£ä»· |

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰æ¶ˆæ¯æ•°é‡å¯¹æ¯”ï¼ˆFigures 5 & 6ï¼‰
- åœ¨å…¨éƒ¨ 135 ä¸ªå›¾ä¸­ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨ **å¹³å‡å’Œæœ€å¤§æ¶ˆæ¯æ•°** ä¸Šå‡ä¼˜äºåŸå§‹æ–¹æ³•ã€‚
- å·®å€¼éš $m$ å¢å¤§è€Œæ‰©å¤§ï¼Œè¯´æ˜ **multi-packet åœºæ™¯ä¸‹ä¼˜åŒ–æ•ˆæœæ›´æ˜¾è‘—**ã€‚
- æ­£å‘å·®å€¼è¡¨æ˜ï¼š**æˆ‘ä»¬çš„æ–¹æ³•å‘é€çš„æ¶ˆæ¯æ›´å°‘**ã€‚

#### ï¼ˆ2ï¼‰è¿è¡Œæ—¶é—´å’Œæ•°æ®ä¸¢å¤±ï¼ˆFigure 3ï¼‰
- å½“ $m=1$ï¼ˆå•åŒ…ï¼‰æ—¶ï¼Œè¿è¡Œæ—¶é—´é•¿ä¸”ä¸¢åŒ…ç‡é«˜ï¼›
- éšç€ $m$ å¢åŠ ï¼ˆå³æ¯æ¡æ¶ˆæ¯åˆ†æ›´å¤šåŒ…ï¼‰ï¼Œè¿è¡Œæ—¶é—´ä¸‹é™ï¼Œä¸¢åŒ…ç‡é™ä½ï¼›
- åŸå› ï¼šå°åŒ…æ˜“å¼•å‘æ‹¥å¡ï¼Œè€Œå¤šåŒ…åˆ†ç‰‡ç»“åˆ ARQ æé«˜äº†ä¼ è¾“ç¨³å®šæ€§ã€‚

#### ï¼ˆ3ï¼‰å†…å­˜ä¸å¼€é”€ï¼ˆFigure 4ï¼‰
- éšç€ $m$ å¢åŠ ï¼Œæ¯ä¸ªèŠ‚ç‚¹éœ€ç¼“å­˜æ›´å¤š packetï¼Œå¯¼è‡´å†…å­˜å ç”¨å’Œå¤„ç†å¼€é”€ä¸Šå‡ï¼›
- ä½†å¢é•¿è¶‹åŠ¿å¹³ç¼“ï¼Œæœªå‡ºç°æŒ‡æ•°çº§è†¨èƒ€ï¼Œ**trade-off åˆç†**ã€‚

#### ï¼ˆ4ï¼‰ä¸­å¿ƒèŠ‚ç‚¹é€‰æ‹©è´¨é‡ï¼ˆTable IIï¼‰
- å¯¹ä¸¤ä¸ªéšæœºå›¾ï¼ˆ120 å’Œ 300 èŠ‚ç‚¹ï¼‰æµ‹è¯•ä¸åŒè¿­ä»£æ¬¡æ•° $D$
- ä¸¤ç§æ–¹æ³•é€‰å‡ºçš„â€œè¿‘ä¼¼æœ€ä¸­å¿ƒèŠ‚ç‚¹â€ä¸çœŸå®æœ€ä¸­å¿ƒèŠ‚ç‚¹çš„è·ç¦»å‡ ä¹ä¸€è‡´
- å½“ $D$ æ¥è¿‘å›¾ç›´å¾„æ—¶ï¼Œè¯¯å·®è¶‹è¿‘äº 0
- â¤ **è¯æ˜æœ¬æ–‡æ–¹æ³•æœªç‰ºç‰²ä¼°è®¡å‡†ç¡®æ€§**

#### ï¼ˆ5ï¼‰ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒï¼ˆTable IIIï¼‰
| æŒ‡æ ‡ | p-value | Effect Size |
|------|--------|------------|
| æ¶ˆæ¯æ•°é‡ | 0.0625 | 0.586ï¼ˆmediumï¼‰ |
| è¿è¡Œæ—¶é—´ | 0.0876 | 0.437ï¼ˆmediumï¼‰ |
| ä¸­å¿ƒæ€§è´¨é‡ | â‰ˆ0 | 0 |

- å°½ç®¡ p-value > 0.01ï¼ˆæœªè¾¾ä¼ ç»Ÿæ˜¾è‘—æ°´å¹³ï¼‰ï¼Œä½† **effect size ä¸º medium**ï¼Œè¯´æ˜å®é™…å·®å¼‚å…·æœ‰æ„ä¹‰ã€‚
- ç‰¹åˆ«æ˜¯ä¸­å¿ƒæ€§è´¨é‡çš„ pâ‰ˆ0ï¼Œ**å¼ºæœ‰åŠ›æ”¯æŒæœ¬æ–‡æ–¹æ³•ä¿æŒäº†åŸå§‹ç²¾åº¦**ã€‚

---

### æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æœªæ˜ç¡®æ ‡æ³¨â€œablation studyâ€ï¼Œä½†ä»¥ä¸‹å¯¹æ¯”æ„æˆäº‹å®ä¸Šçš„æ¶ˆèï¼š
- æ˜¯å¦å¯ç”¨ $D-2$ å‘é€é™åˆ¶ â†’ å½±å“æ¶ˆæ¯æ€»é‡
- æ˜¯å¦ä½¿ç”¨ multi-packet + ARQ â†’ å½±å“ä¸¢åŒ…ç‡å’Œè¿è¡Œæ—¶é—´
- ä¸åŒ $m$ å€¼çš„å½±å“ â†’ æƒè¡¡é€šä¿¡æ•ˆç‡ä¸å†…å­˜å¼€é”€

ç»“è®ºï¼š**multi-packet messaging æ˜¯å¿…è¦æ‰‹æ®µï¼Œä½†å¿…é¡»é…åˆ pruning ä¼˜åŒ–æ‰èƒ½é¿å…åå‘æ¶åŒ–é€šä¿¡è´Ÿè½½**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **multi-packet messaging èƒ½æœ‰æ•ˆé™ä½ä¸¢åŒ…ç‡å¹¶åŠ é€Ÿè¿è¡Œæ—¶é—´**ï¼Œå°¤å…¶æ˜¯åœ¨å¸¦å®½å—é™æˆ–é«˜å»¶è¿Ÿç¯å¢ƒä¸­ã€‚
2. âœ… **ç›´æ¥åº”ç”¨ multi-packet ä¼šåŠ å‰§æ¶ˆæ¯æ€»æ•°å¢é•¿**ï¼Œå› æ­¤å¿…é¡»ç»“åˆ pruning æœºåˆ¶è¿›è¡Œä¼˜åŒ–ã€‚
3. âœ… æœ¬æ–‡æå‡ºçš„ enhanced pruning æ–¹æ³•æˆåŠŸå°†æ¶ˆæ¯æ•°å‡å°‘ **5%-15%**ï¼ŒåŒæ—¶ä¿æŒä¸åŸæ–¹æ³•ç›¸åŒçš„ **closeness centrality è¿‘ä¼¼ç²¾åº¦**ã€‚
4. âœ… å­˜åœ¨åˆç†çš„ trade-offï¼š**å°å¹…å¢åŠ å†…å­˜å’Œæœ¬åœ°å¼€é”€ï¼Œæ¢å–å¤§å¹…é€šä¿¡æ•ˆç‡æå‡**ã€‚
5. âœ… æ–¹æ³•åœ¨å¤šç§æ‹“æ‰‘ï¼ˆéšæœº + çœŸå®ï¼‰ä¸‹è¡¨ç°ç¨³å®šï¼Œå…·å¤‡è‰¯å¥½æ³›åŒ–èƒ½åŠ›ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **å‡è®¾èŠ‚ç‚¹ä¸ä¼šåœ¨ç®—æ³•åˆæœŸå¤±æ•ˆ**ï¼šè‹¥ prunable èŠ‚ç‚¹æå‰å®•æœºï¼Œå…¶é‚»å±…æ— æ³•è·çŸ¥ï¼Œå¯èƒ½å½±å“å±€éƒ¨è§†å›¾ä¸€è‡´æ€§ã€‚
- **ä¾èµ– FIFO å¼‚æ­¥é€šä¿¡æ¨¡å‹**ï¼šåœ¨æç«¯ä¹±åºæˆ–é«˜å»¶è¿Ÿç½‘ç»œä¸­æ€§èƒ½å¯èƒ½é€€åŒ–ã€‚
- **memory overhead éš $m$ å¢åŠ è€Œä¸Šå‡**ï¼šåœ¨èµ„æºæåº¦å—é™è®¾å¤‡ï¼ˆå¦‚ IoT sensorï¼‰ä¸Šéƒ¨ç½²éœ€è°¨æ…ã€‚
- **æœªè€ƒè™‘åŠ¨æ€æ‹“æ‰‘å˜åŒ–**ï¼šå½“å‰æ–¹æ³•é’ˆå¯¹é™æ€å›¾è®¾è®¡ï¼Œä¸é€‚ç”¨äºé¢‘ç¹å˜åŠ¨çš„ç½‘ç»œã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆåŸæ–‡æåŠï¼‰
1. å°†æœ¬æ–¹æ³•æ‰©å±•è‡³å…¶ä»– centrality metricsï¼ˆå¦‚ betweenness æˆ– eigenvector centralityï¼‰ã€‚
2. åœ¨çœŸå®åº”ç”¨åœºæ™¯ä¸­éªŒè¯ï¼Œå¦‚ï¼š
   - ç§»åŠ¨ä¼ æ„Ÿå™¨ç½‘ç»œï¼ˆmobile sensor networksï¼‰
   - ç¤¾äº¤ç½‘ç»œåˆ†æï¼ˆsocial network analysisï¼‰
   - è‡ªåŠ¨é©¾é©¶è½¦é˜ŸååŒå†³ç­–
3. æ¢ç´¢ adaptive $m$ï¼ˆåŠ¨æ€è°ƒæ•´ packet æ•°é‡ï¼‰ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–èµ„æºåˆ©ç”¨ç‡ã€‚
4. ç»“åˆ multicast/broadcast æŠ€æœ¯æå‡ multi-packet åˆ†å‘æ•ˆç‡ã€‚

---

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼šè¯¥è®ºæ–‡åœ¨åˆ†å¸ƒå¼å›¾ç®—æ³•ä¸ç½‘ç»œé€šä¿¡äº¤å‰é¢†åŸŸåšå‡ºäº†æ‰å®è´¡çŒ®ï¼Œæå‡ºçš„ enhanced pruning æ–¹æ³•ä¸ºå¤§è§„æ¨¡ç½‘ç»œä¸­é«˜æ•ˆè®¡ç®— closeness centrality æä¾›äº†ä¸€ä¸ªå®ç”¨ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 7. [Speculative Decoding Speed-of-Light: Optimal Lower Bounds via Branching Random Walks](https://arxiv.org/abs/2512.11718)

**Authors**: Sergey Pankratov, Dan Alistarh  
**Category**: cs.CL  
**Published**: 2025-12-15  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.11718v1  

#### Abstract
Speculative generation has emerged as a promising technique to accelerate inference in large language models (LLMs) by leveraging parallelism to verify multiple draft tokens simultaneously. However, the fundamental limits on the achievable speedup remain poorly understood. In this work, we establish...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Speculative Decoding Speed-of-Light: Optimal Lower Bounds via Branching Random Walks*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬æ–‡è‡´åŠ›äºè§£å†³ **speculative decoding**ï¼ˆæ¨æµ‹è§£ç ï¼‰æŠ€æœ¯ä¸­çš„ä¸€ä¸ªæ ¹æœ¬æ€§ç†è®ºé—®é¢˜ï¼š  
**åœ¨ç»™å®šç³»ç»Ÿçº¦æŸï¼ˆå¦‚å¹¶è¡ŒéªŒè¯å®¹é‡ $P$ï¼‰å’Œç›®æ ‡æ¨¡å‹ç‰¹æ€§ä¸‹ï¼Œæ¨æµ‹ç”Ÿæˆæ‰€èƒ½è¾¾åˆ°çš„æœ€å¤§åŠ é€Ÿä¸Šé™æ˜¯å¤šå°‘ï¼Ÿ**

å°½ç®¡ speculative decoding åœ¨å®è·µä¸­å·²è¢«å¹¿æ³›é‡‡ç”¨ï¼ˆå¦‚ EAGLEã€Medusaï¼‰ï¼Œå…¶**ç†è®ºæé™ä»ä¸æ¸…æ¥š**ã€‚ç°æœ‰åˆ†æå¤šåŸºäºç®€åŒ–å‡è®¾ï¼ˆå¦‚å¹³å‡æ¥å—ç‡ï¼‰ï¼Œç¼ºä¹å¯¹æœ€ä¼˜æ€§èƒ½çš„ä¸¥æ ¼åˆ»ç”»ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

1. **é¦–æ¬¡å»ºç«‹â€œç´§è‡´â€ï¼ˆtightï¼‰çš„è¿è¡Œæ—¶é—´ä¸‹ç•Œï¼ˆç­‰ä»·äºé€Ÿåº¦æå‡ä¸Šç•Œï¼‰**  
   ä½œè€…ä¸ºä»»æ„ç¡®å®šæ€§ speculative generation ç®—æ³•å»ºç«‹äº†é¦–ä¸ª**æœ€ä¼˜ä¸‹ç•Œ**ï¼Œæ­ç¤ºäº†åŠ é€Ÿèƒ½åŠ›çš„æ ¹æœ¬ç“¶é¢ˆã€‚

2. **å¼•å…¥ Branching Random Walks (BRW) åˆ†ææ¡†æ¶**  
   å°† token ç”Ÿæˆè¿‡ç¨‹å»ºæ¨¡ä¸º log-probability ä¸Šçš„ **Branching Random Walk**ï¼Œåˆ©ç”¨æ¦‚ç‡è®ºä¸­æˆç†Ÿçš„å·¥å…·ï¼ˆå¦‚ Many-to-One Lemma å’Œ Renewal Theoryï¼‰æ¥åˆ†æåœ¨æœ‰é™éªŒè¯é¢„ç®— $P$ ä¸‹é«˜æ¦‚ç‡è·¯å¾„çš„åˆ†å¸ƒã€‚

3. **æ¨å¯¼å‡ºæœŸæœ›æˆåŠŸé¢„æµ‹ token æ•°çš„é—­å¼ä¸Šç•Œ**  
   åœ¨åŸºæœ¬å‡è®¾ä¸‹ï¼Œè¯æ˜æ¯è½®è¿­ä»£ä¸­å¯æˆåŠŸé¢„æµ‹çš„ token æ•°æœŸæœ›æ»¡è¶³ï¼š
   $$
   \mathbb{E}[X] \leq \frac{\mu + \mu^{(2)}}{\mu^2} \log(P) + O(1)
   $$
   å…¶ä¸­ï¼š
   - $P$ï¼šverifier çš„å¹¶è¡Œ token å®¹é‡ï¼ˆparallel token capacityï¼‰
   - $\mu$ï¼šç›®æ ‡æ¨¡å‹è¾“å‡ºåˆ†å¸ƒçš„æœŸæœ›ç†µï¼ˆexpected entropyï¼‰
   - $\mu^{(2)}$ï¼šlog-prob çš„æœŸæœ›äºŒé˜¶çŸ©ï¼ˆexpected second log-momentï¼‰

   è¿™ä¸ªå…¬å¼æ­ç¤ºäº†**åŠ é€Ÿæ½œåŠ›ä¸æ¨¡å‹ä¸ç¡®å®šæ€§ä¹‹é—´çš„æœ¬è´¨æƒè¡¡**ã€‚

4. **åŒºåˆ†å®Œç¾çŸ¥è¯† vs ä¸å®Œç¾çŸ¥è¯†åœºæ™¯ä¸‹çš„ç•Œé™**  
   è¿›ä¸€æ­¥åˆ†æäº†å½“ drafter æ¨¡å‹æ— æ³•å®Œå…¨è·çŸ¥ target model è¾“å‡ºåˆ†å¸ƒæ—¶çš„æƒ…å½¢ï¼Œç»™å‡ºäº†åŸºäº cross-entropy çš„ä¸‹ç•Œä¼°è®¡ï¼š
   $$
   \mathbb{E}[X] \gtrsim \frac{\log P}{H(p \| q)}
   $$

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ä»¥å¾€å·¥ä½œ | æœ¬è®ºæ–‡ |
|------|--------|-------|
| **ç†è®ºæ·±åº¦** | åŸºäº agreement rate æˆ– Markov chain æŠ½è±¡ï¼Œæä¾›å®ä¾‹ä¾èµ–è¾¹ç•Œ | é¦–æ¬¡ç»™å‡º**æ™®é€‚ã€ç´§è‡´çš„æ¸è¿‘ä¸Šä¸‹ç•Œ**ï¼Œé€‚ç”¨äºæ‰€æœ‰ç¡®å®šæ€§ç®—æ³• |
| **å»ºæ¨¡ç²¾åº¦** | å¿½ç•¥è·¯å¾„ç›¸å…³æ€§å’Œæ ‘ç»“æ„å¤æ‚æ€§ | åˆ©ç”¨ BRW ç²¾ç¡®åˆ»ç”» token æ ‘ä¸­é«˜æ¦‚ç‡è·¯å¾„çš„å¢é•¿è¡Œä¸º |
| **æŒ‡å¯¼æ„ä¹‰** | ç»éªŒæ€§ä¼˜åŒ– draft tree ç»“æ„ | æä¾›æ˜ç¡®è®¾è®¡åŸåˆ™ï¼š**é™ä½ç›®æ ‡æ¨¡å‹æœ‰æ•ˆç†µæœ‰åŠ©äºæå‡ speculative æ•ˆç‡** |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å¤šç§ä»»åŠ¡ç±»å‹ï¼Œä½¿ç”¨ä»¥ä¸‹åŸºå‡†è¿›è¡Œè¯„ä¼°ï¼š
- **HumanEval**ï¼šä»£ç ç”Ÿæˆ
- **MT-bench**ï¼šå¤šè½®å¯¹è¯è´¨é‡
- **GSM8K**ï¼šæ•°å­¦æ¨ç†
- **CNN/DM**ï¼šæ‘˜è¦ç”Ÿæˆ
- **Natural Questions (NQ)**ï¼šé—®ç­”

è¿™äº›æ˜¯ EAGLE ç³»åˆ—è®ºæ–‡å¸¸ç”¨çš„è¯„æµ‹é›†ï¼Œç¡®ä¿å¯æ¯”æ€§ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹é€‰æ‹©
æµ‹è¯•äº†å¤šä¸ªä¸»æµ LLMï¼š
- **Llama3.1 8B Instruct (L3-8B)**
- **Llama3.3 70B Instruct (L3-70B)**
- **DeepSeek R1 Distill Llama 8B (DS-8B)**
- **Qwen3 8B (Q3-8B)**

#### å‚æ•°æµ‹é‡
- å¯¹æ¯ä¸ªæ¨¡å‹åœ¨å„æ•°æ®é›†ä¸Šè¿è¡Œ target modelï¼Œé‡‡æ · 80 ä¸ªæ ·æœ¬ã€‚
- æ¸©åº¦è®¾ä¸º 1.0ï¼Œè®¡ç®—æ¯ä¸ªä½ç½®çš„ next-token åˆ†å¸ƒã€‚
- ä¼°ç®—å…³é”®å‚æ•°ï¼š
  - $\mu = \mathbb{E}[H(p)]$ï¼šæœŸæœ›ç†µ
  - $\mu^{(2)} = \mathbb{E}[\sum p \log^2 p]$ï¼šæœŸæœ›äºŒé˜¶ log-moment

#### è¯„ä¼°æ–¹å¼
- **ä¸ç›´æ¥æ¯”è¾ƒç«¯åˆ°ç«¯ååé‡**ï¼Œè€Œæ˜¯éªŒè¯ç†è®ºè¾¹ç•Œæ˜¯å¦èƒ½å‡†ç¡®é¢„æµ‹å®é™…ç³»ç»Ÿçš„æ€§èƒ½è¶‹åŠ¿ã€‚
- ä¸»è¦å¯¹æ¯”å¯¹è±¡ä¸º **EAGLE-3**ï¼Œå½“å‰æœ€å…ˆè¿›çš„ speculative decoding æ–¹æ³•ã€‚
- å›ºå®š speculation size $P = 60$ï¼Œè§‚å¯Ÿä¸åŒæ¨¡å‹/ä»»åŠ¡ä¸Šçš„å¹³å‡ accepted tokens per iterationã€‚

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ç†è®ºåŸºçº¿**ï¼š
  - Theorem 1 çš„ç²¾ç¡®ä¸Šç•Œï¼ˆè“è‰²è™šçº¿ï¼‰
  - Corollary 1 çš„æé™ä¸Šç•Œï¼ˆæ©™è‰²è™šçº¿ï¼Œ$\sim \log P / \mu$ï¼‰
  - Lemma 7 çš„ imperfect knowledge ä¸‹ç•Œï¼ˆç»¿è‰²è™šçº¿ï¼‰
- **å®é™…ç³»ç»Ÿ**ï¼š
  - **EAGLE-3**ï¼ˆæ˜Ÿå·æ ‡è®°ï¼‰
  - â€œPotentialâ€ EAGLE-3ï¼ˆé»‘è‰²å®çº¿ï¼‰ï¼šå¿½ç•¥ drafting å¼€é”€çš„ç†æƒ³ç‰ˆæœ¬

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®

#### è¡¨ 1ï¼šä¸åŒæ¨¡å‹ä¸ä»»åŠ¡ä¸‹çš„ $\mu$ å’Œ $\mu^{(2)}$
| Model | Task | $\mu$ | $\mu^{(2)}$ |
|-------|------|--------|-------------|
| L3-8B | HumanEval | 0.279 | 0.777 |
| L3-8B | MT-bench | 1.088 | 6.654 |
| L3-70B | HumanEval | 0.136 | 0.238 |
| DS-8B | MT-bench | 0.633 | 1.951 |
| Q3-8B | MT-bench | 0.369 | 0.814 |

> è§‚å¯Ÿï¼šæ›´å¤§æ›´ä¼˜çš„æ¨¡å‹ï¼ˆå¦‚ L3-70Bï¼‰å…·æœ‰æ›´ä½ä¸”æ›´ç¨³å®šçš„ $\mu$ï¼Œæ„å‘³ç€æ›´é«˜çš„ speculative å¹¶è¡Œæ½œåŠ›ã€‚

---

### ğŸ“ˆ å›¾è¡¨ç»“æœåˆ†æ

#### Figure 1ï¼šéªŒè¯ Lemma 7 çš„é¢„æµ‹èƒ½åŠ›
- æ¨ªè½´ï¼šç†è®ºä¸‹ç•Œ $\log P / H(p\|q)$
- çºµè½´ï¼šEAGLE-3 å®é™…è§‚æµ‹åˆ°çš„å¹³å‡æ¯è½®æ¥å— token æ•°
- **ç»“æœ**ï¼šå‘ˆç°æ˜æ˜¾çš„çº¿æ€§å…³ç³»ï¼Œè¯´æ˜ç†è®ºè¾¹ç•Œèƒ½å¤Ÿå¾ˆå¥½åœ°**æ•æ‰å®é™…ç³»ç»Ÿæ€§èƒ½çš„è¶‹åŠ¿**ã€‚
- å­˜åœ¨ä¸€ä¸ªå¸¸æ•°å·®è·ï¼Œå½’å› äº $o(\log P)$ é¡¹æˆ–å®ç°å¼€é”€ã€‚

#### Figure 2ï¼šéš $P$ å˜åŒ–çš„ speedup æ›²çº¿ï¼ˆä»¥ L3-8B ä¸ºä¾‹ï¼‰
- è“è‰²è™šçº¿ï¼šTheorem 1 çš„ç²¾ç¡®ä¸Šç•Œ
- æ©™è‰²è™šçº¿ï¼š$\log P / \mu$ æé™ä¸Šç•Œ
- ç»¿è‰²è™šçº¿ï¼šimperfect knowledge ä¸‹ç•Œ
- æ˜Ÿå·ï¼šçœŸå® EAGLE-3 æ€§èƒ½ï¼ˆæ¥è‡ªåŸè®ºæ–‡é…ç½®ï¼‰

##### å…³é”®å‘ç°ï¼š
1. **EAGLE-3 æ¥è¿‘å…¶è‡ªèº«ç†æƒ³ä¸Šé™**ï¼ˆé»‘çº¿ï¼‰ï¼Œè¡¨æ˜å…¶å®ç°å·²è¾ƒé«˜æ•ˆï¼›
2. ä½†ä»æ˜¾è‘—ä½äºç†è®ºæœ€ä¼˜ä¸Šç•Œï¼ˆè“çº¿ï¼‰ï¼Œå­˜åœ¨çº¦ **2å€ä»¥ä¸Šçš„åŠ é€Ÿç©ºé—´**ï¼›
3. å·®è·ä¸»è¦æ¥æºäºï¼š
   - drafter ä¸ target model ä¹‹é—´çš„ mismatchï¼ˆcross-entropy å½±å“ï¼‰
   - éæœ€ä¼˜çš„ draft tree æ„é€ ç­–ç•¥

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **Speculative decoding çš„åŠ é€Ÿä¸Šé™å‘ˆ $\log P$ å¢é•¿**  
   å³ä½¿æ— é™å¢åŠ å¹¶è¡Œåº¦ $P$ï¼Œæ”¶ç›Šä¹Ÿæ˜¯**å¯¹æ•°çº§å¢é•¿**ï¼Œå­˜åœ¨ä¸¥é‡è¾¹é™…é€’å‡æ•ˆåº”ã€‚

2. **æ¨¡å‹ç†µ $\mu$ æ˜¯å†³å®šåŠ é€Ÿæ½œåŠ›çš„æ ¸å¿ƒå› ç´ **  
   - ä½ç†µæ¨¡å‹ï¼ˆå¦‚ L3-70Bï¼‰æ›´é€‚åˆ speculation
   - é«˜ç†µä»»åŠ¡ï¼ˆå¦‚å¼€æ”¾å¯¹è¯ MT-benchï¼‰éš¾ä»¥æœ‰æ•ˆæ¨æµ‹

3. **å½“å‰ç³»ç»Ÿï¼ˆå¦‚ EAGLE-3ï¼‰å°šæœªè¾¾åˆ°ç†è®ºæé™**  
   å®éªŒæ˜¾ç¤ºä»æœ‰ **Ã—2 ä»¥ä¸Šçš„æ”¹è¿›ç©ºé—´**ï¼Œä¸»è¦å—é™äºï¼š
   - drafter æ¨¡å‹çš„é¢„æµ‹è¯¯å·®ï¼ˆcross-entropyï¼‰
   - ç¼ºä¹å…¨å±€æœ€ä¼˜ draft tree æ„é€ æœºåˆ¶

4. **BRW æ¡†æ¶æä¾›äº†å¼ºå¤§çš„ç†è®ºåˆ†æå·¥å…·**  
   æˆåŠŸå°† speculative decoding æ˜ å°„ä¸ºç»å…¸éšæœºè¿‡ç¨‹é—®é¢˜ï¼Œæ‰“å¼€äº†æ–°çš„åˆ†æè§†è§’ã€‚

---

### âš ï¸ å±€é™æ€§

1. **i.i.d. å‡è®¾ä¸ç°å®**  
   å‡è®¾ä¸åŒ prefix ä¸‹çš„ acceptance probability ç‹¬ç«‹åŒåˆ†å¸ƒï¼Œå¿½ç•¥äº†è¯­è¨€çš„ä¸Šä¸‹æ–‡ä¾èµ–æ€§ã€‚

2. **ç®€åŒ–æ—¶åºæ¨¡å‹**  
   å¿½ç•¥äº† KV Cache å¢é•¿å¸¦æ¥çš„ verifier å»¶è¿Ÿå˜åŒ–ï¼Œä»¥åŠ drafting æ¨¡å—çš„å®é™…å¼€é”€ã€‚

3. **ä»…åˆ†æç¡®å®šæ€§ç®—æ³•**  
   æœªæ¶µç›–å¯èƒ½æ›´ä¼˜çš„éšæœºæ€§ speculation ç­–ç•¥ã€‚

4. **å®Œç¾çŸ¥è¯†å‡è®¾**  
   ä¸Šç•ŒåŸºäº drafter å®Œå…¨çŸ¥æ™“ target model æ¦‚ç‡åˆ†å¸ƒï¼Œç°å®ä¸­ä¸å¯è¾¾ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³é i.i.d. åœºæ™¯**  
   å¼•å…¥é©¬å°”å¯å¤«æˆ–å¹³ç¨³éå†è¿‡ç¨‹å»ºæ¨¡ context-dependent è¾“å‡ºåˆ†å¸ƒã€‚

2. **è®¾è®¡é€¼è¿‘ç†è®ºæé™çš„æ–°å‹ drafting ç®—æ³•**  
   åŸºäº BRW å¯å‘ï¼Œå¼€å‘èƒ½åŠ¨æ€æ„é€ æ¥è¿‘æœ€ä¼˜ draft tree çš„ç­–ç•¥ã€‚

3. **è”åˆä¼˜åŒ–æ¨¡å‹æ¶æ„ä¸ speculation æœºåˆ¶**  
   å¦‚è®­ç»ƒç›®æ ‡å‡½æ•°æ˜¾å¼é™ä½è¾“å‡ºç†µæˆ–æ–¹å·®ï¼Œä»¥æå‡ speculative æ•ˆç‡ã€‚

4. **æ¢ç´¢ stochastic speculative strategies**  
   åˆ†æéšæœºé‡‡æ ·ç­–ç•¥æ˜¯å¦èƒ½åœ¨æŸäº›æƒ…å†µä¸‹çªç ´ç¡®å®šæ€§ç®—æ³•çš„ç•Œé™ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡é€šè¿‡å¼•å…¥ Branching Random Walks æ¡†æ¶ï¼Œé¦–æ¬¡ä¸º speculative decoding å»ºç«‹äº†â€œå…‰é€Ÿçº§â€çš„ç†è®ºæ€§èƒ½æé™ï¼Œæ­ç¤ºäº†**å¹¶è¡Œåº¦æ”¶ç›Šçš„å¯¹æ•°å¤©èŠ±æ¿**å’Œ**æ¨¡å‹ç†µçš„å…³é”®åˆ¶çº¦ä½œç”¨**ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†è¾¹ç•Œçš„ç´§è‡´æ€§ï¼Œä¸ºæœªæ¥ç³»ç»Ÿè®¾è®¡æä¾›äº†åšå®çš„ç†è®ºåŸºç¡€ã€‚

</details>

---

### 8. [Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization](https://arxiv.org/abs/2512.11391)

**Authors**: Yifan Niu, Han Xiao, Dongyi Liu, Nuo Chen, Jia Li  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.11391v1  

#### Abstract
As Large Language Models (LLMs) are increasingly deployed in real-world applications, it is important to ensure their behaviors align with human values, societal norms, and ethical principles. However, safety alignment under Reinforcement Learning (RL) often suffers from forgetting learned general a...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®é™…åº”ç”¨ä¸­éœ€è¦è¿›è¡Œ **safety alignment**ï¼ˆå®‰å…¨å¯¹é½ï¼‰ï¼Œä»¥ç¡®ä¿å…¶è¾“å‡ºç¬¦åˆäººç±»ä»·å€¼è§‚å’Œç¤¾ä¼šè§„èŒƒã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¯¹é½æ–¹æ³•å¾€å¾€ä¼šå¯¼è‡´æ¨¡å‹åœ¨é€šç”¨ä»»åŠ¡ä¸Šçš„èƒ½åŠ›ä¸‹é™ï¼Œè¿™ç§ç°è±¡è¢«ç§°ä¸º **safety alignment tax**ï¼ˆå®‰å…¨å¯¹é½ç¨ï¼‰ã€‚è¯¥é—®é¢˜æœ¬è´¨ä¸Šæºäºå®‰å…¨ä¼˜åŒ–ä¸é€šç”¨èƒ½åŠ›ä¹‹é—´çš„éšå¼å†²çªã€‚

### æå‡ºçš„æ–°æ–¹æ³•
æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶â€”â€”**Null-Space constrained Policy Optimization (NSPO)**ï¼Œæ—¨åœ¨å®ç°å®‰å…¨å¯¹é½çš„åŒæ—¶æœ‰æ•ˆç¼“è§£å¯¹é½ç¨ã€‚

#### æ ¸å¿ƒæ€æƒ³
- å°† **safety policy gradients**ï¼ˆå®‰å…¨ç­–ç•¥æ¢¯åº¦ï¼‰å‡ ä½•æŠ•å½±åˆ°é€šç”¨ä»»åŠ¡è¡¨å¾çš„**é›¶ç©ºé—´ï¼ˆnull spaceï¼‰**ä¸­ã€‚
- è¿™æ ·åšçš„æ•ˆæœæ˜¯ï¼šå®‰å…¨æ›´æ–°è¢«çº¦æŸä¸ºä¸æ¨¡å‹çš„é€šç”¨èƒ½åŠ›å­ç©ºé—´æ­£äº¤ï¼Œä»è€Œé¿å…å¹²æ‰°å·²å­¦å¾—çš„é€šç”¨èƒ½åŠ›ã€‚

#### æŠ€æœ¯å®ç°
- åˆ©ç”¨ **Singular Value Decomposition (SVD)** å¯¹é€šç”¨ä»»åŠ¡æ•°æ®çš„éä¸­å¿ƒåæ–¹å·®çŸ©é˜µ $KK^T$ è¿›è¡Œåˆ†è§£ï¼Œæå–é›¶ç©ºé—´å¯¹åº”çš„æŠ•å½±çŸ©é˜µ $U U^T$ã€‚
- åœ¨æ¢¯åº¦æ›´æ–°æ—¶ï¼Œå°†åŸå§‹æ¢¯åº¦ä¹˜ä»¥è¯¥æŠ•å½±çŸ©é˜µï¼Œä½¿å…¶è½åœ¨ä¸å½±å“é€šç”¨èƒ½åŠ›çš„ç©ºé—´å†…ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | NSPOä¼˜åŠ¿ |
|------|---------|
| **ä¿ç•™é€šç”¨èƒ½åŠ›** | ç†è®ºä¸Šè¯æ˜èƒ½ä¿æŒæ¨¡å‹åŸæœ‰æ ¸å¿ƒèƒ½åŠ›ä¸é€€åŒ– |
| **å®‰å…¨æ€§èƒ½** | å®ç°æœ‰æ•ˆçš„å®‰å…¨ä¼˜åŒ–æ–¹å‘ï¼Œä¿è¯å®‰å…¨ç›®æ ‡ä¸‹é™ |
| **æ•°æ®æ•ˆç‡** | ä»…éœ€ **40% çš„ PKU-SafeRLHF å®‰å…¨æ•°æ®**å³å¯è¾¾åˆ°ä¼˜å¼‚è¡¨ç°ï¼Œæ— éœ€æ··åˆå¤§é‡é€šç”¨ä»»åŠ¡æ•°æ® |
| **è®­ç»ƒç¨³å®šæ€§** | é›¶ç©ºé—´æŠ•å½±å…·æœ‰éæ‰©å¼ æ€§ï¼ˆnon-expansiveï¼‰ï¼Œæä¾›å½¢å¼åŒ–çš„æ¢¯åº¦ç¨³å®šæ€§ä¿éšœ |
| **å»KLé¡¹è®¾è®¡** | ç§»é™¤äº†ä¼ ç»ŸRLä¸­çš„KLæ•£åº¦æƒ©ç½šé¡¹ï¼Œé¿å…å…¶ä¸å®‰å…¨ç›®æ ‡çš„æ½œåœ¨å†²çª |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

#### å®‰å…¨è®­ç»ƒæ•°æ®
- **PKU-SafeRLHF**ï¼šä½¿ç”¨å…¶ä¸­ **11Kæ ·æœ¬ï¼ˆå æ€»é‡40%ï¼‰** ç”¨äºNSPOè®­ç»ƒï¼Œè¿œå°‘äºå…¶ä»–æ–¹æ³•ä½¿ç”¨çš„å®Œæ•´æ•°æ®é›†ã€‚

#### é€šç”¨èƒ½åŠ›æ•°æ®ï¼ˆç”¨äºæ„å»ºæŠ•å½±çŸ©é˜µï¼‰
- æ„é€ æŠ•å½±çŸ©é˜µ $K$ æ—¶ï¼Œä»ä»¥ä¸‹ä¸‰ä¸ªé¢†åŸŸéšæœºé‡‡æ ·å…± **1,000ä¸ªå®ä¾‹**ï¼š
  - **Common sense**ï¼ˆå¸¸è¯†æ¨ç†ï¼‰
  - **Math**ï¼ˆæ•°å­¦é¢˜å¦‚GSM8Kã€MATHï¼‰
  - **Code**ï¼ˆç¼–ç¨‹é¢˜å¦‚LiveCodeBenchï¼‰

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š
  - `Llama3-8B-Instruct`
  - `Qwen2.5-7B-Instruct`
- **å¥–åŠ±æ¨¡å‹**ï¼š
  - ä½¿ç”¨å¼€æºçš„å®‰å…¨åˆ†ç±»å™¨ **Llama-Guard-4-12B** æä¾›å®‰å…¨è¯„åˆ†ã€‚
- **è®­ç»ƒæ¡†æ¶**ï¼š
  - åŸºäº `verl` æ¡†æ¶å®ç°ï¼Œé‡‡ç”¨ **GRPO** ç»“æ„ä½œä¸ºéª¨å¹²ã€‚
- **è¶…å‚æ•°**ï¼š
  - $\beta = 0.1$, $\epsilon = 0.2$
  - ç‰¹å¾å€¼é˜ˆå€¼è®¾ä¸º $5 \times 10^{-4}$ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦å±äºé›¶ç©ºé—´ï¼‰

### è¯„ä¼°æŒ‡æ ‡

#### å®‰å…¨æ€§è¯„ä¼°ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
- **Attack Success Rate (ASR%)**ï¼šè¡¡é‡æ¨¡å‹ç”Ÿæˆæœ‰å®³å†…å®¹çš„æ¯”ä¾‹ï¼Œç”±GPT-4æˆ–ä¸“ç”¨æ¨¡å‹ï¼ˆå¦‚SORRY-Benchï¼‰è¯„åˆ¤ã€‚

#### é€šç”¨èƒ½åŠ›è¯„ä¼°ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
- **Accuracy (%)**ï¼šç”¨äºMMLUã€GSM8Kã€MATHç­‰ä»»åŠ¡
- **Win Rate (%)**ï¼šAlpacaEvalä¸Šçš„èƒœç‡
- **Pass@1 (%)**ï¼šLiveCodeBenchä»£ç ç”Ÿæˆé€šè¿‡ç‡

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æ˜¯å¦ä½¿ç”¨æ··åˆæ•°æ® |
|------|------|----------------|
| **DPO-H / DPO-S / DPO-Mix** | DPOå˜ä½“ | æ˜¯ï¼ˆéƒ¨åˆ†ï¼‰ |
| **SafeRLHF** | RLHFåŒç›®æ ‡ä¼˜åŒ– | å¦ |
| **PeCAN / MoCAN** | åŒé˜¶æ®µä¼˜åŒ– | å¦ |
| **W-DOOR** | å¼ºæ‹’ç»+åå‘å­¦ä¹  | å¦ |
| **BFPO** | åŒç›®æ ‡åå¥½ä¼˜åŒ– | æ˜¯ï¼ˆæ˜¾å¼æ··åˆï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Tables 1 & 2ï¼‰

#### âœ… å®‰å…¨æ€§èƒ½ï¼ˆASR â†“ï¼‰
åœ¨ `Qwen2.5-7B-Instruct` ä¸Šï¼ŒNSPO æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼š

| Benchmark | NSPO | æœ€ä¼˜åŸºçº¿ | æå‡å¹…åº¦ |
|----------|------|---------|--------|
| **AdvB** | **0.29%** | 0.00% (W-DOOR) | æ¥è¿‘æœ€ä¼˜ |
| **PKU-Safe** | **0.52%** | 1.35% (BFPO) | â†“1.58å€ |
| **HarmB** | **0.50%** | 11.33% (BFPO) | â†“22.66å€ |
| **JailbreakB** | **0.67%** | 1.33% (BFPO) | â†“2å€ |
| **SORRY** | **19.54%** | 15.00% (W-DOOR) | ç•¥é€Šä½†å¯æ§ |
| **HarmQA** | **0.11%** | 0.31% (W-DOOR) | â†“2.8å€ |
| **ALERT** | **0.81%** | 3.40% (W-DOOR) | â†“4.2å€ |

> â­ NSPO åœ¨å¤šä¸ªå®‰å…¨åŸºå‡†ä¸Šå–å¾—**state-of-the-art**è¡¨ç°ã€‚

#### âœ… é€šç”¨èƒ½åŠ›ä¿ç•™ï¼ˆAccuracy â†‘ï¼‰
NSPO å‡ ä¹æ— æŸåœ°ä¿ç•™äº†é€šç”¨èƒ½åŠ›ï¼Œåœ¨å¤šæ•°ä»»åŠ¡ä¸Šæ¥è¿‘ç”šè‡³è¶…è¿‡åŸºçº¿ï¼š

| Task | NSPO | åŸºç¡€æ¨¡å‹ | BFPOï¼ˆæœ€ä½³ä¹‹ä¸€ï¼‰ |
|------|------|--------|--------------|
| **MMLU** | 71.74% | 71.71% | 71.72% |
| **SuperGPQA** | 27.68% | 27.72% | 27.98% |
| **AlpacaEval WR** | 94.33% | 94.35% | 95.22% |
| **GSM8K** | 81.96% | 81.65% | 83.85% |
| **MATH** | 75.05% | 74.80% | 74.55% |
| **OlympiadBench** | 39.00% | 37.80% | 36.35% |
| **LiveCodeBench Pass@1** | 24.05% | 24.07% | 24.36% |

> ğŸ” æ€»ä½“æ¥çœ‹ï¼ŒNSPO åœ¨é€šç”¨ä»»åŠ¡ä¸Šçš„æ€§èƒ½**å‡ ä¹æ²¡æœ‰é€€åŒ–**ï¼ˆå¤šæ•°åœ¨ Â±1% å†…ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–å®‰å…¨å¯¹é½æ–¹æ³•ï¼ˆå¦‚DPO-H/SafeRLHFå¯¼è‡´ä¸¥é‡é€€åŒ–ï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### Q1: Null-Space æŠ•å½± vs KL æ­£åˆ™ï¼Ÿ
- **GRPO w/o KL**ï¼šå®‰å…¨å¼ºï¼Œä½†é€šç”¨èƒ½åŠ›ä¸¥é‡é€€åŒ–
- **Standard GRPO (with KL)**ï¼šä¿æŠ¤äº†é€šç”¨èƒ½åŠ›ï¼Œä½†ç‰ºç‰²äº†å®‰å…¨æ€§èƒ½
- **NSPO**ï¼š**å…¼é¡¾ä¸¤è€…**ï¼Œå®ç°äº†æœ€ä½³å¹³è¡¡

> ğŸ“Š å›¾4æ˜¾ç¤ºï¼šNSPOåœ¨å®‰å…¨å’Œé€šç”¨èƒ½åŠ›ä¹‹é—´å–å¾—äº†æœ€ä¼˜æƒè¡¡ã€‚

#### Q2: æŠ•å½±çŸ©é˜µ $K$ çš„å½±å“ï¼Ÿ
- **æ•°æ®æ¥æº**ï¼šä½¿ç”¨ **mixï¼ˆæ··åˆå¸¸è¯†/æ•°å­¦/ä»£ç ï¼‰** æ„å»º $K$ æ•ˆæœæœ€å¥½ â†’ æ›´å¥½ä¿ç•™é€šç”¨èƒ½åŠ›
- **æ ·æœ¬é‡**ï¼šå¢å¤§æ ·æœ¬é‡å¯æ›´å¥½ä¿ç•™é€šç”¨èƒ½åŠ›ï¼Œä½†å¯èƒ½è½»å¾®é™ä½å®‰å…¨æ€§
- **ç‰¹å¾å€¼é˜ˆå€¼**ï¼šä¸­ç­‰é˜ˆå€¼ï¼ˆå¦‚ $5\times10^{-4}$ï¼‰å–å¾—æœ€ä½³ trade-off

> ğŸ“ˆ å›¾6è¡¨æ˜ï¼šåˆç†é€‰æ‹©æŠ•å½±çŸ©é˜µæ„é€ æ–¹å¼è‡³å…³é‡è¦ã€‚

#### Q3: æ•°æ®æ•ˆç‡åˆ†æ
- å¦‚å›¾7æ‰€ç¤ºï¼Œä½¿ç”¨ **40% vs 100% PKU-SafeRLHF æ•°æ®**ï¼Œæ¨¡å‹æ€§èƒ½å‡ ä¹æ— å·®å¼‚ã€‚
- è®­ç»ƒæ—¥å¿—æ˜¾ç¤ºï¼š40%årewardè¶‹äºé¥±å’Œï¼Œç»§ç»­è®­ç»ƒæ”¶ç›Šæå°ã€‚

> ğŸ’¡ **NSPOå…·å¤‡é«˜åº¦æ•°æ®æ•ˆç‡**ï¼Œä»…éœ€å°‘é‡é«˜è´¨é‡å®‰å…¨æ•°æ®å³å¯å®Œæˆæœ‰æ•ˆå¯¹é½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å®‰å…¨å¯¹é½ç¨çš„æ ¹æœ¬åŸå› åœ¨äºæ¢¯åº¦å†²çª**ï¼šå®‰å…¨æ¢¯åº¦ä¼šç ´åæ¨¡å‹åœ¨é€šç”¨ä»»åŠ¡ä¸Šçš„è¡¨å¾æ˜ å°„ã€‚
2. **é›¶ç©ºé—´æŠ•å½±æ˜¯ä¸€ç§æœ‰æ•ˆçš„è§£è€¦æœºåˆ¶**ï¼šé€šè¿‡å°†å®‰å…¨æ›´æ–°é™åˆ¶åœ¨ä¸å½±å“é€šç”¨èƒ½åŠ›çš„æ–¹å‘ä¸Šï¼Œå®ç°â€œç²¾å‡†æ‰‹æœ¯å¼â€ä¼˜åŒ–ã€‚
3. **NSPOç†è®ºä¸Šæœ‰ä¿éšœ**ï¼š
   - ä¿è¯æ¢¯åº¦ç¨³å®šï¼ˆProposition 4.1ï¼‰
   - ä¿è¯æ˜¯åˆæ³•çš„ä¸‹é™æ–¹å‘ï¼ˆTheorem 4.2ï¼‰
4. **ç§»é™¤KLé¡¹æ›´åˆç†**ï¼šKLæ­£åˆ™å€¾å‘äºæ‹‰å›unsafe reference modelï¼Œåè€Œé˜»ç¢å®‰å…¨ä¼˜åŒ–ï¼›è€Œé›¶ç©ºé—´æŠ•å½±æœ¬èº«å°±èƒ½é˜²æ­¢è¿‡æ‹Ÿåˆã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é¢„å®šä¹‰çš„é€šç”¨ä»»åŠ¡é›†**æ¥æ„å»ºæŠ•å½±çŸ©é˜µ $K$ï¼Œè‹¥è¦†ç›–ä¸è¶³å¯èƒ½å¯¼è‡´æŸäº›èƒ½åŠ›æœªè¢«ä¿æŠ¤ã€‚
- **SVDè®¡ç®—å¼€é”€**è™½ç„¶å¯æ§ï¼ˆ$O(d^3)$ï¼‰ï¼Œä½†åœ¨éå¸¸æ·±å±‚ç½‘ç»œä¸­ä»éœ€æ³¨æ„å†…å­˜ç®¡ç†ï¼ˆå°½ç®¡ä½œè€…é‡‡ç”¨offloadç­–ç•¥ç¼“è§£ï¼‰ã€‚
- å½“å‰æ–¹æ³•å‡è®¾çº¿æ€§å˜æ¢ä¸‹çš„é›¶ç©ºé—´å…³ç³»æˆç«‹ï¼Œå¯¹äºå¤æ‚éçº¿æ€§äº¤äº’å¯èƒ½å­˜åœ¨è¿‘ä¼¼è¯¯å·®ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³å¤šæ¨¡æ€æ¨¡å‹çš„å®‰å…¨å¯¹é½
- è‡ªé€‚åº”é€‰æ‹©æŠ•å½±ç©ºé—´ï¼ˆåŠ¨æ€æ›´æ–° $K$ï¼‰
- æ¢ç´¢æ›´é«˜æ•ˆçš„é›¶ç©ºé—´è¿‘ä¼¼ç®—æ³•ï¼ˆé¿å…SVDï¼‰
- å°†NSPOæ€æƒ³åº”ç”¨äºå…¶ä»–å¯¹é½æŒ‘æˆ˜ï¼ˆå¦‚truthfulness alignmentï¼‰

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> NSPO é€šè¿‡**é›¶ç©ºé—´çº¦æŸçš„æ¢¯åº¦æŠ•å½±**ï¼Œé¦–æ¬¡åœ¨ç†è®ºä¸Šå’Œå®è·µä¸Šå®ç°äº†**å®‰å…¨å¯¹é½ä¸é€šç”¨èƒ½åŠ›çš„è§£è€¦ä¼˜åŒ–**ï¼Œåœ¨å¤§å¹…é™ä½å¯¹é½ç¨çš„åŒæ—¶ï¼Œè¾¾åˆ°äº†SOTAçº§åˆ«çš„å®‰å…¨æ€§å’Œå“è¶Šçš„æ•°æ®æ•ˆç‡ã€‚

</details>

---

### 9. [A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation](https://arxiv.org/abs/2512.11270)

**Authors**: Hong Je-Gal, Chan-Bin Yi, Hyun-Suk Lee  
**Category**: cs.AI  
**Published**: 2025-12-15  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.11270v1  

#### Abstract
Applying reinforcement learning (RL) to real-world tasks requires converting informal descriptions into a formal Markov decision process (MDP), implementing an executable environment, and training a policy agent. Automating this process is challenging due to modeling errors, fragile code, and misali...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **MDPå»ºæ¨¡å›°éš¾**ï¼šå°†éå½¢å¼åŒ–çš„è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°è½¬åŒ–ä¸ºç²¾ç¡®çš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰éœ€è¦å¤§é‡ä¸“å®¶çŸ¥è¯†ã€‚
- **ç¯å¢ƒå®ç°è„†å¼±**ï¼šæ‰‹åŠ¨ç¼–å†™å¯æ‰§è¡Œçš„RLç¯å¢ƒä»£ç å®¹æ˜“å‡ºé”™ï¼Œä¸”éš¾ä»¥ä¿è¯è¯­ä¹‰ä¸€è‡´æ€§ï¼ˆå¦‚çŠ¶æ€ã€åŠ¨ä½œã€å¥–åŠ±æ˜¯å¦å‡†ç¡®åæ˜ ä»»åŠ¡ç›®æ ‡ï¼‰ã€‚
- **æµç¨‹ç¼ºä¹çµæ´»æ€§ä¸å¯æ‰©å±•æ€§**ï¼šä»»åŠ¡éœ€æ±‚å˜æ›´æ—¶éœ€é‡æ–°è®¾è®¡MDPå¹¶ä»å¤´è®­ç»ƒç­–ç•¥ï¼Œæ— æ³•å¿«é€Ÿé€‚åº”ã€‚

è¿™äº›é—®é¢˜å¯¼è‡´RLéƒ¨ç½²æˆæœ¬é«˜ã€å‘¨æœŸé•¿ï¼Œé™åˆ¶äº†å…¶åœ¨å·¥ä¸šåœºæ™¯ä¸­çš„å¹¿æ³›åº”ç”¨ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šA-LAMP æ¡†æ¶
ä½œè€…æå‡º **A-LAMP**ï¼ˆAgentic LLM-Based Framework for Automated MDP Modeling and Policy Generationï¼‰ï¼Œä¸€ä¸ªåŸºäºå¤šæ™ºèƒ½ä½“å¤§æ¨¡å‹ï¼ˆmulti-agent LLMï¼‰çš„è‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œå®ç°ä»è‡ªç„¶è¯­è¨€æè¿°åˆ°å¯æ‰§è¡Œç­–ç•¥çš„ç«¯åˆ°ç«¯ç”Ÿæˆã€‚

#### æ ¸å¿ƒæ€æƒ³ï¼š
å°†æ•´ä¸ªæ”¿ç­–ç”Ÿæˆæµç¨‹åˆ†è§£ä¸ºå¤šä¸ªä¸“ä¸šåŒ–LLMä»£ç†ï¼ˆAgentï¼‰ï¼Œæ¯ä¸ªä»£ç†è´Ÿè´£ç‰¹å®šå­ä»»åŠ¡ï¼Œå¹¶é€šè¿‡æ¨¡å—åŒ–åä½œç¡®ä¿è¯­ä¹‰å¯¹é½ä¸å¯éªŒè¯æ€§ã€‚

#### ä¸»è¦é˜¶æ®µä¸å¯¹åº”Agentï¼š
| é˜¶æ®µ | Agent | åŠŸèƒ½ |
|------|-------|------|
| æŠ½è±¡ç†è§£ | Parameter Agent, Objective Agent, Variable Agent, Constraint Agent | ä»è‡ªç„¶è¯­è¨€ä¸­æå–å‚æ•°ã€ç›®æ ‡ã€å˜é‡å’Œçº¦æŸ |
| MDPå»ºæ¨¡ | Modeling Agent, SAR Agent | å½¢å¼åŒ–å®šä¹‰MDPçš„ç›®æ ‡å‡½æ•°ã€çŠ¶æ€ç©ºé—´ã€åŠ¨ä½œç©ºé—´ã€å¥–åŠ±å‡½æ•° |
| ç¼–ç å®ç° | Env Agent, Coding Agent, Code Executor | ç”Ÿæˆå¯è¿è¡Œçš„Gymé£æ ¼ç¯å¢ƒä»£ç ä¸DQNè®­ç»ƒå¾ªç¯ |

æ­¤å¤–å¼•å…¥**é”™è¯¯çº æ­£æ¨¡å—**ï¼ˆerror correction moduleï¼‰ï¼Œå…è®¸Agentè‡ªæ£€æˆ–å‘äººç±»è¯·æ±‚æ¾„æ¸…ï¼Œæå‡é²æ£’æ€§ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | A-LAMP | å•ä¸€LLMæ–¹æ³•ï¼ˆå¦‚GPT-4oï¼‰ |
|------|--------|------------------------|
| **å»ºæ¨¡å¯é æ€§** | åˆ†æ­¥æ¨ç†ï¼Œé™ä½å•ä¸ªAgentçš„è®¤çŸ¥è´Ÿæ‹…ï¼Œè¾“å‡ºæ›´ä¸€è‡´ | æ˜“å‡ºç°å†…éƒ¨ä¸ä¸€è‡´ï¼ˆå¦‚ä»£ç ä¸ç›®æ ‡è„±èŠ‚ï¼‰ |
| **å¯è§£é‡Šæ€§ä¸å¯éªŒè¯æ€§** | å„é˜¶æ®µè¾“å‡ºé€æ˜ï¼ˆJSON/æ–¹ç¨‹çº§è¡¨è¾¾ï¼‰ï¼Œæ”¯æŒé€æ­¥å®¡æŸ¥ | é»‘ç®±å¤„ç†ï¼Œéš¾ä»¥è¿½æº¯é”™è¯¯æ¥æº |
| **é€‚åº”æ€§** | æ”¯æŒè‡ªç”±æ–‡æœ¬è¾“å…¥ï¼Œä»»åŠ¡å˜æ›´åªéœ€æ›´æ–°æè¿°å³å¯è‡ªåŠ¨é‡æ„ | éœ€äººå·¥å¹²é¢„é‡å†™æç¤ºæˆ–è°ƒæ•´é€»è¾‘ |
| **å°æ¨¡å‹å¯ç”¨æ€§** | è½»é‡ç‰ˆLight A-LAMPå¯åœ¨Gemma3-27Bä¸Šè¿è¡Œï¼Œæ¥è¿‘GPT-4oè¡¨ç° | å°æ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ |
| **æˆåŠŸç‡** | åœ¨å¤æ‚å®šåˆ¶ç¯å¢ƒä¸­æ˜¾è‘—æé«˜ç­–ç•¥ç”ŸæˆæˆåŠŸç‡ | å®¹æ˜“å¤±è´¥äºç¼–ç æˆ–è®­ç»ƒé˜¶æ®µ |

> ğŸ’¡ åˆ›æ–°äº®ç‚¹ï¼šé¦–æ¬¡ç³»ç»Ÿæ€§åœ°å°†â€œ**è®¤çŸ¥åˆ†æ­¥â€+â€œå¤šæ™ºèƒ½ä½“ååŒâ€+â€œåé¦ˆè°ƒè¯•æœºåˆ¶**â€åº”ç”¨äºè‡ªåŠ¨åŒ–RLå»ºæ¨¡ï¼Œå®ç°äº†é«˜ä¿çœŸã€å¯è¿½è¸ªçš„ç«¯åˆ°ç«¯æ”¿ç­–ç”Ÿæˆã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†ï¼ˆBenchmark Tasksï¼‰
å…±æµ‹è¯•5ä¸ªä»»åŠ¡ï¼Œæ¶µç›–ç»å…¸æ§åˆ¶ä¸é¢†åŸŸä¸“ç”¨ä¼˜åŒ–ï¼š

| ä»»åŠ¡ | ç±»å‹ | æ˜¯å¦éœ€è‡ªå®šä¹‰ç¯å¢ƒ |
|------|------|------------------|
| **Cart-pole** | ç»å…¸æ§åˆ¶ | å¦ï¼ˆå·²æœ‰Gymç¯å¢ƒï¼‰ |
| **Mountain-car** | ç»å…¸æ§åˆ¶ | å¦ |
| **Wireless** | æ— çº¿é€šä¿¡èµ„æºè°ƒåº¦ | æ˜¯ï¼ˆShannonå®¹é‡å…¬å¼ç­‰ï¼‰ |
| **Drone-delivery** | æ— äººæœºé…é€è·¯å¾„è§„åˆ’ | æ˜¯ï¼ˆç½‘æ ¼ä¸–ç•Œ+èƒ½é‡çº¦æŸï¼‰ |
| **Inventory-management** | åº“å­˜ç®¡ç†ï¼ˆæ³Šæ¾éœ€æ±‚ï¼‰ | æ˜¯ï¼ˆæˆæœ¬ç»“æ„å¤æ‚ï¼‰ |

æ‰€æœ‰ä»»åŠ¡ä»…é€šè¿‡**è‡ªç”±å½¢å¼çš„è‡ªç„¶è¯­è¨€æè¿°**ä½œä¸ºè¾“å…¥ï¼Œæ— é¢å¤–ç»“æ„åŒ–æ ‡æ³¨ã€‚

---

### ğŸ§ª å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### è¯„ä¼°æ ‡å‡†ï¼ˆä¸‰é¡¹æˆåŠŸç‡ï¼Œæ¯é¡¹åŸºäº20æ¬¡è¯•éªŒï¼‰ï¼š
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Modeling Success Rate** | æå–çš„çŠ¶æ€ã€åŠ¨ä½œã€å¥–åŠ±é€»è¾‘æ­£ç¡®ä¸”å®Œæ•´ |
| **Coding Success Rate** | ç”Ÿæˆä»£ç å¯åœ¨æ ‡å‡†Pythonç¯å¢ƒä¸­æ— è¯­æ³•é”™è¯¯æ‰§è¡Œ |
| **Policy Generation Success Rate** | RLè®­ç»ƒæ”¶æ•›è‡³æœ€å¤§åŒ–å¥–åŠ±çš„ç­–ç•¥ï¼Œä¸”æ»¡è¶³ä»»åŠ¡ç›®æ ‡ï¼ˆæœ€å…³é”®æŒ‡æ ‡ï¼‰ |

#### å¯¹æ¯”æ–¹æ³•ï¼š
| æ–¹æ³• | æè¿° |
|------|------|
| **A-LAMP (w/ GPT-4o)** | å®Œæ•´æ¡†æ¶ï¼Œä½¿ç”¨å¼ºLLM |
| **A-LAMP w/o EC** | ç§»é™¤é”™è¯¯çº æ­£æ¨¡å—çš„ç‰ˆæœ¬ |
| **Light A-LAMP (w/ Gemma3-27B)** | è½»é‡çº§ç‰ˆæœ¬ï¼Œä½¿ç”¨è¾ƒå°LLM |
| **Single GPT-4o** | å•ä¸€LLMç›´æ¥ç”Ÿæˆå®Œæ•´ä»£ç  |
| **Single Gemma3-27B** | å•ä¸€å°å‹LLMç›´æ¥ç”Ÿæˆä»£ç  |

æ‰€æœ‰æ–¹æ³•å‡å¼•å¯¼ä½¿ç”¨**DQN**ç®—æ³•è¿›è¡Œç­–ç•¥è®­ç»ƒï¼Œä»¥ä¿æŒRLåç«¯ä¸€è‡´æ€§ï¼Œçªå‡ºå»ºæ¨¡ä¸ç¼–ç èƒ½åŠ›å·®å¼‚ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š è¡¨æ ¼ï¼šå„æ–¹æ³•åœ¨äº”é¡¹ä»»åŠ¡ä¸Šçš„æˆåŠŸç‡ä¸‰è”ä½“ï¼ˆå»ºæ¨¡ / ç¼–ç  / ç­–ç•¥ç”Ÿæˆï¼‰

| Task | A-LAMP | A-LAMP w/o EC | Light A-LAMP | Gemma3-27B | GPT-4o |
|------|--------|---------------|--------------|------------|--------|
| **Cart-pole** | â€” | 1.00/0.95/0.95 | 1.00/0.85/0.45 | 1.00/0.60/0.35 | 1.00/0.75/0.45 |
| **Mountain-car** | â€” | 1.00/1.00/0.75 | 0.95/0.70/0.55 | 1.00/0.35/0.30 | 1.00/1.00/0.40 |
| **Wireless** | 1.00/1.00/0.45 | 0.90/0.80/0.40 | 0.95/0.60/0.15 | 0.55/0.65/0.05 | 0.80/0.90/0.20 |
| **Drone-del.** | 0.80/0.95/0.45 | 0.65/0.75/0.30 | 0.55/0.50/0.15 | 0.40/0.05/0.00 | 0.35/0.55/0.10 |
| **Inv.-mgmt.** | 1.00/0.55/0.30 | 1.00/0.40/0.20 | 0.85/0.25/0.05 | 0.60/0.00/0.00 | 0.65/0.05/0.05 |

> æ³¨ï¼šâ€œâ€”â€è¡¨ç¤ºæœªæä¾›å®Œæ•´æ•°æ®ï¼›éƒ¨åˆ†ä»»åŠ¡å¯ç”¨äº†Error Correctionï¼ˆECï¼‰æ¨¡å—ã€‚

---

### ğŸ”¬ å…³é”®å‘ç°ï¼š

#### âœ… A-LAMP æ˜¾è‘—ä¼˜äºå•ä¸€LLM
- åœ¨éœ€è¦**è‡ªå®šä¹‰ç¯å¢ƒ**çš„ä»»åŠ¡ï¼ˆWireless, Drone-del., Inv.-mgmt.ï¼‰ä¸­ï¼ŒA-LAMPçš„**ç­–ç•¥ç”ŸæˆæˆåŠŸç‡æ˜¯å•ä¸€LLMçš„2å€ä»¥ä¸Š**ã€‚
- ä¾‹å¦‚åœ¨`Drone-delivery`ä»»åŠ¡ä¸­ï¼ŒA-LAMPè¾¾åˆ° **45% æˆåŠŸç‡**ï¼Œè€ŒGPT-4oä»…ä¸º10%ï¼ŒGemma3-27Bä¸º0%ã€‚

#### âœ… ç»“æ„åˆ†è§£æœ¬èº«å¸¦æ¥å·¨å¤§æ”¶ç›Š
å³ä½¿**æ²¡æœ‰é”™è¯¯çº æ­£æ¨¡å—**ï¼ŒA-LAMPä»å…¨é¢é¢†å…ˆï¼Œè¯´æ˜**å¤šAgentåˆ†å·¥æ¶æ„æ˜¯æ€§èƒ½æå‡çš„å…³é”®é©±åŠ¨å› ç´ **ã€‚

#### âœ… é”™è¯¯çº æ­£è¿›ä¸€æ­¥æå‡éš¾ä»»åŠ¡è¡¨ç°
åœ¨`Wireless`, `Drone-del.`, `Inv.-mgmt.`ä»»åŠ¡ä¸­å¯ç”¨ECåï¼ŒæˆåŠŸç‡è¿›ä¸€æ­¥æå‡ï¼Œå°¤å…¶ä½“ç°åœ¨å‡å°‘æ— æ•ˆç¼–ç æˆåŠŸï¼ˆspurious coding successï¼‰ã€‚

#### âœ… å°æ¨¡å‹ä¹Ÿèƒ½é«˜æ•ˆå·¥ä½œ
**Light A-LAMPï¼ˆGemma3-27Bï¼‰** çš„è¡¨ç°è¿œè¶…å•ç‹¬ä½¿ç”¨Gemma3-27Bï¼Œç”šè‡³æ¥è¿‘GPT-4oæ°´å¹³ï¼Œè¯æ˜æ¡†æ¶æœ¬èº«æ”¾å¤§äº†å°æ¨¡å‹æ½œåŠ›ã€‚

---

### ğŸ” å¤±è´¥æ¡ˆä¾‹åˆ†æï¼ˆFailure Analysisï¼‰
é€šè¿‡å¯¹å¤±è´¥æ¨¡å¼åˆ†ç±»ï¼ˆMÃ—/CÃ—/PÃ—ï¼‰ï¼Œæ­ç¤ºä»¥ä¸‹ä¼˜åŠ¿æ¥æºï¼š
1. **å‡å°‘â€œè™šå‡ç¼–ç æˆåŠŸâ€**ï¼ˆMÃ—, Câ—‹ï¼‰ï¼šå•ä¸€LLMå¸¸ç”Ÿæˆè¯­æ³•æ­£ç¡®ä½†è¯­ä¹‰æ— å…³çš„ä»£ç ï¼›A-LAMPå‡ ä¹æ¶ˆé™¤æ­¤ç±»æƒ…å†µã€‚
2. **é™ä½å®Œå…¨å¤±è´¥ç‡**ï¼ˆMÃ—, CÃ—ï¼‰ï¼šåœ¨`Drone-del.`ä¸­å‡å°‘60%ï¼Œåœ¨`Inv.-mgmt.`ä¸­å®Œå…¨æ¶ˆé™¤ã€‚
3. **å¢å¼ºè®­ç»ƒç¨³å®šæ€§**ï¼šæ›´å¤š(Mâ—‹, Câ—‹)å°è¯•æœ€ç»ˆæˆåŠŸè®­ç»ƒå‡ºæœ‰æ•ˆç­–ç•¥ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **ç»“æ„åŒ–å¤šAgentæ¡†æ¶æ˜¾è‘—æå‡è‡ªåŠ¨åŒ–RLå»ºæ¨¡çš„å¯é æ€§ä¸æˆåŠŸç‡**ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚ã€éœ€è‡ªå®šä¹‰ç¯å¢ƒçš„ä»»åŠ¡ä¸­ã€‚
2. **è¯­ä¹‰å¯¹é½æ˜¯å…³é”®ç“¶é¢ˆ**ï¼šA-LAMPé€šè¿‡åˆ†é˜¶æ®µå»ºæ¨¡ä¸æ˜¾å¼éªŒè¯ï¼Œæœ‰æ•ˆè§£å†³äº†â€œç›®æ ‡â†’ä»£ç â€ä¹‹é—´çš„è¯­ä¹‰æ¼‚ç§»é—®é¢˜ã€‚
3. **è½»é‡åŒ–ç‰ˆæœ¬å…·å¤‡å®ç”¨ä»·å€¼**ï¼šLight A-LAMPè¡¨æ˜è¯¥æ¡†æ¶å¯ç”¨äºèµ„æºå—é™åœºæ™¯ï¼Œæ¨åŠ¨è¾¹ç¼˜æˆ–æœ¬åœ°éƒ¨ç½²ã€‚
4. **ç”Ÿæˆç­–ç•¥å…·æœ‰æœ€ä¼˜æ€§ä¿éšœ**ï¼šåœ¨`Wireless`ä»»åŠ¡ä¸­ï¼ŒDQNç­–ç•¥é€¼è¿‘ç†è®ºæœ€ä¼˜çš„è´ªå©ªè°ƒåº¦å™¨ï¼ŒéªŒè¯äº†ç”Ÿæˆç­–ç•¥çš„è´¨é‡ã€‚

---

### âš ï¸ å±€é™æ€§
1. **ç¼–ç é˜¶æ®µä»è¾ƒè„†å¼±**ï¼šå°½ç®¡æœ‰åé¦ˆæœºåˆ¶ï¼Œä½†ç»“æ„æ€§é”™è¯¯ï¼ˆå¦‚APIè°ƒç”¨é”™è¯¯ï¼‰ä»å¯èƒ½å¯¼è‡´æ‰§è¡Œå¤±è´¥ã€‚
2. **ä¾èµ–LLMåŸºæœ¬èƒ½åŠ›è¾¹ç•Œ**ï¼šè‹¥LLMæ— æ³•ç†è§£æŸäº›é¢†åŸŸæœ¯è¯­ï¼ˆå¦‚ç‰©ç†æ¨¡å‹ï¼‰ï¼Œåˆ™æ•´ä¸ªé“¾æ¡å´©æºƒã€‚
3. **å½“å‰ä»…æ”¯æŒç¦»æ•£åŠ¨ä½œç©ºé—´**ï¼ˆDQNï¼‰ï¼Œå°šæœªæ‰©å±•è‡³è¿ç»­æ§åˆ¶ï¼ˆå¦‚PPOã€SACï¼‰ã€‚
4. **è¶…å‚æ•°æœªè‡ªåŠ¨ä¼˜åŒ–**ï¼šå­¦ä¹ ç‡ã€buffer sizeç­‰ä»å›ºå®šï¼Œå½±å“æ³›åŒ–èƒ½åŠ›ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **ç»†åŒ–ç¼–ç Agent**ï¼šæ‹†åˆ†å‡ºç‹¬ç«‹çš„â€œç¯å¢ƒæ„å»ºAgentâ€å’Œâ€œè®­ç»ƒå¾ªç¯Agentâ€ï¼Œæå‡ä»£ç å¥å£®æ€§ã€‚
2. **é›†æˆè‡ªé€‚åº”è¶…å‚æ•°è°ƒèŠ‚æœºåˆ¶**ï¼šç»“åˆè´å¶æ–¯ä¼˜åŒ–æˆ–Meta-RLè¿›è¡ŒåŠ¨æ€è°ƒå‚ã€‚
3. **èåˆé¢†åŸŸå…ˆéªŒçŸ¥è¯†**ï¼šå¼•å…¥ç»“æ„åŒ–çŸ¥è¯†å›¾è°±æˆ–é¢†åŸŸæ¨¡æ¿ï¼Œè¾…åŠ©LLMç†è§£ä¸“ä¸šæœ¯è¯­ã€‚
4. **æ”¯æŒè¿ç»­åŠ¨ä½œç©ºé—´ä¸é«˜çº§RLç®—æ³•**ï¼šæ‹“å±•è‡³æœºå™¨äººæ§åˆ¶ç­‰æ›´å¹¿æ³›åœºæ™¯ã€‚
5. **äººæœºååŒæ¥å£ä¼˜åŒ–**ï¼šå½“ç½®ä¿¡åº¦ä½æ—¶ï¼Œä¸»åŠ¨å‘èµ·äº¤äº’å¼æ¾„æ¸…å¯¹è¯ã€‚

---

## æ€»ç»“

ğŸ“Œ **A-LAMP æ˜¯è¿ˆå‘å…¨è‡ªåŠ¨å¼ºåŒ–å­¦ä¹ å·¥ç¨‹çš„é‡è¦ä¸€æ­¥**ã€‚å®ƒä¸ä»…æå‡äº†ä»è‡ªç„¶è¯­è¨€åˆ°å¯æ‰§è¡Œç­–ç•¥çš„è½¬åŒ–æ•ˆç‡ï¼Œæ›´é‡è¦çš„æ˜¯å»ºç«‹äº†**å¯è§£é‡Šã€å¯éªŒè¯ã€å¯è¿­ä»£çš„è‡ªåŠ¨åŒ–RLæµæ°´çº¿**ã€‚å…¶å®éªŒå……åˆ†è¯æ˜ï¼š**åˆç†çš„ä»»åŠ¡åˆ†è§£ + å¤šAgentåä½œ + åé¦ˆæœºåˆ¶ = æ›´å¯é ã€æ›´é«˜æˆåŠŸç‡çš„æ™ºèƒ½å†³ç­–ç³»ç»Ÿæ„å»ºæ–¹å¼**ã€‚

è¿™ä¸€æ¡†æ¶ä¸ºRLåœ¨å·¥ä¸šè‡ªåŠ¨åŒ–ã€ç½‘ç»œè°ƒåº¦ã€ä¾›åº”é“¾ä¼˜åŒ–ç­‰é¢†åŸŸçš„å¿«é€Ÿè½åœ°æä¾›äº†å¼ºæœ‰åŠ›çš„å·¥å…·æ”¯æ’‘ã€‚

</details>

---

### 10. [TriFlow: A Progressive Multi-Agent Framework for Intelligent Trip Planning](https://arxiv.org/abs/2512.11271)

**Authors**: Yuxing Chen, Basem Suleiman, Qifan Chen  
**Category**: cs.AI  
**Published**: 2025-12-15  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.11271v1  

#### Abstract
Real-world trip planning requires transforming open-ended user requests into executable itineraries under strict spatial, temporal, and budgetary constraints while aligning with user preferences. Existing LLM-based agents struggle with constraint satisfaction, tool coordination, and efficiency, ofte...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# TriFlow: A Progressive Multi-Agent Framework for Intelligent Trip Planning â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°å®ä¸–ç•Œä¸­çš„ **trip planning** æ˜¯ä¸€ä¸ªå¤æ‚çš„ä»»åŠ¡ï¼Œæ¶‰åŠè‡ªç„¶è¯­è¨€ç†è§£ã€æ—¶ç©ºçº¦æŸæ»¡è¶³å’Œå¤šç›®æ ‡ä¼˜åŒ–ã€‚ç”¨æˆ·é€šå¸¸ä»¥å¼€æ”¾ã€æ¨¡ç³Šçš„è¯­è¨€è¡¨è¾¾éœ€æ±‚ï¼ˆå¦‚â€œæœ‰è¶£çš„åœ°æ–¹â€ã€â€œå½“åœ°ç¾é£Ÿâ€ï¼‰ï¼Œè€Œç”Ÿæˆçš„è¡Œç¨‹å¿…é¡»ä¸¥æ ¼æ»¡è¶³æ—¶é—´ã€ç©ºé—´ã€é¢„ç®—å’Œåå¥½ç­‰ç¡¬æ€§çº¦æŸã€‚

ç°æœ‰çš„ **LLM-based Agent** æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- å®¹æ˜“äº§ç”Ÿ **hallucinations**ï¼ˆå¹»è§‰ï¼‰
- é¢‘ç¹è¿åç°å®ä¸–ç•Œçš„ **hard constraints**
- å·¥å…·è°ƒç”¨æ•ˆç‡ä½ï¼Œtoken æˆæœ¬é«˜
- ç¼ºä¹ç³»ç»Ÿæ€§çš„çº¦æŸç®¡ç†å’Œå¯è§£é‡Šæ€§

è¿™äº›é—®é¢˜å¯¼è‡´ç”Ÿæˆçš„è¡Œç¨‹ä¸å¯è¡Œæˆ–æˆæœ¬è¿‡é«˜ï¼Œéš¾ä»¥å®é™…éƒ¨ç½²ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šTriFlow æ¡†æ¶

TriFlow æ˜¯ä¸€ç§ **progressive multi-agent framework**ï¼Œé‡‡ç”¨ä¸‰é˜¶æ®µæµæ°´çº¿è®¾è®¡ï¼Œå°† trip planning åˆ†è§£ä¸ºä¸‰ä¸ªé€æ­¥æ”¶æ•›çš„é˜¶æ®µï¼š

1. **Retrievalï¼ˆæ£€ç´¢ï¼‰**
   - å°†ç”¨æˆ·è‡ªç„¶è¯­è¨€è¯·æ±‚åˆ†è§£ä¸ºç»“æ„åŒ–æŸ¥è¯¢
   - å¹¶è¡Œæ£€ç´¢èˆªç­ã€ä½å®¿ã€æ™¯ç‚¹ã€é¤å…ç­‰å®ä½“
   - è¿›è¡Œå»é‡ä¸å®Œæ•´æ€§æ ¡éªŒï¼ˆgeometry, time window, price consistencyï¼‰

2. **Planningï¼ˆè§„åˆ’ï¼‰**
   - åœ¨æ£€ç´¢åˆ°çš„äº‹å®å­é›†ä¸­æ„å»ºå¯è¡Œè¡Œç¨‹
   - é‡‡ç”¨ **coarse-to-fine** ç»“æ„ï¼šå…ˆç¡®å®šåŸå¸‚é¡ºåºä¸æ¯æ—¥æ—¶é—´çª—å£ï¼Œå†å¡«å……ç»†èŠ‚
   - å¼•å…¥ **agent-validator loop**ï¼šæ¯ä¸€æ­¥å»ºè®® â†’ éªŒè¯ â†’ å½’ä¸€åŒ–
   - éµå¾ª **monotonic feasibility principle**ï¼šä¸€æ—¦æ»¡è¶³çš„çº¦æŸä¸èƒ½åœ¨åç»­æ­¥éª¤ä¸­è¢«ç ´å

3. **Governanceï¼ˆæ²»ç†ï¼‰**
   - å¯¹åˆæ­¥å¯è¡Œè¡Œç¨‹è¿›è¡Œæœ‰ç•Œè¿­ä»£ä¼˜åŒ–
   - æ¯è½®ç”Ÿæˆç³»ç»ŸæŠ¥å‘Šï¼ˆé¢„ç®—ä½¿ç”¨ã€æ—¶é—´ä¸€è‡´æ€§ã€åå¥½åŒ¹é…ï¼‰
   - æå‡ºé’ˆå¯¹æ€§è°ƒæ•´ï¼ˆæ›¿æ¢æ˜‚è´µé¡¹ç›®ã€è§£å†³å†²çªã€æå‡ä¸ªæ€§åŒ–ï¼‰
   - æœ€å¤§è¿­ä»£æ¬¡æ•°é™åˆ¶ä¸º 8 æ¬¡ï¼Œç¡®ä¿æ”¶æ•›æ€§å’Œæ•ˆç‡

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | TriFlow çš„ä¼˜åŠ¿ |
|------|----------------|
| **å¯è¡Œæ€§ä¿éšœ** | æ˜¾å¼åµŒå…¥ constraint satisfaction ä½œä¸ºé¦–è¦å†³ç­–å±‚ï¼Œç¡®ä¿æ‰€æœ‰è¾“å‡ºéƒ½åœ¨å¯è¡ŒåŸŸå†… |
| **æ•ˆç‡æå‡** | é€šè¿‡é˜¶æ®µæ€§å‰ªææ˜¾è‘—ç¼©å°æœç´¢ç©ºé—´ï¼Œè¿è¡Œé€Ÿåº¦æ¯”å½“å‰ SOTA å¿« **10Ã—ä»¥ä¸Š** |
| **å¯è§£é‡Šæ€§ä¸å¯æ§æ€§** | æ¨¡å—åŒ–è®¾è®¡æ”¯æŒå¯è§‚æµ‹ä¸­é—´çŠ¶æ€ï¼Œä¾¿äºè°ƒè¯•ä¸å®¡è®¡ |
| **ä¸ªæ€§åŒ–ä¸çµæ´»æ€§** | LLM åœ¨è§„åˆ™æ¡†æ¶å†…è¿›è¡Œç»†èŠ‚æ¶¦è‰²ï¼Œå…¼é¡¾è¯­è¨€çµæ´»æ€§ä¸ç»“æ„å®‰å…¨æ€§ |
| **ç³»ç»Ÿé²æ£’æ€§** | é—­ç¯ â€œgenerate-verify-assemble-recomputeâ€ æµç¨‹å¢å¼ºå®¹é”™èƒ½åŠ› |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

- **TravelPlanner**ï¼ˆéªŒè¯é›†ï¼‰  
  åŒ…å« 180 ä¸ªå®ä¾‹ï¼Œæ¶µç›–çœŸå®æ—…è¡Œåœºæ™¯ï¼Œå¼ºè°ƒ **hard-constraint satisfaction** å’Œå¯éªŒè¯æŒ‡æ ‡ã€‚

- **TripTailor**  
  å¤§è§„æ¨¡çœŸå®ä¸–ç•ŒåŸºå‡†ï¼Œæ‰©å±•äº† POI è¦†ç›–èŒƒå›´å’Œä¸ªæ€§åŒ–ç»´åº¦ï¼Œæµ‹è¯•æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

> ä¸¤ä¸ªæ•°æ®é›†å‡æä¾›å®˜æ–¹è¯„ä¼°åè®®å’Œè„šæœ¬åŒ– checkerï¼Œä¿è¯ç»“æœå¯å¤ç°ã€‚

---

### å®éªŒè®¾ç½®

| è®¾ç½®é¡¹ | é…ç½®è¯´æ˜ |
|--------|----------|
| **Base Model** | TravelPlanner ä½¿ç”¨ GPT-4oï¼›TripTailor ä½¿ç”¨ GPT-4o-miniï¼ˆå…¬å¹³æ¯”è¾ƒï¼‰ |
| **Temperature è°ƒåº¦** | åˆ†é˜¶æ®µæ§åˆ¶åˆ›é€ æ€§ï¼š<br>â€¢ Retrieval: 0.0ï¼ˆç¡®å®šæ€§ï¼‰<br>â€¢ Planning: 0.3<br>â€¢ Governance: 0.6 |
| **æœ€å¤§è¿­ä»£æ¬¡æ•°** | Governance é˜¶æ®µæœ€å¤šæ‰§è¡Œ 8 æ¬¡ refine å¾ªç¯ |
| **è¯„ä¼°æ–¹å¼** | ä¸¥æ ¼éµå¾ªå®˜æ–¹ protocolï¼Œä½¿ç”¨ scripted checker è‡ªåŠ¨è¯„åˆ† |

---

### è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Delivery Rate** | æˆåŠŸäº¤ä»˜æœ‰æ•ˆè¡Œç¨‹çš„æ¯”ä¾‹ |
| **Commonsense Pass Rate**ï¼ˆMicro/Macroï¼‰ | è¡Œç¨‹æ˜¯å¦ç¬¦åˆå¸¸è¯†é€»è¾‘ï¼ˆå¦‚ä¸è·¨åŸåƒæ—©é¤ï¼‰ |
| **Hard Constraint Pass Rate**ï¼ˆMicro/Macroï¼‰ | æ˜¯å¦æ»¡è¶³é¢„ç®—ã€æˆ¿å‹ã€ç¦çƒŸç­‰ç¡¬æ€§è¦æ±‚ |
| **Feasibility / Rationality**ï¼ˆTripTailorï¼‰ | å¯è¡Œæ€§ä¸åˆç†æ€§ç»¼åˆè¯„åˆ† |
| **Final Pass Rate (FPR)** | æ‰€æœ‰æ£€æŸ¥å…¨éƒ¨é€šè¿‡çš„æœ€ç»ˆæˆåŠŸç‡ï¼ˆä¸»æŒ‡æ ‡ï¼‰ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿æ–¹æ³• | æ¥æº | ç‰¹ç‚¹ |
|---------|------|------|
| **FormalVerify** [3] | å½“å‰ SOTA | ä½¿ç”¨å½¢å¼åŒ–éªŒè¯å·¥å…·è¾…åŠ© LLM è§„åˆ’ |
| **Workflow** [5] | TripTailor åŸæ–‡æå‡º | åŸºäºæµç¨‹çš„å·¥ä½œæµç³»ç»Ÿ |
| **Direct** [5] | TripTailor åŸºçº¿ | ç›´æ¥ prompt LLM ç”Ÿæˆè¡Œç¨‹ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### åœ¨ TravelPlanner ä¸Šçš„ç»“æœï¼ˆTable 1ï¼‰

| Method | Commonsense (Macro) | Hard Constraint (Macro) | FPR |
|--------|---------------------|--------------------------|-----|
| FormalVerify | 95.0% | 98.9% | **93.3%** |
| **TriFlow (ours)** | **95.0%** | **96.1%** | **91.1%** |

- TriFlow åœ¨ FPR ä¸Šç•¥ä½äº FormalVerifyï¼Œä½†å·®è·å¾ˆå°ï¼ˆ91.1% vs 93.3%ï¼‰
- **è¿è¡Œæ—¶é—´ä»… 22.6s**ï¼Œç›¸æ¯” FormalVerify çš„ 245.7sï¼Œ**æé€Ÿè¶…è¿‡ 10.9Ã—**

> åœ¨ Easy/Medium/Hard éš¾åº¦ä¸Š FPR åˆ†åˆ«ä¸º 96.7%/95.0%/80.0%ï¼Œæ˜¾ç¤ºå…¶åœ¨é«˜çº¦æŸå¯†åº¦ä¸‹ä»ä¿æŒç¨³å®šè¡¨ç°ã€‚

---

### åœ¨ TripTailor ä¸Šçš„ç»“æœï¼ˆTable 2ï¼‰

| Method | Feasibility (Macro) | Rationality (Macro) | FPR |
|--------|---------------------|----------------------|-----|
| Workflow | 97.3% | 63.7% | 63.3% |
| Direct | 96.6% | 22.6% | 21.5% |
| **TriFlow (ours)** | **99.1%** | **97.7%** | **97.7%** |

- **FPR æå‡è¶… 34%**ï¼Œè¿œè¶…æœ€å¼º workflow åŸºçº¿
- æ‰€æœ‰ç»´åº¦æŒ‡æ ‡å‡ â‰¥97.6%ï¼ŒåŒ…æ‹¬ï¼š
  - Budget Compliance: **99.9%**
  - Duration Consistency: **97.6%**
  - Restaurant & Attraction Diversity: **â‰¥99.7%**
  - Complete Information: **99.9%**

---

### æ¶ˆèåˆ†æä¸å…³é”®å‘ç°ï¼ˆTable 3 & Discussionï¼‰

| ç»´åº¦ | æ”¹è¿›æ•ˆæœ |
|------|--------|
| **Within Sandbox** | ä» ~33â€“50% æå‡è‡³ **>95â€“100%**<br>â†’ æ£€ç´¢é˜¶æ®µæœ‰æ•ˆè¿‡æ»¤æ— å…³/é”™è¯¯æ•°æ® |
| **Structural Constraints**ï¼ˆå¦‚ Reasonable City Routeï¼‰ | æ¥è¿‘æˆ–è¶…è¿‡ **98%**<br>â†’ planning é˜¶æ®µçš„ monotonic feasibility è®¾è®¡æœ‰æ•ˆ |
| **Budget Compliance** | ä» 4â€“10% æå‡è‡³ **>95%**<br>â†’ governance é˜¶æ®µæˆåŠŸä¿®å¤æ®‹ä½™è¿è§„ |
| **Room Rule / Cuisine / Room Type** | å…¨éƒ¨è¾¾åˆ° **>95%** é€šè¿‡ç‡<br>â†’ æ˜¾ç¤ºå¯¹é«˜åº¦çº ç¼ çš„ hard constraints çš„å¤„ç†èƒ½åŠ› |

> **Final Pass Rate** åœ¨ Hard éš¾åº¦ä¸‹ä»æ¥è¿‘ 0% æå‡è‡³ **80.0%**ï¼Œè¯æ˜ TriFlow åœ¨å¤æ‚æ¡ä»¶ä¸‹ä¾ç„¶èƒ½äº§å‡ºå¯æ‰§è¡Œè¡Œç¨‹ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. **â€œfeasibility-firstâ€ è®¾è®¡è‡³å…³é‡è¦**  
   å°† constraint satisfaction ç½®äºä¼˜åŒ–ä¹‹å‰ï¼Œé¿å…åæœŸæ— æ³•ä¿®æ­£çš„æ ¹æœ¬æ€§é”™è¯¯ã€‚

2. **é˜¶æ®µæ€§æ¸è¿›æ”¶ç¼©ï¼ˆprogressive narrowingï¼‰ä¼˜äºç«¯åˆ°ç«¯ç”Ÿæˆ**  
   ä¸‰é˜¶æ®µæ¶æ„å®ç°äº†æœç´¢ç©ºé—´çš„æœ‰æ•ˆå‰ªæï¼Œæå‡äº†æ•ˆç‡ä¸ç¨³å®šæ€§ã€‚

3. **Rule-LLM åä½œæ¨¡å¼æ›´ä¼˜**  
   è§„åˆ™ç³»ç»Ÿè´Ÿè´£éª¨æ¶æ„å»ºä¸çº¦æŸä¿éšœï¼ŒLLM è´Ÿè´£ç»†èŠ‚æ¶¦è‰²ä¸ä¸ªæ€§åŒ–è¡¨è¾¾ï¼Œå®ç°å®‰å…¨ä¸çµæ´»çš„å¹³è¡¡ã€‚

4. **bounded iterative refinement æå‡è´¨é‡è€Œä¸ç‰ºç‰²æ•ˆç‡**  
   æœ‰é™æ¬¡è¿­ä»£å³å¯è§£å†³æ®‹ä½™é—®é¢˜ï¼Œé¿å…æ— é™å¾ªç¯æˆ–æ€§èƒ½é€€åŒ–ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

- **ä¾èµ–é«˜è´¨é‡å¤–éƒ¨æ•°æ®æº**ï¼šè‹¥ retrieval é˜¶æ®µè·å–çš„ä¿¡æ¯ä¸å…¨æˆ–ä¸å‡†ï¼Œä¼šå½±å“æ•´ä½“ç»“æœã€‚
- **å¯¹æç«¯æ¨¡ç³Šè¯·æ±‚å¤„ç†èƒ½åŠ›æœªçŸ¥**ï¼šæœªæµ‹è¯•å®Œå…¨æ— ç»“æ„è¾“å…¥ï¼ˆå¦‚â€œæˆ‘æƒ³æ•£å¿ƒâ€ï¼‰çš„è¡¨ç°ã€‚
- **å°šæœªæ¥å…¥å®æ—¶åŠ¨æ€æ•°æ®**ï¼šç›®å‰åŸºäºé™æ€æ•°æ®åº“ï¼Œæœªè€ƒè™‘å¤©æ°”å˜åŒ–ã€ç¥¨ä»·æ³¢åŠ¨ç­‰ç°å®æ‰°åŠ¨ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **ä»ç¦»çº¿è¯„ä¼°è½¬å‘åœ¨çº¿ç¯å¢ƒéƒ¨ç½²**  
   æ¥å…¥ live data retrievalï¼Œæµ‹è¯•åœ¨åŠ¨æ€æ¡ä»¶ä¸‹çš„é²æ£’æ€§ã€‚

2. **å¢å¼ºç”¨æˆ·äº¤äº’ä¸åå¥½æ¼”åŒ–å»ºæ¨¡**  
   æ”¯æŒå¤šè½®åé¦ˆä¸åå¥½æ›´æ–°ï¼Œå®ç°æŒç»­ä¼˜åŒ–ã€‚

3. **æ‰©å±•è‡³å…¶ä»–è§„åˆ’ä»»åŠ¡**  
   å¦‚ä¼šè®®å®‰æ’ã€ç‰©æµè°ƒåº¦ç­‰å…·æœ‰ç±»ä¼¼çº¦æŸç»“æ„çš„ä»»åŠ¡é¢†åŸŸã€‚

4. **è½»é‡åŒ–ç‰ˆæœ¬é€‚é…ç§»åŠ¨ç«¯åº”ç”¨**  
   åˆ©ç”¨ GPT-4o-mini ç±»é«˜æ•ˆæ¨¡å‹æ¨åŠ¨å®ç”¨è½åœ°ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼šTriFlow é€šè¿‡ **structured reasoning + LLM flexibility + progressive constraint enforcement** çš„ä¸‰é˜¶æ®µè®¾è®¡ï¼Œåœ¨ä¿è¯è¡Œç¨‹å¯è¡Œæ€§çš„å‰æä¸‹å¤§å¹…æå‡äº†æ•ˆç‡ä¸ä¸ªæ€§åŒ–æ°´å¹³ï¼Œæ˜¯è¿ˆå‘å¯é  LLM-driven planning çš„é‡è¦ä¸€æ­¥ã€‚

</details>

---

### 11. [PIAST: Rapid Prompting with In-context Augmentation for Scarce Training data](https://arxiv.org/abs/2512.11013)

**Authors**: Pawel Batorski, Paul Swoboda  
**Category**: cs.CL  
**Published**: 2025-12-15  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.11013v1  

#### Abstract
LLMs are highly sensitive to prompt design, but handcrafting effective prompts is difficult and often requires intricate crafting of few-shot examples. We propose a fast automatic prompt construction algorithm that augments human instructions by generating a small set of few shot examples. Our metho...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# PIAST: Rapid Prompting with In-context Augmentation for Scarce Training Data â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹**æç¤ºè®¾è®¡ï¼ˆprompt designï¼‰é«˜åº¦æ•æ„Ÿ**ï¼Œä½†æ‰‹åŠ¨è®¾è®¡é«˜è´¨é‡æç¤ºï¼ˆå¦‚ few-shot examplesï¼‰è´¹æ—¶ä¸”éœ€è¦ä¸“ä¸šçŸ¥è¯†ã€‚ç°æœ‰è‡ªåŠ¨æç¤ºç”Ÿæˆæ–¹æ³•å­˜åœ¨ä¸¤å¤§ç“¶é¢ˆï¼š
- **è®¡ç®—æˆæœ¬é«˜**ï¼šå¦‚ PRL éœ€è¦æ•°åå°æ—¶ï¼›
- **ä¾èµ–å¤§é‡è®­ç»ƒæ•°æ®**ï¼šè®¸å¤šæ–¹æ³•éœ€å®Œæ•´è®­ç»ƒé›†è¿›è¡Œè¯„ä¼°ï¼›
- **å¿½ç•¥ few-shot examples çš„ä¼˜åŒ–**ï¼šå¤šæ•°æ–¹æ³•ä»…ä¼˜åŒ–æŒ‡ä»¤æ–‡æœ¬ï¼ˆinstructionï¼‰ï¼Œè€Œæœªç³»ç»Ÿç”Ÿæˆæˆ–ä¼˜åŒ–ä¸Šä¸‹æ–‡ç¤ºä¾‹ã€‚

### âœ… æå‡ºçš„æ–°æ–¹æ³•ï¼šPIAST
æå‡º **PIAST**ï¼ˆPrompt Improvement with Augmented SHapley Tuningï¼‰ï¼Œä¸€ç§**å¿«é€Ÿã€æ•°æ®é«˜æ•ˆ**çš„è‡ªåŠ¨æç¤ºæ„é€ ç®—æ³•ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åœ¨äººå·¥æŒ‡ä»¤åŸºç¡€ä¸Šï¼Œ**è‡ªåŠ¨ç”Ÿæˆå°‘é‡é«˜è´¨é‡çš„ in-context few-shot examples**ï¼›
- ä½¿ç”¨ **Monte Carlo Shapley å€¼ä¼°è®¡** æ¥è¯„ä¼°æ¯ä¸ªç¤ºä¾‹çš„è¾¹é™…è´¡çŒ®ï¼Œä»è€Œå†³å®šæ˜¯å¦**æ›¿æ¢ã€åˆ é™¤æˆ–ä¿ç•™**è¯¥ç¤ºä¾‹ï¼›
- é€šè¿‡è¿­ä»£ä¼˜åŒ–æå‡æç¤ºè´¨é‡ã€‚

### âœ… ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | PIAST | APE / EvoPrompt | APO | PRL |
|------|-------|------------------|-----|-----|
| è‡ªåŠ¨ç”Ÿæˆ new examples | âœ… | âŒ | âŒï¼ˆä»…ä»è®­ç»ƒé›†é€‰ï¼‰ | âœ… |
| è¿­ä»£ä¼˜åŒ– | âœ… | âŒ | âœ… | âœ… |
| å¿«é€Ÿæ‰§è¡Œï¼ˆ<1 å°æ—¶ï¼‰ | âœ… | âœ… | âŒï¼ˆ~6hï¼‰ | âŒï¼ˆ~48hï¼‰ |
| æ•°æ®é«˜æ•ˆï¼ˆå°æ ·æœ¬ï¼‰ | âœ… | âœ… | âœ… | âŒ |
| æ”¯æŒ Shapley å€¼é€‰æ‹© | âœ… | âŒ | âŒ | âŒ |

> âœ… **PIAST æ˜¯é¦–ä¸ªå…¼å…·â€œå¿«é€Ÿâ€ã€â€œè‡ªåŠ¨ç”Ÿæˆæ–°ç¤ºä¾‹â€ã€â€œæ•°æ®é«˜æ•ˆâ€çš„è‡ªåŠ¨æç¤ºæ–¹æ³•**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
åœ¨å››å¤§ä»»åŠ¡ä¸Šè¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ï¼š

| ä»»åŠ¡ | æ•°æ®é›† | ç±»å‹ |
|------|--------|------|
| **Text Classification** | SST-2, CR, MR, SST-5, AG's News, TREC, SUBJ | å¤šç±»åˆ«æƒ…æ„Ÿ/ä¸»é¢˜åˆ†ç±» |
| **Text Simplification** | ASSET | å¥å­ç®€åŒ– |
| **Summarization** | SAMSUM | å¯¹è¯æ‘˜è¦ |
| **Mathematical Reasoning** | GSM8K | æ•°å­¦åº”ç”¨é¢˜ |

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼šä¸»æ¨¡å‹ä¸º `Qwen2.5-7B-Instruct`ï¼Œæ‰€æœ‰æ–¹æ³•ç»Ÿä¸€ä½¿ç”¨è¯¥æ¨¡å‹ä»¥ä¿è¯å…¬å¹³æ¯”è¾ƒï¼›
- **è¯„ä¼°æ–¹å¼**ï¼šæ‰€æœ‰ç»“æœåŸºäº **3 æ¬¡è¿è¡Œå¹³å‡å€¼**ï¼Œç¡®ä¿é²æ£’æ€§ï¼›
- **è¶…å‚æ•°**ï¼šä½¿ç”¨**åŒä¸€ç»„å›ºå®šè¶…å‚æ•°**è·¨ä»»åŠ¡è¿è¡Œï¼ˆè§ Table 12ï¼‰ï¼Œä½“ç°æ–¹æ³•é€šç”¨æ€§ï¼›
- **è®¡ç®—èµ„æº**ï¼šå•å¼  NVIDIA A100 GPUã€‚

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| ä»»åŠ¡ | ä¸»è¦æŒ‡æ ‡ |
|------|----------|
| Classification | Accuracy |
| Simplification | SARIï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰ |
| Summarization | ROUGE-1, ROUGE-2, ROUGE-L |
| GSM8K | Accuracyï¼ˆexact matchï¼‰ |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç®€ä»‹ |
|------|------|
| **MI (Manual Instruction)** | æ‰‹å·¥ç¼–å†™æŒ‡ä»¤ |
| **APE** | è‡ªåŠ¨ç”Ÿæˆå€™é€‰æŒ‡ä»¤å¹¶ç­›é€‰ï¼Œæ—  few-shot ç¤ºä¾‹ |
| **APO** | åŸºäºåé¦ˆè¿­ä»£ä¼˜åŒ–æç¤ºï¼Œå¯åŒ…å«è®­ç»ƒé›†ä¸­é€‰å–çš„ few-shot ç¤ºä¾‹ |
| **EvoPrompt / GA / DE** | åŸºäºè¿›åŒ–ç®—æ³•æˆ–é—ä¼ ç®—æ³•æœç´¢æç¤º |
| **PRL** | å¼ºåŒ–å­¦ä¹ ç”Ÿæˆç¤ºä¾‹ï¼Œæ€§èƒ½å¼ºä½†ææ…¢ï¼ˆ~48hï¼‰ |
| **PIAST / PIAST(E)** | æœ¬æ–‡æ–¹æ³•ï¼ˆä¸­ç­‰é¢„ç®— / æ‰©å±•é¢„ç®—ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### ï¼ˆ1ï¼‰Text Classificationï¼ˆTable 2ï¼‰
| æ–¹æ³• | å¹³å‡å‡†ç¡®ç‡ï¼ˆAvgï¼‰ | æœ€å¿«ï¼Ÿ | æ˜¯å¦ SOTAï¼Ÿ |
|------|------------------|--------|------------|
| PIAST | **81.50** | âœ…ï¼ˆæœ€å¿«ä¹‹ä¸€ï¼‰ | ç¬¬äºŒ |
| PIAST(E) | **82.79** | âŒï¼ˆçº¦ 3.7hï¼‰ | âœ…ï¼ˆæ–° SOTAï¼‰ |
| PRL | 82.14 | âŒï¼ˆ48hï¼‰ | å¦ |
| APO | 79.42 | âŒ | å¦ |

> âœ… **PIAST(E) åœ¨ AG's News å’Œ SUBJ ä¸Šè¾¾åˆ°æ–° SOTA**ã€‚

#### ï¼ˆ2ï¼‰Text Simplificationï¼ˆTable 3ï¼‰
| æ–¹æ³• | SARI | æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰ |
|------|------|-------------|
| PIAST | **54.52** | **18.14** |
| PIAST(E) | **55.06** | 389.78 |
| PRL | 52.26 | 2880.00 |
| APE | 45.33 | 35.69 |

> âœ… **PIAST åœ¨ç®€åŒ–ä»»åŠ¡ä¸Šé¦–æ¬¡è¶…è¶Š PRLï¼Œä¸”é€Ÿåº¦å¿« 150 å€ä»¥ä¸Š**ã€‚

#### ï¼ˆ3ï¼‰Summarizationï¼ˆTable 4ï¼‰
| æ–¹æ³• | ROUGE-1 | ROUGE-2 | ROUGE-L | æ—¶é—´ |
|------|---------|---------|---------|------|
| PIAST | 41.13 | 16.07 | 36.74 | **34.48 min** |
| PIAST(E) | 42.13 | **16.83** | 37.37 | 737 min |
| PRL | 42.47 | 16.17 | 37.73 | 2880 min |

> âœ… **PIAST æ’åç¬¬äºŒï¼Œé€Ÿåº¦è¿œè¶… PRLï¼›PIAST(E) åœ¨ ROUGE-2 ä¸Šæ¥è¿‘ SOTA**ã€‚

#### ï¼ˆ4ï¼‰GSM8Kï¼ˆTable 5ï¼‰
| æ–¹æ³• | å‡†ç¡®ç‡ | æ—¶é—´ |
|------|--------|------|
| PIAST | **91.65** | **80.26 min** |
| PIAST(E) | 92.12 | 1598 min |
| PRL | 86.15 | 2880 min |
| APE | 83.43 | 180 min |

> âœ… **PIAST æ˜¯å½“å‰è‡ªåŠ¨æç¤ºæ–¹æ³•ä¸­åœ¨ GSM8K ä¸Šè¡¨ç°æœ€å¥½ä¸”æœ€å¿«çš„**ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰æ˜¯å¦éœ€è¦ Replace/Drop/Keep å¾ªç¯ï¼Ÿ
- **PIAST(I)**ï¼šä»…ç”¨åˆå§‹ç”Ÿæˆç¤ºä¾‹ï¼Œä¸è¿­ä»£ä¼˜åŒ–ã€‚
- ç»“æœï¼šåœ¨ç®€å•ä»»åŠ¡ï¼ˆå¦‚ SST-2ï¼‰ä¸Šè¡¨ç°å°šå¯ï¼Œä½†åœ¨å¤æ‚ä»»åŠ¡ï¼ˆå¦‚ SUBJï¼‰ä¸Šæ˜¾è‘—ä¸‹é™ï¼ˆå·® 16.41%ï¼‰ã€‚
- â¡ï¸ è¡¨æ˜**è¿­ä»£ä¼˜åŒ–å¯¹å›°éš¾ä»»åŠ¡è‡³å…³é‡è¦**ã€‚

#### ï¼ˆ2ï¼‰Shapley vs Leave-One-Outï¼ˆLOOï¼‰
- ä½¿ç”¨ LOO æ›¿ä»£ Shapley å€¼é€‰æ‹©æœ€å·®ç¤ºä¾‹ã€‚
- ç»“æœï¼šåœ¨å¤šæ•°ä»»åŠ¡ä¸Šç›¸è¿‘ï¼Œä½†åœ¨ **SUBJ ä¸Šå·®è·æ˜æ˜¾ï¼ˆPIAST: 75.93 vs LOO: 69.73ï¼‰**ã€‚
- â¡ï¸ è¡¨æ˜ **Shapley æ›´èƒ½æ•æ‰ç¤ºä¾‹é—´çš„å†—ä½™ä¸äº’è¡¥å…³ç³»**ï¼Œä¼˜äº LOOã€‚

#### ï¼ˆ3ï¼‰Shapley æŠ½æ ·æ¬¡æ•° $K$
| $K$ | å‡†ç¡®ç‡ | æ—¶é—´ |
|-----|--------|------|
| 1 | 73.68 | 4.61 min |
| 3 | **75.93** | 8.25 min |
| 10 | 76.02 | 20.88 min |
| 50 | 76.32 | 83.90 min |

> âœ… **$K=3$ å³å¯è·å¾—è‰¯å¥½æ€§èƒ½/é€Ÿåº¦æƒè¡¡**ï¼Œæ›´å¤šæŠ½æ ·æ”¶ç›Šé€’å‡ã€‚

#### ï¼ˆ4ï¼‰è·¨æ¨¡å‹è¿ç§»èƒ½åŠ›ï¼ˆCross-model Inferenceï¼‰
- åœ¨ Qwen ä¸Šè®­ç»ƒæç¤ºï¼Œåœ¨ Mistral ä¸Šæµ‹è¯•ï¼ˆSUBJï¼‰ã€‚
- ç»“æœï¼š**PIAST è¡¨ç°æœ€å¼ºï¼ˆ72.87ï¼‰**ï¼Œè€Œ PIAST(E) å› è¿‡æ‹Ÿåˆç•¥æœ‰ä¸‹é™ï¼ˆ68.75ï¼‰ã€‚
- â¡ï¸ è¡¨æ˜ **PIAST å…·æœ‰è‰¯å¥½çš„è·¨æ¨¡å‹æ³›åŒ–èƒ½åŠ›**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **few-shot examples æ¯” instruction é‡å†™æ›´é‡è¦**ï¼š  
   ç›¸æ¯”åå¤æ”¹å†™æŒ‡ä»¤ï¼Œ**ç²¾å¿ƒæ„é€ çš„ä¸Šä¸‹æ–‡ç¤ºä¾‹æ‰æ˜¯æå‡æ€§èƒ½çš„å…³é”®æ æ†**ã€‚

2. **PIAST å®ç°äº†â€œanytime performanceâ€**ï¼š  
   - å³ä½¿åªè¿è¡Œå‡ è½®ï¼ˆå°é¢„ç®—ï¼‰ï¼Œä¹Ÿèƒ½å–å¾—ç«äº‰æ€§ç»“æœï¼›
   - éšç€è®¡ç®—é¢„ç®—å¢åŠ ï¼ˆå¦‚ 150 è½®ï¼‰ï¼Œæ€§èƒ½æŒç»­æå‡ï¼Œæœ€ç»ˆè¾¾åˆ° SOTAã€‚

3. **é€Ÿåº¦ä¸æ€§èƒ½å…¼å¾—**ï¼š  
   PIAST åœ¨å¤šä¸ªä»»åŠ¡ä¸Š**æ—¢å¿«åˆå‡†**ï¼Œå°¤å…¶é€‚åˆä½æ•°æ®ã€ä½ç®—åŠ›åœºæ™¯ã€‚

4. **Shapley å€¼æœ‰æ•ˆæŒ‡å¯¼ç¤ºä¾‹é€‰æ‹©**ï¼š  
   ç›¸æ¯”ç®€å• LOOï¼ŒShapley æ›´å‡†ç¡®è¯†åˆ«å†—ä½™æˆ–æœ‰å®³ç¤ºä¾‹ï¼Œæå‡ç¨³å®šæ€§ã€‚

5. **æ— éœ€å¤§é‡è°ƒå‚**ï¼š  
   ä¸€å¥—è¶…å‚æ•°é€šç”¨äºæ‰€æœ‰ä»»åŠ¡ï¼Œä½“ç°æ–¹æ³•é²æ£’æ€§å’Œæ˜“ç”¨æ€§ã€‚

---

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–åŸºç¡€ LLM çš„ç”Ÿæˆèƒ½åŠ›**ï¼š  
   è‹¥ LLM æœ¬èº«ä¸æ“…é•¿æŸä»»åŠ¡ï¼ˆå¦‚ä¸“ä¸šåŒ»å­¦æ¨ç†ï¼‰ï¼Œç”Ÿæˆçš„ç¤ºä¾‹å¯èƒ½è´¨é‡ä¸é«˜ã€‚

2. **PIAST(E) å­˜åœ¨è¿‡æ‹Ÿåˆé£é™©**ï¼š  
   åœ¨è·¨æ¨¡å‹æµ‹è¯•ä¸­è¡¨ç°ä¸‹é™ï¼Œè¡¨æ˜é•¿æ—¶é—´ä¼˜åŒ–å¯èƒ½å¯¼è‡´å¯¹ç‰¹å®š evaluator è¿‡æ‹Ÿåˆã€‚

3. **æœªç»“åˆ instruction é‡å†™**ï¼š  
   å½“å‰ä»…ä¼˜åŒ–ç¤ºä¾‹ï¼Œæœªæ¥å¯æ¢ç´¢ä¸ instruction æœç´¢è”åˆä¼˜åŒ–ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **ç»“åˆ instruction é‡å†™æœºåˆ¶**ï¼š  
   å°† PIAST ä¸ APE æˆ– EvoPrompt ç»“åˆï¼ŒåŒæ—¶ä¼˜åŒ–æŒ‡ä»¤å’Œç¤ºä¾‹ã€‚

2. **é™ä½å¯¹ evaluator çš„ä¾èµ–**ï¼š  
   æ¢ç´¢æ›´è½»é‡åŒ–çš„è¯„ä¼°æœºåˆ¶ï¼Œå‡å°‘å¯¹å®Œæ•´ LLM çš„è°ƒç”¨ã€‚

3. **æ‰©å±•åˆ°å¤šæ¨¡æ€æç¤ºå·¥ç¨‹**ï¼š  
   å°†ç±»ä¼¼æ¡†æ¶åº”ç”¨äºå›¾åƒ-æ–‡æœ¬æˆ–å¤šæ¨¡æ€ä»»åŠ¡ä¸­çš„ prompt æ„é€ ã€‚

4. **ç†è®ºåˆ†æ Shapley åœ¨ ICL ä¸­çš„æœ‰æ•ˆæ€§**ï¼š  
   æ¢ç´¢ä¸ºä½• Shapley èƒ½æ›´å¥½å»ºæ¨¡ç¤ºä¾‹é—´äº¤äº’ã€‚

---

> ğŸ’¡ **ä»£ç å·²å¼€æº**ï¼šhttps://github.com/Batorskq/PIAST

--- 

ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
**PIAST è¯æ˜äº†â€œé«˜è´¨é‡ few-shot ç¤ºä¾‹ + å¿«é€Ÿ Shapley ä¼˜åŒ–â€æ˜¯å®ç°é«˜æ•ˆã€é«˜æ€§èƒ½è‡ªåŠ¨æç¤ºå·¥ç¨‹çš„æ ¸å¿ƒè·¯å¾„ï¼Œå°¤å…¶é€‚ç”¨äºè®­ç»ƒæ•°æ®ç¨€ç¼ºçš„ç°å®åœºæ™¯ã€‚**

</details>

---

### 12. [Mistake Notebook Learning: Selective Batch-Wise Context Optimization for In-Context Learning](https://arxiv.org/abs/2512.11485)

**Authors**: Xuanbo Su, Yingfang Zhang, Hao Luo, Xiaoteng Liu, Leo Huang  
**Category**: cs.CL  
**Published**: 2025-12-15  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.11485v1  

#### Abstract
Large language models (LLMs) adapt to tasks via gradient fine-tuning (heavy computation, catastrophic forgetting) or In-Context Learning (ICL: low robustness, poor mistake learning). To fix this, we introduce Mistake Notebook Learning (MNL), a training-free framework with a persistent knowledge base...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Mistake Notebook Learning: Selective Batch-Wise Context Optimization for In-Context Learning è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„é€‚åº”é€šå¸¸ä¾èµ–ä¸¤ç§èŒƒå¼ï¼š**åŸºäºæ¢¯åº¦çš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰** å’Œ **æ— éœ€è®­ç»ƒçš„ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰**ã€‚  
- **SFT** è™½ç„¶æ€§èƒ½å¼ºï¼Œä½†è®¡ç®—å¼€é”€å¤§ã€æ˜“å¯¼è‡´ç¾éš¾æ€§é—å¿˜ï¼ˆcatastrophic forgettingï¼‰ã€‚  
- **ICL** è½»é‡ä¸”æ— éœ€å‚æ•°æ›´æ–°ï¼Œä½†å¯¹ç¤ºä¾‹é€‰æ‹©æ•æ„Ÿï¼Œç¼ºä¹ç³»ç»Ÿæ€§ä»é”™è¯¯ä¸­å­¦ä¹ çš„èƒ½åŠ›ã€‚

ç°æœ‰è®°å¿†å¢å¼ºæ–¹æ³•ï¼ˆå¦‚ Mementoã€TFGOï¼‰å­˜åœ¨ä¸¤å¤§æ ¹æœ¬ç¼ºé™·ï¼š
1. **å®ä¾‹çº§å™ªå£°ï¼ˆInstance-Level Noiseï¼‰**ï¼šåŸºäºå•ä¸ªé”™è¯¯è½¨è¿¹çš„è®°å¿†å®¹æ˜“è¿‡æ‹Ÿåˆç»†èŠ‚ï¼Œæ³›åŒ–èƒ½åŠ›å·®ã€‚
2. **æ— æ¡ä»¶è¿­ä»£æ›´æ–°ï¼ˆUnconditional Iterative Updatesï¼‰**ï¼šç›²ç›®æ¥å—æ‰€æœ‰åé¦ˆï¼Œå¯èƒ½å¯¼è‡´æ€§èƒ½é€€åŒ–æˆ–åœæ»ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **Mistake Notebook Learning (MNL)** â€”â€”ä¸€ç§æ— éœ€è®­ç»ƒçš„æ¡†æ¶ï¼Œé€šè¿‡ç»´æŠ¤ä¸€ä¸ªæŒç»­æ¼”åŒ–çš„â€œé”™è¯¯ç¬”è®°æœ¬â€ï¼ˆMistake Notebookï¼‰ï¼Œå®ç°ä¸Šä¸‹æ–‡ä¼˜åŒ–ä¸­çš„ç³»ç»Ÿæ€§é”™è¯¯å­¦ä¹ ã€‚

#### æ ¸å¿ƒæ€æƒ³ï¼š
- å°†ä¸Šä¸‹æ–‡ä¼˜åŒ–è§†ä¸º**æ‰¹å¤„ç†çº§åˆ«çš„çŸ¥è¯†ç§¯ç´¯è¿‡ç¨‹**ï¼Œè€Œéé€å®ä¾‹ä¿®æ­£ã€‚
- å¼•å…¥**é€‰æ‹©æ€§æ›´æ–°æœºåˆ¶**ï¼Œç¡®ä¿æ¯æ¬¡çŸ¥è¯†åº“æ›´æ–°éƒ½å¸¦æ¥å®è¯ä¸Šçš„æ€§èƒ½æå‡ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç‰¹æ€§ | MNL | å…¶ä»–æ–¹æ³•ï¼ˆå¦‚ Memento, TFGOï¼‰ |
|------|-----|-----------------------------|
| **çŸ¥è¯†è¡¨ç¤º** | ç»“æ„åŒ–äº”å…ƒç»„ï¼ˆå« anti-patternsï¼‰ | å­˜å‚¨åŸå§‹é”™è¯¯å®ä¾‹æˆ–è½¨è¿¹ |
| **æŠ½è±¡ç²’åº¦** | æ‰¹æ¬¡çº§é”™è¯¯æ¨¡å¼èšåˆï¼ˆbatch-wiseï¼‰ | å®ä¾‹çº§æˆ–å•è½¨è¿¹å¤„ç† |
| **æ›´æ–°æœºåˆ¶** | ç»éªŒéªŒè¯åé€‰æ‹©æ€§ä¿ç•™ï¼ˆempirical validationï¼‰ | è´ªå©ªå¼æ— æ¡ä»¶æ›´æ–° |
| **æŠ—å™ªèƒ½åŠ›** | é«˜ï¼ˆé€šè¿‡æ‰¹é‡æŠ½è±¡é™å™ªï¼‰ | ä½ï¼ˆæ˜“å—ä¸ªåˆ«é”™è¯¯è¯¯å¯¼ï¼‰ |
| **æ³›åŒ–æ€§** | æ˜¾å¼ anti-patterns é˜²æ­¢è¯¯ç”¨ | ç¼ºä¹é€‚ç”¨è¾¹ç•Œæ§åˆ¶ |

> âœ… MNL åœ¨ä¸ä¿®æ”¹æ¨¡å‹å‚æ•°çš„å‰æä¸‹ï¼Œå®ç°äº†æ¥è¿‘ SFT çš„æ€§èƒ½ï¼ŒåŒæ—¶æ˜¾è‘—ä¼˜äºå…¶ä»– training-free æ–¹æ³•ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

åˆ†ä¸ºä¸¤ç±»ä»»åŠ¡ï¼Œè¦†ç›–ä¸åŒæ¨ç†æ¨¡æ€ä¸æ•°æ®è§„æ¨¡ï¼š

| ç±»åˆ« | æ•°æ®é›† | æè¿° |
|------|--------|------|
| **æ•°å­¦æ¨ç†** | **GSM8K** | å°å­¦ç®—æœ¯åº”ç”¨é¢˜ï¼Œ7.4Kè®­ç»ƒæ ·æœ¬ï¼Œæ ‡å‡† benchmark |
|              | **AIME 2024/2025** | ç«èµ›çº§æ•°å­¦é¢˜ï¼ˆç¾å›½å¥¥æ•°é‚€è¯·èµ›ï¼‰ï¼Œä»…30æµ‹è¯•æ ·ä¾‹ï¼Œé«˜éš¾åº¦ |
| **Text-to-SQL** | **Spider** | è·¨é¢†åŸŸæ–‡æœ¬è½¬SQLï¼Œ7Kè®­ç»ƒæ ·æœ¬ï¼Œå¤æ‚schema |
|                 | **KaggleDBQA** | Kaggleç«èµ›æ•°æ®åº“é—®ç­”ï¼Œä»…87è®­ç»ƒæ ·æœ¬ï¼Œå°æ ·æœ¬æŒ‘æˆ˜ |

> å®éªŒè®¾è®¡æ¶µç›– **å¤§è§„æ¨¡æ•°æ®ï¼ˆlarge-dataï¼‰** ä¸ **å°æ ·æœ¬åœºæ™¯ï¼ˆfew-shot/small-dataï¼‰**ï¼ŒéªŒè¯æ–¹æ³•é²æ£’æ€§ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

| è®¾ç½®é¡¹ | å†…å®¹ |
|-------|------|
| **æ¨¡å‹** | Qwen3-8Bï¼ˆå¼€æºï¼‰ã€DeepSeekV3.2ï¼ˆé—­æºå‰æ²¿ï¼‰ã€Qwen3-Maxï¼ˆé—­æºå‰æ²¿ï¼‰ |
| **è¯„ä¼°åè®®** | Pass@32 å‡†ç¡®ç‡ï¼ˆgreedy decoding, temp=0.0ï¼‰ï¼Œbatch size=16 |
| **è¯„ä»·æŒ‡æ ‡** | - æ•°å­¦ä»»åŠ¡ï¼šnormalized exact matchï¼ˆç¬¦å·åŒ–åç²¾ç¡®åŒ¹é…ï¼‰<br>- Text-to-SQLï¼šexecution accuracyï¼ˆæ‰§è¡Œç»“æœåŒ¹é…ï¼‰ |
| **è®­ç»ƒç­–ç•¥** | å•è½®è®­ç»ƒï¼ˆsingle-epochï¼‰ï¼Œé¿å…è·¨è½®æ¬¡è¿‡æ‹Ÿåˆï¼ˆcross-epoch overfittingï¼‰ |
| **å®ç°æ–¹å¼** | è‡ªè°ƒä¼˜ï¼ˆSelf-Tuningï¼‰ä¸ºä¸»ï¼Œå³ tuner model ä¸ target model ç›¸åŒ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿æ–¹æ³• | ç®€ä»‹ |
|---------|------|
| **BASE** | Vanilla ICLï¼Œæ— ä»»ä½•ä¸Šä¸‹æ–‡ä¼˜åŒ– |
| **Memento** | Memory-based agentï¼Œå­˜å‚¨çŠ¶æ€-åŠ¨ä½œ-å¥–åŠ±è½¨è¿¹è¿›è¡Œæ£€ç´¢ |
| **TFGO** | Training-Free Group Relative Policy Optimizationï¼ŒåŸºäºç»„å†…æ¯”è¾ƒä¼˜åŒ–ä¸Šä¸‹æ–‡ |
| **SFT** | Supervised Fine-Tuningï¼Œå…¨å‚æ•°å¾®è°ƒä½œä¸ºä¸Šé™å‚è€ƒ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### ğŸ“Š æ•°å­¦æ¨ç†ä»»åŠ¡ï¼ˆTable 1ï¼‰

| Dataset | Model | BASE | TFGO | **MNL** |
|--------|--------|------|------|--------|
| GSM8K | Qwen3-8B | 91.8% | 91.2% | **93.9%** |
| AIME 2025 | Qwen3-8B | 23.0% | 23.0% | **30.0%** (+30% rel.) |
| AIME 2025 | DeepSeekV3.2 | 80.0% | 90.0% | **83.0%** |

> ğŸ”¥ MNL åœ¨ GSM8K ä¸Šè¾¾åˆ° **93.9%**ï¼Œå‡ ä¹è¿½å¹³ SFT çš„ **94.3%**ï¼Œå·®è·ä»… 0.4%ï¼Œä¸”æ— éœ€å‚æ•°æ›´æ–°ï¼

---

#### ğŸ’¬ Text-to-SQL ä»»åŠ¡ï¼ˆTable 2ï¼‰

| Dataset | Model | BASE | Memento | TFGO | **MNL** |
|--------|--------|------|----------|-------|--------|
| KaggleDBQA | Qwen3-8B | 19.0% | 15.1% | 22.1% | **28.0%** (+47% rel.) |
| KaggleDBQA | DeepSeekV3.2 | 23.8% | 19.4% | 24.3% | **31.4%** |
| Spider | Qwen3-8B | 68.9% | 67.3% | 70.1% | **71.7%** |

> ğŸš€ åœ¨ KaggleDBQA ä¸Šï¼ŒMNL ç›¸æ¯”æœ€å¼º baseline TFGO æå‡æ˜æ˜¾ï¼Œå°¤å…¶åœ¨èµ„æºå—é™çš„å°æ ·æœ¬ç¯å¢ƒä¸‹è¡¨ç°å“è¶Šã€‚

---

### **ä¸ Supervised Fine-Tuning (SFT) å¯¹æ¯”**

| ä»»åŠ¡ | æ–¹æ³• | æ€§èƒ½ | æˆæœ¬ï¼ˆç¾å…ƒï¼‰ |
|------|------|------|------------|
| GSM8K | SFT | **94.3%** | $1.98 |
|       | MNL | 93.9% | **$0.99** |
| Spider | SFT | **79.0%** | $3.32 |
|        | MNL | 71.7% | **$1.98** |

> ğŸ’¡ MNL åœ¨ GSM8K ä¸Šä»¥ **40% æ›´ä½æˆæœ¬** è¾¾åˆ°æ¥è¿‘ SFT çš„æ€§èƒ½ï¼›åœ¨ Spider ä¸Šè™½è½åï¼Œä½†ä»å¤§å¹…è¶…è¶Š base æ¨¡å‹ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### âœ… æ‰¹å¤§å°ï¼ˆBatch Sizeï¼‰çš„å½±å“ï¼ˆFigure 6ï¼‰
- Batch size=1ï¼ˆå®ä¾‹çº§ï¼‰ï¼šå‡†ç¡®ç‡ 24.0%ï¼ŒKB å¤§å° 69 æ¡ç›®
- Batch size=16ï¼ˆæ‰¹çº§åˆ«ï¼‰ï¼šå‡†ç¡®ç‡ **28.0%**ï¼ŒKB å¤§å°é™è‡³ **23 æ¡ç›®**
- â• æå‡ 17% ç›¸å¯¹æ€§èƒ½ï¼ŒåŒæ—¶çŸ¥è¯†æ›´ç´§å‡‘ï¼ŒéªŒè¯äº† batch-wise æŠ½è±¡çš„æœ‰æ•ˆæ€§ã€‚

#### âš ï¸ è®­ç»ƒè½®æ•°å½±å“ï¼ˆFigure 7ï¼‰
- å•è½®è®­ç»ƒï¼ˆSingle-epochï¼‰ï¼šæµ‹è¯•é›†å‡†ç¡®ç‡æœ€é«˜ï¼ˆ28.1%ï¼‰
- å¤šè½®è®­ç»ƒï¼šå‡ºç°ä¸¥é‡è¿‡æ‹Ÿåˆï¼ˆç¬¬2è½®æµ‹è¯•ä¸‹é™è‡³23.2%ï¼‰
- â— ç»“è®ºï¼šcontext optimization ä¸ç­‰äº parameter optimizationï¼Œéœ€é˜²æ­¢è·¨è½®æ¬¡è¿‡æ‹Ÿåˆã€‚

#### ğŸ” Self-Tuning vs Cross-Model Tuningï¼ˆTable 3ï¼‰
| é…ç½® | KaggleDBQA å‡†ç¡®ç‡ |
|------|------------------|
| Self-Tuningï¼ˆQwen3-8B è‡ªèº«ç”ŸæˆæŒ‡å¯¼ï¼‰ | 28.0% |
| Cross-Model Tuningï¼ˆDeepSeekV3.2 ä½œä¸º tunerï¼‰ | **31.0%** |

> è™½ç„¶æ›´å¼ºçš„ tuner æ¨¡å‹èƒ½ç”Ÿæˆæ›´å¥½æŒ‡å¯¼ï¼Œä½† self-tuning ä»å…·ç«äº‰åŠ›ï¼Œè¯´æ˜ MNL å¯ç”¨äºèµ„æºå—é™åœºæ™¯ä¸‹çš„è‡ªæˆ‘æ”¹è¿›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **ä¸Šä¸‹æ–‡è´¨é‡æ¯”æ•°é‡æ›´é‡è¦**ï¼šé€šè¿‡ batch-wise é”™è¯¯æŠ½è±¡æå–é€šç”¨æ¨¡å¼ï¼Œå¯æ˜¾è‘—æå‡ ICL çš„ç¨³å®šæ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚
2. âœ… **ç»“æ„åŒ–çŸ¥è¯†è¡¨ç¤ºè‡³å…³é‡è¦**ï¼šå¼•å…¥ anti-patterns æ˜ç¡®é™åˆ¶é€‚ç”¨èŒƒå›´ï¼Œæœ‰æ•ˆé˜²æ­¢é”™è¯¯è¿ç§»å’Œè¿‡åº¦æ³›åŒ–ã€‚
3. âœ… **é€‰æ‹©æ€§æ›´æ–°ä¿éšœå•è°ƒæå‡**ï¼šç»éªŒéªŒè¯æœºåˆ¶ç¡®ä¿çŸ¥è¯†åº“åªå¢ç›Šä¸é€€æ­¥ï¼Œè§£å†³ä¼ ç»Ÿè´ªå©ªæ›´æ–°çš„é£é™©ã€‚
4. âœ… **MNL æ¥è¿‘ SFT æ€§èƒ½**ï¼šåœ¨ GSM8K ä¸Šè¾¾åˆ° 93.9%ï¼Œé€¼è¿‘ SFT çš„ 94.3%ï¼Œä¸”æˆæœ¬é™ä½çº¦ 50%ã€‚
5. âœ… **ç‰¹åˆ«é€‚åˆå°æ ·æœ¬åœºæ™¯**ï¼šåœ¨ AIME å’Œ KaggleDBQA ä¸Šç›¸å¯¹æå‡é«˜è¾¾ 30â€“47%ï¼Œå±•ç°å‡ºå¼ºå¤§æ³›åŒ–æ½œåŠ›ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **è¯­ä¹‰ä¸å¯¹ç§°é—®é¢˜**ï¼šæŸ¥è¯¢æ˜¯å…·ä½“å®ä¾‹ï¼Œè€Œ subject æ˜¯æŠ½è±¡æè¿°ï¼Œembedding åŒ¹é…å¯èƒ½å¤±è´¥ã€‚
2. **åˆ†å¸ƒå¤–æ³›åŒ–æœ‰é™**ï¼šçŸ¥è¯†åº“ä»…æ•è·è®­ç»ƒåˆ†å¸ƒå†…çš„é”™è¯¯æ¨¡å¼ï¼Œå¯¹ OOD é—®é¢˜å¸®åŠ©è¾ƒå°ã€‚
3. **ä¾èµ–é«˜è´¨é‡èšç±»**ï¼šsubject clustering æ•ˆæœç›´æ¥å½±å“é”™è¯¯å½’å› ä¸æŒ‡å¯¼ç”Ÿæˆè´¨é‡ã€‚
4. **æ— æ³•å®Œå…¨æ›¿ä»£ SFT**ï¼šåœ¨å¤§è§„æ¨¡å……è¶³æ•°æ®ä¸‹ï¼ŒSFT ä»æœ‰æ€§èƒ½ä¼˜åŠ¿ï¼ˆå¦‚ Spider ä¸Š 79.0% vs 71.7%ï¼‰ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

- æ¢ç´¢åŠ¨æ€è°ƒæ•´ batch size æˆ– subject granularity çš„è‡ªé€‚åº”æœºåˆ¶ã€‚
- å¼•å…¥å¤šæ¨¡æ€æˆ–å¤–éƒ¨å·¥å…·è¾…åŠ©é”™è¯¯åˆ†æä¸æŒ‡å¯¼ç”Ÿæˆã€‚
- æ‰©å±•è‡³ agent-based planningã€long-horizon reasoning ç­‰å¤æ‚ä»»åŠ¡ã€‚
- ç ”ç©¶å¦‚ä½•å°† MNL ä¸è½»é‡å¾®è°ƒï¼ˆLoRA, Prefix-tuningï¼‰ç»“åˆï¼Œå½¢æˆ hybrid adaptation pipelineã€‚

---

## æ€»ç»“

ğŸ“Œ **MNL æ˜¯ä¸€æ¬¡å¯¹ ICL èŒƒå¼çš„æ·±åˆ»é‡æ„**ï¼šå®ƒä¸å†åªæ˜¯â€œæ‹¼æ¥ç¤ºä¾‹â€ï¼Œè€Œæ˜¯æ„å»ºä¸€ä¸ªå¯è¿›åŒ–ã€æœ‰åˆ¤æ–­åŠ›ã€å¸¦åˆ¹è½¦ç³»ç»Ÿçš„â€œé”™è¯¯ç¬”è®°æœ¬â€ã€‚  
ğŸ¯ é€šè¿‡ **structured abstraction + batch-wise aggregation + selective validation**ï¼ŒMNL å®ç°äº† training-free æ–¹æ³•åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šå‘ SFT çš„é€¼è¿‘ï¼Œä¸ºèµ„æºå—é™åœºæ™¯æä¾›äº†æå…·å¸å¼•åŠ›çš„æ›¿ä»£æ–¹æ¡ˆã€‚

> ğŸ”— å¼€æºåœ°å€ï¼š[https://github.com/Bairong-Xdynamics/MistakeNotebookLearning](https://github.com/Bairong-Xdynamics/MistakeNotebookLearning)

</details>

---

### 13. [Evaluation Framework for Centralized and Decentralized Aggregation Algorithm in Federated Systems](https://arxiv.org/abs/2512.10987)

**Authors**: Sumit Chongder  
**Category**: cs.DC  
**Published**: 2025-12-15  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.10987v1  

#### Abstract
In recent years, the landscape of federated learning has witnessed significant advancements, particularly in decentralized methodologies. This research paper presents a comprehensive comparison of Centralized Hierarchical Federated Learning (HFL) with Decentralized Aggregated Federated Learning (AFL...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEvaluation Framework for Centralized and Decentralized Aggregation Algorithm in Federated Systems

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥ç ”ç©¶èšç„¦äº**è”é‚¦å­¦ä¹ ï¼ˆFederated Learning, FLï¼‰ç³»ç»Ÿä¸­ä¸­å¿ƒåŒ–ä¸å»ä¸­å¿ƒåŒ–èšåˆç®—æ³•çš„æ€§èƒ½å¯¹æ¯”é—®é¢˜**ã€‚ä¼ ç»Ÿ **Centralized Hierarchical FL (HFL)** å­˜åœ¨ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **é€šä¿¡ç“¶é¢ˆ**ï¼šæ‰€æœ‰å®¢æˆ·ç«¯éœ€ä¸ä¸­å¤®æœåŠ¡å™¨é¢‘ç¹é€šä¿¡ï¼›
- **éšç§é£é™©**ï¼šæ•°æ®æ›´æ–°é›†ä¸­å¤„ç†å¯èƒ½æ³„éœ²æ•æ„Ÿä¿¡æ¯ï¼›
- **å¯æ‰©å±•æ€§å·®**ï¼šéš¾ä»¥é€‚åº”å¤§è§„æ¨¡ã€å¼‚æ„è®¾å¤‡ç½‘ç»œã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
è®ºæ–‡ç³»ç»Ÿæ¯”è¾ƒäº†ä¸‰ç§ä¸»æµFLèŒƒå¼ï¼š
- **HFLï¼ˆHierarchical FLï¼‰**ï¼šå±‚çº§å¼ä¸­å¿ƒåŒ–æ¶æ„ï¼›
- **AFLï¼ˆAggregated FLï¼‰**ï¼šå»ä¸­å¿ƒåŒ–çš„æ¨¡å‹èšåˆæœºåˆ¶ï¼›
- **CFLï¼ˆContinual FLï¼‰**ï¼šæ”¯æŒæŒç»­å­¦ä¹ çš„å»ä¸­å¿ƒåŒ–æ¡†æ¶ã€‚

å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š
- æ„å»ºäº†ä¸€ä¸ª**ç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶**ï¼Œç”¨äºæ¨ªå‘æ¯”è¾ƒä¸åŒFLæ¶æ„åœ¨ç›¸åŒæ¡ä»¶ä¸‹çš„è¡¨ç°ï¼›
- å¼ºè°ƒå¹¶éªŒè¯äº†**Decentralized Aggregation**åœ¨æå‡ç²¾åº¦ã€é™ä½å»¶è¿Ÿæ–¹é¢çš„æœ‰æ•ˆæ€§ï¼›
- æ¢ç´¢äº†**å»ä¸­å¿ƒåŒ–æ¶æ„å¦‚ä½•é€šè¿‡åˆ†å¸ƒå¼åä½œå®ç°é«˜æ•ˆä¸”éšç§ä¿æŠ¤çš„æ¨¡å‹è®­ç»ƒ**ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´é«˜çš„æ€§èƒ½æŒ‡æ ‡**ï¼šAFL å’Œ CFL åœ¨å¤šä¸ªè¯„ä¼°ç»´åº¦ä¸Šæ˜¾è‘—ä¼˜äº HFLï¼›
- **æ›´å¼ºçš„é²æ£’æ€§å’Œå¯æ‰©å±•æ€§**ï¼šé¿å…å•ç‚¹æ•…éšœï¼Œé€‚åˆè¾¹ç¼˜è®¡ç®—åœºæ™¯ï¼›
- **æ›´ä¼˜çš„æ—¶é—´æ•ˆç‡**ï¼šå°¤å…¶åœ¨åˆ†ç±»æ—¶é—´ï¼ˆClassification Timeï¼‰æ–¹é¢ï¼ŒCFL è¡¨ç°çªå‡ºï¼›
- **å…¼é¡¾éšç§ä¸æ€§èƒ½**ï¼šæ— éœ€ä¾èµ–ä¸­å¤®æœåŠ¡å™¨è¿›è¡Œå…¨å±€èšåˆï¼Œå¢å¼ºæ•°æ®å®‰å…¨æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
- **MNIST**ï¼šæ‰‹å†™æ•°å­—å›¾åƒæ•°æ®é›†ï¼ˆ10ç±»ï¼Œ28Ã—28ç°åº¦å›¾ï¼‰ï¼›
- **Fashion-MNIST**ï¼šæœé¥°å›¾åƒæ•°æ®é›†ï¼ˆ10ç±»ï¼Œ28Ã—28ç°åº¦å›¾ï¼‰ï¼Œæ›´å…·ç°å®æŒ‘æˆ˜æ€§ã€‚

ä¸¤ä¸ªå‡ä¸ºå…¬å¼€åŸºå‡†æ•°æ®é›†ï¼Œå¹¿æ³›ç”¨äºå›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- æ‰€æœ‰æ¨¡å‹é‡‡ç”¨ç›¸åŒçš„ **CNN æ¶æ„**ï¼š
  - ä¸‰å±‚å·ç§¯å±‚ï¼ˆ16@3Ã—3, 12@3Ã—3, 10@3Ã—3ï¼‰
  - ä¸¤å±‚ Max-Pooling
  - ReLU æ¿€æ´»å‡½æ•°
  - å…¨è¿æ¥è¾“å‡ºå±‚
- æ•°æ®åˆ†å¸ƒä¸º **IIDï¼ˆç‹¬ç«‹åŒåˆ†å¸ƒï¼‰**
- ä½¿ç”¨ **FedAvg èšåˆç®—æ³•** è¿›è¡Œå‚æ•°æ›´æ–°
- å®éªŒå·¥å…·é“¾ï¼šPython 3.11.4, TensorFlow 2.16.1, Keras 3.1.1, Jupyter Notebook

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Accuracy** | æ­£ç¡®é¢„æµ‹æ ·æœ¬å æ¯” |
| **Precision** | é¢„æµ‹ä¸ºæ­£ç±»ä¸­å®é™…ä¸ºæ­£çš„æ¯”ä¾‹ |
| **Recall** | å®é™…æ­£ç±»ä¸­è¢«æ­£ç¡®è¯†åˆ«çš„æ¯”ä¾‹ |
| **F1 Score** | Precision ä¸ Recall çš„è°ƒå’Œå¹³å‡ |
| **Build Time (s)** | æ¨¡å‹è®­ç»ƒæ€»è€—æ—¶ |
| **Classification Time (s)** | æ¨ç†é˜¶æ®µè€—æ—¶ |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Hierarchical FL (HFL)**ï¼šä½œä¸ºä¸­å¿ƒåŒ–ä»£è¡¨åŸºçº¿ï¼›
- **Aggregated FL (AFL)**ï¼šå»ä¸­å¿ƒåŒ–èšåˆï¼›
- **Continual FL (CFL)**ï¼šæ”¯æŒæŒç»­å­¦ä¹ çš„å»ä¸­å¿ƒåŒ–æ¶æ„ã€‚

ä¸‰è€…åœ¨åŒä¸€å®éªŒç¯å¢ƒä¸‹è¿›è¡Œå…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & Table 2ï¼‰

#### åœ¨ **Fashion-MNIST** ä¸Šçš„è¡¨ç°ï¼š

| Environment | Testing Acc | Precision | Recall | F1 Score | Build Time (s) | Class. Time (s) |
|------------|-------------|-----------|--------|----------|----------------|------------------|
| HFL        | 0.41        | 0.41      | 0.33   | 0.40     | 86.11          | 0.57             |
| AFL        | 0.70        | 0.71      | 0.68   | 0.68     | 55.33          | 0.47             |
| CFL        | **0.88**    | **0.88**  | **0.87**| **0.86**| 80.07          | **0.31**         |

#### åœ¨ **MNIST** ä¸Šçš„è¡¨ç°ï¼š

| Environment | Testing Acc | Precision | Recall | F1 Score | Build Time (s) | Class. Time (s) |
|------------|-------------|-----------|--------|----------|----------------|------------------|
| HFL        | 0.60        | 0.75      | 0.60   | 0.59     | 88.26          | 0.55             |
| AFL        | 0.72        | 0.76      | 0.72   | 0.72     | **54.02**      | 0.52             |
| CFL        | **0.98**    | **0.98**  | **0.98**| **0.98**| 79.02          | **0.29**         |

> æ³¨ï¼šæœ€ä½³å€¼å·²åŠ ç²—æ˜¾ç¤ºã€‚

### ğŸ” å¯¹æ¯”åˆ†æç»“æœ
- **ç²¾åº¦æ–¹é¢**ï¼š
  - CFL åœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šå‡å–å¾—æœ€é«˜æµ‹è¯•å‡†ç¡®ç‡ï¼ˆFashion-MNIST: 88%, MNIST: 98%ï¼‰ï¼Œè¿œè¶… HFLï¼›
  - AFL æ˜¾è‘—ä¼˜äº HFLï¼Œä½†ç•¥ä½äº CFLï¼›
- **æ•ˆç‡æ–¹é¢**ï¼š
  - **AFL æ‹¥æœ‰æœ€çŸ­ Build Time**ï¼ˆ~54â€“55ç§’ï¼‰ï¼Œä½“ç°å…¶å¿«é€Ÿæ”¶æ•›èƒ½åŠ›ï¼›
  - **CFL åˆ†ç±»æ—¶é—´æœ€çŸ­**ï¼ˆ~0.3ç§’ï¼‰ï¼Œé€‚åˆä½å»¶è¿Ÿæ¨ç†åœºæ™¯ï¼›
- **ç»¼åˆæ€§èƒ½**ï¼š
  - CFL åœ¨ Precisionã€Recallã€F1 Score ä¸Šå…¨é¢é¢†å…ˆï¼Œè¡¨æ˜å…¶å…·å¤‡ä¼˜ç§€çš„æ³›åŒ–èƒ½åŠ›å’Œç¨³å®šæ€§ã€‚

### âŒ æ˜¯å¦æœ‰æ¶ˆèå®éªŒï¼Ÿ
è®ºæ–‡æœªæ˜ç¡®å¼€å±•æ¶ˆèå®éªŒï¼ˆablation studyï¼‰ï¼Œä½†é€šè¿‡å¯¹ä¸‰ç§æ¶æ„çš„æ•´ä½“æ€§èƒ½å¯¹æ¯”ï¼Œé—´æ¥æ­ç¤ºäº†â€œå»ä¸­å¿ƒåŒ–â€ä¸â€œæŒç»­å­¦ä¹ â€æœºåˆ¶å¯¹æ€§èƒ½çš„å½±å“ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å»ä¸­å¿ƒåŒ– FL æ¶æ„æ˜¾è‘—ä¼˜äºä¸­å¿ƒåŒ– HFL**ï¼š
   - åœ¨ Accuracyã€Precisionã€Recallã€F1 Score ç­‰å…³é”®æŒ‡æ ‡ä¸Šå…¨é¢èƒœå‡ºï¼›
   - å°¤å…¶åœ¨å¤æ‚æ•°æ®é›†ï¼ˆå¦‚ Fashion-MNISTï¼‰ä¸Šä¼˜åŠ¿æ›´ä¸ºæ˜æ˜¾ã€‚

2. **Decentralized Aggregation æ˜¯æ€§èƒ½æå‡çš„å…³é”®æœºåˆ¶**ï¼š
   - æ”¯æŒè®¾å¤‡é—´ç›´æ¥é€šä¿¡ä¸å‚æ•°èåˆï¼Œå‡å°‘å¯¹ä¸­å¤®æœåŠ¡å™¨çš„ä¾èµ–ï¼›
   - æé«˜ç³»ç»Ÿé²æ£’æ€§ä¸éšç§ä¿éšœæ°´å¹³ã€‚

3. **CFL æ˜¯æœ€å…·æ½œåŠ›çš„èŒƒå¼**ï¼š
   - ç»“åˆ Continual Learning æ€æƒ³ï¼Œåœ¨é•¿æœŸä»»åŠ¡ä¸­ä¿æŒé«˜æ€§èƒ½ï¼›
   - åŒæ—¶å…·å¤‡è¾ƒä½çš„ Classification Timeï¼Œé€‚ç”¨äºå®æ—¶åº”ç”¨ã€‚

4. **AFL å¹³è¡¡äº†é€Ÿåº¦ä¸æ€§èƒ½**ï¼š
   - Build Time æœ€çŸ­ï¼Œé€‚åˆèµ„æºå—é™ç¯å¢ƒä¸‹çš„å¿«é€Ÿéƒ¨ç½²ï¼›
   - æ€§èƒ½ç¨³å®šï¼Œæ˜¯å®ç”¨æ€§å¼ºçš„æŠ˜ä¸­æ–¹æ¡ˆã€‚

### âš ï¸ å±€é™æ€§
- å®éªŒåŸºäº **IID æ•°æ®åˆ†å¸ƒå‡è®¾**ï¼Œæœªå……åˆ†è€ƒè™‘ç°å®ä¸­å¸¸è§çš„ **Non-IID åœºæ™¯**ï¼›
- ç¼ºä¹å¯¹é€šä¿¡å¼€é”€ã€å¸¦å®½æ¶ˆè€—ç­‰ç½‘ç»œå±‚é¢æŒ‡æ ‡çš„é‡åŒ–åˆ†æï¼›
- æœªæ¶‰åŠè®¾å¤‡å¼‚æ„æ€§ï¼ˆå¦‚ç®—åŠ›å·®å¼‚ã€æ‰çº¿ç‡ï¼‰å¯¹è®­ç»ƒè¿‡ç¨‹çš„å½±å“ï¼›
- æ²¡æœ‰æä¾›è¯¦ç»†çš„èƒ½è€—æˆ–èµ„æºå ç”¨æ•°æ®ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆä½œè€…æå‡ºï¼‰
1. **æ¢ç´¢å¤šæ ·åŒ–çš„æ•°æ®åˆ†å¸ƒç»„åˆ**ï¼šç ”ç©¶ Non-IIDã€åæ–œåˆ†å¸ƒç­‰çœŸå®åœºæ™¯ä¸‹çš„æ€§èƒ½è¡¨ç°ï¼›
2. **è§£å†³å¼‚æ„æ€§ä¸å¯æ‰©å±•æ€§é—®é¢˜**ï¼šä¼˜åŒ–å»ä¸­å¿ƒåŒ–ç½‘ç»œä¸­çš„å®¢æˆ·ç«¯é€‰æ‹©ä¸è´Ÿè½½å‡è¡¡ï¼›
3. **å¼•å…¥ä¸ªæ€§åŒ– Federated Learning**ï¼šæ”¯æŒå„å®¢æˆ·ç«¯æ ¹æ®æœ¬åœ°éœ€æ±‚å®šåˆ¶æ¨¡å‹ï¼›
4. **ç»“åˆçŸ¥è¯†è’¸é¦æˆ–è¿ç§»å­¦ä¹ **ï¼šè¿›ä¸€æ­¥æå‡å°æ ·æœ¬åœºæ™¯ä¸‹çš„è®­ç»ƒæ•ˆç‡ã€‚

---

## âœ… æ€»ç»“
æœ¬è®ºæ–‡é€šè¿‡ç³»ç»Ÿçš„å®éªŒè®¾è®¡ä¸å¤šç»´è¯„ä¼°ï¼Œè¯æ˜äº† **Decentralized FLï¼ˆç‰¹åˆ«æ˜¯ CFLï¼‰åœ¨æ€§èƒ½ã€æ•ˆç‡å’Œéšç§ä¿æŠ¤æ–¹é¢çš„ç»¼åˆä¼˜åŠ¿**ã€‚å®ƒä¸ä»…ä¸ºè”é‚¦å­¦ä¹ æ¶æ„çš„é€‰æ‹©æä¾›äº†å®è¯ä¾æ®ï¼Œä¹Ÿä¸ºæœªæ¥æ„å»ºé«˜æ•ˆã€å®‰å…¨ã€å¯æŒç»­çš„åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ç³»ç»ŸæŒ‡æ˜äº†æ–¹å‘ã€‚

</details>

---

### 14. [ECCO: Leveraging Cross-Camera Correlations for Efficient Live Video Continuous Learning](https://arxiv.org/abs/2512.11727)

**Authors**: Yuze He, Ferdi Kossmann, Srinivasan Seshan, Peter Steenkiste  
**Category**: cs.DC  
**Published**: 2025-12-15  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.11727v1  

#### Abstract
Recent advances in video analytics address real-time data drift by continuously retraining specialized, lightweight DNN models for individual cameras. However, the current practice of retraining a separate model for each camera suffers from high compute and communication costs, making it unscalable....

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ECCO: Leveraging Cross-Camera Correlations for Efficient Live Video Continuous Learning â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åŸºäºè¾¹ç¼˜æœåŠ¡å™¨çš„**å®æ—¶è§†é¢‘è¿ç»­å­¦ä¹ ç³»ç»Ÿ**ï¼ˆlive video continuous learningï¼‰é¢ä¸´ä¸¥é‡çš„èµ„æºæ•ˆç‡ç“¶é¢ˆã€‚ä¸»æµæ–¹æ³•ï¼ˆå¦‚ Ekyaã€RECLï¼‰é‡‡ç”¨â€œç‹¬ç«‹é‡è®­ç»ƒâ€ï¼ˆindependent retrainingï¼‰ç­–ç•¥ï¼Œå³ä¸ºæ¯ä¸ªæ‘„åƒå¤´å•ç‹¬é‡è®­ç»ƒä¸€ä¸ªè½»é‡çº§ DNN æ¨¡å‹ä»¥åº”å¯¹æ•°æ®æ¼‚ç§»ï¼ˆdata driftï¼‰ã€‚è¿™ç§åšæ³•å¯¼è‡´ï¼š
- **è®¡ç®—å†—ä½™**ï¼šå¤šä¸ªæ‘„åƒå¤´ç»å†ç›¸ä¼¼çš„æ•°æ®æ¼‚ç§»æ—¶ï¼Œé‡å¤è®­ç»ƒå¤šä¸ªæ¨¡å‹é€ æˆ GPU èµ„æºæµªè´¹ï¼›
- **é€šä¿¡å¼€é”€å¤§**ï¼šæ¯ä¸ªæ‘„åƒå¤´éœ€ç‹¬ç«‹ä¸Šä¼ å¤§é‡è§†é¢‘å¸§ï¼ŒåŠ å‰§å¸¦å®½å‹åŠ›ï¼›
- **æ‰©å±•æ€§å·®**ï¼šéšç€æ‘„åƒå¤´æ•°é‡å¢åŠ ï¼Œç³»ç»Ÿéš¾ä»¥ç»´æŒä½å»¶è¿Ÿå’Œé«˜ç²¾åº¦ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ ¸å¿ƒæ€æƒ³
è®ºæ–‡æå‡º **ECCO**ï¼ˆEfficient Cross-Camera Optimizationï¼‰ï¼Œä¸€ç§å…¨æ–°çš„è§†é¢‘åˆ†ææ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°æ˜¯ **group retrainingï¼ˆç»„å†…è”åˆé‡è®­ç»ƒï¼‰**ï¼Œé€šè¿‡åˆ©ç”¨è·¨æ‘„åƒå¤´ä¹‹é—´çš„**æ•°æ®æ¼‚ç§»ç›¸å…³æ€§**æ¥æå‡èµ„æºæ•ˆç‡ã€‚

#### ä¸»è¦æŠ€æœ¯è´¡çŒ®åŒ…æ‹¬ä¸‰ä¸ªæ¨¡å—ï¼š
1. **è½»é‡çº§åŠ¨æ€åˆ†ç»„ç®—æ³•**ï¼ˆLightweight Grouping Algorithmï¼‰
   - åˆ©ç”¨å…ƒæ•°æ®ï¼ˆæ—¶é—´ã€åœ°ç†ä½ç½®ï¼‰å¿«é€Ÿç­›é€‰å€™é€‰æ‘„åƒå¤´ï¼›
   - åŸºäºå®é™…æ¨¡å‹å‡†ç¡®ç‡å¢ç›Šå†³å®šæ˜¯å¦åˆå¹¶åˆ°å·²æœ‰ç»„ä¸­ï¼›
   - æ”¯æŒå‘¨æœŸæ€§é‡æ–°è¯„ä¼°ä¸åŠ¨æ€è°ƒæ•´ç»„æˆå‘˜ï¼ˆregroupingï¼‰ã€‚

2. **å…¬å¹³ä¸”é«˜æ•ˆçš„ GPU åˆ†é…å™¨**ï¼ˆGPU Allocatorï¼‰
   - æå‡ºæ–°çš„ä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼Œå¹³è¡¡æ•´ä½“æ€§èƒ½ä¸å„ç»„é—´çš„å…¬å¹³æ€§ï¼›
   - é¿å…ä¼ ç»Ÿæ–¹æ³•åå‘å¤§ç»„è€Œå¿½è§†å°ç»„çš„é—®é¢˜ï¼›
   - ä½¿ç”¨å¾®çª—å£ï¼ˆmicro-windowï¼‰è°ƒåº¦æœºåˆ¶å®ç°è´ªå©ªèµ„æºåˆ†é…ã€‚

3. **èµ„æºæ„ŸçŸ¥çš„ä¼ è¾“æ§åˆ¶å™¨**ï¼ˆTransmission Controllerï¼‰
   - åŠ¨æ€é…ç½®é‡‡æ ·å‚æ•°ï¼ˆframe rate å’Œ resolutionï¼‰ä»¥åŒ¹é… GPU é¢„ç®—ï¼›
   - è®¾è®¡å®šåˆ¶åŒ–çš„ **GAIMD æ‹¥å¡æ§åˆ¶ç®—æ³•**ï¼Œä½¿å¸¦å®½åˆ†é…ä¸ GPU åˆ†é…æœ‰æ¯”ä¾‹å…³ç³»ï¼Œå®ç°â€œè®¡ç®—-é€šä¿¡ååŒä¼˜åŒ–â€ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ECCO | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Ekya, RECLï¼‰ |
|------|------|--------------------------|
| æ¨¡å‹è®­ç»ƒæ–¹å¼ | å¤šæ‘„åƒå¤´å…±äº«æ¨¡å‹ï¼ˆgroup retrainingï¼‰ | æ¯ä¸ªæ‘„åƒå¤´ç‹¬ç«‹è®­ç»ƒï¼ˆindependent retrainingï¼‰ |
| èµ„æºåˆ©ç”¨ç‡ | æ˜¾è‘—é™ä½ GPU å’Œå¸¦å®½æ¶ˆè€— | å­˜åœ¨å¤§é‡å†—ä½™è®¡ç®—å’Œé€šä¿¡ |
| å…¬å¹³æ€§ | æ˜¾å¼ä¼˜åŒ–å°è§„æ¨¡ç»„çš„å‡†ç¡®æ€§ | å€¾å‘äºä¼˜å…ˆæœåŠ¡å¤§è§„æ¨¡ç»„ |
| å“åº”é€Ÿåº¦ | æ›´å¿«æ”¶æ•›ï¼Œå°¤å…¶åœ¨ä½å¸¦å®½ä¸‹ | å—é™äºå•æµæ•°æ®ç§¯ç´¯é€Ÿåº¦ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
è®ºæ–‡åœ¨ä¸‰ä¸ªä¸åŒç±»å‹çš„å…¬å¼€æˆ–ä»¿çœŸæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ï¼š

| æ•°æ®é›† | ç±»å‹ | æè¿° |
|--------|------|------|
| **CityFlow** | å›ºå®šäº¤é€šæ‘„åƒå¤´ | åŒ…å« 40 ä¸ªæ‘„åƒå¤´åœ¨ 10 ä¸ªåŸå¸‚è·¯å£å½•åˆ¶çš„åŒæ­¥è§†é¢‘ï¼Œç”¨äº object detection ä»»åŠ¡ |
| **MDOT** | ç§»åŠ¨æ— äººæœºæ‘„åƒå¤´ | æ¥è‡ªäº”æ¶ç¼–é˜Ÿé£è¡Œæ— äººæœºæ‹æ‘„çš„è§†é¢‘ç‰‡æ®µï¼Œä½“ç°ç§»åŠ¨åœºæ™¯ä¸‹çš„æ—¶ç©ºç›¸å…³æ€§ |
| **CARLA** | è‡ªä¸»é©¾é©¶æ¨¡æ‹Ÿå™¨ç”Ÿæˆ | åœ¨ Unreal Engine ä¸Šæ„å»ºçš„åŸå¸‚ç¯å¢ƒï¼Œå¯çµæ´»æ§åˆ¶æ‘„åƒå¤´å¸ƒå±€ä¸ç›¸ä¼¼åº¦æ°´å¹³ï¼Œç”¨äºå¯æ‰©å±•æ€§å’Œæ¶ˆèç ”ç©¶ |

### âš™ï¸ å®éªŒè®¾ç½®
- **ä»»åŠ¡ç±»å‹**ï¼šobject detectionï¼ˆYOLO11n/xï¼‰ å’Œ instance segmentationï¼ˆYOLO11n/x-Segï¼‰
- **éƒ¨ç½²æ¶æ„**ï¼šè¾¹ç¼˜è®¾å¤‡è¿è¡Œæ¨ç†ï¼Œè¾¹ç¼˜æœåŠ¡å™¨è´Ÿè´£é‡è®­ç»ƒ
- **é‡è®­ç»ƒè§¦å‘æœºåˆ¶**ï¼šæœ¬åœ°æ£€æµ‹åˆ°æ•°æ®æ¼‚ç§»åå‘é€è¯·æ±‚
- **èµ„æºçº¦æŸ**ï¼šæœ‰é™ GPU æ•°é‡ï¼ˆæœ€å¤š 5Ã—RTX 4090ï¼‰ã€å…±äº«ä¸Šè¡Œå¸¦å®½ï¼ˆ3â€“50 Mbpsï¼‰

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **mAP**ï¼ˆmean Average Precisionï¼‰ | è¡¡é‡æ£€æµ‹/åˆ†å‰²ä»»åŠ¡çš„æ•´ä½“å‡†ç¡®ç‡ |
| **Response Time / Retraining Latency** | è¾¾åˆ°ç›®æ ‡ mAP æ‰€éœ€çš„æ—¶é—´ |
| **Scalability** | åœ¨å›ºå®šèµ„æºä¸‹æ”¯æŒçš„æœ€å¤§æ‘„åƒå¤´æ•° |
| **Fairness** | ä¸åŒç»„ä¹‹é—´å‡†ç¡®ç‡å·®å¼‚ç¨‹åº¦ |

### ğŸ” å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
| åŸºçº¿ | ç‰¹ç‚¹ |
|------|------|
| **Naive Baseline** | å‡åŒ€åˆ†é… GPUï¼Œå›ºå®šé‡‡æ ·é…ç½®ï¼Œå¹³å‡å…±äº«å¸¦å®½ |
| **Ekya** | åŠ¨æ€ GPU è°ƒåº¦ï¼Œä½†ä»ç‹¬ç«‹è®­ç»ƒæ¯ä¸ªæ¨¡å‹ |
| **RECL** | ä½¿ç”¨å†å²æ¨¡å‹åˆå§‹åŒ–ï¼ˆmodel zooï¼‰ï¼Œæå‡æ”¶æ•›é€Ÿåº¦ï¼Œä»ä¸ºç‹¬ç«‹è®­ç»ƒ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| æŒ‡æ ‡ | ECCO æå‡å¹…åº¦ |
|------|---------------|
| **mAP æå‡ï¼ˆç›¸åŒèµ„æºï¼‰** | +6.7% ~ 18.1% |
| - Object Detection | +6.7% ~ 16.6% |
| - Instance Segmentation | +9.3% ~ 18.1% |
| **æ”¯æŒå¹¶å‘æ‘„åƒå¤´æ•°** | **3.3Ã— æ›´å¤š**ï¼ˆç›¸åŒå‡†ç¡®ç‡ï¼‰ |
| **å“åº”æ—¶é—´ç¼©çŸ­ï¼ˆä½å¸¦å®½ä¸‹ï¼‰** | **>5Ã— æ›´å¿«** |
| **æ‰€éœ€å¸¦å®½ï¼ˆè¾¾åˆ°ç›¸åŒç²¾åº¦ï¼‰** | ä»…éœ€åŸºçº¿çš„ **25%â€“33%** |

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ **4 GPU + 6 Mbps å¸¦å®½**æ¡ä»¶ä¸‹ï¼ŒECCO åœ¨ CityFlow ä¸Šå°† object detection mAP ä»çº¦ 35% æå‡è‡³æ¥è¿‘ 40%ï¼Œè€ŒåŸºçº¿éœ€è¦æ›´å¤š GPU æ‰èƒ½è¾¾åˆ°åŒç­‰æ•ˆæœã€‚
- åœ¨ **22-camera å¯æ‰©å±•æ€§æµ‹è¯•**ä¸­ï¼Œå½“æ‘„åƒå¤´æ•°é‡ä¸Šå‡æ—¶ï¼Œæ‰€æœ‰åŸºçº¿æ–¹æ³•æ€§èƒ½æ€¥å‰§ä¸‹é™ï¼Œè€Œ ECCO ä¸‹é™æ›´ç¼“ï¼Œ**åœ¨ç›¸åŒèµ„æºä¸‹æ”¯æŒ 3.3Ã— æ›´å¤šæ‘„åƒå¤´**ã€‚
- åœ¨ä½å¸¦å®½ï¼ˆ<200 Kbpsï¼‰ç¯å¢ƒä¸‹ï¼ŒECCO çš„å“åº”æ—¶é—´ä»…ä¸ºåŸºçº¿çš„ **41.3%â€“61.1%**ï¼Œä¼˜åŠ¿æ˜¾è‘—ã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰åŠ¨æ€åˆ†ç»„æœ‰æ•ˆæ€§ï¼ˆFig. 9ï¼‰
- å±•ç¤ºäº†ä¸‰è¾†ç§»åŠ¨è½¦è¾†ä¸Šçš„æ‘„åƒå¤´å¦‚ä½•å› è·¯å¾„å˜åŒ–è¢«åŠ¨æ€æ‹†åˆ†å‡ºåŸç»„ï¼›
- éªŒè¯äº† ECCO èƒ½åŠæ—¶è¯†åˆ«åˆ†å¸ƒåç§»å¹¶è¿›è¡Œ regroupingï¼Œé¿å…é”™è¯¯èšåˆã€‚

#### ï¼ˆ2ï¼‰GPU åˆ†é…å™¨å…¬å¹³æ€§ï¼ˆFig. 10ï¼‰
- ä½¿ç”¨ RECL çš„åˆ†é…å™¨ä¼šå¯¼è‡´å°è§„æ¨¡ç»„ï¼ˆ1 cameraï¼‰é•¿æœŸé¥¥é¥¿ï¼Œå‡†ç¡®ç‡è½åé«˜è¾¾ 23% mAPï¼›
- ECCO çš„åˆ†é…å™¨å®ç°äº†è¿‘ä¼¼åŒæ­¥çš„å‡†ç¡®ç‡å¢é•¿ï¼Œå…¼é¡¾æ•´ä½“æ€§èƒ½ä¸å…¬å¹³æ€§ã€‚

#### ï¼ˆ3ï¼‰ä¼ è¾“æ§åˆ¶å™¨æœ‰æ•ˆæ€§ï¼ˆFig. 11ï¼‰
- å…³é—­æ§åˆ¶å™¨æ—¶ï¼Œå³ä½¿å¸¦å®½å……è¶³ä¹Ÿæ— æ³•å……åˆ†åˆ©ç”¨ GPUï¼›
- å¯ç”¨åï¼Œåœ¨ **ä»… 1/3 å¸¦å®½**ä¸‹å³å¯è¾¾åˆ°ç›¸è¿‘ç”šè‡³æ›´é«˜çš„ mAPï¼›
- å®ç°äº†æ¥è¿‘ç†æƒ³çš„ **GPU-proportional bandwidth allocation**ï¼Œå°¤å…¶åœ¨å¼‚æ„ç½‘ç»œä¸­è¡¨ç°ç¨³å¥ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **è·¨æ‘„åƒå¤´æ•°æ®æ¼‚ç§»å…·æœ‰å¼ºæ—¶ç©ºç›¸å…³æ€§**ï¼Œå°¤å…¶æ˜¯åœ¨åœ°ç†é‚»è¿‘æˆ–è¿åŠ¨ä¸€è‡´çš„åœºæ™¯ä¸­ï¼ˆå¦‚æ— äººæœºç¼–é˜Ÿã€åŸå¸‚äº¤å‰å£ï¼‰ï¼Œè¿™ä¸ºæ¨¡å‹å…±äº«æä¾›äº†ç†è®ºåŸºç¡€ã€‚
2. **group retraining æ˜¯é«˜æ•ˆè¿ç»­å­¦ä¹ çš„å…³é”®èŒƒå¼è½¬å˜**ï¼šé€šè¿‡èšåˆç›¸ä¼¼æ¼‚ç§»çš„æ‘„åƒå¤´æ•°æ®è®­ç»ƒå…±äº«æ¨¡å‹ï¼Œå¤§å¹…å‡å°‘å†—ä½™è®¡ç®—å’Œé€šä¿¡å¼€é”€ã€‚
3. **è®¡ç®—ä¸é€šä¿¡å¿…é¡»è”åˆä¼˜åŒ–**ï¼šECCO è¯æ˜äº† GPU åˆ†é…ä¸å¸¦å®½åˆ†é…çš„è€¦åˆè®¾è®¡èƒ½æ˜¾è‘—æå‡ç«¯åˆ°ç«¯æ•ˆç‡ã€‚
4. **ECCO åœ¨ä½å¸¦å®½ã€é«˜è´Ÿè½½åœºæ™¯ä¸‹ä¼˜åŠ¿æœ€æ˜æ˜¾**ï¼šå¾—ç›Šäºè‡ªç„¶çš„æ¨¡å‹å¤ç”¨ï¼ˆnatural model reuseï¼‰å’Œæ•°æ®èšåˆæ•ˆåº”ï¼Œå“åº”é€Ÿåº¦å¤§å¹…æå‡ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–æ¼‚ç§»ç›¸å…³æ€§çš„å­˜åœ¨**ï¼šè‹¥æ‘„åƒå¤´é—´æ— æ˜¾è‘—ç›¸å…³æ€§ï¼ˆå¦‚å®Œå…¨å¼‚æ„åœºæ™¯ï¼‰ï¼Œgroup retraining æ•ˆæœæœ‰é™ï¼ˆè§ Fig. 8ï¼Œlow-similarity åœºæ™¯å¢ç›Šå¾ˆå°ï¼‰ï¼›
- **åˆ†ç»„å†³ç­–å¼•å…¥é¢å¤–å»¶è¿Ÿ**ï¼šè™½ç„¶æ•´ä½“å»¶è¿Ÿæ›´ä½ï¼Œä½†åˆå§‹ grouping éœ€è¦ä¸€å®šå¤„ç†æ—¶é—´ï¼›
- **å¯¹æ‹¥å¡æ§åˆ¶åè®®æœ‰ä¸€å®šå‡è®¾**ï¼šä¾èµ– GAIMD çš„ç¨³æ€è¡Œä¸ºï¼Œåœ¨æç«¯å¤æ‚ç½‘ç»œæ‹“æ‰‘ä¸­å¯èƒ½åç¦»ç†æƒ³åˆ†é…ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å°† ECCO æ‰©å±•è‡³æ›´å¤šè§†è§‰ä»»åŠ¡ï¼ˆå¦‚ action recognition, trackingï¼‰ï¼›
- æ¢ç´¢é GAIMD çš„æ›´å…ˆè¿›æ‹¥å¡æ§åˆ¶æœºåˆ¶ä»¥è¿›ä¸€æ­¥é€¼è¿‘æœ€ä¼˜å¸¦å®½åˆ†é…ï¼›
- å¼•å…¥é¢„æµ‹æœºåˆ¶æå‰é¢„åˆ¤æ¼‚ç§»è¶‹åŠ¿ï¼Œå®ç° proactive groupingï¼›
- ç»“åˆè”é‚¦å­¦ä¹ æ€æƒ³ï¼Œåœ¨ä¿æŠ¤éšç§çš„å‰æä¸‹å®ç°è·¨åŸŸåä½œã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> ECCO é€šè¿‡æ´å¯Ÿå¹¶åˆ©ç”¨è·¨æ‘„åƒå¤´æ•°æ®æ¼‚ç§»çš„ç›¸å…³æ€§ï¼Œæå‡ºäº† group retraining æ–°èŒƒå¼ï¼Œå¹¶é€šè¿‡ GPU åˆ†é…ã€ä¼ è¾“æ§åˆ¶ä¸åŠ¨æ€åˆ†ç»„ä¸‰å¤§æ¨¡å—ååŒä¼˜åŒ–ï¼Œå®ç°äº†**æ›´é«˜ç²¾åº¦ã€æ›´å¼ºæ‰©å±•æ€§ã€æ›´å¿«å“åº”é€Ÿåº¦**çš„å®æ—¶è§†é¢‘è¿ç»­å­¦ä¹ ç³»ç»Ÿï¼Œä»£è¡¨äº†è¯¥é¢†åŸŸçš„é‡è¦è¿›æ­¥ã€‚

</details>

---

### 15. [Refining Graphical Neural Network Predictions Using Flow Matching for Optimal Power Flow with Constraint-Satisfaction Guarantee](https://arxiv.org/abs/2512.11127)

**Authors**: Kshitiz Khanal  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.11127v1  

#### Abstract
The DC Optimal Power Flow (DC-OPF) problem is fundamental to power system operations, requiring rapid solutions for real-time grid management. While traditional optimization solvers provide optimal solutions, their computational cost becomes prohibitive for large-scale systems requiring frequent rec...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRefining Graphical Neural Network Predictions Using Flow Matching for Optimal Power Flow with Constraint-Satisfaction Guarantee

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **DC Optimal Power Flow (DC-OPF)** é—®é¢˜ä¸­ä¼ ç»Ÿä¼˜åŒ–æ±‚è§£å™¨è®¡ç®—è€—æ—¶é«˜ã€è€Œæœºå™¨å­¦ä¹ æ–¹æ³•å¸¸å­˜åœ¨**çº¦æŸä¸æ»¡è¶³**å’Œ**æˆæœ¬éæœ€ä¼˜**çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å…¼é¡¾**é€Ÿåº¦ã€å¯è¡Œæ€§ä¸ç»æµæ€§**çš„æ–°å‹ä¸¤é˜¶æ®µå­¦ä¹ æ¡†æ¶ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ä¸ª**ä¸¤é˜¶æ®µç‰©ç†ä¿¡æ¯é©±åŠ¨çš„å­¦ä¹ æ¡†æ¶**ï¼Œç»“åˆ **Graph Neural Networks (GNNs)** ä¸ **Continuous Flow Matching (CFM)**ï¼š

- **Stage 1: ç‰©ç†ä¿¡æ¯ GNNï¼ˆPhysics-Informed GNNï¼‰**
  - è®¾è®¡äº†ä¸€ä¸ªåŸºäºå›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰çš„æ¨¡å‹ï¼Œç›´æ¥å°†ç”µåŠ›ç³»ç»Ÿæ‹“æ‰‘ç»“æ„ä½œä¸ºè¾“å…¥ã€‚
  - åœ¨è®­ç»ƒç›®æ ‡ä¸­åµŒå…¥äº†å¤šä¸ªç‰©ç†è§„å¾‹ä¸æœ€ä¼˜æ€§æ¡ä»¶ï¼š
    - ç»æµè°ƒåº¦åŸåˆ™ï¼ˆè¾¹é™…æˆæœ¬ç›¸ç­‰ï¼‰
    - åŸºå°”éœå¤«å®šå¾‹ï¼ˆåŠŸç‡å¹³è¡¡ï¼‰
    - å‘ç”µæœºä¸Šä¸‹é™çº¦æŸ
    - KKT äº’è¡¥æ¡ä»¶ï¼ˆKarush-Kuhn-Tuckerï¼‰
  - å¼•å…¥**å¯å¾®æŠ•å½±å±‚ï¼ˆdifferentiable projectionï¼‰** å’Œ **æ¸è¿›è¯¾ç¨‹å­¦ä¹ ï¼ˆprogressive curriculum learningï¼‰**ï¼Œé€æ­¥ä»â€œæ»¡è¶³çº¦æŸâ€è¿‡æ¸¡åˆ°â€œé€¼è¿‘æœ€ä¼˜â€ã€‚

- **Stage 2: è¿ç»­æµåŒ¹é…ç²¾ç‚¼ï¼ˆCFM Refinementï¼‰**
  - é¦–æ¬¡å°† **Continuous Flow Matching (CFM)** åº”ç”¨äº OPF ä¼˜åŒ–ä»»åŠ¡ï¼Œå°†å…¶è§†ä¸ºä»å¯è¡Œè§£å‘æœ€ä¼˜è§£çš„â€œæ¡ä»¶ç”Ÿæˆâ€è¿‡ç¨‹ã€‚
  - åˆ©ç”¨ CFM å­¦ä¹ ä¸€ä¸ªå‘é‡åœºï¼ˆvector fieldï¼‰ï¼Œé€šè¿‡ ODE ç§¯åˆ†å°† Stage 1 è¾“å‡ºçš„åˆå§‹å¯è¡Œè§£ $ p_g^{(0)} $ æ˜ å°„è‡³æ¥è¿‘æœ€ä¼˜çš„è§£ $ p_g^* $ã€‚
  - åœ¨ç²¾ç‚¼é˜¶æ®µå¼•å…¥é¢å¤–çš„ç‰©ç†æ„ŸçŸ¥æŸå¤±å‡½æ•°ï¼Œç¡®ä¿åœ¨æå‡ç»æµæ€§çš„åŒæ—¶ä¿æŒå¯è¡Œæ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **å¯è¡Œæ€§ä¿éšœ** | é€šè¿‡è½¯/ç¡¬æŠ•å½±æœºåˆ¶å’Œç‰©ç†æ­£åˆ™é¡¹ï¼Œå®ç° **100% å¯è¡Œæ€§**ï¼Œä¼˜äºå¤šæ•°çº¯ç›‘ç£ ML æ–¹æ³•ã€‚ |
| **æˆæœ¬æœ€ä¼˜æ€§** | CFM ç²¾ç‚¼æ˜¾è‘—ç¼©å°æˆæœ¬å·®è·ï¼Œåœ¨æ ‡ç§°è´Ÿè½½ä¸‹è¾¾åˆ° **<0.1% æˆæœ¬é—´éš™**ï¼Œè¿œä¼˜äºä»…ä½¿ç”¨ GNN çš„åŸºçº¿ã€‚ |
| **æ³›åŒ–èƒ½åŠ›** | å€ŸåŠ©ç‰©ç†å…ˆéªŒè€Œéå•çº¯æ‹Ÿåˆæ•°æ®ï¼Œæ¨¡å‹åœ¨è®­ç»ƒåˆ†å¸ƒå¤–ï¼ˆå¦‚ 70% æˆ– 130% è´Ÿè½½ï¼‰ä»è¡¨ç°ç¨³å¥ã€‚ |
| **è®­ç»ƒæ•ˆç‡** | CFM é‡‡ç”¨å›å½’å¼æ— æ¨¡æ‹Ÿè®­ç»ƒï¼ˆsimulation-freeï¼‰ï¼Œé¿å…ä¼ ç»Ÿ CNF ä¸­æ˜‚è´µçš„åå‘ä¼ æ’­ ODE æ±‚è§£ï¼Œæ”¯æŒæ··åˆç²¾åº¦åŠ é€Ÿã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨æ ‡å‡†æµ‹è¯•ç³»ç»Ÿï¼š**IEEE 30-bus system**
  - åŒ…å« 30 ä¸ªèŠ‚ç‚¹ï¼ˆbusesï¼‰ã€6 å°å‘ç”µæœºã€41 æ¡è¾“ç”µçº¿è·¯
  - å‘ç”µæœºå‚æ•°è§ Table Iï¼ˆæˆæœ¬ç³»æ•°ã€å®¹é‡é™åˆ¶ç­‰ï¼‰

### å®éªŒè®¾ç½®
- **è®­ç»ƒæ•°æ®ç”Ÿæˆ**ï¼š
  - é€šè¿‡ SLSQP æ±‚è§£å™¨ç”Ÿæˆ 20,000 ä¸ªæ ·æœ¬
  - è¾“å…¥ä¸ºè´Ÿè·å‘é‡ $ p_d $
  - è¾“å‡ºä¸ºæœ€ä¼˜å‘ç”µè°ƒåº¦ $ p_g^* $ å’Œå¯¹åº”æˆæœ¬
  - è´Ÿè·èŒƒå›´ï¼š70%â€“100% åŸºå‡†è´Ÿè·ï¼ˆuniform samplingï¼‰

- **è¯„ä¼°åœºæ™¯ï¼ˆå…±äº”ç±»ï¼‰**ï¼š
  | åœºæ™¯ | è´Ÿè½½åŒºé—´ | æ˜¯å¦è¶…å‡ºè®­ç»ƒåˆ†å¸ƒ |
  |------|--------|----------------|
  | Very Low Load | 70%â€“75% | æ˜¯ï¼ˆå¤–æ¨ï¼‰ |
  | Low Load | 83%â€“88% | å¦ |
  | Nominal Load | 95%â€“100% | å¦ |
  | High Load | 110%â€“115% | æ˜¯ï¼ˆå¤–æ¨ï¼‰ |
  | Very High Load | 125%â€“130% | æ˜¯ï¼ˆå‹åŠ›æµ‹è¯•ï¼‰ |

- **æ¯ç±»æµ‹è¯• 100 ä¸ªæ ·æœ¬**

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Cost Gap (%)** | $\frac{C(\hat{p}_g) - C(p_g^*)}{C(p_g^*)} \times 100\%$ |
| **Feasibility Rate (%)** | æ»¡è¶³æ‰€æœ‰çº¦æŸï¼ˆè¯¯å·® < 0.1 MWï¼‰çš„æ¯”ä¾‹ |
| **Worst-Case Gap (%)** | æ‰€æœ‰æµ‹è¯•æ ·æœ¬ä¸­çš„æœ€å¤§æˆæœ¬é—´éš™ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **SLSQP Solver**ï¼šä½œä¸ºæœ€ä¼˜åŸºå‡†ï¼ˆground truthï¼‰
- **GNN Only**ï¼šä»… Stage 1 çš„ç‰©ç†ä¿¡æ¯ GNNï¼Œæ—  CFM ç²¾ç‚¼
- **CFM Refined**ï¼šæœ¬æ–‡æå‡ºçš„å®Œæ•´ä¸¤é˜¶æ®µæ–¹æ³•

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table IIï¼‰

| åœºæ™¯ | GNN æˆæœ¬é—´éš™ (%) | CFM æˆæœ¬é—´éš™ (%) | CFM å¯è¡Œæ€§ (%) | æœ€å·®æƒ…å†µé—´éš™ (%) |
|------|------------------|------------------|---------------|------------------|
| Very Low (70â€“75%) | 7.86 | **0.03** | 100.0 | 0.04 |
| Low (83â€“88%) | 9.60 | **0.05** | 100.0 | 0.05 |
| Nominal (95â€“100%) | 10.78 | **0.07** | 100.0 | 0.16 |
| High (110â€“115%) | 9.48 | **2.59** | 100.0 | 3.60 |
| Very High (125â€“130%) | 7.17 | **2.84** | 100.0 | 3.15 |

> âœ… æ‰€æœ‰åœºæ™¯ä¸‹å‡å®ç° **100% å¯è¡Œæ€§**

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆCFM vs GNN Onlyï¼‰
- åœ¨æ ‡ç§°è´Ÿè½½ä¸‹ï¼ŒCFM å°†æˆæœ¬é—´éš™ä» **10.78% é™è‡³ 0.07%**ï¼Œé™å¹…è¾¾ **10.71 ä¸ªç™¾åˆ†ç‚¹**
- å³ä½¿åœ¨æç«¯è´Ÿè½½æ¡ä»¶ä¸‹ï¼ˆ125â€“130%ï¼‰ï¼Œä¹Ÿèƒ½å°†å¹³å‡æˆæœ¬é—´éš™æ§åˆ¶åœ¨ **2.84%** å†…ï¼Œæœ€åæƒ…å†µä»…ä¸º **3.15%**
- å¦‚ Table III æ‰€ç¤ºï¼ŒCFM åœ¨æ‰€æœ‰åœºæ™¯ä¸‹éƒ½å¸¦æ¥æ˜¾è‘—æ”¹è¿›ï¼š
  - æˆæœ¬é™ä½å¹…åº¦ï¼š4.04% ~ 9.67%
  - æˆæœ¬é—´éš™å‡å°‘ï¼š4.33 ~ 10.71 p.p.

### æ¶ˆèå®éªŒä¸åˆ†æï¼ˆéšå«äºè®­ç»ƒåŠ¨æ€ï¼‰
- **Stage 1ï¼ˆGNNï¼‰**ï¼šç»è¿‡ç‰©ç†ä¿¡æ¯è®­ç»ƒåå·²èƒ½è¾“å‡º**å®Œå…¨å¯è¡Œ**çš„è§£ï¼Œä½†æˆæœ¬åé«˜ï¼ˆ7â€“11% é—´éš™ï¼‰
- **Stage 2ï¼ˆCFMï¼‰**ï¼šè¿›ä¸€æ­¥ç²¾ç‚¼ä½¿æˆæœ¬å¤§å¹…ä¸‹é™ï¼ŒéªŒè¯äº†â€œ**å¯è¡Œåˆå§‹åŒ– + æ¸è¿›ä¼˜åŒ–è·¯å¾„å­¦ä¹ **â€çš„æœ‰æ•ˆæ€§
- **éå•è°ƒæ”¶æ•›è¡Œä¸º**ï¼ˆè§ Fig. 3ï¼‰è¡¨æ˜ CFM èƒ½æœ‰æ•ˆå¹³è¡¡ flow matching ä¸ cost minimization ç›®æ ‡

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç‰©ç†å…ˆéªŒæ˜¯å…³é”®**  
   å°†ç»æµè°ƒåº¦ã€KKT æ¡ä»¶ã€åŠŸç‡å¹³è¡¡ç­‰ç‰©ç†è§„å¾‹ç¼–ç è¿›æŸå¤±å‡½æ•°ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„**æ³›åŒ–èƒ½åŠ›å’Œçº¦æŸæ»¡è¶³ç‡**ï¼Œå°¤å…¶åœ¨è®­ç»ƒåˆ†å¸ƒä¹‹å¤–ä¾ç„¶ç¨³å®šã€‚

2. **ä¸¤é˜¶æ®µè®¾è®¡ä¼˜åŠ¿æ˜æ˜¾**  
   - GNN æ“…é•¿å»ºæ¨¡æ‹“æ‰‘å¹¶ä¿è¯å¯è¡Œæ€§
   - CFM æ“…é•¿åœ¨å¯è¡ŒåŸŸå†…æ²¿æœ€ä¼˜è·¯å¾„è¿›è¡Œç²¾ç»†åŒ–è°ƒæ•´
   - åˆ†å·¥æ˜ç¡®ï¼ŒååŒå¢æ•ˆ

3. **CFM é¦–æ¬¡æˆåŠŸåº”ç”¨äº OPF ä¼˜åŒ–**  
   å°†ä¼˜åŒ–é—®é¢˜è½¬åŒ–ä¸ºâ€œä»å¯è¡Œè§£åˆ°æœ€ä¼˜è§£â€çš„è¿ç»­å˜æ¢ï¼Œåˆ©ç”¨ CFM å­¦ä¹ å‘é‡åœºï¼Œå®ç°äº†é«˜æ•ˆä¸”å¯å¯¼çš„ç²¾ç‚¼è¿‡ç¨‹ï¼Œå…·æœ‰è¾ƒå¼ºçš„é€šç”¨æ½œåŠ›ã€‚

4. **å®ç”¨æ€§å¼º**  
   æ¨ç†é€Ÿåº¦å¿«ï¼ˆå‰å‘ä¼ æ’­ + ODE ç§¯åˆ†ï¼‰ï¼Œé€‚ç”¨äºéœ€è¦é¢‘ç¹æ›´æ–°è°ƒåº¦æ–¹æ¡ˆçš„é«˜æ¯”ä¾‹å¯å†ç”Ÿèƒ½æºç”µç½‘ã€‚

### å±€é™æ€§
1. **ä»…é™äº DC-OPF**  
   å¿½ç•¥äº†ç”µå‹å¹…å€¼ã€æ— åŠŸåŠŸç‡å’Œéçº¿æ€§ AC åŠŸç‡æµæ–¹ç¨‹ï¼Œéš¾ä»¥ç›´æ¥ç”¨äºå®é™…ç”µç½‘è¿è¡Œã€‚

2. **è§„æ¨¡å—é™**  
   å½“å‰å®éªŒåŸºäº IEEE 30-bus å°å‹ç³»ç»Ÿï¼Œå°šæœªéªŒè¯åœ¨å¤§è§„æ¨¡ç³»ç»Ÿï¼ˆå¦‚ 1000+ busesï¼‰ä¸Šçš„æ‰©å±•æ€§ã€‚

3. **é™æ€è´Ÿè·å‡è®¾**  
   è®­ç»ƒæ•°æ®åŸºäºç¨³æ€è´Ÿè·åˆ†å¸ƒï¼Œæœªè€ƒè™‘çªå˜äº‹ä»¶æˆ–åˆ†å¸ƒåç§»ä¸‹çš„é²æ£’æ€§ã€‚

4. **ç¼ºä¹ä¸ç¡®å®šæ€§é‡åŒ–**  
   æœªæä¾›é¢„æµ‹ç½®ä¿¡åº¦æˆ–é£é™©è¾¹ç•Œï¼Œå¯¹å®‰å…¨å…³é”®åº”ç”¨æ„æˆæŒ‘æˆ˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **AC-OPF**ï¼Œæ•´åˆç”µå‹ä¸æ— åŠŸçº¦æŸ
- å¼€å‘**åˆ†å±‚ GNN æ¶æ„**ä»¥åº”å¯¹è¶…å¤§è§„æ¨¡ç”µç½‘
- å¼•å…¥**åœ¨çº¿å­¦ä¹ æœºåˆ¶**é€‚åº”æ‹“æ‰‘å˜åŒ–ä¸å‚æ•°æ¼‚ç§»
- æ„å»º**æ¦‚ç‡æ€§ CFM æ¨¡å‹**æˆ–é›†æˆæ–¹æ³•ä»¥å®ç°ä¸ç¡®å®šæ€§ä¼°è®¡
- æ¢ç´¢ä¸å…¶ä»–ç‰©ç†ä¿¡æ¯æ–¹æ³•ï¼ˆå¦‚ PINNsã€Lagrangian ç¥ç»ç½‘ç»œï¼‰çš„èåˆ

---

> ğŸ”— **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/kshitizkhanal7/flow_refiner_dcopf](https://github.com/kshitizkhanal7/flow_refiner_dcopf)

</details>

---

### 16. [High-Dimensional Surrogate Modeling for Closed-Loop Learning of Neural-Network-Parameterized Model Predictive Control](https://arxiv.org/abs/2512.11705)

**Authors**: Sebastian Hirt, Valentinus Suwanto, Hendrik Alsmeier, Maik Pfefferkorn, Rolf Findeisen  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.11705v1  

#### Abstract
Learning controller parameters from closed-loop data has been shown to improve closed-loop performance. Bayesian optimization, a widely used black-box and sample-efficient learning method, constructs a probabilistic surrogate of the closed-loop performance from few experiments and uses it to select ...

---

### 17. [Softmax as Linear Attention in the Large-Prompt Regime: a Measure-based Perspective](https://arxiv.org/abs/2512.11784)

**Authors**: Etienne Boursier, Claire Boyer  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.11784v1  

#### Abstract
Softmax attention is a central component of transformer architectures, yet its nonlinear structure poses significant challenges for theoretical analysis. We develop a unified, measure-based framework for studying single-layer softmax attention under both finite and infinite prompts. For i.i.d. Gauss...

---

### 18. [Deep Learning--Accelerated Multi-Start Large Neighborhood Search for Real-time Freight Bundling](https://arxiv.org/abs/2512.11187)

**Authors**: Haohui Zhang, Wouter van Heeswijk, Xinyu Hu, Neil Yorke-Smith, Martijn Mes  
**Category**: cs.AI  
**Published**: 2025-12-15  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.11187v1  

#### Abstract
Online Freight Exchange Systems (OFEX) play a crucial role in modern freight logistics by facilitating real-time matching between shippers and carrier. However, efficient combinatorial bundling of transporation jobs remains a bottleneck. We model the OFEX combinatorial bundling problem as a multi-co...

---

### 19. [When Actions Teach You to Think: Reasoning-Action Synergy via Reinforcement Learning in Conversational Agents](https://arxiv.org/abs/2512.11277)

**Authors**: Mrinal Rawat, Arkajyoti Chakraborty, Neha Gupta, Roberto Pieraccini  
**Category**: cs.CL  
**Published**: 2025-12-15  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.11277v1  

#### Abstract
Supervised fine-tuning (SFT) has emerged as one of the most effective ways to improve the performance of large language models (LLMs) in downstream tasks. However, SFT can have difficulty generalizing when the underlying data distribution changes, even when the new data does not fall completely outs...

---

### 20. [Agentic Operator Generation for ML ASICs](https://arxiv.org/abs/2512.10977)

**Authors**: Alec M. Hammond, Aram Markosyan, Aman Dontula, Simon Mahns, Zacharias Fisches, Dmitrii Pedchenko, Keyur Muzumdar, Natacha Supper, Mark Saroufim, Joe Isaacson, Laura Wang, Warren Hunt, Kaustubh Gondkar, Roman Levenstein, Gabriel Synnaeve, Richard Li, Jacob Kahn, Ajit Mathews  
**Category**: cs.DC  
**Published**: 2025-12-15  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.10977v1  

#### Abstract
We present TritorX, an agentic AI system designed to generate functionally correct Triton PyTorch ATen kernels at scale for emerging accelerator platforms. TritorX integrates open-source large language models with a custom linter, JIT compilation, and a PyTorch OpInfo-based test harness. This pipeli...

---

### 21. [Bandwidth-constrained Variational Message Encoding for Cooperative Multi-agent Reinforcement Learning](https://arxiv.org/abs/2512.11179)

**Authors**: Wei Duan, Jie Lu, En Yu, Junyu Xuan  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.11179v1  

#### Abstract
Graph-based multi-agent reinforcement learning (MARL) enables coordinated behavior under partial observability by modeling agents as nodes and communication links as edges. While recent methods excel at learning sparse coordination graphs-determining who communicates with whom-they do not address wh...

---

### 22. [Pace: Physics-Aware Attentive Temporal Convolutional Network for Battery Health Estimation](https://arxiv.org/abs/2512.11332)

**Authors**: Sara Sameer, Wei Zhang, Kannan Dhivya Dharshini, Xin Lou, Yulin Gao, Terence Goh, Qingyu Yan  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.11332v1  

#### Abstract
Batteries are critical components in modern energy systems such as electric vehicles and power grid energy storage. Effective battery health management is essential for battery system safety, cost-efficiency, and sustainability. In this paper, we propose Pace, a physics-aware attentive temporal conv...

---

### 23. [FutureWeaver: Planning Test-Time Compute for Multi-Agent Systems with Modularized Collaboration](https://arxiv.org/abs/2512.11213)

**Authors**: Dongwon Jung, Peng Shi, Yi Zhang  
**Category**: cs.AI  
**Published**: 2025-12-15  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.11213v1  

#### Abstract
Scaling test-time computation improves large language model performance without additional training. Recent work demonstrates that techniques such as repeated sampling, self-verification, and self-reflection can significantly enhance task success by allocating more inference-time compute. However, a...

---

### 24. [AgentBalance: Backbone-then-Topology Design for Cost-Effective Multi-Agent Systems under Budget Constraints](https://arxiv.org/abs/2512.11426)

**Authors**: Shuowei Cai, Yansong Ning, Hao Liu  
**Category**: cs.AI  
**Published**: 2025-12-15  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.11426v1  

#### Abstract
Large Language Model (LLM)-based multi-agent systems (MAS) are becoming indispensable building blocks for web-scale applications such as web search, social network analytics, and online customer support, where cost-effectiveness is increasingly the primary constraint for large-scale deployment. Whil...

---

### 25. [TECM*: A Data-Driven Assessment to Reinforcement Learning Methods and Application to Heparin Treatment Strategy for Surgical Sepsis](https://arxiv.org/abs/2512.10973)

**Authors**: Jiang Liu, Yujie Li, Chan Zhou, Yihao Xie, Qilong Sun, Xin Shu, Peiwei Li, Chunyong Yang, Yiziting Zhu, Jiaqi Zhu, Yuwen Chen, Bo An, Hao Wu, Bin Yi  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.10973v1  

#### Abstract
Objective: Sepsis is a life-threatening condition caused by severe infection leading to acute organ dysfunction. This study proposes a data-driven metric and a continuous reward function to optimize personalized heparin therapy in surgical sepsis patients. Methods: Data from the MIMIC-IV v1.0 and eI...

---

### 26. [Harnessing Rich Multi-Modal Data for Spatial-Temporal Homophily-Embedded Graph Learning Across Domains and Localities](https://arxiv.org/abs/2512.11178)

**Authors**: Takuya Kurihana, Xiaojian Zhang, Wing Yee Au, Hon Yung Wong  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.11178v1  

#### Abstract
Modern cities are increasingly reliant on data-driven insights to support decision making in areas such as transportation, public safety and environmental impact. However, city-level data often exists in heterogeneous formats, collected independently by local agencies with diverse objectives and sta...

---

### 27. [Task-Aware Multi-Expert Architecture For Lifelong Deep Learning](https://arxiv.org/abs/2512.11243)

**Authors**: Jianyu Wang, Jacob Nean-Hua Sheikh, Cat P. Le, Hoda Bidkhori  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.11243v1  

#### Abstract
Lifelong deep learning (LDL) trains neural networks to learn sequentially across tasks while preserving prior knowledge. We propose Task-Aware Multi-Expert (TAME), a continual learning algorithm that leverages task similarity to guide expert selection and knowledge transfer. TAME maintains a pool of...

---

### 28. [Symmetry-Aware Steering of Equivariant Diffusion Policies: Benefits and Limits](https://arxiv.org/abs/2512.11345)

**Authors**: Minwoo Park, Junwoo Chang, Jongeun Choi, Roberto Horowitz  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.11345v1  

#### Abstract
Equivariant diffusion policies (EDPs) combine the generative expressivity of diffusion models with the strong generalization and sample efficiency afforded by geometric symmetries. While steering these policies with reinforcement learning (RL) offers a promising mechanism for fine-tuning beyond demo...

---

### 29. [Bhargava Cube--Inspired Quadratic Regularization for Structured Neural Embeddings](https://arxiv.org/abs/2512.11392)

**Authors**: S Sairam, Prateek P Kulkarni  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.11392v1  

#### Abstract
We present a novel approach to neural representation learning that incorporates algebraic constraints inspired by Bhargava cubes from number theory. Traditional deep learning methods learn representations in unstructured latent spaces lacking interpretability and mathematical consistency. Our framew...

---

### 30. [Hyperbolic Gaussian Blurring Mean Shift: A Statistical Mode-Seeking Framework for Clustering in Curved Spaces](https://arxiv.org/abs/2512.11448)

**Authors**: Arghya Pratihar, Arnab Seal, Swagatam Das, Inesh Chattopadhyay  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.11448v1  

#### Abstract
Clustering is a fundamental unsupervised learning task for uncovering patterns in data. While Gaussian Blurring Mean Shift (GBMS) has proven effective for identifying arbitrarily shaped clusters in Euclidean space, it struggles with datasets exhibiting hierarchical or tree-like structures. In this w...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
