# arXiv Papers Bot 🤖

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## 📊 Statistics

- **Last Updated**: 2025-08-14 07:08:18 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.LG, cs.CL, cs.CV, cs.NE, stat.ML

## 📚 Recent Papers

### 1. [Teaching Large Language Models to Maintain Contextual Faithfulness via Synthetic Tasks and Reinforcement Learning](https://arxiv.org/abs/2505.16483)

**Authors**: Shuzheng Si, Haozhe Zhao, Cheng Gao, Yuzhuo Bai, Zhitong Wang, Bofei Gao, Kangyang Luo, Wenhao Li, Yufei Huang, Gang Chen, Fanchao Qi, Minjia Zhang, Baobao Chang, Maosong Sun  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 5.0

arXiv:2505.16483v2 Announce Type: replace-cross 
Abstract: Teaching large language models (LLMs) to be faithful in the provided context is crucial for building reliable information-seeking systems. Therefore, we propose a systematic framework, CANOE, to reduce faithfulness hallucinations of LLMs acr...

---

### 2. [Stable Diffusion Models are Secretly Good at Visual In-Context Learning](https://arxiv.org/abs/2508.09949)

**Authors**: Trevine Oorloff, Vishwanath Sindagi, Wele Gedara Chaminda Bandara, Ali Shafahi, Amin Ghiasi, Charan Prakash, Reza Ardekani  
**Category**: cs.LG  
**Published**: 2025-08-14  
**Score**: 5.0

arXiv:2508.09949v1 Announce Type: cross 
Abstract: Large language models (LLM) in natural language processing (NLP) have demonstrated great potential for in-context learning (ICL) -- the ability to leverage a few sets of example prompts to adapt to various tasks without having to explicitly update t...

---

### 3. [Teaching Large Language Models to Maintain Contextual Faithfulness via Synthetic Tasks and Reinforcement Learning](https://arxiv.org/abs/2505.16483)

**Authors**: Shuzheng Si, Haozhe Zhao, Cheng Gao, Yuzhuo Bai, Zhitong Wang, Bofei Gao, Kangyang Luo, Wenhao Li, Yufei Huang, Gang Chen, Fanchao Qi, Minjia Zhang, Baobao Chang, Maosong Sun  
**Category**: cs.CL  
**Published**: 2025-08-14  
**Score**: 5.0

arXiv:2505.16483v2 Announce Type: replace 
Abstract: Teaching large language models (LLMs) to be faithful in the provided context is crucial for building reliable information-seeking systems. Therefore, we propose a systematic framework, CANOE, to reduce faithfulness hallucinations of LLMs across di...

---

### 4. [Stable Diffusion Models are Secretly Good at Visual In-Context Learning](https://arxiv.org/abs/2508.09949)

**Authors**: Trevine Oorloff, Vishwanath Sindagi, Wele Gedara Chaminda Bandara, Ali Shafahi, Amin Ghiasi, Charan Prakash, Reza Ardekani  
**Category**: cs.CV  
**Published**: 2025-08-14  
**Score**: 5.0

arXiv:2508.09949v1 Announce Type: new 
Abstract: Large language models (LLM) in natural language processing (NLP) have demonstrated great potential for in-context learning (ICL) -- the ability to leverage a few sets of example prompts to adapt to various tasks without having to explicitly update the...

---

### 5. [5G Core Fault Detection and Root Cause Analysis using Machine Learning and Generative AI](https://arxiv.org/abs/2508.09152)

**Authors**: Joseph H. R. Isaac, Harish Saradagam, Nallamothu Pardhasaradhi  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 4.5

arXiv:2508.09152v1 Announce Type: cross 
Abstract: With the advent of 5G networks and technologies, ensuring the integrity and performance of packet core traffic is paramount. During network analysis, test files such as Packet Capture (PCAP) files and log files will contain errors if present in the ...

---

### 6. [NEFMind: Parameter-Efficient Fine-Tuning of Open-Source LLMs for Telecom APIs Automation](https://arxiv.org/abs/2508.09240)

**Authors**: Zainab Khan, Ahmed Hussain, Mukesh Thakur, Arto Hellas, Panos Papadimitratos  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 4.5

arXiv:2508.09240v1 Announce Type: cross 
Abstract: The use of Service-Based Architecture in modern telecommunications has exponentially increased Network Functions (NFs) and Application Programming Interfaces (APIs), creating substantial operational complexities in service discovery and management. ...

---

### 7. [Leveraging Large Language Models for Rare Disease Named Entity Recognition](https://arxiv.org/abs/2508.09323)

**Authors**: Nan Miles Xi, Yu Deng, Lin Wang  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 4.5

arXiv:2508.09323v1 Announce Type: cross 
Abstract: Named Entity Recognition (NER) in the rare disease domain poses unique challenges due to limited labeled data, semantic ambiguity between entity types, and long-tail distributions. In this study, we evaluate the capabilities of GPT-4o for rare disea...

---

### 8. [Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study](https://arxiv.org/abs/2508.09776)

**Authors**: Mahdi Dhaini, Juraj Vladika, Ege Erdogan, Zineb Attaoui, Gjergji Kasneci  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 4.5

arXiv:2508.09776v1 Announce Type: cross 
Abstract: In the rapidly evolving field of Explainable Natural Language Processing (NLP), textual explanations, i.e., human-like rationales, are pivotal for explaining model predictions and enriching datasets with interpretable labels. Traditional approaches ...

---

### 9. [Modern Neural Networks for Small Tabular Datasets: The New Default for Field-Scale Digital Soil Mapping?](https://arxiv.org/abs/2508.09888)

**Authors**: Viacheslav Barkov, Jonas Schmidinger, Robin Gebbers, Martin Atzmueller  
**Category**: cs.LG  
**Published**: 2025-08-14  
**Score**: 4.5

arXiv:2508.09888v1 Announce Type: new 
Abstract: In the field of pedometrics, tabular machine learning is the predominant method for predicting soil properties from remote and proximal soil sensing data, forming a central component of digital soil mapping. At the field-scale, this predictive soil mo...

---

### 10. [5G Core Fault Detection and Root Cause Analysis using Machine Learning and Generative AI](https://arxiv.org/abs/2508.09152)

**Authors**: Joseph H. R. Isaac, Harish Saradagam, Nallamothu Pardhasaradhi  
**Category**: cs.LG  
**Published**: 2025-08-14  
**Score**: 4.5

arXiv:2508.09152v1 Announce Type: cross 
Abstract: With the advent of 5G networks and technologies, ensuring the integrity and performance of packet core traffic is paramount. During network analysis, test files such as Packet Capture (PCAP) files and log files will contain errors if present in the ...

---

### 11. [Leveraging Large Language Models for Rare Disease Named Entity Recognition](https://arxiv.org/abs/2508.09323)

**Authors**: Nan Miles Xi, Yu Deng, Lin Wang  
**Category**: cs.CL  
**Published**: 2025-08-14  
**Score**: 4.5

arXiv:2508.09323v1 Announce Type: new 
Abstract: Named Entity Recognition (NER) in the rare disease domain poses unique challenges due to limited labeled data, semantic ambiguity between entity types, and long-tail distributions. In this study, we evaluate the capabilities of GPT-4o for rare disease...

---

### 12. [Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study](https://arxiv.org/abs/2508.09776)

**Authors**: Mahdi Dhaini, Juraj Vladika, Ege Erdogan, Zineb Attaoui, Gjergji Kasneci  
**Category**: cs.CL  
**Published**: 2025-08-14  
**Score**: 4.5

arXiv:2508.09776v1 Announce Type: new 
Abstract: In the rapidly evolving field of Explainable Natural Language Processing (NLP), textual explanations, i.e., human-like rationales, are pivotal for explaining model predictions and enriching datasets with interpretable labels. Traditional approaches re...

---

### 13. [NEFMind: Parameter-Efficient Fine-Tuning of Open-Source LLMs for Telecom APIs Automation](https://arxiv.org/abs/2508.09240)

**Authors**: Zainab Khan, Ahmed Hussain, Mukesh Thakur, Arto Hellas, Panos Papadimitratos  
**Category**: cs.CL  
**Published**: 2025-08-14  
**Score**: 4.5

arXiv:2508.09240v1 Announce Type: cross 
Abstract: The use of Service-Based Architecture in modern telecommunications has exponentially increased Network Functions (NFs) and Application Programming Interfaces (APIs), creating substantial operational complexities in service discovery and management. ...

---

### 14. [Learning Spatial Decay for Vision Transformers](https://arxiv.org/abs/2508.09525)

**Authors**: Yuxin Mao, Zhen Qin, Jinxing Zhou, Bin Fan, Jing Zhang, Yiran Zhong, Yuchao Dai  
**Category**: cs.CV  
**Published**: 2025-08-14  
**Score**: 4.5

arXiv:2508.09525v1 Announce Type: new 
Abstract: Vision Transformers (ViTs) have revolutionized computer vision, yet their self-attention mechanism lacks explicit spatial inductive biases, leading to suboptimal performance on spatially-structured tasks. Existing approaches introduce data-independent...

---

### 15. [ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning](https://arxiv.org/abs/2508.09303)

**Authors**: Shu Zhao, Tan Yu, Anbang Xu, Japinder Singh, Aaditya Shukla, Rama Akkiraju  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 4.0

arXiv:2508.09303v1 Announce Type: cross 
Abstract: Reasoning-augmented search agents such as Search-R1, trained via reinforcement learning with verifiable rewards (RLVR), demonstrate remarkable capabilities in multi-step information retrieval from external knowledge sources. These agents address the...

---

### 16. [APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification](https://arxiv.org/abs/2508.09378)

**Authors**: Artem Chernodub, Aman Saini, Yejin Huh, Vivek Kulkarni, Vipul Raheja  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 4.0

arXiv:2508.09378v1 Announce Type: cross 
Abstract: Recent advancements in large language models (LLMs) have enabled a wide range of natural language processing (NLP) tasks to be performed through simple prompt-based interactions. Consequently, several approaches have been proposed to engineer prompt...

---

### 17. [LUMA: A Benchmark Dataset for Learning from Uncertain and Multimodal Data](https://arxiv.org/abs/2406.09864)

**Authors**: Grigor Bezirganyan, Sana Sellami, Laure Berti-\'Equille, S\'ebastien Fournier  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 4.0

arXiv:2406.09864v3 Announce Type: replace-cross 
Abstract: Multimodal Deep Learning enhances decision-making by integrating diverse information sources, such as texts, images, audio, and videos. To develop trustworthy multimodal approaches, it is essential to understand how uncertainty impacts these...

---

### 18. [LUMA: A Benchmark Dataset for Learning from Uncertain and Multimodal Data](https://arxiv.org/abs/2406.09864)

**Authors**: Grigor Bezirganyan, Sana Sellami, Laure Berti-\'Equille, S\'ebastien Fournier  
**Category**: cs.LG  
**Published**: 2025-08-14  
**Score**: 4.0

arXiv:2406.09864v3 Announce Type: replace 
Abstract: Multimodal Deep Learning enhances decision-making by integrating diverse information sources, such as texts, images, audio, and videos. To develop trustworthy multimodal approaches, it is essential to understand how uncertainty impacts these model...

---

### 19. [ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning](https://arxiv.org/abs/2508.09303)

**Authors**: Shu Zhao, Tan Yu, Anbang Xu, Japinder Singh, Aaditya Shukla, Rama Akkiraju  
**Category**: cs.CL  
**Published**: 2025-08-14  
**Score**: 4.0

arXiv:2508.09303v1 Announce Type: new 
Abstract: Reasoning-augmented search agents such as Search-R1, trained via reinforcement learning with verifiable rewards (RLVR), demonstrate remarkable capabilities in multi-step information retrieval from external knowledge sources. These agents address the l...

---

### 20. [APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification](https://arxiv.org/abs/2508.09378)

**Authors**: Artem Chernodub, Aman Saini, Yejin Huh, Vivek Kulkarni, Vipul Raheja  
**Category**: cs.CL  
**Published**: 2025-08-14  
**Score**: 4.0

arXiv:2508.09378v1 Announce Type: new 
Abstract: Recent advancements in large language models (LLMs) have enabled a wide range of natural language processing (NLP) tasks to be performed through simple prompt-based interactions. Consequently, several approaches have been proposed to engineer prompts ...

---

### 21. [LUMA: A Benchmark Dataset for Learning from Uncertain and Multimodal Data](https://arxiv.org/abs/2406.09864)

**Authors**: Grigor Bezirganyan, Sana Sellami, Laure Berti-\'Equille, S\'ebastien Fournier  
**Category**: cs.CL  
**Published**: 2025-08-14  
**Score**: 4.0

arXiv:2406.09864v3 Announce Type: replace-cross 
Abstract: Multimodal Deep Learning enhances decision-making by integrating diverse information sources, such as texts, images, audio, and videos. To develop trustworthy multimodal approaches, it is essential to understand how uncertainty impacts these...

---

### 22. [LUMA: A Benchmark Dataset for Learning from Uncertain and Multimodal Data](https://arxiv.org/abs/2406.09864)

**Authors**: Grigor Bezirganyan, Sana Sellami, Laure Berti-\'Equille, S\'ebastien Fournier  
**Category**: cs.CV  
**Published**: 2025-08-14  
**Score**: 4.0

arXiv:2406.09864v3 Announce Type: replace-cross 
Abstract: Multimodal Deep Learning enhances decision-making by integrating diverse information sources, such as texts, images, audio, and videos. To develop trustworthy multimodal approaches, it is essential to understand how uncertainty impacts these...

---

### 23. [UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge](https://arxiv.org/abs/2508.09724)

**Authors**: Yang Zhang, Cunxiang Wang, Lindong Wu, Wenbo Yu, Yidong Wang, Guangsheng Bao, Jie Tang  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 3.5

arXiv:2508.09724v1 Announce Type: new 
Abstract: Pairwise evaluation of Large Language Models (LLMs) is a common paradigm, but it is prone to preference bias, where judges systematically favor certain outputs, such as their own. This bias leads to inconsistent and skewed rankings across different ju...

---

### 24. [Mathematical Computation and Reasoning Errors by Large Language Models](https://arxiv.org/abs/2508.09932)

**Authors**: Liang Zhang, Edith Aurora Graf  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 3.5

arXiv:2508.09932v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are increasingly utilized in AI-driven educational instruction and assessment, particularly within mathematics education. The capability of LLMs to generate accurate answers and detailed solutions for math problem-solving ...

---

### 25. [Hybrid(Transformer+CNN)-based Polyp Segmentation](https://arxiv.org/abs/2508.09189)

**Authors**: Madan Baduwal  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 3.5

arXiv:2508.09189v1 Announce Type: cross 
Abstract: Colonoscopy is still the main method of detection and segmentation of colonic polyps, and recent advancements in deep learning networks such as U-Net, ResUNet, Swin-UNet, and PraNet have made outstanding performance in polyp segmentation. Yet, the p...

---

### 26. [Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs](https://arxiv.org/abs/2508.09288)

**Authors**: Aayush Gupta  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 3.5

arXiv:2508.09288v1 Announce Type: cross 
Abstract: Large language models (LLMs) remain acutely vulnerable to prompt injection and related jailbreak attacks; heuristic guardrails (rules, filters, LLM judges) are routinely bypassed. We present Contextual Integrity Verification (CIV), an inference-time...

---

### 27. [Synaptic Pruning: A Biological Inspiration for Deep Learning Regularization](https://arxiv.org/abs/2508.09330)

**Authors**: Gideon Vos, Liza van Eijk, Zoltan Sarnyai, Mostafa Rahimi Azghadi  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 3.5

arXiv:2508.09330v1 Announce Type: cross 
Abstract: Synaptic pruning in biological brains removes weak connections to improve efficiency. In contrast, dropout regularization in artificial neural networks randomly deactivates neurons without considering activity-dependent pruning. We propose a magnitu...

---

### 28. [DeepFeatIoT: Unifying Deep Learned, Randomized, and LLM Features for Enhanced IoT Time Series Sensor Data Classification in Smart Industries](https://arxiv.org/abs/2508.09468)

**Authors**: Muhammad Sakib Khan Inan, Kewen Liao  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 3.5

arXiv:2508.09468v1 Announce Type: cross 
Abstract: Internet of Things (IoT) sensors are ubiquitous technologies deployed across smart cities, industrial sites, and healthcare systems. They continuously generate time series data that enable advanced analytics and automation in industries. However, ch...

---

### 29. [Verify Distributed Deep Learning Model Implementation Refinement with Iterative Relation Inference](https://arxiv.org/abs/2508.09505)

**Authors**: Zhanghan Wang, Ding Ding, Hang Zhu, Haibin Lin, Aurojit Panda  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 3.5

arXiv:2508.09505v1 Announce Type: cross 
Abstract: Distributed machine learning training and inference is common today because today's large models require more memory and compute than can be provided by a single GPU. Distributed models are generally produced by programmers who take a sequential mod...

---

### 30. [Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models](https://arxiv.org/abs/2508.09874)

**Authors**: Jiaqi Cao, Jiarui Wang, Rubin Wei, Qipeng Guo, Kai Chen, Bowen Zhou, Zhouhan Lin  
**Category**: cs.AI  
**Published**: 2025-08-14  
**Score**: 3.5

arXiv:2508.09874v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have shown strong abilities in general language tasks, yet adapting them to specific domains remains a challenge. Current method like Domain Adaptive Pretraining (DAPT) requires costly full-parameter training and suffers...

---

## 🔧 Configuration

This bot is configured to look for papers containing the following keywords:
- machine learning, deep learning, neural network, transformer, large language model, LLM, GPT, BERT, attention mechanism, reinforcement learning, computer vision, natural language processing, NLP

## 📅 Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## 🚀 How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## 📝 Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## 🔍 Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 