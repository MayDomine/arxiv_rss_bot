# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-10 06:52:33 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [tLoRA: Efficient Multi-LoRA Training with Elastic Shared Super-Models](https://arxiv.org/abs/2602.07263)

**Authors**: Kevin Li, Dibyadeep Saha, Avni Kanodia, Fan Lai  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2602.07263v1  

#### Abstract
As Low-Rank Adaptation (LoRA) becomes the standard approach for efficiently fine-tuning large language models (LLMs), shared clusters increasingly execute many concurrent LoRA training jobs over the same frozen backbone. While recent advances enable batching (co-locating) multiple adapters during se...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼štLoRA: Efficient Multi-LoRA Training with Elastic Shared Super-Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
éšç€ **LoRA**ï¼ˆLow-Rank Adaptationï¼‰æˆä¸ºé«˜æ•ˆå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ ‡å‡†æ–¹æ³•ï¼Œå…±äº«é›†ç¾¤ä¸­è¶Šæ¥è¶Šå¤šåœ°å‡ºç°**å¹¶å‘æ‰§è¡Œå¤šä¸ª LoRA è®­ç»ƒä»»åŠ¡**çš„åœºæ™¯ã€‚å°½ç®¡å·²æœ‰ç ”ç©¶åœ¨æ¨ç†é˜¶æ®µå®ç°äº†å¤š LoRA æ‰¹å¤„ç†ï¼ˆå¦‚ dLoRAã€S-LoRAï¼‰ï¼Œä½†åœ¨**è®­ç»ƒé˜¶æ®µ**ï¼Œç”±äºä»»åŠ¡é—´å­˜åœ¨æ˜¾è‘—å¼‚æ„æ€§ï¼ˆå¦‚ä¸åŒçš„ LoRA rankã€batch sizeã€èµ„æºåˆ†é…ç­‰ï¼‰ï¼Œç›´æ¥æ‰¹å¤„ç†ä¼šå¯¼è‡´ä»¥ä¸‹é—®é¢˜ï¼š
- **åŒæ­¥é˜»å¡**ï¼ˆsynchronization stallsï¼‰
- **é€šä¿¡å¼€é”€å¢åŠ **
- **ä¸ªåˆ«ä»»åŠ¡å˜æ…¢ç”šè‡³åŠ£äºç‹¬ç«‹è¿è¡Œ**

å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¿è¯å„ä»»åŠ¡è¿›åº¦çš„å‰æä¸‹ï¼Œé«˜æ•ˆåœ°ååŒè®­ç»ƒå¤šä¸ªå¼‚æ„ LoRA ä»»åŠ¡ï¼Œæ˜¯ä¸€ä¸ªå°šæœªè¢«å……åˆ†æ¢ç´¢çš„å…³é”®æŒ‘æˆ˜ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **tLoRA**ï¼Œä¸€ä¸ªæ”¯æŒé«˜æ•ˆæ‰¹é‡è®­ç»ƒå¤š LoRA ä»»åŠ¡çš„æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ä¸‰ä¸ªå±‚é¢ï¼š

#### ï¼ˆ1ï¼‰**Shared Super-Model (SSM) æŠ½è±¡**
- å°†å…±äº«åŒä¸€éª¨å¹²æ¨¡å‹ï¼ˆbackboneï¼‰çš„å¤šä¸ª LoRA ä»»åŠ¡èåˆä¸ºä¸€ä¸ªç»Ÿä¸€çš„â€œå¼¹æ€§å…±äº«è¶…æ¨¡å‹â€ï¼ˆElastic Shared Super-Modelï¼‰ã€‚
- è¯¥æŠ½è±¡ä¿ç•™äº†åŸå§‹è®­ç»ƒè¯­ä¹‰ï¼ˆåŠŸèƒ½ç­‰ä»·ï¼‰ï¼ŒåŒæ—¶æš´éœ²æ›´å¤šä¼˜åŒ–ç»“æ„ï¼Œå¯æ— ç¼æ¥å…¥ç°æœ‰åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ï¼ˆå¦‚ Megatron-LM æˆ– PyTorch FSDPï¼‰ï¼Œå®ç°é«˜æ•ˆçš„å¹¶è¡Œæ‰§è¡Œè®¡åˆ’ï¼ˆå¦‚æµæ°´çº¿å¹¶è¡Œï¼‰ã€‚

#### ï¼ˆ2ï¼‰**Fused LoRA Kernelï¼ˆèåˆå†…æ ¸ï¼‰**
- è®¾è®¡äº†ä¸€ä¸ªåŠ¨æ€çš„ LoRA èåˆå†…æ ¸ï¼Œé¿å…æ˜¾å¼æ„é€  $ W = AB^T $ æƒé‡çŸ©é˜µï¼Œæå‡å¯„å­˜å™¨å’Œå…±äº«å†…å­˜å¤ç”¨ã€‚
- å¼•å…¥ **nano-batch** æŠ½è±¡ï¼Œåœ¨å¾®æ‰¹æ¬¡å†…éƒ¨è¿›ä¸€æ­¥ç»†ç²’åº¦åˆ’åˆ†è¾“å…¥æ ·æœ¬ï¼Œé€šè¿‡ **rank-aware è°ƒåº¦**æœ€å¤§åŒ–è®¡ç®—ä¸é€šä¿¡çš„é‡å ï¼Œå‡å°‘æµæ°´çº¿æ°”æ³¡ã€‚

#### ï¼ˆ3ï¼‰**Online Residual-Capacity-Aware Schedulerï¼ˆåœ¨çº¿è°ƒåº¦å™¨ï¼‰**
- åŠ¨æ€ç›‘æ§æ¯ä¸ªä»»åŠ¡çš„å‰©ä½™èµ„æºå®¹é‡ï¼ˆå¦‚æœªä½¿ç”¨çš„ GPU è®¡ç®—/å†…å­˜ï¼‰å’Œç´§è¿«æ€§ï¼ˆurgency scoreï¼‰ã€‚
- è‡ªé€‚åº”åœ°å°†èµ„æºäº’è¡¥çš„ä»»åŠ¡è¿›è¡Œåˆ†ç»„ï¼Œæœ€å¤§åŒ–æ•´ä½“ååé‡ï¼ŒåŒæ—¶ç¡®ä¿ä¸è¿åå•ä¸ªä»»åŠ¡çš„æ€§èƒ½çº¦æŸï¼ˆå¦‚å®Œæˆæ—¶é™ã€æœ€å¤§å‡é€Ÿé™åˆ¶ï¼‰ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | tLoRA ä¼˜åŠ¿ |
|------|-----------|
| **æ•ˆç‡** | æ˜¾è‘—æå‡è®­ç»ƒååé‡ã€GPU åˆ©ç”¨ç‡ï¼Œç¼©çŸ­ä»»åŠ¡å®Œæˆæ—¶é—´ |
| **å…¼å®¹æ€§** | ä¸æ”¹å˜è®­ç»ƒè¯­ä¹‰ï¼Œä¸ç°æœ‰åˆ†å¸ƒå¼è®­ç»ƒæ ˆå®Œå…¨å…¼å®¹ |
| **å…¬å¹³æ€§** | é¿å…â€œå¯Œä»»åŠ¡è¡¥è´´ç©·ä»»åŠ¡â€çš„ä¸å…¬å¹³ç°è±¡ï¼Œä¿éšœä¸ªä½“è¿›åº¦ |
| **è‡ªé€‚åº”æ€§** | æ”¯æŒåœ¨çº¿åŠ¨æ€è°ƒæ•´åˆ†ç»„ç­–ç•¥ï¼Œé€‚åº”çœŸå®é›†ç¾¤è´Ÿè½½å˜åŒ– |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- ä¸»è¦è®­ç»ƒä»»åŠ¡åŸºäº **GSM8K æ•°æ®é›†**ï¼ˆçº¦ 8.5k æ¡å°å­¦æ•°å­¦é¢˜ï¼‰ï¼Œç”¨äºæ¨¡æ‹Ÿå®é™… LoRA å¾®è°ƒä»»åŠ¡ã€‚
- å®éªŒä¸­çš„ LoRA é…ç½®ï¼ˆrankã€batch size ç­‰ï¼‰ä»çœŸå®é›†ç¾¤è½¨è¿¹ä¸­é‡‡æ ·ç”Ÿæˆã€‚

---

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### å®éªŒå¹³å°
- **ç¡¬ä»¶æµ‹è¯•åºŠ**ï¼š12 å— NVIDIA A100 GPU
- **å¤§è§„æ¨¡ä»¿çœŸç¯å¢ƒ**ï¼šä½¿ç”¨ç”Ÿäº§çº§åˆ†å¸ƒå¼è®­ç»ƒæ¨¡æ‹Ÿå™¨ **Sailor**ï¼ˆStrati et al., 2025ï¼‰ï¼Œè¯¯å·®æ§åˆ¶åœ¨ 3% ä»¥å†…
- **é»˜è®¤é›†ç¾¤è§„æ¨¡**ï¼š128-GPU é›†ç¾¤
- **æ¨¡å‹ç±»å‹**ï¼šLlama-3-8B å’Œ Qwen-3-8B

#### å·¥ä½œè´Ÿè½½æ¥æº
- ä½¿ç”¨ **ACMETrace** ä¸­çš„çœŸå® GPU é›†ç¾¤è½¨è¿¹ï¼ŒåŒ…å«ä»»åŠ¡åˆ°è¾¾æ—¶é—´ã€GPU åˆ†é…ã€æ‰§è¡Œæ—¶é•¿ç­‰ä¿¡æ¯ã€‚
- åœ¨æ­¤åŸºç¡€ä¸Šæ³¨å…¥ LoRA ç‰¹å¾ï¼ˆrank âˆˆ {2,4,8,16}, batch size âˆˆ {1,2,4,8}ï¼‰

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Training Throughput** | å…¨å±€ååé‡ï¼ˆsamples/secï¼‰ï¼Œæ‰€æœ‰æ´»è·ƒä»»åŠ¡æ€»å’Œ |
| **Job Completion Time (JCT)** | ä»æäº¤åˆ°è®­ç»ƒå®Œæˆçš„å®é™…å¢™é’Ÿæ—¶é—´ï¼ˆå«æ’é˜Ÿå»¶è¿Ÿï¼‰ |
| **GPU Utilization** | æ‰€æœ‰ GPU çš„å¹³å‡åˆ©ç”¨ç‡ï¼ˆSM åˆ©ç”¨ç‡ï¼‰ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **Megatron** | ç‹¬ç«‹è®­ç»ƒæ¯ä¸ª LoRA ä»»åŠ¡ï¼Œæ— æ‰¹å¤„ç† |
| **mLoRA (Ye et al., 2025)** | å½“å‰æœ€å…ˆè¿›çš„æ‰¹å¤„ç† LoRA è®­ç»ƒç³»ç»Ÿï¼Œä»…æŒ‰å†…å­˜æ˜¯å¦è¶³å¤Ÿå†³å®šæ˜¯å¦åˆå¹¶ |
| **tLoRA w/o Scheduler** | ç§»é™¤è‡ªé€‚åº”è°ƒåº¦å™¨ï¼Œé‡‡ç”¨ mLoRA çš„é™æ€åˆ†ç»„ç­–ç•¥ |
| **tLoRA w/o Kernel Fuser** | ç§»é™¤èåˆå†…æ ¸ï¼Œä½¿ç”¨åŸç”Ÿ PyTorch å†…æ ¸ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªçœŸå®è½¨è¿¹è¯„ä¼°ï¼‰
| æŒ‡æ ‡ | æå‡å¹…åº¦ |
|------|----------|
| **Training Throughput** | **+1.2â€“1.8Ã—** vs. mLoRA / Megatron |
| **Job Completion Time** | **ç¼©çŸ­ 2.3â€“5.4Ã—** |
| **Average GPU Utilization** | **æå‡ 37%**ï¼ˆå³°å€¼è¾¾ 84%ï¼‰ |

> å›¾5æ˜¾ç¤ºï¼Œåœ¨åŠ¨æ€åˆ°è¾¾çš„å·¥ä½œè´Ÿè½½ä¸‹ï¼ŒtLoRA ååé‡æ¯” mLoRA é«˜å‡º **41%**ï¼Œä¸”ä»»åŠ¡å®Œæˆæ—¶é—´é™ä½ **5.4Ã—**ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| å¯¹æ¯”é¡¹ | ç»“æœ |
|--------|------|
| vs. **Megatron** | å³ä½¿ Megatron æœ¬èº«é«˜åº¦ä¼˜åŒ–ï¼ŒtLoRA ä»å› èµ„æºå…±äº«è·å¾—æ˜¾è‘—ä¼˜åŠ¿ |
| vs. **mLoRA** | mLoRA å› å¿½ç•¥å¼‚æ„æ€§å¯¼è‡´éƒ¨åˆ†ç»„åˆåè€Œé™ä½æ€§èƒ½ï¼›è€Œ tLoRA é€šè¿‡æ™ºèƒ½åˆ†ç»„é¿å…æ­¤ç±»é€€åŒ– |
| vs. FIFO åˆ†ç»„ç­–ç•¥ | tLoRA çš„è°ƒåº¦ç­–ç•¥ä½¿å°ä»»åŠ¡ä¸å¤§ä»»åŠ¡æ›´æœ‰æ•ˆäº’è¡¥ï¼Œè€Œ mLoRA çš„é«˜å…±ç½®æ¯”ä¾‹åè€Œå¸¦æ¥â€œé•¿å°¾å»¶è¿Ÿâ€ |

---

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰ç§»é™¤ Kernel Fuser
- ä½¿ç”¨åŸç”Ÿ PyTorch å†…æ ¸ â†’ ååä¸‹é™æ˜æ˜¾
- åŸå› ï¼šé¢‘ç¹çš„å°å¼ é‡æ“ä½œå¯¼è‡´ kernel launch å¼€é”€é«˜ã€æ•°æ®å¤ç”¨å·®ã€éš¾ä»¥é‡å é€šä¿¡

#### ï¼ˆ2ï¼‰ç§»é™¤ Adaptive Scheduler
- æ”¹ç”¨ mLoRA çš„é™æ€åˆ†ç»„ â†’ å®Œæˆæ—¶é—´æ¶åŒ–ï¼Œå°¤å…¶å¯¹èµ„æºç´§å¼ ä»»åŠ¡ä¸å…¬å¹³
- è¡¨æ˜**åŠ¨æ€æ„ŸçŸ¥å‰©ä½™å®¹é‡å’Œç´§è¿«æ€§**æ˜¯å®ç°é«˜æ•ˆä¸”å…¬å¹³è°ƒåº¦çš„å…³é”®

#### ï¼ˆ3ï¼‰Nano-batch å¤§å°å½±å“ï¼ˆå›¾8aï¼‰
- å›ºå®š nano-batch å¤§å°æ— æ³•é€‚åº”ä¸åŒç½‘ç»œå¸¦å®½å’Œç¡¬ä»¶é…ç½®
- tLoRA ä½¿ç”¨ **AIMD æ§åˆ¶å™¨**åœ¨çº¿è°ƒèŠ‚ nano-batch æ•°é‡ï¼Œå®ç°æœ€ä¼˜è®¡ç®—/é€šä¿¡é‡å ï¼Œä¼˜äºæ‰‹åŠ¨è°ƒä¼˜

#### ï¼ˆ4ï¼‰ä¸åŒåˆ°è¾¾æ¨¡å¼ä¸‹çš„è¡¨ç°ï¼ˆå›¾8b & å›¾11ï¼‰
- åœ¨ç¨€ç–åˆ°è¾¾æ—¶ï¼ŒtLoRA æ›´å®¹æ˜“æ‰¾åˆ°äº’è¡¥ä¼™ä¼´ï¼Œå®Œæˆæ—¶é—´æ›´çŸ­
- åœ¨å¯†é›†çªå‘åˆ°è¾¾æ—¶ï¼Œä»èƒ½ç»´æŒæ¥è¿‘å³°å€¼ååï¼Œè¡¨ç°å‡ºå¼ºå¥çš„è´Ÿè½½é€‚åº”èƒ½åŠ›

#### ï¼ˆ5ï¼‰é›†ç¾¤è§„æ¨¡æ‰©å±•æ€§ï¼ˆå›¾9b & å›¾13ï¼‰
- ä»å°å‹ï¼ˆ32 GPUï¼‰åˆ°å¤§å‹ï¼ˆ256 GPUï¼‰é›†ç¾¤ï¼ŒtLoRA å‡ä¿æŒè‰¯å¥½æ‰©å±•æ€§
- å®Œæˆæ—¶é—´éšèµ„æºå‡å°‘å‘ˆçº¿æ€§å³ç§»ï¼Œè€ŒéæŒ‡æ•°å¢é•¿ï¼Œè¯´æ˜è°ƒåº¦æœ‰æ•ˆé¿å…äº†èµ„æºé¥¥é¥¿

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å¼‚æ„æ€§ä¸æ˜¯éšœç¢è€Œæ˜¯æœºä¼š**ï¼šLoRA ä»»åŠ¡é—´çš„å·®å¼‚ï¼ˆå¦‚ rankã€batch sizeï¼‰è‹¥è¢«åˆç†åˆ©ç”¨ï¼Œå¯é€šè¿‡â€œèµ„æºäº’è¡¥â€å®ç°åŒèµ¢ã€‚
2. **é™æ€æ‰¹å¤„ç†ä¸å¯é **ï¼šç®€å•ä¾æ®å†…å­˜æ˜¯å¦å……è¶³æ¥åˆå¹¶ä»»åŠ¡ï¼ˆå¦‚ mLoRAï¼‰å¯èƒ½é€‚å¾—å…¶åï¼Œå¿…é¡»è€ƒè™‘é€šä¿¡ç“¶é¢ˆä¸è´Ÿè½½å‡è¡¡ã€‚
3. **ç»†ç²’åº¦æ‰§è¡Œæ§åˆ¶è‡³å…³é‡è¦**ï¼šå¼•å…¥ **nano-batch + fused kernel** å¯æ˜¾è‘—æå‡ GPU åˆ©ç”¨ç‡å’Œé‡å æ•ˆç‡ã€‚
4. **åœ¨çº¿åé¦ˆé©±åŠ¨ä¼˜äºé¢„è®¾ç­–ç•¥**ï¼šåŸºäºè¿è¡Œæ—¶ä¿¡å·ï¼ˆutilizationã€latencyï¼‰åŠ¨æ€è°ƒæ•´åˆ†ç»„å’Œ nano-batch å¤§å°ï¼Œæ‰èƒ½åº”å¯¹å¤æ‚å¤šå˜çš„çœŸå®è´Ÿè½½ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **å‡è®¾å…±äº«ç›¸åŒ backbone**ï¼šç›®å‰ä»…é€‚ç”¨äºå¤šä¸ª LoRA å…±äº«åŒä¸€ä¸ªåŸºç¡€æ¨¡å‹çš„åœºæ™¯ï¼Œä¸æ”¯æŒè·¨æ¨¡å‹æ‰¹å¤„ç†ã€‚
2. **ä¾èµ–åº•å±‚åˆ†å¸ƒå¼æ¡†æ¶**ï¼šè™½ç„¶å…¼å®¹æ€§å¼ºï¼Œä½†æ€§èƒ½ä»å—é™äºæ‰€ç”¨å¹¶è¡ŒåŒ–å·¥å…·ï¼ˆå¦‚ Megatronï¼‰çš„èƒ½åŠ›è¾¹ç•Œã€‚
3. **æœªè€ƒè™‘ç²¾åº¦æ¼‚ç§»é£é™©**ï¼šè™½ç„¶è®ºæ–‡å£°ç§°â€œlosslessâ€ï¼Œä½†åœ¨æç«¯å¼‚æ„ç»„åˆä¸‹æ˜¯å¦ä¼šå½±å“æ”¶æ•›ç¨³å®šæ€§æœ‰å¾…é•¿æœŸéªŒè¯ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ”¯æŒè·¨æ¨¡å‹ LoRA æ‰¹å¤„ç†**ï¼šæ‹“å±• SSM æŠ½è±¡ä»¥èåˆä¸åŒ backbone çš„ LoRAã€‚
2. **é›†æˆè‡ªåŠ¨è¶…å‚æ¨èæœºåˆ¶**ï¼šç»“åˆ AdaLoRA ç­‰æŠ€æœ¯ï¼Œè”åˆä¼˜åŒ– rank åˆ†é…ä¸è°ƒåº¦å†³ç­–ã€‚
3. **é¢å‘ç»¿è‰² AI çš„èƒ½è€—ä¼˜åŒ–ç‰ˆæœ¬**ï¼šåœ¨æå‡ååçš„åŒæ—¶æœ€å°åŒ– energy-to-solutionã€‚
4. **éƒ¨ç½²åˆ°çœŸå®äº‘æœåŠ¡å¹³å°**ï¼šä¸ Kubernetesã€Ray ç­‰é›†æˆï¼Œæ„å»ºç«¯åˆ°ç«¯çš„ LoRA è®­ç»ƒå³æœåŠ¡ï¼ˆLoRA-as-a-Serviceï¼‰ç³»ç»Ÿã€‚

--- 

> âœ… æ€»ç»“ä¸€å¥è¯ï¼š  
> **tLoRA é€šè¿‡â€œç»Ÿä¸€å»ºæ¨¡ + å†…æ ¸å®ä¾‹èåˆ + åŠ¨æ€èµ„æºè°ƒåº¦â€ä¸‰ä½ä¸€ä½“è®¾è®¡ï¼Œé¦–æ¬¡å®ç°äº†é«˜æ•ˆã€å…¬å¹³ã€å®ç”¨çš„å¤š LoRA å¹¶è¡Œè®­ç»ƒæ¡†æ¶ï¼Œåœ¨çœŸå®é›†ç¾¤è½¨è¿¹ä¸Šå®ç°äº†é«˜è¾¾ 1.8Ã— ååæå‡å’Œ 5.4Ã— æ›´å¿«çš„ä»»åŠ¡å®Œæˆé€Ÿåº¦ã€‚**

</details>

---

### 2. [SpecAttn: Co-Designing Sparse Attention with Self-Speculative Decoding](https://arxiv.org/abs/2602.07223)

**Authors**: Yikang Yue, Yuqi Xue, Jian Huang  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2602.07223v1  

#### Abstract
Long-context large language model (LLM) inference has become the norm for today's AI applications. However, it is severely bottlenecked by the increasing memory demands of its KV cache. Previous works have shown that self-speculative decoding with sparse attention, where tokens are drafted using a s...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSpecAttn: Co-Designing Sparse Attention with Self-Speculative Decoding

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
é•¿ä¸Šä¸‹æ–‡ Large Language Model (LLM) æ¨ç†é¢ä¸´ä¸¥é‡çš„ **KV Cache å†…å­˜å¸¦å®½ç“¶é¢ˆ**ã€‚ä¼ ç»Ÿçš„ç¨€ç–æ³¨æ„åŠ›ï¼ˆSparse Attentionï¼‰è™½ç„¶èƒ½å‡å°‘å†…å­˜è®¿é—®ï¼Œä½†å¯èƒ½ç‰ºç‰²ç”Ÿæˆè´¨é‡ï¼›è€Œç°æœ‰çš„è‡ªæ¨æµ‹è§£ç ï¼ˆSelf-Speculative Decodingï¼‰æ–¹æ³•åœ¨ **drafting å‡†ç¡®ç‡** å’Œ **KV selection å¼€é”€** ä¹‹é—´å­˜åœ¨å›ºæœ‰ trade-offã€‚

ç°æœ‰æ–¹æ³•å°† drafting å’Œ verification è§†ä¸ºç‹¬ç«‹è¿‡ç¨‹ï¼Œå¿½ç•¥äº† verification é˜¶æ®µä¸­å…¨æ³¨æ„åŠ›è®¡ç®—æ‰€éšå«çš„â€œå…è´¹â€KV æ¡ç›®é‡è¦æ€§ä¿¡æ¯ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ ¸å¿ƒæ€æƒ³
æå‡º **SpecAttn** â€”â€” ä¸€ç§ **éªŒè¯å¼•å¯¼çš„ç¨€ç–æ³¨æ„åŠ›ï¼ˆverification-guided sparse attentionï¼‰** è‡ªæ¨æµ‹è§£ç æœºåˆ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š

- **ååŒè®¾è®¡ï¼ˆCo-Designï¼‰drafting ä¸ verification é˜¶æ®µ**ï¼š
  - åˆ©ç”¨ verification é˜¶æ®µæ‰§è¡Œ full attention æ—¶äº§ç”Ÿçš„ä¸­é—´ç»“æœï¼ˆattention logitsï¼‰ï¼Œè¯†åˆ«å‡ºå¯¹ç”Ÿæˆå…³é”®çš„ KV æ¡ç›®ã€‚
  - å°†è¿™äº›â€œè¢«éªŒè¯è¿‡çš„é‡è¦ KVâ€ç”¨äºåç»­ drafting é˜¶æ®µçš„ sparse attentionï¼Œå®ç°é«˜è´¨é‡ draft token ç”Ÿæˆã€‚

- **ä½å¼€é”€ KV é€‰æ‹©ç®—æ³•**ï¼š
  - æå‡º â€œ**Collect-2-Query**â€ æœºåˆ¶ï¼šä»…ä»ç¬¬ä¸€ä¸ª draft token å’Œ bonus token æ”¶é›† attention logitsï¼Œæ˜¾è‘—é™ä½æ—¥å¿—æ”¶é›†å¼€é”€ï¼ŒåŒæ—¶ä¿æŒé«˜å‡†ç¡®æ€§ã€‚
  - èšåˆå¤šä¸ª draft token çš„ attention logits è¿›è¡Œ KV é€‰æ‹©ï¼Œé¿å…ä»…ä¾èµ–æœ€åä¸€ä¸ªæ¥å— token å¯¼è‡´çš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚

- **ç³»ç»Ÿçº§ä¼˜åŒ–ç­–ç•¥**ï¼š
  - è®¾è®¡ä¸‰æ­¥è¶…å‚æ•°è°ƒä¼˜ç­–ç•¥ï¼Œå¹³è¡¡ sparse ratio ä¸ draft token æ•°é‡ $ y $ï¼Œæœ€å¤§åŒ–ç«¯åˆ°ç«¯ååé‡ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ MagicDec + Questï¼‰ | SpecAttn |
|------|-------------------------------|--------|
| **KV Selection å‡†ç¡®æ€§** | æŸ¥è¯¢æ„ŸçŸ¥ä½†æ¯æ­¥é‡ä¼°ï¼Œæ˜“è¿‡æ‹Ÿåˆ | å¤š token èšåˆï¼Œè¦†ç›–æ›´å¹¿ä¸Šä¸‹æ–‡ |
| **KV Selection å¼€é”€** | é«˜ï¼ˆéœ€æ¯æ­¥é‡æ–°ä¼°è®¡ï¼‰ | æä½ï¼ˆåˆ©ç”¨å·²æœ‰ verification ç»“æœï¼‰ |
| **drafting å‡†ç¡®ç‡** | ä¸­ç­‰ï¼ˆå—é™äº selection ç­–ç•¥ï¼‰ | æ›´é«˜ï¼ˆåŸºäºçœŸå® full attention åé¦ˆï¼‰ |
| **æ˜¯å¦è®­ç»ƒä¾èµ–** | å¦ | å¦ï¼ˆtraining-free, plug-and-playï¼‰ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šSpecAttn åœ¨ä¸æŸå¤±è¾“å‡ºè´¨é‡çš„å‰æä¸‹ï¼Œå®ç°äº†æ›´é«˜çš„ draft token æ¥å—ç‡å’Œæ›´ä½çš„é€‰æ‹©å¼€é”€ï¼Œä»è€Œå¤§å¹…æå‡äº†è§£ç ååé‡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **AIME25**ï¼šæ•°å­¦æ¨ç†ä»»åŠ¡ï¼Œè¾“å…¥çŸ­ã€è¾“å‡ºé•¿ï¼ˆå¹³å‡ ~182 è¾“å…¥ tokensï¼Œ~19.7K è¾“å‡º tokensï¼‰
- **CodeElo**ï¼šç¼–ç¨‹ä»£ç ç”Ÿæˆä»»åŠ¡ï¼ŒåŒæ ·å…·æœ‰çŸ­è¾“å…¥ã€é•¿é“¾å¼æ¨ç†ç‰¹ç‚¹
- **LongBench-v2**ï¼šç»¼åˆæ€§é•¿ä¸Šä¸‹æ–‡è¯„æµ‹åŸºå‡†ï¼Œæµ‹è¯•è¾“å…¥é•¿åº¦ä¸º **96Kâ€“120K tokens**ï¼Œæ¶µç›–é—®ç­”ã€æ‘˜è¦ã€æ¨ç†ç­‰å¤šç§ä»»åŠ¡

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### ç¡¬ä»¶å¹³å°
- æœåŠ¡å™¨é…ç½®ï¼šåŒ NVIDIA H100 NVL GPUï¼ˆ94GB æ˜¾å­˜ï¼‰

#### æ¨¡å‹
- å¼€æºæ¨¡å‹æ—ï¼š
  - Qwen3-4B, Qwen3-8B, Qwen3-30B
  - gpt-oss-20bï¼ˆå¸¦ MXFP4 é‡åŒ–ï¼‰

#### åŸºçº¿æ–¹æ³•ï¼ˆå‡é›†æˆäº vLLM æ¡†æ¶å†…è¿›è¡Œå…¬å¹³æ¯”è¾ƒï¼‰
| æ–¹æ³• | ç±»å‹ | KV Selection æ–¹å¼ |
|------|------|------------------|
| **vLLM (default)** | Vanilla auto-regressive decoding | å…¨é‡ KV Cache |
| **MagicDec-Stream** | Self-Speculative + Sparse Attention | Sliding Windowï¼ˆquery-agnosticï¼‰ |
| **MagicDec-Quest** | Self-Speculative + Sparse Attention | Query-awareï¼ˆåŠ¨æ€ä¼°è®¡é‡è¦æ€§ï¼‰ |
| **SpecExtend** | Self-Speculative + Guidance | ä½¿ç”¨ last accepted token çš„ attention æƒé‡æŒ‡å¯¼ |

#### è¯„ä¼°æŒ‡æ ‡
- **Decoding Throughput (tokens/s)**ï¼šä¸»è¦æ€§èƒ½æŒ‡æ ‡
- **Average Accepted Draft Tokens per Iteration**ï¼šè¡¡é‡ drafting å‡†ç¡®ç‡
- **KV Selection Overhead (%)**ï¼šç›¸å¯¹äºç†æƒ³è¿­ä»£å»¶è¿Ÿçš„é¢å¤–å¼€é”€
- **End-to-End Latency**ï¼šæ•´ä½“å“åº”æ—¶é—´

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **æœ€é«˜ååæå‡ï¼ˆvs. vLLMï¼‰** | **2.81Ã—**ï¼ˆQwen3-8B on LongBench-v2ï¼‰ |
| **å¹³å‡ååæå‡ï¼ˆvs. vLLMï¼‰** | **1.25Ã— â€“ 2.70Ã—**ï¼ˆè·¨æ¨¡å‹ä¸æ•°æ®é›†ï¼‰ |
| **ç›¸å¯¹ SOTA æå‡ï¼ˆvs. MagicDec-Quest / Streamï¼‰** | **1.18Ã— â€“ 1.29Ã—** |
| **æœ€å¤§ draft token æ¥å—æ•°/è½®æ¬¡** | æœ€é«˜è¾¾ **8.91**ï¼ˆQwen3-8B, y=11ï¼‰ |

> ğŸ’¡ ç¤ºä¾‹ï¼šåœ¨ LongBench-v2 ä¸Šï¼ŒSpecAttn è¾¾åˆ° **2.81Ã—** äº vanilla vLLMï¼Œä¸”æ¯”å½“å‰æœ€ä¼˜ç¨€ç–æ¨æµ‹æ–¹æ³•å¿« **29%**ã€‚

---

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰ååé‡å¯¹æ¯”ï¼ˆå›¾ 9 & å›¾ 11ï¼‰
- **SpecAttn > MagicDec-Stream > MagicDec-Quest â‰ˆ SpecExtend**
- MagicDec-Quest å›  high KV selection overhead å¯¼è‡´å®é™…é€Ÿåº¦ä½äº MagicDec-Stream
- SpecAttn åœ¨æ‰€æœ‰æ¨¡å‹ä¸Šå‡å–å¾—æœ€ä½³è¡¨ç°ï¼Œå°¤å…¶åœ¨é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸‹ä¼˜åŠ¿æ˜æ˜¾

#### ï¼ˆ2ï¼‰drafting å‡†ç¡®ç‡ï¼ˆå›¾ 10aï¼‰
- SpecAttn å¹³å‡æ¯è½®æ¥å— **6.1â€“9.3 ä¸ª draft tokens**ï¼ˆå–å†³äº y è®¾ç½®ï¼‰
- æ˜æ˜¾ä¼˜äº MagicDec-Quest å’Œ SpecExtendï¼Œè¯´æ˜å…¶ KV selection æ›´æœ‰æ•ˆ

#### ï¼ˆ3ï¼‰KV selection å¼€é”€ï¼ˆå›¾ 10bï¼‰
- **SpecAttn å¼€é”€ä»…ä¸º 5.9%â€“9.4%**
- MagicDec-Questï¼š21.7%
- SpecExtendï¼š11.2%ï¼ˆQwen3-8Bï¼‰ï¼Œé«˜è¾¾ 29.1%ï¼ˆgpt-oss-20bï¼‰
- åŸå› ï¼šSpecExtend å¿…é¡»èšåˆæ‰€æœ‰ token çš„ logitsï¼Œè€Œ SpecAttn ä»…ç”¨ä¸¤ä¸ªè¾¹ç•Œ token å³å¯ä»£è¡¨æ•´ä½“

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰KV Selection ç­–ç•¥å¯¹æ¯”ï¼ˆå›¾ 4ï¼‰
- ä»…ä½¿ç”¨ **last accepted token** çš„ attention â†’ åç»­ draft token æ¥å—ç‡è¿…é€Ÿä¸‹é™
- ä½¿ç”¨ **all draft tokens çš„ attention logits èšåˆ** â†’ æ¥å—ç‡ç¨³å®šç»´æŒé«˜ä½
- å‘ç°ï¼šå³ä½¿è¢«æ‹’ç»çš„ draft tokenï¼Œå…¶è¯­ä¹‰ä»æ¥è¿‘æ­£ç¡®è·¯å¾„ï¼Œä¿ç•™å…¶ attention æœ‰åŠ©äº KV é‡è¦æ€§ä¼°è®¡

#### ï¼ˆ2ï¼‰â€œCollect-2-Queryâ€ æœ‰æ•ˆæ€§ï¼ˆè¡¨ 1 & å›¾ 7ï¼‰
- ä»…ä½¿ç”¨ **first draft + bonus token** æ”¶é›† logitsï¼š
  - æ¥å— token æ•°ï¼š6.11 vs. all-query çš„ 6.13ï¼ˆå‡ ä¹æ— æŸï¼‰
  - å¼€é”€é™ä½è‡³åŸæ¥çš„ **1/10 ä»¥ä¸‹**
- åŸç†ï¼šç›¸é‚» token çš„ top-KV é‡å åº¦é«˜ï¼Œé¦–å°¾ token å…·æœ‰æœ€å¤§ä½ç½®è·¨åº¦ï¼Œæœ€å…·ä»£è¡¨æ€§

#### ï¼ˆ3ï¼‰è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆå›¾ 8 & é™„å½• Bï¼‰
- å½“ sparse ratio â‰¥ 7% æ—¶ï¼Œæ¥å— token æ•°è¶‹äºé¥±å’Œ
- SpecAttn å¯ä½¿ç”¨æ›´å¤§çš„ $ y $ï¼ˆå¦‚ 9â€“11ï¼‰ï¼Œå› å…¶ drafting æ›´é«˜æ•ˆå‡†ç¡®

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Verification ä¸åº”åªæ˜¯â€œéªŒè¯â€ï¼Œæ›´æ˜¯â€œæŒ‡å¯¼â€æ¥æº**  
   verification é˜¶æ®µçš„ full attention è®¡ç®—æä¾›äº†å®è´µçš„ KV æ¡ç›®é‡è¦æ€§ä¿¡å·ï¼Œå¯ä½œä¸º drafting çš„â€œå…è´¹ oracleâ€ã€‚

2. **ååŒè®¾è®¡æ˜¾è‘—æ‰“ç ´ accuracy-overhead trade-off**  
   SpecAttn æˆåŠŸå®ç°äº† **é«˜ drafting accuracy + ä½ KV selection overhead**ï¼Œçªç ´äº†ä»¥å¾€æ–¹æ³•çš„æ€§èƒ½å¤©èŠ±æ¿ã€‚

3. **é•¿ä¸Šä¸‹æ–‡ä¸‹æ€§èƒ½å¢ç›Šéš context length æ‰©å±•è€Œæ”¾å¤§**  
   å› ä¸º SpecAttn çš„ KV selection å¼€é”€å¢é•¿ç¼“æ…¢ï¼Œè€Œæ”¶ç›ŠæŒç»­å¢åŠ ï¼Œåœ¨ç™¾ä¸‡çº§ token åœºæ™¯æ›´å…·æ½œåŠ›ã€‚

4. **æ— éœ€è®­ç»ƒã€å³æ’å³ç”¨ï¼Œå…¼å®¹æ€§å¼º**  
   å®Œå…¨åŸºäº vLLM å®ç°ï¼Œæ”¯æŒå¤šç§æ¶æ„ï¼ˆdenseã€MoEã€RoPE ç­‰ï¼‰ï¼Œé€‚åˆå·¥ä¸šéƒ¨ç½²ã€‚

---

### âš ï¸ å±€é™æ€§
- **ä¾èµ– FlashAttention-3 ä¿®æ”¹èƒ½åŠ›**ï¼šéœ€è¦ä¿®æ”¹åº•å±‚ attention kernel ä»¥å¯¼å‡º attention logitsï¼Œå¯¹æŸäº›é—­æºæ¡†æ¶é€‚é…éš¾åº¦è¾ƒé«˜ã€‚
- **å¯¹ very small models æ”¶ç›Šæœ‰é™**ï¼šå½“ KV cache æœ¬èº«ä¸å¤§æ—¶ï¼Œä¼˜åŒ–ç©ºé—´è¾ƒå°ã€‚
- **ç›®å‰ä»…é€‚ç”¨äº self-speculative setting**ï¼šå°šæœªæ‰©å±•è‡³ auxiliary draft model åœºæ™¯ï¼ˆå¦‚ Medusaï¼‰ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³å¤š draft model setting**ï¼šå°† verification-guided æ€æƒ³åº”ç”¨äº Medusa æˆ– Eagle ç­‰ç»“æ„ã€‚
2. **åŠ¨æ€ sparse ratio è°ƒæ•´**ï¼šæ ¹æ®ä¸Šä¸‹æ–‡å¤æ‚åº¦è‡ªé€‚åº”è°ƒæ•´ç¨€ç–ç¨‹åº¦ã€‚
3. **ç¡¬ä»¶ååŒä¼˜åŒ–**ï¼šç»“åˆå®šåˆ¶ kernel æˆ– FPGA åŠ é€Ÿ logits æ”¶é›†è¿‡ç¨‹ã€‚
4. **å¼•å…¥ç¼“å­˜æœºåˆ¶**ï¼šå¯¹å†å² critical KV å»ºç«‹é•¿æœŸè®°å¿†æ± ï¼Œè¿›ä¸€æ­¥å‡å°‘é‡å¤è®¡ç®—ã€‚

---

> ğŸ“¢ **Impact Statement å¼ºè°ƒ**ï¼š
> - âœ… **å¯é æ€§å¼º**ï¼šä¿è¯ç”Ÿæˆè´¨é‡æ— æŸï¼ˆlosslessï¼‰ï¼Œé€‚ç”¨äºåŒ»ç–—ã€æ³•å¾‹ç­‰é«˜é£é™©é¢†åŸŸã€‚
> - âœ… **ç¯ä¿èŠ‚èƒ½**ï¼šé€šè¿‡æå‡æ•ˆç‡ç›´æ¥é™ä½ LLM æ¨ç†èƒ½è€—ä¸ç¢³è¶³è¿¹ã€‚
> - âœ… **å®‰å…¨å¯æ§**ï¼šä¸æ”¹å˜æ¨¡å‹è¡Œä¸ºï¼Œä»…åŠ é€Ÿæ¨ç†ï¼Œæ— æ–°å¢ bias æˆ–æ»¥ç”¨é£é™©ã€‚

---

## æ€»ç»“ä¸€å¥è¯
> **SpecAttn é€šè¿‡å°† speculative decoding ä¸­çš„ verification é˜¶æ®µå˜ä¸º drafting çš„â€œå¯¼å¸ˆâ€ï¼Œé¦–æ¬¡å®ç°äº†åŸºäºåé¦ˆçš„ç¨€ç–æ³¨æ„åŠ›ååŒè®¾è®¡ï¼Œåœ¨æ— éœ€è®­ç»ƒçš„æƒ…å†µä¸‹è¾¾æˆé«˜è¾¾ 2.81Ã— çš„è§£ç ååæå‡ï¼Œæ˜¯é•¿ä¸Šä¸‹æ–‡ LLM é«˜æ•ˆæ¨ç†çš„ä¸€é¡¹é‡è¦è¿›å±•ã€‚**

</details>

---

### 3. [MedVerse: Efficient and Reliable Medical Reasoning via DAG-Structured Parallel Execution](https://arxiv.org/abs/2602.07529)

**Authors**: Jianwen Chen, Xinyu Yang, Peng Xia, Arian Azarang, Yueh Z Lee, Gang Li, Hongtu Zhu, Yun Li, Beidi Chen, Huaxiu Yao  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2602.07529v1  

#### Abstract
Large language models (LLMs) have demonstrated strong performance and rapid progress in a wide range of medical reasoning tasks. However, their sequential autoregressive decoding forces inherently parallel clinical reasoning, such as differential diagnosis, into a single linear reasoning path, limit...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMedVerse: Efficient and Reliable Medical Reasoning via DAG-Structured Parallel Execution

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜

å½“å‰åŸºäº **Large Language Models (LLMs)** å’Œ **Chain-of-Thought (CoT)** çš„åŒ»ç–—æ¨ç†æ¨¡å‹å­˜åœ¨ä¸‰å¤§ç“¶é¢ˆï¼š

- **å‡†ç¡®æ€§ï¼ˆAccuracyï¼‰**ï¼šåºåˆ—åŒ–è‡ªå›å½’ï¼ˆautoregressive, ARï¼‰è§£ç å¼ºåˆ¶å°†æœ¬åº”å¹¶è¡Œçš„ä¸´åºŠæ¨ç†ï¼ˆå¦‚é‰´åˆ«è¯Šæ–­ï¼‰å‹ç¼©ä¸ºå•ä¸€è·¯å¾„ï¼Œå®¹æ˜“å› æ—©æœŸé”™è¯¯å‡è®¾å¯¼è‡´â€œä¸Šä¸‹æ–‡æ±¡æŸ“â€ï¼ˆcontextual pollutionï¼‰ï¼Œé™åˆ¶äº†å¯¹å¤šç§å¯èƒ½æ€§çš„æ¢ç´¢ã€‚
- **æ•ˆç‡ï¼ˆEfficiencyï¼‰**ï¼šä¸²è¡Œç”Ÿæˆå¯¼è‡´é«˜å»¶è¿Ÿï¼Œå°¤å…¶åœ¨å¤„ç†å¤æ‚å¤šåˆ†æ”¯æ¨ç†æ—¶ï¼Œé‡å¤è®¡ç®—é‡å è¯æ®ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶ä¸´åºŠå†³ç­–æ”¯æŒéœ€æ±‚ã€‚
- **å¯è§£é‡Šæ€§ï¼ˆInterpretabilityï¼‰**ï¼šä¼ ç»Ÿ CoT ç¼ºä¹æ˜¾å¼çš„å› æœä¾èµ–ç»“æ„ï¼Œæ¨ç†è¿‡ç¨‹æ··ä¹±ï¼Œä¸åˆ©äºåŒ»ç”ŸéªŒè¯å’Œç†è§£ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

ä½œè€…æå‡º **MedVerse** â€”â€” ä¸€ç§é¢å‘å¤æ‚åŒ»å­¦æ¨ç†çš„æ–°å‹å»ºæ¨¡èŒƒå¼ï¼Œå…¶æ ¸å¿ƒæ˜¯å°†åŒ»å­¦æ¨ç†é‡æ„ä¸º **æœ‰å‘æ— ç¯å›¾ï¼ˆDirected Acyclic Graph, DAGï¼‰ä¸Šçš„å¹¶è¡Œæ‰§è¡Œè¿‡ç¨‹**ï¼ŒåŸºäº **Petri Net ç†è®º**å®ç°ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š

1. **DAG-Structured Medical Reasoning Framework**
   - å°†ä¸´åºŠæ¨ç†å½¢å¼åŒ–ä¸º DAG ç»“æ„ï¼š
     - **èŠ‚ç‚¹ï¼ˆNodeï¼‰**ï¼šè¡¨ç¤ºä¸­é—´æ¨ç†çŠ¶æ€ï¼ˆå¦‚ç—‡çŠ¶ã€å‡è®¾ã€ç—…ç†æœºåˆ¶ï¼‰
     - **è¾¹ï¼ˆEdgeï¼‰**ï¼šè¡¨ç¤ºå®ä½“é—´çš„æ¡ä»¶ä¾èµ–å…³ç³»
   - æ”¯æŒå¤šä¸ªå‡è®¾å…±äº«ä¸­é—´è¯æ®ã€æ±‡èšäºå…±åŒæœºåˆ¶ï¼Œæ›´è´´è¿‘çœŸå®ä¸´åºŠæ€ç»´ã€‚

2. **åŸºäº Petri Net çš„å¯æ‰§è¡Œæ¨ç†å¼•æ“**
   - å¼•å…¥ **Petri Net** æ•°å­¦æ¡†æ¶ï¼Œå°† DAG æ˜ å°„ä¸ºå¯æ‰§è¡Œçš„å¹¶å‘ç³»ç»Ÿï¼š
     - **Place** å¯¹åº”æ¨ç†çŠ¶æ€ï¼ˆèŠ‚ç‚¹ï¼‰
     - **Transition** å¯¹åº”æ¨ç†æ­¥éª¤ï¼ˆè¾¹ï¼‰
     - **Token** æºå¸¦è¯­ä¹‰ä¿¡æ¯ï¼ˆæ–‡æœ¬å†å² `h` + KV-cache å¼•ç”¨ `k`ï¼‰
   - å®ç°çœŸæ­£çš„ **å› æœä¸€è‡´çš„å¹¶è¡Œæ¨ç†**ï¼Œé¿å…ä¿¡æ¯æ³„éœ²ã€‚

3. **å…¨æ ˆååŒè®¾è®¡ï¼ˆFull-Stack Co-Designï¼‰**
   - **æ•°æ®å±‚ï¼ˆDataï¼‰**ï¼šæå‡º **MedVerse Curator** è‡ªåŠ¨åŒ–æµæ°´çº¿ï¼Œä»åŒ»å­¦çŸ¥è¯†å›¾è°±ç”Ÿæˆ 13,904 æ¡é«˜è´¨é‡ã€ç»“æ„åŒ–çš„ DAG æ¨ç†è½¨è¿¹ï¼Œæ„å»º **MedVerse-14K** æ•°æ®é›†ã€‚
   - **ç®—æ³•å±‚ï¼ˆAlgorithmï¼‰**ï¼šæå‡º **MedVerse Attention**ï¼Œé€šè¿‡æ‹“æ‰‘æ„ŸçŸ¥æ³¨æ„åŠ›æ©ç ï¼ˆtopology-aware attention maskï¼‰å’Œè‡ªé€‚åº”ä½ç½®ç´¢å¼•ï¼ˆadaptive position indicesï¼‰ï¼Œä½¿ Transformer æ”¯æŒ DAG å¹¶è¡Œæ¨ç†ã€‚
   - **ç³»ç»Ÿå±‚ï¼ˆSystemï¼‰**ï¼šå¼€å‘ **MedVerse Engine**ï¼ŒåŸºäº Multiverse Engine æ„å»ºï¼Œæ”¯æŒåŠ¨æ€æå–è®¡åˆ’ã€é›¶æ‹·è´ Fork/Join æ‰§è¡Œï¼Œå®ç°é«˜æ•ˆå¹¶è¡Œè§£ç ã€‚

4. **Hybrid Execution Paradigmï¼ˆçº¿æ€§è§„åˆ’ + å›¾æ‰§è¡Œï¼‰**
   - ç¬¬ä¸€é˜¶æ®µï¼š**çº¿æ€§è§„åˆ’ï¼ˆThink-then-Mapï¼‰**  
     ä½¿ç”¨æ ‡å‡† AR æ¨¡å‹ç”Ÿæˆå¤šä¸ªçº¿æ€§æ¨ç†è·¯å¾„ï¼Œå¹¶æ•´åˆä¸º `<Plan>` å—ï¼Œæ˜ç¡®ä¾èµ–å…³ç³»ã€‚
   - ç¬¬äºŒé˜¶æ®µï¼š**å›¾å¹¶è¡Œæ‰§è¡Œï¼ˆGraph Executionï¼‰**  
     å¼•æ“è§£æ `<Plan>` æ„å»º Petri Netï¼Œè¯†åˆ«â€œå¯ç”¨è½¬æ¢å‰æ²¿â€ï¼ˆenabled-transition frontierï¼‰ï¼Œå¹¶å‘æ‰§è¡Œç‹¬ç«‹æ¨ç†åˆ†æ”¯ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿ CoT / AR æ¨¡å‹ | å¤šæ•° Parallel Thinking æ–¹æ³• | **MedVerse** |
|------|---------------------|-------------------------------|---------------|
| **æ¨ç†ç»“æ„** | çº¿æ€§é“¾å¼ï¼ˆLinear Chainï¼‰ | æ ‘çŠ¶æˆ–ç®€å• Fork-Join | **DAG ç»“æ„ï¼Œæ”¯æŒå¤æ‚ä¾èµ–** |
| **å¹¶è¡Œèƒ½åŠ›** | æ—  | é€šå¸¸é é‡å¤é‡‡æ ·ï¼ˆrepeated samplingï¼‰ | **çœŸæ­£ç»“æ„åŒ–å¹¶è¡Œï¼Œå› æœåŒæ­¥** |
| **è®­ç»ƒå¯¹é½** | ä»…æ¨ç†æ—¶å¹¶è¡Œ | ç¼ºä¹ç»“æ„åŒ–è®­ç»ƒæ•°æ® | **ç«¯åˆ°ç«¯è®­ç»ƒ + å¹¶è¡Œæ¨ç†å¯¹é½** |
| **æ•ˆç‡æå‡æ¥æº** | æ—  | å¢åŠ è®¡ç®—èµ„æºæ¶ˆè€— | **é™ä½æ¨ç†æ·±åº¦ O(D) è€Œéé•¿åº¦ O(N)** |
| **å¯è§£é‡Šæ€§** | å·® | ä¸­ç­‰ | **æ˜¾å¼ç»“æ„ä¾èµ–ï¼Œé€»è¾‘æ¸…æ™°** |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

å®éªŒåœ¨äº”ä¸ªä¸»æµåŒ»å­¦æ¨ç†åŸºå‡†ä¸Šè¿›è¡Œï¼š

- **MedQA**ï¼šç¾å›½åŒ»å¸ˆæ‰§ç…§è€ƒè¯•é£æ ¼é€‰æ‹©é¢˜
- **MedXpert**ï¼šä¸“å®¶çº§åŒ»å­¦é—®ç­”æ•°æ®é›†
- **MedBullets (op4/op5)**ï¼šåŸºäºä¸´åºŠè¦ç‚¹çš„å¤šé€‰é¢˜
- **HLE (Humanityâ€™s Last Exam)**ï¼šç»¼åˆæ€§åŒ»å­¦æŒ‘æˆ˜æµ‹è¯•
- **PubMedQA**ï¼šåŸºäº PubMed æ–‡çŒ®çš„é—®ç­”

æœ€ç»ˆç”¨äºè®­ç»ƒçš„åˆæˆæ•°æ®é›†ä¸º **MedVerse-14K**ï¼ˆ13,904 æ¡ç»“æ„åŒ–æ¨ç†æ ·æœ¬ï¼‰ï¼Œç”± MedVerse Curator ä»ä¸Šè¿°æ•°æ®é›†ä¸­æ„å»ºã€‚

### âš™ï¸ å®éªŒè®¾ç½®

- **åŸºç¡€æ¨¡å‹**ï¼š
  - Qwen2.5-7B-Instruct
  - Llama-3.1-8B-Instruct
- **è®­ç»ƒæ–¹å¼**ï¼š
  - åœ¨ MedVerse-14K ä¸Šå¾®è°ƒ 3 ä¸ª epoch
  - å­¦ä¹ ç‡ï¼š1e-5ï¼ŒBatch Sizeï¼š128
  - ä½¿ç”¨ 4 å— NVIDIA H200 GPUï¼ŒPyTorch FSDP
- **æ¨ç†å¼•æ“**ï¼šåŸºäº **SGLang** å®ç°çš„ **MedVerse Engine**

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Accuracy (%)** | å¤šé¡¹é€‰æ‹©é¢˜çš„æ­£ç¡®ç‡ï¼Œä¸»è¯„ä»·æŒ‡æ ‡ |
| **Latency (s)** | å®Œæ•´æ¨ç†é“¾ç”Ÿæˆçš„ç«¯åˆ°ç«¯è€—æ—¶ï¼ˆwall-clock timeï¼‰ |
| **Throughput (tokens/sec)** | å•ä½æ—¶é—´å†…ç”Ÿæˆçš„ token æ•°é‡ï¼Œè¡¡é‡ååèƒ½åŠ› |
| **Speedup** | ç›¸å¯¹äºæ ‡å‡† AR æ¨¡å‹çš„å»¶è¿ŸåŠ é€Ÿæ¯” |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

- **Base Models**ï¼š
  - Qwen2.5-7B-Instruct
  - Llama-3.1-8B-Instruct
- **Specialized Medical LLMs**ï¼š
  - **MedReason-8B**ï¼šåŸºäºçŸ¥è¯†å›¾è°±ç›‘ç£ CoT çš„åŒ»ç–—ä¸“ç”¨æ¨¡å‹
  - **HuatuoGPT-o1-RL-8B**ï¼šå…·å¤‡å¤æ‚æ¨ç†èƒ½åŠ›çš„ä¸­æ–‡åŒ»ç–—å¤§æ¨¡å‹

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| Model | HLE | MedBullets (op4) | MedBullets (op5) | MedQA | MedXpert | **Average** |
|-------|-----|------------------|------------------|--------|----------|------------|
| Qwen2.5-7B (Base) | 18.4 | 45.8 | 39.6 | 56.2 | 12.3 | **34.5** |
| + MedReason | 20.8 | 49.7 | 44.2 | 56.2 | 14.5 | **37.1** |
| **+ MedVerse** | **19.6** | **55.2** | **48.0** | **58.6** | **15.3** | **39.3** âœ… |
| Llama-3.1-8B (Base) | 13.6 | 48.7 | 42.5 | 58.7 | 13.2 | **35.3** |
| + MedReason | 20.2 | 57.1 | 51.0 | 63.9 | 18.4 | **42.2** |
| + HuatuoGPT-o1 | 14.6 | 55.8 | 53.9 | 72.4 | 16.8 | **42.7** |
| **+ MedVerse** | **20.6** | **62.3** | **53.6** | **66.4** | **19.3** | **44.2** âœ… |

> âœ… **MedVerse åœ¨ä¸¤ä¸ª backbone ä¸Šå‡è¾¾åˆ°æœ€é«˜å¹³å‡å‡†ç¡®ç‡**ï¼Œæ˜¾è‘—ä¼˜äºåŸå§‹æ¨¡å‹å’Œä¸“ä¸šåŒ»ç–—æ¨¡å‹ã€‚

### â± æ•ˆç‡åˆ†æç»“æœï¼ˆFigure 4ï¼‰

- **æ¨ç†å»¶è¿Ÿï¼ˆLatencyï¼‰**ï¼š
  - ç›¸æ¯”æ ‡å‡† AR æ¨¡å‹ï¼Œ**MedVerse å®ç° 1.25Ã— ~ 1.33Ã— çš„ç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½**
  - ä¾‹å¦‚ï¼Œåœ¨ MedXpert ä¸Šä» 5.1s é™è‡³ **4.0s**
- **ç”Ÿæˆååé‡ï¼ˆThroughputï¼‰**ï¼š
  - åœ¨ 2048 é•¿åºåˆ—ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œå³°å€¼ååè¾¾ **~17.1 tokens/sec**
  - ç›¸æ¯” AR åŸºçº¿ï¼ˆ~10.1 tokens/secï¼‰ï¼Œ**æå‡ 69.3%**
- **æ‰©å±•æ€§ä¼˜åŠ¿**ï¼š
  - éšç€åºåˆ—å¢é•¿ï¼ŒMedVerse ååä¸‹é™ç¼“æ…¢ï¼Œè€Œ AR æ¨¡å‹å—é™äºå†…å­˜å¸¦å®½ï¼Œæ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### è¡¨æ ¼ 2ï¼šçº¿æ€§-å¹¶è¡Œæ··åˆç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼ˆMedXpert, Batch=1ï¼‰

| Model Variant | Linear Planning | Parallel Execution | Accuracy (%) | Latency (s) |
|---------------|------------------|---------------------|--------------|-------------|
| Autoregressive | âˆš | Ã— | 18.4 | 5.1 |
| Direct Petri Net | Ã— | âˆš | 17.4 | 4.5 |
| **MedVerse** | âˆš | âˆš | **19.3** | **4.0** |

> ğŸ’¡ å‘ç°ï¼š**ç›´æ¥ç”Ÿæˆ Petri Net ç»“æ„æ•ˆæœå·®**ï¼Œè¯´æ˜ LLM éš¾ä»¥ä»é›¶æ„é€ å¯é å›¾ç»“æ„ï¼›è€Œâ€œå…ˆçº¿æ€§è§„åˆ’ + å†å¹¶è¡Œæ‰§è¡Œâ€çš„æ··åˆèŒƒå¼åœ¨ **å‡†ç¡®æ€§å’Œæ•ˆç‡ä¸Šå–å¾—æœ€ä½³å¹³è¡¡**ã€‚

#### è¡¨æ ¼ 4ï¼šè®­ç»ƒç­–ç•¥ä¸æ¨ç†æ¨¡å¼è”åˆæ¶ˆè

| Configuration | Training | Inference | Avg Acc |
|---------------|----------|-----------|---------|
| Auto-Ser | AR | Serial | 0.3690 |
| Auto-Par | AR | Parallel | 0.3792 |
| Mask-Ser | MedVerse Attention | Serial | 0.3856 |
| **Mask-Par (Ours)** | MedVerse Attention | Parallel | **0.3934** |

> ğŸ” ç»“è®ºï¼š
> - **æ‹“æ‰‘æ„ŸçŸ¥è®­ç»ƒï¼ˆMask-Serï¼‰æœ¬èº«å°±èƒ½æç‚¹ +1.66%**ï¼Œè¯´æ˜ç»“æ„åŒ–è®­ç»ƒæœ‰åŠ©äºå­¦ä¹ å› æœä¾èµ–ã€‚
> - **å¹¶è¡Œæ¨ç†è¿›ä¸€æ­¥å¢ç›Š**ï¼Œè¯æ˜â€œè®­ç»ƒ-æ¨ç†â€ç»“æ„å¯¹é½è‡³å…³é‡è¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **ä¸´åºŠæ¨ç†æœ¬è´¨ä¸Šæ˜¯éçº¿æ€§çš„ DAG è¿‡ç¨‹**ï¼Œå¼ºè¡Œç”¨çº¿æ€§ CoT å»ºæ¨¡ä¼šæŸå¤±è¡¨è¾¾èƒ½åŠ›å’Œé²æ£’æ€§ã€‚
2. **MedVerse æˆåŠŸå°† Petri Net ç†è®ºå¼•å…¥ LLM æ¨ç†**ï¼Œå®ç°äº†ç»“æ„åŒ–ã€å¯æ‰§è¡Œã€å¯å¹¶è¡Œçš„åŒ»å­¦æ¨ç†æ¡†æ¶ã€‚
3. **å…¨æ ˆååŒè®¾è®¡ï¼ˆæ•°æ® + ç®—æ³• + ç³»ç»Ÿï¼‰æ˜¯å…³é”®**ï¼š
   - MedVerse Curator æä¾›ç»“æ„åŒ–è®­ç»ƒä¿¡å·
   - MedVerse Attention å®ç°æ‹“æ‰‘æ„ŸçŸ¥å»ºæ¨¡
   - MedVerse Engine å®ç°é«˜æ•ˆå¹¶è¡Œæ‰§è¡Œ
4. **â€œçº¿æ€§è§„åˆ’ + å›¾æ‰§è¡Œâ€æ··åˆèŒƒå¼æœ€ä¼˜**ï¼šçº¯ç«¯åˆ°ç«¯å›¾ç”Ÿæˆä¸å¯é ï¼Œéœ€å€ŸåŠ©çº¿æ€§æ€è€ƒè¾…åŠ©å›¾æ„å»ºã€‚
5. **æ•ˆç‡æå‡æºäºè®¡ç®—å¤æ‚åº¦é™ç»´**ï¼šä» O(N) åºåˆ—é•¿åº¦å˜ä¸º O(D) å›¾æ·±åº¦ï¼Œç‰¹åˆ«é€‚åˆé•¿ç¨‹å¤æ‚æ¨ç†ã€‚

### âš  å±€é™æ€§

- **ä¾èµ–é«˜è´¨é‡ç»“æ„åŒ–æ•°æ®ç”Ÿæˆ**ï¼šMedVerse Curator çš„å¯é æ€§ç›´æ¥å½±å“æ¨¡å‹è¡¨ç°ï¼Œç›®å‰ä»ä¾èµ–å¼º LLMï¼ˆå¦‚ GPT-5.1ï¼‰ä½œä¸ºæ•™å¸ˆæ¨¡å‹ã€‚
- **Petri Net å»ºæ¨¡å¤æ‚æ€§**ï¼šå¯¹éå¸¸è§„æˆ–æ¨¡ç³Šæ¨ç†è·¯å¾„çš„å»ºæ¨¡èƒ½åŠ›æœ‰é™ï¼Œå¯èƒ½æ— æ³•è¦†ç›–æ‰€æœ‰ä¸´åºŠåœºæ™¯ã€‚
- **ç¡¬ä»¶ä¾èµ–è¾ƒé«˜**ï¼šè™½ç„¶æå‡äº†ååï¼Œä½†ä»éœ€é«˜æ€§èƒ½ GPUï¼ˆå¦‚ H200ï¼‰æ‰èƒ½å……åˆ†å‘æŒ¥å¹¶è¡Œä¼˜åŠ¿ã€‚
- **å°šæœªåœ¨çœŸå®ä¸´åºŠç¯å¢ƒä¸­éƒ¨ç½²éªŒè¯**ï¼šå®éªŒå‡ä¸ºç¦»çº¿ benchmark æµ‹è¯•ï¼Œç¼ºä¹åŒ»ç”Ÿåé¦ˆå’Œå®é™…åº”ç”¨æ•°æ®ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

- **æ‰©å±•è‡³å¤šæ¨¡æ€åŒ»å­¦æ¨ç†**ï¼ˆå¦‚ç»“åˆåŒ»å­¦å½±åƒï¼‰ï¼Œæ„å»º **Multimodal MedVerse**
- **å¼•å…¥å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ¨ç†è·¯å¾„é€‰æ‹©**ï¼Œå®ç°åŠ¨æ€å‰ªæä¸èšç„¦
- **è½»é‡åŒ–ç‰ˆæœ¬é€‚é…è¾¹ç¼˜è®¾å¤‡**ï¼Œæ¨åŠ¨ä¸´åºŠä¸€çº¿éƒ¨ç½²
- **æ„å»ºå¼€æ”¾çš„ DAG åŒ»å­¦çŸ¥è¯†å›¾è°±ç¼–è¾‘å™¨**ï¼Œæ”¯æŒåŒ»ç”Ÿå‚ä¸æ¨ç†ç»“æ„æ ‡æ³¨
- **æ¢ç´¢æ›´å¤š Petri Net å˜ä½“**ï¼ˆå¦‚ Timed/Colored Petri Netsï¼‰ä»¥å»ºæ¨¡æ—¶é—´åŠ¨æ€å’Œä¸ç¡®å®šæ€§

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **MedVerse é€šè¿‡å°†åŒ»å­¦æ¨ç†é‡æ„ä¸º DAG å¹¶è¡Œæ‰§è¡Œè¿‡ç¨‹ï¼Œé¦–æ¬¡å®ç°äº†â€œç»“æ„å¯¹é½ã€è®­ç»ƒå¯¹é½ã€ç³»ç»Ÿå¯¹é½â€çš„é«˜æ•ˆå¯é åŒ»ç–—æ¨ç†æ¡†æ¶ï¼Œåœ¨å‡†ç¡®ç‡ã€å»¶è¿Ÿã€ååä¸‰æ–¹é¢å…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œä¸ºä¸‹ä¸€ä»£ä¸´åºŠ AI å†³ç­–ç³»ç»Ÿæä¾›äº†æ–°èŒƒå¼ã€‚**

</details>

---

### 4. [BitLogic: Training Framework for Gradient-Based FPGA-Native Neural Networks](https://arxiv.org/abs/2602.07400)

**Authors**: Simon B\"uhrer, Andreas Plesner, Aczel Till, Roger Wattenhofer  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.07400v1  

#### Abstract
The energy and latency costs of deep neural network inference are increasingly driven by deployment rather than training, motivating hardware-specialized alternatives to arithmetic-heavy models. Field-Programmable Gate Arrays (FPGAs) provide an attractive substrate for such specialization, yet exist...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# BitLogic: Training Framework for Gradient-Based FPGA-Native Neural Networks è®ºæ–‡æ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰æ¨ç†çš„èƒ½è€—å’Œå»¶è¿Ÿæˆæœ¬æ—¥ç›Šæˆä¸ºç“¶é¢ˆï¼Œå°¤å…¶æ˜¯åœ¨è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ä¸­ã€‚ä¼ ç»Ÿçš„åŸºäºæµ®ç‚¹æˆ–é«˜ç²¾åº¦æ•´æ•°è¿ç®—çš„æ¨¡å‹åœ¨é€šç”¨ç¡¬ä»¶ï¼ˆå¦‚GPUï¼‰ä¸Šæ•ˆç‡ä½ä¸‹ã€‚å°½ç®¡FPGAå› å…¶å¯ç¼–ç¨‹æ€§å’Œä½åŠŸè€—æ½œåŠ›è¢«å¹¿æ³›ç”¨äºåŠ é€Ÿæ¨ç†ï¼Œä½†ç°æœ‰çš„FPGAç¥ç»ç½‘ç»œæ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- å¤šä¸ºå°†ä¼ ç»Ÿæ¨¡å‹é‡åŒ–åæ˜ å°„åˆ°FPGAèµ„æºï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨FPGAåŸç”Ÿé€»è¾‘å•å…ƒï¼ˆå¦‚LUTï¼‰ï¼›
- ä¸åŒç ”ç©¶ä¹‹é—´é‡‡ç”¨å¼‚æ„å¹³å°ã€ä¸åŒå‡è®¾ï¼ˆå¦‚æµæ°´çº¿è®¾è®¡ï¼‰ï¼Œéš¾ä»¥å…¬å¹³æ¯”è¾ƒï¼›
- ç¼ºä¹ç»Ÿä¸€æ¡†æ¶æ”¯æŒç«¯åˆ°ç«¯è®­ç»ƒä¸ç¡¬ä»¶ç”Ÿæˆã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡º **BitLogic** â€”â€”ä¸€ä¸ª**å®Œå…¨æ¢¯åº¦é©±åŠ¨ã€ç«¯åˆ°ç«¯å¯è®­ç»ƒçš„FPGAåŸç”Ÿç¥ç»ç½‘ç»œæ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- ä½¿ç”¨ **Lookup Table (LUT)** èŠ‚ç‚¹æ›¿ä»£ä¼ ç»Ÿçš„ä¹˜ç´¯åŠ ï¼ˆMACï¼‰æ“ä½œï¼Œç›´æ¥å¯¹åº”FPGAä¸­çš„åŸºæœ¬é€»è¾‘å•å…ƒï¼›
- æ‰€æœ‰LUTèŠ‚ç‚¹é€šè¿‡**å¯å¾®æ¾å¼›æŠ€æœ¯**å®ç°æ¢¯åº¦ä¼ æ’­ï¼Œæ”¯æŒåå‘ä¼ æ’­è®­ç»ƒï¼›
- æ„å»ºæ¨¡å—åŒ–åŠŸèƒ½APIï¼Œæ”¯æŒå¤šç§æ¶æ„ç»„åˆï¼ˆå¦‚CNNã€æ®‹å·®è¿æ¥ã€æ³¨æ„åŠ›æœºåˆ¶ç­‰ï¼‰ï¼›
- æä¾›è‡ªåŠ¨åŒ– **Register Transfer Level (RTL)** å¯¼å‡ºæµç¨‹ï¼Œå°†PyTorchæ¨¡å‹æ— ç¼è½¬æ¢ä¸ºå¯ç»¼åˆçš„HDLä»£ç ï¼Œç¡®ä¿è½¯ç¡¬ä»¶ä¸€è‡´æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | BitLogicä¼˜åŠ¿ |
|------|-------------|
| **ç¡¬ä»¶é€‚é…æ€§** | åŸç”Ÿä½¿ç”¨LUTä½œä¸ºè®¡ç®—å•å…ƒï¼Œæ— éœ€ä¾èµ–DSPæˆ–BRAMï¼Œæœ€å¤§åŒ–åˆ©ç”¨FPGAç‰‡ä¸Šé€»è¾‘èµ„æº |
| **è®­ç»ƒæ–¹å¼** | å®Œå…¨åŸºäºæ¢¯åº¦ä¼˜åŒ–ï¼Œæ”¯æŒend-to-endè®­ç»ƒï¼Œé¿å…ç»„åˆæœç´¢æˆ–éè¿ç»­ä¼˜åŒ– |
| **çµæ´»æ€§ä¸æ‰©å±•æ€§** | æ¨¡å—åŒ–è®¾è®¡å…è®¸çµæ´»æ„å»ºå„ç§æ¶æ„ï¼›æ”¯æŒç¼–ç å™¨ï¼ˆencodersï¼‰ã€å¤´å±‚ï¼ˆheadsï¼‰ç­‰ç»„ä»¶å®šåˆ¶ |
| **éƒ¨ç½²ä¾¿æ·æ€§** | è‡ªåŠ¨åŒ–RTLå¯¼å‡º + Vivadoé¡¹ç›®ç”Ÿæˆï¼Œæ˜¾è‘—é™ä½ä»æ¨¡å‹åˆ°ç¡¬ä»¶çš„é—¨æ§› |
| **å…¬å¹³è¯„ä¼°åŸºç¡€** | åœ¨ç»Ÿä¸€æ¡†æ¶ä¸‹ç³»ç»Ÿè¯„ä¼°ä¸åŒLUTæ¾å¼›ç­–ç•¥ã€è¿æ¥æ¨¡å¼ã€èŠ‚ç‚¹ç±»å‹çš„å½±å“ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å››ä¸ªæ ‡å‡†å›¾åƒåˆ†ç±»åŸºå‡†ï¼š
- **MNIST**: æ‰‹å†™æ•°å­—è¯†åˆ«ï¼ˆ10ç±»ï¼‰
- **Fashion-MNIST**: æœé¥°å›¾åƒåˆ†ç±»ï¼ˆ10ç±»ï¼‰
- **CIFAR-10**: å½©è‰²å°å›¾åˆ†ç±»ï¼ˆ10ç±»ï¼‰
- **CIFAR-100**: å½©è‰²å°å›¾ç»†ç²’åº¦åˆ†ç±»ï¼ˆ100ç±»ï¼‰

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
#### æ¨¡å‹é…ç½®
- **ä¸¤ç§ä¸»å¹²æ¶æ„**ï¼š
  - Feedforward Network (FFN)ï¼šä¸¤å±‚Top-Kç¨€ç–LUTå±‚
  - Convolutional Network (CNN)ï¼šä¸¤ä¸ªæ­¥é•¿ä¸º2çš„3Ã—3å·ç§¯å— + å…¨è¿æ¥å±‚
- **å…³é”®å‚æ•°**ï¼š
  - LUTè¾“å…¥ç»´åº¦ $n \in \{2,3,4,5,6\}$
  - ä½¿ç”¨ **probabilistic relaxation** ä½œä¸ºé»˜è®¤å¯å¾®åŒ–æ–¹æ³•
  - è¾“å‡ºå¤´ä½¿ç”¨ **GroupSum** æˆ– **GroupedDSP**

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ |
|--------|---------|
| **å‡†ç¡®æ€§** | æµ‹è¯•å‡†ç¡®ç‡ï¼ˆTest Accuracy %ï¼‰ |
| **ç¡¬ä»¶æ•ˆç‡** | é€»è¾‘é—¨ç­‰æ•ˆæ•°é‡ï¼ˆEquivalent Binary Gatesï¼‰ã€LUTä½¿ç”¨é‡ã€å•æ ·æœ¬æ¨ç†å»¶è¿Ÿï¼ˆLatencyï¼‰ã€ååé‡ï¼ˆFPSï¼‰ã€èƒ½æ•ˆï¼ˆEnergy per Sampleï¼‰ |
| **å¯æ¯”æ€§** | æŠ¥å‘Šâ€œç­‰æ•ˆäºŒè¿›åˆ¶é—¨æ•°â€ä»¥è·¨æ¶æ„å…¬å¹³æ¯”è¾ƒè§„æ¨¡ |

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
ä¸å¤šä¸ªåŸºäºé€»è¾‘é—¨æˆ–LUTçš„ç¥ç»ç½‘ç»œè¿›è¡Œæ¯”è¾ƒï¼š
- **DiffLogic Net** (Petersen et al., 2022)
- **LogicTreeNet** (Petersen et al., 2024)
- **LILogicNet** (Fojcik et al., 2025)
- **DWN** (Bacellar et al., 2025)

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ•°æ®é›† | BitLogic å‡†ç¡®ç‡ | ç­‰æ•ˆé—¨æ•° | æ¨ç†å»¶è¿Ÿï¼ˆFPGAï¼‰ |
|-------|----------------|----------|------------------|
| MNIST | **99.1%** | 384K | <20ns |
| Fashion-MNIST | **93.8%** | 384K | <20ns |
| CIFAR-10 | **72.3%** | <0.3M | <20ns |
| CIFAR-100 | **23.4%** | 384K | <20ns |

> æ³¨ï¼šæ‰€æœ‰FPGAæµ‹è¯•å‡åœ¨ **Xilinx Zynq-7020** ä¸Šå®Œæˆï¼Œä»…ä½¿ç”¨LUTèµ„æºï¼ˆæœªç”¨DSPæˆ–BRAMï¼‰ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ **CIFAR-10** ä¸Šï¼ŒBitLogicè¾¾åˆ° **72.3%** å‡†ç¡®ç‡ï¼Œä¼˜äºå¤§å¤šæ•°è½»é‡çº§é€»è¾‘ç½‘ç»œï¼ˆå¦‚LILogicNet-L: 60.98% @ 256K gatesï¼‰ï¼Œä¸”é—¨æ•°è¿œä½äºå¤§å‹CNNå˜ä½“ï¼ˆå¦‚LogicTreeNet-Géœ€61M gatesè¾¾86.29%ï¼‰ã€‚
- åœ¨ **MNIST** ä¸Šï¼ŒBitLogicä»¥384Ké—¨å®ç° **99.1%** å‡†ç¡®ç‡ï¼Œæ¥è¿‘æœ€ä¼˜æ°´å¹³ï¼Œæ˜¾è‘—é«˜äºå¤šæ•°é€»è¾‘ç½‘ï¼ˆå¦‚DiffLogic Netæœ€é«˜98.47% @ 384Kï¼‰ã€‚
- åœ¨ **èƒ½æ•ˆæ–¹é¢**ï¼ŒFPGAå®æµ‹å•æ ·æœ¬æ¨ç†èƒ½è€—ä»…ä¸º **3.34nJ**ï¼Œè¿œä½äºCPUï¼ˆ5.63mJï¼‰å’ŒGPUï¼ˆ130Î¼Jï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰ç»„ä»¶çº§æ¶ˆèåˆ†æï¼ˆTable 2ï¼‰
åœ¨Fashion-MNISTä¸Šçš„æ§åˆ¶å˜é‡å®éªŒè¡¨æ˜ï¼š
- **èŠ‚ç‚¹è¾“å…¥ç»´åº¦ï¼ˆFan-inï¼‰å½±å“æœ€å¤§**ï¼šä»2å¢è‡³6ï¼Œå‡†ç¡®ç‡ä»79.3%æå‡è‡³84.9%ï¼Œè¯´æ˜æ›´é«˜ç»´LUTå¢å¼ºè¡¨è¾¾èƒ½åŠ›ã€‚
- **å®½åº¦ä¼˜äºæ·±åº¦**ï¼šå¢åŠ å±‚å®½æ¯”å †å å±‚æ•°æ›´æœ‰æ•ˆï¼ˆè§Fig 4aï¼‰ï¼Œæ·±å±‚ç½‘ç»œæ”¶ç›Šé€’å‡ã€‚
- **ç¼–ç æ–¹å¼**ï¼š`distributive thermometer` è¡¨ç°æœ€ä½³ï¼ˆ83.4%ï¼‰ï¼Œä¼˜äºone-hotã€binaryç­‰ã€‚
- **èŠ‚ç‚¹ç±»å‹**ï¼š`hybrid` å’Œ `probabilistic` è¡¨ç°æœ€å¥½ï¼ˆ~84%ï¼‰ï¼Œè€Œ`linear`ã€`warp`è¾ƒå·®ã€‚
- **å¤´éƒ¨è®¾è®¡**ï¼š`GroupSum` ä¼˜äº `GroupedDSP`ï¼Œåè€…å› å¼•å…¥DSPåè€Œå—é™ã€‚

#### ï¼ˆ2ï¼‰æ¸©åº¦è¶…å‚è°ƒèŠ‚ï¼ˆFig 4bï¼‰
- å¼•å…¥ **temperature parameter T** å¯ç¼“è§£ç¦»æ•£åŒ–è¿‡æ‹Ÿåˆé—®é¢˜ï¼›
- æœ€ä½³T â‰ˆ 50æ—¶éªŒè¯å‡†ç¡®ç‡è¾¾å³°å€¼ï¼ˆ85.97%ï¼‰ï¼ŒT=1.0åˆ™ä¸¥é‡è¿‡æ‹Ÿåˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LUT-based NNå¯ä»¥å®ç°é«˜ç²¾åº¦æ¨ç†**ï¼šå³ä½¿ä¸ä½¿ç”¨ä»»ä½•MACæˆ–æµ®ç‚¹è¿ç®—ï¼Œä»…é LUTä¹Ÿèƒ½åœ¨ä¸»æµè§†è§‰ä»»åŠ¡ä¸Šå–å¾—å…·æœ‰ç«äº‰åŠ›çš„ç»“æœã€‚
2. **å®½åº¦ä¼˜å…ˆäºæ·±åº¦**ï¼šå¯¹äºLUTç½‘ç»œï¼Œæ‰©å¤§æ¯å±‚å®½åº¦æ¯”åŠ æ·±ç½‘ç»œæ›´æœ‰åˆ©äºæ€§èƒ½æå‡ï¼Œè¿™ä¸ä¼ ç»ŸDNNè¶‹åŠ¿ä¸€è‡´ï¼Œä½†åœ¨é€»è¾‘ç½‘ç»œä¸­æ›´ä¸ºæ˜æ˜¾ã€‚
3. **èŠ‚ç‚¹è¾“å…¥ç»´åº¦è‡³å…³é‡è¦**ï¼šæ›´å¤§çš„fan-inï¼ˆå³æ›´å¤šè¾“å…¥ä½ï¼‰æ˜¾è‘—æé«˜æ¨¡å‹å®¹é‡ï¼Œä½†ä»£ä»·æ˜¯å‚æ•°å‘ˆæŒ‡æ•°å¢é•¿ï¼ˆ$2^n$ï¼‰ã€‚
4. **ç¡¬ä»¶-ç®—æ³•ååŒè®¾è®¡å¯è¡Œ**ï¼šé€šè¿‡è¾¹ç•Œä¸€è‡´çš„å¯å¾®æ¾å¼› + è‡ªåŠ¨RTLå¯¼å‡ºï¼Œå®ç°äº†çœŸæ­£æ„ä¹‰ä¸Šçš„â€œè®­ç»ƒå³éƒ¨ç½²â€é—­ç¯ã€‚
5. **FPGAæè‡´é«˜æ•ˆ**ï¼šBitLogicåœ¨Zynq-7020ä¸Šå®ç° **<20ns å•æ ·æœ¬å»¶è¿Ÿ** å’Œ **3.34nJ èƒ½è€—**ï¼Œå±•ç¤ºäº†FPGAåœ¨æä½å»¶è¿Ÿåœºæ™¯çš„å·¨å¤§æ½œåŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **è®­ç»ƒç¨³å®šæ€§éšæ·±åº¦ä¸‹é™**ï¼šç›®å‰ä¸»è¦é€‚ç”¨äºæµ…å±‚ç½‘ç»œï¼ˆâ‰¤2å±‚ï¼‰ï¼Œæ·±å±‚è®­ç»ƒé¢ä¸´æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚
2. **CNNç‰ˆæœ¬è¡¨ç°ä¸ä½³**ï¼šå½“å‰å·ç§¯æ¶æ„æœªå……åˆ†è°ƒä¼˜ï¼Œæ€§èƒ½ä½äºFFNï¼Œå¯èƒ½ç”±äºæ»‘åŠ¨çª—å£å¸¦æ¥çš„åºåˆ—å¤„ç†å¼€é”€ã€‚
3. **RTLå¯¼å‡ºé™åˆ¶**ï¼š
   - å½“å‰ä»…æ”¯æŒå…¨ç»„åˆé€»è¾‘ï¼›
   - ä¸æ”¯æŒå¤æ‚æ—¶åºé€»è¾‘ï¼ˆå¦‚æ˜¾å¼æµæ°´çº¿ã€çŠ¶æ€æœºï¼‰ï¼›
   - Vivadoå¯¹å¸¸é‡æ•°ç»„å¤§å°æœ‰é™åˆ¶ï¼Œå½±å“å¤§è§„æ¨¡æ¨¡å‹åˆæˆã€‚
4. **å†…å­˜å¸¦å®½æœªä¼˜åŒ–**ï¼šè™½ç„¶è®¡ç®—é«˜æ•ˆï¼Œä½†è¾“å…¥è¾“å‡ºä»å—å¤–éƒ¨å­˜å‚¨è®¿é—®åˆ¶çº¦ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æå‡æ·±åº¦è®­ç»ƒç¨³å®šæ€§**ï¼š
   - å¼•å…¥å½’ä¸€åŒ–æœºåˆ¶ï¼ˆNormalizationï¼‰
   - æ”¹è¿›åˆå§‹åŒ–ç­–ç•¥ï¼ˆå¦‚Residual Initializationæ¨å¹¿ï¼‰
   - è®¾è®¡é€‚ç”¨äºé€»è¾‘èŠ‚ç‚¹çš„æ®‹å·®è¿æ¥
2. **æ‹“å±•ä»»åŠ¡èŒƒå›´**ï¼š
   - æ”¯æŒåˆ†å‰²ã€é‡å»ºã€åºåˆ—å»ºæ¨¡ç­‰ä»»åŠ¡
   - å¼€å‘RNNã€Transformeré£æ ¼æ¨¡å—
3. **å®Œå–„HDLå¯¼å‡ºèƒ½åŠ›**ï¼š
   - æ”¯æŒæµæ°´çº¿æ’å…¥ã€æ¨¡å—å¤åˆ¶ã€è¿­ä»£åˆ†è§£
   - å®ç°æµå¼æ¥å£ä¸æ—¶é’ŸåŸŸç®¡ç†
4. **ç¡¬ä»¶æ„ŸçŸ¥è”åˆä¼˜åŒ–ï¼ˆCo-designï¼‰**ï¼š
   - å°†LUTåˆ©ç”¨ç‡ã€æ—¶åºçº¦æŸçº³å…¥æŸå¤±å‡½æ•°
   - ç»“åˆNeural Architecture Search (NAS) è‡ªåŠ¨æ¢ç´¢æœ€ä¼˜ç»“æ„
5. **æ¢ç´¢æ–°å‹èŠ‚ç‚¹ä¸è¿æ¥æœºåˆ¶**ï¼š
   - åŠ¨æ€è·¯ç”±ã€è‡ªé€‚åº”æ‹“æ‰‘å­¦ä¹ 
   - æ›´é«˜æ•ˆçš„interconnect parametrizationï¼ˆå‚è€ƒKresse et al., 2025ï¼‰

---

> âœ… æ€»ç»“ï¼š**BitLogic æ˜¯é¦–ä¸ªå®ç°ä»PyTorchè®­ç»ƒåˆ°FPGAéƒ¨ç½²å…¨æµç¨‹è‡ªåŠ¨åŒ–çš„æ¢¯åº¦é©±åŠ¨LUTç¥ç»ç½‘ç»œæ¡†æ¶**ã€‚å®ƒä¸ä»…åœ¨å¤šä¸ªåŸºå‡†ä¸Šå–å¾—äº†é¢†å…ˆçš„é€»è¾‘ç½‘ç»œæ€§èƒ½ï¼Œæ›´é‡è¦çš„æ˜¯å»ºç«‹äº†ä¸€ä¸ªå¼€æ”¾ã€å¯å¤ç°ã€å¯æ‰©å±•çš„ç ”ç©¶èŒƒå¼ï¼Œæ¨åŠ¨FPGA-native AIæ¨¡å‹çš„å‘å±•è¿›å…¥æ–°é˜¶æ®µã€‚

</details>

---

### 5. [DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents](https://arxiv.org/abs/2602.07035)

**Authors**: Jiahao Zhao, Shaoxuan Xu, Zhongxiang Sun, Fengqi Zhu, Jingyang Ou, Yuling Shi, Chongxuan Li, Xiao Zhang, Jun Xu  
**Category**: cs.AI  
**Published**: 2026-02-10  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.07035v1  

#### Abstract
Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundam...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDLLM-Searcher: Adapting Diffusion Large Language Models for Search Agents

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹å½“å‰ **Search Agent** åœ¨å®é™…éƒ¨ç½²ä¸­é¢ä¸´çš„ä¸¤å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼š

1. **Latency Challengeï¼ˆå»¶è¿ŸæŒ‘æˆ˜ï¼‰**ï¼š  
   åœ¨æ ‡å‡†çš„ ReAct èŒƒå¼ä¸‹ï¼ŒAgent éœ€è¦ä¸²è¡Œæ‰§è¡Œâ€œæ€è€ƒ â†’ å·¥å…·è°ƒç”¨ â†’ ç­‰å¾…å·¥å…·å“åº”â€æµç¨‹ã€‚ç”±äºæ¨¡å‹åœ¨ç­‰å¾…å¤–éƒ¨å·¥å…·è¿”å›æ—¶å¤„äºç©ºé—²çŠ¶æ€ï¼Œå¯¼è‡´ç«¯åˆ°ç«¯æ¨ç†å»¶è¿Ÿä¸¥é‡ã€‚

2. **Agent Ability Challengeï¼ˆæ™ºèƒ½ä½“èƒ½åŠ›æŒ‘æˆ˜ï¼‰**ï¼š  
   å½“å‰çš„ **dLLMs**ï¼ˆdiffusion large language modelsï¼‰è™½ç„¶å…·å¤‡å¹¶è¡Œè§£ç ä¼˜åŠ¿ï¼Œä½†åœ¨å¤šæ­¥æ¨ç†ã€å·¥å…·è°ƒç”¨æ ¼å¼éµå¾ªç­‰æ–¹é¢è¡¨ç°è¾ƒå¼±ï¼Œéš¾ä»¥èƒœä»»å¤æ‚ agentic ä»»åŠ¡ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡º **DLLM-Searcher**ï¼Œä¸€ä¸ªä¸“ä¸º dLLMs è®¾è®¡çš„æœç´¢æ™ºèƒ½ä½“ä¼˜åŒ–æ¡†æ¶ï¼ŒåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

#### ï¼ˆ1ï¼‰**ä¸¤é˜¶æ®µåè®­ç»ƒç®¡é“ï¼ˆTwo-stage Post-training Pipelineï¼‰**

- **Agentic SFTï¼ˆSupervised Fine-Tuningï¼‰**  
  åˆ©ç”¨é«˜æ€§èƒ½æ•™å¸ˆæ¨¡å‹ï¼ˆå¦‚ Doubao-Seed-1.8ï¼‰ç”Ÿæˆé«˜è´¨é‡çš„å¤šè·³é—®ç­”è½¨è¿¹ï¼Œç­›é€‰å‡ºæ ¼å¼æ­£ç¡®ã€é€»è¾‘å®Œæ•´çš„æ ·æœ¬è¿›è¡Œç›‘ç£å¾®è°ƒï¼Œæå‡ dLLM å¯¹ `tool_call` æ ¼å¼çš„éµå¾ªèƒ½åŠ›å’ŒåŸºç¡€æ£€ç´¢æ¨ç†èƒ½åŠ›ã€‚

- **Agentic VRPOï¼ˆVariance-Reduced Preference Optimizationï¼‰**  
  åŸºäº SFT æ¨¡å‹ç”Ÿæˆèƒœè€…/è´¥è€…è½¨è¿¹å¯¹ï¼ˆwinner/loser pairsï¼‰ï¼Œé€šè¿‡åå¥½ä¼˜åŒ–è¿›ä¸€æ­¥å¼ºåŒ–æ¨¡å‹çš„æ¨ç†ä¸ä¿¡æ¯æ£€ç´¢èƒ½åŠ›ã€‚å¼•å…¥ **Agentic ELBO** å’Œ **Agentic Noising** æŠ€æœ¯ï¼Œç¡®ä¿ä»…å…³æ³¨ `think` å’Œ `tool_call` åŒºåŸŸçš„å­¦ä¹ ï¼Œé¿å…å·¥å…·å“åº”ä¿¡æ¯æ³„éœ²ã€‚

#### ï¼ˆ2ï¼‰**æ–°å‹ä»£ç†èŒƒå¼ï¼šP-ReActï¼ˆParallel-Reasoning and Actingï¼‰**

ä¸€ç§æ— éœ€é¢å¤–è®­ç»ƒçš„æ¨ç†ç­–ç•¥ï¼Œåˆ©ç”¨ dLLM çš„éè‡ªå›å½’ç‰¹æ€§å®ç°â€œè¾¹ç­‰è¾¹æƒ³â€ï¼š

- **Token Pre-filling**ï¼šé¢„å¡«å…… `<tool_call>` å’Œ `</tool_call>` è¾¹ç•Œæ ‡è®°ã€‚
- **Confidence Biasing**ï¼šåœ¨è§£ç è¿‡ç¨‹ä¸­ï¼Œå¯¹è¾¹ç•Œå†…çš„ token ä½ç½®å¢åŠ ç½®ä¿¡åº¦åç½®ï¼ˆbiasï¼‰ï¼Œå¼•å¯¼æ¨¡å‹ä¼˜å…ˆè§£ç å·¥å…·è°ƒç”¨æŒ‡ä»¤ã€‚

è¿™ä½¿å¾—æ¨¡å‹èƒ½å…ˆå‘å‡ºæœç´¢è¯·æ±‚ï¼Œåœ¨ç­‰å¾…æœç´¢å¼•æ“è¿”å›ç»“æœçš„åŒæ—¶ç»§ç»­å®Œæˆâ€œæ€è€ƒâ€éƒ¨åˆ†çš„ç”Ÿæˆï¼Œä»è€Œæ˜¾è‘—é™ä½ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | P-ReAct å®ç°çº¦ **15% çš„æ¨ç†åŠ é€Ÿ**ï¼Œæ‰“ç ´ ReAct çš„ä¸²è¡Œç“¶é¢ˆ |
| **æ€§èƒ½ä¿æŒ** | æ€§èƒ½åª²ç¾ä¸»æµåŸºäº ARMs çš„ Search Agentï¼ˆå¦‚ R1Searcherï¼‰ï¼Œæ— æ˜æ˜¾ç²¾åº¦æŸå¤± |
| **å¯æ§æ€§é«˜** | P-ReAct å‡ ä¹ä»¥ **100% æˆåŠŸç‡** ä¿è¯ `tool_call` è¢«ä¼˜å…ˆè§£ç  |
| **é€šç”¨æ€§å¼º** | æ–¹æ³•é€‚ç”¨äºå¤šç§ dLLM æ¶æ„ï¼ˆå¦‚ SDARï¼‰ï¼Œä¸”ä¸ä¾èµ–ç‰¹å®šè®­ç»ƒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

å››ä¸ªå¤šè·³é—®ç­”ï¼ˆmulti-hop QAï¼‰åŸºå‡†æ•°æ®é›†ç”¨äºè¯„ä¼°ï¼š

| æ•°æ®é›† | æè¿° |
|--------|------|
| **HotpotQA** | å¤šè·³äº‹å®æ¨ç†ï¼Œéœ€ä»å¤šä¸ªæ®µè½ä¸­æ•´åˆä¿¡æ¯ |
| **2WikiMultiHopQA** | åŸºäºç»´åŸºç™¾ç§‘çš„å¤æ‚å¤šè·³é—®é¢˜ |
| **Musique** | æ›´é•¿é“¾æ¡çš„å¤šè·³æ¨ç†ä»»åŠ¡ |
| **Bamboogle** | å«æœ‰å™ªå£°å¹²æ‰°çš„ç½‘é¡µæœç´¢ QA ä»»åŠ¡ï¼Œç”¨äºæµ‹è¯•æ³›åŒ–èƒ½åŠ› |

- æµ‹è¯•é›†ï¼šä»å‰ä¸‰è€…å¼€å‘é›†ä¸­å„é‡‡æ · 500 æ¡ï¼ŒBamboogle ä½¿ç”¨å…¨éƒ¨ 125 æ¡ã€‚
- è®­ç»ƒé›†ï¼šä» HotpotQAã€2Wikiã€Musique çš„è®­ç»ƒé›†ä¸­å…±é‡‡æ · 2048 æŸ¥è¯¢ï¼Œç”± Doubao-Seed-1.8 ç”Ÿæˆè½¨è¿¹ï¼Œç»è¿‡æ»¤åå¾— 3977 æ¡ç”¨äº Agentic SFTï¼›Agentic VRPO ä½¿ç”¨ R1Searcher å‘å¸ƒçš„ 8k Stage 2 æ•°æ®ç”Ÿæˆ 2237 ä¸ªèƒœ/è´Ÿå¯¹ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°æŒ‡æ ‡**

- **ACCRï¼ˆAccuracyï¼‰**ï¼šé¢„æµ‹ç­”æ¡ˆæ˜¯å¦åŒ…å«çœŸå®ç­”æ¡ˆï¼ˆgolden answerï¼‰
- **ACCLï¼ˆLLM-as-Judge Accuracyï¼‰**ï¼šä½¿ç”¨ Doubao-Seed-1.8 ä½œä¸ºè£åˆ¤æ¨¡å‹åˆ¤æ–­å›ç­”æ­£ç¡®æ€§ï¼Œæ›´é²æ£’åœ°å¤„ç†å†—é•¿è¾“å‡º

> æ³¨ï¼šä¸é‡‡ç”¨ EMï¼ˆExact Matchï¼‰å›  Agent è¾“å‡ºå¸¸å«è¡¥å……è¯´æ˜ï¼Œç²¾ç¡®åŒ¹é…ä¸åˆç†ã€‚

#### **ç¡¬ä»¶ä¸æ¨¡å‹é…ç½®**

- **Backbone**ï¼šSDARï¼ˆBlock Diffusion Language Modelï¼‰ï¼Œblock size = 128
- **æ£€ç´¢å·¥å…·**ï¼šGoogle Search APIï¼Œè¿”å› top-10 ç»“æœ
- **è®­ç»ƒå‚æ•°**ï¼š
  - Agentic SFTï¼šlr=1e-5, batch=32, 3 epochs
  - Agentic VRPOï¼šlr=5e-7, batch=16, 5 epochs
- **æ¨ç†é…ç½®**ï¼š128 denoising steps, temperature=1.0, confidence bias Î±=0.5

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

åˆ†ä¸ºä¸‰ç±»ï¼š

#### ï¼ˆ1ï¼‰ä¼ ç»Ÿ RAG æ–¹æ³•
- SuReã€Selective-Contextã€Adaptive-RAGã€IRCoTã€Iter-RetGenã€CR-Plannerã€ReARTeR

#### ï¼ˆ2ï¼‰åŸºäº ARMs çš„ Search Agent
- Search-o1ã€Search-R1ã€WebSailor*ã€R1Searcher*

#### ï¼ˆ3ï¼‰åŸºäº dLLMs çš„ Agentï¼ˆé¦–æ¬¡ç³»ç»Ÿè¯„ä¼°ï¼‰
- SDARï¼ˆvanillaï¼‰ã€Dreamã€LLaDA
- æ‰€æœ‰ dLLM å‡ä½¿ç”¨ Fast-dLLM åŠ é€Ÿæ¨ç†

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰**

| æ¨¡å‹ | Avg ACCR | Avg ACCL |
|------|----------|----------|
| **R1Searcher***ï¼ˆæœ€å¼º ARM baselineï¼‰ | 53.1 | 56.5 |
| **DLLM-Searcher**ï¼ˆæœ¬æ–‡æ–¹æ³•ï¼‰ | **57.0** | **56.6** |
| LLaDAï¼ˆåŸå§‹ dLLMï¼‰ | 34.9 | 32.5 |
| Dream | 10.1 | 10.1 |
| SDARï¼ˆæœªè®­ç»ƒï¼‰ | /ï¼ˆå®Œå…¨å¤±è´¥ï¼‰ | / |

> âœ… **DLLM-Searcher ä¸ä»…è¶…è¶Šæ‰€æœ‰åŸå§‹ dLLMï¼Œè¿˜å…¨é¢ä¼˜äº R1Searcherï¼Œåœ¨å¤šæ•°æ•°æ®é›†ä¸Šè¾¾åˆ° SOTA æ°´å¹³ã€‚**

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **vs. ä¼ ç»Ÿ RAG**ï¼šå¹³å‡ ACCR æå‡è¶… **37ä¸ªç™¾åˆ†ç‚¹**ï¼ˆå¦‚ ReARTeR ä¸º 45.4 â†’ DLLM-Searcher ä¸º 57.0ï¼‰
- **vs. ARM-based Agents**ï¼š
  - åœ¨ HotpotQAã€2Wikiã€Bamboogle ä¸Šå‡è¶…è¿‡ R1Searcher
  - ä»…åœ¨ Musique ä¸Šç•¥ä½ï¼ˆ29.0 vs 28.2ï¼‰ï¼Œä½†ä»å…·ç«äº‰åŠ›
- **vs. Vanilla dLLMs**ï¼šåŸå§‹ dLLMs å‡ ä¹æ— æ³•ç”Ÿæˆåˆæ³• `tool_call`ï¼Œè€Œ DLLM-Searcher æˆåŠŸç‡æ¥è¿‘ 100%

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **RQ1: ä¸¤é˜¶æ®µåè®­ç»ƒçš„æœ‰æ•ˆæ€§ï¼ˆTable 2ï¼‰**

| æ–¹æ³• | HotpotQA ACCR | 2Wiki ACCR | Bamboogle ACCR | Musique ACCR |
|------|----------------|-------------|------------------|---------------|
| Agentic SFT | 57.2 | 66.4 | 64.6 | 24.4 |
| Agentic VRPO | **60.4 (+3.2)** | **69.8 (+3.4)** | **68.8 (+4.2)** | **29.0 (+4.6)** |

âœ… VRPO åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šå¸¦æ¥ç¨³å®šå¢ç›Šï¼ˆ+3~5 ptsï¼‰ï¼ŒéªŒè¯å…¶å¯¹æ¨ç†è´¨é‡çš„æå‡ä½œç”¨ã€‚

#### **RQ2: P-ReAct çš„æ¨ç†æ•ˆç‡ï¼ˆFigure 3ï¼‰**

| æ•°æ®é›† | æ¨ç†æ—¶é—´å‡å°‘ |
|--------|--------------|
| HotpotQA | 14.77% |
| 2Wiki | 21.00% |
| Bamboogle | 22.08% |
| Musique | 12.67% |

â¡ï¸ **å¹³å‡çº¦ 15% çš„ç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½**ï¼Œä¸” ACCR/ACCL å‡ ä¹æ— æŸã€‚

#### **RQ3: dLLM çš„é¡ºåºè‡ªç”±ç”Ÿæˆä¼˜åŠ¿ï¼ˆFigure 4ï¼‰**

- å°† P-ReAct åº”ç”¨äº **Qwen3 ç³»åˆ— ARMs**ï¼ˆé€šè¿‡æç¤ºå·¥ç¨‹å¼ºåˆ¶å…ˆè¾“å‡º `tool_call`ï¼‰ï¼š
  - å¯¼è‡´æ˜¾è‘—æ€§èƒ½ä¸‹é™ï¼ˆæœ€å¤š -13.3%ï¼‰
- è€Œ **DLLM-Searcher + P-ReAct**ï¼š
  - åœ¨ HotpotQA å’Œ Musique ä¸Šç”šè‡³ç•¥æœ‰æå‡
  - æœ€å¤§é™å¹…ä»… 4.5%ï¼Œè¿œå°äº ARMs

ğŸ’¡ è¡¨æ˜ï¼š**dLLMs å¯åœ¨æœªæ˜¾å¼è§£ç â€œæ€è€ƒâ€å†…å®¹æ—¶ä»åˆ©ç”¨åŒå‘æ³¨æ„åŠ›éšå¼æ¨ç†ï¼Œç”Ÿæˆé«˜è´¨é‡å·¥å…·è°ƒç”¨**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **dLLMs å®Œå…¨å¯ä»¥èƒœä»» Search Agent è§’è‰²**ï¼Œå‰ææ˜¯ç»è¿‡é’ˆå¯¹æ€§çš„ agentic åè®­ç»ƒï¼ˆAgentic SFT + VRPOï¼‰ã€‚
2. **P-ReAct æ˜¯ä¸€ç§é«˜æ•ˆä¸”å…è®­ç»ƒçš„æ¨ç†èŒƒå¼**ï¼Œå……åˆ†åˆ©ç”¨ dLLM çš„éè‡ªå›å½’ç‰¹æ€§ï¼Œå®ç°â€œè¡ŒåŠ¨å‰æ€è€ƒâ€çš„å¹¶è¡ŒåŒ–ã€‚
3. **dLLMs åœ¨ç»“æ„æ§åˆ¶æ–¹é¢å…·æœ‰å¤©ç„¶ä¼˜åŠ¿**ï¼šå³ä½¿ `tool_call` å…ˆäº `think` è§£ç ï¼Œä¹Ÿèƒ½ä¿æŒé«˜è´¨é‡è¾“å‡ºï¼Œè€Œ ARMs ä¸¥é‡ä¾èµ– CoT çš„æ˜¾å¼è¡¨è¾¾ã€‚
4. **DLLM-Searcher å®ç°äº†æ€§èƒ½ä¸æ•ˆç‡çš„åŒèµ¢**ï¼šæ—¢è¾¾åˆ°ç”šè‡³è¶…è¶Šä¸»æµ ARM-based Agent çš„å‡†ç¡®ç‡ï¼Œåˆè·å¾—çº¦ 15% çš„æ¨ç†åŠ é€Ÿã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ–é«˜è´¨é‡æ•™å¸ˆæ¨¡å‹ç”Ÿæˆè®­ç»ƒæ•°æ®**ï¼šAgentic SFT éœ€è¦å¼º teacher modelï¼ˆå¦‚ Doubao-Seed-1.8ï¼‰æä¾›è½¨è¿¹ï¼Œå¯èƒ½é™åˆ¶å¯æ‰©å±•æ€§ã€‚
2. **å½“å‰ä»…æ”¯æŒå•æ¬¡å·¥å…·è°ƒç”¨ä¼˜å…ˆè§£ç **ï¼šP-ReAct åœ¨æ¯è½®è¿­ä»£ä¸­èšç„¦ä¸€ä¸ª `tool_call`ï¼Œå¯¹äºå¤æ‚å¤šå·¥å…·è°ƒåº¦åœºæ™¯æœ‰å¾…æ‰©å±•ã€‚
3. **è¯„ä¼°é›†ä¸­åœ¨è‹±æ–‡å¤šè·³ QA**ï¼šå°šæœªåœ¨å…¶ä»–è¯­è¨€æˆ–å¤šæ¨¡æ€ Agent åœºæ™¯ä¸­éªŒè¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ„å»ºè‡ªåŠ¨åŒ–çš„è½¨è¿¹åˆæˆ pipeline**ï¼Œå‡å°‘å¯¹äººå·¥æ ‡æ³¨æˆ–å¼º teacher çš„ä¾èµ–ã€‚
2. **å°† P-ReAct æ‰©å±•è‡³å¤šå·¥å…·ååŒè°ƒåº¦**ï¼Œæ”¯æŒæ›´å¤æ‚çš„ agentic workflowã€‚
3. **æ¢ç´¢ dLLM åœ¨å…¶ä»– Agent èŒƒå¼ä¸­çš„åº”ç”¨**ï¼Œå¦‚ Plan-and-Executeã€Tree-of-Thought ç­‰ã€‚
4. **ç»“åˆ RL è¿›ä¸€æ­¥ä¼˜åŒ– Agentic VRPO**ï¼Œå®ç°ç«¯åˆ°ç«¯å¥–åŠ±é©±åŠ¨çš„æœç´¢ç­–ç•¥å­¦ä¹ ã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **DLLM-Searcher æˆåŠŸå°† dLLMs ä»â€œä½æ•ˆå¼±æ™ºä½“â€è½¬å˜ä¸ºâ€œé«˜æ•ˆå¼ºæ™ºèƒ½â€ï¼Œä¸ä»…è§£å†³äº†å»¶è¿Ÿç“¶é¢ˆï¼Œæ›´è¯æ˜äº†æ‰©æ•£è¯­è¨€æ¨¡å‹ä½œä¸ºä¸‹ä¸€ä»£ Agent Backbone çš„å·¨å¤§æ½œåŠ›ã€‚**

</details>

---

### 6. [TEAM: Temporal-Spatial Consistency Guided Expert Activation for MoE Diffusion Language Model Acceleration](https://arxiv.org/abs/2602.08404)

**Authors**: Linye Wei, Zixiang Luo, Pingzhi Tang, Meng Li  
**Category**: cs.CL  
**Published**: 2026-02-10  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.08404v1  

#### Abstract
Diffusion large language models (dLLMs) have recently gained significant attention due to their inherent support for parallel decoding. Building on this paradigm, Mixture-of-Experts (MoE) dLLMs with autoregressive (AR) initialization have further demonstrated strong performance competitive with main...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTEAM: Temporal-Spatial Consistency Guided Expert Activation for MoE Diffusion Language Model Acceleration

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **MoE æ¶æ„åœ¨ dLLM ä¸­çš„æ¨ç†æ•ˆç‡ä½ä¸‹**ï¼šå°½ç®¡ Mixture-of-Experts (MoE) åœ¨è®­ç»ƒå’Œæ¨ç†ä¸­å…·æœ‰å‚æ•°ç¨€ç–æ¿€æ´»çš„ä¼˜åŠ¿ï¼Œä½†åœ¨ diffusion large language models (dLLMs) ä¸­ï¼Œç”±äºæ¯ä¸ª denoising step éƒ½éœ€å¯¹æ•´å— token å¹¶è¡Œå¤„ç†ï¼Œå¯¼è‡´å¤§é‡ä¸“å®¶è¢«æ¿€æ´»ï¼Œè€Œåªæœ‰å°‘æ•° token è¢«æ¥å—ï¼ˆunmaskedï¼‰ï¼Œé€ æˆä¸¥é‡çš„è®¡ç®—èµ„æºæµªè´¹ã€‚
- **ä¸“å®¶æ¿€æ´»ä¸ token æ¥å—ä¹‹é—´çš„ä¸åŒ¹é…**ï¼šä¼ ç»Ÿ MoE è®¾è®¡æœªè€ƒè™‘ dLLM çš„ block-wise å¹¶è¡Œè§£ç ç‰¹æ€§ï¼Œå¯¼è‡´å®é™…æ¿€æ´»çš„ä¸“å®¶æ•°é‡è¿œé«˜äºç†è®ºå€¼ï¼Œå‰Šå¼±äº†ç¨€ç–æ€§å¸¦æ¥çš„åŠ é€Ÿä¼˜åŠ¿ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šTEAM
æå‡º **TEAM**ï¼ˆTemporal-Spatial Consistency Guided Expert Activationï¼‰æ¡†æ¶ï¼Œé€šè¿‡åˆ©ç”¨ dLLM è§£ç è¿‡ç¨‹ä¸­çš„**æ—¶é—´ä¸€è‡´æ€§å’Œç©ºé—´ä¸€è‡´æ€§**ï¼Œå®ç°æ›´é«˜æ•ˆçš„ä¸“å®¶æ¿€æ´»ç­–ç•¥ã€‚å…·ä½“åŒ…æ‹¬ä¸‰ä¸ªäº’è¡¥æœºåˆ¶ï¼š

1. **Delayed Caching for Decoded Tokens (DCD)**  
   å¯¹å·²è§£ç çš„ token å»¶è¿Ÿç¼“å­˜å…¶ KV ç¼“å­˜ï¼Œä»…åœ¨é¦–æ¬¡æ¥å—åå‚ä¸ä¸€æ¬¡å‰å‘ä¼ æ’­ï¼Œåç»­è¿­ä»£ç›´æ¥å¤ç”¨ï¼Œé¿å…é‡å¤æ¿€æ´»æ— å…³ä¸“å®¶ã€‚

2. **Speculative Exploration for Hot Tokens (SEH)**  
   å°† masked token åˆ†ä¸ºâ€œçƒ­â€ï¼ˆlikely to be accepted soonï¼‰å’Œâ€œå†·â€ä¸¤ç±»ã€‚å¯¹ hot tokens è¿›è¡Œå¤šåˆ†æ”¯ speculative decodingï¼Œæå‡å•æ­¥ token æ¥å—ç‡ã€‚

3. **Limited Activation for Cold Tokens (LAC)**  
   å¯¹ cold tokens é‡‡ç”¨åŒè½®è·¯ç”±æœºåˆ¶ï¼šå…ˆåŸºäº hot å’Œæ–°è§£ç  token ç¡®å®šå¿…è¦ä¸“å®¶é›†åˆï¼Œå†å°† cold tokens é™åˆ¶åœ¨æ­¤å­é›†ä¸­è¿›è¡Œè·¯ç”±ï¼Œé˜²æ­¢å¼•å…¥é¢å¤–ä¸“å®¶å¼€é”€ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | TEAM çš„ä¼˜åŠ¿ |
|------|-------------|
| **é’ˆå¯¹æ€§å¼º** | æ˜¯é¦–ä¸ªä¸“é—¨åˆ†æ MoE dLLM ä¸­ expert activation è¡Œä¸ºçš„å·¥ä½œï¼Œæ­ç¤ºäº† temporal-spatial consistency ç‰¹æ€§ã€‚ |
| **æ— éœ€ç¡¬ä»¶æ”¹åŠ¨** | å®Œå…¨è½¯ä»¶å±‚é¢ä¼˜åŒ–ï¼Œå³æ’å³ç”¨ï¼ˆplug-and-playï¼‰ï¼Œé€‚ç”¨äºç°æœ‰ MoE dLLM æ¶æ„ã€‚ |
| **å…¼é¡¾æ€§èƒ½ä¸æ•ˆç‡** | åœ¨å‡ ä¹æ— æŸæ¨¡å‹å‡†ç¡®æ€§çš„å‰æä¸‹ï¼Œæ˜¾è‘—é™ä½ä¸“å®¶æ¿€æ´»æ•°å’Œæ¨ç†å»¶è¿Ÿã€‚ |
| **ä¼˜äºé€šç”¨åŠ é€Ÿæ–¹æ¡ˆ** | ä¸åŒäº dKV-Cache æˆ– dInfer ç­‰é€šç”¨ dLLM åŠ é€Ÿæ–¹æ³•ï¼ŒTEAM æ˜ç¡®é’ˆå¯¹ MoE ç»“æ„è®¾è®¡ï¼Œæ•ˆæœæ›´ä¼˜ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
åœ¨å››ä¸ªä¸»æµåŸºå‡†ä¸Šè¯„ä¼°æ€§èƒ½ï¼š
- **ä»£ç ç”Ÿæˆä»»åŠ¡**ï¼š
  - `HumanEval`ï¼ˆ0-shotï¼‰
  - `MBPP`ï¼ˆ0-shotï¼‰
- **æ•°å­¦æ¨ç†ä»»åŠ¡**ï¼š
  - `GSM8K`ï¼ˆ0-shotï¼‰
  - `Math-500`ï¼ˆ0-shotï¼‰

### âš™ï¸ å®éªŒè®¾ç½®
- **ä¸»æ¨¡å‹**ï¼š`SDAR 30B-A3B` â€”â€” ä¸€ä¸ªå…¸å‹çš„ MoE-based dLLMï¼Œé‡‡ç”¨ block diffusion èŒƒå¼ã€‚
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA A100 80GB GPUã€‚
- **å…³é”®è¶…å‚**ï¼š
  - Unmasking threshold: $ T = 0.95 $
  - Block size: 32 tokens
  - Hot token åˆ¤å®šæ ‡å‡†ï¼š$ c_k > 0.7 $ æˆ–è·ç¦»å·²è§£ç  token â‰¤ 3 ä½ç½®
  - Speculative branches: 4 æ¡å¹¶è¡Œåˆ†æ”¯
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - `APF`: Activated Experts Per Forward pass
  - `TPF`: Accepted Tokens Per Forward pass
  - `APT`: Activated Experts Per decoded Tokenï¼ˆç­‰æ•ˆæ¯ token æ¿€æ´»ä¸“å®¶æ•°ï¼‰
  - `Speedup`: ç›¸å¯¹äº vanilla æ¨¡å‹çš„ç«¯åˆ°ç«¯æ¨ç†é€Ÿåº¦æå‡å€æ•°
  - `Score`: ä»»åŠ¡å‡†ç¡®ç‡ï¼ˆPass@1ï¼‰

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Vanilla SDAR**ï¼šåŸå§‹ MoE dLLMï¼Œæ— ä»»ä½•ä¸“å®¶æ¿€æ´»ä¼˜åŒ–ã€‚
- **dKV-Cache**ï¼šå‘¨æœŸæ€§åˆ·æ–°å·²è§£ç  token çš„ KV ç¼“å­˜ï¼Œç”¨äºç¼“è§£ bidirectional attention ä¸‹çš„è¡¨ç¤ºæ¼‚ç§»ã€‚
- **dInfer**ï¼šé¢å‘äº‘éƒ¨ç½²çš„ MoE dLLM æ¨ç†æ¡†æ¶ï¼Œä¾§é‡ expert-parallel æ‰§è¡Œï¼Œéé’ˆå¯¹æ¿€æ´»æ•ˆç‡ä¼˜åŒ–ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š æ€»ä½“æ€§èƒ½å¯¹æ¯”ï¼ˆè§ Table 1ï¼‰

| Benchmark | Method | Score | APF â†“ | TPF â†‘ | APT â†“ | Speedup â†‘ |
|----------|--------|-------|--------|--------|--------|-----------|
| HumanEval | Vanilla | 79.27 | 53.34 | 2.91 | 18.33 | 1Ã— |
|           | **TEAM** | **79.88** (+0.61) | **34.48** (â†“35%) | **5.07** (â†‘1.74Ã—) | **6.80** (â†“63%) | **2.20Ã—** |
| MBPP      | Vanilla | 65.76 | 49.59 | 2.74 | 18.10 | 1Ã— |
|           | **TEAM** | **65.76** | **30.92** (â†“38%) | **4.56** (â†‘1.66Ã—) | **6.78** (â†“63%) | **2.08Ã—** |
| GSM8K     | Vanilla | 90.60 | 59.11 | 3.16 | 18.71 | 1Ã— |
|           | **TEAM** | **90.30** (-0.30) | **36.20** (â†“39%) | **4.79** (â†‘1.52Ã—) | **7.56** (â†“60%) | **1.83Ã—** |
| Math-500  | Vanilla | 76.00 | 57.90 | 3.74 | 15.48 | 1Ã— |
|           | **TEAM** | **75.40** (-0.60) | **36.31** (â†“37%) | **5.57** (â†‘1.49Ã—) | **6.52** (â†“58%) | **1.64Ã—** |
| **Average** | Vanilla | 77.91 | 54.99 | 3.14 | 17.66 | 1Ã— |
|           | **TEAM** | **77.84** (-0.07) | **34.48** (â†“37%) | **5.00** (â†‘1.59Ã—) | **6.92** (â†“61%) | **1.94Ã—** |

> âœ… **å…³é”®å‘ç°**ï¼š
> - TEAM å®ç°å¹³å‡ **1.94Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿ**ï¼Œæœ€é«˜è¾¾ **2.2Ã—**ï¼ˆHumanEvalï¼‰ã€‚
> - æ¯æ­¥æ¿€æ´»ä¸“å®¶æ•°å‡å°‘ **35â€“39%**ï¼ŒåŒæ—¶æ¥å— token æ•°æå‡ **1.49â€“1.74Ã—**ã€‚
> - å•ä¸ª token è§£ç æ‰€éœ€æ¿€æ´»ä¸“å®¶ä» ~17.66 é™è‡³ **6.92**ï¼Œç”šè‡³ä½äºåä¹‰è·¯ç”±æˆæœ¬ï¼ˆ8 experts/tokenï¼‰ã€‚

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆè§ Figure 5 å’Œ Table 2ï¼‰

#### ï¼ˆ1ï¼‰ç»„ä»¶æ¶ˆèï¼ˆé€æ­¥æ·»åŠ  TEAM æ¨¡å—ï¼‰
| é˜¶æ®µ | APT â†“ | Speedup â†‘ | è¯´æ˜ |
|------|--------|------------|------|
| Vanilla | 17.66 | 1Ã— | åŸºçº¿ |
| + SEH | ~12.5 | ~1.5Ã— | å¤šåˆ†æ”¯ speculative decoding æ˜¾è‘—æé«˜æ¥å—ç‡ |
| + DCD | ~8.3 | ~1.8Ã— | ç¼“å­˜å·²è§£ç  token æ˜æ˜¾å‡å°‘å†—ä½™ä¸“å®¶æ¿€æ´» |
| + LAC | **6.92** | **1.94Ã—** | å†· token é™æµè¿›ä¸€æ­¥å‹ç¼©ä¸“å®¶è°ƒç”¨ |

> â¡ï¸ ä¸‰è€…ååŒä½œç”¨æ˜æ˜¾ï¼ŒLAC åœ¨æœ€åé˜¶æ®µæä¾›è¾¹é™…å¢ç›Šã€‚

#### ï¼ˆ2ï¼‰ç¼“å­˜åˆ·æ–°ç­–ç•¥å¯¹æ¯”ï¼ˆTable 2ï¼‰
| Refresh Strategy | Avg Speedup | Avg Score |
|------------------|--------------|------------|
| Refresh every 4 steps | 1.29Ã— | 77.84 |
| Refresh every 8 steps | 1.38Ã— | 77.10 |
| **No refresh (Ours)** | **1.47Ã—** | **77.57** |

> â— å‘ç°ï¼š**æ— éœ€åˆ·æ–°ç¼“å­˜å³å¯ä¿æŒç²¾åº¦**ï¼Œä¸”æ•ˆç‡æ›´é«˜ â€”â€” æ”¯æŒâ€œrefresh-freeâ€è®¾è®¡çš„åˆç†æ€§ã€‚

#### ï¼ˆ3ï¼‰Hot Token è¶…å‚æ•æ„Ÿæ€§åˆ†æï¼ˆTable 3ï¼‰
- æœ€ä½³é…ç½®ï¼š$ T_h = 0.7, L_h = 3 $
- æ›´å®½æ¾ï¼ˆå¦‚ $ T_h=0.4 $ï¼‰ä¼šè½»å¾®æå‡åˆ†æ•°ä½†å¢åŠ  APFï¼›æ›´ä¸¥æ ¼åˆ™å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
- å½“å‰è®¾å®šåœ¨ **accuracy-efficiency trade-off ä¸Šæœ€ä¼˜**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **MoE + dLLM å­˜åœ¨æ ¹æœ¬æ€§æ•ˆç‡çŸ›ç›¾**ï¼šè™½ç„¶ä¸¤è€…å„è‡ªé«˜æ•ˆï¼Œä½†ç®€å•ç»“åˆä¼šå¯¼è‡´ä¸“å®¶æ¿€æ´»è¿‡åº¦ï¼Œç ´åç¨€ç–æ€§ä¼˜åŠ¿ã€‚
2. **dLLM å…·æœ‰å¼º temporal-spatial consistency**ï¼š
   - æ—¶é—´ç»´åº¦ï¼šå·²è§£ç  token è¡¨ç¤ºç¨³å®šï¼Œå¯å®‰å…¨ç¼“å­˜ï¼›
   - ç©ºé—´ç»´åº¦ï¼šmasked token è·¯ç”±é«˜åº¦é›†ä¸­ï¼Œé€‚åˆå…±äº«ä¸“å®¶ï¼›
   - å±€éƒ¨æ€§ï¼šacceptance order å‘ˆç°è¿‘ä¼¼ autoregressive è¶‹åŠ¿ï¼Œæ”¯æŒ hot/cold åˆ’åˆ†ã€‚
3. **TEAM æˆåŠŸèåˆç¨€ç–æ€§ä¸å¹¶è¡Œæ€§**ï¼šé€šè¿‡å·®å¼‚åŒ–ä¸“å®¶è°ƒåº¦ï¼Œåœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹å¤§å¹…æå‡æ¨ç†æ•ˆç‡ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ– autoregressive åˆå§‹åŒ–æ¨¡å‹**ï¼šTEAM çš„æœ‰æ•ˆæ€§éƒ¨åˆ†å»ºç«‹åœ¨ dLLM ç»§æ‰¿ AR prior çš„åŸºç¡€ä¸Šï¼Œè‹¥åˆå§‹åŒ–æ–¹å¼ä¸åŒå¯èƒ½å½±å“ hot token åˆ¤æ–­ã€‚
- **è¶…å‚æ•°æ•æ„Ÿæ€§å­˜åœ¨è¾¹ç•Œ**ï¼šè™½ç„¶ $ T_h=0.7, L_h=3 $ è¡¨ç°æœ€ä½³ï¼Œä½†æç«¯ä»»åŠ¡ä¸‹å¯èƒ½éœ€è¦é‡æ–°è°ƒä¼˜ã€‚
- **æœªæ‰©å±•è‡³å¤šæ¨¡æ€ dLLM**ï¼šå½“å‰éªŒè¯é›†ä¸­åœ¨æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼Œæ˜¯å¦é€‚ç”¨äº vision-language diffusion model å¾…æ¢ç´¢ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å°† TEAM æ€è·¯æ¨å¹¿è‡³å…¶ä»– MoE-based dLLMï¼ˆå¦‚ LLaDA 2.0ï¼‰æˆ–æ›´å¤§è§„æ¨¡æ¨¡å‹ã€‚
- åŠ¨æ€è°ƒæ•´ hot token åˆ¤å®šé˜ˆå€¼ï¼ŒåŸºäºä¸Šä¸‹æ–‡è‡ªé€‚åº”åˆ’åˆ†ã€‚
- ç»“åˆç¡¬ä»¶æ„ŸçŸ¥è°ƒåº¦ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–ä¸“å®¶é€šä¿¡ä¸å†…å­˜è®¿é—®æ¨¡å¼ã€‚
- æ¢ç´¢åœ¨ training é˜¶æ®µå¼•å…¥ consistency-aware routingï¼Œå¢å¼º inference å¯é¢„æµ‹æ€§ã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> TEAM é¦–æ¬¡æ­ç¤ºäº† MoE dLLM ä¸­çš„ä¸“å®¶æ¿€æ´»ä½æ•ˆé—®é¢˜ï¼Œå¹¶æå‡ºä¸€ç§åŸºäº **temporal-spatial consistency** çš„ç²¾ç»†åŒ–ä¸“å®¶è°ƒåº¦æ¡†æ¶ï¼Œåœ¨å‡ ä¹é›¶ç²¾åº¦æŸå¤±ä¸‹å®ç°äº†é«˜è¾¾ **2.2Ã— çš„æ¨ç†åŠ é€Ÿ**ï¼Œä¸º MoE ä¸ diffusion æ¶æ„çš„æ·±åº¦èåˆæä¾›äº†é«˜æ•ˆå¯è¡Œè·¯å¾„ã€‚

ğŸ”— å¼€æºåœ°å€ï¼š[https://github.com/PKU-SEC-Lab/TEAM-MoE-dLLM](https://github.com/PKU-SEC-Lab/TEAM-MoE-dLLM)

</details>

---

### 7. [Parallel Track Transformers: Enabling Fast GPU Inference with Reduced Synchronization](https://arxiv.org/abs/2602.07306)

**Authors**: Chong Wang, Nan Du, Tom Gunter, Tao Lei, Kulin Seth, Senyu Tong, Jianyu Wang, Guoli Yin, Xiyou Zhou, Kelvin Zou, Ruoming Pang  
**Category**: cs.DC  
**Published**: 2026-02-10  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.07306v1  

#### Abstract
Efficient large-scale inference of transformer-based large language models (LLMs) remains a fundamental systems challenge, frequently requiring multi-GPU parallelism to meet stringent latency and throughput targets. Conventional tensor parallelism decomposes matrix operations across devices but intr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šParallel Track Transformers: Enabling Fast GPU Inference with Reduced Synchronization

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨åŸºäº Transformer çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¤§è§„æ¨¡æ¨ç†ä¸­ï¼Œ**å¤š GPU å¹¶è¡Œè®¡ç®—**è™½ç„¶èƒ½æå‡ååé‡å’Œé™ä½å»¶è¿Ÿï¼Œä½†ä¼ ç»Ÿçš„ **tensor parallelism** å¼•å…¥äº†é¢‘ç¹çš„è·¨ GPU åŒæ­¥æ“ä½œï¼ˆå¦‚ all-reduceï¼‰ï¼Œå¯¼è‡´é€šä¿¡ç“¶é¢ˆï¼Œé™åˆ¶äº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§å’Œæ¨ç†æ•ˆç‡ã€‚

éšç€æ¨¡å‹è§„æ¨¡å¢é•¿ï¼Œè¿™äº›åŒæ­¥å¼€é”€æˆä¸ºåˆ¶çº¦ LLM æ¨ç†æ€§èƒ½çš„å…³é”®å› ç´ ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šParallel Track (PT) Transformer
ä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„æ¶æ„èŒƒå¼â€”â€”**Parallel Track (PT) Transformer**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- å°†æ•´ä¸ªæ¨¡å‹åˆ’åˆ†ä¸ºå¤šä¸ªç‹¬ç«‹å¹¶è¡Œè¿è¡Œçš„å­ Transformer å®ä¾‹ï¼Œç§°ä¸ºâ€œ**tracks**â€ã€‚
- æ¯ä¸ª track åœ¨è‹¥å¹²å±‚ï¼ˆå®šä¹‰ä¸ºä¸€ä¸ª track blockï¼Œæ·±åº¦ä¸º $D$ï¼‰å†…ç‹¬ç«‹è®¡ç®—ï¼Œä»…åœ¨ block ç»“æŸæ—¶è¿›è¡Œä¸€æ¬¡è·¨ track çš„åŒæ­¥ï¼ˆall-reduceï¼‰ã€‚
- è¿™ç§è®¾è®¡æ˜¾è‘—å‡å°‘äº†åŒæ­¥æ¬¡æ•°ï¼Œå¹¶é™ä½äº†æ¯æ¬¡åŒæ­¥çš„æ•°æ®é‡ï¼ˆå› æ¯ track ç»´åº¦æ›´ä½ï¼‰ã€‚

è¯¥æ–¹æ³•è¢«ç§°ä¸º **track parallelism**ï¼Œæ˜¯ä¸€ç§ç³»ç»Ÿå±‚é¢é©±åŠ¨çš„å¹¶è¡Œç­–ç•¥ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | ä¼ ç»Ÿ Tensor Parallelism | PT Transformer |
|--------|------------------------|---------------|
| åŒæ­¥é¢‘ç‡ | æ¯ä¸€å±‚éƒ½éœ€åŒæ­¥ â†’ $2L$ æ¬¡ï¼ˆæ³¨æ„åŠ› + FFNï¼‰ | æ¯ $D$ å±‚åŒæ­¥ä¸€æ¬¡ â†’ $L/D$ æ¬¡ |
| åŒæ­¥æ•°æ®é‡ | å…¨ç»´åº¦æ¿€æ´»å€¼äº¤æ¢ | åˆ†å‰²åçš„ä½ç»´ track è¾“å‡º |
| é€šä¿¡æ¨¡å¼ | é«˜é¢‘ã€å°æ‰¹é‡é€šä¿¡ï¼Œæ˜“é€ æˆé˜»å¡ | ä½é¢‘ã€è§„å¾‹æ€§å¼ºï¼Œåˆ©äºä¼˜åŒ– |
| å¯é›†æˆæ€§ | å·²å¹¿æ³›ä½¿ç”¨ä½†å—é™äºé€šä¿¡ç“¶é¢ˆ | å¯æ— ç¼é›†æˆåˆ° TensorRT-LLM å’Œ vLLM |

> â­ æœ€é«˜å®ç° **16Ã— çš„åŒæ­¥æ“ä½œå‡å°‘**ï¼ˆå½“ $D=8$ æ—¶ï¼ŒåŒæ­¥å‡å°‘ 93.75%ï¼‰

æ­¤å¤–ï¼ŒPT ä¸åŒäº MoEï¼š
- MoE æ˜¯ token-level è·¯ç”±ï¼Œå¼•å…¥åŠ¨æ€è´Ÿè½½ä¸å‡ï¼›
- PT æ˜¯æ‰€æœ‰ token å¤„ç†æ‰€æœ‰ tracksï¼ŒåŒæ­¥èŠ‚å¥å›ºå®šï¼Œæ›´é€‚åˆé«˜æ•ˆæ¨ç†è°ƒåº¦ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•ï¼ˆBenchmarksï¼‰
åœ¨ä»¥ä¸‹ä¸»æµè¯„æµ‹é›†ä¸Šè¯„ä¼°æ¨¡å‹è´¨é‡ï¼š
- **ARC-C/E**, **HellaSwag**, **PIQA**, **SciQ**, **WinoGrande**ï¼šå¸¸è¯†æ¨ç†
- **TriviaQA (EM)**ï¼šé—®ç­”å‡†ç¡®ç‡
- **MMLU (EM)**ï¼šå¤šä»»åŠ¡è¯­è¨€ç†è§£
- **GSM8K (EM)**, **MATH (EM)**ï¼šæ•°å­¦æ¨ç†
- **HumanEval (Pass@1)**ï¼šä»£ç ç”Ÿæˆèƒ½åŠ›

---

### âš™ï¸ å®éªŒè®¾ç½®
#### æ¨¡å‹é…ç½®
- æ¨¡å‹å¤§å°ï¼š**6B, 13B, 30B** å‚æ•°
- Tracks æ•°é‡ï¼šç»Ÿä¸€è®¾ä¸º **n = 8**
- Track block depth $D$ï¼šæµ‹è¯• $D = 2, 4, 8$
- ä½¿ç”¨ **Grouped Query Attention (GQA)**
- æ‰€æœ‰æ¨¡å‹é¢„è®­ç»ƒ token æ•°ä¸€è‡´ï¼ˆ6B: 800Bï¼›13B/30B: 400Bï¼‰
- Dense ä¸ PT æ¨¡å‹é‡‡ç”¨ç›¸åŒè®­ç»ƒæµç¨‹ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒ

#### æ¨ç†æœåŠ¡æ ˆæµ‹è¯•ç¯å¢ƒ
- ç¡¬ä»¶å¹³å°ï¼š**8Ã—H100 GPUs**
- æµ‹è¯•æ¡†æ¶ï¼š
  - **TensorRT-LLM**
  - **vLLM**
- æµ‹è¯•æ¨¡å¼ï¼š
  - **Throughput Mode**ï¼šæœ€å¤§ batch size = 256ï¼Œè¡¡é‡è¾“å‡ºååï¼ˆtokens/secï¼‰
  - **Latency Mode**ï¼šbatch size = 1ï¼Œæµ‹é‡ï¼š
    - **TTFT**ï¼ˆTime to First Tokenï¼‰
    - **TPOT**ï¼ˆTime Per Output Tokenï¼‰

#### åŸºçº¿æ–¹æ³•
- æ ‡å‡† dense Transformerï¼ˆæ—  track åˆ†å‰²ï¼‰
- ä¸åŒ $D$ çš„ PT å˜ä½“ä½œä¸ºæ¶ˆèå®éªŒå¯¹ç…§

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š æ¨¡å‹æ€§èƒ½ï¼ˆè´¨é‡ä¿æŒï¼‰
å°½ç®¡åŒæ­¥å¤§å¹…å‡å°‘ï¼ŒPT æ¨¡å‹åœ¨å¤šæ•°ä»»åŠ¡ä¸Šä¿æŒä¸ dense æ¨¡å‹ç›¸å½“ç”šè‡³æ›´ä¼˜çš„è¡¨ç°ï¼š

| æ¨¡å‹ | æœ€å¤§åŒæ­¥å‡å°‘ | æ€§èƒ½å˜åŒ–è¶‹åŠ¿ |
|------|-------------|------------|
| **6B** | 93.75% ($D=8$) | MMLU æ˜æ˜¾ä¸‹é™ï¼ˆ0.56 â†’ 0.36ï¼‰ï¼Œå°æ¨¡å‹æ•æ„Ÿ |
| **13B** | åŒä¸Š | å‡ ä¹æ— æŸï¼Œéƒ¨åˆ†æŒ‡æ ‡åè¶…ï¼ˆå¦‚ ARC-C æå‡è‡³ 0.538ï¼‰ |
| **30B** | åŒä¸Š | æ•´ä½“ç¨³å®šï¼ŒMMLU å¾®é™ï¼ˆ0.63 â†’ 0.615ï¼‰ï¼Œå…¶ä»–æŒå¹³æˆ–ç•¥å‡ |

> âœ… **ç»“è®ºï¼šå¤§æ¨¡å‹å¯¹ PT æ¶æ„å®¹å¿åº¦æ›´é«˜ï¼Œå¯åœ¨å‡ ä¹ä¸æŸå¤±æ€§èƒ½å‰æä¸‹æå¤§å‰Šå‡åŒæ­¥**

---

### â±ï¸ æ¨ç†æ•ˆç‡æå‡ï¼ˆå…³é”®æŒ‡æ ‡ï¼‰

#### åœ¨ **TensorRT-LLM** ä¸Šçš„ç»“æœï¼š
| æŒ‡æ ‡ | æ”¹è¿›å¹…åº¦ |
|------|---------|
| **TTFT**ï¼ˆæœ€é•¿è¾“å…¥ 63488ï¼‰ | â†“ **14.7%**ï¼ˆ1697ms â†’ 1437msï¼‰ |
| **TPOT**ï¼ˆå…¸å‹åœºæ™¯ï¼‰ | â†“ **2â€“12%** |
| **Throughput**ï¼ˆæœ€é«˜ï¼‰ | â†‘ **up to 31.9%**ï¼ˆå¦‚ 1024 in / 128 out åœºæ™¯ï¼‰ |

#### åœ¨ **vLLM** ä¸Šçš„ç»“æœï¼š
| æŒ‡æ ‡ | æ”¹è¿›å¹…åº¦ |
|------|---------|
| **TTFT**ï¼ˆæœ€é•¿è¾“å…¥ 63488ï¼‰ | â†“ **~17.7%**ï¼ˆ2981ms â†’ 2453msï¼‰ |
| **TPOT**ï¼ˆé•¿ä¸Šä¸‹æ–‡ï¼‰ | â†“ **~2â€“5%** |
| **Throughput** | â†‘ **up to ~20%**ï¼ˆçŸ­åºåˆ—åœºæ™¯æ˜æ˜¾ï¼‰ |

> ğŸ’¡ æ³¨ï¼šæŸäº›é•¿è¾“å‡ºåœºæ™¯ï¼ˆå¦‚ 1024â†’4096ï¼‰å‡ºç°è½»å¾®å›é€€ï¼Œå¯èƒ½ç”±äº kernel è°ƒåº¦æœªå®Œå…¨ä¼˜åŒ–ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœ
- **$D=2$ vs $D=8$**ï¼š
  - $D=8$ åŒæ­¥æœ€å°‘ï¼Œé€šä¿¡å¼€é”€æœ€ä½ï¼Œä½†å¯¹å°æ¨¡å‹ï¼ˆ6Bï¼‰å½±å“è¾ƒå¤§ã€‚
  - å¯¹ 13B/30B æ¨¡å‹ï¼Œ$D=8$ ä»èƒ½ç»´æŒé«˜è´¨é‡ï¼Œè¯´æ˜ **block depth å¯å®‰å…¨æ‰©å¤§ä»¥æ¢å–æ€§èƒ½å¢ç›Š**ã€‚
- **Track æ•°é‡é€‰æ‹©ï¼ˆn=8ï¼‰**ï¼š
  - åŒ¹é…å¸¸è§å¤šå¡éƒ¨ç½²ï¼ˆå¦‚ 8Ã—H100ï¼‰ï¼Œä¾¿äºå·¥ç¨‹è½åœ°ã€‚
  - æ›´å¤š tracks å¯è¿›ä¸€æ­¥é™ä½å• track ç»´åº¦ï¼Œä½†éœ€æƒè¡¡å†…å­˜ä¸é€šä¿¡æ‹“æ‰‘ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **åŒæ­¥æ˜¯ LLM æ¨ç†çš„å…³é”®ç“¶é¢ˆ**ï¼Œå°¤å…¶æ˜¯åœ¨ tensor parallelism ä¸‹é«˜é¢‘ all-reduce æ“ä½œã€‚
2. **PT Transformer æˆåŠŸå°†åŒæ­¥ä»æ¯å±‚ä¸€æ¬¡é™è‡³æ¯ $D$ å±‚ä¸€æ¬¡**ï¼Œæœ€å¤šå‡å°‘ **16Ã— åŒæ­¥æ¬¡æ•°**ã€‚
3. åœ¨ **13B åŠä»¥ä¸Šè§„æ¨¡æ¨¡å‹ä¸­ï¼ŒPT å¯åœ¨å‡ ä¹ä¸å½±å“æ¨¡å‹è´¨é‡çš„å‰æä¸‹å¤§å¹…æå‡æ¨ç†æ•ˆç‡**ã€‚
4. PT æ¶æ„å·²æˆåŠŸé›†æˆè‡³ä¸¤å¤§ä¸»æµæ¨ç†æ¡†æ¶ï¼ˆ**TensorRT-LLM**, **vLLM**ï¼‰ï¼Œå®æµ‹è·å¾—ï¼š
   - **15â€“30% TTFT é™ä½**
   - **2â€“12% TPOT é™ä½**
   - **æœ€é«˜è¾¾ 31.9% ååæå‡**
5. PT ä¸ MoE æ­£äº¤ï¼Œåç»­å·¥ä½œ **PT-MoE** è¡¨æ˜äºŒè€…å¯ç»“åˆï¼Œåœ¨ç§æœ‰äº‘åœºæ™¯ä¸­å…·æœ‰åº”ç”¨å‰æ™¯ï¼ˆè§ Apple Foundation Models 2025 æŠ¥å‘Šï¼‰ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **å°æ¨¡å‹ï¼ˆå¦‚ 6Bï¼‰æ€§èƒ½æ³¢åŠ¨è¾ƒæ˜æ˜¾**ï¼Œå°¤å…¶åœ¨ MMLU ç­‰å¤æ‚ä»»åŠ¡ä¸Šéš $D$ å¢å¤§è€Œä¸‹é™ã€‚
2. å½“å‰å®ç°ä¾èµ–å®šåˆ¶åŒ–æ”¯æŒï¼ˆå¦‚å†…éƒ¨ç‰ˆ TensorRT-LLMï¼‰ï¼Œå¼€æºç”Ÿæ€å°šæœªæ™®åŠã€‚
3. æç«¯é•¿åºåˆ—è¾“å‡ºåœºæ™¯ä¸‹ï¼Œæ€§èƒ½å¢ç›Šè¶‹äºé¥±å’Œç”šè‡³ç•¥æœ‰å›é€€ï¼Œéœ€è¿›ä¸€æ­¥ä¼˜åŒ–è°ƒåº¦å™¨ã€‚
4. track é—´å®Œå…¨å‡åŒ€åˆ’åˆ†å‡è®¾è¾ƒå¼ºï¼Œå®é™…ä¸­å¯èƒ½å­˜åœ¨è´Ÿè½½ç»†å¾®ä¸å¹³è¡¡ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **è‡ªé€‚åº” block depth æ§åˆ¶**ï¼šæ ¹æ®è¾“å…¥é•¿åº¦æˆ–ä»»åŠ¡ç±»å‹åŠ¨æ€è°ƒæ•´åŒæ­¥é¢‘ç‡ã€‚
2. **æ··åˆå¹¶è¡Œç­–ç•¥è®¾è®¡**ï¼šå°† track parallelism ä¸ pipeline / data / expert parallelism æ›´æ·±åº¦èåˆã€‚
3. **ç¡¬ä»¶æ„ŸçŸ¥çš„ track åˆ†å¸ƒä¼˜åŒ–**ï¼šè€ƒè™‘ NVLink æ‹“æ‰‘ã€å¸¦å®½å·®å¼‚ç­‰ç‰©ç†è¿æ¥ç‰¹æ€§ã€‚
4. **æ‰©å±•è‡³è®­ç»ƒé˜¶æ®µ**ï¼šæ¢ç´¢ track parallelism åœ¨è®­ç»ƒä¸­çš„æ½œåŠ›ï¼Œæå‡è®­ç»ƒæ•ˆç‡ä¸å®¹é”™æ€§ã€‚
5. **è½»é‡åŒ– PT æ¶æ„ç”¨äºè¾¹ç¼˜è®¾å¤‡**ï¼šç ”ç©¶ä½ track æ•°ï¼ˆå¦‚ n=2~4ï¼‰ä¸‹çš„ç§»åŠ¨ç«¯é€‚ç”¨æ€§ã€‚

---

## âœ… æ€»ç»“ä¸€å¥è¯
> **Parallel Track Transformer é€šè¿‡é‡æ„æ¨¡å‹ç»“æ„ï¼Œå°†é«˜é¢‘åŒæ­¥å‹ç¼©ä¸ºå‘¨æœŸæ€§èåˆæ“ä½œï¼Œåœ¨å‡ ä¹ä¸ç‰ºç‰²æ¨¡å‹æ€§èƒ½çš„å‰æä¸‹ï¼Œå®ç°äº†é«˜è¾¾ 31.9% çš„ååæå‡å’Œæ˜¾è‘—é™ä½çš„ TTFT/TPOTï¼Œä¸ºé«˜æ€§èƒ½ LLM æ¨ç†æä¾›äº†å…¨æ–°çš„ç³»ç»Ÿå‹å¥½å‹æ¶æ„è·¯å¾„ã€‚**

</details>

---

### 8. [DLLM Agent: See Farther, Run Faster](https://arxiv.org/abs/2602.07451)

**Authors**: Huiling Zhen, Weizhe Lin, Renxi Liu, Kai Han, Yiming Li, Yuchuan Tian, Hanting Chen, Xiaoguang Li, Xiaosong Li, Chen Chen, Xianzhi Yu, Mingxuan Yuan, Youliang Yan, Peifeng Qin, Jun Wang, Yu Wang, Dacheng Tao, Yunhe Wang  
**Category**: cs.CL  
**Published**: 2026-02-10  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.07451v1  

#### Abstract
Diffusion large language models (DLLMs) have emerged as an alternative to autoregressive (AR) decoding with appealing efficiency and modeling properties, yet their implications for agentic multi-step decision making remain underexplored. We ask a concrete question: when the generation paradigm is ch...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDLLM Agent: See Farther, Run Faster

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§å¤šæ•° **LLM Agent** ç ”ç©¶é»˜è®¤ **autoregressive (AR)** è§£ç æ˜¯å”¯ä¸€ç”ŸæˆèŒƒå¼ï¼Œè®¤ä¸º agent è¡Œä¸ºä¸»è¦ç”±è®­ç»ƒæ•°æ®å’Œ workflow è®¾è®¡å†³å®šï¼Œè€Œå¿½ç•¥äº† **generation paradigmï¼ˆç”ŸæˆèŒƒå¼ï¼‰æœ¬èº«æ˜¯å¦ç³»ç»Ÿæ€§å½±å“ agent çš„å†³ç­–è¡Œä¸º**ã€‚  
æœ¬æ–‡æå‡ºä¸€ä¸ªæ ¹æœ¬æ€§é—®é¢˜ï¼š  
> å½“ agent æ¡†æ¶å’Œç›‘ç£ä¿¡å·ä¿æŒä¸å˜æ—¶ï¼Œä»…å°†ç”ŸæˆèŒƒå¼ä» AR æ”¹ä¸º **Diffusion LLM (DLLM)**ï¼Œæ˜¯å¦ä¼šå¼•å‘ç³»ç»Ÿæ€§çš„è§„åˆ’ä¸å·¥å…·ä½¿ç”¨è¡Œä¸ºå·®å¼‚ï¼Ÿè¿™äº›å·®å¼‚èƒ½å¦è½¬åŒ–ä¸ºç«¯åˆ°ç«¯æ•ˆç‡æå‡ï¼Ÿ

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
- **é¦–æ¬¡ç³»ç»Ÿç ”ç©¶ diffusion èŒƒå¼åœ¨å¤šæ­¥ agent å†³ç­–ä¸­çš„ä½œç”¨**ï¼Œæ„å»ºäº†åŸºäº DLLM çš„ **DLLM Agent**ã€‚
- åœ¨ç›¸åŒçš„ **DeepDiver å¤šæ™ºèƒ½ä½“æ¡†æ¶** å’Œ **agent-oriented fine-tuning æ•°æ®** ä¸‹ï¼Œå¯¹ AR å’Œ DLLM èƒŒéª¨è¿›è¡Œå…¬å¹³æ¯”è¾ƒï¼Œæ§åˆ¶å˜é‡ä»¥éš”ç¦»ç”ŸæˆèŒƒå¼çš„å½±å“ã€‚
- æå‡ºä¸¤é¡¹å…³é”®æŠ€æœ¯æ”¹è¿›ä»¥é€‚é…å¤šè½® agent åœºæ™¯ï¼š
  - **Context-clean corruption**ï¼šåªå¯¹åŠ¨ä½œæ®µï¼ˆaction spanï¼‰åŠ å™ªï¼Œä¿ç•™ä¸Šä¸‹æ–‡å®Œæ•´ï¼Œé¿å…è®­ç»ƒ-æ¨ç†ä¸ä¸€è‡´ã€‚
  - **Span-aware attention alignment**ï¼šè°ƒæ•´ attention maskï¼Œé˜²æ­¢ context ä¸ action ä¹‹é—´çš„è™šå‡åŒå‘ä¿¡æ¯æµåŠ¨ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´é«˜çš„å…¨å±€è§„åˆ’èƒ½åŠ›**ï¼šDLLM é€šè¿‡è¿­ä»£å»å™ªå®ç°éšå¼å…¨å±€åè°ƒï¼Œèƒ½æ›´æ—©æ”¶æ•›åˆ°æ­£ç¡®è¡ŒåŠ¨è·¯å¾„ï¼Œå‡å°‘å›æº¯ã€‚
- **æ›´å°‘å†—ä½™äº¤äº’**ï¼šç›¸æ¯” AR agent çš„å±€éƒ¨å¢é‡å†³ç­–ï¼ŒDLLM agent æ›´å€¾å‘äºä¸€æ¬¡æ€§åˆ¶å®šå®Œæ•´è®¡åˆ’ï¼Œå‡å°‘é‡å¤å·¥å…·è°ƒç”¨å’Œæ¨ç†æ­¥éª¤ã€‚
- **ç«¯åˆ°ç«¯é€Ÿåº¦æ˜¾è‘—æå‡**ï¼šåœ¨ç›¸åŒå‡†ç¡®ç‡ä¸‹ï¼Œå¹³å‡æé€Ÿè¶…è¿‡ 30%ï¼Œæç«¯æ¡ˆä¾‹å¯è¾¾ **8Ã— åŠ é€Ÿ**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **BrowseComp-zh**ï¼šä¸€ä¸ªå¤šè½®ä¸­æ–‡ç½‘é¡µæµè§ˆåŸºå‡†ï¼Œè¦æ±‚æ¨¡å‹é€šè¿‡å¤šæ¬¡æ£€ç´¢ã€æ¨ç†åŠ¨æ€è¯æ®æ¥å›ç­”å¤æ‚æŸ¥è¯¢ï¼Œå¤©ç„¶äº§ç”Ÿé•¿äº¤äº’å†å²ã€‚
- **Open-ended qualitative prompts**ï¼šä¸€ç»„è‡ªå®šä¹‰çš„å¼€æ”¾å¼å¤šæ­¥ç ”ç©¶é—®é¢˜ï¼Œç”¨äºå®šæ€§åˆ†æ agent çš„æ¢ç´¢ç­–ç•¥ã€è¯æ®æ•´åˆä¸ç»ˆæ­¢è¡Œä¸ºã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
#### ç»Ÿä¸€ agent æ¡†æ¶
æ‰€æœ‰ agent å‡è¿è¡Œäº **DeepDiver** æ¡†æ¶ä¸­ï¼ŒåŒ…å« Plannerã€Information Seeker å’Œ Writer è§’è‰²ï¼Œæ”¯æŒ thinkã€reflectã€web_searchã€document_qa ç­‰å·¥å…·ã€‚

#### æ§åˆ¶å˜é‡
- ç›¸åŒçš„å·¥å…·é›†ã€API æ¥å£ã€prompt æ¨¡æ¿ã€çŠ¶æ€åºåˆ—åŒ–æ–¹å¼
- ç›¸åŒçš„è®­ç»ƒæ•°æ®è½¨è¿¹ï¼ˆæ¥è‡ª AR agent çš„ rolloutï¼‰
- ç›¸åŒçš„ä¼˜åŒ–é¢„ç®—ï¼ˆ5 epochs, lr 5e-6 åˆ° 0ï¼‰
- ç›¸åŒçš„äº¤äº’é™åˆ¶ï¼š
  - æœ€å¤§ context é•¿åº¦ï¼š32K tokens
  - æœ€å¤§å›åˆæ•° $ T_{\text{max}} = 15 $
  - æœ€å¤§ ToolCall æ¬¡æ•°é™åˆ¶

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Accuracy (%)** | æœ€ç»ˆç­”æ¡ˆæ­£ç¡®ç‡ |
| **Tool Calls â†“** | å¹³å‡æ¯ episode å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ |
| **Turns Used â†“** | å¹³å‡ä½¿ç”¨å›åˆæ•°ï¼ˆåæ˜ äº¤äº’é•¿åº¦ï¼‰ |
| **Invalid Action Rate â†‘** | åŠ¨ä½œæ ¼å¼é”™è¯¯æ¯”ä¾‹ï¼ˆå¦‚ schema é”™è¯¯ã€ç¼ºå¤±åˆ†éš”ç¬¦ï¼‰ |
| **End-to-end Latency â†“** | å®Œæˆä»»åŠ¡çš„æ€»è€—æ—¶ï¼ˆç§’ï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **AR Agent** | ä½¿ç”¨ `openPangu-Embedded-7B` ä½œä¸º backboneï¼Œæ ‡å‡† AR è§£ç  |
| **DLLM Agent** | ä½¿ç”¨ `openPangu-R-7B-Diffusion`ï¼Œé‡‡ç”¨è¿­ä»£å»å™ªç”ŸæˆåŠ¨ä½œ |
| **æ¶ˆèå˜ä½“** | ç§»é™¤ context-clean corruption æˆ– span-aware attention alignment çš„ç‰ˆæœ¬ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 å’Œ Figure 2ï¼‰

| Method | Accuracy (%) | Tool Calls | Turns Used | Invalid Action Rate |
|--------|---------------|------------|-------------|------------------------|
| AR Agent | 15.5 | 7.5 | 14.8 | 1.9% |
| DLLM Agent | 15.5 | **6.7** | **13.0** | **6.4%** |
| w/o context-clean corruption | 14.5 | 6.8 | 15.0 | 6.2% |
| w/o span-aware attention | 14.5 | 7.1 | 14.6 | 7.1% |

> æ³¨ï¼šå‡†ç¡®ç‡æŒå¹³ï¼Œä½† DLLM Agent æ˜¾è‘—å‡å°‘å·¥å…·è°ƒç”¨ï¼ˆâ†“10.7%ï¼‰å’Œå›åˆæ•°ï¼ˆâ†“12.2%ï¼‰ï¼Œä½“ç°æ›´é«˜æ•ˆç‡ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç«¯åˆ°ç«¯å»¶è¿Ÿå¤§å¹…é™ä½**ï¼š
  - åœ¨â€œæŸ¥æ‰¾ç¬¦åˆå¤šä¸ªçº¦æŸçš„ç§‘æŠ€å…¬å¸â€ä»»åŠ¡ä¸Šï¼ŒDLLM Agent è€—æ—¶ **140.95s**ï¼ŒAR Agent è€—æ—¶ **1152.68s** â†’ **8.18Ã— åŠ é€Ÿ**
  - åœ¨â€œæ’°å†™ç‰¹æ–¯æ‹‰è´¢æŠ¥æŠ•èµ„æŠ¥å‘Šâ€ä»»åŠ¡ä¸Šï¼ŒDLLM Agent è€—æ—¶ **490.25s**ï¼ŒAR Agent è€—æ—¶ **715.31s** â†’ **1.46Ã— åŠ é€Ÿï¼ˆå³å¿« 31.5%ï¼‰**
- **æ›´ç®€æ´çš„æ‰§è¡Œè½¨è¿¹**ï¼š
  - DLLM Agent æ›´å°‘åˆ›å»ºä¸­é—´è®¡åˆ’æ–‡ä»¶ï¼ˆå¦‚ todo_v1.md, todo_v2.mdï¼‰
  - æ›´å°‘å‘èµ·å¹¶è¡Œæœç´¢ä»»åŠ¡ï¼Œä½†æ¯æ¬¡ä»»åŠ¡ç›®æ ‡æ›´æ˜ç¡®
- **æ›´é«˜çš„ planner hit rate**ï¼šæ›´æ—©é”å®šæ­£ç¡®æ–¹æ¡ˆï¼Œå‡å°‘æ— æ•ˆæ¢ç´¢

### æ¶ˆèå®éªŒç»“æœ
- ç§»é™¤ä»»ä¸€ masking æŠ€æœ¯ï¼ˆcontext-clean corruption æˆ– span-aware attentionï¼‰å‡å¯¼è‡´ï¼š
  - å‡†ç¡®ç‡ä¸‹é™çº¦ 1%
  - å›åˆæ•°å¢åŠ 
  - æ€§èƒ½é€€åŒ–ï¼ŒéªŒè¯äº†ä¸¤ç§ masking å¯¹é½è®­ç»ƒä¸æ¨ç†åˆ†å¸ƒçš„é‡è¦æ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **ç”ŸæˆèŒƒå¼æœ¬èº«æ˜¾è‘—å½±å“ agent è¡Œä¸º**  
   å³ä½¿ workflow å’Œè®­ç»ƒæ•°æ®å®Œå…¨ç›¸åŒï¼ŒDLLM ä¸ AR agent å±•ç°å‡ºæœ¬è´¨ä¸åŒçš„å†³ç­–æ¨¡å¼ï¼š
   - **DLLM Agent**ï¼šå…¨å±€è§†è§’å¼ºï¼Œå…ˆå»ºç«‹é«˜é˜¶è®¡åˆ’å†å¡«å……ç»†èŠ‚ï¼Œè¡¨ç°ä¸ºâ€œcontract-drivenâ€æ‰§è¡Œã€‚
   - **AR Agent**ï¼šå±€éƒ¨æ¡ä»¶ä¾èµ–å¼ºï¼Œé€æ­¥æ¨è¿›ï¼Œæ˜“å‡ºç°å†—ä½™éªŒè¯å’Œå›æº¯ã€‚

2. âœ… **æ•ˆç‡ä¼˜åŠ¿ä¸ä»…æ¥è‡ª token å¹¶è¡Œæ€§**  
   DLLM çš„åŠ é€Ÿä¸ä»…æ˜¯ç”±äºå¹¶è¡Œè§£ç ï¼Œæ›´æ˜¯å› ä¸ºå…¶ **workflow-level æ•ˆç‡æå‡**ï¼š
   - æ›´å°‘çš„å·¥å…·è°ƒç”¨
   - æ›´çŸ­çš„äº¤äº’é“¾
   - æ›´å°‘çš„ä¸­é—´ artifact ç”Ÿæˆ

3. âœ… **DLLM å…·å¤‡æ›´å¼ºçš„å…¨å±€åè°ƒèƒ½åŠ›**  
   æ³¨æ„åŠ›åŠ¨æ€åˆ†ææ˜¾ç¤ºï¼ŒDLLM åœ¨æ—©æœŸé˜¶æ®µå°±è¡¨ç°å‡ºè·¨å—çš„å…¨å±€æ³¨æ„åŠ›ï¼Œæ”¯æŒâ€œå…ˆçœ‹è¿œï¼Œå†åŠ¨æ‰‹â€çš„è§„åˆ’é£æ ¼ã€‚

4. âš ï¸ **éƒ¨ç½²æŒ‘æˆ˜ä¾ç„¶å­˜åœ¨**  
   - DLLM è¾“å‡ºç»“æ„åŒ–åŠ¨ä½œï¼ˆå¦‚ ToolCallï¼‰çš„ç¨³å®šæ€§è¾ƒå·®ï¼ˆinvalid action rate è¾ƒé«˜ï¼‰ï¼Œéœ€åŠ å¼ºé’ˆå¯¹ tool-call çš„ä¸“é¡¹è®­ç»ƒã€‚
   - å¤šè½®åœºæ™¯ä¸‹çš„è®­ç»ƒ-æ¨ç†ä¸ä¸€è‡´é—®é¢˜å¿…é¡»é€šè¿‡ masking å¯¹é½è§£å†³ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å®éªŒé›†ä¸­åœ¨ **deep research-type ä»»åŠ¡**ï¼ˆä¿¡æ¯æ£€ç´¢+ç»¼åˆï¼‰ï¼Œå°šæœªéªŒè¯åœ¨é•¿æœŸè§„åˆ’ã€å…·èº«ç¯å¢ƒæˆ–å¤æ‚é€»è¾‘æ¨ç†ä¸­çš„æ³›åŒ–æ€§ã€‚
- æ‰€æœ‰ DLLM è®­ç»ƒä»åŸºäº AR agent çš„è½¨è¿¹æ•°æ®ï¼Œæœªå¼•å…¥ diffusion-native çš„ curriculum æˆ–ç›‘ç£ä¿¡å·ã€‚
- å½“è¾“å‡ºæ–‡æœ¬é‡å¾ˆå¤§æ—¶ï¼ˆå¦‚é•¿ç¯‡æŠ¥å‘Šï¼‰ï¼ŒDLLM çš„æ•ˆç‡ä¼˜åŠ¿ä¼šè¢«ç¨€é‡Šã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ¢ç´¢ diffusion-native agent è®­ç»ƒèŒƒå¼**ï¼šè®¾è®¡ä¸“é—¨é¢å‘è¿­ä»£ refine çš„ç›‘ç£ç›®æ ‡æˆ–è¯¾ç¨‹å­¦ä¹ ã€‚
2. **æ··åˆæ¶æ„ï¼ˆHybrid Agentsï¼‰**ï¼šç»“åˆ DLLM çš„å…¨å±€è§„åˆ’èƒ½åŠ›å’Œ AR çš„ç²¾ç»†æ‰§è¡Œèƒ½åŠ›ï¼Œæ„å»º dual-path agentã€‚
3. **æ‰©å±•è‡³æ›´å¤æ‚åœºæ™¯**ï¼šæµ‹è¯•åœ¨è½¯ä»¶å·¥ç¨‹ã€æœºå™¨äººæ§åˆ¶ç­‰é•¿è§†é‡ã€éƒ¨åˆ†å¯è§‚æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚
4. **æ·±å…¥æœºåˆ¶åˆ†æ**ï¼šé€šè¿‡å› æœå¹²é¢„ã€æ³¨æ„åŠ›å½’å› ç­‰æ‰‹æ®µè¿›ä¸€æ­¥æ­ç¤º backbone ç‰¹æ€§å¦‚ä½•å¡‘é€  agent è¡Œä¸ºã€‚
5. **æå‡ç»“æ„åŒ–è¾“å‡ºå¯é æ€§**ï¼šå¼€å‘é’ˆå¯¹ ToolCall schema çš„çº¦æŸè§£ç æˆ–æ ¡éªŒæœºåˆ¶ï¼Œé™ä½ invalid action rateã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬è®ºæ–‡è¯æ˜äº† **Diffusion LLM ä¸ä»…æ˜¯ä¸€ç§æ›´å¿«çš„ç”Ÿæˆå™¨ï¼Œæ›´æ˜¯ä¸€ç§å…·å¤‡â€œå‰ç»æ€§æ€ç»´â€çš„ agent èƒŒéª¨**ï¼Œèƒ½åœ¨ç›¸åŒæ¡ä»¶ä¸‹å®ç°â€œçœ‹å¾—æ›´è¿œã€è·‘å¾—æ›´å¿«â€çš„æ™ºèƒ½å†³ç­–ã€‚

</details>

---

### 9. [FEM-Informed Hypergraph Neural Networks for Efficient Elastoplasticity](https://arxiv.org/abs/2602.07364)

**Authors**: Jianchuan Yang, Xi Chen, Jidong Zhao  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.07364v1  

#### Abstract
Graph neural networks (GNNs) naturally align with sparse operators and unstructured discretizations, making them a promising paradigm for physics-informed machine learning in computational mechanics. Motivated by discrete physics losses and Hierarchical Deep Learning Neural Network (HiDeNN) construc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFEM-Informed Hypergraph Neural Networks for Efficient Elastoplasticity

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **Physics-Informed Neural Networks (PINNs)** åœ¨æ±‚è§£éçº¿æ€§ **elastoplasticity** é—®é¢˜æ—¶é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **è®¡ç®—æˆæœ¬é«˜**ï¼šä¾èµ– Automatic Differentiation (AD) å¯¼è‡´è®¡ç®—å›¾åºå¤§ï¼Œè®­ç»ƒæ•ˆç‡ä½ã€‚
- **ç²¾åº¦ä¸è¶³**ï¼šåœ¨å¤æ‚å‡ ä½•ã€å¾ªç¯åŠ è½½ï¼ˆcyclic loadingï¼‰ã€ææ–™ç¡¬åŒ–ï¼ˆhardeningï¼‰ç­‰åœºæ™¯ä¸‹é¢„æµ‹è¯¯å·®å¤§ã€‚
- **è¾¹ç•Œæ¡ä»¶å¤„ç†å›°éš¾**ï¼šDirichlet å’Œ Neumann è¾¹ç•Œæ¡ä»¶éš¾ä»¥æœ‰æ•ˆæ–½åŠ ï¼Œæ˜“å¯¼è‡´æ¢¯åº¦å¤±è¡¡ã€‚
- **é»‘ç®±å»ºæ¨¡**ï¼šç½‘ç»œä½œä¸ºé»‘ç›’ä»£ç†ï¼Œç¼ºä¹ç‰©ç†å¯è§£é‡Šæ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
ä½œè€…æå‡ºäº†ä¸€ç§ **FEM-Informed Hypergraph Neural Network (FHGNN)**ï¼Œå…¶æ ¸å¿ƒæ˜¯å°† **æœ‰é™å…ƒæ³• (FEM)** çš„è®¡ç®—æµç¨‹åµŒå…¥åˆ° **Hypergraph Neural Network** çš„æ¶ˆæ¯ä¼ é€’å±‚ä¸­ï¼Œæ„å»ºä¸€ä¸ª**ç‰©ç†ä¸€è‡´ã€å¯å¾®åˆ†ã€ç™½ç›’å¼çš„æ±‚è§£å™¨**ã€‚

#### åˆ›æ–°ç‚¹ï¼š
- **Nodeâ€“Element Hypergraph è¡¨ç¤º**ï¼šé‡‡ç”¨è¶…å›¾ç»“æ„è¡¨ç¤º FEM ç½‘æ ¼ï¼Œå…¶ä¸­èŠ‚ç‚¹ï¼ˆnodesï¼‰ä»£è¡¨ç½‘æ ¼èŠ‚ç‚¹ï¼Œå…ƒç´ ï¼ˆelementsï¼‰ä½œä¸ºç¬¬äºŒç±»èŠ‚ç‚¹ï¼Œé€šè¿‡æœ‰å‘è¾¹è¿æ¥èŠ‚ç‚¹ä¸æ‰€å±å…ƒç´ ï¼Œè‡ªç„¶ç¼–ç äº† FEM çš„æ‹“æ‰‘å…³ç³»ã€‚
- **FEM è®¡ç®—å†…åµŒäº Message Passing**ï¼š
  - **Isoparametric Transformation Layer**ï¼šåœ¨æ¶ˆæ¯ä¼ é€’ä¸­å®ç°åæ ‡å˜æ¢ä¸å½¢å‡½æ•°æ¢¯åº¦è®¡ç®—ã€‚
  - **Strainâ€“Stress Layer**ï¼šåŸºäºä½ç§»åœºè®¡ç®—åº”å˜ä¸åº”åŠ›ï¼Œæ”¯æŒ J2 plasticity æ¨¡å‹ï¼ˆå« isotropic/kinematic hardeningï¼‰ã€‚
  - **Global Internal Force Layer**ï¼šå®ç°å•å…ƒå†…åŠ›ç»„è£…ï¼Œå½¢æˆå…¨å±€å†…åŠ›å‘é‡ã€‚
- **ç«¯åˆ°ç«¯å¯å¾®åˆ†æ¡†æ¶**ï¼šæ•´ä¸ªæµç¨‹æ”¯æŒåå‘ä¼ æ’­ï¼Œå…è®¸ä¼˜åŒ–ä»»æ„è¾“å…¥å±æ€§ï¼ˆå¦‚èŠ‚ç‚¹åæ ‡ï¼‰ï¼Œå®ç° **r-adaptivity**ã€‚
- **æ— éœ€æ ‡ç­¾æ•°æ®**ï¼šè®­ç»ƒå®Œå…¨ç”±ç‰©ç†é©±åŠ¨ï¼Œä»…éœ€è¾“å…¥ç½‘æ ¼ï¼Œæ— ç›‘ç£å­¦ä¹ ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿ PINN / PIMLP / PIGCN | FHGNN |
|------|--------------------------|--------|
| **è®¡ç®—æ•ˆç‡** | é«˜é˜¶ AD å¯¼è‡´è®¡ç®—å›¾å¤æ‚ï¼Œè®­ç»ƒæ…¢ | åˆ©ç”¨ FEM å½¢å‡½æ•°æ¢¯åº¦ï¼Œç¨€ç–å±€éƒ¨è®¡ç®—ï¼ŒGPU å¹¶è¡ŒåŠ é€Ÿ |
| **ç²¾åº¦** | ä½ç§»å°šå¯ï¼Œä½†åº”åŠ›/å¡‘æ€§åº”å˜è¯¯å·®å¤§ | åº”åŠ›ã€åº”å˜ã€å¡‘æ€§å˜é‡å‡é«˜åº¦å‡†ç¡® |
| **è¾¹ç•Œå¤„ç†** | éœ€é¢å¤–æŸå¤±é¡¹ï¼Œæ˜“æ¢¯åº¦å¤±è¡¡ | Dirichlet æ¡ä»¶é€šè¿‡æ©ç ç›´æ¥æ–½åŠ ï¼ŒNeumann è‡ªç„¶èå…¥å˜åˆ†æŸå¤± |
| **å¯æ‰©å±•æ€§** | éš¾ä»¥å¤„ç†å¤æ‚å‡ ä½•ä¸éç»“æ„åŒ–ç½‘æ ¼ | å¤©ç„¶æ”¯æŒéç»“æ„åŒ–ç½‘æ ¼ä¸å¤æ‚å‡ ä½• |
| **ç‰©ç†ä¸€è‡´æ€§** | é»‘ç®±æ¨¡å‹ï¼Œæ“ä½œä¸å¯è§£é‡Š | ç™½ç›’æ¨¡å‹ï¼Œæ¯ä¸€æ­¥å¯¹åº” FEM ç‰©ç†æ“ä½œ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸é—®é¢˜è®¾ç½®
æ‰€æœ‰å®éªŒå‡ä½¿ç”¨ **Abaqus** ç”Ÿæˆçš„ FEM è§£ä½œä¸ºå‚è€ƒçœŸå€¼ï¼Œå…±è®¾è®¡ **5 ä¸ª 3D å¼¹å¡‘æ€§åŸºå‡†é—®é¢˜**ï¼š
1. **3D Plastic Footing**ï¼šå¹³é¢åº”å˜åŸºç¡€æ¿ï¼Œå®Œç¾å¡‘æ€§ von Mises æ¨¡å‹ã€‚
2. **3D Linear Hardening Cantilever Beam**ï¼šå« **isotropic hardening** ä¸ **kinematic hardening** çš„æ‚¬è‡‚æ¢ï¼ŒéªŒè¯å¾ªç¯åŠ è½½å“åº”ã€‚
3. **3D Linear Hardening Workpiece**ï¼šå¤æ‚å‡ ä½•å·¥ä»¶ï¼Œæµ‹è¯•å¯¹éè§„åˆ™å½¢çŠ¶çš„é€‚åº”èƒ½åŠ›ã€‚
4. **3D Bi-material Plate with a Hole**ï¼šåŒææ–™å¸¦å­”æ¿ï¼ŒéªŒè¯å¯¹ææ–™ä¸è¿ç»­æ€§çš„æ•æ‰èƒ½åŠ›ã€‚
5. **2D Plastic Footing with Cyclic Loading**ï¼šäºŒç»´å¾ªç¯åŠ è½½æ¡ˆä¾‹ï¼Œç”¨äºå¯¹æ¯”ä¼ ç»Ÿ PINNã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶**ï¼šFHGNN åœ¨ **NVIDIA RTX 4090 GPU** ä¸Šè¿è¡Œï¼›FEM åŸºçº¿åœ¨ **Intel i7-12700H CPU** ä¸Šè¿è¡Œã€‚
- **ä¼˜åŒ–å™¨**ï¼šç»Ÿä¸€ä½¿ç”¨ **L-BFGS**ï¼Œåˆå§‹æ­¥é•¿ 1.0ã€‚
- **è¾“å…¥**ï¼šFHGNN è¾“å…¥ä¸º nodeâ€“element hypergraphï¼ŒåŒ…å«èŠ‚ç‚¹åæ ‡ã€å½¢å‡½æ•°æ¢¯åº¦ã€ä½ç§»ç­‰ã€‚
- **è¾“å‡º**ï¼šèŠ‚ç‚¹ä½ç§» $ u_j $ã€é«˜æ–¯ç‚¹åº”å˜ $ \varepsilon_i $ã€åº”åŠ› $ \sigma_i $ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **Relative L2 Error**ï¼š$ L_2 = \frac{\|u - u^*\|_2}{\|u^*\|_2} $
- **Mean Absolute Error (MAE)**ï¼š$ \text{MAE} = \frac{1}{N}\sum |u - u^*| $
- **è®­ç»ƒæ—¶é—´ (Time)**ï¼šæ”¶æ•›è‡³ç›®æ ‡ç²¾åº¦æ‰€éœ€æ—¶é—´ã€‚
- **æ”¶æ•›è¿­ä»£æ¬¡æ•°**ï¼šè¾¾åˆ°æ”¶æ•›æ‰€éœ€çš„ä¼˜åŒ–æ­¥æ•°ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **PINN**ï¼šä¼ ç»Ÿå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰+ AD + PDE æ®‹å·®æŸå¤±ã€‚
- **PIMLP**ï¼šMLP é¢„æµ‹ä½ç§»ï¼Œä½¿ç”¨ FEM å½¢å‡½æ•°æ¢¯åº¦æ„é€ èƒ½é‡æŸå¤±ï¼ˆå¦‚ [26,31]ï¼‰ã€‚
- **PIGCN**ï¼šå›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰å­¦ä¹ ä»åæ ‡åˆ°ä½ç§»çš„æ˜ å°„ï¼Œä½¿ç”¨ Chebyshev å·ç§¯ï¼ˆå¦‚ [24,25]ï¼‰ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| ä»»åŠ¡ | æ–¹æ³• | Time (s) | $ L_2(u_x) $ | $ L_2(u_y) $ | MAE($ \bar{\varepsilon}_p $) |
|------|------|----------|---------------|---------------|-------------------------------|
| **3D Plastic Footing** | PIMLP | 210.47 | 1.85E-01 | 6.52E-02 | 2.50E-3 |
| | PIGCN | 452.08 | 1.28E-01 | 3.38E-02 | 2.10E-3 |
| | **FHGNN** | **125.23** | **8.06E-03** | **2.40E-03** | **8.62E-05** |
| **3D Cantilever Beam (Isotropic)** | PIMLP | 737.6 | â€” | â€” | â€” |
| | PIGCN | 2,520.6 | â€” | â€” | â€” |
| | **FHGNN** | **145.51** | 4.80E-04 | 3.19E-04 | 6.10E-06 |
| **3D Workpiece** | PIMLP | 98.42 | â€” | â€” | 1.02E-05 |
| | PIGCN | 169.71 | â€” | â€” | 2.94E-05 |
| | **FHGNN** | **52.13** | â€” | â€” | **1.90E-07** |
| **Bi-material Plate** | PIMLP | 108.14 | 8.89E-02 | 7.07E-01 | 1.47E-03 |
| | PIGCN | 201.49 | 5.31E-02 | 3.05E-01 | 6.61E-04 |
| | **FHGNN** | **59.80** | **5.78E-05** | **1.77E-04** | **1.38E-06** |

### å¯¹æ¯”ç»“æœ
- **é€Ÿåº¦ä¼˜åŠ¿**ï¼šFHGNN åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå®ç° **2â€“3 å€ä»¥ä¸ŠåŠ é€Ÿ**ï¼Œåœ¨ç¨ å¯†ç½‘æ ¼ä¸‹ç”šè‡³å¿«äºå¤šæ ¸ FEMã€‚
- **ç²¾åº¦ä¼˜åŠ¿**ï¼šç›¸æ¯” PIMLP å’Œ PIGCNï¼ŒFHGNN çš„é¢„æµ‹è¯¯å·®**é™ä½ä¸¤ä¸ªæ•°é‡çº§ä»¥ä¸Š**ï¼Œå°¤å…¶åœ¨åº”åŠ›å’Œå¡‘æ€§åº”å˜åœºè¡¨ç°ä¼˜å¼‚ã€‚
- **æ”¶æ•›æ€§**ï¼šFHGNN æ”¶æ•›æ›´å¿«ï¼Œä¸”æ›´ç¨³å®šã€‚

### æ¶ˆèå®éªŒä¸å…³é”®å‘ç°
#### ï¼ˆ1ï¼‰**èƒ½é‡æŸå¤± vs. Galerkin æŸå¤±**
- **èƒ½é‡æŸå¤± (Energy Loss)**ï¼šæ¨èä½¿ç”¨ï¼Œæ”¶æ•›å¿«ã€ç²¾åº¦é«˜ã€å¯¹ç½‘æ ¼å¯†åº¦é²æ£’ã€‚
- **Galerkin æŸå¤±**ï¼šåœ¨ç»†ç½‘æ ¼ä¸‹**éš¾ä»¥æ”¶æ•›**ï¼Œè¯¯å·®éšç½‘æ ¼åŠ å¯†è€Œå¢å¤§ï¼ˆè§ Fig. 26ï¼‰ã€‚
- **ç†è®ºè§£é‡Š**ï¼šGalerkin æŸå¤±çš„ Hessian çŸ©é˜µæ¡ä»¶æ•° $ \kappa(K^TK) = \kappa(K)^2 $ï¼Œè¿œå¤§äºèƒ½é‡æŸå¤±çš„ $ \kappa(K) $ï¼Œå¯¼è‡´ä¼˜åŒ–ç—…æ€ã€‚

#### ï¼ˆ2ï¼‰**FEM å½¢å‡½æ•°æ¢¯åº¦ vs. AD**
- FEM å½¢å‡½æ•°æ¢¯åº¦ä¸º**ç¨€ç–ã€å±€éƒ¨ã€é¢„è®¡ç®—å¸¸æ•°**ï¼Œé¿å…äº† AD çš„é«˜é˜¶å¯¼æ•°è®¡ç®—ã€‚
- ä½ç§»æ¢¯åº¦è®¡ç®—ä»…æ¶‰åŠå•å…ƒå†…å°‘æ•°èŠ‚ç‚¹ï¼Œè€Œéå…¨ç½‘ç»œå‚æ•°ï¼Œæ˜¾è‘—æå‡æ•ˆç‡ã€‚

#### ï¼ˆ3ï¼‰**Transfer Learning åŠ é€Ÿ**
- åˆ©ç”¨ç²—ç½‘æ ¼è§£ã€ä¸åŒææ–™/è½½è·ä¸‹çš„è§£ä½œä¸ºåˆå€¼ï¼Œå¯è¿›ä¸€æ­¥åŠ é€Ÿæ”¶æ•›ï¼ˆè§ Fig. 24ï¼‰ã€‚

#### ï¼ˆ4ï¼‰**Mesh Adaptivity**
- å°†èŠ‚ç‚¹åæ ‡ $ v_j $ è®¾ä¸ºå¯ä¼˜åŒ–å˜é‡ï¼Œå®ç° **r-adaptivity**ï¼šç½‘æ ¼è‡ªåŠ¨åœ¨é«˜æ¢¯åº¦åŒºåŠ å¯†ï¼Œä½æ¢¯åº¦åŒºç¨€ç–åŒ–ï¼Œç³»ç»Ÿèƒ½é‡è¿›ä¸€æ­¥é™ä½ï¼ˆä» -6.322 â†’ -6.328ï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **FHGNN æ˜¾è‘—ä¼˜äºç°æœ‰ PINN å˜ä½“**ï¼šåœ¨ç²¾åº¦ã€æ•ˆç‡ã€æ”¶æ•›æ€§æ–¹é¢å…¨é¢é¢†å…ˆï¼Œå°¤å…¶é€‚ç”¨äºå¤æ‚å‡ ä½•ã€éçº¿æ€§å¼¹å¡‘æ€§é—®é¢˜ã€‚
2. **FEM å†…åµŒæœºåˆ¶æ˜¯å…³é”®**ï¼šå°† FEM è®¡ç®—æµç¨‹åµŒå…¥ GNN æ¶ˆæ¯ä¼ é€’ï¼Œå®ç°äº†**ç‰©ç†å¯è§£é‡Šæ€§**ä¸**è®¡ç®—é«˜æ•ˆæ€§**çš„ç»Ÿä¸€ã€‚
3. **èƒ½é‡æŸå¤±æœ€ä¼˜**ï¼šå¯¹äºå­˜åœ¨èƒ½é‡æ³›å‡½çš„ææ–™ï¼ˆå¦‚ J2 plasticityï¼‰ï¼Œ**variational energy loss** æ˜¯é¦–é€‰ï¼Œæ”¶æ•›æ›´å¿«æ›´ç¨³ã€‚
4. **GPU å¹¶è¡Œæ½œåŠ›å·¨å¤§**ï¼šåœ¨ç¨ å¯†ç½‘æ ¼ä¸‹ï¼ŒFHGNN å¯è¶…è¶Šå¤šæ ¸ CPU FEMï¼Œå…·å¤‡å¤§è§„æ¨¡åº”ç”¨å‰æ™¯ã€‚
5. **æ”¯æŒè‡ªé€‚åº”ä¼˜åŒ–**ï¼šæ¡†æ¶å¤©ç„¶æ”¯æŒ r-adaptivity ä¸å‚æ•°è”åˆä¼˜åŒ–ï¼Œä¸ºæ™ºèƒ½ä»¿çœŸæä¾›æ–°è·¯å¾„ã€‚

### å±€é™æ€§
- å½“å‰ä»…æ”¯æŒ **closed-form J2 plasticity** æ¨¡å‹ï¼Œå¤æ‚å±ˆæœé¢ï¼ˆyield surfaceï¼‰çš„èƒ½é‡æ³›å‡½éš¾æ¨å¯¼ã€‚
- è¶…å›¾ç»“æ„ä¸æ¶ˆæ¯ä¼ é€’è®¾è®¡ä¾èµ– FEM å…ˆéªŒï¼Œé€šç”¨æ€§å—é™äºå·²æœ‰æ•°å€¼æ–¹æ³•ã€‚
- å¯¹æç«¯éçº¿æ€§æˆ–åŠ¨æ€æ–­è£‚ç­‰é—®é¢˜å°šæœªéªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³ä¸€èˆ¬å¡‘æ€§æ¨¡å‹**ï¼šå¼€å‘å…¼å®¹ AD çš„é€šç”¨å›æ˜ ç®—æ³•ï¼ˆreturn mappingï¼‰ï¼Œæ”¯æŒä»»æ„å±ˆæœå‡†åˆ™ã€‚
2. **å¤šç‰©ç†åœºè€¦åˆ**ï¼šé›†æˆ DEMï¼ˆé¢—ç²’ææ–™ï¼‰ã€FVMï¼ˆæµä½“åŠ›å­¦ï¼‰ç­‰æ¨¡å—ï¼Œæ„å»ºç»Ÿä¸€å¯å¾®åˆ†æ¡†æ¶ã€‚
3. **Operator Learning ç»“åˆ**ï¼šèåˆ FNOã€DeepONet ç­‰ç®—å­å­¦ä¹ æ–¹æ³•ï¼Œè§£å†³å¤šå°ºåº¦é—®é¢˜ã€‚
4. **æ•°æ®åŒåŒ–**ï¼šå¼•å…¥å®éªŒæ•°æ®è¿›è¡Œæ ¡å‡†ä¸éªŒè¯ã€‚
5. **å­¦ä¹ æ›´ä¼˜æ¶ˆæ¯ä¼ é€’æ¨¡å—**ï¼šä»å¤§æ•°æ®ä¸­å­¦ä¹ æ¯”æ ‡å‡† FEM æ›´é«˜æ•ˆçš„ message-passing æ“ä½œã€‚
6. **Preconditioning æŠ€æœ¯**ï¼šæ”¹å–„ Galerkin æŸå¤±çš„æ”¶æ•›æ€§ï¼Œæå‡å…¶é€‚ç”¨èŒƒå›´ã€‚

> **æ€»ä½“è¯„ä»·**ï¼šè¯¥å·¥ä½œæˆåŠŸå°† **FEM çš„ç‰©ç†ä¸¥è°¨æ€§** ä¸ **GNN çš„è®¡ç®—çµæ´»æ€§** ç›¸ç»“åˆï¼Œæå‡ºäº†ä¸€ç§**å¯æ‰©å±•ã€é«˜æ•ˆã€ç™½ç›’åŒ–**çš„ç‰©ç†é©±åŠ¨å­¦ä¹ èŒƒå¼ï¼Œä¸ºéçº¿æ€§å›ºä½“åŠ›å­¦çš„ä¸‹ä¸€ä»£ä»¿çœŸå·¥å…·å¥ å®šäº†åšå®åŸºç¡€ã€‚

</details>

---

### 10. [Towards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective](https://arxiv.org/abs/2602.08009)

**Authors**: Rui Li, Zeyu Zhang, Xiaohe Bo, Quanyu Dai, Chaozhuo Li, Feng Wen, Xu Chen  
**Category**: cs.AI  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.08009v1  

#### Abstract
Multi-agent architectures built on large language models (LLMs) have demonstrated the potential to realize swarm intelligence through well-crafted collaboration. However, the substantial burden of manual orchestration inherently raises an imperative to automate the design of agentic workflows. We fr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTowards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰åŸºäº **Large Language Model (LLM)** çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆ**Multi-Agent System, MAS**ï¼‰åœ¨åè°ƒæœºåˆ¶ä¸Šå­˜åœ¨ä¸‰å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼š

- **Adaptivityï¼ˆé€‚åº”æ€§ï¼‰ä¸è¶³**ï¼šä¼ ç»Ÿæ–¹æ³•ä¾èµ–é¢„è®¾çš„é™æ€æ‹“æ‰‘ï¼ˆå¦‚é“¾å¼ã€æ˜Ÿå‹ç»“æ„ï¼‰ï¼Œæ— æ³•æ ¹æ®æ¨ç†è¿‡ç¨‹ä¸­çš„åŠ¨æ€æ¶ˆæ¯æµè°ƒæ•´é€šä¿¡è·¯å¾„ã€‚
- **Scalabilityï¼ˆå¯æ‰©å±•æ€§ï¼‰å·®**ï¼šå½“æ–°å¢æˆ–ç§»é™¤æ™ºèƒ½ä½“æ—¶ï¼Œéœ€è¦é‡æ–°è¿›è¡Œæ˜‚è´µçš„ç¦»çº¿ä¼˜åŒ–æˆ–å…¨å±€è°ƒåº¦ï¼Œéš¾ä»¥æ”¯æŒå¼€æ”¾æˆå‘˜åˆ¶ã€‚
- **Robustnessï¼ˆé²æ£’æ€§ï¼‰å¼±**ï¼šä¸­å¿ƒåŒ–æ§åˆ¶æ¶æ„ï¼ˆå¦‚ meta-controllerï¼‰å­˜åœ¨å•ç‚¹æ•…éšœé£é™©ï¼ˆSingle Point of Failure, SPoFï¼‰ï¼Œä¸€æ—¦æ§åˆ¶å™¨è¢«æ”»å‡»æˆ–å‡ºé”™ï¼Œæ•´ä¸ªç³»ç»Ÿå¯èƒ½å´©æºƒã€‚

è¿™äº›é—®é¢˜å…±åŒæ„æˆäº†ä¸€ä¸ªâ€œä¸‰éš¾å›°å¢ƒâ€â€”â€”å¦‚ä½•åœ¨ä¸ç‰ºç‰²æ•ˆç‡çš„å‰æä¸‹åŒæ—¶å®ç° **Adaptivityã€Scalability å’Œ Robustness**ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **RAPS**ï¼ˆ**Reputation-Aware Publish-Subscribe**ï¼‰ï¼Œä¸€ç§å— **åŠ¨æ€è‡ªç»„ç»‡ç½‘ç»œï¼ˆDynamic Ad-Hoc Networkingï¼‰** å¯å‘çš„å»ä¸­å¿ƒåŒ–åè°ƒèŒƒå¼ã€‚

#### **æ ¸å¿ƒæ€æƒ³ï¼šå°† LLM Agent åè°ƒç±»æ¯”ä¸ºç½‘ç»œé€šä¿¡é—®é¢˜**
- å°†æ¯ä¸ª LLM Agent è§†ä¸ºä¸€ä¸ª **ç½‘ç»œä¸»æœºï¼ˆHostï¼‰**
- å°†è‡ªç„¶è¯­è¨€æ¶ˆæ¯è§†ä¸º **è¯­ä¹‰æ•°æ®åŒ…ï¼ˆPacketï¼‰**
- å°†é€šä¿¡æ¨¡å¼è§†ä¸ºåŸºäºæ„å›¾çš„ **å†…å®¹ä¸­å¿ƒç½‘ç»œï¼ˆContent-Centric Networkingï¼‰**

#### **RAPS çš„ä¸‰å±‚æ¶æ„è®¾è®¡**

| å±‚çº§ | ç»„ä»¶ | åŠŸèƒ½ |
|------|------|------|
| **Substrateï¼ˆåº•å±‚åŸºè´¨ï¼‰** | **Distributed Publish-Subscribe Protocol** | å»ä¸­å¿ƒåŒ–è§£è€¦ç”Ÿäº§è€…ï¼ˆPublisherï¼‰ä¸æ¶ˆè´¹è€…ï¼ˆSubscriberï¼‰ï¼Œé€šè¿‡ Broker è¿›è¡Œè¯­ä¹‰åŒ¹é… |
| **Overlay I** | **Reactive Subscription** | å…è®¸ Agent åœ¨è¿è¡Œæ—¶åŠ¨æ€æ›´æ–°å…¶è®¢é˜…æ„å›¾ï¼ˆintentï¼‰ï¼Œå®ç°è‡ªé€‚åº”è§’è‰²æ¼”åŒ– |
| **Overlay II** | **Bayesian Reputation** | æ¯ä¸ª Agent é…å¤‡æœ¬åœ° **watchdog**ï¼Œé€šè¿‡è´å¶æ–¯ä¼°è®¡ç»´æŠ¤å¯¹ç­‰ä½“çš„ä¿¡èª‰ï¼Œå®ç°å»ä¸­å¿ƒåŒ–ä¿¡ä»»æœºåˆ¶ |

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ç¼ºé™· | RAPS æ”¹è¿› |
|------|--------------|-----------|
| **Adaptivity** | å›ºå®šæ‹“æ‰‘ï¼Œé€šä¿¡ä¸å†…å®¹æ— å…³ï¼ˆcommunication-agnosticï¼‰ | æ„å›¾é©±åŠ¨ï¼Œæ¶ˆæ¯è·¯ç”±éšä¸Šä¸‹æ–‡åŠ¨æ€æ¼”åŒ– |
| **Scalability** | æ–°å¢ Agent éœ€é‡æ–°è®­ç»ƒæˆ–ä¼˜åŒ– | æ”¯æŒå³æ’å³ç”¨ï¼Œæ— éœ€å…¨å±€é‡æ„ |
| **Robustness** | ä¸­å¿ƒæ§åˆ¶å™¨æ˜“å—æ”»å‡»ï¼Œå­˜åœ¨ SPoF | åˆ†å¸ƒå¼ä¿¡èª‰æœºåˆ¶è‡ªåŠ¨éš”ç¦»æ¶æ„èŠ‚ç‚¹ |
| **è®­ç»ƒå¼€é”€** | å¤šæ•°éœ€ç¦»çº¿æœç´¢æˆ–è®­ç»ƒåè°ƒå›¾ | å®Œå…¨æ— éœ€è®­ç»ƒï¼Œçº¯æ¨ç†æ—¶åè°ƒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

å®éªŒè¦†ç›–äº”ä¸ªä»£è¡¨æ€§ä»»åŠ¡ï¼Œæ¶µç›–ä¸‰å¤§ç±»åˆ«ï¼š

| ç±»åˆ« | æ•°æ®é›† | ä»»åŠ¡æè¿° | è¯„ä¼°æŒ‡æ ‡ |
|------|--------|----------|----------|
| **General Reasoning** | MMLU | è·¨å­¦ç§‘å¤šé€‰é¢˜ï¼ˆSTEMã€äººæ–‡ç­‰ï¼‰ | Accuracy |
| **Mathematical Reasoning** | GSM8K, SVAMP, AQuA | æ•°å­¦åº”ç”¨é¢˜æ±‚è§£ | Accuracy |
| **Code Generation** | HumanEval | Python ç¼–ç¨‹é—®é¢˜ç”Ÿæˆ | Pass@1 |

> æ•°æ®ç»Ÿè®¡è¯¦è§é™„å½• Table 6ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **LLM Backbone**ï¼šç»Ÿä¸€ä½¿ç”¨ `GPT-4o-mini` ä½œä¸ºæ‰€æœ‰ Agent çš„åŸºç¡€æ¨¡å‹ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚
- **Agent æ•°é‡**ï¼šé»˜è®¤é…ç½® 5 ä¸ª Agentã€‚
- **æœ€å¤§é€šä¿¡è½®æ¬¡**ï¼šk = 5ã€‚
- **Broker å®ç°**ï¼š
  - é»˜è®¤ä½¿ç”¨ `text-embedding-3-small` è¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…ï¼ˆé«˜æ•ˆï¼‰
  - æ¶ˆèå®éªŒä¸­ä¹Ÿæµ‹è¯•äº† LLM-based Brokerï¼ˆæ›´ç²¾ç¡®ä½†æ›´æ…¢ï¼‰

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

å…±å››ç±»åŸºçº¿ï¼š

| ç±»å‹ | ä»£è¡¨æ–¹æ³• | ç‰¹ç‚¹ |
|------|---------|------|
| **Single-Agent Models** | CoT, ComplexCoT, SC | å•æ¨¡å‹é“¾å¼æ€ç»´æˆ–è‡ªæ´½æ¨ç† |
| **Static Multi-Agent Models** | Chain, Star, Tree, Random, LLM-Debate | å›ºå®šæ‹“æ‰‘ç»“æ„ |
| **Communication-Agnostic Models** | GPTSwarm, AFlow, G-Designer | ç¦»çº¿æœç´¢æœ€ä¼˜å›¾ç»“æ„ |
| **Meta-Controlled Models** | AutoAgents, Puppeteer, MAS-Zero | ä½¿ç”¨ä¸­å¤®æ§åˆ¶å™¨åŠ¨æ€è°ƒåº¦ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1ï¼‰**

| æ–¹æ³• | MMLU | GSM8K | SVAMP | AQuA | HumanEval | **Average** |
|------|------|-------|-------|------|-----------|------------|
| G-Designer (SOTA prior) | 86.3 | 93.2 | 90.7 | 79.4 | 90.2 | 88.0 |
| **RAPS (Ours)** | **88.2** | **95.4** | **92.2** | **82.6** | **91.5** | **90.0** |

âœ… RAPS åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡è¾¾åˆ° **state-of-the-art æ€§èƒ½**ï¼Œå¹³å‡æå‡ **+2.0%**ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### âœ… **ä¼˜äºé™æ€ç»“æ„**
- Chainã€Star ç­‰å›ºå®šæ‹“æ‰‘åœ¨å¤æ‚ä»»åŠ¡ï¼ˆå¦‚ SVAMPï¼‰ä¸Šè¡¨ç°ä¸ä½³ï¼ˆChain: 82.6 vs RAPS: 92.2ï¼‰
- è¡¨æ˜åˆšæ€§è·¯å¾„æ— æ³•é€‚é…å¤šæ ·åŒ–æ¨ç†éœ€æ±‚ã€‚

#### âœ… **ä¼˜äºç¦»çº¿ä¼˜åŒ–æ–¹æ³•**
- GPTSwarmã€AFlowã€G-Designer è™½ç»ä¼˜åŒ–ï¼Œä½†ä»å—é™äºé¢„è®¾å›¾ç»“æ„ã€‚
- RAPS åœ¨ AQuA ä¸Šæ¯” G-Designer é«˜ **+3.2%**ï¼Œè¯´æ˜å…¶å…·å¤‡æ›´å¼ºçš„æ¨ç†è·¯å¾„çµæ´»æ€§ã€‚

#### âœ… **ä¼˜äºä¸­å¿ƒåŒ–æ§åˆ¶**
- Puppeteerã€AutoAgents å—é™äºæ§åˆ¶å™¨çš„è®¤çŸ¥è´Ÿè·ã€‚
- RAPS å¹³å‡é«˜å‡º **+5.0%**ï¼Œä¸”æ—  SPoF é£é™©ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰**

| å˜ä½“ | MMLU | GSM8K | HumanEval |
|------|------|-------|-----------|
| **RAPS (Full)** | 88.2 | 95.4 | 91.5 |
| w/o RSï¼ˆæ—  Reactive Subscriptionï¼‰ | 85.6 (-2.6) | 93.7 (-1.7) | 89.3 (-2.2) |
| w/o BRï¼ˆæ—  Bayesian Reputationï¼‰ | 86.9 (-1.3) | 94.5 (-0.9) | 90.7 (-0.8) |
| w/o Both | 83.7 (-4.5) | 92.8 (-2.6) | 88.5 (-3.0) |

> âœ… ä¸¤ä¸ª Overlay æœºåˆ¶å‡æœ‰æ˜¾è‘—è´¡çŒ®ï¼Œ**Reactive Subscription å¯¹æ€§èƒ½å½±å“æ›´å¤§**ã€‚

---

### **å…¶ä»–å…³é”®å®éªŒåˆ†æ**

#### ğŸ”¬ **å¯æ‰©å±•æ€§åˆ†æï¼ˆFigure 3aï¼‰**
- éšç€ Agent æ•°é‡å¢åŠ ï¼ŒChain å’Œ Puppeteer æ€§èƒ½ä¸‹é™æ˜æ˜¾ã€‚
- **RAPS æŒç»­æå‡æ€§èƒ½**ï¼ŒéªŒè¯å…¶è‰¯å¥½çš„å¯æ‰©å±•æ€§ã€‚

#### â±ï¸ **æ•ˆç‡åˆ†æï¼ˆFigure 3bï¼‰**
- GPTSwarm/G-Designer çš„ä¼˜åŒ–å¼€é”€éš Agent æ•°æŒ‡æ•°å¢é•¿ï¼ˆ>2å°æ—¶ for 20 agentsï¼‰ã€‚
- **RAPS æ¨ç†å»¶è¿Ÿç¨³å®šå¢é•¿**ï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½²ã€‚

#### ğŸ›¡ï¸ **é²æ£’æ€§åˆ†æï¼ˆTable 2ï¼‰**
- æ³¨å…¥å¯¹æŠ—æ€§ Agentï¼ˆAdversarial Agentsï¼‰åï¼š
  - G-Designer åœ¨ 2T3A åœºæ™¯ä¸‹å‡†ç¡®ç‡é™è‡³ **15.0%**
  - **RAPS ä»ä¿æŒ 83.0%**ï¼Œè¿œè¶…å…¶ä»–æ–¹æ³•ã€‚
- Puppeteer-Cï¼ˆæ”»å‡»ä¸­å¤®æ§åˆ¶å™¨ï¼‰ç›´æ¥å´©æºƒè‡³ **13.7%**ï¼Œå‡¸æ˜¾ SPoF é£é™©ã€‚

#### ğŸ”„ **æˆæœ¬-æ€§èƒ½æƒè¡¡ï¼ˆFigure 4ï¼‰**
- RAPS åœ¨ä¸åŒé€šä¿¡è½®æ¬¡ï¼ˆk=3,5,7,10ï¼‰ä¸‹å½¢æˆ **å¸•ç´¯æ‰˜å‰æ²¿ï¼ˆPareto Frontierï¼‰**ï¼Œåœ¨ç²¾åº¦ä¸ token æ¶ˆè€—ä¹‹é—´å–å¾—æœ€ä½³å¹³è¡¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **åŠ¨æ€è‡ªç»„ç»‡ç½‘ç»œè§†è§’æ˜¯è§£å†³ LLM Agent åè°ƒä¸‰éš¾å›°å¢ƒçš„æœ‰æ•ˆé€”å¾„**ï¼š
   - å°† Agent åè°ƒå»ºæ¨¡ä¸º **å‘å¸ƒ-è®¢é˜…ï¼ˆPublish-Subscribeï¼‰** é€šä¿¡é—®é¢˜ï¼Œå®ç°äº†å»ä¸­å¿ƒåŒ–ã€æ„å›¾é©±åŠ¨çš„åä½œã€‚

2. **Reactive Subscription æ˜¾è‘—æå‡é€‚åº”æ€§**ï¼š
   - Agent å¯æ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´è§’è‰²ï¼ˆå¦‚ä»â€œæ•°å­¦ä¸“å®¶â€ç»†åŒ–ä¸ºâ€œè·ç¦»-é€Ÿç‡-æ—¶é—´åˆ†æå‘˜â€ï¼‰ï¼Œé¿å…è¯­ä¹‰é”™é…ã€‚

3. **Bayesian Reputation å®ç°å»ä¸­å¿ƒåŒ–é²æ£’æ€§**ï¼š
   - æœ¬åœ° watchdog ç»“åˆä¸€é˜¶ä¸äºŒé˜¶è¯æ®ï¼ˆfirst-hand & second-handï¼‰ï¼Œæœ‰æ•ˆè¯†åˆ«å¹¶éš”ç¦»æ¶æ„æˆ–ä½è´¨é‡è¾“å‡ºã€‚

4. **RAPS åœ¨æ€§èƒ½ã€å¯æ‰©å±•æ€§å’Œé²æ£’æ€§ä¸Šå…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•**ï¼š
   - ä¸ä»…åœ¨æ ‡å‡†ä»»åŠ¡ä¸Š SOTAï¼Œè¿˜èƒ½åœ¨å¯¹æŠ—ç¯å¢ƒä¸‹ç»´æŒé«˜å¯é æ€§ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ–åŸºç¡€ LLM èƒ½åŠ›**ï¼š
   - RAPS æ˜¯â€œæ™ºèƒ½æ”¾å¤§å™¨â€ï¼Œä¸èƒ½å¼¥è¡¥åŸºç¡€æ¨¡å‹æœ¬èº«çš„çŸ¥è¯†æˆ–æ¨ç†ç¼ºé™·ã€‚

2. **å†·å¯åŠ¨é—®é¢˜ï¼ˆCold Startï¼‰**ï¼š
   - åˆå§‹é˜¶æ®µä¿¡èª‰ç³»ç»Ÿç¼ºä¹å†å²æ•°æ®ï¼Œå¯èƒ½å¯¼è‡´çŸ­æš‚è¯¯åˆ¤ã€‚

3. **æœªå¼•å…¥å­¦ä¹ æœºåˆ¶**ï¼š
   - å½“å‰ä¸ºçº¯æ¨ç†æ—¶åè°ƒï¼Œæœªåˆ©ç”¨å¼ºåŒ–å­¦ä¹ è¿›ä¸€æ­¥ä¼˜åŒ–é€šä¿¡ç­–ç•¥ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ„å»ºå¯å­¦ä¹ çš„åè°ƒåè®®**ï¼š
   - åˆ©ç”¨åˆ†å¸ƒå¼ä¿¡èª‰åˆ†æ•°ä½œä¸ºå†…åœ¨å¥–åŠ±ä¿¡å·ï¼Œè®­ç»ƒæ›´é«˜æ•ˆçš„é€šä¿¡ç­–ç•¥ã€‚

2. **å¼•å…¥ç½‘ç»œæ‹¥å¡æ§åˆ¶æœºåˆ¶**ï¼š
   - å€Ÿé‰´ TCP/IP çš„ **Congestion Control**ï¼Œé˜²æ­¢ä¸Šä¸‹æ–‡æº¢å‡ºæˆ– token æµªè´¹ã€‚

3. **åˆ†å±‚å­ç½‘åˆ’åˆ†ï¼ˆHierarchical Subnettingï¼‰**ï¼š
   - é¢å¯¹è¶…å¤§è§„æ¨¡ Agent ç¤¾ä¼šï¼Œå¯å€Ÿé‰´ Kleinrock çš„åˆ†å±‚è·¯ç”±æ€æƒ³è¿›è¡ŒåŠŸèƒ½èšç±»ã€‚

4. **è·¨ä¼šè¯ä¿¡èª‰è¿ç§»**ï¼š
   - è§£å†³å†·å¯åŠ¨é—®é¢˜ï¼Œé€šè¿‡æŒä¹…åŒ–ä¿¡èª‰å…ˆéªŒæˆ–è§’è‰²é£é™©å»ºæ¨¡åŠ é€Ÿæ”¶æ•›ã€‚

---

> **æ€»ç»“**ï¼šRAPS ä¸ä»…æ˜¯ä¸€ä¸ªæ–°æ–¹æ³•ï¼Œæ›´æ˜¯å¼€å¯äº†ä¸€ä¸ªå…¨æ–°çš„ç ”ç©¶èŒƒå¼â€”â€”**å°†ç»å…¸è®¡ç®—æœºç½‘ç»œåŸç†ç³»ç»Ÿæ€§è¿ç§»åˆ° LLM å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè®¾è®¡ä¸­**ï¼Œä¸ºæ„å»ºå¼€æ”¾ã€è‡ªç»„ç»‡ã€å¯ä¿¡çš„ Agent ç¤¾ä¼šæä¾›äº†åšå®åŸºç¡€ã€‚

</details>

---

### 11. [Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System](https://arxiv.org/abs/2602.08335)

**Authors**: Yanming Li, Xuelin Zhang, WenJie Lu, Ziye Tang, Maodong Wu, Haotian Luo, Tongtong Wu, Zijie Peng, Hongze Mi, Yibo Feng, Naiqiang Tan, Chao Huang, Hong Chen, Li Shen  
**Category**: cs.AI  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.08335v1  

#### Abstract
Integrating Large Language Models (LLMs) with external tools via multi-agent systems offers a promising new paradigm for decomposing and solving complex problems. However, training these systems remains notoriously difficult due to the credit assignment challenge, as it is often unclear which specif...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šWho Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³çš„é—®é¢˜**
åœ¨åŸºäº **Large Language Models (LLMs)** å’Œå¤–éƒ¨å·¥å…·çš„ **multi-agent system (MAS)** ä¸­ï¼Œå°½ç®¡å¤šæ™ºèƒ½ä½“æ¶æ„èƒ½æœ‰æ•ˆåˆ†è§£å¤æ‚ä»»åŠ¡ï¼ˆå¦‚è§„åˆ’ã€æ‰§è¡Œï¼‰ï¼Œä½†è®­ç»ƒè¿‡ç¨‹é¢ä¸´ä¸¥é‡çš„ **credit assignment problem**ï¼ˆä¿¡ç”¨åˆ†é…é—®é¢˜ï¼‰ï¼š
- æˆåŠŸæˆ–å¤±è´¥çš„å†³ç­–è½¨è¿¹éš¾ä»¥å½’å› äºå…·ä½“çš„æ™ºèƒ½ä½“ï¼ˆå¦‚ planner æˆ– workerï¼‰ã€‚
- ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ– **sparse reward** æˆ– **globally broadcast reward**ï¼Œæ— æ³•åŒºåˆ†ä¸åŒè§’è‰²çš„è¾¹é™…è´¡çŒ®ï¼Œå¯¼è‡´ç­–ç•¥æ›´æ–°ä½æ•ˆç”šè‡³è¯¯å¯¼ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ï¼šSHARP**
ä½œè€…æå‡ºäº† **SHARP (Shapley-based Hierarchical Attribution for Reinforcement Policy)**ï¼Œä¸€ç§åŸºäº **Shapley Value** çš„ç²¾ç»†åŒ–ä¿¡ç”¨åˆ†é…æ¡†æ¶ï¼Œç”¨äºä¼˜åŒ–å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ã€‚

#### **æ ¸å¿ƒåˆ›æ–°ç‚¹**
- **ä¸‰å…ƒå¥–åŠ±æœºåˆ¶ (Tripartite Decomposed Reward)**
  1. **Global Broadcast-Accuracy Reward**ï¼šå…¨å±€å‡†ç¡®ç‡ä¿¡å·ï¼Œç¡®ä¿ä»»åŠ¡æœ€ç»ˆç›®æ ‡å¯¹é½ã€‚
  2. **Shapley-based Marginal-Credit Reward**ï¼šåŸºäº **Shapley Value** è®¡ç®—æ¯ä¸ª agent çš„å› æœè´¡çŒ®ï¼Œå®ç°ä¸ªä½“çº§ä¿¡ç”¨é‡åŒ–ã€‚
  3. **Tool-Process Reward**ï¼šè¿‡ç¨‹çº§åé¦ˆï¼Œè¯„ä¼°å·¥å…·è°ƒç”¨çš„æœ‰æ•ˆæ€§å’Œæ­£ç¡®æ€§ï¼Œæå‡æ‰§è¡Œæ•ˆç‡ã€‚

- **Counterfactual Masking æœºåˆ¶**
  - é€šè¿‡â€œç§»é™¤â€æŸä¸ª agent å¹¶è§‚å¯Ÿä»»åŠ¡æˆåŠŸç‡çš„å˜åŒ–ï¼ˆå³ $ R_{\text{acc}}(T) - R_{\text{acc}}(T^{(-m)}) $ï¼‰ï¼Œè®¡ç®—å…¶ **marginal contribution**ã€‚
  - æ•°å­¦ä¸Šé€¼è¿‘ **Shapley Value**ï¼Œå®ç°å¯¹ planner å’Œ worker çš„å·®å¼‚åŒ–ä¿¡ç”¨èµ‹å€¼ã€‚

- **Hierarchical Advantage Normalization**
  - å¯¹æ¯ä¸ª agent çš„ä¼˜åŠ¿å‡½æ•°è¿›è¡Œç»„å†…æ ‡å‡†åŒ–ï¼ˆgroup-relative advantageï¼‰ï¼Œé™ä½æ–¹å·®ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³• | SHARP |
|------|--------|-------|
| **Credit Assignment** | å…¨å±€å¹¿æ’­ï¼Œæ¨¡ç³Šå½’å›  | ç²¾ç»†åŒ–ã€ä¸ªä½“åŒ–ã€åŸºäºå› æœæ¨ç† |
| **Reward Signal** | å•ä¸€ç»ˆç«¯å¥–åŠ± | å¤šç»´åº¦ï¼šç»“æœ + è´¡çŒ® + è¿‡ç¨‹ |
| **è®­ç»ƒç¨³å®šæ€§** | é«˜æ–¹å·®ï¼Œæ˜“éœ‡è¡ | ä½æ–¹å·®æ¢¯åº¦ï¼Œç¨³å®šæ”¶æ•› |
| **å¯è§£é‡Šæ€§** | é»‘ç®±ç­–ç•¥æ›´æ–° | å¯åˆ†æå„ agent çš„å®é™…è´¡çŒ® |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**
å®éªŒè¦†ç›–å¤šä¸ªçœŸå®ä¸–ç•Œå¤æ‚ä»»åŠ¡åŸºå‡†ï¼š
- **MuSiQue**ï¼šå¤šè·³é—®ç­”ï¼Œéœ€ç»„åˆå¤šä¸ªå•è·³é—®é¢˜ã€‚
- **GAIA-text**ï¼šç»¼åˆ AI åŠ©æ‰‹è¯„æµ‹ï¼Œæ¶µç›–æ¨ç†ã€ç½‘é¡µæµè§ˆã€å·¥å…·ä½¿ç”¨ã€‚
- **WebWalkerQA**ï¼šå¤šæ­¥ç½‘é¡µå¯¼èˆªä¸è¯æ®èšåˆã€‚
- **FRAMES**ï¼šç«¯åˆ°ç«¯æ£€ç´¢å¢å¼ºç”Ÿæˆçš„ç»¼åˆæ€§è¯„æµ‹ã€‚
- **DocMath-Eval**ï¼šé•¿æ–‡æœ¬ä¸­çš„æ•°å­¦æ¨ç†èƒ½åŠ›è¯„ä¼°ï¼ˆå«è¡¨æ ¼ä¸æ–‡æœ¬ï¼‰ã€‚

### **å®éªŒè®¾ç½®**
- **æ¨¡å‹éª¨å¹²**ï¼šä¸»è¦åŸºäº **Qwen3-8B**ï¼Œéƒ¨åˆ†å¯¹æ¯”ä½¿ç”¨ LLaMA-3.1-8Bã€‚
- **è®­ç»ƒæ–¹å¼**ï¼šé‡‡ç”¨ **self-play multi-agent modeling**ï¼Œæ‰€æœ‰è§’è‰²å…±äº«åŒä¸€ policyï¼Œé€šè¿‡ role-specific prompts åŒºåˆ† planner ä¸ workerã€‚
- **ä¼˜åŒ–ç®—æ³•**ï¼šåŸºäº **Group Relative Policy Optimization (GRPO)** æ”¹è¿›ï¼Œå¼•å…¥ SHARP çš„ credit åˆ†é…æœºåˆ¶ã€‚
- **è¶…å‚æ•°**ï¼šreward æƒé‡è®¾ä¸º $\alpha=0.9$, $\beta=0.9$, $\gamma=0.1$ï¼›batch size 256ï¼Œè®­ç»ƒ 180 æ­¥ã€‚

### **è¯„ä¼°æŒ‡æ ‡**
- **ä¸»æŒ‡æ ‡**ï¼š**Average Match Accuracy**ï¼ˆå¹³å‡åŒ¹é…å‡†ç¡®ç‡ï¼‰
- **è¾…åŠ©åˆ†æ**ï¼š
  - Planner Scoreï¼ˆplanner çš„å¹³å‡ Shapley å€¼ï¼‰
  - Useful/Harmful Subagent æ¯”ä¾‹
  - æ¨ç† token æ¶ˆè€—é‡
  - MMLU å‡†ç¡®ç‡ï¼ˆæ£€æµ‹ç¾éš¾æ€§é—å¿˜ï¼‰

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ç±»åˆ« | æ–¹æ³• |
|------|------|
| **Zero-shot / RAG** | LLaMA-3.1-8B RAG, Qwen3-8B RAG |
| **Prompt-based Planning** | Plan-Search |
| **Single-agent RL** | Search-R1, Single-agent GRPO |
| **Multi-agent (æ—  marginal credit)** | Planner-Worker, G-Designer, CARD, COA, MATPO, AceSearcher |
| **Proposed** | **SHARP** |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**
| æ–¹æ³• | MuSiQue | GAIA-text | WebWalkerQA | FRAMES | **AVG** |
|------|---------|-----------|-------------|--------|--------|
| Single-agent GRPO | 45.93 | 27.97 | 7.47 | 30.20 | 27.89 |
| MATPO (SOTA MAS) | 47.00 | 31.65 | 7.47 | 37.10 | **30.81** |
| **SHARP (Ours)** | **50.76** | **33.70** | **8.50** | **37.29** | **32.56** |

- **ç›¸å¯¹æå‡**ï¼š
  - æ¯” **single-agent** æ–¹æ³•å¹³å‡æå‡ **23.66%**
  - æ¯” **multi-agent** æ–¹æ³•å¹³å‡æå‡ **14.05%**

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰**
#### ï¼ˆ1ï¼‰Shapley Credit çš„ä½œç”¨ï¼ˆå›¾3ï¼‰
- **å®Œæ•´ SHARP**ï¼ˆplanner + worker creditï¼‰ï¼šMuSiQue è¾¾ **50.76**
- ä»… planner creditï¼š47.60
- ä»… worker creditï¼š48.00
- æ—  Shapleyï¼š47.00
- âœ… **è”åˆè®­ç»ƒ planner ä¸ worker çš„ credit æ˜¾è‘—ä¼˜äºå•ç‹¬ä¼˜åŒ–**

#### ï¼ˆ2ï¼‰Scaling Lawsï¼ˆå›¾4ï¼‰
- åœ¨ **MuSiQue** ä¸Šæµ‹è¯•ä¸åŒæ¨¡å‹å¤§å°ï¼ˆ0.6B â†’ 8Bï¼‰ï¼š
  - SHARP åœ¨ 8B æ¨¡å‹ä¸Šæ¯” single-agent GRPO é«˜å‡º **14.41 pts**
  - è¡¨æ˜ SHARP æ›´èƒ½ä»æ›´å¤§æ¨¡å‹ä¸­å—ç›Š

#### ï¼ˆ3ï¼‰è®­ç»ƒç¨³å®šæ€§ï¼ˆå›¾5ï¼‰
- åœ¨ GAIA-text ä¸Šè®­ç»ƒ 180 æ­¥ï¼š
  - SHARP å‡†ç¡®ç‡ä» 27.53% å•è°ƒä¸Šå‡è‡³ 33.70%
  - GRPO å’Œ MATPO å‡ºç°æ˜æ˜¾æ³¢åŠ¨
- âœ… SHARP å…·å¤‡æ›´å¼ºçš„é•¿æœŸè®­ç»ƒç¨³å®šæ€§

#### ï¼ˆ4ï¼‰åè°ƒæ€§åˆ†æï¼ˆå›¾6ï¼‰
- **Harmful subagent æ¯”ä¾‹**ï¼š
  - Baseline: 5.48%
  - **SHARP**: **4.40%** â†“
- **Useful subagent æ¯”ä¾‹**ï¼š
  - ä» 11.03% â†‘ è‡³ **12.96%**
- **Planner Score (avg. Shapley)**ï¼š
  - ä» 0.4542 â†‘ è‡³ **0.5084**
- âœ… SHARP æ˜¾è‘—æ”¹å–„äº† planner-worker åè°ƒè´¨é‡

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**
1. **Marginal Credit æ˜¯æ€§èƒ½è·ƒè¿çš„å…³é”®**
   - ç›¸æ¯”æ¶æ„è®¾è®¡æˆ–ä¼˜åŒ–ç­–ç•¥ï¼Œ**æ˜¾å¼çš„ marginal credit modeling** æ˜¯ SHARP æ€§èƒ½é¢†å…ˆçš„æ ¸å¿ƒé©±åŠ¨åŠ›ã€‚
2. **Shapley-based Attribution æå‡è®­ç»ƒæ•ˆç‡**
   - é€šè¿‡ counterfactual åˆ†æéš”ç¦»ä¸ªä½“è´¡çŒ®ï¼Œæ˜¾è‘—é™ä½ç­–ç•¥æ›´æ–°å™ªå£°ï¼Œé¿å…â€œæ­ä¾¿è½¦â€æˆ–â€œæ›¿ç½ªç¾Šâ€ç°è±¡ã€‚
3. **ååŒä¼˜åŒ–å¸¦æ¥ååŒå¢ç›Š**
   - planner ä¸ worker çš„ credit è”åˆå»ºæ¨¡äº§ç”Ÿ **synergistic effect**ï¼Œæœ€ç»ˆæ€§èƒ½è¿œè¶…å„éƒ¨åˆ†ä¹‹å’Œã€‚
4. **æ›´å¼ºçš„æ³›åŒ–ä¸æ‰©å±•èƒ½åŠ›**
   - åœ¨ DocMath-Eval ä¸Šè·¨ä»»åŠ¡è¡¨ç°æœ€ä¼˜ã€‚
   - éšæ¨¡å‹è§„æ¨¡å¢å¤§ï¼ŒSHARP çš„ä¼˜åŠ¿æŒç»­æ‰©å¤§ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **è®¡ç®—å¼€é”€å¢åŠ **ï¼šShapley å€¼ä¼°ç®—éœ€å¤šæ¬¡åäº‹å® rolloutï¼Œè®­ç»ƒæ—¶é—´éš agent æ•°å¢é•¿ã€‚
  - ä½†å¯é€šè¿‡ **sparsification**ï¼ˆåªå¯¹éƒ¨åˆ† subagent è®¡ç®—ï¼‰ç¼“è§£ï¼ˆè§å›¾7ï¼‰ã€‚
- **ä»å­˜åœ¨å†—ä½™è°ƒç”¨**ï¼šå³ä½¿åœ¨ SHARP ä¸‹ï¼Œ**useful subagent ä»å å°‘æ•°**ï¼ˆçº¦13%ï¼‰ï¼Œè¡¨æ˜å½“å‰ MAS å­˜åœ¨ç³»ç»Ÿæ€§æ•ˆç‡ç“¶é¢ˆã€‚
- **å¯¹ planner çš„é—´æ¥å½±å“å»ºæ¨¡è¾ƒç²—ç•¥**ï¼šplanner çš„ credit é€šè¿‡ worker çš„ max(credit) èšåˆï¼Œå¯èƒ½å¿½ç•¥é•¿æœŸç»“æ„å½±å“ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ›´é«˜æ•ˆçš„ Shapley Approximation**
   - å¼•å…¥é‡‡æ ·æˆ–ä»£ç†æ¨¡å‹åŠ é€Ÿ marginal contribution ä¼°è®¡ã€‚
2. **åŠ¨æ€ agent Pruning**
   - åŸºäº credit ä¿¡å·è‡ªåŠ¨å‰ªæä½æ•ˆ workerï¼Œæ„å»ºæ›´ç´§å‡‘çš„ agent graphã€‚
3. **è·¨ä»»åŠ¡è¿ç§» credit ç­–ç•¥**
   - å°† learned credit assignment logic æ³›åŒ–åˆ°æ–°ä»»åŠ¡æˆ–æ–° agent topologyã€‚
4. **ç»“åˆ value-based æ–¹æ³•**
   - æ¢ç´¢å°† Shapley credit ä¸ critic network ç»“åˆï¼Œè¿›ä¸€æ­¥æå‡æ ·æœ¬æ•ˆç‡ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **SHARP é€šè¿‡å¼•å…¥ Shapley-based marginal creditï¼Œé¦–æ¬¡å®ç°äº† multi-agent LLM system ä¸­â€œè°è¯¥å¾—å¥–â€çš„ç²¾ç¡®å›ç­”ï¼Œä¸ä»…æ˜¾è‘—æå‡äº†æ€§èƒ½ä¸ç¨³å®šæ€§ï¼Œä¹Ÿä¸ºå¯è§£é‡Šã€é«˜æ•ˆã€å¯æ‰©å±•çš„ agent coordination æä¾›äº†æ–°èŒƒå¼ã€‚**

</details>

---

### 12. [Scalable Dexterous Robot Learning with AR-based Remote Human-Robot Interactions](https://arxiv.org/abs/2602.07341)

**Authors**: Yicheng Yang, Ruijiao Li, Lifeng Wang, Shuai Zheng, Shunzheng Ma, Keyu Zhang, Tuoyu Sun, Chenyun Dai, Jie Ding, Zhuo Zou  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.07341v1  

#### Abstract
This paper focuses on the scalable robot learning for manipulation in the dexterous robot arm-hand systems, where the remote human-robot interactions via augmented reality (AR) are established to collect the expert demonstration data for improving efficiency. In such a system, we present a unified f...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Scalable Dexterous Robot Learning with AR-based Remote Human-Robot Interactions*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
è¯¥è®ºæ–‡èšç„¦äº**çµå·§æœºå™¨äººè‡‚æ‰‹ç³»ç»Ÿï¼ˆdexterous robot arm-hand systemsï¼‰ä¸­çš„å¯æ‰©å±•æ“ä½œå­¦ä¹ é—®é¢˜**ã€‚ä¼ ç»Ÿæ–¹æ³•é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **ä¸“å®¶ç¤ºèŒƒæ•°æ®è·å–æˆæœ¬é«˜ä¸”æ•ˆç‡ä½**ï¼Œå°¤å…¶æ˜¯åœ¨çœŸå®ä¸–ç•Œä¸­è¿›è¡Œteleoperationæ—¶ï¼›
- å•çº¯çš„**è¡Œä¸ºå…‹éš†ï¼ˆBehavior Cloning, BCï¼‰æ˜“å—æ•°æ®ä¸åŒ¹é…å’Œè¯¯å·®ç´¯ç§¯å½±å“**ï¼Œå¯¼è‡´ç­–ç•¥é€€åŒ–ï¼›
- **å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒæ ·æœ¬æ•ˆç‡ä½ã€æ”¶æ•›æ…¢**ï¼Œä¸”åœ¨å¤æ‚ä»»åŠ¡ä¸­å¯èƒ½å‡ºç°**ç­–ç•¥å´©æºƒï¼ˆpolicy collapseï¼‰**ã€‚

ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆ**å¢å¼ºç°å®ï¼ˆARï¼‰è¿œç¨‹äº¤äº’ã€æ¨¡ä»¿å­¦ä¹ ä¸å¯¹æ¯”å­¦ä¹ å¢å¼ºçš„å¼ºåŒ–å­¦ä¹ **çš„ç»Ÿä¸€æ¡†æ¶ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

è®ºæ–‡æå‡ºä¸€ä¸ª**ä¸¤é˜¶æ®µå­¦ä¹ æ¡†æ¶**ï¼š

1. **ç¬¬ä¸€é˜¶æ®µï¼šåŸºäºARçš„è¿œç¨‹äººç±»-æœºå™¨äººäº¤äº’ç”¨äºè¡Œä¸ºå…‹éš†é¢„è®­ç»ƒ**
   - æ„å»ºäº†ä¸€ä¸ªé€šç”¨çš„**AR-based teleoperation system**ï¼Œåˆ©ç”¨HoloLens 2æ•æ‰äººç±»ä¸“å®¶çš„æ‰‹éƒ¨å§¿æ€ï¼Œå¹¶é€šè¿‡Unityå¹³å°å®ç°ä¸å¤šç§æœºå™¨äººçš„æ— çº¿è¿œç¨‹è¿æ¥ã€‚
   - åˆ©ç”¨è¯¥ç³»ç»Ÿé«˜æ•ˆæ”¶é›†å°‘é‡é«˜è´¨é‡ä¸“å®¶è½¨è¿¹ï¼ˆä»…15æ¡ï¼‰ï¼Œç”¨äºåˆå§‹åŒ–ç­–ç•¥ç½‘ç»œï¼ˆbehavior cloning pretrainingï¼‰ã€‚

2. **ç¬¬äºŒé˜¶æ®µï¼šå¯¹æ¯”å­¦ä¹ å¢å¼ºçš„Soft Actor-Criticï¼ˆSACï¼‰ç®—æ³•**
   - å¼•å…¥ä¸€ä¸ª**projection head**ç»“æ„ï¼Œåœ¨actorç½‘ç»œè®­ç»ƒè¿‡ç¨‹ä¸­æ–½åŠ **å¯¹æ¯”æŸå¤±ï¼ˆcontrastive lossï¼‰**ï¼Œå¼ºåˆ¶æ™ºèƒ½ä½“çš„åŠ¨ä½œè¡¨ç¤ºé è¿‘ä¸“å®¶åŠ¨ä½œçš„è¡¨ç¤ºç©ºé—´ã€‚
   - è®¾è®¡äº†**äº‹ä»¶é©±åŠ¨çš„å¥–åŠ±å‡½æ•°ï¼ˆevent-driven augmented rewardï¼‰** æ¥æå‡å®‰å…¨æ€§ã€‚
   - å¯¹æ¯”å­¦ä¹ ä½œä¸ºè¾…åŠ©ç›®æ ‡ï¼Œå¼•å¯¼RLç­–ç•¥ä¿ç•™ä¸“å®¶åå¥½ï¼Œé˜²æ­¢ç­–ç•¥åç¦»å¯¼è‡´å´©æºƒã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **æ•°æ®é‡‡é›†æ•ˆç‡** | AR-based teleoperationæ”¯æŒè¿œç¨‹ã€ç›´è§‚çš„æ“ä½œï¼Œå…¼å®¹å¤šè®¾å¤‡ï¼Œæ˜¾è‘—é™ä½æ•°æ®é‡‡é›†é—¨æ§›å’Œæ—¶é—´æˆæœ¬ã€‚ |
| **è®­ç»ƒæ•ˆç‡ä¸ç¨³å®šæ€§** | ç›¸æ¯”æ ‡å‡†PPOå’ŒSACï¼Œæ‰€ææ–¹æ³•**è®­ç»ƒé€Ÿåº¦æå‡çº¦4å€**ï¼Œå¹¶æœ‰æ•ˆé¿å…äº†policy collapseã€‚ |
| **æ ·æœ¬æ•ˆç‡** | ä»…éœ€**15æ¡ä¸“å®¶è½¨è¿¹**å³å¯å®Œæˆæœ‰æ•ˆé¢„è®­ç»ƒï¼Œé€‚åˆå°æ ·æœ¬åœºæ™¯ã€‚ |
| **æ€§èƒ½è¡¨ç°** | åœ¨ball graspingå’Œbottle graspingä»»åŠ¡ä¸­å‡è¾¾åˆ°æœ€é«˜æˆåŠŸç‡ï¼Œä¼˜äºä¸»æµRLä¸BC+RLæ–¹æ³•ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **è‡ªå»ºæ•°æ®é›†**ï¼šé€šè¿‡AR teleoperationç³»ç»Ÿé‡‡é›†äº†**15æ¡ä¸“å®¶æ¼”ç¤ºè½¨è¿¹**ï¼Œæ¶µç›–deformable ballå’Œbottleçš„æŠ“å–ä»»åŠ¡ã€‚
- æ‰€æœ‰è®­ç»ƒæ•°æ®å‡æ¥è‡ªä½œè€…æ„å»ºçš„è¿œç¨‹äººæœºäº¤äº’ç³»ç»Ÿï¼Œæœªä½¿ç”¨å…¬å¼€æ•°æ®é›†ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **ä»¿çœŸç¯å¢ƒ**
- ä½¿ç”¨ **PyBullet** è¿›è¡Œç‰©ç†ä»¿çœŸï¼›
- æœºå™¨äººå¹³å°ä¸º **CGXi-G6æœºæ¢°è‡‚ + Inspireçµå·§æ‰‹**ï¼›
- è§†è§‰æ„ŸçŸ¥é‡‡ç”¨ **YOLOv8** æ£€æµ‹ç›®æ ‡ç‰©ä½“ä½ç½®ï¼›
- çŠ¶æ€å‘é‡ç»´åº¦ï¼š20ç»´ï¼›åŠ¨ä½œå‘é‡ç»´åº¦ï¼š8ç»´ï¼›
- æœ€å¤§è½¨è¿¹é•¿åº¦ï¼šT = 100 time-stepsï¼›
- è®­ç»ƒç¡¬ä»¶ï¼šIntel Xeon Gold 6226R CPU + NVIDIA RTX 4090 GPUï¼›
- æ€»æ¨¡æ‹Ÿè¯•éªŒæ¬¡æ•°ï¼š10â´æ¬¡ã€‚

#### **çœŸå®ä¸–ç•Œå®éªŒ**
- åœ¨å®é™…æœºå™¨äººå¹³å°ä¸Šéƒ¨ç½²è®­ç»ƒå¥½çš„ç­–ç•¥ï¼›
- ä½¿ç”¨ARç•Œé¢è¿œç¨‹å¯åŠ¨æœºå™¨äººæ‰§è¡ŒæŠ“å–ä»»åŠ¡ï¼›
- æ¯é¡¹ä»»åŠ¡è¿›è¡Œ50æ¬¡çœŸå®æµ‹è¯•ã€‚

#### **è¯„ä¼°æŒ‡æ ‡**
- **Mean Reward**ï¼ˆå¹³å‡ç´¯è®¡å¥–åŠ±ï¼‰
- **Mean Success Rate**ï¼ˆå¹³å‡æˆåŠŸç‡è¾¾åˆ°ç›®æ ‡çš„æ¯”ä¾‹ï¼‰
- **Number of Iterations until Convergence**ï¼ˆæ”¶æ•›æ‰€éœ€è¿­ä»£æ¬¡æ•°ï¼‰
- **Time Consumption until Convergence (min)**ï¼ˆæ”¶æ•›è€—æ—¶ï¼‰
- **Sim-to-Real Gap** åˆ†æï¼ˆæ¯”è¾ƒä»¿çœŸä¸çœŸå®ç¯å¢ƒçš„è¡¨ç°å·®å¼‚ï¼‰

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿æ–¹æ³• | æè¿° |
|---------|------|
| **PPO** [50] | ç»å…¸on-policy RLç®—æ³•ï¼Œä½œä¸ºå¼ºåŸºå‡†ä¹‹ä¸€ |
| **SAC** [51] | é«˜æ•ˆç¨³å®šçš„off-policyæœ€å¤§ç†µRLç®—æ³•ï¼Œå¹¿æ³›ç”¨äºè¿ç»­æ§åˆ¶ |
| **BC+SAC** | è¡Œä¸ºå…‹éš†é¢„è®­ç»ƒ + SACå¾®è°ƒï¼Œç”¨äºéªŒè¯å¯¹æ¯”å­¦ä¹ çš„æœ‰æ•ˆæ€§ï¼ˆæ¶ˆèå®éªŒï¼‰ |
| **Ours (Proposed Method)** | BCé¢„è®­ç»ƒ + SAC + projection head + contrastive loss |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§Table IIIï¼‰**

| ä»»åŠ¡ | æŒ‡æ ‡ | PPO | SAC | BC+SAC | **Ours** |
|------|------|-----|-----|--------|----------|
| **Ball Grasping** | Mean Reward | 584.03 | 1055.16 | 1070.77 | **1145.61** |
|                   | Success Rate | 37.33% | 84.22% | 85.49% | **91.80%** |
|                   | æ”¶æ•›è¿­ä»£æ•° | 150 | 140 | 30 | **30** |
|                   | æ”¶æ•›è€—æ—¶(min) | 355 | 300 | 75 | **75** |
| **Bottle Grasping** | Mean Reward | 696.76 | 1052.78 | 1110.51 | **1155.79** |
|                    | Success Rate | 44.18% | 83.93% | 88.66% | **91.83%** |
|                    | æ”¶æ•›è¿­ä»£æ•° | 130 | 120 | 25 | **23** |
|                    | æ”¶æ•›è€—æ—¶(min) | 340 | 270 | 60 | **55** |

> âœ… **ç»“è®º**ï¼šæ‰€ææ–¹æ³•åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå…¨é¢é¢†å…ˆï¼Œå°¤å…¶åœ¨**è®­ç»ƒé€Ÿåº¦ï¼ˆå¿«çº¦4å€ï¼‰å’ŒæˆåŠŸç‡æ–¹é¢ä¼˜åŠ¿æ˜æ˜¾**ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

- **BCé¢„è®­ç»ƒçš„ä½œç”¨**ï¼š
  - æ˜¾è‘—å‡å°‘RLé˜¶æ®µçš„æ¢ç´¢ç©ºé—´ï¼Œä½¿ç­–ç•¥å¿«é€Ÿæ¥è¿‘æœ€ä¼˜åŒºåŸŸï¼›
  - æ˜¯åŠ é€Ÿæ”¶æ•›çš„å…³é”®å› ç´ ï¼ˆBC+SACå·²æ¯”çº¯SACå¿«4â€“5å€ï¼‰ã€‚

- **å¯¹æ¯”å­¦ä¹ ï¼ˆcontrastive learningï¼‰çš„ä½œç”¨**ï¼š
  - åœ¨BC+SACåŸºç¡€ä¸Šè¿›ä¸€æ­¥æå‡æ€§èƒ½ï¼ˆsuccess rate â†‘ ~3â€“6%ï¼‰ï¼›
  - æˆåŠŸé˜²æ­¢**policy collapse**ç°è±¡ï¼ˆä»rewardæ›²çº¿ç¨³å®šæ€§å¯çœ‹å‡ºï¼‰ï¼›
  - projection headé€šè¿‡æ‹‰è¿‘agentä¸expertåœ¨éšç©ºé—´ä¸­çš„è¡¨ç¤ºè·ç¦»ï¼Œå¢å¼ºäº†ç­–ç•¥é²æ£’æ€§ã€‚

> ğŸ” å›¾6æ˜¾ç¤ºï¼šOursæ–¹æ³•ä¸ä»…æ”¶æ•›æ›´å¿«ï¼Œä¸”æœ€ç»ˆrewardæ›´é«˜ã€æ³¢åŠ¨æ›´å°ã€‚

---

### **çœŸå®ä¸–ç•Œå®éªŒç»“æœï¼ˆå›¾8ï¼‰**

| ä»»åŠ¡ | PPO | SAC | BC+SAC | **Ours** |
|------|-----|-----|--------|----------|
| Ball Grasping | 32.0% | 40.0% | 66.0% | **72.0%** |
| Bottle Grasping | 70.0% | 72.0% | 86.0% | **90.0%** |

- å°½ç®¡å­˜åœ¨**sim-to-real gap**ï¼ˆå°¤å…¶æ˜¯å¯¹å½¢å˜çƒä½“æ„ŸçŸ¥ä¸å‡†ï¼‰ï¼Œä½†æ‰€ææ–¹æ³•ä»ä¿æŒæœ€ä½³è¡¨ç°ï¼›
- ç“¶å­ï¼ˆåˆšæ€§åœ†æŸ±ä½“ï¼‰æŠ“å–æˆåŠŸç‡æ¥è¿‘ä»¿çœŸç»“æœï¼Œè¡¨æ˜æ–¹æ³•å…·å¤‡è‰¯å¥½è¿ç§»èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **AR-based teleoperationæ˜¯é«˜æ•ˆæ”¶é›†ä¸“å®¶ç¤ºèŒƒçš„æœ‰æ•ˆæ‰‹æ®µ**ï¼Œç‰¹åˆ«é€‚ç”¨äºè¿œç¨‹ã€ä½æˆæœ¬ã€è·¨å¹³å°çš„æ•°æ®é‡‡é›†ã€‚
2. âœ… **è¡Œä¸ºå…‹éš†é¢„è®­ç»ƒæå¤§æå‡äº†RLçš„åˆå§‹ç­–ç•¥è´¨é‡**ï¼Œæ˜¾è‘—ç¼©çŸ­è®­ç»ƒæ—¶é—´ã€‚
3. âœ… **å¼•å…¥contrastive learningå¹¶é€šè¿‡projection headçº¦æŸç­–ç•¥ç©ºé—´ï¼Œèƒ½æœ‰æ•ˆé˜²æ­¢policy collapse**ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§å’Œæœ€ç»ˆæ€§èƒ½ã€‚
4. âœ… æ‰€ææ–¹æ³•åœ¨**ä»¿çœŸä¸çœŸå®ç¯å¢ƒä¸­å‡ä¼˜äºPPOã€SACåŠBC+SAC**ï¼Œå®ç°äº†æ›´é«˜çš„æˆåŠŸç‡ä¸æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ã€‚
5. âœ… å®ç°äº†è¾ƒå°çš„**sim-to-real gap**ï¼Œå°¤å…¶å¯¹äºå‡ ä½•è§„åˆ™çš„ç›®æ ‡ï¼ˆå¦‚ç“¶å­ï¼‰å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. ğŸš« **ä¾èµ–é«˜è´¨é‡ARå§¿æ€ä¼°è®¡**ï¼šè‹¥ARè®¾å¤‡å¯¹æ‰‹éƒ¨è¿½è¸ªä¸å‡†ï¼ˆå¦‚é®æŒ¡ã€å…‰ç…§å˜åŒ–ï¼‰ï¼Œä¼šå½±å“ä¸“å®¶æ•°æ®è´¨é‡ã€‚
2. ğŸš« **ä»…é€‚ç”¨äºå°è§„æ¨¡ä¸“å®¶æ•°æ®åœºæ™¯**ï¼šè™½ç„¶å¼ºè°ƒâ€œå°‘æ ·æœ¬â€ï¼Œä½†æç«¯æƒ…å†µä¸‹ï¼ˆå¦‚<5æ¡è½¨è¿¹ï¼‰æ•ˆæœå¯èƒ½ä¸‹é™ã€‚
3. ğŸš« **å½“å‰ä»…é’ˆå¯¹å•è‡‚å•æ‰‹ç³»ç»Ÿ**ï¼Œå°šæœªæ‰©å±•åˆ°åŒè‡‚åä½œæˆ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚
4. ğŸš« **ç¼ºä¹è§¦è§‰åé¦ˆï¼ˆhaptic feedbackï¼‰**ï¼Œé™åˆ¶äº†å¯¹é«˜åº¦åŠ¨æ€æˆ–æŸ”è½¯ç‰©ä½“çš„ç²¾ç»†æ“æ§èƒ½åŠ›ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. ğŸ”® **è”åˆå¤šä¸ªphysics simulatorè¿›è¡Œç­–ç•¥è®­ç»ƒ**ï¼Œä»¥å¢å¼ºç³»ç»Ÿé²æ£’æ€§ï¼ˆå‚è€ƒ[54] Polysimï¼‰ï¼›
2. ğŸ”® **æå‡ä»¿çœŸä¸­ç‰©ä½“å‡ ä½•é‡å»º fidelity**ï¼Œç¼©å°sim-to-real gapï¼Œä¾‹å¦‚èåˆé«˜åˆ†è¾¨ç‡è§¦è§‰å»ºæ¨¡ï¼ˆå‚è€ƒ[53]ï¼‰ï¼›
3. ğŸ”® **èåˆ2Dè¯­ä¹‰ä¸3Då‡ ä½•ä¿¡æ¯**ï¼ˆå¦‚Visual-Geometry Diffusion Policy [55]ï¼‰ï¼Œæå‡ç©ºé—´ç†è§£èƒ½åŠ›ï¼›
4. ğŸ”® æ¢ç´¢**è§†è§‰+è§¦è§‰åé¦ˆçš„æ··åˆteleoperation**ï¼Œæ”¯æŒæ›´å¤æ‚çš„deformable object manipulationï¼›
5. ğŸ”® å°†æœ¬æ–¹æ³•æ‰©å±•è‡³**multi-agent dexterous systems**ï¼ˆå¦‚åŒè‡‚ååŒæ“ä½œï¼‰ï¼›
6. ğŸ”® åœ¨éç»“æ„åŒ–çœŸå®ç¯å¢ƒä¸­ç ”ç©¶**RLä¸multimodal imitation learningçš„è”åˆéƒ¨ç½²**ï¼Œæ¨åŠ¨å®ç”¨åŒ–è½åœ°ã€‚

---

> ğŸ’¡ **æ€»ä½“è¯„ä»·**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§**é«˜æ•ˆã€ç¨³å®šã€å¯æ‰©å±•çš„çµå·§æ“ä½œå­¦ä¹ èŒƒå¼**ï¼Œå°†ARäº¤äº’ã€æ¨¡ä»¿å­¦ä¹ ä¸å¯¹æ¯”å¢å¼ºRLæœ‰æœºç»“åˆï¼Œä¸ºæœªæ¥äººæœºååŒæœºå™¨äººå­¦ä¹ æä¾›äº†é‡è¦æŠ€æœ¯è·¯å¾„å’Œå®è¯åŸºç¡€ã€‚

</details>

---

### 13. [Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs](https://arxiv.org/abs/2602.08241)

**Authors**: Siqu Ou, Tianrui Wan, Zhiyuan Zhao, Junyu Gao, Xuelong Li  
**Category**: cs.AI  
**Published**: 2026-02-10  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.08241v1  

#### Abstract
While chain-of-thought (CoT) reasoning has substantially improved multimodal large language models (MLLMs) on complex reasoning tasks, existing approaches largely rely on long textual reasoning trajectories and provide limited mechanisms for learning stable visual attention policies. Our analysis sh...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜

å½“å‰çš„ **Multimodal Large Language Models (MLLMs)** åœ¨å¤æ‚è§†è§‰æ¨ç†ä»»åŠ¡ä¸­è™½ç„¶å…·å¤‡å¼ºå¤§çš„è¯­è¨€æ¨ç†èƒ½åŠ›ï¼ˆå¦‚ Chain-of-Thought, CoTï¼‰ï¼Œä½†åœ¨**è§†è§‰æ³¨æ„åŠ›æœºåˆ¶ä¸Šå­˜åœ¨ä¸¥é‡ç¼ºé™·**ã€‚å…·ä½“è¡¨ç°ä¸ºï¼š

- **æ—©æœŸè§†è§‰å…³æ³¨é”™è¯¯éš¾ä»¥çº æ­£**ï¼šä¸€æ—¦æ¨¡å‹åœ¨æ¨ç†åˆæœŸå°†æ³¨æ„åŠ›æ”¾åœ¨é”™è¯¯çš„å›¾åƒåŒºåŸŸï¼Œåç»­çš„ CoT æ¨ç†è¿‡ç¨‹å¾ˆå°‘èƒ½ä¿®æ­£è¿™ä¸€åå·®ï¼Œå¯¼è‡´â€œé”™è¯¯ä¼ æ’­â€ï¼ˆerror propagationï¼‰ã€‚
- **ç¼ºä¹æœ‰æ•ˆçš„ä¿¡ç”¨åˆ†é…æœºåˆ¶**ï¼ˆcredit assignmentï¼‰ï¼šç°æœ‰çš„è®­ç»ƒç›®æ ‡ï¼ˆå¦‚ç­”æ¡ˆå‡†ç¡®ç‡ã€æ ¼å¼å¥–åŠ±ï¼‰æœªèƒ½ä¸ºè§†è§‰æ³¨æ„åŠ›è¡Œä¸ºæä¾›æ˜ç¡®çš„å­¦ä¹ ä¿¡å·ï¼Œå¯¼è‡´æ¨¡å‹å­¦ä¹ ä¸åˆ°ç¨³å®šã€å¯é çš„è§†è§‰èšç„¦ç­–ç•¥ã€‚

è¯¥é—®é¢˜é™åˆ¶äº† MLLMs åœ¨éœ€è¦ç²¾ç¡®è§†è§‰å®šä½çš„ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå°¤å…¶æ˜¯åœ¨é«˜åˆ†è¾¨ç‡ã€å¤šå¯¹è±¡ã€ä¿¡æ¯å¯†é›†çš„åœºæ™¯ä¸­ã€‚

---

### âœ… æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

ä½œè€…æå‡ºäº†ä¸€ç§åŸºäº **Reinforcement Learning (RL)** çš„æ–°å‹è®­ç»ƒæ¡†æ¶ â€”â€” **SAYO**ï¼Œå…¶æ ¸å¿ƒæ˜¯å¼•å…¥ä¸€ä¸ª **region-level è§†è§‰æ³¨æ„åŠ›å¥–åŠ±æœºåˆ¶**ï¼ˆEntropy-Based Target Attention Rewardï¼‰ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š

1. **è§†è§‰æ³¨æ„åŠ›å¥–åŠ±ï¼ˆVisual Attention-Based Rewardï¼‰**  
   åˆ©ç”¨å¸¦æœ‰ **bounding box æ ‡æ³¨**çš„æ•°æ®ï¼Œè®¡ç®—æ¨¡å‹ç”Ÿæˆ token æ—¶å¯¹ç›®æ ‡è§†è§‰åŒºåŸŸçš„å…³æ³¨ç¨‹åº¦ï¼Œå¹¶æ®æ­¤è®¾è®¡å¥–åŠ±å‡½æ•°ï¼š
   $$
   r_v = \tanh\left(\log\left(\frac{a + \epsilon}{u + \epsilon}\right)\right)
   $$
   å…¶ä¸­ $a$ æ˜¯å¯¹ç›®æ ‡åŒºåŸŸçš„å¹³å‡æ³¨æ„åŠ›æƒé‡ï¼Œ$u$ æ˜¯å¯¹æ•´ä¸ªå›¾åƒçš„å¹³å‡æ³¨æ„åŠ›æƒé‡ã€‚è¯¥å¥–åŠ±é¼“åŠ±æ¨¡å‹åœ¨å…³é”®å†³ç­–ç‚¹æ›´å¤šåœ°å…³æ³¨æ­£ç¡®çš„è§†è§‰åŒºåŸŸã€‚

2. **ç†µé€‰æ‹©æœºåˆ¶ï¼ˆEntropy-Selective Rewardï¼‰**  
   å¹¶éå¯¹æ‰€æœ‰ç”Ÿæˆ token éƒ½æ–½åŠ æ³¨æ„åŠ›å¥–åŠ±ï¼Œè€Œæ˜¯ä»…é’ˆå¯¹**é«˜ç†µ token**ï¼ˆå³æ¨¡å‹ä¸ç¡®å®šæ€§é«˜çš„ tokenï¼‰è¿›è¡Œå¥–åŠ±ã€‚è¿™äº› token å¾€å¾€å¯¹åº”æ¨ç†çš„å…³é”®æ­¥éª¤ï¼Œæ­¤æ—¶å¼ºåˆ¶æ¨¡å‹â€œçœ‹å›¾éªŒè¯â€ï¼ˆLook-to-Verifyï¼‰å¯æœ‰æ•ˆæŠ‘åˆ¶å¹»è§‰å’Œè¯­è¨€å…ˆéªŒä¾èµ–ã€‚

3. **æ— éœ€å¤–éƒ¨æç¤ºæˆ–æ¨ç†æ—¶å¹²é¢„**  
   ä¸éœ€è¦äººå·¥è®¾è®¡ visual prompt æˆ–è¿è¡Œæ—¶è¿­ä»£åæ€çš„æ–¹æ³•ä¸åŒï¼ŒSAYO åœ¨è®­ç»ƒé˜¶æ®µé€šè¿‡ RL å¼ºåŒ–æ³¨æ„åŠ›è¡Œä¸ºï¼Œ**æ¨ç†æ—¶å®Œå…¨æ— éœ€é¢å¤–æ“ä½œ**ï¼Œä¿æŒé«˜æ•ˆæ€§å’Œé€šç”¨æ€§ã€‚

---

### âœ… ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ ViP, ReFocus, Reflection-Vï¼‰ | SAYO |
|------|----------------------------------------|------|
| æ˜¯å¦ä¾èµ–å¤–éƒ¨å·¥å…· | æ˜¯ï¼ˆéœ€æ ‡æ³¨/ç¼–è¾‘å›¾åƒï¼‰ | å¦ |
| æ˜¯å¦ä¾èµ–æ¨ç†æ—¶æç¤ºå·¥ç¨‹ | æ˜¯ï¼ˆå¦‚ reflection, look-backï¼‰ | å¦ |
| æ˜¯å¦ç›´æ¥ä¼˜åŒ–æ³¨æ„åŠ›è¡Œä¸º | é—´æ¥ï¼ˆé€šè¿‡ä»»åŠ¡æ€§èƒ½åé¦ˆï¼‰ | ç›´æ¥ï¼ˆæ˜¾å¼æ³¨æ„åŠ›å¥–åŠ±ï¼‰ |
| æ³›åŒ–èƒ½åŠ› | å—é™äºç‰¹å®šæµç¨‹ | è·¨ä»»åŠ¡å¼ºæ³›åŒ–ï¼ˆæ•°å­¦ã€å›¾è¡¨ã€ä¸€èˆ¬è§†è§‰ï¼‰ |
| è®­ç»ƒæ•ˆç‡ | å¤šæ•°ä¸ºç›‘ç£å¾®è°ƒ | åŸºäº GRPO çš„å¼ºåŒ–å­¦ä¹ ï¼Œæ›´é€‚é…ç­–ç•¥ä¼˜åŒ– |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šSAYO å°†è§†è§‰æ³¨æ„åŠ›å»ºæ¨¡ä¸ºå¯å­¦ä¹ çš„ç­–ç•¥ï¼Œè€Œéä¾èµ–åå¤„ç†æˆ–å¤–éƒ¨å¹²é¢„ï¼Œå®ç°äº†ç«¯åˆ°ç«¯ã€ç¨³å®šçš„è§†è§‰æ¥åœ°èƒ½åŠ›æå‡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

| ç±»åˆ« | æ•°æ®é›† | æè¿° |
|------|-------|------|
| **ä¸€èˆ¬è§†è§‰æ¨ç†** | M3CoT, V*, MMStar, MME-RealWorld Lite | åŒ…å«å¤šæ­¥æ¨ç†ã€çœŸå®ä¸–ç•Œå¤æ‚å›¾åƒç†è§£ä»»åŠ¡ |
| **æ•°å­¦è§†è§‰æ¨ç†** | We-Math, MathVision | å›¾åƒä¸­çš„å‡ ä½•é¢˜ã€æ•°å­¦å›¾è¡¨ç†è§£ |
| **ç»“æ„åŒ–å›¾è¡¨ç†è§£** | ChartQA, AI2D, CharXiv | æŠ˜çº¿å›¾ã€æŸ±çŠ¶å›¾ã€ç§‘å­¦æ’å›¾ç­‰å›¾è¡¨é—®ç­” |
| **è®­ç»ƒæ•°æ®æ¥æº** | GQA + ReFocus_Data | ~20k æ ·æœ¬ï¼Œç”¨äºæ„å»ºå¸¦è§†è§‰åŒºåŸŸæ ‡æ³¨çš„ RL è®­ç»ƒæ•°æ® |

---

### âš™ï¸ å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

- **åŸºç¡€æ¨¡å‹**ï¼š
  - `Qwen3-VL-4B/8B/30B`
  - `InternVL3.5-8B`

- **è®­ç»ƒæ–¹æ³•**ï¼š
  - ä½¿ç”¨ **Group Relative Policy Optimization (GRPO)** è¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒ
  - è®­ç»ƒå‘¨æœŸï¼š4 epochsï¼Œ6Ã—NVIDIA H200 GPU
  - æ³¨æ„åŠ›å¥–åŠ±ä»…ä½œç”¨äº **top 30% é«˜ç†µ token**

- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - ä¸»è¦æŒ‡æ ‡ï¼šå„ benchmark ä¸Šçš„ **accuracy**
  - è¾…åŠ©åˆ†ææŒ‡æ ‡ï¼š
    - **Target Attention Score (TAS)**ï¼šè¡¡é‡æ¨¡å‹å¯¹ç›®æ ‡åŒºåŸŸçš„æ³¨æ„åŠ›é›†ä¸­ç¨‹åº¦
    - **Attention Advantage Score (Ra)**ï¼šå½’ä¸€åŒ–çš„æ³¨æ„åŠ›ä¼˜åŠ¿å¾—åˆ†

- **Prompt è®¾è®¡**ï¼š
  - è®­ç»ƒæ—¶è¦æ±‚æ¨¡å‹åœ¨ `<think>` ä¸­è¿›è¡Œå†…éƒ¨æ¨ç†ï¼Œå¼ºè°ƒå…³æ³¨ç›®æ ‡åŒºåŸŸ
  - æµ‹è¯•æ—¶ç»Ÿä¸€ä½¿ç”¨æ ‡å‡†æ€ç»´é“¾æ¨¡æ¿

---

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”

| ç±»å‹ | åŸºçº¿æ¨¡å‹ |
|------|---------|
| **é—­æºæ¨¡å‹** | GPT-4o, Gemini 2.5 Pro |
| **å¼€æºé€šç”¨ MLLMs** | Qwen3-VL, InternVL3.5, Kimi-VL-16B |
| **å¼€æºæ¨ç†ä¸“ç”¨ MLLMs** | OpenVLThinker-7B, Semantic-back-7B, ViGoRL, NoisyRollout-7B, R1-Onevision-7B |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| Model | Avg Score |
|-------|-----------|
| **GPT-4o** | â€“ |
| **SAYO-Qwen-8B** | **64.03** âœ…ï¼ˆå¼€æºæœ€ä½³ï¼‰ |
| Qwen3-VL-8B | 59.64 |
| OpenVLThinker-7B | 59.79 |
| NoisyRollout-7B | 61.80 |
| **SAYO-Qwen-4B** | **62.17**ï¼ˆå°æ¨¡å‹è¶…è¶Šå¤§æ¨¡å‹ï¼‰ |

> ğŸ’¡ **äº®ç‚¹çªç ´**ï¼š
> - SAYO-Qwen-8B åœ¨ **MMStar** ä¸Šè¶…è¿‡ GPT-4o å’Œ Kimi-VL-16B
> - åœ¨ **We-Math** å’Œ **MathVision** ä¸Šæ˜¾è‘—é¢†å…ˆï¼Œå°½ç®¡æœªä½¿ç”¨æ•°å­¦æ•°æ®è®­ç»ƒ â†’ æ˜¾ç¤ºå‡ºå¼ºå¤§è·¨åŸŸæ³›åŒ–èƒ½åŠ›

---

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

| å¯¹æ¯”ç»´åº¦ | ç»“æœ |
|--------|------|
| vs. é—­æºæ¨¡å‹ | åœ¨éƒ¨åˆ†ä»»åŠ¡ï¼ˆå¦‚ MMStarï¼‰ä¸Šä¼˜äº GPT-4o |
| vs. å¼€æºé€šç”¨æ¨¡å‹ | å¹³å‡æå‡çº¦ **+4.4 pts**ï¼ˆQwen-8B â†’ SAYO-Qwen-8Bï¼‰ |
| vs. æ¨ç†ä¸“ç”¨æ¨¡å‹ | å…¨é¢ä¼˜äº OpenVLThinkerã€ViGoRL ç­‰ï¼Œä¸”ä¸ç‰ºç‰²é€šç”¨æ€§ |
| vs. ä¸åŒè§„æ¨¡æ¨¡å‹ | SAYO-Qwen-4B > æ‰€æœ‰å…¶ä»– 7B/8B æ¨¡å‹ï¼Œæ¥è¿‘ 30B è¡¨ç° |

---

### ğŸ”§ æ¶ˆèå®éªŒç»“æœï¼ˆTable 2 & Table 3ï¼‰

#### âœ… æ³¨æ„åŠ›å¥–åŠ±çš„æœ‰æ•ˆæ€§ï¼ˆTable 2ï¼‰

| è®¾ç½® | Avg æå‡ï¼ˆvs. Baseï¼‰ |
|------|------------------|
| Only Accuracy Reward | +1.28 |
| Only Attention Reward | **+4.32** âœ… |
| Combined Reward | **+4.63** |

> â— ç»“è®ºï¼š**æ³¨æ„åŠ›å¥–åŠ±æ¯”ç­”æ¡ˆå‡†ç¡®æ€§å¥–åŠ±æ›´é‡è¦**ï¼Œè¯´æ˜å½“å‰ç“¶é¢ˆåœ¨äºâ€œçœ‹è§â€ï¼Œè€Œéâ€œæ¨ç†â€ã€‚

#### âœ… é«˜ç†µ token é€‰æ‹©çš„é‡è¦æ€§ï¼ˆTable 3ï¼‰

| Token Selection | Avg Score (Qwen-8B) |
|------------------|--------------------|
| All tokens | 60.51 |
| **Top 30% high-entropy tokens** | **63.96** âœ… |
| Top 20% / Top 40% | â†“ æ€§èƒ½ä¸‹é™ï¼ˆè§ Table 6ï¼‰ |

> âœ… æœ€ä½³èŒƒå›´ä¸º **top 30%**ï¼Œå¤ªå°‘ä¼šé—æ¼å…³é”®ä¿¡æ¯ï¼Œå¤ªå¤šåˆ™å¼•å…¥å™ªå£°ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ğŸ¯ ä¸»è¦å‘ç°

1. **MLLMs çš„è§†è§‰æ³¨æ„åŠ›ä¸ç¨³å®šæ˜¯æ¨ç†å¤±è´¥çš„ä¸»å› **  
   åˆ†æè¡¨æ˜ï¼Œ**æ³¨æ„åŠ›é”™ä½ï¼ˆmisalignmentï¼‰ä¸é”™è¯¯é¢„æµ‹é«˜åº¦ç›¸å…³**ï¼Œä¸”æ—©æœŸé”™è¯¯å‡ ä¹ä¸ä¼šè¢«åç»­æ¨ç†çº æ­£ã€‚

2. **ç°æœ‰ RL æ–¹æ³•æœªèƒ½è§£å†³è§†è§‰æ³¨æ„åŠ›å­¦ä¹ é—®é¢˜**  
   å³ä½¿ç»è¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ï¼Œä¸»æµæ¨¡å‹ä»è¡¨ç°å‡ºä½ Target Attention Scoreï¼ˆTASï¼‰ï¼Œè¯´æ˜ä¼ ç»Ÿ RL ç›®æ ‡æ— æ³•æœ‰æ•ˆå¼•å¯¼è§†è§‰èšç„¦ã€‚

3. **æ˜¾å¼çš„æ³¨æ„åŠ›å¥–åŠ±èƒ½è§£é”æ¨¡å‹æ½œåœ¨æ¨ç†èƒ½åŠ›**  
   å½“è¾“å…¥ä¿¡å·ï¼ˆå³â€œçœ‹åˆ°çš„å†…å®¹â€ï¼‰æ­£ç¡®æ—¶ï¼Œé¢„è®­ç»ƒå¥½çš„è¯­è¨€æ¨¡å‹å³å¯å®Œæˆé«˜è´¨é‡æ¨ç†ã€‚SAYO çš„æœ¬è´¨æ˜¯â€œ**ä¿®å¤è¾“å…¥ç«¯çš„æ„ŸçŸ¥ç“¶é¢ˆ**â€ã€‚

4. **é«˜ç†µ token æ˜¯æ³¨æ„åŠ›å¹²é¢„çš„æœ€ä½³æ—¶æœº**  
   æ­¤æ—¶æ¨¡å‹æœ€ä¸ç¡®å®šï¼Œå¼ºåˆ¶å…¶å‚è€ƒè§†è§‰è¯æ®å¯å®ç°â€œ**Look-to-Verify**â€æœºåˆ¶ï¼ŒæŠ‘åˆ¶è¯­è¨€å¹»è§‰ã€‚

5. **æ–¹æ³•å…·æœ‰å¼ºæ³›åŒ–æ€§**  
   å°½ç®¡è®­ç»ƒæ•°æ®ä¸å«æ•°å­¦é¢˜ï¼ŒSAYO åœ¨ We-Math å’Œ MathVision ä¸Šå¤§å¹…æå‡ â†’ è¯æ˜å…¶å­¦åˆ°çš„æ˜¯**é€šç”¨çš„è§†è§‰è§£æèƒ½åŠ›**ï¼Œè€Œéè®°å¿†æ¨¡å¼ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

- **ä¾èµ–æ ‡æ³¨æ•°æ®**ï¼šéœ€è¦ bounding box çº§åˆ«çš„è§†è§‰æ ‡æ³¨æ¥å®šä¹‰â€œç›®æ ‡åŒºåŸŸâ€ï¼Œé™åˆ¶äº†åœ¨æ— æ ‡æ³¨æ•°æ®ä¸Šçš„åº”ç”¨ã€‚
- **è®¡ç®—æˆæœ¬è¾ƒé«˜**ï¼šRL è®­ç»ƒæ¯” SFT æ›´è€—èµ„æºï¼Œä¸é€‚åˆè½»é‡çº§éƒ¨ç½²ã€‚
- **å¯¹æä½ç†µ token å…³æ³¨ä¸è¶³**ï¼šæŸäº›å…³é”®åˆ¤æ–­å¯èƒ½å‘ç”Ÿåœ¨ä½ä¸ç¡®å®šæ€§é˜¶æ®µï¼Œå½“å‰ç­–ç•¥å¯èƒ½å¿½ç•¥ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **å¼±ç›‘ç£/è‡ªç›‘ç£æ³¨æ„åŠ›å¥–åŠ±è®¾è®¡**  
   æ¢ç´¢æ— éœ€äººå·¥æ ‡æ³¨ bounding box çš„æ–¹å¼æ„å»ºæ³¨æ„åŠ›å¥–åŠ±ä¿¡å·ï¼ˆå¦‚åˆ©ç”¨ CLIP æˆ– SAM è‡ªåŠ¨ç”Ÿæˆå€™é€‰åŒºåŸŸï¼‰ã€‚

2. **åŠ¨æ€è°ƒæ•´ç†µé€‰æ‹©é˜ˆå€¼**  
   æ ¹æ®ä»»åŠ¡ç±»å‹è‡ªåŠ¨è°ƒèŠ‚å‚ä¸å¥–åŠ±çš„ token æ¯”ä¾‹ï¼Œè¿›ä¸€æ­¥æå‡è®­ç»ƒæ•ˆç‡ã€‚

3. **æ‰©å±•è‡³è§†é¢‘æˆ–å¤šå¸§æ¨ç†åœºæ™¯**  
   å°† region-level attention reward å»¶ä¼¸åˆ°æ—¶ç©ºç»´åº¦ï¼Œå¢å¼ºå¯¹åŠ¨æ€å†…å®¹çš„ç†è§£èƒ½åŠ›ã€‚

4. **ä¸å…¶ä»–è®¤çŸ¥æœºåˆ¶ç»“åˆ**  
   å¦‚æ•´åˆ memoryã€planning ç­‰æ¨¡å—ï¼Œå½¢æˆæ›´å®Œæ•´çš„â€œè§†è§‰æ€è€ƒâ€ç³»ç»Ÿã€‚

---

## âœ… æ€»ç»“ä¸€å¥è¯

> **SAYO é€šè¿‡å¼•å…¥åŸºäºé«˜ç†µ token çš„ region-level è§†è§‰æ³¨æ„åŠ›å¥–åŠ±ï¼Œåœ¨æ— éœ€æ¨ç†æ—¶å¹²é¢„çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº† MLLMs çš„è§†è§‰èšç„¦èƒ½åŠ›å’Œè·¨ä»»åŠ¡æ¨ç†æ€§èƒ½ï¼Œæ­ç¤ºäº†â€œç²¾å‡†æ„ŸçŸ¥â€æ‰æ˜¯é‡Šæ”¾å¤šæ¨¡æ€æ¨¡å‹æ¨ç†æ½œåŠ›çš„å…³é”®ç“¶é¢ˆã€‚**

</details>

---

### 14. [SCOUT-RAG: Scalable and Cost-Efficient Unifying Traversal for Agentic Graph-RAG over Distributed Domains](https://arxiv.org/abs/2602.08400)

**Authors**: Longkun Li, Yuanben Zou, Jinghan Wu, Yuqing Wen, Jing Li, Hangwei Qian, Ivor Tsang  
**Category**: cs.AI  
**Published**: 2026-02-10  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.08400v1  

#### Abstract
Graph-RAG improves LLM reasoning using structured knowledge, yet conventional designs rely on a centralized knowledge graph. In distributed and access-restricted settings (e.g., hospitals or multinational organizations), retrieval must select relevant domains and appropriate traversal depth without ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠSCOUT-RAG: Scalable and Cost-Efficient Unifying Traversal for Agentic Graph-RAG over Distributed Domainsã€‹æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **Graph-RAG** ç³»ç»Ÿä¾èµ–äºé›†ä¸­å¼çš„å…¨å±€çŸ¥è¯†å›¾è°±ï¼ˆKnowledge Graphï¼‰ï¼Œä½†åœ¨ç°å®åœºæ™¯ä¸­ï¼Œæ•°æ®é€šå¸¸åˆ†å¸ƒåœ¨å¤šä¸ªç‹¬ç«‹ç»„ç»‡ä¹‹é—´ï¼ˆå¦‚åŒ»é™¢ã€è·¨å›½ä¼ä¸šï¼‰ï¼Œç”±äºéšç§ã€æ‰€æœ‰æƒæˆ–æ³•è§„é™åˆ¶ï¼Œæ— æ³•å…±äº«åŸå§‹æ•°æ®ã€‚è¿™ç§**åˆ†å¸ƒå¼ã€å—é™è®¿é—®**çš„ç¯å¢ƒå¯¼è‡´ï¼š
- æ— æ³•æ„å»ºç»Ÿä¸€çš„çŸ¥è¯†å›¾ï¼›
- è·¨åŸŸæ£€ç´¢æˆæœ¬é«˜ï¼ˆå»¶è¿Ÿã€APIè´¹ç”¨ï¼‰ï¼›
- éš¾ä»¥åˆ¤æ–­åº”å‘å“ªäº›é¢†åŸŸå‘èµ·æŸ¥è¯¢ã€‚

ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ supervised domain routerï¼‰ä¾èµ–æ ‡æ³¨æ•°æ®è®­ç»ƒè·¯ç”±æ¨¡å‹ï¼Œåœ¨å†·å¯åŠ¨æˆ–éšç§æ•æ„Ÿåœºæ™¯ä¸‹ä¸å¯è¡Œã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šSCOUT-RAG
æå‡º **SCOUT-RAG** â€”â€” ä¸€ç§**åˆ†å±‚çš„ agentic æ¶æ„**ï¼Œç”¨äºåœ¨åˆ†å¸ƒå¼çŸ¥è¯†åŸŸä¸Šå®ç°å¯æ‰©å±•ä¸”æˆæœ¬é«˜æ•ˆçš„ **Agentic Graph-RAG** æ£€ç´¢ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **æ— éœ€è®­ç»ƒçš„ domain relevance ä¼°è®¡**  
   åˆ©ç”¨ä¸‰ç§ä¿¡å·è¿›è¡Œæ— ç›‘ç£ç›¸å…³æ€§æ‰“åˆ†ï¼š
   - **Semantic similarity**ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰
   - **Knowledge richness**ï¼ˆçŸ¥è¯†ä¸°å¯Œåº¦ï¼ŒåŸºäºæŠ¥å‘Šæ•°é‡å½’ä¸€åŒ–ï¼‰
   - **Historical performance**ï¼ˆå†å²é—®ç­”è´¨é‡ï¼‰

2. **å»ä¸­å¿ƒåŒ–çš„å¤šè·³æ£€ç´¢å†³ç­–æœºåˆ¶**  
   å°†æ¯ä¸ª domain è§†ä¸ºä¸€ä¸ªéƒ¨åˆ†å¯è§‚æµ‹å­å›¾ï¼ŒåŠ¨æ€å†³å®šæ˜¯å¦è¿›è¡Œæœ¬åœ°æ¢ç´¢ï¼ˆlocal traversalï¼‰è¿˜æ˜¯è·¨åŸŸæ‰©å±•ï¼ˆcross-domain expansionï¼‰ã€‚

3. **å°†æ£€ç´¢å»ºæ¨¡ä¸ºåºåˆ—å†³ç­–è¿‡ç¨‹ï¼ˆSequential Decision Processï¼‰**  
   å¼•å…¥å››ä¸ªåä½œ agent å®ç°é—­ç¯æ§åˆ¶ï¼š
   - **Domain Relevance Assessment Agent (DRAA)**ï¼šåˆæ­¥ç­›é€‰ç›¸å…³ domain
   - **Partial Answer Generation Agent (PAGA)**ï¼šæ‰§è¡Œå±€éƒ¨æ£€ç´¢
   - **Overall Answer Synthesis Agent (OASA)**ï¼šåˆæˆåˆå§‹ç­”æ¡ˆ
   - **Answer Quality Assessment Agent (AQAA)**ï¼šè¯„ä¼°å½“å‰ç­”æ¡ˆå¹¶æŒ‡å¯¼åç»­åŠ¨ä½œ

4. **è‡ªé€‚åº”æ·±åº¦-å¹¿åº¦æ¢ç´¢ç­–ç•¥ï¼ˆAdaptive Depth-Breadth Explorationï¼‰**  
   æ ¹æ®ç­”æ¡ˆè´¨é‡åé¦ˆåŠ¨æ€é€‰æ‹©ï¼š
   - **Depth æ‰©å±•**ï¼šæ·±å…¥ HIGH-relevance domain è¡¥å……ç»†èŠ‚
   - **Breadth æ‰©å±•**ï¼šæ¿€æ´» POTENTIAL domain è·å–æ–°è§†è§’
   - **Hybrid æˆ–ç»ˆæ­¢**

5. **å¤šçº§å®‰å…¨æœºåˆ¶ä¿éšœå¯é æ€§**
   - æ—¶é—´é¢„ç®—å¼ºåˆ¶ä¸­æ–­ï¼ˆtime-budget enforcementï¼‰
   - æœ€ä½³ç­”æ¡ˆè¿½è¸ªï¼ˆbest-answer trackingï¼‰
   - å¹¶è¡Œåè°ƒæœºåˆ¶é˜²æ­¢çº§è”å¤±è´¥

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **éƒ¨ç½²çµæ´»æ€§** | æ”¯æŒå†·å¯åŠ¨ã€æ— éœ€æ ‡æ³¨æ•°æ®ï¼Œé€‚ç”¨äºéšç§å—é™åœºæ™¯ |
| **æˆæœ¬æ•ˆç‡** | æ˜¾è‘—å‡å°‘è·¨åŸŸè°ƒç”¨æ¬¡æ•°ã€token æ¶ˆè€—å’Œå»¶è¿Ÿ |
| **å¯æ‰©å±•æ€§** | å¯å¤„ç†å¤šè¾¾ 40 ä¸ª domain çš„å¤æ‚æŸ¥è¯¢ |
| **ç­”æ¡ˆè´¨é‡** | æ¥è¿‘ centralized DRIFT çš„æ€§èƒ½ï¼Œè¿œè¶… naive local/global æ–¹æ³• |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- ä½¿ç”¨æ¥è‡ª **45 ä¸ªå›½å®¶çš„ Wikipedia æ–‡ç« **ä½œä¸ºæ¨¡æ‹Ÿ domain æ•°æ®æºã€‚
- æ¯ä¸ª domain æ„å»ºäº†ä¸€ä¸ªå›¾ç»“æ„çŸ¥è¯†åº“ï¼ŒåŒ…å« 9â€“77 ä¸ª community reportsã€‚
- è®¾è®¡äº† **100 ä¸ªè‡ªç„¶è¯­è¨€æŸ¥è¯¢**ï¼Œå…¶ä¸­ 89 ä¸ªè¢«æ‰€æœ‰æ–¹æ³•æœ‰æ•ˆå›ç­”ã€‚
- æŸ¥è¯¢æŒ‰è¦†ç›– domain æ•°é‡åˆ†ä¸ºäº”ç±»ï¼š
  - å• domainï¼ˆ1 å›½ï¼‰
  - å°è§„æ¨¡ multi-domainï¼ˆ5 å›½ï¼‰
  - ä¸­ç­‰ï¼ˆ10 å›½ï¼‰
  - å¤§è§„æ¨¡ï¼ˆ20 å›½ï¼‰
  - è¶…å¤§è§„æ¨¡ï¼ˆ40 å›½ï¼‰

### âš™ï¸ å®éªŒè®¾ç½®
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š
  - GPU: NVIDIA RTX 3070 (9GB VRAM)
  - CPU: 16 æ ¸ AMD EPYC 7B12
  - å†…å­˜: 31 GB
- **æ—¶é—´é¢„ç®—ä¸Šé™**ï¼š300 ç§’
- æ‰€æœ‰æ–¹æ³•å‡è¿è¡Œç›¸åŒç¯å¢ƒä»¥ä¿è¯å…¬å¹³æ¯”è¾ƒ

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡ï¼ˆç”± GPT-4o ä½œä¸º judge æ‰“åˆ†ï¼Œ0â€“100 åˆ†åˆ¶ï¼‰
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Comprehensiveness (Comp.)** | æ˜¯å¦æ¶µç›–æ ¸å¿ƒæ¦‚å¿µä¸æ–¹é¢ |
| **Diversity (Div.)** | æ¥æºå¤šæ ·æ€§ä¸è§‚ç‚¹å¹¿åº¦ |
| **Empowerment (Emp.)** | æ˜¯å¦æä¾›å¯æ“ä½œæ´å¯Ÿä¸è¿›ä¸€æ­¥æ¢ç´¢æ”¯æŒ |
| **Directness (Dir.)** | å›ç­”æ˜¯å¦ç®€æ´æ¸…æ™° |
| **Overall Quality** | ä¸Šè¿°å››é¡¹å¹³å‡å¾—åˆ† |
| **Time (s)** | æ€»æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰ |
| **Token Count** | æ€»å¤„ç† token æ•°é‡ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºä¸¤ç±»éƒ¨ç½²èŒƒå¼ï¼š

#### âœ… Centralized Settingï¼ˆæ‰€æœ‰æ•°æ®åˆå¹¶ä¸ºå•ä¸€ domainï¼‰
1. **GraphRAGLocal**ï¼šä»…å±€éƒ¨æ£€ç´¢ï¼ˆentity-levelï¼‰
2. **GraphRAGGlobal**ï¼šä»…å…¨å±€æ£€ç´¢ï¼ˆcommunity summaryï¼‰
3. **GraphRAGDRIFT-c**ï¼šå…ˆ global åä¸¤æ¬¡ refineï¼ˆæ¯è½® 3 æ¬¡ follow-upï¼‰

#### âœ… Decentralized Settingï¼ˆæ•°æ®åˆ†æ•£åœ¨ 45 ä¸ª domainï¼‰
1. **GraphRAGDRIFT-dec**ï¼šæ¯ä¸ª domain ç‹¬ç«‹è¿è¡Œ DRIFTï¼Œæœ€åèåˆç»“æœï¼ˆè¿‘ä¹ç©·ä¸¾ï¼‰
2. **SCOUT-RAG (Ours)**ï¼šæå‡ºçš„ agent-based åŠ¨æ€è°ƒåº¦æ¡†æ¶

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| Method | Comp. | Div. | Emp. | Dir. | **Overall** | **Time (s)** | **Token** |
|--------|-------|------|------|------|-------------|--------------|-----------|
| GraphRAGLocal | 65 | 55 | 35 | 58 | 53 | 34.40 | 11,223 |
| GraphRAGGlobal | 60 | 50 | 30 | 55 | 49 | 45.89 | 640,574 |
| GraphRAGDRIFT-c | 72 | 70 | 45 | 63 | **63** | 231.85 | 693,731 |
| GraphRAGDRIFT-dec | 90 | 88 | 75 | 88 | **85** | 414.88 | 879,911 |
| **SCOUT-RAG (Ours)** | 65 | 60 | 40 | 58 | **56** | **75.32** | **159,169** |

### ğŸ” å¯¹æ¯”åˆ†æ
- **è´¨é‡æ–¹é¢**ï¼š
  - SCOUT-RAG è¾¾åˆ° **56 åˆ†**ï¼Œè™½ä½äº DRIFT-decï¼ˆ85ï¼‰ï¼Œä½†æ˜¾è‘—ä¼˜äº GraphRAGGlobalï¼ˆ49ï¼‰å’Œ GraphRAGLocalï¼ˆ53ï¼‰ã€‚
  - ä¸ centralized DRIFT-cï¼ˆ63ï¼‰ç›¸æ¯”ä»…ä½ 7 åˆ†ï¼Œå·®è·è¾ƒå°ï¼Œè¯´æ˜å…¶åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹ä»èƒ½ä¿æŒè¾ƒé«˜æ¨ç†èƒ½åŠ›ã€‚
- **æˆæœ¬æ•ˆç‡æ–¹é¢**ï¼š
  - ç›¸æ¯” **GraphRAGDRIFT-dec**ï¼š
    - å‡å°‘ **81.8% æ—¶é—´**ï¼ˆ75.32s vs 414.88sï¼‰
    - å‡å°‘ **81.9% token**ï¼ˆ159k vs 879kï¼‰
  - ç›¸æ¯” **GraphRAGDRIFT-c**ï¼š
    - æ—¶é—´å‡å°‘ **67.5%**
    - Token å‡å°‘ **77.1%**
- **å¤šæ ·æ€§è¡¨ç°çªå‡º**ï¼š
  - SCOUT-RAG åœ¨ **Diversity (60)** ä¸Šè¶…è¿‡æ‰€æœ‰ centralized æ–¹æ³•ï¼ˆæœ€é«˜ä¸º DRIFT-c çš„ 70ï¼‰ï¼Œæ¥è¿‘ decentralized DRIFT-decï¼ˆ88ï¼‰ï¼Œå¾—ç›Šäºå±‚çº§åŒ– domain æ¿€æ´»æœºåˆ¶ã€‚

### ğŸ“‰ æˆæœ¬-æ€§èƒ½æƒè¡¡å›¾ï¼ˆFigure 3ï¼‰
- SCOUT-RAG åœ¨å‰ 120 ç§’å†…å¿«é€Ÿæå‡è´¨é‡ï¼Œçº¦ 180 ç§’è¶‹äºç¨³å®šï¼Œè¾¹é™…æ”¶ç›Šé€’å‡ã€‚
- åœ¨ 300 ç§’é¢„ç®—å†…è¾¾åˆ°æ”¶æ•›ï¼Œé€‚åˆå®é™…éƒ¨ç½²ã€‚
- DRIFT-c æ€§èƒ½æ¥è¿‘ä½†è€—æ—¶æ›´é•¿ï¼›DRIFT-dec æœ€ç»ˆæ€§èƒ½æœ€å¼ºä½†èµ„æºæ¶ˆè€—æé«˜ã€‚

### ğŸ” æ¶ˆèå®éªŒä¸æ¡ˆä¾‹ç ”ç©¶ï¼ˆFigure 4ï¼‰
- **æ¡ˆä¾‹ï¼šâ€œMade in Italyâ€ è®¤è¯å¯¹æ—¶å°šäº§ä¸š SME çš„å½±å“**
  - Stage Iï¼šå‡†ç¡®è¯†åˆ« Italyã€Sloveniaã€Malta ç­‰é«˜ç›¸å…³ domain
  - Stage IIï¼šç”Ÿæˆåˆæ­¥ç»¼åˆå›ç­”ï¼Œä½†ç¼ºä¹å…·ä½“æ”¿ç­–ä¸å›½é™…åè®®ç»†èŠ‚
  - Stage IIIï¼šé€šè¿‡ä¸¤è½® refinement è¡¥å…… Slovenia å’Œ Malta çš„è®¤è¯ä½“ç³»å¯¹æ¯”ï¼Œè´¨é‡ä» 0.675 æå‡è‡³ **0.725**
  - ç¬¬ä¸‰è½® breadth æ‰©å±•å¼•å…¥å™ªå£°ï¼Œè´¨é‡ä¸‹é™ â†’ **best-answer tracking æœºåˆ¶æˆåŠŸä¿ç•™æœ€ä¼˜ç‰ˆæœ¬**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **SCOUT-RAG å®ç°äº†é«˜è´¨é‡ä¸ä½æˆæœ¬ä¹‹é—´çš„è‰¯å¥½å¹³è¡¡**  
   åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹ï¼Œä»¥ä¸åˆ° 1/5 çš„èµ„æºæ¶ˆè€—ï¼Œè¾¾åˆ°äº†æ¥è¿‘ centralized DRIFT çš„æ€§èƒ½æ°´å¹³ã€‚

2. **agent-based æ¶æ„é€‚åˆåˆ†å¸ƒå¼ Graph-RAG åœºæ™¯**  
   é€šè¿‡å°†æ£€ç´¢è§†ä¸ºåºåˆ—å†³ç­–é—®é¢˜ï¼Œç³»ç»Ÿèƒ½å¤Ÿæ ¹æ®ä¸­é—´åé¦ˆåŠ¨æ€è°ƒæ•´ç­–ç•¥ï¼Œé¿å…ç›²ç›®ç©·ä¸¾ã€‚

3. **æ— éœ€è®­ç»ƒçš„ç›¸å…³æ€§è¯„ä¼°æ˜¯å¯è¡Œä¸”æœ‰æ•ˆçš„**  
   ç»“åˆ semanticã€evidentialã€behavioral ä¸‰ç±»ä¿¡å·å¯åœ¨æ— æ ‡æ³¨æ•°æ®æƒ…å†µä¸‹å®ç°å¯é  domain rankingã€‚

4. **adaptive depth-breadth æ§åˆ¶æ˜¾è‘—æå‡æ•ˆç‡**  
   åŠ¨æ€åˆ‡æ¢â€œæ·±æŒ–â€ä¸â€œæ‹“å®½â€æ¨¡å¼ï¼Œæ—¢èƒ½è¡¥å…¨å…³é”®ä¿¡æ¯ï¼Œåˆèƒ½é¿å…æ— æ•ˆæ¢ç´¢ã€‚

5. **best-answer tracking æé«˜é²æ£’æ€§**  
   é˜²æ­¢åæœŸå› å™ªå£°æ£€ç´¢å¯¼è‡´ç­”æ¡ˆé€€åŒ–ï¼Œç¡®ä¿è¾“å‡ºæœ€ä¼˜è´¨ç»“æœã€‚

### âš ï¸ å±€é™æ€§
- å½“ query æ‰€éœ€ä¿¡æ¯é«˜åº¦åˆ†æ•£äºå¤šä¸ª low-relevance domain æ—¶ï¼Œå¯èƒ½é—æ¼é‡è¦è¯æ®ï¼ˆretrieval regretï¼‰ã€‚
- å½“å‰ historical performance ä¾èµ–å†å²æŸ¥è¯¢ç§¯ç´¯ï¼Œåœ¨å…¨æ–° domain ä¸Šæ•ˆæœæœ‰é™ã€‚
- agent é—´é€šä¿¡å¼€é”€æœªå®Œå…¨å»ºæ¨¡ï¼Œæç«¯å¹¶å‘ä¸‹å¯èƒ½å­˜åœ¨åŒæ­¥ç“¶é¢ˆã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å¼•å…¥è½»é‡çº§ reinforcement learning ä¼˜åŒ–ç­–ç•¥é€‰æ‹©æ¨¡å—ï¼›
- æ¢ç´¢è·¨ domain çš„è”åˆ embedding space ä»¥å¢å¼ºè¯­ä¹‰åŒ¹é…ï¼›
- æ”¯æŒ streaming updates ä¸å¢é‡å­¦ä¹ ï¼Œä½¿ç³»ç»ŸæŒç»­è¿›åŒ–ï¼›
- æ‰©å±•è‡³éæ–‡æœ¬å‹ knowledge graphï¼ˆå¦‚ç”Ÿç‰©åŒ»å­¦ã€é‡‘èå›¾è°±ï¼‰ã€‚

---

## æ€»ç»“
> **SCOUT-RAG æ˜¯é¦–ä¸ªå°† agentic AI ä¸åˆ†å¸ƒå¼ Graph-RAG æ·±åº¦ç»“åˆçš„æ¡†æ¶**ï¼Œå®ƒåœ¨ä¸ç‰ºç‰²å¤ªå¤šæ€§èƒ½çš„å‰æä¸‹ï¼Œå®ç°äº†é«˜è¾¾ **80%+ çš„æˆæœ¬èŠ‚çº¦**ï¼Œä¸ºéšç§æ•æ„Ÿã€èµ„æºå—é™ã€å¤šç»„ç»‡ååŒçš„çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆã€‚å…¶è®¾è®¡æ€æƒ³å¯¹æœªæ¥çš„è”é‚¦å¼ RAGã€è¾¹ç¼˜æ™ºèƒ½é—®ç­”ç³»ç»Ÿå…·æœ‰é‡è¦å¯å‘æ„ä¹‰ã€‚

</details>

---

### 15. [SparseEval: Efficient Evaluation of Large Language Models by Sparse Optimization](https://arxiv.org/abs/2602.07909)

**Authors**: Taolin Zhang, Hang Guo, Wang Lu, Tao Dai, Shu-Tao Xia, Jindong Wang  
**Category**: cs.CL  
**Published**: 2026-02-10  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.07909v1  

#### Abstract
As large language models (LLMs) continue to scale up, their performance on various downstream tasks has significantly improved. However, evaluating their capabilities has become increasingly expensive, as performing inference on a large number of benchmark samples incurs high computational costs. In...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# SparseEval: Efficient Evaluation of Large Language Models by Sparse Optimization â€”â€” è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
éšç€ **Large Language Models (LLMs)** è§„æ¨¡ä¸æ–­å¢å¤§ï¼Œå…¶åœ¨å„ç±»ä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„æ€§èƒ½æ˜¾è‘—æå‡ï¼Œä½†éšä¹‹è€Œæ¥çš„**è¯„ä¼°æˆæœ¬**ä¹Ÿæ€¥å‰§ä¸Šå‡ã€‚å¯¹å¤§è§„æ¨¡ benchmark æ•°æ®é›†è¿›è¡Œæ¨ç†è¯„ä¼°éœ€è¦é«˜æ˜‚çš„è®¡ç®—èµ„æºï¼Œå°¤å…¶æ˜¯åœ¨æ¨¡å‹æ•°é‡å’Œæµ‹è¯•æ ·æœ¬é‡éƒ½å¾ˆå¤§çš„æƒ…å†µä¸‹ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•åœ¨**å¤§å¹…é™ä½è¯„ä¼°å¼€é”€**çš„åŒæ—¶ï¼Œä¿æŒå¯¹æ¨¡å‹èƒ½åŠ›çš„å‡†ç¡®ä¼°è®¡è¿™ä¸€æ ¸å¿ƒæŒ‘æˆ˜ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

ä½œè€…æå‡ºäº† **SparseEval**ï¼Œä¸€ç§åŸºäº**ç¨€ç–ä¼˜åŒ–ï¼ˆsparse optimizationï¼‰** çš„é«˜æ•ˆ LLM è¯„ä¼°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³å¦‚ä¸‹ï¼š

- **é‡æ–°å®¡è§† model-item æ€§èƒ½çŸ©é˜µ**ï¼Œå‘ç°å…¶å…·æœ‰æ˜æ˜¾çš„**ç¨€ç–æ€§å’Œèšç±»ç»“æ„**ï¼ˆsparsity and redundancyï¼‰ï¼Œå³è®¸å¤šæµ‹è¯•æ ·æœ¬åœ¨æ¨¡å‹å“åº”æ¨¡å¼ä¸Šé«˜åº¦ç›¸ä¼¼ã€‚
- å°†é«˜æ•ˆè¯„ä¼°å»ºæ¨¡ä¸ºä¸€ä¸ª**ç¨€ç–ä¼˜åŒ–é—®é¢˜**ï¼šä»å¤§é‡æµ‹è¯•é¡¹ä¸­é€‰æ‹©å°‘é‡ä»£è¡¨æ€§â€œé”šç‚¹â€ï¼ˆanchorsï¼‰ï¼Œå¹¶é€šè¿‡å­¦ä¹ æƒé‡æ¥é‡æ„å…¨é›†ä¸Šçš„æ€»ä½“æ€§èƒ½ã€‚
- é¦–æ¬¡å°†**æ¢¯åº¦ä¸‹é™ï¼ˆgradient descentï¼‰** å¼•å…¥ anchor æƒé‡çš„å­¦ä¹ è¿‡ç¨‹ï¼Œç«¯åˆ°ç«¯åœ°ä¼˜åŒ–é‡å»ºæŸå¤±ï¼ˆreconstruction lossï¼‰ã€‚
- è®¾è®¡äº†ä¸€ç§**ä»»åŠ¡æ„ŸçŸ¥çš„ anchor refinement ç­–ç•¥**ï¼Œé€šè¿‡è¿­ä»£æ›¿æ¢ä½ä»·å€¼ anchor å’Œé«˜æ½œåŠ›å€™é€‰ï¼ŒåŠ¨æ€ä¼˜åŒ– anchor é›†åˆã€‚

#### åˆ›æ–°ç‚¹æ€»ç»“ï¼š
| åˆ›æ–°ç»´åº¦ | å†…å®¹ |
|--------|------|
| **ç†è®ºè§†è§’** | å½¢å¼åŒ–å®šä¹‰â€œè¯„ä¼°ç¨€ç–æ€§â€ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºç¨€ç–ä¼˜åŒ–é—®é¢˜ |
| **æŠ€æœ¯å®ç°** | ä½¿ç”¨ MLP + æ¢¯åº¦ä¸‹é™ç›´æ¥ä¼˜åŒ– anchor æƒé‡ï¼Œä¼˜äºä¼ ç»ŸåŠ æƒå¹³å‡æˆ– IRT æ–¹æ³• |
| **anchor é€‰æ‹©æœºåˆ¶** | æå‡º **Anchor Importance Score (AIS)** å’Œ **Candidate Importance Score (CIS)** è¿›è¡Œä»»åŠ¡æ„ŸçŸ¥ refinement |
| **æ— éœ€é¢å¤–ç‰¹å¾** | ä¸ä¾èµ– prompt embedding æˆ–æ¦‚ç‡åˆ†å¸ƒç­‰å¤–éƒ¨ä¿¡æ¯ï¼Œä»…ä½¿ç”¨ model-item æ­£ç¡®æ€§çŸ©é˜µ |

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹æ³• | å±€é™æ€§ | SparseEval çš„ä¼˜åŠ¿ |
|------|-------|------------------|
| **Anchor Points**, **TinyBenchmark (IRT)** | ä¾èµ–é™æ€èšç±»æˆ– IRT æ¨¡å‹ï¼Œæ— æ³•ç«¯åˆ°ç«¯ä¼˜åŒ–ï¼›æƒé‡å›ºå®š | åŠ¨æ€å­¦ä¹ æƒé‡ï¼Œæ”¯æŒè´Ÿæƒé‡ï¼Œæ‰©å±•ä¼˜åŒ–ç©ºé—´ |
| **TailoredBench** | è‡ªé€‚åº”ä½†æœªç»“åˆæ¢¯åº¦ä¼˜åŒ– | å¼•å…¥ refinement æœºåˆ¶ï¼Œæ›´è´´è¿‘ä¸‹æ¸¸ä»»åŠ¡ç›®æ ‡ |
| **Flash-HELM / Pacchiardi et al.** | å¤šåŸºäºå¯å‘å¼æˆ–ç»Ÿè®¡æ ¡å‡† | å»ºç«‹å¯è®­ç»ƒã€å¯å¾®åˆ†çš„è¯„ä¼°ä»£ç†æ¨¡å‹ï¼ˆproxy modelï¼‰ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šæ›´ä½è¯¯å·®ã€æ›´å¼ºç›¸å…³æ€§ã€æ›´é«˜æ³›åŒ–æ€§ã€æ›´å°‘ anchor æ•°é‡éœ€æ±‚ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåŸºäº **Open-LLM Leaderboard** ä¸Šè¶…è¿‡ **5,000 ä¸ª LLMs** åœ¨ä»¥ä¸‹å…­ä¸ªä¸»æµ benchmark ä¸Šçš„è¡¨ç°æ„å»º model-item çŸ©é˜µï¼š

| æ•°æ®é›† | ä»»åŠ¡ç±»å‹ |
|-------|---------|
| **ARC** | æ¨ç†ä¸å¸¸è¯†é—®ç­” |
| **GSM8K** | æ•°å­¦åº”ç”¨é¢˜æ±‚è§£ |
| **HellaSwag** | æ—¥å¸¸æƒ…å¢ƒä¸‹çš„å¥å­è¡¥å…¨ |
| **MMLU** | å¤šå­¦ç§‘çŸ¥è¯†ç†è§£ï¼ˆæ¶µç›–57ä¸ªå­é¢†åŸŸï¼‰ |
| **TruthfulQA** | æŠ—è¯¯å¯¼ä¸äº‹å®ä¸€è‡´æ€§åˆ¤æ–­ |
| **Winogrande** | å…±æŒ‡æ¶ˆè§£ä¸è¯­ä¹‰æ¨ç† |

> âš ï¸ æ³¨ï¼šç›¸æ¯” TinyBenchmark ä¸­ä»…ä½¿ç”¨çº¦ 300 ä¸ªæ¨¡å‹ï¼Œæœ¬å·¥ä½œæ‰©å¤§è‡³ **5,000 æ¨¡å‹**ï¼Œæå¤§å¢å¼ºäº†æ³›åŒ–æ€§éªŒè¯ã€‚

---

### ğŸ§ª å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### å®éªŒæµç¨‹æ¦‚è§ˆï¼š
1. ä»å…¨éƒ¨æ¨¡å‹ä¸­éšæœºé€‰å– 200 ä¸ªä½œä¸º **validation & test set**ï¼ˆå„100ï¼‰
2. å‰©ä½™ ~4800 ä¸ªç”¨äºè®­ç»ƒ
3. å›ºå®š anchor æ•°é‡ $ k \in \{20, 40, 60, 80, 100\} $
4. ä½¿ç”¨ **4-layer MLP** ä½œä¸ºèšåˆå‡½æ•° $ f $
5. å­¦ä¹ ç‡ï¼š6e-4ï¼Œrefinement æ­¥æ•°ï¼š10

#### è¯„ä¼°æŒ‡æ ‡ï¼š
| æŒ‡æ ‡ | å«ä¹‰ |
|-----|------|
| **MAE â†“** | Mean Absolute Errorï¼Œé¢„æµ‹å‡†ç¡®ç‡ä¸çœŸå®å‡†ç¡®ç‡ä¹‹é—´çš„ç»å¯¹è¯¯å·®ï¼ˆè¶Šå°è¶Šå¥½ï¼‰ |
| **Kendallâ€™s Tau (T) â†‘** | æ’åºä¸€è‡´æ€§ç³»æ•°ï¼Œè¡¡é‡æ¨¡å‹æ’åçš„ç›¸å…³æ€§ï¼ˆè¶Šé«˜è¶Šå¥½ï¼Œæ¥è¿‘1è¡¨ç¤ºå¼ºä¸€è‡´ï¼‰ |

#### å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•ï¼š
- **Anchor Points** (Vivek et al., 2023)ï¼šåŸºäºä»£è¡¨æ€§å­é›†çš„èšç±»æ–¹æ³•
- **gp-IRT** (Polo et al., 2024)ï¼šåŸºäº Item Response Theory çš„è´å¶æ–¯å»ºæ¨¡
- **TailoredBench** (Yuan et al., 2025)ï¼šå®šåˆ¶åŒ–è‡ªé€‚åº” benchmark

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| æ–¹æ³• / æ•°æ®é›† | Anchor=100 æ—¶ MAE (%) | Anchor=100 æ—¶ Kendallâ€™s T |
|--------------|------------------------|----------------------------|
| **SparseEval (å¹³å‡)** | **~1.3%** | **>0.91** |
| **TailoredBench** | ~2.0% | ~0.89 |
| **gp-IRT** | ~2.3% | ~0.83 |
| **Anchor Points** | >3.0% | <0.80 |

> âœ… **ç»“è®º**ï¼šSparseEval åœ¨æ‰€æœ‰ benchmark ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œåœ¨ä»…ç”¨ **100 ä¸ª anchor** çš„æƒ…å†µä¸‹å³å¯å®ç°ï¼š
- **MAE ä½äº 1.5%**
- **Kendallâ€™s T è¶…è¿‡ 0.90**

---

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

| å¯¹æ¯”ç»´åº¦ | ç»“æœ |
|--------|------|
| **ä¼°è®¡ç²¾åº¦** | MAE å¹³å‡æ¯” best baseline ä½ **1â€“2%**ï¼Œå°¤å…¶åœ¨ MMLU å’Œ TruthfulQA ä¸Šä¼˜åŠ¿æ˜æ˜¾ |
| **æ’åºä¸€è‡´æ€§** | Kendallâ€™s T æå‡è¾¾ **+0.1**ï¼Œè¡¨æ˜æ¨¡å‹æ’åé«˜åº¦å¯ä¿¡ |
| **anchor æ•ˆç‡** | ä»…éœ€ **100 ä¸ª anchor** å³å¯è¾¾åˆ°å…¶ä»–æ–¹æ³•ä½¿ç”¨ **500+ anchor** æ‰èƒ½è¾¾åˆ°çš„æ•ˆæœ â†’ **>5x æˆæœ¬èŠ‚çœ**
| **è®­ç»ƒæ•ˆç‡** | ç›¸æ¯” gp-IRTï¼ˆè€—æ—¶é•¿è¾¾ 16 åˆ†é’Ÿï¼‰ï¼ŒSparseEval è®­ç»ƒæ›´å¿«ï¼Œæ›´é€‚åˆå®é™…éƒ¨ç½² |

> ğŸ’¡ å›¾ 3 æ˜¾ç¤ºï¼šSparseEval ä½¿ç”¨ 100 ä¸ª anchor çš„è¡¨ç° â‰ˆ TailoredBench ä½¿ç”¨ 500 ä¸ª anchor çš„è¡¨ç°ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰ç½‘ç»œæ¶æ„å½±å“ï¼ˆFig. 4ï¼‰
- ä½¿ç”¨ **MLP æ›¿ä»£çº¿æ€§åŠ æƒ** å¯æ˜¾è‘—é™ä½ MAEï¼Œè¯´æ˜æ›´å¼ºçš„è¡¨ç¤ºèƒ½åŠ›æœ‰åŠ©äºæ•æ‰å¤æ‚çš„ anchor æƒé‡å…³ç³»ã€‚
- çº¿æ€§æ¨¡å‹å—é™äºè¡¨è¾¾èƒ½åŠ›ï¼Œéš¾ä»¥æ‹Ÿåˆéçº¿æ€§åå·®ã€‚

#### ï¼ˆ2ï¼‰è®­ç»ƒæ•°æ®æ¯”ä¾‹å½±å“ï¼ˆFig. 5ï¼‰
- å³ä½¿åªä½¿ç”¨ **20% çš„è®­ç»ƒæ•°æ®**ï¼ŒSparseEval ä»èƒ½ç»´æŒ MAE < 1%ï¼ŒT > 0.90
- è¡¨æ˜æ–¹æ³•å¯¹æ•°æ®è§„æ¨¡ä¸æ•æ„Ÿï¼Œå…·å¤‡è‰¯å¥½é²æ£’æ€§

#### ï¼ˆ3ï¼‰anchor åˆå§‹åŒ–ç­–ç•¥ï¼ˆTable 2ï¼‰
| åˆå§‹åŒ–æ–¹å¼ | MAE (ARC, k=100) | T (ARC, k=100) |
|-----------|------------------|---------------|
| Random | 1.339% | 0.890 |
| k-means | 1.218% | 0.913 |
| **SparseEval (w/ refinement)** | **1.165%** | **0.917** |

> âœ… **refinement æ˜¯å…³é”®å¢ç›Šæ¥æº**ï¼Œç‰¹åˆ«æ˜¯åœ¨ anchor æ•°é‡è¾ƒå°‘æ—¶æ•ˆæœæ›´æ˜¾è‘—ã€‚

#### ï¼ˆ4ï¼‰AIS/CIS åˆ†å¸ƒåˆ†æï¼ˆFig. 6ï¼‰
- ç»è¿‡ refinement åï¼ŒAIS å’Œ CIS åˆ†å¸ƒæ•´ä½“å³ç§»ï¼Œè¯´æ˜é€‰å‡ºçš„ anchors æ›´å…·å½±å“åŠ›ï¼Œcandidates æ›´å…·è¡¥å……æ½œåŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **LLM benchmark å­˜åœ¨æ˜¾è‘—çš„â€œè¯„ä¼°ç¨€ç–æ€§â€ï¼ˆEvaluation Sparsityï¼‰**
   - model-item çŸ©é˜µå‘ˆç°å¼º intra-cluster ç›¸ä¼¼æ€§å’Œ inter-cluster å¯é¢„æµ‹æ€§
   - æ”¯æŒä½¿ç”¨æå°å­é›†ï¼ˆå¦‚ 100 é¡¹ï¼‰ä»£è¡¨æ•´ä¸ª benchmark

2. **anchor ä¸åº”é™æ€é€‰æ‹©ï¼Œè€Œåº”ä»»åŠ¡æ„ŸçŸ¥åœ°åŠ¨æ€ä¼˜åŒ–**
   - ä¼ ç»Ÿçš„ k-means æˆ– IRT èšç±»è™½æœ‰æ•ˆï¼Œä½†ç¼ºä¹ä»»åŠ¡å¯¹é½
   - å¼•å…¥ AIS/CIS å¯é‡åŒ–æ¯ä¸ª item çš„â€œä»£è¡¨æ€§â€å’Œâ€œå¯æ›¿ä»£æ€§â€

3. **æ¢¯åº¦é©±åŠ¨çš„ç¨€ç–ä¼˜åŒ–ä¼˜äºä¼ ç»Ÿæ–¹æ³•**
   - ç«¯åˆ°ç«¯è®­ç»ƒå…è®¸æ¨¡å‹è‡ªåŠ¨å­¦ä¹ æœ€ä¼˜æƒé‡ç»„åˆï¼Œç”šè‡³å¼•å…¥è´Ÿæƒé‡ä»¥ä¿®æ­£ç³»ç»Ÿæ€§åå·®

4. **SparseEval æ³›åŒ–èƒ½åŠ›å¼º**
   - åœ¨ hold-out çš„ DeepSeek å®¶æ—æ¨¡å‹ä¸Šæµ‹è¯•ï¼ˆTable 3ï¼‰ï¼Œå¹³å‡ MAE ä»…ä¸º **2.09%**ï¼Œè¿œä½äº gp-IRTï¼ˆ2.66%ï¼‰å’Œ TailoredBenchï¼ˆ4.22%ï¼‰

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

1. **ä¾èµ–è¶³å¤Ÿå¤šçš„æ¨¡å‹æ ·æœ¬è¿›è¡Œè®­ç»ƒ**
   - æ¢¯åº¦ä¼˜åŒ–éœ€è¦ä¸€å®šæ•°é‡çš„æ¨¡å‹ï¼ˆæ–‡ä¸­ä½¿ç”¨ ~4800ï¼‰æ‰èƒ½ç¨³å®šæ”¶æ•›
   - åœ¨ä»…æœ‰å°‘æ•°å‡ ä¸ªæ¨¡å‹æ—¶å¯èƒ½å¤±æ•ˆ

2. **å½“å‰ä»…é€‚ç”¨äº binary æ­£ç¡®æ€§è¯„åˆ†åœºæ™¯**
   - è¾“å…¥ä¸º {-1, 1} æ„æˆçš„ model-item çŸ©é˜µï¼Œå°šæœªæ‹“å±•è‡³ soft label æˆ–ç”Ÿæˆè´¨é‡è¯„åˆ†

3. **æœªåˆ©ç”¨æ¨¡å‹å†…éƒ¨è¡¨å¾**
   - å½“å‰æ–¹æ³•å®Œå…¨åŸºäº black-box è¾“å‡ºè¡Œä¸ºï¼Œæœªæ¥å¯èåˆ hidden states æˆ– attention map æå‡ç²¾åº¦

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **ç»“åˆ model-model similarity structure**ï¼ˆFig. 10ï¼‰
   - åˆ©ç”¨æ¨¡å‹é—´çš„æ€§èƒ½ç›¸ä¼¼æ€§è¿›ä¸€æ­¥å‡å°‘æ‰€éœ€ anchor æ•°é‡

2. **æ‰©å±•è‡³å¤šæ¨¡æ€æ¨¡å‹è¯„ä¼°**
   - å°†ç¨€ç–ä¼˜åŒ–æ€æƒ³åº”ç”¨äº VLMã€è¯­éŸ³æ¨¡å‹ç­‰é¢†åŸŸçš„ benchmark è®¾è®¡

3. **åœ¨çº¿å¢é‡æ›´æ–°æœºåˆ¶**
   - æ”¯æŒæ–°æ¨¡å‹åŠ å…¥åå¿«é€Ÿ re-calibrate anchor æƒé‡ï¼Œæ— éœ€é‡æ–°è®­ç»ƒ

4. **æ¢ç´¢ AIS/CIS çš„å¯è§£é‡Šæ€§**
   - åˆ†æä¸ºä½•æŸäº›é¢˜ç›®å¤©ç„¶æ›´å…·ä»£è¡¨æ€§ï¼ˆå¦‚ Fig. 11 ä¸­æ³•å¾‹/ç‰©ç†å…¸å‹é¢˜ï¼‰

---

## âœ… æ€»ç»“

**SparseEval** æ˜¯é¦–ä¸ªå°† **ç¨€ç–ä¼˜åŒ– + æ¢¯åº¦ä¸‹é™ + ä»»åŠ¡æ„ŸçŸ¥ refinement** èä¸ºä¸€ä½“çš„å¤§æ¨¡å‹é«˜æ•ˆè¯„ä¼°æ¡†æ¶ã€‚å®ƒä¸ä»…å®ç°äº†**è¶…ä½è¯„ä¼°æˆæœ¬**ï¼ˆä»…éœ€ 100 ä¸ªæ ·æœ¬ï¼‰ï¼Œè¿˜ä¿è¯äº†**é«˜ç²¾åº¦ä¼°è®¡**ä¸**å¼ºæ’åºä¸€è‡´æ€§**ï¼Œæ˜¯è¿ˆå‘ç»¿è‰² AI è¯„ä¼°çš„é‡è¦ä¸€æ­¥ã€‚

> ğŸ”— å¼€æºåœ°å€ï¼š[https://github.com/taolinzhang/SparseEval](https://github.com/taolinzhang/SparseEval)

</details>

---

### 16. [VocalNet-MDM: Accelerating Streaming Speech LLM via Self-Distilled Masked Diffusion Modeling](https://arxiv.org/abs/2602.08607)

**Authors**: Ziyang Cheng, Yuhao Wang, Heyang Liu, Ronghua Wu, Qunshan Gu, Yanfeng Wang, Yu Wang  
**Category**: cs.CL  
**Published**: 2026-02-10  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.08607v1  

#### Abstract
Recent Speech Large Language Models~(LLMs) have achieved impressive capabilities in end-to-end speech interaction. However, the prevailing autoregressive paradigm imposes strict serial constraints, limiting generation efficiency and introducing exposure bias. In this paper, we investigate Masked Dif...

---

### 17. [Horizon Imagination: Efficient On-Policy Training in Diffusion World Models](https://arxiv.org/abs/2602.08032)

**Authors**: Lior Cohen, Ofir Nabati, Kaixin Wang, Navdeep Kumar, Shie Mannor  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.08032v1  

#### Abstract
We study diffusion-based world models for reinforcement learning, which offer high generative fidelity but face critical efficiency challenges in control. Current methods either require heavyweight models at inference or rely on highly sequential imagination, both of which impose prohibitive computa...

---

### 18. [Compiler-Assisted Speculative Sampling for Accelerated LLM Inference on Heterogeneous Edge Devices](https://arxiv.org/abs/2602.08060)

**Authors**: Alejandro Ruiz y Mesa, Guilherme Korol, Moritz Riesteter, Jo\~ao Paulo Cardoso de Lima, Jeronimo Castrillon  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.08060v1  

#### Abstract
LLM deployment on resource-constrained edge devices faces severe latency constraints, particularly in real-time applications where delayed responses can compromise safety or usability. Among many approaches to mitigate the inefficiencies of sequential token-by-token generation, Speculative Decoding ...

---

### 19. [Towards Efficient Large Language Reasoning Models via Extreme-Ratio Chain-of-Thought Compression](https://arxiv.org/abs/2602.08324)

**Authors**: Yuntian Tang, Bohan Jia, Wenxuan Huang, Lianyue Zhang, Jiao Xie, Wenxi Li, Wei Li, Jie Hu, Xinghao Chen, Rongrong Ji, Shaohui Lin  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.08324v1  

#### Abstract
Chain-of-Thought (CoT) reasoning successfully enhances the reasoning capabilities of Large Language Models (LLMs), yet it incurs substantial computational overhead for inference. Existing CoT compression methods often suffer from a critical loss of logical fidelity at high compression ratios, result...

---

### 20. [Bridging Academia and Industry: A Comprehensive Benchmark for Attributed Graph Clustering](https://arxiv.org/abs/2602.08519)

**Authors**: Yunhui Liu, Pengyu Qiu, Yu Xing, Yongchao Liu, Peng Du, Chuntao Hong, Jiajun Zheng, Tao Zheng, Tieke He  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.08519v1  

#### Abstract
Attributed Graph Clustering (AGC) is a fundamental unsupervised task that integrates structural topology and node attributes to uncover latent patterns in graph-structured data. Despite its significance in industrial applications such as fraud detection and user segmentation, a significant chasm per...

---

### 21. [ERIS: Enhancing Privacy and Communication Efficiency in Serverless Federated Learning](https://arxiv.org/abs/2602.08617)

**Authors**: Dario Fenoglio, Pasquale Polverino, Jacopo Quizi, Martin Gjoreski, Marc Langheinrich  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.08617v1  

#### Abstract
Scaling federated learning (FL) to billion-parameter models introduces critical trade-offs between communication efficiency, model accuracy, and privacy guarantees. Existing solutions often tackle these challenges in isolation, sacrificing accuracy or relying on costly cryptographic tools. We propos...

---

### 22. [PTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognition](https://arxiv.org/abs/2602.08240)

**Authors**: Xun Su, Huamin Wang, Qi Zhang  
**Category**: cs.AI  
**Published**: 2026-02-10  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.08240v1  

#### Abstract
Speech Emotion Recognition (SER) is widely deployed in Human-Computer Interaction, yet the high computational cost of conventional models hinders their implementation on resource-constrained edge devices. Spiking Neural Networks (SNNs) offer an energy-efficient alternative due to their event-driven ...

---

### 23. [Efficient Post-Training Pruning of Large Language Models with Statistical Correction](https://arxiv.org/abs/2602.07375)

**Authors**: Peiqi Yu, Jinhao Wang, Xinyi Sui, Nam Ling, Wei Wang, Wei Jiang  
**Category**: cs.CL  
**Published**: 2026-02-10  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.07375v1  

#### Abstract
Post-training pruning is an effective approach for reducing the size and inference cost of large language models (LLMs), but existing methods often face a trade-off between pruning quality and computational efficiency. Heuristic pruning methods are efficient but sensitive to activation outliers, whi...

---

### 24. [MARTI-MARS$^2$: Scaling Multi-Agent Self-Search via Reinforcement Learning for Code Generation](https://arxiv.org/abs/2602.07848)

**Authors**: Shijie Wang, Pengfei Li, Yikun Fu, Kaifeng Liu, Fangyuan Li, Yang Liu, Xiaowei Sun, Zonglin Li, Siyao Zhao, Jian Zhao, Kai Tian, Dong Li, Junqi Gao, Yutong Zhang, Yiqun Chen, Yuqiang Li, Zoe Li, Weinan Zhang, Peng Ye, Shuyue Hu, Lei Bai, Bowen Zhou, Kaiyan Zhang, Biqing Qi  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.07848v1  

#### Abstract
While the complex reasoning capability of Large Language Models (LLMs) has attracted significant attention, single-agent systems often encounter inherent performance ceilings in complex tasks such as code generation. Multi-agent collaboration offers a promising avenue to transcend these boundaries. ...

---

### 25. [Time Series Reasoning via Process-Verifiable Thinking Data Synthesis and Scheduling for Tailored LLM Reasoning](https://arxiv.org/abs/2602.07830)

**Authors**: Jiahui Zhou, Dan Li, Boxin Li, Xiao Zhang, Erli Meng, Lin Li, Zhuomin Chen, Jian Lou, See-Kiong Ng  
**Category**: cs.AI  
**Published**: 2026-02-10  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.07830v1  

#### Abstract
Time series is a pervasive data type across various application domains, rendering the reasonable solving of diverse time series tasks a long-standing goal. Recent advances in large language models (LLMs), especially their reasoning abilities unlocked through reinforcement learning (RL), have opened...

---

### 26. [iGRPO: Self-Feedback-Driven LLM Reasoning](https://arxiv.org/abs/2602.09000)

**Authors**: Ali Hatamizadeh, Shrimai Prabhumoye, Igor Gitman, Ximing Lu, Seungju Han, Wei Ping, Yejin Choi, Jan Kautz  
**Category**: cs.AI  
**Published**: 2026-02-10  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.09000v1  

#### Abstract
Large Language Models (LLMs) have shown promise in solving complex mathematical problems, yet they still fall short of producing accurate and consistent solutions. Reinforcement Learning (RL) is a framework for aligning these models with task-specific rewards, improving overall quality and reliabili...

---

### 27. [Attn-GS: Attention-Guided Context Compression for Efficient Personalized LLMs](https://arxiv.org/abs/2602.07778)

**Authors**: Shenglai Zeng, Tianqi Zheng, Chuan Tian, Dante Everaert, Yau-Shian Wang, Yupin Huang, Michael J. Morais, Rohit Patki, Jinjin Tian, Xinnan Dai, Kai Guo, Monica Xiao Cheng, Hui Liu  
**Category**: cs.CL  
**Published**: 2026-02-10  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.07778v1  

#### Abstract
Personalizing large language models (LLMs) to individual users requires incorporating extensive interaction histories and profiles, but input token constraints make this impractical due to high inference latency and API costs. Existing approaches rely on heuristic methods such as selecting recent in...

---

### 28. [Cerebellar-Inspired Residual Control for Fault Recovery: From Inference-Time Adaptation to Structural Consolidation](https://arxiv.org/abs/2602.07227)

**Authors**: Nethmi Jayasinghe, Diana Gontero, Spencer T. Brown, Vinod K. Sangwan, Mark C. Hersam, Amit Ranjan Trivedi  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.07227v1  

#### Abstract
Robotic policies deployed in real-world environments often encounter post-training faults, where retraining, exploration, or system identification are impractical. We introduce an inference-time, cerebellar-inspired residual control framework that augments a frozen reinforcement learning policy with...

---

### 29. [Pareto-guided Pipeline for Distilling Featherweight AI Agents in Mobile MOBA Games](https://arxiv.org/abs/2602.07521)

**Authors**: Xionghui Yang, Bozhou Chen, Yunlong Lu, Yongyi Wang, Lingfeng Li, Lanxiao Huang, Lin Liu, Wenjun Wang, Meng Meng, Xia Lin, Wenxin Li  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.07521v1  

#### Abstract
Recent advances in game AI have demonstrated the feasibility of training agents that surpass top-tier human professionals in complex environments such as Honor of Kings (HoK), a leading mobile multiplayer online battle arena (MOBA) game. However, deploying such powerful agents on mobile devices rema...

---

### 30. [Enhancing Bandit Algorithms with LLMs for Time-varying User Preferences in Streaming Recommendations](https://arxiv.org/abs/2602.08067)

**Authors**: Chenglei Shen, Yi Zhan, Weijie Yu, Xiao Zhang, Jun Xu  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.08067v1  

#### Abstract
In real-world streaming recommender systems, user preferences evolve dynamically over time. Existing bandit-based methods treat time merely as a timestamp, neglecting its explicit relationship with user preferences and leading to suboptimal performance. Moreover, online learning methods often suffer...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
