# arXiv Papers Bot ü§ñ

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## üìä Statistics

- **Last Updated**: 2025-11-19 12:55:04 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## üìö Recent Papers

### 1. [SpecEdge: Scalable Edge-Assisted Serving Framework for Interactive LLMs](https://arxiv.org/abs/2505.17052)

**Authors**: Jinwoo Park, Seunggeun Cho, Dongsu Han  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 12.5  
**Type**: replace-cross  
**ArXiv ID**: 2505.17052v2  

Large language models (LLMs) power many modern applications, but serving them at scale remains costly and resource-intensive. Current server-centric systems overlook consumer-grade GPUs at the edge. We introduce SpecEdge, an edge-assisted inference framework that splits LLM workloads between edge an...

---

### 2. [MoM: Linear Sequence Modeling with Mixture-of-Memories](https://arxiv.org/abs/2502.13685)

**Authors**: Jusen Du, Weigao Sun, Disen Lan, Jiaxi Hu, Yu Cheng  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 10.0  
**Type**: replace-cross  
**ArXiv ID**: 2502.13685v4  

Linear sequence modeling methods, such as linear attention, state space modeling, and linear RNNs, offer significant efficiency improvements by reducing the complexity of training and inference. However, these methods typically compress the entire input sequence into a single fixed-size memory state...

---

### 3. [CLO: Efficient LLM Inference System with CPU-Light KVCache Offloading via Algorithm-System Co-Design](https://arxiv.org/abs/2511.14510)

**Authors**: Jiawei Yi, Ping Gong, Youhui Bai, Jiaqi Ruan, Shengnan Wang, Pengcheng Wang, Haibo Wang, Weiguang Wang, Xia Zhu, Feng Wu, Cheng Li  
**Category**: cs.LG  
**Published**: 2025-11-19  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2511.14510v1  

The growth of million-token LLMs exposes the scalability limits of inference systems, where the KVCache dominates memory usage and data transfer overhead. Recent offloading systems migrate the KVCache to CPU memory and incorporate top-k attention to reduce the volume of data transferred from the CPU...

---

### 4. [Seer: Online Context Learning for Fast Synchronous LLM Reinforcement Learning](https://arxiv.org/abs/2511.14617)

**Authors**: Ruoyu Qin, Weiran He, Weixiao Huang, Yangkun Zhang, Yikai Zhao, Bo Pang, Xinran Xu, Yingdi Shan, Yongwei Wu, Mingxing Zhang  
**Category**: cs.DC  
**Published**: 2025-11-19  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2511.14617v1  

Reinforcement Learning (RL) has become critical for advancing modern Large Language Models (LLMs), yet existing synchronous RL systems face severe performance bottlenecks. The rollout phase, which dominates end-to-end iteration time, suffers from substantial long-tail latency and poor resource utili...

---

### 5. [Beat the long tail: Distribution-Aware Speculative Decoding for RL Training](https://arxiv.org/abs/2511.13841)

**Authors**: Zelei Shao, Vikranth Srivatsa, Sanjana Srivastava, Qingyang Wu, Alpay Ariyak, Xiaoxia Wu, Ameen Patel, Jue Wang, Percy Liang, Tri Dao, Ce Zhang, Yiying Zhang, Ben Athiwaratkun, Chenfeng Xu, Junxiong Wang  
**Category**: cs.LG  
**Published**: 2025-11-19  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2511.13841v1  

Reinforcement learning(RL) post-training has become essential for aligning large language models (LLMs), yet its efficiency is increasingly constrained by the rollout phase, where long trajectories are generated token by token. We identify a major bottleneck:the long-tail distribution of rollout len...

---

### 6. [Quartet: Native FP4 Training Can Be Optimal for Large Language Models](https://arxiv.org/abs/2505.14669)

**Authors**: Roberto L. Castro, Andrei Panferov, Soroush Tabesh, Oliver Sieberling, Jiale Chen, Mahdi Nikdan, Saleh Ashkboos, Dan Alistarh  
**Category**: cs.LG  
**Published**: 2025-11-19  
**Score**: 9.0  
**Type**: replace  
**ArXiv ID**: 2505.14669v3  

Training large language models (LLMs) models directly in low-precision offers a way to address computational costs by improving both throughput and energy efficiency. For those purposes, NVIDIA's recent Blackwell architecture facilitates very low-precision operations using FP4 variants. Yet, current...

---

### 7. [Heterogeneous Multi-Agent Proximal Policy Optimization for Power Distribution System Restoration](https://arxiv.org/abs/2511.14730)

**Authors**: Parya Dolatyabi, Mahdi Khodayar  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2511.14730v1  

Restoring power distribution systems (PDS) after large-scale outages requires sequential switching operations that reconfigure feeder topology and coordinate distributed energy resources (DERs) under nonlinear constraints such as power balance, voltage limits, and thermal ratings. These challenges m...

---

### 8. [GCA-ResUNet:Image segmentation in medical images using grouped coordinate attention](https://arxiv.org/abs/2511.14087)

**Authors**: Jun Ding, Shang Gao  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 8.5  
**Type**: cross  
**ArXiv ID**: 2511.14087v1  

Medical image segmentation underpins computer-aided diagnosis and therapy by supporting clinical diagnosis, preoperative planning, and disease monitoring. While U-Net style convolutional neural networks perform well due to their encoder-decoder structures with skip connections, they struggle to capt...

---

### 9. [Hyperion: Hierarchical Scheduling for Parallel LLM Acceleration in Multi-tier Networks](https://arxiv.org/abs/2511.14450)

**Authors**: Mulei Ma, Minrui Xu, Zihan Chen, Yang Yang, Tony Q. S. Quek  
**Category**: cs.DC  
**Published**: 2025-11-19  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2511.14450v1  

Large Language Models (LLMs) are increasingly executed across edge, fog, and cloud tiers where limited GPU memory, heterogeneous compute, and variable inter-tier bandwidth jointly constrain deployment and motivate model partitioning and request scheduling. In this setting, achieving low end-to-end l...

---

### 10. [Guaranteed DGEMM Accuracy While Using Reduced Precision Tensor Cores Through Extensions of the Ozaki Scheme](https://arxiv.org/abs/2511.13778)

**Authors**: Angelika Schwarz, Anton Anders, Cole Brower, Harun Bayraktar, John Gunnels, Kate Clark, RuQing G. Xu, Samuel Rodriguez, Sebastien Cayrols, Pawe{\l} Tabaszewski, Victor Podlozhnyuk  
**Category**: cs.DC  
**Published**: 2025-11-19  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2511.13778v1  

The rapid growth of artificial intelligence (AI) has made low-precision formats such as FP16, FP8, and, most recently, block-scaled FP4 the primary focus of modern GPUs, where Tensor Cores now deliver orders-of-magnitude higher throughput than traditional FP64 pipelines. This hardware shift has spar...

---

### 11. [ParallelKittens: Systematic and Practical Simplification of Multi-GPU AI Kernels](https://arxiv.org/abs/2511.13940)

**Authors**: Stuart H. Sul, Simran Arora, Benjamin F. Spector, Christopher R\'e  
**Category**: cs.DC  
**Published**: 2025-11-19  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2511.13940v1  

Inter-GPU communication has become a major bottleneck for modern AI workloads as models scale and improvements in hardware compute throughput outpace improvements in interconnect bandwidth. Existing systems mitigate this through compute-communication overlap but often fail to meet theoretical peak p...

---

### 12. [FailSafe: High-performance Resilient Serving](https://arxiv.org/abs/2511.14116)

**Authors**: Ziyi Xu, Zhiqiang Xie, Swapnil Gandhi, Christos Kozyrakis  
**Category**: cs.DC  
**Published**: 2025-11-19  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2511.14116v1  

Tensor parallelism (TP) enables large language models (LLMs) to scale inference efficiently across multiple GPUs, but its tight coupling makes systems fragile: a single GPU failure can halt execution, trigger costly KVCache recomputation, and introduce long-term compute and memory imbalance. We pres...

---

### 13. [Syn-STARTS: Synthesized START Triage Scenario Generation Framework for Scalable LLM Evaluation](https://arxiv.org/abs/2511.14023)

**Authors**: Chiharu Hagiwara, Naoki Nonaka, Yuhta Hashimoto, Ryu Uchimido, Jun Seita  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2511.14023v1  

Triage is a critically important decision-making process in mass casualty incidents (MCIs) to maximize victim survival rates. While the role of AI in such situations is gaining attention for making optimal decisions within limited resources and time, its development and performance evaluation requir...

---

### 14. [LSP-YOLO: A Lightweight Single-Stage Network for Sitting Posture Recognition on Embedded Devices](https://arxiv.org/abs/2511.14322)

**Authors**: Nanjun Li, Ziyue Hao, Quanqiang Wang, Xuanyin Wang  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 7.5  
**Type**: cross  
**ArXiv ID**: 2511.14322v1  

With the rise in sedentary behavior, health problems caused by poor sitting posture have drawn increasing attention. Most existing methods, whether using invasive sensors or computer vision, rely on two-stage pipelines, which result in high intrusiveness, intensive computation, and poor real-time pe...

---

### 15. [Attention via Synaptic Plasticity is All You Need: A Biologically Inspired Spiking Neuromorphic Transformer](https://arxiv.org/abs/2511.14691)

**Authors**: Kallol Mondal (Department of Electronics and Communication Engineering, National Institute of Technology Allahabad, Prayagraj, Centre for Nanotechnology, Indian Institute of Technology Roorkee), Ankush Kumar (Centre for Nanotechnology, Indian Institute of Technology Roorkee)  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 7.5  
**Type**: cross  
**ArXiv ID**: 2511.14691v1  

Attention is the brain's ability to selectively focus on a few specific aspects while ignoring irrelevant ones. This biological principle inspired the attention mechanism in modern Transformers. Transformers now underpin large language models (LLMs) such as GPT, but at the cost of massive training a...

---

### 16. [Multi-Agent Deep Research: Training Multi-Agent Systems with M-GRPO](https://arxiv.org/abs/2511.13288)

**Authors**: Haoyang Hong, Jiajun Yin, Yuan Wang, Jingnan Liu, Zhe Chen, Ailing Yu, Ji Li, Zhiling Ye, Hansong Xiao, Yefei Chen, Hualei Zhou, Yun Yue, Minghui Yang, Chunxiao Guo, Junwei Liu, Peng Wei, Jinjie Gu  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 7.5  
**Type**: replace  
**ArXiv ID**: 2511.13288v2  

Multi-agent systems perform well on general reasoning tasks. However, the lack of training in specialized areas hinders their accuracy. Current training methods train a unified large language model (LLM) for all agents in the system. This may limit the performances due to different distributions und...

---

### 17. [Physics-Informed Neural Networks for Real-Time Gas Crossover Prediction in PEM Electrolyzers: First Application with Multi-Membrane Validation](https://arxiv.org/abs/2511.05879)

**Authors**: Yong-Woon Kim, Chulung Kang, Yung-Cheol Byun  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 7.5  
**Type**: replace-cross  
**ArXiv ID**: 2511.05879v2  

Green hydrogen production via polymer electrolyte membrane (PEM) water electrolysis is pivotal for energy transition, yet hydrogen crossover through membranes threatens safety and economic viability-approaching explosive limits (4 mol% H$_2$ in O$_2$) while reducing Faradaic efficiency by 2.5%. Curr...

---

### 18. [MuCPT: Music-related Natural Language Model Continued Pretraining](https://arxiv.org/abs/2511.14245)

**Authors**: Kai Tian, Yirong Mao, Wendong Bi, Hanjie Wang, Que Wenhui  
**Category**: cs.CL  
**Published**: 2025-11-19  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2511.14245v1  

Large language models perform strongly on general tasks but remain constrained in specialized settings such as music, particularly in the music-entertainment domain, where corpus scale, purity, and the match between data and training objectives are critical. We address this by constructing a large, ...

---

### 19. [CoSense-LLM: Semantics at the Edge with Cost- and Uncertainty-Aware Cloud-Edge Cooperation](https://arxiv.org/abs/2510.19670)

**Authors**: Hasan Akgul, Mari Eplik, Javier Rojas, Aina Binti Abdullah, Pieter van der Merwe  
**Category**: cs.CL  
**Published**: 2025-11-19  
**Score**: 7.5  
**Type**: replace  
**ArXiv ID**: 2510.19670v3  

We present CoSense-LLM, an edge-first framework that turns continuous multimodal sensor streams (for example Wi-Fi CSI, IMU, audio, RFID, and lightweight vision) into compact, verifiable semantic tokens and coordinates with large language models under explicit latency, energy, bandwidth, and privacy...

---

### 20. [BitSnap: Checkpoint Sparsification and Quantization in LLM Training](https://arxiv.org/abs/2511.12376)

**Authors**: Yanxin Peng, Qingping Li, Baodong Wu, Shigang Li, Guohao Dai, Shengen Yan, Yu Wang  
**Category**: cs.LG  
**Published**: 2025-11-19  
**Score**: 7.5  
**Type**: replace  
**ArXiv ID**: 2511.12376v2  

As large language models (LLMs) continue to grow in size and complexity, efficient checkpoint saving\&amp;loading has become crucial for managing storage, memory usage, and fault tolerance in LLM training. The current works do not comprehensively take into account the optimization of these several a...

---

### 21. [ALEX:A Light Editing-knowledge Extractor](https://arxiv.org/abs/2511.14018)

**Authors**: Minghu Wang (College of Computer and Cyber Security, Hebei Normal University, Hebei, China), Shuliang Zhao (College of Computer and Cyber Security, Hebei Normal University, Hebei, China), Yuanyuan Zhao (Hebei Provincial Engineering Research Center for Supply Chain Big Data Analytics and Data Security, Hebei, China), Hongxia Xu (College of Computer and Cyber Security, Hebei Normal University, Hebei, China)  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2511.14018v1  

The static nature of knowledge within Large Language Models (LLMs) makes it difficult for them to adapt to evolving information, rendering knowledge editing a critical task. However, existing methods struggle with challenges of scalability and retrieval efficiency, particularly when handling complex...

---

### 22. [HFL-FlowLLM: Large Language Models for Network Traffic Flow Classification in Heterogeneous Federated Learning](https://arxiv.org/abs/2511.14199)

**Authors**: Jiazhuo Tian, Yachao Yuan  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2511.14199v1  

In modern communication networks driven by 5G and the Internet of Things (IoT), effective network traffic flow classification is crucial for Quality of Service (QoS) management and security. Traditional centralized machine learning struggles with the distributed data and privacy concerns in these he...

---

### 23. [From Legacy Fortran to Portable Kokkos: An Autonomous Agentic AI Workflow](https://arxiv.org/abs/2509.12443)

**Authors**: Sparsh Gupta, Kamalavasan Kamalakkannan, Maxim Moraru, Galen Shipman, Patrick Diehl  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 7.0  
**Type**: cross  
**ArXiv ID**: 2509.12443v3  

Scientific applications continue to rely on legacy Fortran codebases originally developed for homogeneous, CPU-based systems. As High-Performance Computing (HPC) shifts toward heterogeneous GPU-accelerated architectures, many accelerators lack native Fortran bindings, creating an urgent need to mode...

---

### 24. [IMSE: Efficient U-Net-based Speech Enhancement using Inception Depthwise Convolution and Amplitude-Aware Linear Attention](https://arxiv.org/abs/2511.14515)

**Authors**: Xinxin Tang, Bin Qin, Yufang Li  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 7.0  
**Type**: cross  
**ArXiv ID**: 2511.14515v1  

Achieving a balance between lightweight design and high performance remains a significant challenge for speech enhancement (SE) tasks on resource-constrained devices. Existing state-of-the-art methods, such as MUSE, have established a strong baseline with only 0.51M parameters by introducing a Multi...

---

### 25. [Personalized Image Generation for Recommendations Beyond Catalogs](https://arxiv.org/abs/2502.18477)

**Authors**: Gabriel Patron, Zhiwei Xu, Ishan Kapnadak, Felipe Maia Polo  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 7.0  
**Type**: replace-cross  
**ArXiv ID**: 2502.18477v2  

Personalization is central to human-AI interaction, yet current diffusion-based image generation systems remain largely insensitive to user diversity. Existing attempts to address this often rely on costly paired preference data or introduce latency through Large Language Models. In this work, we in...

---

### 26. [MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding](https://arxiv.org/abs/2510.25327)

**Authors**: Runxi Huang, Mingxuan Yu, Mingyu Tsoi, Xiaomin Ouyang  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 7.0  
**Type**: replace-cross  
**ArXiv ID**: 2510.25327v5  

Real-time multimodal inference on resource-constrained edge devices is essential for applications such as autonomous driving, human-computer interaction, and mobile health. However, prior work often overlooks the tight coupling between sensing dynamics and model execution, as well as the complex int...

---

### 27. [Principled Coarse-Grained Acceptance for Speculative Decoding in Speech](https://arxiv.org/abs/2511.13732)

**Authors**: Moran Yanuka, Paul Dixon, Eyal Finkelshtein, Daniel Rotman, Raja Giryes  
**Category**: cs.LG  
**Published**: 2025-11-19  
**Score**: 7.0  
**Type**: cross  
**ArXiv ID**: 2511.13732v1  

Speculative decoding accelerates autoregressive speech generation by letting a fast draft model propose tokens that a larger target model verifies. However, for speech LLMs that generate acoustic tokens, exact token matching is overly restrictive: many discrete tokens are acoustically or semanticall...

---

### 28. [SWAT-NN: Simultaneous Weights and Architecture Training for Neural Networks in a Latent Space](https://arxiv.org/abs/2506.08270)

**Authors**: Zitong Huang, Mansooreh Montazerin, Ajitesh Srivastava  
**Category**: cs.LG  
**Published**: 2025-11-19  
**Score**: 7.0  
**Type**: replace  
**ArXiv ID**: 2506.08270v3  

Designing neural networks typically relies on manual trial and error or a neural architecture search (NAS) followed by weight training. The former is time-consuming and labor-intensive, while the latter often discretizes architecture search and weight optimization. In this paper, we propose a fundam...

---

### 29. [Imagine in Space: Exploring the Frontier of Spatial Intelligence and Reasoning Efficiency in Vision Language Models](https://arxiv.org/abs/2511.13782)

**Authors**: Xiaoxing Lian, Aidong Yang, Jun Zhu, Peng Wang, Yue Zhang  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2511.13782v1  

Large language models (LLMs) and vision language models (VLMs), such as DeepSeek R1,OpenAI o3, and Gemini 2.5 Pro, have demonstrated remarkable reasoning capabilities across logical inference, problem solving, and decision making. However, spatial reasoning:a fundamental component of human cognition...

---

### 30. [AutoTool: Efficient Tool Selection for Large Language Model Agents](https://arxiv.org/abs/2511.14650)

**Authors**: Jingyi Jia, Qinbin Li  
**Category**: cs.AI  
**Published**: 2025-11-19  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2511.14650v1  

Large Language Model (LLM) agents have emerged as powerful tools for automating complex tasks by leveraging the reasoning and decision-making abilities of LLMs. However, a major bottleneck in current agent frameworks lies in the high inference cost of tool selection, especially in approaches like Re...

---

## üîß Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## üìÖ Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## üöÄ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## üìù Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## üîç Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
