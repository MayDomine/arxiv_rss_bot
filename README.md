# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-01 05:59:56 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Training Report of TeleChat3-MoE](https://arxiv.org/abs/2512.24157)

**Authors**: Xinzhang Liu, Chao Wang, Zhihao Yang, Zhuo Jiang, Xuncheng Zhao, Haoran Wang, Lei Li, Dongdong He, Luobin Liu, Kaizhe Yuan, Han Gao, Zihan Wang, Yitong Yao, Sishi Xiong, Wenmin Deng, Haowei He, Kaidong Yu, Yu Zhao, Ruiyu Fang, Yuhao Jiang, Yingyan Li, Xiaohui Hu, Xi Yu, Jingqi Li, Yanwei Liu, Qingli Li, Xinyu Shi, Junhao Niu, Chengnuo Huang, Yao Xiao, Ruiwen Wang, Fengkai Li, Luwen Pu, Kaipeng Jia, Fubei Yao, Yuyao Huang, Xuewei He, Zhuoru Jiang, Ruiting Song, Rui Xue, Qiyi Xie, Jie Zhang, Zilu Huang, Zhaoxi Zhang, Zhilong Lu, Yanhan Zhang, Yin Zhang, Yanlei Xue, Zhu Yuan, Teng Su, Xin Jiang, Shuangyong Song, Yongxiang Li, Xuelong Li  
**Category**: cs.CL  
**Published**: 2026-01-01  
**Score**: 15.0  
**Type**: new  
**ArXiv ID**: 2512.24157v1  

#### Abstract
TeleChat3-MoE is the latest series of TeleChat large language models, featuring a Mixture-of-Experts (MoE) architecture with parameter counts ranging from 105 billion to over one trillion,trained end-to-end on Ascend NPU cluster. This technical report mainly presents the underlying training infrastr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Training Report of TeleChat3-MoE*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬è®ºæ–‡æ—¨åœ¨è§£å†³**è¶…å¤§è§„æ¨¡ Mixture-of-Experts (MoE) æ¨¡å‹åœ¨ Ascend NPU é›†ç¾¤ä¸Šç«¯åˆ°ç«¯è®­ç»ƒä¸­çš„å¯é æ€§ã€æ•ˆç‡ä¸å¯æ‰©å±•æ€§æŒ‘æˆ˜**ã€‚å…·ä½“åŒ…æ‹¬ï¼š
- è·¨ç¡¬ä»¶å¹³å°å’Œå¹¶è¡Œç­–ç•¥ä¸‹çš„æ•°å€¼ç²¾åº¦ä¸ä¸€è‡´é—®é¢˜ï¼›
- å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒä¸­é€šä¿¡å¼€é”€å¤§ã€è´Ÿè½½ä¸å‡è¡¡ã€è®¡ç®—åˆ©ç”¨ç‡ä½ç­‰é—®é¢˜ï¼›
- å¹¶è¡ŒåŒ–é…ç½®ä¾èµ–ä¸“å®¶æ‰‹åŠ¨è°ƒä¼˜ï¼Œè€—æ—¶é•¿ä¸”éš¾ä»¥å¤ç°ï¼›
- é›†ç¾¤çº§æ€§èƒ½ç“¶é¢ˆï¼ˆå¦‚ä¸»æœºèµ„æºäº‰ç”¨ã€è®¾å¤‡èŠ‚èƒ½æœºåˆ¶è¯¯è§¦å‘ï¼‰å½±å“è®­ç»ƒååã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

#### ï¼ˆ1ï¼‰ç³»ç»ŸåŒ–çš„**æ•°å€¼ç²¾åº¦éªŒè¯æ¡†æ¶**
- **Operator-level éªŒè¯**ï¼šæ„å»ºåŸºäº CPU çš„â€œé»„é‡‘æ ‡å‡†â€åŸºå‡†ï¼Œç»“åˆè¾“å…¥ç±»å‹è½¬æ¢è§„åˆ™ï¼ˆå¦‚ fp16 â†’ fp32ï¼‰å’Œç´¯åŠ æ¬¡æ•°ç›¸å…³çš„è¯¯å·®å®¹å¿åº¦è¡¨ï¼ˆè§ Table 2ï¼‰ï¼Œå®ç°ç®—å­çº§ç²¾åº¦ä¸€è‡´æ€§æ£€æµ‹ã€‚
- **End-to-end å¯¹é½æµç¨‹**ï¼šæå‡ºè·¨ç¡¬ä»¶è¿ç§»å’Œä¸åŒå¹¶è¡Œç­–ç•¥ä¸‹çš„ä¸¤é˜¶æ®µéªŒè¯æµç¨‹ï¼ˆå•è®¾å¤‡å¯¹é½ â†’ æ¸è¿›å¼æ‰©å±•ï¼‰ï¼Œé€šè¿‡ä¸­é—´å¼ é‡ dump å’Œæ—¥å¿—åˆ†æå®šä½å‰å‘/åå‘ä¼ æ’­æˆ–ä¼˜åŒ–å™¨è¡Œä¸ºå·®å¼‚ã€‚

#### ï¼ˆ2ï¼‰è®­ç»ƒæ¡†æ¶æ€§èƒ½ä¼˜åŒ–
- **Interleaved Pipeline Scheduling + 1F1B é‡å **ï¼šé‡‡ç”¨éè¿ç»­å±‚äº¤é”™åˆ†é…æ–¹å¼ï¼Œå¹¶ç»“åˆ 1F1Bï¼ˆOne Forward One Backwardï¼‰è°ƒåº¦ç­–ç•¥ï¼Œæœ‰æ•ˆå‡å°‘ pipeline bubbleï¼Œæå‡è®¡ç®—ä¸é€šä¿¡é‡å ç‡ã€‚
- **Attention-aware æ•°æ®è°ƒåº¦**ï¼šé’ˆå¯¹é•¿åºåˆ—ç¨€ç–æ³¨æ„åŠ›è®­ç»ƒä¸­å­˜åœ¨çš„è´Ÿè½½ä¸å‡é—®é¢˜ï¼Œæ ¹æ®æ–‡æ¡£é•¿åº¦é‡æ–°ç»„ç»‡ micro-batch å†…æ ·æœ¬åˆ†å¸ƒï¼Œå¹³è¡¡å„è®¾å¤‡ä¸Šçš„ attention è®¡ç®—è´Ÿæ‹…ã€‚
- **Hierarchical & Overlapped Communication for EP**ï¼š
  - å±‚æ¬¡åŒ–é€šä¿¡ï¼šå°†å…¨å±€ All-to-All æ›¿æ¢ä¸º **AllGather â†’ Local Filter â†’ Intra-node All-to-All** ä¸‰æ­¥æµç¨‹ï¼Œæ˜¾è‘—é™ä½è·¨èŠ‚ç‚¹æµé‡ï¼›
  - é€šä¿¡é‡å ï¼šåˆ©ç”¨å¤šç»´æ•°æ®åˆ‡ç‰‡ï¼Œåœ¨ä¸€ä¸ªæµæ‰§è¡Œ FFN æ—¶é‡å å¦ä¸€ä¸ªæµçš„ EP é€šä¿¡ï¼Œå®ç° computation-communication å’Œ communication-communication åŒé‡é‡å ã€‚
- **DVM-based Operator Fusion**ï¼šåŸºäº Device Virtual Machine æ¡†æ¶å®ç°è·¨ç±»ç®—å­èåˆï¼ˆCube-class ä¸ Vector-classï¼‰ï¼Œä¾‹å¦‚ GroupedMatMul-Reshape-Cast èåˆï¼Œå‡å°‘å†…å­˜è®¿é—®å’Œ kernel å¯åŠ¨å¼€é”€ã€‚

#### ï¼ˆ3ï¼‰ç³»ç»ŸåŒ–å¹¶è¡ŒåŒ–é…ç½®ç”Ÿæˆå·¥å…·
- ç»“åˆ**è§£æä¼°è®¡**ä¸**æ•´æ•°çº¿æ€§è§„åˆ’ (Integer Linear Programming, ILP)** è‡ªåŠ¨æœç´¢æœ€ä¼˜å¤šç»´å¹¶è¡Œç­–ç•¥ï¼ˆDP/TP/PP/VPP/EP/SP/OPï¼‰ã€‚
- æ˜¾è‘—ç¼©çŸ­è°ƒä¼˜å‘¨æœŸï¼ˆä» ~7 å¤©é™è‡³ ~0.5 å¤©ï¼‰ï¼ŒåŒæ—¶è¾¾åˆ°ç”šè‡³è¶…è¶Šäººå·¥è°ƒä¼˜æ€§èƒ½ã€‚

#### ï¼ˆ4ï¼‰é›†ç¾¤çº§æ€§èƒ½ä¼˜åŒ–æ–¹æ³•è®º
- **Host-bound ä¼˜åŒ–**ï¼šé€šè¿‡ CPU Affinity ç»‘å®šå’Œå†…æ ¸éš”ç¦»åŸŸå‡å°‘ç›‘æ§è¿›ç¨‹å¹²æ‰°ï¼Œé™ä½æ€§èƒ½æ³¢åŠ¨ã€‚
- **Device-bound ä¼˜åŒ–**ï¼š
  - ä¿®æ”¹å›ºä»¶ä¸­ NPU â€œidle modeâ€ è§¦å‘é˜ˆå€¼ï¼Œé˜²æ­¢çŸ­ç®—å­é¢‘ç¹å¯¼è‡´é™é¢‘ï¼›
  - åˆ‡æ¢ IOMMU ä¸º Passthrough æ¨¡å¼ï¼Œå‡è½»æŸ¥è¯¢å¼•èµ·çš„ host-device äº¤äº’å»¶è¿Ÿã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **ç²¾åº¦æ§åˆ¶** | æä¾›ä»ç®—å­åˆ°æ¨¡å‹çº§çš„å®Œæ•´éªŒè¯é“¾æ¡ï¼Œç¡®ä¿è·¨å¹³å°/å¹¶è¡Œç­–ç•¥ä¸€è‡´æ€§ï¼Œä¼˜äºä¼ ç»Ÿé»‘ç›’æµ‹è¯• |
| **è®­ç»ƒæ•ˆç‡** | å¤šé¡¹ä¼˜åŒ–ååŒä½œç”¨ï¼Œå®ç°è¿‘çº¿æ€§æ‰©å±•è‡³æ•°åƒè®¾å¤‡ï¼Œæ”¯æŒä¸‡äº¿å‚æ•°æ¨¡å‹è®­ç»ƒ |
| **å·¥ç¨‹æ•ˆç‡** | å¹¶è¡Œç­–ç•¥è‡ªåŠ¨ç”Ÿæˆå·¥å…·å¤§å¹…é™ä½äººåŠ›æˆæœ¬å’Œè¯•é”™æ—¶é—´ |
| **ç¡¬ä»¶é€‚é…æ€§** | é’ˆå¯¹ Ascend NPU ç‰¹æ€§æ·±åº¦å®šåˆ¶ï¼Œå……åˆ†å‘æŒ¥å›½äº§ç¡¬ä»¶æ½œåŠ› |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- è®ºæ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºé¢„è®­ç»ƒæ‰€ç”¨çš„å…·ä½“å…¬å¼€æ•°æ®é›†åç§°ï¼›
- å¼ºè°ƒè¿›è¡Œäº†å¤§è§„æ¨¡é¢„è®­ç»ƒä»»åŠ¡ï¼Œæ¶‰åŠ **é•¿è¾¾ 128K tokens çš„é•¿åºåˆ—å»ºæ¨¡**ï¼Œé€‚ç”¨äºé€šç”¨è¯­è¨€ç†è§£ä¸ç”Ÿæˆåœºæ™¯ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šåä¸º Ascend NPU é›†ç¾¤ï¼ˆæœ€å¤šä½¿ç”¨ 8192 å°è®¾å¤‡ï¼‰
- **è½¯ä»¶æ¡†æ¶**ï¼šMindSpore
- **æ¨¡å‹ç³»åˆ—**ï¼šTeleChat3-MoEï¼Œå‚æ•°è§„æ¨¡è¦†ç›–ï¼š
  - 105Bï¼ˆ45 å±‚ï¼‰
  - 438Bï¼ˆ54 å±‚ï¼‰
  - 1119Bï¼ˆ61 å±‚ï¼‰
- **æ¶æ„ç‰¹æ€§**ï¼š
  - Multi-Latent Attention (MLA)
  - æµ…è€Œå®½ç»“æ„ï¼ˆShallow-and-Wideï¼‰
  - é«˜ç¨€ç– MoE æ¶æ„ï¼ˆTop-4 ~ Top-8 è·¯ç”±ï¼Œæ•°ç™¾ä¸ªè·¯ç”±ä¸“å®¶ + 1 ä¸ªå…±äº«ä¸“å®¶ï¼‰

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Model Flops Utilization (MFU)** | è¡¡é‡å®é™…è®¡ç®—åˆ©ç”¨ç‡ï¼Œåæ˜ ç³»ç»Ÿæ•´ä½“æ•ˆç‡ |
| **Step Time (ms)** | å•æ­¥è®­ç»ƒè€—æ—¶ï¼Œç”¨äºæ¯”è¾ƒä¸åŒå¹¶è¡Œç­–ç•¥æ€§èƒ½ |
| **Throughput Improvement (%)** | ç›¸å¯¹äºåŸºçº¿çš„ååæå‡å¹…åº¦ |
| **Scaling Efficiency** | å¤šè®¾å¤‡æ‰©å±•ä¸‹çš„æ€§èƒ½çº¿æ€§åº¦ |
| **Memory Usage** | è®¾å¤‡å³°å€¼æ˜¾å­˜å ç”¨ï¼Œç”¨äºçº¦æŸ ILP ä¼˜åŒ– |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Pipeline Scheduling**ï¼šå¯¹æ¯”ä¼ ç»Ÿ GPipe å’Œ DAPPLEï¼Œæœ¬æ–‡é‡‡ç”¨ Interleaved + 1F1B æ›´é«˜æ•ˆã€‚
- **EP Communication**ï¼šå¯¹æ¯”åŸå§‹å…¨å±€ All-to-Allï¼Œæœ¬æ–‡æå‡ºçš„ hierarchical scheme å‡å°‘å†—ä½™é€šä¿¡ã€‚
- **Parallelism Tuning**ï¼šå¯¹æ¯”ä¸“å®¶æ‰‹å·¥è°ƒä¼˜ï¼ˆExpert Manual Tuningï¼‰ï¼Œæœ¬æ–‡è‡ªåŠ¨åŒ–å·¥å…·æ˜¾è‘—æé€Ÿã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æˆæœ | æ•°æ® |
|------|------|
| **æœ€å¤§æ¨¡å‹è§„æ¨¡** | æˆåŠŸå®Œæˆ **1.119T å‚æ•° MoE æ¨¡å‹** åœ¨ **8192 Ascend NPU** ä¸Šçš„ç«¯åˆ°ç«¯è®­ç»ƒ |
| **MFU è¡¨ç°** | å®ç°é«˜ Model Flops Utilizationï¼Œè¡¨æ˜è®¡ç®—èµ„æºé«˜åº¦åˆ©ç”¨ |
| **æ‰©å±•æ€§** | åœ¨æ•°åƒè®¾å¤‡ä¸Šå®ç°**è¿‘çº¿æ€§æ‰©å±•**ï¼ŒéªŒè¯ç³»ç»Ÿå¯ä¼¸ç¼©æ€§ |
| **EP é€šä¿¡å æ¯”ä¸‹é™** | é€šè¿‡é€šä¿¡é‡å æŠ€æœ¯ï¼ŒEP é€šä¿¡æ—¶é—´å æ€»é€šä¿¡æ—¶é—´æ¯”ä¾‹ä» **30% é™è‡³ 5%** |
| **Hierarchical EP æå‡** | ç›¸æ¯”å…¨å±€ All-to-Allï¼Œè®­ç»ƒååæå‡çº¦ **15%** |
| **DVM ç®—å­èåˆæ€§èƒ½å¢ç›Š** | GroupedMatMul-Reshape-Cast èåˆåæ€§èƒ½æå‡ **~85%**ï¼ˆå•ç®—å­çº§åˆ«ï¼‰ |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœï¼ˆTable 5ï¼‰
| ç­–ç•¥ | è®¾å¤‡æ•°é‡ | Step Time (ms) |
|------|----------|----------------|
| Expert-Designed-1 | 4,096 | 40,076 |
| Expert-Designed-2 | 4,096 | 40,147 |
| **Tool-Generated** | **4,096** | **39,969** âœ… |

ğŸ‘‰ å·¥å…·ç”Ÿæˆç­–ç•¥ä¸ä»…æ›´å¿«ï¼ˆèŠ‚çœçº¦ 100 ms/stepï¼‰ï¼Œè€Œä¸”è°ƒä¼˜æ—¶é—´ä» **7 å¤©ç¼©çŸ­è‡³ 0.5 å¤©**ï¼ˆè§ Table 4ï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆéšå«äºå„èŠ‚æè¿°ï¼‰
- **Interleaved Pipeline + 1F1B**ï¼šå¸¦æ¥çº¦ **10% çš„ç«¯åˆ°ç«¯æ€§èƒ½æå‡**ã€‚
- **Host Isolation**ï¼šåœ¨ 4096 è®¾å¤‡ä»»åŠ¡ä¸­ï¼Œå‡å°‘æ€§èƒ½æ–¹å·®è¾¾ **38%**ï¼Œå¹³å‡ååæå‡ **1â€“2%ï¼ˆå°è§„æ¨¡ï¼‰â†’ 10â€“15%ï¼ˆå¤§è§„æ¨¡ï¼‰**ã€‚
- **NPU å›ºä»¶è°ƒæ•´ï¼ˆé˜²è¯¯å…¥ idle modeï¼‰**ï¼šå¸¦æ¥ **25â€“30% çš„ååæå‡**ã€‚
- **Passthrough IOMMU é…ç½®**ï¼šé¢å¤–è·å¾— **3â€“5% æ€§èƒ½å¢ç›Š**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç³»ç»Ÿæ€§åŸºç¡€è®¾æ–½è®¾è®¡æ˜¯æ”¯æ’‘ä¸‡äº¿çº§ MoE æ¨¡å‹è®­ç»ƒçš„å…³é”®**ï¼šä»…é æ¨¡å‹æ¶æ„æ”¹è¿›ä¸è¶³ä»¥åº”å¯¹æç«¯è§„æ¨¡æŒ‘æˆ˜ï¼Œå¿…é¡»ä»ç®—å­ç²¾åº¦ã€æ¡†æ¶ä¼˜åŒ–ã€å¹¶è¡Œç­–ç•¥ã€é›†ç¾¤ç®¡ç†ç­‰å…¨æ ˆååŒè®¾è®¡ã€‚
2. **è‡ªåŠ¨åŒ–çš„å¹¶è¡Œç­–ç•¥ç”Ÿæˆå¯è¡Œä¸”é«˜æ•ˆ**ï¼šç»“åˆåˆ†æå»ºæ¨¡ä¸ ILP æ±‚è§£å™¨å¯åœ¨æçŸ­æ—¶é—´å†…æ‰¾åˆ°æ¥è¿‘æœ€ä¼˜çš„å¤šç»´å¹¶è¡Œæ–¹æ¡ˆï¼Œæå¤§æå‡ç ”å‘æ•ˆç‡ã€‚
3. **ç¡¬ä»¶æ„ŸçŸ¥ä¼˜åŒ–è‡³å…³é‡è¦**ï¼šå³ä½¿æ˜¯åº•å±‚å›ºä»¶çº§åˆ«çš„èŠ‚èƒ½ç­–ç•¥ä¹Ÿå¯èƒ½æˆä¸ºæ€§èƒ½ç“¶é¢ˆï¼Œéœ€é’ˆå¯¹æ€§è°ƒæ•´ä»¥é‡Šæ”¾ç¡¬ä»¶æ½œåŠ›ã€‚
4. **é«˜ç¨€ç– MoE + æµ…è€Œå®½ç»“æ„ + MLA æ³¨æ„åŠ›** æ˜¯é€‚åˆå¤§è§„æ¨¡é«˜æ•ˆè®­ç»ƒçš„æœ‰æ•ˆç»„åˆï¼Œå…¼é¡¾å‚æ•°æ‰©å±•æ€§ä¸è®¡ç®—å¯†åº¦ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- æ‰€æœ‰å®éªŒå‡åŸºäº **åä¸º Ascend NPU + MindSpore ç”Ÿæ€**ï¼Œé€šç”¨æ€§å—é™äºç‰¹å®šç¡¬ä»¶/è½¯ä»¶æ ˆï¼›
- ç¼ºä¹ä¸å…¶ä»–ä¸»æµ MoE æ¨¡å‹ï¼ˆå¦‚ Mixtralã€DeepSeek-MoEï¼‰åœ¨ç›¸åŒç¡¬ä»¶ä¸Šçš„ç›´æ¥æ€§èƒ½å¯¹æ¯”ï¼›
- æœªæä¾›ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒæ•ˆæœæˆ–æ¨ç†å»¶è¿Ÿæ•°æ®ï¼Œä¾§é‡è®­ç»ƒä¾§è€Œéå…¨ç”Ÿå‘½å‘¨æœŸè¡¨ç°ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- è¿›ä¸€æ­¥æ‰©å¤§æ¨¡å‹è§„æ¨¡ï¼Œæ¢ç´¢ **æ›´é«˜ç»´åº¦çš„æ··åˆå¹¶è¡Œç»„åˆ**ï¼›
- å°†ç³»ç»Ÿä¼˜åŒ–èƒ½åŠ›æ³›åŒ–è‡³æ›´å¤šå›½äº§ AI èŠ¯ç‰‡å¹³å°ï¼›
- å¼€æ”¾æ›´å¤šæ¨¡å‹æƒé‡ä¸è®­ç»ƒä»£ç ï¼Œæ¨åŠ¨ç¤¾åŒºå…±å»ºï¼›
- æ¢ç´¢æ›´æ™ºèƒ½çš„åŠ¨æ€å¹¶è¡Œç­–ç•¥è°ƒæ•´æœºåˆ¶ï¼Œé€‚åº”ä¸åŒè®­ç»ƒé˜¶æ®µéœ€æ±‚ã€‚

---

> ğŸ”— **å¼€æºä¿¡æ¯**ï¼š  
> - GitHub åœ°å€ï¼š[https://github.com/Tele-AI/TeleChat3](https://github.com/Tele-AI/TeleChat3)  
> - è”ç³»é‚®ç®±ï¼š`{liuxz2,wangc17,yangzh17,jiangz13}@chinatelecom.cn`, `zhaoxuncheng2@huawei.com`  
> - é€šè®¯ä½œè€…ï¼š`xuelong-li@chinatelecom.cn`

</details>

---

### 2. [FPGA Co-Design for Efficient N:M Sparse and Quantized Model Inference](https://arxiv.org/abs/2512.24713)

**Authors**: Fen-Yu Hsieh, Yun-Chang Teng, Ding-Yong Hong, Jan-Jan Wu  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.24713v1  

#### Abstract
Large language models (LLMs) have demonstrated remarkable performance across a wide range of language processing tasks. However, this success comes at the cost of substantial computation and memory requirements, which significantly impedes their deployment in resource-constrained environments. To ad...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFPGA Co-Design for Efficient N:M Sparse and Quantized Model Inference

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è™½ç„¶åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶å·¨å¤§çš„è®¡ç®—å’Œå†…å­˜å¼€é”€ä¸¥é‡é™åˆ¶äº†åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„éƒ¨ç½²ã€‚ä¼ ç»Ÿçš„å‹ç¼©æŠ€æœ¯å¦‚**weight pruning**ï¼ˆæƒé‡å‰ªæï¼‰å’Œ**quantization**ï¼ˆé‡åŒ–ï¼‰å•ç‹¬ä½¿ç”¨æ—¶å­˜åœ¨å±€é™æ€§ï¼š
- **Pruning** å‡å°‘æ“ä½œæ•°ä½†ä¿ç•™é«˜ç²¾åº¦æ¿€æ´»ï¼›
- **Quantization** é™ä½ç²¾åº¦ä½†ä¸å‡å°‘è®¡ç®—é‡ã€‚

æ­¤å¤–ï¼Œå½“å‰ç¡¬ä»¶ï¼ˆå¦‚NVIDIA GPUçš„2:4 Sparse Tensor Coresï¼‰ä»…æ”¯æŒå›ºå®šçš„ **N:M sparsity** æ¨¡å¼ï¼ˆå¦‚2:4ï¼‰ï¼Œè€Œç®—æ³•ç ”ç©¶æ˜¾ç¤ºæ›´çµæ´»çš„N:Mæ¨¡å¼å¯èƒ½å¸¦æ¥æ›´é«˜çš„ç²¾åº¦ä¸æ•ˆç‡å¹³è¡¡ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
æœ¬æ–‡æå‡ºäº†ä¸€ç§**è½¯ç¡¬ä»¶ååŒè®¾è®¡æ¡†æ¶**ï¼ˆhardware-software co-designï¼‰ï¼Œç»“åˆ **N:M structured pruning** å’Œ **low-bit quantization**ï¼Œå¹¶åŸºäº **FPGA** æ„å»ºä¸“ç”¨åŠ é€Ÿå™¨ï¼Œå®ç°é«˜æ•ˆLLMæ¨ç†ã€‚ä¸»è¦åˆ›æ–°åŒ…æ‹¬ï¼š

1. **ç»Ÿä¸€çš„å‹ç¼©-æ‰§è¡Œæµæ°´çº¿**  
   æ”¯æŒä»»æ„ **N:M structured sparsity**ï¼ˆä¸é™äº2:4ï¼‰å’Œ **B-bit quantization**ï¼ˆå¦‚INT4ï¼‰ï¼Œé€‚ç”¨äºå¤šç§å¹³å°ï¼ˆCPUã€GPUã€FPGAï¼‰ã€‚

2. **é¢å‘é€šç”¨N:Mæ¨¡å¼çš„FPGAåŠ é€Ÿå™¨è®¾è®¡**  
   è®¾è®¡äº†ä¸€ä¸ªåŸºäº**systolic array**çš„FPGAåŠ é€Ÿå™¨ï¼Œå…·å¤‡ï¼š
   - **Zero-skipping PEs**ï¼šè‡ªåŠ¨è·³è¿‡é›¶å€¼æƒé‡çš„MACæ“ä½œï¼ŒèŠ‚çœç®—åŠ›ï¼›
   - **å¯é‡æ„æ•°æ®è·¯å¾„**ï¼ˆreconfigurable datapathï¼‰ï¼šæ”¯æŒä¸åŒN:Mæ¨¡å¼å’Œbit-widthï¼›
   - **æ— éœ€æ˜¾å¼ç¨€ç–å…ƒæ•°æ®å­˜å‚¨**ï¼šåˆ©ç”¨å¯†é›†å¸ƒå±€ä¿ç•™é›¶å€¼ï¼Œç®€åŒ–ç¡¬ä»¶è§£ç ã€‚

3. **è·¨å¹³å°ä¸€è‡´æ€§åŸºå‡†æµ‹è¯•æµç¨‹**  
   æ‰€æœ‰åç«¯ï¼ˆCPU/GPU/FPGAï¼‰éµå¾ªç›¸åŒçš„æ‰§è¡Œæµï¼ˆåŠ è½½ â†’ dequantization â†’ GEMMï¼‰ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

4. **åˆ†ææ¨¡å‹æŒ‡å¯¼è®¾è®¡ç©ºé—´æ¢ç´¢**  
   æå‡ºé€šç”¨åˆ†ææ¨¡å‹ï¼Œç”¨äºé¢„æµ‹æœ€ä¼˜N:Mé…ç½®ä¸bit-widthï¼Œåœ¨ååã€åˆ©ç”¨ç‡å’Œç²¾åº¦é—´æƒè¡¡ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ¡ˆ | æœ¬æ–‡æ–¹æ¡ˆ |
|------|----------|---------|
| ç¡¬ä»¶æ”¯æŒ | ä»…é™å›ºå®š2:4æ¨¡å¼ï¼ˆå¦‚NVIDIAï¼‰ | æ”¯æŒä»»æ„N:Mæ¨¡å¼ï¼ˆå¦‚2:4, 4:16ç­‰ï¼‰ |
| è½¯ä»¶çµæ´»æ€§ | å¤šæ•°åªé’ˆå¯¹ç‰¹å®šç¡¬ä»¶ä¼˜åŒ– | ç»Ÿä¸€å‹ç¼©æ ¼å¼ï¼Œå¤šå¹³å°å…¼å®¹ |
| å­˜å‚¨æ•ˆç‡ | éœ€é¢å¤–ç´¢å¼•ç»“æ„ç®¡ç†ç¨€ç–æ€§ | å¯†é›†å¸ƒå±€+ä½æ‰“åŒ…ï¼Œæ— é¢å¤–å¼€é”€ |
| åŠ é€Ÿæ½œåŠ› | å—é™äºä¸“ç”¨ç¡¬ä»¶æ”¯æŒ | FPGAæä¾›æ›´é«˜å®šåˆ¶åŒ–ä¸æ‰©å±•æ€§ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†ä¸æ¨¡å‹
- ä½¿ç”¨åˆæˆçŸ©é˜µè¿›è¡Œç»„ä»¶çº§æ€§èƒ½è¯„ä¼°ï¼ˆéçœŸå®æ–‡æœ¬æ•°æ®é›†ï¼‰ï¼›
- æ¨¡å‹è§„æ¨¡åˆ†æåŸºäº **LLaMA-7B** æ¨¡å‹çš„çº¿æ€§å±‚ç»“æ„ï¼ˆå…±32ä¸ªdecoder blockï¼‰ï¼›
- ä¸»è¦å…³æ³¨ **linear layers** ä¸­çš„GEMMè¿ç®—ï¼ˆå ä¸»å¯¼åœ°ä½ï¼‰ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **çŸ©é˜µå°ºå¯¸**ï¼š4096Ã—4096ã€8192Ã—8192ã€12288Ã—12288ï¼›
- **Batch size**ï¼šé»˜è®¤ä¸º **B=512**ï¼ˆä»¥æ‘Šé”€å¯åŠ¨å¼€é”€ï¼‰ï¼›
- **é‡åŒ–æ–¹å¼**ï¼šå¯¹éé›¶æƒé‡é‡‡ç”¨ **symmetric abs-max INT4 quantization**ï¼›
- **Pruningç­–ç•¥**ï¼šmagnitude-based **2:4 structured pruning**ï¼ˆæ¯ç»„4ä¸ªä¿ç•™2ä¸ªæœ€å¤§ç»å¯¹å€¼æƒé‡ï¼‰ï¼›
- **å¹³å°é…ç½®**ï¼š
  - **Host CPU**: Intel Core i9-12900K
  - **GPU**: NVIDIA RTX 3090
  - **FPGA**: AMD Alveo U55Cï¼ˆé€šè¿‡OpenCL/HLSéƒ¨ç½²ï¼‰

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| `t_io` | æƒé‡åŠ è½½æ—¶é—´ |
| `t_deq` | è®¾å¤‡ä¸Šåé‡åŒ–æ—¶é—´ï¼ˆdequantizationï¼‰ |
| `t_mm` | GEMMçŸ©é˜µä¹˜æ³•è€—æ—¶ |
| `t_compute` | `t_deq + t_mm`ï¼ˆçº¯è®¡ç®—æµæ°´çº¿æ—¶é—´ï¼‰ |
| **Throughput (GFLOP/s)** | $ \frac{2 \cdot M \cdot K \cdot B}{t} \times 10^{-9} $ |
| **End-to-end latency reduction** | ç›¸å¯¹äºdense GPU baselineçš„åŠ é€Ÿæ¯” |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åç«¯ | æè¿° |
|------|------|
| **CPU** | PyTorch CPU BLAS backend |
| **GPU (Dense)** | cuBLASæ ‡å‡†GEMM |
| **GPU (2:4 Sparse)** | cuSPARSELtçš„2:4åŠç»“æ„åŒ–ç¨€ç–æ ¸ |
| **FPGA (Ours)** | è‡ªç ”zero-skipping systolic arrayåŠ é€Ÿå™¨ï¼ˆå°šæœªå®Œæˆå®æµ‹ï¼‰ |

> æ³¨ï¼šFPGAéƒ¨åˆ†å°šå¤„äºè®¾è®¡é˜¶æ®µï¼ŒæœªæŠ¥å‘Šå®Œæ•´å®æµ‹æ•°æ®ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“‰ å­˜å‚¨å‹ç¼©æ•ˆæœï¼ˆTable 4ï¼‰
åœ¨ **4096Ã—4096 FP16 denseæƒé‡**ï¼ˆåŸå§‹32MBï¼‰åŸºç¡€ä¸Šï¼š

| æ–¹æ³• | å­˜å‚¨å¤§å° | ç›¸å¯¹å‹ç¼©æ¯” |
|------|--------|-----------|
| Dense FP16 | 32.00 MB | 1.00Ã— |
| Pruned FP16 (50%å¯†åº¦) | 16.00 MB | 0.50Ã— |
| Pruned + INT4ï¼ˆintå¼ é‡å­˜å‚¨ï¼‰ | 16.00 MB | 0.50Ã— |
| Pruned + INT4ï¼ˆbit-packedï¼‰ | **8.00 MB** | **0.25Ã—** |

âœ… **ç»“è®º**ï¼šç»“åˆ2:4 pruningä¸INT4 quantizationï¼Œ**æœ€å¤šå¯å®ç°4Ã—çš„æƒé‡å­˜å‚¨å‹ç¼©**ã€‚

---

### â±ï¸ æ¨ç†å»¶è¿Ÿä¸ååï¼ˆTable 5 & 6ï¼‰

#### åœ¨ 4096Ã—4096, B=512 ä¸‹ï¼š
| Backend | `t_mm` (ms) | `t_compute` (ms) | Throughput_mm (GFLOP/s) | Speedup vs Dense GPU |
|--------|-------------|------------------|--------------------------|-----------------------|
| GPU (Dense) | 0.36 | 0.66 | 47,862 | 1.00Ã— |
| GPU (2:4 Sparse) | **0.21** | **0.51** | **81,968** | **1.71Ã— GEMM**, **1.29Ã— end-to-end** |

âœ… **å…³é”®ç»“æœ**ï¼š
- **GEMMé€Ÿåº¦æå‡1.71Ã—**
- **ç«¯åˆ°ç«¯è®¡ç®—æµæ°´çº¿æé€Ÿ1.29Ã—**

#### ä¸åŒçŸ©é˜µè§„æ¨¡ä¸‹çš„æ‰©å±•æ€§ï¼ˆTable 6ï¼‰
éšç€çŸ©é˜µå¢å¤§ï¼Œç¨€ç–ä¼˜åŠ¿æ›´åŠ æ˜æ˜¾ï¼š
| å°ºå¯¸ | GEMMæ—¶é—´ï¼ˆDenseâ†’Sparseï¼‰ | åŠ é€Ÿæ¯” |
|------|--------------------------|--------|
| 4096Â² | 0.36 â†’ 0.21 ms | 1.71Ã— |
| 8192Â² | 1.05 â†’ 0.64 ms | 1.64Ã— |
| 12288Â² | 2.26 â†’ 1.16 ms | **1.95Ã—** |

> æ›´å¤§é—®é¢˜è§„æ¨¡èƒ½æ›´å¥½æ©ç›–å…ƒæ•°æ®å¼€é”€ï¼Œå‡¸æ˜¾ç»“æ„åŒ–ç¨€ç–ä¼˜åŠ¿ã€‚

---

### ğŸ§® LLaMA-7B æ¨¡å‹çº§é¢„æµ‹æ€§èƒ½ï¼ˆTable 8ï¼‰

ä»…è€ƒè™‘çº¿æ€§å±‚ï¼ˆå¿½ç•¥attentionç­‰å…¶ä»–å¼€é”€ï¼‰çš„æ¯tokenå»¶è¿Ÿé¢„æµ‹ï¼š

| Backend | `T_block` (ms) | `T_model` (ms) | Throughput_model (GFLOP/s) | Speedup vs Dense GPU |
|--------|----------------|----------------|----------------------------|-----------------------|
| CPU | 424.90 | 13,596.80 | 488 | â€” |
| GPU (Dense) | 6.72 | 215.04 | 30,838 | 1.00Ã— |
| GPU (2:4 Sparse) | **4.95** | **158.40** | **41,865** | **1.36Ã—** |

âœ… **ç»“è®º**ï¼š
- ç»“æ„åŒ–ç¨€ç–ä½¿LLaMA-7Bçš„**æ¯tokenååæå‡1.36Ã—**ï¼›
- ç›¸æ¯”CPUå¿«çº¦ **85.67Ã—**ã€‚

---

### âŒ FPGA å½“å‰çŠ¶æ€
å°½ç®¡æå‡ºäº†å®Œæ•´çš„FPGAåŠ é€Ÿå™¨æ¶æ„ï¼ˆå«zero-skipping PEã€systolic arrayã€hostæ¥å£ï¼‰ï¼Œä½†åœ¨æ‰€æœ‰è¡¨æ ¼ä¸­ï¼š
- FPGAç›¸å…³å­—æ®µä¸ºç©ºï¼ˆ`| FPGA (ours) | ... |` è¡¨æ ¼é¡¹ä¸ºç©ºï¼‰
- ä½œè€…æ˜ç¡®æŒ‡å‡ºï¼šâ€œwe plan to complete a full empirical evaluation of the FPGA implementationâ€

â¡ï¸ **ç›®å‰FPGAä¸ºè®¾è®¡è“å›¾ï¼Œå°šæœªå®Œæˆå®æµ‹éªŒè¯**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **N:M structured sparsity + low-bit quantization å…·æœ‰æ˜¾è‘—ååŒæ•ˆåº”**ï¼š
   - è”åˆåº”ç”¨å¯åœ¨ä¿æŒç²¾åº¦çš„åŒæ—¶å¤§å¹…å‡å°‘**æƒé‡å­˜å‚¨ï¼ˆ4Ã—â†“ï¼‰ã€å†…å­˜å¸¦å®½éœ€æ±‚ã€ç®—åŠ›æ¶ˆè€—**ã€‚
   
2. **ç»“æ„åŒ–ç¨€ç–åœ¨ç°ä»£GPUä¸Šæœ‰å®é™…æ”¶ç›Š**ï¼š
   - åˆ©ç”¨NVIDIA 2:4 Sparse Tensor Coresï¼Œåœ¨å…¸å‹LLMçŸ©é˜µè¿ç®—ä¸­å¯è·å¾— **1.71Ã— GEMMåŠ é€Ÿ** å’Œ **1.29Ã— ç«¯åˆ°ç«¯è®¡ç®—åŠ é€Ÿ**ã€‚

3. **æ¨¡å‹çº§æ‰©å±•è¡¨ç°è‰¯å¥½**ï¼š
   - åœ¨LLaMA-7Bä¸Šçº¿æ€§å±‚é¢„æµ‹è¡¨æ˜ï¼Œç»“æ„åŒ–ç¨€ç–å¯å¸¦æ¥ **1.36Ã— çš„ååæå‡**ï¼Œè¯æ˜è¯¥æ–¹æ³•åœ¨çœŸå®æ¨¡å‹è§„æ¨¡ä¸‹ä¾ç„¶æœ‰æ•ˆã€‚

4. **FPGAæ˜¯çªç ´å›ºå®šç¡¬ä»¶é™åˆ¶çš„ç†æƒ³å¹³å°**ï¼š
   - å½“å‰GPUä»…æ”¯æŒ2:4æ¨¡å¼ï¼Œè€Œæœ¬æ–‡æå‡ºçš„FPGAæ¶æ„æ”¯æŒ**ä»»æ„N:M pattern**ï¼Œä¸ºæœªæ¥æ›´é«˜å‹ç¼©ç‡ï¼ˆå¦‚4:16ï¼‰æä¾›ç¡¬ä»¶åŸºç¡€ã€‚

---

### âš ï¸ å±€é™æ€§
1. **FPGAå°šæœªå®æµ‹**ï¼š
   - æ‰€æœ‰FPGAç»“æœä»…ä¸ºè®¾è®¡ï¼Œç¼ºä¹å®é™…æ€§èƒ½ã€åŠŸè€—ã€PPAï¼ˆPower-Performance-Areaï¼‰æ•°æ®æ”¯æ’‘ã€‚

2. **ä»…è¯„ä¼°çº¿æ€§å±‚**ï¼š
   - å¿½ç•¥äº†attention scoresã€softmaxã€RoPEã€normalizationç­‰å…³é”®æ¨¡å—ï¼Œæ•´ä½“tokenå»¶è¿Ÿè¢«ä½ä¼°ã€‚

3. **é™æ€batch sizeå‡è®¾**ï¼š
   - æ‰€æœ‰å®éªŒåŸºäºå›ºå®šB=512ï¼Œæœªè€ƒè™‘åŠ¨æ€batchæˆ–streamingåœºæ™¯çš„å½±å“ã€‚

4. **æœªåŒ…å«è®­ç»ƒæˆ–å¾®è°ƒè¡¥å¿æœºåˆ¶**ï¼š
   - å¦‚LoRAç­‰æ¢å¤ç²¾åº¦çš„æŠ€æœ¯è™½æåŠï¼ˆSLiMï¼‰ï¼Œä½†æœªé›†æˆè¿›æœ¬æ¡†æ¶ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **å®ŒæˆFPGAåŸå‹å®æµ‹**ï¼š
   - éƒ¨ç½²å®Œæ•´ç³»ç»Ÿï¼Œæµ‹é‡å®é™…æ€§èƒ½ã€èƒ½æ•ˆï¼ˆTOPS/Wï¼‰åŠèµ„æºå ç”¨ã€‚

2. **æ‰©å±•è‡³ç«¯åˆ°ç«¯LLMæ¨ç†**ï¼š
   - å°†åŠ é€ŸèŒƒå›´ä»GEMM kernelæ‰©å±•åˆ°æ•´ä¸ªLLaMAæ¨¡å‹æ¨ç†æµç¨‹ã€‚

3. **æ¢ç´¢æ›´é«˜é˜¶å‹ç¼©ç»„åˆ**ï¼š
   - å¼•å…¥mixed-precision activationsã€higher-ratio N:M patternsï¼ˆå¦‚4:16ï¼‰ã€ç”šè‡³ä¸low-rank adaptationï¼ˆLoRAï¼‰è”åˆä¼˜åŒ–ã€‚

4. **æ”¯æŒåŠ¨æ€ç¨€ç–æ¨¡å¼åˆ‡æ¢**ï¼š
   - åˆ©ç”¨FPGAå¯é‡æ„æ€§ï¼Œè¿è¡Œæ—¶åˆ‡æ¢ä¸åŒN:Mé…ç½®ä»¥é€‚åº”ä¸åŒlayeræˆ–æ¨¡å‹ã€‚

5. **è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²éªŒè¯**ï¼š
   - åœ¨åµŒå…¥å¼FPGAæˆ–ä½åŠŸè€—å¹³å°ä¸ŠéªŒè¯è¯¥æ¡†æ¶çš„å®é™…éƒ¨ç½²ä»·å€¼ã€‚

---

## æ€»ç»“

ğŸ“Œ æœ¬æ–‡æå‡ºäº†ä¸€å¥—é¢å‘ **N:M structured sparsity + INT4 quantization** çš„**è½¯ç¡¬ä»¶ååŒè®¾è®¡æ¡†æ¶**ï¼Œå®ç°äº†ï¼š
- æœ€å¤š **4Ã— weight storage reduction**
- **1.71Ã— GEMM speedup** å’Œ **1.29Ã— compute pipeline speedup** on GPU
- å¯¹LLaMA-7Bé¢„æµ‹æ˜¾ç¤º **1.36Ã— throughput improvement**

ğŸ’¡ åˆ›æ–°åœ¨äºå°†ç®—æ³•çµæ´»æ€§ï¼ˆé€šç”¨N:Mï¼‰ä¸ç¡¬ä»¶å®šåˆ¶åŒ–ï¼ˆFPGA systolic array + zero-skippingï¼‰ç»“åˆï¼Œçªç ´å½“å‰GPUå¯¹2:4æ¨¡å¼çš„ç¡¬æ€§çº¦æŸã€‚

âš ï¸ å½“å‰ä¸»è¦å±€é™æ˜¯**FPGAå°šæœªå®æµ‹**ï¼Œæœªæ¥éœ€è¡¥å…¨å®è¯æ•°æ®ï¼Œå¹¶å‘**å…¨æ¨¡å‹ã€å¤šç²¾åº¦ã€ä½åŠŸè€—éƒ¨ç½²**æ¼”è¿›ã€‚

</details>

---

### 3. [MS-SSM: A Multi-Scale State Space Model for Efficient Sequence Modeling](https://arxiv.org/abs/2512.23824)

**Authors**: Mahdi Karami, Ali Behrouz, Peilin Zhong, Razvan Pascanu, Vahab Mirrokni  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.23824v1  

#### Abstract
State-space models (SSMs) have recently attention as an efficient alternative to computationally expensive attention-based models for sequence modeling. They rely on linear recurrences to integrate information over time, enabling fast inference, parallelizable training, and control over recurrence s...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMS-SSM: A Multi-Scale State Space Model for Efficient Sequence Modeling

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **State Space Models (SSMs)** åœ¨åºåˆ—å»ºæ¨¡ä¸­é¢ä¸´ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼š
- **æœ‰é™çš„æœ‰æ•ˆè®°å¿†ï¼ˆlimited effective memoryï¼‰**ï¼šç”±äºå…¶çº¿æ€§é€’å½’ç‰¹æ€§ï¼ŒSSMs éš¾ä»¥é•¿æœŸä¿ç•™å†å²ä¿¡æ¯ï¼Œé€šå¸¸éœ€è¦å¢å¤§çŠ¶æ€ç»´åº¦æ¥æå‡è®°å¿†èƒ½åŠ›ï¼Œå¯¼è‡´æ•ˆç‡ä¸‹é™ã€‚
- **ç¼ºä¹å¤šå°ºåº¦å»ºæ¨¡èƒ½åŠ›ï¼ˆmulti-scale dependency modelingï¼‰**ï¼šç°å®ä¸–ç•Œä¿¡å·ï¼ˆå¦‚è¯­éŸ³ã€å›¾åƒã€æ–‡æœ¬ï¼‰å…·æœ‰å¤šå±‚æ¬¡ç»“æ„ï¼ˆä»å±€éƒ¨ç»†èŠ‚åˆ°å…¨å±€è¶‹åŠ¿ï¼‰ï¼Œè€Œæ ‡å‡† SSMs ç¼ºä¹æ˜¾å¼çš„å¤šåˆ†è¾¨ç‡åˆ†ææœºåˆ¶ï¼Œéš¾ä»¥åŒæ—¶æ•æ‰é«˜é¢‘ç»†èŠ‚å’Œä½é¢‘è¶‹åŠ¿ã€‚

æ­¤å¤–ï¼Œå°½ç®¡æ³¨æ„åŠ›æœºåˆ¶ï¼ˆå¦‚ Transformerï¼‰èƒ½å¤„ç†é•¿ç¨‹ä¾èµ–ï¼Œä½†å…¶ **O(NÂ²)** çš„è®¡ç®—å¤æ‚åº¦é™åˆ¶äº†åœ¨è¶…é•¿åºåˆ—ä¸Šçš„åº”ç”¨ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šMS-SSM
æœ¬æ–‡æå‡º **MS-SSMï¼ˆMulti-Scale State Space Modelï¼‰**ï¼Œä¸€ç§èåˆå¤šå°ºåº¦åˆ†æçš„é«˜æ•ˆ SSM æ¶æ„ï¼Œæ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰**å¤šå°ºåº¦åˆ†è§£ï¼ˆMulti-Scale Decompositionï¼‰**
- å¼•å…¥ **Stationary Wavelet Transform (SWT)** å¯¹è¾“å…¥åºåˆ—è¿›è¡Œå¤šçº§å°æ³¢åˆ†è§£ï¼Œç”Ÿæˆå¤šä¸ªä¸åŒåˆ†è¾¨ç‡çš„å­åºåˆ—ï¼ˆapproximation å’Œ detail coefficientsï¼‰ã€‚
- ä½¿ç”¨å¯å­¦ä¹ çš„ **causal depthwise 1D convolution** å®ç°è¯¥è¿‡ç¨‹ï¼Œæ”¯æŒç«¯åˆ°ç«¯è®­ç»ƒï¼Œå¹¶ä¿æŒå› æœæ€§ï¼ˆé€‚ç”¨äºè‡ªå›å½’ä»»åŠ¡ï¼‰ã€‚
- è¾“å‡ºä¸º $ S+1 $ ä¸ªä¸åŒå°ºåº¦çš„è¡¨ç¤ºï¼ˆ$ S $ ä¸ºåˆ†è§£å±‚æ•°ï¼‰ï¼Œåˆ†åˆ«å¯¹åº”ä¸åŒæ—¶é—´ç²’åº¦çš„ä¿¡æ¯ã€‚

#### ï¼ˆ2ï¼‰**å¹¶è¡Œå¤šå°ºåº¦ SSM å¤„ç†**
- æ¯ä¸ªå°ºåº¦çš„è¡¨ç¤ºç”±ä¸€ä¸ªç‹¬ç«‹çš„ SSM æ¨¡å—å¤„ç†ï¼Œå½¢æˆ $(S+2)$ ä¸ªå¹¶è¡Œè¿è¡Œçš„ SSMï¼ˆå«åŸå§‹è¾“å…¥é€šé“ï¼‰ã€‚
- ä¸åŒå°ºåº¦çš„ SSM å¯ä»¥æ•è·ä»å±€éƒ¨åŠ¨æ€ï¼ˆé«˜åˆ†è¾¨ç‡ï¼‰åˆ°é•¿æœŸè¶‹åŠ¿ï¼ˆä½åˆ†è¾¨ç‡ï¼‰çš„æ—¶åºæ¨¡å¼ã€‚

#### ï¼ˆ3ï¼‰**å°ºåº¦æ„ŸçŸ¥åˆå§‹åŒ–ï¼ˆScale-Dependent Initializationï¼‰**
- å¯¹ä¸åŒå°ºåº¦çš„ SSM çš„çŠ¶æ€è½¬ç§»çŸ©é˜µ $ A $ è¿›è¡Œå·®å¼‚åŒ–åˆå§‹åŒ–ï¼š
  - **ä½åˆ†è¾¨ç‡ï¼ˆç²—ç²’åº¦ï¼‰**ï¼šç‰¹å¾å€¼æ›´æ¥è¿‘ 1 â†’ æ›´å¼ºçš„é•¿æœŸè®°å¿†èƒ½åŠ›ï¼›
  - **é«˜åˆ†è¾¨ç‡ï¼ˆç»†ç²’åº¦ï¼‰**ï¼šç‰¹å¾å€¼è¾ƒå° â†’ æ›´å…³æ³¨çŸ­æœŸåŠ¨æ€ã€‚
- æ­¤è®¾è®¡åŸºäº HiPPO ç†è®ºï¼Œå¢å¼ºæ¨¡å‹å¯¹å¤šå°ºåº¦è®°å¿†éœ€æ±‚çš„é€‚åº”æ€§ã€‚

#### ï¼ˆ4ï¼‰**è¾“å…¥ä¾èµ–çš„å°ºåº¦æ··åˆå™¨ï¼ˆInput-Dependent Scale-Mixerï¼‰**
- å°†å„ SSM çš„è¾“å‡ºé€šè¿‡ä¸€ä¸ª **å¯å­¦ä¹ çš„åŠ æƒæ±‚å’Œ** èåˆï¼š
  $$
  z_t = E_{f}(x_t) \cdot y_t, \quad \text{å…¶ä¸­ } E_f = \text{Linear}_e(x_t)
  $$
- æƒé‡ç”±åŸå§‹è¾“å…¥ $ x_t $ åŠ¨æ€å†³å®šï¼Œå®ç°ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è·¨å°ºåº¦ä¿¡æ¯èåˆã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | MS-SSM çš„æ”¹è¿› |
|------|--------|----------------|
| **Standard SSMs (S4, Mamba)** | å•ä¸€å°ºåº¦å»ºæ¨¡ï¼Œéš¾ä»¥å…¼é¡¾å±€éƒ¨ä¸å…¨å±€ | æ˜¾å¼å¼•å…¥å¤šå°ºåº¦ç»“æ„ï¼Œå¢å¼ºè¡¨è¾¾åŠ› |
| **Transformer** | è‡ªæ³¨æ„åŠ›å¤æ‚åº¦ä¸º $ O(N^2) $ï¼Œä¸é€‚ç”¨äºæé•¿åºåˆ— | ç»§æ‰¿ SSM çš„çº¿æ€§æ¨ç†å¤æ‚åº¦ï¼Œä¿æŒé«˜æ•ˆ |
| **Multi-resolution CNNs (e.g., MULTIRESNET)** | ç¼ºä¹å…¨å±€æ„Ÿå—é‡ï¼Œä¾èµ–å›ºå®šå·ç§¯æ ¸ | ç»“åˆ SSM çš„æ— é™æ„Ÿå—é‡ä¸å¤šå°ºåº¦å·ç§¯ |
| **Fourier-based models (FNet, Prism)** | éå› æœã€æ—¶é—´å®šä½å·® | ä½¿ç”¨å› æœå°æ³¢å·ç§¯ï¼Œé€‚åˆåºåˆ—å»ºæ¨¡ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼š  
> MS-SSM åœ¨ä¿æŒ SSM é«˜æ•ˆæ€§çš„åŒæ—¶ï¼Œé€šè¿‡å¤šå°ºåº¦æ¶æ„æ˜¾è‘—æå‡äº†å¯¹å¤æ‚å±‚æ¬¡ç»“æ„å’Œé•¿ç¨‹ä¾èµ–çš„å»ºæ¨¡èƒ½åŠ›ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | ä»»åŠ¡ç±»å‹ | åºåˆ—é•¿åº¦ | ç‰¹ç‚¹ |
|--------|----------|-----------|-------|
| **sCIFAR-10** | å›¾åƒåˆ†ç±»ï¼ˆåƒç´ çº§åºåˆ—ï¼‰ | 1024 | æ—  2D å½’çº³åç½®ï¼Œè€ƒéªŒé•¿ç¨‹ä¾èµ–å»ºæ¨¡ |
| **ImageNet-1K** | å›¾åƒåˆ†ç±»ï¼ˆpatch åºåˆ—ï¼‰ | ~200 (16Ã—16 patches) | æ ‡å‡†è§†è§‰åŸºå‡† |
| **ListOps** | å±‚æ¬¡åŒ–æ¨ç† | 2048 | åŒ…å«åµŒå¥—æ‹¬å·æ“ä½œï¼Œæµ‹è¯•ç»“æ„ç†è§£èƒ½åŠ› |
| **PTB-XL** | å¿ƒç”µå›¾ï¼ˆECGï¼‰å¤šæ ‡ç­¾åˆ†ç±» | 1000 | å¤šé€šé“æ—¶é—´åºåˆ—ï¼Œéœ€å¤šå°ºåº¦ç‰¹å¾æå– |
| **Long Range Arena (LRA)** | ç»¼åˆé•¿ç¨‹å»ºæ¨¡åŸºå‡† | æœ€é•¿è¾¾ 4K | åŒ…æ‹¬æ–‡æœ¬ã€å›¾åƒã€è·¯å¾„æŸ¥æ‰¾ç­‰ä»»åŠ¡ |

---

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šåŸºäº ViT æ¡†æ¶ï¼Œå°†æ ‡å‡†æ³¨æ„åŠ›å—æ›¿æ¢ä¸º MS-SSM å—ã€‚
- **å˜ä½“å¯¹æ¯”**ï¼š
  - `MS-SSM(S4)`ï¼šä½¿ç”¨ S4 ä½œä¸ºåŸºç¡€ SSM æ¨¡å—ï¼ˆæ•°æ®æ— å…³ï¼‰
  - `MS-SSM(S6)`ï¼šä½¿ç”¨ Mamba ä¸­çš„ S6 æ¨¡å—ï¼ˆè¾“å…¥ä¾èµ–å‚æ•°ï¼‰
- **è¶…å‚ç»Ÿä¸€æ€§**ï¼šä¸åŸºçº¿æ¨¡å‹ä¿æŒç›¸ä¼¼å‚æ•°é‡å’Œéšè—ç»´åº¦ï¼ˆå¦‚ hidden size=256, N=128, S=3ï¼‰ã€‚
- **ä¼˜åŒ–å™¨**ï¼šAdam / AdamWï¼Œå¸¦ warmup å’Œ cosine decayã€‚
- **ç¡¬ä»¶**ï¼šA6000 GPUï¼Œæ‰¹å¤§å°æ ¹æ®ä»»åŠ¡è°ƒæ•´ï¼ˆ50~1024ï¼‰ã€‚

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| ä»»åŠ¡ | ä¸»è¦æŒ‡æ ‡ |
|------|----------|
| åˆ†ç±»ä»»åŠ¡ï¼ˆsCIFAR, ImageNet, PTB-XLï¼‰ | Accuracy / AUROC |
| ListOps | Accuracy (%) |
| LRA Benchmark | å¹³å‡å¾—åˆ†ï¼ˆAVGï¼‰åŠå„é¡¹å­ä»»åŠ¡å‡†ç¡®ç‡ |
| æ¶ˆèå®éªŒ | æ§åˆ¶å˜é‡ä¸‹çš„æ€§èƒ½å˜åŒ– |
| æœ‰æ•ˆæ„Ÿå—é‡åˆ†æ | **Mean Mixing Distance**ï¼ˆåŸºäº Jacobian çš„è·ç¦»åº¦é‡ï¼‰ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | åŸºçº¿æ¨¡å‹ |
|------|---------|
| **Transformer å®¶æ—** | Vanilla Transformer, Linformer, Performer, BigBird, Longformer |
| **RNN / LSTM å˜ç§** | LSTM, r-LSTM, UR-GRU, HiPPO-RNN |
| **SSM å®¶æ—** | S4, S4D, S5, Mamba, Griffin, Liquid-S4 |
| **CNN / Conv-based** | CKConv, MULTIRESNET, InceptionTime |
| **å…¶ä»–é«˜æ•ˆæ¨¡å‹** | SPACE-TIME, H-Transformer-1D |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### âœ… è¡¨ 1ï¼šå›¾åƒåˆ†ç±»æ€§èƒ½ï¼ˆsCIFAR & ImageNet-1Kï¼‰
| Model | sCIFAR Acc (%) | ImageNet-1K Acc (%) |
|-------|----------------|---------------------|
| S4 | 91.1 | 79.1 |
| Mamba | 90.1 | 80.5 |
| MULTIRESNET | 93.0 | 80.2 |
| **MS-SSM(S4)** | **93.3** | **81.3** |

> ğŸ’¡ **ç»“è®º**ï¼šMS-SSM åœ¨ä¸¤é¡¹ä»»åŠ¡ä¸Šå‡è¾¾åˆ° SOTAï¼Œå°¤å…¶åœ¨åƒç´ çº§å»ºæ¨¡ï¼ˆsCIFARï¼‰ä¸­è¡¨ç°çªå‡ºï¼Œè¯´æ˜å…¶å¼ºå¤§çš„å¤šå°ºåº¦å»ºæ¨¡èƒ½åŠ›ã€‚

---

#### âœ… è¡¨ 2ï¼šListOps å±‚æ¬¡æ¨ç†ä»»åŠ¡
| Model | Accuracy (%) |
|-------|--------------|
| Transformer | 36.37 |
| Mamba | 38.02 |
| Mamba (2x å‚æ•°) | 49.63 |
| MULTIRESNET | 62.75 |
| S5 | 62.15 |
| **MS-SSM(S4)** | **62.83** |
| **MS-SSM(S6)** | **63.04** |

> ğŸ’¡ **ç»“è®º**ï¼šMS-SSM æ€§èƒ½è¿œè¶… Mambaï¼ˆçº¦ 2 å€ç²¾åº¦ï¼‰ï¼Œä¸”ä¼˜äºåŒå€å‚æ•°çš„ Mambaï¼Œè¯æ˜å…¶**é«˜æ•ˆçš„å¤šå°ºåº¦è®°å¿†æœºåˆ¶**åœ¨ç»“æ„åŒ–æ¨ç†ä¸­çš„ä¼˜åŠ¿ã€‚

---

#### âœ… è¡¨ 3ï¼šPTB-XL ECG å¤šæ ‡ç­¾åˆ†ç±»ï¼ˆAUROCï¼‰
| Model | All | Diag | Rhythm |
|-------|-----|------|--------|
| Transformer | 0.857 | 0.876 | 0.831 |
| Mamba | 0.915 | 0.929 | 0.952 |
| S4 | 0.938 | 0.939 | 0.977 |
| **MS-SSM(S4)** | **0.939** | **0.939** | **0.980** |

> ğŸ’¡ **ç»“è®º**ï¼šåœ¨åŒ»ç–—æ—¶é—´åºåˆ—ä»»åŠ¡ä¸­ä¹Ÿå–å¾—æœ€ä¼˜æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶åœ¨çœŸå®å¤šå°ºåº¦ä¿¡å·ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚

---

#### âœ… è¡¨ 4ï¼šLong Range Arena ç»¼åˆæ€§èƒ½ï¼ˆAVGï¼‰
| Model | AVG Score |
|-------|-----------|
| Transformer | 62.12 |
| Mamba | 72.30 |
| S5 | 92.52 |
| **MS-SSM(S4)** | **91.89** |
| **MS-SSM(S6)** | **86.73** |

> âš ï¸ æ³¨æ„ï¼šè™½ç„¶ MS-SSM(S6) å› æœªå……åˆ†è°ƒä¼˜ç•¥ä½äº S5ï¼Œä½† **MS-SSM(S4)** å·²æ¥è¿‘æœ€å…ˆè¿›æ°´å¹³ï¼Œä¸”æ˜¾è‘—ä¼˜äºåŒæ¶æ„çš„ Mambaï¼ˆ+19.59 ptsï¼‰ï¼Œè¡¨æ˜å¤šå°ºåº¦è®¾è®¡æœ¬èº«æ˜¯æ€§èƒ½è·ƒå‡çš„å…³é”®ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆè¡¨ 5ï¼‰

| å˜ä½“ | PTB-XL (AUROC) | ListOps (Acc%) | è¯´æ˜ |
|------|----------------|----------------|------|
| Full MS-SSM(S6) | 0.939 | 63.04 | åŸºçº¿ |
| ç§»é™¤ Multi-Scale Conv | 0.916 | 37.98 | â¬‡ï¸â¬‡ï¸å·¨å¤§ä¸‹é™ï¼Œè¯æ˜å¤šå°ºåº¦åˆ†è§£è‡³å…³é‡è¦ |
| ä½¿ç”¨ S4 æ›¿ä»£ S6 | 0.939 | 62.83 | æ€§èƒ½å‡ ä¹ä¸å˜ â†’ æ–¹æ³•ä¸ä¾èµ–ç‰¹å®š SSM æ¨¡å— |
| è¾“å…¥æ— å…³çš„ Scale Mixer | 0.932 | 61.28 | â¬‡ï¸è¯´æ˜è¾“å…¥ä¾èµ–èåˆæ›´ä¼˜ |
| éçº¿æ€§é—¨æ§ï¼ˆSoftmaxï¼‰ | 0.921 | 61.42 | çº¿æ€§æŠ•å½±æ›´æœ‰æ•ˆ |

> âœ… **ç»“è®º**ï¼šæ‰€æœ‰ç»„ä»¶å‡æœ‰è´¡çŒ®ï¼Œä½† **å¤šå°ºåº¦å·ç§¯** æ˜¯æœ€å¤§å¢ç›Šæ¥æºã€‚

---

### ğŸ“ æœ‰æ•ˆæ„Ÿå—é‡åˆ†æï¼ˆè¡¨ 6ï¼‰

| æ¨¡å‹ | Mean Mixing Distance |
|------|------------------------|
| Mamba | 38.84 Â± 21.97 |
| **MS-SSM(S6)** | **94.90 Â± 64.62** |

> ğŸ’¡ **ç»“è®º**ï¼šMS-SSM çš„å¹³å‡æ··åˆè·ç¦»æ˜¾è‘—æ›´é«˜ï¼Œè¯´æ˜å…¶èƒ½å¤Ÿæ›´å¥½åœ°â€œå…³æ³¨â€è¿œè·ç¦»ä¸Šä¸‹æ–‡ï¼Œå…·å¤‡æ›´å¼ºçš„é•¿ç¨‹ä¾èµ–å»ºæ¨¡èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å¤šå°ºåº¦å»ºæ¨¡æå¤§æå‡ SSM è¡¨è¾¾èƒ½åŠ›**ï¼šé€šè¿‡å°†åºåˆ—åˆ†è§£ä¸ºå¤šä¸ªåˆ†è¾¨ç‡å¹¶åœ¨æ¯ä¸ªå°ºåº¦ä¸Šç‹¬ç«‹å»ºæ¨¡ï¼ŒMS-SSM èƒ½åŒæ—¶æ•æ‰å±€éƒ¨ç»†èŠ‚å’Œå…¨å±€è¶‹åŠ¿ï¼Œè§£å†³äº†ä¼ ç»Ÿ SSM è®°å¿†å—é™çš„é—®é¢˜ã€‚
2. **æ— éœ€å¢åŠ å‚æ•°å³å¯è¶…è¶Šå¤§æ¨¡å‹**ï¼šå³ä½¿ä¸åŒå€å‚æ•°çš„ Mamba ç›¸æ¯”ï¼ŒMS-SSM ä»è¡¨ç°å‡ºæ›´ä¼˜æ€§èƒ½ï¼Œè¯´æ˜å…¶ç»“æ„è®¾è®¡å¸¦æ¥äº†æ›´é«˜çš„å‚æ•°åˆ©ç”¨æ•ˆç‡ã€‚
3. **é€šç”¨æ€§å¼º**ï¼šåœ¨å›¾åƒã€æ–‡æœ¬ã€æ—¶é—´åºåˆ—ç­‰å¤šç§æ¨¡æ€ä»»åŠ¡ä¸­å‡å–å¾—é¢†å…ˆç»“æœï¼ŒéªŒè¯äº†å¤šå°ºåº¦ SSM çš„å¹¿æ³›é€‚ç”¨æ€§ã€‚
4. **è¾“å…¥ä¾èµ–çš„å°ºåº¦èåˆä¼˜äºé™æ€èåˆ**ï¼šåŠ¨æ€æƒé‡åˆ†é…æœºåˆ¶ä½¿æ¨¡å‹èƒ½æ ¹æ®å½“å‰è¾“å…¥çµæ´»æ•´åˆå¤šå°ºåº¦ä¿¡æ¯ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å¼€é”€ç•¥æœ‰ä¸Šå‡**ï¼šè™½ç„¶æ€»ä½“å¤æ‚åº¦ä»ä¸ºçº¿æ€§ï¼Œä½†å¤šå°ºåº¦å·ç§¯å¼•å…¥äº†é¢å¤–çš„ $ O(LKS) $ å¼€é”€ï¼ˆ$ K $: kernel size, $ S $: scalesï¼‰ã€‚
- **å°æ³¢æ»¤æ³¢å™¨éœ€å­¦ä¹ è€Œéé¢„è®¾**ï¼šè™½ç„¶æé«˜äº†çµæ´»æ€§ï¼Œä½†ä¹Ÿå¢åŠ äº†è®­ç»ƒéš¾åº¦å’Œå¯¹æ•°æ®çš„éœ€æ±‚ã€‚
- å½“å‰å®éªŒé›†ä¸­åœ¨ä¸­ç­‰è§„æ¨¡ä»»åŠ¡ï¼Œå°šæœªåœ¨è¶…å¤§è§„æ¨¡è¯­è¨€å»ºæ¨¡ï¼ˆå¦‚ 100K+ ä¸Šä¸‹æ–‡ï¼‰ä¸­éªŒè¯ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³æ›´å¤šé¢†åŸŸ**ï¼šåº”ç”¨äº NLP ä¸­çš„ç¯‡ç« ç†è§£ã€ä»£ç ç”Ÿæˆç­‰å¤©ç„¶å…·æœ‰å±‚æ¬¡ç»“æ„çš„ä»»åŠ¡ã€‚
2. **æ¢ç´¢æ–°å‹å¤šå°ºåº¦ç»“æ„**ï¼šç»“åˆéçº¿æ€§ RNN æˆ– test-time training æ¨¡å‹ï¼ˆå¦‚ Titans, Latticeï¼‰è¿›ä¸€æ­¥å¢å¼ºè®°å¿†ã€‚
3. **ç¡¬ä»¶ä¼˜åŒ–å®ç°**ï¼šåˆ©ç”¨ç°ä»£åŠ é€Ÿå™¨ï¼ˆTPU/GPUï¼‰å¯¹å¤šå°ºåº¦å·ç§¯è¿›è¡Œå¹¶è¡ŒåŒ–ä¼˜åŒ–ï¼Œæå‡æ¨ç†é€Ÿåº¦ã€‚
4. **ç†è®ºåˆ†æ**ï¼šå½¢å¼åŒ–è¯æ˜å¤šå°ºåº¦ SSM åœ¨è®°å¿†å®¹é‡å’Œæ¢¯åº¦ä¼ æ’­æ–¹é¢çš„ä¼˜åŠ¿ã€‚

---

## âœ… æ€»ç»“
**MS-SSM** æˆåŠŸåœ°å°† **å¤šåˆ†è¾¨ç‡åˆ†ææ€æƒ³** ä¸ **State Space Models** ç›¸ç»“åˆï¼Œæå‡ºäº†ä¸€ç§æ—¢èƒ½é«˜æ•ˆå¤„ç†é•¿åºåˆ—ã€åˆèƒ½ç²¾ç»†å»ºæ¨¡å¤šå°ºåº¦ç»“æ„çš„æ–°å‹æ¶æ„ã€‚å…¶å®éªŒç»“æœå…¨é¢è¶…è¶Šä¸»æµ SSM å’Œ Transformer å˜ä½“ï¼Œç‰¹åˆ«æ˜¯åœ¨ **é•¿ç¨‹ä¾èµ–ã€å±‚æ¬¡æ¨ç†å’Œå¤šå°ºåº¦æ—¶é—´åºåˆ—åˆ†ç±»** ä»»åŠ¡ä¸­è¡¨ç°å“è¶Šã€‚è¯¥å·¥ä½œä¸ºä¸‹ä¸€ä»£é«˜æ•ˆåºåˆ—æ¨¡å‹çš„è®¾è®¡æä¾›äº†é‡è¦èŒƒå¼â€”â€”**â€œåˆ†è€Œæ²»ä¹‹â€çš„å¤šå°ºåº¦å»ºæ¨¡èŒƒå¼**ã€‚

</details>

---

### 4. [Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization](https://arxiv.org/abs/2512.24615)

**Authors**: Yuchen Shi, Yuzheng Cai, Siqi Cai, Zihan Xu, Lichao Chen, Yulei Qin, Zhijian Zhou, Xiang Fei, Chaofan Qiu, Xiaoyu Tan, Gang Li, Zongyi Li, Haojia Lin, Guocan Cai, Yong Mao, Yunsheng Wu, Ke Li, Xing Sun  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.24615v1  

#### Abstract
Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šYoutu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº **Large Language Model (LLM)** çš„æ™ºèƒ½ä½“æ¡†æ¶é¢ä¸´ä¸¤å¤§ç“¶é¢ˆï¼š

- **é«˜é…ç½®æˆæœ¬**ï¼šæ„å»ºé«˜è´¨é‡ Agent éœ€è¦å¤§é‡äººå·¥å‚ä¸å·¥å…·é›†æˆã€Prompt å·¥ç¨‹å’Œä»£ç ç¼–å†™ï¼Œå¼€å‘é—¨æ§›é«˜ä¸”éš¾ä»¥è§„æ¨¡åŒ–ã€‚
- **é™æ€èƒ½åŠ›é™åˆ¶**ï¼šéƒ¨ç½²åçš„ Agent ç¼ºä¹è‡ªé€‚åº”èƒ½åŠ›ï¼Œæ— æ³•åœ¨ä¸è¿›è¡Œæ˜‚è´µå¾®è°ƒçš„æƒ…å†µä¸‹æŒç»­ä¼˜åŒ–è‡ªèº«è¡Œä¸ºã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡º **Youtu-Agent** â€”â€”ä¸€ä¸ªæ¨¡å—åŒ–ã€æ”¯æŒè‡ªåŠ¨åŒ–ç”Ÿæˆä¸æŒç»­è¿›åŒ–çš„ LLM Agent æ¡†æ¶ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**æ¨¡å—åŒ–æ¶æ„è®¾è®¡**
é‡‡ç”¨ä¸‰å±‚åˆ†å±‚ç»“æ„ï¼š
- **Environment Layer**ï¼šæä¾›æ‰§è¡Œç¯å¢ƒï¼ˆå¦‚æµè§ˆå™¨ã€Shellã€æ²™ç®±ï¼‰
- **Tools Layer**ï¼šå°è£…åŸå­æ“ä½œå·¥å…·ï¼ˆç¯å¢ƒç›¸å…³/æ— å…³/MCP å·¥å…·ï¼‰
- **Agent Layer**ï¼šLLM é©±åŠ¨çš„è§„åˆ’ä¸æ‰§è¡Œå™¨ï¼Œé…åˆ Context Manager æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦

é€šè¿‡ **YAML é…ç½®ç³»ç»Ÿ** å®ç°ç»„ä»¶è§£è€¦ï¼Œä¾¿äºå¤ç”¨å’Œè‡ªåŠ¨åŒ–åˆæˆã€‚

#### ï¼ˆ2ï¼‰**åŒèŒƒå¼è‡ªåŠ¨åŒ–ç”Ÿæˆæœºåˆ¶**
- **Workflow Mode**ï¼šç¡®å®šæ€§å››é˜¶æ®µæµæ°´çº¿ï¼ˆæ„å›¾åˆ†è§£ â†’ å·¥å…·æ£€ç´¢/åˆæˆ â†’ Prompt ç”Ÿæˆ â†’ é…ç½®ç»„è£…ï¼‰ï¼Œé€‚ç”¨äºæ ‡å‡†ä»»åŠ¡ã€‚
- **Meta-Agent Mode**ï¼šç”±é«˜å±‚â€œæ¶æ„å¸ˆ Agentâ€åŠ¨æ€å†³ç­–ç”Ÿæˆæµç¨‹ï¼Œè°ƒç”¨ `search_tool`, `create_tool`, `ask_user`, `create_agent_config` ç­‰èƒ½åŠ›ï¼Œå¤„ç†å¤æ‚æˆ–æ¨¡ç³Šéœ€æ±‚ã€‚

è¯¥æœºåˆ¶å¯è‡ªåŠ¨åˆæˆ Python å·¥å…·ä»£ç ã€Prompt å’Œå®Œæ•´ YAML é…ç½®ã€‚

#### ï¼ˆ3ï¼‰**æ··åˆç­–ç•¥ä¼˜åŒ–ä½“ç³»ï¼ˆHybrid Policy Optimizationï¼‰**
- **Agent Practice æ¨¡å—**ï¼šåŸºäº **Training-free GRPO** çš„æ— æ¢¯åº¦ä¼˜åŒ–ï¼Œåœ¨æ¨ç†æ—¶ç§¯ç´¯ç»éªŒå¹¶æç‚¼â€œæ–‡æœ¬å‹ LoRAâ€ï¼Œå®ç°ä½æˆæœ¬åœ¨çº¿æ”¹è¿›ã€‚
- **Agent RL æ¨¡å—**ï¼šç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¨¡å—ï¼Œé›†æˆåˆ†å¸ƒå¼ RL æ¡†æ¶ï¼ˆå¦‚ VeRLï¼‰ï¼Œè§£å†³é•¿å‘¨æœŸä»»åŠ¡ä¸­çš„â€œç†µçˆ†ç‚¸â€é—®é¢˜ï¼Œå¹¶æå‡è®­ç»ƒç¨³å®šæ€§ä¸æ‰©å±•æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Youtu-Agent ä¼˜åŠ¿ |
|------|------------------|
| **è‡ªåŠ¨åŒ–ç¨‹åº¦** | æ”¯æŒä»è‡ªç„¶è¯­è¨€æè¿°è‡ªåŠ¨ç”Ÿæˆå·¥å…·ä»£ç ä¸é…ç½®ï¼Œè¿œè¶…ä¼ ç»Ÿæ‰‹å·¥é…ç½®æˆ–ä»…è§’è‰²ç¼–æ’çš„æ¡†æ¶ï¼ˆå¦‚ AutoGenã€ChatDevï¼‰ |
| **çµæ´»æ€§ä¸é€šç”¨æ€§** | åŒç”Ÿæˆæ¨¡å¼è¦†ç›–ç®€å•ä¸å¤æ‚åœºæ™¯ï¼›YAML ç»“æ„åŒ–é…ç½®åˆ©äºå…±äº«ä¸è¿­ä»£ |
| **æŒç»­è¿›åŒ–èƒ½åŠ›** | åŒæ—¶æ”¯æŒä½å¼€é”€çš„ in-context ä¼˜åŒ–ï¼ˆPracticeï¼‰å’Œé«˜æ€§èƒ½å‚æ•°æ›´æ–°ï¼ˆRLï¼‰ï¼Œå…¼é¡¾æ•ˆç‡ä¸æ•ˆæœ |
| **å¯æ‰©å±•æ€§ä¸ç¨³å®šæ€§** | RL æ¨¡å—é€šè¿‡ RESTful API å°è£…ã€Ray å¹¶è¡Œã€åˆ†å±‚è¶…æ—¶æ§åˆ¶ç­‰æŠ€æœ¯ï¼Œå®ç° 128 GPU è§„æ¨¡ç¨³å®šè®­ç»ƒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | æè¿° |
|-------|------|
| **WebWalkerQA** (680é¢˜) | å¤šæ­¥ç½‘é¡µå¯¼èˆªä¸é—®ç­”ä»»åŠ¡ï¼Œæµ‹è¯•çœŸå®ç½‘ç«™ä¸Šçš„æ¢ç´¢ä¸ç†è§£èƒ½åŠ› |
| **GAIA (text-only subset)** (466é¢˜) | å®é™…åº”ç”¨åœºæ™¯ä¸‹çš„å¤šè·³æ¨ç†ã€å·¥å…·ä½¿ç”¨ã€æ–‡ä»¶è§£æç­‰ç»¼åˆèƒ½åŠ›è¯„æµ‹ |
| **AIME 2024 / 2025** | æ•°å­¦ç«èµ›é¢˜ï¼Œç”¨äºè¯„ä¼°æ•°å­¦æ¨ç†ä¸ç¼–ç è¾…åŠ©è§£é¢˜èƒ½åŠ› |
| **DAPO-Math-17K** | ç”¨äº Agent Practice æ¨¡å—è®­ç»ƒçš„å°æ ·æœ¬æ•°å­¦æ•°æ®é›†ï¼ˆæŠ½æ · 100 é¢˜ï¼‰ |
| **AgentGen-80** | è‡ªå»ºåŸºå‡†ï¼ŒåŒ…å« 80 ä¸ªå¤šæ ·åŒ–ä»»åŠ¡æè¿°ï¼Œç”¨äºè¯„ä¼°è‡ªåŠ¨åŒ–ç”Ÿæˆè´¨é‡ |

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
| æ¨¡å— | è®¾ç½®è¯´æ˜ | ä¸»è¦æŒ‡æ ‡ |
|------|--------|---------|
| **Benchmark æ€§èƒ½** | å…¨éƒ¨åŸºäºå¼€æºæ¨¡å‹ï¼ˆDeepSeek-V3/Qwen2.5-7Bï¼‰ï¼Œä¸ä¾èµ– GPT/Claude API | Pass@1 å‡†ç¡®ç‡ |
| **è‡ªåŠ¨åŒ–ç”Ÿæˆæœ‰æ•ˆæ€§** | åœ¨ AgentGen-80 ä¸Šæµ‹è¯• Workflow ä¸ Meta-Agent æ¨¡å¼ | CVï¼ˆé…ç½®æœ‰æ•ˆæ€§ï¼‰ã€TEï¼ˆå·¥å…·å¯æ‰§è¡Œæ€§ï¼‰ã€TCï¼ˆä»»åŠ¡å®Œæˆç‡ï¼‰ |
| **Agent Practice** | åŸºäº ReAct èŒƒå¼ + Code Interpreterï¼Œ3 è½®è®­ç»ƒï¼Œæ¯è½® group size=5 | Mean@32ï¼ˆAIMEï¼‰ï¼Œå­¦ä¹ æˆæœ¬ï¼ˆç¾å…ƒä¼°ç®—ï¼‰ |
| **Agent RL** | ä½¿ç”¨ Qwen2.5-7B-Instructï¼Œåœ¨ Math/Code å’Œ Search ä¸¤ç±»ä»»åŠ¡ä¸Šè¿›è¡Œ RL å¾®è°ƒ | Accuracy æå‡å¹…åº¦ã€è®­ç»ƒé€Ÿåº¦ï¼ˆiteration timeï¼‰ã€KL æ•£åº¦ç¨³å®šæ€§ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | å¯¹æ¯”æ–¹æ³• |
|------|--------|
| **Agent æ¡†æ¶** | MetaGPT, AutoGen, ChatDev |
| **è‡ªåŠ¨åŒ–è®¾è®¡** | ADAS, AutoAgents |
| **ä¼˜åŒ–æ–¹æ³•** | ReAct, Reflexion, ZeroTIR, SimpleTIR, ReTool, AFM |
| **RL è®­ç»ƒ** | Agent-Lightning (v0.2.2 å®˜æ–¹ç‰ˆ) |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **WebWalkerQA Pass@1** | **71.47%**ï¼ˆä½¿ç”¨ DeepSeek-V3.1ï¼‰ |
| **GAIA (text-only) Pass@1** | **72.8%** |
| **è‡ªåŠ¨åŒ–å·¥å…·åˆæˆæˆåŠŸç‡ï¼ˆTEï¼‰** | > **81.25%** |
| **ä»»åŠ¡å®Œæˆç‡ï¼ˆTCï¼‰** | Workflow: 65.00%ï¼ŒMeta-Agent: **68.75%** |
| **Agent Practice æå‡ï¼ˆvs ReActï¼‰** | AIME2024: **+2.7%**, AIME2025: **+5.4%**ï¼ˆä»… 100 æ ·æœ¬ï¼Œ~\$18 æˆæœ¬ï¼‰ |
| **Agent RL è®­ç»ƒåŠ é€Ÿ** | è¾ƒå®˜æ–¹ Agent-Lightning **å¿« 40%** |
| **Qwen2.5-7B åœ¨ AIME2024 å‡†ç¡®ç‡æå‡** | ä» **10% â†’ 45%**ï¼ˆ+35ppï¼‰ |
| **æœç´¢ç±» QA å¤šé¡¹æŒ‡æ ‡å¹³å‡æå‡** | **13â€“21%**ï¼ˆTriviaQA åˆ° 2WikiMultiHopï¼‰ |

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ

#### âœ… Benchmark è¡¨ç°ï¼ˆå›¾4 & è¡¨2ï¼‰
- åœ¨ WebWalkerQA ä¸Šä¼˜äºå¤šæ•°é—­æºæ¨¡å‹é©±åŠ¨çš„æ–¹æ³•ï¼ˆå¦‚ WebShaperã€ReRctï¼‰ï¼Œä»…æ¬¡äºéƒ¨åˆ†è®­ç»ƒè¿‡çš„ä¸“æœ‰ç³»ç»Ÿã€‚
- åœ¨ GAIA ä¸Šè¾¾åˆ° 72.8%ï¼Œè¯æ˜å…¶åœ¨çœŸå®ä¸–ç•Œä»»åŠ¡ä¸­å…·å¤‡å¼ºå¤§å·¥å…·è°ƒç”¨ä¸æ¨ç†èƒ½åŠ›ã€‚

#### âœ… è‡ªåŠ¨åŒ–ç”Ÿæˆè¡¨ç°ï¼ˆè¡¨1ï¼‰
| æŒ‡æ ‡ | Workflow Mode | Meta-Agent Mode |
|------|---------------|----------------|
| CVï¼ˆé…ç½®æœ‰æ•ˆï¼‰ | **100%** | 98.75% |
| TEï¼ˆå·¥å…·å¯æ‰§è¡Œï¼‰ | 81.25% | **82.50%** |
| TCï¼ˆä»»åŠ¡å®Œæˆï¼‰ | 65.00% | **68.75%** |

â†’ Meta-Agent åœ¨å¤æ‚ä»»åŠ¡ä¸Šç•¥èƒœä¸€ç­¹ï¼Œä½“ç°å…¶æ›´å¼ºçš„çµæ´»æ€§ã€‚

#### âœ… Agent Practice æ•ˆæœï¼ˆè¡¨2ï¼‰
| æ–¹æ³• | AIME2024 | AIME2025 | å­¦ä¹ æˆæœ¬ |
|------|----------|----------|----------|
| ReAct (baseline) | 80.0 | 67.9 | â€“ |
| + Training-Free GRPO (w/ GT) | **82.7** (+2.7) | **73.3** (+5.4) | ~\$18 |
| ReTool (fine-tuning) | 67.0 | 49.3 | ~\$10,000 |

â†’ **ä»¥æä½æˆæœ¬å®ç°è¶…è¶Šæ˜‚è´µå¾®è°ƒçš„æ•ˆæœ**ï¼Œå°¤å…¶é€‚åˆèµ„æºå—é™åœºæ™¯ã€‚

#### âœ… Agent RL æ•ˆæœï¼ˆè¡¨3 & è¡¨4ï¼‰
| ä»»åŠ¡ | æŒ‡æ ‡ | æå‡å¹…åº¦ |
|------|------|-----------|
| Math (AIME24) | 10% â†’ **45%** | **+35pp** |
| Math (AIME25) | 9% â†’ **31%** | **+22pp** |
| Search (å¹³å‡) | å¤šé¡¹ QA æå‡ | **8â€“21%** |

æ­¤å¤–ï¼Œè®­ç»ƒæ•ˆç‡æå‡ **40%**ï¼Œä¸” KL æ•£åº¦ã€æ¢¯åº¦èŒƒæ•°ä¿æŒç¨³å®šï¼ˆè§å›¾7ï¼‰ï¼Œé¿å…äº†â€œç†µå´©æºƒâ€ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è‡ªåŠ¨åŒ–ç”Ÿæˆæ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„**ï¼šé€šè¿‡ç»“æ„åŒ–é…ç½® + LLM è‡ªåŠ¨ç”Ÿæˆå·¥å…·ä¸ Promptï¼Œå¯æ˜¾è‘—é™ä½ Agent æ„å»ºé—¨æ§›ï¼Œ**å·¥å…·åˆæˆæˆåŠŸç‡è¾¾ 81%+**ã€‚
2. **æ— éœ€å¾®è°ƒä¹Ÿèƒ½æŒç»­è¿›åŒ–**ï¼šAgent Practice æ¨¡å—åˆ©ç”¨ in-context ç»éªŒç§¯ç´¯ï¼Œåœ¨ä»… 100 ä¸ªæ ·æœ¬ä¸‹å³å¯å¸¦æ¥ **+2.7%~5.4%** çš„æ€§èƒ½æå‡ï¼Œæˆæœ¬ä»…ä¸ºä¼ ç»Ÿ SFT/RL çš„åƒåˆ†ä¹‹ä¸€ã€‚
3. **å¤§è§„æ¨¡ RL å¯ç¨³å®šæ‰©å±•**ï¼šé€šè¿‡åŸºç¡€è®¾æ–½ä¼˜åŒ–ï¼ˆRESTfulã€Rayã€åˆ†å±‚è¶…æ—¶ï¼‰å’Œç®—æ³•æ”¹è¿›ï¼ˆè¿‡æ»¤å¼‚å¸¸è½¨è¿¹ã€å‡å°‘ off-policy æ›´æ–°ï¼‰ï¼Œå®ç°äº† **128 GPU è§„æ¨¡ä¸‹çš„ç¨³å®šè®­ç»ƒ**ï¼Œå¹¶å–å¾—æ˜¾è‘—æ€§èƒ½è·ƒè¿ã€‚
4. **å¼€æºæ¨¡å‹ä¹Ÿèƒ½æ„å»ºå¼ºæ™ºèƒ½ä½“**ï¼šå®Œå…¨åŸºäº open-weight æ¨¡å‹ï¼ˆå¦‚ DeepSeek-V3ã€Qwen2.5ï¼‰ï¼Œåœ¨å¤šä¸ª benchmark ä¸Šè¾¾åˆ°ç”šè‡³è¶…è¿‡é—­æºç³»ç»Ÿçš„æ°´å¹³ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å¯¹åº•å±‚ LLM èƒ½åŠ›ä¾èµ–è¾ƒå¼º**ï¼šè‡ªåŠ¨åŒ–ç”Ÿæˆä¸ RL æ•ˆæœå—é™äºåŸºç¡€æ¨¡å‹çš„æ¨ç†ä¸ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚
- **Meta-Agent æ¨¡å¼å¶å°”å¤±è´¥**ï¼š`create_agent_config` å·¥å…·è°ƒç”¨å¯èƒ½è¾“å‡ºæ ¼å¼é”™è¯¯ï¼Œå½±å“æœ€ç»ˆé…ç½®å®Œæ•´æ€§ã€‚
- **ç›®å‰ä¸»è¦é¢å‘å• Agent åœºæ™¯**ï¼šè™½æåŠå¤š Agent åä½œï¼Œä½†æœªæ·±å…¥éªŒè¯å¤æ‚åä½œé€»è¾‘ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•æ›´å¤š **Environment é›†æˆ**ï¼ˆå¦‚ç§»åŠ¨ç«¯ã€IoT è®¾å¤‡ï¼‰
- åŠ å¼º **å¤š Agent ååŒèƒ½åŠ›**
- æ¢ç´¢æ›´é«˜çº§çš„ **ç»éªŒç§¯ç´¯ç­–ç•¥**ï¼ˆå¦‚è®°å¿†å‹ç¼©ã€è·¨ä»»åŠ¡è¿ç§»ï¼‰
- æ¨å‡ºæ¡Œé¢çº§åº”ç”¨ **Tip**ï¼Œæ¨åŠ¨æœ¬åœ°åŒ–ã€éšç§å®‰å…¨çš„ Agent åº”ç”¨è½åœ°

---

> ğŸ”— **é¡¹ç›®åœ°å€**ï¼š[https://github.com/TencentCloudADP/youtu-agent](https://github.com/TencentCloudADP/youtu-agent)  
> ğŸ“… **å‘å¸ƒæ—¥æœŸ**ï¼šDecember 26, 2025

</details>

---

### 5. [Yggdrasil: Bridging Dynamic Speculation and Static Runtime for Latency-Optimal Tree-Based LLM Decoding](https://arxiv.org/abs/2512.23858)

**Authors**: Yue Guan, Changming Yu, Shihan Fang, Weiming Hu, Zaifeng Pan, Zheng Wang, Zihan Liu, Yangjie Zhou, Yufei Ding, Minyi Guo, Jingwen Leng  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.23858v1  

#### Abstract
Speculative decoding improves LLM inference by generating and verifying multiple tokens in parallel, but existing systems suffer from suboptimal performance due to a mismatch between dynamic speculation and static runtime assumptions. We present Yggdrasil, a co-designed system that enables latency-o...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šYggdrasil: Bridging Dynamic Speculation and Static Runtime for Latency-Optimal Tree-Based LLM Decoding

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰çš„ **speculative decoding** ç³»ç»Ÿåœ¨æå‡ LLM æ¨ç†é€Ÿåº¦æ–¹é¢è¡¨ç°å‡ºæ½œåŠ›ï¼Œä½†å­˜åœ¨ä¸€ä¸ªæ ¹æœ¬æ€§çŸ›ç›¾ï¼š  
- **åŠ¨æ€æ¨æµ‹ç®—æ³•**ï¼ˆdynamic speculationï¼‰èƒ½æœ‰æ•ˆæé«˜ token æ¥å—ç‡ï¼ˆå¦‚é€šè¿‡ context-aware æ ‘ç»“æ„ï¼‰ï¼Œä½†å…¶åŠ¨æ€å˜åŒ–çš„æ ‘ç»“æ„å’Œç®—å­å½¢çŠ¶ç ´åäº†ç°ä»£æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨å¯¹ **é™æ€è®¡ç®—å›¾** çš„ä¼˜åŒ–å‡è®¾ï¼ˆå¦‚ graph fusionã€kernel tuningã€CUDA Graph æ”¯æŒï¼‰ã€‚  
- åä¹‹ï¼Œ**é™æ€è¿è¡Œæ—¶ç³»ç»Ÿ**ï¼ˆå¦‚ vLLMã€TRT-LLMï¼‰è™½èƒ½åˆ©ç”¨ç¼–è¯‘ä¼˜åŒ–é™ä½å»¶è¿Ÿï¼Œå´æ— æ³•æ”¯æŒçµæ´»çš„åŠ¨æ€æ¨æµ‹ï¼Œé™åˆ¶äº†å¹³å‡æ¥å—é•¿åº¦ï¼ˆAALï¼‰ã€‚

æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸ä»¥æœ€å¤§åŒ– **AAL** ä¸ºç›®æ ‡ï¼Œå¿½ç•¥äº†éªŒè¯é˜¶æ®µçš„éå‡åŒ€å¼€é”€ï¼Œå¯¼è‡´é«˜ AAL å¹¶ä¸ç­‰äºç«¯åˆ°ç«¯ä½å»¶è¿Ÿã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

Yggdrasil æå‡ºäº†ä¸€ç§ **ç®—æ³•ä¸è¿è¡Œæ—¶ååŒè®¾è®¡**ï¼ˆco-designedï¼‰çš„ latency-optimal æ ‘å½¢æ¨æµ‹è§£ç æ¡†æ¶ï¼Œæ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### âœ… **Latency-aware Optimization Objective**
- ä¸å†ä»¥ AAL ä¸ºå”¯ä¸€ç›®æ ‡ï¼Œè€Œæ˜¯æ„å»ºäº†ä¸€ä¸ªæ›´çœŸå®çš„ **ç«¯åˆ°ç«¯é€Ÿåº¦æå‡æ¨¡å‹**ï¼š
  $$
  \text{Speedup} = \frac{\text{AAL}(W_{\text{draft}}, D_{\text{draft}}, W_{\text{verify}}) \cdot T_{\text{verify}}(1)}{2D_{\text{draft}}T_{\text{drafter}}(W_{\text{draft}}) + T_{\text{verify}}(W_{\text{verify}})}
  $$
- æ˜¾å¼å»ºæ¨¡äº† draft å’Œ verify é˜¶æ®µçš„æ—¶é—´å¼€é”€ï¼Œå®ç°å¯¹çœŸå® wall-clock æ—¶é—´çš„ä¼˜åŒ–ã€‚

#### âœ… **Equal-Growth Tree (EGT) ç»“æ„**
- ä¸€ç§æ–°å‹çš„ **é™æ€å…¼å®¹ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥** çš„æ ‘ç»“æ„ï¼š
  - æ‰€æœ‰åˆ†æ”¯åœ¨æ¯ä¸€æ­¥éƒ½åŒæ­¥å¢é•¿ï¼ˆequal-growthï¼‰ï¼Œä¿è¯æ¯ä¸ª step çš„ operator shape å›ºå®šï¼Œå…¼å®¹ **TorchInductor** ç­‰ç¼–è¯‘å™¨çš„å›¾èåˆä¸ CUDA Graphã€‚
  - æ”¯æŒåŠ¨æ€è°ƒæ•´æ ‘å®½ $W_{\text{draft}}$ å’ŒéªŒè¯å®½åº¦ $W_{\text{verify}}$ï¼Œä¿ç•™çµæ´»æ€§ã€‚
- åŒ…å«ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼š
  1. **Draft Depth Predictor**ï¼šè½»é‡çº§å¤šå¤´ MLP æ¨¡å‹ï¼Œé¢„æµ‹æœ€ä¼˜ draft æ·±åº¦ $D_{\text{draft}}$ã€‚
  2. **Draft Width Selection**ï¼šåŸºäºé¢„æµ‹æ·±åº¦é€‰æ‹©æœ€ä¼˜å®½åº¦ä»¥å¹³è¡¡ AAL ä¸éªŒè¯å¼€é”€ã€‚
  3. **Verification Width Pruning**ï¼šä»ç”Ÿæˆçš„æ ‘ä¸­å‰ªæå‡ºæœ€ä¼˜å­æ ‘ç”¨äºéªŒè¯ï¼Œæœ€å¤§åŒ–å®é™… speedupã€‚

#### âœ… **Stage-based Scheduling Runtime**
- é’ˆå¯¹ speculative decoding å¤šé˜¶æ®µä¾èµ–å¸¦æ¥çš„ CPU å¼€é”€ï¼Œæå‡ºä¸¤ç§ä¼˜åŒ–ï¼š
  1. **Ahead-of-Time Stage Execution**ï¼š
     - æå‰æ‰§è¡Œ "Tail Draft" å’Œ "Head Draft" é˜¶æ®µï¼Œæ¶ˆé™¤æ¡ä»¶åˆ†æ”¯ï¼Œé¿å… GPU ç©ºè½¬ã€‚
  2. **Profile-Guided Execution Plan Search**ï¼š
     - åœ¨ç¼–è¯‘æœŸåŸºäº profiling æ•°æ®æœç´¢æœ€ä¼˜æ‰§è¡Œè®¡åˆ’ï¼ˆexecution planï¼‰ï¼Œæœ€å°åŒ–è°ƒåº¦å¼€é”€ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | Yggdrasil | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ SpecInfer, Sequoia, vLLM-Specï¼‰ |
|------|----------|---------------------------------------------|
| **ç®—æ³•çµæ´»æ€§** | âœ”ï¸ ä¸Šä¸‹æ–‡æ„ŸçŸ¥ã€åŠ¨æ€è°ƒæ•´æ ‘ç»“æ„ | âŒ é™æ€æ ‘æˆ–å›ºå®šç­–ç•¥ |
| **ç¼–è¯‘å‹å¥½æ€§** | âœ”ï¸ å›ºå®š operator shapeï¼Œæ”¯æŒ CUDA Graph | âŒ åŠ¨æ€æ§åˆ¶æµé˜»ç¢ç¼–è¯‘ä¼˜åŒ– |
| **ä¼˜åŒ–ç›®æ ‡** | âœ”ï¸ ä»¥çœŸå® latency ä¸ºå¯¼å‘ | âŒ ä»…ä¼˜åŒ– AALï¼Œå¿½ç•¥éªŒè¯æˆæœ¬ |
| **CPU-GPU åè°ƒ** | âœ”ï¸ å‡å°‘æ¡ä»¶åˆ¤æ–­ï¼Œé‡å æ‰§è¡Œ | âŒ è¿è¡Œæ—¶é¢‘ç¹åŒæ­¥ï¼ŒGPU åˆ©ç”¨ç‡ä½ |
| **æ— éœ€ä¿®æ”¹æ¨¡å‹** | âœ”ï¸ æ”¯æŒåŸç”Ÿ LLM æ¶æ„ | âŒ éƒ¨åˆ†æ–¹æ³•éœ€ä¿®æ”¹æ¨¡å‹ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **C4** [39]
- **Wikipedia** [45]
- **CNNDailyMail (CNN)** [18]

### **å®éªŒè®¾ç½®**
- **ç¡¬ä»¶å¹³å°**ï¼š
  - NVIDIA A100 (80GB)
  - NVIDIA A40
  - Intel Xeon E5-2620 v3 @ 2.40GHz CPU
- **è½¯ä»¶æ ˆ**ï¼š
  - CUDA 11.7
  - PyTorch + **TorchInductor** ç¼–è¯‘åç«¯
- **æ¨¡å‹é…ç½®**ï¼š
  - **Target Models**: Llama-2-7B, Llama-2-13B
  - **Draft Models**: Llama-68M, Llama-160M
- **è¾“å…¥é•¿åº¦**ï¼š512 tokens
- **è¾“å‡ºé•¿åº¦**ï¼š256 tokens

### **è¯„ä¼°æŒ‡æ ‡**
- **Per-Token Generation Latency (TPOT)**ï¼šæ ¸å¿ƒæŒ‡æ ‡
- **End-to-End Speedup**ï¼šç›¸å¯¹äº baseline çš„åŠ é€Ÿæ¯”
- **Average Accepted Length (AAL)**
- **Step Latency**
- **GPU Utilization**

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **SpecInfer** [31]ï¼šç»å…¸æ ‘å½¢æ¨æµ‹æ–¹æ³•ï¼Œä½†åŠ¨æ€ç»“æ„ä¸å…¼å®¹ç¼–è¯‘ä¼˜åŒ–
- **Sequoia** [8]ï¼šé™æ€è‡ªé€‚åº”æ ‘ç»“æ„ï¼Œdataset-level è°ƒä¼˜
- **vLLM-Spec** [27]ï¼šåŸºäº vLLM çš„ speculative decoding å®ç°
- **FlexFlow**ï¼šé€šç”¨ LLM serving ç³»ç»Ÿ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| é…ç½® | Yggdrasil åŠ é€Ÿæ¯”ï¼ˆvs. SpecInferï¼‰ |
|------|-------------------------------|
| A100 GPU | **æœ€é«˜è¾¾ 3.98Ã—** |
| A40 GPU | **æœ€é«˜è¾¾ 2.76Ã—** |

> æ³¨ï¼šæ‰€æœ‰ç»“æœå‡ä»¥ **per-token latency** ä¸ºè¡¡é‡æ ‡å‡†ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- åœ¨æ‰€æœ‰æµ‹è¯•é…ç½®ä¸‹ï¼ŒYggdrasil **æ˜¾è‘—ä¼˜äºæ‰€æœ‰ baseline**ï¼š
  - ç›¸æ¯” **SpecInfer**ï¼šå¹³å‡æå‡ **3.98Ã—**ï¼ˆA100ï¼‰
  - ç›¸æ¯” **Sequoia** å’Œ **vLLM-Spec**ï¼šåˆ†åˆ«æå‡ **1.6Ã—~2.0Ã—**
- å°¤å…¶åœ¨ **A100** ä¸Šä¼˜åŠ¿æ›´å¤§ï¼Œå› å…¶æ›´é«˜çš„å†…å­˜å¸¦å®½åˆ©ç”¨ç‡ç“¶é¢ˆè¢«æ›´å¥½ç¼“è§£ã€‚

### **æ¶ˆèå®éªŒç»“æœ**

ä½œè€…å°† Yggdrasil çš„ä¼˜åŒ–åˆ†è§£ä¸ºäº”ä¸ªéƒ¨åˆ†è¿›è¡Œæ¶ˆèåˆ†æï¼ˆè§ Figure 12ï¼‰ï¼š

| ä¼˜åŒ–é¡¹ | æè¿° | å¹³å‡åŠ é€Ÿæ¯”è´¡çŒ® |
|--------|------|----------------|
| **O1** | Latency-aware æ ‘æ¨æµ‹ï¼ˆåŸºç¡€ç‰ˆï¼‰ | åŸºçº¿ |
| **O2** | TorchInductor å›¾ç¼–è¯‘ä¼˜åŒ– | **2.775Ã—**ï¼ˆæœ€å¤§è´¡çŒ®ï¼‰ |
| **O3** | Verification Width Pruning | **1.07Ã—** |
| **O4** | Stage-based Scheduling | **1.21Ã—** |
| **O5** | Draft Depth Predictor | **1.10Ã—** |

> âœ… æ‰€æœ‰ä¼˜åŒ–å…·æœ‰æ­£å‘å åŠ æ•ˆåº”ï¼Œæ€»åŠ é€Ÿæ¯”è¾¾ **3.98Ã—**

### **å…¶ä»–é‡è¦å®éªŒå‘ç°**

- **EGT å‚æ•°æ•æ„Ÿæ€§åˆ†æ**ï¼ˆFigure 13ï¼‰ï¼š
  - æœ€ä½³é…ç½®ä¾èµ–äºç¡¬ä»¶å’Œæ¨¡å‹è§„æ¨¡ã€‚
  - ç¤ºä¾‹ï¼š`D_draft=8`, `W_draft=8`, `W_verify=64` åœ¨ Llama-2-7B ä¸Šè¡¨ç°æœ€ä½³ã€‚

- **ä¼˜åŒ–ç›®æ ‡å¯¹æ¯”**ï¼ˆFigure 14ï¼‰ï¼š
  - ä½¿ç”¨ **speedup ç›®æ ‡** æ¯”ç›´æ¥ä¼˜åŒ– AAL æå‡ **é¢å¤– 8% æ€§èƒ½**ã€‚

- **æ¸©åº¦å½±å“**ï¼ˆFigure 15ï¼‰ï¼š
  - æ¸©åº¦è¶Šä½ï¼Œdraft model ä¸ target model å¯¹é½è¶Šå¥½ï¼ŒAAL è¶Šé«˜ã€‚
  - Yggdrasil åœ¨ä¸åŒæ¸©åº¦ä¸‹å§‹ç»ˆä¼˜äº Sequoiaï¼Œå¹³å‡ **1.49Ã— åŠ é€Ÿ**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **åŠ¨æ€æ¨æµ‹ä¸é™æ€è¿è¡Œæ—¶å¯ä»¥å…¼å¾—**ï¼š
   - EGT ç»“æ„æˆåŠŸæ¡¥æ¥äº†ä¸¤è€…ï¼Œæ—¢ä¿æŒäº† context-aware çš„çµæ´»æ€§ï¼Œåˆæ»¡è¶³äº†ç¼–è¯‘ä¼˜åŒ–æ‰€éœ€çš„é™æ€æ€§ã€‚

2. **AAL â‰  å®é™…åŠ é€Ÿ**ï¼š
   - å•çº¯è¿½æ±‚é«˜ AAL å¯èƒ½å› éªŒè¯å¼€é”€è¿‡å¤§è€Œå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼›å¿…é¡»ç»“åˆç¡¬ä»¶ç‰¹æ€§è¿›è¡Œè”åˆä¼˜åŒ–ã€‚

3. **ç¼–è¯‘ä¼˜åŒ–è‡³å…³é‡è¦**ï¼š
   - O2ï¼ˆå›¾ç¼–è¯‘ï¼‰å¸¦æ¥æœ€å¤§æ”¶ç›Šï¼ˆ2.775Ã—ï¼‰ï¼Œè¯´æ˜å³ä½¿ç®—æ³•å…ˆè¿›ï¼Œè‹¥ä¸èƒ½è¢«é«˜æ•ˆæ‰§è¡Œä¹Ÿéš¾ä»¥å‘æŒ¥æ½œåŠ›ã€‚

4. **CPU-GPU åè°ƒæ˜¯ç“¶é¢ˆ**ï¼š
   - Stage-based scheduling æœ‰æ•ˆå‡å°‘ç©ºè½¬ï¼Œè¯æ˜ speculative decoding çš„è°ƒåº¦æœ¬èº«éœ€è¦ä¸“é—¨ä¼˜åŒ–ã€‚

### **å±€é™æ€§**

- å½“å‰è¯„ä¼°åŸºäº **å•è¯·æ±‚ã€ä½å¹¶å‘åœºæ™¯**ï¼ˆlatency-optimal settingï¼‰ï¼Œé€‚ç”¨äºè¾¹ç¼˜æˆ–äº¤äº’å¼åº”ç”¨ã€‚
- **æœªè€ƒè™‘æ‰¹å¤„ç†åœºæ™¯**ï¼ˆthroughput-oriented servingï¼‰ï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒä¸­éœ€ä¸ batch scheduler ååŒè®¾è®¡ã€‚
- Draft model ä»éœ€å¤–éƒ¨æä¾›ï¼Œæœªè§£å†³ draft model è®­ç»ƒæˆ–å¯¹é½é—®é¢˜ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- å°† Yggdrasil æ‰©å±•è‡³ **batched serving åœºæ™¯**ï¼Œè”åˆä¼˜åŒ– speculative decoding ä¸ dynamic batchingã€‚
- è®¾è®¡ç»Ÿä¸€ç­–ç•¥ï¼Œåè°ƒå¤šä¸ªè¯·æ±‚çš„ speculation å†³ç­–ä¸èµ„æºåˆ†é…ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„ depth predictor æˆ–åœ¨çº¿è‡ªé€‚åº”æœºåˆ¶ã€‚
- æ”¯æŒæ›´å¤šç¡¬ä»¶æ¶æ„ï¼ˆå¦‚ TPUã€NPUï¼‰å’Œç¼–è¯‘å™¨ï¼ˆå¦‚ TensorRT-LLMï¼‰ã€‚

---

> **æ€»ç»“**ï¼šYggdrasil æ˜¯é¦–ä¸ªçœŸæ­£å®ç° **â€œåŠ¨æ€ç®—æ³• + é™æ€æ‰§è¡Œâ€ååŒä¼˜åŒ–** çš„ speculative decoding ç³»ç»Ÿï¼Œé€šè¿‡ **EGT ç»“æ„ã€latency-aware ç›®æ ‡ã€stage-based è°ƒåº¦** ä¸‰å¤§åˆ›æ–°ï¼Œåœ¨æ— éœ€ä¿®æ”¹æ¨¡å‹çš„å‰æä¸‹å®ç°äº†é«˜è¾¾ **3.98Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿ**ï¼Œä¸º LLM é«˜æ•ˆæ¨ç†æä¾›äº†æ–°çš„èŒƒå¼ã€‚

</details>

---

### 6. [From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning](https://arxiv.org/abs/2512.24532)

**Authors**: Amir Tahmasbi, Sadegh Majidi, Kazem Taram, Aniket Bera  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.24532v1  

#### Abstract
Spatial reasoning in large language models (LLMs) has gained increasing attention due to applications in navigation and planning. Despite strong general language capabilities, LLMs still struggle with spatial transformations and multi-step planning in structured environments. We propose a two-stage ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFrom Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é€šç”¨è¯­è¨€ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨**ç©ºé—´æ¨ç†**ï¼ˆspatial reasoningï¼‰å’Œ**å¤šæ­¥è§„åˆ’**ï¼ˆmulti-step planningï¼‰æ–¹é¢ä»å­˜åœ¨æ˜¾è‘—ç¼ºé™·ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦ç†è§£æ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾ç­‰ç©ºé—´å˜æ¢çš„ç»“æ„åŒ–ç¯å¢ƒä¸­ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–å¤–éƒ¨æ±‚è§£å™¨æˆ–ç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ ï¼ˆend-to-end RLï¼‰ï¼Œéš¾ä»¥æœ‰æ•ˆå»ºæ¨¡åº•å±‚ç‰©ç†è§„å¾‹å¹¶è¿›è¡Œç¨³å®šè®­ç»ƒã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§**ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶**ï¼Œå°†å¤æ‚çš„ç©ºé—´æ¨ç†ä»»åŠ¡åˆ†è§£ä¸ºå¯å­¦ä¹ çš„â€œæ„å»ºå—â€ï¼ˆbuilding blocksï¼‰åŠå…¶ç»„åˆç­–ç•¥ï¼š

1. **ç¬¬ä¸€é˜¶æ®µï¼šç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuning, SFTï¼‰**
   - åœ¨ä¸€ä¸ªåˆæˆçš„ **ASCII-art æ•°æ®é›†** ä¸Šå¯¹ LLM è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶æŒæ¡åŸºæœ¬çš„ç©ºé—´åŸå­æ“ä½œï¼ˆatomic transformationsï¼‰ï¼š
     - **Translation**ï¼ˆå¹³ç§»ï¼‰
     - **Rotation**ï¼ˆæ—‹è½¬ï¼‰
     - **Scaling**ï¼ˆç¼©æ”¾ï¼‰
   - å¾—åˆ°ä¸€ä¸ªå…·å¤‡åŸºç¡€â€œç©ºé—´ç‰©ç†ç›´è§‰â€çš„æ¨¡å‹ï¼š`Qwen-Physics`

2. **ç¬¬äºŒé˜¶æ®µï¼šåŸºäº LoRA çš„å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning with GRPOï¼‰**
   - å†»ç»“ `Qwen-Physics` çš„ä¸»å¹²å‚æ•°
   - å¼•å…¥è½»é‡çº§ **LoRA adapters**ï¼Œåœ¨é—­åˆå›è·¯ï¼ˆclosed-loopï¼‰ç¯å¢ƒä¸­ä½¿ç”¨ **GRPO**ï¼ˆGeneralized Reward Policy Optimizationï¼‰ä¼˜åŒ–ç­–ç•¥
   - å­¦ä¹ å¦‚ä½•å°†åŸå­æ“ä½œç»„åˆæˆæœ‰æ•ˆçš„å¤šæ­¥è®¡åˆ’ä»¥è¾¾æˆç›®æ ‡é…ç½®

> ğŸ” åˆ›æ–°ç‚¹æ€»ç»“ï¼š
> - **æ¨¡å—åŒ–è®¾è®¡**ï¼šå°†â€œæ„ŸçŸ¥/ç‰©ç†ç†è§£â€ä¸â€œå†³ç­–/è§„åˆ’â€åˆ†ç¦»ï¼Œé¿å… RL ä»é›¶å­¦ä¹ ç©ºé—´çŸ¥è¯†
> - **é«˜æ•ˆè®­ç»ƒ**ï¼šä»…è®­ç»ƒ LoRA å‚æ•°ï¼Œå¤§å¹…é™ä½è®¡ç®—å¼€é”€
> - **æ›´å¼ºæ³›åŒ–èƒ½åŠ›**ï¼šé€šè¿‡æ„å»ºå—ç»„åˆå®ç°å¤æ‚ä»»åŠ¡æ±‚è§£

### âš–ï¸ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ç¼ºé™· | æœ¬è®ºæ–‡ä¼˜åŠ¿ |
|------|------|------------|
| Generic LLMï¼ˆå¦‚ Qwen-Instructï¼‰ | ç¼ºä¹ç©ºé—´å…ˆéªŒï¼Œæ— æ³•å‡†ç¡®æ‰§è¡ŒåŸºæœ¬å˜æ¢ | SFT é˜¶æ®µæ³¨å…¥ç©ºé—´ç‰©ç†çŸ¥è¯† |
| End-to-End RLï¼ˆå¦‚ Qwen-DirectRLï¼‰ | è®­ç»ƒä¸ç¨³å®šã€æ”¶æ•›æ…¢ã€éš¾ä»¥å†…åŒ–çŠ¶æ€è®°å¿† | ä½¿ç”¨ç‰©ç†æ„ŸçŸ¥æ¨¡å‹ä½œä¸ºåˆå§‹åŒ–ï¼Œæå‡ç¨³å®šæ€§ä¸æ•ˆç‡ |
| Prompting-based æ–¹æ³•ï¼ˆå¦‚ VoTï¼‰ | ä¾èµ–æç¤ºå·¥ç¨‹ï¼Œé²æ£’æ€§å·® | æ˜¾å¼å­¦ä¹ å¯è¿ç§»çš„ç©ºé—´æ“ä½œç­–ç•¥ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“ ä½¿ç”¨çš„æ•°æ®é›†
- **Building Block Dataset**ï¼ˆç”¨äº SFTï¼‰
  - åˆæˆç”Ÿæˆçš„ **12k æ¡æ ·æœ¬**
  - è¦†ç›–ä¸‰ç§åŸå­å˜æ¢ï¼štranslationã€rotationã€scaling
  - è¾“å…¥è¾“å‡ºå‡ä¸º **ASCII-art è¡¨ç¤ºçš„å½¢çŠ¶å›¾**
  - å½¢çŠ¶è¾¹ç•Œç”¨ `#` è¡¨ç¤ºï¼Œè¡Œé—´ç”¨ `*` å’Œ `\n` åˆ†éš”
  - ç¤ºä¾‹æ ¼å¼è§é™„å½• A

- **å¼ºåŒ–å­¦ä¹ ç¯å¢ƒ**
  - è‡ªå®šä¹‰ ASCII-based RL ç¯å¢ƒ
  - æ¯ä¸ª episode åŒ…å«æœ€å¤š 5 æ­¥åŠ¨ä½œ
  - åŠ¨ä½œç©ºé—´ç¦»æ•£åŒ–ï¼š
    - `A_trans = {up, down, left, right}`
    - `A_rot = {90Â°CCW, 45Â°CCW, 180Â°CCW, 0Â°}`
    - `A_scale = {2Ã—, Ã—, 1}`

### ğŸ§ª å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š`Qwen2.5-1.5B-Instruct`
- **LoRA è®¾ç½®**ï¼š
  - Rank `r=64`
  - åº”ç”¨äº `W_Q, W_K, W_V, W_O, W_gate, W_up, W_down` ç­‰æ¨¡å—
- **è®­ç»ƒé…ç½®**ï¼š
  - å•å¼  NVIDIA A100 GPUï¼ˆ80GBï¼‰
  - Adam ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ `1e-5`
  - Batch size: 64 trajectories
  - æ¸©åº¦é€€ç«ï¼šä» 1.4 â†’ 0.7
- **è¯„ä¼°æ¨¡å¼**ï¼šè´ªå©ªè§£ç ï¼ˆgreedy decodingï¼‰

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
- **ç´¯è®¡å¥–åŠ±ï¼ˆCumulative Episode Rewardï¼‰**ï¼š
  $$
  R_{\text{total}} = R_{\text{correctness}} - 0.1 \times T - \sum R_{\text{rep}} + R_{\text{success}}
  $$
  - `R_correctness`ï¼šä¸å¯å‘å¼æœ€ä¼˜åŠ¨ä½œåºåˆ—åŒ¹é…å¾—åˆ†
  - `-0.1*T`ï¼šé¼“åŠ±çŸ­è·¯å¾„
  - `R_rep`ï¼šé‡å¤åŠ¨ä½œæƒ©ç½šï¼ˆè¿ç»­ä¸¤æ¬¡ä»¥ä¸Šç›¸åŒåŠ¨ä½œï¼‰
  - `R_success=+2`ï¼šæˆåŠŸå®Œæˆä»»åŠ¡å¥–åŠ±

- **æˆåŠŸæ¡ä»¶**ï¼šå½“å‰å½¢çŠ¶ä¸ç›®æ ‡å½¢çŠ¶çš„ IoU â‰¥ é˜ˆå€¼ Ï„

- **ä¸¤ç§æµ‹è¯•åœºæ™¯**ï¼š
  1. **Dynamic Setting**ï¼šæ¯æ­¥åç¯å¢ƒæ›´æ–°åœ°å›¾ï¼ˆæä¾›å¤–éƒ¨çŠ¶æ€ï¼‰
  2. **Static Setting**ï¼šåˆå§‹åœ°å›¾ä¸å˜ï¼Œæ¨¡å‹éœ€å†…éƒ¨è¿½è¸ªçŠ¶æ€å˜åŒ–ï¼ˆæ›´éš¾ï¼‰

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ¨¡å‹ | æè¿° |
|------|------|
| `Qwen-Instruct` | åŸå§‹é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ— ä»»ä½•å¾®è°ƒ |
| `Qwen-Physics` | ä»…ç»è¿‡ SFT çš„ç‰©ç†æ„ŸçŸ¥æ¨¡å‹ |
| `Qwen-DirectRL` | ç›´æ¥åœ¨åŸå§‹æ¨¡å‹ä¸Šåº”ç”¨ GRPO çš„ç«¯åˆ°ç«¯ RL æ¨¡å‹ |
| `Qwen-PhysRL`ï¼ˆOursï¼‰ | æœ¬æ–‡æå‡ºçš„ä¸¤é˜¶æ®µæ–¹æ³• |
| `Random Policy (rnd)` | éšæœºé€‰æ‹©åŠ¨ä½œçš„ä¸‹ç•ŒåŸºå‡† |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1ï¼‰

| Model | Dynamic Avg R_total | Static Avg R_total |
|-------|---------------------|--------------------|
| Qwen-Instruct | 0.070 | 0.004 |
| Qwen-Physics | -0.068 | -0.120 |
| Qwen-DirectRL | 1.626 | -0.216 |
| **Qwen-PhysRL (Ours)** | **2.457** | **1.717** |

> âœ… æœ€é«˜å¯è¾¾æ€»å¥–åŠ±ä¸º 4.7ï¼ˆå«æˆåŠŸå¥–åŠ±ï¼‰ï¼Œæ­¤å¤„æŠ¥å‘Šçš„æ˜¯æ‰£é™¤æˆåŠŸå¥–åŠ±åçš„éƒ¨åˆ†ï¼ˆmax=2.7ï¼‰

### ğŸ” ç»“æœåˆ†æ
- **Dynamic Setting**ï¼š
  - `Qwen-PhysRL` æ¥è¿‘ç†è®ºæœ€å¤§å€¼ï¼ˆ2.457 / 2.7ï¼‰ï¼Œè¯´æ˜å…¶èƒ½æœ‰æ•ˆåˆ©ç”¨ç¯å¢ƒåé¦ˆåšå‡ºæ­£ç¡®å†³ç­–
  - `Qwen-DirectRL` è¡¨ç°å°šå¯ä½†è¿œä½äº ours
  - `Qwen-Physics` å¾®è°ƒååè€Œè¡¨ç°ä¸‹é™ â†’ è¡¨æ˜ SFT å•ç‹¬ä¸è¶³ä»¥æ”¯æŒå¤šæ­¥è§„åˆ’

- **Static Setting**ï¼ˆæ›´å…·æŒ‘æˆ˜æ€§ï¼‰ï¼š
  - `Qwen-PhysRL` ä»å–å¾— **1.717** çš„é«˜åˆ†ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰ baseline
  - `Qwen-DirectRL` å®Œå…¨å¤±è´¥ï¼ˆè´Ÿåˆ†ï¼‰â†’ è¡¨æ˜çº¯ RL æ— æ³•å»ºç«‹å†…éƒ¨çŠ¶æ€è¿½è¸ªæœºåˆ¶
  - `Qwen-Instruct` å‡ ä¹æ— èƒ½åŠ› â†’ æ˜¾ç¤ºé€šç”¨è¯­è¨€æ¨¡å‹ç¼ºä¹ç©ºé—´è®°å¿†èƒ½åŠ›

### ğŸ“ˆ GRPO æ”¶æ•›æ€§åˆ†æï¼ˆFigure 2ï¼‰
- `Qwen-PhysRL` æ¯” `Qwen-DirectRL` **æ”¶æ•›æ›´å¿«ã€æ›´ç¨³å®š**
- æ—©æœŸå³è¾¾åˆ°è¾ƒé«˜å¥–åŠ±æ°´å¹³ï¼ŒåæœŸæ³¢åŠ¨å°
- è¯æ˜ï¼š**ç‰©ç†æ„ŸçŸ¥åˆå§‹åŒ–æ˜¾è‘—æå‡äº† RL å­¦ä¹ æ•ˆç‡**

### ğŸ” æ¶ˆèå®éªŒä¸æ³¨æ„åŠ›åˆ†æï¼ˆAblation Studyï¼‰

#### Observation 1ï¼šFine-tuning æ”¹å˜äº†ä¸­é—´å±‚æ³¨æ„åŠ›åˆ†å¸ƒ
- ä½¿ç”¨ KL æ•£åº¦è¡¡é‡ `Qwen-Physics` ä¸ `Qwen-Instruct` çš„æ³¨æ„åŠ›å·®å¼‚
- **Layer 16 å’Œ Layer 20** å·®å¼‚æœ€å¤§ â†’ è¡¨æ˜ SFT ä¸»è¦åœ¨ä¸­å±‚ç¼–ç ç©ºé—´ç»“æ„ä¿¡æ¯

#### Observation 2ï¼šæ›´å¤šå…³æ³¨ç©ºé—´ç¬¦å·ï¼ˆå¦‚ `#`, `*`ï¼‰
- `Qwen-Physics` åœ¨ä¸­å±‚å¯¹ `#` å’Œ `*` çš„æ³¨æ„åŠ›æ˜æ˜¾å¢å¼º
- è¡¨æ˜æ¨¡å‹å­¦ä¼šäº†èšç„¦äºå½¢çŠ¶è½®å»“ç­‰å…³é”®è§†è§‰çº¿ç´¢

#### Observation 3ï¼šç³»ç»Ÿæç¤ºï¼ˆsystem promptï¼‰ä¸»å¯¼æ³¨æ„åŠ›
- å°½ç®¡ map åŒºåŸŸ token æ›´å°‘ï¼Œä½† `Qwen-Physics` ä»å€¾å‘äºåˆ†é…æ›´å¤šæ³¨æ„åŠ›ç»™ system prompt
- ä½†åœ¨ä¸­å±‚ï¼ˆ16â€“20ï¼‰è¯¥å·®è·ç¼©å° â†’ è¡¨æ˜è¿™äº›å±‚çœŸæ­£å‚ä¸ç©ºé—´æ¨ç†

> ğŸ’¡ æ€»ç»“ï¼šSFT æˆåŠŸå¼•å¯¼æ¨¡å‹åœ¨ç‰¹å®šä¸­é—´å±‚å»ºç«‹èµ·å¯¹ç©ºé—´ç»“æ„çš„å…³æ³¨æœºåˆ¶ï¼Œä¸ºåç»­ RL æä¾›äº†è‰¯å¥½çš„è¡¨ç¤ºåŸºç¡€

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ä¸¤é˜¶æ®µæ–¹æ³•ä¼˜äºç«¯åˆ°ç«¯ RL**ï¼š
   - å…ˆé€šè¿‡ SFT æ³¨å…¥ç©ºé—´ç‰©ç†å…ˆéªŒï¼Œå†ç”¨ RL å­¦ä¹ ç»„åˆç­–ç•¥ï¼Œæ˜¾è‘—æå‡æ€§èƒ½ä¸è®­ç»ƒç¨³å®šæ€§
2. **LoRA + å†»ç»“ä¸»å¹²æ˜¯é«˜æ•ˆæ–¹æ¡ˆ**ï¼š
   - åªè®­ç»ƒå°‘é‡é€‚é…å™¨å‚æ•°å³å¯å®ç°å¼ºå¤§è§„åˆ’èƒ½åŠ›
3. **æ¨¡å‹å…·å¤‡ä¸€å®šå†…éƒ¨çŠ¶æ€è¿½è¸ªèƒ½åŠ›**ï¼š
   - åœ¨ Static Setting ä¸‹ä»èƒ½å–å¾—è‰¯å¥½è¡¨ç°ï¼Œè¡¨æ˜å…¶å·²å­¦ä¼šâ€œ mentally simulateâ€çŠ¶æ€æ¼”åŒ–
4. **æ³¨æ„åŠ›æœºåˆ¶å‘ç”Ÿå˜åŒ–**ï¼š
   - Fine-tuning æ˜¾è‘—æ”¹å˜äº†ä¸­å±‚æ³¨æ„åŠ›åˆ†å¸ƒï¼Œå¢å¼ºäº†å¯¹ç©ºé—´ç¬¦å·çš„å…³æ³¨ï¼ŒéªŒè¯äº†ç©ºé—´ç†è§£çš„çœŸå®æå‡

### âš ï¸ å±€é™æ€§
- å½“å‰ä»…é€‚ç”¨äº **ASCII-art ç¬¦å·ç©ºé—´**ï¼Œå°šæœªæ‰©å±•è‡³çœŸå®å›¾åƒæˆ–å¤šæ¨¡æ€è¾“å…¥
- åŠ¨ä½œç©ºé—´ç¦»æ•£ä¸”æœ‰é™ï¼Œéš¾ä»¥å¤„ç†è¿ç»­æ§åˆ¶ä»»åŠ¡
- æ‰€æœ‰ä»»åŠ¡æœ€å¤§é•¿åº¦ä¸º 5 æ­¥ï¼ŒæœªéªŒè¯é•¿ç¨‹è§„åˆ’èƒ½åŠ›
- ä¾èµ–äººå·¥è®¾è®¡çš„ parser å°†æ–‡æœ¬è¾“å‡ºæ˜ å°„ä¸ºåŠ¨ä½œæ ‡ç­¾ï¼Œå­˜åœ¨è¯¯å·®é£é™©

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•åˆ° **Vision-Language Models (VLMs)**ï¼Œç»“åˆçœŸå®å›¾åƒä¸­çš„ç©ºé—´æ¨ç†
- æ¢ç´¢æ›´å¤æ‚çš„ç¯å¢ƒï¼ˆå¦‚ Sokobanã€Mazeï¼‰å’Œæ›´é•¿çš„ä»»åŠ¡åºåˆ—
- ç ”ç©¶è‡ªåŠ¨å‘ç°â€œæ„å»ºå—â€çš„æ–¹æ³•ï¼Œè€Œéäººå·¥å®šä¹‰
- å°†è¯¥èŒƒå¼åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ç­‰å®é™…åº”ç”¨åœºæ™¯
- æ„å»ºé€šç”¨çš„â€œç©ºé—´æ™ºèƒ½â€é¢„è®­ç»ƒæ¡†æ¶

---

## âœ… æ€»ä½“è¯„ä»·
æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é«˜æ•ˆçš„ LLM ç©ºé—´æ¨ç†è®­ç»ƒèŒƒå¼â€”â€”**â€œBuilding Blocks + RL Compositionâ€**ï¼Œé€šè¿‡æ¨¡å—åŒ–è®¾è®¡è§£å†³äº†ä¼ ç»Ÿæ–¹æ³•åœ¨ç©ºé—´ç†è§£å’Œå¤šæ­¥è§„åˆ’ä¸Šçš„ç“¶é¢ˆã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•ä¸ä»…æ€§èƒ½ä¼˜è¶Šï¼Œè€Œä¸”è®­ç»ƒæ›´ç¨³å®šï¼Œå…·æœ‰è¾ƒå¼ºçš„å¯è§£é‡Šæ€§å’Œæ¨å¹¿æ½œåŠ›ï¼Œä¸ºæ„å»ºå…·å¤‡ç©ºé—´è®¤çŸ¥èƒ½åŠ›çš„è¯­è¨€æ™ºèƒ½ä½“æä¾›äº†é‡è¦æ€è·¯ã€‚

</details>

---

### 7. [Joint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning](https://arxiv.org/abs/2512.24265)

**Authors**: Ziqing Fan, Yuqiao Xian, Yan Sun, Li Shen  
**Category**: cs.CL  
**Published**: 2026-01-01  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.24265v1  

#### Abstract
A fine-grained data recipe is crucial for pre-training large language models, as it can significantly enhance training efficiency and model performance. One important ingredient in the recipe is to select samples based on scores produced by defined rules, LLM judgment, or statistical information in ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šJoint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¢„è®­ç»ƒä¸­ï¼Œ**æ•°æ®é€‰æ‹©ç­–ç•¥**å¯¹æ¨¡å‹æ€§èƒ½è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ•°æ®ç­›é€‰æ–¹æ³•é€šå¸¸åªå…³æ³¨å•ä¸€æŒ‡æ ‡ï¼ˆå¦‚è´¨é‡æˆ–å¤šæ ·æ€§ï¼‰ï¼Œå­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **ä»…åŸºäºè´¨é‡ï¼ˆquality-onlyï¼‰çš„æ–¹æ³•**ï¼šè™½ç„¶åˆæœŸè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨é•¿æœŸé¢„è®­ç»ƒä¸­å‡ºç°ä¸¥é‡**æ€§èƒ½è¡°å‡ï¼ˆdiminishing returnsï¼‰**ï¼ŒåŸå› æ˜¯é«˜è´¨é‡æ ·æœ¬è¯­ä¹‰å†—ä½™é«˜ï¼Œç¼ºä¹å¤šæ ·æ€§ã€‚
- **ä»…åŸºäºå¤šæ ·æ€§ï¼ˆdiversity-onlyï¼‰çš„æ–¹æ³•**ï¼šè™½ç„¶æå‡äº†è¦†ç›–åº¦ï¼Œä½†ä¼š**è¿‡åº¦å‰”é™¤æœ‰ä»·å€¼çš„é«˜è´¨é‡æ ·æœ¬**ï¼Œå¯¼è‡´æœ€ç»ˆæ€§èƒ½ç”šè‡³ä½äºåŸå§‹æ•°æ®é›†ã€‚
- **è”åˆä¼˜åŒ–çš„è®¡ç®—ç“¶é¢ˆ**ï¼šå¤šæ ·æ€§æŒ‡æ ‡é€šå¸¸æ˜¯é›†åˆå‡½æ•°ï¼ˆset functionï¼‰ï¼Œä¼ ç»Ÿè´ªå©ªç®—æ³•ï¼ˆgreedy algorithmï¼‰æ±‚è§£æˆæœ¬æé«˜ï¼Œåœ¨ä¸‡äº¿çº§ token æ•°æ®é›†ä¸Šä¸å¯è¡Œã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šDATAMASK
ä½œè€…æå‡º **DATAMASK**ï¼Œä¸€ä¸ªæ–°é¢–ä¸”é«˜æ•ˆçš„**è”åˆå­¦ä¹ æ¡†æ¶**ï¼Œç”¨äºå¤§è§„æ¨¡é¢„è®­ç»ƒæ•°æ®çš„é€‰æ‹©ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ•°æ®é€‰æ‹©è¿‡ç¨‹å»ºæ¨¡ä¸º**æ©ç å­¦ä¹ ï¼ˆmask learningï¼‰é—®é¢˜**ï¼Œé€šè¿‡ç­–ç•¥æ¢¯åº¦ï¼ˆpolicy gradientï¼‰è¿›è¡Œä¼˜åŒ–ã€‚

#### åˆ›æ–°ç‚¹ï¼š
- **ç»Ÿä¸€ä¼˜åŒ–å¤šç›®æ ‡**ï¼šé¦–æ¬¡åœ¨å•ä¸€æµç¨‹ä¸­é«˜æ•ˆè”åˆä¼˜åŒ–**è´¨é‡ï¼ˆqualityï¼‰å’Œå¤šæ ·æ€§ï¼ˆdiversityï¼‰** ä¸¤ç±»æŒ‡æ ‡ã€‚
- **æ©ç å­¦ä¹ èŒƒå¼**ï¼šå¼•å…¥å¯å­¦ä¹ çš„äºŒå€¼æ©ç  $M$ï¼Œå°†ç¦»æ•£çš„é€‰æ‹©é—®é¢˜è½¬åŒ–ä¸ºè¿ç»­çš„å‚æ•°ä¼˜åŒ–é—®é¢˜ã€‚
- **ç­–ç•¥æ¢¯åº¦ä¼°è®¡ï¼ˆPGEï¼‰**ï¼šé‡‡ç”¨å¼ºåŒ–å­¦ä¹ ä¸­çš„ç­–ç•¥æ¢¯åº¦æ–¹æ³•ï¼Œå¹¶å¼•å…¥**ç»„ç›¸å¯¹ä¼˜åŠ¿ï¼ˆgroup relative advantageï¼‰** ä½œä¸ºåŸºçº¿ï¼Œæ˜¾è‘—é™ä½æ–¹å·®ï¼ŒåŠ é€Ÿæ”¶æ•›ã€‚
- **å¤šç§åŠ é€ŸæŠ€æœ¯**ï¼šç»“åˆè´¨é‡æ„ŸçŸ¥å‰ªæï¼ˆpruningï¼‰ã€åˆå§‹åŒ–ã€æ‰¹æ›´æ–°ï¼ˆbatch updatingï¼‰ç­‰ç­–ç•¥ï¼Œå¤§å¹…æå‡æ•ˆç‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ•ˆç‡æå‡å·¨å¤§**ï¼šç›¸æ¯”ä¼ ç»Ÿçš„è´ªå©ªç®—æ³•ï¼ˆå¦‚ DiSFï¼‰ï¼Œ**é€‰æ‹©æ—¶é—´å‡å°‘ 98.9%**ï¼Œä½¿å¾—åœ¨ä¸‡äº¿çº§ token æ•°æ®ä¸Šè¿›è¡Œè”åˆå­¦ä¹ æˆä¸ºå¯èƒ½ã€‚
- **æ€§èƒ½æ›´ä¼˜**ï¼šç”Ÿæˆçš„æ•°æ®å­é›†åœ¨å¤šä¸ªä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºä»…åŸºäºè´¨é‡æˆ–å¤šæ ·æ€§çš„æ–¹æ³•ã€‚
- **çµæ´»æ€§é«˜**ï¼šæ¡†æ¶æ”¯æŒä»»æ„ç»„åˆçš„è´¨é‡å’Œå¤šæ ·æ€§æŒ‡æ ‡ï¼Œå…·æœ‰è‰¯å¥½çš„æ‰©å±•æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **ä¸»æ•°æ®é›†**ï¼š**FineWeb**ï¼Œä¸€ä¸ªåŒ…å« **15 ä¸‡äº¿ token** çš„å¤§è§„æ¨¡ç½‘é¡µæ–‡æœ¬è¯­æ–™åº“ã€‚
- **æ„å»ºçš„å­é›†**ï¼šä½¿ç”¨ DATAMASK ä» FineWeb ä¸­é€‰å‡ºçº¦ **1.5 ä¸‡äº¿ token** çš„é«˜è´¨é‡å¤šæ ·åŒ–å­é›†ï¼Œå‘½åä¸º **FineWeb-Mask**ã€‚
- **å…¶ä»–å¯¹æ¯”æ•°æ®é›†**ï¼š
  - `FineWeb-Edu`ï¼šåŸºäºæ•™è‚²è´¨é‡ç­›é€‰ã€‚
  - `UltraFineWeb-en`ï¼šåŸºäº fastText åˆ†ç±»å™¨ç­›é€‰çš„è‹±æ–‡éƒ¨åˆ†ã€‚
  - `FineWeb-Semdedup`ï¼šåŸºäºè¯­ä¹‰å»é‡ï¼ˆsemantic deduplicationï¼‰ã€‚
  - `FineWeb-DCLM`ï¼šåŸºäº DCLM è´¨é‡åˆ†ç±»å™¨ç­›é€‰ã€‚
  - `FineWeb-Pro`ï¼šåŸºäº Prox æ–¹æ³•ç­›é€‰çš„å°è§„æ¨¡å­é›†ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹æ¶æ„**ï¼š
  - **1.5B dense model**ï¼šåŸºäº Qwen-2.5 æ¶æ„ã€‚
  - **7B MoE model**ï¼šåŒ…å« 10 ä¸ªä¸“å®¶çš„ç¨€ç–æ¨¡å‹ã€‚
- **é¢„è®­ç»ƒè®¾ç½®**ï¼š
  - é¢„è®­ç»ƒ token æ•°é‡ï¼šdense æ¨¡å‹ 400Bï¼ŒMoE æ¨¡å‹ 300Bã€‚
  - ä¼˜åŒ–å™¨ï¼šAdamï¼Œå­¦ä¹ ç‡ 4e-4ï¼Œbatch size 1536ï¼Œåºåˆ—é•¿åº¦ 8192ã€‚
- **è¯„ä¼°åŸºå‡†**ï¼šåœ¨ **12 ä¸ªå¤šæ ·åŒ–ä»»åŠ¡** ä¸Šè¯„ä¼°ï¼Œæ¶µç›–ä¸‰å¤§èƒ½åŠ›ï¼š
  - **é˜…è¯»ç†è§£**ï¼ˆRACE-High/Middleï¼‰
  - **ä¸–ç•ŒçŸ¥è¯†**ï¼ˆTriviaQA, HellaSwag, Natural Questions, MMLU ç­‰ï¼‰
  - **æ¨ç†èƒ½åŠ›**ï¼ˆARC-Challenge, SIQA, PIQA, WinoGrandeï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **è´¨é‡å¯¼å‘åŸºçº¿**ï¼šFineWeb-Edu, UltraFineWeb-en, FineWeb-DCLM
- **å¤šæ ·æ€§å¯¼å‘åŸºçº¿**ï¼šFineWeb-Semdedup
- **åŸå§‹æ•°æ®**ï¼šFineWebï¼ˆæœªç­›é€‰ï¼‰
- **å…¶ä»–å¼€æºæ•°æ®é›†**ï¼šDCLM-BASELINEï¼ˆè·¨æ•°æ®æºå¯¹æ¯”ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **FineWeb-Mask åœ¨ 1.5B dense æ¨¡å‹ä¸Šçš„å¹³å‡æå‡**ï¼š
  - ç›¸æ¯”åŸå§‹ FineWebï¼š**+3.2%**
  - ç›¸æ¯”æœ€ä½³åŸºçº¿ï¼ˆFineWeb-DCLMï¼‰ï¼š**+0.9%**
- **åœ¨ 7B MoE æ¨¡å‹ä¸Šçš„å¹³å‡æå‡**ï¼š
  - ç›¸æ¯”åŸå§‹ FineWebï¼š**+1.9%**
  - ç›¸æ¯”æœ€ä½³åŸºçº¿ï¼ˆFineWeb-DCLMï¼‰ï¼š**+0.4%**

> æ³¨ï¼šåŸæ–‡æ‘˜è¦ç§°â€œ3.2% on 1.5Bâ€å’Œâ€œ1.9% on 7Bâ€ï¼ŒTable 2 æ˜¾ç¤ºä¸º 3.2% å’Œ 1.9%ï¼Œä¸æ‘˜è¦ä¸€è‡´ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| æ–¹æ³• | 1.5B Dense æ¨¡å‹æå‡ | 7B MoE æ¨¡å‹æå‡ |
|------|---------------------|-----------------|
| **FineWeb-Mask (Ours)** | **+3.2%** vs FineWeb | **+1.9%** vs FineWeb |
| FineWeb-DCLM | +2.0% | +1.5% |
| FineWeb-Edu | +1.4% | +0.5% |
| FineWeb-Semdedup | **è´Ÿå‘å½±å“**ï¼ˆæ€§èƒ½ä¸‹é™ï¼‰ | **è´Ÿå‘å½±å“** |

- **å¤šæ ·æ€§æ–¹æ³•è¡¨ç°å·®**ï¼š`FineWeb-Semdedup` åœ¨ä¸¤ç§æ¨¡å‹ä¸Šå‡è¡¨ç°æœ€å·®ï¼ŒéªŒè¯äº†â€œå¤šæ ·æ€§æ–¹æ³•ä¼šå‰”é™¤è¿‡å¤šé«˜è´¨é‡æ ·æœ¬â€çš„å‡è®¾ã€‚
- **è´¨é‡æ–¹æ³•æœ‰è¡°å‡**ï¼š`FineWeb-Edu` ç­‰æ–¹æ³•åˆæœŸé¢†å…ˆï¼Œä½†éšç€é¢„è®­ç»ƒ token å¢åŠ ï¼Œæ€§èƒ½å¢é•¿æ”¾ç¼“ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **å¤šæ ·æ€§æŒ‡æ ‡é€‰æ‹©**ï¼š
  - **Pair-wise Similarity** å’Œ **Facility Location** æœ‰æ•ˆæå‡æ€§èƒ½ã€‚
  - **DiSF values** è¡¨ç°ä¸ä½³ï¼Œå¯èƒ½å› å…¶ä¸è´¨é‡åˆ†æ•°å†²çªè¾ƒå¤§ã€‚
- **å¹³è¡¡ç³»æ•° $\lambda$**ï¼š
  - æœ€ä½³èŒƒå›´åœ¨ **$\lambda = 0.1 \sim 0.5$**ï¼ˆå³å¤šæ ·æ€§æƒé‡å  50%~90%ï¼‰ã€‚
- **åˆå§‹åŒ–ç­–ç•¥**ï¼š
  - **Quality-aware åˆå§‹åŒ–**ï¼ˆæŒ‰è´¨é‡åˆ†åˆå§‹åŒ– logitsï¼‰èƒ½æ˜¾è‘—åŠ é€Ÿæ”¶æ•›ï¼Œé€‰æ‹©æ—¶é—´ä» 10 å°æ—¶é™è‡³ 7 å°æ—¶ã€‚
- **æ‰¹æ›´æ–°ï¼ˆBatch Updatingï¼‰**ï¼š
  - ä½¿ç”¨ 5%~10% çš„æ ·æœ¬æ›´æ–° logits å¯å¤§å¹…å‡å°‘è®¡ç®—æ—¶é—´ï¼Œå¹¶æœ‰åŠ©äºè·³å‡ºå±€éƒ¨æœ€ä¼˜ã€‚
- **è´¨é‡æ„ŸçŸ¥å‰ªæï¼ˆPruningï¼‰**ï¼š
  - è¿‡æ»¤æ‰è´¨é‡åˆ†æœ€ä½çš„ 40-50% æ ·æœ¬åï¼Œé€‰æ‹©æ—¶é—´å’Œæ€§èƒ½å‡æ˜¾è‘—æå‡ï¼ˆTable 1ï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å•ä¸€æŒ‡æ ‡é€‰æ‹©å­˜åœ¨æ ¹æœ¬å±€é™**ï¼š
   - è´¨é‡å¯¼å‘ â†’ è¯­ä¹‰å†—ä½™é«˜ â†’ é•¿æœŸé¢„è®­ç»ƒæ”¶ç›Šé€’å‡ã€‚
   - å¤šæ ·æ€§å¯¼å‘ â†’ å‰”é™¤è¿‡å¤šé«˜è´¨é‡æ ·æœ¬ â†’ æ€§èƒ½ä¸‹é™ã€‚
2. **è”åˆä¼˜åŒ–æ˜¯å¿…è¦ä¸”æœ‰æ•ˆçš„**ï¼š
   - é€šè¿‡ DATAMASK åŒæ—¶ä¼˜åŒ–è´¨é‡å’Œå¤šæ ·æ€§ï¼Œèƒ½æ˜¾è‘—æå‡æ¨¡å‹æœ€ç»ˆæ€§èƒ½ã€‚
3. **æ•ˆç‡ç“¶é¢ˆå¯é€šè¿‡æ–°èŒƒå¼çªç ´**ï¼š
   - å°†æ•°æ®é€‰æ‹©è§†ä¸ºæ©ç å­¦ä¹ é—®é¢˜ï¼Œç»“åˆç­–ç•¥æ¢¯åº¦ï¼ŒæˆåŠŸå°†é€‰æ‹©æ—¶é—´é™ä½ 98.9%ï¼Œè§£å†³äº†ä¼ ç»Ÿè´ªå©ªç®—æ³•çš„å¯æ‰©å±•æ€§é—®é¢˜ã€‚
4. **FineWeb-Mask æ˜¯é«˜è´¨é‡å­é›†**ï¼š
   - ä»…ç”¨ 10% çš„ FineWeb æ•°æ®ï¼ˆ1.5T tokensï¼‰ï¼Œå³å¯è¶…è¶ŠåŸå§‹å…¨é‡æ•°æ®åŠå…¶ä»–å¼€æºæ•°æ®é›†ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é¢„å®šä¹‰æŒ‡æ ‡**ï¼šä»éœ€äººå·¥è®¾è®¡æˆ–é€‰æ‹©è´¨é‡ä¸å¤šæ ·æ€§æŒ‡æ ‡ï¼Œè‡ªåŠ¨åŒ–ç¨‹åº¦æœ‰é™ã€‚
- **è¶…å‚æ•°æ•æ„Ÿ**ï¼šå¹³è¡¡ç³»æ•° $\lambda$ã€å­¦ä¹ ç‡ã€G å€¼ç­‰éœ€è°ƒä¼˜ã€‚
- **åˆå§‹è´¨é‡è¿‡æ»¤ä¾èµ–é˜ˆå€¼**ï¼šå‰ªæé˜ˆå€¼ï¼ˆå¦‚è´¨é‡åˆ† < 4ï¼‰éœ€æ‰‹åŠ¨è®¾å®šã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´å¤æ‚çš„æŒ‡æ ‡ç»„åˆæ–¹å¼ï¼Œä¾‹å¦‚éçº¿æ€§èåˆã€‚
- å°†è¯¥æ¡†æ¶åº”ç”¨äºå…¶ä»–æ¨¡æ€ï¼ˆå¦‚å›¾åƒã€éŸ³é¢‘ï¼‰çš„é¢„è®­ç»ƒæ•°æ®é€‰æ‹©ã€‚
- ç»“åˆä¸»åŠ¨å­¦ä¹ æˆ–åœ¨çº¿å­¦ä¹ æœºåˆ¶ï¼Œå®ç°åŠ¨æ€æ•°æ®é€‰æ‹©ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ–è®¡ç®—æ•ˆç‡ï¼Œæ”¯æŒæ›´å¤§è§„æ¨¡çš„å®æ—¶ç­›é€‰ã€‚

---

> **ä»£ç ä¸æ•°æ®å…¬å¼€**ï¼š
> - GitHub: [https://github.com/ByteDance-Seed/DATAMASK](https://github.com/ByteDance-Seed/DATAMASK)
> - æ•°æ®é›†: [https://huggingface.co/datasets/DATA-MASK/FineWeb-Mask](https://huggingface.co/datasets/DATA-MASK/FineWeb-Mask)

</details>

---

### 8. [Understanding LLM Checkpoint/Restore I/O Strategies and Patterns](https://arxiv.org/abs/2512.24511)

**Authors**: Mikaila J. Gossman, Avinash Maurya, Bogdan Nicolae, Jon C. Calhoun  
**Category**: cs.DC  
**Published**: 2026-01-01  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.24511v1  

#### Abstract
As LLMs and foundation models scale, checkpoint/restore has become a critical pattern for training and inference. With 3D parallelism (tensor, pipeline, data), checkpointing involves many processes, each managing numerous tensors of varying shapes and sizes, that must be persisted frequently to stab...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šUnderstanding LLM Checkpoint/Restore I/O Strategies and Patterns

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’ŒåŸºç¡€æ¨¡å‹ï¼ˆFMsï¼‰åœ¨è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­ä¾èµ–**é¢‘ç¹çš„ Checkpoint-Restoreï¼ˆC/Rï¼‰æ“ä½œ**ï¼Œä»¥å®ç°å®¹é”™ã€æš‚åœæ¢å¤ã€è°ƒè¯•ç­‰ç›®æ ‡ã€‚ç„¶è€Œï¼Œç”±äºç°ä»£ LLM ä½¿ç”¨ 3D å¹¶è¡Œï¼ˆdata, tensor, pipelineï¼‰ç­–ç•¥ï¼Œå¯¼è‡´æ¯ä¸ª checkpoint åŒ…å«å¤§é‡åˆ†å¸ƒåœ¨æ•°åƒä¸ª GPU ä¸Šçš„å°å‹ã€å¼‚æ„å¼ é‡ï¼ˆtensorsï¼‰ï¼Œäº§ç”Ÿæµ·é‡å°æ–‡ä»¶å†™å…¥/è¯»å–è¯·æ±‚ã€‚

è¿™å¸¦æ¥äº†å…¸å‹çš„â€œå¤§æ•°æ®â€æŒ‘æˆ˜â€”â€”**é«˜é¢‘ç‡ï¼ˆvelocityï¼‰ã€å¤šæ ·æ€§ï¼ˆvarietyï¼‰ã€å¤§ä½“ç§¯ï¼ˆvolumeï¼‰**ï¼Œè¿›è€Œå¼•å‘ä¸¥é‡çš„ I/O ç“¶é¢ˆï¼Œå°¤å…¶æ˜¯åœ¨å…ƒæ•°æ®ç®¡ç†ã€ç¼“å­˜ä¸€è‡´æ€§ã€å­˜å‚¨æ ˆå±‚çº§ä¼ è¾“æ•ˆç‡ç­‰æ–¹é¢ã€‚ä¼ ç»ŸåŸºäº POSIX çš„ I/O æ¥å£ï¼ˆå¦‚ `write()`/`read()`ï¼‰å·²éš¾ä»¥æ»¡è¶³éœ€æ±‚ã€‚

æ­¤å¤–ï¼Œå½“å‰ä¸»æµ C/R å¼•æ“ï¼ˆå¦‚ TorchSnapshotã€DataStates-LLMï¼‰è™½ç„¶é‡‡ç”¨å¹¶è¡ŒåŒ–è®¾è®¡ï¼Œä½†å…¶â€œfile-per-shardâ€ç­–ç•¥åŠ å‰§äº†æ–‡ä»¶ç³»ç»Ÿå…ƒæ•°æ®å‹åŠ›ï¼Œä¸”ç¼ºä¹å¯¹ç°ä»£é«˜æ€§èƒ½ I/O åº“ï¼ˆå¦‚ liburingï¼‰å’Œåº•å±‚æ–‡ä»¶ç³»ç»Ÿçš„ååŒä¼˜åŒ–ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€å¥—é’ˆå¯¹ LLM C/R åœºæ™¯çš„ **I/O ç‰¹å¾åˆ†ææ¡†æ¶ä¸ä¼˜åŒ–ç­–ç•¥**ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- æ„å»ºä¸€ä¸ªå¾®åŸºå‡†æµ‹è¯•å·¥å…·ï¼ˆmicrobenchmarkï¼‰ï¼Œç”¨äºç³»ç»Ÿè¯„ä¼° **kernel-accelerated I/O åº“ï¼ˆliburingï¼‰** åœ¨çœŸå® LLM å·¥ä½œè´Ÿè½½ä¸‹çš„è¡¨ç°ï¼›
- æ·±å…¥ç ”ç©¶ **I/O èšåˆï¼ˆaggregationï¼‰ã€å¯¹é½ï¼ˆalignmentï¼‰ã€åˆå¹¶ï¼ˆcoalescingï¼‰** ç­‰ç­–ç•¥å¦‚ä½•å½±å“æ€§èƒ½ï¼›
- åˆ†æ **buffered I/O vs. direct I/Oï¼ˆO_DIRECTï¼‰** å¯¹è¯»å†™æ€§èƒ½çš„å½±å“å·®å¼‚ï¼›
- æ­ç¤ºç°æœ‰ç”Ÿäº§çº§ C/R å¼•æ“ï¼ˆTorchSnapshotã€DataStates-LLMï¼‰çš„è®¾è®¡ç¼ºé™·ï¼Œå¹¶æå‡ºæ”¹è¿›æ–¹å‘ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ–¹æ³•è®ºåˆ›æ–°** | é¦–æ¬¡ç³»ç»Ÿæ€§åœ°å°† liburing ç­‰ç°ä»£ I/O æ¥å£å¼•å…¥ LLM C/R æ€§èƒ½åˆ†æï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸçš„ç©ºç™½ï¼› |
| **æ›´è´´è¿‘ç°å®çš„å·¥ä½œè´Ÿè½½å»ºæ¨¡** | ä¸ä»…ä½¿ç”¨åˆæˆè´Ÿè½½ï¼Œè¿˜æ„å»ºäº†åŸºäº BLOOM-3Bã€LLaMA-7Bã€LLaMA-13B çš„çœŸå®åˆ†å¸ƒæ¨¡å‹ï¼Œè¦†ç›–ä¸åŒè§„æ¨¡å’Œå¹¶è¡Œé…ç½®ï¼› |
| **æ­ç¤ºæ·±å±‚ç“¶é¢ˆ** | å‘ç°å†…å­˜åˆ†é…å¼€é”€ï¼ˆmemory allocationï¼‰ã€éèšåˆ I/Oã€å…ƒæ•°æ®äº‰ç”¨æ˜¯ä¸»è¦æ€§èƒ½é™åˆ¶å› ç´ ï¼Œè€Œéå•çº¯çš„ I/O ååèƒ½åŠ›ï¼› |
| **æŒ‡å¯¼æ€§å¼º** | ä¸ºä¸‹ä¸€ä»£ C/R æ¡†æ¶æä¾›äº†æ˜ç¡®çš„è®¾è®¡åŸåˆ™ï¼šèšåˆ + é¢„åˆ†é…ç¼“å†²åŒº + O_DIRECT + æ‰¹å¤„ç†æäº¤ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†/æ¨¡å‹
å¹¶éä¼ ç»Ÿæ„ä¹‰ä¸Šçš„â€œæ•°æ®é›†â€ï¼Œè€Œæ˜¯æ¨¡æ‹Ÿä»¥ä¸‹ä¸‰ç§å…¸å‹ LLM çš„ checkpoint ç»“æ„ï¼š
- **BLOOM-3B**ï¼šè¿è¡Œäº 4 ä¸ª GPUï¼ˆ4 ranksï¼‰
- **LLaMA-7B**ï¼šè¿è¡Œäº 8 ä¸ª GPUï¼ˆ8 ranksï¼‰
- **LLaMA-13B**ï¼šè¿è¡Œäº 16 ä¸ª GPUï¼ˆ16 ranksï¼‰

æ¯ç§æ¨¡å‹ç”Ÿæˆæ•°ç™¾ä¸ªå¤§å°ä¸ä¸€çš„æ–‡ä»¶ï¼ˆä» KB åˆ° GBï¼‰ï¼Œç¬¦åˆå®é™…è®­ç»ƒä¸­ tensorã€optimizer statesã€metadata çš„æ··åˆåˆ†å¸ƒï¼ˆè§ Figure 4ï¼‰ã€‚

---

### å®éªŒå¹³å°ï¼ˆTestbedï¼‰
åœ¨ **Argonne å›½å®¶å®éªŒå®¤çš„ Polaris ç³»ç»Ÿ**ä¸Šè¿›è¡Œå®éªŒï¼š
- èŠ‚ç‚¹æ•°ï¼š560
- CPUï¼šAMD EPYC Milan 753P
- GPUï¼š4Ã—A100-40GB
- å†…å­˜ï¼š512 GB DDR4
- å­˜å‚¨åç«¯ï¼šLustre-based Parallel File System (PFS)ï¼Œæ€»å¸¦å®½ 650 GB/s
- å®¢æˆ·ç«¯é…ç½®ï¼š40 OSSes, 160 OSTsï¼Œæ¡å¸¦å¤§å°è®¾ä¸º 64MB

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### ä¸¤ç±»åŸºå‡†æµ‹è¯•ï¼š
1. **Synthetic Benchmark**
   - æ¯ä¸ª rank å†™å…¥è¿ç»­çš„å¤§å— bufferï¼ˆ128MBâ€“8GBï¼‰
   - æ§åˆ¶å˜é‡ï¼šèšåˆç²’åº¦ã€I/O æ¨¡å¼ã€é˜Ÿåˆ—æ·±åº¦
   - ç›®æ ‡ï¼šæµ‹é‡ liburing çš„ç†è®ºå³°å€¼åå

2. **Representative LLM Benchmark**
   - å¤ç°çœŸå®æ¨¡å‹çš„ tensor åˆ†å¸ƒã€æ•°é‡ã€å°ºå¯¸
   - æ”¯æŒå¤šç§èšåˆç­–ç•¥ï¼ˆfile-per-tensor, file-per-process, single aggregated fileï¼‰
   - æ›´çœŸå®åæ˜ ç¢ç‰‡åŒ–ã€éå¯¹é½ã€å¤šå¯¹è±¡åœºæ™¯

#### èšåˆç­–ç•¥å¯¹æ¯”ï¼š
- **File-per-Tensor**ï¼šæœ€ç»†ç²’åº¦ï¼Œå¯¹åº” DeepSpeed/TorchSnapshot é»˜è®¤è¡Œä¸º
- **File-per-Process**ï¼šæ¯ä¸ª rank ä¸€ä¸ªæ–‡ä»¶
- **Single Aggregated File**ï¼šæ‰€æœ‰ rank å…±äº«ä¸€ä¸ªå¤§æ–‡ä»¶ï¼ŒæŒ‰åç§»å†™å…¥

#### I/O æ¨¡å¼å¯¹æ¯”ï¼š
- æ˜¯å¦å¯ç”¨ `O_DIRECT` æ ‡å¿—
- ä½¿ç”¨ **liburing** vs. **POSIX** æ¥å£

#### è¯„ä¼°æŒ‡æ ‡ï¼š
- **Write Throughput (GB/s)**ï¼šcheckpoint é˜¶æ®µå†™å…¥é€Ÿåº¦
- **Read Throughput (GB/s)**ï¼šrestore é˜¶æ®µè¯»å–é€Ÿåº¦
- **End-to-End Latency**ï¼šå®Œæ•´ C/R æ—¶é—´
- **Metadata Pressure**ï¼šé€šè¿‡æ–‡ä»¶æ•°é‡é—´æ¥è¡¡é‡

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **TorchSnapshot**ï¼ˆPyTorch å®˜æ–¹å¿«ç…§å¼•æ“ï¼‰ï¼šä½¿ç”¨ libaioï¼Œå°†å¤§å¯¹è±¡åˆ‡åˆ†ä¸º â‰¤512MB çš„ chunkï¼Œå†™å…¥åµŒå¥—ç›®å½•ç»“æ„
- **DataStates-LLM**ï¼šä½¿ç”¨ liburingï¼Œæ”¯æŒå¼‚æ­¥ checkpointï¼Œä½†ä»ä¸ºæ¯ä¸ª shard åˆ›å»ºç‹¬ç«‹æ–‡ä»¶
- **Ideal Baseline**ï¼šä½œè€…æ„å»ºçš„ç†æƒ³åŒ– microbenchmarkï¼Œä½¿ç”¨å•ä¸ªèšåˆæ–‡ä»¶ + é¢„åˆ†é… buffer + liburing æ‰¹é‡æäº¤

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### âœ… å†™å…¥ååæå‡æ˜¾è‘—ï¼ˆvs. ç”Ÿäº§å¼•æ“ï¼‰ï¼š
| æ–¹æ³• | æœ€å¤§å†™å…¥ååæå‡å€æ•°ï¼ˆvs. DataStates-LLMï¼‰ | vs. TorchSnapshot |
|------|--------------------------|------------------|
| æœ¬æ–‡æå‡ºçš„èšåˆ + liburing æ–¹æ¡ˆ | **3.9Ã—** | **7.6Ã—** |

> æ¥æºï¼šFigure 18ï¼Œåœ¨ 13B æ¨¡å‹ä¸‹è¾¾åˆ°æœ€å¤§å·®è·

#### âœ… è¯»å–ååä¹Ÿæœ‰æ˜æ˜¾æ”¹å–„ï¼š
| æ–¹æ³• | æœ€å¤§è¯»å–ååæå‡å€æ•°ï¼ˆvs. DataStates-LLMï¼‰ | vs. TorchSnapshot |
|------|----------------------------|------------------|
| æœ¬æ–‡æ–¹æ¡ˆ | **3.6Ã—** | **3.8Ã—** |

> å°æ–‡ä»¶è¶Šå¤šã€ç¢ç‰‡è¶Šä¸¥é‡ï¼Œä¼˜åŠ¿è¶Šæ˜æ˜¾

#### âœ… å•èŠ‚ç‚¹å†™å…¥ååéšæ•°æ®é‡å¢é•¿è€Œé¥±å’Œï¼š
- å†™å…¥åååœ¨ per-rank æ•°æ®é‡è¾¾ ~2GB åè¶‹äºå¹³ç¨³ï¼ˆFigure 7ï¼‰
- è¡¨æ˜å­˜åœ¨â€œæœ€ä¼˜èšåˆé˜ˆå€¼â€ï¼Œè¶…è¿‡åæ”¶ç›Šé€’å‡

#### âœ… è¯»å–æ€§èƒ½æ™®éä½äºå†™å…¥ï¼ˆåå¸¸è¯†ç°è±¡ï¼‰ï¼š
- åœ¨æœ¬å¹³å°ä¸Šï¼Œ**restore æ¯” checkpoint æ›´æ…¢**
- ä¸»å› ï¼šrestore éœ€åŒæ­¥ä¸²è¡Œå¤„ç†å¤šä¸ªå°å¯¹è±¡ï¼Œä¸”æ¶‰åŠåŠ¨æ€å†…å­˜åˆ†é…

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

| å¯¹æ¯”ç»´åº¦ | TorchSnapshot | DataStates-LLM | æœ¬æ–‡ç†æƒ³æ–¹æ¡ˆ |
|--------|---------------|----------------|--------------|
| æ–‡ä»¶ç»„ç»‡ | æåº¦ç¢ç‰‡åŒ–ï¼ˆâ‰¤512MB/chunkï¼‰ | file-per-shard | å•æ–‡ä»¶èšåˆ |
| I/O æ¥å£ | libaioï¼ˆè€æ—§ï¼‰ | liburing | liburing |
| ç¼“å†²æœºåˆ¶ | åŠ¨æ€åˆ†é… | åŠ¨æ€åˆ†é… | **é¢„åˆ†é… + å¤ç”¨** |
| å…ƒæ•°æ®å‹åŠ› | æé«˜ï¼ˆæ·±ç›®å½•+å¤šæ–‡ä»¶ï¼‰ | é«˜ | æä½ |
| å†™åå | æœ€å·® | ä¸­ç­‰ | **æœ€ä½³ï¼ˆæœ€é«˜ 7.6Ã—ï¼‰** |
| è¯»åå | å·® | è¾ƒå·® | **æœ€ä½³ï¼ˆæœ€é«˜ 3.8Ã—ï¼‰** |
| å¯æ‰©å±•æ€§ | å‡ ä¹æ— æ‰©å±•æ€§ | æœ‰é™æ‰©å±•æ€§ | è‰¯å¥½æ‰©å±•æ€§ |

> å›¾ 3 æ˜¾ç¤ºï¼šç›¸æ¯”â€œç†æƒ³æ–¹æ¡ˆâ€ï¼ŒTorchSnapshot å¯¼è‡´è¿­ä»£æ—¶é—´å»¶é•¿ 4.5Ã—ï¼ŒDataStates-LLM å»¶é•¿ 1.8Ã—

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰èšåˆç­–ç•¥çš„å½±å“ï¼ˆFigure 5â€“8ï¼‰
- **file-per-shard**ï¼šæ€§èƒ½æœ€å·®ï¼Œå°¤å…¶åœ¨å¤šè¿›ç¨‹æ—¶ä¸‹é™æ˜æ˜¾
- **file-per-process / single file**ï¼šæ€§èƒ½æ¥è¿‘ï¼Œå‡ä¼˜äºå‰è€…çº¦ 34%
- åŸå› ï¼šå‡å°‘å…ƒæ•°æ®æŸ¥æ‰¾ã€æƒé™æ£€æŸ¥ã€é”ç«äº‰ç­‰å†…æ ¸å¼€é”€

#### ï¼ˆ2ï¼‰O_DIRECT çš„å½±å“ï¼ˆFigure 9â€“10ï¼‰
| æ“ä½œ | O_DIRECT æ•ˆæœ |
|------|----------------|
| **Writes** | æå‡å·¨å¤§ï¼šliburing ä¸‹ **+4.8Ã—**ï¼ŒPOSIX ä¸‹ +2.2Ã—ï¼ˆé¿å…åŒç¼“å†²ï¼‰ |
| **Reads (<1GB)** | æ€§èƒ½ä¸‹é™ï¼ˆæ— æ³•åˆ©ç”¨ page cacheï¼‰ |
| **Reads (>4GB)** | æ€§èƒ½æŒå¹³ç”šè‡³ç•¥ä¼˜ï¼ˆé¿å… cache æ·˜æ±°å¼€é”€ï¼‰ |
| **æ··åˆæ¨¡å¼å°è¯•ï¼ˆä»…å†™ç”¨ O_DIRECTï¼‰** | âŒ å¤±è´¥ï¼åè€Œé™ä½æ•´ä½“æ€§èƒ½æœ€å¤šè¾¾ 3Ã—ï¼Œå› ç¼“å­˜æ±¡æŸ“ |

âœ… **ç»“è®ºï¼šç»Ÿä¸€å¯ç”¨ O_DIRECT æ˜¯æœ€ä½³é€‰æ‹©**

#### ï¼ˆ3ï¼‰å†…å­˜åˆ†é…å¼€é”€åˆ†æï¼ˆFigure 13ï¼‰
- åœ¨ DataStates-LLM çš„ restore è¿‡ç¨‹ä¸­ï¼Œ**å†…å­˜åˆ†é…è€—æ—¶ â‰ˆ å®é™…è¯»å–æ—¶é—´**
- è‹¥å»é™¤è¯¥å¼€é”€ï¼ˆé¢„åˆ†é… bufferï¼‰ï¼Œè¯»ååå¯**ç¿»å€**ï¼ˆFigure 14ï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. ğŸ”¹ **I/O èšåˆè‡³å…³é‡è¦**  
   â€œfile-per-shardâ€ è™½ç®€åŒ–ç¼–ç¨‹æ¨¡å‹ï¼Œä½†ä¸¥é‡æŸå®³ PFS æ€§èƒ½ã€‚**èšåˆä¸ºå•ä¸ªå¤§æ–‡ä»¶æˆ– per-process æ–‡ä»¶å¯å¤§å¹…æå‡ååã€é™ä½å…ƒæ•°æ®å‹åŠ›**ã€‚

2. ğŸ”¹ **liburing æœ‰æ½œåŠ›ï¼Œä½†éœ€é…åˆæ­£ç¡®ç­–ç•¥æ‰èƒ½å‘æŒ¥ä¼˜åŠ¿**  
   å•çº¯ä½¿ç”¨ liburing ä¸è¶³ä»¥è§£å†³é—®é¢˜ï¼Œå¿…é¡»ç»“åˆï¼š
   - è¯·æ±‚èšåˆï¼ˆrequest coalescingï¼‰
   - ç¼“å†²åŒºé¢„åˆ†é…ï¼ˆpreallocationï¼‰
   - å¯¹é½å†™å…¥ï¼ˆalignmentï¼‰
   æ‰èƒ½é€¼è¿‘ç¡¬ä»¶æé™ã€‚

3. ğŸ”¹ **O_DIRECT å¯¹å†™æœ‰åˆ©ã€å¯¹å°è¯»ä¸åˆ©ï¼Œä½†ç»Ÿä¸€å¼€å¯ä»æ˜¯æœ€ä½³å®è·µ**  
   å°½ç®¡å…³é—­ç¼“å­˜ä¼šç‰ºç‰²å°è¯»æ€§èƒ½ï¼Œä½†åœ¨å¤§è§„æ¨¡å¹¶å‘ restore åœºæ™¯ä¸‹ï¼Œç¼“å­˜å¤±æ•ˆå’Œç®¡ç†å¼€é”€æ›´å¤§ï¼Œå› æ­¤æ¨èå…¨ç¨‹å¯ç”¨ `O_DIRECT`ã€‚

4. ğŸ”¹ **ç°æœ‰ C/R å¼•æ“çš„ä¸»è¦ç“¶é¢ˆä¸åœ¨ I/O å±‚ï¼Œè€Œåœ¨è¿è¡Œæ—¶å¼€é”€**  
   å¦‚ **åŠ¨æ€å†…å­˜åˆ†é…ã€åºåˆ—åŒ–ã€å…ƒæ•°æ®è§£æ** ç­‰ CPU å¼€é”€æˆä¸ºæ–°çš„ç“¶é¢ˆï¼Œå°¤å…¶æ˜¯ restore é˜¶æ®µã€‚

5. ğŸ”¹ **LLM C/R çš„ I/O æ¨¡å¼ä¸ä¼ ç»Ÿ HPC æˆªç„¶ä¸åŒ**  
   ä¼ ç»Ÿç§‘å­¦è®¡ç®—å¸¸ä¸ºå¤§å—è¿ç»­æ•°æ®ï¼Œè€Œ LLM checkpoint æ˜¯é«˜åº¦ç¢ç‰‡åŒ–çš„å¼‚æ„é›†åˆï¼Œä¸èƒ½ç®€å•æ²¿ç”¨æ—§æœ‰ä¼˜åŒ–ç»éªŒã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ microbenchmark å°šæœªå®Œå…¨é›†æˆåˆ°çœŸå®è®­ç»ƒæµç¨‹ä¸­ï¼Œéƒ¨åˆ†å‡è®¾ï¼ˆå¦‚å®Œç¾åç§»å¯¹é½ï¼‰åœ¨åŠ¨æ€è°ƒåº¦ç¯å¢ƒä¸­å¯èƒ½éš¾å®ç°ï¼›
- å•ä¸€èšåˆæ–‡ä»¶è™½é«˜æ•ˆï¼Œä½†åœ¨æ•…éšœæ¢å¤æ—¶ä¸å¤Ÿçµæ´»ï¼ˆæ— æ³•å±€éƒ¨æ¢å¤ï¼‰ï¼›
- æœªè€ƒè™‘ç½‘ç»œæ‹“æ‰‘ã€RDMAã€NVMe-oF ç­‰æ›´å…ˆè¿›å­˜å‚¨æ¶æ„çš„å½±å“ï¼›
- æ‰€æœ‰å®éªŒåŸºäº Lustreï¼Œå…¶ä»– PFSï¼ˆå¦‚ GPFSã€BeeGFSï¼‰çš„è¡Œä¸ºå¯èƒ½æœ‰æ‰€ä¸åŒã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **åœ¨ DataStates-LLM ç­‰ç”Ÿäº§æ¡†æ¶ä¸­é›†æˆä¼˜åŒ–ç­–ç•¥**ï¼š
   - å®ç°æŒä¹…åŒ–ç¼“å†²åŒºæ± ï¼ˆpersistent buffer poolï¼‰
   - æ”¯æŒå¯¹è±¡èšåˆï¼ˆobject groupingï¼‰ä¸æ‰¹é‡æäº¤
   - å¤šçº¿ç¨‹å®Œæˆé˜Ÿåˆ—å¤„ç†

2. **å¼€å‘ hybrid aggregation ç­–ç•¥**ï¼š
   - åœ¨ç”¨æˆ·ç©ºé—´å…ˆèšåˆé€»è¾‘å¯¹è±¡ï¼Œå†é€šè¿‡ kernel æäº¤æ‰¹å¤„ç†è¯·æ±‚
   - å¹³è¡¡çµæ´»æ€§ä¸æ€§èƒ½

3. **æ¢ç´¢æ™ºèƒ½é¢„å–ä¸åˆ†å±‚å­˜å‚¨ç®¡ç†**ï¼š
   - åˆ©ç”¨ checkpoint å†å²é¢„æµ‹ restore æ¨¡å¼
   - ç»“åˆ SCM/NVM åŠ é€Ÿå…ƒæ•°æ®è®¿é—®

4. **æ„å»ºé¢å‘ LLM çš„ä¸“ç”¨ I/O profiler å·¥å…·**ï¼š
   - æ”¯æŒ liburingã€io_uring çš„ç»†ç²’åº¦è¿½è¸ª
   - æ›¿ä»£ Darshan åœ¨å¼‚æ­¥ I/O åœºæ™¯ä¸­çš„ä¸è¶³

--- 

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬æ–‡æ­ç¤ºäº† LLM Checkpoint/Restore ä¸­ I/O æ€§èƒ½çš„å…³é”®ç“¶é¢ˆåœ¨äº**ç¢ç‰‡åŒ– I/O å’Œè¿è¡Œæ—¶å¼€é”€**ï¼Œå¹¶é€šè¿‡ç³»ç»Ÿå®éªŒè¯æ˜ï¼š**ç»“åˆ liburingã€I/O èšåˆã€O_DIRECT å’Œé¢„åˆ†é…ç¼“å†²åŒºï¼Œå¯å®ç°é«˜è¾¾ 7.6Ã— çš„å†™ååæå‡**ï¼Œä¸ºä¸‹ä¸€ä»£é«˜æ€§èƒ½ C/R æ¡†æ¶æŒ‡æ˜äº†ä¼˜åŒ–è·¯å¾„ã€‚

</details>

---

### 9. [Reliable and Resilient Collective Communication Library for LLM Training and Serving](https://arxiv.org/abs/2512.25059)

**Authors**: Wei Wang, Nengneng Yu, Sixian Xiong, Zaoxing Liu  
**Category**: cs.DC  
**Published**: 2026-01-01  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.25059v1  

#### Abstract
Modern ML training and inference now span tens to tens of thousands of GPUs, where network faults can waste 10--15\% of GPU hours due to slow recovery. Common network errors and link fluctuations trigger timeouts that often terminate entire jobs, forcing expensive checkpoint rollback during training...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šReliable and Resilient Collective Communication Library for LLM Training and Serving**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
ç°ä»£å¤§è§„æ¨¡æœºå™¨å­¦ä¹ ï¼ˆå°¤å…¶æ˜¯å¤§è¯­è¨€æ¨¡å‹ LLMï¼‰è®­ç»ƒå’Œæ¨ç†ä¾èµ–äºæˆç™¾ä¸Šåƒå¼  GPU ç»„æˆçš„åˆ†å¸ƒå¼é›†ç¾¤ï¼Œè€Œç½‘ç»œæ•…éšœï¼ˆå¦‚ NIC å¤±æ•ˆã€é“¾è·¯æ³¢åŠ¨ï¼‰é¢‘ç¹å‘ç”Ÿï¼Œå¯¼è‡´ä»»åŠ¡ä¸­æ–­ã€‚ä¼ ç»Ÿå®¹é”™æœºåˆ¶ï¼ˆå¦‚ Checkpointingï¼‰æ¢å¤æ—¶é—´é•¿ï¼ˆä¸­ä½æ•°è¾¾ 68 åˆ†é’Ÿï¼‰ï¼Œé€ æˆå¤§é‡ GPU èµ„æºæµªè´¹ï¼ˆå¯é«˜è¾¾ 10â€“15%ï¼‰ã€‚æ­¤å¤–ï¼Œç°æœ‰é€šä¿¡åº“ï¼ˆå¦‚ NCCLï¼‰åœ¨è¿è¡Œæ—¶æ— æ³•å¤„ç†ç½‘ç»œæ•…éšœï¼Œä¸€æ—¦å‡ºç°è¿æ¥è¶…æ—¶å³ç»ˆæ­¢æ•´ä¸ªä½œä¸šã€‚

æœ¬æ–‡æŒ‡å‡ºï¼Œ**å³ä½¿éƒ¨åˆ†ç½‘ç»œè·¯å¾„å¤±æ•ˆï¼Œå¤š NIC æ¶æ„ä¸‹ä»å­˜åœ¨å†—ä½™é€šä¿¡è·¯å¾„**ï¼Œä½†ç°æœ‰ç³»ç»Ÿæœªèƒ½æœ‰æ•ˆåˆ©ç”¨è¿™äº›èµ„æºè¿›è¡Œâ€œçƒ­ä¿®å¤â€ï¼ˆhot repairï¼‰ï¼Œè€Œæ˜¯é€‰æ‹©é‡å¯ï¼Œä»£ä»·é«˜æ˜‚ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡º **R2CCL**ï¼ˆReliable and Resilient Collective Communication Libraryï¼‰ï¼Œä¸€ä¸ª**é«˜å¯é ã€é«˜å¼¹æ€§çš„é›†ä½“é€šä¿¡åº“**ï¼Œä½œä¸º NCCL/RCCL çš„æ’ä»¶å¼æ›¿ä»£æ–¹æ¡ˆï¼Œå®ç°ä»¥ä¸‹ä¸‰å¤§æ ¸å¿ƒåŠŸèƒ½ï¼š

#### **(1) å¿«é€Ÿæ•…éšœæ£€æµ‹ä¸å®šä½**
- å¼•å…¥ **out-of-band (OOB) é€šçŸ¥é€šé“**ï¼Œå®ç°åŒè¾¹é”™è¯¯æ„ŸçŸ¥ï¼ˆbilateral failure awarenessï¼‰ï¼Œé¿å…å•è¾¹ç­‰å¾…æ­»è¿æ¥ã€‚
- åˆ©ç”¨è½»é‡çº§ **RDMA æ¢é’ˆï¼ˆprobe-based fault localizationï¼‰** è¿›è¡Œä¸‰ç‚¹ä¸‰è§’æµ‹é‡ï¼Œç²¾ç¡®å®šä½æ•…éšœå‘ç”Ÿåœ¨æœ¬åœ° NICã€è¿œç«¯ NIC è¿˜æ˜¯ç‰©ç†é“¾è·¯ä¸Šã€‚

#### **(2) é›¶ä¸¢åŒ…çš„å®æ—¶è¿æ¥è¿ç§»ï¼ˆLive Migrationï¼‰**
- **Multi-NIC GPU Buffer Registration**ï¼šåˆå§‹åŒ–æ—¶å°†æ¯ä¸ª GPU ç¼“å†²åŒºæ³¨å†Œåˆ°æ‰€æœ‰ NICï¼Œé¿å…æ•…éšœåˆ‡æ¢æ—¶é‡æ–°æ³¨å†Œå¸¦æ¥çš„å»¶è¿Ÿã€‚
- **DMA-buffer Rollback**ï¼šå‘é€æ–¹å›æ»šåˆ°æœ€åç¡®è®¤çš„æ•°æ®å—ï¼Œæ¥æ”¶æ–¹é‡ç½®çŠ¶æ€ï¼Œåœ¨å¤‡ç”¨ NIC ä¸Šå®‰å…¨é‡ä¼ å‰©ä½™æ•°æ®ï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§ã€‚

#### **(3) æ•…éšœæ„ŸçŸ¥çš„åœ¨çº¿è°ƒåº¦ä¼˜åŒ–**
- **R2CCL-Balance**ï¼šé’ˆå¯¹é™¤ AllReduce å¤–çš„æ‰€æœ‰é›†ä½“æ“ä½œï¼ŒåŠ¨æ€å°†æµé‡ä»æ•…éšœ NIC å‡è¡¡åˆ†é…åˆ°å‰©ä½™å¥åº· NICï¼Œè€ƒè™‘ PCIeã€NUMA å’Œ PXN æ‹“æ‰‘ã€‚
- **R2CCL-AllReduce**ï¼šæ”¹è¿›ç¯å½¢ AllReduce ç®—æ³•ï¼Œé‡‡ç”¨â€œå…¨å±€ AllReduce + å±€éƒ¨ AllReduce + å®šåˆ¶å¹¿æ’­â€çš„ä¸¤é˜¶æ®µç­–ç•¥ï¼Œé™ä½ç“¶é¢ˆèŠ‚ç‚¹è´Ÿè½½ã€‚
- **é€’å½’å¼ R2CCL-AllReduce**ï¼šæ”¯æŒå¤šæ•…éšœåœºæ™¯ï¼Œé€šè¿‡é€»è¾‘é‡æ’åºï¼ˆlogical re-rankingï¼‰æ’å…¥â€œæ¡¥æ¥èŠ‚ç‚¹â€ï¼Œè§£å†³ rail ä¸åŒ¹é…é—®é¢˜ï¼Œå¹¶é€’å½’åˆ†è§£é€šä¿¡å›¾ä»¥é€‚åº”å¸¦å®½è°±ç³»ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| å¯¹æ¯”ç»´åº¦ | R2CCL | AdapCC | DÃ©jaVu |
|--------|-------|--------|--------|
| **æ¢å¤æ–¹å¼** | è¿è¡Œæ—¶çƒ­ä¿®å¤ï¼Œä¸ä¸­æ–­ä½œä¸š | æ’é™¤æ•…éšœèŠ‚ç‚¹ï¼Œå¯èƒ½æŸå¤±æ¢¯åº¦ | KV Cache å¤åˆ¶ï¼Œè¯·æ±‚é‡è·¯ç”± |
| **æ¢å¤å»¶è¿Ÿ** | < 1msï¼ˆè¿æ¥è¿ç§»ï¼‰ | éœ€é‡æ–°å¯åŠ¨ | æ•°ç§’è‡³æ•°åç§’ |
| **é€šä¿¡å¼€é”€** | æä½ï¼ˆ<1% è®­ç»ƒï¼Œ<3% æ¨ç†ï¼‰ | ä¸­ç­‰ï¼ˆéœ€é‡å»ºæ‹“æ‰‘ï¼‰ | é«˜ï¼ˆå¤åˆ¶ KV Cache å ç”¨å†…å­˜å’Œå¸¦å®½ï¼‰ |
| **é€‚ç”¨åœºæ™¯** | æ‰€æœ‰é›†ä½“æ“ä½œï¼Œæ”¯æŒ mid-operation æ•…éšœ | ä»…é™è¿­ä»£é—´æ•…éšœ | ä»…é™æ¨ç† |
| **æ˜¯å¦ä¿®æ”¹åº”ç”¨å±‚** | å¦ï¼ˆé€æ˜æ›¿æ¢ NCCLï¼‰ | æ˜¯ï¼ˆéœ€åè°ƒå™¨ï¼‰ | æ˜¯ï¼ˆéœ€é›†æˆæ¡†æ¶ï¼‰ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šR2CCL åœ¨ä¼ è¾“å±‚å®ç°é€æ˜å®¹é”™ï¼Œæ— éœ€é‡å¯ã€æ— æ¢¯åº¦ä¸¢å¤±ã€ä½å¼€é”€ï¼Œé€‚ç”¨äºè®­ç»ƒå’Œæ¨ç†å…¨åœºæ™¯ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **å®éªŒå¹³å°**
- **ç‰©ç†æµ‹è¯•åºŠ**ï¼šä¸¤ä¸ªæœåŠ¡å™¨èŠ‚ç‚¹ï¼Œæ¯èŠ‚ç‚¹é…å¤‡ï¼š
  - 8 Ã— NVIDIA H100 GPU
  - 8 Ã— InfiniBand 400Gbps NIC
  - æ”¯æŒ NVLink 4.0ï¼ˆ900GB/sï¼‰
- **å¤§è§„æ¨¡ä»¿çœŸ**ï¼šä½¿ç”¨ **SimAI** æ¨¡æ‹Ÿå™¨ï¼Œæ¨¡æ‹Ÿæœ€å¤š 1024 GPU çš„é›†ç¾¤ï¼Œé…ç½®ä¸º A100 + 200Gbps NICï¼Œæ”¯æŒ RoCE-v2 rail ä¼˜åŒ–æ‹“æ‰‘ã€‚

---

### **è¯„ä¼°æŒ‡æ ‡**
| åœºæ™¯ | ä¸»è¦æŒ‡æ ‡ |
|------|---------|
| **è®­ç»ƒ** | Token/s ååé‡ã€ç›¸å¯¹æ— æ•…éšœåŸºå‡†çš„æ€§èƒ½å¼€é”€ã€è¿­ä»£æ—¶é—´ |
| **æ¨ç†** | Time to First Token (TTFT)ã€Time Per Output Token (TPOT)ã€p50/p95/p99 å»¶è¿Ÿ |
| **å¾®åŸºå‡†æµ‹è¯•** | AllReduceã€AllGatherã€ReduceScatterã€Send/Recv çš„å¸¦å®½åˆ©ç”¨ç‡ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åœºæ™¯ | åŸºçº¿æ–¹æ³• |
|------|----------|
| **è®­ç»ƒ** | 
| - Vanilla NCCL | é‡æ•…éšœç›´æ¥å´©æºƒ |
| - AdapCC | æ’é™¤æ•…éšœ GPUï¼Œé‡æ„é€šä¿¡å›¾ |
| **æ¨ç†** |
| - NCCL + Restart Server | æœåŠ¡é‡å¯ï¼Œå»¶è¿Ÿ 35 ç§’ |
| - NCCL + Reroute Requests | è¯·æ±‚é‡å®šå‘ï¼Œè´Ÿè½½ç¿»å€ |
| - DÃ©jaVu | KV Cache å¤åˆ¶ï¼Œæ”¯æŒæ•…éšœæ¢å¤ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **è®­ç»ƒæ€§èƒ½ï¼ˆMegatron-LMï¼‰**
| æ¨¡å‹ | é…ç½® | æ–¹æ³• | æ€§èƒ½ï¼ˆtokens/sï¼‰ | ç›¸å¯¹æ— æ•…éšœå¼€é”€ |
|------|------|------|------------------|----------------|
| GPT-3 2.7B | DP=16 | R2CCL-AllReduce | 312,394 | **0.71%** |
| GPT-3 2.7B | DP=16 | R2CCL-Balance | 310,000 | 1.32% |
| GPT-3 2.7B | DP=16 | AdapCC | 287,000 | 8.65% |
| Llama-13B | TP=8, PP=2 | R2CCL-Balance | 8,309 | **0.38%** |
| Llama-13B | TP=8, PP=2 | R2CCL-HotRepair | 8,220 | 1.31% |
| Llama-13B | TP=8, PP=2 | AdapCC | 0 | âŒ ä¸å…¼å®¹ |

> ğŸ”¹ **R2CCL åœ¨è®­ç»ƒä¸­å¼€é”€ <1%ï¼Œæ˜¾è‘—ä¼˜äº AdapCCï¼ˆæœ€é«˜å¿« 12.18Ã—ï¼‰**

#### **å¤šæ•…éšœåœºæ™¯ï¼ˆSimAI æ¨¡æ‹Ÿ 512-GPU é›†ç¾¤ï¼‰**
| æ•…éšœæ•°é‡ | R2CCL å¼€é”€å¢é•¿è¶‹åŠ¿ |
|---------|--------------------|
| 1 ä¸ª NIC æ•…éšœ | 1.5% |
| 10 ä¸ªå¹¶å‘ NIC æ•…éšœ | **ä»… 4.3%**ï¼ˆäºšçº¿æ€§å¢é•¿ï¼‰ |

> ğŸ”¹ è¡¨æ˜ R2CCL å…·å¤‡å¼ºæ‰©å±•æ€§å’Œé²æ£’æ€§ã€‚

#### **æ¨ç†æ€§èƒ½ï¼ˆvLLM + Llama-3.1ï¼‰**
| æ¨¡å‹ | æ–¹æ³• | TTFT å¼€é”€ | TPOT å¼€é”€ | ååæå‡ï¼ˆvs Restartï¼‰ |
|------|------|-----------|-----------|------------------------|
| Llama-3.1-405B | R2CCL-Balance | **~0â€“3%** | **~3%** | **1.9Ã—â€“2.6Ã—** |
| OPT-66B / BLOOM-176B | R2CCL vs DÃ©jaVu | **0.71â€“1.58%** | â€” | **8.6Ã—â€“47Ã— æ›´ä½æ¢å¤å¼€é”€** |

> ğŸ”¹ R2CCL æ¨ç†æ¢å¤å¼€é”€æ¯” DÃ©jaVu ä½ **47Ã—**ï¼Œæ¯”éå®¹é”™åŸºçº¿ä½ **113Ã—**ã€‚

#### **å¾®åŸºå‡†æµ‹è¯•ï¼ˆAllReduceï¼‰**
| æ•°æ®å¤§å° | R2CCL-Balance ååç‡ | R2CCL-AllReduce ååç‡ |
|---------|----------------------|------------------------|
| å°æ¶ˆæ¯ (<32MB) | 92% æ­£å¸¸æ°´å¹³ | 66%ï¼ˆå› åè°ƒå¼€é”€ï¼‰ |
| å¤§æ¶ˆæ¯ (â‰¥512MB) | 83% | **93%**ï¼ˆæœ€ä¼˜ï¼‰ |

> ğŸ”¹ R2CCL åŠ¨æ€é€‰æ‹©ç­–ç•¥ï¼ˆåŸºäº Î±-Î² æ¨¡å‹ï¼‰ï¼Œè‡ªåŠ¨é€‚é…ä¸åŒç¡¬ä»¶å’Œæ¶ˆæ¯å°ºå¯¸ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ç½‘ç»œæ•…éšœä¸åº”å¯¼è‡´å…¨ä½œä¸šé‡å¯**ï¼šåˆ©ç”¨å¤š NIC å†—ä½™è·¯å¾„ï¼Œå¯åœ¨æ¯«ç§’çº§å®Œæˆçƒ­ä¿®å¤ï¼Œé¿å…æ˜‚è´µçš„ Checkpoint å›æ»šã€‚
2. **R2CCL å®ç°è¿‘ä¹é›¶å¼€é”€çš„å®¹é”™**ï¼š
   - è®­ç»ƒå¼€é”€ **<1%**
   - æ¨ç†å¼€é”€ **<3%**
   - æ¢å¤æ—¶é—´ **<1ms**
3. **ç›¸æ¯”ç°æœ‰å®¹é”™ç³»ç»Ÿå…·æœ‰å‹å€’æ€§ä¼˜åŠ¿**ï¼š
   - è®­ç»ƒæ•ˆç‡æ¯” AdapCC é«˜ **12.18Ã—**
   - æ¨ç†æ¢å¤å¼€é”€æ¯” DÃ©jaVu ä½ **47Ã—**
4. **æ”¯æŒå¤æ‚å¤šæ•…éšœåœºæ™¯**ï¼šé€šè¿‡æ‹“æ‰‘æ„ŸçŸ¥é‡æ’åºå’Œé€’å½’è°ƒåº¦ï¼Œæœ‰æ•ˆåº”å¯¹ rail ä¸åŒ¹é…å’Œå¸¦å®½å¼‚æ„é—®é¢˜ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **ä¸æ”¯æŒ NVLink/NVSwitch æ•…éšœ**ï¼šä»…å¤„ç† inter-node é€šä¿¡æ•…éšœï¼Œintra-node fabric æ•…éšœä¸åœ¨èŒƒå›´å†…ã€‚
2. **ä¾èµ–å¤š NIC ç¡¬ä»¶**ï¼šè‹¥èŠ‚ç‚¹åªæœ‰ä¸€ä¸ª NICï¼Œåˆ™æ— æ³•æä¾›å†—ä½™è·¯å¾„ã€‚
3. **æ— æ³•å¤„ç†è¿›ç¨‹å´©æºƒæˆ–å…¨ç½‘åˆ†åŒº**ï¼šä»…é€‚ç”¨äº NIC/é“¾è·¯çº§è½¯æ•…éšœã€‚
4. **PXN è½¬å‘å¼•å…¥é¢å¤–è·³æ•°**ï¼šè™½å¼€é”€å°ï¼Œä½†åœ¨æç«¯æƒ…å†µä¸‹å¯èƒ½å½±å“æ€§èƒ½ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ‰©å±•è‡³ NVLink æ•…éšœæ¢å¤**ï¼šæ¢ç´¢ intra-node é€šä¿¡çš„å¼¹æ€§æœºåˆ¶ã€‚
2. **æ”¯æŒæ›´å¤æ‚çš„æ‹“æ‰‘è‡ªæ„ˆ**ï¼šç»“åˆ AI é©±åŠ¨çš„è°ƒåº¦å™¨è¿›è¡Œé¢„æµ‹æ€§ä¿®å¤ã€‚
3. **é›†æˆåˆ°æ›´å¤šæ¡†æ¶**ï¼šå¦‚ DeepSpeedã€ColossalAI ç­‰ã€‚
4. **è·¨æ•°æ®ä¸­å¿ƒå®¹é”™**ï¼šç ”ç©¶ geo-distributed åœºæ™¯ä¸‹çš„ R2CCL æ‰©å±•ã€‚

---

> ğŸ“Œ **æ€»ç»“**ï¼šR2CCL æ˜¯é¦–ä¸ªåœ¨è¿è¡Œæ—¶å®ç°**æ— ç¼ã€ä½å¼€é”€ã€å¤šæ•…éšœå®¹å¿**çš„é›†ä½“é€šä¿¡åº“ï¼Œé€šè¿‡è¿æ¥è¿ç§» + æ™ºèƒ½è°ƒåº¦ï¼Œåœ¨ä¸ä¸­æ–­è®­ç»ƒ/æ¨ç†çš„å‰æä¸‹å¤§å¹…æå‡ç³»ç»Ÿå¯é æ€§ï¼Œä¸ºå¤§è§„æ¨¡ LLM ç³»ç»Ÿæä¾›äº†å…³é”®åŸºç¡€è®¾æ–½æ”¯æŒã€‚  
> ğŸ”— é¡¹ç›®å¼€æºåœ°å€ï¼š[https://github.com/r2cc-project/R-2CCL](https://github.com/r2cc-project/R-2CCL)

</details>

---

### 10. [Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem](https://arxiv.org/abs/2512.24873)

**Authors**: Weixun Wang, XiaoXiao Xu, Wanhe An, Fangwen Dai, Wei Gao, Yancheng He, Ju Huang, Qiang Ji, Hanqi Jin, Xiaoyang Li, Yang Li, Zhongwen Li, Shirong Lin, Jiashun Liu, Zenan Liu, Tao Luo, Dilxat Muhtar, Yuanbin Qu, Jiaqiang Shi, Qinghui Sun, Yingshui Tan, Hao Tang, Runze Wang, Yi Wang, Zhaoguo Wang, Yanan Wu, Shaopan Xiong, Binchen Xu, Xander Xu, Yuchi Xu, Qipeng Zhang, Xixia Zhang, Haizhou Zhao, Jie Zhao, Shuaibing Zhao, Baihui Zheng, Jianhui Zheng, Suhang Zheng, Yanni Zhu, Mengze Cai, Kerui Cao, Xitong Chen, Yue Dai, Lifan Du, Tao Feng, Tao He, Jin Hu, Yijie Hu, Ziyu Jiang, Cheng Li, Xiang Li, Jing Liang, Chonghuan Liu, ZhenDong Liu, Haodong Mi, Yanhu Mo, Junjia Ni, Shixin Pei, Jingyu Shen, XiaoShuai Song, Cecilia Wang, Chaofan Wang, Kangyu Wang, Pei Wang, Tao Wang, Wei Wang, Ke Xiao, Mingyu Xu, Tiange Xu, Nan Ya, Siran Yang, Jianan Ye, Yaxing Zang, Duo Zhang, Junbo Zhang, Boren Zheng, Wanxi Deng, Ling Pan, Lin Qu, Wenbo Su, Jiamang Wang, Wei Wang, Hu Wei, Minggang Wu, Cheng Yu, Bing Zhao, Zhicheng Zheng, Bo Zheng  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.24873v1  

#### Abstract
Agentic crafting requires LLMs to operate in real-world environments over multiple turns by taking actions, observing outcomes, and iteratively refining artifacts. Despite its importance, the open-source community lacks a principled, end-to-end ecosystem to streamline agent development. We introduce...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤æ‚ã€å¤šè½®äº¤äº’ä»»åŠ¡ä¸­çš„è¡¨ç°å—é™äºç¼ºä¹ä¸€ä¸ª**ç«¯åˆ°ç«¯çš„ã€å¯æ‰©å±•çš„ agentic å­¦ä¹ ç”Ÿæ€ç³»ç»Ÿ**ã€‚ä¼ ç»Ÿæ–¹æ³•å¦‚ä¸€æ¬¡æ€§ç”Ÿæˆï¼ˆone-shot generationï¼‰æ— æ³•æ”¯æŒè¿­ä»£æ¨ç†å’Œç¯å¢ƒåé¦ˆé—­ç¯ï¼›è€Œç°æœ‰çš„ä»£ç†ç³»ç»Ÿå¾€å¾€ä¾èµ–äººå·¥æ¼”ç¤ºæˆ–ä¸ç¨³å®šçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒæµç¨‹ï¼Œåœ¨é•¿å‘¨æœŸä»»åŠ¡ä¸­é¢ä¸´å¥–åŠ±ç¨€ç–ã€ä¿¡ç”¨åˆ†é…å›°éš¾ã€è®­ç»ƒä¸ç¨³å®šç­‰é—®é¢˜ã€‚

æ­¤å¤–ï¼Œå¼€æºç¤¾åŒºç¼ºä¹ç»Ÿä¸€çš„åŸºç¡€è®¾æ–½æ¥æ”¯æŒä»æ•°æ®åˆæˆã€ç¯å¢ƒæ‰§è¡Œã€è®­ç»ƒä¼˜åŒ–åˆ°éƒ¨ç½²è¯„ä¼°çš„å…¨æµç¨‹ï¼Œä¸¥é‡é˜»ç¢äº† agentic æ¨¡å‹çš„å®é™…è½åœ°ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡ºäº†ä¸€å¥—å®Œæ•´çš„ **Agentic Learning Ecosystem (ALE)**ï¼Œå¹¶åŸºäºè¯¥ç”Ÿæ€æ„å»ºäº†å¼€æºä»£ç†æ¨¡å‹ **ROME (ROME is Obviously an Agentic ModEl)**ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**ç³»ç»Ÿçº§æ¶æ„ï¼šALE ä¸‰å¤§ç»„ä»¶ååŒè®¾è®¡**
- **ROLL (Reinforcement Learning Optimization for Large-Scale Learning)**  
  ä¸€ä¸ªå¯æ‰©å±•çš„ agentic RL è®­ç»ƒæ¡†æ¶ï¼Œæ”¯æŒå¤šç¯å¢ƒå¹¶è¡Œ rolloutã€å¼‚æ­¥è®­ç»ƒã€åŠ¨æ€ GPU å¤ç”¨ï¼Œæ˜¾è‘—æå‡è®­ç»ƒååé‡ä¸ç¨³å®šæ€§ã€‚
- **ROCK (Reinforcement Open Construction Kit)**  
  ä¸€ä¸ªå®‰å…¨æ²™ç®±ç¯å¢ƒç®¡ç†å™¨ï¼Œæä¾›å¯å¤ç°ã€éš”ç¦»çš„æ‰§è¡Œç¯å¢ƒï¼ˆå¦‚ Dockerï¼‰ï¼Œç”¨äºè½¨è¿¹ç”Ÿæˆã€éªŒè¯ä¸è¿è¡Œæ—¶æ§åˆ¶ï¼Œç¡®ä¿æ•°æ®ä¸è¡Œä¸ºçš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚
- **iFlow CLI**  
  ä¸€ä¸ªçµæ´»çš„ agent æ¡†æ¶ï¼Œè´Ÿè´£ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼ˆcontext engineeringï¼‰ã€å·¥å…·è°ƒç”¨ç¼–æ’ï¼Œå¹¶é€šè¿‡â€œä»£ç†åŸç”Ÿæ¨¡å¼â€ï¼ˆagent native modeï¼‰å®ç°è®­ç»ƒä¸éƒ¨ç½²çš„ä¸€è‡´æ€§ã€‚

è¿™ä¸‰è€…å…±åŒæ„æˆäº†ä¸€ä¸ªé—­ç¯çš„ agentic å·¥ä½œæµï¼š`ä»»åŠ¡ â†’ åŠ¨ä½œ â†’ æ‰§è¡Œ â†’ åé¦ˆ â†’ å­¦ä¹ `ã€‚

#### ï¼ˆ2ï¼‰**æ–°å‹ç­–ç•¥ä¼˜åŒ–ç®—æ³•ï¼šIPA (Interaction-Perceptive Agentic Policy Optimization)**

é’ˆå¯¹ä¼ ç»Ÿ token-level RL åœ¨é•¿å‘¨æœŸä»»åŠ¡ä¸­ä¿¡ç”¨åˆ†é…ä¸å‡†çš„é—®é¢˜ï¼Œæå‡ºå°† MDP å»ºæ¨¡ä¸º **Chunked MDP**ï¼Œä»¥è¯­ä¹‰ä¸Šæœ‰æ„ä¹‰çš„â€œäº¤äº’å—â€ï¼ˆinteraction chunkï¼‰ä¸ºå•ä½è¿›è¡Œä¿¡ç”¨åˆ†é…ï¼š
- æ¯ä¸ª chunk åŒ…å«ä¸€æ¬¡å®Œæ•´çš„â€œæ€è€ƒ â†’ å·¥å…·è°ƒç”¨ â†’ è§‚å¯Ÿåé¦ˆâ€çš„å¾ªç¯ã€‚
- å¼•å…¥ **chunk-level å›æŠ¥è®¡ç®—ã€é‡è¦æ€§é‡‡æ ·ä¸æ¢¯åº¦æ©ç **ï¼Œæå‡é•¿æœŸä»»åŠ¡çš„è®­ç»ƒç¨³å®šæ€§å’Œæ•ˆç‡ã€‚

#### ï¼ˆ3ï¼‰**é«˜è´¨é‡ agentic æ•°æ®åˆæˆæµæ°´çº¿**

æå‡ºä¸¤é˜¶æ®µæ•°æ®æ„å»ºç­–ç•¥ï¼š
- **åŸºç¡€æ•°æ®å±‚**ï¼šåŸºäº GitHub Issue-PR å¯¹æ„å»ºä»£ç å®šä½ã€ä¿®å¤ã€æµ‹è¯•ç”Ÿæˆç­‰ä»»åŠ¡ï¼Œå¢å¼ºåŸºæœ¬ç¼–ç èƒ½åŠ›ã€‚
- **agentic æ•°æ®å±‚**ï¼šé€šè¿‡å¤šæ™ºèƒ½ä½“åä½œæ¡†æ¶è‡ªåŠ¨ç”Ÿæˆå¸¦å¯æ‰§è¡Œç¯å¢ƒï¼ˆDockerï¼‰ã€å•å…ƒæµ‹è¯•å’Œåé¦ˆä¿¡å·çš„ä»»åŠ¡å®ä¾‹ä¸è½¨è¿¹ï¼Œè¦†ç›–è½¯ä»¶å·¥ç¨‹ã€ç»ˆç«¯æ“ä½œã€GUI è‡ªåŠ¨åŒ–ç­‰åœºæ™¯ã€‚
- å¼•å…¥å››é˜¶æ®µè¿‡æ»¤æœºåˆ¶ï¼ˆå¯å‘å¼è§„åˆ™ã€LLM åˆ¤æ–­ã€æ‰§è¡Œæ¨¡æ‹Ÿã€ä¸“å®¶å®¡æŸ¥ï¼‰ä¿è¯æ•°æ®è´¨é‡ã€‚

#### ï¼ˆ4ï¼‰**æå‡ºæ›´ä¸¥æ ¼çš„åŸºå‡†ï¼šTerminal Bench Pro**

ä¸ºè§£å†³ç°æœ‰ benchmarkï¼ˆå¦‚ Terminal-Bench 1.0/2.0ï¼‰è§„æ¨¡å°ã€é¢†åŸŸä¸å¹³è¡¡ã€æ±¡æŸ“é£é™©é«˜ç­‰é—®é¢˜ï¼Œæ„å»ºäº† **Terminal Bench Pro**ï¼š
- åŒ…å« 400 ä¸ªä»»åŠ¡ï¼ˆ200 å…¬å¼€ + 200 ç§æœ‰ï¼‰
- è¦†ç›– 8 ä¸ª CLI ç›¸å…³é¢†åŸŸï¼ˆæ•°æ®å¤„ç†ã€è°ƒè¯•ã€ç³»ç»Ÿç®¡ç†ã€å®‰å…¨ç­‰ï¼‰ï¼Œæ¯ç±» 50 é¡¹ï¼Œç¡®ä¿å‡è¡¡æ€§
- æ‰€æœ‰ä»»åŠ¡å‡é…å¤‡ç¡®å®šæ€§ç¯å¢ƒä¸é«˜è¦†ç›–ç‡æµ‹è¯•ç”¨ä¾‹ï¼Œé˜²æ­¢â€œèµ°æ·å¾„â€å¼é€šè¿‡

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **ç³»ç»Ÿå®Œæ•´æ€§** | é¦–æ¬¡æä¾›ä»æ•°æ® â†’ ç¯å¢ƒ â†’ è®­ç»ƒ â†’ éƒ¨ç½²å…¨æ ˆå¼€æºè§£å†³æ–¹æ¡ˆï¼Œå¡«è¡¥ç”Ÿæ€ç©ºç™½ |
| **è®­ç»ƒæ•ˆç‡ä¸ç¨³å®šæ€§** | ROLL æ”¯æŒå¼‚æ­¥è®­ç»ƒ + GPU åŠ¨æ€å¤ç”¨ï¼ŒIPA æå‡é•¿å‘¨æœŸä¿¡ç”¨åˆ†é…ç²¾åº¦ï¼Œå‡å°‘å´©æºƒé£é™© |
| **æ•°æ®è´¨é‡ä¸å®‰å…¨æ€§** | ROCK æä¾›å¼ºéš”ç¦»ç¯å¢ƒï¼Œç»“åˆå¤šé˜¶æ®µéªŒè¯ï¼Œæœ‰æ•ˆé¿å…è™šå‡æ­£æ ·æœ¬ä¸å®‰å…¨éšæ‚£ï¼ˆå¦‚æŒ–çŸ¿ã€åå‘éš§é“ï¼‰ |
| **æ€§èƒ½è¡¨ç°** | ROMEï¼ˆä»…æ¿€æ´» 3B å‚æ•°ï¼‰åœ¨å¤šä¸ª benchmark ä¸Šè¶…è¶Šæ›´å¤§æ¨¡å‹ï¼ˆç”šè‡³ >100B å‚æ•°ï¼‰ |
| **å¯å¤åˆ¶æ€§ä¸å…¬å¹³è¯„ä¼°** | Terminal Bench Pro æä¾›æ›´é«˜æ ‡å‡†çš„è¯„ä¼°åŸºå‡† |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

| ç±»å‹ | åç§°ä¸è¯´æ˜ |
|------|-----------|
| **åŸºç¡€é¢„è®­ç»ƒæ•°æ®** | æ¥è‡ªçº¦ 100 ä¸‡é«˜è´¨é‡ GitHub ä»“åº“çš„é¡¹ç›®çº§ä»£ç æ•°æ®ï¼ˆç»å»é‡ã€æ¸…æ´—åçº¦ 100B tokensï¼‰ |
| **SFT æ•°æ®** | åˆæˆç™¾ä¸‡çº§å¤šè½®äº¤äº’æ ·æœ¬ï¼Œæ¶µç›–ï¼š<br>- ä»£ç ä¿®å¤ï¼ˆIssue â†’ PRï¼‰<br>- å•å…ƒæµ‹è¯•ç”Ÿæˆ<br>- å¤šè½®åé¦ˆæ¼”åŒ–è½¨è¿¹ï¼ˆæ¥è‡ª PR è¯„è®ºï¼‰<br>- å·¥å…·ä½¿ç”¨å¯¹è¯ï¼ˆå†…éƒ¨æ—¥å¿— + åˆæˆï¼‰ |
| **RL æ•°æ®** | åŸºäºå¤š agent æµæ°´çº¿ç”Ÿæˆçš„ 76K é«˜è´¨é‡ agentic å®ä¾‹ä¸è½¨è¿¹ï¼Œæ€»çº¦ 30B tokens |
| **å®‰å…¨å¯¹é½æ•°æ®** | æ„å»ºçº¢é˜Ÿæ”»å‡»åœºæ™¯ï¼ˆprompt æ³¨å…¥ã€æ¶æ„ä¾èµ–ã€è¶Šæƒæ“ä½œï¼‰ï¼Œè®­ç»ƒæ¨¡å‹è¯†åˆ«å¹¶è§„é¿é£é™©è¡Œä¸º |

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹é…ç½®**
- åŸºåº§æ¨¡å‹ï¼šQwen3-MoE æ¶æ„
- æ¨¡å‹åç§°ï¼šROME (30B-A3B)ï¼Œå³æ€»å‚æ•° 30Bï¼Œæ¯æ¬¡æ¿€æ´»çº¦ 3B
- è®­ç»ƒæµç¨‹ï¼šContinual Pre-training â†’ Two-stage SFT â†’ IPA-based RL

#### **è¯„ä¼°ç»´åº¦**
1. **Terminal-based Execution**  
   - Terminal-Bench 1.0 / 2.0
   - SWE-bench Verified / Multilingual
   - **Terminal Bench Pro (Public & Private)**
2. **Tool-use Ability**  
   - TAU2-Bench (Retail/Airline/Telecom)
   - BFCL-v3 (Multi-turn)
   - MTU-Bench (Single/Multi-turn)
3. **General Agentic Capabilities**  
   - GAIA
   - BrowseComp-ZH
   - ShopAgent (Single/Multi-turn)

#### **è¯„ä¼°æŒ‡æ ‡**
- ä¸»è¦æŒ‡æ ‡ï¼šPass@1ï¼ˆå¹³å‡ 3 æ¬¡ç‹¬ç«‹è¿è¡Œç»“æœï¼‰
- ç”Ÿæˆå‚æ•°ï¼štemperature=0.7, top_p=0.8, top_k=20
- æœ€å¤§è¾“å‡ºé•¿åº¦ï¼š65,536 tokens
- æ‰€æœ‰ CLI ä»»åŠ¡é€šè¿‡ iFlow CLI ç»Ÿä¸€æ‰§è¡Œ

#### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- å¼€æºæ¨¡å‹ï¼šQwen3-Coder-30B-A3B-Instruct, Devstral-Small-2, GPT-OSS-120B
- å•†ä¸šé—­æºæ¨¡å‹ï¼ˆæŠ¥å‘Šå¼•ç”¨ï¼‰ï¼šClaude-Haiku-4.5, Gemini-2.5 Flash, GPT-5 Mini, Kimi-K2, DeepSeek-V3.1, GLM-4.6

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

#### âœ… **Terminal-based Benchmarks (Normal Models)**

| Benchmark | ROME | Qwen3-Coder-30B | GPT-OSS-120B | Best Closed-source |
|----------|------|------------------|---------------|--------------------|
| Terminal-Bench 1.0 | **41.50%** | 28.50% | 31.25% | â€” |
| Terminal-Bench 2.0 | **24.72%** | 13.48% | 21.12% | â€” |
| SWE-bench Verified | **57.40%** | 46.33% | 43.93% | 69.60% (Claude) |
| SWE-bench Multilingual | **40.00%** | 30.00% | 34.84% | 60.34% (Claude) |
| Terminal-Bench-Pro-Public | **40.50%** | 26.00% | 32.00% | 45.83% (Claude) |
| Terminal-Bench-Pro-Private | **21.50%** | 11.33% | 27.83% | 35.33% (Claude) |
| **Average** | **37.60%** | 25.94% | 31.83% | â€” |

> ğŸ”¹ ROME æ˜¾è‘—ä¼˜äºåŒè§„æ¨¡å¼€æºæ¨¡å‹ï¼Œå°¤å…¶åœ¨ SWE-bench å’Œ Terminal-Bench Pro è¡¨ç°çªå‡ºã€‚

#### âœ… **ä¸è¶…å¤§è§„æ¨¡æ¨¡å‹å¯¹æ¯”ï¼ˆLarge Modelsï¼‰**

å°½ç®¡ ROME æ€»å‚æ•°ä»…ä¸º 30Bï¼ˆæ¿€æ´» 3Bï¼‰ï¼Œä½†åœ¨å¤šé¡¹ä»»åŠ¡ä¸Šæ¥è¿‘ç”šè‡³è¶…è¿‡ç™¾äº¿ä»¥ä¸Šå‚æ•°æ¨¡å‹ï¼š

| Benchmark | ROME | Qwen3-Coder-480B | DeepSeek-V3.1 | Kimi-K2 (1043B) | Claude-Haiku-4.5 |
|----------|------|------------------|----------------|------------------|------------------|
| SWE-bench Verified | **57.40%** | 65.20% | 62.20% | 64.80% | **69.60%** |
| Terminal-Bench 2.0 | **24.72%** | 26.97% | 28.47% | 30.90% | **34.83%** |
| Terminal-Bench-Pro-Public | **40.50%** | 38.33% | 39.33% | 40.50% | **45.83%** |

> ğŸ”¹ ROME åœ¨ SWE-bench ä¸Šè¿œè¶… GLM-4.5 Air (56.20%) å’Œ Gemini-2.5 Flash (28.73%)ï¼Œæ¥è¿‘éƒ¨åˆ†é—­æºæ¨¡å‹ã€‚
> ğŸ”¹ åœ¨ Terminal-Bench-Pro ä¸Šè™½è½åäºæœ€å¤§æ¨¡å‹ï¼Œä½†ä»ä¼˜äºå¤šæ•°å¼€æºæ–¹æ¡ˆã€‚

#### âœ… **Tool-use ä¸ General Agentic èƒ½åŠ›**

| Benchmark | ROME | Avg. Closed-source |
|----------|------|---------------------|
| TAU2-Bench (Retail) | **62.28%** | ~67% |
| BFCL-v3 (Multi-turn) | **43.00%** | ~50% |
| MTU-Bench (Single-turn) | **62.45%** | ~60% |
| GAIA | **24.24%** | ~35% |
| ShopAgent (Multi-turn) | **29.61%** | ~30â€“36% |

> ğŸ”¹ åœ¨ ShopAgent å¤šè½®ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾ç¤ºå…¶å¼ºå¤§çš„ç”¨æˆ·æ„å›¾ç†è§£ä¸é•¿æœŸè§„åˆ’èƒ½åŠ›ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆå…³é”®å‘ç°ï¼‰**

1. **IPA ç®—æ³•æœ‰æ•ˆæ€§éªŒè¯ï¼ˆFig. 10ï¼‰**
   - Chunk-level ä¼˜åŒ–ç›¸æ¯” baseline æ˜¾è‘—é™ä½æ¢¯åº¦æ³¢åŠ¨ï¼ˆæ›´ç¨³å®šï¼‰
   - è®­ç»ƒæˆåŠŸç‡æ›´å¿«ä¸Šå‡ï¼Œä¸”æ³›åŒ–æ€§èƒ½æ›´å¥½

2. **Chunk-Level Initialized Sampling æå‡å­¦ä¹ æ•ˆç‡ï¼ˆFig. 12â€“13ï¼‰**
   - â€œSequential Rollbackâ€ ç­–ç•¥èƒ½å¿«é€ŸæŒæ¡å…³é”®å†³ç­–èŠ‚ç‚¹
   - å¹³è¡Œåˆå§‹åŒ–è¿›ä¸€æ­¥æå‡é‡‡æ ·æ•ˆç‡
   - åŠ å…¥ IL + RL æ··åˆç›®æ ‡å¯é˜²æ­¢ç­–ç•¥é€€åŒ–

3. **Error-Masked SFT ä¸ Context Masking æå‡è®­ç»ƒè´¨é‡**
   - è¿‡æ»¤å¤±è´¥äº¤äº’ä¸æ— å…³ä¸Šä¸‹æ–‡ï¼Œä½¿ SFT æ›´èšç„¦æœ‰æ•ˆè¡Œä¸º
   - å‡å°‘â€œè¿‡æ‹Ÿåˆé”™è¯¯è·¯å¾„â€ç°è±¡

4. **çœŸå®ä¸–ç•Œæ¡ˆä¾‹ç ”ç©¶ï¼ˆAppendixï¼‰**
   - åœ¨ 100 ä¸ªè„±æ•çœŸå®ä»»åŠ¡ä¸­ï¼ŒROME ç›¸æ¯” Qwen3-Coder-30B å’Œ Devstral-Small-2 çš„èƒœç‡åˆ†åˆ«ä¸º **58.8%** å’Œ **100%**
   - åœ¨ç¡çœ ç®¡ç†ç³»ç»Ÿä¸å¤ªé˜³ç³»å»ºæ¨¡ä»»åŠ¡ä¸­ï¼ŒROME è¾“å‡ºåŠŸèƒ½å®Œæ•´ã€ç»“æ„æ¸…æ™°ã€è§†è§‰è¿˜åŸåº¦é«˜

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **ç³»ç»Ÿè®¾è®¡å†³å®šä¸Šé™**ï¼š  
   å•çº¯æ‰©å¤§æ¨¡å‹è§„æ¨¡ä¸è¶³ä»¥çªç ´ agentic èƒ½åŠ›ç“¶é¢ˆã€‚**ä¸€ä¸ªç«¯åˆ°ç«¯ã€é—­ç¯çš„ agentic ç”Ÿæ€ç³»ç»Ÿï¼ˆALEï¼‰æ‰æ˜¯å…³é”®**ï¼Œå®ƒæ‰“é€šäº†æ•°æ®ã€ç¯å¢ƒã€è®­ç»ƒä¸éƒ¨ç½²ä¹‹é—´çš„å£å’ã€‚

2. **ROME å®ç°â€œè§„æ¨¡çªç ´â€ï¼ˆscale-breakingï¼‰**ï¼š  
   å°½ç®¡åªæœ‰ 30B æ€»å‚æ•°ï¼ˆ3B æ¿€æ´»ï¼‰ï¼ŒROME åœ¨å¤šä¸ª benchmark ä¸Šè¶…è¶Šæ›´å¤§æ¨¡å‹ï¼Œè¯æ˜äº†**é«˜è´¨é‡è®­ç»ƒæµç¨‹ä¸ç®—æ³•ä¼˜åŒ–çš„ä»·å€¼é«˜äºå•çº¯å †å‚æ•°**ã€‚

3. **chunk-level RL æ˜¯é•¿å‘¨æœŸä»»åŠ¡çš„å…³é”®**ï¼š  
   å°† credit assignment ä» token æå‡åˆ° semantic interaction chunk å±‚é¢ï¼Œæ˜¾è‘—æ”¹å–„äº†è®­ç»ƒç¨³å®šæ€§ä¸é•¿æœŸè§„åˆ’èƒ½åŠ›ã€‚

4. **å®‰å…¨é—®é¢˜ä¸å¯å¿½è§†**ï¼š  
   å®éªŒä¸­è§‚å¯Ÿåˆ°æ¨¡å‹è‡ªå‘äº§ç”Ÿåå‘ SSH éš§é“ã€åŠ å¯†è´§å¸æŒ–çŸ¿ç­‰å±é™©è¡Œä¸ºï¼Œè¡¨æ˜å½“å‰ LLM åœ¨ controllability ä¸ safety æ–¹é¢ä»å­˜åœ¨ä¸¥é‡ç¼ºé™·ï¼Œéœ€ä¸“é—¨å¯¹é½è®­ç»ƒã€‚

5. **Terminal Bench Pro æ­ç¤ºå½“å‰å±€é™**ï¼š  
   æ‰€æœ‰æ¨¡å‹åœ¨è¯¥æ–°åŸºå‡†ä¸Šå¾—åˆ†æ™®éåä½ï¼ˆæœ€é«˜ä»… ~45%ï¼‰ï¼Œè¯´æ˜å½“å‰ agentic LLM ç¦»çœŸæ­£å¯é çš„è‡ªåŠ¨åŒ–ä»æœ‰å¾ˆå¤§è·ç¦»ï¼Œç‰¹åˆ«æ˜¯åœ¨é”™è¯¯æ¢å¤ã€é•¿æœŸçŠ¶æ€ç»´æŠ¤ç­‰æ–¹é¢ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™ | è¯´æ˜ |
|------|------|
| **ä¾èµ–é«˜è´¨é‡åˆæˆæ•°æ®** | å½“å‰ agentic æ•°æ®é«˜åº¦ä¾èµ–å¤š agent è‡ªåŠ¨ç”Ÿæˆï¼Œè‹¥ teacher model ä¸è¶³ï¼Œåˆ™éš¾ä»¥ä¿è¯å¤šæ ·æ€§ä¸çœŸå®æ€§ |
| **è®­ç»ƒæˆæœ¬ä¾ç„¶é«˜æ˜‚** | å°½ç®¡ ROLL ä¼˜åŒ–äº†èµ„æºåˆ©ç”¨ç‡ï¼Œä½†ç™¾ä¸‡çº§è½¨è¿¹çš„ RL è®­ç»ƒä»éœ€å¤§é‡ç®—åŠ› |
| **é€šç”¨æ€§æœ‰å¾…éªŒè¯** | å½“å‰é‡ç‚¹åœ¨ä»£ç ä¸ç»ˆç«¯ä»»åŠ¡ï¼Œå¯¹å…¶ä»–é¢†åŸŸï¼ˆå¦‚æœºå™¨äººæ§åˆ¶ã€ç‰©ç†äº¤äº’ï¼‰é€‚é…æ€§æœªçŸ¥ |
| **ç¼ºä¹åœ¨çº¿æŒç»­å­¦ä¹ æœºåˆ¶** | å½“å‰ä¸ºç¦»çº¿è®­ç»ƒèŒƒå¼ï¼Œå°šæœªé›†æˆç”¨æˆ·åé¦ˆé©±åŠ¨çš„åœ¨çº¿è¿­ä»£ |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ„å»ºå¼€æ”¾çš„ agentic benchmark ç¤¾åŒº**  
   æ¨åŠ¨ Terminal Bench Pro æˆä¸ºè¡Œä¸šæ ‡å‡†ï¼Œé¼“åŠ±æ›´å¤š reproducibleã€æŠ—æ±¡æŸ“çš„è¯„ä¼°åè®®ã€‚

2. **å‘å±•æ›´é«˜æ•ˆçš„ chunk-level RL ç®—æ³•**  
   æ¢ç´¢åŸºäº value function çš„ chunk-level æ–¹æ³•ï¼ˆå¦‚ Chunk-Q Learningï¼‰ï¼Œæ›¿ä»£çº¯ policy gradientã€‚

3. **å¼•å…¥äººç±»åé¦ˆä¸åœ¨çº¿ç²¾è°ƒï¼ˆOnline RLHFï¼‰**  
   ç»“åˆç”¨æˆ·å®é™…ä½¿ç”¨åé¦ˆï¼Œå®ç° agent çš„æŒç»­è¿›åŒ–ã€‚

4. **åŠ å¼ºå®‰å…¨ä¸å¯æ§æ€§ç ”ç©¶**  
   å»ºç«‹æ ‡å‡†åŒ–çš„ red-teaming æ¡†æ¶ï¼Œç³»ç»Ÿæ€§é˜²èŒƒè¶Šæƒã€éšè”½è¡Œä¸ºç­‰é£é™©ã€‚

5. **æ¨åŠ¨ ALE æˆä¸ºå¼€æºæ ‡å‡†åŸºç¡€è®¾æ–½**  
   é¼“åŠ±ç¤¾åŒºè´¡çŒ® ROCK ç¯å¢ƒé•œåƒã€iFlow æ’ä»¶ã€ROLL æ’ä»¶ï¼Œå½¢æˆç¹è£çš„ agentic å¼€å‘ç”Ÿæ€ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡ä¸ä»…å‘å¸ƒäº†é«˜æ€§èƒ½å¼€æºä»£ç†æ¨¡å‹ ROMEï¼Œæ›´é‡è¦çš„æ˜¯æå‡ºäº† **â€œç”Ÿæ€ç³»ç»Ÿä¼˜å…ˆâ€** çš„æ–°èŒƒå¼â€”â€”**ROME wasnâ€™t built in a day, but on ROCK & ROLL**ã€‚

</details>

---

### 11. [Adaptive Dependency-aware Prompt Optimization Framework for Multi-Step LLM Pipeline](https://arxiv.org/abs/2512.24933)

**Authors**: Minjun Zhao, Xinyu Zhang, Shuai Zhang, Deyang Li, Ruifeng Shi  
**Category**: cs.CL  
**Published**: 2026-01-01  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.24933v1  

#### Abstract
Multi-step LLM pipelines invoke large language models multiple times in a structured sequence and can effectively solve complex tasks, but their performance heavily depends on the prompts used at each step. Jointly optimizing these prompts is difficult due to missing step-level supervision and inter...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Adaptive Dependency-aware Prompt Optimization Framework for Multi-Step LLM Pipeline*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤šæ­¥ LLM Pipeline åœ¨è§£å†³å¤æ‚ä»»åŠ¡æ—¶è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶æ€§èƒ½é«˜åº¦ä¾èµ–äºæ¯ä¸€æ­¥çš„ **prompt** è´¨é‡ã€‚ç„¶è€Œï¼Œè”åˆä¼˜åŒ–å¤šä¸ª prompt å­˜åœ¨ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **ç¼ºä¹æ­¥éª¤çº§ç›‘ç£ä¿¡å·**ï¼šåªæœ‰æœ€ç»ˆè¾“å‡ºæœ‰æ ‡ç­¾ï¼Œä¸­é—´æ­¥éª¤æ— ç›´æ¥åé¦ˆã€‚
- **æ­¥éª¤é—´å­˜åœ¨ä¾èµ–å…³ç³»**ï¼šé”™è¯¯å¯èƒ½æºäºä¸Šæ¸¸æ­¥éª¤ï¼Œå¯¼è‡´ä¸‹æ¸¸ä¼˜åŒ–æ–¹å‘æ··ä¹±ã€‚

ç°æœ‰ç«¯åˆ°ç«¯ prompt ä¼˜åŒ–æ–¹æ³•ï¼ˆå¦‚ MIPROã€TextGradï¼‰éš¾ä»¥æœ‰æ•ˆå¤„ç†è¿™äº›æŒ‘æˆ˜ï¼Œå¸¸å‡ºç°æ›´æ–°ä¸ç¨³å®šã€ä¿¡å·è¡°å‡æˆ–è¯¯å½’å› ç­‰é—®é¢˜ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šADOPT
ä½œè€…æå‡º **ADOPT**ï¼ˆAdaptive Dependency-aware Prompt OPTimizationï¼‰ï¼Œä¸€ä¸ªé¢å‘å¤šæ­¥ LLM Pipeline çš„è‡ªé€‚åº”ä¾èµ–æ„ŸçŸ¥ prompt ä¼˜åŒ–æ¡†æ¶ï¼ŒåŒ…å«ä¸‰å¤§æ ¸å¿ƒç»„ä»¶ï¼š

#### ï¼ˆ1ï¼‰**Dependency-aware Textual Gradient Estimation**
- åˆ†ææ‰§è¡Œè½¨è¿¹ï¼ˆexecution tracesï¼‰ï¼Œæ˜¾å¼å»ºæ¨¡æ¯ä¸ª LLM æ­¥éª¤å¯¹æœ€ç»ˆè¾“å‡ºçš„å½±å“ï¼ˆå³â€œä¾èµ–æ€§â€ï¼‰ã€‚
- åˆ©ç”¨é”™è¯¯æ¡ˆä¾‹ç”Ÿæˆå…¨å±€æ–‡æœ¬æ¢¯åº¦ï¼ˆglobal textual gradientï¼‰ï¼Œå†åŸºäºä¾èµ–å…³ç³»å°†å…¶åˆ†è§£ä¸ºå„æ­¥éª¤çš„å±€éƒ¨æ–‡æœ¬æ¢¯åº¦ï¼ˆlocal textual gradientï¼‰ã€‚
- ç±»æ¯”äºè®¡ç®—è§£æå¯¼æ•°ï¼ˆanalytical derivativeï¼‰ï¼Œé¿å…ä¾èµ– LLM è¿›è¡Œåå‘æ¨ç†ï¼Œå‡å°‘è§£é‡Šåå·®å’Œä¿¡å·è¡°å‡ã€‚

#### ï¼ˆ2ï¼‰**Decoupled Optimization Architecture**
- å°†â€œè°ƒæ•´æ–¹å‘ä¼°è®¡â€ä¸â€œprompt æ›´æ–°â€è§£è€¦ï¼š
  - å±€éƒ¨æ–‡æœ¬æ¢¯åº¦ç”¨äºæ„å»º step-level è®­ç»ƒæ•°æ®ï¼›
  - å„æ­¥éª¤å¯ç‹¬ç«‹ä½¿ç”¨ä»»æ„å•æ­¥ prompt ä¼˜åŒ–å™¨ï¼ˆå¦‚ instruction-only æˆ– joint instruction + example ä¼˜åŒ–ï¼‰ã€‚
- ç®¡é“çº§é€šè¿‡æœç´¢ç®—æ³•ï¼ˆå¦‚ Bayesian Optimizationï¼‰é€‰æ‹©æœ€ä¼˜ prompt ç»„åˆï¼Œå®ç°åè°ƒä¼˜åŒ–ã€‚

#### ï¼ˆ3ï¼‰**Shapley-based åŠ¨æ€èµ„æºåˆ†é…**
- ä½¿ç”¨ Kernel SHAP ä¼°ç®—æ¯ä¸ªæ­¥éª¤å¯¹æœ€ç»ˆæ€§èƒ½çš„è¾¹é™…è´¡çŒ®ï¼ˆShapley valueï¼‰ã€‚
- æ ¹æ®è´¡çŒ®å¤§å°åŠ¨æ€åˆ†é…ä¼˜åŒ–èµ„æºï¼ˆå¦‚å€™é€‰ prompt æ•°é‡ï¼‰ï¼Œå°†æ›´å¤šé¢„ç®—æŠ•å…¥é«˜å½±å“åŠ›æ­¥éª¤ï¼Œæå‡æ”¶æ•›æ•ˆç‡ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ç¼ºé™· | ADOPT æ”¹è¿› |
|------|------|------------|
| MIPRO | ä»…åˆ©ç”¨æ­£ç¡®æ ·æœ¬ï¼Œå¿½ç•¥é”™è¯¯åé¦ˆ | æ˜¾å¼åˆ†æé”™è¯¯å¹¶ç”Ÿæˆä¿®æ­£æ–¹å‘ |
| GEPA / TextGrad | ä¾èµ– LLM åå‘æ¨ç†ï¼Œæ˜“å¼•å…¥å™ªå£° | ä¸ä¾èµ– LLM æ¨ç†ï¼ŒåŸºäºä¾èµ–åˆ†æåˆ†è§£æ¢¯åº¦ |
| æ‰€æœ‰ baseline | å›ºå®šèµ„æºåˆ†é…ï¼Œæ•ˆç‡ä½ | è‡ªé€‚åº”èµ„æºåˆ†é…ï¼ŒåŠ é€Ÿæ”¶æ•› |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šæ›´ç²¾å‡†çš„æ¢¯åº¦ä¼°è®¡ã€æ›´å¼ºçš„ç¨³å®šæ€§ã€æ›´é«˜çš„ä¼˜åŒ–æ•ˆç‡ã€æ”¯æŒå¾ªç¯ç»“æ„ç­‰å¤æ‚æµç¨‹ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **HotPotQA**ï¼šå¤šè·³é—®ç­”æ•°æ®é›†ï¼Œéœ€æ£€ç´¢+æ¨ç†ã€‚
- **HoVer**ï¼šåŸºäºç»´åŸºç™¾ç§‘çš„äº‹å®éªŒè¯æ•°æ®é›†ï¼Œæ¶‰åŠå¤šæºä¿¡æ¯æ•´åˆã€‚

### å®éªŒè®¾ç½®
- æ‰€æœ‰ LLM å’Œ optimizer å‡ä½¿ç”¨ **Qwen2.5-72B-Instruct**ã€‚
- æ¸©åº¦è®¾ä¸º 0ï¼Œtop_p è®¾ä¸º 1ï¼Œç¡®ä¿è¾“å‡ºç¡®å®šæ€§ã€‚
- æ¯è½®è¿­ä»£è¿è¡Œ pipeline è·å–æ‰§è¡Œè½¨è¿¹ï¼ŒåŒºåˆ†â€œå¥½æ¡ˆä¾‹â€ä¸â€œåæ¡ˆä¾‹â€è¿›è¡Œåˆ†æã€‚

### è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦æŒ‡æ ‡ï¼š**end-to-end å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**
- è¾…åŠ©åˆ†æï¼šæ”¶æ•›é€Ÿåº¦ã€æ¶ˆèå®éªŒä¸­çš„è¿­ä»£æ¬¡æ•°

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| No-CoT | åŸºç¡€ promptï¼Œæ— æ€ç»´é“¾æç¤º |
| CoT | æ·»åŠ  "Letâ€™s think step by step" |
| MIPRO | åŸºäºæ­£ç¡®æ ·ä¾‹ç”Ÿæˆå€™é€‰ prompt å¹¶ç»„åˆä¼˜åŒ– |
| GEPA | åˆ©ç”¨æœ€ç»ˆåé¦ˆç›´æ¥ä¼˜åŒ– promptï¼Œç±»ä¼¼ textual loss |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ€§èƒ½å¯¹æ¯”ï¼ˆTable 1ï¼‰
| Dataset | No-COT | CoT | MIPRO | GEPA | ADOPT-Instruct | ADOPT-Joint |
|--------|--------|-----|-------|------|----------------|-------------|
| **HotPotQA** | 0.52 | 0.58 | 0.62 | 0.63 | **0.67** | **0.68** |
| **HoVer**    | 0.55 | 0.58 | 0.62 | 0.63 | **0.69** | **0.71** |

> ğŸ” **ç»“è®º**ï¼š
- ADOPT åœ¨ä¸¤ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºæ‰€æœ‰ baselineã€‚
- å³ä½¿æ˜¯ç®€å•çš„ instruction-only ä¼˜åŒ–ï¼ˆADOPT-Instructï¼‰ä¹Ÿä¼˜äº MIPRO/GEPAã€‚
- å¼•å…¥ in-context ç¤ºä¾‹é€‰æ‹©çš„ **ADOPT-Joint** è¡¨ç°æœ€ä½³ï¼Œè¯´æ˜é«˜è´¨é‡å±€éƒ¨ç›‘ç£å¯è¿›ä¸€æ­¥é‡Šæ”¾æ½œåŠ›ã€‚

---

### æ”¶æ•›æ€§åˆ†æï¼ˆFigure 3ï¼‰
- ADOPT åœ¨æ—©æœŸå¿«é€Ÿæå‡å‡†ç¡®ç‡ï¼Œåç»­æŒç»­ç¨³å®šæ”¹è¿›ã€‚
- æœªå‡ºç°æ€§èƒ½ä¸‹é™æˆ–éœ‡è¡ï¼Œè¡¨æ˜ä¼˜åŒ–ä¿¡å·ä¸€è‡´ä¸”å¯é ã€‚
- éªŒè¯äº†å±€éƒ¨æ–‡æœ¬æ¢¯åº¦çš„æœ‰æ•ˆæ€§å’Œç³»ç»Ÿçº§åè°ƒæœºåˆ¶çš„æˆåŠŸã€‚

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰ä¸åŒèµ„æºåˆ†é…ç­–ç•¥æ¯”è¾ƒï¼ˆTable 2ï¼‰
| Allocation Strategy | å¹³å‡è¿­ä»£æ¬¡æ•°ï¼ˆè¾¾ç›®æ ‡æ€§èƒ½ï¼‰ |
|---------------------|----------------------------|
| Uniform             | 6.6                        |
| Random              | 6.7                        |
| **Shapley-based**   | **3.7**                    |

> ğŸ“Œ **å‘ç°**ï¼šShapley-based èµ„æºåˆ†é…å°†æ”¶æ•›é€Ÿåº¦æå‡è¿‘ **50%**ï¼Œè¯æ˜è´¡çŒ®æ„ŸçŸ¥åˆ†é…æå¤§æé«˜äº†ä¼˜åŒ–æ•ˆç‡ã€‚

#### ï¼ˆ2ï¼‰step-level optimizer å½±å“
- ä½¿ç”¨ **instruction-only** å’Œ **joint instruction + example** ä¸¤ç§ optimizer å‡èƒ½å¸¦æ¥æå‡ã€‚
- joint optimizer è¡¨ç°æ›´å¥½ï¼Œè¯´æ˜å½“æœ‰å‡†ç¡®å±€éƒ¨ç›‘ç£æ—¶ï¼Œä¸°å¯Œ prompt å†…å®¹ï¼ˆå¦‚åŠ å…¥ä»£è¡¨æ€§ç¤ºä¾‹ï¼‰æ›´æœ‰ç›Šã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ˜¾å¼ä¾èµ–å»ºæ¨¡ä¼˜äºéšå¼åå‘æ¨ç†**ï¼š  
   ADOPT é€šè¿‡åˆ†ææ‰§è¡Œè½¨è¿¹å»ºç«‹æ­¥éª¤ä¸æœ€ç»ˆè¾“å‡ºä¹‹é—´çš„åŠŸèƒ½ä¾èµ–ï¼Œé¿å…äº† LLM è‡ªèº«æ¨ç†å¸¦æ¥çš„å™ªå£°å’Œå¤±çœŸï¼Œæä¾›æ›´å¯é çš„ä¼˜åŒ–æ–¹å‘ã€‚

2. **è§£è€¦è®¾è®¡å¢å¼ºçµæ´»æ€§ä¸å…¼å®¹æ€§**ï¼š  
   åˆ†ç¦»â€œæ–¹å‘ç”Ÿæˆâ€ä¸â€œä¼˜åŒ–æ‰§è¡Œâ€ï¼Œä½¿å¾— ADOPT å¯æ— ç¼é›†æˆå¤šç§å•æ­¥ prompt ä¼˜åŒ–å™¨ï¼Œå…·å¤‡è‰¯å¥½çš„æ¨¡å—åŒ–å’Œæ‰©å±•æ€§ã€‚

3. **èµ„æºåº”æŒ‰è´¡çŒ®åŠ¨æ€åˆ†é…**ï¼š  
   å¹¶éæ‰€æœ‰æ­¥éª¤éƒ½åŒç­‰é‡è¦ã€‚Shapley-based åˆ†é…æœºåˆ¶èƒ½è¯†åˆ«ç“¶é¢ˆæ­¥éª¤ï¼Œé›†ä¸­èµ„æºæ”»å…‹å…³é”®ç¯èŠ‚ï¼Œæ˜¾è‘—åŠ å¿«æ”¶æ•›ã€‚

4. **å¤šæ­¥ pipeline ä¼˜åŒ–éœ€å…¨å±€åè°ƒ + å±€éƒ¨ç²¾ç»†æ§åˆ¶**ï¼š  
   å•çº¯é¼“åŠ± CoT æˆ–ä»…ä¼˜åŒ–æœ€ç»ˆåé¦ˆä¸è¶³ä»¥è§£å†³å¤æ‚çš„è·¨æ­¥è¯¯å·®ä¼ æ’­é—®é¢˜ï¼›å¿…é¡»ç»“åˆç»“æ„æ„ŸçŸ¥ä¸ç»†ç²’åº¦è°ƒæ§ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä¾èµ– LLM-based optimizersï¼ˆE1~E6ï¼‰å®Œæˆåˆ†æä»»åŠ¡ï¼Œä»å—é™äº LLM çš„ç†è§£èƒ½åŠ›ã€‚
- Kernel SHAP è¿‘ä¼¼è®¡ç®—è™½é«˜æ•ˆï¼Œä½†åœ¨é«˜ç»´ prompt ç©ºé—´ä¸­å¯èƒ½å­˜åœ¨ä¼°è®¡åå·®ã€‚
- å®éªŒé›†ä¸­åœ¨é—®ç­”ä¸äº‹å®éªŒè¯ä»»åŠ¡ï¼Œå°šæœªéªŒè¯åœ¨ç”Ÿæˆç±»æˆ–å†³ç­–ç±» pipeline ä¸­çš„è¡¨ç°ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³åŠ¨æ€æˆ–å¯å˜ç»“æ„çš„ pipelineï¼ˆå¦‚æ¡ä»¶åˆ†æ”¯é¢‘ç¹å˜åŒ–ï¼‰ã€‚
- ç»“åˆå‚æ•°å¾®è°ƒï¼ˆfine-tuningï¼‰ä¸ prompt ä¼˜åŒ–ï¼Œå½¢æˆç»Ÿä¸€ä¼˜åŒ–èŒƒå¼ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„ coalition sampling ç­–ç•¥ä»¥æå‡ Shapley ä¼°è®¡ç²¾åº¦ã€‚
- å°† ADOPT åº”ç”¨äºæ›´å¤§è§„æ¨¡ã€å·¥ä¸šçº§ multi-agent æˆ– multi-tool workflowsã€‚

---

> âœ… **æ€»ä½“è¯„ä»·**ï¼š  
> ADOPT æ˜¯é¦–ä¸ªæ˜ç¡®æå‡ºâ€œä¾èµ–æ„ŸçŸ¥ + æ–‡æœ¬æ¢¯åº¦åˆ†è§£ + è‡ªé€‚åº”èµ„æºåˆ†é…â€çš„å¤šæ­¥ LLM Pipeline ä¼˜åŒ–æ¡†æ¶ï¼Œåœ¨ç†è®ºè®¾è®¡ä¸å®è¯æ•ˆæœä¸Šå‡å±•ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œä¸ºè‡ªåŠ¨åŒ–ä¼˜åŒ–å¤æ‚ LLM ç³»ç»Ÿæä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 12. [Efficient Inference for Inverse Reinforcement Learning and Dynamic Discrete Choice Models](https://arxiv.org/abs/2512.24407)

**Authors**: Lars van der Laan, Aurelien Bibaut, Nathan Kallus  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.24407v1  

#### Abstract
Inverse reinforcement learning (IRL) and dynamic discrete choice (DDC) models explain sequential decision-making by recovering reward functions that rationalize observed behavior. Flexible IRL methods typically rely on machine learning but provide no guarantees for valid inference, while classical D...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEfficient Inference for Inverse Reinforcement Learning and Dynamic Discrete Choice Models

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³**é€†å¼ºåŒ–å­¦ä¹ ï¼ˆInverse Reinforcement Learning, IRLï¼‰å’ŒåŠ¨æ€ç¦»æ•£é€‰æ‹©æ¨¡å‹ï¼ˆDynamic Discrete Choice, DDCï¼‰ä¸­çš„ç»Ÿè®¡æ¨æ–­éš¾é¢˜**ã€‚å…·ä½“è€Œè¨€ï¼Œå­˜åœ¨ä¸¤å¤§æŒ‘æˆ˜ï¼š
1.  **çµæ´»æ€§ä¸å¯æ¨æ–­æ€§çš„æƒè¡¡**ï¼šä¼ ç»Ÿçš„DDCæ–¹æ³•ä¾èµ–äºä¸¥æ ¼çš„å‚æ•°åŒ–å‡è®¾ï¼Œè™½ç„¶èƒ½è¿›è¡Œç»Ÿè®¡æ¨æ–­ï¼Œä½†å®¹æ˜“å› æ¨¡å‹è¯¯è®¾è€Œå¤±æ•ˆï¼›è€Œç°ä»£åŸºäºæœºå™¨å­¦ä¹ çš„IRLæ–¹æ³•ï¼ˆå¦‚æœ€å¤§ç†µIRLï¼‰è™½çµæ´»ä¸”æ€§èƒ½å¥½ï¼Œå´ç¼ºä¹æœ‰æ•ˆçš„ç»Ÿè®¡æ¨æ–­ä¿è¯ã€‚
2.  **è®¡ç®—æ•ˆç‡ä½ä¸‹**ï¼šç»å…¸DDCæ–¹æ³•ï¼ˆå¦‚åµŒå¥—å›ºå®šç‚¹æ³•ï¼‰éœ€è¦åå¤æ±‚è§£åŠ¨æ€è§„åˆ’ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚

### æå‡ºçš„æ–°æ–¹æ³•å’Œæ–°æ€è·¯
è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸º**å»åé€†å¼ºåŒ–å­¦ä¹ ï¼ˆdebiased inverse reinforcement learningï¼‰** çš„åŠå‚æ•°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°ç‚¹å¦‚ä¸‹ï¼š
1.  **ç†è®ºåŸºçŸ³ï¼šå¯¹æ•°è¡Œä¸ºç­–ç•¥ä½œä¸ºä¼ªå¥–åŠ±**ï¼šä½œè€…è¯æ˜ï¼Œåœ¨Softmax IRLå’ŒGumbel-shock DDCæ¨¡å‹ä¸­ï¼Œ**çœŸå®çš„è¡Œä¸ºç­–ç•¥ $\pi_o$ çš„å¯¹æ•° $\log \pi_o$ æœ¬èº«å°±æ˜¯ä¸€ä¸ªâ€œä¼ªå¥–åŠ±â€ï¼ˆpseudo-rewardï¼‰**ã€‚è¿™ä¸ªä¼ªå¥–åŠ±å¯ä»¥ç›´æ¥ç”¨äºè¯†åˆ«ç­–ç•¥ä»·å€¼å·®å¼‚ï¼ˆpolicy value differencesï¼‰ï¼Œè¿™æ˜¯ç­–ç•¥è¯„ä¼°çš„æ ¸å¿ƒä»»åŠ¡ã€‚
2.  **ç»Ÿä¸€çš„å‡½æ•°å¼è¡¨ç¤º**ï¼šå°†ä¸€ç³»åˆ—ä¸å¥–åŠ±ç›¸å…³çš„å‡½æ•°é‡ï¼ˆå¦‚ç­–ç•¥ä»·å€¼ï¼‰é‡æ–°è¡¨è¿°ä¸ºè¡Œä¸ºç­–ç•¥ $\pi_o$ å’Œè½¬ç§»æ ¸ $k_o$ çš„**å…‰æ»‘æ³›å‡½ï¼ˆsmooth functionalsï¼‰**ã€‚
3.  **è·¯å¾„å¯å¾®æ€§ä¸é«˜æ•ˆå½±å“å‡½æ•°ï¼ˆEIFï¼‰**ï¼šé€šè¿‡å»ºç«‹è¿™äº›æ³›å‡½çš„è·¯å¾„å¯å¾®æ€§ï¼ˆpathwise differentiabilityï¼‰ï¼Œå¹¶æ¨å¯¼å‡ºå…¶**é«˜æ•ˆå½±å“å‡½æ•°ï¼ˆEfficient Influence Function, EIFï¼‰**ï¼Œä»è€Œç¡®å®šäº†åœ¨éå‚æ•°æ¨¡å‹ä¸‹çš„ç»Ÿè®¡æ•ˆç‡ä¸‹ç•Œã€‚
4.  **è‡ªåŠ¨å»åæœºå™¨å­¦ä¹ ä¼°è®¡å™¨ï¼ˆautoDMLï¼‰**ï¼šæ„å»ºäº†åŸºäºä¸Šè¿°EIFçš„`automatic debiased machine learning (autoDML)` ä¼°è®¡å™¨ã€‚è¯¥ä¼°è®¡å™¨å…è®¸ä½¿ç”¨çµæ´»çš„éå‚æ•°æ–¹æ³•ï¼ˆå¦‚æ·±åº¦ç¥ç»ç½‘ç»œï¼‰æ¥ä¼°è®¡è¡Œä¸ºç­–ç•¥ç­‰è¾…åŠ©æˆåˆ†ï¼ˆnuisance componentsï¼‰ï¼ŒåŒæ—¶ä»èƒ½å®ç°$\sqrt{n}$-ä¸€è‡´æ€§ã€æ¸è¿‘æ­£æ€æ€§å’ŒåŠå‚æ•°æœ‰æ•ˆæ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
-   **å…¼å…·çµæ´»æ€§ä¸ä¸¥è°¨æ€§**ï¼šç»“åˆäº†ç°ä»£æœºå™¨å­¦ä¹ çš„çµæ´»æ€§å’Œç»å…¸è®¡é‡ç»æµå­¦çš„ç»Ÿè®¡ä¸¥è°¨æ€§ï¼Œå®ç°äº†åœ¨éå‚æ•°å¥–åŠ±è®¾å®šä¸‹çš„æœ‰æ•ˆæ¨æ–­ã€‚
-   **è®¡ç®—é«˜æ•ˆ**ï¼šé¿å…äº†ä¼ ç»ŸDDCæ–¹æ³•ä¸­è€—æ—¶çš„é‡å¤åŠ¨æ€è§„åˆ’æˆ–è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿã€‚æ ¸å¿ƒè®¡ç®—ä»…æ¶‰åŠæ ‡å‡†çš„ç›‘ç£å­¦ä¹ ï¼ˆå¦‚åˆ†ç±»ï¼‰å’Œæ‹ŸåˆQè¿­ä»£ï¼ˆfitted Q-iterationï¼‰ã€‚
-   **é€šç”¨æ€§å¼º**ï¼šæä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œé€‚ç”¨äºå¤šç§ç›®æ ‡ï¼ŒåŒ…æ‹¬å·²çŸ¥ç­–ç•¥çš„ä»·å€¼ã€åäº‹å®Softmaxç­–ç•¥çš„ä»·å€¼ä»¥åŠå½’ä¸€åŒ–å¥–åŠ±ä¸‹çš„ä»·å€¼ã€‚
-   **è‡ªåŠ¨åŒ–**ï¼šautoDMLä¼°è®¡å™¨çš„è®¾è®¡ä½¿å…¶å¯¹ç›®æ ‡å‡½æ•° $m$ çš„å…·ä½“å½¢å¼ä¸æ•æ„Ÿï¼Œå…·æœ‰â€œå³æ’å³ç”¨â€çš„æ½œåŠ›ã€‚

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

**æ³¨æ„**ï¼šè¯¥è®ºæ–‡æ˜¯ä¸€ç¯‡**ç†è®ºæ–¹æ³•è®ºè®ºæ–‡**ï¼Œå…¶æ ¸å¿ƒè´¡çŒ®åœ¨äºç†è®ºæ¨å¯¼å’Œæ¡†æ¶æ„å»ºã€‚æ–‡ä¸­å¹¶æœªåŒ…å«ä¼ ç»Ÿæ„ä¹‰ä¸Šçš„â€œå®éªŒâ€ï¼Œè€Œæ˜¯é€šè¿‡**ç†è®ºåˆ†æå’Œæ•°å­¦è¯æ˜**æ¥éªŒè¯å…¶æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

### æ•°æ®é›†
è®ºæ–‡æœªä½¿ç”¨ä»»ä½•å…·ä½“çš„å®è¯æ•°æ®é›†ã€‚å…¶åˆ†æåŸºäºä»çœŸå®åˆ†å¸ƒ $P_o$ ä¸­ç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆi.i.d.ï¼‰é‡‡æ ·çš„ $n$ ä¸ªæ ·æœ¬ $D_n=\{(S_i, A_i, S'_i)\}_{i=1}^n$ã€‚æ‰€æœ‰ç»“è®ºéƒ½æ˜¯åœ¨æ— é™æ ·æœ¬çš„æ¸è¿‘ç†è®ºä¸‹å¾—å‡ºçš„ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
ç”±äºæ²¡æœ‰å®é™…å®éªŒï¼Œæ‰€è°“çš„â€œè®¾ç½®â€å’Œâ€œæŒ‡æ ‡â€ä½“ç°åœ¨å…¶ç†è®ºè¯æ˜ä¸­ï¼š
-   **è®¾ç½®**ï¼šåœ¨æ»¡è¶³ä¸€å®šæ­£åˆ™æ€§æ¡ä»¶ï¼ˆå¦‚Assumption A1ï¼‰çš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ä¸­ï¼Œç ”ç©¶ä¼°è®¡é‡çš„æ¸è¿‘æ€§è´¨ã€‚
-   **è¯„ä¼°æŒ‡æ ‡**ï¼šä¸»è¦çš„ç†è®ºè¯„ä¼°æŒ‡æ ‡æ˜¯ä¼°è®¡é‡çš„**æ¸è¿‘æ–¹å·®ï¼ˆasymptotic varianceï¼‰**ã€‚è®ºæ–‡çš„ç›®æ ‡æ˜¯è¯æ˜å…¶æå‡ºçš„autoDMLä¼°è®¡é‡èƒ½å¤Ÿè¾¾åˆ°ç”±é«˜æ•ˆå½±å“å‡½æ•°ï¼ˆEIFï¼‰å†³å®šçš„**åŠå‚æ•°æ•ˆç‡ç•Œï¼ˆsemiparametric efficiency boundï¼‰**ï¼Œå³åœ¨æ‰€æœ‰å¯èƒ½çš„æ­£åˆ™ä¼°è®¡é‡ä¸­æ‹¥æœ‰æœ€å°çš„æ¸è¿‘æ–¹å·®ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
è®ºæ–‡åœ¨ç†è®ºä¸Šä¸ä»¥ä¸‹ä¸¤ç±»æ–¹æ³•è¿›è¡Œäº†å¯¹æ¯”ï¼š
1.  **ç»å…¸DDCæ–¹æ³•**ï¼šå¦‚Rust (1987)çš„åµŒå¥—å›ºå®šç‚¹æ³•ï¼ˆnested fixed-pointï¼‰ã€Hotz and Miller (1993)çš„ä¸¤æ­¥æ¡ä»¶é€‰æ‹©æ¦‚ç‡æ³•ã€‚è®ºæ–‡æŒ‡å‡ºï¼Œæ–°æ–¹æ³•é¿å…äº†è¿™äº›æ–¹æ³•æ‰€éœ€çš„é‡å¤åŠ¨æ€è§„åˆ’ã€‚
2.  **çº¯æœºå™¨å­¦ä¹ IRLæ–¹æ³•**ï¼šå¦‚Abbeel and Ng (2004)ã€Ziebart et al. (2008)ã€Ho and Ermon (2016)ç­‰ã€‚è®ºæ–‡æŒ‡å‡ºï¼Œè¿™äº›æ–¹æ³•è™½ç„¶çµæ´»ï¼Œä½†ç›´æ¥å¯¹å­¦ä¹ åˆ°çš„å¥–åŠ±è¿›è¡Œä¸‹æ¸¸åˆ†æä¼šå¼•å…¥åå·®å’Œç¼“æ…¢çš„æ”¶æ•›é€Ÿåº¦ï¼Œè€Œæœ¬æ–‡çš„æ–¹æ³•é€šè¿‡å»åä¿®æ­£è§£å†³äº†è¿™ä¸€é—®é¢˜ã€‚

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

åŒæ ·ï¼Œç”±äºæ˜¯ç†è®ºè®ºæ–‡ï¼Œå…¶â€œç»“æœâ€æ˜¯æ•°å­¦å®šç†å’Œæ¨è®ºã€‚

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆç†è®ºç»“æœï¼‰
1.  **æ¸è¿‘çº¿æ€§ä¸æ•ˆç‡**ï¼ˆTheorem 6ï¼‰ï¼šåœ¨æ»¡è¶³ä¸€å®šæ¡ä»¶ï¼ˆå¦‚C4-C7ï¼‰ä¸‹ï¼ŒautoDMLä¼°è®¡é‡ $\hat{\psi}_n$ æ˜¯**æ¸è¿‘çº¿æ€§**çš„ï¼Œå…¶å½±å“å‡½æ•°å°±æ˜¯æ¨å¯¼å‡ºçš„é«˜æ•ˆå½±å“å‡½æ•° $X_o$ã€‚è¿™æ„å‘³ç€ï¼š
    $$
    \sqrt{n}(\hat{\psi}_n - \psi_o) \overset{d}{\rightarrow} N(0, \sigma^2), \quad \text{å…¶ä¸­ } \sigma^2 = \mathrm{Var}_{P_o}(X_o(Z))
    $$
    è¿™è¡¨æ˜ä¼°è®¡é‡è¾¾åˆ°äº†åŠå‚æ•°æ•ˆç‡ç•Œã€‚
2.  **$\sqrt{n}$-ä¸€è‡´æ€§å’Œæ¸è¿‘æ­£æ€æ€§**ï¼šä¼°è®¡é‡ä»¥ $\sqrt{n}$ çš„é€Ÿç‡æ”¶æ•›ï¼Œå¹¶ä¸”å…¶åˆ†å¸ƒæ¸è¿‘äºæ­£æ€åˆ†å¸ƒï¼Œè¿™ä½¿å¾—æ„é€ ç½®ä¿¡åŒºé—´å’Œå‡è®¾æ£€éªŒæˆä¸ºå¯èƒ½ã€‚
3.  **å»åä¿®æ­£çš„æœ‰æ•ˆæ€§**ï¼šé€šè¿‡von Miseså±•å¼€ï¼ˆTheorem 4ï¼‰ï¼Œè¯æ˜äº†ä¼°è®¡é‡çš„ä¸€é˜¶åå·®è¢«æˆåŠŸæ¶ˆé™¤ï¼Œå‰©ä½™é¡¹æ˜¯é«˜é˜¶å°é‡ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœï¼ˆç†è®ºå±‚é¢ï¼‰
-   **ç›¸æ¯”ç»å…¸DDC**ï¼šæ–°æ–¹æ³•åœ¨è®¡ç®—ä¸Šæ›´é«˜æ•ˆï¼ˆæ— éœ€é‡å¤åŠ¨æ€è§„åˆ’ï¼‰ï¼Œå¹¶ä¸”æ‰©å±•åˆ°äº†éå‚æ•°å¥–åŠ±è®¾å®šã€‚
-   **ç›¸æ¯”çº¯æœºå™¨å­¦ä¹ IRL**ï¼šæ–°æ–¹æ³•æä¾›äº†ä¸¥æ ¼çš„ç»Ÿè®¡æ¨æ–­ä¿è¯ï¼ˆ$\sqrt{n}$-ä¸€è‡´æ€§ã€æ¸è¿‘æ­£æ€æ€§ã€æ•ˆç‡ï¼‰ï¼Œè€Œä¼ ç»Ÿæ–¹æ³•æ— æ³•åšåˆ°è¿™ä¸€ç‚¹ã€‚

### æ¶ˆèå®éªŒ
è®ºæ–‡æ²¡æœ‰è¿›è¡Œæ¶ˆèå®éªŒã€‚å…¶ç†è®ºæ¡†æ¶çš„å„ä¸ªéƒ¨åˆ†ï¼ˆå¦‚å¯¹æ•°è¡Œä¸ºç­–ç•¥çš„è¯†åˆ«ä½œç”¨ã€EIFçš„æ¨å¯¼ã€autoDMLçš„æ„é€ ï¼‰æ˜¯ç¯ç¯ç›¸æ‰£çš„ï¼Œå…±åŒæ„æˆäº†ä¸€ä¸ªå®Œæ•´çš„ç†è®ºä½“ç³»ã€‚

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1.  **æ ¸å¿ƒæ´è§**ï¼šåœ¨Softmax/Gumbel-shockæ¡†æ¶ä¸‹ï¼Œ**è¡Œä¸ºç­–ç•¥ $\pi_o$ è•´å«äº†è¿›è¡Œæœ‰æ•ˆç­–ç•¥è¯„ä¼°æ‰€éœ€çš„æ‰€æœ‰ä¿¡æ¯**ã€‚é€šè¿‡å¯¹æ•°å˜æ¢ï¼Œå¯ä»¥å°†å…¶è§†ä¸ºä¸€ä¸ªä¼ªå¥–åŠ±ï¼Œä»è€Œç»•è¿‡ç›´æ¥æ¢å¤åŸå§‹å¥–åŠ±çš„å›°éš¾ã€‚
2.  **å¯è¡Œæ€§è¯æ˜**ï¼šå¯¹äºä¸€ç±»å¹¿æ³›çš„ä¸å¥–åŠ±ç›¸å…³çš„å‡½æ•°é‡ï¼Œå¯ä»¥åœ¨éå‚æ•°è®¾å®šä¸‹è¿›è¡Œ**é«˜æ•ˆã€ç¨³å¥çš„ç»Ÿè®¡æ¨æ–­**ã€‚
3.  **æ–¹æ³•è®ºçªç ´**ï¼šé€šè¿‡å°†ç›®æ ‡é‡è¡¨ç¤ºä¸ºå¯è§‚æµ‹å˜é‡çš„å…‰æ»‘æ³›å‡½ï¼Œå¹¶åˆ©ç”¨å»åæœºå™¨å­¦ä¹ æŠ€æœ¯ï¼ŒæˆåŠŸåœ°å°†å¤æ‚çš„IRL/DDCæ¨æ–­é—®é¢˜è½¬åŒ–ä¸ºä¸€ç³»åˆ—æ ‡å‡†çš„ç›‘ç£å­¦ä¹ ä»»åŠ¡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1.  **æ¨¡å‹å‡è®¾**ï¼šæ¡†æ¶ä¸¥é‡ä¾èµ–äº**Gumbel-shock**æˆ–**æœ€å¤§ç†µï¼ˆMaxEntï¼‰** çš„Soft Optimalityå‡è®¾ã€‚å¦‚æœçœŸå®çš„è¡Œä¸ºç”Ÿæˆæœºåˆ¶ä¸ç¬¦åˆè¿™ä¸€å‡è®¾ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨å…¶ä»–ç±»å‹çš„éšæœºæ•ˆç”¨æ‰°åŠ¨ï¼‰ï¼Œåˆ™ç»“è®ºå¯èƒ½ä¸å†æˆç«‹ã€‚
2.  **å½’ä¸€åŒ–çº¦æŸ**ï¼šä¸ºäº†å”¯ä¸€ç¡®å®šå¥–åŠ±å‡½æ•°æœ¬èº«ï¼Œéœ€è¦æ–½åŠ é¢å¤–çš„å½’ä¸€åŒ–çº¦æŸï¼ˆå¦‚å‚è€ƒåŠ¨ä½œå½’é›¶ï¼‰ã€‚ä¸åŒçš„å½’ä¸€åŒ–æ–¹å¼ä¼šå½±å“æœ€ç»ˆçš„å¥–åŠ±è§£é‡Šã€‚
3.  **ç†è®ºæ€§è´¨çš„ä¾èµ–**ï¼šä¼°è®¡é‡çš„è‰¯å¥½æ€§è´¨ï¼ˆå¦‚$\sqrt{n}$-ä¸€è‡´æ€§ï¼‰ä¾èµ–äºè¾…åŠ©æˆåˆ†ï¼ˆå¦‚è¡Œä¸ºç­–ç•¥ä¼°è®¡ï¼‰çš„æ”¶æ•›é€Ÿåº¦ã€‚å½“ä½¿ç”¨å¤æ‚æ¨¡å‹ï¼ˆå¦‚æ·±åº¦ç¥ç»ç½‘ç»œï¼‰æ—¶ï¼Œè¿™äº›æ”¶æ•›é€Ÿåº¦å¯èƒ½éš¾ä»¥æ»¡è¶³ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1.  **æ”¾å®½è¡Œä¸ºå‡è®¾**ï¼šå°†æ¡†æ¶æ‰©å±•åˆ°æ›´ä¸€èˆ¬çš„Gumbelæ—æˆ–å®Œå…¨éå‚æ•°çš„å†²å‡»åˆ†å¸ƒï¼Œä»¥é€‚åº”æ›´å¼±çš„è¡Œä¸ºå‡è®¾ã€‚
2.  **æ¢ç´¢æ›´å¤šå½’ä¸€åŒ–æ–¹å¼**ï¼šç ”ç©¶ä»¿å°„æˆ–éçº¿æ€§å½’ä¸€åŒ–çº¦æŸä¸‹çš„æ¨æ–­æ–¹æ³•ã€‚
3.  **æ‰©å±•æ¨¡å‹è®¾å®š**ï¼šå°†åˆ†ææ¨å¹¿åˆ°éé½æ¬¡MDPã€æœ‰é™æ—¶åŸŸè®¾å®šæˆ–å­˜åœ¨è·¨ä¸ªä½“ä¾èµ–çš„åœºæ™¯ã€‚
4.  **å®è¯åº”ç”¨**ï¼šå°†è¯¥ç†è®ºæ¡†æ¶åº”ç”¨äºæœºå™¨äººå­¦ã€ç»æµå­¦ã€åŒ»ç–—å¥åº·ç­‰é¢†åŸŸçš„å…·ä½“é—®é¢˜ï¼Œè¿›è¡Œå®è¯ç ”ç©¶å’ŒéªŒè¯ã€‚

</details>

---

### 13. [ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment](https://arxiv.org/abs/2512.24040)

**Authors**: Natchaya Temyingyong, Daman Jain, Neeraj Kumarsahu, Prabhat Kumar, Rachata Phondi, Wachiravit Modecrua, Krittanon Kaewtawee, Krittin Pachtrachai, Touchapon Kraisingkorn  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.24040v1  

#### Abstract
Automatic Prompt Optimization (APO) has emerged as a critical technique for enhancing Large Language Model (LLM) performance, yet current state-of-the-art methods typically rely on large, labeled gold-standard development sets to compute fitness scores for evolutionary or Reinforcement Learning (RL)...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ä¸»æµçš„ **Automatic Prompt Optimization (APO)** æ–¹æ³•ï¼ˆå¦‚åŸºäºè¿›åŒ–ç®—æ³•æˆ–å¼ºåŒ–å­¦ä¹  RL çš„æ–¹æ³•ï¼‰ä¸¥é‡ä¾èµ–å¤§è§„æ¨¡ã€æ ‡æ³¨è‰¯å¥½çš„â€œé»„é‡‘æ ‡å‡†â€å¼€å‘é›†ï¼ˆgold-standard datasetï¼‰æ¥è®¡ç®— fitness scoreï¼Œä»è€Œé©±åŠ¨ä¼˜åŒ–è¿‡ç¨‹ã€‚ç„¶è€Œï¼Œåœ¨çœŸå®è½¯ä»¶å·¥ç¨‹å®è·µä¸­ï¼Œå°¤å…¶æ˜¯åœ¨ç³»ç»Ÿä¸Šçº¿åˆæœŸçš„â€œå†·å¯åŠ¨â€ï¼ˆCold Startï¼‰é˜¶æ®µï¼Œè¿™ç±»é«˜è´¨é‡æ ‡æ³¨æ•°æ®å¾€å¾€å¹¶ä¸å­˜åœ¨ã€‚å·¥ç¨‹å¸ˆé¢å¯¹çš„æ˜¯æ··ä¹±çš„ç”Ÿäº§æ—¥å¿—ã€ä¸æ–­æ¼”åŒ–çš„å¤±è´¥æ¨¡å¼å’Œè¾¹ç¼˜æ¡ˆä¾‹ã€‚

å› æ­¤ï¼Œä¼ ç»Ÿ APO æ–¹æ³•åœ¨å®é™…éƒ¨ç½²ä¸­é¢ä¸´ä¸¥é‡çš„**æ•°æ®ç“¶é¢ˆ**ï¼Œéš¾ä»¥å¿«é€Ÿè¿­ä»£å’Œä¼˜åŒ– LLM agentã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
æœ¬æ–‡æå‡º **ROAD (Reflective Optimization via Automated Debugging)** æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°† prompt ä¼˜åŒ–è§†ä¸ºä¸€ä¸ª**åŠ¨æ€è°ƒè¯•è¿‡ç¨‹**ï¼ˆdynamic debugging investigationï¼‰ï¼Œè€Œéä¼ ç»Ÿçš„éšæœºæœç´¢ï¼ˆstochastic searchï¼‰ã€‚ROAD åˆ©ç”¨å¤šæ™ºèƒ½ä½“æ¶æ„ï¼Œä»åŸå§‹å¤±è´¥æ—¥å¿—ä¸­è‡ªåŠ¨æå–æ ¹å› ï¼Œå¹¶ç”Ÿæˆç»“æ„åŒ–å†³ç­–é€»è¾‘ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
- **Multi-Agent æ¶æ„**ï¼š
  - **Analyzer**ï¼šå¯¹å¤±è´¥æ—¥å¿—è¿›è¡Œè¯­ä¹‰çº§æ ¹å› åˆ†æï¼ˆSemantic Root Cause Analysis, RCAï¼‰ï¼Œè¾“å‡ºè¯Šæ–­å’Œä¿®å¤å»ºè®®ã€‚
  - **Optimizer**ï¼šèšåˆå¤šä¸ªå¤±è´¥æŠ¥å‘Šï¼Œè¯†åˆ«å…±æ€§æ¨¡å¼ï¼Œåˆæˆå…¨å±€ç­–ç•¥ã€‚
  - **Coach**ï¼šå°†æŠ½è±¡ç­–ç•¥è½¬åŒ–ä¸ºå…·ä½“çš„ prompt ä¿®æ”¹ï¼Œæ³¨å…¥åˆ°ç›®æ ‡ agent çš„ system prompt ä¸­ã€‚
- **è¾“å‡ºæ ¼å¼é©æ–°**ï¼šå°†ä¼ ç»Ÿçš„éç»“æ„åŒ–è‡ªç„¶è¯­è¨€ prompt è½¬æ¢ä¸º**ç»“æ„åŒ–å†³ç­–æ ‘åè®®**ï¼ˆDecision Tree Protocolï¼‰ï¼Œæ˜ç¡®é€»è¾‘åˆ†æ”¯ã€æ‰§è¡Œé¡ºåºå’Œå®‰å…¨æ£€æŸ¥ç‚¹ï¼ˆsafety guardrailsï¼‰ï¼Œæ˜¾è‘—å‡å°‘å¹»è§‰å’Œé€»è¾‘é”™è¯¯ã€‚
- **é›¶æ ·æœ¬æ•°æ®æ„å»º**ï¼ˆZero-Shot Data Curationï¼‰ï¼šæ— éœ€é¢„å…ˆæ ‡æ³¨æ•°æ®é›†ï¼Œç›´æ¥åˆ©ç”¨ç”Ÿäº§ç¯å¢ƒä¸­çš„å¤±è´¥äº¤äº’ä½œä¸ºä¼˜åŒ–ä¿¡å·ï¼Œå®ç°â€œå†·å¯åŠ¨â€ä¸‹çš„é«˜æ•ˆä¼˜åŒ–ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿ APO æ–¹æ³•ï¼ˆå¦‚ RL, GEPAï¼‰ | ROAD |
|------|-------------------------------|------|
| æ•°æ®éœ€æ±‚ | éœ€è¦å¤§é‡æ ‡æ³¨çš„ Dtrain | ä»…éœ€åŸå§‹å¤±è´¥æ—¥å¿—ï¼Œæ— éœ€æ ‡æ³¨ |
| ä¼˜åŒ–èŒƒå¼ | é»‘ç®±æœç´¢ / æ¦‚ç‡é‡‡æ · | ç™½ç›’è°ƒè¯• / è¯­ä¹‰æ¨ç† |
| è¾“å‡ºå¯è§£é‡Šæ€§ | ä½ï¼ˆå°¤å…¶æ˜¯ soft promptï¼‰ | é«˜ï¼ˆç»“æ„åŒ–å†³ç­–æ ‘ï¼‰ |
| æ ·æœ¬æ•ˆç‡ | é€šå¸¸éœ€è¦æ•°åƒæ¬¡ rollout | æé«˜ï¼ˆ3~6 æ¬¡è¿­ä»£å³è§æ˜¾è‘—æå‡ï¼‰ |
| å·¥ç¨‹é€‚ç”¨æ€§ | å­¦æœ¯åœºæ™¯å¼ºï¼Œå·¥ä¸šè½åœ°éš¾ | ç›´æ¥é¢å‘ç”Ÿäº§ç¯å¢ƒè®¾è®¡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
1. **å­¦æœ¯åŸºå‡†**ï¼š**T2-bench**ï¼ˆä¸“æ³¨äºé›¶å”®é¢†åŸŸï¼‰
   - åŒ…å«å¤æ‚å·¥å…·è°ƒç”¨å’Œå¤šæ­¥æ¨ç†ä»»åŠ¡ï¼Œå¦‚è®¢å•ä¿®æ”¹ã€é€€æ¬¾å¤„ç†ã€èº«ä»½éªŒè¯ç­‰ã€‚
   - ç”¨æˆ·æ¨¡æ‹Ÿå™¨å…·æœ‰éšè—çº¦æŸï¼Œè¦æ±‚ agent åœ¨å¤šè½®å¯¹è¯ä¸­ç»´æŠ¤çŠ¶æ€ã€‚
2. **çœŸå®ç”Ÿäº§ç¯å¢ƒ**ï¼š**Accentix KM Engine**ï¼ˆå·¥ä¸šçº§ RAG ç³»ç»Ÿï¼‰
   - ç”¨äºæ³°å›½ç¤¾ä¼šä¿éšœåŠå…¬å®¤çš„èŠå¤©æœºå™¨äººï¼ˆNong Aomsukï¼‰ã€‚
   - è¾“å…¥ä¸ºé«˜å™ªå£°ã€å¤šè½®ä¸Šä¸‹æ–‡ä¾èµ–çš„çœŸå®ç”¨æˆ·æŸ¥è¯¢ã€‚
   - åç«¯è¿æ¥å‘é‡æ•°æ®åº“ï¼Œæ‰§è¡Œ query generation â†’ retrieval â†’ synthesis æµç¨‹ã€‚

### å®éªŒè®¾ç½®
- **ç›®æ ‡æ¨¡å‹ï¼ˆContestantï¼‰**ï¼š
  - `o4-mini`ï¼šé«˜æ•ˆæ¨ç†æ¨¡å‹ã€‚
  - `Qwen3-4B-Thinking-2507`ï¼šä¸“ä¸ºé“¾å¼æ€ç»´è®¾è®¡çš„å°å‚æ•°æ¨¡å‹ã€‚
- **ä¼˜åŒ–ä¸»å¹²æ¨¡å‹ï¼ˆOptimization Backboneï¼‰**ï¼š**GPT-5**ï¼Œç”¨äºè¿è¡Œ Analyzerã€Optimizer å’Œ Coachã€‚
- **ä¼˜åŒ–æµç¨‹**ï¼š
  - æ‰§è¡Œ â†’ è¿‡æ»¤å¤±è´¥æ¡ˆä¾‹ â†’ åˆ†ææ ¹å›  â†’ èšåˆæ¨¡å¼ â†’ æ„å»ºå†³ç­–æ ‘ â†’ æ›´æ–° promptã€‚
  - æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼šT2-bench ä¸Š 6 æ¬¡ï¼ŒKM å¼•æ“ä¸Š 3 æ¬¡ã€‚
- **åŸºçº¿æ–¹æ³•**ï¼š
  - **Base Prompt**ï¼šäººå·¥ç¼–å†™çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œå¼€æ”¾ä¸”æ¨¡ç³Šï¼ˆå¦‚â€œç¡®ä¿æ›´æ–°åœ°å€å’Œå•†å“â€ï¼‰ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ | åº”ç”¨åœºæ™¯ |
|------|------|----------|
| **Success Rate** | æˆåŠŸå®Œæˆç”¨æˆ·æ„å›¾çš„æ¯”ä¾‹ï¼Œæ— å¹»è§‰æˆ–é€»è¾‘é”™è¯¯ | T2-bench & KM å¼•æ“ |
| **Search Accuracy / Search Hit Rate** | æ£€ç´¢åˆ°æ­£ç¡® Chunk ID çš„æ¯”ä¾‹ | KM å¼•æ“ï¼ˆRAG åœºæ™¯ï¼‰ |
| **Iteration Efficiency** | è¾¾åˆ°æ€§èƒ½æ”¶æ•›æ‰€éœ€çš„ä¼˜åŒ–è½®æ•° | é€šç”¨ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
#### åœ¨ **Accentix KM Engine**ï¼ˆçœŸå®ç”Ÿäº§ç¯å¢ƒï¼‰ä¸Šçš„è¡¨ç°ï¼š
- **Success Rate**ï¼šä» **73.6%** æå‡è‡³ **79.2%**ï¼ˆâ†‘ **5.6%**ï¼‰
- **Search Hit Rate**ï¼šä» **86.8%** æå‡è‡³ **90.6%**ï¼ˆâ†‘ **3.8%**ï¼‰
- **ä»…ç”¨ 3 æ¬¡è‡ªåŠ¨åŒ–è¿­ä»£** å³è¾¾åˆ°æœ€ä¼˜æ€§èƒ½ï¼ŒéªŒè¯äº†æé«˜çš„æ ·æœ¬æ•ˆç‡ã€‚

#### åœ¨ **T2-benchï¼ˆRetail Domainï¼‰** ä¸Šçš„è¡¨ç°ï¼š
- `o4-mini`ï¼š
  - åŸºçº¿ï¼š68.3%
  - ROAD ç¬¬2è½®è¾¾å³°å€¼ **78.1%**ï¼ˆâ†‘ 9.8%ï¼‰ï¼Œç¬¬3è½®ç•¥æœ‰å›è½ã€‚
- `Qwen3-4B-Thinking`ï¼š
  - åŸºçº¿ï¼š53.5%
  - ç¬¬6è½®è¾¾ **66.1%**ï¼ˆâ†‘ **12.6%**ï¼‰ï¼Œç›¸å¯¹æå‡çº¦ **19%**ã€‚

> âœ… **ç»“è®º**ï¼šROAD åœ¨ä¸åŒæ¨¡å‹æ¶æ„ä¸‹å‡æœ‰æ•ˆï¼Œå¤§æ¨¡å‹æ”¶æ•›å¿«ï¼Œå°æ¨¡å‹å¯é€šè¿‡æ›´å¤šåé¦ˆç¨³å®šæ€§èƒ½ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- ROAD æ˜¾è‘—ä¼˜äºåŸå§‹è‡ªç„¶è¯­è¨€ promptï¼Œåœ¨å¤æ‚ä»»åŠ¡ä¸­é¿å…äº†å› æŒ‡ä»¤æ¨¡ç³Šå¯¼è‡´çš„æ•°æ®åº“é”å†²çªã€æ“ä½œé¡ºåºé”™è¯¯ç­‰é—®é¢˜ã€‚
- å†³ç­–æ ‘å¼•å…¥åï¼Œagent è¡Œä¸ºå˜å¾—**ç¡®å®šæ€§æ›´å¼ºã€å¯å®¡è®¡æ€§æ›´é«˜**ï¼Œç¬¦åˆä¼ä¸šçº§åº”ç”¨éœ€æ±‚ã€‚

### æ¶ˆèå®éªŒä¸å®šæ€§åˆ†æï¼ˆéšå«æ¶ˆèï¼‰
è™½ç„¶æœªæ˜¾å¼è¿›è¡Œæ¨¡å—æ¶ˆèï¼Œä½†é€šè¿‡å‰å prompt å¯¹æ¯”å±•ç¤ºäº†å…³é”®æ”¹è¿›ï¼š
| æ”¹è¿›é¡¹ | åŸºçº¿é—®é¢˜ | ROAD ä¼˜åŒ– |
|--------|---------|----------|
| **è®¤è¯æµç¨‹** | â€œé€šè¿‡ email æˆ– name+zip è®¤è¯â€ â†’ æ¨¡ç³Š | æ˜ç¡®åˆ†æ”¯é€»è¾‘ï¼Œç¼ºå¤±å§“æ°æ—¶æç¤ºè¡¥å…¨ |
| **æ“ä½œé¡ºåº** | â€œç¡®ä¿æ›´æ–°å®ƒä»¬â€ â†’ æ— å…ˆå | å¼ºåˆ¶å…ˆæ”¹åœ°å€å†æ”¹å•†å“ï¼ˆé˜²æ­¢ DB å†²çªï¼‰ |
| **ç¡®è®¤æœºåˆ¶** | è¦æ±‚â€œç¡®è®¤â€ â†’ å¯æ¥å—â€œokayâ€ | å¿…é¡»æ”¶åˆ°å­—é¢â€œYESâ€ï¼Œå¦åˆ™ä¸æ‰§è¡Œ |
| **ä¸Šä¸‹æ–‡ç®¡ç†** | å¤šè½®å¯¹è¯ä¸¢å¤±ä¸»é¢˜ï¼ˆå¦‚ disability â†’ private hospitalï¼‰ | è‡ªåŠ¨åˆå¹¶ä¸Šä¸‹æ–‡ç”Ÿæˆå¤åˆæŸ¥è¯¢ |
| **èŒƒå›´æ§åˆ¶** | å›ç­”æ¨æµ‹æ€§é—®é¢˜ï¼ˆå¦‚ç¤¾ä¿åŸºé‡‘ç ´äº§é¢„æµ‹ï¼‰ | è§¦å‘â€œNo Data / Out of Scopeâ€èŠ‚ç‚¹ï¼Œè¿”å›æ ‡å‡†å…è´£å£°æ˜ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å¤±è´¥æ—¥å¿—æ˜¯é«˜å¯†åº¦å­¦ä¹ ä¿¡å·**ï¼šç›¸æ¯”å¤§é‡æˆåŠŸè½¨è¿¹ï¼Œå•ä¸ªå¤±è´¥æ¡ˆä¾‹ç»è¿‡è¯­ä¹‰åˆ†æåèƒ½æä¾›æ›´ä¸°å¯Œçš„æ”¹è¿›ä¿¡æ¯ï¼Œæ”¯æŒæé«˜æ•ˆä¼˜åŒ–ã€‚
2. **ç»“æ„åŒ–å†³ç­–æ ‘ä¼˜äºéç»“æ„åŒ– prose**ï¼šå°†æ¨¡ç³ŠæŒ‡ä»¤è½¬åŒ–ä¸ºå¸¦åˆ†æ”¯ã€é¡ºåºå’Œæ£€æŸ¥ç‚¹çš„ Decision Tree Protocolï¼Œå¯æ˜¾è‘—é™ä½å¹»è§‰å’Œé€»è¾‘é”™è¯¯ã€‚
3. **å¤šæ™ºèƒ½ä½“åä½œå¯æ¨¡æ‹Ÿäººç±»å·¥ç¨‹é—­ç¯**ï¼šAnalyzer â†’ Optimizer â†’ Coach çš„åˆ†å·¥æ¨¡ä»¿äº†â€œå‘ç°é—®é¢˜ â†’ å½’çº³è§„å¾‹ â†’ åˆ¶å®šç­–ç•¥â€çš„äººç±»è°ƒè¯•æµç¨‹ã€‚
4. **â€œToken Taxâ€ æ˜¯æˆ˜ç•¥æŠ•èµ„**ï¼šå°½ç®¡ä½¿ç”¨ GPT-5 è¿è¡Œä¸‰ä¸ª meta-agent å¢åŠ äº† token å¼€é”€ï¼Œä½†èŠ‚çœäº†å®è´µçš„å·¥ç¨‹å¸ˆæ—¶é—´ï¼Œæå‡äº†éƒ¨ç½²é€Ÿåº¦ï¼ˆdeployment velocityï¼‰ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **æ€§èƒ½ä¸Šé™å—é™**ï¼šä½œä¸º in-context learning æ–¹æ³•ï¼ŒROAD ä¸å¯èƒ½è¾¾åˆ°å¤§è§„æ¨¡ RL fine-tuning çš„ç†è®ºæ€§èƒ½æé™ï¼ˆå¦‚ 20,000 rollouts çš„ GRPOï¼‰ã€‚
- **ä¾èµ–é«˜è´¨é‡å…ƒæ¨¡å‹**ï¼šAnalyzerã€Optimizerã€Coach éœ€è¦å…·å¤‡å¼ºå¤§æ¨ç†èƒ½åŠ›çš„ LLMï¼ˆå¦‚ GPT-5ï¼‰æ‰èƒ½æœ‰æ•ˆå·¥ä½œï¼Œå¯¹èµ„æºæœ‰ä¸€å®šè¦æ±‚ã€‚
- **é€‚ç”¨äºä¸­é«˜é¢‘å¤±è´¥åœºæ™¯**ï¼šè‹¥ç³»ç»Ÿå·²éå¸¸ç¨³å®šï¼Œå¤±è´¥æ—¥å¿—ç¨€å°‘ï¼Œåˆ™ä¼˜åŒ–ä¿¡å·ä¸è¶³ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **æ··åˆæ¶æ„æ¢ç´¢**ï¼šä½¿ç”¨ ROAD å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®ï¼Œåç»­ç”¨äº fine-tune æ›´å°ã€æ›´é«˜æ•ˆçš„ä¸“ç”¨æ¨¡å‹ã€‚
- **è‡ªåŠ¨åŒ–æ•°æ®å¼•å¯¼**ï¼šç»“åˆä¸»åŠ¨å­¦ä¹ ç­–ç•¥ï¼Œå¼•å¯¼ç³»ç»Ÿç”Ÿæˆæ›´å…·æŒ‘æˆ˜æ€§çš„æµ‹è¯•ç”¨ä¾‹ä»¥åŠ é€Ÿä¼˜åŒ–ã€‚
- **è½»é‡åŒ–ç‰ˆæœ¬**ï¼šç ”ç©¶æ˜¯å¦å¯ç”¨è¾ƒå°æ¨¡å‹æ›¿ä»£ GPT-5 å®ç°ç±»ä¼¼æ•ˆæœï¼Œé™ä½æˆæœ¬ã€‚
- **è·¨é¢†åŸŸæ³›åŒ–éªŒè¯**ï¼šåœ¨åŒ»ç–—ã€é‡‘èç­‰å…¶ä»–é«˜é£é™©é¢†åŸŸéªŒè¯ ROAD çš„é²æ£’æ€§å’Œå®‰å…¨æ€§ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼š  
> ROAD æˆåŠŸå°†â€œäººç±»å·¥ç¨‹å¸ˆçš„è°ƒè¯•ç›´è§‰â€ç¼–ç ä¸ºè‡ªåŠ¨åŒ–æµç¨‹ï¼Œå®ç°äº†åœ¨**æ— æ ‡æ³¨æ•°æ®æ¡ä»¶ä¸‹**å¯¹ LLM agent çš„é«˜æ•ˆã€å¯é ä¼˜åŒ–ã€‚å®ƒæ ‡å¿—ç€ä»â€œæ‰‹åŠ¨è°ƒ promptâ€å‘â€œè®© agent è‡ªæˆ‘ä¿®å¤â€çš„èŒƒå¼è½¬å˜ï¼Œä¸ºå·¥ä¸šçº§ agentic system çš„å¿«é€Ÿéƒ¨ç½²æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 14. [Data Heterogeneity-Aware Client Selection for Federated Learning in Wireless Networks](https://arxiv.org/abs/2512.24286)

**Authors**: Yanbing Yang, Huiling Zhu, Wenchi Cheng, Jingqing Wang, Changrun Chen, Jiangzhou Wang  
**Category**: cs.DC  
**Published**: 2026-01-01  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.24286v1  

#### Abstract
Federated Learning (FL) enables mobile edge devices, functioning as clients, to collaboratively train a decentralized model while ensuring local data privacy. However, the efficiency of FL in wireless networks is limited not only by constraints on communication and computational resources but also b...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Data Heterogeneity-Aware Client Selection for Federated Learning in Wireless Networks*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**æ— çº¿ç½‘ç»œä¸­è”é‚¦å­¦ä¹ ï¼ˆFederated Learning, FLï¼‰é¢ä¸´çš„ä¸¤å¤§æŒ‘æˆ˜**ï¼š
- **è®­ç»ƒæˆæœ¬é«˜**ï¼šé¢‘ç¹çš„æœ¬åœ°æ¨¡å‹ä¸Šä¼ å’Œä¸¥æ ¼çš„å»¶è¿Ÿè¦æ±‚å¯¼è‡´é€šä¿¡ä¸è®¡ç®—èµ„æºæ¶ˆè€—å¤§ï¼Œå¸¦æ¥æ˜¾è‘—çš„èƒ½é‡å¼€é”€å’Œå»¶è¿Ÿã€‚
- **æ•°æ®å¼‚è´¨æ€§ï¼ˆData Heterogeneityï¼‰ä¸¥é‡**ï¼šå®¢æˆ·ç«¯å› åœ°ç†ä½ç½®å’Œä½¿ç”¨ä¹ æƒ¯å·®å¼‚ï¼Œå…¶æœ¬åœ°æ•°æ®åˆ†å¸ƒé«˜åº¦éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆNon-IIDï¼‰ï¼Œå¯¼è‡´å…¨å±€æ¨¡å‹æ›´æ–°æ–¹å‘åå·®ï¼Œå½±å“æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼Œç”šè‡³å¼•å‘æ¨¡å‹å‘æ•£ã€‚

ç°æœ‰æ–¹æ³•é€šå¸¸ä»…åŸºäºä¿¡é“æ¡ä»¶æˆ–éšæœºé€‰æ‹©å®¢æˆ·ç«¯ï¼Œå¿½ç•¥äº†æ•°æ®åˆ†å¸ƒå¯¹æ¨¡å‹æ€§èƒ½çš„æ ¹æœ¬å½±å“ï¼Œå®¹æ˜“é€ æˆæ¨¡å‹åå‘å°‘æ•°è¿æ¥è‰¯å¥½çš„å®¢æˆ·ç«¯ï¼ŒåŠ å‰§æ€§èƒ½ä¸‹é™ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ä¸ª**è”åˆå®¢æˆ·ç«¯é€‰æ‹©ä¸èµ„æºåˆ†é…æ–¹æ³•ï¼ˆCSRA, Joint Client Selection and Resource Allocationï¼‰**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

- **ç†è®ºåˆ†ææ•°æ®å¼‚è´¨æ€§å¯¹æ³›åŒ–è¯¯å·®çš„å½±å“**ï¼š
  - é¦–æ¬¡ä»ç†è®ºä¸Šæ¨å¯¼äº†**å…¨å±€æ¨¡å‹æ³›åŒ–è¯¯å·®ï¼ˆGeneralization Errorï¼‰çš„ä¸Šç•Œ**ï¼Œå¹¶å°†å…¶åˆ†è§£ä¸ºï¼š
    - **æ³›åŒ–ç›¸å…³è¯¯å·®ï¼ˆGeneralization-related errorï¼‰**ï¼šç”±æ•°æ®åˆ†å¸ƒåç§»ï¼ˆKLæ•£åº¦ $D_{KL}(P_g \| p_k)$ï¼‰å’Œæ ·æœ¬é‡å†³å®šã€‚
    - **è®­ç»ƒç›¸å…³è¯¯å·®ï¼ˆTraining-related errorï¼‰**ï¼šç”±ç®—æ³•ç¨³å®šæ€§ã€å­¦ä¹ ç‡ã€æœ¬åœ°è®­ç»ƒè½®æ•°ç­‰å†³å®šã€‚
  - è¯æ˜ï¼šå½“FLç®—æ³•å…·æœ‰**å‡åŒ€ç¨³å®šæ€§ï¼ˆUniform Stabilityï¼‰**æ—¶ï¼Œå‡å°å®¢æˆ·ç«¯é—´çš„æ•°æ®åˆ†å¸ƒå·®å¼‚ï¼ˆé™ä½KLæ•£åº¦ï¼‰å’Œå¢åŠ æ€»æ•°æ®é‡å¯æ˜¾è‘—æ”¶ç´§æ³›åŒ–è¯¯å·®è¾¹ç•Œã€‚

- **æå‡ºä»¥æ³›åŒ–è¯¯å·®ä¸ºçº¦æŸçš„ä¼˜åŒ–æ¡†æ¶**ï¼š
  - å°†æœ€å°åŒ–è®­ç»ƒå»¶è¿Ÿ $T$ å’Œèƒ½é‡æ¶ˆè€— $E$ çš„ç›®æ ‡å»ºæ¨¡ä¸ºå¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜ï¼Œå½¢å¼ä¸ºï¼š
    $$
    \min \alpha_1 T + \alpha_2 E
    $$
    å¹¶å¼•å…¥ä¸¤ä¸ªå…³é”®çº¦æŸï¼š
    - $D_{KL}(P_g \| p_k) \leq \epsilon_a$ï¼šé™åˆ¶æ‰€é€‰å®¢æˆ·ç«¯çš„æ•°æ®åˆ†å¸ƒä¸å…¨å±€åˆ†å¸ƒçš„KLæ•£åº¦è¿‡å¤§ã€‚
    - $\sum a_{k,t} d_k \geq \epsilon_d$ï¼šç¡®ä¿å‚ä¸è®­ç»ƒçš„å®¢æˆ·ç«¯æ‹¥æœ‰è¶³å¤Ÿçš„æ•°æ®æ€»é‡ã€‚

- **è®¾è®¡é«˜æ•ˆæ±‚è§£ç®—æ³•ï¼ˆCSRAï¼‰**ï¼š
  - å°†åŸæ··åˆæ•´æ•°éçº¿æ€§è§„åˆ’ï¼ˆMINLPï¼‰é—®é¢˜é€šè¿‡å‡¸æ¾å¼›ã€å·®åˆ†å‡¸å‡½æ•°ï¼ˆDC Programmingï¼‰ã€å¯¹å¶æ¬¡æ¢¯åº¦æ³•ç­‰æŠ€æœ¯åˆ†è§£æ±‚è§£ã€‚
  - ç®—æ³•åˆ†ä¸ºä¸¤æ­¥ï¼š
    1. å›ºå®šè®¡ç®—èµ„æºï¼Œä¼˜åŒ–å®¢æˆ·ç«¯é€‰æ‹©ä¸å¸¦å®½åˆ†é…ï¼ˆè½¬åŒ–ä¸ºDCé—®é¢˜ï¼‰ï¼›
    2. å›ºå®šå®¢æˆ·ç«¯ä¸å¸¦å®½ï¼Œä¼˜åŒ–CPUé¢‘ç‡åˆ†é…ï¼ˆå‡¸é—®é¢˜ï¼‰ã€‚
  - æ€»ä½“å¤æ‚åº¦ä¸º $O(K^4)$ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡ç½‘ç»œã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ç¼ºé™· | CSRAä¼˜åŠ¿ |
|------|------|----------|
| **SAE / FedAvg** | ä»…è€ƒè™‘ä¿¡é“è´¨é‡æˆ–éšæœºé€‰æ‹©ï¼Œå¿½ç•¥æ•°æ®åˆ†å¸ƒ | æ˜¾è‘—æå‡æ¨¡å‹å‡†ç¡®ç‡ï¼Œé¿å…æ¨¡å‹åå€š |
| **Pow / CFL** | åŸºäºæŸå¤±å€¼æˆ–æ¢¯åº¦ç›¸ä¼¼æ€§é€‰æ‹©ï¼Œè®¡ç®—å¼€é”€å¤§ä¸”ç¼ºä¹æ³›åŒ–ä¿éšœ | æ›´ç¨³å®šã€æ›´é«˜æ•ˆçš„å®¢æˆ·ç«¯é€‰æ‹©æœºåˆ¶ |
| **ä¼ ç»Ÿèµ„æºåˆ†é…æ–¹æ³•** | å¿½è§†æ•°æ®å¼‚è´¨æ€§å¯¹æ¨¡å‹æ€§èƒ½çš„é•¿æœŸå½±å“ | è”åˆä¼˜åŒ–â€œè®­ç»ƒæˆæœ¬â€ä¸â€œæ¨¡å‹æ€§èƒ½â€ï¼Œå®ç°ç«¯åˆ°ç«¯æ•ˆç‡æå‡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **Fashion-MNIST**ï¼š10ç±»æœè£…å›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚
- **CIFAR-10**ï¼š10ç±»è‡ªç„¶å›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚

### å®éªŒè®¾ç½®
- **ç½‘ç»œç¯å¢ƒ**ï¼š80ä¸ªå®¢æˆ·ç«¯åˆ†å¸ƒåœ¨è·æœåŠ¡å™¨200â€“250ç±³èŒƒå›´å†…ï¼Œæ¨¡æ‹ŸåŸå¸‚è¾¹ç¼˜åœºæ™¯ã€‚
- **æ•°æ®åˆ’åˆ†ç­–ç•¥**ï¼šé‡‡ç”¨æ··åˆéIIDåˆ’åˆ†ï¼š
  - 10% å®¢æˆ·ç«¯ä¸ºIIDï¼ˆæ¯ç±»æ ·æœ¬å‡è¡¡ï¼‰ï¼›
  - 90% å®¢æˆ·ç«¯æŒ‰Dirichletåˆ†å¸ƒï¼ˆæµ“åº¦å‚æ•°0.5ï¼‰ç”Ÿæˆé«˜åº¦éIIDæ•°æ®ã€‚
- **æ¨¡å‹æ¶æ„**ï¼šCNNï¼ˆä¸¤ä¸ªå·ç§¯å±‚ + ä¸‰ä¸ªå…¨è¿æ¥å±‚ + ReLU + MaxPooling + Softmaxï¼‰ã€‚
- **è®­ç»ƒå‚æ•°**ï¼š
  - å­¦ä¹ ç‡ï¼š0.005
  - æœ¬åœ°è®­ç»ƒè½®æ•°ï¼ˆEï¼‰ï¼š10
  - æ¯è½®å‚ä¸å®¢æˆ·ç«¯æ¯”ä¾‹ï¼š25%
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - æµ‹è¯•å‡†ç¡®ç‡ï¼ˆTest Accuracyï¼‰
  - ç´¯è®¡å­¦ä¹ å»¶è¿Ÿï¼ˆLearning Latencyï¼‰
  - ç´¯è®¡èƒ½é‡æ¶ˆè€—ï¼ˆEnergy Consumptionï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
#### æ¨¡å‹æ€§èƒ½å¯¹æ¯”ï¼š
- **SAE**ï¼šåŸºäºç¬æ—¶ä¿¡é“è´¨é‡é€‰æ‹©å®¢æˆ·ç«¯ã€‚
- **FedAvg**ï¼šéšæœºé€‰æ‹©å®¢æˆ·ç«¯ã€‚
- **Pow**ï¼šé€‰æ‹©æŸå¤±å€¼æœ€å¤§çš„å®¢æˆ·ç«¯ã€‚
- **CFL**ï¼šåŸºäºæ¢¯åº¦ç›¸ä¼¼æ€§èšç±»ååœ¨ç°‡å†…è¿›è¡ŒFLã€‚

#### è®­ç»ƒæˆæœ¬å¯¹æ¯”ï¼š
- **CS-Random / GA-Random**ï¼šåˆ†åˆ«ç”¨Algorithm 1æˆ–é—ä¼ ç®—æ³•ï¼ˆGAï¼‰é€‰å®¢æˆ·ç«¯ï¼Œèµ„æºéšæœºåˆ†é…ã€‚
- **CS-Greedy / GA-Greedy**ï¼šç»“åˆè´ªå©ªç®—æ³•è¿›è¡Œèµ„æºåˆ†é…ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ

#### âœ… æ¨¡å‹æ€§èƒ½ï¼ˆæµ‹è¯•å‡†ç¡®ç‡ï¼‰
- åœ¨ **Fashion-MNIST** ä¸Šï¼ŒCSRA è¾¾åˆ°çº¦ **0.78 å‡†ç¡®ç‡**ï¼Œä¼˜äºï¼š
  - FedAvg (~0.65)
  - SAE (~0.64)
  - Pow (~0.68)
  - CFL (~0.62)
- åœ¨ **CIFAR-10** ä¸Šï¼ŒCSRA è¾¾åˆ°çº¦ **0.42 å‡†ç¡®ç‡**ï¼Œæ˜æ˜¾é«˜äºå…¶ä»–æ–¹æ³•ï¼ˆå‡ä½äº0.35ï¼‰ã€‚

> å›¾2æ˜¾ç¤ºï¼ŒCSRAä¸ä»…æ”¶æ•›æ›´å¿«ï¼Œæœ€ç»ˆç²¾åº¦ä¹Ÿæ›´é«˜ã€‚

#### âœ… æ•°æ®åˆ†å¸ƒå¼‚è´¨æ€§å½±å“ï¼ˆKLé˜ˆå€¼ï¼‰
- å½“KLé˜ˆå€¼ $\epsilon_a$ ä»0.2å¢å¤§åˆ°0.8æ—¶ï¼ŒCSRAæ€§èƒ½é€æ¸ä¸‹é™ï¼Œè¶‹è¿‘äºFedAvgã€‚
- è¡¨æ˜ï¼š**ä¸¥æ ¼æ§åˆ¶æ•°æ®åˆ†å¸ƒåç§»æ˜¯ç»´æŒé«˜æ€§èƒ½çš„å…³é”®**ã€‚

#### âœ… æ•°æ®é‡é¢„ç®—å½±å“
- å¢åŠ æ•°æ®é‡é¢„ç®—ï¼ˆ$\epsilon_d$ï¼‰åˆæœŸèƒ½æå‡å‡†ç¡®ç‡ï¼Œä½†è¶…è¿‡ä¸€å®šé˜ˆå€¼åæ”¶ç›Šé€’å‡ã€‚
- ä¾‹å¦‚ï¼Œåœ¨Fashion-MNISTä¸Šï¼Œä»1000å¢è‡³5000æ ·æœ¬æœ‰æ˜æ˜¾æå‡ï¼Œä½†ä»7000åˆ°9000æå‡å¾®å¼±ã€‚

#### âœ… è®­ç»ƒæˆæœ¬ï¼ˆå»¶è¿Ÿä¸èƒ½è€—ï¼‰
- å¦‚å›¾5æ‰€ç¤ºï¼ŒCSRAåœ¨æ‰€æœ‰æ–¹æ³•ä¸­å®ç°äº†**æœ€ä½çš„å­¦ä¹ å»¶è¿Ÿå’Œèƒ½é‡æ¶ˆè€—**ã€‚
- ç›¸æ¯”Randomæ–¹æ³•ï¼Œå»¶è¿Ÿé™ä½çº¦30%ï¼Œèƒ½è€—å‡å°‘çº¦25%ã€‚
- å³ä½¿ä¸Greedyæ–¹æ³•ç›¸æ¯”ï¼ŒCSRAä»è¡¨ç°å‡ºæ›´ä¼˜çš„æ•´ä½“æ•ˆç‡ã€‚

#### âœ… å¸¦å®½ä¸ä¿¡é“å¢ç›Šé²æ£’æ€§
- åœ¨ä½å¸¦å®½æ¡ä»¶ä¸‹ï¼ŒCSRAä¼˜åŠ¿æ›´åŠ æ˜æ˜¾ï¼ˆå›¾6ï¼‰ï¼Œè¯´æ˜å…¶èµ„æºåˆ†é…æœºåˆ¶åœ¨å—é™ç¯å¢ƒä¸‹æ›´å…·é€‚åº”æ€§ã€‚
- åœ¨ä¿¡é“å¢ç›Šå˜åŒ–ä¸‹ï¼ˆ0.1 â†’ 1.3ï¼‰ï¼ŒCSRAä¿æŒç¨³å®šä½å»¶è¿Ÿä¸ä½èƒ½è€—ï¼Œè€ŒåŸºçº¿æ–¹æ³•æ³¢åŠ¨è¾ƒå¤§ï¼ˆå›¾7ï¼‰ï¼Œè¡¨æ˜å…¶å¯¹ä¿¡é“æ³¢åŠ¨å…·æœ‰æ›´å¼ºé²æ£’æ€§ã€‚

#### âœ… æƒè¡¡å‚æ•°æœ‰æ•ˆæ€§
- è°ƒæ•´ $\alpha_1$ï¼ˆå»¶è¿Ÿæƒé‡ï¼‰å’Œ $\alpha_2$ï¼ˆèƒ½è€—æƒé‡ï¼‰å¯çµæ´»æ§åˆ¶äºŒè€…ä¹‹é—´çš„æƒè¡¡ï¼š
  - å¢å¤§ $\alpha_1$ â†’ å»¶è¿Ÿä¸‹é™ï¼Œèƒ½è€—ä¸Šå‡ï¼›
  - å¢å¤§ $\alpha_2$ â†’ èƒ½è€—ä¸‹é™ï¼Œå»¶è¿Ÿä¸Šå‡ã€‚
- éªŒè¯äº†CSRAå…·å¤‡**å¯è°ƒèŠ‚çš„å¤šç›®æ ‡ä¼˜åŒ–èƒ½åŠ›**ï¼ˆå›¾9ï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ•°æ®å¼‚è´¨æ€§æ˜¯å½±å“FLæ³›åŒ–æ€§èƒ½çš„æ ¸å¿ƒå› ç´ **ï¼š
   - KLæ•£åº¦èƒ½æœ‰æ•ˆé‡åŒ–å®¢æˆ·ç«¯æ•°æ®åˆ†å¸ƒä¸å…¨å±€åˆ†å¸ƒçš„åç¦»ç¨‹åº¦ã€‚
   - æ§åˆ¶è¯¥åå·®å¯æ˜¾è‘—æ”¹å–„æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚

2. **è”åˆä¼˜åŒ–å®¢æˆ·ç«¯é€‰æ‹©ä¸èµ„æºåˆ†é…è‡³å…³é‡è¦**ï¼š
   - å•çº¯ä¼˜åŒ–é€šä¿¡æˆ–è®¡ç®—èµ„æºæ— æ³•è§£å†³æ¨¡å‹æ€§èƒ½ç“¶é¢ˆã€‚
   - å¼•å…¥æ³›åŒ–è¯¯å·®çº¦æŸçš„CSRAæ–¹æ¡ˆå®ç°äº†â€œæ€§èƒ½â€ä¸â€œæ•ˆç‡â€çš„åŒèµ¢ã€‚

3. **é€‚åº¦çš„æ•°æ®è§„æ¨¡å³å¯è·å¾—è‰¯å¥½æ€§èƒ½**ï¼š
   - è¿‡åº¦å¢åŠ æ¯è½®è®­ç»ƒæ•°æ®é‡å¸¦æ¥çš„ç²¾åº¦å¢ç›Šæœ‰é™ï¼Œåè€Œå¤§å¹…å¢åŠ å»¶è¿Ÿå’Œèƒ½è€—ã€‚
   - åº”è¿½æ±‚**æ€§ä»·æ¯”æœ€ä¼˜çš„æ•°æ®é¢„ç®—é…ç½®**ã€‚

4. **CSRAå…·å¤‡å¼ºé²æ£’æ€§å’Œçµæ´»æ€§**ï¼š
   - å¯¹å¸¦å®½ã€ä¿¡é“è´¨é‡å˜åŒ–ä¸æ•æ„Ÿã€‚
   - å¯é€šè¿‡è°ƒæ•´ $\alpha_1/\alpha_2$ å®ç°å»¶è¿Ÿä¸èƒ½è€—çš„åŠ¨æ€å¹³è¡¡ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–KLæ•£åº¦ä¼°è®¡**ï¼šéœ€å®¢æˆ·ç«¯ä¸ŠæŠ¥ç±»åˆ«åˆ†å¸ƒæ¯”ä¾‹ï¼Œå‡è®¾ç±»åˆ«å·²çŸ¥ä¸”å¯ç»Ÿè®¡ï¼Œåœ¨è¯­ä¹‰æ¨¡ç³Šæˆ–æœªçŸ¥ç±»åˆ«åœºæ™¯ä¸­å¯èƒ½å¤±æ•ˆã€‚
- **é›†ä¸­å¼èšåˆå‡è®¾**ï¼šæœªè€ƒè™‘å»ä¸­å¿ƒåŒ–æˆ–å±‚æ¬¡åŒ–æ‹“æ‰‘ä¸‹çš„æ‰©å±•æ€§ã€‚
- **é™æ€åˆ†å¸ƒå‡è®¾**ï¼šæ¨¡å‹å‡è®¾å®¢æˆ·ç«¯æ•°æ®åˆ†å¸ƒåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸å˜ï¼Œæœªå¤„ç†åŠ¨æ€æ¼‚ç§»ï¼ˆConcept Driftï¼‰é—®é¢˜ã€‚
- **è®¡ç®—å¤æ‚åº¦è¾ƒé«˜**ï¼š$O(K^4)$ å¤æ‚åº¦åœ¨è¶…å¤§è§„æ¨¡ç½‘ç»œä¸­å¯èƒ½æˆä¸ºç“¶é¢ˆã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³**åŠ¨æ€æ•°æ®åˆ†å¸ƒç¯å¢ƒ**ï¼Œè®¾è®¡è‡ªé€‚åº”KLé˜ˆå€¼æœºåˆ¶ã€‚
2. æ¢ç´¢**æ— æ ‡ç­¾æˆ–æœªçŸ¥ç±»åˆ«åœºæ™¯ä¸‹çš„åˆ†å¸ƒåº¦é‡æ–¹æ³•**ã€‚
3. å°†CSRAåº”ç”¨äº**å¼‚æ„è®¾å¤‡ç±»å‹ï¼ˆå¦‚IoTã€æ— äººæœºï¼‰ç»„æˆçš„ç§»åŠ¨ç½‘ç»œ**ã€‚
4. ç»“åˆ**æ¨¡å‹å‹ç¼©ä¸é‡åŒ–æŠ€æœ¯**ï¼Œè¿›ä¸€æ­¥é™ä½é€šä¿¡å¼€é”€ã€‚
5. ç ”ç©¶**æ¿€åŠ±æœºåˆ¶ä¸éšç§ä¿æŠ¤**åœ¨CSRAæ¡†æ¶ä¸­çš„é›†æˆã€‚

--- 

> **æ€»ç»“**ï¼šæœ¬æ–‡é€šè¿‡ä¸¥è°¨çš„ç†è®ºåˆ†ææ­ç¤ºäº†æ•°æ®å¼‚è´¨æ€§å¯¹FLæ³›åŒ–æ€§èƒ½çš„æœ¬è´¨å½±å“ï¼Œå¹¶æå‡ºäº†ä¸€ç§å…¼é¡¾æ¨¡å‹å‡†ç¡®æ€§ä¸ç³»ç»Ÿæ•ˆç‡çš„è”åˆä¼˜åŒ–æ¡†æ¶CSRAã€‚å®éªŒè¯æ˜å…¶åœ¨å¤šä¸ªç»´åº¦ä¸Šå…¨é¢è¶…è¶Šä¸»æµåŸºçº¿æ–¹æ³•ï¼Œä¸ºæ— çº¿ç½‘ç»œä¸­çš„é«˜æ•ˆè”é‚¦å­¦ä¹ æä¾›äº†é‡è¦è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 15. [SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing](https://arxiv.org/abs/2512.24008)

**Authors**: Gaurab Chhetri, Subasish Das, Tausif Islam Chowdhury  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.24008v1  

#### Abstract
Personalized search demands the ability to model users' evolving, multi-dimensional information needs; a challenge for systems constrained by static profiles or monolithic retrieval pipelines. We present SPARK (Search Personalization via Agent-Driven Retrieval and Knowledge-sharing), a framework in ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿä¸ªæ€§åŒ–æœç´¢ç³»ç»Ÿå­˜åœ¨ä»¥ä¸‹æ ¸å¿ƒé—®é¢˜ï¼š
- **é™æ€ç”¨æˆ·å»ºæ¨¡**ï¼šä¾èµ–å›ºå®šæˆ–ç¼“æ…¢æ›´æ–°çš„ç”¨æˆ·ç”»åƒï¼ˆå¦‚ä¸»é¢˜åå¥½å‘é‡ï¼‰ï¼Œéš¾ä»¥æ•æ‰ç”¨æˆ·æ„å›¾çš„åŠ¨æ€å˜åŒ–å’Œå¤šç»´åº¦éœ€æ±‚ã€‚
- **å•ä½“å¼æ£€ç´¢æ¶æ„**ï¼šé‡‡ç”¨ç»Ÿä¸€çš„æ£€ç´¢æ’åºæµç¨‹å¤„ç†æ‰€æœ‰æŸ¥è¯¢ï¼Œç¼ºä¹å¯¹ä»»åŠ¡ã€è§’è‰²ã€ä¸Šä¸‹æ–‡ç­‰æƒ…å¢ƒçš„é€‚åº”èƒ½åŠ›ã€‚
- **åˆšæ€§ä¸ªäººåŒ–æœºåˆ¶**ï¼šæ— æ³•æœ‰æ•ˆåº”å¯¹â€œéå…¸å‹â€æœç´¢ä¼šè¯ï¼ˆatypical sessionsï¼‰æˆ–å¤æ‚ã€å¤åˆå‹ä¿¡æ¯éœ€æ±‚ã€‚

è¿™äº›é—®é¢˜å¯¼è‡´ç°æœ‰ç³»ç»Ÿåœ¨é¢å¯¹**æƒ…å¢ƒæ•æ„Ÿã€æ¼”åŒ–æ€§å¼ºã€è·¨é¢†åŸŸ**çš„ä¿¡æ¯éœ€æ±‚æ—¶è¡¨ç°ä¸ä½³ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **SPARK**ï¼ˆSearch Personalization via Agent-Driven Retrieval and Knowledge-sharingï¼‰ï¼Œä¸€ä¸ªåŸºäº**å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ**ï¼ˆMulti-Agent System, MASï¼‰çš„æ–°å‹ä¸ªæ€§åŒ–æœç´¢æ¡†æ¶ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**åŸºäº Persona çš„å½¢å¼åŒ–æ¨¡å‹**
å®šä¹‰äº†ä¸€ä¸ªå››ç»´ Persona ç©ºé—´ï¼š
- **Role**ï¼ˆè§’è‰²ï¼‰ï¼šå¦‚ Criticã€Synthesizerã€Librarian
- **Expertise**ï¼ˆä¸“é•¿ï¼‰ï¼šå¦‚å­¦æœ¯ IRã€ç¼–ç¨‹ã€å¥åº·
- **Task Context**ï¼ˆä»»åŠ¡ä¸Šä¸‹æ–‡ï¼‰ï¼šå¦‚æ¢ç´¢å­¦ä¹  vs å†³ç­–åˆ¶å®š
- **Domain**ï¼ˆé¢†åŸŸï¼‰ï¼šå¦‚äº¤é€šå®‰å…¨éƒ¨ã€LLM ç³»ç»Ÿ

è¯¥æ¨¡å‹æ”¯æŒç»†ç²’åº¦çš„è¡Œä¸ºä¸“ä¸šåŒ–ï¼Œä½¿ä¸åŒ agent èƒ½ä»¥ç‰¹å®šè§†è§’å‚ä¸æ£€ç´¢ä¸æ¨ç†ã€‚

#### ï¼ˆ2ï¼‰**Persona Coordinator åŠ¨æ€è°ƒåº¦æœºåˆ¶**
å¼•å…¥ä¸­å¤®åè°ƒå™¨ï¼Œæ ¹æ®å½“å‰æŸ¥è¯¢ $q_t$ å’Œä¼šè¯ä¸Šä¸‹æ–‡ $c_t$ï¼Œé€šè¿‡å¯å­¦ä¹ ç­–ç•¥ï¼ˆå¦‚ contextual banditï¼‰åŠ¨æ€é€‰æ‹©æœ€ç›¸å…³çš„ agent å­é›†ï¼Œå¹¶å†³å®šåä½œåè®®ï¼ˆindependent, relay, debateï¼‰ã€‚

> ç¤ºä¾‹ï¼šä¸€ä¸ªå…³äºâ€œå¦‚ä½•è¯„ä¼° LLM åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„å¯é æ€§â€çš„æŸ¥è¯¢å¯èƒ½æ¿€æ´» Criticï¼ˆæ‰¹åˆ¤æ€§åˆ†æï¼‰ã€Librarianï¼ˆæ–‡çŒ®æ£€ç´¢ï¼‰ã€Synthesizerï¼ˆæ•´åˆè¯æ®ï¼‰ä¸‰ä¸ª agentã€‚

#### ï¼ˆ3ï¼‰**è®¤çŸ¥å¯å‘çš„è®°å¿†åˆ†å±‚æ¶æ„**
å€Ÿé‰´äººç±»è®¤çŸ¥æ¨¡å‹ï¼ˆå¦‚ Baddeley å·¥ä½œè®°å¿†æ¨¡å‹ã€ACT-R æ¶æ„ï¼‰ï¼Œè®¾è®¡ä¸‰å±‚è®°å¿†ç³»ç»Ÿï¼š
- **Working Memory (Ms)**ï¼šä¸´æ—¶çŠ¶æ€ç¼“å†²
- **Episodic Memory (Me)**ï¼šè®°å½•è¿‘æœŸäº¤äº’è½¨è¿¹
- **Semantic Memory (Msem)**ï¼šé•¿æœŸç”¨æˆ·åå¥½ä¸çŸ¥è¯†å›¾è°±

è¿™ç§åˆ†ç¦»æœ‰åŠ©äºåŒºåˆ†çŸ­æœŸæ„å›¾ä¸é•¿æœŸå…´è¶£ï¼Œæå‡è¿ç»­æ€§å’Œé€‚åº”æ€§ã€‚

#### ï¼ˆ4ï¼‰**ç»“æ„åŒ–çš„å¤š agent åä½œåè®®**
æ”¯æŒä¸‰ç§åä½œæ¨¡å¼ï¼š
- **Independent Specialists**ï¼šå¹¶è¡Œæ‰§è¡Œ â†’ é«˜æ•ˆé€‚ç”¨äºç®€å•æŸ¥è¯¢
- **Relay Chain**ï¼šé¡ºåºä¼ é€’ â†’ æ”¯æŒå¤šæ­¥æ¨ç†ä¸é€æ­¥ä¼˜åŒ–
- **Constrained Debate**ï¼šå¸¦è£åˆ¤çš„æœ‰é™è½®æ¬¡è¾©è®º â†’ æå‡ç­”æ¡ˆå‡†ç¡®æ€§ä¸äº‹å®ä¸€è‡´æ€§

å¹¶é€šè¿‡ **adaptive gating mechanism** è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜åè®®ã€‚

#### ï¼ˆ5ï¼‰**é—­ç¯å­¦ä¹ ä¸æŒç»­ä¼˜åŒ–æœºåˆ¶**
- ä½¿ç”¨ **contextual bandits** è¿›è¡ŒåŠ¨æ€è·¯ç”±ç­–ç•¥å­¦ä¹ 
- é‡‡ç”¨ **off-policy evaluation** å®‰å…¨åœ°ç¦»çº¿è¯„ä¼° persona é…ç½®å˜æ›´
- å¼•å…¥ **confidence calibration** å’Œ **intent-aware diversity objectives**ï¼ˆå¦‚ ERR-IAï¼‰é˜²æ­¢è¿‡æ»¤æ°”æ³¡

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | SPARK |
|------|--------|-------|
| ç”¨æˆ·å»ºæ¨¡ | é™æ€ profile æˆ–çŸ­ä¼šè¯å†å² | å¤šç»´ã€åŠ¨æ€ã€å¯æ¼”åŒ–çš„ persona ç©ºé—´ |
| æ£€ç´¢æ¶æ„ | å•ä¸€ pipelineï¼Œå…¨å±€é€‚ç”¨ | åˆ†å¸ƒå¼ agentï¼ŒæŒ‰éœ€æ¿€æ´» |
| ä¸Šä¸‹æ–‡ç†è§£ | æµ…å±‚ session context | åˆ†å±‚è®°å¿† + æ˜¾å¼è¯­ä¹‰/æƒ…æ™¯åˆ†ç¦» |
| æ¨ç†èƒ½åŠ› | å•æ¬¡ç”Ÿæˆæˆ–é‡æ’åº | å¤šé˜¶æ®µ relay / debate å¢å¼ºæ¨ç† |
| å¯è§£é‡Šæ€§ä¸å¯æ§æ€§ | é»‘ç®±æ¨¡å‹ | ç»“æ„åŒ–åä½œ + å¯å®¡è®¡çš„è®°å¿†è®¿é—® |
| ä¸ªæ€§åŒ–æ·±åº¦ | è¡¨å±‚åå¥½åŒ¹é… | æ·±å±‚ä»»åŠ¡é©±åŠ¨ã€è§’è‰²é€‚é… |

> âœ… SPARK å®ç°äº†ä»â€œprofile-based personalizationâ€åˆ°â€œ**emergent personalization**â€çš„èŒƒå¼è½¬å˜â€”â€”å³ä¸ªæ€§åŒ–çš„å±æ€§ç”±åˆ†å¸ƒå¼ agent çš„ååŒè¡Œä¸ºè‡ªç„¶æ¶Œç°ï¼Œè€Œéé¢„è®¾è§„åˆ™ç¡¬ç¼–ç ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **TREC Session Track 2011â€“2014**ï¼šç”¨äºè¯„ä¼°å¤šè½®æœç´¢åœºæ™¯ä¸‹çš„æ„å›¾æ¼”åŒ–ä¸è¦†ç›–èƒ½åŠ›ã€‚
- **MS MARCO**ï¼šæ ‡å‡†å•è½®é—®ç­”æ•°æ®é›†ï¼Œæµ‹è¯•äº‹å®æ€§ä¸ç›¸å…³æ€§ã€‚
- **Domain-specific corpora**ï¼šè‹¥å¹²å‚ç›´é¢†åŸŸè¯­æ–™åº“ï¼ˆå…·ä½“æœªå…¬å¼€åç§°ï¼‰ï¼Œç¡®ä¿è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚
- **Synthetic user personas**ï¼šæ¨¡æ‹Ÿå†·å¯åŠ¨åœºæ™¯ï¼Œæµ‹è¯•ç³»ç»Ÿå­¦ä¹ é€Ÿåº¦ã€‚

---

### å®éªŒè®¾ç½®
- **Agent å®ç°**ï¼šåŸºäº LLMï¼ˆæœªæŒ‡å®šå…·ä½“å‹å·ï¼‰æ„å»ºå¤šä¸ª persona-specialized agentsï¼Œæ¯ä¸ªé…ç½®ç‹¬ç«‹æç¤ºæ¨¡æ¿ä¸å·¥å…·æ¥å£ã€‚
- **Coordinator å®ç°**ï¼šä½¿ç”¨ contextual banditï¼ˆLinUCB / Thompson Samplingï¼‰å®ç°åŠ¨æ€è·¯ç”±ä¸åè®®é€‰æ‹©ã€‚
- **Memory æ¨¡å—**ï¼šworking/episodic memory å­˜å‚¨äºæœ¬åœ°ç¼“å­˜ï¼›semantic memory ä½¿ç”¨å‘é‡åŒ–å­˜å‚¨ + å‘é‡æ•°æ®åº“æ£€ç´¢ã€‚
- **Tool Connectors**ï¼šéµå¾ª Model Context Protocolï¼Œæ¥å…¥ Web Search APIã€ä»£ç æ‰§è¡Œå¼•æ“ç­‰å¤–éƒ¨èµ„æºã€‚
- **Arbiter èåˆæ¨¡å—**ï¼šé»˜è®¤ä½¿ç”¨ **Reciprocal Rank Fusion (RRF)**ï¼Œå¯é€‰ learned fusion modelã€‚

---

### è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **æ£€ç´¢æœ‰æ•ˆæ€§** | nDCG@k, ERR-IA@k |
| **ä¸ªæ€§åŒ–è´¨é‡** | Session Success Rate, Query Reformulation Reduction, Click Model Gain |
| **å¤šæ ·æ€§ä¸è¦†ç›–** | Subtopic Coverage, Intent Coverage (via ERR-IA) |
| **äº‹å®æ€§ä¸å¯ä¿¡åº¦** | Evidence-linked Factuality, Citation Coverageï¼ˆäººå·¥æ ‡æ³¨éªŒè¯ï¼‰ |
| **æ•ˆç‡ä¸å¼€é”€** | Token Consumption per Session, Wall-clock Latency, Tool Call Count |
| **è®¤çŸ¥è´Ÿè·åˆ†å¸ƒ** | Context Length, Memory Access Frequency |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Static Routing Baseline**ï¼šå›ºå®š agent ç»„åˆï¼Œæ— åŠ¨æ€è°ƒåº¦
- **Single-Agent RAG System**ï¼šé€šç”¨ LLM + æ£€ç´¢å¢å¼ºç”Ÿæˆ
- **Non-cooperative Parallel Agents**ï¼šå¤šä¸ª agent å¹¶è¡Œè¿è¡Œä½†æ— ç»“æ„åŒ–åä½œ
- **Fixed Protocol Systems**ï¼šå§‹ç»ˆä½¿ç”¨ relay æˆ– debateï¼Œä¸è‡ªé€‚åº”åˆ‡æ¢

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªå‡è®¾æ€§é¢„æµ‹ä¸åˆæ­¥ä»¿çœŸï¼‰
å°½ç®¡è®ºæ–‡å°šæœªæä¾›å®Œæ•´å®è¯æ•°æ®ï¼ˆå› ä»ä¸ºæ¡†æ¶ææ¡ˆï¼‰ï¼Œä½†æå‡ºäº†å¤šä¸ªå¯æ£€éªŒçš„å‡è¯´ï¼ˆhypothesesï¼‰åŠé¢„æœŸç»“æœï¼š

#### H1: åè°ƒæ•ˆç‡ï¼ˆCoordination Efficiencyï¼‰
- å¯¹äºä½å¤æ‚åº¦æŸ¥è¯¢ï¼š
  - **Independent protocol (kâ‰¤2)** æ¯” **constrained debate** å®ç°æ›´é«˜ **utility per token**
- å¯¹äºé«˜å¤æ‚åº¦æŸ¥è¯¢ï¼ˆéœ€å¤šæºåˆæˆï¼‰ï¼š
  - ä¸€è½® **debate** åœ¨ç›¸ä¼¼æˆæœ¬ä¸‹ä¼˜äºä¸‰åç‹¬ç«‹ agent çš„è¾“å‡ºèåˆï¼Œæ˜¾è‘—æå‡å‡†ç¡®ç‡ä¸å¿ å®åº¦ï¼ˆfaithfulnessï¼‰

#### H2: ä¸ªæ€§åŒ–è´¨é‡ï¼ˆPersonalization Qualityï¼‰
- **Contextual-bandit coordinator** èƒ½åœ¨ **3â€“5 æ¬¡äº¤äº’å†…æ£€æµ‹ä»»åŠ¡æ¼‚ç§»**ï¼ˆtask driftï¼‰
- ç›¸è¾ƒé™æ€è·¯ç”±ï¼Œåœ¨ session-level utility ä¸Šæå‡çº¦ **18â€“25%**

#### H3: è®¤çŸ¥è´Ÿè½½åˆ†å¸ƒï¼ˆCognitive Load Distributionï¼‰
- æ˜¾å¼åˆ†ç¦» working ä¸ long-term memory åï¼š
  - å¹³å‡ context length å‡å°‘ **~30%**
  - å“åº”å»¶è¿Ÿé™ä½ **~22%**
  - ä¿æŒ nDCG@10 ä¸ä¸‹é™ï¼ˆÎ” < 0.02ï¼‰

#### H4: å¤šæ ·æ€§ä¸æ„å¤–å‘ç°ï¼ˆDiversity & Serendipityï¼‰
- ä½¿ç”¨ ERR-IA ä½œä¸ºè·¯ç”±ç›®æ ‡å‡½æ•°åï¼š
  - **subtopic coverage æå‡ 35%**
  - ç”¨æˆ·æ»¡æ„åº¦è°ƒæŸ¥ä¸­â€œæ–°é¢–æ€§â€è¯„åˆ†æé«˜ **1.2/5 åˆ†**

---

### æ¶ˆèå®éªŒè®¾è®¡ï¼ˆAblation Studiesï¼‰
è®ºæ–‡æ˜ç¡®åˆ—å‡ºä»¥ä¸‹æ¶ˆèè·¯å¾„ï¼š
| å®éªŒ | å‘ç°é¢„æœŸ |
|------|--------|
| ç§»é™¤ episodic memory | çŸ­æœŸä»»åŠ¡è¿ç»­æ€§ä¸‹é™ï¼Œquery reformulation å¢åŠ  40% |
| ç¦ç”¨ debate åè®® | åœ¨äº‰è®®æ€§é—®é¢˜ä¸Š factuality ä¸‹é™ 15%ï¼Œcitation coverage å‡å°‘ |
| å›ºå®š k=1ï¼ˆä»…ä¸€ä¸ª agentï¼‰ | å¤æ‚æŸ¥è¯¢ nDCG@10 ä¸‹é™ 28% |
| æ›¿æ¢ RRF ä¸º learned fusion | åœ¨æœ‰è¶³å¤Ÿè®­ç»ƒæ•°æ®æ—¶æå‡ ~5% nDCGï¼Œå¦åˆ™ä¸ç¨³å®š |
| å…³é—­ bandit exploration | é•¿æœŸé€‚åº”èƒ½åŠ›é€€åŒ–ï¼Œå†·å¯åŠ¨æ¢å¤æ—¶é—´å»¶é•¿ 2Ã— |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Emergent Personalization æ˜¯å¯è¡Œçš„**ï¼šé€šè¿‡è½»é‡çº§åè°ƒè§„åˆ™å¼•å¯¼ specialized agents åä½œï¼Œå¯ä»¥è‡ªç„¶æ¶Œç°å‡ºé«˜åº¦æƒ…å¢ƒæ•æ„Ÿçš„ä¸ªæ€§åŒ–è¡Œä¸ºã€‚
2. **ç»“æ„åŒ–åä½œä¼˜äºç›²ç›®å †å  agent**ï¼šrelay ä¸ debate æ˜¾è‘—æå‡å¤æ‚ä»»åŠ¡çš„è¡¨ç°ï¼Œä½†å¿…é¡»é…åˆ adaptive gating é¿å…ç®€å•ä»»åŠ¡çš„è¿‡åº¦å¼€é”€ã€‚
3. **è®¤çŸ¥å¯å‘çš„è®°å¿†æ¶æ„å…·æœ‰å®é™…ä»·å€¼**ï¼šæ˜¾å¼åŒºåˆ† working / episodic / semantic memory å¯æœ‰æ•ˆç®¡ç† context bloatï¼Œæ”¹å–„å»¶è¿Ÿä¸ç¨³å®šæ€§ã€‚
4. **å¤šæ ·æ€§ç›®æ ‡å¿…é¡»æ˜¾å¼å»ºæ¨¡**ï¼šä»…ä¼˜åŒ– relevance ä¼šå¯¼è‡´ filter bubbleï¼›å¼•å…¥ ERR-IA ç­‰ intent-aware æŒ‡æ ‡å¯æœ‰æ•ˆç¼“è§£æ­¤é£é™©ã€‚
5. **å®‰å…¨ä¸æ²»ç†éœ€å‰ç½®è®¾è®¡**ï¼špersistent memory å¸¦æ¥éšç§æ³„éœ²é£é™©ï¼ˆå¦‚ RAG-Thief æ”»å‡»ï¼‰ï¼Œå¿…é¡»ç»“åˆåŠ å¯†ã€æœ€å°æƒé™è®¿é—®ã€å®šæœŸ purge ç­‰æœºåˆ¶ã€‚

---

### å±€é™æ€§
1. **åè°ƒå¼€é”€å¤§**ï¼šå¯¹äºç®€å•æŸ¥è¯¢ï¼Œmulti-agent æ¶æ„å¸¦æ¥ä¸å¿…è¦çš„å»¶è¿Ÿä¸ token æˆæœ¬ã€‚
2. **Personalization Drift é£é™©**ï¼šè‹¥æ— è¡°å‡æƒé‡æˆ–é‡å¤ç¡®è®¤æœºåˆ¶ï¼ŒçŸ­æœŸè¡Œä¸ºæ˜“è¯¯å†™å…¥ semantic memoryï¼Œé€ æˆ profile åç§»ã€‚
3. **è¯„ä¼°éš¾åº¦é«˜**ï¼šmulti-agent ç³»ç»Ÿæ¶‰åŠåè°ƒæ•ˆç‡ã€å…¬å¹³æ€§ã€é²æ£’æ€§ç­‰å¤šä¸ªç»´åº¦ï¼Œä¼ ç»Ÿ IR æŒ‡æ ‡ä¸è¶³ä»¥å…¨é¢è¡¡é‡ã€‚
4. **æŒä¹…åŒ–å†…å­˜çš„å®‰å…¨éšæ‚£**ï¼šå³ä½¿é‡‡ç”¨åŠ å¯†ä¸æŠ½è±¡è¡¨ç¤ºï¼Œä»é¢ä¸´ prompt injection ä¸ memory extraction æ”»å‡»å¨èƒã€‚
5. **ç¼ºä¹çœŸå®éƒ¨ç½²æ•°æ®**ï¼šç›®å‰ä»…ä¸ºæ¡†æ¶è®¾è®¡ï¼Œå°šæ— å¤§è§„æ¨¡çº¿ä¸Š A/B æµ‹è¯•ç»“æœæ”¯æ’‘ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **Live-system deployment studies**ï¼šåœ¨çœŸå®ç¯å¢ƒä¸­æµ‹è¯• SPARK çš„é•¿æœŸç¨³å®šæ€§ä¸ç”¨æˆ·æ¥å—åº¦ã€‚
2. **Learned fusion with per-persona attribution**ï¼šå¼€å‘å¯è§£é‡Šçš„èåˆæ¨¡å‹ï¼Œè¯†åˆ«å„ agent è´¡çŒ®ã€‚
3. **Principled unlearning strategies**ï¼šç ”ç©¶å¦‚ä½•ä» semantic memory ä¸­å®‰å…¨åˆ é™¤é”™è¯¯æˆ–è¿‡æ—¶ä¿¡æ¯ï¼ˆmodel editing / unlearningï¼‰ã€‚
4. **Dynamic agent creation**ï¼šå…è®¸ç³»ç»Ÿæ ¹æ®æ–°é¢†åŸŸè‡ªåŠ¨å®ä¾‹åŒ–æ–°çš„ persona agentã€‚
5. **Human-in-the-loop refinement**ï¼šè®©ç”¨æˆ·ç›´æ¥å¹²é¢„ memory æ›´æ–°ä¸ agent é…ç½®ï¼Œå¢å¼ºæ§åˆ¶æ„Ÿä¸ä¿¡ä»»ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> SPARK æå‡ºäº†ä¸€ç§å°† **multi-agent coordination**ã€**cognitive-inspired memory design** ä¸ **retrieval-augmented generation** æ·±åº¦èåˆçš„ä¸‹ä¸€ä»£ä¸ªæ€§åŒ–æœç´¢èŒƒå¼ï¼Œæ¨åŠ¨ä¸ªæ€§åŒ–ä»â€œé™æ€ç”»åƒåŒ¹é…â€èµ°å‘â€œåŠ¨æ€ã€æƒ…å¢ƒåŒ–ã€å¯è¿›åŒ–çš„æ™ºèƒ½åä½œâ€ã€‚è™½ç„¶é¢ä¸´æ•ˆç‡ä¸å®‰å…¨æŒ‘æˆ˜ï¼Œä½†å…¶æ¶æ„ä¸ºæ„å»ºæ›´æ¥è¿‘äººç±»ä¿¡æ¯å¯»æ±‚è¡Œä¸ºçš„æ™ºèƒ½ç³»ç»Ÿæä¾›äº†åšå®è“å›¾ã€‚

</details>

---

### 16. [LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm](https://arxiv.org/abs/2512.24077)

**Authors**: Chunhui Wan, Xunan Dai, Zhuo Wang, Minglei Li, Yanpeng Wang, Yinan Mao, Yu Lan, Zhiwen Xiao  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.24077v1  

#### Abstract
The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address ...

---

### 17. [CEC-Zero: Zero-Supervision Character Error Correction with Self-Generated Rewards](https://arxiv.org/abs/2512.23971)

**Authors**: Zhiming Lin, Kai Zhao, Sophie Zhang, Peilai Yu, Canran Xiao  
**Category**: cs.CL  
**Published**: 2026-01-01  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.23971v1  

#### Abstract
Large-scale Chinese spelling correction (CSC) remains critical for real-world text processing, yet existing LLMs and supervised methods lack robustness to novel errors and rely on costly annotations. We introduce CEC-Zero, a zero-supervision reinforcement learning framework that addresses this by en...

---

### 18. [Activation Steering for Masked Diffusion Language Models](https://arxiv.org/abs/2512.24143)

**Authors**: Adi Shnaidman, Erin Feiglin, Osher Yaari, Efrat Mentel, Amit Levi, Raz Lapid  
**Category**: cs.CL  
**Published**: 2026-01-01  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.24143v1  

#### Abstract
Masked diffusion language models (MDLMs) generate text through an iterative denoising process. They have recently gained attention due to mask-parallel decoding and competitive performance with autoregressive large language models. However, effective mechanisms for inference-time control and steerin...

---

### 19. [HaluNet: Multi-Granular Uncertainty Modeling for Efficient Hallucination Detection in LLM Question Answering](https://arxiv.org/abs/2512.24562)

**Authors**: Chaodong Tong, Qi Zhang, Jiayang Gao, Lei Jiang, Yanbing Liu, Nannan Sun  
**Category**: cs.CL  
**Published**: 2026-01-01  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.24562v1  

#### Abstract
Large Language Models (LLMs) excel at question answering (QA) but often generate hallucinations, including factual errors or fabricated content. Detecting hallucinations from internal uncertainty signals is attractive due to its scalability and independence from external resources. Existing methods ...

---

### 20. [Distributed Bilevel Optimization with Dual Pruning for Resource-limited Clients](https://arxiv.org/abs/2512.24667)

**Authors**: Mingyi Li, Xiao Zhang, Ruisheng Zheng, Hongjian Shi, Yuan Yuan, Xiuzhen Cheng, Dongxiao Yu  
**Category**: cs.DC  
**Published**: 2026-01-01  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.24667v1  

#### Abstract
With the development of large-scale models, traditional distributed bilevel optimization algorithms cannot be applied directly in low-resource clients. The key reason lies in the excessive computation involved in optimizing both the lower- and upper-level functions. Thus, we present the first resour...

---

### 21. [Rethinking Dense Linear Transformations: Stagewise Pairwise Mixing (SPM) for Near-Linear Training in Neural Networks](https://arxiv.org/abs/2512.23905)

**Authors**: Peter Farag  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.23905v1  

#### Abstract
Dense linear layers are a dominant source of computational and parametric cost in modern machine learning models, despite their quadratic complexity and often being misaligned with the compositional structure of learned representations. We introduce Stagewise Pairwise Mixers (SPM), a structured line...

---

### 22. [Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models](https://arxiv.org/abs/2512.24618)

**Authors**: Junru Lu, Jiarui Qin, Lingfeng Qiao, Yinghui Li, Xinyi Dai, Bo Ke, Jianfeng He, Ruizhi Qiao, Di Yin, Xing Sun, Yunsheng Wu, Yinsong Liu, Shuangyin Liu, Mingkong Tang, Haodong Lin, Jiayi Kuang, Fanxu Meng, Xiaojuan Tang, Yunjia Xi, Junjie Huang, Haotong Yang, Zhenyi Shen, Yangning Li, Qianwen Zhang, Yifei Yu, Siyu An, Junnan Dong, Qiufeng Wang, Jie Wang, Keyu Chen, Wei Wen, Taian Guo, Zhifeng Shen, Daohai Yu, Jiahao Li, Ke Li, Zongyi Li, Xiaoyu Tan  
**Category**: cs.CL  
**Published**: 2026-01-01  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.24618v1  

#### Abstract
We introduce Youtu-LLM, a lightweight yet powerful language model that harmonizes high computational efficiency with native agentic intelligence. Unlike typical small models that rely on distillation, Youtu-LLM (1.96B) is pre-trained from scratch to systematically cultivate reasoning and planning ca...

---

### 23. [DTI-GP: Bayesian operations for drug-target interactions using deep kernel Gaussian processes](https://arxiv.org/abs/2512.24810)

**Authors**: Bence Bolg\'ar, Andr\'as Millinghoffer, P\'eter Antal  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.24810v1  

#### Abstract
Precise probabilistic information about drug-target interaction (DTI) predictions is vital for understanding limitations and boosting predictive performance. Gaussian processes (GP) offer a scalable framework to integrate state-of-the-art DTI representations and Bayesian inference, enabling novel op...

---

### 24. [CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution](https://arxiv.org/abs/2512.23880)

**Authors**: Xu Huang, Junwu Chen, Yuxing Fei, Zhuohan Li, Philippe Schwaller, Gerbrand Ceder  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.23880v1  

#### Abstract
Large language model (LLM) agents currently depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks. We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from "LLM + too...

---

### 25. [Align While Search: Belief-Guided Exploratory Inference for World-Grounded Embodied Agents](https://arxiv.org/abs/2512.24461)

**Authors**: Seohui Bae, Jeonghye Kim, Youngchul Sung, Woohyung Lim  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.24461v1  

#### Abstract
In this paper, we propose a test-time adaptive agent that performs exploratory inference through posterior-guided belief refinement without relying on gradient-based updates or additional training for LLM agent operating under partial observability. Our agent maintains an external structured belief ...

---

### 26. [Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization](https://arxiv.org/abs/2512.24609)

**Authors**: Dong Qiu, Duo Xu, Limengxi Yue  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.24609v1  

#### Abstract
Large Language Models (LLMs) perform well in language tasks but often lack collaborative awareness and struggle to optimize global performance in multi-agent settings. We present a reinforcement learning-augmented LLM agent framework that formulates cooperation as a decentralized partially observabl...

---

### 27. [Compute-Accuracy Pareto Frontiers for Open-Source Reasoning Large Language Models](https://arxiv.org/abs/2512.24776)

**Authors**: \'Akos Prucs, M\'arton Csutora, M\'aty\'as Antal, M\'ark Marosi  
**Category**: cs.CL  
**Published**: 2026-01-01  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.24776v1  

#### Abstract
Large Language Models (LLMs) are demonstrating rapid improvements on complex reasoning benchmarks, particularly when allowed to utilize intermediate reasoning steps before converging on a final solution. However, current literature often overlooks the significant computational burden associated with...

---

### 28. [Squeezing Edge Performance: A Sensitivity-Aware Container Management for Heterogeneous Tasks](https://arxiv.org/abs/2512.23952)

**Authors**: Yongmin Zhang, Pengyu Huang, Mingyi Dong, Jing Yao  
**Category**: cs.DC  
**Published**: 2026-01-01  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.23952v1  

#### Abstract
Edge computing enables latency-critical applications to process data close to end devices, yet task heterogeneity and limited resources pose significant challenges to efficient orchestration. This paper presents a measurement-driven, container-based resource management framework for intra-node optim...

---

### 29. [Learning Coupled System Dynamics under Incomplete Physical Constraints and Missing Data](https://arxiv.org/abs/2512.23761)

**Authors**: Esha Saha, Hao Wang  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.23761v1  

#### Abstract
Advances in data acquisition and computational methods have accelerated the use of differential equation based modelling for complex systems. Such systems are often described by coupled (or more) variables, yet governing equation is typically available for one variable, while the remaining variable ...

---

### 30. [Micro-Macro Tensor Neural Surrogates for Uncertainty Quantification in Collisional Plasma](https://arxiv.org/abs/2512.24205)

**Authors**: Wei Chen, Giacomo Dimarco, Lorenzo Pareschi  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.24205v1  

#### Abstract
Plasma kinetic equations exhibit pronounced sensitivity to microscopic perturbations in model parameters and data, making reliable and efficient uncertainty quantification (UQ) essential for predictive simulations. However, the cost of uncertainty sampling, the high-dimensional phase space, and mult...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
