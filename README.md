# arXiv Papers Bot ü§ñ

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv-rss-equ1ow2e6-maydomines-projects.vercel.app/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## üìä Statistics

- **Last Updated**: 2025-08-18 06:35:20 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## üìö Recent Papers

### 1. [SLiM: One-shot Quantization and Sparsity with Low-rank Approximation for LLM Weight Compression](https://arxiv.org/abs/2410.09615)

**Authors**: Mohammad Mozaffari, Amir Yazdanbakhsh, Maryam Mehri Dehnavi  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 5.0

arXiv:2410.09615v4 Announce Type: replace-cross 
Abstract: Conventional model compression techniques for LLMs address high memory consumption and slow inference challenges but typically require computationally expensive retraining to preserve accuracy. In contrast, one-shot compression methods elimi...

---

### 2. [CSGO: Generalized Optimization for Cold Start in Wireless Collaborative Edge LLM Systems](https://arxiv.org/abs/2508.11287)

**Authors**: Xuran Liu, Nan Xue, Rui Bao, Yaping Sun, Zhiyong Chen, Meixia Tao, Xiaodong Xu, Shuguang Cui  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 4.5

arXiv:2508.11287v1 Announce Type: cross 
Abstract: While deploying large language models on edge devices promises low-latency and privacy-preserving AI services, it is hindered by limited device resources. Although pipeline parallelism facilitates distributed inference, existing approaches often ign...

---

### 3. [NeMo: A Neuron-Level Modularizing-While-Training Approach for Decomposing DNN Models](https://arxiv.org/abs/2508.11348)

**Authors**: Xiaohan Bi, Binhang Qi, Hailong Sun, Xiang Gao, Yue Yu, Xiaojun Liang  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 4.5

arXiv:2508.11348v1 Announce Type: cross 
Abstract: With the growing incorporation of deep neural network (DNN) models into modern software systems, the prohibitive construction costs have become a significant challenge. Model reuse has been widely applied to reduce training costs, but indiscriminate...

---

### 4. [Omni-DPO: A Dual-Perspective Paradigm for Dynamic Preference Learning of LLMs](https://arxiv.org/abs/2506.10054)

**Authors**: Shangpin Peng, Weinong Wang, Zhuotao Tian, Senqiao Yang, Xing Wu, Haotian Xu, Chengquan Zhang, Takashi Isobe, Baotian Hu, Min Zhang  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 4.5

arXiv:2506.10054v2 Announce Type: replace-cross 
Abstract: Direct Preference Optimization (DPO) has become a cornerstone of reinforcement learning from human feedback (RLHF) due to its simplicity and efficiency. However, existing DPO-based approaches typically treat all preference pairs uniformly, i...

---

### 5. [LLM Compression: How Far Can We Go in Balancing Size and Performance?](https://arxiv.org/abs/2508.11318)

**Authors**: Sahil Sk, Debasish Dhal, Sonal Khosla, Sk Shahid, Sambit Shekhar, Akash Dhaka, Shantipriya Parida, Dilip K. Prasad, Ond\v{r}ej Bojar  
**Category**: cs.CL  
**Published**: 2025-08-18  
**Score**: 4.5

arXiv:2508.11318v1 Announce Type: new 
Abstract: Quantization is an essential and popular technique for improving the accessibility of large language models (LLMs) by reducing memory usage and computational costs while maintaining performance. In this study, we apply 4-bit Group Scaling Quantization...

---

### 6. [ElasticMM: Efficient Multimodal LLMs Serving with Elastic Multimodal Parallelism](https://arxiv.org/abs/2507.10069)

**Authors**: Zedong Liu, Shenggan Cheng, Guangming Tan, Yang You, Dingwen Tao  
**Category**: cs.DC  
**Published**: 2025-08-18  
**Score**: 4.5

arXiv:2507.10069v2 Announce Type: replace 
Abstract: Multimodal large language models (MLLMs) extend LLMs to handle images, videos, and audio by incorporating feature extractors and projection modules. However, these additional components -- combined with complex inference pipelines and heterogeneou...

---

### 7. [Probing the Representational Power of Sparse Autoencoders in Vision Models](https://arxiv.org/abs/2508.11277)

**Authors**: Matthew Lyle Olson, Musashi Hinck, Neale Ratzlaff, Changbai Li, Phillip Howard, Vasudev Lal, Shao-Yen Tseng  
**Category**: cs.LG  
**Published**: 2025-08-18  
**Score**: 4.5

arXiv:2508.11277v1 Announce Type: cross 
Abstract: Sparse Autoencoders (SAEs) have emerged as a popular tool for interpreting the hidden states of large language models (LLMs). By learning to reconstruct activations from a sparse bottleneck layer, SAEs discover interpretable features from the high-d...

---

### 8. [MCP-Guard: A Defense Framework for Model Context Protocol Integrity in Large Language Model Applications](https://arxiv.org/abs/2508.10991)

**Authors**: Wenpeng Xing, Zhonghao Qi, Yupeng Qin, Yilin Li, Caini Chang, Jiahui Yu, Changting Lin, Zhenzhen Xie, Meng Han  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 4.0

arXiv:2508.10991v1 Announce Type: cross 
Abstract: The integration of Large Language Models (LLMs) with external tools via protocols such as the Model Context Protocol (MCP) introduces critical security vulnerabilities, including prompt injection, data exfiltration, and other threats. To counter the...

---

### 9. [CURE: Critical-Token-Guided Re-concatenation for Entropy-collapse Prevention](https://arxiv.org/abs/2508.11016)

**Authors**: Qingbin Li, Rongkun Xue, Jie Wang, Ming Zhou, Zhi Li, Xiaofeng Ji, Yongqi Wang, Miao Liu, Zheming Yang, Minghui Qiu, Jing Yang  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 4.0

arXiv:2508.11016v1 Announce Type: cross 
Abstract: Recent advances in Reinforcement Learning with Verified Reward (RLVR) have driven the emergence of more sophisticated cognitive behaviors in large language models (LLMs), thereby enhancing their reasoning capabilities. However, in prior RLVR pipelin...

---

### 10. [Is General-Purpose AI Reasoning Sensitive to Data-Induced Cognitive Biases? Dynamic Benchmarking on Typical Software Engineering Dilemmas](https://arxiv.org/abs/2508.11278)

**Authors**: Francesco Sovrano, Gabriele Dominici, Rita Sevastjanova, Alessandra Stramiglio, Alberto Bacchelli  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 4.0

arXiv:2508.11278v1 Announce Type: cross 
Abstract: Human cognitive biases in software engineering can lead to costly errors. While general-purpose AI (GPAI) systems may help mitigate these biases due to their non-human nature, their training on human-generated data raises a critical question: Do GPA...

---

### 11. [ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism](https://arxiv.org/abs/2508.11356)

**Authors**: Jia Liu, ChangYi He, YingQiao Lin, MingMin Yang, FeiYang Shen, ShaoGuo Liu, TingTing Gao  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 4.0

arXiv:2508.11356v1 Announce Type: cross 
Abstract: Recent advancements in Large Language Models have yielded significant improvements in complex reasoning tasks such as mathematics and programming. However, these models remain heavily dependent on annotated data and exhibit limited adaptability in u...

---

### 12. [PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning](https://arxiv.org/abs/2508.10501)

**Authors**: Yushi Feng, Junye Du, Yingying Hong, Qifan Wang, Lequan Yu  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 4.0

arXiv:2508.10501v2 Announce Type: replace 
Abstract: Existing tool-augmented agentic systems are limited in the real world by (i) black-box reasoning steps that undermine trust of decision-making and pose safety risks, (ii) poor multimodal integration, which is inherently critical for healthcare tas...

---

### 13. [SORT3D: Spatial Object-centric Reasoning Toolbox for Zero-Shot 3D Grounding Using Large Language Models](https://arxiv.org/abs/2504.18684)

**Authors**: Nader Zantout, Haochen Zhang, Pujith Kachana, Jinkai Qiu, Guofei Chen, Ji Zhang, Wenshan Wang  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 4.0

arXiv:2504.18684v2 Announce Type: replace-cross 
Abstract: Interpreting object-referential language and grounding objects in 3D with spatial relations and attributes is essential for robots operating alongside humans. However, this task is often challenging due to the diversity of scenes, large numb...

---

### 14. [Exploring Superior Function Calls via Reinforcement Learning](https://arxiv.org/abs/2508.05118)

**Authors**: Bingguang Hao, Maolin Wang, Zengzhuang Xu, Yicheng Chen, Cunyin Peng, Jinjie GU, Chenyi Zhuang  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 4.0

arXiv:2508.05118v3 Announce Type: replace-cross 
Abstract: Function calling capabilities are crucial for deploying Large Language Models in real-world applications, yet current training approaches fail to develop robust reasoning strategies. Supervised fine-tuning produces models that rely on superf...

---

### 15. [SpecDetect: Simple, Fast, and Training-Free Detection of LLM-Generated Text via Spectral Analysis](https://arxiv.org/abs/2508.11343)

**Authors**: Haitong Luo, Weiyao Zhang, Suhang Wang, Wenji Zou, Chungang Lin, Xuying Meng, Yujun Zhang  
**Category**: cs.CL  
**Published**: 2025-08-18  
**Score**: 4.0

arXiv:2508.11343v1 Announce Type: new 
Abstract: The proliferation of high-quality text from Large Language Models (LLMs) demands reliable and efficient detection methods. While existing training-free approaches show promise, they often rely on surface-level statistics and overlook fundamental signa...

---

### 16. [PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning](https://arxiv.org/abs/2508.00344)

**Authors**: Keer Lu, Chong Chen, Bin Cui, Huang Leng, Wentao Zhang  
**Category**: cs.CL  
**Published**: 2025-08-18  
**Score**: 4.0

arXiv:2508.00344v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have shown remarkable advancements in tackling agent-oriented tasks. Despite their potential, existing work faces challenges when deploying LLMs in agent-based environments. The widely adopted agent paradigm ReAct cent...

---

### 17. [SeamlessFlow: A Trainer Agent Isolation RL Framework Achieving Bubble-Free Pipelines via Tag Scheduling](https://arxiv.org/abs/2508.11553)

**Authors**: Jinghui Wang, Shaojie Wang, Yinghan Cui, Xuxing Chen, Chao Wang, Xiaojiang Zhang, Minglei Zhang, Jiarong Zhang, Wenhao Zhuang, Yuchen Cao, Wankang Bao, Haimo Li, Zheng Lin, Huiming Wang, Haoyang Huang, Zongxian Feng, Zizheng Zhan, Ken Deng, Wen Xiang, Huaixi Tang, Kun Wu, Mengtong Li, Mengfei Xie, Junyi Peng, Haotian Zhang, Bin Chen, Bing Yu  
**Category**: cs.LG  
**Published**: 2025-08-18  
**Score**: 4.0

arXiv:2508.11553v1 Announce Type: new 
Abstract: We introduce SeamlessFlow, a server based reinforcement learning (RL) framework that addresses two core challenges in industrial scale RL: (1) decoupling RL training from the complex execution flow of agents; (2) maximizing GPU utilization with minima...

---

### 18. [Visuomotor Grasping with World Models for Surgical Robots](https://arxiv.org/abs/2508.11200)

**Authors**: Hongbin Lin, Bin Li, Kwok Wai Samuel Au  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 3.5

arXiv:2508.11200v1 Announce Type: cross 
Abstract: Grasping is a fundamental task in robot-assisted surgery (RAS), and automating it can reduce surgeon workload while enhancing efficiency, safety, and consistency beyond teleoperated systems. Most prior approaches rely on explicit object pose trackin...

---

### 19. [On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting](https://arxiv.org/abs/2508.11408)

**Authors**: Wenhao Zhang, Yuexiang Xie, Yuchang Sun, Yanxi Chen, Guoyin Wang, Yaliang Li, Bolin Ding, Jingren Zhou  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 3.5

arXiv:2508.11408v1 Announce Type: cross 
Abstract: Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are two prominent post-training paradigms for refining the capabilities and aligning the behavior of Large Language Models (LLMs). Existing approaches that integrate SFT and RL often face ...

---

### 20. [TokenRec: Learning to Tokenize ID for LLM-based Generative Recommendation](https://arxiv.org/abs/2406.10450)

**Authors**: Haohao Qu, Wenqi Fan, Zihuai Zhao, Qing Li  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 3.5

arXiv:2406.10450v3 Announce Type: replace-cross 
Abstract: There is a growing interest in utilizing large-scale language models (LLMs) to advance next-generation Recommender Systems (RecSys), driven by their outstanding language understanding and in-context learning capabilities. In this scenario, t...

---

### 21. [PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks](https://arxiv.org/abs/2508.10557)

**Authors**: Xinhao Wang, Zhiwei Lin, Zhongyu Xia, Yongtao Wang  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 3.5

arXiv:2508.10557v2 Announce Type: replace-cross 
Abstract: Post-Training Quantization (PTQ) and Quantization-Aware Training (QAT) represent two mainstream model quantization approaches. However, PTQ often leads to unacceptable performance degradation in quantized models, while QAT imposes substantia...

---

### 22. [BeyondWeb: Lessons from Scaling Synthetic Data for Trillion-scale Pretraining](https://arxiv.org/abs/2508.10975)

**Authors**: Pratyush Maini, Vineeth Dorna, Parth Doshi, Aldo Carranza, Fan Pan, Jack Urbanek, Paul Burstein, Alex Fang, Alvin Deng, Amro Abbas, Brett Larsen, Cody Blakeney, Charvi Bannur, Christina Baek, Darren Teh, David Schwab, Haakon Mongstad, Haoli Yin, Josh Wills, Kaleigh Mentzer, Luke Merrick, Ricardo Monti, Rishabh Adiga, Siddharth Joshi, Spandan Das, Zhengping Wang, Bogdan Gaza, Ari Morcos, Matthew Leavitt  
**Category**: cs.CL  
**Published**: 2025-08-18  
**Score**: 3.5

arXiv:2508.10975v1 Announce Type: cross 
Abstract: Recent advances in large language model (LLM) pretraining have shown that simply scaling data quantity eventually leads to diminishing returns, hitting a data wall. In response, the use of synthetic data for pretraining has emerged as a promising pa...

---

### 23. [RULEBREAKERS: Challenging LLMs at the Crossroads between Formal Logic and Human-like Reasoning](https://arxiv.org/abs/2410.16502)

**Authors**: Jason Chan, Robert Gaizauskas, Zhixue Zhao  
**Category**: cs.CL  
**Published**: 2025-08-18  
**Score**: 3.5

arXiv:2410.16502v4 Announce Type: replace 
Abstract: Formal logic enables computers to reason in natural language by representing sentences in symbolic forms and applying rules to derive conclusions. However, in what our study characterizes as "rulebreaker" scenarios, this method can lead to conclus...

---

### 24. [HQ-OV3D: A High Box Quality Open-World 3D Detection Framework based on Diffision Model](https://arxiv.org/abs/2508.10935)

**Authors**: Qi Liu, Yabei Li, Hongsong Wang, Lei He  
**Category**: cs.LG  
**Published**: 2025-08-18  
**Score**: 3.5

arXiv:2508.10935v1 Announce Type: cross 
Abstract: Traditional closed-set 3D detection frameworks fail to meet the demands of open-world applications like autonomous driving. Existing open-vocabulary 3D detection methods typically adopt a two-stage pipeline consisting of pseudo-label generation foll...

---

### 25. [Pr$\epsilon\epsilon$mpt: Sanitizing Sensitive Prompts for LLMs](https://arxiv.org/abs/2504.05147)

**Authors**: Amrita Roy Chowdhury, David Glukhov, Divyam Anshumaan, Prasad Chalasani, Nicolas Papernot, Somesh Jha, Mihir Bellare  
**Category**: cs.LG  
**Published**: 2025-08-18  
**Score**: 3.5

arXiv:2504.05147v2 Announce Type: replace-cross 
Abstract: The rise of large language models (LLMs) has introduced new privacy challenges, particularly during inference where sensitive information in prompts may be exposed to proprietary LLM APIs. In this paper, we address the problem of formally pr...

---

### 26. [Apriel-Nemotron-15B-Thinker](https://arxiv.org/abs/2508.10948)

**Authors**: Shruthan Radhakrishna, Soham Parikh, Gopal Sarda, Anil Turkkan, Quaizar Vohra, Raymond Li, Dhruv Jhamb, Kelechi Ogueji, Aanjaneya Shukla, Oluwanifemi Bamgbose, Toby Liang, Luke Kumar, Oleksiy Ostapenko, Shiva Krishna Reddy Malay, Aman Tiwari, Tara Bogavelli, Vikas Yadav, Jash Mehta, Saloni Mittal, Akshay Kalkunte, Pulkit Pattnaik, Khalil Slimi, Anirudh Sreeram, Jishnu Nair, Akintunde Oladipo, Shashank Maiya, Khyati Mahajan, Rishabh Maheshwary, Masoud Hashemi, Sai Rajeswar Mudumba, Sathwik Tejaswi Madhusudhan, Torsten Scholak, Sebastien Paquet, Sagar Davasam, Srinivas Sunkara  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 3.0

arXiv:2508.10948v1 Announce Type: cross 
Abstract: While large language models (LLMs) have achieved remarkable reasoning capabilities across domains like code, math and other enterprise tasks, their significant memory and computational costs often preclude their use in practical enterprise settings....

---

### 27. [Towards Efficient Prompt-based Continual Learning in Distributed Medical AI](https://arxiv.org/abs/2508.10954)

**Authors**: Gyutae Oh, Jitae Shin  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 3.0

arXiv:2508.10954v1 Announce Type: cross 
Abstract: Modern AI models achieve state-of-the-art performance with large-scale, high-quality datasets; however, ethical, social, and institutional constraints in the medical domain severely restrict data sharing, rendering centralized learning nearly imposs...

---

### 28. [Rule2Text: A Framework for Generating and Evaluating Natural Language Explanations of Knowledge Graph Rules](https://arxiv.org/abs/2508.10971)

**Authors**: Nasim Shirvani-Mahdavi, Chengkai Li  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 3.0

arXiv:2508.10971v1 Announce Type: cross 
Abstract: Knowledge graphs (KGs) can be enhanced through rule mining; however, the resulting logical rules are often difficult for humans to interpret due to their inherent complexity and the idiosyncratic labeling conventions of individual KGs. This work pre...

---

### 29. [MoNaCo: More Natural and Complex Questions for Reasoning Across Dozens of Documents](https://arxiv.org/abs/2508.11133)

**Authors**: Tomer Wolfson, Harsh Trivedi, Mor Geva, Yoav Goldberg, Dan Roth, Tushar Khot, Ashish Sabharwal, Reut Tsarfaty  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 3.0

arXiv:2508.11133v1 Announce Type: cross 
Abstract: Large language models (LLMs) are emerging as a go-to tool for querying information. However, current LLM benchmarks rarely feature natural questions that are both information-seeking as well as genuinely time-consuming for humans. To address this ga...

---

### 30. [Dynamic Quality-Latency Aware Routing for LLM Inference in Wireless Edge-Device Networks](https://arxiv.org/abs/2508.11291)

**Authors**: Rui Bao, Nan Xue, Yaping Sun, Zhiyong Chen  
**Category**: cs.AI  
**Published**: 2025-08-18  
**Score**: 3.0

arXiv:2508.11291v1 Announce Type: cross 
Abstract: The integration of wireless communications and Large Language Models (LLMs) is poised to unlock ubiquitous intelligent services, yet deploying them in wireless edge-device collaborative environments presents a critical trade-off between inference qu...

---

## üîß Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative Decoding

## üìÖ Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## üöÄ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## üìù Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## üîç Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
