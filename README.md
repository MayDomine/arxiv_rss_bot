# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-11 05:57:41 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Training-free Context-adaptive Attention for Efficient Long Context Modeling](https://arxiv.org/abs/2512.09238)

**Authors**: Zeng You, Yaofo Chen, Shuhai Zhang, Zhijie Qiu, Tingyu Wu, Yingjian Li, Yaowei Wang, Mingkui Tan  
**Category**: cs.CL  
**Published**: 2025-12-11  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.09238v1  

#### Abstract
Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of natural language processing tasks. These capabilities stem primarily from the self-attention mechanism, which enables modeling of long-range dependencies. However, the quadratic complexity of self-attention...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTraining-free Context-adaptive Attention for Efficient Long Context Modeling

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¾èµ– **self-attention** æœºåˆ¶å»ºæ¨¡é•¿è·ç¦»ä¾èµ–ï¼Œä½†å…¶è®¡ç®—å¤æ‚åº¦ä¸º $O(L^2)$ï¼Œåœ¨å¤„ç†è¶…é•¿ä¸Šä¸‹æ–‡ï¼ˆå¦‚ 128K tokensï¼‰æ—¶é¢ä¸´ä¸¥é‡çš„ **è®¡ç®—ç“¶é¢ˆ** å’Œ **KV Cache å†…å­˜å¼€é”€**ã€‚æ­¤å¤–ï¼Œè¾“å…¥ä¸­å­˜åœ¨å¤§é‡å†—ä½™ tokenï¼Œå¯¼è‡´æ³¨æ„åŠ›èµ„æºæµªè´¹ã€æ•ˆç‡ä¸‹é™ã€‚

ç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹å±€é™ï¼š
- **é™æ€ç¨€ç–æ³¨æ„åŠ›**ï¼ˆå¦‚ BigBirdã€Longformerï¼‰ï¼šä½¿ç”¨å›ºå®šæ¨¡å¼ï¼Œç¼ºä¹å¯¹è¾“å…¥å†…å®¹çš„é€‚åº”æ€§ã€‚
- **ä»…åŠ é€Ÿ prefilling é˜¶æ®µ** çš„åŠ¨æ€æ–¹æ³•ï¼ˆå¦‚ MInferenceã€FlexPrefillï¼‰ï¼šæ— æ³•ç¼“è§£ decoding é˜¶æ®µçš„ KV Cache å¢é•¿ã€‚
- **ä»…å‹ç¼© KV Cache** çš„æ–¹æ³•ï¼ˆå¦‚ SnapKVã€CAKEï¼‰ï¼šä¸å‡å°‘ prefilling è®¡ç®—é‡ã€‚
- **ç»Ÿä¸€æ¡†æ¶**ï¼ˆå¦‚ DuoAttentionã€Lserveï¼‰ï¼šéœ€è¦é¢å¤–è®­ç»ƒæˆ–ç³»ç»Ÿçº§ä¿®æ”¹ï¼Œéƒ¨ç½²æˆæœ¬é«˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šTCA-Attention
æœ¬æ–‡æå‡º **Training-free Context-adaptive Attention (TCA-Attention)**ï¼Œä¸€ç§æ— éœ€è®­ç»ƒã€å¯è‡ªé€‚åº”è¾“å…¥å†…å®¹çš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºé«˜æ•ˆé•¿ä¸Šä¸‹æ–‡æ¨ç†ã€‚

#### æ ¸å¿ƒè®¾è®¡æ€æƒ³
TCA-Attention åŒ…å«ä¸¤ä¸ªè½»é‡çº§é˜¶æ®µï¼š
1. **Offline Sparsity Configurationï¼ˆç¦»çº¿é…ç½®é˜¶æ®µï¼‰**
   - åœ¨å°è§„æ¨¡æ ¡å‡†æ•°æ®é›†ä¸Šé€šè¿‡ä¸€æ¬¡å‰å‘ä¼ æ’­ï¼Œä¼°è®¡æ¯ä¸ª attention head çš„å†—ä½™ç¨‹åº¦ã€‚
   - ä½¿ç”¨ **log-Gaussian é‡‡æ ·ç­–ç•¥** ç”Ÿæˆå€™é€‰ç¨€ç–é…ç½®ï¼Œå¹¶é€‰æ‹©èƒ½ä¿ç•™è¶³å¤Ÿæ³¨æ„åŠ›è´¨é‡ï¼ˆâ‰¥é˜ˆå€¼ $T$ï¼‰çš„æœ€ç¨€ç–é…ç½®ã€‚
   - ç»“æœæ˜¯æ¯ä¸ª head è·å¾—ä¸€ä¸ªä¸ªæ€§åŒ–çš„ **sparsity budget**ï¼ˆå³åº”ä¿ç•™å¤šå°‘ tokenï¼‰ã€‚

2. **Online Core Context Selectionï¼ˆåœ¨çº¿æ ¸å¿ƒä¸Šä¸‹æ–‡é€‰æ‹©é˜¶æ®µï¼‰**
   - æ¨ç†æ—¶ï¼Œæ ¹æ®ç¦»çº¿ç¡®å®šçš„ sparsity budget åŠ¨æ€é€‰æ‹©å…³é”® tokenã€‚
   - å¼•å…¥è½»é‡çº§ **redundancy metric** æ¥è¡¡é‡ block çº§åˆ«çš„ä¿¡æ¯å¯†åº¦ï¼š
     $$
     h_j = (1-\alpha)\sum_{i \in B_j} s_i + \alpha \cdot \text{HHI}(s_i)
     $$
     å…¶ä¸­ç¬¬ä¸€é¡¹è¡¨ç¤ºæ€»æ³¨æ„åŠ›å¾—åˆ†ï¼Œç¬¬äºŒé¡¹æ˜¯ Herfindahl-Hirschman Index å˜ä½“ï¼Œåæ˜ æ³¨æ„åŠ›é›†ä¸­åº¦ã€‚
   - å°†åºåˆ—åˆ’åˆ†ä¸º blockï¼ŒæŒ‰ $h_j$ æ’åºååˆ†é… token é…é¢ï¼Œä¼˜å…ˆä¿ç•™ä¿¡æ¯å¯†é›† block ä¸­çš„é‡è¦ tokenã€‚
   - åŒæ—¶ä¿ç•™æœ€è¿‘ $w$ ä¸ªå±€éƒ¨ tokenï¼ˆlocal subsetï¼‰ï¼Œä»¥æ•æ‰ç»†ç²’åº¦ä¸Šä¸‹æ–‡ã€‚

æœ€ç»ˆæ³¨æ„åŠ›è®¡ç®—åŸºäº **global subset + local subset** çš„æ‹¼æ¥ï¼Œå…¬å¼å¦‚ä¸‹ï¼š
$$
\text{Att} = \text{Softmax}\left(\frac{Q[K_G; K_L]}{\sqrt{d_h}}\right)[V_G; V_L]
$$

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | TCA-Attention | MInference | FlexPrefill | XAttention | SnapKV | DuoAttention |
|------|---------------|------------|-------------|-------------|---------|----------------|
| **Training-free** | âœ… | âœ… | âœ… | âœ… | âœ… | âŒ |
| **Dynamic Adaptation** | âœ… | âœ… | âœ… | âŒ | âŒ | âŒ |
| **Accelerate Prefilling** | âœ… | âœ… | âœ… | âœ… | âŒ | âš ï¸ï¼ˆæœ‰é™ï¼‰ |
| **Accelerate Decoding** | âœ… | âŒ | âŒ | âŒ | âœ… | âœ… |
| **Reduce KV Cache** | âœ… | âŒ | âŒ | âŒ | âœ… | âœ… |

> âœ… è¡¨ç¤ºæ”¯æŒï¼ŒâŒ ä¸æ”¯æŒï¼Œâš ï¸ è¡¨ç¤ºéƒ¨åˆ†æ”¯æŒ

**ä¼˜åŠ¿æ€»ç»“**ï¼š
- **çœŸæ­£ç»Ÿä¸€åŠ é€Ÿ**ï¼šåŒæ—¶ä¼˜åŒ– prefilling å’Œ decoding é˜¶æ®µã€‚
- **å®Œå…¨å…è®­ç»ƒ**ï¼šæ— éœ€å‚æ•°æ›´æ–°ã€æ¶æ„ä¿®æ”¹æˆ–å¤æ‚è°ƒä¼˜ï¼Œå®ç° **plug-and-play** éƒ¨ç½²ã€‚
- **å¤´æ„ŸçŸ¥ + ä¸Šä¸‹æ–‡è‡ªé€‚åº”**ï¼šæ¯ä¸ª attention head æœ‰ç‹¬ç«‹ç¨€ç–ç­–ç•¥ï¼Œä¸” token é€‰æ‹©éšè¾“å…¥åŠ¨æ€å˜åŒ–ã€‚
- **ç†è®ºä¿éšœ**ï¼šè¯æ˜è¿‘ä¼¼è¯¯å·®æœ‰ç•Œï¼Œä¸”ç”±ä¿ç•™çš„æ³¨æ„åŠ›è´¨é‡æ§åˆ¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | ç±»å‹ | ä»»åŠ¡æè¿° |
|--------|------|----------|
| **LongBench-E** | å¤šä»»åŠ¡é•¿æ–‡æœ¬ç†è§£ | åŒ…å«å•æ–‡æ¡£é—®ç­”ã€å¤šæ–‡æ¡£é—®ç­”ã€æ‘˜è¦ã€ä»£ç ç”Ÿæˆç­‰ 14 ä¸ªä»»åŠ¡ |
| **RULER** | åˆæˆåŸºå‡†æµ‹è¯• | åŸºäº â€œneedle-in-a-haystackâ€ èŒƒå¼ï¼Œè¯„ä¼°æ¨¡å‹ä»æé•¿ä¸Šä¸‹æ–‡ä¸­æå–å…³é”®ä¿¡æ¯çš„èƒ½åŠ› |
| **MMLU** | çŸ¥è¯†ç†è§£ | å¤šå­¦ç§‘çŸ¥è¯†é—®ç­” |
| **GSM8K** | æ•°å­¦æ¨ç† | å°å­¦æ•°å­¦åº”ç”¨é¢˜ |
| **HumanEval** | ä»£ç ç”Ÿæˆ | å‡½æ•°çº§ä»£ç è¡¥å…¨ |
| **OlympiadBench** | ç§‘å­¦æ¨ç† | å¥¥èµ›çº§åˆ«æ•°ç†éš¾é¢˜ |
| **MT-Bench-101** | å¤šè½®å¯¹è¯ | è¯„ä¼°å¤šè½®äº¤äº’ä¸­çš„è¿è´¯æ€§ã€æ¨ç†èƒ½åŠ›ç­‰ |

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼š
  - `LLaMA-3.1-8B-Instruct`ï¼ˆ128K contextï¼‰
  - `Qwen2.5-7B-Instruct`ï¼ˆ128K contextï¼‰
- **ç¡¬ä»¶**ï¼šNVIDIA A800 GPUï¼ˆ80GB VRAMï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **ä»»åŠ¡æ€§èƒ½**ï¼šå„æ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡ã€F1ã€å¹³å‡åˆ†ç­‰ã€‚
  - **æ•ˆç‡æŒ‡æ ‡**ï¼š
    - Attention computation latencyï¼ˆprefilling æ—¶é—´ï¼‰
    - Inter-token latency (ITL)ï¼ˆdecoding é€Ÿåº¦ï¼‰
    - KV Cache å†…å­˜å ç”¨
  - æ‰€æœ‰åŸºçº¿å‡åŸºäº **FlashAttention-2** å®ç°ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **MInference [20]**ï¼šè®­ç»ƒå…è´¹ï¼ŒåŠ¨æ€ç¨€ç–ï¼Œä»…åŠ é€Ÿ prefillingã€‚
- **FlexPrefill [21]**ï¼šè®­ç»ƒå…è´¹ï¼Œcontext-awareï¼Œä»…åŠ é€Ÿ prefillingã€‚
- **XAttention [22]**ï¼šå—ç¨€ç– + åå¯¹è§’è¯„åˆ†ï¼Œè®­ç»ƒå…è´¹ï¼Œä»…åŠ é€Ÿ prefillingã€‚
- **SnapKV [23]** / **CAKE [24]**ï¼šKV Cache å‹ç¼©æ–¹æ³•ï¼Œä»…ä¼˜åŒ– decodingã€‚
- **DuoAttention [25]**ï¼šç»Ÿä¸€æ¡†æ¶ï¼Œéœ€è®­ç»ƒï¼Œæ”¯æŒåŒé˜¶æ®µåŠ é€Ÿã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆ128K contextï¼‰

#### âœ… åœ¨ RULER ä¸Šçš„è¡¨ç°ï¼ˆTable IIï¼‰
| æ–¹æ³• | å¹³å‡å¾—åˆ† | æ¨ç†å»¶è¿Ÿ (ms) | åŠ é€Ÿæ¯” |
|------|--------|--------------|-------|
| Full Attention | 87.52 (LLaMA), 82.63 (Qwen) | 1282.05 / 1101.01 | 1Ã— |
| **TCA-Attention (Ours)** | **88.72 / 82.49** | **453.22 / 396.72** | **~2.8Ã—** |

> TCA-Attention åœ¨æ˜¾è‘—åŠ é€Ÿçš„åŒæ—¶ä¿æŒç”šè‡³ç•¥å¾®æå‡æ€§èƒ½ã€‚

#### âœ… åœ¨ LongBench-E ä¸Šçš„è¡¨ç°ï¼ˆTable Iï¼‰
| æ–¹æ³• | å¹³å‡å¾—åˆ† | æ¨ç†å»¶è¿Ÿ (64K) |
|------|--------|--------------|
| Full Attention | 53.19 / 51.16 | 316.14 / 268.55 ms |
| **TCA-Attention (Ours)** | **53.51 / 51.51** | **120.96 / 105.93 ms** |

> å®ç° **2.5â€“2.6Ã— åŠ é€Ÿ**ï¼Œæ€§èƒ½æŒå¹³æˆ–ç•¥ä¼˜ã€‚

#### âœ… KV Cache å‹ç¼©æ•ˆæœï¼ˆFigure 3ï¼‰
- åœ¨ 128K context ä¸‹ï¼ŒKV Cache å†…å­˜ä½¿ç”¨ä» **8.00 GB** é™è‡³ **3.12 GB**ï¼Œ**å‡å°‘ 61%**ã€‚
- æ˜¾è‘—é™ä½æ˜¾å­˜å‹åŠ›ï¼Œä½¿é•¿ä¸Šä¸‹æ–‡æ¨ç†å¯åœ¨æ¶ˆè´¹çº§ GPU ä¸Šè¿è¡Œã€‚

#### âœ… å¤šè½®å¯¹è¯è¡¨ç°ï¼ˆMT-Bench-101ï¼‰
| æ–¹æ³• | å¹³å‡åˆ† |
|------|--------|
| Full Attention | 8.90 |
| FlexPrefill | 8.90 |
| **TCA-Attention** | **8.97** |

> åœ¨å¤æ‚å¯¹è¯åœºæ™¯ä¸­ä»èƒ½æ›´å¥½ä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§å’Œæ¨ç†èƒ½åŠ›ã€‚

#### âœ… ç»¼åˆåŠ é€Ÿèƒ½åŠ›ï¼ˆFigure 3ï¼‰
- **Prefilling latency**: 2.8Ã— speedup
- **Decoding ITL**: 2.1Ã— faster
- **ç«¯åˆ°ç«¯æ¨ç†æ•ˆç‡å…¨é¢æå‡**

### æ¶ˆèå®éªŒç»“æœ

#### ğŸ”¹ Block Size $b$ï¼ˆFigure 4aï¼‰
- æœ€ä½³ block size ä¸º **128**ï¼Œè¿‡å°æ— æ³•æœ‰æ•ˆè¯†åˆ«å†—ä½™ï¼Œè¿‡å¤§åˆ™å¯èƒ½ä¸¢å¤±å…³é”®ä¿¡æ¯ã€‚

#### ğŸ”¹ Local Window Size $w$ï¼ˆFigure 4bï¼‰
- æ€§èƒ½éš $w$ å¢å¤§è€Œæå‡ï¼Œåœ¨ $w=4096$ æ—¶è¾¾åˆ°å³°å€¼ï¼ˆ51.51ï¼‰ã€‚
- å³ä½¿å¤§å¹…å¢åŠ çª—å£ï¼Œå»¶è¿Ÿä»…è½»å¾®ä¸Šå‡ï¼ˆ38.8 â†’ 41.5msï¼‰ï¼Œè¯´æ˜å±€éƒ¨ä¿ç•™ä»£ä»·ä½ã€‚

#### ğŸ”¹ Threshold $T$ï¼ˆFigure 4c & 5ï¼‰
- $T=0.9$ æ—¶æ€§èƒ½æœ€ä½³ï¼Œè¡¨æ˜ä¿ç•™æ›´å¤šä¸Šä¸‹æ–‡æœ‰åŠ©äºå…¨å±€æ¨ç†ä»»åŠ¡ï¼ˆå¦‚ Multi-Document QAã€Codeï¼‰ã€‚
- å¯¹å±€éƒ¨ä»»åŠ¡ï¼ˆå¦‚ Single-Document QAï¼‰å®¹å¿æ›´é«˜å‹ç¼©ç‡ï¼ˆ$T=0.3$ æ—¶æ€§èƒ½ä¸‹é™ <1ptï¼‰ã€‚
- æä¾›å®ç”¨æŒ‡å¯¼ï¼š**ä¿å®ˆé˜ˆå€¼ç”¨äºå…¨å±€ä»»åŠ¡ï¼Œæ¿€è¿›å‹ç¼©ç”¨äºå±€éƒ¨ä»»åŠ¡**ã€‚

#### ğŸ”¹ Balance Parameter $\alpha$ï¼ˆTable VIIIï¼‰
| $\alpha$ | 0.1 | 0.3 | **0.5** | 0.7 | 0.9 |
|---------|-----|-----|--------|-----|-----|
| Average Score | 51.14 | 51.25 | **51.51** | 51.24 | 51.13 |

> æ–¹æ³•å¯¹ $\alpha$ é«˜åº¦é²æ£’ï¼Œæœ€ä¼˜å€¼å‡ºç°åœ¨ä¸­é—´ï¼ˆ$\alpha=0.5$ï¼‰ï¼Œé€‚åˆé»˜è®¤ä½¿ç”¨ã€‚

#### ğŸ”¹ Calibration Datasetï¼ˆTable IXï¼‰
| æ•°æ®é›† | é¢†åŸŸ | å¹³å‡åˆ† |
|--------|------|--------|
| SlimPajama | é€šç”¨ç½‘é¡µ | 51.54 |
| GovReport | æ”¿åºœæ–‡æ¡£ | 51.56 |
| McEval | ç¼–ç¨‹ä»£ç  | 51.55 |

> ä¸åŒé¢†åŸŸæ ¡å‡†æ•°æ®ä¸‹æ€§èƒ½ç¨³å®šï¼Œä¸”**å•æ¡æ ·æœ¬å³å¯å®Œæˆæœ‰æ•ˆæ ¡å‡†**ï¼Œæå…·å®ç”¨æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **TCA-Attention æ˜¯é¦–ä¸ªçœŸæ­£å®ç°â€œè®­ç»ƒå…è´¹ + è¾“å…¥è‡ªé€‚åº” + ç»Ÿä¸€åŠ é€Ÿ prefilling/decodingâ€çš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶**ã€‚
2. é€šè¿‡ **head-specific sparsity configuration + online redundancy-aware token selection**ï¼Œå®ç°äº†ç»†ç²’åº¦ã€é«˜æ•ˆçš„ä¸Šä¸‹æ–‡å‹ç¼©ã€‚
3. åœ¨ 128K context ä¸‹å®ç° **2.8Ã— åŠ é€Ÿ** å’Œ **61% KV Cache å‹ç¼©**ï¼ŒåŒæ—¶æ€§èƒ½**æŒå¹³ç”šè‡³ä¼˜äº full attention**ã€‚
4. æ–¹æ³•å…·æœ‰å¼ºé²æ£’æ€§ï¼Œå¯¹è¶…å‚æ•°å’Œæ ¡å‡†æ•°æ®ä¸æ•æ„Ÿï¼Œé€‚åˆå®é™…éƒ¨ç½²ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ–¹æ³•åŸºäº block-level åˆ’åˆ†ï¼Œå¯èƒ½å¿½ç•¥è·¨ block çš„é‡è¦ tokenã€‚
- å¯¹ extremely long contextï¼ˆ>1M tokensï¼‰çš„æ‰©å±•æ€§å°šæœªéªŒè¯ã€‚
- è™½ç„¶å…è®­ç»ƒï¼Œä½†ä»éœ€ä¸€æ¬¡ç¦»çº¿æ ¡å‡†è¿‡ç¨‹ï¼ˆå°½ç®¡æˆæœ¬æä½ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† TCA-Attention åº”ç”¨äº vision-language models æˆ– multimodal contextsã€‚
- æ¢ç´¢æ›´ç²¾ç»†çš„ token selection ç­–ç•¥ï¼ˆå¦‚ hierarchical selectionï¼‰ã€‚
- ç»“åˆå…¶ä»–é«˜æ•ˆæŠ€æœ¯ï¼ˆå¦‚ MoEã€quantizationï¼‰æ„å»ºå…¨æ ˆä¼˜åŒ–æ¨ç†ç³»ç»Ÿã€‚
- ç ”ç©¶å¦‚ä½•å°†è¯¥æœºåˆ¶åå‘ç”¨äºæ¨¡å‹è§£é‡Šæˆ–æ³¨æ„åŠ›å¯è§†åŒ–ã€‚

---

> **æ€»ç»“**ï¼šTCA-Attention æå‡ºäº†ä¸€ç§ç®€æ´ã€é«˜æ•ˆã€ç†è®ºå¯é ä¸”æ˜“äºéƒ¨ç½²çš„é•¿ä¸Šä¸‹æ–‡ä¼˜åŒ–æ–¹æ¡ˆï¼Œä¸º LLMs åœ¨çœŸå®åœºæ™¯ä¸­çš„å¤§è§„æ¨¡åº”ç”¨æä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æ’‘ã€‚å…¶â€œå…è®­ç»ƒ + è‡ªé€‚åº” + ç»Ÿä¸€åŠ é€Ÿâ€çš„è®¾è®¡ç†å¿µæœ‰æœ›æˆä¸ºæœªæ¥é«˜æ•ˆ attention è®¾è®¡çš„æ ‡å‡†èŒƒå¼ä¹‹ä¸€ã€‚

</details>

---

### 2. [HPM-KD: Hierarchical Progressive Multi-Teacher Framework for Knowledge Distillation and Efficient Model Compression](https://arxiv.org/abs/2512.09886)

**Authors**: Gustavo Coelho Haase, Paulo Henrique Dourado da Silva  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.09886v1  

#### Abstract
Knowledge Distillation (KD) has emerged as a promising technique for model compression but faces critical limitations: (1) sensitivity to hyperparameters requiring extensive manual tuning, (2) capacity gap when distilling from very large teachers to small students, (3) suboptimal coordination in mul...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# HPM-KD: Hierarchical Progressive Multi-Teacher Framework for Knowledge Distillation and Efficient Model Compression  
**è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ä¼ ç»Ÿ **Knowledge Distillation (KD)** æ–¹æ³•ä¸­å­˜åœ¨çš„å››å¤§å…³é”®æŒ‘æˆ˜æå‡ºè§£å†³æ–¹æ¡ˆï¼š
1. **è¶…å‚æ•°æ•æ„Ÿæ€§**ï¼šä¼ ç»ŸKDä¾èµ–å¤§é‡æ‰‹åŠ¨è°ƒå‚ï¼ˆå¦‚æ¸©åº¦ $T$ã€æŸå¤±æƒé‡ $\alpha$ï¼‰ï¼Œç¼ºä¹è‡ªé€‚åº”èƒ½åŠ›ã€‚
2. **å®¹é‡å·®è·ï¼ˆCapacity Gapï¼‰**ï¼šå½“æ•™å¸ˆæ¨¡å‹è¿œå¤§äºå­¦ç”Ÿæ¨¡å‹æ—¶ï¼Œå•æ­¥è’¸é¦éš¾ä»¥æœ‰æ•ˆä¼ é€’çŸ¥è¯†ã€‚
3. **å¤šæ•™å¸ˆåè°ƒä¸ä½³**ï¼šç°æœ‰å¤šæ•™å¸ˆè’¸é¦æ–¹æ³•é‡‡ç”¨å›ºå®šæˆ–å‡åŒ€åŠ æƒç­–ç•¥ï¼Œæ— æ³•åŠ¨æ€é€‚åº”ä¸åŒæ ·æœ¬ä¸‹å„æ•™å¸ˆçš„ä¸“ä¸šä¼˜åŠ¿ã€‚
4. **èµ„æºåˆ©ç”¨æ•ˆç‡ä½**ï¼šé‡å¤å®éªŒå¯¼è‡´è®¡ç®—å†—ä½™ï¼Œç¼ºä¹è·¨å®éªŒçš„çŸ¥è¯†å¤ç”¨æœºåˆ¶ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šHPM-KD æ¡†æ¶
ä½œè€…æå‡ºäº† **HPM-KD**ï¼ˆHierarchical Progressive Multi-Teacher Knowledge Distillationï¼‰ï¼Œä¸€ä¸ªé›†æˆå…­é¡¹ååŒç»„ä»¶çš„ç»¼åˆæ€§æ¡†æ¶ï¼š

| ç»„ä»¶ | åŠŸèƒ½ |
|------|------|
| **Adaptive Configuration Manager (ACM)** | åŸºäº meta-learning è‡ªåŠ¨é¢„æµ‹æœ€ä¼˜è¶…å‚æ•°é…ç½®ï¼Œæ¶ˆé™¤äººå·¥è°ƒå‚ |
| **Progressive Distillation Chain (PDC)** | æ„å»ºè‡ªåŠ¨ç¡®å®šé•¿åº¦çš„ä¸­é—´æ¨¡å‹é“¾ï¼Œé€æ­¥ç¼©å°å¸ˆç”Ÿå®¹é‡å·®è· |
| **Attention-Weighted Multi-Teacher Ensemble (AWMT)** | å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶ä¸ºæ¯ä¸ªæ ·æœ¬åŠ¨æ€åˆ†é…æ•™å¸ˆæƒé‡ |
| **Meta-Learned Temperature Scheduler (MTS)** | åŠ¨æ€è°ƒæ•´è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¸©åº¦ $T$ï¼Œæå‡è½¯æ ‡ç­¾æ ¡å‡†æ•ˆæœ |
| **Parallel Processing Pipeline (PPP)** | å¹¶è¡ŒåŒ–å¤šæ•™å¸ˆä¸æ¸è¿›é˜¶æ®µä»»åŠ¡ï¼Œæ˜¾è‘—ç¼©çŸ­è®­ç»ƒæ—¶é—´ |
| **Shared Optimization Memory (SOM)** | ç¼“å­˜å†å²å®éªŒç»“æœï¼Œæ”¯æŒé…ç½®é‡ç”¨ä¸ warm-start |

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- âœ… **æ— éœ€æ‰‹åŠ¨è°ƒå‚**ï¼šé€šè¿‡ meta-learning å®ç°å…¨è‡ªåŠ¨é…ç½®é€‰æ‹©ã€‚
- âœ… **æ›´å¼ºå‹ç¼©èƒ½åŠ›**ï¼šåœ¨é«˜å‹ç¼©æ¯”åœºæ™¯ï¼ˆ>10Ã—ï¼‰è¡¨ç°æ›´ä¼˜ã€‚
- âœ… **æ›´é«˜çš„çµæ´»æ€§ä¸é²æ£’æ€§**ï¼šå¤šæ•™å¸ˆåŠ¨æ€èåˆå¢å¼ºå¯¹å™ªå£°å’Œç±»åˆ«ä¸å¹³è¡¡çš„å®¹å¿åº¦ã€‚
- âœ… **é«˜æ•ˆèµ„æºåˆ©ç”¨**ï¼šå¹¶è¡Œå¤„ç† + ç¼“å­˜æœºåˆ¶å‡å°‘ 30â€“40% è®­ç»ƒæ—¶é—´ã€‚
- âœ… **æ¨¡å—åŒ–è®¾è®¡**ï¼šå¯çµæ´»æ‰©å±•è‡³å…¶ä»–ä»»åŠ¡æˆ–æ¶æ„ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒè¦†ç›–å›¾åƒåˆ†ç±»ä¸è¡¨æ ¼æ•°æ®ä¸¤ç±»ä»»åŠ¡ï¼š

#### å›¾åƒåˆ†ç±»
- **CIFAR-10**ï¼š60K å›¾åƒï¼Œ32Ã—32ï¼Œ10 ç±»
- **CIFAR-100**ï¼š60K å›¾åƒï¼Œ32Ã—32ï¼Œ100 ç±»

#### è¡¨æ ¼æ•°æ®ï¼ˆæ¥è‡ª UCI ML Repositoryï¼‰
- **Adult**ï¼šæ”¶å…¥é¢„æµ‹ï¼ˆ48,842 æ¡è®°å½•ï¼‰
- **Credit**ï¼šä¿¡ç”¨è¯„ä¼°ï¼ˆ1,000 æ¡ï¼‰
- **Wine Quality**ï¼šè‘¡è„é…’è´¨é‡è¯„åˆ†ï¼ˆ6,497 æ¡ï¼‰

---

### æ¨¡å‹æ¶æ„
| ä»»åŠ¡ | æ•™å¸ˆæ¨¡å‹ | å­¦ç”Ÿæ¨¡å‹ | å‹ç¼©æ¯”ï¼ˆCRï¼‰ |
|------|----------|----------|-------------|
| CIFAR-10/100 | ResNet-56 (~0.85M å‚æ•°) | ResNet-20 (~0.27M å‚æ•°) | 3.1Ã— |
| è¡¨æ ¼æ•°æ® | MLP [256,128,64] (~0.5M) | MLP [64,32] (~0.05M) | 10Ã— |

---

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Student Accuracy (Acc_s)** | å­¦ç”Ÿæ¨¡å‹æœ€ç»ˆå‡†ç¡®ç‡ |
| **Retention Rate (%)** | $\frac{Acc_s}{Acc_{\text{teacher}}} \times 100\%$ |
| **Compression Ratio (CR)** | å‚æ•°é‡æ¯” $\frac{|\theta_t|}{|\theta_s|}$ |
| **Training Time** | æ€»å¢™é’Ÿæ—¶é—´ï¼ˆwall-clock timeï¼‰ |
| **Efficiency (acc/min)** | å‡†ç¡®ç‡ / è®­ç»ƒåˆ†é’Ÿæ•° |
| **Silhouette Score** | è¡¨å¾åˆ†ç¦»æ€§è¡¡é‡ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¯”è¾ƒäº†ä»¥ä¸‹äº”ç§ä¸»æµæ–¹æ³•ï¼š
1. **Direct Training**ï¼šæ— è’¸é¦çš„å­¦ç”Ÿç›´æ¥è®­ç»ƒ
2. **Traditional KD** [Hinton et al., 2015]
3. **FitNets** [Romero et al., 2015]
4. **Attention Transfer (AT)** [Zagoruyko & Komodakis, 2017]
5. **TAKD** [Mirzadeh et al., 2020]ï¼šå¼•å…¥ Teaching Assistant çš„æ¸è¿›è’¸é¦æ–¹æ³•

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆCIFAR-10 ç»“æœæ±‡æ€»ï¼‰

| æ–¹æ³• | Acc (%) | Retention (%) | CR | Training Time (s) |
|------|---------|---------------|----|------------------|
| Teacher (ResNet-56) | 79.28 | 100.0 | 1.0Ã— | 595.2 |
| **HPM-KD (Ours)** | **67.74Â±0.50** | **85.4%** | 3.1Ã— | 603.1 |
| Direct Training | 68.10Â±0.48 | 85.9% | 3.1Ã— | 593.7 |
| Traditional KD | 67.12Â±0.82 | 84.7% | 3.1Ã— | 578.0 |
| FitNets | 62.66Â±0.76 | 79.0% | 3.1Ã— | 592.4 |
| TAKD | 67.44Â±0.40 | 85.1% | 3.1Ã— | 655.5 |

> ğŸ’¡ åœ¨ moderate compression ratioï¼ˆ3.1Ã—ï¼‰ä¸‹ï¼Œ**Direct Training åè€Œç•¥ä¼˜äºæ‰€æœ‰è’¸é¦æ–¹æ³•**ï¼Œè¯´æ˜è’¸é¦å¹¶éæ€»æ˜¯å¿…è¦ã€‚

---

### æ›´é«˜å‹ç¼©æ¯”ä¸‹çš„è¡¨ç°ï¼ˆè¡¨æ ¼æ•°æ®ï¼‰
- å®ç° **10Ã—â€“15Ã— å‹ç¼©**ï¼ŒåŒæ—¶ä¿æŒ **â‰¥85% çš„å‡†ç¡®ç‡ä¿ç•™ç‡**
- æ˜¾è‘—ä¼˜äº Traditional KDã€FitNets å’Œ AT
- åœ¨ tabular æ•°æ®ä¸ŠéªŒè¯äº†é€šç”¨æ€§å’Œæœ‰æ•ˆæ€§

---

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ
- **ç›¸æ¯” Traditional KD**ï¼šHPM-KD æå‡ +0.62 ppï¼ˆCIFAR-10ï¼‰
- **ç›¸æ¯” FitNets**ï¼šæå‡ +5.08 pp
- **ç›¸æ¯” TAKD**ï¼šç²¾åº¦ç›¸å½“ï¼ˆ67.74 vs 67.44ï¼‰ï¼Œä½†è®­ç»ƒæ—¶é—´æ›´ç¨³å®šï¼ˆæ–¹å·®æ›´ä½ï¼‰ï¼Œä¸”æ— éœ€æ‰‹åŠ¨è®¾è®¡ Teaching Assistant
- **æ•ˆç‡æ–¹é¢**ï¼šé€šè¿‡ PPP å®ç° **30â€“40% æ—¶é—´èŠ‚çœ**ï¼Œ4 worker ä¸‹è¾¾ 2.78Ã— åŠ é€Ÿ

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Study on CIFAR-100ï¼‰

| é…ç½® | Acc (%) | Î” (pp) | Retention (%) |
|------|--------|--------|--------------|
| Full HPM-KD | 36.28Â±0.52 | 0.00 | 100.0 |
| w/o MultiTeach | 35.30Â±0.85 | -0.98 | 97.3 |
| w/o MetaTemp | 35.63Â±0.41 | -0.65 | 98.2 |
| w/o Memory / Parallel | 35.67Â±0.51 | -0.61 | 98.3 |
| w/o ProgChain | 36.06Â±0.31 | -0.22 | 99.4 |
| w/o AdaptConf | 36.18Â±0.38 | -0.10 | 99.7 |

> ğŸ” **Multi-Teacher Ensemble æ˜¯æœ€å…³é”®ç»„ä»¶**ï¼ˆå½±å“æœ€å¤§ï¼‰ï¼Œå…¶æ¬¡æ˜¯ Meta-Temperature Scheduler å’Œå¹¶è¡Œ/ç¼“å­˜ç³»ç»Ÿã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **HPM-KD æˆåŠŸæ•´åˆå…­å¤§ç»„ä»¶ï¼Œåœ¨å¤šä¸ªç»´åº¦è¶…è¶Šç°æœ‰æ–¹æ³•**ï¼š
   - å®ç°è‡ªåŠ¨åŒ–ã€é«˜æ•ˆã€é²æ£’çš„çŸ¥è¯†è’¸é¦æµç¨‹
   - åœ¨é«˜å‹ç¼©æ¯”ï¼ˆ>10Ã—ï¼‰å’Œå¤æ‚åœºæ™¯ä¸‹æ›´å…·ä¼˜åŠ¿

2. **è’¸é¦ä¸ä¸€å®šä¼˜äºç›´æ¥è®­ç»ƒ**ï¼š
   - å½“å‹ç¼©æ¯”é€‚ä¸­ï¼ˆå¦‚ 3.1Ã—ï¼‰ã€å­¦ç”Ÿæ¨¡å‹å…·å¤‡è¶³å¤Ÿå®¹é‡æ—¶ï¼Œ**Direct Training å¯èƒ½æ›´ç®€å•æœ‰æ•ˆ**
   - è’¸é¦çš„ä»·å€¼ä½“ç°åœ¨ï¼šå¤§å®¹é‡å·®è·ã€å¤šæ•™å¸ˆå¯ç”¨ã€éœ€æŠ—å™ª/æŠ—ä¸å¹³è¡¡ç­‰åœºæ™¯

3. **å¤šæ•™å¸ˆæ³¨æ„åŠ›æœºåˆ¶è‡³å…³é‡è¦**ï¼š
   - ä¸åŒæ•™å¸ˆåœ¨ä¸åŒç±»åˆ«ä¸Šè¡¨ç°å‡ºä¸“é•¿
   - åŠ¨æ€åŠ æƒæ˜¾è‘—æå‡æ³›åŒ–èƒ½åŠ›å’Œç¨³å®šæ€§

4. **å¯¹å™ªå£°å’Œç±»åˆ«ä¸å¹³è¡¡å…·æœ‰å¼ºé²æ£’æ€§**ï¼š
   - å³ä½¿åœ¨ **30% æ ‡ç­¾å™ªå£°** æˆ– **100:1 ç±»åˆ«ä¸å¹³è¡¡** ä¸‹ï¼Œæ€§èƒ½ä¸‹é™æœ‰é™ï¼ˆ<1ppï¼‰
   - æ¨æµ‹åŸå› ï¼šæ•™å¸ˆçš„ soft targets å…·æœ‰æ­£åˆ™åŒ–ä½œç”¨ï¼Œå¯è¿‡æ»¤å™ªå£°

5. **å¹¶è¡Œä¸ç¼“å­˜å¸¦æ¥æ˜¾è‘—æ•ˆç‡å¢ç›Š**ï¼š
   - å¹¶è¡ŒåŒ–å®ç°è¿‘çº¿æ€§åŠ é€Ÿï¼ˆç†è®ºå¯è¾¾ KÃ—ï¼‰
   - ç¼“å­˜å‘½ä¸­ç‡è¾¾ 30â€“40%ï¼Œé¿å…é‡å¤è®¡ç®—

---

### æ–¹æ³•çš„å±€é™æ€§
| å±€é™ | æè¿° |
|------|------|
| **éªŒè¯èŒƒå›´æœ‰é™** | ä¸»è¦åœ¨ CIFAR å’Œå°å‹è¡¨æ ¼æ•°æ®ä¸Šæµ‹è¯•ï¼Œå°šæœªåœ¨ ImageNetã€NLP æˆ–åŒ»ç–—å½±åƒç­‰å¤§è§„æ¨¡ä»»åŠ¡éªŒè¯ |
| **å‹ç¼©æ¯”ä¸­ç­‰** | å½“å‰å®éªŒé›†ä¸­åœ¨ 3.1Ã—â€“10Ã—ï¼Œæœªå……åˆ†æ¢ç´¢æç«¯å‹ç¼©ï¼ˆå¦‚ 50â€“100Ã—ï¼‰åœºæ™¯ |
| **ç†è®ºåˆ†æç¼ºå¤±** | ç¼ºä¹å¯¹æ”¶æ•›æ€§ã€æ³›åŒ–ç•Œæˆ– PAC æ¡†æ¶çš„å½¢å¼åŒ–è¯æ˜ |
| **å†·å¯åŠ¨é—®é¢˜** | ACM éœ€è¦çº¦ 5 æ¬¡å†å²è¿è¡Œæ‰èƒ½å‡†ç¡®é¢„æµ‹é…ç½®ï¼Œåœ¨å…¨æ–°é¢†åŸŸå¯èƒ½å¤±æ•ˆ |
| **è®¡ç®—å¼€é”€å¢åŠ ** | ç›¸æ¯” Traditional KDï¼Œå› å¤šæ•™å¸ˆå’Œæ¸è¿›é“¾å¯¼è‡´æ€»è®¡ç®—é‡ä¸Šå‡ 30â€“40% |

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•åˆ° Large Language Models (LLMs)**ï¼šç”¨äºå‹ç¼© GPT ç±»åƒäº¿å‚æ•°æ¨¡å‹
2. **Cross-Modal Distillation**ï¼šä» CLIPã€Flamingo ç­‰å¤šæ¨¡æ€æ¨¡å‹è’¸é¦åˆ°å•æ¨¡æ€ä¸“ç”¨æ¨¡å‹
3. **Theoretical Analysis**ï¼šæ¨å¯¼ progressive distillation çš„æ³›åŒ–è¾¹ç•Œ
4. **Distillation-Aware Architecture Search (DAAS)**ï¼šè”åˆä¼˜åŒ–ç½‘ç»œç»“æ„ä¸è’¸é¦ç­–ç•¥
5. **Federated Knowledge Distillation**ï¼šæ”¯æŒåˆ†å¸ƒå¼è®¾å¤‡ä¸Šçš„éšç§ä¿æŠ¤è’¸é¦
6. **Continuous Distillation**ï¼šæ”¯æŒæ•™å¸ˆæŒç»­æ›´æ–°ä¸‹çš„å¢é‡å­¦ç”Ÿå­¦ä¹ ï¼ˆlifelong learningï¼‰

---

## æ€»ç»“
HPM-KD æ˜¯ä¸€ä¸ªé¢å‘ç”Ÿäº§éƒ¨ç½²çš„ã€é«˜åº¦è‡ªåŠ¨åŒ–ä¸”é«˜æ•ˆçš„å¤šæ•™å¸ˆçŸ¥è¯†è’¸é¦æ¡†æ¶ã€‚å®ƒé€šè¿‡ **meta-learningã€progressive chainã€attention-weighted ensembleã€dynamic temperature schedulingã€parallelization ä¸ caching** å…­å¤§ç»„ä»¶ååŒå·¥ä½œï¼Œè§£å†³äº†ä¼ ç»Ÿ KD ä¸­çš„æ‰‹åŠ¨è°ƒå‚ã€å®¹é‡æ–­å±‚ã€èµ„æºæµªè´¹ç­‰é—®é¢˜ã€‚

å°½ç®¡åœ¨è½»åº¦å‹ç¼©åœºæ™¯ä¸‹ä¸å¦‚ Direct Training ç®€æ´é«˜æ•ˆï¼Œä½†åœ¨ **é«˜å‹ç¼©æ¯”ã€å¤šæ•™å¸ˆã€å™ªå£°ç¯å¢ƒæˆ–éœ€è¦å¿«é€Ÿè¿­ä»£çš„ MLOps åœºæ™¯ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›**ã€‚å…¶å¼€æºå®ç°ï¼ˆDeepBridge åº“ï¼‰é™ä½äº†å·¥ä¸šè½åœ°é—¨æ§›ï¼Œæ¨åŠ¨äº† AI democratization è¿›ç¨‹ã€‚

</details>

---

### 3. [SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments](https://arxiv.org/abs/2512.09897)

**Authors**: Haoye Lu, Pavan Seshadri, Kaheer Suleman  
**Category**: cs.AI  
**Published**: 2025-12-11  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.09897v1  

#### Abstract
Long-term planning in complex, text-based environments presents significant challenges due to open-ended action spaces, ambiguous observations, and sparse feedback. Recent research suggests that large language models (LLMs) encode rich semantic knowledge about the world, which can be valuable for gu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨å¤æ‚çš„æ–‡æœ¬ç¯å¢ƒï¼ˆtext-based environmentsï¼‰ä¸­è¿›è¡Œé•¿æœŸè§„åˆ’ï¼ˆlong-term planningï¼‰é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **å¼€æ”¾çš„åŠ¨ä½œç©ºé—´**ï¼ˆopen-ended action spacesï¼‰
- **æ¨¡ç³Šçš„è§‚æµ‹çŠ¶æ€**ï¼ˆambiguous observationsï¼‰
- **ç¨€ç–çš„å¥–åŠ±åé¦ˆ**ï¼ˆsparse feedbackï¼‰

ç°æœ‰åŸºäº **Large Language Models (LLMs)** çš„åˆ†å±‚è§„åˆ’æ–¹æ³•è™½ç„¶èƒ½åˆ©ç”¨ LLM çš„è¯­ä¹‰çŸ¥è¯†æŒ‡å¯¼æ™ºèƒ½ä½“è¿›è¡Œé«˜å±‚æ¨ç†ï¼Œä½†å­˜åœ¨ä¸¤ä¸ªæ˜¾è‘—ç¼ºé™·ï¼š
1. **è®¡ç®—æˆæœ¬é«˜**ï¼šéœ€è¦åœ¨è®­ç»ƒå’Œæ¨ç†é˜¶æ®µåå¤è°ƒç”¨ LLMï¼Œå¯¼è‡´å»¶è¿Ÿé«˜ã€éƒ¨ç½²å›°éš¾ã€‚
2. **ç¼ºä¹é€‚åº”æ€§**ï¼šLLM é€šå¸¸ä½œä¸ºå†»ç»“æ¨¡å‹ï¼ˆfrozenï¼‰ä½¿ç”¨ï¼Œæ— æ³•é’ˆå¯¹ç›®æ ‡ä»»åŠ¡è¿›è¡Œå‚æ•°æ›´æ–°ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šSCOPE
ä½œè€…æå‡º **SCOPE**ï¼ˆSubgoal-COnditioned Pretraining for Efficient planningï¼‰ï¼Œä¸€ç§é«˜æ•ˆçš„**ä¸€æ¬¡æ€§æ•™å¸ˆæ¡†æ¶**ï¼ˆone-time teacher frameworkï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **ä»…åœ¨åˆå§‹åŒ–é˜¶æ®µä½¿ç”¨ä¸€æ¬¡ LLM**ï¼Œä»äººç±»æä¾›çš„æ¬¡ä¼˜ç¤ºèŒƒè½¨è¿¹ï¼ˆsuboptimal demonstration trajectoriesï¼‰ä¸­æå–å­ç›®æ ‡ï¼ˆsubgoalsï¼‰ã€‚
- åˆ©ç”¨è¿™äº› LLM ç”Ÿæˆçš„å­ç›®æ ‡å¯¹ä¸€ä¸ªè½»é‡çº§å­¦ç”Ÿæ¨¡å‹ï¼ˆlightweight student modelï¼‰è¿›è¡Œé¢„è®­ç»ƒã€‚
- åç»­é€šè¿‡ **Reinforcement Learning (RL)** åœ¨ä¸–ç•Œæ¨¡å‹ï¼ˆworld modelï¼‰ä¸Šè¿›ä¸€æ­¥å¾®è°ƒï¼Œå®ç°ç‹¬ç«‹è¿è¡Œã€‚

#### åˆ›æ–°ç‚¹ï¼š
1. **å»ä¾èµ–åŒ– LLM æ¨ç†**ï¼šä¸å†åœ¨è®­ç»ƒæˆ–æ¨ç†è¿‡ç¨‹ä¸­é‡å¤æŸ¥è¯¢ LLMï¼Œæå¤§æå‡æ•ˆç‡ã€‚
2. **é«˜æ•ˆçš„çŸ¥è¯†è’¸é¦æ–¹å¼**ï¼šä¸åŒäºä¼ ç»Ÿâ€œåœ¨çº¿è’¸é¦â€ï¼ˆonline distillationï¼‰ï¼ŒSCOPE é‡‡ç”¨â€œç¦»çº¿è’¸é¦â€â€”â€”ç›´æ¥ä»ç¤ºèŒƒè½¨è¿¹ä¸­è§£æå‡ºå­ç›®æ ‡åºåˆ—ã€‚
3. **åŒå±‚çº§æ¶æ„è®¾è®¡**ï¼š
   - **Manager Agent**ï¼šè´Ÿè´£æå‡ºé«˜å±‚å­ç›®æ ‡ï¼ˆhigh-level planningï¼‰ã€‚
   - **Employee Agent**ï¼šè´Ÿè´£æ‰§è¡Œå…·ä½“åŠ¨ä½œä»¥å®Œæˆå­ç›®æ ‡ï¼ˆlow-level executionï¼‰ã€‚
4. **å¯æ‰©å±•æ€§å¼º**ï¼šé€‚ç”¨äºçº¯æ–‡æœ¬ç¯å¢ƒï¼Œæ— éœ€è§†è§‰æˆ–ç‰©ç†äº¤äº’å»ºæ¨¡ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ADaPT (Prasad et al., 2024) | SCOPE (æœ¬æ–‡) |
|------|----------------------------|-------------|
| æ˜¯å¦ä¾èµ– LLM æ¨ç† | æ˜¯ï¼ˆæ¯æ¬¡å†³ç­–éƒ½è°ƒç”¨ GPT-3.5ï¼‰ | å¦ï¼ˆä»…åˆå§‹åŒ–æ—¶ç”¨ä¸€æ¬¡ï¼‰ |
| å‚æ•°é‡ | 175Bï¼ˆGPT-3.5ï¼‰ | 11.04Mï¼ˆå°å‹ç¥ç»ç½‘ç»œï¼‰ |
| æ¨ç†æ—¶é—´ | 164.4 ç§’ | **3.0 ç§’** |
| æˆåŠŸç‡ï¼ˆsuccess rateï¼‰ | 0.52 | **0.56** |
| éƒ¨ç½²æˆæœ¬ | é«˜ï¼ˆAPI è°ƒç”¨ + ç½‘ç»œå»¶è¿Ÿï¼‰ | æä½ï¼ˆæœ¬åœ° GPU å¯è¿è¡Œï¼‰ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼š**æ›´é«˜æ€§èƒ½ + æ›´ä½æˆæœ¬ + æ›´å¿«æ¨ç† + æ›´æ˜“éƒ¨ç½²**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- ä½¿ç”¨ **TextCraft** ç¯å¢ƒï¼ˆPrasad et al., 2024 æå‡ºï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå— Minecraft å¯å‘çš„ç®€åŒ–ç‰ˆçº¯æ–‡æœ¬åˆæˆä»»åŠ¡ç¯å¢ƒã€‚
- æ™ºèƒ½ä½“éœ€æ ¹æ®ç›®æ ‡ç‰©å“ï¼ˆå¦‚â€œlime stained glass paneâ€ï¼‰å’Œå¯ç”¨é…æ–¹æŒ‡ä»¤ï¼Œé€šè¿‡ `craft` å’Œ `get` å‘½ä»¤é€æ­¥æ”¶é›†åŸºç¡€ææ–™ã€åˆ¶é€ ä¸­é—´å“ï¼Œæœ€ç»ˆåˆæˆç›®æ ‡ç‰©å“ã€‚
- è§‚æµ‹ä¸ºæ–‡æœ¬æè¿°çš„çŠ¶æ€ï¼ˆinventory å­—å…¸ï¼‰ï¼ŒåŠ¨ä½œä¸ºè‡ªç„¶è¯­è¨€å‘½ä»¤ã€‚

#### æ•°æ®ç”Ÿæˆï¼š
- äººå·¥æ¨¡æ‹Ÿ **50ä¸‡æ¡æ¬¡ä¼˜è½¨è¿¹**ï¼ˆsuboptimal trajectoriesï¼‰ï¼Œå…¶ä¸­åŒ…å«çº¦ 10% çš„éšæœºå™ªå£°åŠ¨ä½œï¼Œä»¥æ¨¡ä»¿äººç±»æ¢ç´¢è¡Œä¸ºã€‚
- å…¶ä¸­ 1K æ¡ç”¨äºéªŒè¯å’Œæµ‹è¯•ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### ä¸»è¦ç»„ä»¶ï¼š
- **LLM å­ç›®æ ‡ç”Ÿæˆå™¨**ï¼šä½¿ç”¨ LLM åˆ†æç¤ºèŒƒè½¨è¿¹ï¼Œè¾“å‡º `fac(T)` å‡½æ•°è‡ªåŠ¨åˆ†è§£å­ç›®æ ‡åºåˆ—ã€‚
- **Manager Agent**ï¼šå­¦ä¹ åœ¨å½“å‰çŠ¶æ€ä¸‹é€‰æ‹©ä¸‹ä¸€ä¸ªå­ç›®æ ‡ã€‚
- **Employee Agent**ï¼šå­¦ä¹ å¦‚ä½•å®Œæˆç»™å®šå­ç›®æ ‡ã€‚
- **World Model**ï¼šåŸºäºç¤ºèŒƒæ•°æ®è®­ç»ƒçš„ç¯å¢ƒæ¨¡æ‹Ÿå™¨ï¼Œç”¨äº RL å¾®è°ƒé˜¶æ®µé¿å…çœŸå®ç¯å¢ƒäº¤äº’å¼€é”€ã€‚

#### è®­ç»ƒæµç¨‹ï¼š
1. **é¢„è®­ç»ƒé˜¶æ®µ**ï¼š
   - Managerï¼šå­¦ä¹ é‡ç° LLM ç”Ÿæˆçš„å­ç›®æ ‡åºåˆ—ã€‚
   - Employeeï¼šæ¨¡ä»¿ç¤ºèŒƒè½¨è¿¹ä¸­çš„åŠ¨ä½œåºåˆ—ã€‚
2. **RL å¾®è°ƒé˜¶æ®µ**ï¼š
   - ä½¿ç”¨ **Cross-Entropy Method (CEM)** ç®—æ³•ï¼Œåœ¨ä¸–ç•Œæ¨¡å‹ä¸­é‡‡æ ·æˆåŠŸè½¨è¿¹å¹¶åŠ æƒæ›´æ–°ç­–ç•¥ã€‚
   - ç›®æ ‡ï¼šæœ€å¤§åŒ–æœ€ç»ˆç›®æ ‡è¾¾æˆç‡ï¼ˆgoal achievement rateï¼‰ã€‚

#### è¯„ä¼°æŒ‡æ ‡ï¼š
- **Success Rate**ï¼šæˆåŠŸå®Œæˆç›®æ ‡ä»»åŠ¡çš„æ¯”ä¾‹ã€‚
- **Inference Time**ï¼šå•æ¬¡æ¸¸æˆå¹³å‡è€—æ—¶ï¼ˆç§’ï¼‰ã€‚
- **#Parameters**ï¼šæ¨¡å‹æ€»å‚æ•°é‡ã€‚
- **æ¶ˆèå®éªŒ**ï¼šéªŒè¯ä¸åŒå­ç›®æ ‡è´¨é‡çš„å½±å“ã€‚

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ADaPT (Prasad et al., 2024)**ï¼šåŸºäº LLM çš„åˆ†å±‚è§„åˆ’å™¨ï¼Œä½¿ç”¨ GPT-3.5 åŠ¨æ€ç”Ÿæˆå­ç›®æ ‡ã€‚
- å¤šç§ LLM åç«¯ç‰ˆæœ¬å¯¹æ¯”ï¼ˆè§ Table 4ï¼‰ï¼š
  - GPT-3.5ã€GPT-4oã€GPT-4o mini
  - Mistral Small 3ã€Claude-3 Haikuã€DeepSeek-R1-Distill-Qwen-32B

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 3ï¼‰

| æ–¹æ³• | Success Rate | #Parameters |
|------|--------------|------------|
| ADaPT (GPT-3.5) | 0.52 | 175B |
| **SCOPE (ours)** | **0.56** | **11.04M** |
| SCOPE (hand-engineered subgoal) | 0.58 | 11.04M |
| SCOPE (without manager RL-finetuning) | 0.24 | 11.04M |

> âœ… **æ ¸å¿ƒç»“æœ**ï¼šSCOPE åœ¨ä»…ä½¿ç”¨ **11M å‚æ•°**çš„æƒ…å†µä¸‹ï¼Œ**è¶…è¶Šäº† 175B å‚æ•°çš„ ADaPT**ï¼ŒæˆåŠŸç‡æå‡è‡³ **0.56**ã€‚

---

### â±ï¸ æ•ˆç‡å¯¹æ¯”
- **SCOPE**ï¼šå¹³å‡ **3.0 ç§’** å®Œæˆæ¸¸æˆï¼ˆNVIDIA A10 GPUï¼‰
- **ADaPT**ï¼šå¹³å‡ **164.4 ç§’**ï¼ˆGPT-3.5 APIï¼Œç†æƒ³ç½‘ç»œæ¡ä»¶ä¸‹ï¼‰

> ğŸ’¡ **é€Ÿåº¦æå‡è¶…è¿‡ 50 å€**ï¼Œä¸”ä¸ä¾èµ–å¤–éƒ¨ APIã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰å­ç›®æ ‡æ¥æºçš„å½±å“ï¼ˆTable 3ï¼‰
- ä½¿ç”¨æ‰‹å·¥è®¾è®¡çš„å¯è§£é‡Šå­ç›®æ ‡ï¼ˆhand-engineered subgoalsï¼‰å¯å°†æˆåŠŸç‡è¿›ä¸€æ­¥æå‡åˆ° **0.58**ã€‚
- è¡¨æ˜ LLM ç”Ÿæˆçš„å­ç›®æ ‡è™½ä¸å¤Ÿé€æ˜ï¼Œä½†ä»æä¾›äº†æœ‰æ•ˆå¼•å¯¼ã€‚

#### ï¼ˆ2ï¼‰æ˜¯å¦è¿›è¡Œ Manager RL å¾®è°ƒ
- è‹¥ç§»é™¤ Manager çš„ RL å¾®è°ƒé˜¶æ®µï¼ŒæˆåŠŸç‡éª¤é™è‡³ **0.24**ã€‚
- è¯´æ˜ **RL å¾®è°ƒå¯¹äºè¡¥å¿ Employee ä¸å®Œç¾æ‰§è¡Œè‡³å…³é‡è¦**ã€‚

#### ï¼ˆ3ï¼‰å­ç›®æ ‡æ¨¡ç³Šæ€§å½±å“ï¼ˆFigure 8aï¼‰
- ç§»é™¤æ•°é‡ä¿¡æ¯ï¼ˆ`SCOPE (no quantity)`ï¼‰åæ€§èƒ½ä¸‹é™ã€‚
- éåˆ†å±‚æ¨¡å‹ï¼ˆNon-Hierarchicalï¼‰è¡¨ç°æœ€å·®ï¼Œè¡¨æ˜**å­ç›®æ ‡ç»“æ„æœ¬èº«å…·æœ‰ä»·å€¼**ã€‚

#### ï¼ˆ4ï¼‰å­ç›®æ ‡ä¸ç¯å¢ƒé”™é…å®éªŒï¼ˆFigure 8bï¼‰
- å½“éšæœºé‡å‘½åå­ç›®æ ‡ä¸­ç‰©å“åç§°æ¯”ä¾‹å¢åŠ ï¼ˆp=0â†’1.0ï¼‰ï¼š
  - p=0.25 æ—¶ï¼ŒæˆåŠŸç‡å·²é™è‡³ 0.09
  - p=1.0 æ—¶ï¼Œå‡ ä¹å®Œå…¨å¤±è´¥ï¼ˆ0.02ï¼‰
- ç»“è®ºï¼š**å­ç›®æ ‡å¿…é¡»ä¸çœŸå®ç¯å¢ƒå› æœå¯¹é½**ï¼Œå¦åˆ™ä¼šè¯¯å¯¼æ™ºèƒ½ä½“ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å³ä½¿æ¬¡ä¼˜çš„ LLM ç”Ÿæˆå­ç›®æ ‡ä¹Ÿèƒ½æä¾›å¼ºå¤§å…ˆéªŒçŸ¥è¯†**ï¼š
   - å°½ç®¡ LLM æœªä¸ç¯å¢ƒäº¤äº’ï¼Œå…¶ç”Ÿæˆçš„å­ç›®æ ‡ä»å¯ä½œä¸ºæœ‰æ•ˆçš„åˆ†å±‚è§„åˆ’èµ·ç‚¹ã€‚
2. **ä¸€æ¬¡æ€§çš„ LLM æ•™å­¦è¶³ä»¥æ”¯æŒé«˜æ€§èƒ½æ™ºèƒ½ä½“è®­ç»ƒ**ï¼š
   - ä¸éœ€è¦æŒç»­è°ƒç”¨ LLMï¼Œå³å¯è·å¾—ä¼˜äºå®æ—¶ LLM æ¨ç†çš„æ•ˆæœã€‚
3. **åˆ†å±‚ç»“æ„ + RL å¾®è°ƒæ˜¯å…³é”®**ï¼š
   - Manager èƒ½é€šè¿‡ RL å­¦ä¹ åŠ¨æ€è°ƒæ•´è®¡åˆ’ï¼Œå¼¥è¡¥ Employee æ‰§è¡Œè¯¯å·®ã€‚
4. **æ•ˆç‡ä¸æ€§èƒ½å…¼å¾—**ï¼š
   - SCOPE åœ¨æ›´å°æ¨¡å‹ã€æ›´ä½å»¶è¿Ÿä¸‹å®ç°äº†æ›´é«˜æˆåŠŸç‡ï¼Œå±•ç¤ºäº†æé«˜çš„å‚æ•°æ•ˆç‡ï¼ˆparameter efficiencyï¼‰ã€‚

---

### âš ï¸ å±€é™æ€§
1. **å­ç›®æ ‡ä¸å¯è§£é‡Šæ€§**ï¼š
   - LLM ç”Ÿæˆçš„å­ç›®æ ‡ç¼ºä¹è¯­ä¹‰æ¸…æ™°æ€§ï¼Œéš¾ä»¥è°ƒè¯•å’Œåˆ†æã€‚
2. **ä¾èµ–é«˜è´¨é‡ç¤ºèŒƒè½¨è¿¹**ï¼š
   - è‹¥ç¤ºèŒƒè½¨è¿¹è¿‡äºæ··ä¹±æˆ–åç¦»ä¸»çº¿ï¼ŒLLM æå–çš„å­ç›®æ ‡å¯èƒ½ä¸¥é‡å¤±çœŸã€‚
3. **å½“å‰ä»…éªŒè¯äº TextCraft**ï¼š
   - è™½ç„¶è¯¥ç¯å¢ƒå…·å¤‡ä»£è¡¨æ€§ï¼Œä½†åœ¨æ›´å¤æ‚ã€åŠ¨æ€å˜åŒ–çš„ä»»åŠ¡ä¸­æ³›åŒ–èƒ½åŠ›æœ‰å¾…éªŒè¯ã€‚
4. **ä¸–ç•Œæ¨¡å‹ç²¾åº¦é™åˆ¶**ï¼š
   - æ‰€æœ‰ RL å¾®è°ƒå‡åœ¨ä¸–ç•Œæ¨¡å‹ä¸­è¿›è¡Œï¼Œè‹¥ä¸–ç•Œæ¨¡å‹å»ºæ¨¡ä¸å‡†ï¼Œä¼šå½±å“æœ€ç»ˆæ€§èƒ½ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ”¹è¿›å­ç›®æ ‡ç”Ÿæˆçš„å¯è§£é‡Šæ€§**ï¼š
   - å¼•å…¥çº¦æŸæœºåˆ¶æˆ–æç¤ºå·¥ç¨‹ï¼Œä½¿ LLM è¾“å‡ºæ›´å…·é€»è¾‘æ€§å’Œå¯è¯»æ€§çš„å­ç›®æ ‡ã€‚
2. **ç»“åˆåœ¨çº¿ LLM æŸ¥è¯¢è¿›è¡Œè‡ªé€‚åº”ä¿®æ­£**ï¼š
   - åœ¨å…³é”®èŠ‚ç‚¹å¼•å…¥å°‘é‡ LLM æŸ¥è¯¢ï¼Œå¹³è¡¡æ•ˆç‡ä¸çµæ´»æ€§ã€‚
3. **æ‰©å±•åˆ°å¤šæ¨¡æ€ç¯å¢ƒ**ï¼š
   - å°† SCOPE æ€è·¯åº”ç”¨äº Vision-Language-Action åœºæ™¯ï¼ˆå¦‚ ALFWorldã€Minecraft GUIï¼‰ã€‚
4. **æ¢ç´¢æ›´å¼ºå¤§çš„è½»é‡çº§å­¦ç”Ÿæ¨¡å‹æ¶æ„**ï¼š
   - å¦‚ä½¿ç”¨ MoE æˆ– TinyLLM æ›¿ä»£å½“å‰ LSTM æ¶æ„ï¼Œè¿›ä¸€æ­¥æå‡æ€§èƒ½è¾¹ç•Œã€‚

---

## âœ… æ€»ç»“
**SCOPE** æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é«˜æ•ˆçš„èŒƒå¼ï¼šå°† LLM ä½œä¸ºâ€œä¸€æ¬¡æ€§æ•™å¸ˆâ€ï¼Œä»…åœ¨è®­ç»ƒåˆæœŸæä¾›å­ç›®æ ‡æŒ‡å¯¼ï¼Œéšåç”±è½»é‡çº§å­¦ç”Ÿæ¨¡å‹è‡ªä¸»å­¦ä¹ å¹¶ä¼˜åŒ–ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§æ–¹æ³•ä¸ä»…åœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†ä¾èµ–å®æ—¶ LLM æ¨ç†çš„å…ˆè¿›ç³»ç»Ÿï¼ˆå¦‚ ADaPTï¼‰ï¼Œè¿˜åœ¨æ¨ç†é€Ÿåº¦å’Œéƒ¨ç½²æˆæœ¬ä¸Šå–å¾—å·¨å¤§ä¼˜åŠ¿ã€‚å®ƒä¸ºæ„å»º**é«˜æ•ˆã€å¯æ‰©å±•ã€ä½å»¶è¿Ÿçš„æ–‡æœ¬ç¯å¢ƒæ™ºèƒ½ä½“**æä¾›äº†é‡è¦æ€è·¯ï¼Œæ¨åŠ¨äº† LLM ä¸å¼ºåŒ–å­¦ä¹ èåˆç ”ç©¶å‘å®ç”¨åŒ–è¿ˆè¿›ã€‚

</details>

---

### 4. [Scalable Construction of Spiking Neural Networks using up to thousands of GPUs](https://arxiv.org/abs/2512.09502)

**Authors**: Bruno Golosio, Gianmarco Tiddia, Jos\'e Villamar, Luca Pontisso, Luca Sergi, Francesco Simula, Pooja Babu, Elena Pastorelli, Abigail Morrison, Markus Diesmann, Alessandro Lonardo, Pier Stanislao Paolucci, Johanna Senk  
**Category**: cs.DC  
**Published**: 2025-12-11  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.09502v1  

#### Abstract
Diverse scientific and engineering research areas deal with discrete, time-stamped changes in large systems of interacting delay differential equations. Simulating such complex systems at scale on high-performance computing clusters demands efficient management of communication and memory. Inspired ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬è®ºæ–‡æ—¨åœ¨è§£å†³**å¤§è§„æ¨¡è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSpiking Neural Networks, SNNsï¼‰åœ¨å¤šGPUé›†ç¾¤å’Œä¸‹ä¸€ä»£Exascaleè¶…çº§è®¡ç®—æœºä¸Šé«˜æ•ˆæ„å»ºä¸æ¨¡æ‹Ÿçš„æŒ‘æˆ˜**ã€‚å…·ä½“è€Œè¨€ï¼Œä¼ ç»Ÿæ–¹æ³•åœ¨ç½‘ç»œæ„å»ºé˜¶æ®µå­˜åœ¨ä»¥ä¸‹ç“¶é¢ˆï¼š
- éœ€è¦è·¨MPIè¿›ç¨‹é€šä¿¡æ¥ç”Ÿæˆè¿œç¨‹è¿æ¥ï¼Œå¯¼è‡´é«˜å»¶è¿Ÿï¼›
- æ•°æ®ç»“æ„ç®¡ç†æ•ˆç‡ä½ï¼Œå½±å“å†…å­˜å ç”¨å’Œé€šä¿¡å¼€é”€ï¼›
- ç¼ºä¹å¯¹GPUå†…å­˜ä½¿ç”¨çš„çµæ´»ä¼˜åŒ–æœºåˆ¶ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†SNNä»¿çœŸåœ¨è„‘ç§‘å­¦ç­‰éœ€è¦äº¿çº§ç¥ç»å…ƒã€ä¸‡äº¿çº§çªè§¦è§„æ¨¡åœºæ™¯ä¸‹çš„å¯æ‰©å±•æ€§ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§**åŸºäºMPIçš„æ–°å‹ç½‘ç»œæ„å»ºç®—æ³•**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**å…¨GPUç«¯ï¼ˆonboardï¼‰ç½‘ç»œæ„å»º**
- æ‰€æœ‰ç¥ç»å…ƒå’Œè¿æ¥ï¼ˆåŒ…æ‹¬æœ¬åœ°å’Œè¿œç¨‹ï¼‰å‡ç›´æ¥åœ¨GPUå†…å­˜ä¸­å®Œæˆåˆ›å»ºï¼Œæ— éœ€ä»CPUä¼ è¾“æ•°æ®ã€‚
- æ¯ä¸ªMPIè¿›ç¨‹ç‹¬ç«‹æ„å»ºå±€éƒ¨è¿æ¥å¹¶å‡†å¤‡é€šä¿¡æ‰€éœ€çš„æ•°æ®ç»“æ„ï¼Œé¿å…äº†æ„å»ºé˜¶æ®µçš„MPIé€šä¿¡å¼€é”€ã€‚

#### ï¼ˆ2ï¼‰**ä»£ç†ç¥ç»å…ƒï¼ˆproxy neuronï¼‰ä¸é€šä¿¡æ˜ å°„ç»“æ„**
- å¼•å…¥â€œå›¾åƒç¥ç»å…ƒâ€ï¼ˆimage neuron / proxyï¼‰è¡¨ç¤ºè¿œç¨‹æºç¥ç»å…ƒåœ¨å…¶ç›®æ ‡è¿›ç¨‹ä¸­çš„è™šæ‹Ÿå‰¯æœ¬ã€‚
- æ„å»ºé«˜æ•ˆçš„æ˜ å°„è¡¨ï¼ˆå¦‚ `R`, `L`, `S` æ•°ç»„ï¼‰ï¼Œå°†è¿œç¨‹æºç¥ç»å…ƒç´¢å¼•ä¸å…¶åœ¨ç›®æ ‡è¿›ç¨‹ä¸­çš„æœ¬åœ°å›¾åƒç´¢å¼•å…³è”ï¼Œæ”¯æŒå¿«é€Ÿè·¯ç”±ã€‚

#### ï¼ˆ3ï¼‰**åŒæ¨¡å¼MPIé€šä¿¡æ”¯æŒ**
- æ”¯æŒä¸¤ç§é€šä¿¡èŒƒå¼ï¼š
  - **Point-to-point communication**ï¼šé€‚ç”¨äºéå‡åŒ€è¿æ¥ã€å¼‚æ„æ´»åŠ¨æ¨¡å¼ï¼ˆå¦‚Multi-Area Modelï¼‰ï¼›
  - **Collective communication**ï¼ˆå¦‚MPI_Allgatherï¼‰ï¼šé€‚ç”¨äºè´Ÿè½½å‡è¡¡çš„å¤§è§„æ¨¡éšæœºç½‘ç»œã€‚
- ç”¨æˆ·å¯æ ¹æ®æ¨¡å‹ç‰¹æ€§é€‰æ‹©æœ€ä¼˜é€šä¿¡ç­–ç•¥ã€‚

#### ï¼ˆ4ï¼‰**å››çº§ä¼˜åŒ–å±‚çº§ï¼ˆOptimization Levels 0â€“3ï¼‰**
é€šè¿‡æ§åˆ¶é€šä¿¡ç›¸å…³æ•°æ®ç»“æ„çš„å­˜å‚¨ä½ç½®ï¼ˆCPU vs GPUï¼‰ï¼Œå®ç°**GPUå†…å­˜ä½¿ç”¨ä¸è¿è¡Œæ—¶é—´ä¹‹é—´çš„æƒè¡¡**ï¼š
| Level | å­˜å‚¨äºGPUçš„å†…å®¹ |
|-------|----------------|
| 0     | ä»…è¿æ¥å‚æ•° |
| 1     | å›¾åƒæ˜ å°„ + å‡ºè¾¹èµ·å§‹ç´¢å¼• + æ•°é‡ â†’ å­˜äºCPU |
| 2     | å›¾åƒæ˜ å°„ + èµ·å§‹ç´¢å¼• â†’ GPUï¼›æ•°é‡åŠ¨æ€è®¡ç®— |
| 3     | å…¨éƒ¨å­˜äºGPUï¼ˆæœ€å¿«ï¼‰ |

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | æœ¬æ–‡æ”¹è¿› |
|------|--------|----------|
| NEST CPU/GPU (offboard) | ç½‘ç»œæ„å»ºåœ¨CPUè¿›è¡Œï¼Œéœ€å¤§é‡CPU-GPUæ•°æ®æ‹·è´ | å®Œå…¨on-GPUæ„å»ºï¼Œå‡å°‘IOå¼€é”€ |
| GeNN | å•GPUæˆ–å°è§„æ¨¡ï¼Œç¼ºä¹åˆ†å¸ƒå¼æ”¯æŒ | æ”¯æŒæ•°åƒGPUé›†ç¾¤ |
| CARLsim | å¤šGPUä½†å±€é™äºå•æœº | æ”¯æŒè·¨èŠ‚ç‚¹å¤§è§„æ¨¡åˆ†å¸ƒå¼ |
| Digital Brain | ä¸ä¿å­˜ä¸ªä½“çªè§¦ä¿¡æ¯ | ä¿ç•™å®Œæ•´çªè§¦çº§ç²¾åº¦ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šé¦–æ¬¡å®ç°äº†**çªè§¦çº§ç²¾åº¦ã€å…¨GPUå†…å­˜æ„å»ºã€æ”¯æŒä¸‡çº§GPUæ‰©å±•**çš„SNNä»¿çœŸæ¡†æ¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹
#### ï¼ˆ1ï¼‰**Multi-Area Model (MAM)**  
- æ¨¡æ‹ŸçŒ•çŒ´è§†è§‰çš®å±‚32ä¸ªåŒºåŸŸï¼›
- æ€»è®¡ï¼š4.13Ã—10â¶ ç¥ç»å…ƒï¼Œ2.42Ã—10Â¹â° çªè§¦ï¼›
- ç”Ÿç‰©å­¦çœŸå®ç»“æ„ï¼Œå…·æœ‰åˆ†å±‚ç»„ç»‡å’Œå¤æ‚é•¿ç¨‹è¿æ¥ï¼›
- è¿è¡Œäº**metastable state**ï¼ˆç±»éº»é†‰é™æ¯æ€ï¼‰ï¼›
- é‡‡ç”¨ **point-to-point MPI communication**ã€‚

#### ï¼ˆ2ï¼‰**Scalable Balanced Network**  
- éšæœºå¹³è¡¡ç½‘ç»œï¼ˆexcitatory/inhibitoryï¼‰ï¼›
- å›ºå®šè¾“å…¥åº¦ï¼ˆKin = 11,250ï¼‰ï¼Œè¿æ¥è§„åˆ™ä¸º `random, fixed in-degree`ï¼›
- è§„æ¨¡éšMPIè¿›ç¨‹æ•°çº¿æ€§å¢é•¿ï¼ˆweak scalingï¼‰ï¼›
- ä½¿ç”¨ **collective MPI communication**ï¼ˆMPI_Allgatherï¼‰ï¼›
- æ¯GPUèŠ‚ç‚¹è§„æ¨¡ï¼š2.25Ã—10âµ ç¥ç»å…ƒï¼Œ2.53Ã—10â¹ çªè§¦ï¼ˆscale=20ï¼‰ã€‚

---

### å®éªŒå¹³å°ç¡¬ä»¶é…ç½®
| å¹³å° | CPU | GPU | æ•°é‡/èŠ‚ç‚¹ | å†…å­˜ |
|------|-----|-----|-----------|------|
| **JUSUF** | AMD EPYC 7742 Ã—2 | NVIDIA V100 | 1 | 16 GB HBM2e |
| **Leonardo Booster** | Intel Xeon Platinum 8358 | NVIDIA A100 Ã—4 | 4 | 64 GB HBM2 |

> æ³¨ï¼šLeonardoç”¨äºå¼ºæ‰©å±•æµ‹è¯•ï¼ˆarea packingï¼‰ï¼ŒJUSUFç”¨äºMAMåŸºå‡†å¯¹æ¯”ã€‚

---

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Network Construction Time** | åŒ…æ‹¬åˆå§‹åŒ–ã€ç¥ç»å…ƒ/è®¾å¤‡åˆ›å»ºã€è¿æ¥ç”Ÿæˆã€æ¨¡æ‹Ÿå‡†å¤‡ç­‰å­ä»»åŠ¡è€—æ—¶ |
| **State Propagation Time** | åŠ¨æ€æ¼”åŒ–é˜¶æ®µè€—æ—¶ï¼Œä»¥ **Real-Time Factor (RTF)** è¡¡é‡ï¼š<br>$$ \text{RTF} = \frac{T_{\text{wall}}}{T_{\text{model}}} $$ |
| **Peak GPU Memory Usage** | æ¯GPUå³°å€¼å†…å­˜æ¶ˆè€—ï¼Œå†³å®šå¯æ‰©å±•ä¸Šé™ |
| **Earth Moverâ€™s Distance (EMD)** | éªŒè¯æ–°æ—§ç‰ˆæœ¬æ”¾ç”µç»Ÿè®¡åˆ†å¸ƒä¸€è‡´æ€§ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Offboard vs Onboard**ï¼šæ¯”è¾ƒåŸNEST GPUï¼ˆCPUæ„å»ºåä¼ GPUï¼‰ä¸æœ¬æ–‡æå‡ºçš„å…¨GPUæ„å»ºæ–¹æ³•ï¼›
- **ä¸åŒOptimization Levels**ï¼šåˆ†æå†…å­˜ä¸æ€§èƒ½æƒè¡¡ï¼›
- **Scaling Behavior**ï¼šä»32åˆ°256èŠ‚ç‚¹ï¼ˆå³128â€“1024 GPUsï¼‰è¿›è¡Œå¼±æ‰©å±•æµ‹è¯•ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ï¼ˆ1ï¼‰Multi-Area Model ç»“æœï¼ˆvs Offboardï¼‰
| æŒ‡æ ‡ | Offboard | Onboard | åŠ é€Ÿæ¯” |
|------|---------|--------|--------|
| **æ€»æ„å»ºæ—¶é—´** | 686.0 Â± 1.5 s | 55.5 Â± 0.1 s | **~12.4Ã—** |
| - è¿æ¥åˆ›å»ºï¼ˆlocalï¼‰ | â€” | â€” | **20Ã—** |
| - è¿æ¥åˆ›å»ºï¼ˆremoteï¼‰ | â€” | â€” | **9Ã—** |
| - ç¥ç»å…ƒ/è®¾å¤‡åˆ›å»º | ~1.9 s | ~0.005 s | **~350Ã—** |
| - æ¨¡æ‹Ÿå‡†å¤‡ | ~1.7 s | ~0.03 s | **~50Ã—** |
| **çŠ¶æ€ä¼ æ’­ RTF** | 16.0 Â± 3.0 | 15.0 Â± 1.7 | ç›¸å½“ |

> ğŸ” å›¾2æ˜¾ç¤ºï¼š**ç½‘ç»œæ„å»ºæˆä¸ºä¸»è¦ç“¶é¢ˆï¼Œè€Œonboardæ–¹æ³•å‡ ä¹å®Œå…¨æ¶ˆé™¤è¯¥ç“¶é¢ˆ**ã€‚

---

### ï¼ˆ2ï¼‰Scalable Balanced Network å¼±æ‰©å±•ç»“æœ
#### ç½‘ç»œè§„æ¨¡ï¼ˆscale=20ï¼‰
| èŠ‚ç‚¹æ•° | GPUæ•° | ç¥ç»å…ƒæ€»æ•° | çªè§¦æ€»æ•° |
|--------|-------|------------|-----------|
| 32 | 128 | 2.88Ã—10â· | 3.24Ã—10Â¹Â¹ |
| 256 | 1024 | 2.30Ã—10â¸ | 2.59Ã—10Â¹Â² |

#### æ€§èƒ½è¶‹åŠ¿ï¼ˆå›¾3ï¼‰
- **éšç€èŠ‚ç‚¹å¢åŠ ï¼Œstate propagation timeä¿æŒç¨³å®šï¼ˆRTF â‰ˆ 1.5â€“2.5ï¼‰**ï¼Œè¡¨æ˜è‰¯å¥½å¼±æ‰©å±•æ€§ï¼›
- **Optimization Level 3 æœ€å¿«**ï¼Œç›¸æ¯”Level 0æé€Ÿçº¦2å€ï¼›
- **å…³é—­spike recordingå¯è¿›ä¸€æ­¥é™ä½RTFçº¦20%**ã€‚

#### å†…å­˜ä½¿ç”¨ï¼ˆå›¾4ï¼‰
- **Level 0 å¯æ‰©å±•è‡³4096èŠ‚ç‚¹ï¼ˆâ‰ˆ16,384 GPUsï¼‰ä¸è¶…é™**ï¼›
- Level 3 åœ¨ ~1024 GPUs è¾¾åˆ°A100å†…å­˜æé™ï¼ˆ64GBï¼‰ï¼›
- å†…å­˜å³°å€¼ç”±è¿œç¨‹è¿æ¥æ˜ å°„ç»“æ„ä¸»å¯¼ã€‚

---

### ï¼ˆ3ï¼‰æ¶ˆèå®éªŒï¼šOptimization Levels å½±å“
| Level | æ„å»ºé€Ÿåº¦ | ä¼ æ’­é€Ÿåº¦ | GPUå†…å­˜ |
|-------|----------|----------|--------|
| 0 | æ…¢ï¼ˆéœ€é¢‘ç¹CPU-GPUè®¿é—®ï¼‰ | æ…¢ | æœ€ä½ |
| 1 | ä¸­ç­‰ | ä¸­ç­‰ | ä½ |
| 2 | å¿« | å¿« | ä¸­ |
| 3 | æœ€å¿«ï¼ˆå…¨GPUæ“ä½œï¼‰ | æœ€å¿« | æœ€é«˜ |

> âš–ï¸ **ç»“è®º**ï¼šLevel 3é€‚åˆè¿½æ±‚æè‡´æ€§èƒ½ï¼ŒLevel 0é€‚åˆå†…å­˜å—é™åœºæ™¯ã€‚

---

### ï¼ˆ4ï¼‰Area Packing å®éªŒï¼ˆé™„å½•Bï¼‰
- åˆ©ç”¨A100å¤§å†…å­˜ï¼Œåœ¨Leonardoä¸Šå®ç°å¤šä¸ªMAMåŒºåŸŸæ‰“åŒ…åˆ°åŒä¸€GPUï¼›
- æœ€å°‘å¯ç”¨ **8 GPUsï¼ˆ2 nodesï¼‰è¿è¡Œå®Œæ•´MAM**ï¼›
- å°½ç®¡æ„å»ºæ—¶é—´ç•¥æœ‰ä¸Šå‡ï¼Œä½†æ•´ä½“å¯è¡Œä¸”èŠ‚çœèµ„æºã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å…¨GPUç½‘ç»œæ„å»ºæ˜¾è‘—åŠ é€Ÿæ„å»ºè¿‡ç¨‹**ï¼šç›¸æ¯”ä¼ ç»Ÿoffboardæ–¹æ³•ï¼Œ**æ„å»ºæ—¶é—´ç¼©çŸ­è¶…è¿‡10å€**ï¼Œå°¤å…¶åœ¨è¿æ¥ç”Ÿæˆå’Œæ¨¡æ‹Ÿå‡†å¤‡é˜¶æ®µè¡¨ç°çªå‡ºã€‚
2. **æ”¯æŒå¤§è§„æ¨¡å¼±æ‰©å±•**ï¼šåœ¨1024 GPUsä¸ŠæˆåŠŸè¿è¡Œå« **2.3äº¿ç¥ç»å…ƒã€2.6ä¸‡äº¿çªè§¦** çš„å¹³è¡¡ç½‘ç»œï¼ŒRTFæ¥è¿‘å®æ—¶ã€‚
3. **çµæ´»é€šä¿¡æœºåˆ¶é€‚åº”ä¸åŒæ¨¡å‹éœ€æ±‚**ï¼š
   - Point-to-point æ›´é€‚åˆç”Ÿç‰©çœŸå®ã€éå‡åŒ€è¿æ¥æ¨¡å‹ï¼ˆå¦‚MAMï¼‰ï¼›
   - Collective æ›´é€‚åˆé«˜åº¦äº’è”ã€è´Ÿè½½å‡è¡¡çš„å¤§è§„æ¨¡éšæœºç½‘ç»œã€‚
4. **å†…å­˜-æ€§èƒ½æƒè¡¡å¯æ§**ï¼šé€šè¿‡4çº§ä¼˜åŒ–ç­–ç•¥ï¼Œå¯åœ¨å®é™…éƒ¨ç½²ä¸­æŒ‰éœ€è°ƒèŠ‚ã€‚
5. **å…·å¤‡Exascaleæ½œåŠ›**ï¼šé¢„è®¡åœ¨JUPITERè¶…ç®—ä¸Šå¯è¾¾ **2Ã—10Â¹â° ç¥ç»å…ƒã€10Â¹â´ çªè§¦** è§„æ¨¡ï¼Œæ¥è¿‘äººç±»å¤§è„‘çªè§¦æ•°é‡çº§ï¼ˆ~10Â¹âµï¼‰ã€‚

---

### â— å±€é™æ€§
1. **å½“å‰å®ç°ä¾èµ–ç”¨æˆ·æ‰‹åŠ¨è´Ÿè½½å‡è¡¡**ï¼Œæœªè‡ªåŠ¨è€ƒè™‘ç¡¬ä»¶æ‹“æ‰‘ï¼›
2. **å°šæœªå¯ç”¨GPUDirect RDMA**ï¼Œä»æœ‰è¿›ä¸€æ­¥é™ä½é€šä¿¡å»¶è¿Ÿçš„ç©ºé—´ï¼›
3. **é›†ä½“é€šä¿¡å‡è®¾åŒæ„æµé‡**ï¼Œå¯¹æç«¯å¼‚æ„æ¨¡å‹å¯èƒ½ä¸é€‚ç”¨ï¼›
4. **éªŒè¯é›†ä¸­åœ¨ç»Ÿè®¡ä¸€è‡´æ€§**ï¼Œæœªæ·±å…¥æ¢è®¨åŠŸèƒ½å±‚é¢çš„è¡Œä¸ºå·®å¼‚ã€‚

---

### ğŸš€ æœªæ¥å·¥ä½œæ–¹å‘
1. **è‡ªåŠ¨åŒ–åˆ†åŒºä¸æ˜ å°„ç­–ç•¥**ï¼šç»“åˆç¥ç»ç½‘ç»œæ‹“æ‰‘ä¸HPCç¡¬ä»¶æ‹“æ‰‘è¿›è¡Œæ™ºèƒ½åˆ†é…ï¼›
2. **æ··åˆé€šä¿¡åè®®è®¾è®¡**ï¼šä¾‹å¦‚å±€éƒ¨ç”¨point-to-pointï¼Œå…¨å±€ç”¨collectiveï¼›
3. **é›†æˆNCCLæˆ–å…¶ä»–GPUä¸“ç”¨é€šä¿¡åº“**æå‡å¸¦å®½åˆ©ç”¨ç‡ï¼›
4. **æ”¯æŒæ›´å¤šçªè§¦å¯å¡‘æ€§è§„åˆ™ä¸åŠ¨æ€è¿æ¥æ›´æ–°**ï¼›
5. **å‘JUPITERç­‰Exascaleç³»ç»Ÿè¿ç§»ä¸å®æµ‹éªŒè¯**ã€‚

---

## æ€»ç»“
è¯¥è®ºæ–‡æå‡ºäº†ä¸€å¥—**é¢å‘Exascaleçš„ã€å¯æ‰©å±•çš„SNNæ„å»ºä¸ä»¿çœŸæ¡†æ¶**ï¼Œé€šè¿‡**å…¨GPUå†…å­˜æ„å»ºã€ä»£ç†ç¥ç»å…ƒæœºåˆ¶ã€åŒæ¨¡å¼MPIé€šä¿¡ä¸å››çº§å†…å­˜ä¼˜åŒ–**ï¼Œå®ç°äº†å‰æ‰€æœªæœ‰çš„è§„æ¨¡ä¸æ•ˆç‡ã€‚å®éªŒè¡¨æ˜å…¶åœ¨MAMå’Œéšæœºå¹³è¡¡ç½‘ç»œä¸Šå‡å–å¾—æ˜¾è‘—æ€§èƒ½æå‡ï¼Œå¹¶å±•ç°å‡ºé€¼è¿‘äººè„‘è§„æ¨¡ä»¿çœŸçš„æ½œåŠ›ï¼Œæ˜¯è¿ˆå‘â€œæ•°å­—å¤§è„‘â€çš„å…³é”®æŠ€æœ¯ä¸€æ­¥ã€‚

</details>

---

### 5. [Learning Unmasking Policies for Diffusion Language Models](https://arxiv.org/abs/2512.09106)

**Authors**: Metod Jazbec, Theo X. Olausson, Louis B\'ethune, Pierre Ablin, Michael Kirchhof, Joao Monterio, Victor Turrisi, Jason Ramapuram, Marco Cuturi  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.09106v1  

#### Abstract
Diffusion (Large) Language Models (dLLMs) now match the downstream performance of their autoregressive counterparts on many tasks, while holding the promise of being more efficient during inference. One particularly successful variant is masked discrete diffusion, in which a buffer filled with speci...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLearning Unmasking Policies for Diffusion Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æ‰©æ•£è¯­è¨€æ¨¡å‹ï¼ˆdLLMsï¼‰åœ¨ç”Ÿæˆæ—¶é€šè¿‡é€æ­¥â€œå»æ©ç â€ï¼ˆunmaskingï¼‰ä¸€ä¸ªåˆå§‹å…¨ä¸ºæ©ç  token çš„åºåˆ—æ¥ç”Ÿæˆæ–‡æœ¬ã€‚ä¼ ç»Ÿçš„é‡‡æ ·ç­–ç•¥ï¼ˆå¦‚éšæœºæˆ–åŸºäºç½®ä¿¡åº¦çš„å¯å‘å¼æ–¹æ³•ï¼‰è™½ç„¶èƒ½æå‡æ•ˆç‡ï¼Œä½†å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **æ‰‹åŠ¨è°ƒå‚å›°éš¾**ï¼šä¾‹å¦‚é˜ˆå€¼ `Î»` æˆ–å—é•¿åº¦ `BL` éœ€è¦é’ˆå¯¹ä¸åŒä»»åŠ¡å’Œæ¨¡å‹è¿›è¡Œè°ƒæ•´ï¼›
- **æ³›åŒ–èƒ½åŠ›å·®**ï¼šåœ¨éåŠè‡ªå›å½’ï¼ˆnon-semi-ARï¼‰è®¾ç½®ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼›
- **éš¾ä»¥å¹³è¡¡æ•ˆç‡ä¸è´¨é‡**ï¼šå›ºå®šè§„åˆ™æ— æ³•åŠ¨æ€é€‚åº”ä¸åŒè¾“å…¥ã€‚

æœ¬æ–‡æå‡ºï¼š**å°† unmasking ç­–ç•¥çš„å­¦ä¹ å½¢å¼åŒ–ä¸ºä¸€ä¸ªå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰é—®é¢˜**ï¼Œä»¥è‡ªåŠ¨å‘ç°é«˜æ•ˆçš„é‡‡æ ·ç­–ç•¥ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

#### ï¼ˆ1ï¼‰å°†é‡‡æ ·è¿‡ç¨‹å»ºæ¨¡ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰
- **çŠ¶æ€ï¼ˆStateï¼‰**ï¼šå½“å‰éƒ¨åˆ†å»æ©ç çš„åºåˆ— `y_t` å’ŒåŸå§‹æç¤º `x`ï¼›
- **åŠ¨ä½œï¼ˆActionï¼‰**ï¼šæ¯ä¸ªä½ç½®æ˜¯å¦è¢«å»æ©ç ï¼ˆäºŒå€¼å‘é‡ `u âˆˆ {0,1}^L`ï¼‰ï¼›
- **å¥–åŠ±ï¼ˆRewardï¼‰**ï¼šæœ€ç»ˆç­”æ¡ˆæ­£ç¡®æ€§ Ã— æ•ˆç‡æƒ©ç½šé¡¹ï¼ˆ`r(y, y*) Ã— (1 - Î±/(Tâˆ’T_final))`ï¼‰ï¼Œé‡‡ç”¨ä¹˜æ³•å½¢å¼é¿å…é”™è¯¯æ ·æœ¬å› é€Ÿåº¦å¿«è€Œè·å¾—æ­£ä¼˜åŠ¿ï¼›
- **ç¯å¢ƒ**ï¼šå›ºå®šçš„é¢„è®­ç»ƒ dLLMï¼ˆå¦‚ LLaDAã€Dreamï¼‰ï¼Œä¸æ›´æ–°å…¶å‚æ•°ã€‚

#### ï¼ˆ2ï¼‰è®¾è®¡è½»é‡çº§ Transformer ç­–ç•¥ç½‘ç»œï¼ˆLightweight Policyï¼‰
- è¾“å…¥ï¼šå„ä½ç½® token çš„é¢„æµ‹ç½®ä¿¡åº¦ `c_k = max_v p(v)`ã€æ©ç çŠ¶æ€ `m_k`ã€æ—¶é—´æ­¥ `t`ï¼›
- ç½‘ç»œç»“æ„ï¼šå•å±‚ Transformerï¼Œæ€»å‚æ•°ä»…çº¦ 300Kï¼ˆ<0.01% of LLaDA-8Bï¼‰ï¼Œè®¡ç®—å¼€é”€æä½ï¼›
- è¾“å‡ºï¼šæ¯ä¸ªä½ç½®çš„ unmasking å¾—åˆ†ï¼Œé€šè¿‡ Bernoulli åˆ†å¸ƒé‡‡æ ·å†³å®šæ˜¯å¦å»æ©ç ã€‚

#### ï¼ˆ3ï¼‰ä½¿ç”¨ Group Relative Policy Optimizationï¼ˆGRPOï¼‰è¿›è¡Œè®­ç»ƒ
- æ¯ç»„é‡‡æ ·å¤šä¸ªè½¨è¿¹ï¼Œè®¡ç®—ç»„å†…ç›¸å¯¹ä¼˜åŠ¿ï¼ˆgroup-mean normalized advantageï¼‰ï¼›
- ä½¿ç”¨é‡è¦æ€§é‡‡æ ·å’Œ clip æœºåˆ¶ç¨³å®šè®­ç»ƒï¼›
- ç§»é™¤ KL æ­£åˆ™é¡¹ï¼ˆå› ä»é›¶å¼€å§‹è®­ç»ƒï¼‰ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | å¯å‘å¼æ–¹æ³•ï¼ˆå¦‚ Fast-dLLMï¼‰ | æœ¬æ–‡æ–¹æ³•ï¼ˆRL Policyï¼‰ |
|------|--------------------------|------------------------|
| **è°ƒå‚éš¾åº¦** | éœ€æ‰‹åŠ¨è°ƒèŠ‚ `Î»` æˆ– `K` | è‡ªåŠ¨å­¦ä¹ ç­–ç•¥ï¼Œæ— éœ€åœ¨çº¿è°ƒå‚ |
| **çµæ´»æ€§** | å›ºå®šè§„åˆ™ï¼Œéš¾ä»¥é€‚åº”å¤æ‚æ¨¡å¼ | å¯å­¦ä¹ ä¸Šä¸‹æ–‡ç›¸å…³çš„åŠ¨æ€ç­–ç•¥ |
| **é semi-AR æ€§èƒ½** | åœ¨ full diffusion ä¸‹æ€§èƒ½éª¤é™ | æ˜¾è‘—ä¼˜äºå¯å‘å¼æ–¹æ³• |
| **æ•ˆç‡-å‡†ç¡®æ€§æƒè¡¡** | é€šè¿‡ `Î»` å¹³æ»‘æ§åˆ¶ | è™½ä¸å¦‚å¯å‘å¼å¹³æ»‘ï¼Œä½†å¯é€šè¿‡ `Î±` å’Œ `T_policy` è°ƒèŠ‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **æ•°å­¦æ¨ç†**ï¼š
  - **GSM8k**ï¼ˆå°å­¦æ•°å­¦é¢˜ï¼‰
  - **MATH**ï¼ˆé«˜ä¸­ç«èµ›çº§æ•°å­¦é¢˜ï¼‰
- **ä»£ç ç”Ÿæˆ**ï¼š
  - **HumanEval**
  - **MBPP**
- **è®­ç»ƒæ•°æ®æ··åˆ**ï¼šGSM8k + MATH æŒ‰æ¯”ä¾‹æ··åˆï¼Œå…± ~15,000 æ¡æ ·æœ¬ï¼›
- **è¿ç§»æµ‹è¯•**ï¼šåœ¨ HumanEval / MBPP ä¸Šæµ‹è¯•è·¨åŸŸè¿ç§»èƒ½åŠ›ã€‚

---

### å®éªŒè®¾ç½®

| ç»„ä»¶ | è®¾ç½® |
|------|------|
| **åŸºç¡€æ¨¡å‹** | LLaDA-8B-Instructã€Dream-7B-Instruct |
| **ç­–ç•¥ç½‘ç»œæ¶æ„** | å•å±‚ Transformerï¼Œéšè—ç»´åº¦ 128ï¼Œæ³¨æ„åŠ›å¤´æ•° 2 |
| **è®­ç»ƒç®—æ³•** | GRPOï¼Œbatch size=16ï¼Œlearning rate=3e-5ï¼Œcosine è°ƒåº¦å™¨ |
| **è®­ç»ƒç›®æ ‡** | å¤šä»»åŠ¡æ··åˆæ•°æ®ä¸Šè®­ç»ƒ 1 ä¸ª epoch |
| **æ¸©åº¦è®¾ç½®** | dLLM æ¸©åº¦ T=0ï¼ˆgreedy decodingï¼‰ï¼Œç­–ç•¥æ¸©åº¦ `T_policy` åœ¨æµ‹è¯•æ—¶å¯è°ƒ |
| **è¯„ä¼°æŒ‡æ ‡** |
| - **å‡†ç¡®æ€§**ï¼šä»»åŠ¡ç‰¹å®šæ­£ç¡®ç‡ï¼ˆå¦‚ pass@1ï¼‰ |
| - **æ•ˆç‡**ï¼šå¹³å‡ NFEsï¼ˆNetwork Function Evaluationsï¼‰ï¼Œå³é‡‡æ ·æ­¥æ•° |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **Random** | éšæœºé€‰æ‹© K ä¸ªä½ç½®å»æ©ç  |
| **High Confidence** | é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„ K ä¸ªä½ç½®ï¼ˆK âˆˆ {8,...,256}ï¼‰ |
| **Fast-dLLM** | ç½®ä¿¡åº¦è¶…è¿‡é˜ˆå€¼ `Î»` çš„ä½ç½®å…¨éƒ¨å»æ©ç ï¼ˆ`Î» âˆˆ [0.1,1.0]`ï¼‰ |
| **Ours (RL)** | æœ¬æ–‡æå‡ºçš„ RL å­¦ä¹ ç­–ç•¥ |
| **Ours (w/ ES)** | å¼•å…¥ Expert Steering çš„å˜ä½“ï¼Œå¼•å¯¼æ¢ç´¢ semi-AR è¡Œä¸º |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ï¼ˆ1ï¼‰åœ¨ semi-AR è®¾ç½®ä¸‹ï¼ˆBL=32ï¼‰åŒ¹é…æœ€å…ˆè¿›å¯å‘å¼æ–¹æ³•

- åœ¨ GSM8k å’Œ MATH ä¸Šï¼ŒRL ç­–ç•¥çš„ Pareto å‰æ²¿å‡ ä¹å®Œå…¨è´´åˆ Fast-dLLMï¼›
- ç‰¹åˆ«æ˜¯ `Î±=10` çš„ç­–ç•¥ï¼Œåœ¨æä½ NFEï¼ˆ~10ï¼‰æ—¶è¡¨ç°æœ€ä¼˜ï¼Œè¯´æ˜å…¶æ“…é•¿æè‡´åŠ é€Ÿï¼›
- ä½† `Î±` å‚æ•°å¯¹è¡Œä¸ºçš„æ§åˆ¶ä¸å¦‚ `Î»` å¹³æ»‘ï¼ˆè§æ¶ˆèå®éªŒï¼‰ã€‚

> âœ… ç»“è®ºï¼š**åœ¨ semi-AR åœºæ™¯ä¸‹ï¼ŒRL ç­–ç•¥èƒ½è¾¾åˆ°ä¸æœ€ä½³å¯å‘å¼ç›¸å½“çš„æ€§èƒ½ã€‚**

---

### ï¼ˆ2ï¼‰åœ¨ full diffusion è®¾ç½®ä¸‹ï¼ˆBL=256ï¼‰æ˜¾è‘—è¶…è¶Šå¯å‘å¼æ–¹æ³•

| æ–¹æ³• | GSM8k @ ~12 NFEs | MATH @ ~12 NFEs |
|------|------------------|------------------|
| Random / High Confidence | â‰¤30% | â‰¤15% |
| Fast-dLLM | â‰¤30% | â‰¤15% |
| **Ours (RL)** | **~50%** | **~25%** |

- æ‰€æœ‰æ–¹æ³•æ€§èƒ½å‡ä¸‹é™ï¼Œä½† RL ç­–ç•¥ä¸‹é™å¹…åº¦æœ€å°ï¼›
- è¡¨æ˜ RL èƒ½æœ‰æ•ˆåº”å¯¹é•¿åºåˆ—ã€æ— å—çº¦æŸçš„æŒ‘æˆ˜ï¼›
- åŠ å…¥ **Expert Steering (ES)** åï¼Œåœ¨ä¸­é«˜ NFE åŒºé—´è¿›ä¸€æ­¥é€¼è¿‘ semi-AR æœ€ä¼˜æ€§èƒ½ï¼ˆå¦‚ GSM8k è¾¾åˆ° ~80%ï¼‰ã€‚

> âœ… ç»“è®ºï¼š**åœ¨ full diffusion åœºæ™¯ä¸‹ï¼ŒRL ç­–ç•¥æ˜æ˜¾ä¼˜äºå¯å‘å¼æ–¹æ³•ï¼Œå°¤å…¶åœ¨ä½ NFE æé™æ•ˆç‡åœºæ™¯ã€‚**

---

### ï¼ˆ3ï¼‰æ¶ˆèå®éªŒç»“æœ

#### â–¶ ä¹˜æ³• vs åŠ æ³•å¥–åŠ±å‡½æ•°
| å¥–åŠ±å½¢å¼ | è®­ç»ƒç¨³å®šæ€§ | æ˜¯å¦å‡ºç° reward hacking |
|---------|------------|------------------------|
| åŠ æ³•ï¼š`r âˆ’ Î±Ã—steps` | å·® | æ˜¯ï¼ˆæ¨¡å‹å­¦ä¼šä¸€æ¬¡æ€§å»æ©ç æ‰€æœ‰ tokenï¼‰ |
| **ä¹˜æ³•ï¼š`r Ã— (1âˆ’Î±/steps)`** | **å¥½** | **å¦** |

> âœ”ï¸ ä¹˜æ³•å¥–åŠ±æ›´åˆç†ï¼šåªæœ‰æ­£ç¡®ç­”æ¡ˆæ‰èƒ½è·å¾—æ­£ä¼˜åŠ¿ï¼Œé˜²æ­¢â€œå¿«ä½†é”™â€çš„ç­–ç•¥å ä¼˜ã€‚

#### â–¶ ä¸åŒç­–ç•¥è¾“å‡ºåˆ†å¸ƒ
| æ–¹æ³• | æ§åˆ¶æ€§ | å®ç°å¤æ‚åº¦ | æ€§èƒ½ |
|------|--------|------------|-------|
| **Bernoulli**ï¼ˆé»˜è®¤ï¼‰ | ä¸€èˆ¬ | ç®€å•ï¼Œé«˜æ•ˆ | â‰ˆ Fast-dLLM |
| **Dynamic Plackett-Luce (DPLS)** | æ›´å¥½ï¼ˆ`Î±` å½±å“æ›´å¹³æ»‘ï¼‰ | å¤æ‚ï¼Œéœ€å¤„ç† STOP token | â‰ˆ Bernoulli |

> âœ”ï¸ DPLS æä¾›æ›´å¥½å¯æ§æ€§ï¼Œä½†æ”¶ç›Šæœ‰é™ï¼›Bernoulli æ›´å®ç”¨ã€‚

#### â–¶ è¾“å…¥ç‰¹å¾è®¾è®¡
| è¾“å…¥ | æ€§èƒ½ | å¤‡æ³¨ |
|------|------|------|
| **Top-1 ç½®ä¿¡åº¦ `c_k`** | **æœ€ä½³** | ç®€æ´æœ‰æ•ˆ |
| Top-50 ç½®ä¿¡åº¦ | ç•¥å·® | æœªå¸¦æ¥å¢ç›Š |
| **Hidden States**ï¼ˆ300M å‚æ•°ï¼‰ | æ›´å·® | è¿‡å¤§ä¸”ä¸ç¨³å®š |

> âœ”ï¸ **ç®€å•çš„ç½®ä¿¡åº¦è¾“å…¥å·²è¶³å¤Ÿ**ï¼Œè¯­ä¹‰ä¿¡æ¯åè€Œå¹²æ‰°ç­–ç•¥å­¦ä¹ ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **Unmasking ç­–ç•¥å¯ä»¥è¢«æœ‰æ•ˆå­¦ä¹ **ï¼šé€šè¿‡ RL å¯è‡ªåŠ¨å‘ç°é«˜è´¨é‡çš„ adaptive sampling ç­–ç•¥ï¼›
2. âœ… **åœ¨ full diffusion åœºæ™¯ä¸‹ä¼˜äºå¯å‘å¼æ–¹æ³•**ï¼šå°¤å…¶åœ¨ä½ NFE æé™æ•ˆç‡åœºæ™¯ï¼ŒRL ç­–ç•¥å±•ç°å‡ºæ›´å¼ºæ½œåŠ›ï¼›
3. âœ… **ç­–ç•¥å…·æœ‰è‰¯å¥½çš„è¿ç§»èƒ½åŠ›**ï¼š
   - **è·¨æ¨¡å‹**ï¼šåœ¨ LLaDA ä¸Šè®­ç»ƒçš„ç­–ç•¥å¯åœ¨ Dream ä¸Šå–å¾—æ¥è¿‘åŸç”Ÿè®­ç»ƒçš„æ•ˆæœï¼›
   - **è·¨é•¿åº¦**ï¼šåœ¨ L=256 è®­ç»ƒçš„ç­–ç•¥å¯ç›´æ¥ç”¨äº L=512ï¼Œæ€§èƒ½ç¨³å®šï¼›
4. âŒ **è·¨é¢†åŸŸè¿ç§»å—é™**ï¼šåœ¨æ•°å­¦æ•°æ®ä¸Šè®­ç»ƒçš„ç­–ç•¥åœ¨ä»£ç ä»»åŠ¡ï¼ˆHumanEval/MBPPï¼‰ä¸Šè¡¨ç°ä¸ä½³ï¼Œéœ€é¢†åŸŸé€‚é…ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
| å±€é™ | æè¿° |
|------|------|
| **å¯æ§æ€§ä¸è¶³** | `Î±` å‚æ•°æ— æ³•åƒ `Î»` é‚£æ ·å¹³æ»‘è°ƒèŠ‚å‡†ç¡®ç‡-æ•ˆç‡æƒè¡¡ |
| **è®­ç»ƒä¸ç¨³å®šæ€§** | å°¤å…¶åœ¨ `Î±=10` æˆ–å¼•å…¥ Expert Steering æ—¶æ˜“å´©æºƒ |
| **ä¾èµ–é«˜è´¨é‡åŸºç¡€æ¨¡å‹è¾“å‡º** | è‹¥ dLLM æœ¬èº«æ€§èƒ½å¼±ï¼ŒRL æ— æ³•å¼¥è¡¥ |
| **ä»éœ€ä¸ºæ¯ä¸ª `Î±` å•ç‹¬è®­ç»ƒç­–ç•¥** | æ— æ³•åœ¨ä¸€ä¸ªæ¨¡å‹ä¸­è¿ç»­è°ƒèŠ‚ trade-off |

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ”¹è¿›ç­–ç•¥å¯æ§æ€§**ï¼š
   - æ¢ç´¢è”åˆå­¦ä¹  `T_policy` æˆ–ä½¿ç”¨æ¡ä»¶ç”Ÿæˆæ–¹å¼ç»Ÿä¸€å¤š `Î±` ç­–ç•¥ï¼›
   - è®¾è®¡æ›´é²æ£’çš„ likelihood ç»“æ„ï¼ˆå¦‚ DPLSï¼‰ã€‚
2. **å¢å¼ºè·¨é¢†åŸŸæ³›åŒ–**ï¼š
   - åœ¨å¤šé¢†åŸŸæ··åˆæ•°æ®ä¸Šè®­ç»ƒé€šç”¨ unmasking ç­–ç•¥ï¼›
   - å¼•å…¥è½»é‡çº§é€‚é…æ¨¡å—ï¼ˆadapterï¼‰å®ç° zero-shot è¿ç§»ã€‚
3. **æ‰©å±•åŠŸèƒ½**ï¼š
   - æ”¯æŒ remaskingï¼ˆå›é€€ä¿®æ­£ï¼‰æ“ä½œï¼›
   - åŠ¨æ€è°ƒæ•´ç”Ÿæˆé•¿åº¦ï¼ˆç±»ä¼¼ Li et al., 2025aï¼‰ï¼›
   - åº”ç”¨äº multimodal diffusion modelsã€‚
4. **ç†è®ºåˆ†æ**ï¼š
   - åˆ†æ RL ç­–ç•¥ä¸ºä½•èƒ½åœ¨ full diffusion ä¸‹ä¼˜äºå¯å‘å¼ï¼›
   - æ¢ç´¢æœ€ä¼˜ unmasking åºåˆ—çš„ç»“æ„æ€§è´¨ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼šæœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿåœ°å°† RL å¼•å…¥ dLLM çš„é‡‡æ ·ç­–ç•¥å­¦ä¹ ï¼Œè¯æ˜äº† learned unmasking policy åœ¨æ•ˆç‡ä¸è´¨é‡ä¹‹é—´å¯è¾¾åˆ°ç”šè‡³è¶…è¶Šäººå·¥è®¾è®¡å¯å‘å¼çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨é semi-AR åœºæ™¯ä¸‹å±•ç°å·¨å¤§æ½œåŠ›ï¼Œä¸ºæœªæ¥é«˜æ•ˆã€æ™ºèƒ½çš„æ–‡æœ¬ç”Ÿæˆæä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 6. [TinyD\'ej\`aVu: Smaller Memory Footprint & Faster Inference on Sensor Data Streams with Always-On Microcontrollers](https://arxiv.org/abs/2512.09786)

**Authors**: Zhaolan Huang, Emmanuel Baccelli  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.09786v1  

#### Abstract
Always-on sensors are increasingly expected to embark a variety of tiny neural networks and to continuously perform inference on time-series of the data they sense. In order to fit lifetime and energy consumption requirements when operating on battery, such hardware uses microcontrollers (MCUs) with...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTinyDejaVu: Smaller Memory Footprint & Faster Inference on Sensor Data Streams with Always-On Microcontrollers

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨èµ„æºæåº¦å—é™çš„ **Microcontroller Unit (MCU)** ä¸Šè¿è¡ŒåŸºäºæ—¶é—´åºåˆ—ä¼ æ„Ÿå™¨æ•°æ®æµçš„ç¥ç»ç½‘ç»œæ¨ç†æ—¶ï¼Œé¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **é«˜ RAM å ç”¨**ï¼šä¼ ç»Ÿæ¨¡å‹å¯¹æ¯ä¸ªæ»‘åŠ¨çª—å£è¾“å…¥éƒ½é‡æ–°è®¡ç®—ä¸­é—´æ¿€æ´»å€¼ï¼Œå¯¼è‡´å†…å­˜å³°å€¼æé«˜ã€‚
- **å†—ä½™è®¡ç®—**ï¼šç”±äºæ»‘åŠ¨çª—å£é«˜åº¦é‡å ï¼ˆoverlapï¼‰ï¼Œå¤§é‡è®¡ç®—æ˜¯é‡å¤æ‰§è¡Œçš„ã€‚

è¿™äº›é—®é¢˜ä¸¥é‡å½±å“äº†ç”µæ± ä¾›ç”µè®¾å¤‡çš„èƒ½æ•ˆä¸å®æ—¶æ€§ï¼Œé™åˆ¶äº† TinyML åœ¨é•¿æœŸã€è¿ç»­æ„ŸçŸ¥åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **TinyDejaVu** â€”â€” ä¸€ç§å…¨æ–°çš„åµŒå…¥å¼è½¯ä»¶æ¡†æ¶ï¼Œé€šè¿‡å°†æ—¶é—´ç®—å­å»ºæ¨¡ä¸º **State-Space Model (SSM)** æ¥ä¼˜åŒ–æ¨ç†è¿‡ç¨‹ã€‚å…¶æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ï¼š

#### âœ… åˆ›æ–°ç‚¹ 1ï¼šå°† Temporal Operators è½¬æ¢ä¸º SSM
- å°†å·ç§¯ï¼ˆConvï¼‰ã€æ± åŒ–ï¼ˆPoolingï¼‰ç­‰å…·æœ‰å› æœç»“æ„çš„æ—¶é—´ç®—å­å½¢å¼åŒ–ä¸º SSMï¼š
  $$
  h_t = A h_{t-1} + B x_t,\quad y_t = g(h_t)
  $$
- è¿™ä½¿å¾—åªéœ€ç»´æŠ¤å›ºå®šå¤§å°çš„éšè—çŠ¶æ€ç¼“å†²åŒºï¼ˆè€Œéå®Œæ•´è¾“å…¥åºåˆ—ï¼‰ï¼Œå®ç°å¸¸é‡ç©ºé—´å¤æ‚åº¦ã€‚

#### âœ… åˆ›æ–°ç‚¹ 2ï¼šå¼•å…¥ Graph Partitioning æœºåˆ¶
- å°†ç¥ç»ç½‘ç»œåˆ’åˆ†ä¸ºä¸¤ä¸ªå­å›¾ï¼š
  - **SSM-subgraph**ï¼šå±€éƒ¨æ—¶é—´ç®—å­ â†’ å¯è½¬æ¢ä¸º SSM æµå¼å¤„ç†ï¼›
  - **GTA-subgraph**ï¼ˆGlobal Temporal Aggregatorï¼‰ï¼šå¦‚å…¨å±€æ± åŒ–ã€Attention â†’ éœ€è¦å…¨å±€ä¸Šä¸‹æ–‡ï¼Œä½œä¸ºè¾¹ç•Œã€‚
- åœ¨æ»‘åŠ¨çª—å£æ›´æ–°æ—¶ï¼Œä»…æ›´æ–°å—å½±å“çš„éšè—çŠ¶æ€ï¼Œé¿å…å…¨å›¾é‡ç®—ã€‚

#### âœ… åˆ›æ–°ç‚¹ 3ï¼šæ”¯æŒ Overlapping Sliding Window çš„é«˜æ•ˆå¤„ç†
- è®¾è®¡ç®—æ³•è¯†åˆ«å“ªäº›éšè—çŠ¶æ€éœ€è¦æ›´æ–°ï¼Œå¹¶åŠ¨æ€è°ƒæ•´ GTA å±‚çš„ strideï¼Œå‡å°‘ä¸å¿…è¦çš„è®¡ç®—ã€‚

#### âœ… åˆ›æ–°ç‚¹ 4ï¼šä¼˜åŒ– Global Pooling å®ç°
- æå‡ºä¸¤çº§ SSM ç»“æ„æ›¿ä»£åŸå§‹å…¨å±€æ± åŒ–æ“ä½œï¼Œå°† RAM å¤æ‚åº¦ä» $O(N)$ é™è‡³ $O(N/s)$ï¼Œæ˜¾è‘—é™ä½å†…å­˜å ç”¨ã€‚

#### âœ… åˆ›æ–°ç‚¹ 5ï¼šå¯é€‰ BF16 æ”¯æŒ
- ä½¿ç”¨ **BF16**ï¼ˆBrain Floating Pointï¼‰æ ¼å¼å­˜å‚¨éšè—çŠ¶æ€ï¼Œåœ¨ç²¾åº¦æŸå¤±æå°çš„æƒ…å†µä¸‹è¿›ä¸€æ­¥å‹ç¼©å†…å­˜ä½¿ç”¨ï¼ˆç›¸æ¯” FP32 å‡å°‘ 50% RAMï¼‰ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ FastWaveNetã€StreamiNNCï¼‰ | TinyDejaVu |
|------|----------------------------------------|-----------|
| æ”¯æŒç®—å­èŒƒå›´ | ä¸»è¦é™äº 1D Convolution | æ”¯æŒ Convã€Poolingã€Global Poolingã€æ··åˆæ¶æ„ |
| æ˜¯å¦æ”¯æŒé€šç”¨æ¨¡å‹ | å¦ï¼Œé’ˆå¯¹ç‰¹å®šç»“æ„è®¾è®¡ | æ˜¯ï¼Œé€‚ç”¨äºå¤šç§ Hybrid æ¶æ„ |
| æ˜¯å¦ç«¯åˆ°ç«¯ä»£ç ç”Ÿæˆ | å¦ | æ˜¯ï¼ŒåŸºäº microTVM è‡ªåŠ¨ç”Ÿæˆå¹³å°æ— å…³ C ä»£ç  |
| å†…å­˜ä¼˜åŒ–ç¨‹åº¦ | ä¸­ç­‰ | æœ€é«˜è¾¾ **99% RAM èŠ‚çœ** |
| æ¨ç†åŠ é€Ÿèƒ½åŠ› | æœ‰é™ | æœ€é«˜å¯è¾¾ **200Ã— åŠ é€Ÿ**ï¼ˆstreaming é˜¶æ®µï¼‰ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šTinyDejaVu æ˜¯é¦–ä¸ªæ”¯æŒå¤šç±»æ—¶é—´ç®—å­ã€é€šç”¨æ¨¡å‹æ¶æ„ã€å…·å¤‡è‡ªåŠ¨ç¼–è¯‘æµæ°´çº¿çš„ SSM åŒ–æ¨ç†ä¼˜åŒ–æ¡†æ¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ¨¡å‹ï¼ˆéä¼ ç»Ÿâ€œæ•°æ®é›†â€ï¼Œè€Œæ˜¯å…¸å‹ TinyML æ—¶é—´åºåˆ—æ¨¡å‹ï¼‰
å®éªŒæœªä½¿ç”¨æ ‡å‡†æ•°æ®é›†ï¼Œè€Œæ˜¯é€‰å–äº†å¤šä¸ªä»£è¡¨æ€§çš„æ—¶é—´åºåˆ—æ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–ä¸åŒæ¶æ„ç±»å‹ï¼š

| æ¨¡å‹ | ç±»å‹ | ç‰¹å¾ |
|------|------|------|
| **WaveNet** | çº¯æ—¶é—´å·ç§¯ç”Ÿæˆæ¨¡å‹ | Dilated 1D Conv æ ˆï¼Œç”¨äºè¯­éŸ³ç”Ÿæˆ |
| **TC-CNN**, **TEMPONet**, **ResTCN** | CNN + Dense åˆ†ç±»/ç”Ÿæˆæ¨¡å‹ | ä½¿ç”¨å·ç§¯å’Œæ± åŒ–æå–ç‰¹å¾ |
| **CET-S**, **TC-TFM** | Transformer-based æ¨¡å‹ | åŒ…å« Attention å±‚ï¼Œæœ€ç»ˆåˆ†ç±» |

æ‰€æœ‰æ¨¡å‹å‡é€‚é…è‡³å¯åœ¨ MCU ä¸Šè¿è¡Œçš„å°è§„æ¨¡ç‰ˆæœ¬ã€‚

---

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - ä¸»æµ‹è¯•å¹³å°ï¼š**STM32F767ZI MCU**
    - RAM: 512 KB
    - Flash: 2 MB
    - CPU: ARM Cortex-M7 @ 216 MHz
  - å…¶ä»–éªŒè¯å¹³å°ï¼šESP32ã€RISC-Vã€x86ï¼ˆéªŒè¯å¯ç§»æ¤æ€§ï¼‰
- **è½¯ä»¶æ ˆ**ï¼š
  - å‰ç«¯ï¼šPyTorch v2.3.0
  - ç¼–è¯‘å™¨åç«¯ï¼šmicroTVM v0.16.0
  - éƒ¨ç½²ç¯å¢ƒï¼šRIOT-MLï¼ˆè½»é‡çº§ç‰©è”ç½‘æ“ä½œç³»ç»Ÿé›†æˆï¼‰

---

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Peak RAM Usage** | æ¨ç†è¿‡ç¨‹ä¸­æœ€å¤§ç¬æ—¶å†…å­˜å ç”¨ |
| **Compute Latency** | å•æ ·æœ¬æ¨ç†å»¶è¿Ÿï¼ˆåˆ† Preheat å’Œ Streaming é˜¶æ®µï¼‰ |
| **Overlap Rate** | æ»‘åŠ¨çª—å£é‡å ç‡ï¼š$ \text{Toverlap} = 1 - s/l $ï¼Œå…¶ä¸­ $s$: stride, $l$: window length |
| **Relative RMSE** | BF16 ä¸ FP32 è¾“å‡ºä¹‹é—´çš„ç›¸å¯¹å‡æ–¹æ ¹è¯¯å·®ï¼Œè¡¡é‡ç²¾åº¦å½±å“ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Vanilla Inference**ï¼šæ ‡å‡†é€çª—å£é‡è®¡ç®—æ–¹å¼ï¼ˆæ— ä»»ä½•ä¼˜åŒ–ï¼‰
- **FastWaveNet**ï¼šä»…é’ˆå¯¹ WaveNet çš„ç¼“å­˜ä¼˜åŒ–æ–¹æ¡ˆ
- **StreamiNNC**ï¼šåˆ©ç”¨å·ç§¯å¹³ç§»ä¸å˜æ€§è·³è¿‡å†—ä½™è®¡ç®—
- **microTVM baseline**ï¼šç›´æ¥éƒ¨ç½²æœªç» SSM è½¬æ¢çš„æ¨¡å‹

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### ğŸ“Š è¡¨ 2ï¼šWaveNet å®éªŒç»“æœï¼ˆç”Ÿæˆ 10,000 ä¸ªæ ·æœ¬ï¼‰
| æ–¹æ³• | RAM Usage | Preheat (ms) | Streaming (ms/sample) |
|------|------------|---------------|--------------------------|
| Vanilla WaveNet | 178.5 MB (**OOM**) | OOM | â€“ |
| TinyDejaVu | **142.6 kB** | 2776.1 | **14.1** |
| + BF16 | **108.3 kB** (-24%) | 3157.1 | 16.0 (+13%) |

> âš¡ï¸ **ç»“è®º**ï¼š
> - RAM ä½¿ç”¨ä»…ä¸ºåŸç‰ˆçš„ **0.08%**
> - Streaming é˜¶æ®µæ¯” Preheat å¿«è¿‘ **200 å€**
> - BF16 å†é™ 31% RAMï¼Œä»£ä»·ä»…ä¸º 13% è®¡ç®—å¼€é”€

---

#### ğŸ“ˆ å›¾ 4ï¼šå„ç±»æ¨¡å‹ RAM ä½¿ç”¨å¯¹æ¯”ï¼ˆå½’ä¸€åŒ–ï¼‰
- æ‰€æœ‰æ¨¡å‹åœ¨ TinyDejaVu ä¸‹å®ç° **è‡³å°‘ 60% RAM èŠ‚çœ**
- æœ€ä½³æƒ…å†µï¼ˆTC-TFMã€TC-CNNï¼‰æ¥è¿‘ **>99% RAM å‡å°‘**
- å¯ç”¨ BF16 åè¿›ä¸€æ­¥ä¸‹é™ï¼ˆé™¤ CET-S å¤–ï¼‰

> ğŸ’¡ åŸå› åˆ†æï¼šTC-TFM è¾“å…¥çª—å£å¤§ï¼ˆ48Kï¼‰ï¼Œä½†æ„Ÿå—é‡å°ï¼ˆkernel=3ï¼‰ï¼Œå› æ­¤ SSM è½¬æ¢æ”¶ç›Šå·¨å¤§ã€‚

---

#### ğŸ“‰ å›¾ 5ï¼šä¸åŒé‡å ç‡ä¸‹çš„ Streaming æ¨ç†å»¶è¿Ÿï¼ˆå½’ä¸€åŒ–ï¼‰
- éšç€ **Overlap Rate â†‘**ï¼Œå»¶è¿Ÿ **çº¿æ€§ä¸‹é™**
- è¡¨æ˜ TinyDejaVu æˆåŠŸæ¶ˆé™¤å†—ä½™è®¡ç®—
- ResTCN å’Œ TEMPONet åœ¨ä½é‡å ç‡ä¸‹ä»ä¿æŒè¾ƒä½å»¶è¿Ÿ â†’ æ·±å±‚ SSM æ›´å¥½åœ°ä¿ç•™å†å²ä¿¡æ¯

---

#### ğŸ” ç²¾åº¦å½±å“ï¼ˆBF16ï¼‰
- æ‰€æœ‰æ¨¡å‹è¾“å‡ºçš„ **Relative RMSE åœ¨ 1%~3% ä¹‹é—´**
- ç²¾åº¦ä¸‹é™å¯å¿½ç•¥
- å»ºè®®ï¼šè‹¥è¿½æ±‚é›¶ç²¾åº¦æŸå¤±ï¼Œå¯åœ¨ BF16 ä¸‹é‡æ–°è®­ç»ƒæ¨¡å‹

---

### æ¶ˆèå®éªŒï¼ˆéšå«åœ¨åˆ†æä¸­ï¼‰
è™½ç„¶æ²¡æœ‰æ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»ä»¥ä¸‹æ–¹é¢ä½“ç°äº†æ¨¡å—æœ‰æ•ˆæ€§ï¼š
| ç»„ä»¶ | æ•ˆæœ |
|------|------|
| SSM è½¬æ¢ | RAM é™ä½ $T/N$ å€ï¼ˆ$T$: æ„Ÿå—é‡ï¼Œ$N$: åºåˆ—é•¿åº¦ï¼‰ |
| Global Pooling SSM åŒ– | RAM ä» $O(N)$ â†’ $O(N/s)$ |
| BF16 å­˜å‚¨ | éšè—çŠ¶æ€ RAM å ç”¨å‡åŠ |
| Graph Partitioning | ä»…æ›´æ–°å¿…è¦éƒ¨åˆ†ï¼Œæå‡è®¡ç®—æ•ˆç‡ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **SSM æ˜¯ç»Ÿä¸€è¡¨è¾¾æ—¶é—´ç®—å­çš„æœ‰æ•ˆèŒƒå¼**  
   å·ç§¯ã€æ± åŒ–ç­‰å‡å¯è½¬åŒ–ä¸º SSMï¼Œå®ç°æµå¼å¤„ç†ï¼Œæ‰“ç ´â€œå¿…é¡»ç¼“å­˜æ•´ä¸ªçª—å£â€çš„æ€ç»´å®šå¼ã€‚

2. âœ… **TinyDejaVu æ˜¾è‘—é™ä½ MCU ä¸Šçš„æ—¶é—´åºåˆ—æ¨ç†æˆæœ¬**  
   - æœ€é«˜èŠ‚çœ **99% RAM**
   - Streaming é˜¶æ®µæé€Ÿæœ€é«˜è¾¾ **200Ã—**

3. âœ… **æ”¯æŒå¤šæ ·åŒ–æ¨¡å‹æ¶æ„**  
   ä¸ä»…é€‚ç”¨äºçº¯ CNN/TN æ¨¡å‹ï¼Œä¹Ÿå…¼å®¹å« Attention çš„ Transformer æ¨¡å‹ã€‚

4. âœ… **å…·å¤‡è‰¯å¥½å¯ç§»æ¤æ€§å’Œå®ç”¨æ€§**  
   åŸºäº microTVM ç”Ÿæˆå¹³å°æ— å…³ C ä»£ç ï¼Œå·²åœ¨å¤šç§ MCU ä¸ŠéªŒè¯å¯ç”¨ã€‚

5. âœ… **Overlap Rate æ˜¯æ§åˆ¶ä¼˜åŒ–ç¨‹åº¦çš„å…³é”®å‚æ•°**  
   ç”¨æˆ·å¯é€šè¿‡è°ƒèŠ‚æ»‘åŠ¨çª—å£æ­¥é•¿æ¥æƒè¡¡å®æ—¶æ€§ä¸èµ„æºæ¶ˆè€—ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
| å±€é™ | è¯´æ˜ |
|------|------|
| **GTA å±‚ä»æ˜¯ç“¶é¢ˆ** | å¦‚ Attentionã€Global Pooling è‹¥ä½äºæ·±å±‚ï¼Œä»éœ€è¾ƒå¤§å†…å­˜ï¼Œæ— æ³•å®Œå…¨é¿å… |
| **åˆå§‹åŒ–é˜¶æ®µï¼ˆPreheatï¼‰è¾ƒæ…¢** | ç¬¬ä¸€ä¸ªçª—å£éœ€å®Œæ•´è®¡ç®—ï¼Œä¸é€‚åˆå†·å¯åŠ¨è¦æ±‚æé«˜çš„åœºæ™¯ |
| **ä¸é€‚ç”¨äºéå› æœæ¨¡å‹** | è‹¥æ¨¡å‹ä¾èµ–æœªæ¥ä¿¡æ¯ï¼ˆé causalï¼‰ï¼Œåˆ™ä¸èƒ½ä½¿ç”¨ SSM æµå¼å¤„ç† |
| **ç²¾åº¦å¾®æŸï¼ˆBF16ï¼‰** | è™½ç„¶ RMSE å¾ˆå°ï¼Œä½†åœ¨æ•æ„Ÿä»»åŠ¡ä¸­å¯èƒ½éœ€é‡æ–°è®­ç»ƒ |

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•æ›´å¤šç®—å­æ”¯æŒ**  
   å½“å‰ä¸»è¦è¦†ç›– Convã€Poolingã€Linearï¼Œæœªæ¥å¯åŠ å…¥æ›´å¤æ‚çš„ temporal blocksã€‚

2. **è‡ªåŠ¨åŒ–æ¨¡å‹é‡æ„å·¥å…·é“¾**  
   å¼€å‘ GUI å·¥å…·æˆ– CLI æ’ä»¶ï¼Œè®©ç”¨æˆ·ä¸€é”®å®Œæˆ SSM è½¬æ¢ä¸éƒ¨ç½²ã€‚

3. **ç»“åˆé‡åŒ–ä¸å‰ªæ**  
   å°† SSM ä¼˜åŒ–ä¸æ¨¡å‹å‹ç¼©æŠ€æœ¯ï¼ˆå¦‚ INT8 Quantizationï¼‰ç»“åˆï¼Œè¿›ä¸€æ­¥é™ä½èµ„æºéœ€æ±‚ã€‚

4. **åœ¨çº¿è‡ªé€‚åº” overlap æ§åˆ¶**  
   åŠ¨æ€è°ƒæ•´æ»‘åŠ¨çª—å£ strideï¼Œæ ¹æ®è¾“å…¥ä¿¡å·å˜åŒ–æ™ºèƒ½å¹³è¡¡ç²¾åº¦ä¸æ•ˆç‡ã€‚

5. **æ”¯æŒæ›´å¤šç¡¬ä»¶åŠ é€Ÿå™¨**  
   é›†æˆåˆ° GAP8ã€Greenwaves ç­‰ä¸“ç”¨ TinyML èŠ¯ç‰‡ä¸­ï¼Œå‘æŒ¥æ›´å¤§æ•ˆèƒ½ã€‚

---

## æ€»ç»“
> **TinyDejaVu æ˜¯ä¸€é¡¹é¢å‘ MCU ä¸Šé•¿æ—¶é—´åºåˆ—æµå¼æ¨ç†çš„é‡å¤§è¿›æ­¥**ã€‚å®ƒé€šè¿‡å°†æ—¶é—´ç®—å­ç»Ÿä¸€å»ºæ¨¡ä¸º SSMï¼Œä»æ ¹æœ¬ä¸Šè§£å†³äº†æ»‘åŠ¨çª—å£å¸¦æ¥çš„å†…å­˜çˆ†ç‚¸ä¸è®¡ç®—å†—ä½™é—®é¢˜ã€‚å…¶å®éªŒç»“æœè¯æ˜ï¼Œåœ¨çœŸå® MCU å¹³å°ä¸Šå®ç°äº† **ä¸¤ä¸ªæ•°é‡çº§çš„ RAM èŠ‚çœ** å’Œ **ç™¾å€ä»¥ä¸Šçš„æ¨ç†åŠ é€Ÿ**ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹å‡†ç¡®æ€§ã€‚è¯¥å·¥ä½œä¸ä»…æå‡ºäº†æ–°ç†è®ºè§†è§’ï¼Œè¿˜æä¾›äº†å¼€æºã€å¯å¤ç°ã€å¯éƒ¨ç½²çš„å®Œæ•´å·¥å…·é“¾ï¼Œä¸ºä¸‹ä¸€ä»£ä½åŠŸè€—ã€å§‹ç»ˆåœ¨çº¿çš„æ™ºèƒ½ä¼ æ„Ÿç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚

</details>

---

### 7. [d-TreeRPO: Towards More Reliable Policy Optimization for Diffusion Language Models](https://arxiv.org/abs/2512.09675)

**Authors**: Leyi Pan, Shuchang Tao, Yunpeng Zhai, Zheyu Fu, Liancheng Fang, Minghua He, Lingzhe Zhang, Zhaoyang Liu, Bolin Ding, Aiwei Liu, Lijie Wen  
**Category**: cs.CL  
**Published**: 2025-12-11  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.09675v1  

#### Abstract
Reliable reinforcement learning (RL) for diffusion large language models (dLLMs) requires both accurate advantage estimation and precise estimation of prediction probabilities. Existing RL methods for dLLMs fall short in both aspects: they rely on coarse or unverifiable reward signals, and they esti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šd-TreeRPO: Towards More Reliable Policy Optimization for Diffusion Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰é’ˆå¯¹ **diffusion large language models (dLLMs)** çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•åœ¨ä»¥ä¸‹ä¸¤ä¸ªæ–¹é¢å­˜åœ¨æ˜¾è‘—ç¼ºé™·ï¼š
- **Reward è®¾è®¡ç¼ºä¹ç»†ç²’åº¦å’Œå¯éªŒè¯æ€§**ï¼šå¤šæ•°æ–¹æ³•ä¾èµ–ç¨€ç–çš„æœ€ç»ˆç»“æœå¥–åŠ±ï¼ˆoutcome rewardsï¼‰ï¼Œå¿½ç•¥ä¸­é—´å»å™ªæ­¥éª¤ï¼›æˆ–ä½¿ç”¨æœªç»éªŒè¯çš„è¿‡ç¨‹ä¿¡å·ï¼ˆå¦‚å‡åŒ€å¹¿æ’­å¥–åŠ±ã€æ¨¡å‹é¢„æµ‹çŠ¶æ€å¥–åŠ±ï¼‰ï¼Œæ˜“å¯¼è‡´ **reward hacking**ã€‚
- **Action log-probability ä¼°è®¡ä¸å‡†ç¡®**ï¼šç”±äº dLLMs æ”¯æŒä»»æ„é¡ºåºè§£ç ï¼ˆany-order decodingï¼‰ï¼Œæ— æ³•åƒ auto-regressive (AR) æ¨¡å‹é‚£æ ·é€šè¿‡é“¾å¼æ³•åˆ™ç²¾ç¡®è®¡ç®—æ¦‚ç‡ã€‚ç°æœ‰æ–¹æ³•ï¼ˆå¦‚åŸºäº ELBO çš„ä¼°è®¡ï¼‰å­˜åœ¨æœªåˆ†æçš„åå·®ï¼Œä¸”å¤šéœ€å¤šæ¬¡å‰å‘ä¼ æ’­ï¼Œæ•ˆç‡ä½ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šd-TreeRPO
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡º **d-TreeRPO** â€”â€”ä¸€ç§æ›´å¯é çš„ dLLM ç­–ç•¥ä¼˜åŒ–æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰æ ‘ç»“æ„ Rollout ä¸è‡ªåº•å‘ä¸Šä¼˜åŠ¿è®¡ç®—ï¼ˆTree-Structured Rollout & Bottom-Up Advantageï¼‰
- å°† rollout ç»„ç»‡æˆä¸€æ£µæ ‘ç»“æ„ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªéƒ¨åˆ†è§£ç çŠ¶æ€ã€‚
- å¶å­èŠ‚ç‚¹å¯¹åº”å®Œæ•´ç”Ÿæˆç»“æœï¼Œå¹¶èµ‹äºˆ **å¯éªŒè¯çš„ç»“æœå¥–åŠ±**ï¼ˆå¦‚æ•°ç‹¬æ˜¯å¦æ­£ç¡®ï¼‰ã€‚
- å¥–åŠ±ä»å¶èŠ‚ç‚¹å‘ä¸Šèšåˆï¼šçˆ¶èŠ‚ç‚¹å¥–åŠ± $ R_p = \frac{1}{|C_p|} \sum_{c \in C_p} R_c $
- å­èŠ‚ç‚¹ç›¸å¯¹äºçˆ¶èŠ‚ç‚¹çš„ä¼˜åŠ¿å®šä¹‰ä¸ºï¼š$ A_c = R_c - R_p $

ğŸ‘‰ è¿™ç§æœºåˆ¶æä¾›äº†**å¯†é›†ã€å¯éªŒè¯ã€åŸºäºå®é™…é‡‡æ ·ç»“æœçš„é€æ­¥éª¤å¥–åŠ±ä¿¡å·**ï¼Œé¿å…äº† reward hacking é£é™©ã€‚

#### ï¼ˆ2ï¼‰å•æ¬¡å‰å‘ä¼ é€’çš„æ¦‚ç‡ä¼°è®¡ + è‡ªè’¸é¦æŸå¤±æå‡ç½®ä¿¡åº¦
- ä½¿ç”¨å•æ¬¡å‰å‘ä¼ é€’ï¼ˆsingle-time forward passï¼‰ä¼°ç®—çˆ¶å­èŠ‚ç‚¹é—´çš„è½¬ç§»å¯¹æ•°æ¦‚ç‡ï¼ˆlog-probabilityï¼‰ã€‚
- ç†è®ºè¯æ˜ï¼šè¯¥ä¼°è®¡è¯¯å·®éšæ¨¡å‹é¢„æµ‹ç½®ä¿¡åº¦å¢åŠ è€Œå‡å°ï¼ˆå³ç¡®å®šæ€§è¶Šé«˜ï¼Œä¼°è®¡è¶Šå‡†ï¼‰ã€‚
- å¼•å…¥ **time-scheduled self-distillation loss**ï¼š
  - æ—©æœŸè®­ç»ƒé˜¶æ®µæ”¾æ¾çº¦æŸï¼Œé¼“åŠ±æ¢ç´¢ï¼›
  - åæœŸé€æ­¥å¢å¼ºçº¦æŸï¼Œæé«˜ç­–ç•¥ç¡®å®šæ€§ï¼Œä»è€Œé™ä½æ¦‚ç‡ä¼°è®¡è¯¯å·®å¹¶ä¿ƒè¿›æ”¶æ•›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³• | d-TreeRPO |
|------|--------|----------|
| Reward Granularity & Verifiability | ç¨€ç–æˆ–ä¸å¯éªŒè¯è¿‡ç¨‹å¥–åŠ± | å¯†é›†ã€å¯éªŒè¯ã€åŸºäºé‡‡æ ·çš„é€æ­¥å¥–åŠ± |
| Log-Probability Estimation | åå·®å¤§ã€éœ€å¤šè½®å‰ä¼ ã€æ— ç†è®ºä¿éšœ | å•æ¬¡å‰ä¼  + ç†è®ºè¯¯å·®ç•Œ + è‡ªè’¸é¦æå‡ç²¾åº¦ |
| æ¢ç´¢-åˆ©ç”¨æƒè¡¡ | å›ºå®šç­–ç•¥ | åŠ¨æ€è°ƒåº¦ï¼šå…ˆæ¢ç´¢åèšç„¦ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒæ¶µç›–å››ç±»æ¨ç†ä»»åŠ¡ï¼š
- **Sudoku**ï¼š4x4 æ•°ç‹¬æ±‚è§£ï¼ˆæ¥è‡ª Diffu-GRPO æä¾›çš„æ•°æ®é›†ï¼‰
- **Countdown**ï¼šæ•°å­—æ‹¼å‡‘æ¸¸æˆï¼ˆ3-to-4 Countdown ä»»åŠ¡ï¼‰
- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜
- **Math500**ï¼šä¸­ç­‰éš¾åº¦æ•°å­¦é—®é¢˜

æ‰€æœ‰ä»»åŠ¡é‡‡ç”¨é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰è¯„ä¼°ï¼Œpass@1 ä½œä¸ºè¯„åˆ†æ ‡å‡†ã€‚

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼šLLaDA-8B-Instructï¼ˆå·²å®Œæˆç›‘ç£å¾®è°ƒï¼Œæœªè¿›è¡Œ RLï¼‰
- **è®­ç»ƒæ–¹å¼**ï¼š
  - ä½¿ç”¨ LoRAï¼ˆrank=128, Î±=64ï¼‰
  - æœ€å¤§ç”Ÿæˆé•¿åº¦ 256 tokensï¼Œå—é•¿åº¦ 32ï¼Œå…± 128 æ­¥å»å™ª
  - Tree ç»“æ„å‚æ•°ï¼šé«˜åº¦ $ H=2 $ï¼Œåˆ†æ”¯å› å­ $ B=4 $
- **è¯„ä¼°è®¾ç½®**ï¼š
  - ä¸¤ç§ç”Ÿæˆé•¿åº¦ï¼š256 å’Œ 512 tokens
  - å»å™ªæ­¥æ•°ä¸ºç”Ÿæˆé•¿åº¦çš„ä¸€åŠ
  - æ¸©åº¦ä¸º 0.0ï¼ˆç¡®å®šæ€§é‡‡æ ·ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å¯¹æ¯”äº†å¤šä¸ªç°æœ‰çš„ dLLM RL æ–¹æ³•ï¼š
- **Diffu-GRPO**ï¼ˆZhao et al., 2025ï¼‰
- **VRPO**ï¼ˆZhu et al., 2025aï¼‰
- **wd1**ï¼ˆTang et al., 2025ï¼‰
- **SAPO+**ï¼ˆXie et al., 2025aï¼‰
- **d2-stepMerge**ï¼ˆWang et al., 2025aï¼‰
- **TraceRL**ï¼ˆWang et al., 2025bï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆ256-token settingï¼‰
| æ–¹æ³• | Sudoku | Countdown | GSM8K | Math500 |
|------|--------|-----------|-------|---------|
| Base Model (LLaDA-8B-Instruct) | 6.7 | 19.5 | 76.7 | 32.4 |
| **d-TreeRPO (Ours)** | **92.9** (+86.2) | **71.1** (+51.6) | **81.2** (+4.5) | **37.7** (+5.3) |

> âœ… åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡å–å¾— SOTA è¡¨ç°ï¼Œå°¤å…¶åœ¨ Sudoku ä¸Šå®ç°å·¨å¤§é£è·ƒï¼ˆ+86.2ï¼‰ã€‚

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”
- åœ¨ Sudoku ä¸Šï¼Œd-TreeRPO æ˜¾è‘—ä¼˜äºæœ€å¼ºåŸºçº¿ d2-stepMergeï¼ˆ76.1 â†’ 92.9ï¼‰
- åœ¨ Countdown ä¸Šè¶…è¶Šæ‰€æœ‰åŸºçº¿ï¼ˆæœ€é«˜è¾¾ 71.1ï¼‰
- åœ¨ GSM8K å’Œ Math500 ä¸Šä¹Ÿç¨³å®šé¢†å…ˆï¼Œè¯´æ˜å…¶æ³›åŒ–èƒ½åŠ›å¼º

### æ¶ˆèå®éªŒç»“æœ
è¿›è¡Œäº†ä¸‰é¡¹å…³é”®æ¶ˆèç ”ç©¶ï¼š

#### ï¼ˆ1ï¼‰ç§»é™¤ self-distillation loss
| æ–¹æ³• | Sudoku | Countdown | GSM8K | Math500 |
|------|--------|-----------|-------|---------|
| d-TreeRPO (Full) | 92.9 | 71.1 | 81.2 | 37.7 |
| w/o self-distillation | 89.8 | 66.4 | 80.9 | 36.1 |

ğŸ‘‰ ç§»é™¤åæ€§èƒ½å…¨é¢ä¸‹é™ï¼ŒéªŒè¯äº† self-distillation å¯¹æ”¶æ•›å’Œæ€§èƒ½çš„é‡è¦æ€§ã€‚

#### ï¼ˆ2ï¼‰æ›¿æ¢ä¸ºâ€œå¤šæ ·æ€§ä¿ƒè¿›â€æŸå¤±ï¼ˆdiversity-promoting lossï¼‰
è®¾è®¡äº†ä¸€ä¸ªåå‘ç›®æ ‡ï¼šæ•…æ„æ‹‰ä½é«˜ä¼˜åŠ¿åŠ¨ä½œçš„ç½®ä¿¡åº¦ï¼Œå¢åŠ åæœŸä¸ç¡®å®šæ€§ã€‚
- ç»“æœæ˜¾ç¤ºè¯¥å˜ä½“ä¸ä»…æœ€ç»ˆæ€§èƒ½æœ€å·®ï¼ˆSudoku: 84.2ï¼‰ï¼Œä¸”è®­ç»ƒä¸ç¨³å®šã€‚
- æ”¯æŒäº†â€œåæœŸåº”å¢å¼ºç¡®å®šæ€§â€çš„è®¾è®¡ç†å¿µã€‚

#### ï¼ˆ3ï¼‰æ—¶é—´è°ƒåº¦ç­–ç•¥åˆ†æï¼ˆreverse scheduleï¼‰
å°† self-distillation çš„æƒé‡ $ \lambda(t) $ å’Œæ¸©åº¦ $ \tau(t) $ è°ƒåº¦åè½¬ï¼ˆåˆæœŸå¼ºè’¸é¦ï¼ŒåæœŸå¼±ï¼‰ï¼š
- åˆæœŸæå‡æ›´å¿«ï¼Œä½†ä¸­æœŸå¼€å§‹æ€§èƒ½å›è½ï¼ˆreward ä» ~0.75 ä¸‹é™ï¼‰
- è¯´æ˜è¿‡æ—©å›ºåŒ–ç­–ç•¥ä¼šæŸå®³æ³›åŒ–èƒ½åŠ›

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç»†ç²’åº¦ã€å¯éªŒè¯çš„å¥–åŠ±ä¿¡å·è‡³å…³é‡è¦**ï¼šé€šè¿‡æ ‘ç»“æ„ rollout å’Œ bottom-up å¥–åŠ±ä¼ æ’­ï¼Œå®ç°äº†çœŸæ­£æ„ä¹‰ä¸Šçš„ step-wise ä¼˜åŠ¿ä¼°è®¡ï¼Œæå‡äº† RL ä¼˜åŒ–å¯é æ€§ã€‚
2. **é¢„æµ‹ç½®ä¿¡åº¦ç›´æ¥å½±å“æ¦‚ç‡ä¼°è®¡å‡†ç¡®æ€§**ï¼šç†è®ºè¯æ˜äº† single-pass æ¦‚ç‡ä¼°è®¡è¯¯å·®éšæ¨¡å‹ç¡®å®šæ€§å‡é«˜è€Œé™ä½ã€‚
3. **åŠ¨æ€è°ƒåº¦çš„ self-distillation æ˜¯å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨çš„æœ‰æ•ˆæ‰‹æ®µ**ï¼šå‰æœŸé¼“åŠ±æ¢ç´¢ï¼ŒåæœŸæå‡ç¡®å®šæ€§ï¼Œå…¼é¡¾å­¦ä¹ æ•ˆç‡ä¸æœ€ç»ˆæ€§èƒ½ã€‚
4. **d-TreeRPO åœ¨å¤šä¸ªå¤æ‚æ¨ç†ä»»åŠ¡ä¸Šæ˜¾è‘—è¶…è¶Šç°æœ‰æ–¹æ³•**ï¼Œå°¤å…¶æ˜¯åœ¨é€»è¾‘ä¸¥å¯†çš„ä»»åŠ¡ï¼ˆå¦‚ Sudokuï¼‰ä¸Šè¡¨ç°çªå‡ºã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼štree rollout çš„è®¡ç®—å¤æ‚åº¦éš $ H $ å’Œ $ B $ æŒ‡æ•°å¢é•¿ï¼Œé™åˆ¶äº†æ›´å¤§è§„æ¨¡ tree çš„ä½¿ç”¨ï¼ˆæ–‡ä¸­ $ H=2, B=4 $ å·²æ¥è¿‘èµ„æºæé™ï¼‰ã€‚
- **ä¾èµ–å¯éªŒè¯çš„æœ€ç»ˆå¥–åŠ±**ï¼šé€‚ç”¨äºæœ‰æ˜ç¡®ç­”æ¡ˆçš„ä»»åŠ¡ï¼ˆå¦‚æ•°å­¦ã€è°œé¢˜ï¼‰ï¼Œå¯¹å¼€æ”¾ç”Ÿæˆä»»åŠ¡ï¼ˆå¦‚åˆ›æ„å†™ä½œï¼‰é€‚ç”¨æ€§æœ‰é™ã€‚
- **å½“å‰å®ç°ä»åŸºäº block-wise decoding**ï¼Œå°šæœªå®Œå…¨é‡Šæ”¾ä»»æ„é¡ºåºè§£ç çš„æ½œåŠ›ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•åˆ°æ›´å¤šç±»å‹çš„ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚ä»£ç ç”Ÿæˆã€å¯¹è¯ç³»ç»Ÿï¼‰
- æ¢ç´¢æ›´é«˜æ•ˆçš„ tree æ„å»ºä¸å‰ªæç­–ç•¥ä»¥é™ä½è®¡ç®—æˆæœ¬
- å°† tree ç»“æ„ä¸ value-based RL æ–¹æ³•ç»“åˆï¼Œè¿›ä¸€æ­¥æå‡ç¨³å®šæ€§
- ç ”ç©¶å¦‚ä½•åœ¨éç¡®å®šæ€§å¥–åŠ±åœºæ™¯ä¸‹åº”ç”¨ç±»ä¼¼æ€æƒ³

---

> ğŸ”š **æ€»ç»“**ï¼š  
> d-TreeRPO æ˜¯é¦–ä¸ªç³»ç»Ÿæ€§è§£å†³ dLLM å¼ºåŒ–å­¦ä¹ ä¸­ **å¥–åŠ±å¯ä¿¡åº¦** ä¸ **æ¦‚ç‡ä¼°è®¡åå·®** ä¸¤å¤§æŒ‘æˆ˜çš„å·¥ä½œã€‚å®ƒé€šè¿‡ **æ ‘ç»“æ„ rollout + è‡ªåº•å‘ä¸Šå¥–åŠ±ä¼ æ’­ + æ—¶é—´è°ƒåº¦è‡ªè’¸é¦** çš„ç»„åˆè®¾è®¡ï¼Œåœ¨ç†è®ºä¸å®è·µå±‚é¢éƒ½å±•ç°å‡ºå“è¶Šæ•ˆæœï¼Œä¸º diffusion language models çš„å¯é å¼ºåŒ–å­¦ä¹ å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚

</details>

---

### 8. [Semantic-Aware Cooperative Communication and Computation Framework in Vehicular Networks](https://arxiv.org/abs/2512.09621)

**Authors**: Jingbo Zhang, Maoxin Ji, Qiong Wu, Pingyi Fan, Kezhi Wang, Wen Chen  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.09621v1  

#### Abstract
Semantic Communication (SC) combined with Vehicular edge computing (VEC) provides an efficient edge task processing paradigm for Internet of Vehicles (IoV). Focusing on highway scenarios, this paper proposes a Tripartite Cooperative Semantic Communication (TCSC) framework, which enables Vehicle User...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSemantic-Aware Cooperative Communication and Computation Framework in Vehicular Networks

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬æ–‡èšç„¦äº**é«˜é€Ÿå…¬è·¯åœºæ™¯ä¸‹çš„è½¦è”ç½‘ï¼ˆInternet of Vehicles, IoVï¼‰ä¸­ä»»åŠ¡å¸è½½å»¶è¿Ÿé«˜ã€é€šä¿¡æ•ˆç‡ä½**çš„é—®é¢˜ã€‚ä¼ ç»ŸåŸºäºæ¯”ç‰¹çº§é€šä¿¡ï¼ˆbit-level communicationï¼‰çš„ä»»åŠ¡å¸è½½æœºåˆ¶å­˜åœ¨å†—ä½™é«˜ã€éš¾ä»¥æ»¡è¶³è¶…ä½æ—¶å»¶å’Œé«˜å¯é æ€§éœ€æ±‚çš„ç¼ºé™·ã€‚æ­¤å¤–ï¼Œç°æœ‰ç ”ç©¶å¤§å¤šä»…è€ƒè™‘ **Vehicle-to-Infrastructure (V2I)** é“¾è·¯ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨ **Vehicle-to-Vehicle (V2V)** åä½œå¸¦æ¥çš„èµ„æºçµæ´»æ€§ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Tripartite Cooperative Semantic Communication (TCSC)** çš„æ¡†æ¶ï¼Œå¹¶è®¾è®¡äº†ç»“åˆå¼ºåŒ–å­¦ä¹ ä¸ä¼˜åŒ–ç†è®ºçš„è”åˆç®—æ³•ï¼š

- **TCSC æ¡†æ¶**ï¼šæ„å»ºäº†ä¸€ä¸ªä¸‰å…ƒååŒè¯­ä¹‰é€šä¿¡æ¶æ„ï¼Œæ”¯æŒè½¦è¾†ç”¨æˆ·ï¼ˆVUsï¼‰é€šè¿‡ **V2I å’Œ V2V åŒé“¾è·¯** å°†è¯­ä¹‰ä»»åŠ¡å¸è½½è‡³è·¯è¾¹å•å…ƒï¼ˆRSUï¼‰æˆ–æœåŠ¡è½¦è¾†ï¼ˆSVsï¼‰ï¼Œå®ç°æ›´çµæ´»é«˜æ•ˆçš„è¾¹ç¼˜è®¡ç®—åä½œã€‚
  
- **MAPPO-PDN + LP è”åˆä¼˜åŒ–æ–¹æ³•**ï¼š
  - **MAPPO-PDN**ï¼šæå‡ºä¸€ç§åŸºäºå‚æ•°åˆ†å¸ƒå™ªå£°çš„å¤šæ™ºèƒ½ä½“è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ç®—æ³•ï¼ˆMulti-Agent Proximal Policy Optimization with Parametric Distribution Noiseï¼‰ï¼Œç”¨äºä¼˜åŒ–ç¦»æ•£å˜é‡â€”â€”æ¯ä¸ªè¯ä¼ è¾“çš„è¯­ä¹‰ç¬¦å·æ•°é‡ $k_{i,j}$ã€‚
    - åˆ›æ–°åœ°å°†ç­–ç•¥ç½‘ç»œå‚æ•°å»ºæ¨¡ä¸ºé«˜æ–¯åˆ†å¸ƒï¼Œå¼•å…¥ **Parametric Distribution Noise (PDN)** æ­£åˆ™é¡¹ï¼Œæå‡æ¨¡å‹åœ¨éå¹³ç¨³ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚
  - **Linear Programming (LP)**ï¼šåˆ©ç”¨çº¿æ€§è§„åˆ’æ±‚è§£è¿ç»­å˜é‡â€”â€”ä»»åŠ¡å¸è½½æ¯”ä¾‹ $p$ï¼Œé™ä½æ•´ä½“ä¼˜åŒ–å¤æ‚åº¦å¹¶æé«˜ç²¾åº¦ã€‚

è¯¥æ–¹æ³•å®ç°äº†å¯¹è¯­ä¹‰ç¬¦å·æ•° $k$ å’Œå¸è½½æ¯”ç‡ $p$ çš„è”åˆä¼˜åŒ–ï¼Œåœ¨ä¿è¯è¯­ä¹‰ç›¸ä¼¼åº¦çš„å‰æä¸‹æœ€å°åŒ–ç³»ç»Ÿæ€»å»¶è¿Ÿã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | æœ¬æ–‡æ–¹æ³•ï¼ˆTCSC + MAPPO-PDN + LPï¼‰ | ç°æœ‰å…¸å‹æ–¹æ³• |
|--------|-------------------------------|-------------|
| é€šä¿¡èŒƒå¼ | è¯­ä¹‰é€šä¿¡ï¼ˆSemantic Communication, SCï¼‰ | ä¼ ç»Ÿæ¯”ç‰¹çº§é€šä¿¡ |
| å¸è½½æ–¹å¼ | æ”¯æŒ V2I + V2V ååŒå¸è½½ | å¤šæ•°ä»…æ”¯æŒ V2I |
| å­¦ä¹ æœºåˆ¶ | å¼•å…¥ PDN å»ºæ¨¡ç­–ç•¥ä¸ç¡®å®šæ€§ï¼Œå¢å¼ºæ¢ç´¢å¤šæ ·æ€§ | ä¼ ç»Ÿ MARL æ˜“è¿‡æ‹Ÿåˆã€æ”¶æ•›ä¸ç¨³å®š |
| ä¼˜åŒ–ç»“æ„ | åˆ†è§£ MINLP é—®é¢˜ï¼ŒMAPPO-PDN å¤„ç†ç¦»æ•£å˜é‡ï¼ŒLP å¤„ç†è¿ç»­å˜é‡ | ç«¯åˆ°ç«¯ MARL æˆ–å•ä¸€ä¼˜åŒ–æ–¹æ³•ï¼Œå¤æ‚åº¦é«˜ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šæ‰€ææ–¹æ¡ˆåœ¨åŠ¨æ€è½¦è”ç½‘ç¯å¢ƒä¸­å…·æœ‰æ›´å¼ºçš„é€‚åº”æ€§ã€æ›´ä½çš„å»¶è¿Ÿã€æ›´é«˜çš„èµ„æºåˆ©ç”¨ç‡å’Œæ›´å¥½çš„è¯­ä¹‰ä¿çœŸåº¦ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†ä¸ä»¿çœŸç¯å¢ƒ
- **æœªä½¿ç”¨çœŸå®å…¬å¼€æ•°æ®é›†**ï¼Œè€Œæ˜¯åŸºäºæ¨¡æ‹Ÿå™¨ç”Ÿæˆç¬¦åˆå®é™…äº¤é€šç‰¹å¾çš„æ•°æ®ã€‚
- åœºæ™¯è®¾å®šä¸ºä¸€æ¡ **400ç±³é•¿çš„åŒè½¦é“é«˜é€Ÿå…¬è·¯**ï¼Œéƒ¨ç½²ä¸€ä¸ªè¿æ¥ MEC æœåŠ¡å™¨çš„ RSUã€‚
- è½¦è¾†åˆ†ä¸ºä¸¤ç±»ï¼š
  - **Vehicle Users (VUs)**ï¼šå…± 20 è¾†ï¼Œäº§ç”Ÿè®¡ç®—å¯†é›†å‹è¯­ä¹‰ä»»åŠ¡ï¼›
  - **Service Vehicles (SVs)**ï¼šå›ºå®š 5 è¾†ï¼Œå¯ä½œä¸ºè¾¹ç¼˜èŠ‚ç‚¹æä¾›è®¡ç®—æœåŠ¡ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
| å‚æ•° | è®¾ç½®å€¼ |
|------|-------|
| ä»»åŠ¡ç”Ÿæˆ | Poisson åˆ†å¸ƒï¼Œæ¯æ—¶éš™ 0.8 Mbit |
| è®¡ç®—éœ€æ±‚ C | 1000 cycles/bit |
| ä¼ è¾“åŠŸç‡ï¼ˆV2I / V2Vï¼‰ | 23 dBm / 15 dBm |
| å™ªå£°åŠŸç‡ | -114 dBm |
| å¸¦å®½ B | 540 kHz |
| è®¡ç®—èƒ½åŠ›ï¼ˆRSU / VU / SVï¼‰ | 6 GHz / 1 GHz / 3 GHz |
| å¥å­å¹³å‡é•¿åº¦ $L_{i,j}$ | 20 words |
| è¯­ä¹‰è½¬æ¢å› å­ H | 1200 bits/sentence |
| è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼ $\theta_{th}$ | 0.9 |
| PDN ä¸Šé™ $\Omega_{max}$ | 20 |

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
- **Average Task Delay**ï¼šä»»åŠ¡ä»ç”Ÿæˆåˆ°å®Œæˆçš„æ€»å»¶è¿Ÿï¼ˆå«ä¼ è¾“ + è®¡ç®—ï¼‰
- **Transmission Delay**
- **Reward Convergence**ï¼ˆè®­ç»ƒè¿‡ç¨‹å¥–åŠ±æ›²çº¿ï¼‰
- ä¸åŒ VU æ•°é‡ä¸‹çš„æ€§èƒ½å˜åŒ–è¶‹åŠ¿

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **MAPPO-PDN + LP**ï¼ˆæœ¬æ–‡æ–¹æ³•ï¼‰
2. **MAPPO-PDN + Ivy**ï¼ˆIvy æ˜¯ä¸€ç§å¯å‘å¼ä¼˜åŒ–ç®—æ³• [26]ï¼‰
3. **MAPPO + LP**
4. **MADQN + LP**
5. **Linear K-Selection + LP**ï¼ˆçº¿æ€§é€‰æ‹© $k$ å€¼ï¼‰
6. **Traditional + LP**ï¼ˆä¼ ç»Ÿé€šä¿¡ + LP å¸è½½ï¼‰
7. **Traditional + Ivy**
8. **Traditional (No LP)**ï¼ˆå›ºå®šå¸è½½æ¯”ä¾‹çš„ä¼ ç»Ÿé€šä¿¡ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“‰ å…³é”®æ€§èƒ½è¡¨ç°ï¼ˆè§ Fig. 3 & Fig. 4ï¼‰

#### ï¼ˆ1ï¼‰å¥–åŠ±æ”¶æ•›æ€§ï¼ˆFig. 2ï¼‰
- **MAPPO-PDN æ–¹æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æŒç»­è·å¾—æ›´é«˜å¥–åŠ±**ï¼Œä¸”æ”¶æ•›æ›´å¿«ã€æ›´ç¨³å®šã€‚
- ä¼ ç»Ÿ MARL æ–¹æ³•ï¼ˆå¦‚ MAPPOã€MADQNï¼‰æ˜“å‡ºç°æ³¢åŠ¨æˆ–æ—©åœæ»ï¼Œè¡¨æ˜å…¶åœ¨éç¨³æ€å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸‹é²æ£’æ€§è¾ƒå·®ã€‚
- **PDN æ­£åˆ™åŒ–æœ‰æ•ˆæå‡äº†ç­–ç•¥æ¢ç´¢èƒ½åŠ›ä¸æ³›åŒ–æ€§èƒ½**ã€‚

#### ï¼ˆ2ï¼‰ä¼ è¾“å»¶è¿Ÿ vs è½¦è¾†æ•°é‡ï¼ˆFig. 3ï¼‰
- å½“ VU æ•°é‡ä» 15 å¢åŠ åˆ° 40ï¼š
  - æ‰€æœ‰æ–¹æ³•å»¶è¿Ÿå‡ä¸Šå‡ï¼ˆèµ„æºç«äº‰åŠ å‰§ï¼‰ï¼›
  - åœ¨ 25â€“35 è¾†ä¹‹é—´å‡ºç°â€œå‡¹å½¢â€ä¸‹é™è¶‹åŠ¿ï¼šå› è½¦è·ç¼©çŸ­ â†’ ä¿¡é“å¢ç›Šæå‡ â†’ ä¼ è¾“é€Ÿç‡å¢åŠ  â†’ å»¶è¿ŸçŸ­æš‚é™ä½ï¼›
  - è¶…è¿‡ä¸€å®šæ•°é‡åï¼ˆå¦‚ 40 è¾†ï¼‰ï¼Œé¢‘è°±å¤ç”¨å¹²æ‰°ä¸¥é‡ï¼Œå»¶è¿Ÿå›å‡ã€‚
- **æœ¬æ–‡æ–¹æ³•ï¼ˆOur-Method + LPï¼‰å§‹ç»ˆä¼˜äºå…¶ä»–æ–¹æ³•**ï¼Œå°¤å…¶åœ¨é«˜å¯†åº¦åœºæ™¯ä¸‹ä¼˜åŠ¿æ˜æ˜¾ã€‚

#### ï¼ˆ3ï¼‰å¹³å‡ä»»åŠ¡å»¶è¿Ÿï¼ˆFig. 4ï¼‰
- éšç€è½¦è¾†å¢å¤šï¼Œ**è®¡ç®—å»¶è¿Ÿæˆä¸ºä¸»å¯¼å› ç´ **ï¼ˆè¾¹ç¼˜èŠ‚ç‚¹èµ„æºè¢«æ‘Šè–„ï¼‰ã€‚
- **æœ¬æ–‡æ–¹æ³•æ˜¾è‘—é™ä½äº†æ•´ä½“ä»»åŠ¡å»¶è¿Ÿ**ï¼š
  - ç›¸æ¯” â€œTraditional + LPâ€ï¼Œå»¶è¿Ÿå‡å°‘çº¦ **30%~40%**ï¼›
  - ç›¸æ¯” â€œMAPPO + LPâ€ï¼Œå»¶è¿Ÿé™ä½çº¦ **20%**ï¼›
  - ç›¸æ¯” â€œMADQN + LPâ€ï¼Œæ€§èƒ½æå‡æ›´ä¸ºæ˜¾è‘—ã€‚

#### ï¼ˆ4ï¼‰æ¶ˆèå®éªŒåˆ†æï¼ˆéšå«äºå¯¹æ¯”ä¸­ï¼‰
è™½ç„¶æ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºâ€œablation studyâ€å°èŠ‚ï¼Œä½†ä»ä»¥ä¸‹å¯¹æ¯”å¯æ¨æ–­å…³é”®ç»„ä»¶ä½œç”¨ï¼š

| ç»„ä»¶ | æ€§èƒ½å½±å“ |
|------|---------|
| **PDN æ­£åˆ™åŒ–**ï¼ˆMAPPO-PDN vs MAPPOï¼‰ | æå‡è®­ç»ƒç¨³å®šæ€§ä¸æœ€ç»ˆæ€§èƒ½ |
| **LP ä¼˜åŒ–å¸è½½ç‡**ï¼ˆ+LP vs +Ivy/no-LPï¼‰ | æ˜¾è‘—é™ä½å»¶è¿Ÿï¼Œè¯´æ˜ç²¾ç¡®æ§åˆ¶å¸è½½æ¯”ä¾‹çš„é‡è¦æ€§ |
| **è¯­ä¹‰é€šä¿¡ï¼ˆvs Traditionalï¼‰** | åŒç­‰æ¡ä»¶ä¸‹å¤§å¹…å‡å°éœ€ä¼ è¾“çš„ä¿¡æ¯é‡ï¼Œä»è€Œé™ä½å»¶è¿Ÿä¸èƒ½è€— |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **è¯­ä¹‰é€šä¿¡ + VEC æ˜¯æ»¡è¶³ IoV è¶…ä½æ—¶å»¶éœ€æ±‚çš„æœ‰æ•ˆè·¯å¾„**ï¼šç›¸æ¯”ä¼ ç»Ÿé€šä¿¡ï¼ŒSC æ˜¾è‘—å‡å°‘äº†ä¿¡æ¯å†—ä½™ï¼Œæé«˜äº†ä¼ è¾“æ•ˆç‡ã€‚
2. **V2I/V2V ååŒå¸è½½ä¼˜äºå•é“¾è·¯æ¨¡å¼**ï¼šTCSC æ¡†æ¶å……åˆ†åˆ©ç”¨ç§»åŠ¨ SVs çš„ç©ºé—²ç®—åŠ›ï¼Œå¢å¼ºäº†ç³»ç»Ÿçš„å¼¹æ€§ä¸å¯æ‰©å±•æ€§ã€‚
3. **MAPPO-PDN åœ¨éç¨³æ€å¤šè½¦ç¯å¢ƒä¸­è¡¨ç°å‡ºä¼˜è¶Šçš„é²æ£’æ€§å’Œæ”¶æ•›æ€§**ï¼šé€šè¿‡å»ºæ¨¡ç­–ç•¥å‚æ•°çš„ä¸ç¡®å®šæ€§ï¼Œé¿å…äº†ä¼ ç»Ÿ MARL çš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚
4. **åˆ†è§£ä¼˜åŒ–ç­–ç•¥ï¼ˆMAPPO-PDN + LPï¼‰ä¼˜äºç«¯åˆ°ç«¯å­¦ä¹ **ï¼šåˆ†åˆ«å¤„ç†ç¦»æ•£ä¸è¿ç»­å˜é‡ï¼Œå…¼é¡¾ç²¾åº¦ä¸æ•ˆç‡ã€‚

### âš ï¸ å±€é™æ€§
- **ä¾èµ–é¢„è®­ç»ƒ DeepSC æ¨¡å‹**ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦æ˜ å°„è¡¨ $ \delta_{i,j} = f(k_{i,j}, \text{SINR}) $ æ¥è‡ª AWGN ä¿¡é“ä¸‹çš„è®­ç»ƒç»“æœï¼Œå¯èƒ½ä¸é€‚ç”¨äºå¤æ‚çœŸå®ä¿¡é“ã€‚
- **å‡è®¾è½¦è¾†é€Ÿåº¦æ’å®š**ï¼šå¿½ç•¥äº†åŠ å‡é€Ÿã€å˜é“ç­‰åŠ¨æ€è¡Œä¸ºå¯¹ä¿¡é“å’Œæ‹“æ‰‘çš„å½±å“ã€‚
- **æœªè€ƒè™‘å¤šæ¨¡æ€ä»»åŠ¡**ï¼ˆå¦‚å›¾åƒã€è¯­éŸ³ï¼‰ï¼šå½“å‰æ¨¡å‹ä¸»è¦é’ˆå¯¹æ–‡æœ¬ç±»è¯­ä¹‰ä»»åŠ¡ã€‚
- **ä»¿çœŸç¯å¢ƒç†æƒ³åŒ–**ï¼šç¼ºä¹çœŸå®é“è·¯æµé‡ã€ä¿¡å·é®æŒ¡ã€çªå‘å¹²æ‰°ç­‰å› ç´ ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **å¤šæ¨¡æ€è¯­ä¹‰é€šä¿¡**ï¼ˆMultimodal Semantic Communicationï¼‰åœ¨ IoV ä¸­çš„åº”ç”¨ï¼›
- å¼•å…¥ **Reconfigurable Intelligent Surface (RIS)** æˆ– **AI-empowered channel prediction** æå‡è¯­ä¹‰ä¼ è¾“è´¨é‡ï¼›
- ç ”ç©¶ **å»ä¸­å¿ƒåŒ–è”é‚¦è¯­ä¹‰å­¦ä¹ æ¡†æ¶**ï¼Œä¿æŠ¤éšç§çš„åŒæ—¶å®ç°è·¨è½¦çŸ¥è¯†å…±äº«ï¼›
- ç»“åˆ **joint communication-computation coding** è¿›ä¸€æ­¥å‹ç¼©è¯­ä¹‰è´Ÿè½½ã€‚

---

## æ€»ç»“

âœ… æœ¬æ–‡æå‡ºäº†é¢å‘é«˜é€Ÿå…¬è·¯åœºæ™¯çš„ **TCSC æ¡†æ¶**ï¼Œèåˆ **è¯­ä¹‰é€šä¿¡ã€V2I/V2V ååŒå¸è½½ä¸ MAPPO-PDN+LP è”åˆä¼˜åŒ–ç®—æ³•**ï¼Œåœ¨ä¿éšœè¯­ä¹‰å‡†ç¡®æ€§çš„å‰æä¸‹æ˜¾è‘—é™ä½äº†ä»»åŠ¡å»¶è¿Ÿã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨å¤šç§äº¤é€šå¯†åº¦ä¸‹å‡ä¼˜äºä¼ ç»ŸåŠä¸»æµ MARL æ–¹æ³•ï¼Œä¸ºä¸‹ä¸€ä»£æ™ºèƒ½è½¦è”ç½‘æä¾›äº†é«˜æ•ˆå¯é çš„è¯­ä¹‰çº§è®¡ç®—å¸è½½è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 9. [RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning](https://arxiv.org/abs/2512.09829)

**Authors**: Khurram Khalil, Muhammad Mahad Khaliq, Khaza Anuarul Hoque  
**Category**: cs.AI  
**Published**: 2025-12-11  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.09829v1  

#### Abstract
The massive scale of modern AI accelerators presents critical challenges to traditional fault assessment methodologies, which face prohibitive computational costs and provide poor coverage of critical failure modes. This paper introduces RIFT (Reinforcement Learning-guided Intelligent Fault Targetin...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ç°ä»£å¤§è§„æ¨¡ **Large Language Models (LLMs)** åœ¨ä¸“ç”¨ AI åŠ é€Ÿå™¨ï¼ˆå¦‚ GPUã€TPUï¼‰ä¸Šè¿è¡Œæ—¶ï¼Œé¢ä¸´ç¡¬ä»¶æ•…éšœå¯¼è‡´åŠŸèƒ½å¤±æ•ˆçš„é£é™©ã€‚ç”±äºæ¨¡å‹å‚æ•°è§„æ¨¡è¾¾åˆ°æ•°åäº¿çº§åˆ«ï¼Œä¼ ç»Ÿæ•…éšœè¯„ä¼°æ–¹æ³•ï¼ˆå¦‚ Random Fault Injection, RFIï¼‰å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

- **è®¡ç®—æˆæœ¬æé«˜**ï¼šå•æ¯”ç‰¹æ•…éšœä½ç½®å¯è¾¾ $ m \times n \times 10^9 $ é‡çº§ï¼ˆä¾‹å¦‚ 8B å‚æ•° Ã— 8bitï¼‰ï¼Œç»„åˆæ•…éšœç©ºé—´å‘ˆæŒ‡æ•°çˆ†ç‚¸ã€‚
- **è¦†ç›–ç‡ä½ä¸”æ•ˆç‡å·®**ï¼šéšæœºæ³¨å…¥éš¾ä»¥å‘ç°ç¨€ç–ä½†é«˜å½±å“çš„â€œæœ€åæƒ…å†µâ€æ•…éšœç»„åˆã€‚
- **ç¼ºä¹å¯æ‰©å±•æ€§**ï¼šç°æœ‰åŸºäºé™æ€åˆ†ææˆ–è¿›åŒ–ç®—æ³•çš„æ–¹æ³•æ— æ³•æœ‰æ•ˆæ‰©å±•åˆ°ç™¾äº¿å‚æ•°æ¨¡å‹ã€‚

å› æ­¤ï¼Œå¦‚ä½•é«˜æ•ˆã€ç³»ç»Ÿåœ°æœç´¢å‡ºèƒ½å¼•å‘ç¾éš¾æ€§å¤±è´¥çš„æœ€å°é«˜å½±å“æ•…éšœé›†åˆï¼Œæˆä¸ºè®¾è®¡è‡ªåŠ¨åŒ–ï¼ˆEDAï¼‰é¢†åŸŸçš„å…³é”®æŒ‘æˆ˜ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **RIFT**ï¼ˆReinforcement Learning-guided Intelligent Fault Targetingï¼‰ï¼Œä¸€ä¸ªå¯æ‰©å±•çš„ã€åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ•…éšœè¯„ä¼°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **å°†æ•…éšœæœç´¢å»ºæ¨¡ä¸ºåºåˆ—å†³ç­–é—®é¢˜**  
   å°†å¯»æ‰¾æœ€å°é«˜å½±å“æ•…éšœé›†çš„é—®é¢˜è½¬åŒ–ä¸º **Markov Decision Process (MDP)**ï¼Œç”± RL Agent é€šè¿‡è¯•é”™é€æ­¥æ„å»ºæœ€ä¼˜æ•…éšœç»„åˆã€‚

2. **ä¸‰é˜¶æ®µåˆ†å±‚ä¼˜åŒ–æ¶æ„**
   - **Phase I: Vulnerability Profiling**  
     ä½¿ç”¨æ··åˆæ•æ„Ÿåº¦è¯„åˆ†ï¼ˆhybrid sensitivity scoreï¼‰ï¼Œç»“åˆå‚æ•°çš„é™æ€é‡è¦æ€§ï¼ˆmagnitudeï¼‰å’ŒåŠ¨æ€æ¢¯åº¦ä¿¡æ¯ï¼ˆgradient w.r.t. lossï¼‰ï¼Œå¯¹æ‰€æœ‰å‚æ•°è¿›è¡Œæ’åºã€‚
   - **Phase II: Candidate Set Initialization**  
     ä»æ’åºåˆ—è¡¨ä¸­é€‰å– top-$ p\% $ æœ€æ•æ„Ÿå‚æ•°ä½œä¸ºå€™é€‰é›† $ P_{\text{crit}} $ï¼Œå¤§å¹…ç¼©å°æœç´¢ç©ºé—´ã€‚
   - **Phase III: RL-Powered Test Vector Generation**  
     åœ¨å€™é€‰é›†ä¸Šè¿è¡Œ Q-learning ç®—æ³•ï¼Œä»¥å‡†ç¡®ç‡ä¸‹é™å’Œæ•…éšœæ•°é‡ä¸ºå¥–åŠ±å‡½æ•°ï¼Œè‡ªåŠ¨æ¢ç´¢æœ€ä¼˜æ•…éšœç»„åˆã€‚

3. **ç”Ÿæˆ UVM-compliant æµ‹è¯•æ¿€åŠ±**
   è‡ªåŠ¨è¾“å‡ºç¬¦åˆå·¥ä¸šæ ‡å‡†çš„ **UVM testbench**ï¼Œæ”¯æŒç›´æ¥é›†æˆè¿›å•†ä¸š RTL éªŒè¯æµç¨‹ï¼Œå®ç°â€œpush-buttonâ€å¼æ•…éšœæ³¨å…¥ã€‚

4. **æŒ‡å¯¼ç¡¬ä»¶ä¿æŠ¤ç­–ç•¥è®¾è®¡**
   åˆ©ç”¨è¯†åˆ«å‡ºçš„å…³é”®è„†å¼±ä½ç‚¹ï¼Œæå‡º **RIFT-guided selective ECC**ï¼Œåœ¨æä½å¼€é”€ä¸‹å®ç°é«˜æ€§ä»·æ¯”çš„å®¹é”™è®¾è®¡ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | RIFT çš„ä¼˜åŠ¿ |
|------|-------------|
| **æ•ˆç‡** | ç›¸æ¯” RFI æé€Ÿ 7.5Ã—ï¼Œç›¸æ¯” GenBFA æé€Ÿ 2.2Ã— |
| **æµ‹è¯•å‘é‡è§„æ¨¡** | å‡å°‘ >99% çš„ test vectorsï¼ˆä»…éœ€ ~847 ä¸ªï¼‰ |
| **è¦†ç›–ç‡** | è¾¾åˆ° 91.7% æ•…éšœè¦†ç›–ç‡ï¼Œæ˜¾è‘—é«˜äºå…¶ä»–æ–¹æ³• |
| **å®ç”¨æ€§** | è¾“å‡º UVM å…¼å®¹ä»£ç ï¼Œæ˜“äºå·¥ç¨‹éƒ¨ç½² |
| **è®¾è®¡æŒ‡å¯¼èƒ½åŠ›** | æ”¯æŒå¯é æ€§æ„ŸçŸ¥çš„ DSEï¼ˆDesign Space Explorationï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸ç›®æ ‡æ¨¡å‹**

- **åŸºå‡†æµ‹è¯•é›†**ï¼š
  - **MMLU**ï¼š57 ä¸ªå­¦ç§‘ï¼Œ15,000+ å¤šé€‰é¢˜ï¼Œç”¨äºè¯„ä¼°é€šç”¨çŸ¥è¯†ç†è§£ã€‚
  - **MMLU-Pro**ï¼šæ›´å…·æŒ‘æˆ˜æ€§çš„å˜ä½“ï¼Œ14 å­¦ç§‘ï¼Œ12,000 é—®é¢˜ã€‚
- **ç›®æ ‡æ¨¡å‹ï¼ˆDUTï¼‰**ï¼š
  - GPT-2 Large (~30.5% baseline acc)
  - LLaMA 3.1 8B (~69.9% baseline acc)
  - DeepSeek-V2 7B MoE (~71.3% baseline acc)
- æ‰€æœ‰æ¨¡å‹é‡‡ç”¨ **8-bit integer quantization**ï¼Œåæ˜ å®é™…éƒ¨ç½²åœºæ™¯ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **æ•…éšœæ¨¡å‹**
- æ³¨å…¥æ–¹å¼ï¼šç¿»è½¬é€‰å®šå‚æ•°çš„ **Most Significant Bit (MSB)**ï¼Œæ¨¡æ‹Ÿæœ€ä¸¥é‡çš„æ•°å€¼åå·®ã€‚
- ç¾éš¾æ€§å¤±è´¥å®šä¹‰ï¼šæ¨¡å‹å‡†ç¡®ç‡ä¸‹é™è¶…è¿‡ 90%ã€‚

#### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Coverage (Cov)** | æˆåŠŸè¯†åˆ«çš„å…³é”®æ•…éšœæ¯”ä¾‹ï¼ˆå¯¼è‡´ >90% æ€§èƒ½é€€åŒ–ï¼‰ |
| **Time (hrs)** | åœ¨ 1000 CPU å°æ—¶é¢„ç®—å†…çš„è¿è¡Œæ—¶é—´ |
| **Test Vectors (TV)** | ç”Ÿæˆçš„æ•…éšœæ³¨å…¥æµ‹è¯•ç”¨ä¾‹æ•° |
| **Efficiency (Eff)** | Coverage / Timeï¼ˆæ¯å°æ—¶è¦†ç›–ç‡ï¼‰ |
| **Cost-Effectiveness (CE)** | Fault Coverage / Area Overheadï¼ˆå•ä½é¢ç§¯è¦†ç›–ï¼‰ |

#### **ç»Ÿè®¡æ–¹æ³•**
- æ‰€æœ‰å®éªŒé‡å¤ 15 æ¬¡ï¼ŒæŠ¥å‘Šå‡å€¼ Â± æ ‡å‡†å·®ã€‚
- æ˜¾è‘—æ€§æ£€éªŒä½¿ç”¨ Welchâ€™s t-test + Bonferroni æ ¡æ­£ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿æ–¹æ³• | ç±»å‹ |
|--------|------|
| **Random Fault Injection (RFI)** | å·¥ä¸šæ ‡å‡†ï¼Œéšæœºé‡‡æ · |
| **Magnitude Ranking** | é™æ€åˆ†æï¼ˆç±»ä¼¼ PrisonBreakï¼‰ |
| **Gradient Selection** | åŠ¨æ€åˆ†æï¼ˆç±»ä¼¼ DeepHammerï¼‰ |
| **GenBFA [17]** | å½“å‰æœ€å…ˆè¿›çš„è¿›åŒ–ç®—æ³•ï¼ˆevolutionary searchï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable Iï¼‰**

| æ–¹æ³• | Coverage (%) | æ—¶é—´ (hrs) | Test Vectors | Efficiency (Cov/hr) | Speedup vs RFI |
|------|--------------|-----------|----------------|-----------------------|----------------|
| RFI | 65.3Â±4.1 | 1000Â±52 | 1.2Ã—10âµ | 0.065 | 1.0Ã— |
| Magnitude Ranking | 73.8Â±3.7 | 245Â±18 | 8.4Ã—10â´ | 0.301 | 4.6Ã— |
| Gradient Selection | 79.2Â±2.9 | 198Â±15 | 6.1Ã—10â´ | 0.400 | 6.2Ã— |
| GenBFA [17] | 84.6Â±3.2 | 388Â±24 | 4.7Ã—10Â³ | 0.218 | 3.4Ã— |
| **RIFT (Ours)** | **91.7Â±2.1** | **187Â±12** | **847Â±73** | **0.490** | **7.5Ã—** |

> âœ… RIFT å®ç°æœ€é«˜è¦†ç›–ç‡ã€æœ€çŸ­æ—¶é—´å’Œæœ€å°‘æµ‹è¯•å‘é‡ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **é€Ÿåº¦æå‡**ï¼š
  - ç›¸æ¯” RFIï¼š**7.5Ã— æ›´é«˜æ•ˆ**
  - ç›¸æ¯” GenBFAï¼š**2.2Ã— æ›´å¿«**
- **æµ‹è¯•å‘é‡å‹ç¼©**ï¼š
  - ç›¸æ¯” RFI å‡å°‘ **>99%** çš„ test vectorsï¼ˆä» 12ä¸‡ â†’ 847ï¼‰
- **èµ„æºæ¶ˆè€—æ›´ä½**ï¼š
  - åœ¨æ›´çŸ­æ—¶é—´å†…å®Œæˆæ›´é«˜è¦†ç›–ç‡ä»»åŠ¡ï¼Œé€‚åˆå·¥ä¸šçº§å¿«é€ŸéªŒè¯ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰**

#### **A. æ··åˆæ•æ„Ÿåº¦æŒ‡æ ‡çš„æœ‰æ•ˆæ€§ï¼ˆFigure 3ï¼‰**

| Î±ï¼ˆmixing coefficientï¼‰ | å¹³å‡æ‰€éœ€æ•…éšœæ•° |
|--------------------------|----------------|
| Î± = 0.0ï¼ˆçº¯ magnitudeï¼‰ | 7.1Â±0.8 |
| Î± = 1.0ï¼ˆçº¯ gradientï¼‰   | 6.4Â±0.6 |
| **Î± = 0.5ï¼ˆhybridï¼‰**    | **5.0Â±0.4** |

> âœ… æ··åˆæŒ‡æ ‡å‡å°‘ 29% çš„æ•…éšœéœ€æ±‚ï¼Œè¯æ˜åŠ¨é™ç»“åˆæ›´ä¼˜ã€‚

#### **B. ä¸‰é˜¶æ®µæ¶æ„å¿…è¦æ€§ï¼ˆTable Vï¼‰**

| é…ç½® | æ‰¾åˆ°çš„å…³é”®æ•…éšœæ•° | æ”¶æ•›æ‰€éœ€ Episodes |
|------|--------------------|---------------------|
| RL-Onlyï¼ˆåŒé¢„ç®— 50epï¼‰ | 47.3Â±8.2 | 50ï¼ˆæœªæ”¶æ•›ï¼‰ |
| RL-Onlyï¼ˆè‡³æ”¶æ•›ï¼‰       | 5.2Â±0.6 | 890Â±67 |
| **å®Œæ•´ RIFT**           | **5.0Â±0.4** | **50Â±3** |

> âœ… Phase I & II æä¾›å…ˆéªŒçŸ¥è¯†ï¼Œä½¿ RL æ”¶æ•›é€Ÿåº¦å¿« **17Ã— ä»¥ä¸Š**ã€‚

#### **C. è¶…å‚æ•°é²æ£’æ€§ï¼ˆFigure 4ï¼‰**

- **è®­ç»ƒ episode æ•°**ï¼šåœ¨ 50 è½®åè¶‹äºé¥±å’Œï¼Œæ— éœ€ç²¾ç»†è°ƒå‚ã€‚
- **æ¢ç´¢ç‡ Îµ âˆˆ [0.05, 0.30]**ï¼šæ€§èƒ½æ³¢åŠ¨ <5%ï¼Œè¡¨æ˜ç®—æ³•ç¨³å®šã€‚

#### **D. æ¶æ„æ³›åŒ–èƒ½åŠ›ï¼ˆTable VIï¼‰**

| DUT æ¨¡å‹ | Hybrid Metric æå‡ | 3-Phase æ¶æ„å¢ç›Š |
|---------|--------------------|------------------|
| GPT-2 Large | 24% | 3.8Ã— |
| LLaMA 3.1 8B | 29% | 4.2Ã— |
| DeepSeek-V2 7B | 31% | 4.6Ã— |

> âœ… RIFT åœ¨ä¸åŒ LLM æ¶æ„ä¸Šå‡è¡¨ç°ä¸€è‡´ä¼˜è¶Šã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **LLM å­˜åœ¨é«˜åº¦ç¨€ç–çš„è„†å¼±ç‚¹**  
   å¹³å‡åªéœ€ **5.4Â±0.8 ä¸ªæ¯”ç‰¹ç¿»è½¬** å³å¯å¯¼è‡´åŠŸèƒ½å´©æºƒï¼ˆaccuracy ä¸‹é™ >99%ï¼‰ã€‚

2. **è„†å¼±æ€§é›†ä¸­åœ¨ç‰¹å®šæ¨¡å—**  
   - 88.5% çš„å…³é”®æ•…éšœä½äºï¼š
     - Attention Mechanisms: 47.3%
     - Normalization Layers: 41.2%
   - Feed-Forward Networks ç›¸å¯¹é²æ£’ã€‚

3. **RIFT å¯æä¾›å¯é æ€§æ„ŸçŸ¥çš„è®¾è®¡æŒ‡å¯¼**
   - **RIFT-guided selective ECC**ï¼š
     - åŒºåŸŸå¼€é”€ä»… **13.8%**
     - è¦†ç›– 88.5% å…³é”®æ•…éšœ
     - æˆæœ¬æ•ˆç›Šè¾¾ **6.4Ã—**ï¼ˆCoverage/Areaï¼‰
   - å¯¹æ¯” Uniform TMRï¼š
     - å¼€é”€é«˜è¾¾ **205%**
     - æˆæœ¬æ•ˆç›Šä»…ä¸º **0.5**
     - âœ RIFT æ–¹æ¡ˆ **12.8Ã— æ›´ cost-effective**

4. **å…·å¤‡è‰¯å¥½çš„ä¸€è‡´æ€§ä¸å¯æ‰©å±•æ€§**
   - ç»Ÿè®¡æµ‹è¯•æ˜¾ç¤ºç»“æœé«˜åº¦ç¨³å®šï¼ˆp < 0.001, Cohen's d > 2.5ï¼‰
   - è¿è¡Œæ—¶é—´éšå€™é€‰é›†å¤§å°çº¿æ€§å¢é•¿ï¼ˆ$ R^2 > 0.99 $ï¼‰
   - å†…å­˜å ç”¨ä¸º $ O(k^{1.3}) $ï¼Œé€‚ç”¨äºä¸‹ä¸€ä»£æ›´å¤§æ¨¡å‹ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ–ä»£è¡¨æ€§æ•°æ®é›† $ D_{\text{rep}} $**  
   è‹¥ $ D_{\text{rep}} $ ä¸èƒ½ä»£è¡¨çœŸå®è´Ÿè½½åˆ†å¸ƒï¼Œå¯èƒ½é—æ¼æŸäº›æ•…éšœæ¨¡å¼ã€‚

2. **å½“å‰ä»…æ”¯æŒæ°¸ä¹…æ€§å†…å­˜æ•…éšœï¼ˆbit-flipï¼‰**  
   æœªæ¶µç›– transient faultsã€timing errors æˆ–é€»è¾‘é—¨çº§æ•…éšœã€‚

3. **Q-learning è¡¨æ ¼æ³•é™åˆ¶è§„æ¨¡**  
   å½“å‰ä½¿ç”¨ tabular Q-learningï¼Œé€‚ç”¨äºæ•°åƒå‚æ•°çº§åˆ«çš„å€™é€‰é›†ï¼›è¶…å¤§è§„æ¨¡éœ€å¼•å…¥ DQN æˆ– Policy Gradientã€‚

4. **GPU æ¨¡æ‹Ÿç¯å¢ƒéå®Œå…¨çœŸå®ç¡¬ä»¶åé¦ˆ**  
   å®é™…èŠ¯ç‰‡ä¸­çš„ç‰©ç†æ•ˆåº”ï¼ˆå¦‚ç”µå‹å™ªå£°ã€æ¸©åº¦æ¼‚ç§»ï¼‰å°šæœªçº³å…¥å»ºæ¨¡ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ‰©å±•è‡³æ›´å¤šæ¨¡å‹ç±»å‹**  
   åº”ç”¨äº Vision Transformersã€Diffusion Models ç­‰å¤§å‹æ¶æ„ã€‚

2. **æ”¯æŒæ›´å¤æ‚çš„æ•…éšœæ¨¡å‹**  
   å¼•å…¥ transient faultsã€crosstalkã€timing violations ç­‰ç‰©ç†å±‚é¢é”™è¯¯ã€‚

3. **é›†æˆåˆ°è‡ªåŠ¨åŒ–ç»¼åˆæµç¨‹**  
   å°† RIFT æ¢ç´¢å¼•æ“åµŒå…¥ RTL-to-GDSII æµç¨‹ï¼Œå®ç° **reliability-aware synthesis**ã€‚

4. **å‘å±•åˆ†å¸ƒå¼å¹¶è¡Œç‰ˆæœ¬**  
   åˆ©ç”¨å¤š GPU/TPU å¹¶è¡ŒåŠ é€Ÿ DUT è¯„ä¼°ç¯èŠ‚ï¼Œè¿›ä¸€æ­¥ç¼©çŸ­å‘¨æœŸã€‚

5. **ç»“åˆå½¢å¼åŒ–æ–¹æ³•è¿›è¡ŒéªŒè¯å¢å¼º**  
   ç”¨ SAT/SMT å·¥å…·éªŒè¯ RL å‘ç°çš„æ•…éšœè·¯å¾„æ˜¯å¦å¯è¾¾ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼šRIFT æ˜¯é¦–ä¸ªå°† **Reinforcement Learning** æˆåŠŸåº”ç”¨äº **LLM åŠ é€Ÿå™¨æ•…éšœè¯„ä¼°** çš„æ¡†æ¶ï¼Œå®ç°äº†ä»â€œç›²ç›®æœç´¢â€åˆ°â€œæ™ºèƒ½å®šå‘æ”»å‡»â€çš„èŒƒå¼è½¬å˜ï¼Œä¸ä»…æå¤§æå‡äº†æ•…éšœè¯„ä¼°æ•ˆç‡ï¼Œè¿˜ä¸ºå¯é æ€§é©±åŠ¨çš„ç¡¬ä»¶è®¾è®¡æä¾›äº†é‡åŒ–ä¾æ®ï¼Œå…·æœ‰é‡è¦çš„ç†è®ºä»·å€¼å’Œå·¥ä¸šåº”ç”¨å‰æ™¯ã€‚

</details>

---

### 10. [Luxical: High-Speed Lexical-Dense Text Embeddings](https://arxiv.org/abs/2512.09015)

**Authors**: DatologyAI,  :, Luke Merrick, Alex Fang, Aldo Carranza, Alvin Deng, Amro Abbas, Brett Larsen, Cody Blakeney, Darren Teh, David Schwab, Fan Pan, Haakon Mongstad, Haoli Yin, Jack Urbanek, Jason Lee, Jason Telanoff, Josh Wills, Kaleigh Mentzer, Paul Burstein, Parth Doshi, Paul Burnstein, Pratyush Maini, Ricardo Monti, Rishabh Adiga, Scott Loftin, Siddharth Joshi, Spandan Das, Tony Jiang, Vineeth Dorma, Zhengping Wang, Bogdan Gaza, Ari Morcos, Matthew Leavitt  
**Category**: cs.CL  
**Published**: 2025-12-11  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.09015v1  

#### Abstract
Frontier language model quality increasingly hinges on our ability to organize web-scale text corpora for training. Today's dominant tools trade off speed and flexibility: lexical classifiers (e.g., FastText) are fast but limited to producing classification output scores, while the vector-valued out...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLuxical: High-Speed Lexical-Dense Text Embeddings

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è®­ç»ƒä¸­ï¼Œ**æ–‡æœ¬è¯­æ–™åº“çš„ç»„ç»‡ä¸è´¨é‡æ§åˆ¶**æˆä¸ºå…³é”®ç“¶é¢ˆã€‚ç°æœ‰çš„æ–‡æœ¬åµŒå…¥æ–¹æ³•é¢ä¸´ä»¥ä¸‹æƒè¡¡ï¼š
- **Transformer-based embedding models**ï¼ˆå¦‚ MiniLMã€Qwenï¼‰è™½èƒ½ç”Ÿæˆé«˜è´¨é‡çš„ dense embeddingsï¼Œé€‚ç”¨äºèšç±»ã€æ£€ç´¢ã€åˆ†ç±»ç­‰å¤šç§ä»»åŠ¡ï¼Œä½†è®¡ç®—å¼€é”€å¤§ï¼Œéš¾ä»¥åœ¨ä¸‡äº¿çº§ token è§„æ¨¡ä¸‹é«˜æ•ˆéƒ¨ç½²ã€‚
- **Lexical classifiers**ï¼ˆå¦‚ FastTextï¼‰è¿è¡Œé€Ÿåº¦å¿«ï¼Œé€‚åˆå¤§è§„æ¨¡å¤„ç†ï¼Œä½†è¾“å‡ºä»…ä¸ºå•ä¸€åˆ†ç±»å¾—åˆ†ï¼Œç¼ºä¹å‘é‡è¡¨ç¤ºèƒ½åŠ›ï¼Œæ— æ³•æ”¯æŒèšç±»æˆ–å¯¹ç§°æ£€ç´¢ç­‰ä»»åŠ¡ã€‚

Luxical æ—¨åœ¨è§£å†³è¿™ä¸€â€œé€Ÿåº¦ vs. çµæ´»æ€§â€çš„çŸ›ç›¾ï¼Œæå‡ºä¸€ç§å…¼å…·é«˜æ•ˆç‡ä¸è¡¨è¾¾åŠ›çš„ä¸­é—´æ–¹æ¡ˆã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šLuxical æ¶æ„
Luxical æ˜¯ä¸€ä¸ªèåˆ **sparse lexical ç‰¹å¾** ä¸ **è½»é‡ç¥ç»ç½‘ç»œ** çš„æ··åˆå‹â€œlexical-denseâ€æ–‡æœ¬åµŒå…¥æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒè®¾è®¡å¦‚ä¸‹ï¼š

- **Sparse Lexical Featurization**ï¼š
  - è¾“å…¥æ–‡æœ¬è¢«åˆ†è¯åæ„å»º **ngram-level TF-IDF å‘é‡**ï¼ˆåŸºäºå›ºå®šå¤§å°çš„ 5-gram è¯æ±‡è¡¨ï¼‰ã€‚
  - ä½¿ç”¨ç²¾ç¡®åŒ¹é…è€Œéå“ˆå¸ŒæŠ€å·§ï¼ˆno hashing trickï¼‰ï¼Œä¿ç•™å®Œæ•´ term ç»Ÿè®¡ä¿¡æ¯ã€‚
  
- **Dense Neural Transformation**ï¼š
  - å°†ç¨€ç– TF-IDF å‘é‡è¾“å…¥ä¸€ä¸ªå°å‹ ReLU ç½‘ç»œï¼ˆMLPï¼‰ï¼Œè¾“å‡ºå½’ä¸€åŒ–çš„ dense embeddingã€‚
  - åˆ©ç”¨ **sparse-by-dense matrix multiplication** å®ç°é«˜æ•ˆå‰å‘ä¼ æ’­ï¼Œæ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ã€‚

- **Knowledge Distillation è®­ç»ƒç›®æ ‡**ï¼š
  - é‡‡ç”¨ **Gram-matrix è’¸é¦æŸå¤±å‡½æ•°**ï¼ˆGram-matrix distillation objectiveï¼‰ï¼š
    $$
    \mathcal{L}_{\text{distill}} = T^2 \cdot \text{KLDiv}(G_s / T, G_t / T)
    $$
    å…¶ä¸­ $G_s = SS^\top$ å’Œ $G_t = TT^\top$ åˆ†åˆ«ä¸ºå­¦ç”Ÿï¼ˆLuxicalï¼‰ä¸æ•™å¸ˆæ¨¡å‹ï¼ˆå¦‚ snowflake-arctic-embed-m-v2.0ï¼‰çš„ç›¸ä¼¼åº¦çŸ©é˜µã€‚
  - ç›®æ ‡æ˜¯è®© Luxical å­¦ä¹ æ•™å¸ˆæ¨¡å‹çš„ **pairwise ç›¸ä¼¼æ€§ç»“æ„**ï¼Œä»è€Œé€¼è¿‘å…¶è¯­ä¹‰å‡ ä½•ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ä¼˜åŠ¿ |
|------|------|
| **vs. Transformer Embedders**ï¼ˆMiniLM, Qwenï¼‰ | æ¨ç†é€Ÿåº¦æå‡ **3x ~ 100x**ï¼Œå¯åœ¨ CPU ä¸Šå®ç°æé«˜ååï¼Œé€‚åˆå¤§è§„æ¨¡é¢„å¤„ç†æµæ°´çº¿ |
| **vs. Lexical Models**ï¼ˆFastTextï¼‰ | è¾“å‡ºä¸º dense vectorï¼Œæ”¯æŒèšç±»ã€æ£€ç´¢ã€ä¸‹æ¸¸åˆ†ç±»ç­‰å¤šç”¨é€”ä»»åŠ¡ï¼Œçµæ´»æ€§æ›´å¼º |
| **æ€»ä½“å®šä½** | åœ¨ **compute/quality trade-off æ›²çº¿ä¸Šæä¾›æ›´ä¼˜å¹³è¡¡ç‚¹**ï¼Œç‰¹åˆ«é€‚ç”¨äº web-scale æ–‡æœ¬ç»„ç»‡åœºæ™¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **FineWeb**ï¼šç”¨äºè®­ç»ƒå’Œè¯„ä¼°çš„ä¸»è¦è‹±æ–‡ç½‘é¡µè¯­æ–™åº“ã€‚
  - è®­ç»ƒé›†ï¼šä» FineWeb ä¸­é‡‡æ ·çš„ **5000 ä¸‡æ–‡æ¡£**
  - æµ‹è¯•é›†ï¼š
    - **100,000 å®Œæ•´æ–‡æ¡£**ï¼šç”¨äºç«¯åˆ°ç«¯ååæµ‹è¯•
    - **50,000 æ–‡æ¡£æ‹†åˆ†ä¸º halves**ï¼šæ„é€ æ­£æ ·æœ¬å¯¹ï¼Œç”¨äº document-half matching æ£€ç´¢ä»»åŠ¡
    - **600B token éšæœºå­é›†**ï¼šç”¨äºæ•°æ®ç­›é€‰å®éªŒï¼Œæœ€ç»ˆè¿‡æ»¤è‡³ 60B token é«˜è´¨é‡å­é›†

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### ï¼ˆ1ï¼‰**Throughput Benchmark**
- **ä»»åŠ¡**ï¼šåµŒå…¥ 100,000 FineWeb æ–‡æ¡£
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š
  - Apple M4 Max CPUï¼ˆLuxical-One ä¸»è¦è¿è¡Œå¹³å°ï¼‰
  - NVIDIA A10G GPUï¼ˆç”¨äºå¯¹æ¯” transformer æ¨¡å‹åŠ é€Ÿæ•ˆæœï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - Documents per secondï¼ˆæ–‡æ¡£/ç§’ï¼‰
  - MiB/secï¼ˆæ¯ç§’å¤„ç†çš„æ•°æ®é‡ï¼‰

#### ï¼ˆ2ï¼‰**Document-Half Matching**
- **ä»»åŠ¡**ï¼šå°†æ¯ä¸ªæ–‡æ¡£åˆ‡åˆ†ä¸ºä¸¤åŠï¼Œé€šè¿‡ embedding ç›¸ä¼¼åº¦æ£€ç´¢åŸå§‹é…å¯¹çš„ä¸€åŠ
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - Error-at-k æ›²çº¿ï¼ˆå³ top-k æ£€ç´¢é”™è¯¯ç‡ï¼‰
  - ä¸åŒ retrieval window å¤§å°ä¸‹çš„è¡¨ç°ï¼ˆå¦‚ top 0.001%, 0.01%, ..., 50%ï¼‰

#### ï¼ˆ3ï¼‰**Classifier-Based Data Curation**
- **ä»»åŠ¡**ï¼šä½¿ç”¨ä¸åŒ scorer å¯¹ FineWeb æ•°æ®è¿›è¡Œè´¨é‡æ‰“åˆ†å¹¶ç­›é€‰ top 10%
- **ä¸‹æ¸¸éªŒè¯æ–¹å¼**ï¼šè®­ç»ƒä¸€ä¸ª 3B å‚æ•°çš„ LLMï¼Œå¹¶åœ¨å¤šä¸ª zero-shot benchmark ä¸Šæµ‹è¯•æ€§èƒ½
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - Scoring pipeline throughputï¼ˆæ–‡æ¡£/ç§’ï¼‰
  - ä¸‹æ¸¸ LLM çš„å¹³å‡å‡†ç¡®ç‡ï¼ˆARC, MMLU, OpenBookQA, SciQï¼‰

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ¨¡å‹ | ç±»å‹ | æè¿° |
|------|------|------|
| **Qwen3-0.6B** | Transformer Encoder | å¼ºå¤§çš„ dense embedding æ¨¡å‹ï¼Œå‚æ•°çº¦ 0.444B |
| **MiniLM-L6-v2** | Small Transformer | è½»é‡çº§ BERT å˜ä½“ï¼Œå¸¸ç”¨äº sentence embedding |
| **FastText** | Lexical Classifier | DCLM é¡¹ç›®ä½¿ç”¨çš„åˆ†ç±»å™¨ï¼Œä»…è¾“å‡º scalar score |
| **FineWeb-Edu Scorer** | Transformer + Classifier Head | åŸºäº BERT çš„æ•™è‚²è´¨é‡è¯„åˆ†å™¨ |
| **Arctic-2.0-M** | Teacher Model | Luxical-One çš„è’¸é¦æ¥æºï¼Œembedding ç»´åº¦ 256 |
| **LEAF-MT** | Distilled MiniLM | ä¸ MiniLM åŒæ¶æ„ä½†ç»çŸ¥è¯†è’¸é¦è®­ç»ƒ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ï¼ˆ1ï¼‰**Throughput æ€§èƒ½å¯¹æ¯”**ï¼ˆå›¾ 3ï¼‰
| æ¨¡å‹ | å¹³å° | ååé‡ï¼ˆdocs/sï¼‰ | ç›¸å¯¹ Luxical-One é€Ÿåº¦ |
|-------|--------|------------------|-------------------------|
| **Luxical-One** | CPU (M4 Max) | **6,803** | 1Ã—ï¼ˆåŸºå‡†ï¼‰ |
| **MiniLM-L6-v2** | CPU | 307 | ~22Ã— æ›´æ…¢ |
| **MiniLM-L6-v2** | GPU | 2,357 | ~2.9Ã— æ›´æ…¢ |
| **Qwen3-0.6B** | GPU | 70 | ~97Ã— æ›´æ…¢ |

> âœ… **ç»“è®º**ï¼šå³ä½¿åœ¨ GPU åŠ é€Ÿä¸‹ï¼Œä¸»æµ transformer æ¨¡å‹ä»è¿œè½åäº Luxical-One çš„ CPU æ¨ç†é€Ÿåº¦ã€‚

---

### ï¼ˆ2ï¼‰**Document-Half Matching æ£€ç´¢æ€§èƒ½**ï¼ˆå›¾ 4ï¼‰
- åœ¨ **top-1 æ£€ç´¢** ä¸Šï¼ŒLuxical-One è¡¨ç°å¼±äºå¤§å‹æ¨¡å‹ï¼ˆå¦‚ Qwenï¼‰ï¼Œä½†ä»ä¼˜äº MiniLMã€‚
- éšç€æ£€ç´¢çª—å£æ‰©å¤§ï¼ˆå¦‚ top 0.1% ~ 1%ï¼‰ï¼ŒLuxical-One å¿«é€Ÿè¿½å¹³ç”šè‡³æ¥è¿‘ Arctic-2.0-M å’Œ Mxbai-L-v1 çš„è¡¨ç°ã€‚
- **å…³é”®å‘ç°**ï¼šåœ¨ç²—ç²’åº¦æ£€ç´¢ä»»åŠ¡ä¸­ï¼ˆä¾‹å¦‚æ‰¾å‡ºæœ€ç›¸ä¼¼çš„å‰ 1% æ–‡æ¡£ï¼‰ï¼ŒLuxical-One çš„è¯­ä¹‰æ•æ‰èƒ½åŠ›æ¥è¿‘å…ˆè¿› transformer æ¨¡å‹ã€‚

> ğŸ“Š ç¤ºä¾‹ï¼šåœ¨ top 1% retrieval window ä¸‹ï¼ŒLuxical-One é”™è¯¯ç‡æ˜¾è‘—ä½äº MiniLM-L6-v2 å’Œ LEAF-MTã€‚

---

### ï¼ˆ3ï¼‰**æ•°æ®ç­›é€‰åº”ç”¨ä¸­çš„ç»¼åˆè¡¨ç°**ï¼ˆå›¾ 5ï¼‰
#### a. **åˆ†ç±»æµæ°´çº¿åå**
| æ–¹æ³• | ååé‡ï¼ˆMiB/sï¼‰ | docs/s |
|------|------------------|--------|
| **Luxical + MLP Scorer** | **23.1** | 6,787 |
| **FastText Scorer** | 19.0 | 5,590 |
| **FineWeb-Edu Scorer** | 1.6 | 478 |

> âš¡ Luxical-based pipeline æ¯” transformer åŸºçº¿å¿« **14.2x**ï¼Œä¸”ç•¥ä¼˜äº FastTextã€‚

#### b. **ä¸‹æ¸¸ LLM æ€§èƒ½**
| è¿‡æ»¤æ–¹æ³• | MMLU å‡†ç¡®ç‡ | ARC Easy | OpenBookQA | SciQ | å¹³å‡ |
|----------|-------------|-----------|--------------|-------|-------|
| No Filter | ä½ | â€” | â€” | â€” | â€” |
| **All Three Filters** | **36.4%** | ~60% | ~50% | ~70% | ~ç›¸è¿‘ |

> âœ… æ‰€æœ‰ä¸‰ç§è¿‡æ»¤æ–¹æ³•ï¼ˆLuxicalã€FastTextã€FineWeb-Eduï¼‰å¾—åˆ°çš„è®­ç»ƒæ•°æ®ï¼Œå‡èƒ½è®­ç»ƒå‡ºæ€§èƒ½ç›¸å½“çš„ LLMï¼Œè¯´æ˜ Luxical åœ¨å®é™…åº”ç”¨ä¸­ä¸ç‰ºç‰²è´¨é‡ã€‚

æ­¤å¤–ï¼Œç”±äº Luxical çš„ embedding æ­¥éª¤å¯å¤ç”¨ï¼Œè€Œ MLP åˆ†ç±»æå¿«ï¼ˆ<0.25% runtimeï¼‰ï¼Œå…è®¸å¿«é€Ÿè¿­ä»£è°ƒå‚ï¼Œè¿›ä¸€æ­¥æå‡å·¥ç¨‹æ•ˆç‡ã€‚

---

### ï¼ˆ4ï¼‰æ¶ˆèå®éªŒä¸åˆ†æï¼ˆéšå«åœ¨æ–‡ä¸­ï¼‰
- **è’¸é¦çš„æœ‰æ•ˆæ€§**ï¼šå°½ç®¡ Luxical æ¶æ„ç®€å•ï¼ˆæ— ä½ç½®ç¼–ç ã€æµ…å±‚ç½‘ç»œï¼‰ï¼Œä½†ç”±äºçŸ¥è¯†è’¸é¦è‡ªå¼ºå¤§ teacherï¼Œå…¶è¡¨ç°è¶…è¶ŠåŒè§„æ¨¡ MiniLM å’Œ LEAF-MTã€‚
- **IDF scaling åˆ†ç¦»è®¾è®¡**ï¼šå°† IDF æƒé‡ç‹¬ç«‹äº MLP ç¬¬ä¸€å±‚ï¼Œæœ‰åŠ©äºä¼˜åŒ–ç¨³å®šæ€§ã€‚
- **tokenization æˆä¸ºç“¶é¢ˆ**ï¼šå¾—ç›Šäºé«˜æ•ˆçš„ sparse projectionï¼Œå®é™…è¿è¡Œä¸­ **tokenization æ—¶é—´ä¸»å¯¼æ€»è€—æ—¶**ï¼Œè¡¨æ˜æ¶æ„å·²é«˜åº¦ä¼˜åŒ–ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Luxical æˆåŠŸå®ç°äº† lexical ä¸ dense æ–¹æ³•çš„ä¼˜ç‚¹ç»“åˆ**ï¼š
   - æ¨ç†é€Ÿåº¦åª²ç¾ FastTextï¼Œåœ¨ CPU ä¸Šè¾¾åˆ°æ•°åƒæ–‡æ¡£/ç§’ï¼›
   - è¾“å‡º dense embedding æ”¯æŒèšç±»ã€æ£€ç´¢ã€åˆ†ç±»ç­‰å¤šæ ·åŒ–ä»»åŠ¡ï¼›
   - è¯­ä¹‰è´¨é‡åœ¨ç²—ç²’åº¦ä»»åŠ¡ä¸Šæ¥è¿‘ transformer æ¨¡å‹ã€‚

2. **çŸ¥è¯†è’¸é¦æ˜¯å…³é”®æ¨åŠ¨åŠ›**ï¼š
   - å³ä½¿å­¦ç”Ÿæ¨¡å‹ç»“æ„å—é™ï¼Œä¹Ÿèƒ½é€šè¿‡å­¦ä¹  teacher çš„ Gram çŸ©é˜µæœ‰æ•ˆç»§æ‰¿å…¶è¯­ä¹‰ç©ºé—´ç»“æ„ã€‚

3. **é€‚åˆå¤§è§„æ¨¡æ–‡æœ¬ç»„ç»‡æµæ°´çº¿**ï¼š
   - Luxical è®¾è®¡ä¸ºâ€œä¸€æ¬¡æ€§åµŒå…¥ + å¤šæ¬¡å¤ç”¨â€ï¼Œéå¸¸é€‚åˆç”¨äº deduplicationã€clusteringã€domain slicing ç­‰é¢„å¤„ç†é˜¶æ®µã€‚

4. **éƒ¨ç½²å‹å¥½**ï¼š
   - æ¨¡å‹å°ã€ä¾èµ–å°‘ã€API ç®€æ´ï¼Œæ˜“äºé›†æˆè¿›ç°æœ‰ç³»ç»Ÿï¼›
   - å¼€æºåœ°å€ï¼š[https://github.com/datologyai/luxical](https://github.com/datologyai/luxical)

---

### å±€é™æ€§
1. **è¯­è¨€ä¸é¢†åŸŸé™åˆ¶**ï¼š
   - å½“å‰ä»…å‘å¸ƒè‹±æ–‡æ¨¡å‹ Luxical-Oneï¼ŒæœªéªŒè¯å¤šè¯­è¨€èƒ½åŠ›ã€‚
   - è®­ç»ƒæ•°æ®æ¥è‡ª FineWebï¼Œå¯èƒ½åå‘ç‰¹å®šç½‘é¡µé£æ ¼ã€‚

2. **ç»†ç²’åº¦ä»»åŠ¡è¡¨ç°æœ‰é™**ï¼š
   - åœ¨éœ€è¦é«˜ç²¾åº¦æ’åºçš„ä»»åŠ¡ï¼ˆå¦‚æœç´¢å¼•æ“ï¼‰ä¸­ï¼Œä»ä¸å¦‚ full transformer encodersã€‚

3. **è¯„ä¼°èŒƒå›´æœ‰é™**ï¼š
   - å®éªŒé›†ä¸­åœ¨ä¸¤ä¸ªä»»åŠ¡ï¼ˆdocument retrieval å’Œ data curationï¼‰ï¼Œå°šæœªè¦†ç›–æ›´å¤šåº”ç”¨åœºæ™¯ï¼ˆå¦‚è·¨æ¨¡æ€ã€é—®ç­”ç­‰ï¼‰ã€‚

4. **æœªæ¢ç´¢å˜ä½“**ï¼š
   - å¦‚æ›´å¤§/æ›´å°ç‰ˆæœ¬ã€ä¸åŒè’¸é¦ç­–ç•¥ã€åŠ¨æ€ vocab ç­‰æ‰©å±•æœªç ”ç©¶ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼€å‘ **multilingual Luxical models**
- æ¢ç´¢ **distilled variants** æˆ– **quantized versions** ä»¥è¿›ä¸€æ­¥å‹ç¼©
- ä¸ corpus management å·¥å…·é“¾æ·±åº¦é›†æˆï¼ˆå¦‚ Dolmaã€DataCompï¼‰
- ç ”ç©¶ä¸å…¶ä»–é™æ€ embedding æ–¹æ³•ï¼ˆå¦‚ Static Embeddingsã€model2vecï¼‰çš„å…³ç³»ä¸èåˆå¯èƒ½æ€§

---

## æ€»ç»“
Luxical æå‡ºäº†ä¸€ç§æ–°é¢–çš„ **lexical-dense hybrid embedding èŒƒå¼**ï¼Œé€šè¿‡ **TF-IDF + small MLP + knowledge distillation** çš„ç»„åˆï¼Œåœ¨ä¿æŒæé«˜æ¨ç†é€Ÿåº¦çš„åŒæ—¶ï¼Œè·å¾—äº†æ¥è¿‘ transformer æ¨¡å‹çš„è¯­ä¹‰è¡¨è¾¾èƒ½åŠ›ã€‚å®éªŒè¯æ˜å…¶åœ¨ web-scale text organization åœºæ™¯ä¸­å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œæ˜¯è¿æ¥ä¼ ç»Ÿ lexical æ–¹æ³•ä¸ç°ä»£ dense embedding çš„ä¸€åº§å®ç”¨æ¡¥æ¢ã€‚

</details>

---

### 11. [MentraSuite: Post-Training Large Language Models for Mental Health Reasoning and Assessment](https://arxiv.org/abs/2512.09636)

**Authors**: Mengxi Xiao, Kailai Yang, Pengde Zhao, Enze Zhang, Ziyan Kuang, Zhiwei Liu, Weiguang Han, Shu Liao, Lianting Huang, Jinpeng Hu, Min Peng, Qianqian Xie, Sophia Ananiadou  
**Category**: cs.CL  
**Published**: 2025-12-11  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.09636v1  

#### Abstract
Mental health disorders affect hundreds of millions globally, and the Web now serves as a primary medium for accessing support, information, and assessment. Large language models (LLMs) offer scalable and accessible assistance, yet their deployment in mental-health settings remains risky when their ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMentraSuite: Post-Training Large Language Models for Mental Health Reasoning and Assessment

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰çš„ Large Language Modelsï¼ˆLLMsï¼‰åœ¨å¿ƒç†å¥åº·é¢†åŸŸçš„åº”ç”¨é¢ä¸´ä»¥ä¸‹å…³é”®æŒ‘æˆ˜ï¼š

- **æ¨ç†ä¸å®Œæ•´ã€ä¸ä¸€è‡´æˆ–ç¼ºä¹ä¾æ®**ï¼šè®¸å¤šæ¨¡å‹ä»…èƒ½ç”Ÿæˆæµç•…ä½†è¡¨é¢åŒ–çš„å›åº”ï¼Œæ— æ³•è¿›è¡Œä¸´åºŠå¯¹é½çš„é€æ­¥æ¨ç†ã€‚
- **ç°æœ‰å¿ƒç†é¢†åŸŸLLMä¾§é‡æƒ…æ„Ÿç†è§£æˆ–çŸ¥è¯†å›å¿†**ï¼Œå¿½è§†äº†å¿ƒç†è¯„ä¼°ä¸­çš„æ ¸å¿ƒè®¤çŸ¥è¿‡ç¨‹ï¼Œå¦‚è®¤çŸ¥é‡æ„ã€è¯Šæ–­ã€å¹²é¢„è§„åˆ’ã€è¯æ®æŠ½è±¡å’Œä¿¡æ¯éªŒè¯ã€‚
- **ç¼ºä¹ç³»ç»Ÿæ€§è¯„ä¼°æ¡†æ¶**ï¼šç°æœ‰åŸºå‡†ï¼ˆå¦‚ PsychCounsel-Benchï¼‰ä¸»è¦å…³æ³¨ä»»åŠ¡å‡†ç¡®ç‡ï¼Œå¿½ç•¥äº†æ¨ç†é“¾çš„è´¨é‡ï¼ˆå¦‚é€»è¾‘è¿è´¯æ€§ã€å¹»è§‰é¿å…ã€å†…éƒ¨ä¸€è‡´æ€§ç­‰ï¼‰ã€‚

å› æ­¤ï¼Œè®ºæ–‡æ—¨åœ¨è§£å†³ï¼šå¦‚ä½•æ„å»ºä¸€ä¸ªèƒ½å¤Ÿè¿›è¡Œ**å¯é ã€å¯è§£é‡Šã€ä¸´åºŠå¯¹é½çš„å¿ƒç†å¥åº·æ¨ç†**çš„ LLM æ¡†æ¶ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

è®ºæ–‡æå‡º **MentraSuite**ï¼Œä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼ŒåŒ…å«ä¸‰å¤§æ ¸å¿ƒç»„ä»¶ï¼š

#### ï¼ˆ1ï¼‰**MentraBench**ï¼šé¦–ä¸ªç»¼åˆæ€§å¿ƒç†å¥åº·æ¨ç†åŸºå‡†
- è¦†ç›–äº”å¤§æ ¸å¿ƒä¸´åºŠæ¨ç†ç»´åº¦ï¼š
  - **Appraisal**ï¼ˆè®¤çŸ¥æ¨¡å¼è¯†åˆ«ï¼‰
  - **Diagnosis**ï¼ˆå¿ƒç†çŠ¶å†µåˆ¤æ–­ï¼‰
  - **Intervention**ï¼ˆå¹²é¢„ç­–ç•¥é€‰æ‹©ï¼‰
  - **Abstraction**ï¼ˆç ”ç©¶è¯æ®æç‚¼ï¼‰
  - **Verification**ï¼ˆä¿¡æ¯çœŸä¼ªè¾¨åˆ«ï¼‰
- åŒ…å« **6é¡¹ä»»åŠ¡ã€13ä¸ªæ•°æ®é›†**ï¼Œæ¶µç›–çœŸå®å¯¹è¯ã€ç¤¾äº¤åª’ä½“æ–‡æœ¬ã€åŒ»å­¦è€ƒè¯•é¢˜ã€ç³»ç»Ÿç»¼è¿°ç­‰å¤šæºæ•°æ®ã€‚
- å¼•å…¥**äº”ç»´æ¨ç†è´¨é‡è¯„ä¼°ä½“ç³»**ï¼š
  - Reasoning Concisenessï¼ˆç®€æ´æ€§ï¼‰
  - Logical Coherenceï¼ˆé€»è¾‘è¿è´¯æ€§ï¼‰
  - Hallucination Avoidanceï¼ˆå¹»è§‰é¿å…ï¼‰
  - Task Understandingï¼ˆä»»åŠ¡ç†è§£ï¼‰
  - Internal Consistencyï¼ˆå†…éƒ¨ä¸€è‡´æ€§ï¼‰

#### ï¼ˆ2ï¼‰**Mindora**ï¼šåè®­ç»ƒä¼˜åŒ–çš„å¿ƒç†å¥åº·ä¸“ç”¨æ¨¡å‹
- åŸºäº Qwen3-8B æ„å»ºï¼Œé‡‡ç”¨ **Hybrid SFT-RL æ¡†æ¶**ï¼ˆç»“åˆç›‘ç£å¾®è°ƒä¸å¼ºåŒ–å­¦ä¹ ï¼‰ã€‚
- åˆ›æ–°å¼•å…¥ **LLM-based inconsistency-detection reward**ï¼Œé€šè¿‡è¾…åŠ©æ¨¡å‹ï¼ˆQwen3-32Bï¼‰åŠ¨æ€æ£€æµ‹æ¨ç†é“¾ä¸­çš„äº‹å®é”™è¯¯å’Œé€»è¾‘çŸ›ç›¾ï¼Œæå‡æ¨ç†ä¿çœŸåº¦ã€‚
- æ”¯æŒå¤šé˜¶æ®µã€æ•´åˆæ€§æ¨ç†ï¼Œé€‚ç”¨äºå¤æ‚å¿ƒç†åœºæ™¯ã€‚

#### ï¼ˆ3ï¼‰**Reasoning Trajectory Generation (RTG)**ï¼šé«˜è´¨é‡æ¨ç†è½¨è¿¹ç”Ÿæˆç­–ç•¥
- **éš¾åº¦ç­›é€‰**ï¼šä»…ä¿ç•™ Llama-3-8B-Instruct é›¶æ ·æœ¬é¢„æµ‹é”™è¯¯çš„æ ·æœ¬ï¼Œç¡®ä¿è®­ç»ƒæ•°æ®å…·æœ‰æŒ‘æˆ˜æ€§ã€‚
- **è¿­ä»£æœ€ä¼˜è·¯å¾„æœç´¢**ï¼šåˆ©ç”¨ GPT-4o è¿›è¡Œå¤šè½®åæ€ä¸ä¿®æ­£ï¼ˆBacktracking / New Path Explorationï¼‰ï¼Œç”Ÿæˆæ­£ç¡®ä¸”æ·±åº¦çš„æ¨ç†é“¾ã€‚
- **ç»“æ„åŒ–æ ¼å¼åŒ–**ï¼šå¼ºåˆ¶ä½¿ç”¨ `<think>` å’Œ `<answer>` æ ‡ç­¾ï¼Œå¹¶åˆ†æ¨¡å—ï¼ˆå¦‚ `###Symptom Analysis`ï¼‰ç»„ç»‡æ¨ç†æ­¥éª¤ï¼Œæå‡å¯è¯»æ€§å’Œä¸€è‡´æ€§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹æ³• | å±€é™æ€§ | MentraSuite çš„ä¼˜åŠ¿ |
|------|--------|------------------|
| **Psyche-R1** | ä¾§é‡å…±æƒ…ä¸çŸ¥è¯†æ•´åˆï¼Œæœªè¦†ç›–å¤šé˜¶æ®µä¸´åºŠæ¨ç† | æ˜ç¡®å»ºæ¨¡ Appraisal â†’ Diagnosis â†’ Intervention å…¨æµç¨‹ |
| **Psy-Interpreter** | ä¾èµ–ä¸“å®¶æ ‡æ³¨åœºæ™¯ï¼Œæ³›åŒ–èƒ½åŠ›å—é™ | é€šè¿‡ RL + inconsistency reward è‡ªåŠ¨ä¼˜åŒ–æ¨ç†è´¨é‡ |
| **PsychCounsel-Bench** | ä»…æµ‹è¯•çŸ¥è¯†è®°å¿†ï¼Œå½¢å¼ä¸ºé€‰æ‹©é¢˜ | å¼•å…¥å¼€æ”¾æ¨ç†ä»»åŠ¡ä¸å¤šç»´è´¨é‡è¯„ä¼° |
| **é€šç”¨LLMï¼ˆå¦‚GPT-4oï¼‰** | æ¨ç†å†—é•¿ã€æ˜“äº§ç”Ÿå¹»è§‰ã€ç¼ºä¹ä¸€è‡´æ€§ | Mindora åœ¨æ‰€æœ‰æ¨ç†ç»´åº¦ä¸Šè¡¨ç°æ›´ä¼˜ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

MentraBench æ•´åˆå¹¶æ–°å»ºäº† **13ä¸ªæ•°æ®é›†**ï¼Œåˆ†ä¸ºå…­ç±»ä»»åŠ¡ï¼š

| ä»»åŠ¡ | æ•°æ®é›† | æ¥æº | ç±»å‹ |
|------|--------|------|------|
| **Cognitive Error Identification** | CognitiveReframing, PatternReframe, Therapist Q&A | åˆæˆ + çœŸå®å’¨è¯¢å¯¹è¯ | Appraisal |
| **Mental Health Condition Detection** | DepSign, SWMH, T-SID | Reddit, Twitter | Diagnosis |
| **Counseling Strategy Formulation** | PsyDTCorpusM, AnnoMI | åˆæˆ & MI è§†é¢‘è½¬å½• | Intervention |
| **Psychiatry QA** | MHQA, MedQAM, MedMCQA, PubMedQAM | PubMed, åŒ»å­¦è€ƒè¯• | Multi-step Reasoning |
| **Systematic Review Summarization** | PSRS*ï¼ˆæœ¬æ–‡æ–°å»ºï¼‰ | Cochrane Library | Abstraction |
| **Misinformation Identification** | MentalMisinfo | YouTube Shorts, BitChute | Verification |

> æ³¨ï¼šå¸¦ * è¡¨ç¤ºæœ¬æ–‡æ–°å»ºï¼›å¸¦ M è¡¨ç¤ºæœ¬æ–‡å¤„ç†è¿‡ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°æ¨¡å‹èŒƒå›´å¹¿æ³›**
- **é—­æºæ¨¡å‹**ï¼šGPT-4o, GPT-4o-mini, DeepSeek-R1, DeepSeek-V3, Qwen-plus, QwQ-plus
- **å¼€æºæ¨¡å‹**ï¼šLLaMA3.1-8B, Qwen3-8B/14B/32B/72B åŠå…¶è’¸é¦ç‰ˆæœ¬
- **å¿ƒç†ä¸“ç”¨æ¨¡å‹**ï¼šEmoLLM, Psyche-R1
- **æœ¬æ–‡æå‡ºæ¨¡å‹**ï¼šMindora_SFT, Mindora_SFT+RL, Mindora_CHORD

#### **è¯„ä¼°æ–¹å¼**
- æ‰€æœ‰æ¨¡å‹å‡æŒ‰ Mindora æ ¼å¼ç”Ÿæˆç»“æ„åŒ–æ¨ç†é“¾ï¼ˆ`<think>...</think><answer>...</answer>`ï¼‰ã€‚
- **ä»»åŠ¡æ€§èƒ½æŒ‡æ ‡**ï¼šMicro-F1, Jaccard Score, Recall ç­‰ï¼ˆä¾ä»»åŠ¡è€Œå®šï¼‰ã€‚
- **æ¨ç†è´¨é‡äººå·¥è¯„ä¼°**ï¼šä»æ¯ä¸ªæ¨¡å‹ä¸­æŠ½æ · 4 ä¾‹ï¼ˆ2 æ­£ç¡® + 2 é”™è¯¯ï¼‰ï¼Œç”±äººå·¥æŒ‰äº”ç»´æ ‡å‡†æ‰“åˆ†ï¼ˆ0/1ï¼‰ï¼Œæœ€ç»ˆå–å¹³å‡å€¼ä½œä¸º **Reasoning Trajectory Score**ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿ç±»åˆ« | ä»£è¡¨æ¨¡å‹ | ç‰¹ç‚¹ |
|---------|----------|------|
| é€šç”¨èŠå¤©æ¨¡å‹ | GPT-4o, Qwen-plus | å¼ºè¯­è¨€èƒ½åŠ›ä½†æ¨ç†ä¸å¯æ§ |
| æ¨ç†ä¼˜åŒ–æ¨¡å‹ | GPT-4o-mini, DeepSeek-R1 | ä½¿ç”¨ RL æå‡æ¨ç†èƒ½åŠ› |
| å¿ƒç†ä¸“ç”¨æ¨¡å‹ | EmoLLM, Psyche-R1 | èšç„¦å…±æƒ…ä¸å¿ƒç†çŸ¥è¯† |
| å¼€æºåŸºç¡€æ¨¡å‹ | Qwen3-8B, LLaMA3.1-8B | æœªç»ä¸“é—¨æ¨ç†ä¼˜åŒ– |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 3ï¼‰**

| æ¨¡å‹ | Avg_allï¼ˆ13é¡¹å¹³å‡ï¼‰ |
|------|--------------------|
| **Mindora_CHORD** | **0.6933** âœ…ï¼ˆæœ€é«˜ï¼‰ |
| Mindora_SFT+RL | 0.6548 |
| GPT-4o-mini | 0.6515 |
| DeepSeek-R1 | 0.6350 |
| Psyche-R1 | 0.5943 |
| Qwen3-8Bï¼ˆéª¨å¹²æ¨¡å‹ï¼‰ | 0.5729 |

> Mindora_CHORD åœ¨ **å…¨éƒ¨13ä¸ªæ•°æ®é›†** ä¸Šå‡ä¼˜äºåŸºçº¿ï¼Œå°¤å…¶åœ¨ **Intervention** å’Œ **Abstraction** ä»»åŠ¡ä¸Šæå‡æ˜¾è‘—ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **è¶…è¶Šæœ€å¼ºé—­æºæ¨ç†æ¨¡å‹**ï¼š
  - Mindora_CHORD æ¯” GPT-4o-mini é«˜å‡º **+4.18ä¸ªç™¾åˆ†ç‚¹**ã€‚
  - åœ¨ **Therapist Q&A**ï¼ˆçœŸå®å’¨è¯¢è®¤çŸ¥é”™è¯¯è¯†åˆ«ï¼‰ä¸Šï¼ŒMindora è¾¾åˆ° 0.5088 vs GPT-4o-mini çš„ 0.4468ã€‚
- **ä¼˜äºå¿ƒç†ä¸“ç”¨æ¨¡å‹ Psyche-R1**ï¼š
  - å¹³å‡å¾—åˆ†é«˜å‡º **è¿‘10ä¸ªç™¾åˆ†ç‚¹**ï¼ˆ0.6933 vs 0.5943ï¼‰ï¼Œè¯´æ˜å…¶æ¨ç†æœºåˆ¶æ›´æœ‰æ•ˆã€‚
- **å°æ¨¡å‹èƒœè¿‡å¤§æ¨¡å‹**ï¼š
  - 8B å‚æ•°çš„ Mindora è¶…è¿‡ 70B çš„ LLaMA-3.3-70Bï¼ˆ0.6933 vs 0.6178ï¼‰ï¼Œè¯æ˜**é’ˆå¯¹æ€§åè®­ç»ƒæ¯”æ¨¡å‹è§„æ¨¡æ›´é‡è¦**ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆéšå«åˆ†æï¼‰**

è™½ç„¶æœªå•ç‹¬åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»ä¸åŒå˜ä½“æ¯”è¾ƒå¯å¾—ï¼š

| æ¨¡å‹å˜ä½“ | Avg_all | åˆ†æ |
|----------|--------|------|
| Qwen3-8B | 0.5729 | åŸºçº¿æ€§èƒ½ |
| Mindora_SFT | 0.6368 | SFT æå‡æ˜æ˜¾ |
| Mindora_SFT+RL | 0.6548 | åŠ å…¥ RL è¿›ä¸€æ­¥æå‡ |
| **Mindora_CHORD** | **0.6933** | åŠ¨æ€èåˆ SFT ä¸ RLï¼Œæ•ˆæœæœ€ä½³ |

> ç»“æœè¡¨æ˜ï¼š**è”åˆè®­ç»ƒï¼ˆJoint SFT-RLï¼‰ä¼˜äºä¸¤é˜¶æ®µè®­ç»ƒï¼ˆSFT â†’ RLï¼‰**ï¼ŒCHORD ç®—æ³•èƒ½æ›´å¥½å¹³è¡¡æ¨¡ä»¿ä¸æ¢ç´¢ã€‚

---

### **æ¨ç†è½¨è¿¹è´¨é‡è¯„ä¼°ï¼ˆTable 4ï¼‰**

| æ¨¡å‹ | R_avgï¼ˆäº”ç»´å¹³å‡åˆ†ï¼‰ |
|------|---------------------|
| **Mindora_CHORD** | **0.9731** âœ… |
| DeepSeek-R1 | 0.9827ï¼ˆR3=1.0ï¼‰ä½† R1=0.9519 |
| Psyche-R1 | 0.9442 |
| Qwen3-8B | 0.9039 |
| GPT-4o-mini | 0.8731 |

> Mindora åœ¨ **Logical Coherenceï¼ˆR2=0.9519ï¼‰** å’Œ **Internal Consistencyï¼ˆR5=0.9808ï¼‰** ä¸Šè¡¨ç°æä½³ï¼Œè¯´æ˜å…¶æ¨ç†é“¾æ›´è¿è´¯ã€æ— çŸ›ç›¾ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **ç»“æ„åŒ–æ¨ç†è®­ç»ƒæ˜¾è‘—æå‡å¿ƒç†å¥åº·ä»»åŠ¡è¡¨ç°**ï¼š
   - é€šè¿‡ RTG ç”Ÿæˆé«˜è´¨é‡ã€ç»“æ„åŒ–ã€ç»è¿‡éªŒè¯çš„æ¨ç†è½¨è¿¹ï¼Œæ˜¯æå‡æ¨¡å‹å¯é æ€§çš„é‡è¦å‰æã€‚

2. âœ… **Hybrid SFT-RL æ¡†æ¶ä¼˜äºçº¯ SFT æˆ–çº¯ RL**ï¼š
   - CHORD ç®—æ³•å®ç°åŠ¨æ€æŸå¤±èåˆï¼Œåœ¨ä¿æŒå‡†ç¡®æ€§çš„åŒæ—¶å¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚

3. âœ… **æ¨ç†è´¨é‡æ¯”ä»»åŠ¡å‡†ç¡®ç‡æ›´é‡è¦**ï¼š
   - å³ä½¿å¤šä¸ªæ¨¡å‹è¾“å‡ºæ­£ç¡®ç­”æ¡ˆï¼Œå…¶æ¨ç†è¿‡ç¨‹ä»å¯èƒ½å­˜åœ¨å¹»è§‰ã€å†—ä½™æˆ–ä¸ä¸€è‡´ï¼›Mindora åœ¨è¿™äº›ç»´åº¦å…¨é¢é¢†å…ˆã€‚

4. âœ… **å°æ¨¡å‹ç»é’ˆå¯¹æ€§ä¼˜åŒ–å¯è¶…è¶Šå¤§æ¨¡å‹**ï¼š
   - 8B çº§åˆ«çš„ Mindora è¶…è¶Š 70B æ¨¡å‹ï¼Œè¡¨æ˜**é¢†åŸŸä¸“ç”¨åè®­ç»ƒçš„ä»·å€¼é«˜äºå•çº¯æ‰©å¤§å‚æ•°é‡**ã€‚

5. âœ… **å¤šç»´åº¦è¯„ä¼°æ­ç¤ºæ¨¡å‹çœŸå®èƒ½åŠ›**ï¼š
   - ä¼ ç»Ÿ Accuracy/F1 æ— æ³•åæ˜ æ¨ç†ç¼ºé™·ï¼Œäº”ç»´è¯„ä¼°ä½“ç³»æ›´è´´è¿‘ä¸´åºŠéœ€æ±‚ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ– GPT-4o æ„å»ºè®­ç»ƒæ•°æ®**ï¼š
   - RTG æµç¨‹ä½¿ç”¨ GPT-4o ç”Ÿæˆå’ŒéªŒè¯æ¨ç†é“¾ï¼Œå­˜åœ¨â€œä»¥å¼ºè®­å¼±â€çš„ä¾èµ–é£é™©ï¼Œå¯èƒ½é™åˆ¶å®Œå…¨å¼€æºç”Ÿæ€çš„åº”ç”¨ã€‚

2. **æ•°æ®æ¥æºåé‡è‹±æ–‡ä¸ç¤¾äº¤åª’ä½“**ï¼š
   - å¤šæ•°æ•°æ®æ¥è‡ª Redditã€Twitterã€YouTubeï¼Œæ–‡åŒ–å¤šæ ·æ€§ä¸ä¸´åºŠä¸¥è°¨æ€§æœ‰å¾…åŠ å¼ºã€‚

3. **å°šæœªåœ¨çœŸå®ä¸´åºŠç¯å¢ƒä¸­éƒ¨ç½²éªŒè¯**ï¼š
   - å½“å‰è¯„ä¼°ä¸ºç¦»çº¿ benchmarkï¼Œç¼ºä¹ä¸çœŸå®æ‚£è€…äº¤äº’çš„å®‰å…¨æ€§ä¸æœ‰æ•ˆæ€§æµ‹è¯•ã€‚

4. **ç»“æ„åŒ–æ ¼å¼å¯èƒ½é™åˆ¶è¡¨è¾¾çµæ´»æ€§**ï¼š
   - å¼ºåˆ¶ `<think>` å’Œæ¨¡å—æ ‡é¢˜å¯èƒ½å½±å“è‡ªç„¶è¯­è¨€æµç•…æ€§ï¼Œéœ€æƒè¡¡å¯è§£é‡Šæ€§ä¸å¯ç”¨æ€§ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ‰©å±•å¤šè¯­è¨€ä¸è·¨æ–‡åŒ–æ•°æ®é›†**ï¼Œæå‡å…¨çƒé€‚ç”¨æ€§ã€‚
2. **å¼€å‘å®Œå…¨å¼€æºçš„ verifier ä¸ trajectory generator**ï¼Œæ‘†è„±å¯¹é—­æºæ¨¡å‹çš„ä¾èµ–ã€‚
3. **å¼€å±•çœŸå®ç”¨æˆ·ç ”ç©¶ï¼ˆUser Studyï¼‰**ï¼Œè¯„ä¼°æ¨¡å‹åœ¨å®é™…å’¨è¯¢åœºæ™¯ä¸­çš„å¸®åŠ©ç¨‹åº¦ä¸æ½œåœ¨é£é™©ã€‚
4. **é›†æˆå¤šæ¨¡æ€è¾“å…¥**ï¼ˆå¦‚è¯­éŸ³ã€è¡¨æƒ…ï¼‰ï¼Œå®ç°æ›´å…¨é¢çš„å¿ƒç†çŠ¶æ€æ„ŸçŸ¥ã€‚
5. **æ¢ç´¢ä¸»åŠ¨å¹²é¢„ä¸é•¿æœŸé™ªä¼´æœºåˆ¶**ï¼Œæ”¯æŒæŒç»­å¿ƒç†å¥åº·ç®¡ç†ã€‚

---

> **æ€»ç»“**ï¼š  
> MentraSuite é€šè¿‡ **MentraBench + Mindora + RTG** ä¸‰ä½ä¸€ä½“è®¾è®¡ï¼Œé¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ¨åŠ¨ LLM åœ¨å¿ƒç†å¥åº·é¢†åŸŸçš„**å¯é æ¨ç†èƒ½åŠ›**å‘å±•ã€‚å…¶å®éªŒå……åˆ†è¯æ˜ï¼š**ç»“æ„åŒ–è®­ç»ƒã€ä¸€è‡´æ€§å¥–åŠ±ã€å¤šç»´è¯„ä¼°**æ˜¯æ„å»ºå¯ä¿¡å¿ƒç†AIçš„å…³é”®è·¯å¾„ï¼Œä¸ºâ€œWeb for Goodâ€æ„¿æ™¯æä¾›äº†åšå®çš„æŠ€æœ¯æ”¯æ’‘ã€‚

</details>

---

### 12. [WarmServe: Enabling One-for-Many GPU Prewarming for Multi-LLM Serving](https://arxiv.org/abs/2512.09472)

**Authors**: Chiheng Lou, Sheng Qi, Rui Kang, Yong Zhang, Chen Sun, Pengcheng Wang, Bingyang Liu, Xuanzhe Liu, Xin Jin  
**Category**: cs.DC  
**Published**: 2025-12-11  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.09472v1  

#### Abstract
Deploying multiple models within shared GPU clusters is promising for improving resource efficiency in large language model (LLM) serving. Existing multi-LLM serving systems optimize GPU utilization at the cost of worse inference performance, especially time-to-first-token (TTFT). We identify the ro...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# WarmServe: Enabling One-for-Many GPU Prewarming for Multi-LLM Serving â€”â€” è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

åœ¨å¤šLLMï¼ˆLarge Language Modelï¼‰æœåŠ¡åœºæ™¯ä¸­ï¼Œç°æœ‰ç³»ç»Ÿé¢ä¸´**æ¨ç†å»¶è¿Ÿé«˜**ï¼ˆå°¤å…¶æ˜¯ Time-to-First-Token, TTFTï¼‰ä¸**èµ„æºåˆ©ç”¨ç‡ä½**ä¹‹é—´çš„æƒè¡¡é—®é¢˜ï¼š

- **Autoscaling ç³»ç»Ÿ**ï¼šé€šè¿‡åŠ¨æ€åˆ›å»º/é”€æ¯å®ä¾‹æé«˜ GPU åˆ©ç”¨ç‡ï¼Œä½†åœ¨è¯·æ±‚çªå‘æ—¶éœ€ç°åœºåŠ è½½æ¨¡å‹ï¼Œå¯¼è‡´æ˜¾è‘—å†·å¯åŠ¨å»¶è¿Ÿã€‚
- **GPU Sharing ç³»ç»Ÿ**ï¼šå°†å¤šä¸ªæ¨¡å‹å…±ç½®åœ¨åŒä¸€ç»„ GPU ä¸Šä»¥æå‡èµ„æºæ•ˆç‡ï¼Œä½†ä¼šé™åˆ¶æ¯ä¸ªæ¨¡å‹çš„ KV Cache ç©ºé—´ï¼Œå¹¶å¼•å…¥æ€§èƒ½å¹²æ‰°ã€‚

æ ¹æœ¬åŸå› åœ¨äºè¿™äº›æ–¹æ³•**ç¼ºä¹å¯¹æœªæ¥å·¥ä½œè´Ÿè½½çš„é¢„çŸ¥èƒ½åŠ›**ï¼Œæ— æ³•æå‰å‡†å¤‡èµ„æºã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

è®ºæ–‡æå‡º **WarmServe**ï¼Œä¸€ä¸ªåŸºäºâ€œ**One-for-Many GPU Prewarming**â€çš„æ–°å‹å¤šLLMæœåŠ¡ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### âœ… **Universal GPU Workersï¼ˆé€šç”¨GPUå·¥ä½œè€…ï¼‰**
- å°†ç©ºé—² GPU é¢„å…ˆåŠ è½½å¤šä¸ªä¸åŒæ¨¡å‹çš„éƒ¨åˆ†æƒé‡ï¼ˆå¦‚å‰å‡ å±‚ï¼‰ï¼Œä½¿å…¶æˆä¸ºâ€œé€šç”¨GPUå·¥ä½œè€…â€ã€‚
- å½“æŸæ¨¡å‹å‡ºç°æµé‡é«˜å³°æ—¶ï¼Œå¯å¿«é€Ÿå°†å…¶è½¬æ¢ä¸ºä¸“ç”¨ GPU å·¥ä½œè€…ï¼ˆdedicated workerï¼‰ï¼Œå®ç°ç§’çº§ç”šè‡³äºšç§’çº§å†·å¯åŠ¨ã€‚

> è¿™ç§è®¾è®¡å®ç°äº†â€œä¸€ä¸ªGPUä¸ºå¤šä¸ªæ¨¡å‹é¢„çƒ­â€çš„ç›®æ ‡ï¼Œæå¤§æå‡äº†é¢„çƒ­èµ„æºçš„å¤ç”¨ç‡ã€‚

#### âœ… **Evict-Aware Model Placement Strategyï¼ˆé©±é€æ„ŸçŸ¥çš„æ¨¡å‹æ”¾ç½®ç­–ç•¥ï¼‰**
- ä¸ºäº†é¿å…å¤šä¸ªé¢„çƒ­æ¨¡å‹ä¹‹é—´å› éƒ¨åˆ†é‡å è€Œå¯¼è‡´â€œä¸€ä¸ªå‘½ä¸­ã€å…¶ä½™å…¨åºŸâ€çš„å¹²æ‰°é—®é¢˜ï¼Œæå‡ºï¼š
  - æ¨¡å‹é—´çš„ GPU é›†åˆå¿…é¡»æ»¡è¶³ï¼š**å®Œå…¨ä¸ç›¸äº¤** æˆ– **åµŒå¥—å…³ç³»**ï¼ˆå³ä¸€ä¸ªé›†åˆæ˜¯å¦ä¸€ä¸ªçš„å­é›†ï¼‰ã€‚
- æ­¤ç­–ç•¥æœ€å°åŒ–äº†é¢„çƒ­å†²çªï¼Œä¿éšœé«˜ä¼˜å…ˆçº§æ¨¡å‹çš„é¢„çƒ­æˆåŠŸç‡ã€‚

#### âœ… **Proactive Prewarmingï¼ˆä¸»åŠ¨é¢„çƒ­ï¼‰**
- åœ¨ autoscaler å‘å‡ºç¼©å®¹ä¿¡å·åã€å®ä¾‹çœŸæ­£ç»ˆæ­¢å‰çš„ **grace period** å†…ï¼Œåˆ©ç”¨è¯¥å®ä¾‹å°šæœªä½¿ç”¨çš„ KV Cache ç©ºé—´ï¼Œé¢„å…ˆåŠ è½½å…¶ä»–æ¨¡å‹çš„æƒé‡ã€‚
- å®ä¾‹é‡Šæ”¾åï¼ŒGPU å¯ç«‹å³è½¬ä¸º universal workerï¼Œæ— éœ€é¢å¤–åŠ è½½æ—¶é—´ã€‚

#### âœ… **Zero-Overhead Memory Switchingï¼ˆé›¶å¼€é”€å†…å­˜åˆ‡æ¢æœºåˆ¶ï¼‰**
- å€ŸåŠ© CUDA VMM API å®ç°è™šæ‹Ÿå†…å­˜é¡µè¡¨çš„çµæ´»æ˜ å°„ã€‚
- æ”¯æŒåœ¨ serving model weightsã€prewarming weights å’Œ KV Cache ä¹‹é—´æ— ç¼åˆ‡æ¢ï¼Œä¸”æ‰€æœ‰æ“ä½œä¸æ•°æ®ä¼ è¾“å¹¶è¡Œæ‰§è¡Œï¼Œé¿å…å¼•å…¥é¢å¤–å»¶è¿Ÿã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | Autoscaling ç³»ç»Ÿ | GPU Sharing ç³»ç»Ÿ | WarmServe |
|------|------------------|------------------|-----------|
| TTFT æ€§èƒ½ | é«˜å»¶è¿Ÿï¼ˆå†·å¯åŠ¨ï¼‰ | ä¸­ç­‰ï¼ˆæ— å†·å¯ï¼Œä½†æ’é˜Ÿä¸¥é‡ï¼‰ | æä½ï¼ˆé¢„çƒ­å®Œæˆå³åˆ»å“åº”ï¼‰ |
| èµ„æºåˆ©ç”¨ç‡ | è¾ƒé«˜ | é«˜ | é«˜ï¼ˆé€šè¿‡ one-for-many æå‡å¤ç”¨ï¼‰ |
| æ¨ç†æ€§èƒ½ï¼ˆTPOTï¼‰ | ä¼˜ç§€ï¼ˆç‹¬å GPUï¼‰ | å·®ï¼ˆå…±äº«å¯¼è‡´é™é€Ÿï¼‰ | ä¼˜ç§€ï¼ˆè¿è¡Œæ—¶ä»ç‹¬å GPUï¼‰ |
| æ‰©å±•æ€§ | åŠ¨æ€æ‰©å±• | å›ºå®šé…ç½® | åŠ¨æ€+é¢„æµ‹é©±åŠ¨ |

> WarmServe æˆåŠŸèåˆäº† autoscaling çš„é«˜æ€§èƒ½ä¸ GPU sharing çš„é«˜æ•ˆèµ„æºåˆ©ç”¨ä¼˜åŠ¿ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†**

- **AzureConv** å’Œ **AzureCode**ï¼šæ¥è‡ªçœŸå®ç”Ÿäº§ç¯å¢ƒçš„ LLM è¯·æ±‚ trace æ•°æ®é›†ã€‚
  - åŒ…å«è¾“å…¥/è¾“å‡º token æ•°é‡ã€è¯·æ±‚åˆ°è¾¾æ—¶é—´ç­‰ä¿¡æ¯ã€‚
  - å…·æœ‰æ˜æ˜¾çš„å‘¨æœŸæ€§å’Œé•¿æœŸå¯é¢„æµ‹æ€§ï¼ˆè®ºæ–‡éªŒè¯é¢„æµ‹å‡†ç¡®ç‡è¾¾ ~93%ï¼‰ã€‚

---

### **å®éªŒè®¾ç½®**

#### **ç¡¬ä»¶å¹³å°**
- ä¸¤å°æœåŠ¡å™¨ï¼Œæ¯å°é…å¤‡ï¼š
  - 8 Ã— GPUï¼ˆFP16ç®—åŠ›çº¦2K TFLOPSï¼‰
  - PCIe 5.0 x16ï¼ˆå¸¦å®½128 GB/sï¼‰ç”¨äºä¸»æœºåˆ°GPUçš„æ•°æ®åŠ è½½
  - NVLink 4.0ï¼ˆ400 GB/sï¼‰è¿æ¥åŒæœºå†…GPU
  - RDMA NICsï¼ˆ8Ã—200Gbpsï¼‰ç”¨äºè·¨æœºé€šä¿¡

#### **æ¨¡å‹é…ç½®**
| Model | Size (GB) | Required GPUs |
|-------|-----------|---------------|
| Llama2-7B | 12.55 | 1 |
| Llama2-13B | 24.24 | 2 |
| Llama2-70B | 128.49 | 4 |

> ä½¿ç”¨ Llama2 ç³»åˆ—æ¨¡å‹ï¼ˆFP16ç²¾åº¦ï¼‰ï¼Œå¹¶å¤åˆ¶ Llama2-7B ä»¥å¢åŠ è°ƒåº¦é¢‘ç‡ã€‚

#### **è¯·æ±‚ç”Ÿæˆæ–¹å¼**
- è¯·æ±‚é€Ÿç‡æœä»å¹‚å¾‹åˆ†å¸ƒï¼ˆpower-law distributionï¼‰ï¼ŒæŒ‡æ•°å‚æ•° Î± æ§åˆ¶çªå‘ç¨‹åº¦ï¼ˆÎ±=0.5 è¡¨ç¤ºæ›´çªå‘ï¼‰ã€‚
- è¯·æ±‚æ€»é‡ç”± RPSï¼ˆRequests Per Secondï¼‰æ§åˆ¶ã€‚

---

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **TTFT**ï¼ˆTime-to-First-Tokenï¼‰ | ä»æäº¤è¯·æ±‚åˆ°æ”¶åˆ°ç¬¬ä¸€ä¸ªè¾“å‡º token çš„ç«¯åˆ°ç«¯å»¶è¿Ÿ |
| **TPOT**ï¼ˆTime-Per-Output-Tokenï¼‰ | ç”Ÿæˆåç»­æ¯ä¸ª token çš„å¹³å‡è€—æ—¶ |
| **Prewarming Hit Ratio** | æˆåŠŸä»é¢„çƒ­çŠ¶æ€å¯åŠ¨å®ä¾‹çš„æ¯”ä¾‹ |
| **Prediction Accuracy** | å·¥ä½œè´Ÿè½½é¢„æµ‹çš„ç›¸å¯¹è¯¯å·®ï¼ˆRelative Errorï¼‰ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿ | æè¿° |
|------|------|
| **SLLM-GPU**ï¼ˆServerlessLLM-GPUï¼‰ | åŸºäºç¼“å­˜æœºåˆ¶çš„ autoscaling ç³»ç»Ÿï¼Œåœ¨ GPU ä¸­ä¿ç•™å·²å¸è½½æ¨¡å‹çš„æƒé‡ |
| **MuxServe** | GPU sharing ç³»ç»Ÿï¼Œæ”¯æŒæ—¶ç©ºå¤ç”¨ï¼Œä½¿ç”¨ CUDA MPS éš”ç¦»ä»»åŠ¡ |
| **WarmServe w/o Proac.** | WarmServe å…³é—­ä¸»åŠ¨é¢„çƒ­åŠŸèƒ½çš„å˜ä½“ï¼ˆæ¶ˆèå®éªŒï¼‰ |

> æ‰€æœ‰ç³»ç»Ÿå‡åŸºäº vLLM å®ç°ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### ğŸ”¹ **é¢„çƒ­æ•ˆæœåˆ†æï¼ˆFig. 8ï¼‰**
- æˆåŠŸé¢„çƒ­ä¸‹ï¼ŒWarmServe å¯å°† **TTFT ç¼©çŸ­ 29.8Ã—â€“54.8Ã—**ã€‚
- å¯¹äº Llama2-70B æ¨¡å‹ï¼Œé¦–æ¬¡ token ç”Ÿæˆå¯åœ¨ **~665ms** å†…å®Œæˆï¼ˆåŸç³»ç»Ÿ >30sï¼‰ã€‚

#### ğŸ”¹ **ç«¯åˆ°ç«¯ TTFT æ€§èƒ½ï¼ˆFig. 9 & 10ï¼‰**
- åœ¨ RPS=25, Î±=0.5 åœºæ™¯ä¸‹ï¼š
  - WarmServe ç›¸æ¯” SLLM-GPUï¼š
    - **P95 TTFT æœ€å¤šé™ä½ 10.06Ã—**
    - **P99 TTFT æœ€å¤šé™ä½ 50.79Ã—ï¼ˆâ‰ˆ50.8Ã—ï¼‰**
  - ç›¸æ¯”è‡ªèº«å…³é—­ä¸»åŠ¨é¢„çƒ­ç‰ˆæœ¬ï¼Œå°¾éƒ¨å»¶è¿Ÿé™ä½ **1.03Ã—â€“32.87Ã—**

#### ğŸ”¹ **ååèƒ½åŠ›å¯¹æ¯”**
- WarmServe èƒ½å¤„ç† **æœ€å¤š 2.5Ã— æ›´å¤šè¯·æ±‚** è€Œä¸é€ æˆä¸¥é‡æ’é˜Ÿï¼Œè¿œè¶… MuxServeã€‚

#### ğŸ”¹ **é¢„çƒ­å‘½ä¸­ç‡ï¼ˆFig. 11ï¼‰**
- åœ¨è½»è´Ÿè½½ä¸‹å‘½ä¸­ç‡æ¥è¿‘ 100%
- å³ä½¿åœ¨ RPS=25 çš„é«˜å‹åœºæ™¯ä¸‹ï¼Œå¹³å‡å‘½ä¸­ç‡ä»è¾¾ **82%**

#### ğŸ”¹ **æ¨ç†æ€§èƒ½ï¼ˆTPOTï¼‰**
- MuxServe å› å…±äº«å¯¼è‡´æ€§èƒ½ä¸‹é™æ˜æ˜¾ï¼š
  - åœ¨ RPS=25 ä¸‹ï¼Œè¶…è¿‡ 40% è¯·æ±‚çš„ TPOT >100ms
  - WarmServe è¶…è¿‡ 60% è¯·æ±‚ TPOT <50ms
- å›¾ 15 æ˜¾ç¤ºï¼ŒMuxServe å¹³å‡ TPOT æ˜¯ WarmServe çš„ **3.26Ã—**

#### ğŸ”¹ **å·¥ä½œè´Ÿè½½é¢„æµ‹å‡†ç¡®æ€§ï¼ˆFig. 16ï¼‰**
- ä½¿ç”¨ CSPï¼ˆCorrective Seasonal Predictorï¼‰è¿›è¡Œ 5 åˆ†é’Ÿçª—å£é¢„æµ‹ï¼š
  - **å¹³å‡è´Ÿè½½é¢„æµ‹è¯¯å·®ï¼š5.25%**
  - **å³°å€¼è´Ÿè½½é¢„æµ‹è¯¯å·®ï¼š7.34%**
- åœ¨æ›´éš¾é¢„æµ‹çš„ AzureCode ä¸Šï¼Œè¯¯å·®åˆ†åˆ«ä¸º 9.58% å’Œ 11.16%ï¼Œä½†ä»è¶³å¤ŸæŒ‡å¯¼é¢„çƒ­å†³ç­–ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

| è®¾ç½® | ç»“æœå½±å“ |
|------|---------|
| **ç¦ç”¨ Evict-Aware Placement** | å¯¼è‡´ 0.29Ã— æ›´å°‘è¯·æ±‚åœ¨ 100ms å†…è·å¾—é¦– token |
| **ç¦ç”¨ Proactive Prewarming** | å¯¼è‡´ 0.88Ã— æ›´å°‘è¯·æ±‚åœ¨ 100ms å†…è·å¾—é¦– token |
| **çª—å£å¤§å° W=3min / 40min** | æ€§èƒ½åˆ†åˆ«ä»…ä¸ºé»˜è®¤ï¼ˆ5minï¼‰çš„ 0.46Ã— å’Œ 0.30Ã— |
| **W=10min** | æ€§èƒ½ä¸ 5min ç›¸å½“ï¼ˆ1.02Ã—ï¼‰ï¼Œè¯´æ˜ç³»ç»Ÿå¯¹çª—å£é€‰æ‹©å…·æœ‰ä¸€å®šé²æ£’æ€§ |

> è¯æ˜ä¸¤ä¸ªæ ¸å¿ƒæœºåˆ¶éƒ½è‡³å…³é‡è¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **LLM å·¥ä½œè´Ÿè½½å…·æœ‰é«˜åº¦å‘¨æœŸæ€§å’Œé•¿æœŸå¯é¢„æµ‹æ€§**ï¼Œå¯ç”¨äºæŒ‡å¯¼èµ„æºé¢„é…ç½®ã€‚
2. **One-for-Many GPU Prewarming æ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„**ï¼Œèƒ½åœ¨ä¸ç‰ºç‰²æ¨ç†æ€§èƒ½çš„å‰æä¸‹å¤§å¹…é™ä½ TTFTã€‚
3. **Universal GPU Workers è®¾è®¡æœ‰æ•ˆæå‡äº†é¢„çƒ­èµ„æºçš„å¤ç”¨ç‡**ï¼Œæ˜¾è‘—å‡å°‘æ‰€éœ€é¢„ç•™ GPU æ•°é‡ã€‚
4. **Proactive Prewarming åˆ©ç”¨äº† grace period çš„é—²ç½®èµ„æº**ï¼Œè§£å†³äº†â€œæ¥ä¸åŠé¢„çƒ­â€çš„éš¾é¢˜ã€‚
5. **Evict-Aware Placement æ˜¾è‘—é™ä½äº†é¢„çƒ­å¹²æ‰°**ï¼Œæé«˜äº†æ•´ä½“é¢„çƒ­æˆåŠŸç‡ã€‚
6. **WarmServe åœ¨ä¿æŒç‹¬å  GPU æ¨ç†ä¼˜åŠ¿çš„åŒæ—¶ï¼Œå…¼å…·é«˜èµ„æºåˆ©ç”¨ç‡å’Œä½å»¶è¿Ÿå“åº”èƒ½åŠ›**ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ–å†å²æ•°æ®çš„å‘¨æœŸæ€§å‡è®¾**ï¼šè‹¥å·¥ä½œè´Ÿè½½çªå˜æˆ–ç¼ºä¹è§„å¾‹ï¼ˆå¦‚çªå‘äº‹ä»¶ï¼‰ï¼Œé¢„æµ‹å¤±æ•ˆä¼šå½±å“é¢„çƒ­æ•ˆæœã€‚
2. **å¤§è§„æ¨¡é›†ç¾¤æ‰©å±•æ€§å¾…éªŒè¯**ï¼šå½“å‰å®éªŒä»…åœ¨åŒèŠ‚ç‚¹ 16 GPU è§„æ¨¡æµ‹è¯•ï¼Œæ›´å¤§è§„æ¨¡ä¸‹çš„åè°ƒå¼€é”€æœªå……åˆ†è¯„ä¼°ã€‚
3. **æ¨¡å‹è¶Šå¤§è¶Šéš¾é¢„çƒ­**ï¼šè™½ç„¶åªé¢„çƒ­å‰å‡ å±‚ï¼Œä½†å¯¹äºåƒäº¿çº§ä»¥ä¸Šæ¨¡å‹ï¼Œä»å¯èƒ½å—é™äº PCIe å¸¦å®½å’Œå†…å­˜å®¹é‡ã€‚
4. **æœªè€ƒè™‘å¼‚æ„ç¡¬ä»¶ç¯å¢ƒ**ï¼šå‡è®¾æ‰€æœ‰ GPU åŒæ„ï¼Œå®é™…éƒ¨ç½²ä¸­å¯èƒ½å­˜åœ¨æ··åˆå‹å·é—®é¢˜ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **ç»“åˆåœ¨çº¿å­¦ä¹ ä¼˜åŒ–é¢„æµ‹å™¨**ï¼šé‡‡ç”¨ LSTMã€Transformer ç­‰æ·±åº¦æ¨¡å‹è¿›ä¸€æ­¥æå‡è´Ÿè½½é¢„æµ‹ç²¾åº¦ã€‚
2. **æ”¯æŒè·¨æœåŠ¡å™¨é¢„çƒ­**ï¼šæ¢ç´¢åˆ†å¸ƒå¼é¢„çƒ­æœºåˆ¶ï¼Œæ‰“ç ´å•æœºå†…å­˜é™åˆ¶ã€‚
3. **ç»†ç²’åº¦åˆ†å±‚é¢„çƒ­ç­–ç•¥**ï¼šæ ¹æ®ä¸åŒå±‚è®¡ç®—ç‰¹æ€§å†³å®šé¢„çƒ­é¡ºåºå’ŒèŒƒå›´ã€‚
4. **é›†æˆæˆæœ¬æ¨¡å‹**ï¼šåœ¨äº‘ç¯å¢ƒä¸­å¹³è¡¡é¢„çƒ­å¸¦æ¥çš„èƒ½è€—/æˆæœ¬ä¸ç”¨æˆ·ä½“éªŒå¢ç›Šã€‚
5. **é€‚é… MoE æ¶æ„**ï¼šç ”ç©¶ç¨€ç–æ¿€æ´»æ¨¡å‹ä¸‹çš„é¢„çƒ­ç­–ç•¥ï¼Œä»…é¢„çƒ­å¸¸ç”¨ä¸“å®¶æ¨¡å—ã€‚

---

## âœ… æ€»ç»“

**WarmServe** æ˜¯é¦–ä¸ªå°† **one-for-many prewarming** æ€æƒ³æˆåŠŸåº”ç”¨äºå¤šLLMæœåŠ¡ç³»ç»Ÿçš„æ–¹æ¡ˆã€‚å®ƒé€šè¿‡ **universal GPU workers + proactive prewarming + evict-aware placement + zero-overhead memory switching** å››å¤§æŠ€æœ¯æ”¯æŸ±ï¼Œåœ¨å‡ ä¹ä¸å½±å“æ¨ç†æ€§èƒ½çš„å‰æä¸‹ï¼Œå®ç°äº†é«˜è¾¾ **50.8Ã— çš„ TTFT æ”¹è¿›** å’Œ **2.5Ã— çš„ååæå‡**ï¼Œä¸ºæ„å»ºé«˜æ•ˆã€ä½å»¶è¿Ÿçš„å¤§è§„æ¨¡ LLM æœåŠ¡å¹³å°æä¾›äº†é‡è¦èŒƒå¼ã€‚

</details>

---

### 13. [Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning](https://arxiv.org/abs/2512.09706)

**Authors**: Kaichen He, Zihao Wang, Muyao Li, Anji Liu, Yitao Liang  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.09706v1  

#### Abstract
The paradigm of agentic AI is shifting from engineered complex workflows to post-training native models. However, existing agents are typically confined to static, predefined action spaces--such as exclusively using APIs, GUI events, or robotic commands. This rigidity limits their adaptability in dy...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰çš„ **Agentic AI** æ¨¡å‹é€šå¸¸è¢«é™åˆ¶åœ¨é™æ€ã€é¢„å®šä¹‰çš„ **action space** ä¸­ï¼Œä¾‹å¦‚ä»…ä½¿ç”¨ API è°ƒç”¨ã€GUI äº‹ä»¶æˆ–æœºå™¨äººæ§åˆ¶å‘½ä»¤ã€‚è¿™ç§åˆšæ€§è®¾è®¡å¯¼è‡´æ¨¡å‹åœ¨åŠ¨æ€ç¯å¢ƒä¸­é€‚åº”èƒ½åŠ›å·®ï¼Œæ— æ³•æ ¹æ®ä»»åŠ¡ä¸Šä¸‹æ–‡çµæ´»é€‰æ‹©æœ€ä¼˜äº¤äº’ç²’åº¦ã€‚

æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äººå·¥è®¾è®¡çš„è§„åˆ™æ¥åˆ‡æ¢ä¸åŒ action spaceï¼Œç¼ºä¹è‡ªä¸»å†³ç­–èƒ½åŠ›ï¼Œä¸”éš¾ä»¥æ³›åŒ–åˆ°å¤æ‚ã€é•¿å‘¨æœŸçš„ä»»åŠ¡ä¸­ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **CrossAgent**ï¼Œä¸€ä¸ªç»Ÿä¸€çš„åŸç”Ÿæ™ºèƒ½ä½“æ¨¡å‹ï¼Œèƒ½å¤Ÿï¼š

- **æŒæ¡å¼‚æ„ action spaces**ï¼ˆheterogeneous action spacesï¼‰ï¼Œå¦‚ Motionã€Groundingã€Raw ç­‰ï¼›
- **è‡ªä¸»é€‰æ‹©æ¯ä¸€æ­¥æœ€åˆé€‚çš„ action space**ï¼Œæ— éœ€äººå·¥æŒ‡å®šè§„åˆ™ï¼›
- åœ¨å•ä¸ªè½¨è¿¹ä¸­å®ç°è·¨å±‚çº§åŠ¨ä½œåˆ‡æ¢ï¼Œå¹³è¡¡é«˜å±‚æ•ˆç‡ä¸åº•å±‚ç²¾åº¦ã€‚

ä¸ºæ­¤ï¼Œä½œè€…è®¾è®¡äº†ä¸€ä¸ªä¸‰é˜¶æ®µè®­ç»ƒæµæ°´çº¿ï¼š

1. **Cold-Start Supervised Fine-Tuning (SFT)**  
   åœ¨æ··åˆå¤š action space æ•°æ®ä¸Šè¿›è¡Œç›‘ç£å¾®è°ƒï¼Œä½¿æ¨¡å‹å…·å¤‡è§£ç å¤šç§åŠ¨ä½œçš„èƒ½åŠ›ã€‚

2. **Single-Turn Reinforcement Learning (STRL)**  
   ä½¿ç”¨ **Group Relative Policy Optimization (GRPO)** ç®—æ³•ä¼˜åŒ–å•æ­¥åŠ¨ä½œç©ºé—´é€‰æ‹©ç­–ç•¥ï¼Œé¼“åŠ±æ¨¡å‹é€‰æ‹©èƒ½æ­£ç¡®æ‰§è¡Œä»»åŠ¡çš„åŠ¨ä½œå½¢å¼ã€‚

3. **Multi-Turn Reinforcement Learning (MTRL)**  
   è¿›ä¸€æ­¥ä¼˜åŒ–æ•´ä¸ªä»»åŠ¡è½¨è¿¹çš„æˆåŠŸç‡ï¼Œå¹¶å¼•å…¥ token æˆæœ¬æƒ©ç½šé¡¹ $ \lambda \cdot l_e(t) $ï¼Œä¿ƒä½¿æ¨¡å‹ä¼˜å…ˆé€‰æ‹©é«˜æ•ˆç®€æ´çš„åŠ¨ä½œç©ºé—´ï¼ˆå¦‚é«˜é˜¶ APIï¼‰è€Œéå†—é•¿çš„åŸå§‹æŒ‡ä»¤ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | CrossAgent |
|------|--------|-----------|
| **Action Space è®¾è®¡** | å›ºå®šå•ä¸€ç©ºé—´ï¼ˆå¦‚ä»… GUI æˆ–ä»… APIï¼‰ | åŠ¨æ€åˆ‡æ¢å¤šä¸ªå¼‚æ„ç©ºé—´ |
| **åˆ‡æ¢æœºåˆ¶** | æ‰‹å·¥è§„åˆ™æˆ–æµç¨‹ç¼–æ’ | è‡ªä¸»å­¦ä¹ ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥ |
| **è®­ç»ƒæ–¹å¼** | å¤šä¸º SFT æˆ–ç®€å• RL | åˆ†é˜¶æ®µå¼ºåŒ–å­¦ä¹ ï¼ˆSTRL + MTRLï¼‰ |
| **æ³›åŒ–èƒ½åŠ›** | å±€é™äºç‰¹å®šä»»åŠ¡ç±»åˆ« | åœ¨ >800 ä¸ªæœªè§ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ |
| **æ•ˆç‡ä¸é²æ£’æ€§** | é«˜å±‚åŠ¨ä½œå¯èƒ½å¤±è´¥ï¼Œä½å±‚åŠ¨ä½œæ•ˆç‡ä½ | è‡ªåŠ¨æƒè¡¡â€œæˆåŠŸç‡â€ä¸â€œæ‰§è¡Œæˆæœ¬â€ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šå°† action space çš„é€‰æ‹©æœ¬èº«ä½œä¸ºå¯å­¦ä¹ çš„éƒ¨åˆ†ï¼Œè€Œéå›ºå®šçº¦æŸã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **ç¯å¢ƒå¹³å°**ï¼š`Minecraft`ï¼ˆç‰ˆæœ¬ 1.16.5ï¼‰ï¼Œé€šè¿‡ `MineRL` æ¡†æ¶æä¾›åŸºäºå›¾åƒçš„è§‚å¯Ÿè¾“å…¥ï¼ˆRGB 640Ã—360ï¼‰å’Œé”®ç›˜/é¼ æ ‡æ§åˆ¶æ¥å£ã€‚
- **åŸºå‡†æµ‹è¯•å¥—ä»¶**ï¼š`OpenHA benchmark`ï¼ŒåŒ…å« **è¶…è¿‡ 800 ä¸ªæ‰‹åŠ¨è®¾è®¡å¹¶éªŒè¯çš„ä»»åŠ¡**ï¼Œæ¶µç›–ä¸‰å¤§ç±»ï¼š
  - **Mine Blocks**ï¼šèµ„æºé‡‡é›†ç±»ä»»åŠ¡ï¼ˆå¦‚ç æ ‘ï¼‰
  - **Kill Entities**ï¼šæˆ˜æ–—ç”Ÿå­˜ç±»ä»»åŠ¡ï¼ˆå¦‚æ€ç¾Šï¼‰
  - **Craft Items**ï¼šGUI å¯†é›†å‹åˆæˆä»»åŠ¡ï¼ˆå¦‚åˆ¶ä½œé™„é­”å°ï¼‰

- **è®­ç»ƒæ•°æ®**ï¼š
  - åˆå§‹ SFT ä½¿ç”¨æ··åˆ action space æ•°æ®é›† `D_mix`ï¼Œç»“åˆ VPT æ•°æ®ä¸äººå·¥æ ‡æ³¨è½¨è¿¹ï¼›
  - MTRL é˜¶æ®µä»…ä½¿ç”¨ **30 ä¸ªè®­ç»ƒä»»åŠ¡**ï¼ˆæ¯ç±» 10 ä¸ªï¼‰ï¼Œç”¨äºåœ¨çº¿ RL å¾®è°ƒã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Finished Tasks (FT)** â†‘ | è‡³å°‘æˆåŠŸå®Œæˆä¸€æ¬¡çš„ä»»åŠ¡æ¯”ä¾‹ï¼Œè¡¡é‡è¦†ç›–å¹¿åº¦ |
| **Average Success Rate (ASR)** â†‘ | æ‰€æœ‰ä»»åŠ¡ä¸Šçš„å¹³å‡æˆåŠŸç‡ï¼Œåæ˜ ç¨³å®šæ€§ |
| **Success Rate on ID/OOD Tasks** | åŒºåˆ†è®­ç»ƒå†…ï¼ˆIn-Distributionï¼‰ä¸åˆ†å¸ƒå¤–ï¼ˆOut-of-Distributionï¼‰æ€§èƒ½ï¼Œæ£€éªŒæ³›åŒ–èƒ½åŠ› |

#### **è®­ç»ƒé…ç½®**

- **åŸºç¡€æ¨¡å‹**ï¼š`Qwen2-VL-7B-Instruct`ï¼Œå…·å¤‡å¼ºå¤§è§†è§‰è¯­è¨€ç†è§£èƒ½åŠ›ã€‚
- **è®­ç»ƒç¡¬ä»¶**ï¼š8Ã—NVIDIA A800-SXM4-80GB GPU
- **ä¼˜åŒ–å™¨**ï¼šAdamW
- **RL ç®—æ³•**ï¼š**GRPO**ï¼ˆGroup Relative Policy Optimizationï¼‰ï¼Œæ— éœ€ä»·å€¼ç½‘ç»œï¼Œåˆ©ç”¨ç»„å†…ç›¸å¯¹è¡¨ç°ä¼°è®¡ä¼˜åŠ¿å‡½æ•°ï¼Œæ›´ç¨³å®šé«˜æ•ˆã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| ç±»åˆ« | åŸºçº¿æ¨¡å‹ |
|------|--------|
| **å• action space æ¨¡å‹** | `RawHA`, `MotionHA`, `GroundingHA`, `LatentHA`, `LanguageHA` |
| **Hierarchical Agent** | `OpenHA`, `UI-TARS-1.5`, `Game-TARS` |
| **ä¸“ç”¨ç­–ç•¥æ¨¡å‹** | `VPT`, `ROCKET-1`, `STEVE-1`, `JARVIS-VLA` |

è¿™äº›åŸºçº¿è¦ä¹ˆå±€é™äºæŸä¸€ action spaceï¼Œè¦ä¹ˆé‡‡ç”¨å›ºå®šç»“æ„ç»„åˆï¼Œç¼ºä¹åŠ¨æ€é€‚åº”èƒ½åŠ›ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰**

| æ–¹æ³• | Mine Blocks (ASR) | Kill Entities (ASR) | Craft Items (ASR) | All Tasks (ASR) |
|------|------------------|--------------------|------------------|----------------|
| **VPT** | 6.0Â±11.4 | 3.6Â±7.7 | 0.8Â±3.3 | 3.5Â±8.4 |
| **ROCKET-1** | 18.9Â±24.3 | 27.9Â±29.3 | 0.0Â±0.0 | 15.6Â±24.9 |
| **JARVIS-VLA** | 30.0Â±35.4 | 18.5Â±22.7 | 25.1Â±23.9 | 24.5Â±28.4 |
| **OpenHA** | 30.1Â±13.9 | 32.5Â±9.2 | 31.9Â±13.7 | 31.5Â±12.5 |
| **CrossAgent (w/o STRL)** | 39.0Â±46.5 | 27.7Â±43.9 | 58.0Â±48.4 | 41.6Â±47.9 |
| **CrossAgent (ours)** | **40.0Â±48.3** | **45.1Â±43.5** | **78.8Â±41.0** | **54.6Â±47.6** |

> ğŸ”´ è¡¨ç¤º SOTAï¼ŒğŸ”µ è¡¨ç¤ºç¬¬äºŒå¥½ï¼›CrossAgent åœ¨æ‰€æœ‰ç±»åˆ«å‡è¾¾åˆ°æˆ–æ¥è¿‘æœ€ä½³ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- CrossAgent æ˜¾è‘—ä¼˜äºæ‰€æœ‰å• action space åŸºçº¿ï¼Œå°¤å…¶åœ¨ **Craft Items** ä¸Šæå‡æ˜æ˜¾ï¼ˆ+47% ASR vs OpenHAï¼‰ã€‚
- ç›¸æ¯”æœ€å¼ºçš„ hierarchical agentï¼ˆå¦‚ OpenHAï¼‰ï¼ŒCrossAgent åœ¨ **Kill Entities** å’Œ **Craft Items** ä¸Šåˆ†åˆ«æå‡ **12.6%** å’Œ **46.9%** çš„ ASRã€‚
- å°½ç®¡åªåœ¨ **30 ä¸ªä»»åŠ¡ä¸Šè¿›è¡Œ RL å¾®è°ƒ**ï¼Œå´èƒ½åœ¨ **800+ ä¸ª OOD ä»»åŠ¡ä¸Šæ³›åŒ–è‰¯å¥½**ï¼Œè¯æ˜å…¶å¼ºå¤§çš„è¿ç§»èƒ½åŠ›ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **(1) æ˜¯å¦åŒ…å« STRL é˜¶æ®µçš„å½±å“ï¼ˆFigure 4 & Table 1ï¼‰**

- ç§»é™¤ STRL é˜¶æ®µåï¼ˆå³ç›´æ¥ä» SFT è¿›å…¥ MTRLï¼‰ï¼Œè®­ç»ƒæ”¶æ•›é€Ÿåº¦å˜æ…¢ï¼Œæœ€ç»ˆæ€§èƒ½ä¸‹é™æ˜¾è‘—ï¼š
  - Craft Items ASR ä» **78.8% â†’ 58.0%**
  - All Tasks ASR ä» **54.6% â†’ 41.6%**
- ç»“è®ºï¼š**STRL æ˜¯æœ‰æ•ˆçš„â€œçƒ­å¯åŠ¨â€æœºåˆ¶**ï¼Œå¸®åŠ©æ¨¡å‹å»ºç«‹åˆæ­¥çš„ action space åå¥½ï¼ŒåŠ é€Ÿåç»­ MTRL æ”¶æ•›ã€‚

#### **(2) æ˜¯å¦ä½¿ç”¨æ··åˆ action spaceï¼ˆFigure 3ï¼‰**

- å¯¹æ¯”ä»…ä½¿ç”¨ `GroundingHA` æˆ– `MotionHA` å­é›†è®­ç»ƒçš„æ¨¡å‹ï¼š
  - CrossAgent æ”¶æ•›æ›´å¿«ã€æœ€ç»ˆæˆåŠŸç‡æ›´é«˜ï¼›
  - å• space æ¨¡å‹å®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œæ— æ³•åº”å¯¹å¤šæ ·åŒ–ä»»åŠ¡éœ€æ±‚ã€‚
- ç»“è®ºï¼š**å¼‚æ„ action space æä¾›æ›´å¤§çµæ´»æ€§ï¼Œæå‡æ•°æ®æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›**ã€‚

#### **(3) OOD æ³›åŒ–èƒ½åŠ›åˆ†æï¼ˆTable 2ï¼‰**

| æ–¹æ³• | Craft Items (OOD) | All Tasks (OOD) |
|------|------------------|----------------|
| RawHA-RL | 69.8Â±44.4 | 42.4Â±45.1 |
| GroundingHA-RL | 57.2Â±48.1 | 39.4Â±44.3 |
| **CrossAgent (w/o STRL)** | 58.0Â±48.4 | 39.7Â±48.1 |
| **CrossAgent (full)** | **78.8Â±41.0** | **49.1Â±46.6** |

- CrossAgent åœ¨ OOD ä»»åŠ¡ä¸Šä»ä¿æŒé«˜æˆåŠŸç‡ï¼Œè€Œå…¶ä»– RL æ¨¡å‹å‡ºç°ä¸¥é‡è¿‡æ‹Ÿåˆï¼ˆID é«˜ä½† OOD ä½ï¼‰ï¼›
- **CrossAgent çš„ generalization gap æ›´å°**ï¼Œè¯´æ˜å…¶å­¦åˆ°çš„æ˜¯é€šç”¨ç­–ç•¥è€Œéè®°å¿†è®­ç»ƒä»»åŠ¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **åŠ¨æ€ action space åˆ‡æ¢æ˜¯æå‡ agentic æ¨¡å‹æ€§èƒ½çš„å…³é”®**ï¼š  
   CrossAgent èƒ½æ ¹æ®ä»»åŠ¡é˜¶æ®µè‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„äº¤äº’ç²’åº¦ï¼ˆå¦‚æ¢ç´¢æ—¶ç”¨ Motionï¼Œäº¤äº’æ—¶ç”¨ Grounding æˆ– Rawï¼‰ï¼Œä»è€Œå…¼é¡¾æ•ˆç‡ä¸ç²¾åº¦ã€‚

2. âœ… **å¼ºåŒ–å­¦ä¹ ï¼ˆå°¤å…¶æ˜¯ MTRLï¼‰å¯¹ OOD æ³›åŒ–è‡³å…³é‡è¦**ï¼š  
   å°½ç®¡ RL å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œä½†åœ¨åˆç†è®¾è®¡å¥–åŠ±å‡½æ•°ï¼ˆæˆåŠŸç‡ + æˆæœ¬æƒ©ç½šï¼‰ä¸‹ï¼Œåè€Œèƒ½ä¿ƒè¿›ç­–ç•¥æŠ½è±¡å’Œè¿ç§»ã€‚

3. âœ… **STRL é˜¶æ®µè™½è½»é‡ä½†ä¸å¯æˆ–ç¼º**ï¼š  
   å®ƒä¸º MTRL æä¾›äº†ä¸€ä¸ªé«˜è´¨é‡çš„åˆå§‹ç­–ç•¥åˆ†å¸ƒï¼Œé¿å…ç›²ç›®æ¢ç´¢ï¼Œæ˜¾è‘—æå‡è®­ç»ƒæ•ˆç‡ã€‚

4. âœ… **CrossAgent å±•ç°å‡ºç±»äººè¡Œä¸ºæ¨¡å¼**ï¼š  
   æ¡ˆä¾‹ç ”ç©¶è¡¨æ˜å…¶åŠ¨ä½œåˆ‡æ¢å…·æœ‰è¯­ä¹‰è¿è´¯æ€§ï¼Œä¾‹å¦‚â€œå¯¼èˆªâ†’æ¥è¿‘â†’äº¤äº’â€ä¸‰é˜¶æ®µä¸­é€æ­¥ç»†åŒ–æ§åˆ¶æ–¹å¼ï¼Œæ¨¡ä»¿äººç±»æ“ä½œé€»è¾‘ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **è®¡ç®—å¼€é”€å¤§**ï¼š  
   MTRL éœ€è¦å¤§é‡åœ¨çº¿ç¯å¢ƒäº¤äº’ï¼ˆ>80 è½®è¿­ä»£ï¼Œæ¯è½® >6,400 æ¬¡äº¤äº’ï¼‰ï¼Œè®­ç»ƒæˆæœ¬è¾ƒé«˜ã€‚

2. **ä¾èµ–é«˜è´¨é‡è§£æå™¨ `g(Â·)`**ï¼š  
   åŠ¨ä½œè¯­ä¹‰ä¸€è‡´æ€§åˆ¤æ–­ä¾èµ–äºç¡®å®šæ€§ parserï¼Œè‹¥ parser ä¸å‡†ç¡®ä¼šå½±å“ STRL æ•ˆæœã€‚

3. **å°šæœªè¿ç§»åˆ°ç‰©ç†ä¸–ç•Œ**ï¼š  
   å½“å‰å®éªŒå…¨éƒ¨åœ¨ Minecraft ä¸­å®Œæˆï¼ŒçœŸå®æœºå™¨äººåœºæ™¯é¢ä¸´å®‰å…¨ã€å»¶è¿Ÿç­‰æŒ‘æˆ˜ã€‚

4. **action space æ•°é‡æœ‰é™**ï¼š  
   å½“å‰æ”¯æŒ 3â€“5 ç§é¢„å®šä¹‰ç©ºé—´ï¼Œæœªæ¥éœ€ç ”ç©¶å¦‚ä½•è‡ªåŠ¨å‘ç°æˆ–ç”Ÿæˆæ–°çš„ action abstractionã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. æ¢ç´¢æ›´é«˜æ•ˆçš„ RL ç®—æ³•ï¼ˆå¦‚ offline RL æˆ– sample-efficient RLï¼‰ä»¥é™ä½è®­ç»ƒæˆæœ¬ï¼›
2. å°† CrossAgent æ¶æ„è¿ç§»åˆ°çœŸå®æœºå™¨äººç³»ç»Ÿï¼Œè§£å†³ sim-to-real gapï¼›
3. å¼•å…¥è‡ªç›‘ç£å­¦ä¹ è‡ªåŠ¨æ„å»º latent action spaceï¼Œå‡å°‘äººå·¥è®¾è®¡ï¼›
4. æ‰©å±•è‡³å¤šæ¨¡æ€å·¥å…·è°ƒç”¨ï¼ˆAPI + GUI + Robotï¼‰çš„é€šç”¨è®¡ç®—æœºåŠ©æ‰‹ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> CrossAgent é¦–æ¬¡å®ç°äº†åœ¨ä¸€ä¸ªç»Ÿä¸€æ¨¡å‹ä¸­**è‡ªä¸»å­¦ä¹ ä½•æ—¶ä½¿ç”¨ä½•ç§ç²’åº¦çš„åŠ¨ä½œç©ºé—´**ï¼Œå¹¶é€šè¿‡ä¸‰é˜¶æ®µ RL è®­ç»ƒæ¡†æ¶ï¼Œåœ¨ Minecraft ä¸­å®ç°äº† SOTA æ€§èƒ½ä¸å“è¶Šçš„ OOD æ³›åŒ–èƒ½åŠ›ï¼Œæ ‡å¿—ç€å‘çœŸæ­£é€šç”¨æ™ºèƒ½ä½“è¿ˆå‡ºå…³é”®ä¸€æ­¥ã€‚

</details>

---

### 14. [Closing the Train-Test Gap in World Models for Gradient-Based Planning](https://arxiv.org/abs/2512.09929)

**Authors**: Arjun Parthasarathy, Nimit Kalra, Rohun Agrawal, Yann LeCun, Oumayma Bounou, Pavel Izmailov, Micah Goldblum  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.09929v1  

#### Abstract
World models paired with model predictive control (MPC) can be trained offline on large-scale datasets of expert trajectories and enable generalization to a wide range of planning tasks at inference time. Compared to traditional MPC procedures, which rely on slow search algorithms or on iteratively ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šClosing the Train-Test Gap in World Models for Gradient-Based Planning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**ä¸–ç•Œæ¨¡å‹ï¼ˆWorld Modelsï¼‰åœ¨æ¢¯åº¦è§„åˆ’ï¼ˆGradient-Based Planning, GBPï¼‰ä¸­çš„è®­ç»ƒ-æµ‹è¯•ä¸ä¸€è‡´é—®é¢˜ï¼ˆtrain-test gapï¼‰**ã€‚å…·ä½“è¡¨ç°ä¸ºï¼š
- **è®­ç»ƒç›®æ ‡**ï¼šä¸–ç•Œæ¨¡å‹é€šå¸¸ä»¥â€œä¸‹ä¸€çŠ¶æ€é¢„æµ‹â€ä¸ºç›®æ ‡ï¼Œåœ¨ä¸“å®¶è½¨è¿¹æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚
- **æµ‹è¯•ç”¨é€”**ï¼šåœ¨æ¨ç†æ—¶å´ç”¨äºä¼˜åŒ–åŠ¨ä½œåºåˆ—ä»¥è¾¾æˆç›®æ ‡ï¼Œå³è§£å†³ä¸€ä¸ªåŸºäºæ¨¡å‹çš„è§„åˆ’é—®é¢˜ã€‚

è¿™ç§ç›®æ ‡é”™é…å¯¼è‡´ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š
1. **åˆ†å¸ƒå¤–è¯¯å·®ç´¯ç§¯**ï¼šGBP åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­å¯èƒ½ç”Ÿæˆè®­ç»ƒæ•°æ®åˆ†å¸ƒä¹‹å¤–çš„åŠ¨ä½œåºåˆ—ï¼Œä½¿æ¨¡å‹è¿›å…¥æœªè§è¿‡çš„çŠ¶æ€åŒºåŸŸï¼Œé¢„æµ‹è¯¯å·®è¿…é€Ÿç´¯ç§¯ã€‚
2. **éå…‰æ»‘ä¼˜åŒ–æ™¯è§‚**ï¼šç”±ä¸–ç•Œæ¨¡å‹è¯±å¯¼çš„åŠ¨ä½œæŸå¤±æ›²é¢å¯èƒ½å­˜åœ¨å¤§é‡å±€éƒ¨æå°å€¼æˆ–å¹³å¦åŒºåŸŸï¼Œé˜»ç¢æœ‰æ•ˆçš„æ¢¯åº¦ä¼˜åŒ–ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡ºä¸¤ç§æ–°çš„å¾®è°ƒç­–ç•¥ï¼š

#### âœ… **Online World Modeling (OWM)**
- **æ€æƒ³**ï¼šå€Ÿé‰´ DAgger æ€è·¯ï¼Œé€šè¿‡åœ¨çº¿äº¤äº’æ‰©å±•è®­ç»ƒæ•°æ®ã€‚
- **æµç¨‹**ï¼š
  1. ä½¿ç”¨ GBP ç”ŸæˆåŠ¨ä½œåºåˆ—ï¼›
  2. å°†è¿™äº›åŠ¨ä½œåœ¨çœŸå®ç¯å¢ƒæ¨¡æ‹Ÿå™¨ä¸­æ‰§è¡Œï¼Œè·å¾—â€œä¿®æ­£è½¨è¿¹â€ï¼ˆcorrected trajectoryï¼‰ï¼›
  3. å°†ä¿®æ­£åçš„è½¨è¿¹åŠ å…¥è®­ç»ƒé›†å¹¶å¾®è°ƒä¸–ç•Œæ¨¡å‹ã€‚
- **ä½œç”¨**ï¼šè®©ä¸–ç•Œæ¨¡å‹å­¦ä¹ åˆ° GBP å®é™…è®¿é—®çš„çŠ¶æ€åŒºåŸŸï¼Œç¼“è§£åˆ†å¸ƒåç§»ã€‚

#### âœ… **Adversarial World Modeling (AWM)**
- **æ€æƒ³**ï¼šé€šè¿‡å¯¹æŠ—è®­ç»ƒå¢å¼ºæ¨¡å‹å¯¹æ‰°åŠ¨çš„é²æ£’æ€§ï¼Œå¹³æ»‘è¾“å…¥ç©ºé—´çš„æŸå¤±æ›²é¢ã€‚
- **æµç¨‹**ï¼š
  1. å¯¹çŠ¶æ€ $z_t$ å’ŒåŠ¨ä½œ $a_t$ æ–½åŠ æœ€å¤§åŒ–é¢„æµ‹è¯¯å·®çš„å°æ‰°åŠ¨ï¼ˆä½¿ç”¨ FGSMï¼‰ï¼›
  2. åœ¨è¿™äº›â€œå¯¹æŠ—æ ·æœ¬â€ä¸Šç»§ç»­è®­ç»ƒä¸–ç•Œæ¨¡å‹ã€‚
- **ä½œç”¨**ï¼šæå‡æ¨¡å‹åœ¨å…³é”®å†³ç­–è¾¹ç•Œé™„è¿‘çš„ç¨³å®šæ€§ï¼Œæ”¹å–„ GBP çš„æ”¶æ•›æ€§å’Œå¯é æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | GBP + AWM åœ¨æ€§èƒ½ä¸ŠåŒ¹é…ç”šè‡³è¶…è¶Š CEMï¼Œä½†è®¡ç®—æ—¶é—´å‡å°‘ **10å€ä»¥ä¸Š**ã€‚ |
| **æ³›åŒ–èƒ½åŠ›** | æ˜¾è‘—ç¼©å° train-test gapï¼Œæå‡é•¿æ—¶åŸŸè§„åˆ’çš„å‡†ç¡®æ€§ã€‚ |
| **é€šç”¨æ€§** | å¯åº”ç”¨äºå¤šç§ä¸–ç•Œæ¨¡å‹æ¶æ„ï¼ˆå¦‚ DINO-WMã€IRISï¼‰ï¼Œä¸ä¾èµ–ç‰¹å®šç»“æ„ã€‚ |
| **æ— éœ€é¢å¤–é‡‡æ ·** | ä¸åƒ CEM/MPPI éœ€è¦å¤§é‡ rolloutï¼ŒGBP ç›´æ¥åå‘ä¼ æ’­ä¼˜åŒ–åŠ¨ä½œã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸ä»»åŠ¡
æ‰€æœ‰å®éªŒåŸºäºä»¥ä¸‹ä¸‰ä¸ªæ§åˆ¶ä»»åŠ¡ï¼Œå‡ä»å›¾åƒè§‚æµ‹ä¸­å­¦ä¹ åŠ¨æ€æ¨¡å‹ï¼š

| ä»»åŠ¡ | æè¿° |
|------|------|
| **PushT** | æ§åˆ¶æœºæ¢°è‡‚æ¨åŠ¨ T å½¢ç‰©ä½“è‡³ç›®æ ‡ä½ç½®ï¼ˆæ“ä½œä»»åŠ¡ï¼‰ |
| **PointMaze** | æ§åˆ¶å°çƒåœ¨è¿·å®«ä¸­å¯¼èˆªè‡³ç›®æ ‡ç‚¹ï¼ˆå¯¼èˆªä»»åŠ¡ï¼‰ |
| **Wall** | åœ¨åŒæˆ¿é—´ç¯å¢ƒä¸­ç©¿é—¨å¯¼èˆªï¼ˆå¤æ‚è·¯å¾„è§„åˆ’ï¼‰ |

æ­¤å¤–è¿˜æµ‹è¯•äº†æ›´å¤æ‚çš„æ“ä½œä»»åŠ¡ï¼š
- **Rope**: æ¨åŠ¨ç»³å­åˆ°æŒ‡å®šå½¢çŠ¶
- **Granular**: æ¨åŠ¨é¢—ç²’ç¾¤å½¢æˆç›®æ ‡æ„å‹

> æ•°æ®æ¥æºï¼šå‡ä¸ºç¦»çº¿ä¸“å®¶æ¼”ç¤ºè½¨è¿¹ï¼ˆimitation learning datasetï¼‰ï¼Œæ¥è‡ª DINO-WM (Zhou et al., 2025)

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼šDINO-WM â€”â€” åŸºäº DINOv2 è§†è§‰ç¼–ç å™¨çš„æ½œå˜é‡ä¸–ç•Œæ¨¡å‹ï¼ˆlatent world modelï¼‰
- **ç¼–ç å™¨**ï¼šå†»ç»“çš„ DINOv2ï¼Œæå–å›¾åƒç‰¹å¾ä½œä¸º latent state $z$
- **è¿‡æ¸¡æ¨¡å‹**ï¼šViT æ¶æ„å»ºæ¨¡ $f_\theta(z_t, a_t) \rightarrow z_{t+1}$
- **è®­ç»ƒæ–¹å¼**ï¼šæœ€å°åŒ– latent space ä¸­çš„ $\ell_2$ é¢„æµ‹è¯¯å·®

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Success Rate (%)** | è§„åˆ’åŠ¨ä½œåºåˆ—èƒ½å¦æˆåŠŸåˆ°è¾¾ç›®æ ‡çŠ¶æ€ï¼ˆå¼€ç¯ / MPCï¼‰ |
| **Wall Clock Time** | å•æ¬¡è§„åˆ’è€—æ—¶ï¼ˆè¡¡é‡è®¡ç®—æ•ˆç‡ï¼‰ |
| **World Model Error (Training vs Planning)** | æ¯”è¾ƒæ¨¡å‹åœ¨ä¸“å®¶è½¨è¿¹ vs è§„åˆ’è½¨è¿¹ä¸Šçš„é¢„æµ‹è¯¯å·®å·®å¼‚ï¼Œåæ˜  train-test gap |
| **Chamfer Distance** | åœ¨ Rope/Granular ä¸Šè¡¡é‡å…³é”®ç‚¹é›†åˆä¹‹é—´çš„å‡ ä½•è·ç¦» |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æ˜¯å¦å¯å¾® |
|------|------|---------|
| **DINO-WM (Baseline)** | Latent world model + next-state prediction | æ˜¯ |
| **CEM (Cross-Entropy Method)** | æœç´¢å¼ã€æ¢¯åº¦è‡ªç”±è§„åˆ’å™¨ | å¦ |
| **MPPI** | åŸºäºé‡‡æ ·çš„éšæœºæœ€ä¼˜æ§åˆ¶ | å¦ |
| **GradCEM** | ç»“åˆæ¢¯åº¦æ›´æ–°çš„ CEM å˜ä½“ | æ˜¯ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| æ–¹æ³• | PushT (MPC) | PointMaze (MPC) | Wall (MPC) |
|------|-------------|------------------|------------|
| DINO-WM + CEM | 92% | 90% | 82% |
| **Adversarial WM + Adam GBP** | **92%** | **98%** | **94%** |
| **Speed-up** | â¬‡ï¸ >10Ã— faster than CEM | â¬‡ï¸ >10Ã— faster | â¬‡ï¸ >10Ã— faster |

> æ³¨ï¼šGBP ä½¿ç”¨ Adam ä¼˜åŒ–å™¨å³å¯è¾¾åˆ°æˆ–è¶…è¿‡ CEM æ€§èƒ½ï¼Œä¸”é€Ÿåº¦å¿«ä¸€ä¸ªæ•°é‡çº§ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **Open-loop è®¾ç½®ä¸‹**ï¼š
  - AWM å¹³å‡æå‡æˆåŠŸç‡ +18% ~ +30%
- **MPC è®¾ç½®ä¸‹**ï¼š
  - AWM è¶…è¶ŠåŸå§‹ DINO-WM + CEM åœ¨ PointMaze å’Œ Wall ä¸Šçš„è¡¨ç°
  - åœ¨ PushT ä¸ŠæŒå¹³ CEMï¼Œä½†é€Ÿåº¦æ˜¾è‘—æ›´å¿«
- **æ•ˆç‡æ–¹é¢**ï¼ˆFigure 3ï¼‰ï¼š
  - CEM éœ€æ•°ç™¾åˆ†é’Ÿå®Œæˆä¸€æ¬¡è§„åˆ’
  - GBP + AWM ä»…éœ€å‡ åˆ†é’Ÿå†…å®Œæˆï¼Œå®ç° **å®æ—¶å¯ç”¨**

### æ¶ˆèå®éªŒç»“æœ

#### âœ… Train-Test Gap åˆ†æï¼ˆFigure 4 & 6ï¼‰
- **DINO-WM**ï¼šplanning æ—¶çš„ä¸–ç•Œæ¨¡å‹è¯¯å·®æ˜¾è‘—é«˜äº training æ—¶ï¼ˆè´Ÿå€¼ï¼‰ï¼Œè¯´æ˜å­˜åœ¨ä¸¥é‡ gap
- **OWM / AWM**ï¼šè¯¥å·®è·è¢«é€†è½¬æˆ–æ¶ˆé™¤ï¼Œè¡¨æ˜æ¨¡å‹åœ¨è§„åˆ’è·¯å¾„ä¸Šä¹Ÿèƒ½å‡†ç¡®é¢„æµ‹

#### âœ… åˆå§‹åŒ–ç½‘ç»œå½±å“ï¼ˆTable 6ï¼‰
- ä½¿ç”¨ä¸“é—¨è®­ç»ƒçš„åˆå§‹åŒ–ç½‘ç»œï¼ˆinitialization networkï¼‰å¹¶æœªå¸¦æ¥æ˜æ˜¾å¢ç›Š
- **éšæœºåˆå§‹åŒ–è¡¨ç°æ›´å¥½æˆ–ç›¸å½“**ï¼Œè¯´æ˜ AWM å·²æœ‰æ•ˆå¹³æ»‘äº†ä¼˜åŒ–åœ°å½¢

#### âœ… ä¸åŒå¯¹æŠ—æ”»å‡»æ–¹å¼æ¯”è¾ƒï¼ˆTable 11ï¼‰
| æ”»å‡»æ–¹å¼ | Backward Passes/Epoch | MPC Success Rate (Wall) |
|----------|------------------------|--------------------------|
| FGSM (1-step) | 2 | 94% |
| 2-step PGD | 3 | 90% |
| 3-step PGD | 4 | 94% |

â¡ï¸ **FGSM æ•ˆç‡æœ€é«˜ï¼Œæ€§èƒ½ä¸é€Šäºæ›´å¼ºæ”»å‡»æ–¹æ³•**

#### âœ… ä¸åŒä¸–ç•Œæ¨¡å‹æ¶æ„éªŒè¯ï¼ˆTable 8ï¼‰
åœ¨ IRIS æ¨¡å‹ä¸Šä¹Ÿè§‚å¯Ÿåˆ°ï¼š
- OWM å¤±æ•ˆï¼ˆsuccess rate ä¸‹é™ï¼‰
- **AWM æ˜¾è‘—æå‡ GBP æ€§èƒ½ï¼ˆä» 0 â†’ 8%ï¼‰**
â¡ï¸ è¡¨æ˜ AWM æ›´å…·æ™®é€‚æ€§å’Œç¨³å®šæ€§

#### âœ… é•¿æ—¶åŸŸè§„åˆ’ï¼ˆTable 9aï¼‰
- Horizon æ‰©å±•è‡³ 50 æ­¥åï¼ŒAWM ä»ä¼˜äº baselineï¼Œä½“ç°å…¶é•¿æœŸä¸€è‡´æ€§ä¼˜åŠ¿

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **Train-test gap æ˜¯ GBP è¡¨ç°ä¸ä½³çš„æ ¹æœ¬åŸå› **  
   - æ¨¡å‹è®­ç»ƒç›®æ ‡ï¼ˆnext-state predictionï¼‰ä¸ä½¿ç”¨ç›®æ ‡ï¼ˆaction optimizationï¼‰ä¸ä¸€è‡´ã€‚
   
2. âœ… **Adversarial World Modeling æœ€æœ‰æ•ˆ**
   - é€šè¿‡å¯¹æŠ—æ‰°åŠ¨æ˜¾å¼åœ°â€œæš´éœ²â€æ¨¡å‹è„†å¼±åŒºåŸŸï¼Œæ˜¾è‘—å¹³æ»‘äº†åŠ¨ä½œä¼˜åŒ–æ›²é¢ï¼ˆFigure 2 å±•ç¤ºæ›´å®½å¹¿çš„æœ€ä¼˜ç›†åœ°ï¼‰ã€‚
   - ä¸ä¾èµ–æ¨¡æ‹Ÿå™¨å›æ»šï¼Œé€‚ç”¨äºé«˜æˆæœ¬æˆ–ä¸å¯åŠçš„ä»¿çœŸåœºæ™¯ã€‚

3. âœ… **Online World Modeling æœ‰æ•ˆä½†å—é™**
   - èƒ½è¦†ç›– GBP å®é™…è®¿é—®çš„çŠ¶æ€æµå½¢ï¼Œä½†åœ¨æŸäº›ä»»åŠ¡ä¸Šæ•ˆæœä¸ç¨³å®šï¼ˆå¦‚ IRIS æ¶æ„å¤±è´¥ï¼‰ã€‚
   - ä¾èµ– simulator è¿›è¡Œè½¨è¿¹çº æ­£ï¼Œå¢åŠ è®¡ç®—å¼€é”€ï¼ˆTable 10 æ˜¾ç¤º simulator rollout æ¯” WM rollout æ…¢ 30â€“150 å€ï¼‰ã€‚

4. âœ… **GBP å¯ä»¥é«˜æ•ˆæ›¿ä»£ CEM**
   - ç»è¿‡ AWM å¾®è°ƒåï¼ŒGBP ä¸ä»…èƒ½è¾¾åˆ° CEM çº§åˆ«çš„æˆåŠŸç‡ï¼Œè€Œä¸”**è¿è¡Œé€Ÿåº¦å¿«ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Š**ã€‚
   - ç‰¹åˆ«é€‚åˆéœ€è¦å¿«é€Ÿå“åº”çš„çœŸå®æœºå™¨äººç³»ç»Ÿã€‚

### æ–¹æ³•çš„å±€é™æ€§
| å±€é™ | è¯´æ˜ |
|------|------|
| **ä¾èµ–é«˜è´¨é‡é¢„è®­ç»ƒè§†è§‰ç¼–ç å™¨** | å½“å‰æ–¹æ³•å»ºç«‹åœ¨ DINOv2 ç­‰å¼ºå¤§ SSL ç‰¹å¾ä¹‹ä¸Šï¼Œè‹¥ç¼–ç å™¨è¡¨è¾¾èƒ½åŠ›å¼±ï¼Œæ•ˆæœä¼šä¸‹é™ |
| **å¯¹æŠ—æ‰°åŠ¨å°ºåº¦æ•æ„Ÿ** | è‹¥æ‰°åŠ¨è¿‡å¤§ï¼ˆå¦‚ $\lambda_z > 0.5$ï¼‰ï¼Œå¯èƒ½ç ´åè¯­ä¹‰ä¿¡æ¯ï¼Œåè€ŒæŸå®³æ€§èƒ½ï¼ˆFigure 9ï¼‰ |
| **å°šæœªåœ¨çœŸå®ç¡¬ä»¶ä¸ŠéªŒè¯** | æ‰€æœ‰å®éªŒå‡åœ¨æ¨¡æ‹Ÿå™¨ä¸­è¿›è¡Œï¼Œç°å®ä¸­çš„å™ªå£°ã€å»¶è¿Ÿç­‰å› ç´ æœªè€ƒè™‘ |
| **OWM è®¡ç®—æˆæœ¬è¾ƒé«˜** | æ¯è½®éœ€è°ƒç”¨ simulator rolloutï¼Œé™åˆ¶å…¶åœ¨èµ„æºç´§å¼ åœºæ™¯çš„åº”ç”¨ |

### æœªæ¥å·¥ä½œæ–¹å‘
1. **çœŸå®ä¸–ç•Œéƒ¨ç½²**ï¼šå°† AWM åº”ç”¨äºçœŸå®æœºå™¨äººå¹³å°ï¼Œç ”ç©¶å…¶å¯¹ä¼ æ„Ÿå™¨å™ªå£°å’ŒåŠ¨åŠ›å­¦ä¸ç¡®å®šæ€§çš„é²æ£’æ€§ã€‚
2. **ç»“åˆç­–ç•¥å­¦ä¹ **ï¼šå°†ç¨³å¥çš„ä¸–ç•Œæ¨¡å‹ç”¨äºç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ ï¼Œæ¢ç´¢å…¶åœ¨ long-horizon å†³ç­–ä¸­çš„æ½œåŠ›ã€‚
3. **å¤šå°ºåº¦/åˆ†å±‚è§„åˆ’**ï¼šæ‹“å±•è‡³ hierarchical world modelsï¼Œåœ¨ä¸åŒæŠ½è±¡å±‚çº§åº”ç”¨ AWM æå‡æ•´ä½“è§„åˆ’ç¨³å®šæ€§ã€‚
4. **é˜²å¾¡ç¯å¢ƒå¯¹æŠ—æ‰°åŠ¨**ï¼šåˆ©ç”¨ AWM æå‡æ¨¡å‹å¯¹ç‰©ç†æ‰°åŠ¨ï¼ˆå¦‚é£åŠ›ã€æ‘©æ“¦å˜åŒ–ï¼‰çš„é€‚åº”èƒ½åŠ›ã€‚

---

> ğŸ”— **ä»£ç å¼€æºåœ°å€**ï¼š[github.com/nimitkalra/robust-world-model-planning](https://github.com/nimitkalra/robust-world-model-planning)

</details>

---

### 15. [Visual Categorization Across Minds and Models: Cognitive Analysis of Human Labeling and Neuro-Symbolic Integration](https://arxiv.org/abs/2512.09340)

**Authors**: Chethana Prasad Kabgere  
**Category**: cs.AI  
**Published**: 2025-12-11  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.09340v1  

#### Abstract
Understanding how humans and AI systems interpret ambiguous visual stimuli offers critical insight into the nature of perception, reasoning, and decision-making. This paper examines image labeling performance across human participants and deep neural networks, focusing on low-resolution, perceptuall...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Visual Categorization Across Minds and Models: Cognitive Analysis of Human Labeling and Neuro-Symbolic Integration*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³ **äººç±»ä¸AIåœ¨è§†è§‰åˆ†ç±»ä»»åŠ¡ä¸­å¤„ç†æ¨¡ç³Šåˆºæ¿€æ—¶çš„è®¤çŸ¥æœºåˆ¶å·®å¼‚**ã€‚å…·ä½“è€Œè¨€ï¼Œç ”ç©¶èšç„¦äºä½åˆ†è¾¨ç‡ã€æ„ŸçŸ¥é€€åŒ–çš„å›¾åƒï¼ˆå¦‚CIFAR-10ä¸­çš„å°å°ºå¯¸å›¾åƒï¼‰ï¼Œæ¢è®¨ï¼š
- äººç±»å¦‚ä½•åŸºäºæœ‰é™è§†è§‰ä¿¡æ¯è¿›è¡Œåˆ†ç±»å†³ç­–ï¼›
- æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰å¦‚ä½•ä¾èµ–ç‰¹å¾æå–åšå‡ºé¢„æµ‹ï¼›
- ä¸¤è€…åœ¨è¡¨ç¤ºã€æ¨ç†å’Œç½®ä¿¡åº¦æ ¡å‡†ä¸Šçš„å¼‚åŒã€‚

è¿™ä¸€é—®é¢˜å¯¹äºæ„å»ºæ›´å¯è§£é‡Šã€è®¤çŸ¥å¯¹é½ï¼ˆcognitively alignedï¼‰çš„AIç³»ç»Ÿè‡³å…³é‡è¦ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
- **è·¨æ¨¡æ€è®¤çŸ¥åˆ†ææ¡†æ¶**ï¼šç»“åˆäººç±»è¢«è¯•çš„è¡Œä¸ºæ•°æ®ï¼ˆæ ‡ç­¾ã€ä¿¡å¿ƒã€ç­–ç•¥æè¿°ã€æ³¨æ„åŠ›ç„¦ç‚¹ç­‰ï¼‰ä¸AIæ¨¡å‹çš„å†…éƒ¨å¯è§†åŒ–ï¼ˆGrad-CAMï¼‰ï¼Œä» Marr çš„ä¸‰å±‚æ¬¡ç†è®ºï¼ˆcomputational, algorithmic, implementationï¼‰å‡ºå‘ï¼Œç³»ç»Ÿæ¯”è¾ƒäººè„‘ä¸äººå·¥ç³»ç»Ÿçš„è§†è§‰åˆ†ç±»æœºåˆ¶ã€‚
- **è®¤çŸ¥ç§‘å­¦é©±åŠ¨çš„å¯¹æ¯”èŒƒå¼**ï¼šå°†äººç±»è¡Œä¸ºç½®äº **bounded rationality**ã€**analogical reasoning**ã€**embodied cognition** å’Œ **distributed cognition** ç­‰ç»å…¸è®¤çŸ¥ç†è®ºä¸‹è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶ä¸è¿æ¥ä¸»ä¹‰AIè¿›è¡Œå¯¹ç…§ã€‚
- **æ¨åŠ¨ neuro-symbolic integration çš„è®¾è®¡è·¯å¾„**ï¼šæå‡ºæœªæ¥åº”èåˆç¬¦å·æ¨ç†æ¨¡å—ï¼ˆå¦‚å½¢çŠ¶è§„åˆ™éªŒè¯ï¼‰ä¸ç¥ç»ç½‘ç»œæ¿€æ´»ä¿¡å·ï¼ˆå¦‚Grad-CAMï¼‰ï¼Œä»¥æå‡AIçš„é²æ£’æ€§å’Œå¯è§£é‡Šæ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•å±€é™ | æœ¬æ–‡ä¼˜åŠ¿ |
|------|--------------|---------|
| åˆ†æè§†è§’ | å¤šå…³æ³¨æ€§èƒ½æŒ‡æ ‡ï¼ˆå‡†ç¡®ç‡ï¼‰æˆ–å•ä¸€å¯è§£é‡Šæ€§å·¥å…· | å¼•å…¥å¤šç»´è®¤çŸ¥ç»´åº¦ï¼ˆä¿¡å¿ƒã€è´Ÿè·ã€æƒ…ç»ªã€ä¿¡ä»»ã€è§£é‡Šï¼‰è¿›è¡Œæ·±åº¦è¡Œä¸ºåˆ†æ |
| å¯è§£é‡Šæ€§ | Grad-CAMä»…æä¾›çƒ­å›¾ï¼Œç¼ºä¹è¯­ä¹‰è§£é‡Š | å°†AIæ³¨æ„åŠ›å›¾ä¸äººç±»è¯­è¨€ç­–ç•¥ç›´æ¥å¯¹æ¯”ï¼Œæ­ç¤ºâ€œä¸ºä½•â€ä¸åŒ |
| ç†è®ºåŸºç¡€ | ç¼ºä¹ç»Ÿä¸€è®¤çŸ¥æ¡†æ¶ | æ˜ç¡®ä¾æ‰˜ Marrâ€™s tri-level hypothesisã€Simonâ€™s bounded rationalityã€PDP æ¡†æ¶ç­‰å»ºç«‹åˆ†æä½“ç³» |
| æ¶æ„å¯ç¤º | å¤šæ•°ä¸ºçº¯è¿æ¥ä¸»ä¹‰æˆ–åæœŸç¬¦å·åå¤„ç† | æå‡º**å®æ—¶ neuro-symbolic é›†æˆæ¶æ„**è®¾æƒ³ï¼Œå®ç°åŠ¨æ€åé¦ˆä¸é€»è¾‘æ ¡éªŒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **ä¸»æ•°æ®é›†**ï¼š`CIFAR-10`ï¼Œé€‰å–å…¶ä¸­10å¼ ä½åˆ†è¾¨ç‡ï¼ˆ32Ã—32ï¼‰å›¾åƒä½œä¸ºæµ‹è¯•æ ·æœ¬ï¼Œæ¶µç›–æ¸…æ™°åˆ°æ¨¡ç³Šçš„ä¸åŒéš¾åº¦ç­‰çº§ã€‚
- å›¾åƒç±»åˆ«åŒ…æ‹¬ï¼šairplane, automobile, bird, cat, deer ç­‰ã€‚

### å®éªŒè®¾ç½®
#### äººç±»å‚ä¸è€…
- **äººæ•°**ï¼š12åå‚ä¸è€…ï¼ˆä¾¿åˆ©æŠ½æ ·ï¼Œæ¥è‡ªè¯¾å ‚åŠåŒäº‹ï¼‰
- **ä»»åŠ¡æµç¨‹**ï¼š
  1. è§‚å¯Ÿæ¯å¼ å›¾åƒå¹¶ç»™å‡ºåˆ†ç±»æ ‡ç­¾ï¼ˆ10ç±»ä¹‹ä¸€ï¼‰
  2. æä¾› **confidence rating**ï¼ˆ1â€“5æå…‹ç‰¹é‡è¡¨ï¼‰
  3. æè¿°æ‰€ç”¨ **strategy**ï¼ˆå¦‚â€œçœ‹èµ·æ¥åƒç¿…è†€â€ã€â€œç±»ä¼¼åœç€çš„è½¦â€ï¼‰
  4. æŠ¥å‘Š **cognitive load**ï¼ˆ1â€“5ï¼‰ã€**focus area**ï¼ˆä¸­å¿ƒ/é¡¶éƒ¨/åº•éƒ¨ç­‰ï¼‰ã€**emotion**ã€**trust in AI**ã€**enjoyment**
- æ‰€æœ‰å‚ä¸è€…å®ŒæˆCITIä¼¦ç†åŸ¹è®­ã€‚

#### AIæ¨¡å‹
- **æ¨¡å‹æ¶æ„**ï¼šResNet-18ï¼ˆé’ˆå¯¹CIFAR-10è°ƒæ•´è¾“å…¥å±‚ï¼š3Ã—3å·ç§¯ï¼Œæ— åˆå§‹max poolingï¼‰
- **è®­ç»ƒæ–¹å¼**ï¼š
  - ä»é›¶å¼€å§‹è®­ç»ƒï¼Œ5ä¸ªepoch
  - ä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼ˆlr=0.001ï¼‰ï¼Œäº¤å‰ç†µæŸå¤±
  - æ•°æ®å¢å¼ºï¼šéšæœºè£å‰ªã€æ°´å¹³ç¿»è½¬ã€å½’ä¸€åŒ–
- **è¾“å‡ºå†…å®¹**ï¼š
  - é¢„æµ‹ç±»åˆ«
  - Softmaxç½®ä¿¡åº¦
  - Grad-CAMçƒ­åŠ›å›¾ï¼ˆç”¨äºå¯è§†åŒ–æ³¨æ„åŠ›åŒºåŸŸï¼‰

### è¯„ä¼°æŒ‡æ ‡
| ç±»å‹ | æŒ‡æ ‡ |
|------|------|
| æ€§èƒ½ | å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ã€Softmaxç½®ä¿¡åº¦ |
| å¯è§£é‡Šæ€§ | Grad-CAMæ³¨æ„åŠ›åˆ†å¸ƒ vs. äººç±»æŠ¥å‘Šçš„ focus area å’Œ strategy |
| è®¤çŸ¥ä¸€è‡´æ€§ | äººç±»ä¿¡å¿ƒ vs. AIç½®ä¿¡åº¦ï¼›ç­–ç•¥ç±»å‹ vs. æ³¨æ„åŠ›æ¨¡å¼ |
| ç†è®ºæ˜ å°„ | æ˜¯å¦ä½“ç° bounded rationalityã€analogical reasoningã€embodied cognition ç­‰åŸåˆ™ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **AI Baseline**ï¼šæ ‡å‡†ResNet-18 + Grad-CAM
- **äººç±» Baseline**ï¼šè‡ªèº«è¡Œä¸ºä½œä¸ºâ€œè®¤çŸ¥åˆç†â€çš„å‚ç…§ç³»
- å¯¹æ¯”é‡ç‚¹ä¸æ˜¯â€œè°æ›´å‡†â€ï¼Œè€Œæ˜¯â€œä¸ºä½•ä¸åŒâ€â€”â€”å³æœºåˆ¶å±‚é¢çš„å·®å¼‚ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| **äººç±»å‡†ç¡®ç‡** | **100%**ï¼ˆæ‰€æœ‰10å¼ å›¾åƒå…¨éƒ¨æ­£ç¡®æ ‡æ³¨ï¼‰ |
| **äººç±»å¹³å‡ä¿¡å¿ƒ** | 4.42 â€“ 4.92 / 5ï¼ˆæé«˜ï¼Œå°¤å…¶å¯¹æ¸…æ™°å›¾åƒï¼‰ |
| **AIæµ‹è¯•å‡†ç¡®ç‡** | ~70.7%ï¼ˆResNet-18 on CIFAR-10ï¼‰ |
| **AIç½®ä¿¡åº¦èŒƒå›´** | 0.329 â€“ 0.957ï¼ˆæ³¢åŠ¨å¤§ï¼Œéƒ¨åˆ†é”™è¯¯é¢„æµ‹ä»å…·ä¸­ç­‰ç½®ä¿¡ï¼‰ |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| å¯¹æ¯”ç»´åº¦ | äººç±»è¡¨ç° | AIè¡¨ç° | å·®å¼‚è¯´æ˜ |
|--------|--------|-------|--------|
| **åˆ†ç±»å‡†ç¡®æ€§** | å®Œç¾ï¼ˆ100%ï¼‰ | ä¸­ç­‰ï¼ˆ~70.7%ï¼‰ | äººç±»åˆ©ç”¨å…ˆéªŒçŸ¥è¯†è¡¥å¿ä½åˆ†è¾¨ç‡ç¼ºé™· |
| **ç½®ä¿¡åº¦ç¨³å®šæ€§** | é«˜ä¸”ç¨³å®šï¼ˆSD â‰¤ 0.53ï¼‰ | æ³¢åŠ¨è¾ƒå¤§ | äººç±»å—â€œæ„ŸçŸ¥ç¨³å®šæ€§â€å½±å“ï¼ŒAIå—å±€éƒ¨çº¹ç†æ‰°åŠ¨å½±å“ |
| **æ¨ç†ç­–ç•¥** | å½¢çŠ¶ä¸»å¯¼ï¼ˆShape, Familiarityï¼‰ | å±€éƒ¨çº¹ç†æ•æ„Ÿï¼ˆtexture-drivenï¼‰ | äººç±»ä½¿ç”¨ analogical reasoning æ˜ å°„åŸå‹ï¼›AIæ˜“è¢«è¯¯å¯¼æ€§è¾¹ç¼˜æ¬ºéª— |
| **æ³¨æ„åŠ›ç„¦ç‚¹** | å…¨å±€ç»“æ„ï¼ˆå¦‚â€œè€³æœµâ€ã€â€œè§’â€ï¼‰ | å±€éƒ¨é«˜é¢‘ç‰¹å¾ï¼ˆå¦‚æ–œè¾¹ã€æ–‘ç‚¹ï¼‰ | Grad-CAMæ˜¾ç¤ºAIå…³æ³¨éè¯­ä¹‰åŒºåŸŸï¼ˆå¦‚deer_00.pngè¯¯åˆ¤ä¸ºairplaneå› é¡¶éƒ¨æ–œçº¿ï¼‰ |
| **ä¸ç¡®å®šæ€§åº”å¯¹** | å¯ç”¨Type 2ï¼ˆåˆ†æå‹ï¼‰æ€ç»´ï¼Œå¢åŠ è®¤çŸ¥è´Ÿè· | æ— æ˜¾å¼å…ƒè®¤çŸ¥è°ƒèŠ‚æœºåˆ¶ | äººç±»è¡¨ç°å‡º metacognitive monitoring èƒ½åŠ› |

### å…¸å‹æ¡ˆä¾‹åˆ†æ
- **deer_00.png**ï¼š
  - AIé¢„æµ‹ä¸ºâ€œairplaneâ€ï¼ˆconf=0.369ï¼‰ï¼ŒGrad-CAMé«˜äº®é¡¶éƒ¨æ–œçº¹ï¼ˆè¯¯è®¤ä¸ºæœºç¿¼ï¼‰
  - äººç±»æ™®éè¯†åˆ«ä¸ºâ€œdeerâ€ï¼Œä¾æ®â€œantler-like shapeâ€æˆ–â€œforest-like fuzzâ€
  - è¡¨æ˜AIç¼ºä¹ä¸Šä¸‹æ–‡ä¸èº«ä½“ç»éªŒæ”¯æŒçš„æ¨ç†èƒ½åŠ›
- **bird_01.png**ï¼š
  - AIæ­£ç¡®ä½†ä½ç½®ä¿¡ï¼ˆ0.358ï¼‰ï¼ŒGrad-CAMåˆ†æ•£
  - äººç±»è™½ä¹Ÿé™ä½ä¿¡å¿ƒï¼ˆå‡å€¼4.42ï¼‰ï¼Œä½†ä»èƒ½é€šè¿‡â€œbeak-like outlineâ€åˆ¤æ–­
  - æ˜¾ç¤ºäººç±»å…·å¤‡æ›´å¼ºçš„ç»“æ„å½’çº³èƒ½åŠ›

### æ¶ˆèå®éªŒï¼ˆé—´æ¥ä½“ç°ï¼‰
è™½ç„¶æœªè¿›è¡Œæ­£å¼æ¶ˆèå®éªŒï¼Œä½†é€šè¿‡ä»¥ä¸‹æ–¹å¼éªŒè¯æœºåˆ¶ï¼š
- æ”¹å˜å›¾åƒæ¸…æ™°åº¦ â†’ è§‚å¯Ÿä¿¡å¿ƒä¸è´Ÿè·å˜åŒ– â†’ éªŒè¯ bounded rationality
- åˆ†æ strategy ç±»å‹åˆ†å¸ƒ â†’ éªŒè¯ analogical reasoning å ä¸»å¯¼
- å¯¹æ¯” Grad-CAM ä¸ human focus â†’ æ­ç¤º attention misalignment

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **äººç±»åœ¨æ¨¡ç³Šå›¾åƒåˆ†ç±»ä¸­å±•ç°å‡ºé«˜åº¦ç¨³å¥æ€§ä¸ä¸€è‡´æ€§**ï¼Œä¾èµ– **shape-based recognition** å’Œ **analogical reasoning**ï¼Œè€Œéåƒç´ çº§åˆ†æã€‚
2. âŒ **AIï¼ˆResNetï¼‰ä¸¥é‡ä¾èµ–å±€éƒ¨çº¹ç†çº¿ç´¢**ï¼Œå®¹æ˜“å› å‡ ä½•ç›¸ä¼¼æ€§äº§ç”Ÿè¯­ä¹‰æ— å…³çš„è¯¯åˆ¤ï¼ˆå¦‚å°†é¹¿è¯¯ä½œé£æœºï¼‰ï¼Œç¼ºä¹é«˜å±‚ç»“æ„ç†è§£ã€‚
3. ğŸ” **Grad-CAM ä¸äººç±»æ³¨æ„åŠ›æ˜¾è‘—ä¸ä¸€è‡´**ï¼šAIå…³æ³¨å±€éƒ¨é«˜é¢‘ç‰¹å¾ï¼Œäººç±»å…³æ³¨æ•´ä½“è½®å»“ä¸å…³é”®éƒ¨ä»¶ï¼ˆears, wings, antlersï¼‰ã€‚
4. ğŸ§  **äººç±»è¡Œä¸ºç¬¦åˆè®¤çŸ¥ç§‘å­¦ç†è®º**ï¼š
   - **Bounded rationality**ï¼šä½¿ç”¨å¯å‘å¼å¿«é€Ÿå†³ç­–ï¼ŒèŠ‚çœè®¤çŸ¥èµ„æº
   - **Dual-process theory**ï¼šæ¸…æ™°å›¾åƒè§¦å‘Type 1ï¼ˆç›´è§‰ï¼‰ï¼Œæ¨¡ç³Šå›¾åƒå¯ç”¨Type 2ï¼ˆåˆ†æï¼‰
   - **Embodied/distributed cognition**ï¼šå€ŸåŠ©èƒŒæ™¯ã€å¸¸è¯†ã€ç¯å¢ƒçº¿ç´¢è¾…åŠ©åˆ¤æ–­
5. âš–ï¸ **AIç¼ºä¹å…ƒè®¤çŸ¥èƒ½åŠ›**ï¼šæ— æ³•åƒäººç±»é‚£æ ·åŠ¨æ€è°ƒèŠ‚ä¿¡å¿ƒæˆ–åˆ‡æ¢ç­–ç•¥ï¼Œå¯¼è‡´åœ¨ä¸ç¡®å®šæƒ…å¢ƒä¸‹å¯é æ€§ä¸‹é™ã€‚

### æ–¹æ³•çš„å±€é™æ€§
| å±€é™ | è¯´æ˜ |
|------|------|
| æ ·æœ¬è§„æ¨¡å° | ä»…12åå‚ä¸è€…ï¼Œå¯èƒ½å½±å“ç»Ÿè®¡æ³›åŒ–æ€§ |
| å›¾åƒæ•°é‡å°‘ | ä»…10å¼ å›¾åƒï¼Œéš¾ä»¥è¦†ç›–å…¨é¢è§†è§‰åœºæ™¯ |
| æ¨¡å‹å¤æ‚åº¦ä½ | ResNet-18ä¸ºè½»é‡çº§æ¨¡å‹ï¼Œé«˜çº§æ¨¡å‹ï¼ˆå¦‚ViTï¼‰å¯èƒ½è¡¨ç°ä¸åŒ |
| ç¼ºä¹æ§åˆ¶å˜é‡ | æœªä¸¥æ ¼æ§åˆ¶å›¾åƒæ¨¡ç³Šç¨‹åº¦ã€ç±»åˆ«è·ç¦»ç­‰å› ç´  |
| è¯­è¨€ç­–ç•¥ä¸»è§‚æ€§å¼º | è‡ªç”±æ–‡æœ¬æè¿°éœ€äººå·¥ç¼–ç ï¼Œå­˜åœ¨è§£é‡Šåå·® |

### æœªæ¥å·¥ä½œæ–¹å‘
1. **Neuro-symbolic System Development**
   - è®¾è®¡æ··åˆæ¶æ„ï¼šå°† Grad-CAM æ¿€æ´»ä½œä¸ºè¾“å…¥ï¼Œè§¦å‘ symbolic rule engineï¼ˆä¾‹å¦‚ï¼šâ€œè‹¥æ£€æµ‹åˆ°ç¿…è†€ â†’ éªŒè¯æ˜¯å¦æœ‰æœºèº«â€ï¼‰
   - å‚è€ƒ Feature-CAM ç­‰æ–¹æ³•æ”¹è¿› attention alignment

2. **Scalability and Representation Alignment**
   - æ¢ç´¢ graph-based embeddings ç»Ÿä¸€ç¥ç»ç‰¹å¾ç©ºé—´ä¸ç¬¦å·åŸå‹
   - åœ¨ CLEVRã€GQA ç­‰éœ€è¦ç»„åˆæ¨ç†çš„æ•°æ®é›†ä¸ŠéªŒè¯æŠ½è±¡èƒ½åŠ›

3. **Trust, Transparency, and Human-AI Collaboration**
   - å¼€å±•ç”¨æˆ·ç ”ç©¶ï¼Œè¯„ä¼° neuro-symbolic è¾“å‡ºï¼ˆå« symbolic traceï¼‰å¯¹ human trustã€reliance å’Œåä½œæ•ˆç‡çš„å½±å“
   - ç‰¹åˆ«å…³æ³¨ä½è´¨é‡å›¾åƒä¸‹çš„äº¤äº’å†³ç­–åœºæ™¯

4. **Towards Neuromorphic and Context-Aware AI**
   - å¼•å…¥å¤šæ„Ÿå®˜è¾“å…¥ä¸ç»éªŒå…ˆéªŒï¼ˆexperiential priorsï¼‰
   - æ„å»ºæ›´å…·â€œembodimentâ€çš„AIç³»ç»Ÿï¼Œå‡å°‘å¯¹é™æ€çº¹ç†çš„è¿‡åº¦ä¾èµ–

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬è®ºæ–‡é€šè¿‡è®¤çŸ¥ç§‘å­¦è§†è§’æ­ç¤ºäº†äººç±»ä¸AIåœ¨è§†è§‰åˆ†ç±»ä¸­çš„æ ¹æœ¬å·®å¼‚â€”â€”å‰è€…åŸºäº**ç»“æ„ç±»æ¯”ä¸å…·èº«ç»éªŒ**ï¼Œåè€…é™·äº**å±€éƒ¨çº¹ç†ç»Ÿè®¡**ï¼Œè¿›è€Œå‘¼åå‘å±•èåˆ symbolic reasoning ä¸ connectionist perception çš„ **neuro-symbolic AI**ï¼Œè¿ˆå‘æ›´å¯è§£é‡Šã€æ›´ç±»äººçš„æ™ºèƒ½ç³»ç»Ÿã€‚

</details>

---

### 16. [An End-to-end Planning Framework with Agentic LLMs and PDDL](https://arxiv.org/abs/2512.09629)

**Authors**: Emanuele La Malfa, Ping Zhu, Samuele Marro, Sara Bernardini, Michael Wooldridge  
**Category**: cs.AI  
**Published**: 2025-12-11  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.09629v1  

#### Abstract
We present an end-to-end framework for planning supported by verifiers. An orchestrator receives a human specification written in natural language and converts it into a PDDL (Planning Domain Definition Language) model, where the domain and problem are iteratively refined by sub-modules (agents) to ...

---

### 17. [Targeting Misalignment: A Conflict-Aware Framework for Reward-Model-based LLM Alignment](https://arxiv.org/abs/2512.09212)

**Authors**: Zixuan Liu, Siavash H. Khajavi, Guangkai Jiang, Xinru Liu  
**Category**: cs.CL  
**Published**: 2025-12-11  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.09212v1  

#### Abstract
Reward-model-based fine-tuning is a central paradigm in aligning Large Language Models with human preferences. However, such approaches critically rely on the assumption that proxy reward models accurately reflect intended supervision, a condition often violated due to annotation noise, bias, or lim...

---

### 18. [Mitigating Social Bias in English and Urdu Language Models Using PRM-Guided Candidate Selection and Sequential Refinement](https://arxiv.org/abs/2512.09854)

**Authors**: Muneeb Ur Raheem Khan  
**Category**: cs.CL  
**Published**: 2025-12-11  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.09854v1  

#### Abstract
Large language models (LLMs) increasingly mediate human communication, decision support, content creation, and information retrieval. Despite impressive fluency, these systems frequently produce biased or stereotypical content, especially when prompted with socially sensitive language. A growing bod...

---

### 19. [Efficient MoE Serving in the Memory-Bound Regime: Balance Activated Experts, Not Tokens](https://arxiv.org/abs/2512.09277)

**Authors**: Yanpeng Yu, Haiyue Ma, Krish Agarwal, Nicolai Oswald, Qijing Huang, Hugo Linsenmaier, Chunhui Mei, Ritchie Zhao, Ritika Borkar, Bita Darvish Rouhani, David Nellans, Ronny Krashinsky, Anurag Khandelwal  
**Category**: cs.DC  
**Published**: 2025-12-11  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.09277v1  

#### Abstract
Expert Parallelism (EP) permits Mixture of Experts (MoE) models to scale beyond a single GPU. To address load imbalance across GPUs in EP, existing approaches aim to balance the number of tokens each GPU processes. Surprisingly, we find that this objective degrades performance rather than improving ...

---

### 20. [Passing the Baton: High Throughput Distributed Disk-Based Vector Search with BatANN](https://arxiv.org/abs/2512.09331)

**Authors**: Nam Anh Dang (Cornell University), Ben Landrum (Cornell University), Ken Birman (Cornell University)  
**Category**: cs.DC  
**Published**: 2025-12-11  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.09331v1  

#### Abstract
Vector search underpins modern information-retrieval systems, including retrieval-augmented generation (RAG) pipelines and search engines over unstructured text and images. As datasets scale to billions of vectors, disk-based vector search has emerged as a practical solution. However, looking to the...

---

### 21. [Comparing AI Agents to Cybersecurity Professionals in Real-World Penetration Testing](https://arxiv.org/abs/2512.09882)

**Authors**: Justin W. Lin, Eliot Krzysztof Jones, Donovan Julian Jasper, Ethan Jun-shen Ho, Anna Wu, Arnold Tianyi Yang, Neil Perry, Andy Zou, Matt Fredrikson, J. Zico Kolter, Percy Liang, Dan Boneh, Daniel E. Ho  
**Category**: cs.AI  
**Published**: 2025-12-11  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.09882v1  

#### Abstract
We present the first comprehensive evaluation of AI agents against human cybersecurity professionals in a live enterprise environment. We evaluate ten cybersecurity professionals alongside six existing AI agents and ARTEMIS, our new agent scaffold, on a large university network consisting of ~8,000 ...

---

### 22. [Contrast transfer functions help quantify neural network out-of-distribution generalization in HRTEM](https://arxiv.org/abs/2512.09067)

**Authors**: Luis Rangel DaCosta, Mary C. Scott  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.09067v1  

#### Abstract
Neural networks, while effective for tackling many challenging scientific tasks, are not known to perform well out-of-distribution (OOD), i.e., within domains which differ from their training data. Understanding neural network OOD generalization is paramount to their successful deployment in experim...

---

### 23. [Improved Physics-Driven Neural Network to Solve Inverse Scattering Problems](https://arxiv.org/abs/2512.09333)

**Authors**: Yutong Du, Zicheng Liu, Bo Wu, Jingwei Kou, Hang Li, Changyou Li, Yali Zong, Bo Qi  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.09333v1  

#### Abstract
This paper presents an improved physics-driven neural network (IPDNN) framework for solving electromagnetic inverse scattering problems (ISPs). A new Gaussian-localized oscillation-suppressing window (GLOW) activation function is introduced to stabilize convergence and enable a lightweight yet accur...

---

### 24. [Physics-Aware Heterogeneous GNN Architecture for Real-Time BESS Optimization in Unbalanced Distribution Systems](https://arxiv.org/abs/2512.09780)

**Authors**: Aoxiang Ma, Salah Ghamizi, Jun Cao, Pedro Rodriguez  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.09780v1  

#### Abstract
Battery energy storage systems (BESS) have become increasingly vital in three-phase unbalanced distribution grids for maintaining voltage stability and enabling optimal dispatch. However, existing deep learning approaches often lack explicit three-phase representation, making it difficult to accurat...

---

### 25. [Knowledge Diversion for Efficient Morphology Control and Policy Transfer](https://arxiv.org/abs/2512.09796)

**Authors**: Fu Feng, Ruixiao Shi, Yucheng Xie, Jianlu Shen, Jing Wang, Xin Geng  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.09796v1  

#### Abstract
Universal morphology control aims to learn a universal policy that generalizes across heterogeneous agent morphologies, with Transformer-based controllers emerging as a popular choice. However, such architectures incur substantial computational costs, resulting in high deployment overhead, and exist...

---

### 26. [Gaussian Process Aggregation for Root-Parallel Monte Carlo Tree Search with Continuous Actions](https://arxiv.org/abs/2512.09727)

**Authors**: Junlin Xiao, Victor-Alexandru Darvariu, Bruno Lacerda, Nick Hawes  
**Category**: cs.AI  
**Published**: 2025-12-11  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.09727v1  

#### Abstract
Monte Carlo Tree Search is a cornerstone algorithm for online planning, and its root-parallel variant is widely used when wall clock time is limited but best performance is desired. In environments with continuous action spaces, how to best aggregate statistics from different threads is an important...

---

### 27. [A Distributed Framework for Privacy-Enhanced Vision Transformers on the Edge](https://arxiv.org/abs/2512.09309)

**Authors**: Zihao Ding, Mufeng Zhu, Zhongze Tang, Sheng Wei, Yao Liu  
**Category**: cs.DC  
**Published**: 2025-12-11  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.09309v1  

#### Abstract
Nowadays, visual intelligence tools have become ubiquitous, offering all kinds of convenience and possibilities. However, these tools have high computational requirements that exceed the capabilities of resource-constrained mobile and wearable devices. While offloading visual data to the cloud is a ...

---

### 28. [PHWSOA: A Pareto-based Hybrid Whale-Seagull Scheduling for Multi-Objective Tasks in Cloud Computing](https://arxiv.org/abs/2512.09568)

**Authors**: Zhi Zhao, Hang Xiao, Wei Rang  
**Category**: cs.DC  
**Published**: 2025-12-11  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.09568v1  

#### Abstract
Task scheduling is a critical research challenge in cloud computing, a transformative technology widely adopted across industries. Although numerous scheduling solutions exist, they predominantly optimize singular or limited metrics such as execution time or resource utilization often neglecting the...

---

### 29. [SynthPix: A lightspeed PIV images generator](https://arxiv.org/abs/2512.09664)

**Authors**: Antonio Terpin, Alan Bonomi, Francesco Banelli, Raffaello D'Andrea  
**Category**: cs.DC  
**Published**: 2025-12-11  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.09664v1  

#### Abstract
We describe SynthPix, a synthetic image generator for Particle Image Velocimetry (PIV) with a focus on performance and parallelism on accelerators, implemented in JAX. SynthPix supports the same configuration parameters as existing tools but achieves a throughput several orders of magnitude higher i...

---

### 30. [GS-KAN: Parameter-Efficient Kolmogorov-Arnold Networks via Sprecher-Type Shared Basis Functions](https://arxiv.org/abs/2512.09084)

**Authors**: Oscar Eliasson  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.09084v1  

#### Abstract
The Kolmogorov-Arnold representation theorem offers a theoretical alternative to Multi-Layer Perceptrons (MLPs) by placing learnable univariate functions on edges rather than nodes. While recent implementations such as Kolmogorov-Arnold Networks (KANs) demonstrate high approximation capabilities, th...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
