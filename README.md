# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-23 05:59:15 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [ACE-Sync: An Adaptive Cloud-Edge Synchronization Framework for Communication-Efficient Large-Scale Distributed Model Training](https://arxiv.org/abs/2512.18127)

**Authors**: Yi Yang, Ziyu Lin, Liesheng Wei  
**Category**: cs.DC  
**Published**: 2025-12-23  
**Score**: 13.5  
**Type**: new  
**ArXiv ID**: 2512.18127v1  

#### Abstract
Large-scale deep learning models impose substantial communication overh ead in distributed training, particularly in bandwidth-constrained or heterogeneous clo ud-edge environments. Conventional synchronous or fixed-compression techniques o ften struggle to balance communication cost, convergence st...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šACE-Sync: An Adaptive Cloud-Edge Synchronization Framework for Communication-Efficient Large-Scale Distributed Model Training

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­é¢ä¸´ä¸¥é‡çš„é€šä¿¡å¼€é”€é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å¸¦å®½å—é™æˆ–è®¾å¤‡å¼‚æ„çš„äº‘è¾¹ååŒï¼ˆcloud-edgeï¼‰ç¯å¢ƒä¸­ã€‚ä¼ ç»Ÿçš„åŒæ­¥æœºåˆ¶ï¼ˆå¦‚ FullSyncï¼‰æˆ–å›ºå®šå‹ç¼©ç­–ç•¥ï¼ˆå¦‚ Top-k Sparsificationï¼‰éš¾ä»¥åœ¨**é€šä¿¡æˆæœ¬ã€æ”¶æ•›ç¨³å®šæ€§ä¸æ¨¡å‹ç²¾åº¦**ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº† **ACE-Sync**ï¼ˆAdaptive Cloud-Edge Synchronization Frameworkï¼‰ï¼Œä¸€ç§é¢å‘å¤§è§„æ¨¡åˆ†å¸ƒå¼æ¨¡å‹è®­ç»ƒçš„è‡ªé€‚åº”äº‘è¾¹åŒæ­¥æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **(1) åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„æ¢¯åº¦é‡è¦æ€§é¢„æµ‹å™¨ï¼ˆAttention-based Gradient Importance Predictorï¼‰**  
  åˆ©ç”¨è½»é‡çº§æ³¨æ„åŠ›æ¨¡å—åŠ¨æ€è¯„ä¼°å„å‚æ•°å¯¹æ”¶æ•›çš„é‡è¦æ€§ï¼Œä¼˜å…ˆåŒæ­¥é«˜å½±å“åŠ›æ¢¯åº¦ï¼Œå‡å°‘å†—ä½™ä¼ è¾“ã€‚

- **(2) å·®å¼‚åŒ–å‚æ•°å‹ç¼©ç­–ç•¥ï¼ˆDifferentiated Parameter Compression Strategyï¼‰**  
  å¯¹é«˜é‡è¦æ€§å‚æ•°è¿›è¡Œå…¨ç²¾åº¦åŒæ­¥ï¼Œä½é‡è¦æ€§å‚æ•°åˆ™é‡‡ç”¨é‡åŒ–+ç¨€ç–åŒ–çš„æ··åˆå‹ç¼©ï¼Œå¹¶ç»“åˆè¯¯å·®è¡¥å¿ï¼ˆerror feedbackï¼‰ä¿è¯é•¿æœŸæ”¶æ•›æ€§ã€‚

- **(3) åˆ†å±‚å¼äº‘è¾¹åè°ƒæœºåˆ¶ï¼ˆHierarchical Cloud-Edge Coordination Mechanismï¼‰**  
  è¾¹ç¼˜èŠ‚ç‚¹æœ¬åœ°ç¼“å­˜æ›´æ–°å¹¶é€‰æ‹©æ€§ä¸Šä¼ ï¼Œäº‘ç«¯è´Ÿè´£å…¨å±€èšåˆã€è°ƒåº¦åŒæ­¥é¢‘ç‡ä¸å‹ç¼©ç­‰çº§ï¼Œå®ç°è·¨è®¾å¤‡ä¸ªæ€§åŒ–ä¸ç³»ç»Ÿå¯æ‰©å±•æ€§çš„ç»Ÿä¸€ã€‚

- **(4) èƒŒåŒ…ä¼˜åŒ–é©±åŠ¨çš„é‡è¦æ¢¯åº¦ä¿ç•™æœºåˆ¶**  
  åœ¨æ¯ä¸ªè®¾å¤‡çš„å¸¦å®½é¢„ç®—ä¸‹ï¼Œé€šè¿‡ knapsack-based ä¼˜åŒ–æœ€å¤§åŒ–â€œé‡è¦æ¢¯åº¦â€çš„ä¿ç•™æ¯”ä¾‹ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³•å±€é™ | ACE-Sync æ”¹è¿› |
|------|--------------|---------------|
| åŒæ­¥é¢‘ç‡ | å›ºå®šå‘¨æœŸåŒæ­¥ï¼ˆå¦‚ FedAvgï¼‰ | åŠ¨æ€è°ƒæ•´ï¼ŒåŸºäºå‘æ•£åº¦è‡ªé€‚åº”æ§åˆ¶ |
| å‹ç¼©ç­–ç•¥ | é™æ€å‹ç¼©ç‡ï¼ˆå¦‚ Top-k å›ºå®šæ¯”ä¾‹ï¼‰ | è‡ªé€‚åº”å‹ç¼©-æ‰©å¼ æœºåˆ¶ï¼Œéšç½‘ç»œæ¡ä»¶å˜åŒ– |
| å‚æ•°å¤„ç† | ç»Ÿä¸€å¤„ç†æ‰€æœ‰å‚æ•° | åŒºåˆ†é‡è¦æ€§ï¼Œå·®å¼‚åŒ–åŒæ­¥ä¸å‹ç¼© |
| æ¶æ„è®¾è®¡ | ä¸­å¿ƒåŒ–æˆ–å»ä¸­å¿ƒåŒ–å•ä¸€æ¨¡å¼ | äº‘è¾¹ååŒåˆ†å±‚æ¶æ„ï¼Œå…¼é¡¾æ•ˆç‡ä¸ç¨³å®š |

> âœ… æ€»ä½“ä¼˜åŠ¿ï¼š**æ›´é«˜æ•ˆé€šä¿¡ + æ›´å¿«æ”¶æ•› + å‡ ä¹æ— æŸç²¾åº¦**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- ä¸»è¦ä»»åŠ¡ä¸º **Transformer è¯­è¨€å»ºæ¨¡**ï¼Œè®­ç»ƒæ•°æ®æ¥æºäºï¼š
  - **OpenWebText2**
  - **C4 (Colossal Clean Crawled Corpus)**
- æ•°æ®æ€»é‡çº¦ **80â€“90 million æ–‡æœ¬æ ·æœ¬**ï¼Œåºåˆ—é•¿åº¦ 512â€“1024 tokensã€‚
- è¡¥å……è¾¹ç¼˜è®¾å¤‡ç”Ÿæˆçš„å…ƒæ•°æ®ï¼šå¸¦å®½è½¨è¿¹ã€å»¶è¿Ÿæ—¥å¿—ã€è®¡ç®—èƒ½åŠ›ç­‰ï¼Œç”¨äºæ¨¡æ‹ŸçœŸå® cloud-edge åœºæ™¯ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼š350M å‚æ•°çš„ Transformer æ¨¡å‹
- **ä¼˜åŒ–å™¨**ï¼šAdamW
- **æ‰¹é‡å¤§å°**ï¼šæ¯è¾¹ç¼˜èŠ‚ç‚¹ batch size = 64
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š
  - **äº‘ç«¯**ï¼š16 å° NVIDIA A100 GPUï¼ˆæ•°æ®ä¸­å¿ƒçº§ï¼‰
  - **è¾¹ç¼˜ç«¯**ï¼š64 å°å¼‚æ„è®¾å¤‡ï¼ˆJetson AGX Xavierã€ARM åŠ é€Ÿå™¨ã€ä½åŠŸè€— CPUï¼‰
- **ç½‘ç»œæ¨¡æ‹Ÿ**ï¼š
  - å¸¦å®½èŒƒå›´ï¼š5â€“200 Mbps
  - å»¶è¿ŸèŒƒå›´ï¼š10â€“300 ms
- **è®­ç»ƒè½®æ•°**ï¼š50 epochsï¼Œé‡å¤ä¸‰æ¬¡ä»¥ç¡®ä¿ç»Ÿè®¡ç¨³å¥æ€§

### è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **é€šä¿¡æ•ˆç‡** | æ€»é€šä¿¡é‡ï¼ˆGBï¼‰ã€å¹³å‡åŒæ­¥å»¶è¿Ÿ |
| **æ¨¡å‹æ€§èƒ½** | Top-1 Accuracy (%)ã€Perplexity |
| **æ”¶æ•›è¡Œä¸º** | æ”¶æ•›æ‰€éœ€ epoch æ•°ã€è®­ç»ƒæŸå¤±æ›²çº¿ |
| **ç¨³å®šæ€§** | æ¢¯åº¦å‘æ•£ç¨‹åº¦ã€è¯¯å·®ç´¯ç§¯å½±å“ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **FullSync**ï¼šå…¨ç²¾åº¦ã€å…¨å‚æ•°åŒæ­¥ï¼ˆç†æƒ³åŸºå‡†ï¼‰
- **Top-k Sparsification**ï¼šä»…åŒæ­¥ Top-k æœ€å¤§æ¢¯åº¦ï¼ˆå…¸å‹ç¨€ç–åŒ–æ–¹æ³•ï¼‰
- **FedAvg-Periodic Sync**ï¼šè”é‚¦å­¦ä¹ å¸¸ç”¨å‘¨æœŸæ€§åŒæ­¥ç­–ç•¥

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| æ–¹æ³• | Top-1 Accuracy (%) | Perplexity | Communication Cost (GB) | Convergence Epochs |
|------|---------------------|-----------|----------------------------|------------------------|
| FullSync | 82.4 | 18.7 | 112.5 | 41 |
| Top-k Sparsification | 80.1 | 20.3 | 68.4 | 45 |
| FedAvg-Periodic Sync | 78.9 | 21.6 | 52.1 | 47 |
| **ACE-Sync (Proposed)** | **82.1** | **18.9** | **44.7** | **39** |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **é€šä¿¡æˆæœ¬é™ä½ 60%**ï¼šä» 112.5 GB â†’ **44.7 GB**ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–å‹ç¼©æ–¹æ³•ã€‚
- **æ”¶æ•›é€Ÿåº¦æœ€å¿«**ï¼šä»…éœ€ **39 epochs** å³æ”¶æ•›ï¼Œæ¯” FullSync å¿« 2 è½®ï¼Œè¿œè¶… Top-kï¼ˆ45ï¼‰å’Œ FedAvgï¼ˆ47ï¼‰ã€‚
- **ç²¾åº¦å‡ ä¹æ— æŸ**ï¼šTop-1 Accuracy ä¸º 82.1%ï¼Œä»…æ¯” FullSync ä½ **0.3%**ã€‚
- **å›°æƒ‘åº¦è¡¨ç°ä¼˜å¼‚**ï¼šPerplexity = 18.9ï¼Œæ¥è¿‘ FullSync çš„ 18.7ï¼Œæ˜æ˜¾ä¼˜äºå…¶ä»–å‹ç¼©æ–¹æ³•ã€‚

> ğŸ“ˆ å›¾2 æ˜¾ç¤º ACE-Sync çš„è®­ç»ƒæŸå¤±ä¸‹é™æœ€å¿«ï¼Œåœ¨ç¬¬20è½®æ—¶å·²æ˜¾è‘—é¢†å…ˆï¼ŒéªŒè¯äº†å…¶ä¼˜åŒ–æ•ˆç‡ã€‚

### æ¶ˆèå®éªŒä¸æœºåˆ¶æœ‰æ•ˆæ€§åˆ†æï¼ˆæ–‡ä¸­éšå«ï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»¥ä¸‹è®¾è®¡è¢«è¯æ˜è‡³å…³é‡è¦ï¼š
- **æ³¨æ„åŠ›é‡è¦æ€§ä¼°è®¡**ï¼šä½¿ç³»ç»Ÿèƒ½è¯†åˆ«å…³é”®æ¢¯åº¦ï¼Œé¿å…ç›²ç›®å‹ç¼©ã€‚
- **æ®‹å·®è¯¯å·®è¡¥å¿ï¼ˆresidual-based error compensationï¼‰**ï¼šé˜²æ­¢å‹ç¼©å¼•å…¥çš„åå·®ç§¯ç´¯å¯¼è‡´å‘æ•£ã€‚
- **è®¾å¤‡èšç±»ï¼ˆdevice clusteringï¼‰**ï¼šæå‡å¼‚æ„ç¯å¢ƒä¸‹çš„ä¸€è‡´æ€§ä¸ä¸ªæ€§åŒ–é€‚é…èƒ½åŠ›ã€‚
- **åŠ¨æ€å‹ç¼©è°ƒåº¦å‡½æ•°**ï¼šæ ¹æ®å®æ—¶å¸¦å®½è‡ªåŠ¨è°ƒèŠ‚å‹ç¼©å¼ºåº¦ï¼Œå¢å¼ºé²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è‡ªé€‚åº”åŒæ­¥ä¼˜äºé™æ€å‹ç¼©**ï¼šå›ºå®šç­–ç•¥æ— æ³•åº”å¯¹è®­ç»ƒåŠ¨æ€å˜åŒ–å’Œç½‘ç»œæ³¢åŠ¨ï¼Œè€Œ ACE-Sync çš„åŠ¨æ€å†³ç­–æœºåˆ¶å¯åœ¨ä¸åŒé˜¶æ®µçµæ´»è°ƒæ•´é€šä¿¡è¡Œä¸ºã€‚
2. **é‡è¦æ€§æ„ŸçŸ¥æ˜¯é«˜æ•ˆé€šä¿¡çš„å…³é”®**ï¼šé€šè¿‡ attention æœºåˆ¶åŒºåˆ†å‚æ•°é‡è¦æ€§ï¼Œèƒ½å¤Ÿåœ¨å¤§å¹…å‰Šå‡é€šä¿¡çš„åŒæ—¶ä¿æŒæ¨¡å‹è´¨é‡ã€‚
3. **äº‘è¾¹ååŒæ¶æ„æå‡å¯æ‰©å±•æ€§**ï¼šåˆ†å±‚ç»“æ„ä½¿å¾—è¾¹ç¼˜è½»é‡è¿è¡Œã€äº‘ç«¯ç»Ÿç­¹è°ƒåº¦ï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½²ã€‚
4. **é€šä¿¡æ•ˆç‡ä¸æ”¶æ•›é€Ÿåº¦å¯ä»¥å…¼å¾—**ï¼šACE-Sync ä¸ä»…å‡å°‘äº†é€šä¿¡å¼€é”€ï¼Œè¿˜å› æ›´æœ‰æ•ˆçš„ä¿¡æ¯ä¼ é€’åŠ å¿«äº†æ”¶æ•›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¡†æ¶ä¾èµ–ä¸€ä¸ªé¢å¤–çš„ attention æ¨¡å—ï¼Œå¸¦æ¥è½»å¾®è®¡ç®—å¼€é”€ï¼ˆå°½ç®¡ä½œè€…å¼ºè°ƒå…¶è½»é‡ï¼‰ã€‚
- å®éªŒé›†ä¸­åœ¨è¯­è¨€æ¨¡å‹ä»»åŠ¡ï¼Œå°šæœªå……åˆ†éªŒè¯åœ¨ CV æˆ–å¤šæ¨¡æ€ä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚
- ç½‘ç»œçŠ¶æ€å»ºæ¨¡ä»åŸºäºç»éªŒè§„åˆ™ï¼ˆå¦‚æŒ‡æ•°è¡°å‡å‡½æ•°ï¼‰ï¼Œç¼ºä¹æ›´æ™ºèƒ½çš„é¢„æµ‹æœºåˆ¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. å¼•å…¥ **Reinforcement Learning æˆ– Meta-Learning** æ¥ä¼˜åŒ–åŒæ­¥ç­–ç•¥ï¼Œè¿›ä¸€æ­¥æå‡è‡ªé€‚åº”èƒ½åŠ›ã€‚
2. æ‰©å±•è‡³ **multi-tenant æˆ– cross-cloud Federated Learning** åœºæ™¯ï¼Œæ”¯æŒæ›´å¤æ‚çš„è¾¹ç¼˜ç”Ÿæ€ã€‚
3. æ¨åŠ¨ **Hardware-Software Co-design**ï¼Œä¾‹å¦‚åˆ©ç”¨å¯ç¼–ç¨‹äº¤æ¢æœºæˆ–ç½‘ç»œæ„ŸçŸ¥ GPU kernel é™ä½å»¶è¿Ÿã€‚
4. åº”ç”¨äº **Foundation Models å’Œ Multi-modal Architectures**ï¼Œæ¢ç´¢æç«¯è§„æ¨¡ä¸‹çš„æ‰©å±•è¡Œä¸ºã€‚

---

## âœ… æ€»ç»“
ACE-Sync æå‡ºäº†ä¸€ç§**é€šä¿¡é«˜æ•ˆã€ç²¾åº¦ä¿ç•™ã€å¯æ‰©å±•æ€§å¼º**çš„å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒè§£å†³æ–¹æ¡ˆã€‚å®ƒé€šè¿‡**é‡è¦æ€§æ„ŸçŸ¥ + è‡ªé€‚åº”å‹ç¼© + äº‘è¾¹ååŒ**ä¸‰å¤§æ”¯æŸ±ï¼Œåœ¨çœŸå®å¼‚æ„ç¯å¢ƒä¸­å®ç°äº† **60% é€šä¿¡å‰Šå‡ã€æå‰ 2 è½®æ”¶æ•›ã€ä»… 0.3% ç²¾åº¦æŸå¤±**çš„å“è¶Šè¡¨ç°ï¼Œä¸ºæœªæ¥äº‘è¾¹ AI åŸºç¡€è®¾æ–½æä¾›äº†é‡è¦çš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 2. [Towards Efficient Agents: A Co-Design of Inference Architecture and System](https://arxiv.org/abs/2512.18337)

**Authors**: Weizhe Lin, Hui-Ling Zhen, Shuai Yang, Xian Wang, Renxi Liu, Hanting Chen, Wangze Zhang, Chuansai Zhou, Yiming Li, Chen Chen, Xing Li, Zhiyuan Yang, Xiaosong Li, Xianzhi Yu, Zhenhua Dong, Mingxuan Yuan, Yunhe Wang  
**Category**: cs.CL  
**Published**: 2025-12-23  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2512.18337v1  

#### Abstract
The rapid development of large language model (LLM)-based agents has unlocked new possibilities for autonomous multi-turn reasoning and tool-augmented decision-making. However, their real-world deployment is hindered by severe inefficiencies that arise not from isolated model inference, but from the...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Towards Efficient Agents: A Co-Design of Inference Architecture and System*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº **Large Language Model (LLM)** çš„è‡ªä¸»ä»£ç†ï¼ˆAutonomous Agentsï¼‰åœ¨å®é™…éƒ¨ç½²ä¸­é¢ä¸´ä¸¥é‡çš„æ•ˆç‡ç“¶é¢ˆã€‚è¿™äº›ç“¶é¢ˆå¹¶éæ¥è‡ªå•æ¬¡æ¨¡å‹æ¨ç†å»¶è¿Ÿï¼Œè€Œæ˜¯æºäº**å¤šè½®æ¨ç†å¾ªç¯ä¸­çš„ç³»ç»Ÿçº§å»¶è¿Ÿç´¯ç§¯**ï¼Œä¸»è¦åŒ…æ‹¬ï¼š
- **æ¨ç†å¾ªç¯ï¼ˆReasoning Loopsï¼‰**ï¼šæŒç»­çš„â€œThink-Act-Observeâ€å¾ªç¯å¯¼è‡´å¤§é‡åŒæ­¥ LLM è°ƒç”¨ã€‚
- **ä¸Šä¸‹æ–‡çˆ†ç‚¸ï¼ˆContext Explosionï¼‰**ï¼šå†å²è®°å¿†ä¸æ–­å¢é•¿ï¼Œå¼•å‘äºŒæ¬¡è®¡ç®—å¼€é”€ã€‚
- **å¼‚æ„å·¥å…·äº¤äº’ï¼ˆHeterogeneous Tool Interactionsï¼‰**ï¼šå¤–éƒ¨å·¥å…·è°ƒç”¨å¼•å…¥é«˜å¹¶å‘å’Œèµ„æºäº‰ç”¨ã€‚

ä¼ ç»Ÿä¼˜åŒ–æ–¹æ³•ï¼ˆå¦‚é‡åŒ–ã€å‰ªæã€è¿ç»­æ‰¹å¤„ç†ï¼‰ä¸“æ³¨äºæå‡æ¯ç§’ç”Ÿæˆ token æ•°ï¼ˆTPSï¼‰ï¼Œä½†åœ¨ä»£ç†åœºæ™¯ä¸‹å¯èƒ½å¯¼è‡´**æ¨ç†è´¨é‡ä¸‹é™ã€é‡è¯•å¢å¤šã€ç«¯åˆ°ç«¯å»¶è¿Ÿåè€Œä¸Šå‡**ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡º **AgentInfer**ï¼Œä¸€ä¸ªç»Ÿä¸€çš„ç«¯åˆ°ç«¯ä»£ç†åŠ é€Ÿæ¡†æ¶ï¼Œé€šè¿‡**æ¨ç†æ¶æ„ä¸ç³»ç»Ÿè®¾è®¡çš„ååŒä¼˜åŒ–ï¼ˆCo-Designï¼‰** æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**ä¼˜åŒ–ç›®æ ‡åº”ä»â€œæ¯ token ååé‡â€è½¬å‘â€œä»»åŠ¡å®Œæˆæ—¶é—´â€**ã€‚

AgentInfer åŒ…å«å››ä¸ªååŒå·¥ä½œçš„æ¨¡å—ï¼š

| æ¨¡å— | åŠŸèƒ½ |
|------|------|
| **AgentCollab** | åˆ†å±‚åŒæ¨¡å‹åä½œæ¡†æ¶ï¼šå¤§æ¨¡å‹è´Ÿè´£æˆ˜ç•¥è§„åˆ’ä¸æ•‘æ´ï¼Œå°æ¨¡å‹æ‰§è¡Œå¸¸è§„æ¨ç†ï¼›é€šè¿‡ `Progress Check` è‡ªæˆ‘è¯„ä¼°æœºåˆ¶åŠ¨æ€å‡é™çº§æ¨¡å‹ä½¿ç”¨ï¼Œå®ç°è®¤çŸ¥èµ„æºçš„é«˜æ•ˆåˆ†é…ã€‚ |
| **AgentCompress** | å¼‚æ­¥è¯­ä¹‰å‹ç¼©æœºåˆ¶ï¼šå¯¹ä»£ç†è®°å¿†è¿›è¡Œè½»é‡çº§è’¸é¦ä¸é‡ç»„ï¼Œåœ¨ä¸ä¸­æ–­æ¨ç†çš„å‰æä¸‹å‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œç¼“è§£ä¸Šä¸‹æ–‡çˆ†ç‚¸ã€‚ |
| **AgentSched** | ç¼“å­˜æ„ŸçŸ¥æ··åˆè°ƒåº¦å™¨ï¼šç»“åˆ Shortest-Job-First ä¸ KVCache ä¿ç•™ç­–ç•¥ï¼Œåˆ©ç”¨å½±å­ä»·æ ¼ï¼ˆshadow-priceï¼‰æ§åˆ¶å™¨åŠ¨æ€åˆ‡æ¢æ¨¡å¼ï¼Œå¹³è¡¡çŸ­è¯·æ±‚å“åº”é€Ÿåº¦ä¸é•¿ä¼šè¯ç¼“å­˜å‘½ä¸­ç‡ã€‚ |
| **AgentSAM** | åŸºäºåç¼€è‡ªåŠ¨æœºï¼ˆSuffix Automatonï¼‰çš„æ¨æµ‹è§£ç æ–¹æ³•ï¼šå¤ç”¨è·¨ä¼šè¯çš„è¯­ä¹‰è®°å¿†ï¼Œæå‡æ¨æµ‹ token çš„æ¥å—ç‡ï¼Œé™ä½ç”Ÿæˆå»¶è¿Ÿã€‚ |

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **ç³»ç»Ÿçº§è§†è§’**ï¼šä¸åŒäºå­¤ç«‹ä¼˜åŒ–æŸä¸€å±‚ï¼ˆå¦‚ä»…æ¨¡å‹æˆ–ä»…è°ƒåº¦ï¼‰ï¼ŒAgentInfer å®ç°äº†**æ¨ç†é€»è¾‘ä¸åº•å±‚ç³»ç»Ÿçš„æ·±åº¦ååŒ**ã€‚
- **ä»»åŠ¡å¯¼å‘ä¼˜åŒ–**ï¼šä»¥â€œä»»åŠ¡å®Œæˆæ—¶é—´â€ä¸ºæ ¸å¿ƒæŒ‡æ ‡ï¼Œé¿å…â€œæ›´å¿«ä½†æ›´é”™â€çš„é™·é˜±ã€‚
- **è‡ªé€‚åº”ä¸é—­ç¯æ§åˆ¶**ï¼šå„æ¨¡å—å…·å¤‡åé¦ˆæœºåˆ¶ï¼ˆå¦‚ Progress Checkã€å½±å­ä»·æ ¼ï¼‰ï¼Œå½¢æˆè‡ªæˆ‘æ¼”åŒ–çš„æ¨ç†å¼•æ“ï¼ˆSelf-Evolution Engineï¼‰ã€‚
- **ç»¼åˆå¢ç›Šæ˜¾è‘—**ï¼šå„æ¨¡å—äº’è¡¥ï¼Œå åŠ æ•ˆæœè¿œè¶…å•ä¸€æŠ€æœ¯ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **BrowseComp-zh**ï¼šä¸­æ–‡ç‰ˆç½‘é¡µæµè§ˆèƒ½åŠ›åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«éœ€å¤šæ­¥ web search çš„å¤æ‚ä»»åŠ¡ã€‚
- **DeepDiver**ï¼šç”¨äºéªŒè¯æ•´ä½“ç³»ç»Ÿæ€§èƒ½çš„æ·±ç ”ä»£ç†åŸºå‡†ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹é…ç½®**ï¼š
  - å¤§æ¨¡å‹ï¼ˆMLï¼‰ï¼š`openPangu-DeepDiverV2-38B`
  - å°æ¨¡å‹ï¼ˆMsï¼‰ï¼š`openPangu-DeepDiverV2-7B`
  - å‹ç¼©æ¨¡å‹ï¼š`openPangu-7B`
- **ç¡¬ä»¶å¹³å°**ï¼šAscend 910B3 NPUsï¼Œä½¿ç”¨ `vLLM-Ascend v0.9.1` æ¨ç†å¼•æ“ã€‚
- **å¹¶è¡Œé…ç½®**ï¼šæµ‹è¯•ä¸åŒ Tensor Parallelismï¼ˆTPï¼‰å’Œå¹¶å‘ä¼šè¯æ•°ï¼ˆNparallelï¼‰ä¸‹çš„æ€§èƒ½ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| **End-to-End Latency** | å®Œæˆæ•´ä¸ªä»»åŠ¡çš„å¢™é’Ÿæ—¶é—´ï¼ˆWall-clock Timeï¼‰ |
| **QPS (Queries Per Second)** | æ¯ç§’å¯å¤„ç†çš„ä»»åŠ¡æ•°é‡ |
| **Speedup** | ç›¸å¯¹äºåŸºçº¿çš„åŠ é€Ÿæ¯” |
| **Token Consumption** | æ€»ç”Ÿæˆ token æ•°ï¼Œè¡¡é‡è®¡ç®—æˆæœ¬ |
| **KV Cache Hit Rate** | ç¼“å­˜å‘½ä¸­ç‡ï¼Œå½±å“ Prefill é˜¶æ®µå¼€é”€ |
| **Task Accuracy / Success Rate** | ä»»åŠ¡å®Œæˆæ­£ç¡®ç‡ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**ï¼šåŸç”Ÿ LLM ä»£ç†ï¼Œé¡ºåºæ‰§è¡Œï¼Œæ— ä¼˜åŒ–ã€‚
- **Large-model only**ï¼šå…¨ç¨‹ä½¿ç”¨å¤§æ¨¡å‹ã€‚
- **Small-model only**ï¼šå…¨ç¨‹ä½¿ç”¨å°æ¨¡å‹ã€‚
- **FCFS / SJF Scheduler**ï¼šæ ‡å‡†å…ˆæ¥å…ˆæœåŠ¡ / æœ€çŸ­ä½œä¸šä¼˜å…ˆè°ƒåº¦å™¨ã€‚
- **SAM speculative decoding**ï¼šåŸºç¡€ç‰ˆæœ¬çš„æ¨æµ‹è§£ç ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **æ•´ä½“æ€§èƒ½æå‡**ï¼š
  - AgentInfer åœ¨ BrowseComp-zh å’Œ DeepDiver ä¸Šå®ç°äº† **1.8Ã—â€“2.5Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿ**ã€‚
  - **æ— æ•ˆ token æ¶ˆè€—å‡å°‘è¶…è¿‡ 50%**ã€‚
  - ä¿æŒä¸å¤§æ¨¡å‹ç›¸å½“çš„å‡†ç¡®ç‡ï¼ˆ33.8% vs 34.6%ï¼‰ã€‚

| æ–¹æ³• | å‡†ç¡®ç‡ (%) | åŠ é€Ÿæ¯” |
|------|------------|--------|
| Large-model only | 34.6 | 1.00Ã— |
| Small-model only | 18.3 | 1.54Ã— |
| **AgentCollab** | **33.8** | **1.32Ã—** |

> AgentCollab åœ¨å‡ ä¹ä¸æŸå¤±ç²¾åº¦çš„æƒ…å†µä¸‹ï¼Œè·å¾—æ˜¾è‘—åŠ é€Ÿã€‚

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **AgentSched vs FCFS/SJF**ï¼š
  - ç›¸æ¯” FCFSï¼Œ**ç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½ 9.6%**ï¼Œ**KV Cache Hit Rate æå‡è‡³ 72%**ï¼ˆFCFS: 63%ï¼ŒSJF: 58%ï¼‰ã€‚
  - æˆåŠŸé¿å… SJF å¯¼è‡´çš„é•¿ä¼šè¯ç¼“å­˜é©±é€é—®é¢˜ã€‚

- **AgentSAM vs åŸºç¡€ SAM**ï¼š
  - **ç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½ 21.2%**ï¼ˆåŸºç¡€ SAM ä¸º 16.3%ï¼‰ã€‚
  - **LLM è§£ç å»¶è¿Ÿé™ä½ 26.0%**ï¼ˆåŸºç¡€ SAM ä¸º 20.7%ï¼‰ã€‚
  - å½’å› äºè·¨ä¼šè¯è®°å¿†å¢å¼ºå¸¦æ¥çš„æ›´é«˜ Speculative Hit Rateã€‚

- **AgentCompress**ï¼š
  - ä¸Šä¸‹æ–‡é•¿åº¦ä» >40K tokens å‹ç¼©è‡³ ~20Kã€‚
  - ç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½ **6â€“42%**ï¼Œå…·ä½“å–å†³äºè´Ÿè½½å‹åŠ›ã€‚
  - ä¿ç•™æ¨ç†è®°å¿†ï¼ˆreasoning tracesï¼‰è‡³å…³é‡è¦ï¼Œå¦åˆ™ä¼šå¯¼è‡´è®¤çŸ¥æ··ä¹±å’Œå»¶è¿Ÿå¢åŠ ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### è¡¨ï¼šAgentSched ç¼“å­˜ç»„ä»¶æ¶ˆèï¼ˆTable 9ï¼‰
| ç»„åˆå˜ä½“ | ç«¯åˆ°ç«¯å»¶è¿Ÿå˜åŒ– | å¯¹è¯è½®æ•° |
|----------|----------------|----------|
| åŸºçº¿ | 0% | 1.0Ã— |
| ç§»é™¤ reasoning traces | **+31.98%** | 1.12Ã— |
| ç§»é™¤ summary | **+21.32%** | 1.09Ã— |
| ç§»é™¤æœ€è¿‘å·¥å…·å“åº” | **+29.50%** | 1.26Ã— |

> ç»“è®ºï¼šæœ‰æ•ˆçš„å‹ç¼©å¿…é¡»é€‰æ‹©æ€§ä¿ç•™è¯­ä¹‰ä¸°å¯Œçš„ä¿¡æ¯ï¼Œè€Œéå•çº¯æœ€å°åŒ–ä¸Šä¸‹æ–‡é•¿åº¦ã€‚

#### è¡¨ï¼šå…¨ç³»ç»Ÿé›†æˆæ•ˆæœï¼ˆTable 13ï¼‰
| æ–¹æ³• | QPS æå‡ (Nparallel=4) | QPS æå‡ (Nparallel=16) |
|------|------------------------|-------------------------|
| Baseline | 1.00Ã— | 1.00Ã— |
| +AgentCollab | 1.32Ã— | 1.52Ã— |
| +Compress | 1.57Ã— | 2.01Ã— |
| +Sched | 1.71Ã— | 2.25Ã— |
| **+SAM (å®Œæ•´ç³»ç»Ÿ)** | **1.97Ã—** | **2.52Ã—** |

> æ‰€æœ‰æ¨¡å—è´¡çŒ®**ç´¯ç§¯ä¸”äº’è¡¥**ï¼Œæœ€ç»ˆå®ç°æ¥è¿‘ 2.5 å€ååæå‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ä»£ç†æ•ˆç‡ä¸èƒ½ä»…é å•ç‚¹ä¼˜åŒ–**ï¼šä¼ ç»Ÿ TPS æŒ‡æ ‡åœ¨ä»£ç†åœºæ™¯ä¸‹å…·æœ‰è¯¯å¯¼æ€§ï¼Œå¿…é¡»è½¬å‘ä»¥â€œä»»åŠ¡å®Œæˆæ—¶é—´â€ä¸ºæ ¸å¿ƒçš„ç³»ç»Ÿçº§ä¼˜åŒ–ã€‚
2. **ååŒè®¾è®¡ï¼ˆCo-Designï¼‰æ˜¯å…³é”®**ï¼šå°†æ¨ç†é€»è¾‘ï¼ˆå¦‚ AgentCollab çš„è‡ªæˆ‘è¯„ä¼°ï¼‰ä¸ç³»ç»Ÿæœºåˆ¶ï¼ˆå¦‚ AgentSched çš„ç¼“å­˜æ„ŸçŸ¥è°ƒåº¦ï¼‰ç´§å¯†ç»“åˆï¼Œæ‰èƒ½å®ç°çœŸæ­£çš„æ•ˆç‡çªç ´ã€‚
3. **è®°å¿†ç®¡ç†è‡³å…³é‡è¦**ï¼šä¸Šä¸‹æ–‡å‹ç¼©å¿…é¡»ä¿ç•™æ¨ç†è½¨è¿¹ï¼Œå¦åˆ™ä¼šå¯¼è‡´è®¤çŸ¥æ–­è£‚å’Œæ€§èƒ½é€€åŒ–ã€‚
4. **è‡ªé€‚åº”æœºåˆ¶æœ‰æ•ˆ**ï¼šå½±å­ä»·æ ¼ï¼ˆAgentSchedï¼‰ã€åŠ¨æ€æ¨¡å‹åˆ‡æ¢ï¼ˆAgentCollabï¼‰ã€å¼‚æ­¥å‹ç¼©ç­‰æœºåˆ¶èƒ½æœ‰æ•ˆåº”å¯¹åŠ¨æ€è´Ÿè½½ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¡†æ¶ä¾èµ–äº**æ˜¾å¼çš„ Progress Check ç»“æ„åŒ–è¾“å‡º**ï¼Œå¯èƒ½é™åˆ¶é€šç”¨æ€§ã€‚
- **è·¨ä¼šè¯è®°å¿†æ£€ç´¢**ï¼ˆAgentSAMï¼‰çš„æ•ˆæœä¾èµ–äºæŸ¥è¯¢ç›¸ä¼¼åº¦ï¼Œå†·å¯åŠ¨æˆ–ç¨€æœ‰ä»»åŠ¡å¯èƒ½æ”¶ç›Šæœ‰é™ã€‚
- åœ¨æé«˜å¹¶å‘ä¸‹ï¼ˆå¦‚ Nparallel=16ï¼‰ï¼Œæ¨æµ‹è§£ç ï¼ˆAgentSAMï¼‰å¯èƒ½è¢«ç¦ç”¨ï¼Œè¾¹é™…å¢ç›Šä¸‹é™ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é€šç”¨çš„è‡ªæˆ‘è¯„ä¼°ä¿¡å·æå–æ–¹å¼ï¼Œå‡å°‘å¯¹ç»“æ„åŒ–è¾“å‡ºçš„ä¾èµ–ã€‚
- æ„å»ºæ›´æ™ºèƒ½çš„é•¿æœŸè®°å¿†å­˜å‚¨ä¸æ£€ç´¢æœºåˆ¶ï¼ˆLong-Term Memory Storeï¼‰ã€‚
- å°† AgentInfer æ¡†æ¶æ‰©å±•è‡³å¤šæ¨¡æ€ä»£ç†å’Œå®æ—¶å†³ç­–ç³»ç»Ÿã€‚
- ç ”ç©¶ä»£ç†ç³»ç»Ÿçš„è‡ªä¼˜åŒ–ä¸åœ¨çº¿å­¦ä¹ èƒ½åŠ›ï¼Œå®ç°çœŸæ­£çš„â€œè‡ªæˆ‘è¿›åŒ–â€ã€‚

---

> **æ€»ç»“**ï¼š  
> *AgentInfer* é€šè¿‡ **AgentCollabã€AgentCompressã€AgentSchedã€AgentSAM** å››å¤§æ¨¡å—çš„ååŒè®¾è®¡ï¼ŒæˆåŠŸè§£å†³äº† LLM ä»£ç†åœ¨çœŸå®åœºæ™¯ä¸­çš„æ•ˆç‡ç“¶é¢ˆã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ä¿æŒé«˜å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œå®ç°äº† **1.8â€“2.5 å€çš„ç«¯åˆ°ç«¯åŠ é€Ÿ** å’Œ **è¶…è¿‡ 50% çš„ token æ¶ˆè€—é™ä½**ï¼Œä¸ºæ„å»ºé«˜æ•ˆã€å¯æ‰©å±•çš„è‡ªä¸»æ™ºèƒ½ç³»ç»Ÿæä¾›äº†é‡è¦èŒƒå¼ã€‚

</details>

---

### 3. [Efficient Mixture-of-Agents Serving via Tree-Structured Routing, Adaptive Pruning, and Dependency-Aware Prefill-Decode Overlap](https://arxiv.org/abs/2512.18126)

**Authors**: Zijun Wang, Yijiahao Qi, Hanqiu Chen, Zishen Wan, Gongjin Sun, Dongyang Li, Shuyi Pei, Cong Hao  
**Category**: cs.AI  
**Published**: 2025-12-23  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2512.18126v1  

#### Abstract
Mixture-of-Agents (MoA) inference can suffer from dense inter-agent communication and low hardware utilization, which jointly inflate serving latency. We present a serving design that targets these bottlenecks through an algorithm-system co-design. First, we replace dense agent interaction graphs wi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEfficient Mixture-of-Agents Serving via Tree-Structured Routing, Adaptive Pruning, and Dependency-Aware Prefill-Decode Overlap

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹ **Mixture-of-Agents (MoA)** æ¨ç†ç³»ç»Ÿä¸­å­˜åœ¨çš„ä¸¤å¤§ç“¶é¢ˆé—®é¢˜ï¼š

1. **å†—ä½™çš„ä»£ç†é—´é€šä¿¡**ï¼šä¼ ç»Ÿ MoA ç³»ç»Ÿé‡‡ç”¨å…¨è¿æ¥ï¼ˆall-to-allï¼‰æ‹“æ‰‘ç»“æ„ï¼Œå¯¼è‡´å¤§é‡ä½æ•ˆç”šè‡³æ— æ„ä¹‰çš„ä¿¡æ¯äº¤æ¢ï¼Œå¢åŠ ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆE2E latencyï¼‰ã€‚
2. **ç¡¬ä»¶åˆ©ç”¨ç‡ä½ä¸‹**ï¼š
   - å±‚çº§åŒæ­¥æœºåˆ¶ä½¿å¾—æ•´ä¸ªå±‚çš„å»¶è¿Ÿç”±æœ€æ…¢çš„ agent å†³å®šï¼›
   - ç°æœ‰ LLM serving æ¡†æ¶æœªè€ƒè™‘ agent ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œæ— æ³•æœ‰æ•ˆé‡å  prefill å’Œ decode é˜¶æ®µã€‚

è¿™äº›é—®é¢˜å…±åŒå¯¼è‡´ MoA ç³»ç»Ÿè™½ç„¶åœ¨å‡†ç¡®æ€§ä¸Šæœ‰æ½œåŠ›ï¼Œä½†åœ¨å®é™…éƒ¨ç½²ä¸­é¢ä¸´é«˜å»¶è¿Ÿå’Œä½ååçš„é—®é¢˜ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **Faster-MoA**ï¼Œä¸€ä¸ªç®—æ³•-ç³»ç»ŸååŒè®¾è®¡çš„é«˜æ•ˆ MoA æœåŠ¡æ¡†æ¶ï¼ŒåŒ…å«ä¸‰å¤§æ ¸å¿ƒæŠ€æœ¯ï¼š

#### â‘  **Hierarchical Tree Topologyï¼ˆåˆ†å±‚æ ‘çŠ¶æ‹“æ‰‘ï¼‰**
- å°†ä¼ ç»Ÿçš„ all-to-all è¿æ¥æ›¿æ¢ä¸ºæ ‘å½¢ç»“æ„ï¼šæ¯å±‚ agent è¢«åˆ’åˆ†ä¸ºè‹¥å¹² clusterï¼Œä¸‹ä¸€å±‚æ¯ä¸ª agent åªæ¥æ”¶å¯¹åº” cluster çš„è¾“å‡ºã€‚
- å®ç°å±€éƒ¨èšåˆ â†’ å…¨å±€èšåˆï¼Œæ˜¾è‘—å‡å°‘å†—ä½™é€šä¿¡å’Œä¸Šä¸‹æ–‡é•¿åº¦ã€‚
- æ”¯æŒè·¨åˆ†æ”¯å¹¶è¡Œæ‰§è¡Œï¼Œé¿å…å…¨å±€å±‚åŒæ­¥å¸¦æ¥çš„ stall timeã€‚

#### â‘¡ **Dynamic Early-Exit (EE) Mechanismï¼ˆåŠ¨æ€æ—©é€€æœºåˆ¶ï¼‰**
- åœ¨è¿è¡Œæ—¶åŸºäºå°æ¨¡å‹ï¼ˆå¦‚ 4B/8Bï¼‰çš„è¾“å‡ºè¯­ä¹‰ç›¸ä¼¼æ€§å’Œç½®ä¿¡åº¦ï¼ˆconfidenceï¼‰ï¼Œå†³å®šæ˜¯å¦è·³è¿‡å¤§æ¨¡å‹ï¼ˆå¦‚ 32Bï¼‰çš„æ¨ç†ã€‚
- åˆ©ç”¨å…±äº« embedding modelï¼ˆQwen3-Embedding-4Bï¼‰è®¡ç®— Frobenius Cosine Similarityï¼ˆFCSï¼‰è¡¡é‡è¯­ä¹‰ä¸€è‡´æ€§ã€‚
- ç»¼åˆ confidence å’Œ similarity å¾—å‡º early-exit æ¦‚ç‡ $ Q = \sqrt{C \cdot B} $ï¼Œå®ç°è‡ªé€‚åº”å‰ªæã€‚

#### â‘¢ **Dependency-Aware Incremental Prefillingï¼ˆä¾èµ–æ„ŸçŸ¥å¢é‡é¢„å¡«å……ï¼‰**
- å°†å‰é©± agent çš„ decode é˜¶æ®µæ‹†åˆ†ä¸ºå­é˜¶æ®µï¼Œå¹¶å°†ç”Ÿæˆçš„ token æµå¼ä¼ è¾“ç»™åç»§ agent è¿›è¡Œå¢é‡ prefillã€‚
- å¤ç”¨å·²æœ‰çš„ KV Cacheï¼Œä»…å¯¹æ–°å¢ token é‡æ–°è®¡ç®— KVï¼Œæå¤§é™ä½é‡å¤ prefill å¼€é”€ã€‚
- å¼•å…¥ **Shell Router** å’Œ **Agent Prompt Cache (APC)** åè°ƒä¾èµ–è°ƒåº¦ï¼Œå®ç° prefill-decode çš„è·¨ agent é‡å ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | æœ€å¤šé™ä½ **90% çš„ E2E å»¶è¿Ÿ**ï¼ŒGPU åˆ©ç”¨ç‡æå‡ï¼Œå‡å°‘ idle æ—¶é—´ |
| **å‡†ç¡®æ€§** | ä¿æŒä¸ all-to-all åŸºçº¿ç›¸å½“ï¼ˆÂ±1%ï¼‰ç”šè‡³æ›´é«˜ï¼ˆåœ¨éƒ¨åˆ†ä»»åŠ¡ä¸Šï¼‰ |
| **å¯æ‰©å±•æ€§** | æ ‘ç»“æ„æ”¯æŒæ›´å¤§è§„æ¨¡ agent éƒ¨ç½²è€Œä¸å¼•å‘é€šä¿¡çˆ†ç‚¸ |
| **ç³»ç»Ÿå…¼å®¹æ€§** | é€‚é…ä¸»æµ LLM serving æ¡†æ¶ï¼ˆSGLang/vLLMï¼‰ï¼Œæ— éœ€ä¿®æ”¹åº•å±‚å¼•æ“ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

å…±äº”ä¸ªåŸºå‡†æµ‹è¯•ï¼Œè¦†ç›–æ•°å­¦æ¨ç†ä¸ç§‘å­¦é—®ç­”ï¼š

| æ•°æ®é›† | æè¿° |
|--------|------|
| **GSM8K** | å°å­¦çº§åˆ«æ•°å­¦åº”ç”¨é¢˜ï¼Œç›¸å¯¹ç®€å• |
| **MATH-500** | ä¸­ç­‰éš¾åº¦æ•°å­¦é—®é¢˜é›†åˆ |
| **AIME2025** | é«˜ä¸­å¥¥æ•°çº§åˆ«éš¾é¢˜ï¼ŒæŒ‘æˆ˜æ€§å¼º |
| **MMLU-ProX-Lite** | å¤šå­¦ç§‘ STEM ç§‘å­¦é—®ç­” |
| **IFBench** | æŒ‡ä»¤è·Ÿéšèƒ½åŠ›è¯„æµ‹ |

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹é€‰æ‹©**
- ä½¿ç”¨ Qwen æ¨¡å‹å®¶æ—ä»¥é¿å… tokenizer ä¸ä¸€è‡´é—®é¢˜ï¼š
  - Qwen3-VL-4B-Instruct
  - Qwen3-VL-8B-Instruct
  - Qwen3-VL-32B-Instruct
  - è¾…åŠ©æ¨¡å‹ï¼šQwen3-Embedding-4Bï¼ˆç”¨äºè¯­ä¹‰ç›¸ä¼¼æ€§è®¡ç®—ï¼‰

#### **ç¡¬ä»¶å¹³å°**
- **6 Ã— NVIDIA H200 GPUs**ï¼ˆå•å° H200 HGX Serverï¼‰
- æ¯ä¸ªæ¨¡å‹åˆ†é…ç‹¬ç«‹çš„ Prefill Engine å’Œ Decode Engine
- ä½¿ç”¨ NVLink å®ç°é«˜é€Ÿ KV Cache ä¼ è¾“

#### **è¯„ä¼°æŒ‡æ ‡**
- **End-to-End Latency (E2E)**ï¼šä»è¾“å…¥åˆ°æœ€ç»ˆè¾“å‡ºçš„æ—¶é—´
- **Accuracy**ï¼šä»»åŠ¡æ­£ç¡®ç‡
- **Model Activation Rate**ï¼šå„ size æ¨¡å‹è¢«è°ƒç”¨çš„æ¯”ä¾‹
- **KV Cache Hit Rate**ï¼šå¢é‡ prefill çš„ç¼“å­˜å‘½ä¸­ç‡

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| è®¾ç½®ç¼–å· | åç§° | æè¿° |
|--------|------|------|
| #1 | All-to-all Baseline | ä¸‰å±‚å…¨è¿æ¥ç»“æ„ï¼ˆ9â†’9â†’1ï¼‰ |
| #2 | Tree only | 9-3-1 æ ‘ç»“æ„ï¼Œæ— å…¶ä»–ä¼˜åŒ– |
| #3 | Tree + Incremental Prefilling | åŠ å…¥å¢é‡ prefill |
| #4 | **Faster-MoA**ï¼ˆå®Œæ•´ç‰ˆï¼‰ | æ ‘ç»“æ„ + åŠ¨æ€ EE + å¢é‡ prefill |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æ–¹æ³• | å¹³å‡ E2E å»¶è¿Ÿä¸‹é™ | å‡†ç¡®ç‡å˜åŒ– |
|------|------------------|-----------|
| Tree only | ~62% | Â±1% å†…æ³¢åŠ¨ |
| Tree + Incremental Prefill | ~76% | æ— å½±å“ï¼ˆä»…è°ƒåº¦ä¼˜åŒ–ï¼‰ |
| **Faster-MoAï¼ˆå®Œæ•´ï¼‰** | **æœ€é«˜è¾¾ 90%** | **æŒå¹³æˆ–æ›´é«˜** |

> æ³¨ï¼šå»¶è¿Ÿä¸‹é™æ˜¯åœ¨ç›¸åŒå‡†ç¡®ç‡æ°´å¹³ä¸‹çš„æµ‹é‡ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- åœ¨æ‰€æœ‰æ•°æ®é›†ä¸­ï¼Œ**Faster-MoA æ˜¾è‘—ä¼˜äº all-to-all åŸºçº¿**ï¼š
  - **GSM8K**: å»¶è¿Ÿ â†“85%, å‡†ç¡®ç‡ 93.9% vs 94.0%
  - **MATH-500**: å»¶è¿Ÿ â†“88%, å‡†ç¡®ç‡ 90.6% vs 90.4%
  - **AIME2025**: å»¶è¿Ÿ â†“82%, å‡†ç¡®ç‡ **56.5% vs 53.4% â†‘**
  - **MMLU-ProX-Lite**: å»¶è¿Ÿ â†“89%, å‡†ç¡®ç‡ **60.0% vs 55.6% â†‘**
  - **IFBench**: å»¶è¿Ÿ â†“73%, å‡†ç¡®ç‡ 34.6% vs 34.6%

ğŸ‘‰ **ç‰¹åˆ«å‘ç°**ï¼šåœ¨è¾ƒéš¾ä»»åŠ¡ï¼ˆAIME2025ã€MMLU-ProX-Liteï¼‰ä¸Šï¼ŒFaster-MoA **åè€Œæå‡äº†å‡†ç¡®ç‡**ï¼Œè¯´æ˜åŠ¨æ€ EE æˆåŠŸè¿‡æ»¤äº†å¼±æ¨¡å‹çš„å™ªå£°è¾“å‡ºï¼Œæé«˜äº†èåˆè´¨é‡ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ï¼ˆ1ï¼‰åŠ¨æ€ Early Exit åˆ†æï¼ˆå›¾ 4(i)ï¼‰
- **å°æ¨¡å‹æ¿€æ´»ç‡è¿œé«˜äºå¤§æ¨¡å‹**ï¼š
  - åœ¨ GSM8K ä¸Šï¼Œ32B æ¨¡å‹ä»…è¢«è°ƒç”¨çº¦ 7% çš„æ ·æœ¬
  - åœ¨ IFBench ä¸Šå‡è‡³ ~18%ï¼Œä½“ç°å…¶è‡ªé€‚åº”æ€§
- **Early Exit åˆ¤æ–­å¼€é”€ä»…å¢åŠ  ~5% å»¶è¿Ÿ**ï¼Œä½†å¸¦æ¥ 10%~50% çš„æ•´ä½“å»¶è¿Ÿä¸‹é™

#### ï¼ˆ2ï¼‰å¢é‡ Prefill æ•ˆæœï¼ˆå›¾ 4(iii)ï¼‰
- ç›¸æ¯”ä¸‰ç§ baselineï¼ˆNaive PDã€Data Parallelismã€Chunked Prefillï¼‰ï¼Œ**å¢é‡ prefill åœ¨ç¬¬äºŒå±‚èšåˆå™¨ä¸Šå¹³å‡é™ä½ 27.4% å»¶è¿Ÿ**
- KV Cache Hit Rate æ¥è¿‘ 100%ï¼ŒéªŒè¯äº†å¢é‡æ›´æ–°çš„æœ‰æ•ˆæ€§

#### ï¼ˆ3ï¼‰ç»¼åˆæ•ˆæœï¼ˆå›¾ 4(ii)ï¼‰
- æ‰€æœ‰ä¼˜åŒ–å åŠ åï¼Œ**å»¶è¿ŸæŒç»­é€’å‡ï¼Œä¸”æ— ç²¾åº¦æŸå¤±**
- è¯æ˜ä¸‰ä¸ªæŠ€æœ¯æ¨¡å—å…·æœ‰æ­£å‘ååŒæ•ˆåº”

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **ç¨€ç–åŒ–è¿æ¥ä¼˜äºå…¨è¿æ¥**ï¼šæ ‘çŠ¶æ‹“æ‰‘é€šè¿‡ç»“æ„åŒ–ç¨€ç–å‡å°‘äº†å†—ä½™é€šä¿¡ï¼Œåœ¨å¤šæ•°ä»»åŠ¡ä¸­æ— éœ€å…¨è¿æ¥å³å¯è¾¾åˆ°åŒç­‰ç”šè‡³æ›´ä¼˜æ€§èƒ½ã€‚
2. âœ… **åŠ¨æ€å‰ªæå¯è¡Œä¸”æœ‰æ•ˆ**ï¼šåˆ©ç”¨è¯­ä¹‰ç›¸ä¼¼æ€§å’Œç½®ä¿¡åº¦ä¿¡å·è¿›è¡Œ early exitï¼Œèƒ½æ™ºèƒ½è·³è¿‡ä¸å¿…è¦çš„å¤§æ¨¡å‹è°ƒç”¨ï¼Œå¤§å¹…èŠ‚çœèµ„æºã€‚
3. âœ… **ä¾èµ–æ„ŸçŸ¥æµæ°´çº¿å¯è¡Œ**ï¼šé€šè¿‡å¢é‡ prefill æŠ€æœ¯ï¼Œå¯åœ¨å­˜åœ¨æ•°æ®ä¾èµ–çš„æƒ…å†µä¸‹å®ç° prefill-decode é‡å ï¼Œæ‰“ç ´ä¼ ç»Ÿä¸²è¡Œç“¶é¢ˆã€‚
4. âœ… **æ€§èƒ½ä¸ç²¾åº¦åŒèµ¢**ï¼šFaster-MoA ä¸ä»…æ˜¾è‘—é™ä½å»¶è¿Ÿï¼ˆup to 90%ï¼‰ï¼Œè¿˜åœ¨å¤æ‚ä»»åŠ¡ä¸Šæå‡äº†å‡†ç¡®ç‡ï¼Œè¡¨æ˜â€œå°‘è€Œç²¾â€çš„ agent åä½œä¼˜äºâ€œå¤šè€Œæ‚â€ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ–ç‰¹å®šæ¨¡å‹æ—**ï¼šå½“å‰å®ç°åŸºäº Qwen å®¶æ—ï¼Œè‹¥è·¨ä¸åŒ tokenizer çš„æ¨¡å‹éœ€é¢å¤–å¤„ç†æ–‡æœ¬æ‹¼æ¥ä¸å¯¹é½ã€‚
2. **embedding model å¼€é”€**ï¼šè¯­ä¹‰ç›¸ä¼¼æ€§è®¡ç®—éœ€è¦é¢å¤–è°ƒç”¨ embedding modelï¼Œå¯èƒ½æˆä¸ºè½»é‡çº§åœºæ™¯çš„è´Ÿæ‹…ã€‚
3. **æ ‘ç»“æ„å›ºå®š**ï¼šç›®å‰é‡‡ç”¨å›ºå®šçš„ 9-3-1 ç»“æ„ï¼Œå°šæœªæ¢ç´¢è‡ªåŠ¨å­¦ä¹ æœ€ä¼˜æ‹“æ‰‘çš„èƒ½åŠ›ã€‚
4. **é•¿å°¾ç”Ÿæˆé£é™©**ï¼šå°½ç®¡æ ‘ç»“æ„éš”ç¦»äº† straggler å½±å“ï¼Œä½†æç«¯é•¿è¾“å‡ºä»å¯èƒ½é˜»å¡ä¸‹æ¸¸ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **è‡ªåŠ¨åŒ–æ‹“æ‰‘æœç´¢**ï¼šç»“åˆå¼ºåŒ–å­¦ä¹ æˆ–è¿›åŒ–ç®—æ³•ï¼ŒåŠ¨æ€ç”Ÿæˆæœ€ä¼˜ agent è¿æ¥ç»“æ„ã€‚
2. **è½»é‡åŒ– EE åˆ¤æ–­æœºåˆ¶**ï¼šç ”ç©¶ä¸ä¾èµ–å¤–éƒ¨ embedding model çš„å†…éƒ¨è¡¨ç¤ºç›¸ä¼¼æ€§åº¦é‡ã€‚
3. **æ”¯æŒå¼‚æ„æ¨¡å‹æ± **ï¼šæ‰©å±•æ¡†æ¶ä»¥å…¼å®¹ä¸åŒå‚å•†ã€ä¸åŒ tokenizer çš„ LLMã€‚
4. **åœ¨çº¿å­¦ä¹ å‹è·¯ç”±ç­–ç•¥**ï¼šè®©ç³»ç»Ÿæ ¹æ®å†å²è¡¨ç°åŠ¨æ€è°ƒæ•´ early-exit é˜ˆå€¼å’Œè·¯ç”±è·¯å¾„ã€‚
5. **é›†æˆ MoE æ€æƒ³**ï¼šå°† Faster-MoA ä¸ Mixture-of-Experts æ¶æ„ç»“åˆï¼Œæ„å»º hybrid å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> Faster-MoA é€šè¿‡ **Tree-Structured Routing + Adaptive Pruning + Dependency-Aware Prefill-Decode Overlap** ä¸‰é‡åˆ›æ–°ï¼Œåœ¨å‡ ä¹ä¸ç‰ºç‰²å‡†ç¡®æ€§çš„å‰æä¸‹ï¼Œå®ç°äº† MoA ç³»ç»Ÿé«˜è¾¾ **90% çš„å»¶è¿Ÿå‹ç¼©**ï¼Œä¸ºå¤§è§„æ¨¡å¤šä»£ç†ç³»ç»Ÿçš„é«˜æ•ˆéƒ¨ç½²æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 4. [TraCT: Disaggregated LLM Serving with CXL Shared Memory KV Cache at Rack-Scale](https://arxiv.org/abs/2512.18194)

**Authors**: Dongha Yoon, Younghoon Min, Hoshik Kim, Sam H. Noh, Jongryool Kim  
**Category**: cs.DC  
**Published**: 2025-12-23  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.18194v1  

#### Abstract
Disaggregated LLM serving improves resource efficiency by separating the compute-intensive prefill phase from the latency-critical decode phase. However, this architecture introduces a fundamental bottleneck: key/value (KV) tensors generated during prefill must be transferred to decode workers, and ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTraCT: Disaggregated LLM Serving with CXL Shared Memory KV Cache at Rack-Scale

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ç³»ç»Ÿå¹¿æ³›é‡‡ç”¨**è§£è€¦æ¶æ„**ï¼ˆdisaggregated architectureï¼‰ï¼Œå°†è®¡ç®—å¯†é›†å‹çš„ **prefill é˜¶æ®µ** å’Œå»¶è¿Ÿæ•æ„Ÿçš„ **decode é˜¶æ®µ** åˆ†ç¦»ï¼Œä»¥æå‡èµ„æºåˆ©ç”¨ç‡ã€‚ç„¶è€Œï¼Œè¿™ç§æ¶æ„å¼•å…¥äº†ä¸€ä¸ªå…³é”®ç“¶é¢ˆï¼š**KV tensors å¿…é¡»åœ¨ prefill worker å’Œ decode worker ä¹‹é—´ä¼ è¾“**ã€‚

å½“å‰ä¸»æµæ–¹æ¡ˆä¾èµ– **RDMA ç½‘ç»œè·¯å¾„** è¿›è¡Œ KV æ•°æ®äº¤æ¢ï¼Œå³ä½¿å­˜åœ¨é«˜å‰ç¼€é‡ç”¨ç‡ï¼ˆprefix reuseï¼‰ï¼Œæ¯æ¬¡ç¼“å­˜å‘½ä¸­ä»éœ€ç»è¿‡ NICã€host DRAM ç¼“å†²åŒºå’Œå¤šå±‚ç½‘ç»œåè®®æ ˆï¼Œå¯¼è‡´ï¼š
- æ˜¾è‘—å¢åŠ  **TTFTï¼ˆTime to First Tokenï¼‰**
- å¼•å…¥å°¾éƒ¨å»¶è¿Ÿæ³¢åŠ¨
- å—é™äºç½‘ç»œå¸¦å®½å’Œæ‹¥å¡

æ­¤å¤–ï¼Œç°æœ‰ CXL Type-3 è®¾å¤‡è™½æä¾›å­—èŠ‚å¯å¯»å€å…±äº«å†…å­˜ï¼Œä½†ç¼ºä¹è·¨èŠ‚ç‚¹åŸå­æ“ä½œå’Œå…¨å±€ä¸€è‡´æ€§æ”¯æŒï¼Œéš¾ä»¥ç›´æ¥ç”¨äºé«˜æ€§èƒ½ KV å…±äº«ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šTraCT
TraCT æ˜¯ä¸€ä¸ªåŸºäº **CXL å…±äº«å†…å­˜** çš„æœºæ¶çº§ï¼ˆrack-scaleï¼‰LLM æ¨ç†æœåŠ¡ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> åˆ©ç”¨ CXL Type-3 è®¾å¤‡ä½œä¸º **æ— ç½‘ç»œè·³è½¬çš„ KV ä¼ è¾“åª’ä»‹ + æœºæ¶èŒƒå›´å†…çš„ prefix-aware KV ç¼“å­˜**ï¼Œå®ç° GPU åˆ° CXL å†…å­˜çš„ç›´æ¥ DMA è®¿é—®ï¼Œå½»åº•ç»•å¼€ NIC å’Œä¸»æœºé—´æ‹·è´ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹
1. **ç»Ÿä¸€çš„ CXL æ•°æ®é€šè·¯ï¼ˆUnified CXL Pathwayï¼‰**
   - å°† KV ä¼ è¾“ä¸ KV ç¼“å­˜ç»Ÿä¸€åˆ°åŒä¸€ä¸ª CXL å…±äº«å†…å­˜è·¯å¾„ä¸­ã€‚
   - Prefill worker é€šè¿‡ GPU-CXL DMA å°† KV å—å†™å…¥ CXLï¼›
   - Decode worker ç›´æ¥ä» CXL è¯»å– KV å—è‡³ GPUï¼Œæ— éœ€ NIC å‚ä¸ã€‚

2. **ä¸¤å±‚è½¯ä»¶åŒæ­¥æœºåˆ¶ï¼ˆTwo-Tier Inter-node Synchronizationï¼‰**
   - é’ˆå¯¹ CXL Type-3 ç¼ºä¹ç¡¬ä»¶åŸå­æ€§å’Œå…¨å±€ä¸€è‡´æ€§çš„æŒ‘æˆ˜ï¼š
     - **æœ¬åœ°å±‚ï¼ˆLocal Tierï¼‰**ï¼šæ¯ä¸ªèŠ‚ç‚¹ç»´æŠ¤é©»ç•™äº DRAM çš„ `local_lock`ï¼Œé™åˆ¶æ¯èŠ‚ç‚¹æœ€å¤šä¸€ä¸ªçº¿ç¨‹å‚ä¸ç«äº‰ã€‚
     - **å…¨å±€å±‚ï¼ˆGlobal Tierï¼‰**ï¼šCXL å†…å­˜ä¸­ç»´æŠ¤å›ºå®šå¤§å°çš„ `global_lock` æ•°ç»„ï¼Œç”±ä¸“ç”¨ lock manager åè°ƒåˆ†é…é”ã€‚
   - å®ç°äº†ä½å¼€é”€ã€å¯æ‰©å±•ä¸”ä¸ä¾èµ–ç¡¬ä»¶åŸå­çš„æ“ä½œã€‚

3. **ç»†ç²’åº¦å…ƒæ•°æ®å¯è§æ€§æ§åˆ¶**
   - ä½¿ç”¨ `clflush` è€Œé `clflushopt` æ¥ç¡®ä¿å…ƒæ•°æ®æ›´æ–°åç«‹å³æŒä¹…åŒ–åˆ° CXL è®¾å¤‡ã€‚
   - åŒºåˆ†â€œå…ƒæ•°æ®â€ä¸â€œpayloadâ€å¯è§æ€§è¾¹ç•Œï¼šä»…åˆ·æ–°ç´§å‡‘çš„å…ƒæ•°æ®åŒºåŸŸï¼ŒKV æ•°æ®å› ç» GPU-CXL DMA ç»•è¿‡ CPU ç¼“å­˜è€Œå¤©ç„¶å¯è§ã€‚

4. **é¢å‘éä¸€è‡´å…±äº«å†…å­˜çš„æ•°æ®ç®¡ç†è®¾è®¡**
   - **åç§»é‡å¯»å€ï¼ˆOffset-based Addressingï¼‰**ï¼šé¿å…è™šæ‹Ÿåœ°å€è·¨èŠ‚ç‚¹ä¸å¯ç”¨é—®é¢˜ã€‚
   - **ä¸¤çº§å†…å­˜åˆ†é…å™¨**ï¼šå…¨å±€ chunk allocator + æ¯èŠ‚ç‚¹æœ¬åœ°å †ï¼Œå‡å°‘è·¨èŠ‚ç‚¹å…ƒæ•°æ®äº‰ç”¨ã€‚
   - **å…±äº«å¯¹è±¡å­˜å‚¨**ï¼šåªå‘å¸ƒæ ¹å¯¹è±¡ï¼ˆå¦‚ prefix cache rootï¼‰ï¼Œå†…éƒ¨ç»“æ„é€šè¿‡åç§»é“¾æ¥ï¼Œé™ä½ç®¡ç†å¼€é”€ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿ RDMA æ–¹æ¡ˆï¼ˆå¦‚ NIXL/UCXï¼‰ | DRAM ç¼“å­˜æ–¹æ¡ˆï¼ˆå¦‚ LMCacheï¼‰ | TraCT |
|------|-------------------------------|-----------------------------|-------|
| KV ä¼ è¾“è·¯å¾„ | ç» NICã€host DRAMã€åè®®æ ˆ | åŒæ ·èµ°ç½‘ç»œï¼ˆå³ä½¿ç¼“å­˜å‘½ä¸­ï¼‰ | **ç›´æ¥ GPU-CXL DMAï¼Œæ—  NIC è·³è½¬** |
| ç¼“å­˜ä½ç½® | åˆ†å¸ƒå¼æˆ–æœ¬åœ° DRAM | ä¸»æœº DRAM | **CXL å…±äº«å†…å­˜ï¼Œå…¨æœºæ¶å¯è§** |
| åŒæ­¥æœºåˆ¶ | ä¾èµ– RDMA æˆ–é›†ä¸­å¼åè°ƒ | ä¸­å¿ƒåŒ–å…ƒæ•°æ®æœåŠ¡å™¨ | **å»ä¸­å¿ƒåŒ–ï¼Œçº¯è½¯ä»¶é”ï¼Œæ— åè°ƒè€…** |
| æ€§èƒ½ç‰¹å¾ | é«˜å»¶è¿Ÿã€æ˜“å—ç½‘ç»œå½±å“ | å‡å°‘è®¡ç®—ä½†æ— æ³•é¿å…ç½‘ç»œä¼ è¾“ | **æ›´ä½å»¶è¿Ÿã€æ›´ç¨³å®šã€æ›´é«˜åå** |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### å®éªŒå¹³å°
- **ç¡¬ä»¶é…ç½®**ï¼š
  - ä¸¤å°æœåŠ¡å™¨ï¼Œå„é…å¤‡ï¼š
    - NVIDIA A6000 GPUï¼ˆ48GB GDDRï¼‰
    - 512GB host DRAM
    - 100Gbps Mellanox NICï¼ˆç”¨äºåŸºçº¿ï¼‰
  - CXL è®¾å¤‡ï¼šNiagara 2.0ï¼ˆç¬¬äºŒä»£ CXL Type-3 å†…å­˜æ‰©å±•å™¨ï¼‰
    - æä¾› 64GB å­—èŠ‚å¯å¯»å€å…±äº«å†…å­˜
    - å»¶è¿Ÿï¼š640nsï¼Œå¸¦å®½ï¼š10.1 GB/s
- **è½¯ä»¶æ¡†æ¶**ï¼šåŸºäº NVIDIA çš„ **Dynamo v0.5.0 + vLLM v0.10.1.1**

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| é…ç½® | æè¿° |
|------|------|
| **NIXL/UCX** | åŸå§‹ Dynamo æ¶æ„ï¼Œä½¿ç”¨ RDMA è¿›è¡Œ KV ä¼ è¾“ï¼Œ**æ—  prefix ç¼“å­˜** |
| **LMCache** | åœ¨ prefill worker çš„ host DRAM ä¸­éƒ¨ç½² 48GB prefix cacheï¼Œä½†ä»é€šè¿‡ RDMA å‘ decode worker ä¼ è¾“æ‰€æœ‰ KV å— |
| **TraCT** | ä½¿ç”¨ CXL å…±äº«å†…å­˜ä½œä¸º KV cache å’Œä¼ è¾“ä»‹è´¨ï¼Œå¯ç”¨ GPU-CXL DMA |

> æ‰€æœ‰å®éªŒå‡å…³é—­ GPU å†…éƒ¨çš„ prefix cachingï¼Œä»¥ä¾¿éš”ç¦»æ¯”è¾ƒå¤–éƒ¨ç¼“å­˜æ•ˆæœã€‚

---

### å·¥ä½œè´Ÿè½½ï¼ˆWorkloadsï¼‰

#### ï¼ˆ1ï¼‰é™æ€å·¥ä½œè´Ÿè½½
- å›ºå®šè¾“å‡ºé•¿åº¦ä¸º 3 tokens
- è¾“å…¥é•¿åº¦å˜åŒ–ï¼š1500ã€3000ã€4500ã€6000 tokens
- ç”¨äºç²¾ç¡®æ§åˆ¶ KV æ•°æ®é‡ï¼Œåˆ†æä¼ è¾“æ€§èƒ½

#### ï¼ˆ2ï¼‰åˆæˆå·¥ä½œè´Ÿè½½ï¼ˆSynthetic Workloadsï¼‰
ä½¿ç”¨ Dynamo å†…ç½®è¯·æ±‚ç”Ÿæˆå™¨åˆ›å»ºä¸‰ç±»è´Ÿè½½ï¼ˆA/B/Cï¼‰ï¼Œç»Ÿè®¡å¦‚ä¸‹ï¼š

| Workload | å¹³å‡è¾“å…¥é•¿åº¦ | å¹³å‡è¾“å‡ºé•¿åº¦ | å¹³å‡å”¯ä¸€å‰ç¼€é•¿åº¦ï¼ˆåæ˜ å¤šæ ·æ€§ï¼‰ |
|---------|--------------|--------------|-------------------------------|
| A       | 4449         | 215          | 1073                          |
| B       | 3775         | 215          | 1215                          |
| C       | 3101         | 215          | 1631                          |

> å”¯ä¸€å‰ç¼€è¶Šé•¿ â†’ ç¼“å­˜å‘½ä¸­ç‡è¶Šä½ â†’ æ›´å…·æŒ‘æˆ˜æ€§

---

### è¯„ä¼°æŒ‡æ ‡
- **TTFTï¼ˆTime to First Tokenï¼‰**ï¼šè¡¡é‡ prefill é˜¶æ®µå»¶è¿Ÿï¼Œé‡ç‚¹å…³æ³¨å¹³å‡å€¼å’Œ P99
- **Request Throughputï¼ˆQPSï¼‰**ï¼šç«¯åˆ°ç«¯è¯·æ±‚ååé‡
- **Prefill Throughput**ï¼šprefill worker å¤„ç†èƒ½åŠ›
- **GPU SM Utilization / Power Consumption**ï¼šèµ„æºåˆ©ç”¨æ•ˆç‡
- **PCIe/CXL Bandwidth Usage**
- **Prefix Cache Hit Rate**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»
| æŒ‡æ ‡ | TraCT æå‡å¹…åº¦ | å¯¹æ¯”åŸºçº¿ |
|------|----------------|----------|
| **å¹³å‡ TTFT** | æœ€é«˜ **9.8Ã— é™ä½** | vs. NIXL/LMCache |
| **P99 TTFT** | æœ€é«˜ **6.2Ã— é™ä½** | vs. NIXL/LMCache |
| **å³°å€¼ååé‡ï¼ˆPeak Throughputï¼‰** | æœ€é«˜ **1.6Ã— æå‡** | vs. LMCache |
| **Prefill å»¶è¿Ÿç¨³å®šæ€§** | æ˜¾è‘—æ”¹å–„ï¼ŒCDF æ›²çº¿æ›´é™¡å³­ | æ›´å°å°¾éƒ¨æ³¢åŠ¨ |

---

### è¯¦ç»†å®éªŒç»“æœ

#### ï¼ˆ1ï¼‰CXL æ›¿ä»£ RDMA çš„æœ‰æ•ˆæ€§ï¼ˆæ— ç¼“å­˜åœºæ™¯ï¼‰
- å›¾5ï¼ˆFigure 5ï¼‰æ˜¾ç¤ºï¼Œåœ¨ä¸åŒè¾“å…¥é•¿åº¦ä¸‹ï¼Œ**TraCTï¼ˆæ— ç¼“å­˜ï¼‰ç›¸æ¯” NIXL æ˜¾è‘—é™ä½ TTFT**ã€‚
  - è¾“å…¥ 6000 tokens æ—¶ï¼Œå°¾éƒ¨å»¶è¿Ÿæ˜æ˜¾ç¼©çŸ­ã€‚
- å›¾6ï¼ˆFigure 6ï¼‰è¡¨æ˜ï¼Œ**TraCT åœ¨é«˜å¹¶å‘ä¸‹ç»´æŒä¸ RDMA ç›¸å½“çš„ååé‡**ï¼Œè¯æ˜ CXL DMA å¯ä½œä¸ºé«˜æ•ˆæ›¿ä»£è·¯å¾„ã€‚

> âœ… ç»“è®ºï¼š**ä»…é  GPU-CXL DMA å³å¯æ˜¾è‘—é™ä½ prefill å»¶è¿Ÿï¼Œä¸”ä¸å½±å“ååã€‚**

---

#### ï¼ˆ2ï¼‰å¯ç”¨ç¼“å­˜åçš„ç»¼åˆæ€§èƒ½ä¼˜åŠ¿
- å›¾7ï¼ˆFigure 7ï¼‰ï¼šTraCT åœ¨æ‰€æœ‰è´Ÿè½½ä¸‹å‡è¾¾åˆ°æœ€é«˜ **request throughput**ï¼Œæœ€é«˜æ¯” LMCache æå‡ **1.6Ã—**ã€‚
- å›¾8ï¼ˆFigure 8ï¼‰ï¼šå°½ç®¡ TraCT çš„ **cache hit rate ä½äºæˆ–æ¥è¿‘ LMCache**ï¼Œä½†æ€§èƒ½åè€Œæ›´å¥½ã€‚
  > è¯´æ˜æ€§èƒ½å¢ç›Šæ¥è‡ª **æ¶ˆé™¤ç¼“å­˜å‘½ä¸­çš„ç½‘ç»œä¼ è¾“å¼€é”€**ï¼Œè€Œéå•çº¯æé«˜å‘½ä¸­ç‡ã€‚

- å›¾9ï¼ˆFigure 9ï¼‰ï¼šTTFT ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰å…¨é¢å·¦ç§»ï¼š
  - **å¹³å‡ TTFT æœ€å¤šé™ä½ 9.83Ã—**
  - **P99 TTFT æœ€å¤šé™ä½ 6.2Ã—**
  - ç‰¹åˆ«æ˜¯åœ¨ bursty æˆ–é«˜å¹¶å‘åœºæ™¯ä¸‹ä¼˜åŠ¿æ˜æ˜¾ã€‚

---

#### ï¼ˆ3ï¼‰æ€§èƒ½åˆ†è§£åˆ†æï¼ˆå›¾10ï¼‰
- **KV Read æ—¶é—´**ï¼šTraCT å‡ ä¹æ’å®šï¼Œè€Œ LMCache/NIXL éšè´Ÿè½½ä¸Šå‡ â†’ è¡¨æ˜ç½‘ç»œæ‹·è´æˆä¸ºç“¶é¢ˆã€‚
- **Compute æ—¶é—´**ï¼šä¸‰è€…ç›¸è¿‘ï¼Œè¯´æ˜ **KV ä¼ è¾“å·²æˆä¸ºä¸»å¯¼å¼€é”€**ï¼Œè€Œéè®¡ç®—æœ¬èº«ã€‚
- **KV Write æ—¶é—´**ï¼šTraCT æ›´å¿«ï¼Œå› å…¶è·³è¿‡é‡å¤å†™å…¥å·²å­˜åœ¨çš„ KV å—ã€‚

---

#### ï¼ˆ4ï¼‰èµ„æºåˆ©ç”¨ä¸èƒ½è€—ä¼˜åŒ–ï¼ˆå›¾11ï¼‰
- **GPU SM åˆ©ç”¨ç‡æ›´ä½ä¸”æ›´ç¨³å®š**ï¼š
  - Prefillï¼šç¼“å­˜å‘½ä¸­é¿å…é‡å¤è®¡ç®—
  - Decodeï¼šKV ç›´æ¥åŠ è½½ï¼Œå‡å°‘ç­‰å¾…
- **PCIe RX å¸¦å®½æ›´é«˜ä¸”ç¨³å®š**ï¼šCXL æä¾›æŒç»­é«˜å¸¦å®½è®¿é—®
- **åŠŸè€—æ›´ä½**ï¼šæ‰§è¡Œæ—¶é—´çŸ­ + SM æ´»åŠ¨å°‘ â†’ **é™ä½ç¬æ—¶ä¸æ€»ä½“èƒ½è€—**
  > æœ‰åŠ©äºé™ä½ LLM æ¨ç†çš„ TCOï¼ˆTotal Cost of Ownershipï¼‰

---

### æ¶ˆèå®éªŒï¼ˆéšå«ï¼‰
è™½ç„¶æœªæ˜ç¡®å‘½åæ¶ˆèå®éªŒï¼Œä½†ä»¥ä¸‹å¯¹æ¯”ä½“ç°äº†æ¨¡å—åŒ–éªŒè¯ï¼š
- **TraCTï¼ˆno cacheï¼‰ vs NIXL** â†’ éªŒè¯ **CXL DMA æœ¬èº«çš„ä»·å€¼**
- **TraCTï¼ˆwith cacheï¼‰ vs LMCache** â†’ éªŒè¯ **CXL ç¼“å­˜ + å»ç½‘ç»œåŒ–çš„ååŒæ•ˆç›Š**
- **ä¸åŒ workload ä¸‹çš„è¡¨ç°å·®å¼‚** â†’ éªŒè¯ç³»ç»Ÿåœ¨å¤šæ ·åŒ–è¯·æ±‚ä¸‹çš„é²æ£’æ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **CXL å…±äº«å†…å­˜å¯ä»¥æœ‰æ•ˆå–ä»£ RDMA æˆä¸º LLM æ¨ç†ä¸­çš„ KV ä¼ è¾“é€šé“**ï¼Œå°¤å…¶é€‚åˆè§£è€¦æ¶æ„ã€‚
2. **å³ä½¿æ²¡æœ‰ç¼“å­˜ï¼ŒGPU-CXL DMA ä¹Ÿèƒ½æ˜¾è‘—é™ä½ TTFT å¹¶ä¿æŒé«˜åå**ï¼Œä¼˜äºä¼ ç»Ÿç½‘ç»œè·¯å¾„ã€‚
3. **å°† CXL ç”¨ä½œæœºæ¶çº§ prefix-aware KV cache å¯å¸¦æ¥å·¨å¤§æ€§èƒ½æ”¶ç›Š**ï¼š
   - æœ€é«˜ **9.8Ã— é™ä½å¹³å‡ TTFT**
   - æœ€é«˜ **6.2Ã— æ”¹å–„ P99 å»¶è¿Ÿ**
   - æœ€é«˜ **1.6Ã— æå‡å³°å€¼åå**
4. **TraCT çš„è½¯ä»¶åŒæ­¥ä¸æ•°æ®ç®¡ç†æœºåˆ¶å¯åœ¨æ— ç¡¬ä»¶åŸå­æ€§å’Œå…¨å±€ä¸€è‡´æ€§çš„å‰æä¸‹ä¿è¯æ­£ç¡®æ€§ä¸é«˜æ€§èƒ½**ã€‚
5. **ç³»ç»Ÿæ›´èŠ‚èƒ½ã€GPU åˆ©ç”¨æ›´å……åˆ†ã€å»¶è¿Ÿæ›´ç¨³å®š**ï¼Œå…·å¤‡å®é™…éƒ¨ç½²æ½œåŠ›ã€‚

---

### å±€é™æ€§
1. **ä¾èµ–ç‰¹å®šç¡¬ä»¶æ”¯æŒ**ï¼šéœ€è¦æ”¯æŒ CXL.mem çš„ Type-3 è®¾å¤‡åŠ GPU ç›´æ¥è®¿é—®èƒ½åŠ›ã€‚
2. **å½“å‰ä½¿ç”¨ç®€å• LRU æ·˜æ±°ç­–ç•¥**ï¼šæœªæ¢ç´¢æ›´å¤æ‚çš„æ›¿æ¢ç®—æ³•ï¼ˆå¦‚ LFUã€ARCï¼‰ï¼Œå¯èƒ½å½±å“ç¼“å­˜å‘½ä¸­ç‡ã€‚
3. **å®éªŒè§„æ¨¡æœ‰é™**ï¼šä»…ä½¿ç”¨ä¸¤ä¸ªæœåŠ¡å™¨èŠ‚ç‚¹ï¼Œå°šæœªéªŒè¯å¤§è§„æ¨¡é›†ç¾¤ä¸‹çš„å¯æ‰©å±•æ€§ã€‚
4. **NUMA æ•æ„Ÿæ€§**ï¼šæ€§èƒ½ä¾èµ–äºçº¿ç¨‹ç»‘å®šè‡³è¿æ¥ CXL çš„ NUMA èŠ‚ç‚¹ï¼Œå¦åˆ™ä¼šå¼•å…¥é¢å¤–å»¶è¿Ÿã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ¢ç´¢æ›´æ™ºèƒ½çš„ **ç¼“å­˜æ›¿æ¢ç­–ç•¥**ï¼ˆå¦‚åŸºäºè®¿é—®é¢‘ç‡æˆ–çƒ­åº¦é¢„æµ‹ï¼‰ã€‚
2. æ‰©å±•è‡³æ›´å¤§è§„æ¨¡çš„ **å¤šèŠ‚ç‚¹æœºæ¶ç¯å¢ƒ**ï¼Œç ”ç©¶ lock manager çš„æ¨ªå‘æ‰©å±•æœºåˆ¶ã€‚
3. æ”¯æŒ **å¼‚æ„æ¨¡å‹å…±å­˜** åœºæ™¯ä¸‹çš„å¤šç§Ÿæˆ· KV ç¼“å­˜éš”ç¦»ä¸è°ƒåº¦ã€‚
4. ç»“åˆ **CXL å†…å­˜æ± åŒ–æŠ€æœ¯** å®ç°åŠ¨æ€å®¹é‡åˆ†é…ä¸æ•…éšœæ¢å¤ã€‚
5. æ¢ç´¢ **CXL ä¸ NVMe-oF çš„ååŒä½¿ç”¨**ï¼Œæ„å»ºå¤šå±‚æ¬¡ KV å­˜å‚¨ä½“ç³»ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼šTraCT å¼€åˆ›æ€§åœ°å°† CXL å…±äº«å†…å­˜åº”ç”¨äº LLM è§£è€¦æ¨ç†ç³»ç»Ÿï¼Œæå‡ºäº†ä¸€å¥—å®Œæ•´çš„è½¯ä»¶æ ˆæ¥å…‹æœéä¸€è‡´æ€§å†…å­˜å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œå®ç°äº†**å»ç½‘ç»œåŒ–ã€é«˜æ€§èƒ½ã€ä½å»¶è¿Ÿã€é«˜èƒ½æ•ˆ**çš„ KV ç®¡ç†æ–¹æ¡ˆï¼Œä¸ºä¸‹ä¸€ä»£ LLM æ¨ç†åŸºç¡€è®¾æ–½æä¾›äº†é‡è¦å‚è€ƒã€‚

</details>

---

### 5. [NOVA: Discovering Well-Conditioned Winograd Transforms through Numerical Optimization of Vandermonde Arithmetic](https://arxiv.org/abs/2512.18453)

**Authors**: Jayant Lohia  
**Category**: cs.LG  
**Published**: 2025-12-23  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.18453v1  

#### Abstract
Winograd convolution is the standard algorithm for efficient inference, reducing arithmetic complexity by 2.25x for 3x3 kernels. However, it faces a critical barrier in the modern era of low precision computing: numerical instability. As tiles scale to maximize efficiency (e.g., F(6,3), F(8,3)), the...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šNOVA: Discovering Well-Conditioned Winograd Transforms through Numerical Optimization of Vandermonde Arithmetic

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
Winograd å·ç§¯æ˜¯æ·±åº¦å­¦ä¹ ä¸­é«˜æ•ˆçš„æ¨ç†ç®—æ³•ï¼Œèƒ½å°† 3Ã—3 å·ç§¯çš„ç®—æœ¯å¤æ‚åº¦é™ä½ 2.25Ã—ã€‚ç„¶è€Œï¼Œå…¶åœ¨ç°ä»£ä½ç²¾åº¦è®¡ç®—ï¼ˆå¦‚ FP16ã€Int8ï¼‰ä¸‹å­˜åœ¨ä¸¥é‡çš„**æ•°å€¼ä¸ç¨³å®šæ€§**é—®é¢˜ã€‚éšç€å·ç§¯å—å°ºå¯¸å¢å¤§ï¼ˆå¦‚ F(6,3)ã€F(8,3)ï¼‰ï¼Œæ ‡å‡†æ•´æ•°æ’å€¼ç‚¹å¯¼è‡´çš„ Vandermonde çŸ©é˜µæ¡ä»¶æ•°ï¼ˆcondition numberï¼‰æ€¥å‰§ä¸Šå‡ï¼ˆF(8,3) è¾¾åˆ° ~2Ã—10âµï¼‰ï¼Œä½¿å¾—å¤§å— Winograd åœ¨ä½ç²¾åº¦ä¸‹å®Œå…¨å¤±æ•ˆï¼Œè¾“å‡ºæ¥è¿‘éšæœºå™ªå£°ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šNOVA
ä½œè€…æå‡º **NOVA**ï¼ˆNumerical Optimization of Vandermonde Arithmeticï¼‰ï¼Œä¸€ç§é€šè¿‡è¿ç»­ç©ºé—´ä¼˜åŒ–å‘ç°ç¨³å®š Winograd æ’å€¼ç‚¹çš„æ–°æ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯æ‰“ç ´ä¼ ç»Ÿâ€œä»…ä½¿ç”¨æ•´æ•°ç‚¹â€çš„è®¾è®¡èŒƒå¼ï¼Œå°†æ’å€¼ç‚¹é€‰æ‹©è§†ä¸ºä¸€ä¸ªè¿ç»­ä¼˜åŒ–é—®é¢˜ã€‚

#### æ–¹æ³•æµç¨‹ï¼š
1. **Evolution Strategy (ES)**ï¼šåœ¨ $\mathbb{R}^{n-1}$ è¿ç»­ç©ºé—´ä¸­æœç´¢æœ€ä¼˜æ’å€¼ç‚¹é…ç½®ã€‚
2. **Snap-to-Rational**ï¼šå°†è¿ç»­è§£æ˜ å°„ä¸ºç®€å•åˆ†æ•°ï¼ˆå¦‚åˆ†æ¯ â‰¤10 çš„æœ‰ç†æ•°ï¼‰ã€‚
3. **Symbolic Verification**ï¼šä½¿ç”¨ SymPy è¿›è¡Œç²¾ç¡®ç¬¦å·éªŒè¯ï¼Œç¡®ä¿åˆ†è§£æ•°å­¦æ­£ç¡®æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³• | NOVA |
|------|--------|------|
| **æœç´¢ç©ºé—´** | å›ºå®šæ•´æ•°æˆ–å‚æ•°åŒ–å®¶æ—ï¼ˆå¦‚ {-1/c, -c, c, 1/c}ï¼‰ | å…¨è¿ç»­ç©ºé—´ $\mathbb{R}^{n-1}$ï¼Œæ— é¢„å®šä¹‰è¯æ±‡é™åˆ¶ |
| **ç‚¹ç±»å‹** | æ•´æ•°ä¸ºä¸» | å‘ç°éå¯¹ç§°ã€éå€’æ•°å…³ç³»çš„åˆ†æ•°ç‚¹ï¼ˆå¦‚ Â±5/6, Â±7/6, Â±3/5ï¼‰ |
| **éªŒè¯æ–¹å¼** | æµ®ç‚¹è¿‘ä¼¼éªŒè¯ï¼Œæ˜“å—èˆå…¥è¯¯å·®å½±å“ | ç¬¦å·éªŒè¯ï¼ˆexact rational arithmeticï¼‰ï¼Œä¿è¯æ•°å­¦æ­£ç¡®æ€§ |
| **éƒ¨ç½²å…¼å®¹æ€§** | éœ€è¦é‡è®­ç»ƒã€æ ¡å‡†æˆ–ä¿®æ”¹æ¶æ„ | **Drop-in replacement**ï¼Œæ— éœ€é‡è®­ç»ƒã€æ— éœ€å­¦ä¹ å‚æ•° |
| **æ€§èƒ½æå‡** | æ¡ä»¶æ•°æ”¹å–„æœ‰é™ï¼ˆå¦‚ Alam et al. æœ€å¤š 11Ã—ï¼‰ | æ¡ä»¶æ•°æ”¹å–„é«˜è¾¾ **415Ã—ï¼ˆ1Dï¼‰**ï¼Œ2D ä¸‹è¾¾ **172,484Ã—** |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **ImageNetV2**ï¼ˆ30,000 å¼ å›¾åƒï¼‰ï¼šç”¨äº FP16 æ¨ç†çš„ä¸»è¯„ä¼°ï¼Œè¦†ç›–å¤šç§ä¸»æµæ¶æ„ã€‚
- **CIFAR-10**ï¼ˆ10,000 å¼ å›¾åƒï¼‰ï¼šç”¨äº INT8 é‡åŒ–è¯„ä¼°ï¼Œæ§åˆ¶å˜é‡åˆ†æå±‚çº§åˆ«è¯¯å·®ã€‚

### æ¶æ„
åœ¨ä»¥ä¸‹ 6 ç§ ImageNet é¢„è®­ç»ƒæ¨¡å‹ä¸Šè¿›è¡Œè¯„ä¼°ï¼š
- ResNet-18, ResNet-50
- VGG-16, VGG-16-BN
- MobileNet-V2, EfficientNet-B0

### ç¡¬ä»¶ä¸ç²¾åº¦è®¾ç½®
- **ç¡¬ä»¶**ï¼šNVIDIA Tesla T4 GPU
- **ç²¾åº¦**ï¼š
  - **FP16**ï¼šæ··åˆç²¾åº¦ï¼ˆ`torch.cuda.amp.autocast`ï¼‰ï¼Œå˜æ¢çŸ©é˜µç”¨ FP32 è®¡ç®—åè½¬ä¸º FP16ã€‚
  - **INT8**ï¼šæµ‹è¯• per-tensor å’Œ per-channel ä¸¤ç§é‡åŒ–æ¨¡å¼ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| **Kâ‚‚(V)** | Vandermonde çŸ©é˜µçš„è°±æ¡ä»¶æ•°ï¼Œè¡¡é‡æ•°å€¼ç¨³å®šæ€§ |
| **Top-1 Accuracy** | å›¾åƒåˆ†ç±»å‡†ç¡®ç‡ï¼Œä¸»ä»»åŠ¡æ€§èƒ½æŒ‡æ ‡ |
| **Relative L2 Error** | å±‚çº§å·ç§¯è¾“å‡ºç›¸å¯¹äº FP64 ç›´æ¥å·ç§¯çš„è¯¯å·® |
| **Latency** | æ¨ç†å»¶è¿Ÿï¼ˆmsï¼‰ï¼ŒéªŒè¯æ˜¯å¦å¼•å…¥å¼€é”€ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Standard Integers**ï¼š{0, Â±1, Â±2, ...}ï¼Œå½“å‰ä¸»æµå®ç°ï¼ˆcuDNN, TensorRTï¼‰ã€‚
- **Alam et al. (2022)**ï¼šåŸºäºå¯¹ç§°å€’æ•°æ— {-1/c, -c, c, 1/c} çš„å‚æ•°åŒ–æœç´¢ã€‚
- **Tap-wise Scaling (Chikin & Kryzhanovskiy, 2022)**ï¼šå­¦ä¹ æ¯ tap ç¼©æ”¾å› å­ä»¥ç¼“è§£é‡åŒ–è¯¯å·®ã€‚
- **Legendre Basis (Barabasz et al., 2020)**ï¼šæ”¹å˜åŸºå‡½æ•°ä»¥æé«˜ç¨³å®šæ€§ï¼Œä½†éœ€é‡æ–°è®­ç»ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### æ¡ä»¶æ•°æ”¹å–„ï¼ˆ1Dï¼‰
| Tile | Standard Kâ‚‚ | Discovered Kâ‚‚ | Improvement |
|------|-------------|---------------|-------------|
| F(4,3) | 42.5 | 14.5 | **2.9Ã—** |
| F(6,3) | 2,075 | 77 | **27Ã—** |
| F(8,3) | 196.9k | 474 | **415Ã—** |

> **å‘ç°ç‚¹ç¤ºä¾‹**ï¼šF(8,3) ä½¿ç”¨ `{0, Â±2/5, Â±5/6, Â±1, Â±7/6}`ï¼Œè¿™äº›ç‚¹ä¸åœ¨ä»»ä½•ä¼ ç»Ÿâ€œè¯æ±‡è¡¨â€ä¸­ã€‚

#### 2D å·ç§¯ä¸‹çš„å¹³æ–¹æ•ˆåº”ï¼ˆKronecker Productï¼‰
ç”±äº 2D å˜æ¢çŸ©é˜µä¸º Kronecker ç§¯ $A \otimes A$ï¼Œæ¡ä»¶æ•°æ»¡è¶³ $K_2(A \otimes A) = K_2(A)^2$ï¼Œå› æ­¤ 1D æ”¹å–„åœ¨ 2D ä¸­**å¹³æ–¹æ”¾å¤§**ï¼š

| 2D Tile | Improvement |
|--------|-------------|
| F(4Ã—4, 3Ã—3) | ~8.5Ã— |
| F(6Ã—6, 3Ã—3) | **733Ã—** |
| F(8Ã—8, 3Ã—3) | **172,484Ã—** |

#### ImageNet FP16 æ¨ç†å‡†ç¡®ç‡æ¢å¤
åœ¨ F(6,3) ä¸Šï¼Œæ ‡å‡†æ•´æ•°ç‚¹å¯¼è‡´ä¸¥é‡å´©æºƒï¼Œè€Œ NOVA å®Œå…¨æ¢å¤ç²¾åº¦ï¼š

| Model | Standard Acc | Discovered Acc | Recovery |
|-------|--------------|----------------|----------|
| VGG-16 | 4.7% | 75.3% | **+70.6pp** |
| VGG-16-BN | 4.7% | 77.5% | **+72.8pp** |
| ResNet-18 | 10.8% | 77.8% | **+67.0pp** |
| ResNet-50 | 38.3% | 80.6% | **+42.3pp** |

> **å¹³å‡æ¢å¤ 67â€“73 ä¸ªç™¾åˆ†ç‚¹**ï¼Œä¸”**æ— éœ€é‡è®­ç»ƒã€æ ¡å‡†æˆ–å­¦ä¹ å‚æ•°**ã€‚

#### INT8 å±‚çº§è¯¯å·®å¤§å¹…é™ä½
| Tile | Standard Error | Discovered Error | Improvement |
|------|----------------|------------------|-------------|
| F(4,3) | 7.1% | 2.1% | 3.4Ã— |
| F(6,3) | 3990% | 12.4% | **322Ã—** |
| F(8,3) | 100% (é¥±å’Œ) | 59.2% | 1.7Ã— |

> æ ‡å‡† F(6,3) è¾“å‡ºå·²å®Œå…¨é”™è¯¯ï¼ˆ>100% è¯¯å·®ï¼‰ï¼Œè€Œ NOVA ä½¿å…¶å¯ç”¨ã€‚

#### æ¶ˆèå®éªŒç»“æœ
- **dtype-aware discovery**ï¼šçº¦æŸæœç´¢ç©ºé—´ä¸º FP16 å¯ç²¾ç¡®è¡¨ç¤ºçš„ dyadic rationalsï¼ˆå¦‚ 3/4, 5/4ï¼‰ï¼Œè™½æ¡ä»¶æ•°ç•¥å·®äºæ— çº¦æŸç‰ˆæœ¬ï¼Œä½†é¿å…äº†è¡¨ç¤ºè¯¯å·®ï¼Œåœ¨ FP16 ä¸‹æ€»è¯¯å·®æ›´ä½ã€‚
- **ä¸ Tap-wise Scaling æ­£äº¤**ï¼šTap-wise scaling ä»…èƒ½å¸¦æ¥çº¦ +1.3% æå‡ï¼Œè€Œ NOVA æä¾› +67% åŸºç¡€ä¿®å¤ï¼›ä¸¤è€…ç»“åˆä»…é¢å¤–æå‡ +0.4%ï¼Œè¡¨æ˜ NOVA æ˜¯æ ¹æœ¬æ€§ä¿®å¤ã€‚
- **ä¸ Alam et al. å¯¹æ¯”**ï¼šNOVA åœ¨ F(6,3) ä¸Šæ¡ä»¶æ•°æ”¹å–„ **11Ã— æ›´ä¼˜**ï¼Œä¸”ç½‘ç»œå‡†ç¡®ç‡ç›¸å½“ï¼Œè¯æ˜å…¶æœç´¢ç©ºé—´æ›´ä¼˜ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ•´æ•°æ’å€¼ç‚¹ä¸¥é‡æ¬¡ä¼˜**ï¼šä¼ ç»Ÿä½¿ç”¨çš„æ•´æ•°ç‚¹ï¼ˆ{0, Â±1, Â±2, ...}ï¼‰å¹¶éæœ€ä¼˜ï¼Œå…¶å¯¼è‡´çš„é«˜æ¡ä»¶æ•°æ˜¯ä½ç²¾åº¦ä¸‹ Winograd å¤±æ•ˆçš„**æ ¹æœ¬åŸå› **ã€‚
2. **åˆ†æ•°ç‚¹æ˜¾è‘—æå‡ç¨³å®šæ€§**ï¼šé€šè¿‡ä¼˜åŒ–å‘ç°çš„åˆ†æ•°ç‚¹ï¼ˆå¦‚ Â±5/6, Â±7/6ï¼‰èƒ½å°†æ¡ä»¶æ•°é™ä½ **2.9â€“415Ã—ï¼ˆ1Dï¼‰**ï¼Œ2D ä¸‹å¯è¾¾ **172,484Ã—**ã€‚
3. **æ€§èƒ½æ¢å¤æ— éœ€é¢å¤–æˆæœ¬**ï¼šNOVA æ˜¯**é›¶æˆæœ¬å‡çº§**ï¼ˆdrop-in replacementï¼‰ï¼Œä»…éœ€æ›¿æ¢å˜æ¢çŸ©é˜µå¸¸é‡ï¼Œå³å¯åœ¨ç°æœ‰æ¡†æ¶ï¼ˆcuDNN/TensorRTï¼‰ä¸­å¯ç”¨å¤§å— Winogradã€‚
4. **è¯¯å·®æ”¹å–„å¯é¢„æµ‹**ï¼šINT8 è¯¯å·®æ”¹å–„ä¸ $\sqrt{K}$ æ”¹å–„ä¸€è‡´ï¼ŒéªŒè¯äº†ç†è®ºè¯¯å·®ç•Œ $\Delta y \propto K \cdot \epsilon$ çš„æœ‰æ•ˆæ€§ã€‚
5. **ä¸ç°æœ‰æ–¹æ³•æ­£äº¤äº’è¡¥**ï¼šNOVA ä¸å…¶ä»–æ–¹æ³•ï¼ˆå¦‚ scale learningã€per-channel quantizationï¼‰ä¸å†²çªï¼Œå¯ç»„åˆä½¿ç”¨è¿›ä¸€æ­¥æå‡é²æ£’æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è¶…å¤§å—ä»å…·æŒ‘æˆ˜**ï¼šF(8,3) åœ¨ INT8 ä¸‹å³ä½¿ä½¿ç”¨ NOVAï¼Œè¯¯å·®ä»è¾¾ 59.2%ï¼Œéœ€ç»“åˆå…¶ä»–æŠ€æœ¯ï¼ˆå¦‚ tap-wise scalingï¼‰ã€‚
- **å¯¹ç§°æ€§åå¥½**ï¼šES å€¾å‘äºå‘ç°å¯¹ç§°é…ç½®ï¼ˆå¦‚ Â±pï¼‰ï¼Œå¯èƒ½é”™è¿‡æŸäº›éå¯¹ç§°æœ€ä¼˜è§£ã€‚
- **æµ®ç‚¹16 è¡¨ç¤ºæƒè¡¡**ï¼šéƒ¨åˆ†åˆ†æ•°ï¼ˆå¦‚ 5/6ï¼‰åœ¨ FP16 ä¸­æ— æ³•ç²¾ç¡®è¡¨ç¤ºï¼Œéœ€ dtype-aware discovery å¹³è¡¡æ¡ä»¶æ•°ä¸è¡¨ç¤ºè¯¯å·®ã€‚
- **ä»…é€‚ç”¨äºæ ‡å‡† Cook-Toom å½¢å¼**ï¼šä¸ç›´æ¥æ”¯æŒ RNS æˆ– SFC ç­‰æ›¿ä»£ç®—æ³•ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† NOVA å‘ç°çš„ç‚¹é›†æˆåˆ° **cuDNN / TensorRT** ç­‰ç”Ÿäº§çº§åº“ä¸­ã€‚
- ç»“åˆ **learned scaling**ï¼ˆå¦‚ PAWã€LoWinoï¼‰æ„å»ºå®Œæ•´çš„ä½ç²¾åº¦ Winograd æµæ°´çº¿ã€‚
- æ‰©å±•è‡³ **5Ã—5 åŠæ›´å¤§å·ç§¯æ ¸**ï¼ˆr=5,7ï¼‰ï¼Œå·²æœ‰åˆæ­¥ç»“æœæ˜¾ç¤º F(6,5) å¯è· 112Ã— æ¡ä»¶æ•°æ”¹å–„ã€‚
- æ¢ç´¢ **ç›´æ¥ 2D ç‚¹é€‰æ‹©** è€Œé Kronecker ç§¯ï¼Œå¯èƒ½è·å¾—æ›´ä¼˜é…ç½®ã€‚
- ç ”ç©¶ **ä¸ Winograd-aware training** çš„è”åˆä¼˜åŒ–ï¼Œè¿›ä¸€æ­¥æå‡ç«¯åˆ°ç«¯æ€§èƒ½ã€‚

---

> **æ€»ç»“**ï¼šNOVA é€šè¿‡å°† Winograd æ’å€¼ç‚¹é€‰æ‹©é‡æ„ä¸ºè¿ç»­ä¼˜åŒ–é—®é¢˜ï¼Œæ‰“ç ´äº†æ•°åå¹´æ¥å¯¹æ•´æ•°ç‚¹çš„ä¾èµ–ï¼Œå‘ç°äº†é«˜åº¦ç¨³å®šçš„åˆ†æ•°é…ç½®ã€‚å…¶å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯åœ¨ä¸å¢åŠ è®¡ç®—å¼€é”€çš„å‰æä¸‹ï¼Œä½¿å¤§å— Winograd åœ¨ FP16/INT8 ä¸‹ä»â€œå®Œå…¨å¤±æ•ˆâ€å˜ä¸ºâ€œé«˜ç²¾åº¦å¯ç”¨â€ï¼Œä¸ºä¸‹ä¸€ä»£é«˜æ•ˆç¥ç»ç½‘ç»œæ¨ç†æä¾›äº†åšå®åŸºç¡€ã€‚

</details>

---

### 6. [CienaLLM: Generative Climate-Impact Extraction from News Articles with Autoregressive LLMs](https://arxiv.org/abs/2512.19305)

**Authors**: Javier Vela-Tambo, Jorge Gracia, Fernando Dominguez-Castro  
**Category**: cs.CL  
**Published**: 2025-12-23  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.19305v1  

#### Abstract
Understanding and monitoring the socio-economic impacts of climate hazards requires extracting structured information from heterogeneous news articles on a large scale. To that end, we have developed CienaLLM, a modular framework based on schema-guided Generative Information Extraction. CienaLLM use...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCienaLLM: Generative Climate-Impact Extraction from News Articles with Autoregressive LLMs

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿæ°”å€™å½±å“ç›‘æµ‹ä¾èµ–äºç‰©ç†å¹²æ—±æŒ‡æ•°ï¼ˆå¦‚SPIã€PDSIï¼‰ï¼Œè¿™äº›æŒ‡æ ‡æ— æ³•åæ˜ ç¤¾ä¼šç»æµå±‚é¢çš„å®é™…å½±å“ã€‚å°½ç®¡æ–°é—»æ–‡ç« æ˜¯è®°å½•å¹²æ—±ç­‰æ°”å€™äº‹ä»¶ç¤¾ä¼šå½±å“çš„ä¸°å¯Œæ¥æºï¼Œä½†å…¶ä¿¡æ¯é«˜åº¦åˆ†æ•£ä¸”å¼‚æ„ï¼Œäººå·¥æˆ–åŠè‡ªåŠ¨æå–æˆæœ¬é«˜ã€éš¾ä»¥è§„æ¨¡åŒ–ã€‚ç°æœ‰ç›‘ç£æ¨¡å‹ï¼ˆå¦‚SeqIAï¼‰è™½èƒ½å®ç°è¾ƒé«˜å‡†ç¡®ç‡ï¼Œä½†éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®å¹¶é’ˆå¯¹ç‰¹å®šä»»åŠ¡é‡æ–°è®­ç»ƒï¼Œç¼ºä¹çµæ´»æ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
æœ¬æ–‡æå‡º **CienaLLM** â€”â€” ä¸€ä¸ªåŸºäº **schema-guided Generative Information Extraction (GenIE)** çš„æ¨¡å—åŒ–æ¡†æ¶ï¼Œåˆ©ç”¨ **open-weight LLMs** åœ¨é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰è®¾ç½®ä¸‹ä»è¥¿ç­ç‰™è¯­æ–°é—»ä¸­æå–ç»“æ„åŒ–æ°”å€™å½±å“ä¿¡æ¯ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
- **é›¶æ ·æœ¬ç”Ÿæˆå¼ä¿¡æ¯æŠ½å–ï¼ˆZero-shot GenIEï¼‰**ï¼šæ— éœ€å¾®è°ƒæˆ–é‡æ–°è®­ç»ƒï¼Œä»…é€šè¿‡è‡ªç„¶è¯­è¨€æç¤ºï¼ˆpromptingï¼‰å¼•å¯¼LLMè¾“å‡ºç¬¦åˆé¢„å®šä¹‰schemaçš„ç»“æ„åŒ–ä¿¡æ¯ï¼ˆå¦‚JSONæ ¼å¼ï¼‰ã€‚
- **æ¨¡å—åŒ–ä¸å¯é…ç½®è®¾è®¡**ï¼šæ”¯æŒçµæ´»é…ç½®promptæ¨¡æ¿ã€output schemaã€å¤šæ­¥pipelineï¼ˆå¦‚summarizationã€self-criticismï¼‰ã€æœ¬åœ°æˆ–äº‘ç«¯æ¨ç†ï¼Œä¾¿äºå¤ç°å’Œæ‰©å±•ã€‚
- **æ¨¡å‹æ— å…³æ€§ï¼ˆModel-agnosticï¼‰**ï¼šå¯åœ¨ä¸åŒLLMå®¶æ—ï¼ˆGemmaã€Llamaã€Qwenï¼‰é—´åˆ‡æ¢ï¼Œé€‚åº”ä¸åŒç¡¬ä»¶èµ„æºéœ€æ±‚ã€‚
- **å¼€æ”¾ä¸å¯å¤ç°**ï¼šå‘å¸ƒä»£ç ã€é…ç½®æ–‡ä»¶å’Œschemaå®šä¹‰ï¼Œä¿ƒè¿›å¯æŒç»­ç ”ç©¶ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿç›‘ç£æ–¹æ³•ï¼ˆå¦‚SeqIAï¼‰ | CienaLLM |
|------|------------------------|---------|
| **æ ‡æ³¨ä¾èµ–** | éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒ | é›¶æ ·æœ¬ï¼Œæ— éœ€æ ‡æ³¨ |
| **æ³›åŒ–èƒ½åŠ›** | æ›´æ¢ä»»åŠ¡/è¯­è¨€éœ€é‡æ–°æ ‡æ³¨å’Œè®­ç»ƒ | åªéœ€ä¿®æ”¹promptå’Œschemaå³å¯è¿ç§» |
| **éƒ¨ç½²çµæ´»æ€§** | å¤šä¸ºAPIæœåŠ¡ï¼Œéšç§ä¸æ§åˆ¶å—é™ | æ”¯æŒæœ¬åœ°éƒ¨ç½²ï¼ˆvia Ollamaï¼‰ï¼Œä¿éšœéšç§ä¸å¯æ§æ€§ |
| **ç»´æŠ¤æˆæœ¬** | æ¨¡å‹æ›´æ–°éœ€é‡æ–°è®­ç»ƒ | ç»§æ‰¿æ–°LLMç‰ˆæœ¬çš„èƒ½åŠ›ï¼Œæ— éœ€é‡è®­ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒåŸºäºå¹¶æ‰©å±•äº†Lopez-Otalç­‰äººæ„å»ºçš„æ•°æ®é›†ï¼Œå¹¶æ–°å¢ä¸‰ä¸ªä¸“ç”¨è¯„ä¼°é›†ï¼š

| æ•°æ®é›† | æè¿° | è§„æ¨¡ |
|-------|------|-----|
| **DID (Drought Impacts Dataset)** | æ–‡ç« çº§å¹²æ—±å½±å“æ ‡æ³¨ï¼Œæ¶µç›–å†œä¸šã€ç•œç‰§ä¸šã€æ°´èµ„æºã€èƒ½æºå››ç±»å½±å“ | 386ç¯‡æ–‡ç« ï¼ˆéªŒè¯é›†269ï¼Œæµ‹è¯•é›†117ï¼‰ |
| **DRD (Drought Relevance Dataset)** | åˆ¤æ–­æ–‡ç« æ˜¯å¦æ¶‰åŠå¹²æ—±çš„äºŒåˆ†ç±»ä»»åŠ¡ | 2,240ç¯‡æ–‡ç« ï¼ˆæ­£ä¾‹1,270ï¼Œè´Ÿä¾‹970ï¼‰ |
| **DILD (Drought Impact Locations Dataset)** | æ ‡æ³¨å—å½±å“çš„è¥¿ç­ç‰™çœä»½ï¼ˆå…±50ä¸ªï¼‰ | 100ç¯‡æ–‡ç« ï¼Œå¹³å‡æ¯ç¯‡æåŠ8.35ä¸ªçœ |

æ­¤å¤–è¿˜æ„å»ºäº†å¤§è§„æ¨¡è¥¿ç­ç‰™æ–°é—»è¯­æ–™åº“ï¼ˆEl PaÃ­s, ABC, 20 Minutosç­‰ï¼‰ï¼Œç”¨äºæœªæ¥åˆ†æã€‚

### å®éªŒè®¾ç½®
- **LLMé€‰æ‹©**ï¼š12ä¸ªopen-weightæ¨¡å‹ï¼Œè¦†ç›–ä¸‰å¤§å®¶æ—ï¼ˆGemmaã€Llamaã€Qwenï¼‰ï¼Œä¸‰ç§è§„æ¨¡ï¼ˆå°<7Bã€ä¸­7â€“25Bã€å¤§>25Bï¼‰ï¼Œä¸¤ç§ç²¾åº¦ï¼ˆfp16 å’Œ 4-bité‡åŒ– q4_K_Mï¼‰ã€‚
- **Promptå·¥ç¨‹ç­–ç•¥**ï¼š
  - **SUM**ï¼ˆSummarizationï¼‰ï¼šå…ˆæ‘˜è¦å†æå–
  - **CoT**ï¼ˆChain of Thoughtï¼‰ï¼šâ€œé€æ­¥æ¨ç†â€æŒ‡ä»¤
  - **SC**ï¼ˆSelf-Criticismï¼‰ï¼šç¬¬äºŒè½®è‡ªæˆ‘ä¿®æ­£
  - **DESC**ï¼ˆImpact Descriptionsï¼‰ï¼šåŠ å…¥å½±å“ç±»åˆ«è¯¦ç»†æè¿°
- **å“åº”è§£æç­–ç•¥ï¼ˆRPARSEï¼‰**ï¼š
  - `RPARSE=False`ï¼šå•æ­¥ç”ŸæˆJSON
  - `RPARSE=True`ï¼šä¸¤æ­¥æ³•ï¼Œå…ˆè‡ªç”±æ–‡æœ¬æå–ï¼Œå†ç”±å¦ä¸€LLMè½¬ä¸ºJSON
- **JGENæ¨¡å¼**ï¼šç»Ÿä¸€ä½¿ç”¨`prompt`æ–¹å¼æŒ‡å®šJSONæ ¼å¼ï¼ˆå› Gemmaä¸æ”¯æŒtool callingï¼‰

### è¯„ä¼°æŒ‡æ ‡
- **å‡†ç¡®æ€§**ï¼šmicro-F1ã€Precisionã€Recallã€Accuracyï¼ˆå¤šæ ‡ç­¾åˆ†ç±»ï¼‰
- **å¯é æ€§**ï¼šParsing Error Rateï¼ˆæ— æ³•è§£æä¸ºåˆæ³•JSONçš„æ¯”ä¾‹ï¼‰
- **æ•ˆç‡**ï¼šæ¯ç¯‡æ–‡ç« å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
ä¸ç›‘ç£æ¨¡å‹ **SeqIA** è¿›è¡Œæ¯”è¾ƒï¼Œåœ¨ç›¸åŒE2Eæ•°æ®é›†ä¸Šè¯„ä¼°æ€§èƒ½ä¸å»¶è¿Ÿã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆåœ¨DIDæµ‹è¯•é›†ä¸Šï¼‰

| é…ç½® | F1 Score | Precision | Recall | Exec. Time (s/art.) |
|------|----------|-----------|--------|---------------------|
| **Best-F1** (qwen_72b + CoT + DESC + RPARSE) | **0.873** | 0.837 | 0.911 | 36.43 |
| **Efficient** (qwen_7b + DESC + RPARSE) | 0.808 | 0.832 | 0.785 | 3.32 |
| **Fastest** (qwen_3b + RPARSE) | 0.646 | 0.810 | 0.538 | 2.47 |

> æ‰€æœ‰é…ç½®å‡æ— parsing errorã€‚

#### åˆ†ç±»åˆ«è¡¨ç°ï¼ˆBest-F1ï¼‰
| å½±å“ç±»å‹ | F1 Score |
|--------|---------|
| å†œä¸š | 0.868 |
| ç•œç‰§ä¸š | 0.966 |
| æ°´èµ„æº | 0.824 |
| èƒ½æº | 0.914 |

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆåœ¨E2Eæ•°æ®é›†ä¸Šï¼‰

| æ–¹æ³• | F1 Score | Exec. Time (s/art.) |
|------|----------|---------------------|
| **CienaLLM (Best-F1)** | **0.782** | 30.07 |
| **SeqIA (supervised)** | 0.769 | **1.54** |

ğŸ‘‰ **ç»“è®º**ï¼šCienaLLMåœ¨å‡†ç¡®æ€§ä¸Š**ç•¥ä¼˜äºSeqIA**ï¼ˆ+1.3% F1ï¼‰ï¼Œä½†æ¨ç†è€—æ—¶é«˜å‡ºçº¦20å€ã€‚

### æ¶ˆèå®éªŒå…³é”®å‘ç°

#### ï¼ˆ1ï¼‰Response Parsing æ˜¾è‘—æå‡å¯é æ€§
- å¹³å‡parsing errorä» **4.0%**ï¼ˆæ— RPARSEï¼‰é™è‡³ **0.7%**ï¼ˆå¯ç”¨RPARSEï¼‰
- å¯¹æŸäº›æ¨¡å‹ï¼ˆå¦‚`llama_8b`ï¼‰é”™è¯¯ç‡ä¸‹é™è¶…15ä¸ªç™¾åˆ†ç‚¹
- å‡†ç¡®ç‡å‡ ä¹ä¸å˜ï¼ˆF1å·®å¼‚ä¸æ˜¾è‘—ï¼‰ï¼Œä½†å¯é æ€§å¤§å¹…æå‡

#### ï¼ˆ2ï¼‰æ¨¡å‹å¤§å°å†³å®šæ€§èƒ½ä¸Šé™
- å¤§æ¨¡å‹ï¼ˆ>70Bï¼‰è¡¨ç°æœ€å¼ºä¸”æœ€ç¨³å®šï¼ˆä½æ–¹å·®ï¼‰
- `qwen_72b` å’Œ `llama_70b` å¹³å‡F1 > 0.85
- å°æ¨¡å‹ï¼ˆå¦‚`gemma_4b`, `qwen_3b`ï¼‰æ€§èƒ½æ³¢åŠ¨å¤§ï¼Œå¯¹promptæ•æ„Ÿ

#### ï¼ˆ3ï¼‰é‡åŒ–å¸¦æ¥æ˜¾è‘—æ•ˆç‡å¢ç›Š
- 4-bité‡åŒ–ä½¿æ‰§è¡Œæ—¶é—´å‡å°‘ **30â€“40%**
- F1æŸå¤±è¾ƒå°ï¼š
  - Gemma: -0.008
  - Llama: -0.017
  - Qwen: -0.008
- æ¨èåœ¨èµ„æºå—é™åœºæ™¯ä½¿ç”¨é‡åŒ–æ¨¡å‹

#### ï¼ˆ4ï¼‰Promptç­–ç•¥æ•ˆæœå…·æœ‰æ¨¡å‹ç‰¹å¼‚æ€§
| ç­–ç•¥ | æ•ˆæœæ€»ç»“ |
|------|--------|
| **SUM** | âœ… å¯¹Gemmaæœ‰æ•ˆï¼ˆ+0.054 F1ï¼‰<br>âŒ å¯¹Llama/Qwenæœ‰å®³ |
| **CoT** | âœ… ä¸­å¤§å‹æ¨¡å‹ç•¥æœ‰æå‡ï¼ˆ+0.01ï¼‰<br>âŒ å°æ¨¡å‹æ— æ•ˆ |
| **SC** | âŒ å‡ ä¹æ— æ”¶ç›Šï¼Œå¤šæ•°æ¨¡å‹å¿½ç•¥æŒ‡ä»¤ |
| **DESC** | âœ… å¤§æ¨¡å‹å—ç›Šæ˜æ˜¾ï¼ˆqwen_72b +0.021ï¼‰<br>âŒ å°æ¨¡å‹åè€Œä¸‹é™ |

> æœ€ä½³é…ç½®é€šå¸¸åŒ…å« **DESC** å’Œ **CoT**ï¼ŒGemmaåå¥½ **SUM**

#### ï¼ˆ5ï¼‰Location Extraction æ˜¯æœ€éš¾ä»»åŠ¡
| é…ç½® | F1 Score | Parsing Error |
|------|----------|---------------|
| Best-F1 | 0.465 | 2% |
| Efficient | 0.233 | 50% |
| Fastest | 0.007 | 62% |

ğŸ‘‰ è¡¨æ˜ä»æ–‡æœ¬æ¨æ–­â€œå—å½±å“åŒºåŸŸâ€æå…·æŒ‘æˆ˜ï¼Œéœ€ç»“åˆåœ°ç†çŸ¥è¯†åº“è¿›ä¸€æ­¥åå¤„ç†ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **CienaLLM åœ¨é›¶æ ·æœ¬ä¸‹å¯è¾¾åˆ°ç”šè‡³è¶…è¶Šç›‘ç£æ¨¡å‹çš„å‡†ç¡®ç‡**ï¼Œå°¤å…¶åœ¨å¹²æ—±å½±å“æå–å’Œç›¸å…³æ€§åˆ¤æ–­ä»»åŠ¡ä¸Šã€‚
2. **æ›´å¤§çš„LLMæä¾›æ›´å¼ºã€æ›´ç¨³å®šçš„æ€§èƒ½**ï¼Œé€‚åˆé«˜ç²¾åº¦åœºæ™¯ï¼›è€Œä¸­å°æ¨¡å‹ç»ä¼˜åŒ–åä¹Ÿå¯å®ç°è‰¯å¥½æ€§ä»·æ¯”ã€‚
3. **é‡åŒ–æŠ€æœ¯å¯åœ¨è½»å¾®ç²¾åº¦ä»£ä»·ä¸‹å¤§å¹…é™ä½è®¡ç®—å¼€é”€**ï¼Œé€‚åˆè¾¹ç¼˜æˆ–ä½æˆæœ¬éƒ¨ç½²ã€‚
4. **Promptç­–ç•¥å¹¶éé€šç”¨é“¶å¼¹**ï¼Œå…¶æœ‰æ•ˆæ€§é«˜åº¦ä¾èµ–æ¨¡å‹å®¶æ—ä¸è§„æ¨¡ï¼Œåº”ä½œä¸ºå¯è°ƒè¶…å‚è€Œéå›ºå®šæµç¨‹ã€‚
5. **å¯ç”¨ä¸¤æ­¥å¼Response Parsingå‡ ä¹æ¶ˆé™¤æ ¼å¼é”™è¯¯**ï¼Œæ˜¯ç¡®ä¿è·¨æ¨¡å‹å…¬å¹³æ¯”è¾ƒçš„å…³é”®æ­¥éª¤ã€‚
6. **åœ°ç†ä½ç½®æå–ä»æ˜¯ç“¶é¢ˆ**ï¼Œå½“å‰LLMéš¾ä»¥å¯é åœ°å°†æ¨¡ç³Šè¡¨è¿°ï¼ˆå¦‚â€œåŠå²›ä¸œåŒ—éƒ¨â€ï¼‰æ˜ å°„åˆ°å…·ä½“è¡Œæ”¿å•ä½ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **é«˜æ¨ç†å»¶è¿Ÿ**ï¼šç›¸æ¯”SeqIAæ…¢æ•°åå€ï¼Œä¸é€‚åˆå¤§è§„æ¨¡é¢„è¿‡æ»¤ã€‚
- **ä¾èµ–é«˜è´¨é‡promptè®¾è®¡**ï¼šéœ€é¢†åŸŸä¸“å®¶å‚ä¸å®šä¹‰impact descriptionsã€‚
- **æœªè¯„ä¼°å…¶ä»–ç¾å®³ç±»å‹**ï¼šç›®å‰ä»…éªŒè¯å¹²æ—±åœºæ™¯ï¼Œæ³›åŒ–è‡³æ´ªæ°´ã€çƒ­æµªç­‰æœ‰å¾…éªŒè¯ã€‚
- **è¯­è¨€é™åˆ¶**ï¼šå®éªŒé›†ä¸­äºè¥¿ç­ç‰™è¯­ï¼Œè·¨è¯­è¨€è¿ç§»éœ€è¿›ä¸€æ­¥æµ‹è¯•ã€‚
- **é™æ€schemaä¾èµ–**ï¼šä»éœ€æ‰‹åŠ¨å®šä¹‰å’Œç»´æŠ¤schemaï¼Œè‡ªåŠ¨åŒ–ç¨‹åº¦æœ‰é™ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³å…¶ä»–æ°”å€™ç¾å®³ï¼ˆfloods, hailstorms, heatwavesï¼‰å’Œå…¶ä»–å›½å®¶/è¯­è¨€ã€‚
- æ¢ç´¢few-shotæˆ–retrieval-augmented generationä»¥è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚
- å¼€å‘ensembleç­–ç•¥èåˆå¤šä¸ªLLMå®¶æ—ä¼˜åŠ¿ã€‚
- ç»“åˆç¡®å®šæ€§åœ°ç†è§£æå·¥å…·ï¼ˆgazetteers, basin mapsï¼‰æå‡location extraction recallã€‚
- æ„å»ºç«¯åˆ°ç«¯ç³»ç»Ÿï¼Œå°†æå–ç»“æœè½¬åŒ–ä¸ºå¯è§†åŒ–ä»ªè¡¨ç›˜æˆ–å†³ç­–æ”¯æŒä¿¡å·ã€‚
- æ¢ç´¢è½»é‡çº§LLM + prompt tuningç»„åˆï¼Œåœ¨ä¿æŒæ•ˆç‡çš„åŒæ—¶é€¼è¿‘å¤§æ¨¡å‹æ€§èƒ½ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> CienaLLM å±•ç¤ºäº† **schema-guided GenIE + open-weight LLMs** åœ¨æ°”å€™å½±å“ä¿¡æ¯æå–ä¸­çš„å¼ºå¤§æ½œåŠ›ï¼Œå®ç°äº†æ— éœ€è®­ç»ƒå³å¯çµæ´»é€‚é…æ–°ä»»åŠ¡çš„èƒ½åŠ›ï¼Œè™½ç„¶ç‰ºç‰²äº†ä¸€å®šæ•ˆç‡ï¼Œä½†åœ¨å‡†ç¡®æ€§å’Œå¯æ‰©å±•æ€§æ–¹é¢å±•ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œä¸ºæ„å»ºåŠ¨æ€ã€å¯è§£é‡Šã€å¯æŒç»­çš„æ°”å€™é£é™©ç›‘æµ‹ç³»ç»Ÿæä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 7. [L4: Low-Latency and Load-Balanced LLM Serving via Length-Aware Scheduling](https://arxiv.org/abs/2512.19179)

**Authors**: Yitao Yuan (Peking University, ScitiX AI), Chenqi Zhao (Peking University), Bohan Zhao (ScitiX AI), Zane Cao (ScitiX AI), Yongchao He (ScitiX AI), Wenfei Wu (Peking University)  
**Category**: cs.DC  
**Published**: 2025-12-23  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.19179v1  

#### Abstract
Efficiently harnessing GPU compute is critical to improving user experience and reducing operational costs in large language model (LLM) services. However, current inference engine schedulers overlook the attention backend's sensitivity to request-length heterogeneity within a batch. As state-of-the...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šL4: Low-Latency and Load-Balanced LLM Serving via Length-Aware Scheduling

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœåŠ¡ä¸­ï¼Œéšç€ä¸Šä¸‹æ–‡é•¿åº¦æ”¯æŒè¶…è¿‡ 128K tokensï¼Œ**è¯·æ±‚åºåˆ—é•¿åº¦å¼‚è´¨æ€§ï¼ˆlength heterogeneityï¼‰** æˆä¸ºç³»ç»Ÿæ€§èƒ½ç“¶é¢ˆã€‚ç°æœ‰è°ƒåº¦å™¨åœ¨æ‰¹å¤„ç†æ—¶æ··åˆé•¿çŸ­è¯·æ±‚ï¼Œå¯¼è‡´ï¼š

- **Attention åç«¯æ€§èƒ½ä¸¥é‡ä¸‹é™**ï¼šç”±äº GPU å†…éƒ¨è´Ÿè½½ä¸å‡è¡¡ã€åŒæ­¥å¼€é”€å¢åŠ ï¼›
- **GPU åˆ©ç”¨ç‡ä½ä¸‹** å’Œ **å»¶è¿Ÿæ˜¾è‘—ä¸Šå‡**ï¼Œå°¤å…¶æ˜¯é•¿å°¾å»¶è¿Ÿï¼ˆtail latencyï¼‰ï¼›
- å•å®ä¾‹è°ƒåº¦å—é™äº Littleâ€™s Lawï¼Œæ— æ³•ç§¯ç´¯è¶³å¤Ÿè¯·æ±‚æ¥å½¢æˆåŒè´¨æ‰¹æ¬¡ã€‚

å°½ç®¡å·²æœ‰ä¼˜åŒ–å¦‚ FlashAttention æå‡äº† kernel æ•ˆç‡ï¼Œä½†**è°ƒåº¦å±‚ä»æœªèƒ½åŒ¹é…ç¡¬ä»¶å¯¹é•¿åº¦åŒè´¨æ€§çš„åå¥½**ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **L4** â€”â€” ä¸€ç§åŸºäº**é•¿åº¦æ„ŸçŸ¥çš„è·¨å®ä¾‹è°ƒåº¦ç³»ç»Ÿ**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **â€œGlobal homogenization for local efficiencyâ€**  
> é€šè¿‡å…¨å±€è°ƒåº¦å®ç°å±€éƒ¨é«˜æ•ˆï¼šå°†å¤šå®ä¾‹é›†ç¾¤ç»„ç»‡æˆæŒ‰åºåˆ—é•¿åº¦åˆ’åˆ†çš„ä¸“ç”¨é˜¶æ®µï¼ˆstagesï¼‰ï¼Œå½¢æˆä¸€ä¸ªé€»è¾‘æµæ°´çº¿ã€‚

#### ä¸»è¦æœºåˆ¶åŒ…æ‹¬ï¼š

1. **Length-Specialized Pipeline æ„å»º**  
   å°†å¤šä¸ª LLM æ¨ç†å®ä¾‹åˆ’åˆ†ä¸ºè‹¥å¹²ç»„ï¼ˆstagesï¼‰ï¼Œæ¯ç»„ä¸“é—¨å¤„ç†ç‰¹å®šé•¿åº¦èŒƒå›´å†…çš„è¯·æ±‚ã€‚éšç€è§£ç è¿›è¡Œï¼Œè¯·æ±‚è‡ªç„¶ä»çŸ­åˆ°é•¿é˜¶æ®µè¿ç§»ã€‚

2. **åŠ¨æ€è§„åˆ’ç®—æ³•è¿›è¡Œæœ€ä¼˜é˜¶æ®µåˆ’åˆ†ï¼ˆStage Partitioningï¼‰**  
   åŸºäºå†å²å·¥ä½œè´Ÿè½½ç»Ÿè®¡ï¼Œä½¿ç”¨åŠ¨æ€è§„åˆ’ï¼ˆDynamic Programmingï¼‰å¯»æ‰¾æœ€ä¼˜çš„ stage æ•°é‡ã€å„ stage é•¿åº¦åŒºé—´åŠå®ä¾‹åˆ†é…ï¼Œä»¥æœ€å°åŒ–æ•´ä½“ QoEï¼ˆQuality of Experienceï¼‰ã€‚

3. **è¿è¡Œæ—¶è‡ªé€‚åº”è¾¹ç•Œè°ƒæ•´ï¼ˆAdaptive Range Refinementï¼‰**  
   æ¯ä¸ªå®ä¾‹é€šè¿‡ `LoadTracker` æ”¶é›†è‡ªèº«ä¸ä¸‹æ¸¸å®ä¾‹çš„è¯·æ±‚é•¿åº¦åˆ†å¸ƒï¼ŒåŠ¨æ€è°ƒæ•´é˜¶æ®µè¾¹ç•Œï¼Œåº”å¯¹è´Ÿè½½æ¼‚ç§»ã€‚

4. **å»ä¸­å¿ƒåŒ–çš„ Bid-Ask è´Ÿè½½å‡è¡¡åè®®**  
   å½“æŸå®ä¾‹è¿‡è½½æ—¶ï¼Œä¸»åŠ¨â€œå‡ºä»·â€ï¼ˆaskï¼‰è¿ç§»è¯·æ±‚ï¼›å…¶ä»–è½»è½½å®ä¾‹â€œç«ä»·â€ï¼ˆbidï¼‰æ¥æ”¶è¯·æ±‚ã€‚æ— éœ€ä¸­å¤®åè°ƒå™¨ï¼Œå®ç°é«˜æ•ˆçš„è·¨é˜¶æ®µå’Œç»„å†…è´Ÿè½½å†å¹³è¡¡ã€‚

5. **KV Cache çš„å¼‚æ­¥ Live Migration**  
   åœ¨è¯·æ±‚è¿ç§»è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨ç±»ä¼¼ Llumnix çš„æœºåˆ¶ï¼Œåˆ†è½®æ¬¡ä¼ è¾“ KV ç¼“å­˜ï¼Œé¿å…é˜»å¡æºå®ä¾‹ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ vLLM, SGLang, Llumnixï¼‰ | L4 |
|------|----------------------------------------|-----|
| è°ƒåº¦ç²’åº¦ | å•å®ä¾‹å†…éƒ¨è°ƒåº¦ä¸ºä¸»ï¼Œå¿½ç•¥è·¨å®ä¾‹ååŒ | å…¨å±€è§†è§’ï¼Œè·¨å®ä¾‹é•¿åº¦æ„ŸçŸ¥è°ƒåº¦ |
| æ‰¹å¤„ç†åŒè´¨æ€§ | éš¾ä»¥é¿å…é•¿çŸ­è¯·æ±‚æ··åˆ | è‡ªåŠ¨å½¢æˆé•¿åº¦åŒè´¨æ‰¹æ¬¡ |
| è´Ÿè½½å‡è¡¡ | ä¸­å¿ƒåŒ–æˆ–ç®€å•è½®è¯¢ | å»ä¸­å¿ƒåŒ– bid-askï¼Œå“åº”å¼è´Ÿè½½å‡è¡¡ |
| å¯æ‰©å±•æ€§ | å­˜åœ¨å•ç‚¹ç“¶é¢ˆé£é™© | åˆ†å¸ƒå¼è®¾è®¡ï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½² |
| æ€§èƒ½æå‡ | å±€é™äºå•å®ä¾‹ä¼˜åŒ– | æ˜¾è‘—é™ä½å»¶è¿Ÿã€æé«˜åå |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **ShareGPT æ•°æ®é›†**ï¼ˆ[RyokoAI/ShareGPT52K](https://huggingface.co/datasets/RyokoAI/ShareGPT52K)ï¼‰
  - åŒ…å«çœŸå® ChatGPT å¯¹è¯è®°å½•ï¼Œå…·æœ‰å…¸å‹çš„**é«˜åº¦åæ–œçš„è¯·æ±‚é•¿åº¦åˆ†å¸ƒ**ï¼ˆå¤§é‡çŸ­è¯·æ±‚ + å°‘é‡æé•¿è¯·æ±‚ï¼‰ã€‚
  - è¯·æ±‚é•¿åº¦ä¸Šé™è®¾ä¸º 128K tokensã€‚

### **å®éªŒè®¾ç½®**

- **æµ‹è¯•å¹³å°**ï¼š
  - **H20 æµ‹è¯•åºŠ**ï¼š2 èŠ‚ç‚¹ Ã— 8Ã—NVLink è¿æ¥çš„ H20 GPUï¼ˆæ¯å¡ 141GB æ˜¾å­˜ï¼‰
  - **L40 æµ‹è¯•åºŠ**ï¼š2 èŠ‚ç‚¹ Ã— 8Ã—PCIe è¿æ¥çš„ L40 GPUï¼ˆæ¯å¡ 48GB æ˜¾å­˜ï¼‰

- **æ¨¡å‹è¦†ç›–èŒƒå›´å¹¿**ï¼š
  - Tiny: Llama-3.2-3B, Phi-3-3B
  - Small: Llama-3.1-8B, GLM-4-9B
  - Moderate: Phi-3-14B, Qwen2.5-14B
  - Large: QwQ-32B, Qwen2.5-32B
  - ç‰¹åˆ«æµ‹è¯•äº† **Llama-3.1-70B** åœ¨ TP=2 å’Œ TP=4 ä¸‹çš„è¡¨ç°

- **è¯·æ±‚æ¨¡å¼**ï¼š
  - ä½¿ç”¨ Poisson è¿‡ç¨‹æ¨¡æ‹Ÿè¯·æ±‚åˆ°è¾¾ï¼Œé€Ÿç‡å¯è°ƒï¼ˆè½»è½½è‡³é‡è½½ï¼‰
  - æ¯ä¸ªæµ‹è¯•æŒç»­ç›¸åŒæ—¶é—´ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒ

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **TTFT** (Time to First Token) | ç”¨æˆ·æäº¤è¯·æ±‚åˆ°æ”¶åˆ°ç¬¬ä¸€ä¸ªè¾“å‡º token çš„å»¶è¿Ÿ |
| **TPOT** (Time per Output Token) | æ¯ç”Ÿæˆä¸€ä¸ªåç»­ token çš„å¹³å‡å»¶è¿Ÿ |
| **Throughput** | ç³»ç»Ÿæ•´ä½“æ¯ç§’ç”Ÿæˆçš„ token æ•°é‡ |
| **SLO Attainment** | æ»¡è¶³é¢„å®šä¹‰ SLOï¼ˆå¦‚ 5Ã—/10Ã—/20Ã—åŸºç¡€å»¶è¿Ÿï¼‰çš„è¯·æ±‚æ¯”ä¾‹ |
| **Normalized Latency** | ç«¯åˆ°ç«¯å»¶è¿Ÿ / è¾“å‡º token æ•°ï¼Œç»¼åˆè¡¡é‡æ•ˆç‡ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿ | æè¿° |
|------|------|
| **vLLM 0.9.1** | ä½¿ç”¨ FCFS è°ƒåº¦ + FlashAttentionï¼Œæ— è·¨å®ä¾‹è°ƒåº¦ |
| **SGLang 0.4.9** | æ”¯æŒç»“æ„åŒ–æ¨ç†ï¼Œä½¿ç”¨ FlashInfer åç«¯ |
| **Llumnix** | å½“å‰æœ€å…ˆè¿›çš„å¤šå®ä¾‹è°ƒåº¦ç³»ç»Ÿï¼Œå…·å¤‡è¯·æ±‚è¿ç§»èƒ½åŠ›ï¼Œä½œä¸ºä¸»è¦å¯¹æ¯”å¯¹è±¡ |

æ‰€æœ‰ç³»ç»Ÿå‡éƒ¨ç½²å¤šä¸ªå®ä¾‹ï¼Œå¹¶é…åˆ Round-Robin æˆ–å†…ç½®è°ƒåº¦å™¨è¿›è¡Œè´Ÿè½½åˆ†å‘ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **å»¶è¿Ÿæ˜¾è‘—é™ä½**

- **Median TTFT ä¸‹é™æœ€å¤šè¾¾ 67%**
- **Tail TTFT ä¸‹é™æœ€å¤šè¾¾ 69%**
- **Mean TPOT ä¸‹é™ 30%-64%**ï¼ˆvs vLLMï¼‰ï¼Œæœ€é«˜è¾¾ 77%ï¼ˆvs SGLangï¼‰

> ç¤ºä¾‹ï¼ˆH20 testbed, heavy loadï¼‰ï¼š
> - Llama-3.2-3B ä¸Šï¼ŒL4 ç›¸æ¯” vLLM å¹³å‡ TTFT é™ä½ **78%**
> - ç›¸æ¯” Llumnixï¼ˆstate-of-the-art inter-instance schedulerï¼‰ï¼ŒTTFT é™ä½ **36%-66%**

#### âœ… **ååå¤§å¹…æå‡**

- **æ•´ä½“ç³»ç»Ÿååæœ€é«˜æå‡ 2.89Ã—**ï¼ˆvs Llumnixï¼‰
- åœ¨ä¸åŒæ¨¡å‹ä¸Šå¹³å‡æå‡ï¼š
  - vs vLLM: **1.99Ã—**
  - vs SGLang: **2.18Ã—**
  - vs Llumnix: **1.71Ã—**

> åœ¨ Llama-3.1-70Bï¼ˆTP=4ï¼‰é…ç½®ä¸‹ï¼Œååæå‡é«˜è¾¾ **4.16Ã—**

#### âœ… **SLO è¾¾æˆç‡æ˜¾è‘—æ”¹å–„**

- åœ¨ 5Ã— SLO æ¡ä»¶ä¸‹ï¼ŒSLO attainment æå‡ **3.8â€“7.6Ã—**
- åœ¨ 20Ã— SLO æ¡ä»¶ä¸‹ï¼Œä»ä¿æŒ **2.0â€“2.8Ã—** çš„ä¼˜åŠ¿

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

#### ğŸ” **QoE æ¨¡å‹å‡†ç¡®æ€§éªŒè¯**
- ç›¸æ¯”é™æ€é¢„æµ‹å™¨ï¼ˆè¿”å›å…¨å±€å¹³å‡å»¶è¿Ÿï¼‰ï¼ŒL4 çš„ QoE æ¨¡å‹é¢„æµ‹è¯¯å·®ä»… **8.9%**ï¼ˆvs 64%ï¼‰
- é”™è¯¯é›†ä¸­åœ¨é›¶é™„è¿‘ï¼Œè¯´æ˜æ¨¡å‹èƒ½å‡†ç¡®åæ˜ å®é™…å»¶è¿Ÿè¶‹åŠ¿

#### ğŸ” **ä¸åŒ pipeline ç»“æ„å¯¹æ¯”**
| é…ç½® | è¡¨ç° |
|------|------|
| **No Pipeline**ï¼ˆæ‰€æœ‰å®ä¾‹åˆå¹¶ä¸ºä¸€ stageï¼‰ | æ€§èƒ½æœ€å·®ï¼Œå› é•¿åº¦å¼‚è´¨æ€§é«˜ |
| **Chain Layout**ï¼ˆæ¯ä¸ª stage ä¸€ä¸ªå®ä¾‹ï¼‰ | è¿ç§»å¼€é”€å¤§ï¼Œè´Ÿè½½éš¾å¹³è¡¡ |
| **L4ï¼ˆåŠ¨æ€åˆ’åˆ†ï¼‰** | **å»¶è¿Ÿä½ 30%ï¼Œååé«˜ 7.1%** |

#### ğŸ” **è¾¹ç•Œè°ƒæ•´ç­–ç•¥å¯¹æ¯”**
| ç­–ç•¥ | è¡¨ç° |
|------|------|
| Quantity-basedï¼ˆæŒ‰è¯·æ±‚æ•°å‡åˆ†ï¼‰ | è´Ÿè½½ä¸¥é‡ä¸å¹³è¡¡ï¼Œæ€§èƒ½å·® |
| Memory-basedï¼ˆæŒ‰æ˜¾å­˜å ç”¨å‡åˆ†ï¼‰ | å¿½è§†è¯·æ±‚å¤æ‚åº¦å·®å¼‚ |
| **L4ï¼ˆåŸºäº QoE ä¼˜åŒ–ï¼‰** | **å»¶è¿Ÿé™ä½ 21%ï¼Œååæå‡ 12%** |

#### ğŸ” **Bid-Ask åè®®æœ‰æ•ˆæ€§**
- ä½¿ç”¨ **Coefficient of Variation (CV)** è¡¡é‡è´Ÿè½½å‡è¡¡ç¨‹åº¦ï¼š
  - Round-Robin: CV æœ€é«˜ï¼ˆæœ€ä¸å‡è¡¡ï¼‰
  - Inter-stage only bid-ask: æœ‰æ‰€æ”¹å–„
  - Full bid-askï¼ˆè·¨é˜¶æ®µ+ç»„å†…ï¼‰: **CV é™ä½ 47%**ï¼ˆvs RRï¼‰

#### ğŸ” **ç®—æ³•æ•ˆç‡ä¼˜åŒ–æ•ˆæœ**
- åŸå§‹ DP å¤æ‚åº¦ï¼šO(EÂ³LÂ²)ï¼Œ16 å®ä¾‹ + 128K é•¿åº¦ â†’ é¢„è®¡è€—æ—¶ **51 å°æ—¶**
- L4 ä¼˜åŒ–åï¼ˆæŒ‡æ•°åˆ†æ¡¶ + ä¸¤é˜¶æ®µå¯å‘å¼ï¼‰â†’ **ä»…éœ€ 0.06 ç§’**ï¼ŒåŠ é€Ÿçº¦ **3Ã—10â¶ å€**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **Attention kernel å¯¹é•¿åº¦å¼‚è´¨æ€§æåº¦æ•æ„Ÿ** æ˜¯å½“å‰ LLM æœåŠ¡çš„ä¸»è¦ç“¶é¢ˆï¼Œå³ä½¿ä½¿ç”¨ FlashAttention ä¹Ÿæ— æ³•å®Œå…¨ç¼“è§£ã€‚
2. **å•å®ä¾‹è°ƒåº¦å—åˆ¶äº Littleâ€™s Law**ï¼Œæ— æ³•ç§¯ç´¯è¶³å¤Ÿè¯·æ±‚æ¥æ¶ˆé™¤å¼‚è´¨æ€§ã€‚
3. **å¤šå®ä¾‹ç³»ç»Ÿçš„è§„æ¨¡æœ¬èº«å¯ä»¥æˆä¸ºè§£å†³æ–¹æ¡ˆ**ï¼šé€šè¿‡å…¨å±€è°ƒåº¦æ„å»ºé•¿åº¦æ„ŸçŸ¥æµæ°´çº¿ï¼Œå¯åœ¨ä¸ä¿®æ”¹åº•å±‚å¼•æ“çš„å‰æä¸‹å¤§å¹…æå‡æ€§èƒ½ã€‚
4. **L4 å®ç°äº†â€œæœ¬åœ°å…¼å®¹ã€å…¨å±€ä¼˜åŒ–â€**ï¼šä¿ç•™åŸæœ‰è°ƒåº¦å™¨ä¸å˜ï¼Œä»…é€šè¿‡è·¨å®ä¾‹è°ƒåº¦å³å¯é‡Šæ”¾ç¡¬ä»¶æ½œåŠ›ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™ | è¯´æ˜ |
|------|------|
| **ä¾èµ–å……è¶³æ˜¾å­˜æ”¯æŒå¤§ batch** | è‹¥æ¨¡å‹å‚æ•°å æ»¡æ˜¾å­˜ï¼ˆå¦‚ >80%ï¼‰ï¼Œå‰©ä½™ç©ºé—´ä¸è¶³ä»¥å®¹çº³å¤§ batchï¼Œåˆ™æ”¶ç›Šå—é™ |
| **å¯¹é•¿åº¦å‡åŒ€çš„å·¥ä½œè´Ÿè½½å¢ç›Šè¾ƒå°** | è‹¥æ‰€æœ‰è¯·æ±‚é•¿åº¦ç›¸è¿‘ï¼ŒL4 ä¸ä¼šå¼•å…¥é¢å¤–å¼€é”€ï¼Œä½†ä»æ— æ³•è¿›ä¸€æ­¥ä¼˜åŒ– |
| **æš‚æœªæ”¯æŒå¼‚æ„å®ä¾‹é…ç½®** | å½“å‰è¯„ä¼°åŸºäºåŒæ„ GPU è®¾ç½®ï¼›å¼‚æ„ç¯å¢ƒä¸‹çš„æœ€ä¼˜ stage åˆ’åˆ†ä»æ˜¯å¼€æ”¾é—®é¢˜ |
| **KV è¿ç§»å¸¦æ¥é€šä¿¡å¼€é”€** | è™½ç„¶è®¾è®¡ä¸Šå·²æœ€å°åŒ–å½±å“ï¼Œä½†åœ¨æç«¯å¸¦å®½å—é™åœºæ™¯å¯èƒ½æˆä¸ºç“¶é¢ˆ |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ”¯æŒå¼‚æ„é›†ç¾¤è°ƒåº¦**ï¼šç»“åˆ tensor/pipeline parallelism å‚æ•°è‡ªåŠ¨æœç´¢æœ€ä¼˜ stage é…ç½®ã€‚
2. **æ›´ç»†ç²’åº¦çš„é•¿åº¦æ„ŸçŸ¥è°ƒåº¦**ï¼šä¾‹å¦‚ç»“åˆè¾“å‡ºé•¿åº¦é¢„æµ‹ï¼Œæå‰è§„åˆ’è¿ç§»è·¯å¾„ã€‚
3. **ä¸ disaggregated serving æ¶æ„é›†æˆ**ï¼šå¦‚ DistServeã€MegaScale-Inferï¼Œå®ç° prefill/decode åˆ†ç¦» + é•¿åº¦åˆ†åŒºåŒé‡ä¼˜åŒ–ã€‚
4. **æ¢ç´¢å¼ºåŒ–å­¦ä¹ ç”¨äºåŠ¨æ€è¾¹ç•Œè°ƒæ•´**ï¼šæ›¿ä»£å½“å‰å¯å‘å¼æ–¹æ³•ï¼Œå®ç°æ›´æ™ºèƒ½çš„ runtime æ§åˆ¶ã€‚

---

## æ€»ç»“

L4 æå‡ºäº†ä¸€ç§å…¨æ–°çš„è§†è§’ï¼š**å°† LLM æ¨ç†ä¸­çš„é•¿åº¦å¼‚è´¨æ€§é—®é¢˜ä»â€œæœ¬åœ°è°ƒåº¦æŒ‘æˆ˜â€è½¬å˜ä¸ºâ€œå…¨å±€èµ„æºç¼–æ’æœºä¼šâ€**ã€‚é€šè¿‡æ„å»ºé•¿åº¦æ„ŸçŸ¥çš„å¤šé˜¶æ®µæµæ°´çº¿ï¼Œé…åˆåŠ¨æ€è§„åˆ’ã€è‡ªé€‚åº”è¾¹ç•Œè°ƒæ•´å’Œå»ä¸­å¿ƒåŒ– bid-ask åè®®ï¼ŒL4 åœ¨ä¸æ”¹åŠ¨åº•å±‚ attention kernel çš„å‰æä¸‹ï¼Œå®ç°äº†ï¼š

- **ç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½æœ€å¤š 67%**
- **å°¾å»¶è¿Ÿé™ä½æœ€å¤š 69%**
- **ç³»ç»Ÿååæå‡æœ€é«˜è¾¾ 2.89Ã—**

è¯¥å·¥ä½œæ­ç¤ºäº†å½“å‰ LLM serving æ¶æ„çš„æ ¹æœ¬çŸ›ç›¾ï¼Œå¹¶æä¾›äº†å¯æ‰©å±•ã€æ­£äº¤ä¸”é«˜æ€§èƒ½çš„è§£å†³æ–¹æ¡ˆï¼Œä¸ºä¸‹ä¸€ä»£é«˜æ•ˆ LLM æœåŠ¡å¹³å°çš„è®¾è®¡æŒ‡æ˜äº†æ–¹å‘ã€‚

</details>

---

### 8. [Rethinking Multi-Agent Intelligence Through the Lens of Small-World Networks](https://arxiv.org/abs/2512.18094)

**Authors**: Boxuan Wang, Zhuoyun Li, Xiaowei Huang, Yi Dong  
**Category**: cs.AI  
**Published**: 2025-12-23  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.18094v1  

#### Abstract
Large language models (LLMs) have enabled multi-agent systems (MAS) in which multiple agents argue, critique, and coordinate to solve complex tasks, making communication topology a first-class design choice. Yet most existing LLM-based MAS either adopt fully connected graphs, simple sparse rings, or...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRethinking Multi-Agent Intelligence Through the Lens of Small-World Networks

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº **Large Language Models (LLMs)** çš„ **Multi-Agent Systems (MAS)** åœ¨é€šä¿¡æ‹“æ‰‘è®¾è®¡ä¸Šç¼ºä¹ç»“æ„æ€§æŒ‡å¯¼ã€‚å¤§å¤šæ•°ç³»ç»Ÿé‡‡ç”¨å…¨è¿æ¥ï¼ˆfully-connectedï¼‰ã€ç¯çŠ¶ç¨€ç–è¿æ¥ï¼ˆring/sparseï¼‰æˆ–åŠ¨æ€é€‰æ‹©æœºåˆ¶ï¼Œè¿™äº›ç»“æ„è¦ä¹ˆé€šä¿¡æˆæœ¬é«˜ï¼Œè¦ä¹ˆç¨³å®šæ€§å·®ï¼Œä¸”æœªå€Ÿé‰´å¤æ‚ç½‘ç»œä¸­çš„ç»å…¸ç†è®ºã€‚

æœ¬æ–‡æå‡ºï¼š**æ˜¯å¦å¯ä»¥å°†å°ä¸–ç•Œï¼ˆSmall-World, SWï¼‰ç½‘ç»œç»“æ„ä½œä¸ºMASçš„è®¾è®¡å…ˆéªŒï¼Ÿ**

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
1. **å¼•å…¥ Small-World ç½‘ç»œä½œä¸ºé€šä¿¡æ‹“æ‰‘å…ˆéªŒ**  
   å—ç¥ç»ç§‘å­¦å’Œå¤æ‚ç½‘ç»œå¯å‘ï¼Œä½œè€…å°† SW ç»“æ„ï¼ˆé«˜å±€éƒ¨èšç±» + çŸ­å¹³å‡è·¯å¾„é•¿åº¦ï¼‰åº”ç”¨äºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„é€šä¿¡æ¶æ„ä¸­ï¼Œä»¥æå‡æ¨ç†çš„ç¨³å®šæ€§å’Œæ•ˆç‡ã€‚

2. **ä¸ç¡®å®šæ€§å¼•å¯¼çš„é‡è¿æœºåˆ¶ï¼ˆUncertainty-Guided Rewiringï¼‰**  
   æå‡ºä¸€ç§å¯æ‰©å±•çš„åŠ¨æ€æ„å»º SW æ‹“æ‰‘çš„æ–¹æ³•ï¼šåˆ©ç”¨ LLM çš„è¯­ä¹‰ä¸ç¡®å®šæ€§ä¿¡å·ï¼ˆå¦‚ semantic entropyï¼‰ï¼Œåœ¨â€œè®¤çŸ¥å·®å¼‚å¤§â€çš„æ™ºèƒ½ä½“ä¹‹é—´æ·»åŠ é•¿ç¨‹â€œæ·å¾„â€ï¼ˆshortcutsï¼‰ï¼Œä»è€Œå½¢æˆå¯æ§ã€è‡ªé€‚åº”çš„å°ä¸–ç•Œç»“æ„ã€‚

3. **æ­ç¤º SW æ‹“æ‰‘å¯¹è®¤çŸ¥è§’è‰²æ¶Œç°çš„å½±å“**  
   å‘ç° SW ç»“æ„èƒ½è‡ªç„¶è¯±å¯¼ä¸åŒæ‹“æ‰‘ä½ç½®çš„ agent è¡¨ç°å‡ºä¸åŒçš„è¡Œä¸ºæ¨¡å¼ï¼ˆå¦‚ Expertã€Bridgeã€Lonerï¼‰ï¼Œæ— éœ€æ˜¾å¼è§’è‰²è®¾è®¡å³å¯å®ç°è®¤çŸ¥å¤šæ ·æ€§ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|------|--------|---------|
| **é€šä¿¡æ•ˆç‡** | å…¨è¿æ¥å¼€é”€å¤§ï¼›ç¨€ç–ç¯å»¶è¿Ÿé«˜ | SW å¹³è¡¡å±€éƒ¨äº¤äº’ä¸å…¨å±€ä¼ æ’­ï¼Œtoken æˆæœ¬é€‚ä¸­ |
| **å…±è¯†ç¨³å®šæ€§** | éšæœºæ‹“æ‰‘æ˜“éœ‡è¡ï¼Œæ”¶æ•›ä¸ç¨³å®š | SW æ˜¾è‘—å¹³æ»‘å…±è¯†è½¨è¿¹ï¼Œé™ä½æ–¹å·® |
| **ç»“æ„è®¾è®¡åŸåˆ™** | ç¼ºä¹ç†è®ºä¾æ®æˆ–ä¾èµ–ç»éªŒ | åŸºäº SW ç†è®ºæä¾›ç»“æ„åŒ–å…ˆéªŒ |
| **å¯æ‰©å±•æ€§** | å›ºå®šæ‹“æ‰‘éš¾ä»¥é€‚åº”ä»»åŠ¡å˜åŒ– | ä¸ç¡®å®šæ€§é©±åŠ¨çš„åŠ¨æ€é‡è¿æ”¯æŒè‡ªé€‚åº”è°ƒæ•´ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ **Multi-Agent Debate (MAD)** æ¡†æ¶ä¸‹è¯„ä¼°ï¼Œæ¶µç›–ä¸‰ä¸ªä»£è¡¨æ€§åŸºå‡†ï¼š
- **ARC-Challenge**ï¼šå¤šé¡¹é€‰æ‹©é¢˜é—®ç­”ï¼Œæµ‹è¯•å¸¸è¯†ä¸æ¨ç†èƒ½åŠ›
- **ScienceQA**ï¼šå¤šæ¨¡æ€ç§‘å­¦é—®é¢˜ç†è§£ä¸æ¨ç†
- **GSM8K**ï¼šæ•°å­¦åº”ç”¨é¢˜ï¼Œè¦æ±‚é“¾å¼æ€ç»´ï¼ˆChain-of-Thoughtï¼‰æ¨ç†

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼šä½¿ç”¨ `GPT-4o-mini` ä½œä¸ºåŸºç¡€ LLM
- **Agent æ•°é‡**ï¼š8 ä¸ª agents
- **é€šä¿¡æ‹“æ‰‘å¯¹æ¯”**ï¼š
  - **Fully-connected**ï¼šå…¨è¿æ¥å›¾
  - **Sparse (Ring)**ï¼šæ¯ä¸ª agent ä»…ä¸é‚»å±…é€šä¿¡
  - **Random (Rand)**ï¼šæ¯è½®éšæœºé‡‡æ ·è¾¹ï¼ˆåŠ¨æ€ï¼‰
  - **Small-world (SW)**ï¼šä»ç¯å½¢ç»“æ„å‡ºå‘ï¼Œé€šè¿‡å°‘é‡è¾¹é‡è¿æ„é€  SW æ‹“æ‰‘ï¼ˆé™æ€ï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**
  - **å¹³å‡æ¯é¢˜é€šä¿¡å¼€é”€ï¼ˆToken cost per questionï¼‰**
  - **å…±è¯†åŠ¨æ€æ›²çº¿ï¼ˆConsensus dynamics over debate roundsï¼‰**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Figure 2 & 3ï¼‰

| æ‹“æ‰‘ç±»å‹ | å‡†ç¡®ç‡ï¼ˆå¹³å‡ï¼‰ | Token å¼€é”€ï¼ˆç›¸å¯¹ï¼‰ | å…±è¯†ç¨³å®šæ€§ |
|--------|----------------|--------------------|------------|
| **Random** | æœ€é«˜ (~95.3%) | æœ€ä½ | å·®ï¼ˆæ³¢åŠ¨å¤§ã€å¯èƒ½é€€åŒ–ï¼‰ |
| **Fully-connected** | è¾ƒé«˜ (~92â€“93%) | æœ€é«˜ | ä¸­ç­‰ |
| **Sparse (Ring)** | è¾ƒä½ (~84â€“87%) | ä½ | è¾ƒæ…¢ä½†è¾ƒç¨³ |
| **Small-world (SW)** | **æ¥è¿‘æœ€ä¼˜ (~92â€“94%)** | **é€‚ä¸­** | âœ… **æœ€ä½³ â€” æ”¶æ•›å¹³ç¨³ã€æ–¹å·®æœ€å°** |

> ğŸ’¡ ç‰¹åˆ«åœ°ï¼Œåœ¨ GSM8K ä¸Šï¼ŒSW æ‹“æ‰‘å±•ç°å‡ºæœ€å¹³æ»‘çš„å…±è¯†æ¼”åŒ–è¿‡ç¨‹ï¼ˆFigure 3ï¼‰ï¼Œè€Œ Random æ‹“æ‰‘å‡ºç°æ˜æ˜¾æŒ¯è¡ç”šè‡³åæœŸæ€§èƒ½ä¸‹é™ã€‚

### ğŸ”¬ æ¶ˆèåˆ†æä¸è§‚å¯Ÿ
- **SW æ‹“æ‰‘ç‰ºç‰²æå°ç²¾åº¦æ¢å–æ˜¾è‘—ç¨³å®šæ€§æå‡**ï¼šç›¸æ¯” Fully-connectedï¼Œå‡†ç¡®ç‡å‡ ä¹æŒå¹³ï¼Œä½†å…±è¯†æ›´å¯é ã€‚
- **Random æ‹“æ‰‘è™½é«˜æ•ˆä½†ä¸ç¨³å®š**ï¼šä¸­é—´æ¨ç†ä¿¡å·ä¼ æ’­ä¸è§„å¾‹ï¼Œé”™è¯¯å®¹æ˜“è¢«æ”¾å¤§ã€‚
- **SW çš„â€œç»“æ„åŒ–æ·å¾„â€æœ‰æ•ˆæŠ‘åˆ¶è¯¯å·®ç§¯ç´¯**ï¼šå±€éƒ¨é›†ç¾¤ç»´æŒä¸€è‡´æ€§ï¼Œé•¿ç¨‹è¿æ¥å¿«é€Ÿçº æ­£åå·®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **SW æ‹“æ‰‘æ˜¯å¤šæ™ºèƒ½ä½“åä½œçš„â€œé»„é‡‘ä¸­åº¸â€ç»“æ„**  
   åœ¨å‡†ç¡®æ€§ã€é€šä¿¡æˆæœ¬ä¸ç¨³å®šæ€§ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡ï¼Œå°¤å…¶é€‚åˆéœ€è¦é•¿æœŸæ¨ç†çš„ä»»åŠ¡ã€‚

2. **SW æ˜¯æ¨ç†ç¨³å®šå™¨ï¼ˆReasoning Stabilizerï¼‰**  
   å±€éƒ¨èšç±»å¢å¼ºä¸€è‡´æ€§ï¼Œé•¿ç¨‹æ·å¾„åŠ é€Ÿå…¨å±€æ ¡æ­£ï¼Œæ˜¾è‘—å‡å°‘å…±è¯†è¿‡ç¨‹ä¸­çš„éœ‡è¡ã€‚

3. **SW æå‡é²æ£’æ€§ä¸å¯æ‰©å±•æ€§**  
   - æŠµå¾¡å±€éƒ¨è¯¯å¯¼ä¿¡æ¯ï¼ˆRobustness Enhancementï¼‰
   - æ”¯æŒå¤§è§„æ¨¡ç³»ç»Ÿä¸­çš„é«˜æ•ˆåè°ƒï¼ˆScalable Coordinatorï¼‰
   - è‡ªç„¶å‚¬ç”Ÿå¤šæ ·åŒ–è®¤çŸ¥è§’è‰²ï¼ˆInductive Bias for Cognitive Diversityï¼‰

4. **ä¸ç¡®å®šæ€§å¯ä½œæ‹“æ‰‘è°ƒæ§ä¿¡å·**  
   åˆ©ç”¨ semantic entropy ç­‰ UQ æ–¹æ³•è¯†åˆ«â€œæœ€ä¸ç¡®å®šâ€ä¸â€œæœ€è‡ªä¿¡â€agentï¼Œå¹¶å»ºç«‹ shortcutï¼Œèƒ½ä¸»åŠ¨ä¼˜åŒ–ä¿¡æ¯æµåŠ¨ï¼Œé˜²æ­¢ç“¶é¢ˆï¼ˆæ°´æ¡¶æ•ˆåº”ï¼‰ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å½“å‰å®éªŒåŸºäº **é™æ€ SW æ‹“æ‰‘**ï¼Œå°šæœªå®Œå…¨å®ç°åœ¨çº¿åŠ¨æ€é‡æ„ã€‚
- æ‰€æœ‰ agents ä½¿ç”¨ç›¸åŒ LLMï¼Œæœªè€ƒè™‘å¼‚æ„ agentï¼ˆheterogeneous agentsï¼‰åœºæ™¯ã€‚
- å°šæœªç«¯åˆ°ç«¯å­¦ä¹ æ‹“æ‰‘ï¼Œä»ä¾èµ–äººå·¥æ„é€ æˆ–å¯å‘å¼è§„åˆ™ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼€å‘å®æ—¶æ‹“æ‰‘è‡ªé€‚åº”ç®—æ³•**ï¼šç»“åˆ uncertainty signals å®ç°åŠ¨æ€å¢åˆ è¾¹ã€‚
2. **æ¢ç´¢ä¸åŒ UQ æŒ‡æ ‡çš„å½±å“**ï¼šæ¯”è¾ƒ epistemic vs. aleatoric uncertainty å¯¹ shortcut å½¢æˆçš„ä½œç”¨ã€‚
3. **ç ”ç©¶ SW æ‹“æ‰‘ä¸ä»»åŠ¡éš¾åº¦çš„åŒ¹é…æœºåˆ¶**ï¼šè‡ªåŠ¨è°ƒèŠ‚ shortcut å¯†åº¦ã€‚
4. **ç«¯åˆ°ç«¯å­¦ä¹  SW ç»“æ„**ï¼šè®© agents åœ¨è®­ç»ƒä¸­è‡ªä¸»æ¼”åŒ–å‡ºæœ€ä¼˜é€šä¿¡å›¾ã€‚
5. **æ¨å¹¿è‡³æ›´å¤æ‚ MAS åœºæ™¯**ï¼šå¦‚åˆ†å¸ƒå¼è§„åˆ’ã€é›†ä½“æ¢ç´¢ã€åˆ†å±‚ç»„ç»‡ç­‰ã€‚

---

## æ€»ç»“

> è¯¥è®ºæ–‡é¦–æ¬¡ç³»ç»Ÿæ€§åœ°å°† **Small-World Network** ç†è®ºå¼•å…¥ LLM-based MAS è®¾è®¡ï¼Œæå‡º **SW æ‹“æ‰‘æ˜¯ä¸€ç§å¼ºæœ‰åŠ›çš„ç»“æ„å…ˆéªŒ**ï¼Œä¸ä»…èƒ½ä¿æŒé«˜æ€§èƒ½ï¼Œè¿˜èƒ½å¤§å¹…æå‡æ¨ç†è¿‡ç¨‹çš„**ç¨³å®šæ€§ä¸é²æ£’æ€§**ã€‚é€šè¿‡å¼•å…¥ **uncertainty-guided rewiring**ï¼Œè¿›ä¸€æ­¥å®ç°äº†å¯æ§ã€å¯æ‰©å±•çš„æ™ºèƒ½ä½“é€šä¿¡æ¶æ„ï¼Œä¸ºä¸‹ä¸€ä»£å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæä¾›äº†æ–°çš„è®¾è®¡èŒƒå¼ã€‚

</details>

---

### 9. [GeoSense-AI: Fast Location Inference from Crisis Microblogs](https://arxiv.org/abs/2512.18225)

**Authors**: Deepit Sapru  
**Category**: cs.CL  
**Published**: 2025-12-23  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.18225v1  

#### Abstract
This paper presents an applied AI pipeline for realtime geolocation from noisy microblog streams, unifying statistical hashtag segmentation, part-of-speech-driven proper-noun detection, dependency parsing around disaster lexicons, lightweight named-entity recognition, and gazetteer-grounded disambig...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šGeoSense-AI: Fast Location Inference from Crisis Microblogs

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **åœ°ç†å…ƒæ•°æ®ç¨€ç–**ï¼šç¤¾äº¤åª’ä½“ï¼ˆå¦‚ Twitterï¼‰åœ¨å±æœºäº‹ä»¶ä¸­æ˜¯é‡è¦çš„å®æ—¶ä¿¡æ¯æºï¼Œä½†ä»…æœ‰æå°‘æ•°æ¨æ–‡ï¼ˆå¦‚å°åº¦åœ°åŒºä»… 0.36%ï¼‰å¸¦æœ‰ç²¾ç¡®çš„ geo-tagï¼ˆåœ°ç†ä½ç½®æ ‡ç­¾ï¼‰ï¼Œä¸¥é‡é™åˆ¶äº†ç©ºé—´åˆ†æèƒ½åŠ›ã€‚
- **éæ­£å¼æ–‡æœ¬å¤„ç†å›°éš¾**ï¼šå¾®åšå®¢æ–‡æœ¬å…·æœ‰è¯­æ³•ä¸è§„èŒƒã€æ‹¼å†™å˜ä½“å¤šã€ç¼©ç•¥è¯­é¢‘ç¹ã€å¤šè¯­è¨€æ··æ‚ç­‰ç‰¹ç‚¹ï¼Œé€šç”¨ NER å·¥å…·éš¾ä»¥æœ‰æ•ˆè¯†åˆ«å…¶ä¸­çš„ location mentionsï¼ˆåœ°åæåŠï¼‰ã€‚
- **å®æ—¶æ€§è¦æ±‚é«˜**ï¼šåº”æ€¥å“åº”åœºæ™¯å¯¹ç³»ç»Ÿå»¶è¿Ÿæä¸ºæ•æ„Ÿï¼Œä¼ ç»Ÿé«˜ç²¾åº¦ NLP æ¨¡å‹å¾€å¾€è®¡ç®—å¼€é”€å¤§ï¼Œæ— æ³•æ»¡è¶³æµå¼å¤„ç†éœ€æ±‚ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
- **æå‡º GeoSense-AI**ï¼šä¸€ä¸ªä¸“ä¸ºå±æœºå¾®åšå®¢è®¾è®¡çš„è½»é‡çº§ã€ä½å»¶è¿Ÿ location inference ç³»ç»Ÿï¼Œç›´æ¥ä»æ–‡æœ¬ä¸­æå–åœ°ç†ä½ç½®ï¼Œè€Œéä¾èµ–ç¨€ç–çš„ geo-tagsã€‚
- **èåˆå¤šé˜¶æ®µ NLP æŠ€æœ¯çš„ç»Ÿä¸€ pipeline**ï¼š
  - **Hashtag Segmentation**ï¼šä½¿ç”¨ç»Ÿè®¡æ–¹æ³•æ‹†åˆ†å¤åˆ hashtagï¼ˆå¦‚ `#ChennaiFloods` â†’ "Chennai" + "Floods"ï¼‰ï¼Œæå‡å¬å›ç‡ã€‚
  - **POS-driven Proper-Noun Detection**ï¼šåŸºäºè¯æ€§æ ‡æ³¨è¯†åˆ«å¯èƒ½çš„åœ°åå®ä½“ã€‚
  - **Dependency Parsing around Disaster Lexicons**ï¼šåˆ©ç”¨ä¾å­˜å¥æ³•åˆ†ææ•æ‰ä¸ç¾å®³å…³é”®è¯ï¼ˆå¦‚ "flood", "earthquake"ï¼‰è¯­ä¹‰ç›¸å…³çš„åœ°ç‚¹ã€‚
  - **Lightweight NER**ï¼šé›†æˆ spaCy é¢„è®­ç»ƒ NER æ¨¡å‹ä½œä¸ºâ€œå…œåº•â€æœºåˆ¶ï¼Œå…¼é¡¾é€Ÿåº¦ä¸è¦†ç›–ã€‚
  - **Gazetteer-Grounded Disambiguation**ï¼šé€šè¿‡ GeoNames æˆ– OpenStreetMap è¿›è¡Œåœ°åéªŒè¯ä¸åæ ‡è§£æï¼Œè¿‡æ»¤å‡é˜³æ€§å¹¶è§£å†³æ­§ä¹‰ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | GeoSense-AI | ä¼ ç»Ÿ NER å·¥å…·ï¼ˆå¦‚ StanfordNERï¼‰ |
|------|-------------|-------------------------------|
| **å‡†ç¡®æ€§** | F1 è¾¾åˆ° 0.8141ï¼Œä¼˜äºå¤šæ•°åŸºçº¿ | å‡†ç¡®æ€§å°šå¯ï¼Œä½†åœ¨éæ­£å¼æ–‡æœ¬ä¸Šè¡¨ç°ä¸‹é™ |
| **é€Ÿåº¦** | å¤„ç†æ¯æ¡ tweet å¹³å‡è€—æ—¶çº¦ 1.19 ç§’ï¼ˆå…¨é›†ï¼‰| StanfordNER è€—æ—¶é«˜è¾¾ 175 ç§’ï¼Œæ…¢ä¸¤ä¸ªæ•°é‡çº§ |
| **é€‚ç”¨åœºæ™¯** | ä¸“ä¸º streaming crisis data è®¾è®¡ï¼Œæ”¯æŒå®æ—¶éƒ¨ç½² | å¤šæ•°ä¸ºæ‰¹å¤„ç†è®¾è®¡ï¼Œä¸é€‚åˆé«˜ååæµå¼è¾“å…¥ |
| **é²æ£’æ€§** | å¯¹ hashtagã€éæ ‡å‡†è¯­æ³•ã€æ‹¼å†™å˜å¼‚æ›´å…·å®¹å¿åº¦ | åœ¨ informal text ä¸Šå¬å›ç‡æ˜¾è‘—é™ä½ |

> âš¡ æ ¸å¿ƒä¼˜åŠ¿ï¼š**åœ¨ä¿æŒé«˜ F1 åˆ†æ•°çš„åŒæ—¶ï¼Œå®ç°æ¯”ä¸»æµå·¥å…·å¿« ~150 å€çš„å¤„ç†é€Ÿåº¦**ï¼ŒçœŸæ­£é€‚ç”¨äº real-time crisis informaticsã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
- **åŸå§‹æ•°æ®**ï¼šé€šè¿‡ Twitter Streaming API æ”¶é›† 2017 å¹´ 9 æœˆ 12 æ—¥è‡³ 10 æœˆ 13 æ—¥æœŸé—´åŒ…å«å…³é”®è¯ `"dengue"` æˆ– `"flood"` çš„æ¨æ–‡ï¼Œå…± 317,567 æ¡ã€‚
- **æ¸…æ´—åæ•°æ®**ï¼šå»é™¤é‡å¤é¡¹å’Œéè‹±æ–‡æ¨æ–‡ï¼Œä¿ç•™ 239,276 æ¡ç”¨äºåˆ†æã€‚
- **äººå·¥æ ‡æ³¨å­é›†**ï¼šéšæœºæŠ½å– 1,000 æ¡æ¨æ–‡ï¼Œç”±äººå·¥æ ‡æ³¨æ˜¯å¦åŒ…å«æ˜ç¡®çš„å°åº¦å¢ƒå†… location mentionï¼ˆéœ€è¾¾åˆ° city çº§åˆ«æˆ–æ›´ç»†ç²’åº¦ï¼‰ã€‚
- **æœ€ç»ˆè¯„ä¼°é›†**ï¼šä»ä¸­ç­›é€‰å‡º **99 æ¡å«æœ‰å¯éªŒè¯åœ°åçš„æ¨æ–‡**ï¼Œæ„æˆé»„é‡‘æ ‡å‡†æµ‹è¯•é›†ã€‚

### ğŸ§ª å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **ä»»åŠ¡å®šä¹‰**ï¼šä»æ¨æ–‡ä¸­æå– location mentionï¼Œå¹¶æ˜ å°„åˆ°å®é™…åœ°ç†åæ ‡ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Precision**ï¼ˆç²¾ç¡®ç‡ï¼‰
  - **Recall**ï¼ˆå¬å›ç‡ï¼‰
  - **F1 Score**ï¼ˆF1 å€¼ï¼‰
  - **Processing Time per Tweet**ï¼ˆå•æ¡æ¨æ–‡å¤„ç†æ—¶é—´ï¼‰â€”â€”å¼ºè°ƒå®æ—¶æ€§
- **Gazetteer ç»Ÿä¸€**ï¼šæ‰€æœ‰æ–¹æ³•å‡ä½¿ç”¨ GeoNames è¿›è¡Œåœ°åéªŒè¯ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ |
|------|------|
| UniLoc | å•è¯ + gazetteer åŒ¹é… |
| BiLoc | åŒè¯ç»„ + gazetteer åŒ¹é… |
| StanfordNER | é€šç”¨ CRF-based NER |
| TwitterNLP | Twitter ç‰¹åŒ– NERï¼ˆRitter et al.ï¼‰ |
| SpaCyNER | è½»é‡çº§é¢„è®­ç»ƒ NER |
| GoogleCloud | å•†ä¸š APIï¼ˆGoogle Cloud NLPï¼‰ |
| GeoLoc / OSMLoc | GeoSense-AI ä¸¤ç§å˜ä½“ï¼ˆåˆ†åˆ«ä½¿ç”¨ GeoNames å’Œ OpenStreetMapï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table IIï¼‰

| Method | Precision | Recall | **F1** | Time (s) |
|--------|-----------|--------|--------|----------|
| UniLoc | 0.3848 | 0.7852 | 0.5165 | 0.0553 |
| BiLoc | 0.4025 | 0.8590 | 0.5482 | 0.0624 |
| StanfordNER | 0.8103 | 0.6322 | 0.6988 | **175.0124** |
| TwitterNLP | 0.6356 | 0.5474 | 0.5882 | 28.0001 |
| SpaCyNER | **0.9883** | 0.5555 | 0.7113 | 1.0891 |
| GoogleCloud | 0.6321 | 0.5339 | 0.5789 | N/A |
| **GeoLoc** | 0.7987 | **0.8300** | **0.8141** | **1.1901** |
| OSMLoc | 0.3383 | 0.8888 | 0.4901 | 711.5817 |

> âœ… **GeoLoc åœ¨ F1 ä¸Šæ˜¾è‘—é¢†å…ˆäºæ‰€æœ‰åŸºçº¿**ï¼ˆæœ€é«˜è¾¾ 0.8141ï¼‰ï¼Œä¸”å¤„ç†é€Ÿåº¦è¿œè¶… StanfordNERï¼ˆå¿«çº¦ 150Ã—ï¼‰ã€‚

### ğŸ” ä¸å…¶ä»–æ–¹æ³•å¯¹æ¯”çš„å…³é”®å‘ç°
- **vs. n-gram æ–¹æ³•ï¼ˆUniLoc/BiLocï¼‰**ï¼š
  - è™½ç„¶ BiLoc å¬å›ç‡è¾ƒé«˜ï¼Œä½† precision å¾ˆä½ï¼›GeoLoc åŒæ—¶å®ç°äº†é«˜ recall å’Œé«˜ precisionã€‚
- **vs. SpaCyNER**ï¼š
  - SpaCyNER ç²¾ç¡®ç‡æé«˜ï¼ˆ0.9883ï¼‰ï¼Œä½† recall æä½ï¼ˆ0.5555ï¼‰ï¼Œæ¼æ£€å¤§é‡çœŸå® locationã€‚
  - GeoSense-AI é€šè¿‡ hashtag segmentation å’Œ dependency parsing æ˜¾è‘—æå‡äº† recallã€‚
- **vs. StanfordNER**ï¼š
  - å°½ç®¡ F1 ç•¥ä½ï¼ˆ0.6988 vs 0.8141ï¼‰ï¼Œä½† GeoSense-AI å¿«äº†è¿‘ä¸¤ä¸ªæ•°é‡çº§ï¼Œæ›´é€‚åˆ streaming åœºæ™¯ã€‚
- **OSMLoc çš„ä»£ä»·**ï¼š
  - ä½¿ç”¨ OpenStreetMap æå‡äº† recallï¼ˆ0.8888ï¼‰ï¼Œä½†ç”±äºæ•°æ®è¿‡äºç²¾ç»†å¯¼è‡´ precision ä¸‹é™ä¸¥é‡ï¼ˆ0.3383ï¼‰ï¼Œä¸”å¤„ç†æ—¶é—´é•¿è¾¾ 711 ç§’ï¼Œä¸é€‚åˆå®æ—¶åº”ç”¨ã€‚

### ğŸ”¤ æ¶ˆèå®éªŒç»“æœï¼ˆGeoLocNoNERï¼‰
- **æ–¹æ³•**ï¼šå…³é—­ lightweight NER æ¨¡å—çš„ GeoSense-AI ç‰ˆæœ¬ã€‚
- **ç»“æœ**ï¼š
  - F1 ä» 0.8141 é™è‡³ 0.7987
  - Precision ä¸å˜ï¼ˆ0.7987ï¼‰ï¼ŒRecall ä¸‹é™ï¼ˆ0.7987ï¼‰
- **ç»“è®º**ï¼šlightweight NER è™½éæ ¸å¿ƒç»„ä»¶ï¼Œä½†ä»è´¡çŒ®äº†ä¸€å®š recall æå‡ï¼Œä½“ç°äº†å…¶â€œå®‰å…¨ç½‘â€ä½œç”¨ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ä¸“ç”¨ç³»ç»Ÿä¼˜äºé€šç”¨å·¥å…·**ï¼šé’ˆå¯¹ crisis microblogs è®¾è®¡çš„ GeoSense-AI åœ¨ accuracy å’Œ speed ä¸Šå‡è¶…è¶Šé€šç”¨æˆ– Twitter-specific NER å·¥å…·ã€‚
2. **å¤šç­–ç•¥èåˆæå‡æ•ˆæœ**ï¼šç»“åˆ hashtag segmentationã€syntactic pattern matchingã€dependency parsing å’Œ gazetteer validation çš„ pipeline èƒ½æœ‰æ•ˆåº”å¯¹éæ­£å¼è¯­è¨€æŒ‘æˆ˜ã€‚
3. **é€Ÿåº¦ä¸ç²¾åº¦å¯å…¼å¾—**ï¼šé€šè¿‡é€‰æ‹©è½»é‡çº§ç»„ä»¶ï¼ˆå¦‚ spaCyï¼‰ã€æ¨¡å—åŒ–è®¾è®¡å’Œé«˜æ•ˆ gazetteer æŸ¥è¯¢ï¼Œå¯åœ¨ä¸ç‰ºç‰²å¤ªå¤šç²¾åº¦çš„å‰æä¸‹å¤§å¹…æå‡å¤„ç†é€Ÿåº¦ã€‚
4. **ç”Ÿäº§å¯ç”¨æ€§å¼º**ï¼šç³»ç»Ÿå·²éƒ¨ç½²ä¸ºåœ¨çº¿æœåŠ¡ï¼ˆ[http://savitr.herokuapp.com](http://savitr.herokuapp.com)ï¼‰ï¼Œå…·å¤‡å®Œæ•´çš„ ingest â†’ inference â†’ visualization æµç¨‹ï¼Œå¯ç”¨äº floodsã€outbreaks ç­‰äº‹ä»¶çš„ situational awarenessã€‚

### âš ï¸ å±€é™æ€§
- **è¯­è¨€é™åˆ¶**ï¼šç›®å‰ä»…æ”¯æŒè‹±æ–‡æ¨æ–‡ï¼Œæœªå¤„ç† code-mixedï¼ˆå¦‚å°åœ°è¯­+è‹±è¯­ï¼‰æˆ–å¤šè¯­è¨€å†…å®¹ã€‚
- **åœ°åè¦†ç›–ä¸è¶³**ï¼šéƒ¨åˆ†åœ°æ–¹æ€§åç§°æˆ–éæ­£å¼ç§°å‘¼ä¸åœ¨ gazetteer ä¸­ï¼Œå¯¼è‡´ false negativeã€‚
- **æ‹¼å†™å˜å¼‚å®¹å¿æœ‰é™**ï¼šè¿‡åº¦åˆ›æ„æ‹¼å†™å¯èƒ½è¶…å‡º fuzzy matching èƒ½åŠ›ã€‚
- **æ­§ä¹‰é—®é¢˜**ï¼šå…¨çƒå­˜åœ¨å¤§é‡åŒååœ°ç‚¹ï¼ˆå¦‚ "Springfield"ï¼‰ï¼Œå½“å‰ç¼ºä¹ä¸Šä¸‹æ–‡ disambiguation æœºåˆ¶ï¼ˆå¦‚ç”¨æˆ· profileã€ç¤¾äº¤ç½‘ç»œç­‰ï¼‰ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- **Multilingual & Code-Mixed Support**ï¼š
  - å¼•å…¥ language identification å’Œ transliteration æŠ€æœ¯å¤„ç†æ··åˆè¯­è¨€æ–‡æœ¬ã€‚
- **Global Scale Deployment**ï¼š
  - æ„å»º hierarchical gazetteer æˆ–ä½¿ç”¨ LSHï¼ˆLocality-Sensitive Hashingï¼‰åŠ é€Ÿå¤§è§„æ¨¡åœ°ååŒ¹é…ã€‚
  - ç»“åˆ user profile locationã€event prior ç­‰è¾…åŠ©ä¿¡æ¯è¿›è¡Œ disambiguationã€‚
- **åŠŸèƒ½æ‰©å±•**ï¼š
  - **Event Detection**ï¼šåŸºäº location + keyword é¢‘ç‡å¼‚å¸¸æ£€æµ‹æ–°å…´å±æœºã€‚
  - **Information Classification**ï¼šå°†æ¨æ–‡åˆ†ç±»ä¸º damage reportã€resource need ç­‰ç±»å‹ã€‚
  - **Summarization & Duplicate Detection**ï¼šç¼“è§£ä¿¡æ¯è¿‡è½½ã€‚
  - **Credibility Assessment**ï¼šè¯†åˆ«å¯ä¿¡ä¿¡æºï¼Œå¯¹æŠ— misinformationã€‚

---

## æ€»ç»“
GeoSense-AI æˆåŠŸå±•ç¤ºäº†å¦‚ä½•é€šè¿‡ **domain-tuned NLP pipeline + knowledge grounding** å…‹æœç¤¾äº¤åª’ä½“ä¸­ geo-tag ç¨€ç¼ºé—®é¢˜ï¼Œåœ¨ä¿è¯é«˜å‡†ç¡®ç‡çš„åŒæ—¶å®ç°æä½å»¶è¿Ÿï¼Œä¸º real-time crisis response æä¾›äº†å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚å…¶æ ¸å¿ƒæ€æƒ³â€”â€”**ä»¥å·¥ç¨‹æ•ˆç‡é©±åŠ¨ AI åº”ç”¨è½åœ°**â€”â€”å¯¹å…¶ä»–ç´§æ€¥å“åº”ç³»ç»Ÿå…·æœ‰é‡è¦å€Ÿé‰´æ„ä¹‰ã€‚

</details>

---

### 10. [Faster Distributed Inference-Only Recommender Systems via Bounded Lag Synchronous Collectives](https://arxiv.org/abs/2512.19342)

**Authors**: Kiril Dichev, Filip Pawlowski, Albert-Jan Yzelman  
**Category**: cs.DC  
**Published**: 2025-12-23  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.19342v1  

#### Abstract
Recommender systems are enablers of personalized content delivery, and therefore revenue, for many large companies. In the last decade, deep learning recommender models (DLRMs) are the de-facto standard in this field. The main bottleneck in DLRM inference is the lookup of sparse features across huge...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFaster Distributed Inference-Only Recommender Systems via Bounded Lag Synchronous Collectives

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨åˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ æ¨èæ¨¡å‹ï¼ˆDLRMï¼‰æ¨ç†è¿‡ç¨‹ä¸­ï¼Œ**`alltoallv` é›†åˆé€šä¿¡æ“ä½œ**æ˜¯ä¸»è¦ç“¶é¢ˆã€‚è¯¥æ“ä½œç”¨äºè·¨å¤šä¸ªèŠ‚ç‚¹åˆ†ç‰‡çš„ embedding è¡¨è¿›è¡Œç¨€ç–ç‰¹å¾æŸ¥æ‰¾ï¼Œå…·æœ‰é«˜åº¦ä¸è§„åˆ™æ€§å’Œé€šä¿¡å¯†é›†æ€§ã€‚ä¼ ç»Ÿå®ç°é‡‡ç”¨**å…¨åŒæ­¥ï¼ˆsynchronousï¼‰é›†ä½“é€šä¿¡æœºåˆ¶**ï¼Œå¯¼è‡´æ‰€æœ‰è¿›ç¨‹å¿…é¡»ä¸¥æ ¼åŒæ­¥ï¼Œä»»ä½•å•ä¸ªâ€œstragglerâ€ï¼ˆå»¶è¿Ÿè¿›ç¨‹ï¼‰éƒ½ä¼šæ‹–æ…¢æ•´ä¸ªç³»ç»Ÿã€‚

è¿™ç§å¼ºåŒæ­¥æ€§åœ¨å­˜åœ¨è®¡ç®—ã€å†…å­˜æˆ–ç½‘ç»œè´Ÿè½½ä¸å¹³è¡¡æ—¶ä¸¥é‡é™åˆ¶äº†ç³»ç»Ÿçš„ååé‡å’Œå»¶è¿Ÿè¡¨ç°ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šBounded Lag Synchronous (BLS) Alltoallv

ä½œè€…æå‡ºäº†ä¸€ç§æ–°å‹çš„ **Bounded Lag Synchronous (BLS) alltoallv** é›†ä½“é€šä¿¡åŸè¯­ï¼Œå¹¶åŸºäºæ­¤æ„å»ºäº†ä¸€ä¸ªæ–°çš„ PyTorch Distributed åç«¯å’Œç›¸åº”çš„ BLS-enabled DLRM å®ç°ã€‚

#### æ ¸å¿ƒæ€æƒ³ï¼š
- å…è®¸ä¸åŒè¿›ç¨‹ä¹‹é—´çš„æ‰§è¡Œè¿›åº¦ç›¸å·®æœ€å¤š `k` ä¸ªè¿­ä»£ï¼ˆå³å…è®¸â€œæœ‰ç•Œæ»åâ€ï¼‰ã€‚
- æœ€å¿«çš„è¿›ç¨‹å¯ä»¥ç»§ç»­å‘å‰æ¨è¿›ï¼Œè€Œæ— éœ€ç­‰å¾…æœ€æ…¢çš„è¿›ç¨‹å®Œæˆå½“å‰è¿­ä»£ã€‚
- å½“æ»åè¶…è¿‡ `k` æ—¶æ‰å¼ºåˆ¶é˜»å¡ï¼Œä»è€Œæ‰“ç ´ä¼ ç»Ÿ collective çš„å…¨å±€åŒæ­¥å±éšœã€‚

#### æŠ€æœ¯å®ç°äº®ç‚¹ï¼š
- è®¾è®¡å¹¶å®ç°äº†æ”¯æŒ BLS çš„ **è½»é‡çº§ PyTorch Distributed åç«¯**ï¼ŒåŸºäº RDMA å’Œ one-sided communicationï¼ˆå¦‚ put æ“ä½œï¼‰ï¼Œé¿å…ä¾èµ–ä¼ ç»Ÿçš„ä¸¤æ–¹é€šä¿¡ï¼ˆsend/recvï¼‰å¸¦æ¥çš„é¢å¤–åŒæ­¥å¼€é”€ã€‚
- åˆ©ç”¨ **tag æœºåˆ¶**åŒºåˆ†ä¸åŒè¿­ä»£çš„æ•°æ®ä¼ è¾“ï¼Œç¡®ä¿æ¶ˆæ¯ä¸ä¼šæ··æ·†ã€‚
- å¼•å…¥ **ç¯å½¢ç¼“å†²åŒºï¼ˆcircular bufferingï¼‰** æ¥å­˜å‚¨å¤šè½®è¿­ä»£çš„ä¸­é—´ç»“æœï¼Œä»¥æ”¯æŒå¼‚æ­¥é€šä¿¡ä¸é‡å æ‰§è¡Œã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆMPI/NCCLï¼‰ | æœ¬æ–‡ BLS æ–¹æ³• |
|------|------------------------|---------------|
| åŒæ­¥æ¨¡å¼ | å®Œå…¨åŒæ­¥ï¼ˆbarrier-styleï¼‰ | æœ‰ç•Œå¼‚æ­¥ï¼ˆå…è®¸æœ€å¤š `k` è½®æ»åï¼‰ |
| é€šä¿¡æ–¹å¼ | å¤šæ•°ä¸º two-sidedï¼ˆsend/recvï¼‰ | one-sided RDMAï¼ˆéé˜»å¡ offload åˆ° NICï¼‰ |
| æ‰§è¡Œé‡å èƒ½åŠ› | ä»…é™åŒè¿­ä»£å†… compute ä¸ communication é‡å  | æ”¯æŒè·¨è¿­ä»£çš„ compute-computeã€compute-communicationã€ç”šè‡³ communication-communication é‡å  |
| å¯¹ä¸å‡è¡¡å®¹å¿åº¦ | å·®ï¼ˆstraggler æ•æ„Ÿï¼‰ | æ˜¾è‘—æå‡ï¼Œåœ¨ `k` èŒƒå›´å†…å¯å®Œå…¨æ©ç›–å»¶è¿Ÿ |

> ğŸ’¡ ç‰¹åˆ«é€‚ç”¨äº **inference-only DLRM** åœºæ™¯ï¼Œå› ä¸ºæ¨¡å‹æƒé‡å·²å›ºå®šï¼Œæ— éœ€ä¿è¯å„è¿›ç¨‹å¤„äºåŒä¸€è®­ç»ƒæ­¥ï¼Œå› æ­¤æ”¾æ¾åŒæ­¥çº¦æŸä¸ä¼šå½±å“å‡†ç¡®æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

| æ•°æ®é›† | ç±»å‹ | æè¿° |
|-------|------|------|
| **Mini-Kaggle (Criteo)** | çœŸå®æ•°æ®é›† | å¹¿å‘Šç‚¹å‡»é¢„æµ‹æ•°æ®ï¼ŒåŒ…å« 13 ä¸ª dense å­—æ®µå’Œ 26 ä¸ª sparse å­—æ®µï¼Œå¯¹åº” 26 ä¸ª embedding tables |
| **Ali-CCP (Alibaba Click & Conversion Prediction)** | çœŸå®æ•°æ®é›† | ç”¨æˆ·ç‚¹å‡»ä¸è½¬åŒ–è¡Œä¸ºæ—¥å¿—ï¼Œç»é¢„å¤„ç†è½¬æ¢ä¸ºç±»ä¼¼ Criteo æ ¼å¼ï¼Œå« 23 ä¸ª categorical tables |
| **Synthetic Heterogeneous Size Benchmark** | åˆæˆæ•°æ® | éšæœºç”Ÿæˆ embedding æŸ¥æ‰¾è¯·æ±‚ï¼Œæ¯è½®è®¿é—®å‘é‡æ•°é‡ä» 1 åˆ° 100 ä¸ç­‰ï¼Œæ¨¡æ‹Ÿä¸å‡åŒ€é€šä¿¡è´Ÿè½½ |
| **Random Delay Injection Benchmark** | åˆæˆæ•°æ® | åœ¨æ¯ä¸ªæ¨ç†æ­¥éª¤ä¸­æ³¨å…¥ 0â€“10ms çš„éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹Ÿ CPUã€å†…å­˜æˆ–é€šä¿¡ç“¶é¢ˆ |

> âš ï¸ æ³¨æ„ï¼šä¸¤ä¸ªçœŸå®æ•°æ®é›†çš„ embedding è¡¨è¾ƒå°ï¼ˆæœ€å¤§çº¦ 2M æ¡ç›®ï¼‰ï¼Œä¸”è®¿é—®æ¨¡å¼è¾ƒå‡åŒ€ï¼Œéš¾ä»¥ä½“ç°é€šä¿¡ä¸å‡è¡¡ä¼˜åŠ¿ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

- **ç¡¬ä»¶å¹³å°**ï¼š8 èŠ‚ç‚¹ ARM Kunpeng 920 é›†ç¾¤ï¼Œæ¯èŠ‚ç‚¹ 1 MPI è¿›ç¨‹
- **ç½‘ç»œ**ï¼šMellanox ConnectX-5 + EDR InfiniBandï¼ˆ100 Gbpsï¼‰ï¼Œæ”¯æŒ RDMA
- **è½¯ä»¶æ ˆ**ï¼š
  - PyTorch 2.5.1 + MPI backendï¼ˆOpen MPI å˜ç§ Hyper MPIï¼‰
  - è‡ªç ” BLS backendï¼ˆåŸºäº LPF å’Œ RDMAï¼‰
  - DLRM åŸºå‡†ä»£ç ï¼ˆNaumov et al. [1]ï¼‰åŸºç¡€ä¸Šæ‰©å±•
- **å‚æ•°é…ç½®**ï¼š
  - Batch size: 512
  - Embedding dimension: 64
  - Bound `k`: 0~400ï¼ˆæµ‹è¯•ä¸åŒæ»åå®¹å¿åº¦ï¼‰

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Latency per batch** | å•ä¸ª batch æ¨ç†è€—æ—¶ï¼ˆç§’ï¼‰ï¼Œè¶Šä½è¶Šå¥½ |
| **Throughput (batches/sec)** | å•ä½æ—¶é—´å†…å¤„ç†çš„ batch æ•°é‡ï¼Œè¶Šé«˜è¶Šå¥½ |
| **95% ç½®ä¿¡åŒºé—´ï¼ˆCIï¼‰** | å¤šæ¬¡é‡å¤å®éªŒä¸‹çš„ç¨³å®šæ€§è¯„ä¼° |

> æ‰€æœ‰æŒ‡æ ‡å‡åœ¨å¤šä¸ªè¿›ç¨‹å’Œå¤šæ¬¡è¿è¡Œä¸Šå–å¹³å‡å€¼ã€‚

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | æè¿° |
|------|------|
| **Original DLRM + MPI backend (k=0)** | åŸå§‹å®ç°ï¼Œä½¿ç”¨æ ‡å‡† PyTorch MPI backendï¼Œå®Œå…¨åŒæ­¥ |
| **BLS-enabled DLRM + MPI backend (k>0)** | ä¿®æ”¹åçš„ DLRM æ”¯æŒéé˜»å¡è°ƒç”¨ï¼Œä½†ä»èµ° MPI backend |
| **BLS-enabled DLRM + BLS backend (k>0)** | å®Œæ•´æ–¹æ¡ˆï¼šè‡ªå®šä¹‰åç«¯ + BLS collectives |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### âœ… åˆæˆåŸºå‡†æµ‹è¯•ç»“æœ

#### ï¼ˆ1ï¼‰å¼‚æ„æ¶ˆæ¯å¤§å°ï¼ˆHeterogeneous Message Sizesï¼‰

- **è§‚å¯Ÿ**ï¼šéšç€ `k` å¢å¤§ï¼Œ**åªæœ‰ BLS backend + BLS DLRM æ–¹æ¡ˆè¡¨ç°å‡ºæŒç»­æ”¹è¿›**
- **æ€§èƒ½å¢ç›Š**ï¼š
  - æœ€é«˜é™ä½ **~7% å»¶è¿Ÿ**
  - æå‡ **~6% ååé‡**
- **åŸå› åˆ†æ**ï¼š
  - BLS backend æ”¯æŒçœŸæ­£çš„è·¨è¿­ä»£ communication é‡å ï¼ˆè§ Table Iï¼‰
  - MPI backend å­˜åœ¨é€šä¿¡è¿›åº¦çº¿ç¨‹ç“¶é¢ˆï¼Œæ— æ³•æœ‰æ•ˆåˆ©ç”¨éé˜»å¡æ¥å£

#### ï¼ˆ2ï¼‰éšæœºå»¶è¿Ÿæ³¨å…¥ï¼ˆRandom Delays: 0â€“10msï¼‰

- **æƒŠäººå‘ç°**ï¼š
  - å½“å¼•å…¥éšæœºå»¶è¿Ÿæ—¶ï¼Œ**BLS æ–¹æ³•å‡ ä¹å®Œå…¨æ©ç›–äº†è¿™äº›å»¶è¿Ÿçš„å½±å“ï¼**
  - å¹³å‡å»¶è¿Ÿä» 0.017s ä¸‹é™åˆ° 0.012s â€”â€” æ­£å¥½ç­‰äº **å»¶è¿Ÿå‡å€¼ï¼ˆ5msï¼‰è¢«æˆåŠŸéšè—**
- **æ€§èƒ½è¶‹åŠ¿**ï¼š
  - å¯¹äº `k â‰¥ 50`ï¼Œæ€§èƒ½è¿…é€Ÿæ”¶æ•›åˆ°æœ€ä¼˜æ°´å¹³
  - **æ— è®ºæ˜¯ MPI è¿˜æ˜¯ BLS backendï¼Œåªè¦ DLRM æ”¯æŒ BLS é€»è¾‘ï¼Œéƒ½èƒ½å—ç›Š**

> ğŸ“Œ ç»“è®ºï¼šå³ä½¿åº•å±‚é€šä¿¡ä»ç”¨ MPIï¼Œåªè¦åº”ç”¨å±‚å…è®¸æ»åï¼Œå°±èƒ½æ˜¾è‘—ç¼“è§£ä¸å‡è¡¡é—®é¢˜ã€‚

---

### âŒ çœŸå®æ•°æ®é›†ç»“æœï¼ˆMini-Kaggle & Ali-CCPï¼‰

- **å…³é”®ç°è±¡**ï¼šå¢åŠ  `k` **æœªå¸¦æ¥æ˜æ˜¾æ€§èƒ½æå‡**
- **å¯èƒ½åŸå› **ï¼š
  - æ•°æ®è®¿é—®é«˜åº¦å‡åŒ€ï¼ˆNVTabular é¢„å¤„ç†ä¼šèšåˆå¤šå‘é‡ä¸ºå•å‘é‡ï¼‰
  - è®¡ç®—ã€é€šä¿¡è´Ÿè½½å¤©ç„¶å¹³è¡¡
  - embedding è¡¨è§„æ¨¡å°ï¼Œé€šä¿¡å æ¯”ä½ï¼ˆä»… ~5%ï¼Œè§å›¾5ç«ç„°å›¾ï¼‰

> ğŸ” å›¾5æ˜¾ç¤ºï¼šä¸»è¦å¼€é”€åœ¨ `apply_emb` å’Œ `apply_mlp`ï¼Œè€Œéé€šä¿¡æœ¬èº«ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒä¸åº•å±‚æ€§èƒ½åˆ†æ

#### BLS alltoallv vs MPI_Alltoallvï¼ˆçº¯é€šä¿¡æµ‹è¯•ï¼‰

| åœºæ™¯ | ç»“æœ |
|------|------|
| å°æ¶ˆæ¯ï¼ˆ<4KBï¼‰ | MPI æ›´ä¼˜ï¼ˆå› å…¶èƒ½åˆå¹¶ IB è¯·æ±‚ï¼‰ |
| å¤§æ¶ˆæ¯ï¼ˆ>4KBï¼‰ | BLS æ›´ä¼˜ï¼ˆone-sided æ— åè®®åˆ‡æ¢å¼€é”€ï¼‰ |
| å¤šæ¬¡è¿ç»­è°ƒç”¨ | MPI æ›´ç¨³å®šï¼›BLS å› é¢‘ç¹ polling å¼€é”€ç•¥å·® |

> âœ… å°½ç®¡ BLS alltoallv åœ¨æŸäº›åœºæ™¯ä¸‹ä¸å¦‚ MPIï¼Œä½†åœ¨å®é™… DLRM æ¨ç†ä¸­é¢‘ç‡è¾ƒä½ï¼Œä¸å½±å“æ•´ä½“æ”¶ç›Šã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **BLS æ˜¯ä¸€ç§æœ‰æ•ˆçš„å»åŒæ­¥åŒ–ç­–ç•¥**ï¼š
   - åœ¨å­˜åœ¨ **é€šä¿¡/è®¡ç®—ä¸å‡è¡¡** çš„åœºæ™¯ä¸‹ï¼ŒBLS å¯æ˜¾è‘—æ”¹å–„ DLRM æ¨ç†çš„å»¶è¿Ÿå’Œååã€‚
   - åœ¨ç†æƒ³æ¡ä»¶ä¸‹ï¼ˆå¦‚éšæœºå»¶è¿Ÿï¼‰ï¼Œ**å¯å®Œå…¨æ©ç›– straggler å½±å“**ã€‚

2. **é€šä¿¡é‡å èƒ½åŠ›é€çº§å¢å¼º**ï¼š
   - å¦‚ Table I æ‰€ç¤ºï¼ŒBLS backend æä¾›æœ€å¼ºçš„å¼‚æ­¥æ”¯æŒï¼Œå…è®¸ä»»æ„é˜¶æ®µè·¨è¿­ä»£é‡å ã€‚

3. **çœŸå®ä¸–ç•Œè´Ÿè½½éœ€æ›´å¤æ‚å»ºæ¨¡**ï¼š
   - å½“å‰ä¸»æµå…¬å¼€æ•°æ®é›†ï¼ˆå¦‚ Mini-Kaggleã€Ali-CCPï¼‰è´Ÿè½½è¿‡äºå‡è¡¡ï¼Œ**æ— æ³•å……åˆ†ä½“ç° BLS ä»·å€¼**ã€‚
   - å®é™…ç”Ÿäº§ç¯å¢ƒä¸­å¯èƒ½å­˜åœ¨æ›´å¤§è§„æ¨¡ã€æ›´é«˜åæ–œçš„è®¿é—®æ¨¡å¼ã€‚

4. **å†…å­˜å¼€é”€å¯æ§**ï¼š
   - æ¯å¢åŠ ä¸€ä¸ª `k`ï¼Œæ¯ä¸ªè¿›ç¨‹é¢å¤–æ¶ˆè€—çº¦ **860 KB å†…å­˜**ï¼ˆä¸ embedding table å¤§å°æ— å…³ï¼‰
   - å¯¹ç°ä»£ç³»ç»Ÿè€Œè¨€å±äºå¯æ¥å—èŒƒå›´ã€‚

---

### âš ï¸ å±€é™æ€§

| é™åˆ¶ | è¯´æ˜ |
|------|------|
| **ä»…é€‚ç”¨äº inference-only åœºæ™¯** | å› ä¸ºè®­ç»ƒéœ€è¦ä¸¥æ ¼åŒæ­¥æ¢¯åº¦æ›´æ–°ï¼Œä¸èƒ½å®¹å¿å‚æ•°é™ˆæ—§ |
| **ä¾èµ– RDMA ç¡¬ä»¶** | å½“å‰å®ç°ç»‘å®š InfiniBand/RDMAï¼Œé€šç”¨æ€§å—é™ |
| **å¯¹å®Œå…¨å¹³è¡¡è´Ÿè½½æ— æ•ˆ** | è‹¥ç³»ç»Ÿæœ¬å°±æ—  stragglerï¼Œåˆ™ BLS æ— æ”¶ç›Š |
| **polling å¼€é”€è¾ƒé«˜** | å½“å‰ç‰ˆæœ¬æœªä¼˜åŒ– IB è¯·æ±‚æ‰¹å¤„ç†ï¼Œå½±å“é«˜é¢‘é€šä¿¡æ€§èƒ½ |

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³å…¶ä»– collective æ“ä½œ**ï¼šå°† BLS æ€æƒ³åº”ç”¨äº `allreduce`ã€`broadcast` ç­‰ã€‚
2. **æ”¯æŒæ›´å¤šç¡¬ä»¶å¹³å°**ï¼šé€‚é… RoCEã€CXL æˆ– PCIe P2P ç­‰æ–°å‹äº’è¿æŠ€æœ¯ã€‚
3. **åŠ¨æ€è°ƒæ•´ bound `k`**ï¼šæ ¹æ®è¿è¡Œæ—¶è´Ÿè½½è‡ªåŠ¨è°ƒèŠ‚æ»åçª—å£å¤§å°ã€‚
4. **ç»“åˆ caching/sharding ç­–ç•¥**ï¼šä¸ TorchRecã€Merlin ä¸­çš„ç¼“å­˜æœºåˆ¶ååŒä¼˜åŒ–ã€‚
5. **æ„å»ºæ›´å…·æŒ‘æˆ˜æ€§çš„ benchmark**ï¼šè®¾è®¡åæ˜ çœŸå®çº¿ä¸Šæµé‡åæ–œçš„å¤§è§„æ¨¡åˆæˆ workloadã€‚

---

## æ€»ç»“

ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
æœ¬æ–‡æå‡ºäº† **Bounded Lag Synchronous (BLS)** æ–°èŒƒå¼ï¼Œé€šè¿‡æ”¾æ¾ DLRM æ¨ç†ä¸­çš„åŒæ­¥çº¦æŸï¼Œåœ¨å­˜åœ¨è´Ÿè½½ä¸å‡è¡¡æ—¶æ˜¾è‘—æå‡äº†åˆ†å¸ƒå¼æ¨ç†ç³»ç»Ÿçš„æ€§èƒ½ï¼Œä¸”ä¸å½±å“æ¨¡å‹ç²¾åº¦ã€‚

ğŸ¯ **é€‚ç”¨åœºæ™¯**ï¼š  
é€‚åˆéƒ¨ç½²åœ¨å­˜åœ¨ç¡¬ä»¶å·®å¼‚ã€èµ„æºäº‰æŠ¢æˆ–è®¿é—®åæ–œä¸¥é‡çš„ç”Ÿäº§çº§æ¨èç³»ç»Ÿä¸­ï¼Œä½œä¸ºç°æœ‰é€šä¿¡æ ˆçš„æœ‰æ•ˆè¡¥å……ã€‚

ğŸ”§ **å·¥ç¨‹æ„ä¹‰é‡å¤§**ï¼š  
æä¾›äº†ä¸€ä¸ªå¯åœ¨ä¸æ”¹å˜ç®—æ³•çš„å‰æä¸‹ï¼Œé€šè¿‡ç³»ç»Ÿçº§ä¼˜åŒ–é€æ˜åŠ é€Ÿæ¨ç†çš„æ–°è·¯å¾„ã€‚

</details>

---

### 11. [MoE-TransMov: A Transformer-based Model for Next POI Prediction in Familiar & Unfamiliar Movements](https://arxiv.org/abs/2512.17985)

**Authors**: Ruichen Tan, Jiawei Xue, Kota Tsubouchi, Takahiro Yabe, Satish V. Ukkusuri  
**Category**: cs.LG  
**Published**: 2025-12-23  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.17985v1  

#### Abstract
Accurate prediction of the next point of interest (POI) within human mobility trajectories is essential for location-based services, as it enables more timely and personalized recommendations. In particular, with the rise of these approaches, studies have shown that users exhibit different POI choic...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MoE-TransMov: A Transformer-based Model for Next POI Prediction in Familiar & Unfamiliar Movements  
**æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ç°æœ‰ Next POI Prediction æ¨¡å‹é€šå¸¸å°†æ‰€æœ‰ç”¨æˆ·ç§»åŠ¨è¡Œä¸ºç»Ÿä¸€å»ºæ¨¡ï¼Œå¿½ç•¥äº†ç”¨æˆ·åœ¨ **familiarï¼ˆç†Ÿæ‚‰ï¼‰åŒºåŸŸ** å’Œ **unfamiliarï¼ˆä¸ç†Ÿæ‚‰ï¼‰åŒºåŸŸ** ä¸­è¡¨ç°å‡ºæ˜¾è‘—ä¸åŒçš„ç§»åŠ¨æ¨¡å¼ï¼ˆå¦‚ POI ç±»å‹åå¥½ã€è½¨è¿¹é€‰æ‹©ç­‰ï¼‰ã€‚è¿™ç§â€œä¸€åˆ€åˆ‡â€çš„å»ºæ¨¡æ–¹å¼å®¹æ˜“å¯¼è‡´ **negative transfer**ï¼ˆè´Ÿè¿ç§»ï¼‰ï¼Œå³æ¨¡å‹åœ¨ä¸€ç§æƒ…å¢ƒä¸‹å­¦åˆ°çš„çŸ¥è¯†å¹²æ‰°å¦ä¸€ç§æƒ…å¢ƒä¸‹çš„é¢„æµ‹ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šMoE-TransMov
æå‡ºäº†ä¸€ç§åŸºäº **Transformer** ä¸ **Mixture-of-Experts (MoE)** æ¶æ„èåˆçš„æ–°å‹æ¨¡å‹ â€”â€” **MoE-TransMov**ï¼Œç”¨äºåŒæ—¶æ•æ‰ç”¨æˆ·åœ¨ç†Ÿæ‚‰ä¸ä¸ç†Ÿæ‚‰ç¯å¢ƒä¸­çš„å¼‚è´¨æ€§ç§»åŠ¨è¡Œä¸ºã€‚

#### åˆ›æ–°è®¾è®¡ï¼š
- **å…±äº« Transformer Encoder**ï¼šæå–å…¨å±€ç”¨æˆ·ç§»åŠ¨åºåˆ—çš„é€šç”¨ç‰¹å¾ã€‚
- **åŒä¸“å®¶ç»“æ„ï¼ˆTwo Expertsï¼‰**ï¼š
  - **Transformer-based Expert**ï¼šæ“…é•¿å»ºæ¨¡é•¿è·ç¦»ä¾èµ–ï¼Œé€‚ç”¨äºç†Ÿæ‚‰åŒºåŸŸä¸­è§„å¾‹æ€§å¼ºã€åºåˆ—è¾ƒé•¿çš„è¡Œä¸ºã€‚
  - **LSTM-based Expert**ï¼šæ›´é€‚åˆå¤„ç†ç¨€ç–ã€çŸ­åºåˆ—ï¼Œé€‚ç”¨äºä¸ç†Ÿæ‚‰åŒºåŸŸä¸­æ¢ç´¢æ€§å¼ºã€æ•°æ®ç¨€ç–çš„è¡Œä¸ºã€‚
- **å¯å­¦ä¹ çš„ Gating Network**ï¼šåŠ¨æ€åœ°æ ¹æ®è¾“å…¥åºåˆ—å†³å®šæ¿€æ´»å“ªä¸ªä¸“å®¶ï¼Œæ— éœ€æ˜¾å¼æ ‡æ³¨â€œfamiliar/unfamiliarâ€æ ‡ç­¾ï¼Œå®ç°ç«¯åˆ°ç«¯è‡ªé€‚åº”è·¯ç”±ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ä¼˜åŠ¿ç»´åº¦ | å…·ä½“ä½“ç° |
|--------|---------|
| **ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›æ›´å¼º** | æ˜¾å¼åŒºåˆ† familiar/unfamiliar ç§»åŠ¨åœºæ™¯ï¼Œé¿å…è¡Œä¸ºæ··æ·† |
| **æ¨¡å‹çµæ´»æ€§æ›´é«˜** | MoE ç»“æ„å…è®¸ä¸åŒä¸“å®¶ä¸“æ³¨ä¸åŒè¡Œä¸ºæ¨¡å¼ï¼Œæå‡è¡¨è¾¾èƒ½åŠ› |
| **è®¡ç®—æ•ˆç‡å¯æ§** | ä»…æ¿€æ´»éƒ¨åˆ†ä¸“å®¶ï¼Œä¿æŒé«˜å®¹é‡çš„åŒæ—¶æ§åˆ¶è®¡ç®—å¼€é”€ |
| **æ³›åŒ–èƒ½åŠ›å¼º** | åœ¨å¤šä¸ªçœŸå®åŸå¸‚æ•°æ®é›†ä¸ŠéªŒè¯æœ‰æ•ˆï¼Œå°¤å…¶åœ¨å¤æ‚ã€å¤šæ ·åŒ–çš„ç°å®åœºæ™¯ä¸­è¡¨ç°ä¼˜å¼‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
| æ•°æ®é›† | æè¿° |
|-------|------|
| **Foursquare NYC Dataset** | å¼€æºå°è§„æ¨¡åŸºå‡†æ•°æ®é›†ï¼Œå¸¸ç”¨äº POI æ¨èç ”ç©¶ï¼ŒåŒ…å«çº½çº¦å¸‚ç”¨æˆ·çš„ç­¾åˆ°è®°å½•ã€‚ä½œä¸ºæ ‡å‡†å¯¹æ¯”ç¯å¢ƒã€‚ |
| **LY Corporation Kyoto Dataset** | è‡ªç ”å¤§è§„æ¨¡çœŸå®ä¸–ç•Œæ•°æ®é›†ï¼Œç”±æ—¥æœ¬ LY Corporationï¼ˆYahoo Japanï¼‰æä¾›ï¼Œæ¶µç›–äº¬éƒ½å¸‚çº¦ 8 ä¸ªæœˆçš„åŒ¿åç”¨æˆ·ç­¾åˆ°æ•°æ®ï¼ŒåŒ…å«è¶…è¿‡ç™¾ä¸‡æ¡æ—¶é—´åºåˆ—ã€‚ç›¸æ¯” Foursquare æ›´å¤§ã€æ›´å¯†é›†ã€æ›´å…·ç°å®å¤šæ ·æ€§ã€‚ |

> âš ï¸ æ³¨ï¼šä¸¤ä¸ªæ•°æ®é›†å‡ç»è¿‡é¢„å¤„ç†ï¼Œè¿‡æ»¤æ‰ä¼šè¯å°‘äº 10 æ¡ã€ç”¨æˆ·å°‘äº 10 ä¸ªä¼šè¯çš„æ•°æ®ã€‚

### ğŸ§ª å®éªŒè®¾ç½®
- **è®­ç»ƒ/éªŒè¯åˆ’åˆ†**ï¼šæŒ‰è½¨è¿¹çº§åˆ«åˆ’åˆ†ä¸º 80%/20%
- **æ¨¡å‹ç»“æ„å‚æ•°**ï¼š
  - Shared Transformer Encoderï¼š4 å±‚ï¼Œ8 å¤´æ³¨æ„åŠ›ï¼Œéšè—å±‚ç»´åº¦ 128
  - Expertsï¼š
    - Transformer Expertï¼šåŒä¸Š
    - LSTM Expertï¼š2 å±‚ï¼Œéšè—å¤§å° 64
  - åºåˆ—é•¿åº¦ï¼šè®­ç»ƒæ—¶æœ€å¤§ 50ï¼Œæ”¯æŒæœ€é•¿ 500 çš„ä½ç½®ç¼–ç 
- **ä¼˜åŒ–å™¨**ï¼šAdamï¼Œå­¦ä¹ ç‡ 0.0005ï¼Œbatch size 64
- **æ—©åœæœºåˆ¶**ï¼šè¿ç»­ 3 è½®éªŒè¯æŸå¤±ä¸Šå‡åˆ™åœæ­¢è®­ç»ƒ

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
- **Top-k Accuracy (k=1,5,10)**ï¼šé¢„æµ‹åˆ—è¡¨å‰ k ä¸ªæ˜¯å¦åŒ…å«çœŸå®ä¸‹ä¸€ä¸ª POI
- **Mean Reciprocal Rank (MRR)**ï¼šè¡¡é‡æ­£ç¡® POI åœ¨æ’åºåˆ—è¡¨ä¸­çš„å¹³å‡æ’åè´¨é‡ï¼Œè¶Šæ—©å‡ºç°å¾—åˆ†è¶Šé«˜

$$
\text{MRR} = \frac{1}{|Q|} \sum_{i=1}^{|Q|} \frac{1}{\text{rank}_i}
$$

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ¨¡å‹ | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| Majority Vote | ç»Ÿè®¡åŸºçº¿ | é¢„æµ‹å†å²æœ€é¢‘ç¹è®¿é—®çš„ POI |
| MLP | æµ…å±‚ç¥ç»ç½‘ç»œ | å­¦ä¹ éçº¿æ€§å…³ç³» |
| LSTM | RNN æ¨¡å‹ | æ•æ‰é•¿æœŸä¾èµ– |
| DeepMove | Attention + RNN | å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶ |
| STAN | Spatio-Temporal Attention | åŒæ—¶å…³æ³¨æ—¶ç©ºä¸Šä¸‹æ–‡ |
| GETNext | Graph-based | æ„å»ºè½¨è¿¹æµå›¾è¿›è¡Œæ¨è |
| Transformer | Self-Attention | å¹¶è¡Œå¤„ç†åºåˆ—ï¼Œæ•è·å…¨å±€ä¾èµ– |
| Informer | Efficient Transformer | ä½¿ç”¨ ProbSparse æ³¨æ„åŠ›ï¼Œé€‚åˆé•¿åºåˆ— |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š æ€§èƒ½å¯¹æ¯”ï¼ˆå…³é”®æ•°æ®æ‘˜è¦ï¼‰

#### âœ… åœ¨ **Foursquare NYC Dataset** ä¸Šçš„ç»“æœï¼ˆTable 3ï¼‰
| æ–¹æ³• | Familiar Top-1 | Unfamiliar Top-1 | Total MRR |
|------|----------------|------------------|-----------|
| Majority Vote | **0.2248** | 0.0056 | 0.1906 |
| MoE-TransMov | 0.2111 | **0.1164** | **0.2639** |

> ğŸ’¡ è§‚å¯Ÿï¼šè™½ç„¶ Majority Vote åœ¨ familiar åœºæ™¯ä¸‹å› â€œé‡å¤è®¿é—®â€ç°è±¡å ä¼˜ï¼Œä½†åœ¨ **unfamiliar åœºæ™¯å‡ ä¹å¤±æ•ˆ**ï¼›è€Œ MoE-TransMov åœ¨ **unfamiliar å’Œ total åœºæ™¯å…¨é¢é¢†å…ˆ**ï¼Œè¯´æ˜å…¶å¯¹ç¨€ç–ã€æ–°é¢–è¡Œä¸ºæœ‰æ›´å¼ºå»ºæ¨¡èƒ½åŠ›ã€‚

#### âœ… åœ¨ **LY Corporation Kyoto Dataset** ä¸Šçš„ç»“æœï¼ˆTable 4ï¼‰
| æ–¹æ³• | Familiar MRR | Unfamiliar Top-1 | Total MRR |
|------|--------------|------------------|-----------|
| STAN | 0.1668 | 0.0797 | 0.1522 |
| Transformer | 0.1770 | 0.0895 | 0.1754 |
| MoE-TransMov | **0.1826** | **0.1179** | **0.1946** |

> âœ… MoE-TransMov åœ¨ **æ‰€æœ‰å­é›†ï¼ˆfamiliar, unfamiliar, totalï¼‰å‡ ä¹æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡è¾¾åˆ° SOTA**ï¼Œç‰¹åˆ«æ˜¯åœ¨ **unfamiliar åœºæ™¯ Top-1 æå‡æ˜¾è‘—ï¼ˆ+32% vs Transformerï¼‰**ï¼Œè¯æ˜å…¶å¯¹é™Œç”ŸåŒºåŸŸçš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Study, Table 5ï¼‰

| å˜ä½“ | Unfamiliar MRR | Total MRR |
|------|----------------|-----------|
| Full MoE-TransMov | **0.2072** | **0.1946** |
| w/o MoEï¼ˆä»…å…±äº« Transformerï¼‰ | 0.1737 | 0.1754 |
| w/o Transformerï¼ˆæ— å…±äº«ç¼–ç å™¨ï¼‰ | 0.1748 | 0.1617 |
| MoE(2 LSTMs) | 0.2005 | 0.1903 |
| MoE(2 Transformers) | 0.1913 | 0.1879 |

#### æ¶ˆèåˆ†æç»“è®ºï¼š
1. **ç§»é™¤ MoE æ¨¡å— â†’ æ€§èƒ½ä¸‹é™æ˜æ˜¾**ï¼Œå°¤å…¶åœ¨ unfamiliar åœºæ™¯ï¼Œè¯´æ˜ä¸“å®¶åˆ†å·¥è‡³å…³é‡è¦ï¼›
2. **ç§»é™¤å…±äº« Transformer â†’ æ€§èƒ½å¤§å¹…é€€åŒ–**ï¼Œè¡¨æ˜å…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡ä¸å¯æˆ–ç¼ºï¼›
3. **åŒ LSTM æˆ–åŒ Transformer ä¸“å®¶ä¸å¦‚æ··åˆæ¶æ„**ï¼Œè¯´æ˜ **Transformer + LSTM çš„å¼‚æ„ä¸“å®¶ç»„åˆæœ€ä¼˜**ï¼Œåˆ†åˆ«é€‚é…é•¿çŸ­åºåˆ—è¡Œä¸ºï¼›
4. **ç«¯åˆ°ç«¯è½¯è·¯ç”±ä¼˜äºç¡¬åˆ‡æ¢**ï¼Œä½“ç° MoE åŠ¨æ€é€‚åº”æ€§çš„ä¼˜åŠ¿ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ç”¨æˆ·åœ¨ familiar å’Œ unfamiliar åŒºåŸŸçš„è¡Œä¸ºå·®å¼‚æ˜¾è‘—**ï¼Œå¿…é¡»åŒºåˆ«å¯¹å¾…æ‰èƒ½æå‡é¢„æµ‹ç²¾åº¦ï¼›
2. **MoE æ¶æ„èƒ½æœ‰æ•ˆè§£è€¦å¼‚è´¨è¡Œä¸ºæ¨¡å¼**ï¼Œé€šè¿‡ä¸“å®¶ä¸“ä¸šåŒ–é¿å… negative transferï¼›
3. **MoE-TransMov åœ¨çœŸå®å¤§è§„æ¨¡æ•°æ®é›†ï¼ˆKyotoï¼‰ä¸Šè¡¨ç°å°¤ä¸ºçªå‡º**ï¼Œè¯´æ˜å…¶åœ¨å¤æ‚ã€å¤šæ ·åŒ–ç°å®åœºæ™¯ä¸­å…·æœ‰å¼ºé²æ£’æ€§å’Œå¯æ‰©å±•æ€§ï¼›
4. **å…±äº«ç¼–ç  + ä¸“ç”¨ä¸“å®¶ + åŠ¨æ€é—¨æ§** çš„è®¾è®¡æ˜¯æˆåŠŸçš„å…³é”®ï¼Œå®ç°äº†â€œç»Ÿä¸€æ¡†æ¶ã€å·®å¼‚åŒ–å»ºæ¨¡â€ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»…è€ƒè™‘ç©ºé—´ç§»åŠ¨ä¸Šä¸‹æ–‡ï¼Œæœªå¼•å…¥å¤©æ°”ã€èŠ‚å‡æ—¥ã€ç¤¾äº¤ä¿¡å·ç­‰å¤–éƒ¨å› ç´ ï¼›
- ä¸“å®¶æ•°é‡å›ºå®šä¸º 2ï¼Œéš¾ä»¥åº”å¯¹æ›´å¤šç»†åˆ†ç§»åŠ¨æ¨¡å¼ï¼ˆå¦‚é€šå‹¤ã€æ—…æ¸¸ã€ç´§æ€¥å‡ºè¡Œï¼‰ï¼›
- è™½ç„¶ MoE æé«˜äº†æ•ˆç‡ï¼Œä½†æ•´ä½“æ¨¡å‹ä»è¾ƒå¤æ‚ï¼Œéƒ¨ç½²æˆæœ¬è¾ƒé«˜ï¼›
- gating network å®Œå…¨ä¾èµ–å†å²è½¨è¿¹å­¦ä¹ ï¼Œç¼ºä¹å¯è§£é‡Šæ€§ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆä½œè€…å»ºè®®ï¼‰
1. **å¼•å…¥å¤šæ¨¡æ€ä¸Šä¸‹æ–‡**ï¼šèåˆå¤©æ°”ã€äº¤é€šã€ç”¨æˆ·æœç´¢æ„å›¾ç­‰è¾…åŠ©ä¿¡æ¯ï¼›
2. **æ‰©å±•ä¸“å®¶æ•°é‡ä¸å±‚æ¬¡åŒ– gating**ï¼šæ„å»ºæ›´ç»†ç²’åº¦çš„è¡Œä¸ºåˆ†ç±»ä½“ç³»ï¼›
3. **è·¨åŸè¿ç§»å­¦ä¹ ï¼ˆCross-city Transferï¼‰**ï¼šæ¢ç´¢æ¨¡å‹åœ¨ä¸åŒåŸå¸‚é—´çš„æ³›åŒ–èƒ½åŠ›ï¼›
4. **é›†æˆç¤¾ä¼šä¿¡å·ä¸ç¾¤ä½“è¡Œä¸º**ï¼šåˆ©ç”¨ co-locationã€å¥½å‹å½±å“ç­‰å¢å¼ºä¸ªæ€§åŒ–æ¨èï¼›
5. **è½»é‡åŒ–ä¸è¾¹ç¼˜éƒ¨ç½²ä¼˜åŒ–**ï¼šæ¨åŠ¨ MoE æ¶æ„åœ¨ç§»åŠ¨ç«¯çš„å®é™…åº”ç”¨ã€‚

---

## âœ… æ€»ç»“
**MoE-TransMov** æ˜¯é¦–ä¸ªå°† **Mixture-of-Experts** æœºåˆ¶ç³»ç»Ÿåº”ç”¨äº **Next POI Prediction** å¹¶æ˜¾å¼åŒºåˆ† **familiar/unfamiliar ç§»åŠ¨åœºæ™¯** çš„ Transformer æ¨¡å‹ã€‚å®ƒé€šè¿‡ **å…±äº«ç¼–ç å™¨ + å¼‚æ„ä¸“å®¶ + åŠ¨æ€é—¨æ§** çš„è®¾è®¡ï¼Œåœ¨å¤šä¸ªçœŸå®æ•°æ®é›†ä¸Šå®ç°äº† SOTA è¡¨ç°ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†ç¨€ç–ã€ä¸å¯é¢„æµ‹çš„ unfamiliar è¡Œä¸ºæ–¹é¢å±•ç°å‡ºå¼ºå¤§ä¼˜åŠ¿ã€‚è¯¥å·¥ä½œä¸ä»…æå‡äº† POI æ¨èç³»ç»Ÿçš„ä¸ªæ€§åŒ–æ°´å¹³ï¼Œä¹Ÿä¸ºå¤æ‚äººç±»ç§»åŠ¨è¡Œä¸ºå»ºæ¨¡æä¾›äº†æ–°çš„èŒƒå¼ã€‚

</details>

---

### 12. [Population-Evolve: a Parallel Sampling and Evolutionary Method for LLM Math Reasoning](https://arxiv.org/abs/2512.19081)

**Authors**: Yanzhi Zhang, Yitong Duan, Zhaoxi Zhang, Jiyan He, Shuxin Zheng  
**Category**: cs.AI  
**Published**: 2025-12-23  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.19081v1  

#### Abstract
Test-time scaling has emerged as a promising direction for enhancing the reasoning capabilities of Large Language Models in last few years. In this work, we propose Population-Evolve, a training-free method inspired by Genetic Algorithms to optimize LLM reasoning. Our approach maintains a dynamic po...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Population-Evolve: a Parallel Sampling and Evolutionary Method for LLM Math Reasoning*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰ç”¨äºæå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ•°å­¦æ¨ç†èƒ½åŠ›çš„æ–¹æ³•ä¸»è¦ä¾èµ–äº**åè®­ç»ƒæŠ€æœ¯**ï¼ˆå¦‚ SFTã€RLHFã€RLVRï¼‰ï¼Œè¿™äº›æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **è®¡ç®—æˆæœ¬é«˜**ï¼Œéœ€è¦å¤§é‡é«˜è´¨é‡æ ‡æ³¨æ•°æ®ï¼›
- æ•°æ®ç¨€ç¼ºå¯¼è‡´è¾¹é™…æ”¶ç›Šé€’å‡ã€‚

å› æ­¤ï¼Œç ”ç©¶è€…è½¬å‘**test-time scaling**ï¼ˆæµ‹è¯•æ—¶æ‰©å±•ï¼‰ç­–ç•¥ï¼Œå³åœ¨ä¸è¿›è¡Œé¢å¤–è®­ç»ƒçš„å‰æä¸‹ï¼Œé€šè¿‡æ¨ç†è¿‡ç¨‹ä¸­çš„ä¼˜åŒ–æ¥æå‡æ€§èƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰ test-time æ–¹æ³•ä¹Ÿé¢ä¸´æŒ‘æˆ˜ï¼š
- **DSER** ç­‰åºåˆ—è‡ªæ¼”åŒ–æ–¹æ³•å­˜åœ¨**é«˜æ—¶é—´å¼€é”€å’Œæ€§èƒ½æ–¹å·®å¤§**çš„é—®é¢˜ï¼›
- **GenSelect** è™½ç„¶ç¨³å®šï¼Œä½†ç¼ºä¹è¿­ä»£ä¼˜åŒ–æœºåˆ¶ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨ LLM çš„ç”Ÿæˆ-éªŒè¯é—­ç¯ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šPopulation-Evolve

ä½œè€…æå‡ºäº†ä¸€ç§å…¨æ–°çš„**æ— éœ€è®­ç»ƒ**çš„å¹¶è¡Œé‡‡æ ·ä¸è¿›åŒ–å¼æ¨ç†æ¡†æ¶ â€”â€” **Population-Evolve**ï¼Œå…¶çµæ„Ÿæ¥æºäºé—ä¼ ç®—æ³•ï¼ˆGenetic Algorithm, GAï¼‰ã€‚

#### æ ¸å¿ƒæ€æƒ³ï¼š
- ç»´æŠ¤ä¸€ä¸ªå€™é€‰è§£çš„åŠ¨æ€â€œç§ç¾¤â€ $ G^{(i)} $ï¼Œæ¯è½®é€šè¿‡ LLM è‡ªæˆ‘æ¼”åŒ–ç”Ÿæˆæ–°ä¸€ä»£ï¼›
- ä½¿ç”¨ç»Ÿä¸€çš„ **evolve prompt** å¼•å¯¼æ¨¡å‹åŸºäºå‰ä¸€ä»£æ‰€æœ‰è§£ç”Ÿæˆæ›´ä¼˜çš„æ–°è§£ï¼›
- æœ€ç»ˆé€šè¿‡ **majority voting** å¾—åˆ°æœ€ç»ˆç­”æ¡ˆã€‚

#### åˆ›æ–°ç‚¹ï¼š
1. **å¹¶è¡Œ + è¿­ä»£ç»“åˆ**ï¼šä¸åŒäº DSER çš„ä¸²è¡Œè¿­ä»£ï¼ŒPopulation-Evolve åœ¨æ¯è½®ä¸­å¹¶è¡Œæ¼”åŒ–æ•´ä¸ªç§ç¾¤ï¼Œæ˜¾è‘—æé«˜æ•ˆç‡ã€‚
2. **è‡ªæˆ‘æ¼”åŒ–çš„é—­ç¯æœºåˆ¶**ï¼šåˆ©ç”¨ LLM å¯¹å¤šä¸ªå€™é€‰è§£çš„ç†è§£ä¸ç»¼åˆèƒ½åŠ›ï¼Œå®ç°â€œç¾¤ä½“æ™ºèƒ½â€å¼çš„æ¸è¿›ä¼˜åŒ–ã€‚
3. **ç¨³å®šæ€§å¼º**ï¼šéšç€è¿­ä»£è¿›è¡Œï¼Œç§ç¾¤è¶‹äºæ”¶æ•›ï¼Œæ€§èƒ½æ³¢åŠ¨å°ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å¹¶è¡Œæ€§ | æ˜¯å¦è¿­ä»£ | æ•ˆç‡ | ç¨³å®šæ€§ | æ€§èƒ½ä¸Šé™ |
|------|--------|----------|-------|---------|-----------|
| **DSER** | âŒ å•è·¯å¾„ | âœ… æ·±åº¦è¿­ä»£ | ä½ï¼ˆä¸¤é˜¶æ®µä¸²è¡Œï¼‰ | å·®ï¼ˆæ–¹å·®å¤§ï¼‰ | é«˜ä½†ä¸ç¨³å®š |
| **GenSelect** | âœ… å¤šæ ·æœ¬ | âŒ æ— è¿­ä»£ | é«˜ | å¥½ | å—é™äºåˆå§‹åˆ†å¸ƒ |
| **Population-Evolve (ours)** | âœ… ç§ç¾¤å¹¶è¡Œ | âœ… è¿­ä»£æ¼”åŒ– | **é«˜**ï¼ˆå•æ­¥ç”Ÿæˆï¼‰ | **æå¥½**ï¼ˆå¿«é€Ÿæ”¶æ•›ï¼‰ | **æœ€é«˜** |

> âœ… å…³é”®ä¼˜åŠ¿ï¼š**åœ¨ä¿æŒé«˜æ•ˆç‡çš„åŒæ—¶å®ç°äº†é«˜æ€§èƒ½ä¸ä½æ–¹å·®çš„ç»Ÿä¸€**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
ä¸‰ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°å­¦ç«èµ›åŸºå‡†ï¼š
- **HMMT24-25**ï¼š60é“é¢˜ï¼Œæœ€å…·éš¾åº¦ï¼ˆHarvard-MIT Mathematics Tournamentï¼‰
- **AIME25**ï¼š30é“é¢˜ï¼Œä¸­ç­‰éš¾åº¦
- **BRUMO25**ï¼š30é“é¢˜ï¼Œç›¸å¯¹ç®€å•

> æ‰€æœ‰æ•°æ®å‡æ¥è‡ª HuggingFace ä¸Šçš„ `MathArena` æˆ–ä½œè€…æ”¶é›†ï¼Œç¡®ä¿æœªè¢«æ±¡æŸ“ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼š
  - å¼€æºæ¨¡å‹ï¼š`Qwen3-4B-Thinking-2507`, `DeepSeek-R1-0528-Distill-Qwen3-8B`, `OpenReasoning-Nemotron-7B`
  - é¡¶çº§é—­æºæ¨¡å‹å¯¹æ¯”ï¼š`Gemini-2.5-Pro`, `GPT-5.1`ï¼ˆé€šè¿‡ OpenRouter API è°ƒç”¨ï¼‰
- **æ¸©åº¦**ï¼š0.6ï¼ˆå¹³è¡¡å¤šæ ·æ€§ä¸å‡†ç¡®æ€§ï¼‰
- **è§£æå·¥å…·**ï¼šä½¿ç”¨ `Math-Verify` åº“è‡ªåŠ¨æå– `\boxed{}` ä¸­çš„ç­”æ¡ˆ

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **maj@k** | Majority Voting over k ä¸ªç‹¬ç«‹ rolloutï¼ˆå¦‚ maj@64ï¼‰ |
| **avg@n** | n æ¬¡ç‹¬ç«‹è¿è¡Œçš„å¹³å‡å‡†ç¡®ç‡ï¼ˆç”¨äºé«˜æ–¹å·®æ–¹æ³•å¦‚ DSERï¼‰ |
| **pass@k** | Oracle ä¸Šç•Œï¼Œè¡¨ç¤ºä» k ä¸ªæ ·æœ¬ä¸­è‡³å°‘æœ‰ä¸€ä¸ªæ­£ç¡®çš„æ¦‚ç‡ |
| **Std Dev** | è¡¡é‡æ–¹æ³•ç¨³å®šæ€§ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
åœ¨ç»Ÿä¸€æ¡†æ¶ä¸‹æ¯”è¾ƒä»¥ä¸‹æ–¹æ³•ï¼š
1. **DSER**ï¼ˆDeep Self-Evolving Reasoningï¼‰ï¼šå•è·¯å¾„éªŒè¯-ä¿®æ­£å¾ªç¯
2. **GenSelect**ï¼šå¹¶è¡Œç”Ÿæˆ + LLM ä½œä¸ºåˆ¤åˆ«å™¨é€‰æ‹©æœ€ä¼˜è§£
3. **Majority Voting (Self-Consistency)**ï¼šåŸºç¡€ baseline
4. **Pass@16**ï¼šç†è®ºæ€§èƒ½ä¸Šç•Œ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

#### åœ¨ **HMMT24-25**ï¼ˆæœ€éš¾ï¼‰ä¸Šçš„è¡¨ç°ï¼š
| Model | Our Method | GenSelect | DSER | Maj@64 |
|-------|------------|-----------|------|--------|
| Qwen3-4B | **64.17%** | 63.75% | 61.46% | 58.33% |
| DeepSeek-Distill-8B | **70.83%** | 68.75% | 65.31% | 65.00% |
| Nemotron-7B | **82.08%** | 78.75% | 77.08% | 70.00% |

> âœ… å…¨é¢è¶…è¶Šæ‰€æœ‰ baselineï¼Œå°¤å…¶åœ¨å›°éš¾ä»»åŠ¡ä¸Šä¼˜åŠ¿æ˜æ˜¾

#### åœ¨ **AIME25** ä¸Šçš„è¡¨ç°ï¼š
| Model | Our Method | GenSelect | DSER | Maj@64 |
|-------|------------|-----------|------|--------|
| Qwen3-4B | **90.00%** | 89.17% | 85.42% | 86.67% |
| DeepSeek-Distill-8B | **88.33%** | 85.00% | 85.42% | 83.33% |
| Nemotron-7B | **93.33%** | 91.67% | 91.88% | 86.67% |

> âœ… å³ä½¿åœ¨è¾ƒæ˜“ä»»åŠ¡ä¸Šä»ä¿æŒé¢†å…ˆ

#### åœ¨ **BRUMO25** ä¸Šçš„è¡¨ç°ï¼š
| Model | Our Method | GenSelect | DSER | Maj@64 |
|-------|------------|-----------|------|--------|
| Qwen3-4B | **93.33%** | 88.33% | 85.62% | 86.67% |
| DeepSeek-Distill-8B | **93.33%** | 90.00% | 88.96% | 90.00% |
| Nemotron-7B | **95.83%** | 94.17% | 94.79% | 93.33% |

> âœ… å°å¹…é¢†å…ˆï¼Œè¯´æ˜æ–¹æ³•æ³›åŒ–æ€§å¼º

---

### ğŸ“Š æ€§èƒ½å¢ç›Šåˆ†æï¼ˆç›¸æ¯” maj@64ï¼‰
| Benchmark | å¹³å‡æå‡å¹…åº¦ |
|----------|----------------|
| HMMT24-25ï¼ˆæœ€éš¾ï¼‰ | **+7.92%** |
| AIME25ï¼ˆä¸­ç­‰ï¼‰ | +5.00% |
| BRUMO25ï¼ˆæœ€æ˜“ï¼‰ | +4.17% |

> ğŸ’¡ å‘ç°ï¼š**é—®é¢˜è¶Šéš¾ï¼ŒPopulation-Evolve çš„ç›¸å¯¹å¢ç›Šè¶Šå¤§**ï¼Œè¡¨æ˜å…¶åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­æ›´å…·æ½œåŠ›ã€‚

---

### ğŸ” æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰

#### å®éªŒè®¾è®¡ï¼š
- å›ºå®šæ¨¡å‹ï¼š`DeepSeek-R1-0528-Qwen3-8B` å’Œ `Qwen3-4B-Thinking-2507`
- æµ‹è¯•ä¸åŒ population size $ P = 4, 8, 16 $
- åœ¨ HMMT24-25 ä¸Šè§‚å¯Ÿ accuracy éšè¿­ä»£çš„å˜åŒ–

#### ç»“æœï¼ˆå›¾5ï¼‰ï¼š
- **population size è¶Šå¤§ï¼Œæ€§èƒ½è¶Šå¥½**
- $ P=16 $ æ˜æ˜¾ä¼˜äº $ P=8 $ å’Œ $ P=4 $
- æ”¯æŒå‡è®¾ï¼šæ›´å¤§çš„ç§ç¾¤å¸¦æ¥æ›´å¤šå¤šæ ·æ€§ï¼Œæœ‰åŠ©äºå¼•å¯¼æ›´é«˜è´¨é‡çš„æ¼”åŒ–

> âœ… éªŒè¯äº†â€œç§ç¾¤å¤šæ ·æ€§ä¿ƒè¿›è¿›åŒ–â€çš„æ ¸å¿ƒæœºåˆ¶

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Population-Evolve æ˜¯ä¸€ç§é«˜æ•ˆã€ç¨³å®šä¸”å¼ºå¤§çš„ test-time scaling æ–¹æ³•**ï¼š
   - åœ¨å¤šä¸ªæ•°å­¦æ¨ç† benchmark ä¸Š consistently è¶…è¶Š DSERã€GenSelect å’Œ Majority Votingã€‚
   - ç‰¹åˆ«æ˜¯åœ¨é«˜éš¾åº¦ä»»åŠ¡ï¼ˆå¦‚ HMMTï¼‰ä¸Šè¡¨ç°çªå‡ºã€‚

2. **ç»Ÿä¸€è§†è§’ï¼šå°† test-time scaling è§†ä¸ºé—ä¼ ç®—æ³•è¿‡ç¨‹**ï¼š
   - æå‡ºé€šç”¨æ¡†æ¶ $ M=(P,T,F_\phi,S) $ï¼Œæ¶µç›– populationã€iterationã€evolution operatorã€selectionã€‚
   - æˆåŠŸè§£é‡Š DSERã€GenSelectã€Population-Evolve ç­‰æ–¹æ³•çš„æœ¬è´¨å·®å¼‚ã€‚

3. **å¹¶è¡Œæ¼”åŒ–æ˜¾è‘—ä¼˜äºä¸²è¡Œè¿­ä»£**ï¼š
   - DSER å­˜åœ¨ä¸¥é‡çš„æ—¶é—´å¼€é”€å’Œæ€§èƒ½æ–¹å·®ï¼ˆstd dev è¾¾ 4.23%ï¼‰ï¼›
   - Population-Evolve æ”¶æ•›å¿«ï¼ˆé€šå¸¸ 4â€“8 è½®ï¼‰ã€æ–¹å·®å°ã€token æ¶ˆè€—å°‘ã€‚

4. **test-time scaling æ½œåŠ›å·¨å¤§**ï¼š
   - å³ä½¿æ˜¯è¾ƒå°çš„å¼€æºæ¨¡å‹ï¼ˆå¦‚ 4Bâ€“8Bï¼‰ï¼Œç» Population-Evolve ä¼˜åŒ–åï¼Œæ€§èƒ½å¯åª²ç¾ç”šè‡³è¶…è¿‡é¡¶çº§é—­æºæ¨¡å‹ï¼ˆå¦‚ GPT-5.1ã€Gemini-2.5-Proï¼‰çš„ pass@1ã€‚

---

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–é«˜è´¨é‡ prompt è®¾è®¡**ï¼ševolve prompt çš„æœ‰æ•ˆæ€§ç›´æ¥å½±å“æ¼”åŒ–è´¨é‡ã€‚
2. **ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶**ï¼šå½“ population size è¾ƒå¤§æ—¶ï¼Œéœ€å°†å†å²è§£å‹ç¼©å¤„ç†ï¼ˆå»é™¤ `<think>` å†…å®¹ï¼‰ï¼Œå¯èƒ½ä¸¢å¤±éƒ¨åˆ†ä¸­é—´é€»è¾‘ã€‚
3. **å°šæœªç«¯åˆ°ç«¯è®­ç»ƒé€‚é…è¯¥èŒƒå¼**ï¼šç›®å‰ä»æ˜¯æ¨ç†é˜¶æ®µçš„â€œå¤–æŒ‚â€æ–¹æ³•ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼•å…¥å¼ºåŒ–å­¦ä¹ **ï¼šè®­ç»ƒä¸“é—¨é€‚é… Population-Evolve èŒƒå¼çš„ LLMï¼Œä½¿å…¶æ›´æ“…é•¿â€œç§ç¾¤æ¼”åŒ–â€ã€‚
2. **é›†æˆ inference-time communication æœºåˆ¶**ï¼šå€Ÿé‰´ Gemini çš„ DeepThink æ¶æ„ï¼Œå¢å¼ºè·¨è§£çš„ä¿¡æ¯äº¤äº’ã€‚
3. **æ‰©å±•è‡³å…¶ä»–æ¨ç†ä»»åŠ¡**ï¼šå¦‚å½¢å¼åŒ–è¯æ˜ã€ä»£ç ç”Ÿæˆã€ç§‘å­¦å‘ç°ç­‰ã€‚

---

## æ€»ç»“

> **Population-Evolve æˆåŠŸåœ°å°†é—ä¼ ç®—æ³•æ€æƒ³å¼•å…¥ LLM æ¨ç†ä¼˜åŒ–ï¼Œæ„å»ºäº†ä¸€ä¸ªé«˜æ•ˆã€ç¨³å®šã€å¯æ‰©å±•çš„ test-time scaling æ–°èŒƒå¼ã€‚å®ƒä¸ä»…åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šå–å¾— SOTA è¡¨ç°ï¼Œæ›´ä¸ºæœªæ¥â€œæ— éœ€è®­ç»ƒå³å¯æå‡æ¨¡å‹èƒ½åŠ›â€çš„ç ”ç©¶æä¾›äº†é‡è¦æ€è·¯ã€‚**

</details>

---

### 13. [Helios: A Foundational Language Model for Smart Energy Knowledge Reasoning and Application](https://arxiv.org/abs/2512.19299)

**Authors**: Haoyu Jiang, Fanjie Zeng, Boan Qu, Xiaojie Lin, Wei Zhong  
**Category**: cs.AI  
**Published**: 2025-12-23  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.19299v1  

#### Abstract
In the global drive toward carbon neutrality, deeply coordinated smart energy systems underpin industrial transformation. However, the interdisciplinary, fragmented, and fast-evolving expertise in this domain prevents general-purpose LLMs, which lack domain knowledge and physical-constraint awarenes...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠHelios: A Foundational Language Model for Smart Energy Knowledge Reasoning and Applicationã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰é€šç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ™ºèƒ½èƒ½æºï¼ˆsmart energyï¼‰é¢†åŸŸåº”ç”¨ä¸­é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- ç¼ºä¹é¢†åŸŸä¸“ä¸šçŸ¥è¯†ï¼ˆdomain knowledgeï¼‰ï¼Œå¯¼è‡´æ¨ç†ç»“æœè¯­ä¹‰åˆç†ä½†ç‰©ç†ä¸Šæ— æ•ˆï¼ˆphysically invalidï¼‰ï¼›
- é¢†åŸŸèƒ½æºçŸ¥è¯†é«˜åº¦è·¨å­¦ç§‘ã€ç¢ç‰‡åŒ–ä¸”å¿«é€Ÿæ¼”è¿›ï¼Œé€šç”¨LLMséš¾ä»¥å‡†ç¡®å»ºæ¨¡ï¼›
- ç°æœ‰ç ”ç©¶å¤šä¾èµ–æç¤ºå·¥ç¨‹ï¼ˆprompt engineeringï¼‰æˆ–å¾®è°ƒå·²æœ‰æ¨¡å‹ï¼Œæœªç³»ç»Ÿæ€§æ³¨å…¥é¢†åŸŸçŸ¥è¯†ï¼›
- ç¼ºä¹é«˜è´¨é‡ã€æ ‡å‡†åŒ–çš„è®­ç»ƒä¸è¯„ä¼°æ•°æ®é›†ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
æœ¬æ–‡æå‡º **Helios**ï¼Œé¦–ä¸ªä¸“ä¸ºæ™ºèƒ½èƒ½æºé¢†åŸŸè®¾è®¡çš„**åŸºç¡€å¤§è¯­è¨€æ¨¡å‹**ï¼ˆfoundational LLMï¼‰ï¼Œå¹¶é…å¥—æ„å»ºå®Œæ•´èµ„æºä½“ç³»ï¼š

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **Helios æ¨¡å‹**  
   - é¦–ä¸ªé¢å‘æ™ºèƒ½èƒ½æºé¢†åŸŸçš„å¼€æºåŸºç¡€LLMï¼Œæ”¯æŒä»çŸ¥è¯†æ¨ç†åˆ°å¤æ‚å»ºæ¨¡ä»»åŠ¡çš„å¹¿æ³›åº”ç”¨åœºæ™¯ï¼›
   - è¾“å‡ºé£æ ¼ä¸ä¸“ä¸šè¯­å¢ƒæ·±åº¦ä¸€è‡´ï¼Œå…·å¤‡ç‰©ç†çº¦æŸæ„è¯†ã€‚

2. **EnerSysï¼šç«¯åˆ°ç«¯å¤šæ™ºèƒ½ä½“ååŒæ•°æ®æ„å»ºæ¡†æ¶**  
   - è‡ªåŠ¨åŒ–ç”Ÿæˆé«˜è´¨é‡é¢„è®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒå’ŒRLHFæ•°æ®ï¼›
   - åŒ…å«ä¸‰å¤§ç»„ä»¶ï¼š
     - **EnerBase**ï¼šé¦–ä¸ªæ™ºèƒ½èƒ½æºçŸ¥è¯†åº“ï¼ˆ30äº¿tokensï¼‰ï¼›
     - **EnerInstruct**ï¼šé¦–ä¸ªé¢†åŸŸä¸“ç”¨æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼›
     - **EnerReinforce**ï¼šé¦–ä¸ªåŸºäºäººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰çš„æ•°æ®é›†ã€‚

3. **EnerBenchï¼šé¦–ä¸ªæ™ºèƒ½èƒ½æºé¢†åŸŸç»¼åˆè¯„æµ‹åŸºå‡†**  
   - åŒ…å« **976é“å®¢è§‚é¢˜**ï¼ˆé€‰æ‹©ã€åˆ¤æ–­ç­‰ï¼‰å’Œ **625é“ä¸»è§‚é¢˜**ï¼ˆé—®ç­”ã€è§£é‡Šã€å»ºæ¨¡ä¼˜åŒ–ç­‰ï¼‰ï¼›
   - åŒè½¨åˆ¶æ„å»ºï¼šå…¬å…±é¢˜åº“æ£€ç´¢ + ä¸“å®¶å®šå‘è®¾è®¡ï¼Œç¡®ä¿è¦†ç›–å¹¿åº¦ä¸éš¾åº¦ã€‚

4. **ä¸‰é˜¶æ®µè®­ç»ƒèŒƒå¼**  
   - å¤§è§„æ¨¡é¢„è®­ç»ƒ â†’ æŒ‡ä»¤å¾®è°ƒï¼ˆSFTï¼‰ â†’ å¼ºåŒ–å­¦ä¹ å¯¹é½ï¼ˆRLHFï¼‰ï¼Œå®ç°çŸ¥è¯†ç§¯ç´¯ã€ä»»åŠ¡é€‚é…ä¸äººç±»åå¥½å¯¹é½ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | Helios |
|------|--------|--------|
| çŸ¥è¯†æ¥æº | ä¾èµ–é€šç”¨è¯­æ–™ï¼Œç¼ºä¹é¢†åŸŸæ·±åº¦ | æ˜¾å¼æ³¨å…¥æ™ºèƒ½èƒ½æºä¸“ä¸šçŸ¥è¯† |
| æ•°æ®è´¨é‡ | å¤šç”±å¤§æ¨¡å‹ç”Ÿæˆï¼Œé£æ ¼åç¦»äººç±»åå¥½ | å¤šæ™ºèƒ½ä½“åä½œ+äººå·¥éªŒè¯ï¼Œä¿éšœå‡†ç¡®æ€§ä¸å®ç”¨æ€§ |
| è¯„ä¼°ä½“ç³» | ç¼ºä¹ç»Ÿä¸€æ ‡å‡† | å‘å¸ƒé¦–ä¸ªé¢†åŸŸBenchmarkï¼ˆEnerBenchï¼‰ |
| æ¨¡å‹èƒ½åŠ› | åº”ç”¨å¯¼å‘ï¼ˆapply priorï¼‰è€ŒéçŸ¥è¯†ç§¯ç´¯ | å…¨æµç¨‹è®­ç»ƒï¼ŒçœŸæ­£æˆä¸ºâ€œé¢†åŸŸåŸºç¡€æ¨¡å‹â€ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

| æ•°æ®é›† | ç±»å‹ | è§„æ¨¡ | å†…å®¹è¯´æ˜ |
|-------|------|-----|---------|
| **EnerBase** | é¢„è®­ç»ƒè¯­æ–™ | ~3B tokens | æ¥è‡ªarXivã€Web of Scienceã€GitHubã€IEAç­‰å¹³å°çš„ç§‘å­¦æ–‡çŒ®ã€ä»£ç ã€æ•°æ®é›† |
| **EnerInstruct** | æŒ‡ä»¤å¾®è°ƒæ•°æ® | 54,027æ¡æ¸…æ´—åæ ·æœ¬ | è¦†ç›–14ä¸ªå­é¢†åŸŸã€11ç±»ä»»åŠ¡ï¼ˆå¦‚Q&Aã€å»ºæ¨¡ã€åˆ†ç±»ç­‰ï¼‰ |
| **EnerReinforce** | RLHFæ•°æ® | 5ä¸‡ä¸»è§‚é—®é¢˜ + 10ä¸‡å€™é€‰ç­”æ¡ˆ | ç”¨äºå¥–åŠ±æ¨¡å‹è®­ç»ƒä¸æ‹’ç»é‡‡æ ·å¾®è°ƒ |
| **EnerBench** | è¯„æµ‹åŸºå‡† | 1,601é¢˜ï¼ˆ976å®¢è§‚ + 625ä¸»è§‚ï¼‰ | å¤šç»´åº¦è¯„ä¼°LLMsåœ¨æ™ºèƒ½èƒ½æºåœºæ™¯ä¸‹çš„è¡¨ç° |

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼šQwen2.5-7Bï¼ˆ7.62Bå‚æ•°ï¼‰
- **è®­ç»ƒä¸‰é˜¶æ®µ**ï¼š
  1. **Pre-training**ï¼šåœ¨EnerBaseä¸Šå•è½®è®­ç»ƒï¼ˆ22,532æ­¥ï¼‰ï¼Œä½¿ç”¨4Ã—A100 GPUï¼Œè€—æ—¶87å°æ—¶ï¼›
  2. **Instruction Tuning**ï¼šé‡‡ç”¨LoRAè¿›è¡Œä¸¤é˜¶æ®µå¾®è°ƒï¼ˆé€šç”¨æŒ‡ä»¤ â†’ é¢†åŸŸä»»åŠ¡ï¼‰ï¼Œä½¿ç”¨4Ã—RTX 4090ï¼Œè€—æ—¶17å°æ—¶ï¼›
  3. **RLHF**ï¼š
     - å¥–åŠ±æ¨¡å‹è®­ç»ƒï¼šåŸºäºå¯¹æ¯”æ’åºæŸå¤±ï¼ˆpairwise ranking lossï¼‰ï¼›
     - æ‹’ç»é‡‡æ ·å¾®è°ƒï¼ˆRejection Samplingï¼‰ï¼šé€‰å–Top-ké«˜åˆ†å“åº”ä½œä¸ºâ€œé»„é‡‘æ ‡å‡†â€ç»§ç»­è®­ç»ƒã€‚

### è¯„ä¼°æŒ‡æ ‡
#### å®¢è§‚ä»»åŠ¡ï¼ˆObjective Tasksï¼‰
- å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ï¼šå®Œå…¨æ­£ç¡®æ‰å¾—åˆ†ï¼Œéƒ¨åˆ†æ­£ç¡®ç»™åˆ†ï¼Œé”™é€‰ä¸å¾—åˆ†ã€‚

#### ä¸»è§‚ä»»åŠ¡ï¼ˆSubjective Tasksï¼‰
é‡‡ç”¨ä¸‰ç»´è¯„ä¼°æ¡†æ¶ï¼š
- **A-Score**ï¼šåŸºäºGPT-4oçš„ç›¸å¯¹æ¯”è¾ƒè¯„åˆ†ï¼ˆ10åˆ†åˆ¶ï¼‰ï¼›
- **E-Score**ï¼šGPT-4oç‹¬ç«‹æ‰“åˆ†ï¼ˆ10åˆ†åˆ¶ï¼‰ï¼›
- **H-Grade**ï¼šé¢†åŸŸä¸“å®¶äººå·¥è¯„çº§ï¼ˆA/B/C/Dç­‰çº§ï¼‰ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å‚ä¸å¯¹æ¯”çš„æ¨¡å‹åŒ…æ‹¬ï¼š
- å¼€æºæ¨¡å‹ï¼š`Qwen3-8B-Instruct`, `Llama3-8B-Instruct`, `Qwen3-14B-Instruct`, `Qwen3-32B-Instruct`
- å•†ä¸šé—­æºæ¨¡å‹ï¼š`GPT-3.5-Turbo`, `GPT-4`

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªTable 3ï¼‰

| æ¨¡å‹ | S-C (%) | M-C (%) | FC (%) | ESM (A/E/H) | Exp (A/E/H) | Q&A (A/E/H) |
|------|--------|--------|--------|------------|-------------|-------------|
| Qwen3-8B-Instruct | 50.24 | 27.56 | 47.81 | 1.74 / 5.88 / D | 1.63 / 5.04 / â€” | 4.74 / 6.50 / C |
| Llama3-8B-Instruct | 68.42 | 37.60 | 58.77 | 3.29 / 6.03 / D | 3.53 / 6.29 / D | 5.13 / 6.47 / C |
| Qwen3-32B-Instruct | 80.14 | 44.09 | 62.72 | 3.82 / 6.93 / D | 5.51 / 7.32 / C | 6.83 / 7.51 / B |
| GPT-3.5-Turbo | 91.63 | 53.93 | 84.65 | 6.03 / 8.05 / C | 6.94 / 8.57 / B | 7.24 / 8.37 / B |
| GPT-4 | **95.69** | **61.18** | **93.86** | 7.61 / 8.97 / â€” | 8.63 / 9.58 / B | 7.64 / 9.21 / B |
| **Helios** | **93.78** | 53.58 | **89.91** | **5.73 / 7.83 / C** | **7.03 / 9.19 / B** | **7.39 / 8.26 / B** |

> æ³¨ï¼šA = A-Score, E = E-Score, H = H-Gradeï¼›æœ€ä½³ç»“æœåŠ ç²—ï¼Œæ¬¡ä¼˜ä¸‹åˆ’çº¿ã€‚

### æ€§èƒ½åˆ†æ
- **å®¢è§‚ä»»åŠ¡å¹³å‡å‡†ç¡®ç‡**ï¼šHelios è¾¾åˆ° **79.09%**ï¼Œæ˜¾è‘—ä¼˜äºåŒè§„æ¨¡å¼€æºæ¨¡å‹ï¼ˆQwen3-8B: 41.87%, Llama3-8B: 54.93%ï¼‰ï¼Œæ¥è¿‘ GPT-4 æ°´å¹³ï¼›
- **ä¸»è§‚ä»»åŠ¡è¡¨ç°**ï¼š
  - åœ¨ Q&A å’Œ Explanation ä»»åŠ¡ä¸Šï¼ŒHelios æ¥è¿‘ GPT-4 è¡¨ç°ï¼ˆA/E Score å·®è· <0.5ï¼‰ï¼›
  - åœ¨ Energy System Modelingï¼ˆESMï¼‰æ–¹é¢ï¼Œè™½è½åäº GPT-4ï¼ˆå› å‚æ•°é‡é™åˆ¶ï¼‰ï¼Œä½†ä»ä¼˜äº GPT-3.5-Turboï¼Œè¡¨æ˜å…¶å…·å¤‡è°ƒç”¨ä¸“ä¸šåº“è¿›è¡Œå»ºæ¨¡çš„èƒ½åŠ›ï¼›
- **è¾“å‡ºé£æ ¼ä¸€è‡´æ€§**ï¼šç»ä¸“å®¶è¯„å®¡ï¼ŒHelios è¾“å‡ºæ›´ç¬¦åˆä¸“ä¸šè¯è¯­ä½“ç³»ï¼Œé€»è¾‘ä¸¥å¯†ä¸”ç‰©ç†å¯è§£é‡Šæ€§å¼ºã€‚

### æ¶ˆèå®éªŒï¼ˆæ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºè¡¨æ ¼ï¼Œä½†æœ‰è®ºè¿°ï¼‰
- **é¢„è®­ç»ƒå½±å“**ï¼šä»…ç”¨é€šç”¨è¯­æ–™è®­ç»ƒçš„æ¨¡å‹åœ¨æ™ºèƒ½èƒ½æºä»»åŠ¡ä¸Šè¡¨ç°å·®ï¼Œè¯æ˜ EnerBase å¯¹çŸ¥è¯†ç§¯ç´¯è‡³å…³é‡è¦ï¼›
- **æŒ‡ä»¤å¾®è°ƒå¿…è¦æ€§**ï¼šè·³è¿‡UHICé˜¶æ®µç›´æ¥è¿›è¡ŒDS-TAä¼šå¯¼è‡´ä»»åŠ¡ç†è§£åå·®ï¼›
- **RLHFä½œç”¨**ï¼šåŠ å…¥äººç±»åå¥½å¯¹é½åï¼Œæ¨¡å‹åœ¨ä¸»è§‚ä»»åŠ¡ä¸­çš„H-Gradeæå‡æ˜æ˜¾ï¼Œå‡å°‘å¹»è§‰ä¸ä¸åˆ‡å®é™…å»ºè®®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é¢†åŸŸä¸“ç”¨åŸºç¡€æ¨¡å‹å¯è¡Œä¸”å¿…è¦**ï¼šé€šè¿‡ç³»ç»Ÿæ€§æ³¨å…¥æ™ºèƒ½èƒ½æºçŸ¥è¯†ï¼ŒHelios åœ¨å¤šé¡¹ä»»åŠ¡ä¸Šè¶…è¶Šé€šç”¨LLMsï¼ŒéªŒè¯äº†â€œé¢†åŸŸåŸºç¡€æ¨¡å‹â€çš„ä»·å€¼ï¼›
2. **é«˜è´¨é‡æ•°æ®æ˜¯å…³é”®ç“¶é¢ˆ**ï¼šEnerSysæ¡†æ¶æœ‰æ•ˆè§£å†³äº†æ•°æ®ç¨€ç¼ºä¸è´¨é‡é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡å¤šæ™ºèƒ½ä½“åä½œ+äººå·¥æ ¡éªŒæœºåˆ¶ä¿éšœæ•°æ®å¯é æ€§ï¼›
3. **ä¸‰é˜¶æ®µè®­ç»ƒè·¯å¾„æœ‰æ•ˆ**ï¼šPre-train â†’ SFT â†’ RLHF æˆåŠŸå®ç°äº†çŸ¥è¯†å†…åŒ–ã€ä»»åŠ¡é€‚åº”ä¸äººç±»åå¥½å¯¹é½ï¼›
4. **Helioså…·å¤‡å®ç”¨æ½œåŠ›**ï¼šä¸ä»…èƒ½å›ç­”é—®é¢˜ï¼Œè¿˜èƒ½å®Œæˆèƒ½æºç³»ç»Ÿå»ºæ¨¡ã€ä¼˜åŒ–æ–¹æ¡ˆç”Ÿæˆç­‰å¤æ‚ä»»åŠ¡ï¼Œå…·å¤‡å·¥ç¨‹è¾…åŠ©å†³ç­–èƒ½åŠ›ã€‚

### å±€é™æ€§
- **å‚æ•°è§„æ¨¡å—é™**ï¼šå½“å‰åŸºäºQwen2.5-7Bï¼Œå‚æ•°é‡è¿œå°äºGPT-4ï¼ˆ~220Bï¼‰ï¼Œåœ¨å¤æ‚æ¨ç†ä¸å»ºæ¨¡ä»»åŠ¡ä¸Šä»æœ‰å·®è·ï¼›
- **æ•°æ®è·å–å£å’**ï¼šéƒ¨åˆ†æƒå¨æœŸåˆŠæ–‡çŒ®å—ç‰ˆæƒä¿æŠ¤ï¼Œæ— æ³•å…¨é¢çº³å…¥è®­ç»ƒè¯­æ–™ï¼›
- **åŠ¨æ€æ›´æ–°æœºåˆ¶ç¼ºå¤±**ï¼šæ¨¡å‹çŸ¥è¯†é™æ€å›ºåŒ–ï¼Œå°šæœªé›†æˆåœ¨çº¿å­¦ä¹ æˆ–æŒç»­é¢„è®­ç»ƒæœºåˆ¶ä»¥åº”å¯¹å¿«é€Ÿæ¼”è¿›çš„æŠ€æœ¯è¶‹åŠ¿ï¼›
- **è®¡ç®—æˆæœ¬è¾ƒé«˜**ï¼šå…¨æµç¨‹è®­ç»ƒéœ€å¤§é‡GPUèµ„æºï¼Œä¸­å°æœºæ„å¤ç°å›°éš¾ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤§å‚æ•°æ¨¡å‹ï¼ˆå¦‚Helios-14B/32Bï¼‰ï¼›
- æ„å»ºå¢é‡å¼çŸ¥è¯†æ›´æ–°æœºåˆ¶ï¼Œæ”¯æŒæ¨¡å‹æŒç»­å­¦ä¹ ï¼›
- æ¢ç´¢å¤šæ¨¡æ€ç‰ˆæœ¬ï¼ˆèåˆGISã€ä¼ æ„Ÿå™¨æ•°æ®ã€å›¾è¡¨ç­‰ï¼‰ï¼›
- å°†HeliosåµŒå…¥å®é™…èƒ½æºç®¡ç†ç³»ç»Ÿï¼ˆEMSï¼‰ã€è™šæ‹Ÿç”µå‚ï¼ˆVPPï¼‰ç­‰å·¥ä¸šåœºæ™¯ä¸­è½åœ°åº”ç”¨ï¼›
- æ¨åŠ¨å»ºç«‹å¼€æ”¾å…±äº«çš„æ™ºèƒ½èƒ½æºAIç”Ÿæ€ã€‚

---

> âœ… **æ‰€æœ‰è®­ç»ƒæ•°æ®ä¸æ¨¡å‹æ£€æŸ¥ç‚¹å·²å…¬å¼€å‘å¸ƒ**ï¼š  
> GitHubåœ°å€ï¼š[https://github.com/fine68/Helios](https://github.com/fine68/Helios)  
> é¡¹ç›®ä¸»é¡µï¼š[https://helios-llm.github.io/](https://helios-llm.github.io/)

</details>

---

### 14. [Interpretable Hybrid Deep Q-Learning Framework for IoT-Based Food Spoilage Prediction with Synthetic Data Generation and Hardware Validation](https://arxiv.org/abs/2512.19361)

**Authors**: Isshaan Singh, Divyansh Chawla, Anshu Garg, Shivin Mangal, Pallavi Gupta, Khushi Agarwal, Nimrat Singh Khalsa, Nandan Patel  
**Category**: cs.LG  
**Published**: 2025-12-23  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.19361v1  

#### Abstract
The need for an intelligent, real-time spoilage prediction system has become critical in modern IoT-driven food supply chains, where perishable goods are highly susceptible to environmental conditions. Existing methods often lack adaptability to dynamic conditions and fail to optimize decision makin...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥ç ”ç©¶é’ˆå¯¹**ç‰©è”ç½‘ï¼ˆIoTï¼‰é©±åŠ¨çš„é£Ÿå“ä¾›åº”é“¾ä¸­é£Ÿå“è…è´¥é¢„æµ‹ç³»ç»Ÿç¼ºä¹å®æ—¶é€‚åº”æ€§å’Œå†³ç­–é€æ˜åº¦**çš„é—®é¢˜ã€‚ä¼ ç»Ÿæœºå™¨å­¦ä¹ ï¼ˆMLï¼‰æ¨¡å‹åœ¨é™æ€æ•°æ®é›†ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨é¢å¯¹è¿è¾“è¿‡ç¨‹ä¸­åŠ¨æ€å˜åŒ–çš„ç¯å¢ƒæ¡ä»¶ï¼ˆå¦‚æ¸©åº¦ã€æ¹¿åº¦æ³¢åŠ¨ã€ä¼ æ„Ÿå™¨å™ªå£°ï¼‰æ—¶ï¼Œå…¶é¢„æµ‹èƒ½åŠ›æ˜¾è‘—ä¸‹é™ï¼Œä¸”æ¨¡å‹å†³ç­–è¿‡ç¨‹ä¸é€æ˜ï¼Œéš¾ä»¥è¢«é¢†åŸŸä¸“å®¶ä¿¡ä»»å’ŒéªŒè¯ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
è®ºæ–‡æå‡ºäº†ä¸€ç§**å¯è§£é‡Šçš„æ··åˆæ·±åº¦å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼ˆInterpretable Hybrid Deep Q-Learning Frameworkï¼‰**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

- **è§„åˆ™å¼•å¯¼çš„å¯è§£é‡Šåˆ†ç±»å™¨ç¯å¢ƒï¼ˆRule-Based Interpretable Classifier Environmentï¼‰**ï¼š  
  è®¾è®¡äº†ä¸€ä¸ªåŸºäºé¢†åŸŸçŸ¥è¯†çš„è§„åˆ™ç³»ç»Ÿæ¥å®šä¹‰è…è´¥ç­‰çº§ï¼ˆå¦‚â€œä½â€ã€â€œä¸­â€ã€â€œç´§æ€¥â€ï¼‰ï¼Œä¸ºæ™ºèƒ½ä½“æä¾›é€æ˜çš„ã€äººç±»å¯ç†è§£çš„ç›‘ç£ä¿¡å·å’Œè¯­ä¹‰è¾¹ç•Œã€‚è¿™ä½¿å¾—æ™ºèƒ½ä½“çš„å†³ç­–å¯ä»¥è¿½æº¯åˆ°å…·ä½“çš„ä¼ æ„Ÿå™¨é˜ˆå€¼ï¼Œæå¤§æå‡äº†æ¨¡å‹çš„**å¯è§£é‡Šæ€§ï¼ˆInterpretabilityï¼‰**ã€‚

- **LSTM + RNN æ··åˆ Deep Q-Network æ¶æ„**ï¼š  
  åœ¨DQNä¸­é›†æˆ**Long Short-Term Memory (LSTM)** å’Œ **Recurrent Neural Network (RNN)** å±‚ï¼Œå½¢æˆæ··åˆæ¶æ„ã€‚LSTMç”¨äºæ•æ‰é•¿æœŸæ—¶é—´ä¾èµ–å…³ç³»ï¼ˆå¦‚ç¼“æ…¢çš„æ°”ä½“ç§¯ç´¯è¶‹åŠ¿ï¼‰ï¼ŒRNNåˆ™ç²¾ç‚¼çŸ­æœŸåŠ¨æ€æ¨¡å¼ï¼Œå…±åŒå¢å¼ºæ¨¡å‹å¯¹æ—¶åºä¼ æ„Ÿå™¨æ•°æ®çš„å»ºæ¨¡èƒ½åŠ›ã€‚

- **é¢å‘å¯è§£é‡Šæ€§çš„è¯„ä¼°æŒ‡æ ‡ä½“ç³»**ï¼š  
  å¼•å…¥äº†ä¸€ç³»åˆ—è‡ªå®šä¹‰çš„ã€ä»¥å¯è§£é‡Šæ€§ä¸ºå¯¼å‘çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚ `spoilage accuracy`ã€`reward-to-step ratio`ã€`loss decrease rate` å’Œ `exploration rate decay`ï¼Œä¸ä»…è¡¡é‡æ€§èƒ½ï¼Œè¿˜æ´å¯Ÿæ™ºèƒ½ä½“çš„å­¦ä¹ åŠ¨æ€å’Œå†³ç­–é€»è¾‘ã€‚

- **åˆæˆæ•°æ®ç”Ÿæˆä¸ç¡¬ä»¶åŒé‡éªŒè¯**ï¼š  
  é€šè¿‡æ¨¡æ‹ŸçœŸå®ä¼ æ„Ÿå™¨è¯»æ•°ç”Ÿæˆ**åˆæˆæ•°æ®é›†ï¼ˆSynthetic Dataï¼‰**è¿›è¡Œå¤§è§„æ¨¡è®­ç»ƒï¼Œå¹¶åœ¨**Arduino**ä¸ºæ ¸å¿ƒçš„**çœŸå®ç¡¬ä»¶å¹³å°**ä¸Šæ”¶é›†å®æ—¶æ•°æ®è¿›è¡ŒéªŒè¯ï¼Œç¡®ä¿äº†æ–¹æ³•çš„é²æ£’æ€§å’Œå®é™…éƒ¨ç½²æ½œåŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
ç›¸æ¯”ä¼ ç»Ÿçš„MLæ¨¡å‹ï¼ˆå¦‚ANNï¼‰ã€å•ä¸€çš„LSTM/RNNæ¨¡å‹æˆ–è’™ç‰¹å¡æ´›æ–¹æ³•ï¼Œè¯¥æ¡†æ¶åœ¨**å‡†ç¡®æ€§ã€å†³ç­–æ•ˆç‡å’Œå¯è§£é‡Šæ€§**ä¸‰æ–¹é¢å‡å±•ç°å‡ºä¼˜åŠ¿ï¼š
1.  **æ›´å¼ºçš„æ—¶åºå»ºæ¨¡èƒ½åŠ›**ï¼šæ··åˆLSTM+RNNèƒ½åŒæ—¶å¤„ç†é•¿çŸ­æœŸä¾èµ–ï¼Œä¼˜äºå•ä¸€æ¨¡å‹ã€‚
2.  **æ›´é«˜çš„å†³ç­–æ•ˆç‡**ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ çš„å¥–åŠ±æœºåˆ¶ï¼Œæ™ºèƒ½ä½“å­¦ä¼šåšå‡ºæ›´ä¼˜çš„å¹²é¢„ç­–ç•¥ã€‚
3.  **å“è¶Šçš„å¯è§£é‡Šæ€§**ï¼šè§„åˆ™ç¯å¢ƒå’Œå¯è¿½è¸ªçš„å†³ç­–è·¯å¾„ä½¿å…¶åŒºåˆ«äºâ€œé»‘ç®±â€æ¨¡å‹ï¼Œæ›´é€‚åˆé£Ÿå“å®‰å…¨ç­‰é«˜é£é™©åº”ç”¨ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **åˆæˆæ•°æ®é›†ï¼ˆSynthetic Dataï¼‰**ï¼š  
  åŸºäºçœŸå®ç¡¬ä»¶è§‚å¯Ÿåˆ°çš„åˆ†å¸ƒï¼Œä½¿ç”¨æ­£æ€åˆ†å¸ƒç”Ÿæˆ1000ä¸ªæ ·æœ¬ã€‚å„å˜é‡å‚æ•°å¦‚ä¸‹ï¼š
  - æ¸©åº¦ï¼ˆTemperatureï¼‰ï¼šå‡å€¼25Â°Cï¼Œæ ‡å‡†å·®5Â°C
  - æ¹¿åº¦ï¼ˆHumidityï¼‰ï¼šå‡å€¼60%ï¼Œæ ‡å‡†å·®10%
  - åœŸå£¤æ°´åˆ†ï¼ˆMoistureï¼‰ï¼šå‡å€¼200ï¼Œæ ‡å‡†å·®50
  - MQ3ä¼ æ„Ÿå™¨ï¼ˆé…’ç²¾ï¼‰ï¼šå‡å€¼150ï¼Œæ ‡å‡†å·®30
  - MQ4ä¼ æ„Ÿå™¨ï¼ˆç”²çƒ·ï¼‰ï¼šå‡å€¼250ï¼Œæ ‡å‡†å·®30
  - æ·»åŠ å‡å€¼ä¸º0ã€æ ‡å‡†å·®ä¸º5çš„é«˜æ–¯å™ªå£°ä»¥æ¨¡æ‹Ÿç°å®ä¸–ç•Œå˜å¼‚æ€§ã€‚

- **çœŸå®ç¡¬ä»¶æ•°æ®é›†ï¼ˆReal-Time Hardware Dataï¼‰**ï¼š  
  ä½¿ç”¨ **Arduino** å¾®æ§åˆ¶å™¨è¿æ¥ **DHT11**ï¼ˆæ¸©æ¹¿åº¦ï¼‰ã€**MQ3**ï¼ˆé…’ç²¾ï¼‰ã€**MQ4**ï¼ˆç”²çƒ·ï¼‰å’ŒåœŸå£¤æ°´åˆ†ä¼ æ„Ÿå™¨ï¼Œåœ¨çœŸå®ç¯å¢ƒä¸­é‡‡é›†æ•°æ®ã€‚ç»Ÿè®¡æ•°æ®æ˜¾ç¤ºï¼Œå¹³å‡æ¸©åº¦ä¸º28.29Â°Cï¼Œæ¹¿åº¦ä¸º91.87%ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **å®éªŒæµç¨‹**ï¼š
  - åˆæˆæ•°æ®å®éªŒè¿è¡Œ **1000ä¸ªepisode**ã€‚
  - çœŸå®ç¡¬ä»¶æ•°æ®å®éªŒè¿è¡Œ **100ä¸ªepisode**ï¼ˆå› èµ„æºé™åˆ¶ï¼‰ã€‚
- **çŠ¶æ€ç©ºé—´ï¼ˆState Spaceï¼‰**ï¼š `[Temperature, Humidity, Moisture, MQ3, MQ4]`ï¼Œå…±5ç»´ï¼Œå½’ä¸€åŒ–è‡³[0,1]ã€‚
- **åŠ¨ä½œç©ºé—´ï¼ˆAction Spaceï¼‰**ï¼šç¦»æ•£åŠ¨ä½œï¼Œå¯¹åº”ä¸åŒå¹²é¢„çº§åˆ«ï¼š
  - 0: ç»§ç»­å¸¸è§„å­˜å‚¨
  - 1: å‘å‡ºä½çº§è­¦æŠ¥
  - 2: è°ƒæ•´å­˜å‚¨å‚æ•°
  - 3: å‘å‡ºç´§æ€¥è­¦æŠ¥
- **å¥–åŠ±å‡½æ•°ï¼ˆReward Functionï¼‰**ï¼šåŒ¹é…çœŸå®è…è´¥ç­‰çº§å¾—+1ï¼Œå¦åˆ™å¾—-1ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Spoilage Accuracy**ï¼šè…è´¥ç­‰çº§é¢„æµ‹æ­£ç¡®çš„ç™¾åˆ†æ¯”ã€‚
  - **Reward-to-Step Ratio**ï¼šå¹³å‡æ¯æ­¥è·å¾—çš„å¥–åŠ±ï¼Œè¡¡é‡å†³ç­–æ•ˆç‡ã€‚
  - **Loss Decrease Rate**ï¼šæŸå¤±å‡½æ•°éšè®­ç»ƒçš„ä¸‹é™é€Ÿç‡ï¼Œåæ˜ æ”¶æ•›ç¨³å®šæ€§ã€‚
  - **Exploration Rate Decay**ï¼šÎµ-greedyç­–ç•¥ä¸­æ¢ç´¢ç‡çš„è¡°å‡é€Ÿç‡ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
ä¸ä»¥ä¸‹äº”ç§æ–¹æ³•è¿›è¡Œäº†å¯¹æ¯”ï¼š
1. **LSTM+RNN (Proposed)**ï¼šæœ¬æ–‡æå‡ºçš„æ··åˆæ¨¡å‹ã€‚
2. **ANN**ï¼šåŸºç¡€äººå·¥ç¥ç»ç½‘ç»œã€‚
3. **LSTM**ï¼šä»…ä½¿ç”¨LSTMå±‚ã€‚
4. **RNN**ï¼šä»…ä½¿ç”¨RNNå±‚ã€‚
5. **Monte Carlo**ï¼šåŸºäºéšæœºé‡‡æ ·çš„æ–¹æ³•ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªTable 2 & Table 3ï¼‰

#### åœ¨åˆæˆæ•°æ®ä¸Šçš„è¡¨ç°ï¼ˆ1000 episodesï¼‰
| Agent Framework | Spoilage Accuracy | Reward-to-Step Ratio | Loss Decrease Rate |
|-----------------|-------------------|----------------------|--------------------|
| **LSTM+RNN (Proposed)** | **0.82** | **0.63** | -0.00042 |
| ANN | 0.74 | 0.49 | 0.42156 |
| LSTM | 0.77 | 0.54 | 0.00143 |
| RNN | 0.75 | 0.51 | 0.00089 |
| Monte Carlo | 0.00 | 0.70 | N/A |

#### åœ¨çœŸå®ç¡¬ä»¶æ•°æ®ä¸Šçš„è¡¨ç°ï¼ˆ100 episodesï¼‰
| Agent Framework | Spoilage Accuracy | Reward-to-Step Ratio | Loss Decrease Rate |
|-----------------|-------------------|----------------------|--------------------|
| **LSTM+RNN (Proposed)** | **0.59** | **0.17** | 0.09148 |
| LSTM | 0.58 | 0.16 | 0.12168 |
| ANN | 0.55 | 0.11 | -6.27726 |
| RNN | 0.42 | -0.17 | 26.60358 |
| Monte Carlo | 0.41 | -0.18 | N/A |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **å‡†ç¡®æ€§æœ€é«˜**ï¼šåœ¨åˆæˆå’ŒçœŸå®æ•°æ®ä¸Šï¼Œ**LSTM+RNN**å‡å–å¾—äº†æœ€é«˜çš„`Spoilage Accuracy`ï¼ˆ0.82å’Œ0.59ï¼‰ï¼Œè¯æ˜å…¶å¼ºå¤§çš„é¢„æµ‹èƒ½åŠ›ã€‚
- **å†³ç­–æœ€é«˜æ•ˆ**ï¼šåœ¨åˆæˆæ•°æ®ä¸Šï¼Œå…¶`Reward-to-Step Ratio`ï¼ˆ0.63ï¼‰ä»…æ¬¡äºMonte Carloï¼ˆ0.70ï¼‰ï¼Œä½†Monte Carloçš„å‡†ç¡®ç‡ä¸º0ï¼Œè¯´æ˜å…¶å¥–åŠ±æ˜¯æ— æ•ˆçš„ã€‚åœ¨çœŸå®æ•°æ®ä¸Šï¼ŒLSTM+RNNçš„æ¯”ç‡ï¼ˆ0.17ï¼‰è¿œé«˜äºå…¶ä»–æœ‰æ•ˆæ¨¡å‹ã€‚
- **å­¦ä¹ æœ€ç¨³å®š**ï¼šåœ¨çœŸå®æ•°æ®ä¸Šï¼ŒLSTM+RNNçš„`Loss Decrease Rate`ï¼ˆ0.09148ï¼‰ä¸ºæ­£å€¼ä¸”é€‚ä¸­ï¼Œè¡¨æ˜å­¦ä¹ è¿‡ç¨‹ç¨³å®šæ”¶æ•›ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒANNå’ŒRNNçš„è´Ÿå€¼æˆ–æé«˜å€¼è¡¨æ˜å­¦ä¹ ä¸ç¨³å®šæˆ–å‘æ•£ã€‚

### æ¶ˆèå®éªŒç»“æœ
è™½ç„¶æœªæ˜ç¡®æ ‡æ³¨ä¸ºæ¶ˆèå®éªŒï¼Œä½†é€šè¿‡æ¯”è¾ƒå•ä¸€æ¨¡å‹ï¼ˆLSTM, RNNï¼‰ä¸æ··åˆæ¨¡å‹ï¼ˆLSTM+RNNï¼‰çš„æ€§èƒ½ï¼Œå¯ä»¥å¾—å‡ºï¼š
- **LSTMçš„é‡è¦æ€§**ï¼šLSTMæ¨¡å‹çš„è¡¨ç°ï¼ˆAccuracy 0.77/0.58ï¼‰è¿œè¶…RNNï¼ˆ0.75/0.42ï¼‰ï¼Œè¯´æ˜æ•æ‰é•¿æœŸä¾èµ–å¯¹è…è´¥é¢„æµ‹è‡³å…³é‡è¦ã€‚
- **æ··åˆæ¶æ„çš„æœ‰æ•ˆæ€§**ï¼šLSTM+RNNåœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºå•ç‹¬çš„LSTMæˆ–RNNï¼Œè¯æ˜äº†ç»“åˆä¸¤è€…ä¼˜åŠ¿çš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ··åˆLSTM+RNNæ¶æ„åœ¨è…è´¥é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°æœ€ä¼˜**ï¼šå®ƒèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰ç¯å¢ƒå‚æ•°çš„å¤æ‚æ—¶åºæ¨¡å¼ï¼Œå®ç°æœ€é«˜ç²¾åº¦å’Œæœ€é«˜æ•ˆçš„å†³ç­–ã€‚
2. **å¯è§£é‡Šæ€§è®¾è®¡è‡³å…³é‡è¦**ï¼šåŸºäºè§„åˆ™çš„ç¯å¢ƒä¸ºå¼ºåŒ–å­¦ä¹ æä¾›äº†æ¸…æ™°çš„è¯­ä¹‰æŒ‡å¯¼ï¼Œä½¿æ¨¡å‹å†³ç­–å˜å¾—é€æ˜å’Œå¯å®¡è®¡ï¼Œè¿™å¯¹äºé£Ÿå“å®‰å…¨åº”ç”¨ä¸å¯æˆ–ç¼ºã€‚
3. **æ–¹æ³•å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œå®ç”¨æ€§**ï¼šåœ¨åˆæˆæ•°æ®å’ŒçœŸå®ç¡¬ä»¶æ•°æ®ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œè¯æ˜äº†ä»ä»¿çœŸåˆ°ç°å®ï¼ˆSimulation-to-Realityï¼‰çš„å¯è¡Œæ€§ï¼Œå…·å¤‡å®é™…éƒ¨ç½²æ½œåŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **åˆæˆæ•°æ®çš„ä»£è¡¨æ€§æœ‰é™**ï¼šå°½ç®¡åŠªåŠ›æ¨¡æ‹ŸçœŸå®åœºæ™¯ï¼Œä½†å¯èƒ½æ— æ³•è¦†ç›–æ‰€æœ‰æç«¯æˆ–ç½•è§æƒ…å†µï¼Œå½±å“æ¨¡å‹åœ¨æœªçŸ¥ç¯å¢ƒä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
2. **ä¼ æ„Ÿå™¨æ¼‚ç§»é—®é¢˜**ï¼šä¼ æ„Ÿå™¨ç²¾åº¦ä¼šéšæ—¶é—´é€€åŒ–ï¼Œéœ€è¦æŒç»­ç›‘æ§å’Œé‡æ–°æ ¡å‡†ã€‚
3. **è®¡ç®—å¤æ‚åº¦è¾ƒé«˜**ï¼šæ··åˆç¥ç»ç½‘ç»œæ¶æ„å¢åŠ äº†è®¡ç®—è´Ÿæ‹…ï¼Œå¯¹è¾¹ç¼˜è®¾å¤‡çš„èµ„æºè¦æ±‚è¾ƒé«˜ã€‚
4. **ä¾èµ–é«˜è´¨é‡è®­ç»ƒæ•°æ®**ï¼šæ¨¡å‹æ€§èƒ½é«˜åº¦ä¾èµ–äºè®­ç»ƒæ•°æ®çš„è´¨é‡ï¼Œæ•°æ®ä¸­çš„åå·®ä¼šå½±å“æœ€ç»ˆå†³ç­–ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ¢ç´¢æ··åˆå¼ºåŒ–å­¦ä¹ æ¶æ„**ï¼šç»“åˆModel-based RLæˆ–Imitation Learningï¼Œæé«˜æ ·æœ¬æ•ˆç‡ã€‚
2. **å¼•å…¥ä¸»åŠ¨å­¦ä¹ ï¼ˆActive Learningï¼‰**ï¼šåŠ¨æ€è°ƒæ•´æ•°æ®é‡‡é›†ç­–ç•¥ï¼Œä¼˜å…ˆè·å–ä¿¡æ¯é‡å¤§çš„æ•°æ®ç‚¹ã€‚
3. **åº”ç”¨è¿ç§»å­¦ä¹ ï¼ˆTransfer Learningï¼‰**ï¼šå°†åœ¨ä¸€ç§é£Ÿç‰©ä¸Šè®­ç»ƒçš„æ¨¡å‹è¿ç§»åˆ°å…¶ä»–é£Ÿç‰©ç±»å‹ï¼Œå‡å°‘æ–°åœºæ™¯ä¸‹çš„è®­ç»ƒæˆæœ¬ã€‚
4. **å‘å±•åˆ†å±‚å¼ºåŒ–å­¦ä¹ ï¼ˆHierarchical RLï¼‰**ï¼šåˆ†è§£ä»»åŠ¡ï¼Œå®ç°é•¿æœŸè§„åˆ’ä¸çŸ­æœŸæ§åˆ¶çš„ç»“åˆã€‚
5. **å¤šç›®æ ‡ä¼˜åŒ–ï¼ˆMulti-objective RLï¼‰**ï¼šåŒæ—¶ä¼˜åŒ–è…è´¥æ§åˆ¶ã€èƒ½è€—ã€æˆæœ¬ç­‰å¤šä¸ªç›®æ ‡ã€‚
6. **å¢å¼ºåœ¨çº¿å­¦ä¹ ä¸è‡ªé€‚åº”æ§åˆ¶**ï¼šä½¿ç³»ç»Ÿèƒ½æŒç»­é€‚åº”ä¸æ–­å˜åŒ–çš„ç¯å¢ƒã€‚
7. **æå‡é²æ£’æ€§ä¸ä¸ç¡®å®šæ€§é‡åŒ–**ï¼šæ›´å¥½åœ°å¤„ç†ä¼ æ„Ÿå™¨å™ªå£°å’Œæ¨¡å‹é¢„æµ‹çš„ä¸ç¡®å®šæ€§ã€‚

</details>

---

### 15. [The Best of Both Worlds: Hybridizing Neural Operators and Solvers for Stable Long-Horizon Inference](https://arxiv.org/abs/2512.19643)

**Authors**: Rajyasri Roy, Dibyajyoti Nayak, Somdatta Goswami  
**Category**: cs.LG  
**Published**: 2025-12-23  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.19643v1  

#### Abstract
Numerical simulation of time-dependent partial differential equations (PDEs) is central to scientific and engineering applications, but high-fidelity solvers are often prohibitively expensive for long-horizon or time-critical settings. Neural operator (NO) surrogates offer fast inference across para...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šThe Best of Both Worlds: Hybridizing Neural Operators and Solvers for Stable Long-Horizon Inference

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿé«˜ä¿çœŸæ•°å€¼æ±‚è§£å™¨ï¼ˆnumerical solversï¼‰è™½ç„¶ç²¾åº¦é«˜ã€ç‰©ç†ä¸€è‡´æ€§å¥½ï¼Œä½†è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œéš¾ä»¥æ»¡è¶³**é•¿æ—¶åŸŸï¼ˆlong-horizonï¼‰ã€å¤šæŸ¥è¯¢æˆ–å¤šä»»åŠ¡åœºæ™¯**ä¸‹çš„å®æ—¶æ€§éœ€æ±‚ã€‚è€ŒåŸºäºå­¦ä¹ çš„ç¥ç»ç®—å­ï¼ˆNeural Operators, NOsï¼‰è™½èƒ½å®ç°å¿«é€Ÿæ¨ç†ï¼Œä½†åœ¨è‡ªå›å½’ï¼ˆautoregressiveï¼‰æ—¶é—´æ­¥è¿›ä¸­å®¹æ˜“å› å±€éƒ¨è¯¯å·®ç´¯ç§¯å¯¼è‡´**é•¿æœŸé¢„æµ‹ä¸ç¨³å®šã€è¯¯å·®çˆ†ç‚¸ã€ç‰©ç†å¤±çœŸ**ã€‚

æ›´ä¸¥é‡çš„æ˜¯ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸åªæŠ¥å‘Š**é›†åˆå¹³å‡è¯¯å·®**ï¼ˆå¦‚å¹³å‡ç›¸å¯¹L2è¯¯å·®ï¼‰ï¼Œæ— æ³•ä¿è¯å•ä¸ªå…³é”®ä»»åŠ¡å®ä¾‹çš„å¯é æ€§ã€‚è¿™åœ¨å·¥ç¨‹æˆ–å®‰å…¨æ”¸å…³åº”ç”¨ä¸­æ˜¯ä¸å¯æ¥å—çš„ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šANCHOR
ä½œè€…æå‡º **ANCHOR**ï¼ˆAdaptive Numerical Correction for High-fidelity Operator Rolloutsï¼‰ï¼Œä¸€ç§**åœ¨çº¿ã€å®ä¾‹æ„ŸçŸ¥ã€è¯¯å·®å¯æ§çš„æ··åˆæ¨ç†æ¡†æ¶**ï¼Œç”¨äºç¨³å®šéçº¿æ€§ã€æ—¶å˜PDEçš„é•¿æ—¶åŸŸé¢„æµ‹ã€‚

#### æ ¸å¿ƒæ€æƒ³
- å°†é¢„è®­ç»ƒçš„ç¥ç»ç®—å­ï¼ˆå¦‚TI-DeepONetï¼‰ä½œä¸ºä¸»æ¨ç†å¼•æ“ï¼Œæä¾›é«˜é€Ÿåº¦ï¼›
- è€¦åˆä¸€ä¸ªç»å…¸é«˜ä¿çœŸæ•°å€¼æ±‚è§£å™¨ï¼ˆå¦‚FDMï¼‰ï¼Œä½œä¸ºâ€œçº é”™æ¨¡å—â€ï¼›
- å¼•å…¥ä¸€ä¸ª**åŸºäºPDEæ®‹å·®çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆEMAï¼‰è¯¯å·®ä¼°è®¡å™¨**ï¼Œæ— éœ€çœŸå®è§£å³å¯åœ¨çº¿ç›‘æµ‹è¯¯å·®å¢é•¿ï¼›
- å½“ä¼°è®¡è¯¯å·®è¶…è¿‡åŠ¨æ€é˜ˆå€¼æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°æ•°å€¼æ±‚è§£å™¨è¿›è¡ŒçŸ­æœŸä¿®æ­£ï¼Œä¹‹åå†åˆ‡å›ç¥ç»ç®—å­ã€‚

### åˆ›æ–°ç‚¹
1. **é¦–æ¬¡å®ç°â€œå®ä¾‹æ„ŸçŸ¥â€çš„è¯¯å·®æ§åˆ¶æœºåˆ¶**  
   ä¸ä¾èµ–å…¨å±€å¹³å‡æŒ‡æ ‡ï¼Œè€Œæ˜¯ä¸ºæ¯ä¸ªç‹¬ç«‹ä»¿çœŸè½¨è¿¹æä¾›è¯¯å·®ç›‘æ§ä¸å¹²é¢„èƒ½åŠ›ã€‚

2. **æå‡ºç‰©ç†ä¿¡æ¯é©±åŠ¨çš„EMAè¯¯å·®ä¼°è®¡å™¨**  
   åˆ©ç”¨å½’ä¸€åŒ–çš„PDEæ®‹å·®æ„å»ºEMAåºåˆ—ï¼Œå®éªŒè¯æ˜å…¶ä¸çœŸå®ç›¸å¯¹L2è¯¯å·®é«˜åº¦ç›¸å…³ï¼ˆPearsonç›¸å…³ç³»æ•° > 0.98ï¼‰ï¼Œå¯åœ¨æ— ground truthæƒ…å†µä¸‹å¯é é¢„è­¦ã€‚

3. **è®¾è®¡è‡ªé€‚åº”è¡°å‡é˜ˆå€¼ç­–ç•¥ï¼ˆadaptive thresholdingï¼‰**  
   é’ˆå¯¹è€—æ•£ç³»ç»Ÿï¼ˆdissipative systemsï¼‰ä¸­è§£å¹…å€¼éšæ—¶é—´è¡°å‡çš„ç‰¹ç‚¹ï¼Œä½¿è¯¯å·®é˜ˆå€¼ä¹Ÿç›¸åº”è¡°å‡ï¼Œé¿å…åæœŸçµæ•åº¦ä¸‹é™ã€‚

4. **æ¨¡å‹æ— å…³ã€æ±‚è§£å™¨æ— å…³çš„é€šç”¨æ¡†æ¶**  
   å¯é€‚é…ä»»æ„æ”¯æŒè‡ªå›å½’æ¨ç†çš„NOï¼ˆå¦‚FNOã€DeepONetç­‰ï¼‰å’Œä»»æ„é«˜ä¿çœŸæ±‚è§£å™¨ï¼ˆFEMã€FDMã€è°±æ–¹æ³•ç­‰ï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³• | ANCHOR |
|------|--------|-------|
| é•¿æœŸç¨³å®šæ€§ | æ˜“å‡ºç°è¯¯å·®ç´¯ç§¯ã€å‘æ•£ | é€šè¿‡é€‰æ‹©æ€§è°ƒç”¨æ±‚è§£å™¨æœ‰æ•ˆæŠ‘åˆ¶è¯¯å·®å¢é•¿ |
| å®ä¾‹çº§å¯é æ€§ | ä»…æŠ¥å‘Šå¹³å‡æ€§èƒ½ï¼Œä¸ªä½“é£é™©æœªçŸ¥ | åœ¨çº¿ç›‘æ§æ¯æ¡è½¨è¿¹ï¼Œç¡®ä¿ä¸ªä½“å¯æ§ |
| è‡ªé€‚åº”æ€§ | å›ºå®šé—´éš”è°ƒç”¨æ±‚è§£å™¨æˆ–å›ºå®šé˜ˆå€¼ | åŠ¨æ€ã€æ•°æ®é©±åŠ¨åœ°å†³å®šä½•æ—¶å¹²é¢„ |
| æ•ˆç‡-ç²¾åº¦å¹³è¡¡ | å¾€å¾€ç‰ºç‰²ä¸€æ–¹æ¢å–å¦ä¸€æ–¹ | å…¼é¡¾é€Ÿåº¦ï¼ˆâ‰ˆNOï¼‰ä¸ç²¾åº¦/é²æ£’æ€§ï¼ˆâ‰ˆsolverï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„PDEæ•°æ®é›†ï¼ˆå…±4ä¸ªå…¸å‹æ–¹ç¨‹ï¼‰
| PDEåç§° | ç»´åº¦ | ç±»å‹ | ç‰¹ç‚¹ |
|--------|-----|------|------|
| 1D Burgersâ€™ | 1D+time | éçº¿æ€§å¯¹æµæ‰©æ•£ | å­˜åœ¨æ¿€æ³¢ï¼Œæ˜“äº§ç”Ÿè¯¯å·®ç´¯ç§¯ |
| 2D Burgersâ€™ | 2D+time | åŒä¸Š | æ›´é«˜ç»´ï¼ŒæŒ‘æˆ˜æ›´å¤§ |
| 2D Allen-Cahn | 2D+time | éçº¿æ€§ååº”æ‰©æ•£ | æ¶‰åŠç›¸åœºæ¼”åŒ–ï¼Œç•Œé¢é”åˆ© |
| 3D Heat Conduction | 3D+time | çº¿æ€§æŠ›ç‰©å‹ | å¤æ‚å‡ ä½•ï¼ˆLå½¢åŸŸï¼‰ï¼ŒçœŸå®è¾¹ç•Œæ¡ä»¶ |

æ‰€æœ‰é—®é¢˜å‡é‡‡ç”¨**å¤–æ¨è®¾ç½®**ï¼ˆextrapolation regimeï¼‰ï¼šè®­ç»ƒæ—¶é—´åŒºé—´ä¸º $[0, t_{\text{interp}}]$ï¼Œæµ‹è¯•/æ¨ç†è‡³ $[t_{\text{interp}}, T]$ï¼Œè€ƒéªŒæ³›åŒ–èƒ½åŠ›ã€‚

### å®éªŒè®¾ç½®
- **ä¸»ç¥ç»ç®—å­**ï¼šTI-DeepONetï¼ˆTime-Integrator Deep Operator Networkï¼‰ï¼Œå› å…¶æœ¬èº«å…·å¤‡ä¸€å®šæŠ—è¯¯å·®ç´¯ç§¯èƒ½åŠ›ã€‚
- **é«˜ä¿çœŸæ±‚è§£å™¨**ï¼šæœ‰é™å·®åˆ†æ³•ï¼ˆFDMï¼‰æˆ–ä¼ªè°±æ³•ï¼ˆpseudospectralï¼‰ï¼Œè§†å…·ä½“PDEè€Œå®šã€‚
- **è€¦åˆæ–¹å¼**ï¼šANCHORä»¥å›ºå®šæ­¥æ•°ï¼ˆå¦‚10æ­¥ï¼‰è°ƒç”¨æ±‚è§£å™¨è¿›è¡Œçº æ­£ï¼Œéšåäº¤è¿˜æ§åˆ¶æƒç»™TI-DeepONetã€‚
- **è¯¯å·®ä¼°è®¡å™¨å‚æ•°**ï¼š
  - EMAå¹³æ»‘ç³»æ•° $\alpha \in [0.01, 0.1]$
  - è‡ªé€‚åº”é˜ˆå€¼è¡°å‡é€Ÿç‡ $\gamma \in [2,3]$

### è¯„ä¼°æŒ‡æ ‡
1. **ç›¸å¯¹L2è¯¯å·®**ï¼ˆRelative L2 Errorï¼‰ï¼š
   $$
   e_{L2} = \frac{\|u_{\text{truth}} - u_{\text{pred}}\|_2}{\|u_{\text{truth}}\|_2}
   $$
2. **EMAè¯¯å·®ä¼°è®¡å™¨ä¸çœŸå®è¯¯å·®çš„ç›¸å…³æ€§**ï¼ˆPearson Correlation Coefficient, $p_{\text{corr}}$ï¼‰
3. **è®¡ç®—è€—æ—¶å¯¹æ¯”**ï¼ˆWall-clock timeï¼‰
4. **è¯¯å·®åˆ†å¸ƒå¯è§†åŒ–**ï¼ˆspatiotemporal error mapsï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| AR-DONï¼ˆAutoregressive DeepONetï¼‰ | æ ‡å‡†è‡ªå›å½’DeepONetï¼Œæ— é›†æˆæ—¶é—´ç§¯åˆ†ç»“æ„ |
| TI-DONï¼ˆTI-DeepONetï¼‰ | æ”¹è¿›ç‰ˆNOï¼ŒåµŒå…¥æ•°å€¼ç§¯åˆ†æ¨¡å—ï¼Œæå‡é•¿æœŸç¨³å®šæ€§ |
| NS-onlyï¼ˆNumerical Solver Onlyï¼‰ | çº¯é«˜ä¿çœŸæ±‚è§£å™¨ï¼Œä½œä¸ºç²¾åº¦åŸºå‡† |
| ANCHORï¼ˆOursï¼‰ | æœ¬æ–‡æå‡ºçš„æ··åˆæ¡†æ¶ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| PDE | æ–¹æ³• | å¹³å‡ç›¸å¯¹L2è¯¯å·®ï¼ˆæµ‹è¯•é›†ï¼‰ | è®¡ç®—æ—¶é—´ï¼ˆç§’ï¼‰ | é€Ÿåº¦æå‡ vs Solver |
|------|--------|--------------------------|----------------|--------------------|
| 1D Burgersâ€™ | TI-DON | 1.79% | ~0.06 | â‰ˆ2.5Ã— |
| | ANCHOR | <5%ï¼ˆç¨³å®šä¸Šé™ï¼‰ | ~0.2 | æ— æ˜¾è‘—åŠ é€Ÿï¼ˆä½ç»´ï¼‰ |
| 2D Burgersâ€™ | TI-DON | 12.99% | ~0.14 | â‰ˆ56Ã— |
| | ANCHOR | æ˜¾è‘—ä½äºTI-DON | ~4.5 | â‰ˆ1.7Ã— |
| 2D Allen-Cahn | TI-DON | 16.16% | ~0.075 | â‰ˆ43Ã— |
| | ANCHOR | æå¤§é™ä½ | ~1.0 | â‰ˆ3Ã—ï¼ˆ75%èŠ‚çœï¼‰ |
| 3D Heat | TI-DON | 6.55% | ~0.18 | â‰ˆ15Ã— |
| | ANCHOR | æœ‰æ•ˆå‹åˆ¶å¢é•¿ | ~1.0 | â‰ˆ2Ã—ï¼ˆ50%èŠ‚çœï¼‰ |

> æ³¨ï¼šå®Œæ•´ç»“æœè§åŸæ–‡Table 1 & Table 2ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **è¯¯å·®æ§åˆ¶æ–¹é¢**ï¼š
  - AR-DONï¼šè¯¯å·®å‘ˆæŒ‡æ•°å¢é•¿ï¼Œå¾ˆå¿«å¤±æ•ˆã€‚
  - TI-DONï¼šæ¯”AR-DONæ˜¾è‘—æ”¹å–„ï¼Œä½†ä»**æœªå®Œå…¨çº¦æŸè¯¯å·®å¢é•¿**ã€‚
  - ANCHORï¼šæˆåŠŸå°†è¯¯å·®å¢é•¿â€œé”¯é½¿åŒ–â€å¹¶é™åˆ¶åœ¨åˆç†èŒƒå›´å†…ï¼Œé¦–æ¬¡å®ç°**æœ‰ç•Œè¯¯å·®é•¿æ—¶é¢„æµ‹**ã€‚

- **è¯¯å·®ä¼°è®¡æœ‰æ•ˆæ€§**ï¼š
  - æ‰€æœ‰å››ä¸ªPDEä¸Šï¼ŒEMAè¯¯å·®ä¼°è®¡å™¨ä¸çœŸå®L2è¯¯å·®çš„**Pearsonç›¸å…³ç³»æ•°å‡ > 0.98**ï¼ˆæœ€é«˜è¾¾0.994ï¼‰ï¼Œè¯æ˜å…¶å¯ä½œä¸ºå¯é çš„ä»£ç†æŒ‡æ ‡ã€‚
  - å›¾4æ˜¾ç¤ºï¼Œæ¯å½“æ•°å€¼æ±‚è§£å™¨è¢«æ¿€æ´»ï¼Œè¯¯å·®ç«‹å³ä¸‹é™ï¼ŒéªŒè¯äº†â€œçº æ­£â€æ•ˆæœã€‚

- **æ•ˆç‡è¡¨ç°**ï¼š
  - åœ¨é«˜ç»´é—®é¢˜ï¼ˆ2DåŠä»¥ä¸Šï¼‰ä¸­ï¼ŒANCHORç›¸æ¯”çº¯æ±‚è§£å™¨ä»ä¿æŒæ˜¾è‘—ä¼˜åŠ¿ï¼š
    - 2D Burgersâ€™ï¼šæé€Ÿçº¦30%
    - 2D Allen-Cahnï¼šæé€Ÿçº¦75%
    - 3D Heatï¼šæé€Ÿçº¦50%

### æ¶ˆèå®éªŒä¸åˆ†æï¼ˆéšå«åœ¨æ–‡ä¸­ï¼‰
å°½ç®¡æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»¥ä¸‹å¯¹æ¯”æ„æˆäº‹å®ä¸Šçš„æ¶ˆèç ”ç©¶ï¼š
- **æ˜¯å¦ä½¿ç”¨EMAä¼°è®¡å™¨ï¼Ÿ** â†’ è‹¥ä¸ç”¨ï¼Œåˆ™æ— æ³•åŠ¨æ€åˆ¤æ–­ä½•æ—¶è°ƒç”¨æ±‚è§£å™¨ã€‚
- **æ˜¯å¦ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼ï¼Ÿ** â†’ å®éªŒè¡¨æ˜å›ºå®šé˜ˆå€¼åœ¨è€—æ•£ç³»ç»ŸåæœŸä¼šæ»åäºå®é™…è¯¯å·®å¢é•¿ã€‚
- **æ˜¯å¦å¼•å…¥æ±‚è§£å™¨åé¦ˆï¼Ÿ** â†’ å•ç‹¬TI-DONæ— æ³•å®Œå…¨éåˆ¶è¯¯å·®ï¼Œè¯´æ˜çº é”™æœºåˆ¶å¿…è¦ã€‚

æ­¤å¤–ï¼Œä½œè€…å¼ºè°ƒANCHORçš„æ€§èƒ½ä¸ä¾èµ–ç‰¹å®šNOæ¶æ„ï¼Œå±•ç¤ºäº†å…¶**æ¡†æ¶é€šç”¨æ€§**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **EMA-based error estimator æ˜¯æœ‰æ•ˆçš„ç‰©ç†æ„ŸçŸ¥ä»£ç†æŒ‡æ ‡**  
   å½’ä¸€åŒ–PDEæ®‹å·®çš„EMAåºåˆ—ä¸çœŸå®è¯¯å·®é«˜åº¦ç›¸å…³ï¼Œå¯ç”¨äºæ— ç›‘ç£åœ¨çº¿ç›‘æ§ã€‚

2. âœ… **ANCHOR èƒ½æœ‰æ•ˆç¨³å®šé•¿æ—¶åŸŸæ¨ç†**  
   é€šè¿‡é—´æ­‡æ€§è°ƒç”¨é«˜ä¿çœŸæ±‚è§£å™¨ï¼Œå®ç°äº†è¯¯å·®å¢é•¿çš„â€œè½¯æˆªæ–­â€ï¼Œè§£å†³äº†NOé•¿æœŸéƒ¨ç½²ä¸­çš„å¯é æ€§ç“¶é¢ˆã€‚

3. âœ… **æ•ˆç‡ä¸ç²¾åº¦å¯ä»¥å…¼å¾—**  
   åœ¨å¤æ‚é«˜ç»´ç³»ç»Ÿä¸­ï¼ŒANCHORåœ¨ä¿æŒæ¥è¿‘NOé€Ÿåº¦çš„åŒæ—¶ï¼Œè·å¾—äº†æ¥è¿‘ä¼ ç»Ÿæ±‚è§£å™¨çš„ç²¾åº¦ä¸ç¨³å®šæ€§ã€‚

4. âœ… **ä»·å€¼éšé—®é¢˜å¤æ‚åº¦ä¸Šå‡è€Œæ”¾å¤§**  
   å¯¹ç®€å•1Dé—®é¢˜åŠ é€Ÿæœ‰é™ï¼›ä½†å¯¹2D/3Då¤æ‚PDEï¼Œè®¡ç®—å¼€é”€èŠ‚çœå¯è¾¾2â€“3å€ï¼Œå‡¸æ˜¾å…¶å·¥ç¨‹å®ç”¨ä»·å€¼ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ç›®å‰ä»…é€‚ç”¨äºè€—æ•£ç³»ç»Ÿï¼ˆdissipative PDEsï¼‰**  
   è‡ªé€‚åº”é˜ˆå€¼è®¾è®¡åŸºäºè§£å¹…å€¼è¡°å‡çš„å‰æï¼Œå¯¹è‰²æ•£ï¼ˆdispersiveï¼‰æˆ–æ··æ²Œç³»ç»Ÿéœ€é‡æ–°å»ºæ¨¡ã€‚

2. **ä¾èµ–PDEæ®‹å·®è®¡ç®—**  
   éœ€è¦åœ¨æ¨ç†è¿‡ç¨‹ä¸­è¯„ä¼°æ®‹å·®ï¼Œå¸¦æ¥é¢å¤–è®¡ç®—è´Ÿæ‹…ï¼Œå°¤å…¶å½“NOè¾“å‡ºåˆ†è¾¨ç‡é«˜æ—¶ã€‚

3. **æ±‚è§£å™¨è°ƒç”¨ç­–ç•¥è¾ƒç®€å•**  
   å½“å‰ä¸ºå›ºå®šæ­¥æ•°çº æ­£ï¼Œæœªæ¥å¯æ¢ç´¢æ›´æ™ºèƒ½çš„â€œçº æ­£é•¿åº¦â€å†³ç­–æœºåˆ¶ã€‚

4. **æœªå¤„ç†ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUQï¼‰**  
   è™½ç„¶æå‡äº†å¯é æ€§ï¼Œä½†å°šæœªæä¾›æ¦‚ç‡æ„ä¹‰ä¸Šçš„ç½®ä¿¡åŒºé—´ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³å…¶ä»–ç±»å‹PDE**  
   å¦‚æ³¢åŠ¨æ–¹ç¨‹ï¼ˆhyperbolicï¼‰ã€Navier-Stokesç­‰éè€—æ•£æˆ–æ··æ²Œç³»ç»Ÿï¼Œéœ€è®¾è®¡æ–°çš„è¯¯å·®å…ˆéªŒä¸é˜ˆå€¼ç­–ç•¥ã€‚

2. **å¼€å‘æ›´é«˜æ•ˆçš„è¯¯å·®ä¼°è®¡å™¨**  
   æ¢ç´¢æ¢å¤å‹ä¼°è®¡å™¨ï¼ˆrecovery-based estimatorï¼‰æˆ–å…¶ä»–è½»é‡çº§ç‰©ç†ä¿¡æ¯ä»£ç†ï¼Œå‡å°‘æ®‹å·®è®¡ç®—å¼€é”€ã€‚

3. **å¼•å…¥å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–è°ƒåº¦ç­–ç•¥**  
   å­¦ä¹ æœ€ä¼˜çš„â€œä½•æ—¶è°ƒç”¨ã€è°ƒç”¨å¤šä¹…â€çš„ç­–ç•¥ï¼Œè¿›ä¸€æ­¥æå‡æ•ˆç‡ã€‚

4. **æ„å»ºç«¯åˆ°ç«¯å¯å¾®åˆ†æ··åˆæµæ°´çº¿**  
   ç»“åˆdifferentiable physicsæ€æƒ³ï¼Œå®ç°æ±‚è§£å™¨ä¸NOçš„è”åˆä¼˜åŒ–ã€‚

5. **åº”ç”¨äºæ•°å­—å­ªç”Ÿä¸å®æ—¶æ§åˆ¶ç³»ç»Ÿ**  
   å°†ANCHORåµŒå…¥å·¥ä¸šçº§ä»¿çœŸå¹³å°ï¼Œæ¨åŠ¨å…¶åœ¨èˆªç©ºèˆªå¤©ã€èƒ½æºã€æ°”å€™æ¨¡æ‹Ÿç­‰é¢†åŸŸçš„è½åœ°ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> ANCHORä¸æ˜¯è¦ç”¨ç¥ç»ç½‘ç»œå–ä»£æ•°å€¼æ–¹æ³•ï¼Œè€Œæ˜¯è®©ä¸¤è€…ååŒå·¥ä½œâ€”â€”**ç”¨å­¦ä¹ æ¢é€Ÿåº¦ï¼Œç”¨ç‰©ç†ä¿å¯é **ï¼Œä¸ºæ„å»ºå¯ä¿¡ã€é«˜æ•ˆã€å¯æ‰©å±•çš„ä¸‹ä¸€ä»£ç§‘å­¦è®¡ç®—å·¥å…·æä¾›äº†åŸåˆ™æ€§è·¯å¾„ã€‚

</details>

---

### 16. [FC-MIR: A Mobile Screen Awareness Framework for Intent-Aware Recommendation based on Frame-Compressed Multimodal Trajectory Reasoning](https://arxiv.org/abs/2512.19107)

**Authors**: Zhe Yang, Xiaoshuang Sheng, Zhengnan Zhang, Jidong Wu, Zexing Wang, Xin He, Shenghua Xu, Guanjing Xiong  
**Category**: cs.AI  
**Published**: 2025-12-23  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.19107v1  

#### Abstract
Identifying user intent from mobile UI operation trajectories is critical for advancing UI understanding and enabling task automation agents. While Multimodal Large Language Models (MLLMs) excel at video understanding tasks, their real-time mobile deployment is constrained by heavy computational cos...

---

### 17. [GenEnv: Difficulty-Aligned Co-Evolution Between LLM Agents and Environment Simulators](https://arxiv.org/abs/2512.19682)

**Authors**: Jiacheng Guo, Ling Yang, Peter Chen, Qixin Xiao, Yinjie Wang, Xinzhe Juan, Jiahao Qiu, Ke Shen, Mengdi Wang  
**Category**: cs.CL  
**Published**: 2025-12-23  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.19682v1  

#### Abstract
Training capable Large Language Model (LLM) agents is critically bottlenecked by the high cost and static nature of real-world interaction data. We address this by introducing GenEnv, a framework that establishes a difficulty-aligned co-evolutionary game between an agent and a scalable, generative e...

---

### 18. [Fast Online Digital Twinning on FPGA for Mission Critical Applications](https://arxiv.org/abs/2512.17942)

**Authors**: Bin Xu, Ayan Banerjee, Sandeep K. S. Gupta  
**Category**: cs.DC  
**Published**: 2025-12-23  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.17942v1  

#### Abstract
Digital twinning enables real-time simulation and predictive modeling by maintaining a continuously updated virtual representation of a physical system. In mission-critical applications, such as mid-air collision avoidance, these models must operate online with extremely low latency to ensure safety...

---

### 19. [Small Language Models as Compiler Experts: Auto-Parallelization for Heterogeneous Systems](https://arxiv.org/abs/2512.19250)

**Authors**: Prathamesh Devadiga  
**Category**: cs.LG  
**Published**: 2025-12-23  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.19250v1  

#### Abstract
Traditional auto-parallelizing compilers, reliant on rigid heuristics, struggle with the complexity of modern heterogeneous systems. This paper presents a comprehensive evaluation of small (approximately 1B parameter) language-model-driven compiler auto-parallelization. We evaluate three models: gem...

---

### 20. [Scalably Enhancing the Clinical Validity of a Task Benchmark with Physician Oversight](https://arxiv.org/abs/2512.19691)

**Authors**: Junze Ye, Daniel Tawfik, Alex J. Goodell, Nikhil V. Kotha, Mark K. Buyyounouski, Mohsen Bayati  
**Category**: cs.AI  
**Published**: 2025-12-23  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.19691v1  

#### Abstract
Automating the calculation of clinical risk scores offers a significant opportunity to reduce physician administrative burden and enhance patient care. The current standard for evaluating this capability is MedCalc-Bench, a large-scale dataset constructed using LLM-based feature extraction and rule-...

---

### 21. [Q-KVComm: Efficient Multi-Agent Communication Via Adaptive KV Cache Compression](https://arxiv.org/abs/2512.17914)

**Authors**: Boris Kriuk, Logic Ng  
**Category**: cs.CL  
**Published**: 2025-12-23  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.17914v1  

#### Abstract
Multi-agent Large Language Model (LLM) systems face a critical bottleneck: redundant transmission of contextual information between agents consumes excessive bandwidth and computational resources. Traditional approaches discard internal semantic representations and transmit raw text, forcing receivi...

---

### 22. [AWPO: Enhancing Tool-Use of Large Language Models through Explicit Integration of Reasoning Rewards](https://arxiv.org/abs/2512.19126)

**Authors**: Zihan Lin, Xiaohan Wang, Hexiong Yang, Jiajun Chai, Jie Cao, Guojun Yin, Wei Lin, Ran He  
**Category**: cs.CL  
**Published**: 2025-12-23  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.19126v1  

#### Abstract
While reinforcement learning (RL) shows promise in training tool-use large language models (LLMs) using verifiable outcome rewards, existing methods largely overlook the potential of explicit reasoning rewards to bolster reasoning and tool utilization. Furthermore, natively combining reasoning and o...

---

### 23. [LeJOT: An Intelligent Job Cost Orchestration Solution for Databricks Platform](https://arxiv.org/abs/2512.18266)

**Authors**: Lizhi Ma, Yi-Xiang Hu, Yuke Wang, Yifang Zhao, Yihui Ren, Jian-Xiang Liao, Feng Wu, Xiang-Yang Li  
**Category**: cs.LG  
**Published**: 2025-12-23  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.18266v1  

#### Abstract
With the rapid advancements in big data technologies, the Databricks platform has become a cornerstone for enterprises and research institutions, offering high computational efficiency and a robust ecosystem. However, managing the escalating operational costs associated with job execution remains a ...

---

### 24. [A Surrogate-Augmented Symbolic CFD-Driven Training Framework for Accelerating Multi-objective Physical Model Development](https://arxiv.org/abs/2512.19031)

**Authors**: Yuan Fang, Fabian Waschkowski, Maximilian Reissmann, Richard D. Sandberg, Takuo Oda, Koichi Tanimoto  
**Category**: cs.LG  
**Published**: 2025-12-23  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.19031v1  

#### Abstract
Computational Fluid Dynamics (CFD)-driven training combines machine learning (ML) with CFD solvers to develop physically consistent closure models with improved predictive accuracy. In the original framework, each ML-generated candidate model is embedded in a CFD solver and evaluated against referen...

---

### 25. [Binary Kernel Logistic Regression: a sparsity-inducing formulation and a convergent decomposition training algorithm](https://arxiv.org/abs/2512.19440)

**Authors**: Antonio Consolo, Andrea Manno, Edoardo Amaldi  
**Category**: cs.LG  
**Published**: 2025-12-23  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.19440v1  

#### Abstract
Kernel logistic regression (KLR) is a widely used supervised learning method for binary and multi-class classification, which provides estimates of the conditional probabilities of class membership for the data points. Unlike other kernel methods such as Support Vector Machines (SVMs), KLRs are gene...

---

### 26. [Deep Learning for Unrelated-Machines Scheduling: Handling Variable Dimensions](https://arxiv.org/abs/2512.19527)

**Authors**: Diego Hitzges, Guillaume Sagnol  
**Category**: cs.LG  
**Published**: 2025-12-23  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.19527v1  

#### Abstract
Deep learning has been effectively applied to many discrete optimization problems. However, learning-based scheduling on unrelated parallel machines remains particularly difficult to design. Not only do the numbers of jobs and machines vary, but each job-machine pair has a unique processing time, dy...

---

### 27. [ESearch-R1: Learning Cost-Aware MLLM Agents for Interactive Embodied Search via Reinforcement Learning](https://arxiv.org/abs/2512.18571)

**Authors**: Weijie Zhou, Xuangtang Xiong, Ye Tian, Lijun Yue, Xinyu Wu, Wei Li, Chaoyang Zhao, Honghui Dong, Ming Tang, Jinqiao Wang, Zhengyou Zhang  
**Category**: cs.AI  
**Published**: 2025-12-23  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.18571v1  

#### Abstract
Multimodal Large Language Models (MLLMs) have empowered embodied agents with remarkable capabilities in planning and reasoning. However, when facing ambiguous natural language instructions (e.g., "fetch the tool" in a cluttered room), current agents often fail to balance the high cost of physical ex...

---

### 28. [Multimodal Bayesian Network for Robust Assessment of Casualties in Autonomous Triage](https://arxiv.org/abs/2512.18908)

**Authors**: Szymon Rusiecki, Cecilia G. Morales, Kimberly Elenberg, Leonard Weiss, Artur Dubrawski  
**Category**: cs.AI  
**Published**: 2025-12-23  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.18908v1  

#### Abstract
Mass Casualty Incidents can overwhelm emergency medical systems and resulting delays or errors in the assessment of casualties can lead to preventable deaths. We present a decision support framework that fuses outputs from multiple computer vision models, estimating signs of severe hemorrhage, respi...

---

### 29. [Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design](https://arxiv.org/abs/2512.18682)

**Authors**: Yuchen Li, Handing Wang, Bing Xue, Mengjie Zhang, Yaochu Jin  
**Category**: cs.CL  
**Published**: 2025-12-23  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.18682v1  

#### Abstract
In the high-cost simulation-driven design domain, translating ambiguous design requirements into a mathematical optimization formulation is a bottleneck for optimizing product performance. This process is time-consuming and heavily reliant on expert knowledge. While large language models (LLMs) offe...

---

### 30. [Towards Guided Descent: Optimization Algorithms for Training Neural Networks At Scale](https://arxiv.org/abs/2512.18373)

**Authors**: Ansh Nagwekar  
**Category**: cs.LG  
**Published**: 2025-12-23  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.18373v1  

#### Abstract
Neural network optimization remains one of the most consequential yet poorly understood challenges in modern AI research, where improvements in training algorithms can lead to enhanced feature learning in foundation models, order-of-magnitude reductions in training time, and improved interpretabilit...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
