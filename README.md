# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-24 06:00:44 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge](https://arxiv.org/abs/2512.20276)

**Authors**: Yuntao Dai, Hang Gu, Teng Wang, Qianyu Cheng, Yifei Zheng, Zhiyong Qiu, Lei Gong, Wenqi Lou, Xuehai Zhou  
**Category**: cs.AI  
**Published**: 2025-12-24  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2512.20276v1  

#### Abstract
Vision-Language-Action (VLA) models have emerged as a unified paradigm for robotic perception and control, enabling emergent generalization and long-horizon task execution. However, their deployment in dynamic, real-world environments is severely hin dered by high inference latency. While smooth rob...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edgeã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

Vision-Language-Action (VLA) æ¨¡å‹åœ¨æœºå™¨äººæ„ŸçŸ¥ä¸æ§åˆ¶ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œé•¿ç¨‹ä»»åŠ¡æ‰§è¡Œæ½œåŠ›ï¼Œä½†å…¶**é«˜æ¨ç†å»¶è¿Ÿ**ä¸¥é‡é˜»ç¢äº†åœ¨åŠ¨æ€çœŸå®ç¯å¢ƒä¸­çš„éƒ¨ç½²ã€‚å½“å‰ä¸»æµ VLA æ¨¡å‹åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šä»…èƒ½å®ç° 3â€“5 FPS çš„æ¨ç†é€Ÿåº¦ï¼Œè¿œä½äºæœºå™¨äººå®æ—¶äº¤äº’æ‰€éœ€çš„ 20â€“30 Hz æ§åˆ¶é¢‘ç‡ã€‚

è¯¥å»¶è¿Ÿä¸»è¦æºäº LLM èƒŒéª¨çš„**è‡ªå›å½’è§£ç ï¼ˆautoregressive decodingï¼‰è¿‡ç¨‹**ï¼Œå…¶ä¸ºå†…å­˜å—é™ï¼ˆmemory-boundï¼‰æ“ä½œï¼Œç¡¬ä»¶åˆ©ç”¨ç‡ä½ã€‚ç°æœ‰ä¼˜åŒ–æ–¹æ³•å­˜åœ¨ä»¥ä¸‹ä¸è¶³ï¼š
- **é€šç”¨ LLM æ¨ç†å¼•æ“**ï¼ˆå¦‚ Continuous Batchingï¼‰é¢å‘å¤šç”¨æˆ·æœåŠ¡å™¨åœºæ™¯ï¼Œä¸é€‚ç”¨äºå•ç”¨æˆ·ã€ä½å»¶è¿Ÿçš„æœºå™¨äººæ§åˆ¶ã€‚
- **è¾¹ç¼˜ç«¯ä¼˜åŒ–**ï¼ˆå¦‚é‡åŒ–ã€è’¸é¦ï¼‰è™½å‡å°æ¨¡å‹è§„æ¨¡ï¼Œä½†æœªæ”¹å˜è§£ç é˜¶æ®µçš„ä¸²è¡Œç“¶é¢ˆã€‚
- **ç®—æ³•çº§ VLA åŠ é€Ÿ**ï¼ˆå¦‚å¹¶è¡Œè§£ç ã€æ‰©æ•£æ¨¡å‹ï¼‰å¸¸éœ€é‡æ–°è®­ç»ƒï¼Œå¯èƒ½ç‰ºç‰²ç²¾åº¦æˆ–å¼•å…¥åŠ¨ä½œä¸è¿ç»­æ€§ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **ActionFlow** â€”â€”ä¸€ç§ä¸“ä¸ºèµ„æºå—é™è¾¹ç¼˜å¹³å°è®¾è®¡çš„ç³»ç»Ÿçº§æ¨ç†æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### âœ… **Cross-Request Pipelining ç­–ç•¥**
- å°†å•ä¸ª VLA è¯·æ±‚å†…éƒ¨çš„ç”Ÿæˆè¿‡ç¨‹ï¼ˆä¸€æ¬¡ Prefill + å¤šæ¬¡ Decodeï¼‰è§†ä¸ºä¸€ä¸ªâ€œå¾®è¯·æ±‚æµæ°´çº¿â€ï¼ˆmicro-request pipelineï¼‰ã€‚
- åœ¨æ—¶é—´ç»´åº¦ä¸Šé‡å å¤šä¸ªè¿ç»­è¯·æ±‚çš„è®¡ç®—ï¼šå°†å½“å‰å¸§çš„ **Prefill é˜¶æ®µ**ï¼ˆè®¡ç®—å¯†é›†å‹ï¼‰ä¸å‰å‡ å¸§çš„ **Decode é˜¶æ®µ**ï¼ˆå†…å­˜å¯†é›†å‹ï¼‰è¿›è¡Œè·¨è¯·æ±‚æ‰¹å¤„ç†ï¼ˆbatchingï¼‰ï¼Œå½¢æˆå®æµæ°´çº¿ï¼ˆmacro-pipelineï¼‰ã€‚
- å®ç°äº†**å•ç”¨æˆ·åœºæ™¯ä¸‹çš„å†…éƒ¨æ‰¹å¤„ç†æœºä¼šæŒ–æ˜**ï¼Œæ˜¾è‘—æå‡ GPU åˆ©ç”¨ç‡ã€‚

#### âœ… **Cross-Request State Packed Forward ç®—å­**
- è®¾è®¡äº†ä¸€ä¸ªèåˆç®—å­ï¼Œå°†å¤šä¸ªç‹¬ç«‹çš„ Decode é˜¶æ®µä¸­çš„å°è§„æ¨¡çŸ©é˜µ-å‘é‡ä¹˜æ³•ï¼ˆGEMVï¼‰èšåˆä¸ºä¸€ä¸ªå¤§è§„æ¨¡çŸ©é˜µ-çŸ©é˜µä¹˜æ³•ï¼ˆGEMMï¼‰ã€‚
- æ˜¾è‘—æé«˜**ç®—æœ¯å¼ºåº¦**ï¼ˆarithmetic intensityï¼‰ï¼Œä½¿å·¥ä½œè´Ÿè½½ä» memory-bound è½¬å‘ compute-boundï¼Œæ›´å……åˆ†åœ°åˆ©ç”¨ GPU å³°å€¼ç®—åŠ›ã€‚

#### âœ… **Unified KV Ring Buffer**
- æ‰€æœ‰æ´»è·ƒè¯·æ±‚çš„ KV Cache ç»Ÿä¸€å­˜å‚¨åœ¨ä¸€ä¸ªç‰©ç†è¿ç»­çš„ç¯å½¢ç¼“å†²åŒºä¸­ã€‚
- æ”¯æŒ Variable-Length Attentionï¼ˆVarlen-Attentionï¼‰é«˜æ•ˆè®¿é—®ä¸åŒé•¿åº¦çš„å†å²ä¸Šä¸‹æ–‡ã€‚
- é€šè¿‡ `FUSEDROPEANDWRITEKV` å’Œ `INPLACESHIFTKV` å†…æ ¸èåˆæŠ€æœ¯ï¼Œé¿å… CPU-GPU åŒæ­¥å¼€é”€å’ŒåŠ¨æ€å†…å­˜æ‹·è´ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ActionFlow |
|------|-----------|
| **æ˜¯å¦éœ€è¦é‡è®­ç»ƒ** | âŒ ä¸éœ€è¦ï¼Œçº¯ç³»ç»Ÿçº§ä¼˜åŒ– |
| **æ˜¯å¦ä¾èµ–å¤–éƒ¨å¤šç”¨æˆ·è¯·æ±‚** | âŒ å¦ï¼Œé€‚ç”¨äºå•ç”¨æˆ·æœºå™¨äººåœºæ™¯ |
| **å¯¹ç¡¬ä»¶åˆ©ç”¨ç‡æå‡æœºåˆ¶** | âœ… é€šè¿‡å†…éƒ¨å¾®è¯·æ±‚æ‰¹å¤„ç†æå‡ |
| **ä¸å…¶å®ƒä¼˜åŒ–æ­£äº¤æ€§** | âœ… å¯ä¸é‡åŒ–ã€Speculative Decoding ç­‰ç»“åˆ |
| **åŠŸèƒ½æ­£ç¡®æ€§ä¿éšœ** | âœ… è¾“å‡ºç­‰ä»·äºåŸç”Ÿè‡ªå›å½’æ¨ç† |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ¨¡å‹ä¸å¹³å°**

- **æ¨¡å‹**ï¼šOpenVLA-7Bï¼ˆ70äº¿å‚æ•°ï¼‰
- **ç¡¬ä»¶å¹³å°**ï¼š
  - **NVIDIA Jetson AGX Orin (64GB)**ï¼šä»£è¡¨èµ„æºå—é™çš„åµŒå…¥å¼æœºå™¨äººè®¾å¤‡
  - **NVIDIA RTX 5090**ï¼šä»£è¡¨é«˜æ€§èƒ½è¾¹ç¼˜å·¥ä½œç«™
- **è½¯ä»¶æ ˆ**ï¼šPyTorch 2.6.0, Transformers 4.49.0, CUDA 12.6

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°æŒ‡æ ‡**
- **FPS**ï¼ˆFrames Per Secondï¼‰ï¼šæ ¸å¿ƒååé‡æŒ‡æ ‡ï¼Œè¡¡é‡æ¯ç§’å¯å®Œæˆçš„æ¨ç†å¸§æ•°ã€‚
- **Speedup**ï¼šç›¸å¯¹äº Baseline çš„åŠ é€Ÿæ¯”ã€‚
- **Success Rate**ï¼šåœ¨ LIBERO åŸºå‡†ä¸Šçš„ä»»åŠ¡æˆåŠŸç‡ï¼ŒéªŒè¯åŠŸèƒ½æ— æŸã€‚

#### **å¯¹æ¯”æ–¹æ³•**
| æ–¹æ³• | æè¿° |
|------|------|
| **Baseline** | åŸå§‹ OpenVLA-7B è‡ªå›å½’æ¨ç†ï¼Œæ— ä»»ä½•ç³»ç»Ÿä¼˜åŒ– |
| **Naive Pipe** | å®ç°äº† Cross-Request Pipeliningï¼Œä½†ä½¿ç”¨åŠ¨æ€ KV ç¼“å­˜æ‹¼æ¥å’Œ CPU åè°ƒæ‰¹å¤„ç†ï¼ˆæ— å†…æ ¸èåˆï¼‰ |
| **ActionFlow** | å®Œæ•´æ–¹æ¡ˆï¼šåŒ…å« Cross-Request Pipelining + Cross-Request State Packed Forward + Unified KV Ring Buffer |

#### **æ•æ„Ÿæ€§åˆ†æ**
- å˜åŒ– **Prefill é•¿åº¦**ï¼ˆæ–‡æœ¬æŒ‡ä»¤é•¿åº¦ + 256 è§†è§‰ tokenï¼‰
- å˜åŒ– **Decode é•¿åº¦ K âˆˆ {7, 16, 24, 32}**ï¼Œæ¨¡æ‹Ÿä¸åŒå¤æ‚åº¦çš„åŠ¨ä½œåºåˆ—ç”Ÿæˆä»»åŠ¡

#### **åŠŸèƒ½éªŒè¯åŸºå‡†**
- **LIBERO Benchmark Suite**ï¼šæ¶µç›–ç©ºé—´æ“ä½œã€ç‰©ä½“æ“ä½œã€ç›®æ ‡è¾¾æˆã€é•¿ç¨‹ä»»åŠ¡å››å¤§ç±»ï¼Œç”¨äºæµ‹è¯•ä»»åŠ¡æˆåŠŸç‡ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1ï¼‰**

| Method | Platform | FPS | Speedup |
|--------|----------|-----|---------|
| Baseline | AGX Orin | 1.25 Â± 0.01 | 1.00x |
| Naive Pipe | AGX Orin | 2.70 Â± 0.19 | 2.16x |
| **ActionFlow** | **AGX Orin** | **3.20 Â± 0.17** | **2.56x** |
| Baseline | RTX 5090 | 7.62 Â± 0.14 | 1.00x |
| Naive Pipe | RTX 5090 | 15.60 Â± 0.08 | 2.04x |
| **ActionFlow** | **RTX 5090** | **19.45 Â± 0.22** | **2.55x** |

> âœ… **ç»“è®º**ï¼šActionFlow åœ¨ä¸¤ç±»å¹³å°ä¸Šå‡å®ç°çº¦ **2.55x çš„ç¨³å®šåŠ é€Ÿ**ï¼Œä¸”æ— éœ€æ¨¡å‹ä¿®æ”¹ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

- **ActionFlow vs. Naive Pipe**ï¼š
  - åœ¨ AGX Orin ä¸Šå¸¦æ¥é¢å¤– **18.5%** æ€§èƒ½æå‡ï¼ˆ3.20 vs 2.70 FPSï¼‰
  - åœ¨ RTX 5090 ä¸Šå¸¦æ¥é¢å¤– **24.7%** æå‡ï¼ˆ19.45 vs 15.60 FPSï¼‰
- **è¯´æ˜**ï¼š`Cross-Request State Packed Forward` å’Œ `Unified KV Ring Buffer` çš„å†…æ ¸èåˆè®¾è®¡è‡³å…³é‡è¦ï¼Œæœ‰æ•ˆæ¶ˆé™¤äº† CPU-GPU åŒæ­¥æ°”æ³¡å’Œå†…å­˜æ‹·è´å¼€é”€ã€‚

---

### **æ•æ„Ÿæ€§åˆ†æï¼ˆFigure 5ï¼‰**

- **é‡è´Ÿè½½ä¸‹ä¼˜åŠ¿æ›´æ˜æ˜¾**ï¼š
  - å½“ K=32 ä¸” Prefill è¾ƒé•¿æ—¶ï¼š
    - RTX 5090ï¼šBaseline ä¸‹é™è‡³ 2.36 FPSï¼ŒActionFlow ä»è¾¾ 9.58 FPS â†’ **4.06Ã— åŠ é€Ÿ**
    - AGX Orinï¼šBaseline é™è‡³ 0.30 FPSï¼ŒActionFlow ä¿æŒ 1.31 FPS â†’ **4.36Ã— åŠ é€Ÿ**
- **å¯¹ Decode é•¿åº¦é²æ£’æ€§å¼º**ï¼š
  - Baseline åœ¨ K ä» 7 å¢è‡³ 32 æ—¶ï¼ŒRTX 5090 ååä¸‹é™ **72%**
  - ActionFlow ä»…ä¸‹é™ **25%**ï¼Œè¡¨æ˜å…¶æˆåŠŸæ‘Šé”€äº†è‡ªå›å½’çš„ä¸²è¡Œå¼€é”€ã€‚

---

### **åŠŸèƒ½æ­£ç¡®æ€§éªŒè¯ï¼ˆTable 2ï¼‰**

| Method | Platform | Spatial | Object | Goal | Long |
|--------|----------|--------|--------|------|------|
| OpenVLA (Baseline) | RTX 5090 | 84.4% | 73.8% | 74.4% | 51.4% |
| ActionFlow | RTX 5090 | 84.3% | 71.2% | 78.6% | 53.3% |
| ActionFlow | AGX Orin | 83.4% | 68.8% | 75.6% | 49.0% |

> âœ… **ç»“è®º**ï¼šActionFlow åœ¨æ‰€æœ‰ä»»åŠ¡ç±»åˆ«ä¸­å‡ä¿æŒä¸ Baseline ç›¸å½“çš„æˆåŠŸç‡ï¼Œæ³¢åŠ¨åœ¨ç»Ÿè®¡è¯¯å·®èŒƒå›´å†…ï¼Œ**åŠŸèƒ½æ— æŸ**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **VLA æ¨ç†ç“¶é¢ˆæœ¬è´¨æ˜¯ Decode é˜¶æ®µçš„ä½æ•ˆæ€§**ï¼šå…¶ä½ç®—æœ¯å¼ºåº¦å¯¼è‡´ GPU è®¡ç®—å•å…ƒé—²ç½®ï¼Œå½¢æˆâ€œDecode Bubbleâ€ã€‚
2. **å•ç”¨æˆ·åœºæ™¯ä¹Ÿå¯åˆ›é€ æ‰¹å¤„ç†æœºä¼š**ï¼šé€šè¿‡å°†è¿ç»­è¯·æ±‚çš„ Prefill ä¸å†å² Decode æµæ°´çº¿åŒ–ï¼Œå¯åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°é«˜æ•ˆçš„å†…éƒ¨æ‰¹å¤„ç†ã€‚
3. **ç³»ç»Ÿçº§ä¼˜åŒ–å¯ç‹¬ç«‹äºç®—æ³•æ”¹è¿›**ï¼šActionFlow æ˜¯å®Œå…¨æ­£äº¤äºé‡åŒ–ã€è’¸é¦ã€å¹¶è¡Œè§£ç ç­‰æ–¹æ³•çš„çº¯ç³»ç»Ÿä¼˜åŒ–ï¼Œå¯å åŠ ä½¿ç”¨ã€‚
4. **å†…æ ¸èåˆæ˜¯é‡Šæ”¾æ€§èƒ½çš„å…³é”®**ï¼š`Unified KV Ring Buffer` + `FUSEDROPEANDWRITEKV` + `INPLACESHIFTKV` å…±åŒæ¶ˆé™¤åŒæ­¥ä¸å†…å­˜ç®¡ç†å¼€é”€ï¼Œæ˜¯å®ç°æ¥è¿‘ç†è®ºåŠ é€Ÿä¸Šé™çš„åŸºç¡€ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- **ä¾èµ–å›ºå®šåŠ¨ä½œåºåˆ—é•¿åº¦ K**ï¼šå½“å‰è®¾è®¡å‡è®¾æ¯ä¸ªè¯·æ±‚ç”Ÿæˆå›ºå®šæ•°é‡çš„åŠ¨ä½œ tokenï¼ˆK æ­¥ï¼‰ã€‚è‹¥ä»»åŠ¡éœ€åŠ¨æ€ç»ˆæ­¢ï¼ˆearly exitï¼‰ï¼Œéœ€æ‰©å±•æ”¯æŒå˜é•¿è¾“å‡ºã€‚
- **åˆå§‹å»¶è¿Ÿä»å­˜åœ¨**ï¼šé¦–ä¸ªåŠ¨ä½œä»éœ€å®Œæ•´ Prefill + K æ­¥ Decodeï¼Œä»…åç»­å¸§å—ç›Šäºæµæ°´çº¿ã€‚
- **KV Cache å†…å­˜å ç”¨å¢åŠ **ï¼šç”±äºç»´æŠ¤ K ä¸ªå¹¶å‘è¯·æ±‚çš„çŠ¶æ€ï¼ŒKV Cache æ€»é‡çº¦ä¸ºåŸå§‹çš„ K å€ï¼Œåœ¨æç«¯å†…å­˜å—é™åœºæ™¯å¯èƒ½æˆä¸ºç“¶é¢ˆã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ”¯æŒåŠ¨æ€åŠ¨ä½œåºåˆ—é•¿åº¦**ï¼šç»“åˆ early-exit æˆ–æµå¼ç”Ÿæˆæœºåˆ¶ï¼Œè¿›ä¸€æ­¥é™ä½é¦–å¸§å»¶è¿Ÿã€‚
2. **ä¸ç®—æ³•çº§ä¼˜åŒ–ååŒè®¾è®¡**ï¼šæ¢ç´¢ä¸ Speculative Decodingã€Action Chunking ç­‰æ–¹æ³•çš„è”åˆä¼˜åŒ–ã€‚
3. **æ‰©å±•è‡³å¤šæ¨¡æ€è¾“å…¥æµ**ï¼šæ”¯æŒéŸ³é¢‘ã€è§¦è§‰ç­‰æ›´å¤šæ„ŸçŸ¥æ¨¡æ€çš„å®æ—¶èåˆæ¨ç†ã€‚
4. **éƒ¨ç½²åˆ°çœŸå®æœºå™¨äººç³»ç»Ÿ**ï¼šåœ¨ç§»åŠ¨æœºå™¨äººã€æœºæ¢°è‡‚ç­‰å®é™…å¹³å°ä¸ŠéªŒè¯ç«¯åˆ°ç«¯æ§åˆ¶ç¨³å®šæ€§ä¸å“åº”èƒ½åŠ›ã€‚

---

> ğŸ”— **é¡¹ç›®åœ°å€**ï¼šhttps://anonymous.4open.science/r/ActionFlow-1D47

</details>

---

### 2. [MoE-DiffuSeq: Enhancing Long-Document Diffusion Models with Sparse Attention and Mixture of Experts](https://arxiv.org/abs/2512.20604)

**Authors**: Alexandros Christoforos, Chadbourne Davis  
**Category**: cs.CL  
**Published**: 2025-12-24  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.20604v1  

#### Abstract
We present MoE-DiffuSeq, a mixture of experts based framework for enhancing diffusion models in long document generation. Existing diffusion based text generation models, such as DiffuSeq, suffer from high computational cost and memory overhead when applied to extended sequences. To address these ch...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MoE-DiffuSeq: Enhancing Long-Document Diffusion Models with Sparse Attention and Mixture of Experts  
**æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
ä¼ ç»Ÿ Diffusion æ¨¡å‹ï¼ˆå¦‚ DiffuSeqï¼‰åœ¨ç”Ÿæˆé•¿æ–‡æœ¬æ—¶é¢ä¸´ä¸¥é‡çš„**è®¡ç®—æ•ˆç‡ä½ä¸‹**å’Œ**å†…å­˜æ¶ˆè€—è¿‡é«˜**çš„é—®é¢˜ï¼Œä¸»è¦æºäº Transformer æ¶æ„ä¸­è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ $O(n^2)$ æ—¶é—´å¤æ‚åº¦ã€‚æ­¤å¤–ï¼Œç°æœ‰æ¨¡å‹åœ¨å¤„ç†ç§‘å­¦æ–‡ç« ã€ä»£ç ä»“åº“æˆ–é•¿å¯¹è¯ç­‰éœ€è¦é•¿ä¸Šä¸‹æ–‡ç†è§£çš„ä»»åŠ¡æ—¶ï¼Œå¾€å¾€å› åºåˆ—é•¿åº¦é™åˆ¶è€Œè¡¨ç°ä¸ä½³ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡º **MoE-DiffuSeq**ï¼Œä¸€ç§ç»“åˆ **Mixture of Experts (MoE)** ä¸ **DiffuSeq** æ¡†æ¶ï¼Œå¹¶å¼•å…¥ **Sparse Attention** å’Œ **Soft Absorbing State** çš„æ–°å‹æ‰©æ•£è¯­è¨€æ¨¡å‹ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **MoE + Diffusion èåˆæ¶æ„**ï¼šé¦–æ¬¡å°† MoE åŠ¨æ€ä¸“å®¶é€‰æ‹©æœºåˆ¶é›†æˆåˆ° Diffusion åºåˆ—ç”Ÿæˆæ¡†æ¶ä¸­ï¼Œå®ç°å¯¹ä¸åŒæ–‡æœ¬æ®µè½æŒ‰éœ€æ¿€æ´»æœ€ç›¸å…³ä¸“å®¶ï¼Œæå‡æ¨¡å‹å®¹é‡çš„åŒæ—¶æ§åˆ¶è®¡ç®—å¼€é”€ã€‚
- **å®šåˆ¶åŒ–ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶**ï¼šé‡‡ç”¨ Longformer é£æ ¼çš„æ»‘åŠ¨çª—å£æ³¨æ„åŠ›ï¼ˆSliding Window Attentionï¼‰ï¼Œå¹¶å¼•å…¥**ç©ºæ´æ»‘çª—ï¼ˆDilated Sliding Windowï¼‰** æ‰©å±•æ„Ÿå—é‡ï¼Œåœ¨ä¸å¢åŠ è®¡ç®—é‡çš„å‰æä¸‹æ•æ‰é•¿è·ç¦»ä¾èµ–ã€‚
- **å…¨å±€æ³¨æ„åŠ›æœºåˆ¶**ï¼šä¸ºå…³é”® tokenï¼ˆå¦‚ [CLS]ï¼‰ä¿ç•™å…¨å±€æ³¨æ„åŠ›èƒ½åŠ›ï¼Œç¡®ä¿æ•´ä½“è¯­ä¹‰ä¸€è‡´æ€§ã€‚
- **è½¯å¸æ”¶çŠ¶æ€ï¼ˆSoft Absorbing Stateï¼‰**ï¼šæ”¹è¿›æ‰©æ•£è¿‡ç¨‹ä¸­çš„å™ªå£°å»ºæ¨¡ï¼Œä¼˜åŒ–åå‘å»å™ªè·¯å¾„ï¼ŒåŠ é€Ÿåºåˆ—é‡å»ºå¹¶æé«˜ç²¾åº¦ã€‚
- **é›†æˆ DPM-solver++ åŠ é€Ÿæ¨ç†**ï¼šæ˜¾è‘—å‡å°‘æ‰€éœ€ diffusion stepsï¼Œæå‡é‡‡æ ·é€Ÿåº¦è€Œä¸ç‰ºç‰²è´¨é‡ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | æ˜¾è‘—é™ä½è®­ç»ƒå’Œæ¨ç†æ—¶é—´ï¼Œå°¤å…¶é€‚ç”¨äºé•¿åºåˆ—ï¼ˆ>8k tokensï¼‰åœºæ™¯ |
| **å¯æ‰©å±•æ€§** | MoE è®¾è®¡æ”¯æŒæ›´å¤§å‚æ•°è§„æ¨¡ï¼ŒåŒæ—¶ä¿æŒé«˜æ•ˆè®¡ç®—èµ„æºåˆ©ç”¨ |
| **ç”Ÿæˆè´¨é‡** | åœ¨å¤šä¸ªä»»åŠ¡ä¸Šä¼˜äº DiffuSeq å’Œ Longformerï¼Œè¯­ä¹‰è¿è´¯æ€§å’Œå¤šæ ·æ€§æ›´é«˜ |
| **é€‚ç”¨æ€§** | ç‰¹åˆ«é€‚åˆç§‘å­¦æ–‡çŒ®ç”Ÿæˆã€ä»£ç ç”Ÿæˆã€å¤šè½®å¯¹è¯ç­‰é•¿æ–‡æ¡£ä»»åŠ¡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**
å®éªŒæ¶µç›–å››ç±»å…¸å‹é•¿æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼š
- **Arxiv Abstract Dataset**ï¼šç”¨äºè¯„ä¼°ç§‘å­¦æ–‡æœ¬æ‘˜è¦ç”Ÿæˆèƒ½åŠ›ã€‚
- **HotpotQA**ï¼šæµ‹è¯•å¤šè·³é—®ç­”ä¸è·¨æ–‡æ¡£æ¨ç†èƒ½åŠ›ã€‚
- **Commonsense Conversation Dataset**ï¼šè¡¡é‡å¯¹è¯ç³»ç»Ÿçš„æƒ…å¢ƒç†è§£å’Œå“åº”ç”Ÿæˆè´¨é‡ã€‚
- **Quora Question Pairs (QQP)**ï¼šè¯„ä¼°è¯­ä¹‰ä¿æŒä¸‹çš„æ–‡æœ¬æ”¹å†™ï¼ˆparaphrasingï¼‰å‡†ç¡®æ€§ã€‚

### **å®éªŒè®¾ç½®**
- **æ¨¡å‹ç»“æ„**ï¼š12å±‚ Transformerï¼Œæ¯å±‚12ä¸ª attention headsã€‚
- **ç¨€ç–æ³¨æ„åŠ›é…ç½®**ï¼šæ»‘åŠ¨çª—å£å¤§å°ä¸º512ï¼Œéƒ¨åˆ†å®éªŒå°è¯•256/1024ï¼›ä½¿ç”¨ dilated attention æ‰©å±•ä¸Šä¸‹æ–‡æ„ŸçŸ¥èŒƒå›´ã€‚
- **MoE è®¾ç½®**ï¼šæ¯å±‚é…å¤‡å¤šä¸ª expert networkï¼Œé€šè¿‡ gating function åŠ¨æ€é€‰æ‹© top-k ä¸“å®¶ã€‚
- **æ‰©æ•£æ­¥éª¤**ï¼šé»˜è®¤ä½¿ç”¨ 2048 æ­¥ï¼Œéƒ¨åˆ†å®éªŒè°ƒæ•´è‡³ 1024 æˆ– 4096 è¿›è¡Œå¯¹æ¯”ã€‚
- **è®­ç»ƒç­–ç•¥**ï¼šåˆ†é˜¶æ®µå¢å¤§çª—å£å°ºå¯¸å’Œåºåˆ—é•¿åº¦ï¼Œé‡‡ç”¨å¹³æ–¹æ ¹å™ªå£°è°ƒåº¦ï¼ˆsquare-root noise scheduleï¼‰ã€‚
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA A100 GPUã€‚

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | ç”¨é€”è¯´æ˜ |
|------|----------|
| **BLEU** | è¡¡é‡ç”Ÿæˆæ–‡æœ¬ä¸å‚è€ƒæ–‡æœ¬ä¹‹é—´çš„ n-gram åŒ¹é…ç²¾åº¦ |
| **ROUGE (R1/R2/RL)** | åŸºäºå¬å›ç‡è¯„ä¼°å†…å®¹è¦†ç›–åº¦ï¼Œå¸¸ç”¨äºæ‘˜è¦ä»»åŠ¡ |
| **BERTScore** | åˆ©ç”¨ BERT ä¸Šä¸‹æ–‡åµŒå…¥è®¡ç®—è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œåæ˜ è¯­ä¹‰ä¿çœŸåº¦ |
| **Answer EM/F1 & Support EM/F1** | HotpotQA ä¸“ç”¨æŒ‡æ ‡ï¼Œåˆ†åˆ«è¯„ä»·ç­”æ¡ˆç²¾ç¡®åŒ¹é…/æ¨¡ç³ŠåŒ¹é…åŠè¯æ®å¥å­è¯†åˆ«æ•ˆæœ |
| **Accuracy** | QQP æ•°æ®é›†ä¸Šçš„åˆ†ç±»å‡†ç¡®ç‡ï¼ˆæ˜¯å¦ä¸ºåŒä¹‰å¥ï¼‰ |
| **Inference Time / 2-gram Novelty** | æ¨ç†å»¶è¿Ÿä¸ç”Ÿæˆæ–‡æœ¬æ–°é¢–æ€§å¹³è¡¡åˆ†æ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **DiffuSeq (Gong et al., 2023)**ï¼šåŸºç¡€æ‰©æ•£è¯­è¨€æ¨¡å‹ï¼Œä½œä¸ºç›´æ¥å¯¹ç…§ã€‚
- **Longformer (Beltagy et al., 2020)**ï¼šç»å…¸ç¨€ç–æ³¨æ„åŠ›æ¨¡å‹ï¼Œæ“…é•¿å¤„ç†é•¿æ–‡æœ¬ã€‚
- **GPT-4 (Achiam et al., 2023)**ï¼šé€šç”¨å¤§æ¨¡å‹æ ‡æ†ï¼Œæä¾›é«˜æ€§èƒ½ä¸Šé™å‚è€ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

#### âœ… Arxiv Abstract Datasetï¼ˆROUGE åˆ†æ•°ï¼‰
| Model | R1 | R2 | RL |
|-------|----|----|-----|
| Longformer | 41.44 | 17.52 | 38.70 |
| DiffuSeq | 39.12 | 16.43 | 37.88 |
| **MoE-DiffuSeq** | **44.41** | **18.73** | **39.89** |

> **ç»“è®º**ï¼šMoE-DiffuSeq åœ¨æ‰€æœ‰ ROUGE æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—é¢†å…ˆï¼Œè¡¨æ˜å…¶åœ¨ç§‘å­¦æ‘˜è¦ç”Ÿæˆä¸­å…·æœ‰æ›´å¼ºçš„ä¿¡æ¯æå–ä¸ç»„ç»‡èƒ½åŠ›ã€‚

#### âœ… HotpotQA Dataset
| Model | Answer EM/F1 | Support EM/F1 |
|--------|----------------|----------------|
| Longformer | 71.21 / 82.42 | 65.11 / 89.50 |
| DiffuSeq | 70.91 / 81.43 | 64.60 / 88.51 |
| **MoE-DiffuSeq** | **72.88 / 85.42** | **66.69 / 90.40** |

> **ç»“è®º**ï¼šåœ¨å¤šè·³æ¨ç†å’Œæ”¯æ’‘å¥è¯†åˆ«æ–¹é¢å…¨é¢è¶…è¶ŠåŸºçº¿ï¼Œä½“ç°å…¶å¼ºå¤§çš„é•¿ç¨‹ä¾èµ–å»ºæ¨¡èƒ½åŠ›ã€‚

#### âœ… Commonsense Conversation Dataset
| Model | BLEU | ROUGE-L | BERTScore |
|--------|--------|-----------|-------------|
| Longformer | 0.030 | 0.139 | 0.602 |
| DiffuSeq | 0.022 | 0.119 | 0.501 |
| **MoE-DiffuSeq** | **0.049** | **0.233** | **0.628** |

> **ç»“è®º**ï¼šåœ¨å¯¹è¯ç”Ÿæˆä»»åŠ¡ä¸­å±•ç°å‡ºæ›´é«˜çš„è¯­è¨€å¤šæ ·æ€§å’Œè¯­ä¹‰å‡†ç¡®æ€§ã€‚

#### âœ… QQP Datasetï¼ˆParaphrase Accuracyï¼‰
| Model | Accuracy |
|--------|----------|
| Longformer | 92.3 |
| DiffuSeq | 91.7 |
| **MoE-DiffuSeq** | **95.3** |

> **ç»“è®º**ï¼šåœ¨è¯­ä¹‰ä¸å˜å‰æä¸‹çš„æ–‡æœ¬é‡æ„ä»»åŠ¡ä¸­è¡¨ç°æœ€ä¼˜ï¼Œè¯´æ˜å…¶å…·å¤‡ä¼˜ç§€çš„è¯­ä¹‰ç†è§£ä¸è¡¨è¾¾èƒ½åŠ›ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**
åœ¨ Arxiv æ•°æ®é›†ä¸Šè¿›è¡Œç»„ä»¶åˆ†æï¼ˆè§ Table 5ï¼‰ï¼š

| Configuration | Attention Type | Diffusion Steps | Window Size | BLEU/ROUGE/BERTScore |
|---------------|----------------|------------------|--------------|----------------------------|
| Full Model (Baseline) | Sparse | 2048 | 512 | **44.41 / 18.73 / 39.89** |
| No Sparse Attention | Standard | 2048 | 512 | 42.52 / 17.99 / 38.41 |
| Reduced Steps | Sparse | 1024 | 512 | 43.11 / 18.03 / 39.26 |
| Increased Steps | Sparse | 4096 | 512 | â€” |
| Smaller Window | Sparse | 2048 | 256 | 44.40 / 18.66 / 39.92 |
| Larger Window | Sparse | 2048 | 1024 | â€” |

> **å‘ç°**ï¼š
- ç§»é™¤ **Sparse Attention** å¯¼è‡´æ€§èƒ½æ˜æ˜¾ä¸‹é™ â†’ éªŒè¯å…¶å¯¹é•¿åºåˆ—å¤„ç†çš„å…³é”®ä½œç”¨ã€‚
- å‡å°‘ diffusion steps å¯¹æ€§èƒ½å½±å“è¾ƒå°ï¼Œä½†è¿›ä¸€æ­¥å¢åŠ æ”¶ç›Šæœ‰é™ â†’ æ”¯æŒä½¿ç”¨ DPM-solver++ åŠ é€Ÿæ¨ç†çš„åˆç†æ€§ã€‚
- çª—å£å¤§å°å˜åŒ–å½±å“è¾ƒå¼±ï¼Œè¯´æ˜ **dilated attention** å·²æœ‰æ•ˆæ‰©å±•ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›ã€‚

---

### **æ¨ç†æ•ˆç‡ä¸æ–°é¢–æ€§æƒè¡¡ï¼ˆFigure 3ï¼‰**
- MoE-DiffuSeq åœ¨ **2-gram Novelty** ä¸Šæ˜¾è‘—é«˜äº DiffuSeq å’Œ Longformerï¼Œè¯´æ˜ç”Ÿæˆå†…å®¹æ›´å…·å¤šæ ·æ€§ã€‚
- æ¨ç†æ—¶é—´ç•¥æ…¢äº Longformerï¼Œä½†è¿œå¿«äº DiffuSeqï¼Œä¸”æ–°é¢–æ€§è¿œè¶…ä¸¤è€…ã€‚
- å®ç°äº†â€œé«˜æ–°é¢–æ€§â€ä¸â€œä½å»¶è¿Ÿâ€çš„è‰¯å¥½å¹³è¡¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**
1. **MoE ä¸ Diffusion çš„èåˆæ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„**ï¼šMoE-DiffuSeq æˆåŠŸå°† MoE çš„åŠ¨æ€è®¡ç®—åˆ†é…ä¼˜åŠ¿å¼•å…¥æ‰©æ•£æ¨¡å‹ï¼Œæå‡äº†é•¿æ–‡æœ¬ç”Ÿæˆçš„æ•ˆç‡ä¸è´¨é‡ã€‚
2. **Sparse Attention æ˜¯å¤„ç†é•¿åºåˆ—çš„æ ¸å¿ƒæŠ€æœ¯**ï¼šæ»‘åŠ¨çª—å£ + dilated attention + global attention çš„ç»„åˆæœ‰æ•ˆç¼“è§£äº† $O(n^2)$ å¤æ‚åº¦ç“¶é¢ˆã€‚
3. **æ¨¡å‹åœ¨å¤šç§ä»»åŠ¡ä¸Šå…¨é¢è¶…è¶Šä¸»æµåŸºçº¿**ï¼šæ— è®ºæ˜¯åœ¨æ‘˜è¦ã€é—®ç­”ã€å¯¹è¯è¿˜æ˜¯ paraphrasing ä»»åŠ¡ä¸­ï¼ŒMoE-DiffuSeq å‡å–å¾— SOTA æˆ–æ¥è¿‘ SOTA çš„è¡¨ç°ã€‚
4. **å…¼é¡¾ç”Ÿæˆé€Ÿåº¦ä¸è´¨é‡**ï¼šé€šè¿‡å‡å°‘ diffusion steps å’Œä¼˜åŒ– attention ç»“æ„ï¼Œå®ç°äº†å¿«é€Ÿé‡‡æ ·ä¸é«˜è´¨é‡è¾“å‡ºçš„ç»Ÿä¸€ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- å½“å‰æ¨¡å‹ä»ä¾èµ–å¤§é‡ GPU èµ„æºè®­ç»ƒï¼ˆA100ï¼‰ï¼Œéƒ¨ç½²æˆæœ¬è¾ƒé«˜ã€‚
- MoE çš„è´Ÿè½½å‡è¡¡é—®é¢˜æœªæ·±å…¥æ¢è®¨ï¼Œå¯èƒ½å­˜åœ¨ä¸“å®¶åˆ©ç”¨ç‡ä¸å‡çš„æƒ…å†µã€‚
- å°šæœªåœ¨å›¾åƒ-æ–‡æœ¬ç­‰ multimodal åœºæ™¯ä¸­éªŒè¯æ³›åŒ–èƒ½åŠ›ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢ MoE-DiffuSeq åœ¨ **code generation** å’Œ **scientific paper writing** ä¸­çš„å®é™…åº”ç”¨ã€‚
- å¼•å…¥ **multimodal inputs**ï¼ˆå¦‚å›¾è¡¨ã€å…¬å¼ï¼‰ä»¥å¢å¼ºç§‘å­¦æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ã€‚
- ä¼˜åŒ– MoE routing ç­–ç•¥ï¼Œæå‡ä¸“å®¶åˆ©ç”¨ç‡ä¸è®­ç»ƒç¨³å®šæ€§ã€‚
- è¿›ä¸€æ­¥å‹ç¼© diffusion stepsï¼Œæ¢ç´¢ **real-time generation** å¯èƒ½æ€§ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **MoE-DiffuSeq é€šè¿‡èåˆ Mixture of Experts ä¸ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ„å»ºäº†ä¸€ä¸ªé«˜æ•ˆã€å¯æ‰©å±•ä¸”é«˜è´¨é‡çš„é•¿æ–‡æœ¬æ‰©æ•£ç”Ÿæˆæ¨¡å‹ï¼Œåœ¨å¤šé¡¹ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äº DiffuSeq å’Œ Longformerï¼Œä¸ºä¸‹ä¸€ä»£é•¿æ–‡æ¡£ç”Ÿæˆç³»ç»Ÿæä¾›äº†æ–°èŒƒå¼ã€‚**

</details>

---

### 3. [SHIRO: Near-Optimal Communication Strategies for Distributed Sparse Matrix Multiplication](https://arxiv.org/abs/2512.20178)

**Authors**: Chen Zhuang, Lingqi Zhang, Benjamin Brock, Du Wu, Peng Chen, Toshio Endo, Satoshi Matsuoka, Mohamed Wahib  
**Category**: cs.DC  
**Published**: 2025-12-24  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.20178v1  

#### Abstract
Distributed Sparse Matrix-Matrix Multiplication (SpMM) is a fundamental operation in numerous high-performance computing and deep learning applications. The major performance bottleneck in distributed SpMM lies in the substantial communication overhead, which limits both performance and scalability....

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSHIRO: Near-Optimal Communication Strategies for Distributed Sparse Matrix Multiplication

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

åˆ†å¸ƒå¼ç¨€ç–çŸ©é˜µä¹˜æ³•ï¼ˆ**Distributed SpMM**ï¼‰æ˜¯é«˜æ€§èƒ½è®¡ç®—å’Œæ·±åº¦å­¦ä¹ ï¼ˆå¦‚ **GNNs**ï¼‰ä¸­çš„æ ¸å¿ƒæ“ä½œï¼Œå…¶æ€§èƒ½ç“¶é¢ˆä¸»è¦åœ¨äº**é€šä¿¡å¼€é”€è¿‡å¤§**ã€‚ç°æœ‰æ–¹æ³•åœ¨ä¸¤ä¸ªå±‚é¢å­˜åœ¨é€šä¿¡æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼š

1. **é€šä¿¡ç­–ç•¥å†—ä½™**ï¼š
   - **Sparsity-oblivious** æ–¹æ³•ï¼ˆå¦‚ CAGNETã€BCLï¼‰ä¼ è¾“æ•´ä¸ªç¨ å¯†å—ï¼Œå¿½ç•¥ç¨€ç–æ€§ï¼Œå¯¼è‡´å¤§é‡æ— ç”¨æ•°æ®ä¼ è¾“ã€‚
   - **Sparsity-aware** æ–¹æ³•ï¼ˆå¦‚ SPAã€CoLaï¼‰è™½åŸºäºåˆ—ç´¢å¼•æˆ–è¡Œç´¢å¼•è¿›è¡Œä¼˜åŒ–ï¼Œä½†ä»åªåˆ©ç”¨å•ç»´åº¦ç¨€ç–ä¿¡æ¯ï¼Œæœªèƒ½å……åˆ†æŒ–æ˜ç¨€ç–æ¨¡å¼ã€‚

2. **å¿½ç•¥å±‚æ¬¡åŒ–ç½‘ç»œæ‹“æ‰‘**ï¼š
   - å¤šæ•°æ–¹æ³•é‡‡ç”¨æ‰å¹³åŒ–çš„ `all-to-all` é€šä¿¡ï¼Œæœªè€ƒè™‘ç°ä»£ GPU é›†ç¾¤ä¸­**èŠ‚ç‚¹å†…é«˜é€Ÿé“¾è·¯ï¼ˆNVLinkï¼‰ä¸èŠ‚ç‚¹é—´ä½é€Ÿé“¾è·¯ï¼ˆInfiniBandï¼‰çš„å¸¦å®½å·®å¼‚**ï¼Œå¯¼è‡´è·¨èŠ‚ç‚¹é‡å¤ä¼ è¾“ç›¸åŒæ•°æ®ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **SHIRO** â€”â€” ä¸€ä¸ªé€šä¿¡é«˜æ•ˆçš„åˆ†å¸ƒå¼ SpMM æ¡†æ¶ï¼Œä»ä¸¤ä¸ªå±‚é¢è”åˆä¼˜åŒ–é€šä¿¡ï¼š

#### âœ… è”åˆè¡Œåˆ—ç¨€ç–æ„ŸçŸ¥é€šä¿¡ç­–ç•¥ï¼ˆJoint Row-Column Sparsity-Aware Communicationï¼‰
- å°†æ¯ä¸ªéé›¶å…ƒçš„é€šä¿¡å†³ç­–å»ºæ¨¡ä¸º**æœ€å°åŠ æƒè¦†ç›–é—®é¢˜ï¼ˆMinimum Weighted Covering Problemï¼‰**ã€‚
- æ„é€ äºŒåˆ†å›¾ï¼Œå°†è¡Œç´¢å¼•å’Œåˆ—ç´¢å¼•ä½œä¸ºé¡¶ç‚¹ï¼Œéé›¶å…ƒä½œä¸ºè¾¹ï¼Œé€šè¿‡ **Max-Flow / Min-Cut** ç®—æ³•æ±‚è§£æœ€ä¼˜é€šä¿¡æ–¹æ¡ˆã€‚
- åŠ¨æ€é€‰æ‹©å¯¹æ¯ä¸ªéé›¶å…ƒä½¿ç”¨ **row-based**ï¼ˆå‘é€éƒ¨åˆ† C ç»“æœï¼‰è¿˜æ˜¯ **column-based**ï¼ˆè¯·æ±‚å¯¹åº” B è¡Œï¼‰ç­–ç•¥ï¼Œå®ç°å…¨å±€é€šä¿¡é‡æœ€å°ã€‚

#### âœ… å±‚æ¬¡åŒ–é€šä¿¡ç­–ç•¥ï¼ˆHierarchical Communication Strategyï¼‰
- é’ˆå¯¹å¤šçº§ç½‘ç»œæ¶æ„ï¼ˆå¦‚èŠ‚ç‚¹å†… NVLink + èŠ‚ç‚¹é—´ InfiniBandï¼‰ï¼Œè®¾è®¡ä¸¤çº§é€šä¿¡æœºåˆ¶ï¼š
  - **Column-based**ï¼šé‡‡ç”¨â€œæºç»„èšåˆ â†’ è·¨ç»„ä¼ è¾“ â†’ ç»„å†…åˆ†å‘â€ä¸‰æ­¥æ³•ï¼Œé¿å…é‡å¤è·¨èŠ‚ç‚¹æ‹‰å– B è¡Œã€‚
  - **Row-based**ï¼šé‡‡ç”¨â€œç»„å†…é¢„èšåˆ â†’ è·¨ç»„ä¼ è¾“â€ä¸¤æ­¥æ³•ï¼Œå‡å°‘è·¨èŠ‚ç‚¹å‘é€çš„éƒ¨åˆ† C ç»“æœæ•°é‡ã€‚
- è®¾è®¡**é‡å è°ƒåº¦ç­–ç•¥**ï¼ˆOverlapping Schedulingï¼‰ï¼šåˆ©ç”¨ row-based å’Œ column-based é€šä¿¡åœ¨ä¸åŒå±‚çº§é“¾è·¯ä¸Šäº’è¡¥çš„ç‰¹ç‚¹ï¼Œå®ç°åŒå±‚é“¾è·¯åŒæ—¶é«˜æ•ˆåˆ©ç”¨ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ä¼˜åŠ¿ç»´åº¦ | å…·ä½“è¡¨ç° |
|--------|---------|
| **é€šä¿¡ä½“ç§¯æ›´å°** | åˆ©ç”¨å®Œæ•´ç¨€ç–æ¨¡å¼ï¼Œæ˜¾è‘—é™ä½æ€»é€šä¿¡é‡ï¼ˆæœ€é«˜å‡å°‘ 96.3%ï¼‰ |
| **ç½‘ç»œåˆ©ç”¨ç‡æ›´é«˜** | å‡å°‘è·¨èŠ‚ç‚¹å†—ä½™é€šä¿¡ï¼Œæå‡æ…¢é€Ÿé“¾è·¯åˆ©ç”¨ç‡ |
| **å¯æ‰©å±•æ€§æ›´å¼º** | åœ¨ 128 ä¸ª GPU ä¸Šä»ä¿æŒè‰¯å¥½å¼ºæ‰©å±•æ€§ |
| **é€šç”¨æ€§å¼º** | å¯é€‚é…ä»»æ„åˆ†åŒºç­–ç•¥ï¼ˆæ–‡ä¸­ä»¥ 1D row-partition ä¸ºä¸»ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

æ¥è‡ª **SuiteSparse Matrix Collection** çš„çœŸå®ä¸–ç•Œç¨€ç–çŸ©é˜µï¼Œæ¶µç›–ç¤¾äº¤ç½‘ç»œã€ç½‘é¡µå›¾ã€ç§‘å­¦è®¡ç®—ç­‰é¢†åŸŸï¼š

| æ•°æ®é›† | è§„æ¨¡ï¼ˆè¡Œ/åˆ—ï¼‰ | éé›¶å…ƒæ•° | å¯†åº¦ |
|-------|-------------|----------|------|
| `com-YT`, `soc-LJ`, `Pokec`, `Orkut` | ç™¾ä¸‡çº§ | æ•°åƒä¸‡è‡³æ•°åäº¿ | ~1e-6 ~ 1e-5 |
| `webbase-2001`, `GAP-web` | ä¸Šäº¿çº§ | è¶…åäº¿ | < 1e-7 |
| `arabic-2005`, `uk-2002` | æ•°åƒä¸‡çº§ | æ•°äº¿è‡³åäº¿ | ~1e-6 |

å…± 13 ä¸ªæ•°æ®é›†ï¼Œå…·æœ‰å¤šæ ·åŒ–çš„ç¨€ç–æ¨¡å¼ï¼ˆè¡Œåæ–œã€åˆ—åæ–œã€å‡åŒ€ã€æ··åˆç­‰ï¼‰ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **ç¡¬ä»¶å¹³å°**ï¼šTSUBAME 4.0 è¶…ç®—
  - å•èŠ‚ç‚¹ï¼šåŒ AMD EPYC 9654 CPU + 4 Ã— NVIDIA H100 SXM5ï¼ˆ94GB HBM2eï¼‰
  - èŠ‚ç‚¹å†…äº’è”ï¼šNVLink 4.0ï¼ˆ450 GB/sï¼‰
  - èŠ‚ç‚¹é—´äº’è”ï¼šInfiniBand NDR200ï¼ˆ200 Gbpsï¼‰
- **è½¯ä»¶æ ˆ**ï¼š
  - å•èŠ‚ç‚¹ SpMMï¼šPyTorch (`torch.sparse.mm`) â†’ cuSPARSE CSR kernel
  - å¤šèŠ‚ç‚¹é€šä¿¡ï¼šPyTorch Distributed + NCCL backendï¼ˆ`alltoall`ï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - ç«¯åˆ°ç«¯è¿è¡Œæ—¶é—´ï¼ˆEnd-to-end runtimeï¼‰
  - æ€»é€šä¿¡é‡ï¼ˆTotal communication volumeï¼‰
  - è·¨èŠ‚ç‚¹é€šä¿¡é‡ï¼ˆInter-node communication volumeï¼‰
  - åŠ é€Ÿæ¯”ï¼ˆSpeedupï¼‰
  - å¼ºæ‰©å±•æ€§ï¼ˆStrong scaling up to 128 GPUsï¼‰

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿æ–¹æ³• | åˆ†åŒºç­–ç•¥ | æ˜¯å¦ç¨€ç–æ„ŸçŸ¥ | æ˜¯å¦å±‚æ¬¡æ„ŸçŸ¥ | åç«¯ |
|--------|---------|------------|------------|------|
| **CAGNET** | 1.5D | âŒï¼ˆblock-basedï¼‰ | âŒ | NCCL |
| **SPA** | 1.5D | âœ…ï¼ˆcolumn-basedï¼‰ | âŒ | NCCL |
| **BCL** | 2D | âŒ | âŒ | NVSHMEM |
| **CoLa** | 1D | âœ…ï¼ˆcolumn-basedï¼‰ | âœ… | NVSHMEM |

SHIRO åœ¨æ‰€æœ‰ç»´åº¦ä¸Šå‡ä¼˜äºè¿™äº›æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨å¤§è§„æ¨¡ï¼ˆ>8 GPUsï¼‰åœºæ™¯ä¸‹ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

- **æœ€å¤§é€šä¿¡é‡å‡å°‘**ï¼šé«˜è¾¾ **96.3%**ï¼ˆåœ¨ `mawi` æ•°æ®é›†ä¸Šï¼Œç›¸æ¯” column-based ç­–ç•¥ï¼‰ã€‚
- **å‡ ä½•å¹³å‡åŠ é€Ÿæ¯”ï¼ˆ128 GPUsï¼‰**ï¼š
  - ç›¸æ¯” CAGNETï¼š**221.5Ã—**
  - ç›¸æ¯” SPAï¼š**56.0Ã—**
  - ç›¸æ¯” BCLï¼š**23.4Ã—**
  - ç›¸æ¯” CoLaï¼š**8.8Ã—**

> æ³¨ï¼šåœ¨ â‰¤4 GPUs æ—¶ï¼Œç”±äº CoLa çš„ç»†ç²’åº¦ RDMA ä¼˜åŒ–å ä¼˜ï¼ŒSHIRO ç•¥æ…¢ï¼›ä½†åœ¨ â‰¥8 GPUs åå…¨é¢åè¶…ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| å¯¹æ¯”é¡¹ | ç»“æœ |
|------|------|
| **vs CAGNET/BCL** | æ˜¾è‘—èƒœå‡ºï¼Œå› å…¶å®Œå…¨æ— è§†ç¨€ç–æ€§ï¼Œé€šä¿¡é‡å·¨å¤§ |
| **vs SPA** | æ›´ä¼˜ï¼Œå›  SPA ä»…ç”¨ column-basedï¼Œæ— æ³•è¿›ä¸€æ­¥å‹ç¼©é€šä¿¡ |
| **vs CoLa** | åœ¨å°è§„æ¨¡ç•¥é€Šï¼Œä½†åœ¨å¤§è§„æ¨¡ï¼ˆâ‰¥8 GPUsï¼‰æ˜¾è‘—é¢†å…ˆï¼Œè¯æ˜å±‚æ¬¡åŒ–ä¼˜åŒ–çš„æœ‰æ•ˆæ€§ |

> å›¾ 7 æ˜¾ç¤ºï¼Œåœ¨å¤šæ•°æ•°æ®é›†ä¸Šï¼ŒSHIRO çš„æ‰§è¡Œæ—¶é—´éš GPU æ•°å¢åŠ è€Œä¸‹é™ï¼ˆè‰¯å¥½æ‰©å±•æ€§ï¼‰ï¼Œè€Œå…¶ä»–æ–¹æ³•åœ¨è¶…è¿‡ 8 GPU åæ€§èƒ½æ¶åŒ–ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ï¼ˆ1ï¼‰é€šä¿¡ä½“ç§¯å‡å°‘ï¼ˆå›¾ 8ï¼‰
- **Joint row-col vs Col-based**ï¼š
  - å¹³å‡é€šä¿¡é‡å‡å°‘ 30â€“70%ï¼Œåœ¨ `mawi` ä¸Šè¾¾ 96%
  - é€šä¿¡æ¨¡å¼æ›´å‡è¡¡ï¼Œæ¶ˆé™¤çƒ­ç‚¹é€šä¿¡å¯¹ï¼ˆè§å›¾ 9ï¼‰

- **åŠ å…¥ Hierarchical ç­–ç•¥å**ï¼š
  - è¿›ä¸€æ­¥å‡å°‘è·¨èŠ‚ç‚¹é€šä¿¡é‡ï¼ˆinter-node volumeï¼‰
  - åœ¨ `com-LJ`, `Orkut`, `sx-SO` ä¸Šæ•ˆæœæœ€æ˜æ˜¾

#### ï¼ˆ2ï¼‰é€æ­¥ä¼˜åŒ–æ•ˆæœï¼ˆå›¾ 10ï¼‰
- ä¸‰é˜¶æ®µæ¶ˆèï¼š
  1. Baseï¼ˆcol-basedï¼‰
  2. + Joint row-col
  3. + Hierarchical
- æ‰€æœ‰æ•°æ®é›†ä¸Šå‡æœ‰æŒç»­æ€§èƒ½æå‡ï¼ŒéªŒè¯ä¸¤ä¸ªæ¨¡å—çš„æ­£äº¤æ€§å’Œæœ‰æ•ˆæ€§ã€‚

> å”¯ä¸€ä¾‹å¤–æ˜¯ `del24`ï¼Œå› å…¶é€šä¿¡æåº¦ä¸å‡è¡¡ï¼Œå±‚æ¬¡åŒ–æ‹†åˆ†åè€Œé™ä½é“¾è·¯åˆ©ç”¨ç‡ã€‚

#### ï¼ˆ3ï¼‰ä¸åŒç¨ å¯†åˆ—æ•° N çš„å½±å“ï¼ˆå›¾ 11ï¼‰
- å¤šæ•°æ•°æ®é›†ï¼šè¿è¡Œæ—¶é—´éš N çº¿æ€§å¢é•¿ â†’ **é€šä¿¡ååå—é™**
- å°‘æ•°ï¼ˆå¦‚ `arabic`ï¼‰ï¼šN å¢å¤§åå¢é€Ÿæ”¾ç¼“ â†’ **é€šä¿¡å»¶è¿Ÿå—é™**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **å•ç»´åº¦ç¨€ç–æ„ŸçŸ¥ä¸è¶³ä»¥æœ€å¤§åŒ–é€šä¿¡æ•ˆç‡**ï¼š
   - è”åˆåˆ©ç”¨è¡Œå’Œåˆ—ç¨€ç–æ¨¡å¼å¯æ˜¾è‘—å‡å°‘é€šä¿¡é‡ï¼Œå°¤å…¶åœ¨éé›¶å…ƒåˆ†å¸ƒå¤æ‚çš„çŸ©é˜µä¸Šã€‚

2. **å±‚æ¬¡åŒ–ç½‘ç»œå¿…é¡»æ˜¾å¼å»ºæ¨¡**ï¼š
   - å¿½è§† NVLink/InfiniBand å·®å¼‚ä¼šå¯¼è‡´ä¸¥é‡å†—ä½™ï¼›
   - é€šè¿‡ç»„å†…èšåˆ + è·¨ç»„ä¼ è¾“å¯å¤§å¹…å‡å°‘æ…¢é“¾è·¯è´Ÿè½½ã€‚

3. **ä¸¤ç§ä¼˜åŒ–å¯å åŠ ä¸”äº’è¡¥**ï¼š
   - å…ˆåšè”åˆä¼˜åŒ–é™ä½æ€»é‡ï¼Œå†åšå±‚æ¬¡ä¼˜åŒ–é™ä½è·¨èŠ‚ç‚¹æµé‡ï¼›
   - é‡å è°ƒåº¦è¿›ä¸€æ­¥æå‡å¸¦å®½åˆ©ç”¨ç‡ã€‚

4. **SHIRO å…·å¤‡å¼ºæ‰©å±•æ€§**ï¼š
   - åœ¨ 128 ä¸ª H100 GPU ä¸Šä»èƒ½æœ‰æ•ˆæ‰©å±•ï¼Œè¿œè¶…ç°æœ‰æ–¹æ³•ï¼ˆé€šå¸¸åªèƒ½æ‰©å±•åˆ° 8 GPUï¼‰ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **é¢„å¤„ç†å¼€é”€**ï¼š
   - æœ€å°é¡¶ç‚¹è¦†ç›–æ±‚è§£éœ€ç¦»çº¿è¿›è¡Œï¼Œè™½ç„¶å¯å¤ç”¨ï¼Œä½†å¯¹åŠ¨æ€å›¾æˆ–é¢‘ç¹å˜åŒ–çš„ç¨€ç–æ¨¡å¼å¯èƒ½ä¸é€‚ç”¨ã€‚

2. **æç«¯ä¸å‡è¡¡é€šä¿¡æ¨¡å¼ä¸‹æ€§èƒ½é€€åŒ–**ï¼š
   - å¦‚ `del24`ï¼Œå±‚æ¬¡åŒ–æ‹†åˆ†å¯èƒ½å¯¼è‡´è´Ÿè½½ä¸å‡ï¼Œå½±å“æ€§èƒ½ã€‚

3. **å½“å‰å®ç°åŸºäº 1D åˆ†åŒº**ï¼š
   - è™½ç„¶å¯æ¨å¹¿ï¼Œä½†æœªåœ¨ 2D æˆ– 1.5D åˆ†åŒºä¸Šç³»ç»ŸéªŒè¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ”¯æŒåŠ¨æ€ç¨€ç–æ¨¡å¼**ï¼š
   - å¼€å‘è½»é‡çº§åœ¨çº¿ä¼˜åŒ–å™¨ï¼Œé€‚åº”å›¾ç»“æ„åŠ¨æ€å˜åŒ–çš„åº”ç”¨ï¼ˆå¦‚åŠ¨æ€ GNNï¼‰ã€‚

2. **ç»“åˆå›¾åˆ†åŒºæŠ€æœ¯**ï¼š
   - ä¸ hypergraph partitioning æˆ– Arrow decomposition è”åˆä¼˜åŒ–ï¼Œè¿›ä¸€æ­¥å‡å°‘é€šä¿¡è¾¹ç•Œã€‚

3. **æ‰©å±•è‡³ SpGEMM**ï¼š
   - å°†ç±»ä¼¼æ€æƒ³åº”ç”¨äºç¨€ç–-ç¨€ç–çŸ©é˜µä¹˜æ³•ï¼ˆSpGEMMï¼‰ã€‚

4. **å¼‚æ„é›†ç¾¤ä¼˜åŒ–**ï¼š
   - æ”¯æŒ CPU-GPU æ··åˆé›†ç¾¤æˆ–å¤šçº§å­˜å‚¨æ¶æ„ã€‚

---

> **æ€»ç»“**ï¼šSHIRO é€šè¿‡**è”åˆè¡Œåˆ—ç¨€ç–æ„ŸçŸ¥**ä¸**å±‚æ¬¡åŒ–é€šä¿¡è°ƒåº¦**ï¼Œå®ç°äº†è¿‘æœ€ä¼˜çš„åˆ†å¸ƒå¼ SpMM é€šä¿¡æ•ˆç‡ï¼Œåœ¨çœŸå®æ•°æ®é›†å’Œå¤§è§„æ¨¡ GPU é›†ç¾¤ä¸Šå±•ç°å‡ºæ˜¾è‘—æ€§èƒ½ä¼˜åŠ¿å’Œå“è¶Šå¯æ‰©å±•æ€§ï¼Œä¸º GNNã€å›¾è®¡ç®—ç­‰åº”ç”¨æä¾›äº†å¼ºæœ‰åŠ›çš„åº•å±‚æ”¯æ’‘ã€‚

</details>

---

### 4. [EdgeFlex-Transformer: Transformer Inference for Edge Devices](https://arxiv.org/abs/2512.19741)

**Authors**: Shoaib Mohammad, Guanqun Song, Ting Zhu  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.19741v1  

#### Abstract
Deploying large-scale transformer models on edge devices presents significant challenges due to strict constraints on memory, compute, and latency. In this work, we propose a lightweight yet effective multi-stage optimization pipeline designed to compress and accelerate Vision Transformers (ViTs) fo...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡ã€ŠEdgeFlex-Transformer: Transformer Inference for Edge Devicesã€‹æ ¸å¿ƒæ€»ç»“**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
Vision Transformers (ViTs) åœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†ç”±äºå…¶é«˜å†…å­˜å ç”¨ã€è®¡ç®—å¯†é›†æ€§å’Œå»¶è¿Ÿé—®é¢˜ï¼Œåœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ï¼ˆå¦‚ç§»åŠ¨è®¾å¤‡ã€IoTä¼ æ„Ÿå™¨ï¼‰ä¸Šéƒ¨ç½²é¢ä¸´å·¨å¤§æŒ‘æˆ˜ã€‚ä¼ ç»Ÿå‹ç¼©æ–¹æ³•å¾€å¾€ä¾èµ–é‡è®­ç»ƒã€å¤æ‚çš„æ¶æ„æœç´¢æˆ–äº§ç”Ÿç¡¬ä»¶ä¸å‹å¥½çš„ç¨€ç–æ¨¡å¼ï¼Œéš¾ä»¥åœ¨çœŸå®è¾¹ç¼˜åœºæ™¯ä¸­é«˜æ•ˆéƒ¨ç½²ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹æ ¸å¿ƒçŸ›ç›¾ï¼š
- å¦‚ä½•åœ¨**ä¸ç‰ºç‰²ç²¾åº¦çš„å‰æä¸‹**ï¼Œæ˜¾è‘—é™ä½ ViT æ¨¡å‹çš„**å³°å€¼å†…å­˜ä½¿ç”¨é‡å’Œæ¨ç†å»¶è¿Ÿ**ï¼›
- å¦‚ä½•è®¾è®¡ä¸€ç§**æ— éœ€é‡è®­ç»ƒã€è½»é‡çº§ä¸”æ¨¡å—åŒ–**çš„ä¼˜åŒ–æµç¨‹ï¼Œé€‚ç”¨äºå¤šç§ ViT æ¶æ„å’Œå¼‚æ„è¾¹ç¼˜å¹³å°ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **EdgeFlex-Transformer** çš„å¤šé˜¶æ®µä¼˜åŒ–æµæ°´çº¿ï¼Œç»“åˆäº†å››ç§å…³é”®æŠ€æœ¯ï¼Œå½¢æˆä¸€ä¸ªæ¸è¿›å¼ã€è®­ç»ƒå…è´¹ï¼ˆtraining-freeï¼‰çš„å‹ç¼©ä¸åŠ é€Ÿæ¡†æ¶ï¼š

1. **Activation Profilingï¼ˆæ¿€æ´»åˆ†æï¼‰**  
   åˆ©ç”¨å‰å‘é’©å­ï¼ˆforward hooksï¼‰åœ¨ MLP å±‚æ”¶é›†æ¿€æ´»ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚å¹³å‡ç»å¯¹æ¿€æ´»å€¼ï¼‰ï¼Œè¯†åˆ«ä½é‡è¦æ€§é€šé“ã€‚

2. **Memory-Aware Structured Pruningï¼ˆå†…å­˜æ„ŸçŸ¥ç»“æ„åŒ–å‰ªæï¼‰**  
   åŸºäºæ¿€æ´»å¼ºåº¦å¯¹ MLP è¾“å‡ºé€šé“è¿›è¡Œæ’åºï¼Œå¹¶å‰ªé™¤æœ€ä¸æ´»è·ƒçš„é€šé“ï¼ˆä¾‹å¦‚æœ€ä½ 10%ï¼‰ï¼Œå®ç°ç»“æ„åŒ–ç¨€ç–ï¼Œå…¼å®¹ç°ä»£ç¡¬ä»¶æ‰§è¡Œå•å…ƒã€‚

3. **Selective Mixed-Precision Executionï¼ˆé€‰æ‹©æ€§æ··åˆç²¾åº¦æ‰§è¡Œï¼‰**  
   å¯¹éƒ¨åˆ†å­æ¨¡å—å¯ç”¨ FP16 ç²¾åº¦ï¼ˆé€šè¿‡ PyTorch AMPï¼‰ï¼Œå‡å°‘å†…å­˜å¹¶æå‡ååï¼ŒåŒæ—¶ä¿ç•™å…³é”®å±‚ä¸º FP32 ä»¥ç»´æŒæ•°å€¼ç¨³å®šæ€§ã€‚

4. **Activation-Aware Quantization (AWQ)**  
   å°†æƒé‡å’Œæ¿€æ´»é‡åŒ–è‡³ INT8ï¼Œåˆ©ç”¨æ¯é€šé“ç¼©æ”¾å› å­ï¼ˆchannel-wise scalingï¼‰ä¿æŠ¤æ•æ„Ÿé€šé“ï¼Œæœ€å°åŒ–é‡åŒ–å¸¦æ¥çš„ç²¾åº¦æŸå¤±ã€‚

> âœ… æ•´ä¸ªæµç¨‹æ— éœ€æ¨¡å‹å¾®è°ƒæˆ–é‡æ–°è®­ç»ƒï¼Œå…·å¤‡é«˜åº¦å¯ç§»æ¤æ€§å’Œå®ç”¨æ€§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹æ³• | ç¼ºé™· | EdgeFlex çš„ä¼˜åŠ¿ |
|------|------|------------------|
| Unstructured Pruning | äº§ç”Ÿä¸è§„åˆ™ç¨€ç–ï¼Œç¡¬ä»¶éš¾åŠ é€Ÿ | ç»“æ„åŒ–å‰ªæï¼Œç¡¬ä»¶å‹å¥½ |
| Naive Quantization | æ˜“å¯¼è‡´æ˜¾è‘—ç²¾åº¦ä¸‹é™ | AWQ åŸºäºæ¿€æ´»æ•æ„Ÿæ€§ä¿æŠ¤å…³é”®é€šé“ |
| Knowledge Distillation | éœ€å¤æ‚è®­ç»ƒæµç¨‹ï¼Œæ³›åŒ–å·® | å®Œå…¨æ— éœ€è®­ç»ƒ |
| NAS | æœç´¢æˆæœ¬æé«˜ï¼Œä¸å¯æ‰©å±• | è½»é‡çº§ã€å¿«é€Ÿé€‚é…ä¸åŒè®¾å¤‡ |
| å•ä¸€ä¼˜åŒ–æŠ€æœ¯ | æ”¹è¿›æœ‰é™ | å¤šé˜¶æ®µååŒä¼˜åŒ–ï¼Œæ•ˆæœå åŠ  |

> ğŸ”‘ **æ ¸å¿ƒåˆ›æ–°åœ¨äºå°† activation profiling ä½œä¸ºç»Ÿä¸€æŒ‡å¯¼ä¿¡å·ï¼Œè´¯ç©¿å‰ªæä¸é‡åŒ–å…¨è¿‡ç¨‹ï¼Œå®ç°äº†â€œæ„ŸçŸ¥æ¿€æ´» â†’ å†³ç­–å‰ªæ â†’ ç²¾ç»†é‡åŒ–â€çš„é—­ç¯ä¼˜åŒ–ç­–ç•¥**ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **CIFAR-10**ï¼šç”¨äºæ¿€æ´»æ ¡å‡†ï¼ˆcalibrationï¼‰å’Œæœ€ç»ˆæµ‹è¯•ã€‚
  - æ ¡å‡†é›†ï¼š32 ä¸ªæ ·æœ¬ï¼ˆæå°è§„æ¨¡ï¼Œä½“ç°è½»é‡æ€§ï¼‰
  - æµ‹è¯•é›†ï¼šå…¨éƒ¨ 10,000 å¼ å›¾åƒ

---

### **å®éªŒè®¾ç½®**
- **åŸºç¡€æ¨¡å‹**ï¼šViT-Hugeï¼ˆ32 å±‚ï¼Œéšè—ç»´åº¦ 1280ï¼ŒMLP ç»´åº¦ 5120ï¼Œæ€»å‚æ•°çº¦ 6.32 äº¿ï¼‰
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA A100 GPUï¼ˆæ¥è‡ª Ohio Super-Computing Center çš„ Ascend é›†ç¾¤ï¼‰ï¼Œå¯ç”¨äº†å†…å­˜å‰–æåŠŸèƒ½
- **æ‰¹å¤§å°ï¼ˆbatch sizeï¼‰**ï¼š32
- **å®ç°å·¥å…·**ï¼šPyTorch + Hugging Face Transformers åº“

---

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Accuracy (%)** | Top-1 å‡†ç¡®ç‡ |
| **Average Batch Latency (s)** | å•æ‰¹æ¬¡å¹³å‡æ¨ç†æ—¶é—´ |
| **Total Inference Time (s)** | æ¨ç†å®Œæ•´æµ‹è¯•é›†æ‰€éœ€æ€»æ—¶é—´ |
| **Peak Memory Usage (MB)** | æ¨ç†è¿‡ç¨‹ä¸­æœ€å¤§å†…å­˜å ç”¨ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
å…±æ¯”è¾ƒäº†å››ä¸ªæ¨¡å‹å˜ä½“ï¼š

| å˜ä½“ | è¯´æ˜ |
|------|------|
| **Original FP32** | åŸå§‹æœªä¿®æ”¹çš„ ViT-Huge æ¨¡å‹ |
| **Pruned FP32** | ç»è¿‡ç»“æ„åŒ–å‰ªæåçš„ FP32 æ¨¡å‹ |
| **Pruned + FP16** | å‰ªæåå¯ç”¨æ··åˆç²¾åº¦ï¼ˆFP16ï¼‰ |
| **Pruned + AWQ** | å‰ªæååº”ç”¨ AWQ é‡åŒ–è‡³ INT8 |

> âš ï¸ æ‰€æœ‰ä¼˜åŒ–å‡æ—  fine-tuning æˆ– retrainingã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Fig. 3ï¼‰**

| Variant | Accuracy (%) | Avg Batch Latency (s) | Total Time (s) | Peak Memory (MB) |
|--------|---------------|------------------------|----------------|------------------|
| Original FP32 | 8.56 | 0.194 | 25.07 | 2613.45 |
| Pruned FP32 | 7.78 | 0.198 | 25.68 | ~2528 |
| Pruned + FP16 | **11.67** | **0.028** | **4.15** | **1356.10** |
| Pruned + AWQ | 11.28 | 0.199 | 25.79 | **623** |

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### âœ… **å†…å­˜æ•ˆç‡**
- **Pruned + AWQ** å®ç° **76.2% çš„å³°å€¼å†…å­˜ä¸‹é™**ï¼ˆä» 2613 MB â†’ 623 MBï¼‰ï¼Œè¿œä½äºå…¸å‹è¾¹ç¼˜è®¾å¤‡ <100MB çš„é™åˆ¶ç›®æ ‡ï¼ˆæ³¨ï¼šæ­¤å¤„å¯èƒ½ä¸ºæŠ¥å‘Šå•ä½è¯¯å·®æˆ–ä»…æŒ‡æ¨¡å‹é™æ€åŠ è½½å†…å­˜ä»¥å¤–çš„éƒ¨åˆ†ï¼›å®é™…ä»åé«˜ï¼Œä½†è¶‹åŠ¿æ˜ç¡®ï¼‰ã€‚
- **Pruned + FP16** å†…å­˜å‡åŠï¼ˆâ†“48.1%ï¼‰ï¼Œé€‚åˆä¸­ç­‰èµ„æºè®¾å¤‡ã€‚

#### âœ… **æ¨ç†é€Ÿåº¦**
- **Pruned + FP16** è¾¾åˆ° **6.9Ã— åŠ é€Ÿ**ï¼ˆæ€»æ—¶é—´ä» 25.07s â†’ 4.15sï¼‰ï¼Œå¹³å‡æ‰¹å»¶è¿Ÿé™ä½ **6.9Ã—**ï¼ˆ0.194 â†’ 0.028sï¼‰ï¼Œæ˜¯æ‰€æœ‰å˜ä½“ä¸­æœ€ä¼˜ã€‚
- AWQ ç‰ˆæœ¬è™½æœªæé€Ÿï¼ˆå› æœªä½¿ç”¨ä¸“ç”¨ INT8 kernelï¼‰ï¼Œä½†ä¸ºæœªæ¥ç¡¬ä»¶åŠ é€Ÿç•™å‡ºç©ºé—´ã€‚

#### âœ… **ç²¾åº¦è¡¨ç°**
- æ‰€æœ‰ä¼˜åŒ–ç‰ˆæœ¬å‡æœªå‡ºç°ä¸¥é‡ç²¾åº¦é€€åŒ–ã€‚
- **ä»¤äººæ„å¤–çš„æ˜¯ï¼ŒPruned + FP16 å’Œ Pruned + AWQ çš„å‡†ç¡®ç‡åè€Œé«˜äºåŸå§‹æ¨¡å‹ï¼ˆ~11.3% vs 8.56%ï¼‰**ï¼Œæ¨æµ‹åŸå› å¯èƒ½æ˜¯ï¼š
  - FP16 æå‡äº†è®­ç»ƒ/æ¨ç†ä¸€è‡´æ€§ï¼ˆå°½ç®¡æœª fine-tuneï¼‰
  - å‰ªæå»é™¤äº†å™ªå£°é€šé“ï¼Œèµ·åˆ°æ­£åˆ™åŒ–ä½œç”¨
  - æ•°æ®åˆ†å¸ƒä¸ ViT å…ˆéªŒæ›´åŒ¹é…ï¼ˆCIFAR-10 ä¸Š ViT é€šå¸¸éœ€ fine-tune æ‰èƒ½å‘æŒ¥æ½œåŠ›ï¼Œæ­¤å¤„åŸå§‹æ€§èƒ½åä½å±æ­£å¸¸ç°è±¡ï¼‰

---

### **æ¶ˆèå®éªŒç»“æœ**
è™½ç„¶æ–‡ä¸­æœªæ˜ç¡®æ ‡æ³¨â€œablation studyâ€ç« èŠ‚ï¼Œä½†ä»ä¸åŒå˜ä½“çš„ç»“æœå¯è§†ä¸ºå¤©ç„¶çš„æ¶ˆèåˆ†æï¼š

| ä¼˜åŒ–æ­¥éª¤ | å†…å­˜å˜åŒ– | å»¶è¿Ÿå˜åŒ– | ç²¾åº¦å½±å“ | è´¡çŒ®æ€»ç»“ |
|--------|---------|----------|-----------|------------|
| å‰ªæï¼ˆPruningï¼‰ | â†“~3.3% | â†‘è½»å¾® | â†“0.78% | è´¡çŒ®æœ‰é™ï¼Œä½†ä¸ºåç»­æ‰“åŸºç¡€ |
| + FP16 | â†“48% | â†“6.9Ã— | â†‘+3.1% | æœ€å¤§åŠ é€Ÿæ¥æºï¼Œç²¾åº¦åå‡ |
| + AWQ | â†“76% | â‰ˆæŒå¹³ | â†‘+2.7% | æè‡´å†…å­˜å‹ç¼©ï¼Œé€‚åˆè¾¹ç¼˜ |

> ğŸ“Œ **ç»“è®ºï¼šå•ä¸€å‰ªææ•ˆæœæœ‰é™ï¼ŒçœŸæ­£çš„æ€§èƒ½é£è·ƒæ¥è‡ªäºâ€œå‰ªæ + æ··åˆç²¾åº¦â€æˆ–â€œå‰ªæ + AWQâ€çš„ç»„åˆæ•ˆåº”**ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **å¤šé˜¶æ®µååŒä¼˜åŒ–ä¼˜äºå•ä¸€æŠ€æœ¯**ï¼šå•ç‹¬å‰ªææ”¶ç›Šè¾ƒå°ï¼Œä½†ä½œä¸ºå‰ç½®æ­¥éª¤å¯ä¸ºé‡åŒ–/æ··åˆç²¾åº¦æä¾›æ›´å¥½èµ·ç‚¹ã€‚
2. **æ— éœ€é‡è®­ç»ƒä¹Ÿèƒ½ä¿æŒç”šè‡³æå‡ç²¾åº¦**ï¼šå¾—ç›Šäº activation-aware è®¾è®¡ï¼Œå°¤å…¶æ˜¯ AWQ å’Œ FP16 çš„æ•°å€¼ç¨³å®šæ€§å’Œæ½œåœ¨æ­£åˆ™åŒ–æ•ˆåº”ã€‚
3. **EdgeFlex å®ç°äº†æ˜¾è‘—çš„èµ„æºèŠ‚çº¦**ï¼š
   - å†…å­˜æœ€é«˜å‡å°‘ **76%+**
   - æ¨ç†å»¶è¿Ÿæœ€å¤šé™ä½ **6.9Ã—**
   - æ€»æ¨ç†æ—¶é—´ç¼©çŸ­ **83.4%**
4. **AWQ åœ¨ INT8 ä¸‹è¡¨ç°å‡ºè‰²**ï¼šå³ä½¿æ²¡æœ‰ä¸“ç”¨ INT8 åŠ é€Ÿå™¨ï¼Œä¹Ÿèƒ½åœ¨å‡ ä¹ä¸æŸç²¾åº¦çš„æƒ…å†µä¸‹å®ç°é«˜å‹ç¼©æ¯”ï¼Œå…·å¤‡è‰¯å¥½æ‰©å±•å‰æ™¯ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **å½“å‰å®éªŒåŸºäº A100 GPU**ï¼Œå°šæœªåœ¨çœŸå®è¾¹ç¼˜èŠ¯ç‰‡ï¼ˆå¦‚æ‰‹æœº NPUã€MCUï¼‰ä¸ŠéªŒè¯ç«¯åˆ°ç«¯æ€§èƒ½ã€‚
2. **CIFAR-10 ä¸Š ViT åŸå§‹æ€§èƒ½åä½**ï¼ˆ8.56%ï¼‰ï¼Œè¡¨æ˜æ¨¡å‹æœªç»é¢„è®­ç»ƒæˆ–è¿ç§»å­¦ä¹ ï¼Œå¯èƒ½å½±å“ç»“è®ºæ™®é€‚æ€§ã€‚
3. **AWQ æ¨ç†æœªåŠ é€Ÿ**ï¼šç”±äºç¼ºä¹ INT8 kernel èåˆæ”¯æŒï¼Œå»¶è¿Ÿæœªæ”¹å–„ï¼Œä¾èµ–åº•å±‚è¿è¡Œæ—¶ä¼˜åŒ–ã€‚
4. **ä»…åº”ç”¨äº ViT-Huge**ï¼ŒæœªéªŒè¯åœ¨å…¶ä»– ViT å˜ä½“ï¼ˆå¦‚ ViT-Base/Tinyï¼‰æˆ–å…¶ä»–æ¨¡æ€ï¼ˆå¦‚ NLPï¼‰ä¸­çš„é€šç”¨æ€§ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆåŸæ–‡ IX èŠ‚ï¼‰**
1. **æ‰©å±•è‡³ Mixture-of-Experts (MoE) æ¶æ„**ï¼šæ¢ç´¢åŠ¨æ€ç¨€ç–ä¸“å®¶ç½‘ç»œçš„å‰ªæä¸é‡åŒ–ç­–ç•¥ã€‚
2. **Task-Aware Pruning**ï¼šå¼•å…¥ä¸‹æ¸¸ä»»åŠ¡åé¦ˆæœºåˆ¶ï¼ŒæŒ‡å¯¼å‰ªæä¼˜å…ˆçº§ã€‚
3. **Layer-wise Dynamic Precision Control**ï¼šæŒ‰å±‚åŠ¨æ€åˆ‡æ¢ FP32/FP16/INT8ï¼Œè¿›ä¸€æ­¥èŠ‚çœèƒ½è€—ã€‚
4. **é›†æˆå®æ—¶è°ƒåº¦ç³»ç»Ÿ**ï¼šä¸è¾¹ç¼˜æ“ä½œç³»ç»Ÿè”åŠ¨ï¼Œå®ç°åŠ¨æ€èµ„æºåˆ†é…ä¸æ¨ç†è°ƒåº¦ã€‚

---

## **æ€»ç»“**
> **EdgeFlex-Transformer æä¾›äº†ä¸€ä¸ªå®ç”¨ã€æ¨¡å—åŒ–ã€æ— éœ€é‡è®­ç»ƒçš„ ViT å‹ç¼©æ¡†æ¶ï¼Œé€šè¿‡ activation profiling é©±åŠ¨çš„â€œå‰ªæ + æ··åˆç²¾åº¦ + AWQâ€ä¸‰æ­¥èµ°ç­–ç•¥ï¼Œåœ¨ CIFAR-10 ä¸Šå®ç°äº†é«˜è¾¾ 76% çš„å†…å­˜å‹ç¼©å’Œè¿‘ 7Ã— çš„å»¶è¿Ÿé™ä½ï¼Œä¸”ç²¾åº¦ä¸é™åå‡ã€‚è¯¥å·¥ä½œä¸ºå¤§è§„æ¨¡ Transformer åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„é«˜æ•ˆéƒ¨ç½²æä¾›äº†å¯è¡Œè·¯å¾„ï¼Œå¹¶ä¸ºæœªæ¥åŠ¨æ€ç¨€ç–ä¸ç»¿è‰² AI è®¡ç®—å¥ å®šåŸºç¡€ã€‚**

ğŸ”— **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/Shoaib-git20/EdgeFlex.git](https://github.com/Shoaib-git20/EdgeFlex.git)

</details>

---

### 5. [Multi-hop Reasoning via Early Knowledge Alignment](https://arxiv.org/abs/2512.20144)

**Authors**: Yuxin Wang, Shicheng Fang, Bo Wang, Qi Luo, Xuanjing Huang, Yining Zheng, Xipeng Qiu  
**Category**: cs.CL  
**Published**: 2025-12-24  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.20144v1  

#### Abstract
Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for Large Language Models (LLMs) to address knowledge-intensive queries requiring domain-specific or up-to-date information. To handle complex multi-hop questions that are challenging for single-step retrieval, iterative RAG app...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Multi-hop Reasoning via Early Knowledge Alignment*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **Iterative RAG** ç³»ç»Ÿåœ¨å¤„ç†å¤æ‚å¤šè·³æ¨ç†ä»»åŠ¡æ—¶ï¼Œé€šå¸¸åœ¨æ²¡æœ‰åˆ©ç”¨æ£€ç´¢è¯­æ–™åº“ä¿¡æ¯çš„æƒ…å†µä¸‹è¿›è¡Œé—®é¢˜åˆ†è§£å’Œåˆå§‹è§„åˆ’ï¼ˆplanningï¼‰ï¼Œå¯¼è‡´ï¼š
- **è®¡åˆ’å¤±è´¥ï¼ˆplan failureï¼‰**ï¼šåˆå§‹æ€è€ƒæ­¥éª¤ç¼ºä¹ä¸Šä¸‹æ–‡æ”¯æ’‘ï¼Œäº§ç”Ÿè¯¯å¯¼æ€§å‡è®¾ï¼›
- **çº§è”é”™è¯¯ï¼ˆcascading errorsï¼‰**ï¼šé”™è¯¯çš„æ£€ç´¢è·¯å¾„å¼•å‘åç»­æ¨ç†åå·®ï¼›
- **ä½æ•ˆæ¢ç´¢ï¼ˆinefficient explorationï¼‰**ï¼šåœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒä¸­ï¼Œæ¨¡å‹ç›²ç›®æ¢ç´¢ï¼Œå¢åŠ å™ªå£°ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šEarly Knowledge Alignment (EKA)
ä½œè€…æå‡º **Early Knowledge Alignment (EKA)**ï¼Œä¸€ç§ç®€å•ä½†æœ‰æ•ˆçš„æ¨¡å—ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> åœ¨ LLM å¼€å§‹æ¨ç†å‰ï¼Œå…ˆä»æ£€ç´¢ç³»ç»Ÿè·å–åˆæ­¥ç›¸å…³çŸ¥è¯†ï¼ˆearly knowledgeï¼‰ï¼Œå¹¶å°†å…¶ä½œä¸ºåˆå§‹ä¸Šä¸‹æ–‡è¾“å…¥ï¼Œä»è€Œå®ç°â€œçŸ¥è¯†å¯¹é½â€ã€‚

#### å…·ä½“æµç¨‹ï¼š
1. ç»™å®šé—®é¢˜ $ q $ï¼Œé¦–å…ˆæ‰§è¡Œä¸€æ¬¡ `Retrieve(q, D, k)` è·å– top-k æ–‡æ¡£ $ P_0 $ï¼›
2. å°† $ P_0 $ æ³¨å…¥æç¤ºè¯ä¸­ï¼ˆç½®äº `<knowledge>...</knowledge>` å†…ï¼‰ï¼›
3. LLM åŸºäºè¯¥çŸ¥è¯†å¼€å§‹é¦–æ¬¡ `Think` æ­¥éª¤ï¼Œåç»­æŒ‰æ ‡å‡†è¿­ä»£æµç¨‹è¿›è¡Œ `Search` å’Œ `Think`ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- âœ… **æ›´å¼ºçš„æ¨ç†åŸºç¡€**ï¼šé€šè¿‡æ—©æœŸçŸ¥è¯†æä¾›ä¸Šä¸‹æ–‡é”šç‚¹ï¼Œå‡å°‘æ— ä¾æ®çŒœæµ‹ï¼›
- âœ… **é™ä½ç†µå€¼ï¼ˆentropyï¼‰**ï¼šä½¿æ¨¡å‹åœ¨ RL æ¢ç´¢è¿‡ç¨‹ä¸­æ›´èšç„¦ã€æ›´ç¡®å®šï¼›
- âœ… **æå‡æ£€ç´¢ç²¾åº¦ä¸æ•ˆç‡**ï¼šå‡å°‘æ— æ•ˆæŸ¥è¯¢ï¼Œæé«˜ R-S åˆ†æ•°ï¼›
- âœ… **æ— éœ€è®­ç»ƒçš„å³æ’å³ç”¨ç­–ç•¥**ï¼šå¯ä½œä¸º inference-time æ¨¡å—ç›´æ¥åº”ç”¨äºå¤§æ¨¡å‹ï¼›
- âœ… **é€šç”¨æ€§å¼º**ï¼šå…¼å®¹ä¸åŒ RL ç®—æ³•ï¼ˆå¦‚ GRPOã€PPOï¼‰ã€ä¸åŒ backbone æ¨¡å‹å’Œæ£€ç´¢æ¶æ„ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ä¸¤ä¸ªä¸»æµ RAG å®éªŒè®¾ç½®ä¸‹éªŒè¯ï¼š
- **Graph-R1 è®¾ç½®**ï¼šä½¿ç”¨ 6 ä¸ªæ ‡å‡† QA æ•°æ®é›†
  - 2WikiHop
  - HotpotQA
  - Musique
  - NQ (Natural Questions)
  - PopQA
  - TriviaQA
- **Search-R1 è®¾ç½®**ï¼šé¢å¤–åŠ å…¥ **Bamboogle**ï¼ŒåŒºåˆ† in-domain (IND) ä¸ out-of-domain (OOD) æµ‹è¯•ã€‚

### å®éªŒè®¾ç½®
- **Backbone æ¨¡å‹**ï¼š
  - Qwen2.5-7B-Instruct
  - Qwen2.5-14B-Instruct
  - GPT-4o-miniï¼ˆç”¨äºéƒ¨åˆ†åŸºçº¿ï¼‰
- **RL è®­ç»ƒæ¡†æ¶**ï¼š
  - GRPOï¼ˆGroup Relative Policy Optimizationï¼‰
  - PPOï¼ˆProximal Policy Optimizationï¼‰
- **æœ€å¤§æ¨ç†è½®æ¬¡**ï¼šé»˜è®¤ä¸ºå¤šè½®äº¤äº’å¼æ£€ç´¢ç”Ÿæˆã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **EM** | Exact Matchï¼Œç­”æ¡ˆå®Œå…¨åŒ¹é…ç‡ |
| **F1** | ç”Ÿæˆç­”æ¡ˆä¸çœŸå®ç­”æ¡ˆçš„ token çº§ F1 åˆ†æ•° |
| **R-S (Retrieval Similarity)** | æ£€ç´¢åˆ°çš„å†…å®¹ä¸â€œé»„é‡‘â€ä¸Šä¸‹æ–‡ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆåŸºäºåµŒå…¥å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | æ–¹æ³• |
|------|------|
| **éè®­ç»ƒæ–¹æ³•** | NaiveGeneration, StandardRAG, GraphRAG, LightRAG, PathRAG, HippoRAG2, HyperGraphRAG |
| **ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰** | SFT |
| **RL æ–¹æ³•** | R1, R1-Searcher, Search-R1, Search-R1-PPO, Graph-R1 |
| **å…¶ä»–æ¨ç†ç­–ç•¥** | CoT, IRCoT, Search-o1, Rejection Sampling |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ€§èƒ½æå‡æ˜¾è‘—ï¼ˆä»¥ F1 ä¸ºä¸»ï¼‰

#### åœ¨ Graph-R1 è®¾ç½®ä¸‹çš„å¹³å‡æå‡ï¼ˆQwen2.5-7Bï¼‰ï¼š
| æ–¹æ³• | +EKA å F1 æå‡ |
|------|----------------|
| Graph-R1 | **+2.83** |
| Search-R1 | **+11.64** |
| Search-R1-PPO | **+7.67** |

> è¡¨æ˜ EKA å¯¹å¼±åˆå§‹è§„åˆ’çš„æ–¹æ³•ï¼ˆå¦‚ Search-R1ï¼‰å¢ç›Šæ›´å¤§ã€‚

#### åœ¨ Search-R1 è®¾ç½®ä¸‹çš„è¡¨ç°ï¼š
| æ–¹æ³• | å¹³å‡ F1 æå‡ |
|------|-------------|
| Search-R1 | **+6.3** |

å³ä½¿åœ¨å¤§è§„æ¨¡ Fullwiki æ£€ç´¢é›†ä¸­ï¼ŒEKA ä»å¸¦æ¥ç¨³å®šå¢ç›Šï¼Œè¯´æ˜å…¶å¯¹æ£€ç´¢è§„æ¨¡ä¸æ•æ„Ÿã€‚

#### å¤§æ¨¡å‹ä¸Šçš„è®­ç»ƒå…è´¹æ•ˆæœï¼ˆTraining-free Inferenceï¼‰
| æ¨¡å‹ | +EKA å¹³å‡ F1 æå‡ |
|------|------------------|
| Qwen2.5-32B-Instruct | +4.0 ~ +6.0 |
| Qwen3-235-A30B-Instruct | +5.0 ~ +8.0 |

> éªŒè¯äº† EKA å¯ä½œä¸º plug-and-play æ¨¡å—ç”¨äºè¶…å¤§æ¨¡å‹ï¼Œé¿å…æ˜‚è´µçš„ RL å¾®è°ƒã€‚

### æ£€ç´¢è´¨é‡æå‡ï¼ˆR-S æŒ‡æ ‡ï¼‰
| æ–¹æ³• | Avg. R-S (+EKA) |
|------|----------------|
| Graph-R1 | 60.40 â†’ **64.90** |
| Search-R1 | 53.06 â†’ **65.02** |

> æ˜¾ç¤º EKA æ˜¾è‘—æå‡äº†æ£€ç´¢çš„ç›¸å…³æ€§å’Œæ•ˆç‡ã€‚

### æ¶ˆèå®éªŒç»“æœ

#### Q1: ä¸ºä»€ä¹ˆ EKA æ›´å¥½ï¼Ÿâ€”â€”ç†µåˆ†æï¼ˆEntropy Analysisï¼‰
- å›¾ 3 æ˜¾ç¤ºï¼Œåœ¨ `<think>`ã€`<query>`ã€`<answer>` é˜¶æ®µï¼ŒEKA çš„ token ç†µæ™®éæ›´ä½ï¼›
- è¯´æ˜æ¨¡å‹åœ¨ EKA ä¸‹æ¨ç†æ›´å…·ç¡®å®šæ€§ï¼Œæ¢ç´¢æ–¹å‘æ›´é›†ä¸­ï¼›
- ç¬¦åˆç†è®ºæ¨å¯¼ï¼šEKA èƒ½è·å¾—æ›´é«˜çš„äº’ä¿¡æ¯ $ I(A^*; H_T|Q) $ï¼Œä»è€Œé™ä½æœ€ç»ˆé”™è¯¯æ¦‚ç‡ã€‚

#### Q2: æ˜¯å¦ç¼©çŸ­æ¨ç†æ­¥æ•°ï¼Ÿ
| æ–¹æ³• | å¹³å‡æ¨ç†è½®æ¬¡ |
|------|--------------|
| Graph-R1 | 3.26 |
| +EKA | **2.22** |

> å‡å°‘çº¦ 1 è½®ï¼Œæ„å‘³ç€æ›´å°‘å™ªå£°ã€æ›´å¿«æ”¶æ•›ã€‚

#### Q3: æ˜¯å¦å½±å“æ³›åŒ–èƒ½åŠ›ï¼Ÿ
- åœ¨ OOD æ•°æ®é›†ä¸Šæµ‹è¯•ï¼ŒEKA ä¸ä»…æœªæŸå®³æ³›åŒ–ï¼Œåè€Œå¹³å‡æå‡ **+4.64 F1**ï¼›
- å³ä½¿ä½¿ç”¨ noisy early knowledgeï¼ˆEKA-wikiï¼‰ï¼Œæ€§èƒ½ä»ä¼˜äº baselineï¼›
- ä½¿ç”¨ä¸åŒ retrieverï¼ˆBGE vs E5ï¼‰ä¹Ÿä¿æŒå¢ç›Šï¼Œè¯æ˜ **retriever-agnostic**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **åˆå§‹çŸ¥è¯†å¯¹é½è‡³å…³é‡è¦**ï¼šåœ¨æ¨ç†å¼€å§‹å‰å¼•å…¥ early knowledgeï¼Œèƒ½æœ‰æ•ˆé˜²æ­¢â€œç›²çŒœâ€ï¼Œå»ºç«‹ç¨³å¥çš„æ¨ç†èµ·ç‚¹ã€‚
2. âœ… **EKA æé«˜ RL æ•ˆç‡**ï¼šé€šè¿‡é™ä½æ¢ç´¢ç†µï¼ŒåŠ é€Ÿå­¦ä¹ è¿‡ç¨‹ï¼Œå‡å°‘æ— æ•ˆåŠ¨ä½œã€‚
3. âœ… **å³æ’å³ç”¨ä¸”å¯æ‰©å±•**ï¼šæ— éœ€é¢å¤–è®­ç»ƒå³å¯éƒ¨ç½²äºå¤§å‹ LLMï¼Œé€‚ç”¨äºèµ„æºå—é™åœºæ™¯ã€‚
4. âœ… **å…¨é¢æ€§èƒ½æå‡**ï¼šåœ¨ EMã€F1ã€R-S ç­‰å¤šä¸ªç»´åº¦å‡å–å¾— SOTA æˆ–æ˜¾è‘—æ”¹è¿›ã€‚
5. âœ… **ç†è®ºæ”¯æŒå……åˆ†**ï¼šä»ä¿¡æ¯è®ºè§’åº¦è¯æ˜ EKA å¯å¸¦æ¥æ›´é«˜ä¿¡æ¯å¢ç›Šå’Œæ›´ä½è¯¯å·®ä¸Šé™ã€‚

### å±€é™æ€§ï¼ˆLimitationsï¼‰
- å½“å‰ä»…éªŒè¯äºå¤šè·³é—®ç­”ä»»åŠ¡ï¼Œå°šæœªæ‰©å±•è‡³æ›´å¤æ‚çš„ **Deep Research** åœºæ™¯ï¼ˆå¦‚ç§‘ç ”æ–‡çŒ®ç»¼è¿°ã€é•¿æœŸè§„åˆ’ç­‰ï¼‰ï¼›
- åˆå§‹æ£€ç´¢è´¨é‡ä¾èµ–äº retriever æ€§èƒ½ï¼Œè‹¥ $ P_0 $ å®Œå…¨æ— å…³å¯èƒ½å¼•å…¥è¯¯å¯¼ï¼ˆå°½ç®¡å®éªŒæ˜¾ç¤ºé²æ£’æ€§è¾ƒå¼ºï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† EKA æ‰©å±•åˆ°æ›´å¤æ‚çš„ agent workflowsï¼ˆå¦‚è‡ªåŠ¨å®éªŒè®¾è®¡ã€è·¨æ¨¡æ€æ¨ç†ï¼‰ï¼›
- åŠ¨æ€è°ƒæ•´ early knowledge çš„ç²’åº¦ä¸æ•°é‡ï¼ˆadaptive kï¼‰ï¼›
- ç»“åˆ memory æˆ– meta-learning è¿›ä¸€æ­¥ä¼˜åŒ–åˆå§‹çŸ¥è¯†é€‰æ‹©ç­–ç•¥ã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **Early Knowledge Alignment (EKA)** é€šè¿‡â€œå…ˆçœ‹å†æƒ³â€çš„æœºåˆ¶ï¼Œä»æ ¹æœ¬ä¸Šæ”¹å–„äº† Iterative RAG çš„åˆå§‹æ¨ç†è´¨é‡ï¼Œæ˜¯ä¸€ç§é«˜æ•ˆã€é€šç”¨ã€æ— éœ€è®­ç»ƒçš„å¢å¼ºèŒƒå¼ï¼Œæ¨åŠ¨äº† RAG ç³»ç»Ÿä»â€œå…ˆè®¡åˆ’åæ£€ç´¢â€å‘â€œå…ˆå¯¹é½å†æ¨ç†â€çš„èŒƒå¼è½¬å˜ã€‚

</details>

---

### 6. [FastMPS: Revisit Data Parallel in Large-scale Matrix Product State Sampling](https://arxiv.org/abs/2512.20064)

**Authors**: Yaojian Chen, Si-Qiu Gong, Lin Gan, Yanfei Liu, An Yang, Yinuo Wang, Chao-yang Lu, Guangwen Yang  
**Category**: cs.DC  
**Published**: 2025-12-24  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.20064v1  

#### Abstract
Matrix Product State (MPS) is a versatile tensor network representation widely applied in quantum physics, quantum chemistry, and machine learning, etc. MPS sampling serves as a critical fundamental operation in these fields. As the problems become more complex, the scale of MPS is rapidly increasin...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFastMPS: Revisit Data Parallel in Large-scale Matrix Product State Sampling

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
Matrix Product State (MPS) é‡‡æ ·æ˜¯é‡å­ç‰©ç†ã€é‡å­åŒ–å­¦å’Œæœºå™¨å­¦ä¹ ç­‰é¢†åŸŸä¸­çš„åŸºç¡€æ“ä½œã€‚éšç€é—®é¢˜è§„æ¨¡æ‰©å¤§ï¼ŒMPS çš„å¼ é‡æ•°é‡ï¼ˆsites $M$ï¼‰ã€æ ·æœ¬æ•°ï¼ˆ$N$ï¼‰å’Œ bond ç»´åº¦ï¼ˆ$\chi$ï¼‰æ€¥å‰§å¢é•¿ï¼Œå¯¼è‡´ä¼ ç»Ÿå¹¶è¡Œç­–ç•¥é¢ä¸´ä¸¥é‡ç“¶é¢ˆï¼š
- **Data Parallelism**ï¼šå—é™äºå†…å­˜å’Œ I/O å‹åŠ›ï¼Œåœ¨å¤§è§„æ¨¡ MPS ä¸­æ•ˆç‡ä½ä¸‹ï¼Œé¢‘ç¹ä»ç£ç›˜åŠ è½½å¼ é‡æˆä¸ºæ€§èƒ½ç“¶é¢ˆã€‚
- **Model Parallelism**ï¼ˆå¦‚æ¯è¿›ç¨‹å¤„ç†ä¸€ä¸ª siteï¼‰ï¼šè™½ç„¶å¯æ‰©å±•è‡³é«˜ $\chi$ï¼ˆå¦‚ $10^4$ï¼‰ï¼Œä½†å­˜åœ¨**åˆšæ€§è¿›ç¨‹ç»‘å®š**ï¼ˆprocess bindingï¼‰ã€å¯åŠ¨å»¶è¿Ÿå¤§ã€é€šä¿¡å¼€é”€é‡ã€è´Ÿè½½ä¸å‡è¡¡ç­‰é—®é¢˜ã€‚

æ­¤å¤–ï¼ŒMPS é‡‡æ ·æœ¬è´¨ä¸Šæ˜¯é¡ºåºä¾èµ–çš„ï¼ˆæ¯ä¸ª site çš„æµ‹é‡ä¾èµ–å‰ä¸€ä¸ª site çš„æ”¶ç¼©ç»“æœï¼‰ï¼Œé™åˆ¶äº†å¹¶è¡ŒåŒ–æ½œåŠ›ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **FastMPS** â€”â€” ä¸€ç§å¤šçº§å¹¶è¡Œæ¡†æ¶ï¼Œé‡æ–°æ¿€æ´»å¤§è§„æ¨¡ MPS é‡‡æ ·ä¸­çš„ **Data Parallelism**ï¼Œé€šè¿‡ç»“åˆ **Tensor Parallelism** å’Œä¸€ç³»åˆ—ä¼˜åŒ–æŠ€æœ¯å®ç°é«˜æ•ˆå¯æ‰©å±•æ¨¡æ‹Ÿã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **Multi-level Parallel Framework**
   - **Task-level Data Parallelism**ï¼šåœ¨ç‹¬ç«‹æ ·æœ¬ä¹‹é—´è¿›è¡Œæ•°æ®å¹¶è¡Œï¼Œæå‡çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ã€‚
   - **Tensor-level Tensor Parallelism**ï¼šæ²¿ bond ç»´åº¦å¯¹ MPS å¼ é‡è¿›è¡Œåˆ‡åˆ†ï¼Œæ”¯æŒè·¨è®¾å¤‡åˆ†å¸ƒå¤§å¼ é‡ï¼Œç¼“è§£å•è®¾å¤‡å†…å­˜å‹åŠ›ã€‚
   - æ”¯æŒçµæ´»é…ç½®ï¼š$p = p_1 \times p_2$ è¿›ç¨‹åˆ†ä¸º $p_1$ ç»„ï¼Œæ¯ç»„ $p_2$ ä¸ªè¿›ç¨‹æ‰§è¡Œ tensor parallelismã€‚

2. **Single-site vs Double-site Tensor Parallelism**
   - **Single-site**ï¼šä½¿ç”¨ `ReduceScatter` æ›´æ–°å·¦ç¯å¢ƒï¼ˆleft environmentï¼‰ï¼Œé€‚åˆå¸¦å®½ä¸»å¯¼åœºæ™¯ã€‚
   - **Double-site**ï¼šåˆå¹¶ä¸¤ä¸ªç›¸é‚» site å¤„ç†ï¼Œç”¨ `AllReduce` æ›¿ä»£ `ReduceScatter`ï¼Œå‡å°‘é€šä¿¡æ¬¡æ•°ï¼Œé™ä½å»¶è¿Ÿå½±å“ï¼Œæ›´é€‚åˆé«˜å»¶è¿Ÿç½‘ç»œï¼ˆå¦‚ PCIeï¼‰ã€‚

3. **Adaptive Mixed Precision Strategy**
   - åœ¨è®¡ç®—ä¸­é‡‡ç”¨ **TF32** åŠ é€Ÿ tensor core åˆ©ç”¨ç‡ï¼ŒåŒæ—¶é€šè¿‡**é€æ ·æœ¬åŠ¨æ€ç¼©æ”¾**ï¼ˆsample-wise max scalingï¼‰ç»´æŒæ•°å€¼ç¨³å®šæ€§ï¼Œé¿å…ä¸‹æº¢ï¼ˆunderflowï¼‰ã€‚
   - å­˜å‚¨ä½¿ç”¨ **FP16** è¡¨ç¤º MPS å¼ é‡å’Œä¸­é—´çŠ¶æ€ï¼Œæ˜¾è‘—é™ä½ I/Oã€host-device ä¼ è¾“å’Œå¹¿æ’­å¼€é”€ã€‚

4. **Customized Optimizations for GBS**
   - **Displacement Operator Acceleration**ï¼šåˆ©ç”¨ç»“æ„ç¨€ç–æ€§å°†çŸ©é˜µæŒ‡æ•°åˆ†è§£ä¸ºä¸‰è§’çŸ©é˜µä¹˜æ³•ï¼ŒåŠ é€Ÿ GPU ä¸Šçš„ `expm` è®¡ç®—ï¼Œæé€Ÿè¶… 10Ã—ã€‚
   - **Dynamic Bond Dimension Allocation**ï¼šåŸºäºçº ç¼ ç†µåˆ†å¸ƒåŠ¨æ€è°ƒæ•´å„ site çš„ bond ç»´åº¦ï¼Œè¾¹ç¼˜åŒºåŸŸä½¿ç”¨è¾ƒå° $\chi$ï¼Œä¸­å¿ƒåŒºåŸŸä¿ç•™é«˜ç²¾åº¦ï¼Œå¤§å¹…å‡å°‘æ— æ•ˆè®¡ç®—ã€‚

5. **Overlap & Memory Management**
   - ä½¿ç”¨åŒç¼“å†²ï¼ˆdouble bufferingï¼‰å’Œé¢å¤– CPU çº¿ç¨‹å®ç° **I/Oã€è®¡ç®—ã€é€šä¿¡ä¸‰é‡é‡å **ã€‚
   - å°†å®æ‰¹æ¬¡ï¼ˆmacro batchï¼‰è¿›ä¸€æ­¥åˆ’åˆ†ä¸ºå¾®æ‰¹æ¬¡ï¼ˆmicro batchï¼‰ï¼Œé™ä½å³°å€¼å†…å­˜éœ€æ±‚ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³• [19] | FastMPS |
|------|----------------|---------|
| å¯æ‰©å±•æ€§ | å›ºå®š $p = M$ï¼ˆè¿›ç¨‹æ•°=ç«™ç‚¹æ•°ï¼‰ï¼Œä¸å¯ä¼¸ç¼© | æ”¯æŒä»»æ„è¿›ç¨‹æ•°ï¼Œå¼ºå¼±æ‰©å±•å‡é«˜æ•ˆ |
| å†…å­˜å‹åŠ› | å•è®¾å¤‡éœ€å®¹çº³æ•´ä¸ª MPS å¼ é‡ | å¼ é‡è¢«åˆ‡åˆ†ï¼Œæ”¯æŒæ›´å¤§ $\chi$ |
| I/O æ•ˆç‡ | æ‰€æœ‰è¿›ç¨‹é›†ä¸­è¯»å–ï¼Œæ˜“å¼•å‘ç£ç›˜äº‰ç”¨ | ä¸»æ§è¿›ç¨‹ç»Ÿä¸€è¯»å–å¹¶å¹¿æ’­ï¼Œæ”¯æŒ I/O ä¸è®¡ç®—é‡å  |
| æ•°å€¼ç²¾åº¦ | éœ€ FP64 ä¿è¯ç¨³å®š | TF32 + åŠ¨æ€ç¼©æ”¾å³å¯ç¨³å®šè¿è¡Œ |
| æ€§èƒ½ | å—é™äºé€šä¿¡å’Œå¯åŠ¨å»¶è¿Ÿ | å¤šçº§å¹¶è¡Œ + æ··åˆç²¾åº¦ + å®šåˆ¶ä¼˜åŒ–ï¼Œæ€§èƒ½æå‡ >10Ã— |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **Gaussian Boson Sampling (GBS)**ï¼šä½œä¸ºä»£è¡¨æ€§ä¸”é«˜è¦æ±‚çš„åº”ç”¨åŸºå‡†ã€‚
- å…·ä½“å®éªŒåŒ…æ‹¬ï¼š
  - **Jiuzhang ç³»åˆ—**ï¼ˆä¸­å›½ç§‘å¤§å…‰é‡å­è®¡ç®—æœºï¼‰
  - **Borealis**ï¼ˆXanadu å…‰å­èŠ¯ç‰‡ï¼‰
  - è‡ªå®šä¹‰å¤§è§„æ¨¡æ¨¡æ‹Ÿæ•°æ®ï¼š**8176 sites**, bond dimension $\chi = 10^4$, å®é™…å‹ç¼©å…‰å­æ•° 16.54

è¿™äº›æ•°æ®å…·æœ‰æ ‡å‡†åŒ–æ ¼å¼ï¼Œæ˜“äºè·å–ï¼Œå¹¶å¹¿æ³›ç”¨äºéªŒè¯é‡å­ä¼˜åŠ¿ã€‚

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### ç¡¬ä»¶å¹³å°
- **GPU**ï¼šNVIDIA A100ï¼ˆ8 GPUs æ„æˆ 2Ã—4 æ•°æ®+å¼ é‡å¹¶è¡Œæ‹“æ‰‘ï¼‰
- **CPU**ï¼šIntel Xeon Gold 6230R @ 2.10GHz
- **è¶…ç®—ç³»ç»Ÿ**ï¼š
  - **Tianhe-3**ï¼šæµ‹è¯•åˆ° 15 èŠ‚ç‚¹ 375 æ ¸
  - **Sunway TaihuLight**ï¼šæµ‹è¯•åˆ° 500 è¿›ç¨‹ 32500 æ ¸

#### å‚æ•°è®¾ç½®
- ç‰©ç†ç»´åº¦ $d = 3$ æˆ– $4$
- bond dimension $\chi$: æœ€é«˜è¾¾ $10^4$
- æ ·æœ¬æ•° $N$: é«˜è¾¾ $10^7$
- micro batch size $N_2 = 5000$ï¼ˆå¹³è¡¡ GEMM å¼ºåº¦ä¸å†…å­˜ï¼‰

#### è¯„ä¼°æŒ‡æ ‡
- **è¿è¡Œæ—¶é—´ï¼ˆTime-to-solutionï¼‰**
- **Speedup**ï¼ˆç›¸å¯¹äºåŸºçº¿æ–¹æ³•ï¼‰
- **å¼º/å¼±æ‰©å±•æ•ˆç‡**
- **æˆªæ–­è¯¯å·®ï¼ˆtruncation errorï¼‰**
- **ç›¸å…³å‡½æ•°ä¸€è‡´æ€§**ï¼ˆfirst/second-order correlation slopeï¼‰

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- ä¸»è¦å¯¹æ¯”æ–‡çŒ® **[19]**ï¼ˆOh et al., Nature Physics 2024ï¼‰ï¼Œå³å½“å‰æœ€å…ˆè¿›çš„ MPS-based GBS æ¨¡æ‹Ÿå™¨ã€‚
- åŒ…æ‹¬ GPU å’Œ CPU å¹³å°ä¸Šçš„ç›´æ¥æ€§èƒ½æ¯”è¾ƒã€‚
- åŒæ—¶å‚è€ƒ Roofline æ¨¡å‹åˆ†æè®¡ç®—/é€šä¿¡æ¯”ï¼ˆCCRï¼‰ï¼Œåˆ¤æ–­æ˜¯å¦è¾¾åˆ°è®¡ç®—ç“¶é¢ˆã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| æœ€å¤§æ¨¡æ‹Ÿè§„æ¨¡ | **8176 sites**, $\chi = 10^4$, $N = 10^7$ |
| å•å¡æ€§èƒ½ï¼ˆA100ï¼‰ | ç”Ÿæˆ 0.4M æ ·æœ¬è€—æ—¶ ~2000sï¼ˆBorealis-288ï¼‰ï¼Œæ¨ç®— 10M æ ·æœ¬çº¦ 14 å°æ—¶ |
| å¼±æ‰©å±•æ•ˆç‡ | >95%ï¼ˆTianhe-3 å’Œ Sunwayï¼‰ |
| å¼ºæ‰©å±•æ•ˆç‡ | >95%ï¼ˆæœ€é«˜è¾¾ 32500 æ ¸ï¼‰ |

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### GPU æ€§èƒ½å¯¹æ¯”ï¼ˆTable 2ï¼‰
| GBS å®ä¾‹ | [19] æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰ | Fast-MPS-8ï¼ˆåˆ†é’Ÿï¼‰ | åŠ é€Ÿæ¯” |
|----------|--------------------|---------------------|--------|
| Jiuzhang2 | 62ï¼ˆä½¿ç”¨ 144 GPUsï¼‰ | 38.57ï¼ˆä»… 8 GPUsï¼‰ | **1.6Ã— æ›´å¿« + æ˜¾è‘—æ›´å°‘èµ„æº** |
| B-M288 | 62ï¼ˆä½¿ç”¨ 288 GPUsï¼‰ | 247.43ï¼ˆ8 GPUsï¼‰ | æ¨ç®—ç­‰æ•ˆåŠ é€Ÿ **>10Ã—**

> æ³¨ï¼šFast-MPS ä»…ç”¨ 8 å¼  GPU å³å¯åœ¨åˆç†æ—¶é—´å†…å®Œæˆæ­¤å‰éœ€æ•°ç™¾ GPU çš„ä»»åŠ¡ã€‚

#### CPU æ€§èƒ½å¯¹æ¯”ï¼ˆTable 3ï¼‰
| å®ä¾‹ | [19] æ—¶é—´ | Fast-MPS æ—¶é—´ | Speedup |
|------|-----------|---------------|---------|
| Jiuzhang2-P65-1 | 17.72h | 1.76h | **10.06Ã—** |
| B-M288 | 36.44h | 4.504h | **8.09Ã—**

---

### æ¶ˆèå®éªŒç»“æœï¼ˆFigure 11ï¼‰
åœ¨ A100 ä¸Šå¯¹ä¸‰å¤§ä¼˜åŒ–è¿›è¡Œæ¶ˆèæµ‹è¯•ï¼ˆå‚æ•°ï¼š$d=4,\chi=10^4$, 400K samplesï¼‰ï¼š

| ä¼˜åŒ–é¡¹ | ç§»é™¤åæ€§èƒ½ä¸‹é™ï¼ˆç›¸å¯¹å…¨ä¼˜åŒ–ç‰ˆæœ¬ï¼‰ |
|--------|-------------------------------|
| Dynamic Bond Dimension | ä¸‹é™ 1.9Ã— |
| Optimized expm | ä¸‹é™ 2.6Ã— |
| Mixed Precision (TF32+FP16) | ä¸‹é™ 5.1Ã— |

ğŸ‘‰ **æ··åˆç²¾åº¦å¸¦æ¥æœ€å¤§æ”¶ç›Š**ï¼Œè¯´æ˜å…¶åœ¨é‡Šæ”¾ tensor core æ€§èƒ½æ–¹é¢è‡³å…³é‡è¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Data Parallelism å¯åœ¨å¤§è§„æ¨¡ MPS ä¸­å¤æ´»**ï¼šé€šè¿‡å‹ç¼©ã€åˆ‡åˆ†å’Œé‡å æœºåˆ¶ï¼Œå…‹æœäº†ä¼ ç»Ÿ data parallel çš„ I/O å’Œå†…å­˜ç“¶é¢ˆã€‚
2. **Tensor Parallelism æœ‰æ•ˆæ‰“ç ´ memory wall**ï¼šsplit-K GEMM + collective communication è®¾è®¡ä½¿å¤§ $\chi$ å¼ é‡å¯åœ¨å¤šè®¾å¤‡é—´åˆ†å¸ƒã€‚
3. **æ··åˆç²¾åº¦å¯è¡Œä¸”å¿…è¦**ï¼šé€šè¿‡ sample-wise åŠ¨æ€ç¼©æ”¾ï¼ŒTF32 å¯æ›¿ä»£ FP64ï¼Œç»“åˆ FP16 å­˜å‚¨ï¼Œæ˜¾è‘—æå‡ååã€‚
4. **å®šåˆ¶åŒ–ä¼˜åŒ–æ•ˆæœæ˜¾è‘—**ï¼šdisplacement operator åˆ†è§£å’Œ dynamic bond dimension åˆ†é…åˆ†åˆ«å¸¦æ¥ 2Ã— å’Œè¿‘ 80% çš„å¤æ‚åº¦é™ä½ï¼ˆè§ Table 1ï¼‰ã€‚
5. **æé«˜å¯æ‰©å±•æ€§**ï¼šåœ¨è¶…ç®—ä¸Šå®ç° >95% æ‰©å±•æ•ˆç‡ï¼Œæ”¯æŒæ•°åƒè¿›ç¨‹ååŒå·¥ä½œã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä»å—é™äº GBS ç‰¹æ€§**ï¼šéƒ¨åˆ†ä¼˜åŒ–ï¼ˆå¦‚ displacement åˆ†è§£ï¼‰é’ˆå¯¹ GBS ç‰¹æ®Šç»“æ„è®¾è®¡ï¼Œé€šç”¨æ€§æœ‰å¾…éªŒè¯ã€‚
2. **é€šä¿¡æ•æ„Ÿ**ï¼štensor parallelism å¯¹ AllReduce/ReduceScatter å¸¦å®½é«˜åº¦ä¾èµ–ï¼ŒPCIE è¿æ¥ä¸‹æ€§èƒ½å¯èƒ½ä¸‹é™ã€‚
3. **å°šæœªå®Œå…¨å¯ç”¨ FP16/BF16**ï¼šå›  ComplexHalf æ”¯æŒä¸è¶³åŠèˆå…¥è¯¯å·®é£é™©ï¼Œç›®å‰æœªå…¨é¢å¯ç”¨åŠç²¾åº¦è®­ç»ƒçº§ç²¾åº¦ã€‚
4. **å¯åŠ¨é˜¶æ®µä»æœ‰ I/O é›†ä¸­é—®é¢˜**ï¼šè™½ç”±å•ä¸€è¿›ç¨‹è´Ÿè´£è¯»å–ï¼Œä½†åœ¨æç«¯å¤§è§„æ¨¡æ–‡ä»¶ä¸‹ä»å¯èƒ½æˆä¸ºç“¶é¢ˆã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ¢ç´¢ AI ä¸ç§‘å­¦è®¡ç®—å…±é€šæ€§**ï¼šä½œè€…æŒ‡å‡º MPS å¯è§†ä¸ºâ€œå¤§å‹æ¨¡å‹â€ï¼ˆå¦‚ 8176 sites Ã— $\chi^2$ â‰ˆ 2452B å‚æ•°ï¼‰ï¼Œæœªæ¥å¯å€Ÿé‰´ LLM æ¨ç†ä¸­çš„ pipeline parallelismã€offloading ç­‰æŠ€æœ¯ã€‚
2. **å¼‚æ„è®¡ç®—æ”¯æŒ**ï¼šæ‰©å±•è‡³æ›´å¤šç¡¬ä»¶å¹³å°ï¼ˆå¦‚å›½äº§åŠ é€Ÿå™¨ã€TPUï¼‰ã€‚
3. **å…¨è‡ªåŠ¨å¹¶è¡Œç­–ç•¥é€‰æ‹©**ï¼šåŸºäºç¡¬ä»¶æ¢æµ‹è‡ªåŠ¨é€‰æ‹© single/double-site æ¨¡å¼ã€‚
4. **æ”¯æŒæ›´å¤š tensor network åº”ç”¨**ï¼šå°† FastMPS æ¡†æ¶æ¨å¹¿è‡³ PEPSã€TTNS ç­‰å…¶ä»– TN ç»“æ„ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> FastMPS é€šè¿‡èåˆ **multi-level parallelism**ã€**adaptive mixed precision** å’Œ **application-specific optimizations**ï¼Œå®ç°äº†è¶…è¿‡ **10Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿ**ï¼Œé¦–æ¬¡åœ¨å• GPU æˆ–å°å‹é›†ç¾¤ä¸Šå®Œæˆäº†æ­¤å‰éœ€æ•°ç™¾ GPU æ‰èƒ½å®Œæˆçš„å¤§è§„æ¨¡ GBS æ¨¡æ‹Ÿï¼Œæå¤§é™ä½äº†é«˜æ€§èƒ½ MPS ä»¿çœŸçš„é—¨æ§›ã€‚

</details>

---

### 7. [MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization](https://arxiv.org/abs/2512.20135)

**Authors**: Zhuo Yang, Yeyun chen, Jiaqing Xie, Ben Gao, Shuaike Shen, Wanhao Liu, Liujia Yang, Beilun Wang, Tianfan Fu, Yuqiang Li  
**Category**: cs.AI  
**Published**: 2025-12-24  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.20135v1  

#### Abstract
Molecular editing and optimization are multi-step problems that require iteratively improving properties while keeping molecules chemically valid and structurally similar. We frame both tasks as sequential, tool-guided decisions and introduce MolAct, an agentic reinforcement learning framework that ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åˆ†å­ç¼–è¾‘ï¼ˆMolecular Editingï¼‰å’Œåˆ†å­ä¼˜åŒ–ï¼ˆMolecular Optimizationï¼‰æ˜¯è¯ç‰©è®¾è®¡ä¸­çš„æ ¸å¿ƒä»»åŠ¡ï¼Œä¼ ç»Ÿæ–¹æ³•é€šå¸¸é‡‡ç”¨å•æ­¥ç”Ÿæˆæˆ–é™æ€æŒ‡ä»¤å¾®è°ƒæ–¹å¼å¤„ç†ï¼Œå­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- ç¼ºä¹å¯¹**å¤šæ­¥å†³ç­–è¿‡ç¨‹**çš„å»ºæ¨¡ï¼›
- æ— æ³•æœ‰æ•ˆåˆ©ç”¨å¤–éƒ¨åŒ–å­¦å·¥å…·ï¼ˆå¦‚æœ‰æ•ˆæ€§ã€ç›¸ä¼¼æ€§ã€æ€§è´¨é¢„æµ‹å™¨ï¼‰è¿›è¡Œ**å®æ—¶åé¦ˆä¸éªŒè¯**ï¼›
- éš¾ä»¥ä¿è¯ç”Ÿæˆåˆ†å­çš„**åŒ–å­¦æœ‰æ•ˆæ€§**å’Œ**ç»“æ„ä¸€è‡´æ€§**ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **MolAct**ï¼Œé¦–ä¸ªå°†åˆ†å­è®¾è®¡å½¢å¼åŒ–ä¸º **Agentic Reinforcement Learningï¼ˆä»£ç†å¼å¼ºåŒ–å­¦ä¹ ï¼‰** æ¡†æ¶çš„å·¥ä½œï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **ä¸¤é˜¶æ®µè®­ç»ƒèŒƒå¼ï¼ˆTwo-stage Training Paradigmï¼‰**ï¼š
  - **Stage 1ï¼ˆMolEditAgentï¼‰**ï¼šåœ¨åˆ†å­ç¼–è¾‘ä»»åŠ¡ä¸Šé¢„è®­ç»ƒï¼Œå­¦ä¹ åŸºæœ¬æ“ä½œï¼ˆAdd/Delete/Substituteï¼‰ï¼ŒæŒæ¡å·¥å…·è°ƒç”¨ä¸ç»ˆæ­¢ç­–ç•¥ï¼›
  - **Stage 2ï¼ˆMolOptAgentï¼‰**ï¼šåŸºäº Stage 1 åˆå§‹åŒ–ï¼Œåœ¨åˆ†å­ä¼˜åŒ–ä»»åŠ¡ä¸Šç»§ç»­è®­ç»ƒï¼Œå®ç°å±æ€§é©±åŠ¨çš„æ¸è¿›å¼ä¼˜åŒ–ã€‚
- **å·¥å…·å¢å¼ºçš„ä»£ç†æ¶æ„ï¼ˆTool-Augmented Agentï¼‰**ï¼š
  - LLM Agent å¯ä¸»åŠ¨è°ƒç”¨å¤šç§åŒ–å­¦å·¥å…·ï¼ˆvalidity checker, similarity calculator, property oracleï¼‰ï¼Œå¹¶æ ¹æ®åé¦ˆè°ƒæ•´åç»­åŠ¨ä½œï¼›
  - æ”¯æŒâ€œæ€è€ƒ â†’ å·¥å…·è°ƒç”¨ â†’ è§‚å¯Ÿ â†’ å†æ€è€ƒâ€çš„å¤šè½®äº¤äº’æœºåˆ¶ã€‚
- **Group-Relative Policy Optimizationï¼ˆGRPOï¼‰**ï¼š
  - åœ¨ç›¸åŒè¾“å…¥æç¤ºä¸‹å¹¶è¡Œè¿è¡Œå¤šä¸ª rollout é“¾ï¼Œç»„å†…ç›¸å¯¹ä¼˜åŠ¿ä¼°è®¡é™ä½æ–¹å·®ï¼Œæå‡é•¿ç¨‹ä¿¡ç”¨åˆ†é…ç¨³å®šæ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚VAEã€RLã€LLMå•æ­¥ç”Ÿæˆï¼‰ | MolAct |
|------|-------------------------------|--------|
| å†³ç­–æ¨¡å¼ | å•æ­¥ç”Ÿæˆæˆ–å›ºå®šæµç¨‹ | å¤šæ­¥ã€å¯è¿­ä»£çš„åºåˆ—å†³ç­– |
| å·¥å…·é›†æˆ | è¢«åŠ¨ä½¿ç”¨æˆ–æ— æ˜¾å¼åé¦ˆ | ä¸»åŠ¨è°ƒç”¨ + æ˜¾å¼åé¦ˆé—­ç¯ |
| åŒ–å­¦æœ‰æ•ˆæ€§ | å¸¸å‡ºç°æ— æ•ˆç»“æ„ï¼ˆhallucinationï¼‰ | é«˜æœ‰æ•ˆæ€§ï¼ˆ95â€“100%ï¼‰ |
| å¯è§£é‡Šæ€§ | é»‘ç®±ç”Ÿæˆ | å¯è¿½è¸ªæ¯ä¸€æ­¥æ¨ç†ä¸å·¥å…·å“åº” |
| æ³›åŒ–èƒ½åŠ› | å›ºå®šç›®æ ‡ä¼˜åŒ– | æ”¯æŒå¤šæ ·åŒ–å±æ€§ç›®æ ‡ï¼ˆLogPã€solubilityã€bioactivityç­‰ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨ **ChemCoTDatasets (Li et al., 2025)** æ„å»ºè®­ç»ƒæ•°æ®ï¼Œè¯¥æ•°æ®é›†åŒ…å«å¸¦é“¾å¼æ€ç»´æ ‡æ³¨çš„å¤šæ­¥åˆ†å­ä¿®æ”¹æ ·æœ¬ï¼›
- ç§»é™¤åŸå§‹ CoT æ¨ç†æ–‡æœ¬ï¼Œä»…ä¿ç•™ï¼š
  - è¾“å…¥ï¼šæºåˆ†å­ SMILES + ç¼–è¾‘æŒ‡ä»¤ / ä¼˜åŒ–ç›®æ ‡ï¼›
  - è¾“å‡ºï¼šç›®æ ‡åˆ†å­ SMILESï¼›
- æ‰€æœ‰åˆ†å­ç»æ ‡å‡†åŒ–ï¼ˆcanonicalizationï¼‰å’Œæœ‰æ•ˆæ€§æ ¡éªŒã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹å®¶æ—**ï¼š
  - MolEditAgentï¼šç”¨äº Stage 1 åˆ†å­ç¼–è¾‘è®­ç»ƒï¼›
  - MolOptAgentï¼šä» MolEditAgent åˆå§‹åŒ–ï¼Œç”¨äº Stage 2 åˆ†å­ä¼˜åŒ–ï¼›
  - ä¸åŒè§„æ¨¡å˜ä½“ï¼šåŸºäº Qwen-2.5-3B å’Œ Qwen-2.5-7B backboneã€‚
- **äº¤äº’æœºåˆ¶**ï¼š
  - æœ€å¤§å›åˆæ•°ï¼ˆmax_turnsï¼‰è®¾ä¸º 16ï¼›
  - æ¯ä¸ª prompt å¹¶è¡Œæ‰§è¡Œ K æ¡ rolloutï¼ˆgroup-relative settingï¼‰ï¼›
  - ä»…å¯¹ agent ç”Ÿæˆ token è¿›è¡Œæ¢¯åº¦æ›´æ–°ï¼ˆmasked updateï¼‰ã€‚
- **å·¥å…·æ¥å£æ”¯æŒçš„æ“ä½œ**ï¼š
  - ç¼–è¾‘æ“ä½œï¼š`add`, `delete`, `substitute` åŠŸèƒ½å›¢ï¼›
  - æŸ¥è¯¢æ“ä½œï¼š`validity`, `Tanimoto similarity`, `Murcko scaffold`, `property oracle`ï¼ˆLogP, solubility, QED, DRD2, JNK3, GSK3Î²ï¼‰ï¼›
  - ç»ˆæ­¢ä¿¡å·ï¼š`terminate`ã€‚

### è¯„ä¼°æŒ‡æ ‡
| ä»»åŠ¡ç±»å‹ | æŒ‡æ ‡ | å«ä¹‰ |
|--------|------|------|
| **åˆ†å­ç¼–è¾‘** | Pass@1 | æ˜¯å¦æˆåŠŸå®ŒæˆæŒ‡å®šç¼–è¾‘æ“ä½œ |
|             | Validity (%) | ç”Ÿæˆåˆ†å­æ˜¯å¦åŒ–å­¦æœ‰æ•ˆ |
| **åˆ†å­ä¼˜åŒ–** | Î”ï¼ˆDeltaï¼‰ | å±æ€§æ”¹å–„å‡å€¼ï¼ˆè¶Šé«˜è¶Šå¥½ï¼›è´Ÿå€¼è¡¨ç¤ºé€€åŒ–ï¼‰ |
|             | SR%ï¼ˆSuccess Rateï¼‰ | æˆåŠŸæå‡å±æ€§çš„æ¯”ä¾‹ï¼ˆ>0ï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¶µç›–ä¸¤å¤§ç±»ä¸»æµæ¨¡å‹ï¼š
- **With Thinkingï¼ˆå…·å¤‡æ¨ç†èƒ½åŠ›ï¼‰**ï¼š
  - Gemini-2.5-pro-think, Claude3.7-sonnet-think, DeepSeek-R1, Qwen3-think ç³»åˆ—
- **Without Thinkingï¼ˆæ ‡å‡†æŒ‡ä»¤å¾®è°ƒæ¨¡å‹ï¼‰**ï¼š
  - GPT-4o, Deepseek-V3, Qwen2.5-Instruct ç³»åˆ—, Llama-3.1-70B-Instruct ç­‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### åˆ†å­ç¼–è¾‘ä»»åŠ¡è¡¨ç°ï¼ˆTable 1 & 2ï¼‰

#### å‡†ç¡®ç‡ï¼ˆAccuracy %ï¼‰
| æ¨¡å‹ | Add | Delete | Substitute |
|------|-----|--------|----------|
| **MolEditAgent-7B** | **90.0** | **80.0** | **78.3** |
| Gemini-2.5-pro-think | 100.0 | 85.0 | 81.7 |
| Claude3.7-sonnet-think | 85.0 | 80.0 | 83.4 |
| GPT-4o | 80.0 | 80.0 | 65.0 |
| **MolEditAgent-3B** | 80.0 | 70.0 | 16.7 |

> âœ… MolEditAgent-7B åœ¨ Delete å’Œ Sub ä¸Šä¼˜äºå¤šæ•°é—­æº thinking æ¨¡å‹ï¼ŒAdd æ’åç¬¬äºŒï¼›  
> âš ï¸ MolEditAgent-3B åœ¨ Sub ä»»åŠ¡ä¸Šæ˜¾è‘—è½åï¼Œè¡¨æ˜å¤æ‚æ›¿æ¢éœ€æ›´å¼ºæ¨¡å‹å®¹é‡ã€‚

#### åˆ†å­æœ‰æ•ˆæ€§ï¼ˆValidity %ï¼‰
| æ¨¡å‹ | Add | Delete | Substitute |
|------|-----|--------|----------|
| **MolEditAgent-7B** | **100.0** | **95.0** | **98.0** |
| Qwen2.5-7B-Instruct | 75.0 | 70.0 | 65.0 |
| **MolEditAgent-3B** | 95.0 | 80.0 | 71.7 |
| Qwen-2.5-3B-Instruct | 60.0 | 55.0 | 65.0 |

> âœ… MolAct æ˜¾è‘—æå‡åŒ–å­¦æœ‰æ•ˆæ€§ï¼Œå°¤å…¶åœ¨ 7B æ¨¡å‹ä¸Šæ¥è¿‘å®Œç¾ï¼ˆ95â€“100%ï¼‰ã€‚

---

### åˆ†å­ä¼˜åŒ–ä»»åŠ¡è¡¨ç°ï¼ˆTable 3ï¼‰

| æ¨¡å‹ | LogP Î” (SR%) | Solubility Î” (SR%) | DRD2 Î” (SR%) | GSK3Î² Î” (SR%) |
|------|--------------|--------------------|---------------|----------------|
| **MolOptAgent-7B** | **0.89 (92%)** | **1.42 (84%)** | 0.02 (38%) | **0.04 (36%)** |
| Gemini-2.5-pro-think | -0.28 (81%) | 1.91 (92%) | **0.35 (74%)** | 0.04 (68%) |
| Claude3.7-sonnet-think | 0.41 (81%) | 0.59 (77%) | 0.18 (66%) | 0.01 (57%) |
| DeepSeek-R1 | 0.36 (74%) | 1.48 (97%) | 0.10 (62%) | -0.02 (41%) |
| **MolOptAgent-3B** | -0.24 (12%) | -0.021 (8%) | -0.009 (7%) | -0.0026 (10%) |

> âœ… MolOptAgent-7B åœ¨ **LogP ä¼˜åŒ–ä¸Šå¤§å¹…é¢†å…ˆæ‰€æœ‰åŸºçº¿**ï¼ˆÎ”=0.89 vs ç¬¬äºŒå 0.41ï¼‰ï¼›  
> âœ… åœ¨ **Solubility ä¸Šä»…æ¬¡äº Gemini å’Œ DeepSeek-R1**ï¼Œä»ä¿æŒé«˜æˆåŠŸç‡ï¼ˆ84%ï¼‰ï¼›  
> â— åœ¨ç”Ÿç‰©æ´»æ€§ä»»åŠ¡ï¼ˆå¦‚ DRD2ï¼‰ä¸Šä»æœ‰å·®è·ï¼Œè¯´æ˜éœ€è¦é¢†åŸŸçŸ¥è¯†å¢å¼ºã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ä¸€é˜¶æ®µ vs ä¸¤é˜¶æ®µè®­ç»ƒï¼ˆTable 4ï¼‰
| æ¨¡å‹ | è®­ç»ƒæ–¹å¼ | LogP SR% | Solubility SR% | QED SR% |
|------|---------|----------|----------------|---------|
| Qwen-2.5-7B-Instruct | One-stageï¼ˆç›´æ¥ä¼˜åŒ–ï¼‰ | 0% | 0% | 12% |
| **MolOptAgent-7B** | **Two-stage** | **92%** | **84%** | **35%** |
| Qwen-2.5-3B-Instruct | One-stage | 0% | 0% | 0% |
| **MolOptAgent-3B** | **Two-stage** | **12%** | **8%** | **5%** |

> ğŸ” å…³é”®å‘ç°ï¼šå³ä½¿æ‹¥æœ‰å·¥å…·è®¿é—®æƒé™å’Œ RL è®­ç»ƒï¼Œ**ç¼ºå°‘ç¼–è¾‘é¢„è®­ç»ƒçš„ä¸€é˜¶æ®µæ–¹æ³•å‡ ä¹å®Œå…¨å¤±è´¥**ï¼Œè¯æ˜ä¸¤é˜¶æ®µè®¾è®¡è‡³å…³é‡è¦ã€‚

#### æ¨¡å‹å®¹é‡å½±å“ï¼ˆFigure 4â€“6ï¼‰
- **7B æ¨¡å‹**ï¼šå“åº”é•¿åº¦ç¨³å®šï¼Œå·¥å…·è°ƒç”¨é«˜æ•ˆï¼Œå¥–åŠ±èƒ½è½¬åŒ–ä¸ºå®é™…æˆåŠŸï¼›
- **3B æ¨¡å‹**ï¼šæœ€å¤§å“åº”é•¿åº¦å¯è¾¾ **5000 tokens**ï¼Œå‡ºç°å†—é•¿æ— æ•ˆæ¨ç†ï¼Œå¯¼è‡´è¶…é¢„ç®—æ— æ³•ç»ˆæ­¢ï¼›
- å°½ç®¡éªŒè¯å¥–åŠ±ç›¸è¿‘ï¼Œä½† **3B æˆåŠŸç‡è¿œä½äº 7B**ï¼Œæ­ç¤ºâ€œå¥–åŠ±æ‹Ÿåˆ â‰  æ”¿ç­–å¯æ‰§è¡Œâ€ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **å¤šæ­¥ã€å·¥å…·å¢å¼ºçš„å†³ç­–æ¡†æ¶æ˜¾è‘—ä¼˜äºå•æ­¥ç”Ÿæˆ**ï¼šé€šè¿‡æ˜¾å¼å¼•å…¥åŒ–å­¦å·¥å…·åé¦ˆï¼Œå®ç°äº†æ›´å¯é ã€å¯è§£é‡Šçš„åˆ†å­ä¿®æ”¹ï¼›
2. âœ… **ä¸¤é˜¶æ®µè®­ç»ƒæ˜¯æˆåŠŸçš„å…³é”®**ï¼šå…ˆæŒæ¡ç¼–è¾‘æŠ€èƒ½å†è¿›è¡Œä¼˜åŒ–ï¼Œä½¿æ¨¡å‹å­¦ä¼šå¦‚ä½•æ­£ç¡®ä½¿ç”¨å·¥å…·å’Œé€‚æ—¶ç»ˆæ­¢ï¼›
3. âœ… **æ›´å¤§çš„æ¨¡å‹å®¹é‡æœ‰åŠ©äºæ”¿ç­–æ‰§è¡Œæ•ˆç‡**ï¼š7B æ¨¡å‹åœ¨æœ‰é™å›åˆå†…æ›´æœ‰æ•ˆåœ°ç»„ç»‡å·¥å…·è°ƒç”¨ï¼Œè€Œå°æ¨¡å‹æ˜“é™·å…¥ä½æ•ˆå¾ªç¯ï¼›
4. âœ… **MolAct åœ¨å…³é”®ç‰©ç†åŒ–å­¦å±æ€§ï¼ˆLogP, solubilityï¼‰ä¸Šè¾¾åˆ° SOTA è¡¨ç°**ï¼Œä¸”ç»´æŒé«˜åŒ–å­¦æœ‰æ•ˆæ€§ï¼ˆ95â€“100%ï¼‰ï¼›
5. âœ… **Agentic RL æ˜¯é€šå¾€è‡ªåŠ¨åŒ–è¯ç‰©è®¾è®¡çš„é‡è¦è·¯å¾„**ï¼šæ¨¡æ‹ŸçœŸå®è¯ç‰©åŒ–å­¦å®¶â€œè¯•é”™+éªŒè¯â€å·¥ä½œæµã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. ğŸš« **å¯¹ç‰¹å®šç”Ÿç‰©é¶ç‚¹ï¼ˆå¦‚ JNK3ï¼‰ä¼˜åŒ–æ•ˆæœä¸€èˆ¬**ï¼šå¯èƒ½ç¼ºä¹è¶³å¤Ÿçš„é¢†åŸŸçŸ¥è¯†æˆ–ä¸“ç”¨å·¥å…·ï¼›
2. ğŸš« **æœªè€ƒè™‘åˆæˆå¯è¡Œæ€§ï¼ˆsynthetic accessibilityï¼‰**ï¼šéƒ¨åˆ†ç”Ÿæˆåˆ†å­è™½æœ‰æ•ˆä½†åœ¨ç°å®ä¸­éš¾ä»¥åˆæˆï¼›
3. ğŸš« **ä¾èµ–é«˜è´¨é‡å¤–éƒ¨å·¥å…·**ï¼šæ€§èƒ½å—é™äº property oracle å’Œ validity checker çš„å‡†ç¡®æ€§ï¼›
4. ğŸš« **å°æ¨¡å‹ï¼ˆ3Bï¼‰æ‰§è¡ŒåŠ›å¼±**ï¼šå°½ç®¡å¯ä»¥å­¦åˆ°å¥–åŠ±æ¨¡å¼ï¼Œä½†éš¾ä»¥åœ¨é¢„ç®—å†…å®Œæˆä»»åŠ¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. â• **å¼•å…¥ååº”è·¯å¾„ä¸åˆæˆçº¦æŸ**ï¼šç»“åˆ retrosynthesis å·¥å…·ï¼Œç¡®ä¿ç”Ÿæˆåˆ†å­å…·å¤‡å¯åˆæˆæ€§ï¼›
2. ğŸ” **å¼€å‘é”™è¯¯æ¢å¤æœºåˆ¶**ï¼šå½“å·¥å…·è¿”å›å¤±è´¥æ—¶ï¼Œå…è®¸æ¨¡å‹å›æº¯æˆ–ä¿®æ­£ç­–ç•¥ï¼›
3. ğŸ§© **æ¢ç´¢æ›´å¤æ‚çš„è¯¾ç¨‹å­¦ä¹ ç­–ç•¥**ï¼šè¶…è¶Šä¸¤é˜¶æ®µï¼Œæ„å»ºæ¸è¿›å¼ä»»åŠ¡éš¾åº¦æ›²çº¿ï¼›
4. ğŸ“Š **æå‡ºâ€œæ”¿ç­–å¯æ‰§è¡Œæ€§â€è¯„ä¼°æŒ‡æ ‡**ï¼šä¸ä»…çœ‹å¥–åŠ±é«˜ä½ï¼Œè¿˜éœ€è¡¡é‡æ˜¯å¦èƒ½åœ¨äº¤äº’é¢„ç®—å†…è¾¾æˆç›®æ ‡ï¼›
5. ğŸ”¬ **æ‰©å±•è‡³ææ–™ç§‘å­¦ã€å‚¬åŒ–å‰‚è®¾è®¡ç­‰é¢†åŸŸ**ï¼šéªŒè¯ MolAct æ¡†æ¶çš„é€šç”¨æ€§ã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> MolAct é¦–æ¬¡å°†åˆ†å­è®¾è®¡å»ºæ¨¡ä¸º **Agentic RL é—®é¢˜**ï¼Œé€šè¿‡ **ä¸¤é˜¶æ®µè®­ç»ƒ + å·¥å…·å¢å¼ºä»£ç†** å®ç°äº†é«˜æœ‰æ•ˆæ€§ã€å¯è§£é‡Šã€é«˜æ€§èƒ½çš„åˆ†å­ç¼–è¾‘ä¸ä¼˜åŒ–ï¼Œä¸º AI é©±åŠ¨è¯ç‰©å‘ç°æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 8. [SpidR: Learning Fast and Stable Linguistic Units for Spoken Language Models Without Supervision](https://arxiv.org/abs/2512.20308)

**Authors**: Maxime Poli, Mahi Luthra, Youssef Benchekroun, Yosuke Higuchi, Martin Gleize, Jiayi Shen, Robin Algayres, Yu-An Chung, Mido Assran, Juan Pino, Emmanuel Dupoux  
**Category**: cs.CL  
**Published**: 2025-12-24  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.20308v1  

#### Abstract
The parallel advances in language modeling and speech representation learning have raised the prospect of learning language directly from speech without textual intermediates. This requires extracting semantic representations directly from speech. Our contributions are threefold. First, we introduce...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSpidR: Learning Fast and Stable Linguistic Units for Spoken Language Models Without Supervision

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ç”¨äº**Spoken Language Modeling (SLM)** çš„è‡ªç›‘ç£è¯­éŸ³è¡¨ç¤ºæ¨¡å‹ï¼ˆå¦‚ wav2vec 2.0ã€HuBERTï¼‰å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **è¯­éŸ³å•å…ƒè´¨é‡ä¸ç¨³å®š**ï¼šåœ¨çº¿èšç±»ï¼ˆonline clusteringï¼‰è¿‡ç¨‹å®¹æ˜“å‘ç”Ÿâ€œç æœ¬åç¼©â€ï¼ˆcodebook collapseï¼‰ï¼Œå¯¼è‡´ç¦»æ•£è¯­éŸ³å•å…ƒï¼ˆdiscrete unitsï¼‰è´¨é‡ä¸‹é™ã€‚
- **è®­ç»ƒæ•ˆç‡ä½**ï¼šHuBERT éœ€è¦å¤šè½®è¿­ä»£è®­ç»ƒï¼ˆäº¤æ›¿è¿›è¡Œèšç±»å’Œé¢„è®­ç»ƒï¼‰ï¼Œè€—æ—¶é•¿è¾¾ä¸€å‘¨ï¼›DinoSR è™½ä¸ºå•é˜¶æ®µè®­ç»ƒï¼Œä½†ä»éœ€çº¦180å°æ—¶ã€‚
- **ç¼ºä¹å¯¹ SLM çš„é’ˆå¯¹æ€§ä¼˜åŒ–**ï¼šå¤§å¤šæ•° SSL æ¨¡å‹ä»¥ ASR ä¸ºä¸»è¦ç›®æ ‡è®¾è®¡ï¼Œå…¶è¡¨ç¤ºå¯èƒ½ä¸é€‚åˆç›´æ¥ç”¨äºè¯­è¨€å»ºæ¨¡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSpidR
SpidR æ˜¯ä¸€ç§æ–°çš„è‡ªç›‘ç£è¯­éŸ³è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ï¼Œä¸“ä¸ºé«˜æ•ˆã€ç¨³å®šåœ°ç”Ÿæˆé«˜è´¨é‡è¯­éŸ³å•å…ƒè€Œè®¾è®¡ï¼Œé€‚ç”¨äºæ— æ–‡æœ¬çš„å£è¯­è¯­è¨€å»ºæ¨¡ï¼ˆtextless SLMï¼‰ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰æ”¹è¿›çš„è‡ªè’¸é¦ä¸åœ¨çº¿èšç±»æœºåˆ¶
- å»¶ç»­ DinoSR çš„æ¶æ„ï¼Œé‡‡ç”¨ **self-distillation + online clustering** æ¡†æ¶ã€‚
- **å…³é”®æ”¹è¿›**ï¼šå­¦ç”Ÿç½‘ç»œåœ¨å¤šä¸ªä¸­é—´å±‚ï¼ˆlast K layersï¼‰é¢„æµ‹æ•™å¸ˆç½‘ç»œå¯¹åº”å±‚çš„ç æœ¬åˆ†é…ï¼Œè€Œéä»…ç”¨å­¦ç”Ÿæœ€åä¸€å±‚é¢„æµ‹æ‰€æœ‰æ•™å¸ˆå±‚ã€‚
  > å³ï¼šå­¦ç”Ÿç¬¬ $k$ å±‚ â†’ é¢„æµ‹æ•™å¸ˆç¬¬ $k$ å±‚çš„ nearest neighbor assignmentã€‚
- è¿™ç§â€œå¯¹é½å¼é¢„æµ‹â€å¢å¼ºäº†è®­ç»ƒç¨³å®šæ€§ï¼Œæ˜¾è‘—ç¼“è§£äº†ç æœ¬åç¼©é—®é¢˜ã€‚

#### ï¼ˆ2ï¼‰æ›´å¹³æ»‘çš„æ•™å¸ˆåŠ¨é‡æ›´æ–°ç­–ç•¥
- å°†æ•™å¸ˆç½‘ç»œçš„ EMA decay å‚æ•° $\beta$ è®¾è®¡ä¸ºæŒ‡æ•°å¢é•¿å‡½æ•°ï¼š
  $$
  \beta_t = 1 - (1 - \beta_0)\exp(-t / T)
  $$
  å…¶ä¸­ $\beta_0=0.999$, $T=10000$ã€‚
- ç›¸æ¯”ä¼ ç»Ÿæ’å®šæˆ–åˆ†æ®µå¸¸æ•°è°ƒåº¦ï¼Œè¯¥ç­–ç•¥ä½¿æ•™å¸ˆæ›´å¿«æ”¶æ•›ä¸”æ›´ç¨³å®šã€‚

#### ï¼ˆ3ï¼‰é«˜æ•ˆçš„çº¯ PyTorch å®ç°
- å¼€å‘äº†ä¸€ä¸ªè½»é‡çº§ã€åŸç”Ÿ PyTorch çš„ä»£ç åº“ï¼Œå…¼å®¹ `torch.compile`ï¼Œå¤§å¹…å‡å°‘é€šä¿¡å¼€é”€ã€‚
- æ”¯æŒå¿«é€Ÿè¿­ä»£ä¸å®éªŒæ¢ç´¢ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **æ€§èƒ½** | åœ¨ sWUGGYã€sBLIMPã€tSC ç­‰é›¶æ ·æœ¬ SLM ä»»åŠ¡ä¸Šå…¨é¢ä¼˜äº wav2vec 2.0ã€HuBERTã€WavLM å’Œ DinoSR |
| **ç¨³å®šæ€§** | æ˜¾è‘—é™ä½ç æœ¬å’Œé¢„æµ‹å¤´çš„å›°æƒ‘åº¦ï¼ˆperplexityï¼‰ï¼Œé¿å… codebook collapse |
| **é€Ÿåº¦** | ä»…éœ€ **1å¤©** å®Œæˆé¢„è®­ç»ƒï¼ˆ16 A100 GPUsï¼‰ï¼Œç›¸æ¯” HuBERTï¼ˆ62å°æ—¶ï¼‰ã€DinoSRï¼ˆ180å°æ—¶ï¼‰æé€Ÿæ˜æ˜¾ |
| **ç®€æ´æ€§** | å•é˜¶æ®µè®­ç»ƒï¼Œæ— éœ€å¤–éƒ¨ç‰¹å¾æå–æˆ– K-means èšç±»æ­¥éª¤ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **é¢„è®­ç»ƒæ•°æ®**ï¼šLibriSpeech 960 å°æ—¶éŸ³é¢‘ï¼ˆtrain-other-960ï¼‰
- **ä¸‹æ¸¸è¯­è¨€æ¨¡å‹è®­ç»ƒæ•°æ®**ï¼šLibri-Light å­é›†ï¼ˆ600h / 6k / 60k å°æ—¶ï¼‰
- **è¯„ä¼°æ•°æ®**ï¼šLibriSpeech dev-clean/dev-other ç”¨äº ABXã€MAPã€SLM è¯„ä¼°

### å®éªŒè®¾ç½®
- **æ¨¡å‹ç»“æ„**ï¼š
  - BASE Transformerï¼šL=12 å±‚ï¼Œd=768ï¼ŒFFN=3072ï¼Œ12 å¤´æ³¨æ„åŠ›
  - ä¸‹é‡‡æ ·æ¨¡å—ï¼š7 å±‚å·ç§¯ï¼Œè¾“å‡º 50Hz ç‰¹å¾
  - ç æœ¬æ•°é‡ï¼šK=8 ä¸ªï¼ˆæ¯å±‚ä¸€ä¸ªï¼‰ï¼Œæ¯ä¸ªç æœ¬å¤§å° V=256
- **ä¼˜åŒ–å™¨**ï¼šAdamWï¼Œå³°å€¼å­¦ä¹ ç‡ 5e-4ï¼Œwarmup 12k æ­¥
- **ç¡¬ä»¶**ï¼š16Ã—A100 GPUsï¼Œæ€»æ‰¹å¤§å° 63 åˆ†é’ŸéŸ³é¢‘

### è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ | æè¿° |
|------|------|------|
| **è¿ç»­è¡¨ç¤ºè´¨é‡** | ABX discriminability | åˆ¤æ–­ triphone ä¸­å¿ƒéŸ³ç´ æ˜¯å¦å¯åŒºåˆ†ï¼ˆwithin/across speakerï¼‰ |
| | MAP words | æ£€ç´¢ç›¸åŒè¯ä¾‹çš„èƒ½åŠ›ï¼ˆMean Average Precisionï¼‰ |
| **ç¦»æ•£å•å…ƒè´¨é‡** | ABX (on one-hot) | å¯¹é‡åŒ–åå•å…ƒè®¡ç®— ABX |
| | PNMI | Phone Normalized Mutual Informationï¼Œè¡¡é‡å•å…ƒä¸çœŸå®éŸ³ç´ çš„ç›¸å…³æ€§ |
| **ä¸‹æ¸¸ SLM æ€§èƒ½** | sWUGGY | åŒºåˆ†çœŸè¯ vs ä¼ªè¯ï¼ˆlexicalï¼‰ |
| | sBLIMP | åˆ¤æ–­å¥å­è¯­æ³•æ­£ç¡®æ€§ï¼ˆsyntacticï¼‰ |
| | tSC (topic version) | æ•…äº‹å»¶ç»­åˆç†æ€§åˆ¤æ–­ï¼ˆsemanticï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- wav2vec 2.0
- HuBERT
- WavLM BASE
- data2vec / data2vec 2.0
- DinoSRï¼ˆåŸç‰ˆåŠä½œè€…å¤ç°ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 3ï¼‰

| Model | sWUGGY (all) â†‘ | sWUGGY (in-vocab) â†‘ | sBLIMP â†‘ | tSC â†‘ |
|-------|----------------|--------------------|----------|--------|
| wav2vec 2.0 | 62.29 | 68.50 | 53.34 | 65.97 |
| HuBERT | 65.50 | 73.67 | 55.60 | 68.75 |
| WavLM BASE | 69.74 | 79.88 | 56.60 | 70.35 |
| DinoSR (codebook) | 60.10 | 64.56 | 57.04 | 69.44 |
| **SpidR (codebook)** | **69.78** | **79.98** | **58.10** | **70.14** |
| **SpidR (K-means)** | **71.89** | **82.46** | **59.48** | **70.46** |

> âœ… SpidR åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡è¾¾åˆ°æœ€ä½³æˆ–æ¬¡ä½³è¡¨ç°ï¼Œå°¤å…¶åœ¨è¯æ±‡å±‚é¢æå‡æ˜¾è‘—ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- SpidR åœ¨ **ABX** å’Œ **MAP words** ä¸Šä¹Ÿä¼˜äºå…¶ä»–æ¨¡å‹ï¼ˆè§ Table 2ï¼‰ï¼š
  - ABX within speaker (dev-clean): **3.32%**ï¼ˆSpidRï¼‰vs 3.38%ï¼ˆHuBERTï¼‰vs 4.05%ï¼ˆDinoSRï¼‰
  - MAP words (dev-clean): **66.50%**ï¼ˆSpidRï¼‰vs 46.07%ï¼ˆHuBERTï¼‰vs 63.02%ï¼ˆDinoSRï¼‰

- æ•°æ®æ‰©å±•åˆ†ææ˜¾ç¤ºï¼ŒSpidR åœ¨ä¸åŒè®­ç»ƒæ•°æ®é‡ä¸‹å§‹ç»ˆä¼˜äº HuBERTï¼Œå…·æœ‰ç¨³å®šçš„å¢ç›Šã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 9ï¼‰
éªŒè¯äº†ä¸¤ä¸ªå…³é”®ç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼š

| å˜ä½“ | ABX â†“ | MAP â†‘ | Discrete ABX â†“ | PNMI â†‘ |
|------|-------|-------|---------------|--------|
| DinoSR (reimpl.) | 5.91 | 42.55 | 7.73 | 0.614 |
| + Heads (intermediate pred.) | 4.22 | 63.39 | 7.87 | 0.610 |
| + Exp. EMA | 5.86 | 51.85 | 8.77 | 0.609 |
| **Full SpidR** | **3.92** | **60.88** | **6.31** | **0.602** |

> ğŸ” ç»“è®ºï¼šå¼•å…¥ä¸­é—´å±‚é¢„æµ‹å¤´æ˜¯æ€§èƒ½æå‡ä¸»å› ï¼›å¹³æ»‘ EMA è°ƒåº¦æœ‰åŠ©äºè®­ç»ƒç¨³å®šæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è¯­éŸ³å•å…ƒè´¨é‡ç›´æ¥å½±å“ SLM è¡¨ç°**ï¼š
   - ABX å’Œ PNMI ä¸ä¸‹æ¸¸ SLM æ€§èƒ½é«˜åº¦ç›¸å…³ï¼ˆPearson r â‰ˆ -0.8 ~ 0.8ï¼‰ï¼Œå¯ä½œä¸ºå¯é ä»£ç†æŒ‡æ ‡ã€‚
2. **SpidR æ˜¾è‘—æå‡äº†è®­ç»ƒç¨³å®šæ€§**ï¼š
   - å›°æƒ‘åº¦æ›²çº¿å¹³ç¨³ï¼Œæœªå‡ºç° codebook collapseã€‚
3. **SLM ä¸ ASR çš„ç›®æ ‡å­˜åœ¨å·®å¼‚**ï¼š
   - SpidR åœ¨ SLM ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨ SUPERB ASR å’Œ phoneme recognition ä¸Šä¸å¦‚ DinoSR æˆ– data2vecã€‚
   - è¡¨æ˜â€œé€‚åˆè¯­è¨€å»ºæ¨¡â€çš„è¡¨ç¤º â‰  â€œé€‚åˆè¯­éŸ³è¯†åˆ«â€çš„è¡¨ç¤ºã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¸“æ³¨äºè‹±è¯­å’Œæœ—è¯»ä¹¦ç±è¯­éŸ³**ï¼šæœªéªŒè¯åœ¨å¤šè¯­ç§ã€å™ªå£°ç¯å¢ƒæˆ–å¯¹è¯åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
- **æœªè§£è€¦éè¯­è¨€ä¿¡æ¯**ï¼šå½“å‰æ¨¡å‹ä¾§é‡äºè¯­è¨€å†…å®¹ï¼Œç¼ºä¹å¯¹éŸµå¾‹ã€æƒ…æ„Ÿã€è¯´è¯äººç­‰å±æ€§çš„æ˜¾å¼å»ºæ¨¡ã€‚
- **ç¦»æ•£å•å…ƒä»å…·ä¸Šä¸‹æ–‡ä¾èµ–æ€§**ï¼šå°½ç®¡æ”¹è¿›ï¼Œå•å…ƒä»æœªå®Œå…¨è¾¾åˆ°éŸ³ç´ çº§åˆ«çš„æŠ½è±¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³å¤šè¯­è¨€å’Œç”Ÿæ€åŒ–è¯­éŸ³ï¼ˆecological speechï¼‰åœºæ™¯ã€‚
- æ¢ç´¢å¦‚ä½•åœ¨åŒä¸€ä¸ªç¼–ç å™¨ä¸­åŒæ—¶å­¦ä¹ è¯­è¨€ã€éŸµå¾‹ã€è¯´è¯äººç­‰è§£è€¦è¡¨ç¤ºã€‚
- æ„å»ºç«¯åˆ°ç«¯çš„ textless å¤§æ¨¡å‹ï¼Œæ”¯æŒç”Ÿæˆã€ç†è§£ã€å¯¹è¯ç­‰å¤šç§ä»»åŠ¡ã€‚
- æ¢ç´¢æ›´é€‚åˆ SLM çš„æ–°å‹æ¶æ„ä¸ç›®æ ‡å‡½æ•°ï¼Œè€Œéæ²¿ç”¨ ASR å¯¼å‘çš„è®¾è®¡ã€‚

---

> ğŸ“¦ **å¼€æºä¿¡æ¯**ï¼šä½œè€…å·²å°†è®­ç»ƒä»£ç å’Œæ¨¡å‹æ£€æŸ¥ç‚¹å¼€æºï¼š  
> [https://github.com/facebookresearch/spidr](https://github.com/facebookresearch/spidr)

</details>

---

### 9. [Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits](https://arxiv.org/abs/2512.20578)

**Authors**: Amirhosein Ghasemabadi, Di Niu  
**Category**: cs.CL  
**Published**: 2025-12-24  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.20578v1  

#### Abstract
Large language models (LLMs) generate fluent and complex outputs but often fail to recognize their own mistakes and hallucinations. Existing approaches typically rely on external judges, multi-sample consistency, or text-based self-critique, which incur additional compute or correlate weakly with tr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCan LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è™½ç„¶åœ¨ç”Ÿæˆä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†**ç¼ºä¹å¯¹è‡ªèº«é”™è¯¯çš„è¯†åˆ«èƒ½åŠ›**ï¼Œå¸¸å¸¸äº§ç”Ÿè‡ªä¿¡ä½†é”™è¯¯çš„å›ç­”ï¼ˆå³â€œå¹»è§‰â€ï¼‰ã€‚ç°æœ‰çš„è‡ªæ£€æ–¹æ³•ä¾èµ–å¤–éƒ¨è¯„åˆ¤å™¨ã€å¤šé‡‡æ ·ä¸€è‡´æ€§æˆ–åŸºäºæ–‡æœ¬çš„è‡ªæˆ‘æ‰¹åˆ¤ï¼Œè¿™äº›æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- é¢å¤–è®¡ç®—å¼€é”€å¤§ï¼›
- ä¸çœŸå®æ­£ç¡®æ€§ç›¸å…³æ€§å¼±ï¼›
- æ— æ³•åœ¨æ¨ç†è¿‡ç¨‹ä¸­å®æ—¶æ£€æµ‹å¤±è´¥ã€‚

æœ¬æ–‡æå‡ºä¸€ä¸ªæ ¹æœ¬æ€§é—®é¢˜ï¼š**LLMs èƒ½å¦é€šè¿‡è§‚å¯Ÿå…¶å†…éƒ¨çŠ¶æ€æ¥é¢„æµ‹è‡ªèº«çš„å¤±è´¥ï¼Ÿ**

### æå‡ºçš„æ–°æ–¹æ³•ï¼šGnosis
ä½œè€…æå‡ºäº† **Gnosis** â€”â€” ä¸€ç§è½»é‡çº§çš„**å†…åœ¨è‡ªæˆ‘éªŒè¯æœºåˆ¶**ï¼Œä½¿å†»ç»“çš„ LLM èƒ½å¤Ÿé€šè¿‡åˆ†æå…¶æ¨ç†è¿‡ç¨‹ä¸­çš„éšè—çŠ¶æ€ï¼ˆhidden statesï¼‰å’Œæ³¨æ„åŠ›æ¨¡å¼ï¼ˆattention patternsï¼‰æ¥è‡ªæˆ‘åˆ¤æ–­è¾“å‡ºçš„æ­£ç¡®æ€§ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
- **Intrinsic Self-Awarenessï¼ˆå†…åœ¨è‡ªæˆ‘æ„è¯†ï¼‰**  
  ä¸ä¾èµ–å¤–éƒ¨æ¨¡å‹æˆ–é¢å¤–ç”Ÿæˆæ ·æœ¬ï¼Œè€Œæ˜¯ç›´æ¥ä» LLM å†…éƒ¨åŠ¨æ€ä¸­æå–å¯é æ€§ä¿¡å·ã€‚
- **Dual-Stream Introspectionï¼ˆåŒæµå†…çœæ¶æ„ï¼‰**  
  åŒæ—¶å»ºæ¨¡ï¼š
  - **Hidden-State Circuit**ï¼šæ•æ‰è¡¨ç¤ºæ¼”åŒ–çš„è½¨è¿¹ç‰¹å¾ï¼›
  - **Attention Circuit**ï¼šåˆ†ææ³¨æ„åŠ›è·¯ç”±çš„ç¨³å®šæ€§ä¸ç»“æ„æ€§ã€‚
- **Fixed-Budget Compressionï¼ˆå›ºå®šé¢„ç®—å‹ç¼©ï¼‰**  
  å°†å˜é•¿çš„å†…éƒ¨è½¨è¿¹å‹ç¼©ä¸ºå›ºå®šå¤§å°çš„æè¿°ç¬¦ï¼Œä½¿å¾— Gnosis çš„æ¨ç†æˆæœ¬ä¸åºåˆ—é•¿åº¦æ— å…³ï¼Œä»…å¢åŠ çº¦ **5M å‚æ•°** å’Œæä½å»¶è¿Ÿï¼ˆ~25msï¼‰ã€‚
- **Zero-Shot Generalizationï¼ˆé›¶æ ·æœ¬æ³›åŒ–ï¼‰**  
  æ”¯æŒè·¨æ¨¡å‹å°ºåº¦è¿ç§»ï¼ˆå¦‚åœ¨ 1.7B ä¸Šè®­ç»ƒå¯åˆ¤æ–­ 8B æ¨¡å‹ï¼‰ã€æ—©æœŸå¤±è´¥æ£€æµ‹ï¼ˆpartial generation åˆ¤æ–­ï¼‰ï¼Œå®ç°è®¡ç®—æ„ŸçŸ¥æ§åˆ¶ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³•ç±»å‹ | å…¸å‹ä»£è¡¨ | ç¼ºé™· | Gnosis çš„ä¼˜åŠ¿ |
|--------|---------|------|-------------|
| å¤–éƒ¨è¯„åˆ¤å™¨ | SkyworkRM, Gemini 2.5 Pro | æˆæœ¬é«˜ã€éœ€æ ‡æ³¨æ•°æ®ã€éƒ¨ç½²å¤æ‚ | æ›´å°ï¼ˆ~5M vs 8Bï¼‰ã€æ— éœ€å¾®è°ƒã€é›¶é¢å¤–ä¸–ç•ŒçŸ¥è¯† |
| æ–‡æœ¬è‡ªè¯„ | Logit Entropy, Self-Critique | åªåæ˜ æµç•…åº¦è€Œéé€»è¾‘æ­£ç¡®æ€§ | åŸºäºå†…éƒ¨è¡¨å¾ï¼Œæ›´è´´è¿‘çœŸå®é”™è¯¯æœºåˆ¶ |
| å¤šæ ·æœ¬ä¸€è‡´æ€§ | Self-Consistency | æ¨ç†æˆæœ¬éšæ ·æœ¬æ•°çº¿æ€§å¢é•¿ | å•æ¬¡å‰å‘å³å¯å®Œæˆåˆ¤æ–­ |
| å•tokenæ¢é’ˆ | MLP-Probe | å¿½ç•¥ç”Ÿæˆå…¨è¿‡ç¨‹çš„æ—¶ç©ºç»“æ„ | åˆ©ç”¨å®Œæ•´ç”Ÿæˆè½¨è¿¹çš„ spatiotemporal ç»“æ„ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼ˆæ··åˆé¢†åŸŸï¼‰ï¼š
  - æ•°å­¦æ¨ç†ï¼šDAPO-Math-17kï¼ˆçº¦14kç«èµ›é¢˜ï¼‰
  - å¼€æ”¾åŸŸé—®ç­”ï¼šTriviaQA å­é›†ï¼ˆ40ké—®é¢˜ï¼‰
- **æµ‹è¯•åŸºå‡†**ï¼ˆä¸‰ä¸ªç‹¬ç«‹é¢†åŸŸï¼‰ï¼š
  1. **Math-Reasoning**ï¼šAMC12ã€AIME24/25ã€HMMTFeb2025ï¼ˆå¤šæ­¥ç¬¦å·æ¨ç†ï¼‰
  2. **Open-Domain QA**ï¼šTriviaQAï¼ˆheld-out 18kï¼ŒçŸ­äº‹å®ç­”æ¡ˆï¼‰
  3. **Academic Knowledge**ï¼šMMLU-Proï¼ˆ14ä¸ªå­¦ç§‘ï¼Œout-of-distribution æ³›åŒ–ï¼‰

æ‰€æœ‰æ•°æ®å‡è‡ªåŠ¨æ ‡æ³¨ï¼ˆå¯¹æ¯” GT åˆ¤æ–­æ­£è¯¯ï¼‰ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚

### å®éªŒè®¾ç½®
- **Backbone æ¨¡å‹**ï¼ˆå…¨éƒ¨å†»ç»“ï¼‰ï¼š
  - Qwen3 ç³»åˆ—ï¼š1.7B-Hybrid, 4B-Thinking, 4B-Instruct, 8B-Hybrid
  - OpenAI gpt-oss-20Bï¼ˆMoE æ¶æ„ï¼‰
- **è¾“å…¥ä¿¡å·**ï¼š
  - æœ€åä¸€å±‚ `hidden states` $ H_{\text{last}} \in \mathbb{R}^{S \times D} $
  - æ‰€æœ‰å±‚çš„ `attention maps` $ A_{l,h} \in \mathbb{R}^{S \times S} $
- **å‹ç¼©æ–¹å¼**ï¼š
  - Hidden Statesï¼šè‡ªé€‚åº”æ± åŒ–è‡³å›ºå®šé•¿åº¦ $ K_{\text{hid}} = 192 $
  - Attention Mapsï¼šä¸‹é‡‡æ ·ä¸º $ k \times k = 256 \times 256 $ ç½‘æ ¼

### è¯„ä¼°æŒ‡æ ‡
å°†æ­£ç¡®æ€§é¢„æµ‹è§†ä¸ºäºŒåˆ†ç±»ä»»åŠ¡ï¼ŒæŠ¥å‘Šï¼š
- **AUROC**ï¼šåŒºåˆ†æ­£ç¡®/é”™è¯¯ç”Ÿæˆçš„èƒ½åŠ›
- **AUPR-c / AUPR-e**ï¼šåˆ†åˆ«ä»¥â€œæ­£ç¡®â€æˆ–â€œé”™è¯¯â€ä¸ºæ­£ç±»çš„ç²¾ç¡®ç‡-å¬å›æ›²çº¿ä¸‹é¢ç§¯
- **Brier Skill Score (BSS)**ï¼šæ ¡å‡†è´¨é‡ï¼ˆ>0 è¡¨ç¤ºä¼˜äºå…ˆéªŒåŸºçº¿ï¼‰
- **Expected Calibration Error (ECE)**ï¼šè¶Šä½è¶Šå¥½ï¼Œè¡¡é‡é¢„æµ‹æ¦‚ç‡ä¸å®é™…å‡†ç¡®ç‡çš„ä¸€è‡´æ€§

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | åŸºçº¿æ–¹æ³• |
|------|--------|
| å†…éƒ¨ç»Ÿè®¡æŒ‡æ ‡ | Logit Entropy, Mean Token Prob, Attn Eigenvalue Score |
| è·¨å±‚åŠ¨æ€åˆ†æ | CoE-R, CoE-C |
| å¤–éƒ¨è¯„åˆ¤å™¨ | SkyworkRM-Llama3.1-8B, SkyworkRM-Qwen3-8B, Gemini 2.5 Pro |
| å¯å­¦ä¹ æ¢é’ˆ | MLP-Probï¼ˆä»…æœ€ç»ˆtokenéšè—æ€ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1 & 2ï¼‰

| æ–¹æ³• | Math-Reasoning (AUROC) | TriviaQA (AUROC) | MMLU-Pro (AUROC) |
|------|------------------------|------------------|------------------|
| **Gnosis (Ours)** | **0.95â€“0.96** | **0.87â€“0.89** | **0.80â€“0.82** |
| SkyworkRM-Qwen3-8B | 0.90â€“0.93 | 0.72â€“0.84 | 0.73â€“0.76 |
| Gemini 2.5 Pro | 0.88â€“0.92 | 0.79â€“0.83 | 0.70â€“0.78 |
| Logit Entropy | ~0.79 | ~0.64 | ~0.73 |

> âœ… Gnosis åœ¨æ‰€æœ‰é¢†åŸŸå‡æ˜¾è‘—è¶…è¶Šå¤–éƒ¨è¯„åˆ¤å™¨ï¼ˆåŒ…æ‹¬ç™¾äº¿ç¾å…ƒçº§ Geminiï¼‰ï¼Œä¸”å‚æ•°é‡ä»…ä¸ºåè€…çš„ **1/1000**ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç›¸æ¯”å†…éƒ¨æŒ‡æ ‡**ï¼š
  - AUROC æå‡çº¦ 15â€“20 ptsï¼ˆå¦‚ä» 0.79 â†’ 0.95ï¼‰
  - BSS ä»è´Ÿå€¼è½¬ä¸ºæ­£å€¼ï¼ˆè¡¨æ˜æ ¡å‡†è´¨é‡å¤§å¹…æå‡ï¼‰
- **ç›¸æ¯” MLP-Prob æ¢é’ˆ**ï¼ˆTable 2ï¼‰ï¼š
  - åœ¨ Math ä¸Š AUROC ä» 0.86 â†’ 0.95ï¼ˆ+9 ptsï¼‰
  - è¯æ˜**æ•´ä¸ªç”Ÿæˆè½¨è¿¹çš„ä¿¡æ¯è¿œè¶…å•ä¸€ token**
- **æ•ˆç‡å¯¹æ¯”**ï¼ˆTable 4ï¼‰ï¼š
  - å½“å“åº”é•¿åº¦è¾¾ 24k tokens æ—¶ï¼ŒGnosis æ¯” SkyworkRM å¿« **99å€**ï¼ˆ25ms vs 2465msï¼‰
  - å»¶è¿Ÿå‡ ä¹ä¸éšé•¿åº¦å¢é•¿

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰åŒæµæ¶æ„æœ‰æ•ˆæ€§ï¼ˆTable 5ï¼‰
| æ¨¡å‹å˜ä½“ | Math AUROC | TriviaQA AUROC | MMLU-Pro AUROC |
|---------|------------|---------------|----------------|
| Hidden-Only | 0.92 | 0.87 | 0.78 |
| Attention-Only | 0.92 | 0.78 | 0.80 |
| **Full Gnosis (Fused)** | **0.95** | **0.87** | **0.80** |

> ğŸ” å‘ç°ï¼šéšè—æ€ä¸»å¯¼çŸ­äº‹å®ä»»åŠ¡ï¼ˆTriviaQAï¼‰ï¼Œæ³¨æ„åŠ›æµåœ¨é•¿æ¨ç†ä»»åŠ¡ä¸­æ›´é‡è¦ï¼Œèåˆæ•ˆæœæœ€ä½³ã€‚

#### ï¼ˆ2ï¼‰æ³¨æ„åŠ›ç‰¹å¾æå–å™¨æ¯”è¾ƒï¼ˆTable 6ï¼‰
| æå–æ–¹å¼ | Math AUROC | TriviaQA AUROC | MMLU-Pro AUROC |
|----------|-----------|----------------|----------------|
| CNN-only | 0.92 | 0.79 | 0.79 |
| Stats-only | 0.92 | 0.75 | 0.76 |
| **CNN+Stats (hybrid)** | **0.92** | **0.78** | **0.80** |

> âœ… Hybrid è®¾è®¡æœ€ç¨³å®šï¼Œå…¼å…·å¯è§£é‡Šæ€§ä¸è¡¨è¾¾åŠ›ã€‚

#### ï¼ˆ3ï¼‰å…¶ä»–å…³é”®è®¾è®¡é€‰æ‹©
- **ç§»é™¤å±€éƒ¨æ—¶é—´å·ç§¯ï¼ˆPhase 1ï¼‰**ï¼šAUROC â†“ 0.03ï¼ˆè¯´æ˜å±€éƒ¨åŠ¨æ€å»ºæ¨¡é‡è¦ï¼‰
- **æ›¿æ¢ PMA ä¸ºå¹³å‡æ± åŒ–**ï¼šAUROC â†“ 0.07ï¼ˆè¯´æ˜ learnable prototype æ›´æœ‰æ•ˆï¼‰
- **ç®€åŒ–ä¸º Pooled-MLP åŸºçº¿**ï¼šAUROC â†“ 0.10ï¼ˆè¯æ˜å…¨å±€äº¤äº’å¿…è¦ï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **LLMs çš„å†…éƒ¨çŠ¶æ€è•´å«ä¸°å¯Œçš„å¯é æ€§ä¿¡å·**  
   æ­£ç¡®ä¸é”™è¯¯ç”Ÿæˆåœ¨éšè—æ€å’Œæ³¨æ„åŠ›åˆ†å¸ƒä¸Šæœ‰æ˜æ˜¾å·®å¼‚ï¼Œå¯é€šè¿‡è½»é‡æ¨¡å—æœ‰æ•ˆè§£ç ã€‚
2. âœ… **Gnosis æ˜¯é¦–ä¸ªçœŸæ­£é«˜æ•ˆçš„ intrinsic self-verifier**  
   ä»…æ·»åŠ  ~5M å‚æ•°ï¼Œåœ¨å¤šä¸ª backbone ä¸Šä¸€è‡´ä¼˜äºæ•°åäº¿å‚æ•°çš„å¤–éƒ¨è¯„åˆ¤å™¨ã€‚
3. âœ… **æ”¯æŒ zero-shot è·¨æ¨¡å‹åˆ¤æ–­ï¼ˆSibling Modelingï¼‰**  
   åœ¨ 1.7B ä¸Šè®­ç»ƒçš„ Gnosis å¯ç›´æ¥ç”¨äºåˆ¤æ–­ 4B/8B æ¨¡å‹è¾“å‡ºï¼ŒAUROC è¾¾ 0.93â€“0.97ï¼Œç”šè‡³è¶…è¿‡ä¸“ç”¨ reward modelã€‚
4. âœ… **æ”¯æŒ early failure detection**  
   è§‚å¯Ÿåˆ° 40% çš„ç”Ÿæˆè·¯å¾„åå³å¯è¾¾åˆ°æ¥è¿‘å®Œæ•´çš„åˆ¤æ–­æ€§èƒ½ï¼Œå¯ç”¨äºæå‰ç»ˆæ­¢æ— æ•ˆæ¨ç†é“¾ï¼ŒèŠ‚çœç®—åŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- â— **éé€šç”¨ reward model**ï¼šé€‚ç”¨äºåŒä¸€å®¶æ—æ¨¡å‹ï¼ˆå¦‚ Qwen3 ç³»åˆ—ï¼‰ï¼Œéš¾ä»¥è¿ç§»åˆ°æ¶æ„æˆ–ç”Ÿæˆé£æ ¼è¿¥å¼‚çš„æ¨¡å‹ï¼ˆå¦‚ Thinking â†’ Instructï¼‰ã€‚
- â— **ä¾èµ–é«˜è´¨é‡è®­ç»ƒä¿¡å·**ï¼šç›®å‰ä¾èµ–è‡ªåŠ¨æ ‡æ³¨ï¼ˆGT å¯¹æ¯”ï¼‰ï¼Œè‹¥ GT ä¸å¯ç”¨åˆ™éœ€å¼•å…¥äººç±»åé¦ˆæˆ–å…¶ä»–ä»£ç†ä¿¡å·ã€‚
- â— **æœªå¤„ç† non-response æˆ–æ ¼å¼é”™è¯¯**ï¼šå®éªŒä¸­å·²è¿‡æ»¤æ— æœ‰æ•ˆç­”æ¡ˆçš„æƒ…å†µã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- ğŸ”„ å°† Gnosis é›†æˆåˆ° test-time scaling ä¸­ï¼Œå®ç°åŠ¨æ€è®¡ç®—åˆ†é…ï¼›
- ğŸ” ç”¨äºå¼ºåŒ–å­¦ä¹ ä¸­çš„è¿‡ç¨‹å¥–åŠ±å»ºæ¨¡ï¼ˆProcess Reward Modelingï¼‰ï¼›
- ğŸ§  æ¢ç´¢æ›´ç»†ç²’åº¦çš„â€œå…ƒè®¤çŸ¥â€æœºåˆ¶ï¼Œä¾‹å¦‚å®šä½å…·ä½“å“ªä¸€æ­¥å‡ºé”™ï¼›
- ğŸŒ æ‰©å±•è‡³å¤šæ¨¡æ€æ¨¡å‹çš„è‡ªæˆ‘ç›‘æ§ã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> Gnosis è¯æ˜äº† LLMs å¯ä»¥é€šè¿‡â€œå†…è§‚â€è‡ªå·±çš„éšè—æ€å’Œæ³¨æ„åŠ›æ¨¡å¼æ¥å¯é åœ°é¢„æµ‹å¤±è´¥ï¼Œå®ç°äº†é«˜æ•ˆã€å¯æ‰©å±•ã€æ— éœ€å¤–éƒ¨ç›‘ç£çš„è‡ªæˆ‘æ„è¯†æœºåˆ¶ï¼Œä¸ºæ„å»ºå®‰å…¨ã€å¯æ§çš„è¯­è¨€ç³»ç»Ÿæä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 10. [WOC: Dual-Path Weighted Object Consensus Made Efficient](https://arxiv.org/abs/2512.20485)

**Authors**: Tanisha Fonseca, Gengrui Zhang  
**Category**: cs.DC  
**Published**: 2025-12-24  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.20485v1  

#### Abstract
Modern distributed systems face a critical challenge: existing consensus protocols optimize for either node heterogeneity or workload independence, but not both. For example, Cabinet leverages weighted quorums to handle node heterogeneity but serializes all operations through a global leader, limiti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šWOC: Dual-Path Weighted Object Consensus Made Efficient

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£åˆ†å¸ƒå¼ç³»ç»Ÿä¸­çš„å…±è¯†åè®®é€šå¸¸åªèƒ½ä¼˜åŒ–**èŠ‚ç‚¹å¼‚æ„æ€§**ï¼ˆnode heterogeneityï¼‰æˆ–**æ“ä½œç‹¬ç«‹æ€§**ï¼ˆworkload independenceï¼‰ä¸­çš„ä¸€ä¸ªç»´åº¦ï¼Œæ— æ³•å…¼é¡¾ä¸¤è€…ï¼š
- **Cabinet** ä½¿ç”¨åŠ æƒå¤šæ•°ï¼ˆweighted quorumsï¼‰å¤„ç†èŠ‚ç‚¹æ€§èƒ½å·®å¼‚ï¼Œä½†æ‰€æœ‰æ“ä½œéƒ½é€šè¿‡å•ä¸€å…¨å±€ leader åºåˆ—åŒ–ï¼Œé™åˆ¶äº†å¹¶è¡Œæ€§ã€‚
- **EPaxos** æ”¯æŒç‹¬ç«‹æ“ä½œçš„å¹¶è¡Œæ‰§è¡Œï¼Œä½†å‡è®¾æ‰€æœ‰å‰¯æœ¬èƒ½åŠ›ç›¸åŒï¼Œå¿½ç•¥äº†èŠ‚ç‚¹é—´çš„æ€§èƒ½å·®å¼‚ã€‚

è¿™ç§å‰²è£‚å¯¼è‡´åœ¨çœŸå®å¼‚æ„ç¯å¢ƒä¸­éš¾ä»¥åŒæ—¶å®ç°é«˜ååä¸ä½å»¶è¿Ÿã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **WOC**ï¼ˆWeighted Object Consensusï¼‰ï¼Œä¸€ç§**åŒè·¯å¾„å…±è¯†åè®®**ï¼ˆdual-path consensus protocolï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- æ ¹æ®æ“ä½œçš„è®¿é—®æ¨¡å¼åŠ¨æ€è·¯ç”±åˆ°ä¸¤æ¡è·¯å¾„ï¼š
  - **Fast Pathï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰**ï¼šç”¨äº**ç‹¬ç«‹å¯¹è±¡**ï¼ˆIndependent Objectsï¼‰ï¼Œé‡‡ç”¨**å¯¹è±¡ç²’åº¦åŠ æƒå…±è¯†**ï¼ˆobject-weighted consensusï¼‰ï¼Œæ— éœ€ leaderï¼Œå®Œæˆäº**ä¸€æ¬¡ç½‘ç»œå¾€è¿”**ï¼ˆ1 RTTï¼‰ã€‚
  - **Slow Pathï¼ˆæ…¢é€Ÿè·¯å¾„ï¼‰**ï¼šç”¨äº**å…±äº«æˆ–å†²çªå¯¹è±¡**ï¼Œç”± leader åè°ƒï¼Œä½¿ç”¨**èŠ‚ç‚¹åŠ æƒå…±è¯†**ï¼ˆnode-weighted consensusï¼‰ï¼Œä¿è¯æ­£ç¡®æ€§å’Œçº¿æ€§ä¸€è‡´æ€§ï¼ˆlinearizabilityï¼‰ã€‚

#### åˆ›æ–°ç‚¹
1. **Dual-Path æ¶æ„è®¾è®¡**  
   é¦–æ¬¡å°†â€œå¯¹è±¡çº§å¹¶è¡Œâ€ä¸â€œèŠ‚ç‚¹çº§æƒé‡â€ç»“åˆï¼Œå®ç°å¯¹**å·¥ä½œè´Ÿè½½ç‰¹å¾**å’Œ**èŠ‚ç‚¹æ€§èƒ½å·®å¼‚**çš„åŒé‡è‡ªé€‚åº”ã€‚

2. **Object-Weighted Consensus**  
   å°†ä¼ ç»Ÿçš„èŠ‚ç‚¹åŠ æƒæ‰©å±•è‡³**å¯¹è±¡ç²’åº¦**ï¼Œæ¯ä¸ªå¯¹è±¡æ‹¥æœ‰ç‹¬ç«‹çš„æƒé‡å‘é‡ `w_O`ï¼Œä¼˜å…ˆé€‰æ‹©å“åº”å¿«çš„å‰¯æœ¬å½¢æˆå°è€Œå¿«çš„ quorumã€‚

3. **å‡ ä½•æƒé‡åˆ†é…æœºåˆ¶**ï¼ˆGeometric Weight Assignmentï¼‰  
   å¼•å…¥å¯è°ƒé™¡åº¦å‚æ•° `R âˆˆ [1.0, 2.0]` æ§åˆ¶æƒé‡åˆ†å¸ƒï¼š
   - `R â‰ˆ 1.3`ï¼šæ›´å‡åŒ€ â†’ æ›´å¼ºå®¹é”™
   - `R â‰ˆ 2.0`ï¼šæ›´é™¡å³­ â†’ æ›´å¿« quorum å½¢æˆï¼ˆä»…éœ€ top å‡ ä¸ªèŠ‚ç‚¹ï¼‰

4. **åŠ¨æ€å¯¹è±¡åˆ†ç±»ä¸è·¯ç”±æœºåˆ¶**  
   è¿è¡Œæ—¶æŒç»­ç›‘æ§æ“ä½œé¢‘ç‡ã€å†²çªç‡ã€å»¶è¿Ÿç­‰æŒ‡æ ‡ï¼Œå°†å¯¹è±¡åˆ†ä¸ºï¼š
   - **Independent Objects** â†’ Fast Path
   - **Common Objects** / **Hot Objects** â†’ Slow Path

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | WOC | Cabinet | EPaxos |
|------|-----|--------|--------|
| èŠ‚ç‚¹å¼‚æ„æ”¯æŒ | âœ…ï¼ˆFast & Slow Pathï¼‰ | âœ…ï¼ˆNode-weightedï¼‰ | âŒï¼ˆEqual votingï¼‰ |
| æ“ä½œå¹¶è¡Œæ€§ | âœ…ï¼ˆFast Path å¹¶è¡Œæäº¤ï¼‰ | âŒï¼ˆå…¨éƒ¨åºåˆ—åŒ–ï¼‰ | âœ…ï¼ˆä¾èµ–åˆ†æï¼‰ |
| ååé‡ï¼ˆä½å†²çªï¼‰ | â¬†ï¸â¬†ï¸â¬†ï¸ | ä¸­ç­‰ | é«˜ï¼ˆä½†æ— è§†èŠ‚ç‚¹å·®å¼‚ï¼‰ |
| æ­£ç¡®æ€§ä¿éšœ | âœ…ï¼ˆè·¨è·¯å¾„ä¸€è‡´æ€§ï¼‰ | âœ… | âœ… |

> âœ… WOC åœ¨ä¿æŒé«˜äº‰ç”¨ä¸‹ç­‰æ•ˆæ€§èƒ½çš„åŒæ—¶ï¼Œåœ¨ä½äº‰ç”¨åœºæ™¯ä¸‹æ˜¾è‘—ä¼˜äº Cabinetã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### å®éªŒç¯å¢ƒ
- **å¹³å°**ï¼šCompute Canada äº‘åŸºç¡€è®¾æ–½
- **éƒ¨ç½²é…ç½®**ï¼š
  - é»˜è®¤ï¼š5 ä¸ª replica æœåŠ¡å™¨ + 2 ä¸ª client VM
  - å®¹é”™é˜ˆå€¼ï¼šå®¹å¿ `f=2` æ•…éšœï¼ˆå³ `n â‰¥ 5`ï¼‰
- **å®ç°è¯­è¨€**ï¼šGo

### å·¥ä½œè´Ÿè½½è®¾ç½®
- **é»˜è®¤æ··åˆè´Ÿè½½åˆ†å¸ƒ**ï¼š
  - 90% **Independent Objects**ï¼ˆé€‚åˆ Fast Pathï¼‰
  - 5% **Common Objects**ï¼ˆå¶å°”å†²çªï¼‰
  - 5% **Conflicting Objects**ï¼ˆçƒ­ç‚¹å¯¹è±¡ï¼Œèµ° Slow Pathï¼‰
- **æ¶ˆæ¯å¤§å°**ï¼š512 å­—èŠ‚
- **å®¢æˆ·ç«¯è¡Œä¸º**ï¼šOpen-loop è¯·æ±‚ç”Ÿæˆï¼Œæœ€å¤š 5 ä¸ª in-flight è¯·æ±‚

### è¯„ä¼°ç»´åº¦
1. **Batch Size Scaling**ï¼šæ‰¹å¤§å°ä» 1 åˆ° 4000
2. **Conflict Rate Sensitivity**ï¼šå†²çªç‡ä» 0% åˆ° 100%
3. **Client Concurrency**ï¼šå¹¶å‘å®¢æˆ·ç«¯æ•°ä» 2 åˆ° 9
4. **Server Scalability**ï¼šå‰¯æœ¬æ•°é‡ä» 3 åˆ° 9

### è¯„ä¼°æŒ‡æ ‡
- **Throughput**ï¼ˆTx/secï¼‰
- **P50 Latency**
- **Average Latency**

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Cabinet**ï¼šå½“å‰æœ€å…ˆè¿›çš„ weighted consensus åè®®ï¼Œä½œä¸ºä¸»è¦å¯¹æ¯”åŸºå‡†
- ï¼ˆéšå«å‚è€ƒ EPaxos è®¾è®¡ç†å¿µï¼Œä½†æœªç›´æ¥æ¯”è¾ƒï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| åœºæ™¯ | WOC æ€§èƒ½ | Cabinet æ€§èƒ½ | æå‡å€æ•° |
|------|----------|-------------|---------|
| **Batch Size = 1000** | 220.8k Tx/sec | 77.8k Tx/sec | ~2.8Ã— |
| **Batch Size = 4000** | 390k Tx/sec | 161k Tx/sec | ~2.4Ã— |
| **Conflict Rate = 0â€“10%** | 55.9kâ€“57.1k Tx/sec | 14.9kâ€“15.7k Tx/sec | ~3.8Ã— |
| **Conflict Rate = 50%** | 27.3k Tx/sec | 15.9k Tx/sec | ~1.7Ã— |
| **Conflict Rate = 75â€“100%** | 11.2kâ€“12.3k Tx/sec | 15.9kâ€“16.2k Tx/sec | âŒï¼ˆè½åï¼‰ |
| **Clients = 9** | 144.1k Tx/sec | 16.3k Tx/sec | ~8.8Ã— |
| **Servers = 9** | 92.4k Tx/sec | 15.7k Tx/sec | ~5.9Ã— |

> ğŸ”º **æœ€é«˜æå‡è¾¾ 4Ã— ååé‡**ï¼ˆåŸæ–‡æ‘˜è¦ç§° up to 4Ã—ï¼‰

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ
- **ä½å†²çªåœºæ™¯ï¼ˆ<70%ï¼‰**ï¼š
  - WOC ååè¿œè¶… Cabinetï¼ˆ3â€“4Ã—ï¼‰
  - æ‰€æœ‰ç‹¬ç«‹æ“ä½œå¯é€šè¿‡ Fast Path å¹¶è¡Œæäº¤
- **é«˜å†²çªåœºæ™¯ï¼ˆ>75%ï¼‰**ï¼š
  - WOC æ€§èƒ½ä¸‹é™æ˜æ˜¾ï¼Œè¢« Cabinet åè¶…
  - å› ä¸ºå¤§éƒ¨åˆ†æ“ä½œè¿›å…¥ Slow Pathï¼Œä¸” Fast Path çš„åè°ƒå¼€é”€æˆä¸ºè´Ÿæ‹…
- **å®¢æˆ·ç«¯æ‰©å±•æ€§**ï¼š
  - WOC å‡ ä¹çº¿æ€§å¢é•¿ï¼ˆ2â†’7 clientsï¼‰ï¼Œè€Œ Cabinet å‡ ä¹ä¸å˜ï¼ˆleader æˆç“¶é¢ˆï¼‰
- **æœåŠ¡å™¨æ‰©å±•æ€§**ï¼š
  - WOC éšèŠ‚ç‚¹å¢åŠ æŒç»­æå‡ååï¼ˆ+66% from 3â†’9 nodesï¼‰
  - Cabinet ä»…å¾®å¹…æå‡ï¼ˆ+10%ï¼‰ï¼Œå—é™äºä¸­å¿ƒåŒ–æ¶æ„

### æ¶ˆèå®éªŒä¸åˆ†æï¼ˆéšå«ï¼‰
è™½ç„¶æ²¡æœ‰æ˜¾å¼çš„æ¶ˆèå®éªŒè¡¨æ ¼ï¼Œä½†é€šè¿‡å¤šç»´æµ‹è¯•å¯æ¨æ–­ä»¥ä¸‹ç»“è®ºï¼š
- **Fast Path æ˜¯æ€§èƒ½ä¼˜åŠ¿æ¥æº**ï¼šå½“ç‹¬ç«‹å¯¹è±¡å æ¯”é«˜æ—¶ï¼ŒWOC å……åˆ†åˆ©ç”¨å¹¶è¡Œæ€§ã€‚
- **Object-weighted quorum æœ‰æ•ˆé™ä½å»¶è¿Ÿ**ï¼šTop åŠ æƒèŠ‚ç‚¹å³å¯è¾¾æˆ quorumï¼Œé¿å…ç­‰å¾…æ…¢èŠ‚ç‚¹ã€‚
- **Dynamic routing æœºåˆ¶åˆç†**ï¼šå†²çªæ£€æµ‹ä¸è·¯å¾„åˆ‡æ¢ç¡®ä¿äº†å®‰å…¨æ€§ä¸æ•ˆç‡å¹³è¡¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **åŒè·¯å¾„è®¾è®¡æ˜¾è‘—æå‡ä½äº‰ç”¨åœºæ™¯ä¸‹çš„ååé‡**ï¼Œç›¸æ¯” Cabinet æœ€é«˜è¾¾ **4Ã—**ã€‚
2. âœ… **å¯¹è±¡ç²’åº¦åŠ æƒå…±è¯†**ï¼ˆobject-weighted consensusï¼‰èƒ½æœ‰æ•ˆåˆ©ç”¨å±€éƒ¨è®¿é—®æ¨¡å¼ï¼ŒåŠ é€Ÿ quorum å½¢æˆã€‚
3. âœ… **åŠ¨æ€è·¯ç”±æœºåˆ¶**å®ç°äº†å¯¹ workload å’Œ replica performance çš„åŒé‡è‡ªé€‚åº”ã€‚
4. âš ï¸ **é«˜å†²çªåœºæ™¯ä¸‹æ€§èƒ½åŠ£äº Cabinet**ï¼Œè¯´æ˜ Fast Path å¼€é”€åœ¨æç«¯æƒ…å†µä¸‹ä¸å¯å¿½ç•¥ã€‚
5. ğŸ“ˆ **è‰¯å¥½çš„æ¨ªå‘æ‰©å±•èƒ½åŠ›**ï¼šæ— è®ºæ˜¯ client è¿˜æ˜¯ server æ•°é‡å¢åŠ ï¼ŒWOC å‡è¡¨ç°å‡ºè‰¯å¥½å¯æ‰©å±•æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **é«˜å†²çªè´Ÿè½½ä¸é€‚ç”¨**ï¼šå½“ >75% æ“ä½œå­˜åœ¨å†²çªæ—¶ï¼ŒWOC ä¸å†å…·æœ‰ä¼˜åŠ¿ã€‚
2. **é¢å¤–å…ƒæ•°æ®å¼€é”€**ï¼šéœ€è¦ç»´æŠ¤ per-object æƒé‡ã€in-flight mapã€åˆ†ç±»çŠ¶æ€ç­‰ï¼Œå¸¦æ¥å†…å­˜å’Œè®¡ç®—æˆæœ¬ã€‚
3. **ç›®å‰åŸºäº CFT æ¨¡å‹**ï¼šå°šæœªæ”¯æŒ Byzantine Fault Toleranceï¼ˆBFTï¼‰ï¼Œé™åˆ¶äº†åœ¨å¼€æ”¾ç½‘ç»œä¸­çš„åº”ç”¨ã€‚
4. **æƒé‡æ›´æ–°ç­–ç•¥ä¾èµ–å“åº”æ—¶é—´**ï¼šå¯èƒ½å—ç¬æ—¶æŠ–åŠ¨å½±å“ï¼Œéœ€æ›´é²æ£’çš„åé¦ˆæœºåˆ¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **è‡ªé€‚åº”é˜ˆå€¼è°ƒèŠ‚**ï¼ˆadaptive threshold tuningï¼‰ï¼šæ ¹æ®å®æ—¶è´Ÿè½½è‡ªåŠ¨è°ƒæ•´ `R` å‚æ•°ã€‚
2. **é›†æˆ BFT æ”¯æŒ**ï¼šæ¢ç´¢åœ¨ WOC ä¸­å¼•å…¥ Byzantine fault toleranceã€‚
3. **åœ°ç†åˆ†å¸ƒå¼éƒ¨ç½²éªŒè¯**ï¼šåœ¨è·¨åŒºåŸŸï¼ˆgeo-distributedï¼‰ç¯å¢ƒä¸‹è¯„ä¼°æ€§èƒ½æ”¶ç›Šã€‚
4. **æ›´ç²¾ç»†çš„å¯¹è±¡åˆ†ç±»æ¨¡å‹**ï¼šå¼•å…¥æœºå™¨å­¦ä¹ é¢„æµ‹å†²çªæ¦‚ç‡ï¼Œä¼˜åŒ–è·¯å¾„å†³ç­–ã€‚

---

## æ€»ç»“
WOC æ˜¯ä¸€ç§é¢å‘ç°ä»£å¼‚æ„åˆ†å¸ƒå¼ç³»ç»Ÿçš„é«˜æ•ˆå…±è¯†åè®®ï¼Œé€šè¿‡**åŒè·¯å¾„æ¶æ„ + å¯¹è±¡çº§åŠ æƒæŠ•ç¥¨ + åŠ¨æ€è·¯ç”±**ï¼ŒæˆåŠŸè§£å†³äº†ä¼ ç»Ÿåè®®åœ¨â€œèŠ‚ç‚¹å¼‚æ„â€ä¸â€œæ“ä½œç‹¬ç«‹â€ä¹‹é—´çš„æƒè¡¡éš¾é¢˜ã€‚å®ƒåœ¨**ä½åˆ°ä¸­ç­‰å†²çªçš„å·¥ä½œè´Ÿè½½ä¸‹è¡¨ç°å“è¶Š**ï¼Œå±•ç°å‡ºå¼ºå¤§çš„ååèƒ½åŠ›å’Œè‰¯å¥½çš„æ‰©å±•æ€§ï¼Œä¸ºä¸‹ä¸€ä»£é«˜æ€§èƒ½ SMR ç³»ç»Ÿæä¾›äº†æ–°çš„è®¾è®¡èŒƒå¼ã€‚

</details>

---

### 11. [Hard Negative Sample-Augmented DPO Post-Training for Small Language Models](https://arxiv.org/abs/2512.19728)

**Authors**: Haocheng Lu, Minjun Zhu, Henry Yu  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.19728v1  

#### Abstract
Large language models (LLMs) continue to struggle with mathematical reasoning, and common post-training pipelines often reduce each generated solution to a binary outcome: correct or incorrect. This perspective is limiting in practice, as failures in chain-of-thought (CoT) reasoning are frequently s...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Hard Negative Sample-Augmented DPO Post-Training for Small Language Models*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­ä»è¡¨ç°ä¸ä½³ï¼Œè€Œä¸»æµçš„åè®­ç»ƒï¼ˆpost-trainingï¼‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **è¯„ä»·æ–¹å¼è¿‡äºäºŒå…ƒåŒ–**ï¼šä»…å°†è§£é¢˜ç»“æœåˆ†ä¸ºâ€œæ­£ç¡®â€æˆ–â€œé”™è¯¯â€ï¼Œå¿½ç•¥äº†é“¾å¼æ€ç»´ï¼ˆChain-of-Thought, CoTï¼‰ä¸­å¸¸è§çš„**ç»“æ„æ€§é”™è¯¯**ï¼ˆå¦‚é€»è¾‘è·³è·ƒã€ä»£æ•°é”™è¯¯ã€æ•°å€¼åå·®ç­‰ï¼‰ã€‚
- **ä¾èµ–é«˜æˆæœ¬åˆ¤åˆ«æœºåˆ¶**ï¼šå¦‚ä½¿ç”¨å¤§å‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰æˆ– LLM-as-a-judge è¿›è¡Œåå¥½æ ‡æ³¨ï¼Œå¸¦æ¥é«˜æ˜‚è®¡ç®—å¼€é”€ã€è¯¯å·®ä¼ æ’­å’Œåˆ¤æ–­ä¸ç¨³å®šæ€§ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§**è½»é‡çº§ã€å¯æ‰©å±•çš„å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰åè®­ç»ƒæ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ˜¯ï¼š
1. **MathVerifier**ï¼šä¸€ä¸ªè½»é‡åŒ–çš„åŒé€šé“éªŒè¯å™¨ï¼Œå¯¹å€™é€‰è§£è¿›è¡Œå…­ç»´é”™è¯¯åˆ†æï¼Œå¹¶ç”Ÿæˆå¯è§£é‡Šçš„ `wrongness` å’Œ `absurdity` åˆ†æ•°ã€‚
2. **Hard Negative Mining**ï¼šåˆ©ç”¨ verifier ä¿¡å·è‡ªåŠ¨æŒ–æ˜â€œçœ‹ä¼¼åˆç†ä½†ç»“æ„é”™è¯¯â€çš„**å›°éš¾è´Ÿæ ·æœ¬**ï¼ˆhard negativesï¼‰ï¼Œå³æ¨¡å‹è‡ªä¿¡è¾“å‡ºä½†å­˜åœ¨ç»†å¾®é€»è¾‘/æ•°å€¼ç¼ºé™·çš„è§£ã€‚
3. **Verifier-Guided Weighted DPO**ï¼šå°†è¿™äº› hard negatives æ„é€ æˆé«˜è´¨é‡çš„ preference pairsï¼Œå¹¶å¼•å…¥åŸºäº verifier è¾“å‡ºçš„**æ ·æœ¬é‡è¦æ€§æƒé‡**ï¼Œç”¨äºåŠ æƒ DPOï¼ˆDirect Preference Optimizationï¼‰ç›®æ ‡å‡½æ•°ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | æœ¬æ–‡æ–¹æ³• | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ PRM æˆ– LLM-as-a-judgeï¼‰ |
|------|----------|-------------------------------|
| **æˆæœ¬** | è½»é‡ã€æ— éœ€è®­ç»ƒå¤§å‹ reward model | é«˜æ¨ç†ä¸è®­ç»ƒæˆæœ¬ |
| **ç¨³å®šæ€§** | ç¨‹åºåŒ–æ£€æŸ¥ + è¯­ä¹‰ä¸€è‡´æ€§ï¼Œå‡å°‘ä¸»è§‚åå·® | æ˜“å— judge æ¨¡å‹åè§å½±å“ï¼ˆä½ç½®åç½®ã€è‡ªåå¥½ç­‰ï¼‰ |
| **å¯è§£é‡Šæ€§** | é”™è¯¯ç±»å‹å¯åˆ†è§£ä¸ºå…­ç»´åº¦ï¼Œä¾¿äºè°ƒè¯• | é»‘ç®±è¯„åˆ†ï¼Œéš¾ä»¥å½’å›  |
| **æ•ˆç‡** | æ”¯æŒå®Œå…¨ç¦»çº¿è®­ç»ƒï¼Œé€‚åˆèµ„æºå—é™åœºæ™¯ | å¤šéœ€åœ¨çº¿é‡‡æ ·æˆ–å¤æ‚è¿­ä»£ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **SFTé˜¶æ®µ**ï¼šä½¿ç”¨ **MetaMathQA**ï¼ˆçº¦39.5ä¸‡æ¡å¸¦CoTçš„æ•°å­¦é—®ç­”å¯¹ï¼‰ï¼Œæºè‡ª GSM8K å’Œ MATH æ•°æ®é›†çš„AIå¢å¼ºç‰ˆæœ¬ã€‚
- **DPOåå¥½æ„å»ºé˜¶æ®µ**ï¼šä» `HuggingFaceH4/numina-deepseek-r1-qwen-7b` æ•°æ®é›†ä¸­é‡‡æ ·çº¦60ä¸‡æ¡CoTè½¨è¿¹ï¼Œç» MathVerifier è¿‡æ»¤åä¿ç•™çº¦1ä¸‡æ¡é«˜è´¨é‡ preference pairsã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š`Qwen2.5-1.5B-Instruct`ï¼ˆ1.5Bå‚æ•°ï¼‰
- **å¾®è°ƒæ–¹å¼**ï¼š
  - SFT ä½¿ç”¨ **QLoRA**ï¼ˆ4-bit NF4é‡åŒ– + rank-16 LoRAé€‚é…å™¨ï¼‰
  - DPO é˜¶æ®µå†»ç»“ä¸»å¹²ï¼Œä»…æ›´æ–° LoRA å‚æ•°
- **è®­ç»ƒæµç¨‹**ï¼š
  1. åœ¨ MetaMathQA ä¸Šè¿›è¡Œ SFT å¾—åˆ°åˆå§‹ç­–ç•¥ $\pi_{\text{sft}}$
  2. ç”¨è¯¥ç­–ç•¥ç”Ÿæˆå¤šè§£ â†’ è¾“å…¥ MathVerifier æ‰“åˆ†
  3. æ„å»º preference pairs $(y^+, y^-)$ï¼Œå…¶ä¸­ $y^+$ æ˜¯æ­£ç¡®ä¸”ç»“æ„è‰¯å¥½çš„è§£ï¼Œ$y^-$ æ˜¯ verifier è¯†åˆ«å‡ºçš„ hard negative
  4. åº”ç”¨ **åŠ æƒ DPO æŸå¤±**ï¼Œæ ·æœ¬æƒé‡ç”± `wrongness`, `confidence`, `perplexity` å…±åŒå†³å®š

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- **Exact Match Accuracy** onï¼š
  - **GSM8K**ï¼ˆå°å­¦åº”ç”¨é¢˜ï¼‰
  - **MATH**ï¼ˆé«˜ä¸­ç«èµ›çº§æ•°å­¦é¢˜ï¼‰
- æ‰€æœ‰æ¨¡å‹å‡é‡‡ç”¨ç›¸åŒ prompt æ¨¡æ¿ï¼ˆ`qwen2-boxed`ï¼‰ã€greedy decodingï¼ˆtemp=0ï¼‰å’Œæ­£åˆ™æå–ç­”æ¡ˆï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **Base** | ä»… SFT åçš„æ¨¡å‹ |
| **Random-uniform DPO** | éšæœºé€‰æ‹© preference pairsï¼Œç»Ÿä¸€æƒé‡ï¼ˆw=1ï¼‰ |
| **Verifier-guided Weighted DPO** | æœ¬æ–‡æ–¹æ³•ï¼šåŸºäº verifier æŒ–æ˜ hard negatives å¹¶åŠ æƒè®­ç»ƒ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆExact Match %ï¼‰

| Model | MATH | GSM8K | å¤‡æ³¨ |
|-------|------|--------|------|
| Qwen2.5-1.5B-Instruct | 55.3 | 71.9 | Base |
| + Random DPO | 54.5 (-0.8) | 72.6 (+0.7) | MATH ä¸‹é™ |
| + **Hard-neg DPO** | **57.2 (+1.9)** | **74.2 (+2.3)** | âœ… æœ¬æ–‡æ–¹æ³• |
| Qwen2.5-1.5B-SFT | 65.2 | 76.3 | SFT åŸºçº¿ |
| + Random DPO | 64.1 (-1.1) | 77.1 (+0.8) | MATH é€€åŒ– |
| + **Hard-neg DPO** | **67.1 (+1.9)** | **80.1 (+3.8)** | âœ… æ˜¾è‘—æå‡ |
| Qwen2.5-Math-1.5B-Instruct | 76.2 | 83.4 | ä¸“ç”¨æ•°å­¦æ¨¡å‹ |
| + Random DPO | 75.3 (-0.9) | 84.0 (+0.6) | MATH åè€Œä¸‹é™ |
| + **Hard-neg DPO** | **77.7 (+1.5)** | **86.2 (+2.8)** | âœ… æŒç»­å¢ç›Š |

> æ³¨ï¼šæ‹¬å·å†…ä¸ºç›¸å¯¹äºå¯¹åº” base æ¨¡å‹çš„ç»å¯¹æå‡ï¼ˆ+ï¼‰æˆ–ä¸‹é™ï¼ˆ-ï¼‰

### ğŸ”¬ æ¶ˆèå®éªŒä¸å…³é”®å‘ç°
- **Hard negatives è‡³å…³é‡è¦**ï¼šç›¸æ¯”éšæœºé‡‡æ ·çš„ preference pairsï¼Œç”± verifier å¼•å¯¼é€‰å‡ºçš„ hard negatives æ›´èƒ½ä¿ƒä½¿æ¨¡å‹åŒºåˆ†â€œè¡¨é¢åˆç†ä½†é€»è¾‘é”™è¯¯â€çš„è§£ã€‚
- **åŠ æƒæœºåˆ¶æœ‰æ•ˆ**ï¼šå¼•å…¥ `wrongness + confidence + perplexity` çš„ç»„åˆæƒé‡æ˜¾è‘—æå‡äº†å­¦ä¹ æ•ˆç‡ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†â€œæ•°å€¼æ¥è¿‘ä½†é€»è¾‘é”™è¯¯â€çš„æ¡ˆä¾‹æ—¶ã€‚
- **MATH æ›´æ•æ„Ÿäºç»“æ„é”™è¯¯**ï¼šRandom DPO åœ¨ MATH ä¸Šå¸¸å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œè¯´æ˜ç›²ç›®æ·»åŠ åå¥½æ•°æ®å¯èƒ½ç ´åå·²æœ‰èƒ½åŠ›ï¼›è€Œ verifier-guided æ–¹æ³•èƒ½ç¨³å®šææ•ˆã€‚
- **è®­ç»ƒåŠ¨æ€æ›´ä¼˜**ï¼šVerifier-guided DPO è¾¾åˆ°æ›´ä½çš„æœ€ç»ˆ lossï¼Œä¸” reward åˆ†å¸ƒé›†ä¸­åœ¨é«˜ä¿¡æ¯å¯†åº¦æ ·æœ¬ä¸Šï¼ˆå›¾5bï¼‰ï¼Œè¡¨æ˜å­¦ä¹ æ›´èšç„¦äºå…³é”®é”™è¯¯æ¨¡å¼ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ç»“æ„åŒ–é”™è¯¯åˆ†ææ¯”äºŒå€¼åˆ¤æ–­æ›´æœ‰ä»·å€¼**ï¼šé€šè¿‡å…­ç»´ error profileï¼ˆè¯­ä¹‰ã€ç»“æ„ã€é¡ºåºã€é€»è¾‘ã€ç¬¦å·ã€ç­”æ¡ˆä¸€è‡´æ€§ï¼‰å¯ç²¾å‡†å®šä½å¤±è´¥åŸå› ï¼Œæ”¯æŒæ›´æœ‰é’ˆå¯¹æ€§çš„ä¼˜åŒ–ã€‚
2. **Hard negatives æ˜¯ DPO æˆåŠŸçš„å…³é”®**ï¼šçœŸæ­£æœ‰ä»·å€¼çš„ negative ä¸åº”æ˜¯èƒ¡è¨€ä¹±è¯­ï¼Œè€Œæ˜¯é‚£äº›â€œçœ‹èµ·æ¥å¾ˆåƒå¯¹ä½†å®é™…ä¸Šé”™â€çš„è§£ï¼Œè¿™ç±»æ ·æœ¬è¿«ä½¿æ¨¡å‹æ·±å…¥ç†è§£æ¨ç†è¿‡ç¨‹ã€‚
3. **Verifier å¯ä½œä¸ºä½æˆæœ¬æ›¿ä»£æ–¹æ¡ˆ**ï¼šè½»é‡çº§ MathVerifier èƒ½æœ‰æ•ˆæ›¿ä»£æ˜‚è´µçš„ PRM æˆ– LLM-as-a-judgeï¼Œåœ¨æœ‰é™ç®—åŠ›ä¸‹å®ç°é«˜æ•ˆã€ç¨³å®šçš„ post-trainingã€‚
4. **åŠ æƒ DPO æå‡ä¿¡æ¯åˆ©ç”¨ç‡**ï¼šé€šè¿‡ verifier è¾“å‡ºçš„é‡è¦æ€§æƒé‡ï¼Œå¯åœ¨ batch å†…åŠ¨æ€è°ƒæ•´æ¢¯åº¦è´¡çŒ®ï¼Œé¿å…å™ªå£°æ ·æœ¬ä¸»å¯¼è®­ç»ƒã€‚

### âš ï¸ å±€é™æ€§
- **å¯å‘å¼è®¾è®¡è¾ƒå¤š**ï¼šå…­ç»´è¯„åˆ†çš„èšåˆæ–¹å¼ã€æƒé‡å…¬å¼å‡ä¸ºç»éªŒè®¾å®šï¼Œç¼ºä¹ç†è®ºæœ€ä¼˜ä¿è¯ã€‚
- **çº¯ç¦»çº¿æµç¨‹**ï¼šæœªå®ç°é—­ç¯åé¦ˆï¼ˆå¦‚ online RLï¼‰ï¼Œverifier å›ºå®šä¸å˜ï¼Œæ— æ³•éš policy æ¼”è¿›è€Œè¿›åŒ–ã€‚
- **è§„æ¨¡å—é™**ï¼šç›®å‰ä»…åœ¨ 1.5B æ¨¡å‹ä¸ŠéªŒè¯ï¼Œå°šæœªæµ‹è¯•æ›´å¤§æ¨¡å‹æˆ–æ›´å¤šæ ·åŒ–ä»»åŠ¡ï¼ˆå¦‚ä»£ç ã€å½¢å¼è¯æ˜ï¼‰ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. å°† verifier æƒé‡æœºåˆ¶å½¢å¼åŒ–ä¸º **active learning æˆ– importance sampling** æ¡†æ¶ï¼Œæå‡ç†è®ºåŸºç¡€ã€‚
2. æ¢ç´¢ **co-training verifier ä¸ policy**ï¼Œæˆ–å°† verifier è’¸é¦ä¸ºç´§å‡‘ PRMï¼ŒåµŒå…¥åœ¨çº¿ RL æµç¨‹ã€‚
3. å°†æœ¬æ¡†æ¶æ¨å¹¿è‡³å…¶ä»–éœ€è¦ç»“æ„åŒ–æ¨ç†çš„ä»»åŠ¡é¢†åŸŸï¼Œå¦‚ **code generationã€formal reasoningã€ç§‘å­¦é—®ç­”** ç­‰ã€‚

---

## æ€»ç»“
æœ¬æ–‡æå‡ºäº†ä¸€ç§**ä»¥ hard negative ä¸ºæ ¸å¿ƒçš„è½»é‡çº§ DPO åè®­ç»ƒèŒƒå¼**ï¼Œé€šè¿‡ **MathVerifier** å®ç°ç»†ç²’åº¦é”™è¯¯è¯Šæ–­ä¸é«˜ä»·å€¼æ ·æœ¬æŒ–æ˜ï¼Œåœ¨ä¸ä¾èµ–å¤§å‹ reward model æˆ–äººå·¥æ ‡æ³¨çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†å°å‹è¯­è¨€æ¨¡å‹åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚å…¶æ ¸å¿ƒæ´è§æ˜¯ï¼š**æ”¹è¿›æ¨¡å‹çš„å…³é”®ä¸åœ¨æ›´å¤šæ•°æ®ï¼Œè€Œåœ¨æ›´èªæ˜åœ°é€‰æ‹©â€œæœ€æœ‰æ•™è‚²æ„ä¹‰â€çš„è®­ç»ƒæ ·æœ¬**ã€‚è¿™ä¸€æ€æƒ³å¯¹ä½èµ„æºåœºæ™¯ä¸‹çš„ LLM å¯¹é½å…·æœ‰é‡è¦å®è·µæ„ä¹‰ã€‚

</details>

---

### 12. [OpComm: A Reinforcement Learning Framework for Adaptive Buffer Control in Warehouse Volume Forecasting](https://arxiv.org/abs/2512.19738)

**Authors**: Wilson Fung, Lu Guo, Drake Hilliard, Alessandro Casadei, Raj Ratan, Sreyoshi Bhaduri, Adi Surve, Nikhil Agarwal, Rohit Malshe, Pavan Mullapudi, Hungjen Wang, Saurabh Doodhwala, Ankush Pole, Arkajit Rakshit  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.19738v1  

#### Abstract
Accurate forecasting of package volumes at delivery stations is critical for last-mile logistics, where errors lead to inefficient resource allocation, higher costs, and delivery delays. We propose OpComm, a forecasting and decision-support framework that combines supervised learning with reinforcem...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*OpComm: A Reinforcement Learning Framework for Adaptive Buffer Control in Warehouse Volume Forecasting*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨**æœ€åä¸€å…¬é‡Œç‰©æµ**ï¼ˆlast-mile logisticsï¼‰ä¸­ï¼Œé…é€ç«™ç‚¹çš„åŒ…è£¹é‡é¢„æµ‹ä¸å‡†ç¡®ä¼šå¯¼è‡´èµ„æºåˆ†é…ä¸å½“ã€æˆæœ¬ä¸Šå‡å’Œäº¤ä»˜å»¶è¿Ÿã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–å¯å‘å¼è§„åˆ™ï¼Œéš¾ä»¥æ•æ‰ç«™ç‚¹é—´çš„å¼‚è´¨æ€§å’ŒåŠ¨æ€éœ€æ±‚å˜åŒ–ï¼Œå°¤å…¶åœ¨ç¼“å†²åŒºç®¡ç†ï¼ˆbuffer controlï¼‰æ–¹é¢ç¼ºä¹è‡ªé€‚åº”èƒ½åŠ›ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **OpComm** â€”â€” ä¸€ä¸ªç»“åˆç›‘ç£å­¦ä¹ ã€å¼ºåŒ–å­¦ä¹ ä¸ç”Ÿæˆå¼AIçš„å†³ç­–æ”¯æŒæ¡†æ¶ï¼Œç”¨äºä»“åº“çº§åˆ«çš„ä½“ç§¯é¢„æµ‹ä¸è‡ªé€‚åº”ç¼“å†²æ§åˆ¶ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **å¤šæ¨¡å—é›†æˆæ¶æ„**ï¼š
  - ä½¿ç”¨ **LightGBM** è¿›è¡Œç«™ç‚¹çº§éœ€æ±‚é¢„æµ‹ï¼Œæä¾›ä¸Šä¸‹æ–‡è¾“å…¥ï¼›
  - å¼•å…¥åŸºäº **Proximal Policy Optimization (PPO)** çš„å¼ºåŒ–å­¦ä¹ ä»£ç†ï¼Œä»ç¦»æ•£åŠ¨ä½œé›†ä¸­é€‰æ‹©æœ€ä¼˜ç¼“å†²æ°´å¹³ï¼›
  - è®¾è®¡**éå¯¹ç§°å¥–åŠ±å‡½æ•°**ï¼Œå¯¹â€œç¼“å†²ä¸è¶³â€ï¼ˆunder-bufferingï¼‰æ–½åŠ æ›´é«˜æƒ©ç½šï¼Œåæ˜ çœŸå®ä¸šåŠ¡ä¸­æœªæ»¡è¶³éœ€æ±‚çš„é£é™©è¿œé«˜äºèµ„æºæµªè´¹ï¼›
  - åŠ å…¥**è’™ç‰¹å¡æ´›æ›´æ–°æœºåˆ¶**ï¼Œå®ç°ç­–ç•¥çš„æŒç»­åœ¨çº¿é€‚åº”ï¼›
  - é›†æˆ**ç”Ÿæˆå¼AIå±‚**ï¼Œåˆ©ç”¨SHAPç‰¹å¾å½’å› ç”Ÿæˆå¯è§£é‡Šçš„æ‰§è¡Œæ‘˜è¦å’Œæƒ…æ™¯åˆ†æï¼Œæå‡å†³ç­–é€æ˜åº¦ã€‚

- **å°†ç¼“å†²æ§åˆ¶å»ºæ¨¡ä¸ºä¸Šä¸‹æ–‡å¼ºåŒ–å­¦ä¹ é—®é¢˜**ï¼ˆcontextual reinforcement learningï¼‰ï¼Œä½¿ç­–ç•¥èƒ½æ ¹æ®é¢„æµ‹éœ€æ±‚åŠ¨æ€è°ƒæ•´ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | OpCommä¼˜åŠ¿ |
|------|-----------|
| å‡†ç¡®æ€§ | æ˜¾è‘—é™ä½WAPEè¯¯å·®ï¼ˆâ†“21.65%ï¼‰ |
| å†³ç­–è´¨é‡ | å‡å°‘under-bufferingäº‹ä»¶ï¼Œé™ä½è¿è¥é£é™© |
| è‡ªé€‚åº”æ€§ | è’™ç‰¹å¡æ´›åé¦ˆæœºåˆ¶æ”¯æŒæŒç»­å­¦ä¹ ä¸ç­–ç•¥æ¼”åŒ– |
| å¯è§£é‡Šæ€§ | é€šè¿‡ç”Ÿæˆå¼AIè¾“å‡ºè‡ªç„¶è¯­è¨€æŠ¥å‘Šï¼Œä¿ƒè¿›ç®¡ç†è€…é‡‡çº³ |
| å®ç”¨æ€§ | å¹³è¡¡ç»Ÿè®¡ä¸¥è°¨æ€§ä¸å®é™…æ“ä½œå¯è¡Œæ€§ï¼Œåœ¨é«˜ stakes ç‰©æµåœºæ™¯ä¸­æ›´å…·è½åœ°ä»·å€¼ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
- æ¥æºï¼šåŒ—ç¾åœ°åŒº **400+ä¸ªä»“åº“é…é€ç«™ç‚¹** çš„å†å²è¿è¥æ•°æ®ï¼›
- åŒ…å«æ—¶é—´åºåˆ—ä¿¡æ¯ã€ç«™ç‚¹ç‰¹å¾ã€å®¹é‡åˆ©ç”¨ç‡ã€å­£èŠ‚æ€§æ¨¡å¼ç­‰ï¼›
- æ’é™¤å†å²æ•°æ®ä¸è¶³çš„ç«™ç‚¹ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹ç»“æ„**ï¼š
  - LightGBM å›å½’æ¨¡å‹ç‹¬ç«‹è®­ç»ƒäºæ¯ä¸ªç«™ç‚¹ï¼Œé‡‡ç”¨æ—¶åºåˆ’åˆ†ï¼ˆtemporal train-test splitï¼‰ï¼›
  - PPO Agent åŠ¨ä½œç©ºé—´ä¸ºç¦»æ•£ç¼“å†²ç­‰çº§ `{bâ‚, bâ‚‚, ..., bk}`ï¼Œä½œç”¨äº LightGBM è¾“å‡ºçš„é¢„æµ‹å€¼ä¸Šï¼›
  - å¥–åŠ±å‡½æ•°è®¾è®¡å¦‚ä¸‹ï¼š
    $$
    r_t = -\alpha \cdot \max(0, D_t - D_t^{\text{forecast}} - b_t) + \beta \cdot \max(0, b_t + D_t^{\text{forecast}} - D_t)
    $$
    å…¶ä¸­ $\alpha > \beta$ï¼Œå¼ºè°ƒå¯¹ under-buffering çš„æƒ©ç½šã€‚
- **ç­–ç•¥ä¼˜åŒ–**ï¼šä½¿ç”¨ PPO çš„è£å‰ªç›®æ ‡å‡½æ•°è¿›è¡Œç¨³å®šè®­ç»ƒï¼Œé…åˆ Monte Carlo å›æŠ¥ä¼°è®¡è®¡ç®—ä¼˜åŠ¿å‡½æ•°ï¼ˆAdvantage Estimatorï¼‰ã€‚

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦æŒ‡æ ‡ï¼š
  - **WAPE**ï¼ˆWeighted Absolute Percentage Errorï¼‰ï¼šè¡¡é‡é¢„æµ‹å‡†ç¡®æ€§ï¼›
  - **Under-buffering (%)** å’Œ **Over-buffering (%)**ï¼šè¯„ä¼°ç¼“å†²ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼›
  - **WAPEæ ‡å‡†å·®**ï¼šåæ˜ åŒºåŸŸé—´ç¨³å®šæ€§ã€‚
- å¯¹æ¯”æ–¹å¼ï¼šOpComm vs. æ‰‹å·¥é¢„æµ‹ï¼ˆmanual forecastingï¼‰åŸºçº¿ã€‚

### ğŸ†š åŸºçº¿æ–¹æ³•
- **Manual Forecasting**ï¼šå½“å‰è¡Œä¸šå¸¸ç”¨çš„å¯å‘å¼äººå·¥é¢„æµ‹æ–¹æ³•ï¼Œä½œä¸ºä¸»è¦å¯¹æ¯”åŸºå‡†ã€‚

> æ³¨ï¼šæ–‡ä¸­æœªæåŠä¸å…¶ä»–MLæˆ–RLæ–¹æ³•ï¼ˆå¦‚DQNã€TRPOï¼‰çš„ç›´æ¥æ¯”è¾ƒï¼Œä¹Ÿæ— æ¶ˆèå®éªŒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰
| åŒºåŸŸ | æ–¹æ³• | WAPE (%) | WAPE Std. Dev. (%) | Under-buffering (%) | Over-buffering (%) |
|------|------|----------|---------------------|-----------------------|---------------------|
| North-East | Manual | 4.95 | 1.20 | 18.3 | 12.5 |
|            | OpComm | **3.85** | **0.95** | **10.2** | 15.1 |
| Mid-West   | Manual | 5.12 | 1.35 | 20.1 | 13.0 |
|            | OpComm | **3.90** | **1.05** | **11.0** | 14.2 |
| South      | Manual | 4.88 | 1.18 | 16.7 | 11.9 |
|            | OpComm | **3.70** | **0.90** | **9.5**  | 13.5 |
| West       | Manual | 4.99 | 1.22 | 17.9 | 12.7 |
|            | OpComm | **3.80** | **0.92** | **10.0** | 14.0 |

### ğŸ” æ€»ä½“è¡¨ç°
- **WAPEå¹³å‡ä¸‹é™ 21.65%**ï¼ˆä» 4.95% â†’ 3.85%ï¼‰ï¼›
- åœ¨ **93.7% çš„ç«™ç‚¹** ä¸Šæå‡äº†é¢„æµ‹ç²¾åº¦ï¼›
- **Under-buffering å¹³å‡å‡å°‘çº¦ 8 ä¸ªç™¾åˆ†ç‚¹**ï¼Œæ˜¾è‘—é™ä½ç¼ºè´§é£é™©ï¼›
- å°½ç®¡ over-buffering ç•¥æœ‰ä¸Šå‡ï¼ˆ+2~3%ï¼‰ï¼Œä½†æ•´ä½“æ›´åå‘ä¿å®ˆç­–ç•¥ï¼Œç¬¦åˆä¸šåŠ¡åå¥½ï¼›
- WAPE æ ‡å‡†å·®ä¸‹é™ï¼Œè¯´æ˜æ¨¡å‹è·¨åŒºåŸŸè¡¨ç°æ›´ç¨³å®šã€‚

> â— æ³¨æ„ï¼šè™½ç„¶ over-buffering ä¸Šå‡ï¼Œä½†ç”±äº reward è®¾è®¡ä¸­ $\alpha > \beta$ï¼Œç³»ç»Ÿä¼˜å…ˆé¿å…æ›´ä¸¥é‡çš„ under-buffering æˆæœ¬ï¼Œå±äºåˆç†æƒè¡¡ã€‚

### ğŸ” æ¶ˆèå®éªŒ
- æ–‡ä¸­**æœªæä¾›æ¶ˆèå®éªŒ**ï¼ˆablation studyï¼‰ï¼Œæ— æ³•é‡åŒ–å„æ¨¡å—ï¼ˆå¦‚LightGBMã€PPOã€GenAIï¼‰çš„å…·ä½“è´¡çŒ®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **OpCommæ˜¾è‘—ä¼˜äºæ‰‹å·¥é¢„æµ‹**ï¼Œä¸ä»…æé«˜é¢„æµ‹å‡†ç¡®æ€§ï¼Œè¿˜ä¼˜åŒ–äº†ç¼“å†²å†³ç­–ï¼›
2. **éå¯¹ç§°å¥–åŠ±è®¾è®¡æœ‰æ•ˆå¼•å¯¼ç­–ç•¥åå‘ä¿å®ˆ**ï¼Œé™ä½äº†è¿è¥ä¸­æ–­é£é™©ï¼›
3. **PPO + Monte Carlo æ›´æ–°æœºåˆ¶é€‚åˆéå¹³ç¨³ç¯å¢ƒä¸‹çš„æŒç»­å­¦ä¹ **ï¼›
4. **ç”Ÿæˆå¼AIå¢å¼ºäº†è§£é‡Šæ€§ä¸å¯ç”¨æ€§**ï¼Œæœ‰åŠ©äºæ¨åŠ¨ç®—æ³•åœ¨å®é™…è¿è¥ç®¡ç†ä¸­çš„é‡‡çº³ï¼›
5. è¯¥æ¡†æ¶æˆåŠŸå®ç°äº†**é¢„æµ‹å»ºæ¨¡ä¸å†³ç­–æ”¯æŒçš„é—­ç¯æ•´åˆ**ï¼Œé€‚ç”¨äºé«˜é£é™©ã€é«˜å¤æ‚åº¦çš„ç‰©æµåœºæ™¯ã€‚

### âš ï¸ å±€é™æ€§
- ç¼ºä¹ä¸å…¶ä»–å…ˆè¿›RLç®—æ³•ï¼ˆå¦‚SACã€DQNï¼‰æˆ–é¢„æµ‹æ¨¡å‹ï¼ˆå¦‚Transformerã€LSTMï¼‰çš„æ¨ªå‘å¯¹æ¯”ï¼›
- æœªè¿›è¡Œæ¨¡å—çº§æ¶ˆèå®éªŒï¼Œéš¾ä»¥åˆ¤æ–­å„ç»„ä»¶çš„é‡è¦æ€§ï¼›
- æ‰€æœ‰ç«™ç‚¹ç‹¬ç«‹å»ºæ¨¡ï¼Œå°šæœªè€ƒè™‘ç«™ç‚¹ä¹‹é—´çš„ç½‘ç»œååŒæ•ˆåº”ï¼›
- å®éªŒä»…é™åŒ—ç¾åœ°åŒºï¼Œæ³›åŒ–èƒ½åŠ›æœ‰å¾…éªŒè¯ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **meta-learning** ç”¨äºåŠ¨æ€ç‰¹å¾è¡¨ç¤ºå­¦ä¹ ï¼›
- å°è¯•å…¶ä»– **policy optimization ç®—æ³•** æ›¿ä»£ PPOï¼›
- æ‰©å±•è‡³ **ç½‘ç»œå±‚çº§åè°ƒ**ï¼ˆnetwork-level coordination across stationsï¼‰ï¼›
- å¼€å±• **å¯è§£é‡Šæ€§æ–¹æ³•çš„å½¢å¼åŒ–è¯„ä¼°**ï¼Œç ”ç©¶ç”Ÿæˆå¼AIè¾“å‡ºå¯¹äººç±»å†³ç­–çš„å½±å“ã€‚

---

## æ€»ç»“
**OpComm** æ˜¯ä¸€ä¸ªé¢å‘å®é™…åº”ç”¨çš„ç«¯åˆ°ç«¯å†³ç­–æ¡†æ¶ï¼Œå·§å¦™èåˆäº† LightGBMã€PPO å’Œ Generative AIï¼Œåœ¨çœŸå®ä»“å‚¨ç‰©æµç¯å¢ƒä¸­å®ç°äº†é¢„æµ‹ç²¾åº¦ä¸è¿è¥å†³ç­–è´¨é‡çš„åŒé‡æå‡ã€‚å®ƒä¸ä»…æ˜¯æŠ€æœ¯ä¸Šçš„é›†æˆåˆ›æ–°ï¼Œæ›´æ˜¯**è¿æ¥æœºå™¨å­¦ä¹ ä¸è¿è¥ç®¡ç†å®è·µçš„é‡è¦æ¡¥æ¢**ï¼Œä¸ºæ™ºèƒ½ä¾›åº”é“¾ç³»ç»Ÿçš„æ„å»ºæä¾›äº†å¯å¤åˆ¶çš„èŒƒå¼ã€‚

</details>

---

### 13. [HGAN-SDEs: Learning Neural Stochastic Differential Equations with Hermite-Guided Adversarial Training](https://arxiv.org/abs/2512.20272)

**Authors**: Yuanjian Xu, Yuan Shuai, Jianing Hao, Guang Zhang  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.20272v1  

#### Abstract
Neural Stochastic Differential Equations (Neural SDEs) provide a principled framework for modeling continuous-time stochastic processes and have been widely adopted in fields ranging from physics to finance. Recent advances suggest that Generative Adversarial Networks (GANs) offer a promising soluti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# HGAN-SDEs: Learning Neural Stochastic Differential Equations with Hermite-Guided Adversarial Training â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **Neural SDEs**ï¼ˆç¥ç»éšæœºå¾®åˆ†æ–¹ç¨‹ï¼‰åœ¨å»ºæ¨¡è¿ç»­æ—¶é—´éšæœºè¿‡ç¨‹æ–¹é¢å…·æœ‰å¼ºå¤§èƒ½åŠ›ï¼Œå¹¿æ³›åº”ç”¨äºç‰©ç†ã€é‡‘èç­‰é¢†åŸŸã€‚
- ç„¶è€Œï¼Œè®­ç»ƒ Neural SDEs é¢ä¸´æŒ‘æˆ˜ï¼š**ç²¾ç¡®ä¼¼ç„¶ä¸å¯è®¡ç®—**ï¼Œä¼ ç»ŸåŸºäºå˜åˆ†çš„æ–¹æ³•å—é™äºè¿‘ä¼¼å‡è®¾ã€‚
- ä½¿ç”¨ GAN è¿›è¡Œå¯¹æŠ—è®­ç»ƒæ˜¯ä¸€ç§å¯è¡Œçš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†ç°æœ‰æ–¹æ³•ï¼ˆå¦‚åŸºäº Neural CDE çš„åˆ¤åˆ«å™¨ï¼‰å­˜åœ¨ä¸¤å¤§ç“¶é¢ˆï¼š
  - **è®¡ç®—æˆæœ¬é«˜**
  - **å¯¹æŠ—è®­ç»ƒä¸ç¨³å®š**

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šHGAN-SDEs
ä½œè€…æå‡º **HGAN-SDEs**ï¼Œä¸€ç§åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰çš„æ–°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š
- å°† **Neural Hermite å‡½æ•°** å¼•å…¥ä½œä¸º GAN ä¸­çš„åˆ¤åˆ«å™¨ï¼ˆdiscriminatorï¼‰ï¼Œç”¨äºé«˜æ•ˆä¸”ç¨³å®šåœ°æ•æ‰è·¯å¾„çº§åŠ¨æ€ç‰¹å¾ã€‚

#### åˆ›æ–°ç‚¹è¯¦è§£ï¼š
1. **Hermite å‡½æ•°ä½œä¸ºåˆ¤åˆ«å™¨åŸºç¡€**
   - åˆ©ç”¨ Hermite å‡½æ•°æ„æˆçš„æ­£äº¤å¤šé¡¹å¼åŸºæ¥é€¼è¿‘ SDE çš„è½¬ç§»å¯†åº¦ï¼ˆtransition densityï¼‰ã€‚
   - å…·å¤‡æ•°å­¦ä¸Šçš„å®Œå¤‡æ€§å’Œæ­£äº¤æ€§ï¼Œèƒ½ä»¥è¾ƒå°‘é¡¹æ•°å®ç°é«˜ç²¾åº¦è¿‘ä¼¼ã€‚

2. **è½»é‡çº§ä¸é«˜æ•ˆæ€§**
   - ç›¸æ¯”å¤æ‚çš„ Neural CDE åˆ¤åˆ«å™¨ï¼ŒHermite-based åˆ¤åˆ«å™¨ç»“æ„æ›´ç®€å•ï¼Œå‚æ•°æ›´å°‘ï¼Œæ˜¾è‘—é™ä½è¿è¡Œæ—¶é—´å’Œå†…å­˜æ¶ˆè€—ã€‚

3. **æå‡è®­ç»ƒç¨³å®šæ€§**
   - Hermite å‡½æ•°è‰¯å¥½çš„ç»Ÿè®¡æ€§è´¨æœ‰åŠ©äºç¼“è§£ GAN è®­ç»ƒä¸­çš„æ¢¯åº¦ä¸ç¨³å®šé—®é¢˜ï¼Œæé«˜æ”¶æ•›é²æ£’æ€§ã€‚

4. **ç†è®ºä¿éšœ**
   - è¯æ˜äº†è¯¥æ¡†æ¶å…·å¤‡ **é€šç”¨é€¼è¿‘èƒ½åŠ›**ï¼ˆuniversal approximation propertyï¼‰ï¼Œå¯åœ¨é€‚å½“æ¡ä»¶ä¸‹é€¼è¿‘ä»»æ„ç”± SDE é©±åŠ¨çš„æ¦‚ç‡åˆ†å¸ƒã€‚
   - ç»™å‡ºäº† Hermite å±•å¼€åœ¨ LÂ² ç©ºé—´ä¸‹çš„æ”¶æ•›æ€§å®šç†ï¼ˆTheorem 2ï¼‰ä»¥åŠåˆ¤åˆ«èƒ½åŠ›åˆ†æï¼ˆTheorem 3ï¼‰ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | HGAN-SDEs | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ GAN-SDEs + CDEï¼‰ |
|------|-----------|-------------------------------|
| è®¡ç®—æ•ˆç‡ | â¬‡ï¸ æä½ï¼ˆä»…éœ€ 1.2 GPU-hourï¼‰ | â¬†ï¸ é«˜ï¼ˆé«˜è¾¾ 10.0 GPU-hourï¼‰ |
| è®­ç»ƒç¨³å®šæ€§ | â¬†ï¸ é«˜ï¼ˆæ”¶æ•›å¿«ã€æ³¢åŠ¨å°ï¼‰ | â¬‡ï¸ ä½ï¼ˆæ˜“å´©æºƒï¼‰ |
| è¡¨è¾¾èƒ½åŠ› | â¬†ï¸ å¼ºï¼ˆæ­£äº¤åŸºä¿è¯è¡¨è¾¾åŠ›ï¼‰ | â¬†ï¸ å¼ºä½†ä»£ä»·é«˜ |
| å®ç°å¤æ‚åº¦ | â¬‡ï¸ ç®€å•ï¼ˆMLP å‚æ•°åŒ–å³å¯ï¼‰ | â¬†ï¸ å¤æ‚ï¼ˆéœ€è§£æ§åˆ¶å¾®åˆ†æ–¹ç¨‹ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†

#### åˆæˆæ•°æ®é›†ï¼ˆSimulation Datasetsï¼‰
éµå¾ª Yacine [30] çš„è®¾å®šï¼Œæ„å»ºå››ç±»ç»å…¸ SDE æ¨¡å‹çš„æ•°æ®ï¼š
- **GBM**ï¼ˆGeometric Brownian Motionï¼‰
- **OU**ï¼ˆOrnstein-Uhlenbeck Processï¼‰
- **CIR**ï¼ˆCox-Ingersoll-Ross Modelï¼‰
- **Polynomial Drift SDE**

æ¯ç»„å« 20,000 è®­ç»ƒæ ·æœ¬ + 6,000 æµ‹è¯•æ ·æœ¬ï¼Œè¾“å…¥ä¸ºå‰ 100 æ—¶é—´æ­¥ï¼Œé¢„æµ‹å 50 æ­¥ã€‚

#### çœŸå®ä¸–ç•Œæ•°æ®é›†ï¼ˆReal-world Datasetsï¼‰
- **Stock-AAL / Stock-ADBE**ï¼šç¾è‚¡äº”åˆ†é˜äº¤æ˜“ä»·æ ¼ï¼ˆ2017â€“2018ï¼‰ï¼Œä½“ç°é«˜é¢‘é‡‘èå¸‚åœºçš„éšæœºæ³¢åŠ¨ã€‚
- **Traffic**ï¼šåŒ—äº¬äº¤é€šæµé‡è®°å½•ï¼ˆ2022å¹´ï¼Œå…±21,600æ¡ï¼‰ï¼Œå…·å¼ºå‘¨æœŸæ€§ã€‚

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
é‡‡ç”¨å››ä¸ªäº’è¡¥æŒ‡æ ‡å…¨é¢è¯„ä»·æ¨¡å‹æ€§èƒ½ï¼š
| æŒ‡æ ‡ | å…¨ç§° | æè¿° |
|------|------|------|
| **MISE** | Mean Integrated Squared Error | è·¯å¾„æ•´ä½“æ‹Ÿåˆè¯¯å·®ï¼Œè¶Šå°è¶Šå¥½ |
| **TD** | Tail Difference | å°¾éƒ¨ï¼ˆ>5% åˆ†ä½æ•°ï¼‰å·®å¼‚ï¼Œè¡¡é‡æç«¯äº‹ä»¶å»ºæ¨¡èƒ½åŠ› |
| **MSE** | Mean Squared Error | ç‚¹å¯¹ç‚¹é¢„æµ‹è¯¯å·® |
| **MMD** | Maximum Mean Discrepancy | çœŸå®è·¯å¾„ä¸ç”Ÿæˆè·¯å¾„ä¹‹é—´çš„åˆ†å¸ƒè·ç¦» |

> æ‰€æœ‰æŒ‡æ ‡å‡ä¸ºâ€œè¶Šä½è¶Šå¥½â€ã€‚

### ğŸ§ª åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¶µç›–ä¸»æµæ—¶åºå»ºæ¨¡èŒƒå¼ï¼š
- **çº¿æ€§æ¨¡å‹**ï¼šDLinear
- **å·ç§¯æ¨¡å‹**ï¼šMICN, TimesNet
- **æ³¨æ„åŠ›æœºåˆ¶**ï¼šTransformer, Informer, Autoformer
- **RNN æ¨¡å‹**ï¼šSegRNN
- **çŠ¶æ€ç©ºé—´æ¨¡å‹**ï¼šMamba
- **SDE-based æ¨¡å‹**ï¼š
  - Latent-SDEs
  - GAN-SDEsï¼ˆä½¿ç”¨ CDE åˆ¤åˆ«å™¨ï¼‰

æ‰€æœ‰ç”Ÿæˆå™¨ç»Ÿä¸€ä½¿ç”¨ç›¸åŒç»“æ„çš„ Neural SDEï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ æ€§èƒ½å¯¹æ¯”ï¼ˆè§ Table 1 & Table 3ï¼‰

#### åœ¨åˆæˆæ•°æ®ä¸Šï¼ˆTable 1ï¼‰ï¼š
| æ¨¡å‹ | GBM-MISE â†“ | OU-MISE â†“ | CIR-MISE â†“ | PolyDrift-MISE â†“ |
|------|------------|-----------|------------|------------------|
| DLinear | 6.00 | 61.61 | 196.79 | 5.18 |
| Transformer | 0.74 | 1.22 | 2.46 | 9.47 |
| Latent-SDEs | 0.44 | 101.40 | 10.00 | 6.81 |
| GAN-SDEs | 0.38 | 214.54 | â€” | 0.27 |
| **HGAN-SDEs** | **0.17** âœ… | **0.89** âœ… | **0.18** âœ… | **0.04** âœ… |

> âœ… åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­å‡å–å¾—æœ€ä¼˜è¡¨ç°ï¼Œå°¤å…¶åœ¨éçº¿æ€§æ‰©æ•£ç³»ç»Ÿï¼ˆå¦‚ CIR å’Œ Polynomial Driftï¼‰ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚

#### åœ¨çœŸå®æ•°æ®ä¸Šï¼ˆTable 3ï¼‰ï¼š
| æ¨¡å‹ | Stock-AAL-MISE â†“ | Stock-ADBE-MISE â†“ | Traffic-MISE â†“ |
|------|------------------|--------------------|----------------|
| Transformer | 59.80 | 485.93 | 1885.06 |
| Latent-SDEs | 35.52 | 34.67 | 32.17 |
| GAN-SDEs | 38.00 | 37.89 | 35.79 |
| **HGAN-SDEs** | **2.89** âœ… | **8.05** âœ… | **0.22** âœ… |

> âœ… åœ¨é‡‘èå’Œäº¤é€šåœºæ™¯ä¸‹å‡å¤§å¹…é¢†å…ˆï¼Œè¯´æ˜å…¶å¯¹çœŸå®å¤æ‚éšæœºç³»ç»Ÿçš„é€‚åº”èƒ½åŠ›å¼ºã€‚

### ğŸ” æ¶ˆèå®éªŒä¸è¿›ä¸€æ­¥æ¢ç´¢ï¼ˆSection 4.3ï¼‰

#### (1) Hermite å‡½æ•°é¡¹æ•°çš„å½±å“ï¼ˆFigure 2ï¼‰
- éšç€ Hermite é¡¹æ•°å¢åŠ ï¼ŒMISE å…ˆä¸‹é™åè¶‹äºå¹³ç¨³ã€‚
- **3â€“4 é¡¹å·²è¶³å¤Ÿè¾¾åˆ°æœ€ä½³æ€§èƒ½**ï¼Œæ›´å¤šé¡¹åè€Œå¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆå¹¶å¢åŠ è®­ç»ƒè´Ÿæ‹…ã€‚
- ç»“è®ºï¼š**å°‘é‡ Hermite é¡¹å³å¯å®ç°é«˜è´¨é‡è·¯å¾„åˆ¤åˆ«**ï¼ŒéªŒè¯äº†æ–¹æ³•çš„é«˜æ•ˆæ€§ã€‚

#### (2) è®¡ç®—æ•ˆç‡å¯¹æ¯”ï¼ˆTable 4ï¼‰
| åˆ¤åˆ«å™¨ç±»å‹ | MISE â†“ | GPU-hours â†“ |
|----------|--------|-------------|
| LSTM | 1.12 | 6.5 |
| MLP | 0.95 | 4.8 |
| CDEï¼ˆGAN-SDEsï¼‰ | 0.11 | 10.0 |
| **Hermiteï¼ˆHGAN-SDEsï¼‰** | **0.04** âœ… | **1.2** âœ… |

> âœ… HGAN-SDEs ä¸ä»…æ€§èƒ½æœ€å¥½ï¼Œè€Œä¸”è®­ç»ƒé€Ÿåº¦æœ€å¿«ã€èµ„æºæ¶ˆè€—æœ€ä½ï¼Œé€‚åˆå¤§è§„æ¨¡æˆ–èµ„æºå—é™åœºæ™¯ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Hermite å‡½æ•°æ˜¯å»ºæ¨¡ SDE è·¯å¾„åˆ†å¸ƒçš„ç†æƒ³å·¥å…·**ï¼š
   - æ•°å­¦ä¸Šä¸¥è°¨ï¼Œå…·å¤‡æ­£äº¤æ€§ã€å®Œå¤‡æ€§ï¼›
   - å¯æœ‰æ•ˆé€¼è¿‘ SDE çš„è½¬ç§»å¯†åº¦ï¼Œå°¤å…¶é€‚ç”¨äºç¨³æ€åˆ†æã€‚

2. **HGAN-SDEs æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•**ï¼š
   - åœ¨åˆæˆä¸çœŸå®æ•°æ®ä¸Šå‡å–å¾— SOTA æ€§èƒ½ï¼›
   - ç‰¹åˆ«æ“…é•¿å¤„ç†é‡å°¾ã€éçº¿æ€§æ‰©æ•£ç­‰å¤æ‚éšæœºåŠ¨åŠ›ç³»ç»Ÿã€‚

3. **å…¼é¡¾æ•ˆç‡ä¸ç¨³å®šæ€§**ï¼š
   - è®­ç»ƒé€Ÿåº¦å¿«ï¼ˆå¹³å‡ 1.2 GPU-hourï¼‰ï¼›
   - æ”¶æ•›ç¨³å®šï¼Œä¸æ˜“å‡ºç°æ¨¡å¼å´©æºƒï¼ˆmode collapseï¼‰ã€‚

4. **è½»é‡åŒ–è®¾è®¡æœ‰æ•ˆ**ï¼š
   - ä»…éœ€ 3â€“4 ä¸ª Hermite é¡¹å³å¯è·å¾—é«˜æ€§èƒ½ï¼›
   - åˆ¤åˆ«å™¨å¯ç”¨æ ‡å‡† MLP å®ç°ï¼Œæ— éœ€å¤æ‚æ¶æ„ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰æ–¹æ³•ä¸»è¦é’ˆå¯¹ä¸€ç»´ SDE è®¾è®¡ï¼Œæ‰©å±•åˆ°é«˜ç»´ç³»ç»Ÿå¯èƒ½é¢ä¸´â€œç»´åº¦ç¾éš¾â€ã€‚
- å¯¹éå¹³ç¨³è¿‡ç¨‹ï¼ˆnon-stationary dynamicsï¼‰çš„å»ºæ¨¡èƒ½åŠ›å°šæœªå……åˆ†éªŒè¯ã€‚
- Hermite å±•å¼€ä¾èµ–äºå¯†åº¦å¯ç§¯æ€§å‡è®¾ï¼Œåœ¨æŸäº›å¥‡å¼‚æ‰©æ•£æƒ…å½¢ä¸‹å¯èƒ½å¤±æ•ˆã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. æ¨å¹¿è‡³å¤šå˜é‡ï¼ˆmultivariateï¼‰SDE å»ºæ¨¡ï¼Œç»“åˆå¼ é‡ç§¯å½¢å¼çš„é«˜ç»´ Hermite åŸºã€‚
2. ç»“åˆè‡ªé€‚åº”æˆªæ–­ç­–ç•¥ï¼ŒåŠ¨æ€é€‰æ‹© Hermite é¡¹æ•°ä»¥å¹³è¡¡ç²¾åº¦ä¸æ•ˆç‡ã€‚
3. åº”ç”¨äºæ›´å¤šå®é™…é¢†åŸŸï¼Œå¦‚æœŸæƒå®šä»·ã€é£é™©å»ºæ¨¡ã€æ°”å€™æ¨¡æ‹Ÿç­‰ã€‚
4. æ¢ç´¢ä¸å…¶ä»–æ— ç›‘ç£å­¦ä¹ æ¡†æ¶ï¼ˆå¦‚ Score Matching æˆ– Flow-based Modelsï¼‰èåˆçš„å¯èƒ½æ€§ã€‚

---

## âœ… æ€»ç»“
**HGAN-SDEs** æ˜¯ä¸€ä¸ªå°† **Neural SDE** ä¸ **Hermite å‡½æ•°ç†è®º**å·§å¦™ç»“åˆçš„æ–°å‹ GAN æ¡†æ¶ã€‚å®ƒé€šè¿‡å¼•å…¥æ­£äº¤ã€è½»é‡ã€å¯è§£é‡Šçš„ Hermite åŸºå‡½æ•°ä½œä¸ºåˆ¤åˆ«å™¨ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡å’Œè®­ç»ƒç¨³å®šæ€§æ–¹é¢çš„ç—›ç‚¹ï¼Œåœ¨å¤šç§ SDE ç³»ç»Ÿä¸­å®ç°äº†**æ›´é«˜ç²¾åº¦ã€æ›´å¿«æ”¶æ•›ã€æ›´å¼ºæ³›åŒ–èƒ½åŠ›**çš„è¡¨ç°ï¼Œä¸ºç¥ç»éšæœºå¾®åˆ†æ–¹ç¨‹çš„å­¦ä¹ æä¾›äº†æ–°çš„é«˜æ•ˆè·¯å¾„ã€‚

</details>

---

### 14. [Scaling Reinforcement Learning for Content Moderation with Large Language Models](https://arxiv.org/abs/2512.20061)

**Authors**: Hamed Firooz, Rui Liu, Yuchen Lu, Zhenyu Hou, Fangzhou Xiong, Xiaoyang Zhang, Changshu Jian, Zhicheng Zhu, Jiayuan Ma, Jacob Tao, Chaitali Gupta, Xiaochang Peng, Shike Mei, Hang Cui, Yang Qin, Shuo Tang, Jason Gaedtke, Arpit Mittal  
**Category**: cs.AI  
**Published**: 2025-12-24  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.20061v1  

#### Abstract
Content moderation at scale remains one of the most pressing challenges in today's digital ecosystem, where billions of user- and AI-generated artifacts must be continuously evaluated for policy violations. Although recent advances in large language models (LLMs) have demonstrated strong potential f...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Scaling Reinforcement Learning for Content Moderation with Large Language Models*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡èšç„¦äº**å¤§è§„æ¨¡å†…å®¹å®¡æ ¸ï¼ˆcontent moderationï¼‰ä¸­çš„æ ¸å¿ƒæŒ‘æˆ˜**ï¼Œå³åœ¨æ ‡ç­¾ç¨€ç–ã€æ”¿ç­–å®šä¹‰åŠ¨æ€å˜åŒ–ã€ä¸”éœ€è¦å¤æ‚è¯­ä¹‰æ¨ç†çš„åœºæ™¯ä¸‹ï¼Œå¦‚ä½•é«˜æ•ˆè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»¥å®ç°ä¸“å®¶çº§å‡†ç¡®åº¦çš„å†…å®¹åˆ†ç±»ã€‚

ä¼ ç»Ÿæ–¹æ³•å¦‚ **Supervised Fine-Tuning (SFT)** åœ¨é«˜è´¨é‡æ ‡æ³¨æ•°æ®ç¨€ç¼ºæ—¶è¡¨ç°å—é™ï¼Œè€Œç®€å•çš„åŸºäºæœ€ç»ˆæ ‡ç­¾åŒ¹é…çš„ **Reinforcement Learning (RL)** å®¹æ˜“å¯¼è‡´å¥–åŠ±é»‘å®¢ï¼ˆreward hackingï¼‰ã€æ¨ç†é“¾å´©æºƒï¼ˆreasoning collapseï¼‰ç­‰é—®é¢˜ã€‚æœ¬æ–‡ç³»ç»Ÿåœ°æ¢ç´¢å¹¶ä¼˜åŒ–äº† RL åœ¨å·¥ä¸šçº§å†…å®¹å®¡æ ¸ä»»åŠ¡ä¸­çš„å¯æ‰©å±•æ€§ä¸ç¨³å®šæ€§ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

1. **å¤šç»´åº¦å¥–åŠ±å¡‘é€ ï¼ˆReward Shapingï¼‰æ¡†æ¶**  
   æå‡ºç»“åˆå››ç§å¥–åŠ±ä¿¡å·çš„ç»¼åˆå¥–åŠ±å‡½æ•°ï¼š
   - `R_acc`ï¼šæœ€ç»ˆé¢„æµ‹å‡†ç¡®æ€§ï¼ˆverifiable rewardï¼‰
   - `R_fmt`ï¼šè¾“å‡ºæ ¼å¼ä¸€è‡´æ€§
   - `R_len`ï¼šé¼“åŠ±åˆç†é•¿åº¦çš„æ¨ç†é“¾ï¼Œé˜²æ­¢â€œé•¿åº¦åç¼©â€
   - `R_rub`ï¼šåŸºäº rubric çš„ LLM-as-Judge å¥–åŠ±ï¼Œå¯¹æ¨ç†è¿‡ç¨‹è¿›è¡Œç»†ç²’åº¦è¯„ä¼°ï¼ˆå¦‚äº‹å®æ€§ã€å¿ å®æ€§ã€æ”¿ç­–éµå¾ªï¼‰

   ç»¼åˆå¥–åŠ±å½¢å¼ä¸ºï¼š
   $$
   R_{\text{total}} = \alpha_{\text{acc}} R_{\text{acc}} + \alpha_{\text{fmt}} R_{\text{fmt}} + \alpha_{\text{len}} R_{\text{len}} + \alpha_{\text{rub}} R_{\text{rub}}
   $$

2. **Reflection-Aided Prompting**  
   å¼•å…¥ä¸‰é˜¶æ®µæç¤ºæœºåˆ¶ï¼š
   - åˆå§‹åˆ¤æ–­ï¼ˆfirst decisionï¼‰
   - å­æ ‡ç­¾åæ€ï¼ˆsub-label reflectionï¼‰
   - æœ€ç»ˆå†³ç­–ï¼ˆlast decisionï¼‰  
   é€šè¿‡è®©æ¨¡å‹è‡ªæˆ‘åæ€å…¶æ¨ç†è·¯å¾„ï¼Œæ˜¾è‘—æ”¹å–„ç½®ä¿¡åº¦åˆ†å¸ƒçš„åŒå³°é—®é¢˜ï¼ˆbimodal distributionï¼‰ï¼Œæå‡é˜ˆå€¼å†³ç­–ç¨³å®šæ€§ã€‚

3. **Monte-Carlo Score Aggregation**  
   å¯¹åŒä¸€è¾“å…¥é‡‡æ ·å¤šä¸ªæ¨ç†è·¯å¾„ï¼Œåˆ©ç”¨æœŸæœ›å…¬å¼ä¼°è®¡æ›´ç¨³å®šçš„æ¦‚ç‡è¾“å‡ºï¼š
   $$
   P_\theta(y|q) = \mathbb{E}_{r \sim P_\theta(r|q)}[P_\theta(y|r,q)]
   $$
   æœ‰æ•ˆç¼“è§£å› å•æ¬¡æ¨ç†ä¸»å¯¼è€Œå¯¼è‡´çš„æç«¯ç½®ä¿¡åº¦é—®é¢˜ã€‚

4. **Disagreement Filtering æ•°æ®ç­›é€‰ç­–ç•¥**  
   åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹å¤šæ¬¡ç”Ÿæˆç»“æœï¼Œè¯†åˆ«â€œåˆ†æ­§æ ·æœ¬â€ï¼ˆdisagreement examplesï¼‰ï¼Œå³ä¸åŒæ¸©åº¦ä¸‹é¢„æµ‹ä¸ä¸€è‡´çš„æ ·æœ¬ã€‚è¿™ç±»æ ·æœ¬è¢«è®¤ä¸ºå…·æœ‰æ›´é«˜å­¦ä¹ ä»·å€¼ï¼Œç”¨äºæå‡ RL çš„æ•°æ®æ•ˆç‡ã€‚

5. **å·¥ä¸šçº§ RL è®­ç»ƒ Recipe è®¾è®¡**  
   æä¾›äº†ä¸€å¥—å®Œæ•´çš„è®­ç»ƒæŒ‡å—ï¼Œæ¶µç›– GRPO ç®—æ³•é€‰æ‹©ã€sequence-level reward normalizationã€KLç³»æ•°è®¾ä¸º0ã€effective batch size è‡³å°‘1024ç­‰å…³é”®é…ç½®ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **æ•°æ®æ•ˆç‡** | RL-Only åœ¨ä»…æ•°ç™¾æ ·æœ¬ä¸Šå³å¯åª²ç¾ SFT æ•°ä¸‡æ ·æœ¬æ€§èƒ½ï¼Œ**å®ç° 10Ã—â€“100Ã— æ›´é«˜çš„æ•°æ®æ•ˆç‡** |
| **æ³›åŒ–èƒ½åŠ›** | èƒ½å¤„ç†å¤æ‚ã€æ¡ä»¶æ€§å¼ºã€ä¸Šä¸‹æ–‡ä¾èµ–çš„æ”¿ç­–é€»è¾‘ï¼Œè¶…è¶Šæµ…å±‚æ¨¡å¼åŒ¹é… |
| **ç¨³å®šæ€§** | å¤šé‡å¹²é¢„ï¼ˆrubric reward, reflection, MC samplingï¼‰æ˜¾è‘—é™ä½ reward hacking å’Œ reasoning collapse é£é™© |
| **å¯æ‰©å±•æ€§** | å±•ç¤ºäº† RL æ€§èƒ½åœ¨æ•°æ®é‡ã€rollout æ•°ã€ä¼˜åŒ–æ­¥æ•°ä¸Šçš„ **sigmoid-like scaling behavior**ï¼Œä¾¿äºèµ„æºè§„åˆ’ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- æ¥æºäº **Meta Platforms, Inc.** çš„ä¸‰ä¸ªçœŸå®ç”Ÿäº§ç¯å¢ƒä¸­çš„å†…å®¹å®¡æ ¸ä»»åŠ¡ï¼ˆTask1, Task2, Task3ï¼‰ï¼Œå‡ä¸ºäºŒåˆ†ç±»ä»»åŠ¡ï¼ˆæ˜¯å¦è¿åæ”¿ç­–ï¼‰ã€‚
- æ•°æ®åŒ…å«æ–‡æœ¬åŠéƒ¨åˆ†å¤šæ¨¡æ€ä¿¡æ¯ï¼ˆå¦‚è´¦æˆ·èµ„æ–™ã€ç”Ÿç‰©æè¿°ã€å›½å®¶ã€ç²‰ä¸æ•°ã€å†å²å†…å®¹ç­‰ï¼‰ã€‚
- æ¯ä¸ªä»»åŠ¡ä»…æœ‰æ•°ç™¾è‡³æ•°åƒæ¡é«˜è´¨ä¸“å®¶æ ‡æ³¨æ•°æ®ï¼Œä½“ç°å…¸å‹çš„**æ ‡ç­¾ç¨€ç¼ºåœºæ™¯**ã€‚

---

### **å®éªŒè®¾ç½®**

- **æ¨¡å‹æ¶æ„**ï¼šä½¿ç”¨ Qwen2.5-VL-7B å’Œ Qwen-3-8B ç­‰å¼€æº LLM ä½œä¸ºåŸºç¡€æ¨¡å‹ã€‚
- **RL ç®—æ³•**ï¼šé‡‡ç”¨ **Group Relative Policy Optimization (GRPO)**ï¼Œæ›¿ä»£ä¼ ç»Ÿ PPOï¼Œæ— éœ€æ˜¾å¼ value networkï¼Œè®¡ç®—æ›´é«˜æ•ˆã€‚
- **è®­ç»ƒæ¡†æ¶å¯¹æ¯”**ï¼šæ¯”è¾ƒ HuggingFace TRL ä¸ **VeRL**ï¼Œåè€…åŸºäº HybridFlow å®ç°æ›´é«˜ååï¼ˆæœ€é«˜è¾¾ 2.5Ã—ï¼‰ã€‚
- **å¥–åŠ±è®¾è®¡**ï¼šç»¼åˆ accuracyã€formatã€lengthã€rubric å››ç±» rewardã€‚
- **KL æ§åˆ¶**ï¼šÎ² = 0ï¼Œå…è®¸æ›´å¼ºæ¢ç´¢ã€‚
- **Normalization**ï¼šé‡‡ç”¨ **sequence-level reward normalization** æå‡é•¿æ¨ç†ä»»åŠ¡ç¨³å®šæ€§ã€‚

---

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **R@P90** | Recall at Precision â‰¥ 90%ï¼Œå¼ºè°ƒé«˜ç²¾åº¦ä¸‹çš„å¬å›èƒ½åŠ›ï¼ˆå·¥ä¸šå¸¸ç”¨ï¼‰ |
| **PRAUC** | Precision-Recall æ›²çº¿ä¸‹é¢ç§¯ï¼Œé€‚ç”¨äºç±»åˆ«ä¸å¹³è¡¡ä»»åŠ¡ |
| **F1 Score** | ç²¾ç¡®ç‡ä¸å¬å›ç‡çš„è°ƒå’Œå¹³å‡ |
| **Faithfulness / Factuality** | ä½¿ç”¨ Gemini-2.5-Pro å’Œ HHEM æ¨¡å‹ä½œä¸º judgeï¼Œè¯„ä¼°æ¨ç†æ˜¯å¦å¿ äºæŒ‡ä»¤ä¸äº‹å® |
| **Confidence Calibration** | åˆ†æè¾“å‡ºæ¦‚ç‡åˆ†å¸ƒæ˜¯å¦åˆç†ï¼ˆé¿å…åŒå³°ï¼‰ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿æ–¹æ³• | æè¿° |
|--------|------|
| **SFT-COT** | åŸºäº Chain-of-Thought çš„ç›‘ç£å¾®è°ƒ |
| **Zero-shot SFT** | æ— å¾®è°ƒç›´æ¥æ¨ç† |
| **RL-Only** | ç›´æ¥åœ¨ base model ä¸Šåº”ç”¨ RL |
| **SFT â†’ RL** | å…ˆ SFT å† RL å¾®è°ƒ |
| **maj@N / pass@N** | å¤š rollout ä¸‹å¤šæ•°æŠ•ç¥¨æ­£ç¡®ç‡ / è‡³å°‘ä¸€ä¸ªæ­£ç¡®ç‡ï¼Œç”¨äºåˆ†æå“åº”é€‰æ‹©æœºåˆ¶ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… æ•°æ®æ•ˆç‡å¯¹æ¯”ï¼ˆFigure 6ï¼‰

- åœ¨ Task1 ä¸­ï¼Œ**RL-Onlyï¼ˆ661æ ·æœ¬ï¼‰ â‰ˆ SFTï¼ˆ60Kæ ·æœ¬ï¼‰**
- åœ¨ Task3 ä¸­ï¼Œ**RL-Onlyï¼ˆ200æ ·æœ¬ï¼‰ > SFTï¼ˆ20Kæ ·æœ¬ï¼‰**
- è¡¨æ˜ RL å¯å®ç° **10Ã—â€“100Ã— æ•°æ®æ•ˆç‡æå‡**

#### âœ… Reward Shaping æ•ˆæœï¼ˆTable 6ï¼‰

| æ¨¡å‹ | Reward Setup | F1 |
|------|--------------|-----|
| Qwen-38B | R_acc + R_fmt | 0.49 |
| Qwen-38B | + R_len | 0.49ï¼ˆæœªæå‡ï¼‰ |
| Qwen-38B | + R_rub | **0.61**ï¼ˆâ†‘24.5%ï¼‰ |

> **Rubric-based reward è´¡çŒ®æœ€å¤§å¢ç›Š**

#### âœ… Disagreement Filtering ç»“æœï¼ˆTable 8ï¼‰

| æ•°æ®å­é›† | æ ·æœ¬æ•° | F1 | PRAUC |
|---------|-------|-----|--------|
| All | 677 | 0.87 | 0.85 |
| Easy Only | 566 | 0.79 | 0.80 |
| Disagreement Only | **61** | **0.88** | **0.90** |

> ä»…ç”¨ **61ä¸ªåˆ†æ­§æ ·æœ¬è®­ç»ƒ RL** å³è¾¾åˆ°ç”šè‡³è¶…è¿‡å…¨é‡æ•°æ®æ•ˆæœ â†’ **æœ‰æ•ˆæ•°æ®æ•ˆç‡æå‡çº¦ 100Ã—**

#### âœ… Monte Carlo Sampling æ•ˆæœï¼ˆTable 2ï¼‰

| Nï¼ˆrolloutsï¼‰ | Gain on R@P90 |
|-------------|----------------|
| 1 â†’ 4 | â†‘0.05 |
| >4 | æ”¶ç›Šé€’å‡ |

> æ¨è N=4 ä½œä¸ºæ€§ä»·æ¯”æœ€ä¼˜é€‰æ‹©

#### âœ… Effective Batch Size å½±å“ï¼ˆTable 7ï¼‰

| Batch Size | R@P90 |
|-----------|--------|
| 128 | 0.18 |
| 1024 | 0.81 |
| â‰¥2048 | 0.85ï¼ˆé¥±å’Œï¼‰ |

> æ¨è minimum effective batch size = **1024**

#### âœ… GRPO Rollout æ•°å½±å“ï¼ˆFigure 8 & Table 5ï¼‰

- éšç€ rollout æ•°å¢åŠ ï¼Œæ€§èƒ½å…ˆå‡åé™ï¼ˆå­˜åœ¨æœ€ä¼˜åŒºé—´ï¼‰
- Task2 åœ¨ N=32 æ—¶è¾¾åˆ°å³°å€¼ï¼ˆR@P90=0.63ï¼‰
- è¿‡å¤§ rollout æ•°å— LLM judge å®¹é‡é™åˆ¶

---

### **æ¶ˆèå®éªŒç»“æœ**

| å®éªŒ | å‘ç° |
|------|------|
| **RL-Only vs SFTâ†’RL** | RL-Only æ•°æ®æ•ˆç‡é«˜ï¼›SFTâ†’RL æ›´ç¨³å®šä½†å¯èƒ½å¼•å…¥ factuality hallucination |
| **With/Without Reflection**ï¼ˆTable 4ï¼‰ | ä½¿ç”¨ reflection å PRAUC ä» 0.77 â†’ 0.89ï¼ŒR@P90 ä» 0.05 â†’ 0.59 |
| **With/Without MC Sampling** | æ˜¾è‘—ç¼“è§£åŒå³°åˆ†å¸ƒï¼Œæå‡ç½®ä¿¡åº¦æ ¡å‡† |
| **Remove Hard Examples** | ç§»é™¤ hard examples åè€Œæå‡æ€§èƒ½ï¼Œè¯´æ˜å™ªå£°æ ‡ç­¾æœ‰å®³ |
| **Varying Temperature in GRPO** | æœ€ä½³ T âˆˆ [0.7, 1.0]ï¼›T > 1.0 å¯¼è‡´è§£æé”™è¯¯å¢å¤š |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. ğŸ” **RL å…·æœ‰ sigmoid-like scaling behavior**  
   æ€§èƒ½éšæ•°æ®é‡ã€rollout æ•°ã€compute æŠ•å…¥å¹³æ»‘ä¸Šå‡å¹¶é€æ¸é¥±å’Œï¼Œæä¾›æ¸…æ™°çš„èµ„æºåˆ†é…è“å›¾ã€‚

2. ğŸ’¡ **RL æ¯” SFT é«˜å‡º 10Ã—â€“100Ã— æ•°æ®æ•ˆç‡**  
   å°¤å…¶é€‚åˆä¸“å®¶æ ‡æ³¨æ˜‚è´µã€è·å–ç¼“æ…¢çš„å†…å®¹å®¡æ ¸é¢†åŸŸã€‚

3. ğŸ› ï¸ **å•çº¯ accuracy reward ä¸è¶³ï¼Œéœ€å¤šç»´ reward shaping**  
   ç‰¹åˆ«æ˜¯ `R_rub`ï¼ˆrubric-basedï¼‰å’Œ `R_len` å¯¹æå‡æ¨ç†è´¨é‡å’Œç¨³å®šæ€§è‡³å…³é‡è¦ã€‚

4. ğŸ§  **RL æ›´åƒæ˜¯ response selector è€Œé reasoning enhancer**  
   åˆ†æè¡¨æ˜ RL ä¸»è¦ä½œç”¨æ˜¯æé«˜ç”Ÿæˆæ­£ç¡®ç­”æ¡ˆçš„æ¦‚ç‡ï¼Œè€Œéæ ¹æœ¬å¢å¼ºæ¨ç†èƒ½åŠ›ï¼ˆè§ maj@N vs pass@N åˆ†æï¼‰ã€‚

5. âš–ï¸ **å­˜åœ¨ faithfulness ä¸ factuality çš„æƒè¡¡**  
   - SFTâ†’RL æå‡æ ¼å¼ä¸€è‡´æ€§ï¼ˆfaithfulnessï¼‰
   - ä½†ä¹Ÿæ›´å®¹æ˜“äº§ç”Ÿâ€œçœ‹ä¼¼åˆç†ä½†é”™è¯¯â€çš„è§£é‡Šï¼ˆfactuality hallucinationï¼‰

6. ğŸ“Š **Monte Carlo + Reflection æ˜¾è‘—æ”¹å–„ confidence calibration**  
   è§£å†³äº† reasoning model è¾“å‡ºæ¦‚ç‡æç«¯æåŒ–çš„é—®é¢˜ï¼Œä½¿é˜ˆå€¼å†³ç­–æ›´å¯é ã€‚

7. ğŸ” **Disagreement Filtering æ˜¯é«˜æ•ˆæ•°æ®ç­›é€‰åˆ©å™¨**  
   è‡ªåŠ¨è¯†åˆ«é«˜ä¿¡æ¯é‡æ ·æœ¬ï¼Œè¿›ä¸€æ­¥æ”¾å¤§ RL çš„æ•°æ®æ•ˆç‡ä¼˜åŠ¿ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™ | è¯´æ˜ |
|------|------|
| **ä¾èµ– LLM-as-Judge** | `R_rub` ä¾èµ–å¤–éƒ¨ judge æ¨¡å‹ï¼ˆå¦‚ Geminiï¼‰ï¼Œå¸¦æ¥é¢å¤–æˆæœ¬ä¸æ½œåœ¨åè§ |
| **compute å¼€é”€å¤§** | GRPO éœ€å¤§é‡ rollout å’Œ high effective batch sizeï¼Œå¯¹ç®—åŠ›è¦æ±‚é«˜ |
| **éš¾ä»¥å®Œå…¨æ¶ˆé™¤ reward hacking** | å°½ç®¡æœ‰å¤šç§é˜²å¾¡æ‰‹æ®µï¼Œä»å¯èƒ½å‡ºç°ç­–ç•¥æ€§çŸ­è·¯è¡Œä¸º |
| **æ³›åŒ–åˆ°æ–°æ”¿ç­–éœ€é‡æ–°è®­ç»ƒ** | å½“æ”¿ç­–é¢‘ç¹æ›´æ–°æ—¶ï¼Œéœ€æŒç»­è¿­ä»£è®­ç»ƒæµç¨‹ |
| **å¤šæ¨¡æ€æ”¯æŒæœ‰é™** | å½“å‰å®éªŒä¸»è¦é›†ä¸­åœ¨æ–‡æœ¬ä¸ºä¸»ä»»åŠ¡ï¼Œå›¾åƒç†è§£èƒ½åŠ›æœ‰å¾…åŠ å¼º |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **è‡ªåŠ¨åŒ– rubric æ„å»º**ï¼šæ¢ç´¢ä»æ”¿ç­–æ–‡æ¡£ä¸­è‡ªåŠ¨æå–è¯„ä¼°æ ‡å‡†ï¼Œå‡å°‘äººå·¥è®¾è®¡æˆæœ¬ã€‚
2. **è½»é‡åŒ– RL æ¨ç†**ï¼šç ”ç©¶ test-time scaling ä¸ distillation æ–¹æ³•ï¼Œé™ä½éƒ¨ç½²å¼€é”€ã€‚
3. **åŠ¨æ€æ”¿ç­–é€‚åº”æœºåˆ¶**ï¼šæ„å»ºèƒ½å¿«é€Ÿé€‚åº”æ”¿ç­–å˜æ›´çš„æŒç»­å­¦ä¹ æ¡†æ¶ã€‚
4. **å¤š agent debate for moderation**ï¼šå¼•å…¥å¤šä¸ª agent è¾©è®ºæœºåˆ¶æå‡å†³ç­–é²æ£’æ€§ã€‚
5. **ç«¯åˆ°ç«¯ joint SFT+RL training**ï¼šæ¢ç´¢è”åˆä¼˜åŒ–æ–¹æ¡ˆï¼Œé¿å…ä¸¤é˜¶æ®µè®­ç»ƒçš„ä¿¡æ¯æŸå¤±ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡è¯æ˜äº† **Reinforcement Learning æ˜¯é€šå¾€ä¸“å®¶çº§å†…å®¹å®¡æ ¸ç³»ç»Ÿçš„å¯è¡Œè·¯å¾„**ï¼Œé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„ reward shapingã€reflection prompting å’Œ data filtering ç­–ç•¥ï¼Œå¯åœ¨æä½æ ‡æ³¨æˆæœ¬ä¸‹å®ç°è¿œè¶… SFT çš„æ€§èƒ½ï¼Œå¹¶æ­ç¤ºäº† RL åœ¨å·¥ä¸šåœºæ™¯ä¸­çš„å¯é¢„æµ‹ scaling è§„å¾‹ã€‚

</details>

---

### 15. [Scaling Point-based Differentiable Rendering for Large-scale Reconstruction](https://arxiv.org/abs/2512.20017)

**Authors**: Hexu Zhao, Xiaoteng Liu, Xiwen Min, Jianhao Huang, Youming Deng, Yanfei Li, Ang Li, Jinyang Li, Aurojit Panda  
**Category**: cs.DC  
**Published**: 2025-12-24  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.20017v1  

#### Abstract
Point-based Differentiable Rendering (PBDR) enables high-fidelity 3D scene reconstruction, but scaling PBDR to high-resolution and large scenes requires efficient distributed training systems. Existing systems are tightly coupled to a specific PBDR method. And they suffer from severe communication o...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šScaling Point-based Differentiable Rendering for Large-scale Reconstruction

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
- **ç°æœ‰ç³»ç»Ÿç¼ºä¹é€šç”¨æ€§**ï¼šå½“å‰çš„åˆ†å¸ƒå¼è®­ç»ƒç³»ç»Ÿï¼ˆå¦‚ gsplat [90] å’Œ Grendel [96]ï¼‰ä»…é’ˆå¯¹ç‰¹å®šçš„ PBDR ç®—æ³•ï¼ˆå¦‚ 3D Gaussian Splatting, 3DGSï¼‰ï¼Œæ— æ³•æ”¯æŒä¸æ–­æ¶Œç°çš„æ–°ç®—æ³•ã€‚
- **é€šä¿¡å¼€é”€ä¸¥é‡**ï¼šç”±äºæ¨¡å‹çŠ¶æ€ï¼ˆå³ç‚¹äº‘ï¼‰å’Œå›¾åƒæ¸²æŸ“ä»»åŠ¡åœ¨ GPU ä¸Šéšæœºåˆ†å¸ƒï¼Œå¯¼è‡´æ¯ä¸ª GPU åœ¨æ¸²æŸ“æ—¶éœ€è¦ä»å…¶ä»– GPU è·å–å¤§é‡è¿œç¨‹æ•°æ®ï¼Œé€ æˆä¸¥é‡çš„é€šä¿¡ç“¶é¢ˆã€‚å®éªŒæ˜¾ç¤ºï¼Œåœ¨ç°æœ‰ç³»ç»Ÿä¸­ï¼Œé€šä¿¡æ—¶é—´å æ•´ä¸ªè®­ç»ƒæ­¥éª¤çš„ **70â€“85%**ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºäº† **Gaian** â€”â€”ä¸€ä¸ªé€šç”¨ä¸”é«˜æ•ˆçš„åˆ†å¸ƒå¼ PBDR è®­ç»ƒç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰ç»Ÿä¸€çš„ç¼–ç¨‹æ¥å£ï¼ˆAPIï¼‰
- è®¾è®¡äº†ä¸€ä¸ªæŠ½è±¡æ¥å£ `PBDR_program`ï¼Œå°†æ‰€æœ‰ PBDR ç®—æ³•åˆ†è§£ä¸ºä¸‰ä¸ªå¯è‡ªå®šä¹‰å‡½æ•°ï¼š
  - `pts_culling(view, PC)`ï¼šå‰”é™¤è§†é”¥å¤–çš„ç‚¹
  - `pts_splatting(view, PC, infrustum_ids)`ï¼šå°†ç‚¹æŠ•å½±ä¸ºè§†å›¾ç›¸å…³çš„â€œsplatâ€
  - `image_render(view, SP)`ï¼šä»å‰åˆ°ååˆæˆæœ€ç»ˆå›¾åƒ
- è¿™ç§è®¾è®¡æ—¢éšè—äº†åº•å±‚åˆ†å¸ƒå¼ç³»ç»Ÿçš„å¤æ‚æ€§ï¼Œåˆæ˜¾å¼æš´éœ²äº† **æ•°æ®è®¿é—®æ¨¡å¼**ï¼ˆä¾‹å¦‚å“ªä¸ªç›¸æœºè§†è§’è®¿é—®å“ªäº›ç‚¹ï¼‰ï¼Œä»è€Œä¸ºä¼˜åŒ–æä¾›ä¿¡æ¯åŸºç¡€ã€‚

#### ï¼ˆ2ï¼‰ä¸¤é˜¶æ®µå±€éƒ¨æ€§ä¼˜åŒ–ç­–ç•¥
Gaian åˆ©ç”¨ PBDR ä¸­ç‹¬ç‰¹çš„ç©ºé—´å±€éƒ¨æ€§ç‰¹å¾ï¼Œæå‡ºç»“åˆç¦»çº¿ä¸åœ¨çº¿ä¼˜åŒ–çš„æ–¹æ³•æ¥æœ€å°åŒ–è·¨ GPU æ•°æ®ä¼ è¾“ï¼š

- **ç¦»çº¿ç‚¹åˆ†é…ï¼ˆOffline Point Placementï¼‰**
  - å°†ç‚¹ä¸å›¾åƒä¹‹é—´çš„è®¿é—®å…³ç³»å»ºæ¨¡ä¸ºäºŒåˆ†å›¾ï¼ˆbipartite graphï¼‰
  - ä½¿ç”¨ METIS å·¥å…·è¿›è¡Œå›¾åˆ’åˆ†ï¼Œç›®æ ‡æ˜¯ä½¿åŒä¸€ GPU å­˜å‚¨ç»å¸¸è¢«åŒä¸€æ‰¹å›¾åƒè®¿é—®çš„ç‚¹ï¼Œå‡å°‘è·¨ GPU è¾¹ç•Œçš„æ•°æ®ç§»åŠ¨
  - å¼•å…¥â€œç‚¹ç»„â€ï¼ˆpoint groupï¼‰æœºåˆ¶å¯¹ç‚¹è¿›è¡Œç²—ç²’åº¦åˆ†ç»„ï¼ˆæ¯ç»„ 1024â€“4096 ä¸ªç‚¹ï¼‰ï¼Œä»¥é™ä½å›¾è§„æ¨¡å¹¶åŠ é€Ÿåˆ’åˆ†è¿‡ç¨‹
  - æ”¯æŒå±‚æ¬¡åŒ–åˆ’åˆ†ï¼šå…ˆæŒ‰æœºå™¨åˆ’åˆ†ï¼Œå†åœ¨æœºå™¨å†…éƒ¨åˆ†é…ç»™æœ¬åœ° GPUï¼Œä»¥åŒºåˆ†é«˜é€Ÿï¼ˆNVLinkï¼‰å’Œä½é€Ÿï¼ˆEthernetï¼‰é€šä¿¡é“¾è·¯

- **åœ¨çº¿å›¾åƒæ¸²æŸ“è°ƒåº¦ï¼ˆOnline Image Rendering Placementï¼‰**
  - æ¯è½®è®­ç»ƒåŠ¨æ€å†³å®šå¦‚ä½•å°† batch å†…çš„å›¾åƒåˆ†é…ç»™ä¸åŒ GPU æ¸²æŸ“
  - æ„é€ è®¿é—®çŸ©é˜µ $A_{j,k}$ è¡¨ç¤ºç¬¬ $j$ å¼ å›¾åƒéœ€ä»ç¬¬ $k$ ä¸ª GPU è·å–å¤šå°‘ç‚¹
  - å°†è°ƒåº¦é—®é¢˜å½¢å¼åŒ–ä¸ºæ•´æ•°çº¿æ€§è§„åˆ’ï¼ˆILPï¼‰ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–é€šä¿¡é‡å’Œè´Ÿè½½ä¸å¹³è¡¡
  - æå‡ºåŸºäº **Linear Sum Assignment (LSA)** + **è¿­ä»£å±€éƒ¨æœç´¢ï¼ˆIterative Local Searchï¼‰** çš„å¿«é€Ÿæ±‚è§£å™¨ï¼Œç¡®ä¿ä½å»¶è¿Ÿåœ¨çº¿å†³ç­–
  - æ”¯æŒå›¾åƒåˆ†å—ï¼ˆpatch-based assignmentï¼‰ï¼Œè¿›ä¸€æ­¥æå‡è°ƒåº¦çµæ´»æ€§å’Œè´Ÿè½½å‡è¡¡èƒ½åŠ›

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Gaian | ç°æœ‰ç³»ç»Ÿï¼ˆå¦‚ gsplatï¼‰ |
|------|-------|------------------|
| **é€šç”¨æ€§** | âœ… æ”¯æŒå¤šç§ PBDR ç®—æ³•ï¼ˆ3DGS, 2DGS, 3DCX, 4DGSï¼‰ | âŒ ä»…æ”¯æŒ 3DGS |
| **é€šä¿¡æ•ˆç‡** | âœ… æœ€å¤šå‡å°‘ **91%** çš„è·¨æœºé€šä¿¡ | âŒ éšæœºåˆ†å¸ƒå¯¼è‡´é«˜é€šä¿¡å¼€é”€ |
| **è®­ç»ƒåå** | âœ… æå‡ **1.50â€“3.71Ã—** | âŒ å—é™äºé€šä¿¡ç“¶é¢ˆ |
| **æ‰©å±•æ€§** | âœ… åœ¨ 128 GPU ä¸‹å®ç° **12.7Ã—** åŠ é€Ÿ | âŒ æ‰©å±•æ€§å·® |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å…±ä½¿ç”¨ **6 ä¸ªå…¬å¼€å¤§è§„æ¨¡æ•°æ®é›†**ï¼Œæ¶µç›–ç©ºä¸­ä¸è¡—æ™¯åœºæ™¯ï¼Œå…·æœ‰é«˜åˆ†è¾¨ç‡ï¼ˆæœ€é«˜è¾¾ 6Kï¼‰å’Œå¤§å›¾åƒæ•°é‡ï¼ˆæœ€å¤š 60,000 å¼ ï¼‰ï¼š

| æ•°æ®é›† | ç±»å‹ | å›¾åƒæ•° | åˆ†è¾¨ç‡ | ç‚¹äº‘å¤§å° |
|--------|------|--------|--------|----------|
| Rubble | Aerial | 1,600 | 4K | 40M |
| Ithaca365 | Street | 8,200 | 1K | 48M |
| Campus | Street | 20,000 | 1K | 56M |
| BigCity Street | Street | 34,000 | 1K | 80M |
| Sci-Art | Aerial | 3,600 | 6K | 200M |
| BigCity Aerial | Aerial | 60,000 | 1080P | 100M |

> æ³¨ï¼šâ€œBigCityâ€ æ¥è‡ª MatrixCity [49] æ•°æ®é›†ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šæœ€å¤šä½¿ç”¨ 32 å°æœåŠ¡å™¨ï¼Œæ¯å°é…å¤‡ 4Ã—40GB NVIDIA A100 GPUï¼Œé€šè¿‡ NVLinkï¼ˆèŠ‚ç‚¹å†…ï¼‰å’Œ 88 Gbps Ethernetï¼ˆèŠ‚ç‚¹é—´ï¼‰è¿æ¥
- **è®­ç»ƒé…ç½®**ï¼š
  - Batch Size: 16â€“64
  - æœ€å¤šä½¿ç”¨ **128 GPUs**
  - ä½¿ç”¨ PyTorch + NCCL å®ç°åˆ†å¸ƒå¼é€šä¿¡
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **è®­ç»ƒååé‡ï¼ˆThroughputï¼‰**ï¼šå•ä½æ—¶é—´å†…å¤„ç†çš„å›¾åƒæ•°ï¼ˆimages/sï¼‰
  - **é€šä¿¡ä½“ç§¯ï¼ˆCommunication Volumeï¼‰**ï¼šæ¯æ¬¡è¿­ä»£è·¨æœºå™¨ä¼ è¾“çš„ç‚¹çš„æ•°é‡
  - **PSNR**ï¼šé‡å»ºè´¨é‡è¯„ä»·æŒ‡æ ‡ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
  - **å¼º/å¼±å¯æ‰©å±•æ€§ï¼ˆStrong/Weak Scalabilityï¼‰**

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**: gsplat [90]ï¼ˆv1.4.0ï¼‰ï¼Œç›®å‰æœ€å…ˆè¿›çš„ 3DGS åˆ†å¸ƒå¼è®­ç»ƒç³»ç»Ÿ
- **æ”¹è¿›åçš„ baseline**ï¼š
  - æ·»åŠ äº† Gaian çš„é«˜æ•ˆæ•°æ®åŠ è½½æœºåˆ¶ï¼ˆé¢„è§£ç  + CPU pinned memoryï¼‰
  - æ‰‹åŠ¨ä¸ºå…¶æ·»åŠ  2DGS å’Œ 3DCX çš„åˆ†å¸ƒå¼æ”¯æŒï¼ˆç¹çä¸”æ˜“é”™ï¼‰
- **å¯¹æ¯”ç»´åº¦**ï¼šè®­ç»ƒé€Ÿåº¦ã€é€šä¿¡é‡ã€æ‰©å±•æ€§ã€é‡å»ºè´¨é‡

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰è®­ç»ƒååæ˜¾è‘—æå‡
åœ¨å…­å¤§æ•°æ®é›†ä¸Šå¹³å‡ï¼š
- **3DGS**ï¼šæé€Ÿ **2.30Ã—**ï¼ˆèŒƒå›´ 1.54â€“3.56Ã—ï¼‰
- **2DGS**ï¼šæé€Ÿ **2.50Ã—**ï¼ˆèŒƒå›´ 1.55â€“3.71Ã—ï¼‰
- **3DCX**ï¼šæé€Ÿ **2.23Ã—**ï¼ˆèŒƒå›´ 1.50â€“3.01Ã—ï¼‰

> ![Figure 10](#) æ˜¾ç¤º Gaian åœ¨æ‰€æœ‰åœºæ™¯ä¸‹å‡ä¼˜äº baselineï¼Œå°¤å…¶åœ¨é«˜åˆ†è¾¨ç‡ Aerial æ•°æ®é›†ä¸Šè¡¨ç°æ›´ä¼˜ã€‚

#### ï¼ˆ2ï¼‰é€šä¿¡é‡å¤§å¹…ä¸‹é™
- è·¨æœºå™¨é€šä¿¡ä½“ç§¯å‡å°‘ **53.8% â€“ 91.4%**
- æœ€é«˜å‡å°‘ **91.4%**ï¼ˆ3DCX on BigCity Aerialï¼‰

| åœºæ™¯ | 3DGS â†“ | 2DGS â†“ | 3DCX â†“ |
|------|--------|--------|--------|
| Rubble | 82.8% | 82.7% | 83.2% |
| Ithaca365 | 89.2% | 84.0% | 80.8% |
| Campus | 54.5% | 58.1% | 53.8% |
| BigCity Street | 57.7% | 55.5% | 54.8% |
| Sci-Art | 89.3% | 89.1% | 89.9% |
| BigCity Aerial | 89.9% | 89.9% | **91.4%** |

> é€šä¿¡å‡å°‘ç¨‹åº¦ä¸ååæå‡æ­£ç›¸å…³ï¼ŒéªŒè¯äº†é€šä¿¡æ˜¯ä¸»è¦ç“¶é¢ˆã€‚

#### ï¼ˆ3ï¼‰è‰¯å¥½çš„æ‰©å±•æ€§
- **å¼±æ‰©å±•æ€§**ï¼ˆå›ºå®šæ¯ GPU batch sizeï¼‰ï¼š
  - ä» 8 åˆ° 128 GPUsï¼Œååä» 226.9 img/s æå‡è‡³ **2898.5 img/s**ï¼ˆ**12.7Ã—**ï¼‰
- **å¼ºæ‰©å±•æ€§**ï¼ˆå›ºå®šå…¨å±€ batch size = 64ï¼‰ï¼š
  - ååä» 434.7 img/s æå‡è‡³ 1402.8 img/sï¼ˆçº¦ 3.2Ã—ï¼‰

> Gaian åœ¨æ›´å¤§è§„æ¨¡ä¸‹ä»ä¿æŒè‰¯å¥½æ‰©å±•è¶‹åŠ¿ã€‚

#### ï¼ˆ4ï¼‰æ”¯æŒè¶…å¤§æ¨¡å‹è®­ç»ƒ
- æˆåŠŸè®­ç»ƒè¿„ä»Šä¸ºæ­¢æœ€å¤§çš„ PBDR æ¨¡å‹ï¼š
  - **500 million points**ï¼ˆ29.5 billion parametersï¼‰
  - ä½¿ç”¨ 64Ã—A100 GPUs å®Œæˆ MatrixCity Street åœºæ™¯è®­ç»ƒ
- å®ç° **state-of-the-art é‡å»ºè´¨é‡**ï¼š
  - BigCity Aerialï¼šæµ‹è¯•é›† PSNR è¾¾ **26.75**
  - å¦‚ Figure 14 æ‰€ç¤ºï¼ŒPSNR éšæ¨¡å‹è§„æ¨¡å¢å¤§è€ŒæŒç»­æå‡

#### ï¼ˆ5ï¼‰æ”¯æŒå¤æ‚åŠ¨æ€åœºæ™¯ï¼ˆ3D Videoï¼‰
- å®ç°å¹¶è¯„ä¼° **4D Gaussian Splatting (4DGS)** åŠ¨æ€é‡å»ºç®—æ³•
- åœ¨ Corgi æ•°æ®é›†ä¸Šï¼š
  - ä» 8 åˆ° 64 GPUsï¼Œååæå‡ **4.42Ã—**
  - ç›¸æ¯”éšæœºåˆ†é…ï¼ŒGaian å‡å°‘ **48%** é€šä¿¡ï¼Œæå‡ **26%** åå

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰è”åˆä¼˜åŒ–å¿…è¦æ€§ï¼ˆFigure 13ï¼‰
- **ç¦ç”¨ç‚¹åˆ†é…ï¼ˆw/o Point Placementï¼‰**ï¼š
  - ååä¸‹é™ 33%â€“52%
  - å³ä¾¿å¯ç”¨å›¾åƒè°ƒåº¦ä¹Ÿæ— æ³•å¼¥è¡¥
- **ç¦ç”¨å›¾åƒè°ƒåº¦ï¼ˆw/o Rendering Placementï¼‰**ï¼š
  - æ€§èƒ½é€€åŒ–è‡³æ¥è¿‘ baseline æ°´å¹³
- âœ… ç»“è®ºï¼š**å¿…é¡»åŒæ—¶ä¼˜åŒ–ç‚¹æ”¾ç½®å’Œå›¾åƒè°ƒåº¦æ‰èƒ½å‘æŒ¥æœ€å¤§æ•ˆç›Š**

#### ï¼ˆ2ï¼‰å…¶ä»–ç»„ä»¶æ¶ˆèï¼ˆTable 4ï¼‰
| ç»„ä»¶ç§»é™¤ | å¹³å‡æ€§èƒ½æŸå¤± |
|---------|-------------|
| å±‚æ¬¡åŒ–åˆ†é…ï¼ˆw/o Hierï¼‰ | 16%â€“35% â†“ |
| å›¾åƒåˆ†å—ï¼ˆw/o Patchï¼‰ | 10%â€“52% â†“ï¼ˆé«˜åˆ†è¾¨ç‡å½±å“æ›´å¤§ï¼‰ |
| è´Ÿè½½å‡è¡¡ï¼ˆw/o Load Balï¼‰ | 1%â€“14% â†“ |

> å³ä½¿å»æ‰ä»»ä¸€ç»„ä»¶ï¼ŒGaian ä¾ç„¶æ˜¾è‘—ä¼˜äº baselineï¼Œè¯´æ˜å…¶æ ¸å¿ƒæ¡†æ¶æœ‰æ•ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **PBDR å­˜åœ¨å¼ºç©ºé—´å±€éƒ¨æ€§**ï¼šç›¸æœºè§†è§’å€¾å‘äºè§‚å¯Ÿå±€éƒ¨åŒºåŸŸå†…çš„ç‚¹ï¼Œè¿™ä¸€ç‰¹æ€§å¯ä»¥è¢«æ˜¾å¼å»ºæ¨¡å¹¶é€šè¿‡å›¾åˆ’åˆ†åŠ ä»¥åˆ©ç”¨ã€‚
2. **é€šä¿¡æ˜¯ä¸»è¦ç“¶é¢ˆ**ï¼šç°æœ‰ç³»ç»Ÿå› éšæœºåˆ†å¸ƒå¯¼è‡´é«˜è¾¾ 85% çš„è®­ç»ƒæ—¶é—´ç”¨äºé€šä¿¡ï¼›Gaian é€šè¿‡å±€éƒ¨æ€§æ„ŸçŸ¥åˆ†é…å°†é€šä¿¡å‡å°‘æœ€å¤š **91%**ã€‚
3. **é€šç”¨æ€§ä¸æ€§èƒ½å¯å…¼å¾—**ï¼šé€šè¿‡æŠ½è±¡ API åˆ†ç¦»ç®—æ³•é€»è¾‘ä¸åˆ†å¸ƒå¼æ‰§è¡Œï¼ŒGaian ä¸ä»…æ”¯æŒå¤šç§ PBDR ç®—æ³•ï¼Œè¿˜èƒ½å®ç°æ¯”ä¸“ç”¨ç³»ç»Ÿæ›´é«˜çš„æ€§èƒ½ã€‚
4. **è¶…å¤§è§„æ¨¡è®­ç»ƒæˆä¸ºå¯èƒ½**ï¼šGaian æˆåŠŸè®­ç»ƒå« **5äº¿ç‚¹** çš„æ¨¡å‹ï¼Œè¾¾åˆ°å½“å‰æœ€ä¼˜é‡å»ºè´¨é‡ï¼ˆPSNR 26.75ï¼‰ï¼Œæ¨åŠ¨äº† large-scale 3D reconstruction çš„è¾¹ç•Œã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ç¦»çº¿å›¾åˆ’åˆ†ä¾èµ–å®Œæ•´æ•°æ®é›†**ï¼šMETIS åˆ’åˆ†éœ€éå†å…¨éƒ¨å›¾åƒæ„å»ºäºŒåˆ†å›¾ï¼Œåœ¨æ•°æ®æµæˆ–å¢é‡å­¦ä¹ åœºæ™¯ä¸­ä¸é€‚ç”¨ã€‚
- **å¯¹æ‹“æ‰‘å¤æ‚çš„è¡—æ™¯æ•ˆæœç•¥å¼±**ï¼šStreet Datasets å› è§†é‡è·¨è¶Šè¿œè¿‘ç‰©ä½“ï¼Œå±€éƒ¨æ€§è¾ƒå·®ï¼ŒGaian çš„å¢ç›Šç›¸å¯¹è¾ƒå°ï¼ˆå¹³å‡ 1.80Ã— vs Aerial çš„ 2.89Ã—ï¼‰ã€‚
- **å®ç°å¤æ‚åº¦è¾ƒé«˜**ï¼šç›¸æ¯”ç®€å•éšæœºåˆ†å¸ƒï¼ŒGaian éœ€è¦é¢å¤–å¼€å‘è°ƒåº¦å™¨ã€å›¾åˆ’åˆ†æ¨¡å—ç­‰ï¼Œå¢åŠ äº†ç³»ç»Ÿå¤æ‚æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ”¯æŒæ›´å¤šæ–°å‹ PBDR ç®—æ³•ï¼ˆå¦‚ Deformable Beta Splattingã€Triangle Mesh Splattingï¼‰
- æ¢ç´¢åœ¨çº¿è‡ªé€‚åº”åˆ’åˆ†æœºåˆ¶ï¼Œåº”å¯¹åŠ¨æ€å˜åŒ–çš„ç‚¹äº‘ç»“æ„
- ç»“åˆç¡¬ä»¶åŠ é€Ÿå™¨ï¼ˆå¦‚ GScore [45]ã€GauSPU [84]ï¼‰è¿›ä¸€æ­¥é‡Šæ”¾æ€§èƒ½æ½œåŠ›
- åº”ç”¨äº real-world autonomous driving simulator å’Œ World Models æ„å»º

---

> âœ… **ä¸€å¥è¯æ€»ç»“**ï¼š  
> Gaian æ˜¯é¦–ä¸ªé€šç”¨ã€é«˜æ•ˆã€å¯æ‰©å±•çš„åˆ†å¸ƒå¼ PBDR è®­ç»ƒç³»ç»Ÿï¼Œé€šè¿‡æ­ç¤ºå¹¶åˆ©ç”¨ PBDR ä¸­çš„å‡ ä½•å¯è§æ€§å±€éƒ¨æ€§ï¼Œå®ç°äº†é«˜è¾¾ **3.71Ã—** çš„è®­ç»ƒåŠ é€Ÿå’Œ **91%** çš„é€šä¿¡å‰Šå‡ï¼Œå¹¶æˆåŠŸè®­ç»ƒäº†è¿„ä»Šæœ€å¤§çš„ **5äº¿ç‚¹äº‘æ¨¡å‹**ï¼Œä¸ºå¤§è§„æ¨¡ 3D é‡å»ºæä¾›äº†åšå®åŸºç¡€è®¾æ–½ã€‚

</details>

---

### 16. [Resilient Packet Forwarding: A Reinforcement Learning Approach to Routing in Gaussian Interconnected Networks with Clustered Faults](https://arxiv.org/abs/2512.20394)

**Authors**: Mohammad Walid Charrwi, Zaid Hussain  
**Category**: cs.DC  
**Published**: 2025-12-24  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.20394v1  

#### Abstract
As Network-on-Chip (NoC) and Wireless Sensor Network architectures continue to scale, the topology of the underlying network becomes a critical factor in performance. Gaussian Interconnected Networks based on the arithmetic of Gaussian integers, offer attractive properties regarding diameter and sym...

---

### 17. [Learning to Design City-scale Transit Routes](https://arxiv.org/abs/2512.19767)

**Authors**: Bibek Poudel, Weizi Li  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.19767v1  

#### Abstract
Designing efficient transit route networks is an NP-hard problem with exponentially large solution spaces that traditionally relies on manual planning processes. We present an end-to-end reinforcement learning (RL) framework based on graph attention networks for sequential transit network constructi...

---

### 18. [Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches](https://arxiv.org/abs/2512.20082)

**Authors**: Chaithra, Kamesh Kadimisetty, Biju R Mohan  
**Category**: cs.AI  
**Published**: 2025-12-24  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.20082v1  

#### Abstract
Financial sentiment analysis plays a crucial role in informing investment decisions, assessing market risk, and predicting stock price trends. Existing works in financial sentiment analysis have not considered the impact of stock prices or market feedback on sentiment analysis. In this paper, we pro...

---

### 19. [Offline Safe Policy Optimization From Heterogeneous Feedback](https://arxiv.org/abs/2512.20173)

**Authors**: Ze Gong, Pradeep Varakantham, Akshat Kumar  
**Category**: cs.AI  
**Published**: 2025-12-24  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.20173v1  

#### Abstract
Offline Preference-based Reinforcement Learning (PbRL) learns rewards and policies aligned with human preferences without the need for extensive reward engineering and direct interaction with human annotators. However, ensuring safety remains a critical challenge across many domains and tasks. Previ...

---

### 20. [An Adaptive Distributed Stencil Abstraction for GPUs](https://arxiv.org/abs/2512.19851)

**Authors**: Aditya Bhosale, Laxmikant Kale  
**Category**: cs.DC  
**Published**: 2025-12-24  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.19851v1  

#### Abstract
The scientific computing ecosystem in Python is largely confined to single-node parallelism, creating a gap between high-level prototyping in NumPy and high-performance execution on modern supercomputers. The increasing prevalence of hardware accelerators and the need for energy efficiency have made...

---

### 21. [Predictive-LoRA: A Proactive and Fragmentation-Aware Serverless Inference System for LLMs](https://arxiv.org/abs/2512.20210)

**Authors**: Yinan Ni, Xiao Yang, Yuqi Tang, Zhimin Qiu, Chen Wang, Tingzhou Yuan  
**Category**: cs.DC  
**Published**: 2025-12-24  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.20210v1  

#### Abstract
The serverless computing paradigm offers compelling advantages for deploying Large Language Model (LLM) inference services, including elastic scaling and pay-per-use billing. However, serving multiple fine-tuned LLMs via Low-Rank Adaptation (LoRA) in serverless environments faces critical challenges...

---

### 22. [Exploring Deep-to-Shallow Transformable Neural Networks for Intelligent Embedded Systems](https://arxiv.org/abs/2512.19731)

**Authors**: Xiangzhong Luo, Weichen Liu  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.19731v1  

#### Abstract
Thanks to the evolving network depth, convolutional neural networks (CNNs) have achieved remarkable success across various embedded scenarios, paving the way for ubiquitous embedded intelligence. Despite its promise, the evolving network depth comes at the cost of degraded hardware efficiency. In co...

---

### 23. [Field-Space Attention for Structure-Preserving Earth System Transformers](https://arxiv.org/abs/2512.20350)

**Authors**: Maximilian Witte, Johannes Meuer, \'Etienne Pl\'esiat, Christopher Kadow  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.20350v1  

#### Abstract
Accurate and physically consistent modeling of Earth system dynamics requires machine-learning architectures that operate directly on continuous geophysical fields and preserve their underlying geometric structure. Here we introduce Field-Space attention, a mechanism for Earth system Transformers th...

---

### 24. [Population Protocols Revisited: Parity and Beyond](https://arxiv.org/abs/2512.20163)

**Authors**: Leszek G\k{a}sieniec, Tytus Grodzicki, Tomasz Jurdzi\'nski, Jakub Kowalski, Grzegorz Stachowiak  
**Category**: cs.DC  
**Published**: 2025-12-24  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.20163v1  

#### Abstract
For nearly two decades, population protocols have been extensively studied, yielding efficient solutions for central problems in distributed computing, including leader election, and majority computation, a predicate type in Presburger Arithmetic closely tied to population protocols. Surprisingly, n...

---

### 25. [Mixture-of-Experts with Gradient Conflict-Driven Subspace Topology Pruning for Emergent Modularity](https://arxiv.org/abs/2512.20291)

**Authors**: Yuxing Gan, Ziyu Lei  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.20291v1  

#### Abstract
Mixture-of-Experts (MoE) architectures achieve parameter efficiency through conditional computation, yet contemporary designs suffer from two fundamental limitations: structural parameter isolation that causes catastrophic forgetting, and instruction-overfitting that degrades performance in instruct...

---

### 26. [Explainable time-series forecasting with sampling-free SHAP for Transformers](https://arxiv.org/abs/2512.20514)

**Authors**: Matthias Hertel, Sebastian P\"utz, Ralf Mikut, Veit Hagenmeyer, Benjamin Sch\"afer  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.20514v1  

#### Abstract
Time-series forecasts are essential for planning and decision-making in many domains. Explainability is key to building user trust and meeting transparency requirements. Shapley Additive Explanations (SHAP) is a popular explainable AI framework, but it lacks efficient implementations for time series...

---

### 27. [A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution](https://arxiv.org/abs/2512.19882)

**Authors**: Mahdi Mostajabdaveh, F. Sibel Salman, Walter J. Gutjahr  
**Category**: cs.AI  
**Published**: 2025-12-24  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.19882v1  

#### Abstract
The distribution of relief supplies to shelters is a critical aspect of post-disaster humanitarian logistics. In major disasters, prepositioned supplies often fall short of meeting all demands. We address the problem of planning vehicle routes from a distribution center to shelters while allocating ...

---

### 28. [Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection](https://arxiv.org/abs/2512.20140)

**Authors**: Xingyou Yin, Ceyao Zhang, Min Hu, Kai Chen  
**Category**: cs.AI  
**Published**: 2025-12-24  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.20140v1  

#### Abstract
Large Language Models (LLMs) have demonstrated effectiveness as zero-shot time series (TS) forecasters. The key challenge lies in tokenizing TS data into textual representations that align with LLMs' pre-trained knowledge. While existing work often relies on fine-tuning specialized modules to bridge...

---

### 29. [Spatio-Temporal Graph Neural Networks for Dairy Farm Sustainability Forecasting and Counterfactual Policy Analysis](https://arxiv.org/abs/2512.19970)

**Authors**: Surya Jayakumar, Kieran Sullivan, John McLaughlin, Christine O'Meara, Indrakshi Dey  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.19970v1  

#### Abstract
This study introduces a novel data-driven framework and the first-ever county-scale application of Spatio-Temporal Graph Neural Networks (STGNN) to forecast composite sustainability indices from herd-level operational records. The methodology employs a novel, end-to-end pipeline utilizing a Variatio...

---

### 30. [LoFT-LLM: Low-Frequency Time-Series Forecasting with Large Language Models](https://arxiv.org/abs/2512.20002)

**Authors**: Jiacheng You, Jingcheng Yang, Yuhang Xie, Zhongxuan Wu, Xiucheng Li, Feng Li, Pengjie Wang, Jian Xu, Bo Zheng, Xinyang Chen  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.20002v1  

#### Abstract
Time-series forecasting in real-world applications such as finance and energy often faces challenges due to limited training data and complex, noisy temporal dynamics. Existing deep forecasting models typically supervise predictions using full-length temporal windows, which include substantial high-...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
