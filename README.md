# arXiv Papers Bot ü§ñ

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## üìä Statistics

- **Last Updated**: 2025-11-12 07:06:15 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## üìö Recent Papers

### 1. [From Attention to Disaggregation: Tracing the Evolution of LLM Inference](https://arxiv.org/abs/2511.07422)

**Authors**: Madabattula Rajesh Kumar, Srinivasa Rao Aravilli, Mustafa Saify, Shashank Srivastava  
**Category**: cs.DC  
**Published**: 2025-11-12  
**Score**: 12.5  
**Type**: new  
**ArXiv ID**: 2511.07422v1  

The evolution of Large Language Models from the Transformer architecture to models with trillions of parameters has shifted the primary bottleneck from model training to real time inference. Deploying these massive models is a complex distributed systems challenge constrained by memory bandwidth, co...

---

### 2. [Tool-Aided Evolutionary LLM for Generative Policy Toward Efficient Resource Management in Wireless Federated Learning](https://arxiv.org/abs/2505.11570)

**Authors**: Chongyang Tan, Ruoqi Wen, Rongpeng Li, Zhifeng Zhao, Ekram Hossain, Honggang Zhang  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 11.0  
**Type**: replace-cross  
**ArXiv ID**: 2505.11570v2  

Federated Learning (FL) enables distributed model training across edge devices in a privacy-friendly manner. However, its efficiency heavily depends on effective device selection and high-dimensional resource allocation in dynamic and heterogeneous wireless environments. Conventional methods demand ...

---

### 3. [Motif 2 12.7B technical report](https://arxiv.org/abs/2511.07464)

**Authors**: Junghwan Lim, Sungmin Lee, Dongseok Kim, Taehyun Kim, Eunhwan Park, Jeesoo Lee, Jeongdoo Lee, Junhyeok Lee, Wai Ting Cheung, Dahye Choi, Jaeheui Her, Jaeyeon Huh, Hanbin Jung, Changjin Kang, Beomgyu Kim, Minjae Kim, Taewhan Kim, Youngrok Kim, Hyukjin Kweon, Haesol Lee, Kungyu Lee, Dongpin Oh, Yeongjae Park, Bokki Ryu, Dongjoo Weon  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 10.0  
**Type**: cross  
**ArXiv ID**: 2511.07464v1  

We introduce Motif-2-12.7B, a new open-weight foundation model that pushes the efficiency frontier of large language models by combining architectural innovation with system-level optimization. Designed for scalable language understanding and robust instruction generalization under constrained compu...

---

### 4. [Synera: Synergistic LLM Serving across Device and Cloud at Scale](https://arxiv.org/abs/2511.07423)

**Authors**: Genglin Wang, Liekang Zeng, Bufang Yang, Kaiwei Liu, Guoliang Xing, Chumin Sun, Li Zhou, Jie Sun, Zhenyu Yan  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 9.5  
**Type**: cross  
**ArXiv ID**: 2511.07423v1  

Large Language Models (LLMs) are becoming key components in various mobile operating systems, driving smart applications like interactive chatbots and personal assistants. While bringing enhanced intelligence to mobile ends, their deployment suffers from a set of performance challenges, especially t...

---

### 5. [ElasticMM: Efficient Multimodal LLMs Serving with Elastic Multimodal Parallelism](https://arxiv.org/abs/2507.10069)

**Authors**: Zedong Liu, Shenggan Cheng, Guangming Tan, Yang You, Dingwen Tao  
**Category**: cs.DC  
**Published**: 2025-11-12  
**Score**: 9.5  
**Type**: replace  
**ArXiv ID**: 2507.10069v3  

Multimodal large language models (MLLMs) extend LLMs to handle images, videos, and audio by incorporating feature extractors and projection modules. However, these additional components -- combined with complex inference pipelines and heterogeneous workloads -- introduce significant inference overhe...

---

### 6. [Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views](https://arxiv.org/abs/2511.07813)

**Authors**: Haida Feng, Hao Wei, Zewen Xu, Haolin Wang, Chade Li, Yihong Wu  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 9.0  
**Type**: cross  
**ArXiv ID**: 2511.07813v1  

Recently, large language models (LLMs) have been explored widely for 3D scene understanding. Among them, training-free approaches are gaining attention for their flexibility and generalization over training-based methods. However, they typically struggle with accuracy and efficiency in practical dep...

---

### 7. [MA-GTS: A Multi-Agent Framework for Solving Complex Graph Problems in Real-World Applications](https://arxiv.org/abs/2502.18540)

**Authors**: Zike Yuan, Ming Liu, Hui Wang, Bing Qin  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 9.0  
**Type**: replace-cross  
**ArXiv ID**: 2502.18540v2  

Graph-theoretic problems arise in real-world applications like logistics, communication networks, and traffic optimization. These problems are often complex, noisy, and irregular, posing challenges for traditional algorithms. Large language models (LLMs) offer potential solutions but face challenges...

---

### 8. [FedSEA-LLaMA: A Secure, Efficient and Adaptive Federated Splitting Framework for Large Language Models](https://arxiv.org/abs/2505.15683)

**Authors**: Zishuai Zhang, Hainan zhang, Weihua Li, Qinnan zhang, jin Dong, Yongxin Tong, Zhiming Zheng  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 9.0  
**Type**: replace-cross  
**ArXiv ID**: 2505.15683v3  

Private data holds promise for improving LLMs due to its high quality, but its scattered distribution across data silos and the high computational demands of LLMs limit their deployment in federated environments. To address this, the transformer-based federated split models are proposed, which offlo...

---

### 9. [FractalCloud: A Fractal-Inspired Architecture for Efficient Large-Scale Point Cloud Processing](https://arxiv.org/abs/2511.07665)

**Authors**: Yuzhe Fu, Changchun Zhou, Hancheng Ye, Bowen Duan, Qiyu Huang, Chiyue Wei, Cong Guo, Hai "Helen'' Li, Yiran Chen  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 8.5  
**Type**: cross  
**ArXiv ID**: 2511.07665v1  

Three-dimensional (3D) point clouds are increasingly used in applications such as autonomous driving, robotics, and virtual reality (VR). Point-based neural networks (PNNs) have demonstrated strong performance in point cloud analysis, originally targeting small-scale inputs. However, as PNNs evolve ...

---

### 10. [A Remarkably Efficient Paradigm to Multimodal Large Language Models for Sequential Recommendation](https://arxiv.org/abs/2511.05885)

**Authors**: Qiyong Zhong, Jiajie Su, Ming Yang, Yunshan Ma, Xiaolin Zheng, Chaochao Chen  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 8.5  
**Type**: replace-cross  
**ArXiv ID**: 2511.05885v2  

Sequential recommendations (SR) predict users' future interactions based on their historical behavior. The rise of Large Language Models (LLMs) has brought powerful generative and reasoning capabilities, significantly enhancing SR performance, while Multimodal LLMs (MLLMs) further extend this by int...

---

### 11. [Network and Systems Performance Characterization of MCP-Enabled LLM Agents](https://arxiv.org/abs/2511.07426)

**Authors**: Zihao Ding, Mufeng Zhu, Yao Liu  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 8.0  
**Type**: cross  
**ArXiv ID**: 2511.07426v1  

Model Context Protocol (MCP) has recently gained increased attention within the AI community for providing a standardized way for large language models (LLMs) to interact with external tools and services, significantly enhancing their capabilities. However, the inclusion of extensive contextual info...

---

### 12. [How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference](https://arxiv.org/abs/2505.09598)

**Authors**: Nidhal Jegham, Marwan Abdelatti, Chan Young Koh, Lassad Elmoubarki, Abdeltawab Hendawi  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 8.0  
**Type**: replace-cross  
**ArXiv ID**: 2505.09598v5  

This paper introduces an infrastructure-aware benchmarking framework for quantifying the environmental footprint of LLM inference across 30 state-of-the-art models in commercial datacenters. The framework combines public API performance data with company-specific environmental multipliers and statis...

---

### 13. [RSVG-ZeroOV: Exploring a Training-Free Framework for Zero-Shot Open-Vocabulary Visual Grounding in Remote Sensing Images](https://arxiv.org/abs/2509.18711)

**Authors**: Ke Li, Di Wang, Ting Wang, Fuyu Dong, Yiming Zhang, Luyao Zhang, Xiangyu Wang, Shaofeng Li, Quan Wang  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 8.0  
**Type**: replace-cross  
**ArXiv ID**: 2509.18711v2  

Remote sensing visual grounding (RSVG) aims to localize objects in remote sensing images based on free-form natural language expressions. Existing approaches are typically constrained to closed-set vocabularies, limiting their applicability in open-world scenarios. While recent attempts to leverage ...

---

### 14. [TeleRAG: Efficient Retrieval-Augmented Generation Inference with Lookahead Retrieval](https://arxiv.org/abs/2502.20969)

**Authors**: Chien-Yu Lin, Keisuke Kamahori, Yiyu Liu, Xiaoxiang Shi, Madhav Kashyap, Yile Gu, Rulin Shao, Zihao Ye, Kan Zhu, Rohan Kadekodi, Stephanie Wang, Arvind Krishnamurthy, Luis Ceze, Baris Kasikci  
**Category**: cs.DC  
**Published**: 2025-11-12  
**Score**: 8.0  
**Type**: replace  
**ArXiv ID**: 2502.20969v3  

Retrieval-augmented generation (RAG) extends large language models (LLMs) with external data sources to enhance factual correctness and domain coverage. Modern RAG pipelines rely on large datastores, creating a significant system challenge: achieving high throughput and low latency is difficult, esp...

---

### 15. [ARAC: Adaptive Regularized Multi-Agent Soft Actor-Critic in Graph-Structured Adversarial Games](https://arxiv.org/abs/2511.08412)

**Authors**: Ruochuan Shi, Runyu Lu, Yuanheng Zhu, Dongbin Zhao  
**Category**: cs.LG  
**Published**: 2025-11-12  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2511.08412v1  

In graph-structured multi-agent reinforcement learning (MARL) adversarial tasks such as pursuit and confrontation, agents must coordinate under highly dynamic interactions, where sparse rewards hinder efficient policy learning. We propose Adaptive Regularized Multi-Agent Soft Actor-Critic (ARAC), wh...

---

### 16. [CATransformers: Carbon Aware Transformers Through Joint Model-Hardware Optimization](https://arxiv.org/abs/2505.01386)

**Authors**: Irene Wang, Newsha Ardalani, Mostafa Elhoushi, Daniel Jiang, Samuel Hsia, Ekin Sumbul, Divya Mahajan, Carole-Jean Wu, Bilge Acun  
**Category**: cs.LG  
**Published**: 2025-11-12  
**Score**: 8.0  
**Type**: replace  
**ArXiv ID**: 2505.01386v4  

Machine learning solutions are rapidly adopted to enable a variety of key use cases, from conversational AI assistants to scientific discovery. This growing adoption is expected to increase the associated lifecycle carbon footprint, including both \emph{operational carbon} from training and inferenc...

---

### 17. [Global Optimization on Graph-Structured Data via Gaussian Processes with Spectral Representations](https://arxiv.org/abs/2511.07734)

**Authors**: Shu Hong, Yongsheng Mei, Mahdi Imani, Tian Lan  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 7.5  
**Type**: cross  
**ArXiv ID**: 2511.07734v1  

Bayesian optimization (BO) is a powerful framework for optimizing expensive black-box objectives, yet extending it to graph-structured domains remains challenging due to the discrete and combinatorial nature of graphs. Existing approaches often rely on either full graph topology-impractical for larg...

---

### 18. [OTSNet: A Neurocognitive-Inspired Observation-Thinking-Spelling Pipeline for Scene Text Recognition](https://arxiv.org/abs/2511.08133)

**Authors**: Lixu Sun, Nurmemet Yolwas, Wushour Silamu  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 7.5  
**Type**: cross  
**ArXiv ID**: 2511.08133v1  

Scene Text Recognition (STR) remains challenging due to real-world complexities, where decoupled visual-linguistic optimization in existing frameworks amplifies error propagation through cross-modal misalignment. Visual encoders exhibit attention bias toward background distractors, while decoders su...

---

### 19. [Dual-Kernel Graph Community Contrastive Learning](https://arxiv.org/abs/2511.08287)

**Authors**: Xiang Chen, Kun Yue, Wenjie Liu, Zhenyu Zhang, Liang Duan  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 7.5  
**Type**: cross  
**ArXiv ID**: 2511.08287v1  

Graph Contrastive Learning (GCL) has emerged as a powerful paradigm for training Graph Neural Networks (GNNs) in the absence of task-specific labels. However, its scalability on large-scale graphs is hindered by the intensive message passing mechanism of GNN and the quadratic computational complexit...

---

### 20. [Glia: A Human-Inspired AI for Automated Systems Design and Optimization](https://arxiv.org/abs/2510.27176)

**Authors**: Pouya Hamadanian, Pantea Karimi, Arash Nasr-Esfahany, Kimia Noorbakhsh, Joseph Chandler, Ali ParandehGheibi, Mohammad Alizadeh, Hari Balakrishnan  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 7.5  
**Type**: replace  
**ArXiv ID**: 2510.27176v2  

Can an AI autonomously design mechanisms for computer systems on par with the creativity and reasoning of human experts? We present Glia, an AI architecture for networked systems design that uses large language models (LLMs) in a human-inspired, multi-agent workflow. Each agent specializes in reason...

---

### 21. [GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding](https://arxiv.org/abs/2511.00810)

**Authors**: Shijie Zhou, Viet Dac Lai, Hao Tan, Jihyung Kil, Wanrong Zhu, Changyou Chen, Ruiyi Zhang  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 7.5  
**Type**: replace-cross  
**ArXiv ID**: 2511.00810v2  

Graphical user interface (GUI) grounding is a key function of computer-use agents, which maps natural-language instructions to actionable screen regions. Existing approaches based on Multimodal Large Language Models (MLLMs) typically formulate it as a text-based coordinate generation task, yet direc...

---

### 22. [REIS: A High-Performance and Energy-Efficient Retrieval System with In-Storage Processing](https://arxiv.org/abs/2506.16444)

**Authors**: Kangqi Chen, Andreas Kosmas Kakolyris, Rakesh Nadig, Manos Frouzakis, Nika Mansouri Ghiasi, Yu Liang, Haiyu Mao, Jisung Park, Mohammad Sadrosadati, Onur Mutlu  
**Category**: cs.CL  
**Published**: 2025-11-12  
**Score**: 7.5  
**Type**: replace  
**ArXiv ID**: 2506.16444v2  

Large Language Models (LLMs) face an inherent challenge: their knowledge is confined to the data that they have been trained on. To overcome this issue, Retrieval-Augmented Generation (RAG) complements the static training-derived knowledge of LLMs with an external knowledge repository. RAG consists ...

---

### 23. [Resource Allocation in Hybrid Radio-Optical IoT Networks using GNN with Multi-task Learning](https://arxiv.org/abs/2511.07428)

**Authors**: Aymen Hamrouni, Sofie Pollin, Hazem Sallouha  
**Category**: cs.LG  
**Published**: 2025-11-12  
**Score**: 7.5  
**Type**: cross  
**ArXiv ID**: 2511.07428v1  

This paper addresses the problem of dual-technology scheduling in hybrid Internet of Things (IoT) networks that integrate Optical Wireless Communication (OWC) alongside Radio Frequency (RF). We begin by formulating a Mixed-Integer Nonlinear Programming (MINLP) model that jointly considers throughput...

---

### 24. [BDD2Seq: Enabling Scalable Reversible-Circuit Synthesis via Graph-to-Sequence Learning](https://arxiv.org/abs/2511.08315)

**Authors**: Mingkai Miao, Jianheng Tang, Guangyu Hu, Hongce Zhang  
**Category**: cs.LG  
**Published**: 2025-11-12  
**Score**: 7.5  
**Type**: cross  
**ArXiv ID**: 2511.08315v1  

Binary Decision Diagrams (BDDs) are instrumental in many electronic design automation (EDA) tasks thanks to their compact representation of Boolean functions. In BDD-based reversible-circuit synthesis, which is critical for quantum computing, the chosen variable ordering governs the number of BDD no...

---

### 25. [SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment](https://arxiv.org/abs/2511.08583)

**Authors**: Rong Xue, Jiageng Mao, Mingtong Zhang, Yue Wang  
**Category**: cs.LG  
**Published**: 2025-11-12  
**Score**: 7.5  
**Type**: cross  
**ArXiv ID**: 2511.08583v1  

Developing efficient and accurate visuomotor policies poses a central challenge in robotic imitation learning. While recent rectified flow approaches have advanced visuomotor policy learning, they suffer from a key limitation: After iterative distillation, generated actions may deviate from the grou...

---

### 26. [Alignment-Aware Quantization for LLM Safety](https://arxiv.org/abs/2511.07842)

**Authors**: Sunghyun Wee, Suyoung Kim, Hyeonjin Kim, Kyomin Hwang, Nojun Kwak  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2511.07842v1  

Safety and efficiency are both important factors when deploying large language models(LLMs). LLMs are trained to follow human alignment for safety, and post training quantization(PTQ) is applied afterward for efficiency. However, these two objectives are often in conflict, revealing a fundamental fl...

---

### 27. [Benchmarking Multi-Step Legal Reasoning and Analyzing Chain-of-Thought Effects in Large Language Models](https://arxiv.org/abs/2511.07979)

**Authors**: Wenhan Yu, Xinbo Lin, Lanxin Ni, Jinhua Cheng, Lei Sha  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2511.07979v1  

Large language models (LLMs) have demonstrated strong reasoning abilities across specialized domains, motivating research into their application to legal reasoning. However, existing legal benchmarks often conflate factual recall with genuine inference, fragment the reasoning process, and overlook t...

---

### 28. [Two Heads are Better than One: Distilling Large Language Model Features Into Small Models with Feature Decomposition and Mixture](https://arxiv.org/abs/2511.07110)

**Authors**: Tianhao Fu, Xinxin Xu, Weichen Xu, Jue Chen, Ruilong Ren, Bowen Deng, Xinyu Zhao, Jian Cao, Xixin Cao  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 7.0  
**Type**: replace  
**ArXiv ID**: 2511.07110v2  

Market making (MM) through Reinforcement Learning (RL) has attracted significant attention in financial trading. With the development of Large Language Models (LLMs), more and more attempts are being made to apply LLMs to financial areas. A simple, direct application of LLM as an agent shows signifi...

---

### 29. [A Unified and Fast-Sampling Diffusion Bridge Framework via Stochastic Optimal Control](https://arxiv.org/abs/2505.21528)

**Authors**: Mokai Pan, Kaizhen Zhu, Yuexin Ma, Yanwei Fu, Jingyi Yu, Jingya Wang, Ye Shi  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 7.0  
**Type**: replace-cross  
**ArXiv ID**: 2505.21528v2  

Recent advances in diffusion bridge models leverage Doob's $h$-transform to establish fixed endpoints between distributions, demonstrating promising results in image translation and restoration tasks. However, these approaches often produce blurred or excessively smoothed image details and lack a co...

---

### 30. [Federated Learning with Gramian Angular Fields for Privacy-Preserving ECG Classification on Heterogeneous IoT Devices](https://arxiv.org/abs/2511.03753)

**Authors**: Youssef Elmir, Yassine Himeur, Abbes Amira  
**Category**: cs.AI  
**Published**: 2025-11-12  
**Score**: 7.0  
**Type**: replace-cross  
**ArXiv ID**: 2511.03753v2  

This study presents a federated learning (FL) framework for privacy-preserving electrocardiogram (ECG) classification in Internet of Things (IoT) healthcare environments. By transforming 1D ECG signals into 2D Gramian Angular Field (GAF) images, the proposed approach enables efficient feature extrac...

---

## üîß Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## üìÖ Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## üöÄ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## üìù Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## üîç Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
