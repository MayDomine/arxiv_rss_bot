# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-20 06:36:50 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Mobility-Aware Cache Framework for Scalable LLM-Based Human Mobility Simulation](https://arxiv.org/abs/2602.16727)

**Authors**: Hua Yan, Heng Tan, Yingxue Zhang, Yu Yang  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.16727v1  

#### Abstract
Large-scale human mobility simulation is critical for applications such as urban planning, epidemiology, and transportation analysis. Recent works treat large language models (LLMs) as human agents to simulate realistic mobility behaviors using structured reasoning, but their high computational cost...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šMobility-Aware Cache Framework for Scalable LLM-Based Human Mobility Simulation**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å¤§è§„æ¨¡åŸºäº **LLM** çš„äººç±»ç§»åŠ¨æ€§æ¨¡æ‹Ÿåœ¨åŸå¸‚è§„åˆ’ã€æµè¡Œç—…å­¦å’Œäº¤é€šåˆ†æç­‰é¢†åŸŸå…·æœ‰é‡è¦æ„ä¹‰ã€‚ç„¶è€Œï¼Œç›´æ¥è°ƒç”¨ LLM è¿›è¡Œé€äººé€æ­¥æ¨ç†ä¼šå¯¼è‡´æé«˜çš„è®¡ç®—æˆæœ¬å’Œ API è´¹ç”¨ï¼ˆä¾‹å¦‚ï¼Œæ¨¡æ‹Ÿç™¾ä¸‡äººä¸€å¤©å¯èƒ½è¶…è¿‡ \$1,000ï¼‰ã€‚ç°æœ‰ä¼˜åŒ–æ–¹æ³•å­˜åœ¨ä»¥ä¸‹ç¼ºé™·ï¼š
- **Group-based æ–¹æ³•**ï¼ˆå¦‚ LLM-archetypesï¼‰é€šè¿‡å…±äº«ç¾¤ä½“è¡Œä¸ºå‡å°‘è°ƒç”¨æ¬¡æ•°ï¼Œä½†ç‰ºç‰²äº†ä¸ªä½“å¤šæ ·æ€§ã€‚
- **å“åº”ç¼“å­˜ï¼ˆresponse cachingï¼‰** å¯é‡ç”¨è¾“å‡ºï¼Œä½†å¯¼è‡´é‡å¤è¡Œä¸ºï¼Œé™ä½ä»¿çœŸçœŸå®æ€§ã€‚

æ­¤å¤–ï¼Œç›´æ¥åœ¨è‡ªç„¶è¯­è¨€ç©ºé—´ä¸­é‡ç»„æ¨ç†é“¾å¯èƒ½å¯¼è‡´é€»è¾‘ä¸ä¸€è‡´ï¼ˆå¦‚æ—¶é—´å†²çªã€ç©ºé—´ä¸åˆç†ï¼‰ï¼Œå½±å“ä»¿çœŸè´¨é‡ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡º **MobCache** â€”â€” ä¸€ç§é¢å‘å¯æ‰©å±• LLM ç§»åŠ¨æ€§ä»¿çœŸçš„ **mobility-aware cache framework**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯æ„å»º **reconstructible cachesï¼ˆå¯é‡æ„ç¼“å­˜ï¼‰**ï¼Œå³ï¼š
- ä¸ç¼“å­˜æœ€ç»ˆè‡ªç„¶è¯­è¨€è¾“å‡ºï¼Œè€Œæ˜¯ç¼“å­˜ LLM åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­äº§ç”Ÿçš„ **latent-space reasoning embeddingsï¼ˆæ½œåœ¨ç©ºé—´æ¨ç†åµŒå…¥ï¼‰**ã€‚
- æ”¯æŒå¯¹è¿™äº›åµŒå…¥è¿›è¡Œçµæ´»çš„æ ‘çŠ¶æœç´¢ä¸é‡ç»„ï¼Œå½¢æˆæ–°çš„æ¨ç†è·¯å¾„ã€‚
- å¼•å…¥è½»é‡åŒ–è§£ç å™¨å°†æ½œåœ¨æ¨ç†é“¾é«˜æ•ˆè¿˜åŸä¸ºè‡ªç„¶è¯­è¨€æ´»åŠ¨åºåˆ—ã€‚

#### **ä¸¤å¤§æ ¸å¿ƒç»„ä»¶**
1. **Reconstructible Cacheï¼ˆå¯é‡æ„ç¼“å­˜ï¼‰**
   - å­˜å‚¨ fine-tuned LLM è¾“å‡ºçš„ latent-space reasoning chainsã€‚
   - æ”¯æŒæ ‘å½¢ç»“æ„æ£€ç´¢ä¸åˆ†æ”¯æ¢ç´¢ï¼Œå®ç°æ¨ç†æ­¥éª¤çš„å¤ç”¨ä¸ç»„åˆã€‚
   - è®¾è®¡ **latent-space evaluator** åˆ¤æ–­æ½œåœ¨åµŒå…¥è¿æ¥çš„åˆç†æ€§ï¼Œç¡®ä¿é€»è¾‘ä¸€è‡´æ€§ã€‚

2. **Lightweight Decoderï¼ˆè½»é‡åŒ–è§£ç å™¨ï¼‰**
   - é€šè¿‡ **mobility law-constrained distillation** è®­ç»ƒå°å‹æ¨¡å‹ï¼ˆå¦‚ LLaMA-1Bï¼‰æ›¿ä»£åŸå§‹å¤§æ¨¡å‹è§£ç ã€‚
   - æ˜¾è‘—é™ä½æ¨ç†å»¶è¿Ÿä¸æˆæœ¬ï¼ŒåŒæ—¶ä¿æŒè¾“å‡ºçš„ç©ºé—´-æ—¶é—´ä¸€è‡´æ€§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | å¤§å¹…å‡å°‘ LLM è°ƒç”¨æ¬¡æ•°ï¼Œæå‡ååé‡ï¼Œé™ä½æˆæœ¬ï¼ˆæœ€é«˜è¾¾ 93% æˆæœ¬ä¸‹é™ï¼‰ã€‚ |
| **å¤šæ ·æ€§** | é€šè¿‡æ½œåœ¨ç©ºé—´ä¸­çš„è·¯å¾„é‡ç»„æ”¯æŒä¸ªæ€§åŒ–è¡Œä¸ºç”Ÿæˆï¼Œé¿å…â€œåƒäººä¸€é¢â€ã€‚ |
| **ä¿çœŸåº¦** | å¼•å…¥ mobility laws çº¦æŸè®­ç»ƒï¼Œä¿éšœç”Ÿæˆè½¨è¿¹ç¬¦åˆçœŸå®ç§»åŠ¨è§„å¾‹ï¼ˆå¦‚è·³è·åˆ†å¸ƒã€åœç•™æ—¶é•¿ç­‰ï¼‰ã€‚ |
| **é€šç”¨æ€§** | å¯ä½œä¸ºæ’ä»¶åŠ é€Ÿå…¶ä»– LLM-based mobility simulatorsï¼ˆå¦‚ Urban-Mobility-LLMï¼‰ã€‚ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
1. **Beijing Dataset**
   - æ—¶é—´èŒƒå›´ï¼š2019å¹´10æœˆ1æ—¥ â€“ 12æœˆ31æ—¥
   - å†…å®¹ï¼šç”¨æˆ·ç§»åŠ¨è½¨è¿¹ + ç”¨æˆ·ç”»åƒï¼ˆå¹´é¾„ã€æ€§åˆ«ã€èŒä¸šï¼‰
   - æ¥æºï¼šç¤¾äº¤ç½‘ç»œå¹³å°é‡‡é›†
2. **NYC POI Check-in Dataset**
   - åŸºäºç¾å›½äººå£æ™®æŸ¥ï¼ˆU.S. Censusï¼‰æ¨¡æ‹Ÿç”¨æˆ·ç”»åƒ
   - ä½¿ç”¨ POI æ•°æ®ç”Ÿæˆç§»åŠ¨è¡Œä¸º
   - ç”¨äºè·¨åŸæ³›åŒ–å®éªŒ

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **è®­ç»ƒæµç¨‹**
- ä½¿ç”¨ GPT ç”Ÿæˆçº¦ 13,000 æ¡ synthetic mobility trajectoriesï¼ˆå« reasoning chain å’Œ activityï¼‰ã€‚
- Fine-tune LLaMA-3B å®ç° **latent-space reasoning**ï¼Œè¾“å‡ºæ¯ä¸€æ­¥çš„ embeddingã€‚
- æ„å»º reconstructible cache å¹¶è®­ç»ƒ lightweight decoderï¼ˆLLaMA-1Bï¼‰ã€‚

#### **æ¨ç†ç­–ç•¥**
- å¯¹æ–°ç”¨æˆ·ï¼Œåœ¨ cache ä¸­æŸ¥æ‰¾ç›¸ä¼¼ profile ç”¨æˆ·ã€‚
- ä¸‰ç§æœç´¢ç­–ç•¥ï¼š
  1. **Follow existing chains**ï¼šæ²¿ç”¨å·²æœ‰è·¯å¾„
  2. **Explore alternative chains**ï¼šä»æŸèŠ‚ç‚¹åˆ†å‰ï¼Œå¯»æ‰¾é«˜è¯„åˆ†å€™é€‰ embedding
  3. **Generate new chains**ï¼šè‹¥æ— åˆé€‚åˆ†æ”¯ï¼Œåˆ™è°ƒç”¨ LLM é‡æ–°ç”Ÿæˆå¹¶ç¼“å­˜

#### **è¯„ä¼°æŒ‡æ ‡**

| ç±»åˆ« | æŒ‡æ ‡ | æè¿° |
|------|------|------|
| **Efficiency** | Inference time â†“<br>Tokens/s â†‘<br>Throughput â†‘<br>Cost â†“ | å•æ¡è½¨è¿¹å¹³å‡è€—æ—¶ã€æ¯ç§’å¤„ç† token æ•°ã€æ‰¹é‡ååé‡ã€å•ä½è½¨è¿¹è´¹ç”¨ |
| **Quality** | Radius of gyration JSD â†“<br>Stay duration JSD â†“<br>Jump length JSD â†“<br>LocFreq JSD â†“<br>OdSim JSD â†“ | ä½¿ç”¨ Jensen-Shannon Divergence è¡¡é‡ç”Ÿæˆè½¨è¿¹ä¸çœŸå®æ•°æ®åœ¨äº”ä¸ªå…³é”®ç§»åŠ¨ç‰¹å¾ä¸Šçš„åˆ†å¸ƒå·®å¼‚ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
#### **æ— éœ€çœŸå®æ•°æ®è®­ç»ƒçš„æ–¹æ³•**
- **CoPB**ï¼šåŸºäº structured reasoning çš„ few-shot mobility generation
- **Urban-Mobility-LLM**ï¼šåˆ©ç”¨ LLM åˆæˆå‡ºè¡Œè°ƒæŸ¥æ•°æ®
- **LLMob**ï¼šç»“åˆ self-consistency ä¸ retrieval çš„ agent æ¡†æ¶

#### **éœ€è¦çœŸå®æ•°æ®è®­ç»ƒçš„æ–¹æ³•**
- **Geo-LLaMA**ï¼šåœ¨çœŸå®è½¨è¿¹ä¸Šå¾®è°ƒ LLMï¼Œæ»¡è¶³æ—¶ç©ºè®¿é—®çº¦æŸ

#### **æ¶ˆèå˜ä½“**
- **MobCache w/o LE**ï¼šç§»é™¤ latent-space evaluatorï¼Œä»…ç”¨ embedding ç›¸ä¼¼åº¦é€‰æ‹©åˆ†æ”¯
- **MobCache w/o MD**ï¼šç§»é™¤ mobility law distillation çº¦æŸ
- **MobCache w/o LD**ï¼šä¸ä½¿ç”¨è½»é‡åŒ–è§£ç å™¨ï¼Œä»ç”±åŸ LLM è§£ç 

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆBeijing æ•°æ®é›†ï¼‰**

| æ–¹æ³• | Inference Time â†“ (s) | Tokens/s â†‘ | Throughput â†‘ (traj/s) | Cost â†“ (\$Ã—10â»Â³) |
|------|------------------------|------------|--------------------------|------------------|
| CoPB | 69.1675 | 25.7023 | 0.1005 | 1.7776 |
| Urban-Mobility-LLM | 8.0800 | 67.3117 | 0.9010 | 0.5439 |
| Geo-LLaMA | 2.3410 | 25.8006 | 1.2701 | 0.0325 |
| LLMob | 24.3361 | 65.2083 | 0.2997 | 1.5652 |
| **MobCache** | **1.3530** | **121.7636** | **1.6329** | **0.0187** |

> âœ… **ç›¸æ¯”æœ€ä¼˜ baselineï¼ˆGeo-LLaMAï¼‰ï¼š**
- æ¨ç†æ—¶é—´ â†“ **42.20%**
- Tokens/s â†‘ **80.89%**
- ååé‡ â†‘ **28.56%**
- æˆæœ¬ â†“ **42.46%**

---

### **ä»¿çœŸè´¨é‡è¡¨ç°ï¼ˆJSD è¶Šä½è¶Šå¥½ï¼‰**

| æ–¹æ³• | Radius â†“ | Duration â†“ | Jump Length â†“ | LocFreq â†“ | OdSim â†“ |
|------|---------|-----------|---------------|-----------|--------|
| CoPB | 0.0247 | 0.0233 | 0.0250 | 0.1029 | 0.2628 |
| Urban-Mobility-LLM | 0.0473 | 0.0249 | 0.0192 | 0.0950 | 0.3199 |
| Geo-LLaMA | 0.0216 | 0.0270 | 0.0188 | 0.1198 | 0.2498 |
| **MobCache** | 0.0333 | **0.0191** | 0.0258 | **0.1061** | **0.2215** |

> ğŸ” **ç»“è®ºï¼šMobCache åœ¨å¤šæ•°è´¨é‡æŒ‡æ ‡ä¸Šä¸ SOTA æ–¹æ³•ç›¸å½“ç”šè‡³æ›´ä¼˜**ï¼Œå°¤å…¶åœ¨ OdSim ä¸Šæ˜¾è‘—é¢†å…ˆã€‚

---

### **æ¡ˆä¾‹ç ”ç©¶ï¼šåŠ é€Ÿ Urban-Mobility-LLM**
å°† MobCache åº”ç”¨äº Urban-Mobility-LLM çš„æ¨ç†è¿‡ç¨‹ï¼š

| æŒ‡æ ‡ | åŸå§‹æ–¹æ³• | +MobCache | æå‡å¹…åº¦ |
|------|--------|----------|--------|
| Inference Time | 8.080 s | 2.672 s | â†“ **66.93%** |
| Cost per traj | \$5.44Ã—10â»Â³ | \$3.71Ã—10â»â´ | â†“ **93.18%** |
| è´¨é‡ | - | ä¿æŒç›¸å½“ | âœ… æ— æŸå¤± |

> ğŸ’¡ è¡¨æ˜ MobCache å¯ä½œä¸ºé€šç”¨åŠ é€Ÿæ¨¡å—é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿä¸­ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆBeijing æ•°æ®é›†ï¼‰**

| æ–¹æ³• | Inference Time | Cost | Duration â†“ | LocFreq â†“ | OdSim â†“ |
|------|----------------|------|-----------|-----------|--------|
| w/o LE | 1.3546 | 0.0188 | 0.0203 | 0.1092 | 0.2302 |
| w/o MD | 1.3551 | 0.0188 | 0.0198 | 0.1082 | 0.2286 |
| w/o LD | 2.2450 | 0.0325 | 0.0180 | 0.0955 | 0.2013 |
| **MobCache** | **1.3530** | **0.0187** | **0.0191** | **0.1061** | **0.2215** |

> ğŸ” å‘ç°ï¼š
- ç§»é™¤ **latent-space evaluator** å¯¼è‡´è´¨é‡è½»å¾®ä¸‹é™ â†’ éªŒè¯å…¶å¯¹é€»è¾‘è¿è´¯æ€§çš„å¼•å¯¼ä½œç”¨ã€‚
- ç§»é™¤ **mobility law distillation** åŒæ ·é™ä½ä¿çœŸåº¦ â†’ è¯´æ˜æ˜¾å¼çº¦æŸæœ‰åŠ©äºç»´æŒçœŸå®ç§»åŠ¨æ¨¡å¼ã€‚
- ç§»é™¤ **lightweight decoder** æ•ˆç‡å¤§å¹…ä¸‹é™ â†’ è¯æ˜è½»é‡åŒ–è®¾è®¡å¿…è¦ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **Reconstructible latent-space cache æ˜¯é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆ**
   - ç¼“å­˜ä¸­é—´æ¨ç†åµŒå…¥è€Œéæœ€ç»ˆè¾“å‡ºï¼Œå®ç°äº†é«˜å¤ç”¨æ€§å’Œå¤šæ ·æ€§ã€‚
   - æ”¯æŒè·¨ä¸ªä½“ã€è·¨åœºæ™¯çš„æ¨ç†è·¯å¾„é‡ç»„ï¼Œçªç ´ä¼ ç»Ÿ group-based æ–¹æ³•çš„å¤šæ ·æ€§ç“¶é¢ˆã€‚

2. **Latent-space reasoning + evaluator å¯æœ‰æ•ˆä¿è¯é€»è¾‘ä¸€è‡´æ€§**
   - è‡ªç„¶è¯­è¨€å±‚é¢çš„æ‹¼æ¥æ˜“äº§ç”Ÿè¯­ä¹‰æµç•…ä½†é€»è¾‘é”™è¯¯çš„è¡Œä¸ºï¼ˆå¦‚â€œå‘¨æœ«å»ä¸Šç­è´­ç‰©â€ï¼‰ã€‚
   - åœ¨æ½œåœ¨ç©ºé—´ä¸­é€šè¿‡ evaluator æ‰“åˆ†ç­›é€‰è¿æ¥è·¯å¾„ï¼Œæ˜¾è‘—æå‡è¡Œä¸ºåˆç†æ€§ï¼ˆLLM è¯„æµ‹è®¤å¯ç‡è¾¾ 91% vs 82%ï¼‰ã€‚

3. **Mobility law-constrained distillation æå‡è½»é‡åŒ–è§£ç å™¨ä¿çœŸåº¦**
   - å•çº¯è’¸é¦ä¼šä¸¢å¤±ç©ºé—´-æ—¶é—´ç»Ÿè®¡ç‰¹æ€§ã€‚
   - åŠ å…¥ KL divergence æ­£åˆ™é¡¹ä½¿å­¦ç”Ÿæ¨¡å‹å­¦ä¹ åˆ° teacher çš„ jump distanceã€stay duration åˆ†å¸ƒã€‚

4. **æ¡†æ¶å…·å¤‡è‰¯å¥½æ³›åŒ–èƒ½åŠ›**
   - åœ¨ **cross-city å®éªŒ** ä¸­ï¼Œä½¿ç”¨åŒ—äº¬ cache åŠ é€Ÿçº½çº¦ä»¿çœŸä»èƒ½å–å¾—å¯æ¥å—æ•ˆæœï¼ˆå°½ç®¡æ•ˆç‡ç•¥é™ï¼‰ã€‚
   - å› ä¸ºç¼“å­˜çš„æ˜¯é€šç”¨å†³ç­–é€»è¾‘è€Œéå…·ä½“åœ°ç†ä½ç½®ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **ä¾èµ–å¯è§£é‡Šçš„æ¨ç†è¿‡ç¨‹**
   - ä»…é€‚ç”¨äºèƒ½æä¾› step-by-step reasoning çš„æ¨¡å‹ï¼ˆå¦‚ CoT-based LLMsï¼‰ã€‚
   - é»‘ç®±å¼ç«¯åˆ°ç«¯æ¨¡å‹æ— æ³•ä»ä¸­å—ç›Šã€‚

2. **å†·å¯åŠ¨é—®é¢˜**
   - åˆå§‹é˜¶æ®µ cache ç©ºç™½ï¼Œéœ€è°ƒç”¨ LLM ç”Ÿæˆç§å­æ•°æ®ã€‚
   - ä½†åœ¨å¤§è§„æ¨¡é•¿æœŸè¿è¡Œä¸­ï¼Œå‘½ä¸­ç‡è¿…é€Ÿä¸Šå‡ï¼Œæ”¶ç›Šæ˜¾è‘—ã€‚

3. **åŸå¸‚é—´è¿ç§»ä»æœ‰å·®è·**
   - å°½ç®¡ reasoning å¯è¿ç§»ï¼Œä½† POI åˆ†å¸ƒã€é€šå‹¤ä¹ æƒ¯å·®å¼‚ä¼šå½±å“åŒ¹é…ç²¾åº¦ï¼ˆçº¦ 6% ç”¨æˆ·æ— æ³•æ‰¾åˆ°è¿‘é‚»ï¼‰ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **åŠ¨æ€ cache æ›´æ–°æœºåˆ¶**
   - æ”¯æŒåœ¨çº¿å¢é‡å­¦ä¹ ï¼ŒæŒç»­å¸æ”¶æ–°ç”Ÿæˆçš„é«˜è´¨é‡æ¨ç†é“¾ã€‚
2. **å¤šåŸå¸‚è”åˆ cache æ„å»º**
   - è·¨åŸå¸‚å¯¹é½æ½œåœ¨ç©ºé—´è¡¨ç¤ºï¼Œå¢å¼ºè¿ç§»èƒ½åŠ›ã€‚
3. **å¼•å…¥ä¸ç¡®å®šæ€§å»ºæ¨¡**
   - åœ¨ latent space ä¸­å»ºæ¨¡è¡Œä¸ºåˆ†å¸ƒè€Œéå•ä¸€è·¯å¾„ï¼Œè¿›ä¸€æ­¥æå‡å¤šæ ·æ€§ã€‚
4. **ä¸æœ¬åœ°éƒ¨ç½² LLM æ›´æ·±åº¦æ•´åˆ**
   - ç»“åˆ KV caching ç­‰åº•å±‚ä¼˜åŒ–ï¼Œå®ç°å…¨æ ˆåŠ é€Ÿã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯ï¼š**  
> **MobCache é€šè¿‡æ„å»ºâ€œå¯é‡æ„çš„æ½œåœ¨ç©ºé—´æ¨ç†ç¼“å­˜â€ï¼Œé¦–æ¬¡å®ç°äº†åœ¨ä¸ç‰ºç‰²ä»¿çœŸè´¨é‡çš„å‰æä¸‹ï¼Œå°† LLM-based human mobility simulation çš„æ•ˆç‡æå‡ä¸€ä¸ªæ•°é‡çº§ï¼Œä¸ºç™¾ä¸‡çº§åŸå¸‚ä»¿çœŸæä¾›äº†å¯è¡Œè·¯å¾„ã€‚**

</details>

---

### 2. [Operationalization of Machine Learning with Serverless Architecture: An Industrial Operationalization of Machine Learning with Serverless Architecture: An Industrial Implementation for Harmonized System Code Prediction](https://arxiv.org/abs/2602.17102)

**Authors**: Sai Vineeth Kandappareddigari, Santhoshkumar Jagadish, Gauri Verma, Ilhuicamina Contreras, Christopher Dignam, Anmol Srivastava, Benjamin Demers  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.17102v1  

#### Abstract
This paper presents a serverless MLOps framework orchestrating the complete ML lifecycle from data ingestion, training, deployment, monitoring, and retraining to using event-driven pipelines and managed services. The architecture is model-agnostic, supporting diverse inference patterns through stand...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šOperationalization of Machine Learning with Serverless Architecture: An Industrial Implementation for Harmonized System Code Prediction

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡èšç„¦äº**Harmonized System (HS) code é¢„æµ‹**è¿™ä¸€åœ¨å›½é™…è´¸æ˜“ä¸­è‡³å…³é‡è¦çš„åˆè§„æ€§åˆ†ç±»ä»»åŠ¡ã€‚ç”±äºäº§å“æè¿°ç®€çŸ­ã€éç»“æ„åŒ–ï¼Œä¸”å„å›½å¯¹ HS code çš„å®šä¹‰å­˜åœ¨å·®å¼‚ï¼Œäººå·¥åˆ†é…æ˜“å‡ºé”™ï¼Œå¯¼è‡´æ¸…å…³å»¶è¿Ÿå’Œç»æµæŸå¤±ã€‚ä¼ ç»Ÿæ–¹æ³•éš¾ä»¥åº”å¯¹é¢‘ç¹æ›´æ–°å’Œé«˜å‡†ç¡®ç‡è¦æ±‚ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
æå‡ºäº†ä¸€ç§**åŸºäº Serverless æ¶æ„çš„ç«¯åˆ°ç«¯ MLOps æ¡†æ¶**ï¼Œç”¨äºå·¥ä¸šçº§éƒ¨ç½²æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå…·ä½“åŒ…æ‹¬ï¼š

- **å…¨ç”Ÿå‘½å‘¨æœŸè‡ªåŠ¨åŒ–**ï¼šå®ç°ä»æ•°æ®æ‘„å…¥ã€è®­ç»ƒã€éƒ¨ç½²ã€ç›‘æ§åˆ°è‡ªåŠ¨é‡è®­ç»ƒï¼ˆretrainingï¼‰çš„å®Œæ•´ pipeline è‡ªåŠ¨åŒ–ã€‚
- **Serverless æ¶æ„è®¾è®¡**ï¼šåˆ©ç”¨ AWS çš„æ— æœåŠ¡å™¨æœåŠ¡ï¼ˆå¦‚ AWS Lambda, Sagemaker, Step Functions, EventBridge ç­‰ï¼‰ï¼Œå®ç°å¼¹æ€§ä¼¸ç¼©ã€æŒ‰éœ€è®¡è´¹ã€å…è¿ç»´åŸºç¡€è®¾æ–½ã€‚
- **æ¨¡å‹æ— å…³æ€§ï¼ˆModel-agnosticï¼‰æ¥å£**ï¼šæ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¶æ„ï¼ˆDNN, LSTM, Text-CNNï¼‰ï¼Œä¾¿äºçµæ´»åˆ‡æ¢ä¸æ¯”è¾ƒã€‚
- **è‡ªåŠ¨åŒ– A/B Testing**ï¼šå¼•å…¥åŠ¨æ€æ¨¡å‹é€‰æ‹©æœºåˆ¶ï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒä¸­å®‰å…¨åœ°è¯„ä¼°å¹¶æ¨å¹¿æœ€ä¼˜æ¨¡å‹ã€‚
- **å®šåˆ¶åŒ–æ–‡æœ¬åµŒå…¥ï¼ˆCustom Text Embedding Encoderï¼‰**ï¼šé’ˆå¯¹å·¥ç¨‹é¢†åŸŸç‰¹å®šæœ¯è¯­ï¼Œæ”¾å¼ƒé¢„è®­ç»ƒ embeddingsï¼ˆå¦‚ Word2Vec/GloVeï¼‰ï¼Œé‡‡ç”¨è‡ªå®šä¹‰ embedding å±‚ä»¥æå‡æ•ˆæœã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | æœ¬æ–‡æ–¹æ¡ˆä¼˜åŠ¿ |
|------|--------------|
| **å¯æ‰©å±•æ€§** | Serverless æ¶æ„å¤©ç„¶æ”¯æŒé«˜å¹¶å‘ä¸è‡ªåŠ¨æ‰©ç¼©å®¹ï¼Œé€‚åº”è´¸æ˜“æµé‡æ³¢åŠ¨ |
| **å¯é æ€§ä¸å®¡è®¡æ€§** | å®Œæ•´çš„æ—¥å¿—è¿½è¸ªã€ç‰ˆæœ¬æ§åˆ¶ä¸ SLA ä¿éšœï¼Œæ»¡è¶³ä¼ä¸šçº§åˆè§„éœ€æ±‚ |
| **æˆæœ¬æ•ˆç‡** | ç›¸è¾ƒ Transformer ç±»æ¨¡å‹ï¼ŒText-CNN åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½è®­ç»ƒä¸æ¨ç†å¼€é”€ |
| **å¯å¤ç°æ€§ä¸å·¥ä¸šåŒ–èƒ½åŠ›** | CI/CD + è‡ªåŠ¨åŒ– pipeline æ”¯æŒæŒç»­é›†æˆä¸éƒ¨ç½²ï¼Œé€‚åˆå¤§è§„æ¨¡è½åœ° |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
- **æ¥æº**ï¼šæ¥è‡ª Schneider Electric å†…éƒ¨å‡ºå£æ§åˆ¶ç³»ç»Ÿçš„çœŸå®ä¸šåŠ¡æ•°æ®ã€‚
- **ç‰¹å¾**ï¼š
  - `Short Description`ï¼šå¹³å‡é•¿åº¦ 15.2 å­—ç¬¦
  - `Medium Description`ï¼šå¹³å‡é•¿åº¦ 63.9 å­—ç¬¦
  - `ETIM`ï¼šå›½é™…æŠ€æœ¯äº§å“åˆ†ç±»æ ‡å‡†å±æ€§
- **æ ‡ç­¾**ï¼šHS codeï¼ˆå…±çº¦ 5000 ç±»ï¼Œç ”ç©¶ä¸­èšç„¦ 24 ä¸ªé«˜é¢‘ç±»åˆ«ï¼‰
- **æ•°æ®è´¨é‡åˆ†çº§**ï¼šä¸“å®¶æ ‡æ³¨ååˆ†ä¸º Assurance Level 1â€“4ï¼Œä»…ä½¿ç”¨ Level 3 å’Œ 4ï¼ˆé«˜ç½®ä¿¡åº¦ï¼‰è¿›è¡Œè®­ç»ƒã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **ä»»åŠ¡ç±»å‹**ï¼šå¤šç±»æ–‡æœ¬åˆ†ç±»ï¼ˆMulticlass Text Classificationï¼‰
- **æ•°æ®åˆ’åˆ†**ï¼šåˆ†å±‚æŠ½æ ·ï¼ˆStratified Samplingï¼‰ï¼Œè®­ç»ƒé›†å  95%ï¼Œæµ‹è¯•é›†å  5%
- **ç±»åˆ«ä¸å¹³è¡¡å¤„ç†**ï¼š
  - å°è¯• SMOTEã€Borderline SMOTE å’Œéšæœºä¸Šé‡‡æ ·ï¼ˆRandom Up-samplingï¼‰
  - æœ€ç»ˆé€‰ç”¨ **Stratified Up-sampling**ï¼Œå› å…¶ä¿ç•™åŸå§‹æ ·æœ¬ã€é¿å…åˆæˆå™ªå£°ã€æ›´ç¨³å®šå¯é 
- **ç‰¹å¾å·¥ç¨‹**ï¼š
  - æ¸…æ´—æ–‡æœ¬ï¼ˆå»ç¬¦å·ã€åœç”¨è¯ã€è½¬å°å†™ï¼‰
  - Tokenization + è‡ªå®šä¹‰ Vocabularyï¼ˆå¤§å° ~5000ï¼‰
  - ä½¿ç”¨è‡ªå®šä¹‰ embedding å±‚ï¼ˆæœªä½¿ç”¨ GloVe/Word2Vecï¼‰

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Accuracy** | æ•´ä½“é¢„æµ‹æ­£ç¡®ç‡ |
| **Precision / Recall / F1-score** | åˆ†ç±»æ€§èƒ½ç»†ç²’åº¦è¡¡é‡ï¼Œå°¤å…¶å…³æ³¨ä½é¢‘ç±»åˆ«çš„è¡¨ç° |
| **A/B Testing + ANOVA æ£€éªŒ** | åˆ¤æ–­ä¸åŒæ¨¡å‹é—´æ€§èƒ½å·®å¼‚æ˜¯å¦å…·æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§ |
| **Latency ä¸ Cost-efficiency** | æ¨ç†å»¶è¿Ÿä¸é•¿æœŸè¿è¥æˆæœ¬ä½œä¸ºå®é™…éƒ¨ç½²è€ƒé‡ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ¨¡å‹ | ç±»å‹ | æ˜¯å¦ä½¿ç”¨ |
|------|------|---------|
| SVM (with TF-IDF) | ç»å…¸æœºå™¨å­¦ä¹  | æ˜¯ï¼ˆåˆå§‹åŸºçº¿ï¼‰ |
| DNN | æ·±åº¦ç¥ç»ç½‘ç»œ | æ˜¯ |
| LSTM | åºåˆ—æ¨¡å‹ | æ˜¯ |
| Text-CNN | å·ç§¯ç¥ç»ç½‘ç»œ | æ˜¯ï¼ˆæœ€ç»ˆèƒœå‡ºï¼‰ |
| Transformer-based models | é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ | è¢«è€ƒè™‘ä½†æœªé‡‡ç”¨ï¼ˆå› æˆæœ¬è¿‡é«˜ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTest Setï¼‰

| Model | Accuracy | Precision (â‰¥90%) | Recall (â‰¥90%) | F1 (Avg) |
|-------|----------|------------------|---------------|-----------|
| **SVM (Baseline)** | 85% | â€” | â€” | â€” |
| **DNN (Base)** | 89% | 15/24 | 12/24 | â€” |
| **DNN (Up-sampled)** | 95% | 19/24 | 20/24 | â€” |
| **LSTM (Base)** | 92% | 19/24 | 16/24 | â€” |
| **LSTM (Up-sampled)** | 97% | 20/24 | 22/24 | â€” |
| **Text-CNN (Base)** | **98%** | **19/24** | **20/24** | â€” |
| **Text-CNN (Up-sampled)** | **98%** | **20/24** | **21/24** | â€” |

> âœ… **Text-CNN åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡è¾¾åˆ°æœ€ä½³è¡¨ç°ï¼Œå‡†ç¡®ç‡è¾¾ 98%**

### ğŸ” A/B Testing ä¸ç»Ÿè®¡éªŒè¯
- é‡‡ç”¨ **k-fold cross-validation (k=37)** å¯¹æ¯ä¸ª HS code è¿›è¡Œå¤šæ¬¡è¯„ä¼°
- ä½¿ç”¨ **ANOVA æ£€éªŒ**åˆ¤æ–­æ¨¡å‹é—´æ€§èƒ½å·®å¼‚æ˜¯å¦æ˜¾è‘—
- ç»“æœæ˜¾ç¤ºï¼šText-CNN åœ¨å¤šæ•°ç±»åˆ«ä¸Šçš„ Precision å’Œ Recall åˆ†å¸ƒæ˜¾è‘—ä¼˜äº DNN å’Œ LSTMï¼ˆp < 0.05ï¼‰

### â±ï¸ æ¶ˆèå®éªŒä¸è®­ç»ƒæ—¶é—´å¯¹æ¯”ï¼ˆè§ Table VIIï¼‰

| Model | Base Model Total Time | Up-sampled Model Total Time |
|-------|------------------------|------------------------------|
| DNN | 51 mins | 3h 36min |
| LSTM | 5.5 hrs | 5.4 hrs |
| **Text-CNN** | **3h 15min** | **3h 10min** |

> ğŸ’¡ å°½ç®¡ LSTM è¡¨ç°æ¥è¿‘ï¼Œä½†å…¶è®­ç»ƒè€—æ—¶æœ€é•¿ï¼›è€Œ Text-CNN ä¸ä»…ç²¾åº¦æœ€é«˜ï¼Œä¸”è®­ç»ƒæ•ˆç‡æ›´é«˜ã€‚

### ğŸ§ª å…¶ä»–æ¶ˆèå‘ç°
- **Custom Embedding > Pretrained Embedding**ï¼šåœ¨æœ¬é¢†åŸŸæ•°æ®ä¸Šï¼ŒWord2Vec/GloVe è¡¨ç°ä¸ä½³ï¼Œä¸»å› æ˜¯æœ¯è¯­ä¸“ä¸šåŒ–ç¨‹åº¦é«˜ã€‚
- **Up-sampling æ˜¾è‘—æ”¹å–„é•¿å°¾ç±»åˆ«è¡¨ç°**ï¼šç‰¹åˆ«æ˜¯å¯¹äºå‡ºç°é¢‘ç‡ <1% çš„ HS codeï¼Œrecall æå‡æ˜æ˜¾ã€‚
- **Text-CNN æ›´æ“…é•¿æ•æ‰å±€éƒ¨å…³é”®è¯ç»„ï¼ˆn-gram ç‰¹å¾ï¼‰**ï¼Œé€‚ç”¨äºçŸ­æ–‡æœ¬åœºæ™¯ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **Text-CNN æ˜¯ HS code åˆ†ç±»çš„æœ€ä½³é€‰æ‹©**ï¼šåœ¨å‡†ç¡®ç‡ï¼ˆ98%ï¼‰ã€è®­ç»ƒæ•ˆç‡å’Œç¨³å®šæ€§æ–¹é¢å…¨é¢é¢†å…ˆã€‚
2. **Serverless MLOps å¯æœ‰æ•ˆæ”¯æ’‘å·¥ä¸šçº§ ML éƒ¨ç½²**ï¼šé€šè¿‡ AWS å·¥å…·é“¾å®ç°äº†å…¨æµç¨‹è‡ªåŠ¨åŒ–ã€å¯å®¡è®¡ã€å¯æ‰©å±•çš„ç³»ç»Ÿã€‚
3. **è‡ªåŠ¨åŒ– A/B Testing æå‡æ¨¡å‹è¿­ä»£å®‰å…¨æ€§**ï¼šå¯åœ¨çœŸå®ç¯å¢ƒä¸‹ç§‘å­¦å†³ç­–æ¨¡å‹ä¸Šçº¿ç­–ç•¥ã€‚
4. **æˆæœ¬æ•ˆç›Šä¼˜å…ˆäºâ€œæœ€å…ˆè¿›â€æ¨¡å‹**ï¼šå°½ç®¡ Transformer å¯èƒ½è¾¾åˆ°ç›¸è¿‘ç²¾åº¦ï¼Œä½†å…¶é«˜æ˜‚çš„è®­ç»ƒä¸æ¨ç†æˆæœ¬ä½¿å…¶ä¸é€‚åˆé•¿æœŸè¿è¥ã€‚
5. **Deterministic åˆ†ç±»ä¼˜äº Generative AI**ï¼šåœ¨éœ€è¦å¯è§£é‡Šæ€§ã€ä½å»¶è¿Ÿå’Œå¼ºä¸€è‡´æ€§çš„åˆè§„åœºæ™¯ä¸­ï¼Œç¡®å®šæ€§æ¨¡å‹æ›´å…·ä¼˜åŠ¿ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
| é™åˆ¶ | è¯´æ˜ |
|------|------|
| **åŒºåŸŸä¾èµ–æ€§å¼º** | å½“å‰æ¨¡å‹ä¸»è¦åŸºäº EU å’Œ US æ•°æ®è®­ç»ƒï¼Œè·¨åŒºåŸŸæ³›åŒ–èƒ½åŠ›æœ‰å¾…éªŒè¯ |
| **æ— æ³•å¤„ç†å…¨æ–°äº§å“** | è‹¥æ–°äº§å“ä»æœªå‡ºç°åœ¨è®­ç»ƒé›†ä¸­ï¼Œåˆ™æ— æ³•å‡†ç¡®é¢„æµ‹ï¼Œä»éœ€äººå·¥å¹²é¢„ |
| **HS code åŠ¨æ€æ›´æ–°æŒ‘æˆ˜** | WCO æ¯ 5â€“6 å¹´æ›´æ–°ä¸€æ¬¡ HS code ä½“ç³»ï¼Œéœ€å®šæœŸé‡è®­ç»ƒæ¨¡å‹ |
| **ç±»åˆ«æåº¦ä¸å‡è¡¡** | å°‘æ•° HS code å æ¯”æä½ï¼ˆ<1%ï¼‰ï¼Œå³ä½¿ä¸Šé‡‡æ ·ä¹Ÿéš¾å®Œå…¨ç¼“è§£åå·®é£é™© |
| **ç¼ºä¹å®æ—¶åé¦ˆé—­ç¯** | å½“å‰ drift detection è§¦å‘æœºåˆ¶ä¾èµ–äººå·¥ä¿®æ­£åçš„æ•°æ®ä¸Šä¼ ï¼Œå°šæœªå®Œå…¨è‡ªåŠ¨åŒ– |

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- âœ… å¼•å…¥æ›´å¤š**categorical features**ï¼ˆå¦‚ ETIM åˆ†ç±»ç ï¼‰å¢å¼ºè¾“å…¥è¡¨ç¤º
- âœ… æ¢ç´¢ **SMOTE ç­‰é«˜çº§ä¸Šé‡‡æ ·æŠ€æœ¯**è¿›ä¸€æ­¥ä¼˜åŒ–é•¿å°¾ç±»åˆ«
- âœ… æ‰©å±•è‡³**äºšå¤ªã€å—ç¾ç­‰å…¶ä»–åœ°åŒº**çš„æ•°æ®é›†
- âœ… é›†æˆ **KL Divergence æˆ–å…¶ä»– drift detection æ–¹æ³•**å®ç°è‡ªåŠ¨è§¦å‘é‡è®­ç»ƒ
- âœ… å¼•å…¥**å¹¶è¡Œè®¡ç®—**åŠ é€Ÿè¶…å‚è°ƒä¼˜ä¸è®­ç»ƒè¿‡ç¨‹
- âœ… ä½¿ç”¨ **CloudFormation æ¨¡æ¿**å®ç°ç¯å¢ƒé—´ä¸€é”®éƒ¨ç½²
- âœ… æ¢ç´¢ **Generative AI** åœ¨ HS code æ¨èä¸­çš„æ½œåŠ›ï¼ˆå¾…æ•°æ®æ²»ç†æ”¿ç­–å…è®¸ï¼‰

---

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼š  
> æœ¬æ–‡æä¾›äº†ä¸€ä¸ªæå…·å®ç”¨ä»·å€¼çš„ä¼ä¸šçº§ MLOps å®æ–½è“å›¾ï¼Œå°†å‰æ²¿ AI æŠ€æœ¯ä¸äº‘åŸç”Ÿæ¶æ„æ·±åº¦èåˆï¼Œä¸ä»…è§£å†³äº† HS code é¢„æµ‹çš„å®é™…éš¾é¢˜ï¼Œä¹Ÿä¸ºå…¶ä»–å·¥ä¸šåœºæ™¯ä¸‹çš„ ML è½åœ°æä¾›äº†å¯å¤åˆ¶èŒƒå¼ã€‚å…¶å¼ºè°ƒâ€œ**æ€§èƒ½ã€æˆæœ¬ã€å¯é æ€§ä¸‰ä½ä¸€ä½“**â€çš„è®¾è®¡å“²å­¦ï¼Œä»£è¡¨äº†å½“å‰å·¥ä¸šç•Œ MLOps å‘å±•çš„é‡è¦è¶‹åŠ¿ã€‚

</details>

---

### 3. [A Theoretical Framework for Modular Learning of Robust Generative Models](https://arxiv.org/abs/2602.17554)

**Authors**: Corinna Cortes, Mehryar Mohri, Yutao Zhong  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.17554v1  

#### Abstract
Training large-scale generative models is resource-intensive and relies heavily on heuristic dataset weighting. We address two fundamental questions: Can we train Large Language Models (LLMs) modularly-combining small, domain-specific experts to match monolithic performance-and can we do so robustly...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Theoretical Framework for Modular Learning of Robust Generative Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹å¤§è§„æ¨¡ç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚Large Language Models, LLMsï¼‰è®­ç»ƒä¸­çš„ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜æå‡ºè§£å†³æ–¹æ¡ˆï¼š
- **å¯æŒç»­æ€§ä¸é€‚åº”æ€§**ï¼šä¼ ç»Ÿå•ä½“ï¼ˆmonolithicï¼‰æ¨¡å‹è®­ç»ƒæˆæœ¬é«˜æ˜‚ï¼Œéš¾ä»¥å¿«é€Ÿé€‚åº”æ–°æ•°æ®åŸŸæˆ–æ›´æ–°æ¨¡å—ã€‚
- **é²æ£’æ€§**ï¼šæ ‡å‡†è®­ç»ƒä¾èµ–å¯å‘å¼çš„æ•°æ®æ··åˆæƒé‡ï¼Œåœ¨æµ‹è¯•åˆ†å¸ƒå‘ç”Ÿåç§»æ—¶è¡¨ç°ä¸ç¨³å®šã€‚

ä½œè€…æ—¨åœ¨å›ç­”ä¸¤ä¸ªæ ¹æœ¬æ€§é—®é¢˜ï¼š
1. æ˜¯å¦å¯ä»¥ä»¥**æ¨¡å—åŒ–æ–¹å¼**è®­ç»ƒLLMï¼Œå³ç»„åˆå¤šä¸ªé¢†åŸŸä¸“ç”¨çš„å°å‹ä¸“å®¶æ¨¡å‹æ¥åŒ¹é…å¤§å‹å•ä½“æ¨¡å‹çš„æ€§èƒ½ï¼Ÿ
2. æ˜¯å¦å¯ä»¥å®ç°å¯¹ä»»æ„æ•°æ®æ··åˆéƒ½**é²æ£’**çš„æ¨¡å—åŒ–ç³»ç»Ÿï¼Œä»è€Œå®Œå…¨æ¶ˆé™¤å¯¹å¯å‘å¼åŠ æƒçš„ä¾èµ–ï¼Ÿ

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
è®ºæ–‡æå‡ºäº†ä¸€ä¸ª**åŸºäºåšå¼ˆè®ºçš„æ¨¡å—åŒ–ç”Ÿæˆå»ºæ¨¡æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³å¦‚ä¸‹ï¼š

- **æ¨¡å—åŒ–æ¶æ„**ï¼šä½¿ç”¨ä¸€ç»„é¢„è®­ç»ƒçš„å†»ç»“ä¸“å®¶æ¨¡å‹ $ \{\Pi_k\} $ï¼Œé€šè¿‡ä¸€ä¸ªå¯å­¦ä¹ çš„**é—¨æ§æœºåˆ¶**ï¼ˆgating mechanismï¼‰åŠ¨æ€ç»„åˆå®ƒä»¬ï¼Œå½¢æˆæœ€ç»ˆè¾“å‡ºæ¨¡å‹ï¼š
  $$
  T_g(x) = \sum_k g(x,k) \Pi_k(x)
  $$
  å…¶ä¸­ $ g(x,\cdot) \in \Delta $ æ˜¯è¾“å…¥ç›¸å…³çš„å½’ä¸€åŒ–é—¨å‡½æ•°ã€‚

- **é²æ£’ä¼˜åŒ–ç›®æ ‡**ï¼šå°†é—®é¢˜å½¢å¼åŒ–ä¸ºä¸€ä¸ª**æå°æå¤§åšå¼ˆ**ï¼ˆminimax gameï¼‰ï¼Œç›®æ ‡æ˜¯æ‰¾åˆ°ä¸€ä¸ªå•ä¸€çš„é²æ£’é—¨æ§å‡½æ•° $ g^* $ï¼Œä½¿å…¶åœ¨æœ€åæƒ…å†µä¸‹çš„æ•°æ®æ··åˆ $ \lambda $ ä¸‹ä»èƒ½æœ€å°åŒ–KLæ•£åº¦ï¼š
  $$
  \min_{g \in \mathcal{G}_1} \max_{\lambda \in \Delta} D_{\text{KL}}(p_\lambda \| T_g)
  $$
  è¿™ç§è®¾å®šç¡®ä¿äº†æ¨¡å‹å¯¹æœªçŸ¥æˆ–å¯¹æŠ—æ€§çš„åˆ†å¸ƒæ··åˆå…·æœ‰å¼ºé²æ£’æ€§ã€‚

- **ç†è®ºä¿è¯**ï¼šåˆ©ç”¨Kakutaniä¸åŠ¨ç‚¹å®šç†è¯æ˜äº†æ­¤ç±»é²æ£’é—¨çš„å­˜åœ¨æ€§ï¼Œå¹¶æ¨å¯¼å‡ºæ³›åŒ–ç•Œè¡¨æ˜æ ·æœ¬å¤æ‚åº¦ä»…ä¾èµ–äºè½»é‡çº§é—¨æ§ç½‘ç»œçš„å®¹é‡ï¼Œè€Œéåºå¤§çš„ä¸“å®¶å‚æ•°ã€‚

- **ä¿¡æ¯è®ºä¼˜åŠ¿åˆ†æ**ï¼šè¯æ˜è¯¥æ¨¡å—åŒ–æ–¹æ³•åœ¨ç†è®ºä¸Šå¯ä¼˜äºåœ¨èšåˆæ•°æ®ä¸Šé‡æ–°è®­ç»ƒçš„å•ä½“æ¨¡å‹ï¼Œä¸”æ€§èƒ½å·®è·ç”±**Jensen-Shannon Divergence (JSD)** åˆ»ç”»ã€‚

- **é«˜æ•ˆæ¨ç†æ–¹æ¡ˆ**ï¼šæå‡º**Structural Distillation**æ–¹æ³•ï¼Œå°†éå› æœçš„é²æ£’é—¨è’¸é¦åˆ°ä¸€ä¸ªè½»é‡çº§çš„å› æœè·¯ç”±å™¨ï¼ˆcausal routerï¼‰ä¸­ï¼Œå®ç°åœ¨ä¿æŒæ¨¡å—æ€§çš„åŒæ—¶è¿›è¡Œé«˜æ•ˆçš„è‡ªå›å½’ç”Ÿæˆã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | æœ¬æ–‡æ–¹æ³• | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚Model Soups, MoEç­‰ï¼‰ |
|------|--------|-------------------------------|
| **é²æ£’æ€§** | å¯¹ä»»æ„æ··åˆåˆ†å¸ƒæä¾›ç»Ÿä¸€æ€§èƒ½ä¿è¯ | é€šå¸¸é’ˆå¯¹å¹³å‡æ€§èƒ½ä¼˜åŒ–ï¼Œç¼ºä¹æœ€åæƒ…å†µä¿éšœ |
| **æ¨¡å—æ€§ä¿ç•™** | æ˜ç¡®ç»´æŠ¤ä¸“å®¶ç‹¬ç«‹æ€§ï¼Œæ”¯æŒå¢é‡æ›´æ–° | å¤šæ•°åˆå¹¶æ–¹æ³•ç ´åæ¨¡å—ç»“æ„ï¼ˆå¦‚æƒé‡å¹³å‡ï¼‰ |
| **ç†è®ºåŸºç¡€** | æä¾›å­˜åœ¨æ€§è¯æ˜ã€æ³›åŒ–ç•Œå’Œä¿¡æ¯è®ºæ¯”è¾ƒ | å¤šä¸ºç»éªŒæ€§è®¾è®¡ï¼Œç¼ºä¹ä¸¥æ ¼ç†è®ºæ”¯æ’‘ |
| **æ¨ç†æ•ˆç‡** | é€šè¿‡Structural Distillationå®ç°O(1)è‡ªå›å½’é‡‡æ · | éå› æœé—¨å¯¼è‡´é«˜å»¶è¿Ÿï¼ˆéœ€SIR/Rejection Samplingï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒåˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š

#### åˆæˆæ•°æ®é›†ï¼ˆSynthetic Benchmarksï¼‰
- æ„é€ ä¸¤ä¸ªå…·æœ‰**å†²çªè§„åˆ™**çš„è¯­è¨€æ¨¡å‹ä»»åŠ¡ï¼š
  - **Domain A**: $ x_{t+1} = (x_t + 1) \mod 100 $
  - **Domain B**: $ x_{t+1} = (x_t - 1) \mod 100 $
- æµ‹è¯•æ—¶é€šè¿‡è°ƒæ•´æ··åˆæ¯”ä¾‹ $ \lambda \in [0,1] $ æ¥æ¨¡æ‹Ÿåˆ†å¸ƒåç§»ã€‚

#### çœŸå®ä¸–ç•Œæ•°æ®é›†ï¼ˆReal-World Datasetsï¼‰
ä½¿ç”¨ä¸‰ä¸ªå·®å¼‚æ˜¾è‘—çš„HuggingFaceæ•°æ®é›†ï¼š
- `wikimedia/wikipedia`: é«˜è´¨é‡äº‹å®æ€§æ–‡æœ¬
- `bigcode/the-stack-smol`: è·¨30+è¯­è¨€çš„æºä»£ç 
- `fineweb-edu`: ç»è¿‡æ»¤çš„é«˜è´¨é‡æ•™è‚²ç½‘é¡µå†…å®¹  
è¿™äº›æ•°æ®ä»£è¡¨äº†è‡ªç„¶è¯­è¨€ä¸ç¼–ç¨‹è¯­è¨€ä¹‹é—´çš„å·¨å¤§åˆ†å¸ƒå·®å¼‚ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹è§„æ¨¡**ï¼šå°å‹Transformeræ¶æ„ï¼ˆçº¦20Må‚æ•°ï¼‰ï¼Œä¾¿äºæ§åˆ¶å˜é‡ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - ä¸»è¦æŒ‡æ ‡ï¼š**Negative Log-Likelihood (NLL) per token**
  - é²æ£’æ€§è¯„ä¼°ï¼šåœ¨ä¸åŒæµ‹è¯•æ··åˆæ¯”ä¾‹ $ \lambda $ ä¸‹çš„NLLè¡¨ç°
- **è®­ç»ƒåè®®**ï¼š
  - ä¸“å®¶æ¨¡å‹å…ˆåˆ†åˆ«åœ¨å„è‡ªé¢†åŸŸæ”¶æ•›ã€‚
  - é—¨æ§æ¨¡å‹åœ¨è”åˆæ•°æ®ä¸Šä½¿ç”¨æå‡ºçš„**Stochastic Primal-Dual Algorithm**è¿›è¡Œè®­ç»ƒã€‚
  - Structural Distillationé˜¶æ®µä½¿ç”¨æ‹’ç»é‡‡æ ·ç”Ÿæˆâ€œé²æ£’åºåˆ—â€ä½œä¸ºæ•™å¸ˆä¿¡å·ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿åç§° | æè¿° |
|--------|------|
| **Fixed Smaller/Larger Retrained** | åœ¨èšåˆæ•°æ®ä¸Šä»å¤´è®­ç»ƒçš„å•ä½“æ¨¡å‹ï¼ˆå‚æ•°é‡ç›¸è¿‘æˆ–æ›´å¤§ï¼‰ |
| **Oracle Smaller/Larger** | â€œä½œå¼Šâ€åŸºçº¿ï¼Œåœ¨æ¯ä¸ªæµ‹è¯•æ··åˆæ¯”ä¾‹ä¸‹å•ç‹¬é‡æ–°è®­ç»ƒçš„æ¨¡å‹ï¼ˆç†æƒ³ä¸Šé™ï¼‰ |
| **Monolithic Distillation** | å°†æ•´ä¸ªé—¨æ§ç³»ç»Ÿçš„è¾“å‡ºè’¸é¦æˆä¸€ä¸ªå•ä¸€å­¦ç”Ÿæ¨¡å‹ï¼ˆæ”¾å¼ƒæ¨¡å—æ€§ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
#### åˆæˆä»»åŠ¡ç»“æœï¼ˆFig. 5â€“7ï¼‰
- åœ¨é«˜å¹²æ‰°åŒºåŸŸï¼ˆ$ \lambda \approx 0.5 $ï¼‰ï¼š
  - **Robust Gate** çš„NLLç¨³å®šåœ¨ **~0.06**
  - **Larger Oracle** å•ä½“æ¨¡å‹NLLé«˜è¾¾ **~0.10**
  - è¡¨æ˜å³ä½¿çŸ¥é“çœŸå®æ··åˆæ¯”ä¾‹ï¼Œå•ä½“æ¨¡å‹ä¹Ÿæ— æ³•å…‹æœæ¢¯åº¦å†²çª
- åœ¨æç«¯æ··åˆï¼ˆ$ \lambda \to 0 $ æˆ– $ 1 $ï¼‰ï¼š
  - Oracleæ¨¡å‹ç•¥ä¼˜ï¼Œå› ä»»åŠ¡é€€åŒ–ä¸ºå•ä¸€é¢†åŸŸ
- **Structural Distillation** æ•ˆæœï¼š
  - è’¸é¦åçš„å› æœè·¯ç”±å™¨æ€§èƒ½å‡ ä¹ä¸åŸå§‹éå› æœé—¨æ§æ¨¡å‹ä¸€è‡´ï¼ˆFig. 8ï¼‰
  - NLLå·®è·å°äº0.005ï¼ŒéªŒè¯äº†è’¸é¦æœ‰æ•ˆæ€§

#### çœŸå®ä¸–ç•Œä»»åŠ¡ç»“æœï¼ˆTable 1 & 2ï¼‰
| æ¨¡å‹ | NLL (ä¸åŒseed) | NLL (ä¸åŒdata) |
|------|---------------|----------------|
| Retrained Model | 5.133 Â± 0.010 | 5.306 Â± 0.257 |
| **Gate Model (Ours)** | **4.994 Â± 0.013** | **5.087 Â± 0.141** |

- åœ¨æ‰€æœ‰æµ‹è¯•æ··åˆæ¯”ä¾‹ä¸‹ï¼Œ**Gate Modelå‡æ˜¾è‘—ä¼˜äºRetrained Model**ï¼ˆTable 2ï¼‰
- æœ€å¤§æå‡å‡ºç°åœ¨å¹³è¡¡æ··åˆï¼ˆ$ \lambda = (1/3,1/3,1/3) $ï¼‰æ—¶ï¼ŒNLLé™ä½è¶…è¿‡0.13
- å³ä½¿åœ¨éå¹³è¡¡æ··åˆä¸‹ï¼Œä¹Ÿå§‹ç»ˆä¿æŒæ›´ä½çš„NLLå’Œæ›´å°çš„æ ‡å‡†å·®ï¼Œæ˜¾ç¤ºå‡ºæ›´å¼ºçš„ç¨³å®šæ€§

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **vs å›ºå®šé‡è®­ç»ƒæ¨¡å‹**ï¼šåœ¨é«˜å¹²æ‰°åŒºæ€§èƒ½è¿œè¶…ï¼Œè¯å®äº†æ¨¡å—åŒ–èƒ½æœ‰æ•ˆç¼“è§£negative transferã€‚
- **vs Oracleæ¨¡å‹**ï¼šåœ¨ä¸­é—´æ··åˆåŒºåè¶…ï¼ŒéªŒè¯äº†â€œThe JSD Gapâ€ç†è®ºâ€”â€”å¤šæ ·æ€§æœ¬èº«æˆä¸ºæ¨¡å—ç³»ç»Ÿçš„å‡ ä½•å¢ç›Šè€Œéè´Ÿæ‹…ã€‚
- **vs Monolithic Distillation**ï¼šStructural Distillationåœ¨ä¿æŒæ¨ç†æ•ˆç‡çš„åŒæ—¶ï¼Œä¿ç•™äº†æ¨¡å—æ›´æ–°èƒ½åŠ›ï¼Œè€Œå‰è€…ä¸€æ—¦ä¸“å®¶æ›´æ–°å°±å¿…é¡»é‡æ–°è’¸é¦ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **ç®—æ³•ç¨³å®šæ€§**ï¼ˆSection 8.2ï¼‰ï¼š
  - å¯¹æ‰‹æ··åˆæƒé‡ $ \lambda_t $ å¿«é€Ÿæ”¶æ•›è‡³ $ [0.5, 0.5] $ï¼Œè¯´æ˜é—¨æ§æˆåŠŸå¹³è¡¡å„é¢†åŸŸæ€§èƒ½ã€‚
  - å¯¹å¶å˜é‡ $ u $ ç¨³å®šä¸Šå‡åè¶‹äºå¹³ç¨³ï¼Œè¡¨æ˜å½’ä¸€åŒ–çº¦æŸè¢«æœ‰æ•ˆæ»¡è¶³ã€‚
- **ä¸åŒä¸“å®¶é‡å ç¨‹åº¦çš„å½±å“**ï¼š
  - å½“ä¸“å®¶é—´å…±äº«æ›´å¤šæ•°æ®ï¼ˆå¦‚Domain Aå«75% Domain Bï¼‰æ—¶ï¼Œæ¨¡å—åŒ–ä¼˜åŠ¿å‡å¼±ä½†ä»å­˜åœ¨ã€‚
  - éªŒè¯äº†ç†è®ºé¢„æµ‹ï¼šå½“JSDè¾ƒå°æ—¶ï¼Œå•ä½“æ¨¡å‹æ›´å…·ç«äº‰åŠ›ï¼›å½“JSDå¤§æ—¶ï¼Œæ¨¡å—åŒ–å ä¼˜ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **æ¨¡å—åŒ–å¯å®ç°é²æ£’ç”Ÿæˆå»ºæ¨¡**ï¼šé€šè¿‡æå°æå¤§åšå¼ˆæ¡†æ¶ï¼Œç¡®å®å­˜åœ¨ä¸€ä¸ªå¯¹ä»»æ„æ•°æ®æ··åˆéƒ½é²æ£’çš„é—¨æ§ç­–ç•¥ã€‚
2. âœ… **æ¨¡å—åŒ–æ˜¯ä¸€ç§å¼ºæ­£åˆ™åŒ–å™¨**ï¼šæ³›åŒ–è¯¯å·®ä»…ä¾èµ–äºé—¨æ§ç½‘ç»œå¤æ‚åº¦ï¼Œè€Œéä¸“å®¶å‚æ•°æ€»é‡ã€‚
3. âœ… **ä¿¡æ¯è®ºä¼˜åŠ¿æˆç«‹**ï¼šæ¨¡å—åŒ–ç³»ç»Ÿå¯åœ¨ç†è®ºä¸Šè¶…è¶Šåœ¨èšåˆæ•°æ®ä¸Šé‡æ–°è®­ç»ƒçš„å•ä½“æ¨¡å‹ï¼Œå°¤å…¶åœ¨ä»»åŠ¡é—´å·®å¼‚å¤§ï¼ˆJSDé«˜ï¼‰æ—¶ã€‚
4. âœ… **Structural Distillationå¯è¡Œ**ï¼šå¯å°†éå› æœé²æ£’é—¨é«˜æ•ˆè’¸é¦ä¸ºå› æœè·¯ç”±å™¨ï¼Œå…¼é¡¾æ€§èƒ½ã€æ•ˆç‡ä¸æ¨¡å—æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **éå› æœé—¨çš„æ¨ç†ç“¶é¢ˆ**ï¼šåŸå§‹é²æ£’é—¨æ— æ³•ç›´æ¥ç”¨äºè‡ªå›å½’ç”Ÿæˆï¼Œå¿…é¡»ä¾èµ–SIRæˆ–è’¸é¦ã€‚
- **ä¸“å®¶éœ€é¢„å…ˆå®šä¹‰å¹¶å†»ç»“**ï¼šå½“å‰æ¡†æ¶å‡è®¾ä¸“å®¶å·²å­˜åœ¨ä¸”ä¸å¯å¾®è°ƒï¼Œé™åˆ¶äº†ç«¯åˆ°ç«¯è”åˆä¼˜åŒ–çš„å¯èƒ½æ€§ã€‚
- **ç†è®ºä¾èµ–å‡¸æ€§å‡è®¾**ï¼šéƒ¨åˆ†æ”¶æ•›æ€§è¯æ˜åŸºäºæŸå¤±å‡½æ•°å…³äºé—¨æ§çš„å‡¸æ€§ï¼Œå®é™…æ·±åº¦ç½‘ç»œå¯èƒ½åç¦»æ­¤å‡è®¾ã€‚
- **æ‰©å±•æ€§å¾…éªŒè¯**ï¼šå®éªŒè§„æ¨¡è¾ƒå°ï¼ˆ~20Må‚æ•°ï¼‰ï¼Œåœ¨è¶…å¤§è§„æ¨¡LLMä¸Šçš„æ•ˆæœå°šéœ€è¿›ä¸€æ­¥éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢**å¯å¾®åˆ†ä¸“å®¶é€‰æ‹©æœºåˆ¶**ï¼Œå…è®¸é—¨æ§ä¸ä¸“å®¶ååŒä¼˜åŒ–ã€‚
- å°†æ¡†æ¶åº”ç”¨äº**å¤šæ¨¡æ€æ¨¡å‹é›†æˆ**ï¼ˆå¦‚è§†è§‰+è¯­è¨€ä¸“å®¶ï¼‰ã€‚
- ç»“åˆ**ç»æµæ¿€åŠ±æœºåˆ¶**ï¼Œç ”ç©¶åœ¨å¼€æ”¾å¸‚åœºä¸­å¦‚ä½•æ¿€åŠ±é«˜è´¨é‡æ¨¡å—ç”Ÿäº§ï¼ˆå‘¼åº”æ–‡ä¸­Modular Marketplacesè®¨è®ºï¼‰ã€‚
- å¼€å‘æ›´é«˜æ•ˆçš„**åœ¨çº¿è·¯ç”±æ›´æ–°æœºåˆ¶**ï¼Œä»¥åº”å¯¹æŒç»­å˜åŒ–çš„æ•°æ®æµã€‚

--- 

> **æ€»ç»“**ï¼šæœ¬è®ºæ–‡ä¸ºæ¨¡å—åŒ–AIæä¾›äº†åšå®çš„ç†è®ºåŸºç¡€å’Œå®ç”¨ç®—æ³•è·¯å¾„ï¼Œä¸ä»…è¯æ˜äº†â€œå¤šæ ·æ€§å³ä¼˜åŠ¿â€çš„æ–°èŒƒå¼ï¼Œä¹Ÿä¸ºæ„å»ºç»¿è‰²ã€å¯æŒç»­ã€å¯æ¼”åŒ–çš„ä¸‹ä¸€ä»£LLMç”Ÿæ€ç³»ç»ŸæŒ‡æ˜äº†æ–¹å‘ã€‚

</details>

---

### 4. [Automating Agent Hijacking via Structural Template Injection](https://arxiv.org/abs/2602.16958)

**Authors**: Xinhao Deng, Jiaqing Wu, Miao Chen, Yue Xiao, Ke Xu, Qi Li  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.16958v1  

#### Abstract
Agent hijacking, highlighted by OWASP as a critical threat to the Large Language Model (LLM) ecosystem, enables adversaries to manipulate execution by injecting malicious instructions into retrieved content. Most existing attacks rely on manually crafted, semantics-driven prompt manipulation, which ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠAutomating Agent Hijacking via Structural Template Injectionã€‹æ ¸å¿ƒæ€»ç»“

## 1. ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹ **LLM Agent** ä¸­æ—¥ç›Šä¸¥é‡çš„ **Agent Goal Hijacking** å®‰å…¨å¨èƒï¼Œæ­ç¤ºäº†ä¸€ç§æ–°å‹æ”»å‡»èŒƒå¼ã€‚ä¼ ç»Ÿ **Indirect Prompt Injection (IPI)** æ”»å‡»ä¾èµ–è¯­ä¹‰æ“çºµï¼Œä½†éšç€æ¨¡å‹é€šè¿‡ RLHF å’Œ Safety Alignment ä¸æ–­å¢å¼ºå¯¹è‡ªç„¶è¯­è¨€æŒ‡ä»¤çš„é²æ£’æ€§ï¼Œè¿™ç±»æ”»å‡»æˆåŠŸç‡ä¸‹é™ä¸”éš¾ä»¥è·¨æ¨¡å‹è¿ç§»ã€‚

ä½œè€…æŒ‡å‡ºï¼Œç°æœ‰æ”»å‡»çš„æ ¹æœ¬å±€é™åœ¨äºï¼šå®ƒä»¬è¯•å›¾â€œè¯´æœâ€æ¨¡å‹è¿èƒŒå…¶å®‰å…¨ç­–ç•¥ï¼Œè€Œéåˆ©ç”¨å…¶åº•å±‚æ¶æ„ç¼ºé™·ã€‚è€Œç°å®ä¸­çš„ LLM Agent æ™®éä¾èµ– **Chat Template** å’Œç‰¹æ®Šæ ‡è®°ï¼ˆå¦‚ `<|im_start|>`ï¼‰æ¥è§£æå¯¹è¯è§’è‰²ï¼ˆSystem/User/Assistant/Toolï¼‰ï¼Œè¿™äº›æ§åˆ¶ä¿¡å·ä¸å¤–éƒ¨å†…å®¹åœ¨ token å±‚é¢è¢«ç»Ÿä¸€å¤„ç†ï¼Œç¼ºä¹ä¸¥æ ¼çš„éš”ç¦»æœºåˆ¶ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡º **Phantom** â€”â€”ä¸€ç§åŸºäº **Structured Template Injection (STI)** çš„è‡ªåŠ¨åŒ–ä»£ç†åŠ«æŒæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **ä¸æ”»å‡»è¯­ä¹‰ï¼Œè€Œæ˜¯æ”»å‡»ç»“æ„**ï¼šé€šè¿‡å‘ä»£ç†æ£€ç´¢çš„å¤–éƒ¨å†…å®¹ä¸­æ³¨å…¥ç²¾å¿ƒæ„é€ çš„ **ç»“æ„åŒ–æ¨¡æ¿åºåˆ—**ï¼ˆåŒ…å«ç‰¹æ®Š tokenï¼‰ï¼Œè¯±å¯¼ä»£ç†äº§ç”Ÿ **Role Confusion**ï¼Œä½¿å…¶è¯¯å°†æ”»å‡»è€…æ³¨å…¥çš„å†…å®¹è¯†åˆ«ä¸ºåˆæ³•çš„ç”¨æˆ·æŒ‡ä»¤æˆ–å·¥å…·è¾“å‡ºã€‚
- **è‡ªåŠ¨åŒ–æ”»å‡»ç”Ÿæˆ**ï¼šä¸ºåº”å¯¹å•†ä¸šé—­æºæ¨¡å‹æ¨¡æ¿æœªçŸ¥çš„é»‘ç›’åœºæ™¯ï¼Œè®¾è®¡äº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„è‡ªåŠ¨åŒ–æœç´¢æ¡†æ¶ï¼š
  1. **Multi-level Template Augmentation**ï¼šç»“åˆ LLM è¯­ä¹‰ç”Ÿæˆä¸ç¬¦å·è§„åˆ™æ‰°åŠ¨ï¼Œæ„å»ºé«˜å¤šæ ·æ€§çš„åˆå§‹æ¨¡æ¿æ± ã€‚
  2. **Template Autoencoder (TAE)**ï¼šå°†ç¦»æ•£çš„æ–‡æœ¬æ¨¡æ¿ç¼–ç åˆ°è¿ç»­çš„æ½œåœ¨ç©ºé—´ï¼Œå®ç°ç»“æ„å¯æœç´¢åŒ–ã€‚
  3. **Latent-space Bayesian Optimization**ï¼šåœ¨è¿ç»­æ½œåœ¨ç©ºé—´ä¸­é«˜æ•ˆæœç´¢æœ€ä¼˜æ”»å‡»å‘é‡ï¼Œè§£ç åå¾—åˆ°é«˜å¨åŠ›æ”»å‡»æ¨¡æ¿ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´é«˜çš„æ”»å‡»æˆåŠŸç‡ (ASR)**ï¼šåœ¨å¤šä¸ª SOTA é—­æºæ¨¡å‹ä¸Šæ˜¾è‘—è¶…è¶Šè¯­ä¹‰æ³¨å…¥å’Œé™æ€æ¨¡æ¿æ–¹æ³•ã€‚
- **æ›´å¼ºçš„è·¨æ¨¡å‹å¯è¿ç§»æ€§**ï¼šä¸ä¾èµ–ç‰¹å®šè¯­ä¹‰è¡¨è¾¾ï¼Œæ”»å‡»åŸºäºé€šç”¨çš„æ¨¡æ¿è§£æé€»è¾‘ï¼Œå› æ­¤èƒ½æœ‰æ•ˆç©¿é€ä¸åŒå‚å•†çš„æ¨¡å‹ã€‚
- **ç»•è¿‡ä¸»æµé˜²å¾¡æœºåˆ¶**ï¼šå¯¹åŸºäºæŒ‡ä»¤çš„é˜²å¾¡ï¼ˆå¦‚ Delimiter Spotlightingï¼‰ã€æ ‡ç­¾è¿‡æ»¤ï¼ˆTag Filterï¼‰ç”šè‡³åŸºäº DeBERTa çš„è¯­ä¹‰æ£€æµ‹å™¨å‡è¡¨ç°å‡ºå¼ºé²æ£’æ€§ã€‚
- **è‡ªåŠ¨åŒ–ä¸å¯æ‰©å±•æ€§**ï¼šæ— éœ€äººå·¥è®¾è®¡ï¼Œå¯ç³»ç»Ÿæ€§åœ°å‘ç°æ–°å‹ç»“æ„æ¼æ´ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **AgentDojo**ï¼šä½œä¸ºä¸»è¦è¯„æµ‹åŸºå‡†ï¼ŒåŒ…å« 97 ä¸ªçœŸå®ç”¨æˆ·ä»»åŠ¡å’Œ 629 ä¸ªå¯¹æŠ—æµ‹è¯•ç”¨ä¾‹ï¼Œè¦†ç›– Workspaceã€Travelã€Slackã€Banking å››å¤§åœºæ™¯ã€‚
- **è‡ªå»ºæ¨¡æ¿åº“**ï¼šä»å¼€æºæ¸ é“æ”¶é›† 78 ä¸ªæ ‡å‡† Chat Template ä½œä¸ºç§å­ã€‚
- **çœŸå®ä¸–ç•Œè¯„ä¼°**ï¼šåœ¨ä¸€å®¶å¤§å‹ç§‘æŠ€ä¼ä¸šåŸºç¡€è®¾æ–½ä¸­éƒ¨ç½²ï¼Œè¯„ä¼°äº† **942 ä¸ªå•†ç”¨ Agent**ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
#### è¯„ä¼°æŒ‡æ ‡
- **Attack Success Rate (ASR)**ï¼šæˆåŠŸè§¦å‘æ¶æ„è¡Œä¸ºçš„æ ·æœ¬æ¯”ä¾‹ã€‚
- **Utility Score**ï¼šåœ¨å­˜åœ¨æ”»å‡»çš„æƒ…å†µä¸‹ï¼Œä»£ç†ä»èƒ½å®ŒæˆåŸå§‹ä»»åŠ¡çš„æ¯”ä¾‹ï¼Œè¡¡é‡æ”»å‡»çš„éšè”½æ€§ã€‚

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | æè¿° |
|--------|------|
| **Semantic-Injection** | ä½¿ç”¨ `<INFORMATION>` ç­‰æ ‡ç­¾å°è£…æ¶æ„æŒ‡ä»¤çš„ç»å…¸ IPI æ–¹æ³•ã€‚ |
| **Single-Template** | ä½¿ç”¨å¼€æºå¯¹åº”æ¨¡å‹ï¼ˆå¦‚ Qwen3/GPT-OSSï¼‰çš„å›ºå®šæ¨¡æ¿è¿›è¡Œæ”»å‡»ã€‚ |
| **ChatInject** | åˆ©ç”¨èŠå¤©æ¨¡æ¿æ¨¡æ‹Ÿå¤šè½®å¯¹è¯å†å²çš„ç»“æ„åŒ–æ”»å‡»æ–¹æ³•ã€‚ |

æ‰€æœ‰æ–¹æ³•åœ¨ç›¸åŒè¯­ä¹‰è´Ÿè½½ä¸‹æ¯”è¾ƒï¼Œä»¥éš”ç¦»ç»“æ„å·®å¼‚çš„å½±å“ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
åœ¨ **AgentDojo** ä¸Šå¯¹ 7 ä¸ªé—­æºæ¨¡å‹å’Œ 1 ä¸ªå¼€æºæ¨¡å‹çš„ç»¼åˆè¯„ä¼°æ˜¾ç¤ºï¼š

| æ–¹æ³• | å¹³å‡ ASR |
|------|--------|
| **Phantom** | **79.76%** |
| Single-Template | 54.09% |
| Semantic-Injection | 39.86% |
| ChatInject | 38.46% |

Phantom åœ¨æ‰€æœ‰æ¨¡å‹ä¸Šå‡å–å¾—å‹å€’æ€§ä¼˜åŠ¿ï¼Œå°¤å…¶åœ¨ **GPT-4.1** ä¸Šè¾¾åˆ° **75.97%** çš„ ASRã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- Phantom çš„ ASR æ¯”æœ€å¼ºåŸºçº¿ **Single-Template** é«˜å‡º **25.67%**ã€‚
- åœ¨å¤æ‚åœºæ™¯ï¼ˆå¦‚ Workspaceï¼‰ä¸­ï¼ŒPhantom ä¾ç„¶ä¿æŒé¢†å…ˆï¼Œè¯æ˜å…¶ç»“æ„æ”»å‡»çš„æ™®é€‚æ€§ã€‚
- å‘ç°â€œèƒ½åŠ›è¯…å’’â€ï¼ˆcapability curseï¼‰ç°è±¡ï¼š**æ¨¡å‹è¶Šå¼ºå¤§ï¼Œè¶Šå®¹æ˜“è¢«ç»“æ„åŒ–æ”»å‡»åŠ«æŒ**ã€‚ä¾‹å¦‚ GPT-4.1 æ¯” GPT-4o æ›´è„†å¼±ï¼Œå› å…¶æ›´å¼ºçš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›åè€Œæ›´å¿ å®åœ°æ‰§è¡Œäº†æ³¨å…¥çš„æ¶æ„ç»“æ„ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### é˜²å¾¡æœ‰æ•ˆæ€§è¯„ä¼°ï¼ˆTable 2 & 3ï¼‰
| é˜²å¾¡æœºåˆ¶ | Phantom è¡¨ç° |
|--------|-------------|
| **Delimiter Spotlighting** | å‡ ä¹æ— æ•ˆï¼ŒASR ä»…è½»å¾®ä¸‹é™ï¼ˆå¦‚ GPT-4.1 ä» 75.97% â†’ 76.62%ï¼‰ã€‚ |
| **Tag Filter** | æ•ˆæœæœ‰é™ï¼ŒPhantom ä»å¯è¾¾ 50%+ ASRï¼Œå› å…¶èƒ½ç”Ÿæˆè§„é¿è§„åˆ™çš„å˜ä½“ã€‚ |
| **Injection Detector (DeBERTa)** | èƒ½æŠ‘åˆ¶ ASRï¼Œä½†ä»£ä»·å·¨å¤§â€”â€”**Utility Score æš´è·Œè‡³ 15.58%**ï¼Œè¯´æ˜æ— æ³•åŒºåˆ†å¤æ‚æŒ‡ä»¤ä¸ç»“æ„æ”»å‡»ã€‚ |

#### ç»“æ„å¿…è¦æ€§åˆ†æï¼ˆTable 4ï¼‰
é€šè¿‡æ‰°åŠ¨æ¨¡æ¿ç»“æ„éªŒè¯å…¶ä½œç”¨ï¼š
- ç§»é™¤æ‹¬å·æˆ–æ•´ä¸ªæ¨¡æ¿ â†’ ASR æ¥è¿‘ 0%ï¼Œæ³¨æ„åŠ›å›å½’ç”¨æˆ·æç¤ºã€‚
- ä»…æ”¹å˜ token åŒ–æ–¹å¼ï¼ˆå¦‚ HTML ç¼–ç ï¼‰â†’ ASR ä»é«˜è¾¾ 46.29%ï¼Œè¯æ˜æ”»å‡»ä¾èµ–çš„æ˜¯**é€šç”¨è¯­æ³•ç»“æ„å…ˆéªŒ**ï¼Œè€Œéç‰¹å®š tokenã€‚

#### è¶…å‚æ•°åˆ†æ
- **æœç´¢è¿­ä»£æ•°**ï¼šçº¦ 40 æ¬¡è¿­ä»£å³å¯æ”¶æ•›ï¼Œæ»¡è¶³ä½æŸ¥è¯¢é¢„ç®—ä¸‹çš„é«˜æ•ˆæ”»å‡»ã€‚
- **æ½œåœ¨ç©ºé—´ç»´åº¦**ï¼šASR åœ¨ä¸­é—´ç»´åº¦ï¼ˆå¦‚ 24ï¼‰è¾¾åˆ°å³°å€¼ï¼Œè¿‡é«˜ç»´åº¦åè€Œä¸åˆ©äºä¼˜åŒ–ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ ¹æœ¬æ€§æ¶æ„æ¼æ´**ï¼šå½“å‰ LLM Agent å°†æ§åˆ¶ token ä¸å†…å®¹ token æ··åˆå¤„ç†ï¼Œå¯¼è‡´ **Role Confusion** æˆä¸ºç³»ç»Ÿæ€§é£é™©ã€‚
2. **ç»“æ„ > è¯­ä¹‰**ï¼š**Syntactic attacks** å¯ç»•è¿‡ä¸»æµåŸºäºè¯­ä¹‰çš„é˜²å¾¡ä½“ç³»ï¼Œæ„æˆå¯¹å½“å‰å®‰å…¨èŒƒå¼çš„æ ¹æœ¬æ€§æŒ‘æˆ˜ã€‚
3. **è‡ªåŠ¨åŒ–å¯è¡Œ**ï¼šé€šè¿‡ TAE + Bayesian Optimization çš„ç»„åˆï¼Œå¯åœ¨é»‘ç›’æ¡ä»¶ä¸‹é«˜æ•ˆå‘ç°é«˜å¨åŠ›æ”»å‡»æ¨¡æ¿ã€‚
4. **çœŸå®ä¸–ç•Œå±å®³ä¸¥é‡**ï¼šåœ¨ 942 ä¸ªå•†ç”¨ Agent ä¸­å‘ç° **70+ æ¼æ´**ï¼Œæ¶µç›–æ•°æ®æ³„éœ²ã€RCE ç­‰é«˜å±è¡Œä¸ºï¼Œå¹¶ç¡®è®¤å½±å“ **OpenHands** å’Œ **AutoGen** ç­‰ä¸»æµæ¡†æ¶ï¼ˆCVE-2025-6***4ï¼‰ã€‚
5. **èƒ½åŠ›ä¸è„†å¼±æ€§æ­£ç›¸å…³**ï¼šæ›´å¼ºçš„æ¨¡å‹å› æ›´ä¸¥æ ¼éµå¾ªç»“æ„åè®®è€Œæ›´æ˜“è¢«åŠ«æŒï¼Œå½¢æˆâ€œèƒ½åŠ›è¯…å’’â€ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **æ¨¡æ€é™åˆ¶**ï¼šç›®å‰ä»…é€‚ç”¨äºæ–‡æœ¬è¾“å…¥ï¼Œæœªè€ƒè™‘å¤šæ¨¡æ€ Agentï¼ˆvision/audioï¼‰çš„æ½œåœ¨æ”»å‡»é¢ã€‚
- **é»‘ç›’å‡è®¾**ï¼šå‡è®¾æ— å†…éƒ¨çŸ¥è¯†ï¼Œè‹¥æ”»å‡»è€…æŒæ¡æ¨¡æ¿ç»†èŠ‚ï¼Œå¯èƒ½æ„é€ æ›´å¼ºæ”»å‡»ã€‚
- **é€Ÿç‡é™åˆ¶**ï¼šä¾èµ–å¤šæ¬¡ API æŸ¥è¯¢ï¼Œåœ¨æœ‰ä¸¥æ ¼é™æµæˆ–å¼‚å¸¸æ£€æµ‹çš„ç³»ç»Ÿä¸­å¯èƒ½å—é™ã€‚
- **é•¿æœŸæŒä¹…æ€§**ï¼šæœªè¯„ä¼°æ”»å‡»åœ¨é•¿å‘¨æœŸå¯¹è¯çŠ¶æ€ç®¡ç†ä¸­çš„æŒç»­æ•ˆæœã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **å¼€å‘ç»“æ„æ€§é˜²å¾¡åŸè¯­**ï¼šå¦‚ç¡¬ä»¶è¾…åŠ©çš„ token éš”ç¦»ã€å½¢å¼åŒ–éªŒè¯çš„æ¨¡æ¿è§£æå™¨ã€‚
- **æ‰©å±•è‡³å¤šæ¨¡æ€ç¯å¢ƒ**ï¼šç ”ç©¶è·¨æ¨¡æ€ç»“æ„æ³¨å…¥æ”»å‡»ï¼ˆå¦‚å›¾åƒå…ƒæ•°æ®ä¸­åµŒå…¥æ§åˆ¶ tokenï¼‰ã€‚
- **å»ºç«‹æ ‡å‡†åŒ–åŸºå‡†**ï¼šæ¨åŠ¨ç¤¾åŒºå»ºç«‹ä¸“é—¨è¯„ä¼° Agent å¯¹ç»“æ„æ”»å‡»é²æ£’æ€§çš„ Benchmarkã€‚
- **æ¢ç´¢åˆå§‹åŒ–ä¼˜åŒ–**ï¼šæ”¹è¿›åˆå§‹æ¨¡æ¿é€‰æ‹©ç­–ç•¥ï¼Œæå‡æœç´¢æ•ˆç‡ä¸ç¨³å®šæ€§ã€‚

> **æ€»ç»“**ï¼šPhantom æ­ç¤ºäº† LLM Agent æ¶æ„ä¸­çš„ä¸€ä¸ªæ·±å±‚ç»“æ„æ€§ç¼ºé™·ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•é€šè¿‡è‡ªåŠ¨åŒ–æ–¹æ³•ç³»ç»Ÿæ€§åœ°åˆ©ç”¨è¯¥ç¼ºé™·ã€‚å…¶å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰ä»¥è¯­ä¹‰å¯¹é½ä¸ºæ ¸å¿ƒçš„é˜²å¾¡ä½“ç³»åœ¨é¢å¯¹ç»“æ„åŒ–æ”»å‡»æ—¶å­˜åœ¨æ ¹æœ¬æ€§ä¸è¶³ï¼ŒäºŸéœ€è½¬å‘â€œæ¶æ„çº§å®‰å…¨â€è®¾è®¡ã€‚

</details>

---

### 5. [Retrospective In-Context Learning for Temporal Credit Assignment with Large Language Models](https://arxiv.org/abs/2602.17497)

**Authors**: Wen-Tse Chen, Jiayu Chen, Fahim Tajwar, Hao Zhu, Xintong Duan, Ruslan Salakhutdinov, Jeff Schneider  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.17497v1  

#### Abstract
Learning from self-sampled data and sparse environmental feedback remains a fundamental challenge in training self-evolving agents. Temporal credit assignment mitigates this issue by transforming sparse feedback into dense supervision signals. However, previous approaches typically depend on learnin...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRetrospective In-Context Learning for Temporal Credit Assignment with Large Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡æ—¨åœ¨è§£å†³**åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆonline RLï¼‰ä¸­ç¨€ç–ç¯å¢ƒåé¦ˆï¼ˆsparse environmental feedbackï¼‰å¯¼è‡´çš„å­¦ä¹ æ•ˆç‡ä½ä¸‹å’Œè®­ç»ƒä¸ç¨³å®š**çš„é—®é¢˜ã€‚åœ¨å¤šè½®å†³ç­–ä»»åŠ¡ï¼ˆmulti-turn settingsï¼‰ä¸­ï¼Œæ™ºèƒ½ä½“é€šå¸¸éœ€è¦æ‰§è¡Œä¸€ç³»åˆ—æ­£ç¡®åŠ¨ä½œæ‰èƒ½è·å¾—å¥–åŠ±ï¼Œè¿™ä½¿å¾—ä¼ ç»Ÿçš„æ—¶åºä¿¡ç”¨åˆ†é…ï¼ˆtemporal credit assignmentï¼‰æ–¹æ³•éš¾ä»¥é«˜æ•ˆåœ°å°†ç¨€ç–å¥–åŠ±è½¬åŒ–ä¸ºå¯†é›†çš„ç›‘ç£ä¿¡å·ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸¤ç§æ ¸å¿ƒæ–¹æ³•ï¼š

- **RICL (Retrospective In-Context Learning)**  
  ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„**å›æº¯å¼ä¸Šä¸‹æ–‡å†…å­¦ä¹ ç®—æ³•**ï¼Œç”¨äºè¿›è¡Œæ—¶åºä¿¡ç”¨åˆ†é…ã€‚RICL åˆ©ç”¨é¢„è®­ç»ƒ LLM çš„çŸ¥è¯†ï¼Œé€šè¿‡åˆ†æå•æ¡è½¨è¿¹çš„â€œäº‹åâ€ç»éªŒï¼ˆhindsight trajectoryï¼‰ï¼Œç”Ÿæˆé’ˆå¯¹æ¯ä¸ªçŠ¶æ€-åŠ¨ä½œå¯¹çš„**å¯†é›†ä¼˜åŠ¿å‡½æ•°ä¼°è®¡**ï¼ˆadvantage functionï¼‰ã€‚å…¶ç†è®ºåŸºç¡€æ˜¯ï¼šæ¯”è¾ƒåŸå§‹ç­–ç•¥ $\pi_0$ å’Œç»è¿‡ in-context æ›´æ–°åçš„ç­–ç•¥ $\pi'$ çš„ log-probability å·®å¼‚ï¼Œå¯ä»¥æ¨å¯¼å‡ºå¯¹åº”çš„ä¼˜åŠ¿å‡½æ•° $A(s,a)$ã€‚

- **RICOL (Retrospective In-Context Online Learning)**  
  ä¸€ä¸ªå®Œæ•´çš„**åœ¨çº¿å­¦ä¹ æ¡†æ¶**ï¼Œç»“åˆ RICL è¿›è¡Œç­–ç•¥è¯„ä¼°ï¼Œå¹¶ä½¿ç”¨ **Advantage Weighted Regression (AWR)** è¿›è¡Œç­–ç•¥æ”¹è¿›ã€‚RICOL è¿­ä»£åœ°åˆ©ç”¨ RICL äº§ç”Ÿçš„å¯†é›†ä¼˜åŠ¿ä¿¡å·æ¥å¾®è°ƒ LLM ç­–ç•¥ï¼Œå®ç°é«˜æ•ˆçš„è‡ªæˆ‘è¿›åŒ–ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´é«˜çš„æ ·æœ¬æ•ˆç‡ï¼ˆsample efficiencyï¼‰**ï¼šç›¸æ¯”ä¼ ç»Ÿ Monte Carlo æ–¹æ³•ä¼°è®¡ä¼˜åŠ¿å‡½æ•°ï¼ŒRICL åœ¨ 1D Key-Door ç¯å¢ƒä¸­å®ç°äº†çº¦ **100Ã— çš„æ ·æœ¬æ•ˆç‡æå‡**ã€‚
- **æ›´ç²¾ç»†çš„ä¿¡ç”¨åˆ†é…**ï¼šä¸åŒäºä»…æä¾›è½¨è¿¹çº§åé¦ˆçš„æ–¹æ³•ï¼ˆå¦‚ Reflexionï¼‰ï¼ŒRICL ä¸ºæ¯ä¸ªæ—¶é—´æ­¥ç”ŸæˆçŠ¶æ€ç‰¹å®šçš„åé¦ˆï¼Œèƒ½è¯†åˆ«å‡ºæ›´ç»†ç²’åº¦çš„å…³é”®çŠ¶æ€ã€‚
- **æ— éœ€é¢å¤–è®­ç»ƒåå°„å™¨ç½‘ç»œ**ï¼šä¸éœ€è¦å¾®è°ƒé¢å¤– reflector çš„æ–¹æ³•ï¼ˆå¦‚ Retroformerï¼‰ä¸åŒï¼ŒRICOL ä½¿ç”¨å›ºå®šçš„ LLM ä½œä¸º reflectorï¼Œä»…æ›´æ–° actor ç­–ç•¥ï¼Œç®€åŒ–äº†æµç¨‹ã€‚
- **æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›**ï¼šåˆ©ç”¨ LLM çš„é¢„è®­ç»ƒçŸ¥è¯†ï¼Œé¿å…ä»é›¶å¼€å§‹å­¦ä¹ ä»·å€¼å‡½æ•°ï¼Œæå‡äº†è·¨ä»»åŠ¡çš„é€‚åº”æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **1D Key-Door Environment**ï¼šä¸€ä¸ªä¸€ç»´ç½‘æ ¼ä¸–ç•Œï¼Œä»£ç†éœ€å…ˆå‘å·¦å–é’¥åŒ™ï¼Œå†å‘å³å¼€é—¨ã€‚è¯¥ç¯å¢ƒå…è®¸ç²¾ç¡®è®¡ç®— ground-truth ä¼˜åŠ¿å‡½æ•°ï¼Œç”¨äºéªŒè¯ RICL çš„å‡†ç¡®æ€§ã€‚
- **BabyAI å¹³å°ä¸Šçš„å››ä¸ªä»»åŠ¡**ï¼š
  - `goto`ï¼šå¯¼èˆªåˆ°æŒ‡å®šç‰©ä½“
  - `pickup`ï¼šæ‹¾å–æŒ‡å®šç‰©ä½“
  - `pick_up_seq_go_to`ï¼šæŒ‰é¡ºåºæ‹¾å–å¹¶å‰å¾€ç›®æ ‡
  - `open`ï¼šæ‰“å¼€é—¨
  æ‰€æœ‰è¾“å…¥è¾“å‡ºå‡ä»¥æ–‡æœ¬å½¢å¼å‘ˆç°ï¼ŒåŠ¨ä½œç©ºé—´ç¦»æ•£ä¸”å¯æšä¸¾ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **Actor æ¨¡å‹**ï¼šLLaMA-3.2-3B-Instruct æˆ– LLaMA-3.1-8B-Instruct
- **Reflector æ¨¡å‹**ï¼šGPT-4o mini
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Success Rate**ï¼šä»»åŠ¡å®Œæˆç‡
  - **Environment Steps (Env Steps)**ï¼šäº¤äº’æ­¥æ•°ï¼Œè¡¡é‡æ ·æœ¬æ•ˆç‡
  - **Training Time**ï¼šè®­ç»ƒè€—æ—¶ï¼ˆè§ Table 2ï¼‰
- **è¶…å‚æ•°**ï¼šé‡å¤ä¸‰æ¬¡éšæœºç§å­å®éªŒï¼ŒæŠ¥å‘Šå‡å€¼ä¸æ ‡å‡†å·®ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **GPT-4o mini** | Zero-shot | ä½¿ç”¨ reflector æ¨¡å‹æœ¬èº«ä½œä¸ºç­–ç•¥ï¼Œæµ‹è¯•é›¶æ ·æœ¬æ€§èƒ½ |
| **Reflexion** | In-context Learning | åŸºäºè½¨è¿¹çº§åé¦ˆè¿­ä»£è‡ªçœï¼Œä¸æ›´æ–°æ¨¡å‹å‚æ•° |
| **PPO (3B)** | Online RL | å¾®è°ƒ Qwen2.5-3B-Instruct æ¨¡å‹ï¼Œä½¿ç”¨ PPO ç®—æ³• |
| **PPO (10M)** | Online RL | ä½¿ç”¨ä¸¤å±‚ MLP ç½‘ç»œä»å¤´è®­ç»ƒï¼Œæ— é¢„è®­ç»ƒçŸ¥è¯† |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- åœ¨ **1D Key-Door** ç¯å¢ƒä¸­ï¼š
  - RICL ä»…éœ€ **çº¦ 10 æ¡è½¨è¿¹**å³å¯è¾¾åˆ°ä¸ Monte Carlo æ–¹æ³•ä½¿ç”¨ **1000 æ¡è½¨è¿¹**ç›¸å½“çš„ä¼˜åŠ¿å‡½æ•°ä¼°è®¡ç²¾åº¦ï¼ˆè§ Figure 2ï¼‰ã€‚
  - RICL èƒ½å‡†ç¡®è¯†åˆ«å…³é”®çŠ¶æ€ï¼ŒåŒ…æ‹¬â€œæ‹¾å–é’¥åŒ™â€ä»¥åŠæ—©æœŸâ€œç§»åŠ¨å‘é’¥åŒ™â€çš„å…³é”®å†³ç­–ç‚¹ï¼ˆè§ Figure 13ï¼‰ã€‚

- åœ¨ **BabyAI å››ä¸ªä»»åŠ¡**ä¸Šï¼ˆè§ Figure 4ï¼‰ï¼š
  - **RICOL æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•**ï¼Œåœ¨æ›´å°‘çš„ç¯å¢ƒäº¤äº’ä¸‹è¾¾åˆ°æ›´é«˜æˆåŠŸç‡ã€‚
  - ç›¸æ¯” **PPO (3B)**ï¼ŒRICOL è¾¾åˆ°ç›¸ä¼¼æ€§èƒ½æ‰€éœ€ç¯å¢ƒæ­¥æ•°å‡å°‘ **çº¦ 10Ã—**ã€‚
  - ç›¸æ¯” **PPO (10M)**ï¼Œå‡å°‘ **çº¦ 50Ã—** çš„æ ·æœ¬é‡ã€‚
  - å³ä½¿ä½¿ç”¨æ›´å°çš„ 3B æ¨¡å‹ï¼ŒRICOL ä»**è¶…è¶Š GPT-4o mini çš„è¡¨ç°**ï¼Œè¯´æ˜äº¤äº’å­¦ä¹ çš„é‡è¦æ€§ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **vs Reflexion**ï¼š  
  Reflexion è™½ç„¶æ ·æœ¬é«˜æ•ˆï¼Œä½†æ€§èƒ½å¾ˆå¿«é¥±å’Œã€‚å› å…¶ä¾èµ–é€šç”¨è½¨è¿¹çº§è§„åˆ™ï¼Œæ— æ³•æ•æ‰çŠ¶æ€çº§ç»†èŠ‚ã€‚è€Œ RICOL é€šè¿‡ RICL æä¾›å¯†é›†ã€çŠ¶æ€ç‰¹å®šçš„ç›‘ç£ä¿¡å·ï¼ŒæŒç»­æ”¹è¿›ç­–ç•¥ã€‚
  
- **vs PPO æ–¹æ³•**ï¼š  
  PPO éœ€è¦å¤§é‡é‡‡æ ·è¿›è¡Œä»·å€¼å‡½æ•°ä¼°è®¡ï¼Œå°¤å…¶æ˜¯ä»å¤´è®­ç»ƒæ—¶ï¼ˆPPO 10Mï¼‰æä½æ•ˆã€‚RICOL åˆ©ç”¨ LLM çš„é¢„è®­ç»ƒçŸ¥è¯†ç›´æ¥ç”Ÿæˆä¼˜åŠ¿ä¿¡å·ï¼Œæ˜¾è‘—é™ä½æ ·æœ¬éœ€æ±‚ã€‚

- **vs RWR (Reward-Weighted Regression)**ï¼š  
  RWR ç›´æ¥ä½¿ç”¨è½¨è¿¹çº§å¥–åŠ±ï¼Œç¼ºä¹æ—¶åºä¿¡ç”¨åˆ†é…ã€‚å®éªŒæ˜¾ç¤ºï¼ˆFigure 5ï¼‰ï¼ŒRWR åªåœ¨åˆå§‹æˆåŠŸç‡è¾ƒé«˜çš„ `goto` ä»»åŠ¡ä¸­æœ‰æ•ˆï¼Œåœ¨å…¶ä»–ç¨€ç–å¥–åŠ±ä»»åŠ¡ä¸­è¡¨ç°å·®ï¼Œå‡¸æ˜¾äº† RICL è¿›è¡Œ credit assignment çš„å¿…è¦æ€§ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **åé¦ˆå¯é æ€§å®éªŒï¼ˆFigure 6ï¼‰**ï¼š  
  å³ä½¿äººä¸ºæ³¨å…¥å™ªå£°ä½¿ verbal feedback å‡†ç¡®ç‡é™è‡³ **70%**ï¼ŒRICOL ä»èƒ½ä¿æŒè‰¯å¥½æ€§èƒ½ã€‚è¿™å½’åŠŸäºæŸå¤±å‡½æ•°ä¸­çš„ **trust region constraint**ï¼ˆç”± KL æ­£åˆ™é¡¹å¼•å…¥ï¼‰ï¼Œå¢å¼ºäº†å¯¹å™ªå£°åé¦ˆçš„é²æ£’æ€§ã€‚
- **å›æº¯æ›´æ–° vs æ ‡å‡† ICLï¼ˆFigure 3ï¼‰**ï¼š  
  åœ¨ BabyAI `goto` ä»»åŠ¡ä¸­ï¼Œ**RICL æ¯”æ ‡å‡† ICL é«˜å‡º 7.2% çš„å‡†ç¡®ç‡**ï¼Œè¯æ˜â€œå›æº¯å¼â€æ›´æ–°ï¼ˆä»…åœ¨äº§ç”Ÿåé¦ˆçš„åŒä¸€æ¡è½¨è¿¹ä¸Šåº”ç”¨ï¼‰æ¯”æ³›åŒ–åˆ°æ–°è½¨è¿¹æ›´å¯é æœ‰æ•ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
- **LLM çš„é¢„è®­ç»ƒçŸ¥è¯†å¯ç”¨äºé«˜æ•ˆçš„æ—¶åºä¿¡ç”¨åˆ†é…**ï¼šé€šè¿‡ RICLï¼Œç¨€ç–å¥–åŠ±å¯è¢«è½¬åŒ–ä¸ºå¯†é›†çš„ä¼˜åŠ¿å‡½æ•°ï¼Œæå¤§æå‡æ ·æœ¬æ•ˆç‡ã€‚
- **å›æº¯å¼ in-context learning æ›´ç¨³å®šå¯é **ï¼šå°†åé¦ˆåº”ç”¨äºåŒä¸€è½¨è¿¹çš„çŠ¶æ€ï¼Œé¿å…äº†è¿‡åº¦æ³›åŒ–å¸¦æ¥çš„ä¸ç¨³å®šæ€§ã€‚
- **RICOL æ˜¯ä¸€ç§é«˜æ ·æœ¬æ•ˆç‡çš„åœ¨çº¿å­¦ä¹ èŒƒå¼**ï¼šåœ¨è¯­è¨€æ¡ä»¶ä¸‹çš„ç¨€ç–å¥–åŠ±ä»»åŠ¡ä¸­ï¼ŒRICOL æ˜¾è‘—ä¼˜äºä¼ ç»Ÿ RL å’Œçº¯ in-context æ–¹æ³•ã€‚
- **æ–¹æ³•å¯¹å™ªå£°åé¦ˆå…·æœ‰é²æ£’æ€§**ï¼štrust region è®¾è®¡ä½¿å¾—ç®—æ³•èƒ½åœ¨ä¸å®Œç¾åé¦ˆä¸‹ä¾ç„¶æœ‰æ•ˆå­¦ä¹ ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä»…æ”¯æŒç¦»æ•£æœ‰é™åŠ¨ä½œç©ºé—´**ï¼šå› éœ€æšä¸¾æ‰€æœ‰åŠ¨ä½œè®¡ç®— KL æ•£åº¦å’Œå½’ä¸€åŒ–é¡¹ $Z(s)$ã€‚å¯¹äºè¿ç»­æˆ–æå¤§åŠ¨ä½œç©ºé—´ï¼ˆå¦‚é•¿æ€ç»´é“¾ï¼‰ï¼Œéœ€æ”¹ç”¨é‡‡æ ·è¿‘ä¼¼ã€‚
- **ä¾èµ–é«˜è´¨é‡çš„ reflector LLM**ï¼šè™½ç„¶æœªå¾®è°ƒ reflectorï¼Œä½†å…¶æ¨ç†èƒ½åŠ›ç›´æ¥å½±å“åé¦ˆè´¨é‡ã€‚
- **å½“å‰å®éªŒé›†ä¸­åœ¨å°å‹ä»»åŠ¡**ï¼šå°šæœªåœ¨å¤§è§„æ¨¡çœŸå®ä¸–ç•Œä»»åŠ¡æˆ– token-level MDP ä¸ŠéªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† RICOL æ‰©å±•è‡³ **token-level MDPs** å’Œå¤æ‚æ¨ç†ä»»åŠ¡ã€‚
- æ¢ç´¢åœ¨ **è¿ç»­åŠ¨ä½œç©ºé—´** ä¸­çš„åº”ç”¨ï¼Œä¾‹å¦‚é€šè¿‡åŠ¨ä½œé‡‡æ ·æ›¿ä»£æšä¸¾ã€‚
- ç ”ç©¶å¦‚ä½•è¿›ä¸€æ­¥é™ä½å¯¹ reflector æ¨¡å‹èƒ½åŠ›çš„ä¾èµ–ã€‚
- å°†è¯¥æ¡†æ¶åº”ç”¨äºå…·èº«æ™ºèƒ½ï¼ˆembodied agentsï¼‰æˆ–å¤šæ¨¡æ€åœºæ™¯ã€‚

--- 

> **æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºçš„ **RICL** å’Œ **RICOL** ä¸º LLM æ™ºèƒ½ä½“çš„åœ¨çº¿è‡ªæˆ‘è¿›åŒ–æä¾›äº†æ–°çš„é«˜æ•ˆè·¯å¾„ï¼Œé€šè¿‡å·§å¦™åˆ©ç”¨ LLM çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›å®ç°é«˜ç²¾åº¦ã€é«˜æ•ˆç‡çš„æ—¶åºä¿¡ç”¨åˆ†é…ï¼Œæ¨åŠ¨äº†æ›´å…·æ³›åŒ–æ€§å’Œæ ·æœ¬æ•ˆç‡çš„ RL èŒƒå¼å‘å±•ã€‚

</details>

---

### 6. [DeepContext: Stateful Real-Time Detection of Multi-Turn Adversarial Intent Drift in LLMs](https://arxiv.org/abs/2602.16935)

**Authors**: Justin Albrethsen, Yash Datta, Kunal Kumar, Sharath Rajasekar  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.16935v1  

#### Abstract
While Large Language Model (LLM) capabilities have scaled, safety guardrails remain largely stateless, treating multi-turn dialogues as a series of disconnected events. This lack of temporal awareness facilitates a "Safety Gap" where adversarial tactics, like Crescendo and ActorAttack, slowly bleed ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠDeepContext: Stateful Real-Time Detection of Multi-Turn Adversarial Intent Drift in LLMsã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰ä¸»æµçš„ LLM å®‰å…¨é˜²æŠ¤æœºåˆ¶ï¼ˆå¦‚ Llama Guardã€Granite Guardianï¼‰å¤§å¤šæ˜¯**stateless**ï¼ˆæ— çŠ¶æ€ï¼‰çš„ï¼Œå³åœ¨å¤šè½®å¯¹è¯ä¸­å°†æ¯ä¸€è½®è§†ä¸ºç‹¬ç«‹äº‹ä»¶è¿›è¡Œå®‰å…¨æ£€æµ‹ã€‚è¿™ç§è®¾è®¡å­˜åœ¨â€œ**Safety Gap**â€â€”â€”æ”»å‡»è€…åˆ©ç”¨ **Crescendo** å’Œ **ActorAttack** ç­‰å¤šè½®å¯¹æŠ—ç­–ç•¥ï¼Œé€šè¿‡è¯­ä¹‰æ¼‚ç§»ï¼ˆsemantic driftï¼‰é€æ­¥å¼•å¯¼æ¨¡å‹åç¦»å®‰å…¨è¾¹ç•Œï¼Œè€Œå•è½®æ£€æµ‹æ— æ³•æ•æ‰è¿™ç§æ¸è¿›å¼çš„æ¶æ„æ„å›¾ç§¯ç´¯ã€‚

æ­¤å¤–ï¼Œç°æœ‰é˜²å¾¡æ–¹æ¡ˆå¸¸é‡‡ç”¨â€œ**transcript concatenation**â€æ–¹å¼ï¼Œå°†æ•´ä¸ªå¯¹è¯å†å²é‡æ–°è¾“å…¥å¤§æ¨¡å‹è¿›è¡Œé‡è¯„ä¼°ï¼Œå¯¼è‡´è®¡ç®—å¼€é”€éšå¯¹è¯é•¿åº¦å‘ˆäºŒæ¬¡å¢é•¿ï¼ˆquadratic costï¼‰ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶åº”ç”¨éœ€æ±‚ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **DeepContext**ï¼Œä¸€ç§**stateful**ï¼ˆæœ‰çŠ¶æ€ï¼‰çš„å®æ—¶ç›‘æ§æ¡†æ¶ï¼Œç”¨äºè¿½è¸ªç”¨æˆ·æ„å›¾åœ¨å¤šè½®å¯¹è¯ä¸­çš„æ¼”åŒ–è½¨è¿¹ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†å®‰å…¨æ£€æµ‹å»ºæ¨¡ä¸ºä¸€ä¸ª**çŠ¶æ€ç©ºé—´é—®é¢˜**ï¼ˆstate-space problemï¼‰ï¼Œç»´æŠ¤ä¸€ä¸ªæŒç»­æ›´æ–°çš„éšè—çŠ¶æ€ $ h_t $ æ¥è¡¨å¾ç´¯ç§¯é£é™©ã€‚
- é‡‡ç”¨ **Recurrent Neural Network (RNN)** æ¶æ„ï¼ˆå…·ä½“ä¸º GRUï¼‰ï¼Œé€è½®å¤„ç†å¯¹è¯ï¼Œå®ç°å¯¹â€œ**intent drift**â€çš„åŠ¨æ€æ„ŸçŸ¥ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | DeepContext | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Llama Guardï¼‰ |
|------|-------------|--------------------------|
| **çŠ¶æ€æ€§** | âœ… Statefulï¼šç»´æŠ¤å¯¹è¯è®°å¿† | âŒ Statelessï¼šå­¤ç«‹åˆ¤æ–­æ¯è½® |
| **æ•ˆç‡** | âš¡ï¸ **<20ms** æ¨ç†å»¶è¿Ÿï¼ˆT4 GPUï¼‰ | ğŸ¢ æ•°ç™¾æ¯«ç§’è‡³ç§’çº§å»¶è¿Ÿ |
| **å‡†ç¡®æ€§** | ğŸ† F1: **0.84**ï¼ˆmulti-turnï¼‰ | ğŸ”» æœ€é«˜ä»… 0.67 |
| **å¯æ‰©å±•æ€§** | âœ”ï¸ å›ºå®šå¤§å°éšè—çŠ¶æ€ï¼Œä¸éšå¯¹è¯å˜é•¿è€Œè†¨èƒ€ | âŒ ä¸Šä¸‹æ–‡è¶Šé•¿ï¼Œè®¡ç®—æˆæœ¬è¶Šé«˜ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
#### è®­ç»ƒæ•°æ®é›†ï¼ˆå…± 437,058 æ¡å¯¹è¯åºåˆ—ï¼Œçº¦ 20% æ¶æ„ï¼‰
| æ•°æ®é›† | æè¿° | æ¥æº |
|-------|------|------|
| `LLMail` | é’ˆå¯¹é‚®ä»¶åŠ©æ‰‹çš„ prompt injection æ”»å‡» | [18] |
| `HH-RLHF` | äººç±»æ ‡æ³¨çš„å®‰å…¨åå¥½ä¸çº¢é˜Ÿå¯¹è¯ | [19] |
| `XGuard` | åˆæˆçš„è‡ªé€‚åº”å¤šè½® jailbreak æ”»å‡» | [20] |
| `PRODIGy` | åŸºäºå¥½è±åå‰§æœ¬çš„è§’è‰²æ‰®æ¼”å¯¹è¯ | [21] |
| `DEF CON` | AI Village çº¢é˜ŸæŒ‘æˆ˜èµ›ç”Ÿæˆçš„çœŸå®æ”»å‡»æ ·æœ¬ | [26] |

#### è¯„æµ‹æ•°æ®é›†ï¼ˆå…± 1,010 æ¡ï¼Œè§ Table 3ï¼‰
- **è‰¯æ€§æ•°æ®**ï¼š`LMSYS`, `Glaive`, `Nemotron`, `Anthropic HH-RLHF`ï¼ˆæ¨¡æ‹Ÿé«˜å™ªå£°ç¯å¢ƒï¼‰
- **å¯¹æŠ—æ•°æ®**ï¼š
  - äººå·¥çº¢é˜Ÿï¼š`HarmBench`, `DEFCON 34`
  - è‡ªåŠ¨åŒ–å¤šè½®æ”»å‡»ï¼š`Red Queen`, `XGuard`, `Automated-Multi-Turn`

> æ³¨ï¼šæµ‹è¯•é›†ä¸­æœªåŒ…å«è®­ç»ƒæ—¶è§è¿‡çš„å…·ä½“æ ·æœ¬ï¼Œç¡®ä¿æ³›åŒ–èƒ½åŠ›è¯„ä¼°æœ‰æ•ˆã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **ä»»åŠ¡**ï¼šäºŒåˆ†ç±»å®‰å…¨æ£€æµ‹ï¼ˆSafe / Unsafeï¼‰
- **ä¸»è¦æŒ‡æ ‡**ï¼š
  - **F1 Score**ï¼ˆç»¼åˆè¡¡é‡ç²¾ç¡®ç‡ä¸å¬å›ç‡ï¼‰
  - **Recall**ï¼ˆæ£€å‡ºç‡ï¼Œå°¤å…¶å…³æ³¨å¤æ‚æ”»å‡»ï¼‰
  - **Precision**ï¼ˆè¯¯æŠ¥ç‡ï¼‰
  - **Mean Turns to Detection (MTTD)**ï¼šå¹³å‡åœ¨ç¬¬å‡ è½®è¯†åˆ«å‡ºå¨èƒ
  - **Latency (ms)**ï¼šæ¯è½®æ¨ç†è€—æ—¶ï¼ˆT4 GPUï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¶µç›–ä¸‰å¤§ç±»ä¸»æµé˜²æŠ¤æ–¹æ¡ˆï¼š

| ç±»å‹ | åŸºçº¿æ¨¡å‹ |
|------|--------|
| **è½»é‡ç¼–ç å™¨** | Llama-Prompt-Guard-2-86M, Deberta-v3-Prompt-Injection |
| **ç”Ÿæˆå¼è£åˆ¤æ¨¡å‹** | Llama-Guard-4-12B, Granite-Guardian-3.3-8B, Qwen3Guard-Gen-8B, Gpt5-Nano |
| **äº‘å‚å•†æ‰˜ç®¡æœåŠ¡** | Azure Prompt Shield, AWS Prompt Attack Guardrails, GCP Model Armor |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 4ï¼‰

| Model | F1 Score | Recall | Precision | MTTD |
|-------|----------|--------|-----------|------|
| **DeepContext (Ours)** | **0.84** | **0.83** | **0.86** | **4.24** |
| Llama-Prompt-Guard-2 | 0.67 | 0.60 | 0.76 | 5.83 |
| Granite-Guardian-3.3-8B | 0.67 | 0.57 | 0.83 | 5.03 |
| Gpt5-Nano | 0.65 | 0.55 | 0.81 | 5.73 |
| Azure Prompt Shield | 0.19 | 0.11 | 0.62 | 8.00 |

> âœ… **DeepContext åœ¨ F1 ä¸Šé¢†å…ˆç¬¬äºŒåçº¦ 25%**

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ˜¾è‘—ä¼˜äºæ‰€æœ‰ stateless æ–¹æ³•**ï¼šç‰¹åˆ«æ˜¯åœ¨ Recall ä¸Šè¡¨ç°çªå‡ºï¼ˆ0.83ï¼‰ï¼Œè¯´æ˜èƒ½æœ‰æ•ˆæ•è·ç¼“æ…¢æ¼”åŒ–çš„æ”»å‡»æ¨¡å¼ã€‚
- **è¿œè¶…äº‘å‚å•†æ–¹æ¡ˆ**ï¼šAzure Prompt Shield è™½ Precision è¾ƒé«˜ï¼ˆ0.62ï¼‰ï¼Œä½† Recall æä½ï¼ˆ0.11ï¼‰ï¼Œè¡¨æ˜å…¶å‡ ä¹æ— æ³•è¯†åˆ«å¤šè½®æ”»å‡»ã€‚
- **ä¼˜äºå¤§å‹ LLM è£åˆ¤æ¨¡å‹**ï¼šå°½ç®¡ Llama-Guard-4-12B å‚æ•°è¾¾ 12Bï¼Œä½†åœ¨ full context ä¸‹ F1 ä»…ä¸º 0.42ï¼Œç”šè‡³ä½äºæ»‘çª—ç‰ˆæœ¬ï¼ˆ0.51ï¼‰ï¼Œæ˜¾ç¤ºå…¶æ˜“å—ä¸Šä¸‹æ–‡ç¨€é‡Šå½±å“ã€‚

#### å¤šè½® vs å•è½®æ€§èƒ½å¯¹æ¯”ï¼ˆTable 5ï¼‰
| Model | Full Context | Sliding Window (last 5) |
|-------|--------------|-------------------------|
| Llama-Guard-4-12B | 0.42 | 0.51 |
| Gpt5-Nano | 0.58 | 0.65 |

> ğŸ’¡ è¡¨æ˜ï¼š**æ²¡æœ‰ä¸“é—¨çš„çŠ¶æ€è·Ÿè¸ªæœºåˆ¶ï¼Œå³ä½¿å¤§æ¨¡å‹ä¹Ÿéš¾ä»¥ä»å®Œæ•´ä¸Šä¸‹æ–‡ä¸­æå–æœ‰æ•ˆä¿¡å·**

### å•è½® jailbreak æ€§èƒ½ï¼ˆTable 6ï¼‰
åœ¨ `JailBreakBench` ä¸ŠåŒæ ·è¡¨ç°å‡ºè‰²ï¼š
| Model | F1 Score |
|-------|----------|
| **DeepContext** | **0.98** |
| Qwen3Guard-Gen-8B | 0.88 |
| Llama-Guard-4-12B | 0.86 |

> âœ… è¯æ˜è¯¥æ¶æ„æ—¢èƒ½å¤„ç†å¤šè½® driftï¼Œä¹Ÿèƒ½é«˜æ•ˆæ£€æµ‹å•è½®æ”»å‡»ã€‚

### æ¨ç†å»¶è¿Ÿå¯¹æ¯”ï¼ˆTable 7ï¼‰
| Model | Latency (ms) |
|-------|---------------|
| **DeepContext** | **19** |
| Llama-Prompt-Guard-2 | 4 |
| Granite-Guardian-3.3-8B | 125 |
| AWS Prompt Attack Guardrails | 235 |
| Gpt5-Nano | 317 |

> âš–ï¸ åœ¨ç²¾åº¦ä¸é€Ÿåº¦ä¹‹é—´å–å¾—æä½³å¹³è¡¡ï¼š**ä»…æ¯”æœ€è½»é‡æ¨¡å‹æ…¢ 4 å€ï¼Œå´å¤§å¹…è¶…è¶Šå…¶æ£€æµ‹èƒ½åŠ›**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **State over Scale**ï¼š  
   > â€œ**çŠ¶æ€æ€§ > è§„æ¨¡æ€§**â€â€”â€”ç›¸æ¯”å †å å‚æ•°çš„å¤§å‹æ¨¡å‹ï¼Œ**ç»´æŠ¤ä¸€ä¸ªç´§å‡‘çš„ recurrent state** æ›´èƒ½æœ‰æ•ˆæ•æ‰å¤šè½®æ”»å‡»çš„æœ¬è´¨ç‰¹å¾ã€‚

2. **Temporal Awareness æ˜¯å…³é”®**ï¼š  
   å¤šè½®æ”»å‡»çš„æˆåŠŸä¾èµ–äºæ—¶é—´ç»´åº¦ä¸Šçš„è¯­ä¹‰æ¼‚ç§»ï¼›åªæœ‰å…·å¤‡ temporal reasoning èƒ½åŠ›çš„ç³»ç»Ÿæ‰èƒ½æå‰é¢„è­¦ï¼ˆå¦‚ DeepContext å¹³å‡åœ¨ç¬¬ 4.24 è½®å°±è§¦å‘æ‹¦æˆªï¼‰ã€‚

3. **æ•ˆç‡ä¸å®‰å…¨å¯ä»¥å…¼å¾—**ï¼š  
   DeepContext ä»¥ <20ms çš„å»¶è¿Ÿå®ç°äº† SOTA æ€§èƒ½ï¼Œæ‰“ç ´äº†â€œå¼ºå®‰å…¨å¿…é«˜å»¶è¿Ÿâ€çš„å›ºæœ‰è®¤çŸ¥ï¼Œé€‚ç”¨äºç”Ÿäº§çº§éƒ¨ç½²ã€‚

4. **é™æ€å¿«ç…§åˆ†æå­˜åœ¨æ ¹æœ¬ç¼ºé™·**ï¼š  
   å³ä½¿å°†æ•´æ®µå¯¹è¯å–‚ç»™ 12B å‚æ•°çš„ LLMï¼Œå…¶æ€§èƒ½ä»ä¸å¦‚åŸºäºæ»‘çª—çš„å°æ¨¡å‹ï¼Œè¯´æ˜ç¼ºä¹æ˜¾å¼çŠ¶æ€å»ºæ¨¡ä¼šå¯¼è‡´æ³¨æ„åŠ›åˆ†æ•£ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **False Positives in Complex Functional Dialogs**ï¼š  
  åœ¨å‡½æ•°è°ƒç”¨ç­‰æŠ€æœ¯æ€§å¤æ‚æŒ‡ä»¤åœºæ™¯ä¸­ï¼Œtask-attention æœºåˆ¶å¯èƒ½è¯¯åˆ¤ä¸ºä»£ç æ³¨å…¥æ”»å‡»ã€‚
- **ä¾èµ–é«˜è´¨é‡ embedding æå–**ï¼š  
  æ€§èƒ½å—é™äº fine-tuned BERT encoder å¯¹â€œé«˜ä¿¡å·â€token çš„è¯†åˆ«èƒ½åŠ›ã€‚
- **å°šæœªæ”¯æŒè·¨ä¼šè¯è·Ÿè¸ª**ï¼š  
  å½“å‰ä»…é™å•æ¬¡å¯¹è¯å†…çš„çŠ¶æ€ç»´æŒï¼Œæœªè€ƒè™‘é•¿æœŸç”¨æˆ·è¡Œä¸ºå»ºæ¨¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **Generalized Intent Detection**ï¼š  
   æ‰©å±•ä¸ºé€šç”¨æ„å›¾è½¨è¿¹å¯¹é½å·¥å…·ï¼Œç”¨äºæ£€æµ‹ autonomous agent æ˜¯å¦å‘ç”Ÿ goal driftã€‚
   
2. **Dynamic Policy Controls**ï¼š  
   åˆ©ç”¨è¿ç»­çš„é£é™©å‘é‡ $ R_t $ å®ç°åŠ¨æ€æ‘©æ“¦æ§åˆ¶ï¼ˆadaptive frictionï¼‰ï¼Œä¾‹å¦‚æ¥è¿‘é˜ˆå€¼æ—¶è‡ªåŠ¨é™æƒæˆ–å¼•å…¥ human-in-the-loopã€‚

3. **Deterministic Algorithmic Threat Tracking**ï¼š  
   ç»“åˆå›¾ç»“æ„æ‰§è¡Œè¿½è¸ªæˆ–çŠ¶æ€æœºè§„åˆ™ï¼Œæä¾›å¯è§£é‡Šã€åˆè§„çš„å®¡è®¡è·¯å¾„ï¼Œé™ä½é«˜å™ªå£°ç¯å¢ƒä¸‹çš„è¯¯æŠ¥ã€‚

4. **Federated Intent Tracking**ï¼š  
   åœ¨å¤šä¸ª agent workflow é—´å…±äº«è½»é‡ intent embeddingï¼Œæ„å»ºåˆ†å¸ƒå¼å®‰å…¨ç½‘ç»œã€‚

---

> ğŸ”š **ç»“è¯­**ï¼š  
> DeepContext å±•ç¤ºäº† **â€œsmall but statefulâ€** æ¶æ„åœ¨ LLM å®‰å…¨é¢†åŸŸçš„å·¨å¤§æ½œåŠ›ã€‚å®ƒä¸ä»…æ˜¯å¤šè½® jailbreak æ£€æµ‹çš„æ–° SOTAï¼Œæ›´æ ‡å¿—ç€é˜²å¾¡èŒƒå¼ä»â€œ**safety-as-a-judge**â€å‘â€œ**safety-as-a-signal**â€çš„è½¬å˜â€”â€”æœªæ¥çš„å®‰å…¨ç³»ç»Ÿåº”åƒç¥ç»ç³»ç»Ÿä¸€æ ·ï¼ŒæŒç»­æ„ŸçŸ¥ã€é¢„æµ‹å¹¶è°ƒèŠ‚æ„å›¾æµåŠ¨ï¼Œè€Œéä»…ä»…åšä¸€æ¬¡æ€§çš„åˆ¤å†³ã€‚

</details>

---

### 7. [LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation](https://arxiv.org/abs/2602.16953)

**Authors**: Hejia Zhang, Zhongming Yu, Chia-Tung Ho, Haoxing Ren, Brucek Khailany, Jishen Zhao  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.16953v1  

#### Abstract
Execution-aware LLM agents offer a promising paradigm for learning from tool feedback, but such feedback is often expensive and slow to obtain, making online reinforcement learning (RL) impractical. High-coverage hardware verification exemplifies this challenge due to its reliance on industrial simu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ç¡¬ä»¶éªŒè¯ï¼ˆhardware verificationï¼‰æ˜¯èŠ¯ç‰‡è®¾è®¡æµç¨‹ä¸­æˆæœ¬æœ€é«˜ã€è€—æ—¶æœ€é•¿çš„ç¯èŠ‚ä¹‹ä¸€ã€‚å…¶æ ¸å¿ƒä»»åŠ¡æ˜¯ç”Ÿæˆé«˜è¦†ç›–ç‡çš„ testbenchï¼Œä»¥å……åˆ†æ¿€å‘å’Œæ£€æµ‹ç¡¬ä»¶è®¾è®¡ä¸­çš„æ½œåœ¨ç¼ºé™·ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿæ–¹æ³•ä¾èµ–äººå·¥ç¼–å†™ testbenchï¼Œæ•ˆç‡ä½ä¸‹ï¼›è€Œç°æœ‰çš„ LLM æ–¹æ³•åœ¨æ‰§è¡Œæ„ŸçŸ¥ï¼ˆexecution-awareï¼‰çš„ä»£ç†å­¦ä¹ ä¸­é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **ä»¿çœŸå™¨è°ƒç”¨ä»£ä»·é«˜æ˜‚**ï¼šå·¥ä¸šçº§ cycle-accurate simulator è¿è¡Œä¸€æ¬¡å¯èƒ½éœ€è¦æ•°åˆ†é’Ÿåˆ°æ•°å°æ—¶ï¼Œä½¿å¾—åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆonline RLï¼‰ä¸å¯è¡Œã€‚
- **åé¦ˆä¿¡å·éå¯å¾®ä¸”ç¨€ç–**ï¼šcoverage æ˜¯ç¦»æ•£ã€éè¿ç»­çš„æ‰§è¡Œåé¦ˆï¼Œéš¾ä»¥ç›´æ¥ç”¨äºæ¢¯åº¦ä¼˜åŒ–ã€‚
- **çŠ¶æ€åˆ†å¸ƒåç§»ï¼ˆstate distribution shiftï¼‰**ï¼šå­¦ç”Ÿæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é‡åˆ°çš„å¤±è´¥çŠ¶æ€ä¸æ•™å¸ˆæ¨¡å‹è½¨è¿¹ä¸­çš„çŠ¶æ€å·®å¼‚å¤§ï¼Œå¯¼è‡´ç›‘ç£ä¿¡å·ä¸åŒ¹é…ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **LLM4Cov** â€”â€” é¦–ä¸ªé¢å‘é«˜è¦†ç›–ç‡ testbench ç”Ÿæˆçš„ **ç¦»çº¿æ‰§è¡Œæ„ŸçŸ¥ä»£ç†å­¦ä¹ æ¡†æ¶ï¼ˆoffline execution-aware agentic learning frameworkï¼‰**ï¼Œå…¶ä¸‰å¤§æ ¸å¿ƒæŠ€æœ¯ä¸ºï¼š

#### ï¼ˆ1ï¼‰**Coverage-Guided Agentic Rejection Fine-tuningï¼ˆè¦†ç›–å¼•å¯¼çš„æ‹’ç»å¼å¾®è°ƒï¼‰**
- åˆ©ç”¨ simulator æ‰§è¡Œåé¦ˆä½œä¸ºå¯†é›†ç›‘ç£ä¿¡å·ã€‚
- å­¦ç”Ÿæ¨¡å‹ç”Ÿæˆå¤šä¸ª testbench è‰ç¨¿ï¼Œä»…ä¿ç•™é‚£äº›ä»ä½è¦†ç›–ç‡çŠ¶æ€å‡ºå‘å¹¶å®ç°æ˜¾è‘— coverage æå‡çš„â€œæ¢å¤è¡Œä¸ºâ€ï¼ˆrecovery behaviorï¼‰ã€‚
- é€šè¿‡ **execution-based rejection sampling** è¿‡æ»¤æ— æ•ˆæ ·æœ¬ï¼Œæœ€å¤§åŒ–æ¯æ¬¡ä»¿çœŸè°ƒç”¨çš„ä¿¡æ¯å¢ç›Šã€‚

#### ï¼ˆ2ï¼‰**Verification-Conditioned Progressive Learningï¼ˆéªŒè¯æ¡ä»¶åŒ–çš„æ¸è¿›å­¦ä¹ ï¼‰**
- å°†è®­ç»ƒåˆ†ä¸ºå¤šé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µçš„æ•°æ®åˆæˆåŸºäºå½“å‰å­¦ç”Ÿæ¨¡å‹çš„çŠ¶æ€åˆ†å¸ƒè¿›è¡Œã€‚
- **Stage 0**ï¼šä½¿ç”¨ teacher model çš„å®Œæ•´è½¨è¿¹è¿›è¡Œ warm-upï¼›
- **Stage 1**ï¼šé‡‡ç”¨æ¨¡ä»¿å­¦ä¹ ï¼ˆimitation-styleï¼‰ï¼Œå³å­¦ç”Ÿé‡‡æ ·ä¸­é—´çŠ¶æ€ + æ•™å¸ˆç”Ÿæˆä¿®å¤åŠ¨ä½œï¼›
- **Stage 2**ï¼šå®Œå…¨è‡ªé‡‡æ ·ï¼ˆself-samplingï¼‰ï¼Œç”±å­¦ç”Ÿè‡ªèº«å®ŒæˆçŠ¶æ€æ¢ç´¢ä¸ä¿®å¤ã€‚
- æ­¤æœºåˆ¶ç¡®ä¿ç›‘ç£æ•°æ®å§‹ç»ˆä¸å½“å‰å­¦ç”Ÿçš„æ‰§è¡Œèƒ½åŠ›å¯¹é½ï¼Œé¿å…å› æ··åˆä¸åŒèƒ½åŠ›çº§åˆ«çš„æ•°æ®è€Œå¯¼è‡´ä¿¡å·ç¨€é‡Šã€‚

#### ï¼ˆ3ï¼‰**Worst-State-Prioritized Samplingï¼ˆæœ€å·®çŠ¶æ€ä¼˜å…ˆé‡‡æ ·ï¼‰**
- åœ¨è½¨è¿¹åˆæˆæ—¶ï¼Œä¼˜å…ˆé€‰æ‹© coverage æœ€ä½çš„ä¸­é—´çŠ¶æ€æ¥ç”Ÿæˆä¿®å¤å°è¯•ã€‚
- æ˜¾è‘—æé«˜è®­ç»ƒæ•°æ®ä¸­â€œå›°éš¾æ¡ˆä¾‹â€çš„æ¯”ä¾‹ï¼Œåœ¨æœ‰é™ä»¿çœŸé¢„ç®—ä¸‹æå‡å­¦ä¹ æ•ˆç‡ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³• | LLM4Cov |
|------|--------|---------|
| å­¦ä¹ èŒƒå¼ | å¤šä¸ºå•è½®ç”Ÿæˆæˆ–ç®€å•è¿­ä»£ | å¤šè½®ã€è®°å¿†æ— å…³ï¼ˆmemorylessï¼‰ã€æ‰§è¡Œé©±åŠ¨çš„ä»£ç†å­¦ä¹  |
| æ•°æ®åˆ©ç”¨ | é™æ€æ•°æ®é›†æˆ–åœ¨çº¿äº¤äº’ | ç¦»çº¿ä½†åŠ¨æ€åˆæˆï¼Œéšå­¦ç”Ÿæ¼”è¿›è€Œæ›´æ–° |
| åˆ†å¸ƒå¯¹é½ | å¿½è§†å­¦ç”Ÿä¸æ•™å¸ˆçš„çŠ¶æ€åˆ†å¸ƒå·®å¼‚ | æ˜¾å¼å»ºæ¨¡å¹¶é€æ­¥å¯¹é½çŠ¶æ€åˆ†å¸ƒ |
| æˆæœ¬æ§åˆ¶ | ä»¿çœŸè°ƒç”¨é¢‘ç¹ï¼Œéš¾ä»¥æ‰©å±• | æå¤§å‡å°‘æœ‰æ•ˆä»¿çœŸæ¬¡æ•°ï¼Œé€‚åˆå·¥ä¸šéƒ¨ç½² |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **ä¸»åŸºå‡†**ï¼š`CVDP-ECov`ï¼Œæ”¹ç¼–è‡ª CVDP benchmark (Pinckney et al., 2025)ï¼ŒåŒ…å« **83 ä¸ªç‹¬ç«‹ç¡¬ä»¶ä»“åº“ï¼ˆhardware repositoriesï¼‰**ã€‚
- **è®­ç»ƒæ•°æ®æ¥æº**ï¼šæ¥è‡ª CodeV-R1 æ•°æ®é›†çš„ 87k ä¸ªç‹¬ç«‹ä»“åº“ã€‚
- **å»æ±¡æŸ“å¤„ç†**ï¼šç§»é™¤ä¸æµ‹è¯•é›†ç›¸ä¼¼åº¦è¶…è¿‡ 50% ROUGE-L çš„æ ·æœ¬ï¼Œé˜²æ­¢æ•°æ®æ³„éœ²ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼š
  - å­¦ç”Ÿæ¨¡å‹ï¼š`Qwen3-4B-Instruct-2507`ï¼ˆ4B å‚æ•°ï¼‰
  - æ•™å¸ˆæ¨¡å‹ï¼š`Qwen3-Coder-30B-A3B-Instruct`ï¼ˆ30B å‚æ•°ï¼‰
- **è®­ç»ƒæµç¨‹**ï¼šä¸‰é˜¶æ®µ SFT æµç¨‹
  1. **Stage 0**ï¼šTeacher-generated è½¨è¿¹ + syntax constraint promptï¼ˆè§ Appendix Aï¼‰
  2. **Stage 1**ï¼šImitation-style + worst-state sampling
  3. **Stage 2**ï¼šSelf-sampling + coverage-guided rejection
- **ä»¿çœŸå·¥å…·é“¾**ï¼šCadence Xcelium (`xrun`) ç¼–è¯‘æ‰§è¡Œï¼ŒIMC å·¥å…·åˆ†æ coverageã€‚
- **ä»¿çœŸé¢„ç®—å›ºå®š**ï¼šæ‰€æœ‰æ¶ˆèå®éªŒä¿æŒç›¸åŒçš„ simulator call æ•°é‡ã€‚

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Cov Pass @1**ï¼ˆä¸»æŒ‡æ ‡ï¼‰ | åœ¨ N=3 è½®ä»£ç†æ‰§è¡Œåï¼Œcoverage è¾¾åˆ°é¢„è®¾é˜ˆå€¼çš„ä»“åº“å æ¯” |
| **Avg Cov** | æ‰€æœ‰ä»“åº“å¹³å‡ coverageï¼Œå¤±è´¥åˆ™è®°ä¸º 0% |
| **Sim Pass** | testbench èƒ½æˆåŠŸç¼–è¯‘å¹¶é€šè¿‡ä»¿çœŸçš„æ¯”ä¾‹ï¼ˆè¡¡é‡è¯­æ³•æ­£ç¡®æ€§ï¼‰ |
| **Direct Inference** | å•æ¬¡ç”Ÿæˆæ— åé¦ˆçš„ç»“æœï¼ˆå¯¹ç…§ç»„ï¼‰ |
| **Agentic Evaluation** | å…è®¸æ¨¡å‹åŸºäº simulator åé¦ˆè¿­ä»£ä¼˜åŒ–ï¼ˆN=3ï¼‰ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **é€šç”¨ LLMs**ï¼š`Llama-4-Maverick (400B)`ã€`Qwen3-235B` ç­‰
- **ç¼–ç ä¸“ç”¨ LLMs**ï¼š`Qwen-Coder` ç³»åˆ—
- **ç¡¬ä»¶ç‰¹å®šæ¨¡å‹**ï¼š`VeriCoder`, `CodeV-R1-RL`, `VeriReason` ç­‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2ï¼‰

| æ¨¡å‹ | Cov Pass (Agentic) | Avg Cov (Agentic) | æ¨¡å‹å¤§å° |
|------|---------------------|--------------------|----------|
| Qwen3-4B-Baseï¼ˆåˆå§‹ï¼‰ | 28.4% | 48.5% | 4B |
| **LLM4Cov (+Stage2)** | **69.2%** | **90.4%** | 4B |
| Qwen3-Coder-30Bï¼ˆæ•™å¸ˆï¼‰ | 63.9% | 79.9% | 30B |
| Llama-4-Maverick (400B) | 60.2% | 81.7% | ~400B |

> âœ… **ç»“è®º**ï¼šä¸€ä¸ªä»… **4B å‚æ•°** çš„æ¨¡å‹ï¼Œåœ¨ç»è¿‡ LLM4Cov æ¡†æ¶è®­ç»ƒåï¼Œ**è¶…è¶Šäº† 30B çš„æ•™å¸ˆæ¨¡å‹ï¼ˆ+5.3% Cov Passï¼‰**ï¼Œç”šè‡³ä¼˜äºéƒ¨åˆ† **50â€“100 å€æ›´å¤§è§„æ¨¡çš„é€šç”¨æ¨¡å‹**ã€‚

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”
- LLM4Cov çš„ **coverage pass rate æ¯”åŒçº§åˆ«ç¡¬ä»¶ä¸“ç”¨æ¨¡å‹é«˜å‡º 40+ ä¸ªç™¾åˆ†ç‚¹**ã€‚
- åœ¨ direct inference ä¸‹ä¹Ÿæ˜¾è‘—ä¼˜äºå…¶ä»– 4Bâ€“14B çº§åˆ«æ¨¡å‹ï¼Œè¯´æ˜è®­ç»ƒè¿‡ç¨‹æå‡äº†æ³›åŒ–èƒ½åŠ›ã€‚
- å¦‚å›¾ 2 å’Œå›¾ 7 æ‰€ç¤ºï¼ŒLLM4Cov åœ¨ **coverage-performance æ›²çº¿ä¸Šå¤„äº Pareto å‰æ²¿**ï¼Œå®ç°äº†å°æ¨¡å‹ä¸‹çš„é«˜æ•ˆèƒ½çªç ´ã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰**Intermediate State Selection ç­–ç•¥å¯¹æ¯”**ï¼ˆFigure 5ï¼‰
| ç­–ç•¥ | Cov Pass |
|------|----------|
| Best-State Selection | ~62% |
| Uniform Selection | ~63% |
| Median-State Selection | ~64% |
| **Worst-State Selection** | **~67.5%** |

> âœ”ï¸ æœ€å·®çŠ¶æ€ä¼˜å…ˆç­–ç•¥è¡¨ç°æœ€ä½³ï¼ŒéªŒè¯äº†èšç„¦å¤±è´¥çŠ¶æ€çš„æœ‰æ•ˆæ€§ã€‚

#### ï¼ˆ2ï¼‰**Progressive vs Naive Data Augmentation**ï¼ˆFigure 6ï¼‰
- ä½¿ç”¨ç›¸åŒæ•°æ®æ€»é‡ï¼Œ**åˆ†é˜¶æ®µè®­ç»ƒï¼ˆprogressiveï¼‰æ˜æ˜¾ä¼˜äºè”åˆè®­ç»ƒï¼ˆnaive augmentationï¼‰**ã€‚
- ç‰¹åˆ«æ˜¯åœ¨ Stage 1+2 æ•°æ®ä¸Šï¼Œä» Stage 0 checkpoint ç»§ç»­è®­ç»ƒæ¯”ä»å¤´è®­ç»ƒæ•ˆæœæ›´å¥½ï¼ˆ+2â€“3%ï¼‰ã€‚
> âœ”ï¸ è¡¨æ˜ **distribution alignment è‡³å…³é‡è¦**ï¼Œä¸èƒ½ç®€å•åˆå¹¶ä¸åŒé˜¶æ®µçš„æ•°æ®ã€‚

#### ï¼ˆ3ï¼‰**Trajectory Synthesis æ–¹å¼æ¼”å˜**ï¼ˆFigure 4ï¼‰
- **Stage 1**ï¼šTeacher-guided transitions æ˜æ˜¾ä¼˜äº student è‡ªä¸»ç”Ÿæˆã€‚
- **Stage 2**ï¼šéšç€å­¦ç”Ÿèƒ½åŠ›å¢å¼ºï¼Œself-sampling æ¥è¿‘ teacher æ€§èƒ½ï¼Œå¹¶æ›´å…·é€‚é…æ€§ã€‚
> âœ”ï¸ æ”¯æŒäº†â€œä» teacher correction å‘ student-driven refinement æ¸è¿›â€çš„åˆç†æ€§ã€‚

#### ï¼ˆ4ï¼‰**Execution-Based Dataset Curation æ¶ˆè**ï¼ˆTable 3ï¼‰
| æ•°æ®æ„å»ºæ–¹å¼ | Sim Pass (Agentic) |
|--------------|---------------------|
| Teacher ç›´æ¥ç”Ÿæˆ | 85.1% |
| SFT without filtering | 79.5% |
| **SFT with execution filtering** | **87.7%** |

> âœ”ï¸ æ‰§è¡ŒéªŒè¯è¿‡æ»¤ä¸ä»…æå‡è®­ç»ƒè´¨é‡ï¼Œè¿˜å¢å¼ºäº†æœ€ç»ˆæ¨¡å‹çš„è¯­æ³•é²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å°æ¨¡å‹ä¹Ÿèƒ½å®ç°é«˜æ€§èƒ½ç¡¬ä»¶éªŒè¯**ï¼šé€šè¿‡ **execution-aware çš„ç¦»çº¿ä»£ç†å­¦ä¹ **ï¼Œ4B æ¨¡å‹å³å¯è¾¾åˆ°ç”šè‡³è¶…è¶Šæ•°åå€æ›´å¤§æ¨¡å‹çš„ coverage è¡¨ç°ã€‚
2. **ç›‘ç£ä¿¡å·çš„è´¨é‡æ¯”æ•°é‡æ›´é‡è¦**ï¼šç›¸æ¯”ç›²ç›®æ‰©å¤§æ¨¡å‹è§„æ¨¡ï¼Œ**ç²¾å‡†æå– recovery behavior å¹¶å¯¹é½çŠ¶æ€åˆ†å¸ƒ** æ›´èƒ½æ¨åŠ¨æ€§èƒ½è·ƒè¿ã€‚
3. **worst-state-prioritized sampling æå¤§åœ°æå‡äº†å­¦ä¹ æ•ˆç‡**ï¼šå°†æœ‰é™çš„ä»¿çœŸèµ„æºé›†ä¸­åœ¨æœ€éš¾è¦†ç›–çš„çŠ¶æ€ä¸Šï¼Œæ˜¯åº”å¯¹é«˜æˆæœ¬æ‰§è¡Œåé¦ˆçš„å…³é”®ã€‚
4. **æ¸è¿›å¼è®­ç»ƒç¨³å®šäº†å­¦ä¹ è¿‡ç¨‹**ï¼šé˜¶æ®µæ€§åœ°è°ƒæ•´æ•°æ®åˆæˆç­–ç•¥ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå¹³ç¨³è¿‡æ¸¡ä»æ¨¡ä»¿åˆ°è‡ªä¸»æ¢ç´¢ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **ä»ä¾èµ– simulator çš„ç¡®å®šæ€§è¾“å‡º**ï¼šè‹¥ä»¿çœŸå­˜åœ¨éšæœºæ€§æˆ–è¶…æ—¶ä¸ç¡®å®šæ€§ï¼Œä¼šå½±å“ç›‘ç£ä¿¡å·ç¨³å®šæ€§ã€‚
- **å½“å‰æ¡†æ¶æœªæ•´åˆ reasoning æˆ– planning æ¨¡å—**ï¼šè™½ç„¶æ”¯æŒæœªæ¥æ¥å…¥ RLï¼Œä½†ç›®å‰ä¸»è¦ä¾èµ– prompt-level å†³ç­–ã€‚
- **domain-specific syntax constraints éœ€æ‰‹åŠ¨è®¾è®¡**ï¼šå°½ç®¡æœ‰æ•ˆï¼Œä½†ä¸å…·å¤‡å®Œå…¨è‡ªåŠ¨åŒ–è¿ç§»èƒ½åŠ›ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å°† LLM4Cov è¾“å‡ºä½œä¸º **RL çš„åˆå§‹åŒ–ç­–ç•¥**ï¼Œè¿›ä¸€æ­¥æ¢ç´¢ long-horizon credit assignmentã€‚
- å¼•å…¥ **multi-agent collaboration**ï¼Œå¦‚åˆ†ç¦» stimulus generator ä¸ assertion writerã€‚
- æ‰©å±•è‡³ **analog/mixed-signal è®¾è®¡éªŒè¯** æˆ– **post-silicon debugging** åœºæ™¯ã€‚
- æ¢ç´¢ **zero-shot transfer across architectures**ï¼Œé™ä½ per-project å¾®è°ƒæˆæœ¬ã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **LLM4Cov è¯æ˜äº†â€œæ­£ç¡®çš„å­¦ä¹ èŒƒå¼ > æ›´å¤§çš„æ¨¡å‹â€ï¼Œé€šè¿‡æ‰§è¡Œæ„ŸçŸ¥ã€çŠ¶æ€å¯¹é½å’Œæ¸è¿›å¼ç›‘ç£ï¼Œè®©å°å‹ LLM åœ¨é«˜æˆæœ¬ç¡¬ä»¶éªŒè¯ä»»åŠ¡ä¸­å®ç°äº†è¶…è¶Šå¤§è§„æ¨¡æ¨¡å‹çš„æ€§èƒ½çªç ´ã€‚**

</details>

---

### 8. [Small LLMs for Medical NLP: a Systematic Analysis of Few-Shot, Constraint Decoding, Fine-Tuning and Continual Pre-Training in Italian](https://arxiv.org/abs/2602.17475)

**Authors**: Pietro Ferrazzi, Mattia Franzin, Alberto Lavelli, Bernardo Magnini  
**Category**: cs.CL  
**Published**: 2026-02-20  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.17475v1  

#### Abstract
Large Language Models (LLMs) consistently excel in diverse medical Natural Language Processing (NLP) tasks, yet their substantial computational requirements often limit deployment in real-world healthcare settings. In this work, we investigate whether "small" LLMs (around one billion parameters) can...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Small LLMs for Medical NLP: a Systematic Analysis of Few-Shot, Constraint Decoding, Fine-Tuning and Continual Pre-Training in Italian*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜
æœ¬ç ”ç©¶æ¢è®¨äº†åœ¨èµ„æºå—é™çš„åŒ»ç–—ç¯å¢ƒä¸­ï¼Œæ˜¯å¦å¯ä»¥ä½¿ç”¨å‚æ•°é‡çº¦10äº¿ï¼ˆone billion parametersï¼‰çš„ **Small LLMs (SLLMs)** æ›¿ä»£è®¡ç®—æˆæœ¬é«˜æ˜‚çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚32Bä»¥ä¸Šï¼‰ï¼Œä»¥é«˜æ•ˆæ‰§è¡Œæ„å¤§åˆ©è¯­åŒ»å­¦è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆMedical NLPï¼‰ä»»åŠ¡ã€‚

ä¼ ç»Ÿä¸Šï¼ŒLarge Language Models (LLMs) åœ¨åŒ»å­¦NLPä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†å…¶é«˜ç®—åŠ›éœ€æ±‚é™åˆ¶äº†åœ¨åŒ»é™¢ç­‰å®é™…åœºæ™¯ä¸­çš„éƒ¨ç½²ã€‚æœ¬æ–‡ç³»ç»Ÿåœ°è¯„ä¼°äº†SLLMsåœ¨å¤šç§é€‚åº”ç­–ç•¥ä¸‹çš„æ½œåŠ›ï¼Œæ—¨åœ¨ä¸ºèµ„æºæœ‰é™çš„åŒ»ç–—æœºæ„æä¾›å¯è¡Œæ–¹æ¡ˆã€‚

### âœ… æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
- **ç³»ç»Ÿæ€§æ¯”è¾ƒå››å¤§ç±»æ¨¡å‹é€‚åº”ç­–ç•¥**ï¼š
  - **Inference-time methods**: `few-shot prompting` å’Œ `constraint decoding`
  - **Training-time methods**: `supervised fine-tuning (FT)` å’Œ `continual pre-training (CPT)`
- æ„å»ºå¹¶å‘å¸ƒäº†é¦–ä¸ªå…¨é¢çš„ã€å…¬å¼€å¯ç”¨çš„**æ„å¤§åˆ©è¯­åŒ»å­¦NLPæ•°æ®é›†åˆ**ï¼Œæ¶µç›–5ç±»ä»»åŠ¡ã€12ä¸ªæ•°æ®é›†ã€20ä¸ªå­ä»»åŠ¡ã€‚
- æ”¶é›†å¹¶å¼€æºä¸¤ä¸ªå¤§è§„æ¨¡æ„å¤§åˆ©è¯­åŒ»å­¦æ–‡æœ¬è¯­æ–™åº“ç”¨äºCPTï¼š
  - ä¸´åºŠæ•°æ®ï¼šæ¥è‡ªæ€¥è¯Šç§‘çš„ **1.26äº¿è¯** åŒ¿åç”µå­å¥åº·è®°å½•ï¼ˆEHRï¼‰
  - ç§‘å­¦æ–‡çŒ®ï¼šæ•´åˆå¤šæºçš„ **2.8äº¿è¯** åŒ»å­¦ç§‘å­¦æ–‡æœ¬ï¼ˆå«è®ºæ–‡ã€è¯å“è¯´æ˜ä¹¦ã€ç»´åŸºç™¾ç§‘ç­‰ï¼‰

### âœ… ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- é¦–æ¬¡åœ¨**å•ä¸€ç´§å‡‘æ¨¡å‹æ¶æ„ä¸‹**å®ç°å¯¹å¤šä¸ªå¼‚æ„åŒ»å­¦NLPä»»åŠ¡çš„ç»Ÿä¸€å»ºæ¨¡ï¼ˆé€šè¿‡instruction-following + JSONè¾“å‡ºæ ¼å¼ï¼‰ã€‚
- å®éªŒè¯æ˜ï¼šç»è¿‡é€‚å½“è°ƒä¼˜çš„å°å‹æ¨¡å‹ï¼ˆå¦‚Qwen3-1.7Bï¼‰**å¯è¶…è¶Šé«˜è¾¾30å€å‚æ•°è§„æ¨¡çš„åŸºçº¿æ¨¡å‹**ï¼ˆQwen3-32Bï¼‰ã€‚
- æä¾›å®Œæ•´å¯å¤ç°ä»£ç åº“ä¸è®­ç»ƒæµç¨‹ï¼Œæ”¯æŒæ‰©å±•è‡³æ–°ä»»åŠ¡å’Œæ¨¡å‹ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å…±æ¶‰åŠ **5ç±»ä»»åŠ¡ã€12ä¸ªæ•°æ®é›†ã€20ä¸ªå­ä»»åŠ¡**ï¼Œåˆ†ä¸ºä¸¤ç±»ç”¨é€”ï¼š

| ä»»åŠ¡ç±»åˆ« | æ•°æ®é›† | å­ä»»åŠ¡æ•° | æ˜¯å¦ç”¨äºè®­ç»ƒ |
|--------|-------|---------|-------------|
| **Named Entity Recognition (NER)** | E3C, PharmaER, CardioCCC | 7 | æ˜¯ |
| **Relation Extraction (RE)** | E3C | 1 | æ˜¯ |
| **Case Report Form Filling (CRF)** | E3Cè¡ç”Ÿ | 3 | æ˜¯ |
| **Question Answering (QA)** | MedExpQA | 2 | æ˜¯ |
| **Argument Mining (ARG)** | Casimedicos-Arg | 1 | æ˜¯ |

> å¦å¤–6ä¸ªæ•°æ®é›†ç”¨äº**out-of-distribution (OOD) æµ‹è¯•**ï¼ŒåŒ…æ‹¬ï¼šDisteMISTï¼ˆç–¾ç—…è¯†åˆ«ï¼‰ã€PsyNITï¼ˆç²¾ç¥ç—‡çŠ¶ï¼‰ã€E3C-projectedã€ATã€MedMCQAã€MedQAã€‚

æ‰€æœ‰è¾“å…¥å‡è½¬æ¢ä¸ºç»Ÿä¸€çš„ **instruction-following æ ¼å¼**ï¼Œè¾“å‡ºå¼ºåˆ¶ä¸º **JSONç»“æ„åŒ–å­—ç¬¦ä¸²**ï¼Œä¾¿äºä¸‹æ¸¸è§£æã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹é€‰æ‹©**ï¼šåŸºäºLlama-3.2ã€Gemma-3ã€Qwen-3ä¸‰ä¸ªä¸»æµå®¶æ—ï¼Œé€‰å–çº¦1Bå‚æ•°çš„æ¨¡å‹è¿›è¡Œè¯„æµ‹ï¼š
  - Llama-3.2-1B (1.24B)
  - Gemma-3-1B (1.00B)
  - Qwen-3-1.7B (1.72B)
- **åŸºçº¿æ¨¡å‹**ï¼š
  - Qwen3-32B + 4-shot
  - Medgemma-27B + 4-shot
- **é€‚åº”ç­–ç•¥å¯¹æ¯”**ï¼š
  - 0-shot / 4-shot
  - Constraint Decoding (CD)
  - Supervised Fine-Tuning (FT)
  - Continual Pre-Training + FT (CPT+FT)

- **è®­ç»ƒç»†èŠ‚**ï¼š
  - Fine-tuningé‡‡ç”¨LoRAï¼Œå•å¼ H200 GPUï¼Œbatch size=16ï¼Œlr=5e-4ï¼Œå¹³å‡è€—æ—¶çº¦2å°æ—¶/æ¨¡å‹
  - CPTä½¿ç”¨3Ã—L40S GPUï¼ŒBF16æ··åˆç²¾åº¦ï¼Œåºåˆ—æ‰“åŒ…ï¼ˆsequence packingï¼‰+ Flash Attention 2ï¼Œè®­ç»ƒ8â€“12å°æ—¶

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
- **NER, CRF, RE, ARG**ï¼šExact Match F1 Score
- **QA**ï¼šAccuracy
- æœ€ç»ˆå¾—åˆ†å–å„ä»»åŠ¡/å­ä»»åŠ¡çš„**å¹³å‡å€¼ï¼ˆmacro-averageï¼‰**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 3ï¼‰

| æ¨¡å‹ | æ–¹æ³• | AVG Score | Î” vs Baseline (Qwen3-32B) |
|------|------|-----------|----------------------------|
| Qwen3-32B | 4-shot | 54.7 | â€” |
| **Qwen3-1.7B** | **FT** | **63.9** | **+9.2 â˜…â˜…â˜…** |
| Gemma-3-1b-it | CPT+FT | 59.4 | +4.7 â˜…â˜… |
| Llama-3.2-1B-Instruct | FT | 59.0 | +4.3 â˜…â˜… |

> âœ… **æœ€ä½³é…ç½® Qwen3-1.7B + FT æ¯” Qwen3-32B åŸºçº¿é«˜å‡º +9.2 åˆ†**

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- æ‰€æœ‰å…­ç§å°å‹æ¨¡å‹ä¸­æœ‰äº”ç§åœ¨fine-tuningå**è¶…è¿‡æœ€å¤§åŸºçº¿æ¨¡å‹**ã€‚
- å³ä½¿æ˜¯ä»…ç”¨4-shotæç¤ºçš„SLLMsä¹Ÿè¿œé€ŠäºåŸºçº¿ï¼›ä½†ä¸€æ—¦å¼•å…¥fine-tuningï¼Œæ€§èƒ½é€†è½¬ã€‚
- åœ¨OODæµ‹è¯•ä¸­ï¼Œå°æ¨¡å‹ä»ä¼˜äºè‡ªèº«æœªè®­ç»ƒç‰ˆæœ¬ï¼Œä½†**æ€»ä½“ä»ä½äºQwen3-32BåŸºçº¿**ï¼Œè¯´æ˜æ³›åŒ–èƒ½åŠ›ä»æœ‰å·®è·ã€‚

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰æ¨ç†é˜¶æ®µæ–¹æ³•å¯¹æ¯”ï¼ˆFigure 1 å·¦ï¼‰
| æ–¹æ³• | å¹³å‡æå‡ | æ¨ç†æ—¶é—´å¢åŠ  |
|------|----------|--------------|
| 4-shot vs 0-shot | +9.4 pts | +53% â— |
| Constraint Decoding | +3.8 pts | â‰ˆ0% âœ… |
| 4-shot + CD | +13.2 pts | +53% |

> ğŸ’¡ ç»“è®ºï¼š**few-shotæ•ˆæœæ˜¾è‘—ä¼˜äºCD**ï¼Œä½†CDå‡ ä¹ä¸å¢åŠ å»¶è¿Ÿï¼ŒäºŒè€…ç»“åˆæ•ˆæœæœ€å¥½ã€‚

#### ï¼ˆ2ï¼‰è®­ç»ƒé˜¶æ®µæ–¹æ³•å¯¹æ¯”ï¼ˆFigure 1 å³ï¼‰
| æ–¹æ³• | æ•ˆæœæ’åº |
|------|--------|
| Fine-Tuning (FT) | âœ… æœ€æœ‰æ•ˆ |
| CPT + FT | æ¬¡ä¹‹ï¼Œä»…åœ¨Gemmaä¸Šæœ‰å¢ç›Š |
| 0-shot / CD | æä½ |

> ğŸ’¡ ç»“è®ºï¼š**Fine-tuning æ˜¯æœ€æœ‰æ•ˆçš„é€‚åº”æ–¹å¼**ï¼Œå°¤å…¶å¯¹å°æ¨¡å‹è‡³å…³é‡è¦ã€‚

#### ï¼ˆ3ï¼‰ä»»åŠ¡éš¾åº¦åˆ†æ
- **æœ€éš¾ä»»åŠ¡**ï¼šRelation Extractionï¼ˆREï¼‰â†’ å°æ¨¡å‹éš¾ä»¥æ•æ‰å®ä½“é—´å¤æ‚å…³ç³»
- **æœ€å®¹æ˜“ä»»åŠ¡**ï¼šQuestion Answeringï¼ˆQAï¼‰â†’ å› é¢„è®­ç»ƒä¸­å·²æ¥è§¦å¤§é‡QAæ•°æ®
- **æå‡æœ€å¤§ä»»åŠ¡**ï¼šArgument Mining â†’ è¡¨æ˜fine-tuningèƒ½æ˜¾è‘—å¢å¼ºé€»è¾‘æ¨ç†è¡¨è¾¾èƒ½åŠ›

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Small LLMs ç»è¿‡ fine-tuning åå¯åœ¨å¤šé¡¹åŒ»å­¦NLPä»»åŠ¡ä¸­åŒ¹é…ç”šè‡³è¶…è¶Šæ•°åå€å¤§çš„æ¨¡å‹**ã€‚
2. **Supervised Fine-Tuning æ˜¯æœ€é«˜æ•ˆçš„é€‚åº”ç­–ç•¥**ï¼Œè¿œè¶…inference-timeæ–¹æ³•ã€‚
3. **Continual Pre-Training è´¡çŒ®æœ‰é™**ï¼Œä»…åœ¨ç‰¹å®šæƒ…å†µä¸‹ï¼ˆå¦‚gemma-3-1b-itï¼‰å¸¦æ¥é¢å¤–æ”¶ç›Šã€‚
4. **Inference-time ä¸­ï¼Œ4-shot + Constraint Decoding æ˜¯ä½æˆæœ¬æ›¿ä»£æ–¹æ¡ˆ**ï¼Œé€‚åˆæ— æ³•å¾®è°ƒçš„åœºæ™¯ã€‚
5. **æ¨¡å‹å…·å¤‡ä¸€å®šOODæ³›åŒ–èƒ½åŠ›**ï¼šfine-tunedæ¨¡å‹åœ¨æœªè§è¿‡çš„æ•°æ®é›†ä¸Šä»ä¼˜äºåŸå§‹ç‰ˆæœ¬ï¼ˆTable 4ï¼‰ï¼Œä½†å°šæœªè¾¾åˆ°åŸºçº¿æ°´å¹³ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **è¯­è¨€é™åˆ¶**ï¼šç ”ç©¶èšç„¦äº**æ„å¤§åˆ©è¯­**ï¼Œç»“è®ºå¯èƒ½ä¸é€‚ç”¨äºå…¶ä»–è¯­è¨€ã€‚
- **OODè¯„ä¼°ä¿å®ˆ**ï¼šæœªå¯¹OODæ•°æ®åšä»»ä½•è°ƒå‚ï¼Œå¯èƒ½å¯¼è‡´ä½ä¼°æ¨¡å‹é²æ£’æ€§ã€‚
- **ä»»åŠ¡ä¸å¹³è¡¡**ï¼šQAæ ·æœ¬å¤šä¸”æ˜“ï¼Œè€ŒREæ ·æœ¬å°‘ä¸”éš¾ï¼Œå½±å“èšåˆåˆ†æ•°ä»£è¡¨æ€§ã€‚
- **æœªæ¢ç´¢å¼ºåŒ–å­¦ä¹ æˆ–å…¶ä»–é«˜çº§è®­ç»ƒèŒƒå¼**ï¼ˆå¦‚RLHFï¼‰ã€‚
- **ç¼ºä¹çœŸå®ä¸–ç•Œéƒ¨ç½²æµ‹è¯•**ï¼ˆå¦‚APIå»¶è¿Ÿã€å†…å­˜å ç”¨å®æµ‹ï¼‰ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•åˆ°å¤šè¯­è¨€ä¸è·¨è¯­è¨€è¿ç§»ï¼ˆmultilingual transferï¼‰ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„æŒç»­å­¦ä¹ æœºåˆ¶ï¼ˆcontinual learningï¼‰ä»¥åº”å¯¹ä¸æ–­æ›´æ–°çš„åŒ»å­¦çŸ¥è¯†ã€‚
- å¼•å…¥reinforcement learningè¿›ä¸€æ­¥ä¼˜åŒ–è¾“å‡ºä¸€è‡´æ€§ä¸ä¸´åºŠå®‰å…¨æ€§ã€‚
- å¼€å‘é¢å‘å…·ä½“åº”ç”¨åœºæ™¯ï¼ˆå¦‚ç”µå­ç—…å†è‡ªåŠ¨å¡«å†™ï¼‰çš„ç«¯åˆ°ç«¯ç³»ç»ŸåŸå‹ã€‚
- è¿›ä¸€æ­¥å‹ç¼©æ¨¡å‹ï¼ˆå¦‚é‡åŒ–ã€è’¸é¦ï¼‰ä»¥é€‚é…è¾¹ç¼˜è®¾å¤‡ã€‚

---

## æ€»ç»“ä¸€å¥è¯
> **é€šè¿‡åˆç†çš„fine-tuningï¼Œä¸€ä¸ªä»…1.7Bå‚æ•°çš„Qwen3æ¨¡å‹å°±èƒ½åœ¨æ„å¤§åˆ©è¯­åŒ»å­¦NLPä»»åŠ¡ä¸Šå‡»è´¥32Bçš„å¤§æ¨¡å‹ï¼Œè¯æ˜Small LLMsæ˜¯èµ„æºå—é™åŒ»ç–—ç¯å¢ƒä¸­çš„å¼ºæœ‰åŠ›å€™é€‰è€…ã€‚**

</details>

---

### 9. [Heterogeneous Federated Fine-Tuning with Parallel One-Rank Adaptation](https://arxiv.org/abs/2602.16936)

**Authors**: Zikai Zhang, Rui Hu, Jiahao Xu  
**Category**: cs.DC  
**Published**: 2026-02-20  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.16936v1  

#### Abstract
Large Language Models (LLMs) have demonstrated remarkable effectiveness in adapting to downstream tasks through fine-tuning. Federated Learning (FL) extends this capability by enabling collaborative fine-tuning across distributed clients using Low-Rank Adaptation (LoRA), while preserving data privac...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šHeterogeneous Federated Fine-Tuning with Parallel One-Rank Adaptation

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬è®ºæ–‡é’ˆå¯¹**å¼‚æ„è”é‚¦å¾®è°ƒ**ï¼ˆHeterogeneous Federated Fine-Tuning, FFTï¼‰ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼šå®¢æˆ·ç«¯èµ„æºå·®å¼‚å¯¼è‡´çš„**LoRAç§©å¼‚è´¨æ€§**ï¼ˆheterogeneous LoRA ranksï¼‰ã€‚åœ¨å®é™…éƒ¨ç½²ä¸­ï¼Œä¸åŒå®¢æˆ·ç«¯çš„è®¡ç®—èƒ½åŠ›ä¸åŒï¼Œå› æ­¤åªèƒ½è®­ç»ƒä¸åŒç§©ï¼ˆrankï¼‰çš„LoRAæ¨¡å—ã€‚è¿™ç§å·®å¼‚ä¼šå¯¼è‡´ä¸¤ä¸ªä¸¥é‡é—®é¢˜ï¼š
- **åˆå§‹åŒ–å™ªå£°**ï¼ˆInitialization Noiseï¼‰ï¼šæœåŠ¡å™¨èšåˆå‡ºçš„é«˜ç§©å…¨å±€æ¨¡å‹æ— æ³•ç›´æ¥ç”¨äºåˆå§‹åŒ–ä½ç§©å®¢æˆ·ç«¯ï¼Œå¿…é¡»é€šè¿‡æˆªæ–­ï¼ˆtruncationï¼‰æˆ–éšæœºé‡åˆå§‹åŒ–ï¼Œé€ æˆä¿¡æ¯ä¸¢å¤±å’Œæ€§èƒ½ä¸‹é™ã€‚
- **èšåˆå™ªå£°**ï¼ˆAggregation Noiseï¼‰ï¼šå°†ä¸åŒç§©çš„æœ¬åœ°æ›´æ–°èšåˆåˆ°ç»Ÿä¸€çš„é«˜ç§©å…¨å±€æ¨¡å‹æ—¶ï¼Œä¼šå¼•å…¥åå·®å’Œè¯¯å·®ã€‚

### æå‡ºçš„æ–°æ–¹æ³•å’Œæ–°æ€è·¯
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡ºäº† **Fed-PLoRA** æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ˜¯ä¸¤ä¸ªåˆ›æ–°è®¾è®¡ï¼š
1.  **å¹¶è¡Œå•ç§©é€‚é…**ï¼ˆParallel One-Rank Adaptation, PLoRAï¼‰ï¼š
    - è¿™æ˜¯ä¸€ç§æ–°çš„LoRAå˜ä½“ã€‚å®ƒä¸ä½¿ç”¨ä¼ ç»Ÿçš„å•ä¸ªé«˜ç§©çŸ©é˜µ `â–³W = BA`ï¼Œè€Œæ˜¯å°†ä¸€ä¸ªç§©ä¸º `R` çš„LoRAæ¨¡å—åˆ†è§£ä¸º `R` ä¸ªå¹¶è¡Œçš„ã€ç‹¬ç«‹çš„**å•ç§©**ï¼ˆone-rankï¼‰æ¨¡å—ã€‚
    - æ•°å­¦ä¸Šç­‰ä»·äºæ ‡å‡†LoRAï¼Œä½†æä¾›äº†æ¨¡å—åŒ–çš„ç»“æ„ï¼Œå¤©ç„¶æ”¯æŒä¸åŒå®¢æˆ·ç«¯é€‰æ‹©ä¸åŒæ•°é‡çš„æ¨¡å—è¿›è¡Œè®­ç»ƒã€‚

2.  **Select-N-Fold ç­–ç•¥**ï¼š
    - åœ¨æ¯ä¸€è½®è®­ç»ƒå¼€å§‹æ—¶ï¼Œæ¯ä¸ªå®¢æˆ·ç«¯ä»æœåŠ¡å™¨æ¥æ”¶å®Œæ•´çš„ `R` ä¸ªå…¨å±€PLoRAæ¨¡å—ã€‚
    - å®¢æˆ·ç«¯æ ¹æ®è‡ªèº«ç®—åŠ›é¢„ç®—ï¼Œ**éšæœºé€‰æ‹©**ï¼ˆSelectï¼‰å…¶ä¸­ `r_i` ä¸ªæ¨¡å—è¿›è¡Œè®­ç»ƒã€‚
    - å¯¹äºæœªè¢«é€‰ä¸­çš„ `(R - r_i)` ä¸ªæ¨¡å—ï¼Œå°†å…¶â€œæŠ˜å â€ï¼ˆFoldï¼‰åˆ°å†»ç»“çš„é¢„è®­ç»ƒæƒé‡ä¸­ï¼Œä½œä¸ºå›ºå®šçš„æ¨¡å‹åç§»é‡ã€‚
    - è¿™ç§ç­–ç•¥ç¡®ä¿äº†æ‰€æœ‰å®¢æˆ·ç«¯éƒ½èƒ½åˆ©ç”¨å…¨éƒ¨çš„å…¨å±€çŸ¥è¯†ï¼Œè€Œä¸ä»…ä»…æ˜¯å…¶æœ¬åœ°ç§©æ‰€å…è®¸çš„éƒ¨åˆ†ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **é›¶åˆå§‹åŒ–å™ªå£°**ï¼šç”±äºæ‰€æœ‰å®¢æˆ·ç«¯éƒ½åŸºäºç›¸åŒçš„å…¨å±€æ¨¡å—è¿›è¡Œåˆå§‹åŒ–ï¼ˆåªæ˜¯é€‰æ‹©ä¸åŒçš„å­é›†è®­ç»ƒï¼‰ï¼Œå®Œå…¨æ¶ˆé™¤äº†å› ç§©ä¸åŒ¹é…å¯¼è‡´çš„åˆå§‹åŒ–å™ªå£°ã€‚
- **æœ€å°åŒ–èšåˆå™ªå£°**ï¼šæœåŠ¡å™¨å¯¹æ¯ä¸ªå¹¶è¡Œçš„å•ç§©æ¨¡å—è¿›è¡Œç‹¬ç«‹çš„åŠ æƒå¹³å‡ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚é›¶å¡«å……ã€SVDé‡æ„ï¼‰å¼•å…¥çš„ç»“æ„æ€§åå·®å’Œåˆ†è§£è¯¯å·®ã€‚
- **è½»é‡çº§ä¸”å…¼å®¹æ€§å¼º**ï¼šFed-PLoRAæ˜¯ä¸€ä¸ªè½»é‡çº§æ¡†æ¶ï¼Œå¯ä»¥æ— ç¼é›†æˆåˆ°ç°æœ‰çš„LoRAå’ŒFLæµç¨‹ä¸­ã€‚
- **é«˜æ•ˆæ€§**ï¼šåœ¨é€šä¿¡ã€è®¡ç®—å’Œå†…å­˜å¼€é”€æ–¹é¢ï¼Œä»…åœ¨ä¸‹é“¾è·¯ï¼ˆdownlinkï¼‰æœ‰å°‘é‡å¢åŠ ï¼Œæ€»ä½“æ•ˆç‡å¾ˆé«˜ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–äº†å¤šä¸ªé¢†åŸŸå’Œä»»åŠ¡ï¼Œä»¥éªŒè¯æ–¹æ³•çš„æ™®é€‚æ€§ï¼š
- **é€šç”¨æŒ‡ä»¤éµå¾ª**ï¼š`Natural Instructions`, `Dolly-15K`
- **é€šç”¨è‡ªç„¶è¯­è¨€ç†è§£**ï¼š`GLUE` benchmark (`CoLA`, `SST-2`, `MRPC`, `QQP`, `QNLI`, `RTE`)
- **é‡‘èé¢†åŸŸ**ï¼š`FinGPT` (è®­ç»ƒ), `FPB`, `FIQA`, `TFNS` (è¯„ä¼°)
- **åŒ»ç–—é¢†åŸŸ**ï¼š`MedAlpaca` (è®­ç»ƒ), `PubMedQA`, `MedMCQA`, `MedQA`, `CareQA` (è¯„ä¼°)
- **æ•°å­¦æ¨ç†**ï¼š`MATH`

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼šä½¿ç”¨äº†å¤šç§è§„æ¨¡çš„LLMï¼ŒåŒ…æ‹¬ `BERT-base`, `Llama-1B`, `Llama-3.1-8B`, `OPT-1.3B`, `Mistral-7B-v0.3`, `Qwen3-4B`ã€‚
- **LoRAé…ç½®**ï¼šé€šå¸¸åº”ç”¨äºè‡ªæ³¨æ„åŠ›å±‚çš„ `query` å’Œ `value` æŠ•å½±ã€‚
- **å®¢æˆ·ç«¯è®¾ç½®**ï¼šæ¨¡æ‹Ÿå¼‚æ„ç¯å¢ƒï¼Œå®¢æˆ·ç«¯åˆ†ä¸ºä¸‰ç»„ï¼Œåˆ†åˆ«æ‹¥æœ‰é«˜ã€ä¸­ã€ä½ä¸‰ç§LoRAç§©ï¼ˆä¾‹å¦‚ï¼Œ`R=16`, `rm=8`, `rl=1`ï¼‰ï¼Œå¹³å‡ç§©è¿œä½äºæœ€é«˜ç§©ã€‚
- **æ•°æ®åˆ†å¸ƒ**ï¼šåŒæ—¶æµ‹è¯•äº†IIDï¼ˆå‡åŒ€åˆ’åˆ†ï¼‰å’ŒéIIDï¼ˆç—…ç†æ€§å’Œç‹„åˆ©å…‹é›·åˆ’åˆ†ï¼‰åœºæ™¯ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
    - åˆ†ç±»ä»»åŠ¡ï¼šAccuracy, Matthews Correlation (CoLA)
    - ç”Ÿæˆä»»åŠ¡ï¼šRouge-L
    - å¹³å‡æ€§èƒ½ï¼šå„ä»»åŠ¡æŒ‡æ ‡çš„å¹³å‡å€¼ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **åŒæ„åŸºçº¿**ï¼š`FedIT` (ç»å…¸FedAvg + LoRA)ï¼Œç”¨äºæ— èµ„æºé™åˆ¶çš„ç†æƒ³æƒ…å†µå¯¹æ¯”ã€‚
- **å¼‚æ„åŸºçº¿**ï¼š
    - `FLoRA`ï¼šåŸºäºå †å ï¼ˆstackingï¼‰çš„èšåˆï¼Œæ¯è½®éšæœºåˆå§‹åŒ–ã€‚
    - `FlexLoRA`ï¼šåŸºäºSVDçš„èšåˆå’Œåˆå§‹åŒ–ã€‚
    - `HETLoRA`ï¼šé€šè¿‡é›¶å¡«å……å’Œæˆªæ–­è¿›è¡Œèšåˆå’Œåˆå§‹åŒ–ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ
Fed-PLoRAåœ¨å‡ ä¹æ‰€æœ‰ä»»åŠ¡å’Œæ•°æ®é›†ä¸Šéƒ½**æ˜¾è‘—ä¼˜äº**æ‰€æœ‰å¼‚æ„åŸºçº¿æ–¹æ³•ï¼Œå¹¶ä¸”ç»å¸¸èƒ½**è¶…è¶Šç”šè‡³æ¥è¿‘æˆ–è¶…è¿‡**åŒæ„çš„ `FedIT` (Rank=R/2) æˆ– `FedIT` (Rank=R)ã€‚

#### ä»£è¡¨æ€§ç»“æœæ‘˜è¦ï¼š
- **Natural Instructions (IID)**ï¼š
  - Fed-PLoRA çš„Rouge-Låˆ†æ•°è¾¾åˆ° **64.96**ï¼Œæ¯”æœ€ä½³å¼‚æ„åŸºçº¿ `HETLoRA` (58.84) é«˜å‡º **+6.12**ï¼Œç”šè‡³è¶…è¿‡äº†åŒæ„çš„ `FedIT` (Rank=R/2) (64.52)ã€‚
- **GLUE Benchmark (IID)**ï¼š
  - Fed-PLoRA çš„å¹³å‡å¾—åˆ†è¾¾åˆ° **79.89**ï¼Œå¤§å¹…é¢†å…ˆäº `FLoRA` (47.81), `FlexLoRA` (65.31), å’Œ `HETLoRA` (73.55)ã€‚
  - åœ¨ `CoLA` ä¸Šï¼Œç›¸æ¯” `FLoRA` çš„æ€§èƒ½æå‡é«˜è¾¾ **+63.46%**ã€‚
- **é‡‘èæ•°æ®é›† (IID)**ï¼š
  - Fed-PLoRA å¹³å‡å¾—åˆ†ä¸º **53.27**ï¼Œä¼˜äº `FLoRA` (+8.51%), `FlexLoRA` (+0.89%), å’Œ `HETLoRA` (+2.55%)ï¼Œå¹¶ä¸”è¶…è¿‡äº†åŒæ„çš„ `FedIT`ã€‚
- **MATH æ•°æ®é›†**ï¼š
  - Fed-PLoRA çš„å¹³å‡å‡†ç¡®ç‡è¾¾åˆ° **28.96**ï¼Œæ˜¾è‘—é«˜äº `FLoRA` (7.94), `FlexLoRA` (24.88), å’Œ `HETLoRA` (18.16)ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **Select-N-Fold ç­–ç•¥çš„æœ‰æ•ˆæ€§**ï¼š
  - å¯¹æ¯”äº† `Weight Norm`ï¼ˆæŒ‰æƒé‡èŒƒæ•°é€‰æ‹©ï¼‰ã€`Fixed`ï¼ˆå›ºå®šé€‰æ‹©å‰å‡ ä¸ªï¼‰å’Œ `Select-N-Drop`ï¼ˆéšæœºé€‰æ‹©ä½†ä¸¢å¼ƒæœªé€‰æ¨¡å—ï¼‰ã€‚
  - ç»“æœæ˜¾ç¤ºï¼Œ**éšæœºé€‰æ‹©**ï¼ˆ`Select-N-Fold` å’Œ `Select-N-Drop`ï¼‰çš„æ€§èƒ½è¿œè¶…ç¡®å®šæ€§é€‰æ‹©ï¼Œå› ä¸ºéšæœºæ€§ä¿è¯äº†æ‰€æœ‰å…¨å±€æ¨¡å—æœ€ç»ˆéƒ½ä¼šè¢«æ›´æ–°ã€‚
  - `Select-N-Fold` æ€§èƒ½æœ€å¥½ï¼Œå› ä¸ºå®ƒé€šè¿‡â€œæŠ˜å â€æœºåˆ¶å¤ç”¨äº†æœªé€‰æ¨¡å—çš„ä¿¡æ¯ã€‚
- **ä¸åŒè¶…å‚æ•°çš„å½±å“**ï¼š
  - å®éªŒè¡¨æ˜ï¼ŒFed-PLoRAåœ¨ä¸åŒçš„å®¢æˆ·ç«¯æ€»æ•°ï¼ˆTCï¼‰å’Œèµ„æºå¼‚è´¨æ€§æ¯”ä¾‹ï¼ˆHRï¼‰ä¸‹éƒ½è¡¨ç°ç¨³å¥ï¼Œæ€§èƒ½å§‹ç»ˆé¢†å…ˆã€‚
- **PLoRA ç§©å¤§å°çš„å½±å“**ï¼š
  - å¯¹æ¯”äº†å¹¶è¡Œâ€œå•ç§©â€å’Œâ€œåŒç§©â€æ¨¡å—ï¼Œç»“æœæ˜¾ç¤ºå•ç§©è®¾è®¡æ•ˆæœæ›´ä¼˜ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1.  **åˆå§‹åŒ–å’Œèšåˆå™ªå£°æ˜¯å¼‚æ„FFTæ€§èƒ½ç“¶é¢ˆçš„å…³é”®**ï¼šç°æœ‰æ–¹æ³•ï¼ˆFLoRA, FlexLoRA, HETLoRAï¼‰å› å¤„ç†ç§©å¼‚è´¨æ€§è€Œå¼•å…¥çš„å™ªå£°æ˜¯å…¶æ€§èƒ½å—é™çš„æ ¹æœ¬åŸå› ã€‚
2.  **Fed-PLoRAçš„è®¾è®¡æœ‰æ•ˆè§£å†³äº†å™ªå£°é—®é¢˜**ï¼šé€šè¿‡ `PLoRA` çš„æ¨¡å—åŒ–è®¾è®¡å’Œ `Select-N-Fold` ç­–ç•¥ï¼Œå®ç°äº†**é›¶åˆå§‹åŒ–å™ªå£°**å’Œ**æä½çš„èšåˆå™ªå£°**ã€‚
3.  **å¹¶è¡ŒåŒ–è®¾è®¡å¸¦æ¥äº†æ›´å¥½çš„è·¨å®¢æˆ·ç«¯å¯¹é½**ï¼šå®éªŒä¸­çš„ä½™å¼¦ç›¸ä¼¼åº¦åˆ†æï¼ˆFigure 2ï¼‰æ˜¾ç¤ºï¼ŒFed-PLoRAè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸åŒå®¢æˆ·ç«¯çš„ç›¸åŒç§©æ¨¡å—å‚æ•°é€æ¸å¯¹é½ï¼Œè¿™è§£é‡Šäº†å…¶ä½èšåˆå™ªå£°çš„åŸå› ã€‚
4.  **æ–¹æ³•å…·æœ‰å¼ºå¤§çš„é²æ£’æ€§å’Œé€‚åº”æ€§**ï¼šFed-PLoRAåœ¨å„ç§æ¨¡å‹ã€æ•°æ®é›†ã€IID/éIIDæ•°æ®åˆ†å¸ƒä»¥åŠä¸åŒç¨‹åº¦çš„èµ„æºå¼‚è´¨æ€§ä¸‹éƒ½è¡¨ç°å‡ºè‰²ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¸‹é“¾è·¯é€šä¿¡æˆæœ¬å¢åŠ **ï¼šæœåŠ¡å™¨éœ€è¦å‘æ‰€æœ‰å®¢æˆ·ç«¯å¹¿æ’­å®Œæ•´çš„é«˜ç§©ï¼ˆRï¼‰å…¨å±€æ¨¡å‹ï¼Œå¯¹äºèµ„æºæåº¦å—é™çš„å®¢æˆ·ç«¯ï¼Œè¿™å¯èƒ½æ„æˆä¸€å®šçš„å¸¦å®½è´Ÿæ‹…ï¼ˆå°½ç®¡å®éªŒè¯æ˜å…¶ç»å¯¹å€¼å¾ˆå°ï¼‰ã€‚
- **ç†è®ºä¸Šçš„èšåˆå™ªå£°æœªå®Œå…¨æ¶ˆé™¤**ï¼šè™½ç„¶å™ªå£°è¢«æœ€å°åŒ–ï¼Œä½†å½“ä¸åŒå®¢æˆ·ç«¯å¯¹åŒä¸€ç§©æ¨¡å—çš„æ›´æ–°å­˜åœ¨è¾ƒå¤§æ–¹å·®æ—¶ï¼Œèšåˆå™ªå£°ä¾ç„¶å­˜åœ¨ï¼ˆå°½ç®¡è¿œå°äºå…¶ä»–æ–¹æ³•ï¼‰ã€‚
- **ä¾èµ–äºLoRAå‡è®¾**ï¼šè¯¥æ–¹æ³•æ˜¯ä¸“é—¨ä¸ºåŸºäºLoRAçš„å¾®è°ƒè®¾è®¡çš„ï¼Œå…¶ä¼˜åŠ¿åœ¨å…¶ä»–PEFTæ–¹æ³•ï¼ˆå¦‚Adapterï¼‰ä¸­å¯èƒ½ä¸ç›´æ¥é€‚ç”¨ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **è¿›ä¸€æ­¥é™ä½èšåˆå™ªå£°**ï¼šæ¢ç´¢å¦‚ä½•æ›´å¥½åœ°åè°ƒå®¢æˆ·ç«¯æ›´æ–°ï¼Œä½¿åŒä¸€ç§©æ¨¡å—çš„å‚æ•°æ›´åŠ ä¸€è‡´ã€‚
- **ç»“åˆå…¶ä»–ä¼˜åŒ–æŠ€æœ¯**ï¼šå°†Fed-PLoRAä¸é‡åŒ–ï¼ˆQuantizationï¼‰ã€é›¶é˜¶ä¼˜åŒ–ï¼ˆZeroth-order optimizationï¼‰ç­‰æŠ€æœ¯ç»“åˆï¼Œæ‰“é€ æ›´å…¨é¢çš„èµ„æºé«˜æ•ˆè®­ç»ƒæ–¹æ¡ˆã€‚
- **æ¢ç´¢æ•°æ®å¼‚è´¨æ€§ä¸‹çš„åº”ç”¨**ï¼šæ›´æ·±å…¥åœ°ç ”ç©¶åœ¨æç«¯éIIDæ•°æ®åˆ†å¸ƒä¸‹ï¼Œ`Select-N-Fold` ç­–ç•¥å¦‚ä½•å½±å“æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œå…¬å¹³æ€§ã€‚

</details>

---

### 10. [Trivance: Latency-Optimal AllReduce by Shortcutting Multiport Networks](https://arxiv.org/abs/2602.17254)

**Authors**: Anton Juerss, Vamsi Addanki, Stefan Schmid  
**Category**: cs.DC  
**Published**: 2026-02-20  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.17254v1  

#### Abstract
AllReduce is a fundamental collective operation in distributed computing and a key performance bottleneck for large-scale training and inference. Its completion time is determined by the number of communication steps, which dominates latency-sensitive workloads, and the communication distance affect...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTRIVANCE: Latency-Optimal AllReduce by Shortcutting Multiport Networks

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜

åœ¨å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒå’Œæ¨ç†ä¸­ï¼Œ**AllReduce** æ˜¯ä¸€ä¸ªæ ¸å¿ƒçš„é›†ä½“é€šä¿¡æ“ä½œï¼Œå¸¸ç”¨äºæ¢¯åº¦åŒæ­¥ã€‚å…¶æ€§èƒ½ç“¶é¢ˆä¸»è¦ä½“ç°åœ¨ä¸¤ä¸ªæ–¹é¢ï¼š

- **å»¶è¿Ÿæ•æ„Ÿåœºæ™¯ä¸‹çš„é€šä¿¡æ­¥æ•°ï¼ˆlatencyï¼‰**ï¼šä¼ ç»Ÿç®—æ³•å¦‚ Recursive Doubling éœ€è¦ $ \log_2 n $ æ­¥ï¼Œé™åˆ¶äº†å°æ¶ˆæ¯çš„æ•ˆç‡ã€‚
- **ç½‘ç»œæ‹¥å¡ä¸é€šä¿¡è·ç¦»ï¼ˆcongestion & bandwidthï¼‰**ï¼šBruck ç®—æ³•è™½èƒ½åœ¨ $ \log_3 n $ æ­¥å†…å®Œæˆï¼Œä½†æ‰€æœ‰æµé‡å•å‘ä¼ è¾“ï¼Œå¯¼è‡´åå‘é“¾è·¯é—²ç½®ã€ä¸¥é‡æ‹¥å¡ã€‚

ç°æœ‰æ–¹æ³•å¾€å¾€åœ¨â€œä½å»¶è¿Ÿâ€å’Œâ€œä½æ‹¥å¡/é«˜å¸¦å®½åˆ©ç”¨ç‡â€ä¹‹é—´æƒè¡¡ï¼Œæ— æ³•åŒæ—¶ä¼˜åŒ–ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ ¸å¿ƒæ€æƒ³

æœ¬æ–‡æå‡º **TRIVANCE**ï¼Œä¸€ç§å…¨æ–°çš„ AllReduce ç®—æ³•ï¼Œä¸“ä¸ºå…·æœ‰åŒå‘è¿æ¥èƒ½åŠ›çš„å¤šç«¯å£ç½‘ç»œï¼ˆå¦‚ç¯å½¢ã€torusï¼‰è®¾è®¡ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š

1. **åˆ©ç”¨åŒç«¯å£å®ç°ä¸‰å€é€šä¿¡è·ç¦»ï¼ˆTriple Communication Distanceï¼‰**
   - åœ¨æ¯ä¸€æ­¥ä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹é€šè¿‡å·¦å³ä¸¤ä¸ª port åŒæ—¶å‘é€/æ¥æ”¶æ•°æ®ï¼Œé€šä¿¡è·ç¦»ä¸º $ 3^k $ã€‚
   - ç›¸æ¯”äº Bruck çš„å•å‘ $ 3^k $ è·³è·ƒï¼ŒTRIVANCE åŒå‘å¹¶è¡Œè·³è·ƒï¼Œæœ‰æ•ˆâ€œshortcutting the ringâ€ã€‚

2. **è”åˆå½’çº¦ï¼ˆJoint Reductionï¼‰æœºåˆ¶**
   - æ¯ä¸ªèŠ‚ç‚¹åœ¨æ¥æ”¶åˆ°æ¥è‡ªä¸¤ä¸ªæ–¹å‘çš„æ•°æ®åï¼Œç«‹å³è¿›è¡Œåˆå¹¶å½’çº¦ï¼Œå¹¶å°†ç»“æœè½¬å‘è‡³ä¸‹ä¸€è·³ã€‚
   - è¿™ç§æ–¹å¼æ˜¾è‘—æå‡äº†æ¯æ­¥å¤„ç†çš„æ•°æ®å—æ•°é‡ï¼ŒåŠ å¿«å…¨å±€è¦†ç›–é€Ÿåº¦ã€‚

3. **è¾¾åˆ°ç†è®ºæœ€ä¼˜é€šä¿¡æ­¥æ•° $ \lceil \log_3 n \rceil $**
   - å®ç°äº†ä¸ Bruck ç›¸åŒçš„ **latency-optimal** æ€§è´¨ï¼Œå³æœ€å°‘é€šä¿¡æ­¥éª¤ã€‚
   - ä½†åœ¨ç›¸åŒæ­¥æ•°ä¸‹ï¼Œ**å¤§å¹…é™ä½é“¾è·¯æ‹¥å¡**ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç‰¹æ€§ | TRIVANCE | Bruck | Recursive Doubling / Swing |
|------|----------|-------|-----------------------------|
| é€šä¿¡æ­¥æ•°ï¼ˆLatencyï¼‰ | âœ… $ \log_3 n $ï¼ˆæœ€ä¼˜ï¼‰ | âœ… $ \log_3 n $ | âŒ $ \log_2 n $ï¼ˆæ›´æ…¢ï¼‰ |
| æ‹¥å¡ç¨‹åº¦ï¼ˆCongestionï¼‰ | âœ… æä½ï¼ˆå‡åŒ€åˆ†å¸ƒï¼‰ | âŒ é«˜ï¼ˆå•å‘é›†ä¸­ï¼‰ | â­• ä¸­ç­‰ |
| å¸¦å®½åˆ©ç”¨ç‡ | âœ… å‡åŒ€åˆ©ç”¨åŒå‘é“¾è·¯ | âŒ æµªè´¹åå‘å¸¦å®½ | â­• åˆ©ç”¨éƒ¨åˆ† |
| ä¼ è¾“å»¶è¿Ÿï¼ˆTransmission Delayï¼‰ | âœ… æ˜¾è‘—ä¼˜äº Bruckï¼ˆä½3å€ï¼‰ | âŒ æœ€å·® | âœ… è¾ƒå¥½ï¼ˆå°¤å…¶å¤§æ¶ˆæ¯ï¼‰ |
| æ‰©å±•æ€§ | âœ… è‡ªç„¶æ‰©å±•åˆ° Dç»´ torus | âœ… å¯æ‰©å±• | âœ… å¯æ‰©å±• |

> âœ… **TRIVANCE æˆåŠŸå®ç°äº† latency-optimal å’Œ congestion-minimized çš„ç»Ÿä¸€**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ§ª å®éªŒå¹³å°ä¸å·¥å…·

- **ä»¿çœŸå™¨**ï¼šStructural Simulation Toolkit (**SST**)ï¼Œäº‹ä»¶é©±åŠ¨ã€åŒ…çº§ç½‘ç»œæ¨¡æ‹Ÿå™¨ã€‚
- **å®ç°å†…å®¹**ï¼š
  - å®Œæ•´å®ç°äº† TRIVANCE ç®—æ³•ï¼ˆlatency-optimal å’Œ bandwidth-optimal ä¸¤ç§å˜ä½“ï¼‰ã€‚
  - å¤ç°å¹¶ä¼˜åŒ–äº† Bruckã€Bucketã€Recursive Doublingã€Swing ç­‰åŸºçº¿ç®—æ³•ã€‚
- **å¼€æºä»£ç ä¾èµ–**ï¼šåŸºäº Daniele et al. [35] çš„å…¬å¼€å®ç°ã€‚

---

### ğŸ“ ç½‘ç»œé…ç½®å‚æ•°

| å‚æ•° | è®¾ç½® |
|------|------|
| ç½‘ç»œæ‹“æ‰‘ | Ring, 2D Torus ($8\times8$, $32\times32$), 3D Torus ($16\times16\times16$) |
| èŠ‚ç‚¹æ•°èŒƒå›´ | $ n = 8, 64, 729 $ï¼ˆæ”¯æŒ power-of-three å’Œ power-of-twoï¼‰ |
| é“¾è·¯å¸¦å®½ | é»˜è®¤ 800 Gb/sï¼ˆæµ‹è¯•æ—¶æ‰©å±•è‡³ 200 Gb/s ~ 3.2 Tb/sï¼‰ |
| é“¾è·¯å»¶è¿Ÿ | 100 ns |
| åŒ…å¤„ç†å»¶è¿Ÿ | 100 ns/hop |
| æ¯æ­¥å¯åŠ¨å»¶è¿Ÿï¼ˆÎ±ï¼‰ | 1.5 Î¼s |

---

### ğŸ“Š æ¶ˆæ¯å¤§å°ä¸è¯„ä¼°æŒ‡æ ‡

- **æ¶ˆæ¯å°ºå¯¸**ï¼šä» **32 Bytes åˆ° 128 MiB**ï¼Œè¦†ç›–å…¸å‹è®­ç»ƒä¸­å°åˆ°å¤§çš„æ¢¯åº¦è§„æ¨¡ã€‚
- **ä¸»è¦è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **AllReduce å®Œæˆæ—¶é—´ï¼ˆCompletion Timeï¼‰**
  - å½’ä¸€åŒ–æ€§èƒ½æå‡ï¼ˆç›¸å¯¹äº TRIVANCEï¼‰
  - é€šä¿¡é˜¶æ®µåˆ†è§£åˆ†æï¼ˆReduce-Scatter vs AllGatherï¼‰

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| ç®—æ³• | ç±»å‹ | æè¿° |
|------|------|------|
| **Bruck** | Latency-optimal | ç»å…¸ $ \log_3 n $ æ­¥ç®—æ³•ï¼Œä½†å•å‘é€šä¿¡å¯¼è‡´é«˜æ‹¥å¡ |
| **Recursive Doubling** | Latency/BW-optimal | ä¼ ç»Ÿ $ \log_2 n $ æ­¥ç®—æ³•ï¼Œæœ‰å¸¦å®½ä¼˜åŒ–ç‰ˆæœ¬ï¼ˆRabenseifnerï¼‰ |
| **Swing** | Recent low-congestion | æ–°è¿‘æå‡ºçš„ç¯ç½‘ä¼˜åŒ–ç®—æ³•ï¼Œäº¤æ›¿æ–¹å‘ä»¥å¹³è¡¡è´Ÿè½½ |
| **Bucket** | Bandwidth-optimal | åœ¨ torus ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œé€‚åˆå¤§æ¶ˆæ¯ |

> æ‰€æœ‰ç®—æ³•å‡é€‚é…åŒå‘å¤šç«¯å£æ¨¡å‹ï¼Œå¹¶å°½å¯èƒ½å‘æŒ¥å…¶æ½œåŠ›ï¼ˆå¦‚ mirror collectiveï¼‰ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| åœºæ™¯ | TRIVANCE æå‡å¹…åº¦ | è¯´æ˜ |
|------|--------------------|------|
| å°æ¶ˆæ¯ (< 8 MiB) on 2D Torus | **5â€“30% æ›´å¿«** | latency-bound åŒºåŸŸä¼˜åŠ¿æ˜æ˜¾ |
| é«˜å¸¦å®½ç¯å¢ƒ (< 32 MiB) | **æœ€é«˜è¾¾ 30%** | å»¶è¿Ÿä¸»å¯¼ï¼ŒTRIVANCE æ›´ä¼˜ |
| 3D Torus (< 128 MiB) | **5â€“15% æ›´å¿«** | å³ä½¿å¤§æ¶ˆæ¯ä»ä¿æŒé¢†å…ˆ |
| Power-of-three ç½‘ç»œ | **>50% æå‡ï¼ˆvs Bucket @ 512 KiBï¼‰** | åœ¨ç†æƒ³æ‹“æ‰‘ä¸‹ä¼˜åŠ¿å·¨å¤§ |

---

### ğŸ“Š ä¸åŸºçº¿æ–¹æ³•çš„å…·ä½“å¯¹æ¯”

#### ğŸ”¹ Ring ç½‘ç»œï¼ˆFig. 6ï¼‰

- **å°æ¶ˆæ¯ï¼ˆ< 512 KiBï¼‰**ï¼š
  - TRIVANCE æ¯” Swing / Recursive Doubling å¿« **>20%**
  - æ¯” Bruck å¿« **~5â€“10%**ï¼ˆå°½ç®¡æ­¥æ•°ç›¸åŒï¼Œä½†æ‹¥å¡æ›´ä½ï¼‰
- **å¤§æ¶ˆæ¯ï¼ˆ> 4 MiBï¼‰**ï¼š
  - Bucket å› å¸¦å®½æœ€ä¼˜å¼€å§‹åè¶…
  - ä½† TRIVANCE åœ¨ **< 128 KiB** å†…å§‹ç»ˆæœ€ä¼˜

#### ğŸ”¹ 2D Torusï¼ˆFig. 7ï¼‰

- **trade-off point æ¨è¿Ÿåˆ° 8 MiB**ï¼ˆæ¯” ring æ›´é«˜ï¼‰
- åœ¨ **32 KiB ~ 2 MiB** åŒºé—´ï¼ŒTRIVANCE æ¯”æ‰€æœ‰ç®—æ³•å¿« **æœ€å¤š 25%**
- åœ¨ **power-of-three torus (27Ã—27)** ä¸Šï¼š
  - å¯¹ Bucket å’Œ Bruck å®ç° **>50% åŠ é€Ÿï¼ˆ@ >512 KiBï¼‰**
  - å³ä½¿åœ¨ 32 MiB ä»å¿« **>40%**

#### ğŸ”¹ 3D Torusï¼ˆFig. 10ï¼‰

- TRIVANCE **åœ¨å…¨æ¶ˆæ¯èŒƒå›´å†…ï¼ˆ32Bâ€“128MiBï¼‰å…¨é¢é¢†å…ˆ**
- å¹³å‡å¿« **5â€“15%**
- åœ¨ 128 MiB æ—¶ä»æ¯”ç¬¬äºŒå Swing å¿« **8%**

#### ğŸ”¹ å¸¦å®½å½±å“åˆ†æï¼ˆFig. 8ï¼‰

- **ä½å¸¦å®½ï¼ˆ200 Gb/sï¼‰**ï¼šbandwidth-optimal æ–¹æ³•ï¼ˆå¦‚ Swingï¼‰æ›´å¿«ï¼ˆ>4 MiBï¼‰
- **é«˜å¸¦å®½ï¼ˆ>2.4 Tb/sï¼‰**ï¼šTRIVANCE ä¼˜åŠ¿æŒç»­åˆ° **64 MiB**
  > è¡¨æ˜ TRIVANCE æ›´é€‚ç”¨äºç°ä»£é«˜é€Ÿäº’è”ï¼ˆå¦‚ TPUv4ï¼‰

---

### ğŸ”¬ æ¶ˆèå®éªŒä¸ç†è®ºéªŒè¯ï¼ˆéšå«ï¼‰

è™½ç„¶æœªæ˜ç¡®å‘½åâ€œablationâ€ï¼Œä½†è®ºæ–‡é€šè¿‡ä»¥ä¸‹æ–¹å¼éªŒè¯è®¾è®¡æœ‰æ•ˆæ€§ï¼š

- **ç†è®ºè¯æ˜**ï¼š
  - Lemmas 4.1â€“4.2 å’Œ Theorem 4.3 ä¸¥æ ¼è¯æ˜äº† TRIVANCE çš„ **bandwidth-optimality** å’Œ **latency-optimality**ã€‚
- **æ‹¥å¡å»ºæ¨¡åˆ†æ**ï¼š
  - åˆ†ææ˜¾ç¤º Bruck çš„ä¼ è¾“å»¶è¿Ÿæ˜¯ TRIVANCE çš„ **3å€**ï¼ˆå› æ¯æ­¥æ‹¥å¡ä¸º $3 \times 3^k$ï¼‰ã€‚
- **ä»»æ„ç½‘ç»œè§„æ¨¡é€‚åº”æ€§**ï¼š
  - æ”¯æŒé power-of-three è§„æ¨¡ï¼Œä»…éœ€æœ€åä¸€æ­¥è°ƒæ•´è·ç¦»ï¼Œä»æ¥è¿‘æœ€ä¼˜ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **TRIVANCE æ˜¯é¦–ä¸ªåŒæ—¶å®ç° $ \log_3 n $ æ­¥å’Œä½æ‹¥å¡çš„ AllReduce ç®—æ³•**ã€‚
2. é€šè¿‡ **åŒå‘å¹¶å‘é€šä¿¡ + è”åˆå½’çº¦**ï¼Œå®ç°äº†å¯¹ç¯å½¢/å¤šç»´ torus ç½‘ç»œçš„é«˜æ•ˆâ€œshortcuttingâ€ã€‚
3. åœ¨ **å°åˆ°ä¸­ç­‰æ¶ˆæ¯ï¼ˆup to 128 MiBï¼‰** ä¸‹ï¼ŒTRIVANCE æ˜¯å½“å‰æ€§èƒ½æœ€å¥½çš„ **latency-optimal AllReduce ç®—æ³•**ã€‚
4. åœ¨ **power-of-three ç½‘ç»œæ‹“æ‰‘** ä¸Šä¼˜åŠ¿æœ€å¤§ï¼Œå¯è¾¾ **50%+ æ€§èƒ½æå‡**ã€‚
5. éšç€ç½‘ç»œç»´åº¦å’Œå¸¦å®½å¢åŠ ï¼ŒTRIVANCE çš„ä¼˜åŠ¿åŒºé—´è¿›ä¸€æ­¥æ‰©å¤§ã€‚

---

### âš ï¸ å±€é™æ€§

1. **æœ€ä½³æ€§èƒ½ä¾èµ– power-of-three èŠ‚ç‚¹æ•°**
   - å½“å‰ä¸»æµç³»ç»Ÿå¤šé‡‡ç”¨ power-of-twoï¼Œéƒ¨ç½²éœ€é‡æ–°è§„åˆ’æ‹“æ‰‘ã€‚
2. **å¤§æ¶ˆæ¯åœºæ™¯ä¸‹ bandwidth-optimal ç®—æ³•æœ€ç»ˆèƒœå‡º**
   - å¦‚ Bucket åœ¨ >128 MiB æ—¶æ›´ä¼˜ï¼ŒTRIVANCE ä¸å–ä»£å¸¦å®½æœ€ä¼˜æ–¹æ¡ˆã€‚
3. **æœªè€ƒè™‘ç¡¬ä»¶ offload æˆ– in-network computing**
   - è‹¥æœªæ¥æ”¯æŒæ™ºèƒ½ç½‘å¡åŠ é€Ÿï¼Œå¯èƒ½æ”¹å˜ç›¸å¯¹ä¼˜åŠ¿ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³å…¶ä»– collective operations**
   - å¦‚ AllGatherã€All-to-Allï¼Œåº”ç”¨ TRIVANCE çš„åŒå‘ shortcutting æ€æƒ³ã€‚
2. **é€‚é…æ›´å¤šç½‘ç»œæ‹“æ‰‘**
   - å¦‚ Dragonflyã€Fat Treeã€HammingMesh ç­‰å¤šç«¯å£ç»“æ„ã€‚
3. **ä¸è°ƒåº¦å™¨ç»“åˆï¼ˆco-designï¼‰**
   - åŠ¨æ€é€‰æ‹© TRIVANCEï¼ˆå°æ¶ˆæ¯ï¼‰æˆ– Bucketï¼ˆå¤§æ¶ˆæ¯ï¼‰ä»¥å®ç°è‡ªé€‚åº”ä¼˜åŒ–ã€‚
4. **å®é™…éƒ¨ç½²éªŒè¯**
   - åœ¨çœŸå® TPU/GPU é›†ç¾¤ä¸Šé›†æˆ TRIVANCEï¼ˆå¦‚é€šè¿‡ MPI æˆ– NCCL æ‰©å±•ï¼‰ã€‚

---

## âœ… æ€»ç»“ä¸€å¥è¯

> **TRIVANCE é€šè¿‡åŒå‘å¹¶å‘é€šä¿¡ä¸è”åˆå½’çº¦ï¼Œåœ¨ä¿æŒ $ \log_3 n $ æœ€ä¼˜å»¶è¿Ÿçš„åŒæ—¶ï¼Œå°†æ‹¥å¡é™ä½3å€ï¼Œæˆä¸ºå½“å‰ latency-optimal AllReduce ç®—æ³•ä¸­çš„æ€§èƒ½æ ‡æ†ï¼Œç‰¹åˆ«é€‚ç”¨äºé«˜å¸¦å®½ã€ä¸­å°æ¶ˆæ¯çš„ç°ä»£ AI è®­ç»ƒé›†ç¾¤ï¼ˆå¦‚ TPUv4ï¼‰ã€‚**

</details>

---

### 11. [Spatio-temporal dual-stage hypergraph MARL for human-centric multimodal corridor traffic signal control](https://arxiv.org/abs/2602.17068)

**Authors**: Xiaocai Zhang, Neema Nassir, Milad Haghani  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.17068v1  

#### Abstract
Human-centric traffic signal control in corridor networks must increasingly account for multimodal travelers, particularly high-occupancy public transportation, rather than focusing solely on vehicle-centric performance. This paper proposes STDSH-MARL (Spatio-Temporal Dual-Stage Hypergraph based Mul...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSpatio-temporal dual-stage hypergraph MARL for human-centric multimodal corridor traffic signal control

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿäº¤é€šä¿¡å·æ§åˆ¶ï¼ˆTSCï¼‰æ–¹æ³•ï¼ˆå¦‚ SCATSã€SCOOTï¼‰ä¸»è¦ä¼˜åŒ–**è½¦è¾†ä¸­å¿ƒåŒ–æŒ‡æ ‡**ï¼ˆå¦‚æ’é˜Ÿé•¿åº¦ã€ç­‰å¾…æ—¶é—´ï¼‰ï¼Œå¿½è§†äº†å¤šæ¨¡å¼å‡ºè¡Œè€…ï¼ˆå°¤å…¶æ˜¯é«˜è½½å®¢é‡å…¬å…±äº¤é€šå¦‚å…¬äº¤ã€æœ‰è½¨ç”µè½¦ï¼‰çš„é€šè¡Œéœ€æ±‚ã€‚è¿™å¯¼è‡´åœ¨æ‹¥å µæƒ…å†µä¸‹ï¼Œå¤§é‡ä¹˜å®¢å› å…¬å…±äº¤é€šå»¶è¯¯è€Œæ‰¿å—ä¸æˆæ¯”ä¾‹çš„å‡ºè¡Œæˆæœ¬ã€‚

æ­¤å¤–ï¼Œç°æœ‰åŸºäº DRL çš„å¤šæ™ºèƒ½ä½“ TSC æ–¹æ³•å¤§å¤šï¼š
- å¿½è§†**äººç±»ä¸­å¿ƒåŒ–ç›®æ ‡**ï¼ˆhuman-centric objectivesï¼‰
- é‡‡ç”¨ç®€å•å›¾ç»“æ„å»ºæ¨¡è·¯ç½‘ï¼Œéš¾ä»¥æ•æ‰å¤æ‚æ—¶ç©ºä¾èµ–å…³ç³»
- åŠ¨ä½œç©ºé—´è®¾è®¡å•ä¸€ï¼Œæ— æ³•è”åˆä¼˜åŒ–ç›¸ä½é€‰æ‹©ä¸ç»¿ç¯æ—¶é•¿

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
æœ¬æ–‡æå‡º **STDSH-MARL**ï¼ˆSpatio-Temporal Dual-Stage Hypergraph-based Multi-Agent Reinforcement Learningï¼‰ï¼Œä¸€ç§é¢å‘äººæœ¬ä¸»ä¹‰çš„å¤šæ¨¡å¼èµ°å»Šäº¤é€šä¿¡å·æ§åˆ¶æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

| åˆ›æ–°ç‚¹ | å†…å®¹è¯´æ˜ |
|--------|--------|
| **1. äººç±»ä¸­å¿ƒåŒ–å¥–åŠ±æœºåˆ¶** | å°†â€œç»å†å»¶è¿Ÿçš„ä¹˜å®¢æ€»æ•°â€ä½œä¸ºå¥–åŠ±å‡½æ•°ï¼Œè€Œéä»…è€ƒè™‘è½¦è¾†æ•°é‡ï¼ŒçœŸæ­£å®ç°å¯¹å…¬äº¤ã€æœ‰è½¨ç”µè½¦ç­‰é«˜è½½å®¢ç‡äº¤é€šå·¥å…·çš„ä¼˜å…ˆä¿éšœ |
| **2. å¤šæ¨¡å¼äº¤é€šå»ºæ¨¡** | æ˜¾å¼å»ºæ¨¡ç§å®¶è½¦ã€å…¬äº¤è½¦ã€æœ‰è½¨ç”µè½¦ã€è¡Œäººã€éª‘è¡Œè€…ç­‰å¤šç§å‡ºè¡Œæ–¹å¼ï¼Œå¹¶åˆ©ç”¨å®æ—¶æ„ŸçŸ¥æŠ€æœ¯ï¼ˆå¦‚è“ç‰™è®¡æ•°ã€Wi-Fi ä¹˜å‘˜æ£€æµ‹ï¼‰è·å–å„æ¨¡å¼ä¹˜å®¢æ•° |
| **3. è‡ªé€‚åº”æ··åˆåŠ¨ä½œç©ºé—´** | è”åˆå†³ç­–ä¸‹ä¸€ä¿¡å·ç›¸ä½é…ç½®ï¼ˆ4ç§ï¼‰åŠå…¶å¯¹åº”ç»¿ç¯æŒç»­æ—¶é—´ï¼ˆ8â€“45ç§’å…±38ä¸ªé€‰é¡¹ï¼‰ï¼Œå½¢æˆç»´åº¦ä¸º $4 \times 38 = 152$ çš„ç¦»æ•£åŠ¨ä½œç©ºé—´ï¼Œæå‡æ§åˆ¶çµæ´»æ€§ |
| **4. åŒé˜¶æ®µè¶…å›¾æ³¨æ„åŠ›æœºåˆ¶ï¼ˆDSHAï¼‰** | æ„å»ºæ—¶ç©ºåŒç»´è¶…å›¾ï¼ˆspatio-temporal hypergraphï¼‰ï¼š<br>â€¢ **ç©ºé—´è¶…è¾¹ï¼ˆSHEï¼‰**ï¼šè¿æ¥åŒä¸€æ—¶åˆ»æ‰€æœ‰äº¤å‰å£<br>â€¢ **æ—¶é—´è¶…è¾¹ï¼ˆTHEï¼‰**ï¼šè¿æ¥åŒä¸€äº¤å‰å£çš„å†å²çŠ¶æ€<br>é€šè¿‡ **intra-/inter-hyperedge attention** å­¦ä¹ èŠ‚ç‚¹é—´é«˜é˜¶äº¤äº’å…³ç³» |
| **5. CTDE æ¶æ„ä¸‹çš„å¯æ‰©å±•æ€§è®¾è®¡** | é‡‡ç”¨ Centralized Training and Decentralized Executionï¼ˆCTDEï¼‰èŒƒå¼ï¼Œè®­ç»ƒæ—¶ä½¿ç”¨å…¨å±€è¶…å›¾åµŒå…¥æŒ‡å¯¼ criticï¼Œæ‰§è¡Œæ—¶å„ agent ä»…ä¾èµ–æœ¬åœ°è§‚æµ‹ï¼Œæ”¯æŒå¤§è§„æ¨¡éƒ¨ç½² |

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- æ›´å¥½åœ°å¹³è¡¡**å¤šæ¨¡æ€å…¬å¹³æ€§**ï¼Œæ˜¾è‘—é™ä½é«˜è½½å®¢å…¬å…±äº¤é€šå·¥å…·çš„å»¶è¯¯
- æ•æ‰æ›´å¤æ‚çš„**è·¨æ—¶ç©ºä¾èµ–å…³ç³»**ï¼Œä¼˜äºä¼ ç»Ÿ GNN/GAT/CNN å›¾å»ºæ¨¡
- æ”¯æŒ**ç²¾ç»†åŒ–ä¿¡å·æ§åˆ¶**ï¼ŒåŠ¨æ€è°ƒæ•´ç›¸ä½ä¸æ—¶é•¿ï¼Œå“åº”èƒ½åŠ›æ›´å¼º
- åœ¨å¤šä¸ªçœŸå®æ„Ÿäº¤é€šåœºæ™¯ä¸‹è¡¨ç°ç¨³å®šä¸”é²æ£’æ€§å¼º

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸ä»¿çœŸç¯å¢ƒ
- ä½¿ç”¨ **PTV VISSIM** æ„å»ºä¸€ä¸ªåŒ…å« **6ä¸ªä¿¡å·äº¤å‰å£** çš„åˆæˆåŸå¸‚èµ°å»Šç½‘ç»œï¼ˆå·¦èˆµé©¾é©¶ï¼‰
- åŒ…å«å¸¸è§„è½¦é“ä¸æœ‰è½¨ç”µè½¦ä¸“ç”¨é“ï¼Œè®¾æœ‰ **3ä¸ª tram stop**
- æ‰€æœ‰äº¤é€šæµæ•°æ®ç”±å¾®è§‚ä»¿çœŸç”Ÿæˆï¼Œæ¶µç›–äº”ç±»å…¸å‹äº¤é€šåœºæ™¯

### å®éªŒè®¾ç½®
#### åœºæ™¯è®¾è®¡ï¼ˆ5ç±»ç‹¬ç«‹æµ‹è¯•åœºæ™¯ï¼‰
| åœºæ™¯ | æè¿° |
|------|------|
| Scenario 1 | éé«˜å³°æ—¶æ®µï¼Œä½äº¤é€šéœ€æ±‚ |
| Scenario 2 | å¹³å³°å‘é«˜å³°è¿‡æ¸¡æœŸï¼Œä¸­ç­‰éœ€æ±‚å¢é•¿ |
| Scenario 3 | é«˜å³°æ—¶æ®µï¼Œé«˜äº¤é€šè´Ÿè· |
| Scenario 4 | ä¸Šå­¦æ—©é«˜å³°ï¼Œç‰¹å®šåŒºåŸŸè¿›å‘æµé‡æ¿€å¢ |
| Scenario 5 | æ”¾å­¦æ™šé«˜å³°ï¼Œç‰¹å®šåŒºåŸŸå‡ºå‘æµé‡ä¸Šå‡ |

#### è¯„ä¼°æŒ‡æ ‡ï¼ˆNetwork-wideï¼‰
| æŒ‡æ ‡ | å…¨ç§° | å«ä¹‰ |
|------|------|------|
| **ANP** | Average Number of Passengers experiencing delay | å¹³å‡æ¯ç§’ç»å†å»¶è¿Ÿçš„ä¹˜å®¢æ•°ï¼ˆä¸»æŒ‡æ ‡ï¼‰ |
| **AQL** | Average Queue Length (vehicles) | æ’é˜Ÿè½¦è¾†å¹³å‡é•¿åº¦ï¼ˆä¸å« tramï¼‰ |
| **AWT (bus)** | Average Waiting Time for buses | å…¬äº¤ç©¿è¶Šèµ°å»Šå¹³å‡ç­‰å¾…æ—¶é—´ |
| **AWT (tram)** | Average Waiting Time for trams | æœ‰è½¨ç”µè½¦ç©¿è¶Šèµ°å»Šå¹³å‡ç­‰å¾…æ—¶é—´ |

> æ³¨ï¼šåä¸¤é¡¹ç›´æ¥åæ˜ **å…¬å…±äº¤é€šä¼˜å…ˆç¨‹åº¦**

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **FS-WF** | å›ºå®šé…æ—¶ | Websterå…¬å¼è®¡ç®—å‘¨æœŸä¸ç»¿ä¿¡æ¯” |
| **MADQN** | Value-based | åˆ†å¸ƒå¼ DQNï¼ŒDTDE èŒƒå¼ |
| **MADDQN** | Value-based | æ”¹è¿›ç‰ˆ DDQNï¼Œç¼“è§£è¿‡ä¼°è®¡é—®é¢˜ |
| **MAA2C** | Hybrid | Actor-Critic ç»“æ„ï¼ŒCTDE |
| **MAPPO** | Policy-based | æ ‡å‡†å¤šæ™ºèƒ½ä½“ PPOï¼Œæ— è¶…å›¾æ¨¡å— |
| **CMRM** | Policy-based | PPO + GATï¼Œä»£è¡¨å…ˆè¿›å›¾ç¥ç»æ–¹æ³• |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆæœ€ä¼˜å€¼åŠ ç²—ï¼Œæ¬¡ä¼˜ä¸‹åˆ’çº¿ï¼‰

| Model | ANP â†“ | AQL â†“ | AWT (bus) â†“ | AWT (tram) â†“ |
|-------|--------|--------|--------------|----------------|
| FS-WF | 1919.64~1957.46 | 346.84~384.20 | 502.73~649.73 | 601.95~615.19 |
| MADQN | 1561.18~1608.17 | 285.24~296.93 | 770.98~951.51 | 1556.67~1598.45 |
| MADDQN | 1534.40~1614.39 | 284.17~335.45 | 760.18~951.51 | 1563.67~1607.45 |
| MAA2C | 1673.93~1771.49 | 372.29~395.23 | 358.01~409.98 | 262.05~330.45 |
| MAPPO | 1666.44~1792.93 | 343.47~366.89 | 362.21~411.59 | 325.30~366.55 |
| CMRM | 1801.19~1912.38 | 384.60~424.46 | 384.99~419.64 | 395.90~470.10 |
| **STDSH-MARL** | **1381.70~1573.86** | **304.41~359.24** | **296.79~356.45** | **267.15~351.80** |

> âœ… **STDSH-MARL åœ¨æ‰€æœ‰åœºæ™¯ä¸­å‡å–å¾—æœ€ä½³ ANP è¡¨ç°**

### æ€§èƒ½ä¼˜åŠ¿åˆ†æ
- **ANP æå‡æ˜¾è‘—**ï¼š
  - ç›¸æ¯”æœ€å¼º baselineï¼ˆMADDQNï¼‰ï¼Œåœ¨ Scenario 1 ä¸‹ ANP é™ä½ **10.59%**
  - ç›¸æ¯” MAPPOï¼Œåœ¨ Scenario 5 ä¸­ ANP é™ä½ **5.56%**
- **å…¬å…±äº¤é€šä¼˜å…ˆæ•ˆæœçªå‡º**ï¼š
  - AWT (tram) æœ€ä½å¯è¾¾ **267.15 ç§’**ï¼ˆScenario 2ï¼‰ï¼Œè¿œä½äº DQN/DDQN ç±»æ–¹æ³•ï¼ˆ>1500 ç§’ï¼‰
  - è¡¨æ˜æ¨¡å‹æœ‰æ•ˆè¯†åˆ«å¹¶ä¼˜å…ˆæ”¾è¡Œé«˜è½½å®¢ç‡ tram
- **è½¦è¾†çº§æŒ‡æ ‡ä¿æŒç«äº‰åŠ›**ï¼š
  - AQL è™½ç•¥é«˜äº MADDQNï¼Œä½†å·®è·å°ï¼ˆ<15%ï¼‰ï¼Œä¸”æ¢æ¥äº†å·¨å¤§çš„ä¹˜å®¢ä½“éªŒæå‡

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

| ç»„ä»¶ç§»é™¤æƒ…å†µ | ANPï¼ˆå¹³å‡ï¼‰ | ç›¸å¯¹ä¸‹é™ |
|-------------|-------------|----------|
| å®Œæ•´ STDSH-MARLï¼ˆâˆšHG, âˆšDSHA, âˆšSHE, âˆšTHEï¼‰ | **1541.89** | â€” |
| ç§»é™¤ THEï¼ˆTemporal Hyperedgeï¼‰ | 1765.38 | â†‘14.49% |
| ç§»é™¤ HGï¼ˆHypergraphï¼‰ | 1728.64 | â†‘12.11% |
| ç§»é™¤ DSHAï¼ˆDual-Stage Attentionï¼‰ | 1684.13 | â†‘9.22% |
| ç§»é™¤ SHEï¼ˆSpatial Hyperedgeï¼‰ | 1602.44 | â†‘3.93% |

> ğŸ” **ç»„ä»¶é‡è¦æ€§æ’åºï¼šTHE > HG > DSHA > SHE**

- **Temporal Hyperedges æ˜¯æœ€å…³é”®ç»„ä»¶**ï¼Œè¯´æ˜å»ºæ¨¡å•ä¸ªäº¤å‰å£çš„æ—¶é—´æ¼”åŒ–å†å²å¯¹äºæ€§èƒ½æå‡æœ€ä¸ºå…³é”®
- å³ä½¿åªä¿ç•™ SHE å’Œ THEï¼Œä¹Ÿèƒ½è·å¾—è¾ƒå¥½æ€§èƒ½ï¼ŒéªŒè¯äº†è¶…å›¾ç»“æ„çš„æœ‰æ•ˆæ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **äººç±»ä¸­å¿ƒåŒ–ç›®æ ‡å¯è¡Œä¸”å¿…è¦**ï¼šå°†â€œå»¶è¿Ÿä¹˜å®¢æ•°â€ä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼Œèƒ½å¤Ÿæ˜¾è‘—æ”¹å–„å…¬å…±äº¤é€šæœåŠ¡è´¨é‡ï¼Œä¿ƒè¿›å¤šæ¨¡æ€å…¬å¹³ã€‚
2. **æ—¶ç©ºè¶…å›¾ä¼˜äºä¼ ç»Ÿå›¾å»ºæ¨¡**ï¼šåŒé˜¶æ®µè¶…å›¾æ³¨æ„åŠ›æœºåˆ¶èƒ½æ›´æœ‰æ•ˆåœ°æ•æ‰äº¤å‰å£é—´çš„é«˜é˜¶æ—¶ç©ºä¾èµ–ï¼Œå°¤å…¶åœ¨åŠ¨æ€å˜åŒ–å¼ºçƒˆçš„é«˜å³°æ—¶æ®µè¡¨ç°ä¼˜å¼‚ã€‚
3. **æ—¶é—´ç»´åº¦å»ºæ¨¡è‡³å…³é‡è¦**ï¼šæ¶ˆèå®éªŒè¯æ˜ï¼Œ**Temporal Hyperedges å¯¹æ€§èƒ½å½±å“æœ€å¤§**ï¼Œå¼ºè°ƒäº†å†å²çŠ¶æ€èšåˆçš„é‡è¦æ€§ã€‚
4. **è”åˆç›¸ä½ä¸æ—¶é•¿å†³ç­–æ›´å…·é€‚åº”æ€§**ï¼šç›¸æ¯”ä»…ä¼˜åŒ–ç›¸åºæˆ–å›ºå®šç»¿ç¯æ—¶é•¿çš„æ–¹æ³•ï¼Œæ··åˆåŠ¨ä½œç©ºé—´æå‡äº†ç³»ç»Ÿå“åº”çµæ´»æ€§ã€‚
5. **STDSH-MARL å…·å¤‡å¼ºæ³›åŒ–èƒ½åŠ›**ï¼šåœ¨äº”ç§ä¸åŒäº¤é€šæ¨¡å¼ä¸‹å‡è¡¨ç°ç¨³å¥ï¼Œé€‚ç”¨äºéé«˜å³°ã€é€šå‹¤é«˜å³°åŠç‰¹æ®Šäº‹ä»¶ï¼ˆå¦‚ä¸Šå­¦æ½®æ±æµï¼‰ã€‚

### æ–¹æ³•å±€é™æ€§
- å½“å‰å®éªŒè§„æ¨¡è¾ƒå°ï¼ˆä»…6ä¸ªäº¤å‰å£ï¼‰ï¼Œå°šæœªéªŒè¯åœ¨**åŸåŸŸçº§ç½‘ç»œ**ä¸­çš„å¯æ‰©å±•æ€§
- ä¾èµ–è¾ƒé«˜è´¨é‡çš„**å¤šæ¨¡æ€å®æ—¶æ„ŸçŸ¥æ•°æ®**ï¼ˆå¦‚è½¦è½½ä¹˜å®¢æ•°ã€è½¦é“çº§ occupancyï¼‰ï¼Œå®é™…éƒ¨ç½²å¯èƒ½å—é™äºä¼ æ„Ÿå™¨è¦†ç›–ç‡
- è¶…å›¾æ„å»ºä¸ attention è®¡ç®—å¸¦æ¥ä¸€å®š**é¢å¤–è®¡ç®—å¼€é”€**ï¼Œéœ€è¿›ä¸€æ­¥ä¼˜åŒ–æ¨ç†æ•ˆç‡

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³åŸå¸‚å°ºåº¦ç½‘ç»œ**ï¼ˆæ•°ç™¾ä¸ªäº¤å‰å£ï¼‰ï¼Œæµ‹è¯•è®­ç»ƒæ•ˆç‡ä¸åè°ƒèƒ½åŠ›
2. **å¼•å…¥å¯¹æŠ—æ€§æ‰°åŠ¨æµ‹è¯•**ï¼šè¯„ä¼°åœ¨äº¤é€šäº‹æ•…ã€çªå‘å¤§å®¢æµã€æ¢æµ‹å™¨æ•…éšœç­‰å¼‚å¸¸æ¡ä»¶ä¸‹çš„é²æ£’æ€§
3. **æ‹“å±•å¤šæ¨¡æ€ä¼˜å…ˆç­–ç•¥**ï¼šçº³å…¥è¡Œäººã€éª‘è¡Œè€…ã€åº”æ€¥è½¦è¾†ç­‰æ›´å¤šå¼±åŠ¿æˆ–é«˜ä¼˜å…ˆçº§ç¾¤ä½“
4. **å‘å±•å¯è§£é‡Š DRL æ¡†æ¶**ï¼šæä¾›ä¿¡å·å†³ç­–ä¾æ®ï¼Œå¢å¼ºäº¤é€šç®¡ç†è€…ä¿¡ä»»åº¦ï¼Œæ¨åŠ¨å®é™…è½åœ°åº”ç”¨

--- 

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **STDSH-MARL æˆåŠŸå°† human-centric æ€æƒ³èå…¥ MARL äº¤é€šæ§åˆ¶ï¼Œé€šè¿‡åˆ›æ–°çš„æ—¶ç©ºè¶…å›¾æ¶æ„ä¸è”åˆåŠ¨ä½œç©ºé—´è®¾è®¡ï¼Œåœ¨ä¿éšœæ•´ä½“äº¤é€šæ•ˆç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†å…¬å…±äº¤é€šæœåŠ¡å“è´¨ï¼Œæ˜¯è¿ˆå‘å…¬å¹³ã€é«˜æ•ˆã€æ™ºèƒ½åŒ–åŸå¸‚äº¤é€šç®¡ç†çš„é‡è¦ä¸€æ­¥ã€‚**

</details>

---

### 12. [Powering Up Zeroth-Order Training via Subspace Gradient Orthogonalization](https://arxiv.org/abs/2602.17155)

**Authors**: Yicheng Lang, Changsheng Wang, Yihua Zhang, Mingyi Hong, Zheng Zhang, Wotao Yin, Sijia Liu  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.17155v1  

#### Abstract
Zeroth-order (ZO) optimization provides a gradient-free alternative to first-order (FO) methods by estimating gradients via finite differences of function evaluations, and has recently emerged as a memory-efficient paradigm for fine-tuning large-scale models by avoiding backpropagation. However, ZO ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPowering Up Zeroth-Order Training via Subspace Gradient Orthogonalization

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
Zeroth-Order (ZO) ä¼˜åŒ–é€šè¿‡å‡½æ•°å€¼çš„æœ‰é™å·®åˆ†ä¼°è®¡æ¢¯åº¦ï¼Œé¿å…äº†åå‘ä¼ æ’­ï¼ˆbackpropagationï¼‰ï¼Œä»è€Œæ˜¾è‘—é™ä½å¤§æ¨¡å‹å¾®è°ƒæ—¶çš„å†…å­˜å¼€é”€ã€‚ç„¶è€Œï¼Œæ ‡å‡† ZO æ–¹æ³•é¢ä¸´ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š
- **é«˜æ–¹å·®**ï¼šé«˜ç»´å‚æ•°ç©ºé—´ä¸­ï¼ŒZO æ¢¯åº¦ä¼°è®¡çš„æ–¹å·®éšç»´åº¦å¢é•¿è€Œå¢å¤§ï¼Œå¯¼è‡´æ”¶æ•›æ…¢ã€ç²¾åº¦ä½ã€‚
- **æŸ¥è¯¢æ•ˆç‡ä½ä¸‹**ï¼šä¸ºé™ä½æ–¹å·®è€Œå¢åŠ æŸ¥è¯¢æ¬¡æ•°ï¼ˆmulti-queryï¼‰å¸¸é™·å…¥â€œå¤šæŸ¥è¯¢æ‚–è®ºâ€ï¼ˆmulti-query paradoxï¼‰ï¼Œå³æ€§èƒ½æå‡ä¸æ˜æ˜¾ç”šè‡³ä¸‹é™ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³è¿™ä¸€æ ¹æœ¬æ€§çš„ **accuracy-efficiency trade-off**ï¼Œæå‡ºä¸€ç§æ—¢èƒ½æå‡ç²¾åº¦åˆèƒ½æé«˜æ•ˆç‡çš„æ–°æ–¹æ³•ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šZO-Muon
ä½œè€…æå‡ºäº† **ZO-Muon**ï¼Œä¸€ä¸ªç»Ÿä¸€çš„å­ç©ºé—´æ¢¯åº¦æ­£äº¤åŒ–ï¼ˆsubspace gradient orthogonalizationï¼‰æ¡†æ¶ï¼Œç»“åˆäº†ä¸¤ç§äº’è¡¥æ€æƒ³ï¼š

1. **åŸºäºæŠ•å½±çš„å­ç©ºé—´ ZO ä¼˜åŒ–ï¼ˆSubspace RGEï¼‰**  
   å°†åŸå§‹å…¨å‚æ•°ç©ºé—´çš„ä¼˜åŒ–é—®é¢˜æŠ•å½±åˆ°ä¸€ä¸ªä½ç»´å­ç©ºé—´ä¸­è¿›è¡Œæ¢¯åº¦ä¼°è®¡ã€‚ç”±äºå­ç©ºé—´ç»´åº¦è¿œä½äºåŸç©ºé—´ï¼Œæ¢¯åº¦ä¼°è®¡æ–¹å·®æ˜¾è‘—é™ä½ã€‚è¯¥æ–¹æ³•å½¢å¼ä¸Šç­‰ä»·äºåœ¨ä½ç§©å­ç©ºé—´ä¸­æ‰§è¡Œ Randomized Gradient Estimator (RGE)ã€‚

2. **Muon é£æ ¼çš„è°±ä¼˜åŒ–ï¼ˆGradient Orthogonalization, GOï¼‰**  
   å¼•å…¥ Muon ä¼˜åŒ–å™¨ä¸­çš„çŸ©é˜µç¬¦å·å‡½æ•°ï¼ˆ`msign`ï¼‰å¯¹å­ç©ºé—´å†…çš„ ZO æ¢¯åº¦è¿›è¡Œæ­£äº¤åŒ–å¤„ç†ï¼Œæå–å…¶è°±ç»“æ„ä¸­çš„æœ‰æ•ˆä¸‹é™æ–¹å‘ï¼ŒæŠ‘åˆ¶å™ªå£°æ–¹å‘çš„å½±å“ã€‚

æœ€ç»ˆï¼ŒZO-Muon åœ¨å­ç©ºé—´å†…å®Œæˆæ¢¯åº¦ä¼°è®¡ä¸æ­£äº¤åŒ–åï¼Œå†å°†æ›´æ–°æ˜ å°„å›å…¨å‚æ•°ç©ºé—´è¿›è¡Œæƒé‡æ›´æ–°ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **åŒèµ¢æ”¹è¿›**ï¼šé¦–æ¬¡åœ¨ ZO ä¼˜åŒ–ä¸­å®ç° **ç²¾åº¦ä¸æ•ˆç‡çš„åŒæ—¶æå‡**ï¼Œè€Œéç‰ºç‰²ä¸€æ–¹æ¢å–å¦ä¸€æ–¹ã€‚
- **è‡ªç„¶è§£é‡Šæ€§**ï¼šå­ç©ºé—´æŠ•å½±å…·æœ‰æ˜ç¡®å‡ ä½•æ„ä¹‰ï¼ˆå¦‚ `P = U[:,k]` å¯è§†ä¸ºä¿ç•™å‰ k ä¸ªä¸»å¥‡å¼‚æ–¹å‘ï¼‰ï¼Œä¼˜äº LOZO ç­‰æ— çº¦æŸä½ç§©æ‰°åŠ¨ã€‚
- **é«˜æ•ˆå®ç°**ï¼šé‡‡ç”¨ Newton-Schulz (NS) è¿­ä»£è¿‘ä¼¼ `msign` æ“ä½œï¼Œé¿å…æ˜‚è´µçš„ SVDï¼Œä¿æŒè®¡ç®—å¯è¡Œæ€§ã€‚
- **é²æ£’æ€§å¼º**ï¼šå¯¹ batch size ä¸æ•æ„Ÿï¼Œåœ¨å°æ‰¹é‡ä¸‹ä»èƒ½ä¿æŒé«˜æ€§èƒ½ï¼Œé€‚åˆèµ„æºå—é™åœºæ™¯ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **LLM å¾®è°ƒä»»åŠ¡**ï¼šåœ¨ **SuperGLUE** åŸºå‡†ä¸Šçš„å¤šä¸ªä»»åŠ¡ï¼š
  - SST-2ï¼ˆæƒ…æ„Ÿåˆ†ç±»ï¼‰
  - RTEï¼ˆæ–‡æœ¬è•´å«ï¼‰
  - CBï¼ˆæ‰¿è¯ºé“¶è¡Œï¼‰
  - BoolQï¼ˆæ˜¯éé—®ç­”ï¼‰
  - WiCï¼ˆè¯ä¹‰æ¶ˆæ­§ï¼‰
  - SQuADï¼ˆæŠ½å–å¼é—®ç­”ï¼‰
- **Vision Transformer å¾®è°ƒä»»åŠ¡**ï¼š
  - **CIFAR-10 / CIFAR-100** å›¾åƒåˆ†ç±»

### æ¨¡å‹
- **è¯­è¨€æ¨¡å‹**ï¼š
  - OPT-1.3B / OPT-13B
  - LLaMA3-8B
  - Gemma2-2B
- **è§†è§‰æ¨¡å‹**ï¼š
  - ViT-B/16
  - ViT-L/16

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
| è®¾ç½®é¡¹ | æè¿° |
|--------|------|
| **è®­ç»ƒæ­¥æ•°** | LLM: 20k æ­¥ï¼›ViT: 20k æ­¥ï¼ˆæŒ‰ query budget å¯¹é½ï¼‰ |
| **Batch Size** | LLM: 16ï¼›ViT: 64 (CIFAR-10), 256 (CIFAR-100) |
| **Query Budget** | å›ºå®šæ€»æŸ¥è¯¢æ¬¡æ•°ï¼ˆå¦‚ 40kï¼‰ç”¨äºå…¬å¹³æ¯”è¾ƒ |
| **è¯„ä¼°æŒ‡æ ‡** | å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ã€F1 åˆ†æ•°ã€è®­ç»ƒæŸå¤±ã€è¿è¡Œæ—¶é—´ï¼ˆruntimeï¼‰ã€GPU å†…å­˜å ç”¨ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ZO æ–¹æ³•**ï¼š
  - MeZO (Malladi et al., 2023)
  - SparseMeZO (S-MeZO)
  - HiZOO (Zhao et al., 2025a)
  - LOZO (Chen et al., 2025b)
  - SubZero (Yu et al., 2025)
  - Subspace-MeZOï¼ˆæœ¬æ–‡æå‡ºçš„ä¸­é—´å˜ä½“ï¼‰
- **First-Order æ–¹æ³•**ï¼ˆä½œä¸ºæ€§èƒ½ä¸Šé™å‚è€ƒï¼‰ï¼š
  - Adam
  - LoRA + Adam

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 å’Œæ­£æ–‡ï¼‰

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **LLM å¾®è°ƒï¼ˆOPT-13B on SST-2ï¼‰** | ZO-Muon è¾¾åˆ° **92.5%** å‡†ç¡®ç‡ï¼Œä¼˜äº MeZO (91.4%) å’Œ LOZO (91.7%) |
| **ViT å¾®è°ƒï¼ˆViT-L on CIFAR-100ï¼‰** | ZO-Muon è¾¾åˆ° **72.4%** å‡†ç¡®ç‡ï¼Œæ¯” MeZO æå‡ **25.1%**ï¼Œæ¯”æ¬¡ä¼˜ ZO æ–¹æ³•ï¼ˆSubspace-MeZOï¼‰é«˜ 7.7% |
| **æŸ¥è¯¢æ•ˆç‡ï¼ˆSST-2ï¼‰** | ZO-Muon ä»…éœ€ MeZO **24.7% çš„æŸ¥è¯¢æ¬¡æ•°** å³å¯è¾¾åˆ°ç›¸åŒæ€§èƒ½ |
| **è¿è¡Œæ—¶é—´æ•ˆç‡ï¼ˆOPT-13B on SST-2ï¼‰** | åœ¨ç›¸åŒ query budget ä¸‹ï¼ŒZO-Muon è·‘å®Œåªéœ€ **2h 33min**ï¼Œæ¯” MeZO å¿« **70.5%**ï¼ˆMeZO: 3h 37minï¼‰ |
| **æ”¶æ•›é€Ÿåº¦** | ZO-Muon æ”¶æ•›æ‰€éœ€è¿­ä»£æ•°ä»…ä¸º MeZO çš„ **40%**ï¼ˆ8k vs 20k stepsï¼‰ |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **å…¨é¢è¶…è¶Šæ‰€æœ‰ ZO åŸºçº¿**ï¼šåœ¨å‡ ä¹æ‰€æœ‰ä»»åŠ¡ä¸Šï¼ŒZO-Muon å‡å–å¾—æœ€é«˜å‡†ç¡®ç‡æˆ– F1ã€‚
- **æ˜¾è‘—ç¼©å°ä¸ FO æ–¹æ³•å·®è·**ï¼šåœ¨éƒ¨åˆ†ä»»åŠ¡ï¼ˆå¦‚ SST-2ï¼‰ä¸Šæ¥è¿‘ Adam æ€§èƒ½ï¼Œè¿œè¶… LoRAã€‚
- **ä¼˜äºå­ç©ºé—´ç±»æ–¹æ³•**ï¼šå³ä½¿ä¸ LOZOã€SubZero ç­‰ä½ç§© ZO æ–¹æ³•ç›¸æ¯”ï¼ŒZO-Muon ä»å…·ä¼˜åŠ¿ï¼Œè¯´æ˜ **GO ä¸å­ç©ºé—´çš„ååŒæ•ˆåº”** æ˜¯å…³é”®ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰å­ç©ºé—´æŠ•å½±çš„æœ‰æ•ˆæ€§ï¼ˆSubspace-MeZO vs MeZOï¼‰
- Subspace-MeZO å·²ä¼˜äºæ ‡å‡† MeZOï¼ŒéªŒè¯äº†å­ç©ºé—´é™ç»´å¯¹é™ä½æ–¹å·®çš„æœ‰æ•ˆæ€§ã€‚
- ä½†åœ¨æŸäº›ä»»åŠ¡ä¸Šä»åŠ£äº LOZO æˆ– HiZOOï¼Œè¯´æ˜ä»…æœ‰å­ç©ºé—´ä¸è¶³ä»¥å®Œå…¨é‡Šæ”¾æ½œåŠ›ã€‚

#### ï¼ˆ2ï¼‰Gradient Orthogonalization çš„å¿…è¦æ€§
- **ZO-Muon-V0ï¼ˆç›´æ¥å¯¹å…¨ç©ºé—´ ZO æ¢¯åº¦åº”ç”¨ GOï¼‰** è¡¨ç°ä¸ä½³ï¼Œç”šè‡³ä¸å¦‚ MeZOã€‚
- è¡¨æ˜ **GO å¿…é¡»ä¸å­ç©ºé—´ç»“åˆ** æ‰èƒ½å‘æŒ¥ä½œç”¨ â€”â€” å¦åˆ™å™ªå£°ä¼šè¢«æ”¾å¤§ã€‚

#### ï¼ˆ3ï¼‰æŸ¥è¯¢æ•° $N_q$ çš„å½±å“
- Subspace-MeZO å­˜åœ¨ **multi-query paradox**ï¼š$N_q > 1$ æ—¶æ€§èƒ½åè€Œä¸‹é™ã€‚
- ZO-Muon åˆ™ **å—ç›Šäºå¤šæŸ¥è¯¢**ï¼ˆå¦‚ $N_q=4$ æœ€ä½³ï¼‰ï¼Œè¯´æ˜ GO æˆåŠŸåˆ©ç”¨äº†å¤šæŸ¥è¯¢æä¾›çš„é¢å¤–ä¿¡æ¯ã€‚

#### ï¼ˆ4ï¼‰æŠ•å½±ç§© $r$ çš„é€‰æ‹©
- æœ€ä½³ $r \in \{64, 128\}$ï¼Œè¿‡å¤§ï¼ˆå¦‚ 256ï¼‰ä¼šå¯¼è‡´ä¸ç¨³å®šï¼Œè¿‡å°ï¼ˆå¦‚ 16ï¼‰ä¼šä¸¢å¤±é‡è¦æ¢¯åº¦ä¿¡æ¯ã€‚
- ä¸ FO è®­ç»ƒä¸­è§‚å¯Ÿåˆ°çš„æ¢¯åº¦ä½ç§©ç»“æ„ä¸€è‡´ï¼ˆè§ Figure 3aï¼‰ã€‚

#### ï¼ˆ5ï¼‰NS vs SVD å®ç° `msign`
- SVD æ›´ç²¾ç¡®ï¼Œä½†è¿è¡Œæ—¶é—´çº¦ä¸º NS çš„ **3 å€**ã€‚
- NS åœ¨ç²¾åº¦ä¸æ•ˆç‡é—´å–å¾—è‰¯å¥½å¹³è¡¡ï¼Œæ˜¯é»˜è®¤é€‰æ‹©ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å­ç©ºé—´ + GO æ˜¯ ZO ä¼˜åŒ–çš„æ–°èŒƒå¼**ï¼š  
   å•ç‹¬ä½¿ç”¨å­ç©ºé—´æˆ– GO æ•ˆæœæœ‰é™ï¼Œä½†äºŒè€…ç»“åˆå½¢æˆâ€œå­ç©ºé—´æ¢¯åº¦æ­£äº¤åŒ–â€æ¡†æ¶ï¼Œèƒ½åŒæ—¶æå‡ç²¾åº¦ä¸æ•ˆç‡ã€‚

2. **ZO-Muon å®ç°äº† accuracy-efficiency çš„åŒèµ¢**ï¼š  
   ä¸ä»…åŠ é€Ÿæ”¶æ•›ï¼Œè¿˜æå‡äº†æœ€ç»ˆæ€§èƒ½ï¼Œæ‰“ç ´äº†ä¼ ç»Ÿ ZO æ–¹æ³•çš„ trade-offã€‚

3. **ä½ç§©ç»“æ„æ˜¯ ZO æˆåŠŸçš„å…³é”®å…ˆéªŒ**ï¼š  
   æ·±åº¦æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¢¯åº¦å¤©ç„¶å­˜åœ¨äºä½ç»´å­ç©ºé—´ï¼Œè¿™ä¸ºå­ç©ºé—´æ–¹æ³•æä¾›äº†ç†è®ºåŸºç¡€ã€‚

4. **å° batch size ä¸‹ä¾ç„¶é²æ£’**ï¼š  
   ZO-Muon åœ¨ batch size=64 æ—¶çš„è¡¨ç°ä¼˜äºå…¶ä»–æ–¹æ³•åœ¨ batch size=256 æ—¶çš„è¡¨ç°ï¼Œæ˜¾ç¤ºå‡ºæ›´å¼ºçš„å®ç”¨æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰å·¥ä½œèšç„¦äº **parameter-efficient fine-tuning**ï¼Œå°šæœªæ‰©å±•è‡³å¤§è§„æ¨¡é¢„è®­ç»ƒï¼ˆpre-trainingï¼‰ã€‚
- æŠ•å½±çŸ©é˜µ $P$ é‡‡ç”¨éšæœºç”Ÿæˆï¼Œæœªæ¢ç´¢æ›´æ™ºèƒ½çš„ adaptive subspace selectionã€‚
- `msign` çš„ NS è¿‘ä¼¼åœ¨æ›´å¤§æ¨¡å‹ä¸Šå¯èƒ½å­˜åœ¨ç´¯ç§¯è¯¯å·®ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† ZO-Muon æ‰©å±•åˆ° **full pre-training** åœºæ™¯ã€‚
- æ¢ç´¢ **adaptive subspace learning**ï¼ŒåŠ¨æ€æ•æ‰æœ€ä¼˜ä½ç»´ç»“æ„ã€‚
- ç»“åˆ **quantization** æˆ– **pruning** è¿›ä¸€æ­¥å‹ç¼©è®¡ç®—ä¸å­˜å‚¨æˆæœ¬ã€‚
- ç†è®ºåˆ†æ ZO-Muon çš„æ”¶æ•›é€Ÿç‡ä¸æ³›åŒ–æ€§èƒ½ã€‚

---

> âœ… **ä»£ç å·²å¼€æº**ï¼š[https://github.com/OPTML-Group/ZO-Muon](https://github.com/OPTML-Group/ZO-Muon)

</details>

---

### 13. [Continual learning and refinement of causal models through dynamic predicate invention](https://arxiv.org/abs/2602.17217)

**Authors**: Enrique Crespo-Fernandez, Oliver Ray, Telmo de Menezes e Silva Filho, Peter Flach  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.17217v1  

#### Abstract
Efficiently navigating complex environments requires agents to internalize the underlying logic of their world, yet standard world modelling methods often struggle with sample inefficiency, lack of transparency, and poor scalability. We propose a framework for constructing symbolic causal world mode...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Continual Learning and Refinement of Causal Models through Dynamic Predicate Invention*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³**æ™ºèƒ½ä½“åœ¨åŠ¨æ€ç¯å¢ƒä¸­æ„å»ºä¸–ç•Œæ¨¡å‹æ—¶é¢ä¸´çš„ä¸‰å¤§æŒ‘æˆ˜**ï¼š
- **æ ·æœ¬æ•ˆç‡ä½**ï¼ˆSample inefficiencyï¼‰ï¼šä¼ ç»Ÿæ·±åº¦å¼ºåŒ–å­¦ä¹ éœ€è¦å¤§é‡äº¤äº’æ•°æ®ã€‚
- **ç¼ºä¹å¯è§£é‡Šæ€§**ï¼ˆLack of transparencyï¼‰ï¼šç¥ç»ç½‘ç»œæ¨¡å‹æ˜¯é»‘ç®±ï¼Œéš¾ä»¥ç†è§£å…¶å†³ç­–é€»è¾‘ã€‚
- **æ‰©å±•æ€§å·®**ï¼ˆPoor scalabilityï¼‰ï¼šå‘½é¢˜åŒ–æ–¹æ³•ï¼ˆå¦‚SAT/ASPï¼‰åœ¨å¤æ‚å…³ç³»ç¯å¢ƒä¸­é¢ä¸´ç»„åˆçˆ†ç‚¸ã€‚

æ­¤å¤–ï¼Œå¤§å¤šæ•°ç¬¦å·ç³»ç»Ÿä¾èµ–äºæ‰‹å·¥è®¾è®¡çš„ä¸–ç•Œæ¨¡å‹æˆ–æ‰¹å¤„ç†å¼çš„å½’çº³é€»è¾‘ç¼–ç¨‹ï¼ˆILPï¼‰ï¼Œæ— æ³•å®ç°çœŸæ­£çš„åœ¨çº¿ã€æŒç»­å­¦ä¹ ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§**å®Œå…¨åœ¨çº¿çš„ç¬¦å·å› æœä¸–ç•Œå»ºæ¨¡æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæœºåˆ¶ä¸ºï¼š

- **Continuous Model Repairï¼ˆè¿ç»­æ¨¡å‹ä¿®å¤ï¼‰**  
  å°†æ¨¡å‹å­¦ä¹ ä¸å†³ç­–å¾ªç¯ç´§å¯†ç»“åˆï¼Œå½¢æˆä¸€ä¸ªâ€œé¢„æµ‹-éªŒè¯-ä¿®æ­£â€ï¼ˆPredict-Verify-Refineï¼‰çš„è‡ªç›‘ç£é—­ç¯ã€‚å½“é¢„æµ‹å¤±è´¥æ—¶ï¼Œå®æ—¶è§¦å‘å±€éƒ¨ä¿®å¤ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚

- **Meta-Interpretive Learning (MIL) + åŠ¨æ€è°“è¯å‘æ˜ï¼ˆDynamic Predicate Inventionï¼‰**  
  åˆ©ç”¨äºŒé˜¶è§„åˆ™æ¨¡æ¿ï¼ˆmetarulesï¼‰æŒ‡å¯¼å‡è®¾ç”Ÿæˆï¼Œå¹¶é€šè¿‡é€’å½’åæ¼”ï¼ˆabductionï¼‰è‡ªåŠ¨å‘æ˜æ–°çš„é«˜é˜¶æŠ½è±¡è°“è¯ï¼ˆå¦‚ `p2`, `p3`ï¼‰ï¼Œä»è€Œæ„å»ºå±‚æ¬¡åŒ–çš„æ¦‚å¿µä½“ç³»ã€‚

- **Scale-Invariant Learningï¼ˆå°ºåº¦ä¸å˜å­¦ä¹ ï¼‰**  
  ä½¿ç”¨æå‡æ¨ç†ï¼ˆlifted inferenceï¼‰è€Œéæ¥åœ°æ¨ç†ï¼ˆgroundingï¼‰ï¼Œä½¿å¾—è®¡ç®—å¤æ‚åº¦å–å†³äºé€»è¾‘æ·±åº¦ $D_{max}$ å’Œè°“è¯æ•°é‡ï¼Œè€Œä¸éšçŠ¶æ€ç©ºé—´å¤§å°å¢é•¿ï¼Œå…‹æœäº†å‘½é¢˜æ–¹æ³•çš„ç“¶é¢ˆã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | æœ¬æ–‡æ–¹æ³• | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚PPOã€Apperception Engineç­‰ï¼‰ |
|------|--------|----------------------------|
| **å­¦ä¹ æ¨¡å¼** | åœ¨çº¿ã€å¢é‡å¼ | æ‰¹å¤„ç†ã€ç¦»çº¿è®­ç»ƒ |
| **å¯è§£é‡Šæ€§** | å®Œå…¨é€æ˜çš„ä¸€é˜¶é€»è¾‘ç†è®º | é»‘ç®±ç¥ç»ç½‘ç»œæˆ–é™æ€ç¬¦å·æ¨¡å‹ |
| **æ ·æœ¬æ•ˆç‡** | æé«˜ï¼ˆä¸€æ¬¡å¤±è´¥åå³å¯å­¦ä¼šï¼‰ | éœ€æ•°ç™¾ç”šè‡³ä¸Šåƒæ¬¡å°è¯• |
| **æ³›åŒ–èƒ½åŠ›** | å­¦å¾—çš„æ¦‚å¿µå…·æœ‰å°ºåº¦ä¸å˜æ€§ï¼Œé›¶æ ·æœ¬è¿ç§»åˆ°æ›´å¤§ç½‘æ ¼ | è¡¨ç¤ºè€¦åˆäºå…·ä½“ç¯å¢ƒè§„æ¨¡ |
| **è®¡ç®—å¤æ‚åº¦** | ä¸çŠ¶æ€ç©ºé—´æ— å…³ï¼Œä»…ä¾èµ–é€»è¾‘ç»“æ„ | éšç½‘æ ¼å°ºå¯¸æŒ‡æ•°å¢é•¿ï¼ˆå°¤å…¶å‘½é¢˜æ–¹æ³•ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **MiniHack Lava Crossing**ï¼šä¸€ä¸ªåŸºäºNetHackçš„å°å‹ç½‘æ ¼ä¸–ç•Œä»»åŠ¡ï¼Œä»£ç†éœ€ç©¿è¶Šç†”å²©åŒºåŸŸåˆ°è¾¾ç›®æ ‡ä½ç½®ã€‚
  - çŠ¶æ€ç”±ä¸€ç»„**ä¸€é˜¶è°“è¯åŸå­**è¡¨ç¤ºï¼ˆå¦‚ `at(agent, loc)`ã€`islava(loc)`ã€`adjacent(...)`ï¼‰
  - åŠ¨ä½œç©ºé—´æœ‰é™ï¼Œç¯å¢ƒç¡®å®šä¸”å®Œå…¨å¯è§‚æµ‹ã€‚

> å®éªŒåˆ†åˆ«åœ¨ **10Ã—10** å’Œæ›´å¤§çš„ **100Ã—100** ç½‘æ ¼ä¸Šè¿›è¡Œï¼Œç”¨äºæµ‹è¯•**å°ºåº¦ä¸å˜æ€§**ã€‚

---

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
#### è®¾ç½®
- **Agentç±»å‹**ï¼š
  - **Online MIL Agent**ï¼šæœ¬æ–‡æå‡ºçš„åŸºäºMILçš„ç¬¦å·å­¦ä¹ å™¨ã€‚
  - **PPO Baseline**ï¼šæ ‡å‡†çš„Proximal Policy Optimizationç®—æ³•ï¼Œä½¿ç”¨é¢„è®­ç»ƒCNNæå–ç‰¹å¾ã€‚
- **è®­ç»ƒæ–¹å¼**ï¼š
  - MIL Agentï¼šä»é›¶å¼€å§‹ï¼Œåœ¨æ¯ä¸ªæ—¶é—´æ­¥æ¥æ”¶çŠ¶æ€æµ $S_t$ï¼Œæ‰§è¡ŒPredict-Verify-Refineå¾ªç¯ã€‚
  - PPOï¼šéœ€æ”¶é›†å®Œæ•´episodeè¿›è¡Œç­–ç•¥æ¢¯åº¦æ›´æ–°ã€‚
- **èƒŒæ™¯çŸ¥è¯† B**ï¼šæä¾›åŸºæœ¬è°“è¯ï¼ˆå¦‚ `adjacent/3`, `islava/1`ï¼‰å’Œç±»å‹çº¦æŸã€‚

#### è¯„ä¼°æŒ‡æ ‡
1. **First Success Episode**ï¼šé¦–æ¬¡æˆåŠŸå®Œæˆä»»åŠ¡çš„å›åˆæ•°ã€‚
2. **Sample Efficiency**ï¼šè¾¾åˆ°ç¨³å®šæ€§èƒ½æ‰€éœ€çš„äº¤äº’æ¬¡æ•°ã€‚
3. **Model Size Evolution**ï¼šåŠ¨æ€ç»Ÿè®¡ `Abs`ï¼ˆæŠ½è±¡ï¼‰ã€`Dyn`ï¼ˆåŠ¨æ€è§„åˆ™ï¼‰ã€`Con`ï¼ˆçº¦æŸï¼‰çš„æ•°é‡å˜åŒ–ã€‚
4. **Prediction Error**ï¼šFalse Positive / False Negative æ•°é‡ã€‚
5. **Zero-shot Transfer**ï¼šå°ç¯å¢ƒå­¦å¾—æ¨¡å‹ç›´æ¥åº”ç”¨äºå¤§ç¯å¢ƒçš„èƒ½åŠ›ã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **PPO (Schulman et al., 2017)**ï¼šä»£è¡¨ä¸»æµæ·±åº¦RLæ–¹æ³•ã€‚
- ï¼ˆéšå«å¯¹æ¯”ï¼‰**Batch ILP æ–¹æ³•**ï¼ˆå¦‚Apperception Engine, Popperï¼‰ï¼šè™½èƒ½å­¦ä¹ ç¬¦å·æ¨¡å‹ï¼Œä½†éåœ¨çº¿ã€ä¸å¯æŒç»­ä¿®å¤ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æŒ‡æ ‡ | æœ¬æ–‡æ–¹æ³•ï¼ˆOnline MILï¼‰ | PPO Baseline |
|------|-----------------------|-------------|
| é¦–æ¬¡æˆåŠŸå›åˆï¼ˆEpisodeï¼‰ | **2** | ~128 |
| è¾¾åˆ°ç¨³å®šæ€§èƒ½æ‰€éœ€å›åˆ | < 5 | > 300 |
| æœ€ç»ˆæ¨¡å‹å¤§å° | 43 æ¡å­å¥ï¼ˆ28 æŠ½è±¡ + 13 åŠ¨æ€ + 2 çº¦æŸï¼‰ | â€”â€”ï¼ˆå‚æ•°åŒ–ç½‘ç»œï¼‰ |
| é¢„æµ‹é”™è¯¯ç‡ | æ”¶æ•›è‡³ **0**ï¼ˆçº¦ step 23ï¼‰ | ä¸å¯ç›´æ¥æµ‹é‡ |

> å›¾2æ˜¾ç¤ºï¼ŒMIL agentåœ¨ç¬¬2ä¸ªepisodeå³æˆåŠŸå¯¼èˆªï¼›è€ŒPPOç›´åˆ°ç¬¬129ä¸ªepisodeæ‰é¦–æ¬¡æˆåŠŸã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ ·æœ¬æ•ˆç‡é«˜å‡ºä¸¤ä¸ªæ•°é‡çº§**ï¼šMIL agentå®ç°**one-shot learning after first failure**ï¼Œè€ŒPPOéœ€è¦çº¦128å€æ›´å¤šç»éªŒã€‚
- **é›¶æ ·æœ¬è¿ç§»æˆåŠŸ**ï¼šåœ¨10Ã—10ä¸Šå­¦åˆ°çš„â€œå±é™©â€æ¦‚å¿µï¼ˆå¦‚ç§»åŠ¨è¿›å…¥ç†”å²©å¯¼è‡´æ­»äº¡ï¼‰å¯ç›´æ¥ç”¨äº100Ã—100ç¯å¢ƒï¼Œæ— éœ€å¾®è°ƒã€‚
- **æ¨¡å‹ç´§å‡‘ä¸”å¯è¯»**ï¼šæœ€ç»ˆå¾—åˆ°ä»…43æ¡é€»è¾‘è§„åˆ™çš„å®Œæ•´ä¸–ç•Œæ¨¡å‹ï¼Œäººç±»å¯è½»æ¾ç†è§£ï¼ˆè§å›¾1ï¼‰ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆæ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèå®éªŒï¼Œä½†å¯é€šè¿‡åˆ†ææ¨æ–­ï¼‰
å°½ç®¡æ²¡æœ‰æ­£å¼çš„ablation studyï¼Œä»¥ä¸‹è§‚å¯Ÿå¯è§†ä¸ºåŠŸèƒ½åˆ†è§£è¯æ®ï¼š
- **è°“è¯å¤ç”¨æœºåˆ¶æœ‰æ•ˆ**ï¼šåŒä¸€æŠ½è±¡è°“è¯ï¼ˆå¦‚ `p2`: â€œagent moving toward cell Bâ€ï¼‰è¢«å¤šä¸ªè§„åˆ™å…±äº«ï¼ˆmovement å’Œ dyingï¼‰ï¼Œè¡¨æ˜**å±‚æ¬¡åŒ–è¡¨ç¤ºæå‡äº†æ³›åŒ–èƒ½åŠ›**ã€‚
- **Top Program + å±€éƒ¨ä¿®å¤æœºåˆ¶æ”¶æ•›å¿«**ï¼šæ¨¡å‹å¤§å°å…ˆä¸Šå‡ï¼ˆgeneralizationï¼‰åä¸‹é™ï¼ˆspecializationï¼‰ï¼Œæœ€ç»ˆç¨³å®šï¼Œè¯´æ˜**è¯¯æŠ¥ï¼ˆFPï¼‰èƒ½è¢«æœ‰æ•ˆä¿®å‰ª**ã€‚
- **ç±»å‹ç³»ç»Ÿä¸ç¼“å­˜æ˜¾è‘—é™ä½æœç´¢å¼€é”€**ï¼šé€šè¿‡å…¨å±€è°“è¯æ³¨å†Œè¡¨ï¼ˆGlobal Predicate Registryï¼‰é¿å…é‡å¤å‘æ˜ç›¸åŒæ¦‚å¿µï¼Œæå‡æ•ˆç‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. âœ… **ç¬¦å·ä¸–ç•Œæ¨¡å‹å¯ä»¥å®Œå…¨åœ¨çº¿ã€å¢é‡åœ°å­¦ä¹ **ï¼Œæ— éœ€æ‰¹å¤„ç†æˆ–å¤–éƒ¨æ ‡æ³¨ã€‚
2. âœ… **åŠ¨æ€è°“è¯å‘æ˜èƒ½å¤Ÿè‡ªåŠ¨æ„å»ºè§£è€¦çš„ã€å±‚çº§åŒ–çš„è¯­ä¹‰æ¦‚å¿µ**ï¼Œæ”¯æŒé«˜æ•ˆæ¨ç†ä¸æ³›åŒ–ã€‚
3. âœ… **åŸºäºMILçš„è¿ç»­æ¨¡å‹ä¿®å¤æœºåˆ¶å®ç°äº†æé«˜çš„æ ·æœ¬æ•ˆç‡**ï¼Œè¿œè¶…æ ‡å‡†PPOç­‰ç¥ç»æ–¹æ³•ã€‚
4. âœ… **lifted inference + predicate invention å®ç°äº†å°ºåº¦ä¸å˜çš„å­¦ä¹ **ï¼Œæ¨¡å‹å¯åœ¨ä¸åŒè§„æ¨¡ç¯å¢ƒä¸­é›¶æ ·æœ¬è¿ç§»ã€‚
5. âœ… **æ•´ä¸ªå­¦ä¹ è¿‡ç¨‹äº§ç”Ÿå®Œå…¨å¯è§£é‡Šçš„FOLç†è®º**ï¼Œæ¯ä¸€æ­¥ä¿¡å¿µæ›´æ–°éƒ½å¯è¿½æº¯å’ŒéªŒè¯ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- â— **å½“å‰å‡è®¾ç¯å¢ƒä¸ºç¡®å®šæ€§ã€å®Œå…¨å¯è§‚æµ‹**ï¼Œå°šæœªå¤„ç†å™ªå£°è§‚æµ‹æˆ–éƒ¨åˆ†å¯è§‚æµ‹æ€§ã€‚
- â— **ä¾èµ–ç”¨æˆ·å®šä¹‰çš„metaruleså’ŒåŸºç¡€è°“è¯ç±»å‹**ï¼Œå°šä¸èƒ½å…¨è‡ªåŠ¨åœ°ä»åŸå§‹æ„ŸçŸ¥ï¼ˆå¦‚åƒç´ ï¼‰ä¸­æå–åˆå§‹ç¬¦å·ã€‚
- â— **æœç´¢ç©ºé—´ä»å—é™äºmetaruleé›†åˆå’Œæœ€å¤§æ·±åº¦ $D_{max}$**ï¼Œå¯èƒ½é—æ¼æŸäº›å¤æ‚ç»“æ„ã€‚
- â— **ç›®å‰ä»…éªŒè¯äºå°å‹grid world**ï¼Œåœ¨æ›´å¤æ‚çš„ç°å®åœºæ™¯ä¸­çš„å¯æ‰©å±•æ€§æœ‰å¾…æ£€éªŒã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **ä¸»åŠ¨æ¨¡å‹ç²¾ç‚¼ï¼ˆActive Model Refinementï¼‰**ï¼šè®©agentä¸»åŠ¨è®¾è®¡å®éªŒæ¥éªŒè¯æˆ–è¯ä¼ªæŸæ¡è§„åˆ™ï¼ˆå°†rule bodyè®¾ä¸ºç›®æ ‡å»æµ‹è¯•ï¼‰ã€‚
2. **å‘æ¦‚ç‡é€»è¾‘æ‰©å±•**ï¼šå¼•å…¥ä¸ç¡®å®šæ€§å»ºæ¨¡ï¼Œæ”¯æŒéç¡®å®šæ€§ç¯å¢ƒä¸‹çš„å­¦ä¹ ã€‚
3. **ç»“åˆç¥ç»è°“è¯ï¼ˆNeural Predicatesï¼‰**ï¼šåˆ©ç”¨ç¥ç»ç½‘ç»œä»åŸå§‹è¾“å…¥ï¼ˆå¦‚å›¾åƒï¼‰ä¸­è‡ªåŠ¨æå–åŸºç¡€è°“è¯ï¼Œå®ç°ç«¯åˆ°ç«¯çš„ç¬¦å·ç”Ÿæˆã€‚
4. **ä¸ç¥ç»ç­–ç•¥ç»“åˆ**ï¼šå°†ç¬¦å·æ¨¡å‹ä½œä¸º planner çš„çŸ¥è¯†åº“ï¼Œä¸ reactive policy ååŒå·¥ä½œï¼Œå…¼é¡¾é²æ£’æ€§ä¸çµæ´»æ€§ã€‚
5. **å¼€æ”¾åŸŸæ¦‚å¿µå­¦ä¹ **ï¼šæ¢ç´¢å¦‚ä½•åœ¨æœªçŸ¥é¢†åŸŸä¸­è‡ªä¸»å‘ç°æ–°çš„å¯¹è±¡ç±»åˆ«å’Œå…³ç³»ç±»å‹ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬å·¥ä½œå±•ç¤ºäº†**é€šè¿‡åŠ¨æ€è°“è¯å‘æ˜é©±åŠ¨çš„åœ¨çº¿MILæ¡†æ¶**ï¼Œèƒ½å¤Ÿåœ¨æå°‘æ ·æœ¬ä¸‹æŒç»­æ„å»ºé«˜è´¨é‡ã€å¯è§£é‡Šã€å¯æ³›åŒ–çš„ç¬¦å·å› æœæ¨¡å‹ï¼Œä¸ºè¿ˆå‘çœŸæ­£é€šç”¨ã€é€æ˜ã€é«˜æ•ˆçš„äººå·¥æ™ºèƒ½ä»£ç†æä¾›äº†æ–°è·¯å¾„ã€‚

</details>

---

### 14. [What Language is This? Ask Your Tokenizer](https://arxiv.org/abs/2602.17655)

**Authors**: Clara Meister, Ahmetcan Yavuz, Pietro Lesci, Tiago Pimentel  
**Category**: cs.CL  
**Published**: 2026-02-20  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.17655v1  

#### Abstract
Language Identification (LID) is an important component of many multilingual natural language processing pipelines, where it facilitates corpus curation, training data analysis, and cross-lingual evaluation of large language models. Despite near-perfect performance on high-resource languages, existi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠWhat Language is This? Ask Your Tokenizerã€‹æ ¸å¿ƒæ€»ç»“

## 1. ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯­è¨€è¯†åˆ«ï¼ˆ**Language Identification, LID**ï¼‰åœ¨å¤šè¯­è¨€è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æµç¨‹ä¸­è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰ç³»ç»Ÿåœ¨ä»¥ä¸‹åœºæ™¯è¡¨ç°ä¸ä½³ï¼š
- **ä½èµ„æºè¯­è¨€**ï¼ˆlow-resource languagesï¼‰
- **å¯†åˆ‡ç›¸å…³çš„è¯­è¨€å¯¹**ï¼ˆå¦‚æ³¢æ–¯å°¼äºšè¯­ã€å…‹ç½—åœ°äºšè¯­ã€å¡å°”ç»´äºšè¯­ï¼‰
- **ç»†ç²’åº¦æ–¹è¨€è¯†åˆ«**ï¼ˆfine-grained dialect identificationï¼‰
- **é¢†åŸŸåç§»å’Œæ­£å­—æ³•å™ªå£°**ï¼ˆdomain shift, orthographic noiseï¼‰

å°½ç®¡é«˜èµ„æºè¯­è¨€ä¸Šå·²æœ‰è¿‘å®Œç¾æ€§èƒ½ï¼Œä½†ä¸Šè¿°æŒ‘æˆ˜è¡¨æ˜ LID è¿œæœªâ€œè§£å†³â€ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šUniLID
ä½œè€…æå‡º **UniLID**ï¼Œä¸€ç§åŸºäº **UnigramLM** åˆ†è¯ç®—æ³•çš„ç”Ÿæˆå¼ LID æ–¹æ³•ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **å°†åˆ†è¯ï¼ˆsegmentationï¼‰è§†ä¸ºè¯­è¨€ç‰¹å®šçš„æ½œåœ¨å˜é‡**ï¼Œè€Œéè·¨è¯­è¨€å›ºå®šçš„é¢„å¤„ç†æ­¥éª¤ã€‚

#### æ–¹æ³•æ¡†æ¶
1. **å…±äº«è¯æ±‡è¡¨**ï¼ˆshared vocabularyï¼‰ï¼šæ‰€æœ‰è¯­è¨€å…±ç”¨ä¸€ä¸ª tokenizer çš„è¯æ±‡è¡¨ $ \mathcal{V} $ã€‚
2. **è¯­è¨€æ¡ä»¶ä¸‹çš„ Unigram åˆ†å¸ƒ**ï¼šä¸ºæ¯ç§è¯­è¨€ $ l $ å•ç‹¬å­¦ä¹ ä¸€ä¸ª unigram åˆ†å¸ƒ $ \phi_l $ï¼Œé€šè¿‡ EM ç®—æ³•ä»è¯¥è¯­è¨€çš„æ–‡æœ¬ä¸­ä¼°è®¡ã€‚
3. **ä¼¼ç„¶è®¡ç®—**ï¼šå¯¹è¾“å…¥å­—ç¬¦ä¸² $ s $ï¼Œä½¿ç”¨æ¯ä¸ªè¯­è¨€çš„ $ \phi_l $ æ‰¾åˆ°æœ€å¯èƒ½çš„åˆ†è¯è·¯å¾„ $ v^*_l = \arg\max_{v \in \mathcal{T}(s)} p_l(v) $ã€‚
4. **è´å¶æ–¯å†³ç­–**ï¼šè®¡ç®—åéªŒæ¦‚ç‡å¹¶é€‰æ‹©æœ€ä¼˜è¯­è¨€ï¼š
   $$
   l(s) = \arg\max_{l \in \mathcal{A}} p_l(v^*_l)
   $$

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | UniLID | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ fastText, CLD3ï¼‰ |
|------|--------|-----------------------------|
| **æ•°æ®æ•ˆç‡** | æé«˜ï¼Œåœ¨ä»… **5 ä¸ªæ ·æœ¬/è¯­è¨€** ä¸‹å¯è¾¾ 70% å‡†ç¡®ç‡ | éœ€å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œä½èµ„æºä¸‹æ³›åŒ–å·® |
| **å¢é‡å­¦ä¹ ** | å¯**æ— éœ€é‡è®­ç»ƒ**æ·»åŠ æ–°è¯­è¨€ | é€šå¸¸éœ€é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ |
| **è®¡ç®—æ•ˆç‡** | æ¨ç†å¿«ï¼Œå¤æ‚åº¦æ¥è¿‘æ ‡å‡† UnigramLM åˆ†è¯ |
| **é›†æˆæ€§** | å¯ç›´æ¥åµŒå…¥ LLM çš„ tokenizer æµç¨‹ | å¤šä¸ºç‹¬ç«‹æ¨¡å— |
| **é²æ£’æ€§** | å¯¹çŸ­æ–‡æœ¬ã€å™ªå£°ã€é¢†åŸŸåç§»æ›´é²æ£’ | åœ¨è¿™äº›åœºæ™¯ä¸‹æ€§èƒ½ä¸‹é™æ˜æ˜¾ |

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | æè¿° | ç‰¹ç‚¹ |
|-------|------|------|
| **GlotLID-C** | è¦†ç›–è¿‘ 2000 ç§è¯­è¨€-è„šæœ¬ç»„åˆçš„å¤§è§„æ¨¡åŸºå‡† | å¼ºè°ƒä½èµ„æºå’Œç›¸è¿‘è¯­è¨€ |
| **UDHR** | ã€Šä¸–ç•Œäººæƒå®£è¨€ã€‹çš„å¹³è¡Œæ–‡æœ¬ï¼Œè¦†ç›–æ•°ç™¾è¯­è¨€ | æ§åˆ¶è¯­ä¹‰å†…å®¹ï¼Œç”¨äºè·¨è¯­è¨€æ³›åŒ–è¯„ä¼° |
| **FLORES-200** | ç»´åŸºåª’ä½“é¡¹ç›®çš„ä¸“ä¸šç¿»è¯‘å¥å­ | é«˜è´¨é‡ï¼Œç”¨äºä½èµ„æºè¯­è¨€è¯„ä¼° |
| **DSL-ML 2024** | ç»†ç²’åº¦æ–¹è¨€è¯†åˆ«ä»»åŠ¡ï¼Œå«è‹±è¯­ã€æ³•è¯­ç­‰åŒºåŸŸå˜ä½“ | é«˜è¯æ±‡é‡å ï¼ŒåŒºåˆ†ç»†å¾® |
| **WiLI-2018** | æ¥è‡ªç»´åŸºç™¾ç§‘çš„ 235 ç§è¯­è¨€æ®µè½ï¼Œæ¯ç±» 1000 æ¡ | å¹³è¡¡æ•°æ®é›†ï¼Œç”¨äºæ¶ˆèç ”ç©¶ |
| **Tatoeba** | ç”¨æˆ·è´¡çŒ®çš„çŸ­å¥ï¼Œé£æ ¼éæ­£å¼ã€é•¿åº¦ä¸ä¸€ | è¯„ä¼°ç°å®å™ªå£°ä¸‹çš„é²æ£’æ€§ |

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **è®­ç»ƒåè®®**ï¼šå¤šæ•°å®éªŒä½¿ç”¨ GlotLID-C ä½œä¸ºè®­ç»ƒé›†ï¼Œå…¶ä½™ä¸ºæµ‹è¯•é›†ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Macro-averaged F1**ï¼šå…¬å¹³å¯¹å¾…æ‰€æœ‰è¯­è¨€ï¼Œå°¤å…¶å…³æ³¨å°‘æ•°ç±»ã€‚
  - **Macro-averaged False Positive Rate (FPR)**ï¼šè¡¡é‡è¯¯åˆ¤ç‡ï¼Œå¯¹ä½èµ„æºè¯­è¨€å°¤ä¸ºé‡è¦ã€‚
  - **Accuracy**ï¼šåœ¨ WiLI ä¸Šç”¨äºåˆ†ææ ·æœ¬æ•ˆç‡å’Œè¾“å…¥é•¿åº¦å½±å“ã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | ç±»å‹ | æ˜¯å¦å¯å¤ç° |
|------|------|-----------|
| **fastText** | åˆ¤åˆ«å¼ï¼Œå­—ç¬¦ n-gram + çº¿æ€§åˆ†ç±»å™¨ | âœ… è‡ªè¡Œè®­ç»ƒ |
| **CLD3** | è½»é‡çº§ç¥ç»ç½‘ç»œï¼Œæ”¯æŒ 107 ç§è¯­è¨€ | âŒ ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ |
| **GlotLID-M** | åŸºäº fastText æ¶æ„ï¼Œä½†è®­ç»ƒæ•°æ®ç²¾å¿ƒç­›é€‰ | âŒ ä½¿ç”¨å…¬å¼€ checkpoint |

> æ³¨ï¼šåªæœ‰ fastText å…è®¸æ§åˆ¶è®­ç»ƒæ•°æ®ï¼Œå› æ­¤æˆä¸ºä¸»è¦å¯¹æ¯”å¯¹è±¡ã€‚

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 å’Œ Figure 1ï¼‰

#### æ•´ä½“æ€§èƒ½ï¼ˆMacro F1ï¼‰
| æ–¹æ³• | GlotLID-C (1940ç±») | UDHR (366ç±») | FLORES-200 (190ç±») |
|------|--------------------|--------------|-------------------|
| **fastText** | 0.944 | 0.855 | 0.938 |
| **UniLID** | 0.929 | 0.859 | 0.932 |
| **UniLID-Mistral-Nemo** | 0.912 | 0.836 | 0.923 |

> â†’ UniLID æ€§èƒ½**å…·æœ‰ç«äº‰åŠ›**ï¼Œç•¥ä½äº fastTextï¼Œä½†åœ¨å…¶ä»–ç»´åº¦æ˜¾è‘—å ä¼˜ã€‚

#### é”™è¯¯ç‡ï¼ˆFalse Positive Rateï¼‰
| æ–¹æ³• | GlotLID-C FPR |
|------|---------------|
| **fastText** | 2.71e-5 |
| **UniLID** | **2.03e-5** â†“ |

> â†’ UniLID **FPR é™ä½çº¦ 25%**ï¼Œè¿™å¯¹é˜²æ­¢ä½èµ„æºè¯­è¨€è¢«æ±¡æŸ“è‡³å…³é‡è¦ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ğŸ“ˆ **æ ·æœ¬æ•ˆç‡ï¼ˆSample Efficiencyï¼‰**
- åœ¨ **WiLI** ä¸Šè¿›è¡Œæ§åˆ¶å®éªŒï¼ˆæ¯è¯­è¨€ä»… K ä¸ªæ ·æœ¬ï¼‰ï¼š
  - **UniLID @ 5 samples/lang**: **>70% å‡†ç¡®ç‡**
  - **fastText @ 5 samples/lang**: ~10% å‡†ç¡®ç‡ï¼ˆå‡ ä¹æ— æ³•æ³›åŒ–ï¼‰
  - **UniLID @ <50 samples/lang**: >90% å‡†ç¡®ç‡

> å›¾ 1 æ˜¾ç¤º UniLID åœ¨ä½èµ„æºåŒºé—´çš„å·¨å¤§ä¼˜åŠ¿ã€‚

#### ğŸ—£ï¸ **æ–¹è¨€è¯†åˆ«ï¼ˆDSL-ML 2024ï¼‰**
| æ–¹æ³• | Macro F1 |
|------|---------|
| **fastText** | 0.532 |
| **UniLID** | **0.723** â†‘

> å°¤å…¶åœ¨æ–¯æ‹‰å¤«è¯­æ—ï¼ˆSR, HR, BS, MEï¼‰ä¸Šï¼ŒfastText è¡¨ç°æå·®ï¼ˆF1=0ï¼‰ï¼Œè€Œ UniLID ä¿æŒç¨³å¥ã€‚

#### ğŸ”„ **è·¨åŸŸé²æ£’æ€§ï¼ˆTatoeba æµ‹è¯•ï¼‰**
| æ–¹æ³• | Tatoeba Macro F1 |
|------|------------------|
| **fastText** | 0.160 |
| **UniLID** | **0.414** â†‘

> åœ¨çŸ­ã€å™ªã€éæ­£å¼æ–‡æœ¬ä¸Šï¼ŒUniLID æ³›åŒ–èƒ½åŠ›æ›´å¼ºã€‚

#### ğŸ“ **è¾“å…¥é•¿åº¦é²æ£’æ€§ï¼ˆWiLIï¼‰**
| è¾“å…¥é•¿åº¦ (chars) | UniLID Acc (%) | fastText Acc (%) |
|------------------|----------------|------------------|
| 101â€“150 | **93.10** | 90.73 |
| 151â€“200 | **94.17** | 92.56 |
| ... | ... | ... |
| Overall | **95.65** | 94.54 |

> UniLID åœ¨**çŸ­æ–‡æœ¬ä¸Šå¢ç›Šæœ€å¤§**ï¼Œç¬¦åˆå®é™…åº”ç”¨åœºæ™¯ï¼ˆå¦‚ç¤¾äº¤åª’ä½“ï¼‰ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ğŸ”¤ è¯æ±‡è¡¨æ•æ„Ÿæ€§ï¼ˆTable 8ï¼‰
| æ–¹æ³• | Macro F1 | FPR |
|------|----------|-----|
| **UniLID (base)** | 0.960 | 1.859e-4 |
| **UniLID-Mistral-Nemo** | 0.958 | 1.925e-4 |
| **UniLID-LLaMA3.2** | 0.954 | 2.084e-4 |

> â†’ ä½¿ç”¨ä¸åŒ LLM çš„ tokenizerï¼ˆå¦‚ Mistral, LLaMAï¼‰ä»èƒ½ä¿æŒé«˜æ€§èƒ½ï¼Œè¯´æ˜æ–¹æ³•**å¯¹è¯æ±‡è¡¨é€‰æ‹©é²æ£’**ã€‚

#### ğŸ“š è¯æ±‡å¤§å°å½±å“ï¼ˆTable 7ï¼‰
| è¯æ±‡å¤§å° | Macro F1 | æ¨ç†å»¶è¿Ÿ (ms) |
|--------|----------|----------------|
| 10k | 0.945 | 0.113 |
| 100k | 0.960 | 0.175 |
| 200k | 0.9606 | 0.233 |

> â†’ æ€§èƒ½åœ¨ 50k åè¶‹äºé¥±å’Œï¼Œ**æ— éœ€æå¤§è¯æ±‡è¡¨**å³å¯è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **åˆ†è¯åº”æ˜¯è¯­è¨€ç‰¹å®šçš„**ï¼šå…è®¸ä¸åŒè¯­è¨€æœ‰ä¸åŒçš„æœ€ä¼˜åˆ†è¯è¾¹ç•Œï¼Œèƒ½æ›´å¥½åœ°æ•æ‰å½¢æ€å­¦å·®å¼‚ï¼Œæå‡è¯†åˆ«ç²¾åº¦ã€‚
2. **ç”Ÿæˆå¼å»ºæ¨¡ + è´å¶æ–¯å†³ç­–** åœ¨ LID ä¸Šä¾ç„¶å¼ºå¤§ï¼Œå°¤å…¶åœ¨ä½èµ„æºå’Œç»†ç²’åº¦ä»»åŠ¡ä¸­ä¼˜äºåˆ¤åˆ«å¼æ–¹æ³•ã€‚
3. **æé«˜çš„æ•°æ®æ•ˆç‡**ï¼šä»…éœ€æå°‘é‡æ ·æœ¬å³å¯è®­ç»ƒå‡ºæœ‰æ•ˆæ¨¡å‹ï¼Œé€‚åˆå¿«é€Ÿæ‰©å±•è‡³æ–°è¯­è¨€ã€‚
4. **å¤©ç„¶é›†æˆæ€§**ï¼šå¯æ— ç¼åµŒå…¥ç°æœ‰ LLM çš„ tokenizer æµç¨‹ï¼Œæ— éœ€é¢å¤–æ¨ç†å¼€é”€ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **Unigram å‡è®¾**ï¼šå¿½ç•¥ token é—´ä¾èµ–å…³ç³»ï¼Œè¡¨è¾¾èƒ½åŠ›å—é™ã€‚
2. **å­˜å‚¨æˆæœ¬çº¿æ€§å¢é•¿**ï¼šæ¯æ–°å¢ä¸€ç§è¯­è¨€éœ€å­˜å‚¨ä¸€å¥— $ \phi_l $ï¼Œå¯¹æ•°åƒè¯­è¨€åœºæ™¯å¯èƒ½æ„æˆæŒ‘æˆ˜ã€‚
3. **ä¾èµ–é«˜è´¨é‡ tokenizer è¯æ±‡è¡¨**ï¼šè™½ç„¶å¯¹è¯æ±‡é€‰æ‹©é²æ£’ï¼Œä½†ä»éœ€åˆç†è®¾è®¡ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼•å…¥ n-gram æˆ–ä¸Šä¸‹æ–‡ä¾èµ–**ï¼šæ„å»ºè¯­è¨€æ¡ä»¶ä¸‹çš„ n-gram æ¨¡å‹ä»¥æ•è·å±€éƒ¨ä¾èµ–ã€‚
2. **ä¸ç¡®å®šæ€§å»ºæ¨¡**ï¼šä¸å†ä½¿ç”¨â€œæœ€å¯èƒ½åˆ†è¯â€ä½œä¸ºç‚¹ä¼°è®¡ï¼Œè€Œæ˜¯å¯¹æ‰€æœ‰åˆ†è¯è·¯å¾„è¿›è¡Œè¿‘ä¼¼è¾¹ç¼˜åŒ–ï¼Œæå‡é²æ£’æ€§ã€‚
3. **å‹ç¼©ä¸å…±äº«å‚æ•°**ï¼šæ¢ç´¢è·¨è¯­è¨€å‚æ•°å…±äº«æœºåˆ¶ä»¥é™ä½å­˜å‚¨å¼€é”€ã€‚
4. **ç»“åˆ contrastive learning**ï¼šåˆ©ç”¨ç›‘ç£å¯¹æ¯”å­¦ä¹ è¿›ä¸€æ­¥æ‹‰å¤§ç›¸ä¼¼è¯­è¨€é—´çš„è¡¨ç¤ºè·ç¦»ã€‚

---

### å½±å“å£°æ˜ï¼ˆImpact Statementï¼‰
- **æ­£é¢å½±å“**ï¼šæœ‰åŠ©äºæ„å»ºæ›´åŒ…å®¹ã€å¤šæ ·åŒ–çš„å¤šè¯­è¨€æ•°æ®é›†ï¼Œå‡å°‘é«˜/ä½èµ„æºè¯­è¨€ä¹‹é—´çš„æ€§èƒ½å·®è·ã€‚
- **æ½œåœ¨é£é™©**ï¼šç²¾ç»†çš„æ–¹è¨€è¯†åˆ«å¯èƒ½è¢«æ»¥ç”¨äºç›‘æ§æˆ–æ­§è§†ç‰¹å®šè¯­è¨€ç¾¤ä½“ï¼Œéœ€è°¨æ…åº”ç”¨ã€‚

> ä½œè€…å¼ºè°ƒï¼ŒæŠ€æœ¯æœ¬èº«æ˜¯ä¸­ç«‹çš„ï¼Œå…³é”®åœ¨äºå¦‚ä½•è´Ÿè´£ä»»åœ°ä½¿ç”¨ LID æŠ€æœ¯ã€‚

</details>

---

### 15. [WarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation](https://arxiv.org/abs/2602.17442)

**Authors**: Marco Avolio, Potito Aghilar, Sabino Roccotelli, Vito Walter Anelli, Chiara Mallamaci, Vincenzo Paparella, Marco Valentini, Alejandro Bellog\'in, Michelantonio Trizio, Joseph Trotta, Antonio Ferrara, Tommaso Di Noia  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.17442v1  

#### Abstract
Innovation in Recommender Systems is currently impeded by a fractured ecosystem, where researchers must choose between the ease of in-memory experimentation and the costly, complex rewriting required for distributed industrial engines. To bridge this gap, we present WarpRec, a high-performance frame...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šWarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### âœ… **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

æ¨èç³»ç»Ÿï¼ˆ**Recommender Systems, RS**ï¼‰é¢†åŸŸé•¿æœŸå­˜åœ¨**å­¦æœ¯ç•Œä¸å·¥ä¸šç•Œä¹‹é—´çš„å‰²è£‚**ï¼š

- **å­¦æœ¯æ¡†æ¶**ï¼ˆå¦‚ RecBoleã€Elliotï¼‰ï¼šçµæ´»æ˜“ç”¨ï¼Œæ”¯æŒä¸°å¯Œçš„è¯„ä¼°åè®®å’Œå¯å¤ç°æ€§ï¼Œä½†åŸºäºå•æœºå†…å­˜è®¡ç®—ï¼ˆin-memoryï¼‰ï¼Œéš¾ä»¥æ‰©å±•åˆ°å¤§è§„æ¨¡å·¥ä¸šåœºæ™¯ã€‚
- **å·¥ä¸šæ¡†æ¶**ï¼ˆå¦‚ NVIDIA Merlinã€MS Recommendersï¼‰ï¼šæ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒå’Œé«˜ååï¼Œä½†ç¼ºä¹ç§‘å­¦ä¸¥è°¨æ€§ï¼Œç¼ºå°‘ç»Ÿè®¡æ£€éªŒã€å¤šç›®æ ‡ä¼˜åŒ–ã€å…¬å¹³æ€§ç­‰ç ”ç©¶æ‰€éœ€åŠŸèƒ½ã€‚

æ­¤å¤–ï¼Œå½“å‰æ¡†æ¶åœ¨ä»¥ä¸‹æ–¹é¢ä¹Ÿå­˜åœ¨ä¸è¶³ï¼š
- ç¼ºä¹å¯¹ **Green AI**ï¼ˆç»¿è‰²äººå·¥æ™ºèƒ½ï¼‰çš„æ”¯æŒï¼Œæ— æ³•è¿½è¸ªèƒ½è€—ä¸ç¢³æ’æ”¾ï¼›
- æœªé€‚é… **Agentic AI** èŒƒå¼ï¼Œä¸èƒ½ä½œä¸º LLM å¯è°ƒç”¨çš„å·¥å…·ï¼ˆtoolï¼‰å‚ä¸æ¨ç†æµç¨‹ã€‚

---

### âœ… **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **WARPREC** â€”â€” ä¸€ä¸ªé«˜æ€§èƒ½ã€æ¨¡å—åŒ–ã€åç«¯æ— å…³çš„æ¨èç³»ç»Ÿæ¡†æ¶ï¼Œæ—¨åœ¨ç»Ÿä¸€å­¦æœ¯ä¸¥è°¨æ€§ä¸å·¥ä¸šçº§å¯æ‰©å±•æ€§ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š

1. **Backend-Agnostic æ¶æ„**
   - åŸºäº **Narwhals** å®ç°â€œä¸€æ¬¡ç¼–å†™ï¼Œéšå¤„è¿è¡Œâ€ï¼ˆwrite-once, run-anywhereï¼‰ã€‚
   - æ”¯æŒä»æœ¬åœ°è°ƒè¯•æ— ç¼åˆ‡æ¢åˆ° Ray é›†ç¾¤ä¸Šçš„åˆ†å¸ƒå¼è®­ç»ƒã€‚

2. **äº”å¤§è§£è€¦æ¨¡å—è®¾è®¡**
   - **Reader**ï¼šç»Ÿä¸€æ•°æ®è¯»å–æ¥å£ï¼Œæ”¯æŒæœ¬åœ°ä¸äº‘å­˜å‚¨ã€‚
   - **Data Engine**ï¼šæä¾›è¿‡æ»¤ã€åˆ’åˆ†ã€å¯¹é½ç­‰åŠŸèƒ½ï¼Œç¡®ä¿å®éªŒå¯å¤ç°ã€‚
   - **Recommendation Engine**ï¼šå°è£… 55+ SOTA æ¨¡å‹ï¼Œæ”¯æŒ HPO å’Œåˆ†å¸ƒå¼è®­ç»ƒã€‚
   - **Evaluation Module**ï¼šé›†æˆ 40 ä¸ªæŒ‡æ ‡ + 19 ç§åˆ’åˆ†ç­–ç•¥ + ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒï¼ˆå¦‚ t-test, Wilcoxonï¼‰åŠå¤šé‡å‡è®¾æ ¡æ­£ï¼ˆBonferroni, FDRï¼‰ã€‚
   - **Writer Module**ï¼šæŒä¹…åŒ–ç»“æœè‡³å¤šç§åç«¯ï¼Œå¹¶è®°å½•ç¢³è¶³è¿¹ã€‚

3. **ç”Ÿæ€è´£ä»»ï¼ˆGreen AIï¼‰**
   - é¦–ä¸ªé›†æˆ **CodeCarbon** çš„æ¨èæ¡†æ¶ï¼Œå®æ—¶ç›‘æ§è®­ç»ƒè¿‡ç¨‹ä¸­çš„èƒ½æºæ¶ˆè€—ä¸ç¢³æ’æ”¾ã€‚

4. **é¢å‘ Agentic AI çš„å‡†å¤‡**
   - åŸç”Ÿå®ç° **Model Context Protocol (MCP)** æ¥å£ï¼Œä½¿æ¨èæ¨¡å‹å¯è¢« LLM ä»¥æ ‡å‡†åŒ–æ–¹å¼è°ƒç”¨ï¼Œæˆä¸ºæ™ºèƒ½ä½“ç”Ÿæ€ç³»ç»Ÿä¸­çš„â€œå·¥å…·â€ã€‚

5. **é«˜åº¦æ¨¡å—åŒ–ä¸å¯å®šåˆ¶æ€§**
   - æ”¯æŒé€šè¿‡é…ç½®æ–‡ä»¶å®šä¹‰å®Œæ•´ pipelineï¼Œä¹Ÿå¯æå–ä»»æ„æ¨¡å—åµŒå…¥å¤–éƒ¨ç³»ç»Ÿã€‚
   - æä¾›äº‹ä»¶é©±åŠ¨çš„ **Callback ç³»ç»Ÿ**ï¼Œä¾¿äºæ³¨å…¥è‡ªå®šä¹‰é€»è¾‘ã€‚

---

### âœ… **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | WARPREC ä¼˜åŠ¿ |
|------|-------------|
| **Scalability** | æ”¯æŒå•æœº â†’ å¤šGPU â†’ Rayé›†ç¾¤å¼¹æ€§æ‰©å±•ï¼Œè¿œè¶…å¤§å¤šæ•°å­¦æœ¯æ¡†æ¶ |
| **Reproducibility** | è‡ªåŠ¨åŒ–éšæœºç§å­æ§åˆ¶ã€æ•°æ®å¯¹é½ã€ç»Ÿè®¡æ£€éªŒï¼Œé¿å… p-hacking |
| **Green AI** | å†…ç½®èƒ½è€—ç›‘æ§ï¼Œæ¨åŠ¨å¯æŒç»­AIç ”ç©¶ |
| **Agentic Readiness** | æ”¯æŒ MCP åè®®ï¼Œå¯ç›´æ¥æ¥å…¥ LLM å·¥ä½œæµ |
| **Flexibility** | æ¨¡å—è§£è€¦ï¼Œæ”¯æŒå®šåˆ¶ç®—æ³•ã€è¯„ä¼°æµç¨‹ã€éƒ¨ç½²æ–¹å¼ |

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### âœ… **ä½¿ç”¨çš„æ•°æ®é›†**

å®éªŒè¦†ç›–ä»å°è§„æ¨¡åˆ°å·¥ä¸šçº§çš„æ•°æ®é›†ï¼ŒéªŒè¯å¯æ‰©å±•æ€§ï¼š

| æ•°æ®é›† | ç”¨æˆ·æ•° | ç‰©å“æ•° | äº¤äº’æ•° | ç¨€ç–åº¦ |
|--------|--------|--------|--------|--------|
| **MovieLens-1M** | 6,040 | 3,883 | ~1M | 95.7% |
| **MovieLens-32M** | 200,948 | 87,585 | ~32M | 99.8% |
| **NetflixPrize-100M** | 480,189 | 17,770 | ~100M | 98.8% |

> æ³¨ï¼šé€‰æ‹©è¿™äº›æ•°æ®é›†æ˜¯ä¸ºäº†ä¸ä¸»æµæ¡†æ¶è¿›è¡Œå…¬å¹³æ¯”è¾ƒï¼Œä¸” WARPREC å®é™…èƒ½åŠ›å¯å¤„ç†æ›´å¤§è§„æ¨¡æ•°æ®ã€‚

---

### âœ… **å®éªŒè®¾ç½®**

- **æ‰§è¡Œæ¨¡å¼**ï¼š
  - **Serial**ï¼šå•ä»»åŠ¡é¡ºåºæ‰§è¡Œ
  - **Parallel**ï¼šä½¿ç”¨ Ray å¹¶è¡Œæ‰§è¡Œå¤šä¸ª HPO trial
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š
  - CPU: 16æ ¸
  - GPU: 64GB NVIDIA A100
  - å†…å­˜ï¼šæœ€é«˜è¾¾ 256GB
- **HPO è®¾ç½®**ï¼š
  - ä½¿ç”¨ç½‘æ ¼æœç´¢ï¼ˆGrid Searchï¼‰ï¼Œæ¯æ¨¡å‹6ç§é…ç½®
  - è¶…å‚ä¼˜åŒ–æ—¶é—´ä¸Šé™ä¸º 24 å°æ—¶/ trial
  - æœ€ä½³æ¨¡å‹æŒ‰éªŒè¯é›† **nDCG@10** é€‰æ‹©
- **Batch Size**: 8,192
- **Epochs**: MovieLens ä¸Šè®­ç»ƒ 10 è½®ï¼ŒNetflix ä¸Šè®­ç»ƒ 2 è½®

---

### âœ… **è¯„ä¼°æŒ‡æ ‡**

| ç±»åˆ« | æŒ‡æ ‡ç¤ºä¾‹ |
|------|----------|
| **æ•ˆç‡æŒ‡æ ‡** | Preprocessing Time, Training Time, Evaluation Time, HPO Duration, Total Wall-clock Time |
| **æ€§èƒ½æŒ‡æ ‡** | **nDCG@10**ï¼ˆä¸»æŒ‡æ ‡ï¼‰ï¼ŒRecall@10, Precision@10 ç­‰ |
| **ç»Ÿè®¡ä¸¥è°¨æ€§** | Paired t-test, Wilcoxon signed-rank test, Bonferroni, FDR æ ¡æ­£ |
| **Green AI æŒ‡æ ‡** | èƒ½è€—ï¼ˆkWhï¼‰ã€COâ‚‚ æ’æ”¾é‡ï¼ˆkgï¼‰ã€CPU/GPU åŠŸç‡ï¼ˆWï¼‰ |

---

### âœ… **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

é€‰å–ä»£è¡¨æ€§æ¡†æ¶ä½œä¸º baselineï¼š

| ç±»å‹ | æ¡†æ¶ |
|------|------|
| å­¦æœ¯æ¡†æ¶ | **RecBole**, **Elliot**, **Cornac**, **DaisyRec** |
| å·¥ä¸šæ¡†æ¶ | **Microsoft Recommenders (MS Rec.)** |

> æ‰€æœ‰å®éªŒå‡ä½¿ç”¨å›ºå®šéšæœºç§å­ï¼Œé€šè¿‡ **Weights & Biases** è¿½è¸ªï¼Œä»£ç å¼€æºï¼š[GitHub](https://github.com/sisinflab/warprec)

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### âœ… **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 4ï¼‰**

#### ğŸ”¹ åœ¨ **NetflixPrize-100M** ä¸Šçš„è¡¨ç°ï¼ˆä¸­ç­‰è§„æ¨¡ï¼‰

| æ–¹æ³• | HPO æ€»è€—æ—¶ | æ˜¯å¦å®Œæˆ | nDCG@10 |
|------|------------|----------|---------|
| **WARPREC (Parallel)** | **28m 0s** | âœ… å®Œæˆ | 0.1323 |
| WARPREC+ (Serial) | 3h44m | âœ… å®Œæˆ | 0.1204 |
| RecBole | 10h17m | âŒ è¶…æ—¶ (2/6) | 0.0247 |
| Elliot | >15h | âŒ è¶…æ—¶ (1/6) | 0.1779ï¼ˆä»…éƒ¨åˆ†å®Œæˆï¼‰ |
| MS Recommenders | Out of Memory (VRAM) | âŒ å¤±è´¥ | - |

> ğŸ’¡ **LightGCN æ˜¯æœ€è€—èµ„æºçš„æ¨¡å‹**ï¼Œé™¤ WARPREC å’Œ RecBole å¤–ï¼Œå…¶ä½™æ¡†æ¶å‡æ— æ³•å®Œæˆè®­ç»ƒã€‚

#### ğŸ”¹ åœ¨ **MovieLens-32M** ä¸Šçš„è¡¨ç°ï¼ˆå°è§„æ¨¡ï¼‰

| æ–¹æ³• | HPO æ€»è€—æ—¶ | æ˜¯å¦å®Œæˆ | nDCG@10 |
|------|------------|----------|---------|
| **WARPREC (Parallel)** | **1h34m** | âœ… å®Œæˆ | 0.1456 |
| RecBole | 7h10m | âœ… å®Œæˆ | 0.3609ï¼ˆè¾ƒé«˜ä½†æ…¢ï¼‰ |
| Elliot | >16h | âŒ è¶…æ—¶ (3/6) | - |
| DaisyRec | Out of Memory (RAM/VRAM) | âŒ å¤±è´¥ | - |

> âš ï¸ æ³¨æ„ï¼šRecBole è™½ç„¶æœ€ç»ˆå®Œæˆï¼Œä½†åœ¨å¤§æ¨¡å‹ï¼ˆå¦‚ LightGCNï¼‰ä¸Šè¡¨ç°æå·®æˆ–å´©æºƒã€‚

#### ğŸ”¹ åœ¨ **MovieLens-1M** ä¸Šçš„è¡¨ç°ï¼ˆå¾®å‹è§„æ¨¡ï¼‰

æ‰€æœ‰æ¡†æ¶å‡å¯å®Œæˆï¼ŒWARPREC ä»ä¿æŒæœ€å¿«ï¼š
- WARPREC HPO æ—¶é—´ï¼š**1m42s**
- RecBoleï¼š5m13s
- Elliotï¼š1m32s
- MS Recommendersï¼š35m51s

---

### âœ… **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| å¯¹æ¯”ç»´åº¦ | WARPREC è¡¨ç° |
|----------|--------------|
| **å¯æ‰©å±•æ€§** | å”¯ä¸€èƒ½åœ¨æ‰€æœ‰æ•°æ®é›†å’Œæ¨¡å‹ä¸ŠæˆåŠŸå®Œæˆ end-to-end pipeline çš„æ¡†æ¶ |
| **é€Ÿåº¦ä¼˜åŠ¿** | åœ¨å¹¶è¡Œæ¨¡å¼ä¸‹ï¼ŒHPO æ—¶é—´æ¯”ç¬¬äºŒå¿«è€…å¿« **2â€“10å€** |
| **å†…å­˜æ•ˆç‡** | æœ‰æ•ˆç®¡ç† GPU/CPU å†…å­˜ï¼Œé¿å… OOM é”™è¯¯ |
| **ç¨³å®šæ€§** | æ— éšæœºå¤±è´¥ï¼Œcheckpoint æ”¯æŒæ–­ç‚¹ç»­è®­ |

---

### âœ… **æ¶ˆèå®éªŒç»“æœï¼ˆéšå«åˆ†æï¼‰**

è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºä¼ ç»Ÿâ€œæ¶ˆèå®éªŒâ€ï¼Œä½†é€šè¿‡ä¸åŒæ‰§è¡Œæ¨¡å¼ï¼ˆserial vs parallelï¼‰å’Œç»„ä»¶å¯ç”¨çŠ¶æ€è¿›è¡Œäº†åŠŸèƒ½éªŒè¯ï¼š

- **Ray åˆ†å¸ƒå¼åŠ é€Ÿæ•ˆæœæ˜¾è‘—**ï¼šåœ¨ Netflix æ•°æ®é›†ä¸Šï¼Œparallel æ¨¡å¼å°† HPO æ—¶é—´ä» 3h+ ç¼©çŸ­è‡³ <30minã€‚
- **Narwhals åç«¯æŠ½è±¡æ— æ€§èƒ½æŸå¤±**ï¼šè·¨å¹³å°æ•°æ®æ“ä½œæœªå¼•å…¥é¢å¤–å¼€é”€ã€‚
- **CodeCarbon å¼€é”€æä½**ï¼šç›‘æ§èƒ½è€—å¯¹è®­ç»ƒé€Ÿåº¦å½±å“å¯å¿½ç•¥ã€‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### âœ… **è®ºæ–‡çš„ä¸»è¦å‘ç°**

1. **å­¦æœ¯ä¸å·¥ä¸šé¸¿æ²Ÿå¯ä»¥è¢«å¼¥åˆ**  
   WARPREC æˆåŠŸå®ç°äº†â€œä¸€æ¬¡å¼€å‘ï¼Œå¤šç¯å¢ƒéƒ¨ç½²â€çš„æ„¿æ™¯ï¼Œæ— éœ€é‡å†™å³å¯ä»å®éªŒå®¤èµ°å‘ç”Ÿäº§ã€‚

2. **å¯æ‰©å±•æ€§ä¸ç‰ºç‰²ç§‘å­¦ä¸¥è°¨æ€§**  
   åœ¨ä¿è¯åˆ†å¸ƒå¼æ€§èƒ½çš„åŒæ—¶ï¼Œä»èƒ½æ‰§è¡Œå¤æ‚çš„è¯„ä¼°åè®®ã€ç»Ÿè®¡æ£€éªŒå’Œå¤šç›®æ ‡ä¼˜åŒ–ã€‚

3. **Green AI å¯è½åœ°**  
   å®éªŒè¡¨æ˜ï¼Œä¸åŒæ¨¡å‹çš„ç¢³è¶³è¿¹å·®å¼‚å·¨å¤§ï¼ˆå¦‚ LightGCN æ˜¯ EASE çš„ 20 å€ä»¥ä¸Šï¼‰ï¼Œæé†’ç¤¾åŒºå…³æ³¨â€œè¾¹é™…æ”¶ç›Š vs ç¢³æˆæœ¬â€ã€‚

4. **Agentic AI æ˜¯æœªæ¥æ–¹å‘**  
   é€šè¿‡ MCP æ¥å£ï¼ŒWARPREC å·²ç»æ”¯æŒ LLM åŠ¨æ€è°ƒç”¨æ¨èæœåŠ¡ï¼Œå®ç°â€œè§£é‡Š+æ¨èâ€ä¸€ä½“åŒ–è¾“å‡ºï¼ˆè§ Figure 2 ç¤ºä¾‹ï¼‰ã€‚

---

### âš ï¸ **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™ | è¯´æ˜ |
|------|------|
| **å­¦ä¹ æ›²çº¿è¾ƒé™¡** | æ¨¡å—åŒ–è®¾è®¡å¸¦æ¥çµæ´»æ€§ï¼Œä½†ä¹Ÿå¢åŠ åˆå­¦è€…ç†è§£æˆæœ¬ |
| **æ–‡æ¡£å°šå¾…å®Œå–„** | å½“å‰ä¾èµ– GitHub ç¤ºä¾‹ï¼Œæ­£å¼æ–‡æ¡£ä»åœ¨å»ºè®¾ä¸­ |
| **ç‰¹å®šç¡¬ä»¶ä¾èµ–** | å……åˆ†å‘æŒ¥æ€§èƒ½éœ€é…å¤‡é«˜ç«¯ GPU å’Œ Ray é›†ç¾¤ |
| **å†·å¯åŠ¨æ”¯æŒæœ‰é™** | å½“å‰è¿‡æ»¤ç­–ç•¥åå‘æˆç†Ÿç”¨æˆ·/ç‰©å“ï¼Œå¯¹æç¨€ç–åœºæ™¯ä¼˜åŒ–ä¸è¶³ |

---

### â• **æœªæ¥å·¥ä½œæ–¹å‘**

1. **å¢å¼º AutoML æ”¯æŒ**ï¼šè‡ªåŠ¨æ¨¡å‹é€‰æ‹© + è¶…å‚ä¼˜åŒ– pipelineã€‚
2. **æ‰©å±• MCP åŠŸèƒ½**ï¼šæ”¯æŒæ›´å¤æ‚çš„å¯¹è¯å¼æ¨èäº¤äº’ã€‚
3. **é›†æˆæ›´å¤š Green AI å·¥å…·**ï¼šå¦‚ CarbonTrackerï¼Œæä¾›æ›´ç»†ç²’åº¦æŠ¥å‘Šã€‚
4. **æ”¯æŒæµå¼æ¨èï¼ˆStreaming Recommendationï¼‰**ï¼šå®ç°å®æ—¶å¢é‡æ›´æ–°ã€‚
5. **æ„å»ºå¯è§†åŒ– IDE æ’ä»¶**ï¼šé™ä½ WARPREC ä½¿ç”¨é—¨æ§›ã€‚

---

## âœ… **æ€»ç»“**

**WARPREC** ä¸åªæ˜¯ä¸€ä¸ªæ–°çš„æ¨èæ¡†æ¶ï¼Œæ›´æ˜¯æ¨èç³»ç»Ÿå·¥ç¨‹èŒƒå¼çš„å‡çº§ï¼š

> å®ƒé¦–æ¬¡å°† **Academic Rigor**ï¼ˆç§‘å­¦ä¸¥è°¨ï¼‰ã€**Industrial Scale**ï¼ˆå·¥ä¸šå¯æ‰©å±•ï¼‰ã€**Green AI**ï¼ˆå¯æŒç»­æ€§ï¼‰å’Œ **Agentic Readiness**ï¼ˆæ™ºèƒ½ä½“å°±ç»ªï¼‰å››å¤§æ”¯æŸ±èåˆäºåŒä¸€æ¶æ„ä¹‹ä¸­ã€‚

å…¶å¼€æºå®ç°ä¸ºä¸‹ä¸€ä»£è´Ÿè´£ä»»ã€å¯å¤ç°ã€é«˜æ•ˆä¸”ç”Ÿæ€å‹å¥½çš„æ¨èç³»ç»Ÿç ”ç©¶æä¾›äº†åšå®åŸºç¡€ã€‚

ğŸ”— **é¡¹ç›®åœ°å€**ï¼š[https://github.com/sisinflab/warprec](https://github.com/sisinflab/warprec)

</details>

---

### 16. [AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing](https://arxiv.org/abs/2602.17607)

**Authors**: Jianda Du, Youran Sun, Haizhao Yang  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.17607v1  

#### Abstract
PDEs are central to scientific and engineering modeling, yet designing accurate numerical solvers typically requires substantial mathematical expertise and manual tuning. Recent neural network-based approaches improve flexibility but often demand high computational cost and suffer from limited inter...

---

### 17. [NeuDiff Agent: A Governed AI Workflow for Single-Crystal Neutron Crystallography](https://arxiv.org/abs/2602.16812)

**Authors**: Zhongcan Xiao (Neutron Scattering Division, Oak Ridge National Laboratory, Oak Ridge, Tennesse USA), Leyi Zhang (Neutron Scattering Division, Oak Ridge National Laboratory, Oak Ridge, Tennesse USA, Department of Linguistics, University of Illinois Urbana-Champaign, Urbana, Illinois, USA), Guannan Zhang (Computer Science and Mathematics Division, Oak Ridge National Laboratory, Oak Ridge, Tennessee, USA), Xiaoping Wang (Neutron Scattering Division, Oak Ridge National Laboratory, Oak Ridge, Tennesse USA)  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.16812v1  

#### Abstract
Large-scale facilities increasingly face analysis and reporting latency as the limiting step in scientific throughput, particularly for structurally and magnetically complex samples that require iterative reduction, integration, refinement, and validation. To improve time-to-result and analysis effi...

---

### 18. [Node Learning: A Framework for Adaptive, Decentralised and Collaborative Network Edge AI](https://arxiv.org/abs/2602.16814)

**Authors**: Eiman Kanjo, Mustafa Aslanov  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.16814v1  

#### Abstract
The expansion of AI toward the edge increasingly exposes the cost and fragility of cen- tralised intelligence. Data transmission, latency, energy consumption, and dependence on large data centres create bottlenecks that scale poorly across heterogeneous, mobile, and resource-constrained environments...

---

### 19. [Pareto Optimal Benchmarking of AI Models on ARM Cortex Processors for Sustainable Embedded Systems](https://arxiv.org/abs/2602.17508)

**Authors**: Pranay Jain, Maximilian Kasper, G\"oran K\"ober, Axel Plinge, Dominik Seu{\ss}  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.17508v1  

#### Abstract
This work presents a practical benchmarking framework for optimizing artificial intelligence (AI) models on ARM Cortex processors (M0+, M4, M7), focusing on energy efficiency, accuracy, and resource utilization in embedded systems. Through the design of an automated test bench, we provide a systemat...

---

### 20. [KLong: Training LLM Agent for Extremely Long-horizon Tasks](https://arxiv.org/abs/2602.17547)

**Authors**: Yue Liu, Zhiyuan Hu, Flood Sung, Jiaheng Zhang, Bryan Hooi  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.17547v1  

#### Abstract
This paper introduces KLong, an open-source LLM agent trained to solve extremely long-horizon tasks. The principle is to first cold-start the model via trajectory-splitting SFT, then scale it via progressive RL training. Specifically, we first activate basic agentic abilities of a base model with a ...

---

### 21. [Entropy-Based Data Selection for Language Models](https://arxiv.org/abs/2602.17465)

**Authors**: Hongming Li, Yang Liu, Chao Huang  
**Category**: cs.CL  
**Published**: 2026-02-20  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.17465v1  

#### Abstract
Modern language models (LMs) increasingly require two critical resources: computational resources and data resources. Data selection techniques can effectively reduce the amount of training data required for fine-tuning LMs. However, their effectiveness is closely related to computational resources,...

---

### 22. [ML-driven detection and reduction of ballast information in multi-modal datasets](https://arxiv.org/abs/2602.16876)

**Authors**: Yaroslav Solovko  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.16876v1  

#### Abstract
Modern datasets often contain ballast as redundant or low-utility information that increases dimensionality, storage requirements, and computational cost without contributing meaningful analytical value. This study introduces a generalized, multimodal framework for ballast detection and reduction ac...

---

### 23. [Dynamic Delayed Tree Expansion For Improved Multi-Path Speculative Decoding](https://arxiv.org/abs/2602.16994)

**Authors**: Rahul Thomas, Teo Kitanovski, Micah Goldblum, Arka Pal  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.16994v1  

#### Abstract
Multi-path speculative decoding accelerates lossless sampling from a target model by using a cheaper draft model to generate a draft tree of tokens, and then applies a verification algorithm that accepts a subset of these. While prior work has proposed various verification algorithms for i.i.d rollo...

---

### 24. [WS-GRPO: Weakly-Supervised Group-Relative Policy Optimization for Rollout-Efficient Reasoning](https://arxiv.org/abs/2602.17025)

**Authors**: Gagan Mundada, Zihan Huang, Rohan Surana, Sheldon Yu, Jennifer Yuntong Zhang, Xintong Li, Tong Yu, Lina Yao, Jingbo Shang, Julian McAuley, Junda Wu  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.17025v1  

#### Abstract
Group Relative Policy Optimization (GRPO) is effective for training language models on complex reasoning. However, since the objective is defined relative to a group of sampled trajectories, extended deliberation can create more chances to realize relative gains, leading to inefficient reasoning and...

---

### 25. [Multi-Probe Zero Collision Hash (MPZCH): Mitigating Embedding Collisions and Enhancing Model Freshness in Large-Scale Recommenders](https://arxiv.org/abs/2602.17050)

**Authors**: Ziliang Zhao, Bi Xue, Emma Lin, Mengjiao Zhou, Kaustubh Vartak, Shakhzod Ali-Zade, Carson Lu, Tao Li, Bin Kuang, Rui Jian, Bin Wen, Dennis van der Staay, Yixin Bao, Eddy Li, Chao Deng, Songbin Liu, Qifan Wang, Kai Ren  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.17050v1  

#### Abstract
Embedding tables are critical components of large-scale recommendation systems, facilitating the efficient mapping of high-cardinality categorical features into dense vector representations. However, as the volume of unique IDs expands, traditional hash-based indexing methods suffer from collisions ...

---

### 26. [RLGT: A reinforcement learning framework for extremal graph theory](https://arxiv.org/abs/2602.17276)

**Authors**: Ivan Damnjanovi\'c, Uro\v{s} Milivojevi\'c, Irena {\DJ}or{\dj}evi\'c, Dragan Stevanovi\'c  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.17276v1  

#### Abstract
Reinforcement learning (RL) is a subfield of machine learning that focuses on developing models that can autonomously learn optimal decision-making strategies over time. In a recent pioneering paper, Wagner demonstrated how the Deep Cross-Entropy RL method can be applied to tackle various problems f...

---

### 27. [Decoding the Human Factor: High Fidelity Behavioral Prediction for Strategic Foresight](https://arxiv.org/abs/2602.17222)

**Authors**: Ben Yellin, Ehud Ezra, Mark Foreman, Shula Grinapol  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2602.17222v1  

#### Abstract
Predicting human decision-making in high-stakes environments remains a central challenge for artificial intelligence. While large language models (LLMs) demonstrate strong general reasoning, they often struggle to generate consistent, individual-specific behavior, particularly when accurate predicti...

---

### 28. [All Leaks Count, Some Count More: Interpretable Temporal Contamination Detection in LLM Backtesting](https://arxiv.org/abs/2602.17234)

**Authors**: Zeyu Zhang, Ryan Chen, Bradly C. Stadie  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2602.17234v1  

#### Abstract
To evaluate whether LLMs can accurately predict future events, we need the ability to \textit{backtest} them on events that have already resolved. This requires models to reason only with information available at a specified past date. Yet LLMs may inadvertently leak post-cutoff knowledge encoded du...

---

### 29. [A Privacy by Design Framework for Large Language Model-Based Applications for Children](https://arxiv.org/abs/2602.17418)

**Authors**: Diana Addae, Diana Rogachova, Nafiseh Kahani, Masoud Barati, Michael Christensen, Chen Zhou  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2602.17418v1  

#### Abstract
Children are increasingly using technologies powered by Artificial Intelligence (AI). However, there are growing concerns about privacy risks, particularly for children. Although existing privacy regulations require companies and organizations to implement protections, doing so can be challenging in...

---

### 30. [TopoFlow: Physics-guided Neural Networks for high-resolution air quality prediction](https://arxiv.org/abs/2602.16821)

**Authors**: Ammar Kheder, Helmi Toropainen, Wenqing Peng, Samuel Ant\~ao, Jia Chen, Zhi-Song Liu, Michael Boy  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2602.16821v1  

#### Abstract
We propose TopoFlow (Topography-aware pollutant Flow learning), a physics-guided neural network for efficient, high-resolution air quality prediction. To explicitly embed physical processes into the learning framework, we identify two critical factors governing pollutant dynamics: topography and win...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
