# arXiv Papers Bot 🤖

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## 📊 Statistics

- **Last Updated**: 2025-09-09 12:53:50 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## 📚 Recent Papers

### 1. [Ban&Pick: Achieving Free Performance Gains and Inference Speedup via Smarter Routing in MoE-LLMs](https://arxiv.org/abs/2509.06346)

**Authors**: Yuanteng Chen, Peisong Wang, Yuantian Shao, Jian Cheng  
**Category**: cs.AI  
**Published**: 2025-09-09  
**Score**: 7.5

arXiv:2509.06346v1 Announce Type: cross 
Abstract: Sparse Mixture-of-Experts (MoE) has become a key architecture for scaling large language models (LLMs) efficiently. Recent fine-grained MoE designs introduce hundreds of experts per layer, with multiple experts activated per token, enabling stronger...

---

### 2. [Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers](https://arxiv.org/abs/2509.06493)

**Authors**: Ran Xin, Zeyu Zheng, Yanchen Nie, Kun Yuan, Xia Xiao  
**Category**: cs.AI  
**Published**: 2025-09-09  
**Score**: 6.0

arXiv:2509.06493v1 Announce Type: new 
Abstract: The integration of Large Language Models (LLMs) into automated theorem proving has shown immense promise, yet is fundamentally constrained by challenges in scaling up both training-time reinforcement learning (RL) and inference-time compute. This pape...

---

### 3. [DSDE: Dynamic Speculative Decoding with KLD Stability for Real-World Serving](https://arxiv.org/abs/2509.01083)

**Authors**: Mingyu Yang, Jae-Young Choi, Kihyo Moon, Minsung Jang, Eunjoo Jeon  
**Category**: cs.AI  
**Published**: 2025-09-09  
**Score**: 6.0

arXiv:2509.01083v2 Announce Type: replace-cross 
Abstract: Speculative decoding accelerates large language model inference, but its reliance on a fixed speculation length is suboptimal in large-batch serving environments with diverse requests. This paper explores a new direction for dynamic adaptati...

---

### 4. [Neural Breadcrumbs: Membership Inference Attacks on LLMs Through Hidden State and Attention Pattern Analysis](https://arxiv.org/abs/2509.05449)

**Authors**: Disha Makhija, Manoj Ghuhan Arivazhagan, Vinayshekhar Bannihatti Kumar, Rashmi Gangadharaiah  
**Category**: cs.AI  
**Published**: 2025-09-09  
**Score**: 5.5

arXiv:2509.05449v1 Announce Type: cross 
Abstract: Membership inference attacks (MIAs) reveal whether specific data was used to train machine learning models, serving as important tools for privacy auditing and compliance assessment. Recent studies have reported that MIAs perform only marginally bet...

---

### 5. [Domain-Aware RAG: MoL-Enhanced RL for Efficient Training and Scalable Retrieval](https://arxiv.org/abs/2509.06650)

**Authors**: Hao Lin, Peitong Xie, Jingxue Chen, Jie Lin, Qingkun Tang, Qianchun Lu  
**Category**: cs.CL  
**Published**: 2025-09-09  
**Score**: 5.0

arXiv:2509.06650v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) systems rely heavily on the retrieval stage, particularly the coarse-ranking process. Existing coarse-ranking optimization approaches often struggle to balance domain-specific knowledge learning with query enhencem...

---

### 6. [Pierce the Mists, Greet the Sky: Decipher Knowledge Overshadowing via Knowledge Circuit Analysis](https://arxiv.org/abs/2505.14406)

**Authors**: Haoming Huang, Yibo Yan, Jiahao Huo, Xin Zou, Xinfeng Li, Kun Wang, Xuming Hu  
**Category**: cs.CL  
**Published**: 2025-09-09  
**Score**: 5.0

arXiv:2505.14406v3 Announce Type: replace 
Abstract: Large Language Models (LLMs), despite their remarkable capabilities, are hampered by hallucinations. A particularly challenging variant, knowledge overshadowing, occurs when one piece of activated knowledge inadvertently masks another relevant pie...

---

### 7. [ProfilingAgent: Profiling-Guided Agentic Reasoning for Adaptive Model Optimization](https://arxiv.org/abs/2509.05584)

**Authors**: Sadegh Jafari, Aishwarya Sarkar, Mohiuddin Bilwal, Ali Jannesari  
**Category**: cs.LG  
**Published**: 2025-09-09  
**Score**: 5.0

arXiv:2509.05584v1 Announce Type: new 
Abstract: Foundation models face growing compute and memory bottlenecks, hindering deployment on resource-limited platforms. While compression techniques such as pruning and quantization are widely used, most rely on uniform heuristics that ignore architectural...

---

### 8. [Advanced Brain Tumor Segmentation Using EMCAD: Efficient Multi-scale Convolutional Attention Decoding](https://arxiv.org/abs/2509.05431)

**Authors**: GodsGift Uzor, Tania-Amanda Nkoyo Fredrick Eneye, Chukwuebuka Ijezue  
**Category**: cs.AI  
**Published**: 2025-09-09  
**Score**: 4.5

arXiv:2509.05431v1 Announce Type: cross 
Abstract: Brain tumor segmentation is a critical pre-processing step in the medical image analysis pipeline that involves precise delineation of tumor regions from healthy brain tissue in medical imaging data, particularly MRI scans. An efficient and effectiv...

---

### 9. [MachineLearningLM: Continued Pretraining Language Models on Millions of Synthetic Tabular Prediction Tasks Scales In-Context ML](https://arxiv.org/abs/2509.06806)

**Authors**: Haoyu Dong, Pengkun Zhang, Mingzhe Lu, Yanzhen Shen, Guolin Ke  
**Category**: cs.AI  
**Published**: 2025-09-09  
**Score**: 4.5

arXiv:2509.06806v1 Announce Type: cross 
Abstract: Large language models (LLMs) possess broad world knowledge and strong general-purpose reasoning ability, yet they struggle to learn from many in-context examples on standard machine learning (ML) tasks, that is, to leverage many-shot demonstrations ...

---

### 10. [ReST-RL: Achieving Accurate Code Reasoning of LLMs with Optimized Self-Training and Decoding](https://arxiv.org/abs/2508.19576)

**Authors**: Sining Zhoubian, Dan Zhang, Jie Tang  
**Category**: cs.AI  
**Published**: 2025-09-09  
**Score**: 4.5

arXiv:2508.19576v2 Announce Type: replace 
Abstract: With respect to improving the reasoning accuracy of LLMs, the representative reinforcement learning (RL) method GRPO faces failure due to insignificant reward variance, while verification methods based on process reward models (PRMs) suffer from d...

---

### 11. [Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA](https://arxiv.org/abs/2508.00719)

**Authors**: Yingxu Wang, Shiqi Fan, Mengzhu Wang, Siyang Gao, Siwei Liu, Nan Yin  
**Category**: cs.AI  
**Published**: 2025-09-09  
**Score**: 4.5

arXiv:2508.00719v3 Announce Type: replace-cross 
Abstract: Knowledge Graph Question Answering (KGQA) aims to interpret natural language queries and perform structured reasoning over knowledge graphs by leveraging their relational and semantic structures to retrieve accurate answers. Recent KGQA meth...

---

### 12. [Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning](https://arxiv.org/abs/2509.06948)

**Authors**: Liang Chen, Xueting Han, Li Shen, Jing Bai, Kam-Fai Wong  
**Category**: cs.CL  
**Published**: 2025-09-09  
**Score**: 4.5

arXiv:2509.06948v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has proven effective in incentivizing the reasoning abilities of large language models (LLMs), but suffers from severe efficiency challenges due to its trial-and-error nature. While the common practice employs supervised fi...

---

### 13. [Not All Features Deserve Attention: Graph-Guided Dependency Learning for Tabular Data Generation with Language Models](https://arxiv.org/abs/2507.18504)

**Authors**: Zheyu Zhang, Shuo Yang, Bardh Prenkaj, Gjergji Kasneci  
**Category**: cs.CL  
**Published**: 2025-09-09  
**Score**: 4.5

arXiv:2507.18504v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have shown strong potential for tabular data generation by modeling textualized feature-value pairs. However, tabular data inherently exhibits sparse feature-level dependencies, where many feature interactions are stru...

---

### 14. [FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving](https://arxiv.org/abs/2509.06261)

**Authors**: Kyungmin Bin, Seungbeom Choi, Jimyoung Son, Jieun Choi, Daseul Bae, Daehyeon Baek, Kihyo Moon, Minsung Jang, Hyojung Lee  
**Category**: cs.DC  
**Published**: 2025-09-09  
**Score**: 4.5

arXiv:2509.06261v1 Announce Type: new 
Abstract: Recent advances in Post-Training Quantization (PTQ) techniques have significantly increased demand for serving quantized large language models (LLMs), enabling higher throughput and substantially reduced memory usage with minimal accuracy loss. Quanti...

---

### 15. [LoaQ: Layer-wise Output Approximation Quantization](https://arxiv.org/abs/2509.06297)

**Authors**: Li Lin, Xiaojun Wan  
**Category**: cs.LG  
**Published**: 2025-09-09  
**Score**: 4.5

arXiv:2509.06297v1 Announce Type: new 
Abstract: A natural and intuitive idea in model quantization is to approximate each component's quantized output to match its original. Layer-wise post-training quantization (PTQ), though based on this idea, adopts a strictly local view and can achieve, at best...

---

### 16. [ALPHA: LLM-Enabled Active Learning for Human-Free Network Anomaly Detection](https://arxiv.org/abs/2509.05936)

**Authors**: Xuanhao Luo, Shivesh Madan Nath Jha, Akruti Sinha, Zhizhen Li, Yuchen Liu  
**Category**: cs.LG  
**Published**: 2025-09-09  
**Score**: 4.5

arXiv:2509.05936v1 Announce Type: cross 
Abstract: Network log data analysis plays a critical role in detecting security threats and operational anomalies. Traditional log analysis methods for anomaly detection and root cause analysis rely heavily on expert knowledge or fully supervised learning mod...

---

### 17. [ALPS: Improved Optimization for Highly Sparse One-Shot Pruning for Large Language Models](https://arxiv.org/abs/2406.07831)

**Authors**: Xiang Meng, Kayhan Behdin, Haoyue Wang, Rahul Mazumder  
**Category**: cs.LG  
**Published**: 2025-09-09  
**Score**: 4.5

arXiv:2406.07831v3 Announce Type: replace 
Abstract: The impressive performance of Large Language Models (LLMs) across various natural language processing tasks comes at the cost of vast computational resources and storage requirements. One-shot pruning techniques offer a way to alleviate these burd...

---

### 18. [Unleashing Hierarchical Reasoning: An LLM-Driven Framework for Training-Free Referring Video Object Segmentation](https://arxiv.org/abs/2509.05751)

**Authors**: Bingrui Zhao, Lin Yuanbo Wu, Xiangtian Fan, Deyin Liu, Lu Zhang, Ruyi He, Jialie Shen, Ximing Li  
**Category**: cs.AI  
**Published**: 2025-09-09  
**Score**: 4.0

arXiv:2509.05751v1 Announce Type: cross 
Abstract: Referring Video Object Segmentation (RVOS) aims to segment an object of interest throughout a video based on a language description. The prominent challenge lies in aligning static text with dynamic visual content, particularly when objects exhibiti...

---

### 19. [PolicyEvolve: Evolving Programmatic Policies by LLMs for multi-player games via Population-Based Training](https://arxiv.org/abs/2509.06053)

**Authors**: Mingrui Lv, Hangzhi Liu, Zhi Luo, Hongjie Zhang, Jie Ou  
**Category**: cs.AI  
**Published**: 2025-09-09  
**Score**: 4.0

arXiv:2509.06053v1 Announce Type: cross 
Abstract: Multi-agent reinforcement learning (MARL) has achieved significant progress in solving complex multi-player games through self-play. However, training effective adversarial policies requires millions of experience samples and substantial computation...

---

### 20. [PL-CA: A Parametric Legal Case Augmentation Framework](https://arxiv.org/abs/2509.06356)

**Authors**: Ao Chang, Yubo Chen, Jun Zhao  
**Category**: cs.AI  
**Published**: 2025-09-09  
**Score**: 4.0

arXiv:2509.06356v1 Announce Type: cross 
Abstract: Conventional RAG is considered one of the most effective methods for addressing model knowledge insufficiency and hallucination, particularly in the judicial domain that requires high levels of knowledge rigor, logical consistency, and content integ...

---

### 21. [Crown, Frame, Reverse: Layer-Wise Scaling Variants for LLM Pre-Training](https://arxiv.org/abs/2509.06518)

**Authors**: Andrei Baroian, Kasper Notebomer  
**Category**: cs.AI  
**Published**: 2025-09-09  
**Score**: 4.0

arXiv:2509.06518v1 Announce Type: cross 
Abstract: Transformer-based language models traditionally use uniform (isotropic) layer sizes, yet they ignore the diverse functional roles that different depths can play and their computational capacity needs. Building on Layer-Wise Scaling (LWS) and pruning...

---

### 22. [floq: Training Critics via Flow-Matching for Scaling Compute in Value-Based RL](https://arxiv.org/abs/2509.06863)

**Authors**: Bhavya Agrawalla, Michal Nauman, Khush Agarwal, Aviral Kumar  
**Category**: cs.AI  
**Published**: 2025-09-09  
**Score**: 4.0

arXiv:2509.06863v1 Announce Type: cross 
Abstract: A hallmark of modern large-scale machine learning techniques is the use of training objectives that provide dense supervision to intermediate computations, such as teacher forcing the next token in language models or denoising step-by-step in diffus...

---

### 23. [Nemotron-H: A Family of Accurate and Efficient Hybrid Mamba-Transformer Models](https://arxiv.org/abs/2504.03624)

**Authors**: NVIDIA,  :, Aaron Blakeman, Aarti Basant, Abhinav Khattar, Adithya Renduchintala, Akhiad Bercovich, Aleksander Ficek, Alexis Bjorlin, Ali Taghibakhshi, Amala Sanjay Deshmukh, Ameya Sunil Mahabaleshwarkar, Andrew Tao, Anna Shors, Ashwath Aithal, Ashwin Poojary, Ayush Dattagupta, Balaram Buddharaju, Bobby Chen, Boris Ginsburg, Boxin Wang, Brandon Norick, Brian Butterfield, Bryan Catanzaro, Carlo del Mundo, Chengyu Dong, Christine Harvey, Christopher Parisien, Dan Su, Daniel Korzekwa, Danny Yin, Daria Gitman, David Mosallanezhad, Deepak Narayanan, Denys Fridman, Dima Rekesh, Ding Ma, Dmytro Pykhtar, Dong Ahn, Duncan Riach, Dusan Stosic, Eileen Long, Elad Segal, Ellie Evans, Eric Chung, Erick Galinkin, Evelina Bakhturina, Ewa Dobrowolska, Fei Jia, Fuxiao Liu, Gargi Prasad, Gerald Shen, Guilin Liu, Guo Chen, Haifeng Qian, Helen Ngo, Hongbin Liu, Hui Li, Igor Gitman, Ilia Karmanov, Ivan Moshkov, Izik Golan, Jan Kautz, Jane Polak Scowcroft, Jared Casper, Jarno Seppanen, Jason Lu, Jason Sewall, Jiaqi Zeng, Jiaxuan You, Jimmy Zhang, Jing Zhang, Jining Huang, Jinze Xue, Jocelyn Huang, Joey Conway, John Kamalu, Jon Barker, Jonathan Cohen, Joseph Jennings, Jupinder Parmar, Karan Sapra, Kari Briski, Kateryna Chumachenko, Katherine Luna, Keshav Santhanam, Kezhi Kong, Kirthi Sivamani, Krzysztof Pawelec, Kumar Anik, Kunlun Li, Lawrence McAfee, Leon Derczynski, Lindsey Pavao, Luis Vega, Lukas Voegtle, Maciej Bala, Maer Rodrigues de Melo, Makesh Narsimhan Sreedhar, Marcin Chochowski, Markus Kliegl, Marta Stepniewska-Dziubinska, Matthieu Le, Matvei Novikov, Mehrzad Samadi, Michael Andersch, Michael Evans, Miguel Martinez, Mike Chrzanowski, Mike Ranzinger, Mikolaj Blaz, Misha Smelyanskiy, Mohamed Fawzy, Mohammad Shoeybi, Mostofa Patwary, Nayeon Lee, Nima Tajbakhsh, Ning Xu, Oleg Rybakov, Oleksii Kuchaiev, Olivier Delalleau, Osvald Nitski, Parth Chadha, Pasha Shamis, Paulius Micikevicius, Pavlo Molchanov, Peter Dykas, Philipp Fischer, Pierre-Yves Aquilanti, Piotr Bialecki, Prasoon Varshney, Pritam Gundecha, Przemek Tredak, Rabeeh Karimi, Rahul Kandu, Ran El-Yaniv, Raviraj Joshi, Roger Waleffe, Ruoxi Zhang, Sabrina Kavanaugh, Sahil Jain, Samuel Kriman, Sangkug Lym, Sanjeev Satheesh, Saurav Muralidharan, Sean Narenthiran, Selvaraj Anandaraj, Seonmyeong Bak, Sergey Kashirsky, Seungju Han, Shantanu Acharya, Shaona Ghosh, Sharath Turuvekere Sreenivas, Sharon Clay, Shelby Thomas, Shrimai Prabhumoye, Shubham Pachori, Shubham Toshniwal, Shyamala Prayaga, Siddhartha Jain, Sirshak Das, Slawek Kierat, Somshubra Majumdar, Song Han, Soumye Singhal, Sriharsha Niverty, Stefania Alborghetti, Suseella Panguluri, Swetha Bhendigeri, Syeda Nahida Akter, Szymon Migacz, Tal Shiri, Terry Kong, Timo Roman, Tomer Ronen, Trisha Saar, Tugrul Konuk, Tuomas Rintamaki, Tyler Poon, Ushnish De, Vahid Noroozi, Varun Singh, Vijay Korthikanti, Vitaly Kurin, Wasi Uddin Ahmad, Wei Du, Wei Ping, Wenliang Dai, Wonmin Byeon, Xiaowei Ren, Yao Xu, Yejin Choi, Yian Zhang, Ying Lin, Yoshi Suhara, Zhiding Yu, Zhiqi Li, Zhiyu Li, Zhongbo Zhu, Zhuolin Yang, Zijia Chen  
**Category**: cs.AI  
**Published**: 2025-09-09  
**Score**: 4.0

arXiv:2504.03624v4 Announce Type: replace-cross 
Abstract: As inference-time scaling becomes critical for enhanced reasoning capabilities, it is increasingly becoming important to build models that are efficient to infer. We introduce Nemotron-H, a family of 8B and 56B/47B hybrid Mamba-Transformer m...

---

### 24. [Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models](https://arxiv.org/abs/2509.06949)

**Authors**: Yinjie Wang, Ling Yang, Bowen Li, Ye Tian, Ke Shen, Mengdi Wang  
**Category**: cs.CL  
**Published**: 2025-09-09  
**Score**: 4.0

arXiv:2509.06949v1 Announce Type: new 
Abstract: We propose TraceRL, a trajectory-aware reinforcement learning framework for diffusion language models (DLMs) that incorporates preferred inference trajectory into post-training, and is applicable across different architectures. Equipped with a diffusi...

---

### 25. [Repetition Improves Language Model Embeddings](https://arxiv.org/abs/2402.15449)

**Authors**: Jacob Mitchell Springer, Suhas Kotha, Daniel Fried, Graham Neubig, Aditi Raghunathan  
**Category**: cs.CL  
**Published**: 2025-09-09  
**Score**: 4.0

arXiv:2402.15449v2 Announce Type: replace 
Abstract: Bidirectional models are considered essential for strong text embeddings. Recent approaches to adapt autoregressive language models (LMs) into strong text embedding models have largely had the requirement to modify the LM architecture to be bidire...

---

### 26. [Fast Quiet-STaR: Thinking Without Thought Tokens](https://arxiv.org/abs/2505.17746)

**Authors**: Wei Huang, Yizhe Xiong, Xin Ye, Zhijie Deng, Hui Chen, Zijia Lin, Guiguang Ding  
**Category**: cs.CL  
**Published**: 2025-09-09  
**Score**: 4.0

arXiv:2505.17746v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have achieved impressive performance across a range of natural language processing tasks. However, recent advances demonstrate that further gains particularly in complex reasoning tasks require more than merely scaling...

---

### 27. [Step-level Verifier-guided Hybrid Test-Time Scaling for Large Language Models](https://arxiv.org/abs/2507.15512)

**Authors**: Kaiyan Chang, Yonghao Shi, Chenglong Wang, Hang Zhou, Chi Hu, Xiaoqian Liu, Yingfeng Luo, Yuan Ge, Tong Xiao, Jingbo Zhu  
**Category**: cs.CL  
**Published**: 2025-09-09  
**Score**: 4.0

arXiv:2507.15512v2 Announce Type: replace 
Abstract: Test-Time Scaling (TTS) is a promising approach to progressively elicit the model's intelligence during inference. Recently, training-based TTS methods, such as continued reinforcement learning (RL), have further surged in popularity, while traini...

---

### 28. [Efficient Large Language Models with Zero-Shot Adjustable Acceleration](https://arxiv.org/abs/2509.01190)

**Authors**: Sajjad Kachuee, Mohammad Sharifkhani  
**Category**: cs.CL  
**Published**: 2025-09-09  
**Score**: 4.0

arXiv:2509.01190v2 Announce Type: replace 
Abstract: Using Large Language Models (LLMs) in real-world applications presents significant challenges, particularly in balancing computational efficiency with model performance. Optimizing acceleration after fine-tuning and during inference is critical fo...

---

### 29. [Self-Aligned Reward: Towards Effective and Efficient Reasoners](https://arxiv.org/abs/2509.05489)

**Authors**: Peixuan Han, Adit Krishnan, Gerald Friedland, Jiaxuan You, Chris Kong  
**Category**: cs.LG  
**Published**: 2025-09-09  
**Score**: 4.0

arXiv:2509.05489v1 Announce Type: new 
Abstract: Reinforcement learning with verifiable rewards has significantly advanced reasoning in large language models (LLMs), but such signals remain coarse, offering only binary correctness feedback. This limitation often results in inefficiencies, including ...

---

### 30. [Smoothed Online Optimization for Target Tracking: Robust and Learning-Augmented Algorithms](https://arxiv.org/abs/2509.05930)

**Authors**: Ali Zeynali, Mahsa Sahebdel, Qingsong Liu, Mohammad Hajiesmaili, Ramesh K. Sitaraman  
**Category**: cs.LG  
**Published**: 2025-09-09  
**Score**: 4.0

arXiv:2509.05930v1 Announce Type: new 
Abstract: We introduce the Smoothed Online Optimization for Target Tracking (SOOTT) problem, a new framework that integrates three key objectives in online decision-making under uncertainty: (1) tracking cost for following a dynamically moving target, (2) adver...

---

## 🔧 Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative Decoding

## 📅 Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## 🚀 How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## 📝 Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## 🔍 Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
