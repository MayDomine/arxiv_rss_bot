# arXiv Papers Bot ü§ñ

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## üìä Statistics

- **Last Updated**: 2025-10-07 12:52:43 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## üìö Recent Papers

### 1. [Speculative Actions: A Lossless Framework for Faster Agentic Systems](https://arxiv.org/abs/2510.04371)

**Authors**: Naimeng Ye, Arnav Ahuja, Georgios Liargkovas, Yunan Lu, Kostis Kaffes, Tianyi Peng  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 11.5

arXiv:2510.04371v1 Announce Type: new 
Abstract: Despite growing interest in AI agents across industry and academia, their execution in an environment is often slow, hampering training, evaluation, and deployment. For example, a game of chess between two state-of-the-art agents may take hours. A cri...

---

### 2. [UniPruning: Unifying Local Metric and Global Feedback for Scalable Sparse LLMs](https://arxiv.org/abs/2510.03291)

**Authors**: Yizhuo Ding, Wanying Qu, Jiawei Geng, Wenqi Shao, Yanwei Fu  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 11.5

arXiv:2510.03291v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) achieve strong performance across diverse tasks but face prohibitive computational and memory costs. Pruning offers a promising path by inducing sparsity while preserving architectural flexibility. However, existing meth...

---

### 3. [PT$^2$-LLM: Post-Training Ternarization for Large Language Models](https://arxiv.org/abs/2510.03267)

**Authors**: Xianglong Yan, Chengzhu Bao, Zhiteng Li, Tianao Zhang, Kaicheng Yang, Haotong Qin, Ruobing Xie, Xingwu Sun, Yulun Zhang  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 11.0

arXiv:2510.03267v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have shown impressive capabilities across diverse tasks, but their large memory and compute demands hinder deployment. Ternarization has gained attention as a promising compression technique, delivering substantial size ...

---

### 4. [ElasWave: An Elastic-Native System for Scalable Hybrid-Parallel Training](https://arxiv.org/abs/2510.00606)

**Authors**: Xueze Kang, Guangyu Xiang, Yuxin Wang, Hao Zhang, Yuchu Fang, Yuhang Zhou, Zhenheng Tang, Youhui Lv, Eliran Maman, Mark Wasserman, Alon Zameret, Zhipeng Bian, Shushu Chen, Zhiyou Yu, Jin Wang, Xiaoyu Wu, Yang Zheng, Chen Tian, Xiaowen Chu  
**Category**: cs.DC  
**Published**: 2025-10-07  
**Score**: 10.5

arXiv:2510.00606v2 Announce Type: replace 
Abstract: Large-scale LLM pretraining now runs across $10^5$--$10^6$ accelerators, making failures routine and elasticity mandatory. We posit that an elastic-native training system must jointly deliver (i) parameter consistency, (ii) low mean time to recove...

---

### 5. [Compressed Convolutional Attention: Efficient Attention in a Compressed Latent Space](https://arxiv.org/abs/2510.04476)

**Authors**: Tomas Figliolia, Nicholas Alonso, Rishi Iyer, Quentin Anthony, Beren Millidge  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 10.0

arXiv:2510.04476v1 Announce Type: cross 
Abstract: Multi-headed Attention's (MHA) quadratic compute and linearly growing KV-cache make long-context transformers expensive to train and serve. Prior works such as Grouped Query Attention (GQA) and Multi-Latent Attention (MLA) shrink the cache, speeding...

---

### 6. [ZSMerge: Zero-Shot KV Cache Compression for Memory-Efficient Long-Context LLMs](https://arxiv.org/abs/2503.10714)

**Authors**: Xin Liu, Xudong Wang, Pei Liu, Guoming Tang  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 10.0

arXiv:2503.10714v3 Announce Type: replace-cross 
Abstract: The linear growth of key-value (KV) cache memory and quadratic computational in attention mechanisms complexity pose significant bottlenecks for large language models (LLMs) in long-context processing. While existing KV cache optimization me...

---

### 7. [MoESD: Unveil Speculative Decoding's Potential for Accelerating Sparse MoE](https://arxiv.org/abs/2505.19645)

**Authors**: Zongle Huang, Lei Zhu, Zongyuan Zhan, Ting Hu, Weikai Mao, Xianzhi Yu, Yongpan Liu, Tianyu Zhang  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 10.0

arXiv:2505.19645v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have achieved remarkable success across many applications, with Mixture of Experts (MoE) models demonstrating great potential. Compared to traditional dense models, MoEs achieve better performance with less compu...

---

### 8. [KVComm: Enabling Efficient LLM Communication through Selective KV Sharing](https://arxiv.org/abs/2510.03346)

**Authors**: Xiangyu Shi, Marco Chiesa, Gerald Q. Maguire Jr., Dejan Kostic  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 9.5

arXiv:2510.03346v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) are increasingly deployed in multi-agent systems, where effective inter-model communication is crucial. Existing communication protocols either rely on natural language, incurring high inference costs and information los...

---

### 9. [ReTiDe: Real-Time Denoising for Energy-Efficient Motion Picture Processing with FPGAs](https://arxiv.org/abs/2510.03812)

**Authors**: Changhong Li, Cl\'ement Bled, Rosa Fernandez, Shreejith Shanker  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 9.5

arXiv:2510.03812v1 Announce Type: cross 
Abstract: Denoising is a core operation in modern video pipelines. In codecs, in-loop filters suppress sensor noise and quantisation artefacts to improve rate-distortion performance; in cinema post-production, denoisers are used for restoration, grain managem...

---

### 10. [Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning](https://arxiv.org/abs/2510.04072)

**Authors**: Ziyan Wang, Zheng Wang, Jie Fu, Xingwei Qu, Qi Cheng, Shengpu Tang, Minjia Zhang, Xiaoming Huo  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 9.5

arXiv:2510.04072v1 Announce Type: cross 
Abstract: Reinforcement learning (RL) has become central to enhancing reasoning in large language models (LLMs). Yet on-policy algorithms such as Group Relative Policy Optimization (GRPO) often suffer in early training: noisy gradients from low-quality rollou...

---

### 11. [LUMION: Fast Fault Recovery for ML Jobs Using Programmable Optical Fabrics](https://arxiv.org/abs/2505.23105)

**Authors**: Abhishek Vijaya Kumar, Eric Ding, Arjun Devraj, Darius Bunandar, Rachee Singh  
**Category**: cs.LG  
**Published**: 2025-10-07  
**Score**: 9.5

arXiv:2505.23105v2 Announce Type: replace 
Abstract: When accelerators fail in modern ML datacenters, operators migrate the affected ML training or inference jobs to entirely new racks. This approach, while preserving network performance, is highly inefficient, requiring datacenters to reserve full ...

---

### 12. [Taming Latency-Memory Trade-Off in MoE-Based LLM Serving via Fine-Grained Expert Offloading](https://arxiv.org/abs/2502.05370)

**Authors**: Hanfei Yu, Xingqi Cui, Hong Zhang, Hao Wang, Hao Wang  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 9.0

arXiv:2502.05370v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have gained immense success in revolutionizing various applications, including content generation, search and recommendation, and AI-assisted operation. To reduce high training costs, Mixture-of-Experts (MoE) arc...

---

### 13. [Fed-SB: A Silver Bullet for Extreme Communication Efficiency and Performance in (Private) Federated LoRA Fine-Tuning](https://arxiv.org/abs/2502.15436)

**Authors**: Raghav Singhal, Kaustubh Ponkshe, Rohit Vartak, Lav R. Varshney, Praneeth Vepakomma  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 9.0

arXiv:2502.15436v2 Announce Type: replace-cross 
Abstract: Low-Rank Adaptation (LoRA) has become ubiquitous for efficiently fine-tuning foundation models. However, federated fine-tuning using LoRA is challenging due to suboptimal updates arising from traditional federated averaging of individual ada...

---

### 14. [Solar Photovoltaic Assessment with Large Language Model](https://arxiv.org/abs/2507.19144)

**Authors**: Muhao Guo, Yang Weng  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 9.0

arXiv:2507.19144v2 Announce Type: replace-cross 
Abstract: Accurate detection and localization of solar photovoltaic (PV) panels in satellite imagery is essential for optimizing microgrids and active distribution networks (ADNs), which are critical components of renewable energy systems. Existing me...

---

### 15. [FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient Federated Large Language Models Fine-Tuning](https://arxiv.org/abs/2510.04601)

**Authors**: Guochen Yan, Luyuan Xie, Qingni Shen, Yuejian Fang, Zhonghai Wu  
**Category**: cs.CL  
**Published**: 2025-10-07  
**Score**: 9.0

arXiv:2510.04601v1 Announce Type: new 
Abstract: The current paradigm of training large language models (LLMs) on publicly available Web data is becoming unsustainable, with high-quality data sources in specialized domains nearing exhaustion. Federated Learning (FL) emerges as a practical solution f...

---

### 16. [Certifiable Safe RLHF: Fixed-Penalty Constraint Optimization for Safer Language Models](https://arxiv.org/abs/2510.03520)

**Authors**: Kartik Pandit, Sourav Ganguly, Arnesh Banerjee, Shaahin Angizi, Arnob Ghosh  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 8.5

arXiv:2510.03520v1 Announce Type: cross 
Abstract: Ensuring safety is a foundational requirement for large language models (LLMs). Achieving an appropriate balance between enhancing the utility of model outputs and mitigating their potential for harm is a complex and persistent challenge. Contempora...

---

### 17. [EvoEngineer: Mastering Automated CUDA Kernel Code Evolution with Large Language Models](https://arxiv.org/abs/2510.03760)

**Authors**: Ping Guo, Chenyu Zhu, Siyuan Chen, Fei Liu, Xi Lin, Zhichao Lu, Qingfu Zhang  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 8.5

arXiv:2510.03760v1 Announce Type: cross 
Abstract: CUDA kernel optimization has become a critical bottleneck for AI performance, as deep learning training and inference efficiency directly depends on highly optimized GPU kernels.
  Despite the promise of Large Language Models (LLMs) for automating k...

---

### 18. [SliceMoE: Routing Embedding Slices Instead of Tokens for Fine-Grained and Balanced Transformer Scaling](https://arxiv.org/abs/2510.04286)

**Authors**: Harshil Vejendla  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 8.5

arXiv:2510.04286v1 Announce Type: cross 
Abstract: Mixture-of-Experts (MoE) layers scale transformers by routing tokens to a sparse subset of feed-forward experts. Token-level routing, however, assigns an entire semantic spectrum to each expert, creating capacity bottlenecks, load-balancing patholog...

---

### 19. [Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training](https://arxiv.org/abs/2510.04996)

**Authors**: Wei Xiong, Chenlu Ye, Baohao Liao, Hanze Dong, Xinxing Xu, Christof Monz, Jiang Bian, Nan Jiang, Tong Zhang  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 8.5

arXiv:2510.04996v1 Announce Type: cross 
Abstract: Reinforcement learning applied to large language models (LLMs) for reasoning tasks is often bottlenecked by unstable gradient estimates due to fixed and uniform sampling of responses across prompts. Prior work such as GVM-RAFT addresses this by dyna...

---

### 20. [Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution](https://arxiv.org/abs/2504.05424)

**Authors**: Raffi Khatchadourian, Tatiana Castro V\'elez, Mehdi Bagherzadeh, Nan Jia, Anita Raja  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 8.5

arXiv:2504.05424v4 Announce Type: replace-cross 
Abstract: Efficiency is essential to support ever-growing datasets, especially for Deep Learning (DL) systems. DL frameworks have traditionally embraced deferred execution-style DL code -- supporting symbolic, graph-based Deep Neural Network (DNN) com...

---

### 21. [AgentRL: Scaling Agentic Reinforcement Learning with a Multi-Turn, Multi-Task Framework](https://arxiv.org/abs/2510.04206)

**Authors**: Hanchen Zhang, Xiao Liu, Bowen Lv, Xueqiao Sun, Bohao Jing, Iat Long Iong, Zhenyu Hou, Zehan Qi, Hanyu Lai, Yifan Xu, Rui Lu, Hongning Wang, Jie Tang, Yuxiao Dong  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 8.0

arXiv:2510.04206v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have sparked growing interest in building generalist agents that can learn through online interactions. However, applying reinforcement learning (RL) to train LLM agents in multi-turn, multi-task setting...

---

### 22. [MACE: A Hybrid LLM Serving System with Colocated SLO-aware Continuous Retraining Alignment](https://arxiv.org/abs/2510.03283)

**Authors**: Yufei Li, Yu Fu, Yue Dong, Cong Liu  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 8.0

arXiv:2510.03283v1 Announce Type: cross 
Abstract: Large language models (LLMs) deployed on edge servers are increasingly used in latency-sensitive applications such as personalized assistants, recommendation, and content moderation. However, the non-stationary nature of user data necessitates frequ...

---

### 23. [Agile Tradespace Exploration for Space Rendezvous Mission Design via Transformers](https://arxiv.org/abs/2510.03544)

**Authors**: Yuji Takubo, Daniele Gammelli, Marco Pavone, Simone D'Amico  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 8.0

arXiv:2510.03544v1 Announce Type: cross 
Abstract: Spacecraft rendezvous enables on-orbit servicing, debris removal, and crewed docking, forming the foundation for a scalable space economy. Designing such missions requires rapid exploration of the tradespace between control cost and flight time acro...

---

### 24. [CHARME: A chain-based reinforcement learning approach for the minor embedding problem](https://arxiv.org/abs/2406.07124)

**Authors**: Hoang M. Ngo, Nguyen H K. Do, Minh N. Vu, Tre' R. Jeter, Tamer Kahveci, My T. Thai  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 8.0

arXiv:2406.07124v2 Announce Type: replace 
Abstract: Quantum annealing (QA) has great potential to solve combinatorial optimization problems efficiently. However, the effectiveness of QA algorithms is heavily based on the embedding of problem instances, represented as logical graphs, into the quantu...

---

### 25. [PoLi-RL: A Point-to-List Reinforcement Learning Framework for Conditional Semantic Textual Similarity](https://arxiv.org/abs/2510.04080)

**Authors**: Zixin Song, Bowen Zhang, Qian-Wen Zhang, Di Yin, Xing Sun, Chunping Li  
**Category**: cs.CL  
**Published**: 2025-10-07  
**Score**: 8.0

arXiv:2510.04080v1 Announce Type: new 
Abstract: Conditional Semantic Textual Similarity (C-STS) measures the semantic proximity between text segments under a specific condition, thereby overcoming the ambiguity inherent in traditional STS. However, existing methods are largely confined to discrimin...

---

### 26. [SAFA-SNN: Sparsity-Aware On-Device Few-Shot Class-Incremental Learning with Fast-Adaptive Structure of Spiking Neural Network](https://arxiv.org/abs/2510.03648)

**Authors**: Huijing Zhang, Muyang Cao, Linshan Jiang, Xin Du, Di Yu, Changze Lv, Shuiguang Deng  
**Category**: cs.LG  
**Published**: 2025-10-07  
**Score**: 8.0

arXiv:2510.03648v1 Announce Type: new 
Abstract: Continuous learning of novel classes is crucial for edge devices to preserve data privacy and maintain reliable performance in dynamic environments. However, the scenario becomes particularly challenging when data samples are insufficient, requiring o...

---

### 27. [A Unified Optimization Framework for Multiclass Classification with Structured Hyperplane Arrangements](https://arxiv.org/abs/2510.05047)

**Authors**: V\'ictor Blanco, Harshit Kothari, James Luedtke  
**Category**: cs.LG  
**Published**: 2025-10-07  
**Score**: 8.0

arXiv:2510.05047v1 Announce Type: cross 
Abstract: In this paper, we propose a new mathematical optimization model for multiclass classification based on arrangements of hyperplanes. Our approach preserves the core support vector machine (SVM) paradigm of maximizing class separation while minimizing...

---

### 28. [Rethinking Probabilistic Circuit Parameter Learning](https://arxiv.org/abs/2505.19982)

**Authors**: Anji Liu, Zilei Shao, Guy Van den Broeck  
**Category**: cs.LG  
**Published**: 2025-10-07  
**Score**: 8.0

arXiv:2505.19982v2 Announce Type: replace 
Abstract: Probabilistic Circuits (PCs) offer a computationally scalable framework for generative modeling, supporting exact and efficient inference of a wide range of probabilistic queries. While recent advances have significantly improved the expressivenes...

---

### 29. [Principled and Tractable RL for Reasoning with Diffusion Language Models](https://arxiv.org/abs/2510.04019)

**Authors**: Anthony Zhan  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 7.5

arXiv:2510.04019v1 Announce Type: cross 
Abstract: Diffusion large language models (dLLMs) are a new paradigm of non-autoregressive language models that are trained to predict multiple tokens in parallel and generate text via iterative unmasking. Recent works have successfully pretrained dLLMs to pa...

---

### 30. [LaDiR: Latent Diffusion Enhances LLMs for Text Reasoning](https://arxiv.org/abs/2510.04573)

**Authors**: Haoqiang Kang, Yizhe Zhang, Nikki Lijing Kuang, Nicklas Majamaki, Navdeep Jaitly, Yi-An Ma, Lianhui Qin  
**Category**: cs.AI  
**Published**: 2025-10-07  
**Score**: 7.5

arXiv:2510.04573v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) demonstrate their reasoning ability through chain-of-thought (CoT) generation. However, LLM's autoregressive decoding may limit the ability to revisit and refine earlier tokens in a holistic manner, which can also lead t...

---

## üîß Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## üìÖ Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## üöÄ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## üìù Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## üîç Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
