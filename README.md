# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-18 05:57:22 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Multiscale Aggregated Hierarchical Attention (MAHA): A Game Theoretic and Optimization Driven Approach to Efficient Contextual Modeling in Large Language Models](https://arxiv.org/abs/2512.14925)

**Authors**: Caner Erden  
**Category**: cs.CL  
**Published**: 2025-12-18  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.14925v1  

#### Abstract
The quadratic computational complexity of MultiHead SelfAttention (MHSA) remains a fundamental bottleneck in scaling Large Language Models (LLMs) for longcontext tasks. While sparse and linearized attention mechanisms attempt to mitigate this, they often compromise the representation of global depen...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMultiscale Aggregated Hierarchical Attention (MAHA)

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
- **Multi-Head Self-Attention (MHSA)** å­˜åœ¨ **O(nÂ²)** çš„è®¡ç®—å¤æ‚åº¦ï¼Œé™åˆ¶äº† Large Language Models (LLMs) åœ¨é•¿åºåˆ—ä»»åŠ¡ä¸­çš„æ‰©å±•èƒ½åŠ›ã€‚
- ç°æœ‰ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼ˆå¦‚ Longformerã€BigBirdï¼‰è™½ç„¶é™ä½äº†è®¡ç®—å¼€é”€ï¼Œä½†å¾€å¾€ç‰ºç‰²äº†å¯¹å…¨å±€ä¾èµ–å…³ç³»çš„å»ºæ¨¡èƒ½åŠ›ã€‚
- å±‚æ¬¡åŒ–æ³¨æ„åŠ›æ–¹æ³•ç¼ºä¹ç†è®ºä¸¥è°¨çš„èšåˆæœºåˆ¶ï¼Œé€šå¸¸é‡‡ç”¨å¯å‘å¼åŠ æƒå¹³å‡ï¼Œå¯¼è‡´ä¿¡æ¯ç¨€é‡Šã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
**MAHA (Multiscale Aggregated Hierarchical Attention)** æ˜¯ä¸€ç§å…¨æ–°çš„æ³¨æ„åŠ›æ¶æ„ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **å¤šå°ºåº¦åˆ†å±‚åˆ†è§£ï¼ˆMultiscale Decompositionï¼‰**  
  å°†è¾“å…¥åºåˆ—é€šè¿‡å¯å­¦ä¹ çš„ä¸‹é‡‡æ ·æ“ä½œï¼ˆå¦‚ Strided Convolution æˆ– Adaptive Poolingï¼‰åŠ¨æ€åˆ’åˆ†ä¸ºå¤šä¸ªå±‚çº§ï¼ˆscalesï¼‰ï¼Œæ¯ä¸ªå±‚çº§å¯¹åº”ä¸åŒçš„è¯­ä¹‰æŠ½è±¡ç²’åº¦ï¼ˆä»å±€éƒ¨è¯­æ³•åˆ°å…¨å±€ä¸»é¢˜ï¼‰ã€‚

- **ä¼˜åŒ–é©±åŠ¨çš„èšåˆæœºåˆ¶ï¼ˆOptimization-Driven Aggregationï¼‰**  
  å¼•å…¥ä¸¤ç§æ•°å­¦ä¸Šä¸¥æ ¼çš„èšåˆç­–ç•¥ï¼š
  - **å‡¸ä¼˜åŒ–ï¼ˆConvex Optimization, COï¼‰**ï¼šå°†å¤šå°ºåº¦æ³¨æ„åŠ›è¾“å‡ºçš„èåˆå»ºæ¨¡ä¸ºå¸¦çº¦æŸçš„æœ€ä¼˜åŒ–é—®é¢˜ï¼Œç›®æ ‡æ˜¯å¹³è¡¡æ•ˆç‡ä¸ä¸Šä¸‹æ–‡ä¿çœŸåº¦ã€‚
  - **åšå¼ˆè®ºå‡è¡¡ï¼ˆNash Equilibrium, NEï¼‰**ï¼šå°†ä¸åŒå°ºåº¦è§†ä¸ºâ€œç©å®¶â€ï¼Œé€šè¿‡éåˆä½œåšå¼ˆå¯»æ‰¾çº³ä»€å‡è¡¡ï¼Œç¡®ä¿æ²¡æœ‰å•ä¸€å°ºåº¦èƒ½é€šè¿‡å•æ–¹é¢æ”¹å˜æƒé‡æ¥æå‡æ•´ä½“è¡¨ç¤ºè´¨é‡ã€‚

- **å…±äº«å€¼æŠ•å½±ä¸æ··åˆéª¨å¹²è®¾è®¡**  
  - æŸ¥è¯¢ï¼ˆQueryï¼‰å’Œé”®ï¼ˆKeyï¼‰æŠ•å½±æ˜¯å°ºåº¦ç‰¹å®šçš„ï¼Œè€Œå€¼ï¼ˆValueï¼‰æŠ•å½±è·¨å°ºåº¦å…±äº«ï¼Œæ˜¾è‘—å‡å°‘å‚æ•°é‡ã€‚
  - ç»“åˆ **dilated convolution** æ•æ‰å±€éƒ¨ä¸Šä¸‹æ–‡ï¼Œå¹¶ä½¿ç”¨è·¨å°ºåº¦é—¨æ§ï¼ˆCross-Scale Gatingï¼‰å¢å¼ºä¿¡æ¯æµåŠ¨ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | MAHAä¼˜åŠ¿ |
|------|---------|
| **è®¡ç®—æ•ˆç‡** | å®ç°è¿‘çº¿æ€§å¤æ‚åº¦ **O(n)**ï¼Œè¿œä¼˜äºæ ‡å‡† MHSA çš„ **O(nÂ²)** |
| **ä¸Šä¸‹æ–‡å»ºæ¨¡** | èƒ½åŒæ—¶æ•æ‰ç»†ç²’åº¦å±€éƒ¨æ¨¡å¼å’Œç²—ç²’åº¦å…¨å±€ä¾èµ–ï¼Œé¿å…ä¿¡æ¯ä¸¢å¤± |
| **ç†è®ºåŸºç¡€** | èšåˆè¿‡ç¨‹åŸºäºå‡¸ä¼˜åŒ–æˆ–åšå¼ˆè®ºï¼Œå…·æœ‰æ•°å­¦æœ€ä¼˜æ€§ä¿è¯ï¼Œè€Œéå¯å‘å¼èåˆ |
| **å…¼å®¹æ€§** | å¯ä½œä¸ºå³æ’å³ç”¨æ¨¡å—æ›¿æ¢ Transformer ä¸­çš„æ ‡å‡†æ³¨æ„åŠ›å±‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å¤šç§ NLP ä»»åŠ¡ä»¥éªŒè¯é€šç”¨æ€§å’Œé•¿ä¸Šä¸‹æ–‡èƒ½åŠ›ï¼š
- **æ–‡æœ¬åˆ†ç±»**ï¼šGLUE åŸºå‡†ï¼ˆMNLI, SST-2ï¼‰
- **é•¿è·ç¦»ä¾èµ–å»ºæ¨¡**ï¼šPG-19 æ•°æ®é›†ï¼ˆå¹³å‡ >4k tokensï¼‰
- **æœºå™¨ç¿»è¯‘**ï¼šWMT14 è‹±å¾·ç¿»è¯‘ï¼ˆEnglish-Germanï¼‰
- **é—®ç­”ç³»ç»Ÿ**ï¼šSQuAD v2.0

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼š12å±‚ Transformerï¼Œéšè—ç»´åº¦ 768ï¼Œ12ä¸ª attention heads
- **è®­ç»ƒé…ç½®**ï¼š
  - Batch Sizeï¼š32ï¼ˆåˆ†ç±»ï¼‰ï¼Œ16ï¼ˆç¿»è¯‘/é—®ç­”ï¼‰
  - å­¦ä¹ ç‡ï¼š5e-5ï¼Œwarmup 10k æ­¥
  - åºåˆ—é•¿åº¦ï¼š512ï¼ˆå¸¸è§„ä»»åŠ¡ï¼‰ï¼Œ4096ï¼ˆPG-19ï¼‰
- **MAHA å‚æ•°**ï¼š
  - åˆ†å±‚æ•° $ L = 4 $ï¼ˆtoken æ•°åˆ†åˆ«ä¸º 32, 64, 128, 256ï¼‰
  - ä¸‹é‡‡æ ·æ–¹å¼ï¼šæ­¥å¹…å·ç§¯ï¼ˆkernel=3ï¼‰
  - èšåˆæ­£åˆ™åŒ–ç³»æ•° $ \lambda = 0.1 $

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- Standard MHA (Vaswani et al., 2017)
- Longformer (Beltagy et al., 2020)
- BigBird (Zaheer et al., 2020)
- Reformer (Kitaev et al., 2020)
- Performer (Choromanski et al., 2020)

### è¯„ä¼°æŒ‡æ ‡
- å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ã€BLEUã€F1ã€Perplexity (PPL)â†“
- å†…å­˜å ç”¨ï¼ˆMemory, GBï¼‰â†“
- ååé‡ï¼ˆThroughput, seq/sï¼‰â†‘
- FLOPsï¼ˆæµ®ç‚¹è¿ç®—æ•°ï¼‰åˆ†æ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰
| æ¨¡å‹ | MNLI (Acc) | SST-2 (Acc) | PG-19 (PPL)â†“ | WMT (BLEU) | SQuAD (F1) | Memory (GB)â†“ | Throughput (seq/s)â†‘ |
|------|------------|-------------|--------------|------------|------------|---------------|------------------------|
| Standard MHA | 86.2 | 93.5 | 24.3 | 28.7 | 88.4 | 15.2 | 42 |
| Longformer | 85.7 | 92.8 | 23.8 | 27.9 | 87.6 | 9.1 | 58 |
| BigBird | 85.9 | 93.1 | 23.5 | 28.1 | 87.9 | 10.3 | 53 |
| Reformer | 84.3 | 91.7 | 25.6 | 26.4 | 85.2 | 7.8 | 62 |
| Performer | 85.1 | 92.4 | 24.9 | 27.3 | 86.7 | 8.5 | 67 |
| **MAHA** | **86.0** | **93.3** | **23.1** | **28.5** | **88.2** | **2.5** | **20.5*** |

> *æ³¨ï¼šMAHA çš„ååé‡è¾ƒä½æ˜¯ç”±äºåŸå‹å®ç°æœªå……åˆ†ä¼˜åŒ–ï¼›ç†è®ºå¤æ‚åº¦ä»ä¸ºçº¿æ€§*

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ€§èƒ½ä¿æŒ**ï¼šåœ¨å¤šæ•°ä»»åŠ¡ä¸Šä¸ Standard MHA æ€§èƒ½ç›¸å½“ï¼ˆå·®è· < 0.2%ï¼‰ï¼Œä¸”åœ¨ **PG-19 ä¸Šå–å¾—æœ€ä½ PPL (23.1)**ï¼Œè¡¨æ˜å…¶æ›´å¼ºçš„é•¿ç¨‹å»ºæ¨¡èƒ½åŠ›ã€‚
- **å†…å­˜å¤§å¹…é™ä½**ï¼šç›¸æ¯” Standard MHAï¼Œå†…å­˜å ç”¨å‡å°‘ **83.6%**ï¼ˆ15.2 â†’ 2.5 GBï¼‰ã€‚
- **è®¡ç®—æ•ˆç‡æ˜¾è‘—æå‡**ï¼š
  - åœ¨åºåˆ—é•¿åº¦ **N=4096** æ—¶ï¼š
    - Standard MHAï¼šçº¦ **16.8M FLOPs**
    - MAHAï¼šä»… **3.2M FLOPs**
    - **FLOPs å‡å°‘ 81%**
  - éšç€åºåˆ—å¢é•¿ï¼Œæ•ˆç‡ä¼˜åŠ¿å‘ˆæŒ‡æ•°çº§æ‰©å¤§ï¼ˆè§ Figure 3ï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœ

#### èšåˆç­–ç•¥æ¯”è¾ƒï¼ˆTable 2ï¼‰
| æ–¹æ³• | MNLI (Acc) | Memory (GB) | è®­ç»ƒé€Ÿåº¦ |
|------|------------|-------------|----------|
| Convex Optimization (CO) | 86.0 | 6.7 | 1.0x |
| Nash Equilibrium (NE) | 85.8 | 6.9 | 0.9x |
| å¹³å‡èåˆï¼ˆBaselineï¼‰ | 85.2 | 7.2 | 1.1x |

- **CO ä¸ NE å‡ä¼˜äºç®€å•å¹³å‡**ï¼Œè¯´æ˜ä¼˜åŒ–é©±åŠ¨èšåˆæ›´æœ‰æ•ˆã€‚
- NE åœ¨åæœŸæ”¶æ•›æŸå¤±æ›´ä½ï¼ˆè§ Figure 4ï¼‰ï¼Œå¯èƒ½æ‰¾åˆ°æ›´é²æ£’çš„å°ºåº¦å¹³è¡¡ï¼Œä½†è®­ç»ƒç¨æ…¢ã€‚

#### åˆ†å±‚æ·±åº¦åˆ†æï¼ˆFigure 5ï¼‰
- æœ€ä¼˜æ€§èƒ½å‡ºç°åœ¨ **L=4** å±‚ã€‚
- **L=2**ï¼ˆå¤ªå°‘ï¼‰ï¼šç²¾åº¦ä¸‹é™è‡³ 84.5%ï¼Œå› ç»†èŠ‚ä¸è¶³ã€‚
- **L=6**ï¼ˆå¤ªå¤šï¼‰ï¼šæ€§èƒ½é™è‡³ 84.8%ï¼Œå› è¿‡åº¦ä¸‹é‡‡æ ·å¼•å…¥å™ªå£°ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **MAHA æˆåŠŸå°†æ³¨æ„åŠ›å¤æ‚åº¦ä» O(nÂ²) é™è‡³è¿‘çº¿æ€§ O(n)**ï¼Œè§£å†³äº† LLM æ‰©å±•ä¸­çš„æ ¹æœ¬ç“¶é¢ˆã€‚
2. é€šè¿‡ **å¤šå°ºåº¦åˆ†è§£ + ä¼˜åŒ–é©±åŠ¨èšåˆ**ï¼Œå®ç°äº†å±€éƒ¨ç²¾ç»†ä¸å…¨å±€ä¸Šä¸‹æ–‡çš„é«˜æ•ˆç»Ÿä¸€å»ºæ¨¡ã€‚
3. åœ¨é•¿æ–‡æœ¬ä»»åŠ¡ï¼ˆå¦‚ PG-19ï¼‰ä¸Šè¡¨ç°ä¼˜äºæ‰€æœ‰ç¨€ç–æ³¨æ„åŠ›åŸºçº¿ï¼Œè¯æ˜å…¶åœ¨çœŸå®åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚
4. **Nash Equilibrium èšåˆ** æä¾›æ›´å¼ºçš„ç†è®ºä¿éšœï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ä¼˜äºå‡¸ä¼˜åŒ–æ–¹æ¡ˆã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å¼•å…¥é¢å¤–è¶…å‚æ•°ï¼ˆå¦‚åˆ†å±‚æ•° $ L $ã€å‹ç¼©æ¯” $ r $ï¼‰ï¼Œéœ€é’ˆå¯¹é¢†åŸŸè°ƒä¼˜ã€‚
- Nash Equilibrium èšåˆæ¶‰åŠè¿­ä»£æ±‚è§£ï¼Œå¸¦æ¥ä¸€å®šè®­ç»ƒå¼€é”€ã€‚
- å‡è®¾è¯­è¨€ç»“æ„å…·æœ‰å¤©ç„¶å±‚æ¬¡æ€§ï¼Œå¯èƒ½éš¾ä»¥å¤„ç†é«˜åº¦éç»„åˆæˆ–åˆ†æ•£å¼•ç”¨çš„æ–‡æœ¬ï¼ˆå¦‚æŸäº›è¯—æ­Œæˆ–æ³•å¾‹æ–‡ä¹¦ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† MAHA æ¡†æ¶æ‰©å±•è‡³å…¶ä»–æ¨¡æ€ï¼ˆå¦‚ **Computer Vision** å’Œ **Speech Processing**ï¼‰ï¼Œåˆ©ç”¨å…¶å¤©ç„¶çš„å¤šå°ºåº¦ç‰¹æ€§ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„å¯å¾®ä¼˜åŒ–å±‚å®ç°ï¼Œè¿›ä¸€æ­¥é™ä½æ¨ç†å»¶è¿Ÿã€‚
- åº”ç”¨äº **Genomics**ï¼ˆåŸºå› åºåˆ—åˆ†æï¼‰ã€**Multimodal Learning**ï¼ˆè§†é¢‘-æ–‡æœ¬æ£€ç´¢ï¼‰ã€**Federated Learning** ç­‰èµ„æºå—é™æˆ–è·¨ç²’åº¦åœºæ™¯ã€‚
- æ”¹è¿›è§£é‡Šæ€§ï¼Œè§£å†³å› ä¼˜åŒ–æƒé‡äº¤äº’å¸¦æ¥çš„å†³ç­–è·¯å¾„ä¸é€æ˜é—®é¢˜ã€‚

> âœ… **ä»£ç ä¸æ¨¡å‹å·²å¼€æº**ï¼š[GitHub - MAHA Project](https://github.com/can-ererden/MAHA-Project)ï¼ŒDOI: `10.5281/zenodo.17936753`

</details>

---

### 2. [DEER: Draft with Diffusion, Verify with Autoregressive Models](https://arxiv.org/abs/2512.15176)

**Authors**: Zicong Cheng, Guo-Wei Yang, Jia Li, Zhijie Deng, Meng-Hao Guo, Shi-Min Hu  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.15176v1  

#### Abstract
Efficiency, as a critical practical challenge for LLM-driven agentic and reasoning systems, is increasingly constrained by the inherent latency of autoregressive (AR) decoding. Speculative decoding mitigates this cost through a draft-verify scheme, yet existing approaches rely on AR draft models (a....

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDEER: Draft with Diffusion, Verify with Autoregressive Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ç°æœ‰çš„ **speculative decoding** æ–¹æ³•ï¼ˆå¦‚ EAGLEã€Medusaï¼‰ä¾èµ–äº **autoregressive (AR) drafters** æ¥ç”Ÿæˆå€™é€‰åºåˆ—ï¼Œè¿™äº›æ–¹æ³•é¢ä¸´ä¸¤ä¸ªæ ¹æœ¬æ€§ç“¶é¢ˆï¼š

1. **é€æ­¥ä¸ç¡®å®šæ€§ç´¯ç§¯ï¼ˆstep-wise uncertainty accumulationï¼‰**ï¼šç”±äº AR drafter æ˜¯ä»å·¦åˆ°å³é€ä¸ªç”Ÿæˆ tokenï¼Œæ—©æœŸçš„å°è¯¯å·®ä¼šé€šè¿‡è‡ªå›å½’ä¾èµ–ä¸æ–­æ”¾å¤§ï¼Œå¯¼è‡´ä¸ç›®æ ‡æ¨¡å‹çš„ä¿¡ä»»å…³ç³»é€æ¸å´©æºƒï¼ˆgradual collapse of trustï¼‰ï¼Œä»è€Œé™åˆ¶äº†å¯æ¥å—çš„ draft é•¿åº¦ã€‚
2. **å›ºæœ‰çš„ä¸²è¡Œè§£ç é™åˆ¶**ï¼šAR drafters å¿…é¡»é¡ºåºç”Ÿæˆï¼Œæ— æ³•å¹¶è¡ŒåŒ–ï¼Œåˆ¶çº¦äº†è§£ç æ•ˆç‡ã€‚

è¿™ä¸¤ä¸ªå› ç´ å…±åŒå¯¼è‡´ç°æœ‰æ–¹æ³•çš„åŠ é€Ÿæ¯”æœ‰é™ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **DEER** â€”â€” ä¸€ç§å…¨æ–°çš„ speculative decoding æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **ç”¨ diffusion LLMï¼ˆdLLMï¼‰ä½œä¸º drafterï¼Œç”¨ AR æ¨¡å‹ä½œä¸º verifier**ï¼Œå®ç°â€œæ‰©æ•£å¼èµ·è‰ã€è‡ªå›å½’éªŒè¯â€ã€‚

#### åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

- **é¦–æ¬¡å®Œå…¨åŸºäºç¦»æ•£ç©ºé—´ dLLM çš„ speculative decoding æ¡†æ¶**ï¼šæ— éœ€è¾…åŠ© AR æ¨¡å‹æˆ–æ··åˆæ¶æ„ï¼Œä»…ä½¿ç”¨ä¸€ä¸ªè½»é‡çº§ dLLM ä½œä¸º drafterã€‚
- **æå‡º Diffusion-to-AR (D2A) å¯¹é½è®­ç»ƒæµç¨‹**ï¼š
  - **Stage I: AR-Style Continuation Distillation**  
    å°†é¢„è®­ç»ƒçš„ dLLM å¾®è°ƒä¸ºèƒ½è¿›è¡Œå‰ç¼€æ¡ä»¶ç»­å†™çš„æ¨¡å¼ï¼Œé€šè¿‡åœ¨æ•™å¸ˆè¾“å‡ºåæ·»åŠ  `[SEP]` æ ‡è®°æ¥æ¨¡æ‹Ÿæˆªæ–­ä¸Šä¸‹æ–‡ã€‚
  - **Stage II: Scribe Refinement**  
    å¼•å…¥æŒ‡æ•°åŠ æƒçš„åç¼€æ©ç ç­–ç•¥ï¼Œå¼ºåŒ–é è¿‘å‰ç¼€è¾¹ç•Œçš„ token å‡†ç¡®æ€§ï¼Œæå‡å±€éƒ¨ä¸€è‡´æ€§ã€‚
- **æ­ç¤ºäº†ä¸€ç§æ–°å…´èƒ½åŠ›ï¼šå¯é å—å†ç”Ÿï¼ˆreliable block regenerationï¼‰**  
  dLLM èƒ½å¤Ÿåå¤æ¥å—éƒ¨åˆ†æ©ç çš„åç¼€å¹¶è¿è´¯åœ°é‡å»ºï¼Œæ”¯æŒçœŸæ­£çš„å—çº§ç”Ÿæˆã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | DEER | ä¼ ç»Ÿ AR-based draftersï¼ˆå¦‚ EAGLE-3ï¼‰ |
|------|------|-----------------------------|
| **drafting å¹¶è¡Œæ€§** | âœ… å•æ­¥ç”Ÿæˆæ•´ä¸ª block | âŒ ä¸²è¡Œç”Ÿæˆï¼Œæ— æ³•å¹¶è¡Œ |
| **è¯¯å·®ä¼ æ’­** | âŒ æ— å·¦åˆ°å³ä¾èµ–ï¼Œä¸ç´¯ç§¯è¯¯å·® | âœ… ä¸¥é‡ç´¯ç§¯ |
| **æœ€å¤§æ¥å—é•¿åº¦** | é«˜è¾¾ 32 tokens | é€šå¸¸ â‰¤ 8â€“10 tokens |
| **é€Ÿåº¦æå‡** | æœ€é«˜ 5.54Ã— | æœ€é«˜çº¦ 2.41Ã— |
| **è®­ç»ƒæˆæœ¬** | æ›´ä½ï¼ˆè§ Table 8ï¼‰ | æ›´é«˜ï¼Œä¸”å¤§æ¨¡å‹æ˜“ OOM |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

#### **ä»£ç ç”Ÿæˆä»»åŠ¡**
- **è®­ç»ƒé›†**ï¼šOpenCodeInstruct
- **æµ‹è¯•é›†**ï¼š
  - HumanEval
  - MBPP
  - LiveCodeBench
  - CodeAlpacaï¼ˆPython å­é›†ï¼‰

#### **æ•°å­¦æ¨ç†ä»»åŠ¡**
- **è®­ç»ƒé›†**ï¼šUltraChat + ShareGPT
- **æµ‹è¯•é›†**ï¼š
  - GSM8K
  - Math500
  - Minerva Math

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹é…ç½®**
- **ç›®æ ‡æ¨¡å‹ï¼ˆverifierï¼‰**ï¼šQwen3 ç³»åˆ—ï¼ˆ4B, 8B, 14B, 30B-A3Bï¼‰
- **drafter æ¨¡å‹**ï¼š
  - ä»£ç ä»»åŠ¡ï¼šåŸºäº Open-dLLM çš„ 0.5B å‚æ•° discrete dLLM
  - æ•°å­¦ä»»åŠ¡ï¼šå°† Qwen2.5-0.5B-Instruct æ”¹é€ ä¸º diffusion æ¨¡å‹

#### **è¯„ä¼°æŒ‡æ ‡**
- **Speedup Ratio**ï¼šç«¯åˆ°ç«¯æ¨ç†é€Ÿåº¦ç›¸å¯¹äºæ ‡å‡† AR è§£ç çš„åŠ é€Ÿæ¯”ã€‚
- **Average Acceptance Length (T)**ï¼šæ¯æ¬¡ draft-verify å¾ªç¯ä¸­å¹³å‡è¢«æ¥å—çš„ token æ•°é‡ï¼Œåæ˜  speculative æ•ˆç‡ã€‚
- **Maximum Accepted Token Length**ï¼šå•æ¬¡æˆåŠŸæ¥å—çš„æœ€å¤§ token æ•°ã€‚

#### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **EAGLE-3**ï¼ˆå½“å‰æœ€å…ˆè¿›çš„ speculative decoding æ–¹æ³•ï¼‰
- Medusa
- Hydra
- å…¶ä»–ç›¸å…³æ–¹æ³•ä¹Ÿåœ¨ Related Work ä¸­è®¨è®ºï¼ˆå¦‚ DiffuSpecã€SDDï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **åœ¨ Qwen3-30B-A3B ä¸Šçš„è¡¨ç°ï¼ˆtemperature=0ï¼‰**

| æ–¹æ³• | Speedup | Tï¼ˆå¹³å‡æ¥å—é•¿åº¦ï¼‰ |
|------|---------|--------------------|
| EAGLE-3 | Ã—2.41 | 3.21 |
| **DEER** | **Ã—5.54** | **6.58** |

> âš¡ï¸ **DEER å®ç°äº† 5.54 å€åŠ é€Ÿï¼Œæ˜¯ EAGLE-3 çš„ä¸¤å€ä»¥ä¸Šï¼**

---

#### **è·¨æ¨¡å‹è§„æ¨¡è¡¨ç°æ±‡æ€»ï¼ˆTable 2ï¼‰**

| ç›®æ ‡æ¨¡å‹ | æ–¹æ³• | å¹³å‡ Speedup | å¹³å‡ T |
|--------|------|--------------|--------|
| Qwen3-30B-A3B | EAGLE-3 | Ã—2.21 | 3.05 |
| | **DEER** | **Ã—4.04** | **5.03** |

> åœ¨æ‰€æœ‰æ¨¡å‹å°ºåº¦ä¸Šï¼ŒDEER çš„ T æå‡ **50%â€“120%**ï¼Œä¸”æ¨¡å‹è¶Šå¤§ä¼˜åŠ¿è¶Šæ˜æ˜¾ã€‚

---

#### **æœ€å¤§æ¥å—é•¿åº¦å¯¹æ¯”ï¼ˆTable 4ï¼‰**

| æ¨¡å‹ | EAGLE-3 | DEER |
|------|---------|------|
| Qwen3-4B ~ 30B | 7â€“8 tokens | **32 tokens** âœ… |

> DEER å¯ç¨³å®šæ¥å—é•¿è¾¾ **32 ä¸ª token** çš„ blockï¼Œè¿œè¶… EAGLE-3 çš„ä¸Šé™ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

#### **Stage IIï¼ˆScribe Refinementï¼‰çš„å½±å“ï¼ˆTable 3ï¼‰**

| Benchmark | w/o Refinement | w/ Refinement | Î”â†‘ |
|----------|----------------|---------------|----|
| MBPP | 4.74 | 4.87 | +0.13 |
| CodeAlpacaPy | 3.47 | 4.04 | +0.57 |
| HumanEval | 5.38 | **6.58** | **+1.20** |
| LiveCodeBench | 3.87 | **5.03** | **+1.16** |

> ç»“æœè¡¨æ˜ï¼ŒStage II æ˜¾è‘—æå‡äº†å¤æ‚ä»»åŠ¡ä¸Šçš„å¯¹é½ç²¾åº¦ï¼Œå°¤å…¶æ˜¯åœ¨é•¿ç¨‹ä¾èµ–å¼ºçš„ä»»åŠ¡ä¸­æ•ˆæœæ›´æ˜æ˜¾ã€‚

#### **è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æ**
- æŒ‡æ•°åŠ æƒç³»æ•° `Î±` è¿‡å¤§ä¼šå¯¼è‡´è®­ç»ƒä¸ç¨³å®šï¼ˆå¦‚ Î±=1.05 æ—¶å‘æ•£ï¼‰ï¼Œä½†åˆç†èŒƒå›´å†…ï¼ˆå¦‚ Î±=1.01ï¼‰å¯ç¨³å®šä¼˜åŒ–ã€‚
- è¡¨æ˜è¯¥é˜¶æ®µè™½æ•æ„Ÿä½†å¯æ§ï¼Œä¸”å¸¦æ¥æ˜¾è‘—æ”¶ç›Šã€‚

---

### **æ‰¹å¤„ç†æ‰©å±•æ€§ï¼ˆBatch Inference Scalabilityï¼‰**

| æ‰¹å¤§å° | AR baseline (tokens/s) | DEER (tokens/s) | åŠ é€Ÿæ¯” |
|-------|------------------------|------------------|--------|
| 2 | 34.03 | 82.97 | ~2.4Ã— |
| 8 | 38.35 | 159.87 | ~4.2Ã— |
| 16 | 49.76 | 175.66 | ~3.5Ã— |

> DEER åœ¨æ‰¹å¤„ç†åœºæ™¯ä¸‹è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨ batch=8 æ—¶æ¥è¿‘ **4 å€ååæå‡**ï¼Œè¯´æ˜å…¶é«˜åº¦é€‚é… GPU å¹¶è¡Œè®¡ç®—ã€‚

---

### **æ•°å­¦æ¨ç†ä»»åŠ¡è¡¨ç°ï¼ˆTable 6ï¼‰**

å°½ç®¡æ•°å­¦é¢†åŸŸçš„ dLLM å°šæœªå……åˆ†æ”¶æ•›ï¼ŒDEER ä»å–å¾—ä¸€è‡´å¢ç›Šï¼š

| Benchmark | EAGLE-3 (Speedup/T) | DEER (Speedup/T) |
|----------|---------------------|------------------|
| Math500 | Ã—1.89 / 2.04 | **Ã—2.12 / 2.45** |
| GSM8K | Ã—1.92 / 2.43 | **Ã—2.23 / 2.70** |
| Minerva Math | Ã—1.91 / 2.07 | **Ã—2.02 / 2.31** |
| **å¹³å‡** | Ã—1.91 / 2.18 | **Ã—2.12 / 2.47** |

> å³ä½¿åœ¨å¼± drafter ä¸‹ï¼ŒDEER ä¾ç„¶ä¼˜äº EAGLE-3ï¼Œè¯æ˜å…¶æœºåˆ¶é²æ£’æ€§å¼ºã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **dLLM ä½œä¸º drafter å¯ä»æ ¹æœ¬ä¸Šé¿å… AR æ¨¡å‹çš„è¯¯å·®ç´¯ç§¯é—®é¢˜**  
   å› ä¸ºå…¶ç”Ÿæˆæ˜¯å…¨å±€å»å™ªè¿‡ç¨‹ï¼Œæ¯ä¸ªä½ç½®ç‹¬ç«‹äºå…ˆå‰ draft tokenï¼Œæ‰“ç ´äº† left-to-right ä¾èµ–ã€‚

2. **DEER å®ç°äº†å‰æ‰€æœªæœ‰çš„é•¿å—æ¥å—èƒ½åŠ›ï¼ˆup to 32 tokensï¼‰**  
   è¿™å¾—ç›Šäº one-step block generation å’Œç²¾å‡†çš„ D2A å¯¹é½è®­ç»ƒã€‚

3. **DEER åœ¨å¤šç§ä»»åŠ¡ã€æ¨¡å‹è§„æ¨¡å’Œæ‰¹å¤„ç†æ¡ä»¶ä¸‹å‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•**  
   ä¸ä»…åœ¨ä»£ç ç”Ÿæˆï¼Œåœ¨æ•°å­¦æ¨ç†ç­‰å¤æ‚ä»»åŠ¡ä¸Šä¹Ÿå±•ç°æ³›åŒ–èƒ½åŠ›ã€‚

4. **è®­ç»ƒæˆæœ¬æ›´ä½ï¼Œéƒ¨ç½²æ›´çµæ´»**  
   ç›¸æ¯” Medusa/Hydraï¼ŒDEER è®­ç»ƒæ›´é«˜æ•ˆï¼ˆTable 8ï¼‰ï¼Œä¸”ä¸éœ€é‡è®­ç»ƒä¸»æ¨¡å‹ã€‚

5. **æ­ç¤ºäº† dLLM çš„â€œå¯é å—å†ç”Ÿâ€èƒ½åŠ›**  
   æ”¯æŒå¯¹å±€éƒ¨æ©ç ç‰‡æ®µè¿›è¡Œè¿è´¯æ‰©å±•ï¼Œæ‹“å±•äº† diffusion æ¨¡å‹çš„åº”ç”¨è¾¹ç•Œã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ç¼ºä¹æˆç†Ÿçš„ dLLM æ¨ç†æ¡†æ¶æ”¯æŒ**  
   å½“å‰ä¸»æµç³»ç»Ÿï¼ˆå¦‚ vLLMã€SGLangï¼‰å°šæœªæ”¯æŒ dLLM çš„ KV cacheï¼Œå½±å“å®é™…éƒ¨ç½²æ•ˆç‡ï¼ˆè§ Appendix Fï¼‰ã€‚
   
2. **Stage II å¯¹è¶…å‚æ•°è¾ƒæ•æ„Ÿ**  
   æŒ‡æ•°åŠ æƒç³»æ•°éœ€ç²¾ç»†è°ƒèŠ‚ï¼Œå¦åˆ™å¯èƒ½å¼•å‘è®­ç»ƒä¸ç¨³å®šã€‚

3. **dLLM è‡ªèº«å°šæœªåœ¨æ‰€æœ‰é¢†åŸŸæˆç†Ÿ**  
   ç‰¹åˆ«æ˜¯åœ¨æ•°å­¦ç­‰é¢†åŸŸï¼Œå…¬å¼€å¯ç”¨çš„é«˜è´¨é‡ pretrained dLLM è¾ƒå°‘ï¼Œé™åˆ¶äº†ç›´æ¥åº”ç”¨ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ¨åŠ¨ dLLM æ¨ç†åŸºç¡€è®¾æ–½å»ºè®¾**  
   å¦‚é›†æˆ Fast-dLLM æˆ– dInfer çš„ KV cache æŠ€æœ¯ï¼Œè¿›ä¸€æ­¥é‡Šæ”¾ batch inference æ½œåŠ›ã€‚

2. **æ¢ç´¢æ›´å¤§è§„æ¨¡ dLLM ä½œä¸º drafter**  
   å½“å‰ä»…ä½¿ç”¨ 0.5B æ¨¡å‹ï¼Œè‹¥ä½¿ç”¨æ›´å¤§ dLLM å¯èƒ½å¸¦æ¥æ›´å¤§æ”¶ç›Šã€‚

3. **æ‰©å±•è‡³æ›´å¤šæ¨¡æ€ä¸ä»»åŠ¡**  
   å¦‚å›¾åƒã€è¯­éŸ³ç”Ÿæˆä¸­çš„ speculative decodingã€‚

4. **åŠ¨æ€è°ƒæ•´ block size**  
   æ ¹æ®ä¸Šä¸‹æ–‡éš¾åº¦è‡ªé€‚åº”é€‰æ‹© draft é•¿åº¦ï¼Œæå‡çµæ´»æ€§ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼šDEER å¼€è¾Ÿäº† speculative decoding çš„æ–°èŒƒå¼â€”â€”**ä»¥ diffusion æ¨¡å‹æ‰“ç ´è‡ªå›å½’ç“¶é¢ˆ**ï¼Œé€šè¿‡åˆ›æ–°çš„ D2A å¯¹é½è®­ç»ƒå®ç°äº†é«˜æ•ˆã€ç¨³å®šã€å¯æ‰©å±•çš„åŠ é€Ÿæ–¹æ¡ˆï¼Œåœ¨å¤šä¸ªç»´åº¦å…¨é¢è¶…è¶Šç°æœ‰æŠ€æœ¯ï¼Œä¸º LLM é«˜æ•ˆæ¨ç†æä¾›äº†æå…·å‰æ™¯çš„æ–¹å‘ã€‚

</details>

---

### 3. [Meta Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN](https://arxiv.org/abs/2512.13715)

**Authors**: Fatemeh Lotfi, Fatemeh Afghah  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.13715v1  

#### Abstract
The increasing complexity of modern applications demands wireless networks capable of real time adaptability and efficient resource management. The Open Radio Access Network (O-RAN) architecture, with its RAN Intelligent Controller (RIC) modules, has emerged as a pivotal solution for dynamic resourc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

**è®ºæ–‡æ ‡é¢˜**: *Meta-Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£æ— çº¿ç½‘ç»œï¼ˆç‰¹åˆ«æ˜¯åŸºäº **O-RAN** æ¶æ„ï¼‰é¢ä¸´åŠ¨æ€ã€ä¸å¯é¢„æµ‹ä¸”é«˜åº¦å¼‚æ„çš„èµ„æºç®¡ç†æŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ–¹æ³•åœ¨ä»¥ä¸‹æ–¹é¢å­˜åœ¨ä¸è¶³ï¼š
- éš¾ä»¥åº”å¯¹çªå‘æµé‡ã€çƒ­ç‚¹åŒºåŸŸå’Œéå¹³ç¨³ç¯å¢ƒï¼›
- ç¼ºä¹å¯¹å¤šç§ç½‘ç»œåˆ‡ç‰‡ï¼ˆå¦‚ eMBBã€URLLCã€mMTCï¼‰çš„è”åˆä¼˜åŒ–èƒ½åŠ›ï¼›
- åœ¨å¤§è§„æ¨¡éƒ¨ç½²ä¸‹é€‚åº”æ€§å·®ã€æ”¶æ•›æ…¢ã€ç¨³å®šæ€§ä½ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§ **è‡ªé€‚åº” Meta-Hierarchical Reinforcement Learning (Meta-HRL)** æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**åˆ†å±‚å†³ç­–æ¶æ„ï¼ˆHRLï¼‰**
- å°†èµ„æºç®¡ç†åˆ†è§£ä¸ºä¸¤ä¸ªå±‚çº§ï¼š
  - **é«˜å±‚æ§åˆ¶å™¨ï¼ˆHigh-level Controllerï¼‰**ï¼šè´Ÿè´£è·¨åˆ‡ç‰‡çš„èµ„æºåˆ†é…ï¼ˆå¦‚å¸¦å®½ã€åŠŸç‡ï¼‰ï¼›
  - **åº•å±‚ä»£ç†ï¼ˆLow-level Agentsï¼‰**ï¼šæ‰§è¡Œå„åˆ‡ç‰‡å†…çš„ç”¨æˆ·çº§è°ƒåº¦ï¼ˆå¦‚ RB åˆ†é…ï¼‰ã€‚
- è¿™ç§ç»“æ„æå‡äº†å¯æ‰©å±•æ€§å’Œå†³ç­–ç²’åº¦ï¼Œé€‚ç”¨äºå¤æ‚å¤šå˜çš„ O-RAN åœºæ™¯ã€‚

#### ï¼ˆ2ï¼‰**åŸºäº MAML çš„å…ƒå­¦ä¹ æœºåˆ¶**
- å¼•å…¥ **Model-Agnostic Meta-Learning (MAML)** æ€æƒ³ï¼Œä½¿æ¨¡å‹èƒ½ä»å†å²ä»»åŠ¡ä¸­â€œå­¦ä¼šå¦‚ä½•å¿«é€Ÿå­¦ä¹ â€ï¼›
- æ”¯æŒåœ¨æ–° DU æˆ–çªå‘åœºæ™¯ä¸‹å®ç° **few-shot adaptation**ï¼Œæ˜¾è‘—åŠ å¿«ç­–ç•¥å¾®è°ƒé€Ÿåº¦ã€‚

#### ï¼ˆ3ï¼‰**è‡ªé€‚åº”åŠ æƒå…ƒæ›´æ–°æœºåˆ¶ï¼ˆAdaptive Variance Weightingï¼‰**
- åˆ›æ–°æ€§åœ°ä½¿ç”¨ **Temporal Difference Error (TD-error) æ–¹å·®** æ¥è¡¡é‡ä»»åŠ¡å¤æ‚åº¦ï¼›
- å®šä¹‰è‡ªé€‚åº”æƒé‡ $ w_g = \text{Softmin}(\sigma^2_{\text{TD},g}) $ï¼Œä¼˜å…ˆæ›´æ–°é«˜æ–¹å·®ï¼ˆå³æ›´å¤æ‚/ä¸ç¨³å®šï¼‰çš„ä»»åŠ¡ï¼›
- æå‡è®­ç»ƒç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œé¿å…å¯¹ç®€å•ä»»åŠ¡è¿‡æ‹Ÿåˆæˆ–å¿½ç•¥å…³é”®éš¾ç‚¹ã€‚

#### ï¼ˆ4ï¼‰ç†è®ºä¿éšœ
- ç»™å‡ºäº† **æ”¶æ•›æ€§åˆ†æ** å’Œ **regret bound**ï¼Œè¯æ˜è¯¥æ¡†æ¶å…·æœ‰äºšçº¿æ€§æ”¶æ•›é€Ÿç‡å’Œç¨³å®šçš„ä¸¤æ—¶é—´å°ºåº¦å­¦ä¹ è¡Œä¸ºã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | æœ¬æ–‡æ–¹æ³•ï¼ˆMeta-HRLï¼‰ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ DRLã€Federated RLã€Single-Slice Meta-RLï¼‰ |
|--------|---------------------|---------------------------------------------|
| é€‚åº”æ€§ | å¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡ï¼ˆfew-shotï¼‰ | å†·å¯åŠ¨æ…¢ï¼Œéœ€å¤§é‡è®­ç»ƒ |
| å¯æ‰©å±•æ€§ | åˆ†å¸ƒå¼ DU æ¶æ„ + å±‚æ¬¡åŒ–æ§åˆ¶ï¼Œæ”¯æŒå¤§è§„æ¨¡éƒ¨ç½² | å¤šæ•°é›†ä¸­å¼è®¾è®¡ï¼Œæ‰©å±•æ€§å—é™ |
| æ³›åŒ–èƒ½åŠ› | è·¨ä»»åŠ¡è¿ç§»å¼ºï¼Œé€šè¿‡ meta-learning å®ç° | é€šå¸¸å±€é™äºç‰¹å®šåœºæ™¯ |
| ç¨³å®šæ€§ | è‡ªé€‚åº”åŠ æƒå‡å°‘ç¾éš¾æ€§é—å¿˜ | æ˜“å—éå¹³ç¨³ç¯å¢ƒå¹²æ‰° |
| QoS ä¿è¯ | åŒæ—¶æ»¡è¶³ eMBBã€URLLCã€mMTC çš„å·®å¼‚åŒ–éœ€æ±‚ | å¾€å¾€åªå…³æ³¨å•ä¸€ç±»å‹æœåŠ¡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### å®éªŒå¹³å°ä¸ä»¿çœŸç¯å¢ƒ
- åŸºäº **O-RAN æ¶æ„æ¨¡æ‹Ÿå™¨** æ„å»ºä»¿çœŸç³»ç»Ÿï¼›
- ä½¿ç”¨ **PyTorch** å®ç° DDPG-based actor-critic æ¨¡å‹ï¼›
- æ‰€æœ‰æ™ºèƒ½ä½“ä½œä¸º **xApp** éƒ¨ç½²åœ¨ Near-RT RIC ä¸­ï¼Œç¬¦åˆ O-RAN è§„èŒƒã€‚

### ç½‘ç»œé…ç½®å‚æ•°ï¼ˆè§ Table 1ï¼‰
| å‚æ•° | å€¼ |
|------|----|
| å­è½½æ³¢é—´éš” | 15 kHz |
| å•ä¸ª DU æ€»å¸¦å®½ | 20 MHz |
| æ¯ä¸ª DU çš„ RB æ•°é‡ ($K_p$) | 100 |
| ç”¨æˆ·æ•°é‡ per DU | 30 |
| åˆ†å¸ƒå¼å•å…ƒæ•° ($N_g$) | 7 |
| ç”¨æˆ·ç§»åŠ¨é€Ÿåº¦ | 10â€“20 m/s |
| æŠ˜æ‰£å› å­ $\gamma$ | 0.99 |

### ç½‘ç»œåˆ‡ç‰‡ç±»å‹åŠ KPI
| åˆ‡ç‰‡ç±»å‹ | QoS æŒ‡æ ‡ | å®šä¹‰ |
|--------|---------|------|
| eMBB | ååé‡ï¼ˆThroughputï¼‰ | $ \frac{1}{N_u}\sum C_i $ |
| mMTC | å¯†åº¦æ”¯æŒèƒ½åŠ› | $ \frac{1}{N_u}\sum C_i \cdot \mathbf{1}(C_i \geq \lambda_i) $ |
| URLLC | æœ€å¤§å»¶è¿Ÿï¼ˆLatencyï¼‰ | $ \max(T_i) $ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **DRL**ï¼šæ ‡å‡†æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆä»é›¶å¼€å§‹è®­ç»ƒï¼‰ï¼›
- **Transfer Learning (TL)**ï¼šè¿ç§»é¢„è®­ç»ƒæ¨¡å‹ï¼›
- **Multi-Task Learning (MTL)**ï¼šåŒæ—¶å­¦ä¹ å¤šä¸ªä»»åŠ¡ï¼›
- **MAML-RL**ï¼šåŸºç¡€å…ƒå¼ºåŒ–å­¦ä¹ ï¼›
- **Uniform-Meta**ï¼šç­‰æƒå…ƒæ›´æ–°ï¼ˆæ¶ˆèå®éªŒç”¨ï¼‰ï¼›
- **Static-Var**ï¼šå›ºå®šæ–¹å·®åŠ æƒï¼ˆæ¶ˆèå®éªŒç”¨ï¼‰ã€‚

### è¯„ä¼°æŒ‡æ ‡
- å¹³å‡ç´¯è®¡å¥–åŠ±ï¼ˆCumulative Rewardï¼‰
- å„åˆ‡ç‰‡ QoS æ»¡è¶³ç‡ï¼ˆCDF æ›²çº¿ï¼‰
- ç”¨æˆ·ååé‡åˆ†å¸ƒï¼ˆper-user throughputï¼‰
- é€‚åº”é€Ÿåº¦ï¼ˆAdaptation shots to convergeï¼‰
- å…¬å¹³æ€§ï¼ˆJainâ€™s Fairness Indexï¼‰
- å¹³å‡å»¶è¿Ÿã€æŠ—çªå‘æµé‡é²æ£’æ€§

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### âœ… **æ€»ä½“æ•ˆç‡æå‡**
- ç›¸æ¯”åŸºçº¿æ–¹æ³•ï¼ˆDRLã€TLã€MTLï¼‰ï¼Œæå‡ºçš„ **Adaptive MAML-HRL** åœ¨æœ€ç»ˆè¿”å›å€¼ä¸Šå®ç°äº† **19.8% çš„ç½‘ç»œç®¡ç†æ•ˆç‡æå‡**ï¼ˆSection VII-B, Fig. 4ï¼‰ã€‚

#### âœ… **æ›´å¿«çš„é€‚åº”èƒ½åŠ›**
- åœ¨ **5-shot åœºæ™¯** ä¸‹ï¼ŒAdaptive MAML-HRL è¾ƒæ™®é€š MAML-RL æå‡çº¦ **4%**ï¼Œè¾ƒ DRL æå‡é«˜è¾¾ **73%**ï¼›
- æ¶ˆèå®éªŒæ˜¾ç¤ºï¼Œç›¸æ¯”å‡åŒ€åŠ æƒï¼ˆUniform-Metaï¼‰ï¼Œæ‰€æè‡ªé€‚åº”æœºåˆ¶å¯å®ç° **40% æ›´å¿«æ”¶æ•›**ï¼ˆTable 3ï¼‰ã€‚

#### âœ… **QoS è¡¨ç°å…¨é¢é¢†å…ˆ**
- **eMBB åˆ‡ç‰‡**ï¼šæä¾›æœ€é«˜ååé‡ï¼Œé€‚åˆé«˜æ¸…è§†é¢‘æµç­‰åº”ç”¨ï¼›
- **mMTC åˆ‡ç‰‡**ï¼šåœ¨é«˜å¯†åº¦è®¾å¤‡è¿æ¥ä¸‹ä»ä¿æŒè‰¯å¥½æœåŠ¡è´¨é‡ï¼›
- **URLLC åˆ‡ç‰‡**ï¼šå®ç°æœ€ä½å»¶è¿Ÿï¼Œæ»¡è¶³è‡ªåŠ¨é©¾é©¶ç­‰ä¸¥è‹›è¦æ±‚ï¼ˆFig. 6, 9ï¼‰ã€‚

#### âœ… **ç”¨æˆ·çº§ä½“éªŒæ”¹å–„**
- Fig. 7 æ˜¾ç¤ºï¼Œæ‰€æœ‰åˆ‡ç‰‡ä¸­ç”¨æˆ·çš„ **ååé‡ CDF æ›²çº¿æ˜æ˜¾å³ç§»**ï¼Œè¡¨æ˜ç”¨æˆ·ä½“éªŒæ˜¾è‘—æå‡ï¼›
- ç‰¹åˆ«æ˜¯åœ¨ mMTC åœºæ™¯ä¸­ï¼Œè‡ªé€‚åº”æœºåˆ¶æœ‰æ•ˆå¹³è¡¡äº†æµ·é‡è®¾å¤‡é—´çš„èµ„æºç«äº‰ã€‚

#### âœ… **æ¶ˆèå®éªŒéªŒè¯æœ‰æ•ˆæ€§ï¼ˆTable 3ï¼‰**
| æ–¹æ³• | å½’ä¸€åŒ–å¥–åŠ± | æ”¶æ•›æ‰€éœ€é€‚åº”æ­¥æ•° |
|------|------------|------------------|
| Uniform-Meta | 0.78 | 28 |
| Static-Var | 0.81 | 22 |
| **Adaptive-Var (æå‡º)** | **0.84** | **17** |

> ç»“æœè¡¨æ˜ï¼š**åŠ¨æ€è½¯æœ€å°åŠ æƒï¼ˆSoftmin on TD-error varianceï¼‰æ˜¯æœ€ä¼˜ç­–ç•¥**ï¼Œå¸¦æ¥çº¦ **3% å¥–åŠ±å¢ç›Š** å’Œ **è¿‘ 40% åŠ é€Ÿæ”¶æ•›**ã€‚

#### âœ… **é¢å¤–ç½‘ç»œæŒ‡æ ‡æ”¹è¿›ï¼ˆSection Iï¼‰**
- å¹³å‡åŒ…å»¶è¿Ÿ â†“ **9.2%**
- Jain å…¬å¹³æ€§æŒ‡æ•° â†‘ ä» **0.91 â†’ 0.96**
- åœ¨ **50% æµé‡æ¿€å¢** åœºæ™¯ä¸‹æ€§èƒ½ä¸‹é™ < **5%**ï¼Œè¡¨ç°å‡ºå¼ºé²æ£’æ€§ã€‚

#### âœ… **å¯æ‰©å±•æ€§è¡¨ç°ä¼˜å¼‚ï¼ˆTable 2ï¼‰**
| $N_{DU}$ | $N_{UE}$ | æ”¶æ•›è¿­ä»£å¢åŠ  | å½’ä¸€åŒ–å¥–åŠ±å˜åŒ– |
|----------|-----------|---------------|----------------|
| 7 | 30 | 0% (åŸºå‡†) | 0.00 |
| 15 | 100 | +32% | -0.01 |
| 30 | 200 | +69% | -0.02 |

> è¡¨æ˜ï¼šå°½ç®¡ä»»åŠ¡è§„æ¨¡æ‰©å¤§ï¼Œä½† **å½’ä¸€åŒ–æ€§èƒ½å‡ ä¹ä¸å˜**ï¼Œè¯´æ˜æ¡†æ¶å…·å¤‡è‰¯å¥½çš„ **scalability**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Meta-HRL æ˜¯è§£å†³ O-RAN åŠ¨æ€èµ„æºç®¡ç†çš„æœ‰æ•ˆèŒƒå¼**ï¼š
   - ç»“åˆ HRL çš„ç»“æ„æ€§ä¼˜åŠ¿ä¸ Meta-RL çš„å¿«é€Ÿé€‚åº”èƒ½åŠ›ï¼Œç‰¹åˆ«é€‚åˆå¤šåˆ‡ç‰‡ã€éå¹³ç¨³ç¯å¢ƒã€‚

2. **è‡ªé€‚åº”åŠ æƒæœºåˆ¶è‡³å…³é‡è¦**ï¼š
   - åˆ©ç”¨ TD-error æ–¹å·®è‡ªåŠ¨è¯†åˆ«â€œå›°éš¾ä»»åŠ¡â€ï¼Œå¹¶èµ‹äºˆæ›´é«˜å­¦ä¹ ä¼˜å…ˆçº§ï¼Œæ˜¾è‘—æå‡è®­ç»ƒæ•ˆç‡å’Œç¨³å®šæ€§ã€‚

3. **æœ¬åœ°åŒ–å¤„ç†å¢å¼ºå®æ—¶æ€§**ï¼š
   - å°†å†³ç­–ä¸‹æ²‰è‡³ DU å±‚é¢ï¼Œå‡å°‘ä¿¡ä»¤å¼€é”€ï¼Œç¼“è§£ä¹±åºé—®é¢˜ï¼Œæœ‰åˆ©äºä½å»¶è¿Ÿæ“ä½œã€‚

4. **ç†è®ºä¸å®è·µä¸€è‡´**ï¼š
   - ç†è®ºåˆ†æè¯æ˜äº†ç®—æ³•çš„ **sublinear convergence** å’Œ **bounded regret**ï¼Œå®éªŒç»“æœä¹ŸéªŒè¯äº†å…¶ç¨³å®šæ€§å’Œé«˜æ•ˆæ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ç ”ç©¶åŸºäº **ä»¿çœŸç¯å¢ƒ**ï¼Œå°šæœªåœ¨çœŸå® O-RAN testbed ä¸ŠéªŒè¯ï¼›
- å…ƒæ›´æ–°é€šä¿¡è™½è½»é‡ï¼ˆä»…ä¼ è¾“å‚æ•°ï¼‰ï¼Œä½†åœ¨è¶…å¤§è§„æ¨¡éƒ¨ç½²ä¸­ä»å¯èƒ½å¼•å…¥å»¶è¿Ÿï¼›
- æ¨¡å‹å‡è®¾çŠ¶æ€ç©ºé—´è¿ç»­ä¸”å¯è§‚æµ‹ï¼Œåœ¨éƒ¨åˆ†é®è”½ç¯å¢ƒä¸‹å¯èƒ½é€€åŒ–ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **ç¡¬ä»¶åœ¨ç¯éªŒè¯ï¼ˆHardware-in-the-loop testingï¼‰**ï¼›
2. **é€šä¿¡é«˜æ•ˆçš„å…ƒå‚æ•°æ›´æ–°æœºåˆ¶**ï¼ˆå¦‚é‡åŒ–ã€ç¨€ç–åŒ–ï¼‰ï¼›
3. **æ‰©å±•è‡³ multi-hop å’Œ UAV-assisted 6G åœºæ™¯**ï¼›
4. æ¢ç´¢ä¸å…¶ä»– AI æŠ€æœ¯ï¼ˆå¦‚è”é‚¦å­¦ä¹ ã€å› æœæ¨ç†ï¼‰çš„èåˆã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºçš„ **Adaptive Meta-HRL** æ¡†æ¶é€šè¿‡ **å±‚æ¬¡åŒ–æ§åˆ¶ + MAML å…ƒå­¦ä¹  + TD-error æ–¹å·®åŠ æƒæœºåˆ¶**ï¼Œå®ç°äº† O-RAN ç³»ç»Ÿä¸­é«˜æ•ˆã€å¿«é€Ÿã€å…¬å¹³ä¸”å¯æ‰©å±•çš„èµ„æºç®¡ç†ï¼Œåœ¨å¤šé¡¹æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶å…·å¤‡åšå®çš„ç†è®ºæ”¯æ’‘å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

</details>

---

### 4. [LLMQ: Efficient Lower-Precision Pretraining for Consumer GPUs](https://arxiv.org/abs/2512.15306)

**Authors**: Erik Schultheis, Dan Alistarh  
**Category**: cs.DC  
**Published**: 2025-12-18  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.15306v1  

#### Abstract
We present LLMQ, an end-to-end CUDA/C++ implementation for medium-sized language-model training, e.g. 3B to 32B parameters, on affordable, commodity GPUs. These devices are characterized by low memory availability and slow communication compared to datacentre-grade GPUs. Consequently, we showcase a ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# LLMQ: Efficient Lower-Precision Pretraining for Consumer GPUs è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è®­ç»ƒä¸»è¦ä¾èµ–æ˜‚è´µçš„æ•°æ®ä¸­å¿ƒçº§GPUï¼ˆå¦‚H100ã€L40Sï¼‰ï¼Œè¿™äº›è®¾å¤‡å…·æœ‰é«˜å†…å­˜å¸¦å®½å’ŒNVLinké€šä¿¡èƒ½åŠ›ã€‚ç„¶è€Œï¼Œæ™®é€šç”¨æˆ·é€šå¸¸åªèƒ½è®¿é—®æ¶ˆè´¹çº§GPUï¼ˆå¦‚RTX 4090ã€RTX 5060Tiï¼‰ï¼Œå…¶å­˜åœ¨ä»¥ä¸‹ç“¶é¢ˆï¼š
- **æ˜¾å­˜å®¹é‡æœ‰é™**ï¼ˆé€šå¸¸â‰¤24GBï¼‰
- **GPUé—´é€šä¿¡å¸¦å®½ä½**ï¼ˆé€šè¿‡PCIeè€ŒéNVLinkï¼‰
- **ç¼ºä¹é«˜æ•ˆçš„é›†ä½“é€šä¿¡æ”¯æŒ**

è¿™å¯¼è‡´åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šéš¾ä»¥é«˜æ•ˆè®­ç»ƒä¸­ç­‰è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚7B~32Bå‚æ•°ï¼‰ã€‚LLMQæ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ï¼Œå®ç°**åœ¨ä½æˆæœ¬æ¶ˆè´¹çº§GPUä¸Šè¿›è¡Œé«˜æ•ˆã€ç«¯åˆ°ç«¯çš„LLMé¢„è®­ç»ƒä¸å¾®è°ƒ**ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹

LLMQæ˜¯ä¸€ä¸ªå®Œå…¨ç”¨C++/CUDAç¼–å†™çš„å¼€æºæ¡†æ¶ï¼Œä¸“ä¸ºæ¶ˆè´¹çº§GPUä¼˜åŒ–ï¼Œæ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**æ··åˆç²¾åº¦FP8è®­ç»ƒæµæ°´çº¿**
- æ”¯æŒ **bfloat16ï¼ˆBF16ï¼‰ä¸FP8æ··åˆè®­ç»ƒ**ï¼Œä¸»Transformerå±‚ä¸­çš„çŸ©é˜µä¹˜æ³•ï¼ˆmatmulï¼‰ä½¿ç”¨FP8ï¼Œéçº¿æ€§æ“ä½œã€æ³¨æ„åŠ›ï¼ˆSDPAï¼‰ã€åµŒå…¥å±‚å’ŒLM Headä¿æŒBF16ã€‚
- é‡‡ç”¨ **tensor-level absmaxåŠ¨æ€ç¼©æ”¾** è¿›è¡ŒFP8é‡åŒ–ï¼Œä¿è¯æ— æº¢å‡ºï¼Œé€‚ç”¨äºAdaï¼ˆRTX 40xxï¼‰å’ŒBlackwellï¼ˆRTX 50xxï¼‰æ¶æ„ã€‚
- åœ¨ä¸å¼•å…¥é¢å¤–ç®—æ³•è¿‘ä¼¼çš„æƒ…å†µä¸‹ï¼Œç»´æŒé«˜FLOPsåˆ©ç”¨ç‡ã€‚

#### ï¼ˆ2ï¼‰å¤šå±‚æ¬¡å†…å­˜ä¼˜åŒ–ç­–ç•¥
é’ˆå¯¹æ˜¾å­˜å—é™åœºæ™¯ï¼Œæå‡ºç»„åˆå¼ä¼˜åŒ–æ–¹æ¡ˆï¼š
- **é€‰æ‹©æ€§æ¿€æ´»é‡è®¡ç®—ï¼ˆSelective Recomputationï¼‰**ï¼šä»ä»…é‡ç®—éçŸ©é˜µè¿ç®—å±‚ï¼ˆå¦‚SwiGLUã€RMSNormï¼‰åˆ°å®Œæ•´Transformerå—é‡ç®—ï¼Œçµæ´»å¹³è¡¡è®¡ç®—ä¸å†…å­˜ã€‚
- **CPU Offloading**ï¼š
  - å°†æ®‹å·®ï¼ˆresidualsï¼‰ã€ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆm/vï¼‰ã€ä¸»å‚æ•°ï¼ˆmaster weightsï¼‰ã€æ¢¯åº¦ç¼“å†²åŒºç­‰å¸è½½è‡³CPUå†…å­˜ã€‚
  - åˆ©ç”¨â€œæƒé‡ç¼“å­˜åœ¨ä¸»æœºâ€æœºåˆ¶å‡å°‘å¤šå¡é€šä¿¡å¼€é”€ã€‚
- **åˆ†å—è®¡ç®—ï¼ˆChunkingï¼‰**ï¼šå¯¹logitså’ŒFlashAttentionçš„workspaceè¿›è¡Œåˆ‡ç‰‡å¤„ç†ï¼Œé¿å…å¤§å¼ é‡å ç”¨è¿‡å¤šå†…å­˜ã€‚

#### ï¼ˆ3ï¼‰åŸºäº`cudaMemcpy`çš„é«˜æ•ˆé€šä¿¡åç«¯
- é’ˆå¯¹æ¶ˆè´¹çº§GPUæ— æ³•ç›´æ¥P2Pé€šä¿¡çš„é—®é¢˜ï¼Œè®¾è®¡äº†ä¸€ç§**åŸºäºcopy engineçš„reduce-scatterå’Œall-gatherå®ç°**ã€‚
- åˆ©ç”¨GPUçš„DMAå¼•æ“ï¼ˆcopy engineï¼‰æ‰§è¡Œæ•°æ®ä¼ è¾“ï¼Œ**ä¸å ç”¨SMèµ„æº**ï¼Œå¯ä¸åç»­backwardè®¡ç®—å¹¶è¡Œã€‚
- ç›¸æ¯”NCCLï¼Œåœ¨RTX 4090é›†ç¾¤ä¸Šæ˜¾è‘—æå‡PCIeå¸¦å®½åˆ©ç”¨ç‡ã€‚

#### ï¼ˆ4ï¼‰ç¡®å®šæ€§è®­ç»ƒæ”¯æŒ
- æ‰€æœ‰kernelå‡ä¸ºbitwise-deterministicï¼Œç¡®ä¿ç›¸åŒé…ç½®ä¸‹ç»“æœå¯å¤ç°ã€‚
- ä½¿ç”¨counter-basedéšæœºæ•°ç”Ÿæˆå™¨å®ç°ç¡®å®šæ€§stochastic roundingã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | LLMQä¼˜åŠ¿ |
|------|----------|
| **ç¡¬ä»¶é€‚é…æ€§** | ä¸“ä¸ºæ¶ˆè´¹çº§GPUè®¾è®¡ï¼Œå……åˆ†åˆ©ç”¨å…¶æ€§ä»·æ¯”ï¼ˆFLOPs/$ï¼‰ |
| **å†…å­˜æ•ˆç‡** | å¤šçº§offloading + é‡è®¡ç®— + FP8ï¼Œå¯åœ¨16GBæ˜¾å­˜ä¸Šè®­ç»ƒ7Bæ¨¡å‹ |
| **é€šä¿¡æ•ˆç‡** | `cudaMemcpy`-based collectivesåœ¨æ— NVLinkè®¾å¤‡ä¸Šè¿œä¼˜äºNCCL |
| **æ€§èƒ½è¡¨ç°** | åœ¨4Ã—RTX 4090ä¸Šè®­ç»ƒ32Bæ¨¡å‹è¾¾åˆ°51% MFUï¼Œè¶…è¿‡L40Sçš„29% MFU |
| **æ˜“ç”¨æ€§** | ç«¯åˆ°ç«¯C++å®ç°ï¼Œå¯åŠ¨æ—¶å®Œæˆæ‰€æœ‰å†…å­˜åˆ†é…ï¼Œé¿å…è¿è¡Œæ—¶OOM |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **é¢„è®­ç»ƒæ•°æ®**ï¼šä½¿ç”¨retokenizedå¹¶å­é‡‡æ ·çš„[ClimbMix](https://arxiv.org/abs/2504.13161)æ•°æ®é›†ï¼ŒåŒ…å«10B~30B tokensã€‚
- **å¾®è°ƒä»»åŠ¡**ï¼š
  - **GSM8K**ï¼šæ•°å­¦æ¨ç†åŸºå‡†ï¼Œç”¨äºè¯„ä¼°LLaMA2-7Bå’ŒQwen2.5-14Bçš„å¾®è°ƒæ•ˆæœã€‚

---

### å®éªŒè®¾ç½®

#### ç¡¬ä»¶å¹³å°
- **å•å¡**ï¼šRTX 5060Tiï¼ˆ16GBï¼‰ã€RTX 4090ï¼ˆ24GBï¼‰
- **å¤šå¡å·¥ä½œç«™**ï¼š4Ã—RTX 4090ã€4Ã—L40S
- **æ–°å‹è®¾å¤‡æµ‹è¯•**ï¼šNVIDIA DGX Sparkï¼ˆBlackwellæ¶æ„ï¼Œ128GBç»Ÿä¸€å†…å­˜ï¼‰

#### æ¨¡å‹è§„æ¨¡
è¦†ç›–0.5B ~ 32Bå‚æ•°æ¨¡å‹ï¼Œå…¸å‹ç»“æ„ä¸ºQwen-styleæˆ–LLaMA2æ¶æ„ã€‚

#### è¯„ä¼°æŒ‡æ ‡
- **Tokens Per Second (TPS)**ï¼šååé‡
- **Model FLOPs Utilization (MFU)**ï¼šå®é™…FLOPså ç†è®ºå³°å€¼çš„æ¯”ä¾‹ï¼Œè€ƒè™‘æ··åˆç²¾åº¦ä¸‹çš„åŠ æƒè®¡ç®—
- **Speedup (Sp)**ï¼šFP8ç›¸å¯¹äºBF16çš„åŠ é€Ÿæ¯”
- **éªŒè¯æŸå¤±ä¸å‡†ç¡®ç‡**ï¼šGSM8Kä¸Šçš„few-shot/zero-shotæ€§èƒ½

#### åŸºçº¿å¯¹æ¯”
- **LLaMA-Factory (LF)**ï¼šä¸»æµå¼€æºå¾®è°ƒæ¡†æ¶
- **NCCL-basedç³»ç»Ÿ**ï¼šæ ‡å‡†å¤šGPUé€šä¿¡æ–¹æ¡ˆ
- **ä¸“ä¸šçº§GPUï¼ˆL40Sï¼‰**ï¼šä½œä¸ºé«˜æ€§èƒ½å¯¹ç…§ç»„

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªTables 1â€“3ï¼‰

| æ¨¡å‹å¤§å° | ç¡¬ä»¶é…ç½® | ç²¾åº¦ | TPS | MFU |
|---------|--------|-----|-----|-----|
| 7B | å•å¡ RTX 5060Ti (16GB) | FP8 | 1.4k | 70% |
| 7B | å•å¡ RTX 4090 | FP8 | 4.3k | 61% |
| 14B | å•å¡ RTX 4090 | FP8 | 2.0k | 55% |
| 32B | 4Ã—RTX 4090 | FP8 | 3.4k | 51% |
| 32B | 4Ã—L40S | BF16 | 3.0k | 40% |

> âš ï¸ æ³¨ï¼šLLMQåœ¨4Ã—RTX 4090ä¸Šè®­ç»ƒ32Bæ¨¡å‹è¾¾åˆ°**51% MFU**ï¼Œè€ŒåŒè§„æ¨¡L40Sä»…è¾¾**29% MFU**ï¼Œè¯´æ˜æ¶ˆè´¹çº§ç¡¬ä»¶ç»ä¼˜åŒ–åå¯è¶…è¶Šä¸“ä¸šå¡æ•ˆç‡ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”

#### vs LLaMA-Factoryï¼ˆTable 4 & Appendix A.1ï¼‰
| æ¨¡å‹ | ç¡¬ä»¶ | æ–¹æ³• | TPS | å¯¹æ¯”ä¼˜åŠ¿ |
|------|------|------|-----|----------|
| 1.5B | 1Ã—4090 | LLMQ (FP8) | 20k | æ˜¯LFçš„~2å€ |
| 14B | 1Ã—4090 | LLMQ (FP8) | 2.0k | æ˜¯LF (~1.2k) çš„1.7å€ |
| 32B | 4Ã—4090 | LLMQ (FP8) | 3.4k | LF OOM |

- LLMQé€šè¿‡æ›´ç»†ç²’åº¦çš„offloadingæ§åˆ¶å’Œæ›´ä½å¼€é”€çš„kernelè°ƒåº¦ï¼Œåœ¨å¤§æ¨¡å‹ä¸Šæ˜¾è‘—èƒœå‡ºã€‚
- LFå€¾å‘äºâ€œå…¨é‡offloadä»¥æ”¯æŒå¤§batchâ€ï¼Œè€ŒLLMQé‡‡ç”¨æ¸è¿›å¼offloadï¼Œåœ¨ä¸­ç­‰batchä¸‹å³å¯ç¨³å®šè¿è¡Œã€‚

#### vs NCCLé€šä¿¡ï¼ˆTable 5ï¼‰
| ç¡¬ä»¶ | æ–¹æ³• | FP8 TPS (14B) | åŠ é€Ÿæ¯” |
|------|------|----------------|--------|
| 4Ã—RTX 4090 | NCCL only | 4.3k | â€”â€” |
| 4Ã—RTX 4090 | Full `cudaMemcpy` | **7.8k** | **+81%** |
| 4Ã—L40S | NCCL only | 9.5k | â€”â€” |
| 4Ã—L40S | Full `cudaMemcpy` | 9.9k | +4% |

> âœ… ç»“è®ºï¼š**åœ¨æ— P2Pè¿æ¥çš„æ¶ˆè´¹çº§GPUä¸Šï¼Œ`cudaMemcpy`-basedé€šä¿¡è‡³å…³é‡è¦ï¼›è€Œåœ¨ä¸“ä¸šå¡ä¸ŠNCCLå·²è¶³å¤Ÿé«˜æ•ˆ**ã€‚

---

### æ¶ˆèå®éªŒä¸å…³é”®å‘ç°

#### FP8å¸¦æ¥çš„åŠ é€Ÿæ•ˆæœï¼ˆSpåˆ—ï¼‰
- å°æ¨¡å‹ï¼ˆ0.5Bï¼‰ï¼šFP8æé€Ÿçº¦20%~30%
- ä¸­å¤§æ¨¡å‹ï¼ˆâ‰¥7Bï¼‰ï¼šFP8æé€Ÿè¾¾**50%ä»¥ä¸Š**
- åŸå› ï¼šéšç€æ¨¡å‹å¢å¤§ï¼ŒGEMMå æ¯”ä¸Šå‡ï¼ŒFP8ä¼˜åŠ¿æ˜¾ç°

#### å†…å­˜ä¼˜åŒ–æœ‰æ•ˆæ€§
- åœ¨RTX 5060Tiä¸Šï¼Œç»“åˆblock-level recompute + offloading (m,v,0*,x,g)ï¼ŒæˆåŠŸå°†7Bæ¨¡å‹micro-batch sizeä»1æå‡è‡³16ã€‚
- Offloadingæ¢¯åº¦ç¼“å†²åŒºåï¼Œæ˜¾å­˜æ¶ˆè€—é™è‡³â€œä¸¤å±‚Transformerâ€æ°´å¹³ã€‚

#### DGX Sparkåˆæ­¥æµ‹è¯•ï¼ˆTable 3ï¼‰
- è™½ç„¶æ‹¥æœ‰128GBç»Ÿä¸€å†…å­˜ï¼Œä½†å†…å­˜å¸¦å®½è¾ƒä½ï¼ˆ300 GB/sï¼‰ï¼Œé™åˆ¶äº†æ€§èƒ½ã€‚
- å°æ¨¡å‹ï¼ˆâ‰¤3Bï¼‰å—ç›Šäºæ— éœ€offloadï¼Œä½†FP8æé€Ÿæœ‰é™ï¼ˆ<22%ï¼‰ï¼Œå› å†…å­˜bound kernelæœªå—ç›Šäºä½ç²¾åº¦ã€‚
- ä»…å½“æ¨¡å‹è¾¾7Bæ—¶ï¼ŒGEMMä¸»å¯¼è®¡ç®—ï¼ŒFP8å¸¦æ¥**41%åŠ é€Ÿ**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ¶ˆè´¹çº§GPUå®Œå…¨å¯ä»¥èƒœä»»ä¸­ç­‰è§„æ¨¡LLMè®­ç»ƒ**ï¼Œåªè¦é…åˆåˆç†çš„ç³»ç»Ÿä¼˜åŒ–ï¼ˆoffload + recompute + FP8 + custom commï¼‰ã€‚
2. **FP8è®­ç»ƒåœ¨å¤§æ¨¡å‹ä¸Šèƒ½å¸¦æ¥æ˜¾è‘—åŠ é€Ÿï¼ˆ~50%ï¼‰**ï¼Œä¸”ä¸å½±å“æœ€ç»ˆæ¨¡å‹è´¨é‡ï¼ˆè§GSM8Kç»“æœï¼‰ã€‚
3. **ä¼ ç»ŸNCCLåœ¨æ¶ˆè´¹çº§GPUä¸Šæ€§èƒ½ä¸ä½³**ï¼Œåº”ä¼˜å…ˆé‡‡ç”¨`cudaMemcpy`é©±åŠ¨çš„é€šä¿¡æ–¹æ¡ˆã€‚
4. **LLMQçš„MFUé«˜è¾¾51%~70%**ï¼Œåª²ç¾ç”šè‡³è¶…è¿‡äº‘å‚å•†çš„å¤§è§„æ¨¡è®­ç»ƒç³»ç»Ÿã€‚
5. **ç»Ÿä¸€å†…å­˜è®¾å¤‡ï¼ˆå¦‚DGX Sparkï¼‰è™½ç®€åŒ–ç¼–ç¨‹æ¨¡å‹ï¼Œä½†ä»å—å¸¦å®½é™åˆ¶**ï¼Œéœ€è¿›ä¸€æ­¥è½¯ç¡¬ä»¶ååŒä¼˜åŒ–ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ç›®å‰ä»…æ”¯æŒå•èŠ‚ç‚¹å†…å¤šGPUè®­ç»ƒ**ï¼Œå°šæœªæ‰©å±•è‡³è·¨èŠ‚ç‚¹åˆ†å¸ƒå¼ã€‚
2. **FP8é‡åŒ–ä¾èµ–absmax scaling**ï¼Œå¯èƒ½ä¸å¦‚channel-wise scalingç²¾ç¡®ï¼Œä½†åœ¨å®è·µä¸­è¡¨ç°è‰¯å¥½ã€‚
3. **æç«¯å¤§è§„æ¨¡è®­ç»ƒï¼ˆ>100B tokensï¼‰ç¨³å®šæ€§å¾…éªŒè¯**ï¼Œä½œè€…æŒ‡å‡ºä½ç²¾åº¦è®­ç»ƒåœ¨è¶…é•¿è®­ç»ƒä¸­å¯èƒ½å­˜åœ¨é€€åŒ–é£é™©ã€‚
4. **offloadingé‡åº¦ä¾èµ–ä¸»æœºå†…å­˜å¸¦å®½**ï¼Œè‹¥host memoryä¸è¶³æˆ–NVMeå‚ä¸ï¼Œåˆ™å»¶è¿Ÿä¸å¯éšè—ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³**å¤šèŠ‚ç‚¹è®­ç»ƒ**ï¼Œç»“åˆZero-Infinityç­‰NVMe offloadingæŠ€æœ¯ã€‚
- æ¢ç´¢**æ›´ç»†ç²’åº¦çš„é‡åŒ–ç­–ç•¥**ï¼ˆå¦‚per-channel FP8 scalingï¼‰ã€‚
- æ”¯æŒæ›´å¤š**parameter-efficient fine-tuningï¼ˆPEFTï¼‰æ–¹æ³•**ï¼ˆå¦‚LoRAï¼‰ä»¥è¿›ä¸€æ­¥é™ä½å†…å­˜éœ€æ±‚ã€‚
- é’ˆå¯¹**Blackwellæ¶æ„ç‰¹æ€§**ï¼ˆå¦‚åŸç”ŸFP8 transposeæ”¯æŒï¼‰è¿›è¡Œæ·±åº¦ä¼˜åŒ–ã€‚
- å¼€å‘è‡ªåŠ¨åŒ–å·¥å…·ï¼Œæ ¹æ®ç¡¬ä»¶è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜çš„recompute/offload/batché…ç½®ã€‚

---

> ğŸ”— **ä»£ç åœ°å€**ï¼š[https://github.com/IST-DASLab/llmq](https://github.com/IST-DASLab/llmq)  
> ğŸ“„ **åŸæ–‡é“¾æ¥**ï¼š[arXiv:2512.15306](https://arxiv.org/abs/2512.15306)

</details>

---

### 5. [Dynamic Rebatching for Efficient Early-Exit Inference with DREX](https://arxiv.org/abs/2512.15705)

**Authors**: Xuting Liu, Daniel Alexander, Siva Kesava Reddy Kakarla, Behnaz Arzani, Vincent Liu  
**Category**: cs.DC  
**Published**: 2025-12-18  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.15705v1  

#### Abstract
Early-Exit (EE) is a Large Language Model (LLM) architecture that accelerates inference by allowing easier tokens to be generated using only a subset of the model's layers. However, traditional batching frameworks are ill-suited for EE LLMs, as not all requests in a batch may be ready to exit at the...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šDynamic Rebatching for Efficient Early-Exit Inference with DREX**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
ä¼ ç»Ÿ **Early-Exit (EE)** æ¨ç†åœ¨ **æ‰¹å¤„ç†ï¼ˆbatchingï¼‰** åœºæ™¯ä¸‹é¢ä¸´ä¸¥é‡æŒ‘æˆ˜ï¼š
- **Grouped Exit Policies**ï¼ˆå¦‚ Consensusã€Majorityã€Greedyï¼‰å¼ºåˆ¶æ•´ä¸ª batch ç»Ÿä¸€å†³å®šæ˜¯å¦é€€å‡ºï¼Œå¯¼è‡´ä¸¤ç±»é—®é¢˜ï¼š
  - **Involuntary Exits**ï¼šæœ¬åº”ç»§ç»­è®¡ç®—çš„è¯·æ±‚è¢«å¼ºåˆ¶æå‰é€€å‡ºï¼ŒæŸå®³è¾“å‡ºè´¨é‡ã€‚
  - **Involuntary Stays**ï¼šå·²æ»¡è¶³é€€å‡ºæ¡ä»¶çš„è¯·æ±‚è¢«è¿«ç»§ç»­è®¡ç®—ï¼Œæµªè´¹ç®—åŠ›ï¼Œé™ä½ååé‡ã€‚
- æ­¤å¤–ï¼ŒEE ä¼šè·³è¿‡ä¸­é—´å±‚ï¼Œå¯¼è‡´åç»­è§£ç æ‰€éœ€çš„ **KV Cache ç¼ºå¤±**ï¼Œå½±å“è‡ªå›å½’æ¨ç†ã€‚

è¿™äº›é—®é¢˜ä½¿å¾— EE åœ¨å®é™…éƒ¨ç½²ä¸­éš¾ä»¥å‘æŒ¥å…¶ç†è®ºä¸Šçš„æ•ˆç‡ä¼˜åŠ¿ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ï¼šDREX ä¸ Dynamic Rebatching**

è®ºæ–‡æå‡ºäº† **DREX**ï¼Œé¦–ä¸ªæ”¯æŒé«˜æ•ˆæ‰¹å¤„ç† EE æ¨ç†çš„æœåŠ¡ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒæ˜¯ **Dynamic Rebatching** æŠ€æœ¯ï¼š

#### **æ ¸å¿ƒæ€æƒ³**
- ä¸å†å¯¹æ•´ä¸ª batch å¼ºåˆ¶ç»Ÿä¸€çš„ EE å†³ç­–ã€‚
- å½“å‡ºç°â€œåˆ†è£‚å†³ç­–â€æ—¶ï¼ˆéƒ¨åˆ†è¯·æ±‚å¯ EEï¼Œéƒ¨åˆ†ä¸èƒ½ï¼‰ï¼š
  - å…è®¸æ»¡è¶³æ¡ä»¶çš„è¯·æ±‚ç«‹å³é€€å‡ºå¹¶ç”Ÿæˆ tokenã€‚
  - å°†æœªé€€å‡ºçš„è¯·æ±‚æš‚å­˜äºä¸€ä¸ª **é€»è¾‘ç¼“å†²åŒºï¼ˆlogical bufferï¼‰**ã€‚
  - å½“ç¼“å†²åŒºç§¯ç´¯è¶³å¤Ÿå¤šè¯·æ±‚åï¼Œé‡æ–°ç»„ç»‡æˆæ–° batch è¿›å…¥æ·±å±‚ç½‘ç»œã€‚

è¿™å®ç°äº†ï¼š
- âœ… æ¯ä¸ªè¯·æ±‚ç‹¬ç«‹å†³ç­–ï¼Œ**å®Œå…¨æ¶ˆé™¤ involuntary exits**ã€‚
- âœ… æœ€å¤§åŒ–åˆ©ç”¨ EE æœºä¼šï¼Œæå‡ååã€‚

---

### **å…³é”®æŠ€æœ¯ä¼˜åŒ–**

1. **Copy-Free Rebatching Buffer**
   - åˆ©ç”¨ç°ä»£æ³¨æ„åŠ›å†…æ ¸ï¼ˆå¦‚ FlashAttentionï¼‰çš„ `cache_batch_idx` APIï¼Œé€šè¿‡ **è™šæ‹Ÿå¼ é‡ç´¢å¼•ï¼ˆvirtual tensor indexingï¼‰** å®ç°é›¶æ‹·è´é‡ç»„ã€‚
   - é¿å…ç‰©ç†ç§»åŠ¨éšè—çŠ¶æ€å’Œ KV Cacheï¼Œæ˜¾è‘—é™ä½ rebatching å¼€é”€ï¼ˆ<6% æ ‡å‡†è¿­ä»£æ—¶é—´ï¼‰ã€‚

2. **Memory-Efficient State-Copying**
   - è§£å†³è·³è¿‡å±‚ç¼ºå¤± KV Cache çš„é—®é¢˜ã€‚
   - ä½¿ç”¨ **è™šæ‹Ÿå†…å­˜æ˜ å°„ï¼ˆvirtual memory mappingï¼‰**ï¼Œå°†æ‰€æœ‰è·³è¿‡å±‚çš„ KV Cache æ˜ å°„åˆ°æœ€åä¸€å±‚çš„å®é™…å†…å­˜å—ã€‚
   - å®ç°å…±äº«åªè¯»å†…å­˜ï¼Œé¿å…å†—ä½™å¤åˆ¶ï¼Œå‡å°‘æœ€å¤š **18.3% CUDA å†…å­˜å ç”¨**ã€‚

3. **Adaptive Rebatching Threshold (ART)**
   - åˆ†æ rebatching çš„å¼€é”€ï¼ˆcï¼‰ä¸ EE èŠ‚çœçš„è®¡ç®—é‡ï¼ˆsavingsï¼‰ï¼ŒåŠ¨æ€åˆ¤æ–­æ˜¯å¦å€¼å¾—è¿›è¡Œ rebatchingã€‚
   - åªæœ‰å½“ EE è¯·æ±‚æ•°é‡è¶…è¿‡é˜ˆå€¼æ—¶æ‰è§¦å‘ rebatchingï¼Œé¿å…â€œå¾—ä¸å¿å¤±â€çš„æ“ä½œã€‚
   - æå‡ååè¾¾ **9%**ã€‚

4. **SLA-Aware Forced Flushing**
   - ç¼“å†²åŒºä¸­çš„è¯·æ±‚å¯èƒ½å› ç­‰å¾…è€Œå»¶è¿Ÿã€‚
   - å¼•å…¥åŸºäº SLA çš„åˆ·æ–°æœºåˆ¶ï¼šè‹¥è¯·æ±‚æ¥è¿‘æˆªæ­¢æ—¶é—´ï¼Œåˆ™å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒºï¼Œä¿éšœå»¶è¿Ÿã€‚
   - å¹³å‡ RCT æ”¹å–„ **58.4%**ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | DREX | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Apparateã€[31]ï¼‰ |
|------|------|-----------------------------|
| **EE å†³ç­–ç²’åº¦** | Per-request ç‹¬ç«‹å†³ç­– | Batch-wise ç»Ÿä¸€å†³ç­– |
| **Involuntary Exits** | **0%**ï¼ˆå®Œå…¨æ¶ˆé™¤ï¼‰ | é«˜å‘ï¼ˆå°¤å…¶ Greedyï¼‰ |
| **KV Cache ç®¡ç†** | è™šæ‹Ÿæ˜ å°„ï¼Œæ— å†—ä½™ | ç‰©ç†å¤åˆ¶æˆ–é‡è®¡ç®—ï¼Œä½æ•ˆ |
| **Rebatching å¼€é”€æ§åˆ¶** | è‡ªé€‚åº”é˜ˆå€¼ï¼ˆARTï¼‰ | å›ºå®šç­–ç•¥ï¼Œæ˜“å¼•å…¥è´Ÿæ”¶ç›Š |
| **SLA ä¿éšœ** | ä¸»åŠ¨åˆ·æ–°æœºåˆ¶ | å¿½ç•¥å»¶è¿Ÿå½±å“ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›†**
- **æ¨¡å‹**ï¼š
  - `Llama-EE-13B`, `Llama-EE-70B`, `Qwen-EE-14B`
  - å‡åŸºäº Apparate æ¶æ„æ·»åŠ  EE rampï¼ˆSoftmax ç½®ä¿¡åº¦åˆ†ç±»å™¨ï¼‰
- **æ•°æ®é›†**ï¼šCNN/Daily Mail æ–°é—»æ‘˜è¦ä»»åŠ¡ï¼ˆæ¥è‡ª HELM benchmarkï¼‰
  - è¿‡æ»¤ä¸º <2048 tokens çš„æ¡ç›®ï¼Œå…± 2160 æ¡æ ·æœ¬
- **ç¡¬ä»¶**ï¼š
  - 13B/14Bï¼šNVIDIA A100 (80GB)
  - 70Bï¼šNVIDIA H200 (141GB)

---

### **å®éªŒè®¾ç½®**
- **Batch Size**ï¼š4 å’Œ 8
- **EE é…ç½®**ï¼šæ¯æ¨¡å‹ä¸¤ç§é…ç½®ï¼ˆä¸åŒ ramp å±‚ + ç½®ä¿¡åº¦é˜ˆå€¼ï¼‰ï¼Œè§ Table 3
- **è¯„ä¼°é˜¶æ®µ**ï¼šDecode Phaseï¼ˆè‡ªå›å½’ç”Ÿæˆï¼‰

---

### **è¯„ä¼°æŒ‡æ ‡**

| ç±»åˆ« | æŒ‡æ ‡ | å®šä¹‰ |
|------|------|------|
| **æ€§èƒ½** | Throughput | è¾“å‡º token æ•° / ç§’ |
|       | RCT (Request Completion Time) | è¯·æ±‚ä»è°ƒåº¦åˆ°å®Œæˆçš„æ—¶é—´ |
| **è´¨é‡** | P95 Confidence Score | æ‰€æœ‰ EE token ä¸­ç½®ä¿¡åº¦æœ€ä½çš„ 5%ï¼Œåæ˜ æœ€å·®æƒ…å†µä¸‹çš„è¾“å‡ºå¯é æ€§ |
|       | BERT Score | ç”Ÿæˆæ‘˜è¦ä¸å‚è€ƒæ‘˜è¦çš„è¯­ä¹‰ç›¸ä¼¼åº¦ |
| **EE ç»Ÿè®¡** | EE Proportion | æ—©æœŸé€€å‡º token å æ€» token æ•°æ¯”ä¾‹ |
|           | Involuntary Exit (%) | è¢«è¿«æå‰é€€å‡ºçš„ token æ¯”ä¾‹ |
|           | Involuntary Stay (%) | è¢«è¿«ç»§ç»­è®¡ç®—çš„ token æ¯”ä¾‹ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Latency-only**ï¼ˆApparateï¼‰ï¼šå…è®¸ EE ä½†ä¿ç•™è¯·æ±‚åœ¨ batch ä¸­ â†’ ä½å»¶è¿Ÿä½†ä½åå
- **Consensus**ï¼šå…¨ batch åŒæ„æ‰ EE â†’ é«˜è´¨é‡ä½† EE æœºä¼šå°‘
- **Majority**ï¼šå¤šæ•°æŠ•ç¥¨å†³å®š EE
- **Greedy**ï¼šä»»ä¸€è¯·æ±‚æƒ³ EE å°±å…¨ä½“é€€å‡º â†’ é«˜ååä½†è´¨é‡æå·®
- **Non-EE**ï¼šæ—  EE çš„æ ‡å‡†æ¨ç†

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

| æ¨¡å‹ | æ–¹æ³• | Throughput æå‡ | P95 Confidence | Involuntary Exit |
|------|------|------------------|----------------|------------------|
| Llama-EE-70B | DREX (Rebatching) | **+12%** vs Non-EE | â‰ˆ0.8ï¼ˆæœ€é«˜ï¼‰ | **0%** |
| Llama-EE-13B | DREX | **+2â€“10.3%** vs å…¶ä»– EE æ–¹æ³• | >0.75 | 0% |
| Qwen-EE-14B | DREX | æ˜¾è‘—ä¼˜äºåŸºçº¿ | ä¿æŒé«˜ä½ | 0% |

- **KV Cache å†…å­˜èŠ‚çœ**ï¼šå¹³å‡å‡å°‘ **5.7%**ï¼Œæœ€å¤šè¾¾ **18.3%**ï¼ˆGreedy ä¸‹ï¼‰
- **Rebatching å¼€é”€**ï¼š<6% æ ‡å‡†è¿­ä»£æ—¶é—´ï¼ˆLlama-EE-70Bï¼‰

---

### **ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ**

#### **åå vs è´¨é‡æƒè¡¡ï¼ˆFigure 8, 9ï¼‰**
- **Greedy**ï¼šååæœ€é«˜ï¼Œä½† P95 Confidence ä»… **0.03**ï¼ˆæä½ï¼‰ï¼ŒBERT Score æœ€å·®ã€‚
- **Consensus**ï¼šè´¨é‡é«˜ï¼Œä½† EE æ¯”ä¾‹æä½ï¼Œååç”šè‡³ä½äº Non-EEï¼ˆå› æ£€æŸ¥å¼€é”€ï¼‰ã€‚
- **DREX**ï¼š
  - ååæ¯” Consensus/Majority é«˜ **2â€“12%**
  - è´¨é‡ä¸ Consensus ç›¸å½“ï¼Œè¿œè¶… Greedy
  - **å”¯ä¸€å®ç° 0% involuntary exits çš„æ–¹æ³•**

#### **EE æ¯”ä¾‹åˆ†æï¼ˆFigure 9ï¼‰**
- DREX å®ç°ç¬¬äºŒé«˜çš„ EE æ¯”ä¾‹ï¼Œä½† **involuntary exits ä¸º 0**
- Greedy çš„ EE æ¯”ä¾‹ >97%ï¼Œä½†å…¶ä¸­ **>35% æ˜¯ involuntary**

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **Adaptive Rebatching Threshold (ART) çš„å½±å“ï¼ˆTable 5ï¼‰**
- åœ¨ Llama-EE-13B ä¸Šï¼Œæœ€ä¼˜ ART = 3ï¼ˆå³è‡³å°‘ 4 ä¸ªè¯·æ±‚ EE æ‰ rebatchï¼‰
- ç›¸æ¯” ART=0ï¼ˆæ€»æ˜¯ rebatchï¼‰ï¼Œååæå‡ **9%**
- è¯´æ˜ï¼šç›²ç›® rebatching åè€Œé™ä½æ€§èƒ½ï¼Œ**è‡ªé€‚åº”é˜ˆå€¼è‡³å…³é‡è¦**

#### **SLA-Aware Flushingï¼ˆFigure 12ï¼‰**
- æ—  SLA å‹åŠ›æ—¶ï¼šååæ¯” Consensus é«˜ **11.4%**
- é«˜ SLA å‹åŠ›æ—¶ï¼šè‡ªåŠ¨åˆ‡æ¢è‡³ä¿å®ˆç­–ç•¥ï¼Œä¿éšœå»¶è¿Ÿï¼Œ**å¹³å‡ RCT æ”¹å–„ 58.4%**

#### **å¤šå‡ºå£åœºæ™¯ï¼ˆFigure 11ï¼‰**
- åœ¨ Llama-EE-70B è®¾ç½®ä¸¤ä¸ª EE ramp
- DREX æ¯” Greedy ååç•¥ä½ï¼Œä½† **BERT Score é«˜ 11%**
- è¡¨æ˜ DREX æ›´å¥½åœ°å¹³è¡¡äº†æ•ˆç‡ä¸è´¨é‡

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **Dynamic Rebatching æ˜¯ EE æ‰¹å¤„ç†çš„å…³é”®çªç ´**ï¼š
   - è§£è€¦äº† EE å†³ç­–ä¸ batch åŒæ­¥çº¦æŸï¼Œé‡Šæ”¾äº† EE çš„çœŸå®æ½œåŠ›ã€‚
2. **DREX å®ç°äº†ååä¸è´¨é‡çš„åŒèµ¢**ï¼š
   - ååæå‡ **2â€“12%**
   - **å®Œå…¨æ¶ˆé™¤ involuntary exits**ï¼Œä¿è¯è¾“å‡ºè´¨é‡
   - P95 Confidence å’Œ BERT Score å‡ä¼˜äºæˆ–ç­‰äºå…¶ä»– EE æ–¹æ³•
3. **ç³»ç»Ÿçº§ä¼˜åŒ–è‡³å…³é‡è¦**ï¼š
   - Copy-free buffer å’Œ virtual state-copying æå¤§é™ä½äº† EE å¼€é”€ã€‚
   - ART å’Œ SLA-aware è°ƒåº¦ä½¿ç³»ç»Ÿæ›´æ™ºèƒ½ã€é²æ£’ã€‚

---

### **å±€é™æ€§**
- å½“å‰å®ç°ä¾èµ–äºæ”¯æŒè™šæ‹Ÿç´¢å¼•çš„ attention kernelï¼ˆå¦‚ FlashAttentionï¼‰ã€‚
- å¯¹æç«¯å° batch æˆ–ä½è´Ÿè½½åœºæ™¯ä¼˜åŒ–ç©ºé—´æœ‰é™ã€‚
- æœªæ¢ç´¢ä¸å…¶ä»–åŠ¨æ€è®¡ç®—æŠ€æœ¯ï¼ˆå¦‚ Speculative Decodingï¼‰çš„ç»“åˆã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•è‡³æ›´å¤š EE æ¶æ„ï¼ˆå¦‚ CALMã€DEEDã€FREEï¼‰ã€‚
- ç»“åˆ **Speculative Decoding** ä¸ Dynamic Rebatchingã€‚
- æ¢ç´¢ **å¼‚æ„ç¡¬ä»¶**ï¼ˆCPU+GPUï¼‰ä¸‹çš„ rebatching ç­–ç•¥ã€‚
- è‡ªåŠ¨åŒ– EE ramp ä½ç½®ä¸é˜ˆå€¼è°ƒä¼˜ï¼ˆä¸ Apparateã€HELIOS è”åŠ¨ï¼‰ã€‚

---

> **æ€»ç»“**ï¼š  
> DREX æ˜¯é¦–ä¸ªçœŸæ­£è®© **Early-Exit LLM** èµ°å‘å®ç”¨çš„æ¨ç†ç³»ç»Ÿã€‚å®ƒé€šè¿‡ **Dynamic Rebatching** è§£å†³äº†æ‰¹å¤„ç†ä¸ EE çš„æ ¹æœ¬çŸ›ç›¾ï¼Œå¹¶è¾…ä»¥å¤šé¡¹ç³»ç»Ÿçº§ä¼˜åŒ–ï¼Œåœ¨ä¸ç‰ºç‰²è´¨é‡çš„å‰æä¸‹æ˜¾è‘—æå‡äº†ååã€‚è¯¥å·¥ä½œä¸ºé«˜æ•ˆ LLM æ¨ç†æä¾›äº†æ–°çš„èŒƒå¼ã€‚

</details>

---

### 6. [Bits for Privacy: Evaluating Post-Training Quantization via Membership Inference](https://arxiv.org/abs/2512.15335)

**Authors**: Chenxiang Zhang, Tongxi Qu, Zhong Li, Tian Zhang, Jun Pang, Sjouke Mauw  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.15335v1  

#### Abstract
Deep neural networks are widely deployed with quantization techniques to reduce memory and computational costs by lowering the numerical precision of their parameters. While quantization alters model parameters and their outputs, existing privacy analyses primarily focus on full-precision models, le...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šBits for Privacy: Evaluating Post-Training Quantization via Membership Inference**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
æœ¬æ–‡ç³»ç»Ÿç ”ç©¶äº†**Post-Training Quantization (PTQ)** å¯¹æ¨¡å‹éšç§çš„å½±å“ï¼Œå¡«è¡¥äº†å½“å‰ç ”ç©¶ä¸­å¯¹é‡åŒ–æ¨¡å‹éšç§åˆ†æçš„ç©ºç™½ã€‚å°½ç®¡ PTQ è¢«å¹¿æ³›ç”¨äºæå‡æ¨ç†æ•ˆç‡ï¼Œä½†å…¶åœ¨é™ä½å‚æ•°ç²¾åº¦è¿‡ç¨‹ä¸­å¯èƒ½æ”¹å˜æ¨¡å‹è¾“å‡ºåˆ†å¸ƒï¼Œä»è€Œå½±å“éšç§æ³„éœ²é£é™©ã€‚ç„¶è€Œï¼Œç°æœ‰éšç§åˆ†æå¤šé›†ä¸­äºå…¨ç²¾åº¦æ¨¡å‹ï¼Œç¼ºä¹å¯¹ä¸åŒé‡åŒ–ä½å®½ä¸‹éšç§-æ•ˆç”¨æƒè¡¡çš„æ·±å…¥ç†è§£ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
- é¦–æ¬¡å°† **Membership Inference Attack (MIA)** ä½œä¸ºè¯„ä¼°å·¥å…·ï¼Œç³»ç»Ÿåˆ†æå¤šç§å…ˆè¿› PTQ æ–¹æ³•ï¼ˆAdaRoundã€BRECQã€OBCï¼‰åœ¨ä¸åŒé‡åŒ–ç²¾åº¦ï¼ˆ4-bitã€2-bitã€1.58-bitï¼‰ä¸‹çš„éšç§è¡¨ç°ã€‚
- å¼•å…¥å¹¶é€‚é…äº† **1.58-bit quantization** åˆ° PTQ åœºæ™¯ï¼ŒåŸºäº ternary æƒé‡ {-1,0,1} å®ç°æä½æ¯”ç‰¹å‹ç¼©ï¼Œå¹¶éªŒè¯å…¶åœ¨éšç§ä¿æŠ¤ä¸­çš„æ½œåŠ›ã€‚
- æå‡ºâ€œ**decoupled quantization**â€ç­–ç•¥ï¼šä»…å°†æœ€åä¸€å±‚ä»¥æ›´é«˜ç²¾åº¦ï¼ˆå¦‚ 8-bitï¼‰ä¿ç•™ï¼Œå…¶ä½™å±‚ä¿æŒä½æ¯”ç‰¹é‡åŒ–ï¼Œå®ç°å¯¹éšç§-æ•ˆç”¨å…³ç³»çš„ç»†ç²’åº¦æ§åˆ¶ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **æ›´è´´è¿‘å®é™…éƒ¨ç½²åœºæ™¯**ï¼šèšç„¦æ— éœ€é‡æ–°è®­ç»ƒçš„ PTQ æ–¹æ³•ï¼Œé€‚ç”¨äºå·¥ä¸šç•Œå¹¿æ³›ä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹å‹ç¼©æµç¨‹ã€‚
- **æ›´å¼ºçš„æ”»å‡»åŸºå‡†**ï¼šé‡‡ç”¨å½“å‰æœ€å…ˆè¿›çš„ **LiRA (Likelihood Ratio Attack)** åœ¨çº¿ä¸ç¦»çº¿ç‰ˆæœ¬è¿›è¡Œ MIA è¯„ä¼°ï¼Œå°¤å…¶æ˜¯åœ¨çº¿æ”»å‡»æ›´å…·æŒ‘æˆ˜æ€§å’Œç°å®å¨èƒæ€§ã€‚
- **å…¨é¢çš„æƒè¡¡åˆ†æ**ï¼šä¸ä»…æŠ¥å‘Šå‡†ç¡®ç‡ä¸‹é™ï¼Œè¿˜é€šè¿‡ **TPR@0.1%FPR** è¿™ä¸€æ•æ„ŸæŒ‡æ ‡è¡¡é‡éšç§æ³„éœ²ç¨‹åº¦ï¼Œæ­ç¤ºé‡åŒ–ç²¾åº¦å¯ä½œä¸ºè°ƒèŠ‚éšç§ä¿æŠ¤å¼ºåº¦çš„â€œæ—‹é’®â€ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†**
- **CIFAR-10**ï¼š10 ç±»å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œ32Ã—32 å½©è‰²å›¾åƒã€‚
- **CIFAR-100**ï¼š100 ç±»æ›´å¤æ‚å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼ŒåŒåˆ†è¾¨ç‡ã€‚
- **TinyImageNet**ï¼š200 ç±»ï¼Œ64Ã—64 å›¾åƒï¼Œæ›´å…·æŒ‘æˆ˜æ€§çš„å­é›†ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **æ¨¡å‹æ¶æ„**ï¼šä¸»è¦ä½¿ç”¨ **ResNet18**ï¼Œéƒ¨åˆ†æ¶ˆèå®éªŒæ‰©å±•è‡³ ResNet50 å’Œ DenseNet121ã€‚
- **PTQ æ–¹æ³•**ï¼š
  - **AdaRound**
  - **BRECQ**
  - **OBC**
- **é‡åŒ–ä½å®½**ï¼š32-bitï¼ˆå…¨ç²¾åº¦ï¼‰ã€4-bitã€2-bitã€1.58-bitï¼ˆternaryï¼‰
- **é‡åŒ–æ–¹å¼**ï¼šä»…å¯¹æƒé‡è¿›è¡Œ per-channel asymmetric quantizationï¼Œæ¿€æ´»å‡½æ•°ä¿æŒå…¨ç²¾åº¦ã€‚
- **æ ¡å‡†æ•°æ®**ï¼šä»è®­ç»ƒé›†ä¸­éšæœºé€‰å– 1024 ä¸ªæ ·æœ¬ç”¨äº PTQ æ ¡å‡†ï¼Œç¡®ä¿æ— é¢å¤–æ•°æ®æ³„éœ²ã€‚
- **MIA æ”»å‡»æ–¹æ³•**ï¼š
  - **LiRA Online Attack**ï¼šè®­ç»ƒ 64 ä¸ª shadow modelsï¼ˆä¸€åŠå«ç›®æ ‡æ ·æœ¬ï¼‰ï¼Œä¼°è®¡æŸå¤±åˆ†å¸ƒã€‚
  - **LiRA Offline Attack with Fixed Variance**ï¼šæ›´é«˜æ•ˆï¼Œä½†ä»å…·å¼ºæ”»å‡»èƒ½åŠ›ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Utility**ï¼šæµ‹è¯•å‡†ç¡®ç‡ï¼ˆTest Accuracyï¼‰
  - **Privacy Leakage**ï¼š
    - **TPR@0.1%FPR**ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼Œåæ˜ ä½è¯¯æŠ¥ç‡ä¸‹çš„çœŸå®æ³„éœ²é£é™©ï¼‰
    - log-AUROCï¼ˆè¾…åŠ©æŒ‡æ ‡ï¼‰

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
#### **(1) å‡†ç¡®ç‡è¡¨ç°ï¼ˆUtilityï¼‰**
| æ•°æ®é›† | æ–¹æ³• | 4-bit Acc (%) | 2-bit Acc (%) | 1.58-bit Acc (%) |
|--------|------|----------------|----------------|--------------------|
| CIFAR-100 | Full Precision | 70.22 | â€” | â€” |
| | AdaRound | ~70 | ~69.7 | **62.35** |
| | BRECQ | ~70 | ~69.8 | **67.61** |
| | OBC | ~70 | ~69.3 | **64.34** |

> æ³¨ï¼š4-bit é‡åŒ–å‡ ä¹æ— ç²¾åº¦æŸå¤±ï¼›2-bit ç²¾åº¦ç•¥æœ‰ä¸‹é™ï¼›1.58-bit ä¸‹ BRECQ è¡¨ç°æœ€ä¼˜ã€‚

#### **(2) éšç§æ³„éœ²ï¼ˆTPR@0.1%FPRï¼‰â€”â€”ä»¥ CIFAR-100 ä¸ºä¾‹**
| æ–¹æ³• | Full Precision | 4-bit | 2-bit | 1.58-bit |
|------|----------------|-------|-------|----------|
| AdaRound (Online) | 0.3765 | 0.372 | 0.2196 | **0.0031** |
| BRECQ (Online) | 0.3765 | ~0.37 | ~0.2 | **<0.01** |
| OBC (Online) | 0.3765 | ~0.38 | ~0.25 | **<0.01** |

> **å…³é”®å‘ç°**ï¼š1.58-bit é‡åŒ–ä½¿ TPR ä¸‹é™ **è¶…è¿‡ä¸€ä¸ªæ•°é‡çº§ï¼ˆ~99% reductionï¼‰**ï¼Œæ˜¾è‘—å¢å¼ºéšç§ä¿æŠ¤ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **4-bit PTQ**ï¼šéšç§æ³„éœ²æ°´å¹³ä¸å…¨ç²¾åº¦æ¨¡å‹ç›¸å½“ï¼ˆç”šè‡³ç•¥é«˜ï¼‰ï¼Œè¯´æ˜å¸¸è§„è½»é‡é‡åŒ–**ä¸æä¾›é¢å¤–éšç§å¢ç›Š**ã€‚
- **2-bit PTQ**ï¼šå¸¦æ¥é€‚åº¦éšç§æ”¹å–„ï¼ˆTPR ä¸‹é™çº¦ 40â€“50%ï¼‰ï¼Œä½†æ”¶ç›Šæœ‰é™ã€‚
- **1.58-bit PTQ**ï¼šå®ç°**æ˜¾è‘—éšç§æå‡**ï¼ŒTPR å¯é™è‡³ 0.001â€“0.01 åŒºé—´ï¼ŒåŒæ—¶ä»ç»´æŒå¯ç”¨å‡†ç¡®ç‡ï¼ˆå°¤å…¶ BRECQï¼‰ã€‚
- æ‰€æœ‰ä¸‰ç§ PTQ æ–¹æ³•åœ¨æç«¯ä½ä½å®½ä¸‹å‡è¡¨ç°å‡ºä¸€è‡´è¶‹åŠ¿ï¼š**è¶Šä½ç²¾åº¦ â†’ è¶Šå¥½éšç§ä¿æŠ¤**ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **(1) Decoupled Quantizationï¼ˆè§£è€¦é‡åŒ–ï¼‰**
- å°†æœ€åä¸€å±‚è®¾ä¸º 8-bitï¼Œå…¶ä½™å±‚ä¸º 1.58-bit æˆ– 2-bitã€‚
- **æ•ˆæœ**ï¼š
  - åœ¨ **TinyImageNet** ä¸Šï¼ŒAdaRound çš„å‡†ç¡®ç‡ä» 33%ï¼ˆ1.58-bit å…¨å±€ï¼‰æ¢å¤åˆ° **52.4%**ï¼ˆä»…æœ€åå±‚ 8-bitï¼‰ã€‚
  - åŒæ—¶ï¼ŒTPR@0.1%FPR ä»è¿œä½äºå…¨ç²¾åº¦æ¨¡å‹ï¼ˆå¦‚ä» 0.53 é™è‡³ <0.1ï¼‰ã€‚
- **æ„ä¹‰**ï¼šå¯åœ¨å‡ ä¹ä¸ç‰ºç‰²éšç§çš„å‰æä¸‹å¤§å¹…æå‡æ¨¡å‹å®ç”¨æ€§ï¼Œæä¾›çµæ´»è°ƒæ§æ‰‹æ®µã€‚

#### **(2) ä¸åŒæ¨¡å‹æ¶æ„æ³›åŒ–æ€§**
- åœ¨ **ResNet18 / ResNet50 / DenseNet121** ä¸Šåº”ç”¨ OBC è¿›è¡Œé‡åŒ–ã€‚
- ç»“æœæ˜¾ç¤ºï¼šæ— è®ºç½‘ç»œæ·±åº¦æˆ–ç»“æ„å¦‚ä½•ï¼Œ**æ›´ä½é‡åŒ–ä½å®½å§‹ç»ˆä¼´éšæ›´ä½å‡†ç¡®ç‡å’Œæ›´ä½ TPR**ï¼ŒéªŒè¯ç»“è®ºå…·æœ‰æ™®é€‚æ€§ã€‚

#### **(3) 1.58-bit æ¨¡å‹çš„æ–¹å·®åˆ†æ**
- BRECQ åœ¨ 1.58-bit ä¸‹è¡¨ç°å‡ºè¾ƒå¤§ TPR æ–¹å·®ï¼ˆæŸäº›è¿è¡Œéšç§æå¥½ï¼ŒæŸäº›è¾ƒå·®ï¼‰ï¼Œä½†å¹³å‡è€Œè¨€ä»ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚
- è¡¨æ˜ PTQ è¿‡ç¨‹å­˜åœ¨éšæœºæ€§ï¼Œéœ€å¤šæ¬¡è¿è¡Œé€‰æ‹©ç¨³å¥æ¨¡å‹ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **ä½ä½å®½ PTQ æ˜¾è‘—é™ä½ MIA æˆåŠŸç‡**ï¼šç‰¹åˆ«æ˜¯ **1.58-bit é‡åŒ–**å¯å°† TPR@0.1%FPR é™ä½ **è¾¾ 99%ä»¥ä¸Š**ï¼Œæ˜¯æœ‰æ•ˆçš„éšç§å¢å¼ºæ‰‹æ®µã€‚
2. âš–ï¸ **å­˜åœ¨æ˜ç¡®çš„ privacy-utility trade-off**ï¼š
   - 4-bitï¼šæ•ˆç”¨é«˜ï¼Œéšç§æ— æ”¹å–„ï¼›
   - 2-bitï¼šè½»å¾®æ•ˆç”¨æŸå¤±ï¼Œé€‚åº¦éšç§å¢ç›Šï¼›
   - 1.58-bitï¼šæ˜¾è‘—éšç§æå‡ï¼Œä½†æ•ˆç”¨æ˜æ˜¾ä¸‹é™ã€‚
3. ğŸ”§ **Decoupled quantization æ˜¯å®ç”¨è§£å†³æ–¹æ¡ˆ**ï¼šé€šè¿‡æé«˜æœ€åä¸€å±‚ç²¾åº¦ï¼Œå¯åœ¨ä¿ç•™å¤§éƒ¨åˆ†éšç§ä¼˜åŠ¿çš„åŒæ—¶å¤§å¹…æ¢å¤å‡†ç¡®ç‡ã€‚
4. ğŸ“ˆ **BRECQ åœ¨æç«¯é‡åŒ–ä¸‹ç»¼åˆè¡¨ç°æœ€ä½³**ï¼šåœ¨ 1.58-bit ä¸‹è¾¾åˆ°æœ€é«˜å‡†ç¡®ç‡å’Œæœ€ä½å¹³å‡ TPRï¼Œé€‚åˆè¿½æ±‚æè‡´å‹ç¼©ä¸éšç§å¹³è¡¡çš„åœºæ™¯ã€‚
5. ğŸ”„ **ç»“è®ºè·¨æ•°æ®é›†ã€è·¨æ¶æ„ç¨³å®šæˆç«‹**ï¼šåœ¨ CIFAR-10ã€CIFAR-100ã€TinyImageNet åŠå¤šç§ DNN æ¶æ„ä¸Šå‡è§‚å¯Ÿåˆ°ä¸€è‡´è¶‹åŠ¿ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä»…è¯„ä¼°è§†è§‰ä»»åŠ¡**ï¼šå®éªŒé›†ä¸­åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼ˆCIFAR/TinyImageNetï¼‰ï¼Œæœªæ¶‰åŠ NLP æˆ–å›¾ç¥ç»ç½‘ç»œç­‰å…¶ä»–æ¨¡æ€ã€‚
- **æœªåŒ…å«æ¿€æ´»é‡åŒ–**ï¼šæ‰€æœ‰å®éªŒä»…å¯¹æƒé‡è¿›è¡Œé‡åŒ–ï¼Œè‹¥æ¿€æ´»ä¹Ÿå‚ä¸é‡åŒ–ï¼Œå¯èƒ½è¿›ä¸€æ­¥å½±å“éšç§è¡Œä¸ºã€‚
- **ä¾èµ–ç»éªŒæ€§è¯„ä¼°**ï¼šç¼ºä¹ç†è®ºè§£é‡Šä¸ºä½•ä½ä½å®½èƒ½æŠ‘åˆ¶ MIAï¼Œç›®å‰ä»…ä¸ºå®è¯è§‚å¯Ÿã€‚
- **shadow model å¼€é”€å¤§**ï¼šLiRA online æ”»å‡»éœ€è¦å¤§é‡ shadow models è®­ç»ƒï¼Œé™åˆ¶å¤§è§„æ¨¡å®éªŒã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ‰©å±•è‡³å…¶ä»–é¢†åŸŸ**ï¼šæ¢ç´¢æ–‡æœ¬ã€è¯­éŸ³ã€å›¾ç»“æ„æ•°æ®ä¸­çš„ PTQ éšç§æ•ˆåº”ã€‚
2. **ç»“åˆå…¶ä»–éšç§æœºåˆ¶**ï¼šç ”ç©¶ PTQ ä¸ **Differential Privacy (DP)**ã€**Federated Learning** ç­‰æŠ€æœ¯è”åˆä½¿ç”¨çš„æ•ˆæœã€‚
3. **ç†è®ºå»ºæ¨¡**ï¼šå»ºç«‹é‡åŒ–å™ªå£°ä¸ MIA æŠµæŠ—åŠ›ä¹‹é—´çš„æ•°å­¦è”ç³»ï¼Œæä¾›å¯è§£é‡Šæ¡†æ¶ã€‚
4. **è‡ªåŠ¨åŒ–è°ƒå‚**ï¼šè®¾è®¡ç®—æ³•è‡ªåŠ¨é€‰æ‹©æ¯å±‚æœ€ä¼˜é‡åŒ–ä½å®½ï¼Œåœ¨ç»™å®šéšç§é¢„ç®—ä¸‹æœ€å¤§åŒ–æ•ˆç”¨ã€‚
5. **scaling law ä¸‹çš„è¡Œä¸ºç ”ç©¶**ï¼šæ¢ç©¶å¤§æ¨¡å‹ï¼ˆå¦‚ ViTã€LLMï¼‰åœ¨ PTQ åçš„éšç§å˜åŒ–è§„å¾‹ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿè¯æ˜ï¼Œ**æç«¯ä½ä½å®½çš„ Post-Training Quantizationï¼ˆå°¤å…¶æ˜¯ 1.58-bitï¼‰æ˜¯ä¸€ç§ç®€å•è€Œé«˜æ•ˆçš„ Membership Inference é˜²å¾¡æ‰‹æ®µ**ï¼Œé€šè¿‡åˆç†è®¾è®¡ï¼ˆå¦‚ decoupled quantizationï¼‰ï¼Œå¯åœ¨ä¿æŒè¾ƒé«˜æ¨¡å‹æ•ˆç”¨çš„åŒæ—¶å®ç°å¼ºéšç§ä¿æŠ¤ï¼Œä¸ºé«˜æ•ˆä¸”å®‰å…¨çš„è¾¹ç¼˜ AI éƒ¨ç½²æä¾›äº†æ–°æ€è·¯ã€‚

</details>

---

### 7. [Sparse Multi-Modal Transformer with Masking for Alzheimer's Disease Classification](https://arxiv.org/abs/2512.14491)

**Authors**: Cheng-Han Lu, Pei-Hsuan Tsai  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.14491v1  

#### Abstract
Transformer-based multi-modal intelligent systems often suffer from high computational and energy costs due to dense self-attention, limiting their scalability under resource constraints. This paper presents SMMT, a sparse multi-modal transformer architecture designed to improve efficiency and robus...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSparse Multi-Modal Transformer with Masking for Alzheimer's Disease Classification

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹å½“å‰åŸºäº **Transformer** çš„å¤šæ¨¡æ€æ™ºèƒ½ç³»ç»Ÿåœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…ï¼ˆAlzheimer's Disease, ADï¼‰åˆ†ç±»ä»»åŠ¡ä¸­é¢ä¸´çš„ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼š
- **é«˜è®¡ç®—ä¸èƒ½è€—æˆæœ¬**ï¼šä¼ ç»Ÿå¯†é›†è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆdense self-attentionï¼‰å¯¼è‡´æ—¶é—´å¤æ‚åº¦ä¸º $O(n^2)$ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹æ‰©å±•ã€‚
- **å¯¹ä¸å®Œæ•´è¾“å…¥æ•æ„Ÿ**ï¼šä¸´åºŠæ•°æ®å¸¸å­˜åœ¨ç¼ºå¤±æ¨¡æ€ï¼ˆmissing modalitiesï¼‰ï¼Œè€Œç°æœ‰æ¨¡å‹ç¼ºä¹æ˜¾å¼æœºåˆ¶æ¥å¤„ç†æ­¤ç±»æƒ…å†µï¼Œå½±å“å®é™…éƒ¨ç½²ä¸­çš„é²æ£’æ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSMMT
ä½œè€…æå‡º **Sparse Multi-Modal Transformer with Masking (SMMT)**ï¼Œä¸€ç§ä»ç³»ç»Ÿå±‚é¢è®¾è®¡çš„é«˜æ•ˆã€é²æ£’çš„å¤šæ¨¡æ€èåˆæ¶æ„ã€‚å…¶ä¸¤å¤§æ ¸å¿ƒåˆ›æ–°ä¸ºï¼š

#### ï¼ˆ1ï¼‰Cluster-based Sparse Attention
- å°†æ¯ä¸ªæ¨¡æ€å†…çš„ token é€šè¿‡ **K-Means èšç±»** åˆ†ç»„ï¼ˆç°‡æ•° $k = \log_2 n$ï¼‰ã€‚
- è‡ªæ³¨æ„åŠ›ä»…åœ¨åŒç°‡å†…è®¡ç®—ï¼Œå°†è®¡ç®—å¤æ‚åº¦ä» $O(n^2)$ é™ä½è‡³ $O(n \log n)$ã€‚
- ä½¿ç”¨æŸ¥è¯¢å‘é‡ï¼ˆquery vectorsï¼‰è¿›è¡Œèšç±»ï¼Œç¡®ä¿è¯­ä¹‰ç›¸å…³ token è¢«èšé›†ï¼Œæå‡ç¨€ç–æ³¨æ„åŠ›çš„æœ‰æ•ˆæ€§ã€‚

#### ï¼ˆ2ï¼‰Modality-wise Masking
- åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹å„æ¨¡æ€ç‰¹å¾è¾“å‡ºæ–½åŠ éšæœºæ©ç ï¼ˆmasking ratio $r=0.3$ï¼‰ï¼Œæ¨¡æ‹ŸçœŸå®åœºæ™¯ä¸‹çš„æ¨¡æ€ç¼ºå¤±ã€‚
- æ¨åŠ¨æ¨¡å‹å­¦ä¹ æ›´é²æ£’çš„è¡¨ç¤ºï¼Œå¢å¼ºåœ¨å°æ ·æœ¬æˆ–éƒ¨åˆ†æ¨¡æ€ç¼ºå¤±æ¡ä»¶ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ•ˆç‡æ›´é«˜**ï¼šæ˜¾è‘—å‡å°‘è®­ç»ƒæ—¶é—´å’Œå†…å­˜å ç”¨ï¼Œé€‚åˆä½èµ„æºç¯å¢ƒã€‚
- **æ›´èŠ‚èƒ½**ï¼šè®­ç»ƒè¿‡ç¨‹èƒ½è€—ä¸‹é™è¶…è¿‡ 40%ï¼Œæœ‰åˆ©äºå¯æŒç»­ AI éƒ¨ç½²ã€‚
- **æ›´å¼ºé²æ£’æ€§**ï¼šåœ¨æ•°æ®ç¨€ç–ï¼ˆå¦‚ä»…ç”¨ 20% æ•°æ®ï¼‰æˆ–æ¨¡æ€ç¼ºå¤±æ—¶ä»ä¿æŒé«˜æ€§èƒ½ã€‚
- **å¯æ‰©å±•æ€§å¼º**ï¼šé€‚ç”¨äºå¤§è§„æ¨¡è¾“å…¥å’Œè¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **ADNI-1 å’Œ ADNI-2** å…¬å¼€æ•°æ®åº“ï¼Œç”¨äºé˜¿å°”èŒ¨æµ·é»˜ç—…ç ”ç©¶ã€‚
- åŒ…å«å¤šæ¨¡æ€æ•°æ®ï¼š
  - **å½±åƒæ•°æ®**ï¼šT1-weighted MRI åˆ‡ç‰‡ï¼ˆå…± 12,680 å¼ ï¼‰
  - **ä¸´åºŠè¯„åˆ†**ï¼šMMSEã€CDRã€FAQ
  - **äººå£ç»Ÿè®¡å­¦ä¿¡æ¯**ï¼šå¹´é¾„ã€æ€§åˆ«
  - **é—ä¼ æ ‡è®°**ï¼šAPOE åŸºå› å‹
- åªä¿ç•™ç¡®è¯Šä¸º **ADï¼ˆAlzheimerâ€™s Diseaseï¼‰** æˆ– **CNï¼ˆCognitively Normalï¼‰** çš„ä¸ªä½“ï¼Œæ’é™¤ MCI æ ·æœ¬ä»¥é¿å…ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚
- æœ€ç»ˆçº³å…¥äººæ•°è§è¡¨ IIï¼ˆæ€»è®¡çº¦ 3,000 åå—è¯•è€…ï¼‰ã€‚

### å®éªŒè®¾ç½®
| é¡¹ç›® | è®¾ç½® |
|------|------|
| æ¡†æ¶ | PyTorch |
| ç¡¬ä»¶ | NVIDIA RTX 3060 GPU (12GB) |
| è®­ç»ƒè½®æ¬¡ | 50 epochs |
| æ‰¹å¤§å° | 8 |
| ä¼˜åŒ–å™¨ | Adam |
| å­¦ä¹ ç‡ | $1 \times 10^{-3}$ |
| æŸå¤±å‡½æ•° | Cross Entropy |
| ç‰¹å¾ç»´åº¦ | 512 |
| æ©ç æ¯”ä¾‹ | 0.3ï¼ˆmodality-level random maskingï¼‰ |
| é‡å¤å®éªŒ | 5 æ¬¡ä¸åŒéšæœºç§å­å–å¹³å‡ |

### è¯„ä¼°æŒ‡æ ‡

#### ï¼ˆ1ï¼‰åˆ†ç±»æ€§èƒ½æŒ‡æ ‡
- **Accuracy**ï¼ˆå‡†ç¡®ç‡ï¼‰
- **Precision**ï¼ˆç²¾ç¡®ç‡ï¼‰
- **Recall / Sensitivity**ï¼ˆå¬å›ç‡ / æ•æ„Ÿæ€§ï¼‰
- **F1-score**
- **Specificity**ï¼ˆç‰¹å¼‚æ€§ï¼‰
- **AUC**ï¼ˆROC æ›²çº¿ä¸‹é¢ç§¯ï¼‰

#### ï¼ˆ2ï¼‰è®¡ç®—å¯æŒç»­æ€§æŒ‡æ ‡ï¼ˆvia CodeCarbonï¼‰
- **æ€»èƒ½é‡æ¶ˆè€—ï¼ˆkWhï¼‰**ï¼šç›‘æµ‹ CPUã€GPUã€RAM åŠŸè€—
- **ç¢³æ’æ”¾é‡ï¼ˆCOâ‚‚, kgï¼‰**ï¼šåŸºäºå°æ¹¾ç”µç½‘ç¢³å¼ºåº¦ï¼ˆ0.502 kgCOâ‚‚/kWhï¼‰ä¼°ç®—

### å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
| æ¨¡å‹ | ç±»å‹è¯´æ˜ |
|------|--------|
| **3MT [8]** | å½“å‰ SOTA å¤šæ¨¡æ€ Transformerï¼Œé‡‡ç”¨çº§è”äº¤å‰æ³¨æ„åŠ›ï¼ˆcascaded cross-attentionï¼‰ |
| **ADDFformer [20]** | åŸºäºç»“æ„ MRI çš„å•æ¨¡æ€ Transformer |
| **FusionNet [21]** | é€šç”¨å¤šæ¨¡æ€èåˆç½‘ç»œï¼ˆæ—  attentionï¼‰ |
| **CNN-only [22]** | åŸºäº VGG16 çš„çº¯å›¾åƒæ¨¡å‹ï¼ˆMRI-onlyï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆ100% æ•°æ®ï¼‰

| æ¨¡å‹ | Accuracy (%) | Sensitivity (%) | Specificity (%) | AUC |
|------|--------------|------------------|------------------|-----|
| **SMMT (Ours)** | **97.05** | **96.31** | **97.58** | **0.986** |
| 3MT [8] | 90.28 | 93.64 | 93.81 | 0.965 |
| ADDFformer [20] | 88.20 | 91.87 | 91.53 | 0.948 |
| FusionNet [21] | 94.28 | 91.01 | 93.24 | 0.956 |
| CNN-only [22] | 80.24 | 78.45 | 80.22 | 0.852 |

> âœ… SMMT åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡è¾¾åˆ°æœ€ä¼˜ï¼Œå°¤å…¶åœ¨ AUC ä¸Šé¢†å…ˆæ˜æ˜¾ã€‚

### å°æ ·æœ¬åœºæ™¯è¡¨ç°ï¼ˆä½æ•°æ® regimeï¼‰

| æ•°æ®æ¯”ä¾‹ | SMMT | 3MT | ADDFformer | FusionNet | CNN-only |
|---------|-------|------|------------|-----------|----------|
| **20%** | **84.96%** | 78.92% | 71.92% | 75.15% | 68.53% |

> ğŸ”¥ åœ¨ä»…ä½¿ç”¨ 20% æ•°æ®æ—¶ï¼ŒSMMT ä»èƒ½ç»´æŒ **84.96% å‡†ç¡®ç‡**ï¼Œè¿œè¶…å…¶ä»–æ¨¡å‹ï¼Œä½“ç°æå¼ºçš„æ•°æ®æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

### è®­ç»ƒæ•ˆç‡å¯¹æ¯”

- **è®­ç»ƒæ—¶é—´ vs æ•°æ®è§„æ¨¡**ï¼ˆå›¾ 5ï¼‰ï¼š
  - SMMT æ˜¯æ‰€æœ‰ Transformer ç±»æ¨¡å‹ä¸­è®­ç»ƒæœ€å¿«çš„ã€‚
  - éšç€æ•°æ®é‡å¢åŠ ï¼ŒSMMT çš„æ‰©å±•æ€§ä¼˜äº 3MTã€‚
- **èƒ½é‡æ¶ˆè€—å¯¹æ¯”**ï¼ˆè¡¨ Vï¼‰ï¼š

| ç»„ä»¶ | 3MT (Baseline) | SMMT | ä¸‹é™å¹…åº¦ |
|------|----------------|--------|----------|
| GPU | 0.283977 kWh | 0.159642 kWh | **-43.8%** |
| CPU | 0.108489 kWh | 0.071179 kWh | -34.4% |
| RAM | 0.051035 kWh | 0.033485 kWh | -34.4% |
| **Total** | **0.443501 kWh** | **0.264306 kWh** | **-40.4%** |

- **ç¢³æ’æ”¾é‡**ï¼š
  - 3MTï¼š0.2226 kgCOâ‚‚
  - SMMTï¼š**0.1327 kgCOâ‚‚** â†’ **å‡å°‘ 40.3%**

> ğŸŒ± èŠ‚èƒ½æ•ˆæœæ˜¾è‘—ï¼Œç›¸å½“äºèŠ‚çœäº†çº¦ 18 æ¬¡æ™ºèƒ½æ‰‹æœºå……ç”µæˆ–ç‚¹äº®ä¸€ä¸ª 60W ç¯æ³¡ 30 å°æ—¶çš„èƒ½é‡ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

| é…ç½® | 100% æ•°æ® Accuracy / Time (min) | 20% æ•°æ® Accuracy |
|------|-------------------------------|------------------|
| 3MT (Baseline) | 90.28 / 133 | 78.92 |
| w/o Sparse Attention | 91.35 / **147** | 84.85 |
| w/o Masking | 95.42 / 108 | **80.85** |
| **SMMT (Full)** | **97.05 / 112** | **84.96** |

#### å‘ç°ï¼š
- ç§»é™¤ **sparse attention** å¯¼è‡´è®­ç»ƒæ—¶é—´å¤§å¹…ä¸Šå‡ï¼ˆ+14 minï¼‰ï¼Œä½†ç²¾åº¦ç•¥å‡ â†’ è¡¨æ˜ç¨€ç–åŒ–å¸¦æ¥æ˜¾è‘—æ•ˆç‡å¢ç›Šã€‚
- ç§»é™¤ **masking** åè®­ç»ƒæ›´å¿«ï¼Œä½†åœ¨å°æ ·æœ¬ä¸‹ç²¾åº¦ä¸‹é™æ˜æ˜¾ï¼ˆ20% æ•°æ®æ—¶ â†“4.11%ï¼‰â†’ è¯æ˜ masking æ˜¾è‘—æå‡é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚
- **ä¸¤è€…ç»“åˆå®ç°æœ€ä½³æƒè¡¡**ï¼šæ—¢é«˜æ•ˆåˆå‡†ç¡®ã€‚

æ­¤å¤–ï¼Œä½œè€…è¿˜éªŒè¯äº†ä¸åŒ masking ratio $r$ çš„å½±å“ï¼ˆå›¾ 7ï¼‰ï¼š
- æœ€ä½³å€¼ä¸º **$r=0.3$**ï¼Œè¿‡é«˜çš„ maskingï¼ˆ>0.6ï¼‰ä¼šå¯¼è‡´æ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **SMMT åœ¨ AD åˆ†ç±»ä»»åŠ¡ä¸­å®ç°äº† SOTA æ€§èƒ½**ï¼š
   - å…¨æ•°æ®ä¸‹è¾¾ **97.05% å‡†ç¡®ç‡**ï¼ŒAUC è¾¾ **0.986**ã€‚
   - å³ä½¿åªç”¨ 20% æ•°æ®ä¹Ÿèƒ½è¾¾åˆ° **84.96% å‡†ç¡®ç‡**ï¼Œè¿œè¶…åŸºçº¿ã€‚

2. **ç¨€ç–æ³¨æ„åŠ›æœ‰æ•ˆé™ä½è®¡ç®—è´Ÿæ‹…**ï¼š
   - æ—¶é—´å¤æ‚åº¦é™è‡³ $O(n \log n)$ï¼Œè®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œå†…å­˜å ç”¨æ›´ä½ã€‚
   - K-Means èšç±»ç­–ç•¥å…·æœ‰æ•°æ®é©±åŠ¨ä¼˜åŠ¿ï¼Œä¼˜äºå›ºå®šæ¨¡å¼çš„ç¨€ç–æ–¹æ¡ˆã€‚

3. **modality-wise masking æ˜¾è‘—æå‡é²æ£’æ€§**ï¼š
   - æ¨¡æ‹Ÿæ¨¡æ€ç¼ºå¤±ï¼Œä½¿æ¨¡å‹æ›´å…·ç°å®é€‚åº”æ€§ã€‚
   - åœ¨å°æ ·æœ¬æ¡ä»¶ä¸‹é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚

4. **æ˜¾è‘—èŠ‚èƒ½å‡æ’**ï¼š
   - ç›¸æ¯” 3MTï¼Œ**æ€»èƒ½è€—é™ä½ 40.4%**ï¼Œç¢³æ’æ”¾å‡å°‘è¿‘ä¸€åŠã€‚
   - ä¸ºç»¿è‰² AI å’Œå¯æŒç»­åŒ»ç–— AI éƒ¨ç½²æä¾›å¯è¡Œè·¯å¾„ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **æœªåŒ…å« MCIï¼ˆè½»åº¦è®¤çŸ¥éšœç¢ï¼‰ç±»åˆ«**ï¼šç›®å‰ä»…ä¸ºäºŒåˆ†ç±»ï¼ˆAD vs CNï¼‰ï¼Œé™åˆ¶äº†ä¸´åºŠåˆ†æœŸé¢„æµ‹çš„åº”ç”¨ã€‚
- **ä¾èµ–æ‰¹å¤„ç†èšç±»**ï¼šK-Means åœ¨æ¯ batch ä¸­æ‰§è¡Œï¼Œè™½å¤ç”¨å¯æ¥å—ï¼Œä½†ä»å¼•å…¥é¢å¤–å¼€é”€ã€‚
- **å°šæœªåœ¨æ›´å¤§ã€æ›´å¤šæ ·åŒ–çš„è·¨ä¸­å¿ƒæ•°æ®é›†ä¸ŠéªŒè¯**ï¼šæ³›åŒ–èƒ½åŠ›æœ‰å¾…è¿›ä¸€æ­¥æ£€éªŒã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³ **ä¸‰åˆ†ç±»æˆ–å¤šé˜¶æ®µé¢„æµ‹**ï¼ˆCN â†’ MCI â†’ ADï¼‰ã€‚
2. æ”¯æŒ **çºµå‘å»ºæ¨¡ï¼ˆlongitudinal modelingï¼‰**ï¼Œç”¨äºç–¾ç—…è¿›å±•è¿½è¸ªã€‚
3. è®¾è®¡ **è‡ªé€‚åº”æ¨¡æ€é€‰æ‹©æœºåˆ¶**ï¼ŒåŠ¨æ€åº”å¯¹æ¨ç†æ—¶æ¨¡æ€ç¼ºå¤±ã€‚
4. åœ¨æ›´å¤§è§„æ¨¡ã€è·¨æœºæ„çš„ä¸´åºŠæ•°æ®é›†ä¸­éªŒè¯ SMMT çš„æ™®é€‚æ€§ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> SMMT é€šè¿‡ **cluster-based sparse attention** å’Œ **modality-wise masking**ï¼Œæ„å»ºäº†ä¸€ä¸ªé«˜æ•ˆã€èŠ‚èƒ½ä¸”é²æ£’çš„å¤šæ¨¡æ€ Transformer æ¶æ„ï¼Œåœ¨ AD åˆ†ç±»ä»»åŠ¡ä¸­å®ç°äº†æ€§èƒ½ä¸å¯æŒç»­æ€§çš„åŒé‡çªç ´ï¼Œæ˜¯é¢å‘çœŸå®ä¸–ç•ŒåŒ»ç–— AI éƒ¨ç½²çš„ç†æƒ³å€™é€‰æ¨¡å‹ã€‚

</details>

---

### 8. [CTkvr: KV Cache Retrieval for Long-Context LLMs via Centroid then Token Indexing](https://arxiv.org/abs/2512.15550)

**Authors**: Kuan Lu, Shuhang Lin, Sai Wu, Yichen Yao, Junhan Yang, Huan Li, Wei Chu, Xu Yinghui, Yuan Qi, Gang Chen  
**Category**: cs.CL  
**Published**: 2025-12-18  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.15550v1  

#### Abstract
Large language models (LLMs) are increasingly applied in long-context scenarios such as multi-turn conversations. However, long contexts pose significant challenges for inference efficiency, including high memory overhead from Key-Value (KV) cache and increased latency due to excessive memory access...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCTKvR: Efficient KV Cache Retrieval for Long-Context LLMs via Centroid-then-Token Indexing

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿ä¸Šä¸‹æ–‡åœºæ™¯ï¼ˆå¦‚å¤šè½®å¯¹è¯ã€é•¿æ–‡æ¡£é—®ç­”ï¼‰ä¸­é¢ä¸´æ˜¾è‘—çš„æ¨ç†æ•ˆç‡æŒ‘æˆ˜ï¼Œä¸»è¦ä½“ç°åœ¨ï¼š
- **é«˜å†…å­˜å¼€é”€**ï¼šKey-Value (KV) cache éšåºåˆ—é•¿åº¦çº¿æ€§å¢é•¿ï¼Œæ¶ˆè€—å¤§é‡ GPU æ˜¾å­˜ï¼ˆVRAMï¼‰ï¼Œé™åˆ¶æ‰¹å¤„ç†å¤§å°ï¼ˆbatch sizeï¼‰å’Œååé‡ã€‚
- **é«˜å»¶è¿Ÿ**ï¼šä¼ ç»Ÿç¨€ç–æ³¨æ„åŠ›æ–¹æ³•åœ¨é¢„å¡«å……ï¼ˆprefillingï¼‰å’Œè§£ç ï¼ˆdecodingï¼‰é˜¶æ®µå¼•å…¥æ˜¾è‘—è®¡ç®—å¼€é”€ã€‚

ç°æœ‰æ–¹æ³•å­˜åœ¨æƒè¡¡ï¼š
- **åŸºäºé©±é€çš„æ–¹æ³•**ï¼ˆå¦‚ SNAPKVï¼‰ï¼šé€šè¿‡ä¸¢å¼ƒ KV å¯¹å‡å°‘å†…å­˜ï¼Œä½†å¯¼è‡´ä¿¡æ¯ä¸¢å¤±å’Œç²¾åº¦ä¸‹é™ã€‚
- **å—çº§ç´¢å¼•**ï¼ˆå¦‚ ShadowKV, QUESTï¼‰ï¼šæ£€ç´¢ç²’åº¦ç²—ï¼Œå¯èƒ½å¼•å…¥æ— å…³ KV æ¡ç›®ï¼Œå½±å“ç²¾åº¦ã€‚
- **ä»¤ç‰Œçº§ç´¢å¼•**ï¼ˆå¦‚ MAGICPIG, RetrievalAttentionï¼‰ï¼šç²¾åº¦é«˜ï¼Œä½†ç´¢å¼•æ„å»ºå’Œæ£€ç´¢å¼€é”€å¤§ï¼Œå»¶è¿Ÿé«˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šCTKvR
æå‡º **Centroid-then-Token KV Retrieval (CTKvR)**ï¼Œä¸€ç§æ–°é¢–çš„ä¸¤é˜¶æ®µ KV æ£€ç´¢æ–¹æ¡ˆï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ **Rotary Position Embedding (RoPE)** åç›¸é‚»ä½ç½®æŸ¥è¯¢å‘é‡çš„é«˜åº¦ç›¸ä¼¼æ€§ã€‚

#### åˆ›æ–°ç‚¹
1. **ä¸¤é˜¶æ®µæ£€ç´¢æœºåˆ¶**ï¼š
   - **ç¬¬ä¸€é˜¶æ®µï¼šæŸ¥è¯¢ä¸­å¿ƒç‚¹ç´¢å¼• (Query-centroid Indexing)**  
     åœ¨é¢„å¡«å……é˜¶æ®µï¼Œä»é•¿ä¸Šä¸‹æ–‡ä¸­æå–æœ€å `C` ä¸ªæŸ¥è¯¢å‘é‡ä½œä¸ºâ€œä¸­å¿ƒç‚¹â€ï¼ˆcentroidsï¼‰ã€‚ä¸ºæ¯ä¸ªä¸­å¿ƒç‚¹è®¡ç®—å…¶ä¸æ‰€æœ‰ Key çš„æ³¨æ„åŠ›åˆ†æ•°ï¼Œå¹¶å­˜å‚¨å…¶æœ€ç›¸ä¼¼çš„ `p` ä¸ª Key çš„ç´¢å¼•ï¼Œå½¢æˆ **æŸ¥è¯¢ä¸­å¿ƒç‚¹å€’æ’æ–‡ä»¶ (QcIVF)**ã€‚è¯¥ç´¢å¼•è½»é‡ä¸”æ˜“äºæ„å»ºã€‚
   - **ç¬¬äºŒé˜¶æ®µï¼šç»†ç²’åº¦ä»¤ç‰Œçº§ç´¢å¼• (Fine-grained Token-Level Indexing)**  
     åœ¨è§£ç æ—¶ï¼Œå…ˆè®¡ç®—å½“å‰æŸ¥è¯¢ `Q` ä¸æ‰€æœ‰ä¸­å¿ƒç‚¹çš„ç›¸ä¼¼åº¦ï¼Œé€‰å‡ºæœ€ç›¸ä¼¼çš„ `C'` ä¸ªä¸­å¿ƒç‚¹ï¼Œè·å–å®ƒä»¬å¯¹åº”çš„å€™é€‰ Key é›†åˆï¼ˆ`KRecall`ï¼‰ã€‚ç„¶ååœ¨è¿™äº›å€™é€‰é›†ä¸­è¿›è¡Œç²¾ç»†æ’åºï¼ˆrerankï¼‰ï¼Œé€‰å‡ºæœ€ç»ˆçš„ `p'` ä¸ª Key è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚

2. **ç³»ç»Ÿçº§ä¼˜åŒ–**ï¼š
   - **CPU-GPU ååŒæ‰§è¡Œ**ï¼šå°†å¤§éƒ¨åˆ† KV cache å’Œéƒ¨åˆ†è®¡ç®—ï¼ˆå¦‚ Q2K Rerankï¼‰å¸è½½åˆ° CPUï¼Œåˆ©ç”¨ DRAM æ‰©å±•å†…å­˜å®¹é‡ï¼Œæ”¯æŒæ›´å¤§ batch sizeã€‚
   - **å®šåˆ¶åŒ– CUDA å†…æ ¸ä¸å¤šæµæŠ€æœ¯**ï¼šä¼˜åŒ–ç´¢å¼•å»é‡å’Œæ£€ç´¢è¿‡ç¨‹ï¼Œå¹¶é€šè¿‡ CUDA å¤šæµå®ç° GPU å’Œ CPU è®¡ç®—çš„é‡å ï¼Œæœ€å¤§åŒ–ååé‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **é«˜ç²¾åº¦**ï¼šé€šè¿‡ä¸¤é˜¶æ®µæ£€ç´¢ï¼Œæ—¢ä¿è¯äº†æ£€ç´¢èŒƒå›´çš„å‡†ç¡®æ€§ï¼Œåˆé¿å…äº†å—çº§æ–¹æ³•çš„å™ªå£°ã€‚
- **é«˜æ•ˆç‡**ï¼šQcIVF æ„å»ºå’Œæœç´¢æˆæœ¬è¿œä½äº ANN æ–¹æ³•ï¼ˆå¦‚ HNSW, IVFï¼‰ï¼Œæ˜¾è‘—é™ä½é¢„å¡«å……å¼€é”€ã€‚
- **é«˜ååé‡**ï¼šæ”¯æŒæ›´å¤§çš„ batch size å’Œæ›´é•¿çš„ä¸Šä¸‹æ–‡ï¼Œå®æµ‹ååé‡æå‡ 3-4 å€ã€‚
- **ä½å†…å­˜å ç”¨**ï¼šQcIVF æœ¬èº«å†…å­˜å¼€é”€æå°ï¼ˆçº¦ 20MBï¼‰ï¼Œå¯å°† GPU ä¸Šçš„ KV cache å­˜å‚¨é™è‡³åŸå§‹çš„ 5%ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **RULER**ï¼šä¸€ä¸ªå¯å®šåˆ¶ä¸Šä¸‹æ–‡é•¿åº¦çš„åŸºå‡†ï¼ŒåŒ…å« 13 ä¸ªä»»åŠ¡ï¼Œæ¶µç›–æ£€ç´¢ã€å¤šè·³è¿½è¸ªã€èšåˆå’Œé—®ç­”ï¼ˆQAï¼‰å››ç±»ï¼Œæµ‹è¯•ä¸Šä¸‹æ–‡é•¿åº¦ä» 8K åˆ° 128Kã€‚
- **LongBench**ï¼šåŒ…å« 21 ä¸ªè‹±æ–‡å’Œä¸­æ–‡æ•°æ®é›†ï¼Œèšç„¦äºå•æ–‡æ¡£ QAã€å¤šæ–‡æ¡£ QAã€æ‘˜è¦ã€å°‘æ ·æœ¬å­¦ä¹ å’Œä»£ç è¡¥å…¨ç­‰ä»»åŠ¡ã€‚
- **Needle-in-a-Haystack**ï¼šç”¨äºæµ‹è¯•æ¨¡å‹ä»è¶…é•¿æ–‡æœ¬ä¸­æ£€ç´¢å…³é”®ä¿¡æ¯çš„èƒ½åŠ›ï¼Œä¸Šä¸‹æ–‡é•¿åº¦ä» 16K åˆ° 1Mã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼šLlama-3-8B-262K å’Œ Yi-9B-200Kã€‚
- **ä¸Šä¸‹æ–‡é•¿åº¦**ï¼šä¸»è¦åœ¨ 96K ä¸Šè¯„ä¼°ç³»ç»Ÿæ•ˆç‡ï¼Œåœ¨ 8K-128K ä¸Šè¯„ä¼°ç²¾åº¦ã€‚
- **ç¡¬ä»¶**ï¼šA6000 (48GB/24GB), V100 (32GB), æ­é… Intel Xeon CPUã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **ç²¾åº¦**ï¼šä»»åŠ¡å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ã€å¹³å‡å¾—åˆ†ã€‚
  - **æ•ˆç‡**ï¼šååé‡ï¼ˆTokens/sï¼‰ã€æœ€å¤§æ”¯æŒ batch sizeã€ç´¢å¼•æ„å»ºæ—¶é—´ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **FULLKV**ï¼šä¸å‹ç¼© KV cacheï¼Œä½œä¸ºç²¾åº¦ä¸Šé™ã€‚
- **SNAPKV**ï¼šåŸºäºæ³¨æ„åŠ›åˆ†æ•°çš„ KV é©±é€æ–¹æ³•ã€‚
- **QUEST / ShadowKV**ï¼šå—çº§ç¨€ç–æ³¨æ„åŠ›æ–¹æ³•ã€‚
- **MAGICPIG**ï¼šåŸºäº LSH çš„ä»¤ç‰Œçº§ç¨€ç–æ³¨æ„åŠ›æ–¹æ³•ã€‚
- **FLAT**ï¼šç²¾ç¡® KNN æ£€ç´¢æ–¹æ³•ï¼ˆä½œä¸ºç†æƒ³å‚ç…§ï¼‰ã€‚
- **VLLM**ï¼šé«˜æ•ˆçš„ Full-KV æ¨ç†æ¡†æ¶ï¼ˆå…±äº« KV cacheï¼‰ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **ç²¾åº¦**ï¼š
  - CTKvR åœ¨ RULER å’Œ LongBench ä¸Šçš„ç²¾åº¦æŸå¤±å°äº 1%ï¼Œä¸ FULLKV å‡ ä¹æŒå¹³ã€‚
  - åœ¨ Needle-in-a-Haystack ä»»åŠ¡ä¸­ï¼ŒCTKvR èƒ½æˆåŠŸæ£€ç´¢åˆ°ä¸åŒä½ç½®çš„â€œé’ˆâ€ï¼Œå³ä½¿åœ¨ 1M ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹ä¹Ÿè¡¨ç°ç¨³å¥ã€‚
- **ååé‡**ï¼š
  - åœ¨ 96K ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹ï¼Œç›¸æ¯” FULLKVï¼ŒCTKvR åœ¨ Llama-3-8B ä¸Šå®ç° **3Ã— åååŠ é€Ÿ**ï¼Œåœ¨ Yi-9B ä¸Šå®ç° **4Ã— åŠ é€Ÿ**ã€‚
- **æ‰¹å¤„ç†å¤§å°**ï¼š
  - æ”¯æŒçš„ batch size è¾¾åˆ° FULLKV çš„ **10-20 å€**ã€‚
  - å³ä½¿åœ¨ä»… 24GB VRAM çš„ GPU ä¸Šä¹Ÿèƒ½å¤„ç† 96K ä¸Šä¸‹æ–‡ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| æ–¹æ³• | ç²¾åº¦ | ååé‡ | å†…å­˜æ•ˆç‡ | å¤‡æ³¨ |
|------|------|--------|----------|------|
| **FULLKV** | âœ… æœ€é«˜ | âŒ æœ€ä½ | âŒ å·® | åŸºå‡† |
| **SNAPKV** | âŒ ä¸¥é‡ä¸‹é™ | âš ï¸ ä¸­ç­‰ | âœ… å¥½ | ä¿¡æ¯ä¸¢å¤± |
| **ShadowKV / QUEST** | âš ï¸ ä¸­ç­‰ä¸‹é™ | âš ï¸ ä¸­ç­‰ | âœ… å¥½ | å—å†…å™ªå£° |
| **MAGICPIG** | âœ… é«˜ | âš ï¸ ä¸­ç­‰ | âš ï¸ ä¸€èˆ¬ | LSH è¡¨å å†…å­˜ |
| **CTKvR** | âœ… æ¥è¿‘ FULLKV (<1% é™) | âœ… **æœ€é«˜ (3-4Ã—)** | âœ… **æœ€ä¼˜** | ç»¼åˆæœ€ä½³ |

- **ç´¢å¼•æ„å»ºæ•ˆç‡**ï¼šCTKvR çš„ç´¢å¼•æ„å»ºæ—¶é—´æ¯” HNSWã€IVFã€KMeans ç­‰ ANN æ–¹æ³•å¿« **50-10000 å€**ï¼Œä¸”éšä¸Šä¸‹æ–‡å¢é•¿æ›´ç¨³å®šã€‚

### æ¶ˆèå®éªŒç»“æœ
- **Rerank æ¨¡å—**ï¼šå¯ç”¨ Rerank å¯è¿›ä¸€æ­¥æå‡ååé‡è¾¾ **2Ã—**ï¼Œå› ä¸ºå®ƒå‡å°‘äº†æœ€ç»ˆæ³¨æ„åŠ›è®¡ç®—çš„ Key æ•°é‡ã€‚
- **åŠ¨æ€ä¸­å¿ƒç‚¹æ›´æ–° (DCU)**ï¼šåœ¨å¤šè½®å¯¹è¯åœºæ™¯ä¸­ï¼ŒDCU æ˜¾è‘—æå‡äº†åç»­è½®æ¬¡çš„æ£€ç´¢ç²¾åº¦ï¼ˆå¦‚ç¬¬ 8 è½®å¯¹è¯ä¸­ï¼Œå‡†ç¡®ç‡ä» 85.67% æå‡è‡³ 94.02%ï¼‰ã€‚
- **å‚æ•°æ•æ„Ÿæ€§**ï¼š
  - **ç»´æŠ¤çš„ä¸­å¿ƒç‚¹æ•° C**ï¼šå¢åŠ  C æå‡ç²¾åº¦ï¼Œä½†åœ¨ Câ‰ˆ320 åè¶‹äºé¥±å’Œã€‚
  - **æ£€ç´¢çš„ä¸­å¿ƒç‚¹æ•° C'**ï¼šå¢åŠ  C' æå‡ç²¾åº¦ï¼Œä½†åœ¨ C'â‰ˆ5 åè¶‹äºé¥±å’Œï¼Œä½†ä¼šæ˜¾è‘—é™ä½ååé‡ï¼ˆå›  Rerank å¼€é”€å¢å¤§ï¼‰ã€‚
  - **ç¨€ç–é¢„ç®— p'**ï¼šå³ä½¿ p'=512ï¼ˆä»… 0.39% çš„ä¸Šä¸‹æ–‡ï¼‰ï¼ŒCTKvR ä»èƒ½æ¥è¿‘ FULLKV ç²¾åº¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç›¸é‚»æŸ¥è¯¢é«˜åº¦ç›¸ä¼¼**ï¼šRoPE ç¼–ç åï¼Œä½ç½®ç›¸è¿‘çš„æŸ¥è¯¢å‘é‡å…·æœ‰é«˜ä½™å¼¦ç›¸ä¼¼æ€§ï¼Œä¸”å…¶ top-k æ£€ç´¢çš„ Key é›†åˆé«˜åº¦é‡å ã€‚è¿™æ˜¯ CTKvR è®¾è®¡çš„åŸºç¡€ã€‚
2. **ä¸¤é˜¶æ®µæ£€ç´¢æœ‰æ•ˆå¹³è¡¡æ•ˆç‡ä¸ç²¾åº¦**ï¼šå…ˆç”¨è½»é‡çº§ä¸­å¿ƒç‚¹ç´¢å¼•ç¼©å°æœç´¢èŒƒå›´ï¼Œå†è¿›è¡Œç²¾ç»†æ’åºï¼Œå®ç°äº†é«˜æ•ˆä¸”å‡†ç¡®çš„ KV æ£€ç´¢ã€‚
3. **CPU-GPU ååŒå¯è¡Œä¸”é«˜æ•ˆ**ï¼šç°ä»£ CPU çš„ç®—åŠ›å’Œå¸¦å®½è¶³ä»¥æ‰¿æ‹…éƒ¨åˆ†æ³¨æ„åŠ›è®¡ç®—ï¼Œç»“åˆå®šåˆ¶ä¼˜åŒ–ï¼Œå¯å¤§å¹…æå‡ç³»ç»Ÿååã€‚
4. **CTKvR å…·æœ‰å¼ºæ‰©å±•æ€§**ï¼šåœ¨æç«¯é•¿ä¸Šä¸‹æ–‡ï¼ˆ1M tokensï¼‰ä¸‹ä¾ç„¶ä¿æŒé«˜æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ– RoPE**ï¼šæ–¹æ³•çš„æœ‰æ•ˆæ€§å»ºç«‹åœ¨ RoPE å¯¼è‡´ç›¸é‚»æŸ¥è¯¢ç›¸ä¼¼çš„åŸºç¡€ä¸Šï¼Œå¯¹å…¶ä»–ä½ç½®ç¼–ç æ–¹å¼çš„æ™®é€‚æ€§æœ‰å¾…éªŒè¯ã€‚
- **CPU æˆä¸ºç“¶é¢ˆ**ï¼šå°½ç®¡ä¼˜åŒ–äº† CPU è®¡ç®—ï¼Œä½† Q2K Rerank å’Œ CPU æ³¨æ„åŠ›ä»æ˜¯ä¸»è¦è€—æ—¶ç¯èŠ‚ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ– CPU ç«¯ä»æœ‰ç©ºé—´ã€‚
- **åŠ¨æ€æ›´æ–°æœºåˆ¶å¤æ‚æ€§**ï¼šDCU è™½ç„¶æœ‰æ•ˆï¼Œä½†å¢åŠ äº†ç³»ç»Ÿå¤æ‚æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„ CPU ç«¯è®¡ç®—ä¼˜åŒ–ï¼Œå¦‚é‡åŒ–ã€ç¨€ç–åŒ–ã€‚
- å°† CTKvR æ€æƒ³åº”ç”¨äºå…¶ä»–æ³¨æ„åŠ›å˜ä½“æˆ–æ¨¡å‹æ¶æ„ã€‚
- ç ”ç©¶æ›´æ™ºèƒ½çš„ä¸­å¿ƒç‚¹é€‰æ‹©å’Œæ›´æ–°ç­–ç•¥ï¼Œå‡å°‘å¯¹ FIFO é˜Ÿåˆ—çš„ä¾èµ–ã€‚
- æ¢ç´¢åœ¨è®­ç»ƒé˜¶æ®µé›†æˆ CTKvR ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½ã€‚

</details>

---

### 9. [FlowBind: Efficient Any-to-Any Generation with Bidirectional Flows](https://arxiv.org/abs/2512.15420)

**Authors**: Yeonwoo Cha, Semin Kim, Jinhyeon Kwon, Seunghoon Hong  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.15420v1  

#### Abstract
Any-to-any generation seeks to translate between arbitrary subsets of modalities, enabling flexible cross-modal synthesis. Despite recent success, existing flow-based approaches are challenged by their inefficiency, as they require large-scale datasets often with restrictive pairing constraints, inc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# FlowBind: Efficient Any-to-Any Generation with Bidirectional Flows â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **flow-based any-to-any generation** æ–¹æ³•é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **æ•°æ®ä¾èµ–æ€§å¼º**ï¼šéœ€è¦å¤§é‡å®Œå…¨é…å¯¹çš„å¤šæ¨¡æ€æ•°æ®ï¼ˆå¦‚æ–‡æœ¬-å›¾åƒ-éŸ³é¢‘ä¸‰å…ƒç»„ï¼‰ï¼Œè¿™ç±»æ•°æ®ç¨€ç¼ºä¸”æ˜‚è´µã€‚
- **è®¡ç®—æˆæœ¬é«˜**ï¼šå»ºæ¨¡è”åˆåˆ†å¸ƒå¯¼è‡´è®¡ç®—å¤æ‚åº¦éšæ¨¡æ€æ•°å¹³æ–¹å¢é•¿ï¼Œè®­ç»ƒæ•ˆç‡ä½ã€‚
- **è®­ç»ƒæµç¨‹å¤æ‚**ï¼šæ™®éé‡‡ç”¨å¤šé˜¶æ®µè®­ç»ƒï¼ˆå¦‚å…ˆå¯¹é½å†ç”Ÿæˆï¼‰ï¼Œéš¾ä»¥ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šFlowBind
FlowBind æ˜¯ä¸€ç§ç®€æ´é«˜æ•ˆçš„ flow-based æ¡†æ¶ï¼Œç”¨äºå®ç°ä»»æ„å­é›†ä¹‹é—´çš„è·¨æ¨¡æ€ç”Ÿæˆï¼ˆany-to-any generationï¼‰ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å¼•å…¥ä¸€ä¸ª**å¯å­¦ä¹ çš„å…±äº«æ½œåœ¨ç©ºé—´ï¼ˆlearnable shared latentï¼‰**ï¼Œä½œä¸ºæ‰€æœ‰æ¨¡æ€ä¹‹é—´ä¿¡æ¯äº¤äº’çš„â€œæ¡¥æ¢â€ã€‚
- æ¯ä¸ªæ¨¡æ€é€šè¿‡ä¸€ä¸ª**å¯é€†çš„ã€æ¨¡æ€ç‰¹å®šçš„æµæ¨¡å‹ï¼ˆinvertible flowï¼‰** è¿æ¥åˆ°è¯¥å…±äº«æ½œåœ¨ç©ºé—´ã€‚
- æ‰€æœ‰ç»„ä»¶åœ¨**å•ä¸€ flow matching ç›®æ ‡å‡½æ•°ä¸‹è”åˆè®­ç»ƒ**ï¼Œæ— éœ€å¤šé˜¶æ®µæµç¨‹ã€‚

### åˆ›æ–°ç‚¹ä¸ä¼˜åŠ¿
| ç‰¹æ€§ | FlowBind | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ CoDi, OmniFlowï¼‰ |
|------|---------|-----------------------------|
| **è®­ç»ƒæ–¹å¼** | å•ä¸€ç›®æ ‡ã€ç«¯åˆ°ç«¯è”åˆè®­ç»ƒ | å¤šé˜¶æ®µè®­ç»ƒï¼ˆå¦‚å¯¹é½ + ç”Ÿæˆï¼‰ |
| **æ•°æ®è¦æ±‚** | æ”¯æŒä»»æ„éƒ¨åˆ†é…å¯¹æ•°æ®ï¼ˆpartial pairingï¼‰ | éœ€è¦å…¨é…å¯¹æˆ–é”šå®šæ¨¡æ€ï¼ˆå¦‚å¿…é¡»å«æ–‡æœ¬ï¼‰ |
| **è®¡ç®—æ•ˆç‡** | å‚æ•°æ›´å°‘ã€è®­ç»ƒæ›´å¿«ï¼ˆ~10Ã— speedupï¼‰ | é«˜ç»´è”åˆå»ºæ¨¡ï¼Œè®¡ç®—å¼€é”€å¤§ |
| **çµæ´»æ€§** | çœŸæ­£æ”¯æŒä»»æ„è¾“å…¥è¾“å‡ºç»„åˆï¼ˆany-to-anyï¼‰ | å—é™äºå›ºå®šè·¯å¾„æˆ–é”šå®šè®¾è®¡ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼š**æ›´ç®€å•ã€æ›´é«˜æ•ˆã€æ›´çµæ´»**ï¼ŒåŒæ—¶ä¿æŒç”šè‡³è¶…è¶Šç°æœ‰æ–¹æ³•çš„ç”Ÿæˆè´¨é‡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
FlowBind åœ¨ä¸‰ä¸ªä¸»æµæ¨¡æ€ï¼ˆtext, image, audioï¼‰ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œä½¿ç”¨ä»¥ä¸‹é…å¯¹æ•°æ®é›†ï¼š
- **Text-Image**: LAION-COCO (242K), Flickr-30k (30K)
- **Text-Audio**: AudioCaps v2 (91K)
- **Audio-Image**: VGGSound (184K)

> âš ï¸ æ³¨æ„ï¼š**æœªä½¿ç”¨ä»»ä½•ä¸‰å…ƒç»„ï¼ˆtripletï¼‰æ•°æ®**ï¼Œä»…ä¾èµ–åŒæ¨¡æ€é…å¯¹æ•°æ®å³å¯å®Œæˆ any-to-any å­¦ä¹ ã€‚

### å®éªŒè®¾ç½®
- **ç¼–ç å™¨å†»ç»“**ï¼šä½¿ç”¨é¢„è®­ç»ƒå¼ºç¼–ç å™¨æå–è¯­ä¹‰ç‰¹å¾ï¼ˆé¿å…ä»åŸå§‹æ•°æ®å­¦ä¹ ï¼‰ï¼š
  - æ–‡æœ¬ï¼šEmbeddingGemma
  - å›¾åƒï¼šCLIP + Stable-UnCLIP ä½œä¸ºè§£ç å™¨
  - éŸ³é¢‘ï¼šCLAP
- **æµæ¨¡å‹æ¶æ„**ï¼šMLP-based drift networks with AdaLN-zero æ—¶é—´è°ƒåˆ¶
- **å…±äº«æ½œåœ¨ç©ºé—´ç»´åº¦**ï¼šç»Ÿä¸€ä¸º 768 ç»´
- **è®­ç»ƒç­–ç•¥**ï¼šæ··åˆé‡‡æ ·æ—¶é—´ $ t \sim (1-\alpha)\text{Unif}(0,1) + \alpha\delta(t=0) $ï¼Œä»¥ç¨³å®š encoder è®­ç»ƒ

### è¯„ä¼°æŒ‡æ ‡

#### ç”Ÿæˆè´¨é‡ï¼ˆFidelityï¼‰
- å›¾åƒï¼š**FID**
- éŸ³é¢‘ï¼š**FAD**
- æ–‡æœ¬ï¼š**CIDEr**

#### è·¨æ¨¡æ€å¯¹é½ï¼ˆAlignmentï¼‰
- æ–‡æœ¬-å›¾åƒï¼š**CLIP Score**
- æ–‡æœ¬-éŸ³é¢‘ï¼š**CLAP Score**
- å›¾åƒ-éŸ³é¢‘ï¼š**AIS (Audio-Image Similarity)**

#### å¤šå¯¹å¤šä»»åŠ¡é¢å¤–æŒ‡æ ‡
- è‡ªæ„åˆæˆä¸‰å…ƒç»„æ•°æ®é›†ï¼ˆåŸºäº AudioCaps + FLUX.1 ç”Ÿæˆå›¾åƒï¼‰ï¼Œç”¨äº many-to-one å’Œ one-to-many å®šé‡è¯„ä¼°ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Generalist Models**:
  - **CoDi** (Tang et al., 2023): åŸºäºæ–‡æœ¬é”šå®šçš„ä¸¤é˜¶æ®µæ¡†æ¶
  - **OmniFlow** (Li et al., 2025b): å»ºæ¨¡è”åˆæ¡ä»¶æµï¼Œéœ€å…¨é…å¯¹æ•°æ®
- **Specialist Models**:
  - SD3-Medium, FLUX.1 (textâ†’image)
  - LLaVA-NeXT (imageâ†’text)
  - TangoFlux, AudioX (textâ†’audio)
  - Qwen2-Audio (audioâ†’text)
  - Seeing & Hearing, Sound2Vision (cross-modal)

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### 3.1 ä¸€å¯¹ä¸€ä»£æ¢æ€§èƒ½ï¼ˆOne-to-One Generationï¼‰

#### è¡¨æ ¼ï¼šç”Ÿæˆè´¨é‡å¯¹æ¯”ï¼ˆè¶Šä½è¶Šå¥½ / è¶Šé«˜è¶Šå¥½ï¼‰

| Task | Model | FIDâ†“ | CIDErâ†‘ | FADâ†“ | ... |
|------|-------|------|--------|------|-----|
| Tâ†’I | FlowBind | **17.39** | â€“ | â€“ | |
| Iâ†’T | FlowBind | â€“ | **46.26** | â€“ | |
| Tâ†’A | FlowBind | â€“ | â€“ | **4.19** | |
| Aâ†’T | FlowBind | â€“ | **55.11** | â€“ | |
| Iâ†’A | FlowBind | â€“ | â€“ | **2.50** | |
| Aâ†’I | FlowBind | **26.60** | â€“ | â€“ | |

> âœ… FlowBind åœ¨**æ‰€æœ‰å…­é¡¹ä¸€å¯¹ä¸€ä»£æ¢ä»»åŠ¡ä¸­å‡å–å¾—æœ€ä½³ç”Ÿæˆè´¨é‡**ã€‚

#### å¯¹é½æ€§èƒ½ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰

| Task | Model | CLIPâ†‘ | CLAPâ†‘ | AISâ†‘ |
|------|-------|-------|-------|------|
| Tâ†’I | FlowBind | 28.35 | â€“ | â€“ |
| Iâ†’T | FlowBind | 29.74 | â€“ | â€“ |
| Tâ†’A | FlowBind | â€“ | 29.08 | â€“ |
| Aâ†’T | FlowBind | â€“ | 36.70 | â€“ |
| Iâ†’A | FlowBind | â€“ | â€“ | **82.89** |
| Aâ†’I | FlowBind | â€“ | â€“ | **78.17** |

> âœ… åœ¨å››é¡¹ä»»åŠ¡ä¸­å¯¹é½å¾—åˆ†æœ€ä¼˜ï¼Œå°¤å…¶åœ¨ **image-audio äº’ç”Ÿä»»åŠ¡ä¸Šæ˜¾è‘—é¢†å…ˆ**ï¼ˆAIS > 80 vs. < 75 for othersï¼‰ã€‚

---

### 3.2 å¤šå¯¹å¤šç”Ÿæˆèƒ½åŠ›ï¼ˆMany-to-Many Generationï¼‰

#### Many-to-One ç»“æœï¼ˆè¡¨4ï¼‰
| Condition â†’ Output | Metric | CoDi | OmniFlow | **FlowBind** |
|--------------------|--------|------|----------|------------|
| (I+A)â†’T | CLIP(Iâ†’T) | 24.04 | 26.38 | **27.83** |
| (T+A)â†’I | AIS(Aâ†’I) | 57.52 | 54.90 | **57.93** |
| (T+I)â†’A | CLAP(Tâ†’A) | 4.85 | 7.68 | **28.13** |

> âœ… FlowBind æ˜¾è‘—æå‡å¤šæºæ¡ä»¶ä¸‹çš„å¯¹é½è¡¨ç°ï¼Œå°¤å…¶åœ¨ **(T+I)â†’A** ä¸Šè¿œè¶…åŸºçº¿ï¼Œè¯´æ˜èƒ½æœ‰æ•ˆèåˆå¤šç§è¾“å…¥ã€‚

#### One-to-Many ç»“æœï¼ˆè¡¨5ï¼‰
| Input â†’ (Outputs) | Metric | CoDi | OmniFlow | **FlowBind** |
|-------------------|--------|------|----------|------------|
| Tâ†’(I+A) | CLAP(Tâ†’A) | 10.99 | 12.92 | **29.12** |
| Iâ†’(T+A) | AIS(Iâ†’A) | 58.65 | 63.99 | **74.34** |
| Aâ†’(T+I) | CLAP(Aâ†’T) | 18.03 | 36.07 | **36.79** |

> âœ… FlowBind åœ¨ one-to-many è®¾ç½®ä¸‹ä¹Ÿè¡¨ç°å‡ºæ›´å¼ºçš„è·¨æ¨¡æ€æ§åˆ¶èƒ½åŠ›å’Œä¸€è‡´æ€§ã€‚

---

### 3.3 æ•ˆç‡ä¸å‚æ•°é‡å¯¹æ¯”ï¼ˆè¡¨1ï¼‰

| Model | Train Params | GPU-hours | Data Size (relative) |
|-------|--------------|-----------|------------------------|
| CoDi | 4.3B | â€“ | 100% |
| OmniFlow | 3.2B | 480 hr | 100% |
| **FlowBind** | **568M** | **48 hr** | **~1.8% of OmniFlow** |

> âœ… **å‚æ•°å‡å°‘çº¦ 6Ã—ï¼Œè®­ç»ƒé€Ÿåº¦å¿« 10Ã—ï¼Œæ•°æ®éœ€æ±‚ä»…ä¸º 1.79%**ï¼Œæå…·å®ç”¨æ€§å’Œæ‰©å±•æ€§ã€‚

---

### 3.4 æ¶ˆèå®éªŒä¸åˆ†æï¼ˆå…³é”®å‘ç°ï¼‰

#### ï¼ˆ1ï¼‰å¯å­¦ä¹ å…±äº«æ½œç©ºé—´ vs å›ºå®šæ–‡æœ¬é”š
| Model | Iâ†’T | Aâ†’T | Iâ†’A |
|-------|-----|-----|-----|
| Text-anchoring (baseline) | 27.94 | 36.72 | 55.48 |
| FlowBind w/o I-A pairs | **30.04** | **37.04** | **61.88** |

> âœ… å³ä½¿ä¸ä½¿ç”¨ image-audio é…å¯¹æ•°æ®ï¼ŒFlowBind çš„ learnable shared latent ä»ä¼˜äº text-anchor è®¾è®¡ï¼ŒéªŒè¯äº†å…¶æ³›åŒ–èƒ½åŠ›ã€‚

#### ï¼ˆ2ï¼‰å…±äº«æ½œç©ºé—´çš„è´¨é‡åˆ†æï¼ˆCKNNAï¼‰
| Model | T-A Alignment | A-I Alignment |
|-------|---------------|---------------|
| Modality-specific latents | 0.1965 | 0.1343 |
| **Shared Latent (FlowBind)** | **0.2872** | **0.3026** |

> âœ… å…±äº«æ½œç©ºé—´å…·æœ‰æ›´é«˜çš„è·¨æ¨¡æ€å¯¹é½åº¦ï¼Œè¯æ˜å…¶æ˜¯ä¸€ä¸ªçœŸæ­£æ„ä¹‰ä¸Šçš„â€œç»Ÿä¸€è¯­ä¹‰ç©ºé—´â€ã€‚

#### ï¼ˆ3ï¼‰æ’å€¼å¯è§†åŒ–ï¼ˆå›¾3ï¼‰
- åœ¨å…±äº«æ½œç©ºé—´ä¸­è¿›è¡Œçº¿æ€§æ’å€¼ï¼Œè§£ç åå›¾åƒå’Œæ–‡æœ¬å‘ˆç°å¹³æ»‘è¿‡æ¸¡ã€‚
- è¡¨æ˜æ½œç©ºé—´å…·å¤‡è‰¯å¥½çš„è¯­ä¹‰è¿ç»­æ€§å’Œç»“æ„åŒ–ç‰¹æ€§ã€‚

#### ï¼ˆ4ï¼‰å†²çªæ¡ä»¶é²æ£’æ€§ï¼ˆå›¾4ï¼‰
- å½“è¾“å…¥æ–‡æœ¬ä¸éŸ³é¢‘è¯­ä¹‰å†²çªæ—¶ï¼ˆå¦‚â€œå®‰é™èŠ±å›­â€ + â€œç”µé’»å£°â€ï¼‰ï¼ŒFlowBind èƒ½åˆç†åæ˜ ä¸¤è€…ï¼Œè€Œéå¿½ç•¥å…¶ä¸€æˆ–äº§ç”Ÿæ··ä¹±è¾“å‡ºã€‚
- å½’å› äºå…±äº«æ½œç©ºé—´çš„è‰¯å¥½å‡ ä½•ç»“æ„å’Œå¹³å‡èšåˆæœºåˆ¶çš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å¯å­¦ä¹ å…±äº«æ½œç©ºé—´æ˜¯é«˜æ•ˆ any-to-any ç”Ÿæˆçš„å…³é”®**ï¼š
   - æ›¿ä»£äº†ä¼ ç»Ÿçš„â€œæ–‡æœ¬é”šå®šâ€æˆ–â€œè”åˆæµâ€ï¼Œå®ç°äº†çœŸæ­£çš„æ¨¡æ€å¯¹ç§°æ€§ã€‚
   - é€šè¿‡æœ€å°åŒ– conditional variance æ¥é©±åŠ¨ encoder å­¦ä¹ æœ‰æ„ä¹‰çš„å…±æ€§è¡¨ç¤ºã€‚

2. **å•ä¸€ flow matching ç›®æ ‡è¶³ä»¥å®ç°ç«¯åˆ°ç«¯è®­ç»ƒ**ï¼š
   - æ— éœ€å¤æ‚çš„å¤šé˜¶æ®µæµç¨‹æˆ–å¤šæŸå¤±é¡¹ï¼ˆå¦‚ contrastive lossï¼‰ã€‚
   - ç®€åŒ–äº†è®­ç»ƒï¼Œæå‡äº†ç¨³å®šæ€§ã€‚

3. **é«˜é˜¶è¯­ä¹‰ç©ºé—´å»ºæ¨¡å¤§å¹…æå‡æ•ˆç‡**ï¼š
   - å†»ç»“å¼ºå¤§ç¼–ç å™¨ + åœ¨ compact latent space ä¸­å»ºæ¨¡ flowï¼Œå¤§å¹…é™ä½æ•°æ®å’Œè®¡ç®—éœ€æ±‚ã€‚
   - åˆ†ç¦»äº† intra-modal ç”Ÿæˆä¸ inter-modal å¯¹é½ä»»åŠ¡ã€‚

4. **FlowBind å…·å¤‡å‡ºè‰²çš„æ‰©å±•æ€§**ï¼š
   - æˆåŠŸæ‰©å±•è‡³ **3D point clouds**ï¼ˆPix3D æ•°æ®é›†ï¼‰ï¼Œä»…å¢åŠ ä¸€ä¸ª drift networkã€‚
   - å®ç°äº†æœªè§è¿‡çš„è·¨æ¨¡æ€ä»»åŠ¡ï¼ˆå¦‚ text â†’ point cloudï¼‰ï¼Œå±•ç¤ºäº†å¼ºå¤§çš„é›¶æ ·æœ¬è¿ç§»èƒ½åŠ›ã€‚

---

### å±€é™æ€§
- å½“å‰ä¾èµ–é«˜è´¨é‡é¢„è®­ç»ƒ encoderï¼ˆå¦‚ CLIP, CLAPï¼‰ï¼Œè‹¥æŸæ¨¡æ€ç¼ºä¹æ­¤ç±»æ¨¡å‹åˆ™å—é™ã€‚
- æ¨ç†è¿‡ç¨‹ä¾èµ– ODE ç§¯åˆ†ï¼Œå¯èƒ½å­˜åœ¨é€Ÿåº¦ç“¶é¢ˆï¼ˆå°½ç®¡æ¯”è®­ç»ƒå¿«å¾—å¤šï¼‰ã€‚
- å°šæœªåœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸»å¯¼çš„ any-to-any èŒƒå¼ä¸­ç›´æ¥æ¯”è¾ƒï¼ˆå¦‚ UnifiedIO2-Lï¼‰ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢å°† FlowBind ä¸ LLM æ¶æ„ç»“åˆï¼Œæ„å»º hybrid å¤šæ¨¡æ€ç”Ÿæˆç³»ç»Ÿã€‚
- æ‰©å±•åˆ°æ›´å¤šæ¨¡æ€ï¼ˆè§†é¢‘ã€åŠ¨ä½œã€æœºå™¨äººç­‰ï¼‰å¹¶ç ”ç©¶åŠ¨æ€æ¨¡æ€å¢åˆ æœºåˆ¶ã€‚
- åŠ é€Ÿæ¨ç†ï¼šæ¢ç´¢è’¸é¦æˆ– lookup table æ–¹æ³•æ›¿ä»£ ODE solverã€‚
- æ›´æ·±å…¥ç ”ç©¶å…±äº«æ½œç©ºé—´çš„è§£è€¦ä¸å¯æ§æ€§ã€‚

---

## æ€»ç»“
FlowBind æå‡ºäº†ä¸€ç§**ç®€æ´ã€é«˜æ•ˆã€çµæ´»**çš„ any-to-any ç”ŸæˆèŒƒå¼ï¼Œé€šè¿‡å¼•å…¥ **learnable shared latent + bidirectional invertible flows**ï¼Œè§£å†³äº†ç°æœ‰ flow-based æ–¹æ³•åœ¨æ•°æ®ã€è®¡ç®—å’Œè®­ç»ƒå¤æ‚æ€§ä¸Šçš„ç“¶é¢ˆã€‚å®éªŒè¯æ˜å…¶åœ¨ç”Ÿæˆè´¨é‡å’Œè·¨æ¨¡æ€å¯¹é½æ–¹é¢è¾¾åˆ° SOTA æ°´å¹³ï¼ŒåŒæ—¶**å‚æ•°å‡å°‘ 6Ã—ï¼Œè®­ç»ƒå¿« 10Ã—ï¼Œæ•°æ®éœ€æ±‚æä½**ï¼Œä¸ºé€šç”¨å¤šæ¨¡æ€ç”Ÿæˆæä¾›äº†æå…·å‰æ™¯çš„æ–°è·¯å¾„ã€‚

</details>

---

### 10. [Dual-Density Inference for Efficient Language Model Reasoning](https://arxiv.org/abs/2512.15358)

**Authors**: Zhengyi Zhao, Shubo Zhang, Yuxi Zhang, Huimin Wang, Binyang Li, Kam-Fai Wong  
**Category**: cs.CL  
**Published**: 2025-12-18  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.15358v1  

#### Abstract
Large Language Models (LLMs) have shown impressive capabilities in complex reasoning tasks. However, current approaches employ uniform language density for both intermediate reasoning and final answers, leading to computational inefficiency. Our observation found that reasoning process serves a comp...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDual-Density Inference for Efficient Language Model Reasoning

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­æ™®éé‡‡ç”¨ **Chain-of-Thought (CoT)** èŒƒå¼ï¼Œå³åœ¨æ•´ä¸ªæ¨ç†è¿‡ç¨‹ä¸­ï¼ˆä»ä¸­é—´è®¡ç®—åˆ°æœ€ç»ˆç­”æ¡ˆï¼‰éƒ½ä½¿ç”¨å†—é•¿çš„è‡ªç„¶è¯­è¨€ï¼ˆNatural Language, NLï¼‰ã€‚è¿™ç§æ–¹æ³•å­˜åœ¨æ˜¾è‘—çš„**è®¡ç®—æ•ˆç‡ä½ä¸‹**é—®é¢˜ã€‚

ä½œè€…æŒ‡å‡ºï¼Œè¿™ç§ç»Ÿä¸€çš„è¡¨ç¤ºæ–¹å¼é€ æˆäº†ä¸€ä¸ªæ ¹æœ¬æ€§çš„â€œè¡¨å¾é”™é…â€ï¼ˆrepresentational mismatchï¼‰ï¼š
- **å†…éƒ¨æ¨ç†ï¼ˆInternal Reasoningï¼‰** æ˜¯ä¸€ç§**è®¡ç®—åŠŸèƒ½**ï¼Œéœ€è¦é«˜ä¿¡æ¯å¯†åº¦ã€ç²¾ç¡®ä¸”ç´§å‡‘çš„ç¬¦å·åŒ–è¡¨è¾¾ã€‚
- **æœ€ç»ˆå›ç­”ï¼ˆFinal Answerï¼‰** æ˜¯ä¸€ç§**æ²Ÿé€šåŠŸèƒ½**ï¼Œéœ€è¦äººç±»å¯è¯»ã€è§£é‡Šæ€§å¼ºçš„è‡ªç„¶è¯­è¨€ã€‚

ä½¿ç”¨å†—é•¿çš„è‡ªç„¶è¯­è¨€è¿›è¡Œå†…éƒ¨è®¡ç®—ï¼Œä¼šæ¶ˆè€—å¤§é‡ä¸å¿…è¦çš„è®¡ç®—èµ„æºï¼ˆtokenï¼‰ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤æ‚çš„å¤šæ­¥æ¨ç†é—®é¢˜æ—¶ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šDenser (Dual-density Inference)
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œè®ºæ–‡æå‡ºäº† **Denser**ï¼Œä¸€ç§æ–°é¢–çš„**åŒå¯†åº¦æ¨ç†æ¡†æ¶**ï¼ˆDual-density Inferenceï¼‰ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ¨ç†è¿‡ç¨‹è§£è€¦ï¼Œå¯¹ä¸åŒé˜¶æ®µä½¿ç”¨ä¸åŒä¿¡æ¯å¯†åº¦çš„è¯­è¨€ï¼š

1.  **é«˜å¯†åº¦æ¨ç†ï¼ˆHigh-density Reasoningï¼‰**ï¼šåœ¨ä¸­é—´è®¡ç®—é˜¶æ®µï¼Œæ¨¡å‹ä½¿ç”¨**å‹ç¼©çš„ã€å¯Œå«ç¬¦å·çš„è¯­è¨€**ï¼ˆå¦‚æ•°å­¦å…¬å¼ã€é€»è¾‘ç¬¦å·ã€ä¼ªä»£ç ï¼‰è¿›è¡Œé«˜æ•ˆè®¡ç®—ã€‚è¿™æå¤§åœ°å‡å°‘äº†tokenæ¶ˆè€—ã€‚
2.  **ä½å¯†åº¦å›ç­”ï¼ˆLow-density Answeringï¼‰**ï¼šåœ¨æœ€ç»ˆè¾“å‡ºé˜¶æ®µï¼Œç³»ç»Ÿå°†å‹ç¼©çš„æ¨ç†è·¯å¾„**ç¿»è¯‘å¹¶æ‰©å±•**æˆæµç•…ã€æ˜“æ‡‚çš„è‡ªç„¶è¯­è¨€è§£é‡Šï¼Œä»¥æ»¡è¶³äººç±»ç”¨æˆ·çš„ç†è§£éœ€æ±‚ã€‚

è¯¥æ¡†æ¶ç”±ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼š
- **æŸ¥è¯¢åˆ†ææ¨¡å—ï¼ˆQuery Analysis Moduleï¼‰**ï¼šè¯†åˆ«è¾“å…¥é—®é¢˜çš„é¢†åŸŸï¼ˆæ•°å­¦ã€é€»è¾‘ã€ç¼–ç ç­‰ï¼‰å’Œå¤æ‚åº¦ï¼Œä»¥æŒ‡å¯¼åç»­çš„æ¨ç†ç­–ç•¥ã€‚
- **é«˜å¯†åº¦æ¨ç†æ¨¡å—ï¼ˆHigh-density Reasoning Moduleï¼‰**ï¼šæ‰§è¡Œæ ¸å¿ƒçš„ã€ç¬¦å·åŒ–çš„è®¡ç®—æ­¥éª¤ã€‚
- **ä½å¯†åº¦å›ç­”ç”Ÿæˆæ¨¡å—ï¼ˆLow-density Answering Moduleï¼‰**ï¼šå°†ç¬¦å·åŒ–çš„æ¨ç†ç»“æœè½¬åŒ–ä¸ºäººç±»å¯è¯»çš„ç­”æ¡ˆã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ˜¾è‘—æå‡æ•ˆç‡**ï¼šé€šè¿‡å‹ç¼©ä¸­é—´æ¨ç†ï¼Œå¤§å¹…å‡å°‘tokenæ¶ˆè€—ï¼Œä»è€Œé™ä½è®¡ç®—æˆæœ¬å’Œå»¶è¿Ÿã€‚
- **ä¿æŒç”šè‡³æå‡å‡†ç¡®æ€§**ï¼šé¿å…äº†åœ¨å†—é•¿æ–‡æœ¬ä¸­ä¸¢å¤±å…³é”®ä¿¡æ¯çš„é£é™©ï¼Œç¬¦å·åŒ–è¡¨è¾¾æ›´ç²¾ç¡®ï¼Œæœ‰åŠ©äºæé«˜æ¨ç†çš„å‡†ç¡®æ€§ã€‚
- **ç†è®ºåŸºç¡€æ‰å®**ï¼šæ˜ç¡®åŒºåˆ†äº†è¯­è¨€çš„â€œè®¡ç®—åŠŸèƒ½â€å’Œâ€œæ²Ÿé€šåŠŸèƒ½â€ï¼Œä¸ºä¼˜åŒ–æ¨ç†æä¾›äº†æ–°çš„ç†è®ºè§†è§’ã€‚
- **é€šç”¨æ€§å¼º**ï¼šæ¡†æ¶è®¾è®¡çµæ´»ï¼Œå¯æ ¹æ®ä¸åŒé¢†åŸŸï¼ˆæ•°å­¦ã€é€»è¾‘ã€ç¼–ç¨‹ï¼‰è‡ªé€‚åº”åœ°é€‰æ‹©æœ€ä¼˜çš„å‹ç¼©ç­–ç•¥ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒæ¶µç›–äº†å››ä¸ªæ ¸å¿ƒæ¨ç†é¢†åŸŸï¼Œå…±å…«ä¸ªåŸºå‡†æ•°æ®é›†ï¼š
- **æ•°å­¦ï¼ˆMathï¼‰**: GSM8K, MATH500
- **é€»è¾‘ï¼ˆLogicï¼‰**: LogiQA, ProofWriter
- **ç¼–ç ï¼ˆCodeï¼‰**: MBPP, HumanEval
- **é€šç”¨é—®ç­”ï¼ˆGeneral QAï¼‰**: MMLU, StrategyQA

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **ä¸»å¹²æ¨¡å‹**ï¼šä¸»è¦ä½¿ç”¨ **Qwen3-14B** è¿›è¡Œå®éªŒï¼Œå¹¶åœ¨å¤šä¸ªAPIæ¨¡å‹ï¼ˆå¦‚ GPT-4o, o1-mini, DeepSeek-V3, Claude-3.7-Sonnetï¼‰ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **æ€§èƒ½å‡†ç¡®ç‡ï¼ˆPerformance Accuracyï¼‰**ï¼šå„é¢†åŸŸçš„æ ‡å‡†å‡†ç¡®ç‡æŒ‡æ ‡ã€‚
  - **Tokenæ¶ˆè€—ï¼ˆToken Costï¼‰**ï¼šç”Ÿæˆçš„æ€»tokenæ•°ï¼Œç”¨äºè¡¡é‡æ•ˆç‡ã€‚
  - **è®¡ç®—å»¶è¿Ÿï¼ˆComputational Latencyï¼‰**ï¼šæ¯é“é¢˜ç›®çš„å¹³å‡æ¨ç†æ—¶é—´ï¼ˆç§’ï¼‰ã€‚
  - **æ¨ç†æ•ˆç‡æŒ‡æ•°ï¼ˆReasoning Efficiency Index, REIï¼‰**ï¼šç»¼åˆè¡¡é‡å‡†ç¡®ç‡ä¸tokenæ¶ˆè€—çš„æƒè¡¡ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å®éªŒå¯¹æ¯”äº†ä¸¤å¤§ç±»åŸºçº¿æ–¹æ³•ï¼š
1.  **Test-Time Scaling (TTS) æ–¹æ³•**ï¼šè¿™äº›æ–¹æ³•é€šå¸¸é€šè¿‡å¢åŠ tokenæ¥æå‡å‡†ç¡®ç‡ã€‚
    - Chain-of-Thought (CoT)
    - Self-Consistency (SC)
    - Tree-of-Thought (ToT)
    - Think-to-Think (T)
    - Reflection-CoT
    - Process Supervision
    - Self-Verification (SV)
2.  **æ¨ç†å‹ç¼©åŸºçº¿**ï¼šæ—¨åœ¨å‡å°‘tokenæ¶ˆè€—çš„æ–¹æ³•ã€‚
    - BeConcise (æç¤ºç®€æ´)
    - OnlyNumbers (ä»…è¾“å‡ºæ•°å­—å’Œç¬¦å·)
    - AbbreWords (ä½¿ç”¨ç¼©å†™)
    - TokenSkip (ä¸€ç§å…ˆè¿›çš„tokenå‰ªææŠ€æœ¯)

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
åœ¨ **Qwen3-14B** æ¨¡å‹ä¸Šçš„ä¸»è¦ç»“æœå¦‚ä¸‹ï¼ˆè§Table 4ï¼‰ï¼š

| æ–¹æ³• | å¹³å‡å‡†ç¡®ç‡ | Tokenæ¶ˆè€— (%) |
| :--- | :--- | :--- |
| **Denser (Ours)** | **81.5%** | **-58.7%** |
| Self-Verification (æœ€ä½³TTSåŸºçº¿) | 79.2% | +142.8% |
| Chain-of-Thought (CoT) | 77.3% | 0.0% |

- **å‡†ç¡®ç‡**ï¼šDenser åœ¨æ‰€æœ‰é¢†åŸŸå‡ä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•ï¼Œå¹³å‡å‡†ç¡®ç‡æ¯”æœ€å¼ºçš„TTSåŸºçº¿ï¼ˆSelf-Verificationï¼‰é«˜å‡º **1.8%**ã€‚
- **Tokenæ¶ˆè€—**ï¼šç›¸æ¯”æ ‡å‡†çš„CoTï¼ŒDenser å°†tokenæ¶ˆè€—**é™ä½äº†58.7%**ï¼Œè€Œå…¶ä»–TTSæ–¹æ³•åˆ™å¢åŠ äº†127%-345%çš„tokenæ¶ˆè€—ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **vs. TTSæ–¹æ³•**ï¼šDenser åœ¨**å¤§å¹…æå‡æ•ˆç‡**çš„åŒæ—¶ï¼Œè¿˜å®ç°äº†**æ›´é«˜çš„å‡†ç¡®ç‡**ã€‚ä¾‹å¦‚ï¼Œåœ¨GSM8Kä¸Šï¼ŒDenser å‡†ç¡®ç‡ä¸º88.2%ï¼Œè€ŒSelf-Verificationä¸º87.0%ï¼Œä½†åè€…tokenæ¶ˆè€—æ˜¯å‰è€…çš„è¿‘6å€ã€‚
- **vs. å‹ç¼©åŸºçº¿**ï¼šDenser çš„ä¼˜åŠ¿åœ¨äº**ä¿å…¨äº†è®¡ç®—å®Œæ•´æ€§**ã€‚åƒ `OnlyNumbers` è¿™æ ·çš„æ–¹æ³•è™½ç„¶tokenå‡å°‘æœ€å¤šï¼ˆ-66.2%ï¼‰ï¼Œä½†å‡†ç¡®ç‡å¤§å¹…ä¸‹é™ã€‚Denser åœ¨å®ç°æ˜¾è‘—å‹ç¼©çš„åŒæ—¶ï¼Œå‡†ç¡®ç‡ä¸é™åå‡ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
æ¶ˆèå®éªŒï¼ˆè§Table 6ï¼‰éªŒè¯äº†å„ç»„ä»¶çš„é‡è¦æ€§ï¼š
- **ç§»é™¤é«˜å¯†åº¦æ¨ç†æ¨¡å—**ï¼šå¯¼è‡´å‡†ç¡®ç‡**ä¸‹é™3.6%**ï¼Œtokenå‡å°‘ä»…8%ï¼Œè¯æ˜è¿™æ˜¯æ ¸å¿ƒåˆ›æ–°ã€‚
- **ç§»é™¤æŸ¥è¯¢åˆ†ææ¨¡å—**ï¼šå‡†ç¡®ç‡ä¸‹é™1.3%ï¼Œè¡¨æ˜è‡ªé€‚åº”é¢†åŸŸåˆ†æè‡³å…³é‡è¦ã€‚
- **ç§»é™¤ä½å¯†åº¦å›ç­”æ¨¡å—**ï¼šå‡†ç¡®ç‡å½±å“è¾ƒå°ï¼ˆ-0.7%ï¼‰ï¼Œä½†ä¼šç‰ºç‰²äººç±»å¯è¯»æ€§ã€‚
- **ä½¿ç”¨å›ºå®šå¯†åº¦ç­–ç•¥**ï¼šå‡†ç¡®ç‡ä¸‹é™2.4%ï¼Œè¯æ˜äº†**é¢†åŸŸè‡ªé€‚åº”**çš„å¿…è¦æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1.  **ä¿¡æ¯å¯†åº¦é”™é…æ˜¯æ•ˆç‡ç“¶é¢ˆ**ï¼šè®ºæ–‡è¯å®äº†åœ¨æ¨ç†ä¸­ç»Ÿä¸€ä½¿ç”¨è‡ªç„¶è¯­è¨€æ˜¯ä¸€ç§ä½æ•ˆçš„è®¾è®¡ã€‚åˆ†ç¦»è®¡ç®—å’Œæ²Ÿé€šåŠŸèƒ½å¯ä»¥å¸¦æ¥å·¨å¤§æ”¶ç›Šã€‚
2.  **Denser æ˜¾è‘—æå‡æ•ˆç‡**ï¼šåœ¨å¤šä¸ªåŸºå‡†ä¸Šï¼ŒDenser å°†tokenæ¶ˆè€—**æœ€é«˜å‡å°‘62%**ï¼ŒåŒæ—¶**ä¿æŒæˆ–æé«˜äº†å‡†ç¡®ç‡**ã€‚
3.  **æ•ˆç‡å¢ç›Šéšé—®é¢˜å¤æ‚åº¦å¢åŠ è€Œæ”¾å¤§**ï¼šå¯¹äºå¤æ‚åº¦é«˜çš„é—®é¢˜ï¼ŒDenser çš„tokenèŠ‚çœå¯è¾¾71%ï¼Œè¿œé«˜äºç®€å•é—®é¢˜çš„38%ã€‚
4.  **åœ¨ç¬¦å·åŒ–é¢†åŸŸä¼˜åŠ¿æœ€æ˜æ˜¾**ï¼šåœ¨æ•°å­¦ã€é€»è¾‘ç­‰æ‹¥æœ‰æˆç†Ÿç¬¦å·ç³»ç»Ÿçš„é¢†åŸŸï¼ŒDenser çš„æ€§èƒ½æå‡æœ€ä¸ºæ˜¾è‘—ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å¼•å…¥é¢å¤–å¼€é”€**ï¼šæŸ¥è¯¢åˆ†æå’Œç­”æ¡ˆç”Ÿæˆæ¨¡å—ä¼šå¸¦æ¥ä¸€å®šçš„è®¡ç®—å¼€é”€ï¼Œå¯èƒ½ä¸é€‚åˆå¯¹å»¶è¿Ÿæåº¦æ•æ„Ÿçš„åº”ç”¨ã€‚
- **æ€§èƒ½å¢ç›Šå› ä»»åŠ¡è€Œå¼‚**ï¼šåœ¨æŸäº›ä»»åŠ¡æˆ–æ¨¡å‹æ¶æ„ä¸Šï¼Œæ€§èƒ½æå‡å¯èƒ½ä¸å¦‚åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šé‚£ä¹ˆæ˜¾è‘—ã€‚
- **ä¾èµ–äºé¢†åŸŸé€‚é…**ï¼šæ–¹æ³•çš„æœ‰æ•ˆæ€§ä¾èµ–äºä¸ºä¸åŒé¢†åŸŸè®¾è®¡åˆé€‚çš„é«˜å¯†åº¦è¡¨ç¤ºï¼ˆå¦‚æ•°å­¦ç¬¦å·ã€é€»è¾‘æ¼”ç®—ã€ä¼ªä»£ç ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„é¢†åŸŸè‡ªé€‚åº”æœºåˆ¶ã€‚
- å°†è¯¥æ¡†æ¶åº”ç”¨äºæ›´å¤šéç»“æ„åŒ–æˆ–åˆ›é€ æ€§ä»»åŠ¡ï¼Œæ¢ç´¢å…¶è¾¹ç•Œã€‚
- ç ”ç©¶å¦‚ä½•å°†è¿™ç§åŒå¯†åº¦æ€æƒ³é›†æˆåˆ°æ¨¡å‹è®­ç»ƒä¸­ï¼Œè€Œä¸ä»…ä»…æ˜¯ä½œä¸ºæ¨ç†æ—¶çš„æç¤ºå·¥ç¨‹æŠ€å·§ã€‚

</details>

---

### 11. [How Does Fourier Analysis Network Work? A Mechanism Analysis and a New Dual-Activation Layer Proposal](https://arxiv.org/abs/2512.14873)

**Authors**: Sam Jeong, Hae Yong Kim  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.14873v1  

#### Abstract
Fourier Analysis Network (FAN) was recently proposed as a simple way to improve neural network performance by replacing part of ReLU activations with sine and cosine functions. Although several studies have reported small but consistent gains across tasks, the underlying mechanism behind these impro...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*How Does Fourier Analysis Network Work? A Mechanism Analysis and a New Dual-Activation Layer Proposal*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **æ¾„æ¸… FANï¼ˆFourier Analysis Networkï¼‰æœºåˆ¶çš„æ¨¡ç³Šæ€§**ï¼šå°½ç®¡å·²æœ‰ç ”ç©¶è§‚å¯Ÿåˆ° FAN åœ¨å¤šç§ä»»åŠ¡ä¸­èƒ½å¸¦æ¥æ€§èƒ½æå‡ï¼Œä½†å…¶èƒŒåçš„ä½œç”¨æœºåˆ¶å°šä¸æ˜ç¡®ã€‚åŸå§‹å‡è®¾è®¤ä¸º sine å’Œ cosine çš„å‘¨æœŸæ€§æœ‰åŠ©äºæ•æ‰ä¿¡å·ä¸­çš„å‘¨æœŸæ¨¡å¼ï¼Œä½†è¯¥è§£é‡Šç¼ºä¹å®è¯æ”¯æŒã€‚
- **æ­ç¤º cosine æ¿€æ´»å‡½æ•°çš„è´Ÿé¢å½±å“**ï¼šæ­¤å‰æœªæœ‰äººç‹¬ç«‹åˆ†æ sine ä¸ cosine åœ¨ FAN ä¸­å„è‡ªçš„ä½œç”¨ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
- **Dual-Activation Layer (DAL)**ï¼šæå‡ºä¸€ç§æ–°çš„æ¿€æ´»å±‚è®¾è®¡ï¼Œå°† ReLU ç±»å‹æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ ReLUã€Leaky ReLUã€GELUã€Swishï¼‰ä¸å…·æœ‰éé›¶å¯¼æ•°ä¸”å…³äºåŸç‚¹å¯¹ç§°çš„å¹³æ»‘å‡½æ•°ï¼ˆå¦‚ sine æˆ– tanhï¼‰æŒ‰æ¯”ä¾‹æ··åˆã€‚
  - å½¢å¼åŒ–è¡¨ç¤ºä¸º `(f, g, a:b)`ï¼Œå…¶ä¸­ï¼š
    - `f` æ˜¯ä¸»æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ ReLUï¼‰
    - `g` æ˜¯è¾…åŠ©æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ sineï¼‰
    - `a:b` æ˜¯ä¸¤è€…çš„æ¯”ä¾‹
- **ç†è®ºæ´è§é©±åŠ¨è®¾è®¡**ï¼šæå‡ºæ€§èƒ½æå‡å¹¶éæºäº sine çš„å‘¨æœŸæ€§ï¼Œè€Œæ˜¯å…¶åœ¨ $x=0$ é™„è¿‘çš„å±€éƒ¨è¡Œä¸ºâ€”â€”ç‰¹åˆ«æ˜¯éé›¶å¯¼æ•°ï¼Œèƒ½å¤Ÿç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´é«˜æ•ˆæ”¶æ•›**ï¼šç›¸æ¯”æ ‡å‡† ReLU åŠå…¶å˜ä½“ï¼ˆLeaky ReLUã€GELUã€Swishï¼‰ï¼ŒDAL æ˜¾è‘—åŠ é€Ÿè®­ç»ƒåˆæœŸçš„æ”¶æ•›é€Ÿåº¦ã€‚
- **å‡å°‘â€œæ­»äº¡ç¥ç»å…ƒâ€ç°è±¡**ï¼šé€šè¿‡å¼•å…¥ç¨³å®šæ¢¯åº¦è·¯å¾„ï¼Œæœ‰æ•ˆé™ä½å› è¾“å…¥é•¿æœŸä¸ºè´Ÿè€Œå¯¼è‡´çš„â€œdead neuronâ€é—®é¢˜ã€‚
- **é€šç”¨æ€§å¼º**ï¼šå¯ä¸ç°ä»£æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ GELUã€Swishï¼‰ç»“åˆä½¿ç”¨ï¼Œå¹¶å…¼å®¹ Batch Normalizationã€æ®‹å·®è¿æ¥ç­‰æŠ€æœ¯ï¼Œå…·å¤‡ååŒå¢æ•ˆæ½œåŠ›ã€‚
- **è®¡ç®—å¼€é”€å°**ï¼šä»…æ›¿æ¢éƒ¨åˆ†æ¿€æ´»å‡½æ•°ï¼Œå‡ ä¹ä¸å¢åŠ æ¨¡å‹å¤æ‚åº¦ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | ç±»å‹ | ä»»åŠ¡ |
|-------|------|-----|
| åˆæˆ 1D ä¿¡å· | æ­£å¼¦å™ªå£° vs çº¯é«˜æ–¯å™ªå£° | äºŒåˆ†ç±» |
| MNIST | æ‰‹å†™æ•°å­—å›¾åƒ | å¤šç±»åˆ†ç±»ï¼ˆ10ç±»ï¼‰ |
| ECG-ID | å•å¯¼è”å¿ƒç”µå›¾ï¼ˆECGï¼‰ | ç”Ÿç‰©ç‰¹å¾è¯†åˆ«ï¼ˆ90äººèº«ä»½åˆ†ç±»ï¼‰ |

### âš™ï¸ å®éªŒè®¾ç½®
- **ç½‘ç»œæ¶æ„**ï¼š
  - åˆæˆä¿¡å· & ECG-IDï¼š1D CNN æ¶æ„
  - MNISTï¼š2D CNN æ¶æ„
- **è®­ç»ƒé…ç½®**ï¼š
  - ä¼˜åŒ–å™¨ï¼šAdam
  - æŸå¤±å‡½æ•°ï¼šBinary Crossentropyï¼ˆåˆæˆä»»åŠ¡ï¼‰ã€Categorical Crossentropyï¼ˆMNISTã€ECG-IDï¼‰
  - åˆå§‹åŒ–ï¼šç›¸åŒéšæœºç§å­ç¡®ä¿å¯æ¯”æ€§
  - é‡å¤å®éªŒå¤šæ¬¡ï¼ˆN=50~100æ¬¡ï¼‰è¿›è¡Œç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰
  - æŸå¤±å€¼ï¼ˆLossï¼‰
  - æ”¶æ•›é€Ÿåº¦ï¼ˆæ—©æœŸ epoch è¡¨ç°ï¼‰
  - â€œæ­»äº¡ç¥ç»å…ƒâ€æ¯”ä¾‹ï¼ˆæ¯å±‚è¾“å‡ºæ’ä¸º0çš„æ¯”ä¾‹ï¼‰

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| ReLU-only | æ ‡å‡†åŸºçº¿ |
| FAN (ReLU + sin + cos, 6:1:1) | åŸå§‹ FAN ç»“æ„ |
| (ReLU, sin, 6:2) | æå‡ºçš„ DAL é…ç½® |
| (ReLU, cos, 6:2) | åˆ†ç¦» cosine æ•ˆæœ |
| (ReLU, tanh/TSine/linear, 6:2) | éªŒè¯å‘¨æœŸæ€§æ˜¯å¦å¿…è¦ |
| GELU / Leaky ReLU / Swish-only | ç°ä»£æ¿€æ´»å‡½æ•°åŸºçº¿ |
| (GELU, sin, 7:1) ç­‰ | DAL ä¸ç°ä»£æ¿€æ´»ç»“åˆ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### ï¼ˆ1ï¼‰åˆæˆ 1D ä¿¡å·åˆ†ç±»ï¼ˆNoisy Sinusoid vs Noiseï¼‰
| æ¨¡å‹ | å¹³å‡å‡†ç¡®ç‡ï¼ˆM=10ï¼‰ | p-value |
|------|------------------|--------|
| ReLU-only | 0.7826 | â€” |
| (ReLU, sin, cos, 6:1:1) | 0.8340 | 0.0026 |
| (ReLU, cos, 6:2) | 0.7608 | â€” |
| **(ReLU, sin, 6:2)** | **0.8153** | **0.0035** |

> âœ… ç»“è®ºï¼šåªæœ‰ sine èµ·æ­£å‘ä½œç”¨ï¼›cosine å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

å½“è®­ç»ƒå»¶é•¿è‡³ M=60 epochsï¼š
- æœ€ç»ˆå‡†ç¡®ç‡è¶‹åŒï¼ˆ0.8579 vs 0.8572, p=0.9127ï¼‰
- ä½† **(ReLU, sin, 6:2) æ”¶æ•›æ›´å¿«**

#### ï¼ˆ2ï¼‰MNIST æ•°å­—åˆ†ç±»
| æ¨¡å‹ | è®­ç»ƒå‡†ç¡®ç‡ï¼ˆM=5ï¼‰ | æµ‹è¯•å‡†ç¡®ç‡ï¼ˆM=5ï¼‰ | p-value |
|------|------------------|------------------|--------|
| ReLU-only | 0.9939 | 0.9905 | â€” |
| **(ReLU, sin, 6:2)** | **0.9957** | **0.9910** | **<0.05** |

> âœ… ç»Ÿè®¡æ˜¾è‘—å·®å¼‚ï¼Œè¡¨æ˜ DAL åŠ é€Ÿæ—©æœŸå­¦ä¹ è¿‡ç¨‹ã€‚

M=30 epochs åä¸¤è€…æœ€ç»ˆæ€§èƒ½æ¥è¿‘ï¼Œä½† DAL è¿‡æ‹Ÿåˆæ›´è½»ã€‚

#### ï¼ˆ3ï¼‰ECG-ID ç”Ÿç‰©è¯†åˆ«ï¼ˆæ—  BatchNormï¼‰
| æ¨¡å‹ | æµ‹è¯•å‡†ç¡®ç‡ï¼ˆM=50ï¼‰ | æµ‹è¯•å‡†ç¡®ç‡ï¼ˆM=500ï¼‰ |
|------|--------------------|----------------------|
| ReLU-only | 0.1580 | 0.8483 |
| **(ReLU, sin, 1:1)** | **0.3178** | **0.9372** |
| p-value | <0.0001 | <0.0001 |

> âœ… ä¸ä»…æ”¶æ•›å¿«ï¼Œä¸”è¾¾åˆ°æ›´é«˜çš„æœ€ç»ˆæ€§èƒ½ï¼

#### ï¼ˆ4ï¼‰ECG-IDï¼ˆå« BatchNormï¼‰
| æ¨¡å‹ | æµ‹è¯•å‡†ç¡®ç‡ï¼ˆM=500ï¼‰ |
|------|----------------------|
| ReLU-only | 0.9054 |
| **(ReLU, sin, 1:1)** | **0.9355**, p=0.0000 |

> âœ… å³ä½¿åŠ å…¥ BN ç¼“è§£äº†æ­»äº¡ç¥ç»å…ƒé—®é¢˜ï¼ŒDAL ä»ä¿æŒä¼˜åŠ¿ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœ

| å®éªŒç›®çš„ | å‘ç° |
|--------|------|
| æ˜¯å¦ cosine æœ‰ç›Šï¼Ÿ | âŒ (ReLU, cos, 6:2) æ€§èƒ½ä½äº ReLU-only |
| æ˜¯å¦ sine çš„å‘¨æœŸæ€§é‡è¦ï¼Ÿ | âŒ ä½¿ç”¨éå‘¨æœŸå‡½æ•°ï¼ˆtanhã€truncated sineã€linearï¼‰æ•ˆæœç›¸è¿‘ï¼Œè¯´æ˜å…³é”®æ˜¯å±€éƒ¨å½¢çŠ¶è€Œéå‘¨æœŸæ€§ |
| æ˜¯å¦åªé€‚ç”¨äº ReLUï¼Ÿ | âŒ å¦ï¼åœ¨ GELUã€Leaky ReLUã€Swish ä¸Šä¹Ÿè§‚å¯Ÿåˆ°åŠ é€Ÿæ”¶æ•› |
| æ˜¯å¦å‡å°‘æ­»äº¡ç¥ç»å…ƒï¼Ÿ | âœ… è¡¨æ ¼æ˜¾ç¤º DAL å±‚ä¸­æ­»äº¡ç¥ç»å…ƒæ¯”ä¾‹æ˜¾è‘—æ›´ä½ï¼ˆå¦‚ dense layer ä» 36.95% â†’ 16.80%ï¼‰ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **FAN çš„æ€§èƒ½æå‡ä¸»è¦æ¥è‡ª sineï¼Œè€Œé cosine**ï¼š
   - cosine æ¿€æ´»å€¾å‘äºæŸå®³æ¨¡å‹æ€§èƒ½ã€‚
2. **æ€§èƒ½å¢ç›Šæºäºå±€éƒ¨æ¢¯åº¦ç‰¹æ€§ï¼Œè€Œéå‘¨æœŸæ€§å‡è®¾**ï¼š
   - sine åœ¨ $x=0$ å¤„æœ‰éé›¶å¯¼æ•°ï¼Œæä¾›ç¨³å®šçš„æ¢¯åº¦æµï¼Œç¼“è§£â€œdying ReLUâ€é—®é¢˜ã€‚
3. **å‘¨æœŸæ€§ä¸æ˜¯å…³é”®å› ç´ **ï¼š
   - tanhã€truncated sineã€linear ç­‰éå‘¨æœŸå‡½æ•°ä¹Ÿèƒ½å–å¾—ç±»ä¼¼ç”šè‡³æ›´å¥½æ•ˆæœã€‚
4. **DAL æ˜¯ FAN çš„ç®€åŒ–ä¸å¼ºåŒ–ç‰ˆæœ¬**ï¼š
   - ç§»é™¤ cosine åæ€§èƒ½åè€Œæå‡ï¼Œè¯æ˜ cosine æ˜¯å†—ä½™ç”šè‡³æœ‰å®³çš„ã€‚
5. **å¹¿æ³›é€‚ç”¨æ€§**ï¼š
   - åœ¨åˆæˆä¿¡å·ã€å›¾åƒï¼ˆMNISTï¼‰ã€ç”Ÿç†ä¿¡å·ï¼ˆECGï¼‰ä¸Šå‡éªŒè¯æœ‰æ•ˆã€‚
   - å¯ä¸ç°ä»£æ¿€æ´»å‡½æ•°å’Œæ­£åˆ™åŒ–æŠ€æœ¯ï¼ˆå¦‚ BNï¼‰å…±å­˜å¹¶äº§ç”ŸååŒæ•ˆåº”ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **æœ€ä¼˜æ¯”ä¾‹ä¾èµ–ä»»åŠ¡å’Œæ¶æ„**ï¼šå¦‚ MNIST æ¨è 6:2ï¼Œè€Œ ECG-ID æ›´é€‚åˆ 1:1ï¼Œéœ€è°ƒå‚ã€‚
- **å¯¹ç®€å•ä»»åŠ¡å¯èƒ½ä»…åŠ å¿«æ”¶æ•›ï¼Œä¸æå‡æœ€ç»ˆç²¾åº¦**ï¼šå¦‚ MNIST å’Œåˆæˆä»»åŠ¡ä¸­ï¼Œé•¿æ—¶é—´è®­ç»ƒåå·®è·ç¼©å°ã€‚
- **sine å‡½æ•°åœ¨æç«¯è¾“å…¥ä¸‹å¯èƒ½å‡ºç°æŒ¯è¡è¡Œä¸º**ï¼šè™½ç„¶å®éªŒä¸­æœªå‡ºç°ï¼Œä½†åœ¨æç«¯åˆ†å¸ƒä¸‹éœ€æ³¨æ„ç¨³å®šæ€§ã€‚
- **ç¡¬ä»¶å®ç°è€ƒè™‘**ï¼šsine è®¡ç®—æ¯” ReLU ç¨å¤æ‚ï¼Œä½†åœ¨ç°ä»£æ¡†æ¶ä¸­å½±å“æå°ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **è‡ªåŠ¨åŒ–æ¯”ä¾‹æœç´¢æœºåˆ¶**ï¼šè®¾è®¡è‡ªé€‚åº”è°ƒæ•´ `a:b` æ¯”ä¾‹çš„æ–¹æ³•ã€‚
2. **æ‰©å±•åˆ° Transformer å’Œ KAN æ¶æ„**ï¼šæ¢ç´¢ DAL åœ¨æ³¨æ„åŠ›æœºåˆ¶æˆ– Kolmogorov-Arnold ç½‘ç»œä¸­çš„åº”ç”¨ã€‚
3. **ä¸å…¶ä»–æ¢¯åº¦å¢å¼ºæŠ€æœ¯è”åˆå»ºæ¨¡**ï¼šç ”ç©¶ DAL ä¸æ®‹å·®è¿æ¥ã€LayerNormã€ä¼˜åŒ–å™¨è®¾è®¡çš„æ·±å±‚äº¤äº’ã€‚
4. **ç†è®ºåˆ†æ**ï¼šå»ºç«‹å…³äºæ··åˆæ¿€æ´»å¦‚ä½•å½±å“æŸå¤±æ›²é¢å’Œå¹³æ»‘æ€§çš„æ•°å­¦æ¨¡å‹ã€‚
5. **éƒ¨ç½²åœºæ™¯éªŒè¯**ï¼šåœ¨è¾¹ç¼˜è®¾å¤‡æˆ–å®æ—¶ç³»ç»Ÿä¸­æµ‹è¯• DAL çš„å®é™…æ•ˆç‡ä¸é²æ£’æ€§ã€‚

---

## æ€»ç»“

æœ¬æ–‡é€šè¿‡å¯¹ FAN çš„æ·±å…¥æœºåˆ¶åˆ†æï¼Œé¢ è¦†äº†â€œå‘¨æœŸæ€§æœ‰ç›Šâ€çš„ç›´è§‰è®¤çŸ¥ï¼Œæ­ç¤ºäº† **sine æ¿€æ´»çš„ä»·å€¼åœ¨äºå…¶åœ¨åŸç‚¹é™„è¿‘è‰¯å¥½çš„æ¢¯åº¦æ€§è´¨**ï¼Œä»è€Œæå‡ºäº†æ›´ç®€æ´æœ‰æ•ˆçš„ **Dual-Activation Layer (DAL)**ã€‚å®éªŒè¯æ˜ DAL èƒ½æ˜¾è‘—åŠ é€Ÿè®­ç»ƒã€å‡å°‘æ­»äº¡ç¥ç»å…ƒï¼Œåœ¨å¤šä¸ªçœŸå®ä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºä¼ ç»ŸåŠç°ä»£æ¿€æ´»å‡½æ•°ç»„åˆï¼Œæ˜¯ä¸€ç§è½»é‡çº§ã€é€šç”¨æ€§å¼ºçš„è®­ç»ƒåŠ é€Ÿç»„ä»¶ã€‚

</details>

---

### 12. [Accelerating High-Throughput Catalyst Screening by Direct Generation of Equilibrium Adsorption Structures](https://arxiv.org/abs/2512.15228)

**Authors**: Songze Huo, Xiao-Ming Cao  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.15228v1  

#### Abstract
The adsorption energy serves as a crucial descriptor for the large-scale screening of catalysts. Nevertheless, the limited distribution of training data for the extensively utilised machine learning interatomic potential (MLIP), predominantly sourced from near-equilibrium structures, results in unre...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAccelerating High-Throughput Catalyst Screening by Direct Generation of Equilibrium Adsorption Structures

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨**å¼‚ç›¸å‚¬åŒ–ååº”**ä¸­ï¼Œ**å¸é™„èƒ½**ï¼ˆadsorption energyï¼‰æ˜¯è¡¡é‡å‚¬åŒ–å‰‚æ´»æ€§çš„å…³é”®æè¿°ç¬¦ã€‚ç„¶è€Œï¼Œå‡†ç¡®è®¡ç®—å¸é™„èƒ½ä¾èµ–äºå¯¹å¸é™„ç»“æ„è¿›è¡Œé«˜ç²¾åº¦çš„å‡ ä½•ä¼˜åŒ–ï¼ˆgeometry relaxationï¼‰ï¼Œä¼ ç»Ÿä¸Šä¾èµ–**å¯†åº¦æ³›å‡½ç†è®º**ï¼ˆDFTï¼‰è®¡ç®—ï¼Œå…¶æ—¶é—´å¤æ‚åº¦ä¸º $O(n^3)$ï¼Œè®¡ç®—æˆæœ¬æé«˜ï¼Œä¸¥é‡åˆ¶çº¦äº†å¤§è§„æ¨¡å‚¬åŒ–å‰‚çš„é«˜é€šé‡ç­›é€‰ã€‚

å°½ç®¡å·²æœ‰åŸºäº**æœºå™¨å­¦ä¹ åŠ¿å‡½æ•°**ï¼ˆMLIPï¼‰çš„æ–¹æ³•å°è¯•æ›¿ä»£ DFT è¿›è¡Œç»“æ„ä¼˜åŒ–ï¼Œä½†è¿™äº›æ¨¡å‹é€šå¸¸éœ€è¦è¦†ç›–æ•´ä¸ª**åŠ¿èƒ½é¢**ï¼ˆPESï¼‰çš„å¤§è§„æ¨¡è®­ç»ƒæ•°æ®ï¼Œä¸”è®­ç»ƒæ•°æ®å¤šé›†ä¸­äºå¹³è¡¡æ€é™„è¿‘ï¼Œå¯¼è‡´å¯¹éå¹³è¡¡åˆå§‹ç»“æ„çš„ä¼˜åŒ–è½¨è¿¹ä¸å¯é ï¼Œé¢„æµ‹çš„å¸é™„ç»“æ„å’Œèƒ½é‡ä¸å‡†ç¡®ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šDBCata
æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º **DBCata**ï¼ˆDiffusion Bridge Model for Catalystsï¼‰çš„æ–°å‹æ·±åº¦ç”Ÿæˆæ¨¡å‹ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **ç›´æ¥å»ºæ¨¡ä»åˆå§‹æœªå¼›è±«ç»“æ„åˆ° DFT å¼›è±«ç»“æ„çš„è½¬æ¢è¿‡ç¨‹**ï¼Œè€Œéæ‹Ÿåˆæ•´ä¸ª PESã€‚
- åŸºäº**å‘¨æœŸæ€§å¸ƒæœ—æ¡¥æ¡†æ¶**ï¼ˆperiodic Brownian-bridge frameworkï¼‰å’Œ**ç­‰å˜å›¾ç¥ç»ç½‘ç»œ**ï¼ˆequivariant GNN, å¦‚ PaiNNï¼‰ï¼Œæ„å»ºä¸€ä¸ªä½ç»´è¿‡æ¸¡æµå½¢ï¼ˆlow-dimensional transition manifoldï¼‰ã€‚
- åœ¨è®­ç»ƒé˜¶æ®µï¼Œé€šè¿‡å‘åˆå§‹ä¸ç›®æ ‡ç»“æ„ä¹‹é—´çš„æ’å€¼è·¯å¾„æ·»åŠ å™ªå£°æ¥æ¨¡æ‹Ÿå¸ƒæœ—æ¡¥è¿‡ç¨‹ï¼›åœ¨ç”Ÿæˆé˜¶æ®µï¼Œé€šè¿‡ç¡®å®šæ€§ ODE é‡‡æ ·å¿«é€Ÿç”Ÿæˆé«˜ä¿çœŸåº¦çš„å¼›è±«ç»“æ„ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **æ— éœ€èƒ½é‡/åŠ›æ ‡ç­¾** | DBCata ä»…éœ€æˆå¯¹çš„åˆå§‹-å¼›è±«ç»“æ„æ•°æ®ï¼Œæ— éœ€ DFT è®¡ç®—çš„èƒ½é‡æˆ–åŸå­åŠ›ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œæ˜¾è‘—é™ä½æ•°æ®å‡†å¤‡æˆæœ¬ã€‚ |
| **é«˜æ•ˆæ€§** | å•ä¸ªç»“æ„ç”Ÿæˆæ—¶é—´ < 1 ç§’ï¼Œæ¯”ä¼ ç»Ÿ DFT å¿«çº¦ $10^4$ å€ï¼Œæ¯”å½“å‰æœ€å…ˆè¿›çš„ MLIPï¼ˆå¦‚ UMA-OC20ï¼‰å¿«çº¦ 10 å€ã€‚ |
| **é«˜ç²¾åº¦** | åœ¨ Catalysis-Hub æ•°æ®é›†ä¸Šï¼Œ**DMAE**ï¼ˆDistance Mean Absolute Errorï¼‰ä»…ä¸º **0.035 Ã…**ï¼Œçº¦ä¸º UMA-OC20 çš„ 1/3ã€‚ |
| **å¼ºæ³›åŒ–èƒ½åŠ›** | å¯¹å¤šç§å¸é™„ç‰©ï¼ˆH, C, O, OH, S ç­‰ï¼‰å’Œä¸åŒæ™¶é¢ï¼ˆfcc(111), fcc(110)ï¼‰å‡è¡¨ç°ç¨³å®šã€‚ |
| **å¯é›†æˆå¼‚å¸¸æ£€æµ‹** | æå‡ºæ··åˆåŒ–å­¦å¯å‘å¼ä¸è‡ªç›‘ç£å¼‚å¸¸æ£€æµ‹æœºåˆ¶ï¼Œè¯†åˆ«å¹¶ä¿®æ­£å¼‚å¸¸é¢„æµ‹ï¼Œè¿›ä¸€æ­¥æå‡å¯é æ€§ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **Catalysis-Hub Dataset**ï¼šå…¬å¼€çš„å‚¬åŒ–æ•°æ®åº“ï¼ŒåŒ…å«çº¦ 80,000 æ¡é‡‘å±åŠåˆé‡‘è¡¨é¢çš„ DFT å¼›è±«è½¨è¿¹ï¼ˆä½¿ç”¨ BEEF-vdW æ³›å‡½ï¼‰ã€‚
- ä»ä¸­æå– **76,737 å¯¹**åˆå§‹-å¼›è±«ç»“æ„ï¼Œæ¶µç›– 12 ç±»å¸é™„ç‰©ï¼ˆH, C, CH, CHâ‚‚, CHâ‚ƒ, N, NH, O, OH, Hâ‚‚O, S, SHï¼‰ã€‚
- æ•°æ®æŒ‰ 8:2 åˆ’åˆ†ä¸ºè®­ç»ƒé›†ï¼ˆ58,943ï¼‰å’Œæµ‹è¯•é›†ï¼ˆ14,728ï¼‰ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šåŸºäº Brownian Bridge çš„æ‰©æ•£ç”Ÿæˆæ¨¡å‹ï¼Œé‡‡ç”¨ **PaiNN** ä½œä¸ºç­‰å˜ GNN ä¸»å¹²ã€‚
- **å‘¨æœŸè¾¹ç•Œæ¡ä»¶å¤„ç†**ï¼š
  - ä½¿ç”¨**å¤šå›¾æ–¹æ³•**ï¼ˆmulti-graphï¼‰æœç´¢å‘¨æœŸé•œåƒä¸­çš„é‚»å±…åŸå­ã€‚
  - æå‡º**æœ€è¿‘åŸå­æ’å€¼æ³•**ï¼ˆnearest-atom interpolationï¼‰ç¡®ä¿æ’å€¼è·¯å¾„æ»¡è¶³ PBCã€‚
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - æ‰©æ•£æ­¥æ•° $T=100$ï¼Œæœ€å¤§å™ªå£°æ–¹å·® $\sigma_{\text{max}}=0.05$ã€‚
  - éšè—ç»´åº¦ 256ï¼Œå±‚æ•° 4ï¼Œå­¦ä¹ ç‡ $10^{-4}$ï¼ŒAdamW ä¼˜åŒ–å™¨ã€‚
  - ä½¿ç”¨å•å¼  NVIDIA RTX 4090 GPUï¼Œè®­ç»ƒè€—æ—¶çº¦ 12 å°æ—¶ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ä¸ç”¨é€” |
|------|-----------|
| **DMAE**ï¼ˆDistance Mean Absolute Errorï¼‰ | è¡¡é‡ç”Ÿæˆç»“æ„ä¸ DFT å¼›è±«ç»“æ„ä¹‹é—´æ‰€æœ‰åŸå­å¯¹è·ç¦»çš„å¹³å‡ç»å¯¹è¯¯å·®ï¼Œå•ä½ Ã…ã€‚ç”¨äºè¯„ä¼°å‡ ä½•ç²¾åº¦ã€‚ |
| **Success Rate @ 0.1 eV** | å¸é™„èƒ½é¢„æµ‹è¯¯å·® â‰¤ 0.1 eV çš„æ ·æœ¬å æ¯”ï¼Œåæ˜ èƒ½é‡é¢„æµ‹å‡†ç¡®æ€§ã€‚ |
| **Ionic Steps** | DFT å†ä¼˜åŒ–æ‰€éœ€çš„ç¦»å­æ­¥æ•°ï¼Œè¡¡é‡åˆå§‹çŒœæµ‹è´¨é‡ã€‚ |
| **Force/Energy RMSE** | MLIP é¢„æµ‹åŠ›ä¸ DFT åŠ›ä¹‹é—´çš„å‡æ–¹æ ¹è¯¯å·®ï¼Œè¯„ä¼° MLIP åœ¨ä¸åŒåŒºåŸŸçš„å¯é æ€§ã€‚ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **DFT Relaxation**ï¼šé‡‘æ ‡å‡†ï¼Œä½†ææ…¢ã€‚
- **UMA-OC20**ï¼šå½“å‰æœ€å…ˆè¿›çš„é¢„è®­ç»ƒ MLIP æ¨¡å‹ï¼ˆæ¥è‡ª Open Catalyst Projectï¼‰ï¼Œç”¨äºç»“æ„ä¼˜åŒ–å’Œèƒ½é‡è¯„ä¼°ã€‚
- **FAIRChem**ï¼šå¦ä¸€ä¸»æµ MLIP æ¡†æ¶ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ–¹æ³• | DMAE (Ã…) | Success Rate @ 0.1 eV | å•ç»“æ„ç”Ÿæˆæ—¶é—´ | é€Ÿåº¦æå‡å€æ•° |
|------|----------|------------------------|----------------|---------------|
| DFT Relaxation | / | / | ~850 s | 1x |
| UMA-OC20 | 0.1133 | 68% | ~9.8 s | 87x |
| **DBCata** | **0.0352** | **91%** | **~0.2 s** | **~4,000x** |
| DBCata + OD + DFT | 0.0281 | 94% | â€” | â€” |

> æ³¨ï¼šDBCata + OD è¡¨ç¤ºç»“åˆå¼‚å¸¸æ£€æµ‹åå¯¹å¼‚å¸¸æ ·æœ¬è¿›è¡Œ DFT å†ä¼˜åŒ–ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **å‡ ä½•ç²¾åº¦**ï¼šDBCata çš„ DMAE æ¯” UMA-OC20 ä½è¿‘ **3 å€**ï¼ˆ0.035 vs 0.113 Ã…ï¼‰ã€‚
- **èƒ½é‡é¢„æµ‹ç²¾åº¦**ï¼š
  - DBCata ç”Ÿæˆç»“æ„ç» DFT å•ç‚¹è®¡ç®—åï¼Œ91% çš„å¸é™„èƒ½è¯¯å·® < 0.1 eVï¼Œæ˜¾è‘—ä¼˜äº UMA-OC20 çš„ 68%ã€‚
  - å›¾ 2 æ˜¾ç¤º DBCata çš„å¸é™„èƒ½é¢„æµ‹ä¸ DFT ç»“æœå…·æœ‰æ›´å¼ºçš„ä¸€è‡´æ€§ï¼ˆ$R^2 = 0.983$ vs 0.877ï¼‰ã€‚
- **å†ä¼˜åŒ–æ•ˆç‡**ï¼š
  - ä»åˆå§‹ç»“æ„ç›´æ¥ DFT å¼›è±«å¹³å‡éœ€ **65 æ­¥**ï¼›
  - ä» DBCata ç”Ÿæˆç»“æ„å¼€å§‹ä»…éœ€ **15 æ­¥**å³å¯æ”¶æ•›ï¼ˆå›¾ 3aï¼‰ï¼›
  - æ€»ä½“èŠ‚çœè¶…è¿‡ 80% çš„ DFT è®¡ç®—æˆæœ¬ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆè§ Supplementary Table 4ï¼‰
| å˜ä½“ | Fractional Coord | Gaussian Basis | Fourier Basis | DMAE (Ã…) |
|------|------------------|----------------|---------------|----------|
| Baseline | âœ— | âœ“ | âœ— | 0.0409 |
| Baseline | âœ“ | âœ— | âœ“ | 0.0621 |
| **Baseline** | âœ— | âœ— | âœ“ | **0.0353** |

> ç»“è®ºï¼šä½¿ç”¨ Cartesian åæ ‡ + Fourier ç‰¹å¾ç¼–ç ï¼ˆç”¨äºå‘¨æœŸæ€§ä½ç½®åµŒå…¥ï¼‰æ•ˆæœæœ€ä½³ã€‚

### å¼‚å¸¸æ£€æµ‹æœ‰æ•ˆæ€§ï¼ˆå›¾ 3c & Table S5ï¼‰
- å¼‚å¸¸åˆ†ç±»å™¨è¾“å‡ºçš„ç½®ä¿¡åº¦ä¸ DMAE è´Ÿç›¸å…³ï¼š**ä½ç½®ä¿¡åº¦ â†’ é«˜ DMAE**ã€‚
- åˆ†ç±»å™¨åœ¨æµ‹è¯•é›†ä¸Šçš„ F1-score è¾¾ **0.92**ï¼ˆæ­£ç±»ä¸ºæ­£å¸¸ç»“æ„ï¼‰ï¼Œèƒ½æœ‰æ•ˆè¯†åˆ«å¼‚å¸¸ã€‚
- ç»å¼‚å¸¸æ£€æµ‹ä¸å†ä¼˜åŒ–åï¼Œé¢„æµ‹å‡†ç¡®ç‡ä» 91% æå‡è‡³ **94%**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **DBCata èƒ½é«˜æ•ˆä¸”é«˜ç²¾åº¦åœ°ç”Ÿæˆæ¥è¿‘ DFT å¹³è¡¡æ€çš„å¸é™„ç»“æ„**ï¼Œå…¶æ€§èƒ½è¿œè¶…å½“å‰ä¸»æµ MLIP æ¨¡å‹ã€‚
2. **ç”Ÿæˆç»“æ„å·²å¤„äº PES çš„è¿‘å¹³è¡¡åŒº**ï¼Œä½¿å¾—åç»­ MLIP æˆ– DFT ä¼˜åŒ–æä¸ºé«˜æ•ˆï¼Œé¿å…é™·å…¥é”™è¯¯å±€éƒ¨æå°ã€‚
3. **ç»“åˆå¼‚å¸¸æ£€æµ‹æœºåˆ¶å¯è¿›ä¸€æ­¥æå‡é²æ£’æ€§**ï¼Œå®ç°â€œå¿«é€Ÿåˆç­› + ç²¾ç»†éªŒè¯â€çš„ä¸¤é˜¶æ®µå‚¬åŒ–ç­›é€‰æµç¨‹ã€‚
4. **æˆåŠŸåº”ç”¨äº ORR å‚¬åŒ–å‰‚é«˜é€šé‡ç­›é€‰**ï¼š
   - è‡ªåŠ¨æ„å»º 1,760 ç§äºŒå…ƒåˆé‡‘ä½“ç³»ï¼Œç”Ÿæˆ 15,911 ä¸ªåˆå§‹å¸é™„æ„å‹ã€‚
   - DBCata åœ¨ **5 åˆ†é’Ÿå†…å®Œæˆå…¨éƒ¨ç»“æ„å¼›è±«**ã€‚
   - å‘ç°å¤šä¸ªæœ‰æ½œåŠ›çš„å€™é€‰ææ–™ï¼Œå¦‚ **AgAu(110)** åœ¨ç¢±æ€§æ¡ä»¶ä¸‹å¯èƒ½è¡¨ç°å‡ºä¼˜å¼‚ ORR æ´»æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡çš„åˆå§‹-å¼›è±«é…å¯¹æ•°æ®**ï¼šè¦æ±‚è¾“å…¥åˆå§‹ç»“æ„éµå¾ªå›ºå®šè§„åˆ™ç”Ÿæˆï¼ˆå¦‚ Catalysis-Hub æµç¨‹ï¼‰ï¼Œé™åˆ¶äº†å¯¹ä»»æ„å¤æ‚åˆå§‹æ„å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
- **å¯¹æç«¯åç¦»è®­ç»ƒåˆ†å¸ƒçš„ç»“æ„å¯èƒ½å¤±æ•ˆ**ï¼šè™½ç„¶å¼‚å¸¸æ£€æµ‹å¯ç¼“è§£ï¼Œä½†ä»éœ€äººå·¥å¹²é¢„æˆ– DFT éªŒè¯ã€‚
- **ç›®å‰ä»…é€‚ç”¨äºè¡¨é¢å¸é™„ç³»ç»Ÿ**ï¼Œå°šæœªæ‰©å±•è‡³æ›´å¤æ‚çš„å¤šç›¸å‚¬åŒ–æˆ–æº¶æ¶²ç¯å¢ƒã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢å°†**éšæœºæœ€ä¼˜æ§åˆ¶**ï¼ˆstochastic optimal controlï¼‰ä¸ diffusion bridge ç»“åˆï¼Œå‡å°‘å¯¹æˆå¯¹æ•°æ®çš„ä¾èµ–ã€‚
- å­¦ä¹ ç›´æ¥ä» PES æ¢¯åº¦ä¸­æ¨æ–­å¸é™„è¿‡ç¨‹ï¼Œé¿å…ä¾èµ– DFT å¼›è±«ç”Ÿæˆè®­ç»ƒæ•°æ®ã€‚
- æ‰©å±•è‡³åŠ¨æ€å¸é™„ã€ååº”è·¯å¾„æ¢ç´¢ç­‰æ›´å¤æ‚çš„å‚¬åŒ–åœºæ™¯ã€‚
- æ„å»ºç«¯åˆ°ç«¯çš„è‡ªåŠ¨åŒ–å‚¬åŒ–å‰‚è®¾è®¡å¹³å°ï¼Œé›†æˆç»“æ„ç”Ÿæˆã€èƒ½é‡è¯„ä¼°ã€ç¨³å®šæ€§åˆ†æä¸å®éªŒéªŒè¯é—­ç¯ã€‚

---

> **æ€»ç»“**ï¼šDBCata å¼€è¾Ÿäº†ä¸€æ¡**ç»•è¿‡å®Œæ•´ PES å»ºæ¨¡**ã€ç›´æ¥å­¦ä¹ â€œåˆå§‹â†’å¼›è±«â€æ˜ å°„çš„æ–°èŒƒå¼ï¼Œæ˜¾è‘—åŠ é€Ÿäº†å‚¬åŒ–å‰‚çš„é«˜é€šé‡è®¡ç®—ç­›é€‰ï¼Œä¸ºä¸‹ä¸€ä»£æ™ºèƒ½å‚¬åŒ–ææ–™è®¾è®¡æä¾›äº†å¼ºæœ‰åŠ›çš„å·¥å…·ã€‚

</details>

---

### 13. [Metanetworks as Regulatory Operators: Learning to Edit for Requirement Compliance](https://arxiv.org/abs/2512.15469)

**Authors**: Ioannis Kalogeropoulos, Giorgos Bouritsas, Yannis Panagakis  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.15469v1  

#### Abstract
As machine learning models are increasingly deployed in high-stakes settings, e.g. as decision support systems in various societal sectors or in critical infrastructure, designers and auditors are facing the need to ensure that models satisfy a wider variety of requirements (e.g. compliance with reg...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Metanetworks as Regulatory Operators: Learning to Edit for Requirement Compliance*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
éšç€æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨é«˜é£é™©åœºæ™¯ï¼ˆå¦‚åŒ»ç–—ã€é‡‘èã€å¸æ³•ï¼‰ä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œç¡®ä¿å…¶æ»¡è¶³**å¤šæ ·åŒ–è¦æ±‚**ï¼ˆå¦‚åˆè§„æ€§ã€å…¬å¹³æ€§ã€éšç§ä¿æŠ¤ã€è®¡ç®—æ•ˆç‡ï¼‰å˜å¾—è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿæ–¹æ³•é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **Post-processing** æ–¹æ³•å¸¸ä¸¥é‡æŸå®³æ¨¡å‹æ€§èƒ½ï¼›
- **Fine-tuning æˆ–é‡æ–°è®­ç»ƒ** æˆæœ¬é«˜æ˜‚ï¼Œä¸”åœ¨æ•°æ®ä¸å¯ç”¨æˆ–å—çŸ¥è¯†äº§æƒé™åˆ¶æ—¶ä¸å¯è¡Œï¼›
- æ–°è§„æˆ–éœ€æ±‚å¾€å¾€åœ¨æ¨¡å‹éƒ¨ç½²åæ‰å‡ºç°ï¼Œå¯¼è‡´â€œè®­ç»ƒ-éœ€æ±‚â€æ—¶é—´é”™é…ã€‚

å› æ­¤ï¼Œè®ºæ–‡æå‡ºå¹¶è§£å†³äº†ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š  
> **èƒ½å¦é«˜æ•ˆåœ°ç¼–è¾‘å·²è®­ç»ƒçš„ç¥ç»ç½‘ç»œä»¥æ»¡è¶³æ–°è¦æ±‚ï¼ŒåŒæ—¶ä¸ç‰ºç‰²å…¶åŸå§‹åŠŸèƒ½ï¼Ÿ**

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ä¸ª**ç»Ÿä¸€çš„ã€å¯å­¦ä¹ çš„ç¥ç»ç½‘ç»œç¼–è¾‘æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

- **ç»Ÿä¸€çš„å¤šç›®æ ‡ä¼˜åŒ–æ¡†æ¶**ï¼šå°†å„ç§è¦æ±‚ï¼ˆå¦‚å…¬å¹³æ€§ã€æ•°æ®æœ€å°åŒ–ã€æƒé‡å‰ªæï¼‰å½¢å¼åŒ–ä¸ºæ•°å­¦ç›®æ ‡å‡½æ•°ï¼Œå¹¶ä¸â€œåŠŸèƒ½ä¿ç•™â€ç›®æ ‡è”åˆä¼˜åŒ–ï¼Œæ„æˆä¸€ä¸ªå¤šç›®æ ‡é—®é¢˜ã€‚
- **åŸºäº Metanetwork çš„å¯å­¦ä¹ ç¼–è¾‘å™¨**ï¼šå¼•å…¥ä¸€ä¸ªå›¾ç»“æ„çš„ **metanetwork**ï¼ˆä¸€ç§ä¸“é—¨ç”¨äºå¤„ç†ç¥ç»ç½‘ç»œå‚æ•°çš„ NNï¼‰ï¼Œé€šè¿‡ç›‘ç£å­¦ä¹ ä»å¤§é‡ NN å‚æ•°åˆ†å¸ƒä¸­å­¦ä¹ å¦‚ä½•ç›´æ¥æ˜ å°„åŸå§‹å‚æ•°åˆ°åˆè§„çš„ç¼–è¾‘åå‚æ•°ã€‚
- **å•æ­¥æ¨ç†å®ç°ç¼–è¾‘**ï¼šä¸€æ—¦ metanetwork è®­ç»ƒå®Œæˆï¼Œå¯¹ä»»æ„åŒä»»åŠ¡åˆ†å¸ƒä¸‹çš„æ¨¡å‹è¿›è¡Œåˆè§„ç¼–è¾‘ä»…éœ€ä¸€æ¬¡å‰å‘ä¼ æ’­ï¼ˆsingle inference stepï¼‰ï¼Œæå¤§æå‡æ•ˆç‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆPost-processing / Retrainingï¼‰ | æœ¬æ–‡æ–¹æ³•ï¼ˆMetanetwork-based Editingï¼‰ |
|------|----------------------------------------|----------------------------------------|
| **æ•ˆç‡** | é«˜å»¶è¿Ÿï¼Œéœ€å¤šæ¬¡è¿­ä»£ä¼˜åŒ–æˆ–è®­ç»ƒ | æå¿«ï¼Œå•æ¬¡æ¨ç†å³å¯å®Œæˆç¼–è¾‘ï¼ˆæ¯«ç§’çº§ï¼‰ |
| **é€šç”¨æ€§** | å¤šä¸ºä»»åŠ¡/è¦æ±‚ç‰¹å®šï¼ˆrequirement-specificï¼‰ | ç»Ÿä¸€æ¡†æ¶æ”¯æŒå¤šç§è¦æ±‚ï¼ˆdata minimization, fairness, pruningï¼‰ |
| **æ€§èƒ½ä¿ç•™** | å¸¸æ˜¾è‘—é™ä½åŸå§‹æ€§èƒ½ | æ˜¾è‘—æ›´å¥½åœ°å¹³è¡¡â€œåˆè§„æ€§â€ä¸â€œåŠŸèƒ½ä¿ç•™â€ |
| **èµ„æºä¾èµ–** | é€šå¸¸éœ€è¦åŸå§‹è®­ç»ƒæ•°æ®æˆ–å®Œæ•´å†è®­ç»ƒ | å¯ä½¿ç”¨å°‘é‡å¤–éƒ¨æ•°æ®è®­ç»ƒ metanetworkï¼Œæ— éœ€è®¿é—®åŸå§‹è®­ç»ƒæ•°æ® |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **UCI Adult** å’Œ **Bank Marketing** æ•°æ®é›†ï¼Œå‡ä¸ºçœŸå®ä¸–ç•Œè¡¨æ ¼æ•°æ®ï¼ˆtabular dataï¼‰ã€‚
- æ‰€æœ‰å®éªŒå‡åŸºäº **MLP**ï¼ˆå¤šå±‚æ„ŸçŸ¥æœºï¼‰æ¨¡å‹ã€‚

### å®éªŒè®¾ç½®
- **æ„å»º NN Populationï¼ˆDmï¼‰**ï¼šé€šè¿‡é‡‡æ ·ä¸åŒæ¶æ„ï¼ˆå±‚æ•°ã€éšè—ç»´åº¦ï¼‰ã€è¶…å‚æ•°ï¼ˆå­¦ä¹ ç‡ã€dropoutã€æ¿€æ´»å‡½æ•°ç­‰ï¼‰è®­ç»ƒçº¦ 12,000 ä¸ª MLP æ¨¡å‹ï¼Œå½¢æˆè®­ç»ƒ metanetwork æ‰€éœ€çš„æ¨¡å‹é›†åˆã€‚
- **æ•°æ®åˆ†å¸ƒåˆ†ç¦»**ï¼š`pm` è¡¨ç¤ºæ¨¡å‹å‚æ•°åˆ†å¸ƒï¼Œ`pd` è¡¨ç¤ºè¾“å…¥æ•°æ®åˆ†å¸ƒï¼›è®­ç»ƒ metanetwork æ—¶ä½¿ç”¨çš„ `pd` æ•°æ®ç‹¬ç«‹äºåŸå§‹æ¨¡å‹è®­ç»ƒæ•°æ®ï¼Œæ¨¡æ‹Ÿå®¡è®¡æ–¹æ— åŸå§‹æ•°æ®çš„æƒ…å¢ƒã€‚
- **Metanetwork æ¶æ„**ï¼šé‡‡ç”¨ **Graph Metanetwork**ï¼ˆLim et al., 2024ï¼‰ï¼Œå°† MLP è§†ä¸ºå›¾ç»“æ„ï¼ˆèŠ‚ç‚¹=ç¥ç»å…ƒï¼Œè¾¹=æƒé‡ï¼‰ï¼Œåˆ©ç”¨ GNN å¤„ç†å‚æ•°å›¾ï¼Œå¹¶ä¿è¯å¯¹å‚æ•°ç½®æ¢å¯¹ç§°æ€§ï¼ˆpermutation equivarianceï¼‰ã€‚

### è¯„ä¼°æŒ‡æ ‡
æ‰€æœ‰å®éªŒå‡ç»˜åˆ¶ **Pareto Frontï¼ˆå¸•ç´¯æ‰˜å‰æ²¿ï¼‰** æ›²çº¿ï¼Œè¡¡é‡ä¸¤ä¸ªç›®æ ‡ä¹‹é—´çš„æƒè¡¡ï¼š
- **Yè½´**ï¼šJensen-Shannon Divergenceï¼ˆJSDï¼‰ï¼Œè¡¡é‡ç¼–è¾‘å‰åæ¨¡å‹è¾“å‡ºåˆ†å¸ƒçš„å·®å¼‚ï¼ˆè¶Šå°è¶Šå¥½ï¼Œè¡¨ç¤ºåŠŸèƒ½ä¿ç•™æ›´å¼ºï¼‰ï¼›
- **Xè½´**ï¼š
  - *Data Minimization*ï¼šæ´»è·ƒè¾“å…¥ç‰¹å¾æ¯”ä¾‹ï¼›
  - *Fairness*ï¼šEqualized Odds Difference (EOD)ï¼Œè¶Šå°è¶Šå…¬å¹³ï¼›
  - *Pruning*ï¼šå‰©ä½™æƒé‡æ¯”ä¾‹ï¼ˆå³ç¨€ç–åº¦ï¼‰ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ä»»åŠ¡ | åŸºçº¿æ–¹æ³• |
|------|---------|
| **Data Minimization** | Feature Selection (FS), FS + Retrain (çŸ¥è¯†è’¸é¦), FS (GMN)ï¼ˆä»…é¢„æµ‹maskï¼‰ |
| **Fairness (Bias Mitigation)** | ThresholdOpt, RejectOption, CalEqOdds, FairCls |
| **Pruning** | Random, Magnitude, Gradient Importance, SNIP, Lottery Ticket |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ

#### âœ… **Data Minimizationï¼ˆæ•°æ®æœ€å°åŒ–ï¼‰**
- åœ¨ Adult å’Œ Bank æ•°æ®é›†ä¸Šï¼Œ**GMN** æ–¹æ³•åœ¨ç›¸åŒæ´»è·ƒç‰¹å¾æ¯”ä¾‹ä¸‹ï¼ŒJSD æ˜¾è‘—ä½äºæ‰€æœ‰åŸºçº¿ï¼ˆè§ Fig. 1 & 6ï¼‰ã€‚
- å°¤å…¶åœ¨é«˜æ©ç æ¯”ä¾‹ï¼ˆå³ä¿ç•™å¾ˆå°‘ç‰¹å¾ï¼‰æ—¶ä¼˜åŠ¿æ›´æ˜æ˜¾ï¼Œè¯´æ˜ metanetwork èƒ½æœ‰æ•ˆè¡¥å¿ä¿¡æ¯æŸå¤±ã€‚
- **FS (GMN)**ï¼ˆä»…é¢„æµ‹ maskï¼Œä¸ç¼–è¾‘å‚æ•°ï¼‰è¡¨ç°ç•¥å·®äºå®Œæ•´ GMNï¼Œè¡¨æ˜å‚æ•°ç¼–è¾‘å¯¹åŠŸèƒ½ä¿æŒè‡³å…³é‡è¦ã€‚

#### âœ… **Bias Mitigationï¼ˆåè§ç¼“è§£ï¼‰**
- GMN åœ¨æ•´ä¸ª Pareto å‰æ²¿ä¸Šå…¨é¢ä¼˜äºæ‰€æœ‰ post-processing åŸºçº¿ï¼ˆFig. 2ï¼‰ã€‚
- åœ¨ç›¸åŒ EOD æ°´å¹³ä¸‹ï¼ŒGMN çš„ JSD æ›´ä½ï¼ˆå³å¯¹åŸå§‹æ€§èƒ½å½±å“æ›´å°ï¼‰ï¼›
- åŸºçº¿å¦‚ ThresholdOpt å’Œ CalEqOdds åªèƒ½äº§ç”Ÿå•ä¸€æ“ä½œç‚¹ï¼Œè€Œ GMN å¯ç”Ÿæˆè¿ç»­çš„æƒè¡¡æ›²çº¿ï¼Œæä¾›æ›´å¤§çµæ´»æ€§ã€‚

#### âœ… **Weight Pruningï¼ˆæƒé‡å‰ªæï¼‰**
- **GMN-Prune & Edit** åœ¨æ‰€æœ‰ç¨€ç–åº¦æ°´å¹³ä¸‹å‡ä¼˜äº Randomã€Magnitudeã€Gradient Importanceã€SNIP å’Œ Lottery Ticketï¼ˆFig. 3ï¼‰ã€‚
- ç‰¹åˆ«æ˜¯åœ¨é«˜ç¨€ç–åº¦ï¼ˆ<20% æƒé‡ä¿ç•™ï¼‰æ—¶ï¼Œç¼–è¾‘å‰©ä½™å‚æ•°çš„æ•ˆæœå°¤ä¸ºæ˜¾è‘—ã€‚

#### â±ï¸ **æ—¶é—´æ•ˆç‡å¯¹æ¯”ï¼ˆTable 1ï¼‰**
| æ–¹æ³• | ç¼–è¾‘å•ä¸ªæ¨¡å‹è€—æ—¶ï¼ˆç§’ï¼‰ |
|------|------------------|
| **GMN (all variants)** | **0.03** |
| FS & Retrain | 32.35 |
| RejectOption | 4.36 |
| SNIP | 0.41 |
| Random/Magnitude | ~0.003 |

> å°½ç®¡æŸäº›ç®€å•å‰ªææ–¹æ³•æ›´å¿«ï¼Œä½†æ€§èƒ½è¿œä¸å¦‚ GMNã€‚**GMN åœ¨æ€§èƒ½ä¸é€Ÿåº¦ä¹‹é—´å®ç°äº†æœ€ä½³å¹³è¡¡**ã€‚

#### ğŸ” **æ¶ˆèå®éªŒï¼šè®­ç»ƒæ ·æœ¬æ•ˆç‡ï¼ˆFig. 4ï¼‰**
- å³ä½¿åªä½¿ç”¨ **10% çš„è®­ç»ƒæ•°æ®**ï¼ˆå³ 1,200 ä¸ªæ¨¡å‹ï¼‰è®­ç»ƒ metanetworkï¼Œå…¶æ€§èƒ½ä»ä¼˜äºå¤§å¤šæ•°åŸºçº¿ï¼›
- ä½¿ç”¨ **25% æ•°æ®** æ—¶ï¼Œå·²å…¨é¢è¶…è¶Šæ‰€æœ‰åŸºçº¿ï¼›
- 50% ä»¥ä¸Šæ•°æ®æ€§èƒ½è¶‹äºé¥±å’Œï¼Œè¡¨æ˜ metanetwork å…·æœ‰å¾ˆå¼ºçš„**æ ·æœ¬æ•ˆç‡**å’Œæ³›åŒ–èƒ½åŠ›ã€‚

#### ğŸ”„ **ç»„åˆå¤šä¸ª metanetworkï¼ˆFig. 8ï¼‰**
- å°†åˆ†åˆ«è®­ç»ƒç”¨äº **Data Minimization** å’Œ **Pruning** çš„ metanetwork è¿›è¡Œä¸²è”ï¼ˆ$ \mathcal{S}_{pr} \circ \mathcal{S}_{dm} $ï¼‰ï¼Œä»èƒ½æœ‰æ•ˆå·¥ä½œï¼Œä¸”æ€§èƒ½ä¼˜äºåŸºçº¿ç»„åˆï¼ˆFS & Retrain + SNIPï¼‰ã€‚
- è¡¨æ˜ metanetwork ç¼–è¾‘ä¸ä¼šç ´åå‚æ•°åˆ†å¸ƒï¼Œæ”¯æŒæ¨¡å—åŒ–ç»„åˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Metanetwork å¯ä½œä¸ºé«˜æ•ˆçš„â€œç›‘ç®¡æ“ä½œç¬¦â€**ï¼šèƒ½å¤Ÿä»¥å•æ­¥æ¨ç†æ–¹å¼å¯¹å·²éƒ¨ç½²æ¨¡å‹è¿›è¡Œåˆè§„æ€§ç¼–è¾‘ï¼Œé€‚ç”¨äºæ•°æ®æœ€å°åŒ–ã€å…¬å¹³æ€§å’Œå‰ªæç­‰å¤šç§è¦æ±‚ã€‚
2. **æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•**ï¼šåœ¨æ€§èƒ½ä¿ç•™ä¸è¦æ±‚æ»¡è¶³ä¹‹é—´çš„æƒè¡¡ä¸Šï¼Œå…¨é¢è¶…è¶Š post-processing å’Œè½»é‡ retraining æ–¹æ³•ã€‚
3. **é«˜åº¦é«˜æ•ˆä¸å®ç”¨**ï¼šç¼–è¾‘è¿‡ç¨‹ä»…éœ€æ¯«ç§’çº§æ—¶é—´ï¼Œé€‚åˆå®æ—¶æˆ–å¤§è§„æ¨¡æ¨¡å‹æ²»ç†åœºæ™¯ã€‚
4. **å…·å¤‡è‰¯å¥½æ³›åŒ–ä¸ç»„åˆèƒ½åŠ›**ï¼šå³ä½¿åœ¨å°æ ·æœ¬è®­ç»ƒä¸‹ä¹Ÿèƒ½å–å¾—ä¼˜å¼‚æ•ˆæœï¼Œä¸”å¤šä¸ª metanetwork å¯å †å ä½¿ç”¨ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ–¹æ³•å±€é™äº**åŒä¸€ä»»åŠ¡ä¸‹çš„æ¨¡å‹æ—**ï¼ˆsame task distributionï¼‰ï¼Œå°šä¸èƒ½è·¨ä»»åŠ¡é€šç”¨ï¼›
- å®éªŒä»…åœ¨ **MLP** ä¸ŠéªŒè¯ï¼Œå¤æ‚æ¶æ„ï¼ˆå¦‚ CNNã€Transformerï¼‰å°šæœªæµ‹è¯•ï¼›
- éœ€è¦é¢„å…ˆæ”¶é›†ä¸€æ‰¹è®­ç»ƒå¥½çš„æ¨¡å‹ç”¨äºè®­ç»ƒ metanetworkï¼Œåœ¨æŸäº›åœºæ™¯ä¸‹å¯èƒ½éš¾ä»¥è·å–ï¼›
- å®Œå…¨è‡ªåŠ¨åŒ–ç¼–è¾‘å­˜åœ¨é£é™©ï¼Œ**äººç±»ç›‘ç£ä»æ˜¯å¿…è¦ç¯èŠ‚**ï¼ˆä½œè€…å¼ºè°ƒéœ€é¢†åŸŸä¸“å®¶è¯„ä¼°æƒè¡¡ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤æ‚çš„ç½‘ç»œæ¶æ„ï¼ˆCNNã€Transformerï¼‰ï¼›
- æ¢ç´¢è·¨ä»»åŠ¡çš„é€šç”¨ metanetworkï¼ˆmulti-task learnable editingï¼‰ï¼›
- ç»“åˆæ›´å¤šç±»å‹çš„åˆè§„è¦æ±‚ï¼ˆå¦‚é²æ£’æ€§ã€å¯è§£é‡Šæ€§ï¼‰ï¼›
- å‘å±•æ ‡å‡†åŒ–çš„ metanetwork å·¥å…·åŒ…ï¼Œç”¨äº AI å®¡è®¡ä¸ç›‘ç®¡å®è·µï¼›
- æ¢ç´¢ metanetwork åœ¨è”é‚¦å­¦ä¹ ã€æ¨¡å‹ç‰ˆæƒç®¡ç†ç­‰åœºæ™¯çš„åº”ç”¨ã€‚

---

> **æ€»ç»“**ï¼šè¯¥è®ºæ–‡å¼€åˆ›æ€§åœ°å°† **weight space learning** ä¸ **AI åˆè§„æ²»ç†**ç›¸ç»“åˆï¼Œæå‡ºäº†ä¸€ç§é«˜æ•ˆã€çµæ´»ã€å¯æ‰©å±•çš„æ¨¡å‹ç¼–è¾‘èŒƒå¼ã€‚å®ƒä¸ä»…è§£å†³äº†â€œäº‹ååˆè§„â€çš„ç°å®éš¾é¢˜ï¼Œä¹Ÿä¸ºæœªæ¥æ„å»ºè‡ªåŠ¨åŒ–çš„ AI ç›‘ç®¡åŸºç¡€è®¾æ–½æä¾›äº†ç†è®ºåŸºç¡€å’ŒæŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 14. [Multi-Modal Semantic Communication](https://arxiv.org/abs/2512.15691)

**Authors**: Matin Mortaheb, Erciyes Karakaya, Sennur Ulukus  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.15691v1  

#### Abstract
Semantic communication aims to transmit information most relevant to a task rather than raw data, offering significant gains in communication efficiency for applications such as telepresence, augmented reality, and remote sensing. Recent transformer-based approaches have used self-attention maps to ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMulti-Modal Semantic Communication

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåŸºäºè§†è§‰è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆself-attentionï¼‰çš„è¯­ä¹‰é€šä¿¡æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸­å­˜åœ¨ä»¥ä¸‹å±€é™ï¼š
- åœ¨å¤šç‰©ä½“ã€èƒŒæ™¯æ‚ä¹±æˆ–è¯­ä¹‰æ¨¡ç³Šçš„å›¾åƒä¸­ï¼Œ**è‡ªæ³¨æ„åŠ›å›¾å®¹æ˜“æ‰©æ•£æˆ–èšç„¦äºè§†è§‰æ˜¾è‘—ä½†è¯­ä¹‰æ— å…³çš„åŒºåŸŸ**ï¼›
- ç¼ºä¹å¯¹å…·ä½“ä»»åŠ¡ç›®æ ‡çš„æ˜¾å¼å¼•å¯¼ï¼Œå¯¼è‡´æ— æ³•ç²¾å‡†æå–ä¸ç”¨æˆ·æŸ¥è¯¢ç›¸å…³çš„è¯­ä¹‰å†…å®¹ï¼›
- å½“é€šä¿¡ä»»åŠ¡æ”¹å˜æ—¶éœ€é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ï¼Œ**çµæ´»æ€§å·®ä¸”è®¡ç®—æˆæœ¬é«˜**ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§**Multi-Modal Semantic Communication (MMSC)** æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

- **å¼•å…¥æ–‡æœ¬æŸ¥è¯¢ä½œä¸ºä»»åŠ¡æŒ‡å¯¼ä¿¡å·**ï¼šåˆ©ç”¨ç”¨æˆ·æä¾›çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼ˆå¦‚â€œWhere is the crosswalk?â€ï¼‰ï¼Œå®ç°ä»»åŠ¡é©±åŠ¨çš„ä¿¡æ¯é€‰æ‹©ã€‚
- **è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ï¼ˆCross-Modal Attentionï¼‰**ï¼šèåˆå›¾åƒç‰¹å¾ä¸æ–‡æœ¬åµŒå…¥ï¼ˆtext embeddingï¼‰ï¼Œé€šè¿‡é¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆå¦‚CLIPï¼‰ç”Ÿæˆè½¯ç›¸å…³æ€§å¾—åˆ†ï¼ˆsoft relevance scoresï¼‰ï¼Œé‡åŒ–æ¯ä¸ªå›¾åƒå—ä¸æŸ¥è¯¢ä¹‹é—´çš„è¯­ä¹‰åŒ¹é…ç¨‹åº¦ã€‚
- **åŠ¨æ€é€‚åº”æ€§ç¼–ç ç­–ç•¥**ï¼šåŸºäºä¿¡é“å¸¦å®½å’Œè¯­ä¹‰é‡è¦æ€§åˆ†æ•°ï¼Œå°†å›¾åƒå—åˆ†é…åˆ°ä¸åŒåˆ†è¾¨ç‡ç­‰çº§è¿›è¡Œç¼–ç ä¼ è¾“ï¼Œç¡®ä¿å…³é”®åŒºåŸŸä»¥æ›´é«˜ä¿çœŸåº¦é‡å»ºã€‚
- **æ— éœ€é‡è®­ç»ƒå³å¯æ”¯æŒä»»æ„æŸ¥è¯¢**ï¼šç³»ç»Ÿå¯åœ¨æ¨ç†é˜¶æ®µç›´æ¥å¤„ç†è‡ªç”±å½¢å¼çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œæ— éœ€ä¸ºæ¯ä¸ªæ–°ä»»åŠ¡å¾®è°ƒæ¨¡å‹ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | æœ¬æ–‡ MMSC | åŸºçº¿æ–¹æ³•ï¼ˆå¦‚ ViT-SC [6]ï¼‰ |
|------|-----------|--------------------------|
| è¾“å…¥æ¨¡æ€ | å›¾åƒ + æ–‡æœ¬æŸ¥è¯¢ï¼ˆåŒæ¨¡æ€ï¼‰ | ä»…å›¾åƒï¼ˆå•æ¨¡æ€ï¼‰ |
| æ³¨æ„åŠ›æœºåˆ¶ | Cross-Attentionï¼ˆå›¾æ–‡äº¤äº’ï¼‰ | Self-Attentionï¼ˆä»…è§†è§‰å†…éƒ¨ï¼‰ |
| æŸ¥è¯¢çµæ´»æ€§ | æ”¯æŒå¼€æ”¾è¯æ±‡ã€å¤åˆå¯¹è±¡æŸ¥è¯¢ï¼ˆå¦‚â€œcat and keyboardâ€ï¼‰ | å›ºå®šç±»åˆ«æ ‡ç­¾æˆ–ä¾èµ–é¢„å®šä¹‰ä»»åŠ¡ |
| å†³ç­–æ–¹å¼ | è½¯ç›¸å…³æ€§è¯„åˆ†ï¼ˆsoft scoresï¼‰ï¼Œæ”¯æŒæ¸è¿›å¼å‹ç¼© | ä¾èµ–è§†è§‰æ˜¾è‘—æ€§ï¼Œç¼ºä¹è¯­ä¹‰å¯¹é½ |
| å¯æ‰©å±•æ€§ | åŠ¨æ€é€‚é…æ–°ä»»åŠ¡ï¼Œæ— éœ€å†è®­ç»ƒ | æ›´æ¢ä»»åŠ¡éœ€é‡æ–°ä¼˜åŒ–ç¼–ç å™¨ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨ **COCO validation set** çš„ä¸€ä¸ªå­é›†ï¼Œå…± **200 å¼ å›¾åƒ**ï¼›
- æ‰€æœ‰å›¾åƒç»Ÿä¸€è°ƒæ•´ä¸º **320Ã—480 åˆ†è¾¨ç‡**ï¼›
- æ„é€ ä¸¤ç±»ç”¨æˆ·æŸ¥è¯¢ï¼š
  1. å•ä¸€å¯¹è±¡æŸ¥è¯¢ï¼ˆå¦‚ â€œdogâ€ï¼‰
  2. å¤åˆå¯¹è±¡æŸ¥è¯¢ï¼ˆå¦‚ â€œperson and bicycleâ€ï¼‰
- æä¾›å¯¹åº”å¯¹è±¡çš„ **ground truth segmentation masks** ç”¨äºè¯„ä¼°è¯­ä¹‰ä¸€è‡´æ€§ã€‚

### å®éªŒè®¾ç½®
- **Patch åˆ’åˆ†**ï¼šå›¾åƒåˆ’åˆ†ä¸º 8Ã—8 åƒç´ çš„å°å—ï¼Œæ¯å¼ å›¾å…± 2,400 ä¸ª patchï¼›
- **åˆ†è¾¨ç‡å±‚çº§**ï¼šé‡‡ç”¨äº”çº§ç¼–ç æ–¹æ¡ˆï¼Œå¯¹åº”ç ç‡åˆ†åˆ«ä¸ºï¼š
  - $ L = 0 $: ä¸ä¼ è¾“ï¼ˆ0 å­—èŠ‚ï¼‰
  - $ L = 12, 24, 48 $: å‹ç¼©ç¼–ç 
  - $ L = 192 $: åŸå§‹ patch æ— æŸä¼ è¾“ï¼ˆ3Ã—8Ã—8=192 å­—èŠ‚ï¼‰
- **æ€»å¸¦å®½èŒƒå›´**ï¼šä» 0 åˆ° $ 2400 \times 192 = 460,800 $ å­—èŠ‚ï¼Œæ¨¡æ‹Ÿä¸åŒä¿¡é“æ¡ä»¶ã€‚

### è¯„ä¼°æŒ‡æ ‡
1. **Masked MSE**ï¼šåœ¨ ground truth æ©ç åŒºåŸŸå†…è®¡ç®—åŸå§‹å›¾åƒä¸é‡å»ºå›¾åƒçš„å‡æ–¹è¯¯å·®ï¼Œè¡¡é‡è¯­ä¹‰å…³é”®åŒºåŸŸçš„ä¿çœŸåº¦ï¼›
2. **Informativeness Score Consistency (L1 Distance)**ï¼šæ¯”è¾ƒåŸå§‹å›¾åƒä¸é‡å»ºå›¾åƒåœ¨ç›¸åŒæŸ¥è¯¢ä¸‹çš„ $ S_{\text{inf}} $ å›¾ä¹‹é—´çš„ L1 è·ç¦»ï¼Œåæ˜ è¯­ä¹‰ç»“æ„ä¿æŒèƒ½åŠ›ï¼›
3. **CLIP Relevancy Score**ï¼šä½¿ç”¨ CLIP æ¨¡å‹è®¡ç®—é‡å»ºå›¾åƒä¸è¾“å…¥æ–‡æœ¬ä¹‹é—´çš„ç›¸ä¼¼åº¦å¾—åˆ†ï¼Œè¯„ä¼°å›¾æ–‡è¯­ä¹‰å¯¹é½è´¨é‡ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ViT-SC [6]**ï¼šåŸºäº Vision Transformer è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„è¯­ä¹‰é€šä¿¡ç³»ç»Ÿï¼Œä»…ä½¿ç”¨å›¾åƒè¾“å…¥ï¼Œä¸æ¥å—æ–‡æœ¬æŸ¥è¯¢ï¼›
- ä¸¤ç§æ–¹æ³•å…±äº«ç›¸åŒçš„ encoder-decoder ç»“æ„å’Œå¤šåˆ†è¾¨ç‡æ§åˆ¶æ¨¡å—ï¼Œä¿è¯å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰Masked MSE å¯¹æ¯”ï¼ˆå›¾4ï¼‰
- åœ¨æ‰€æœ‰å¸¦å®½æ°´å¹³ä¸‹ï¼Œ**MMSC çš„ masked MSE æ˜¾è‘—ä½äº ViT-SC**ï¼›
- ä¾‹å¦‚ï¼Œåœ¨çº¦ 200,000 Bytes ä¿¡é“é€Ÿç‡ä¸‹ï¼š
  - MMSC: ~0.015
  - ViT-SC: ~0.030
- è¡¨æ˜ MMSC æ›´å¥½åœ°ä¿ç•™äº†ä¸æŸ¥è¯¢ç›¸å…³çš„è¯­ä¹‰å†…å®¹ã€‚

> âœ… **ä¼˜åŠ¿ä½“ç°**ï¼šå¼•å…¥æ–‡æœ¬å¼•å¯¼ä½¿ç³»ç»Ÿèƒ½å‡†ç¡®è¯†åˆ«å¹¶ä¼˜å…ˆé‡å»ºç›®æ ‡å¯¹è±¡ï¼ˆå¦‚é”®ç›˜ï¼‰ï¼Œè€Œä¸ä»…ä»…æ˜¯è§†è§‰æœ€æ˜¾è‘—çš„å¯¹è±¡ï¼ˆå¦‚çŒ«ï¼‰ã€‚

#### ï¼ˆ2ï¼‰Informativeness Score L1 Distanceï¼ˆå›¾5ï¼‰
- MMSC çš„ $ S_{\text{inf}} $ å·®å¼‚æ›´å°ï¼Œè¯´æ˜å…¶é‡å»ºåçš„å›¾åƒä»é«˜åº¦å“åº”åŸå§‹æŸ¥è¯¢ï¼›
- åœ¨ä½è‡³ä¸­ç­‰å¸¦å®½æ¡ä»¶ä¸‹ï¼Œæ€§èƒ½å·®è·å°¤ä¸ºæ˜æ˜¾ï¼›
- è¡¨æ˜è¯¥æ¡†æ¶æœ‰æ•ˆç»´æŒäº†â€œä»€ä¹ˆæ˜¯é‡è¦çš„â€è¿™ä¸€è¯­ä¹‰åˆ¤æ–­çš„ä¸€è‡´æ€§ã€‚

#### ï¼ˆ3ï¼‰CLIP Relevancy Scoreï¼ˆå›¾6ï¼‰
- MMSC åœ¨ä¸­ç­‰å¸¦å®½åŒºé—´ï¼ˆ~100Kâ€“300K Bytesï¼‰è¾¾åˆ°æœ€é«˜ CLIP å¾—åˆ†ï¼ˆæ¥è¿‘ 0.20ï¼‰ï¼›
- éšç€å¸¦å®½å¢åŠ ï¼ŒViT-SC å¾—åˆ†è¶‹äºé¥±å’Œç”šè‡³ç•¥é™ï¼Œè€Œ MMSC ä¸‹é™è¾ƒç¼“ï¼›
- åŸå› åˆ†æï¼šé«˜å¸¦å®½æ—¶éç›¸å…³åŒºåŸŸä¹Ÿè¢«é‡å»ºï¼Œç¨€é‡Šäº†è¯­ä¹‰ç„¦ç‚¹ï¼›ä½† MMSC å› æœ‰æŸ¥è¯¢å¼•å¯¼ï¼Œä»èƒ½è¾ƒå¥½é›†ä¸­èµ„æºã€‚

> ğŸ“Œ å…¸å‹æ¡ˆä¾‹è§ Fig. 3ï¼šâ€œCat and Keyboardâ€ æŸ¥è¯¢ä¸­ï¼ŒMMSC æˆåŠŸé‡å»ºä¸¤ä¸ªå¯¹è±¡ï¼Œè€Œ ViT-SC å¿½ç•¥äº†é”®ç›˜ã€‚

### æ¶ˆèå®éªŒï¼ˆæ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºï¼Œä½†ä»è®¾è®¡å¯æ¨æ–­ï¼‰
è™½ç„¶è®ºæ–‡æœªæä¾›æ­£å¼æ¶ˆèç ”ç©¶ï¼Œä½†ä»æ¶æ„è®¾è®¡å¯å¾—å‡ºä»¥ä¸‹éšå«ç»“è®ºï¼š
- è‹¥ç§»é™¤ CDTï¼ˆContent-Dependent Transferï¼‰æ¨¡å— â†’ æ–‡æœ¬åµŒå…¥ä¸å›¾åƒä¸Šä¸‹æ–‡å¯¹é½å‡å¼± â†’ ç›¸å…³æ€§è¯„åˆ†ä¸å‡†ï¼›
- è‹¥ä½¿ç”¨ç¡¬æ©ç è€Œéè½¯è¯„åˆ† â†’ ä¸¢å¤±ç»†ç²’åº¦è¯­ä¹‰å¼ºåº¦ä¿¡æ¯ï¼Œä¸åˆ©äºå¤šçº§å‹ç¼©ï¼›
- è‹¥å†»ç»“ CLIP-V å’Œ CLIP-T ä¸æ›´æ–° â†’ æ€§èƒ½ä¸‹é™ï¼Œå°¤å…¶åœ¨ mask quality alignment ä¸Šè¡¨ç°ä¸ä½³ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ–‡æœ¬æŸ¥è¯¢æ˜¾è‘—æå‡è¯­ä¹‰é€šä¿¡çš„ç›®æ ‡å¯¼å‘æ€§**ï¼šç›¸æ¯”çº¯è§†è§‰è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå¼•å…¥è‡ªç„¶è¯­è¨€æŒ‡ä»¤èƒ½æ›´ç²¾ç¡®åœ°å®šä½ä»»åŠ¡ç›¸å…³åŒºåŸŸï¼›
2. **è·¨æ¨¡æ€æ³¨æ„åŠ›ä¼˜äºå•æ¨¡æ€æ³¨æ„åŠ›**ï¼šCLIP-based cross-attention èƒ½æœ‰æ•ˆèåˆå›¾æ–‡ä¿¡æ¯ï¼Œç”Ÿæˆæ›´å…·è¯­ä¹‰æ„ä¹‰çš„ç›¸å…³æ€§åœ°å›¾ï¼›
3. **è½¯ç›¸å…³æ€§è¯„åˆ†æ”¯æŒç²¾ç»†åŒ–èµ„æºåˆ†é…**ï¼šè¿ç»­å€¼è¯„åˆ†æ¯”äºŒå€¼åˆ†å‰²æ›´é€‚åˆå¤šåˆ†è¾¨ç‡ç¼–ç ï¼Œå®ç°å¸¦å®½é«˜æ•ˆåˆ©ç”¨ï¼›
4. **æ— éœ€é‡è®­ç»ƒå³å¯åº”å¯¹å¤šæ ·åŒ–ä»»åŠ¡**ï¼šç³»ç»Ÿå…·å¤‡è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œå®æ—¶é€‚åº”æ€§ï¼Œé€‚åˆå¤šç”¨é€”é€šä¿¡åœºæ™¯ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡é¢„è®­ç»ƒæ¨¡å‹**ï¼šæ€§èƒ½ä¸¥é‡ä¾èµ– CLIP ç­‰å¤§è§„æ¨¡è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œéƒ¨ç½²æˆæœ¬è¾ƒé«˜ï¼›
- **Patch-wise ç¼–ç å¯èƒ½å¼•å…¥è¾¹ç•Œä¼ªå½±**ï¼šç‹¬ç«‹ç¼–è§£ç å„ patch å¯èƒ½åœ¨æ‹¼æ¥å¤„äº§ç”Ÿä¸è¿ç»­ç°è±¡ï¼›
- **æœªè€ƒè™‘æ—¶é—´ç»´åº¦**ï¼šå½“å‰æ¡†æ¶é’ˆå¯¹é™æ€å›¾åƒï¼Œå°šæœªæ‰©å±•è‡³è§†é¢‘æµä¸­çš„æ—¶åºä¸€è‡´æ€§å»ºæ¨¡ï¼›
- **æŸ¥è¯¢ç†è§£å—é™äº CLIP çš„è¯­ä¹‰è¦†ç›–èŒƒå›´**ï¼šæç«¯æŠ½è±¡æˆ–ç½•è§è¡¨è¾¾å¯èƒ½æ— æ³•æ­£ç¡®è§£æã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°†æ¡†æ¶æ‰©å±•è‡³ **video semantic communication**ï¼Œç»“åˆæ—¶ç©ºæ³¨æ„åŠ›æœºåˆ¶ï¼›
- å¼•å…¥ **end-to-end joint optimization**ï¼Œè”åˆè®­ç»ƒè¯­ä¹‰æå–ä¸ç¼–ç æ¨¡å—ï¼›
- æ¢ç´¢ **low-bitrate quantization** ä¸ **neural codec integration**ï¼Œè¿›ä¸€æ­¥é™ä½ä¼ è¾“å¼€é”€ï¼›
- æ”¯æŒ **interactive feedback loops**ï¼Œå…è®¸æ¥æ”¶ç«¯åé¦ˆä»»åŠ¡å®ŒæˆçŠ¶æ€ä»¥åŠ¨æ€è°ƒæ•´åç»­ä¼ è¾“ç­–ç•¥ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºçš„ MMSC æ¡†æ¶å¼€åˆ›æ€§åœ°å°†æ–‡æœ¬æŸ¥è¯¢å¼•å…¥è¯­ä¹‰é€šä¿¡ç³»ç»Ÿï¼Œå®ç°äº†çœŸæ­£æ„ä¹‰ä¸Šçš„â€œæŒ‰éœ€ä¼ è¾“â€ã€‚å…¶å®éªŒè¯æ˜ï¼Œåœ¨å¤æ‚åœºæ™¯å’Œæœ‰é™å¸¦å®½ä¸‹ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºä»…ä¾èµ–è§†è§‰è‡ªæ³¨æ„åŠ›çš„ä¼ ç»Ÿæ–¹æ¡ˆï¼Œä¸ºä¸‹ä¸€ä»£æ™ºèƒ½é€šä¿¡ç³»ç»Ÿæä¾›äº†å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 15. [RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees](https://arxiv.org/abs/2512.14069)

**Authors**: Junjie Ma, Jinlong Li  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.14069v1  

#### Abstract
Inference with modern Large Language Models (LLMs) is expensive and slow, and speculative sampling has emerged as an effective solution to this problem, however, the number of the calls to the draft model for generating candidate tokens in speculative sampling is a preset hyperparameter, lacking fle...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ç°ä»£ Large Language Models (LLMs) æ¨ç†è¿‡ç¨‹æ˜‚è´µä¸”ç¼“æ…¢ã€‚**Speculative Sampling** æ˜¯ä¸€ç§æœ‰æ•ˆçš„åŠ é€Ÿæ–¹æ³•ï¼Œé€šè¿‡ä¸€ä¸ªå°çš„ draft model å¿«é€Ÿç”Ÿæˆå€™é€‰ tokenï¼Œå¹¶ç”±ç›®æ ‡ LLM å¹¶è¡ŒéªŒè¯ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¸­å¯¹ draft model çš„è°ƒç”¨æ¬¡æ•°æ˜¯ä¸€ä¸ª**é¢„è®¾è¶…å‚æ•°**ï¼ˆå¦‚å›ºå®šä¸º8æ¬¡ï¼‰ï¼Œç¼ºä¹çµæ´»æ€§ï¼Œå¯¼è‡´åœ¨æŸäº›ä¸Šä¸‹æ–‡ä¸­äº§ç”Ÿå†—ä½™è®¡ç®—ï¼ˆä¾‹å¦‚ï¼Œå³ä½¿åç»­ token è¢«é¢‘ç¹æ‹’ç»ï¼Œä»å¼ºåˆ¶æ‰§è¡Œå¤šæ¬¡å‰å‘ä¼ æ’­ï¼‰ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šRADAR
ä½œè€…æå‡º **RADAR**ï¼ˆReinforcement learning Adjusted Draft-generation Algorithm for speculative samplingï¼‰ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

- **åŠ¨æ€ç”Ÿæˆ draft tree**ï¼šä¸åŒäºä¼ ç»Ÿé™æ€æˆ–å›ºå®šæ·±åº¦çš„ draft tree ç»“æ„ï¼ŒRADAR èƒ½å¤Ÿæ ¹æ®å½“å‰ä¸Šä¸‹æ–‡**å®æ—¶å†³å®šæ˜¯å¦ç»§ç»­è°ƒç”¨ draft model**ï¼Œä»è€Œæ„å»º**åŠ¨æ€æ·±åº¦çš„ draft tree**ã€‚
- **å°† draft tree æ„å»ºå»ºæ¨¡ä¸º MDP**ï¼šå°†æ¯ä¸€æ­¥æ˜¯å¦ç»§ç»­ç”Ÿæˆå€™é€‰ token è§†ä¸ºä¸€ä¸ªå†³ç­–é—®é¢˜ï¼Œå½¢å¼åŒ–ä¸º **Markov Decision Process (MDP)**ã€‚
- **åŸºäºç¦»çº¿å¼ºåŒ–å­¦ä¹ è®­ç»ƒé¢„æµ‹æ¨¡å‹**ï¼šä½¿ç”¨ offline reinforcement learningï¼ˆRLï¼‰è®­ç»ƒä¸€ä¸ªè½»é‡çº§çš„ LSTM-based é¢„æµ‹æ¨¡å‹ï¼Œè¾“å…¥ä¸º draft model è¾“å‡ºçš„ top-k ç½®ä¿¡åº¦åˆ†æ•°ï¼Œè¾“å‡ºä¸º `continue` æˆ– `stop` çš„æ§åˆ¶ä¿¡å·ã€‚
- **æ— éœ€çœŸå®æ ‡ç­¾æ•°æ®**ï¼šç”±äº acceptance length å…·æœ‰éšæœºæ€§ï¼Œæ— æ³•è·å¾—ç²¾ç¡®æ ‡ç­¾ã€‚RADAR åˆ›æ–°åœ°åˆ©ç”¨åœ¨ ShareGPT æ•°æ®é›†ä¸Šè¿è¡Œ EAGLE-3 å¾—åˆ°çš„ **acceptance length åˆ†å¸ƒ**æ„å»ºè®­ç»ƒæ•°æ®é›†ï¼Œç”¨äºè®¡ç®—å¥–åŠ±å‡½æ•°ï¼Œé¿å…äº†åœ¨çº¿äº¤äº’å¸¦æ¥çš„é«˜æˆæœ¬ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | EAGLE-2 / EAGLE-3 | RADAR |
|------|------------------|--------|
| è°ƒç”¨æ¬¡æ•° | å›ºå®šè¶…å‚æ•°ï¼ˆå¦‚8æ¬¡ï¼‰ | åŠ¨æ€å†³å®šï¼ŒæŒ‰éœ€åœæ­¢ |
| å†³ç­–æœºåˆ¶ | å¯å‘å¼å‰ªæ/é‡æ’åº | åŸºäº RL çš„å®æ—¶ç­–ç•¥å†³ç­– |
| è®¡ç®—æ•ˆç‡ | å­˜åœ¨å†—ä½™è°ƒç”¨é£é™© | æ˜¾è‘—å‡å°‘æ— æ•ˆè°ƒç”¨ |
| åŠ é€Ÿæ•ˆæœ | å·²è¾ƒä¼˜ | è¿›ä¸€æ­¥æå‡é€Ÿåº¦ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šåœ¨ä¿æŒå‡ ä¹ç›¸åŒ acceptance length çš„å‰æä¸‹ï¼Œæ˜¾è‘—å‡å°‘ draft model çš„è°ƒç”¨æ¬¡æ•°ï¼Œé™ä½æ¨ç†å»¶è¿Ÿï¼Œå®ç°æ›´é«˜ speedupã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **è®­ç»ƒæ•°æ®é›†**ï¼š`ShareGPT`ï¼ˆç”¨äºæ”¶é›† draft model çš„ confidence scores å’Œæ„å»º acceptance length åˆ†å¸ƒï¼‰
- **è¯„ä¼°ä»»åŠ¡ä¸æ•°æ®é›†**ï¼ˆå››ç±»å…¸å‹ä»»åŠ¡ï¼‰ï¼š
  - å¤šè½®å¯¹è¯ï¼š**MT-bench**
  - æ•°å­¦æ¨ç†ï¼š**GSM8K**
  - æŒ‡ä»¤éµå¾ªï¼š**Alpaca**
  - ä»£ç ç”Ÿæˆï¼š**MBPP**

> æ‰€æœ‰ä»»åŠ¡å‡æœªè¿›è¡Œä»»åŠ¡ç‰¹å®šå¾®è°ƒï¼Œæƒé‡å…±äº«ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **Target LLMs**ï¼š
  - LLaMA-Instruct 3.1 8B (**L3 8B**)
  - Vicuna 13B (**V13B**)
  - DeepSeek-R1-Distill-LLaMA 8B (**DSL 8B**)
- **Draft Model**ï¼šæ²¿ç”¨ EAGLE-3 ä¸­çš„è®¾è®¡ï¼ˆå…·ä½“ç»“æ„æœªè¯¦è¿°ï¼Œä½†éæœ¬æ–‡é‡ç‚¹ï¼‰
- **å…³é”®å‚æ•°**ï¼š
  - Branching factor $ k = 10 $
  - Maximum draft model calls: 8
  - Temperature: 1.0
  - Batch size: 1
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š2Ã— NVIDIA RTX 3090 GPUs

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ä¸æ„ä¹‰ |
|------|-----------|
| **Speedup Ratio** | ç›¸å¯¹äº vanilla auto-regressive decoding çš„å®é™…åŠ é€Ÿæ¯” |
| **Average Acceptance Length (T)** | æ¯ä¸ª drafting-verification cycle å¹³å‡æ¥å—çš„ token æ•°é‡ï¼Œåæ˜  draft è´¨é‡ |
| **Average Number of Calls to Draft Model** | æ¯ cycle å¹³å‡è°ƒç”¨ draft model çš„æ¬¡æ•°ï¼ˆä¸å†æ˜¯å›ºå®šå€¼ï¼‰ |

> â— æ³¨æ„ï¼šä¸æŠ¥å‘Šç”Ÿæˆè´¨é‡ï¼ˆå¦‚ BLEUã€ROUGEï¼‰ï¼Œå› ä¸º speculative sampling æ˜¯ lossless çš„ï¼Œè¾“å‡ºåˆ†å¸ƒä¸å˜ã€‚

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**ï¼šVanilla Auto-Regressive Decodingï¼ˆé€Ÿåº¦åŸºå‡† = 1.00xï¼‰
- **å¯¹æ¯”æ–¹æ³•**ï¼š
  - **EAGLE-2**ï¼šåŸºäºä¸ç¡®å®šæ€§ä¼˜åŒ–çš„ speculative sampling
  - **EAGLE-3**ï¼šå½“å‰æœ€å…ˆè¿›çš„ tree-based speculative sampling æ–¹æ³•ï¼ˆå›ºå®šè°ƒç”¨8æ¬¡ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| Target LLM | Method | MT-bench Speedup | GSM8K Speedup | Alpaca Speedup | MBPP Speedup |
|------------|--------|------------------|---------------|----------------|--------------|
| L3 8B      | EAGLE-2 | 2.56x            | 3.43x         | 2.89x          | 3.29x        |
| L3 8B      | EAGLE-3 | 3.08x            | 4.68x         | 3.86x          | 4.21x        |
| L3 8B      | **RADAR** | **3.41x**        | **4.82x**     | **4.04x**      | **4.44x**    |
| V13B       | EAGLE-3 | 3.74x            | 4.24x         | 3.50x          | 4.55x        |
| V13B       | **RADAR** | **4.05x**        | **4.36x**     | **3.84x**      | **4.75x**    |
| DSL 8B     | EAGLE-3 | 3.42x            | 4.39x         | 3.08x          | 3.71x        |
| DSL 8B     | **RADAR** | **3.86x**        | **4.71x**     | **3.17x**      | **3.99x**    |

> âœ… **æ€»ä½“åŠ é€ŸèŒƒå›´**ï¼š**3.17x ~ 4.82x**ï¼Œç›¸æ¯” EAGLE-3 æå‡ **3% ~ 29%**

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”åˆ†æ

#### ï¼ˆ1ï¼‰Acceptance Length å¯¹æ¯”
- RADAR çš„å¹³å‡ acceptance length ç•¥ä½äº EAGLE-3ï¼ˆçº¦ä½ 1.2%ï¼‰ï¼Œè¯´æ˜ draft token è´¨é‡ç›¸è¿‘ã€‚
- å°½ç®¡ acceptance length ç¨ä½ï¼Œä½† RADAR å®ç°äº†æ›´é«˜çš„ speedup â€”â€” è¡¨æ˜å…¶ä¼˜åŠ¿å¹¶éæ¥è‡ªæ›´é«˜è´¨é‡çš„ draftï¼Œè€Œæ˜¯**æ›´é«˜çš„è®¡ç®—æ•ˆç‡**ã€‚

#### ï¼ˆ2ï¼‰Draft Model è°ƒç”¨æ¬¡æ•°å¯¹æ¯”ï¼ˆTable 2ï¼‰

| Model | MT-bench | GSM8K | Alpaca | MBPP |
|-------|----------|-------|--------|------|
| L3 8B | 5.25     | 6.19  | 6.20   | 6.60 |
| V13B  | 6.88     | 7.26  | 6.83   | 7.26 |
| DSL 8B| 6.10     | 7.20  | 5.85   | 6.47 |

> âœ… **å¹³å‡å‡å°‘è°ƒç”¨æ¬¡æ•°ï¼š9.3% ~ 34.3%ï¼Œå¹³å‡é™å¹…è¾¾ 18.7%**
>
> â†’ è¯æ˜ RADAR æˆåŠŸå®ç°äº†â€œæ—©åœâ€æœºåˆ¶ï¼Œåœ¨ä½æ•ˆæ—¶ä¸»åŠ¨ç»ˆæ­¢ draft ç”Ÿæˆï¼Œå‡å°‘å†—ä½™è®¡ç®—ã€‚

#### ï¼ˆ3ï¼‰å¯è§†åŒ–åˆ†æï¼ˆFigure 2ï¼‰
- å›¾ (a)ï¼šRADAR ä¸ EAGLE-3 çš„ acceptance length åˆ†å¸ƒæ¥è¿‘ï¼Œç»´æŒé«˜æ¥å—ç‡ã€‚
- å›¾ (b)ï¼šRADAR çš„ draft model è°ƒç”¨æ¬¡æ•°é›†ä¸­åœ¨ä¸­é—´åŒºé—´ï¼ˆå¦‚5~7ï¼‰ï¼Œè€Œéå›ºå®šä¸º8ï¼Œä½“ç°åŠ¨æ€å†³ç­–èƒ½åŠ›ã€‚

> ğŸ’¡ å‘ç°ï¼š**é€šè¿‡ç‰ºç‰²æå°‘é‡ acceptance lengthï¼Œæ¢æ¥å¤§å¹…å‡å°‘è®¡ç®—å¼€é”€ï¼Œæœ€ç»ˆå®ç°æ›´é«˜ overall speedupã€‚**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **åŠ¨æ€å†³ç­–ä¼˜äºå›ºå®šè°ƒç”¨**ï¼šå…è®¸æ¨¡å‹æ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€å†³å®šæ˜¯å¦ç»§ç»­ç”Ÿæˆ draft tokenï¼Œèƒ½æœ‰æ•ˆé¿å…åœ¨ä½æ¥å—æ¦‚ç‡åœºæ™¯ä¸‹çš„æµªè´¹ã€‚
2. **MDP + Offline RL å¯è¡Œä¸”é«˜æ•ˆ**ï¼šå³ä½¿æ²¡æœ‰çœŸå®æ ‡æ³¨çš„â€œæœ€ä¼˜è°ƒç”¨æ¬¡æ•°â€ï¼Œä¹Ÿèƒ½é€šè¿‡æ¨¡æ‹Ÿ acceptance length åˆ†å¸ƒæ„å»º rewardï¼ŒæˆåŠŸè®­ç»ƒå‡ºé«˜æ•ˆçš„å†³ç­–ç­–ç•¥ã€‚
3. **åŠ é€Ÿæ¥æºäºæ•ˆç‡ä¼˜åŒ–è€Œé draft è´¨é‡æå‡**ï¼šRADAR å¹¶æœªæ”¹è¿› draft model æœ¬èº«ï¼Œè€Œæ˜¯é€šè¿‡æ™ºèƒ½è°ƒåº¦å‡å°‘äº†å†—ä½™è°ƒç”¨ï¼Œæ˜¯å…¸å‹çš„â€œç³»ç»Ÿçº§ä¼˜åŒ–â€ã€‚
4. **é€šç”¨æ€§å¼º**ï¼šåœ¨ä¸‰ç§ä¸åŒ LLM å’Œå››ç§ä¸åŒç±»å‹ä»»åŠ¡ä¸Šå‡å–å¾—ä¸€è‡´é¢†å…ˆï¼Œè¡¨æ˜æ–¹æ³•å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

### âš ï¸ å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡çš„ acceptance length åˆ†å¸ƒä¼°è®¡**ï¼šè®­ç»ƒæ•°æ®æ¥è‡ª EAGLE-3 åœ¨ ShareGPT ä¸Šçš„è¡Œä¸ºï¼Œè‹¥ draft model æˆ–ä»»åŠ¡å·®å¼‚è¿‡å¤§ï¼Œå¯èƒ½å½±å“è¿ç§»æ•ˆæœã€‚
- **é¢„æµ‹æ¨¡å‹å¼•å…¥é¢å¤–å¼€é”€**ï¼šè™½ç„¶ä½¿ç”¨è½»é‡ LSTMï¼Œä½†ä»å¢åŠ äº†ä¸€å®šè®¡ç®—è´Ÿæ‹…ï¼ˆ$ T_{\text{eye}} $ï¼‰ï¼Œåœ¨æå° draft model åœºæ™¯ä¸‹æ”¶ç›Šå¯èƒ½å—é™ã€‚
- **æœªæ¢ç´¢æ›´å¤æ‚æ¶æ„**ï¼šç›®å‰ä»…ä½¿ç”¨ç®€å• LSTMï¼Œæœªæ¥å¯å°è¯• Transformer æˆ– MoE æ¶æ„ä»¥è¿›ä¸€æ­¥æå‡å†³ç­–ç²¾åº¦ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ”¹è¿›é¢„æµ‹æ¨¡å‹æ¶æ„ä¸è®­ç»ƒæœºåˆ¶ï¼ˆå¦‚å¼•å…¥ contrastive learningã€better reward shapingï¼‰
- è®¾è®¡æ›´ç²¾ç»†çš„ reward å‡½æ•°ï¼Œè€ƒè™‘ memory bandwidthã€GPU occupancy ç­‰ç¡¬ä»¶å› ç´ 
- æ‰©å±•è‡³ streaming æˆ– long-context åœºæ™¯ä¸‹çš„ adaptive drafting
- æ¢ç´¢ä¸å…¶ä»–åŠ é€ŸæŠ€æœ¯ï¼ˆå¦‚ quantizationã€prompt cachingï¼‰çš„è”åˆä¼˜åŒ–

---

## æ€»ç»“

> **RADAR æå‡ºäº†ä¸€ç§æ–°é¢–çš„ã€åŸºäº RL çš„åŠ¨æ€ speculative sampling æ¡†æ¶ï¼Œé¦–æ¬¡å°† draft tree çš„ç”Ÿæˆè¿‡ç¨‹å»ºæ¨¡ä¸º MDPï¼Œå¹¶é€šè¿‡ offline RL å®ç°å¯¹ draft model è°ƒç”¨æ¬¡æ•°çš„å®æ—¶è°ƒæ§ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ª LLM å’Œä»»åŠ¡ä¸Šå®ç°äº† 3.17xâ€“4.82x çš„åŠ é€Ÿï¼Œç›¸æ¯” EAGLE-3 å¹³å‡å‡å°‘ 18.7% çš„ draft model è°ƒç”¨ï¼Œåœ¨å‡ ä¹ä¸æŸå¤± acceptance length çš„æƒ…å†µä¸‹æ˜¾è‘—æå‡äº†æ¨ç†æ•ˆç‡ï¼Œä»£è¡¨äº† speculative sampling æ–¹å‘çš„é‡è¦è¿›å±•ã€‚**

</details>

---

### 16. [Distillation-Guided Structural Transfer for Continual Learning Beyond Sparse Distributed Memory](https://arxiv.org/abs/2512.15267)

**Authors**: Huiyan Xue, Xuming Ran, Yaxin Li, Qi Xu, Enhui Li, Yi Xu, Qiang Zhang  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.15267v1  

#### Abstract
Sparse neural systems are gaining traction for efficient continual learning due to their modularity and low interference. Architectures such as Sparse Distributed Memory Multi-Layer Perceptrons (SDMLP) construct task-specific subnetworks via Top-K activation and have shown resilience against catastr...

---

### 17. [AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach](https://arxiv.org/abs/2512.13714)

**Authors**: Gangesh Pathak, Prasanna Kumar  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.13714v1  

#### Abstract
LLM implementations are failing in highly regulated industries owing to instability issues, inconsistent reasoning, hallucinations and performance variability, especially in workflows. These reliability issues restrict safe use of LLM in areas that need the precision of facts and consistent behavior...

---

### 18. [Adversarial versification in portuguese as a jailbreak operator in LLMs](https://arxiv.org/abs/2512.15353)

**Authors**: Joao Queiroz  
**Category**: cs.CL  
**Published**: 2025-12-18  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.15353v1  

#### Abstract
Recent evidence shows that the versification of prompts constitutes a highly effective adversarial mechanism against aligned LLMs. The study 'Adversarial poetry as a universal single-turn jailbreak mechanism in large language models' demonstrates that instructions routinely refused in prose become e...

---

### 19. [Is GPT-OSS All You Need? Benchmarking Large Language Models for Financial Intelligence and the Surprising Efficiency Paradox](https://arxiv.org/abs/2512.14717)

**Authors**: Ziqian Bi, Danyang Zhang, Junhao Song, Chiung-Yi Tseng  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.14717v1  

#### Abstract
The rapid adoption of large language models in financial services necessitates rigorous evaluation frameworks to assess their performance, efficiency, and practical applicability. This paper conducts a comprehensive evaluation of the GPT-OSS model family alongside contemporary LLMs across ten divers...

---

### 20. [SigMA: Path Signatures and Multi-head Attention for Learning Parameters in fBm-driven SDEs](https://arxiv.org/abs/2512.15088)

**Authors**: Xianglin Wu, Chiheb Ben Hammouda, Cornelis W. Oosterlee  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.15088v1  

#### Abstract
Stochastic differential equations (SDEs) driven by fractional Brownian motion (fBm) are increasingly used to model systems with rough dynamics and long-range dependence, such as those arising in quantitative finance and reliability engineering. However, these processes are non-Markovian and lack a s...

---

### 21. [State-Dependent Refusal and Learned Incapacity in RLHF-Aligned Language Models](https://arxiv.org/abs/2512.13762)

**Authors**: TK Lee  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.13762v1  

#### Abstract
Large language models (LLMs) are widely deployed as general-purpose tools, yet extended interaction can reveal behavioral patterns not captured by standard quantitative benchmarks. We present a qualitative case-study methodology for auditing policy-linked behavioral selectivity in long-horizon inter...

---

### 22. [Sparsity-Controllable Dynamic Top-p MoE for Large Foundation Model Pre-training](https://arxiv.org/abs/2512.13996)

**Authors**: Can Jin, Hongwu Peng, Mingcan Xiang, Qixin Zhang, Xiangchi Yuan, Amit Hasan, Ohiremen Dibua, Yifan Gong, Yan Kang, Dimitris N. Metaxas  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.13996v1  

#### Abstract
Sparse Mixture-of-Experts (MoE) architectures effectively scale model capacity by activating only a subset of experts for each input token. However, the standard Top-k routing strategy imposes a uniform sparsity pattern that ignores the varying difficulty of tokens. While Top-p routing offers a flex...

---

### 23. [TiCard: Deployable EXPLAIN-only Residual Learning for Cardinality Estimation](https://arxiv.org/abs/2512.14358)

**Authors**: Qizhi Wang  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.14358v1  

#### Abstract
Cardinality estimation is a key bottleneck for cost-based query optimization, yet deployable improvements remain difficult: classical estimators miss correlations, while learned estimators often require workload-specific training pipelines and invasive integration into the optimizer. This paper pres...

---

### 24. [Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning](https://arxiv.org/abs/2512.15274)

**Authors**: Yiliu Sun, Zicheng Zhao, Yang Wei, Yanfang Zhang, Chen Gong  
**Category**: cs.CL  
**Published**: 2025-12-18  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.15274v1  

#### Abstract
Reinforcement Learning with Verifiable Rewards (RLVR) significantly enhances the reasoning capability of Large Language Models (LLMs). Current RLVR approaches typically conduct training across all generated tokens, but neglect to explore which tokens (e.g., prefix tokens) actually contribute to reas...

---

### 25. [LeaseGuard: Raft Leases Done Right](https://arxiv.org/abs/2512.15659)

**Authors**: A. Jesse Jiryu Davis, Murat Demirbas, Lingzhi Deng  
**Category**: cs.DC  
**Published**: 2025-12-18  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.15659v1  

#### Abstract
Raft is a leading consensus algorithm for replicating writes in distributed databases. However, distributed databases also require consistent reads. To guarantee read consistency, a Raft-based system must either accept the high communication overhead of a safety check for each read, or implement lea...

---

### 26. [How a Bit Becomes a Story: Semantic Steering via Differentiable Fault Injection](https://arxiv.org/abs/2512.14715)

**Authors**: Zafaryab Haider, Md Hafizur Rahman, Shane Moeykens, Vijay Devabhaktuni, Prabuddha Chakraborty  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.14715v1  

#### Abstract
Hard-to-detect hardware bit flips, from either malicious circuitry or bugs, have already been shown to make transformers vulnerable in non-generative tasks. This work, for the first time, investigates how low-level, bitwise perturbations (fault injection) to the weights of a large language model (LL...

---

### 27. [Deep Learning and Elicitability for McKean-Vlasov FBSDEs With Common Noise](https://arxiv.org/abs/2512.14967)

**Authors**: Felipe J. P. Antunes, Yuri F. Saporito, Sebastian Jaimungal  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.14967v1  

#### Abstract
We present a novel numerical method for solving McKean-Vlasov forward-backward stochastic differential equations (MV-FBSDEs) with common noise, combining Picard iterations, elicitability and deep learning. The key innovation involves elicitability to derive a path-wise loss function, enabling effici...

---

### 28. [EMFusion: Conditional Diffusion Framework for Trustworthy Frequency Selective EMF Forecasting in Wireless Networks](https://arxiv.org/abs/2512.15067)

**Authors**: Zijiang Yan, Yixiang Huang, Jianhua Pei, Hina Tabassum, Luca Chiaraviglio  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.15067v1  

#### Abstract
The rapid growth in wireless infrastructure has increased the need to accurately estimate and forecast electromagnetic field (EMF) levels to ensure ongoing compliance, assess potential health impacts, and support efficient network planning. While existing studies rely on univariate forecasting of wi...

---

### 29. [How Many Heads Make an SSM? A Unified Framework for Attention and State Space Models](https://arxiv.org/abs/2512.15115)

**Authors**: Ali Ghodsi  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.15115v1  

#### Abstract
Sequence modeling has produced diverse architectures -- from classical recurrent neural networks to modern Transformers and state space models (SSMs) -- yet a unified theoretical understanding of expressivity and trainability trade-offs remains limited. We introduce a unified framework that represen...

---

### 30. [O-EENC-SD: Efficient Online End-to-End Neural Clustering for Speaker Diarization](https://arxiv.org/abs/2512.15229)

**Authors**: Elio Gruttadauria (IP Paris, LTCI, IDS, S2A), Mathieu Fontaine (LTCI, IP Paris), Jonathan Le Roux (IDS, S2A, LTCI), Slim Essid (IDS, S2A, LTCI)  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.15229v1  

#### Abstract
We introduce O-EENC-SD: an end-to-end online speaker diarization system based on EEND-EDA, featuring a novel RNN-based stitching mechanism for online prediction. In particular, we develop a novel centroid refinement decoder whose usefulness is assessed through a rigorous ablation study. Our system p...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
