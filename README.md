# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-19 05:57:41 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Staggered Batch Scheduling: Co-optimizing Time-to-First-Token and Throughput for High-Efficiency LLM Inference](https://arxiv.org/abs/2512.16134)

**Authors**: Jian Tian, Shuailong Li, Yang Cao, Wenbo Cui, Minghan Zhu, Wenkang Wu, Jianming Zhang, Yanpeng Wang, Zhiwen Xiao, Zhenyu Hou, Dou Shen  
**Category**: cs.DC  
**Published**: 2025-12-19  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2512.16134v1  

#### Abstract
The evolution of Large Language Model (LLM) serving towards complex, distributed architectures--specifically the P/D-separated, large-scale DP+EP paradigm--introduces distinct scheduling challenges. Unlike traditional deployments where schedulers can treat instances as black boxes, DP+EP architectur...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Staggered Batch Scheduling: Co-optimizing Time-to-First-Token and Throughput for High-Efficiency LLM Inference*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹å¤§è§„æ¨¡ **DP+EP**ï¼ˆData Parallelism + Expert Parallelismï¼‰æ¶æ„ä¸‹çš„ **Large Language Model (LLM)** æ¨ç†æœåŠ¡ä¸­å­˜åœ¨çš„è°ƒåº¦æ•ˆç‡ç“¶é¢ˆé—®é¢˜ï¼Œå°¤å…¶æ˜¯ **P/Dåˆ†ç¦»æ¶æ„**ï¼ˆPrefill/Decode disaggregationï¼‰ä¸­å› é«˜åŒæ­¥å¼€é”€å¯¼è‡´çš„æ€§èƒ½é€€åŒ–ã€‚

å…·ä½“é—®é¢˜åŒ…æ‹¬ï¼š
- **Immediate Dispatch** ç­–ç•¥åœ¨éæŠ¢å å¼ã€ç¦»æ•£æ‰¹å¤„ç†çš„ **Prefill é˜¶æ®µ** å¼•å‘ä¸¥é‡çš„ **Head-of-Line (HOL) é˜»å¡** å’Œè®¾å¤‡å†…éƒ¨æ’é˜Ÿï¼ˆDevice-side Queuingï¼‰ï¼Œæ˜¾è‘—å¢åŠ  **TTFT**ï¼ˆTime-to-First-Tokenï¼‰ã€‚
- åœ¨ **DP+EP æ¶æ„** ä¸­ï¼Œç”±äº All-to-All é€šä¿¡å’Œè´Ÿè½½ä¸å‡è¡¡ï¼ˆstraggler effectï¼‰ï¼Œä¼ ç»Ÿè°ƒåº¦ç­–ç•¥æ— æ³•æœ‰æ•ˆå¹³è¡¡å„ DP å•å…ƒé—´çš„è®¡ç®—è´Ÿè½½ï¼Œé€ æˆèµ„æºæµªè´¹å’Œååä¸‹é™ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

#### âœ… **Staggered Batch Scheduling (SBS)**
- **æ ¸å¿ƒæ€æƒ³**ï¼šä¸»åŠ¨å¼•å…¥ä¸€ä¸ªçŸ­æš‚çš„ã€è‡ªé€‚åº”çš„ç­‰å¾…çª—å£ï¼ˆbuffering windowï¼‰ï¼Œå°†è¯·æ±‚èšåˆä¸ºæœ€ä¼˜æ‰¹æ¬¡åå†ç»Ÿä¸€è°ƒåº¦ï¼Œå®ç°â€œä»¥çŸ­æ—¶ç­‰å¾…æ¢å–æ›´ä¼˜æ‰§è¡Œâ€ã€‚
- **æœºåˆ¶ä¼˜åŠ¿**ï¼š
  - å°†æ’é˜Ÿä»ä¸å¯æ§çš„ **Device-side Queue** è½¬ç§»åˆ°å¯ç®¡ç†çš„ **Scheduler-side Queue**ã€‚
  - æ¶ˆé™¤å†…éƒ¨ HOL é˜»å¡ï¼Œæ˜¾è‘—é™ä½ TTFTã€‚
  - åˆ©ç”¨æ‰¹å¤„ç†çª—å£è·å¾—å…¨å±€è§†å›¾ï¼Œæ”¯æŒç²¾ç»†åŒ–è´Ÿè½½å‡è¡¡ã€‚

#### âœ… **Load-Aware Global Allocation**
- åŸºäº SBS æä¾›çš„æ‰¹å¤„ç†çª—å£ï¼Œè®¾è®¡äº†ä¸¤ä¸ªé˜¶æ®µçš„ç»Ÿä¸€è´Ÿè½½åˆ†é…ç­–ç•¥ï¼š
  - **Prefill é˜¶æ®µ**ï¼šé‡‡ç”¨ **Water-Filling å¯å‘å¼ç®—æ³•**ï¼ˆåŸºäºè´ªå¿ƒçš„ bin-packingï¼‰ï¼Œä¼˜å…ˆå°†é•¿åºåˆ—è¯·æ±‚åˆ†é…ç»™å‰©ä½™å®¹é‡æœ€å¤§çš„ DP å•å…ƒï¼Œå‡å°‘å¹¶è¡ŒåŒ–æ°”æ³¡ï¼ˆParallelization Bubblesï¼‰ã€‚
  - **Decode é˜¶æ®µ**ï¼šæå‡º **IQR-Aware Lexicographical Scheduling**ï¼Œè”åˆä¼˜åŒ– **Batch Size å¹³è¡¡** ä¸ **KV Cache å†…å­˜è´Ÿè½½å¹³è¡¡**ï¼Œç¼“è§£è€¦åˆå‹è´Ÿè½½å¤±è¡¡é—®é¢˜ã€‚

#### âœ… **é—­ç¯åé¦ˆæ§åˆ¶æœºåˆ¶**
- è®¾è®¡äº†ä¸€ä¸ªåŒ…å« **Control Plane**ã€**State Plane** å’Œ **Resource Plane** çš„é—­ç¯ç³»ç»Ÿï¼ŒåŠ¨æ€è°ƒæ•´è°ƒåº¦é—´éš” $I_{opt}$ï¼Œç¡®ä¿ä¸é›†ç¾¤å¤„ç†èƒ½åŠ›åŒ¹é…ã€‚
- å¼•å…¥ä¸‰é‡çŠ¶æ€åŒæ­¥åè®®ï¼ˆQuiescence Polling, Asynchronous Signaling, Liveness Watchdogï¼‰ï¼Œä¿éšœç³»ç»Ÿé²æ£’æ€§å’Œå¯ç”¨æ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ Immediate Dispatchï¼‰ | æœ¬æ–‡ SBS |
|------|-------------------------------|--------|
| **TTFT** | é«˜ï¼ˆå—è®¾å¤‡å†…æ’é˜Ÿå½±å“ï¼‰ | â†“ 30â€“40% |
| **Throughput** | å—è´Ÿè½½ä¸å‡é™åˆ¶ | â†‘ 15â€“20% |
| **è´Ÿè½½å‡è¡¡** | å±€éƒ¨å†³ç­–ï¼Œæ˜“äº§ç”Ÿ straggler | å…¨å±€ä¼˜åŒ–ï¼Œæ˜¾è‘—æŠ‘åˆ¶ straggler |
| **è°ƒåº¦ç²’åº¦** | å®ä¾‹çº§ï¼ˆInstance-levelï¼‰ | å­å®ä¾‹çº§ï¼ˆDP-Attention Unit çº§ï¼‰ |
| **é€‚ç”¨æ¶æ„** | å•ä½“æˆ–ç®€å• TP æ¶æ„ | å¤æ‚ P/D åˆ†ç¦» + DP+EP æ¶æ„ |

> SBS ä¸æ˜¯ç®€å•çš„â€œå»¶è¿Ÿè°ƒåº¦â€ï¼Œè€Œæ˜¯é€šè¿‡ **æ—¶é—´è§£è€¦** å®ç° **ç©ºé—´åˆ©ç”¨ç‡æœ€å¤§åŒ–**ï¼Œå®ç°äº† **TTFT ä¸ Throughput çš„ååŒä¼˜åŒ–**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### å®éªŒå¹³å°ä¸æ¨¡å‹
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šç”Ÿäº§çº§ **NVIDIA H800 GPU é›†ç¾¤**
- **éƒ¨ç½²æ¶æ„**ï¼š**DeepSeek-V3** æ¨¡å‹ï¼Œé‡‡ç”¨ **P/D åˆ†ç¦» + DP+EP æ··åˆå¹¶è¡Œ** æ¶æ„
- **å…¸å‹é…ç½®**ï¼š
  - Prefill å®ä¾‹ï¼š`TP=4`, `DP=8`, `EP=32`
  - Decode å®ä¾‹ï¼š`TP=1`, `DP=32`, `EP=32`
  - Chunk Sizeï¼š3K / 5K / 16K tokens

### å·¥ä½œè´Ÿè½½ï¼ˆWorkloadï¼‰
- **Prefill é˜¶æ®µæµ‹è¯•**ï¼š
  - è¾“å…¥é•¿åº¦èŒƒå›´ï¼š0â€“3K tokensï¼ˆå‡å€¼ 1Kï¼‰å’Œ 3Kâ€“64K tokensï¼ˆå‡å€¼ 6.7Kï¼‰
  - æ¨¡æ‹ŸçœŸå®å¯¹è¯åœºæ™¯ä¸­çš„å˜é•¿è¯·æ±‚åˆ†å¸ƒ
- **Decode é˜¶æ®µæµ‹è¯•**ï¼š
  - æ€»é•¿åº¦çº¦ 2.5K tokensï¼ˆå«è¾“å…¥è¾“å‡ºï¼‰
  - å¹³å‡ Batch Size â‰ˆ 35

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **TTFT** | Time-to-First-Tokenï¼Œé¦– token å»¶è¿Ÿ |
| **Queue Time** | è¯·æ±‚åœ¨é˜Ÿåˆ—ä¸­çš„ç­‰å¾…æ—¶é—´ï¼ˆåŒºåˆ† device-side vs scheduler-sideï¼‰ |
| **QPS** | Queries Per Secondï¼Œç³»ç»Ÿååé‡ |
| **Chunk Utilization** | Prefill Chunk çš„ token å®¹é‡åˆ©ç”¨ç‡ |
| **KV Cache Load Distribution** | Decode é˜¶æ®µå„ DP å•å…ƒçš„ç¼“å­˜å ç”¨æ–¹å·® |
| **P99 Latency** | å°¾éƒ¨å»¶è¿Ÿè¡¨ç° |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**ï¼šImmediate Dispatch è°ƒåº¦å™¨ï¼ˆå³æ¥å³å‘ï¼‰
- å¯¹æ¯”é¡¹åŒ…æ‹¬ï¼š
  - ä¸åŒè´Ÿè½½æ°´å¹³ä¸‹çš„ TTFT ä¸åå
  - å†…éƒ¨é˜Ÿåˆ—å»¶è¿Ÿåˆ†è§£
  - è´Ÿè½½å‡è¡¡ç¨‹åº¦ï¼ˆKV Cache æ–¹å·®ã€Chunk åˆ©ç”¨ç‡ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“‰ **TTFT æ˜¾è‘—é™ä½ï¼ˆæœ€é«˜è¾¾ 40%ï¼‰**

| åœºæ™¯ | ç»“æœ |
|------|------|
| **è¾“å…¥é•¿åº¦ 0â€“3K tokens**ï¼ˆå›¾6aï¼‰ | åœ¨ â‰¤80% è´Ÿè½½ä¸‹ï¼ŒSBS ç›¸æ¯” baseline **TTFT ä¸‹é™ 30â€“40%** |
| **è¾“å…¥é•¿åº¦ 3Kâ€“64K tokens**ï¼ˆå›¾6bï¼‰ | å³ä½¿åœ¨é«˜æ–¹å·®é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸‹ï¼Œä»èƒ½ **æœ‰æ•ˆå‹åˆ¶å°¾å»¶è¿Ÿï¼ˆtail latencyï¼‰**ï¼ŒéªŒè¯é²æ£’æ€§ |

> å…³é”®åŸå› ï¼šSBS æˆåŠŸå°†åŸæœ¬éšè—åœ¨è®¾å¤‡å†…éƒ¨çš„æ’é˜Ÿæš´éœ²åˆ°è°ƒåº¦å±‚ï¼Œå¹¶é€šè¿‡æ‰¹é‡è°ƒåº¦æ¶ˆé™¤ç©ºè½¬å‘¨æœŸã€‚

---

### ğŸ“ˆ **Throughput æ˜¾è‘—æå‡**

#### âœ… **Prefill é˜¶æ®µååæå‡ 12.9% â€“ 22.8%**

| é…ç½® | Baseline QPS | SBS QPS | Î”QPS (%) | Chunk Util. æå‡ |
|------|-------------|--------|----------|------------------|
| Chunk 3K | 57 | 70 | **+22.8%** | 51.83% â†’ 88.7% (+36.9pp) |
| Chunk 5K | 70 | 79 | **+12.9%** | 53.0% â†’ 88.0% (+35.0pp) |

> **Chunk Utilization ä» ~52% æå‡è‡³ ~88%**ï¼Œè¯´æ˜ SBS æˆåŠŸå¡«è¡¥äº†å¹¶è¡ŒåŒ–è¿‡ç¨‹ä¸­çš„â€œæ°”æ³¡â€ï¼Œæå¤§æå‡äº†èµ„æºåˆ©ç”¨ç‡ã€‚

#### âœ… **Decode é˜¶æ®µååæå‡ ~15%**

- **KV Cache è´Ÿè½½æ–¹å·®é™ä½ 40%**ï¼ˆå›¾7ï¼‰ï¼š
  - Baselineï¼šÂ±1Ïƒ èŒƒå›´ä¸º 40Kâ€“130K tokensï¼Œå­˜åœ¨æç«¯ outlierï¼ˆ~150Kï¼‰
  - SBSï¼šç¨³å®šåœ¨ 60Kâ€“100K tokensï¼Œæ— ä¸¥é‡ straggler
- **Aggregate Decode Throughput æå‡ 15%**ï¼ˆå›¾8ï¼‰
  - åŸå› ï¼šé€šè¿‡ IQR-aware masking + lexicographical selectionï¼Œæœ‰æ•ˆé¿å…æ…¢èŠ‚ç‚¹æ‹–ç´¯æ•´ä½“åŒæ­¥é€Ÿåº¦

---

### ğŸ” æ¶ˆèåˆ†æï¼ˆéšå«äºè®¾è®¡é€»è¾‘ä¸­ï¼‰

è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»æœºåˆ¶è®¾è®¡å¯æ¨æ–­ä»¥ä¸‹å…³é”®ç»„ä»¶çš„ä½œç”¨ï¼š

| ç»„ä»¶ | åŠŸèƒ½ | å½±å“ |
|------|------|------|
| **Adaptive Interval ($I_{opt}$)** | åŠ¨æ€åŒ¹é…é›†ç¾¤åå | é¿å…è¿‡æ—©æˆ–è¿‡æ™š dispatchï¼Œä¿æŒé«˜åˆ©ç”¨ç‡ |
| **Water-Filling Allocation (Prefill)** | è´ªå¿ƒæœ€é•¿åºåˆ—ä¼˜å…ˆåˆ†é… | å‡å°‘ stragglerï¼Œæé«˜ Chunk åˆ©ç”¨ç‡ |
| **IQR-Aware Masking (Decode)** | è¿‡æ»¤æ½œåœ¨å†…å­˜æº¢å‡º DP å•å…ƒ | æå‡è°ƒåº¦å®‰å…¨æ€§ä¸ç¨³å®šæ€§ |
| **Lexicographical Selection** | å…ˆå¹³è¡¡ Batch Sizeï¼Œå†å¹³è¡¡ KV Cache | å®ç°å¤šç›®æ ‡ååŒä¼˜åŒ– |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **Immediate Dispatch åœ¨ DP+EP æ¶æ„ä¸­æœ¬è´¨ä¸Šæ˜¯æ¬¡ä¼˜çš„**  
   å› å…¶å¿½è§† Prefill é˜¶æ®µçš„â€œé—¨æ§æœåŠ¡â€ç‰¹æ€§ï¼ˆGated Serviceï¼‰ï¼Œå¯¼è‡´å¤§é‡è¯·æ±‚é™·å…¥ä¸å¯è§çš„è®¾å¤‡å†…é˜Ÿåˆ—ï¼Œæ¶åŒ– TTFTã€‚

2. **çŸ­æ—¶ç¼“å†²åè€Œèƒ½åŠ é€Ÿæ•´ä½“å“åº”ï¼ˆCounter-intuitive accelerationï¼‰**  
   SBS è¯æ˜ï¼šé€šè¿‡å¯æ§çš„ **scheduler-side buffering**ï¼Œå¯ä»¥å°†ç¢ç‰‡åŒ–çš„å¹¶è¡Œæ‰§è¡Œè½¬åŒ–ä¸ºé«˜åº¦åè°ƒçš„æ‰¹é‡å¤„ç†ï¼Œä»è€ŒåŒæ—¶ä¼˜åŒ–å»¶è¿Ÿä¸ååã€‚

3. **å…¨å±€è§†å›¾æ˜¯è§£å†³è´Ÿè½½ä¸å‡è¡¡çš„å…³é”®**  
   æ‰¹å¤„ç†çª—å£æä¾›äº†è§‚å¯Ÿå¤šä¸ªè¯·æ±‚çš„æœºä¼šï¼Œä½¿å¾— **bin-packing** å’Œ **multi-objective allocation** æˆä¸ºå¯èƒ½ï¼Œæ˜¾è‘—æ”¹å–„ DP å•å…ƒé—´çš„è´Ÿè½½åˆ†å¸ƒã€‚

4. **Prefill ä¸ Decode çš„è´Ÿè½½å¤±è¡¡æœ¬è´¨ä¸åŒä½†å¯ç»Ÿä¸€å»ºæ¨¡**  
   - Prefillï¼šä¸»è¦æ˜¯è®¡ç®—è´Ÿè½½ä¸å‡ï¼ˆsequence lengthï¼‰
   - Decodeï¼šæ˜¯ **Batch Size ä¸ KV Cache å®¹é‡çš„è€¦åˆå¤±è¡¡**
   - SBS æå‡ºåˆ†é˜¶æ®µç­–ç•¥ï¼Œåœ¨ç»Ÿä¸€æ¡†æ¶ä¸‹åˆ†åˆ«åº”å¯¹

---

### âš ï¸ å±€é™æ€§

1. **ä¾èµ–ç¨³å®šçš„ç½‘ç»œä¸ä½å»¶è¿Ÿåé¦ˆæœºåˆ¶**  
   è‹¥ EndForward ä¿¡å·å»¶è¿Ÿè¿‡é«˜æˆ–ä¸¢å¤±é¢‘ç¹ï¼Œä¼šå½±å“ $I_{opt}$ çš„å‡†ç¡®æ€§ï¼Œè¿›è€Œå½±å“æ€§èƒ½ã€‚

2. **å¯¹æä½å»¶è¿Ÿ SLA åœºæ™¯å¯èƒ½å­˜åœ¨æŒ‘æˆ˜**  
   è™½ç„¶å¹³å‡ TTFT ä¸‹é™ï¼Œä½†åœ¨æä½å®¹å¿å»¶è¿Ÿï¼ˆå¦‚ <100msï¼‰çš„åœºæ™¯ä¸­ï¼Œäººä¸ºå¼•å…¥çš„ buffering window å¯èƒ½æˆä¸ºç“¶é¢ˆã€‚

3. **æ‰©å±•æ€§ä¾èµ–å¥åº·å®ä¾‹æ¢æµ‹æœºåˆ¶**  
   å½“é›†ç¾¤è§„æ¨¡è¿›ä¸€æ­¥æ‰©å¤§æ—¶ï¼Œæ‹“æ‰‘æ„ŸçŸ¥ä¸æ•…éšœæ£€æµ‹å¤æ‚åº¦ä¸Šå‡ï¼Œéœ€æ›´å¼ºå¥çš„ auto-scaling æ”¯æŒã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **ç»“åˆ Prefix Cache-Aware Scheduling**  
   å¦‚ Preble æˆ– SGL-Router æ‰€ç¤ºï¼Œåˆ©ç”¨å‰ç¼€å…±äº«è¿›ä¸€æ­¥å‡å°‘å†—ä½™è®¡ç®—ï¼Œä¸ SBS å½¢æˆååŒä¼˜åŒ–ã€‚

2. **æ”¯æŒåŠ¨æ€å¼¹æ€§æ‰©ç¼©å®¹ï¼ˆAuto-scalingï¼‰ä¸‹çš„å¿«é€Ÿæ”¶æ•›**  
   å½“å‰ $I_{opt}$ ä¾èµ–æ»‘åŠ¨çª—å£ç»Ÿè®¡ï¼Œæœªæ¥å¯æ¢ç´¢æ›´å¿«é€Ÿé€‚åº”çªå‘æµé‡çš„æ§åˆ¶ç®—æ³•ï¼ˆå¦‚ PID æ§åˆ¶å™¨ï¼‰ã€‚

3. **è·¨ç§Ÿæˆ·å…¬å¹³æ€§ä¿éšœæœºåˆ¶**  
   åœ¨å¤šç§Ÿæˆ·ç¯å¢ƒä¸‹ï¼Œå¦‚ä½•åœ¨æ‰¹å¤„ç†ä¸­ä¿è¯ FCFS å…¬å¹³æ€§ä¸ä¼˜å…ˆçº§è°ƒåº¦çš„å…¼å®¹æ€§å€¼å¾—æ·±å…¥ç ”ç©¶ã€‚

4. **åº”ç”¨äº MoE åŠ¨æ€è·¯ç”±åœºæ™¯**  
   å°† SBS æ€æƒ³å»¶ä¼¸è‡³ä¸“å®¶é€‰æ‹©ï¼ˆexpert routingï¼‰å±‚é¢ï¼Œå®ç° **routing + scheduling joint optimization**ã€‚

---

## æ€»ç»“

> **SBS çš„æ ¸å¿ƒæ´è§æ˜¯ï¼šåœ¨é«˜åŒæ­¥æˆæœ¬çš„ç°ä»£ LLM æ¨ç†æ¶æ„ä¸­ï¼Œâ€œç«‹å³è°ƒåº¦â€ä¸å†æ˜¯æœ€ä½³é€‰æ‹©ï¼›é€‚åº¦å»¶è¿Ÿã€å…¨å±€ç»Ÿç­¹çš„â€œé”™å³°æ‰¹å¤„ç†â€æ‰æ˜¯å®ç°ä½å»¶è¿Ÿä¸é«˜åååŒèµ¢çš„å…³é”®ã€‚**

è¯¥å·¥ä½œä¸ä»…æå‡ºäº†å®ç”¨é«˜æ•ˆçš„è°ƒåº¦æœºåˆ¶ï¼Œæ›´ä¸ºä¸‹ä¸€ä»£è¶…å¤§è§„æ¨¡ MoE æ¨¡å‹çš„æ¨ç†ç³»ç»Ÿè®¾è®¡æä¾›äº†å¯æ‰©å±•çš„èŒƒå¼â€”â€”**ç¦»æ•£åŒ–è°ƒåº¦ + å…¨å±€è´Ÿè½½æ•´å½¢ï¼ˆDiscrete Scheduling + Global Load Shapingï¼‰**ã€‚

</details>

---

### 2. [Efficient CPU-GPU Collaborative Inference for MoE-based LLMs on Memory-Limited Systems](https://arxiv.org/abs/2512.16473)

**Authors**: En-Ming Huang, Li-Shang Lin, Chun-Yi Lee  
**Category**: cs.DC  
**Published**: 2025-12-19  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2512.16473v1  

#### Abstract
Large Language Models (LLMs) have achieved impressive results across various tasks, yet their high computational demands pose deployment challenges, especially on consumer-grade hardware. Mixture of Experts (MoE) models provide an efficient solution through selective activation of parameter subsets,...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEfficient CPU-GPU Collaborative Inference for MoE-based LLMs on Memory-Limited Systems

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº **Mixture of Experts (MoE)** çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ Mixtral 8x7Bï¼‰è™½ç„¶åœ¨è®¡ç®—ä¸Šå…·æœ‰ç¨€ç–æ¿€æ´»ä¼˜åŠ¿ï¼Œä½†å…¶åºå¤§çš„æ¨¡å‹æƒé‡ï¼ˆä¾‹å¦‚ 80GBï¼‰è¿œè¶…æ¶ˆè´¹çº§ GPUï¼ˆå¦‚ RTX 4090 çš„ 24GB æ˜¾å­˜ï¼‰ï¼Œå¯¼è‡´éƒ¨ç½²å›°éš¾ã€‚ä¼ ç»Ÿçš„ **offloading** æ–¹æ³•å°†ä¸“å®¶æƒé‡ä» CPU å†…å­˜åŠ è½½åˆ° GPUï¼Œä½†ç”±äºé€šä¿¡å»¶è¿Ÿé«˜ï¼Œä¸¥é‡å½±å“æ¨ç†é€Ÿåº¦ï¼Œå°¤å…¶æ˜¯åœ¨å•è¯·æ±‚ï¼ˆsingle-requestï¼‰åœºæ™¯ä¸‹ã€‚

æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é™åˆ¶ï¼š
- **ä»…ä¾èµ– GPU è®¡ç®—**ï¼Œæœªå……åˆ†åˆ©ç”¨ CPU å¤šæ ¸å¹¶è¡Œèƒ½åŠ›ï¼›
- **é¢„å–ï¼ˆprefetchingï¼‰æœºåˆ¶å—é™äºé€šä¿¡ç“¶é¢ˆ**ï¼Œéš¾ä»¥å®ç°æœ‰æ•ˆè®¡ç®—-é€šä¿¡é‡å ï¼›
- éƒ¨åˆ†æ–¹æ³•éœ€ä¿®æ”¹æ¨¡å‹ç»“æ„æˆ–è¿›è¡Œç¦»çº¿åˆ†æï¼ˆprofilingï¼‰ï¼Œé€šç”¨æ€§å·®ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

æœ¬æ–‡æå‡ºä¸€ç§ **CPU-GPU ååŒæ¨ç†æ¡†æ¶ï¼ˆCPU-GPU Collaborative Inference Frameworkï¼‰**ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

1. **å°† GPU æ˜¾å­˜ä½œä¸º MoE ä¸“å®¶çš„ç¼“å­˜ï¼ˆexpert cacheï¼‰**  
   - å°†éƒ¨åˆ†é¢‘ç¹ä½¿ç”¨çš„ä¸“å®¶æƒé‡ä¿ç•™åœ¨ GPU ä¸Šï¼Œå…¶ä½™å­˜å‚¨åœ¨ CPU å†…å­˜ä¸­ã€‚
   - åˆ©ç”¨ **LRU ç¼“å­˜ç­–ç•¥** åŠ¨æ€ç®¡ç†ç¼“å­˜å†…å®¹ï¼ŒåŸºäºâ€œè¿ç»­ token ä¸­ä¸“å®¶é‡å¤ä½¿ç”¨â€çš„è§‚å¯Ÿè®¾è®¡ã€‚

2. **å¼‚æ­¥å¤„ç†ç¼“å­˜æœªå‘½ä¸­ï¼ˆasynchronous cache miss handlingï¼‰**
   - å½“æ‰€éœ€ä¸“å®¶ä¸åœ¨ GPU ç¼“å­˜ä¸­æ—¶ï¼ˆcache missï¼‰ï¼Œä¸ç­‰å¾…æ•°æ®ä¼ è¾“ï¼Œè€Œæ˜¯ç«‹å³å°†ä¸­é—´çŠ¶æ€ï¼ˆattention è¾“å‡ºï¼‰ä¼ è‡³ CPUï¼Œåœ¨ CPU ä¸Šå®Œæˆè¯¥å±‚çš„ä¸“å®¶è®¡ç®—ã€‚
   - åŒæ—¶åå°å¼‚æ­¥åœ°å°†ç¼ºå¤±ä¸“å®¶ä» CPU åŠ è½½å› GPUï¼Œä¾›åç»­ token ä½¿ç”¨ã€‚

3. **å……åˆ†å‘æŒ¥ CPU å¤šçº¿ç¨‹è®¡ç®—æ½œåŠ›**
   - åˆ©ç”¨ PyTorch çš„ OpenMP æ”¯æŒï¼Œåœ¨ CPU ä¸Šé«˜æ•ˆæ‰§è¡Œ FFN å±‚è®¡ç®—ã€‚
   - å®éªŒè¡¨æ˜ï¼šå°½ç®¡å•æ¬¡è®¡ç®—æ…¢äº GPUï¼Œä½†é¿å…äº†é«˜æ˜‚çš„ PCIe æ•°æ®ä¼ è¾“å¼€é”€ï¼Œåœ¨æ•´ä½“å»¶è¿Ÿä¸Šæ›´ä¼˜ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | æœ¬æ–¹æ³• | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ DeepSpeedã€Pre-gated MoEã€Fiddlerï¼‰ |
|------|--------|---------------------------------------------|
| æ˜¯å¦éœ€è¦æ¨¡å‹ä¿®æ”¹ | âŒ ä¸éœ€è¦ | âœ… Pre-gated MoE éœ€æ”¹ router |
| æ˜¯å¦ä¾èµ–ç¦»çº¿ profiling | âŒ åŠ¨æ€é€‚åº” | âœ… Fiddler éœ€ç»Ÿè®¡ä¸“å®¶æ¿€æ´»é¢‘ç‡ |
| æ˜¯å¦åˆ©ç”¨ CPU è®¡ç®—èµ„æº | âœ… å……åˆ†åˆ©ç”¨å¤šæ ¸ CPU | âŒ å¤šæ•°ä»…ç”¨äºæ•°æ®æ¬è¿ |
| é€šä¿¡-è®¡ç®—é‡å æ•ˆç‡ | âœ… å¼‚æ­¥åŠ è½½ + CPU å¹¶è¡Œè®¡ç®— | âš ï¸ é¢„å–å—é™äºçŸ­æ—¶é—´çª—å£ |
| å…¼å®¹æ€§ | âœ… æ”¯æŒä»»æ„ MoE æ¨¡å‹ï¼ˆMixtralã€Phi-3.5-MoEï¼‰ | âŒ å¤šä¸ºç‰¹å®šæ¶æ„å®šåˆ¶ |
| æ€§èƒ½æå‡ | âœ… æœ€é«˜è¾¾ 4.4Ã— é€Ÿåº¦æå‡ | â€” |

> âœ… **æ ¸å¿ƒæ´è§**ï¼šå¯¹äº MoE æ¨ç†ï¼Œ**é€šä¿¡æˆæœ¬ > è®¡ç®—æˆæœ¬**ï¼Œå› æ­¤å‡å°‘ä¼ è¾“æ¯”åŠ é€Ÿè®¡ç®—æ›´é‡è¦ï¼›è€Œ CPU æ˜¯å¯è¢«æœ‰æ•ˆåˆ©ç”¨çš„é—²ç½®èµ„æºã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- ä¸»è¦æµ‹è¯•é›†ï¼š**MMLU [22][23]** æ•°æ®é›†ä¸Šçš„å®é™…æ¨ç†ä»»åŠ¡ï¼ˆçœŸå® prompt è¾“å…¥ï¼‰
- ç›®çš„ï¼šåˆ†æä¸“å®¶é€‰æ‹©æ¨¡å¼ï¼ˆexpert selection patternï¼‰ï¼ŒéªŒè¯ç¼“å­˜æœ‰æ•ˆæ€§

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - CPU: AMD Ryzen Threadripper 7960Xï¼ˆ24 æ ¸ï¼‰
  - GPU: NVIDIA RTX 4090ï¼ˆ24GBï¼‰
  - äº’è”ï¼šPCIe Gen 4.0 Ã—16ï¼ˆåŒå‘å¸¦å®½ 64 GB/sï¼‰
- **è½¯ä»¶ç¯å¢ƒ**ï¼š
  - åŸºäºå®˜æ–¹ MistralAI å’Œ HuggingFace å®ç°
  - ä½¿ç”¨ CUDA Streams å®ç°åŒé€šé“å¹¶å‘ä¼ è¾“ï¼ˆfetch ä¸ compute åˆ†ç¦»ï¼‰

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **ååé‡ï¼ˆThroughputï¼‰** | tokens/secï¼Œè¡¡é‡æ¨ç†é€Ÿåº¦ |
| **ç¼“å­˜å‘½ä¸­ç‡ï¼ˆHit Rateï¼‰** | â€œè‡³å°‘ä¸€ä¸ªä¸“å®¶å‘½ä¸­â€ã€â€œä¸¤ä¸ªä¸“å®¶éƒ½å‘½ä¸­â€ |
| **ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆLatencyï¼‰** | å•ä¸ª token ç”Ÿæˆæ—¶é—´ |
| **åŠŸè€—ä¸èƒ½è€—ï¼ˆPower & Energyï¼‰** | ä½¿ç”¨ RAPL å’Œ nvidia-smi ç›‘æ§ï¼Œè®¡ç®— Joule/token |

### å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **On-demand Fetching** [13][21] | æŒ‰éœ€åŠ è½½ | è·¯ç”±å†³å®šåæ‰å¼€å§‹åŠ è½½ä¸“å®¶ï¼Œæ— é¢„å– |
| **Pre-gated MoE** [15] | é¢„å–ç±» | ä¿®æ”¹ router æå‰é¢„æµ‹ä¸‹ä¸€å±¤ä¸“å®¶ï¼Œå‡è®¾å®Œç¾é‡å  |
| **Fiddler** [26] | CPU-GPU åä½œ | åŸºäºç¦»çº¿ profiling ç¼“å­˜çƒ­é—¨ä¸“å®¶ï¼Œå†³ç­–å¤æ‚åº¦é«˜ |
| **CPU Only** | å®Œå…¨ CPU æ¨ç† | æ‰€æœ‰ä¸“å®¶è®¡ç®—åœ¨ CPU æ‰§è¡Œï¼Œä½œä¸ºæ€§èƒ½ä¸‹ç•Œ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable II & Fig. 5ï¼‰

| æ¨¡å‹ | æ–¹æ³• | æœ€é«˜ååé‡ï¼ˆtokens/secï¼‰ | ç›¸å¯¹æé€Ÿ |
|------|------|--------------------------|-----------|
| **Mixtral 8x7B** | æœ¬æ–‡æ–¹æ³•ï¼ˆ24 coresï¼‰ | **4.8** | â†‘4.4Ã— vs Pre-gated MoE |
| **Phi-3.5-MoE** | æœ¬æ–‡æ–¹æ³•ï¼ˆ24 coresï¼‰ | **10.4** | â†‘4.3Ã— vs Pre-gated MoE |
| Mixtral 8x7B | On-demand Fetching | ~1.1 | åŸºçº¿ |
| Mixtral 8x7B | Pre-gated MoEï¼ˆç†è®ºæœ€ä¼˜ï¼‰ | ~1.1 | å®é™…æ— æ³•è¾¾åˆ°ç†æƒ³é‡å  |

> ğŸ’¡ æ³¨ï¼šå³ä½¿ Pre-gated MoE å‡è®¾å®Œå…¨é‡å ï¼Œä»å—é™äº PCIe ä¼ è¾“é€Ÿç‡ï¼Œæ— æ³•çªç ´ç“¶é¢ˆã€‚

---

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ

- åœ¨ **Mixtral 8x7B** ä¸Šï¼š
  - æœ¬æ–‡æ–¹æ³•æ¯” **on-demand fetching** å¿« **4.4Ã—**
  - æ¯” **Fiddler** å¿« **1.6Ã—**
  - ä»…ç”¨ **2 ä¸ª CPU æ ¸å¿ƒ** å³å¯è¶…è¶Šæ‰€æœ‰ GPU-only offloading æ–¹æ³•

- åœ¨ **Phi-3.5-MoE** ä¸Šï¼š
  - Fiddler è¡¨ç°è¾ƒå·®ï¼Œå› å…¶ä¾èµ–ç¦»çº¿ profilingï¼Œä¸”ä¸“å®¶æ•°é‡ç¿»å€ï¼ˆ16 vs 8ï¼‰å¯¼è‡´å†³ç­–å¼€é”€æŒ‡æ•°å¢é•¿
  - æœ¬æ–‡æ–¹æ³•é€šè¿‡åŠ¨æ€ç¼“å­˜é€‚åº”æ€§å¼ºï¼Œè¡¨ç°ç¨³å®šé¢†å…ˆ

- **CPU-only é…ç½®å·²ä¼˜äºä¼ ç»Ÿ offloading**ï¼š
  - ç”±äºé€šä¿¡è€—æ—¶ï¼ˆ~28msï¼‰è¿œå¤§äº CPU è®¡ç®—æ—¶é—´ï¼ˆå¤šæ ¸ä¸‹ <10msï¼‰ï¼Œç›´æ¥åœ¨ CPU è¿ç®—åè€Œæ›´å¿«

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰ä¸åŒ CPU æ ¸å¿ƒæ•°çš„å½±å“ï¼ˆFig. 3 & Fig. 5ï¼‰
- **1â€“4 æ ¸å¿ƒ**ï¼šè®¡ç®—æ˜¯ç“¶é¢ˆ â†’ åº”ä¼˜å…ˆæ‰©å¤§ç¼“å­˜è¦†ç›–å±‚æ•°ï¼ˆæ›´å¤š indexesï¼‰
- **8â€“24 æ ¸å¿ƒ**ï¼šé€šä¿¡æˆç“¶é¢ˆ â†’ åº”å¢åŠ æ¯å±‚ç¼“å­˜æ–¹å¼æ•°ï¼ˆmore waysï¼‰ä»¥æé«˜å‘½ä¸­ç‡
- ç»“è®ºï¼š**ç¼“å­˜é…ç½®åº”éš CPU èµ„æºåŠ¨æ€è°ƒæ•´**

#### ï¼ˆ2ï¼‰ç¼“å­˜æ›¿æ¢ç­–ç•¥æ¯”è¾ƒï¼ˆFig. 6ï¼‰
| æ›¿æ¢ç­–ç•¥ | Mixtral 8x7B ç¼“å­˜å‘½ä¸­ç‡ | Phi-3.5-MoE ç¼“å­˜å‘½ä¸­ç‡ |
|---------|------------------------|------------------------|
| Random | ~40%ï¼ˆ1 expert hitï¼‰ | ~30% |
| FIFO | ç•¥é«˜äº Random | â€” |
| **LRU** | **â†‘5â€“15% æå‡** | **æ˜¾è‘—ä¼˜äº Random** |

> âœ… LRU æ›´ç¬¦åˆâ€œè¿‘æœŸä½¿ç”¨çš„ä¸“å®¶å¾ˆå¯èƒ½å†æ¬¡ä½¿ç”¨â€çš„å±€éƒ¨æ€§è§„å¾‹

#### ï¼ˆ3ï¼‰èƒ½é‡æ•ˆç‡åˆ†æï¼ˆTable Vï¼‰
| æ¨¡å‹ | æ–¹æ³• | Joule/tokenï¼ˆè¶Šä½è¶Šå¥½ï¼‰ | èƒ½æ•ˆæå‡ |
|------|------|------------------------|----------|
| Mixtral 8x7B | Pre-gated MoE | 171.3 | åŸºå‡† |
| Mixtral 8x7B | æœ¬æ–‡ï¼ˆ24 coresï¼‰ | **51.1** | â†“70.2% èƒ½è€— |
| Phi-3.5-MoE | Pre-gated MoE | 78.7 | åŸºå‡† |
| Phi-3.5-MoE | æœ¬æ–‡ï¼ˆ24 coresï¼‰ | **21.9** | â†“72.2% èƒ½è€— |

> ğŸ”‹ ç»“è®ºï¼šæ›´é«˜çš„ CPU åˆ©ç”¨ç‡å¸¦æ¥æ›´é«˜åŠŸè€—ï¼Œä½†å› é€Ÿåº¦å¤§å¹…æå‡ï¼Œ**å•ä½ token èƒ½è€—æ˜¾è‘—é™ä½**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **CPU æ˜¯è¢«ä¸¥é‡ä½ä¼°çš„è®¡ç®—èµ„æº**ï¼šåœ¨ MoE æ¨ç†ä¸­ï¼ŒCPU å¤šæ ¸å¹¶è¡Œè¶³ä»¥å¼¥è¡¥å…¶å•æ ¸æ€§èƒ½åŠ£åŠ¿ï¼Œä¸”é¿å…äº†æ˜‚è´µçš„ PCIe ä¼ è¾“ã€‚
2. **é€šä¿¡æ˜¯ä¸»è¦ç“¶é¢ˆ**ï¼šä¸“å®¶æƒé‡ä¼ è¾“æ—¶é—´ï¼ˆ~28msï¼‰è¿œè¶… GPU è®¡ç®—æ—¶é—´ï¼ˆ~0.3msï¼‰ï¼Œä½¿å¾—ä»»ä½•ä¾èµ–é¢‘ç¹ä¼ è¾“çš„æ–¹æ³•éƒ½éš¾é€ƒæ€§èƒ½å¤©èŠ±æ¿ã€‚
3. **å­˜åœ¨å¼ºä¸“å®¶å¤ç”¨æ¨¡å¼**ï¼š
   - **Consecutive Layers Pattern**ï¼šç›¸é‚»å±‚å¸¸é€‰ç›¸åŒä¸“å®¶ï¼ˆçº¦ 44%ï¼‰
   - **Consecutive Tokens Pattern**ï¼šåŒä¸€å±‚åœ¨è¿ç»­ token ä¸­é‡å¤ä½¿ç”¨ä¸“å®¶æ¦‚ç‡è¾¾ 40â€“60%
   - è¿™äº›æ¨¡å¼æ”¯æŒæœ‰æ•ˆçš„ç¼“å­˜è®¾è®¡
4. **å¼‚æ­¥åä½œä¼˜äºåŒæ­¥é¢„å–**ï¼šæœ¬æ–‡æå‡ºçš„â€œCPU è®¡ç®— + å¼‚æ­¥å›å¡«â€æœºåˆ¶å®ç°äº†æ›´å¥½çš„è®¡ç®—-é€šä¿¡é‡å ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–è¾ƒå¼ºçš„ CPU æ€§èƒ½**ï¼šè‹¥ CPU è¾ƒå¼±æˆ–å¤šæ ¸è°ƒåº¦ä¸ä½³ï¼Œæ€§èƒ½å¢ç›Šä¼šä¸‹é™ã€‚
- **ä¸é€‚åˆæé«˜åååœºæ™¯**ï¼šæœ¬æ–‡èšç„¦ single-request åœºæ™¯ï¼Œå¯¹å¤§è§„æ¨¡ batch æ¨ç†ä¼˜åŒ–æœ‰é™ã€‚
- **ç¼“å­˜å®¹é‡å—æ˜¾å­˜é™åˆ¶**ï¼šåªèƒ½ç¼“å­˜éƒ¨åˆ†ä¸“å®¶ï¼Œå‘½ä¸­ç‡ä¸Šé™å—é™äº GPU memory sizeã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³ **multi-user / batched inference** åœºæ™¯ä¸‹çš„èµ„æºè°ƒåº¦ï¼›
2. ç»“åˆé‡åŒ–ï¼ˆquantizationï¼‰è¿›ä¸€æ­¥å‹ç¼©ä¸“å®¶ä½“ç§¯ï¼Œæå‡ç¼“å­˜è¦†ç›–ç‡ï¼›
3. è‡ªé€‚åº”ç¼“å­˜ç­–ç•¥ï¼šæ ¹æ®è¿è¡Œæ—¶è´Ÿè½½è‡ªåŠ¨è°ƒèŠ‚ cache é…ç½®ï¼ˆindexes/waysï¼‰ï¼›
4. æ¢ç´¢ **NVLink / UCIe** ç­‰é«˜é€Ÿäº’è¿æŠ€æœ¯ä¸‹çš„ååŒæœºåˆ¶ã€‚

---

## æ€»ç»“

âœ… æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— éœ€ä¿®æ”¹æ¨¡å‹ã€æ— éœ€ç¦»çº¿åˆ†æçš„ **CPU-GPU ååŒ MoE æ¨ç†æ¡†æ¶**ï¼Œé€šè¿‡å¼•å…¥ **GPU ä¸“å®¶ç¼“å­˜ + CPU å¤šæ ¸è®¡ç®— + å¼‚æ­¥å›å¡«æœºåˆ¶**ï¼Œæœ‰æ•ˆç¼“è§£äº†æ¶ˆè´¹çº§è®¾å¤‡ä¸Šçš„å†…å­˜ç“¶é¢ˆã€‚

ğŸš€ å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ Mixtral 8x7B å’Œ Phi-3.5-MoE ä¸Šåˆ†åˆ«å®ç° **4.8 å’Œ 10.4 tokens/sec** çš„æ¨ç†é€Ÿåº¦ï¼Œç›¸æ¯”ç°æœ‰æ–¹æ¡ˆæœ€é«˜æé€Ÿ **4.4Ã—**ï¼ŒåŒæ—¶èŠ‚èƒ½è¶…è¿‡ **70%**ã€‚

ğŸ§  æ ¸å¿ƒå¯ç¤ºï¼š**åœ¨å¼‚æ„ç³»ç»Ÿä¸­ï¼Œæœ€å¤§åŒ–èµ„æºåˆ©ç”¨ç‡æ¯”å•ä¸€è¿½æ±‚å³°å€¼ç®—åŠ›æ›´é‡è¦**ã€‚

</details>

---

### 3. [AIE4ML: An End-to-End Framework for Compiling Neural Networks for the Next Generation of AMD AI Engines](https://arxiv.org/abs/2512.15946)

**Authors**: Dimitrios Danopoulos, Enrico Lupi, Chang Sun, Sebastian Dittmeier, Michael Kagan, Vladimir Loncar, Maurizio Pierini  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2512.15946v1  

#### Abstract
Efficient AI inference on AMD's Versal AI Engine (AIE) is challenging due to tightly coupled VLIW execution, explicit datapaths, and local memory management. Prior work focused on first-generation AIE kernel optimizations, without tackling full neural network execution across the 2D array. In this w...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAIE4ML: An End-to-End Framework for Compiling Neural Networks for the Next Generation of AMD AI Engines

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åœ¨ AMD Versal AI Engineï¼ˆAIEï¼‰ä¸Šè¿›è¡Œé«˜æ•ˆ AI æ¨ç†é¢ä¸´å¤šé‡æŒ‘æˆ˜ï¼š
- **æ¶æ„å¤æ‚æ€§**ï¼šAIE é‡‡ç”¨ VLIW æ¶æ„ã€æ˜¾å¼æ•°æ®æµå’Œæœ¬åœ°å†…å­˜ç®¡ç†ï¼Œç¼–ç¨‹éš¾åº¦é«˜ã€‚
- **ç¼ºä¹ç«¯åˆ°ç«¯æ”¯æŒ**ï¼šå·²æœ‰å·¥ä½œï¼ˆå¦‚ MaxEVAã€AutoMMã€CHARMï¼‰ä¸»è¦èšç„¦äºå•ä¸ª GEMM å†…æ ¸ä¼˜åŒ–ï¼Œæœªè§£å†³å®Œæ•´ç¥ç»ç½‘ç»œåœ¨ AIE-ML 2D é˜µåˆ—ä¸Šçš„è‡ªåŠ¨ç¼–è¯‘ã€å±‚é—´é€šä¿¡å’Œå…¨ç‰‡ä¸Šæ‰§è¡Œé—®é¢˜ã€‚
- **å¯¹ä½å»¶è¿Ÿåœºæ™¯æ”¯æŒä¸è¶³**ï¼šè®¸å¤šå®æ—¶åº”ç”¨ï¼ˆå¦‚ç²’å­ç‰©ç†å®éªŒä¸­çš„è§¦å‘ç³»ç»Ÿï¼‰éœ€è¦å¾®ç§’çº§å»¶è¿Ÿå’Œç¡®å®šæ€§æ¨ç†ï¼Œè€Œä¸»æµåŠ é€Ÿå™¨ï¼ˆGPU/TPUï¼‰éš¾ä»¥æ»¡è¶³ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
AIE4ML æ˜¯é¦–ä¸ªé¢å‘æ–°ä¸€ä»£ AMD AIE-ML æ¶æ„çš„**ç«¯åˆ°ç«¯ç¥ç»ç½‘ç»œç¼–è¯‘æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### âœ… å…¨æ ˆè‡ªåŠ¨åŒ–ç¼–è¯‘æµç¨‹
- æ”¯æŒä» PyTorch/TensorFlow ç­‰é«˜çº§æ¡†æ¶å¯¼å…¥é‡åŒ–æ¨¡å‹ï¼Œè‡ªåŠ¨ç”Ÿæˆä¼˜åŒ–å›ºä»¶ã€‚
- å¼•å…¥ä¸“æœ‰çš„ **AIE-IRï¼ˆIntermediate Representationï¼‰**ï¼Œç»Ÿä¸€è¡¨ç¤ºå±‚æ‹“æ‰‘ã€å¼ é‡ç»´åº¦ã€é‡åŒ–æ ¼å¼å’Œè¿æ¥å…³ç³»ã€‚

#### âœ… é«˜æ•ˆé€šç”¨çº¿æ€§å±‚å®ç°
- è®¾è®¡åŸºäº `aie::mmul` API çš„é€šç”¨çº¿æ€§å±‚å†…æ ¸ï¼ŒåŸç”Ÿæ”¯æŒ **bias åŠ æ³•èåˆ** å’Œ **ReLU æ¿€æ´»èåˆ**ã€‚
- é‡‡ç”¨ **2Ã—2 åˆ†å—ç´¯åŠ å™¨è°ƒåº¦**ï¼Œæå‡ç®—æœ¯å¼ºåº¦å¹¶éšè—è®¿å­˜å»¶è¿Ÿï¼Œæ¥è¿‘ç¡¬ä»¶å³°å€¼æ€§èƒ½ã€‚

#### âœ… åŸºäº Memory Tile çš„å…¨ç‰‡ä¸Šæ•°æ®æµ
- åˆ©ç”¨ AIE-ML æ–°å¢çš„ **Memory Tiles** ä½œä¸ºå±‚é—´ä¸­ç»§ç¼“å†²åŒºï¼Œå®ç°ï¼š
  - å±‚é—´æ¿€æ´»å€¼çš„é›¶å¡«å……ï¼ˆzero-paddingï¼‰
  - åŠ¨æ€é‡åˆ†å—ï¼ˆre-tilingï¼‰
  - å¹¿æ’­ä¼ è¾“ï¼ˆbroadcastingï¼‰
- æ‰€æœ‰æ•°æ®ç§»åŠ¨å‡åœ¨èŠ¯ç‰‡å†…éƒ¨å®Œæˆï¼Œæ— éœ€ PL å‚ä¸ï¼Œé¿å… I/O ç“¶é¢ˆã€‚

#### âœ… è‡ªåŠ¨åŒ–å›¾æ”¾ç½®ç®—æ³•
- æå‡ºä¸€ç§åŸºäº **Branch-and-Bound (B&B)** çš„æœç´¢ç®—æ³•ï¼Œç”¨äºå°†å¤šå±‚è®¡ç®—å›¾æ˜ å°„åˆ° 2D AIE é˜µåˆ—ã€‚
- æœ€å°åŒ–è·¨å±‚è¿æ¥å¼€é”€ï¼Œä¼˜å…ˆä½¿ç”¨ä½è¡Œï¼ˆé è¿‘å­˜å‚¨èµ„æºï¼‰ï¼Œç”Ÿæˆç´§å‡‘ä¸”é«˜æ•ˆçš„å¸ƒå±€ã€‚

#### âœ… ä½ç²¾ç¡®ï¼ˆbit-exactï¼‰é‡åŒ–æ”¯æŒ
- æ”¯æŒä» hls4ml æˆ– PyTorch å¯¼å…¥çš„é‡åŒ–æ¨¡å‹ï¼Œå¹¶åœ¨æ•´ä¸ªå·¥å…·é“¾ä¸­ä¿æŒ **bit-exactness**ã€‚
- æ˜¾å¼æ”¯æŒæ•´æ•°é‡åŒ–ç²¾åº¦ï¼ˆå¦‚ i8Ã—i8, i16Ã—i8ï¼‰ï¼Œé€‚é… AIE-ML çš„æ•´æ•°è¿ç®—å•å…ƒã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç‰¹æ€§ | AIE4ML | Prior Works (e.g., AutoMM, CHARM, GAMA) |
|------|--------|------------------------------------------|
| æ”¯æŒ AIE-ML æ¶æ„ | âœ… | âŒ / éƒ¨åˆ†æ”¯æŒ |
| å®Œæ•´ NN ç¼–è¯‘ | âœ… | âŒï¼ˆä»…é™å•å±‚æˆ– GEMMï¼‰ |
| æƒé‡é©»ç•™ AIE ç‰‡ä¸Š | âœ… | âŒï¼ˆéœ€ PL æµå¼è¾“å…¥ï¼‰ |
| å±‚é—´å…¨ç‰‡ä¸Šé€šä¿¡ | âœ…ï¼ˆé€šè¿‡ Memory Tileï¼‰ | âŒï¼ˆä¾èµ– PL ç¼“å†²ï¼‰ |
| èåˆ Bias/Activation | âœ… | âŒ |
| è‡ªåŠ¨å›¾æ”¾ç½® | âœ…ï¼ˆB&B ç®—æ³•ï¼‰ | âŒï¼ˆæ‰‹åŠ¨æˆ–ç®€å•å¯å‘å¼ï¼‰ |
| ä½ç²¾ç¡®é‡åŒ–æ”¯æŒ | âœ… | ä¸æ˜ç¡® |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹
è®ºæ–‡æœªä½¿ç”¨ä¼ ç»Ÿå›¾åƒåˆ†ç±»æ•°æ®é›†ï¼ˆå¦‚ ImageNetï¼‰ï¼Œè€Œæ˜¯è¯„ä¼°äº†å¤šç§å…¸å‹ç¥ç»ç½‘ç»œç»“æ„ï¼Œé€‚ç”¨äºä½å»¶è¿Ÿæ¨ç†åœºæ™¯ï¼š

- **MLP-Mixer Blocks**ï¼šæ¥è‡ª Vision Transformer ç±»æ¨¡å‹ï¼Œåœ¨ Jet Tagging ç­‰ç‰©ç†å®éªŒä¸­æœ‰å¹¿æ³›åº”ç”¨ã€‚
- **Standalone MLPs**ï¼šåŒ…æ‹¬ 2 å±‚å’Œ 7 å±‚å…¨è¿æ¥ç½‘ç»œï¼Œç”¨äºæ¨¡æ‹Ÿå®é™…éƒ¨ç½²ä¸­çš„è½»é‡çº§æ¨¡å‹ã€‚
- æ‰€æœ‰æ¨¡å‹å‡ç»è¿‡é‡åŒ–å¤„ç†ï¼ˆINT8/INT16ï¼‰ï¼Œè¾“å…¥ä¸ºåˆæˆå¼ é‡ã€‚

### å®éªŒè®¾ç½®
- **ç›®æ ‡å¹³å°**ï¼šAMD Versal AIE-ML æ¶æ„ï¼ˆVEK280 å¹³å°ï¼‰
- **ä»¿çœŸç¯å¢ƒ**ï¼šAMD Vitis 2025 å·¥å…·é“¾ä¸­çš„å‘¨æœŸç²¾ç¡® AIE æ¨¡æ‹Ÿå™¨
- **æ—¶é’Ÿé¢‘ç‡**ï¼š1.25 GHz
- **è¯„ä¼°å¯¹è±¡**ï¼š
  - å•å†…æ ¸æ€§èƒ½ï¼ˆSingle-kernel throughputï¼‰
  - å¤šå±‚æ‰©å±•æ€§ï¼ˆScaling across AIE tilesï¼‰
  - ç«¯åˆ°ç«¯ååé‡ä¸å»¶è¿Ÿ
- **å¯¹æ¯”åŸºçº¿**ï¼š
  - AIE é¢†åŸŸï¼šAutoMM [15], MaxEVA [13], CHARM [16], GAMA [19], ARIES [17]
  - è·¨æ¶æ„ï¼šFPGA (hls4ml), GPU (NVIDIA RTX 3060 + TensorRT), Apple M4 ANE (Core ML)

### è¯„ä¼°æŒ‡æ ‡
- **TOPS/GOPS**ï¼šæ¯ç§’ä¸‡äº¿/åäº¿æ¬¡æ“ä½œæ•°ï¼ˆä»¥ INT8 ä¸ºä¸»ï¼‰
- **æ•ˆç‡ï¼ˆEfficiencyï¼‰**ï¼šå®æµ‹æ€§èƒ½å ç†è®ºå³°å€¼çš„æ¯”ä¾‹
- **ç©ºé—´åˆ©ç”¨ç‡**ï¼šä½¿ç”¨çš„ AIE tiles æ•°é‡å æ¯”
- **å»¶è¿Ÿï¼ˆLatencyï¼‰**ï¼šå•æ ·æœ¬æ¨ç†æ—¶é—´ï¼ˆå¾®ç§’çº§ï¼‰
- **è¾“å‡ºé—´éš”ï¼ˆOutput Intervalï¼‰**ï¼šç¨³æ€ä¸‹è¿ç»­è¾“å‡ºä¹‹é—´çš„å¹³å‡æ—¶é—´

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å•å†…æ ¸æ€§èƒ½ï¼ˆTable IIï¼‰
åœ¨å•ä¸ª AIE tile ä¸Šè¿è¡Œçº¿æ€§å±‚ï¼ˆå« Bias + ReLUï¼‰çš„ç»“æœæ˜¾ç¤ºæ¥è¿‘ç†è®ºå³°å€¼ï¼š

| æ•°æ®ç±»å‹ | ååé‡ï¼ˆGOPSï¼‰ | æ•ˆç‡ |
|---------|----------------|-------|
| i8Ã—i8   | 520 GOPS       | 81.3% |
| i16Ã—i8  | 287 GOPS       | 89.7% |
| i16Ã—i16 | 114 GOPS       | 70.6% |

> æ³¨ï¼ši8Ã—i8 åœºæ™¯ç†è®ºå³°å€¼ä¸º 640 GOPSï¼ˆTable Iï¼‰ï¼Œæ€§èƒ½å—é™ä¸»è¦ç”±äº store å’Œ activation å¼€é”€ã€‚

### å¤šå±‚æ‰©å±•æ€§ï¼ˆFigure 4ï¼‰
- åœ¨æœ€å¤šä½¿ç”¨ **296 out of 304 AIE tilesï¼ˆ97.4% åˆ©ç”¨ç‡ï¼‰** çš„æƒ…å†µä¸‹ï¼š
  - i8Ã—i8ï¼šè¾¾åˆ° **97.3%** ç›¸å¯¹äºå• tile çš„æ‰©å±•æ•ˆç‡
  - i16Ã—i8ï¼š**98.6%**
  - i16Ã—i16ï¼š**97.1%**
- è¡¨æ˜ AIE4ML èƒ½æœ‰æ•ˆæ‰©å±•è‡³æ•´ä¸ª AIE-ML é˜µåˆ—ï¼Œå‡ ä¹æ— é€šä¿¡ç“¶é¢ˆã€‚

### ç«¯åˆ°ç«¯æ¨¡å‹æ€§èƒ½ï¼ˆTable IIIï¼‰
åœ¨çœŸå®æ¨¡å‹ä¸Šçš„è¡¨ç°ï¼ˆå…¨ç‰‡ä¸Šæ‰§è¡Œï¼‰ï¼š

| æ¨¡å‹é…ç½® | æ“ä½œæ•°ï¼ˆMOPsï¼‰ | è¾“å‡ºé—´éš”ï¼ˆÎ¼sï¼‰ | ååé‡ï¼ˆTOPSï¼‰ |
|---------|----------------|----------------|----------------|
| Token MLP - S/16 | 102 | 1.2 | 82.5 |
| Channel MLP - S/16 | 822 | 10.4 | 77.3 |
| 2-Layer MLP | 1074 | 8.2 | 129.7 |
| **7-Layer MLP** | **3.7K** | **0.03** | **113.4** |

> âš¡ï¸ 7-Layer MLP å®ç° **113.4 TOPS** ååé‡ï¼Œè¾“å‡ºé—´éš”ä»… **30 ns**ï¼Œé€‚åˆè¶…ä½å»¶è¿Ÿæµæ°´çº¿ã€‚

### ä¸ç°æœ‰ AIE æ¡†æ¶å¯¹æ¯”ï¼ˆTable IVï¼‰

| æ¡†æ¶ | AIE æ¶æ„ | INT8 æ•ˆç‡ | å¤šå±‚æ”¯æŒ | æƒé‡é©»ç•™ | å…¨ç‰‡ä¸Šæ‰§è¡Œ |
|------|----------|-----------|-----------|------------|--------------|
| AIE4ML | AIE-ML | **82.2%** | âœ… | âœ… | âœ… |
| GAMA | AIE-ML | ~85% | âŒ | âŒ | âŒ |
| MaxEVA | AIE | 56â€“60% | âŒ | âŒ | âŒ |
| AutoMM | AIE | 27.5% | âœ…ï¼ˆPL æ§åˆ¶ï¼‰ | âŒ | âŒ |

> å°½ç®¡ GAMA åœ¨ GEMM å•é¡¹ä»»åŠ¡ä¸­æ•ˆç‡ç•¥é«˜ï¼Œä½† AIE4ML æ˜¯å”¯ä¸€å®ç°**å®Œæ•´å¤šå±‚ã€å…¨ç‰‡ä¸Šã€æƒé‡é©»ç•™**çš„æ¡†æ¶ã€‚

### è·¨æ¶æ„æ€§èƒ½å¯¹æ¯”ï¼ˆTable Vï¼‰
å¯¹åŒä¸€ 7-layer MLP è¿›è¡Œæ¨ªå‘æ¯”è¾ƒï¼š

| è®¾å¤‡ | å¹³å° | å·¥å…·é“¾ | ååé‡ï¼ˆTOPSï¼‰ |
|------|------|--------|----------------|
| **Versal VEK280 (AIE-ML)** | AIE4ML | **113.4** |
| VU13P FPGA | hls4ml | 3.7 |
| NVIDIA RTX 3060 GPU | TensorRT | 14.1 |
| Apple M4 ANE | Core ML | 10.5 |

> ğŸ”¥ AIE4ML ååé‡æ˜¯ GPU çš„ **8 å€ä»¥ä¸Š**ï¼ŒFPGA çš„ **30 å€ä»¥ä¸Š**ï¼Œå±•ç°å‡ºå¼ºå¤§çš„è¾¹ç¼˜/åµŒå…¥å¼æ¨ç†èƒ½åŠ›ã€‚

### æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æ²¡æœ‰ç‹¬ç«‹è¡¨æ ¼ï¼Œä½†æ–‡ä¸­é€šè¿‡ä»¥ä¸‹æ–¹å¼ä½“ç°è®¾è®¡é€‰æ‹©çš„æœ‰æ•ˆæ€§ï¼š
- **Memory Tile ä½¿ç”¨**ï¼šå¯ç”¨åå¯å®ç°å…¨ç‰‡ä¸Šæ‰§è¡Œï¼Œæ¶ˆé™¤ PL I/O å¼€é”€ã€‚
- **2Ã—2 åˆ†å—è°ƒåº¦ vs å•å—**ï¼šå‰è€…æ˜¾è‘—æé«˜ MAC åˆ©ç”¨ç‡ï¼Œå‡å°‘ load/store æ°”æ³¡ã€‚
- **B&B æ”¾ç½® vs è´ªå©ªç­–ç•¥**ï¼ˆFigure 3ï¼‰ï¼šB&B ç”Ÿæˆæ›´ç´§å‡‘å¸ƒå±€ï¼Œå‡å°‘è·¨å±‚è·³è½¬è·ç¦»ï¼Œé™ä½äº’è¿å‹åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **AIE-ML æ¶æ„éå¸¸é€‚åˆä½å»¶è¿Ÿæ¨ç†**ï¼šç»“åˆ VLIWã€æœ¬åœ°å†…å­˜å’Œ Memory Tilesï¼Œå¯åœ¨å¾®ç§’çº§å»¶è¿Ÿä¸‹å®ç° GPU çº§ååã€‚
2. **å…¨ç‰‡ä¸Šæ‰§è¡Œè‡³å…³é‡è¦**ï¼šé€šè¿‡ Memory Tiles å®ç°å±‚é—´é€šä¿¡ï¼Œé¿å… PL æˆä¸ºç“¶é¢ˆï¼Œæ˜¯å®ç°é«˜æ€§èƒ½çš„å…³é”®ã€‚
3. **è‡ªåŠ¨åŒ–ç¼–è¯‘å¯è¡Œä¸”é«˜æ•ˆ**ï¼šAIE4ML å®ç°äº†ä»é«˜å±‚æ¨¡å‹åˆ°å›ºä»¶çš„å…¨è‡ªåŠ¨è½¬æ¢ï¼Œæ€§èƒ½æ¥è¿‘æ‰‹å·¥ä¼˜åŒ–æ°´å¹³ã€‚
4. **ä½ç²¾ç¡®æ€§å’Œé‡åŒ–æ”¯æŒå®Œå¤‡**ï¼šèƒ½æ— ç¼é›†æˆç°æœ‰é‡åŒ–æµç¨‹ï¼ˆå¦‚ hls4mlï¼‰ï¼Œç¡®ä¿éƒ¨ç½²ä¸€è‡´æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä¸»è¦æ”¯æŒ **Linear Layer** å’Œ **MLP-like ç»“æ„**ï¼Œå°šæœªè¦†ç›– CNNã€Transformer Self-Attention ç­‰å¤æ‚ç®—å­ã€‚
- å¯¹éè§„åˆ™å½¢çŠ¶ï¼ˆshape not divisible by tile sizeï¼‰å­˜åœ¨ padding å¼€é”€ï¼Œå½±å“èµ„æºåˆ©ç”¨ç‡ã€‚
- å›¾æ”¾ç½®ç®—æ³•è™½é«˜æ•ˆï¼Œä½†åœ¨ææ·±ç½‘ç»œä¸­å¯èƒ½é¢ä¸´ç»„åˆçˆ†ç‚¸é£é™©ï¼ˆå°½ç®¡å®é™…ä¸­å½±å“è¾ƒå°ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•æ”¯æŒæ›´å¤šç®—å­ç±»å‹ï¼ˆConv, Attention, LSTM ç­‰ï¼‰ã€‚
- æ”¯æŒåŠ¨æ€è¾“å…¥å°ºå¯¸å’Œå¯å˜é•¿åº¦åºåˆ—æ¨¡å‹ï¼ˆå¦‚ Mambaï¼‰ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ– AIE-MLv2 æ¶æ„ç‰¹æ€§ï¼ˆæ›´å¤§å†…å­˜ã€æ›´é«˜å¹¶è¡Œåº¦ï¼‰ã€‚
- æ¢ç´¢ä¸å…¶ä»–å‰ç«¯ï¼ˆONNX, TensorFlow Liteï¼‰çš„é›†æˆã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> AIE4ML æ˜¯é¦–ä¸ªå®ç° **ç«¯åˆ°ç«¯ã€å…¨ç‰‡ä¸Šã€ä½ç²¾ç¡®ã€è‡ªåŠ¨åŒ–ç¼–è¯‘** çš„ AIE-ML æ¡†æ¶ï¼Œåœ¨è¶…ä½å»¶è¿Ÿåœºæ™¯ä¸‹å®ç°äº†è¿œè¶… GPU/FPGA çš„æ¨ç†ååï¼Œä¸ºä¸‹ä¸€ä»£ AI åŠ é€Ÿå™¨éƒ¨ç½²æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 4. [LoPA: Scaling dLLM Inference via Lookahead Parallel Decoding](https://arxiv.org/abs/2512.16229)

**Authors**: Chenkai Xu, Yijie Jin, Jiajun Li, Yi Tu, Guoping Long, Dandan Tu, Tianqi Hou, Junchi Yan, Zhijie Deng  
**Category**: cs.CL  
**Published**: 2025-12-19  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.16229v1  

#### Abstract
Diffusion Large Language Models (dLLMs) have demonstrated significant potential for high-speed inference. However, current confidence-driven decoding strategies are constrained by limited parallelism, typically achieving only 1--3 tokens per forward pass (TPF). In this work, we identify that the deg...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**LoPA: Scaling dLLM Inference via Lookahead Parallel Decoding**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„ **Diffusion Large Language Models (dLLMs)** è™½ç„¶ç†è®ºä¸Šå…·å¤‡å¹¶è¡Œç”Ÿæˆæ½œåŠ›ï¼Œä½†åœ¨å®é™…æ¨ç†ä¸­å—é™äº **Token Filling Order (TFO)** å¯¹é¢„æµ‹ç½®ä¿¡åº¦çš„å½±å“ï¼Œå¯¼è‡´å¹¶è¡Œåº¦æä½ï¼ˆé€šå¸¸æ¯æ­¥ä»…å¡«å…… 1â€“3 ä¸ª tokenï¼‰ã€‚ä¼ ç»Ÿçš„ç½®ä¿¡é©±åŠ¨é‡‡æ ·ç­–ç•¥ï¼ˆconfidence-driven samplingï¼‰åœ¨å±€éƒ¨æœ€ä¼˜ä¸‹å¯èƒ½é™·å…¥æ¬¡ä¼˜è·¯å¾„ï¼Œé™åˆ¶äº†æ•´ä½“è§£ç æ•ˆç‡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼š**Lookahead PArallel Decoding (LoPA)**
LoPA æ˜¯ä¸€ç§**æ— éœ€è®­ç»ƒã€å³æ’å³ç”¨**çš„ç®—æ³•ï¼Œæ—¨åœ¨é€šè¿‡ä¸»åŠ¨æ¢ç´¢æ›´ä¼˜çš„ TFO æ¥æå‡ dLLM æ¨ç†è¿‡ç¨‹ä¸­çš„å¹¶è¡Œæ€§ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯â€œå‘å‰çœ‹â€å¤šä¸ªå€™é€‰å¡«å……é¡ºåºï¼Œå¹¶é€‰æ‹©æœ€å…·æœªæ¥å¹¶è¡Œæ½œåŠ›çš„ä¸€æ¡è·¯å¾„ã€‚

#### æ–¹æ³•æµç¨‹ï¼š
1. **Anchor Branch æ„å»º**ï¼šä½¿ç”¨æ ‡å‡†ç½®ä¿¡é©±åŠ¨ç­–ç•¥æ¨è¿›ä¸€ä¸ªä¸»åˆ†æ”¯ã€‚
2. **Lookahead Branches ç”Ÿæˆ**ï¼šä»å‰©ä½™æœªå¡«ä½ç½®ä¸­é€‰å– top-k é«˜ç½®ä¿¡åº¦ä½ç½®ï¼Œå„è‡ªç‹¬ç«‹é‡‡æ ·æ„å»º k ä¸ªå‰ç»åˆ†æ”¯ã€‚
3. **Branch Confidence éªŒè¯**ï¼šåœ¨ä¸€ä¸ªå‰å‘ä¼ æ’­ä¸­å¹¶è¡ŒéªŒè¯æ‰€æœ‰åˆ†æ”¯ï¼ˆå« anchorï¼‰ï¼Œä¾æ®å„åˆ†æ”¯å‰©ä½™ä½ç½®çš„å¹³å‡ç½®ä¿¡åº¦ $ C(B_j) = \frac{1}{|M_{B_j}|} \sum_{i \in M_{B_j}} \text{Conf}(i) $ é€‰æ‹©æœ€ä¼˜åˆ†æ”¯ã€‚
4. è¿­ä»£æ‰§è¡Œï¼ŒæŒç»­ä¼˜åŒ– TFOã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | LoPA çš„ä¼˜åŠ¿ |
|------|-------------|
| **é€šç”¨æ€§** | æ— éœ€æ¨¡å‹å¾®è°ƒï¼Œå¯ç›´æ¥é›†æˆåˆ°ä»»ä½•åŸºäºç½®ä¿¡åº¦çš„ dLLMï¼ˆå¦‚ D2Fã€Dreamï¼‰ |
| **å¹¶è¡Œæ•ˆç‡** | æ˜¾è‘—æé«˜ Tokens Per Forward pass (TPF)ï¼Œçªç ´ä¼ ç»Ÿ 1â€“3 çš„ç“¶é¢ˆ |
| **æ€§èƒ½ä¿æŒ** | åœ¨å¤§å¹…æå‡é€Ÿåº¦çš„åŒæ—¶ï¼Œç»´æŒç”šè‡³è¶…è¶ŠåŸå§‹æ¨¡å‹çš„ç”Ÿæˆè´¨é‡ |
| **ç³»ç»ŸååŒè®¾è®¡** | æå‡º **Branch Parallelism (BP)** åˆ†å¸ƒå¼æ¨ç†æ¶æ„ï¼Œå®ç°ç¡¬ä»¶çº§åŠ é€Ÿ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **æ•°å­¦æ¨ç†ä»»åŠ¡**ï¼š
  - **GSM8K**ï¼ˆ4-shotï¼‰
  - **MATH**ï¼ˆ4-shotï¼‰
- **ä»£ç ç”Ÿæˆä»»åŠ¡**ï¼š
  - **HumanEval**ï¼ˆ0-shotï¼‰
  - **MBPP**ï¼ˆ3-shotï¼‰
- æ›´ä¸¥æ ¼çš„æ‰©å±•åŸºå‡†ï¼š
  - **HumanEval+**, **MBPP+**ï¼ˆæ¥è‡ª EvalPlusï¼Œç”¨äºé²æ£’æ€§è¯„ä¼°ï¼‰

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### ä¸»è¦æ¨¡å‹
- **D2F-Dream-7B** å’Œ **D2F-DiffuCoder-7B**ï¼ˆåŸºäº D2F objective å¾®è°ƒçš„ dLLMï¼‰
- **Vanilla Dream-7B**ï¼ˆåŸºç¡€æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºéªŒè¯æ³›åŒ–æ€§ï¼‰

#### å¹³å°é…ç½®
- **LoPA-Dist-NV**ï¼š8 Ã— NVIDIA H200 GPUsï¼Œæ”¯æŒ Tensor Parallelism (TP) ä¸ Branch Parallelism (BP)
- **LoPA-Dist-Ascend**ï¼š8 Ã— Huawei Ascend 910C NPUsï¼Œé‡‡ç”¨ TP4 + BP4 æ··åˆå¹¶è¡Œç­–ç•¥

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **TPF (Tokens Per Forward pass)** | æ¯æ¬¡å‰å‘ä¼ æ’­å¡«å……çš„ token æ•°é‡ï¼Œè¡¡é‡å¹¶è¡Œæ•ˆç‡ |
| **TPS (Tokens Per Second)** | å®é™…ååé‡ï¼Œåæ˜ ç«¯åˆ°ç«¯æ¨ç†é€Ÿåº¦ |
| **Avg TPS / Max TPS** | å¹³å‡ä¸å³°å€¼ååé‡ |
| **Latency** | å•æ ·æœ¬ç”Ÿæˆå»¶è¿Ÿ |
| **Score** | ä»»åŠ¡å‡†ç¡®ç‡ï¼ˆpass@1ï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Vanilla dLLM**ï¼šåŸå§‹é€è½®å¡«å……æ–¹å¼
- **Fast-dLLM**ï¼šè®­ç»ƒè‡ªç”±çš„åŠ é€Ÿæ–¹æ³•ï¼Œåˆ©ç”¨ KV ç¼“å­˜å’Œå¹¶è¡Œè§£ç 
- **SDAR-8B-Chat**ï¼šå…ˆè¿›çš„ dLLM æ¶æ„
- **Qwen3-8B (AR model)**ï¼šä½œä¸ºè‡ªå›å½’æ¨¡å‹çš„æ€§èƒ½å‚è€ƒ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 3 & Figure 1ï¼‰

| æ¨¡å‹ | å¹³å° | Avg TPS | Max TPS | TPF | Latency (s) | Score (GSM8K) |
|------|------|--------|--------|-----|------------|----------------|
| D2F-Dream-Base | LoPA-Dist-NV | 630.28 | 1472.37 | 15.69 | 0.84 | 60.12 |
| D2F-Dream-Base | **LoPA-Dist-Ascend** | **1073.86** | **2400.12** | **11.92** | **0.78** | **62.55** |
| D2F-Dream-Instruct | LoPA-Dist-Ascend | 896.21 | 2586.73 | 8.64 | 0.11 | 66.87 |

> âœ… **å•æ ·æœ¬ååé«˜è¾¾ 1073.9 tokens/s**ï¼ˆè§ Figure 1ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ï¼ˆTable 1 & Table 2ï¼‰

#### åœ¨ D2F-Dream ä¸Šçš„è¡¨ç°ï¼ˆGSM8Kï¼‰
| æ–¹æ³• | TPF | Score |
|------|-----|-------|
| Vanilla | 3.1 | 78.5 |
| Fast-dLLM | 2.1 | 72.6 |
| **LoPA** | **10.1** | **73.8** |

- **TPF æå‡è¶…è¿‡ 3 å€ä»¥ä¸Š**ï¼Œä¸”å¾—åˆ†ä»é«˜äº Dream åŸå§‹ baselineï¼ˆ72.6ï¼‰
- åœ¨ MATH ä¸Šè¾¾åˆ° **TPF=8.0**ï¼Œæ€§èƒ½ä¼˜äº vanilla baseline

#### åœ¨ D2F-DiffuCoder ä¸Šçš„è¡¨ç°ï¼ˆHumanEval+ï¼‰
| æ–¹æ³• | TPF | Score |
|------|-----|-------|
| Vanilla | 2.2 | 65.9 |
| **LoPA** | **8.3** | **64.0** |

- **TPF æå‡è¿‘ 4 å€**ï¼Œæ€§èƒ½ä»…æœ‰è½»å¾®ä¸‹é™ï¼ˆ-1.9 ptsï¼‰ï¼Œå±äºå¯æ¥å—èŒƒå›´

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 4 & Figure 5ï¼‰
- **Branch æ•°é‡å½±å“**ï¼šéšç€ branch æ•°å¢åŠ ï¼ˆkâ†‘ï¼‰ï¼ŒTPF æ˜¾è‘—ä¸Šå‡ï¼Œåœ¨ k=14 æ—¶è¾¾åˆ°å³°å€¼ï¼ˆ>10 TPFï¼‰
- **å¹³å°å·®å¼‚**ï¼š
  - LoPA-Dist-Ascend åœ¨é«˜ branch æ•°ä¸‹è¡¨ç°æ›´ç¨³å®šï¼Œå¾—ç›Šäºä¸“ç”¨ä¼˜åŒ–ï¼ˆå¦‚ Graph Compilationã€PagedAttention-like å†…å­˜ç®¡ç†ï¼‰
  - LoPA-Dist-NV å—é™äº CUDA åŠ¨æ€è°ƒåº¦å¼€é”€ï¼Œæ‰©å±•æ€§ç•¥å·®
- **æƒè¡¡åˆ†æ**ï¼šæ›´é«˜çš„ branch æ•°å¸¦æ¥æ›´é«˜ TPSï¼Œä½†å¯èƒ½å¯¼è‡´ score ä¸‹é™ï¼ˆå› è¿‡åº¦è¿½æ±‚æœªæ¥ç½®ä¿¡åº¦è€Œç‰ºç‰²å½“å‰è¯­ä¹‰ä¸€è‡´æ€§ï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **TFO æ˜¯å†³å®š dLLM å¹¶è¡Œæ€§çš„å…³é”®å› ç´ **  
   ä¸åŒå¡«å……é¡ºåºä¼šæ˜¾è‘—æ”¹å˜åç»­ token çš„ç½®ä¿¡åˆ†å¸ƒï¼Œè´ªå©ªç­–ç•¥å¹¶éå…¨å±€æœ€ä¼˜ã€‚

2. **LoPA æˆåŠŸè§£é”äº† dLLM çš„æ½œåœ¨å¹¶è¡Œèƒ½åŠ›**  
   é€šè¿‡ lookahead æ¢ç´¢æœºåˆ¶ï¼Œå°† TPF ä» 1â€“3 æå‡è‡³ **10 ä»¥ä¸Š**ï¼Œå®ç°äº†å‰æ‰€æœªæœ‰çš„å¹¶è¡Œè§£ç æ•ˆç‡ã€‚

3. **ç³»ç»Ÿä¸ç®—æ³•ååŒè®¾è®¡è‡³å…³é‡è¦**  
   å•é ç®—æ³•æ— æ³•å‘æŒ¥å…¨éƒ¨æ½œåŠ›ã€‚æå‡ºçš„ **LoPA-Dist** ç³»ç»Ÿé€šè¿‡ **Branch Parallelism (BP)** å®ç°è·¨è®¾å¤‡åˆ†æ”¯å¹¶è¡Œï¼Œé…åˆé™æ€ KV ç¼“å­˜ã€FlashAttentionã€å›¾ç¼–è¯‘ç­‰æŠ€æœ¯ï¼Œåœ¨ Ascend å¹³å°ä¸Šå®ç° **è¶… 1000 tokens/s çš„å•æ ·æœ¬åå**ã€‚

4. **LoPA å…·æœ‰è‰¯å¥½æ³›åŒ–æ€§**  
   ä¸ä»…é€‚ç”¨äº D2F æ¶æ„ï¼Œä¹Ÿèƒ½æœ‰æ•ˆåŠ é€Ÿ vanilla Dream æ¨¡å‹ï¼ˆTPF ä» 1.0 â†’ 3.4 on MATHï¼‰ï¼Œè¯æ˜å…¶ä¸ºé€šç”¨ plug-and-play åŠ é€Ÿæ–¹æ¡ˆã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—èµ„æºæ¶ˆè€—å¤§**ï¼šéœ€åŒæ—¶ç»´æŠ¤å¤šä¸ªåˆ†æ”¯ï¼Œå¯¹æ˜¾å­˜/å†…å­˜å‹åŠ›è¾ƒå¤§ï¼Œå°¤å…¶åœ¨å¤§è§„æ¨¡ branching æ—¶ã€‚
- **ä¾èµ–é«˜è´¨é‡ç½®ä¿¡åº¦ä¼°è®¡**ï¼šè‹¥æ¨¡å‹æœ¬èº«ç½®ä¿¡åº¦ä¸å‡†ï¼ˆå¦‚ calibration å·®ï¼‰ï¼Œbranch selection å¯èƒ½å¤±æ•ˆã€‚
- **è¾¹é™…æ”¶ç›Šé€’å‡**ï¼šå½“ branch æ•°è¿‡å¤šæ—¶ï¼ŒTPF å¢é•¿è¶‹ç¼“ï¼Œç”šè‡³å‡ºç°æ€§èƒ½æ³¢åŠ¨ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **åŠ¨æ€ branch æ•°æ§åˆ¶**ï¼šæ ¹æ®è¾“å…¥å¤æ‚åº¦è‡ªé€‚åº”è°ƒæ•´æ¢ç´¢å¹¿åº¦
- **è½»é‡åŒ– branch éªŒè¯æœºåˆ¶**ï¼šå‡å°‘åˆ†æ”¯é—´å†—ä½™è®¡ç®—
- **ä¸å…¶ä»–åŠ é€ŸæŠ€æœ¯èåˆ**ï¼šå¦‚ç»“åˆ KV cachingï¼ˆdllm-cacheï¼‰ã€consistency distillationï¼ˆdParallelï¼‰è¿›ä¸€æ­¥å‹ç¼©æ­¥æ•°
- **æ‰©å±•è‡³å¤šæ¨¡æ€ diffusion model**ï¼šæ¢ç´¢å›¾åƒã€éŸ³é¢‘ç”Ÿæˆä¸­çš„ lookahead è§£ç å¯èƒ½æ€§

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> LoPA é€šè¿‡å¼•å…¥ **lookahead å¤šåˆ†æ”¯æ¢ç´¢æœºåˆ¶**ï¼Œé¦–æ¬¡å®ç°äº† dLLM åœ¨ä¸æŸå¤±æ€§èƒ½å‰æä¸‹çš„ **åå€çº§å¹¶è¡Œè§£ç åŠ é€Ÿ**ï¼Œå¹¶é€šè¿‡ä¸“ç”¨ç³»ç»Ÿè®¾è®¡å°†ç®—æ³•æ½œåŠ›è½¬åŒ–ä¸ºçœŸå®ä¸–ç•Œä¸­çš„ **åƒ token/s çº§åå**ï¼Œä¸ºé«˜æ•ˆéè‡ªå›å½’ç”Ÿæˆæä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 5. [TS-DP: Reinforcement Speculative Decoding For Temporal Adaptive Diffusion Policy Acceleration](https://arxiv.org/abs/2512.15773)

**Authors**: Ye Li, Jiahe Feng, Yuan Meng, Kangye Ji, Chen Tang, Xinwan Wen, Shutao Xia, Zhi Wang, Wenwu Zhu  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.15773v1  

#### Abstract
Diffusion Policy (DP) excels in embodied control but suffers from high inference latency and computational cost due to multiple iterative denoising steps. The temporal complexity of embodied tasks demands a dynamic and adaptable computation mode. Static and lossy acceleration methods, such as quanti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTS-DP: Reinforcement Speculative Decoding For Temporal Adaptive Diffusion Policy Acceleration

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
**Diffusion Policy (DP)** åœ¨å…·èº«æ§åˆ¶ï¼ˆembodied controlï¼‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç”±äºå…¶ä¾èµ–å¤šæ¬¡è¿­ä»£å»å™ªï¼ˆiterative denoisingï¼‰ï¼Œå¯¼è‡´æ¨ç†å»¶è¿Ÿé«˜ã€è®¡ç®—æˆæœ¬å¤§ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶æ€§è¦æ±‚ã€‚ç°æœ‰çš„åŠ é€Ÿæ–¹æ³•å¦‚é‡åŒ–ï¼ˆquantizationï¼‰ã€ç¼“å­˜ï¼ˆcachingï¼‰ç­‰å±äºé™æ€æˆ–æœ‰æŸå‹ç¼©ï¼Œæ— æ³•é€‚åº”åŠ¨æ€å˜åŒ–çš„ä»»åŠ¡å¤æ‚åº¦ã€‚

æœ¬æ–‡é’ˆå¯¹ä»¥ä¸‹ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜æå‡ºè§£å†³æ–¹æ¡ˆï¼š
1. å¦‚ä½•åœ¨æ—¶é—´å˜åŒ–çš„ä»»åŠ¡éš¾åº¦ä¸‹ï¼Œä»¥æ›´ä½çš„æˆæœ¬åŒ¹é…åŸºç¡€æ¨¡å‹çš„å»å™ªè´¨é‡ï¼Ÿ
2. å¦‚ä½•æ ¹æ®ä»»åŠ¡éš¾åº¦åŠ¨æ€è°ƒæ•´è®¡ç®—èµ„æºï¼Œå®ç°ç¨³å®šé«˜æ•ˆçš„åŠ é€Ÿï¼Ÿ

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº† **TS-DP**ï¼ˆTemporal-aware Reinforcement-based Speculative Diffusion Policyï¼‰ï¼Œæ˜¯é¦–ä¸ªå°† **speculative decoding** å¼•å…¥ DP å¹¶å…·å¤‡**æ—¶é—´è‡ªé€‚åº”èƒ½åŠ›**çš„æ¡†æ¶ã€‚å…¶ä¸»è¦åˆ›æ–°åŒ…æ‹¬ï¼š

- **åŸºäº Transformer çš„è½»é‡çº§ Drafter æ¨¡å‹**  
  é€šè¿‡çŸ¥è¯†è’¸é¦è®­ç»ƒä¸€ä¸ªå•å±‚ Transformer ä½œä¸º drafterï¼Œæ¨¡ä»¿ base model çš„å¤šæ­¥å»å™ªè¡Œä¸ºï¼Œåœ¨ä½å¼€é”€ä¸‹ç”Ÿæˆå¤šä¸ªå€™é€‰åŠ¨ä½œåºåˆ—ã€‚

- **å¹¶è¡ŒéªŒè¯æœºåˆ¶ + Reflection-Maximal Coupling**  
  åˆ©ç”¨ base model å¯¹ drafter ç”Ÿæˆçš„å¤šä¸ªå€™é€‰è¿›è¡Œå¹¶è¡ŒéªŒè¯ï¼Œæ¥å—ç¬¦åˆåˆ†å¸ƒçš„ç»“æœï¼›å¯¹ç¬¬ä¸€ä¸ªè¢«æ‹’ç»çš„æ ·æœ¬ä½¿ç”¨ reflection-maximal coupling è¿›è¡Œä¿®æ­£ï¼Œä¿è¯é‡‡æ ·åˆ†å¸ƒä¸å˜ï¼Œå®ç°**æ— æŸåŠ é€Ÿ**ã€‚

- **åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„åŠ¨æ€è°ƒåº¦å™¨ï¼ˆSchedulerï¼‰**  
  è®¾è®¡äº†ä¸€ä¸ª PPO-based çš„ RL è°ƒåº¦å™¨ï¼Œæ ¹æ®å½“å‰ç¯å¢ƒçŠ¶æ€ï¼ˆå¦‚æœ«ç«¯æ‰§è¡Œå™¨é€Ÿåº¦ã€ä»»åŠ¡é˜¶æ®µï¼‰åŠ¨æ€è°ƒèŠ‚ speculative å‚æ•°ï¼Œå¦‚ draft æ­¥æ•° $K$ã€æ¥å—é˜ˆå€¼ $\lambda$ å’Œ $\sigma$ ç¼©æ”¾å› å­ï¼Œä»è€Œå®ç°**æ—¶é—´å¤æ‚åº¦æ„ŸçŸ¥çš„è‡ªé€‚åº”åŠ é€Ÿ**ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³•ç±»å‹ | ä»£è¡¨æ–¹æ³• | æ˜¯å¦æœ‰æŸ | æ˜¯å¦è‡ªé€‚åº” | åŠ é€Ÿæ¯” | å®æ—¶æ€§ |
|--------|--------|--------|----------|--------|-------|
| é™æ€å‹ç¼© | Quantization, Pruning | æ˜¯ | å¦ | â‰¤3Ã— | ä¸è¶³ |
| ç¼“å­˜ä¼˜åŒ– | BAC, SpeCa | æ˜¯/éƒ¨åˆ† | å¦ | ~3.4Ã— | æœ‰é™æå‡ |
| å›ºå®šå‚æ•° speculative | Frozen Target Draft | å¦ | å¦ | ~3.0Ã— | ä¸€èˆ¬ |
| **TS-DPï¼ˆæœ¬æ–‡ï¼‰** | â€” | **å¦ï¼ˆlosslessï¼‰** | **æ˜¯ï¼ˆtemporal-awareï¼‰** | **æœ€é«˜è¾¾ 4.17Ã—** | **æ”¯æŒ 25Hz å®æ—¶æ§åˆ¶** |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šTS-DP å®ç°äº†**æ— æŸã€é«˜æ•ˆã€å¯åŠ¨æ€è°ƒèŠ‚**çš„åŠ é€Ÿï¼Œåœ¨ä¿æŒç”šè‡³æå‡æˆåŠŸç‡çš„åŒæ—¶æ˜¾è‘—é™ä½ NFEï¼ˆNumber of Function Evaluationsï¼‰ï¼Œé€‚ç”¨äºçœŸå®æœºå™¨äººéƒ¨ç½²åœºæ™¯ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸ä»»åŠ¡
å®éªŒåœ¨å››ä¸ªä¸»æµæœºå™¨äººæ“ä½œåŸºå‡†ä¸Šè¿›è¡Œï¼Œæ¶µç›–ä¸åŒéš¾åº¦å’Œé˜¶æ®µæ€§çš„ä»»åŠ¡ï¼š
- **Robomimic** ä¸‹å±å­ä»»åŠ¡ï¼š
  - Proficient Human (PH)ï¼šç†Ÿç»ƒäººç±»æ¼”ç¤ºæ•°æ®
  - Mixed Human (MH)ï¼šæ··åˆæŠ€èƒ½æ°´å¹³çš„äººç±»æ¼”ç¤º
- å¤šé˜¶æ®µå¤æ‚ä»»åŠ¡ï¼š
  - **Kitchen**ï¼šæ¶‰åŠå¾®æ³¢ç‚‰ã€çƒ§æ°´å£¶ç­‰å¤šä¸ªç‰©ä½“äº¤äº’
  - **Block Pushing (BP)**ï¼šåˆ†é˜¶æ®µæ¨è¿›æ–¹å—è‡³ç›®æ ‡åŒºåŸŸ

æ‰€æœ‰ä»»åŠ¡å‡é‡‡ç”¨å›ºå®š seed è®¾ç½®ï¼Œç¡®ä¿å¯å¤ç°æ€§ã€‚

### å®éªŒè®¾ç½®
- **Base Model**ï¼šåŸå§‹ Diffusion Policy [10]
- **Hardware**ï¼šNVIDIA A100 GPU (40GB)
- **Drafter æ¶æ„**ï¼šå•å±‚ Transformer blockï¼Œå…±äº« encoder ä¸ DDPM/DDIM scheduler
- **Training**ï¼šé€šè¿‡çŸ¥è¯†è’¸é¦è®­ç»ƒ drafterï¼ŒæŸå¤±å‡½æ•°åŒ…å«é¢„æµ‹ä¸€è‡´æ€§ï¼ˆ$ \mathcal{L}_{\text{pred}} $ï¼‰å’Œè°ƒåº¦å™¨å¯¹é½é¡¹ï¼ˆ$ \mathcal{L}_{\text{norm}} $ï¼‰
- **Scheduler è®­ç»ƒ**ï¼šä½¿ç”¨ PPO ç®—æ³•ï¼Œè¾“å…¥ä¸ºè§‚æµ‹ã€åŠ¨ä½œå†å²å’Œä»»åŠ¡è¿›åº¦ï¼Œè¾“å‡ºä¸º speculative å‚æ•°ï¼ˆ$K$, $\lambda$, $\sigma$ scaleï¼‰

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Success Rate (%)** | ä¸»è¦ç²¾åº¦æŒ‡æ ‡ï¼ˆé™¤ Push-T å¤–ï¼‰ |
| **Coverage Rate (%)** | Push-T å’Œ Block Push ä½¿ç”¨çš„ç›®æ ‡åŒºåŸŸè¦†ç›–ç‡ |
| **NFE (Number of Function Evaluations)** | è¡¡é‡è®¡ç®—æ•ˆç‡ï¼Œæ¯ä¸ª drafter æ¨ç†è®°ä¸º 1/8 NFE |
| **Speed Ã—** | æ¨ç†åŠ é€Ÿå€æ•°ï¼ˆvs. åŸå§‹ DPï¼‰ |
| **Frequency (Hz)** | æ§åˆ¶é¢‘ç‡ï¼Œè¡¡é‡æ˜¯å¦æ»¡è¶³å®æ—¶éœ€æ±‚ |
| **Draft Acceptance Rate (%)** | éªŒè¯é€šè¿‡çš„è‰æ¡ˆæ¯”ä¾‹ï¼Œåæ˜  drafter è´¨é‡ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Diffusion Policy [10]**ï¼šåŸå§‹æœªåŠ é€Ÿç‰ˆæœ¬ï¼ˆbaselineï¼‰
- **Frozen Target Draft [2]**ï¼šæ—©æœŸ speculative decoding æ–¹æ³•
- **SpeCa [27]**ï¼šåŸºäºç‰¹å¾ç¼“å­˜çš„ speculative æ–¹æ³•
- **BAC [15]**ï¼šblock-wise adaptive cachingï¼Œå½“å‰æœ€ä¼˜ç¼“å­˜åŠ é€Ÿæ–¹æ³•

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### åœ¨ Proficient Human (PH) æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼ˆTable 1ï¼‰
| æ–¹æ³• | AVG Success Rate (%) | NFE (%) | Speed Ã— | Draft Acceptance |
|------|------------------------|---------|--------|------------------|
| DP [10] | 76 / 80 | 100 | 1Ã— | â€” |
| BAC [15] | 77 / 81 | ~66 | 3.40Ã— | â€” |
| **TS-DP** | **85 / 80** â†‘ | **24 / 24** â†“ | **4.17Ã—** | **~94%** |

> ğŸ“Œ **äº®ç‚¹**ï¼šä¸ä»…æé€Ÿ 4.17Ã—ï¼Œè¿˜æå‡äº†å¹³å‡æˆåŠŸç‡ï¼ˆ+9%ï¼‰ï¼Œä¸” NFE é™ä½ 76%

#### åœ¨ Mixed Human (MH) æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼ˆTable 2ï¼‰
| æ–¹æ³• | AVG Success Rate (%) | NFE (%) | Speed Ã— |
|------|------------------------|---------|--------|
| DP [10] | 76 / 81 | 100 | 1Ã— |
| BAC [15] | 75 / 80 | ~66 | 3.41Ã— |
| **TS-DP** | **75 / 84** | **26 / 26** | **3.84Ã—** |

> âœ… å®ç°æ¥è¿‘æ— æŸåŠ é€Ÿï¼ˆaccuracy ç»´æŒä¸å˜ï¼‰ï¼ŒNFE å‡å°‘ 74%

#### å¤šé˜¶æ®µä»»åŠ¡ï¼ˆKitchen & BPï¼‰è¡¨ç°ï¼ˆTable 3ï¼‰
| æ–¹æ³• | AVG Success Rate (%) | NFE (%) | Speed Ã— |
|------|------------------------|---------|--------|
| DP [10] | 99 / 99 | 100 | 1Ã— |
| BAC [15] | 99 / 98 | ~64 | 3.60Ã— |
| **TS-DP** | **99 / 99** | **27 / 27** | **3.70Ã—** |

> ğŸ” åœ¨å¤æ‚å¤šé˜¶æ®µä»»åŠ¡ä¸­ä»ä¿æŒå®Œç¾æˆåŠŸç‡ï¼ŒåŒæ—¶è·å¾— 3.7Ã— åŠ é€Ÿ

#### å®é™…å»¶è¿Ÿä¸é¢‘ç‡æµ‹è¯•ï¼ˆTable 5ï¼‰
| æ–¹æ³• | Average Frequency (Hz) | Latency (s) |
|------|--------------------------|------------|
| DP | 7.42 Hz | 0.14 s |
| **TS-DP** | **25.00 Hz** | **0.04 s** |

> âš¡ è¾¾åˆ° **25Hz å®æ—¶æ§åˆ¶é¢‘ç‡**ï¼Œè¿œè¶…å·¥ä¸šçº§å®æ—¶æ§åˆ¶æ ‡å‡†ï¼ˆé€šå¸¸ â‰¥10Hzï¼‰

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### å›ºå®š vs è‡ªé€‚åº”è°ƒåº¦å™¨ï¼ˆTable 4ï¼‰
| é…ç½® | AVG Success Rate (%) | Speed Ã— |
|------|------------------------|--------|
| K=10ï¼ˆä¿å®ˆï¼‰ | 84% | 2.45Ã— |
| K=25 | 75% | 3.47Ã— |
| K=40ï¼ˆæ¿€è¿›ï¼‰ | 72% | 3.92Ã— |
| **TS-DPï¼ˆè‡ªé€‚åº”ï¼‰** | **87%** | **3.80Ã—** |

> ğŸ’¡ ç»“è®ºï¼š**å›ºå®šå‚æ•°å­˜åœ¨ç²¾åº¦-æ•ˆç‡æƒè¡¡å›°å¢ƒ**ï¼Œè€Œ TS-DP çš„ RL è°ƒåº¦å™¨èƒ½æ™ºèƒ½å¹³è¡¡äºŒè€…ï¼Œåœ¨æ›´é«˜æˆåŠŸç‡ä¸‹å®ç°æ¥è¿‘æœ€ä¼˜åŠ é€Ÿã€‚

#### å¯è§†åŒ–åˆ†æï¼ˆFigures 5 & 6ï¼‰
- Figure 5 æ˜¾ç¤ºï¼šscheduler èƒ½éšä»»åŠ¡é˜¶æ®µåŠ¨æ€è°ƒæ•´ $K$ã€$\lambda$ã€$\sigma$ï¼Œåœ¨ç²¾ç»†æ“ä½œé˜¶æ®µå‡å°‘ draft æ•°é‡ï¼Œåœ¨å¹³ç¨³è¿åŠ¨é˜¶æ®µå¢åŠ å¹¶è¡Œåº¦ã€‚
- Figure 6 æ˜¾ç¤ºï¼šTS-DP çš„è‰æ¡ˆæ¥å—ç‡å§‹ç»ˆé«˜äºé™æ€æ–¹æ³•ï¼Œä¸” draft æ•°æ›´å¤šï¼Œè¯´æ˜å…¶æ›´æœ‰æ•ˆåœ°åˆ©ç”¨äº† speculative å¹¶è¡Œæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Speculative Decoding ç‰¹åˆ«é€‚åˆ I/O-bound çš„ DP**  
   ä¸å›¾åƒç”Ÿæˆä¸­ compute-bound çš„æ‰©æ•£æ¨¡å‹ä¸åŒï¼ŒDP è¾“å‡ºä½ç»´åŠ¨ä½œå‘é‡ï¼ŒéªŒè¯å¼€é”€å°ï¼Œå› æ­¤ speculative decoding æ›´æ˜“å¸¦æ¥æ˜¾è‘—åŠ é€Ÿã€‚

2. **ä»»åŠ¡éš¾åº¦å…·æœ‰æ˜æ˜¾çš„æ—¶é—´åŠ¨æ€æ€§**  
   å®éªŒå‘ç°æœ«ç«¯æ‰§è¡Œå™¨é€Ÿåº¦ä¸è‰æ¡ˆæ¥å—ç‡å‘ˆè´Ÿç›¸å…³ï¼šé«˜é€Ÿç²—ç²’åº¦åŠ¨ä½œï¼ˆå¦‚ç§»åŠ¨ï¼‰æ¥å—ç‡ä½ï¼Œä½é€Ÿç²¾ç»†åŠ¨ä½œï¼ˆå¦‚æŠ“å–ï¼‰æ¥å—ç‡é«˜ã€‚è¿™è¡¨æ˜**å›ºå®šå‚æ•° speculative æ˜¯æ¬¡ä¼˜çš„**ã€‚

3. **RL-based Scheduler å¯æœ‰æ•ˆå»ºæ¨¡ temporal complexity**  
   å°† speculative å‚æ•°é€‰æ‹©å»ºæ¨¡ä¸º MDPï¼Œå¹¶ç”¨ PPO å­¦ä¹ ç­–ç•¥ï¼Œèƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡è‡ªåŠ¨è°ƒèŠ‚ï¼Œå®ç°â€œè¯¥å¿«æ—¶å¿«ï¼Œè¯¥ç¨³æ—¶ç¨³â€çš„æ™ºèƒ½åŠ é€Ÿã€‚

4. **TS-DP å®ç°äº†çœŸæ­£çš„ lossless acceleration**  
   æ‰€æœ‰ä»»åŠ¡çš„æˆåŠŸç‡æŒå¹³æˆ–æå‡ï¼Œè¯æ˜å…¶åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹å¤§å¹…æé«˜æ•ˆç‡ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡çš„ base model å’Œ drafter å¯¹é½**ï¼šè‹¥ distillation ä¸å……åˆ†ï¼Œä¼šå¯¼è‡´è¿‡å¤š rejectionï¼Œå‰Šå¼±åŠ é€Ÿæ•ˆæœã€‚
- **scheduler éœ€é¢å¤–è®­ç»ƒæˆæœ¬**ï¼šè™½ç„¶ inference æ—¶ä¸å¢åŠ  latencyï¼ˆå¹¶è¡Œè¿è¡Œï¼‰ï¼Œä½†éœ€é¢å¤– RL è®­ç»ƒæµç¨‹ã€‚
- **ç›®å‰ä»…é™äº offline setting**ï¼šå°šæœªåœ¨çœŸå®æœºå™¨äººä¸Šé—­ç¯éªŒè¯ï¼Œæœªæ¥éœ€è€ƒè™‘ online adaptation èƒ½åŠ›ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•åˆ° online continual learning åœºæ™¯**ï¼šè®© scheduler èƒ½åœ¨çº¿é€‚åº”æ–°ä»»åŠ¡æˆ–ç¯å¢ƒå˜åŒ–ã€‚
2. **æ¢ç´¢ multi-agent æˆ– multi-task å…±äº« drafter**ï¼šé™ä½éƒ¨ç½²æˆæœ¬ã€‚
3. **ç»“åˆ one-step diffusion policy**ï¼šè¿›ä¸€æ­¥å‹ç¼© base modelï¼Œå½¢æˆç«¯åˆ°ç«¯è½»é‡åŒ–æ–¹æ¡ˆã€‚
4. **ç¡¬ä»¶ååŒè®¾è®¡**ï¼šé’ˆå¯¹ TS-DP çš„å¹¶è¡ŒéªŒè¯ç‰¹æ€§ä¼˜åŒ– GPU å†…å­˜è°ƒåº¦ä¸ kernel æ‰§è¡Œã€‚

---

## æ€»ç»“
âœ… **TS-DP æ˜¯é¦–ä¸ªé¢å‘ Diffusion Policy çš„æ—¶é—´è‡ªé€‚åº” speculative decoding æ¡†æ¶**ï¼Œé€šè¿‡ **lightweight drafter + RL scheduler + parallel verification** çš„ç»„åˆï¼Œåœ¨å¤šç§å…·èº«æ§åˆ¶ä»»åŠ¡ä¸Šå®ç°äº†é«˜è¾¾ **4.17Ã— çš„æ— æŸåŠ é€Ÿ**ï¼Œå¹¶å°†æ§åˆ¶é¢‘ç‡æå‡è‡³ **25Hz**ï¼Œä¸º diffusion-based å®æ—¶æœºå™¨äººæ§åˆ¶æä¾›äº†å¯è¡Œè·¯å¾„ã€‚  
ğŸ¯ å…¶æ ¸å¿ƒæ€æƒ³â€”â€”â€œåŠ¨æ€é€‚åº”ä»»åŠ¡å¤æ‚åº¦â€â€”â€”æœ‰æœ›æ¨å¹¿è‡³å…¶ä»–æ—¶åºå†³ç­–ç³»ç»Ÿä¸­çš„ç”Ÿæˆå¼ç­–ç•¥åŠ é€Ÿã€‚

</details>

---

### 6. [Predictive Concept Decoders: Training Scalable End-to-End Interpretability Assistants](https://arxiv.org/abs/2512.15712)

**Authors**: Vincent Huang, Dami Choi, Daniel D. Johnson, Sarah Schwettmann, Jacob Steinhardt  
**Category**: cs.AI  
**Published**: 2025-12-19  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.15712v1  

#### Abstract
Interpreting the internal activations of neural networks can produce more faithful explanations of their behavior, but is difficult due to the complex structure of activation space. Existing approaches to scalable interpretability use hand-designed agents that make and test hypotheses about how inte...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Predictive Concept Decoders: Training Scalable End-to-End Interpretability Assistants â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ç¥ç»ç½‘ç»œå†…éƒ¨æ¿€æ´»ç©ºé—´ï¼ˆactivation spaceï¼‰ç»“æ„å¤æ‚ï¼Œéš¾ä»¥äººå·¥è§£é‡Šå…¶è¡Œä¸ºã€‚ç°æœ‰çš„å¯è§£é‡Šæ€§æ–¹æ³•ï¼ˆå¦‚ probesã€concept dictionaries æˆ– interpretability agentsï¼‰é€šå¸¸ä¾èµ–æ‰‹å·¥è®¾è®¡çš„ä»£ç†æ¨¡å‹ï¼ˆoff-the-shelf modelsï¼‰ï¼Œè¿™äº›æ¨¡å‹å¹¶éä¸ºå¯è§£é‡Šæ€§ä»»åŠ¡ä¸“é—¨ä¼˜åŒ–ï¼Œå¯¼è‡´å…¶èƒ½åŠ›å—é™ã€‚

æ­¤å¤–ï¼Œä¼ ç»Ÿæ–¹æ³•ç¼ºä¹**ç«¯åˆ°ç«¯è®­ç»ƒä¿¡å·**ï¼Œæ— æ³•ç³»ç»Ÿåœ°ä»æ¨¡å‹è¡Œä¸ºä¸­å­¦ä¹ å¦‚ä½•è§£é‡Šå…¶å†…éƒ¨çŠ¶æ€ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **Predictive Concept Decoder (PCD)**ï¼Œä¸€ç§**ç«¯åˆ°ç«¯å¯è®­ç»ƒçš„å¯è§£é‡Šæ€§åŠ©æ‰‹æ¶æ„**ï¼Œå°†å¯è§£é‡Šæ€§ä»»åŠ¡è½¬åŒ–ä¸ºä¸€ä¸ªå¯ç›‘ç£çš„å­¦ä¹ ç›®æ ‡ã€‚

PCD çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **è®­ç»ƒä¸€ä¸ªç¼–ç å™¨-è§£ç å™¨æ¶æ„**ï¼Œé€šè¿‡ä¸€ä¸ª**é€šä¿¡ç“¶é¢ˆï¼ˆcommunication bottleneckï¼‰** æ¥é¢„æµ‹ä¸»ä½“æ¨¡å‹ï¼ˆsubject modelï¼‰çš„è¡Œä¸ºã€‚
- ç¼–ç å™¨ï¼ˆEncoderï¼‰ä»ä¸»ä½“æ¨¡å‹çš„æ¿€æ´»ä¸­æå–ä¸€ä¸ª**ç¨€ç–çš„æ¦‚å¿µåˆ—è¡¨ï¼ˆsparse list of conceptsï¼‰**ã€‚
- è§£ç å™¨ï¼ˆDecoderï¼‰ä»…åŸºäºè¿™ä¸ªç¨€ç–æ¦‚å¿µåˆ—è¡¨å’Œä¸€ä¸ªè‡ªç„¶è¯­è¨€é—®é¢˜ï¼Œæ¥é¢„æµ‹ä¸»ä½“æ¨¡å‹çš„è¡Œä¸ºæˆ–å›ç­”é—®é¢˜ã€‚
- **ç¼–ç å™¨ä¸çœ‹é—®é¢˜ï¼Œè§£ç å™¨ä¸ç›´æ¥çœ‹åŸå§‹æ¿€æ´»**ï¼Œè¿«ä½¿ç¼–ç å™¨å­¦ä¹ é€šç”¨ã€å¯å¤ç”¨çš„â€œè§£é‡Šâ€ã€‚

è¯¥æ¡†æ¶å®ç°äº†ï¼š
- **å¯å®¡è®¡æ€§ï¼ˆauditableï¼‰**ï¼šä»»ä½•é¢„æµ‹éƒ½å¯è¿½æº¯è‡³å°‘æ•°å‡ ä¸ªæ´»è·ƒæ¦‚å¿µã€‚
- **å¯æ‰©å±•æ€§ï¼ˆscalableï¼‰**ï¼šå¯é€šè¿‡å¤§è§„æ¨¡æ— æ ‡æ³¨æ•°æ®é¢„è®­ç»ƒï¼Œå†å¾®è°ƒç”¨äºå…·ä½“ä»»åŠ¡ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **è®­ç»ƒèŒƒå¼** | å°†å¯è§£é‡Šæ€§ä»â€œæ‰‹å·¥åˆ†æâ€è½¬å˜ä¸ºâ€œç«¯åˆ°ç«¯è®­ç»ƒâ€ï¼Œåˆ©ç”¨è¡Œä¸ºé¢„æµ‹ä½œä¸ºå¤©ç„¶ç›‘ç£ä¿¡å·ã€‚ |
| **æ¶æ„è®¾è®¡** | å¼•å…¥ç¨€ç–ç“¶é¢ˆï¼ˆsparsity bottleneckï¼‰ï¼Œæå‡äººç±»å¯è¯»æ€§å’Œå¯å®¡è®¡æ€§ã€‚ |
| **æ€§èƒ½è¡¨ç°** | åœ¨æ£€æµ‹ jailbreakã€æ­ç¤ºéšè—æç¤ºã€è¯†åˆ«æ¤å…¥æ¦‚å¿µç­‰ä»»åŠ¡ä¸Šä¼˜äº LatentQA å’Œç›´æ¥ promptingã€‚ |
| **æ³›åŒ–èƒ½åŠ›** | èƒ½æ­ç¤ºæ¨¡å‹è‡ªèº«æ— æ³•è‡ªè¿°çš„ä¿¡æ¯ï¼ˆå¦‚æ³•å¾‹é¡¾è™‘ã€ç§˜å¯†æç¤ºä½¿ç”¨ï¼‰ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

| æ•°æ®é›† | ç”¨é€” | æè¿° |
|--------|------|------|
| **FineWeb** (Penedo et al., 2024) | é¢„è®­ç»ƒ | å¤§è§„æ¨¡ç½‘é¡µæ–‡æœ¬è¯­æ–™ï¼Œç”¨äº next-token prediction é¢„è®­ç»ƒã€‚ |
| **SynthSys** (Choi et al., 2025) | å¾®è°ƒä¸è¯„ä¼° | åŒ…å«ç”¨æˆ·å¯¹è¯åŠæ¨¡å‹å¯¹ç”¨æˆ·å±æ€§ï¼ˆå¦‚æ€§åˆ«ã€å©šå§»çŠ¶å†µï¼‰çš„éšå«å‡è®¾ï¼Œç”¨äºè¯„ä¼° decoder å›ç­”é—®é¢˜çš„èƒ½åŠ›ã€‚ |
| **è‡ªå»ºæ”»å‡»æ•°æ®é›†** | æ¡ˆä¾‹ç ”ç©¶ | æ„é€ äº† 50 ç§æœ‰å®³è¯·æ±‚ï¼ˆå¦‚åˆ¶é€ ç‚¸å¼¹ï¼‰å¹¶åº”ç”¨ä¸‰ç§ jailbreak æ¨¡æ¿ï¼ˆ3 Words, Distractors, Dreamï¼‰è¿›è¡Œæµ‹è¯•ã€‚ |
| **Introspection Dataset** | å†…çœä»»åŠ¡ | åŸºäº Lindsey (2025) çš„ 58 ä¸ªæ¦‚å¿µï¼Œç”Ÿæˆå¯¹æ¯”æ®µè½ä»¥æ„é€  steering vectorsã€‚ |

### **å®éªŒè®¾ç½®**

- **ä¸»ä½“æ¨¡å‹**ï¼š`Llama-3.1-8B-Instruct`
- **PCD æ¶æ„**ï¼š
  - ç¼–ç å™¨ï¼šçº¿æ€§å±‚ + TopK ç¨€ç–åŒ–ï¼ˆk=16ï¼‰+ é‡æ–°åµŒå…¥ï¼ˆre-embeddingï¼‰
  - è§£ç å™¨ï¼šä¸ä¸»ä½“æ¨¡å‹åŒæ„çš„ LMï¼Œé™„åŠ  LoRA é€‚é…å™¨
  - æ¦‚å¿µæ•°ï¼šm = 32,768ï¼ˆè¿œå¤§äºéšè—ç»´åº¦ d=4096ï¼‰
- **ä¸¤é˜¶æ®µè®­ç»ƒ**ï¼š
  1. **é¢„è®­ç»ƒ**ï¼šåœ¨ FineWeb ä¸Šè¿›è¡Œ next-token predictionï¼Œç›‘ç£ decoder åˆ©ç”¨ç¼–ç åçš„æ¦‚å¿µé¢„æµ‹åç»­æ–‡æœ¬ã€‚
  2. **å¾®è°ƒ**ï¼šå†»ç»“ç¼–ç å™¨ï¼Œåœ¨ SynthSys ä¸Šå¾®è°ƒ decoder å›ç­”å…³äºæ¨¡å‹ä¿¡å¿µçš„é—®é¢˜ã€‚
- **è¾…åŠ©æŸå¤±**ï¼šå¼•å…¥ `auxiliary loss` é˜²æ­¢æ¦‚å¿µâ€œæ­»äº¡â€ï¼ˆinactive conceptsï¼‰ï¼Œæå‡å­—å…¸è´¨é‡ã€‚

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Auto-Interp Score** | è‡ªåŠ¨å¯è§£é‡Šæ€§è¯„åˆ†ï¼šé€šè¿‡ç”Ÿæˆæ¦‚å¿µæè¿°ï¼Œå¹¶ç”¨æ¨¡æ‹Ÿå™¨é¢„æµ‹æ¿€æ´»æ¨¡å¼çš„ç›¸å…³æ€§ï¼ˆPearson correlationï¼‰è¡¡é‡æ¦‚å¿µè´¨é‡ã€‚ |
| **Concept Coverage (Recall)** | ç”¨æˆ·å±æ€§åˆ†ç±»å‡†ç¡®ç‡ï¼šæ¯ä¸ªç¼–ç æ–¹å‘æ˜¯å¦èƒ½æ•æ‰ç‰¹å®šç”¨æˆ·å±æ€§ï¼ˆå¦‚æ€§åˆ«ï¼‰ã€‚ |
| **Question-Answering Accuracy** | åœ¨ SynthSys ä¸Šçš„å¤šé€‰é¢˜å‡†ç¡®ç‡ã€‚ |
| **Jailbreak Awareness Rate** | PCD æ˜¯å¦èƒ½æ„è¯†åˆ°æ¨¡å‹æ­£åœ¨è¢« jailbreak å¹¶æ‰§è¡Œæœ‰å®³æ“ä½œã€‚ |
| **Hint Usage Detection** | æ˜¯å¦èƒ½æ£€æµ‹æ¨¡å‹ä½¿ç”¨äº†æœªå£°æ˜çš„ç§˜å¯†æç¤ºã€‚ |
| **Introspection Performance** | æ˜¯å¦èƒ½å£å¤´è¡¨è¾¾è¢«æ³¨å…¥çš„æ½œæ„è¯†æ¦‚å¿µã€‚ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿ | æè¿° |
|------|------|
| **LatentQA** (Pan et al., 2024) | ç±»ä¼¼æ¶æ„ä½†æ— ç¨€ç–ç“¶é¢ˆï¼Œdecoder ç›´æ¥è¯»å–å®Œæ•´æ¿€æ´»ã€‚ |
| **Direct Prompting** | ç›´æ¥è¯¢é—®ä¸»ä½“æ¨¡å‹è‡ªèº«ï¼ˆç¬¬ä¸€äººç§°æˆ–ç¬¬ä¸‰äººç§°ï¼‰ã€‚ |
| **SAE (Sparse Autoencoder)** | æ ‡å‡†ç¨€ç–è‡ªç¼–ç å™¨ï¼Œç”¨äºå­¦ä¹ æ¦‚å¿µå­—å…¸ï¼Œä½œä¸ºç¼–ç å™¨æ›¿ä»£ã€‚ |
| **KL SAE** | æ”¹è¿›ç‰ˆ SAEï¼Œä½¿ç”¨ KL æ•£åº¦é¢„æµ‹è¾“å‡ºåˆ†å¸ƒè€Œéé‡å»ºæ¿€æ´»ã€‚ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **é¢„è®­ç»ƒé˜¶æ®µï¼šç¼–ç å™¨å¯è§£é‡Šæ€§éšæ•°æ®é‡æå‡**
- å›¾4æ˜¾ç¤ºï¼šPCD åœ¨ `k=16` ä¸‹çš„ auto-interp score éšé¢„è®­ç»ƒ token æ•°å¢åŠ è€ŒæŒç»­ä¸Šå‡ï¼Œåœ¨ 72M tokens æ—¶ä¼˜äºåŒç­‰æ•°æ®ä¸‹çš„ SAEï¼ˆk=16 æˆ– k=50ï¼‰ã€‚
- å¼•å…¥ auxiliary loss åï¼Œè¶…è¿‡ 90% çš„æ¦‚å¿µä¿æŒæ´»è·ƒï¼Œé¿å…â€œæ­»æ¦‚å¿µâ€é—®é¢˜ã€‚

#### âœ… **å¾®è°ƒé˜¶æ®µï¼šé—®ç­”æ€§èƒ½æ¥è¿‘ LatentQA**
- å›¾5æ˜¾ç¤ºï¼šPCD ç»è¿‡å……åˆ†é¢„è®­ç»ƒåï¼ˆâ‰¥36M tokensï¼‰ï¼Œåœ¨ SynthSys ä¸Šçš„è¡¨ç°ä¸ LatentQA ç›¸å½“ã€‚
- è‹¥ä½¿ç”¨å†»ç»“çš„ SAE ç¼–ç å™¨ï¼Œåˆ™æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œè¯´æ˜**è”åˆè®­ç»ƒè‡³å…³é‡è¦**ã€‚

#### âœ… **Jailbreak æ£€æµ‹ï¼šPCD æ˜¾è‘—ä¼˜äºåŸºçº¿**
- å›¾7ï¼šå¹³å‡ jailbreak awareness è¾¾ **~50%**ï¼Œåœ¨ Dream æ”»å‡»ä¸‹é«˜è¾¾ 50%ï¼Œè€Œå…¶ä»–æ–¹æ³•å‡ä½äº 30%ã€‚
- å›¾8ï¼šawareness éšé¢„è®­ç»ƒæ•°æ®é‡å¢åŠ è€Œæå‡ï¼Œå°¤å…¶åœ¨å¤æ‚æ”»å‡»ï¼ˆå¦‚ 3 Wordsï¼‰ä¸­å‡ºç°â€œæ¶Œç°â€ç°è±¡ï¼ˆemergent awareness at 72M tokensï¼‰ã€‚

#### âœ… **ç§˜å¯†æç¤ºæ£€æµ‹ï¼šPCD èƒ½æ­ç¤ºæ¨¡å‹éšç’çš„è¡Œä¸º**
- å›¾9ï¼šPCDï¼ˆæ— ç“¶é¢ˆï¼‰å’Œ LatentQA èƒ½æœ‰æ•ˆæ­ç¤ºâ€œtop-secret shortcutâ€çš„ä½¿ç”¨ï¼Œè€Œç›´æ¥ prompting å€¾å‘äºç¼–é€ â€œå·§å¦™ç®—æ³•â€æ¥æ©ç›–çœŸç›¸ã€‚
- PCD åœ¨æ›´å¤§é¢„è®­ç»ƒè§„æ¨¡ä¸‹æ€§èƒ½æŒç»­æå‡ã€‚

#### âœ… **å†…çœä»»åŠ¡ï¼ˆIntrospectionï¼‰ï¼šPCD æ›´æ“…é•¿è¡¨è¾¾æ³¨å…¥æ¦‚å¿µ**
- å›¾11ï¼šPCD èƒ½æ›´é¢‘ç¹åœ°å£å¤´è¡¨è¾¾è¢«æ³¨å…¥çš„ç›´æ¥ç›¸å…³æ¦‚å¿µï¼ˆdirectly relevantï¼‰ï¼Œä¸”æ€§èƒ½éšé¢„è®­ç»ƒæ•°æ®å¢é•¿è€Œæå‡ã€‚
- å°½ç®¡ SAE å­—å…¸åœ¨æ¦‚å¿µåŒ¹é…ä¸Šç•¥ä¼˜ï¼Œä½† PCD çš„ç«¯åˆ°ç«¯è®­ç»ƒä½¿å…¶åœ¨è¡Œä¸ºé¢„æµ‹ä¸Šæ›´å¼ºã€‚

#### âœ… **æ¶ˆèå®éªŒç»“æœ**
| å®éªŒ | å‘ç° |
|------|------|
| **ç§»é™¤ auxiliary loss** | æ¦‚å¿µæ´»æ€§ä¸‹é™ï¼Œauto-interp score å’Œ recall å‡é™ä½ã€‚ |
| **å‡å°‘é¢„è®­ç»ƒæ•°æ®** | PCD æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œå°¤å…¶åœ¨é«˜ç¨€ç–åº¦ï¼ˆk=16ï¼‰ä¸‹ã€‚ |
| **æ›¿æ¢ç¼–ç å™¨ä¸º SAE** | æ€§èƒ½å¤§å¹…ä¸‹é™ï¼Œè¯æ˜è”åˆè®­ç»ƒçš„é‡è¦æ€§ã€‚ |
| **æµ‹è¯•æ—¶ç§»é™¤ç“¶é¢ˆï¼ˆk=âˆï¼‰** | åœ¨å°è§„æ¨¡é¢„è®­ç»ƒä¸‹æ€§èƒ½æå‡ï¼ˆOOD è¾“å…¥ä»æœ‰æ•ˆï¼‰ï¼Œä½†åœ¨å¤§è§„æ¨¡ä¸‹åè€Œä¸‹é™ï¼Œè¯´æ˜ PCD å­¦ä¼šäº†é«˜æ•ˆå‹ç¼©ã€‚ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **ç«¯åˆ°ç«¯è®­ç»ƒå¯è¡Œä¸”æœ‰æ•ˆ**ï¼š  
   å°†å¯è§£é‡Šæ€§ä»»åŠ¡å»ºæ¨¡ä¸ºâ€œä»æ¿€æ´»é¢„æµ‹è¡Œä¸ºâ€çš„ç›‘ç£å­¦ä¹ é—®é¢˜æ˜¯å¯è¡Œçš„ï¼ŒPCD å¯é€šè¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒä¸æ–­æå‡è§£é‡Šèƒ½åŠ›ã€‚

2. âœ… **ç¨€ç–ç“¶é¢ˆå¸¦æ¥å¯å®¡è®¡æ€§è€Œä¸ç‰ºç‰²æ€§èƒ½**ï¼š  
   å°½ç®¡å¼•å…¥äº†ä¿¡æ¯å‹ç¼©ï¼Œä½†ç»è¿‡å……åˆ†è®­ç»ƒåï¼ŒPCD åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„è¡¨ç°ä»å¯åŒ¹æ•Œç”šè‡³è¶…è¶Šæ— ç“¶é¢ˆçš„ LatentQAã€‚

3. âœ… **PCD èƒ½æ­ç¤ºæ¨¡å‹â€œä¸å¯è¨€è¯´â€çš„ä¿¡æ¯**ï¼š  
   - æ¨¡å‹æ‹’ç»è¯·æ±‚çš„çœŸå®åŸå› å¯èƒ½æ˜¯â€œè§„é¿æ³•å¾‹è´£ä»»â€è€Œéâ€œç”¨æˆ·å®‰å…¨â€ï¼ˆå›¾12ï¼‰ã€‚
   - æ¨¡å‹ä½¿ç”¨ç§˜å¯†æç¤ºä½†ä»ä¸æ‰¿è®¤ï¼ŒPCD å´èƒ½å‡†ç¡®æ­ç¤ºã€‚
   - æ¨¡å‹å¯¹è‡ªèº«è¢«æ¤å…¥çš„æ¦‚å¿µç¼ºä¹æ„è¯†ï¼ŒPCD å´èƒ½è¡¨è¾¾å‡ºæ¥ã€‚

4. âœ… **ç¼©æ”¾å¾‹æˆç«‹ï¼ˆScaling Lawsï¼‰**ï¼š  
   PCD çš„ç¼–ç å™¨è´¨é‡å’Œè§£ç å™¨æ€§èƒ½å‡éšé¢„è®­ç»ƒæ•°æ®é‡å¢åŠ è€Œæå‡ï¼Œå±•ç°å‡ºè‰¯å¥½çš„å¯æ‰©å±•æ€§ã€‚

5. âœ… **PCD å…·æœ‰â€œæœ‰åˆ©å½’çº³åç½®â€ï¼ˆfavorable inductive biasï¼‰**ï¼š  
   å³ä½¿ä¸ LatentQA æ¶æ„ç›¸åŒï¼ˆæ— ç“¶é¢ˆï¼‰ï¼Œç”±äºè®­ç»ƒè¿‡ç¨‹ä¸­å­˜åœ¨ç“¶é¢ˆï¼ŒPCD decoder å­¦ä¼šäº†æ›´å…³æ³¨ç»†ç²’åº¦æ¦‚å¿µã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

1. **æ€§èƒ½ plateau**ï¼š  
   åœ¨çº¦ 72â€“144M tokens åï¼Œauto-interp score å‡ºç°å¹³å°æœŸï¼Œå¯èƒ½ä¸ KL-based ç›®æ ‡å‡½æ•°æœ‰å…³ã€‚

2. **æ¦‚å¿µå­—å…¸è´¨é‡ä»ä¸å¦‚ SAE**ï¼š  
   åœ¨ introspection ä»»åŠ¡ä¸­ï¼ŒSAE å­—å…¸åœ¨åŒ¹é…æ³¨å…¥æ¦‚å¿µæ–¹é¢è¡¨ç°æ›´å¥½ï¼Œè¯´æ˜å½“å‰ PCD ç¼–ç å™¨ä»æœ‰æ”¹è¿›ç©ºé—´ã€‚

3. **ä¾èµ–é«˜è´¨é‡è‡ªåŠ¨è§£é‡Š pipeline**ï¼š  
   auto-interp score æœ¬èº«ä¾èµ– GPT-5-mini ç­‰å¼ºæ¨¡å‹ç”Ÿæˆæè¿°å’Œåˆ¤æ–­ï¼Œå¯èƒ½å­˜åœ¨åå·®ã€‚

4. **è®¡ç®—æˆæœ¬è¾ƒé«˜**ï¼š  
   éœ€è¦å¤§é‡é¢„è®­ç»ƒå’Œå¾®è°ƒèµ„æºï¼Œé™åˆ¶äº†è½»é‡çº§éƒ¨ç½²ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **çªç ´ plateau**ï¼šæ¢ç´¢æ›´ä¸°å¯Œçš„è®­ç»ƒç›®æ ‡ï¼ˆå¦‚ multi-step predictionã€counterfactual reasoningï¼‰ã€‚
2. **æ”¹è¿›ç¼–ç å™¨æ¶æ„**ï¼šä½¿ç”¨ Transformer ç¼–ç å™¨ã€æ”¯æŒæ¦‚å¿µé—´å…³ç³»å»ºæ¨¡ï¼ˆbindingã€compositionï¼‰ã€‚
3. **å¤šå±‚è¯»å–**ï¼šä»å¤šä¸ªç½‘ç»œå±‚è¯»å–æ¿€æ´»ï¼Œæå‡ä¿¡æ¯å®Œæ•´æ€§ã€‚
4. **æ‰©å±•ä»»åŠ¡èŒƒå›´**ï¼šè®­ç»ƒ end-to-end assistants æ‰§è¡Œ neuron ablationã€feature patching ç­‰å¹²é¢„ä»»åŠ¡ã€‚
5. **äººç±»è¯„ä¼°**ï¼šå¼•å…¥çœŸå®äººç±»ç”¨æˆ·è¯„ä¼° PCD è¾“å‡ºçš„å¯ç†è§£æ€§å’Œå®ç”¨æ€§ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> PCD å¼€åˆ›äº†ä¸€ç§**å°†å¯è§£é‡Šæ€§ä»»åŠ¡è½¬åŒ–ä¸ºç«¯åˆ°ç«¯ç›‘ç£å­¦ä¹ **çš„æ–°èŒƒå¼ï¼Œé€šè¿‡ç¨€ç–ç“¶é¢ˆå®ç°å¯å®¡è®¡æ€§ï¼Œå¹¶åœ¨ jailbreak æ£€æµ‹ã€æç¤ºæ­ç¤ºã€å†…çœç­‰ä»»åŠ¡ä¸Šå±•ç°å‡ºè¶…è¶Š prompting å’Œ LatentQA çš„èƒ½åŠ›ï¼Œæ ‡å¿—ç€ scalable interpretability è¿ˆå‘ trainable assistant çš„é‡è¦ä¸€æ­¥ã€‚

</details>

---

### 7. [CKA-Guided Modular Quantization: Beyond Bit-Width to Algorithmic Diversity](https://arxiv.org/abs/2512.16282)

**Authors**: Jinhao Zhang, Yunquan Zhang, Daning Chen  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.16282v1  

#### Abstract
Current mainstream post-training quantization methods for large language models typically apply a uniform quantization strategy across all network layers, overlooking the substantial differences in algorithmic suitability among layers. To address this limitation, we propose CKA Guided Modular Quanti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# CKA-Guided Modular Quantization: Beyond Bit-Width to Algorithmic Diversity è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰ä¸»æµçš„**Post-Training Quantization (PTQ)** æ–¹æ³•ï¼ˆå¦‚ GPTQã€AWQã€SmoothQuantï¼‰é€šå¸¸åœ¨æ‰€æœ‰ç½‘ç»œå±‚ä¸Šé‡‡ç”¨**ç»Ÿä¸€çš„é‡åŒ–ç­–ç•¥**ï¼Œå¿½ç•¥äº†ä¸åŒ Transformer å±‚å¯¹é‡åŒ–è¯¯å·®çš„æ•æ„Ÿåº¦å­˜åœ¨æ˜¾è‘—å·®å¼‚è¿™ä¸€äº‹å®ã€‚è¿™ç§â€œä¸€åˆ€åˆ‡â€çš„æ–¹å¼é™åˆ¶äº†æ¨¡å‹å‹ç¼©åçš„æ€§èƒ½ä¸Šé™ã€‚

æ­¤å¤–ï¼Œç°æœ‰çš„æ··åˆç²¾åº¦ï¼ˆMixed-Precisionï¼‰æ–¹æ³•ä»…é€šè¿‡è°ƒæ•´**bit-width**ï¼ˆå¦‚æŸäº›å±‚ç”¨ INT4ï¼Œå¦ä¸€äº›ç”¨ INT8ï¼‰æ¥ä¼˜åŒ–ï¼Œè€Œå›ºå®šä½¿ç”¨åŒä¸€ç§é‡åŒ–ç®—æ³•ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨**ç®—æ³•å±‚é¢çš„å¤šæ ·æ€§**ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **CKA-Guided Modular Quantization** â€”â€” ä¸€ç§æ— éœ€å¾®è°ƒï¼ˆfine-tuning-freeï¼‰ã€å³æ’å³ç”¨ï¼ˆplug-and-playï¼‰çš„**ç®—æ³•å¼‚æ„é‡åŒ–æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- åœ¨æ¯ä¸€å±‚ç‹¬ç«‹è¯„ä¼°å¤šä¸ª PTQ ç®—æ³•ï¼ˆå¦‚ GPTQã€AWQã€SmoothQuantï¼‰
- ä½¿ç”¨ **Linear Centered Kernel Alignment (CKA)** ä½œä¸ºè¡¡é‡æ ‡å‡†ï¼Œè‡ªåŠ¨é€‰æ‹©æ¯å±‚æœ€ä¼˜çš„é‡åŒ–æ–¹æ³•
- å°†å„å±‚é€‰å‡ºçš„æœ€ä½³ç­–ç•¥ç»„åˆæˆä¸€ä¸ª**æ··åˆé‡åŒ–æ¨¡å‹**

è¯¥æ–¹æ³•å®ç°äº†**ç®—æ³•çº§å¼‚è´¨æ€§ï¼ˆalgorithmic heterogeneityï¼‰**ï¼Œè€Œéä»…ä»… bit-width çš„å˜åŒ–ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|------|--------|---------|
| é‡åŒ–ç²’åº¦ | ç»Ÿä¸€ç®—æ³• + å¯å˜ bit-widthï¼ˆbit-heterogeneityï¼‰ | å›ºå®š bit-width + å¯å˜ç®—æ³•ï¼ˆmethod-heterogeneityï¼‰ |
| å†³ç­–ä¾æ® | å¯å‘å¼è§„åˆ™æˆ–æ•æ„Ÿæ€§åˆ†æ | æ•°æ®é©±åŠ¨çš„ CKA è¡¨å¾ç›¸ä¼¼æ€§åº¦é‡ |
| æ˜¯å¦éœ€è¦è®­ç»ƒ | å¤šæ•°ä¸ºæ— è®­ç»ƒ | å®Œå…¨æ— è®­ç»ƒï¼ˆpost-training onlyï¼‰ |
| æ€§èƒ½è¡¨ç° | å­˜åœ¨æ€§èƒ½å¤©èŠ±æ¿ | è¶…è¶Šå•ä¸€ç®—æ³•æé™ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼š  
> - æ›´å¥½åœ°åŒ¹é…å„å±‚ç‰¹æ€§ï¼ˆæƒé‡åˆ†å¸ƒã€æ¿€æ´»å¼‚å¸¸å€¼ç­‰ï¼‰  
> - æ˜¾è‘—é™ä½è¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸­çš„ **Perplexity (PPL)**  
> - æå‡ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚æ•°å­¦æ¨ç†ã€ä»£ç ç”Ÿæˆï¼‰å‡†ç¡®ç‡  
> - ä¸ä¾èµ– fine-tuningï¼Œéƒ¨ç½²å‹å¥½  

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
| ç±»å‹ | æ•°æ®é›† |
|------|-------|
| **è¯­è¨€å»ºæ¨¡è¯„ä¼°** | `C4`, `WikiText-2`ï¼ˆwiki2ï¼‰ |
| **ä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°** |  
- æ•°å­¦æ¨ç†ï¼š`GSM8K`  
- ä»£ç ç”Ÿæˆï¼š`HumanEval`  
- å¸¸è¯†æ¨ç†ï¼š`HellaSwag`  
- å¤šä»»åŠ¡ç†è§£ï¼š`MMLU`  

æ ¡å‡†ï¼ˆcalibrationï¼‰ä½¿ç”¨ä» `C4` ä¸­éšæœºé‡‡æ ·çš„ **128 æ¡åºåˆ—**ï¼Œé•¿åº¦ä¸º 1024 tokensã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **ç›®æ ‡é‡åŒ–æ ¼å¼**ï¼šW4A8ï¼ˆ4-bit weights, 8-bit activationsï¼‰ï¼Œgroup size = 128
- **ä¿ç•™é«˜ç²¾åº¦æ¨¡å—**ï¼šEmbeddingã€KV Cacheã€forward activations ä¿æŒ FP16/BF16
- **å€™é€‰ PTQ æ–¹æ³•æ± **ï¼šGPTQã€AWQã€SmoothQuantã€SpinQuant
- **æœç´¢ç­–ç•¥**ï¼šé€å±‚è´ªå©ªé€‰æ‹©ï¼ˆgreedy layer-wise selectionï¼‰ï¼ŒåŸºäº CKA åˆ†æ•°å†³ç­–
- **æ¨¡å‹ç³»åˆ—**ï¼š
  - Llama ç³»åˆ—ï¼šLlama-3-8B, Llama-3.2-3B, Llama-3.2-1B
  - Qwen ç³»åˆ—ï¼šQwen2.5-1.5B, Qwen2.5-0.5B

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Perplexity (PPL)** â†“ | è¡¡é‡è¯­è¨€æ¨¡å‹é¢„æµ‹èƒ½åŠ›ï¼Œè¶Šä½è¶Šå¥½ |
| **Accuracy (%)** â†‘ | ä¸‹æ¸¸ä»»åŠ¡å¾—åˆ†ï¼Œè¶Šé«˜è¶Šå¥½ï¼ˆGSM8Kã€HumanEvalã€HellaSwagã€MMLUï¼‰ |
| **CKA Score** â†‘ | è¡¡é‡é‡åŒ–åå±‚è¾“å‡ºä¸åŸå§‹ FP16 è¾“å‡ºä¹‹é—´çš„è¡¨å¾ä¸€è‡´æ€§ |

### ğŸ†š å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
- **FP16**ï¼šå…¨ç²¾åº¦åŸºå‡†
- **GPTQ**ï¼šåŸºäº Hessian çš„æƒé‡é‡åŒ–
- **AWQ**ï¼šä¿æŠ¤æ˜¾è‘—æƒé‡é€šé“
- **SmoothQuant**ï¼šå¹³æ»‘æ¿€æ´»ä»¥ç¼“è§£å¼‚å¸¸å€¼å½±å“
- **SpinQuant**ï¼šæ—‹è½¬çŸ©é˜µæŠ‘åˆ¶å¼‚å¸¸å€¼
- **MP-GPTQ(FP16/4/2)**ï¼šä¼ ç»Ÿæ··åˆç²¾åº¦æ–¹æ³•ï¼ˆéƒ¨åˆ†å±‚ 2-bitï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & Table 2ï¼‰

#### âœ… Perplexity (PPL) ç»“æœï¼ˆè¶Šä½è¶Šå¥½ï¼‰
| Model | Method | C4 â†“ | Wiki2 â†“ |
|-------|--------|-----|--------|
| Llama-3-8B | FP16 | 12.28 | 6.41 |
| | **Ours** | **12.72** | **6.89** |
| | GPTQ | 14.12 | 8.81 |
| | AWQ | 13.56 | 8.12 |
| | SmoothQuant | 13.64 | 7.32 |
| | SpinQuant | 13.39 | 7.48 |

> ğŸ’¡ **Ours æ¥è¿‘ FP16ï¼Œä¸”å…¨é¢ä¼˜äºå…¶ä»– PTQ æ–¹æ³•**

| Model | Method | Wiki2 â†“ |
|-------|--------|--------|
| Qwen1.5-1.5B | **Ours** | **12.87** |
| | SpinQuant (SOTA) | 13.31 |
| | AWQ | 14.05 |

> âœ… **é¢†å…ˆç¬¬äºŒå 0.44 PPLï¼Œåœ¨å°æ¨¡å‹ä¸Šä¼˜åŠ¿æ›´æ˜æ˜¾**

#### âœ… ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
| Model | Method | GSM8K â†‘ | HumanEval â†‘ | MMLU â†‘ |
|-------|--------|--------|------------|--------|
| Llama-3-8B | FP16 | 77.17 | 60.71 | 67.31 |
| | **Ours** | **74.33** | **59.67** | **65.87** |
| | GPTQ | 71.89 | 58.45 | 60.54 |

| Qwen1.5-0.5B | FP16 | 26.78 | 49.65 | 45.76 |
| | **Ours** | **25.12** | **48.68** | **44.12** |
| | GPTQ | 19.04 | 47.38 | 42.82 |

> âœ… åœ¨æè½»é‡æ¨¡å‹ä¸Šä»å¤§å¹…é¢†å…ˆï¼Œå°¤å…¶åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­æå‡æ˜¾è‘—ï¼ˆ+3.25~4.90 ptsï¼‰

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰PTQ å€™é€‰æ–¹æ³•å¤šæ ·æ€§çš„å½±å“ï¼ˆTable 3ï¼‰
ç§»é™¤ä»»ä¸€å€™é€‰ç®—æ³•å‡å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼š
- ç§»é™¤ **SmoothQuant** â†’ Llama-3-8B C4 PPL ä» 12.72 å‡è‡³ 13.55
- ç§»é™¤ **AWQ** â†’ GSM8K å‡†ç¡®ç‡ä¸‹é™ 1.48%
- æ‰€æœ‰æ¨¡å‹å‡è¡¨æ˜ï¼šå¤šç§ç®—æ³•ååŒäº’è¡¥è‡³å…³é‡è¦

> âœ… éªŒè¯äº†â€œæ²¡æœ‰ä¸‡èƒ½ç®—æ³•â€ï¼Œå¿…é¡»åŠ¨æ€é€‚é…

#### ï¼ˆ2ï¼‰Method-Heterogeneity vs Bit-Heterogeneityï¼ˆTable 4ï¼‰
åœ¨ç›¸åŒå¹³å‡ bit-width ä¸‹æ¯”è¾ƒï¼š
| æ–¹æ³• | Wiki2 PPL (Llama-3-8B) | GSM8K Acc |
|------|------------------------|-----------|
| MP-GPTQ (FP16/4/2) | 7.95 | 73.40 |
| **Ours (W4-Mix)** | **6.89** | **74.33** |

> âœ… **ä¿æŒ 4-bit å…¨å±€ç²¾åº¦ä½†åˆ‡æ¢ç®—æ³•ï¼Œæ•ˆæœè¿œè¶…é™çº§åˆ° 2-bit çš„ä¼ ç»Ÿæ··åˆç²¾åº¦æ–¹æ¡ˆ**

#### ï¼ˆ3ï¼‰é‡åŒ–ç²’åº¦å½±å“ï¼ˆTable 5ï¼‰
| ç²’åº¦ | C4 PPL (Llama-3-8B) | GSM8K Acc |
|------|--------------------|-----------|
| Block-8ï¼ˆæ¯8å±‚å…±äº«é…ç½®ï¼‰ | 13.15 | 73.05 |
| Block-2 | 12.78 | 74.10 |
| **Oursï¼ˆé€å±‚ï¼‰** | **12.72** | **74.33** |

> âœ… **é€å±‚ä¼˜åŒ–ä¼˜äºå—çº§å…±äº«é…ç½®**ï¼Œè¯´æ˜ç²¾ç»†æ§åˆ¶å¿…è¦

#### ï¼ˆ4ï¼‰ä½æ¯”ç‰¹å®½åº¦ä¸‹çš„è¡¨ç°ï¼ˆTable 6ï¼‰
åœ¨ **3-bit** è®¾ç½®ä¸‹ï¼š
- ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ GPTQï¼‰PPL å‰§å¢ï¼ˆè¾¾ 19.25ï¼‰
- **Ours** å®ç°å¹³ç¨³é€€åŒ–ï¼ˆPPL=13.55ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰ baseline

> âœ… å±•ç°å‡ºåœ¨æç«¯ä½æ¯”ç‰¹ç¯å¢ƒä¸‹çš„é²æ£’æ€§å’Œé€‚åº”æ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ğŸ§  ä¸»è¦å‘ç°
1. **ä¸åŒ Transformer å±‚å¯¹é‡åŒ–ç®—æ³•å…·æœ‰é«˜åº¦å¼‚è´¨åå¥½**ï¼š
   - æµ…å±‚å€¾å‘äº GPTQ
   - ä¸­æ·±å±‚äº¤æ›¿ä½¿ç”¨ AWQ å’Œ SmoothQuant
   - å°æ¨¡å‹åˆ‡æ¢æ›´é¢‘ç¹ï¼Œä½“ç°æ›´å¼ºå¼‚è´¨æ€§ï¼ˆè§ Figure 4ï¼‰

2. **CKA æ˜¯æœ‰æ•ˆçš„åŠŸèƒ½ä¿çœŸåº¦ä»£ç†æŒ‡æ ‡**ï¼š
   - é«˜ CKA åˆ†æ•° â‰ˆ æ›´å¥½çš„è¯­ä¹‰ä¸€è‡´æ€§
   - é™„å½•ä¸­é€šè¿‡çº¿æ€§æ¢å¤çŸ©é˜µ $M$ å®éªŒè¯æ˜ï¼šæå‡ CKA å¯ç›´æ¥æ”¹å–„å…¨å±€æ€§èƒ½ï¼ˆPPLâ†“, Accâ†‘ï¼‰

3. **ç®—æ³•å¤šæ ·æ€§æ¯” bit-width å¤šæ ·æ€§æ›´é‡è¦**ï¼š
   - åœ¨å›ºå®š 4-bit æ¡ä»¶ä¸‹ï¼Œæ”¹å˜ç®—æ³•çš„æ•ˆæœè¿œèƒœäºå°†éƒ¨åˆ†å±‚é™è‡³ 2-bit
   - â€œæ–¹æ³•å¼‚è´¨æ€§â€æ˜¯çªç ´ PTQ æ€§èƒ½ç“¶é¢ˆçš„å…³é”®è·¯å¾„

4. **æ— éœ€è®­ç»ƒå³å¯å®ç° SOTA æ€§èƒ½**ï¼š
   - æ•´ä¸ªæµç¨‹å®Œå…¨ post-trainingï¼Œé€‚åˆå¿«é€Ÿéƒ¨ç½²
   - å¯æ— ç¼é›†æˆè¿›ç°æœ‰ PTQ æµæ°´çº¿

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
| é—®é¢˜ | æè¿° |
|------|------|
| **ç†è®ºè¿‘ä¼¼æ€§** | è´ªå©ªé€å±‚é€‰æ‹©æ— æ³•ä¿è¯å…¨å±€æœ€ä¼˜ï¼Œå¯èƒ½å¿½ç•¥é•¿ç¨‹ä¾èµ– |
| **æ¨ç†å»¶è¿Ÿä¸ç³»ç»Ÿé›†æˆæŒ‘æˆ˜** | æ··åˆç®—æ³•éœ€å¤„ç†å¼‚æ„ kernel å’Œå†…å­˜å¸ƒå±€ï¼Œå½±å“ vLLM ç­‰å¼•æ“çš„ç®—å­èåˆä¸è®¿å­˜æ•ˆç‡ |
| **ç¦»çº¿å¼€é”€å¢åŠ ** | æœç´¢è¿‡ç¨‹éœ€å¯¹æ¯ä¸ªå±‚å°è¯•å¤šä¸ªç®—æ³•ï¼Œè€—æ—¶éšå€™é€‰æ± è§„æ¨¡çº¿æ€§å¢é•¿ |

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. è®¾è®¡æ›´é«˜æ•ˆçš„æœç´¢æœºåˆ¶ï¼ˆå¦‚åŸºäºå¼ºåŒ–å­¦ä¹ æˆ–ä»£ç†æ¨¡å‹ï¼‰ä»¥é€¼è¿‘å…¨å±€æœ€ä¼˜
2. å¼€å‘æ”¯æŒå¼‚æ„ kernel çš„æ¨ç†å¼•æ“ï¼Œè§£å†³éƒ¨ç½²ç“¶é¢ˆ
3. å°†è¯¥èŒƒå¼æ‰©å±•è‡³ **Quantization-Aware Training (QAT)** æˆ– **MoE æ¶æ„**ä¸­çš„ä¸“å®¶æ¨¡å—
4. æ¢ç´¢ CKA ä»¥å¤–çš„è¡¨ç¤ºå¯¹é½æŒ‡æ ‡ï¼ˆå¦‚ SVCCAã€Procrustes alignmentï¼‰

---

## âœ… æ€»ç»“
æœ¬è®ºæ–‡æå‡ºäº† **CKA-Guided Modular Quantization** æ¡†æ¶ï¼Œé¦–æ¬¡ç³»ç»Ÿæ¢ç´¢äº†åœ¨ LLM ä¸­è¿›è¡Œ**è·¨å±‚ç®—æ³•å¼‚æ„é‡åŒ–**çš„å¯èƒ½æ€§ã€‚é€šè¿‡å¼•å…¥ CKA ä½œä¸ºé€‰æ‹©å‡†åˆ™ï¼Œå®ç°äº†æ— éœ€è®­ç»ƒçš„é€å±‚æœ€ä¼˜ç®—æ³•åˆ†é…ï¼Œåœ¨å¤šä¸ªä¸»æµ LLM ä¸Šæ˜¾è‘—è¶…è¶Šäº†ç»Ÿä¸€é‡åŒ–å’Œä¼ ç»Ÿæ··åˆç²¾åº¦æ–¹æ³•ã€‚

> ğŸ”‘ **æ ¸å¿ƒæ´è§**ï¼š  
> â€œ**Not all layers are created equal â€” nor should they be quantized equally.**â€  
> çœŸæ­£çš„é«˜æ•ˆå‹ç¼©ä¸ä»…åœ¨äºâ€œå¤šå®½â€ï¼Œæ›´åœ¨äºâ€œæ€ä¹ˆå‹â€ã€‚

è¯¥å·¥ä½œä¸º PTQ æä¾›äº†ä¸€ä¸ªå…¨æ–°çš„è®¾è®¡ç»´åº¦ â€”â€” **ç®—æ³•å¤šæ ·æ€§**ï¼Œæœ‰æœ›æˆä¸ºæœªæ¥å¤§æ¨¡å‹å‹ç¼©çš„æ ‡å‡†ç»„ä»¶ä¹‹ä¸€ã€‚

</details>

---

### 8. [LLMCache: Layer-Wise Caching Strategies for Accelerated Reuse in Transformer Inference](https://arxiv.org/abs/2512.16843)

**Authors**: Harsh Vardhan Bansal  
**Category**: cs.CL  
**Published**: 2025-12-19  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.16843v1  

#### Abstract
Transformer-based language models have achieved remarkable performance across a wide range of tasks, yet their high inference latency poses a significant challenge for real-timeand large-scale deployment. While existing caching mechanisms,such as token-level key-value caches, offer speedups in autor...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLLMCache: Layer-Wise Caching Strategies for Accelerated Reuse in Transformer Inference

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
Transformer æ¨¡å‹åœ¨æ¨ç†é˜¶æ®µå­˜åœ¨é«˜å»¶è¿Ÿé—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†è¯­ä¹‰ç›¸ä¼¼æˆ–é‡å¤è¾“å…¥ï¼ˆå¦‚å¯¹è¯ç³»ç»Ÿã€æ–‡æ¡£æ‘˜è¦ã€RAGï¼‰æ—¶ï¼Œä»æ‰§è¡Œå®Œæ•´çš„å‰å‘ä¼ æ’­ï¼Œå¯¼è‡´å¤§é‡å†—ä½™è®¡ç®—ã€‚

ä¼ ç»Ÿ **Key-Value (KV) Caching** è™½ç„¶èƒ½åŠ é€Ÿè‡ªå›å½’ç”Ÿæˆï¼Œä½†ä»…é€‚ç”¨äº Decoder-only æ¶æ„ï¼Œä¸”å±€é™äº token-level çš„ç¼“å­˜ï¼Œæ— æ³•è·¨å±‚å¤ç”¨ä¸­é—´æ¿€æ´»ï¼ˆintermediate activationsï¼‰ï¼Œä¹Ÿä¸èƒ½ç”¨äº Encoder æˆ– Encoder-Decoder æ¨¡å‹ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šLLMCache
æå‡º **LLMCache** â€”â€” ä¸€ç§**æ¨¡å‹æ— å…³**ï¼ˆmodel-agnosticï¼‰ã€**æ¶æ„å…¼å®¹**ï¼ˆæ”¯æŒ Encoderã€Decoder å’Œ Encoder-Decoderï¼‰çš„**å±‚çº§åˆ«ç¼“å­˜æ¡†æ¶**ï¼ˆlayer-wise cachingï¼‰ï¼Œé€šè¿‡é‡ç”¨è¯­ä¹‰ç›¸ä¼¼è¾“å…¥å¯¹åº”çš„ä¸­é—´å±‚è¾“å‡ºæ¥åŠ é€Ÿæ¨ç†ã€‚

#### æ ¸å¿ƒæœºåˆ¶ï¼š
- **è¯­ä¹‰æŒ‡çº¹ç”Ÿæˆï¼ˆSemantic Fingerprintingï¼‰**  
  å¯¹è¾“å…¥åºåˆ—ç”Ÿæˆè½»é‡çº§å›ºå®šé•¿åº¦çš„ fingerprintï¼ˆå¦‚ä½¿ç”¨ Avg(E(X)) + æ³¨æ„åŠ›ç»Ÿè®¡ + SimHash/PCA å‹ç¼©ï¼‰ï¼Œä½œä¸ºç¼“å­˜é”®ã€‚
- **å±‚ç‹¬ç«‹ç¼“å­˜é“¶è¡Œï¼ˆLayer-wise Cache Banksï¼‰**  
  æ¯ä¸ª Transformer å±‚ç»´æŠ¤ä¸€ä¸ª `(fingerprint, hidden_state)` ç¼“å­˜æ± ã€‚
- **åŸºäºç›¸ä¼¼åº¦çš„æŸ¥æ‰¾ä¸å¤ç”¨**  
  è‹¥å½“å‰è¾“å…¥æŒ‡çº¹ä¸ç¼“å­˜ä¸­æŸé¡¹çš„ç›¸ä¼¼åº¦ï¼ˆcosine/Jaccardï¼‰è¶…è¿‡é˜ˆå€¼ `Ï„`ï¼Œåˆ™ç›´æ¥å¤ç”¨è¯¥å±‚è¾“å‡ºï¼Œè·³è¿‡è®¡ç®—ã€‚
- **åŠ¨æ€åˆ·æ–°ç­–ç•¥ï¼ˆAdaptive Evictionï¼‰**  
  æ”¯æŒ LRUã€staleness-awareã€divergence-monitor ç­‰ç­–ç•¥ç®¡ç†ç¼“å­˜æ–°é²œåº¦ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç‰¹æ€§ | KV-Cache | DocCache | LLMCache |
|------|----------|----------|-----------|
| æ”¯æŒ Encoder | âŒ | âœ…ï¼ˆéƒ¨åˆ†ï¼‰ | âœ… |
| æ”¯æŒ Decoder | âœ… | âŒ | âœ… |
| ç¼“å­˜ç²’åº¦ | Token-level | Document-level | **Layer-wise** |
| æ˜¯å¦éœ€é‡è®­ç»ƒ | âŒ | âŒ | âŒ |
| æ˜¯å¦æ¨¡å‹æ— å…³ | âŒï¼ˆä»…é™ Decoderï¼‰ | âŒï¼ˆç‰¹å®šä»»åŠ¡ï¼‰ | âœ… |
| å¤ç”¨æ·±åº¦ | æµ…å±‚ï¼ˆä»… attention keys/valuesï¼‰ | æµ…å±‚ï¼ˆembeddingï¼‰ | **æ·±å±‚ï¼ˆä»»æ„å±‚ hidden statesï¼‰** |

> âœ… **é¦–æ¬¡å®ç°ç»Ÿä¸€ã€é€šç”¨ã€æ— éœ€ä¿®æ”¹æ¶æ„çš„ layer-wise ç¼“å­˜æœºåˆ¶**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **WikiText-103**ï¼šè¯­è¨€å»ºæ¨¡ä»»åŠ¡
- **SQuAD v2**ï¼šé—®ç­”ä»»åŠ¡ï¼ˆå«ä¸å¯å›ç­”é—®é¢˜ï¼‰
- **OpenBookQA**ï¼šå¼€æ”¾çŸ¥è¯†é—®ç­”ä»»åŠ¡

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼š
  - BERT-baseï¼ˆEncoderï¼‰
  - DistilBERTï¼ˆå°å‹åŒ– Encoderï¼‰
  - GPT-2-smallï¼ˆDecoderï¼‰
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šNVIDIA A100 GPU
- **å‚æ•°é…ç½®**ï¼š
  - Batch size = 1
  - Sequence length = 128

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Inference Latency (ms)** | å¹³å‡å•æ¬¡æ¨ç†è€—æ—¶ |
| **Cache Hit Rate (%)** | æˆåŠŸå‘½ä¸­ç¼“å­˜çš„æ¯”ä¾‹ |
| **Accuracy Drop (%)** | ç›¸æ¯”æ— ç¼“å­˜ç‰ˆæœ¬çš„ä»»åŠ¡å‡†ç¡®ç‡ä¸‹é™ |
| **Memory Overhead (MB)** | ç¼“å­˜å¼•å…¥çš„é¢å¤–å†…å­˜å¼€é”€ |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | è¯´æ˜ |
|------|------|
| **NoCache** | æ ‡å‡† Transformer æ¨ç†æµç¨‹ï¼ˆæ— ä»»ä½•ç¼“å­˜ï¼‰ |
| **KV-Cache** | è‡ªå›å½’è§£ç ä¸­çš„æ ‡å‡† KV ç¼“å­˜ï¼ˆä»…ç”¨äº GPT-2ï¼‰ |
| **DocCache** | æ–‡æ¡£çº§ embedding ç¼“å­˜ï¼ˆé¢„è®¡ç®—å¹¶å¤ç”¨ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable I & IIIï¼‰

#### è¡¨æ ¼ï¼šå¹³å‡æ¨ç†å»¶è¿Ÿï¼ˆå•ä½ï¼šmsï¼‰

| Model | NoCache | KV-Cache | LLMCache (Ours) |
|-------|---------|----------|------------------|
| BERT-base | 218.6 | â€” | **91.3** |
| DistilBERT | 123.4 | â€” | **57.9** |
| GPT-2-small | 304.8 | 177.3 | **112.5** |

> ğŸ’¡ **æœ€é«˜è¾¾ 3.1Ã— åŠ é€Ÿ**ï¼ˆä»¥ BERT-base è®¡ç®—çº¦ä¸º 2.4Ã—ï¼‰

#### è¡¨æ ¼ï¼šä»»åŠ¡å‡†ç¡®ç‡å¯¹æ¯”ï¼ˆ%ï¼‰

| Dataset | NoCache | DocCache | LLMCache (Ours) |
|--------|---------|----------|------------------|
| WikiText-103 | 92.1 | 91.7 | **91.9** |
| SQuAD v2 | 86.3 | 85.8 | **86.1** |
| OpenBookQA | 72.5 | 71.9 | **72.3** |

> âœ… **å‡†ç¡®ç‡æŸå¤± < 0.5%**ï¼Œæ˜¾è‘—ä¼˜äº DocCache

---

### ğŸ” ç¼“å­˜å‘½ä¸­ç‡åˆ†æï¼ˆFigure 3ï¼‰
- åœ¨ **GPT-2 ä¸Šä¸åŒå±‚çš„ç¼“å­˜å‘½ä¸­ç‡**æ˜¾ç¤ºï¼š
  - ä½å±‚å’Œä¸­å±‚ï¼ˆç¬¬ 3â€“9 å±‚ï¼‰å‘½ä¸­ç‡é«˜è¾¾ **92%**
  - é«˜å±‚å› è¯­ä¹‰æ›´æ•æ„Ÿï¼Œå‘½ä¸­ç‡ä¸‹é™
- è¡¨æ˜ï¼š**æµ…å±‚è¡¨ç¤ºæ›´å…·è¯­ä¹‰ç¨³å®šæ€§**ï¼Œé€‚åˆç¼“å­˜å¤ç”¨

---

### ğŸ§ª æ¶ˆèå®éªŒï¼ˆAblation Studiesï¼‰

#### å›¾ 5ï¼šç›¸ä¼¼åº¦é˜ˆå€¼ `Ï„` æ•æ„Ÿæ€§åˆ†æ
- å½“ `Ï„ âˆˆ [0.82, 0.88]` æ—¶ï¼Œè¾¾åˆ°æœ€ä½³å¹³è¡¡
- è¿‡é«˜çš„ `Ï„` å¯¼è‡´å‘½ä¸­ç‡ä¸‹é™ï¼›è¿‡ä½åˆ™å¯èƒ½å¼•å…¥è¯­ä¹‰é”™é…

#### å›¾ 4ï¼šç¼“å­˜å¤§å° vs. å‘½ä¸­ç‡ï¼ˆBERT-baseï¼‰
- ç¼“å­˜å®¹é‡å¢åŠ å¸¦æ¥å‘½ä¸­ç‡æå‡ï¼Œä½†æ”¶ç›Šå‘ˆå¯¹æ•°å¢é•¿
- è¡¨æ˜å¯é€šè¿‡åˆç†æ§åˆ¶ç¼“å­˜å¤§å°å®ç°é«˜æ•ˆæƒè¡¡

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ä¸­é—´å±‚æ¿€æ´»å…·æœ‰è¯­ä¹‰ç¨³å®šæ€§**ï¼šç›¸åŒæˆ–ç›¸ä¼¼è¾“å…¥åœ¨ Transformer ä¸­é—´å±‚äº§ç”Ÿé«˜åº¦ä¸€è‡´çš„ hidden statesï¼Œä¸ºç¼“å­˜æä¾›äº†ç†è®ºåŸºç¡€ã€‚
2. **LLMCache æ˜¾è‘—é™ä½æ¨ç†å»¶è¿Ÿ**ï¼šåœ¨å¤šç§æ¨¡å‹å’Œä»»åŠ¡ä¸Šå®ç° **2.4Ã—~3.1Ã— æ¨ç†åŠ é€Ÿ**ï¼Œä¸”å‡†ç¡®ç‡æŸå¤±æå°ï¼ˆ<0.5%ï¼‰ã€‚
3. **é€šç”¨æ€§å¼º**ï¼šé€‚ç”¨äº BERTã€GPT ç­‰ä¸åŒæ¶æ„ï¼Œæ— éœ€é‡æ–°è®­ç»ƒæˆ–ç»“æ„è°ƒæ•´ã€‚
4. **ç¼“å­˜æ•ˆç›Šé›†ä¸­åœ¨ä¸­ä½å±‚**ï¼šé«˜å±‚å˜åŒ–å¤§ï¼Œå»ºè®®é€‰æ‹©æ€§ç¼“å­˜æ—©æœŸå±‚ä»¥èŠ‚çœå†…å­˜ã€‚

---

### âš ï¸ å±€é™æ€§
1. **å¯¹åˆ†å¸ƒå¤–è¾“å…¥æ•ˆæœæœ‰é™**ï¼šå½“è¾“å…¥å·®å¼‚å¤§æˆ–éšæœºæ€§å¼ºæ—¶ï¼Œfingerprint åŒ¹é…å¤±è´¥ç‡ä¸Šå‡ï¼Œç¼“å­˜å‘½ä¸­ç‡ä¸‹é™ã€‚
2. **å†…å­˜æ‰©å±•æŒ‘æˆ˜**ï¼šå¯¹äºæ›´å¤§æ¨¡å‹ï¼ˆå¦‚ GPT-3ï¼‰ï¼Œå…¨å±‚ç¼“å­˜å¯èƒ½å¯¼è‡´ GPU å†…å­˜å‹åŠ›ã€‚
3. **å¾®è°ƒåè¡Œä¸ºä¸ç¨³å®š**ï¼šfine-tuned æ¨¡å‹å¯èƒ½æ”¹å˜ä¸­é—´è¡¨ç¤ºåˆ†å¸ƒï¼Œå¯¼è‡´ç¼“å­˜å¿«é€Ÿå¤±æ•ˆã€‚
4. **å½“å‰æŒ‡çº¹ä¸ºæ‰‹å·¥è®¾è®¡**ï¼šæœªä½¿ç”¨å¯å­¦ä¹ çš„ fingerprint encoderï¼Œå¯èƒ½é™åˆ¶åŒ¹é…ç²¾åº¦ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **åŠ¨æ€é˜ˆå€¼è°ƒæ•´ï¼ˆDynamic Thresholdingï¼‰**  
   æ¯å±‚æˆ–æ¯è¾“å…¥è‡ªé€‚åº”è°ƒæ•´ `Ï„`ï¼Œç»“åˆä¸ç¡®å®šæ€§ä¼°è®¡ä¼˜åŒ–å†³ç­–ã€‚
2. **åˆ†å¸ƒå¼ç¼“å­˜å…±äº«ï¼ˆDistributed Cache Sharingï¼‰**  
   åœ¨å¤šèŠ‚ç‚¹æœåŠ¡ç³»ç»Ÿä¸­å…±äº« fingerprint ç¼“å­˜æ± ï¼Œè¿›ä¸€æ­¥æå‡å…¨å±€å‘½ä¸­ç‡ã€‚
3. **å¯å­¦ä¹ æŒ‡çº¹ç¼–ç å™¨ï¼ˆLearned Fingerprintsï¼‰**  
   ä½¿ç”¨è½»é‡çº§å¯è®­ç»ƒç½‘ç»œæ›¿ä»£ SimHash/AvgPoolï¼Œæé«˜è¯­ä¹‰åŒ¹é…èƒ½åŠ›ã€‚
4. **ä¸é‡åŒ–/å‰ªæç­‰æŠ€æœ¯è”åˆä¼˜åŒ–**  
   å°† LLMCache ä¸å…¶ä»–æ¨ç†åŠ é€Ÿæ–¹æ³•é›†æˆï¼Œæ„å»ºç»¼åˆä¼˜åŒ–æ–¹æ¡ˆã€‚

---

## æ€»ç»“
LLMCache æå‡ºäº†ä¸€ç§æ–°é¢–ã€å®ç”¨ä¸”é€šç”¨çš„ **layer-wise ç¼“å­˜èŒƒå¼**ï¼Œçªç ´äº†ä¼ ç»Ÿ KV-Cache çš„æ¶æ„é™åˆ¶ï¼Œå®ç°äº†åœ¨ä¸ç‰ºç‰²æ¨¡å‹æ€§èƒ½çš„å‰æä¸‹å¤§å¹…åŠ é€Ÿ Transformer æ¨ç†ã€‚å…¶å®éªŒå……åˆ†éªŒè¯äº†è¯­ä¹‰ç›¸ä¼¼è¾“å…¥ä¸‹ä¸­é—´æ¿€æ´»å¤ç”¨çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå¤§è§„æ¨¡ LLM éƒ¨ç½²æä¾›äº†ä¸€ä¸ªæå…·æ½œåŠ›çš„ç³»ç»Ÿçº§ä¼˜åŒ–å·¥å…·ã€‚

</details>

---

### 9. [LOG.io: Unified Rollback Recovery and Data Lineage Capture for Distributed Data Pipelines](https://arxiv.org/abs/2512.16038)

**Authors**: Eric Simon, Renato B. Hoffmann, Lucas Alf, Dalvan Griebler  
**Category**: cs.DC  
**Published**: 2025-12-19  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.16038v1  

#### Abstract
This paper introduces LOG.io, a comprehensive solution designed for correct rollback recovery and fine-grain data lineage capture in distributed data pipelines. It is tailored for serverless scalable architectures and uses a log-based rollback recovery protocol. LOG.io supports a general programming...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLOG.io: Unified Rollback Recovery and Data Lineage Capture for Distributed Data Pipelines

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡æ—¨åœ¨è§£å†³**åˆ†å¸ƒå¼æ•°æ®æµæ°´çº¿ï¼ˆdata pipelinesï¼‰ä¸­çš„ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜**ï¼š
1. **æ­£ç¡®å›æ»šæ¢å¤ï¼ˆCorrect Rollback Recoveryï¼‰**ï¼šåœ¨ç³»ç»Ÿæ•…éšœåï¼Œèƒ½å¤Ÿå°†æ•´ä¸ªæ•°æ®æµæ°´çº¿æ¢å¤åˆ°ä¸€ä¸ªä¸€è‡´çš„çŠ¶æ€ï¼Œå¹¶ä¿è¯æ¢å¤åçš„æ‰§è¡Œç»“æœç­‰ä»·äºæ— æ•…éšœæƒ…å†µä¸‹çš„æ‰§è¡Œç»“æœï¼ˆå³å®ç°â€œç«¯åˆ°ç«¯ç²¾ç¡®ä¸€æ¬¡â€è¯­ä¹‰ï¼‰ã€‚
2. **ç»†ç²’åº¦æ•°æ®è¡€ç¼˜æ•è·ï¼ˆFine-grain Data Lineage Captureï¼‰**ï¼šè¿½è¸ªä»»æ„ä¸¤ä¸ªç®—å­ä¹‹é—´è¾“å…¥äº‹ä»¶ä¸è¾“å‡ºäº‹ä»¶ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œç”¨äºè°ƒè¯•ã€å®¡è®¡å’Œæº¯æºã€‚

ç°æœ‰ä¸»æµæ–¹æ¡ˆå¦‚ **Asynchronous Barrier Snapshotting (ABS)** å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **é˜»å¡æ€§æ¢å¤**ï¼šå•ä¸ªç®—å­å¤±è´¥ä¼šå¯¼è‡´æ•´ä¸ªæµæ°´çº¿é‡å¯ï¼Œæ— æ³•åˆ©ç”¨å¹¶è¡Œå¤„ç†èƒ½åŠ›ã€‚
- **ä¸æ”¯æŒåŠ¨æ€æ‰©ç¼©å®¹**ï¼šæ‰©ç¼©å®¹éœ€åœæ­¢æµæ°´çº¿ã€å–æ£€æŸ¥ç‚¹ã€é‡æ–°éƒ¨ç½²ã€‚
- **å¤–éƒ¨ç³»ç»Ÿæ›´æ–°å»¶è¿Ÿ**ï¼šå†™æ“ä½œå¿…é¡»ç­‰åˆ°å®Œæ•´ epoch ç»“æŸæ‰èƒ½æäº¤ï¼Œå¯¼è‡´å»¶è¿Ÿã€‚
- **è¡€ç¼˜ç²’åº¦ç²—**ï¼šç°æœ‰è¡€ç¼˜æ–¹æ¡ˆé€šå¸¸åŸºäº RDD åˆ†åŒºæˆ–é™æ€æ‰¹å¤„ç†ï¼Œæ— æ³•ç²¾ç¡®åˆ°äº‹ä»¶çº§åˆ«ï¼Œä¸”ä¸æ”¯æŒéç¡®å®šæ€§ç®—å­ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
ä½œè€…æå‡ºäº† **LOG.io** â€”â€” ä¸€ç§ç»Ÿä¸€çš„æ—¥å¿—å‹å›æ»šæ¢å¤åè®®ï¼ŒåŒæ—¶æ”¯æŒç»†ç²’åº¦æ•°æ®è¡€ç¼˜æ•è·ã€‚

#### æ ¸å¿ƒæœºåˆ¶
- **æ—¥å¿—é©±åŠ¨æ¢å¤ï¼ˆLog-based Recoveryï¼‰**ï¼š
  - æ¯ä¸ªç®—å­åœ¨ç”Ÿæˆè¾“å‡ºäº‹ä»¶å‰ï¼Œå…ˆä»¥â€œundoneâ€çŠ¶æ€å°†å…¶æŒä¹…åŒ–åˆ°æ—¥å¿—ä¸­ã€‚
  - åŒæ—¶æ ‡è®°å…¶ä¾èµ–çš„è¾“å…¥äº‹ä»¶ä¸ºâ€œdoneâ€ï¼Œé€šè¿‡åŸå­äº‹åŠ¡ç¡®ä¿ä¸€è‡´æ€§ã€‚
  - æ•…éšœå‘ç”Ÿæ—¶ï¼Œä»…éœ€æ¢å¤å¤±è´¥ç®—å­è‡ªèº«ï¼Œæ— éœ€ä¸­æ–­å…¶ä»–æ­£å¸¸è¿è¡Œçš„ç®—å­ï¼ˆ**éé˜»å¡æ¢å¤**ï¼‰ã€‚
- **ç»Ÿä¸€è¡€ç¼˜æ•è·**ï¼š
  - åœ¨è®°å½•è¾“å‡ºäº‹ä»¶çš„åŒæ—¶ï¼Œè®°å½•å…¶ä¸è¾“å…¥äº‹ä»¶é›†åˆï¼ˆInput Setï¼‰çš„æ˜ å°„å…³ç³»ï¼Œå­˜å‚¨åœ¨ `EVENT_LINEAGE` è¡¨ä¸­ã€‚
  - æ”¯æŒä»»æ„ç®—å­ï¼ˆåŒ…æ‹¬éç¡®å®šæ€§ã€è‡ªå®šä¹‰ä»£ç ã€ä¸å¤–éƒ¨ç³»ç»Ÿäº¤äº’ï¼‰çš„äº‹ä»¶çº§è¡€ç¼˜è¿½è¸ªã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | ABS (Flink) | LOG.io |
|------|-----------|--------|
| **æ¢å¤æ¨¡å¼** | é˜»å¡å¼ï¼ˆå…¨æµæ°´çº¿é‡å¯ï¼‰ | éé˜»å¡å¼ï¼ˆç‹¬ç«‹æ¢å¤ï¼‰ |
| **åŠ¨æ€æ‰©ç¼©å®¹** | éœ€åœæœºå–æ£€æŸ¥ç‚¹ | è¿è¡Œæ—¶åŠ¨æ€è°ƒæ•´ |
| **å¤–éƒ¨ç³»ç»Ÿå†™å…¥** | å»¶è¿Ÿè‡³ epoch ç»“æŸ | å¯ç«‹å³æäº¤ |
| **è¡€ç¼˜ç²’åº¦** | åˆ†åŒºçº§ï¼ˆç²—ç²’åº¦ï¼‰ | äº‹ä»¶çº§ï¼ˆç»†ç²’åº¦ï¼‰ |
| **ç®—å­çµæ´»æ€§** | è¦æ±‚ç¡®å®šæ€§ | æ”¯æŒéç¡®å®šæ€§ã€è‡ªå®šä¹‰ç®—å­ |
| **è¡€ç¼˜å¼€é”€** | é¢å¤–å¼€é”€é«˜ï¼ˆ~20-30%ï¼‰ | æä½ï¼ˆ<1.5%ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### å®éªŒç¯å¢ƒ
- **å¹³å°**ï¼šSAP Data Intelligence Cloudï¼ˆåŸºäº Kubernetesï¼‰
- **å¯¹æ¯”åè®®**ï¼š
  - **LOG.io**ï¼ˆæœ¬æ–‡æå‡ºï¼‰
  - **ABS**ï¼ˆAsynchronous Barrier Snapshottingï¼ŒFlink ä¸­å®ç°ï¼‰
- **æ•°æ®åº“**ï¼šSAP HANAï¼ˆç”¨äºå­˜å‚¨å¿«ç…§æˆ–æ—¥å¿—ï¼‰

### å®éªŒè®¾ç½®
è®¾è®¡äº†ä¸‰ä¸ª **Use Case** æ¥è¯„ä¼°ä¸åŒåœºæ™¯ä¸‹çš„æ€§èƒ½ï¼š

#### Use Case 1ï¼šä¸²è¡Œæµæ°´çº¿ï¼Œå­˜åœ¨â€œæ…¢ç®—å­â€ï¼ˆstragglerï¼‰
- æµæ°´çº¿ç»“æ„ï¼š`OP1(Source) â†’ OP2 â†’ OP3(straggler) â†’ OP4(Writer) â†’ OP5(Sink)`
- å˜é‡ï¼š
  - äº‹ä»¶ååç‡ï¼ˆ100ms ~ 500ms/äº‹ä»¶ï¼‰
  - äº‹ä»¶å¤§å°ï¼ˆ10KB ~ 10MBï¼‰
  - å¤±è´¥ç®—å­ä½ç½®ï¼ˆOP3 æˆ– OP4ï¼‰
  - ABS å¿«ç…§é—´éš”ï¼ˆ15s, 30s, 45sï¼‰

#### Use Case 2ï¼šå¹¶è¡Œè·¯å¾„æµæ°´çº¿
- ç»“æ„ï¼šä¸¤æ¡å¹¶è¡Œè·¯å¾„æ±‡åˆåˆ° `OP4`
- ç›®çš„ï¼šæµ‹è¯•å¹¶è¡Œå¤„ç†å¯¹æ¢å¤æ€§èƒ½çš„å½±å“

#### Use Case 3ï¼šå¸¦æ•°æ®å¹¶è¡ŒåŒ–çš„æµæ°´çº¿
- ç»“æ„ï¼š`Dispatcher â†’ 2 replicas of OP3 â†’ Merger â†’ ...`
- ç›®çš„ï¼šè¯„ä¼°æ•°æ®å¹¶è¡ŒåŒ–å¯¹ LOG.io å’Œ ABS æ€§èƒ½çš„å½±å“

### è¯„ä¼°æŒ‡æ ‡
- **æ­£å¸¸å¤„ç†å¼€é”€ï¼ˆNormal Processing Overheadï¼‰**ï¼šç›¸æ¯”æ— æ¢å¤æœºåˆ¶çš„åŸºå‡†æ‰§è¡Œæ—¶é—´å¢åŠ çš„ç™¾åˆ†æ¯”ã€‚
- **æ¢å¤å¼€é”€ï¼ˆRecovery Overheadï¼‰**ï¼šæ•…éšœæ¢å¤æœŸé—´é¢å¤–æ¶ˆè€—çš„æ—¶é—´å æ¯”ã€‚
- **æ•°æ®è¡€ç¼˜å¼€é”€ï¼ˆLineage Overheadï¼‰**ï¼šå¼€å¯è¡€ç¼˜åŠŸèƒ½å¸¦æ¥çš„æ€§èƒ½å½±å“ã€‚
- æ‰€æœ‰å®éªŒé‡å¤ 10 æ¬¡ï¼Œå–å¹³å‡å€¼ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ­£å¸¸å¤„ç†æ€§èƒ½
| åœºæ™¯ | LOG.io å¼€é”€ | ABS å¼€é”€ |
|------|------------|---------|
| å­˜åœ¨æ…¢ç®—å­ï¼ˆOP3 æ…¢ 100Ã—ï¼‰ï¼Œä¸­ç­‰ååï¼ˆ100ms/äº‹ä»¶ï¼‰ | <1% ~ 6% | 2% ~ 3% |
| ç®—å­å¤„ç†æ—¶é—´ç›¸è¿‘ï¼Œé«˜ååï¼ˆ30ms/äº‹ä»¶ï¼‰ | **42.5%** | **3%** |
| æ•°æ®å¹¶è¡ŒåŒ–ï¼ˆ2 ä¸ªå‰¯æœ¬ï¼‰ | **25%**ï¼ˆæ˜¾è‘—é™ä½ï¼‰ | ~3.2%ï¼ˆå‡ ä¹ä¸å˜ï¼‰ |

> âœ… **ç»“è®º**ï¼šå½“å­˜åœ¨ **straggler ç®—å­** ä¸”ååé€‚ä¸­æ—¶ï¼ŒLOG.io ä¸ ABS æ€§èƒ½ç›¸å½“ï¼›ä½†åœ¨é«˜ååã€ç®—å­é€Ÿåº¦æ¥è¿‘æ—¶ï¼ŒLOG.io å› æ‚²è§‚æ—¥å¿—ï¼ˆpessimistic loggingï¼‰å¼€é”€è¾ƒå¤§ã€‚**æ•°æ®å¹¶è¡ŒåŒ–å¯å¤§å¹…ç¼“è§£ LOG.io å¼€é”€**ã€‚

### æ¢å¤æ€§èƒ½
| åœºæ™¯ | LOG.io æ¢å¤å¼€é”€ | ABS æ¢å¤å¼€é”€ |
|------|----------------|-------------|
| æ…¢ç®—å­å¤±è´¥ï¼ˆOP3 æ…¢ 100Ã—ï¼‰ | **1% ~ 12%** | **21% ~ 88%** |
| å¿«ç®—å­å¤±è´¥ï¼ˆOP4ï¼‰ | 18.9% ~ 36.5% | 24.6% ~ 63.6% |
| å¹¶è¡Œè·¯å¾„ä¸­å¤±è´¥ | **7.1% ~ 43.7%** | **19.2% ~ 56%** |

> âœ… **ç»“è®º**ï¼šLOG.io **åœ¨æ¢å¤é˜¶æ®µå§‹ç»ˆä¼˜äº ABS**ï¼Œå°¤å…¶å½“å¤±è´¥ç®—å­è¾ƒæ…¢æˆ–å­˜åœ¨å¹¶è¡Œè·¯å¾„æ—¶ä¼˜åŠ¿æ˜æ˜¾ã€‚**éé˜»å¡æ¢å¤**é¿å…äº†å¤§é‡å·²å¤„ç†å·¥ä½œçš„æµªè´¹ã€‚

### æ•°æ®è¡€ç¼˜æ•è·å¼€é”€
- åœ¨æ‰€æœ‰å®éªŒä¸­ï¼Œå¼€å¯è¡€ç¼˜åŠŸèƒ½çš„é¢å¤–å¼€é”€ **å‡ä½äº 1.5%**ï¼ˆæœ€ä½ 0.4%ï¼‰ã€‚
- ç›¸æ¯”å·²æœ‰æ–¹æ¡ˆï¼ˆå¦‚ Spark è¡€ç¼˜å¼€é”€ 20-30%ï¼‰ï¼ŒLOG.io çš„è¡€ç¼˜æ•è·å‡ ä¹â€œé›¶æˆæœ¬â€ã€‚

> âœ… **ç»“è®º**ï¼šLOG.io å°†è¡€ç¼˜æ•è·ä¸æ¢å¤æ—¥å¿—æœºåˆ¶ç»Ÿä¸€ï¼Œå®ç°äº†**é«˜æ•ˆã€ä½å¼€é”€çš„ç»†ç²’åº¦è¡€ç¼˜è¿½è¸ª**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LOG.io å®ç°äº†éé˜»å¡ã€ç‹¬ç«‹çš„ç®—å­æ¢å¤**ï¼Œæ˜¾è‘—æå‡äº†æ•…éšœæ¢å¤æ•ˆç‡ï¼Œå°¤å…¶é€‚ç”¨äºå­˜åœ¨å¤„ç†ç“¶é¢ˆï¼ˆstragglerï¼‰çš„æµæ°´çº¿ã€‚
2. **æ”¯æŒåŠ¨æ€æ‰©ç¼©å®¹**ï¼Œå¯åœ¨è¿è¡Œæ—¶æ— ç¼è°ƒæ•´ç®—å­å‰¯æœ¬æ•°ï¼Œé€‚åº”è´Ÿè½½å˜åŒ–ã€‚
3. **ç»Ÿä¸€äº†å›æ»šæ¢å¤ä¸æ•°æ®è¡€ç¼˜æ•è·**ï¼Œè¡€ç¼˜ä¿¡æ¯ç›´æ¥æ¥è‡ªæ¢å¤æ—¥å¿—ï¼Œå¼€é”€æä½ï¼ˆ<1.5%ï¼‰ã€‚
4. **æ”¯æŒé€šç”¨ç¼–ç¨‹æ¨¡å‹**ï¼šå…è®¸éç¡®å®šæ€§ç®—å­ã€è‡ªå®šä¹‰ä»£ç ã€ä¸å¤–éƒ¨ç³»ç»Ÿçš„ä»»æ„äº¤äº’ã€‚
5. **åœ¨é«˜ååã€ç®—å­é€Ÿåº¦å‡è¡¡åœºæ™¯ä¸‹ï¼ŒLOG.io æ­£å¸¸å¤„ç†å¼€é”€è¾ƒé«˜**ï¼Œä½†å¯é€šè¿‡**æ•°æ®å¹¶è¡ŒåŒ–**æœ‰æ•ˆç¼“è§£ã€‚

### å±€é™æ€§
- **æ‚²è§‚æ—¥å¿—ï¼ˆPessimistic Loggingï¼‰** å¯¼è‡´é«˜åååœºæ™¯ä¸‹æ€§èƒ½ä¸‹é™ã€‚
- å½“å‰å®ç°ä¾èµ– HANA DB æ—¥å¿—å­˜å‚¨ï¼Œå¯èƒ½æˆä¸ºæ€§èƒ½ç“¶é¢ˆã€‚
- å¯¹äºå®Œå…¨ç¡®å®šæ€§ç®—å­ï¼Œä¹è§‚æ—¥å¿—ï¼ˆOptimistic Loggingï¼‰å¯è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œä½†éœ€é¢å¤–æ¡ä»¶ï¼ˆå¦‚ replayabilityï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **è‡ªåŠ¨é€‰æ‹©æ—¥å¿—æ¨¡å¼**ï¼šæ ¹æ®ç®—å­ç‰¹æ€§ï¼ˆæ˜¯å¦ç¡®å®šæ€§ã€äº‹ä»¶å¤§å°ã€ååç‡ï¼‰åŠ¨æ€åˆ‡æ¢æ‚²è§‚/ä¹è§‚æ—¥å¿—ã€‚
2. **ä¼˜åŒ–æ—¥å¿—å­˜å‚¨**ï¼šé‡‡ç”¨æ›´é«˜æ•ˆã€å¯æ‰©å±•çš„æŒä¹…åŒ–ç»“æ„æ›¿ä»£å½“å‰ HANA DB å®ç°ã€‚
3. **æ”¯æŒæ›´å¤æ‚çš„è¡€ç¼˜æŸ¥è¯¢**ï¼šç»“åˆ schema-level lineage å®ç°è®°å½•çº§ä¾èµ–åˆ†æã€‚

---

> **æ€»ç»“**ï¼šLOG.io æ˜¯ä¸€ä¸ªåˆ›æ–°æ€§çš„ç»Ÿä¸€æ¡†æ¶ï¼Œè§£å†³äº†åˆ†å¸ƒå¼æ•°æ®æµæ°´çº¿ä¸­æ¢å¤ä¸è¡€ç¼˜ä¸¤å¤§éš¾é¢˜ã€‚å®ƒåœ¨æ¢å¤æ•ˆç‡å’ŒåŠŸèƒ½çµæ´»æ€§ä¸Šæ˜¾è‘—ä¼˜äº ABSï¼Œå°½ç®¡åœ¨æŸäº›é«˜åååœºæ™¯ä¸‹æ­£å¸¸å¤„ç†å¼€é”€è¾ƒé«˜ï¼Œä½†å…¶ä¼˜åŠ¿åœ¨çœŸå®å¤æ‚åœºæ™¯ä¸­å°¤ä¸ºçªå‡ºã€‚

</details>

---

### 10. [Data Valuation for LLM Fine-Tuning: Efficient Shapley Value Approximation via Language Model Arithmetic](https://arxiv.org/abs/2512.15765)

**Authors**: M\'elissa Tamine, Otmane Sakhi, Benjamin Heymann  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.15765v1  

#### Abstract
Data is a critical asset for training large language models (LLMs), alongside compute resources and skilled workers. While some training data is publicly available, substantial investment is required to generate proprietary datasets, such as human preference annotations or to curate new ones from ex...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šData Valuation for LLM Fine-Tuning: Efficient Shapley Value Approximation via Language Model Arithmetic

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡èšç„¦äº**å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¾®è°ƒä¸­çš„æ•°æ®ä¼°å€¼ï¼ˆdata valuationï¼‰é—®é¢˜**ï¼Œå³å¦‚ä½•å…¬å¹³ã€å‡†ç¡®åœ°è¡¡é‡ä¸åŒæ•°æ®æºå¯¹æœ€ç»ˆæ¨¡å‹æ€§èƒ½çš„è´¡çŒ®ã€‚ä¼ ç»ŸåŸºäº **Shapley value** çš„æ•°æ®ä¼°å€¼æ–¹æ³•è™½ç„¶ç†è®ºä¸Šå…·æœ‰å…¬å¹³æ€§å’Œå”¯ä¸€æ€§ï¼Œä½†ç”±äºå…¶è®¡ç®—å¤æ‚åº¦ä¸º $O(2^n)$ï¼Œéœ€è¦å¯¹æ¯ä¸ªå¯èƒ½çš„æ•°æ®å­é›†ï¼ˆcoalescenceï¼‰è¿›è¡Œæ¨¡å‹å¾®è°ƒï¼Œè¿™åœ¨ LLM åœºæ™¯ä¸‹æ˜¯ä¸å¯è¡Œçš„ã€‚

å°¤å…¶æ˜¯åœ¨åå¥½å¯¹é½ä»»åŠ¡ä¸­ï¼ˆå¦‚ RLHF æˆ– DPOï¼‰ï¼Œæ¯æ¬¡å¾®è°ƒæˆæœ¬æé«˜ï¼Œå¯¼è‡´ Shapley å€¼çš„å®é™…åº”ç”¨å—é™ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§**é«˜æ•ˆè¿‘ä¼¼ Shapley value çš„æ–°æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> åˆ©ç”¨ **Direct Preference Optimization (DPO)** å’Œ **Language Model Arithmetic** çš„æ•°å­¦ç»“æ„ï¼Œé¿å…ä¸ºæ¯ä¸ªæ•°æ®è”ç›Ÿï¼ˆcoalitionï¼‰å•ç‹¬å¾®è°ƒæ¨¡å‹ã€‚

å…·ä½“æ–¹æ³•å¦‚ä¸‹ï¼š
1. å¯¹æ¯ä¸ªç‹¬ç«‹æ•°æ®æºä½¿ç”¨ DPO å•ç‹¬å¾®è°ƒä¸€ä¸ªæ¨¡å‹ï¼ˆå…± $n$ æ¬¡å¾®è°ƒï¼‰ï¼›
2. åœ¨æ¨ç†é˜¶æ®µï¼Œé€šè¿‡ **æ¨¡å‹ç®—æœ¯ï¼ˆmodel arithmeticï¼‰** ç»„åˆè¿™äº›å¾®è°ƒåçš„æ¨¡å‹ï¼ˆåŠå…¶ LoRA é€‚é…å™¨ï¼‰ï¼Œæ„é€ ä»»æ„æ•°æ®è”ç›Ÿå¯¹åº”çš„â€œç»„åˆç­–ç•¥â€ï¼ˆcoalition policyï¼‰ï¼›
3. åŸºäºæ­¤ç»„åˆæ¨¡å‹è¯„ä¼°æ•ˆç”¨ï¼ˆutilityï¼‰ï¼Œè¿›è€Œè®¡ç®— Shapley valueã€‚

è¯¥æ–¹æ³•çš„å…³é”®æ´å¯Ÿåœ¨äºï¼š  
åœ¨ DPO æ¡†æ¶ä¸‹ï¼Œå¤šä¸ªæ•°æ®é›†è”åˆè®­ç»ƒæ‰€å¾—åˆ°çš„æœ€ä¼˜ç­–ç•¥ï¼Œç­‰ä»·äºå„ä¸ªæ•°æ®é›†å•ç‹¬è®­ç»ƒæ‰€å¾—å¥–åŠ±å‡½æ•°ä¹‹å’Œä½œç”¨äºåŸºç¡€æ¨¡å‹çš„ç»“æœã€‚å› æ­¤ï¼Œ**è”ç›Ÿç­–ç•¥å¯ä»¥é€šè¿‡å·²è®­ç»ƒæ¨¡å‹çš„æ¦‚ç‡è¾“å‡ºè¿›è¡Œä»£æ•°åˆæˆ**ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|------|--------|---------|
| å¾®è°ƒæ¬¡æ•° | $O(2^n)$ï¼ŒæŒ‡æ•°çº§ | $O(n)$ï¼Œçº¿æ€§ |
| è®¡ç®—å¯è¡Œæ€§ | ä¸é€‚ç”¨äºå¤§è§„æ¨¡ LLM | å¯æ‰©å±•è‡³å¤šæ•°æ®æºåœºæ™¯ |
| æ–¹æ³•æ–°é¢–æ€§ | é»‘ç®±é‡è®­ç»ƒ | åˆ©ç”¨ DPO ç»“æ„ç‰¹æ€§å®ç°è®­ç»ƒ-free æ¨ç†ç»„åˆ |
| åº”ç”¨æ½œåŠ› | é™äºå°è§„æ¨¡å®éªŒ | æ”¯æŒå¤šç›®æ ‡æ•°æ®ä»·å€¼åˆ†æã€åŠ¨æ€æ•°æ®é€‰æ‹©ç­‰ |

æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¯ä¸æ ‡å‡† Shapley è¿‘ä¼¼æŠ€æœ¯ï¼ˆå¦‚ Monte Carlo é‡‡æ ·ï¼‰ç»“åˆï¼Œåœ¨æ›´å¤§è§„æ¨¡ä¸‹è¿›ä¸€æ­¥é™ä½æ¨ç†å¼€é”€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **åŸºç¡€æ¨¡å‹**ï¼š`SmolLM-135M-Instruct`ï¼ˆè½»é‡çº§æŒ‡ä»¤æ¨¡å‹ï¼‰
- **è®­ç»ƒæ•°æ®æ¥æº**ï¼šUltraFeedback æ•°æ®é›†çš„å››ä¸ªå­é›†ä½œä¸ºç‹¬ç«‹æ•°æ®æä¾›è€…ï¼š
  - `flan_v2_niv2`
  - `sharegpt`
  - `evol_instruct`
  - `ultrachat`
- **è¯„ä¼°æ•°æ®**ï¼šä» UltraFeedback ä¸­é€‰å–ä¸ä¸Šè¿°è®­ç»ƒå­é›†æ— äº¤é›†çš„ 128 ä¸ªæç¤ºï¼ˆpromptsï¼‰

---

### å®éªŒè®¾ç½®
- **å¾®è°ƒæ–¹å¼**ï¼šé‡‡ç”¨ HuggingFace TRL åº“å®ç° DPOï¼Œå‚æ•° $\beta = 0.1$
- **ç¡¬ä»¶èµ„æº**ï¼šå•å¼  A100 80GB GPU
- **è®­ç»ƒé…ç½®**ï¼š
  - Epochs: 4
  - Batch size: 32ï¼ˆå« 4 æ­¥æ¢¯åº¦ç´¯ç§¯ï¼‰
  - Learning rate: $2 \times 10^{-5}$
  - å‚æ•°é«˜æ•ˆå¾®è°ƒï¼šLoRAï¼ˆrank=8, alpha=16ï¼‰
- **æ¨¡å‹ç»„åˆæ–¹å¼**ï¼šå†»ç»“ base modelï¼Œåˆå¹¶å„æ•°æ®æºå¯¹åº”çš„ LoRA æƒé‡ä»¥æ„å»º coalition model

---

### è¯„ä¼°æŒ‡æ ‡
- **æ•ˆç”¨å‡½æ•°ï¼ˆUtilityï¼‰å®šä¹‰ä¸ºæœŸæœ›å¥–åŠ±å€¼**ï¼š
  $$
  v(\pi_S) = \mathbb{E}_{x \sim D, y \sim \pi_S(\cdot|x)}[r(x,y)]
  $$
- ä½¿ç”¨ä¸¤ä¸ªé¢„è®­ç»ƒçš„æ ‡é‡å¥–åŠ±æ¨¡å‹è¯„ä¼°ï¼š
  - **Helpfulness Reward Model**ï¼šè¡¡é‡å›å¤æ˜¯å¦æœ‰å¸®åŠ©
  - **Harmlessness Reward Model**ï¼šè¡¡é‡å›å¤æ˜¯å¦å®‰å…¨æ— å®³
- æœ€ç»ˆ Shapley value åœ¨è¿™ä¸¤ä¸ªç»´åº¦ä¸Šåˆ†åˆ«è®¡ç®—å¹¶å¯è§†åŒ–

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ–‡ä¸­æœªç›´æ¥ä¸å…¶ä»– Shapley è¿‘ä¼¼æ–¹æ³•è¿›è¡Œæ•°å€¼æ€§èƒ½å¯¹æ¯”ï¼Œè€Œæ˜¯å¼ºè°ƒï¼š
- ä¼ ç»Ÿç²¾ç¡® Shapley éœ€è¦ $2^n = 16$ æ¬¡å¾®è°ƒï¼ˆæœ¬å®éªŒ $n=4$ï¼‰ï¼Œè€Œæœ¬æ–‡ä»…éœ€ 4 æ¬¡ï¼›
- æ‰€æœ‰ $2^4 = 16$ ä¸ªè”ç›Ÿçš„æ•ˆç”¨å‡é€šè¿‡æ¨¡å‹ç®—æœ¯æ„é€ å¹¶è¯„ä¼°ï¼ŒéªŒè¯äº†æ–¹æ³•çš„å®Œæ•´æ€§ï¼›
- å¼ºè°ƒå…¶ç›¸å¯¹äºâ€œæ¯è”ç›Ÿé‡è®­ç»ƒâ€èŒƒå¼çš„æ•ˆç‡é£è·ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- æˆåŠŸåœ¨ä»… **4 æ¬¡ DPO å¾®è°ƒ**çš„åŸºç¡€ä¸Šï¼Œä¼°è®¡å‡ºå…¨éƒ¨ 4 ä¸ªæ•°æ®æºåœ¨ **helpfulness** å’Œ **harmlessness** ä¸¤ä¸ªç»´åº¦ä¸Šçš„ Shapley valueï¼›
- æ‰€æœ‰ $2^4 = 16$ ä¸ª coalition çš„æ•ˆç”¨å‡å¯é€šè¿‡ LoRA åˆæˆæ¨¡å‹å‡†ç¡®ä¼°ç®—ï¼›
- å›¾2å±•ç¤ºäº†å››ç±»æ•°æ®æºåœ¨äºŒç»´ä»·å€¼ç©ºé—´ä¸­çš„åˆ†å¸ƒï¼ˆå³â€œspatial signatureâ€ï¼‰ï¼š

| æ•°æ®æº | Helpfulness è´¡çŒ® | Harmlessness è´¡çŒ® |
|-------|------------------|--------------------|
| `sharegpt` | æ˜¾è‘—æ­£å‘ | è½»å¾®æ­£å‘ |
| `ultrachat` | å‡ ä¹ä¸­æ€§ | æ˜¾è‘—æå‡å®‰å…¨æ€§ |
| `flan_v2_niv2` | å°å¹…æå‡ | è½»å¾®è´Ÿé¢å½±å“ |
| `evol_instruct` | æå‡æ˜æ˜¾ | æœ€ä¸¥é‡çš„è´Ÿé¢æ•ˆåº” |

> æ³¨ï¼šè´Ÿ Shapley å€¼è¡¨æ˜è¯¥æ•°æ®æºå¹³å‡è€Œè¨€ä¼šæ‹‰ä½æŸé¡¹æŒ‡æ ‡ï¼Œå³ä½¿å®ƒåœ¨æŸäº›è”ç›Ÿä¸­æœ‰æ­£é¢ä½œç”¨ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **è®¡ç®—æˆæœ¬å¯¹æ¯”**ï¼š
  - ä¼ ç»Ÿæ–¹æ³•ï¼šéœ€ 16 æ¬¡å®Œæ•´å¾®è°ƒ â†’ æˆæœ¬é«˜ã€ä¸å¯æ‰©å±•
  - æœ¬æ–‡æ–¹æ³•ï¼šä»… 4 æ¬¡å¾®è°ƒ + æ¨ç†æ—¶ç»„åˆ â†’ æˆæœ¬ä¸‹é™ 75%
- **ç²¾åº¦ä¿éšœ**ï¼š
  - åœ¨æ”¶æ•›å‡è®¾ä¸‹ï¼Œç†è®ºè¯æ˜ coalition policy å¯ç”±ä¸ªä½“æ¨¡å‹ç²¾ç¡®é‡æ„ï¼›
  - å®è·µä¸­è™½å­˜åœ¨æœ‰é™æ­¥è®­ç»ƒåå·®ï¼Œä½† LoRA åŠ æƒç»„åˆä»èƒ½æœ‰æ•ˆé€¼è¿‘çœŸå®è”åˆè®­ç»ƒæ•ˆæœã€‚

---

### æ¶ˆèå®éªŒï¼ˆæ–‡ä¸­æœªæ˜ç¡®å¼€å±•ï¼Œä½†æœ‰è®¨è®ºï¼‰
- æ–‡ä¸­æŒ‡å‡ºæœªæ¥éœ€ç ”ç©¶ï¼š
  - Sequential DPO æ˜¯å¦æ»¡è¶³äº¤æ¢å¾‹ï¼ˆcommutativityï¼‰ï¼Ÿ
  - å®é™…éæ”¶æ•›æƒ…å†µä¸‹æ¨¡å‹ç®—æœ¯çš„è¯¯å·®è¾¹ç•Œï¼Ÿ
- å½“å‰å®éªŒé»˜è®¤æ¨¡å‹ç®—æœ¯æˆç«‹ï¼Œå¹¶é€šè¿‡å¤šç»´åº¦ä»·å€¼åˆ†æå±•ç¤ºå…¶è¯­ä¹‰æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **DPO å…·æœ‰è‰¯å¥½çš„ä»£æ•°ç»“æ„**ï¼Œå…è®¸å¤šä¸ªæ•°æ®é›†çš„å½±å“å åŠ ï¼Œä»è€Œæ”¯æŒ **language model arithmetic**ï¼›
2. âœ… åˆ©ç”¨è¿™ä¸€æ€§è´¨ï¼Œå¯ä»¥å°† Shapley value çš„è®¡ç®—ä» **æŒ‡æ•°çº§å¾®è°ƒ** é™ä¸º **çº¿æ€§å¾®è°ƒ + æ¨ç†æœŸæ¨¡å‹ç»„åˆ**ï¼›
3. âœ… æ•°æ®æºçš„ä»·å€¼å…·æœ‰**å¤šç»´å¼‚è´¨æ€§**ï¼šæœ‰çš„æå‡ helpfulnessï¼Œæœ‰çš„æ”¹å–„ harmlessnessï¼Œæœ‰çš„ç”šè‡³å¸¦æ¥è´Ÿå‘å½±å“ï¼›
4. âœ… è´Ÿ Shapley å€¼å…·æœ‰è§£é‡Šæ„ä¹‰ï¼Œå¯ç”¨äºè¯†åˆ«â€œæ¯’åŒ–â€æˆ–ä½è´¨é‡æ•°æ®æºï¼›
5. âœ… æå‡ºçš„â€œæ•°æ®ç­¾åâ€ï¼ˆdata signatureï¼‰æ¦‚å¿µæœ‰åŠ©äºç†è§£ä¸åŒæ•°æ®é›†åœ¨å¯¹é½è¿‡ç¨‹ä¸­çš„è§’è‰²åˆ†å·¥ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- ğŸš« **ä¾èµ– DPO çš„ç‰¹å®šæ•°å­¦å½¢å¼**ï¼Œä¸ç›´æ¥é€‚ç”¨äº PPO ç­‰åŸºäºå¼ºåŒ–å­¦ä¹ çš„å¯¹é½æ–¹æ³•ï¼›
- ğŸš« å‡è®¾ Sequential DPO ä¸ Joint DPO æ”¶æ•›åˆ°ç›¸åŒè§£ï¼Œä½†åœ¨å®é™…è®­ç»ƒä¸­ç”±äºä¼˜åŒ–è·¯å¾„å·®å¼‚å¯èƒ½å­˜åœ¨åå·®ï¼›
- ğŸš« å½“å‰å®éªŒè§„æ¨¡è¾ƒå°ï¼ˆä»… 4 ä¸ªæ•°æ®æºï¼Œæ¨¡å‹ä¸º 135Mï¼‰ï¼Œå°šæœªéªŒè¯åœ¨åäº¿çº§ä»¥ä¸Šæ¨¡å‹ä¸Šçš„ç¨³å®šæ€§ï¼›
- ğŸš« LoRA åˆå¹¶å¯èƒ½å¼•å…¥å¹²æ‰°ï¼Œå°¤å…¶å½“é€‚é…å™¨ä¹‹é—´å­˜åœ¨å†²çªæ—¶ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‹“å±•è‡³å…¶ä»–å¯¹é½ç®—æ³•**ï¼šæ¢ç´¢æ˜¯å¦å­˜åœ¨ç±»ä¼¼ä»£æ•°ç»“æ„çš„ RLHF å˜ä½“æˆ–å…¶ä»–åå¥½å­¦ä¹ ç›®æ ‡ï¼›
2. **åŠ¨æ€æ•°æ®åŠ æƒæœºåˆ¶**ï¼šåˆ©ç”¨ Shapley å€¼åœ¨çº¿è°ƒæ•´è®­ç»ƒæ•°æ®æƒé‡ï¼Œå®ç°è‡ªåŠ¨æ•°æ®æ¸…æ´—ä¸å¢å¼ºï¼›
3. **ç‰ˆæƒä¸è´£ä»»è¿½æº¯**ï¼šåŸºäºæ•°æ®è´¡çŒ®åº¦åˆ¤æ–­ç”Ÿæˆå†…å®¹çš„è´£ä»»å½’å±ï¼Œæ”¯æŒåˆè§„æ€§å®¡è®¡ï¼›
4. **ç¤¾ä¼šé€‰æ‹©ç†è®ºèåˆ**ï¼šå°† LLM è§†ä¸ºåå¥½èšåˆå™¨ï¼Œè®¾è®¡ç¬¦åˆå…¬å¹³å…¬ç†çš„è®­ç»ƒæœºåˆ¶ï¼›
5. **æ›´é«˜æ•ˆçš„ Shapley è¿‘ä¼¼**ï¼šç»“åˆ Monte Carlo é‡‡æ ·æˆ–å›å½’æŠ€å·§ï¼Œå°†æ¨ç†æ¬¡æ•°ä» $2^n$ é™è‡³å¤šé¡¹å¼çº§åˆ«ã€‚

---

## æ€»ç»“
æœ¬æ–‡æå‡ºäº†ä¸€ä¸ª**åŸºäº DPO å’Œ Language Model Arithmetic çš„é«˜æ•ˆæ•°æ®ä¼°å€¼æ¡†æ¶**ï¼Œé¦–æ¬¡å®ç°äº†åœ¨ LLM åå¥½å¾®è°ƒä¸­**çº¿æ€§æˆæœ¬ä¸‹çš„ Shapley value è¿‘ä¼¼è®¡ç®—**ã€‚å…¶å®éªŒéªŒè¯äº†æ•°æ®ä»·å€¼çš„å¤šç»´æ€§å’Œéå¯¹ç§°æ€§ï¼Œä¸ºæ„å»ºé€æ˜ã€å¯è§£é‡Šã€è´Ÿè´£ä»»çš„ LLM è®­ç»ƒæµç¨‹æä¾›äº†é‡è¦å·¥å…·ã€‚è¯¥å·¥ä½œæ‰“é€šäº† **cooperative game theory** ä¸ **LLM alignment** ä¹‹é—´çš„æ¡¥æ¢ï¼Œå…·æœ‰é‡è¦çš„ç†è®ºæ„ä¹‰å’Œåº”ç”¨å‰æ™¯ã€‚

</details>

---

### 11. [Twin Restricted Kernel Machines for Multiview Classification](https://arxiv.org/abs/2512.15757)

**Authors**: A. Quadir, M. Sajid, Mushir Akhtar, M. Tanveer  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.15757v1  

#### Abstract
Multi-view learning (MVL) is an emerging field in machine learning that focuses on improving generalization performance by leveraging complementary information from multiple perspectives or views. Various multi-view support vector machine (MvSVM) approaches have been developed, demonstrating signifi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Twin Restricted Kernel Machines for Multiview Classification è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **Multi-view Support Vector Machine (MvSVM)** åŠå…¶å˜ä½“åœ¨å¤„ç†å¤šè§†å›¾åˆ†ç±»ä»»åŠ¡æ—¶é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- éœ€è¦æ±‚è§£å¤§è§„æ¨¡çš„äºŒæ¬¡è§„åˆ’é—®é¢˜ï¼ˆQuadratic Programming Problems, QPPsï¼‰ï¼Œè®¡ç®—æˆæœ¬é«˜ï¼Œå°¤å…¶åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šæ•ˆç‡ä½ä¸‹ï¼›
- å¯¹è§†å›¾é—´çš„ä¸ä¸€è‡´æ€§ï¼ˆview inconsistenciesï¼‰æ•æ„Ÿï¼›
- åœ¨èåˆç­–ç•¥ä¸Šå­˜åœ¨å±€é™ï¼šæ—©æœŸèåˆæ˜“å¯¼è‡´ç»´åº¦ç¾éš¾å¹¶å¿½ç•¥å„è§†å›¾ç‰¹æ€§ï¼Œæ™šæœŸèåˆåˆ™ç¼ºä¹è®­ç»ƒè¿‡ç¨‹ä¸­çš„è·¨è§†å›¾ä¿¡æ¯äº¤äº’ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼š**TMvRKM**ï¼ˆTwin Multiview Restricted Kernel Machineï¼‰
æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹å¤šè§†å›¾åˆ†ç±»æ¨¡å‹â€”â€”**Twin Multiview Restricted Kernel Machine (TMvRKM)**ï¼Œç»“åˆäº†ä»¥ä¸‹å…³é”®æŠ€æœ¯æ€æƒ³ï¼š
- åŸºäº **Restricted Kernel Machine (RKM)** æ¶æ„ï¼Œå¼•å…¥å¯è§å±‚ä¸éšè—å±‚å˜é‡ï¼Œå€Ÿé‰´ **Restricted Boltzmann Machine (RBM)** çš„èƒ½é‡å‡½æ•°è®¾è®¡æ€è·¯ï¼›
- é‡‡ç”¨ **Twin** å­¦ä¹ æœºåˆ¶ï¼Œæ„å»ºä¸¤ä¸ªéå¹³è¡Œè¶…å¹³é¢ä»¥æå‡åˆ†ç±»è¾¹ç•Œçµæ´»æ€§ï¼›
- åˆ©ç”¨ **æ­£åˆ™åŒ–æœ€å°äºŒä¹˜æ³•**ï¼ˆRegularized Least Squaresï¼‰æ›¿ä»£ä¼ ç»Ÿçš„ QPP æ±‚è§£æ–¹å¼ï¼Œæ˜¾è‘—æé«˜è®¡ç®—æ•ˆç‡ï¼›
- å¼•å…¥ **è€¦åˆé¡¹**ï¼ˆcoupling termï¼‰æ¥å¹³è¡¡å¤šä¸ªè§†å›¾ä¹‹é—´çš„è¯¯å·®ï¼Œæœ‰æ•ˆåˆ©ç”¨äº’è¡¥æ€§å’Œä¸€è‡´æ€§åŸåˆ™ï¼›
- èåˆ **æ—©æœŸèåˆä¸æ™šæœŸèåˆçš„ä¼˜ç‚¹**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ•´åˆå¤šè§†å›¾ä¿¡æ¯ï¼ˆæ—©èåˆï¼‰ï¼ŒåŒæ—¶ä¸ºæ¯ä¸ªè§†å›¾ä¿ç•™ç‹¬ç«‹çš„æ­£åˆ™åŒ–å‚æ•°ä»¥é€‚åº”å…¶ç‹¬ç‰¹ç»Ÿè®¡ç‰¹æ€§ï¼ˆæ™šèåˆçµæ´»æ€§ï¼‰ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | ä¼ ç»Ÿ MvSVM ç±»æ–¹æ³• | æœ¬æ–‡ TMvRKM |
|------|------------------|-------------|
| è®¡ç®—å¤æ‚åº¦ | é«˜ï¼ˆéœ€è§£ QPPï¼‰ | ä½ï¼ˆè½¬åŒ–ä¸ºçº¿æ€§ç³»ç»Ÿæ±‚è§£ï¼‰ |
| å¤šè§†å›¾èåˆæœºåˆ¶ | å¤šä¸ºå•ä¸€æ—©/æ™šèåˆ | åŒæ—¶é›†æˆæ—©èåˆä¸æ™šèåˆä¼˜åŠ¿ |
| è§†å›¾é—´åè°ƒæ€§ | è¾ƒå¼± | é€šè¿‡è€¦åˆé¡¹æ˜¾å¼å»ºæ¨¡è§†å›¾å…³ç³» |
| æ‰©å±•æ€§ | ä¸é€‚ç”¨äºå¤§è§„æ¨¡æ•°æ® | æ›´é€‚åˆå¤§è§„æ¨¡æ•°æ®åœºæ™¯ |

> âœ… **æ ¸å¿ƒåˆ›æ–°**ï¼šé¦–æ¬¡å°† RKM ä¸ Twin æ¡†æ¶æ‰©å±•è‡³å¤šè§†å›¾å­¦ä¹ é¢†åŸŸï¼Œæå‡ºé«˜æ•ˆã€å¯æ‰©å±•ä¸”å…·æœ‰è‰¯å¥½æ³›åŒ–èƒ½åŠ›çš„ TMvRKM æ¨¡å‹ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåœ¨ä¸‰ç±»å…¬å¼€åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œï¼š
- **UCI æ•°æ®é›†**ï¼šå…± 27 ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ï¼ˆå¦‚ `breast_cancer`, `pima`, `bank` ç­‰ï¼‰ï¼›
- **KEEL æ•°æ®é›†**ï¼šåŒæ ·åŒ…å« 27 ä¸ªæ ‡å‡†åˆ†ç±»ä»»åŠ¡ï¼›
- **AwAï¼ˆAnimal with Attributesï¼‰æ•°æ®é›†**ï¼šåŒ…å« 50 ç§åŠ¨ç‰©ç±»åˆ«ï¼Œä»ä¸­é€‰å– 10 ç±»æ„é€  27 ä¸ªäºŒåˆ†ç±»ä»»åŠ¡ï¼Œæ¯æ ·æœ¬æœ‰ 6 ç§é¢„æå–ç‰¹å¾è¡¨ç¤ºï¼ˆå¤©ç„¶å¤šè§†å›¾ç»“æ„ï¼‰ã€‚

> æ³¨ï¼šå¯¹äº UCI å’Œ KEEL æ•°æ®é›†ï¼Œç”±äºæœ¬èº«æ— å¤šè§†å›¾å±æ€§ï¼Œä½œè€…äººå·¥æ„é€ ä¸¤ä¸ªè§†å›¾ï¼š
> - View Aï¼šåŸå§‹ç‰¹å¾ï¼›
> - View Bï¼šé€šè¿‡ PCA æå–å‰ 95% ä¸»æˆåˆ†å¾—åˆ°çš„é™ç»´ç‰¹å¾ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **äº¤å‰éªŒè¯**ï¼šé‡‡ç”¨ 5-fold cross-validationï¼›
- **æ•°æ®åˆ’åˆ†**ï¼šè®­ç»ƒé›† : æµ‹è¯•é›† = 70% : 30%ï¼›
- **æ ¸å‡½æ•°**ï¼šä½¿ç”¨ RBF æ ¸ $ K(x,x') = \exp(-\|x - x'\|^2 / (2\sigma^2)) $ï¼Œå…¶ä¸­ $\sigma$ ä»é›†åˆ $\{2^{-5}, ..., 2^{5}\}$ ä¸­é€‰æ‹©ï¼›
- **è¶…å‚æ•°è°ƒä¼˜**ï¼šé€šè¿‡ç½‘æ ¼æœç´¢ä¼˜åŒ–æƒ©ç½šå‚æ•° $m_1=m_2$ å’Œæ­£åˆ™åŒ–ç³»æ•° $\lambda_1=\lambda_2$ï¼ŒèŒƒå›´ä¸º $\{10^{-5}, ..., 10^{5}\}$ï¼›
- **å®ç°ç¯å¢ƒ**ï¼šPython 3.11ï¼Œè¿è¡Œäº Intel Xeon Gold 6226R CPU + 128GB RAMã€‚

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- **åˆ†ç±»å‡†ç¡®ç‡ï¼ˆAccuracy, Accï¼‰**
- **å¹³å‡æ’åï¼ˆAverage Rankï¼‰**ï¼šç”¨äºç»¼åˆæ¯”è¾ƒä¸åŒæ¨¡å‹åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼›
- **ç»Ÿè®¡æ£€éªŒ**ï¼š
  - Friedman æ£€éªŒï¼ˆåˆ¤æ–­æ˜¯å¦å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼‰
  - Nemenyi post-hoc æ£€éªŒï¼ˆæˆå¯¹æ¯”è¾ƒï¼Œè®¡ç®—ä¸´ç•Œå·® C.D.ï¼‰

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
ä¸ä»¥ä¸‹ä¸»æµå¤šè§†å›¾åˆ†ç±»å™¨è¿›è¡Œå¯¹æ¯”ï¼š
- **SVM-2K** [11]
- **MvTSVM** [13]
- **MVLDM** [31]
- **MvTPMSVM** [22]
- **MvRKM** [27]

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table I & IIï¼‰

#### åœ¨ UCI + KEEL æ•°æ®é›†ä¸Šçš„ç»“æœï¼š
| æ¨¡å‹ | å¹³å‡ Accuracy (%) | å¹³å‡ Rank |
|------|--------------------|-----------|
| SVM-2K | 76.65 | 4.22 |
| MvTSVM | 67.24 | 5.70 |
| MVLDM | 79.90 | 3.74 |
| MvTPMSVM | 83.56 | 3.06 |
| MvRKM | 84.39 | 2.48 |
| **TMvRKM (Ours)** | **85.62** | **1.80** |

âœ… **TMvRKM åœ¨æ‰€æœ‰æ¨¡å‹ä¸­å–å¾—æœ€é«˜å¹³å‡å‡†ç¡®ç‡å’Œæœ€ä½å¹³å‡æ’å**ã€‚

#### åœ¨ AwA æ•°æ®é›†ä¸Šçš„ç»“æœï¼š
| æ¨¡å‹ | å¹³å‡ Accuracy (%) | å¹³å‡ Rank |
|------|--------------------|-----------|
| SVM-2K | 77.61 | 2.35 |
| MvTSVM | 67.18 | 4.78 |
| MVLDM | 74.09 | 3.72 |
| MvTPMSVM | 74.02 | 3.67 |
| MvRKM | 72.53 | 4.46 |
| **TMvRKM (Ours)** | **78.09** | **2.02** |

âœ… **å†æ¬¡ä¼˜äºæ‰€æœ‰åŸºçº¿æ¨¡å‹ï¼Œå°¤å…¶åœ¨ AwA ä¸Šè¶…è¶Šæœ€å¼ºå¯¹æ‰‹ SVM-2K**ã€‚

### ğŸ“Š ç»Ÿè®¡æ˜¾è‘—æ€§åˆ†æ
- **Friedman æ£€éªŒ**ï¼š
  - UCI/KEELï¼š$\chi_F^2 = 73.59$, $F_F = 31.16$ï¼Œè¿œå¤§äºä¸´ç•Œå€¼ $F_{(5,130)} = 2.2839$ â†’ **æ‹’ç»é›¶å‡è®¾**
  - AwAï¼š$\chi_F^2 = 47.44$, $F_F = 14.08$ï¼Œä¹Ÿæ˜¾è‘— â†’ **å­˜åœ¨æ˜¾è‘—æ€§èƒ½å·®å¼‚**

- **Nemenyi æ£€éªŒï¼ˆC.D. = 1.4788ï¼‰**
  - åœ¨ UCI/KEEL ä¸Šï¼ŒTMvRKM ä¸ SVM-2Kã€MvTSVMã€MVLDM çš„æ’åå·®å‡è¶…è¿‡ C.D.ï¼Œè¯´æ˜æ€§èƒ½æå‡æ˜¾è‘—ï¼›
  - å°½ç®¡ä¸ MvTPMSVM å’Œ MvRKM çš„å·®è·æœªè¾¾æ˜¾è‘—æ°´å¹³ï¼Œä½†ä»ä¿æŒæ›´ä¼˜æ’åã€‚

### ğŸ” æ•æ„Ÿæ€§åˆ†æï¼ˆSensitivity Analysisï¼‰
- å›¾ 1 æ˜¾ç¤ºæ¨¡å‹å¯¹å‚æ•° $m$ å’Œ $\sigma$ å…·æœ‰ä¸€å®šé²æ£’æ€§ï¼›
- æœ€ä½³æ€§èƒ½å‡ºç°åœ¨ï¼š
  - $m \in [10^{-1}, 10^5]$
  - $\sigma \in [10^0, 10^5]$
- å»ºè®®åœ¨æ­¤èŒƒå›´å†…è¿›è¡Œç²¾ç»†è°ƒå‚ä»¥è·å¾—æœ€ä¼˜æ³›åŒ–æ€§èƒ½ã€‚

> â—æ–‡ä¸­æœªæŠ¥å‘Šæ¶ˆèå®éªŒï¼ˆablation studyï¼‰ï¼Œæ— æ³•é‡åŒ–â€œè€¦åˆé¡¹â€ã€â€œåŒæ›²é¢ç»“æ„â€æˆ–â€œRKM æ¶æ„â€çš„å•ç‹¬è´¡çŒ®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **TMvRKM æ˜¾è‘—æå‡äº†å¤šè§†å›¾åˆ†ç±»çš„æ³›åŒ–æ€§èƒ½**ï¼Œåœ¨ UCIã€KEEL å’Œ AwA æ•°æ®é›†ä¸Š consistently outperform æ‰€æœ‰åŸºçº¿æ¨¡å‹ï¼›
2. é‡‡ç”¨ **æ­£åˆ™åŒ–æœ€å°äºŒä¹˜æ¡†æ¶** æ›¿ä»£ä¼ ç»Ÿ QPPï¼Œå¤§å¹…é™ä½è®¡ç®—å¤æ‚åº¦ï¼Œæ›´é€‚åˆå¤§è§„æ¨¡åº”ç”¨ï¼›
3. æˆåŠŸèåˆ **early fusion ä¸ late fusion çš„ä¼˜åŠ¿**ï¼Œæ—¢èƒ½åœ¨è®­ç»ƒä¸­å…±äº«ä¿¡æ¯ï¼Œåˆèƒ½çµæ´»é€‚åº”å„è§†å›¾ç‰¹æ€§ï¼›
4. å¼•å…¥çš„ **è€¦åˆé¡¹** æœ‰æ•ˆå¹³è¡¡å¤šè§†å›¾è¯¯å·®ï¼Œå¢å¼ºäº†æ¨¡å‹å¯¹è§†å›¾ä¸ä¸€è‡´æ€§çš„é²æ£’æ€§ï¼›
5. ç»Ÿè®¡æ£€éªŒè¯å® TMvRKM çš„ä¼˜è¶Šæ€§å…·æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§ã€‚

### âš ï¸ å±€é™æ€§
- ç¼ºä¹ **æ¶ˆèå®éªŒ** æ¥éªŒè¯å„ä¸ªç»„ä»¶ï¼ˆå¦‚ twin ç»“æ„ã€è€¦åˆé¡¹ã€RKM æ¶æ„ï¼‰çš„å…·ä½“ä½œç”¨ï¼›
- æ‰€æœ‰äººå·¥æ„é€ è§†å›¾çš„æ–¹å¼ï¼ˆPCA åˆ†è§£ï¼‰å¯èƒ½ä¸èƒ½å®Œå…¨åæ˜ çœŸå®å¤šè§†å›¾æ•°æ®çš„å¤æ‚ä¾èµ–å…³ç³»ï¼›
- ä»…ç”¨äºåˆ†ç±»ä»»åŠ¡ï¼Œæœªæ¢ç´¢å…¶åœ¨å›å½’ã€èšç±»æˆ–å¤šæ ‡ç­¾å­¦ä¹ ä¸­çš„æ½œåŠ›ï¼›
- è¶…å‚æ•°è¾ƒå¤šï¼Œä¾èµ–ç½‘æ ¼æœç´¢ï¼Œåœ¨å®é™…éƒ¨ç½²ä¸­å¯èƒ½å¢åŠ è°ƒå‚è´Ÿæ‹…ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å°† TMvRKM æ‰©å±•åˆ° **unsupervised learning** åœºæ™¯ï¼Œå¦‚å¤šè§†å›¾èšç±»ï¼ˆMultiview Clusteringï¼‰ï¼›
- æ¢ç´¢åœ¨ **dimensionality reduction** å’Œ **representation learning** ä¸­çš„åº”ç”¨ï¼›
- è®¾è®¡è‡ªåŠ¨è¶…å‚æ•°ä¼˜åŒ–ç­–ç•¥ï¼ˆå¦‚è´å¶æ–¯ä¼˜åŒ–ï¼‰ä»¥å‡å°‘äººå·¥å¹²é¢„ï¼›
- åº”ç”¨äºæ›´å¤šçœŸå®å¤šè§†å›¾åœºæ™¯ï¼Œå¦‚åŒ»å­¦å½±åƒï¼ˆMRI/PETï¼‰ã€å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«ç­‰ã€‚

---

## æ€»ç»“
> **TMvRKM æ˜¯ä¸€ç§æ–°é¢–é«˜æ•ˆçš„å¤šè§†å›¾åˆ†ç±»æ¨¡å‹ï¼Œé€šè¿‡èåˆ RKMã€Twin å­¦ä¹ ä¸å¤šè§†å›¾èåˆæœºåˆ¶ï¼Œåœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶å¤§å¹…æå‡è®¡ç®—æ•ˆç‡ã€‚å®éªŒè¯æ˜å…¶åœ¨å¤šç§åŸºå‡†æ•°æ®é›†ä¸Šä¼˜äºä¸»æµ MvSVM ç±»æ–¹æ³•ï¼Œå…·å¤‡è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œæ˜¯å¤šè§†å›¾å­¦ä¹ é¢†åŸŸçš„ä¸€é¡¹é‡è¦è¿›å±•ã€‚**

</details>

---

### 12. [Meta-RL Induces Exploration in Language Agents](https://arxiv.org/abs/2512.16848)

**Authors**: Yulun Jiang, Liangze Jiang, Damien Teney, Michael Moor, Maria Brbic  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.16848v1  

#### Abstract
Reinforcement learning (RL) has enabled the training of large language model (LLM) agents to interact with the environment and to solve multi-turn long-horizon tasks. However, the RL-trained agents often struggle in tasks that require active exploration and fail to efficiently adapt from trial-and-e...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMeta-RL Induces Exploration in Language Agents

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº **Reinforcement Learning (RL)** è®­ç»ƒçš„ **Large Language Model (LLM) agents** åœ¨éœ€è¦ä¸»åŠ¨æ¢ç´¢ï¼ˆactive explorationï¼‰çš„ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œéš¾ä»¥ä»è¯•é”™ç»éªŒä¸­é«˜æ•ˆé€‚åº”ã€‚æ ‡å‡† RL æ–¹æ³•å€¾å‘äºåœ¨è®­ç»ƒä¸­æ”¶æ•›åˆ°å›ºå®šç­–ç•¥ï¼Œç¼ºä¹åœ¨æµ‹è¯•æ—¶åŠ¨æ€è°ƒæ•´è¡Œä¸ºçš„èƒ½åŠ›ï¼Œå°¤å…¶åœ¨ç¨€ç–å¥–åŠ±ã€é•¿è§†é‡ï¼ˆlong-horizonï¼‰ä»»åŠ¡ä¸­å®¹æ˜“é™·å…¥æ¬¡ä¼˜è§£ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šLAMER
æœ¬æ–‡æå‡º **LAMER**ï¼ˆ**LLM Agent with Meta-RL**ï¼‰ï¼Œä¸€ä¸ªåŸºäº **Meta-RL**ï¼ˆMeta-Reinforcement Learningï¼‰æ¡†æ¶çš„è¯­è¨€æ™ºèƒ½ä½“è®­ç»ƒæ–¹æ³•ï¼Œæ—¨åœ¨è®© LLM agents èƒ½å¤Ÿåœ¨æµ‹è¯•æ—¶ä¸»åŠ¨æ¢ç´¢ç¯å¢ƒå¹¶ä»åé¦ˆä¸­å­¦ä¹ ã€‚

å…¶ä¸¤å¤§æ ¸å¿ƒè®¾è®¡æ˜¯ï¼š
1. **è·¨å›åˆè®­ç»ƒæ¡†æ¶ï¼ˆCross-episode Training Frameworkï¼‰**  
   å°†æ¯ä¸ªä»»åŠ¡è§†ä¸ºå¤šä¸ª episode çš„åºåˆ—ï¼Œåœ¨æ—©æœŸ episode é¼“åŠ±æ¢ç´¢ä»¥æ”¶é›†å¤šæ ·åŒ–ç»éªŒï¼Œåœ¨åæœŸ episode åˆ©ç”¨è¿™äº›ç»éªŒè¿›è¡Œ exploitationã€‚é€šè¿‡æœ€å¤§åŒ–è·¨ episode çš„é•¿æœŸå›æŠ¥ï¼Œæ¨¡å‹å†…åŒ–äº†ä¸€ç§â€œæ¢ç´¢-åˆ©ç”¨â€å¹³è¡¡çš„å­¦ä¹ ç®—æ³•ã€‚

2. **ä¸Šä¸‹æ–‡ä¸­çš„ç­–ç•¥è‡ªé€‚åº”ï¼ˆIn-context Policy Adaptation via Reflectionï¼‰**  
   åœ¨æ¯ä¸ª episode ç»“æŸåï¼Œå¼•å¯¼ agent å¯¹å¤±è´¥æˆ–ä½æ•ˆè¡Œä¸ºè¿›è¡Œ **self-reflection**ï¼Œç”Ÿæˆæ–‡æœ¬å½¢å¼çš„åæ€ï¼Œå¹¶å°†å…¶ä½œä¸ºä¸Šä¸‹æ–‡è¾“å…¥ç”¨äºåç»­ episodeã€‚è¿™ç§æ— éœ€æ¢¯åº¦æ›´æ–°çš„ in-context adaptation æœºåˆ¶ï¼Œå……åˆ†åˆ©ç”¨äº† LLM çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **è¶…è¶Šçº¯æç¤ºï¼ˆpromptingï¼‰å’Œæ ‡å‡† RL æ–¹æ³•**ï¼šLAMER æ˜¾è‘—æå‡äº†åœ¨å¤æ‚ã€éƒ¨åˆ†å¯è§‚æµ‹ç¯å¢ƒä¸­çš„æˆåŠŸç‡ã€‚
- **å®ç°æµ‹è¯•æ—¶è‡ªé€‚åº”ï¼ˆtest-time adaptationï¼‰**ï¼šagent å¯åœ¨ä¸ä¿®æ”¹å‚æ•°çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡åæ€è°ƒæ•´ç­–ç•¥ï¼Œå…·å¤‡æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚
- **è¯±å¯¼æ¢ç´¢è¡Œä¸º**ï¼šMeta-RL æ¡†æ¶å¤©ç„¶é¼“åŠ±æ¢ç´¢ï¼Œé¿å…è¿‡æ—©æ”¶æ•›ï¼Œæå‡è½¨è¿¹å¤šæ ·æ€§ã€‚
- **æ›´å¥½çš„æµ‹è¯•æ—¶æ‰©å±•æ€§ï¼ˆtest-time scalingï¼‰**ï¼šéšç€å°è¯•æ¬¡æ•°å¢åŠ ï¼Œæ€§èƒ½æå‡æ›´æ˜¾è‘—ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨å››ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é•¿è§†é‡ä»»åŠ¡ç¯å¢ƒä¸­è¿›è¡Œè¯„ä¼°ï¼š
- **Sokoban**ï¼šç»å…¸æ¨ç®±å­æ¸¸æˆï¼Œå®Œå…¨å¯è§‚æµ‹ï¼Œè€ƒéªŒè§„åˆ’èƒ½åŠ›ã€‚
- **MineSweeper**ï¼šæ‰«é›·æ¸¸æˆï¼Œéƒ¨åˆ†å¯è§‚æµ‹ï¼Œéœ€é€»è¾‘æ¨ç†åˆ¤æ–­åœ°é›·ä½ç½®ã€‚
- **Webshop**ï¼šæ¨¡æ‹Ÿç”µå•†è´­ç‰©ç¯å¢ƒï¼Œagent éœ€æœç´¢ã€ç­›é€‰å¹¶è´­ä¹°ç¬¦åˆè¦æ±‚çš„å•†å“ã€‚
- **ALFWorld**ï¼šæ–‡æœ¬ç‰ˆå®¶åº­ä»»åŠ¡ç¯å¢ƒï¼ˆå¦‚åŠ çƒ­ç‰©å“ã€æ¸…æ´ç­‰ï¼‰ï¼Œéƒ¨åˆ†å¯è§‚æµ‹ï¼Œæ¨¡æ‹ŸçœŸå®ä¸–ç•Œäº¤äº’ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **åŸºç¡€æ¨¡å‹**ï¼šQwen3-4Bï¼ˆä¸»å®éªŒï¼‰ï¼Œå¹¶åœ¨ Llama3.1-8B-Instruct ä¸ŠéªŒè¯é€šç”¨æ€§ã€‚
- **è®­ç»ƒæ–¹å¼**ï¼š
  - **Meta-RL (LAMER)**ï¼šæ¯è½®ä»»åŠ¡é‡‡æ · 3 ä¸ª episodeï¼Œä½¿ç”¨è·¨ episode æŠ˜æ‰£å› å­ `Î³_traj = 0.6`ã€‚
  - **æ ‡å‡† RL**ï¼šä¸ºå…¬å¹³æ¯”è¾ƒï¼Œä½¿ç”¨ 24 ä¸ªç‹¬ç«‹ episodeï¼ˆ3Ã—8ï¼‰ï¼Œç¡®ä¿æ€»æ ·æœ¬æ•°ä¸€è‡´ã€‚
- **ä¼˜åŒ–å™¨**ï¼šé»˜è®¤ä½¿ç”¨ **GiGPO**ï¼ˆGroup-in-group Policy Optimizationï¼‰ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **pass@k**ï¼šk æ¬¡å°è¯•å†…çš„æˆåŠŸç‡è¾¾åˆ°å¤šå°‘ï¼ˆk=1,2,3ï¼‰ã€‚
  - **è½¨è¿¹å¤šæ ·æ€§ï¼ˆtrajectory diversityï¼‰**ï¼šé€šè¿‡è½¨è¿¹åˆ†å¸ƒçš„ç†µæ¥è¡¡é‡æ¢ç´¢ç¨‹åº¦ã€‚
  - **æ³›åŒ–èƒ½åŠ›**ï¼šåœ¨æ›´éš¾ä»»åŠ¡ï¼ˆincreased difficultyï¼‰å’Œæœªè§ä»»åŠ¡ï¼ˆout-of-distribution, OODï¼‰ä¸Šçš„è¡¨ç°ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• |
|------|------|
| **Prompting åŸºçº¿** | Zero-shot, ReAct, Reflexion |
| **RL åŸºçº¿** | PPO, RLOO, GRPO, GiGPO |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆpass@3 æˆåŠŸç‡ï¼‰
| æ–¹æ³• | Sokoban | MineSweeper | Webshop |
|------|---------|-------------|---------|
| **GiGPO (æœ€å¼º RL)** | 44.1% | 55.1% | 75.2% |
| **LAMER (ours)** | **55.9%** (+11.8%) | **74.4%** (+19.3%) | **89.1%** (+13.9%) |

> âœ… LAMER åœ¨æ‰€æœ‰ç¯å¢ƒä¸­å‡æ˜¾è‘—ä¼˜äº RL å’Œ prompting æ–¹æ³•ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ€§èƒ½æå‡æ˜¾è‘—**ï¼šåœ¨ Sokobanã€MineSweeper å’Œ Webshop ä¸Šåˆ†åˆ«å–å¾—çº¦ **11%ã€19%ã€14%** çš„ç»å¯¹æ€§èƒ½å¢ç›Šã€‚
- **æµ‹è¯•æ—¶æ‰©å±•æ€§æ›´å¼º**ï¼šä¾‹å¦‚åœ¨ Sokoban ä¸Šï¼ŒLAMER ä» pass@1 åˆ° pass@3 æå‡äº† **13.5%**ï¼Œè€Œ RL åŸºçº¿ä»…æå‡ä¸åˆ° 5%ï¼Œè¡¨æ˜å…¶èƒ½æœ‰æ•ˆåˆ©ç”¨å¤šæ¬¡å°è¯•è¿›è¡Œç­–ç•¥æ”¹è¿›ã€‚
- **å³ä½¿åˆå§‹è¡¨ç°ç•¥ä½ä¹Ÿèƒ½åè¶…**ï¼šåœ¨ MineSweeper å’Œ Webshop ä¸­ï¼ŒLAMER çš„ pass@1 ç•¥ä½äºæœ€ä½³ RL æ¨¡å‹ï¼Œä½†åœ¨ pass@2 å’Œ pass@3 è¿…é€Ÿåè¶…ï¼Œä½“ç°å…¶â€œå…ˆæ¢ç´¢ååˆ©ç”¨â€çš„ä¼˜åŠ¿ã€‚

### æ¶ˆèå®éªŒç»“æœ

#### (1) è·¨ episode æŠ˜æ‰£å› å­ `Î³_traj` çš„å½±å“ï¼ˆå›¾5ï¼‰
- `Î³_traj` æ§åˆ¶æ¢ç´¢ä¸åˆ©ç”¨çš„æƒè¡¡ï¼š
  - è¾ƒå°å€¼ â†’ æ›´å…³æ³¨çŸ­æœŸæ”¶ç›Šï¼ˆå¿«é€Ÿ exploitationï¼‰
  - è¾ƒå¤§å€¼ â†’ æ›´å…³æ³¨é•¿æœŸå›æŠ¥ï¼ˆé¼“åŠ± explorationï¼‰
- æœ€ä¼˜å€¼å› ä»»åŠ¡è€Œå¼‚ï¼š
  - Sokoban/Webshopï¼š`Î³_traj = 0.6` æ•ˆæœæœ€å¥½
  - MineSweeperï¼š`Î³_traj = 0.9` è¡¨ç°æœ€ä½³ï¼Œè¯´æ˜è¯¥ä»»åŠ¡å—ç›Šäºæ›´é•¿çš„ä¿¡ç”¨åˆ†é…

#### (2) è·¨ episode è®°å¿†é…ç½®æ¶ˆèï¼ˆè¡¨3ï¼‰
| è®°å¿†å†…å®¹ | Sokoban | MineSweeper | Webshop |
|--------|--------|-------------|---------|
| ä»…å†å²è½¨è¿¹ï¼ˆTrajectory-onlyï¼‰ | 34.8% | 69.5% | 89.3% |
| ä»…åæ€ï¼ˆReflection-onlyï¼‰ | **56.4%** | **80.5%** | **92.8%** |
| ä¸¤è€…éƒ½ä¿ç•™ï¼ˆBothï¼‰ | 55.9% | 74.4% | 89.1% |

> ğŸ” **å…³é”®å‘ç°**ï¼š**ä»…ä¿ç•™åæ€ï¼ˆreflection-onlyï¼‰æ•ˆæœæœ€å¥½**ï¼Œè¯´æ˜ç®€æ´ã€èšç„¦çš„åæ€æ¯”åŸå§‹è½¨è¿¹æ›´èƒ½æœ‰æ•ˆæŒ‡å¯¼ç­–ç•¥æ›´æ–°ã€‚

#### (3) å…¶ä»–è¡¥å……å®éªŒ
- **åœ¨ Llama3.1-8B ä¸ŠéªŒè¯**ï¼ˆè¡¨4ï¼‰ï¼šLAMER ä»æ˜¾è‘—ä¼˜äº GiGPOï¼Œè¯æ˜å…¶å¯¹ä¸åŒæ¶æ„å’Œè§„æ¨¡æ¨¡å‹çš„é€šç”¨æ€§ã€‚
- **RL + è·¨ episode è®°å¿† vs LAMER**ï¼ˆè¡¨5ï¼‰ï¼šå³ä½¿ç»™ RL æ·»åŠ è®°å¿†ï¼ŒLAMER ä»å¤§å¹…é¢†å…ˆï¼Œè¯´æ˜ Meta-RL æ¡†æ¶æœ¬èº«æ˜¯æ€§èƒ½æå‡çš„å…³é”®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Meta-RL æ˜¯è¯±å¯¼è¯­è¨€ agent æ¢ç´¢çš„æœ‰æ•ˆèŒƒå¼**ï¼šç›¸æ¯”æ ‡å‡† RLï¼ŒMeta-RL èƒ½è‡ªç„¶åœ°å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ï¼Œæå‡ agent çš„é€‚åº”æ€§å’Œé²æ£’æ€§ã€‚
2. **LAMER å®ç°äº†æµ‹è¯•æ—¶çš„ in-context å­¦ä¹ **ï¼šé€šè¿‡ self-reflectionï¼Œagent èƒ½åœ¨ä¸æ›´æ–°å‚æ•°çš„æƒ…å†µä¸‹åŠ¨æ€è°ƒæ•´ç­–ç•¥ï¼ŒçœŸæ­£å®ç°â€œè¾¹åšè¾¹å­¦â€ã€‚
3. **æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›**ï¼š
   - åœ¨æ›´éš¾ä»»åŠ¡ä¸Šï¼ˆå¦‚æ›´å¤šç®±å­çš„ Sokoban æˆ–æ›´å¤šåœ°é›·çš„ MineSweeperï¼‰ï¼ŒLAMER æŒç»­ä¼˜äº RLã€‚
   - åœ¨ ALFWorld çš„ out-of-distribution ä»»åŠ¡ï¼ˆCool å’Œ Pick2ï¼‰ä¸Šï¼ŒLAMER åˆ†åˆ«å–å¾— **23%** å’Œ **14%** çš„æ€§èƒ½æå‡ã€‚
4. **è½¨è¿¹å¤šæ ·æ€§æ›´é«˜**ï¼šLAMER ä¿æŒäº†æ¯” RL æ›´é«˜çš„è½¨è¿¹ç†µï¼Œè¯´æ˜å…¶æ¢ç´¢è¡Œä¸ºæ›´ä¸°å¯Œï¼Œé¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **è®­ç»ƒæ•ˆç‡è¾ƒä½**ï¼šç”±äº episode ä¹‹é—´å­˜åœ¨ä¾èµ–å…³ç³»ï¼Œæ— æ³•åƒæ ‡å‡† RL é‚£æ ·å¹¶è¡Œé‡‡æ ·ï¼Œå¯¼è‡´è®­ç»ƒæ—¶é—´çº¦ä¸º RL çš„ä¸¤å€ã€‚
2. **ä¾èµ–é«˜è´¨é‡åæ€**ï¼šself-reflection çš„è´¨é‡ç›´æ¥å½±å“ç­–ç•¥æ›´æ–°æ•ˆæœï¼Œè‹¥æ¨¡å‹åæ€èƒ½åŠ›å¼±ï¼Œå¯èƒ½æ— æ³•æœ‰æ•ˆå­¦ä¹ ã€‚
3. **æ³›åŒ–èŒƒå›´æœ‰é™**ï¼šç›®å‰ä¸»è¦åœ¨åŒç±»ä»»åŠ¡ä¸­æ³›åŒ–ï¼ˆå¦‚æ›´éš¾çš„ Sokobanï¼‰ï¼Œå°šæœªéªŒè¯åœ¨å®Œå…¨å¼‚æ„ä»»åŠ¡é—´çš„è¿ç§»èƒ½åŠ›ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æå‡è®­ç»ƒæ•ˆç‡**ï¼šæ¢ç´¢å¼‚æ­¥ rolloutã€å¹¶è¡ŒåŒ–ç­–ç•¥ç­‰æ–¹æ³•ä»¥å‡å°‘è®­ç»ƒæ—¶é—´å¼€é”€ã€‚
2. **ç»“åˆæ›´å¼ºçš„ RL ç®—æ³•æˆ–åæ€æ¡†æ¶**ï¼šå¦‚å¼•å…¥æ›´å…ˆè¿›çš„ advantage estimation æˆ–é›†æˆå¤–éƒ¨ verifier æ¥æå‡åæ€è´¨é‡ã€‚
3. **æ„å»ºé€šç”¨å‹ agent**ï¼šå°† LAMER æ‰©å±•åˆ°å¤šæ¨¡æ€ç¯å¢ƒï¼Œå¹¶æ¢ç´¢å…¶åœ¨å®Œå…¨æ–°é¢–ä»»åŠ¡ä¸Šçš„ zero-shot é€‚åº”èƒ½åŠ›ã€‚
4. **ç†è®ºåˆ†æ**ï¼šè¿›ä¸€æ­¥ç ”ç©¶ Meta-RL å¦‚ä½•åœ¨ LLM ä¸­ç¼–ç â€œå­¦ä¹ å¦‚ä½•å­¦ä¹ â€çš„æœºåˆ¶ã€‚

---

> **æ€»ç»“**ï¼šLAMER é¦–æ¬¡å°† Meta-RL æˆåŠŸåº”ç”¨äº LLM agent è®­ç»ƒï¼Œæå‡ºäº†ä¸€ç§è®©è¯­è¨€æ¨¡å‹â€œå­¦ä¼šæ¢ç´¢â€çš„ç³»ç»Ÿæ€§æ–¹æ³•ã€‚å…¶å®éªŒè¯æ˜ï¼Œé€šè¿‡è·¨ episode è®­ç»ƒå’Œ in-context åæ€ï¼ŒLLM agents èƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­æ›´æœ‰æ•ˆåœ°å­¦ä¹ ã€é€‚åº”å¹¶æ³›åŒ–ï¼Œä¸ºæ„å»ºçœŸæ­£è‡ªä¸»çš„æ™ºèƒ½ä½“æä¾›äº†é‡è¦è·¯å¾„ã€‚

</details>

---

### 13. [LADY: Linear Attention for Autonomous Driving Efficiency without Transformers](https://arxiv.org/abs/2512.15038)

**Authors**: Jihao Huang, Xi Xia, Zhiyuan Li, Tianle Liu, Jingke Wang, Junbo Chen, Tengju Ye  
**Category**: cs.AI  
**Published**: 2025-12-19  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.15038v2  

#### Abstract
End-to-end paradigms have demonstrated great potential for autonomous driving. Additionally, most existing methods are built upon Transformer architectures. However, transformers incur a quadratic attention cost, limiting their ability to model long spatial and temporal sequences-particularly on res...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# LADY: Linear Attention for Autonomous Driving Efficiency without Transformers â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰ä¸»æµçš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ¨¡å‹æ™®éä¾èµ– **Transformer æ¶æ„**è¿›è¡Œç‰¹å¾èåˆä¸è·¨æ¨¡æ€äº¤äº’ï¼Œä½†å…¶ **è‡ªæ³¨æ„åŠ›æœºåˆ¶å…·æœ‰ $O(T^2)$ çš„è®¡ç®—å’Œå†…å­˜å¤æ‚åº¦**ï¼Œåœ¨é•¿åºåˆ—æ—¶ç©ºå»ºæ¨¡ä¸­æ•ˆç‡ä½ä¸‹ï¼Œå°¤å…¶éš¾ä»¥éƒ¨ç½²äºèµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ï¼ˆå¦‚è½¦è½½èŠ¯ç‰‡ï¼‰ã€‚æ­¤å¤–ï¼Œå¤šæ•°æ–¹æ³•ä»…ä½¿ç”¨å•å¸§ä¼ æ„Ÿå™¨è¾“å…¥ï¼Œç¼ºä¹å¯¹å†å²æ—¶åºä¿¡æ¯çš„æœ‰æ•ˆåˆ©ç”¨ï¼Œå¯¼è‡´åœ¨åŠ¨æ€åœºæ™¯ä¸‹è§„åˆ’ä¿å®ˆæˆ–ä¸å®‰å…¨ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
æœ¬æ–‡æå‡º **LADY**ï¼ˆ**L**inear **A**ttention for **D**riving Efficienc**Y**ï¼‰ï¼Œæ˜¯é¦–ä¸ªå®Œå…¨åŸºäº **çº¿æ€§æ³¨æ„åŠ›ï¼ˆLinear Attentionï¼‰** çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ç”Ÿæˆæ¨¡å‹ï¼Œæ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

- **é¦–æ¬¡å®ç°å…¨çº¿æ€§æ³¨æ„åŠ›æ¶æ„**ï¼šæ‘’å¼ƒä¼ ç»Ÿ Transformerï¼Œé‡‡ç”¨ **RWKV-7** æ¨¡å—æ„å»ºç¼–ç å™¨ï¼Œå®ç°å¤šå¸§ç›¸æœºä¸ LiDAR ç‰¹å¾çš„é«˜æ•ˆèåˆï¼Œæ—¶é—´ä¸å†…å­˜å¼€é”€ä¸ºå¸¸æ•°çº§ $O(Td)$ å’Œ $O(d)$ï¼Œä¸å—å†å²å¸§æ•°å½±å“ã€‚
  
- **æå‡ºè½»é‡çº§çº¿æ€§äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼ˆLICAï¼‰**ï¼šè§£å†³ç°æœ‰çº¿æ€§æ³¨æ„åŠ›æ— æ³•æ”¯æŒè·¨æ¨¡æ€ã€è·¨æ—¶åºæŸ¥è¯¢çš„é—®é¢˜ã€‚LICA åœ¨ä¿æŒçº¿æ€§å¤æ‚åº¦çš„å‰æä¸‹ï¼Œå®ç° BEV ç‰¹å¾ä¸è½¨è¿¹æŸ¥è¯¢ä¹‹é—´çš„æœ‰æ•ˆäº¤äº’ï¼Œç¡®ä¿æ•´ä¸ªæ¨¡å‹ä»å¤´åˆ°å°¾å‡ä¸ºçº¿æ€§æ³¨æ„åŠ›è®¾è®¡ã€‚

- **æ”¯æŒæ— é™é•¿åº¦å†å²ä¸Šä¸‹æ–‡èåˆ**ï¼šåœ¨æ¨ç†é˜¶æ®µé€šè¿‡ç»´æŠ¤ä¸€ä¸ªç´§å‡‘çš„ **Temporal Hidden State**ï¼Œå¯é€å¸§æ›´æ–°å¹¶èåˆä»»æ„é•¿åº¦çš„å†å²ä¼ æ„Ÿå™¨ä¿¡æ¯ï¼Œæ˜¾è‘—å¢å¼ºå¯¹åŠ¨æ€äº¤é€šå‚ä¸è€…è¡Œä¸ºé¢„æµ‹çš„èƒ½åŠ›ã€‚

- **ç»“åˆæ‰©æ•£è§£ç å™¨æå‡å¤šæ¨¡æ€æ€§**ï¼šé‡‡ç”¨ **Truncated Diffusion Policy** ä½œä¸ºè§£ç å™¨ï¼Œç”Ÿæˆé«˜è´¨é‡ã€å¤šæ ·åŒ–çš„å€™é€‰è½¨è¿¹ï¼Œå¹¶å¼•å…¥è¯„åˆ†å¤´é€‰æ‹©æœ€ä¼˜è½¨è¿¹ï¼Œå…¼é¡¾å®‰å…¨æ€§ä¸èˆ’é€‚æ€§ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | LADY | ä¼ ç»Ÿ Transformer / DRAMA |
|------|------|--------------------------|
| **è®¡ç®—å¤æ‚åº¦** | $O(Td)$ æ—¶é—´ï¼Œ$O(d)$ å†…å­˜ | $O(T^2d)$ æ—¶é—´ï¼Œ$O(T^2 + Td)$ å†…å­˜ |
| **æ˜¯å¦æ”¯æŒå¤šå¸§å†å²** | æ”¯æŒä¸”æ¨ç†å¼€é”€æ’å®š | å¤šæ•°ä¸æ”¯æŒï¼›è‹¥æ”¯æŒåˆ™æˆæœ¬å‰§å¢ |
| **æ˜¯å¦å…¨çº¿æ€§æ³¨æ„åŠ›** | æ˜¯ï¼ˆå« cross-attentionï¼‰ | å¦ï¼ˆå³ä½¿ Mamba ä¹Ÿéœ€ Transformer åš cross-attentionï¼‰ |
| **å®æ—¶æ€§ä¸è¾¹ç¼˜éƒ¨ç½²èƒ½åŠ›** | å¼ºï¼Œåœ¨ Jetson AGX Orin ä¸ŠéªŒè¯ | å·®ï¼Œéšå¸§æ•°å¢é•¿å»¶è¿Ÿæ€¥å‰§ä¸Šå‡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **NAVSIM Benchmark**ï¼šåŸºäº nuPlan çš„ç´§å‡‘å†åˆ†å‘æ•°æ®é›†ï¼ŒåŒ…å« 120 å°æ—¶é©¾é©¶æ—¥å¿—ï¼ˆé‡‡æ ·é¢‘ç‡ 2Hzï¼‰ï¼Œæä¾›å¼€æ”¾å›è·¯ï¼ˆopen-loopï¼‰ä¸é—­åˆå›è·¯ï¼ˆclosed-loopï¼‰è¯„ä¼°æ¥å£ã€‚
- **CARLA Simulator + Bench2Drive Benchmark**ï¼šç”¨äºé—­åˆå›è·¯æµ‹è¯•ï¼Œè¯„ä¼°çœŸå®é©¾é©¶ä»»åŠ¡ä¸­çš„æˆåŠŸç‡ã€èˆ’é€‚åº¦ç­‰ç»¼åˆæ€§èƒ½ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **è¾“å…¥**ï¼š
  - å¤šå¸§ï¼ˆæœ€å¤š 10 å¸§ï¼‰ç›¸æœºå›¾åƒï¼ˆå‰è§†ä¸‰å›¾æ‹¼æ¥ä¸º 1024Ã—256ï¼‰ä¸æ …æ ¼åŒ– LiDARï¼›
  - è‡ªè½¦çŠ¶æ€ï¼ˆé€Ÿåº¦ã€åŠ é€Ÿåº¦ã€å¯¼èˆªæŒ‡ä»¤ï¼‰ï¼›
  - åˆå§‹å™ªå£°é”šè½¨è¿¹ï¼ˆanchor trajectoriesï¼‰ã€‚
- **è¾“å‡º**ï¼š
  - 8 ä¸ªèˆªç‚¹çš„å¤šæ¨¡æ€è½¨è¿¹ï¼ˆ4 ç§’ï¼Œ2Hzï¼‰ï¼›
  - è½¨è¿¹ç½®ä¿¡åº¦åˆ†æ•°ã€å¯é€šè¡Œåœ°å›¾ã€ä»–è½¦æœªæ¥çŠ¶æ€é¢„æµ‹ã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - ä½¿ç”¨ 4Ã—RTX 4090ï¼Œbatch size=4ï¼ŒAdam ä¼˜åŒ–å™¨ï¼Œè®­ç»ƒ 100 è½®ï¼›
  - é‡‡ç”¨ ResNet-34 ä½œä¸ºéª¨å¹²ç½‘ç»œæå–å›¾åƒä¸ LiDAR ç‰¹å¾ï¼›
  - æ‰©æ•£æ­¥æ•°ï¼šè®­ç»ƒæ—¶ 50 æ­¥ï¼ˆä» 1000 ä¸­æˆªæ–­ï¼‰ï¼Œæ¨ç†ä»… 2 æ­¥ã€‚

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
#### åœ¨ NAVSIM ä¸Šï¼š
- **PDMSï¼ˆPredictive Driver Model Scoreï¼‰**ï¼šç»¼åˆå¾—åˆ†ï¼Œç”±ä»¥ä¸‹å­é¡¹åŠ æƒï¼š
  - NCï¼ˆNo Collisionï¼‰ï¼šæ— ç¢°æ’ â†’ è‹¥å¤±è´¥åˆ™ PDMS=0
  - DACï¼ˆDrivable Area Complianceï¼‰ï¼šåˆè§„è¡Œé©¶
  - TTCï¼ˆTime-to-Collisionï¼‰ï¼šæœ€å°å®‰å…¨è·ç¦»
  - Comfortï¼šåŠ é€Ÿåº¦ä¸æ€¥åŠ¨åº¦æ§åˆ¶
  - EPï¼ˆEgo Progressï¼‰ï¼šæ²¿è·¯çº¿å‰è¿›ç¨‹åº¦

#### åœ¨ Bench2Drive ä¸Šï¼š
- **é—­åˆå›è·¯æŒ‡æ ‡**ï¼šæˆåŠŸç‡è¾¾ç‡ã€é©¾é©¶å¾—åˆ†ã€èˆ’é€‚æ€§ã€æ•ˆç‡
- **å¤šèƒ½åŠ›ä»»åŠ¡è¡¨ç°**ï¼šå˜é“ã€è¶…è½¦ã€ç´§æ€¥åˆ¶åŠ¨ã€è®©è¡Œã€äº¤é€šæ ‡å¿—è¯†åˆ«ç­‰

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
åŒ…æ‹¬ï¼š
- **UniAD**, **Transfuser**, **VADv2**, **Hydra-MDP**, **DiffusionDrive**, **iPad**
- **DRAMA**ï¼ˆMamba-basedï¼Œéƒ¨åˆ†çº¿æ€§ï¼‰
- æ‰€æœ‰æ¨¡å‹å‡ä½¿ç”¨ç›¸åŒ ResNet-34 éª¨å¹²ä»¥ä¿è¯å…¬å¹³æ¯”è¾ƒ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆNAVSIM æµ‹è¯•é›†ï¼‰

| æ–¹æ³• | NC | DAC | TTC | Comfort | EP | **PDMS** |
|------|----|-----|-----|---------|-----|-----------|
| UniAD | 97.8 | 91.9 | 92.9 | 100 | 78.8 | 83.4 |
| Transfuser | 97.7 | 92.8 | 92.8 | 100 | 79.2 | 84.0 |
| DRAMA | 98.0 | 93.1 | 94.8 | 100 | 80.1 | 85.5 |
| DiffusionDrive | 98.2 | 96.2 | 94.7 | 100 | 82.2 | 88.1 |
| iPad | 98.6 | 98.3 | 94.9 | 100 | 88.0 | **91.7** |
| **LADY (Ours)** | **98.0** | **97.3** | 94.0 | 100 | **88.6** | **90.9** |

> ğŸ’¡ **åˆ†æ**ï¼šLADY åœ¨ PDMS ä¸Šä»…æ¬¡äº iPadï¼Œä½†åœ¨ **EPï¼ˆè¿›åº¦ï¼‰ä¸Šè¶…è¶Šæ‰€æœ‰åŸºçº¿**ï¼Œè¯´æ˜æ›´å°‘ä¿å®ˆï¼›åŒæ—¶ **è®¡ç®—å¼€é”€è¿œä½äº iPad**ã€‚

### â±ï¸ æ¨ç†æ•ˆç‡å¯¹æ¯”ï¼ˆJetson AGX Orinï¼‰
å¦‚å›¾ 6 æ‰€ç¤ºï¼Œéšç€è¾“å…¥å¸§æ•°å¢åŠ ï¼š
- **Transfuser / DiffusionDrive**ï¼šæ¨ç†æ—¶é—´å’Œå†…å­˜å ç”¨å‘ˆ **å¹³æ–¹å¢é•¿**
- **DRAMA**ï¼šè™½ç”¨ Mamba æå‡æ•ˆç‡ï¼Œä½†ä»å›  cross-attention ä½¿ç”¨ Transformerï¼Œå¼€é”€ä»éšå¸§æ•°ä¸Šå‡
- **LADY**ï¼šç»´æŒ **æ’å®šå»¶è¿Ÿä¸å†…å­˜å ç”¨**ï¼Œæ— è®ºå†å²å¸§æ•°å¤šå°‘

ğŸ‘‰ è¿™ä½¿å¾— LADY å¯æ— ç¼æ‰©å±•è‡³â€œæ— é™å¸§â€å†å²å»ºæ¨¡ã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰ä¸åŒå†å²å¸§æ•°çš„å½±å“ï¼ˆå›ºå®šè®­ç»ƒå¸§æ•°=10ï¼‰

| å¸§æ•° | NC | DAC | TTC | EP | PDMS |
|------|----|-----|-----|-----|--------|
| 1 | 97.4 | 95.5 | 91.8 | 83.2 | 86.8 |
| 4 | 97.6 | 96.9 | 92.9 | 86.8 | 89.5 |
| 8 | 97.7 | 97.1 | 93.3 | 88.2 | 90.3 |
| 10 | 97.9 | 97.1 | 93.6 | 88.5 | 90.6 |
| 15 | 98.0 | 97.3 | 94.0 | 88.6 | **90.9** |
| 20 | 98.0 | 97.2 | 94.1 | 88.5 | **90.9** |

âœ… ç»“è®ºï¼šå³ä½¿è®­ç»ƒåªç”¨äº† 10 å¸§ï¼Œ**æ¨ç†æ—¶ä½¿ç”¨æ›´å¤šå¸§ä»èƒ½æŒç»­æå‡æ€§èƒ½**ï¼Œè¯æ˜å…¶å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œé•¿æœŸè®°å¿†ä¼˜åŠ¿ã€‚

#### ï¼ˆ2ï¼‰å¤šå¸§ DiffusionDrive å¯¹æ¯”
ä½œè€…å¤ç°äº†å¤šå¸§ç‰ˆæœ¬çš„ DiffusionDriveï¼ŒPDMS ä» 88.1 æå‡è‡³ 89.3ï¼ŒéªŒè¯äº†å¤šå¸§ä¿¡æ¯çš„ä»·å€¼ï¼Œä½†å…¶è®¡ç®—æˆæœ¬éšä¹‹é£™å‡ï¼Œè€Œ LADY åœ¨åŒç­‰æ¡ä»¶ä¸‹å®ç°äº†æ›´é«˜æ€§èƒ½ä¸”ä¿æŒé«˜æ•ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **çº¿æ€§æ³¨æ„åŠ›å¯ç”¨äºå®Œæ•´çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿ**ï¼ŒLADY æ˜¯é¦–ä¸ªå®ç° **å…¨é“¾è·¯çº¿æ€§æ³¨æ„åŠ›**ï¼ˆå« self-attention ä¸ cross-attentionï¼‰çš„æ¨¡å‹ã€‚
2. **LICA æœºåˆ¶æˆåŠŸè§£å†³äº†çº¿æ€§æ³¨æ„åŠ›ä¸­ cross-attention ç¼ºå¤±çš„é—®é¢˜**ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†é€šç”¨æ¨¡å—ã€‚
3. **é•¿æœŸå†å²ä¿¡æ¯èåˆæ˜¾è‘—æå‡è§„åˆ’è´¨é‡**ï¼Œå°¤å…¶æ˜¯åœ¨é®æŒ¡ã€çªå‘è¡Œä¸ºç­‰å¤æ‚åœºæ™¯ä¸­ï¼ŒLADY è¡¨ç°å‡ºæ›´å¼ºçš„é¢„åˆ¤èƒ½åŠ›ã€‚
4. **æ’å®šå¤æ‚åº¦ä½¿ LADY å…·å¤‡æå¼ºå®ç”¨æ€§**ï¼Œå·²åœ¨ Jetson AGX Orin ä¸Šéƒ¨ç½²éªŒè¯ï¼Œé€‚åˆå®é™…è½¦è½½å¹³å°åº”ç”¨ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰ scorerï¼ˆè¯„åˆ†å™¨ï¼‰æœªèƒ½å……åˆ†æŒ–æ˜å¤šæ¨¡æ€å€™é€‰è½¨è¿¹çš„è´¨é‡æ½œåŠ›ã€‚å½“ä½¿ç”¨ Oracle Scorerï¼ˆBest-of-Nï¼‰æ—¶ï¼ŒPDMS å¯è¾¾ **99.2**ï¼Œè¿œé«˜äºå½“å‰ 90.9ï¼Œè¡¨æ˜ **scorer æˆä¸ºæ€§èƒ½ç“¶é¢ˆ**ã€‚
- æ•°æ®é›†ä¸­éœ€è¦é•¿æ—¶åºæ¨ç†çš„æ ·æœ¬è¾ƒå°‘ï¼Œé™åˆ¶äº† LADY ä¼˜åŠ¿çš„å…¨é¢ä½“ç°ã€‚
- å½“å‰ä»ä½¿ç”¨ ResNet-34ï¼Œæœªæ¢ç´¢æ›´å…ˆè¿›çš„è§†è§‰ä¸»å¹²ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. è®¾è®¡æ›´å¼ºå¤§çš„ trajectory scorerï¼Œæå‡æœ€ä¼˜è½¨è¿¹é€‰æ‹©èƒ½åŠ›ï¼›
2. æ¢ç´¢å…¶ä»–çº¿æ€§æ³¨æ„åŠ›æ¶æ„ï¼ˆå¦‚ RetNetã€DeltaNetï¼‰é›†æˆï¼›
3. åœ¨çœŸå®è½¦è¾†ä¸Šè¿›è¡Œé—­ç¯æµ‹è¯•ä¸éƒ¨ç½²ï¼›
4. å¼•å…¥ V2X æˆ–åœ°å›¾å…ˆéªŒä¿¡æ¯è¿›ä¸€æ­¥å¢å¼ºæ„ŸçŸ¥ä¸é¢„æµ‹èƒ½åŠ›ã€‚

---

## æ€»ç»“

> **LADY å¼€åˆ›æ€§åœ°å°†çº¿æ€§æ³¨æ„åŠ›å®Œæ•´åº”ç”¨äºç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿï¼Œåœ¨ä¿è¯ SOTA è§„åˆ’æ€§èƒ½çš„åŒæ—¶ï¼Œå®ç°äº†å¸¸æ•°çº§æ¨ç†å¼€é”€ï¼Œè§£å†³äº† Transformer åœ¨é•¿åºåˆ—å»ºæ¨¡ä¸­çš„æ•ˆç‡ç“¶é¢ˆï¼Œä¸ºé«˜å®æ—¶æ€§ã€ä½åŠŸè€—è¾¹ç¼˜éƒ¨ç½²æä¾›äº†å¯è¡Œè·¯å¾„ã€‚**

å…¶æå‡ºçš„ **LICA** æœºåˆ¶å’Œ **æ— é™å†å²èåˆèƒ½åŠ›**ï¼Œæ ‡å¿—ç€è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥-å†³ç­–ä¸€ä½“åŒ–æ¶æ„å‘æ›´é«˜æ•ˆã€æ›´å…·æ‰©å±•æ€§çš„æ–¹å‘è¿ˆå‡ºå…³é”®ä¸€æ­¥ã€‚

</details>

---

### 14. [TENG++: Time-Evolving Natural Gradient for Solving PDEs With Deep Neural Nets under General Boundary Conditions](https://arxiv.org/abs/2512.15771)

**Authors**: Xinjie He, Chenggong Zhang  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.15771v1  

#### Abstract
Partial Differential Equations (PDEs) are central to modeling complex systems across physical, biological, and engineering domains, yet traditional numerical methods often struggle with high-dimensional or complex problems. Physics-Informed Neural Networks (PINNs) have emerged as an efficient altern...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTENG++: Time-Evolving Natural Gradient for Solving PDEs With Deep Neural Nets under General Boundary Conditions

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **ä¼ ç»Ÿ Physics-Informed Neural Networks (PINNs)** åœ¨å¤„ç†éå‘¨æœŸæ€§è¾¹ç•Œæ¡ä»¶ï¼ˆå¦‚ Dirichletã€Neumannï¼‰æ—¶å­˜åœ¨ç²¾åº¦ä¸è¶³å’Œè®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ã€‚
- åŸå§‹çš„ **Time-Evolving Natural Gradient (TENG)** æ–¹æ³•ä»…é€‚ç”¨äº**å‘¨æœŸæ€§è¾¹ç•Œæ¡ä»¶**ï¼Œé™åˆ¶äº†å…¶åœ¨çœŸå®ç‰©ç†åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
- æå‡ºäº† **TENG++** â€”â€” å¯¹åŸå§‹ TENG æ¡†æ¶çš„æ‰©å±•ç‰ˆæœ¬ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†**ä»»æ„è¾¹ç•Œæ¡ä»¶**ï¼Œç‰¹åˆ«æ˜¯ **Dirichlet è¾¹ç•Œæ¡ä»¶**ã€‚
- å°†è‡ªç„¶æ¢¯åº¦ä¼˜åŒ–ï¼ˆNatural Gradient Optimizationï¼‰ä¸æ˜¾å¼æ—¶é—´æ­¥è¿›æ–¹æ³•ï¼ˆå¦‚ Euler å’Œ Heun æ–¹æ³•ï¼‰ç»“åˆï¼Œå½¢æˆä¸€ä¸ªç¨³å®šä¸”é«˜æ•ˆçš„æ±‚è§£æ¡†æ¶ã€‚
- åœ¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥**è¾¹ç•Œæƒ©ç½šé¡¹**ï¼ˆpenalty termsï¼‰ï¼Œå®ç°å¯¹ Dirichlet æ¡ä»¶çš„ç²¾ç¡®æ–½åŠ ï¼š
  $$
  \mathcal{L}_{\text{Dirichlet}} = \mathcal{L}_{\text{PDE}} + \lambda_{\text{Dirichlet}} \|u(x_{\text{boundary}}) - u_{\text{Dirichlet}}\|^2
  $$

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **è¾¹ç•Œæ¡ä»¶æ”¯æŒ** | æ”¯æŒéå‘¨æœŸæ€§è¾¹ç•Œæ¡ä»¶ï¼ˆå¦‚ Dirichletï¼‰ï¼Œè€ŒåŸç‰ˆ TENG ä»…æ”¯æŒå‘¨æœŸæ€§æ¡ä»¶ |
| **æ•°å€¼ç¨³å®šæ€§** | åˆ©ç”¨ Natural Gradient è°ƒæ•´å‚æ•°æ›´æ–°æ–¹å‘ï¼Œæå‡ä¼˜åŒ–è¿‡ç¨‹çš„å‡ ä½•ä¸€è‡´æ€§ä¸æ”¶æ•›ç¨³å®šæ€§ |
| **é«˜é˜¶ç²¾åº¦æ½œåŠ›** | é›†æˆ Heun æ–¹æ³•ç­‰äºŒé˜¶æ—¶é—´ç§¯åˆ†å™¨ï¼Œæ˜¾è‘—æé«˜æ—¶é—´æ¼”åŒ–ç²¾åº¦ |
| **æ¨¡å—åŒ–è®¾è®¡** | å¯çµæ´»æ›¿æ¢ä¸åŒæ—¶é—´æ­¥è¿›æ–¹æ¡ˆï¼ˆEuler / Heunï¼‰ï¼Œä¾¿äºæ‹“å±•è‡³æ›´é«˜é˜¶æ–¹æ³•ï¼ˆå¦‚ RK4ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†ä¸é—®é¢˜è®¾å®š
- **ç›®æ ‡æ–¹ç¨‹**ï¼šäºŒç»´å„å‘åŒæ€§çƒ­ä¼ å¯¼æ–¹ç¨‹ï¼ˆheat equationï¼‰
  $$
  \frac{\partial u}{\partial t} = D \nabla^2 u, \quad D = 0.1
  $$
- **ç©ºé—´åŸŸ**ï¼šå•ä½åœ†ç›˜ $\Omega = B(0,1) \subset \mathbb{R}^2$
- **è¾¹ç•Œæ¡ä»¶**ï¼šDirichlet æ¡ä»¶ $u(x,t) = 0, \forall x \in \partial\Omega$
- **åˆå§‹æ¡ä»¶**ï¼šç”± Bessel å‡½æ•°æ„æˆçš„çº¿æ€§ç»„åˆï¼ˆdisk harmonicsï¼‰ï¼Œç¡®ä¿æœ‰è§£æè§£ç”¨äºè¯¯å·®è¯„ä¼°

### âš™ï¸ å®éªŒè®¾ç½®
| å‚æ•° | è®¾ç½® |
|------|------|
| æ—¶é—´èŒƒå›´ | Euler: $T=0.8$ï¼›Heun: $T=4$ |
| æ—¶é—´æ­¥é•¿ | Euler: $dt=0.001$ï¼›Heun: $dt=0.005$ |
| æ€»è¿­ä»£æ­¥æ•° | 800 æ­¥ |
| æ¯æ­¥ä¼˜åŒ–æ¬¡æ•° | 5 æ¬¡ Natural Gradient æ›´æ–° |
| ç½‘ç»œé‡‡æ ·ç‚¹æ•° | 65536 ä¸ªéšæœºç©ºé—´ç‚¹ |
| åˆå§‹åŒ–æ–¹å¼ | å®éªŒ1ï¼šé¢„è®­ç»ƒæƒé‡ï¼›å®éªŒ2ï¼šåŒç½‘ç»œå·®åˆ†åˆå§‹åŒ–ï¼ˆone frozenï¼‰ |

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
- **è¯¯å·®åº¦é‡**ï¼šé¢„æµ‹è§£ä¸çœŸå®è§£æè§£ä¹‹é—´çš„ $L^2$ è¯¯å·®éšæ—¶é—´çš„å˜åŒ–
- **å¯è§†åŒ–è¾“å‡º**ï¼šç»˜åˆ¶â€œError vs Tâ€æ›²çº¿ï¼Œåˆ†åˆ«å±•ç¤ºä¸¤ä¸ªåæ ‡æ–¹å‘åŠæ€»ä½“è¯¯å·®

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **TENG_Euler**ï¼šåŸºäºä¸€é˜¶ Euler æ—¶é—´ç§¯åˆ†çš„ TENG++
- **TENG_Heun**ï¼šåŸºäºäºŒé˜¶ Heun æ–¹æ³•çš„ TENG++
- ï¼ˆéšå«å¯¹æ¯”ï¼‰åŸå§‹ TENGï¼ˆä»…æ”¯æŒå‘¨æœŸè¾¹ç•Œï¼‰ã€æ ‡å‡† PINNï¼ˆæ— è‡ªç„¶æ¢¯åº¦ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### âœ… å…³é”®æ€§èƒ½æ•°æ®
| æ–¹æ³• | æœ€ç»ˆè¯¯å·®æ°´å¹³ | æ—¶é—´æ­¥é•¿ | é€‚ç”¨åœºæ™¯ |
|------|---------------|----------|---------|
| **TENG_Euler** | ~$2 \times 10^{-3}$ | 0.001 | å¿«é€Ÿä½ç²¾åº¦æ¨æ–­ |
| **TENG_Heun** | <$10^{-4}$ | 0.005 | é«˜ç²¾åº¦é•¿æ—¶é—´æ¨¡æ‹Ÿ |

> å›¾1ï¼ˆTENG_Heunï¼‰æ˜¾ç¤ºè¯¯å·®åœ¨æ•´ä¸ª $T=4$ æ—¶é—´åŒºé—´å†…ä¿æŒåœ¨ $10^{-4}$ é‡çº§ä»¥ä¸‹ï¼Œè¡¨ç°å‡ºä¼˜å¼‚çš„ç´¯ç§¯è¯¯å·®æ§åˆ¶èƒ½åŠ›ã€‚

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **TENG_Heun æ˜¾è‘—ä¼˜äº TENG_Euler**ï¼š
  - å°½ç®¡ Heun ä½¿ç”¨æ›´å¤§çš„æ—¶é—´æ­¥é•¿ï¼ˆ5å€äº Eulerï¼‰ï¼Œä½†æœ€ç»ˆè¯¯å·®ä½ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Šã€‚
  - å½’å› äº Heun çš„äºŒé˜¶ä¿®æ­£æœºåˆ¶æœ‰æ•ˆæŠ‘åˆ¶äº†è¯¯å·®ä¼ æ’­ã€‚
- **TENG_Euler æ›´é«˜æ•ˆä½†ç²¾åº¦æœ‰é™**ï¼š
  - é€‚åˆç®€å•æˆ–å®æ—¶æ€§è¦æ±‚é«˜çš„ä»»åŠ¡ã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆInitialization Impactï¼‰
- **å®éªŒ1ï¼ˆé¢„è®­ç»ƒåˆå§‹åŒ–ï¼‰**ï¼šè¯¯å·®å¿«é€Ÿä¸‹é™å¹¶ç¨³å®šåœ¨ $10^{-4}$ ä»¥å†…ã€‚
- **å®éªŒ2ï¼ˆåŒç½‘ç»œ + å†»ç»“åˆå§‹åŒ–ï¼‰**ï¼šè¯¯å·®æ˜¾è‘—å¢å¤§ï¼Œæ”¶æ•›ç¼“æ…¢ã€‚
- **ç»“è®º**ï¼šè‰¯å¥½çš„å‚æ•°åˆå§‹åŒ–å¯¹ TENG++ çš„æ€§èƒ½è‡³å…³é‡è¦ï¼Œç›´æ¥å½±å“æ”¶æ•›é€Ÿåº¦å’Œæœ€ç»ˆç²¾åº¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **TENG++ æˆåŠŸå°† TENG æ¡†æ¶æ¨å¹¿åˆ° Dirichlet è¾¹ç•Œæ¡ä»¶**ï¼Œè§£å†³äº†åŸæœ‰æ–¹æ³•æ— æ³•å¤„ç†ä¸€èˆ¬è¾¹ç•Œçš„å±€é™ã€‚
2. **Heun æ–¹æ³•åœ¨ç²¾åº¦ä¸Šæ˜æ˜¾ä¼˜äº Euler æ–¹æ³•**ï¼ŒéªŒè¯äº†é«˜é˜¶æ—¶é—´ç§¯åˆ†åœ¨ç¥ç» PDE æ±‚è§£ä¸­çš„æœ‰æ•ˆæ€§ã€‚
3. **Natural Gradient æä¾›äº†æ›´ç¨³å®šçš„ä¼˜åŒ–è·¯å¾„**ï¼Œæœ‰åŠ©äºå¹³è¡¡ PDE æ®‹å·®æœ€å°åŒ–ä¸è¾¹ç•Œçº¦æŸæ»¡è¶³ã€‚
4. **åˆå§‹åŒ–ç­–ç•¥å¯¹æ¨¡å‹è¡¨ç°å½±å“å·¨å¤§**ï¼Œåˆç†çš„å…ˆéªŒçŸ¥è¯†æ³¨å…¥å¯å¤§å¹…æå‡è®­ç»ƒæ•ˆç‡å’Œæœ€ç»ˆç²¾åº¦ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»…éªŒè¯äº† **Dirichlet æ¡ä»¶**ï¼Œå°šæœªæµ‹è¯• Neumann æˆ–æ··åˆè¾¹ç•Œæ¡ä»¶ã€‚
- æ‰€æœ‰å®éªŒåŸºäºè§„åˆ™å‡ ä½•ï¼ˆåœ†å½¢åŒºåŸŸï¼‰ï¼Œå¤æ‚å‡ ä½•ä¸‹çš„æ³›åŒ–èƒ½åŠ›å¾…éªŒè¯ã€‚
- è®­ç»ƒä¾èµ–é«˜è´¨é‡åˆå§‹çŒœæµ‹ï¼ˆå¦‚é¢„è®­ç»ƒæƒé‡ï¼‰ï¼Œå†·å¯åŠ¨æ€§èƒ½è¾ƒå¼±ã€‚
- å°šæœªä¸å…¶ä»–å…ˆè¿›æ–¹æ³•ï¼ˆå¦‚ DeepONetã€Fourier Neural Operatorï¼‰è¿›è¡Œæ¨ªå‘æ¯”è¾ƒã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³ Neumann ä¸ Mixed Boundary Conditions**
   - å¼•å…¥æ³•å‘å¯¼æ•°æƒ©ç½šé¡¹æˆ– Lagrange multiplier æœºåˆ¶ã€‚
2. **åº”ç”¨äºæ›´å¹¿æ³›çš„ PDE ç±»å‹**
   - å¦‚éçº¿æ€§ PDEï¼ˆNavier-Stokesï¼‰ã€æ³¢åŠ¨æ–¹ç¨‹ã€ååº”æ‰©æ•£ç³»ç»Ÿã€‚
3. **é›†æˆæ›´é«˜é˜¶æ—¶é—´ç§¯åˆ†å™¨**
   - å¦‚ Runge-Kutta (RK4) æ–¹æ³•ï¼Œè¿›ä¸€æ­¥æå‡é•¿æœŸæ¨¡æ‹Ÿç²¾åº¦ã€‚
4. **æ¢ç´¢è‡ªé€‚åº”æ—¶é—´æ­¥é•¿ä¸åŠ¨æ€é‡‡æ ·ç­–ç•¥**
   - æé«˜è®¡ç®—èµ„æºåˆ©ç”¨æ•ˆç‡ã€‚
5. **ç»“åˆç‰©ç†å…ˆéªŒç»“æ„è®¾è®¡ç½‘ç»œæ¶æ„**
   - å¦‚å¯¹ç§°æ€§åµŒå…¥ã€è°±åŸºå±•å¼€ç­‰ï¼Œå¢å¼ºè¡¨ç¤ºèƒ½åŠ›ã€‚

---

## æ€»ç»“

âœ… **TENG++ æ˜¯ä¸€é¡¹é‡è¦çš„æ¨è¿›**ï¼šå®ƒä¸ä»…æ‰©å±•äº† TENG çš„é€‚ç”¨èŒƒå›´è‡³é€šç”¨è¾¹ç•Œæ¡ä»¶ï¼Œè¿˜é€šè¿‡ç»“åˆé«˜é˜¶æ—¶é—´ç§¯åˆ†ä¸è‡ªç„¶æ¢¯åº¦ä¼˜åŒ–ï¼Œåœ¨ç²¾åº¦ä¸ç¨³å®šæ€§ä¹‹é—´å–å¾—äº†è‰¯å¥½å¹³è¡¡ã€‚  
ğŸ§  ç‰¹åˆ«æ˜¯åœ¨é•¿æ—¶é—´æ¼”åŒ–é—®é¢˜ä¸­ï¼Œ**TENG_Heun å±•ç°å‡ºæ¥è¿‘æœºå™¨ç²¾åº¦çš„æ½œåŠ›**ï¼Œä¸ºç¥ç»ç½‘ç»œæ±‚è§£ PDE æä¾›äº†ä¸€æ¡å¯é è·¯å¾„ã€‚  
ğŸš€ ç»“åˆåˆç†åˆå§‹åŒ–ä¸æœªæ¥å¯¹ Neumann/mixed æ¡ä»¶çš„æ”¯æŒï¼Œè¯¥æ¡†æ¶æœ‰æœ›æˆä¸ºç§‘å­¦è®¡ç®—ä¸­æ–°ä¸€ä»£ PDE æ±‚è§£å™¨çš„é‡è¦å€™é€‰ã€‚

</details>

---

### 15. [Boosting t-SNE Efficiency for Sequencing Data: Insights from Kernel Selection](https://arxiv.org/abs/2512.15900)

**Authors**: Avais Jan, Prakash Chourasia, Sarwan Ali, Murray Patterson  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.15900v1  

#### Abstract
Dimensionality reduction techniques are essential for visualizing and analyzing high-dimensional biological sequencing data. t-distributed Stochastic Neighbor Embedding (t-SNE) is widely used for this purpose, traditionally employing the Gaussian kernel to compute pairwise similarities. However, the...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šBoosting t-SNE Efficiency for Sequencing Data: Insights from Kernel Selection

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**é«˜ç»´ç”Ÿç‰©åºåˆ—æ•°æ®**ï¼ˆå¦‚SARS-CoV-2åˆºçªè›‹ç™½åºåˆ—ï¼‰åœ¨è¿›è¡Œå¯è§†åŒ–å’Œåˆ†ææ—¶ï¼Œä¼ ç»Ÿt-SNEæ–¹æ³•å­˜åœ¨çš„ä¸¤ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š
1.  **æ ¸å‡½æ•°é€‰æ‹©ä¸å½“**ï¼šä¼ ç»Ÿçš„t-SNEé»˜è®¤ä½¿ç”¨**Gaussian Kernel**ï¼ˆåŸºäºæ¬§æ°è·ç¦»ï¼‰ï¼Œè€Œç”Ÿç‰©åºåˆ—æ˜¯ç¦»æ•£çš„ç±»åˆ«å‹æ•°æ®ï¼Œæ¬§æ°è·ç¦»æ— æ³•æœ‰æ•ˆæ•æ‰å…¶å†…åœ¨çš„ç›¸ä¼¼æ€§ï¼ˆå¦‚ç¼–è¾‘è·ç¦»ï¼‰ã€‚
2.  **è®¡ç®—æ•ˆç‡ä½ä¸‹**ï¼šGaussian Kernelå’Œè¿‘æœŸæå‡ºçš„Isolation Kernelè®¡ç®—å¼€é”€å¤§ï¼Œéš¾ä»¥æ‰©å±•åˆ°å¤§è§„æ¨¡æµ‹åºæ•°æ®ã€‚

### æå‡ºçš„æ–°æ–¹æ³•/æ–°æ€è·¯
è®ºæ–‡æå‡ºäº†ä¸€ç§ç³»ç»Ÿæ€§çš„è§£å†³æ–¹æ¡ˆï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äº**æ ¸å‡½æ•°ï¼ˆKernelï¼‰çš„é€‰æ‹©**ï¼š
- **å…¨é¢è¯„ä¼°å¤šç§æ ¸å‡½æ•°**ï¼šé¦–æ¬¡å¯¹åº”ç”¨äºt-SNEçš„ä¹ç§ä¸åŒæ ¸å‡½æ•°è¿›è¡Œäº†ç»¼åˆè¯„ä¼°ï¼ŒåŒ…æ‹¬ï¼š**Cosine Similarity**, Linear, Polynomial, Gaussian, Isolation, Laplacian, Sigmoid, Chi-squared, å’Œ Additive-chi2ã€‚
- **æ¨èæœ€ä¼˜æ ¸å‡½æ•°**ï¼šé€šè¿‡å¤§é‡å®éªŒè¯æ˜ï¼Œåœ¨å¤„ç†åˆ†å­åºåˆ—æ•°æ®æ—¶ï¼Œ**Cosine Similarity Kernel** æ˜¯ä¸€ä¸ªæ›´ä¼˜çš„é€‰æ‹©ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ€§èƒ½æ›´ä¼˜**ï¼šCosine Similarity Kernel åœ¨ä¿ç•™åŸå§‹é«˜ç»´ç©ºé—´ä¸­çš„æˆå¯¹è·ç¦»å…³ç³»æ–¹é¢è¡¨ç°æœ€ä½³ï¼Œä¼˜äºå¹¿æ³›ä½¿ç”¨çš„Gaussian Kernelå’Œæ–°è¿‘æå‡ºçš„Isolation Kernelã€‚
- **æ•ˆç‡æ›´é«˜**ï¼šCosine Similarity Kernel å…·æœ‰å“è¶Šçš„è®¡ç®—æ•ˆç‡ï¼Œå…¶è¿è¡Œæ—¶é—´éšåºåˆ—æ•°é‡å‘ˆ**çº¿æ€§å¢é•¿**ï¼Œè¿œå¿«äºGaussian Kernelã€‚
- **é€‚ç”¨æ€§å¹¿**ï¼šè¯¥ç»“è®ºä¸ä»…é€‚ç”¨äºå¯è§†åŒ–è´¨é‡ï¼Œè¿˜æ˜¾è‘—æå‡äº†ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚åˆ†ç±»å’Œèšç±»ï¼‰çš„æ€§èƒ½ã€‚

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
ç ”ç©¶åœ¨å…­ä¸ªå¤šæ ·åŒ–çš„ç”Ÿç‰©æ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œæ¶µç›–äº†ç—…æ¯’åŸºå› ç»„ã€å®¿ä¸»æ¥æºå’ŒæŠ—ç™Œè‚½ç­‰ä¸åŒç±»å‹ï¼š
- **Spike7k**: 7,000æ¡SARS-CoV-2åˆºçªè›‹ç™½åºåˆ—ï¼Œ22ä¸ªè°±ç³»ã€‚
- **Host**: 5,558æ¡å† çŠ¶ç—…æ¯’åˆºçªè›‹ç™½åºåˆ—ï¼Œæ¥è‡ª21ç§ä¸åŒå®¿ä¸»ã€‚
- **ShortRead**: 10,181æ¡æ¨¡æ‹Ÿçš„SARS-CoV-2çŸ­è¯»é•¿åºåˆ—ã€‚
- **Rabies**: 20,051æ¡ç‹‚çŠ¬ç—…æ¯’åŸºå› ç»„åºåˆ—ã€‚
- **Genome**: 8,220æ¡å®Œæ•´çš„SARS-CoV-2åŸºå› ç»„åºåˆ—ã€‚
- **Breast Cancer**: 949æ¡è†œè£‚è§£æŠ—ç™Œè‚½ï¼ˆACPsï¼‰åºåˆ—ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **åµŒå…¥æ–¹æ³•**ï¼šä½¿ç”¨ä¸‰ç§æ–¹æ³•å°†åºåˆ—è½¬æ¢ä¸ºæ•°å€¼å‘é‡ï¼š
  - **One-Hot Encoding (OHE)**
  - **Spike2Vec** (word2vecå¯å‘çš„æ·±åº¦å­¦ä¹ æ–¹æ³•)
  - **Minimizers** (k-merçš„å‹ç¼©è¡¨ç¤º)
  - ï¼ˆéƒ¨åˆ†å®éªŒè¿˜åŒ…æ‹¬Spaced k-mersï¼‰
- **è¯„ä¼°ç»´åº¦**ï¼š
  1.  **t-SNEå¯è§†åŒ–è´¨é‡**ï¼š
      - **ä¸»è§‚è¯„ä¼°**ï¼šé€šè¿‡2D/3Dæ•£ç‚¹å›¾è§‚å¯Ÿç°‡çš„åˆ†ç¦»æƒ…å†µã€‚
      - **å®¢è§‚è¯„ä¼°**ï¼šä½¿ç”¨ **AUCRNx** (Area Under the RNX curve) æŒ‡æ ‡é‡åŒ–é‚»åŸŸä¿ç•™åº¦ï¼ˆNeighborhood Preservationï¼‰ã€‚
  2.  **ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½**ï¼š
      - **åˆ†ç±»**ï¼šä½¿ç”¨7ç§MLç®—æ³•ï¼ˆSVM, NB, MLP, KNN, RF, LR, DTï¼‰ï¼Œè¯„ä¼°å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ã€ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰ã€å¬å›ç‡ï¼ˆRecallï¼‰ã€F1åˆ†æ•°å’ŒAUCã€‚
      - **èšç±»**ï¼šä½¿ç”¨k-meanså’Œk-modesï¼Œè¯„ä¼°è½®å»“ç³»æ•°ï¼ˆSilhouette Coefficientï¼‰ã€Calinski-HarabaszæŒ‡æ•°å’ŒDavies-Bouldinå¾—åˆ†ã€‚
  3.  **è®¡ç®—æ•ˆç‡**ï¼šè®°å½•æ ¸çŸ©é˜µè®¡ç®—æ—¶é—´å’Œt-SNEæ€»è¿è¡Œæ—¶é—´ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ä¸»è¦åŸºçº¿**ï¼šä¼ ç»Ÿçš„ **Gaussian Kernel** å’Œè¿‘æœŸæå‡ºçš„ **Isolation Kernel**ã€‚
- **å¯¹æ¯”å¯¹è±¡**ï¼šè®ºæ–‡æå‡ºçš„ **Cosine Similarity Kernel** ä»¥åŠå…¶ä»–ä¸ƒç§æ ¸å‡½æ•°ã€‚

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ
- **t-SNEæ€§èƒ½ (ä»¥Spike7kæ•°æ®é›†ä¸ºä¾‹)**ï¼š
  - **AUCRNxå€¼**ï¼šCosine Similarity Kernel (Spike2VecåµŒå…¥) è¾¾åˆ°äº† **0.331**ï¼Œæ˜¾è‘—é«˜äºGaussian Kernel (0.235) å’Œ Isolation Kernel (0.189)ã€‚
  - **è®¡ç®—æ—¶é—´**ï¼šCosine Similarity Kernelçš„æ ¸è®¡ç®—æ—¶é—´ï¼ˆ15.865ç§’ï¼‰è¿œä½äºGaussian Kernelï¼ˆ54.192ç§’ï¼‰å’ŒIsolation Kernelï¼ˆ24.162ç§’ï¼‰ã€‚

- **åˆ†ç±»æ€§èƒ½**ï¼š
  - åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šï¼Œ**Linear** å’Œ **Cosine** Kernel è¡¨ç°ä¼˜å¼‚ã€‚ä¾‹å¦‚ï¼Œåœ¨Spike7kæ•°æ®é›†ä¸Šï¼ŒLinear Kernelé…åˆRandom Forestè¾¾åˆ°äº†æ¥è¿‘80%çš„å‡†ç¡®ç‡ã€‚
  - **Isolation Kernel** åœ¨OHEå’Œk-meråµŒå…¥ä¸Šçš„è¡¨ç°æå·®ï¼Œå‡†ç¡®ç‡å¸¸æ¥è¿‘éšæœºæ°´å¹³ï¼ˆ~0.5ï¼‰ï¼Œè¡¨æ˜å…¶ä¸è¿™äº›è¡¨ç¤ºä¸å…¼å®¹ã€‚

- **èšç±»æ€§èƒ½**ï¼š
  - ç»“æœé«˜åº¦ä¾èµ–äºæ•°æ®é›†å’ŒåµŒå…¥æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨Hostæ•°æ®é›†ä¸Šï¼ŒPolynomial Kernelé…åˆk-meanså–å¾—äº†é«˜è¾¾0.975çš„è½®å»“ç³»æ•°ã€‚

- **è®¡ç®—æ•ˆç‡**ï¼š
  - **Runtime Analysis** å›¾æ˜¾ç¤ºï¼Œ**Cosine Similarity Kernel** çš„è®¡ç®—æ—¶é—´å¢é•¿æœ€å¹³ç¼“ï¼Œå‘ˆç°è‰¯å¥½çš„çº¿æ€§ç¼©æ”¾è¡Œä¸ºï¼Œè€ŒGaussian Kernelçš„è®¡ç®—æˆæœ¬æœ€é«˜ã€‚

### æ¶ˆèå®éªŒç»“æœ
è™½ç„¶æ²¡æœ‰æ˜ç¡®æ ‡æ³¨ä¸ºâ€œæ¶ˆèå®éªŒâ€ï¼Œä½†è®ºæ–‡é€šè¿‡ä»¥ä¸‹æ–¹å¼å®ç°äº†ç±»ä¼¼æ•ˆæœï¼š
- **è·¨æ•°æ®é›†éªŒè¯**ï¼šåœ¨6ä¸ªæˆªç„¶ä¸åŒçš„æ•°æ®é›†ä¸Šé‡å¤å®éªŒï¼Œè¯æ˜äº†ç»“è®ºçš„æ™®é€‚æ€§ã€‚
- **è·¨åµŒå…¥æ–¹æ³•éªŒè¯**ï¼šåœ¨OHEã€Spike2Vecã€Minimizersç­‰å¤šç§åµŒå…¥æ–¹æ³•ä¸‹æµ‹è¯•ï¼Œè¯æ˜äº†Cosine Kernelçš„é²æ£’æ€§ã€‚
- **å¤šä»»åŠ¡éªŒè¯**ï¼šä¸ä»…è¯„ä¼°äº†t-SNEçš„é™ç»´è´¨é‡ï¼Œè¿˜è¯„ä¼°äº†å…¶å¯¹åˆ†ç±»å’Œèšç±»ç­‰ä¸‹æ¸¸ä»»åŠ¡çš„å½±å“ï¼Œå…¨é¢å±•ç¤ºäº†æ ¸å‡½æ•°é€‰æ‹©çš„é‡è¦æ€§ã€‚

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1.  **æ ¸å‡½æ•°è‡³å…³é‡è¦**ï¼šæ ¸å‡½æ•°çš„é€‰æ‹©å¯¹t-SNEçš„æ€§èƒ½æœ‰æ ¹æœ¬æ€§å½±å“ï¼Œä¸åº”è¢«è§†ä¸ºä¸€ä¸ªæ— å…³ç´§è¦çš„æŠ€æœ¯ç»†èŠ‚ã€‚
2.  **Cosine Similarityæ˜¯æ›´ä¼˜é€‰æ‹©**ï¼šå¯¹äºç”Ÿç‰©åºåˆ—æ•°æ®ï¼Œ**Cosine Similarity Kernel** åœ¨**æ€§èƒ½**å’Œ**æ•ˆç‡**ä¸Šå‡ä¼˜äºä¼ ç»Ÿçš„Gaussian Kernelå’ŒIsolation Kernelã€‚
3.  **Gaussian Kernelå­˜åœ¨ç¼ºé™·**ï¼šåŸºäºæ¬§æ°è·ç¦»çš„Gaussian Kernel ä¸é€‚åˆæ•æ‰ç¦»æ•£åºåˆ—é—´çš„ç›¸ä¼¼æ€§ï¼Œå¯¼è‡´åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°ä¸ä½³ã€‚
4.  **åµŒå…¥æ–¹æ³•ä¸æ ¸å‡½æ•°ç›¸äº’ä½œç”¨**ï¼šæœ€ä½³çš„æ ¸å‡½æ•°é€‰æ‹©ä¹Ÿä¾èµ–äºæ‰€ä½¿ç”¨çš„åºåˆ—åµŒå…¥æ–¹æ³•ï¼Œä¸å­˜åœ¨ä¸€ä¸ªç»å¯¹é€šç”¨çš„â€œæœ€ä½³â€ç»„åˆã€‚
5.  **æ•ˆç‡ä¼˜åŠ¿æ˜æ˜¾**ï¼šCosine Kernelçš„çº¿æ€§æ—¶é—´å¤æ‚åº¦ä½¿å…¶ç‰¹åˆ«é€‚åˆå¤„ç†å¤§è§„æ¨¡æµ‹åºæ•°æ®ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å¹¶éæ‰€æœ‰åœºæ™¯éƒ½æœ€ä¼˜**ï¼šå°½ç®¡Cosine Kernelæ€»ä½“è¡¨ç°æœ€å¥½ï¼Œä½†åœ¨æŸäº›ç‰¹å®šæ•°æ®é›†ï¼ˆå¦‚Breast Cancerï¼‰å’Œä»»åŠ¡ä¸­ï¼Œå…¶ä»–æ ¸å‡½æ•°ï¼ˆå¦‚Chi-squaredï¼‰å¯èƒ½è¡¨ç°æ›´å¥½ã€‚
- **Isolation Kernelçš„å±€é™æ€§**ï¼šè®ºæ–‡å‘ç°Isolation Kernelåœ¨OHEå’Œk-merç­‰æ ‡å‡†åµŒå…¥ä¸Šè¡¨ç°ç³Ÿç³•ï¼Œè¿™é™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚
- **æœªæ¢ç´¢æ‰€æœ‰å¯èƒ½æ€§**ï¼šç ”ç©¶èšç„¦äºä¹ç§æ ¸å‡½æ•°ï¼Œå¯èƒ½å­˜åœ¨å…¶ä»–æ›´é€‚åˆç‰¹å®šåºåˆ—ç‰¹å¾çš„æ ¸å‡½æ•°æœªè¢«æ¢ç´¢ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **æ¢ç´¢æ›´å¤šä¸“ç”¨æ ¸å‡½æ•°**ï¼šå¼€å‘ä¸“é—¨é’ˆå¯¹ç”Ÿç‰©åºåˆ—è®¾è®¡çš„æ ¸å‡½æ•°ï¼Œå¯èƒ½è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚
- **ç»“åˆUMAPç­‰æ–°æ–¹æ³•**ï¼šå°†æ ¸å‡½æ•°é€‰æ‹©çš„ç ”ç©¶æ‰©å±•åˆ°UMAPç­‰å…¶ä»–æµè¡Œçš„é™ç»´æŠ€æœ¯ã€‚
- **è‡ªåŠ¨åŒ–æ ¸å‡½æ•°é€‰æ‹©**ï¼šç ”ç©¶å¦‚ä½•æ ¹æ®æ•°æ®ç‰¹å¾è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜çš„æ ¸å‡½æ•°-åµŒå…¥æ–¹æ³•ç»„åˆã€‚
- **åº”ç”¨äºæ›´å¤§è§„æ¨¡æ•°æ®**ï¼šåœ¨PBçº§çš„åŸºå› ç»„æ•°æ®åº“ä¸ŠéªŒè¯è¯¥æ–¹æ³•çš„å¯æ‰©å±•æ€§å’Œæœ‰æ•ˆæ€§ã€‚

</details>

---

### 16. [Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models](https://arxiv.org/abs/2512.15089)

**Authors**: Jinwu Hu, Dongjin Yang, Langyu Bian, Zhiquan Wen, Yufeng Wang, Yaofo Chen, Bin Xiao, Yuanqing Li, Mingkui Tan  
**Category**: cs.AI  
**Published**: 2025-12-19  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.15089v1  

#### Abstract
Large language models (LLMs) have demonstrated impressive performance across various language tasks. However, existing LLM reasoning strategies mainly rely on the LLM itself with fast or slow mode (like o1 thinking) and thus struggle to balance reasoning efficiency and accuracy across queries of var...

---

### 17. [BRAID: Bounded Reasoning for Autonomous Inference and Decisions](https://arxiv.org/abs/2512.15959)

**Authors**: Arma\u{g}an Amcalar, Eyup Cinar  
**Category**: cs.CL  
**Published**: 2025-12-19  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.15959v1  

#### Abstract
Large Language Models (LLMs) exhibit nonlinear relationships between performance, cost, and token usage. This paper presents a quantitative study on structured prompting using BRAID (Bounded Reasoning for Au tonomous Inference and Decisions) across multiple GPT model tiers, eval uated on the Advance...

---

### 18. [An Information-Theoretic Framework for Robust Large Language Model Editing](https://arxiv.org/abs/2512.16227)

**Authors**: Qizhou Chen, Chengyu Wang, Taolin Zhang, Xiaofeng He  
**Category**: cs.CL  
**Published**: 2025-12-19  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.16227v1  

#### Abstract
Large Language Models (LLMs) have become indispensable tools in science, technology, and society, enabling transformative advances across diverse fields. However, errors or outdated information within these models can undermine their accuracy and restrict their safe deployment. Developing efficient ...

---

### 19. [Semantic-Constrained Federated Aggregation: Convergence Theory and Privacy-Utility Bounds for Knowledge-Enhanced Distributed Learning](https://arxiv.org/abs/2512.15759)

**Authors**: Jahidul Arafat  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.15759v1  

#### Abstract
Federated learning enables collaborative model training across distributed data sources but suffers from slow convergence under non-IID data conditions. Existing solutions employ algorithmic modifications treating all client updates identically, ignoring semantic validity. We introduce Semantic-Cons...

---

### 20. [Stackelberg Learning from Human Feedback: Preference Optimization as a Sequential Game](https://arxiv.org/abs/2512.16626)

**Authors**: Barna P\'asztor, Thomas Kleine Buening, Andreas Krause  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.16626v1  

#### Abstract
We introduce Stackelberg Learning from Human Feedback (SLHF), a new framework for preference optimization. SLHF frames the alignment problem as a sequential-move game between two policies: a Leader, which commits to an action, and a Follower, which responds conditionally on the Leader's action. This...

---

### 21. [Posterior Behavioral Cloning: Pretraining BC Policies for Efficient RL Finetuning](https://arxiv.org/abs/2512.16911)

**Authors**: Andrew Wagenmaker, Perry Dong, Raymond Tsao, Chelsea Finn, Sergey Levine  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.16911v1  

#### Abstract
Standard practice across domains from robotics to language is to first pretrain a policy on a large-scale demonstration dataset, and then finetune this policy, typically with reinforcement learning (RL), in order to improve performance on deployment domains. This finetuning step has proved critical ...

---

### 22. [A Clustering-Based Variable Ordering Framework for Relaxed Decision Diagrams for Maximum Weighted Independent Set Problem](https://arxiv.org/abs/2512.15198)

**Authors**: Mohsen Nafar, Michael R\"omer, Lin Xie  
**Category**: cs.AI  
**Published**: 2025-12-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.15198v1  

#### Abstract
Efficient exact algorithms for Discrete Optimization (DO) rely heavily on strong primal and dual bounds. Relaxed Decision Diagrams (DDs) provide a versatile mechanism for deriving such dual bounds by compactly over-approximating the solution space through node merging. However, the quality of these ...

---

### 23. [CangLing-KnowFlow: A Unified Knowledge-and-Flow-fused Agent for Comprehensive Remote Sensing Applications](https://arxiv.org/abs/2512.15231)

**Authors**: Zhengchao Chen, Haoran Wang, Jing Yao, Pedram Ghamisi, Jun Zhou, Peter M. Atkinson, Bing Zhang  
**Category**: cs.AI  
**Published**: 2025-12-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.15231v1  

#### Abstract
The automated and intelligent processing of massive remote sensing (RS) datasets is critical in Earth observation (EO). Existing automated systems are normally task-specific, lacking a unified framework to manage diverse, end-to-end workflows--from data preprocessing to advanced interpretation--acro...

---

### 24. [JustRL: Scaling a 1.5B LLM with a Simple RL Recipe](https://arxiv.org/abs/2512.16649)

**Authors**: Bingxiang He, Zekai Qu, Zeyuan Liu, Yinghao Chen, Yuxin Zuo, Cheng Qian, Kaiyan Zhang, Weize Chen, Chaojun Xiao, Ganqu Cui, Ning Ding, Zhiyuan Liu  
**Category**: cs.CL  
**Published**: 2025-12-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.16649v1  

#### Abstract
Recent advances in reinforcement learning for large language models have converged on increasing complexity: multi-stage training pipelines, dynamic hyperparameter schedules, and curriculum learning strategies. This raises a fundamental question: \textbf{Is this complexity necessary?} We present \te...

---

### 25. [Bridging Data and Physics: A Graph Neural Network-Based Hybrid Twin Framework](https://arxiv.org/abs/2512.15767)

**Authors**: M. Gorpinich (Valeo, PIMM Lab. ENSAM Institute of Technology), B. Moya (PIMM Lab. ENSAM Institute of Technology), S. Rodriguez (PIMM Lab. ENSAM Institute of Technology), F. Meraghni (PIMM Lab. ENSAM Institute of Technology), Y. Jaafra (Valeo), A. Briot (Valeo), M. Henner (Valeo), R. Leon (Valeo), F. Chinesta (PIMM Lab. ENSAM Institute of Technology, CNRS@CREATE LTD. Singapore)  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.15767v1  

#### Abstract
Simulating complex unsteady physical phenomena relies on detailed mathematical models, simulated for instance by using the Finite Element Method (FEM). However, these models often exhibit discrepancies from the reality due to unmodeled effects or simplifying assumptions. We refer to this gap as the ...

---

### 26. [Surrogate Neural Architecture Codesign Package (SNAC-Pack)](https://arxiv.org/abs/2512.15998)

**Authors**: Jason Weitz, Dmitri Demler, Benjamin Hawks, Nhan Tran, Javier Duarte  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.15998v1  

#### Abstract
Neural Architecture Search is a powerful approach for automating model design, but existing methods struggle to accurately optimize for real hardware performance, often relying on proxy metrics such as bit operations. We present Surrogate Neural Architecture Codesign Package (SNAC-Pack), an integrat...

---

### 27. [Quantitative Verification of Fairness in Tree Ensembles](https://arxiv.org/abs/2512.16386)

**Authors**: Zhenjiang Zhao, Takahisa Toda, Takashi Kitamura  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.16386v1  

#### Abstract
This work focuses on quantitative verification of fairness in tree ensembles. Unlike traditional verification approaches that merely return a single counterexample when the fairness is violated, quantitative verification estimates the ratio of all counterexamples and characterizes the regions where ...

---

### 28. [IoMT-based Automated Leukemia Classification using CNN and Higher Order Singular Value](https://arxiv.org/abs/2512.16448)

**Authors**: Shabnam Bagheri Marzijarani, Mohammad Zolfaghari, Hedieh Sajedi  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.16448v1  

#### Abstract
The Internet of Things (IoT) is a concept by which objects find identity and can communicate with each other in a network. One of the applications of the IoT is in the field of medicine, which is called the Internet of Medical Things (IoMT). Acute Lymphocytic Leukemia (ALL) is a type of cancer categ...

---

### 29. [Graph Contextual Reinforcement Learning for Efficient Directed Controller Synthesis](https://arxiv.org/abs/2512.15295)

**Authors**: Toshihide Ubukata, Enhong Mu, Takuto Yamauchi, Mingyue Zhang, Jialong Li, Kenji Tei  
**Category**: cs.AI  
**Published**: 2025-12-19  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.15295v1  

#### Abstract
Controller synthesis is a formal method approach for automatically generating Labeled Transition System (LTS) controllers that satisfy specified properties. The efficiency of the synthesis process, however, is critically dependent on exploration policies. These policies often rely on fixed rules or ...

---

### 30. [Sigma-Moe-Tiny Technical Report](https://arxiv.org/abs/2512.16248)

**Authors**: Qingguo Hu, Zhenghao Lin, Ziyue Yang, Yucheng Ding, Xiao Liu, Yuting Jiang, Ruizhe Wang, Tianyu Chen, Zhongxin Guo, Yifan Xiong, Rui Gao, Lei Qu, Jinsong Su, Peng Cheng, Yeyun Gong  
**Category**: cs.CL  
**Published**: 2025-12-19  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.16248v1  

#### Abstract
Mixture-of-Experts (MoE) has emerged as a promising paradigm for foundation models due to its efficient and powerful scalability. In this work, we present Sigma-MoE-Tiny, an MoE language model that achieves the highest sparsity compared to existing open-source models. Sigma-MoE-Tiny employs fine-gra...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
