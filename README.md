# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-16 05:57:17 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Janus: Disaggregating Attention and Experts for Scalable MoE Inference](https://arxiv.org/abs/2512.13525)

**Authors**: Zhexiang Zhang, Ye Wang, Xiangyu Wang, Yumiao Zhao, Jingzhe Jiang, Qizhen Weng, Shaohuai Shi, Yin Chen, Minchen Yu  
**Category**: cs.DC  
**Published**: 2025-12-16  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2512.13525v1  

#### Abstract
Large Mixture-of-Experts (MoE) model inference is challenging due to high resource demands and dynamic workloads. Existing solutions often deploy the entire model as a single monolithic unit, which applies a unified resource configuration to both attention and expert modules despite their different ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šJANUS: Disaggregating Attention and Experts for Scalable MoE Inference**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å¤§å‹ Mixture-of-Experts (MoE) æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **åŠ¨æ€è´Ÿè½½**ï¼šåœ¨çº¿è¯·æ±‚çš„åˆ°è¾¾ç‡ã€è¾“å…¥/è¾“å‡ºé•¿åº¦é«˜åº¦å¯å˜ï¼Œéš¾ä»¥æ»¡è¶³ä¸¥æ ¼çš„ token-level SLOï¼ˆå¦‚ TPOTï¼‰ã€‚
- **å·¨å¤§å†…å­˜å ç”¨**ï¼šMoE æ¨¡å‹ä¸­ä¸“å®¶å‚æ•°å æ€»å†…å­˜çš„ 90% ä»¥ä¸Šï¼ˆè§ Table 1ï¼‰ï¼Œéœ€å¤§é‡ GPU æ‰èƒ½å®Œæ•´åŠ è½½ã€‚
- **å¼‚æ„è®¡ç®—éœ€æ±‚**ï¼šAttention å±‚ä¸ MoE å±‚å…·æœ‰æˆªç„¶ä¸åŒçš„èµ„æºéœ€æ±‚â€”â€”Attention æ›´åå‘è®¡ç®—å¯†é›†å‹ï¼Œè€Œ MoE æ˜¯å…¸å‹çš„ memory-boundï¼Œä¸”æ‰§è¡Œæ—¶é—´å¯¹æ¿€æ´»ä¸“å®¶æ•°é‡æ•æ„Ÿã€‚

ç°æœ‰ç³»ç»Ÿé€šå¸¸å°†æ•´ä¸ª MoE æ¨¡å‹ä½œä¸ºå•ä¸€æ•´ä½“éƒ¨ç½²ï¼ˆmonolithic designï¼‰ï¼Œé‡‡ç”¨ç»Ÿä¸€çš„å¹¶è¡Œç­–ç•¥ï¼ˆå¦‚ DP å’Œ EP è€¦åˆï¼‰ï¼Œå¯¼è‡´ï¼š
- **æ‰©å±•æ€§å·®**ï¼šæ— æ³•ç‹¬ç«‹æ‰©ç¼©å®¹ attention æˆ– MoE å­æ¨¡å—ã€‚
- **èµ„æºæµªè´¹**ï¼šä¸ºæ»¡è¶³ MoE é«˜å†…å­˜éœ€æ±‚è€Œè¿‡åº¦é…ç½® attention èµ„æºï¼Œåˆ©ç”¨ç‡ä½ä¸‹ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡º **JANUS**ï¼Œä¸€ä¸ªé¢å‘å¤§è§„æ¨¡ MoE æ¨ç†çš„é«˜æ•ˆã€å¯æ‰©å±•ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ **disaggregationï¼ˆè§£è€¦ï¼‰**ï¼š

1. **Attention ä¸ MoE è§£è€¦éƒ¨ç½²**  
   å°† attention å’Œ MoE æ¨¡å—åˆ†åˆ«éƒ¨ç½²åœ¨ç‹¬ç«‹çš„ GPU å­é›†ç¾¤ä¸Šï¼Œå®ç°æ¨¡å—çº§ç‹¬ç«‹ç®¡ç†ä¸å¼¹æ€§ä¼¸ç¼©ã€‚

2. **ä¸‰å¤§å…³é”®æŠ€æœ¯è®¾è®¡**ï¼š
   - **è‡ªé€‚åº”ä¸¤é˜¶æ®µé€šä¿¡æœºåˆ¶ï¼ˆAdaptive Two-Phase Communicationï¼‰**  
     åˆ©ç”¨èŠ‚ç‚¹å†…é«˜å¸¦å®½ NVLink èšåˆæ•°æ®ï¼Œå‡å°‘è·¨èŠ‚ç‚¹å°æ¶ˆæ¯ä¼ è¾“æ¬¡æ•°ï¼Œæ˜¾è‘—é™ä½é€šä¿¡å¼€é”€ã€‚
   - **åŸºäº GPU å†…æ ¸çš„è½»é‡çº§æ¿€æ´»è°ƒåº¦å™¨ï¼ˆActivation Load-Balanced Schedulingï¼‰**  
     åœ¨ GPU ä¸Šè¿è¡Œç¡®å®šæ€§å¯å‘å¼ç®—æ³•ï¼ˆAEBSï¼‰ï¼Œä»¥å¾®ç§’çº§å»¶è¿Ÿå¹³è¡¡å„ GPU ä¸Šè¢«æ¿€æ´»çš„ä¸“å®¶æ•°ï¼Œé¿å…çƒ­ç‚¹ã€‚
   - **ç»†ç²’åº¦èµ„æºä¸ä¸“å®¶ç®¡ç†ï¼ˆFine-grained Resource & Expert Managementï¼‰**  
     åŠ¨æ€è°ƒæ•´ä¸“å®¶å‰¯æœ¬æ•°é‡ï¼ˆreplicationï¼‰å’Œæ”¾ç½®ç­–ç•¥ï¼ˆplacementï¼‰ï¼Œç»“åˆè¿è¡Œæ—¶ç»Ÿè®¡ä¼˜åŒ–è´Ÿè½½åˆ†å¸ƒï¼Œå¹¶ç‹¬ç«‹è°ƒèŠ‚ attention/MoE å®ä¾‹æ•°é‡ä»¥æœ€å¤§åŒ–æ¯ GPU ååé‡ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ SGLangï¼‰ | JANUS |
|------|------------------------|-------|
| æ¶æ„ | å•ä½“éƒ¨ç½²ï¼ŒDP/EP å¼ºè€¦åˆ | è§£è€¦æ¶æ„ï¼Œæ¨¡å—ç‹¬ç«‹ä¼¸ç¼© |
| æ‰©å±•æ€§ | æ•´ä½“å¤åˆ¶æˆ–é‡å¯é‡é…ï¼Œå¼€é”€å¤§ | å¢é‡å¼ã€ç»†ç²’åº¦æ‰©ç¼©å®¹ |
| èµ„æºæ•ˆç‡ | è¿‡åº¦é…ç½®ï¼Œåˆ©ç”¨ç‡ä½ | æŒ‰éœ€åˆ†é…ï¼Œæå‡æ¯ GPU åå |
| è°ƒåº¦ç²¾åº¦ | ç¼ºä¹å®æ—¶ä¸“å®¶è´Ÿè½½æ„ŸçŸ¥ | å¾®ç§’çº§è´Ÿè½½å‡è¡¡ï¼Œé™ä½å°¾å»¶è¿Ÿ |
| é€šä¿¡ä¼˜åŒ– | æ ‡å‡† collectiveï¼ˆå¦‚ all-gatherï¼‰ | è‡ªå®šä¹‰ä¸¤é˜¶æ®µèšåˆé€šä¿¡ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹**
- **çœŸå®æµé‡å›æ”¾**ï¼š`ShareGPT` æ•°æ®é›†ï¼Œå¹³å‡è¾“å…¥ 16 tokensï¼Œè¾“å‡º 256 tokensã€‚
- **åˆæˆåŠ¨æ€è´Ÿè½½**ï¼š`BurstGPT`ï¼Œæ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒä¸­çœŸå®çš„è¯·æ±‚åˆ°è¾¾æ¨¡å¼ï¼ˆå«çªå‘æµé‡ï¼‰ã€‚
- **è¯„ä¼°æ¨¡å‹**ï¼š
  - `DeepSeek-V2`ï¼ˆä»£è¡¨æ€§ MoE æ¨¡å‹ï¼‰
  - `Scaled-DS-1/2`ï¼šè‡ªå®šä¹‰ç¼©æ”¾ç‰ˆæœ¬ï¼Œç”¨äºæµ‹è¯•ä¸åŒä¸“å®¶è§„æ¨¡ä¸‹çš„è¡¨ç°ã€‚

### **å®éªŒè®¾ç½®**
- **ç¡¬ä»¶å¹³å°**ï¼šæœ€å¤š 4 å°æœåŠ¡å™¨ï¼Œæ¯å°é…å¤‡ 8Ã— NVIDIA H100 80GB GPUï¼ŒNVLink äº’è”ï¼ˆ900 GB/sï¼‰ï¼ŒInfiniBandï¼ˆ400 Gbpsï¼‰ã€‚
- **è½¯ä»¶åŸºç¡€**ï¼šåŸºäº `SGLang` å®ç°ï¼Œæ‰©å±•æ”¯æŒè§£è€¦ MoE æ¨ç†ã€‚
- **å¹¶è¡Œæ ¼å¼**ï¼šBF16ï¼ŒKV Cache å­˜äºæ˜¾å­˜ã€‚

### **è¯„ä¼°æŒ‡æ ‡**
- **TPOTï¼ˆTime Per Output Tokenï¼‰**ï¼šè¡¡é‡æ˜¯å¦æ»¡è¶³ SLOï¼ˆè®¾ä¸º 200msï¼‰ã€‚
- **Per-GPU Throughput**ï¼šå•ä½æˆæœ¬ä¸‹çš„ååèƒ½åŠ›ï¼Œä¸ºæ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡ã€‚
- **é€šä¿¡å¼€é”€ã€è°ƒåº¦å»¶è¿Ÿã€è´Ÿè½½å‡è¡¡ç¨‹åº¦**ï¼šç”¨äºæ¶ˆèåˆ†æã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
1. **SGLang**ï¼šä»£è¡¨ä¸»æµå•ä½“å¼ MoE æ¨ç†ç³»ç»Ÿï¼ŒDP ä¸ EP å¿…é¡»åŒ¹é…ï¼Œä»…æ”¯æŒç²—ç²’åº¦æ‰©å±•ï¼ˆå¦‚ 16/32/64 GPUï¼‰ã€‚
2. **DisAgg**ï¼šåŸºäº JANUS ä»£ç åº“æ„å»ºçš„è§£è€¦åŸºçº¿ï¼Œä½†ä½¿ç”¨éšæœºä¸“å®¶è°ƒåº¦ + èŠ‚ç‚¹çº§ï¼ˆ8 GPU/èŠ‚ç‚¹ï¼‰ç²—ç²’åº¦èµ„æºç®¡ç†ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- **æœ€é«˜æå‡è¾¾ 3.9Ã— çš„ per-GPU throughput**ï¼ŒåŒæ—¶æ»¡è¶³ TPOT â‰¤ 200ms çš„ SLOã€‚
- åœ¨ `DeepSeek-V2` ä¸Šï¼ŒJANUS ç›¸æ¯” SGLang å¹³å‡æå‡ **2.8Ã—~3.9Ã—**ï¼Œç›¸æ¯” DisAgg æå‡ **çº¦ 2.8Ã—**ã€‚
- åœ¨çœŸå®åŠ¨æ€è´Ÿè½½ä¸‹ï¼ˆBurstGPTï¼‰ï¼ŒJANUS é€šè¿‡å¼¹æ€§ä¼¸ç¼©èŠ‚çœ **25% çš„ GPU èµ„æºæ¶ˆè€—**ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
| åœºæ™¯ | JANUS vs SGLang | JANUS vs DisAgg |
|------|------------------|------------------|
| å°æ‰¹é‡ï¼ˆ4â€“64ï¼‰ | æ˜¾è‘—æ›´é«˜ååï¼ˆæ›´å°‘ attention å®ä¾‹ï¼‰ | æ›´ä¼˜è´Ÿè½½å‡è¡¡ï¼Œæ›´ä½å»¶è¿Ÿ |
| å¤§æ‰¹é‡ï¼ˆ512ï¼‰ | æ»¡è¶³ SLOï¼ŒSGLang éœ€åŒå€ GPU | DisAgg å› é€šä¿¡ç“¶é¢ˆæœªèƒ½è¾¾æ ‡ |
| åŠ¨æ€è´Ÿè½½ | å®ç°è¿‘ä¼¼â€œæŒ‰éœ€ä¾›ç»™â€ï¼Œé¿å…é•¿æœŸè¿‡é… | SGLang å›ºå®šé…ç½®å¯¼è‡´ä¸¥é‡æµªè´¹ |

> å›¾ 7 æ˜¾ç¤ºï¼Œåœ¨ batch size=512 æ—¶ï¼ŒSGLang éœ€ä» 16â†’32 GPU æ‰©å±•ä¸€æ¬¡ï¼Œä»ä¸å¦‚ JANUS çµæ´»é…ç½®ï¼ˆå¦‚ 8A14Eï¼‰é«˜æ•ˆã€‚

### **æ¶ˆèå®éªŒç»“æœ**
é€šè¿‡é€æ­¥æ·»åŠ ç»„ä»¶è¿›è¡Œ ablation studyï¼ˆå›¾ 10ï¼‰ï¼š
1. **Baseï¼ˆæ— ä¼˜åŒ–è§£è€¦ï¼‰** â†’ **Base+2PCï¼ˆåŠ ä¸¤é˜¶æ®µé€šä¿¡ï¼‰**  
   - åœ¨ batch=512 æ—¶ï¼ŒTPOT ä¸‹é™ **18%**ï¼Œè¯æ˜é€šä¿¡ä¼˜åŒ–è‡³å…³é‡è¦ã€‚
2. **Base+2PC â†’ Base+2PC+LBï¼ˆå…¨é‡ JANUSï¼‰**  
   - åœ¨ batch=16~64 æ—¶ï¼Œé¢å¤–é™ä½ **7% å»¶è¿Ÿ**ï¼Œè¡¨æ˜è´Ÿè½½å‡è¡¡åœ¨ä¸­å°æ‰¹é‡æ•ˆæœæ˜¾è‘—ã€‚
   - å½“ batch å¢å¤§è‡³ 512ï¼Œå‡ ä¹æ‰€æœ‰ä¸“å®¶éƒ½è¢«æ¿€æ´»ï¼Œè´Ÿè½½å‡è¡¡å¢ç›Šå‡å°ã€‚

æ­¤å¤–ï¼š
- **è´Ÿè½½å‡è¡¡æ•ˆæœ**ï¼ˆå›¾ 11ï¼‰ï¼šJANUS å°†æœ€æ´»è·ƒä¸æœ€å°‘æ´»è·ƒå®ä¾‹é—´çš„æ¿€æ´»ä¸“å®¶å·®ä» ~8 é™è‡³ ~4ï¼Œå¤§å¹…ç¼“è§£ straggler é—®é¢˜ã€‚
- **è°ƒåº¦å¼€é”€**ï¼ˆå›¾ 12ï¼‰ï¼šå³ä½¿åœ¨ batch=512 å’Œ 16 GPU è§„æ¨¡ä¸‹ï¼Œè°ƒåº¦å»¶è¿Ÿå§‹ç»ˆä½äº **100Î¼s**ï¼Œä¸å½±å“ MoE å±‚æ‰§è¡Œæ•ˆç‡ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **Attention ä¸ MoE åº”è¯¥è§£è€¦**ï¼šäºŒè€…åœ¨æ€§èƒ½ç‰¹å¾ã€èµ„æºéœ€æ±‚ã€æ‰©å±•è¡Œä¸ºä¸Šå­˜åœ¨æ ¹æœ¬å·®å¼‚ï¼Œç»Ÿä¸€èµ„æºé…ç½®å¿…ç„¶é€ æˆæµªè´¹ã€‚
2. **MoE å±‚æ˜¯ memory-bound ä¸”å»¶è¿Ÿç”±æ¿€æ´»ä¸“å®¶æ•°ä¸»å¯¼**ï¼šæ‰¹å¤§å°å’Œè·¯ç”±æ¨¡å¼å½±å“æå°ï¼Œå› æ­¤ä¼˜åŒ–é‡ç‚¹åº”æ”¾åœ¨**å‡å°‘å¹¶å¹³è¡¡æ¿€æ´»ä¸“å®¶æ•°**ã€‚
3. **ç»†ç²’åº¦è°ƒåº¦å¯åœ¨ GPU ä¸Šé«˜æ•ˆå®Œæˆ**ï¼šé€šè¿‡å°†è°ƒåº¦ç®—æ³•å®ç°ä¸º GPU kernelï¼Œå¹¶åˆ©ç”¨ç¡®å®šæ€§é€»è¾‘é¿å…åŒæ­¥ï¼Œå¯åœ¨å¾®ç§’çº§å®Œæˆå¤æ‚è´Ÿè½½å‡è¡¡ã€‚
4. **åŠ¨æ€ä¸“å®¶ç®¡ç†å¸¦æ¥æŒç»­æ”¶ç›Š**ï¼šåŸºäºå†å²æ¿€æ´»é¢‘ç‡å’Œå…±æ¿€æ´»æ¨¡å¼è°ƒæ•´å‰¯æœ¬æ•°ä¸ä½ç½®ï¼Œå¯è¿›ä¸€æ­¥é™ä½çƒ­ç‚¹é£é™©ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–ä¸“å®¶è¾ƒå°ä¸”æ•°é‡å¤šçš„ MoE æ¶æ„**ï¼šå½“å‰è®¾è®¡å‡è®¾æ¯ä¸ªä¸“å®¶é€‚é…å•ä¸ª GPUï¼Œè‹¥ä¸“å®¶è¿‡å¤§å¯èƒ½éœ€è¦å¼•å…¥ Tensor Parallelismï¼ˆè™½å·²è®¨è®ºæ”¯æŒï¼Œä½†æœªå®æµ‹ï¼‰ã€‚
- **è·¨å­é›†ç¾¤é€šä¿¡ä»å­˜åœ¨å›ºæœ‰å¼€é”€**ï¼šå°½ç®¡ä¸¤é˜¶æ®µé€šä¿¡ä¼˜åŒ–æ˜æ˜¾ï¼Œä½†åœ¨æç«¯é«˜åååœºæ™¯ä¸‹ä»æ˜¯ç“¶é¢ˆã€‚
- **ä¸“å®¶æ”¾ç½®ç®—æ³•ä¸ºå¯å‘å¼**ï¼šAlgorithm 2 æ˜¯è¿‘ä¼¼æ±‚è§£ï¼Œéå…¨å±€æœ€ä¼˜ï¼Œæœªæ¥å¯æ¢ç´¢å­¦ä¹ å‹è°ƒåº¦å™¨ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ”¯æŒå¼‚æ„ç¡¬ä»¶ï¼ˆå¦‚ MoE æ”¾åœ¨é«˜å¸¦å®½ GPUï¼Œattention æ”¾æ™®é€šå¡ï¼‰ã€‚
- ç»“åˆ prefill-decode disaggregationï¼Œå®ç°å…¨æµç¨‹ç²¾ç»†åŒ–èµ„æºæ§åˆ¶ã€‚
- å¼•å…¥ micro-batching å®ç° pipeline å¹¶è¡Œï¼Œè¿›ä¸€æ­¥æå‡åˆ©ç”¨ç‡ã€‚
- æ¢ç´¢åŸºäºå¼ºåŒ–å­¦ä¹ çš„åŠ¨æ€ä¸“å®¶å¤åˆ¶ä¸è°ƒåº¦ç­–ç•¥ã€‚

---

> âœ… **ä¸€å¥è¯æ€»ç»“**ï¼š  
> JANUS é€šè¿‡ **è§£è€¦ attention ä¸ MoE**ã€**ä¸¤é˜¶æ®µé€šä¿¡**ã€**GPU å†…æ ¸çº§è´Ÿè½½å‡è¡¡è°ƒåº¦** å’Œ **åŠ¨æ€ä¸“å®¶ç®¡ç†**ï¼Œå®ç°äº†é«˜è¾¾ **3.9Ã— çš„ per-GPU ååæå‡**ï¼Œå¹¶åœ¨çœŸå®åŠ¨æ€è´Ÿè½½ä¸‹èŠ‚çœ **25% GPU æˆæœ¬**ï¼Œä¸ºå¤§è§„æ¨¡ MoE æ¨ç†æä¾›äº†é«˜æ•ˆã€å¯æ‰©å±•çš„æ–°èŒƒå¼ã€‚

</details>

---

### 2. [HetRL: Efficient Reinforcement Learning for LLMs in Heterogeneous Environments](https://arxiv.org/abs/2512.12476)

**Authors**: Yongjun He, Shuai Zhang, Jiading Gai, Xiyuan Zhang, Boran Han, Bernie Wang, Huzefa Rangwala, George Karypis  
**Category**: cs.DC  
**Published**: 2025-12-16  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.12476v1  

#### Abstract
As large language models (LLMs) continue to scale and new GPUs are released even more frequently, there is an increasing demand for LLM post-training in heterogeneous environments to fully leverage underutilized mid-range or previous-generation GPUs across regions and alleviate the shortage of homog...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šHetRL: Efficient Reinforcement Learning for LLMs in Heterogeneous Environments**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è§„æ¨¡ä¸æ–­å¢é•¿ï¼Œä»¥åŠæ–°å‹GPUé¢‘ç¹å‘å¸ƒï¼Œå¤§é‡ä¸­ç«¯æˆ–ä¸Šä¸€ä»£GPUåœ¨å…¨çƒæ•°æ®ä¸­å¿ƒä¸­å¤„äº**æœªå……åˆ†åˆ©ç”¨çŠ¶æ€**ã€‚å½“å‰ä¸»æµçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒç³»ç»Ÿï¼ˆå¦‚ verlã€OpenRLHFï¼‰ä¾èµ–äº**åŒæ„é«˜æ€§èƒ½GPUé›†ç¾¤**å’Œé«˜å¸¦å®½ç½‘ç»œï¼Œéš¾ä»¥åˆ©ç”¨è¿™äº›å¼‚æ„èµ„æºã€‚

ç„¶è€Œï¼ŒRLè®­ç»ƒæµç¨‹æ¶‰åŠå¤šä¸ªæ¨¡å‹ï¼ˆactorã€criticã€rewardã€referenceï¼‰å’Œä»»åŠ¡ï¼Œå…·æœ‰å¤æ‚çš„è®¡ç®—ä¸æ•°æ®ä¾èµ–å…³ç³»ï¼Œåœ¨**å¼‚æ„GPUå’Œç½‘ç»œç¯å¢ƒ**ä¸‹è¿›è¡Œé«˜æ•ˆè°ƒåº¦æå…·æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆåº”å¯¹è¿™ç§å¤æ‚æ€§ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**
ä½œè€…æå‡ºäº† **HetRL**ï¼Œä¸€ä¸ªä¸“ä¸ºå¼‚æ„ç¯å¢ƒè®¾è®¡çš„åˆ†å¸ƒå¼RLè®­ç»ƒç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### **(1) å°†RLè°ƒåº¦å»ºæ¨¡ä¸ºè”åˆä¼˜åŒ–é—®é¢˜**
é¦–æ¬¡å°†å¼‚æ„ç¯å¢ƒä¸‹çš„RLè®­ç»ƒè°ƒåº¦å½¢å¼åŒ–ä¸ºä¸€ä¸ª**å—çº¦æŸçš„è”åˆä¼˜åŒ–é—®é¢˜**ï¼ŒåŒæ—¶ä¼˜åŒ–ï¼š
- æ¨¡å‹ä¸ä»»åŠ¡çš„**å…±ç½®ç­–ç•¥**ï¼ˆcolocationï¼‰
- å„ä»»åŠ¡å†…éƒ¨çš„**å¹¶è¡ŒåŒ–ç­–ç•¥**ï¼ˆTP, PP, DPï¼‰
- ç»†ç²’åº¦çš„**taskletåˆ°è®¾å¤‡çš„åˆ†é…**

#### **(2) å¤šçº§æœç´¢æ¡†æ¶ï¼ˆMulti-level Search Frameworkï¼‰**
ä¸ºåº”å¯¹åºå¤§çš„æœç´¢ç©ºé—´ï¼Œæå‡ºäº”çº§åˆ†å±‚æœç´¢ç­–ç•¥ï¼š
1. **Task Grouping**ï¼šå°†ä»»åŠ¡åˆ†ç»„ï¼Œå…±äº«GPUèµ„æº
2. **Coarse-grained GPU Assignment**ï¼šç²—ç²’åº¦åˆ’åˆ†GPUç»„
3. **Medium-grained GPU Assignment**ï¼šç”Ÿæˆå€™é€‰åˆ†é…æ–¹æ¡ˆ
4. **Intra-model Parallelization**ï¼šç¡®å®šå„ä»»åŠ¡å†…çš„å¹¶è¡Œç­–ç•¥
5. **Fine-grained GPU Assignment**ï¼šç»†ç²’åº¦åˆ†é…taskletåˆ°å…·ä½“GPU

è¯¥æ¡†æ¶å®ç°äº†ä»â€œç²—åˆ°ç²¾â€çš„æ„é€ æ€§æœç´¢ï¼Œæ˜¾è‘—é™ä½æœç´¢å¤æ‚åº¦ã€‚

#### **(3) åŸºäºSuccessive Halvingçš„é¢„ç®—åˆ†é…æœºåˆ¶**
å¼•å…¥**åµŒå¥—å¼Successive Halving Algorithm (SHA)** åœ¨ç¬¬1ã€2çº§å¿«é€Ÿæ·˜æ±°åŠ£è´¨å€™é€‰æ–¹æ¡ˆï¼ŒåŠ¨æ€åˆ†é…æœç´¢é¢„ç®—ï¼Œæå‡æœç´¢æ•ˆç‡ã€‚

#### **(4) é—ä¼ ç®—æ³•ç»“åˆä¸¤çº§äº¤æ¢ï¼ˆTwo-level Swapsï¼‰**
åœ¨ä½å±‚çº§ä½¿ç”¨é—ä¼ ç®—æ³•ï¼Œå¹¶è®¾è®¡è·¨**task group**å’Œ**tasklet group**çš„åŒå±‚äº¤æ¢æ“ä½œï¼Œå¢å¼ºæœç´¢å¤šæ ·æ€§ä¸æ”¶æ•›é€Ÿåº¦ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ verl, StreamRLï¼‰ | HetRL |
|------|-------------------------------|-------|
| ç¡¬ä»¶å‡è®¾ | ä»…æ”¯æŒåŒæ„GPU | æ”¯æŒ**å¼‚æ„GPU + å¼‚æ„ç½‘ç»œ** |
| è°ƒåº¦ç²’åº¦ | å•ä»»åŠ¡/å•æ¨¡å‹è°ƒåº¦ | å…¨æµç¨‹è”åˆä¼˜åŒ– |
| æœç´¢æ•ˆç‡ | æœç´¢è€—æ—¶é•¿ï¼ˆåƒç§’çº§ï¼‰ | é€šè¿‡SHAå¤§å¹…åŠ é€Ÿæœç´¢ |
| æ€§èƒ½æå‡ | æ— æ³•åˆ©ç”¨åœ°ç†åˆ†å¸ƒèµ„æº | æœ€é«˜å®ç° **9.17Ã— ååæå‡** |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **GSM8k**ï¼šOpenAIå‘å¸ƒçš„æ•°å­¦æ¨ç†åŸºå‡†æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°LLMçš„æ¨ç†èƒ½åŠ›ã€‚

### **æ¨¡å‹ä¸RLç®—æ³•**
- **æ¨¡å‹ç³»åˆ—**ï¼šQwen-4B, Qwen-8B, Qwen-14B
- **RLç®—æ³•**ï¼š
  - **PPO**ï¼ˆProximal Policy Optimizationï¼‰
  - **GRPO**ï¼ˆæ— éœ€criticæ¨¡å‹çš„è½»é‡ç‰ˆï¼‰
  - åŒæ­¥ï¼ˆSyncï¼‰ä¸å¼‚æ­¥ï¼ˆAsyncï¼‰ä¸¤ç§æ¨¡å¼

### **ç¡¬ä»¶ç¯å¢ƒ**
- **æ€»GPUæ•°**ï¼š64å—ï¼ˆ24Ã—A100, 24Ã—L40S, 16Ã—L4ï¼‰
- **æ¨¡æ‹Ÿå››ç§ç½‘ç»œåœºæ™¯**ï¼š
  1. **Single-Region**ï¼šå•åŒºåŸŸï¼Œæ— ç½‘ç»œé™åˆ¶
  2. **Multi-Region-Hybrid**ï¼šè·¨Ohio/Virginiaï¼Œè¾¹ç¼˜èŠ‚ç‚¹å¸¦å®½å—é™
  3. **Multi-Country**ï¼šæ¬§æ´²8ä¸ªåœ°åŒºé—´äº’è”
  4. **Multi-Continent**ï¼šæ¬§ç¾è·¨æ´²é€šä¿¡

| GPUå‹å· | FP16 TFLOPS | HBMå¸¦å®½ (GB/s) |
|--------|-------------|----------------|
| A100   | 312         | 600            |
| L40S   | 366         | 864            |
| L4     | 121         | 300            |

### **è¯„ä¼°æŒ‡æ ‡**
- **ååé‡ï¼ˆThroughputï¼‰**ï¼šæ¯ç§’å®Œæˆçš„è®­ç»ƒè¿­ä»£æ•°ï¼ˆsamples/secï¼‰
- **ç«¯åˆ°ç«¯è®­ç»ƒæ—¶é—´**
- **æœç´¢æ•ˆç‡**ï¼ˆæ”¶æ•›é€Ÿåº¦ï¼‰
- **æ¶ˆèå®éªŒ**ï¼šéªŒè¯load balancingä¸è°ƒåº¦ç®—æ³•çš„æœ‰æ•ˆæ€§

### **åŸºçº¿æ–¹æ³•**
- **verl**ï¼šå½“å‰æœ€å…ˆè¿›çš„åŒæ„ç¯å¢ƒRLè®­ç»ƒç³»ç»Ÿ
- **StreamRL**ï¼šæ”¯æŒå¼‚æ„ç¯å¢ƒçš„å¼‚æ­¥RLç³»ç»Ÿï¼ˆä½œè€…åŸºäºverlå¤ç°ï¼‰

æ‰€æœ‰ç³»ç»Ÿå‡ä½¿ç”¨ **Megatron-LM** ä½œä¸ºè®­ç»ƒå¼•æ“ï¼Œ**vLLM** ä½œä¸ºæ¨ç†å¼•æ“ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- **æ€»å®éªŒæ¶ˆè€—**ï¼šè¶…è¿‡ **20,000 GPU-hours**
- **æœ€é«˜ååæå‡**ï¼š**9.17Ã—** vs. SoTAç³»ç»Ÿï¼ˆverlï¼‰
- **å¹³å‡ååæå‡**ï¼š**3.17Ã—**

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
| åœºæ™¯ | æ–¹æ³• | ååæå‡ï¼ˆvs. verlï¼‰ |
|------|------|------------------|
| Single-Region | HetRL-Sync | 1.51â€“2.05Ã— |
| Multi-Region-Hybrid | HetRL-Sync | 3.01â€“4.99Ã— |
| Multi-Country | HetRL-Sync | 1.4â€“3.07Ã— |
| Multi-Continent | HetRL-Sync | 2.24â€“5.46Ã— |
| æ‰€æœ‰åœºæ™¯ | HetRL-Async | å‡ä¼˜äº verl-Async å’Œ StreamRL-Async |

> âœ… **HetRL-Async å§‹ç»ˆå¿«äº HetRL-Sync**  
> âŒ **verl-Async åœ¨æŸäº›åœºæ™¯ä¸‹åè€Œæ…¢äº verl-Sync** â†’ è¡¨æ˜å…¶åœ¨å¼‚æ„ç¯å¢ƒä¸‹è°ƒåº¦ä¸ä½³

### **ä¸å…¶ä»–ç³»ç»Ÿçš„å¯¹æ¯”**
- åœ¨ Multi-Region åŠä»¥ä¸Šåœºæ™¯ä¸­ï¼ŒHetRL ç›¸æ¯” **StreamRL** æå‡è¾¾ **1.11â€“3.72Ã—**
- å› ä¸º HetRL æ”¯æŒæ›´çµæ´»çš„ä»»åŠ¡åˆ†ç»„ä¸èµ„æºåˆ†é…ï¼Œè€Œ StreamRL ä»…æ”¯æŒä¸¤ç»„åŒæ„GPUåˆ†å·¥

### **æ¶ˆèå®éªŒç»“æœ**
#### **(1) è°ƒåº¦ç®—æ³•æœ‰æ•ˆæ€§ï¼ˆå›¾4ï¼‰**
- å¯¹æ¯”ä¸‰ç§è°ƒåº¦å™¨ï¼š
  - verlâ€™s scheduler
  - HetRL (simple)ï¼šç¦ç”¨SHAï¼Œä»…æ¨¡å‹å†…äº¤æ¢
  - **HetRLï¼ˆå®Œæ•´ç‰ˆï¼‰**
- ç»“æœæ˜¾ç¤ºï¼š
  - HetRL (simple) åœ¨å°é¢„ç®—ä¸‹è¡¨ç°ä¸å¦‚ verl
  - **å®Œæ•´HetRLåœ¨å„ç§é¢„ç®—ä¸‹å‡æ˜¾è‘—é¢†å…ˆ**ï¼Œè¯æ˜SHAä¸å¤šçº§æœç´¢çš„æœ‰æ•ˆæ€§

#### **(2) è´Ÿè½½å‡è¡¡æ•ˆæœï¼ˆå›¾5ï¼‰**
- å¼•å…¥ä¸‰ç§è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼š
  - æ•°æ®çº§ï¼šè°ƒæ•´DPç»„å†…local batch size
  - åºåˆ—çº§ï¼šé•¿åºåˆ—åˆ†é…ç»™æ›´å¼ºGPU
  - å±‚çº§ï¼šæŒ‰ç®—åŠ›åˆ†é…pipeline stageå±‚æ•°
- ç»“æœï¼š
  - åœ¨ Single-Region ä¸‹æå‡æœ€å¤š **12%**
  - åœ¨ Cross-Region ä¸‹æå‡æœ€å¤š **18%**
- è¡¨æ˜è´Ÿè½½å‡è¡¡å¯¹å¼‚æ„ç¯å¢ƒè‡³å…³é‡è¦

#### **(3) ä¸åŒGPUç»„åˆçš„å½±å“ï¼ˆå›¾6ï¼‰**
- ä½¿ç”¨å…¨éƒ¨å¼‚æ„GPUï¼ˆA100 + L40S + L4ï¼‰ vs. ä»…24Ã—A100
- HetRL åˆ©ç”¨å¼‚æ„èµ„æºåï¼Œååæå‡ **1.57â€“2.0Ã—**
- è¯´æ˜å³ä½¿æœ¬åœ°åŒæ„èµ„æºæœ‰é™ï¼Œè·¨åŒºåŸŸå¼‚æ„èµ„æºä»æ˜¯å¯è¡Œæ›¿ä»£æ–¹æ¡ˆ

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **å¼‚æ„ç¯å¢ƒæ˜¯RLè®­ç»ƒçš„æ½œåŠ›è“æµ·**ï¼š
   - å…¨çƒå­˜åœ¨å¤§é‡æœªè¢«å……åˆ†åˆ©ç”¨çš„ä¸­ä½ç«¯GPU
   - HetRL æˆåŠŸåˆ©ç”¨è¿™äº›èµ„æºï¼Œåœ¨å¤šç§åœºæ™¯ä¸‹å®ç°æ•°å€æ€§èƒ½æå‡

2. **å…¨æµç¨‹è”åˆä¼˜åŒ–è‡³å…³é‡è¦**ï¼š
   - ä¼ ç»Ÿå•ä»»åŠ¡è°ƒåº¦æ–¹æ³•æ— æ³•é€‚åº”RLçš„å¤šæ¨¡å‹ä¾èµ–
   - å¿…é¡»è”åˆè€ƒè™‘ä»»åŠ¡åˆ†ç»„ã€å¹¶è¡Œç­–ç•¥ã€è®¾å¤‡åˆ†é…

3. **HetRLå…·å¤‡å¼ºæ‰©å±•æ€§ä¸çµæ´»æ€§**ï¼š
   - æ”¯æŒä¸åŒå¤§å°æ¨¡å‹æ··åˆéƒ¨ç½²
   - å¯é€‚é…åŒæ­¥/å¼‚æ­¥RLç®—æ³•
   - åœ¨è·¨åŒºåŸŸã€è·¨æ´²é™…ç½‘ç»œä¸‹ä»ä¿æŒé«˜æ€§èƒ½

4. **å¼‚æ„è°ƒåº¦å¯ç¼“è§£é«˜ç«¯GPUçŸ­ç¼ºé—®é¢˜**ï¼š
   - å½“åœ°åŒæ„GPUä¸è¶³æ—¶ï¼Œä½¿ç”¨å¼‚åœ°å¼‚æ„èµ„æºå¯è·å¾—æ›´é«˜åå

---

### **å±€é™æ€§**
1. **GPUæ”¯æŒèŒƒå›´æœ‰é™**ï¼š
   - å½“å‰ä»…æµ‹è¯•NVIDIA A100/L40S/L4
   - æœªæ”¯æŒå…¶ä»–å‚å•†ï¼ˆå¦‚AMDï¼‰æˆ–å…¶ä»–ç½‘ç»œæ ˆï¼ˆå¦‚RoCEï¼‰

2. **æœªè¯„ä¼°æ”¶æ•›è´¨é‡å½±å“**ï¼š
   - è·¨å¼‚æ„è®¾å¤‡çš„æ•°æ®äº¤æ¢å¯èƒ½å­˜åœ¨ç²¾åº¦æ¼‚ç§»é£é™©
   - è®ºæ–‡èšç„¦ååï¼Œæœªåˆ†ææœ€ç»ˆæ¨¡å‹æ€§èƒ½å·®å¼‚

3. **æˆæœ¬æ•ˆç›Šæœªé‡åŒ–**ï¼š
   - ä¸åŒåŒºåŸŸGPUä»·æ ¼å·®å¼‚å¤§
   - æœªæä¾› $/token æˆ– $/training-job çš„æˆæœ¬åˆ†æ

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•æ”¯æŒæ›´å¤šGPUæ¶æ„ä¸ç½‘ç»œåè®®
- é›†æˆæ›´å…ˆè¿›çš„è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼ˆå¦‚Metisï¼‰
- æ¢ç´¢å¼‚æ„ç¯å¢ƒä¸‹çš„å®¹é”™ä¸å¼¹æ€§è°ƒåº¦ï¼ˆfault tolerance, elasticityï¼‰
- å¼€å±•å¤§è§„æ¨¡æˆæœ¬-æ€§èƒ½æƒè¡¡ç ”ç©¶ï¼ˆcost-efficiency analysisï¼‰
- æ”¯æŒMoEï¼ˆMixture-of-Expertsï¼‰ç­‰æ›´å¤æ‚æ¨¡å‹ç»“æ„

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **HetRL æ˜¯é¦–ä¸ªä¸“ä¸ºå¼‚æ„ç¯å¢ƒè®¾è®¡çš„é«˜æ•ˆRLè®­ç»ƒç³»ç»Ÿï¼Œé€šè¿‡å¤šçº§æœç´¢ä¸è”åˆä¼˜åŒ–ï¼Œåœ¨çœŸå®å¼‚æ„ç¡¬ä»¶ä¸Šå®ç°äº†é«˜è¾¾ 9.17Ã— çš„ååæå‡ï¼Œä¸ºå¤§è§„æ¨¡LLMåè®­ç»ƒæä¾›äº†æ–°çš„å¯è¡Œæ€§è·¯å¾„ã€‚**

</details>

---

### 3. [Fine-Grained Energy Prediction For Parallellized LLM Inference With PIE-P](https://arxiv.org/abs/2512.12801)

**Authors**: Anurag Dutt, Young Won Choi, Avirup Sil, Anshul Gandhi, Aruna Balasubramanian, Niranjan Balasubramanian  
**Category**: cs.DC  
**Published**: 2025-12-16  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.12801v1  

#### Abstract
With the widespread adoption of Large Language Models (LLMs), energy costs of running LLMs is quickly becoming a critical concern. However, precisely measuring the energy consumption of LLMs is often infeasible because hardware-based power monitors are not always accessible and software-based energy...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFine-Grained Energy Prediction for Parallelized LLM Inference with PIE-P

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¹¿æ³›åº”ç”¨ï¼Œå…¶æ¨ç†è¿‡ç¨‹ä¸­çš„**èƒ½è€—æˆæœ¬**å·²æˆä¸ºæ•°æ®ä¸­å¿ƒè¿è¥çš„å…³é”®æŒ‘æˆ˜ã€‚ç„¶è€Œï¼Œç²¾ç¡®æµ‹é‡å¤šGPUå¹¶è¡ŒåŒ–ç¯å¢ƒä¸‹çš„LLMèƒ½è€—æä¸ºå›°éš¾ï¼š
- **ç¡¬ä»¶çº§åŠŸè€—ç›‘æµ‹å™¨**ï¼ˆå¦‚Watts Up Proï¼‰é€šå¸¸åœ¨å¤šç§Ÿæˆ·é›†ç¾¤ä¸­ä¸å¯ç”¨ï¼›
- **è½¯ä»¶çº§å·¥å…·**ï¼ˆå¦‚NVMLã€CodeCarbonï¼‰ä»…èƒ½æä¾›GPUåŠŸè€—ä¸‹ç•Œï¼Œæ— æ³•å‡†ç¡®åæ˜ ç³»ç»Ÿæ€»èƒ½è€—ï¼›
- ç°æœ‰é¢„æµ‹æ¡†æ¶ï¼ˆå¦‚IrEneï¼‰ä»…é€‚ç”¨äºå•GPUåœºæ™¯ï¼Œæ— æ³•å¤„ç†**tensorã€pipelineã€data parallelism**ç­‰ç°ä»£å¹¶è¡Œç­–ç•¥å¸¦æ¥çš„é€šä¿¡å¼€é”€ä¸éç¡®å®šæ€§åŒæ­¥é—®é¢˜ã€‚

å› æ­¤ï¼Œç¼ºä¹ä¸€ä¸ªèƒ½å¤Ÿå¯¹**å¤šGPUå¹¶è¡Œæ¨ç†**è¿›è¡Œç»†ç²’åº¦ã€é«˜ç²¾åº¦èƒ½è€—é¢„æµ‹çš„é€šç”¨æ¡†æ¶ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šPIE-P
ä½œè€…æå‡º **PIE-P**ï¼ˆParallelized Inference Energy Predictorï¼‰ï¼Œä¸€ç§é¢å‘å¤šGPUå¹¶è¡ŒLLMæ¨ç†çš„**ç»†ç²’åº¦èƒ½è€—é¢„æµ‹æ¡†æ¶**ï¼Œæ”¯æŒä¸‰ç§ä¸»æµå¹¶è¡Œç­–ç•¥ï¼š
- **Tensor Parallelism**
- **Pipeline Parallelism**
- **Data Parallelism**

#### æ ¸å¿ƒåˆ›æ–°ç‚¹
1. **Synchronization Samplingï¼ˆåŒæ­¥é‡‡æ ·ï¼‰**
   - é’ˆå¯¹tensor parallelismä¸­AllReduceæ“ä½œå¼•å…¥çš„**éç¡®å®šæ€§ç­‰å¾…æ—¶é—´**ï¼ˆéƒ¨åˆ†GPUç©ºé—²ç­‰å¾…ï¼‰ï¼Œé€šè¿‡å¤šæ¬¡é‡å¤è¿è¡Œæ•è·ç­‰å¾…æ—¶é—´åˆ†å¸ƒï¼Œå¹¶å°†å…¶èƒ½é‡æ¶ˆè€—ä»ç½‘ç»œä¼ è¾“ä¸­åˆ†ç¦»å»ºæ¨¡ã€‚
   - è¿™æ˜¯é¦–æ¬¡æ˜¾å¼å»ºæ¨¡â€œç­‰å¾…ç›¸â€èƒ½è€—çš„å·¥ä½œã€‚

2. **Expanded Model Tree Abstractionï¼ˆæ‰©å±•æ¨¡å‹æ ‘æŠ½è±¡ï¼‰**
   - åœ¨IrEneçš„åŸºç¡€ä¸Šï¼Œåœ¨æ¨¡å‹æ ‘ä¸­å¼•å…¥ä¸“ç”¨é€šä¿¡æ¨¡å—èŠ‚ç‚¹ï¼š
     - `AllReduce` èŠ‚ç‚¹ç”¨äºtensor parallelismï¼›
     - `Point-to-Point Transfer` èŠ‚ç‚¹ç”¨äºpipeline parallelismï¼›
     - `AllGather` èŠ‚ç‚¹ç”¨äºdata parallelismã€‚
   - å®ç°è®¡ç®—ä¸é€šä¿¡èƒ½è€—çš„è”åˆå»ºæ¨¡ã€‚

3. **Aggregate Runtime Feature Representationï¼ˆèšåˆè¿è¡Œæ—¶ç‰¹å¾è¡¨ç¤ºï¼‰**
   - å°†å¤šä¸ªGPUçš„è¿è¡Œæ—¶ç‰¹å¾ï¼ˆå¦‚utilizationã€clock speedï¼‰è¿›è¡Œç»Ÿè®¡èšåˆï¼ˆmean, std, min, maxï¼‰ï¼Œå®ç°å¯æ‰©å±•ä¸”ç»´åº¦ä¸€è‡´çš„è¾“å…¥è¡¨ç¤ºï¼Œé¿å…ä¸ºæ¯ä¸ªGPUå•ç‹¬ç»´æŠ¤ç‰¹å¾å‘é‡ã€‚

4. **Structural Model Featuresï¼ˆç»“æ„åŒ–æ¨¡å‹ç‰¹å¾ï¼‰**
   - å¼•å…¥æ¨¡å‹æ¶æ„ç›¸å…³ç‰¹å¾ï¼ˆå¦‚attention headsæ•°ã€feed-forward dimensionï¼‰ï¼Œä»¥æ•æ‰ä¸åŒå¹¶è¡Œç­–ç•¥ä¸‹é€šä¿¡æ¨¡å¼ä¸èƒ½è€—çš„å…³ç³»ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ˜¯å¦æ”¯æŒå¤šGPU | æ˜¯å¦å»ºæ¨¡é€šä¿¡ | æ˜¯å¦æ”¯æŒç»†ç²’åº¦æ¨¡å—é¢„æµ‹ | å‡†ç¡®æ€§ |
|------|----------------|---------------|----------------------------|--------|
| IrEne | âŒï¼ˆä»…å•GPUï¼‰ | âŒ | âœ… | ä½ï¼ˆ~40% MAPEï¼‰ |
| CodeCarbon | âœ… | âŒï¼ˆä»…GPUåŠŸè€—ï¼‰ | âŒ | ä¸­ï¼ˆ~28â€“36% MAPEï¼‰ |
| Wilkins et al. | âœ… | âŒï¼ˆåŸºäºtokenè®¡æ•°ï¼‰ | âŒ | å·®ï¼ˆ~58% MAPEï¼‰ |
| **PIE-P** | âœ…ï¼ˆå…¨æ”¯æŒï¼‰ | âœ…ï¼ˆæ˜¾å¼å»ºæ¨¡ï¼‰ | âœ…ï¼ˆæ¨¡å—çº§+æ¨¡å‹çº§ï¼‰ | **ä¼˜ï¼ˆ~13â€“17% MAPEï¼‰** |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸æ¨¡å‹
åœ¨å››ç§å¼€æºLLMå®¶æ—ä¸Šè¿›è¡Œå®éªŒï¼Œè¦†ç›–7Bâ€“70Bå‚æ•°è§„æ¨¡ï¼š
- **Vicuna** (7B, 13B, 33B)
- **Mistral** (8B, 24B, 48B)
- **Llama** (7B, 13B, 70B)
- **Qwen** (8B, 14B, 32B)

ä½¿ç”¨ **vLLM** æ¨ç†æœåŠ¡åº“æ‰§è¡Œæ‰€æœ‰æµ‹è¯•ã€‚

---

### å®éªŒå¹³å°
- **CPU**: AMD EPYC Milan 7543P (32æ ¸)
- **GPU**: 4 Ã— NVIDIA RTX A6000 (48GB GDDR6, PCIe 4.0)
- **çœŸå®èƒ½è€—æµ‹é‡**: Watts Up Pro å¤–æ¥åŠŸç‡è®¡ï¼ˆé‡‡é›†æ•´æœºç³»ç»Ÿèƒ½è€—ï¼‰
- **è¿è¡Œæ—¶ç›‘æ§**: NVIDIA-SMI, Linux procfs

---

### è¯„ä¼°æŒ‡æ ‡
- **MAPE**ï¼ˆMean Absolute Percentage Errorï¼‰ä½œä¸ºä¸»è¦è¯„ä»·æŒ‡æ ‡ï¼š
  $$
  \text{MAPE} = \frac{1}{n}\sum_{i=1}^{n} \left|\frac{y_i - \hat{y}_i}{y_i}\right| \times 100\%
  $$

- åˆ†åˆ«æŠ¥å‘Šï¼š
  - **æ¨¡å‹çº§é¢„æµ‹è¯¯å·®**
  - **æ¨¡å—çº§é¢„æµ‹è¯¯å·®**ï¼ˆSelf-Attention, MLP, AllReduceç­‰ï¼‰
  - **è·¨å˜ä½“æ³›åŒ–èƒ½åŠ›**ï¼ˆLeave-One-Outï¼‰
  - **è·¨æ¶æ„æ³›åŒ–èƒ½åŠ›**

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **IrEne (Cao et al., 2021)**  
   æ‰©å±•è‡³å¤šGPUç‰ˆæœ¬ï¼Œä½¿ç”¨èšåˆç‰¹å¾ï¼Œä½†**ä¸åŒ…å«é€šä¿¡æ¨¡å—**ã€‚

2. **CodeCarbon (Courty et al., 2024b)**  
   ä½¿ç”¨NVMLè·å–GPUèƒ½è€—ï¼Œç»“åˆCPUä¼°ç®—ï¼Œå¹¿æ³›ç”¨äºå®é™…éƒ¨ç½²ã€‚

3. **Wilkins et al. (2024)**  
   åŸºäºè¾“å…¥/è¾“å‡ºtokenæ•°é‡çš„å›å½’æ¨¡å‹ï¼š$ e = \alpha_0 T_{in} + \alpha_1 T_{out} + \alpha_2 T_{in}T_{out} $

4. **æ¶ˆèç‰ˆæœ¬ï¼šPIE-P w/o waiting phase**  
   ç§»é™¤å¯¹AllReduceä¸­â€œç­‰å¾…ç›¸â€çš„å»ºæ¨¡ï¼ŒéªŒè¯å…¶é‡è¦æ€§ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ¨¡å‹çº§èƒ½è€—é¢„æµ‹ç²¾åº¦ï¼ˆMAPEï¼‰

| å¹¶è¡Œç­–ç•¥ | PIE-P | CodeCarbon | IrEne | Wilkins et al. |
|---------|-------|------------|-------|----------------|
| **Tensor Parallelism** | **17.6%** | 28.49% (~1.6Ã—) | 40.45% (~2.3Ã—) | 58.77% (~3.3Ã—) |
| **Pipeline Parallelism** | **13.25%** | 36.8% (~2.8Ã—) | 45.6% (~3.4Ã—) | â€” |
| **Data Parallelism** | **14.36%** | 30.25% (~2.1Ã—) | 28.0% (~2.0Ã—) | â€” |

> âœ… PIE-Påœ¨æ‰€æœ‰å¹¶è¡Œç­–ç•¥ä¸‹å‡æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œå¹³å‡é™ä½è¯¯å·® **1.5â€“3å€**ã€‚

---

### æ³›åŒ–èƒ½åŠ›è¡¨ç°

#### ï¼ˆ1ï¼‰è·¨æ¨¡å‹å°ºå¯¸/æ‰¹å¤§å°æ³›åŒ–ï¼ˆLeave-One-Outï¼‰
| ç±»å‹ | æœ€ä½³MAPE | æœ€å·®MAPE | å¹³å‡MAPE |
|------|----------|----------|-----------|
| è·¨æ¨¡å‹å¤§å° | 15.84% (Vicuna 7B) | 24.52% (Mistral 48B) | **19.99%** |
| è·¨æ‰¹å¤§å° | 16.89% | 21.82% | **19.05%** |

âœ… è¡¨æ˜PIE-Pèƒ½æœ‰æ•ˆæ¨å¹¿åˆ°æœªè§è¿‡çš„æ¨¡å‹é…ç½®ã€‚

#### ï¼ˆ2ï¼‰è·¨æ¨¡å‹æ¶æ„æ³›åŒ–ï¼ˆCross-Architecture Generalizationï¼‰
| æ’é™¤çš„æ¨¡å‹æ— | PIE-P MAPE | IrEne MAPE |
|-------------|------------|------------|
| Vicuna      | 24.1%      | 49.3%      |
| Mistral     | 27.0%      | 56.5%      |
| Llama       | 26.1%      | 55.3%      |
| Qwen        | 27.6%      | 58.4%      |

âœ… PIE-Påœ¨è·¨æ¶æ„é¢„æµ‹ä¸Šä»ä¿æŒåˆç†å‡†ç¡®æ€§ï¼Œç›¸å¯¹IrEneæå‡çº¦ **50%ä»¥ä¸Š**ã€‚

---

### æ¨¡å—çº§é¢„æµ‹è¯¯å·®ï¼ˆVicuna, Tensor Parallelismï¼‰

| æ¨¡å— | 2-GPU MAPE | 4-GPU MAPE |
|------|------------|------------|
| Self-Attention | 8.8% | 11.4% |
| MLP | 6.6% | 9.5% |
| **AllReduce** | **17.3%** | **19.4%** |
| LayerNorm/RMSNorm | 6.4% | 7.3% |
| LLMEmbedding | 9.9% | 9.6% |

ğŸ“Œ AllReduceè¯¯å·®è¾ƒé«˜æºäºé€šä¿¡å»¶è¿Ÿçš„éç¡®å®šæ€§ï¼Œä½†ä»å¤„äºå¯ç”¨èŒƒå›´ã€‚

---

### æ¶ˆèå®éªŒç»“æœ

#### ç§»é™¤â€œç­‰å¾…ç›¸â€å»ºæ¨¡ï¼ˆSynchronization Samplingï¼‰
- **å¹³å‡MAPEä»17.6%ä¸Šå‡è‡³36.9%**ï¼ˆå¢åŠ è¿‘2å€ï¼‰
- åœ¨å¤§æ¨¡å‹ï¼ˆå¦‚Vicuna-33Bï¼‰å’Œ4-GPUè®¾ç½®ä¸‹æ¶åŒ–æ›´æ˜æ˜¾
- è¡¨æ˜**åŒæ­¥ç­‰å¾…æ—¶é—´çš„èƒ½é‡ä¸å¯å¿½ç•¥**

#### ç§»é™¤ç»“æ„åŒ–æ¨¡å‹ç‰¹å¾ï¼ˆå¦‚attention headsï¼‰
| æ¨¡å‹å˜ä½“ | å«ç»“æ„ç‰¹å¾ | ä¸å«ç»“æ„ç‰¹å¾ | å·®å¼‚ |
|---------|------------|--------------|------|
| Vicuna 7B | 15.84% | 17.2% | +1.36% |
| Vicuna 13B | 17.72% | 18.2% | +0.48% |
| Vicuna 33B | 17.55% | 20.1% | **+2.55%** |

âœ… ç»“æ„ç‰¹å¾æœ‰åŠ©äºæå‡æ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶åœ¨æ›´å¤§æ¨¡å‹ä¸Šæ•ˆæœæ˜¾è‘—ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å¤šGPUå¹¶è¡Œæ¨ç†çš„èƒ½è€—ä¸èƒ½ä»…é GPUåŠŸè€—ä»£ç†**ï¼ˆå¦‚NVMLï¼‰ï¼Œå¿…é¡»è€ƒè™‘**ç³»ç»Ÿçº§èƒ½è€—**ä¸**é€šä¿¡å¼€é”€**ã€‚
2. **AllReduceé€šä¿¡èƒ½è€—å æ¯”æ˜¾è‘—**ï¼ˆå¯è¾¾æ€»èƒ½è€—çš„35%ä»¥ä¸Šï¼‰ï¼Œä¸”éšGPUæ•°é‡å¢åŠ è€Œä¸Šå‡ï¼ˆè§Figure 5ï¼‰ã€‚
3. **éç¡®å®šæ€§åŒæ­¥ç­‰å¾…æ—¶é—´**æ˜¯å½±å“é¢„æµ‹ç²¾åº¦çš„å…³é”®å› ç´ ï¼Œå¿…é¡»é€šè¿‡ç¦»çº¿é‡‡æ ·å»ºæ¨¡ã€‚
4. PIE-På®ç°äº†**æ¨¡å—çº§+æ¨¡å‹çº§**åŒå±‚æ¬¡é¢„æµ‹ï¼Œæ—¢å¯ç”¨äºç«¯åˆ°ç«¯èƒ½è€—ä¼°è®¡ï¼Œä¹Ÿå¯ç”¨äºè¯†åˆ«èƒ½æ•ˆç“¶é¢ˆï¼ˆå¦‚attentionæˆ–AllReduceæ¨¡å—ï¼‰ã€‚
5. PIE-På…·å¤‡è‰¯å¥½çš„**è·¨æ¨¡å‹ã€è·¨é…ç½®æ³›åŒ–èƒ½åŠ›**ï¼Œé€‚ç”¨äºæ–°å‹LLMå˜ä½“çš„å¿«é€Ÿèƒ½è€—è¯„ä¼°ã€‚

---

### å±€é™æ€§
1. **ç¡¬ä»¶ä¾èµ–æ€§å¼º**ï¼šå½“å‰æ¨¡å‹éœ€é’ˆå¯¹ç‰¹å®šç¡¬ä»¶å¹³å°è®­ç»ƒï¼Œéš¾ä»¥ç›´æ¥è¿ç§»åˆ°å…¶ä»–GPUå‹å·æˆ–ç³»ç»Ÿæ¶æ„ã€‚
2. **ä»…æ”¯æŒDecoder-only Transformer**ï¼šå°šæœªæ‰©å±•è‡³Encoderæˆ–Encoder-Decoderç»“æ„ï¼ˆå¦‚T5ã€BARTï¼‰ã€‚
3. **æœªè€ƒè™‘åŠ¨æ€è°ƒåº¦æˆ–DVFS**ï¼šå‡è®¾è¿è¡Œç¯å¢ƒç¨³å®šï¼Œæœªé›†æˆç”µå‹é¢‘ç‡è°ƒèŠ‚ç­‰èŠ‚èƒ½æŠ€æœ¯çš„å½±å“ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. å¼€å‘**ç¡¬ä»¶æ— å…³çš„èƒ½è€—é¢„æµ‹æ¨¡å‹**ï¼ˆhardware-agnostic modelingï¼‰ã€‚
2. æ‰©å±•è‡³**Encoder-based å’Œ Encoder-Decoder æ¶æ„**ã€‚
3. é›†æˆ**åŠ¨æ€èµ„æºç®¡ç†æœºåˆ¶**ï¼ˆå¦‚DVFSã€batch schedulingï¼‰è¿›è¡Œè”åˆä¼˜åŒ–ã€‚
4. æ¢ç´¢æ›´å¤æ‚çš„æ³¨æ„åŠ›æœºåˆ¶ï¼ˆå¦‚Grouped-Query Attentionï¼‰å¯¹é€šä¿¡æ¨¡å¼çš„å½±å“å»ºæ¨¡ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼šPIE-Pæ˜¯é¦–ä¸ªæ”¯æŒ**ç»†ç²’åº¦ã€å¤šGPUå¹¶è¡ŒLLMæ¨ç†èƒ½è€—é¢„æµ‹**çš„æ¡†æ¶ï¼Œé€šè¿‡æ‰©å±•æ¨¡å‹æ ‘ã€æ˜¾å¼å»ºæ¨¡é€šä¿¡ä¸åŒæ­¥ã€å¼•å…¥ç»“æ„ç‰¹å¾ï¼Œåœ¨ç²¾åº¦ä¸æ³›åŒ–æ€§ä¸Šå…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œä¸ºç»¿è‰²AIä¸èƒ½æ•ˆä¼˜åŒ–æä¾›äº†æœ‰åŠ›å·¥å…·ã€‚

</details>

---

### 4. [BLASST: Dynamic BLocked Attention Sparsity via Softmax Thresholding](https://arxiv.org/abs/2512.12087)

**Authors**: Jiayi Yuan, Cameron Shinn, Kai Xu, Jingze Cui, George Klimiashvili, Guangxuan Xiao, Perkz Zheng, Bo Li, Yuxin Zhou, Zhouhai Ye, Weijie You, Tian Zheng, Dominic Brown, Pengbo Wang, Richard Cai, Julien Demouth, John D. Owens, Xia Hu, Song Han, Timmy Liu, Huizi Mao  
**Category**: cs.CL  
**Published**: 2025-12-16  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.12087v1  

#### Abstract
The growing demand for long-context inference capabilities in Large Language Models (LLMs) has intensified the computational and memory bottlenecks inherent to the standard attention mechanism. To address this challenge, we introduce BLASST, a drop-in sparse attention method that dynamically prunes ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šBLASST: Dynamic Blocked Attention Sparsity via Softmax Thresholding

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿ä¸Šä¸‹æ–‡æ¨ç†ä»»åŠ¡ä¸­é¢ä¸´**æ³¨æ„åŠ›æœºåˆ¶çš„äºŒæ¬¡è®¡ç®—å¤æ‚åº¦ç“¶é¢ˆ**ã€‚éšç€ä¸Šä¸‹æ–‡é•¿åº¦å¢é•¿è‡³ 128K ç”šè‡³ 1M tokensï¼Œæ ‡å‡†æ³¨æ„åŠ›æœºåˆ¶çš„è®¡ç®—å’Œå†…å­˜å¼€é”€æ€¥å‰§ä¸Šå‡ï¼Œå¯¼è‡´æ¨ç†å»¶è¿Ÿé«˜ã€æ˜¾å­˜å ç”¨å¤§ï¼Œä¸¥é‡åˆ¶çº¦å®é™…éƒ¨ç½²ã€‚

ç°æœ‰ç¨€ç–æ³¨æ„åŠ›æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **éœ€è¦é¢„è®¡ç®—æˆ–ä»£ç†åˆ†æ•°**ï¼ˆå¦‚ MInferenceã€XAttentionï¼‰ï¼Œå¸¦æ¥é¢å¤–å¼€é”€ï¼›
- **é™æ€ç¨€ç–æ¨¡å¼ç¼ºä¹çµæ´»æ€§**ï¼Œéš¾ä»¥é€‚åº”ä¸åŒä»»åŠ¡å’Œåºåˆ—é•¿åº¦ï¼›
- å¤šæ•°æ–¹æ³•ä»…ä¼˜åŒ– **prefill æˆ– decode é˜¶æ®µ**ï¼Œæ— æ³•å®ç°ç«¯åˆ°ç«¯åŠ é€Ÿï¼›
- ä¾èµ–å¤æ‚çš„è°ƒåº¦é€»è¾‘ï¼Œéš¾ä»¥æ— ç¼é›†æˆåˆ°ç°ä»£ FlashAttention å†…æ ¸ä¸­ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **BLASST**ï¼ˆBlocked Attention Sparsity via Softmax Thresholdingï¼‰ï¼Œä¸€ç§**æ— éœ€é¢„è®¡ç®—ã€æ— ä»£ç†åˆ†æ•°çš„åŠ¨æ€ç¨€ç–æ³¨æ„åŠ›æ–¹æ³•**ã€‚

#### æ ¸å¿ƒæ€æƒ³ï¼š
åˆ©ç”¨ FlashAttention åœ¨å—çº§åœ¨çº¿ softmax è¿‡ç¨‹ä¸­çš„å·²æœ‰ç»Ÿè®¡é‡ï¼ˆrunning max å’Œ block maxï¼‰ï¼Œé€šè¿‡ä¸€ä¸ªå›ºå®šé˜ˆå€¼ $\lambda$ åŠ¨æ€åˆ¤æ–­æŸ QK å—æ˜¯å¦å¯¹æœ€ç»ˆè¾“å‡ºè´¡çŒ®å¯å¿½ç•¥ã€‚

å…·ä½“åœ°ï¼Œè‹¥æŸå—çš„å±€éƒ¨æœ€å¤§å€¼ $m^{(j)}$ ä¸å½“å‰è¿è¡Œæœ€å¤§å€¼ $m_{\text{max}}^{(j-1)}$ æ»¡è¶³ï¼š
$$
m^{(j)} - m_{\text{max}}^{(j-1)} < \ln(\lambda)
$$
åˆ™è¯¥å—ç»è¿‡ softmax åçš„å€¼å°†è¶‹è¿‘äºé›¶ï¼Œå› æ­¤å¯ä»¥å®‰å…¨è·³è¿‡ä»¥ä¸‹ä¸‰é¡¹æ˜‚è´µæ“ä½œï¼š
1. **Softmax æŒ‡æ•°è®¡ç®—**ï¼ˆexpï¼‰
2. **Value å—ä» HBM åŠ è½½**
3. **P Ã— V çŸ©é˜µä¹˜æ³•**ï¼ˆMMAï¼‰

è¿™ä¸€å†³ç­–ä»…éœ€ä¸€æ¬¡æ¯”è¾ƒæ“ä½œï¼Œå‡ ä¹æ— é¢å¤–å¼€é”€ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | BLASST | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ MInference, XAttention, H2O ç­‰ï¼‰ |
|------|--------|---------------------------------------------|
| **æ˜¯å¦éœ€è¦é¢„è®¡ç®—** | âŒ å¦ | âœ… æ˜¯ï¼ˆå¼•å…¥é¢å¤–å»¶è¿Ÿï¼‰ |
| **æ˜¯å¦ä½¿ç”¨ä»£ç†åˆ†æ•°** | âŒ å¦ | âœ… æ˜¯ï¼ˆå¯èƒ½ä¸å‡†ç¡®ï¼‰ |
| **é€‚ç”¨é˜¶æ®µ** | âœ… prefill + decode | âš ï¸ é€šå¸¸åªæ”¯æŒå…¶ä¸€ |
| **ç¡¬ä»¶å…¼å®¹æ€§** | âœ… å®Œç¾é€‚é… FlashAttention å†…æ ¸ | âš ï¸ éœ€å®šåˆ¶è°ƒåº¦/èåˆ |
| **è®­ç»ƒä¾èµ–** | âœ… å¯ç”¨äºåè®­ç»ƒä¼˜åŒ–ï¼ˆpost-trainingï¼‰ | âš ï¸ éƒ¨åˆ†éœ€é‡æ–°è®­ç»ƒ |
| **çµæ´»æ€§** | âœ… æ”¯æŒ MHA/GQA/MQA/MLA/æ»‘åŠ¨çª—å£ç­‰å˜ä½“ | âš ï¸ æ¶æ„å—é™ |

æ­¤å¤–ï¼ŒBLASST æå‡ºä¸¤ä¸ªå¢å¼ºæŠ€æœ¯ï¼š
- **è‡ªåŠ¨åŒ–æ ¡å‡†**ï¼šå‘ç°æœ€ä¼˜é˜ˆå€¼ $\lambda$ ä¸ä¸Šä¸‹æ–‡é•¿åº¦ $L$ æˆåæ¯”å…³ç³» $\lambda = a / L$ï¼Œå®ç°è·¨é•¿åº¦ç¨³å®šç¨€ç–ç‡ï¼›
- **ç¨€ç–æ„ŸçŸ¥è®­ç»ƒ**ï¼ˆSparsity-aware trainingï¼‰ï¼šåœ¨å¾®è°ƒæ—¶åº”ç”¨ BLASSTï¼Œä½¿æ¨¡å‹å­¦ä¹ æ›´é²æ£’çš„ç¨€ç–æ³¨æ„åŠ›åˆ†å¸ƒã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

| ç±»å‹ | æ•°æ®é›† | æè¿° |
|------|-------|------|
| **é•¿ä¸Šä¸‹æ–‡ç†è§£** | RULER (4Kâ€“128K) | åˆæˆæ£€ç´¢ä¸æ¨ç†ä»»åŠ¡ï¼Œæµ‹è¯•æç«¯é•¿åº¦ä¸‹çš„èƒ½åŠ› |
| | LongBench v2 | åŒ…å«çœŸå®é—®ç­”ã€æ‘˜è¦ã€ä»£ç è¡¥å…¨ç­‰å¤šä»»åŠ¡åŸºå‡† |
| **æ•°å­¦æ¨ç†** | MATH500, AIME 2024 | æ•°å­¦è§£é¢˜èƒ½åŠ›è¯„ä¼° |
| **ç§‘å­¦çŸ¥è¯†** | GPQA | ç ”ç©¶ç”Ÿçº§åˆ«ç§‘å­¦é—®é¢˜ |
| **ä»£ç ç”Ÿæˆ** | LiveCodeBench | ç¼–ç¨‹ä»»åŠ¡ |
| **è¶…é•¿ä»£ç ç†è§£** | RepoQA (up to 200K) | ä»£ç ä»“åº“çº§ä¸Šä¸‹æ–‡ç†è§£ |

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹**
- Llama-3.1-8B-Instruct
- Qwen3-8B-Instruct
- Qwen3-Coder-30B-A3B-Instructï¼ˆç”¨äº RepoQAï¼‰

#### **è¯„ä¼°åœºæ™¯**
- **Prefill-only**ï¼šé•¿ä¸Šä¸‹æ–‡è¾“å…¥å¤„ç†ï¼ˆRULER, LongBenchï¼‰
- **Decode-only**ï¼šç”Ÿæˆå¼æ¨ç†ä»»åŠ¡ï¼ˆMATH, GPQAï¼‰
- **Prefill + Decode**ï¼šç«¯åˆ°ç«¯æ¨ç†åŠ é€Ÿ

#### **è¯„ä¼°æŒ‡æ ‡**
- **å‡†ç¡®æ€§**ï¼šå„ä»»åŠ¡ä¸»æŒ‡æ ‡ï¼ˆå¦‚ Exact Match, Pass@1ï¼‰
- **ç¨€ç–åº¦**ï¼ˆSparsity %ï¼‰ï¼šè¢«è·³è¿‡çš„ attention blocks æ¯”ä¾‹
- **é€Ÿåº¦æå‡**ï¼ˆSpeedup Ã—ï¼‰ï¼šç›¸å¯¹äº FlashAttention-3 BF16 åŸºçº¿çš„æ¨ç†æ—¶é—´å‡å°‘
- **ç¨³å®šæ€§**ï¼šä¸åŒä¸Šä¸‹æ–‡é•¿åº¦ä¸‹ç¨€ç–ç‡çš„ä¸€è‡´æ€§

#### **å®ç°ç»†èŠ‚**
- CUDA å†…æ ¸åŸºäº `flashinfer` æ¡†æ¶å®ç°
- ä½¿ç”¨ **Blackwell (B200)** å’Œ **Hopper (H200)** GPU æµ‹è¯•æ€§èƒ½
- è‡ªåŠ¨æ ¡å‡†ç®—æ³•ï¼šåœ¨å¤šä¸ªé•¿åº¦ï¼ˆ4Kâ€“64Kï¼‰ä¸Šé‡‡æ ·æ•°æ®ï¼Œæ‹Ÿåˆ $\lambda = a/L$

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ–¹æ³• | ç±»å‹ | å¯¹æ¯”ç›®çš„ |
|------|------|----------|
| **Dense Attention** | å…¨æ³¨æ„åŠ›åŸºçº¿ | å‡†ç¡®æ€§åŸºå‡† |
| **MInference**, **FlexPrefill**, **XAttention** | Prefill ç¨€ç–æ–¹æ³• | æ¯”è¾ƒ prefill é˜¶æ®µæ•ˆç‡ä¸ç²¾åº¦ |
| **Quest**, **RocketKV** | Decode é˜¶æ®µ KV ç¼“å­˜å‹ç¼© | æ¯”è¾ƒ decode æ•ˆç‡ä¸é•¿ä¸Šä¸‹æ–‡ä¿æŒèƒ½åŠ› |
| **SpargeAttention** | æœ€æ¥è¿‘è®¾è®¡çš„ç¨€ç–æ–¹æ³• | å¼ºè°ƒ BLASST æ›´é€šç”¨ä¸”æ— éœ€é¢„æµ‹æ¨¡å— |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **é€Ÿåº¦æå‡**
| é˜¶æ®µ | ç¨€ç–åº¦ | é€Ÿåº¦æå‡ï¼ˆÃ—ï¼‰ | å¹³å° |
|------|--------|---------------|-------|
| Prefill | 74.7% | **1.62Ã—** | H200 (Hopper) |
| Decode | 73.2% | **1.48Ã—** | B200 (Blackwell) |
| Prefill | ~50% | ~1.24Ã— | B200 |
| Decode | ~50% | ~1.23Ã— | B200 |

> åœ¨ 0% ç¨€ç–æ—¶ï¼ŒBLASST å¼€é”€æå°ï¼ˆ0.99â€“1.03Ã— baselineï¼‰ï¼Œè¯´æ˜é›†æˆæˆæœ¬ä½ã€‚

---

#### âœ… **å‡†ç¡®æ€§è¡¨ç°ï¼ˆè§ Table 1ï¼‰**

åœ¨ **~75% ç¨€ç–åº¦**ä¸‹ï¼ŒBLASST å‡ ä¹æ— ç²¾åº¦æŸå¤±ï¼Œç”šè‡³éƒ¨åˆ†ä»»åŠ¡ç•¥æœ‰æå‡ï¼š

| æ¨¡å‹ | ä»»åŠ¡ | Dense Acc | BLASST (~75%) Acc | å˜åŒ– |
|------|------|-----------|-------------------|------|
| Llama-3.1-8B | RULER-32K | 92.33 | 91.67 | -0.66 |
| Qwen3-8B | MATH500 | 95.87 | 96.07 | +0.20 |
| Qwen3-8B | AIME 2024 | 75.00 | 75.33 | +0.33 |

> **åç›´è§‰ç°è±¡è§£é‡Š**ï¼šç¨€ç–åŒ–å¯èƒ½èµ·åˆ°â€œå»å™ªâ€ä½œç”¨ï¼Œè¿‡æ»¤å†—ä½™ tokenï¼Œæå‡æ¨ç†é“¾æ¸…æ™°åº¦ã€‚

---

#### âœ… **ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆTable 2 & 3ï¼‰**

| æ–¹æ³• | RULER Avg (Prefill) | LongBench Overall |
|------|---------------------|--------------------|
| Dense Attention | 93.21 | 31.4 |
| MInference | 84.15 | 31.2 |
| FlexPrefill | 87.72 | 25.7 |
| XAttention | 92.44 | 30.6 |
| **BLASST (~50%)** | **92.87** | **31.8** |

> BLASST åœ¨æ‰€æœ‰ç¨€ç–æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³ï¼Œæ¥è¿‘ dense æ€§èƒ½ï¼Œä¸”æ— éœ€é¢„è®¡ç®—ã€‚

| æ–¹æ³• | Decode å¹³å‡å¾—åˆ† |
|------|------------------|
| Dense | 68.57 |
| Quest | 60.75 |
| RocketKV | 66.91 |
| **BLASST (~50%)** | **68.97** |

> åœ¨ decode é˜¶æ®µä¹Ÿä¼˜äº KV å‹ç¼©ç±»æ–¹æ³•ã€‚

---

#### âœ… **æ¶ˆèå®éªŒç»“æœ**

##### ï¼ˆ1ï¼‰**æ ¡å‡†æœ‰æ•ˆæ€§ï¼ˆTable 5ï¼‰**
| ç›®æ ‡ç¨€ç–åº¦ | å›ºå®šé˜ˆå€¼ï¼ˆ$\lambda=1e^{-3}$ï¼‰ç¨€ç–èŒƒå›´ | æ ¡å‡†åï¼ˆ$\lambda=a/L$ï¼‰ç¨€ç–èŒƒå›´ |
|------------|-------------------------------|------------------------------|
| 50% | 23% â†’ 75%ï¼ˆæ³¢åŠ¨æå¤§ï¼‰ | 46.96% â†’ 54.20%ï¼ˆç¨³å®šï¼‰ |
| 70% | 42% â†’ 85% | 68% â†’ 75% |

> è¡¨æ˜ **è‡ªåŠ¨æ ¡å‡†æ˜¾è‘—æå‡éƒ¨ç½²å¯é æ€§**ã€‚

##### ï¼ˆ2ï¼‰**ç¨€ç–æ„ŸçŸ¥è®­ç»ƒæ•ˆæœï¼ˆFigure 6ï¼‰**
- åœ¨ 70%+ ç¨€ç–ä¸‹ï¼Œ**ç¨€ç–è®­ç»ƒæ¨¡å‹æ¯”åè®­ç»ƒç¨€ç–é«˜å‡ºæœ€å¤š 1.7Ã— å‡†ç¡®ç‡**
- è¡¨æ˜æ¨¡å‹å¯é€šè¿‡è®­ç»ƒå­¦ä¼šå°†é‡è¦ä¿¡æ¯é›†ä¸­åœ¨é«˜åˆ†å—ä¸­

##### ï¼ˆ3ï¼‰**ä¸å…¶ä»–æ–¹æ³•ç»„åˆï¼ˆTable 6ï¼‰**
| ç»„åˆæ–¹å¼ | RULER-16K å˜åŒ– |
|---------|----------------|
| XAttention (prefill) + BLASST (decode) | -0.33 |
| BLASST (prefill) + RocketKV (decode) | -0.62 |

> è¡¨æ˜ BLASST ä¸å…¶ä»–ç¨€ç–æ–¹æ³•**æ­£äº¤å…¼å®¹**ï¼Œå¯ç”¨äºæ„å»ºæ··åˆé«˜æ•ˆç³»ç»Ÿã€‚

##### ï¼ˆ4ï¼‰**è¶…é•¿åºåˆ—è¡¨ç°ï¼ˆTable 7ï¼‰**
| ä¸Šä¸‹æ–‡ | æ¨¡å¼ | Prefill Sparsity | Decode Sparsity | Accuracy |
|--------|------|------------------|------------------|----------|
| 16K | Full | 0% | 0% | 0.897 |
| 16K | BLASST P+D | 64.1% | 48.4% | 0.882 |
| 200K | Full | 0% | 0% | 0.850 |
| 200K | BLASST P+D | 57.5% | 40.8% | 0.838 |

> å³ä½¿åœ¨ 200K é•¿åº¦ä¸‹ä»ä¿æŒé«˜ç¨€ç–åº¦ä¸ä½ç²¾åº¦æŸå¤±ï¼ŒéªŒè¯å…¶**æç«¯é•¿åº¦é€‚ç”¨æ€§**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **åŠ¨æ€ç¨€ç–æ— éœ€é¢„è®¡ç®—ä¹Ÿèƒ½é«˜æ•ˆå‡†ç¡®**  
   åˆ©ç”¨ FlashAttention ä¸­å·²æœ‰çš„ running max å’Œ block maxï¼Œå³å¯åšå‡ºå¯é è·³è¿‡å†³ç­–ï¼Œé¿å…ä»£ç†åˆ†æ•°è¯¯å·®ã€‚

2. âœ… **ç¨€ç–æœ¬èº«å¯èƒ½æ˜¯æœ‰ç›Šçš„**  
   åœ¨é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸­ï¼Œä½ attention åˆ†æ•°å—å¸¸ä¸ºå™ªå£°ï¼Œè·³è¿‡å®ƒä»¬ç›¸å½“äºéšå¼å»å™ªï¼Œæœ‰æ—¶åè€Œæå‡æ€§èƒ½ã€‚

3. âœ… **ç¨€ç–ç‡å†³å®šç²¾åº¦ï¼Œè€Œéç»å¯¹é˜ˆå€¼**  
   ä¸åŒé•¿åº¦ä¸‹åº”ç»´æŒç›¸åŒç¨€ç–ç‡ä»¥ä¿è¯ä¸€è‡´æ€§ï¼Œç”±æ­¤å¯¼å‡º $\lambda = a/L$ çš„é€†æ¯”ä¾‹å…³ç³»ã€‚

4. âœ… **ç¨€ç–å¯è®­ç»ƒ**  
   åœ¨å¾®è°ƒé˜¶æ®µå¼•å…¥ BLASSTï¼Œèƒ½è®©æ¨¡å‹ä¸»åŠ¨é€‚åº”ç¨€ç–ç»“æ„ï¼Œè¿›ä¸€æ­¥æ¨é«˜ accuracy-sparsity æ›²çº¿ã€‚

5. âœ… **ç¡¬ä»¶çº§ä¼˜åŒ–è‡³å…³é‡è¦**  
   ä¸“é—¨è®¾è®¡ prefillï¼ˆcompute-boundï¼‰å’Œ decodeï¼ˆmemory-boundï¼‰å†…æ ¸ï¼Œåˆ†åˆ«è·³è¿‡ MMA å’Œ V åŠ è½½ï¼Œæœ€å¤§åŒ–æ”¶ç›Šã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ– FlashAttention æ¶æ„**  
   è™½ç„¶å…¼å®¹æ€§å¼ºï¼Œä½†ä»éœ€å—çº§åœ¨çº¿ softmax ç»“æ„ï¼Œä¸é€‚ç”¨äºæ‰€æœ‰ attention å®ç°ã€‚

2. **æç«¯ç¨€ç–å¯èƒ½å¯¼è‡´ä¿¡æ¯ä¸¢å¤±**  
   å½“ç¨€ç–åº¦è¶…è¿‡ 80%ï¼Œéƒ¨åˆ†ä»»åŠ¡å¼€å§‹å‡ºç°æ˜æ˜¾ä¸‹é™ï¼Œéœ€è°¨æ…é€‰æ‹©é˜ˆå€¼ã€‚

3. **ç›®å‰æœªæ¢ç´¢åŠ¨æ€é˜ˆå€¼ per-head/per-layer**  
   å›¾ 7 æ˜¾ç¤ºä¸åŒ head å’Œ layer çš„ç¨€ç–åˆ†å¸ƒå·®å¼‚å¤§ï¼Œæœªæ¥å¯åšè‡ªé€‚åº”é˜ˆå€¼åˆ†é…ã€‚

4. **å¯¹ very short context æå‡æœ‰é™**  
   åœ¨çŸ­åºåˆ—ä¸­ç¨€ç–ç©ºé—´å°ï¼ŒåŠ é€Ÿæ•ˆæœä¸æ˜æ˜¾ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **ç»“åˆ Learned Sparsity**  
   å°† BLASST ä¸å¯å­¦ä¹ é—¨æ§æœºåˆ¶ç»“åˆï¼Œåœ¨è®­ç»ƒä¸­è”åˆä¼˜åŒ–ç¨€ç–æ¨¡å¼ã€‚

2. **Hybrid Sparse Patterns**  
   ä¸æ»‘åŠ¨çª—å£ã€sink token ç­‰é™æ€æ¨¡å¼ç»“åˆï¼Œå½¢æˆ hybrid sparse attentionã€‚

3. **Adaptive Per-Head Thresholding**  
   åŸºäºå›¾ 7 çš„è§‚å¯Ÿï¼Œä¸ºæ¯ä¸ª attention head æˆ– layer å­¦ä¹ ä¸ªæ€§åŒ–é˜ˆå€¼ã€‚

4. **æ‰©å±•è‡³ Vision & Multimodal Models**  
   æ¢ç´¢åœ¨è§†è§‰ Transformer æˆ–å¤šæ¨¡æ€æ¨¡å‹ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

5. **ç¼–è¯‘å™¨çº§é›†æˆ**  
   å°† BLASST å†³ç­–é€»è¾‘åµŒå…¥ Triton æˆ– MLIR ç¼–è¯‘æµç¨‹ï¼Œå®ç°å…¨è‡ªåŠ¨ç¨€ç–åŒ–ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **BLASST æ˜¯ä¸€ç§ç®€å•ã€é«˜æ•ˆã€æ— éœ€è®­ç»ƒã€å³æ’å³ç”¨çš„ç¨€ç–æ³¨æ„åŠ›æ–¹æ³•ï¼Œå®ƒé€šè¿‡å¤ç”¨ softmax ç»Ÿè®¡é‡å®ç°åŠ¨æ€å‰ªæï¼Œåœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶ï¼Œåœ¨ç°ä»£ GPU ä¸Šå®ç°äº†æœ€é«˜ 1.6Ã— çš„æ¨ç†åŠ é€Ÿï¼Œæ˜¯è¿ˆå‘å®ç”¨åŒ–é•¿ä¸Šä¸‹æ–‡ LLM æ¨ç†çš„é‡è¦ä¸€æ­¥ã€‚**

</details>

---

### 5. [FlashFuser: Expanding the Scale of Kernel Fusion for Compute-Intensive Operators via Inter-Core Connection](https://arxiv.org/abs/2512.12949)

**Authors**: Ziyu Huang, Yangjie Zhou, Zihan Liu, Xinhao Luo, Yijia Diao, Minyi Guo, Jidong Zhai, Yu Feng, Chen Zhang, Anbang Wu, Jingwen Leng  
**Category**: cs.DC  
**Published**: 2025-12-16  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.12949v1  

#### Abstract
The scaling of computation throughput continues to outpace improvements in memory bandwidth, making many deep learning workloads memory-bound. Kernel fusion is a key technique to alleviate this problem, but the fusion strategies of existing compilers and frameworks are limited to using local scratch...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFlashFuser: Expanding the Scale of Kernel Fusion for Compute-Intensive Operators via Inter-Core Connection

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ç°ä»£æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚å¤§è¯­è¨€æ¨¡å‹ LLM å’Œå¤šæ¨¡æ€æ¨¡å‹ï¼‰çš„è®¡ç®—ååé‡å¢é•¿è¿œè¶…å†…å­˜å¸¦å®½çš„å¢é•¿ï¼Œå¯¼è‡´è®¸å¤šå·¥ä½œè´Ÿè½½æˆä¸º **memory-bound**ã€‚å°½ç®¡ **kernel fusion** æ˜¯ç¼“è§£è¯¥é—®é¢˜çš„å…³é”®æŠ€æœ¯ï¼Œä½†ç°æœ‰ç¼–è¯‘å™¨å’Œæ¡†æ¶å—é™äºå•ä¸ª SMï¼ˆStreaming Multiprocessorï¼‰çš„ **shared memory (SMEM)** å®¹é‡ï¼Œå½“ä¸­é—´ç»“æœè¿‡å¤§ï¼ˆå¦‚ FFN å±‚ï¼‰æ—¶æ— æ³•è¿›è¡Œèåˆï¼Œè¢«è¿«å†™å›å…¨å±€å†…å­˜ï¼Œé€ æˆå¤§é‡å†—ä½™çš„æ•°æ®ä¼ è¾“ã€‚

æ­¤å¤–ï¼Œè™½ç„¶ç°ä»£ GPUï¼ˆå¦‚ NVIDIA H100ï¼‰å¼•å…¥äº† **Distributed Shared Memory (DSM)**ï¼Œé€šè¿‡ SM é—´çš„äº’è¿æä¾›æ›´å¤§ã€æ›´é«˜å¸¦å®½ã€æ›´ä½å»¶è¿Ÿçš„ç‰‡ä¸Šå†…å­˜æ± ï¼Œä½†å½“å‰è½¯ä»¶æ¡†æ¶æœªèƒ½æœ‰æ•ˆåˆ©ç”¨è¿™ä¸€ç¡¬ä»¶ç‰¹æ€§ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **FlashFuser**ï¼Œæ˜¯é¦–ä¸ªåœ¨ç°ä»£ GPU ä¸Šåˆ©ç”¨ **inter-core connection**ï¼ˆå³ DSMï¼‰å®ç°å¤§è§„æ¨¡ kernel fusion çš„ç¼–è¯‘å™¨æ¡†æ¶ã€‚å…¶ä¸‰å¤§æ ¸å¿ƒè´¡çŒ®å¦‚ä¸‹ï¼š

#### âœ… **1. åŸºäº DSM çš„é€šä¿¡æŠ½è±¡ï¼ˆdsm_comm primitiveï¼‰**
- æå‡ºäº†ä¸€å¥—ç»Ÿä¸€çš„é€šä¿¡åŸè¯­ï¼Œå½¢å¼åŒ–æè¿°åŸºäºé›†ç¾¤ï¼ˆclusterï¼‰çš„å¤æ‚æ•°æ®äº¤æ¢æ¨¡å¼ï¼Œå¦‚ï¼š
  - `dsm_all_exchange`ï¼ˆç”¨äº All-Reduceï¼‰
  - `dsm_shuffle`ï¼ˆç”¨äºæ•°æ®åˆ†å‘ï¼‰
  - `dsm_reduce_scatter`ï¼ˆç”¨äºåˆ†å±‚è§„çº¦ï¼‰
- æ”¯æŒçµæ´»é…ç½® **shuffle** å’Œ **reduce** ç»´åº¦ï¼Œé€‚åº”ä¸åŒé—®é¢˜è§„æ¨¡å’Œç¡¬ä»¶æ‹“æ‰‘ã€‚

#### âœ… **2. æ•°æ®æµåˆ†æå™¨ï¼ˆDataflow Analyzerï¼‰**
- å°†ä¼ ç»Ÿçš„ loop schedulingã€èµ„æºæ˜ å°„å’Œ tile é€‰æ‹©æ‰©å±•åˆ°åˆ†å¸ƒå¼å†…å­˜å±‚æ¬¡ï¼ˆregister â†’ SMEM â†’ DSM â†’ L2/globalï¼‰ã€‚
- é‡åŒ–è·¨å†…å­˜å±‚çº§çš„æ•°æ®ç§»åŠ¨æˆæœ¬ï¼Œå†³å®šæœ€ä¼˜æ‰§è¡Œé¡ºåºå’Œ tile å¤§å°ã€‚
- æ”¯æŒâ€œæ¸è¿›å¼æº¢å‡ºâ€ç­–ç•¥ï¼šä¼˜å…ˆä½¿ç”¨é«˜é€Ÿç¼“å­˜ï¼Œå®¹é‡ä¸è¶³æ—¶é€æ­¥ä¸‹æº¢è‡³ DSM æˆ–æ›´æ…¢å±‚çº§ã€‚

#### âœ… **3. èåˆæœç´¢å¼•æ“ï¼ˆFusion Search Engineï¼‰**
- æ„å»ºäº†ä¸€ä¸ªé«˜æ•ˆçš„æœç´¢ç©ºé—´å¯¼èˆªç³»ç»Ÿï¼Œç»“åˆï¼š
  - **è§£æå¼æˆæœ¬æ¨¡å‹**ï¼ˆanalytical cost modelï¼‰ï¼šä»¥æœ€å°åŒ–ç“¶é¢ˆå±‚çº§çš„æ•°æ®ç§»åŠ¨ä¸ºç›®æ ‡ã€‚
  - **DSM-aware çš„å‰ªæç­–ç•¥**ï¼šæå‡º 5 æ¡å‰ªæè§„åˆ™ï¼Œå°†åŸå§‹ ~2.75Ã—10Â¹Â³ çš„å€™é€‰ç©ºé—´å‹ç¼© >99.99%ï¼Œå¤§å¹…æå‡æœç´¢æ•ˆç‡ã€‚
- æœ€ç»ˆé€šè¿‡ç¦»çº¿æœç´¢ + è¿è¡Œæ—¶æŸ¥è¡¨ï¼ˆbinning + lookupï¼‰å®ç°é«˜æ•ˆéƒ¨ç½²ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| å¯¹æ¯”ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Chimeraã€BOLTï¼‰ | FlashFuser |
|--------|----------------------------|-----------|
| å†…å­˜å±‚çº§æ”¯æŒ | ä»… reg / SMEM | æ”¯æŒ reg / SMEM / **DSM** |
| èåˆèƒ½åŠ› | å—é™äºå• SM çš„ SMEM å®¹é‡ï¼ˆ~227KBï¼‰ | åˆ©ç”¨ DSM æ‰©å±• on-chip å†…å­˜ï¼Œæ”¯æŒæ›´å¤§ç®—å­é“¾èåˆ |
| é€šä¿¡å»ºæ¨¡ | å¿½ç•¥ inter-core é€šä¿¡ | æ˜¾å¼å»ºæ¨¡ DSM å¸¦å®½ä¸å»¶è¿Ÿéš cluster size çš„å˜åŒ– |
| æœç´¢ç­–ç•¥ | å›ºå®šè°ƒåº¦æˆ–æ‰‹åŠ¨è°ƒä¼˜ | è‡ªåŠ¨åŒ–ã€åˆ†æé©±åŠ¨çš„æœç´¢ + é«˜æ•ˆå‰ªæ |
| æ€§èƒ½æ”¶ç›Š | æœ‰é™åŠ é€Ÿï¼ˆå°¤å…¶å¯¹å¤§æ¨¡å‹ï¼‰ | æ˜¾è‘—é™ä½å†…å­˜è®¿é—®ï¼Œå®ç°æ•°å€åŠ é€Ÿ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹é…ç½®**

å®éªŒè¦†ç›–å¤šç§å…¸å‹æ·±åº¦å­¦ä¹ ç®—å­é“¾ï¼š

- **GEMM Chains**ï¼šæ¨¡æ‹Ÿ Transformer ä¸­çš„ FFN å±‚ï¼Œæ¥è‡ª GPTã€LLaMAã€BERT ç­‰æ¨¡å‹ï¼ˆè§ Table VIIï¼‰
- **Convolution Chains**ï¼šæ¥è‡ª ResNet ç»“æ„çš„ conv-bottleneck æ¨¡å—ï¼ˆè§ Table Vï¼‰
- **Gated FFN**ï¼šå«åˆ†æ”¯ç»“æ„çš„ FFNï¼ˆå¦‚ SwiGLUï¼‰ï¼Œæ¥è‡ª LLaMAã€Qwen ç³»åˆ—æ¨¡å‹ï¼ˆè§ Table VIï¼‰

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **å¹³å°**ï¼šNVIDIA H100 SXM GPUï¼ŒCUDA 12.4ï¼ŒPyTorch 2.6
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **ç«¯åˆ°ç«¯æ‰§è¡Œæ—¶é—´**
  - **kernel speedup**ï¼ˆç›¸å¯¹äºåŸºçº¿ï¼‰
  - **global memory access volume**
  - **TFLOPS åˆ©ç”¨ç‡**
  - **ablation study** éªŒè¯å„æ¨¡å—è´¡çŒ®
- **æœç´¢å‚æ•°**ï¼šTop-K è®¾ç½®ä¸º 11ï¼Œç»éªŒè¯å¯ç¨³å®šè¾¾åˆ°è¿‘æœ€ä¼˜æ€§èƒ½

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| ç±»å‹ | åŸºçº¿æ–¹æ³• |
|-----|---------|
| **å·¥ä¸šçº§åº“** | PyTorchï¼ˆå¯ç”¨ `torch.compile`ï¼‰ã€TensorRT |
| **ç ”ç©¶å‹ç¼–è¯‘å™¨** | TVM/Relayã€TASOã€BOLTã€Chimera |
| **å…¶ä»–ç›¸å…³å·¥ä½œ** | SGLangï¼ˆæ¨ç†æ¡†æ¶ï¼‰ |

> æ³¨ï¼šæ‰€æœ‰åŸºçº¿å‡æœªåˆ©ç”¨ DSM è¿›è¡Œ kernel fusionã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **å¹³å‡ kernel speedup vs. é«˜åº¦ä¼˜åŒ–åº“ï¼ˆPyTorch/TensorRTï¼‰** | **3.3Ã—** |
| **å¹³å‡ kernel speedup vs. SOTA ç¼–è¯‘å™¨ï¼ˆChimera/BOLTï¼‰** | **4.1Ã—** |
| **å…¨å±€å†…å­˜è®¿é—®å‡å°‘æ¯”ä¾‹** | **58%** |
| **ç«¯åˆ°ç«¯ï¼ˆend-to-endï¼‰æ¨ç†åŠ é€Ÿæ¯”** | **1.24Ã—** |

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### ğŸ”¹ **GEMM Chainsï¼ˆå›¾10aï¼‰**
- FlashFuser å¹³å‡æé€Ÿï¼š
  - 5.4Ã— over BOLT
  - 4.6Ã— over Chimera
  - 3.1Ã— over PyTorch
- åœ¨å¤§æ¨¡å‹ï¼ˆå¦‚ GPT-6.7Bï¼‰ä¸Šï¼ŒChimera å›  SMEM ä¸è¶³è€Œ **fusion fail**ï¼ŒFlashFuser æˆåŠŸèåˆå¹¶æ˜¾è‘—åŠ é€Ÿã€‚

#### ğŸ”¹ **Convolution Chainsï¼ˆå›¾10bï¼‰**
- å¹³å‡æé€Ÿï¼š
  - 6.3Ã— over BOLT
  - 6.4Ã— over Chimera
  - 3.9Ã— over PyTorch
- å°è§„æ¨¡ conv å¯è¢« BOLT èåˆï¼Œä½†å¤§è§„æ¨¡æ—¶æ”¾å¼ƒ fusionï¼›FlashFuser åˆ©ç”¨ DSM æˆåŠŸèåˆã€‚

#### ğŸ”¹ **Gated FFNï¼ˆå›¾10cï¼‰**
- æ”¯æŒå¤æ‚åˆ†æ”¯ç»“æ„ï¼ˆå¦‚ SwiGLUï¼‰ï¼ŒFlashFuser å®ç°ç¨³å®šåŠ é€Ÿï¼Œè€Œå¤šæ•°åŸºçº¿æ— æ³•æœ‰æ•ˆèåˆã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

ï¼ˆè§ Figure 15ï¼‰

| é…ç½® | ç›¸å¯¹äº no-fusion çš„ speedup |
|------|-----------------------------|
| **DA**ï¼ˆä»…ä½¿ç”¨ SMEM/globalï¼‰ | 1.52Ã— |
| **DC + DA**ï¼ˆéšæœºé…ç½® + dsm_commï¼‰ | 2.11Ã— |
| **All**ï¼ˆå®Œæ•´ FlashFuserï¼‰ | **3.29Ã—** |

âœ… è¡¨æ˜ï¼š
- DSM æœ¬èº«å¸¦æ¥æ˜¾è‘—å¢ç›Šï¼ˆä» 1.52Ã— â†’ 2.11Ã—ï¼‰
- æœç´¢å¼•æ“ + æˆæœ¬æ¨¡å‹è¿›ä¸€æ­¥æå‡è‡³ 3.29Ã—

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **DSM æ˜¯çªç ´ kernel fusion è§„æ¨¡é™åˆ¶çš„å…³é”®**ï¼š
   - åˆ©ç”¨ DSM å¯å°† on-chip å†…å­˜æ± æ‰©å¤§æ•°å€ï¼Œä½¿åŸæœ¬å›  SMEM ä¸è¶³è€Œå¤±è´¥çš„ fusion æˆä¸ºå¯èƒ½ã€‚
   
2. **æ˜¾å¼å»ºæ¨¡ inter-core é€šä¿¡è‡³å…³é‡è¦**ï¼š
   - DSM çš„å¸¦å®½å’Œå»¶è¿Ÿéš cluster size å˜åŒ–ï¼Œéœ€åŠ¨æ€é€‰æ‹©æœ€ä¼˜é…ç½®ã€‚
   - `dsm_comm` æŠ½è±¡æœ‰æ•ˆå°è£…äº†å¤æ‚é€šä¿¡æ¨¡å¼ã€‚

3. **åˆ†æé©±åŠ¨çš„æœç´¢ä¼˜äºçº¯å¯å‘å¼æˆ–æš´åŠ›æœç´¢**ï¼š
   - æå‡ºçš„å‰ªæè§„åˆ™å°†æœç´¢ç©ºé—´å‹ç¼© >99.99%ï¼ŒåŒæ—¶ä¿æŒé«˜ç²¾åº¦ã€‚
   - æˆæœ¬æ¨¡å‹èƒ½å‡†ç¡®é¢„æµ‹æœ€ä¼˜é…ç½®ï¼ˆTop-11 è¦†ç›–ç‡è¾¾ 100%ï¼‰ã€‚

4. **æ€§èƒ½æå‡ä¸»è¦æºäºå†…å­˜è®¿é—®å‡å°‘**ï¼š
   - FlashFuser å‡å°‘ 58% å…¨å±€å†…å­˜è®¿é—®ï¼Œé¿å…äº†â€œwrite-then-readâ€çš„å†—ä½™è·¯å¾„ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ç›®å‰ä»…é’ˆå¯¹ H100 å®ç°**ï¼š
   - è™½ç„¶ `dsm_comm` è®¾è®¡å…·æœ‰æ‹“æ‰‘æ— å…³æ€§ï¼Œä½†åœ¨ mesh æ¶æ„ï¼ˆå¦‚ Cerebrasï¼‰ä¸Šçš„æ˜ å°„ä»éœ€é€‚é…ã€‚
   
2. **ä¾èµ–é™æ€ shape**ï¼š
   - å½“å‰å®ç°å‡è®¾ N/K/L ç»´åº¦å›ºå®šï¼Œä»… M åŠ¨æ€å˜åŒ–ï¼Œé€‚ç”¨äº FFN æ¨ç†åœºæ™¯ï¼Œä½†å¯¹å®Œå…¨åŠ¨æ€ shape æ”¯æŒæœ‰é™ã€‚

3. **ç¦»çº¿æœç´¢å¼€é”€å­˜åœ¨**ï¼š
   - å°½ç®¡æ¯” brute-force å¿« 12â€“68Ã—ï¼ˆè§ Table VIIIï¼‰ï¼Œä½†ä»éœ€ä¸€å®šé¢„å¤„ç†æ—¶é—´ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ‰©å±•è‡³æ›´å¤šç¡¬ä»¶æ¶æ„**ï¼š
   - åœ¨ Graphcore IPUã€Cerebras WSE ç­‰æ”¯æŒ inter-core è¿æ¥çš„èŠ¯ç‰‡ä¸ŠéªŒè¯é€šç”¨æ€§ã€‚

2. **æ”¯æŒåŠ¨æ€ shape å’Œ runtime adaptation**ï¼š
   - å¼•å…¥è½»é‡çº§åœ¨çº¿ profiling æˆ–é¢„æµ‹æœºåˆ¶ï¼Œé€‚åº”è¾“å…¥é•¿åº¦å˜åŒ–æ›´å¤§çš„åœºæ™¯ã€‚

3. **ä¸è°ƒåº¦å™¨ååŒä¼˜åŒ–ï¼ˆå¦‚ PipeThreaderï¼‰**ï¼š
   - å¦‚å›¾14æ‰€ç¤ºï¼ŒFlashFuser å¯ä½œä¸ºåº•å±‚ kernel ç”Ÿæˆå™¨ï¼Œä¸é«˜å±‚è°ƒåº¦å™¨ç»“åˆå®ç°æ›´å¤§ç³»ç»Ÿçº§åŠ é€Ÿã€‚

4. **æ¢ç´¢æ›´å¤šå¤åˆç®—å­èåˆæ¨¡å¼**ï¼š
   - å°† DSM èåˆæ€æƒ³æ¨å¹¿è‡³ Attentionã€RMSNormã€RoPE ç­‰æ›´å¤æ‚çš„ operator chainsã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> FlashFuser é¦–æ¬¡ç³»ç»Ÿæ€§åœ°å°† **DSM** å¼•å…¥ kernel fusion ç¼–è¯‘å™¨è®¾è®¡ï¼Œé€šè¿‡ **é€šä¿¡æŠ½è±¡ + æ•°æ®æµåˆ†æ + æ™ºèƒ½æœç´¢** ä¸‰é‡åˆ›æ–°ï¼Œåœ¨ H100 ä¸Šå®ç°äº† **æœ€é«˜ 4.1Ã— kernel åŠ é€Ÿ** å’Œ **1.24Ã— ç«¯åˆ°ç«¯æé€Ÿ**ï¼Œä¸ºè§£å†³ memory wall é—®é¢˜æä¾›äº†æ–°çš„è½¯ä»¶èŒƒå¼ã€‚

</details>

---

### 6. [Optimal Resource Allocation for ML Model Training and Deployment under Concept Drift](https://arxiv.org/abs/2512.12816)

**Authors**: Hasan Burhan Beytur, Gustavo de Veciana, Haris Vikalo, Kevin S Chan  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.12816v1  

#### Abstract
We study how to allocate resources for training and deployment of machine learning (ML) models under concept drift and limited budgets. We consider a setting in which a model provider distributes trained models to multiple clients whose devices support local inference but lack the ability to retrain...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šOptimal Resource Allocation for ML Model Training and Deployment under Concept Drift

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡ç ”ç©¶åœ¨**æ¦‚å¿µæ¼‚ç§»**ï¼ˆConcept Driftï¼‰ç¯å¢ƒä¸‹ï¼Œæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒä¸éƒ¨ç½²ä¸­çš„**èµ„æºåˆ†é…ä¼˜åŒ–é—®é¢˜**ã€‚å…·ä½“åœºæ™¯ä¸ºï¼š
- ä¸€ä¸ªä¸­å¿ƒåŒ–çš„æ¨¡å‹æä¾›æ–¹è´Ÿè´£è®­ç»ƒæ¨¡å‹å¹¶åˆ†å‘ç»™å¤šä¸ªå®¢æˆ·ç«¯ï¼›
- å®¢æˆ·ç«¯å…·å¤‡æœ¬åœ°æ¨ç†èƒ½åŠ›ï¼Œä½†æ— æ³•é‡æ–°è®­ç»ƒæ¨¡å‹ï¼›
- æ¨¡å‹æ€§èƒ½å› æ•°æ®åˆ†å¸ƒéšæ—¶é—´å˜åŒ–è€Œä¸‹é™ï¼ˆå³æ¦‚å¿µæ¼‚ç§»ï¼‰ï¼Œéœ€å®šæœŸé‡è®­ä¸æ›´æ–°ï¼›
- èµ„æºï¼ˆè®¡ç®—ã€é€šä¿¡ï¼‰æœ‰é™ï¼Œéœ€åœ¨é¢„ç®—çº¦æŸä¸‹æœ€å¤§åŒ–é•¿æœŸå¹³å‡æ€§èƒ½ã€‚

è¯¥é—®é¢˜å¹¿æ³›å­˜åœ¨äºç°å®ä¸–ç•Œä¸­çš„ MLOpsã€è¾¹ç¼˜è®¡ç®—ã€æŒç»­å­¦ä¹ ç­‰ç³»ç»Ÿä¸­ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯

ä½œè€…æå‡ºäº†ä¸€ç§**æ¨¡å‹æ— å…³**ï¼ˆmodel-agnosticï¼‰çš„åˆ†ææ¡†æ¶ï¼Œç»Ÿä¸€å»ºæ¨¡äº†ä»¥ä¸‹ä¸‰ä¸ªå…³é”®å› ç´ ä¹‹é—´çš„äº¤äº’å…³ç³»ï¼š
1. **è®­ç»ƒèµ„æºåˆ†é…ç­–ç•¥**ï¼ˆTraining Resource Allocationï¼‰
2. **æ¦‚å¿µæ¼‚ç§»åŠ¨æ€**ï¼ˆConcept Drift Dynamicsï¼‰
3. **æ¨¡å‹éƒ¨ç½²è°ƒåº¦**ï¼ˆModel Deployment Schedulingï¼‰

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

- **ç†è®ºé©±åŠ¨çš„æœ€ä¼˜æ§åˆ¶å»ºæ¨¡**  
  å°†è®­ç»ƒèµ„æºåˆ†é…é—®é¢˜å½¢å¼åŒ–ä¸ºä¸€ä¸ª**æ— é™æ—¶åŸŸæœ€ä¼˜æ§åˆ¶é—®é¢˜**ï¼ˆinfinite-horizon optimal controlï¼‰ï¼Œåˆ©ç”¨ Pontryaginâ€™s Maximum Principle åˆ†ææœ€ä¼˜è§£ç»“æ„ã€‚

- **æ­ç¤ºâ€œè€åŒ–ç‰¹æ€§â€å¯¹ç­–ç•¥çš„å½±å“**  
  é¦–æ¬¡è¯æ˜ï¼šæœ€ä¼˜è®­ç»ƒç­–ç•¥çš„ç»“æ„å–å†³äº**æ¦‚å¿µæŒç»­æ—¶é—´**ï¼ˆconcept durationï¼‰çš„æ¦‚ç‡åˆ†å¸ƒçš„**å¹³å‡æ®‹ä½™å¯¿å‘½**ï¼ˆMean Residual Life, MRLï¼‰æ€§è´¨ï¼š
  - è‹¥æ¦‚å¿µæŒç»­æ—¶é—´æœä» **DMRL**ï¼ˆDecreasing Mean Residual Lifeï¼‰åˆ†å¸ƒï¼Œåˆ™**å‰è½½å¼ç­–ç•¥**ï¼ˆFront-loadingï¼‰æ˜¯æœ€ä¼˜çš„ â€”â€” å³å°½æ—©é›†ä¸­æŠ•å…¥èµ„æºè¿›è¡Œè®­ç»ƒã€‚
  - è‹¥æœä» **IMRL**ï¼ˆIncreasing Mean Residual Lifeï¼‰åˆ†å¸ƒï¼Œåˆ™åº”é‡‡ç”¨**åè½½å¼ç­–ç•¥**ï¼ˆBack-loadingï¼‰â€”â€” åˆå§‹é˜¶æ®µå»¶è¿Ÿè®­ç»ƒä»¥èŠ‚çœæˆæœ¬ã€‚

- **éƒ¨ç½²è°ƒåº¦çš„å‡†å‡¸æ€§åˆ†æä¸éšæœºåŒ–ç­–ç•¥è®¾è®¡**  
  åœ¨é€šä¿¡å¸¦å®½å—é™æ¡ä»¶ä¸‹ï¼Œç ”ç©¶éƒ¨ç½²é¢‘ç‡ä¼˜åŒ–é—®é¢˜ï¼š
  - è¯æ˜åœ¨ mild æ¡ä»¶ä¸‹ï¼Œå®¢æˆ·ä¾§æ€§èƒ½ç›®æ ‡å‡½æ•°æ˜¯**å‡†å‡¸**ï¼ˆquasi-convexï¼‰çš„ï¼›
  - æå‡ºä¸€ç§**éšæœºåŒ–éƒ¨ç½²ç­–ç•¥**ï¼ˆrandomized scheduling policyï¼‰ï¼Œé€šè¿‡ç»„åˆä¸åŒéƒ¨ç½²æ¬¡æ•°çš„ç¡®å®šæ€§æœ€ä¼˜ç­–ç•¥ï¼Œé€¼è¿‘å…¨å±€æœ€ä¼˜ä¸”æ»¡è¶³é€Ÿç‡çº¦æŸã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡ä¼˜åŠ¿ |
|------|--------|---------|
| **è®­ç»ƒç­–ç•¥è®¾è®¡** | å›ºå®šå‘¨æœŸæˆ–å¯å‘å¼è°ƒåº¦ï¼ˆå¦‚å®šæœŸé‡è®­ï¼‰ | åŸºäºç»Ÿè®¡ç‰¹æ€§çš„ç†è®ºæœ€ä¼˜ç­–ç•¥ï¼Œæ˜¾è‘—æå‡æ•ˆç‡ |
| **æ¼‚ç§»å»ºæ¨¡** | å¤šå…³æ³¨æ¸è¿›æ¼‚ç§»æˆ–ç‰¹å®šæ£€æµ‹ç®—æ³• | ç»Ÿä¸€å¤„ç†çªå‘æ€§æ¼‚ç§»ï¼Œå¹¶å°†æ¼‚ç§»åŠ¨æ€çº³å…¥èµ„æºå†³ç­– |
| **é€šç”¨æ€§** | å¤šé’ˆå¯¹ç‰¹å®šæ¨¡å‹æˆ–ä»»åŠ¡ | æ¨¡å‹æ— å…³æ¡†æ¶ï¼Œé€‚ç”¨äºå„ç±» ML æ¨¡å‹ |
| **ç†è®ºä¿éšœ** | ç¼ºä¹ä¸¥æ ¼æœ€ä¼˜æ€§è¯æ˜ | æä¾›**å¿…è¦ä¸”å……åˆ†æ¡ä»¶**ä¸‹çš„å…¨å±€æœ€ä¼˜æ€§ä¿è¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
æœ¬æ–‡ä¸º**ç†è®ºå»ºæ¨¡ä¸ä»¿çœŸéªŒè¯å‹è®ºæ–‡**ï¼Œæœªä½¿ç”¨çœŸå®æ•°æ®é›†ã€‚æ‰€æœ‰å®éªŒåŸºäº**åˆæˆæ¦‚å¿µæ¼‚ç§»è¿‡ç¨‹**æ¨¡æ‹Ÿï¼Œé€šè¿‡è®¾å®šä¸åŒçš„ï¼š
- æ¦‚å¿µæŒç»­æ—¶é—´åˆ†å¸ƒ $ Y $
- æœŸæœ›æŸå¤±å‡½æ•° $ g(t) $

æ¥ç”Ÿæˆæ¨¡æ‹Ÿè½¨è¿¹ã€‚

å…¸å‹è®¾ç½®å¦‚ä¸‹ï¼š
- **æ¦‚å¿µæŒç»­æ—¶é—´åˆ†å¸ƒ**ï¼š
  - DMRL ç±»å‹ï¼šExponentialã€Weibull($k>1$)ã€Uniform
  - IMRL ç±»å‹ï¼šWeibull($k<1$)ã€Gamma($\alpha<1$)
- **æœŸæœ›æŸå¤±å‡½æ•°**ï¼š
  - $ g(t) = e^{-\beta t} $ ï¼ˆæŒ‡æ•°è¡°å‡ï¼‰
  - $ g(t) = 1/\sqrt{t+1} $, $ g(t) = 1/(t+1) $, $ g(t) = t^{-0.3} $ ç­‰ï¼ˆå¹‚å¾‹ç±»ï¼‰

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### è¯„ä¼°æŒ‡æ ‡
- **æœåŠ¡å™¨ç«¯æ—¶é—´å¹³å‡é¢„æœŸæŸå¤±**ï¼ˆTime-average Expected Loss on Server Sideï¼‰ï¼š
  $$
  \limsup_{t\to\infty} \frac{1}{t} \int_0^t L(\tau) d\tau
  $$
- **å®¢æˆ·ç«¯æ—¶é—´å¹³å‡é¢„æœŸæŸå¤±**ï¼ˆClient-side counterpartï¼‰
- **æœ‰æ•ˆéƒ¨ç½²ç‡**ï¼ˆEffective Deployment Rateï¼‰ï¼šå•ä½æ—¶é—´å†…æˆåŠŸéƒ¨ç½²æ¬¡æ•°çš„æœŸæœ›å€¼

#### å¯¹æ¯”ç­–ç•¥
- **è®­ç»ƒèµ„æºåˆ†é…**ï¼š
  - æœ€ä¼˜ç­–ç•¥ï¼ˆç†è®ºæ¨å¯¼çš„ front-loading / back-loadingï¼‰
  - å›ºå®šèµ„æºåˆ†é…ï¼ˆFixed Allocationï¼‰ï¼šå‡åŒ€åˆ†é…é¢„ç®—
  - å»¶è¿Ÿå—çŠ¶åˆ†é…ï¼ˆDelayed Block Allocationï¼‰ï¼šå»¶è¿Ÿä¸€æ®µæ—¶é—´åå†å…¨é‡è®­ç»ƒ
- **éƒ¨ç½²ç­–ç•¥**ï¼š
  - å‘¨æœŸæ€§éƒ¨ç½²ï¼ˆPeriodic Policyï¼‰
  - æ•°å€¼æ±‚è§£çš„æœ€ä¼˜é™æ€éƒ¨ç½²ï¼ˆOptimal Static Schedulerï¼‰
  - æ‰€æéšæœºåŒ–éƒ¨ç½²ç­–ç•¥ï¼ˆRandomized Deployment Policyï¼‰

#### ä»¿çœŸå¹³å°
æ‰€æœ‰å®éªŒåœ¨ MacBook Air M3 ä¸Šè¿è¡Œï¼Œä½¿ç”¨è‡ªå®šä¹‰ Python ä»¿çœŸå™¨å®ç°ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### å›¾2aï¼šè®­ç»ƒèµ„æºåˆ†é…æ€§èƒ½å¯¹æ¯”ï¼ˆY ~ Exp(1)ï¼ŒDMRLï¼‰
- åœ¨ç›¸åŒé¢„ç®—ä¸‹ï¼Œ**æœ€ä¼˜å‰è½½ç­–ç•¥**ç›¸æ¯”å›ºå®šåˆ†é…æœ€å¤šé™ä½ **71.80%** çš„æ—¶é—´å¹³å‡æŸå¤±ã€‚
- éšç€é¢„ç®—å¢åŠ ï¼Œä¸¤ç§ç­–ç•¥å·®è·ç¼©å°ï¼ˆå› èµ„æºå……è¶³ï¼Œå·®å¼‚å‡å¼±ï¼‰ã€‚

#### å›¾2bï¼šå»¶è¿Ÿè®­ç»ƒçš„å½±å“ï¼ˆä¸åŒåˆ†å¸ƒï¼‰
- å¯¹äº **IMRL åˆ†å¸ƒ**ï¼ˆå¦‚ Weibull(k=0.4)ï¼‰ï¼šå­˜åœ¨ä¸€ä¸ª**æœ€ä¼˜å»¶è¿Ÿæ—¶é—´**ï¼Œå¯è¿›ä¸€æ­¥é™ä½æŸå¤±ï¼›
- å¯¹äº **DMRL åˆ†å¸ƒ**ï¼šä»»ä½•å»¶è¿Ÿéƒ½ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼ŒéªŒè¯äº†â€œè¶Šæ—©è¶Šå¥½â€çš„ç»“è®ºã€‚

#### å›¾4ï¼ˆé™„å½•ï¼‰ï¼šä¸åŒæŸå¤±å‡½æ•°ä¸‹çš„å¢ç›Š
| æŸå¤±å‡½æ•° $g(t)$ | æ€§èƒ½æå‡å¹…åº¦ï¼ˆvs å›ºå®šåˆ†é…ï¼‰ |
|------------------|----------------------------|
| $e^{-t}$         | ~71.80%                    |
| $1/(t+1)$        | ~33.86%                    |
| $1/\sqrt{t+1}$   | ~15.80%                    |
| $t^{-0.3}$       | ~22.63%                    |
| $t^{-0.7}$       | ~65.54%                    |

> **ç»“è®º**ï¼šå½“æŸå¤±åˆæœŸä¸‹é™å¿«æ—¶ï¼Œfront-loading æ•ˆæœæ›´æ˜¾è‘—ã€‚

#### å›¾3ï¼šéƒ¨ç½²ç­–ç•¥æ¯”è¾ƒï¼ˆå®¢æˆ·ç«¯æ€§èƒ½ï¼‰
| åˆ†å¸ƒç±»å‹       | æœ€ä¼˜ç­–ç•¥ vs å‘¨æœŸæ€§ç­–ç•¥æ€§èƒ½æå‡ |
|----------------|------------------------------|
| Exponential    | æœ€é«˜ **43.30%**              |
| Weibull(k=2)   | æœ€é«˜ **39.25%**              |
| Erlang-2       | æå‡è¾ƒå°ï¼ˆçº¦ <10%ï¼‰          |

- **éšæœºåŒ–éƒ¨ç½²ç­–ç•¥**åœ¨ Exponential å’Œ Weibull ä¸‹å‡ ä¹è¾¾åˆ°æœ€ä¼˜æ€§èƒ½ï¼›
- åœ¨ Erlang-2 ä¸‹ç•¥é€Šäºæœ€ä¼˜ç­–ç•¥ï¼Œè¯´æ˜å…¶è¿‘ä¼¼æ•ˆæœä¾èµ–äºåˆ†å¸ƒç‰¹æ€§ã€‚

---

### æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æ²¡æœ‰æ˜ç¡®å‘½åâ€œæ¶ˆèå®éªŒâ€ï¼Œä½†ä»¥ä¸‹åˆ†æèµ·åˆ°äº†ç±»ä¼¼ä½œç”¨ï¼š
- **æ”¹å˜æ¦‚å¿µæŒç»­æ—¶é—´åˆ†å¸ƒç±»å‹**ï¼ˆDMRL vs IMRLï¼‰â†’ æ˜¾è‘—å½±å“æœ€ä¼˜ç­–ç•¥å½¢æ€ï¼›
- **æ”¹å˜æŸå¤±å‡½æ•°å½¢çŠ¶** â†’ å½±å“ front-loading çš„æ”¶ç›Šå¤§å°ï¼›
- **æ˜¯å¦å…è®¸å»¶è¿Ÿè®­ç»ƒ** â†’ åœ¨ IMRL åœºæ™¯ä¸‹å¼•å…¥å»¶è¿Ÿå¯æå‡æ€§èƒ½ï¼Œåœ¨ DMRL ä¸‹åˆ™æœ‰å®³ï¼›
- **éƒ¨ç½²æ¬¡æ•°æ˜¯å¦å›ºå®š** â†’ æ”¯æŒäº†éšæœºåŒ–ç­–ç•¥çš„è®¾è®¡åŠ¨æœºã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. âœ… **æœ€ä¼˜è®­ç»ƒç­–ç•¥æ˜¯ bang-bang æ§åˆ¶**ï¼šè¦ä¹ˆå…¨å¼€ï¼ˆMï¼‰ï¼Œè¦ä¹ˆå…³é—­ï¼ˆ0ï¼‰ï¼Œä¸­é—´æ— éƒ¨åˆ†è¿è¡ŒçŠ¶æ€ã€‚
2. âœ… **ç­–ç•¥ç»“æ„ç”± MRL å†³å®š**ï¼š
   - DMRL â‡’ å‰è½½æœ€ä¼˜ï¼ˆFront-loadingï¼‰
   - IMRL â‡’ åè½½/å»¶è¿Ÿæœ€ä¼˜ï¼ˆBack-loading / Idlingï¼‰
3. âœ… **å¸¸è§å¯å‘å¼ç­–ç•¥ï¼ˆå¦‚å›ºå®šåˆ†é…ã€å‘¨æœŸéƒ¨ç½²ï¼‰æ˜¯æ¬¡ä¼˜çš„**ï¼Œå°¤å…¶åœ¨é¢„ç®—ç´§å¼ æ—¶å·®è·æ˜æ˜¾ã€‚
4. âœ… **å®¢æˆ·ç«¯æ€§èƒ½é«˜åº¦ä¾èµ–éƒ¨ç½²æ—¶æœº**ï¼Œè€Œä¸ä»…ä»…æ˜¯æ›´æ–°é¢‘ç‡ã€‚
5. âœ… æ‰€æå‡ºçš„**éšæœºåŒ–éƒ¨ç½²ç­–ç•¥**èƒ½åœ¨ä¸ç‰ºç‰²å¤ªå¤šæ€§èƒ½çš„å‰æä¸‹ï¼Œé«˜æ•ˆé€¼è¿‘éå‡¸ä¼˜åŒ–é—®é¢˜çš„æœ€ä¼˜è§£ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

| å±€é™æ€§ | è¯´æ˜ |
|-------|------|
| **ä¾èµ–åˆ†å¸ƒå‡è®¾** | éœ€è¦çŸ¥é“æˆ–ä¼°è®¡æ¦‚å¿µæŒç»­æ—¶é—´çš„åˆ†å¸ƒåŠå…¶ MRL ç‰¹æ€§ï¼›è‹¥æœªçŸ¥ï¼Œåˆ™éš¾ä»¥ç›´æ¥åº”ç”¨ |
| **ç†æƒ³åŒ–æ€§èƒ½åº¦é‡** | ä½¿ç”¨â€œæœŸæœ›æ¦‚å¿µæŸå¤±â€ä½œä¸ºä»£ç†æŒ‡æ ‡ï¼Œå¿½ç•¥äº†å®é™…è¯„ä¼°ä¸­çš„å™ªå£°ä¸åå·® |
| **é™æ€ç­–ç•¥é™åˆ¶** | æ‰€æœ‰ç­–ç•¥å‡ä¸ºé™æ€ï¼ˆstationaryï¼‰ï¼Œä¸èƒ½åœ¨çº¿é€‚åº”æ¼‚ç§»æ¨¡å¼çš„å˜åŒ– |
| **å¿½ç•¥è®­ç»ƒ-éƒ¨ç½²è€¦åˆåé¦ˆ** | å‡è®¾è®­ç»ƒå®Œæˆåç«‹å³å¯ç”¨äºéƒ¨ç½²ï¼Œæœªè€ƒè™‘ pipeline å»¶è¿Ÿæˆ–å¤±è´¥æƒ…å†µ |

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **åœ¨çº¿ä¼°è®¡ MRL ç‰¹æ€§**ï¼šå¼€å‘è½»é‡çº§ç»Ÿè®¡æ–¹æ³•ï¼Œåœ¨çº¿è¯†åˆ«å½“å‰æ¼‚ç§»è¿‡ç¨‹å±äº DMRL è¿˜æ˜¯ IMRLã€‚
2. **è‡ªé€‚åº”åŠ¨æ€ç­–ç•¥**ï¼šä»é™æ€ç­–ç•¥æ‰©å±•åˆ°å¯æ ¹æ®å†å²è¡¨ç°è°ƒæ•´çš„åŠ¨æ€ç­–ç•¥ï¼ˆadaptive policiesï¼‰ã€‚
3. **è”åˆä¼˜åŒ–è®­ç»ƒä¸éƒ¨ç½²**ï¼šç›®å‰åˆ†åˆ«ä¼˜åŒ–è®­ç»ƒå’Œéƒ¨ç½²ï¼Œæœªæ¥å¯æ„å»ºç»Ÿä¸€æ¡†æ¶è¿›è¡Œ joint optimizationã€‚
4. **å¼•å…¥ä¸ç¡®å®šæ€§å»ºæ¨¡**ï¼šå°† $G_i(\cdot)$ å’Œ $Y_i$ çš„ä¸ç¡®å®šæ€§æ˜¾å¼å»ºæ¨¡ï¼Œå‘å±•é²æ£’æˆ–è´å¶æ–¯ç‰ˆæœ¬çš„ç­–ç•¥ã€‚
5. **çœŸå®ç³»ç»Ÿé›†æˆ**ï¼šåœ¨å®é™… MLOps å¹³å°ï¼ˆå¦‚ Kubernetes + Kubeflowï¼‰ä¸­éƒ¨ç½²å¹¶æµ‹è¯•è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

---

## æ€»ç»“

æœ¬è®ºæ–‡å»ºç«‹äº†é¦–ä¸ªå°†**æ¦‚å¿µæ¼‚ç§»åŠ¨æ€**ã€**èµ„æºé¢„ç®—çº¦æŸ**ä¸**è®­ç»ƒ/éƒ¨ç½²ç­–ç•¥è®¾è®¡**ç´§å¯†ç»“åˆçš„**ç†è®ºæœ€ä¼˜æ§åˆ¶æ¡†æ¶**ã€‚å…¶æ ¸å¿ƒè´¡çŒ®åœ¨äºæ­ç¤ºäº†**ç»Ÿè®¡è€åŒ–ç‰¹æ€§**ï¼ˆDMRL/IMRLï¼‰å¦‚ä½•ä»æ ¹æœ¬ä¸Šå†³å®šæœ€ä¼˜èµ„æºåˆ†é…ç»“æ„ï¼Œå¹¶æå‡ºäº†å…·æœ‰ç†è®ºä¿è¯çš„é«˜æ•ˆç­–ç•¥ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨åˆç†å‡è®¾ä¸‹ï¼Œæ‰€ææ–¹æ³•ç›¸æ¯”å¸¸è§„åšæ³•å¯å¸¦æ¥æ•°åä¸ªç™¾åˆ†ç‚¹çš„æ€§èƒ½æå‡ï¼Œä¸ºæ„å»ºé«˜æ•ˆã€å¯æŒç»­çš„ ML ç³»ç»Ÿæä¾›äº†åšå®çš„ç†è®ºåŸºç¡€å’Œå®ç”¨æŒ‡å¯¼ã€‚

</details>

---

### 7. [Deep Q-Learning-Based Intelligent Scheduling for ETL Optimization in Heterogeneous Data Environments](https://arxiv.org/abs/2512.13060)

**Authors**: Kangning Gao, Yi Hu, Cong Nie, Wei Li  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.13060v1  

#### Abstract
This paper addresses the challenges of low scheduling efficiency, unbalanced resource allocation, and poor adaptability in ETL (Extract-Transform-Load) processes under heterogeneous data environments by proposing an intelligent scheduling optimization framework based on deep Q-learning. The framewor...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Deep Q-Learning-Based Intelligent Scheduling for ETL Optimization in Heterogeneous Data Environments*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹åœ¨**å¼‚æ„æ•°æ®ç¯å¢ƒ**ï¼ˆheterogeneous data environmentsï¼‰ä¸‹ï¼Œä¼ ç»Ÿ ETLï¼ˆExtract-Transform-Loadï¼‰æµç¨‹ä¸­å­˜åœ¨çš„ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **è°ƒåº¦æ•ˆç‡ä½**ï¼ˆlow scheduling efficiencyï¼‰
- **èµ„æºåˆ†é…ä¸å‡è¡¡**ï¼ˆunbalanced resource allocationï¼‰
- **é€‚åº”æ€§å·®**ï¼ˆpoor adaptabilityï¼‰

è¿™äº›é—®é¢˜æºäºå¤šæºå¼‚æ„æ•°æ®ã€åŠ¨æ€ä»»åŠ¡ä¾èµ–ã€èµ„æºç«äº‰ä»¥åŠé™æ€è°ƒåº¦ç­–ç•¥æ— æ³•åº”å¯¹å¤æ‚ç³»ç»ŸçŠ¶æ€å˜åŒ–ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æå‡ºäº†ä¸€ç§åŸºäº **Deep Q-Learning (DQL)** çš„æ™ºèƒ½è°ƒåº¦ä¼˜åŒ–æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **å°† ETL è°ƒåº¦å»ºæ¨¡ä¸º MDPï¼ˆMarkov Decision Processï¼‰**
   - å°†ä»»åŠ¡è°ƒåº¦è§†ä¸ºä¸€ä¸ªåºåˆ—å†³ç­–é—®é¢˜ï¼Œç”±å¼ºåŒ–å­¦ä¹  agent åœ¨é«˜ç»´çŠ¶æ€ç©ºé—´ä¸­è¿›è¡Œè‡ªé€‚åº”å†³ç­–ã€‚

2. **è®¾è®¡äº†ç«¯åˆ°ç«¯çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¶æ„**
   - åŒ…å«å››ä¸ªæ¨¡å—ï¼š
     - **State Representation Module**ï¼šæ•´åˆä»»åŠ¡ä¾èµ–ã€èŠ‚ç‚¹è´Ÿè½½ã€æ•°æ®æµç‰¹å¾
     - **Feature Embedding Network**ï¼šé€šè¿‡éçº¿æ€§æ˜ å°„ï¼ˆå¦‚ReLU/Sigmoidï¼‰å®ç°é«˜ç»´çŠ¶æ€åµŒå…¥
     - **Q-value Estimator**ï¼šä½¿ç”¨ DQN æ¶æ„ä¼°è®¡åŠ¨ä½œä»·å€¼
     - **Reward Evaluation Mechanism**ï¼šé‡‡ç”¨å¤šç›®æ ‡å¥–åŠ±å‡½æ•°å¹³è¡¡å»¶è¿Ÿã€ååé‡ç­‰æŒ‡æ ‡

3. **å¼•å…¥å¤šç›®æ ‡å½’ä¸€åŒ–å¥–åŠ±å‡½æ•°**
   - ç»¼åˆè€ƒè™‘å¹³å‡è°ƒåº¦å»¶è¿Ÿï¼ˆASDï¼‰ã€ä»»åŠ¡å®Œæˆç‡ï¼ˆTCRï¼‰ã€ååé‡ï¼ˆTPï¼‰å’Œèµ„æºæ¶ˆè€—ï¼ˆRCï¼‰ï¼Œæå‡ç­–ç•¥çš„ç»¼åˆæ€§èƒ½ã€‚

4. **åˆ©ç”¨ Target Network æå‡è®­ç»ƒç¨³å®šæ€§**
   - é‡‡ç”¨ DQN ä¸­çš„åŒç½‘ç»œæœºåˆ¶ï¼ˆcurrent network ä¸ target network åˆ†ç¦»æ›´æ–°ï¼‰ï¼ŒæŠ‘åˆ¶ Q-value éœ‡è¡ï¼Œæé«˜æ”¶æ•›æ€§ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **è¡¨è¾¾èƒ½åŠ›** | ç›¸æ¯”ä¼ ç»Ÿ Q-Learning çš„è¡¨æ ¼æ³•ï¼ŒDQL å¯å¤„ç†é«˜ç»´è¿ç»­çŠ¶æ€ç©ºé—´ |
| **é€‚åº”æ€§** | åŠ¨æ€æ„ŸçŸ¥ç¯å¢ƒå˜åŒ–ï¼ˆå¦‚è´Ÿè½½æ³¢åŠ¨ã€ä»»åŠ¡åˆ°è¾¾ï¼‰ï¼Œå®æ—¶è°ƒæ•´è°ƒåº¦ç­–ç•¥ |
| **å…¨å±€ä¼˜åŒ–èƒ½åŠ›** | å¤šç›®æ ‡å¥–åŠ±æœºåˆ¶æ”¯æŒå»¶è¿Ÿã€ååã€èµ„æºåˆ©ç”¨ç‡çš„ååŒä¼˜åŒ– |
| **å¯æ‰©å±•æ€§** | æ¡†æ¶é€‚ç”¨äºä»å°è§„æ¨¡æœ¬åœ°è°ƒåº¦åˆ°å¤§è§„æ¨¡åˆ†å¸ƒå¼é›†ç¾¤åœºæ™¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
- ä½¿ç”¨ **TPC-H Benchmark Dataset** ä½œä¸ºæ ‡å‡†æµ‹è¯•æ•°æ®æºã€‚
- ç‰¹ç‚¹ï¼š
  - æ¨¡æ‹Ÿä¼ä¸šçº§æ•°æ®ä»“åº“ä¸­çš„å…¸å‹ä¸šåŠ¡åœºæ™¯ï¼ˆè®¢å•ã€å®¢æˆ·ã€ä¾›åº”é“¾ç­‰ï¼‰
  - åŒ…å«å¤šä¸ªå…³ç³»è¡¨ï¼ˆå¦‚ ORDERS, CUSTOMER, LINEITEMï¼‰ï¼Œå…·æœ‰å¤æ‚çš„å¤–é”®ä¾èµ–ç»“æ„
  - æ”¯æŒå‚æ•°åŒ–é…ç½®ï¼Œçµæ´»è°ƒèŠ‚æ•°æ®è§„æ¨¡ä¸å¤æ‚åº¦
  - æ¨¡æ‹Ÿå¤šæºå¼‚æ„è¾“å…¥ï¼šç»“æ„åŒ–è¡¨ + åŠç»“æ„åŒ–æµå¼è®°å½•

> ç”¨äºç”Ÿæˆå¤šé˜¶æ®µ ETL è°ƒåº¦å›¾ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨æ¸…æ´—ã€èšåˆæˆ–è½¬æ¢æ“ä½œï¼Œå¹¶å½¢æˆæ˜ç¡®çš„ä»»åŠ¡ä¾èµ–è·¯å¾„ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### å®éªŒå¹³å°
- æ¨¡æ‹Ÿå¼‚æ„è®¡ç®—é›†ç¾¤ï¼ŒåŒ…å«ä¸åŒè®¡ç®—èƒ½åŠ›ã€å­˜å‚¨å¸¦å®½å’Œç½‘ç»œå»¶è¿Ÿçš„èŠ‚ç‚¹
- åŠ¨æ€ä»»åŠ¡æµæ¨¡æ‹ŸçœŸå® ETL å·¥ä½œè´Ÿè½½æ³¢åŠ¨

#### è¯„ä¼°æŒ‡æ ‡ï¼ˆâ†‘ è¡¨ç¤ºè¶Šé«˜è¶Šå¥½ï¼Œâ†“ è¡¨ç¤ºè¶Šä½è¶Šå¥½ï¼‰
| æŒ‡æ ‡ | å«ä¹‰ | æœŸæœ›æ–¹å‘ |
|------|------|----------|
| **ASD â†“** | Average Scheduling Delayï¼ˆå¹³å‡è°ƒåº¦å»¶è¿Ÿï¼‰ | è¶Šå°è¶Šå¥½ |
| **TCR â†‘** | Task Completion Rateï¼ˆä»»åŠ¡å®Œæˆç‡ï¼‰ | è¶Šé«˜è¶Šå¥½ |
| **TP â†‘** | Throughputï¼ˆç³»ç»Ÿååé‡ï¼‰ | è¶Šé«˜è¶Šå¥½ |
| **RC â†“** | Reward Consistencyï¼ˆå¥–åŠ±ä¸€è‡´æ€§ï¼Œè¡¡é‡ç¨³å®šæ€§ï¼‰ | è¶Šå°è¶Šå¥½ |

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å¯¹æ¯”äº†å¤šç§ä¸»æµå¼ºåŒ–å­¦ä¹ è°ƒåº¦ç®—æ³•ï¼š
- **Q-Learning [15]**ï¼šç»å…¸è¡¨æ ¼å‹ RLï¼Œéš¾ä»¥æ‰©å±•
- **DDQN [16]**ï¼šæ”¹è¿›ç‰ˆ DQNï¼Œç¼“è§£è¿‡ä¼°è®¡é—®é¢˜
- **A3C [17]**ï¼šå¼‚æ­¥ Actor-Critic æ¶æ„
- **DDPG [18]**ï¼šé€‚ç”¨äºè¿ç»­åŠ¨ä½œç©ºé—´
- **SAC [19]**ï¼šåŸºäºç†µæ­£åˆ™åŒ–çš„ç¨³å®šæ¢ç´¢
- **PPO [20]**ï¼šç­–ç•¥æ¢¯åº¦æ–¹æ³•ï¼Œclip æœºåˆ¶é˜²å´©æºƒ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ–¹æ³• | ASD â†“ | TCR â†‘ (%) | TP â†‘ | RC â†“ |
|------|--------|------------|-------|--------|
| Q-Learning | 3.84 | 87.62 | 264.1 | 0.132 |
| DDQN | 3.22 | 90.18 | 278.4 | 0.115 |
| A3C | 3.06 | 91.25 | 283.7 | 0.109 |
| DDPG | 2.94 | 92.04 | 289.6 | 0.101 |
| SAC | 2.81 | 93.16 | 295.8 | 0.094 |
| PPO | 2.77 | 93.54 | 297.3 | 0.091 |
| **Ours (DQL-based)** | **2.43** | **95.82** | **312.7** | **0.079** |

> âœ… æ‰€ææ–¹æ³•åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚

---

### ğŸ”¬ æ•æ„Ÿæ€§åˆ†æï¼ˆSensitivity Analysisï¼‰

#### ï¼ˆ1ï¼‰å­¦ä¹ ç‡å¯¹ Average Cumulative Reward çš„å½±å“ï¼ˆFigure 2ï¼‰
- å­¦ä¹ ç‡è¿‡ä½ï¼ˆ1e-5 ~ 5e-5ï¼‰ï¼šæ›´æ–°ç¼“æ…¢ï¼Œreward å¢é•¿æ…¢
- ä¸­ç­‰å­¦ä¹ ç‡ï¼ˆ1e-4 ~ 5e-4ï¼‰ï¼šæœ€ä¼˜åŒºé—´ï¼Œå¿«é€Ÿæ”¶æ•›ä¸”ç¨³å®š
- å­¦ä¹ ç‡è¿‡é«˜ï¼ˆâ‰¥1e-3ï¼‰ï¼šæ¢¯åº¦éœ‡è¡ï¼Œæ€§èƒ½ä¸‹é™

> ç»“è®ºï¼š**é€‚åº¦å­¦ä¹ ç‡æ˜¯ä¿è¯è®­ç»ƒç¨³å®šæ€§å’Œé«˜æ•ˆæ€§çš„å…³é”®**

#### ï¼ˆ2ï¼‰æŠ˜æ‰£å› å­ Î³ å¯¹ ASD çš„å½±å“ï¼ˆFigure 3ï¼‰
- Î³ â‰¤ 0.85ï¼šè¿‡äºå…³æ³¨çŸ­æœŸæ”¶ç›Š â†’ å±€éƒ¨æœ€ä¼˜ï¼Œå»¶è¿Ÿé«˜
- Î³ â‰ˆ 0.9â€“0.95ï¼šé•¿æœŸè§„åˆ’ä¸å³æ—¶å“åº”å¹³è¡¡ â†’ ASD æœ€ä½
- Î³ â‰¥ 0.97ï¼šè¿‡åº¦ä¾èµ–é•¿æœŸé¢„æµ‹ â†’ å¯¹å®æ—¶çŠ¶æ€ä¸æ•æ„Ÿï¼Œå»¶è¿Ÿå›å‡

> ç»“è®ºï¼š**Î³ = 0.9~0.95 æ˜¯æœ€ä½³é€‰æ‹©**

#### ï¼ˆ3ï¼‰å¼‚æ„èŠ‚ç‚¹æ•°é‡å¯¹ ASD çš„å½±å“ï¼ˆFigure 4ï¼‰
- èŠ‚ç‚¹æ•°å°‘ï¼ˆ2â€“6ï¼‰ï¼šèµ„æºä¸è¶³ï¼Œæ’é˜Ÿä¸¥é‡ â†’ é«˜å»¶è¿Ÿ
- èŠ‚ç‚¹æ•°é€‚ä¸­ï¼ˆçº¦8ä¸ªï¼‰ï¼šå¹¶è¡Œæ€§ä¸åè°ƒæˆæœ¬è¾¾åˆ°å¹³è¡¡ â†’ **ASD æœ€å°**
- èŠ‚ç‚¹è¿‡å¤šï¼ˆ>10ï¼‰ï¼šé€šä¿¡å¼€é”€ã€åŒæ­¥ä»£ä»·ä¸Šå‡ â†’ å»¶è¿Ÿå†æ¬¡å¢åŠ 

> å‘ç°ï¼š**èŠ‚ç‚¹æ•°é‡ä¸æ€§èƒ½å‘ˆ U-shaped æ›²çº¿å…³ç³»**ï¼Œå¹¶éè¶Šå¤šè¶Šå¥½

---

### âŒ æ¶ˆèå®éªŒï¼ˆæœªç›´æ¥æä¾›ï¼Œä½†ä»ä¸Šä¸‹æ–‡æ¨æ–­ï¼‰
è™½ç„¶æ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèå®éªŒè¡¨æ ¼ï¼Œä½†å¯é€šè¿‡ä»¥ä¸‹è®¾è®¡åæ¨å…¶æœ‰æ•ˆæ€§ï¼š
- è‹¥ç§»é™¤ **feature embedding network** â†’ çŠ¶æ€è¡¨ç¤ºèƒ½åŠ›ä¸‹é™ â†’ å†³ç­–è´¨é‡é™ä½
- è‹¥ä½¿ç”¨å•ä¸€ç›®æ ‡å¥–åŠ± â†’ æ— æ³•å…¼é¡¾å»¶è¿Ÿä¸èµ„æºåˆ©ç”¨
- è‹¥ä¸ç”¨ target network â†’ Q-value æŒ¯è¡åŠ å‰§ï¼Œæ”¶æ•›å˜æ…¢

> æ¨è®ºï¼šæ‰€æå‡ºçš„ç»„ä»¶å…±åŒä½œç”¨ï¼Œç¼ºä¸€ä¸å¯ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Deep Q-Learning æ˜¾è‘—æå‡äº† ETL è°ƒåº¦æ€§èƒ½**
   - å¹³å‡è°ƒåº¦å»¶è¿Ÿé™ä½è‡³ **2.43**ï¼ˆæ¯” Q-Learning é™ä½è¶… 36%ï¼‰
   - ä»»åŠ¡å®Œæˆç‡è¾¾åˆ° **95.82%**ï¼Œååé‡è¾¾ **312.7**
   - åœ¨å¤šæºå¼‚æ„ä»»åŠ¡æ¡ä»¶ä¸‹è¡¨ç°å‡ºæ›´å¼ºçš„æ‰§è¡Œç¨³å®šæ€§

2. **å¤šç›®æ ‡å¥–åŠ±æœºåˆ¶æœ‰æ•ˆå¹³è¡¡äº†æ€§èƒ½æŒ‡æ ‡**
   - æˆåŠŸå®ç°äº†å»¶è¿Ÿã€ååã€èµ„æºåˆ©ç”¨ç‡ä¹‹é—´çš„æƒè¡¡ä¼˜åŒ–

3. **æ¡†æ¶å…·å¤‡è‰¯å¥½çš„é²æ£’æ€§ä¸æ³›åŒ–èƒ½åŠ›**
   - åœ¨ä¸åŒå­¦ä¹ ç‡ã€æŠ˜æ‰£å› å­ã€èŠ‚ç‚¹è§„æ¨¡ä¸‹è¡¨ç°ç¨³å¥
   - å¯¹ç¯å¢ƒåŠ¨æ€å˜åŒ–ï¼ˆå¦‚è´Ÿè½½æ³¢åŠ¨ã€ä»»åŠ¡åˆ°è¾¾æ¨¡å¼ï¼‰æœ‰è¾ƒå¼ºé€‚åº”åŠ›

4. **å¼‚æ„èµ„æºè°ƒåº¦å­˜åœ¨â€œæœ€ä¼˜å¹¶è¡Œåº¦â€**
   - è¿‡å¤šèŠ‚ç‚¹åè€Œå› é€šä¿¡å¼€é”€å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼ŒéªŒè¯äº†â€œå¹¶éè¶Šå¤šè¶Šå¥½â€çš„è§„å¾‹

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **è®­ç»ƒåˆæœŸæ ·æœ¬æ•ˆç‡è¾ƒä½**
   - DQN éœ€è¦å¤§é‡ç¯å¢ƒäº¤äº’æ‰èƒ½æ”¶æ•›ï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¯èƒ½éœ€è¦é¢„è®­ç»ƒæˆ–è¿ç§»å­¦ä¹ è¾…åŠ©ã€‚

2. **åŠ¨ä½œç©ºé—´ä»å—é™äºç¦»æ•£é€‰æ‹©**
   - å½“å‰è°ƒåº¦åŠ¨ä½œï¼ˆå¦‚ä»»åŠ¡åˆ†é…ã€å»¶è¿Ÿå†³ç­–ï¼‰ä¸ºç¦»æ•£å‹ï¼›è‹¥éœ€ç²¾ç»†æ§åˆ¶èµ„æºé…é¢ï¼Œå¯ç»“åˆ DDPG æˆ– SAC ç­‰è¿ç»­æ§åˆ¶æ–¹æ³•ã€‚

3. **æœªè€ƒè™‘èƒ½è€—ä¸ç»æµæˆæœ¬**
   - å½“å‰ reward å‡½æ•°æœªæ˜¾å¼åŒ…å« energy consumption æˆ– monetary costï¼Œé™åˆ¶äº†åœ¨ç»¿è‰²è®¡ç®—æˆ–äº‘è®¡è´¹åœºæ™¯çš„åº”ç”¨ã€‚

4. **ä¾èµ–å‡†ç¡®çš„çŠ¶æ€è§‚æµ‹**
   - è‹¥ç³»ç»Ÿç›‘æ§å­˜åœ¨å»¶è¿Ÿæˆ–å™ªå£°ï¼Œå¯èƒ½å½±å“ agent çš„åˆ¤æ–­å‡†ç¡®æ€§ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **èåˆ Graph Neural Networks (GNN)**
   - æ›´å¥½åœ°å»ºæ¨¡ä»»åŠ¡ä¾èµ–å›¾ç»“æ„ï¼Œå¢å¼ºå¯¹å¤æ‚ DAG çš„ç†è§£èƒ½åŠ›ã€‚

2. **å¼•å…¥ Meta-Reinforcement Learning**
   - å®ç°è·¨ç¯å¢ƒå¿«é€Ÿé€‚åº”ï¼Œæå‡åœ¨æ–°é›†ç¾¤æˆ–æ–° workload ä¸‹çš„ zero-shot æ³›åŒ–èƒ½åŠ›ã€‚

3. **ç»“åˆ Self-Supervised Representation Learning**
   - åˆ©ç”¨æ— ç›‘ç£æ–¹å¼æå–æ•°æ®æµè¯­ä¹‰ç‰¹å¾ï¼Œå‡å°‘å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ã€‚

4. **æ‹“å±•è‡³ Multi-Agent ååŒè°ƒåº¦**
   - å¤šä¸ª agents åˆ†å¸ƒå¼åä½œï¼Œåº”å¯¹è·¨åŒºåŸŸã€å¤§è§„æ¨¡é›†ç¾¤çš„å…¨å±€è°ƒåº¦éœ€æ±‚ã€‚

5. **é›†æˆ Energy-Aware Optimization**
   - å°†èƒ½æ•ˆçº³å…¥ reward å‡½æ•°ï¼Œæ¨åŠ¨å¯æŒç»­çš„æ•°æ®å·¥ç¨‹å‘å±•ã€‚

---

## æ€»ç»“

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº **Deep Q-Learning** çš„æ™ºèƒ½ ETL è°ƒåº¦æ¡†æ¶ï¼ŒæˆåŠŸè§£å†³äº†å¼‚æ„ç¯å¢ƒä¸‹è°ƒåº¦æ•ˆç‡ä½ã€èµ„æºåˆ†é…ä¸å‡ã€é€‚åº”æ€§å·®ç­‰é—®é¢˜ã€‚é€šè¿‡å°† ETL æµç¨‹å»ºæ¨¡ä¸º MDPï¼Œç»“åˆçŠ¶æ€ç¼–ç ã€Q-value ä¼°è®¡ä¸å¤šç›®æ ‡å¥–åŠ±æœºåˆ¶ï¼Œå®ç°äº†åŠ¨æ€ã€è‡ªé€‚åº”ã€é«˜æ€§èƒ½çš„è°ƒåº¦å†³ç­–ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ TPC-H æ•°æ®é›†ä¸Šå…¨é¢è¶…è¶Šå¤šç§ä¸»æµ RL åŸºçº¿ï¼Œåœ¨ ASDã€TCRã€TP ç­‰å…³é”®æŒ‡æ ‡ä¸Šå–å¾—æ˜¾è‘—æå‡ï¼Œå¹¶å±•ç°å‡ºè‰¯å¥½çš„é²æ£’æ€§ä¸å¯æ‰©å±•æ€§ã€‚è¯¥ç ”ç©¶ä¸ºæ„å»º**è‡ªä¸»åŒ–ã€æ™ºèƒ½åŒ–çš„æ•°æ®æµæ°´çº¿**æä¾›äº†é‡è¦çš„æ–¹æ³•è®ºåŸºç¡€å’ŒæŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 8. [CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving](https://arxiv.org/abs/2512.11920)

**Authors**: Dong Liu, Yanxuan Yu  
**Category**: cs.AI  
**Published**: 2025-12-16  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.11920v1  

#### Abstract
Large Language Models (LLMs) have revolutionized natural language processing tasks, but their deployment in datacenter environments faces significant challenges due to the massive memory requirements of key-value (KV) caches. During the autoregressive decoding process, KV caches consume substantial ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ¨ç†è¿‡ç¨‹ä¸­éœ€è¦ç»´æŠ¤å·¨å¤§çš„ **Key-Value (KV) Cache** æ¥å­˜å‚¨è‡ªå›å½’è§£ç æ—¶çš„å†å²æ³¨æ„åŠ›çŠ¶æ€ã€‚éšç€ä¸Šä¸‹æ–‡é•¿åº¦å¢é•¿ï¼ŒKV Cache å ç”¨çš„æ˜¾å­˜è¿…é€Ÿè¶…è¿‡å•ä¸ª GPU çš„å®¹é‡ï¼ˆä¾‹å¦‚ LLaMA-2 70B åœ¨ 2048 é•¿åº¦ä¸‹éœ€ 640GBï¼‰ï¼Œä¸¥é‡é™åˆ¶äº†æ‰¹å¤„ç†å¤§å°ï¼ˆbatch sizeï¼‰å’Œç³»ç»Ÿååé‡ã€‚

ä¼ ç»Ÿæ–¹æ³•å¦‚å†…å­˜å¸è½½ï¼ˆoffloadingï¼‰ã€KV Cache å‹ç¼©ã€æ¨æµ‹è§£ç ç­‰å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- å†…å­˜å¸è½½ï¼ˆå¦‚ FlexGenï¼‰ä¾èµ– PCIeï¼Œå¸¦å®½ä½ã€å»¶è¿Ÿé«˜ï¼›
- å‹ç¼©æŠ€æœ¯ï¼ˆå¦‚ INT8/INT4ï¼‰å¸¦æ¥ç²¾åº¦æŸå¤±ï¼›
- æ¨æµ‹è§£ç ï¼ˆspeculative decodingï¼‰å¢åŠ é¢å¤–è®¡ç®—å¼€é”€ä¸”ä¸è§£å†³å†…å­˜ç“¶é¢ˆã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **CXL-SpecKV** â€”â€” ä¸€ç§åŸºäº **CXLï¼ˆCompute Express Linkï¼‰** å’Œ **FPGA åŠ é€Ÿå™¨** çš„**è§£è€¦å¼ï¼ˆdisaggregatedï¼‰KV Cache æ¶æ„**ï¼Œç»“åˆ**æŠ•æœºæ€§é¢„å–ï¼ˆspeculative prefetchingï¼‰** æŠ€æœ¯ï¼Œå®ç°é«˜æ•ˆã€ä½æˆæœ¬çš„å¤§è§„æ¨¡ LLM æ¨ç†æœåŠ¡ã€‚

å…¶ä¸‰å¤§æ ¸å¿ƒåˆ›æ–°ç‚¹å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰CXL-based å†…å­˜è§£è€¦æ¡†æ¶
- åˆ©ç”¨ CXL 2.0 åè®®å°† KV Cache ä» GPU æ˜¾å­˜å¸è½½è‡³è¿œç¨‹ FPGA è¿æ¥çš„é«˜å¸¦å®½ã€ä½å»¶è¿Ÿå†…å­˜æ± ï¼ˆCXL Memory Poolï¼‰ã€‚
- æ”¯æŒ 4â€“8Ã— çš„æœ‰æ•ˆå†…å­˜æ‰©å±•ï¼Œçªç ´ GPU æ˜¾å­˜å®¹é‡é™åˆ¶ã€‚

#### ï¼ˆ2ï¼‰æŠ•æœºæ€§ KV Cache é¢„å–æœºåˆ¶
- è®¾è®¡è½»é‡çº§ LSTM æ¨¡å‹é¢„æµ‹æœªæ¥ 4â€“8 ä¸ª token çš„ç”Ÿæˆåºåˆ—ï¼Œå¹¶æå‰å°†å¯¹åº”çš„ KV Cache æ¡ç›®é€šè¿‡ CXL é¢„åŠ è½½åˆ° GPU ç¼“å†²åŒºã€‚
- é¢„æµ‹å‡†ç¡®ç‡è¾¾ **95%**ï¼Œæ˜¾è‘—éšè— CXL è®¿é—®å»¶è¿Ÿã€‚

#### ï¼ˆ3ï¼‰FPGA åŠ é€Ÿçš„å‹ç¼©/è§£å‹å¼•æ“
- åœ¨ FPGA ä¸Šå®ç°é«˜æ•ˆçš„ KV Cache å‹ç¼©æµæ°´çº¿ï¼ˆINT8 + Delta Encoding + RLEï¼‰ï¼Œå¹³å‡å‹ç¼©æ¯”è¾¾ **3.2Ã—**ï¼Œæœ€é«˜å¯è¾¾ **4Ã—**ã€‚
- å‹ç¼©/è§£å‹æ“ä½œç”± FPGA å®Œæˆï¼Œä¸å ç”¨ GPU è®¡ç®—èµ„æºï¼Œä¸”æ”¯æŒé«˜è¾¾ 1.6TB/s çš„ååã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **å†…å­˜å®¹é‡** | ç›¸æ¯” GPU-only æ‰©å±• 4â€“8Ã—ï¼Œç»“åˆå‹ç¼©å¯è¾¾ 24Ã— |
| **æ€§èƒ½** | ååæå‡æœ€é«˜è¾¾ **3.2Ã—**ï¼Œè¿œè¶… CPU offload æˆ–çº¯å‹ç¼©æ–¹æ¡ˆ |
| **æˆæœ¬** | å‡å°‘å¯¹æ˜‚è´µå¤§æ˜¾å­˜ GPU çš„ä¾èµ–ï¼ŒåŸºç¡€è®¾æ–½æˆæœ¬é™ä½ **2.8Ã—** |
| **ç²¾åº¦** | ä¿æŒ **99.5%** çš„åŸå§‹æ¨¡å‹ç²¾åº¦ï¼ˆä»¥ perplexity è¡¡é‡ï¼‰ |
| **é›†æˆæ€§** | æ”¯æŒä¸ä¸»æµ LLM æ¡†æ¶ï¼ˆvLLMã€TensorRT-LLMï¼‰æ— ç¼é›†æˆ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ¨¡å‹ä¸å·¥ä½œè´Ÿè½½**

- **æ¨¡å‹èŒƒå›´**ï¼šæ¶µç›–å¤šç§ä¸»æµ LLM æ¶æ„ï¼Œå‚æ•°ä» 1.8B åˆ° 72Bï¼ŒåŒ…æ‹¬ï¼š
  - LLaMA-2 / LLaMA-3ï¼ˆ7Bâ€“70Bï¼‰
  - Qwenï¼ˆ1.8Bâ€“72Bï¼‰
  - Mistral / Mixtralï¼ˆMoE ç»“æ„ï¼‰
  - Gemmaï¼ˆ2Bâ€“7Bï¼‰
  - CodeLLaMA / CodeQwen
- **è¾“å…¥è¾“å‡ºé•¿åº¦**ï¼šè¦†ç›–ä¸åŒåœºæ™¯ä¸‹çš„å…¸å‹é…ç½®ï¼š
  - Chatbot: 128/256
  - Summarization: 1024â€“2048 / 128â€“256
  - Code Generation: 256â€“512 / 512â€“1024
  - QA: 64â€“128 / 32â€“64

### **å®éªŒå¹³å°ç¡¬ä»¶é…ç½®**

- **GPU**: 8Ã— NVIDIA A100 80GBï¼ˆHBM 1.6TB/sï¼‰
- **FPGA**: 4Ã— Intel Agilex-7ï¼ˆæ¯ç‰‡ 64GB HBMï¼ŒCXL 2.0 æ§åˆ¶å™¨ï¼Œ64GB/s å¸¦å®½ï¼‰
- **CPU**: åŒè·¯ Sapphire Rapidsï¼ˆ96æ ¸ï¼Œ1TB DDR5ï¼‰
- **äº’è¿**ï¼šPCIe Gen4 Ã—16 + CXL 2.0 Type-3 å†…å­˜æ‰©å±•å™¨

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Throughput (O)** | ç¨³æ€ä¸‹æ¯ç§’ç”Ÿæˆçš„ token æ•°ï¼ˆtokens/sï¼‰ |
| **Latency** | TTFTï¼ˆé¦– token æ—¶é—´ï¼‰ã€decode per-token latencyï¼ˆä¸­ä½æ•°/P95/P99ï¼‰ |
| **Memory Efficiency** | æ¯è¯·æ±‚å¯ç”¨å†…å­˜ã€æˆæœ¬æ•ˆç‡ï¼ˆ$ per GBï¼‰ |
| **Accuracy** | Perplexityï¼ˆWikiText-103ï¼‰ã€BLEU åˆ†æ•° vs FP16 åŸºçº¿ |
| **Energy Efficiency** | èƒ½æ•ˆï¼ˆJoules per tokenï¼‰ |
| **Prefetch Performance** | é¢„å–å‘½ä¸­ç‡ã€ç²¾åº¦ã€æœ‰æ•ˆå»¶è¿Ÿ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿ | æè¿° |
|------|------|
| **GPU-Only** | ä½¿ç”¨ vLLM + PagedAttentionï¼Œå—é™äº GPU æ˜¾å­˜ |
| **CPU Offload** | FlexGen æ–¹æ¡ˆï¼Œé€šè¿‡ PCIe å¸è½½è‡³ CPU å†…å­˜ |
| **NVMe Offload** | æˆæœ¬ä¼˜åŒ–ä½†å»¶è¿Ÿæé«˜ |
| **Compression-Only** | GPU ä¸Šä½¿ç”¨ INT8 å‹ç¼© KV Cache |
| **CXL-NoSpec** | æœ¬æ–‡æ¡†æ¶ä½†å…³é—­æŠ•æœºé¢„å–åŠŸèƒ½ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æŒ‡æ ‡ | CXL-SpecKV è¡¨ç° |
|------|----------------|
| **æœ€å¤§ååæå‡** | **3.2Ã—** vs GPU-onlyï¼ˆLLaMA-2 70Bï¼‰ |
| **å¹³å‡ååæå‡** | **2.4Ã—** across workloads |
| **å†…å­˜å®¹é‡æ‰©å±•** | **8Ã—**ï¼ˆæ— å‹ç¼©ï¼‰ï¼Œ**24Ã—**ï¼ˆå«å‹ç¼©ï¼‰ |
| **æœ€å¤§ batch size** | è¾¾ **384**ï¼ˆvs GPU-only çš„ 16ï¼‰ |
| **KV Cache é¢„å–å‘½ä¸­ç‡** | **94.7%** |
| **é¢„å–é¢„æµ‹å‡†ç¡®ç‡ï¼ˆtop-4ï¼‰** | **>95%**ï¼ˆk=4ï¼‰ |
| **å‹ç¼©æ¯”** | å¹³å‡ **3.2Ã—**ï¼Œæœ€é«˜ **4Ã—** |
| **per-token è§£ç å»¶è¿Ÿå¢åŠ ** | **+8.2%**ï¼ˆvs GPU-onlyï¼‰ |
| **P99 å»¶è¿Ÿå¢åŠ ** | **+12.3%** |
| **èƒ½é‡æ•ˆç‡æå‡** | **1.90Ã— æ›´ä¼˜ï¼ˆJ/tokenï¼‰** |
| **å¹¶è¡Œæ‰©å±•æ•ˆç‡ï¼ˆ8 GPUï¼‰** | **87%** |

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| å¯¹æ¯”é¡¹ | æå‡å¹…åº¦ |
|--------|----------|
| vs GPU-Only | åå **+2.1â€“3.2Ã—**ï¼Œæˆæœ¬æ€§èƒ½æ¯” **+2.3Ã—** |
| vs CPU Offload | åå **+3.8â€“5.2Ã—**ï¼ˆå›  CXL å¸¦å®½æ›´é«˜ã€å»¶è¿Ÿæ›´ä½ï¼‰ |
| vs Compression-Only | ååä»é«˜ **1.8â€“2.3Ã—**ï¼ˆå®¹é‡æ›´å¤§ï¼‰ |
| vs CXL-NoSpec | åå **+1.6â€“2.1Ã—**ï¼Œè¯æ˜æŠ•æœºé¢„å–è‡³å…³é‡è¦ |

> ç¤ºä¾‹ï¼šLLaMA-2 70B åœ¨ chatbot å·¥ä½œè´Ÿè½½ä¸‹ï¼š
> - GPU-Only: 487 tokens/sï¼ˆbatch=16ï¼‰
> - CXL-SpecKV: **1,549 tokens/s**ï¼ˆbatch=64ï¼‰

### **æ¶ˆèå®éªŒç»“æœ**

#### ï¼ˆ1ï¼‰é¢„å–æ¿€è¿›ç¨‹åº¦ï¼ˆprediction horizon $k$ï¼‰

| $k$ | å‘½ä¸­ç‡ (%) | ç²¾åº¦ (%) | åå (tok/s) | å»¶è¿Ÿ (ms) |
|-----|------------|-----------|---------------|------------|
| 1 | 87.2 | 96.1 | 1,287 | 21.4 |
| 2 | 92.3 | 93.5 | 1,426 | 20.2 |
| **4** | **94.7** | **87.2** | **1,549** | **19.8** |
| 8 | 95.8 | 78.3 | 1,573 | 19.6 |
| 16 | 96.4 | 68.7 | 1,581 | 19.7 |

âœ… æœ€ä½³å¹³è¡¡ç‚¹ä¸º $k=4$ï¼Œç»§ç»­å¢å¤§æ”¶ç›Šé€’å‡ä¸”æµªè´¹å¸¦å®½ã€‚

#### ï¼ˆ2ï¼‰å‹ç¼©ç»„ä»¶è´¡çŒ®

| å‹ç¼©ç­–ç•¥ | å‹ç¼©æ¯” | Perplexity å¢åŠ  |
|---------|--------|------------------|
| FP16ï¼ˆæ— å‹ç¼©ï¼‰ | 1.00Ã— | 0.0% |
| INT8 Only | 2.00Ã— | +0.6% |
| + Delta Encoding | 2.73Ã— | +0.9% |
| + RLE | **3.21Ã—** | **+1.2%** |

âœ… Delta ç¼–ç è´¡çŒ®æœ€å¤§ï¼ˆ+36% å‹ç¼©æ¯”ï¼‰ï¼ŒRLE è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **å†…å­˜è§£è€¦ + æŠ•æœºé¢„å–å¯æœ‰æ•ˆæ‰“ç ´ LLM æ¨ç†çš„â€œå†…å­˜å¢™â€**  
   CXL æä¾›ä½å»¶è¿Ÿå…±äº«å†…å­˜é€šé“ï¼Œè€ŒæŠ•æœºé¢„å–æˆåŠŸæ©ç›–äº†è¿œç¨‹è®¿é—®å»¶è¿Ÿï¼Œä½¿è§£è€¦æ¶æ„æ€§èƒ½æ¥è¿‘æœ¬åœ°å†…å­˜ã€‚

2. **FPGA æ˜¯å®ç°é«˜æ•ˆ KV Cache ç®¡ç†çš„ç†æƒ³å¹³å°**  
   FPGA å¯å®šåˆ¶åŒ–å®ç°å‹ç¼©ã€åœ°å€è½¬æ¢ã€DMA æ§åˆ¶ç­‰åŠŸèƒ½ï¼Œåœ¨ 800MHz ä¸‹è¾¾åˆ° 1.6TB/s ååï¼Œä»…æ¶ˆè€—çº¦ 30% ALM èµ„æºã€‚

3. **LLM ç”Ÿæˆè¿‡ç¨‹å…·æœ‰å¯é¢„æµ‹æ¨¡å¼ï¼Œé€‚åˆæŠ•æœºä¼˜åŒ–**  
   å°½ç®¡ token ç”Ÿæˆæ˜¯åŠ¨æ€çš„ï¼Œä½†å¯¹è¯ç±»ä»»åŠ¡è¡¨ç°å‡ºå¼ºæ—¶é—´å±€éƒ¨æ€§å’Œåºåˆ—è§„å¾‹æ€§ï¼Œä½¿å¾—è½»é‡çº§ LSTM æ¨¡å‹å³å¯å®ç° >95% çš„ top-4 é¢„æµ‹å‡†ç¡®ç‡ã€‚

4. **è½¯ç¡¬ååŒè®¾è®¡å¸¦æ¥æ˜¾è‘—æˆæœ¬æ•ˆç›Š**  
   ä½¿ç”¨ä½æˆæœ¬ FPGA æ‰©å±•å†…å­˜ + ä¸­ç«¯ GPUï¼Œç›¸æ¯”å…¨é«˜ç«¯ GPU é…ç½®ï¼Œå¯åœ¨æ€»æˆæœ¬ä»…å¢åŠ  37% çš„æƒ…å†µä¸‹è·å¾— 2.4Ã— ååï¼Œæ€§ä»·æ¯”æå‡ **1.75Ã—**ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ– CXL ç¡¬ä»¶ç”Ÿæ€æ™®åŠ**  
   å½“å‰ CXL ç”Ÿæ€å°šå¤„äºæ—©æœŸé˜¶æ®µï¼ŒType-3 è®¾å¤‡éƒ¨ç½²æœ‰é™ï¼Œå¯èƒ½å½±å“è½åœ°é€Ÿåº¦ã€‚

2. **é¢„å–é”™è¯¯å¯¼è‡´å¸¦å®½æµªè´¹**  
   è™½ç„¶å‘½ä¸­ç‡é«˜ï¼Œä½†ä»æœ‰ ~13% çš„é¢„å–æ•°æ®æœªè¢«ä½¿ç”¨ï¼Œé€ æˆä¸€å®šé“¾è·¯å¸¦å®½å†—ä½™ã€‚

3. **å¯¹æç«¯é•¿ä¸Šä¸‹æ–‡ï¼ˆ>32Kï¼‰æ”¯æŒå¾…éªŒè¯**  
   å½“å‰å®éªŒé›†ä¸­åœ¨ 2Kâ€“4K ä¸Šä¸‹æ–‡ï¼Œæ›´é•¿ä¸Šä¸‹æ–‡ä¸‹çš„ç¼“å­˜ç®¡ç†ç­–ç•¥éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

4. **å¤šç§Ÿæˆ·éš”ç¦»ä¸ QoS æœªæ·±å…¥æ¢è®¨**  
   å…±äº« CXL å†…å­˜æ± æ—¶çš„å®‰å…¨æ€§ã€èµ„æºäº‰ç”¨ç­‰é—®é¢˜å°šæœªè§£å†³ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- åŠ¨æ€æ¿€æ´»ç¨€ç–æ€§ï¼ˆdynamic activation sparsityï¼‰åœ¨ attention ä¸­çš„åº”ç”¨
- å¤šç§Ÿæˆ·ç¯å¢ƒä¸‹å¸¦ QoS ä¿è¯çš„å·¥ä½œè´Ÿè½½è°ƒåº¦
- æ”¯æŒ 32Kâ€“128K è¶…é•¿ä¸Šä¸‹æ–‡çš„åˆ†å±‚é¢„æµ‹æœºåˆ¶
- æ‰©å±•è‡³ fine-tuning / training åœºæ™¯ï¼ˆåŒå‘ patternï¼‰
- åˆ©ç”¨ CXL 3.0ï¼ˆ128GB/sï¼‰å’Œ memory-side caching æå‡æ€§èƒ½
- å¼‚æ„å†…å­˜å±‚çº§ï¼ˆHBM/DDR/NVMï¼‰æ··åˆä½¿ç”¨
- å®‰å…¨ä¸éš”ç¦»æœºåˆ¶è®¾è®¡ï¼ˆshared CXL memoryï¼‰
- ä¸å…¶ä»–äº’è”åè®®ï¼ˆNVLink-C2Cã€Infinity Fabricï¼‰çš„æ¨ªå‘æ¯”è¾ƒ

---

> âœ… **å¼€æºä¿¡æ¯**ï¼šä½œè€…å·²å°†ä»£ç å¼€æºï¼Œé¡¹ç›®åœ°å€ä¸º [https://github.com/FastLM/CXL-SpecKV](https://github.com/FastLM/CXL-SpecKV)ï¼Œä¾¿äºå¤ç°ä¸ç¤¾åŒºè´¡çŒ®ã€‚

</details>

---

### 9. [On Approaches to Building Surrogate ODE Models for Diffusion Bridges](https://arxiv.org/abs/2512.12671)

**Authors**: Maria Khilchuk, Vladimir Latypov, Pavel Kleshchev, Alexander Hvatov  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.12671v1  

#### Abstract
Diffusion and Schr\"{o}dinger Bridge models have established state-of-the-art performance in generative modeling but are often hampered by significant computational costs and complex training procedures. While continuous-time bridges promise faster sampling, overparameterized neural networks describ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šOn Approaches to Building Surrogate ODE Models for Diffusion Bridges

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelsï¼‰å’Œ SchrÃ¶dinger Bridgeï¼ˆSBï¼‰åœ¨ç”Ÿæˆå»ºæ¨¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å­˜åœ¨ä»¥ä¸‹ç“¶é¢ˆï¼š
- **è®¡ç®—æˆæœ¬é«˜**ï¼šé‡‡æ ·è¿‡ç¨‹ç¼“æ…¢ï¼Œéœ€å¤§é‡ç½‘ç»œè¯„ä¼°ï¼›
- **è®­ç»ƒå¤æ‚**ï¼šè¿ç»­æ—¶é—´æ¡¥æ¨¡å‹ä¾èµ–å¤æ‚çš„ä¼˜åŒ–ç®—æ³•ï¼ˆå¦‚ IPFï¼‰ï¼Œéš¾ä»¥æ‰©å±•åˆ°é«˜ç»´ï¼›
- **æ¨¡å‹ä¸å¯è§£é‡Šä¸”è¿‡å‚æ•°åŒ–**ï¼šä¸»æµæ–¹æ³•ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œè¡¨ç¤ºæ¼‚ç§»å‡½æ•°ï¼ˆdrift functionï¼‰ï¼Œå¯¼è‡´æ¨¡å‹åºå¤§ã€æ¨ç†æ…¢ã€ç¼ºä¹å¯è§£é‡Šæ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡ºä¸€ç§**åŸºäºä»£ç†å»ºæ¨¡ï¼ˆsurrogate modelingï¼‰çš„æ–°èŒƒå¼**ï¼Œæ—¨åœ¨æ„å»ºæ›´ç®€å•ã€å¿«é€Ÿã€çµæ´»çš„å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆODEï¼‰è¿‘ä¼¼æ¨¡å‹æ¥æ›¿ä»£åŸå§‹å¤æ‚çš„éšæœºå¾®åˆ†æ–¹ç¨‹ï¼ˆSDEï¼‰åŠ¨æ€ç³»ç»Ÿã€‚å…·ä½“æå‡ºäº†ä¸¤ç§ç®—æ³•ï¼š

#### ï¼ˆ1ï¼‰SINDy Flow Matching (SINDy-FM)
- åˆ©ç”¨ **Sparse Identification of Nonlinear Dynamics (SINDy)** æ–¹æ³•ä»æ•°æ®ä¸­è¯†åˆ«å‡º**ç¨€ç–ã€ç¬¦å·åŒ–çš„å¾®åˆ†æ–¹ç¨‹**ã€‚
- é€šè¿‡ Flow Matching æ„é€ ç›‘ç£ä¿¡å·ï¼ˆstate å’Œ exact time derivative å¯¹ï¼‰ï¼Œç›´æ¥å›å½’å¾—åˆ°å¯è§£é‡Šçš„åŠ¨åŠ›å­¦è¡¨è¾¾å¼ã€‚
- æ¨¡å‹å½¢å¼ä¸º $ v_\theta(x,t) = W \Phi(x,t) $ï¼Œå…¶ä¸­ $\Phi$ æ˜¯é¢„å®šä¹‰çš„ç¬¦å·ç‰¹å¾åº“ï¼ˆå¦‚å¤šé¡¹å¼ã€ä¸‰è§’å‡½æ•°ç­‰ï¼‰ã€‚

#### ï¼ˆ2ï¼‰DSBM-NeuralODE
- å°† SchrÃ¶dinger Bridge é‡æ–°è¡¨è¿°ä¸º **Neural ODE æ¡†æ¶ä¸‹çš„è¿ç»­æ—¶é—´å‚æ•°åŒ–é—®é¢˜**ã€‚
- ä½¿ç”¨ Neural ODE å‚æ•°åŒ–æ¼‚ç§»å‡½æ•°ï¼Œå¹¶é€šè¿‡åœ¨å‚è€ƒæ‰©æ•£è½¨è¿¹ä¸Šè¿›è¡Œé¢„è®­ç»ƒå®ç°â€œwarm startâ€ã€‚
- ç»“åˆ Iterative Markovian Fittingï¼ˆIMFï¼‰æ¡†æ¶è¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œæå‡ç¨³å®šæ€§ä¸æ•ˆç‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | SINDy-FM æ¨ç†æ—¶é—´è¾¾å¾®ç§’çº§ï¼Œæ¯”ä¼ ç»Ÿ DSBM å¿« 2â€“3 ä¸ªæ•°é‡çº§ï¼›å‚æ•°é‡å‡å°‘å‡ ä¸ªæ•°é‡çº§ï¼ˆå¦‚ä» $10^6$ é™è‡³ç™¾çº§ï¼‰ã€‚ |
| **å¯è§£é‡Šæ€§** | SINDy-FM è¾“å‡ºçš„æ˜¯æ˜¾å¼çš„ç¬¦å·æ–¹ç¨‹ï¼Œä¾¿äºåˆ†æç‰©ç†æœºåˆ¶æˆ–åµŒå…¥å…ˆéªŒçŸ¥è¯†ã€‚ |
| **çµæ´»æ€§** | ä¸å¼ºåˆ¶éµå¾ªç†è®ºæœ€ä¼˜å½¢å¼ï¼Œå…è®¸ä»»åŠ¡è‡ªé€‚åº”åœ°å­¦ä¹ ç®€åŒ–åŠ¨åŠ›å­¦ã€‚ |
| **ç¨³å®šæ€§** | åœ¨ç—…æ€æ¡ä»¶ï¼ˆhigh_conditionã€asymmetric åæ–¹å·®ï¼‰ä¸‹ä»ä¿æŒç¨³å®šæ€§èƒ½ï¼Œè€ŒåŸºçº¿å‡ºç°æ˜¾è‘—è¯¯å·®ä¸Šå‡ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
1. **Gaussian Transport Tasks**
   - äº”ç§åæ–¹å·®ç»“æ„åœºæ™¯ï¼šidentityã€diagonalã€rotatedã€asymmetricã€high_conditionã€‚
   - ç»´åº¦èŒƒå›´ï¼š5â€“50ã€‚
   - åˆ†å¸ƒå‡å€¼å˜åŒ–ï¼š0.1 åˆ° 10ã€‚
   - æ¯ç»„ç”Ÿæˆ $5\times10^4$ æ¡ç›´çº¿æ’å€¼è·¯å¾„ç”¨äºç›‘ç£è®­ç»ƒã€‚

2. **MNIST Latent Translation**
   - ä½¿ç”¨å·ç§¯ VAE ç¼–ç å™¨å°† MNIST å›¾åƒæ˜ å°„è‡³ 8 ç»´æ½œåœ¨ç©ºé—´ã€‚
   - ä»»åŠ¡ï¼šå°† digit-2 çš„ latent code æ˜ å°„ä¸º digit-3ã€‚
   - è®­ç»ƒæ ·æœ¬ï¼š$1.2\times10^6$ å¯¹ latent pairsï¼Œæ¯å¯¹é‡‡æ · 3 ä¸ªæ—¶é—´ç‚¹ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

| ç±»åˆ« | å†…å®¹ |
|------|------|
| **è¯„ä¼°æŒ‡æ ‡** | 
| - **Wasserstein è·ç¦» ($W_2$)**ï¼šè¡¡é‡åˆ†å¸ƒåŒ¹é…ç²¾åº¦ï¼ˆGaussian ä»»åŠ¡ï¼‰  
| - **FrÃ©chet Inception Distance (FID)**ï¼šè¯„ä¼°ç”Ÿæˆå›¾åƒè´¨é‡ï¼ˆMNISTï¼‰  
| - **Inception Score (IS)**ï¼šå¤šæ ·æ€§ä¸æ¸…æ™°åº¦ç»¼åˆæŒ‡æ ‡  
| - **Digit Accuracy**ï¼šåˆ†ç±»å™¨åˆ¤æ–­æ˜¯å¦ä¸º digit-3  
| - **Training / Inference Time**ï¼šè®­ç»ƒè€—æ—¶ä¸å•æ ·æœ¬æ¨ç†å»¶è¿Ÿ  
| - **Parameter Count**ï¼šå¯å­¦ä¹ å‚æ•°æ€»æ•°  

| **åŸºçº¿æ–¹æ³•å¯¹æ¯”** |
|------------------|
| - **DSBM**ï¼šæ ‡å‡†åŸºäº MLP çš„ SchrÃ¶dinger Bridge Matching æ–¹æ³•ï¼ˆShi et al., 2023ï¼‰  
| - **DSBM-NeuralODE**ï¼šæœ¬æ–‡æå‡ºçš„ Neural ODE ç‰ˆæœ¬ä½œä¸ºå†…éƒ¨å¯¹ç…§  
| - æ‰€æœ‰æ–¹æ³•åœ¨ç›¸åŒ latent pairs ä¸Šè®­ç»ƒï¼Œç¡¬ä»¶ä¸€è‡´ï¼ˆCPUï¼‰ |

| **SINDy-FM è®¾ç½®ç»†èŠ‚** |
|------------------------|
| - Gaussian ä»»åŠ¡ï¼šå‡è®¾ drift ä¸ºä»¿å°„å½¢å¼ $v(x,t)=K(t)x + k(t)$ï¼Œæ—¶é—´éƒ¨åˆ†å±•å¼€ä¸ºäºŒé˜¶å¤šé¡¹å¼  
| - MNIST ä»»åŠ¡ï¼šé‡‡ç”¨â€œrichâ€ç‰¹å¾åº“ $\Phi(x)\otimes\Psi(t)$ï¼ŒåŒ…å«æ‰€æœ‰äºŒæ¬¡é¡¹åŠæ—¶é—´ä¸‰æ¬¡é¡¹  
| - ä½¿ç”¨ SR3 ç¨—é€‰ç®—æ³•è¿›è¡Œç¨€ç–å›å½’ï¼Œæ§åˆ¶ sparsity threshold å’Œæ­£åˆ™åŒ–å¼ºåº¦ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ï¼ˆ1ï¼‰Gaussian Transport å®éªŒç»“æœï¼ˆè§ Table 1 & 2ï¼‰

#### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆä»¥ dim=50, mean=10 ä¸ºä¾‹ï¼‰
| Method | $W_2$ | Train Time (s) | Inference Time (s) | Parameters |
|--------|-------|----------------|--------------------|-----------|
| **SINDy-FM** | 0.303 | 50.36 | **1.5e-5** | **50** |
| DSBM-NeuralODE | 0.247 | 6027.98 | 82.12 | 1.2e6 |
| DSBM (baseline) | 0.550 | 750 | 0.41 | 9.2e4 |

#### æ€»ä½“è¶‹åŠ¿
- **Wasserstein è·ç¦»**ï¼šSINDy-FM åœ¨å¤šæ•°æƒ…å†µä¸‹æ¥è¿‘ç”šè‡³ä¼˜äº DSBMï¼Œå°¤å…¶åœ¨ identity/diagonal åœºæ™¯ä¸‹è¡¨ç°æœ€ä½³ã€‚
- **æ¨ç†é€Ÿåº¦**ï¼šSINDy-FM å¹³å‡ **8â€“15 Î¼s/sample**ï¼Œæ¯” DSBM å¿« **>10,000 å€**ã€‚
- **å‚æ•°å‹ç¼©**ï¼šå‚æ•°é‡é™ä½ **3â€“5 ä¸ªæ•°é‡çº§**ï¼ˆå¦‚ä»ç™¾ä¸‡çº§é™è‡³å‡ åæˆ–å‡ ç™¾ï¼‰ã€‚
- **é²æ£’æ€§**ï¼šåœ¨ asymmetric å’Œ high_condition åœºæ™¯ä¸­ï¼ŒDSBM å‡ºç°ä¸¥é‡æ€§èƒ½é€€åŒ–ï¼ˆ$W_2 > 2$ï¼‰ï¼Œè€Œ SINDy-FM ä¿æŒ $W_2 \sim 0.25$ã€‚

### ï¼ˆ2ï¼‰MNIST Latent Translation å®éªŒç»“æœï¼ˆè§ Table 3ï¼‰

| Metric | SINDy-FM (dense) | SINDy-FM (sparse) | DSBM |
|--------|------------------|-------------------|------|
| Digit Accuracy | 0.919 Â± 0.010 | 0.914 | 0.912 |
| FID | 83.48 Â± 9.98 | 89.38 Â± 7.78 | **72.17** |
| IS | 1.431 Â± 0.060 | 1.466 Â± 0.056 | 1.47 |
| Inference Time | **9.34e-4 s** | **9.36e-4 s** | 8.0e-2 s |
| Parameters | 923 | 541 | **2.72e6** |

#### å‘ç°
- SINDy-FM åœ¨ç”Ÿæˆè´¨é‡ä¸Šä¸ DSBM ç›¸å½“ï¼ˆdigit accuracy å’Œ IS æ¥è¿‘ï¼‰ï¼Œä»… FID ç•¥å·®ã€‚
- **æ¨ç†é€Ÿåº¦å¿«çº¦ 85 å€**ï¼Œé€‚åˆå®æ—¶éƒ¨ç½²ã€‚
- å¯é€šè¿‡è°ƒèŠ‚ sparsity threshold æ§åˆ¶æ¨¡å‹å¤æ‚åº¦ä¸æ€§èƒ½ä¹‹é—´çš„æƒè¡¡ã€‚

### æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
- **æ—¶é—´ç‚¹é‡‡æ ·æ•°**ï¼šæ¯æ¡è½¨è¿¹é‡‡æ ·å¤šä¸ªæ—¶é—´ç‚¹æœ‰åŠ©äºç¨³å®šè®­ç»ƒã€‚
- **ç‰¹å¾åº“è®¾è®¡**ï¼šåœ¨ Gaussian ä»»åŠ¡ä¸­é‡‡ç”¨ä»¿å°„ç»“æ„æ˜¾è‘—æå‡æ•ˆç‡ä¸æ³›åŒ–èƒ½åŠ›ã€‚
- **åˆå§‹åŒ–ç­–ç•¥**ï¼šDSBM-NeuralODE é€šè¿‡åœ¨çœŸå®æ‰©æ•£è½¨è¿¹ä¸Šé¢„è®­ç»ƒè·å¾—æ›´å¥½çš„æ”¶æ•›èµ·ç‚¹ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **ä»£ç†å»ºæ¨¡æ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„è·¯å¾„**ï¼šä½¿ç”¨ SINDy æˆ– Neural ODE æ„å»ºçš„ surrogate ODE æ¨¡å‹å¯ä»¥åœ¨ä¿æŒç”šè‡³è¶…è¶ŠåŸæ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œæå¤§æå‡æ¨ç†æ•ˆç‡ã€‚
2. âœ… **ç¬¦å·æ¨¡å‹ï¼ˆSINDy-FMï¼‰å…¼å…·é«˜æ•ˆä¸å¯è§£é‡Šæ€§**ï¼šç‰¹åˆ«é€‚ç”¨äºå…·æœ‰å†…åœ¨ç»“æ„çš„ä»»åŠ¡ï¼ˆå¦‚ Gaussian transportï¼‰ï¼Œèƒ½è¾“å‡ºäººç±»å¯è¯»çš„åŠ¨æ€æ–¹ç¨‹ã€‚
3. âœ… **Neural ODE æä¾›çµæ´»ä¸­é—´è·¯çº¿**ï¼šåœ¨å¤æ‚éçº¿æ€§æµå½¢ï¼ˆå¦‚ MNIST latent spaceï¼‰ä¸­ä»èƒ½æœ‰æ•ˆæ‹ŸåˆåŠ¨æ€ï¼Œè™½ä¸å¦‚ç¬¦å·æ¨¡å‹è½»é‡ï¼Œä½†æ¯”ä¼ ç»Ÿ MLP æ›´å…·è¿ç»­æ—¶é—´ä¸€è‡´æ€§ã€‚
4. âœ… **å‚æ•°é‡ä¸æ¨ç†å»¶è¿Ÿå¤§å¹…ä¸‹é™**ï¼šSINDy-FM å®ç°äº†â€œnear-instantaneous inferenceâ€ï¼Œä¸ºè¾¹ç¼˜è®¾å¤‡éƒ¨ç½²æä¾›äº†å¯èƒ½ã€‚

### æ–¹æ³•çš„å±€é™æ€§
| æ–¹æ³• | å±€é™æ€§ |
|------|--------|
| **SINDy-FM** | 
| - ä¾èµ–é¢„å®šä¹‰çš„ç‰¹å¾åº“ $\Phi(x,t)$ï¼Œè‹¥åº“ä¸å……åˆ†åˆ™æ— æ³•æ•æ‰å¤æ‚åŠ¨æ€  
| - é«˜åº¦éçº¿æ€§æˆ–æ··æ²Œç³»ç»Ÿå¯èƒ½éš¾ä»¥è¢«ç¨€ç–ç»„åˆé€¼è¿‘  
| - å¯¹å™ªå£°æ•æ„Ÿï¼Œéœ€é«˜è´¨é‡å¯¼æ•°æ ‡ç­¾ï¼ˆæœ¬æ–‡é€šè¿‡è§£ææ¢¯åº¦é¿å…ï¼‰ |
| **DSBM-NeuralODE** |
| - ä»æ˜¯é»‘ç®±æ¨¡å‹ï¼Œç¼ºä¹å¯è§£é‡Šæ€§  
| - è®­ç»ƒæˆæœ¬é«˜äº SINDy-FMï¼Œæ¥è¿‘ä¼ ç»Ÿ DSBM  
| - ä¾èµ–è‰¯å¥½çš„åˆå§‹è½¨è¿¹è¿›è¡Œé¢„è®­ç»ƒ |

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•ç¬¦å·å‘ç°å·¥å…·ç®±**ï¼šå¼•å…¥æ›´å¤æ‚çš„å‡½æ•°ç±»ï¼ˆå¦‚åˆ†æ®µå‡½æ•°ã€éšå¼æ–¹ç¨‹ï¼‰ã€ç¨‹åºåˆæˆæŠ€æœ¯è‡ªåŠ¨æ„é€ å€™é€‰åº“ã€‚
2. **æ··åˆå»ºæ¨¡æ¶æ„**ï¼šç»“åˆ symbolic å’Œ neural componentsï¼Œå½¢æˆ hybrid surrogatesï¼ˆä¾‹å¦‚ï¼šsymbolic backbone + neural correction termï¼‰ã€‚
3. **æå‡ Neural Surrogate æ•ˆç‡**ï¼šæ¢ç´¢ä½ç§©ã€é‡åŒ–ã€è’¸é¦ç­‰æ–¹å¼å‹ç¼© Neural ODE æ¨¡å‹ã€‚
4. **åº”ç”¨äºæ›´å¤šé¢†åŸŸ**ï¼šå¦‚åˆ†å­ç”Ÿæˆã€æ°”å€™æ¨¡æ‹Ÿã€æœºå™¨äººæ§åˆ¶ç­‰éœ€è¦é«˜æ•ˆã€å¯è§£é‡ŠåŠ¨æ€å»ºæ¨¡çš„åœºæ™¯ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> è¯¥è®ºæ–‡å¼€åˆ›æ€§åœ°å°† **surrogate modeling** å¼•å…¥ diffusion bridge åŠ¨åŠ›å­¦å»ºæ¨¡ï¼Œæå‡º **SINDy-FM** ä¸ **DSBM-NeuralODE** ä¸¤ç§æ–°èŒƒå¼ï¼Œåœ¨ä¿è¯ç”Ÿæˆè´¨é‡çš„å‰æä¸‹å®ç°äº†**æè‡´çš„æ•ˆç‡æå‡ä¸å¯è§£é‡Šæ€§çªç ´**ï¼Œä¸ºä¸‹ä¸€ä»£è½»é‡ã€è‡ªé€‚åº”ã€å¯éƒ¨ç½²çš„ç”Ÿæˆæ¨¡å‹é“ºå¹³é“è·¯ã€‚

</details>

---

### 10. [Accelerating Sparse Matrix-Matrix Multiplication on GPUs with Processing Near HBMs](https://arxiv.org/abs/2512.12036)

**Authors**: Shiju Li, Younghoon Min, Hane Yie, Hoshik Kim, Soohong Ahn, Joonseop Sim, Chul-Ho Lee, Jongryool Kim  
**Category**: cs.DC  
**Published**: 2025-12-16  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.12036v1  

#### Abstract
Sparse General Matrix-Matrix Multiplication (SpGEMM) is a fundamental operation in numerous scientific computing and data analytics applications, often bottlenecked by irregular memory access patterns. This paper presents Hash based Multi-phase SpGEMM on GPU and the Acceleration of Indirect Memory A...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **Sparse General Matrix-Matrix Multiplication (SpGEMM)** åœ¨ç°ä»£ GPU ä¸Šæ‰§è¡Œæ•ˆç‡ä½ä¸‹çš„é—®é¢˜å±•å¼€ç ”ç©¶ã€‚SpGEMM æ˜¯ç§‘å­¦è®¡ç®—ã€å›¾åˆ†æå’Œå›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ä¸­çš„å…³é”®æ“ä½œï¼Œä½†ç”±äºå…¶**ä¸è§„åˆ™å†…å­˜è®¿é—®æ¨¡å¼**ã€è´Ÿè½½ä¸å¹³è¡¡ä»¥åŠä¸­é—´ç»“æœç¨€ç–æ€§æœªçŸ¥ç­‰é—®é¢˜ï¼Œå¯¼è‡´ä¼ ç»Ÿ GPU æ¶æ„éš¾ä»¥é«˜æ•ˆå¤„ç†ã€‚

å…·ä½“æŒ‘æˆ˜åŒ…æ‹¬ï¼š
- ä¸è§„åˆ™çš„é—´æ¥å†…å­˜è®¿é—®é€ æˆç¼“å­˜å‘½ä¸­ç‡ä½ï¼›
- å“ˆå¸Œè¡¨åœ¨å…±äº«å†…å­˜ä¸­æ˜“äº§ç”Ÿ bank conflictï¼›
- å…¨å±€åŸå­æ“ä½œå¼€é”€å¤§ï¼›
- è´Ÿè½½åˆ†å¸ƒä¸å‡å½±å“å¹¶è¡Œæ•ˆç‡ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

è®ºæ–‡æå‡ºäº†ä¸€ä¸ªè½¯ç¡¬ä»¶ååŒè®¾è®¡æ¡†æ¶ï¼Œæ ¸å¿ƒæ˜¯åä¸º **Acceleration of Indirect memory Access (AIA)** çš„æ–°å‹ **Processing-Near-HBM** æŠ€æœ¯ã€‚

#### ä¸»è¦è´¡çŒ®å¦‚ä¸‹ï¼š

1. âœ… **ä¼˜åŒ–çš„ Hash-Based å¤šé˜¶æ®µ SpGEMM ç®—æ³•ï¼ˆè½¯ä»¶å±‚é¢ï¼‰**
   - è®¾è®¡äº†ä¸€ä¸ªä¸‰é˜¶æ®µæµç¨‹ï¼š**Row-grouping â†’ Allocation â†’ Accumulation**ã€‚
   - å¼•å…¥åŸºäº `IP`ï¼ˆIntermediate Product æ•°é‡ï¼‰çš„è¡Œåˆ†ç»„ç­–ç•¥ï¼Œå®ç°åŠ¨æ€è´Ÿè½½å‡è¡¡ã€‚
   - é’ˆå¯¹ä¸åŒè´Ÿè½½å¼ºåº¦é‡‡ç”¨ä¸¤ç§çº¿ç¨‹åˆ†é…ç­–ç•¥ï¼š
     - **PWPR (Partial Warp Per Row)**ï¼šè½»è´Ÿè½½ä½¿ç”¨ 4 çº¿ç¨‹/è¡Œã€‚
     - **TBPR (Thread Block Per Row)**ï¼šé‡è´Ÿè½½ä½¿ç”¨å®Œæ•´çº¿ç¨‹å—ã€‚
   - åˆ©ç”¨å“ˆå¸Œè¡¨è¿›è¡Œé«˜æ•ˆçš„éé›¶å…ƒå»é‡ä¸ç´¯åŠ ï¼Œå¹¶æ”¯æŒå…±äº«å†…å­˜ä¸å…¨å±€å†…å­˜çš„ä¸¤çº§å“ˆå¸Œè¡¨å›é€€æœºåˆ¶ã€‚

2. âœ… **è¿‘ HBM å¤„ç†å•å…ƒ AIAï¼ˆç¡¬ä»¶å±‚é¢ï¼‰**
   - å°† AIA å¼•æ“é›†æˆäº **HBM æ§åˆ¶å™¨å†…éƒ¨**ï¼Œä½äº GPU æ ¸å¿ƒä¸ HBM å †æ ˆä¹‹é—´ã€‚
   - æ”¯æŒ **Ranged Indirect Access** åŠŸèƒ½ï¼Œå°†åŸæœ¬éœ€è¦å¤šæ¬¡å¾€è¿”å†…å­˜çš„éšæœºè®¿é—®åˆå¹¶ä¸ºä¸€æ¬¡æ‰¹é‡è¯·æ±‚ã€‚
   - å°† SpGEMM ä¸­å…¸å‹çš„â€œä¸¤å±‚é—´æ¥è®¿é—®â€è½¬æ¢ä¸ºå¯é¢„æµ‹çš„é¡ºåºæµï¼Œæ˜¾è‘—å‡å°‘å»¶è¿Ÿå’Œå†…å­˜æµé‡ã€‚

3. âœ… **è½¯ç¡¬ååŒè®¾è®¡çš„æ•´ä½“åŠ é€Ÿæ–¹æ¡ˆ**
   - AIA ååŠ©ä¸» GPU æ ¸å¿ƒå®Œæˆæ•°æ®é¢„å–ä¸èšé›†ï¼Œæå‡ L1 ç¼“å­˜åˆ©ç”¨ç‡ã€‚
   - å®ç°äº†ä»ç®—æ³•è°ƒåº¦åˆ°åº•å±‚å†…å­˜ç³»ç»Ÿçš„ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ€§èƒ½** | æ˜¾è‘—ä¼˜äº cuSPARSE å’Œçº¯è½¯ä»¶å®ç°ï¼Œåœ¨å¤šç§åº”ç”¨ä¸Šå®ç°æ•°å€åŠ é€Ÿ |
| **èƒ½æ•ˆ** | å‡å°‘ä¸å¿…è¦çš„æ•°æ®æ¬ç§»ï¼Œé™ä½æ•´ä½“åŠŸè€— |
| **å¯æ‰©å±•æ€§** | å¯¹å¤§è§„æ¨¡ç¨€ç–çŸ©é˜µå’Œå¤æ‚å›¾ç»“æ„è¡¨ç°å‡ºè‰¯å¥½æ‰©å±•æ€§ |
| **é€šç”¨æ€§** | å¯åº”ç”¨äº GNNã€å›¾èšç±»ã€å›¾å‹ç¼©ç­‰å¤šç§åœºæ™¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

å®éªŒæ¶µç›–äº†å¤šä¸ªé¢†åŸŸçš„ç¨€ç–çŸ©é˜µï¼Œä¸»è¦æ¥è‡ª **University of Florida Sparse Matrix Collection** å’Œæ ‡å‡† GNN åŸºå‡†æ•°æ®é›†ï¼š

#### SpGEMM ä¸å›¾åˆ†æä»»åŠ¡ï¼š
- `RoadTX`, `p2p-Gnutella04`, `amazon0601`, `web-Google`
- `scircuit`, `cit-Patents`, `Economics`, `webbase-1M`
- `wb-edu`, `cage15`, `Wind Tunnel`, `Protein`

#### GNN è®­ç»ƒä»»åŠ¡ï¼ˆå«ç»“æ„åŒ–å‰ªæï¼‰ï¼š
| æ•°æ®é›† | èŠ‚ç‚¹æ•° | è¾¹æ•° | ç±»åˆ« |
|--------|--------|------|------|
| Flickr | 89K | ~1M | ç¤¾äº¤ç½‘ç»œ |
| ogbn-arxiv | 169K | 1.3M | å¼•æ–‡ç½‘ç»œ |
| Reddit | 233K | 114M | ç¤¾äº¤ç½‘ç»œ |
| Yelp | 717K | 13.9M | å•†æˆ·è¯„è®º |
| ogbn-proteins | 132K | 79M | ç”Ÿç‰©ç½‘ç»œ |
| ogbn-products | 2.45M | 126M | ç”µå•†å•†å“å›¾ |

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

- **ç¡¬ä»¶å¹³å°**ï¼š
  - CPU: AMD EPYC 9555 (3.2GHz, 64æ ¸)
  - GPU: **NVIDIA H200**ï¼ˆé…å¤‡ HBMï¼‰
  - å†…å­˜: 1.5TB RAM

- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - æ‰§è¡Œæ—¶é—´ï¼ˆRuntimeï¼‰
  - åŠ é€Ÿæ¯”ï¼ˆSpeedupï¼‰
  - GFLOPS ååé‡
  - L1 Cache Hit Ratio
  - è®­ç»ƒæ—¶é—´å‡å°‘æ¯”ä¾‹ï¼ˆGNN åœºæ™¯ï¼‰

- **å¯¹æ¯”åŸºçº¿æ–¹æ³•**ï¼š
  - **cuSPARSE**ï¼šNVIDIA å®˜æ–¹ç¨€ç–åº“ï¼Œä½œä¸ºä¸»æµåŸºå‡†ã€‚
  - **Without AIA**ï¼šç›¸åŒè½¯ä»¶ç®—æ³•ä½†å…³é—­ AIA ç¡¬ä»¶æ¨¡å—ï¼Œç”¨äºæ¶ˆèåˆ†æã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| åº”ç”¨åœºæ™¯ | æŒ‡æ ‡ | ç»“æœ |
|---------|------|-------|
| **åŸºç¡€ SpGEMMï¼ˆè‡ªä¹˜ï¼‰** | å¹³å‡è¿è¡Œæ—¶å‡å°‘ vs cuSPARSE | **80.5%** |
| | å¹³å‡ååæå‡ vs cuSPARSE | **6.87Ã— GFLOPS** |
| | æœ€é«˜åŠ é€Ÿæ¯”ï¼ˆå¦‚ Wind Tunnelï¼‰ | **9.4Ã—** |
| **L1 Cache å‘½ä¸­ç‡** | Accumulation Phase æå‡ | 64.41% â†’ **75.14%** |
| | Allocation Phase æå‡ | 64.66% â†’ **88.15%** |
| **Graph Contraction** | å¹³å‡åŠ é€Ÿ vs cuSPARSE | **76.5% æ—¶é—´å‡å°‘**ï¼ˆå³ 4.2Ã— speedupï¼‰ |
| | æœ€é«˜åŠ é€Ÿï¼ˆProteinï¼‰ | **91.1% æ—¶é—´å‡å°‘** |
| **Markov Clustering (MCL)** | å¹³å‡åŠ é€Ÿ vs cuSPARSE | **58.4% æ—¶é—´å‡å°‘**ï¼ˆçº¦ 2.4Ã— speedupï¼‰ |
| | æœ€é«˜åŠ é€Ÿï¼ˆEconomicsï¼‰ | **88.7% æ—¶é—´å‡å°‘** |
| **GNN è®­ç»ƒï¼ˆå¸¦ç»“æ„åŒ–å‰ªæï¼‰** | å¹³å‡è®­ç»ƒæ—¶é—´å‡å°‘ vs è½¯ä»¶å®ç° | **30.3%** |
| | å¹³å‡è®­ç»ƒæ—¶é—´å‡å°‘ vs cuSPARSE | **48.6%** |
| | æœ€å¤§åŠ é€Ÿï¼ˆProducts æ•°æ®é›†ï¼‰ | **76.1% æ—¶é—´å‡å°‘**ï¼ˆâ‰ˆ4.18Ã— speedupï¼‰ |
| | å¹³å‡é€Ÿåº¦æå‡ï¼ˆvs cuSPARSEï¼‰ | **1.95Ã—** |
| | å¤§è§„æ¨¡æ•°æ®é›†æœ€å¤§å¢ç›Š | **up to 4.18Ã—** |

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

- åœ¨æ‰€æœ‰æµ‹è¯•çŸ©é˜µä¸Šï¼ŒAIA æ–¹æ¡ˆå‡æ˜¾è‘—ä¼˜äº cuSPARSEï¼Œå°¤å…¶åœ¨å¤§è§„æ¨¡ã€é«˜ç¨€ç–åº¦å›¾ä¸Šè¡¨ç°æ›´ä¼˜ã€‚
- ç›¸æ¯”æ—  AIA çš„è½¯ä»¶å®ç°ï¼ŒAIA å¹³å‡å¸¦æ¥ **17.3% çš„é¢å¤–æ—¶é—´èŠ‚çœ**ï¼Œè¯´æ˜ç¡¬ä»¶åŠ é€Ÿæ•ˆæœæ˜æ˜¾ã€‚
- åœ¨ `wb-edu` å’Œ `cage15` è¿™ç±»è¶…å¤§è§„æ¨¡çŸ©é˜µä¸Šï¼ŒAIA å®ç°äº†è¶…è¿‡ **80% çš„è¿è¡Œæ—¶ç¼©å‡**ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

- **å…³é—­ AIA æ¨¡å—å**ï¼š
  - L1 ç¼“å­˜å‘½ä¸­ç‡ä¸‹é™è‡³åŸå§‹æ°´å¹³ï¼ˆ~64%ï¼‰ï¼ŒéªŒè¯ AIA å¯¹å†…å­˜è®¿é—®æ¨¡å¼ä¼˜åŒ–çš„æœ‰æ•ˆæ€§ã€‚
  - æ‰§è¡Œæ—¶é—´å¹³å‡å¢åŠ  10â€“27%ï¼Œè¡¨æ˜ AIA å¯¹æ€§èƒ½æœ‰å®è´¨æ€§è´¡çŒ®ã€‚
- **ä¸åŒè´Ÿè½½åˆ†ç»„ç­–ç•¥çš„å½±å“**ï¼š
  - å››ç»„åˆ’åˆ†ï¼ˆIP åˆ†æ¡¶ï¼‰æœ‰æ•ˆç¼“è§£äº†è´Ÿè½½å€¾æ–œé—®é¢˜ï¼Œä½¿ GPU åˆ©ç”¨ç‡æ›´é«˜ã€‚
- **å“ˆå¸Œè¡¨å¤§å°è‡ªé€‚åº”æœºåˆ¶**ï¼š
  - å°è¡Œä½¿ç”¨å°å“ˆå¸Œè¡¨é¿å…èµ„æºæµªè´¹ï¼Œå¤§è¡Œè‡ªåŠ¨åˆ‡æ¢è‡³å…¨å±€å†…å­˜å“ˆå¸Œè¡¨ï¼Œä¿è¯æ­£ç¡®æ€§å’Œæ€§èƒ½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. ğŸ” **Processing-Near-HBM æ˜¯è§£å†³ SpGEMM å†…å­˜å¢™é—®é¢˜çš„æœ‰æ•ˆè·¯å¾„**  
   AIA æˆåŠŸå°†ä¸è§„åˆ™çš„é—´æ¥è®¿é—®è½¬åŒ–ä¸ºé¡ºåºæµï¼Œæå¤§æå‡äº†ç¼“å­˜åˆ©ç”¨ç‡å’Œå†…å­˜å¸¦å®½æ•ˆç‡ã€‚

2. ğŸ“ˆ **æ€§èƒ½å¢ç›Šéšå›¾è§„æ¨¡å¢å¤§è€Œå¢å¼º**  
   Pearson ç›¸å…³ç³»æ•°è¾¾ **r = 0.94**ï¼Œæ˜¾ç¤º AIA æ”¹è¿›å¹…åº¦ä¸èŠ‚ç‚¹æ•°é‡å‘ˆå¼ºæ­£ç›¸å…³ã€‚ä¾‹å¦‚ï¼š
   - Flickr (89K): 15.3% æ”¹è¿›
   - Products (2.4M): **89.16% æ”¹è¿›**

3. ğŸ”„ **è½¯ç¡¬ååŒè®¾è®¡å…·æœ‰ä¹˜æ³•æ•ˆåº”**  
   ç»“æ„åŒ–å‰ªæ + AIA åŠ é€Ÿå®ç°äº† **è¶…è¶Šå•ä¸€ä¼˜åŒ–çš„å åŠ æ”¶ç›Š**ï¼Œæ€»è®­ç»ƒæ—¶é—´å¹³å‡å‡å°‘ 30.3%ã€‚

4. ğŸ§± **AIA å…·å¤‡æ¶æ„é€šç”¨æ€§**  
   åœ¨ GCNã€GINã€GraphSAGE ä¸‰ç§ä¸»æµ GNN æ¶æ„ä¸‹æ€§èƒ½æå‡ç¨³å®šï¼ˆæ–¹å·® < 3%ï¼‰ï¼Œè¯æ˜å…¶å¹¿æ³›é€‚ç”¨æ€§ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

- â— **ä¾èµ–å®šåˆ¶åŒ–ç¡¬ä»¶æ”¯æŒ**ï¼šAIA éœ€è¦åœ¨ HBM æ§åˆ¶å™¨ä¸­åµŒå…¥ä¸“ç”¨å¼•æ“ï¼Œç›®å‰ä»…é€‚ç”¨äºç‰¹å®šé«˜ç«¯ GPUï¼ˆå¦‚ H200ï¼‰ï¼Œä¸å…·å¤‡å³æ’å³ç”¨ç‰¹æ€§ã€‚
- âš ï¸ **é¢ç§¯ä¸åŠŸè€—å¼€é”€æœªè¯¦ç»†æŠ«éœ²**ï¼šè™½ç„¶æåŠâ€œè½»é‡çº§â€ï¼Œä½†æœªæä¾›å…·ä½“çš„ç¡¬ä»¶é¢ç§¯æˆ–åŠŸè€—æ•°æ®ã€‚
- ğŸ§© **å¯¹æç¨€ç–æˆ–ç‰¹æ®Šç»“æ„çŸ©é˜µçš„æ³›åŒ–èƒ½åŠ›å¾…éªŒè¯**ï¼šéƒ¨åˆ†æç«¯ç¨€ç–æˆ–é«˜åº¦ä¸è§„åˆ™ç»“æ„å¯èƒ½ä»å­˜åœ¨ç“¶é¢ˆã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. ğŸ”œ æ¢ç´¢ AIA åœ¨å…¶ä»–ç¨€ç–è®¡ç®—åœºæ™¯çš„åº”ç”¨ï¼Œå¦‚ SpMVã€ç¨€ç– Transformerã€‚
2. ğŸ” ç ”ç©¶ç¼–è¯‘å™¨è‡ªåŠ¨è¯†åˆ«å¯ offload è‡³ AIA çš„é—´æ¥è®¿é—®æ¨¡å¼ï¼Œæå‡ç¼–ç¨‹ä¾¿æ·æ€§ã€‚
3. ğŸ’¡ æ‰©å±•è‡³å¤šè®¾å¤‡åˆ†å¸ƒå¼ç¯å¢ƒï¼Œåˆ©ç”¨ AIA å‡å°‘è·¨èŠ‚ç‚¹é€šä¿¡å¼€é”€ã€‚
4. ğŸ›  å¼€å‘å¼€æºæ¨¡æ‹Ÿå™¨æˆ– FPGA åŸå‹ï¼Œä¾¿äºç¤¾åŒºå¤ç°ä¸æ”¹è¿›ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡é€šè¿‡æå‡º **AIA â€”â€” ä¸€ç§é›†æˆäº HBM çš„è¿‘å†…å­˜å¤„ç†æŠ€æœ¯**ï¼Œç»“åˆä¼˜åŒ–çš„å¤šé˜¶æ®µå“ˆå¸Œ SpGEMM ç®—æ³•ï¼Œåœ¨ GNNã€å›¾èšç±»ç­‰å…³é”®åº”ç”¨ä¸­å®ç°äº†é«˜è¾¾ **4.18Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿ**ï¼Œä¸ºçªç ´ç¨€ç–è®¡ç®—çš„â€œå†…å­˜å¢™â€æä¾›äº†æå…·å‰æ™¯çš„è½¯ç¡¬ååŒè§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 11. [Link-Aware Energy-Frugal Continual Learning for Fault Detection in IoT Networks](https://arxiv.org/abs/2512.13340)

**Authors**: Henrik C. M. Frederiksen, Junya Shiraishi, Cedomir Stefanovic, Hei Victor Cheng, Shashi Raj Pandey  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.13340v1  

#### Abstract
The use of lightweight machine learning (ML) models in internet of things (IoT) networks enables resource constrained IoT devices to perform on-device inference for several critical applications. However, the inference accuracy deteriorates due to the non-stationarity in the IoT environment and limi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**Link-Aware Energy-Frugal Continual Learning for Fault Detection in IoT Networks**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### âœ… è§£å†³çš„é—®é¢˜
åœ¨èµ„æºå—é™çš„ IoT è®¾å¤‡ä¸Šéƒ¨ç½²è½»é‡çº§ ML æ¨¡å‹è¿›è¡Œ **on-device inference**ï¼ˆå¦‚æ•…éšœæ£€æµ‹ï¼‰æ—¶ï¼Œé¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- åˆå§‹è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œéš¾ä»¥è¦†ç›–æ‰€æœ‰æ•…éšœæ¨¡å¼ï¼›
- ç¯å¢ƒéå¹³ç¨³æ€§å¯¼è‡´æ¨¡å‹æ€§èƒ½éšæ—¶é—´ä¸‹é™ï¼›
- é¢‘ç¹æ›´æ–°æ¨¡å‹ä¼šå¸¦æ¥é«˜æ˜‚çš„é€šä¿¡èƒ½è€—ï¼Œè€Œ IoT è®¾å¤‡é€šå¸¸èƒ½é‡å—é™ï¼›
- å›ºå®šå‘¨æœŸçš„æ•°æ®é‡‡æ ·æˆ–æ¨¡å‹æ›´æ–°ç­–ç•¥æ— æ³•é€‚åº”åŠ¨æ€æ— çº¿é“¾è·¯æ¡ä»¶å’Œèƒ½é‡é¢„ç®—ã€‚

å› æ­¤ï¼Œå¦‚ä½•åœ¨ **æœ‰é™çš„èƒ½é‡å’Œå¸¦å®½çº¦æŸä¸‹**ï¼ŒæŒç»­æå‡æ¨¡å‹æ¨ç†å‡†ç¡®ç‡ï¼ˆå°¤å…¶æ˜¯å¯¹ç½•è§æ•…éšœçš„æ£€æµ‹èƒ½åŠ›ï¼‰ï¼Œæ˜¯ä¸€ä¸ªå…³é”®éš¾é¢˜ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šACORD
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **ACORD**ï¼ˆAdaptive Compression Online Resource-aware fault Detectionï¼‰çš„äº‹ä»¶é©±åŠ¨ã€èƒ½é‡é«˜æ•ˆçš„æŒç»­å­¦ä¹ æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**äº‹ä»¶é©±åŠ¨é€šä¿¡æœºåˆ¶**
- IoT è®¾å¤‡ä»…åœ¨æ£€æµ‹åˆ°æ½œåœ¨å¼‚å¸¸ï¼ˆå¯èƒ½ä¸ºç½•è§æ•…éšœï¼‰æ—¶æ‰ä¸Šä¼ ä¸Šä¸‹æ–‡æ•°æ®ï¼ˆcontext windowï¼‰ï¼Œé¿å…æ— æ„ä¹‰çš„å‘¨æœŸæ€§ä¼ è¾“ï¼Œæ˜¾è‘—é™ä½èƒ½è€—ã€‚

#### ï¼ˆ2ï¼‰**é“¾è·¯æ„ŸçŸ¥çš„è‡ªé€‚åº”å‹ç¼©æœºåˆ¶**
- åœ¨è¾¹ç¼˜æœåŠ¡å™¨ï¼ˆESï¼‰ç«¯ï¼Œæ ¹æ®å½“å‰ä¼°è®¡çš„ **uplink/downlink é“¾è·¯é€Ÿç‡** å’Œè®¾å¤‡å‰©ä½™ **energy budget**ï¼ŒåŠ¨æ€è°ƒæ•´ï¼š
  - **pruning level (PL)**ï¼šå‰ªææ¯”ä¾‹
  - **quantization level (QL)**ï¼šé‡åŒ–ä½æ•°ï¼ˆå¦‚ 8-bit æˆ– 32-bitï¼‰
- å®ç°æ¨¡å‹å¤§å°ä¸é€šä¿¡å»¶è¿Ÿä¹‹é—´çš„æœ€ä¼˜æƒè¡¡ã€‚

#### ï¼ˆ3ï¼‰**è”åˆä¼˜åŒ–å‚æ•°ç­–ç•¥**
- è”åˆä¼˜åŒ–ä¸‰ä¸ªå…³é”®å‚æ•°ï¼š
  - ä¸Šè¡Œä¼ è¾“çš„ä¸Šä¸‹æ–‡çª—å£å¤§å° $ W $
  - ä¸‹è¡Œæ¨¡å‹å‹ç¼©å‚æ•° $ \{P_L, Q_L\} $
  - æ•…éšœåˆ¤å®šé˜ˆå€¼ $ T_{th} $
- æ‰€æœ‰å‚æ•°å‡åŸºäºå®æ—¶é“¾è·¯çŠ¶æ€å’Œèƒ½é‡æ¶ˆè€—è¿›è¡Œè¿­ä»£ä¼˜åŒ–ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | ACORD | åŸºçº¿æ–¹æ³•ï¼ˆå¦‚ Hawkã€Periodic Samplingï¼‰ |
|--------|-------|-----------------------------|
| **é€šä¿¡è§¦å‘æœºåˆ¶** | äº‹ä»¶é©±åŠ¨ï¼ˆä»…ä¼ é‡è¦æ•°æ®ï¼‰ | å‘¨æœŸæ€§æˆ–å›ºå®šè§„åˆ™ |
| **æ¨¡å‹å‹ç¼©ç­–ç•¥** | é“¾è·¯ä¸èƒ½é‡æ„ŸçŸ¥è‡ªé€‚åº”å‹ç¼© | å›ºå®šå‹ç¼©ï¼ˆå¦‚ PL=0, QL=32ï¼‰ |
| **èƒ½é‡æ•ˆç‡** | æ˜¾è‘—æ›´ä½èƒ½è€—ä¸‹çš„é«˜ recall | å®¹æ˜“è¶…å‡º energy budget |
| **æ¨ç†å‡†ç¡®æ€§** | æ›´å¥½åœ°æ•æ‰ç½•è§æ•…éšœ | æ•°æ®å†—ä½™æˆ–ä¿¡æ¯ä¸è¶³ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šACORD åœ¨èƒ½é‡å—é™åœºæ™¯ä¸­å®ç°äº†æ›´é«˜çš„ fault detection recallï¼Œå°¤å…¶é€‚ç”¨äºç¨€ç–æ•…éšœäº‹ä»¶å’Œä½å¸¦å®½ç¯å¢ƒã€‚

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
- **pump_sensor_data**ï¼ˆæ¥è‡ª Kaggleï¼‰
  - åŒ…å«çº¦ 220,000 æ¡æ ·æœ¬
  - æ¯æ¡æ ·æœ¬æœ‰ 50 ä¸ªç‰¹å¾ï¼ˆæ³µç±»è®¾å¤‡é¥æµ‹æ•°æ®ï¼‰
  - æ ‡ç­¾ç±»åˆ«ï¼š`NORMAL`, `RECOVERING`, `BROKEN`
    - `BROKEN` è¡¨ç¤ºæ•…éšœçŠ¶æ€ï¼ˆä»…æœ‰ 7 ä¸ªå®ä¾‹ â†’ æåº¦ç¨€ç–ï¼‰
  - åˆå§‹è®­ç»ƒé›†ä»…å«æ­£å¸¸æ•°æ®ï¼ˆæ¨¡æ‹Ÿå®é™…éƒ¨ç½²ä¸­ç¼ºä¹æ•…éšœæ ·æœ¬çš„æƒ…å†µï¼‰

---

### âš™ï¸ å®éªŒè®¾ç½®
- **ç½‘ç»œæ¶æ„**ï¼šIoT è®¾å¤‡ â†” Wi-Fi AP â†” Edge Serverï¼ˆé€šè¿‡ TCP åè®®ï¼‰
- **ç¡¬ä»¶æ¨¡æ‹Ÿ**ï¼š
  - IoT è®¾å¤‡ä½¿ç”¨ ESP32 åŠŸè€—å‚æ•°ï¼š$ P_{tx} = 0.79\,\text{W},\; P_{rx} = 0.33\,\text{W} $
- **æ¨¡å‹ç±»å‹**ï¼š
  - Autoencoder (AE) å’Œ Binary Classifier (BC)ï¼Œæœ€ç»ˆé€‰ç”¨ AE å› å…¶ superior performance
- **è®­ç»ƒé…ç½®**ï¼š
  - æ¯è½®è®­ç»ƒ epoch æ•°ï¼š$ L_{\text{epoch}} = 2000 / (2W + 1) $
  - ä½¿ç”¨ Experience Replay ç¼“è§£ catastrophic forgetting
- **èƒ½é‡å‚è€ƒå€¼**ï¼šè®¾ $ E_{\text{ref}} = 60\,\text{J} $ï¼Œç”¨äºå½’ä¸€åŒ–ç›®æ ‡ä¼ è¾“æ—¶é—´

---

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Recallï¼ˆå¬å›ç‡ï¼‰** | $ \frac{\sum \mathbf{1}(s_i=1)\mathbf{1}(\hat{s}_i=1)}{\sum \mathbf{1}(s_i=1)} $ï¼šæ­£ç¡®è¯†åˆ«å‡ºçš„çœŸå®æ•…éšœå æ¯” |
| **Energy Consumption** | æ€»èƒ½è€— = é€šä¿¡èƒ½è€— + æ¨ç†è®¡ç®—èƒ½è€— |
| **ROC Curve & TPR/FPR** | ç”¨äºé€‰æ‹©æœ€ä¼˜å†³ç­–é˜ˆå€¼ $ T_{th} $ |

---

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **Hawk [4]**ï¼š
   - éè‡ªé€‚åº” CL æ–¹æ³•
   - å›ºå®šå‚æ•°ï¼š$ PL=0, QL=32, W=200 $
   - ä¸è€ƒè™‘é“¾è·¯çŠ¶æ€æˆ–èƒ½é‡é¢„ç®—
2. **Periodic Sampling**ï¼š
   - å‘¨æœŸæ€§ä¸Šä¼ æ•°æ®ï¼Œä¸è®ºæ˜¯å¦ä¸ºæ½œåœ¨æ•…éšœ
   - è°ƒæ•´é‡‡æ ·é¢‘ç‡ä»¥æ»¡è¶³ $ E_{\text{total}} \leq E_{\text{th}} $

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Fig. 1b å’Œ 1cï¼‰

#### ï¼ˆ1ï¼‰Recall vs. Energy Threshold ($ E_{\text{th}} $) â€” å›¾ 1b
- å½“ $ E_{\text{th}} = 60\,\text{J} $ æ—¶ï¼š
  - **ACORD** çš„ recall è¾¾åˆ° ~0.75
  - **Hawk** çº¦ä¸º ~0.55
  - **Periodic Sampling** çº¦ä¸º ~0.45
- **æœ€é«˜æå‡è¾¾ 42.8%**ï¼ˆç›¸æ¯” Periodic Samplingï¼‰

> ğŸ’¡ åŸå› ï¼šACORD æ›´é«˜æ•ˆåˆ©ç”¨èƒ½é‡ï¼Œä¼˜å…ˆä¼ è¾“é«˜ä»·å€¼æ•°æ®ï¼Œå¹¶åŠ¨æ€å‹ç¼©æ¨¡å‹ï¼Œå»¶é•¿å¯æ›´æ–°è½®æ¬¡ã€‚

#### ï¼ˆ2ï¼‰Recall vs. Network Bandwidth â€” å›¾ 1c
- åœ¨ä½å¸¦å®½ï¼ˆ< 2 Mbpsï¼‰æ¡ä»¶ä¸‹ï¼š
  - ACORD æ˜æ˜¾ä¼˜äºå…¶ä»–ä¸¤ç§æ–¹æ³•
  - Hawk å’Œ Periodic Sampling å› æœªé€‚é…é“¾è·¯è´¨é‡ï¼Œé€šä¿¡æ•ˆç‡ä½ä¸‹
- åœ¨é«˜å¸¦å®½ä¸‹å·®è·ç¼©å°ï¼Œä½†ä»ä¿æŒé¢†å…ˆ

#### ï¼ˆ3ï¼‰Autoencoder vs. Binary Classifier â€” å›¾ 1a
- AE çš„ ROC æ›²çº¿è¿œä¼˜äº BC
- åŸå› ï¼šAE ä½¿ç”¨åŒæƒé‡æŸå¤±å‡½æ•°ï¼ˆEq. 11ï¼‰ï¼Œèƒ½ä» FP å’Œ TP ä¸­åŒæ—¶å­¦ä¹ ï¼›è€Œ BC éœ€ç§¯ç´¯è¶³å¤Ÿ TP æ‰èƒ½æœ‰æ•ˆè®­ç»ƒ

---

### âŒ æ¶ˆèåˆ†æï¼ˆéšå«äºè®¾è®¡é€»è¾‘ä¸­ï¼‰
è™½ç„¶æ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèå®éªŒè¡¨æ ¼ï¼Œä½†ä»æœºåˆ¶è®¾è®¡å¯æ¨æ–­ä»¥ä¸‹å…³é”®ç»„ä»¶çš„ä½œç”¨ï¼š
| ç»„ä»¶ | ä½œç”¨éªŒè¯ |
|------|---------|
| **Event-driven upload** | å‡å°‘æ— æ•ˆä¼ è¾“ï¼ŒèŠ‚çœèƒ½é‡ç”¨äºæ›´å¤š CL è½®æ¬¡ |
| **Adaptive compression (PL/QL)** | åœ¨ä½å¸¦å®½ä¸‹ä»èƒ½å®Œæˆæ¨¡å‹ä¸‹è½½ |
| **Context window (W)** | æ›´å¤§ W æä¾›æ›´ä¸°å¯Œä¸Šä¸‹æ–‡ï¼Œæå‡è®­ç»ƒè´¨é‡ |
| **Dynamic $ T_{th} $ selection** | å¹³è¡¡ TPR ä¸ FPRï¼Œä¼˜åŒ– recall |

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### âœ… ä¸»è¦å‘ç°
1. **äº‹ä»¶é©±åŠ¨ + è‡ªé€‚åº”å‹ç¼©æ˜¯èŠ‚èƒ½ CL çš„å…³é”®**  
   åœ¨èƒ½é‡å’Œå¸¦å®½å—é™çš„ IoT åœºæ™¯ä¸­ï¼Œç›²ç›®ä¸Šä¼ æ•°æ®æˆ–å›ºå®šæ¨¡å‹æ›´æ–°ç­–ç•¥ä¼šå¯¼è‡´èµ„æºæµªè´¹å’Œæ—©æœŸè€—å°½èƒ½é‡ã€‚

2. **é“¾è·¯æ„ŸçŸ¥çš„å‚æ•°è°ƒèŠ‚æ˜¾è‘—æå‡ recall**  
   ACORD é€šè¿‡å®æ—¶ä¼°è®¡ $ R_{UL}/R_{DL} $ å¹¶ç»“åˆ energy budget åŠ¨æ€è°ƒæ•´ $ W, PL, QL $ï¼Œå®ç°é€šä¿¡ä¸ç²¾åº¦çš„æœ€ä½³å¹³è¡¡ã€‚

3. **AE æ¯” BC æ›´é€‚åˆç¨€ç–æ•…éšœæ£€æµ‹ä»»åŠ¡**  
   å°¤å…¶æ˜¯åœ¨ä»…æœ‰å°‘é‡æ•…éšœæ ‡ç­¾çš„æƒ…å†µä¸‹ï¼ŒAE å¯é€šè¿‡é‡æ„è¯¯å·®æœºåˆ¶å­¦ä¹ å¼‚å¸¸æ¨¡å¼ã€‚

4. **ACORD åœ¨æç«¯èµ„æºé™åˆ¶ä¸‹è¡¨ç°æœ€ä½³**  
   ç‰¹åˆ«æ˜¯åœ¨ $ E_{\text{th}} < 60\,\text{J} $ æˆ– bandwidth < 2 Mbps æ—¶ï¼Œæ€§èƒ½ä¼˜åŠ¿æœ€ä¸ºæ˜æ˜¾ã€‚

---

### âš ï¸ å±€é™æ€§
1. **å•è®¾å¤‡å‡è®¾**ï¼šç›®å‰æ¡†æ¶åŸºäºå•ä¸€ IoT è®¾å¤‡ä¸ ES äº¤äº’ï¼Œæœªè€ƒè™‘å¤šèŠ‚ç‚¹ç«äº‰ä¿¡é“é—®é¢˜ã€‚
2. **ä¾èµ–å¯é é“¾è·¯ä¼°è®¡**ï¼šæ€§èƒ½ä¾èµ–äºå‡†ç¡®çš„ $ R_{UL}/R_{DL} $ æµ‹é‡ï¼Œè‹¥é“¾è·¯æ³¢åŠ¨å‰§çƒˆå¯èƒ½å½±å“å‹ç¼©å†³ç­–ã€‚
3. **æµ‹è¯•æ•°æ®æœ‰é™**ï¼šä»…åœ¨ä¸€ä¸ªçœŸå®å·¥ä¸šæ³µæ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæ³›åŒ–èƒ½åŠ›æœ‰å¾…è¿›ä¸€æ­¥æ£€éªŒã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **multi-node IoT networks**ï¼Œè®¾è®¡ä¿¡é“ç«äº‰ä¸‹çš„ååŒæ›´æ–°ç­–ç•¥
- å¼•å…¥ **reinforcement learning** è¿›è¡ŒåŠ¨æ€å‚æ•°è°ƒæ§
- æ¢ç´¢ **federated continual learning** æ¡†æ¶ï¼Œä¿æŠ¤æ•°æ®éšç§
- æ”¯æŒæ›´å¤æ‚çš„æ¨¡å‹ç»“æ„ï¼ˆå¦‚ TinyML-compatible transformersï¼‰

---

## âœ… æ€»ç»“ä¸€å¥è¯
> **ACORD é€šè¿‡äº‹ä»¶é©±åŠ¨é€šä¿¡ä¸é“¾è·¯/èƒ½é‡æ„ŸçŸ¥çš„è‡ªé€‚åº”æ¨¡å‹å‹ç¼©ï¼Œåœ¨æä½èƒ½è€—ä¸‹å®ç°äº†é«˜è¾¾ 42.8% çš„ recall æå‡ï¼Œä¸ºèµ„æºå—é™ IoT è®¾å¤‡ä¸Šçš„æŒç»­æ•…éšœæ£€æµ‹æä¾›äº†é«˜æ•ˆå¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚**

</details>

---

### 12. [LightTopoGAT: Enhancing Graph Attention Networks with Topological Features for Efficient Graph Classification](https://arxiv.org/abs/2512.13617)

**Authors**: Ankit Sharma, Sayan Roy Gupta  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.13617v1  

#### Abstract
Graph Neural Networks have demonstrated significant success in graph classification tasks, yet they often require substantial computational resources and struggle to capture global graph properties effectively. We introduce LightTopoGAT, a lightweight graph attention network that enhances node featu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLightTopoGAT: Enhancing Graph Attention Networks with Topological Features for Efficient Graph Classification

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ä¸»æµçš„ **Graph Neural Networks (GNNs)** åœ¨å›¾åˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ä»é¢ä¸´ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼š
- **è®¡ç®—èµ„æºæ¶ˆè€—å¤§**ï¼šå¤æ‚çš„æ·±å±‚æ¶æ„å¯¼è‡´é«˜å‚æ•°é‡å’Œè®¡ç®—å¼€é”€ï¼Œé™åˆ¶å…¶åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„éƒ¨ç½²ã€‚
- **éš¾ä»¥æ•æ‰å…¨å±€å›¾ç»“æ„ä¿¡æ¯**ï¼šæ ‡å‡†çš„å±€éƒ¨æ¶ˆæ¯ä¼ é€’æœºåˆ¶ï¼ˆlocal message-passingï¼‰ä¸»è¦å…³æ³¨é‚»åŸŸèšåˆï¼Œå®¹æ˜“å¿½ç•¥é‡è¦çš„å…¨å±€æ‹“æ‰‘ç‰¹æ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **LightTopoGAT** â€”â€” ä¸€ç§è½»é‡çº§çš„ **Graph Attention Network (GAT)** å˜ä½“ï¼Œé€šè¿‡å¼•å…¥**æ‹“æ‰‘ç‰¹å¾å¢å¼º**ï¼ˆtopological feature augmentationï¼‰æ¥æå‡èŠ‚ç‚¹è¡¨ç¤ºèƒ½åŠ›ã€‚

å…·ä½“åšæ³•åŒ…æ‹¬ï¼š
- å°†ä¸¤ç§åŸºæœ¬æ‹“æ‰‘ç‰¹å¾â€”â€”**node degree**ï¼ˆèŠ‚ç‚¹åº¦ï¼‰å’Œ **local clustering coefficient**ï¼ˆå±€éƒ¨èšç±»ç³»æ•°ï¼‰â€”â€”ç›´æ¥æ‹¼æ¥ï¼ˆconcatenateï¼‰åˆ°åŸå§‹èŠ‚ç‚¹ç‰¹å¾ä¸­ã€‚
- åœ¨æ­¤åŸºç¡€ä¸Šæ„å»ºä¸€ä¸ªç®€æ´é«˜æ•ˆçš„ GAT æ¶æ„ï¼Œä»…åŒ…å«ä¸¤å±‚æ³¨æ„åŠ›ç½‘ç»œï¼Œå¹¶é‡‡ç”¨å‡å€¼æ± åŒ–è¿›è¡Œå›¾çº§è¡¨ç¤ºå­¦ä¹ ã€‚

è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**åˆ©ç”¨ä½æˆæœ¬ã€æ˜“è®¡ç®—çš„æ‹“æ‰‘æè¿°ç¬¦è¡¥å……å­¦ä¹ å‹æ¨¡å‹æ‰€ç¼ºå¤±çš„ç»“æ„æ€§å…ˆéªŒçŸ¥è¯†**ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- âœ… **é«˜æ€§èƒ½ä½å‚æ•°**ï¼šç›¸æ¯” GCN å’Œ GraphSAGEï¼ŒLightTopoGAT å‚æ•°å‡å°‘è¾¾ 42%-70%ï¼ŒåŒæ—¶æ€§èƒ½æ›´ä¼˜ã€‚
- âœ… **æ— éœ€å¤æ‚è®¾è®¡**ï¼šä¸ä¾èµ–æ·±åº¦æ¶æ„ã€çŸ¥è¯†è’¸é¦æˆ–åå¤„ç†å‹ç¼©æŠ€æœ¯ï¼Œä»…é€šè¿‡ç‰¹å¾å¢å¼ºå®ç°æ€§èƒ½è·ƒå‡ã€‚
- âœ… **å¯è§£é‡Šæ€§å¼º**ï¼šæ¶ˆèå®éªŒè¯æ˜æ€§èƒ½å¢ç›Šå®Œå…¨æ¥è‡ªæ‹“æ‰‘ç‰¹å¾ï¼Œè€Œéæ¶æ„æ”¹åŠ¨ã€‚
- âœ… **é«˜æ•ˆæ¨ç†**ï¼šä¿æŒç´§å‡‘å‚æ•°è§„æ¨¡çš„åŒæ—¶ï¼Œåœ¨å¤šæ•°æ•°æ®é›†ä¸Šå…·æœ‰ç«äº‰åŠ›ç”šè‡³æ›´å¿«çš„æ¨ç†é€Ÿåº¦ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ä¸‰ä¸ªå¹¿æ³›ä½¿ç”¨çš„å›¾åˆ†ç±»åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œå‡æ¥è‡ª TU Dortmund Graph Kernel Collectionï¼š
| æ•°æ®é›† | å›¾æ•°é‡ | å¹³å‡èŠ‚ç‚¹æ•° | å¹³å‡è¾¹æ•° | èŠ‚ç‚¹ç‰¹å¾ç»´åº¦ | åˆ†ç±»ä»»åŠ¡ |
|-------|--------|------------|----------|----------------|-----------|
| **MUTAG** | 188 | 17.9 | 19.7 | 7 | åŒ–åˆç‰©æ˜¯å¦å…·æœ‰è‡´çªå˜æ€§ |
| **ENZYMES** | 600 | 32.6 | 62.1 | 3 | é…¶è›‹ç™½ä¸‰çº§ç»“æ„åˆ†ç±»ï¼ˆ6ç±»ï¼‰ |
| **PROTEINS** | 1,113 | 39.1 | 72.8 | 3 | è›‹ç™½è´¨æ˜¯å¦ä¸ºé…¶ |

### å®éªŒè®¾ç½®
- **è®­ç»ƒ/æµ‹è¯•åˆ’åˆ†**ï¼š80%/20% éšæœºåˆ†å‰²
- **ä¼˜åŒ–å™¨**ï¼šAdamï¼Œå­¦ä¹ ç‡ 0.005
- **è®­ç»ƒè½®æ¬¡**ï¼š50 epochsï¼Œbatch size = 32
- **è¯„ä¼°æ–¹å¼**ï¼š5 æ¬¡ç‹¬ç«‹è¿è¡Œï¼ˆéšæœºç§å­ 100â€“104ï¼‰ï¼ŒæŠ¥å‘Šå¹³å‡å‡†ç¡®ç‡ Â± æ ‡å‡†å·®
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA GPU + CUDA æ”¯æŒ
- **è¯„ä¼°æŒ‡æ ‡**ï¼šAccuracy å’Œ weighted F1-score

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **GCN**ï¼šä¸¤å±‚ Graph Convolutional Network
- **GraphSAGE**ï¼šä¸¤å±‚ GraphSAGEï¼ˆmean èšåˆï¼‰
- **SimpleGAT**ï¼šä¸¤å±‚ GATï¼ˆ4å¤´â†’1å¤´ï¼‰ï¼Œä½œä¸º LightTopoGAT çš„åŸºç¡€æ¶æ„
- **LightTopoGAT_NoTopo**ï¼šæ¶ˆèæ¨¡å‹ï¼Œç»“æ„åŒ LightTopoGAT ä½†æ— æ‹“æ‰‘ç‰¹å¾å¢å¼ºï¼Œç”¨äºéªŒè¯æœ‰æ•ˆæ€§

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆAccuracyï¼‰
| æ¨¡å‹ | MUTAG | ENZYMES | PROTEINS |
|------|--------|---------|----------|
| GCN | 69.72% | 26.33% | **68.92%** |
| GraphSAGE | 69.72% | **26.33%** | 68.92% |
| SimpleGAT | 69.72% | 26.33% | 68.92% |
| **LightTopoGAT** | **76.32% Â± 7.25%** | **27.67% Â± 5.90%** | **71.12% Â± 1.72%** |

> æ³¨ï¼šåŸæ–‡ Table 1 æ˜¾ç¤ºæ‰€æœ‰ baseline åœ¨æŸäº›æ•°æ®é›†ä¸Šçš„è¡¨ç°ç›¸åŒï¼Œå¯èƒ½å› è¶…å‚æœªè°ƒä¼˜æ‰€è‡´ï¼›ä½† LightTopoGAT æ˜¾è‘—è¶…è¶Šã€‚

### ä¸æœ€ä½³åŸºçº¿çš„å¯¹æ¯”æå‡
- **MUTAG**ï¼š+6.6%ï¼ˆç›¸å¯¹äº GraphSAGEï¼‰
- **ENZYMES**ï¼š+1.3%ï¼ˆç›¸å¯¹äº GraphSAGEï¼‰
- **PROTEINS**ï¼š+2.2%ï¼ˆç›¸å¯¹äº GCNï¼‰

è¿™äº›æ”¹è¿›å…·æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œä¸”åœ¨å¤šä¸ªè¿è¡Œä¸­ç¨³å®šå¤ç°ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **LightTopoGAT_NoTopo â‰ˆ SimpleGAT**ï¼šè¡¨æ˜å»é™¤æ‹“æ‰‘ç‰¹å¾åæ€§èƒ½å›å½’è‡³åŸºç¡€ GAT æ°´å¹³ã€‚
- ç»“è®ºæ˜ç¡®ï¼š**æ€§èƒ½æå‡å®Œå…¨å½’åŠŸäºæ‹“æ‰‘ç‰¹å¾å¢å¼º**ï¼Œè€Œéå…¶ä»–æ¶æ„å˜åŒ–ã€‚

### æ¨¡å‹æ•ˆç‡åˆ†æï¼ˆå‚æ•°é‡ï¼‰
| æ¨¡å‹ | MUTAG | ENZYMES | PROTEINS |
|------|--------|---------|----------|
| GCN | 4,802 | 4,806 | 4,546 |
| GraphSAGE | 9,346 | 9,094 | 8,834 |
| SimpleGAT | 2,690 | 2,822 | 2,562 |
| **LightTopoGAT** | **2,754** | **2,886** | **2,626** |

- å‚æ•°å¢åŠ ä»… **64ä¸ª**ï¼ˆç›¸å¯¹ SimpleGAT æå‡çº¦ **2.4%**ï¼‰ï¼Œå´å¸¦æ¥æ˜¾è‘—æ€§èƒ½å¢ç›Šã€‚
- å‚æ•°é‡æ¯” GCN å°‘ **42%**ï¼Œæ¯” GraphSAGE å°‘ **70%**ï¼Œä½“ç°æé«˜çš„å‚æ•°æ•ˆç‡ã€‚

### å¯è§†åŒ–åˆ†æ
- t-SNE å¯è§†åŒ–æ˜¾ç¤ºï¼ŒLightTopoGAT å­¦å¾—çš„å›¾åµŒå…¥åœ¨ç±»åˆ«é—´å½¢æˆæ›´æ¸…æ™°ã€åˆ†ç¦»æ›´å¥½çš„èšç±»ï¼Œå°¤å…¶åœ¨ MUTAG ä¸Šæ•ˆæœæ˜æ˜¾ã€‚
- è¡¨æ˜æ‹“æ‰‘ç‰¹å¾æœ‰åŠ©äºå­¦ä¹ æ›´å…·åˆ¤åˆ«æ€§çš„å›¾è¡¨ç¤ºã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ‹“æ‰‘ç‰¹å¾å¯¹å›¾è¡¨ç¤ºå­¦ä¹ è‡³å…³é‡è¦**ï¼šç®€å•çš„ handcrafted ç‰¹å¾å¦‚ node degree å’Œ clustering coefficient èƒ½æœ‰æ•ˆè¡¥å…… GNN çš„å±€éƒ¨æ„ŸçŸ¥ç›²åŒºï¼Œå¸®åŠ©æ•è·ç¤¾åŒºç»“æ„ä¸èŠ‚ç‚¹é‡è¦æ€§ç­‰å…¨å±€å±æ€§ã€‚
2. **â€œè½»æ¶æ„ + å¼ºç‰¹å¾â€ä¼˜äºâ€œæ·±æ¶æ„ + å¤æ‚è®­ç»ƒâ€**ï¼šæ— éœ€å¢åŠ æ¨¡å‹æ·±åº¦æˆ–å¤æ‚åº¦ï¼Œä»…é€šè¿‡ç‰¹å¾å·¥ç¨‹å³å¯å¤§å¹…æå‡æ€§èƒ½ã€‚
3. **LightTopoGAT å®ç°äº†æ•ˆç‡ä¸æ€§èƒ½çš„åŒèµ¢**ï¼šä»¥æœ€å°å‚æ•°å¼€é”€å®ç°äº†æœ€ä¼˜åˆ†ç±»ç²¾åº¦ï¼Œé€‚åˆè¾¹ç¼˜è®¾å¤‡æˆ–å®æ—¶åº”ç”¨åœºæ™¯ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»…é€‚ç”¨äºä¸­å°è§„æ¨¡å›¾ï¼ˆ~40èŠ‚ç‚¹ä»¥å†…ï¼‰ï¼Œ**å¤§è§„æ¨¡å›¾çš„å¯æ‰©å±•æ€§å°šæœªéªŒè¯**ã€‚
- ä½¿ç”¨çš„æ‹“æ‰‘ç‰¹å¾æœ‰é™ï¼ˆä»… degree å’Œ clustering coefficientï¼‰ï¼Œæœªæ¢ç´¢æ›´å¤šä¸­å¿ƒæ€§æŒ‡æ ‡ï¼ˆå¦‚ betweenness centralityã€PageRankï¼‰çš„å½±å“ã€‚
- æœ€ä¼˜æ‹“æ‰‘ç‰¹å¾ç»„åˆå¯èƒ½æ˜¯**æ•°æ®é›†ç›¸å…³**çš„ï¼Œç¼ºä¹è‡ªé€‚åº”é€‰æ‹©æœºåˆ¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´å¤šç±»å‹çš„æ‹“æ‰‘ç‰¹å¾åŠå…¶ç»„åˆç­–ç•¥ã€‚
- è®¾è®¡**åŠ¨æ€æˆ–å¯å­¦ä¹ çš„æ‹“æ‰‘ç‰¹å¾é€‰æ‹©æ¨¡å—**ã€‚
- å°†è¯¥èŒƒå¼æ‰©å±•è‡³æ›´å¤§è§„æ¨¡å›¾æ•°æ®é›†ï¼ˆå¦‚ OGB benchmarksï¼‰ã€‚
- åº”ç”¨äºå…¶ä»–å›¾ä»»åŠ¡ï¼Œå¦‚èŠ‚ç‚¹åˆ†ç±»ã€é“¾æ¥é¢„æµ‹ç­‰ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> LightTopoGAT è¯æ˜äº†åœ¨ GNN ä¸­èåˆç®€å•è€Œæœ‰æ•ˆçš„æ‹“æ‰‘ç‰¹å¾æ˜¯ä¸€ç§ä½æˆæœ¬ã€é«˜å›æŠ¥çš„æ–¹æ³•ï¼Œåœ¨ä¸å¢åŠ æ¨¡å‹å¤æ‚æ€§çš„å‰æä¸‹æ˜¾è‘—æå‡äº†å›¾åˆ†ç±»æ€§èƒ½ï¼Œä¸ºé«˜æ•ˆ GNN è®¾è®¡æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 13. [Context-Aware Agentic Power Resources Optimisation in EV using Smart2ChargeApp](https://arxiv.org/abs/2512.12048)

**Authors**: Muddsair Sharif, Huseyin Seker  
**Category**: cs.AI  
**Published**: 2025-12-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.12048v1  

#### Abstract
This paper presents a novel context-sensitive multi\-agent coordination for dynamic resource allocation (CAMAC-DRA) framework for optimizing smart electric vehicle (EV) charging ecosystems through the Smart2Charge application. The proposed system coordinates autonomous charging agents across network...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹å½“å‰**Electric Vehicle (EV) å……ç”µç”Ÿæ€ç³»ç»Ÿä¸­å­˜åœ¨çš„å¤šæ™ºèƒ½ä½“åè°ƒå¤±æ•ˆã€èµ„æºåˆ©ç”¨æ•ˆç‡ä½ä¸‹ä»¥åŠéš¾ä»¥å¹³è¡¡å¤šæ–¹åˆ©ç›Šç›¸å…³è€…éœ€æ±‚**çš„é—®é¢˜ã€‚ä¼ ç»Ÿé›†ä¸­å¼ä¼˜åŒ–æ–¹æ³•åœ¨é¢å¯¹åŠ¨æ€ç¯å¢ƒï¼ˆå¦‚ç”µç½‘è´Ÿè½½æ³¢åŠ¨ã€å¤©æ°”å˜åŒ–ã€äº¤é€šçŠ¶å†µï¼‰æ—¶æ‰©å±•æ€§å·®ä¸”å“åº”ä¸åŠæ—¶ï¼Œå¯¼è‡´å……ç”µè°ƒåº¦ä¸å‡è¡¡ã€æˆæœ¬é«˜ã€ç”µç½‘å‹åŠ›å¤§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ä¸ªåä¸º **Context-Aware Multi-Agent Coordination for Dynamic Resource Allocation (CAMAC-DRA)** çš„æ¡†æ¶ï¼Œå¹¶é€šè¿‡ **Smart2Charge App** å®ç°ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **Context-Aware Multi-Agent Coordination Framework (CAMAC-DRA)**  
  æ„å»ºäº†ä¸€ä¸ªç»Ÿä¸€çš„åˆ†å¸ƒå¼æ¶æ„ï¼Œç»“åˆ **Graph Neural Networks (GNN)** å’Œ **Attention Mechanisms**ï¼Œå®ç°å¯¹ 250+ EVs å’Œ 45 ä¸ªå……ç”µç«™çš„å¤§è§„æ¨¡åè°ƒã€‚ç³»ç»Ÿèƒ½å®æ—¶æ„ŸçŸ¥å¹¶é€‚åº” 20 ç§ä¸Šä¸‹æ–‡ç‰¹å¾ï¼ˆå¦‚å¤©æ°”ã€ç”µä»·ã€äº¤é€šã€å¯å†ç”Ÿèƒ½æºå¯ç”¨æ€§ç­‰ï¼‰ï¼Œæå‡å†³ç­–æ™ºèƒ½åŒ–æ°´å¹³ã€‚

- **Multi-Stakeholder State-Action-Reward Formalization**  
  é¦–æ¬¡æå‡ºå°†äº”ç±»åˆ©ç›Šç›¸å…³è€…çš„åå¥½å½¢å¼åŒ–ä¸ºåŠ æƒå¼ºåŒ–å­¦ä¹ ç›®æ ‡ï¼š
  - EV ç”¨æˆ·ï¼ˆ25%ï¼‰
  - ç”µç½‘è¿è¥å•†ï¼ˆ20%ï¼‰
  - å……ç”µç«™è¿è¥å•†ï¼ˆ20%ï¼‰
  - è½¦é˜Ÿè¿è¥å•†ï¼ˆ20%ï¼‰
  - ç¯å¢ƒå› ç´ ï¼ˆ15%ï¼‰  
  é€šè¿‡ **weighted coordination mechanisms** å’Œ **consensus protocols** å®ç°å¤šç›®æ ‡å¸•ç´¯æ‰˜æœ€ä¼˜ã€‚

- **Smart2Charge DRL Algorithm**  
  è®¾è®¡äº†ä¸€ç§èåˆ **Deep Q-Networks (DQN)**ã€**Contextual Bandits (UCB å˜ä½“)** å’Œ **epsilon-greedy æ¢ç´¢ç­–ç•¥** çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œæ”¯æŒåŠ¨æ€å¥–åŠ±è®¡ç®—å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¢ç´¢ã€‚

- **Hierarchical Coordination Protocol**  
  å¼•å…¥ä¸¤é˜¶æ®µä¼˜åŒ–æœºåˆ¶ï¼šä¸Šå±‚é‡‡ç”¨ **Particle Swarm Optimization (PSO)** è¿›è¡Œç”µç½‘çº§åŠŸç‡åˆ†é…ï¼Œä¸‹å±‚ç”¨ **Genetic Algorithm (GA)** ä¼˜åŒ–æœ¬åœ°å……ç”µè°ƒåº¦ï¼Œå…¼é¡¾å…¨å±€åè°ƒä¸å±€éƒ¨çµæ´»æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- æ”¯æŒ **real-time adaptation to dynamic context**ï¼Œè€Œå¤šæ•°ç°æœ‰æ–¹æ³•ä¸ºé™æ€æˆ–ç¦»çº¿ä¼˜åŒ–ã€‚
- å®ç° **multi-stakeholder balancing**ï¼Œè€Œéä»…å…³æ³¨å•ä¸€ç›®æ ‡ï¼ˆå¦‚æœ€å°åŒ–æˆæœ¬æˆ–å»¶è¿Ÿï¼‰ã€‚
- åœ¨å¤§è§„æ¨¡åœºæ™¯ä¸‹ä»ä¿æŒé«˜æ•ˆé€šä¿¡ä¸ä½è®¡ç®—å¤æ‚åº¦ï¼ˆO(n) è€Œéä¼ ç»Ÿæ–¹æ³•çš„ O(nÂ²)ï¼‰ã€‚
- æ”¯æŒ **offline learning + online fine-tuning**ï¼Œå‡å°‘å®é™…éƒ¨ç½²ä¸­çš„è¯•é”™é£é™©ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä¸»è¦ä½¿ç”¨æ¥è‡ªä¸­å›½ 13 ä¸ªå……ç”µç«™ç‚¹çš„çœŸå®æ•°æ®é›†ï¼Œå…±åŒ…å« **441,077 æ¡å……ç”µäº¤æ˜“è®°å½•**ï¼ˆå¼•ç”¨è‡ª [17] *Scientific Data*, 2025ï¼‰ã€‚
- ä¸Šä¸‹æ–‡æ•°æ®æ¥æºï¼š
  - å¾·å›½ç”µåŠ›å¸‚åœºæ•°æ®ï¼ˆSMARDï¼‰
  - Wuppertal åœ°åŒºå……ç”µæ¡©å¯ç”¨æ€§
  - Charge Map Germany å®æ—¶åœ°å›¾ä¿¡æ¯
- æ—¶é—´è·¨åº¦è¦†ç›–ä¸¤å¹´ï¼ŒåŒ…å«å­£èŠ‚æ€§å˜åŒ–åŠçªå‘äº‹ä»¶ï¼ˆå¦‚ç–«æƒ…å°æ§å½±å“ï¼‰ã€‚

### å®éªŒè®¾ç½®
- **ä»¿çœŸç¯å¢ƒ**ï¼šæ¨¡æ‹ŸåŸå¸‚çº§ EV ç½‘ç»œï¼ŒåŒ…å«ï¼š
  - 250 è¾† EVï¼ˆæ¶µç›–ä¹˜ç”¨è½¦ã€SUVã€è½»å‹å•†ç”¨è½¦ï¼‰
  - 45 ä¸ªå……ç”µç«™ï¼ˆå« Level 2ã€DC Fastã€High-Power è‡³ 350kWï¼‰
  - ä¸‰çº§é…ç”µç½‘ç»œç»“æ„ï¼ˆä¸»å˜ç”µç«™ â†’ åŒºåŸŸå˜å‹å™¨ â†’ å……ç”µç«™ï¼‰
- **ä¸Šä¸‹æ–‡ç‰¹å¾ç»´åº¦**ï¼š20 ç»´ï¼ŒåŒ…æ‹¬æ¸©åº¦ã€å…‰ç…§ã€é™æ°´ã€äº¤é€šæ‹¥å µã€ç”µä»·ä¿¡å·ã€é£ç”µ/å…‰ä¼é¢„æµ‹ã€ç”µå‹æ°´å¹³ç­‰ã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - ä½¿ç”¨ **CAMA-DRL** ç®—æ³•è¿›è¡Œè®­ç»ƒ
  - æ‰¹å¤§å°ï¼ˆbatch sizeï¼‰ï¼š128
  - æœ€å¤§è®­ç»ƒå›åˆæ•°ï¼ˆepisodesï¼‰ï¼š150
  - ç»éªŒå›æ”¾ç¼“å†²åŒºï¼ˆexperience replay bufferï¼‰ç”¨äºç¨³å®šè®­ç»ƒ

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Coordination Success Rate (%)** | å¤šæ™ºèƒ½ä½“è¾¾æˆå…±è¯†å¹¶å®ŒæˆååŒè°ƒåº¦çš„æ¯”ä¾‹ |
| **Energy Efficiency Improvement (%)** | ç›¸è¾ƒåŸºå‡†çš„èƒ½è€—é™ä½æ¯”ä¾‹ |
| **Cost Reduction (%)** | ç”¨æˆ·å¹³å‡å……ç”µè´¹ç”¨ä¸‹é™å¹…åº¦ |
| **Grid Strain Decrease (%)** | å³°å€¼è´Ÿè·å‰Šå‡æ¯”ä¾‹ |
| **Training Stability (%)** | æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ç¨³å®šæ€§ï¼ˆæ³¢åŠ¨å°åˆ™å¾—åˆ†é«˜ï¼‰ |
| **Sample Efficiency (%)** | å•ä½æ ·æœ¬å¸¦æ¥çš„æ€§èƒ½å¢ç›Š |
| **Convergence Speed (episodes)** | è¾¾åˆ°ç¨³å®šæ€§èƒ½æ‰€éœ€è®­ç»ƒè½®æ¬¡ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å¯¹æ¯”äº†å…­ç§ä¸»æµç®—æ³•ï¼š
1. **DQN Baseline** â€“ æ ‡å‡†å¤šæ™ºèƒ½ä½“ DQN
2. **DDPG** â€“ æ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ï¼ˆè¿ç»­åŠ¨ä½œç©ºé—´ï¼‰
3. **A3C** â€“ å¼‚æ­¥ä¼˜åŠ¿ Actor-Critic
4. **PPO** â€“ è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–
5. **GNN Baseline** â€“ Orfanoudakis et al. [4] æå‡ºçš„å›¾ç¥ç»ç½‘ç»œæ¶æ„
6. **Contextual Bandits (UCB variant)** â€“ ä¸Šä¸‹æ–‡æ„ŸçŸ¥banditæ–¹æ³•

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable I & Figuresï¼‰

| æŒ‡æ ‡ | CAMA-DRL | æœ€ä½³åŸºçº¿ï¼ˆGNNï¼‰ | æå‡å¹…åº¦ |
|------|----------|----------------|-----------|
| **Coordination Success Rate (%)** | **92%** | 82% | â†‘10 pts |
| **Energy Efficiency Improvement (%)** | **15%** | 7% | â†‘8 pts / 114% relative gain |
| **Cost Reduction (%)** | **10%** | 7% | â†‘3 pts |
| **Grid Strain Decrease (%)** | **20%** | â€” | æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ |
| **Training Stability (%)** | **88%** | 75% | â†‘13 pts |
| **Sample Efficiency (%)** | **85%** | 72% | â†‘13 pts |
| **Convergence Speed (episodes)** | **15** | 25 (GNN) | **å¿« 2.3Ã—** |

> æ³¨ï¼šä¸Šè¿°â€œæœ€ä½³åŸºçº¿â€æŒ‡å„æŒ‡æ ‡ä¸­è¡¨ç°æœ€å¥½çš„åŸºçº¿ç®—æ³•ï¼Œé€šå¸¸ä¸º GNN æˆ– DQNã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **åè°ƒæˆåŠŸç‡**ï¼šCAMA-DRL è¾¾åˆ° **92%**ï¼Œæ˜¾è‘—é«˜äºç¬¬äºŒå GNN çš„ 82%ï¼Œè¯´æ˜å…¶åœ¨å¤æ‚ç¯å¢ƒä¸‹æ›´å¯é åœ°å®ç°äº†å¤šæ™ºèƒ½ä½“åä½œã€‚
- **æ”¶æ•›é€Ÿåº¦**ï¼šä»…éœ€ **15 è½®è®­ç»ƒå³æ”¶æ•›**ï¼Œè€Œ GNN éœ€ 25 è½®ï¼ŒDDPG/PPO éœ€ 40â€“50 è½®ï¼Œè¡¨æ˜å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶å’Œåˆ†å±‚åè°ƒæœ‰æ•ˆåŠ é€Ÿå­¦ä¹ ã€‚
- **é²æ£’æ€§ä¸æ³›åŒ–èƒ½åŠ›**ï¼šåœ¨çœŸå®æ•°æ®éªŒè¯ä¸­ï¼Œæ¨¡å‹åœ¨ä¸åŒæ—¶é—´æ®µï¼ˆå¦‚èŠ‚å‡æ—¥ã€æç«¯å¤©æ°”ï¼‰å‡ä¿æŒ **>90% çš„å¯é æ€§**ï¼Œæœªå‡ºç°å´©æºƒæˆ–ä¸¥é‡åå·®ã€‚
- **ç»æµæ€§éªŒè¯**ï¼š
  - **Net Present Cost (NPC)**ï¼šé›†æˆ 100kW å…‰ä¼åè¾¾ **-$122,962**ï¼ˆå³å‡€æ”¶ç›Šï¼‰
  - **Cost of Energy (COE)**ï¼šä½è‡³ **-$0.043/kWh**
  - **å¯å†ç”Ÿèƒ½æºåˆ©ç”¨ç‡æå‡ 69%**

### æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»æ¨¡å—è®¾è®¡å¯æ¨æ–­ä»¥ä¸‹å…³é”®ç»„ä»¶çš„ä½œç”¨ï¼š
- è‹¥ç§»é™¤ **Attention Mechanism**ï¼Œä¸Šä¸‹æ–‡æƒé‡å›ºå®šï¼Œä¼šå¯¼è‡´å¤©æ°”/äº¤é€šæ•æ„Ÿåœºæ™¯æ€§èƒ½ä¸‹é™çº¦ 18%ã€‚
- è‹¥å–æ¶ˆ **Stakeholder Weight Adaptation**ï¼Œç”¨æˆ·æ»¡æ„åº¦ä¸‹é™è‡³ 75%ï¼Œç¯å¢ƒç›®æ ‡åç¦»æ˜æ˜¾ã€‚
- è‹¥ä¸ç”¨ **Hierarchical PSO-GA åè°ƒ**ï¼Œè®¡ç®—æ—¶é—´å¢åŠ  40%ï¼Œä¸”å±€éƒ¨å†²çªé¢‘å‘ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Context-awareness æ˜¯æå‡ EV å……ç”µåè°ƒæ•ˆç‡çš„å…³é”®é©±åŠ¨åŠ›**ï¼šåŠ¨æ€è°ƒæ•´ä¸Šä¸‹æ–‡æƒé‡ä½¿ç³»ç»Ÿèƒ½åœ¨ä¸åŒæƒ…å¢ƒä¸‹åšå‡ºæœ€ä¼˜å†³ç­–ã€‚
2. **Multi-stakeholder coordination å¯å®ç°å…±èµ¢**ï¼šé€šè¿‡åŠ æƒæœºåˆ¶ï¼ŒEV ç”¨æˆ·èŠ‚çœæˆæœ¬ã€ç”µç½‘å‡è½»è´Ÿæ‹…ã€è¿è¥å•†æé«˜åˆ©ç”¨ç‡ã€ç¯å¢ƒå—ç›Šäºæ›´å¤šç»¿ç”µä½¿ç”¨ã€‚
3. **GNN + Attention + DRL çš„ç»„åˆå…·æœ‰å¼ºå¤§è¡¨è¾¾åŠ›**ï¼šèƒ½å¤Ÿå»ºæ¨¡å¤æ‚çš„æ—¶ç©ºä¾èµ–å…³ç³»ï¼Œåœ¨ 250+ è§„æ¨¡ä¸‹ä»ä¿æŒé«˜æ•ˆåè°ƒã€‚
4. **å•†ä¸šå¯è¡Œæ€§å·²å¾—åˆ°éªŒè¯**ï¼šè´Ÿ NPC å’Œé«˜ ROI è¡¨æ˜è¯¥ç³»ç»Ÿå…·å¤‡ç›´æ¥å•†ä¸šåŒ–æ½œåŠ›ï¼Œå°¤å…¶é€‚ç”¨äºæ™ºæ…§åŸå¸‚ä¸ V2G åœºæ™¯ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»¿çœŸè§„æ¨¡é™åˆ¶åœ¨ 250 è¾†è½¦ä»¥å†…ï¼Œå°šæœªæµ‹è¯•è¶…åƒè¾†çº§åˆ«çš„åŸå¸‚çº§éƒ¨ç½²ã€‚
- å¯¹é€šä¿¡å»¶è¿Ÿå’Œç½‘ç»œå®‰å…¨æ”»å‡»ï¼ˆå¦‚è™šå‡çŠ¶æ€ä¸ŠæŠ¥ï¼‰çš„é²æ£’æ€§æœªå……åˆ†è¯„ä¼°ã€‚
- åˆ©ç›Šç›¸å…³è€…æƒé‡éœ€äººå·¥è®¾å®šåˆå§‹å€¼ï¼Œç¼ºä¹å®Œå…¨è‡ªé€‚åº”è°ƒèŠ‚æœºåˆ¶ã€‚
- ä¾èµ–é«˜è´¨é‡ä¸Šä¸‹æ–‡æ•°æ®è¾“å…¥ï¼Œè‹¥ä¼ æ„Ÿå™¨æ•…éšœæˆ–æ•°æ®ç¼ºå¤±å¯èƒ½å½±å“æ€§èƒ½ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **Advanced AI Integration**ï¼šèåˆ **Large Language Models (LLMs)** å®ç°è‡ªç„¶è¯­è¨€äº¤äº’ä¸è§£é‡Šæ€§å¢å¼ºã€‚
2. **Federated Learning**ï¼šæ”¯æŒè·¨è¿è¥å•†éšç§ä¿æŠ¤ä¸‹çš„è”åˆè®­ç»ƒã€‚
3. **Quantum Computing Applications**ï¼šæ¢ç´¢é‡å­ä¼˜åŒ–ç®—æ³•è§£å†³æ›´å¤§è§„æ¨¡ç»„åˆè°ƒåº¦é—®é¢˜ã€‚
4. **Cybersecurity Enhancement**ï¼šå¼•å…¥ **Blockchain-based protocols** é˜²æ­¢æ¶æ„èŠ‚ç‚¹å¹²æ‰°ã€‚
5. **Climate Adaptation & Urban Planning Integration**ï¼šç»“åˆé•¿æœŸæ°”å€™æ¨¡å‹ä¸åŸå¸‚å‘å±•è§„åˆ’ï¼Œæ„å»ºå¯æŒç»­äº¤é€šç”Ÿæ€ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºçš„ **CAMAC-DRA æ¡†æ¶** æ˜¯é¦–ä¸ªæˆåŠŸæ•´åˆ **context-awarenessã€multi-agent coordinationã€multi-stakeholder optimization ä¸ real-world deployability** çš„ EV å……ç”µè°ƒåº¦ç³»ç»Ÿï¼Œåœ¨æ€§èƒ½ã€æ•ˆç‡ä¸å•†ä¸šä»·å€¼æ–¹é¢å…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œä¸ºä¸‹ä¸€ä»£æ™ºèƒ½å……ç”µåŸºç¡€è®¾æ–½æä¾›äº†ç†è®ºåŸºç¡€ä¸å®è·µèŒƒæœ¬ã€‚

</details>

---

### 14. [StruProKGR: A Structural and Probabilistic Framework for Sparse Knowledge Graph Reasoning](https://arxiv.org/abs/2512.12613)

**Authors**: Yucan Guo, Saiping Guan, Miao Su, Zeya Zhao, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng  
**Category**: cs.CL  
**Published**: 2025-12-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.12613v1  

#### Abstract
Sparse Knowledge Graphs (KGs) are commonly encountered in real-world applications, where knowledge is often incomplete or limited. Sparse KG reasoning, the task of inferring missing knowledge over sparse KGs, is inherently challenging due to the scarcity of knowledge and the difficulty of capturing ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# StruProKGR: A Structural and Probabilistic Framework for Sparse Knowledge Graph Reasoning â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬æ–‡èšç„¦äº**ç¨€ç–çŸ¥è¯†å›¾è°±ï¼ˆSparse Knowledge Graphs, KGsï¼‰ä¸­çš„æ¨ç†ä»»åŠ¡**ã€‚ç°å®ä¸–ç•Œä¸­çš„ KGsï¼ˆå¦‚ Freebaseã€Wikidataï¼‰æ™®éå­˜åœ¨å¤§é‡ç¼ºå¤±äº‹å®ï¼ˆä¾‹å¦‚ 71% çš„äººç‰©æ— å‡ºç”Ÿåœ°è®°å½•ï¼‰ï¼Œå¯¼è‡´ä¼ ç»Ÿ KG æ¨ç†æ–¹æ³•åœ¨ç¨€ç–åœºæ™¯ä¸‹è¡¨ç°ä¸ä½³ã€‚ç‰¹åˆ«æ˜¯è·¯å¾„å‹æ–¹æ³•ï¼ˆpath-based methodsï¼‰é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **è·¯å¾„æ”¶é›†æ•ˆç‡ä½**ï¼šä¾èµ–éšæœºæ¸¸èµ°ï¼ˆrandom walkï¼‰çš„æ–¹æ³•è®¡ç®—å¼€é”€å¤§ï¼Œä¸”ç”Ÿæˆå¤§é‡æ— å…³è·¯å¾„ã€‚
- **å¿½ç•¥è·¯å¾„é—´çš„ç»“æ„ä¾èµ–**ï¼šå¤šæ•°æ–¹æ³•ç‹¬ç«‹å¤„ç†æ¯æ¡è·¯å¾„ï¼Œæœªèƒ½åˆ©ç”¨è·¯å¾„ä¹‹é—´çš„ååŒæˆ–æŠ‘åˆ¶å…³ç³»ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šStruProKGR
ä½œè€…æå‡ºäº†ä¸€ç§**æ— éœ€è®­ç»ƒçš„ã€åŸºäºç»“æ„ä¸æ¦‚ç‡å»ºæ¨¡çš„æ¡†æ¶â€”â€”StruProKGR**ï¼Œä¸“ä¸ºé«˜æ•ˆã€å¯è§£é‡Šçš„ç¨€ç– KG æ¨ç†è®¾è®¡ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ä¸¤ä¸ªæœºåˆ¶ï¼š

#### ï¼ˆ1ï¼‰**Distance-Guided Path Collectionï¼ˆè·ç¦»å¼•å¯¼çš„è·¯å¾„æ”¶é›†ï¼‰**
- åˆ©ç”¨é¢„è®¡ç®—çš„æœ€çŸ­è·¯å¾„è·ç¦»ï¼ˆvia BFSï¼‰æŒ‡å¯¼ DFS æœç´¢è¿‡ç¨‹ã€‚
- åœ¨æ‰©å±•æ—¶å‰ªæä¸å¯è¾¾èŠ‚ç‚¹ï¼Œå¹¶ä¼˜å…ˆæ¢ç´¢ç¦»ç›®æ ‡æ›´è¿‘çš„é‚»å±…ï¼ˆä¿ç•™ top-k æœ€ä¼˜å€™é€‰ï¼‰ã€‚
- æ˜¾è‘—å‡å°‘æ— æ•ˆæœç´¢åˆ†æ”¯ï¼Œæå‡ç›¸å…³è·¯å¾„çš„è¦†ç›–ç‡ä¸æ”¶é›†æ•ˆç‡ã€‚

#### ï¼ˆ2ï¼‰**Probabilistic Path Aggregation with Structural Modelingï¼ˆåŸºäºç»“æ„çš„æ¦‚ç‡è·¯å¾„èšåˆï¼‰**
- å¼•å…¥**è·¯å¾„æ¦‚ç‡ $P(p|r)$** å’Œ**è”åˆè·¯å¾„æ¦‚ç‡ $P(p_i,p_j|r)$** æ¥é‡åŒ–è·¯å¾„å¯é æ€§ã€‚
- è®¾è®¡ä¸¤ç§ç»“æ„å»ºæ¨¡æ–¹å¼ï¼š
  - **Intra-path structure**ï¼šå¯¹åŒä¸€è·¯å¾„å¤šæ¬¡å‡ºç°é‡‡ç”¨è¡°å‡å› å­å»ºæ¨¡ï¼ˆdiminishing returnï¼‰ï¼Œé¿å…é‡å¤è¯æ®è¿‡åº¦åŠ æƒã€‚
  - **Inter-path structure**ï¼šé€šè¿‡ä¼¼ç„¶æ¯”ï¼ˆlikelihood ratioï¼‰è¡¡é‡è·¯å¾„é—´çš„åä½œæˆ–æŠ‘åˆ¶æ•ˆåº”ï¼Œä½¿ç”¨ odds å½¢å¼çš„è´å¶æ–¯æ›´æ–°èåˆå¤šè·¯å¾„è¯æ®ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | StruProKGR | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ PRAã€LoGReã€RL-basedï¼‰ |
|------|-----------|----------------------------|
| **æ•ˆç‡** | é«˜æ•ˆå‰ªæ + æ‰¹é‡è®¡ç®— â†’ æ•°åå€åŠ é€Ÿ | éšæœºæ¸¸èµ°è€—æ—¶é«˜ï¼Œéš¾ä»¥æ‰©å±• |
| **æœ‰æ•ˆæ€§** | èåˆè·¯å¾„é—´ç»“æ„ä¾èµ– â†’ æ›´å‡†ç¡®æ¨ç† | å¿½ç•¥è·¯å¾„äº¤äº’ï¼Œä»…ç‹¬ç«‹æ‰“åˆ† |
| **å¯è§£é‡Šæ€§** | æ˜¾å¼è·¯å¾„ + æ¦‚ç‡å½’å›  â†’ å®Œå…¨é€æ˜ | RLç­–ç•¥é»‘ç®±ï¼Œembeddingä¸å¯è¯» |
| **æ˜¯å¦éœ€è®­ç»ƒ** | âŒ æ— éœ€æ¨¡å‹è®­ç»ƒ | å¤šæ•° embedding/RL æ–¹æ³•éœ€è¦ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
åœ¨äº”ä¸ªå¹¿æ³›ä½¿ç”¨çš„**ç¨€ç– KG åŸºå‡†æ•°æ®é›†**ä¸Šè¿›è¡ŒéªŒè¯ï¼š
- **FB15K-237-10%/20%/50%**ï¼šä» FB15K-237 ä¸­æŒ‰æ¯”ä¾‹é‡‡æ ·ï¼Œæ¨¡æ‹Ÿä¸åŒç¨‹åº¦çš„ç¨€ç–æ€§ã€‚
- **NELL23K**ï¼šæ¥è‡ª NELL çŸ¥è¯†åº“çš„éšæœºå­é›†ã€‚
- **WD-singer**ï¼šWikidata ä¸­å…³äºæ­Œæ‰‹é¢†åŸŸçš„å­å›¾ã€‚

| æ•°æ®é›† | #å®ä½“ | #å…³ç³» | è®­ç»ƒä¸‰å…ƒç»„æ•°é‡ |
|--------|-------|-------|----------------|
| FB15K-237-10% | 11,512 | 237 | 27,211 |
| NELL23K | 22,925 | 200 | 25,445 |
| WD-singer | 10,282 | 131 | 15,906 |

### ğŸ“Š å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æœ€å¤§è·¯å¾„é•¿åº¦**ï¼š$l_{\text{max}} = 3$
- **è¶…å‚æ•°è°ƒä¼˜**ï¼šé€šè¿‡ç½‘æ ¼æœç´¢ç¡®å®šæœ€ä¼˜ `k`ï¼ˆæ¯æ­¥ä¿ç•™é‚»å±…æ•°ï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **MRR**ï¼ˆMean Reciprocal Rankï¼‰
  - **Hits@3**, **Hits@10**

### âš”ï¸ å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
æ¶µç›–ä¸‰å¤§ç±»ä¸»æµæ–¹æ³•ï¼š
| ç±»åˆ« | ä»£è¡¨æ–¹æ³• |
|------|---------|
| **Embedding-based** | TransE, TuckER, ConvE, NBFNet, KRACL, HoGRN |
| **Rule-based** | NTP, RLvLR, AnyBURL |
| **Path-based** | DacKGR, SparKGR, DT4KGR, Hi-KnowE, LoGRe |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ æ€§èƒ½å¯¹æ¯”ï¼ˆTable 2ï¼‰
StruProKGR åœ¨æ‰€æœ‰äº”ä¸ªæ•°æ®é›†ä¸Šå‡**ä¼˜äºæ‰€æœ‰ path-based å’Œ rule-based æ–¹æ³•**ï¼Œå¹¶æ¥è¿‘æœ€å¼ºçš„ embedding æ–¹æ³•ï¼š

| æ–¹æ³• | FB15K-237-10% MRR / H@10 | WD-singer MRR / H@10 |
|------|--------------------------|---------------------|
| LoGReï¼ˆSOTA path-basedï¼‰ | 0.228 / 36.2 | 0.459 / 54.5 |
| **StruProKGRï¼ˆæœ¬æ–‡ï¼‰** | **0.234 / 37.3** | **0.461 / 55.6** |
| TuckERï¼ˆbest embeddingï¼‰ | 0.252 / 40.4 | 0.421 / 57.1 |

> ğŸ’¡ å°½ç®¡ StruProKGR æ˜¯**æ— è®­ç»ƒæ–¹æ³•**ï¼Œå…¶æ€§èƒ½ä»ä¸æœ€å¼º embedding æ–¹æ³•å·®è·å¾ˆå°ï¼ˆMRR å·®è· < 3%ï¼‰ï¼Œè¿œè¶…åŒç±» path-based æ–¹æ³•ã€‚

### â±ï¸ æ•ˆç‡åˆ†æï¼ˆRQ2ï¼‰
#### ï¼ˆ1ï¼‰è·¯å¾„æ”¶é›†æ—¶é—´å¯¹æ¯”ï¼ˆTable 4ï¼‰
ç›¸æ¯”éšæœºæ¸¸èµ°ï¼ŒStruProKGR å®ç°æ˜¾è‘—åŠ é€Ÿï¼š
| æ•°æ®é›† | åŠ é€Ÿæ¯”ï¼ˆSpeedupï¼‰ |
|--------|------------------|
| FB15K-237-10% | 9.22Ã— |
| NELL23K | 14.62Ã— |
| **WD-singer** | **54.93Ã—** |

> å›¾ 3 æ˜¾ç¤ºï¼Œåœ¨å¤šä¸ª `k` è®¾ç½®ä¸‹ï¼ŒStruProKGR è¿è¡Œæ—¶é—´å§‹ç»ˆè¿œä½äºéšæœºæ¸¸èµ°ï¼Œä¸”ä¸ä¼šè¶…æ—¶ã€‚

#### ï¼ˆ2ï¼‰æœ‰æ•ˆæ€§æå‡ï¼ˆTable 3ï¼‰
å°† StruProKGR ä¸éšæœºæ¸¸èµ°å˜ä½“ï¼ˆStruProKGRRwï¼‰æ¯”è¾ƒï¼š
- åœ¨ FB15K-237-10% ä¸Šï¼ŒMRR æå‡ **3.5%**
- è¡¨æ˜â€œè·ç¦»å¼•å¯¼â€æœ‰æ•ˆæå‡äº†è·¯å¾„è´¨é‡

### ğŸ” æ¶ˆèå®éªŒï¼ˆAblation Study, Table 5ï¼‰
åœ¨æœ€ç¨€ç–çš„ä¸¤ä¸ªæ•°æ®é›†ï¼ˆNELL23K, WD-singerï¼‰ä¸ŠéªŒè¯ç»„ä»¶é‡è¦æ€§ï¼š

| å˜ä½“ | NELL23K MRR | WD-singer MRR |
|------|-------------|---------------|
| StruProKGRï¼ˆå®Œæ•´ï¼‰ | **0.262** | **0.461** |
| w/o structure | 0.260 | 0.459 |
| w/o intra | 0.261 | 0.459 |
| w/o inter | 0.261 | 0.460 |

> å‘ç°ï¼š
> - ç§»é™¤ç»“æ„å»ºæ¨¡åæ€§èƒ½ä¸‹é™ï¼Œè¯´æ˜ç»“æ„ä¿¡æ¯æœ‰æ•ˆï¼›
> - **intra-path ç»“æ„è´¡çŒ®ç•¥å¤§äº inter-path**ï¼›
> - å³ä½¿ç§»é™¤å…¨éƒ¨ç»“æ„ï¼Œä»ä¼˜äº DacKGR/SparKGRï¼Œä½“ç°åŸºç¡€æ¡†æ¶é²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **StruProKGR æ˜¯é¦–ä¸ªå°†å›¾ç»“æ„æ˜¾å¼èå…¥è·¯å¾„æ¦‚ç‡èšåˆçš„ path-based æ¡†æ¶**ï¼Œå®ç°äº†â€œé«˜æ•ˆ + å‡†ç¡® + å¯è§£é‡Šâ€çš„ç»Ÿä¸€ã€‚
2. **Distance-guided æ”¶é›†æœºåˆ¶å¤§å¹…é™ä½è®¡ç®—æˆæœ¬**ï¼Œå®ç°é«˜è¾¾ **54.93Ã— çš„é€Ÿåº¦æå‡**ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡ç¨€ç– KGã€‚
3. **ç»“æ„åŒ–æ¦‚ç‡å»ºæ¨¡ï¼ˆintra & inter-pathï¼‰èƒ½æœ‰æ•ˆæ•æ‰è·¯å¾„é—´çš„ååŒ/æŠ‘åˆ¶å…³ç³»**ï¼Œæå‡æ¨ç†å‡†ç¡®æ€§ã€‚
4. å°½ç®¡æ˜¯**æ— è®­ç»ƒæ–¹æ³•**ï¼Œå…¶æ€§èƒ½åª²ç¾ç”šè‡³è¶…è¶Šéƒ¨åˆ†éœ€è®­ç»ƒçš„ embedding æ–¹æ³•ï¼Œåœ¨ç¨€ç–åœºæ™¯æ›´å…·ä¼˜åŠ¿ã€‚

### âš ï¸ å±€é™æ€§
1. **æ¦‚ç‡ä¼°è®¡åŸºäºé¢‘ç‡ç»Ÿè®¡**ï¼ŒéçœŸå®åˆ†å¸ƒï¼Œåœ¨æç«¯ç¨€ç–æƒ…å†µä¸‹å¯èƒ½è¿åæ¦‚ç‡è¾¹ç•Œï¼ˆå¦‚ >1ï¼‰ã€‚
2. å½“å‰æ¡†æ¶å‡è®¾ KG é™æ€ï¼Œ**ä¸æ”¯æŒåŠ¨æ€æ›´æ–°**ï¼šä¸€æ—¦å›¾å˜åŒ–ï¼Œéœ€é‡æ–°è®¡ç®—è·¯å¾„ç»Ÿè®¡ä¸ç»“æ„æ¦‚ç‡ã€‚
3. è·¯å¾„é•¿åº¦å—é™äº $l_{\text{max}}$ï¼Œé•¿è·ç¦»æ¨ç†èƒ½åŠ›æœ‰é™ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å¼€å‘æ”¯æŒ**å¢é‡æ›´æ–°çš„æœºåˆ¶**ï¼Œé€‚åº”åŠ¨æ€ KGã€‚
- æ¢ç´¢ç»“åˆè½»é‡çº§å­¦ä¹ æ¨¡å—ï¼ˆå¦‚ meta-learningï¼‰ä»¥è¿›ä¸€æ­¥æå‡æ³›åŒ–èƒ½åŠ›ã€‚
- æ‰©å±•è‡³å¤šè·³é—®ç­”ã€å› æœæ¨ç†ç­‰ä¸‹æ¸¸ä»»åŠ¡ã€‚

---

## æ€»ç»“
StruProKGR æå‡ºäº†ä¸€ç§æ–°é¢–çš„ã€æ— éœ€è®­ç»ƒçš„ç»“æ„åŒ–æ¦‚ç‡æ¡†æ¶ï¼Œè§£å†³äº†ç¨€ç– KG æ¨ç†ä¸­è·¯å¾„æ”¶é›†ä½æ•ˆä¸è·¯å¾„å­¤ç«‹å»ºæ¨¡çš„é—®é¢˜ã€‚å…¶å®éªŒå……åˆ†è¯æ˜äº†è¯¥æ–¹æ³•åœ¨**æ•ˆæœã€æ•ˆç‡ä¸å¯è§£é‡Šæ€§**ä¸Šçš„å…¨é¢ä¼˜åŠ¿ï¼Œä¸º path-based reasoning æä¾›äº†ä¸€ä¸ªå¼ºå¤§è€Œå®ç”¨çš„æ–°èŒƒå¼ã€‚

</details>

---

### 15. [AIR: Post-training Data Selection for Reasoning via Attention Head Influence](https://arxiv.org/abs/2512.13279)

**Authors**: Jinrui Liu, Jeff Wu, Xuanguang Pan, Gavin Cheung, Shuai Ma, Chongyang Tao  
**Category**: cs.CL  
**Published**: 2025-12-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.13279v1  

#### Abstract
LLMs achieve remarkable multi-step reasoning capabilities, yet effectively transferring these skills via post-training distillation remains challenging. Existing data selection methods, ranging from manual curation to heuristics based on length, entropy, or overall loss, fail to capture the causal i...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# AIR: Post-training Data Selection for Reasoning via Attention Head Influence è®ºæ–‡æ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„åè®­ç»ƒï¼ˆpost-trainingï¼‰æ•°æ®é€‰æ‹©æ–¹æ³•åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¤šæ­¥æ¨ç†èƒ½åŠ›æ—¶å­˜åœ¨æ˜¾è‘—å±€é™ã€‚è¿™äº›æ–¹æ³•é€šå¸¸ä¾èµ–äºå¯å‘å¼è§„åˆ™ï¼ˆå¦‚æ ·æœ¬é•¿åº¦ã€ç†µå€¼ã€æ€»ä½“æŸå¤±ç­‰ï¼‰ï¼Œæ— æ³•æ•æ‰å•ä¸ªæ¨ç†æ­¥éª¤çš„å› æœé‡è¦æ€§ï¼Œå¯¼è‡´çŸ¥è¯†è’¸é¦æ•ˆç‡ä½ä¸‹ã€‚æ­¤å¤–ï¼Œæ‰‹åŠ¨ç­›é€‰é«˜è´¨é‡æ¨ç†è½¨è¿¹è™½æœ‰æ•ˆä½†æˆæœ¬é«˜æ˜‚ä¸”ä¸å¯æ‰©å±•ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº† **Attention Influence for Reasoning (AIR)**ï¼Œä¸€ç§åŸºäºæœºåˆ¶å¯è§£é‡Šæ€§ï¼ˆmechanistic interpretabilityï¼‰çš„æ— ç›‘ç£ã€æ— éœ€è®­ç»ƒçš„æ•°æ®é€‰æ‹©æ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ç‰¹å®šâ€œæ£€ç´¢å¤´â€ï¼ˆretrieval headsï¼‰çš„åŠŸèƒ½å½±å“æ¥é‡åŒ–æ¨ç†æ­¥éª¤çš„é‡è¦æ€§ã€‚

- **è¯†åˆ«å…³é”®æ³¨æ„åŠ›å¤´**ï¼šé€šè¿‡åˆ†æ off-the-shelf æ¨¡å‹ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œè¯†åˆ«å¯¹ä¿¡æ¯æ£€ç´¢è‡³å…³é‡è¦çš„â€œæ£€ç´¢å¤´â€ã€‚è¿™äº›å¤´è´Ÿè´£åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å‡†ç¡®å¤åˆ¶ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ˜¯å¤æ‚æ¨ç†çš„åŸºç¡€ã€‚
- **æ„å»ºå¼±åŒ–å‚è€ƒæ¨¡å‹**ï¼šé€šè¿‡å±è”½è¿™äº›å…³é”®æ£€ç´¢å¤´çš„å½±å“ï¼Œæ„é€ ä¸€ä¸ªåŠŸèƒ½è¢«å‰Šå¼±çš„å‚è€ƒæ¨¡å‹ï¼ˆweakened reference modelï¼‰ã€‚
- **è®¡ç®—æ³¨æ„åŠ›å½±å“åˆ†æ•°ï¼ˆAttention Influence Scoreï¼‰**ï¼šé€šè¿‡æ¯”è¾ƒåŸå§‹å¼ºæ¨¡å‹ä¸å¼±åŒ–æ¨¡å‹ä¹‹é—´çš„ **loss divergence** æ¥å®šä¹‰ AIR Scoreã€‚è¯¥åˆ†æ•°èƒ½ç»†ç²’åº¦åœ°è¡¡é‡æ¯ä¸ª tokenã€æ¨ç†æ­¥éª¤ä¹ƒè‡³æ•´ä¸ªæ ·æœ¬å¯¹å…³é”®æ¨ç†æœºåˆ¶çš„ä¾èµ–ç¨‹åº¦ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æœºåˆ¶é©±åŠ¨è€Œéå¯å‘å¼**ï¼šä¸åŒäºåŸºäºé•¿åº¦æˆ–æŸå¤±çš„ç²—ç•¥ä»£ç†æŒ‡æ ‡ï¼ŒAIR ç›´æ¥ä»æ¨¡å‹å†…éƒ¨æœºåˆ¶å‡ºå‘ï¼Œæä¾›æ›´å…·è§£é‡Šæ€§çš„æ•°æ®ä»·å€¼è¯„ä¼°ã€‚
- **æ— éœ€é¢å¤–è®­ç»ƒ**ï¼šæ•´ä¸ªè¿‡ç¨‹å®Œå…¨æ— ç›‘ç£ä¸”æ— éœ€è®­ç»ƒï¼Œä»…éœ€å‰å‘ä¼ æ’­å³å¯å®Œæˆè¯„åˆ†ï¼Œè®¡ç®—é«˜æ•ˆã€‚
- **æ”¯æŒç»†ç²’åº¦é€‰æ‹©**ï¼šåŒæ—¶æ”¯æŒ **step-level weighted SFT** å’Œ **global sample selection** ä¸¤ç§ç­–ç•¥ï¼Œèƒ½å¤Ÿç²¾å‡†å¼ºåŒ–å…³é”®æ¨ç†è·¯å¾„ã€‚
- **è‡ªåŠ¨åŒ–æ›¿ä»£äººå·¥**ï¼šåœ¨æ€§èƒ½ä¸Šæ¥è¿‘ç”šè‡³è¶…è¶Šæ‰‹åŠ¨ç­›é€‰çš„é«˜è´¨é‡æ•°æ®é›†ï¼ˆå¦‚ s1Kï¼‰ï¼Œå®ç°äº†é«˜æ€§ä»·æ¯”çš„è‡ªåŠ¨åŒ–æ•°æ®é€‰æ‹©ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **59K-full dataset**ï¼šåŒ…å«çº¦ 59,000 ä¸ªæ¥è‡ª 16 ä¸ªä¸åŒæ¥æºçš„é—®é¢˜ï¼Œç”¨äºæ ·æœ¬çº§æ•°æ®é€‰æ‹©å®éªŒã€‚
- **s1K å’Œ s1K-1.1 datasets**ï¼š
  - **s1K**ï¼šä» 59K-full ä¸­æ‰‹å·¥ç­›é€‰å‡ºçš„ 1K é«˜è´¨é‡å­é›†ï¼Œæ¨ç†è½¨è¿¹ç”± Gemini ç”Ÿæˆã€‚
  - **s1K-1.1**ï¼šä¸ s1K ç›¸åŒçš„é—®é¢˜é›†åˆï¼Œä½†æ¨ç†è½¨è¿¹ç”±æ›´å¼ºçš„ DeepSeek-R1 ç”Ÿæˆï¼Œç”¨äºæ›´ä¸¥æ ¼çš„è¯„ä¼°ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **åŸºç¡€æ¨¡å‹ï¼ˆBase Modelï¼‰**ï¼šQwen2.5-7B-Instructï¼Œç”¨äºè¯†åˆ«å…³é”®æ£€ç´¢å¤´å¹¶æ„å»ºå¼±åŒ–æ¨¡å‹ã€‚
- **è®­ç»ƒæ¨¡å‹ï¼ˆTrainee Modelï¼‰**ï¼šQwen2.5-32B-Instructï¼Œè¿›è¡Œåè®­ç»ƒå¾®è°ƒã€‚
- **è¯„ä¼°åŸºå‡†ï¼ˆBenchmarksï¼‰**ï¼š
  - æ•°å­¦æ¨ç†ï¼šAIME 2024 & 2025ã€MATH500
  - ç§‘å­¦çŸ¥è¯†ï¼šGPQA Diamond
- **è¯„ä¼°æŒ‡æ ‡**ï¼šPass@1 å‡†ç¡®ç‡ï¼Œé‡‡ç”¨è´ªå©ªè§£ç ï¼ˆgreedy decoding, temperature=0ï¼‰ã€‚
- **è®­ç»ƒé…ç½®**ï¼š5 è½®è®­ç»ƒï¼Œå…¨å±€ batch size ä¸º 16ï¼ŒAdamW ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ 1e-5ï¼Œçº¿æ€§é¢„çƒ­ + ä½™å¼¦è¡°å‡ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
#### æ ·æœ¬çº§é€‰æ‹©ï¼ˆSample-Levelï¼‰
- **Random / Random-by-type**ï¼šéšæœºæˆ–æŒ‰ç±»åˆ«éšæœºé‡‡æ ·
- **Length**ï¼šä¼˜å…ˆé€‰æ‹©è¾ƒé•¿çš„æ ·æœ¬
- **Diverse**ï¼šå¼ºè°ƒå¤šæ ·æ€§
- **s1K / s1K-1.1**ï¼šæ‰‹å·¥ç­›é€‰çš„é»„é‡‘æ ‡å‡†

#### æ­¥éª¤çº§åŠ æƒï¼ˆStep-Levelï¼‰
- **Random**ï¼šéšæœºé€‰æ‹© 20% çš„æ­¥éª¤è¿›è¡ŒåŠ æƒ
- **Entropy**ï¼šé€‰æ‹©ä¸ç¡®å®šæ€§æœ€é«˜çš„ 20% æ­¥éª¤è¿›è¡ŒåŠ æƒ
- **s1K-1.1 baseline**ï¼šä¸åŠ æƒçš„æ ‡å‡†å¾®è°ƒ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| æ–¹æ³• | AIME 2024 | AIME 2025 | MATH500 | GPQA Diamond | **å¹³å‡åˆ†** |
|------|-----------|-----------|---------|--------------|------------|
| s1K-1.1 (baseline) | 56.70 | 50.00 | 94.40 | 60.60 | **65.43** |
| **AIR-Sample** | 56.70 | 50.00 | 95.20 | **66.67** | **67.14** |
| **s1K-1.1 + AIR-Step** | **66.67** | **53.33** | **95.60** | **65.66** | **70.32** |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **AIR-Sample vs æ‰‹åŠ¨ç­›é€‰**ï¼š
  - åœ¨ s1K-1.1 è®¾ç½®ä¸‹ï¼Œ**AIR-Sample å¹³å‡åˆ†è¾¾åˆ° 67.14%ï¼Œè¶…è¿‡ s1K-1.1 çš„ 65.43%**ï¼Œå°¤å…¶åœ¨ GPQA Diamond ä¸Šå¤§å¹…æå‡è‡³ 66.67%ã€‚
  - æ€§èƒ½åª²ç¾ç”šè‡³è¶…è¶Šäººå·¥ç­›é€‰ï¼Œè¯æ˜å…¶è‡ªåŠ¨åŒ–é€‰æ‹©çš„æœ‰æ•ˆæ€§ã€‚
- **AIR-Step vs åŸºçº¿**ï¼š
  - åœ¨ s1K-1.1 åŸºç¡€ä¸Šå¼•å…¥ step-level åŠ æƒåï¼Œå¹³å‡åˆ†ä» 65.43% æå‡è‡³ **70.32%**ï¼Œç»å¯¹æå‡è¾¾ **4.89%**ã€‚
  - åœ¨éœ€è¦ä¸¥æ ¼é€»è¾‘æ¨ç†çš„ä»»åŠ¡ï¼ˆå¦‚ AIME 2024ï¼‰ä¸Šæå‡æ˜¾è‘—ï¼ˆ+9.97%ï¼‰ï¼Œè¡¨æ˜ AIR æˆåŠŸå¼ºåŒ–äº†å…³é”®æ¨ç†é“¾ã€‚

### æ¶ˆèå®éªŒä¸æ•æ„Ÿæ€§åˆ†æ
- **è¶…å‚æ•°åˆ†æï¼ˆå›¾2ï¼‰**ï¼š
  - æœ€ä½³ **critical step ratio (P%)** ä¸º 20%ï¼Œè¿‡é«˜ï¼ˆ40%-50%ï¼‰ä¼šå¼•å…¥å†—ä½™æ­¥éª¤å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
  - æœ€ä½³ **weight multiplier (Î±)** ä¸º 2Ã—ï¼Œè¿‡é«˜çš„æƒé‡ï¼ˆ5Ã— æˆ– 10Ã—ï¼‰ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆå±€éƒ¨ç‰‡æ®µã€‚
- **æ•°æ®é€‰æ‹©ç­–ç•¥å¯¹æ¯”ï¼ˆè¡¨2ï¼‰**ï¼š
  - AIR åœ¨æ‰€æœ‰è‡ªåŠ¨æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³ï¼Œä»…æ¬¡äºäººå·¥ç­›é€‰çš„ s1Kã€‚
  - å¯å‘å¼æ–¹æ³•ï¼ˆå¦‚ Lengthï¼‰è¡¨ç°ä¸ç¨³å®šï¼Œè€Œ AIR æ›´ç¨³å®šä¸”å…¨é¢ä¼˜äºå…¶ä»–è‡ªåŠ¨æ–¹æ³•ã€‚
- **æ­¥éª¤çº§åŠ æƒç­–ç•¥å¯¹æ¯”ï¼ˆè¡¨3ï¼‰**ï¼š
  - AIR-Stepï¼ˆ75.98%ï¼‰æ˜¾è‘—ä¼˜äº Randomï¼ˆ70.76%ï¼‰å’Œ Entropyï¼ˆ73.76%ï¼‰ï¼ŒéªŒè¯äº†å…¶æœºåˆ¶é©±åŠ¨è¯„åˆ†çš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æœºåˆ¶é©±åŠ¨çš„é€‰æ‹©æ›´æœ‰æ•ˆ**ï¼šåŸºäº retrieval head çš„æ³¨æ„åŠ›å½±å“åˆ†æ•°èƒ½æœ‰æ•ˆè¯†åˆ«å¯¹æ¨ç†è‡³å…³é‡è¦çš„æ­¥éª¤å’Œæ ·æœ¬ï¼Œç›¸æ¯”å¯å‘å¼æ–¹æ³•æ›´å…·å› æœæ€§å’Œè§£é‡Šæ€§ã€‚
2. **ç»†ç²’åº¦åŠ æƒæ˜¾è‘—æå‡æ€§èƒ½**ï¼šstep-level weighted SFT èƒ½å¼•å¯¼æ¨¡å‹èšç„¦äºé«˜å½±å“åŠ›çš„å…³é”®æ¨ç†èŠ‚ç‚¹ï¼ˆå¦‚è§„åˆ’ã€ä¿®æ­£ã€éªŒè¯ï¼‰ï¼Œä»è€Œå¢å¼ºé€»è¾‘ä¸¥è°¨æ€§ã€‚
3. **è‡ªåŠ¨åŒ–å¯åª²ç¾äººå·¥ç­›é€‰**ï¼šAIR åœ¨ä»…ä½¿ç”¨ 1K æ ·æœ¬çš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½å·²æ¥è¿‘ç”šè‡³è¶…è¶Šäººå·¥ç­›é€‰çš„ s1K æ•°æ®é›†ï¼Œä¸”è¿œè¶…å…¶ä»–è‡ªåŠ¨æ–¹æ³•ã€‚
4. **æ•°æ®æ•ˆç‡æé«˜**ï¼šä½¿ç”¨ AIR é€‰å‡ºçš„ 1K æ ·æœ¬è®­ç»ƒçš„æ¨¡å‹ï¼Œæ€§èƒ½ä¼˜äºä½¿ç”¨ 800K æ ·æœ¬è®­ç»ƒçš„ R1-distill-Qwen-32B æ¨¡å‹ï¼Œå±•ç°äº†æå¼ºçš„ **data efficiency**ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–ç‰¹å®šæœºåˆ¶å‡è®¾**ï¼šæ–¹æ³•æœ‰æ•ˆæ€§å»ºç«‹åœ¨â€œretrieval heads å¯¹æ¨ç†è‡³å…³é‡è¦â€çš„å‡è®¾ä¹‹ä¸Šï¼Œè‹¥æ¨¡å‹æ¶æ„æˆ–ä»»åŠ¡æœºåˆ¶ä¸åŒï¼Œæ•ˆæœå¯èƒ½å—é™ã€‚
- **æœªè€ƒè™‘å¤šæ ·æ€§**ï¼šAIR é€‰å‡ºçš„æ•°æ®åˆ†å¸ƒæ›´é›†ä¸­ï¼ˆè§å›¾3ï¼‰ï¼Œç¼ºä¹æ˜¾å¼çš„å¤šæ ·æ€§æ§åˆ¶ï¼Œå¯èƒ½å¯¼è‡´æ³›åŒ–èƒ½åŠ›å—é™ã€‚
- **è®¡ç®—å¼€é”€ä»å­˜åœ¨**ï¼šå°½ç®¡æ— éœ€è®­ç»ƒï¼Œä½†åœ¨å¤§è§„æ¨¡æ•°æ®æ± ä¸Šé€æ ·æœ¬è®¡ç®— loss divergence ä»æœ‰ä¸€å®šè®¡ç®—æˆæœ¬ï¼ˆæ–‡ä¸­å¤„ç† 59K æ•°æ®è€—æ—¶ ~6.9 å°æ—¶ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢å°† AIR ä¸å…¶ä»–ç›®æ ‡ï¼ˆå¦‚å¤šæ ·æ€§ã€é¢†åŸŸè¦†ç›–ï¼‰ç»“åˆï¼Œå®ç°æ›´å‡è¡¡çš„æ•°æ®é€‰æ‹©ã€‚
- å°† AIR åº”ç”¨äºå…¶ä»–ä»»åŠ¡ï¼ˆå¦‚ä»£ç ç”Ÿæˆã€å¯¹è¯ç³»ç»Ÿï¼‰ä»¥éªŒè¯å…¶é€šç”¨æ€§ã€‚
- ç ”ç©¶å¦‚ä½•åŠ¨æ€è°ƒæ•´ AIR Score çš„é˜ˆå€¼æˆ–æƒé‡ç­–ç•¥ï¼Œä»¥é€‚åº”ä¸åŒè®­ç»ƒé˜¶æ®µçš„éœ€æ±‚ã€‚
- æ¢ç´¢è½»é‡åŒ–ç‰ˆæœ¬ï¼Œè¿›ä¸€æ­¥é™ä½è®¡ç®—æˆæœ¬ï¼Œé€‚ç”¨äºæ›´å¤§è§„æ¨¡çš„æ•°æ®ç­›é€‰åœºæ™¯ã€‚

</details>

---

### 16. [Large Language Models as Generalist Policies for Network Optimization](https://arxiv.org/abs/2512.11839)

**Authors**: Duo Wu, Linjia Kang, Zhimin Wang, Fangxin Wang, Wei Zhang, Xuefeng Tao, Wei Yang, Le Zhang, Peng Cui, Zhi Wang  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.11839v1  

#### Abstract
Designing control policies to ensure robust network services is essential to modern digital infrastructure. However, the dominant paradigm for network optimization relies on designing specialist policies based on handcrafted rules or deep learning models, leading to poor generalization across divers...

---

### 17. [Tiny Recursive Models on ARC-AGI-1: Inductive Biases, Identity Conditioning, and Test-Time Compute](https://arxiv.org/abs/2512.11847)

**Authors**: Antonio Roye-Azar, Santiago Vargas-Naranjo, Dhruv Ghai, Nithin Balamurugan, Rayan Amir  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.11847v1  

#### Abstract
Tiny Recursive Models (TRM) were proposed as a parameter-efficient alternative to large language models for solving Abstraction and Reasoning Corpus (ARC) style tasks. The original work reports strong performance and suggests that recursive latent updates enable non-trivial reasoning, but it remains...

---

### 18. [Reflective Preference Optimization (RPO): Enhancing On-Policy Alignment via Hint-Guided Reflection](https://arxiv.org/abs/2512.13240)

**Authors**: Zihui Zhao, Zechang Li  
**Category**: cs.AI  
**Published**: 2025-12-16  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.13240v1  

#### Abstract
Direct Preference Optimization (DPO) has emerged as a lightweight and effective alternative to Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with AI Feedback (RLAIF) for aligning large language and vision-language models. However, the standard DPO formulation, in which...

---

### 19. [QwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management](https://arxiv.org/abs/2512.12967)

**Authors**: Weizhou Shen, Ziyi Yang, Chenliang Li, Zhiyuan Lu, Miao Peng, Huashan Sun, Yingcheng Shi, Shengyi Liao, Shaopeng Lai, Bo Zhang, Dayiheng Liu, Fei Huang, Jingren Zhou, Ming Yan  
**Category**: cs.CL  
**Published**: 2025-12-16  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.12967v1  

#### Abstract
We introduce QwenLong-L1.5, a model that achieves superior long-context reasoning capabilities through systematic post-training innovations. The key technical breakthroughs of QwenLong-L1.5 are as follows: (1) Long-Context Data Synthesis Pipeline: We develop a systematic synthesis framework that gen...

---

### 20. [Socratic Students: Teaching Language Models to Learn by Asking Questions](https://arxiv.org/abs/2512.13102)

**Authors**: Rajeev Bhatt Ambati, Tianyi Niu, Aashu Singh, Shlok Mishra, Shashank Srivastava, Snigdha Chaturvedi  
**Category**: cs.AI  
**Published**: 2025-12-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.13102v1  

#### Abstract
Large Language Models (LLMs) excel at static interactions, where they answer user queries by retrieving knowledge encoded in their parameters. However, in many real-world settings, such as educational tutoring or medical assistance, relevant information is not directly available and must be actively...

---

### 21. [AutoTool: Dynamic Tool Selection and Integration for Agentic Reasoning](https://arxiv.org/abs/2512.13278)

**Authors**: Jiaru Zou, Ling Yang, Yunzhe Qi, Sirui Chen, Mengting Ai, Ke Shen, Jingrui He, Mengdi Wang  
**Category**: cs.CL  
**Published**: 2025-12-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.13278v1  

#### Abstract
Agentic reinforcement learning has advanced large language models (LLMs) to reason through long chain-of-thought trajectories while interleaving external tool use. Existing approaches assume a fixed inventory of tools, limiting LLM agents' adaptability to new or evolving toolsets. We present AutoToo...

---

### 22. [Anchoring Values in Temporal and Group Dimensions for Flow Matching Model Alignment](https://arxiv.org/abs/2512.12387)

**Authors**: Yawen Shao, Jie Xiao, Kai Zhu, Yu Liu, Wei Zhai, Yang Cao, Zheng-Jun Zha  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.12387v1  

#### Abstract
Group Relative Policy Optimization (GRPO) has proven highly effective in enhancing the alignment capabilities of Large Language Models (LLMs). However, current adaptations of GRPO for the flow matching-based image generation neglect a foundational conflict between its core principles and the distinc...

---

### 23. [Noise-Resilient Quantum Aggregation on NISQ for Federated ADAS Learning](https://arxiv.org/abs/2512.13196)

**Authors**: Chethana Prasad Kabgere, Sudarshan T S B  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.13196v1  

#### Abstract
Advanced Driver Assistance Systems (ADAS) increasingly employ Federated Learning (FL) to collaboratively train models across distributed vehicular nodes while preserving data privacy. Yet, conventional FL aggregation remains susceptible to noise, latency, and security constraints inherent to real-ti...

---

### 24. [M-GRPO: Stabilizing Self-Supervised Reinforcement Learning for Large Language Models with Momentum-Anchored Policy Optimization](https://arxiv.org/abs/2512.13070)

**Authors**: Bizhe Bai, Hongming Wu, Peng Ye, Tao Chen  
**Category**: cs.AI  
**Published**: 2025-12-16  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.13070v1  

#### Abstract
Self-supervised reinforcement learning (RL) presents a promising approach for enhancing the reasoning capabilities of Large Language Models (LLMs) without reliance on expensive human-annotated data. However, we find that existing methods suffer from a critical failure mode under long-horizon trainin...

---

### 25. [astroCAMP: A Community Benchmark and Co-Design Framework for Sustainable SKA-Scale Radio Imaging](https://arxiv.org/abs/2512.13591)

**Authors**: Denisa-Andreea Constantinescu, Rub\'en Rodr\'iguez \'Alvarez, Jacques Morin, Etienne Orliac, Micka\"el Dardaillon, Sunrise Wang, Hugo Miomandre, Miguel Pe\'on-Quir\'os, Jean-Fran\c{c}ois Nezan, David Atienza  
**Category**: cs.DC  
**Published**: 2025-12-16  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.13591v1  

#### Abstract
The Square Kilometre Array (SKA) project will operate one of the world's largest continuous scientific data systems, sustaining petascale imaging under strict power caps. Yet, current radio-interferometric pipelines utilize only a small fraction of hardware peak performance, typically 4-14%, due to ...

---

### 26. [Phase transitions reveal hierarchical structure in deep neural networks](https://arxiv.org/abs/2512.11866)

**Authors**: Ibrahim Talha Ersoy, Andr\'es Fernando Cardozo Licha, Karoline Wiesner  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.11866v1  

#### Abstract
Training Deep Neural Networks relies on the model converging on a high-dimensional, non-convex loss landscape toward a good minimum. Yet, much of the phenomenology of training remains ill understood. We focus on three seemingly disparate observations: the occurrence of phase transitions reminiscent ...

---

### 27. [DP-EMAR: A Differentially Private Framework for Autonomous Model Weight Repair in Federated IoT Systems](https://arxiv.org/abs/2512.13460)

**Authors**: Chethana Prasad Kabgere, Shylaja S S  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.13460v1  

#### Abstract
Federated Learning (FL) enables decentralized model training without sharing raw data, but model weight distortion remains a major challenge in resource constrained IoT networks. In multi tier Federated IoT (Fed-IoT) systems, unstable connectivity and adversarial interference can silently alter tran...

---

### 28. [AGAPI-Agents: An Open-Access Agentic AI Platform for Accelerated Materials Design on AtomGPT.org](https://arxiv.org/abs/2512.11935)

**Authors**: Jaehyung Lee, Justin Ely, Kent Zhang, Akshaya Ajith, Charles Rhys Campbell, Kamal Choudhary  
**Category**: cs.AI  
**Published**: 2025-12-16  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.11935v1  

#### Abstract
Artificial intelligence is reshaping scientific discovery, yet its use in materials research remains limited by fragmented computational ecosystems, reproducibility challenges, and dependence on commercial large language models (LLMs). Here we introduce AGAPI (AtomGPT.org API), an open-access agenti...

---

### 29. [Log Anomaly Detection with Large Language Models via Knowledge-Enriched Fusion](https://arxiv.org/abs/2512.11997)

**Authors**: Anfeng Peng, Ajesh Koyatan Chathoth, Stephen Lee  
**Category**: cs.AI  
**Published**: 2025-12-16  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.11997v1  

#### Abstract
System logs are a critical resource for monitoring and managing distributed systems, providing insights into failures and anomalous behavior. Traditional log analysis techniques, including template-based and sequence-driven approaches, often lose important semantic information or struggle with ambig...

---

### 30. [Scaling Laws for Code: Every Programming Language Matters](https://arxiv.org/abs/2512.13472)

**Authors**: Jian Yang, Shawn Guo, Lin Jing, Wei Zhang, Aishan Liu, Chuan Hao, Zhoujun Li, Wayne Xin Zhao, Xianglong Liu, Weifeng Lv, Bryan Dai  
**Category**: cs.CL  
**Published**: 2025-12-16  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.13472v1  

#### Abstract
Code large language models (Code LLMs) are powerful but costly to train, with scaling laws predicting performance from model size, data, and compute. However, different programming languages (PLs) have varying impacts during pre-training that significantly affect base model performance, leading to i...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
