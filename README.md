# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-19 06:44:07 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Distributed physics-informed neural networks via domain decomposition for fast flow reconstruction](https://arxiv.org/abs/2602.15883)

**Authors**: Yixiao Qian, Jiaxu Liu, Zewei Xia, Song Chen, Chao Xu, Shengze Cai  
**Category**: cs.LG  
**Published**: 2026-02-19  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2602.15883v1  

#### Abstract
Physics-Informed Neural Networks (PINNs) offer a powerful paradigm for flow reconstruction, seamlessly integrating sparse velocity measurements with the governing Navier-Stokes equations to recover complete velocity and latent pressure fields. However, scaling such models to large spatiotemporal dom...

---

### 2. [MoE-Spec: Expert Budgeting for Efficient Speculative Decoding](https://arxiv.org/abs/2602.16052)

**Authors**: Bradley McDanel, Steven Li, Sruthikesh Surineni, Harshit Khaitan  
**Category**: cs.LG  
**Published**: 2026-02-19  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2602.16052v1  

#### Abstract
Speculative decoding accelerates Large Language Model (LLM) inference by verifying multiple drafted tokens in parallel. However, for Mixture-of-Experts (MoE) models, this parallelism introduces a severe bottleneck: large draft trees activate many unique experts, significantly increasing memory press...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MoE-Spec: Expert Budgeting for Efficient Speculative Decoding è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨ **Mixture-of-Experts (MoE)** æ¶æ„çš„å¤§è¯­è¨€æ¨¡å‹ä¸­ï¼Œ**Speculative Decoding**ï¼ˆæ¨æµ‹è§£ç ï¼‰è™½ç„¶èƒ½é€šè¿‡å¹¶è¡ŒéªŒè¯å¤šä¸ªå€™é€‰ token æ¥åŠ é€Ÿæ¨ç†ï¼Œä½†å…¶æ•ˆç‡å—åˆ°ä¸¥é‡é™åˆ¶ã€‚åŸå› åœ¨äºï¼š
- åœ¨éªŒè¯é˜¶æ®µï¼Œæ¯ä¸ª token ç‹¬ç«‹è·¯ç”±åˆ°ä¸åŒçš„ä¸“å®¶å­é›†ï¼›
- éªŒè¯æ•´ä¸ª **draft tree** æ—¶ï¼Œç›®æ ‡æ¨¡å‹å¿…é¡»åŠ è½½æ‰€æœ‰è¢«æ¿€æ´»çš„ä¸“å®¶çš„å¹¶é›†ï¼›
- éšç€ draft tree è§„æ¨¡å¢å¤§ï¼Œæ¿€æ´»çš„ä¸“å®¶æ•°é‡è¿…é€Ÿæ¥è¿‘æ€»ä¸“å®¶æ•°ï¼ˆå³ç¨€ç–æ€§å¤±æ•ˆï¼‰ï¼Œå¯¼è‡´å†…å­˜å¸¦å®½å‹åŠ›å‰§å¢ï¼ŒæŠµæ¶ˆäº†æ¨æµ‹å¸¦æ¥çš„åŠ é€Ÿæ”¶ç›Šã€‚

è¿™ä¸€ç“¶é¢ˆä½¿å¾—ä¼ ç»Ÿ speculative decodingï¼ˆå¦‚ EAGLEï¼‰åœ¨ MoE æ¨¡å‹ä¸Šéš¾ä»¥å®ç°ç†æƒ³ååæå‡ã€‚

---

### ğŸ†• æå‡ºçš„æ–°æ–¹æ³•ï¼šMoE-Spec
ä½œè€…æå‡º **MoE-Spec** â€”â€” ä¸€ç§æ— éœ€è®­ç»ƒã€ä»…åœ¨éªŒè¯é˜¶æ®µç”Ÿæ•ˆçš„ **expert budgeting** æ–¹æ³•ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **åœ¨æ¯å±‚å¼ºåˆ¶è®¾å®šä¸“å®¶å®¹é‡ä¸Šé™ Bï¼ˆexpert budgetï¼‰**ï¼›
- èšåˆ draft tree ä¸­æ‰€æœ‰ token çš„ routing probabilityï¼Œé€‰æ‹©å¾—åˆ†æœ€é«˜çš„å‰ B ä¸ªä¸“å®¶æ„æˆçŸ­åå•ï¼ˆshortlistï¼‰ï¼›
- åªåŠ è½½è¿™äº›é«˜è´¡çŒ®ä¸“å®¶è¿›è¡ŒéªŒè¯ï¼Œå¿½ç•¥é•¿å°¾ä¸­ä½é¢‘ä½¿ç”¨çš„ä¸“å®¶ã€‚

è¯¥æ–¹æ³•å®ç°äº† **speculation depth ä¸ memory cost çš„è§£è€¦**ï¼šæ— è®º draft tree å¤šå¤§ï¼Œæ¯å±‚æœ€å¤šåªåŠ è½½ B ä¸ªä¸“å®¶ã€‚

#### æ”¯æŒä¸‰ç§ ranking ç­–ç•¥ï¼š
| æ–¹æ³• | æè¿° | ç‰¹ç‚¹ |
|------|------|------|
| **Static Ranking** | åŸºäºæ ¡å‡†æ•°æ®ç»Ÿè®¡ä¸“å®¶è¢«é€‰ä¸­çš„é¢‘ç‡ï¼Œå›ºå®šæ’åº | é›¶è¿è¡Œå¼€é”€ï¼Œé€‚åˆä¸­ç­‰é¢„ç®— |
| **Router-Based Ranking**ï¼ˆä¸»æ¨ï¼‰ | å¯¹å½“å‰ draft tree å†…æ‰€æœ‰ token çš„ routing probability æ±‚å’Œï¼ŒåŠ¨æ€é€‰å‡º top-B | è‡ªé€‚åº”è¾“å…¥ï¼Œæ— é¢å¤–æ¨¡å‹è®¡ç®— |
| **Oracle Ranking** | è´ªå¿ƒæœ€å°åŒ–é‡æ„è¯¯å·®ï¼Œç†è®ºä¸Šé™ | ä¸å®ç”¨ä½†ç”¨äºåˆ†ææ½œåŠ› |

#### ä¸¤ç§å¤„ç†ç¼ºå¤±ä¸“å®¶çš„æ–¹å¼ï¼š
- **Truncation**ï¼šä¿ç•™åŸå§‹ top-k è·¯ç”±æƒé‡ï¼Œæœªå‘½ä¸­ä¸“å®¶ç›´æ¥ç½®é›¶ï¼›
- **Substitution**ï¼šä» shortlist ä¸­é€‰å–æ›¿ä»£ä¸“å®¶ï¼Œç¡®ä¿æ¯ä¸ª token ä»ä½¿ç”¨ k ä¸ªä¸“å®¶ï¼ˆé»˜è®¤ç­–ç•¥ï¼‰ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | MoE-Spec vs. ç°æœ‰æ–¹æ³• |
|------|------------------------|
| **æ— éœ€ä¿®æ”¹æ¶æ„æˆ–è®­ç»ƒ** | åŒºåˆ«äºéœ€è¦è®­ç»ƒ drifter æˆ–è°ƒæ•´ç»“æ„çš„æ–¹æ³•ï¼ˆå¦‚ EAGLE-3ï¼‰ï¼ŒMoE-Spec å®Œå…¨ training-freeï¼Œå¯æ’æ‹”é›†æˆè¿›ç°æœ‰ pipeline |
| **æ˜¾è‘—é™ä½å†…å­˜å¸¦å®½å¼€é”€** | å°†éªŒè¯é˜¶æ®µåŠ è½½çš„ä¸“å®¶æ•°ä»è¿‘ä¹å…¨éƒ¨ï¼ˆå¦‚ 54/64ï¼‰å‹ç¼©è‡³å›ºå®šé¢„ç®—ï¼ˆå¦‚ B=32ï¼‰ |
| **æ›´é«˜åå + æ›´å¥½æ‰©å±•æ€§** | åœ¨å¤§ draft tree ä¸‹æŒç»­å¢ç›Šï¼Œè€Œ EAGLE ç±»æ–¹æ³•å› â€œstraggler ä¸“å®¶â€å‡ºç°æ€§èƒ½ä¸‹é™ |
| **çµæ´»çš„è´¨é‡-å»¶è¿Ÿæƒè¡¡** | é€šè¿‡è°ƒèŠ‚ B å®ç°è¿ç»­çš„ Pareto æ›²çº¿ï¼Œé€‚é…ä¸åŒåº”ç”¨åœºæ™¯éœ€æ±‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
æ¶µç›–ä¸‰å¤§ä»»åŠ¡ç±»åˆ«ï¼Œå…± **5 ä¸ªåŸºå‡†**ï¼š
- **æ•°å­¦æ¨ç†**ï¼šGSM8Kï¼ˆå¤šæ­¥ç®—æœ¯ï¼‰ã€MATH500ï¼ˆç«èµ›çº§æ•°å­¦é¢˜ï¼‰
- **ä»£ç ç”Ÿæˆ**ï¼šHumanEvalã€MBPPï¼ˆå‡½æ•°åˆæˆä»»åŠ¡ï¼Œpass@1 æŒ‡æ ‡ï¼‰
- **æ‘˜è¦ç”Ÿæˆ**ï¼šCNN/DailyMailï¼ˆæŠ½è±¡å¼æ‘˜è¦ï¼ŒROUGE-L F1ï¼‰

---

### âš™ï¸ å®éªŒè®¾ç½®
| å‚æ•° | è®¾ç½® |
|------|------|
| **æ¨¡å‹** | OLMoE-1B-7Bï¼ˆ64 experts, k=8ï¼‰<br>Qwen3-30B-A3Bï¼ˆ128 experts, k=8ï¼‰<br>Mixtral-8x7Bï¼ˆ8 experts, k=2ï¼‰ |
| **Speculative Decoder** | EAGLE-3ï¼ˆOLMoE/Qwen3ï¼‰ã€EAGLE-1ï¼ˆMixtralï¼‰ |
| **Draft Tree Size** | ä¸»å®éªŒä¸º 63ï¼›æ¶ˆèå®éªŒæ‰«æ 3â€“511 |
| **æ¸©åº¦** | T=0ï¼ˆgreedy decodingï¼‰ã€T=1ï¼ˆsamplingï¼‰ |
| **è¯„ä¼°æŒ‡æ ‡** | Speedupï¼ˆç›¸å¯¹ autoregressive çš„åŠ é€Ÿæ¯”ï¼‰<br>Mean Accept Lengthï¼ˆå¹³å‡æ¥å—é•¿åº¦ï¼‰<br>Task Accuracy / Pass@1 / ROUGE-L |
| **ç¡¬ä»¶å¹³å°** | NVIDIA A100ï¼ˆ80GBï¼‰ |
| **ç²¾åº¦** | FP16 |

> æ‰€æœ‰æ–¹æ³•å‡å¯ç”¨ **batched MoE computation** ä»¥å…¬å¹³æ¯”è¾ƒï¼ˆè¯¦è§ Appendix Cï¼‰

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **Autoregressive (AR)** | é€ token ç”Ÿæˆï¼Œæ—  speculationï¼Œä½œä¸ºé€Ÿåº¦åŸºå‡† |
| **EAGLE / EAGLE-3** | å½“å‰æœ€å…ˆè¿›çš„ tree-based speculative decoding æ–¹æ³•ï¼Œä»£è¡¨ state-of-the-art |
| **MoE-Spec**ï¼ˆæœ¬æ–‡ï¼‰ | åœ¨ EAGLE åŸºç¡€ä¸ŠåŠ å…¥ expert budgeting æœºåˆ¶ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1 å’Œ Figure 3ï¼‰

| æ¨¡å‹ | æ–¹æ³• | å¹³å‡ Speedup æå‡ï¼ˆvs. EAGLEï¼‰ | ç¤ºä¾‹è¡¨ç° |
|------|------|-------------------------------|----------|
| **Mixtral-8x7B** | MoE-Spec | **+27%** | MBPP ä¸Šè¾¾ 2.3Ã— vs. EAGLE çš„ 1.7Ã—ï¼ˆ+35%ï¼‰ |
| **Qwen3-30B-A3B** | MoE-Spec | **+16%** | GSM8K ä¸Šè¾¾ 2.4Ã— vs. 1.9Ã— |
| **OLMoE-1B-7B** | MoE-Spec | **+6%** | æå‡è¾ƒå°ï¼Œä½†ä»ä¼˜äºåŸºçº¿ |

> æ€»ä½“ï¼šåœ¨ **30 ä¸ª model-benchmark ç»„åˆä¸­æœ‰ 27 ä¸ªå®ç°æ›´é«˜ throughput**ï¼Œä¸”è´¨é‡ç›¸å½“ã€‚

---

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ
- **Speedup æ˜¾è‘—é¢†å…ˆ**ï¼š
  - MoE-Spec åœ¨å¤§ draft tree ä¸‹æŒç»­å—ç›Šï¼Œè€Œ EAGLE åœ¨ tree size >31 åæ€§èƒ½å›è½ï¼ˆå› ä¸“å®¶åŠ è½½æˆæœ¬è¶…è¿‡æ”¶ç›Šï¼‰ï¼›
  - åœ¨ tree size=255 æ—¶ï¼ŒEAGLE åŠ è½½ ~54/64 ä¸“å®¶ä»…å¾— 1.85Ã— åŠ é€Ÿï¼ŒMoE-Specï¼ˆB=32ï¼‰ä»…åŠ è½½ 32 ä¸“å®¶å´è¾¾åˆ° **2.1Ã—**ã€‚
- **Acceptance Length å‡ ä¹ä¸å˜**ï¼š
  - å¹³å‡ä»…å‡å°‘ **1.4%**ï¼Œè¯´æ˜éªŒè¯å‡†ç¡®æ€§ä¿æŒè‰¯å¥½ï¼›
  - åŠ é€Ÿä¸»è¦æ¥è‡ª **verification cost é™ä½**ï¼Œè€Œéç‰ºç‰²æ¥å—ç‡ã€‚

---

### ğŸ”§ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰Ranking æ–¹æ³•æ¯”è¾ƒï¼ˆFigure 5aï¼‰
| æ–¹æ³• | è¡¨ç° |
|------|------|
| **Router-Based** | åœ¨å„ç§é¢„ç®—ä¸‹ç¨³å®šè·Ÿè¸ª Oracle ä¸Šé™ï¼Œåœ¨ Bâ‰¥32 æ—¶æ¥è¿‘ AR è´¨é‡ |
| **Static** | åœ¨ä½é¢„ç®—ï¼ˆBâ‰¤16ï¼‰ä¸‹å´©æºƒï¼ˆå¦‚ GSM8K å‡†ç¡®ç‡ä¸º 0ï¼‰ï¼Œæ— æ³•é€‚åº”è¾“å…¥å˜åŒ– |
| **Oracle** | å³ä½¿åœ¨ B=24ï¼ˆ37.5% ä¸“å®¶ï¼‰ä¹Ÿèƒ½æ¥è¿‘ AR è´¨é‡ï¼Œæ˜¾ç¤ºæ”¹è¿›ç©ºé—´ |

> ç»“è®ºï¼š**router-based æ˜¯æœ€ä½³å®è·µæŠ˜è¡·æ–¹æ¡ˆ**

#### ï¼ˆ2ï¼‰Coverage Policy æ¯”è¾ƒï¼ˆFigure 5bï¼‰
- **Truncation vs. Substitution**ï¼šä¸¤è€…æ€§èƒ½å‡ ä¹ä¸€è‡´ï¼›
- é»˜è®¤é‡‡ç”¨ **Substitution** ä»¥ç»´æŒæ¯ä¸ª token ä½¿ç”¨ k ä¸ªä¸“å®¶çš„ä¸€è‡´æ€§ã€‚

#### ï¼ˆ3ï¼‰Reconstruction Error åˆ†æï¼ˆFigure 6ï¼‰
- Oracle åœ¨ **å°‘ç”¨ 25% ä¸“å®¶çš„æƒ…å†µä¸‹è¾¾åˆ°ç›¸åŒé‡æ„è¯¯å·®**ï¼›
- åŸå› ï¼šOracle è€ƒè™‘ä¸“å®¶é—´çš„ç›¸å…³æ€§ï¼ˆco-activationï¼‰ï¼Œé¿å…å†—ä½™é€‰æ‹©ï¼›
- Router ç‹¬ç«‹æ‰“åˆ†ï¼Œæ˜“é‡å¤é€‰æ‹©å¼ºç›¸å…³ä¸“å®¶ â†’ æµªè´¹é¢„ç®—ã€‚

> å‘ç°ï¼šæŸäº› expert pairs å…±ç°é¢‘ç‡é«˜è¾¾éšæœºé¢„æœŸçš„ **10â€“30Ã—**ï¼ˆå¹³å‡ 23Ã—ï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **MoE éªŒè¯è¿‡ç¨‹ä¸­çš„ä¸“å®¶æ¿€æ´»å‘ˆé‡å°¾åˆ†å¸ƒ**ï¼š
   - å‰ 32/64 ä¸“å®¶å æ® **93% çš„ aggregate routing weight**ï¼›
   - é•¿å°¾ä¸“å®¶å¯¹è¾“å‡ºå½±å“å°ä½†å¸¦æ¥é«˜æ˜‚å¸¦å®½ä»£ä»·ã€‚

2. **expert budgeting å¯æœ‰æ•ˆè§£è€¦éªŒè¯æˆæœ¬ä¸ draft tree å¤æ‚åº¦**ï¼š
   - å›ºå®š B åï¼Œmemory cost ä¸å†éš tree size å¢é•¿ï¼›
   - å®ç°æ›´æ¿€è¿›çš„ speculation è€Œä¸å¼•å‘æ€§èƒ½é€€åŒ–ã€‚

3. **MoE-Spec å®ç° 10â€“30% ååæå‡**ï¼š
   - åœ¨ä¸‰ä¸ªä¸»æµ MoE æ¨¡å‹ä¸Šå…¨é¢è¶…è¶Š EAGLE-3ï¼›
   - å°¤å…¶åœ¨è¾ƒå¤§æ¨¡å‹ï¼ˆå¦‚ Mixtralï¼‰ä¸Šå¢ç›Šæ›´æ˜æ˜¾ã€‚

4. **quality-speedup tradeoff å¯æ§æ€§å¼º**ï¼š
   - é€šè¿‡è°ƒèŠ‚ B å¾—åˆ°ä¸€æ¡è¿ç»­çš„ Pareto æ›²çº¿ï¼›
   - åº”ç”¨å¯æ ¹æ®åœºæ™¯é€‰æ‹©æ“ä½œç‚¹ï¼ˆä¿å®ˆ or æ¿€è¿›ï¼‰ã€‚

---

### âš ï¸ å±€é™æ€§
| é—®é¢˜ | è¯´æ˜ |
|------|------|
| **éœ€æ‰‹åŠ¨è®¾ç½® expert budget B** | ç¼ºä¹è‡ªåŠ¨è°ƒå‚æœºåˆ¶ï¼Œéƒ¨ç½²æ—¶éœ€æ ¹æ®ä»»åŠ¡æ ¡å‡† |
| **router-based ranking å¿½ç•¥ä¸“å®¶é—´ä¾èµ–** | å­˜åœ¨çº¦ 25% çš„ä¼˜åŒ–ç©ºé—´ï¼ˆç›¸æ¯” Oracleï¼‰ |
| **å° draft tree ä¸‹å¯èƒ½æ— æ”¶ç›Š** | routing aggregation å¼€é”€å  ~2â€“3%ï¼Œæå°æ ‘æ—¶å¯èƒ½æŠµæ¶ˆèŠ‚çœ |
| **é™æ€ batching åœºæ™¯å¢ç›Šæœ‰é™** | å¤šè¯·æ±‚å…±äº«ä¸“å®¶æ—¶è¾¹é™…æˆæœ¬ä¸‹é™ï¼Œbudgeting æ•ˆç›Šå‡å¼± |
| **ä¾èµ– softmax routing** | å¯¹ DeepSeek-V3 ç­‰ sigmoid-based routing éœ€é€‚é… |

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **è®¾è®¡æ›´å¥½çš„ expert selection ç­–ç•¥**ï¼š
   - å¼•å…¥å»ºæ¨¡ä¸“å®¶ co-activation æ¨¡å¼çš„è½»é‡é¢„æµ‹å™¨ï¼›
   - åˆ©ç”¨ clustering æˆ–å›¾ç»“æ„æ•æ‰ expert group ç»“æ„ã€‚

2. **åˆ†å±‚è‡ªé€‚åº” budgeting**ï¼š
   - ä¸åŒ MoE layer è®¾ç½®ä¸åŒ Bï¼ˆæµ…å±‚å®½æ¾ï¼Œæ·±å±‚ç´§ç¼©ï¼‰ã€‚

3. **ç»“åˆå‹ç¼©æŠ€æœ¯**ï¼š
   - ä¸ MoE pruningã€quantizationã€offloading ç­‰æ­£äº¤æ–¹æ³•å åŠ ä½¿ç”¨ã€‚

4. **åŠ¨æ€ budget æ§åˆ¶**ï¼š
   - æ ¹æ®è¾“å…¥ç±»å‹ï¼ˆcode vs. mathï¼‰å®æ—¶è°ƒæ•´ Bã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **MoE-Spec æ­ç¤ºäº† MoE æ¨ç†ä¸­â€œéªŒè¯å³ç“¶é¢ˆâ€çš„æœ¬è´¨ï¼Œå¹¶é€šè¿‡ç®€å•çš„ expert budgeting æœºåˆ¶ï¼Œåœ¨ä¸æŸå¤±è´¨é‡çš„å‰æä¸‹å°† speculative decoding çš„ååæå‡äº† 10â€“30%ï¼Œä¸ºé«˜æ•ˆ MoE æ¨ç†æä¾›äº†æ–°çš„åŸºç¡€è®¾æ–½çº§ä¼˜åŒ–æ€è·¯ã€‚**

</details>

---

### 3. [Supercharging Agenda Setting Research: The ParlaCAP Dataset of 28 European Parliaments and a Scalable Multilingual LLM-Based Classification](https://arxiv.org/abs/2602.16516)

**Authors**: Taja Kuzman Punger\v{s}ek, Peter Rupnik, Daniela \v{S}irini\'c, Nikola Ljube\v{s}i\'c  
**Category**: cs.CL  
**Published**: 2026-02-19  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.16516v1  

#### Abstract
This paper introduces ParlaCAP, a large-scale dataset for analyzing parliamentary agenda setting across Europe, and proposes a cost-effective method for building domain-specific policy topic classifiers. Applying the Comparative Agendas Project (CAP) schema to the multilingual ParlaMint corpus of ov...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Supercharging Agenda Setting Research: The ParlaCAP Dataset of 28 European Parliaments and a Scalable Multilingual LLM-Based Classification*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **Comparative Agendas Project (CAP)** ç ”ç©¶ä¾èµ–å¤§é‡äººå·¥æ ‡æ³¨æ”¿ç­–è®®é¢˜æ ‡ç­¾ï¼Œé™åˆ¶äº†è·¨å›½å®¶ã€é•¿æ—¶é—´è·¨åº¦çš„è®®ä¼šè¯è¯­æ¯”è¾ƒç ”ç©¶ã€‚ç°æœ‰è‡ªåŠ¨åˆ†ç±»æ¨¡å‹å¤šåŸºäº**éé¢†åŸŸå†…ï¼ˆout-of-domainï¼‰** æ•°æ®è®­ç»ƒï¼ˆå¦‚æ–°é—»æˆ–è¡Œæ”¿æ–‡ä»¶ï¼‰ï¼Œåœ¨å¤„ç†è®®ä¼šè¯­å¢ƒæ—¶è¡¨ç°ä¸ä½³ã€‚

æœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- å¦‚ä½•é«˜æ•ˆã€ä½æˆæœ¬åœ°ä¸ºå¤§è§„æ¨¡å¤šè¯­è¨€è®®ä¼šè¯­æ–™ï¼ˆå¦‚ ParlaMintï¼‰è¿›è¡Œ CAP æ”¿ç­–ä¸»é¢˜æ ‡æ³¨ï¼›
- å¦‚ä½•æ„å»ºä¸€ä¸ª**é¢†åŸŸé€‚é…æ€§å¼ºã€é«˜ç²¾åº¦ã€å¯æ‰©å±•çš„å¤šè¯­è¨€æ”¿ç­–è¯é¢˜åˆ†ç±»å™¨**ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
æå‡ºäº†ä¸€ç§ **LLM teacher-student æ¡†æ¶**ï¼Œç”¨äºæ„å»ºé¢†åŸŸä¸“ç”¨çš„å¤šè¯­è¨€æ”¿ç­–è¯é¢˜åˆ†ç±»å™¨ï¼š
1. **Teacher é˜¶æ®µ**ï¼šä½¿ç”¨å¼ºå¤§çš„é—­æº LLMï¼ˆGPT-4oï¼‰è‡ªåŠ¨æ ‡æ³¨è®­ç»ƒæ•°æ®ï¼›
2. **Student é˜¶æ®µ**ï¼šç”¨ LLM æ ‡æ³¨çš„æ•°æ®å¾®è°ƒè½»é‡çº§å¤šè¯­è¨€ BERT æ¨¡å‹ï¼ˆå¦‚ XLM-RoBERTa å’Œ XLM-R-Parlaï¼‰ï¼Œå®ç°é«˜æ•ˆæ¨ç†ã€‚

æ­¤å¤–ï¼Œå¼•å…¥äº†é’ˆå¯¹ç¨€æœ‰ç±»åˆ«ï¼ˆå¦‚ *Public Lands*ï¼‰çš„**åŸºäºå…³é”®è¯æ£€ç´¢ + LLM è¿‡æ»¤çš„æ•°æ®å¢å¼ºç­–ç•¥**ï¼Œæœ‰æ•ˆç¼“è§£æ•°æ®ä¸å¹³è¡¡é—®é¢˜ã€‚

### â­ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | æœ¬æ–‡æ–¹æ³•ï¼ˆParlaCAPï¼‰ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ CAP Babel Machineï¼‰ |
|------|------------------------|-------------------------------|
| **è®­ç»ƒæ•°æ®æ¥æº** | é¢†åŸŸå†…ï¼ˆin-domainï¼‰è®®ä¼šè¯­æ–™ï¼ˆParlaMintï¼‰ | è·¨é¢†åŸŸï¼ˆæ–°é—»ã€é¢„ç®—æ–‡ä»¶ç­‰ï¼‰ |
| **æ ‡æ³¨æ–¹å¼** | LLM è‡ªåŠ¨ç”Ÿæˆï¼ˆæˆæœ¬ä½ã€å¯æ‰©å±•ï¼‰ | äººå·¥æ ‡æ³¨ï¼ˆæ˜‚è´µã€è€—æ—¶ï¼‰ |
| **æ¨¡å‹é€‚ç”¨æ€§** | ä¸“ä¸ºè®®ä¼šè¯è¯­ä¼˜åŒ– | æ³›åŒ–äºå¤šç§æ–‡æœ¬ç±»å‹ |
| **æ€§èƒ½è¡¨ç°** | åœ¨è®®ä¼šæ•°æ®ä¸Šæ˜¾è‘—æ›´ä¼˜ | åœ¨ç›®æ ‡é¢†åŸŸå¤–æ³›åŒ–èƒ½åŠ›æœ‰é™ |

> ğŸ’¡ **æ ¸å¿ƒåˆ›æ–°**ï¼šé¦–æ¬¡å°† LLM ä½œä¸ºé«˜è´¨é‡â€œè™šæ‹Ÿæ ‡æ³¨å‘˜â€åº”ç”¨äº CAP æ”¿ç­–åˆ†ç±»ä»»åŠ¡ï¼Œå¹¶éªŒè¯å…¶å¯é æ€§æ¥è¿‘äººç±»æ°´å¹³ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
| ç±»å‹ | åç§° | æè¿° |
|------|------|------|
| **è®­ç»ƒæ•°æ®** | `ParlaMint 4.1` | æ¥è‡ª 29 ä¸ªæ¬§æ´²å›½å®¶/åœ°åŒºçš„è®®ä¼šè¯­æ–™ï¼Œå…± 34,800 æ¡æ¼”è®²ï¼›ç» GPT-4o è‡ªåŠ¨æ ‡æ³¨åæ‰©å……è‡³ 35,579 æ¡ï¼ˆå« Public Lands å¢å¼ºï¼‰ |
| **æµ‹è¯•æ•°æ®** | `ParlaCAP-test` | å››ç§è¯­è¨€çš„äººå·¥æ ‡æ³¨æµ‹è¯•é›†ï¼š<br>- è‹±è¯­ï¼ˆEN, 876 æ¡ï¼‰<br>- å…‹ç½—åœ°äºšè¯­ï¼ˆHR, 869 æ¡ï¼‰<br>- å¡å°”ç»´äºšè¯­ï¼ˆSR, 874 æ¡ï¼‰<br>- æ³¢æ–¯å°¼äºšè¯­ï¼ˆBS, 824 æ¡ï¼‰<br>æ¯ç±»çº¦å¹³è¡¡é‡‡æ ·ï¼Œæ’é™¤ "do not know" å’Œ "Other"/"Mix" |
| **æœ€ç»ˆåº”ç”¨æ•°æ®** | `ParlaMint 5.0` | åŒ…å«è¶…è¿‡ **800 ä¸‡æ¡**æ¥è‡ª 28 ä¸ªè®®ä¼šçš„æ¼”è®²ï¼Œç”¨äºç”Ÿæˆå®Œæ•´çš„ **ParlaCAP dataset** |

### ğŸ§ª å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ ‡ç­¾ä½“ç³»**ï¼šé‡‡ç”¨ CAP çš„ 21 ä¸ªä¸»ç±»åˆ« + æ–°å¢ "Other" ç±»åˆ« â†’ å…± **22 ç±»**ã€‚
- **æ¨¡å‹æ¶æ„**ï¼š
  - Student æ¨¡å‹å€™é€‰ï¼š`XLM-RoBERTa-large` å’Œ `XLM-R-Parla`ï¼ˆåè€…é¢å¤–é¢„è®­ç»ƒäºè®®ä¼šè¯­æ–™ï¼‰
  - Teacher æ¨¡å‹ï¼š`GPT-4o`ï¼ˆä»…ç”¨äºæ ‡æ³¨ï¼Œä¸ç›´æ¥éƒ¨ç½²ï¼‰
- **å¾®è°ƒé…ç½®**ï¼š
  - å­¦ä¹ ç‡ï¼š1e-5
  - Epochsï¼š3
  - Batch sizeï¼š16
  - ä¸‰æ¬¡é‡å¤è®­ç»ƒä»¥æ”¯æŒæ˜¾è‘—æ€§æ£€éªŒ
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - ä¸»è¦ï¼š**macro-F1**, **micro-F1**, **accuracy**
  - å¯é æ€§åˆ†æï¼š**Krippendorffâ€™s alpha**ï¼ˆè¡¡é‡äºº-äººã€äºº-LLM ä¸€è‡´æ€§ï¼‰

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
å¯¹æ¯”äº† Sebok et al. (2024) å¼€å‘çš„å¤šä¸ªå…¬å¼€å¯ç”¨çš„ CAP åˆ†ç±»æ¨¡å‹ï¼Œå‡åŸºäº `xlm-roberta-large` å¾®è°ƒï¼Œä½†åœ¨ä¸åŒé¢†åŸŸæ•°æ®ä¸Šè®­ç»ƒï¼š
- `party-cap`, `parlspeech-cap`, `execspeech-cap`, `media-cap`, `budget-cap`, `social-cap` ç­‰ç³»åˆ—æ¨¡å‹

è¿™äº›æ¨¡å‹ä»£è¡¨å½“å‰ä¸»æµåšæ³•â€”â€”ä½¿ç”¨æ‰‹åŠ¨æ ‡æ³¨ä½†éè®®ä¼šåŸç”Ÿæ•°æ®è¿›è¡Œè®­ç»ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 2 & Table 3ï¼‰

#### è¡¨ï¼šå„æ¨¡å‹åœ¨å››è¯­è¨€æµ‹è¯•é›†ä¸Šçš„ macro-F1 è¡¨ç°ï¼ˆTable 2ï¼‰
| Model | EN | HR | SR | BS |
|-------|-----|-----|-----|-----|
| **ParlaCAP (XLM-R-Parla + PL)** | **0.72** | **0.68** | **0.71** | **0.64** |
| XLM-R-Parla (w/o PL) | 0.70 | 0.66 | 0.68 | 0.62 |
| XLM-RoBERTa (baseline) | 0.68 | 0.65 | 0.67 | 0.63 |
| GPT-4oï¼ˆä¸Šé™å‚è€ƒï¼‰ | 0.74 | 0.68 | 0.72 | 0.63 |

âœ… **ç»“è®º**ï¼š  
- ä½¿ç”¨ **XLM-R-Parla** å¹¶åŠ å…¥ **Public Lands æ•°æ®å¢å¼º**çš„æ¨¡å‹è¡¨ç°æœ€ä½³ï¼›
- æ€§èƒ½å·²æ¥è¿‘ GPT-4o ä¸Šé™ï¼Œä¸”è¿œä¼˜äºåŸºç¡€ XLM-RoBERTaï¼›
- åœ¨æ‰€æœ‰è¯­è¨€ä¸Šå‡å–å¾—æœ€ä¼˜ç»“æœã€‚

#### åŠ å…¥ç½®ä¿¡åº¦è¿‡æ»¤åçš„æœ€ç»ˆæ€§èƒ½ï¼ˆTable 3ï¼‰
è®¾å®šé¢„æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ä¸º **0.60**ï¼Œä½äºè¯¥å€¼æ ‡è®°ä¸º "Mix"ï¼ˆä¸ç¡®å®šï¼‰ï¼Œå…¶ä½™ä¿ç•™ï¼š

| Dataset | Micro-F1 | Macro-F1 | Accuracy |
|--------|----------|----------|----------|
| EN | 0.76 | 0.76 | 0.76 |
| HR | 0.72 | 0.73 | 0.72 |
| SR | 0.75 | 0.74 | 0.75 |
| BS | 0.69 | 0.68 | 0.69 |

ğŸ“Œ è¯´æ˜ï¼šé€šè¿‡è¿‡æ»¤ä½ç½®ä¿¡æ ·æœ¬ï¼Œå¯åœ¨ **çº¦ 90% æ•°æ®ä¸Šå®ç°é«˜è¾¾ 0.76 çš„ F1 åˆ†æ•°**ï¼Œå…·å¤‡å®é™…åº”ç”¨ä»·å€¼ã€‚

### ğŸ” ä¸ç°æœ‰ CAP æ¨¡å‹çš„å¯¹æ¯”ï¼ˆTable 4ï¼‰
| Model Type | EN | HR | SR | BS |
|-----------|-----|-----|-----|-----|
| **ParlaCAP** | **0.72** | **0.69** | **0.71** | **0.65** |
| CAP Babel Machine variants | 0.52â€“0.64 | 0.44â€“0.63 | 0.48â€“0.62 | 0.46â€“0.57 |

âœ… **å…³é”®å‘ç°**ï¼š  
> æ‰€æœ‰åŸºäºå…¶ä»–é¢†åŸŸæ•°æ®å¾®è°ƒçš„ CAP æ¨¡å‹ï¼Œåœ¨è®®ä¼šæ•°æ®ä¸Šçš„è¡¨ç°**å…¨é¢è½åäº ParlaCAP**ï¼Œå³ä½¿å®ƒä»¬ä¹Ÿä½¿ç”¨ç›¸åŒçš„ backbone æ¨¡å‹ã€‚

è¿™è¯æ˜ï¼š**é¢†åŸŸå¯¹é½çš„è®­ç»ƒæ•°æ®æ¯”æ ‡æ³¨è´¨é‡æœ¬èº«æ›´é‡è¦** â€”â€” å³ä½¿æ˜¯ LLM è‡ªåŠ¨ç”Ÿæˆçš„æ ‡æ³¨ï¼Œåªè¦æ¥è‡ªç›®æ ‡é¢†åŸŸï¼Œä¹Ÿèƒ½è®­ç»ƒå‡ºæ›´ä¼˜æ¨¡å‹ã€‚

### ğŸ”¬ æ¶ˆèå®éªŒä¸å…³é”®éªŒè¯

#### ï¼ˆ1ï¼‰LLM æ˜¯å¦å¯é ï¼Ÿâ€”â€” ä¸äººç±»æ ‡æ³¨è€…çš„ä¸€è‡´æ€§
- ä¸‰ä½äººç±»æ ‡æ³¨å‘˜ä¹‹é—´çš„ Krippendorffâ€™s alphaï¼š**0.59â€“0.68**
- äººç±» vs GPT-4o çš„ä¸€è‡´æ€§ï¼š**0.60â€“0.64**

ğŸ‘‰ ç»“è®ºï¼š**GPT-4o çš„æ ‡æ³¨è´¨é‡ä¸äººç±»ç›¸å½“**ï¼Œæ”¯æŒå…¶ä½œä¸ºâ€œæ•™å¸ˆâ€çš„åˆç†æ€§ã€‚

#### ï¼ˆ2ï¼‰æ•°æ®å¢å¼ºæ•ˆæœï¼ˆPublic Landsï¼‰
- åŸå§‹è®­ç»ƒé›†ä¸­ Public Lands ä»…æœ‰ ~145 æ¡ï¼›
- ç»å…³é”®è¯æ£€ç´¢ + GPT-4o è¿‡æ»¤åæ–°å¢ 779 æ¡ï¼›
- å¯¹åº”ç±»åˆ« F1 åˆ†æ•°ä» **0.30 æå‡è‡³ 0.80**ï¼

âœ… æ˜¾è‘—æ”¹å–„é•¿å°¾ç±»åˆ«æ€§èƒ½ï¼ŒéªŒè¯äº†â€œfind the needle in a haystackâ€ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **LLM å¯æ›¿ä»£äººå·¥æ ‡æ³¨**ï¼šGPT-4o åœ¨ CAP æ”¿ç­–åˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°ä¸äººç±»æ ‡æ³¨å‘˜ä¸€è‡´ï¼Œå¯ç”¨äºä½æˆæœ¬ç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®ã€‚
2. **é¢†åŸŸé€‚é…è‡³å…³é‡è¦**ï¼šåœ¨è®®ä¼šè¯­æ–™ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼ˆå³ä½¿ä½¿ç”¨ LLM æ ‡æ³¨ï¼‰æ˜¾è‘—ä¼˜äºåœ¨å…¶ä»–é¢†åŸŸï¼ˆå¦‚åª’ä½“ã€é¢„ç®—ï¼‰ä¸Šè®­ç»ƒçš„ä¼ ç»Ÿæ¨¡å‹ã€‚
3. **Teacher-Student æ¡†æ¶é«˜æ•ˆå¯è¡Œ**ï¼šåˆ©ç”¨ LLM æ„å»ºè®­ç»ƒé›† + å¾®è°ƒå°å‹ BERT æ¨¡å‹ï¼Œå®ç°äº†é«˜æ€§èƒ½ä¸é«˜æ•ˆç‡çš„ç»Ÿä¸€ã€‚
4. **ParlaCAP æ•°æ®é›†å…·æœ‰é‡å¤§ç ”ç©¶ä»·å€¼**ï¼šæä¾›è¦†ç›– 28 å›½ã€800 ä¸‡æ¡æ¼”è®²çš„ç»“æ„åŒ–æ•°æ®ï¼ŒåŒ…å«ï¼š
   - CAP æ”¿ç­–ä¸»é¢˜æ ‡ç­¾
   - ParlaSent æƒ…æ„Ÿåˆ†æç»“æœï¼ˆæ­£/ä¸­/è´Ÿï¼‰
   - ä¸°å¯Œçš„ speaker å’Œ party metadataï¼ˆæ”¿å…šèº«ä»½ã€æ€§åˆ«ã€èŒä½ç­‰ï¼‰

### âš ï¸ å±€é™æ€§
- æµ‹è¯•é›†æœªå…¬å¼€å‘å¸ƒï¼ˆé˜²æ­¢æ±¡æŸ“ LLM é¢„è®­ç»ƒï¼‰ï¼Œå¯èƒ½å½±å“å¤ç°ä¸å¤–éƒ¨éªŒè¯ï¼›
- å½“å‰æ¨¡å‹ä»ä¾èµ–è‹±æ–‡ç¿»è¯‘ç‰ˆæœ¬ï¼ˆParlaMint.en-anaï¼‰è¿›è¡Œå…³é”®è¯æ£€ç´¢ï¼Œå­˜åœ¨ç¿»è¯‘è¯¯å·®é£é™©ï¼›
- â€œOtherâ€ ç±»å æ¯”é«˜ï¼ˆå°¤å…¶åœ¨ BS æ•°æ®ä¸­è¾¾ 10.4%ï¼‰ï¼Œåæ˜ éƒ¨åˆ†è®®ä¼šå‘è¨€é«˜åº¦ç¨‹åºåŒ–æˆ–æƒ…ç»ªåŒ–ï¼Œé™ä½è®®é¢˜è¯†åˆ«è¦†ç›–ç‡ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å°†æ¡†æ¶æ‰©å±•è‡³æ›´å¤šæ”¿ç­–ç¼–ç ä½“ç³»ï¼ˆå¦‚ UN Sustainable Development Goalsï¼‰ï¼›
- æ¢ç´¢å®Œå…¨å¼€æº LLMï¼ˆå¦‚ Llama ç³»åˆ—ï¼‰æ›¿ä»£é—­æº GPT-4oï¼Œæå‡å¯å¤åˆ¶æ€§ï¼›
- ç»“åˆåŠ¨æ€æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°ç»†ç²’åº¦å¥å­çº§è®®é¢˜è¿½è¸ªï¼›
- åˆ©ç”¨ ParlaCAP æ•°æ®å¼€å±•è·¨å›½æ°‘ä¸»ä»£è¡¨æ€§ã€è®®ç¨‹ç«äº‰ã€æ€§åˆ«æ”¿æ²»ç­‰æ·±å±‚ç¤¾ä¼šç§‘å­¦ç ”ç©¶ã€‚

---

## ğŸ“¦ é™„åŠ èµ„æº
- **ParlaCAP åˆ†ç±»å™¨**ï¼š[Hugging Face](https://www.doi.org/10.57967/hf/6684)
- **ParlaCAP æ•°æ®é›†**ï¼š[CROSSDA Repository](https://doi.org/10.23669/1ZTELP)
- **ä»£ç ä¸æ•™ç¨‹**ï¼š[GitHub - ParlaCAP Analysis Tutorials](https://github.com/clarinsi/ParlaCAP-Analysis-Tutorials)

> æœ¬æ–‡æ ‡å¿—ç€ NLP æŠ€æœ¯èµ‹èƒ½æ”¿æ²»ç§‘å­¦çš„å¤§è§„æ¨¡å®è¯ç ”ç©¶è¿ˆå…¥æ–°é˜¶æ®µï¼Œä¸º agenda setting ç†è®ºæä¾›äº†å‰æ‰€æœªæœ‰çš„æ•°æ®åŸºç¡€å’ŒæŠ€æœ¯å·¥å…·ã€‚

</details>

---

### 4. [DistributedEstimator: Distributed Training of Quantum Neural Networks via Circuit Cutting](https://arxiv.org/abs/2602.16233)

**Authors**: Prabhjot Singh, Adel N. Toosi, Rajkumar Buyya  
**Category**: cs.DC  
**Published**: 2026-02-19  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.16233v1  

#### Abstract
Circuit cutting decomposes a large quantum circuit into a collection of smaller subcircuits. The outputs of these subcircuits are then classically reconstructed to recover the original expectation values. While prior work characterises cutting overhead largely in terms of subcircuit counts and sampl...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šDistributedEstimator: Distributed Training of Quantum Neural Networks via Circuit Cutting**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å½“å‰é‡å­æœºå™¨å­¦ä¹ ï¼ˆQMLï¼‰ä¸­çš„ **Variational Quantum Algorithms (VQAs)** å’Œ **Quantum Neural Networks (QNNs)** åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é¢ä¸´ç¡¬ä»¶é™åˆ¶ï¼šå®é™…å¯ç”¨çš„é‡å­è®¾å¤‡ï¼ˆå¦‚NISQè®¾å¤‡ï¼‰åœ¨å®½åº¦ï¼ˆqubitæ•°é‡ï¼‰ã€æ·±åº¦å’Œä¿çœŸåº¦ä¸Šæ— æ³•ç›´æ¥æ‰§è¡Œå¤§è§„æ¨¡é‡å­ç”µè·¯ã€‚è™½ç„¶ **Circuit Cutting** æŠ€æœ¯å¯ä»¥å°†å¤§ç”µè·¯åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„å­ç”µè·¯ï¼Œä½†å…¶ç³»ç»Ÿçº§å¼€é”€ï¼ˆå¦‚è°ƒåº¦ã€é‡æ„æ—¶é—´ã€åè°ƒæˆæœ¬ï¼‰å°šæœªè¢«å……åˆ†é‡åŒ–ã€‚

ç°æœ‰ç ”ç©¶å¤šä»ç®—æ³•è§’åº¦åˆ†æåˆ‡å‰²çš„ç†è®ºå¼€é”€ï¼ˆå¦‚å­ç”µè·¯æ•°é‡ã€é‡‡æ ·å¤æ‚åº¦ï¼‰ï¼Œä½†ç¼ºä¹å¯¹ **end-to-endè®­ç»ƒæµç¨‹ä¸­çœŸå®è¿è¡Œæ—¶å¼€é”€** çš„æµ‹é‡ï¼Œå°¤å…¶æ˜¯åœ¨åˆ†å¸ƒå¼å¹¶è¡Œæ‰§è¡Œä¸‹çš„æ€§èƒ½ç“¶é¢ˆã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡º **DistributedEstimator** â€”â€” ä¸€ç§**æ˜¾å¼å»ºæ¨¡Circuit Cuttingä¸ºåˆ†é˜¶æ®µåˆ†å¸ƒå¼å·¥ä½œæµ**çš„æ‰§è¡Œæ¡†æ¶ï¼Œå¹¶å¼•å…¥**ç»†ç²’åº¦ä»ªå™¨åŒ–ï¼ˆinstrumentationï¼‰æœºåˆ¶**ï¼Œå°†æ¯ä¸ªEstimatoræŸ¥è¯¢åˆ†è§£ä¸ºä»¥ä¸‹å››ä¸ªé˜¶æ®µè¿›è¡Œç›‘æ§ï¼š

1. **Partitioning**ï¼šé€‰æ‹©åˆ‡å‰²ä½ç½®ï¼Œç”Ÿæˆå­ç”µè·¯åˆ’åˆ†æ–¹æ¡ˆ  
2. **Subexperiment Generation**ï¼šç”Ÿæˆæ‰€æœ‰éœ€æ‰§è¡Œçš„å­å®éªŒåŠå…¶é‡å»ºç³»æ•°  
3. **Parallel Execution**ï¼šåœ¨åˆ†å¸ƒå¼workeræ± ä¸­å¹¶è¡Œæ‰§è¡Œå­ä»»åŠ¡  
4. **Classical Reconstruction**ï¼šèšåˆç»“æœä»¥æ¢å¤åŸå§‹æœŸæœ›å€¼  

è¯¥æ¡†æ¶é¦–æ¬¡å°†Circuit Cuttingè§†ä¸ºä¸€ä¸ªå…¸å‹çš„ **staged distributed pipeline**ï¼ˆç±»ä¼¼MapReduceï¼‰ï¼Œä»è€Œå¯ä»¥ä»ç³»ç»Ÿå±‚é¢åˆ†æå…¶æ€§èƒ½ç‰¹å¾ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **ç³»ç»Ÿè§†è§’åˆ›æ–°**ï¼šä¸åŒäºä»¥å¾€ä»…å…³æ³¨â€œèƒ½åˆ‡â€æˆ–â€œå¤šå°‘æ¬¡é‡‡æ ·â€ï¼Œæœ¬å·¥ä½œèšç„¦äºâ€œ**å¢™é’Ÿæ—¶é—´ï¼ˆwall-clock timeï¼‰å»å“ªäº†**â€ï¼Œæ­ç¤ºäº†çœŸå®è®­ç»ƒä¸­çš„æ€§èƒ½ç“¶é¢ˆã€‚
- **ç«¯åˆ°ç«¯å¯æµ‹é‡æ€§**ï¼šé€šè¿‡æ—¥å¿—è®°å½•å„é˜¶æ®µè€—æ—¶ï¼Œæ”¯æŒå¯¹å¼€é”€æ¥æºçš„ç²¾ç¡®å½’å› ï¼ˆoverhead attributionï¼‰ã€‚
- **æ”¯æŒè°ƒåº¦ç­–ç•¥è¯„ä¼°**ï¼šå…è®¸å®ç°ä¸åŒçš„ä»»åŠ¡è°ƒåº¦ç­–ç•¥ï¼ˆå¦‚staggeringï¼‰ï¼Œç”¨äºç¼“è§£straggleræ•ˆåº”ã€‚
- **è”åˆè¯„ä¼°æ¨¡å‹è´¨é‡**ï¼šä¸ä»…çœ‹é€Ÿåº¦ï¼Œè¿˜åŒæ­¥è¿½è¸ªå‡†ç¡®ç‡ï¼ˆaccuracyï¼‰å’Œé²æ£’æ€§ï¼ˆrobustnessï¼‰ï¼Œç¡®ä¿æ€§èƒ½æå‡ä¸ä»¥ç‰ºç‰²æ¨¡å‹è´¨é‡ä¸ºä»£ä»·ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **Iris**ï¼šç»å…¸ä¸‰ç±»é¸¢å°¾èŠ±æ•°æ®é›†ï¼ŒäºŒåˆ†ç±»ç‰ˆæœ¬ç”¨äºæµ‹è¯•ï¼ˆ`iris_binary_pml`ï¼‰
- **MNIST**ï¼šæ‰‹å†™æ•°å­—æ•°æ®é›†ï¼Œæ„å»ºä¸ºäºŒåˆ†ç±»ä»»åŠ¡ï¼ˆå¦‚0 vs é0ï¼‰

### **å®éªŒè®¾ç½®**
- **æ¨¡å‹ç»“æ„**ï¼š
  - Feature Map: `ZFeatureMap`
  - Ansatz: `RealAmplitudes`ï¼ˆé‡å¤æ¬¡æ•° reps=1ï¼‰
  - Observable: Pauli-Z tensor productï¼ˆ`SparsePauliOp`ï¼‰
- **è®­ç»ƒåè®®å›ºå®š**ï¼š
  - Shoté¢„ç®—ç»Ÿä¸€ä¸º **1024 shots per (sub)experiment**
  - ä½¿ç”¨ç›¸åŒä¼˜åŒ–å™¨ï¼ˆPyTorch SGDï¼‰å’Œè®­ç»ƒè½®æ•°ï¼ˆbudgetï¼‰
  - ç§å­ï¼ˆseedï¼‰æ§åˆ¶å˜é‡ï¼Œä¿è¯å¯æ¯”æ€§
- **åˆ‡å‰²é…ç½®**ï¼š
  - å¯¹æ¯”ä¸åŒåˆ‡å‰²æ•°é‡ï¼š`NO_CUT`, `1-cut`, `2-cut`, `3-cut`
  - åˆ‡å‰²ç”± `qiskit-addon-cutting` è‡ªåŠ¨å®Œæˆ
- **åˆ†å¸ƒå¼æ‰§è¡Œç¯å¢ƒ**ï¼š
  - åŸºäºçº¿ç¨‹æ± æ¨¡æ‹Ÿworkeræ± ï¼ˆ`subexp_workers`ï¼‰
  - workeræ•°é‡ä»1åˆ°16å˜åŒ–ï¼Œç”¨äºåˆ†ææ‰©å±•æ€§
- **æ³¨å…¥straggleræ§åˆ¶**ï¼š
  - æ¨¡æ‹Ÿå¼‚æ„å»¶è¿Ÿï¼šéƒ¨åˆ†å­ä»»åŠ¡éšæœºå»¶è¿Ÿ0.1ç§’ï¼ˆæ¦‚ç‡p=0.2ï¼‰ï¼Œç”¨äºæµ‹è¯•å°¾éƒ¨å»¶è¿Ÿæ•æ„Ÿæ€§

### **è¯„ä¼°æŒ‡æ ‡**
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **ç³»ç»Ÿæ€§èƒ½** | `T_total`, `T_part`, `T_gen`, `T_exec`, `T_rec`, Speedup, Reconstructionå æ¯” (`T_rec / T_total`) |
| **æ‰©å±•æ€§** | ä¸åŒworkeræ•°ä¸‹çš„åŠ é€Ÿæ¯” |
| **å®¹é”™æ€§** | æ³¨å…¥straggleråçš„ç›¸å¯¹æ…¢åŒ–ï¼ˆslowdown ratioï¼‰ |
| **å­¦ä¹ æ•ˆæœ** | Test Accuracyï¼ˆæµ‹è¯•å‡†ç¡®ç‡ï¼‰ |
| **é²æ£’æ€§** | åœ¨Gaussianå™ªå£°å’ŒFGSMæ”»å‡»ä¸‹çš„å¹³å‡å‡†ç¡®ç‡ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Baseline**: æ— åˆ‡å‰²ï¼ˆ`NO_CUT`ï¼‰çš„åŸå§‹ç”µè·¯æ‰§è¡Œ
- **Cut Variants**: åŒä¸€æ¨¡å‹ä¸‹å¯ç”¨1~3æ¬¡circuit cutting
- æ‰€æœ‰æ¯”è¾ƒå‡åœ¨**ç›¸åŒshoté¢„ç®—ã€è®­ç»ƒè¿­ä»£æ•°ã€ç§å­ã€ç¡¬ä»¶æ¨¡æ‹Ÿå™¨ï¼ˆAerï¼‰** ä¸‹è¿›è¡Œï¼Œç¡®ä¿å…¬å¹³

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **RQ1: Cuttingå¼•å…¥æ˜¾è‘—ç«¯åˆ°ç«¯å¼€é”€**
- å›¾4æ˜¾ç¤ºï¼Œåœ¨Iriså’ŒMNISTä¸Šï¼Œéšç€cutæ•°å¢åŠ ï¼Œæ€»è®­ç»ƒæ—¶é—´æ€¥å‰§ä¸Šå‡ã€‚
- ä¾‹å¦‚ï¼Œåœ¨Irisä¸Šï¼Œ3-cutæ¯”no-cutè®­ç»ƒæ—¶é—´é«˜å‡ºæ•°å€ï¼Œä¸”å¢é•¿éçº¿æ€§ï¼Œè¡¨æ˜å¼€é”€éšåˆ‡å‰²ç¨‹åº¦åŠ å‰§ã€‚

#### âœ… **RQ2: Reconstructionæˆä¸ºå…³é”®è·¯å¾„ç“¶é¢ˆ**
- è¡¨Iæ˜¾ç¤ºï¼Œéšç€cutæ•°å¢åŠ ï¼Œ**reconstructioné˜¶æ®µå å•æ¬¡queryæ€»æ—¶é—´çš„æ¯”ä¾‹æŒç»­å‡é«˜**ï¼š
  | #cuts | median T_rec/T_total | p95 T_rec/T_total |
  |-------|------------------------|--------------------|
  | 1     | 43.0%                  | 47.4%              |
  | 2     | 48.9%                  | 53.3%              |
  | 3     | 53.0%                  | 58.0%              |
- å³ä½¿å­ç”µè·¯å¯é«˜åº¦å¹¶è¡Œæ‰§è¡Œï¼Œä¸²è¡Œçš„reconstructionä»é™åˆ¶æ•´ä½“åŠ é€Ÿã€‚
- å›¾5æ˜¾ç¤ºï¼š**å³ä½¿workerä»1å¢è‡³16ï¼Œspeedupæ¥è¿‘1ç”šè‡³ä½äº1**ï¼Œè¯´æ˜å¹¶è¡ŒåŒ–æ”¶ç›Šè¢«åè°ƒä¸èšåˆå¼€é”€æŠµæ¶ˆã€‚

#### âœ… **RQ3: Straggleræ•æ„Ÿæ€§ä¾èµ–äºç“¶é¢ˆæ‰€åœ¨é˜¶æ®µ**
- å›¾6æ˜¾ç¤ºï¼Œåœ¨æ³¨å…¥straggleråï¼ŒæŸäº›é…ç½®ä¸‹è®­ç»ƒæ—¶é—´æ˜¾è‘—å»¶é•¿ã€‚
- ä½†æ•æ„Ÿæ€§å–å†³äºå½“å‰ç³»ç»Ÿçš„ç“¶é¢ˆï¼š
  - è‹¥å·²å¤„äº**reconstructionä¸»å¯¼çŠ¶æ€** â†’ executionä¾§å»¶è¿Ÿå½±å“è¾ƒå°
  - è‹¥ä»å¤„äº**executionä¸»å¯¼çŠ¶æ€** â†’ stragglerä¼šæ˜¾è‘—æ‹–æ…¢æ•´ä½“è¿›åº¦
- è¿™è¡¨æ˜ï¼šä»…ä¼˜åŒ–æ‰§è¡Œè°ƒåº¦ä¸è¶³ä»¥æ”¹å–„æ€§èƒ½ï¼Œå¿…é¡»ååŒè€ƒè™‘reconstructionè®¾è®¡ã€‚

#### âœ… **RQ4: å‡†ç¡®ç‡æœªä¸‹é™ï¼Œéƒ¨åˆ†æƒ…å†µä¸‹åè€Œæå‡**
- å›¾7æ˜¾ç¤ºï¼š
  - **Iris**: æ‰€æœ‰cuté…ç½®è¾¾åˆ°å®Œå…¨ç›¸åŒçš„test accuracyï¼ˆâ‰ˆ100%ï¼‰
  - **MNIST**: å¤šä¸ªcuté…ç½®çš„accuracyä¸baselineç›¸å½“ï¼Œä¸ªåˆ«ç”šè‡³æ›´é«˜
- è¡¨æ˜ï¼šå°½ç®¡estimatorå› åˆ‡å‰²è€Œæ”¹å˜ï¼ˆæ›´å¤šé‡‡æ ·+é‡æ„ï¼‰ï¼Œä½†**æœ€ç»ˆå­¦ä¹ ç»“æœæœªå—æŸ**ï¼Œä¸”å¯èƒ½å› å™ªå£°æ¨¡å¼å˜åŒ–å¸¦æ¥æœ‰ç›Šæ‰°åŠ¨ã€‚

#### âœ… **RQ5: é²æ£’æ€§ä¿æŒç¨³å®šï¼Œéƒ¨åˆ†é…ç½®æ›´ä¼˜**
- å›¾8æ˜¾ç¤ºï¼Œåœ¨Gaussianå’ŒFGSMæ‰°åŠ¨ä¸‹ï¼š
  - Irisï¼šrobustnessä¸clean accuracyä¸€è‡´ï¼Œæ— é€€åŒ–
  - MNISTï¼šå¤šä¸ªcuté…ç½®è¡¨ç°å‡ºä¸baselineç›¸å½“æˆ–æ›´é«˜çš„é²æ£’æ€§
- è¯´æ˜ï¼š**åˆ‡å‰²æœªæŸå®³æ¨¡å‹æ³›åŒ–èƒ½åŠ›å’ŒæŠ—æ”»å‡»èƒ½åŠ›**

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **Circuit Cuttingæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼æµæ°´çº¿é—®é¢˜**ï¼Œä¸èƒ½ä»…å½“ä½œç¼–è¯‘ä¼˜åŒ–å¤„ç†ã€‚
2. **Reconstructionæ˜¯ä¸»è¦æ€§èƒ½ç“¶é¢ˆ**ï¼Œå…¶ä¸²è¡Œç‰¹æ€§ä¸¥é‡åˆ¶çº¦å¹¶è¡Œæ‰©å±•æ½œåŠ›ï¼Œå³ä½¿æ‹¥æœ‰å¤§é‡workerä¹Ÿæ— æ³•æœ‰æ•ˆæé€Ÿã€‚
3. **ç«¯åˆ°ç«¯å¼€é”€éšcutæ•°å¿«é€Ÿå¢é•¿**ï¼Œä¸»è¦æ¥è‡ªå­ä»»åŠ¡æ•°é‡è†¨èƒ€å’Œèšåˆæˆæœ¬ï¼Œè€Œéåˆ‡å‰²è§„åˆ’æœ¬èº«ã€‚
4. **Stragglerçš„å½±å“å…·æœ‰ä¸Šä¸‹æ–‡ä¾èµ–æ€§**ï¼šå½“ç³»ç»Ÿå·²è¢«reconstructionç»‘å®šæ—¶ï¼Œexecutionä¼˜åŒ–æ”¶æ•ˆç”šå¾®ã€‚
5. **æ¨¡å‹æ€§èƒ½ï¼ˆaccuracy + robustnessï¼‰åœ¨å®æµ‹èŒƒå›´å†…å¾—ä»¥ä¿ç•™**ï¼Œç”šè‡³éƒ¨åˆ†cuté…ç½®è¡¨ç°æ›´å¥½ï¼Œè¯´æ˜åˆ‡å‰²å¸¦æ¥çš„estimatorå˜åŒ–æœªå¿…æœ‰å®³ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- å½“å‰å®éªŒåŸºäº**æ¨¡æ‹Ÿå™¨ï¼ˆAerï¼‰å’Œçº¿ç¨‹æ± **ï¼Œæœªæ¶‰åŠçœŸå®QPUsçš„æ’é˜Ÿã€ç½‘ç»œå»¶è¿Ÿã€æ‰¹å¤„ç†ç­‰ç°å®å› ç´ ã€‚
- Reconstructionç›®å‰ä¸º**é›†ä¸­å¼ä¸²è¡Œèšåˆ**ï¼Œæœªå°è¯•åˆ†å¸ƒå¼æˆ–å¢é‡å¼é‡æ„ã€‚
- è°ƒåº¦ç­–ç•¥è¾ƒç®€å•ï¼ˆå¦‚staggeringï¼‰ï¼Œå°šæœªé›†æˆæ›´å¤æ‚çš„speculative executionæˆ–work-stealingæœºåˆ¶ã€‚
- æ•°æ®é›†è§„æ¨¡æœ‰é™ï¼ˆIris/MNISTäºŒåˆ†ç±»ï¼‰ï¼Œå°šéœ€éªŒè¯åœ¨æ›´å¤§ã€æ›´æ·±æ¨¡å‹ä¸Šçš„æ™®é€‚æ€§ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **åˆ†å¸ƒå¼/å¢é‡å¼Reconstruction**ï¼š
   - è®¾è®¡æ ‘çŠ¶reduceæˆ–æµå¼èšåˆï¼Œå‡å°‘ç­‰å¾…æ—¶é—´ï¼Œå®ç°executionä¸reconstructioné‡å ã€‚
2. **æ–¹å·®æ„ŸçŸ¥è°ƒåº¦ï¼ˆVariance-aware Schedulingï¼‰**ï¼š
   - æ ¹æ®å­å®éªŒå¯¹ä¼°è®¡è¯¯å·®çš„è´¡çŒ®åŠ¨æ€åˆ†é…shotsæˆ–ä¼˜å…ˆçº§ï¼Œæé«˜æ•ˆç‡ã€‚
3. **æ˜¾å¼å°¾å»¶è¿Ÿç¼“è§£æœºåˆ¶**ï¼š
   - å¼•å…¥speculative executionã€task replicationç­‰ç­–ç•¥ï¼Œå¹¶ä½œä¸ºä¸€çº§å‚æ•°è®°å½•ä¸è¯„ä¼°ã€‚
4. **ç¡¬ä»¶çœŸå®éƒ¨ç½²éªŒè¯**ï¼š
   - åœ¨æ··åˆç¯å¢ƒä¸­ï¼ˆsimulator + real QPUï¼‰æµ‹è¯•ï¼Œçº³å…¥queueing delayã€network jitterç­‰å› ç´ ã€‚
5. **æ›´å¹¿æ³›çš„workloadè¦†ç›–**ï¼š
   - æ‰©å±•è‡³æ›´æ·±ansatzã€ä¸åŒfeature mapã€å¤šåˆ†ç±»ä»»åŠ¡ï¼Œå»ºç«‹é¢„æµ‹æ€§æ€§èƒ½æ¨¡å‹ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æ­ç¤ºäº† **Circuit Cutting çš„çœŸæ­£ç“¶é¢ˆä¸åœ¨é‡å­æ‰§è¡Œï¼Œè€Œåœ¨ç»å…¸é‡æ„ä¸åè°ƒ**ï¼›è¦å®ç°å¯æ‰©å±•çš„åˆ†å¸ƒå¼QNNè®­ç»ƒï¼Œå¿…é¡»å°† **reconstruction è§†ä¸ºå…³é”®ç³»ç»Ÿç»„ä»¶è¿›è¡Œä¼˜åŒ–**ï¼Œè€Œä¸ä»…ä»…æ˜¯â€œåå¤„ç†æ­¥éª¤â€ã€‚

</details>

---

### 5. [Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents](https://arxiv.org/abs/2602.16246)

**Authors**: Yun-Shiuan Chuang, Chaitanya Kulkarni, Alec Chiu, Avinash Thangali, Zijie Pan, Shivani Shekhar, Yirou Ge, Yixi Li, Uma Kona, Linsey Pang, Prakhar Mehrotra  
**Category**: cs.AI  
**Published**: 2026-02-19  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.16246v1  

#### Abstract
Interactive large language model (LLM) agents operating via multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchmarks for these agents must both reliably compare models and yield on-policy training data. Prior agentic benchmarks (e.g., tau-bench, tau2-bench, App...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents  
**è®ºæ–‡æ ¸å¿ƒæ€»ç»“**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰ç”¨äºè¯„ä¼°å¤šè½®ã€å¤šæ­¥ **Tool-Calling LLM Agents** çš„åŸºå‡†ï¼ˆå¦‚ T-benchã€AppWorldï¼‰ä¾èµ–äº**å®Œå…¨ç¡®å®šæ€§çš„åç«¯æ•°æ®åº“**ï¼ˆdeterministic backendï¼‰ï¼Œä»¥å®ç°åŸºäºæœ€ç»ˆçŠ¶æ€çš„è¯„ä¼°ï¼ˆstate-based evaluationï¼‰ã€‚ç„¶è€Œï¼Œæ„å»ºå’Œç»´æŠ¤è¿™ç±»ç³»ç»Ÿæˆæœ¬é«˜æ˜‚ï¼ˆä¾‹å¦‚ AppWorld æŠ¥å‘Šçº¦ 60K LOC å¼•æ“ä»£ç  + 40K LOC æµ‹è¯•ä»£ç ï¼‰ï¼Œä¸¥é‡é™åˆ¶äº†è¿­ä»£é€Ÿåº¦å’Œå·¥ä¸šéƒ¨ç½²çš„å¯æ‰©å±•æ€§ã€‚

è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³è¿™ä¸€å·¥ç¨‹ç“¶é¢ˆï¼š  
> **èƒ½å¦åœ¨ä¸æ„å»ºé‡å‹ç¡®å®šæ€§åç«¯çš„å‰æä¸‹ï¼Œä¿ç•™ state-based evaluation çš„ä¼˜åŠ¿ï¼Ÿ**

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šProxy State-Based Evaluation
æå‡ºäº†ä¸€ç§åä¸º **Proxy State-Based Evaluation** çš„æ–°å‹ä»¿çœŸè¯„ä¼°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **ç”¨ LLM é©±åŠ¨çš„çŠ¶æ€è¿½è¸ªå™¨ï¼ˆLLM state trackerï¼‰ä»å®Œæ•´çš„äº¤äº’è½¨è¿¹ä¸­æ¨æ–­å‡ºä¸€ä¸ªâ€œä»£ç†çŠ¶æ€â€ï¼ˆproxy stateï¼‰**ï¼Œæ›¿ä»£çœŸå®æ•°æ®åº“ï¼›
- åˆ©ç”¨ LLM judges å¯¹æ¯”ä»£ç†æœ€ç»ˆçŠ¶æ€ä¸é¢„æœŸç›®æ ‡ï¼Œåˆ¤æ–­ä»»åŠ¡æ˜¯å¦å®Œæˆï¼›
- æ•´ä¸ªç¯å¢ƒç”±å¤šä¸ªåä½œçš„ LLM ç»„ä»¶æ„æˆï¼Œå½¢æˆä¸€ä¸ªè½»é‡çº§ã€å¯å¿«é€Ÿæ­å»ºçš„â€œbenchmark-as-environmentâ€ã€‚

#### å…³é”®ç»„ä»¶ï¼ˆ5ä¸ªååŒ LLM æ¨¡å—ï¼‰ï¼š
| ç»„ä»¶ | åŠŸèƒ½ |
|------|------|
| **Reasoning Agent (RA)** | è¢«è¯„æµ‹çš„æ™ºèƒ½ä½“æ¨¡å‹ï¼Œæ‰§è¡Œ ReAct-style æ¨ç†ä¸å·¥å…·è°ƒç”¨ |
| **User Simulator (`fuser`)** | æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸ºï¼Œç”Ÿæˆç¬¦åˆ persona çš„æŸ¥è¯¢ |
| **Tool Simulators (`ftool`)** | æ¨¡æ‹Ÿå·¥å…·å“åº”ï¼Œè¯»å†™ proxy state |
| **State Tracker (`fstate`)** | ä»å¯¹è¯+å·¥å…·è°ƒç”¨å†å²ä¸­æ¨ç†ç»“æ„åŒ– proxy state |
| **LLM Judge (`J`)** | åˆ¤æ–­ç›®æ ‡æ˜¯å¦è¾¾æˆï¼Œå¹¶æ£€æµ‹ hallucination |

#### åœºæ™¯å®šä¹‰ï¼ˆScenario Schemaï¼‰
æ¯ä¸ªä»»åŠ¡é€šè¿‡ä¸€ä¸ª `scenario z` æ˜ç¡®æŒ‡å®šï¼š
- ç”¨æˆ·ç›®æ ‡ `g(z)`
- ç”¨æˆ·äº‹å® `u(z)` å’Œç³»ç»Ÿäº‹å® `so(z)`
- é¢„æœŸæœ€ç»ˆçŠ¶æ€ `s*(z)`
- é¢„æœŸä»£ç†è¡Œä¸º `b*(z)`

è¯„ä¼°ä¸å†å…³æ³¨è·¯å¾„åŒ¹é…ï¼ˆtrajectory matchingï¼‰ï¼Œè€Œæ˜¯çœ‹æœ€ç»ˆè¾“å‡ºæ˜¯å¦æ»¡è¶³ `s*(z)` å’Œ `b*(z)`ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ AppWorldï¼‰ | æœ¬æ–‡æ–¹æ³•ï¼ˆProxy State-Based Evalï¼‰ |
|------|------------------------|-------------------------------|
| åç«¯ä¾èµ– | å¿…é¡»æœ‰ç¡®å®šæ€§æ•°æ®åº“ | æ— éœ€çœŸå® DBï¼Œä»…éœ€ LLM æ¨ç† proxy state |
| å·¥ç¨‹å¼€é”€ | æé«˜ï¼ˆæ•°ä¸‡è¡Œä»£ç  + å•å…ƒæµ‹è¯•ï¼‰ | æä½ï¼Œåœºæ™¯æ–‡ä»¶å³å¯é©±åŠ¨æ•´ä¸ªç¯å¢ƒ |
| å¯æ‰©å±•æ€§ | è¿­ä»£æ…¢ï¼Œéš¾ä»¥éšäº§å“æ¼”è¿› | å¿«é€Ÿæ­å»ºï¼Œæ”¯æŒæ•æ·å¼€å‘ |
| æ•°æ®ç”Ÿæˆ | æ”¯æŒ on-policy rollout | æ”¯æŒ on/off-policy rolloutï¼Œå¯ç”¨äº SFT/RFT è®­ç»ƒ |
| è¯„ä¼°å¯é æ€§ | é«˜ï¼ˆåŸºäºçœŸå®çŠ¶æ€ï¼‰ | é«˜ï¼ˆhuman-LLM judge agreement >90%ï¼‰ |
| æˆæœ¬ | é«˜æ˜‚ | æ˜¾è‘—é™ä½ |

âœ… **æœ¬è´¨åˆ›æ–°**ï¼šå°†â€œç¡®å®šæ€§åç«¯â€æ›¿æ¢ä¸ºâ€œLLM-inferred proxy stateâ€ï¼Œå®ç°äº† **scalable + verifiable reward** çš„ç»Ÿä¸€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- è‡ªå»ºåˆæˆæ•°æ®é›†ï¼Œå…± **|Z|=208 ä¸ªåœºæ™¯**ï¼Œæ¶µç›–ç”µå•†ï¼ˆCommerceï¼‰ä¸è´¦æˆ·ç®¡ç†ï¼ˆAccount Managementï¼‰ä¸¤å¤§é¢†åŸŸã€‚
- åˆ†ä¸ºè®­ç»ƒé›† `Ztrain=157` å’Œæµ‹è¯•é›† `Ztest=51`ã€‚
- æ‰€æœ‰åœºæ™¯å‡äººå·¥è®¾è®¡ï¼Œç¡®ä¿å†…éƒ¨ä¸€è‡´æ€§ï¼ˆé€»è¾‘è‡ªæ´½ï¼‰ã€è¦†ç›–å¤šæ ·åŒ– workflowã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

#### é¢†åŸŸä¸å·¥å…·é›†ï¼ˆTwo Tool Familiesï¼‰
- **Commerce Tools**: Product Discovery, Checkout, Cart Management, Product Q&A, Offers & Promotions
- **Account Tools**: Wallet & Funding, Payment & Transfer, Dispute & Refund, Security & Fraud, Transaction Inquiry

#### è¢«æµ‹æ¨¡å‹ï¼ˆReasoning Agent, RAï¼‰
æ¶µç›–å¤šç§ä¸»æµ LLM å®¶æ—ï¼š
- **GPT-5**ï¼ˆä¸åŒ reasoning effort: minimal â†’ highï¼‰
- **GPT-4o / GPT-4o-mini**
- **Gemini-2.5-pro / flash**
- **Qwen3-235B / Qwen3-30B-A3B-Thinking-2507**

æ‰€æœ‰ rollout ä½¿ç”¨ temperature=1ã€‚

#### æ¨¡æ‹Ÿå™¨ä¸è£åˆ¤æ¨¡å‹
é™¤éç‰¹åˆ«è¯´æ˜ï¼š
- `fuser`, `ftool`, `fstate`, `J` å‡ä½¿ç”¨ **GPT-5o**ï¼ˆmedium reasoning effortï¼‰
- é»˜è®¤ persona ä¸º **power user**ï¼ˆé¿å…ç”¨æˆ·ä¾§é”™è¯¯å¹²æ‰°ï¼‰

#### ç”¨æˆ· Persona è®¾ç½®
ä¸‰ç§ persona æ§åˆ¶ç”¨æˆ·è¡Œä¸ºå¤æ‚åº¦ï¼š
- **Power user**: æ¸…æ™°è¡¨è¾¾éœ€æ±‚ï¼Œé«˜æ•ˆäº¤äº’
- **Ambiguous user**: åˆå§‹ä¿¡æ¯æ¨¡ç³Šï¼Œéœ€æ¾„æ¸…
- **Confused user**: ä¸ç†è§£æµç¨‹ï¼Œæ˜“è¯¯è§£ç³»ç»Ÿåé¦ˆ

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
å¯¹ä»»æ„äºŒå€¼æŒ‡æ ‡ $ x(z) $ï¼Œå®šä¹‰å…¶ rate ä¸ºï¼š

$$
\text{Rate}(x) = \frac{1}{|Z_{\text{test}}|} \sum_{z \in Z_{\text{test}}} x(z)
$$

ä¸»è¦æŠ¥å‘Šä»¥ä¸‹æŒ‡æ ‡ï¼ˆå‡åœ¨ `Ztest` ä¸Šè®¡ç®—ï¼‰ï¼š
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **GC (Goal Completion Rate)** | ç›®æ ‡æˆåŠŸå®Œæˆçš„æ¯”ä¾‹ |
| **ER_agent** | å›  agent é”™è¯¯å¯¼è‡´å¤±è´¥çš„æ¯”ä¾‹ |
| **ER_user** | å›  user é”™è¯¯å¯¼è‡´å¤±è´¥çš„æ¯”ä¾‹ |
| **HR_tool** | Tool hallucination rateï¼ˆå·¥å…·è™šæ„ä¿¡æ¯ï¼‰ |
| **HR_user** | User hallucination rateï¼ˆç”¨æˆ·è™šæ„ä¿¡æ¯ï¼‰ |

æ­¤å¤–è¿˜è¿›è¡Œæ¶ˆèå®éªŒä¸æ•æ„Ÿæ€§åˆ†æã€‚

---

### ğŸ” è®­ç»ƒèŒƒå¼ï¼ˆPost-Training Supportï¼‰
éªŒè¯è¯¥ç¯å¢ƒä¹Ÿå¯ç”¨äºè®­ç»ƒï¼š
- **On-policy Training (RFT)**: å½“å‰ RA ä¸ç¯å¢ƒäº¤äº’ï¼Œåªä¿ç•™æˆåŠŸè½¨è¿¹ï¼ˆc=1ï¼‰ç”¨äº rejection-sampling fine-tuning
- **Off-policy Training (SFT)**: ä½¿ç”¨æ›´å¼º teacher æ¨¡å‹ç”ŸæˆæˆåŠŸè½¨è¿¹ï¼Œå¾®è°ƒ base RA

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ åŸºçº¿æ¨¡å‹æ¯”è¾ƒï¼ˆFig. 3ï¼‰
| æ¨¡å‹ | GC (%) |
|------|--------|
| GPT-5 (high RE) | **85.76** |
| GPT-5 (medium RE) | 84.47 |
| GPT-5 (low RE) | 83.21 |
| GPT-4o | 80.53 |
| GPT-4o-mini | 76.08 |
| Qwen3-235B | 74.59 |
| Qwen3-30B (base) | **65.64** |

âœ… **å…³é”®å‘ç°**ï¼š
- GC éšæ¨¡å‹è§„æ¨¡å’Œæ¨ç†åŠªåŠ›ï¼ˆreasoning effortï¼‰å•è°ƒä¸Šå‡ï¼›
- ä¸åŒå®¶æ—é—´æ’åºåˆç†ï¼Œè¡¨æ˜è¯„ä¼°å…·æœ‰è‰¯å¥½çš„åŒºåˆ†èƒ½åŠ›å’Œç¨³å®šæ€§ã€‚

---

### ğŸ› ï¸ è®­ç»ƒæå‡æ•ˆæœï¼ˆFine-tuning Resultsï¼‰
åœ¨ Qwen3-30B-A3B-Thinking-2507 ä¸Šè¿›è¡Œè®­ç»ƒï¼š
| æ–¹æ³• | GC (%) | æå‡å¹…åº¦ |
|------|--------|---------|
| Base Model | 65.64 | â€” |
| RFT (on-policy) | 67.11 | +1.47 |
| SFT (off-policy) | **77.34** | **+11.70** |

âœ… è¡¨æ˜è¯¥ç¯å¢ƒèƒ½æœ‰æ•ˆç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®ï¼Œä¸”ç›‘ç£ä¿¡å·å¯è¿ç§»åˆ°æœªè§åœºæ™¯ã€‚

---

### ğŸ” æ¶ˆèå®éªŒï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰State Tracker æ¨¡å‹å¼ºåº¦å½±å“
- å°†é»˜è®¤ `GPT-5o` æ›¿æ¢ä¸ºè¾ƒå¼±çš„ `GPT-4o`
- ç»“æœï¼š**tool hallucination rate ä» 1.33% â†‘ è‡³ 3.61%**
- åŸå› ï¼šstate tracker æ¨ç†ä¸å‡† â†’ proxy state å‡ºé”™ â†’ tool simulator â€œè¯»å–â€é”™è¯¯çŠ¶æ€ â†’ è¾“å‡ºå¤±çœŸ

â¡ï¸ è¯´æ˜ **accurate state tracking æ˜¯ç¨³å®šè¯„ä¼°çš„å…³é”®**ã€‚

#### ï¼ˆ2ï¼‰Scenario Fact å®Œæ•´æ€§æ¶ˆèï¼ˆFig. 4ï¼‰
éšæœºç§»é™¤éƒ¨åˆ†ç³»ç»Ÿäº‹å®æˆ–ç”¨æˆ·äº‹å®ï¼š
- ç§»é™¤è¶Šå¤š â†’ **tool hallucination å’Œ user hallucination ç‡æ˜¾è‘—ä¸Šå‡**
- å®Œå…¨ç§»é™¤æ—¶å¯è¾¾ 25%+ çš„ hallucination ç‡

â¡ï¸ è¯æ˜ï¼š**ç²¾å¿ƒè®¾è®¡çš„ scenario æ–‡ä»¶è‡³å…³é‡è¦**ï¼Œå®ƒé”šå®šäº†æ¨¡æ‹Ÿçš„çœŸå®æ€§è¾¹ç•Œã€‚

---

### ğŸ‘¥ ç”¨æˆ· persona æ•æ„Ÿæ€§åˆ†æï¼ˆFig. 5ï¼‰
| Persona | ER_user (%) | HR_user (%) |
|--------|-------------|------------|
| Power user | 3.55 | 0.67 |
| Ambiguous user | 5.50 | 2.75 |
| Confused user | 5.14 | 1.87 |

âœ… å‘ç°ï¼š
- æ›´å¤æ‚çš„ persona å¯¼è‡´æ›´é«˜çš„ç”¨æˆ·ä¾§é”™è¯¯å’Œå¹»è§‰ï¼›
- ä½†é»˜è®¤ä½¿ç”¨ power user å¯æ§åœ°å°†ç”¨æˆ·è¯¯å·®å‹åˆ¶åœ¨ä½ä½ï¼ˆ<4%ï¼‰ï¼Œä½¿è¯„ä¼°èšç„¦äº RA æ€§èƒ½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **Proxy State-Based Evaluation æ˜¯å¯è¡Œä¸”å¯é çš„æ›¿ä»£æ–¹æ¡ˆ**ï¼š
   - åœ¨æ— çœŸå®æ•°æ®åº“çš„æƒ…å†µä¸‹ï¼Œä»èƒ½å®ç°ç¨³å®šçš„ state-based evaluationï¼›
   - human-LLM judge agreement > **90%**ï¼Œæ”¯æŒè‡ªåŠ¨åŒ–è¯„ä¼°çš„å¯ä¿¡åº¦ã€‚

2. **å…·å¤‡è‰¯å¥½æ¨¡å‹åŒºåˆ†èƒ½åŠ›**ï¼š
   - GC æŒ‡æ ‡éšæ¨¡å‹å¤§å°å’Œæ¨ç†åŠªåŠ›å•è°ƒå¢é•¿ï¼Œæ’åºç¬¦åˆé¢„æœŸï¼›
   - æ”¯æŒè·¨æ¨¡å‹ family çš„å…¬å¹³æ¯”è¾ƒã€‚

3. **æ”¯æŒé«˜æ•ˆè®­ç»ƒæ•°æ®ç”Ÿæˆ**ï¼š
   - å¯ç”Ÿæˆå¸¦ reward æ ‡ç­¾çš„ on-policy å’Œ off-policy rolloutï¼›
   - å¾®è°ƒåæ€§èƒ½æ˜¾è‘—æå‡ï¼ˆSFT æå‡è¶… 11% GCï¼‰ï¼Œå¹¶å…·æ³›åŒ–èƒ½åŠ›ã€‚

4. **é«˜åº¦å¯é…ç½®ä¸å¯æ‰©å±•**ï¼š
   - æ”¯æŒ persona æ§åˆ¶ã€å·¥å…· schema æ¼”è¿›ï¼›
   - åœºæ™¯å³ä»£ç ï¼Œæ˜“äºéšäº§å“è¿­ä»£æ›´æ–°ã€‚

---

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–é«˜è´¨é‡ LLM ç»„ä»¶**ï¼š
   - è‹¥ state tracker æˆ– tool simulator èƒ½åŠ›ä¸è¶³ï¼Œå¯èƒ½å¼•å…¥ cascading errorsï¼›
   - å½“å‰ä¾èµ– GPT-5o çº§åˆ«æ¨¡å‹æ‰èƒ½ç»´æŒä½ hallucinationã€‚

2. **åˆæˆåœºæ™¯çš„çœŸå®æ€§è¾¹ç•Œ**ï¼š
   - åœºæ™¯è™½å¤šæ ·ä½†ä»ä¸ºäººå·¥æ„é€ ï¼Œå¯èƒ½å­˜åœ¨åˆ†å¸ƒåå·®ï¼›
   - éœ€æŒç»­æ³¨å…¥çœŸå®ç”¨æˆ·è¡Œä¸ºæ•°æ®ä»¥å¢å¼º realismã€‚

3. **è®¡ç®—æˆæœ¬è½¬ç§»è€Œéæ¶ˆé™¤**ï¼š
   - è™½çœå»å·¥ç¨‹å¼€å‘æˆæœ¬ï¼Œä½†å¤šæ¬¡ LLM è°ƒç”¨å¸¦æ¥æ¨ç†å¼€é”€ï¼›
   - å¤§è§„æ¨¡è¯„ä¼°æ—¶éœ€æƒè¡¡ cost-efficiencyã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **é™ä½å¯¹å¼º LLM çš„ä¾èµ–**ï¼š
   - æ¢ç´¢æ›´å°æ¨¡å‹ + prompt engineering å®ç°å¯é  state trackingï¼›
   - å¼•å…¥ retrieval augmentation æå‡ factual consistencyã€‚

2. **åŠ¨æ€åœºæ™¯ç”Ÿæˆï¼ˆDynamic Scenario Generationï¼‰**ï¼š
   - åˆ©ç”¨ LLM è‡ªåŠ¨ç”Ÿæˆæ–°åœºæ™¯ï¼Œæ‰©å¤§è¦†ç›–èŒƒå›´ï¼›
   - æ”¯æŒ adversarial testing å’Œ stress-testingã€‚

3. **ä¸çœŸå®ç³»ç»Ÿè”è°ƒéªŒè¯**ï¼š
   - å°† proxy evaluation ä¸ production ç³»ç»Ÿç»“æœå¯¹é½ï¼Œå»ºç«‹ external validityã€‚

4. **å¼€æ”¾åŸºå‡†ç”Ÿæ€å»ºè®¾**ï¼š
   - å¼€æº scenario schema ä¸ evaluatorï¼Œæ¨åŠ¨ community-wide adoptionã€‚

---

## âœ… æ€»ç»“ä¸€å¥è¯
> æœ¬æ–‡æå‡ºçš„ **Proxy State-Based Evaluation** æ¡†æ¶æˆåŠŸè§£è€¦äº† agentic benchmark ä¸ heavy deterministic backend çš„å¼ºç»‘å®šï¼Œé€šè¿‡ LLM-driven simulation å®ç°äº† **scalableã€reliableã€trainable** çš„å¤šè½®å·¥å…·è°ƒç”¨æ™ºèƒ½ä½“è¯„ä¼°ä½“ç³»ï¼Œä¸ºå·¥ä¸šçº§ LLM agent çš„å¿«é€Ÿè¿­ä»£æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 6. [How Reliable is Your Service at the Extreme Edge? Analytical Modeling of Computational Reliability](https://arxiv.org/abs/2602.16362)

**Authors**: MHD Saria Allahham, Hossam S. Hassanein  
**Category**: cs.DC  
**Published**: 2026-02-19  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.16362v1  

#### Abstract
Extreme Edge Computing (XEC) distributes streaming workloads across consumer-owned devices, exploiting their proximity to users and ubiquitous availability. Many such workloads are AI-driven, requiring continuous neural network inference for tasks like object detection and video analytics. Distribut...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*How Reliable is Your Service at the Extreme Edge? Analytical Modeling of Computational Reliability*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹ **Extreme Edge Computing (XEC)** ç¯å¢ƒä¸‹ï¼Œç”±æ¶ˆè´¹è€…æ‹¥æœ‰çš„è¾¹ç¼˜è®¾å¤‡ï¼ˆå¦‚æ‰‹æœºã€å¹³æ¿ã€å¯ç©¿æˆ´è®¾å¤‡ï¼‰æ„æˆçš„åˆ†å¸ƒå¼æ¨ç†ï¼ˆDistributed Inference, DIï¼‰ç³»ç»Ÿæ‰€é¢ä¸´çš„**è®¡ç®—å¯é æ€§å»ºæ¨¡éš¾é¢˜**ã€‚

ä¼ ç»Ÿå¯é æ€§æ¨¡å‹é€šå¸¸åŸºäºèŠ‚ç‚¹â€œæ­£å¸¸/å¤±æ•ˆâ€çš„äºŒå…ƒå‡è®¾ï¼Œè€ŒXECè®¾å¤‡å…·æœ‰é«˜åº¦åŠ¨æ€çš„è®¡ç®—èƒ½åŠ›ï¼ˆå—åå°åº”ç”¨ã€ç”µæ± ç®¡ç†ã€çƒ­èŠ‚æµç­‰å½±å“ï¼‰ï¼Œå…¶æ€§èƒ½æ˜¯è¿ç»­æ³¢åŠ¨è€Œéå®Œå…¨å®•æœºã€‚å› æ­¤ï¼Œç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆé‡åŒ–ï¼š**ä¸€ä¸ªè®¾å¤‡æˆ–è®¾å¤‡ç»„åœ¨ç»™å®šæ—¶åˆ»èƒ½å¦æ»¡è¶³æµå¼AIæœåŠ¡ï¼ˆå¦‚å®æ—¶ç›®æ ‡æ£€æµ‹ï¼‰çš„QoSéœ€æ±‚ï¼ˆå¦‚å»¶è¿Ÿã€ååé‡ï¼‰**ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

è®ºæ–‡æå‡ºäº†ä¸€å¥—**å½¢å¼åŒ–çš„åˆ†ææ¡†æ¶**ï¼Œç”¨äºå»ºæ¨¡å’Œé‡åŒ–XECç¯å¢ƒä¸‹çš„ **computational reliabilityï¼ˆè®¡ç®—å¯é æ€§ï¼‰**ï¼Œå®šä¹‰ä¸ºï¼š

> åœ¨æŒ‡å®šçš„ **Quality of Service (QoS)** é˜ˆå€¼ä¸‹ï¼Œè®¾å¤‡å¯ç”¨è®¡ç®—å®¹é‡ $C(t)$ æ»¡è¶³æœåŠ¡éœ€æ±‚ $\Delta(t)$ çš„æ¦‚ç‡ï¼š
> $$
> R(t) = P\left(\frac{C(t)}{\Delta(t)} \geq \Theta\right)
> $$
> å…¶ä¸­ $\Theta$ æ˜¯QoSé˜ˆå€¼ï¼ˆä¾‹å¦‚ï¼Œ$\Theta=3$ è¡¨ç¤ºè®¾å¤‡éœ€æä¾›è‡³å°‘3å€äºéœ€æ±‚çš„ç®—åŠ›ä»¥åº”å¯¹æ³¢åŠ¨ï¼‰ã€‚

è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¿¡æ¯å±‚çº§çš„å»ºæ¨¡æ–¹æ³•ï¼š

1. **Minimal Information (MI) æ¨¡å‹**ï¼š
   - ä»…ä¾èµ–è®¾å¤‡å£°æ˜çš„ç®—åŠ›èŒƒå›´ $[C_{\min}, C_{\max}]$ å’ŒæœåŠ¡çš„éœ€æ±‚èŒƒå›´ $[\Delta_{\min}, \Delta_{\max}]$ã€‚
   - å‡è®¾ $C(t)$ å’Œ $\Delta(t)$ åœ¨å…¶èŒƒå›´å†…æœä»å‡åŒ€åˆ†å¸ƒï¼Œæ¨å¯¼å‡ºé—­å¼è§£ï¼ˆclosed-form expressionï¼‰çš„å¯é æ€§è¡¨è¾¾å¼ï¼ˆè§ Lemma 1ï¼‰ã€‚
   - é€‚ç”¨äºæ— å†å²äº¤äº’çš„æ–°è®¾å¤‡æˆ–æ–°æœåŠ¡åœºæ™¯ã€‚

2. **Historical Data æ¨¡å‹**ï¼š
   - åˆ©ç”¨å†å²è§‚æµ‹æ•°æ®ï¼Œé€šè¿‡ **Maximum Likelihood Estimation (MLE)** ä¼°è®¡ $C(t)$ å’Œ $\Delta(t)$ çš„åˆ†å¸ƒå‚æ•°ã€‚
   - é‡‡ç”¨æˆªæ–­æ­£æ€åˆ†å¸ƒï¼ˆTruncated Normal Distributionï¼‰ä»¥ä¿è¯ç‰©ç†è¾¹ç•Œçº¦æŸã€‚
   - æ¨å¯¼å‡ºæ›´ç²¾ç¡®çš„å¯é æ€§è¡¨è¾¾å¼ï¼ˆè§ Lemma 2ï¼‰ï¼Œå¹¶è¯æ˜å…¶éšæ•°æ®ç§¯ç´¯æ”¶æ•›åˆ°çœŸå®å¯é æ€§ã€‚

æ­¤å¤–ï¼Œæ¡†æ¶æ‰©å±•è‡³å¤šè®¾å¤‡ç³»ç»Ÿï¼Œæ”¯æŒä»¥ä¸‹é…ç½®ï¼š

- **Series Configuration**ï¼šæ‰€æœ‰è®¾å¤‡å¿…é¡»æˆåŠŸï¼ˆå¯é æ€§ç›¸ä¹˜ï¼‰ã€‚
- **Parallel Configuration**ï¼šä»»ä¸€è®¾å¤‡æˆåŠŸå³å¯ï¼ˆå¯é æ€§äº’è¡¥ç›¸ä¹˜ï¼‰ã€‚
- **Work Partitioning**ï¼šä»»åŠ¡æŒ‰æ¯”ä¾‹åˆ†é…ï¼Œå„è®¾å¤‡æ‰¿æ‹…éƒ¨åˆ†è´Ÿè½½ã€‚

å¹¶æå‡ºï¼š

- **æœ€ä¼˜ä»»åŠ¡åˆ†é…è§„åˆ™ï¼ˆLemma 3ï¼‰**ï¼šæœ€å¤§åŒ–ç³»ç»Ÿå¯é æ€§çš„åˆ†é…åº”æ»¡è¶³â€œè¾¹é™…å¯¹æ•°å¯é æ€§ç›¸ç­‰â€æ¡ä»¶ã€‚
- **è®¾å¤‡é€‰æ‹©åˆ†æè¾¹ç•Œï¼ˆLemmas 4 & 5ï¼‰**ï¼šç»™å‡ºç³»åˆ—éƒ¨ç½²æœ€å¤§å¯è¡Œè®¾å¤‡æ•°ã€å¹¶è¡Œå†—ä½™æœ€å°æ‰€éœ€è®¾å¤‡æ•°çš„è§£æè¡¨è¾¾å¼ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | æœ¬æ–‡ä¼˜åŠ¿ |
|------|---------|
| **å¯é æ€§å®šä¹‰** | è¶…è¶Šâ€œèŠ‚ç‚¹æ˜¯å¦å­˜æ´»â€ï¼Œèšç„¦â€œ**æŒç»­æ€§èƒ½æ˜¯å¦è¾¾æ ‡**â€ï¼Œæ›´è´´åˆXECå®é™…æŒ‘æˆ˜ã€‚ |
| **å»ºæ¨¡çµæ´»æ€§** | æ”¯æŒä»â€œé›¶å…ˆéªŒâ€åˆ°â€œæœ‰å†å²æ•°æ®â€çš„å¹³æ»‘è¿‡æ¸¡ï¼Œé€‚åº”ä¸åŒéƒ¨ç½²é˜¶æ®µã€‚ |
| **åˆ†æå¯æ‰©å±•æ€§** | æä¾›**é—­å¼è§£**ï¼Œä¾¿äºå®æ—¶å†³ç­–å’Œèµ„æºç¼–æ’ï¼ˆorchestrationï¼‰ï¼Œæ— éœ€å¤æ‚ä»¿çœŸã€‚ |
| **ç³»ç»Ÿçº§æ´å¯Ÿ** | ç»™å‡º**æœ€ä¼˜åˆ†é…ç­–ç•¥**å’Œ**è®¾å¤‡é€‰æ‹©è¾¹ç•Œ**ï¼Œä¸ºç³»ç»Ÿè®¾è®¡æä¾›ç†è®ºæŒ‡å¯¼ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†**

è®ºæ–‡æœªä½¿ç”¨å…¬å¼€æ•°æ®é›†ï¼Œè€Œæ˜¯æ„å»ºäº†ä¸€ä¸ª**åŸºäºä»¿çœŸçš„å®éªŒç¯å¢ƒ**ï¼Œä»¥ **YOLO11m** æ¨¡å‹å¤„ç†è§†é¢‘æµä½œä¸ºä»£è¡¨æ€§ **Distributed Inference (DI)** å·¥ä½œè´Ÿè½½ã€‚

- **æ¨¡å‹**ï¼šYOLO11mï¼ˆå•é˜¶æ®µç›®æ ‡æ£€æµ‹å™¨ï¼‰
- **è¾“å…¥**ï¼šåŠ¨æ€åˆ†è¾¨ç‡çš„è§†é¢‘å¸§ï¼ˆé€šè¿‡ç¼©æ”¾å› å­ `scale` æ§åˆ¶è®¡ç®—éœ€æ±‚ï¼‰
- **å¹³å°**ï¼šåŸºäº **Docker å®¹å™¨**æ¨¡æ‹Ÿå¤šä¸ª XEDï¼ˆExtreme Edge Devicesï¼‰

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **ä»¿çœŸæ¶æ„**
- **å®¹é‡æ§åˆ¶**ï¼šé€šè¿‡åŠ¨æ€è°ƒæ•´å®¹å™¨åˆ†é…çš„ **CPUçº¿ç¨‹æ•°**ï¼ˆ2â€“12çº¿ç¨‹ï¼‰æ¥æ¨¡æ‹Ÿ $C(t)$ çš„æ³¢åŠ¨ã€‚
- **éœ€æ±‚æ§åˆ¶**ï¼šé€šè¿‡æ”¹å˜è¾“å…¥å¸§çš„ **ç©ºé—´åˆ†è¾¨ç‡**ï¼ˆscale âˆˆ [0.1, 0.9]ï¼‰æ¥æ¨¡æ‹Ÿ $\Delta(t)$ çš„å˜åŒ–ï¼ˆè®¡ç®—æˆæœ¬ä¸åƒç´ æ•°æˆæ­£æ¯”ï¼‰ã€‚
- **QoSé˜ˆå€¼ $\Theta$**ï¼šç›´æ¥å¯¹åº”ç›®æ ‡å¸§ç‡ï¼ˆFPSï¼‰ã€‚ä¾‹å¦‚ $\Theta = 3$ è¡¨ç¤ºéœ€è¾¾åˆ°3 FPSã€‚

#### **è¯„ä¼°æµç¨‹**
1. **Profiling**ï¼šé¢„å…ˆæµ‹é‡ä¸åŒçº¿ç¨‹æ•°å’Œç¼©æ”¾å› å­ç»„åˆä¸‹çš„æ¨ç†æ—¶é—´ï¼Œå»ºç«‹â€œçº¿ç¨‹â†’ç®—åŠ›â€ã€â€œç¼©æ”¾â†’éœ€æ±‚â€çš„æ˜ å°„è¡¨ã€‚
2. **åŠ¨æ€é‡‡æ ·**ï¼šæ¯30å¸§éšæœºé‡‡æ ·ä¸€æ¬¡çº¿ç¨‹æ•°å’Œç¼©æ”¾å› å­ï¼Œæ¨¡æ‹ŸçœŸå®æ³¢åŠ¨ã€‚
3. **è®°å½•**ï¼šæ¯å¸§è®°å½•ï¼šçº¿ç¨‹æ•°ã€ç¼©æ”¾å› å­ã€æ¨ç†æ—¶é—´ã€æ˜¯å¦æ»¡è¶³QoSã€‚
4. **è®¡ç®—**ï¼š
   - **Empirical Reliability**ï¼šæ»¡è¶³QoSçš„å¸§å æ¯”ã€‚
   - **Analytical Prediction**ï¼šä½¿ç”¨MIå’ŒHistorical Dataæ¨¡å‹è®¡ç®— $R(t,\Theta)$ã€‚
   - **Monte Carlo Sampling**ï¼šç”¨äºéªŒè¯è§£æå…¬å¼çš„å‡†ç¡®æ€§ã€‚

#### **è¯„ä¼°æŒ‡æ ‡**
- **Reliability $R(t,\Theta)$**ï¼šæ ¸å¿ƒæŒ‡æ ‡ã€‚
- **Throughput (FPS)** å’Œ **Latency (ms)**ï¼šç”¨äºéªŒè¯ç³»ç»Ÿæ€§èƒ½æå‡ã€‚
- **Convergence of MLE Estimates**ï¼šå†å²æ•°æ®æ¨¡å‹éšæ ·æœ¬é‡å¢åŠ çš„é¢„æµ‹ç²¾åº¦æå‡ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **Analytical Models**ï¼š
  - **MI Model (Uniform Assumption)**ï¼šä»…ç”¨è¾¹ç•Œä¿¡æ¯ã€‚
  - **Historical Model (MLE + Truncated Normal)**ï¼šä½¿ç”¨å†å²æ•°æ®æ‹Ÿåˆã€‚
- **Ground Truth**ï¼š
  - **Monte Carlo Simulation**ï¼šå¤§é‡é‡‡æ ·éªŒè¯è§£æç§¯åˆ†ã€‚
  - **Empirical Measurement**ï¼šå®é™…ä»¿çœŸè¿è¡Œç»“æœã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **MIæ¨¡å‹éªŒè¯ï¼ˆFig. 3ï¼‰**
- åœ¨ $C \in [55,152]$ GFLOPS, $\Delta \in [55,278]$ GFLOPS, $\Theta \in [1,4]$ FPS ä¸‹ï¼š
  - **Analytical**, **Monte Carlo**, å’Œ **Empirical** æ›²çº¿é«˜åº¦ä¸€è‡´ã€‚
  - è¯æ˜ **Lemma 1 çš„é—­å¼è§£å‡†ç¡®å¯é **ã€‚

#### âœ… **Historical Data æ¨¡å‹éªŒè¯ï¼ˆFig. 4ï¼‰**
- ä½¿ç”¨ MLE æ‹Ÿåˆæˆªæ–­æ­£æ€åˆ†å¸ƒåï¼Œ**Analytical**, **MC**, **Simulation** ç»“æœä¾ç„¶é«˜åº¦å»åˆã€‚
- **MLE æ”¶æ•›æ€§ï¼ˆFig. 5ï¼‰**ï¼š
  - ä»…éœ€çº¦ **50ä¸ªç‹¬ç«‹æ ·æœ¬**ï¼ŒMLEä¼°è®¡çš„å¯é æ€§å³æ”¶æ•›åˆ°çœŸå®å€¼ã€‚
  - ç›¸æ¯”MIæ¨¡å‹ï¼ˆåˆå§‹ä¼°è®¡ $R \approx 0.55$ï¼‰ï¼Œæœ€ç»ˆæ”¶æ•›åˆ° $R \approx 0.82$ï¼Œ**ç»å¯¹æå‡è¾¾ 0.27**ã€‚

#### âœ… **ç³»ç»Ÿçº§é…ç½®éªŒè¯ï¼ˆFig. 6 & 7ï¼‰**
- **Series Systemï¼ˆFig. 7ï¼‰**ï¼š
  - å•è®¾å¤‡ï¼š1.9 FPSï¼Œ520 ms å»¶è¿Ÿã€‚
  - 4è®¾å¤‡åˆ†åŒºå¹¶è¡Œï¼š**5.3 FPSï¼ˆ2.8Ã—æå‡ï¼‰**ï¼Œ**207 ms å»¶è¿Ÿï¼ˆ2.5Ã—é™ä½ï¼‰**ã€‚
  - å¯é æ€§ï¼šå•è®¾å¤‡ $R > 0.8$ï¼Œä½†ç³»ç»Ÿå¯é æ€§å› ä¹˜ç§¯æ•ˆåº”é™è‡³ **~0.5 @ 5 FPS**ã€‚
- **Device Selection Boundsï¼ˆFig. 6ï¼‰**ï¼š
  - **Series**ï¼šé«˜å¯é è®¾å¤‡ï¼ˆ$R=0.99$ï¼‰æœ€å¤šæ”¯æŒ10å°ä¸²è”ï¼›ä½å¯é ï¼ˆ$R=0.95$ï¼‰ä»…æ”¯æŒ2å°ã€‚
  - **Parallel**ï¼šä¸ºè¾¾åˆ° $e=0.99$ï¼Œ$R=0.9$ è®¾å¤‡éœ€2å°ï¼Œ$R=0.5$ è®¾å¤‡éœ€9å°ã€‚
  - å†å²æ•°æ®æ¨¡å‹é¢„æµ‹ä¸ä»¿çœŸç»“æœåŒ¹é…è‰¯å¥½ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| å¯¹æ¯”é¡¹ | ç»“æœ |
|--------|------|
| **MI vs Empirical** | MIæ¨¡å‹æä¾›**ä¿å®ˆä¸‹ç•Œ**ï¼Œç•¥ä½äºå®æµ‹å€¼ï¼ˆå› å‡è®¾å‡åŒ€åˆ†å¸ƒï¼Œä½ä¼°é›†ä¸­è¶‹åŠ¿ï¼‰ã€‚ |
| **Historical vs MI** | Historicalæ¨¡å‹æ˜¾è‘—**æ›´æ¥è¿‘å®æµ‹å€¼**ï¼ˆå¦‚åœ¨ $\Theta=3$ æ—¶ï¼ŒMIé¢„æµ‹ $R=0.69$ï¼ŒHistoricalé¢„æµ‹ $R=0.85$ï¼Œå®æµ‹ $R=0.87$ï¼‰ã€‚ |
| **Analytical vs Monte Carlo** | è§£æç»“æœä¸è’™ç‰¹å¡æ´›é‡‡æ ·å‡ ä¹å®Œå…¨é‡åˆï¼ŒéªŒè¯å…¬å¼æ­£ç¡®æ€§ã€‚ |

---

### **æ¶ˆèå®éªŒç»“æœ**

- **å®¹é‡å½±å“ï¼ˆFig. 3bï¼‰**ï¼šæ›´é«˜çº¿ç¨‹æ•°ï¼ˆæ›´é«˜ $C$ï¼‰ä½¿å¯é æ€§æ›²çº¿å³ç§»ï¼Œå¯åœ¨æ›´é«˜QoSä¸‹ç»´æŒé«˜å¯é æ€§ã€‚
- **éœ€æ±‚å½±å“ï¼ˆFig. 3cï¼‰**ï¼šä½éœ€æ±‚ï¼ˆå°scaleï¼‰ä¸‹å¯é æ€§æ¥è¿‘1ï¼›é«˜éœ€æ±‚ä¸‹è¿…é€Ÿä¸‹é™ã€‚
- **MLEæ ·æœ¬é‡å½±å“ï¼ˆFig. 5ï¼‰**ï¼šå¯é æ€§ä¼°è®¡éšæ ·æœ¬é‡å•è°ƒæ”¶æ•›ï¼Œå‰50ä¸ªæ ·æœ¬å¸¦æ¥æœ€å¤§æå‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **Computational Reliability æ˜¯XECçš„æ ¸å¿ƒæŒ‘æˆ˜**ï¼šè®¾å¤‡æ€§èƒ½æ³¢åŠ¨æ˜¯å¸¸æ€ï¼Œéœ€ä»â€œæŒç»­æ€§èƒ½è¾¾æ ‡â€è§’åº¦é‡æ–°å®šä¹‰å¯é æ€§ã€‚
2. **MIæ¨¡å‹å®ç”¨æ€§å¼º**ï¼šå³ä½¿æ— å†å²æ•°æ®ï¼Œä»…å‡­å£°æ˜è¾¹ç•Œä¹Ÿèƒ½æä¾›**ä¿å®ˆä½†å¯ç”¨çš„å¯é æ€§ä¼°è®¡**ï¼Œæ”¯æŒå¿«é€Ÿå†³ç­–ã€‚
3. **Historical Data æ˜¾è‘—æå‡ç²¾åº¦**ï¼šå°‘é‡å†å²æ•°æ®å³å¯é€šè¿‡MLEå¤§å¹…æå‡é¢„æµ‹å‡†ç¡®æ€§ï¼Œå®ç°**æ¸è¿›å¼å¯é æ€§æ„ŸçŸ¥**ã€‚
4. **ç³»ç»Ÿé…ç½®æƒè¡¡æ˜ç¡®**ï¼š
   - **Series**ï¼šæ€§èƒ½æå‡æ˜æ˜¾ï¼Œä½†å¯é æ€§å‘ˆæŒ‡æ•°è¡°å‡ï¼Œéœ€ä¸¥æ ¼ç­›é€‰é«˜å¯é è®¾å¤‡ã€‚
   - **Parallel**ï¼šç‰ºç‰²ç®—åŠ›æ¢å¯é æ€§ï¼Œé€‚åˆå…³é”®ä»»åŠ¡ã€‚
5. **æœ€ä¼˜åˆ†é…éå‡ç­‰**ï¼šåº”å°†æ›´å¤šè´Ÿè½½åˆ†é…ç»™â€œå¯é æ€§éšè´Ÿè½½å¢é•¿æ›´å¹³ç¼“â€çš„è®¾å¤‡ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **å‡è®¾ç‹¬ç«‹æ€§**ï¼šæ¨¡å‹å‡è®¾è®¾å¤‡é—´è®¡ç®—æˆåŠŸäº‹ä»¶ç›¸äº’ç‹¬ç«‹ï¼Œå¿½ç•¥äº†å¯èƒ½çš„å…±å› æ•…éšœï¼ˆå¦‚åŒºåŸŸç½‘ç»œä¸­æ–­ï¼‰ã€‚
2. **å¿½ç•¥é€šä¿¡å¼€é”€**ï¼šå½“å‰æ¡†æ¶èšç„¦**è®¡ç®—å¯é æ€§**ï¼Œæœªæ˜¾å¼å»ºæ¨¡ä¼ è¾“å»¶è¿Ÿå’Œå¸¦å®½æ³¢åŠ¨å¯¹ç«¯åˆ°ç«¯QoSçš„å½±å“ã€‚
3. **é™æ€QoSé˜ˆå€¼**ï¼š$\Theta$ è¢«è§†ä¸ºå¸¸é‡ï¼Œæœªè€ƒè™‘åŠ¨æ€è°ƒæ•´çš„å¯èƒ½æ€§ã€‚
4. **åˆ†å¸ƒå‡è®¾**ï¼šè™½æ”¯æŒä¸€èˆ¬åŒ–ï¼Œä½†MLEå®éªŒä¸­é»˜è®¤ä½¿ç”¨æˆªæ–­æ­£æ€åˆ†å¸ƒï¼Œæœªå¿…é€‚ç”¨äºæ‰€æœ‰åœºæ™¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ‰©å±•è‡³é€šä¿¡å¯é æ€§**ï¼šå°†ç½‘ç»œå»¶è¿Ÿã€ä¸¢åŒ…ç­‰çº³å…¥è”åˆå¯é æ€§æ¨¡å‹ï¼Œæ„å»º **End-to-End Reliability Framework**ã€‚
2. **åŠ¨æ€QoSä¸è‡ªé€‚åº”è°ƒåº¦**ï¼šç»“åˆå¯é æ€§é¢„æµ‹ï¼Œå®ç°åŠ¨æ€è´Ÿè½½è°ƒæ•´å’Œè®¾å¤‡é‡é€‰ã€‚
3. **è·¨å±‚ä¼˜åŒ–**ï¼šè”åˆä¼˜åŒ–è®¡ç®—ã€é€šä¿¡ã€ç¼“å­˜èµ„æºï¼Œæœ€å¤§åŒ–ç³»ç»Ÿæ•ˆç”¨ã€‚
4. **çœŸå®ä¸–ç•Œéƒ¨ç½²éªŒè¯**ï¼šåœ¨çœŸå®XEDé›†ç¾¤ä¸Šæµ‹è¯•æ¡†æ¶çš„æœ‰æ•ˆæ€§å’Œå¼€é”€ã€‚
5. **å®‰å…¨ä¸æ¿€åŠ±æœºåˆ¶**ï¼šåœ¨å¯é æ€§æ¨¡å‹ä¸­å¼•å…¥è®¾å¤‡å¯ä¿¡åº¦å’Œæ¿€åŠ±æœºåˆ¶ï¼Œé˜²æ­¢æ¶æ„æˆ–æ‡’æƒ°èŠ‚ç‚¹å½±å“ç³»ç»Ÿã€‚

--- 

> **æ€»ç»“**ï¼šè¯¥è®ºæ–‡é¦–æ¬¡ä¸ºXECç¯å¢ƒä¸‹çš„æµå¼AIæœåŠ¡æä¾›äº†**å¯è®¡ç®—ã€å¯æ‰©å±•ã€å¯æ“ä½œçš„å¯é æ€§åˆ†ææ¡†æ¶**ï¼Œå¡«è¡¥äº†ä»â€œèµ„æºå¯ç”¨æ€§â€åˆ°â€œæœåŠ¡è´¨é‡ä¿éšœâ€ä¹‹é—´çš„ç†è®ºç©ºç™½ï¼Œä¸ºæ„å»ºçœŸæ­£å¯é çš„æç«¯è¾¹ç¼˜æ™ºèƒ½ç³»ç»Ÿå¥ å®šäº†é‡è¦åŸºç¡€ã€‚

</details>

---

### 7. [LLM-Driven Intent-Based Privacy-Aware Orchestration Across the Cloud-Edge Continuum](https://arxiv.org/abs/2602.16100)

**Authors**: Zijie Su, Muhammed Tawfiqul Islam, Mohammad Goudarzi, Adel N. Toosi  
**Category**: cs.DC  
**Published**: 2026-02-19  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.16100v1  

#### Abstract
With the rapid advancement of large language models (LLMs), efficiently serving LLM inference under limited GPU resources has become a critical challenge. Recently, an increasing number of studies have explored applying serverless computing paradigms to LLM serving in order to maximize resource util...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLLM-Driven Intent-Based Privacy-Aware Orchestration Across the Cloud-Edge Continuum

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨ **cloud-edge continuum**ï¼ˆäº‘è¾¹ååŒï¼‰ç¯å¢ƒä¸­ï¼Œéšç€è¾¹ç¼˜è®¡ç®—å’Œç‰©è”ç½‘ï¼ˆIoTï¼‰è®¾å¤‡çš„æ™®åŠï¼Œå¤§é‡æ•æ„Ÿæ•°æ®ï¼ˆå¦‚åŒ»ç–—ã€é‡‘èã€ä¸ªäººèº«ä»½ä¿¡æ¯ï¼‰åœ¨è¾¹ç¼˜ç”Ÿæˆå¹¶éœ€è¦å¤„ç†ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿç¼–æ’ç³»ç»Ÿï¼ˆå¦‚ Kubernetes å’Œ SDN æ§åˆ¶å™¨ï¼‰å­˜åœ¨ä»¥ä¸‹æŒ‘æˆ˜ï¼š

- **éšç§åˆè§„æ€§éš¾ä»¥ä¿éšœ**ï¼šæ•°æ®å¿…é¡»æ»¡è¶³æ•°æ®é©»ç•™æ³•è§„ï¼ˆå¦‚ GDPRï¼‰ï¼Œå³ç‰¹å®šæ•°æ®åªèƒ½åœ¨æŒ‡å®šå¸æ³•ç®¡è¾–åŒºï¼ˆå¦‚æ¬§ç›Ÿï¼‰å†…å­˜å‚¨å’Œä¼ è¾“ã€‚
- **é…ç½®å¤æ‚ä¸”ä¾èµ–ä¸“å®¶**ï¼šå°†é«˜å±‚çº§çš„éšç§æ„å›¾ï¼ˆå¦‚â€œæ‰€æœ‰ä¸ªäººæ•°æ®ä¸å¾—ç¦»å¼€æ¬§ç›Ÿâ€ï¼‰è½¬åŒ–ä¸ºåº•å±‚çš„ Kubernetes èŠ‚ç‚¹é€‰æ‹©è§„åˆ™å’Œ SDN æµæ§ç­–ç•¥ï¼Œéœ€è¦é¢†åŸŸä¸“å®¶æ‰‹åŠ¨ç¼–å†™æ•°åæ¡ä½çº§ç­–ç•¥ã€‚
- **è·¨å±‚åè°ƒå›°éš¾**ï¼šç°æœ‰æ–¹æ¡ˆé€šå¸¸åªå…³æ³¨è®¡ç®—å±‚ï¼ˆplacementï¼‰æˆ–ç½‘ç»œå±‚ï¼ˆroutingï¼‰ï¼Œç¼ºä¹å¯¹ **compute + network** çš„è”åˆæ§åˆ¶ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§ **LLM é©±åŠ¨çš„ intent-based æ¡†æ¶**ï¼Œå®ç°è‡ªç„¶è¯­è¨€éšç§æ„å›¾åˆ°å¯æ‰§è¡Œç­–ç•¥çš„è‡ªåŠ¨åŒ–è½¬æ¢ä¸éƒ¨ç½²ï¼š

- **LLM ä½œä¸ºè‡ªç„¶è¯­è¨€æ¥å£**ï¼šä½¿ç”¨ GPT-4o å°†ç”¨æˆ·è¾“å…¥çš„è‡ªç„¶è¯­è¨€éšç§æ„å›¾ï¼ˆå¦‚â€œç¡®ä¿æ‰€æœ‰å¥åº·æ•°æ®ä»…åœ¨é«˜å®‰å…¨æ€§çš„äº‘ç«¯èŠ‚ç‚¹è¿è¡Œâ€ï¼‰è§£æä¸ºç»“æ„åŒ–ç­–ç•¥ã€‚
- **è·¨å±‚è”åˆç¼–æ’**ï¼š
  - åœ¨ **è®¡ç®—å±‚**ï¼Œç”Ÿæˆ Kubernetes çš„ `nodeSelector` æˆ–äº²å’Œæ€§è§„åˆ™ï¼Œçº¦æŸ Pod åªèƒ½è°ƒåº¦åˆ°ç¬¦åˆéšç§è¦æ±‚çš„èŠ‚ç‚¹ä¸Šã€‚
  - åœ¨ **ç½‘ç»œå±‚**ï¼Œç”Ÿæˆ SDNï¼ˆONOSï¼‰çš„æµè§„åˆ™ï¼Œç¡®ä¿æ•°æ®åŒ…ä»…é€šè¿‡åˆè§„è·¯å¾„ä¼ è¾“ï¼ˆå¦‚é¿å¼€ä¸å—ä¿¡äº¤æ¢æœºï¼‰ã€‚
- **é—­ç¯éªŒè¯æœºåˆ¶**ï¼šæ„å»ºäº†ä¸€ä¸ªè‡ªåŠ¨åŒ–çš„éªŒè¯æµæ°´çº¿ï¼Œåœ¨çœŸå® Kubernetes + ONOS æµ‹è¯•å¹³å°ä¸Šéƒ¨ç½²ç­–ç•¥ï¼Œå¹¶æ£€æŸ¥è¿è¡Œæ—¶çŠ¶æ€æ˜¯å¦æ»¡è¶³åŸå§‹æ„å›¾ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|------|--------|---------|
| **æ„å›¾è¡¨è¾¾æ–¹å¼** | DSL æˆ–é¢„å®šä¹‰ç­–ç•¥æ¨¡æ¿ | è‡ªç„¶è¯­è¨€è¾“å…¥ï¼Œéä¸“å®¶ä¹Ÿå¯ç”¨ |
| **è¦†ç›–èŒƒå›´** | å•ä¸€å±‚ï¼ˆè®¡ç®—æˆ–ç½‘ç»œï¼‰ | è·¨å±‚è”åˆæ§åˆ¶ï¼ˆcompute + networkï¼‰ |
| **è‡ªåŠ¨åŒ–ç¨‹åº¦** | æ‰‹åŠ¨é…ç½®æˆ–åŠè‡ªåŠ¨ | å…¨æµç¨‹è‡ªåŠ¨åŒ–ï¼ˆè§£æ â†’ ç¼–è¯‘ â†’ éƒ¨ç½² â†’ éªŒè¯ï¼‰ |
| **è¯„ä¼°æ‰‹æ®µ** | æ‰‹åŠ¨éªŒè¯æˆ–æœ‰é™æµ‹è¯•ç”¨ä¾‹ | æ„å»ºäº†å« 90 æ¡æ„å›¾çš„æ ‡å‡† benchmark + è‡ªåŠ¨åŒ– validator |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- æ„å»ºäº†ä¸€ä¸ªåŒ…å« **90 æ¡å¤šæ ·åŒ–éšç§æ„å›¾** çš„ benchmark æ•°æ®é›†ï¼Œåˆ†ä¸ºä¸‰ç±»ï¼š
  - **Computing-only**ï¼ˆ30 æ¡ï¼‰ï¼šä»…æ¶‰åŠè®¡ç®—èµ„æºè°ƒåº¦ï¼ˆå¦‚â€œå°† PHI å¤„ç†æœåŠ¡éƒ¨ç½²åœ¨ EU èŠ‚ç‚¹â€ï¼‰
  - **Networking-only**ï¼ˆ30 æ¡ï¼‰ï¼šä»…æ¶‰åŠç½‘ç»œè·¯å¾„æ§åˆ¶ï¼ˆå¦‚â€œæµé‡å¿…é¡»ç»è¿‡å¤‡ä»½äº¤æ¢æœº s8â€ï¼‰
  - **Hybrid**ï¼ˆ30 æ¡ï¼‰ï¼šåŒæ—¶åŒ…å«è®¡ç®—ä¸ç½‘ç»œçº¦æŸï¼ˆå¦‚â€œé¢„çº¦æœåŠ¡éƒ¨ç½²åœ¨é«˜å®‰å…¨äº‘èŠ‚ç‚¹ï¼Œä¸”é€šä¿¡éœ€ç»•ç» s8â€ï¼‰
- æ¯æ¡æ„å›¾è¿›ä¸€æ­¥æŒ‰å¤æ‚åº¦åˆ†ç±»ï¼š
  - **Simple**ï¼ˆ38 æ¡ï¼‰ï¼šå•æ¡ä»¶
  - **Complex**ï¼ˆ52 æ¡ï¼‰ï¼šå¤šæ¡ä»¶æˆ–ä¾‹å¤–æƒ…å†µ

### âš™ï¸ å®éªŒè®¾ç½®
- **å¹³å°æ¶æ„**ï¼š
  - **Orchestration Core**ï¼šK3sï¼ˆè½»é‡çº§ Kubernetesï¼‰ç”¨äºå®¹å™¨ç¼–æ’
  - **Network Controller**ï¼šONOS + Mininet + Open vSwitch æ¨¡æ‹Ÿ SDN ç½‘ç»œ
  - **LLM æ¥å£**ï¼šè°ƒç”¨ GPT-4o API è¿›è¡Œæ„å›¾è§£æ
- **åŸºç¡€è®¾æ–½æ ‡ç­¾ä½“ç³»**ï¼š
  - èŠ‚ç‚¹æ ‡æ³¨ `location=EU`, `security=high`, `zone=cloud/edge` ç­‰
  - ç½‘ç»œè®¾å¤‡æ ‡æ³¨ `mfr=CISCO/Huawei`, `location`, `trusted=yes/no` ç­‰
- **åº”ç”¨è´Ÿè½½**ï¼šæ¨¡æ‹ŸåŒ»é™¢ä¿¡æ¯ç³»ç»Ÿï¼ŒåŒ…å« `PHI-DB`, `Patient`, `Appointment` ç­‰å¾®æœåŠ¡ï¼Œå…·æœ‰ä¸åŒæ•æ„Ÿçº§åˆ«

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **End-to-end Success Rate** | æ„å›¾è¢«æ­£ç¡®è§£æã€éƒ¨ç½²å¹¶é€šè¿‡ validator æ£€æŸ¥çš„æ¯”ä¾‹ |
| **Avg. Completion Time** | ä»è¾“å…¥æ„å›¾åˆ°å®ŒæˆéªŒè¯çš„ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆç§’ï¼‰ |
| **Token Usage** | LLM è¾“å…¥è¾“å‡ºæ€» token æ•° |
| **Avg. Checks / Task** | æ¯ä¸ªæ„å›¾è§¦å‘çš„åŸå­éªŒè¯æ–­è¨€æ•°é‡ï¼ˆåæ˜ ç­–ç•¥å¤æ‚åº¦ï¼‰ |
| **Failure Mode Analysis** | å¯¹å¤±è´¥æ¡ˆä¾‹è¿›è¡Œå½’å› åˆ†æ |

### ğŸ”€ åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¯”è¾ƒäº†ä¸‰ç§ä¸»æµ LLM åœ¨ç›¸åŒ prompt æ¨¡æ¿ä¸‹çš„è¡¨ç°ï¼š
- **GPT-4o**ï¼ˆOpenAIï¼‰
- **Claude 3.5 Haiku**ï¼ˆAnthropicï¼‰
- **DeepSeek-V3 (671B)**ï¼ˆå¼€æºå¤§æ¨¡å‹ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆåŸºäº GPT-4oï¼‰

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| **æ€»ä½“æˆåŠŸç‡** | **95.6%**ï¼ˆ86/90 æˆåŠŸï¼‰ |
| **å¹³å‡ç«¯åˆ°ç«¯è€—æ—¶** | **20.97 ç§’** |
| **å¹³å‡æ¯ä»»åŠ¡ token æ•°** | 15,133 |
| **å¹³å‡æ¯ä»»åŠ¡éªŒè¯æ–­è¨€æ•°** | 3.7 ä¸ª |

### ğŸ†š ä¸å…¶ä»– LLM çš„å¯¹æ¯”ç»“æœ

| Model | Success Rate | Avg. Time (s) | Notes |
|-------|--------------|----------------|-------|
| **GPT-4o** | **95.6%** | 20.97 | æœ€é«˜å‡†ç¡®ç‡ï¼Œå“åº”å¿« |
| **Claude 3.5 Haiku** | 86.7% | ~20 | è®¡ç®—ä»»åŠ¡æ»¡åˆ†ï¼Œæ··åˆä»»åŠ¡ä¸‹é™æ˜æ˜¾ |
| **DeepSeek-V3** | 77.8% | ~88 | å“åº”ææ…¢ï¼Œå‡†ç¡®ç‡æœ€ä½ |

#### åˆ†åŸŸæˆåŠŸç‡ï¼ˆGPT-4oï¼‰ï¼š
- **Computing**: 100.0%
- **Hybrid**: 96.7%
- **Networking**: 90.3%

> ğŸ’¡ **è¯´æ˜**ï¼šç½‘ç»œå±‚ç­–ç•¥æ›´æ˜“å‡ºé”™ï¼Œå› å…¶ä¾èµ–åŠ¨æ€æ‹“æ‰‘å’Œç²¾ç¡®çš„ `<src, dst, must_go>` ä¸‰å…ƒç»„ï¼Œæ¨¡ç³Šæè¿°ä¼šå¯¼è‡´â€œno-op policyâ€ã€‚

#### æŒ‰å¤æ‚åº¦åˆ’åˆ†ï¼š
- **Simple intents**: 96.2% æˆåŠŸç‡
- **Complex intents**: 94.9% æˆåŠŸç‡  
â†’ å·®å¼‚ä¸æ˜¾è‘—ï¼Œè¡¨æ˜è¯¥æ¡†æ¶å¯¹å¤æ‚æ„å›¾å…·å¤‡è‰¯å¥½é²æ£’æ€§ã€‚

### ğŸ” æ¶ˆèå®éªŒä¸å¤±è´¥æ¨¡å¼åˆ†æ
é€šè¿‡å¯¹å¤±è´¥çš„ 4 ä¸ªæ¡ˆä¾‹è¿›è¡ŒåéªŒåˆ†æï¼Œè¯†åˆ«å‡ºå››å¤§ç³»ç»Ÿæ€§é”™è¯¯æ¥æºï¼š

| å¤±è´¥æ¨¡å¼ | æè¿° | ç¤ºä¾‹ |
|--------|------|------|
| **Semantic Congestion** | å¤šæ¡ä»¶èåˆå¥ä¸­ï¼ŒLLM ä»…æ»¡è¶³ç¬¬ä¸€ä¸ªå­å¥ | â€œA ä¸” B ä¸” Câ€ â†’ åªå¤„ç† A |
| **Ambiguous Path Specification** | ç¼ºå°‘æ˜ç¡®æº/ç›®çš„åœ°å€ | â€œä¸ host4 é€šä¿¡çš„æµé‡â€¦â€ â†’ æœªæŒ‡å®šå…·ä½“ä¸»æœºå¯¹ |
| **Hallucinated Identifiers** | ç”Ÿæˆä¸å­˜åœ¨çš„æ ‡ç­¾ | è¾“å‡º `region: eu_region`ï¼Œä½†å®é™…æ˜¯ `location=EU` |
| **Partial Topology Awareness** | å¿½ç•¥ä¸­é—´ä¼ è¾“è®¾å¤‡çš„ä½ç½®æ ‡ç­¾ | æ’é™¤ `region-b`ï¼Œä½†è·¯å¾„ä»ç»è¿‡å…¶èšåˆäº¤æ¢æœº |

âœ… **ç¼“è§£æªæ–½æœ‰æ•ˆ**ï¼šå¯¹å¤±è´¥æ„å›¾è¿›è¡Œ **å¥å­åˆ†è§£** æˆ– **æ˜¾å¼æšä¸¾çº¦æŸ** åï¼Œé‡è¯•å‡æˆåŠŸã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **GPT-4o èƒ½é«˜æ•ˆå°†è‡ªç„¶è¯­è¨€éšç§æ„å›¾è½¬åŒ–ä¸ºå¯æ‰§è¡Œç­–ç•¥**ï¼Œåœ¨ 90 ä¸ªæµ‹è¯•æ„å›¾ä¸­è¾¾åˆ° **95.6% çš„ç«¯åˆ°ç«¯æˆåŠŸç‡**ï¼Œå¹³å‡å»¶è¿Ÿçº¦ **21 ç§’**ï¼Œå…·å¤‡å®ç”¨ä»·å€¼ã€‚
2. **è·¨å±‚è”åˆæ§åˆ¶æ˜¯å¯è¡Œä¸”å¿…è¦çš„**ï¼šå•ä¸€è®¡ç®—æˆ–ç½‘ç»œç­–ç•¥ä¸è¶³ä»¥ä¿è¯éšç§åˆè§„ï¼›æœ¬æ–‡é¦–æ¬¡å®ç°äº† compute + network çš„ç»Ÿä¸€ intent ç¼–è¯‘ä¸éªŒè¯ã€‚
3. **è‡ªåŠ¨åŒ–éªŒè¯è‡³å…³é‡è¦**ï¼šäººå·¥éªŒè¯æˆæœ¬é«˜æ˜‚ï¼ˆå¯è¾¾æ•°å°æ—¶ï¼‰ï¼Œè€Œæœ¬æ–‡çš„ validator å¯åœ¨å‡ ç§’å†…å®Œæˆé—­ç¯æ£€æŸ¥ï¼Œæå¤§æå‡å¯é æ€§ã€‚
4. **Hybrid intents æ˜¯æœ€éš¾å¤„ç†çš„ç±»åˆ«**ï¼šè™½ç„¶æˆåŠŸç‡ä»é«˜è¾¾ 96.7%ï¼Œä½†å…¶å¹³å‡è€—æ—¶è¾¾ **39.2 ç§’**ï¼Œtoken æ¶ˆè€—è¶… 28kï¼Œå»ºè®®é‡‡ç”¨ **è½»é‡çº§æ„å›¾åˆ†è§£** ç­–ç•¥ä¼˜åŒ–ã€‚

### âš ï¸ å±€é™æ€§
- **ä¾èµ–æ ‡ç­¾å®Œæ•´æ€§ä¸ä¸€è‡´æ€§**ï¼šè‹¥èŠ‚ç‚¹æˆ–ç½‘ç»œè®¾å¤‡æœªæ­£ç¡®æ ‡æ³¨ï¼ˆå¦‚ç¼ºå¤± `location` å­—æ®µï¼‰ï¼Œåˆ™æ— æ³•æ­£ç¡®æ‰§è¡Œç­–ç•¥ã€‚
- **å¤–éƒ¨ LLM å­˜åœ¨éšç§æ³„éœ²é£é™©**ï¼šç”¨æˆ·æ„å›¾å¯èƒ½åŒ…å«æ•æ„Ÿä¸Šä¸‹æ–‡ï¼Œéœ€è€ƒè™‘æ•°æ®è„±æ•æˆ–æœ¬åœ°åŒ–éƒ¨ç½²ã€‚
- **å½“å‰ success rate ä¸è¶³ä»¥æ”¯æŒå®Œå…¨æ— äººå¹²é¢„éƒ¨ç½²**ï¼š95.6% è™½é«˜ï¼Œä½†åœ¨é«˜å…³é”®æ€§åœºæ™¯ï¼ˆå¦‚åŒ»ç–—ã€é‡‘èï¼‰ä»éœ€ human-in-the-loop å®¡æ ¸ã€‚
- **æµ‹è¯•ç¯å¢ƒä¸ºå—æ§ä»¿çœŸå¹³å°**ï¼šå°šæœªåœ¨å¤§è§„æ¨¡ã€å¤šç§Ÿæˆ·ç”Ÿäº§ç¯å¢ƒä¸­éªŒè¯ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **è‡ªåŠ¨æ„å›¾åˆ†è§£ï¼ˆAutomatic Intent Decompositionï¼‰**ï¼šå°†å¤æ‚ hybrid intent æ‹†è§£ä¸ºå¤šä¸ªç®€å•å­ä»»åŠ¡ï¼Œé™ä½ LLM è§£æéš¾åº¦ã€‚
2. **é¢†åŸŸé€‚é…ä¸å¾®è°ƒï¼ˆDomain Adaptation/Fine-tuningï¼‰**ï¼šè®­ç»ƒä¸“ç”¨ LLM ä»¥å‡å°‘å¹»è§‰å’Œæ ‡ç­¾è¯¯ç”¨ã€‚
3. **å¢å¼º label schema portability**ï¼šè®¾è®¡è·¨äº‘å‚å•†é€šç”¨çš„æ ‡ç­¾æ ‡å‡†ï¼Œæå‡å¯ç§»æ¤æ€§ã€‚
4. **å®è¯ç ”ç©¶ï¼ˆEmpirical Studyï¼‰**ï¼šåœ¨çœŸå®è¡Œä¸šåœºæ™¯ï¼ˆå¦‚ healthcare IoTã€regulated financeï¼‰ä¸­è¯„ä¼°æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸äººå·¥é…ç½®åŸºçº¿å¯¹æ¯”ã€‚
5. **fail-closed éƒ¨ç½²æœºåˆ¶**ï¼šå¯¹äºå…³é”®æ„å›¾ï¼Œå¼•å…¥åˆ†é˜¶æ®µ rollout å’Œå®¡æ‰¹æµç¨‹ï¼Œé˜²æ­¢é”™è¯¯ç­–ç•¥ä¸Šçº¿ã€‚

---

> ğŸ§  **æœ€ç»ˆæ„¿æ™¯**ï¼šè®©ç”¨æˆ·åªéœ€â€œè¯´å‡ºéšç§åå¥½â€ï¼ŒAI å³å¯è‡ªåŠ¨å°†å…¶è½¬åŒ–ä¸º Kubernetes + SDN ä¸­çš„ enforceable policies â€”â€” å®ç° **human intent ä¸ machine execution çš„æ— ç¼å¯¹é½**ã€‚

</details>

---

### 8. [push0: Scalable and Fault-Tolerant Orchestration for Zero-Knowledge Proof Generation](https://arxiv.org/abs/2602.16338)

**Authors**: Mohsen Ahmadvand, Rok Pajni\v{c}, Ching-Lun Chiu  
**Category**: cs.DC  
**Published**: 2026-02-19  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.16338v1  

#### Abstract
Zero-knowledge proof generation imposes stringent timing and reliability constraints on blockchain systems. For ZK-rollups, delayed proofs cause finality lag and economic loss; for Ethereum's emerging L1 zkEVM, proofs must complete within the 12-second slot window to enable stateless validation. The...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼špush0: Scalable and Fault-Tolerant Orchestration for Zero-Knowledge Proof Generation**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
é›¶çŸ¥è¯†è¯æ˜ï¼ˆZKPsï¼‰åœ¨åŒºå—é“¾ç³»ç»Ÿä¸­æ‰®æ¼”ç€å…³é”®è§’è‰²ï¼Œå°¤å…¶åœ¨ **ZK-Rollups** å’Œä»¥å¤ªåŠå³å°†æ¨å‡ºçš„ **L1 zkEVM** ä¸­ã€‚ç„¶è€Œï¼ŒZK è¯æ˜ç”Ÿæˆé¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **ä¸¥æ ¼çš„æ—¶åºçº¦æŸ**ï¼šL1 zkEVM è¦æ±‚åœ¨ 12 ç§’çš„ slot å†…å®Œæˆè¯æ˜ç”Ÿæˆï¼ˆP99 < 10sï¼‰ï¼Œå¦åˆ™æ— æ³•å‚ä¸å…±è¯†ã€‚
- **é“¾å¤´é¡ºåºä¸€è‡´æ€§**ï¼šå¿…é¡»æŒ‰åŒºå—é¡ºåºç”Ÿæˆè¯æ˜ï¼Œé¿å…â€œé“¾åœæ»â€ï¼ˆchain haltï¼‰ã€‚
- **å®¹é”™ä¸ä»»åŠ¡é‡åˆ†é…**ï¼šç¡¬ä»¶æ•…éšœã€GPU å†…å­˜æº¢å‡ºç­‰å¸¸è§é—®é¢˜éœ€è‡ªåŠ¨æ¢å¤ã€‚
- **å¼‚æ„ zkVM æ”¯æŒ**ï¼šä¸åŒè¯æ˜ç³»ç»Ÿï¼ˆå¦‚ STARKã€SNARKã€é€’å½’èšåˆï¼‰æµç¨‹å·®å¼‚å¤§ï¼Œéš¾ä»¥ç»Ÿä¸€è°ƒåº¦ã€‚
- **ç¼ºä¹æ ‡å‡†åŒ–çš„ç¼–æ’æ¡†æ¶**ï¼šç°æœ‰æ–¹æ¡ˆè¦ä¹ˆæ˜¯ä¸­å¿ƒåŒ–ã€å°é—­ç³»ç»Ÿï¼Œè¦ä¹ˆç¼ºä¹ä¸¥æ ¼æ’åºå’Œå®¹é”™æœºåˆ¶ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡º **push0** â€”â€” ä¸€ä¸ªäº‘åŸç”Ÿã€äº‹ä»¶é©±åŠ¨çš„ **ZK è¯æ˜ç¼–æ’ç³»ç»Ÿ**ï¼Œå…¶æ ¸å¿ƒè®¾è®¡åŒ…æ‹¬ï¼š

#### âœ… **Dispatcher-Collector æ¶æ„**
- **Dispatcher**ï¼šä»ä¼˜å…ˆçº§é˜Ÿåˆ—æ‹‰å–ä»»åŠ¡ï¼Œè°ƒç”¨ prover äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œæ— çŠ¶æ€ï¼Œå¯æ°´å¹³æ‰©å±•ã€‚
- **Collector**ï¼šæ¥æ”¶å¤šä¸ªè¾“å…¥æµï¼Œé€šè¿‡å¯æ’æ‹”çš„ **collection strategy**ï¼ˆå¦‚ Matchã€Sequentialï¼‰è¿›è¡Œèšåˆï¼Œå®ç°å±éšœåŒæ­¥ï¼ˆbarrier synchronizationï¼‰ã€‚
- **æ¶ˆæ¯æ€»çº¿**ï¼ˆMessage Busï¼‰ï¼šåŸºäºæŒä¹…åŒ–ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼ˆå¦‚ NATS JetStreamï¼‰ï¼Œç¡®ä¿ä»»åŠ¡ä¸ä¸¢å¤±ï¼Œå¹¶æ”¯æŒ at-least-once è¯­ä¹‰ã€‚

#### âœ… **éšå¼å·¥ä½œæµå»ºæ¨¡**
- å·¥ä½œæµï¼ˆworkflow DAGï¼‰é€šè¿‡ **é˜Ÿåˆ—æ‹“æ‰‘å’Œæ”¶é›†ç­–ç•¥** éšå¼å®šä¹‰ï¼Œæ— éœ€æ˜¾å¼ DAG æ•°æ®ç»“æ„ã€‚
- æ”¯æŒå¤šé˜Ÿåˆ—å¹¶è¡Œæµæ°´çº¿ï¼ˆmulti-queue pipelineï¼‰ï¼Œå®ç° **ææ¡ˆæµï¼ˆproposer flowï¼‰** ä¸ **è¯æ˜æµï¼ˆproving flowï¼‰** è§£è€¦ã€‚

#### âœ… **åˆ†åŒºäº²å’Œè·¯ç”±ï¼ˆPartition-Affine Routingï¼‰**
- æ‰€æœ‰å±äºåŒä¸€èšåˆç»„ï¼ˆå¦‚ block_numï¼‰çš„æ¶ˆæ¯è¢«è·¯ç”±åˆ°åŒä¸€ä¸ª Collectorï¼Œè§£å†³ **barrier fragmentation** é—®é¢˜ã€‚
- è·¯ç”±å…¬å¼ï¼š`partition(m) = h(g) mod C`ï¼Œå…¶ä¸­ `g` æ˜¯åˆ†ç»„é”®ï¼ˆå¦‚ block_numï¼‰ï¼Œ`C` æ˜¯ Collector æ•°é‡ã€‚

#### âœ… **Prover-Agnostic è®¾è®¡**
- æ”¯æŒä¸¤ç§é›†æˆæ¨¡å¼ï¼š
  - **JSON Executor**ï¼šé€‚ç”¨äº CLI å·¥å…·ï¼Œé€šè¿‡ `--input-path` å’Œ `--output-path` æ¥å£è°ƒç”¨ã€‚
  - **Composer Executor**ï¼šé€‚ç”¨äº Rust åº“ï¼Œç›´æ¥è°ƒç”¨ `prove()` å‡½æ•°ï¼Œé›¶æ‹·è´å…±äº«å†…å­˜ã€‚
- ç¼–æ’å±‚å®Œå…¨ä¸ prover è§£è€¦ï¼Œåªéœ€åœ¨è°ƒç”¨è¾¹ç•Œé€‚é…ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç‰¹æ€§ | push0 | DIZK / SHARP | Decentralized Markets (Snarktor, zkCloud) | Kubernetes |
|------|-------|---------------|------------------------------------------|------------|
| **Head-of-chain ordering** | âœ… ä¸¥æ ¼ä¿è¯ | âŒ ä¾èµ–ä¸­å¿ƒåŒ–æ§åˆ¶ | âŒ æ— ä¿éšœ | âŒ æ— å†…ç½®æœºåˆ¶ |
| **Fault tolerance** | âœ… è‡ªåŠ¨é‡è¯•ã€å¿ƒè·³ã€çº¢é˜Ÿäº¤ä»˜ | âš ï¸ æœ‰é™ | âš ï¸ ä¾èµ–ç»æµæ¿€åŠ± | âœ… ä½†éœ€è‡ªå®šä¹‰ Operator |
| **Prover agnosticism** | âœ… å®Œå…¨æ”¯æŒå¼‚æ„ zkVM | âŒ ç»‘å®šç‰¹å®šç³»ç»Ÿ | âœ… ä½†è°ƒåº¦ä¸å¯æ§ | âœ… ä½†æ— ç¼–æ’è¯­ä¹‰ |
| **Horizontal scalability** | âœ… æ— çŠ¶æ€ Dispatcher å¯æ‰©å±• | âœ… ä½†åŒæ„ | âœ… | âœ… |
| **Observability** | âœ… Prometheus + OpenTelemetry | âŒ | âŒ | âœ… ä½†éœ€é¢å¤–å¼€å‘ |
| **Barrier synchronization** | âœ… Collector + åˆ†åŒºäº²å’Œ | âš ï¸ æ‰‹åŠ¨ç®¡ç† | âŒ | âŒ |

> **æ ¸å¿ƒä¼˜åŠ¿**ï¼špush0 æ˜¯é¦–ä¸ªåŒæ—¶æ»¡è¶³ **å…­ä¸ªç”Ÿäº§çº§è¦æ±‚** çš„ ZK ç¼–æ’ç³»ç»Ÿï¼š
> 1. Head-of-chain ordering  
> 2. Bounded latency  
> 3. Fault tolerance  
> 4. Prover agnosticism  
> 5. Horizontal scalability  
> 6. Observability

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **å®éªŒç¯å¢ƒ**
- **ä¸»å®éªŒ**ï¼š3 èŠ‚ç‚¹ AWS Kubernetes é›†ç¾¤ï¼ˆt3.mediumï¼Œ2 vCPUï¼Œ4GB RAMï¼‰ï¼Œä½¿ç”¨ **Synadia NGS**ï¼ˆäº‘æ‰˜ç®¡ NATSï¼‰ä½œä¸ºæ¶ˆæ¯æ€»çº¿ã€‚
- **éªŒè¯å®éªŒ**ï¼šå•æœº Docker Composeï¼ˆApple M3 Maxï¼Œ36GB RAMï¼‰ï¼Œæœ¬åœ° NATS JetStreamï¼Œæ¶ˆé™¤ç½‘ç»œæ³¢åŠ¨å½±å“ã€‚

### **æ¨¡æ‹Ÿ Prover**
- ä½¿ç”¨ **echo executor** æ¨¡æ‹Ÿä¸åŒå»¶è¿Ÿçš„è¯æ˜ä»»åŠ¡ï¼ˆ0ms ~ 5sï¼‰ï¼Œéš”ç¦»çº¯ç¼–æ’å¼€é”€ã€‚
- çœŸå® workload ä½¿ç”¨ **SP1 GPU prover** è¿›è¡Œç”Ÿäº§éƒ¨ç½²éªŒè¯ã€‚

### **å·¥ä½œè´Ÿè½½ç”Ÿæˆ**
- Python è„šæœ¬å‘ NATS å‘å¸ƒ JSON æ¶ˆæ¯ï¼ŒåŒ…å« `block_num`ã€`task_id` ç­‰å­—æ®µã€‚
- ä»»åŠ¡æ•°é‡éš Dispatcher æ•°é‡çº¿æ€§å¢é•¿ï¼ˆ`N = 10 Ã— D`ï¼‰ï¼Œç¡®ä¿è´Ÿè½½å‡è¡¡ã€‚

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Orchestration Overhead** | ä»ä»»åŠ¡å‘å¸ƒåˆ°ç»“æœæ¥æ”¶çš„æ—¶é—´ï¼ˆä¸å« prover æ‰§è¡Œæ—¶é—´ï¼‰ |
| **P50 / P99 Latency** | ç¼–æ’å»¶è¿Ÿçš„ä¸­ä½æ•°å’Œå°¾éƒ¨å»¶è¿Ÿ |
| **Scaling Efficiency** | `S/D`ï¼Œå³åŠ é€Ÿæ¯”é™¤ä»¥ Dispatcher æ•°é‡ï¼Œè¡¡é‡å¹¶è¡Œæ•ˆç‡ |
| **Memory Consumption** | å„ç»„ä»¶å†…å­˜å ç”¨ |
| **Fault Recovery Time** | ç»„ä»¶å´©æºƒåä»»åŠ¡æ¢å¤æ—¶é—´ |
| **Barrier Completion Rate** | å¤šè¾“å…¥ Collector æˆåŠŸèšåˆçš„æ¯”ä¾‹ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Linear Pipeline**ï¼šä¸²è¡Œå¤„ç†ï¼Œæ¯é˜¶æ®µé˜»å¡å‰ä¸€é˜¶æ®µã€‚
- **Round-Robin Routing**ï¼šCollector é—´è½®è¯¢åˆ†é…æ¶ˆæ¯ï¼Œæ— åˆ†åŒºäº²å’Œã€‚
- **No Heartbeat**ï¼šä¸å¯ç”¨å¿ƒè·³æœºåˆ¶ï¼Œæµ‹è¯•é•¿ä»»åŠ¡è¶…æ—¶è¡Œä¸ºã€‚

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **æä½çš„ç¼–æ’å¼€é”€**
| ç¯å¢ƒ | æ³¨å…¥é€Ÿç‡ (tasks/s) | P50 (ms) | P99 (ms) |
|------|---------------------|----------|----------|
| Kubernetes + Synadia NGS | 10â€“100 | **5.2â€“5.3** | **8.0â€“8.5** |
| Docker + Local NATS | 100 | **2.7** | **4.9** |

> - ç¼–æ’å¼€é”€ä»…å å…¸å‹è¯æ˜æ—¶é—´ï¼ˆ7+ ç§’ï¼‰çš„ **<0.1%**ã€‚
> - å³ä½¿åœ¨é«˜è´Ÿè½½ä¸‹ä»ä¿æŒç¨³å®šã€‚

#### âœ… **è¿‘ä¹å®Œç¾çš„æ°´å¹³æ‰©å±•æ•ˆç‡**
| Prover å»¶è¿Ÿ | 1 Dispatcher | 32 Dispatchers | æ•ˆç‡ |
|-------------|--------------|----------------|------|
| 0msï¼ˆå‹åŠ›æµ‹è¯•ï¼‰ | 100% | 14% | ä½ï¼ˆåè°ƒå¼€é”€ä¸»å¯¼ï¼‰ |
| 100ms | 100% | 55% | ä¸­ç­‰ |
| **1s** | 100% | **99%** | âœ… å‡ ä¹å®Œç¾ |
| **5s** | 100% | **100%** | âœ… å®Œç¾çº¿æ€§æ‰©å±• |

> - å¯¹äºçœŸå® ZK workloadï¼ˆ1s+ï¼‰ï¼Œpush0 å®ç° **99â€“100% æ‰©å±•æ•ˆç‡**ã€‚

#### âœ… **åˆ†åŒºäº²å’Œè·¯ç”±æ˜¾è‘—æå‡å±éšœå®Œæˆç‡**
| è·¯ç”±ç­–ç•¥ | Collector æ•° | Barrier è¾“å…¥æ•° | å®Œæˆç‡ |
|--------|-------------|----------------|--------|
| Round-Robin | 4 | 4 | **5%**ï¼ˆç†è®ºå€¼ 1.56%ï¼‰ |
| **Partition-Affine** | 4 | 4 | **100%** |

> - æœ´ç´ è´Ÿè½½å‡è¡¡å¯¼è‡´ **95% çš„å±éšœå¤±è´¥**ï¼Œè€Œåˆ†åŒºäº²å’Œè·¯ç”±å½»åº•è§£å†³æ­¤é—®é¢˜ã€‚

#### âœ… **å¤šé˜Ÿåˆ—æ¶æ„æ˜¾è‘—æå‡å®¹é”™èƒ½åŠ›**
| æ¶æ„ | æ€»è€—æ—¶ (s) | æœ€ç»ˆæ€§åç§»ï¼ˆblocksï¼‰ | è¯´æ˜ |
|------|-----------|----------------------|------|
| **Multi-Queue (push0)** | **23.9** | 25 | ææ¡ˆæµç»§ç»­æ¨è¿› |
| Linear Pipeline | 101.5 | 0ï¼ˆé˜»å¡ï¼‰ | å…¨é“¾é˜»å¡ |

> - åœ¨æ³¨å…¥ä¸€ä¸ª 15 ç§’â€œæ¯’ä»»åŠ¡â€æ—¶ï¼Œpush0 ä»èƒ½æŒç»­æäº¤ææ¡ˆï¼Œ**æé€Ÿ 4.2Ã—**ã€‚

#### âœ… **å®¹é”™æ¢å¤è¡¨ç°ä¼˜å¼‚**
| æ•…éšœç±»å‹ | æ¢å¤åœºæ™¯ | MTTR |
|--------|----------|------|
| Dispatcher Crash | å­˜æ´» Dispatcher å­˜åœ¨ | **~0.5s** |
| Dispatcher Crash | æ‰€æœ‰ Dispatcher å´©æºƒ | = ACK Timeoutï¼ˆé»˜è®¤ 30sï¼‰ |
| Collector Crash | é‡å¯å | **0.5s**ï¼Œæ‰€æœ‰ barrier å®Œæˆ |

> - åˆ©ç”¨å¿ƒè·³æœºåˆ¶ï¼Œé•¿ä»»åŠ¡ä¸ä¼šå› è¶…æ—¶è¢«è¯¯é‡å‘ã€‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ç¼–æ’å±‚æ˜¯ ZK ç³»ç»Ÿå¯é æ€§çš„ç“¶é¢ˆ**ï¼šç”Ÿäº§ä¸­å¤§å¤šæ•°æ•…éšœæ¥è‡ªç¼–æ’ç³»ç»Ÿè€Œé prover æœ¬èº«ã€‚
2. **Dispatcher-Collector æ¶æ„æœ‰æ•ˆè§£è€¦é¡ºåºä¸å¹¶è¡Œæ€§**ï¼šé€šè¿‡ä¼˜å…ˆçº§é˜Ÿåˆ—ä¿è¯åŒºå—é¡ºåºï¼Œé€šè¿‡ Collector å®ç°å—å†…å¹¶è¡Œã€‚
3. **åˆ†åŒºäº²å’Œè·¯ç”±å¯¹å±éšœåŒæ­¥è‡³å…³é‡è¦**ï¼šé¿å… barrier fragmentationï¼Œæ˜¯å®ç°é«˜å¯ç”¨èšåˆçš„å‰æã€‚
4. **Prover-Agnostic è®¾è®¡æå¤§æå‡å¯ç»´æŠ¤æ€§**ï¼šä» Halo2 è¿ç§»åˆ° SP1 ä»…éœ€é…ç½®å˜æ›´å’Œå°‘é‡èƒ¶æ°´ä»£ç ã€‚
5. **ç”Ÿæ€æœ‰æ•ˆæ€§å·²éªŒè¯**ï¼šè‡ª 2025 å¹´ 3 æœˆ 4 æ—¥èµ·åœ¨ Zircuit zkRollup ä¸Šè¿è¡Œï¼Œå¤„ç† **1400 ä¸‡+ ä¸»ç½‘åŒºå—**ï¼Œé›¶ç¼–æ’æ•…éšœã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
1. **æ¶ˆæ¯æ€»çº¿ä¸ºä¿¡ä»»æ ¹**ï¼šå½“å‰å‡è®¾æ¶ˆæ¯æ€»çº¿å¯ä¿¡ï¼Œä¸æ”¯æŒæ‹œå åº­å®¹é”™ã€‚
2. **æœªæä¾›å»ä¸­å¿ƒåŒ–æ¿€åŠ±æœºåˆ¶**ï¼šé€‚ç”¨äºä¸­å¿ƒåŒ–è¿è¥å•†æˆ–è”ç›Ÿé“¾ï¼Œå°šæœªé›†æˆä»£å¸æ¿€åŠ±ã€‚
3. **ä¿å¯†æ€§éœ€åº”ç”¨å±‚ä¿éšœ**ï¼šè¯æ˜è¾“å…¥æœªåŠ å¯†ï¼Œéœ€å¤–éƒ¨æœºåˆ¶ä¿æŠ¤éšç§ã€‚
4. **é™æ€æ‹“æ‰‘é…ç½®**ï¼šé˜Ÿåˆ—æ‹“æ‰‘å’Œ Collector ç­–ç•¥éœ€é¢„å…ˆé…ç½®ï¼ŒåŠ¨æ€å˜æ›´éœ€é‡å¯ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **å»ä¸­å¿ƒåŒ–ç¼–æ’å±‚**ï¼šç»“åˆå…±è¯†æœºåˆ¶å®ç°æŠ—å®¡æŸ¥çš„ä»»åŠ¡åˆ†é…ä¸ç»“æœéªŒè¯ã€‚
2. **æ¿€åŠ±å…¼å®¹çš„ Prover å¸‚åœº**ï¼šé›†æˆç»æµæ¨¡å‹ï¼Œæ”¯æŒå¼€æ”¾å‚ä¸çš„ proving ç½‘ç»œã€‚
3. **è‡ªåŠ¨åŒ–å·¥ä½œæµä¼˜åŒ–**ï¼šåŸºäºå†å²æ•°æ®åŠ¨æ€è°ƒæ•´ Collector æ•°é‡ã€è¶…æ—¶å‚æ•°ç­‰ã€‚
4. **è·¨é“¾è¯æ˜ç¼–æ’**ï¼šæ”¯æŒå¤šé“¾å¹¶è¡Œè¯æ˜ç”Ÿæˆä¸èšåˆã€‚

---

> **æ€»ç»“**ï¼š  
> push0 æ˜¯é¦–ä¸ªé¢å‘ç”Ÿäº§çº§ ZK ç³»ç»Ÿçš„ **é€šç”¨ã€å¯æ‰©å±•ã€å®¹é”™** çš„ç¼–æ’æ¡†æ¶ã€‚å®ƒä¸ä»…è§£å†³äº† L1 zkEVM å’Œ ZK-Rollups çš„å®æ—¶æ€§ä¸å¯é æ€§æŒ‘æˆ˜ï¼Œè¿˜ä¸ºæœªæ¥å»ä¸­å¿ƒåŒ– proving ç½‘ç»œæä¾›äº†åŸºç¡€æ¶æ„ã€‚å…¶æ ¸å¿ƒæ€æƒ³â€”â€”**é€šè¿‡äº‹ä»¶é©±åŠ¨ + æŒä¹…é˜Ÿåˆ— + åˆ†åŒºäº²å’Œ** å®ç°ä¸¥æ ¼é¡ºåºä¸é«˜åº¦å¹¶è¡Œçš„ç»Ÿä¸€â€”â€”å¯¹åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡å…·æœ‰å¹¿æ³›å€Ÿé‰´æ„ä¹‰ã€‚

</details>

---

### 9. [Adaptive Semi-Supervised Training of P300 ERP-BCI Speller System with Minimum Calibration Effort](https://arxiv.org/abs/2602.15955)

**Authors**: Shumeng Chen, Jane E. Huggins, Tianwen Ma  
**Category**: cs.LG  
**Published**: 2026-02-19  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.15955v1  

#### Abstract
A P300 ERP-based Brain-Computer Interface (BCI) speller is an assistive communication tool. It searches for the P300 event-related potential (ERP) elicited by target stimuli, distinguishing it from the neural responses to non-target stimuli embedded in electroencephalogram (EEG) signals. Conventiona...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Adaptive Semi-Supervised Training of P300 ERP-BCI Speller System with Minimum Calibration Effort*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåŸºäº P300 ERP çš„ BCI æ‹¼å†™ç³»ç»Ÿä¾èµ–**å¤§é‡æ ‡æ³¨æ•°æ®è¿›è¡Œæ ¡å‡†ï¼ˆcalibrationï¼‰**ï¼Œè¿™ä¸€è¿‡ç¨‹è€—æ—¶é•¿ã€æ˜“å¼•èµ·ç”¨æˆ·ç–²åŠ³ï¼Œé™åˆ¶äº†ç³»ç»Ÿçš„å®æ—¶æ€§å’Œå®ç”¨æ€§ã€‚å°¤å…¶æ˜¯åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè·å–é«˜è´¨é‡æ ‡æ³¨ EEG æ•°æ®å›°éš¾ï¼Œä¸¥é‡å½±å“ç³»ç»Ÿéƒ¨ç½²æ•ˆç‡ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§**è‡ªé€‚åº”åŠç›‘ç£å­¦ä¹ æ¡†æ¶ï¼ˆadaptive semi-supervised EM-GMMï¼‰**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åˆ©ç”¨å°‘é‡æ ‡æ³¨æ•°æ®åˆå§‹åŒ–æ¨¡å‹ï¼›
- åœ¨åç»­ä½¿ç”¨è¿‡ç¨‹ä¸­æŒç»­åˆ©ç”¨æœªæ ‡æ³¨çš„å®æ—¶ EEG è¾“å…¥æ•°æ®ï¼Œé€šè¿‡ Expectation-Maximization ç®—æ³•ç»“åˆ Gaussian Mixture Modelï¼ˆEM-GMMï¼‰åŠ¨æ€æ›´æ–°åˆ†ç±»å™¨å‚æ•°ï¼›
- å®ç°â€œè¾¹æ‹¼å†™ã€è¾¹è®­ç»ƒâ€çš„åœ¨çº¿è‡ªé€‚åº”æœºåˆ¶ï¼Œæ˜¾è‘—å‡å°‘åˆå§‹æ ¡å‡†è´Ÿæ‹…ã€‚

è¯¥æ–¹æ³•ç›´æ¥å¯¹ EEG ç‰¹å¾å‘é‡å»ºæ¨¡ï¼ˆè€Œéä»…ä½œç”¨äºå†…ç§¯ï¼‰ï¼Œå¹¶å‡è®¾ç›®æ ‡ä¸éç›®æ ‡ ERP å…±äº«åæ–¹å·®çŸ©é˜µï¼Œæå‡äº†æ¨¡å‹ç¨³å®šæ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚

### âš–ï¸ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ SVM, LDA, CNNï¼‰ | æœ¬æ–‡æ–¹æ³• |
|------|-------------------------------|--------|
| æ•°æ®éœ€æ±‚ | éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ç”¨äºç¦»çº¿è®­ç»ƒ | ä»…éœ€æå°é‡æ ‡æ³¨æ•°æ®å³å¯å¯åŠ¨ï¼Œåç»­æ— éœ€äººå·¥æ ‡æ³¨ |
| æ ¡å‡†æ—¶é—´ | é•¿ï¼ˆé€šå¸¸éœ€æ‹¼å†™å®Œæ•´å¥å­ï¼‰ | æçŸ­ï¼ˆçº¦10ä¸ªå­—ç¬¦å³å¯å¼€å§‹è‡ªç”±è¾“å…¥ï¼‰ |
| å­¦ä¹ èŒƒå¼ | å®Œå…¨ç›‘ç£å­¦ä¹  | åŠç›‘ç£ + è‡ªé€‚åº”åœ¨çº¿å­¦ä¹  |
| å®ç”¨æ€§ | å—é™äºç”¨æˆ·è€åŠ›å’Œæ³¨æ„åŠ›æ³¢åŠ¨ | æ›´é€‚åˆé•¿æœŸã€å®æ—¶äº¤äº’åœºæ™¯ |

> ğŸ” **å…³é”®ä¼˜åŠ¿æ€»ç»“**ï¼šåœ¨ä¿è¯é«˜æ‹¼å†™å‡†ç¡®ç‡çš„å‰æä¸‹ï¼Œå°†æ ¡å‡†åŠªåŠ›æœ€å°åŒ–ï¼Œæå‡ BCI ç³»ç»Ÿçš„æ•´ä½“å¯ç”¨æ€§ï¼ˆutilityï¼‰å’Œç”¨æˆ·ä½“éªŒã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **çœŸå®æ•°æ®æ¥æº**ï¼šæ¥è‡ªå¯†æ­‡æ ¹å¤§å­¦ Direct Brain Interface Labï¼ˆUM-DBIï¼‰çš„å…¬å¼€ EEG æ•°æ®é›†ã€‚
- **å‚ä¸è€…æ•°é‡**ï¼šå…±15åè¢«è¯•ï¼ˆparticipantsï¼‰ï¼Œæ¯äººå®Œæˆä¸€ä¸ªè®­ç»ƒä»»åŠ¡ï¼ˆTRNï¼‰å’Œæœ€å¤šä¸‰ä¸ªè‡ªç”±æ‹¼å†™æµ‹è¯•ä»»åŠ¡ï¼ˆFRTï¼‰ã€‚
- **EEG è®¾ç½®**ï¼š
  - 16é€šé“ EEG ç”µæï¼ˆF3, Fz, F4, C3, Cz, C4, P3, Pz, P4, Oz ç­‰ï¼‰ï¼›
  - é‡‡æ ·é¢‘ç‡ 256 Hzï¼Œç» notch filterï¼ˆ60Hzï¼‰ã€band-pass filterï¼ˆ0.5â€“6 Hzï¼‰å¤„ç†ï¼Œå¹¶ä¸‹é‡‡æ ·è‡³ 32 Hzï¼›
  - ä½¿ç”¨ xDAWN è¿›è¡Œç©ºé—´æ»¤æ³¢é™ç»´ï¼Œæå–å‰ä¸¤ä¸ªæ­£äº¤æˆåˆ†ä½œä¸ºç‰¹å¾ã€‚

### ğŸ§ª å®éªŒè®¾ç½®
- **åˆºæ¿€èŒƒå¼**ï¼šé‡‡ç”¨ Row-Column Paradigmï¼ˆRCPï¼‰ï¼Œ6Ã—6 è™šæ‹Ÿé”®ç›˜ï¼Œæ¯è½®é—ªçƒ12æ¬¡ï¼ˆ6è¡Œ+6åˆ—ï¼‰ï¼›
- **åºåˆ—å®šä¹‰**ï¼šæ¯ä¸ªå­—ç¬¦å¯¹åº”ä¸€ä¸ª super-sequenceï¼ŒåŒ…å«15ä¸ª sequencesï¼ˆå…±180æ¬¡é—ªçƒï¼‰ï¼›
- **è®­ç»ƒé˜¶æ®µ**ï¼šè¦æ±‚è¢«è¯•æ‹¼å†™ â€œTHE QUICK BROWN_FOXâ€ï¼ˆå…±19å­—ç¬¦ï¼Œå«ç©ºæ ¼ï¼‰ï¼›
- **æµ‹è¯•é˜¶æ®µ**ï¼šå…è®¸è‡ªç”±æ‹¼å†™ï¼Œç³»ç»Ÿæ ¹æ®é¢„æµ‹æ¦‚ç‡åŠ¨æ€åœæ­¢è¾“å‡ºå­—ç¬¦ï¼ˆdynamic stopping criterionï¼Œé˜ˆå€¼ Î¸=0.9ï¼‰ï¼›

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Character-level Accuracy (p)** | æµ‹è¯•é›†ä¸­æ­£ç¡®è¯†åˆ«å­—ç¬¦çš„æ¯”ä¾‹ï¼Œè¦æ±‚ â‰¥0.7 æ‰å…·å®ç”¨ä»·å€¼ |
| **Information Transfer Rate (ITR)** | è¡¡é‡é€šä¿¡æ•ˆç‡ï¼ˆå•ä½ï¼šbits/minï¼‰ï¼Œç»¼åˆè€ƒè™‘å‡†ç¡®æ€§ä¸é€Ÿåº¦ |
| **BCI Utility** | ç»¼åˆ ITR å’Œå‡†ç¡®æ€§çš„åŠ æƒæŒ‡æ ‡ï¼Œå½“ p < 0.5 æ—¶ä¸º0ï¼Œæ›´è´´è¿‘å®é™…å¯ç”¨æ€§ |

### ğŸ” å¯¹æ¯”åŸºçº¿æ–¹æ³•
- **Offline EM-GMM**ï¼šä½¿ç”¨å…¨éƒ¨è®­ç»ƒæ•°æ®ä¸€æ¬¡æ€§è®­ç»ƒæ¨¡å‹ï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™åŸºå‡†ï¼›
- **Adaptive EM-GMM**ï¼šæœ¬æ–‡æå‡ºçš„åœ¨çº¿è‡ªé€‚åº”æ–¹æ³•ï¼Œæ¯2ä¸ª sequences æ›´æ–°ä¸€æ¬¡å‚æ•°ï¼›
- ä¸¤è€…å‡åŸºäºç›¸åŒçš„ GMM ç»“æ„å’Œåˆå§‹åŒ–ç­–ç•¥ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰ä»¿çœŸåˆ†æç»“æœï¼ˆSimulation Studyï¼‰
- åœ¨200æ¬¡è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿä¸­ï¼š
  - **Offline æ–¹æ³•**ï¼šä½¿ç”¨å…¨éƒ¨285ä¸ªè®­ç»ƒ sequencesï¼Œå¹³å‡å­—ç¬¦å‡†ç¡®ç‡è¾¾ **91%**ï¼›
  - **Adaptive æ–¹æ³•**ï¼šä»…ç”¨ **75ä¸ª sequences**ï¼ˆçº¦å‡å°‘74%æ•°æ®é‡ï¼‰ï¼Œå¹³å‡å‡†ç¡®ç‡ä»è¶…è¿‡ **80%**ï¼›
  - è¡¨æ˜æ‰€ææ–¹æ³•åœ¨ä½æ•°æ®æ¡ä»¶ä¸‹ä»ä¿æŒè‰¯å¥½æ€§èƒ½ã€‚

#### ï¼ˆ2ï¼‰çœŸå®æ•°æ®åˆ†æç»“æœï¼ˆReal Data Analysisï¼‰
- åœ¨15åè¢«è¯•ä¸­ï¼š
  - **9äºº**è¾¾åˆ°äº†æœ€ä½å¯ç”¨æ ‡å‡†ï¼ˆaccuracy > 0.7ï¼‰ï¼›
  - å…¶ä¸­ **7äºº**åœ¨ adaptive è®¾ç½®ä¸‹çš„è¡¨ç°ä¼˜äº offline åŸºçº¿ï¼›
- å¹³å‡æ€§èƒ½ï¼ˆåŸºäº ~150 sequences / 10 characters åˆå§‹åŒ–ï¼‰ï¼š
  - Adaptive æ–¹æ³•åœ¨ **Accuracyã€ITRã€BCI Utility ä¸‰é¡¹æŒ‡æ ‡ä¸Šå‡é«˜äº offline åŸºçº¿**ï¼›
  - Interquartile range æ›´çª„ â†’ æ€§èƒ½æ›´ç¨³å®šã€‚

#### ï¼ˆ3ï¼‰å…¸å‹ä¸ªä½“è¶‹åŠ¿ï¼ˆFigure 6 & 7ï¼‰
- **K117ã€K183**ï¼šadaptive æ›²çº¿å¿«é€Ÿä¸Šå‡ï¼Œåœ¨çº¦150 sequences åè¶…è¶Š offline æ€§èƒ½ï¼›
- **K171**ï¼šè™½èµ·å§‹è¾ƒä½ï¼Œä½†å‘ˆç¨³æ­¥å¢é•¿è¶‹åŠ¿ï¼›
- æ‰€æœ‰è¢«è¯•çš„ **ITR ä¸ BCI Utility å‡éšè®­ç»ƒåºåˆ—å¢åŠ è€Œä¸Šå‡**ï¼Œä½“ç°è‡ªé€‚åº”ä¼˜åŠ¿ã€‚

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”æ€»ç»“
| ç»´åº¦ | å¯¹æ¯”ç»“æœ |
|------|---------|
| å‡†ç¡®æ€§ | å¤šæ•°ç”¨æˆ·ï¼ˆ7/9ï¼‰adaptive > offlineï¼›æ•´ä½“å‡å€¼æ›´é«˜ |
| æ•ˆç‡ | ITR å’Œ BCI Utility æŒç»­æå‡ï¼ŒåæœŸä¼˜äºå›ºå®šæ¨¡å‹ |
| æ•°æ®æ•ˆç‡ | ä»…éœ€ ~10å­—ç¬¦ï¼ˆ150 seqï¼‰å³å¯è¾¾åˆ°å®ç”¨æ°´å¹³ï¼Œç›¸æ¯” offline çš„19å­—ç¬¦å¤§å¹…é™ä½é—¨æ§› |

> â— æ³¨ï¼šæ— æ˜ç¡®æ¶ˆèå®éªŒï¼ˆablation studyï¼‰ï¼Œä½†æ–‡ä¸­å¼ºè°ƒäº†å‚æ•°åˆå§‹åŒ–å’Œå…±äº«åæ–¹å·®å‡è®¾çš„é‡è¦æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **æœ€å°åŒ–æ ¡å‡†å¯è¡Œ**ï¼šåªéœ€å°‘é‡æ ‡æ³¨æ•°æ®ï¼ˆå¦‚10ä¸ªå­—æ¯ï¼‰å³å¯æˆåŠŸåˆå§‹åŒ–æ¨¡å‹ï¼Œè¿›å…¥è‡ªé€‚åº”æ¨¡å¼ï¼›
2. **è‡ªé€‚åº”æœºåˆ¶æœ‰æ•ˆ**ï¼šåˆ©ç”¨æœªæ ‡æ³¨æ•°æ®æŒç»­ä¼˜åŒ–åˆ†ç±»å™¨ï¼Œèƒ½å¤Ÿåœ¨çœŸå®ä½¿ç”¨ä¸­ä¸æ–­æå‡æ€§èƒ½ï¼›
3. **æ•´ä½“æ•ˆèƒ½æå‡**ï¼šä¸ä»…æé«˜ accuracyï¼Œè¿˜æ˜¾è‘—æ”¹å–„ ITR å’Œ BCI Utilityï¼Œå°¤å…¶é€‚ç”¨äºèµ„æºå—é™æˆ–ç”¨æˆ·ç–²åŠ³æ•æ„Ÿçš„åº”ç”¨åœºæ™¯ï¼›
4. **ä¼˜äºä¼ ç»Ÿç¦»çº¿è®­ç»ƒ**ï¼šå¤šæ•°ç”¨æˆ·æœ€ç»ˆè¡¨ç°è¶…è¿‡ä¸€æ¬¡æ€§è®­ç»ƒçš„åŸºå‡†æ¨¡å‹ï¼ŒéªŒè¯äº†â€œè¶Šç”¨è¶Šå¥½â€çš„æ½œåŠ›ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **å¯¹åˆå§‹åŒ–æ•æ„Ÿ**ï¼šè‹¥åˆå§‹æ ‡æ³¨æ•°æ®è´¨é‡å·®æˆ–ä»£è¡¨æ€§ä¸è¶³ï¼Œå¯èƒ½å¯¼è‡´æ¨¡å‹æ”¶æ•›ç¼“æ…¢ç”šè‡³å¤±è´¥ï¼›
2. **ä¸é€‚ç”¨äºå¼‚æ­¥æ§åˆ¶**ï¼šå½“å‰æ¡†æ¶å‡è®¾ç”¨æˆ·å§‹ç»ˆå¤„äºæ‹¼å†™çŠ¶æ€ï¼Œæ— æ³•æ£€æµ‹åˆ†å¿ƒæˆ–ç»ˆæ­¢æ„å›¾ï¼›
3. **å™ªå£°é²æ£’æ€§å¾…åŠ å¼º**ï¼šEEG æ˜“å—çœ¼åŠ¨ã€è‚Œç”µç­‰å¹²æ‰°ï¼Œç¼ºä¹æ˜¾å¼çš„å»å™ªæ¨¡å—å¯èƒ½å½±å“é•¿æœŸç¨³å®šæ€§ï¼›
4. **æœªå¼•å…¥è¯­è¨€å…ˆéªŒ**ï¼šæœªèåˆä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚ n-gram æˆ– Transformerï¼‰ï¼Œé”™å¤±è¿›ä¸€æ­¥çº é”™æœºä¼šã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ”¹è¿›åˆå§‹åŒ–ç­–ç•¥**ï¼šæ¢ç´¢è·¨è¢«è¯•è¿ç§»å­¦ä¹ ï¼ˆtransfer learningï¼‰æˆ–å…ƒå­¦ä¹ ï¼ˆmeta-learningï¼‰ä»¥åŠ é€Ÿå†·å¯åŠ¨ï¼›
2. **å¢å¼ºå™ªå£°æŠ‘åˆ¶**ï¼šé›†æˆå…ˆè¿›å»å™ªç®—æ³•ï¼ˆå¦‚ ICAã€æ·±åº¦å»å™ªç½‘ç»œï¼‰æå‡ä¿¡å·è´¨é‡ï¼›
3. **å¼•å…¥ä¸Šä¸‹æ–‡å»ºæ¨¡**ï¼šç»“åˆè¯­è¨€æ¨¡å‹è¿›è¡Œ next-character predictionï¼Œå®ç° context-aware æ‹¼å†™ä¿®æ­£ï¼›
4. **ä¼˜åŒ–åˆºæ¿€é€‰æ‹©**ï¼šé‡‡ç”¨å¼ºåŒ–å­¦ä¹ åŠ¨æ€è°ƒæ•´ RCP é—ªçƒé¡ºåºï¼Œæå‡ä¿¡æ¯å¢ç›Šï¼›
5. **æ¨åŠ¨ä¸´åºŠè½åœ°**ï¼šåœ¨ ALS ç­‰æ‚£è€…ç¾¤ä½“ä¸­éªŒè¯ç³»ç»Ÿçš„é•¿æœŸå¯ç”¨æ€§å’Œå¯é æ€§ã€‚

---

> ğŸ’¡ **æ€»ä½“è¯„ä»·**ï¼š  
æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æå…·å®ç”¨ä»·å€¼çš„è‡ªé€‚åº”åŠç›‘ç£è®­ç»ƒæ¡†æ¶ï¼ŒæˆåŠŸè§£å†³äº† P300 BCI æ‹¼å†™ç³»ç»Ÿä¸­â€œé«˜ç²¾åº¦ vs. ä½æ ¡å‡†æˆæœ¬â€çš„çŸ›ç›¾ã€‚å…¶å®éªŒè®¾è®¡ä¸¥è°¨ï¼Œç»“æœå……åˆ†æ”¯æŒæ ¸å¿ƒä¸»å¼ â€”â€”**ä»¥æœ€å°æ ¡å‡†ä»£ä»·å®ç°é«˜æ•ˆã€å¯æŒç»­è¿›åŒ–çš„ BCI äº¤äº’ä½“éªŒ**ï¼Œä¸ºæœªæ¥è¿ˆå‘â€œå³æ’å³ç”¨â€å‹è„‘æœºæ¥å£æä¾›äº†é‡è¦æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 10. [Training-Free Adaptation of Diffusion Models via Doob's $h$-Transform](https://arxiv.org/abs/2602.16198)

**Authors**: Qijie Zhu, Zeqi Ye, Han Liu, Zhaoran Wang, Minshuo Chen  
**Category**: cs.LG  
**Published**: 2026-02-19  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.16198v1  

#### Abstract
Adaptation methods have been a workhorse for unlocking the transformative power of pre-trained diffusion models in diverse applications. Existing approaches often abstract adaptation objectives as a reward function and steer diffusion models to generate high-reward samples. However, these approaches...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTraining-Free Adaptation of Diffusion Models via Doob's $h$-Transform

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³**é¢„è®­ç»ƒ diffusion model åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„é€‚åº”æ€§é—®é¢˜**ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦æœ€å¤§åŒ–éå¯å¾®å¥–åŠ±å‡½æ•°ï¼ˆnon-differentiable rewardï¼‰çš„æƒ…å†µä¸‹ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸ä¾èµ–äºé¢å¤–çš„ç½‘ç»œè®­ç»ƒï¼ˆå¦‚ RL fine-tuning æˆ– guidance learningï¼‰ï¼Œè¿™å¸¦æ¥äº†é«˜æ˜‚çš„è®¡ç®—æˆæœ¬ï¼Œå¹¶ä¸”å¯¹å¥–åŠ±å‡½æ•°çš„å¯å¾®æ€§æœ‰ä¸¥æ ¼è¦æ±‚ã€‚

æ­¤å¤–ï¼Œè®¸å¤šç°æœ‰çš„æ¨ç†æ—¶ï¼ˆinference-timeï¼‰é€‚åº”æ–¹æ³•ï¼ˆå¦‚ SMC æˆ–æœç´¢ç±»æ–¹æ³•ï¼‰å­˜åœ¨æ ·æœ¬åç¼©ï¼ˆsample collapseï¼‰ã€æ¨ç†æ•ˆç‡ä½ç­‰é—®é¢˜ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡ºäº† **DOIT (Doob-Oriented Inference-time Transformation)** â€”â€”ä¸€ç§æ— éœ€è®­ç»ƒã€é€‚ç”¨äºé€šç”¨ï¼ˆåŒ…æ‹¬éå¯å¾®ï¼‰å¥–åŠ±å‡½æ•°çš„æ¨ç†æ—¶é€‚åº”ç®—æ³•ã€‚

å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ‰©æ•£æ¨¡å‹çš„é€‚åº”è¿‡ç¨‹å»ºæ¨¡ä¸ºä¸€ä¸ª**æµ‹åº¦è¾“è¿é—®é¢˜**ï¼ˆmeasure transportï¼‰ï¼Œå³ä»åŸå§‹ç”Ÿæˆåˆ†å¸ƒ $P_\theta$ è½¬ç§»åˆ°é«˜å¥–åŠ±åŒºåŸŸçš„æ¡ä»¶åˆ†å¸ƒ $P_\theta(\cdot \mid \mathcal{E}_{x_0})$ã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼•å…¥äº† **Doob's $h$-transform** æ¥å®ç°è¿™ä¸€è½¬ç§»ã€‚

- **Doob's $h$-transform** é€šè¿‡åœ¨åå‘é‡‡æ ·è¿‡ç¨‹ä¸­æ·»åŠ ä¸€ä¸ªåŠ¨æ€ä¿®æ­£é¡¹ $\nabla_x \log h(x,t)$ æ¥å¼•å¯¼è½¨è¿¹æœå‘ç›®æ ‡äº‹ä»¶ $\mathcal{E}_{x_0}$ï¼ˆä¾‹å¦‚ $r(x_0) \geq r_0$ï¼‰ã€‚
- è¯¥ä¿®æ­£é¡¹ä¸ä¿®æ”¹é¢„è®­ç»ƒæ¨¡å‹å‚æ•°ï¼Œä»…åœ¨æ¨ç†é˜¶æ®µè¿›è¡Œè°ƒæ•´ï¼Œä»è€Œå®ç°äº†å®Œå…¨çš„ **training-free adaptation**ã€‚
- ä¸ºäº†å¤„ç† $h(x,t) = \mathbb{P}(\mathcal{E}_{x_0} \mid X_t = x)$ éš¾ä»¥è§£æè®¡ç®—çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè’™ç‰¹å¡æ´›ï¼ˆMCï¼‰æ¨¡æ‹Ÿçš„è¿‘ä¼¼æ–¹æ³•æ¥ä¼°è®¡ $\nabla \log h(x,t)$ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | DOIT | ç°æœ‰æ–¹æ³• |
|------|------|--------|
| æ˜¯å¦éœ€è¦è®­ç»ƒ | âŒ å¦ï¼ˆtraining-freeï¼‰ | âœ… å¤šæ•°éœ€é¢å¤–è®­ç»ƒï¼ˆå¦‚ RL fine-tuningï¼‰ |
| æ”¯æŒéå¯å¾®å¥–åŠ± | âœ… æ˜¯ | âŒ å¤šæ•°ä¾èµ–æ¢¯åº¦ï¼ˆå¦‚ gradient-based guidanceï¼‰ |
| æ¨ç†æ•ˆç‡ | â±ï¸ é«˜æ•ˆï¼ˆä»…å¢åŠ å°‘é‡ NFEï¼‰ | ğŸ¢ è¾ƒä½ï¼ˆå¦‚ SMC / tree search å¢åŠ å¤§é‡é‡‡æ ·ï¼‰ |
| ç†è®ºä¿éšœ | âœ… æä¾›é«˜æ¦‚ç‡æ”¶æ•›ä¿è¯ | âŒ å¤šæ•°ç¼ºä¹ç†è®ºåˆ†æ |
| æ˜“äºé›†æˆ | âœ… å¯ä¸å…¶ä»–æ–¹æ³•ï¼ˆå¦‚ BoK, BFSï¼‰ç»“åˆ | â€” |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡**ï¼šä½¿ç”¨ **Stable Diffusion v1.5** æ¨¡å‹ï¼Œåœ¨ LAION æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œè¯„ä¼°å…¶åœ¨æå‡ç¾å­¦è¯„åˆ†ï¼ˆaesthetic scoreï¼‰ä¸Šçš„è¡¨ç°ã€‚
- **ç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆOffline RLï¼‰ä»»åŠ¡**ï¼šé‡‡ç”¨ **D4RL benchmark**ï¼ŒåŒ…å«ä»¥ä¸‹ç¯å¢ƒä¸æ•°æ®ç»„åˆï¼š
  - Environments: `HalfCheetah`, `Hopper`, `Walker2d`
  - Dataset types: `Medium-Expert`, `Medium`, `Medium-Replay`

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
#### æ–‡æœ¬åˆ°å›¾åƒä»»åŠ¡
- **å¥–åŠ±å‡½æ•°**ï¼šLAION Aesthetic Score å’Œ ImageReward
- **é‡‡æ ·å™¨**ï¼šEuler ancestral samplerï¼ˆ$L=20$ æ­¥ï¼‰
- **è¯„ä¼°æ–¹å¼**ï¼šç”Ÿæˆ $K=32$ å¼ å›¾åƒï¼ŒæŠ¥å‘Šç¾å­¦åˆ†æ•°çš„å‡å€¼ã€æœ€å°å€¼ã€æœ€å¤§å€¼åŠåˆ†ä½æ•°ï¼ˆviolin plotï¼‰
- **æ¶ˆèå®éªŒ**ï¼šæµ‹è¯•ä¸åŒæ¸©åº¦ $T$ ä¸ä¿®æ­£å¼ºåº¦ $\gamma$ çš„å½±å“

#### ç¦»çº¿ RL ä»»åŠ¡
- **æ¨¡å‹**ï¼šä½¿ç”¨ Lu et al. [2023] æä¾›çš„é¢„è®­ç»ƒ diffusion policy
- **å¥–åŠ±ä¿¡å·**ï¼šä½¿ç”¨ ground-truth Q-function ä½œä¸º reward oracle
- **é‡‡æ ·å™¨**ï¼šDDIM ($L=15$ æ­¥)
- **è¯„ä¼°æŒ‡æ ‡**ï¼šæ ‡å‡† returnï¼ˆå›æŠ¥ï¼‰ï¼Œè¶Šé«˜è¶Šå¥½
- **å¯¹æ¯”åŸºçº¿**ï¼š
  - **Training-based**: IQL, Diffuser, D-QL, QGPO
  - **Inference-time**: TFG, DAS, TTS

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• |
|------|------|
| Training-based | IQL, Diffuser, D-QL, QGPO |
| Inference-time | TFG, DAS, TTS, FK-Steering, TreeG, SVDD |
| ç»„åˆæ–¹æ³• | BoK, BFS |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆD4RL å¹³å‡å¾—åˆ†ï¼‰
| æ–¹æ³• | å¹³å‡ Return |
|------|------------|
| **DOIT (Ours)** | **87.6** âœ… |
| TTS (SOTA inference-time) | 86.1 |
| QGPO (training-based) | 86.6 |
| DAS | 80.2 |
| TFG | 82.1 |

> DOIT åœ¨ **9ä¸ªä»»åŠ¡ä¸­çš„8ä¸ª** ä¸Šä¼˜äºæ‰€æœ‰ inference-time åŸºçº¿ï¼Œå¹³å‡å¾—åˆ†æœ€é«˜ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ `Hopper-medium` ä¸Šï¼ŒDOIT è¾¾åˆ° **101.0 Â± 0.3**ï¼Œæ˜¾è‘—è¶…è¿‡ TTS çš„ 99.5 å’Œ DAS çš„ 71.3ã€‚
- åœ¨ `Walker2d-medium-expert` ä¸Šè¾¾åˆ° **113.2 Â± 0.7**ï¼Œä¼˜äºæ‰€æœ‰ baselineã€‚
- å³ä½¿åœ¨ `Medium-Replay` è¿™ç±»å¤šæ ·æ€§é«˜çš„æ•°æ®é›†ä¸Šä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œè¯´æ˜æ–¹æ³•é²æ£’æ€§å¼ºã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰Surrogate vs Full Trajectory Simulation
| æ–¹æ³• | Mean Score | Runtime (sec/image) |
|------|-----------|---------------------|
| Pre-trained | 6.372 | 1.260 |
| Surrogate (ours) | 6.726 | **1.712** |
| Full Simulation | 6.714 | 39.584 |

> ä½¿ç”¨ **one-step lookahead surrogate**ï¼ˆå…¬å¼ (10)ï¼‰å³å¯æ¥è¿‘å®Œæ•´è½¨è¿¹æ¨¡æ‹Ÿçš„æ•ˆæœï¼ŒåŒæ—¶é€Ÿåº¦æå‡ **20å€ä»¥ä¸Š**ã€‚

#### ï¼ˆ2ï¼‰ä¸ Resampling æ–¹æ³•ç»“åˆ
| æ–¹æ³• (K=4) | ImageReward Score |
|----------|------------------|
| BoK | 0.702 |
| BoK + DOIT | **0.875** (+24.6%) |
| BFS | 0.882 |
| **BFS + DOIT** | **0.950** âœ… |

> DOIT å¯ä½œä¸ºâ€œå…ˆéªŒä¼˜åŒ–â€æ¨¡å—ï¼Œæ˜¾è‘—å¢å¼º BoK/BFS ç­‰ resampling æ–¹æ³•çš„è¡¨ç°ã€‚

#### ï¼ˆ3ï¼‰è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆT å’Œ Î³ï¼‰
- å‘ç°å­˜åœ¨ trade-offï¼šä½æ¸© $T$ éœ€è¾ƒå° $\gamma$ ä»¥ä¿æŒç¨³å®šï¼›é«˜æ¸©ä¸‹å¯ä½¿ç”¨æ›´å¤§ $\gamma$ åŠ é€Ÿä¼˜åŒ–ã€‚
- æœ€ä½³é…ç½®èŒƒå›´ï¼š$T \in [0.3, 0.4]$, $\gamma \in [4.0, 8.0]$ï¼ˆå…·ä½“è§é™„å½• Tables 4â€“8ï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. âœ… **Doob's $h$-transform æ˜¯å®ç° training-free adaptation çš„æœ‰æ•ˆå·¥å…·**ï¼šå®ƒæä¾›äº†ä¸€ä¸ªç†è®ºä¸¥è°¨çš„æ¦‚ç‡æ¡†æ¶ï¼Œç”¨äºå°†ç”Ÿæˆåˆ†å¸ƒå¯¼å‘é«˜å¥–åŠ±åŒºåŸŸã€‚
2. âœ… **æ— éœ€è®­ç»ƒä¹Ÿèƒ½é«˜æ•ˆé€‚é…éå¯å¾®å¥–åŠ±**ï¼šDOIT æˆåŠŸç»•è¿‡äº†å¯¹å¥–åŠ±æ¢¯åº¦çš„éœ€æ±‚ï¼Œé€‚ç”¨äºé»‘ç®± rewardï¼ˆå¦‚åˆ†å­è®¾è®¡ã€æœºå™¨äººæ§åˆ¶ï¼‰ã€‚
3. âœ… **å…¼å…·é«˜æ€§èƒ½ä¸é«˜æ•ˆç‡**ï¼šç›¸æ¯”å…¶ä»– inference-time æ–¹æ³•ï¼ŒDOIT åœ¨å‡ ä¹ä¸ç‰ºç‰²é‡‡æ ·æ•ˆç‡çš„å‰æä¸‹å®ç°äº†æ›´ä¼˜æ€§èƒ½ã€‚
4. âœ… **å¯ç»„åˆæ€§å¼º**ï¼šDOIT å¯ä½œä¸ºæ’ä»¶å¼æ¨¡å—ï¼Œä¸ BoKã€BFS ç­‰æœç´¢ç­–ç•¥æ— ç¼é›†æˆï¼Œè¿›ä¸€æ­¥æå‡æœ€ç»ˆè¾“å‡ºè´¨é‡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å¯¹é«˜å¥–åŠ±åŒºåŸŸç¨€ç–æ•æ„Ÿ**ï¼šå½“ç›®æ ‡äº‹ä»¶ $\mathcal{E}_{x_0}$ åœ¨åŸå§‹åˆ†å¸ƒä¸­æ¦‚ç‡æä½æ—¶ï¼ˆ$P(\mathcal{E}_{x_0}) \to 0$ï¼‰ï¼ŒMC ä¼°è®¡æ–¹å·®å¢å¤§ï¼Œå¯¼è‡´ $\nabla \log h$ è¿‘ä¼¼ä¸ç¨³å®šã€‚
- **ä¾èµ–é¢„è®­ç»ƒæ¨¡å‹çš„è´¨é‡**ï¼šè‹¥ $P_\theta$ æœ¬èº«éš¾ä»¥è¦†ç›–ç›®æ ‡åŒºåŸŸï¼Œåˆ™å³ä½¿åº”ç”¨ DOIT ä¹Ÿæ— æ³•ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬ã€‚
- **è¶…å‚æ•°è°ƒä¼˜éœ€æ±‚**ï¼š$\gamma$, $T$, $l^*$ ç­‰éœ€æ ¹æ®ä»»åŠ¡è°ƒæ•´ï¼Œç¼ºä¹è‡ªé€‚åº”æœºåˆ¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- è®¾è®¡ **variance-reduced estimator** for $\nabla \log h$ï¼Œä»¥åº”å¯¹æç«¯ç¨€ç– reward åœºæ™¯ã€‚
- æ¢ç´¢ **adaptive scheduling** of Doob correctionï¼ˆå¦‚è‡ªåŠ¨è°ƒèŠ‚ $\gamma(t)$ï¼‰ã€‚
- å°† DOIT æ‰©å±•è‡³ **flow models**, **autoregressive models** ç­‰å…¶ä»–ç”Ÿæˆæ¶æ„ã€‚
- ç»“åˆ **active exploration** æˆ– **reward shaping** æ¥ç¼“è§£åˆå§‹åˆ†å¸ƒä¸ç›®æ ‡ä¹‹é—´çš„å·¨å¤§ gapã€‚

---

> ğŸ”— **ä»£ç å¼€æºåœ°å€**ï¼šhttps://github.com/liamyzq/Doob_training_free_adaptation

</details>

---

### 11. [Quality-constrained Entropy Maximization Policy Optimization for LLM Diversity](https://arxiv.org/abs/2602.15894)

**Authors**: Haihui Pan, Yuzhong Hong, Shaoke Lv, Junwei Bao, Hongfei Jiang, Yang Song  
**Category**: cs.CL  
**Published**: 2026-02-19  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.15894v1  

#### Abstract
Recent research indicates that while alignment methods significantly improve the quality of large language model(LLM) outputs, they simultaneously reduce the diversity of the models' output. Although some methods have been proposed to enhance LLM output diversity, they often come at the cost of redu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Quality-constrained Entropy Maximization Policy Optimization for LLM Diversity*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰ä¸»æµçš„ **LLM å¯¹é½æ–¹æ³•**ï¼ˆå¦‚ SFTã€RLHFã€DPOï¼‰è™½ç„¶æ˜¾è‘—æå‡äº†è¾“å‡ºçš„ **è´¨é‡ï¼ˆqualityï¼‰**ã€æœ‰ç”¨æ€§å’Œå®‰å…¨æ€§ï¼Œä½†æ™®éè§‚å¯Ÿåˆ°å…¶ä¸¥é‡æŠ‘åˆ¶äº†æ¨¡å‹è¾“å‡ºçš„ **å¤šæ ·æ€§ï¼ˆdiversityï¼‰**ã€‚è¿™ç§å¤šæ ·æ€§ä¸‹é™è¡¨ç°ä¸ºè¾“å‡ºè¶‹äºé‡å¤ã€æ¨¡å¼åŒ–ã€ç¼ºä¹åˆ›é€ æ€§ï¼Œå°¤å…¶åœ¨éœ€è¦å¼€æ”¾æ€§ç”Ÿæˆçš„ä»»åŠ¡ï¼ˆå¦‚åˆ›æ„å†™ä½œï¼‰ä¸­è¡¨ç°ä¸ä½³ã€‚

å·²æœ‰æ–¹æ³•åœ¨æå‡å¤šæ ·æ€§æ—¶å¾€å¾€ä»¥ç‰ºç‰²è´¨é‡ä¸ºä»£ä»·ï¼Œå¯¼è‡´ç”Ÿæˆå†…å®¹å˜å¾—æ— æ„ä¹‰æˆ–ä¸è¿è´¯ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ **ä¿è¯è¾“å‡ºè´¨é‡çš„å‰æä¸‹æå‡å¤šæ ·æ€§**ï¼Œæˆä¸ºä¸€ä¸ªäºŸå¾…è§£å†³çš„é—®é¢˜ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¯¹é½ä¼˜åŒ–æ¡†æ¶ï¼š**Quality-constrained Entropy Maximization Policy Optimization (QEMPO)**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- å°†å¯¹é½ä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªç›®æ ‡ï¼š**æœ€å¤§åŒ–è´¨é‡** å’Œ **æœ€å¤§åŒ–å¤šæ ·æ€§**ã€‚
- æ˜ç¡®å°† **policy entropy** ä½œä¸ºå¤šæ ·æ€§çš„ä»£ç†æŒ‡æ ‡è¿›è¡Œæœ€å¤§åŒ–ã€‚
- åŒæ—¶å¼•å…¥ **quality constraint** æ¥ç¡®ä¿è¾“å‡ºæ»¡è¶³äººç±»åå¥½ï¼Œé˜²æ­¢ç†µå¢å¯¼è‡´è´¨é‡å´©æºƒã€‚
- åœ¨æ­¤åŸºç¡€ä¸Šè¿›ä¸€æ­¥æå‡ºäº†å˜ä½“ **QEMPO-KL**ï¼Œé¢å¤–åŠ å…¥ KL æ•£åº¦çº¦æŸä»¥ç¨³å®šè®­ç»ƒã€‚

è¯¥æ–¹æ³•ä»ç†è®ºå±‚é¢é‡æ–°å®¡è§†äº† RLHF çš„æœ¬è´¨ï¼Œå¹¶æŒ‡å‡ºå…¶ç­‰ä»·äºä¸€ä¸ªåœ¨è´¨é‡çº¦æŸä¸‹çš„ KL æœ€å°åŒ–é—®é¢˜ï¼Œè€Œ **å¹¶æœªæ˜¾å¼é¼“åŠ±å¤šæ ·æ€§**ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ˜¯å¦æ˜¾å¼ä¼˜åŒ–å¤šæ ·æ€§ | æ˜¯å¦ä¿æŒé«˜è´¨é‡ | æ˜¯å¦ä¾èµ– reference model |
|------|------------------|---------------|------------------------|
| **RLHF / DPO** | âŒ | âœ… | âœ… |
| **SPL (Soft Preference Learning)** | âœ… | âš ï¸ï¼ˆæœ‰æ—¶ä½äº RLHFï¼‰ | âœ… |
| **QEMPO** | âœ… | âœ…ï¼ˆä¼˜äºæˆ–ç­‰äº RLHFï¼‰ | âŒï¼ˆå¯çœç•¥ï¼‰ |
| **QEMPO-KL** | âœ… | âœ… | âœ… |

- **ç†è®ºä¼˜åŠ¿**ï¼šé¦–æ¬¡å½¢å¼åŒ–è¯æ˜äº†å¯¹é½ä»»åŠ¡åº”åŒæ—¶ä¼˜åŒ–è´¨é‡å’Œå¤šæ ·æ€§ï¼›å¹¶è¯æ˜ QEMPO/QEMPO-KL çš„æœ€ä¼˜ç­–ç•¥å…·æœ‰æ¯” RLHF æ›´é«˜çš„ entropyã€‚
- **å®è·µä¼˜åŠ¿**ï¼šåœ¨å¤šä¸ªæ¨¡å‹å’Œä»»åŠ¡ä¸ŠéªŒè¯äº† QEMPO èƒ½ **æ˜¾è‘—æå‡å¤šæ ·æ€§**ï¼ˆlexical, syntactic, semanticï¼‰ï¼ŒåŒæ—¶ **ç»´æŒç”šè‡³ç•¥å¾®æå‡è´¨é‡**ã€‚
- **çµæ´»æ€§é«˜**ï¼šæ”¯æŒ offline å’Œ online ä¸¤ç§è®­ç»ƒæ¨¡å¼ï¼Œä¸” QEMPO å¯å®Œå…¨å»é™¤ reference modelï¼Œé™ä½å†…å­˜å¼€é”€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- **Offline å®éªŒ**ï¼š
  - **UltraFeedback Binarized Dataset**ï¼šåŸºäºäººç±»åé¦ˆæ ‡æ³¨â€œchosenâ€å’Œâ€œrejectedâ€çš„å“åº”å¯¹ï¼Œç”¨äº preference learning ç±»æ–¹æ³•è®­ç»ƒã€‚
- **Online å®éªŒ**ï¼š
  - **GSM8K** å’Œ **MATH500**ï¼šæ•°å­¦æ¨ç†æ•°æ®é›†ï¼Œå…±çº¦ 12,000 ä¸ªæ ·æœ¬ï¼Œç”¨äºæµ‹è¯•æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„å¤šè·¯å¾„æ±‚è§£èƒ½åŠ›ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹è§„æ¨¡
- å°æ¨¡å‹ï¼š`Qwen2.5-1.5B-Instruct`, `Llama-3.2-1B-Instruct`
- å¤§æ¨¡å‹ï¼š`Qwen2.5-7B-Instruct`, `Llama-3.1-8B-Instruct`

#### è¯„ä¼°æŒ‡æ ‡
| ç»´åº¦ | æŒ‡æ ‡ | è¯´æ˜ |
|------|------|------|
| **å¤šæ ·æ€§ï¼ˆDiversityï¼‰** | Lexical / Syntactic / Semantic Diversity | ä½¿ç”¨ Guo et al. (2024) æå‡ºçš„æ¡†æ¶ï¼Œä»è¯æ³•ã€å¥æ³•ã€è¯­ä¹‰ä¸‰ä¸ªå±‚é¢é‡åŒ–è¾“å‡ºå·®å¼‚æ€§ |
| **è´¨é‡ï¼ˆQualityï¼‰** | MT-Bench Scoreï¼ˆç”± gpt-4o æ‰“åˆ†ï¼‰ | è¡¡é‡å›ç­”çš„å‡†ç¡®æ€§ã€é€»è¾‘æ€§å’Œæœ‰ç”¨æ€§ |
| **ç»¼åˆæ€§èƒ½ï¼ˆOnlineï¼‰** | **pass@k**ï¼ˆk=1, 4, 8, 16, 32ï¼‰ | è¡¡é‡åœ¨å¤šæ¬¡é‡‡æ ·ä¸‹è‡³å°‘æœ‰ä¸€æ¬¡æ­£ç¡®è§£ç­”çš„æ¦‚ç‡ï¼Œå…¼é¡¾è´¨é‡ä¸å¤šæ ·æ€§ |

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **RLHF**ï¼šæ ‡å‡†å¼ºåŒ–å­¦ä¹ å¯¹é½æ–¹æ³•
- **SPL (Soft Preference Learning)**ï¼šè¿‘æœŸæå‡ºçš„å¤šæ ·æ€§å¢å¼ºæ–¹æ³•
- **Base Model**ï¼šæœªå¯¹é½çš„åŸºç¡€æ¨¡å‹

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2ï¼‰

| æ–¹æ³• | å¹³å‡å¤šæ ·æ€§ | MT-Bench è´¨é‡ |
|------|------------|----------------|
| **QEMPO (å¹³å‡)** | **42.83** â†‘â†‘ | **7.05** â‰ˆ |
| **QEMPO-KL (å¹³å‡)** | **42.42** â†‘ | **7.04** â‰ˆ |
| **SPL (å¹³å‡)** | 40.43 â†’ | **6.93** â†“ |
| **RLHF (å¹³å‡)** | 39.28 | **7.02** |

> æ³¨ï¼šæ•°å€¼è¶Šé«˜è¶Šå¥½ï¼›â†‘ è¡¨ç¤ºä¼˜äº RLHFï¼Œâ†“ è¡¨ç¤ºåŠ£äº RLHF

#### å…¸å‹ç»“æœäº®ç‚¹ï¼š
- åœ¨ `Llama-3.2-1B-Instruct` ä¸Šï¼ŒQEMPO-KL çš„ **lexical å¤šæ ·æ€§è¾¾ 48.36**ï¼Œè¿œè¶… RLHF çš„ 43.85ã€‚
- åœ¨ `Qwen2.5-1.5B-Instruct` ä¸Šï¼ŒQEMPO çš„ **MT-Bench å¾—åˆ†ä¸º 6.54**ï¼Œé«˜äº RLHF çš„ 6.30ï¼Œå®ç°â€œåŒå‡â€ã€‚
- åœ¨ **online æ•°å­¦ä»»åŠ¡** ä¸­ï¼ˆFigure 3ï¼‰ï¼Œéšç€ `k` å¢å¤§ï¼ˆå³å…è®¸æ›´å¤šå°è¯•ï¼‰ï¼ŒQEMPO å’Œ QEMPO-KL çš„ **pass@k æ˜¾è‘—è¶…è¶Š RLHF**ï¼Œè¡¨æ˜å…¶ç”Ÿæˆæ›´å¤šæœ‰æ•ˆè§£è·¯å¾„ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- âœ… **QEMPO åœ¨æ‰€æœ‰å®éªŒä¸­å‡ä¼˜äºæˆ–æŒå¹³ RLHF çš„è´¨é‡ï¼Œä¸”æ˜¾è‘—æå‡å¤šæ ·æ€§**ã€‚
- âš ï¸ **SPL è™½èƒ½æå‡å¤šæ ·æ€§ï¼Œä½†åœ¨éƒ¨åˆ†æ¨¡å‹ï¼ˆå¦‚ Llama-3.1-8Bï¼‰ä¸Šè´¨é‡æ˜æ˜¾ä¸‹é™ï¼Œç”šè‡³ä¸å¦‚ base model**ï¼Œæ˜¾ç¤ºå…¶ç¨³å®šæ€§å·®ã€‚
- âœ… **QEMPO-KL æ€§èƒ½æ¥è¿‘ RLHFï¼Œåœ¨ Qwen ç³»åˆ—ä¸Šæœ‰å¢ç›Šï¼Œåœ¨ Llama ä¸Šç•¥æœ‰æ³¢åŠ¨**ï¼Œä½†ä»ä¼˜äº SPLã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
- ä½¿ç”¨ `Qwen2.5-1.5B-Instruct` æµ‹è¯•ä¸åŒè¶…å‚æ•°ï¼ˆÎ»ï¼‰çš„å½±å“ï¼ˆTable 3ï¼‰ï¼š
  - ä¸åŒ Î» è®¾ç½®ä¸‹ï¼Œ**å¤šæ ·æ€§ä¸è´¨é‡å˜åŒ–å¹³ç¼“**ï¼Œè¯´æ˜æ–¹æ³•é²æ£’æ€§å¼ºã€‚
  - å³ä½¿è°ƒæ•´å‚æ•°ï¼Œ**æ‰€æœ‰é…ç½®çš„å¹³å‡å¤šæ ·æ€§ä»é«˜äº RLHF çš„ 40.36**ã€‚
  - æ‰€æœ‰ QEMPO é…ç½®çš„è´¨é‡å¾—åˆ† **ä¸ä½äº RLHF çš„ 6.30**ï¼Œä½“ç°è´¨é‡çº¦æŸçš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. âœ… **å¤šæ ·æ€§ä¸è´¨é‡æ˜¯å¯¹é½ä»»åŠ¡ä¸­ä¸¤ä¸ªä¸å¯ååºŸçš„æ ¸å¿ƒç»´åº¦**ï¼Œä»…ä¼˜åŒ–å…¶ä¸€ä¼šå¯¼è‡´æ¬¡ä¼˜ç­–ç•¥ã€‚
2. âœ… **Policy Gradient ç±»æ–¹æ³•æœ¬è´¨ä¸Šåªä¼˜åŒ–è´¨é‡**ï¼Œæ— æ³•ä¿éšœå¤šæ ·æ€§ï¼ˆCorollary 3.1ï¼‰ã€‚
3. âœ… **QEMPO å’Œ QEMPO-KL çš„ç†è®ºæœ€ä¼˜ç­–ç•¥å…·æœ‰æ›´é«˜çš„ entropy**ï¼Œä»è€Œæ”¯æŒæ›´ä¸°å¯Œçš„è¾“å‡ºåˆ†å¸ƒã€‚
4. âœ… å®éªŒéªŒè¯ï¼š**QEMPO èƒ½åœ¨ä¸ç‰ºç‰²è´¨é‡çš„å‰æä¸‹æ˜¾è‘—æå‡ LLM è¾“å‡ºå¤šæ ·æ€§**ï¼Œå°¤å…¶é€‚ç”¨äºéœ€è¦åˆ›é€ æ€§æˆ–å¤šè·¯å¾„æ¢ç´¢çš„ä»»åŠ¡ã€‚
5. âœ… **online å®éªŒè¡¨æ˜ï¼Œå¤šæ ·æ€§æå‡æœ‰åŠ©äºè§£å†³å›°éš¾é—®é¢˜**ï¼ˆpass@k éš k å¢é•¿æ›´å¿«ï¼‰ï¼Œè¯´æ˜å¤šæ ·æ€§æœ¬èº«å¯è½¬åŒ–ä¸ºæ€§èƒ½å¢ç›Šã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ–¹æ³•ä¾èµ– reward model æˆ–äººå·¥è®¾è®¡çš„ reward signalï¼Œè‹¥ reward ä¸å‡†ç¡®å¯èƒ½å¯¼è‡´é”™è¯¯çš„æ–¹å‘ä¼˜åŒ–ã€‚
- åœ¨ extremely low-quality outputs ä¸Šç›´æ¥å¢åŠ  entropy ä¼šå¯¼è‡´è®­ç»ƒä¸ç¨³å®šï¼Œéœ€é€šè¿‡ **conditional variance masking** æŠ€å·§ç¼“è§£ï¼ˆä»…åœ¨æ­£ç¡®è¾“å‡ºä¸Šè®¡ç®— var(log Ï€)ï¼‰ã€‚
- è¶…å‚æ•°ï¼ˆå¦‚ Î»ï¼‰çš„é€‰æ‹©è™½æ•´ä½“ç¨³å¥ï¼Œä½†ä»éœ€ä¸€å®šè°ƒå‚ç»éªŒã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **è‡ªé€‚åº” entropy æ§åˆ¶æœºåˆ¶**ï¼Œæ ¹æ®ä»»åŠ¡éš¾åº¦åŠ¨æ€è°ƒèŠ‚å¤šæ ·æ€§å¼ºåº¦ã€‚
- ç»“åˆ **intrinsic motivation**ï¼ˆå¦‚ curiosityï¼‰è¿›ä¸€æ­¥æ¿€å‘æ¨¡å‹æ¢ç´¢èƒ½åŠ›ã€‚
- å°† QEMPO æ¡†æ¶æ‰©å±•è‡³ **å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹** çš„å¯¹é½ä»»åŠ¡ä¸­ã€‚
- ç ”ç©¶å¦‚ä½•åœ¨ **zero-reference setting** ä¸‹æ›´é«˜æ•ˆåœ°è®­ç»ƒ QEMPOï¼Œå‡å°‘å¯¹å¤–éƒ¨ reward model çš„ä¾èµ–ã€‚

---

> ğŸ” **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬è®ºæ–‡æå‡º **QEMPO** â€”â€”ä¸€ç§åœ¨ä¸¥æ ¼è´¨é‡çº¦æŸä¸‹æœ€å¤§åŒ–ç­–ç•¥ç†µçš„æ–°å¯¹é½èŒƒå¼ï¼Œå®ç°äº† **é«˜è´¨é‡ä¸é«˜å¤šæ ·æ€§çš„ç»Ÿä¸€**ï¼Œä¸ºæ„å»ºæ›´å…·åˆ›é€ åŠ›å’Œæ³›åŒ–èƒ½åŠ›çš„ LLM æä¾›äº†æ–°çš„ç†è®ºè§†è§’ä¸å®ç”¨å·¥å…·ã€‚

</details>

---

### 12. [Muon with Spectral Guidance: Efficient Optimization for Scientific Machine Learning](https://arxiv.org/abs/2602.16167)

**Authors**: Binghang Lu, Jiahao Zhang, Guang Lin  
**Category**: cs.LG  
**Published**: 2026-02-19  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.16167v1  

#### Abstract
Physics-informed neural networks and neural operators often suffer from severe optimization difficulties caused by ill-conditioned gradients, multi-scale spectral behavior, and stiffness induced by physical constraints. Recently, the Muon optimizer has shown promise by performing orthogonalized upda...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Muon with Spectral Guidance: Efficient Optimization for Scientific Machine Learning*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨**Scientific Machine Learning**ï¼ˆå¦‚ **Physics-Informed Neural Networks**ï¼ˆPINNsï¼‰å’Œ **Neural Operators**ï¼‰ä¸­ï¼Œä¼˜åŒ–è¿‡ç¨‹é¢ä¸´ä¸¥é‡æŒ‘æˆ˜ï¼Œä¸»è¦åŒ…æ‹¬ï¼š
- **Ill-conditioned gradients**ï¼ˆæ¢¯åº¦ç—…æ€ï¼‰
- **Multi-scale spectral behavior**ï¼ˆå¤šå°ºåº¦è°±è¡Œä¸ºï¼‰
- **Stiffness**ï¼ˆåˆšæ€§ï¼‰ç”±ç‰©ç†çº¦æŸå¼•å…¥
- ä¼ ç»Ÿä¼˜åŒ–å™¨ï¼ˆå¦‚ Adamã€AdamWï¼‰åœ¨è¿™äº›ä»»åŠ¡ä¸­æ”¶æ•›æ…¢ã€ä¸ç¨³å®šï¼Œä¸”å¯¹è¶…å‚æ•°æ•æ„Ÿã€‚

å°½ç®¡ **Muon** ä¼˜åŒ–å™¨é€šè¿‡åœ¨æ¢¯åº¦çš„å¥‡å¼‚å‘é‡åŸºä¸Šè¿›è¡Œæ­£äº¤åŒ–æ›´æ–°ï¼Œæ”¹å–„äº†å‡ ä½•æ¡ä»¶ï¼Œä½†å…¶â€œå•ä½å¥‡å¼‚å€¼â€æ›´æ–°å¯èƒ½å¯¼è‡´æ­¥é•¿è¿‡äºæ¿€è¿›ï¼Œç¼ºä¹èƒ½é‡ç¨³å®šæ€§ä¿è¯ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSpecMuon
æœ¬æ–‡æå‡º **SpecMuon**ï¼Œä¸€ç§ç»“åˆäº† **Muon çš„å‡ ä½•æ­£äº¤åŒ–** å’Œ **Relaxed Scalar Auxiliary Variable**ï¼ˆRSAVï¼‰æœºåˆ¶çš„æ–°å‹ä¼˜åŒ–å™¨ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†çŸ©é˜µæ¢¯åº¦åˆ†è§£ä¸º**ä¸»å¯¼å¥‡å¼‚æ¨¡å¼**ï¼ˆsingular modesï¼‰
- åœ¨æ¯ä¸ªæ¨¡å¼ä¸Šç‹¬ç«‹åº”ç”¨ **RSAV æ›´æ–°**
- é€šè¿‡è¾…åŠ©å˜é‡åŠ¨æ€è°ƒèŠ‚æ­¥é•¿ï¼Œå®ç°å¯¹åˆšæ€§è°±åˆ†é‡çš„é€‰æ‹©æ€§é˜»å°¼

### åˆ›æ–°ç‚¹
- **ç»Ÿä¸€å‡ ä½•ä¸èƒ½é‡æ§åˆ¶**ï¼šé¦–æ¬¡å°† Muon çš„æ­£äº¤åŒ–å‡ ä½•ä¸ SAV çš„èƒ½é‡ç¨³å®šæ€§æœºåˆ¶èåˆï¼Œå½¢æˆâ€œå¤šæ¨¡æ€æ¢¯åº¦æµâ€è§†è§’ã€‚
- **æ¨¡å¼è‡ªé€‚åº”è°ƒèŠ‚**ï¼šé€šè¿‡ per-mode RSAV æœºåˆ¶ï¼Œä½¿ä¸åŒé¢‘è°±æ–¹å‘çš„æ›´æ–°æ­¥é•¿èƒ½æ ¹æ®å…¨å±€æŸå¤±èƒ½é‡è‡ªé€‚åº”è°ƒæ•´ã€‚
- **ä¿ç•™ Muon çš„å°ºåº¦å¹³è¡¡ç‰¹æ€§**ï¼šåœ¨ç¨³å®šèƒ½é‡çš„åŒæ—¶ï¼Œä¸ç‰ºç‰² Muon å¯¹å¤šå°ºåº¦å‚æ•°çš„å‡è¡¡å¤„ç†èƒ½åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ä¼˜åŠ¿ |
|------|------|
| **vs Adam / AdamW** | æ›´å¿«æ”¶æ•›ã€æ›´ä½è®­ç»ƒæŸå¤±ã€æ›´å¼ºç¨³å®šæ€§ï¼Œå°¤å…¶åœ¨åˆšæ€§å’Œå¤šå°ºåº¦é—®é¢˜ä¸­ |
| **vs Muon** | é¿å…è¿‡æ¿€è¿›çš„æ›´æ–°ï¼Œæä¾›æ˜ç¡®çš„èƒ½é‡è€—æ•£å¾‹å’Œç¨³å®šæ€§ä¿è¯ï¼Œæ”¶æ•›æ›´å¹³æ»‘ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹ä»»åŠ¡
å®éªŒè¦†ç›–å¤šä¸ªå…¸å‹ç§‘å­¦æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œæ„æˆä¸€ä¸ªä»ç®€å•åˆ°å¤æ‚çš„å±‚æ¬¡ç»“æ„ï¼š

1. **Linear Regression**ï¼ˆçº¿æ€§å›å½’ï¼‰  
   - ç”¨äºéªŒè¯åœ¨å‡¸é—®é¢˜ä¸­çš„è°±æ•ˆåº”
   - æ•°æ®ï¼šåˆæˆæ•°æ® $ \mathbf{W}\mathbf{X} - \mathbf{Y} $

2. **PINN for 1D Burgersâ€™ Equation**ï¼ˆç²˜æ€§ä¼¯æ ¼æ–¯æ–¹ç¨‹ï¼‰  
   - éçº¿æ€§ PDEï¼Œç»å…¸ PINN æµ‹è¯•åŸºå‡†
   - ç‰©ç†æ–¹ç¨‹ï¼š$ u_t + uu_x = \nu u_{xx} $
   - åˆå§‹æ¡ä»¶ï¼š$ u(x,0) = -\sin(\pi x) $

3. **DeepONet for Burgersâ€™ Equation**  
   - ç®—å­å­¦ä¹ æ¡†æ¶ï¼Œå­¦ä¹ ä»åˆå§‹æ¡ä»¶åˆ°è§£çš„æ˜ å°„
   - æ¶æ„åŒ…å« branch å’Œ trunk ç½‘ç»œ

4. **fPINN-DeepONet for 2D Heat Equation**ï¼ˆåˆ†æ•°é˜¶çƒ­ä¼ å¯¼æ–¹ç¨‹ï¼‰  
   - æ›´å¤æ‚çš„åˆ†æ•°é˜¶ PDE é—®é¢˜
   - åˆ†æè§£å·²çŸ¥ï¼Œä¾¿äºå®šé‡è¯„ä¼°è¯¯å·®

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA H100 80GB GPU
- **è®­ç»ƒè½®æ¬¡**ï¼š10,000 epochsï¼ˆBurgersï¼‰ã€2,000 epochsï¼ˆHeat Equationï¼‰
- **è¶…å‚æ•°è°ƒä¼˜**ï¼šå¯¹æ‰€æœ‰ä¼˜åŒ–å™¨è¿›è¡Œç½‘æ ¼æœç´¢ï¼ˆgrid searchï¼‰ï¼Œé€‰æ‹©æœ€ä¼˜ learning rateã€momentum ç­‰
- **SpecMuon ç‰¹æœ‰å‚æ•°**ï¼š
  - `rtop`ï¼šä¿ç•™çš„ä¸»å¯¼å¥‡å¼‚æ–¹å‘æ•°ï¼ˆ2â€“10ï¼‰
  - `Î·_sav`ï¼šSAV å¹³æ»‘å› å­ï¼ˆé»˜è®¤ 0.2ï¼‰

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Final Training Loss** | æœ€ç»ˆè®­ç»ƒæŸå¤±ï¼ˆlog scaleï¼‰ |
| **Mean Squared Error (MSE)** | é¢„æµ‹è§£ä¸çœŸè§£ä¹‹é—´çš„å‡æ–¹è¯¯å·® |
| **Relative L2 Error** | ç›¸å¯¹ L2 èŒƒæ•°è¯¯å·® |
| **Training Time** | æ€»è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰ |
| **Solution Smoothness & Accuracy** | å¯è§†åŒ–è§£çš„ç©ºé—´åˆ†å¸ƒä¸è¯¯å·®å›¾ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Adam**
- **AdamW**
- **Muon**ï¼ˆåŸå§‹ç‰ˆæœ¬ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### è¡¨ 1ï¼šBurgersâ€™ PINN å®éªŒç»“æœï¼ˆTable 2ï¼‰
| Optimizer | Final Training Loss | MSE | Training Time (s) |
|----------|---------------------|------|------------------|
| Adam     | $5.88 \times 10^{-4}$ | $1.42 \times 10^{-3}$ | 120 Â± 12 |
| AdamW    | $7.46 \times 10^{-4}$ | $1.50 \times 10^{-3}$ | 117 Â± 11 |
| Muon     | $3.39 \times 10^{-4}$ | $1.25 \times 10^{-3}$ | 149 Â± 15 |
| **SpecMuon** | $\mathbf{1.55 \times 10^{-4}}$ | $\mathbf{5.06 \times 10^{-4}}$ | 180 Â± 18 |

> âœ… **SpecMuon è¾¾åˆ°æœ€ä½è®­ç»ƒæŸå¤±å’Œæœ€å° MSE**

#### è¡¨ 2ï¼šDeepONet å®éªŒç»“æœï¼ˆTable 4ï¼‰
| Optimizer | Final Training Loss | MSE |
|----------|---------------------|------|
| Adam     | $1.89 \times 10^{-3}$ | 0.0014 |
| AdamW    | $4.71 \times 10^{-5}$ | 0.0013 |
| Muon     | $6.38 \times 10^{-4}$ | 0.0011 |
| **SpecMuon** | $\mathbf{4.82 \times 10^{-5}}$ | $\mathbf{0.0010}$ |

> âœ… **SpecMuon åœ¨ç®—å­å­¦ä¹ ä»»åŠ¡ä¸­ä»ä¿æŒé¢†å…ˆ**

#### è¡¨ 3ï¼šfPINN-DeepONet å®éªŒç»“æœï¼ˆTable 6ï¼‰
| Optimizer | Training Loss @500ep | MSE |
|----------|------------------------|------|
| Adam     | $3.72 \times 10^{-2}$ | 0.0268 |
| AdamW    | $3.64 \times 10^{-2}$ | 0.0275 |
| Muon     | $3.52 \times 10^{-2}$ | 0.0272 |
| **SpecMuon** | $\mathbf{2.31 \times 10^{-2}}$ | $\mathbf{0.0262}$ |

> âœ… **å³ä½¿åœ¨åˆ†æ•°é˜¶ PDE ä¸­ï¼ŒSpecMuon ä¾ç„¶æ˜¾è‘—ä¼˜äºåŸºçº¿**

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ”¶æ•›é€Ÿåº¦**ï¼šSpecMuon åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºæ›´å¿«çš„åˆå§‹ä¸‹é™é€Ÿåº¦å’Œæ›´ç¨³å®šçš„åæœŸæ”¶æ•›ã€‚
- **ç¨³å®šæ€§**ï¼šé¿å…äº† Adam çš„éœ‡è¡å’Œ Muon çš„è¿‡å†²ç°è±¡ã€‚
- **ç²¾åº¦æå‡**ï¼šMSE æ™®éé™ä½ **30%~60%**ï¼Œå°¤å…¶æ˜¯åœ¨ DeepONet å’Œ fPINN è®¾ç½®ä¸‹ã€‚
- **è®¡ç®—å¼€é”€**ï¼šç”±äº SVD å’Œ RSAV å¼€é”€ï¼ŒSpecMuon è®­ç»ƒæ—¶é—´ç•¥é«˜ï¼ˆçº¦å¢åŠ  20â€“50%ï¼‰ï¼Œä½†ç²¾åº¦æ”¶ç›Šè¿œè¶…æˆæœ¬ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
- **rtop å‚æ•°å½±å“**ï¼ˆå›¾ 2b, 5b, 6bï¼‰ï¼š
  - å½“ `rtop = 6~8` æ—¶æ€§èƒ½æœ€ä½³
  - è¿‡å°ï¼ˆå¦‚ 2ï¼‰æ— æ³•æ•æ‰è¶³å¤Ÿè°±ç»“æ„ï¼›è¿‡å¤§åˆ™å¼•å…¥å™ªå£°å¹¶å¢åŠ è®¡ç®—è´Ÿæ‹…
- **SAV æœºåˆ¶ä½œç”¨**ï¼š
  - ç§»é™¤ RSAV åé€€åŒ–ä¸ºæ™®é€š Muonï¼Œå‡ºç°ä¸ç¨³å®šæ›´æ–°
  - ä¿ç•™ RSAV æ˜¾è‘—å¢å¼ºé²æ£’æ€§å’Œæ”¶æ•›ä¸€è‡´æ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è°±ç»“æ„åœ¨ç§‘å­¦æœºå™¨å­¦ä¹ ä¼˜åŒ–ä¸­è‡³å…³é‡è¦**ï¼šå³ä½¿æ˜¯çº¿æ€§å›å½’è¿™æ ·çš„å‡¸é—®é¢˜ï¼Œè°±ä¸å¹³è¡¡ä¹Ÿä¼šå½±å“æ”¶æ•›æ•ˆç‡ã€‚
2. **å‡ ä½•æ­£äº¤åŒ– + èƒ½é‡æ§åˆ¶ = æ›´ä¼˜ä¼˜åŒ–è·¯å¾„**ï¼šSpecMuon æˆåŠŸå°† Muon çš„å‡ ä½•ä¼˜åŠ¿ä¸ SAV çš„èƒ½é‡ç¨³å®šæ€§ç»“åˆï¼Œå®ç°äº†â€œæ—¢å¿«åˆç¨³â€çš„ä¼˜åŒ–ã€‚
3. **å¤šæ¨¡æ€æ¢¯åº¦æµè§†è§’æœ‰æ•ˆ**ï¼šå°†ä¼˜åŒ–è§†ä¸ºå„å¥‡å¼‚æ¨¡å¼ä¸Šçš„ç‹¬ç«‹æ¼”åŒ–ï¼Œå…è®¸å¯¹åˆšæ€§é«˜é¢‘åˆ†é‡è¿›è¡Œé€‰æ‹©æ€§é˜»å°¼ï¼ŒåŒæ—¶ä¿ç•™ä½é¢‘å¿«é€Ÿæ›´æ–°ã€‚
4. **ç†è®ºä¿éšœå¼º**ï¼šä½œè€…å»ºç«‹äº†ä¸¥æ ¼çš„ç†è®ºæ€§è´¨ï¼ŒåŒ…æ‹¬ï¼š
   - ä¿®æ”¹åçš„èƒ½é‡è€—æ•£å¾‹ï¼ˆmodified energy dissipation lawï¼‰
   - è¾…åŠ©å˜é‡çš„æ­£å®šæ€§ä¸æœ‰ç•Œæ€§
   - åœ¨ **Polyak-Åojasiewicz æ¡ä»¶** ä¸‹çš„çº¿æ€§æ”¶æ•›é€Ÿç‡

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å¤æ‚åº¦è¾ƒé«˜**ï¼šä¾èµ– SVD åˆ†è§£ï¼Œåœ¨å¤§è§„æ¨¡å‚æ•°çŸ©é˜µä¸Šå¯èƒ½æˆä¸ºç“¶é¢ˆï¼ˆå°½ç®¡é‡‡ç”¨æˆªæ–­ç­–ç•¥ç¼“è§£ï¼‰
- **ç›®å‰ä»…é€‚ç”¨äºå…¨æ‰¹é‡æˆ–å¤§æ‰¹æ¬¡è®¾ç½®**ï¼šå°šæœªæ‰©å±•è‡³ mini-batch æˆ–éšæœºè®¾å®š
- **éœ€æ‰‹åŠ¨è®¾ç½® `rtop`**ï¼šè™½ç„¶å¯é€šè¿‡æ¶ˆèç¡®å®šï¼Œä½†ç¼ºä¹è‡ªåŠ¨é€‰æ‹©æœºåˆ¶

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³éšæœºä¼˜åŒ–åœºæ™¯**ï¼šç ”ç©¶ SpecMuon åœ¨ mini-batch SGD ä¸­çš„è¡¨ç°ï¼Œå¹¶ç»“åˆæ–¹å·®ç¼©å‡æŠ€æœ¯ã€‚
2. **è‡ªé€‚åº”è°±æˆªæ–­ç­–ç•¥**ï¼šè®¾è®¡è‡ªåŠ¨é€‰æ‹© `rtop` çš„æœºåˆ¶ï¼Œæ ¹æ®æ¢¯åº¦è°±åŠ¨æ€è°ƒæ•´ä¿ç•™æ¨¡å¼æ•°é‡ã€‚
3. **æ›´å¹¿æ³›çš„ç§‘å­¦é—®é¢˜åº”ç”¨**ï¼šåº”ç”¨äºå¤šç‰©ç†åœºè€¦åˆç³»ç»Ÿã€åé—®é¢˜ã€ä¸ç¡®å®šæ€§é‡åŒ–ç­‰æ›´å…·æŒ‘æˆ˜æ€§çš„åœºæ™¯ã€‚
4. **ç†è®ºæ·±åŒ–**ï¼šæ¢ç´¢æ›´å¼±å‡è®¾ä¸‹çš„æ”¶æ•›ç‡ï¼Œåˆ†æè°±æ¼”åŒ–è·¨è¿­ä»£çš„åŠ¨åŠ›å­¦è¡Œä¸ºã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **SpecMuon é€šè¿‡å°† Muon çš„å¥‡å¼‚å‘é‡æ­£äº¤åŒ–ä¸ RSAV çš„èƒ½é‡è°ƒæ§æœºåˆ¶ç›¸ç»“åˆï¼Œæå‡ºäº†ä¸€ç§é¢å‘ç§‘å­¦æœºå™¨å­¦ä¹ çš„æ–°å‹è°±æ„ŸçŸ¥ä¼˜åŒ–å™¨ï¼Œåœ¨å¤šç§ PINN ä¸ Neural Operator ä»»åŠ¡ä¸­å®ç°äº†æ›´å¿«ã€æ›´ç¨³ã€æ›´å‡†çš„è®­ç»ƒæ•ˆæœï¼Œå…¼å…·åšå®çš„ç†è®ºåŸºç¡€ä¸æ˜¾è‘—çš„å®è¯ä¼˜åŠ¿ã€‚**

</details>

---

### 13. [Fast KV Compaction via Attention Matching](https://arxiv.org/abs/2602.16284)

**Authors**: Adam Zweiger, Xinghong Fu, Han Guo, Yoon Kim  
**Category**: cs.LG  
**Published**: 2026-02-19  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.16284v1  

#### Abstract
Scaling language models to long contexts is often bottlenecked by the size of the key-value (KV) cache. In deployed settings, long contexts are typically managed through compaction in token space via summarization. However, summarization can be highly lossy, substantially harming downstream performa...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šFast KV Compaction via Attention Matching**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
ç°ä»£å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶é¢ä¸´ **Key-Value (KV) ç¼“å­˜** å†…å­˜ç“¶é¢ˆã€‚éšç€ä¸Šä¸‹æ–‡é•¿åº¦å¢åŠ ï¼ŒKV cache å¯èƒ½å ç”¨æ•° GB å†…å­˜ï¼Œä¸¥é‡å½±å“æ¨ç†æ•ˆç‡ã€‚ä¼ ç»Ÿæ–¹æ³•å¦‚ **token summarization** æˆ– **token eviction** è™½ç„¶å¿«é€Ÿï¼Œä½†åœ¨é«˜å‹ç¼©æ¯”ä¸‹æŸå¤±ä¸¥é‡ï¼Œå¯¼è‡´ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½å¤§å¹…ä¸‹é™ã€‚

ç°æœ‰æ–¹æ³•å¦‚ **Cartridges (Eyuboglu et al., 2025)** èƒ½åœ¨æ½œåœ¨ç©ºé—´ä¸­è®­ç»ƒé«˜åº¦ç´§å‡‘çš„ KV cacheï¼Œå®ç°é«˜è´¨é‡å‹ç¼©ï¼ˆå¦‚ 50Ã—ï¼‰ï¼Œä½†ä¾èµ–ç«¯åˆ°ç«¯æ¢¯åº¦ä¼˜åŒ–ï¼Œè€—æ—¶é•¿è¾¾æ•°å°æ—¶ï¼Œéš¾ä»¥å®ç”¨ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³ **â€œå¦‚ä½•åœ¨ä¿è¯é«˜è´¨é‡çš„å‰æä¸‹ï¼Œå®ç°æå¿«çš„ KV cache å‹ç¼©â€** è¿™ä¸€å…³é”®æŒ‘æˆ˜ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æå‡º **Attention Matching (AM)** æ¡†æ¶ï¼Œä¸€ç§åŸºäºæ³¨æ„åŠ›è¡Œä¸ºåŒ¹é…çš„ **éæ¢¯åº¦ã€é—­å¼è§£ï¼ˆclosed-formï¼‰** çš„ KV å‹ç¼©æ–¹æ³•ã€‚

#### **æ ¸å¿ƒæ€æƒ³**
ä¸é€šè¿‡ç«¯åˆ°ç«¯ä¼˜åŒ–è¾“å‡ºåˆ†å¸ƒï¼Œè€Œæ˜¯ç›´æ¥ä¼˜åŒ–å‹ç¼©åçš„ `(Ck, Cv)`ï¼Œä½¿å…¶æ»¡è¶³ä¸¤ä¸ªå…³é”®æ¡ä»¶ï¼š
1. **Attention Output Matching**ï¼šå‹ç¼©å—å¯¹å‚è€ƒæŸ¥è¯¢ `q` çš„æ³¨æ„åŠ›è¾“å‡ºåº”ä¸åŸå§‹ KV å—ä¸€è‡´ã€‚
2. **Attention Mass Matching**ï¼šå‹ç¼©å—çš„æ³¨æ„åŠ›è´¨é‡ï¼ˆmassï¼‰åº”ä¸åŸå§‹å—åŒ¹é…ï¼Œä»¥ç¡®ä¿åœ¨æ‹¼æ¥æœªæ¥ token æ—¶è¡Œä¸ºä¸€è‡´ã€‚

ä¸ºæ­¤å¼•å…¥ **per-token scalar bias Î²**ï¼Œç”¨äºè°ƒæ•´æ¯ä¸ªä¿ç•™ key çš„æ³¨æ„åŠ›æƒé‡ï¼Œä»è€Œè¡¥å¿å› æ•°é‡å‡å°‘å¯¼è‡´çš„è´¨é‡æŸå¤±ã€‚

#### **æ–¹æ³•æµç¨‹**
1. **ç”Ÿæˆå‚è€ƒæŸ¥è¯¢ `Qref`**ï¼šé€šè¿‡ `repeat-prefill` æˆ– `self-study` ç”Ÿæˆæ¨¡å‹å¯èƒ½äº§ç”Ÿçš„æŸ¥è¯¢å‘é‡ã€‚
2. **é€‰æ‹©å‹ç¼© keys `Ck`**ï¼šé‡‡ç”¨å¯å‘å¼ï¼ˆå¦‚æœ€é«˜æ³¨æ„åŠ› keyï¼‰æˆ– OMPï¼ˆæ­£äº¤åŒ¹é…è¿½è¸ªï¼‰é€‰æ‹©å­é›†ã€‚
3. **æ‹Ÿåˆ bias `Î²` å’Œ values `Cv`**ï¼š
   - `Î²` é€šè¿‡ **éè´Ÿæœ€å°äºŒä¹˜ (NNLS)** æ‹Ÿåˆï¼Œä½¿ attention mass åŒ¹é…ã€‚
   - `Cv` é€šè¿‡ **æ™®é€šæœ€å°äºŒä¹˜ (OLS)** æ‹Ÿåˆï¼Œä½¿ attention output åŒ¹é…ã€‚

è¯¥æ¡†æ¶å°†å¤æ‚ä¼˜åŒ–åˆ†è§£ä¸ºå¤šä¸ªå¯é«˜æ•ˆæ±‚è§£çš„å­é—®é¢˜ï¼Œé¿å…äº†è€—æ—¶çš„æ¢¯åº¦ä¸‹é™ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç‰¹æ€§ | Cartridges | Token Pruning (H2O, KVzip) | **Attention Matching (æœ¬æ–‡)** |
|------|----------|----------------------------|------------------------------|
| **å‹ç¼©è´¨é‡** | é«˜ | ä½ï¼ˆå°¤å…¶é«˜æ¯”ä¾‹æ—¶ï¼‰ | **æ¥è¿‘ Cartridges** |
| **å‹ç¼©é€Ÿåº¦** | ææ…¢ï¼ˆå°æ—¶çº§ï¼‰ | å¿«ï¼ˆç§’çº§ï¼‰ | **æå¿«ï¼ˆç§’çº§ï¼‰ï¼Œæ¯” Cartridges å¿« 100Ã—** |
| **æ˜¯å¦éœ€è®­ç»ƒ** | æ˜¯ï¼ˆper-context ä¼˜åŒ–ï¼‰ | å¦ | å¦ï¼ˆpost-hocï¼‰ |
| **æ˜¯å¦æ”¯æŒ chunking** | æ˜¯ï¼ˆè·¨ chunk ä¼˜åŒ–ï¼‰ | æ˜¯ | æ˜¯ï¼ˆç‹¬ç«‹ chunk å¤„ç†ï¼‰ |
| **æ˜¯å¦å¼•å…¥ bias** | å¦ | å¦ | **æ˜¯ï¼ˆå…³é”®è®¾è®¡ï¼‰** |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šåœ¨ **50Ã— å‹ç¼©æ¯”** ä¸‹ï¼Œ**è´¨é‡æ¥è¿‘ Cartridgesï¼Œé€Ÿåº¦æå‡ 2 ä¸ªæ•°é‡çº§**ï¼Œé¦–æ¬¡å®ç°äº†é«˜è´¨é‡ä¸é«˜é€Ÿåº¦çš„å¸•ç´¯æ‰˜å‰æ²¿çªç ´ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **QuALITY**ï¼šé•¿æ–‡æœ¬ç†è§£åŸºå‡†ï¼Œæ¯ç¯‡ 5â€“8k tokensï¼Œå« 15â€“20 ä¸ªå¤šé¡¹é€‰æ‹©é¢˜ï¼Œå…± 50 ç¯‡æ–‡ç« ï¼ˆ894 é—®ï¼‰ã€‚
- **LongHealth**ï¼šä¸´åºŠç—…å†é—®ç­”ä»»åŠ¡ï¼Œæ¯ä¸Šä¸‹æ–‡çº¦ 60k tokensï¼ˆ5 åæ‚£è€…è®°å½•ï¼‰ï¼Œä¿¡æ¯å¯†é›†ï¼Œæ›´å…·æŒ‘æˆ˜æ€§ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **æ¨¡å‹**ï¼šQwen3-4B, Llama3.1-8B, Gemma3-12Bã€‚
- **å‹ç¼©æ¯”èŒƒå›´**ï¼š10Ã— åˆ° 100Ã—ã€‚
- **è¯„ä¼°æ–¹å¼**ï¼š
  - ä¸€æ¬¡æ€§å‹ç¼©ä¸Šä¸‹æ–‡ï¼Œç„¶åç”¨å‹ç¼© cache å›ç­”æ‰€æœ‰é—®é¢˜ã€‚
  - æŠ¥å‘Š **ä¸‹æ¸¸ QA å‡†ç¡®ç‡** å’Œ **log-perplexity**ï¼ˆè¡¡é‡ token-level è¡Œä¸ºä¿çœŸåº¦ï¼‰ã€‚
- **ç¡¬ä»¶**ï¼šå•å¼  H100/H200 GPUï¼ŒæŠ¥å‘Š **wall-clock compaction time**ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åŸºçº¿ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| **Cartridges** | æ¢¯åº¦ä¼˜åŒ– | ç«¯åˆ°ç«¯è®­ç»ƒ latent cacheï¼Œé«˜è´¨é‡ä½†ææ…¢ |
| **H2O+, SnapKV, PyramidKV, KVzip** | Token Pruning | åŸºäº attention score é€‰æ‹© tokenï¼Œé€Ÿåº¦å¿«ä½†è´¨é‡å·® |
| **Summarization** | Token Space | æ–‡æœ¬æ‘˜è¦ï¼Œä¸¥é‡ä¸¢å¤±ç»†èŠ‚ |
| **No Context** | æ§åˆ¶ç»„ | å®Œå…¨æ— ä¸Šä¸‹æ–‡ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- åœ¨ **Qwen3-4B + QuALITY** ä¸Šï¼Œ**50Ã— å‹ç¼©**ï¼š
  - **AM-OMP**ï¼šå‡†ç¡®ç‡ **~0.65**ï¼Œå‹ç¼©æ—¶é—´ **~10 åˆ†é’Ÿ**ã€‚
  - **AM-HighestAttnKeys-fast**ï¼šå‡†ç¡®ç‡ **~0.60**ï¼Œå‹ç¼©æ—¶é—´ **< 1 åˆ†é’Ÿ**ã€‚
  - **Cartridges**ï¼šå‡†ç¡®ç‡ **~0.62**ï¼Œå‹ç¼©æ—¶é—´ **~5 å°æ—¶**ã€‚
  - **Summarization**ï¼šå‡†ç¡®ç‡ **~0.45**ã€‚
- **é€Ÿåº¦æå‡**ï¼šAM æ–¹æ³•æ¯” Cartridges **å¿« 50â€“100Ã—**ï¼ŒåŒæ—¶è´¨é‡æ›´é«˜ã€‚

> ğŸ“ˆ å›¾ 1 æ˜¾ç¤º AM æ–¹æ³•åœ¨ **å‡†ç¡®ç‡ vs. å‹ç¼©æ—¶é—´** æ›²çº¿ä¸Šå½¢æˆæ–°çš„å¸•ç´¯æ‰˜å‰æ²¿ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **ä¼˜äºæ‰€æœ‰ token pruning æ–¹æ³•**ï¼ˆH2O, SnapKV, KVzipï¼‰åœ¨é«˜å‹ç¼©æ¯”ä¸‹ã€‚
- **åœ¨ 50Ã— æ—¶è´¨é‡è¶…è¿‡ Cartridges**ï¼Œåœ¨ 100Ã— æ—¶ç•¥é€Šï¼ˆå› æ¢¯åº¦æ–¹æ³•æœç´¢ç©ºé—´æ›´å¤§ï¼‰ã€‚
- **KVzip** åœ¨æŸäº›è®¾ç½®ä¸‹è¡¨ç°æ¥è¿‘ AMï¼Œå½’å› äºå…¶éå‡åŒ€é¢„ç®—åˆ†é…ã€‚
- **Summarization** åœ¨ LongHealth ä¸Šå‡ ä¹é€€åŒ–åˆ° â€œNo Contextâ€ æ°´å¹³ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**
- **ç§»é™¤ nonuniform head budgets**ï¼šæ€§èƒ½æ˜¾è‘—ä¸‹é™ â†’ è¯æ˜ä¸åŒ attention head å¯¹å‹ç¼©æ•æ„Ÿåº¦ä¸åŒã€‚
- **ç§»é™¤ bias Î²**ï¼šæ€§èƒ½ä¸‹é™ï¼Œå°¤å…¶åœ¨é«˜æ¯”ä¾‹å‹ç¼©æ—¶ â†’ è¯æ˜ bias å¯¹ mass matching è‡³å…³é‡è¦ã€‚
- **ç§»é™¤ self-study æŸ¥è¯¢**ï¼šæ€§èƒ½è½»å¾®ä¸‹é™ â†’ `repeat-prefill` å·²è¶³å¤Ÿæœ‰æ•ˆã€‚
- **ä½¿ç”¨ on-policy queries**ï¼šå¸¦æ¥ç¨³å®šå°å¹…æå‡ã€‚
- **OMP vs. Highest Attention Keys**ï¼šOMP æ›´ä¼˜ä½†æ›´æ…¢ï¼Œfast variant å¹³è¡¡è‰¯å¥½ã€‚

> ğŸ” æ¶ˆèéªŒè¯äº† **biasã€value fittingã€nonuniform budgetã€query quality** çš„å¿…è¦æ€§ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **Attention Matching æ˜¯æœ‰æ•ˆçš„å‹ç¼©èŒƒå¼**ï¼šé€šè¿‡åŒ¹é… attention output å’Œ massï¼Œå¯åœ¨ä¸ä¾èµ–æ¢¯åº¦çš„æƒ…å†µä¸‹å®ç°é«˜è´¨é‡å‹ç¼©ã€‚
2. **å¼•å…¥ scalar bias Î² æ˜¯å…³é”®**ï¼šè§£å†³äº†å‹ç¼©å attention mass ä¸è¶³çš„é—®é¢˜ï¼Œä½¿è¡Œä¸ºåœ¨æ‹¼æ¥æ—¶ä¿æŒä¸€è‡´ã€‚
3. **éå‡åŒ€å‹ç¼©ï¼ˆnonuniform compactionï¼‰æ›´ä¼˜**ï¼šä¸åŒ attention head å¯¹å®¹é‡æ•æ„Ÿåº¦å·®å¼‚å¤§ï¼Œé¢„è®¡ç®— head budget å¯æ˜¾è‘—æå‡æ•ˆç‡ã€‚
4. **chunked compaction æ”¯æŒè¶…é•¿ä¸Šä¸‹æ–‡**ï¼šå¯ç‹¬ç«‹å¤„ç†å„ chunk å¹¶åˆå¹¶ï¼Œé€‚ç”¨äº 60k+ token åœºæ™¯ã€‚
5. **AM å¯ä¸ summarization ç»“åˆ**ï¼šå…ˆæ‘˜è¦å† AM å‹ç¼©ï¼Œå®ç° **200Ã— æ€»å‹ç¼©æ¯”**ï¼Œæ€§èƒ½ä»æ¥è¿‘çº¯æ‘˜è¦ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **OMP + self-study å˜ä½“ä»éœ€æ•°åˆ†é’Ÿ**ï¼šè™½æ¯” Cartridges å¿«ï¼Œä½†ä»ä¸å¤Ÿå®æ—¶ã€‚
2. **åœ¨æç«¯å‹ç¼©æ¯”ï¼ˆå¦‚ 100Ã—ï¼‰ä¸‹ï¼ŒCartridges ä»ç•¥ä¼˜**ï¼šå› å…¶å¯æœç´¢æ›´å¹¿çš„è¡¨ç¤ºç©ºé—´ï¼ˆä¸é™äºåŸ key å­é›†ï¼‰ã€‚
3. **æœªæ¢ç´¢é‡åŒ–æˆ–ç¨€ç–åŒ–**ï¼šå½“å‰ä½¿ç”¨ FP32/BF16ï¼Œè¿›ä¸€æ­¥å‹ç¼©æ½œåŠ›æœªå¼€å‘ã€‚
4. **online compaction åˆæ­¥éªŒè¯æœ‰æ•ˆï¼Œä½†ç­–ç•¥ç®€å•**ï¼šå¦‚å§‹ç»ˆå‹ç¼©æ•´ä¸ªä¸Šä¸‹æ–‡ï¼Œæœªå†»ç»“å†å²éƒ¨åˆ†ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **åŠ é€Ÿ query generation å’Œ key selection**ï¼šå¦‚ä½¿ç”¨è½»é‡æ¨¡å‹ç”ŸæˆæŸ¥è¯¢ã€‚
2. **è¶…è¶Šå­é›†é€‰æ‹©**ï¼šç›´æ¥ä¼˜åŒ– compact keysï¼ˆéä»åŸ key ä¸­é€‰ï¼‰ï¼Œæ‰©å¤§æœç´¢ç©ºé—´ã€‚
3. **é›†æˆåˆ° inference engine**ï¼šå¦‚ RadixAttentionã€varlen KV packingã€disaggregated compactionã€‚
4. **ç»“åˆ token-space ä¸ latent-space æ–¹æ³•**ï¼šå¦‚ retrieval + summarization + AMï¼Œæ„å»ºæ··åˆè®°å¿†ç³»ç»Ÿã€‚
5. **æ”¯æŒåœ¨çº¿å‹ç¼©ï¼ˆonline compactionï¼‰**ï¼šåœ¨é•¿ç¨‹æ¨ç†ä¸­åŠ¨æ€å‹ç¼©ï¼Œæ”¯æŒæ— é™é•¿åº¦ç”Ÿæˆã€‚
6. **æ¨¡å‹æ¶æ„å±‚é¢æ”¯æŒ compaction**ï¼šè®­ç»ƒæ—¶æ˜¾å¼è®¾è®¡å¯å‹ç¼©çš„ KV ç»“æ„ã€‚

---

> âœ… **æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºçš„ **Attention Matching** æ¡†æ¶ï¼Œé€šè¿‡ **è¡Œä¸ºåŒ¹é… + é—­å¼æ±‚è§£**ï¼Œåœ¨ **é€Ÿåº¦ä¸è´¨é‡ä¹‹é—´å–å¾—äº†å‰æ‰€æœªæœ‰çš„å¹³è¡¡**ï¼Œä¸ºé•¿ä¸Šä¸‹æ–‡ LLM æ¨ç†æä¾›äº†å®ç”¨ä¸”é«˜æ•ˆçš„ KV å‹ç¼©æ–¹æ¡ˆã€‚

</details>

---

### 14. [Towards Efficient Constraint Handling in Neural Solvers for Routing Problems](https://arxiv.org/abs/2602.16012)

**Authors**: Jieyi Bi, Zhiguang Cao, Jianan Zhou, Wen Song, Yaoxin Wu, Jie Zhang, Yining Ma, Cathy Wu  
**Category**: cs.AI  
**Published**: 2026-02-19  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.16012v1  

#### Abstract
Neural solvers have achieved impressive progress in addressing simple routing problems, particularly excelling in computational efficiency. However, their advantages under complex constraints remain nascent, for which current constraint-handling schemes via feasibility masking or implicit feasibilit...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
- å½“å‰ç¥ç»æ±‚è§£å™¨ï¼ˆNeural Solversï¼‰åœ¨å¤„ç†**ç®€å•è·¯å¾„è§„åˆ’é—®é¢˜**ï¼ˆå¦‚ CVRPï¼‰æ—¶è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨é¢å¯¹**å¤æ‚çº¦æŸ**ï¼ˆå¦‚æ—¶é—´çª—ã€å›ç¨‹ã€å®¹é‡ç­‰å¤šé‡ç¡¬çº¦æŸï¼‰æ—¶è¡¨ç°ä¸ä½³ã€‚
- ç°æœ‰çº¦æŸå¤„ç†æœºåˆ¶å­˜åœ¨ä¸¤å¤§ç“¶é¢ˆï¼š
  - **å¯è¡Œæ€§æ©ç ï¼ˆFeasibility Maskingï¼‰**ï¼šåœ¨å¤æ‚é—®é¢˜ä¸­è®¡ç®—æ©ç æœ¬èº«æ˜¯ NP-hardï¼ˆä¾‹å¦‚ TSPTWï¼‰ï¼Œå¯¼è‡´ä¸å¯è¡Œæˆ–æ•ˆç‡ä½ä¸‹ã€‚
  - **éšå¼å¯è¡Œæ€§æ„ŸçŸ¥ï¼ˆImplicit Feasibility Awarenessï¼‰**ï¼šé€šè¿‡å¥–åŠ±å¡‘å½¢æˆ–ç‰¹å¾å¢å¼ºå¼•å¯¼ç­–ç•¥ï¼Œä½†éš¾ä»¥ä¿è¯ä¸¥æ ¼å¯è¡Œæ€§ï¼Œä¸”ä»å¯èƒ½å¯¼è‡´é«˜ä¸å¯è¡Œç‡ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æå‡º **Construct-and-Refine (CaR)** æ¡†æ¶ï¼Œé¦–ä¸ªåŸºäº**æ˜¾å¼å­¦ä¹ å‹å¯è¡Œæ€§ç²¾ç‚¼**ï¼ˆexplicit learning-based feasibility refinementï¼‰çš„é€šç”¨é«˜æ•ˆçº¦æŸå¤„ç†æ¡†æ¶ã€‚

#### **æ ¸å¿ƒåˆ›æ–°ç‚¹**ï¼š
1. **è”åˆè®­ç»ƒæ„é€ ä¸ç²¾ç‚¼æ¨¡å—**ï¼š
   - æ„é€ æ¨¡å—ç”Ÿæˆå¤šæ ·ä¸”é«˜è´¨é‡çš„åˆå§‹è§£ã€‚
   - ç²¾ç‚¼æ¨¡å—åœ¨æå°‘æ•°æ­¥éª¤å†…ï¼ˆå¦‚ 10 æ­¥ vs. å…ˆå‰å·¥ä½œçš„ 5k æ­¥ï¼‰è¿›è¡Œè½»é‡çº§æ”¹è¿›ã€‚
   - ä¸¤è€…é€šè¿‡ç«¯åˆ°ç«¯è”åˆè®­ç»ƒååŒä¼˜åŒ–ï¼Œæ„é€ æ¨¡å—è¢«å¼•å¯¼ç”Ÿæˆâ€œæ˜“äºç²¾ç‚¼â€çš„è§£ã€‚

2. **æ˜¾å¼å¯è¡Œæ€§ç²¾ç‚¼å–ä»£ä¸¥æ ¼æ©ç **ï¼š
   - æ”¾å¼ƒåœ¨æ„é€ é˜¶æ®µå¼ºåˆ¶æ‰§è¡Œä¸¥æ ¼æ©ç ï¼Œå…è®¸ç”Ÿæˆéƒ¨åˆ†ä¸å¯è¡Œè§£ã€‚
   - ç”±ä¸“é—¨çš„ç²¾ç‚¼æ¨¡å—åœ¨åç»­æ­¥éª¤ä¸­ä¸»åŠ¨ä¿®æ­£ä¸å¯è¡Œæ€§ï¼Œå®ç°æ›´çµæ´»é«˜æ•ˆçš„æ¢ç´¢ã€‚

3. **è·¨èŒƒå¼è¡¨ç¤ºå…±äº«ï¼ˆCross-Paradigm Representation Learningï¼‰**ï¼š
   - é¦–æ¬¡åœ¨æ„é€ ä¸ç²¾ç‚¼æ¨¡å—é—´å…±äº«ç¼–ç å™¨ï¼ˆShared Encoderï¼‰ã€‚
   - å®ç°çŸ¥è¯†è¿ç§»ï¼Œæå‡æ¨¡å‹åœ¨å¤æ‚çº¦æŸä¸‹çš„æ³›åŒ–èƒ½åŠ›ä¸æ€§èƒ½ã€‚

4. **å®šåˆ¶åŒ–æŸå¤±å‡½æ•°è®¾è®¡**ï¼š
   - å¼•å…¥**å¤šæ ·æ€§æŸå¤±**ï¼ˆdiversity lossï¼‰é¼“åŠ±ç­–ç•¥æ¢ç´¢ã€‚
   - è®¾è®¡**ç›‘ç£ä¿¡å·æŸå¤±**ï¼ˆsupervised lossï¼‰ï¼Œç”¨ç²¾ç‚¼åçš„ä¼˜è´¨è§£åå‘æŒ‡å¯¼æ„é€ ç­–ç•¥æ›´æ–°ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **æ›´å¹¿é€‚ç”¨æ€§**ï¼šé¦–æ¬¡èƒ½æœ‰æ•ˆå¤„ç†æ©ç ä¸å¯è®¡ç®—ï¼ˆå¦‚ TSPTWï¼‰å’Œæ©ç è¿‡åº¦é™åˆ¶ï¼ˆå¦‚ CVRPBLTWï¼‰çš„å¤æ‚ VRPã€‚
- **æ›´é«˜æ•ˆç‡**ï¼šç²¾ç‚¼ä»…éœ€ 5â€“20 æ­¥ï¼Œæ¨ç†æ—¶é—´ä»å°æ—¶çº§é™è‡³ç§’çº§ï¼ˆå¦‚ 8Ã— é€Ÿåº¦æå‡ï¼‰ã€‚
- **æ›´ä¼˜æ€§èƒ½**ï¼šåœ¨å¯è¡Œæ€§ã€æœ€ä¼˜æ€§å·®è·ï¼ˆGapï¼‰ã€è§£è´¨é‡ä¸Šå…¨é¢è¶…è¶Šç»å…¸æ±‚è§£å™¨ï¼ˆLKH-3, OR-Toolsï¼‰å’Œå‰æ²¿ç¥ç»æ±‚è§£å™¨ï¼ˆPOMO, NeuOpt-GIREï¼‰ã€‚
- **æ›´å¼ºé²æ£’æ€§**ï¼šå¯¹å¤šçº¦æŸè€¦åˆåœºæ™¯æ›´å…·é€‚åº”æ€§ï¼Œé¿å…å› ä¸¥æ ¼æ©ç å¯¼è‡´æœç´¢ç©ºé—´åå¡Œã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **TSPTW**ï¼ˆTraveling Salesman Problem with Time Windowsï¼‰ï¼š
  - åŒ…å«ä¸åŒéš¾åº¦ç­‰çº§ï¼ˆMedium, Hardï¼‰ï¼Œå…¶ä¸­ Hard ç‰ˆæœ¬æ©ç è®¡ç®—ä¸º NP-hardã€‚
- **CVRPBLTW**ï¼ˆCapacitated VRP with Backhaul, Duration, and Time Windowï¼‰ï¼š
  - å¤šé‡ç¡¬çº¦æŸå åŠ ï¼Œæ©ç è™½å¯è®¡ç®—ä½†è¿‡äºä¸¥æ ¼ï¼Œä¸¥é‡é™åˆ¶æœç´¢ç©ºé—´ã€‚
- **å…¶ä»–éªŒè¯ä»»åŠ¡**ï¼š
  - SOPï¼ˆSequential Ordering Problemï¼‰
  - TSPDLï¼ˆTSP with Draft Limitï¼‰
  - CVRP åŠçœŸå®ä¸–ç•ŒåŸºå‡† **CVRPLIB**

æ‰€æœ‰å®ä¾‹å‡åœ¨çº¿ç”Ÿæˆï¼ˆon-the-flyï¼‰ï¼Œæµ‹è¯•é›†æ¥è‡ªå…¬å¼€åŸºå‡†ä»¥ç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **å®éªŒè®¾ç½®**
- **æ¨¡å‹è§„æ¨¡**ï¼šé—®é¢˜è§„æ¨¡ `n=50` å’Œ `n=100`ã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - è®­ç»ƒ 5000 è½®ï¼Œæ¯è½® 20,000 å®ä¾‹ï¼Œbatch size=128ã€‚
  - ä½¿ç”¨å•å¼  NVIDIA RTX 4090 GPUã€‚
  - ç²¾ç‚¼æ­¥æ•° `TR=5` ç”¨äºè®­ç»ƒï¼Œæ¨ç†æ—¶æµ‹è¯• `TR=5,10,20`ã€‚
- **æ¨ç†è§£ç **ï¼š
  - ä½¿ç”¨ 8Ã— æ•°æ®å¢å¼ºï¼ˆaugmentationï¼‰ç”Ÿæˆåˆå§‹è§£ã€‚
  - å¯¹äº CVRPBLTWï¼Œæœ€ç»ˆæ·»åŠ ä¸€æ¬¡å¸¦æ©ç çš„é‡æ„ä»¥ç¡®ä¿å®Œå…¨å¯è¡Œã€‚

#### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Obj. â†“** | å¹³å‡å¯è¡Œè§£çš„ç›®æ ‡å€¼ï¼ˆè¶Šå°è¶Šå¥½ï¼‰ |
| **Gap â†“** | ç›¸å¯¹äºæœ€å¼ºç»å…¸æ±‚è§£å™¨ï¼ˆLKH-3 æˆ– OR-Toolsï¼‰çš„å¹³å‡æœ€ä¼˜æ€§å·®è· |
| **Infsb% â†“** | ä¸å¯è¡Œè§£æ¯”ä¾‹ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ |
| **Time** | æ±‚è§£ 10,000ï¼ˆTSPTWï¼‰æˆ– 1,000ï¼ˆCVRPBLTWï¼‰ä¸ªå®ä¾‹çš„æ€»æ¨ç†æ—¶é—´ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
#### **ç»å…¸æ±‚è§£å™¨**
- **LKH-3**ï¼šå¼ºå¯å‘å¼æ±‚è§£å™¨ï¼Œæ”¯æŒå¤šæ¬¡ trialã€‚
- **OR-Tools**ï¼šGoogle å¼€æºå·¥å…·åŒ…ï¼Œä½¿ç”¨å¼•å¯¼å±€éƒ¨æœç´¢ã€‚
- **Greedy Heuristics**ï¼šæœ€è¿‘é‚»æˆ–æœ€æ—©æˆªæ­¢æ—¶é—´ä¼˜å…ˆã€‚

#### **ç¥ç»æ±‚è§£å™¨**
- **æ„é€ ç±»**ï¼šPOMO, PIP, UDC, MVMoE
- **æ”¹è¿›ç±»**ï¼šNeuOpt-GIRE
- **æ··åˆç±»**ï¼šNCS, LCP
- **åæœç´¢å¢å¼º**ï¼šPOMO+EAS+SGBS

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **TSPTW-100 ç»“æœï¼ˆHardï¼‰**
| æ–¹æ³• | Obj. | Gap â†“ | Infsb% â†“ | Time |
|------|------|--------|-----------|-------|
| LKH-3 (100 trials) | 46.625 | 0.103% | 31.05% | 27m |
| NeuOpt-GIRE* (5k steps) | 46.913 | 0.123% | 0.02% | 30m |
| **CaR-PIP (TR=20)** | **46.923** | **0.146%** | **0.02%** | **2.4m** |

> âœ… **CaR åœ¨ 1/12 æ—¶é—´å†…è¾¾åˆ°ä¸ NeuOpt ç›¸å½“ç”šè‡³æ›´ä¼˜çš„æ€§èƒ½ï¼Œä¸”é¦–æ¬¡å®ç° <0.2% ä¸å¯è¡Œç‡ã€‚**

#### **CVRPBLTW-100 ç»“æœ**
| æ–¹æ³• | Obj. | Gap â†“ | Infsb% â†“ | Time |
|------|------|--------|-----------|-------|
| POMO* | 27.049 | 7.004% | 0.00% | 4s |
| NeuOpt-GIRE* (5k steps) | 24.038 | -1.541% | 39.10% | 12.7m |
| **CaR(R&R, TR=20)** | **24.400** | **-2.448%** | **0.00%** | **19s** |

> âœ… **CaR æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œåœ¨ä¿æŒ 0% ä¸å¯è¡Œçš„åŒæ—¶ï¼Œç›®æ ‡å€¼è¿œè¶… POMOï¼Œå¹¶å‡»è´¥è€—æ—¶æ›´é•¿çš„ NeuOptã€‚**

#### **æ•ˆç‡å¯¹æ¯”ï¼ˆTSPTW-100ï¼‰**
- **CaR è¾ƒ NeuOpt-GIRE å®ç°çº¦ 8Ã— é€Ÿåº¦æå‡**ï¼ˆè§ Figure 3ï¼‰ï¼Œåœ¨ 10 åˆ†é’Ÿé¢„ç®—å†…å–å¾—æ›´ä¼˜ Pareto å‰æ²¿ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **(1) è”åˆè®­ç»ƒçš„é‡è¦æ€§ï¼ˆTable 5ï¼‰**
| æ„é€ æ¨¡å— | ç²¾ç‚¼æ¨¡å— | Gap â†“ | Infsb% â†“ |
|---------|----------|--------|-----------|
| Random | LKH-3 | 0.011% | 60.66% |
| Pretrained PIP | Pretrained NeuOpt* | 0.172% | 2.59% |
| **Trainable PIP + Trainable NeuOpt* (CaR)** | **0.005%** | **0.00%** |

> ğŸ” å•çº¯ç»„åˆé¢„è®­ç»ƒæ¨¡å‹æ•ˆæœæœ‰é™ï¼Œ**è”åˆè®­ç»ƒå¸¦æ¥æ˜¾è‘—å¢ç›Š**ï¼Œè¯æ˜æ¨¡å—é—´ååŒä¼˜åŒ–çš„å…³é”®ä½œç”¨ã€‚

#### **(2) å¤šæ ·æ€§æŸå¤± $L_{div}$ çš„å½±å“ï¼ˆTable 6ï¼‰**
| é—®é¢˜ | æ˜¯å¦ä½¿ç”¨ $L_{div}$ | Gap â†“ | Infsb% â†“ |
|------|---------------------|--------|-----------|
| TSPTW | å¦ | 0.421% | 0.58% |
| TSPTW | æ˜¯ | **0.014%** | **0.01%** |

> âœ… æ·»åŠ å¤šæ ·æ€§æŸå¤±æ˜¾è‘—æå‡æ€§èƒ½ï¼Œå°¤å…¶åœ¨å¤æ‚çº¦æŸä¸‹ã€‚

#### **(3) ç›‘ç£ä¿¡å·æŸå¤± $L_{SL}$ çš„å½±å“ï¼ˆTable 7ï¼‰**
- å¯¹å¼±æ„é€ éª¨å¹²ï¼ˆPOMO*ï¼‰ï¼šGap ä» 0.136% â†’ 0.014%ï¼ŒInfsb% ä» 0.29% â†’ 0.01%
- å¯¹å¼ºéª¨å¹²ï¼ˆPIPï¼‰ï¼šä»æœ‰è¾¹é™…æå‡ï¼ˆ0.006% â†’ 0.005%ï¼‰

> ğŸ” è¡¨æ˜ç›‘ç£ä¿¡å·å¯¹æå‡æ„é€ -ç²¾ç‚¼ååŒè‡³å…³é‡è¦ï¼Œå°¤å…¶å½“æ„é€ æ¨¡å—è¾ƒå¼±æ—¶ã€‚

#### **(4) å…±äº«è¡¨ç¤ºçš„å½±å“ï¼ˆTable 8ï¼‰**
| æ˜¯å¦å…±äº«ç¼–ç å™¨ | #Params | TSPTW-50 Gap â†“ | Infsb% â†“ |
|----------------|--------|----------------|------------|
| å¦ | 2.8M | 0.199% | 0.68% |
| **æ˜¯** | **1.6M** | **0.014%** | **0.01%** |

> âœ… å…±äº«ç¼–ç å™¨ä¸ä»…æå‡æ€§èƒ½ï¼Œè¿˜å‡å°‘å‚æ•°é‡ï¼ˆ1.7Ã—ï¼‰ï¼Œå¢å¼ºçŸ¥è¯†è¿ç§»ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ä¸¥æ ¼æ©ç åœ¨å¤æ‚ VRP ä¸­æœ‰å®³æ— ç›Š**ï¼š
   - æ©ç ä¸å¯è®¡ç®—ï¼ˆTSPTWï¼‰æˆ–è¿‡åº¦é™åˆ¶ï¼ˆCVRPBLTWï¼‰ä¼šé˜»ç¢ RL æ”¶æ•›ã€‚
   - æ”¾æ¾æ©ç  + æ˜¾å¼ç²¾ç‚¼æ˜¯æ›´ä¼˜è·¯å¾„ã€‚

2. **Construct-and-Refine æ˜¯é«˜æ•ˆçº¦æŸå¤„ç†çš„æ–°èŒƒå¼**ï¼š
   - æ„é€ æä¾›é«˜è´¨é‡å€™é€‰ï¼Œç²¾ç‚¼å¿«é€Ÿä¿®å¤ä¸å¯è¡Œæ€§ã€‚
   - è”åˆè®­ç»ƒä½¿ä¸¤æ¨¡å—å½¢æˆæ­£å‘å¾ªç¯ã€‚

3. **å…±äº«è¡¨ç¤ºæå¤§ä¿ƒè¿›è·¨èŒƒå¼å­¦ä¹ **ï¼š
   - ç»Ÿä¸€ç¼–ç å™¨å®ç°æ„é€ ä¸ç²¾ç‚¼é—´çš„çŸ¥è¯†å…±äº«ï¼Œå°¤å…¶åœ¨å¤æ‚åœºæ™¯ä¸‹ä¼˜åŠ¿æ˜æ˜¾ã€‚

4. **CaR æ˜¯é¦–ä¸ªçœŸæ­£é€‚ç”¨äºå¤šç§å¤æ‚çº¦æŸçš„ç¥ç»æ±‚è§£å™¨**ï¼š
   - åœ¨ TSPTWã€CVRPBLTWã€SOP ç­‰ä»»åŠ¡ä¸Šå‡å–å¾— SOTA æ€§èƒ½ã€‚
   - æ•ˆç‡è¿œè¶…ä¼ ç»Ÿæ”¹è¿›æ–¹æ³•ï¼ˆå¦‚ NeuOptï¼‰ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–åˆå§‹æ„é€ è´¨é‡**ï¼šè‹¥æ„é€ æ¨¡å—å®Œå…¨å¤±æ•ˆï¼Œç²¾ç‚¼éš¾ä»¥æŒ½æ•‘ã€‚
- **å½“å‰ä»…é™å•ä»»åŠ¡**ï¼šæœªæ¢ç´¢å¤šä»»åŠ¡ç»Ÿä¸€å»ºæ¨¡ã€‚
- **ç†è®ºåˆ†æä¸è¶³**ï¼šç¼ºä¹å¯¹æ”¶æ•›æ€§ã€æ³›åŒ–ç•Œçš„ä¸¥æ ¼è¯æ˜ï¼ˆä½œè€…æŒ‡å‡ºä¸ºæœªæ¥æ–¹å‘ï¼‰ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. é›†æˆæ›´å¤š backbone æ±‚è§£å™¨ï¼ˆå¦‚ AM, PolyNetï¼‰ã€‚
2. æ‰©å±•è‡³æ›´å¹¿æ³›çš„ COPsï¼ˆå¦‚è°ƒåº¦é—®é¢˜ï¼‰ã€‚
3. æå‡å¯æ‰©å±•æ€§ä»¥å¤„ç†æ›´å¤§è§„æ¨¡å®ä¾‹ï¼ˆå¦‚ n > 1000ï¼‰ã€‚
4. ç†è®ºç ”ç©¶ï¼šå­¦ä¹ æ€§ï¼ˆlearnabilityï¼‰ã€æ”¶æ•›æ€§ã€æ³›åŒ–ç•Œã€‚
5. æ„å»ºåŸºäº CaR çš„ **NCO Foundation Model**ï¼Œåˆ©ç”¨è·¨èŒƒå¼è¡¨ç¤ºå­¦ä¹ å®ç°é€šç”¨è·¯ç”±æ±‚è§£ã€‚

> ğŸ“Œ **ä»£ç ã€é¢„è®­ç»ƒæ¨¡å‹ä¸æ•°æ®é›†å·²å¼€æº**ï¼š[https://github.com/jieyibi/CaR-constraint](https://github.com/jieyibi/CaR-constraint)

</details>

---

### 15. [Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs](https://arxiv.org/abs/2602.16512)

**Authors**: Felix Fricke, Simon Malberg, Georg Groh  
**Category**: cs.AI  
**Published**: 2026-02-19  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.16512v1  

#### Abstract
Prompting schemes such as Chain of Thought, Tree of Thoughts, and Graph of Thoughts can significantly enhance the reasoning capabilities of large language models. However, most existing schemes require users to define static, problem-specific reasoning structures that lack adaptability to dynamic or...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFramework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜

ç°æœ‰çš„ **prompting schemes**ï¼ˆå¦‚ Chain of Thought, Tree of Thoughts, Graph of Thoughtsï¼‰å­˜åœ¨ä¸‰å¤§å…³é”®å±€é™æ€§ï¼š

1. **é™æ€å›¾ç»“æ„**ï¼šå¤§å¤šæ•°æ–¹æ¡ˆä¾èµ–äººå·¥å®šä¹‰çš„ã€å›ºå®šçš„æ¨ç†ç»“æ„ï¼Œæ— æ³•é€‚åº”åŠ¨æ€æˆ–æœªè§è¿‡çš„é—®é¢˜ç±»å‹ã€‚
2. **ä¼˜åŒ–ä¸è¶³**ï¼šæç¤ºï¼ˆpromptsï¼‰å’Œè¶…å‚æ•°ï¼ˆhyperparametersï¼‰é€šå¸¸æœªç»ç³»ç»Ÿä¼˜åŒ–ï¼Œé™åˆ¶äº†æ€§èƒ½æ½œåŠ›ã€‚
3. **æ‰§è¡Œæ•ˆç‡ä½**ï¼šå¤šæ•°æ–¹æ¡ˆä¸²è¡Œæ‰§è¡Œ LLM è°ƒç”¨ï¼Œé‡å¤è®¡ç®—å¤šï¼Œå¯¼è‡´é«˜å»¶è¿Ÿå’Œé«˜æˆæœ¬ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

ä½œè€…æå‡ºäº† **Framework of Thoughts (FoT)** â€”â€”ä¸€ä¸ªé€šç”¨çš„ã€åŸºç¡€æ€§çš„æ¡†æ¶ï¼Œç”¨äºæ„å»ºå’Œä¼˜åŒ–åŸºäºé“¾ã€æ ‘å’Œå›¾çš„åŠ¨æ€æ¨ç†æ–¹æ¡ˆã€‚

FoT ä¸æ˜¯ä¸€ä¸ªå…·ä½“çš„æ¨ç†æ–¹æ³•ï¼Œè€Œæ˜¯ä¸€ä¸ªæ”¯æŒå¤šç§ prompting schemes å®ç°å’Œè‡ªåŠ¨ä¼˜åŒ–çš„**å…ƒæ¡†æ¶**ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

FoT å…·å¤‡ä»¥ä¸‹å››å¤§æ ¸å¿ƒä¼˜åŠ¿ï¼š

- **(a) åŠ¨æ€å›¾ç»“æ„ï¼ˆDynamic graph structuresï¼‰**  
  æ”¯æŒåœ¨è¿è¡Œæ—¶è‡ªåŠ¨æ¼”åŒ–å›¾ç»“æ„ï¼Œå…è®¸æ¨ç†è·¯å¾„æ ¹æ®é—®é¢˜å®ä¾‹åŠ¨æ€è°ƒæ•´ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚

- **(b) å¹¶è¡ŒåŒ–æ‰§è¡Œï¼ˆFaster parallelized executionï¼‰**  
  é€šè¿‡æ™ºèƒ½è°ƒåº¦å™¨å®ç°å®‰å…¨çš„å¹¶è¡Œæ“ä½œæ‰§è¡Œï¼Œæ˜¾è‘—å‡å°‘ç­‰å¾…æ—¶é—´ã€‚

- **(c) æŒä¹…ç¼“å­˜æœºåˆ¶ï¼ˆCost savings through persistent cachingï¼‰**  
  ç¼“å­˜æ“ä½œç»“æœï¼ˆè¿›ç¨‹çº§å’ŒæŒä¹…çº§ï¼‰ï¼Œé¿å…é‡å¤è°ƒç”¨ LLMï¼Œå¤§å¹…é™ä½æˆæœ¬ã€‚

- **(d) å†…å»ºä¼˜åŒ–å·¥å…·ï¼ˆOptimized hyperparameters and promptsï¼‰**  
  é›†æˆ **Optuna** è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–ï¼Œä»¥åŠ **DSPy/COPRO** è¿›è¡Œæç¤ºè¯ä¼˜åŒ–ï¼Œå¸®åŠ©å¼€å‘è€…æŒ–æ˜æ–¹æ¡ˆçš„æœ€å¤§æ½œåŠ›ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†

å®éªŒè¦†ç›–äº”ä¸ªä»»åŠ¡ï¼Œåˆ†åˆ«æ¥è‡ªä¸‰ä¸ªç»å…¸ prompting schemes çš„åŸå§‹ç ”ç©¶ï¼š

| ä»»åŠ¡ | æ•°æ®é›† | æ¥æº |
|------|--------|------|
| æ•°å­¦æ¨ç† | Game of 24 (**Go24**) | Yao et al. (2023) |
| æ’åºä»»åŠ¡ | Sorting (128ä¸ªæ•´æ•°æ’åº) | Besta et al. (2024a) |
| æ–‡æ¡£åˆå¹¶ | Document Merging (**DM**) | Besta et al. (2024a) |
| å¤šè·³é—®ç­” | **HotpotQA** | Yang et al. (2018) |
| å¤šè·³é—®ç­” | **MuSiQue** | Trivedi et al. (2022) |

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### å®éªŒè®¾ç½®ï¼š
- å°†ä¸‰ç§ä¸»æµæ–¹æ¡ˆï¼ˆ**ToT**, **GoT**, **ProbTree**ï¼‰é‡æ–°å®ç°åœ¨ FoT æ¡†æ¶ä¸­ã€‚
- å¯¹æ¯”ä¸åŒé…ç½®ä¸‹çš„æ€§èƒ½ï¼š
  - æ˜¯å¦å¯ç”¨ **å¹¶è¡Œæ‰§è¡Œ**ï¼ˆParallel vs Sequentialï¼‰
  - æ˜¯å¦å¯ç”¨ **ç¼“å­˜**ï¼ˆNo cache / Process cache / Persistent cacheï¼‰
  - æ˜¯å¦è¿›è¡Œ **è¶…å‚æ•°ä¸æç¤ºä¼˜åŒ–**

#### è¯„ä¼°æŒ‡æ ‡ï¼š
| ä»»åŠ¡ | ä¸»è¦æŒ‡æ ‡ |
|------|---------|
| Go24 | å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ |
| Sorting | é”™è¯¯æ•°é‡ï¼ˆMistakesï¼Œè¶Šå°‘è¶Šå¥½ï¼‰ |
| DM | F1 åˆ†æ•°ï¼ˆåŸºäºå†—ä½™ä¸ä¿ç•™ä¿¡æ¯ï¼‰ |
| HotpotQA / MuSiQue | F1 åˆ†æ•° |
| æ‰€æœ‰ä»»åŠ¡ | å•å®ä¾‹å¹³å‡è¿è¡Œæ—¶é—´ï¼ˆç§’ï¼‰ã€æˆæœ¬ï¼ˆUSD centsï¼‰ |

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- åŸå§‹æ–¹æ¡ˆä½œä¸ºåŸºå‡†ï¼ˆå¦‚ Yao et al. çš„ ToTã€Besta et al. çš„ GoTï¼‰
- åœ¨ç›¸åŒæ¨¡å‹ä¸‹å¤ç°å®éªŒï¼ˆå¦‚ GPT-4o æ›¿ä»£ GPT-4ï¼ŒGPT-3.5-Turbo ç”¨äºæ’åºç­‰ï¼‰
- å¯¹æ¯”ä¸åŒé…ç½®ç»„åˆï¼ˆS/P + ç¼“å­˜ç­–ç•¥ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### è¡¨æ ¼ 3ï¼šå¹³å‡è¿è¡Œæ—¶é—´å’Œæˆæœ¬ï¼ˆå…³é”®ç»“æœæ±‡æ€»ï¼‰

| æ–¹æ¡ˆ | è®¾ç½® | å¹³å‡è¿è¡Œæ—¶é—´ï¼ˆç§’ï¼‰ | åŠ é€Ÿæ¯” | æˆæœ¬ï¼ˆç¾åˆ†ï¼‰ |
|------|------|------------------|--------|-------------|
| ToT (Go24) | Sequential + No cache | 782 | 1.0x | 29.6 |
| â†’ | Parallel + Persistent cache | **22** | **35.4x** | **16.1** |
| GoT (Sorting) | Sequential + No cache | 259 | 1.0x | 5.0 |
| â†’ | Parallel + Persistent cache | **30** | **8.5x** | 5.0 |
| ProbTree (MuSiQue) | Sequential + No cache | 21.6 | 1.0x | 0.8 |
| â†’ | Parallel + Persistent cache | **8.9** | **2.4x** | **0.7** |

> âœ… **æ€»ä½“åŠ é€Ÿè¾¾ 10.7x**ï¼Œæœ€å¤§æé€Ÿ **35.4x**ï¼ˆToT on Go24ï¼‰ï¼Œæˆæœ¬é™ä½æœ€é«˜è¾¾ **46%**ã€‚

#### è¡¨æ ¼ 4ï¼šä¼˜åŒ–åä»»åŠ¡å¾—åˆ†æå‡

| æ–¹æ¡ˆ | ä»»åŠ¡ | åŸå§‹å¾—åˆ† | ä¼˜åŒ–åå¾—åˆ† | å˜åŒ– |
|------|------|----------|------------|------|
| ToT | Go24 (å‡†ç¡®ç‡) | 63.0% | **66.0%** | â†‘3.0% |
| ToT | Sorting (é”™è¯¯æ•°) | 18.4 | **18.2** | â†“0.2 |
| GoT | Sorting (é”™è¯¯æ•°) | 12.7 | **12.1** | â†“0.6 |
| GoT | DM (F1) | 8.4 | **8.8** | â†‘0.4 |

> âœ… æ‰€æœ‰æ–¹æ¡ˆåœ¨ä¼˜åŒ–åå‡å®ç°äº†**æ›´é«˜ä»»åŠ¡å¾—åˆ† + æ›´ä½æˆæœ¬**ã€‚

#### ä¼˜åŒ–è¿‡ç¨‹æ•ˆç‡æå‡ï¼ˆæ¶ˆèå®éªŒï¼‰

| è®¾ç½® | æ€»ä¼˜åŒ–è€—æ—¶ï¼ˆåˆ†é’Ÿï¼‰ | åŠ é€Ÿæ¯” |
|------|------------------|--------|
| Sequential + No cache | æœ€é«˜è¾¾ 39,596 min (~27.5å¤©) | 1.0x |
| Parallel + Persistent cache | **æœ€ä½ 788 min (~13å°æ—¶)** | **50.2x** |

> âš ï¸ æ— ç¼“å­˜æ—¶ä¼˜åŒ–æˆæœ¬æé«˜ï¼›**å¼•å…¥ç¼“å­˜ä½¿ä¼˜åŒ–æˆæœ¬é™è‡³åŸæ¥çš„ 9â€“36%**ï¼Œæˆä¸ºå¯è¡Œå·¥ç¨‹å®è·µã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. **åŠ¨æ€å›¾ç»“æ„æ˜¯æœªæ¥æ–¹å‘**  
   FoT æ”¯æŒè¿è¡Œæ—¶å›¾æ¼”åŒ–ï¼Œä¸ºåº”å¯¹æœªçŸ¥æˆ–å¤æ‚é—®é¢˜æä¾›äº†æ›´å¼ºçš„é€‚åº”æ€§ã€‚

2. **å¹¶è¡Œ + ç¼“å­˜ = æ•ˆç‡é©å‘½**  
   å¹¶è¡Œæ‰§è¡Œç»“åˆæ™ºèƒ½ç¼“å­˜å¯å°†æ¨ç†é€Ÿåº¦æå‡ä¸€ä¸ªæ•°é‡çº§ï¼ˆ10.7xï¼‰ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½æˆæœ¬ã€‚

3. **ä¼˜åŒ–å¿…é¡»ä¸é«˜æ•ˆæ‰§è¡Œå…±å­˜**  
   è¶…å‚æ•°å’Œæç¤ºä¼˜åŒ–æœ¬èº«å¼€é”€å·¨å¤§ï¼Œåªæœ‰åœ¨å…·å¤‡ç¼“å­˜å’Œå¹¶è¡Œèƒ½åŠ›çš„å‰æä¸‹æ‰å…·æœ‰å®é™…å¯è¡Œæ€§ã€‚

4. **FoT æ˜¯é€šç”¨å¢å¼ºå¹³å°**  
   å³ä½¿æ˜¯å¯¹å·²æœ‰æ–¹æ¡ˆï¼ˆå¦‚ ToTã€GoTï¼‰çš„â€œç§»æ¤â€ï¼Œä¹Ÿèƒ½é€šè¿‡ FoT çš„åŸºç¡€è®¾æ–½è·å¾—æ˜¾è‘—æ€§èƒ½å¢ç›Šã€‚

### æ–¹æ³•çš„å±€é™æ€§

- å½“å‰éªŒè¯é›†ä¸­åœ¨ **åŠè‡ªåŠ¨** å’Œ **æ‰‹åŠ¨** prompting schemesï¼ˆå¦‚ ToTã€GoTï¼‰ï¼Œå°šæœªå……åˆ†å±•ç¤º**å®Œå…¨è‡ªåŠ¨åŒ–åŠ¨æ€å›¾**çš„ä¼˜åŠ¿ã€‚
- å®éªŒæœªæ¶µç›–æ›´å¤šå¤æ‚å¤–éƒ¨å·¥å…·é›†æˆåœºæ™¯ï¼ˆå¦‚æ•°æ®åº“æŸ¥è¯¢ã€ä»£ç æ‰§è¡Œé—­ç¯ï¼‰ã€‚
- å›¾ä¿®æ”¹çš„å®‰å…¨çº¦æŸè¾ƒä¿å®ˆï¼Œå¯èƒ½é™åˆ¶æŸäº›é«˜åº¦å¹¶å‘çš„åŠ¨æ€è¡Œä¸ºã€‚

### æœªæ¥å·¥ä½œæ–¹å‘

- å¼€å‘æ–°çš„ **Fully Automatic** prompting schemesï¼Œå……åˆ†åˆ©ç”¨ FoT çš„åŠ¨æ€å›¾èƒ½åŠ›ã€‚
- æ”¯æŒæ›´çµæ´»çš„å›¾ä¿®æ”¹è§„åˆ™ï¼Œåœ¨ä¿è¯å®‰å…¨çš„åŒæ—¶æå‡å¹¶å‘åº¦ã€‚
- å®ç° **è”åˆä¼˜åŒ–**ï¼šåŒæ—¶ä¼˜åŒ– prompts å’Œ hyperparametersã€‚
- å¼•å…¥æ›´å¤š prompt optimization æŠ€æœ¯ï¼ˆå¦‚ GEPAï¼‰è¿›è¡Œå¤šç­–ç•¥æ¢ç´¢ã€‚
- æä¾›æ›´é«˜å±‚æ¬¡çš„æŠ½è±¡æ¥å£ï¼Œé™ä½ä½¿ç”¨é—¨æ§›ã€‚

---

> ğŸ”— **å¼€æºå£°æ˜**ï¼šä½œè€…å·²å…¬å¼€å®Œæ•´ä»£ç åº“ï¼ˆ[GitHub](https://github.com/fjfricke/framework-of-thoughts)ï¼‰ï¼Œæ”¯æŒå¤ç°ä¸æ‰©å±•ã€‚

> ğŸ›‘ **ä¼¦ç†æé†’**ï¼šLLM-based prompting schemes å¯èƒ½ç”Ÿæˆçœ‹ä¼¼åˆç†ä½†é”™è¯¯çš„ç­”æ¡ˆï¼Œé«˜é£é™©åœºæ™¯éœ€äººå·¥æ ¡éªŒè¾“å‡ºã€‚

</details>

---

### 16. [Gated Tree Cross-attention for Checkpoint-Compatible Syntax Injection in Decoder-Only LLMs](https://arxiv.org/abs/2602.15846)

**Authors**: Xinyu Gao, Shaonan Wang, Nai Ding  
**Category**: cs.CL  
**Published**: 2026-02-19  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.15846v1  

#### Abstract
Decoder-only large language models achieve strong broad performance but are brittle to minor grammatical perturbations, undermining reliability for downstream reasoning. However, directly injecting explicit syntactic structure into an existing checkpoint can interfere with its pretrained competence....

---

### 17. [CLAA: Cross-Layer Attention Aggregation for Accelerating LLM Prefill](https://arxiv.org/abs/2602.16054)

**Authors**: Bradley McDanel, Steven Li, Harshit Khaitan  
**Category**: cs.CL  
**Published**: 2026-02-19  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.16054v1  

#### Abstract
The prefill stage in long-context LLM inference remains a computational bottleneck. Recent token-ranking heuristics accelerate inference by selectively processing a subset of semantically relevant tokens. However, existing methods suffer from unstable token importance estimation, often varying betwe...

---

### 18. [Reinforced Fast Weights with Next-Sequence Prediction](https://arxiv.org/abs/2602.16704)

**Authors**: Hee Seung Hwang, Xindi Wu, Sanghyuk Chun, Olga Russakovsky  
**Category**: cs.CL  
**Published**: 2026-02-19  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.16704v1  

#### Abstract
Fast weight architectures offer a promising alternative to attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP optimizes single-token...

---

### 19. [EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments](https://arxiv.org/abs/2602.16179)

**Authors**: Sushant Mehta, Logan Ritchie, Suhaas Garre, Nick Heiner, Edwin Chen  
**Category**: cs.AI  
**Published**: 2026-02-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.16179v1  

#### Abstract
We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce \corecraft{}, the first environment in \textsc{EnterpriseGym}, Surge AI's suite of agentic RL environments. \corecraft{} is a full...

---

### 20. [Multi-source Heterogeneous Public Opinion Analysis via Collaborative Reasoning and Adaptive Fusion: A Systematically Integrated Approach](https://arxiv.org/abs/2602.15857)

**Authors**: Yi Liu  
**Category**: cs.CL  
**Published**: 2026-02-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.15857v1  

#### Abstract
The analysis of public opinion from multiple heterogeneous sources presents significant challenges due to structural differences, semantic variations, and platform-specific biases. This paper introduces a novel Collaborative Reasoning and Adaptive Fusion (CRAF) framework that systematically integrat...

---

### 21. [Towards Fair and Efficient De-identification: Quantifying the Efficiency and Generalizability of De-identification Approaches](https://arxiv.org/abs/2602.15869)

**Authors**: Noopur Zambare, Kiana Aghakasiri, Carissa Lin, Carrie Ye, J. Ross Mitchell, Mohamed Abdalla  
**Category**: cs.CL  
**Published**: 2026-02-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.15869v1  

#### Abstract
Large language models (LLMs) have shown strong performance on clinical de-identification, the task of identifying sensitive identifiers to protect privacy. However, previous work has not examined their generalizability between formats, cultures, and genders. In this work, we systematically evaluate ...

---

### 22. [VDLM: Variable Diffusion LMs via Robust Latent-to-Text Rendering](https://arxiv.org/abs/2602.15870)

**Authors**: Shuhui Qu  
**Category**: cs.CL  
**Published**: 2026-02-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.15870v1  

#### Abstract
Autoregressive language models decode left-to-right with irreversible commitments, limiting revision during multi-step reasoning. We propose \textbf{VDLM}, a modular variable diffusion language model that separates semantic planning from text rendering. VDLM applies LLaDA-style masked diffusion over...

---

### 23. [P-RAG: Prompt-Enhanced Parametric RAG with LoRA and Selective CoT for Biomedical and Multi-Hop QA](https://arxiv.org/abs/2602.15874)

**Authors**: Xingda Lyu, Gongfu Lyu, Zitai Yan, Yuxin Jiang  
**Category**: cs.CL  
**Published**: 2026-02-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.15874v1  

#### Abstract
Large Language Models (LLMs) demonstrate remarkable capabilities but remain limited by their reliance on static training data. Retrieval-Augmented Generation (RAG) addresses this constraint by retrieving external knowledge during inference, though it still depends heavily on knowledge base quality. ...

---

### 24. [Quecto-V1: Empirical Analysis of 8-bit Quantized Small Language Models for On-Device Legal Retrieval](https://arxiv.org/abs/2602.16640)

**Authors**: Subrit Dikshit  
**Category**: cs.CL  
**Published**: 2026-02-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.16640v1  

#### Abstract
The rapid proliferation of Large Language Models (LLMs) has revolutionized Natural Language Processing (NLP) but has simultaneously created a "resource divide." State-of-the-art legal intelligence systems typically rely on massive parameter counts (7B+) and cloud-based inference, rendering them inac...

---

### 25. [Distributed Order Recording Techniques for Efficient Record-and-Replay of Multi-threaded Programs](https://arxiv.org/abs/2602.15995)

**Authors**: Xiang Fu, Shiman Meng, Weiping Zhang, Luanzheng Guo, Kento Sato, Dong H. Ahn, Ignacio Laguna, Gregory L. Lee, Martin Schulz  
**Category**: cs.DC  
**Published**: 2026-02-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.15995v1  

#### Abstract
After all these years and all these other shared memory programming frameworks, OpenMP is still the most popular one. However, its greater levels of non-deterministic execution makes debugging and testing more challenging. The ability to record and deterministically replay the program execution is k...

---

### 26. [SEMixer: Semantics Enhanced MLP-Mixer for Multiscale Mixing and Long-term Time Series Forecasting](https://arxiv.org/abs/2602.16220)

**Authors**: Xu Zhang, Qitong Wang, Peng Wang, Wei Wang  
**Category**: cs.LG  
**Published**: 2026-02-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.16220v1  

#### Abstract
Modeling multiscale patterns is crucial for long-term time series forecasting (TSF). However, redundancy and noise in time series, together with semantic gaps between non-adjacent scales, make the efficient alignment and integration of multi-scale temporal dependencies challenging. To address this, ...

---

### 27. [A Scalable Approach to Solving Simulation-Based Network Security Games](https://arxiv.org/abs/2602.16564)

**Authors**: Michael Lanier, Yevgeniy Vorobeychik  
**Category**: cs.LG  
**Published**: 2026-02-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.16564v1  

#### Abstract
We introduce MetaDOAR, a lightweight meta-controller that augments the Double Oracle / PSRO paradigm with a learned, partition-aware filtering layer and Q-value caching to enable scalable multi-agent reinforcement learning on very large cyber-network environments. MetaDOAR learns a compact state pro...

---

### 28. [Knowledge-Embedded Latent Projection for Robust Representation Learning](https://arxiv.org/abs/2602.16709)

**Authors**: Weijing Tang, Ming Yuan, Zongqi Xia, Tianxi Cai  
**Category**: cs.LG  
**Published**: 2026-02-19  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.16709v1  

#### Abstract
Latent space models are widely used for analyzing high-dimensional discrete data matrices, such as patient-feature matrices in electronic health records (EHRs), by capturing complex dependence structures through low-dimensional embeddings. However, estimation becomes challenging in the imbalanced re...

---

### 29. [Multi-agent cooperation through in-context co-player inference](https://arxiv.org/abs/2602.16301)

**Authors**: Marissa A. Weis, Maciej Wo{\l}czyk, Rajai Nasser, Rif A. Saurous, Blaise Ag\"uera y Arcas, Jo\~ao Sacramento, Alexander Meulemans  
**Category**: cs.AI  
**Published**: 2026-02-19  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2602.16301v1  

#### Abstract
Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual cooperation can be induced between "learning-aware" agents that account for and shape the learning dynamics of their co-players. However, existing ...

---

### 30. [TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers](https://arxiv.org/abs/2602.16429)

**Authors**: Ido Levy, Eilam Shapira, Yinon Goldshtein, Avi Yaeli, Nir Mashkif, Segev Shlomov  
**Category**: cs.CL  
**Published**: 2026-02-19  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2602.16429v1  

#### Abstract
Agentic systems, AI architectures that autonomously execute multi-step workflows to achieve complex goals, are often built using repeated large language model (LLM) calls for closed-set decision tasks such as routing, shortlisting, gating, and verification. While convenient, this design makes deploy...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
