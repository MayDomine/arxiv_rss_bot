# arXiv Papers Bot ü§ñ

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## üìä Statistics

- **Last Updated**: 2025-09-26 12:51:27 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## üìö Recent Papers

### 1. [Data-Centric Elastic Pipeline Parallelism for Efficient Long-Context LLM Training](https://arxiv.org/abs/2509.21275)

**Authors**: Shiju Wang, Yujie Wang, Ao Sun, Fangcheng Fu, Zijian Zhu, Bin Cui, Xu Han, Kaisheng Ma  
**Category**: cs.AI  
**Published**: 2025-09-26  
**Score**: 12.5

arXiv:2509.21275v1 Announce Type: cross 
Abstract: Long context training is crucial for LLM's context extension. Existing schemes, such as sequence parallelism, incur substantial communication overhead. Pipeline parallelism (PP) reduces this cost, but its effectiveness hinges on partitioning granula...

---

### 2. [PLaMo 2 Technical Report](https://arxiv.org/abs/2509.04897)

**Authors**: Preferred Networks,  :, Kaizaburo Chubachi, Yasuhiro Fujita, Shinichi Hemmi, Yuta Hirokawa, Kentaro Imajo, Toshiki Kataoka, Goro Kobayashi, Kenichi Maehashi, Calvin Metzger, Hiroaki Mikami, Shogo Murai, Daisuke Nishino, Kento Nozawa, Toru Ogawa, Shintarou Okada, Daisuke Okanohara, Shunta Saito, Shotaro Sano, Shuji Suzuki, Kuniyuki Takahashi, Daisuke Tanaka, Avinash Ummadisingu, Hanqin Wang, Sixue Wang, Tianqi Xu  
**Category**: cs.AI  
**Published**: 2025-09-26  
**Score**: 10.0

arXiv:2509.04897v2 Announce Type: replace-cross 
Abstract: In this report, we introduce PLaMo 2, a series of Japanese-focused large language models featuring a hybrid Samba-based architecture that transitions to full attention via continual pre-training to support 32K token contexts. Training levera...

---

### 3. [Distributed Specialization: Rare-Token Neurons in Large Language Models](https://arxiv.org/abs/2509.21163)

**Authors**: Jing Liu, Haozheng Wang, Yueheng Li  
**Category**: cs.AI  
**Published**: 2025-09-26  
**Score**: 8.5

arXiv:2509.21163v1 Announce Type: new 
Abstract: Large language models (LLMs) struggle with representing and generating rare tokens despite their importance in specialized domains. We investigate whether LLMs develop internal specialization mechanisms through discrete modular architectures or distri...

---

### 4. [TyphoonMLA: A Mixed Naive-Absorb MLA Kernel For Shared Prefix](https://arxiv.org/abs/2509.21081)

**Authors**: Ahmet Caner Y\"uz\"ug\"uler, Ahmet \c{C}elik, Jiawei Zhuang, Lukas Cavigelli  
**Category**: cs.AI  
**Published**: 2025-09-26  
**Score**: 8.5

arXiv:2509.21081v1 Announce Type: cross 
Abstract: Multi-Head Latent Attention (MLA) is a recent attention mechanism adopted in state-of-the-art LLMs such as DeepSeek-v3 and Kimi K2. Thanks to its novel formulation, MLA allows two functionally equivalent but computationally distinct kernel implement...

---

### 5. [Semantic Edge-Cloud Communication for Real-Time Urban Traffic Surveillance with ViT and LLMs over Mobile Networks](https://arxiv.org/abs/2509.21259)

**Authors**: Murat Arda Onsu, Poonam Lohan, Burak Kantarci, Aisha Syed, Matthew Andrews, Sean Kennedy  
**Category**: cs.AI  
**Published**: 2025-09-26  
**Score**: 8.5

arXiv:2509.21259v1 Announce Type: cross 
Abstract: Real-time urban traffic surveillance is vital for Intelligent Transportation Systems (ITS) to ensure road safety, optimize traffic flow, track vehicle trajectories, and prevent collisions in smart cities. Deploying edge cameras across urban environm...

---

### 6. [Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning](https://arxiv.org/abs/2506.03136)

**Authors**: Yinjie Wang, Ling Yang, Ye Tian, Ke Shen, Mengdi Wang  
**Category**: cs.CL  
**Published**: 2025-09-26  
**Score**: 8.5

arXiv:2506.03136v2 Announce Type: replace 
Abstract: We propose CURE, a novel reinforcement learning framework with a dedicated reward design that co-evolves coding and unit test generation capabilities based on their interaction outcomes, without any ground-truth code as supervision. This approach ...

---

### 7. [From Text to Talk: Audio-Language Model Needs Non-Autoregressive Joint Training](https://arxiv.org/abs/2509.20072)

**Authors**: Tianqiao Liu, Xueyi Li, Hao Wang, Haoxuan Li, Zhichao Chen, Weiqi Luo, Zitao Liu  
**Category**: cs.CL  
**Published**: 2025-09-26  
**Score**: 8.5

arXiv:2509.20072v2 Announce Type: replace 
Abstract: Recent advances in large language models (LLMs) have attracted significant interest in extending their capabilities to multimodal scenarios, particularly for speech-to-speech conversational systems. However, existing multimodal models handling int...

---

### 8. [RollPacker: Mitigating Long-Tail Rollouts for Fast, Synchronous RL Post-Training](https://arxiv.org/abs/2509.21009)

**Authors**: Wei Gao, Yuheng Zhao, Dakai An, Tianyuan Wu, Lunxi Cao, Shaopan Xiong, Ju Huang, Weixun Wang, Siran Yang, Wenbo Su, Jiamang Wang, Lin Qu, Bo Zheng, Wei Wang  
**Category**: cs.DC  
**Published**: 2025-09-26  
**Score**: 8.5

arXiv:2509.21009v1 Announce Type: new 
Abstract: Reinforcement Learning (RL) is a pivotal post-training technique for enhancing the reasoning capabilities of Large Language Models (LLMs). However, synchronous RL post-training often suffers from significant GPU underutilization, referred to as bubble...

---

### 9. [Spiking Brain Compression: Exploring One-Shot Post-Training Pruning and Quantization for Spiking Neural Networks](https://arxiv.org/abs/2506.03996)

**Authors**: Lianfeng Shi, Ao Li, Benjamin Ward-Cherrier  
**Category**: cs.LG  
**Published**: 2025-09-26  
**Score**: 8.5

arXiv:2506.03996v2 Announce Type: replace 
Abstract: Spiking Neural Networks (SNNs) have emerged as a new generation of energy-efficient neural networks suitable for implementation on neuromorphic hardware. As neuromorphic hardware has limited memory and computing resources, weight pruning and quant...

---

### 10. [APRIL: Active Partial Rollouts in Reinforcement Learning to Tame Long-tail Generation](https://arxiv.org/abs/2509.18521)

**Authors**: Yuzhen Zhou, Jiajun Li, Yusheng Su, Gowtham Ramesh, Zilin Zhu, Xiang Long, Chenyang Zhao, Jin Pan, Xiaodong Yu, Ze Wang, Kangrui Du, Jialian Wu, Ximeng Sun, Jiang Liu, Qiaolin Yu, Hao Chen, Zicheng Liu, Emad Barsoum  
**Category**: cs.AI  
**Published**: 2025-09-26  
**Score**: 8.0

arXiv:2509.18521v2 Announce Type: replace-cross 
Abstract: Reinforcement learning (RL) has become a cornerstone in advancing large-scale pre-trained language models (LLMs). Successive generations, including GPT-o series, DeepSeek-R1, Kimi-K1.5, Grok 4, and GLM-4.5, have relied on large-scale RL trai...

---

### 11. [Distributed-memory Algorithms for Sparse Matrix Permutation, Extraction, and Assignment](https://arxiv.org/abs/2509.20776)

**Authors**: Elaheh Hassani, Md Taufique Hussain, Ariful Azad  
**Category**: cs.DC  
**Published**: 2025-09-26  
**Score**: 8.0

arXiv:2509.20776v1 Announce Type: new 
Abstract: We present scalable distributed-memory algorithms for sparse matrix permutation, extraction, and assignment. Our methods follow an Identify-Exchange-Build (IEB) strategy where each process identifies the local nonzeros to be sent, exchanges the requir...

---

### 12. [SuperOffload: Unleashing the Power of Large-Scale LLM Training on Superchips](https://arxiv.org/abs/2509.21271)

**Authors**: Xinyu Lian, Masahiro Tanaka, Olatunji Ruwase, Minjia Zhang  
**Category**: cs.DC  
**Published**: 2025-09-26  
**Score**: 8.0

arXiv:2509.21271v1 Announce Type: cross 
Abstract: The emergence of Superchips represents a significant advancement in next-generation AI hardware. These Superchips employ a tightly coupled heterogeneous architecture that integrates GPU and CPU on the same package, which offers unprecedented computa...

---

### 13. [Reconstruction-Based Adaptive Scheduling Using AI Inferences in Safety-Critical Systems](https://arxiv.org/abs/2509.20513)

**Authors**: Samer Alshaer, Ala Khalifeh, Roman Obermaisser  
**Category**: cs.AI  
**Published**: 2025-09-26  
**Score**: 7.5

arXiv:2509.20513v1 Announce Type: new 
Abstract: Adaptive scheduling is crucial for ensuring the reliability and safety of time-triggered systems (TTS) in dynamic operational environments. Scheduling frameworks face significant challenges, including message collisions, locked loops from incorrect pr...

---

### 14. [From Sorting Algorithms to Scalable Kernels: Bayesian Optimization in High-Dimensional Permutation Spaces](https://arxiv.org/abs/2507.13263)

**Authors**: Zikai Xie, Linjiang Chen  
**Category**: cs.AI  
**Published**: 2025-09-26  
**Score**: 7.5

arXiv:2507.13263v3 Announce Type: replace-cross 
Abstract: Bayesian Optimization (BO) is a powerful tool for black-box optimization, but its application to high-dimensional permutation spaces is severely limited by the challenge of defining scalable representations. The current state-of-the-art BO a...

---

### 15. [FastEagle: Cascaded Drafting for Accelerating Speculative Decoding](https://arxiv.org/abs/2509.20416)

**Authors**: Haiduo Huang, Jiangcheng Song, Wenzhe Zhao, Pengju Ren  
**Category**: cs.LG  
**Published**: 2025-09-26  
**Score**: 7.5

arXiv:2509.20416v1 Announce Type: new 
Abstract: Speculative decoding accelerates generation by drafting candidates and verifying them in parallel, yet state-of-the-art drafters (e.g., EAGLE) still require N sequential passes to propose N tokens. We present FastEagle, a non-autoregressive cascaded d...

---

### 16. [Aligning Inductive Bias for Data-Efficient Generalization in State Space Models](https://arxiv.org/abs/2509.20789)

**Authors**: Qiyu Chen, Guozhang Chen  
**Category**: cs.LG  
**Published**: 2025-09-26  
**Score**: 7.5

arXiv:2509.20789v1 Announce Type: new 
Abstract: The remarkable success of large-scale models is fundamentally tied to scaling laws, yet the finite nature of high-quality data presents a looming challenge. One of the next frontiers in modeling is data efficiency: the ability to learn more from less....

---

### 17. [Decoupled-Value Attention for Prior-Data Fitted Networks: GP Inference for Physical Equations](https://arxiv.org/abs/2509.20950)

**Authors**: Kaustubh Sharma, Simardeep Singh, Parikshit Pareek  
**Category**: cs.LG  
**Published**: 2025-09-26  
**Score**: 7.5

arXiv:2509.20950v1 Announce Type: new 
Abstract: Prior-data fitted networks (PFNs) are a promising alternative to time-consuming Gaussian Process (GP) inference for creating fast surrogates of physical systems. PFN reduces the computational burden of GP-training by replacing Bayesian inference in GP...

---

### 18. [RL Squeezes, SFT Expands: A Comparative Study of Reasoning LLMs](https://arxiv.org/abs/2509.21128)

**Authors**: Kohsei Matsutani, Shota Takashiro, Gouki Minegishi, Takeshi Kojima, Yusuke Iwasawa, Yutaka Matsuo  
**Category**: cs.AI  
**Published**: 2025-09-26  
**Score**: 7.0

arXiv:2509.21128v1 Announce Type: new 
Abstract: Large language models (LLMs) are typically trained by reinforcement learning (RL) with verifiable rewards (RLVR) and supervised fine-tuning (SFT) on reasoning traces to improve their reasoning abilities. However, how these methods shape reasoning capa...

---

### 19. [Dynamic Reasoning Chains through Depth-Specialized Mixture-of-Experts in Transformer Architectures](https://arxiv.org/abs/2509.20577)

**Authors**: Sampurna Roy, Ayan Sar, Anurag Kaushish, Kanav Gupta, Tanupriya Choudhury, Abhijit Kumar  
**Category**: cs.AI  
**Published**: 2025-09-26  
**Score**: 7.0

arXiv:2509.20577v1 Announce Type: cross 
Abstract: Contemporary transformer architectures apply identical processing depth to all inputs, creating inefficiencies and limiting reasoning quality. Simple factual queries are subjected to the same multilayered computation as complex logical problems, was...

---

### 20. [Trustworthy Semantic Communication for Vehicular Networks: Challenges and Solutions](https://arxiv.org/abs/2509.20830)

**Authors**: Yanghe Pan, Yuntao Wang, Shaolong Guo, Chengyu Yin, Ruidong Li, Zhou Su, Yuan Wu  
**Category**: cs.AI  
**Published**: 2025-09-26  
**Score**: 7.0

arXiv:2509.20830v1 Announce Type: cross 
Abstract: Semantic communication (SemCom) has the potential to significantly reduce communication delay in vehicle-to-everything (V2X) communications within vehicular networks (VNs). However, the deployment of vehicular SemCom networks (VN-SemComNets) faces c...

---

### 21. [A Preprocessing Framework for Efficient Approximate Bi-Objective Shortest-Path Computation in the Presence of Correlated Objectives](https://arxiv.org/abs/2505.22244)

**Authors**: Yaron Halle, Ariel Felner, Sven Koenig, Oren Salzman  
**Category**: cs.AI  
**Published**: 2025-09-26  
**Score**: 7.0

arXiv:2505.22244v2 Announce Type: replace 
Abstract: The bi-objective shortest-path (BOSP) problem seeks to find paths between start and target vertices of a graph while optimizing two conflicting objective functions. We consider the BOSP problem in the presence of correlated objectives. Such correl...

---

### 22. [Shift Happens: Mixture of Experts based Continual Adaptation in Federated Learning](https://arxiv.org/abs/2506.18789)

**Authors**: Rahul Atul Bhope, K. R. Jayaram, Praveen Venkateswaran, Nalini Venkatasubramanian  
**Category**: cs.AI  
**Published**: 2025-09-26  
**Score**: 7.0

arXiv:2506.18789v2 Announce Type: replace-cross 
Abstract: Federated Learning (FL) enables collaborative model training across decentralized clients without sharing raw data, yet faces significant challenges in real-world settings where client data distributions evolve dynamically over time. This pa...

---

### 23. [ILRe: Intermediate Layer Retrieval for Context Compression in Causal Language Models](https://arxiv.org/abs/2508.17892)

**Authors**: Manlai Liang, Mandi Liu, Jiangzhou Ji, Huaijun Li, Haobo Yang, Yaohan He, Jinlong Li  
**Category**: cs.CL  
**Published**: 2025-09-26  
**Score**: 7.0

arXiv:2508.17892v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated success across many benchmarks. However, they still exhibit limitations in long-context scenarios, primarily due to their short effective context length, quadratic computational complexity, and high m...

---

### 24. [EpiCache: Episodic KV Cache Management for Long Conversational Question Answering](https://arxiv.org/abs/2509.17396)

**Authors**: Minsoo Kim, Arnav Kundu, Han-Byul Kim, Richa Dixit, Minsik Cho  
**Category**: cs.CL  
**Published**: 2025-09-26  
**Score**: 7.0

arXiv:2509.17396v2 Announce Type: replace 
Abstract: Modern large language models (LLMs) extend context lengths to up to millions of tokens, enabling AI assistants to generate coherent and personalized responses grounded in long conversational histories. This ability, however, hinges on Key-Value (K...

---

### 25. [Shaping Initial State Prevents Modality Competition in Multi-modal Fusion: A Two-stage Scheduling Framework via Fast Partial Information Decomposition](https://arxiv.org/abs/2509.20840)

**Authors**: Jiaqi Tang, Yinsong Xu, Yang Liu, Qingchao Chen  
**Category**: cs.LG  
**Published**: 2025-09-26  
**Score**: 7.0

arXiv:2509.20840v1 Announce Type: new 
Abstract: Multi-modal fusion often suffers from modality competition during joint training, where one modality dominates the learning process, leaving others under-optimized. Overlooking the critical impact of the model's initial state, most existing methods ad...

---

### 26. [Toward Robust and Efficient ML-Based GPU Caching for Modern Inference](https://arxiv.org/abs/2509.20979)

**Authors**: Peng Chen, Jiaji Zhang, Hailiang Zhao, Yirong Zhang, Jiahong Yu, Xueyan Tang, Yixuan Wang, Hao Li, Jianping Zou, Gang Xiong, Kingsum Chow, Shuibing He, Shuiguang Deng  
**Category**: cs.LG  
**Published**: 2025-09-26  
**Score**: 7.0

arXiv:2509.20979v1 Announce Type: new 
Abstract: In modern GPU inference, cache efficiency remains a major bottleneck. In recommendation models, embedding hit rates largely determine throughput, while in large language models, KV-cache misses substantially increase time-to-first-token (TTFT). Heuris...

---

### 27. [Agreement-Based Cascading for Efficient Inference](https://arxiv.org/abs/2407.02348)

**Authors**: Steven Kolawole, Don Dennis, Ameet Talwalkar, Virginia Smith  
**Category**: cs.LG  
**Published**: 2025-09-26  
**Score**: 7.0

arXiv:2407.02348v4 Announce Type: replace 
Abstract: Adaptive inference schemes reduce the cost of machine learning inference by assigning smaller models to easier examples, attempting to avoid invocation of larger models when possible. In this work we explore a simple, effective adaptive inference ...

---

### 28. [MDPO: Overcoming the Training-Inference Divide of Masked Diffusion Language Models](https://arxiv.org/abs/2508.13148)

**Authors**: Haoyu He, Katrin Renz, Yong Cao, Andreas Geiger  
**Category**: cs.LG  
**Published**: 2025-09-26  
**Score**: 7.0

arXiv:2508.13148v2 Announce Type: replace 
Abstract: Diffusion language models, as a promising alternative to traditional autoregressive (AR) models, enable faster generation and richer conditioning on bidirectional context. However, they suffer from a key discrepancy between training and inference:...

---

### 29. [USB-Rec: An Effective Framework for Improving Conversational Recommendation Capability of Large Language Model](https://arxiv.org/abs/2509.20381)

**Authors**: Jianyu Wen, Jingyun Wang, Cilin Yan, Jiayin Cai, Xiaolong Jiang, Ying Zhang  
**Category**: cs.AI  
**Published**: 2025-09-26  
**Score**: 6.5

arXiv:2509.20381v1 Announce Type: cross 
Abstract: Recently, Large Language Models (LLMs) have been widely employed in Conversational Recommender Systems (CRSs). Unlike traditional language model approaches that focus on training, all existing LLMs-based approaches are mainly centered around how to ...

---

### 30. [Measuring LLM Sensitivity in Transformer-based Tabular Data Synthesis](https://arxiv.org/abs/2509.20768)

**Authors**: Maria F. Davila R, Azizjon Turaev, Wolfram Wingerath  
**Category**: cs.AI  
**Published**: 2025-09-26  
**Score**: 6.5

arXiv:2509.20768v1 Announce Type: cross 
Abstract: Synthetic tabular data is used for privacy-preserving data sharing and data-driven model development. Its effectiveness, however, depends heavily on the used Tabular Data Synthesis (TDS) tool. Recent studies have shown that Transformer-based models ...

---

## üîß Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## üìÖ Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## üöÄ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## üìù Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## üîç Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
