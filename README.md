# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-06 05:59:48 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [OrchestrRL: Dynamic Compute and Network Orchestration for Disaggregated RL](https://arxiv.org/abs/2601.01209)

**Authors**: Xin Tan, Yicheng Feng, Yu Zhou, Yimin Jiang, Yibo Zhu, Hong Xu  
**Category**: cs.DC  
**Published**: 2026-01-06  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2601.01209v1  

#### Abstract
Post-training with reinforcement learning (RL) has greatly enhanced the capabilities of large language models. Disaggregating the generation and training stages in RL into a parallel, asynchronous pipeline offers the potential for flexible scaling and improved throughput. However, it still faces two...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*OrchestrRL: Dynamic Compute and Network Orchestration for Disaggregated RL*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹**è§£è€¦å¼å¼ºåŒ–å­¦ä¹ ï¼ˆdisaggregated RLï¼‰ç³»ç»Ÿä¸­çš„ä¸¤ä¸ªæ ¸å¿ƒç“¶é¢ˆ**ï¼š

1. **ç”Ÿæˆé˜¶æ®µï¼ˆGenerationï¼‰æˆä¸ºç«¯åˆ°ç«¯æ€§èƒ½ç“¶é¢ˆ**ï¼š
   - ç”±äºè¾“å‡ºé•¿åº¦åˆ†å¸ƒé•¿å°¾ã€è¯·æ±‚å¤„ç†æ—¶é—´ä¸å‡è¡¡ï¼ˆstragglersï¼‰ã€KV-cache åˆ©ç”¨ç‡æ³¢åŠ¨ç­‰é—®é¢˜ï¼Œå¯¼è‡´ç”Ÿæˆæ­¥éª¤çš„ *makespan*ï¼ˆå®Œæˆæ‰€æœ‰æ ·æœ¬çš„æ—¶é—´ï¼‰æ˜¾è‘—å¢åŠ ã€‚
   - é™æ€å¹¶è¡Œç­–ç•¥æ— æ³•é€‚åº”è·¨æ­¥ï¼ˆacross stepsï¼‰å’Œæ­¥å†…ï¼ˆwithin stepï¼‰çš„å·¥ä½œè´Ÿè½½åŠ¨æ€å˜åŒ–ã€‚

2. **ç½‘ç»œæ¶æ„ä¸é€šä¿¡æ¨¡å¼ä¸åŒ¹é…**ï¼š
   - è§£è€¦å¼ RL åœ¨è®­ç»ƒï¼ˆTrainï¼‰ã€ç”Ÿæˆï¼ˆGenï¼‰å’Œæƒé‡åŒæ­¥ï¼ˆWeight Syncï¼‰é˜¶æ®µè¡¨ç°å‡ºé«˜åº¦å¼‚æ„ä¸”åŠ¨æ€çš„é€šä¿¡æ¨¡å¼ï¼ˆå¦‚é›†ä½“é€šä¿¡ã€åŒç«¯é€šä¿¡ã€çªå‘å¹¿æ’­ç­‰ï¼‰ã€‚
   - ä¼ ç»Ÿé™æ€ç½‘ç»œï¼ˆå¦‚ Fat-Treeï¼‰éš¾ä»¥é«˜æ•ˆæ”¯æŒè¿™äº›å¤šæ ·åŒ–çš„æµé‡ï¼Œå¯¼è‡´å¸¦å®½æµªè´¹æˆ–æ‹¥å¡ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

è®ºæ–‡æå‡º **OrchestrRL**ï¼Œä¸€ä¸ªé¢å‘è§£è€¦å¼ RL çš„**è®¡ç®—ä¸ç½‘ç»œååŒç¼–æ’æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### âœ… **OrchestrRL Compute Schedulerï¼ˆè®¡ç®—è°ƒåº¦å™¨ï¼‰**
- **Proactive Plannerï¼ˆä¸»åŠ¨è§„åˆ’å™¨ï¼‰**ï¼š
  - å‘¨æœŸæ€§è¿è¡Œï¼ŒåŸºäºåœ¨çº¿é¢„æµ‹çš„å“åº”é•¿åº¦åˆ†å¸ƒï¼ˆARIMA æ¨¡å‹ï¼‰å’Œå½“å‰è¯·æ±‚è¿›åº¦ï¼Œé€šè¿‡æ±‚è§£ **MILPï¼ˆMixed-Integer Linear Programï¼‰** æ¥é€‰æ‹©æœ€ä¼˜çš„å¹¶è¡Œç­–ç•¥ï¼ˆå¦‚ TPã€EPã€AFDï¼‰ã€‚
  - æ”¯æŒåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­åŠ¨æ€åˆ‡æ¢å¹¶è¡Œé…ç½®ï¼ˆdynamic parallelism switchingï¼‰ï¼Œä»¥åº”å¯¹å·¥ä½œè´Ÿè½½æ¼‚ç§»ã€‚
- **Reactive Balancerï¼ˆååº”å¼å¹³è¡¡å™¨ï¼‰**ï¼š
  - æŒç»­ç›‘æ§å„ç”ŸæˆèŠ‚ç‚¹çš„è´Ÿè½½ï¼Œå®šä¹‰äº†ä¸€ä¸ªç»¼åˆè€ƒè™‘é˜Ÿåˆ—æ·±åº¦ã€KV-cache ä½™é‡å’ŒæœåŠ¡é€Ÿç‡çš„ **LoadIndex** æŒ‡æ ‡ã€‚
  - é€šè¿‡è½»é‡çº§è¯·æ±‚è¿ç§»ï¼ˆrequest migrationï¼‰ç¼“è§£çŸ­æ—¶è´Ÿè½½ä¸å‡ï¼Œå‡å°‘ stragglersã€‚

#### âœ… **RFabricï¼ˆå¯é‡æ„æ··åˆå…‰-ç”µç½‘ç»œæ¶æ„ï¼‰**
- ä¸€ç§ä¸“ä¸ºè§£è€¦å¼ RL è®¾è®¡çš„ **åˆ†å±‚æ··åˆå…‰ç”µè·¯äº¤æ¢ï¼ˆOCSï¼‰+ ç”µå­åˆ†ç»„äº¤æ¢ï¼ˆEPSï¼‰ç½‘ç»œ**ã€‚
- æ”¯æŒ**æŒ‰éœ€æ‹“æ‰‘å®ä¾‹åŒ–ï¼ˆon-demand topology materializationï¼‰**ï¼Œæ ¹æ®ä¸åŒé˜¶æ®µéœ€æ±‚åŠ¨æ€é‡æ„ç½‘ç»œï¼š
  - **Training Phase**ï¼šæ„å»ºé«˜äºŒåˆ†å¸¦å®½çš„äº’è¿æ‹“æ‰‘ï¼Œæ”¯æŒ DP AllReduce ç­‰å¤§è§„æ¨¡é›†ä½“é€šä¿¡ã€‚
  - **Generation Phase**ï¼šéš”ç¦» PoD å†…éƒ¨é€šä¿¡ï¼Œä¼˜åŒ– TP/EP/AFD ç­‰å±€éƒ¨é€šä¿¡æ¨¡å¼ã€‚
  - **Weight Sync Phase**ï¼šæ„å»ºå¤šæ’­æ ‘ç»“æ„ï¼Œå®ç°è·¨é›†ç¾¤çš„é«˜æ•ˆå‚æ•°å¹¿æ’­ã€‚
- åˆ©ç”¨ä¸åŒé˜¶æ®µä¹‹é—´çš„é€šä¿¡ç©ºé—²çª—å£ï¼ˆreconfiguration slackï¼‰è¿›è¡Œæ— å¹²æ‰°é‡æ„ã€‚

#### âœ… **ç»Ÿä¸€æ§åˆ¶å¹³é¢**
- å°†è®¡ç®—è°ƒåº¦ä¸ç½‘ç»œåè°ƒè”åˆè®¾è®¡ï¼Œå½¢æˆé—­ç¯åé¦ˆç³»ç»Ÿï¼Œå®ç°â€œ**è®¡ç®—é©±åŠ¨ç½‘ç»œï¼Œç½‘ç»œåå“ºè®¡ç®—**â€çš„ååŒä¼˜åŒ–ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ç°æœ‰æ–¹æ³• | OrchestrRL |
|------|--------|-----------|
| **å¹¶è¡Œç­–ç•¥** | é™æ€é…ç½®ï¼ˆå¦‚å›ºå®š TP=8ï¼‰ | åŠ¨æ€åˆ‡æ¢ï¼Œè‡ªé€‚åº”è´Ÿè½½æ¼”åŒ– |
| **è´Ÿè½½å‡è¡¡** | æ— æˆ–ç²—ç²’åº¦ | è½»é‡çº§å®æ—¶è¿ç§» + å¤šç»´åº¦è´Ÿè½½æŒ‡æ ‡ |
| **ç½‘ç»œæ¶æ„** | å›ºå®šæ‹“æ‰‘ï¼ˆå¦‚ Fat-Treeï¼‰ | å¯é‡æ„æ··åˆå…‰-ç”µæ¶æ„ï¼ˆRFabricï¼‰ |
| **é€šä¿¡é€‚é…æ€§** | â€œä¸€åˆ€åˆ‡â€è®¾è®¡ | æŒ‰é˜¶æ®µå®šåˆ¶æ‹“æ‰‘ï¼ˆè®­ç»ƒ/ç”Ÿæˆ/åŒæ­¥ï¼‰ |
| **æˆæœ¬æ•ˆç‡** | æ˜‚è´µçš„å…¨é€šç½‘ç»œ | ä»…åœ¨éœ€è¦æ—¶æä¾›é«˜å¸¦å®½ï¼ŒèŠ‚çœå…‰å­¦èµ„æº |

> ğŸ“Œ **å…³é”®ä¼˜åŠ¿æ€»ç»“**ï¼šOrchestrRL æ˜¯é¦–ä¸ªå°†**åŠ¨æ€å¹¶è¡Œé‡é…ç½®**ä¸**é˜¶æ®µæ„ŸçŸ¥ç½‘ç»œé‡æ„**ç»“åˆç”¨äºç«¯åˆ°ç«¯ RL æµæ°´çº¿çš„ç³»ç»Ÿï¼Œå®ç°äº†è®¡ç®—ä¸ç½‘ç»œçš„ååŒèŠ‚å¥è°ƒæ§ï¼ˆorchestrate rhythmsï¼‰ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹**

- **æ•°æ®é›†**ï¼š
  - `openr1-math-220k`ï¼ˆç”¨äº Qwen-14Bï¼‰
  - `deepmath-103k`ï¼ˆç”¨äº Qwen-32Bï¼‰
- **æ¨¡å‹**ï¼š
  - Qwen-2.5 14B å’Œ 32B
- **RL ç®—æ³•**ï¼šGRPOï¼ˆä¸€ç§ç­–ç•¥æ¢¯åº¦ç®—æ³•ï¼‰

---

### **å®éªŒè®¾ç½®**

#### **ç‰©ç†æµ‹è¯•åºŠï¼ˆTestbedï¼‰**
- **ç¡¬ä»¶**ï¼š48 å°é…å¤‡ NVIDIA H800 GPU çš„æœåŠ¡å™¨
  - Train Clusterï¼š32 GPUs
  - Gen Clusterï¼š40 GPUsï¼ˆéƒ¨åˆ†å®éªŒä½¿ç”¨ 32 æˆ– 48ï¼‰
- **è½¯ä»¶æ ˆ**ï¼š
  - è®­ç»ƒæ¡†æ¶ï¼šMegatron-LM
  - æ¨ç†åç«¯ï¼švLLMï¼ˆæ”¯æŒ PagedAttentionï¼‰

#### **å¤§è§„æ¨¡ä»¿çœŸå¹³å°ï¼ˆRLSimï¼‰**
- å¼€å‘äº†é«˜ä¿çœŸæ¨¡æ‹Ÿå™¨ **RLSim**ï¼Œç”¨äºè¯„ä¼° RFabric åœ¨åƒçº§ GPU è§„æ¨¡ä¸‹çš„è¡¨ç°ã€‚
- æ”¯æŒå¤šç§ç½‘ç»œæ‹“æ‰‘å»ºæ¨¡ï¼ˆFat-Treeã€TopoOptã€RFabric ç­‰ï¼‰å’Œç»†ç²’åº¦é€šä¿¡æ¨¡æ‹Ÿã€‚

---

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | æè¿° |
|------|------|
| **End-to-End Throughput** | å•ä½æ—¶é—´å†…å®Œæˆçš„è®­ç»ƒæ­¥æ•°ï¼ˆsteps/secï¼‰ï¼Œä¸ºä¸»è¦æ€§èƒ½æŒ‡æ ‡ |
| **Per-Step Makespan** | æ¯ä¸ªç”Ÿæˆæ­¥éª¤çš„æ€»è€—æ—¶ï¼Œåæ˜ ç”Ÿæˆæ•ˆç‡ |
| **Cost-Efficiency** | æ€§èƒ½ä¸ç½‘ç»œå»ºè®¾æˆæœ¬çš„æ¯”å€¼ï¼ˆå¦‚ååé‡ / ç½‘ç»œå¼€é”€ï¼‰ |
| **Reconfiguration Overhead** | å¹¶è¡Œåˆ‡æ¢ä¸ç½‘ç»œé‡æ„å¸¦æ¥çš„å»¶è¿Ÿ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿ | æè¿° |
|------|------|
| **veRL-TO** | ä¼˜å…ˆæ•°æ®å¹¶è¡Œï¼ˆDPï¼‰ï¼Œæœ€å¤§åŒ–å¹¶å‘å®ä¾‹æ•° |
| **veRL-LO** | ä¼˜å…ˆå¼ é‡å¹¶è¡Œï¼ˆTP=8ï¼‰ï¼Œæœ€å°åŒ–å•å®ä¾‹å»¶è¿Ÿ |
| **Partial-Rollout (PR)** | å…è®¸å“åº”è·¨ä¸¤ä¸ªæ¨¡å‹ç‰ˆæœ¬ç»§ç»­ç”Ÿæˆï¼Œç¼“è§£é•¿å°¾é—®é¢˜ |
| **Fat-Tree (FT)** | éé˜»å¡ Fat-Tree ç½‘ç»œï¼ˆç†æƒ³åŸºå‡†ï¼‰ |
| **Fat-Tree-OS (FT-OS)** | 3:1 è¿‡è®¢é˜… Fat-Tree |
| **Rail-Optimized (RO)** | NVIDIA æ¨èçš„ä½å»¶è¿Ÿäº’è” |
| **TopoOpt [37]** | å½“å‰æœ€å…ˆè¿›çš„ OCS æ¶æ„ä¹‹ä¸€ï¼Œç”¨äºå¯¹æ¯”ç½‘ç»œæ€§èƒ½ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### ğŸ”¹ **ç«¯åˆ°ç«¯ååæå‡ï¼ˆTestbed å®æµ‹ï¼‰**

| æ¨¡å‹ | é…ç½® | æœ€å¤§ç”Ÿæˆé•¿åº¦ | ç›¸å¯¹ veRL-TO æå‡ |
|------|------|--------------|------------------|
| Qwen-14B | 32 GPUs | 15K tokens | **1.31Ã—** |
| Qwen-14B | 32 GPUs | 25K tokens | **1.40Ã—** |
| Qwen-32B | 48 GPUs | 15K tokens | **1.32Ã—** |
| Qwen-32B | 48 GPUs | 25K tokens | **1.34Ã—** |

> âœ… **æœ€é«˜è¾¾ 1.40Ã— ååæå‡**ï¼Œå°¤å…¶åœ¨é•¿åºåˆ—åœºæ™¯ä¸‹ä¼˜åŠ¿æ›´æ˜æ˜¾ã€‚

---

#### ğŸ”¹ **æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰**

| ç»„ä»¶ | Qwen-14B æå‡ | Qwen-32B æå‡ |
|------|---------------|----------------|
| Baselineï¼ˆveRL-TOï¼‰ | 1.00Ã— | 1.00Ã— |
| + Proactive Planning (PP) | 1.23Ã— | 1.19Ã— |
| + Reactive Balancing (RB) | **1.40Ã—** | **1.34Ã—** |

> ğŸ“Š ç»“æœè¡¨æ˜ï¼š
> - **ä¸»åŠ¨è§„åˆ’ï¼ˆPPï¼‰** è´¡çŒ®çº¦ 20%~23% æå‡ï¼›
> - **ååº”å¼å¹³è¡¡ï¼ˆRBï¼‰** åœ¨æ­¤åŸºç¡€ä¸Šå†å¸¦æ¥çº¦ 14%~15% æå‡ï¼›
> - ä¸¤è€…ååŒä½œç”¨æ˜¾è‘—ã€‚

---

#### ğŸ”¹ **å¤§è§„æ¨¡ç½‘ç»œä»¿çœŸç»“æœï¼ˆRLSimï¼‰**

| æŒ‡æ ‡ | RFabric è¡¨ç° |
|------|-------------|
| **ç›¸å¯¹éé˜»å¡ Fat-Tree æ€§èƒ½** | è¾¾åˆ° **~98%** |
| **ç›¸æ¯” Fat-Tree æˆæœ¬æ•ˆç‡** | æå‡ **2.2Ã—â€“3.1Ã—** |
| **ç›¸æ¯” Rail-Optimized æˆæœ¬æ•ˆç‡** | æå‡ **2.3Ã—â€“3.2Ã—** |
| **åœ¨ 2048 GPU è§„æ¨¡ä¸‹æ€§èƒ½ä¿æŒç¨³å®š** | âœ”ï¸ æ˜¾è‘—ä¼˜äº TopoOpt å’Œ FT-OS |

> ğŸ“ˆ å›¾ 14 æ˜¾ç¤º RFabric åœ¨æ€§èƒ½-æˆæœ¬å¸•ç´¯æ‰˜å‰æ²¿ä¸Šå…¨é¢é¢†å…ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **ç”Ÿæˆé˜¶æ®µæ˜¯è§£è€¦å¼ RL çš„ä¸»è¦ç“¶é¢ˆ**ï¼š
   - è¾“å‡ºé•¿åº¦çš„é•¿å°¾åˆ†å¸ƒå’Œ KV-cache ä¸å‡è¡¡å¯¼è‡´ä¸¥é‡çš„ straggler é—®é¢˜ã€‚
   - é™æ€å¹¶è¡Œç­–ç•¥æ— æ³•é€‚åº”åŠ¨æ€è´Ÿè½½ï¼Œå¿…é¡»å¼•å…¥**è¿è¡Œæ—¶é‡é…ç½®æœºåˆ¶**ã€‚

2. **ç½‘ç»œå¿…é¡»å…·å¤‡â€œèŠ‚å¥æ„ŸçŸ¥â€èƒ½åŠ›**ï¼š
   - RL å·¥ä½œæµå…·æœ‰æ˜æ˜¾çš„**æ—¶ç©ºå¼‚è´¨æ€§**ï¼ˆspatiotemporal variabilityï¼‰ã€‚
   - åˆ©ç”¨ä¸åŒé˜¶æ®µé—´çš„é€šä¿¡ç©ºé—²çª—å£ï¼ˆslackï¼‰è¿›è¡Œ OCS é‡æ„ï¼Œå¯åœ¨ä¸å½±å“å…³é”®è·¯å¾„çš„å‰æä¸‹å®ç°é«˜æ€§èƒ½é€šä¿¡ã€‚

3. **è®¡ç®—ä¸ç½‘ç»œéœ€ååŒè®¾è®¡**ï¼š
   - OrchestrRL è¯æ˜äº†â€œ**åŠ¨æ€å¹¶è¡Œåˆ‡æ¢ â†’ æ”¹å˜é€šä¿¡æ¨¡å¼ â†’ è§¦å‘ç½‘ç»œé‡æ„**â€è¿™ä¸€é—­ç¯çš„æœ‰æ•ˆæ€§ã€‚
   - å•ç‹¬ä¼˜åŒ–è®¡ç®—æˆ–ç½‘ç»œæ— æ³•è¾¾åˆ°å…¨å±€æœ€ä¼˜ã€‚

4. **RFabric å®ç°äº†é«˜æ€§èƒ½ä¸é«˜æ€§ä»·æ¯”çš„ç»Ÿä¸€**ï¼š
   - åœ¨æ¥è¿‘ç†æƒ³ Fat-Tree æ€§èƒ½çš„åŒæ—¶ï¼Œå¤§å¹…é™ä½ç½‘ç»œæˆæœ¬ï¼ˆå°¤å…¶æ˜¯å…‰å­¦æ”¶å‘å™¨æ•°é‡ï¼‰ã€‚
   - ç‰¹åˆ«é€‚åˆå¤§è§„æ¨¡ã€é«˜å¸¦å®½éœ€æ±‚çš„ RL åœºæ™¯ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **OCS é‡æ„å»¶è¿Ÿé™åˆ¶**ï¼š
   - å½“å‰ OCS æŠ€æœ¯ï¼ˆå¦‚ 3D MEMS, ~10msï¼‰ä¸é€‚åˆå¤„ç†å¾®ç§’çº§é€šä¿¡äº‹ä»¶ï¼Œå› æ­¤è¾¹ç¼˜ä»ä¾èµ– EPSã€‚
   - å¯¹æçŸ­å‘¨æœŸä»»åŠ¡çš„æ”¯æŒæœ‰é™ã€‚

2. **MILP æ±‚è§£å¤æ‚åº¦**ï¼š
   - è™½ç„¶é‡‡ç”¨å¯å‘å¼å‰ªæï¼ˆå¦‚è¯·æ±‚åˆ†æ¡¶ã€å€™é€‰é›†ç­›é€‰ï¼‰ï¼Œä½†åœ¨è¶…å¤§è§„æ¨¡é›†ç¾¤ä¸­ä»å¯èƒ½é¢ä¸´å®æ—¶æ€§æŒ‘æˆ˜ã€‚

3. **æœªå……åˆ†éªŒè¯ MoE å’Œ AFD åœºæ™¯**ï¼š
   - è®ºæ–‡æåˆ°æœªæ¥å°†æ‰©å±•è‡³ MoE æ¨¡å‹ï¼Œç›®å‰å®éªŒä¸»è¦åŸºäº Dense æ¨¡å‹ã€‚

4. **ä¾èµ–å‡†ç¡®çš„è´Ÿè½½é¢„æµ‹**ï¼š
   - ARIMA æ¨¡å‹å¯¹å“åº”é•¿åº¦åˆ†å¸ƒçš„é¢„æµ‹è¯¯å·®ä¼šå½±å“è§„åˆ’è´¨é‡ï¼Œæç«¯æƒ…å†µä¸‹å¯èƒ½å¯¼è‡´æ¬¡ä¼˜å†³ç­–ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ”¯æŒæ›´å¤šå¹¶è¡ŒèŒƒå¼**ï¼š
   - æ‰©å±•å¯¹ **Attention-FFN Disaggregation (AFD)** å’Œ **Mixture-of-Experts (MoE)** çš„å®Œæ•´æ”¯æŒã€‚

2. **é›†æˆæ›´å…ˆè¿›çš„é¢„æµ‹æ¨¡å‹**ï¼š
   - ä½¿ç”¨è½»é‡çº§ ML æ¨¡å‹æ›¿ä»£ ARIMAï¼Œæå‡å‰©ä½™å·¥ä½œé‡é¢„æµ‹ç²¾åº¦ã€‚

3. **æ¢ç´¢å…¨æ ˆååŒä¼˜åŒ–**ï¼š
   - å°† OrchestrRL ä¸ LLM Agent Workflowã€Speculative Decoding ç­‰æŠ€æœ¯ç»“åˆï¼Œè¿›ä¸€æ­¥æå‡ç«¯åˆ°ç«¯æ•ˆç‡ã€‚

4. **ç¡¬ä»¶ååŒè®¾è®¡**ï¼š
   - æ¢ç´¢æ›´ä½å»¶è¿Ÿã€æ›´é«˜å¯†åº¦çš„ OCS å™¨ä»¶ï¼ˆå¦‚ç¡…å…‰èŠ¯ç‰‡ï¼‰ä»¥æ”¯æŒæ›´ç»†ç²’åº¦é‡æ„ã€‚

5. **è·¨ä½œä¸šè°ƒåº¦ä¸èµ„æºå…±äº«**ï¼š
   - åœ¨å¤šç§Ÿæˆ·ç¯å¢ƒä¸‹å®ç°å¤šä¸ª RL ä»»åŠ¡é—´çš„èµ„æºåŠ¨æ€åˆ†é…ä¸å¹²æ‰°æ§åˆ¶ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **OrchestrRL é€šè¿‡â€œåŠ¨æ€è®¡ç®—è°ƒåº¦ + å¯é‡æ„å…‰-ç”µç½‘ç»œâ€çš„ååŒè®¾è®¡ï¼Œé¦–æ¬¡å®ç°äº†å¯¹è§£è€¦å¼ RL ä¸­è®¡ç®—ä¸ç½‘ç»œèŠ‚å¥çš„è”åˆè°ƒæ§ï¼Œåœ¨çœŸå®æµ‹è¯•åºŠä¸Šå®ç°äº†æœ€é«˜ 1.40Ã— çš„ååæå‡ï¼Œå¹¶åœ¨å¤§è§„æ¨¡ä»¿çœŸä¸­å±•ç°å‡ºå“è¶Šçš„æˆæœ¬æ•ˆç›Šï¼Œä¸ºä¸‹ä¸€ä»£å¤§è§„æ¨¡ RL ç³»ç»Ÿæä¾›äº†æ–°çš„æ¶æ„èŒƒå¼ã€‚**

</details>

---

### 2. [DiT-HC: Enabling Efficient Training of Visual Generation Model DiT on HPC-oriented CPU Cluster](https://arxiv.org/abs/2601.01500)

**Authors**: Jinxiao Zhang, Yunpu Xu, Xiyong Wu, Runmin Dong, Shenggan Cheng, Yi Zhao, Mengxuan Chen, Qinrui Zheng, Jianting Liu, Haohuan Fu  
**Category**: cs.DC  
**Published**: 2026-01-06  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.01500v1  

#### Abstract
Generative foundation models have become an important tool for data reconstruction and simulation in scientific computing, showing a tight integration with traditional numerical simulations. At the same time, with the development of new hardware features, such as matrix acceleration units and high-b...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDiT-HC: Enabling Efficient Training of Visual Generation Model DiT on HPC-oriented CPU Cluster

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ç”Ÿæˆå¼åŸºç¡€æ¨¡å‹ï¼ˆå¦‚Diffusion Modelsï¼‰åœ¨ç§‘å­¦è®¡ç®—ä¸­æ—¥ç›Šé‡è¦ï¼Œä½†å…¶è®­ç»ƒä¸»è¦ä¾èµ–GPU/TPUå¹³å°ã€‚è€Œ**HPCï¼ˆé«˜æ€§èƒ½è®¡ç®—ï¼‰ç³»ç»Ÿå¤šä»¥CPUé›†ç¾¤ä¸ºä¸»**ï¼Œä¼ ç»Ÿä¸Šç¼ºä¹å¯¹å¤§è§„æ¨¡ç”Ÿæˆæ¨¡å‹é«˜æ•ˆè®­ç»ƒçš„æ”¯æŒã€‚è¿™å¯¼è‡´AIä¸ç§‘å­¦æ¨¡æ‹Ÿéš¾ä»¥ç»Ÿä¸€éƒ¨ç½²åœ¨åŒä¸€HPCå¹³å°ä¸Šã€‚

æ­¤å¤–ï¼Œå°½ç®¡æ–°ä¸€ä»£HPC CPUå·²å¼•å…¥**Matrix Acceleration Units (MAUs)** å’Œ **On-Package Memory (OPM)** ç­‰AIåŠ é€Ÿç‰¹æ€§ï¼Œä½†ç”±äºæŒ‡ä»¤é›†ã€å†…å­˜å±‚çº§å¤æ‚ï¼Œç°æœ‰æ¡†æ¶ï¼ˆå¦‚PyTorchï¼‰æ— æ³•æœ‰æ•ˆåˆ©ç”¨è¿™äº›ç¡¬ä»¶ä¼˜åŠ¿ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
ä½œè€…æå‡º **DiT-HC** â€”â€”é¦–ä¸ªåœ¨é¢å‘HPCçš„CPUé›†ç¾¤ä¸Šé«˜æ•ˆè®­ç»ƒè§†è§‰ç”Ÿæˆæ¨¡å‹ **DiT (Diffusion Transformer)** çš„å¯æ‰©å±•è®­ç»ƒæ¡†æ¶ï¼ŒåŒ…å«ä¸‰å¤§æ ¸å¿ƒæŠ€æœ¯ï¼š

#### ï¼ˆ1ï¼‰é€šä¿¡è‡ªç”±å¼ é‡å¹¶è¡Œï¼ˆCFTPï¼‰
- **åˆ›æ–°æ€è·¯**ï¼šä¼ ç»ŸTensor Parallelismï¼ˆTPï¼‰éœ€è¦è·¨è¿›ç¨‹é€šä¿¡åŒæ­¥ä¸­é—´ç»“æœï¼Œå¸¦æ¥æ˜¾è‘—å¼€é”€ã€‚
- **æ–°æ–¹æ³•**ï¼šåˆ©ç”¨åŒä¸€Dieå†…CPU Clusterå…±äº«DDRæ§åˆ¶å™¨ä¸”è®¿é—®å»¶è¿Ÿä¸€è‡´çš„ç‰¹ç‚¹ï¼Œå°†TPæ“ä½œæ”¹ä¸º**é€šè¿‡å…±äº«å†…å­˜ç›´æ¥è¯»å†™**ï¼Œé¿å…MPIé€šä¿¡ã€‚
- **ä¼˜åŠ¿**ï¼š
  - æ¶ˆé™¤TPå†…éƒ¨é€šä¿¡å¼€é”€ï¼›
  - å‡å°‘MPIè¿›ç¨‹æ•°é‡ï¼ˆä»æ¯èŠ‚ç‚¹16ä¸ªé™è‡³4ä¸ªï¼‰ï¼›
  - æ”¯æŒçµæ´»å¼ é‡åˆ‡åˆ†ï¼Œé™ä½å†…å­˜å†—ä½™ã€‚

#### ï¼ˆ2ï¼‰è‡ªåŠ¨å†…å­˜æ„ŸçŸ¥æ•°æ®æµç®¡ç†æ¨¡å— AutoMem
- **èƒŒæ™¯æŒ‘æˆ˜**ï¼šLX2 CPUé‡‡ç”¨OPM+DDRæ··åˆå†…å­˜æ¶æ„ï¼ŒOPMå¸¦å®½é«˜ä½†å®¹é‡å°ï¼Œæ‰‹åŠ¨ç®¡ç†æ•°æ®è¿ç§»å¤æ‚ã€‚
- **æ–°æ–¹æ³•**ï¼šè®¾è®¡éä¾µå…¥å¼AutoMemæ¨¡å—ï¼Œåœ¨å‰å‘/åå‘ä¼ æ’­å‰åæ’å…¥hookï¼Œå®ç°ï¼š
  - è‡ªåŠ¨åˆ¤æ–­æ˜¯å¦éœ€åŠ è½½æƒé‡/æ¿€æ´»åˆ°OPMï¼›
  - é¢„å–ä¸‹ä¸€å±‚å‚æ•°ï¼›
  - ä½¿ç”¨SDMAå¼‚æ­¥æ¬è¿æ•°æ®ï¼›
  - åˆ©ç”¨å¤§é¡µå†…å­˜ï¼ˆHuge Pageï¼‰æå‡TLBå‘½ä¸­ç‡ã€‚
- **ä¼˜åŠ¿**ï¼š
  - å……åˆ†åˆ©ç”¨é«˜å¸¦å®½OPMï¼›
  - å®ç°è®¡ç®—ã€é€šä¿¡ã€å†…å­˜æ¬è¿é‡å ï¼›
  - æ— éœ€ä¿®æ”¹æ¨¡å‹ä»£ç å³å¯å¤ç”¨ä¼˜åŒ–ç­–ç•¥ã€‚

#### ï¼ˆ3ï¼‰ä¸“ä¸ºHPC CPUä¼˜åŒ–çš„æ“ä½œç¬¦åº“ HCOps
- **ç›®æ ‡**ï¼šå……åˆ†å‘æŒ¥LX2 CPUä¸­çš„VAUï¼ˆVector Acceleration Unitï¼‰å’ŒMAUï¼ˆMatrix Acceleration Unitï¼‰èƒ½åŠ›ã€‚
- **ä¼˜åŒ–å†…å®¹**ï¼š
  - **GEMM**ï¼šæå‡ºNUMA-awareçš„äºŒç»´åˆ†å—ç­–ç•¥ï¼Œå‡å°‘è¿œç¨‹NUMAè®¿é—®ï¼Œæé«˜L2ç¼“å­˜åˆ©ç”¨ç‡ï¼›
  - **AI Operators**ï¼šå¯¹GeLUã€SiLUã€Softmaxã€LayerNormç­‰è¿›è¡Œä½å±‚intrinsicsä¼˜åŒ–ï¼›
  - **AdamWèåˆç®—å­**ï¼šå‡å°‘å†…å­˜å†™å›æ¬¡æ•°ï¼Œæé€Ÿ12.5Ã—ã€‚
- **æˆæœ**ï¼šå‘å¸ƒå¼€æºæ‰©å±•åŒ…HCOpsï¼Œé›†æˆè‡³PyTorchç”Ÿæ€ã€‚

#### ï¼ˆ4ï¼‰å®šåˆ¶åŒ–å¼‚æ­¥MPIåç«¯
- **é—®é¢˜**ï¼šåŸç”ŸPyTorch DDPä½¿ç”¨OpenMPçº¿ç¨‹å¤„ç†é€šä¿¡ï¼Œä¸è®¡ç®—äº‰æŠ¢æ ¸å¿ƒèµ„æºã€‚
- **è§£å†³æ–¹æ¡ˆ**ï¼š
  - å®ç°è‡ªå®šä¹‰MPIåç«¯ï¼Œæ”¯æŒ`MPI_Iallreduce`ç­‰å¼‚æ­¥é›†åˆé€šä¿¡ï¼›
  - å°†é€šä¿¡ä»»åŠ¡ç»‘å®šåˆ°ä¸“ç”¨CPUæ ¸å¿ƒï¼Œå®ç°è®¡ç®—ä¸é€šä¿¡è§£è€¦ã€‚
- **æ•ˆæœ**ï¼šæ˜¾è‘—æå‡é€šä¿¡-è®¡ç®—é‡å æ•ˆç‡ï¼Œå‡å°‘ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒæ¶µç›–ä¸‰ä¸ªé¢†åŸŸï¼š
- **ImageNet**ï¼šé€šç”¨å›¾åƒç”ŸæˆåŸºå‡†ï¼›
- **Gaofen-2**ï¼šå›½äº§é«˜åˆ†äºŒå·å«æ˜Ÿé¥æ„Ÿæ•°æ®ï¼Œ4æ³¢æ®µï¼Œç©ºé—´åˆ†è¾¨ç‡ä¸º2m/pixelï¼›
- **Sentinel-2**ï¼šæ¬§æ´²å“¨å…µäºŒå·å«æ˜Ÿæ•°æ®ï¼Œ13æ³¢æ®µï¼Œ10m/pixelã€‚

ç”¨äºéªŒè¯æ¨¡å‹çš„è·¨åŸŸè¿ç§»èƒ½åŠ›å’Œç§‘å­¦åº”ç”¨æ½œåŠ›ã€‚

### æ¨¡å‹é…ç½®
æµ‹è¯•ä¸åŒè§„æ¨¡çš„DiTæ¨¡å‹ï¼š
- DiT-S/2, DiT-B/2, DiT-L/2, DiT-XL/2  
éµå¾ªåŸå§‹DiTè®¾å®šï¼Œä½¿ç”¨AdamWä¼˜åŒ–å™¨ï¼ˆå­¦ä¹ ç‡1e-4ï¼‰ã€‚

### ç¡¬ä»¶å¹³å°
åŸºäº **LS Pilot System**ï¼Œä¸€ä¸ª256èŠ‚ç‚¹çš„HPC CPUé›†ç¾¤ï¼š
- æ¯èŠ‚ç‚¹é…å¤‡ä¸¤é¢— **LX2 CPU**ï¼ˆ>256æ ¸ï¼‰ï¼›
- æ”¯æŒMAUï¼ˆ8Ã—8åŒç²¾åº¦çŸ©é˜µè¿ç®—ï¼‰ã€VAUã€OPMï¼ˆç‰‡ä¸Šé«˜å¸¦å®½å†…å­˜ï¼‰ï¼›
- èŠ‚ç‚¹é—´é€šè¿‡LXLinkäº’è”ï¼ˆåŒå‘48 GB/sï¼‰ã€‚

è½¯ä»¶æ ˆï¼š
- OS: OpenEuler 22.03
- Compiler: Clang 17.0.0
- MPI: OpenMPI
- åŸºçº¿ï¼šNativeBLAS + oneDNN 3.6.2 + PyTorch 2.5.1

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **FID (FrÃ©chet Inception Distance)** | è¡¡é‡ç”Ÿæˆå›¾åƒä¸çœŸå®å›¾åƒåˆ†å¸ƒä¹‹é—´çš„è·ç¦»ï¼Œè¶Šä½è¶Šå¥½ |
| **å•æ­¥è¿­ä»£æ—¶é—´ (Iteration Time)** | åæ˜ è®­ç»ƒååæ€§èƒ½ |
| **å³°å€¼å†…å­˜æ¶ˆè€— (Peak Memory Usage)** | è¯„ä¼°å†…å­˜æ•ˆç‡ |
| **å¼±æ‰©å±•æ•ˆç‡ (Weak Scaling Efficiency)** | å›ºå®šæ¯èŠ‚ç‚¹batch sizeï¼Œè¡¡é‡éšèŠ‚ç‚¹å¢åŠ çš„æ€§èƒ½æ‰©å±•æ€§ |
| **å¼ºæ‰©å±•æ•ˆç‡ (Strong Scaling Efficiency)** | å›ºå®šæ€»batch sizeï¼Œè¯„ä¼°åŠ é€Ÿæ¯” |

### åŸºçº¿å¯¹æ¯”æ–¹æ³•
- **DP (Data Parallelism)**ï¼šæ ‡å‡†æ•°æ®å¹¶è¡Œï¼Œæ¯ä¸ªè®¾å¤‡ä¿å­˜å®Œæ•´æ¨¡å‹å‰¯æœ¬ï¼›
- **TP/PP + DP**ï¼šä¼ ç»Ÿå¼ é‡/æµæ°´çº¿å¹¶è¡Œç»„åˆï¼›
- **NativeBLAS / oneDNN / OpenBLAS**ï¼šä¸»æµCPUæ•°å­¦åº“ä½œä¸ºæ€§èƒ½åŸºçº¿ï¼›
- **NVIDIA H100 GPU**ï¼šç”¨äºå‡†ç¡®æ€§éªŒè¯ä¸æ€§èƒ½å¯¹æ ‡ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **å•èŠ‚ç‚¹åŠ é€Ÿæ¯”ï¼ˆvs åŸç”Ÿæ ˆï¼‰** | æœ€é«˜ **8.2Ã—** åŠ é€Ÿï¼ˆDiT-S/2ï¼‰ |
| **vs OpenBLAS** | æœ€é«˜è¾¾ **87.7Ã—** åŠ é€Ÿ |
| **å¼±æ‰©å±•æ•ˆç‡ï¼ˆ256èŠ‚ç‚¹ï¼‰** | **90.6%**ï¼ˆDiT-XL/2ï¼‰ |
| **æŒç»­ç®—åŠ›ï¼ˆ256èŠ‚ç‚¹ï¼‰** | è¶…è¿‡ **1 PFLOPS (FP32)** |
| **æœ€å¤§å…¨å±€batch size** | è¾¾ **28,672**ï¼ˆè¿œè¶…GPUå•æœºæé™ï¼‰ |

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”

#### è¡¨1ï¼šä¸åŒå¹¶è¡Œç­–ç•¥ä¸‹çš„æ€§èƒ½ä¸å†…å­˜å¯¹æ¯”ï¼ˆéƒ¨åˆ†ï¼‰
| Batch Size | Model | Iteration Time (s) â€“ DP+TP | CFTP | Peak Memory (GB) â€“ DP | CFTP |
|------------|-------|----------------------------|--------|------------------------|--------|
| 112        | B/2   | 8.7                        | **3.97** | 247                    | **198** |
| 112        | XL/2  | OOM                        | **13.18** | OOM                    | **358** |

> âœ… CFTPåœ¨å¤§æ¨¡å‹ä¸‹é¿å…OOMï¼Œå¹¶å¤§å¹…ç¼©çŸ­è¿­ä»£æ—¶é—´ã€‚

#### è¡¨2ï¼šFIDç”Ÿæˆè´¨é‡å¯¹æ¯”ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
| Dataset     | GPU (bs=112) | LX2 (bs=112) | LX2 (bs=28,672) |
|-------------|--------------|---------------|------------------|
| Gaofen-2    | 30.44        | 28.51         | **24.70**         |
| Sentinel-2  | 24.97        | 29.03         | **22.61**         |

> âœ… åœ¨æå¤§batch sizeä¸‹ä»èƒ½ç»§ç»­æ”¶æ•›ï¼Œç”Ÿæˆè´¨é‡ä¼˜äºGPUã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆå›¾9ï¼‰

é€æ­¥æ·»åŠ ä¼˜åŒ–ç»„ä»¶åçš„æ€§èƒ½æå‡è·¯å¾„ï¼š
1. **Baseline (CFTP)** â†’ 1Ã—
2. **+ GEMMä¼˜åŒ–** â†’ 5.5Ã—
3. **+ å¼‚æ­¥é€šä¿¡åç«¯** â†’ 6.3Ã—
4. **+ AIç®—å­ä¼˜åŒ–** â†’ 6.6Ã—
5. **+ AutoMemé¢„å–** â†’ 6.7Ã—
6. **+ å¤šçº§è°ƒä¼˜ï¼ˆNUMAæ„ŸçŸ¥ã€ç¼“å†²ç­‰ï¼‰** â†’ **8.2Ã—**

è¡¨æ˜å„å±‚æ¬¡ä¼˜åŒ–å…·æœ‰å åŠ æ•ˆåº”ã€‚

### GEMMæ¨¡å—çº§åŠ é€Ÿï¼ˆè¡¨4ï¼‰
| Operator     | Speedup vs NativeBLAS |
|--------------|------------------------|
| `down_proj`  | **35.49Ã—**             |
| `qkv_proj`   | 30.10Ã—                 |
| `up_proj`    | 16.49Ã—                 |
| `o_proj`     | 13.89Ã—                 |

æ˜¾ç¤ºé’ˆå¯¹MAUå’Œå†…å­˜å±‚çº§çš„GEMMé‡æ„å¸¦æ¥å·¨å¤§æ”¶ç›Šã€‚

### ä¸GPUç³»ç»Ÿçš„å¯¹æ¯”ï¼ˆ5.6èŠ‚ï¼‰
- åœ¨ç›¸è¿‘ç³»ç»Ÿçº§ç®—åŠ›æ¡ä»¶ä¸‹ï¼š
  - H100åŒæœåŠ¡å™¨ï¼ˆ16å¡ï¼‰ï¼š**7.6ç§’/step**
  - LX2 256èŠ‚ç‚¹CPUé›†ç¾¤ï¼š**13.5ç§’/step**
- å°½ç®¡ç»å¯¹é€Ÿåº¦è½åäºGPUï¼Œä½†åœ¨**å¼±æ‰©å±•æ€§å’Œå†…å­˜å®¹é‡**æ–¹é¢å…·å¤‡ä¼˜åŠ¿ï¼Œå°¤å…¶é€‚åˆè¶…å¤§è§„æ¨¡batchè®­ç»ƒã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **CPUé›†ç¾¤å¯ä»¥é«˜æ•ˆè®­ç»ƒç°ä»£ç”Ÿæˆæ¨¡å‹**ï¼šé€šè¿‡è½¯ç¡¬ä»¶ååŒè®¾è®¡ï¼ŒDiT-HCè¯æ˜äº†åœ¨HPC CPUé›†ç¾¤ä¸Šè®­ç»ƒDiTç±»Transformerç”Ÿæˆæ¨¡å‹çš„å¯è¡Œæ€§ã€‚
2. **æ–°å‹ç¡¬ä»¶ç‰¹æ€§å¯è¢«æœ‰æ•ˆæŒ–æ˜**ï¼šMAUã€OPMã€SDMAç­‰ç‰¹æ€§è‹¥é…åˆä¸“ç”¨è°ƒåº¦ä¸ç®—å­ä¼˜åŒ–ï¼Œèƒ½æ˜¾è‘—æå‡è®­ç»ƒæ•ˆç‡ã€‚
3. **CFTP+AutoMemæ˜¯è§£å†³CPUå†…å­˜ç“¶é¢ˆçš„å…³é”®**ï¼šé€šè¿‡æ¶ˆé™¤é€šä¿¡ã€æ™ºèƒ½ç®¡ç†æ··åˆå†…å­˜ï¼Œå®ç°äº†æ¥è¿‘çº¿æ€§çš„å¼±æ‰©å±•æ•ˆç‡ï¼ˆ90.6% @ 256èŠ‚ç‚¹ï¼‰ã€‚
4. **å¤§batchè®­ç»ƒæ›´å…·ä¼˜åŠ¿**ï¼šCPUå¹³å°æ”¯æŒæå¤§batch sizeï¼ˆ>28kï¼‰ï¼Œæœ‰åŠ©äºæå‡ç”Ÿæˆè´¨é‡å’Œè®­ç»ƒç¨³å®šæ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ç»å¯¹æ€§èƒ½ä»ä½äºé«˜ç«¯GPU**ï¼šå—é™äºæ•´ä½“å†…å­˜å¸¦å®½å’Œäº’è¿é€Ÿç‡ï¼Œå•æ­¥æ‰§è¡Œæ—¶é—´ä»æ…¢äºH100ã€‚
- **å®šåˆ¶åŒ–ç¨‹åº¦è¾ƒé«˜**ï¼šç›®å‰ä¼˜åŒ–ç´§å¯†ä¾èµ–LX2æ¶æ„ç‰¹æ€§ï¼Œç§»æ¤åˆ°å…¶ä»–CPUå¹³å°éœ€é‡æ–°é€‚é…ã€‚
- **å°šæœªæ”¯æŒç¨€ç–è®¡ç®—æˆ–é‡åŒ–è®­ç»ƒ**ï¼šæœªæ¢ç´¢æ›´å‰æ²¿çš„å‹ç¼©æŠ€æœ¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤šç”Ÿæˆæ¨¡å‹ç±»åˆ«ï¼ˆå¦‚Video Diffusionã€LLMsï¼‰ï¼›
- æ¢ç´¢ä¸æ°”å€™æ¨¡æ‹Ÿã€åœ°çƒç³»ç»Ÿæ¨¡å‹çš„æ·±åº¦è€¦åˆï¼›
- æ„å»ºç»Ÿä¸€çš„HPC-AIå…±è®¾è®¡èŒƒå¼ï¼Œæ¨åŠ¨â€œä»¿çœŸ+AIâ€ä¸€ä½“åŒ–å·¥ä½œæµï¼›
- å¼€æºHCOpsä¸DiT-HCæ¡†æ¶ï¼Œä¿ƒè¿›ç¤¾åŒºå…±å»ºã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> DiT-HCé¦–æ¬¡å®ç°äº†åœ¨HPC CPUé›†ç¾¤ä¸Šé«˜æ•ˆå¯æ‰©å±•åœ°è®­ç»ƒDiTç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡CFTPã€AutoMemã€HCOpså’Œå¼‚æ­¥MPIå››å¤§æŠ€æœ¯åˆ›æ–°ï¼Œè¾¾æˆ8.2Ã—åŠ é€Ÿä¸90.6%å¼±æ‰©å±•æ•ˆç‡ï¼Œä¸ºAIä¸ç§‘å­¦è®¡ç®—çš„èåˆæä¾›äº†æ–°è·¯å¾„ã€‚

</details>

---

### 3. [Accelerating Decentralized Optimization via Overlapping Local Steps](https://arxiv.org/abs/2601.01493)

**Authors**: Yijie Zhou, Shi Pu  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.01493v1  

#### Abstract
Decentralized optimization has emerged as a critical paradigm for distributed learning, enabling scalable training while preserving data privacy through peer-to-peer collaboration. However, existing methods often suffer from communication bottlenecks due to frequent synchronization between nodes. We...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAccelerating Decentralized Optimization via Overlapping Local Steps

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

åœ¨åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ä¸­ï¼Œ**é€šä¿¡ç“¶é¢ˆ**æ˜¯åˆ¶çº¦è®­ç»ƒæ•ˆç‡çš„å…³é”®å› ç´ ã€‚ä¼ ç»Ÿçš„é›†ä¸­å¼æ–¹æ³•ä¾èµ–å‚æ•°æœåŠ¡å™¨è¿›è¡ŒåŒæ­¥ï¼Œå®¹æ˜“å½¢æˆå•ç‚¹æ•…éšœå’Œé€šä¿¡ç“¶é¢ˆï¼›è€Œå»ä¸­å¿ƒåŒ–ä¼˜åŒ–ï¼ˆDecentralized Optimization, DOï¼‰è™½é¿å…äº†ä¸­å¿ƒèŠ‚ç‚¹ï¼Œä½†ä»éœ€é¢‘ç¹çš„é‚»å±…é—´é€šä¿¡ï¼Œå¯¼è‡´å¤§é‡ç½‘ç»œç©ºé—²æ—¶é—´ã€‚

æ­¤å¤–ï¼Œå°½ç®¡å·²æœ‰æ–¹æ³•å¦‚ **Local DSGD (LDSGD)** é€šè¿‡å¢åŠ æœ¬åœ°æ›´æ–°æ­¥æ•°ï¼ˆlocal stepsï¼‰å‡å°‘é€šä¿¡é¢‘ç‡ï¼Œä½†è®¡ç®—ä¸é€šä¿¡è¿‡ç¨‹ä»æ˜¯ä¸²è¡Œæ‰§è¡Œï¼Œæ— æ³•æœ‰æ•ˆæ©ç›–é€šä¿¡å»¶è¿Ÿã€‚æ›´è¿›ä¸€æ­¥ï¼Œä¸€äº›å°è¯•é‡å é€šä¿¡ä¸è®¡ç®—çš„æ–¹æ³•ï¼ˆå¦‚ Overlap-Local-SGDï¼‰å› å¼•å…¥è¿‡æ—¶æ¢¯åº¦ï¼ˆstale gradientsï¼‰è€Œå¯¼è‡´æ”¶æ•›æ€§èƒ½ä¸‹é™ï¼Œå°¤å…¶åœ¨éå‡¸ç›®æ ‡ä¸‹è¡¨ç°ä¸ç¨³å®šã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º **Overlapping Local Decentralized SGD (OLDSGD)** çš„æ–°å‹å»ä¸­å¿ƒåŒ–è®­ç»ƒç®—æ³•ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **å°†é€šä¿¡ä¸è®¡ç®—å®Œå…¨é‡å ï¼ˆcomputation-communication overlappingï¼‰**ï¼Œä»è€Œæœ€å¤§é™åº¦åœ°å‡å°‘ç­‰å¾…æ—¶é—´ã€‚
- é‡‡ç”¨ **Combine-Then-Adapt (CTA)** æ›´æ–°æœºåˆ¶ï¼Œåœ¨é€šä¿¡è¿‡ç¨‹ä¸­ä½¿ç”¨**è¿‡æ—¶æ¨¡å‹ï¼ˆstale modelsï¼‰** è¿›è¡Œæ··åˆï¼ˆmixingï¼‰ï¼ŒåŒæ—¶ä¿ç•™æœ€æ–°çš„æœ¬åœ°æ¢¯åº¦è¿›è¡Œæ›´æ–°ã€‚
- è®¾è®¡æ›´æ–°è§„åˆ™ä½¿å¾—æ‰€æœ‰èŠ‚ç‚¹çš„**å¹³å‡æ¨¡å‹æ›´æ–°è·¯å¾„ç­‰ä»·äºæ ‡å‡† SGD**ï¼Œä»è€Œé¿å…å› æ¢¯åº¦é™ˆæ—§å¯¼è‡´çš„æ–¹å‘åå·®ã€‚

è¯¥æ–¹æ³•å®ç°äº†ä»¥ä¸‹æŠ€æœ¯çªç ´ï¼š
- é¦–ä¸ªå°† **æœ¬åœ°æ›´æ–°ï¼ˆlocal stepsï¼‰** ä¸ **é€šä¿¡-è®¡ç®—é‡å ** ç»“åˆçš„å»ä¸­å¿ƒåŒ–ç®—æ³•ï¼›
- åœ¨ä¸ç‰ºç‰²ç†è®ºæ”¶æ•›æ€§çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡æ¯è½®è¿­ä»£çš„å®é™…è¿è¡Œé€Ÿåº¦ï¼ˆwall-clock timeï¼‰ï¼›
- ä¸éœ€è¦é¢å¤–çš„è¡¥å¿æœºåˆ¶ï¼ˆå¦‚æ¢¯åº¦è£å‰ªã€è¯¯å·®æ ¡æ­£ç­‰ï¼‰æ¥ç¼“è§£é™ˆæ—§æ€§å¸¦æ¥çš„åå·®ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | OLDSGD çš„ä¼˜åŠ¿ |
|------|----------------|
| **é€šä¿¡æ•ˆç‡** | å®Œå…¨æ©ç›–é€šä¿¡å»¶è¿Ÿï¼ˆåªè¦é€šä¿¡ä¸è¶…è¿‡è®¡ç®—æ—¶é—´çš„ T å€ï¼‰ï¼Œå®ç°æ¥è¿‘é›¶ç­‰å¾… |
| **ç†è®ºä¿è¯** | æ”¶æ•›é€Ÿç‡ä¸ Local DSGD ç›¸åŒï¼ˆ$ \mathcal{O}(1/\sqrt{T}) $ï¼‰ï¼Œæ— é€€åŒ– |
| **å®ç°ç®€å•** | åªéœ€å¯¹ç°æœ‰æ¡†æ¶åšè½»å¾®ä¿®æ”¹å³å¯éƒ¨ç½²ï¼Œæ— éœ€å¤æ‚è°ƒåº¦æˆ–å†…å­˜æ‰©å±• |
| **é€‚ç”¨æ€§å¹¿** | æ”¯æŒä»»æ„ç½‘ç»œæ‹“æ‰‘ç»“æ„ï¼ˆring, mesh ç­‰ï¼‰ï¼Œé€‚ç”¨äºè¾¹ç¼˜è®¡ç®—ã€è”é‚¦å­¦ä¹ ç­‰åœºæ™¯ |
| **å®é™…åŠ é€Ÿæ˜æ˜¾** | å®éªŒæ˜¾ç¤ºåœ¨é«˜é€šä¿¡å»¶è¿Ÿç¯å¢ƒä¸‹å¯è·å¾—é«˜è¾¾ **3.32Ã—** çš„ç«¯åˆ°ç«¯åŠ é€Ÿ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸ä»»åŠ¡**

| ä»»åŠ¡ | æ•°æ®é›† | æ¨¡å‹ | èŠ‚ç‚¹æ•° |
|------|--------|-------|--------|
| å›¾åƒåˆ†ç±» | CIFAR-10 | VGG11, ResNet18 | 9 |
| è¯­è¨€æ¨¡å‹å¾®è°ƒ | WikiText-2 | GPT2-Small | 8 |

å®éªŒæ¶µç›–ï¼š
- **åŒæ„æ•°æ®åˆ†å¸ƒï¼ˆHomogeneousï¼‰**ï¼šæ•°æ®å‡åŒ€åˆ’åˆ†ï¼›
- **å¼‚æ„æ•°æ®åˆ†å¸ƒï¼ˆHeterogeneousï¼‰**ï¼šæŒ‰ç±»åˆ«åæ–œåˆ†é…ï¼ˆ70% ç±»ä¸“å± + 30% å‡åŒ€é‡‡æ ·ï¼‰ï¼›

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **æ‹“æ‰‘ç»“æ„**
- é»˜è®¤ä¸º **undirected ring topology**ï¼ˆç¯å½¢æ‹“æ‰‘ï¼‰ï¼Œæ¨¡æ‹ŸçœŸå®è¾¹ç¼˜è®¾å¤‡è¿æ¥ï¼›
- æ‰©å±•æµ‹è¯•äº†ä» 2 åˆ° 32 ä¸ª agent çš„å¯æ‰©å±•æ€§ã€‚

#### **é€šä¿¡å»ºæ¨¡**
- æ¯æ¬¡å…±è¯†æ“ä½œè€—æ—¶ `c` å•ä½æ—¶é—´ï¼›
- æ¯æ¬¡æœ¬åœ°æ¢¯åº¦è®¡ç®—è€—æ—¶ 1 å•ä½æ—¶é—´ï¼›
- æµ‹è¯•ä¸¤ç§å»¶è¿Ÿæ°´å¹³ï¼š`c = 1` å’Œ `c = 5`ï¼ˆåè€…ä»£è¡¨ä¸¥é‡é€šä¿¡ç“¶é¢ˆï¼‰ï¼›

#### **è¯„ä¼°æŒ‡æ ‡**
- **Wall-clock time æ”¶æ•›æ›²çº¿**ï¼šæŸå¤±å‡½æ•°éšæ¨¡æ‹Ÿæ—¶é—´çš„å˜åŒ–ï¼›
- **è¾¾åˆ°ç›®æ ‡ç²¾åº¦æ‰€éœ€çš„æ—¶é—´åŠ é€Ÿæ¯”ï¼ˆspeedupï¼‰**ï¼›
- **å¯æ‰©å±•æ€§åˆ†æ**ï¼šä¸åŒ agent æ•°é‡ä¸‹çš„æ”¶æ•›åŠ é€Ÿæƒ…å†µï¼›
- **è¿­ä»£çº§æ”¶æ•›æ€§**ï¼šéªŒè¯ç†è®ºé¢„æµ‹æ˜¯å¦æˆç«‹ã€‚

#### **è¶…å‚æ•°è®¾ç½®**
- å­¦ä¹ ç‡ç»Ÿä¸€è®¾ä¸º `Î± = 0.01`ï¼›
- å±€éƒ¨æ‰¹å¤§å°ï¼šVGG/ResNet ä½¿ç”¨ 8ï¼ŒGPT2 ä½¿ç”¨ 2ï¼›
- å¯¹ GPT2 ä½¿ç”¨æ¢¯åº¦è£å‰ªï¼ˆnorm â‰¤ 1ï¼‰ä»¥ç¨³å®šè®­ç»ƒï¼›
- æ¯ç§ç®—æ³•éå†å¤šä¸ª `T âˆˆ {1,3,5,...,40}` å¹¶é€‰æ‹©æœ€ä¼˜å€¼ç”¨äºæ¯”è¾ƒã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ–¹æ³• | ç®€ç§° | ç‰¹ç‚¹ |
|------|------|------|
| Local DSGD | LDSGD | ç»å…¸å»ä¸­å¿ƒåŒ–å±€éƒ¨æ›´æ–°æ–¹æ³• |
| KGT | KGT | åŸºäº Gradient Tracking çš„å±€éƒ¨ç‰ˆæœ¬ |
| LUGT | LUGT | å¦ä¸€ç§ Gradient Tracking æ‰©å±• |
| LED | LED | åŸºäº Exact Diffusion çš„å±€éƒ¨æ–¹æ³• |
| Local SGD + Ring AllReduce | LSGD | ä¸­å¿ƒåŒ–é£æ ¼çš„é«˜æ•ˆé€šä¿¡åè®®ä½œä¸ºå¼ºåŸºçº¿ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **è¡¨ 3ï¼šOLDSGD ç›¸å¯¹äºå…¶ä»–æ–¹æ³•çš„é€Ÿåº¦æå‡ï¼ˆå‡ ä½•å¹³å‡ï¼‰**

| æ–¹æ³• | VGG11 (c=1) | VGG11 (c=5) | ResNet18 (c=1) | ResNet18 (c=5) | GPT2 (c=1) | GPT2 (c=5) | **GeoMean** |
|------|-------------|-------------|----------------|----------------|------------|------------|--------------|
| LDSGD | 1.23Ã— | 1.26Ã— | 1.50Ã— | 1.62Ã— | 1.95Ã— | 2.65Ã— | **1.64Ã—** |
| KGT | 1.26Ã— | 1.30Ã— | 1.42Ã— | 1.73Ã— | 1.86Ã— | 2.54Ã— | **1.63Ã—** |
| LSGD | 1.34Ã— | 1.64Ã— | 1.84Ã— | 2.18Ã— | 2.08Ã— | 3.32Ã— | **1.98Ã—** |
| LUGT | 2.68Ã— | 3.53Ã— | 1.98Ã— | 4.62Ã— | â€” | â€” | **3.05Ã—** |

> æ³¨ï¼šé€Ÿåº¦æå‡å®šä¹‰ä¸ºâ€œåŸºçº¿æ‰€éœ€æ—¶é—´ / OLDSGD æ‰€éœ€æ—¶é—´â€ï¼Œè¶Šé«˜è¶Šå¥½ã€‚

#### ğŸ” è§‚å¯Ÿè¦ç‚¹ï¼š
- åœ¨é€šä¿¡å»¶è¿Ÿå¤§ï¼ˆ`c=5`ï¼‰æ—¶ï¼ŒOLDSGD åŠ é€Ÿæ•ˆæœæ›´æ˜¾è‘—ï¼›
- åœ¨ GPT2 å¾®è°ƒä»»åŠ¡ä¸Šï¼ŒOLDSGD è¾¾åˆ° **3.32Ã—** åŠ é€Ÿï¼Œè¿œè¶… LSGDï¼›
- å³ä½¿é¢å¯¹å¼ºåŸºçº¿ LSGDï¼ˆring-allreduceï¼‰ï¼ŒOLDSGD ä»ä¿æŒä¼˜åŠ¿ï¼Œè¯´æ˜å…¶åœ¨å»ä¸­å¿ƒåŒ–æ¶æ„ä¸­çš„ç«äº‰åŠ›ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **åœ¨æ‰€æœ‰ä»»åŠ¡å’Œè®¾ç½®ä¸‹ï¼ŒOLDSGD å‡ä¼˜äºæˆ–æŒå¹³äº LDSGD**ï¼Œä¸”éšç€ `T` å¢åŠ ä¼˜åŠ¿æ‰©å¤§ï¼›
- **Gradient Tracking ç±»æ–¹æ³•ï¼ˆKGT, LUGTï¼‰è¡¨ç°ä¸ä½³**ï¼š
  - KGT åœ¨å¼‚æ„æ•°æ®ä¸‹æ”¶æ•›å˜æ…¢ï¼›
  - LUGT åœ¨ `T > 1` æ—¶å¸¸å‘æ•£ï¼›
- **LED å‡ ä¹åœ¨æ‰€æœ‰é…ç½®ä¸­éƒ½å‘æ•£**ï¼Œå³ä½¿ä½¿ç”¨å° `T`ï¼›
- **OLDSGD çš„å¹³å‡æ¨¡å‹æ”¶æ•›è¡Œä¸ºä¸ LDSGD å‡ ä¹ä¸€è‡´**ï¼ŒéªŒè¯äº†å…¶ç†è®ºç­‰æ•ˆæ€§ï¼›
- **åœ¨ GPT2 ä¸Šï¼ŒOLDSGD æ˜¾è‘—é™ä½æµ‹è¯•å›°æƒ‘åº¦ï¼ˆperplexityï¼‰**ï¼Œè¡¨æ˜å…¶æ³›åŒ–èƒ½åŠ›æ›´å¼ºã€‚

---

### **æ¶ˆèå®éªŒä¸è¡¥å……åˆ†æï¼ˆè§é™„å½• Dï¼‰**

- **è¿­ä»£çº§æ”¶æ•›éªŒè¯**ï¼šOLDSGD ä¸ LDSGD å…·æœ‰å‡ ä¹ç›¸åŒçš„æŸå¤±ä¸‹é™è½¨è¿¹ï¼Œæ”¯æŒç†è®ºåˆ†æï¼›
- **å¯æ‰©å±•æ€§æµ‹è¯•**ï¼ˆå›¾ 4ï¼‰ï¼š
  - åœ¨ VGG11 å’Œ ResNet18 ä¸Šï¼ŒOLDSGD å®ç°è¿‘ä¼¼çº¿æ€§åŠ é€Ÿï¼›
  - æœ€å¤šæ”¯æŒ 16 ä¸ªèŠ‚ç‚¹ä¿æŒé«˜æ•ˆï¼Œè¶…è¿‡åå—é™äº ring æ‹“æ‰‘çš„ä¿¡æ¯ä¼ æ’­é€Ÿåº¦ï¼›
- **å¼‚æ„æ•°æ®ä¸‹çš„æ€§èƒ½å¢å¼º**ï¼ˆè¡¨ 4ï¼‰ï¼š
  - åœ¨å¼‚æ„è®¾ç½®ä¸‹ï¼ŒOLDSGD å¯¹ LDSGD çš„å¹³å‡åŠ é€Ÿæ¯”è¾¾ **1.64Ã—**ï¼Œé«˜äºåŒæ„ä¸‹çš„ **1.39Ã—**ï¼›
  - è¡¨æ˜ OLDSGD æ›´é²æ£’äºæ•°æ®åˆ†å¸ƒå·®å¼‚ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **é€šä¿¡-è®¡ç®—é‡å å¯åœ¨å»ä¸­å¿ƒåŒ–è®­ç»ƒä¸­å®‰å…¨ä¸”é«˜æ•ˆåœ°å®ç°**ï¼ŒOLDSGD æ˜¯é¦–ä¸ªæˆåŠŸç»“åˆ local steps ä¸ overlapping çš„å»ä¸­å¿ƒåŒ–ç®—æ³•ï¼›
2. âœ… **CTA æ›´æ–°æœºåˆ¶å¤©ç„¶æ¶ˆé™¤å¹³å‡æ›´æ–°åå·®**ï¼Œæ— éœ€é¢å¤–ä¿®æ­£é¡¹å³å¯ä¿æŒ SGD-like åŠ¨æ€ï¼›
3. âœ… **ç†è®ºæ”¶æ•›é€Ÿç‡æœªé€€åŒ–**ï¼šåœ¨éå‡¸å…‰æ»‘ç›®æ ‡ä¸‹ï¼ŒOLDSGD ä¸ Local DSGD å…·æœ‰ç›¸åŒå¤æ‚åº¦ï¼›
4. âœ… **å®é™…è¿è¡Œæ—¶é—´å¤§å¹…ç¼©çŸ­**ï¼šåœ¨å…¸å‹é€šä¿¡å»¶è¿Ÿä¸‹ï¼ˆ`c=5`ï¼‰ï¼Œå¯å®ç° **2â€“3Ã— ä»¥ä¸Šç«¯åˆ°ç«¯åŠ é€Ÿ**ï¼›
5. âœ… **ç‰¹åˆ«é€‚åˆç°ä»£ Transformer æ¶æ„**ï¼šåœ¨ GPT2 å¾®è°ƒä¸­è¡¨ç°å“è¶Šï¼Œå‡¸æ˜¾å…¶åœ¨å¤§æ¨¡å‹è®­ç»ƒä¸­çš„æ½œåŠ›ï¼›
6. âœ… **å¯¹æ•°æ®å¼‚æ„æ€§å…·æœ‰æ›´å¼ºé²æ£’æ€§**ï¼Œæ›´é€‚åˆéšç§æ•æ„Ÿçš„çœŸå®åº”ç”¨åœºæ™¯ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- **ä¾èµ–åŒæ­¥å‡è®¾**ï¼šå½“å‰åˆ†æåŸºäºåŒæ­¥ç³»ç»Ÿï¼Œè‹¥å„èŠ‚ç‚¹è®¡ç®—/é€šä¿¡é€Ÿåº¦å·®å¼‚è¿‡å¤§ï¼Œå¯èƒ½ä»å­˜åœ¨é˜»å¡ï¼›
- **ä»…é€‚ç”¨äºå›ºå®šæ‹“æ‰‘**ï¼šåŠ¨æ€ç½‘ç»œæˆ–é¢‘ç¹æ–­è¿åœºæ™¯å°šæœªè€ƒè™‘ï¼›
- **æœªæ¢ç´¢å¼‚æ­¥ç‰ˆæœ¬**ï¼šè™½ç„¶è®¾è®¡ä¸Šå…è®¸é‡å ï¼Œä½†å®Œå…¨å¼‚æ­¥æ›´æ–°å¯èƒ½å¯¼è‡´ç¨³å®šæ€§é—®é¢˜ï¼›
- **Gradient Tracking ç±»æ–¹æ³•éš¾ä»¥ç›´æ¥é€‚é…**ï¼šå°è¯•æ„å»º OLGT å’Œ OLED å¯¼è‡´æ€§èƒ½ä¸¥é‡é€€åŒ–ï¼ˆè§é™„å½• Bï¼‰ï¼Œè¯´æ˜å¹¶éæ‰€æœ‰ç®—æ³•éƒ½èƒ½ç®€å•å åŠ  overlappingã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ‰©å±•è‡³å¼‚æ­¥å»ä¸­å¿ƒåŒ–è®­ç»ƒæ¡†æ¶**ï¼Œé€‚åº”æ›´çœŸå®çš„è¾¹ç¼˜ç¯å¢ƒï¼›
2. **ç ”ç©¶è‡ªé€‚åº” local steps è°ƒåº¦ç­–ç•¥**ï¼Œæ ¹æ®é€šä¿¡/è®¡ç®—è´Ÿè½½åŠ¨æ€è°ƒæ•´ `T`ï¼›
3. **æ¢ç´¢ä¸å…¶ä»–åŠ é€ŸæŠ€æœ¯çš„èåˆ**ï¼Œå¦‚é‡åŒ–é€šä¿¡ã€ç¨€ç–æ›´æ–°ç­‰ï¼›
4. **åº”ç”¨äºæ›´å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹å’Œæ¨èç³»ç»Ÿ**ï¼ŒéªŒè¯å·¥ä¸šçº§å®ç”¨æ€§ï¼›
5. **å¼€å‘ç¨³å®šçš„ overlapping ç‰ˆæœ¬ Gradient Tracking æˆ– Exact Diffusion**ï¼Œå…‹æœå½“å‰æ–¹æ³•çš„ä¸å…¼å®¹æ€§ã€‚

---

## æ€»ç»“

**OLDSGD** æ˜¯ä¸€ä¸ªç®€æ´ã€é«˜æ•ˆã€ç†è®ºå¥å…¨çš„å»ä¸­å¿ƒåŒ–è®­ç»ƒæ–°èŒƒå¼ã€‚å®ƒé€šè¿‡å·§å¦™åˆ©ç”¨ **CTA ç»“æ„** å’Œ **stale model mixing**ï¼Œé¦–æ¬¡å®ç°äº†çœŸæ­£çš„é€šä¿¡-è®¡ç®—é›¶ç­‰å¾…é‡å ï¼ŒåŒæ—¶ä¿æŒäº†ä¸ç»å…¸ Local DSGD ç›¸åŒçš„æ”¶æ•›æ€§è´¨ã€‚å®éªŒè¯æ˜å…¶åœ¨å¤šç§è§†è§‰ä¸è¯­è¨€ä»»åŠ¡ä¸­å‡èƒ½å¸¦æ¥æ˜¾è‘—çš„ **wall-clock time åŠ é€Ÿ**ï¼Œç‰¹åˆ«æ˜¯åœ¨é€šä¿¡å—é™çš„ç°å®ç¯å¢ƒä¸­è¡¨ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œæ˜¯ä¸€ä¸ªæå…·å®ç”¨ä»·å€¼çš„â€œå³æ’å³ç”¨â€è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 4. [Quantized SO(3)-Equivariant Graph Neural Networks for Efficient Molecular Property Prediction](https://arxiv.org/abs/2601.02213)

**Authors**: Haoyu Zhou, Ping Xue, Tianfan Fu, Hao Zhang  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.02213v1  

#### Abstract
Deploying 3D graph neural networks (GNNs) that are equivariant to 3D rotations (the group SO(3)) on edge devices is challenging due to their high computational cost. This paper addresses the problem by compressing and accelerating an SO(3)-equivariant GNN using low-bit quantization techniques. Speci...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Quantized SO(3)-Equivariant Graph Neural Networks for Efficient Molecular Property Prediction*

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
è¯¥è®ºæ–‡é’ˆå¯¹ **SO(3)-equivariant GNNs**ï¼ˆå¦‚ So3kratesã€NequIPï¼‰åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²å›°éš¾çš„é—®é¢˜ã€‚è¿™ç±»æ¨¡å‹è™½ç„¶åœ¨åˆ†å­æ€§è´¨é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç”±äºå…¶å¤æ‚çš„å¼ é‡è¿ç®—å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œè®¡ç®—å¼€é”€å¤§ã€å†…å­˜å ç”¨é«˜ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„è®¾å¤‡ï¼ˆå¦‚æ‰‹æœºã€èŠ¯ç‰‡å®éªŒå®¤ä¼ æ„Ÿå™¨ï¼‰ä¸Šå®æ—¶è¿è¡Œã€‚

æ­¤å¤–ï¼Œç›´æ¥å¯¹è¿™äº›å¯¹ç§°æ€§æ•æ„Ÿçš„æ¨¡å‹è¿›è¡Œä½æ¯”ç‰¹é‡åŒ–ï¼ˆlow-bit quantizationï¼‰ä¼šå¯¼è‡´ï¼š
- å‘é‡ç‰¹å¾çš„æ–¹å‘å’Œæ¨¡é•¿å¤±çœŸï¼›
- æ³¨æ„åŠ›æœºåˆ¶ä¸ç¨³å®šï¼›
- æ¨¡å‹å¤±å» SO(3) ç­‰å˜æ€§ï¼ˆequivarianceï¼‰ï¼Œä»è€Œç ´åç‰©ç†ä¸€è‡´æ€§å¹¶æ˜¾è‘—é™ä½ç²¾åº¦ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡ºäº†ä¸€å¥—ä¸“ä¸º SO(3)-equivariant GNNs è®¾è®¡çš„ **ç­‰å˜æ€§æ„ŸçŸ¥é‡åŒ–æ¡†æ¶**ï¼ŒåŒ…å«ä¸‰é¡¹æ ¸å¿ƒåˆ›æ–°ï¼š

#### ï¼ˆ1ï¼‰**Magnitude-Direction Decoupled Quantization (MDDQ)**  
å°†ç­‰å˜å‘é‡ç‰¹å¾åˆ†è§£ä¸º**æ¨¡é•¿ï¼ˆmagnitudeï¼‰** å’Œ **æ–¹å‘ï¼ˆdirectionï¼‰** ä¸¤ä¸ªéƒ¨åˆ†åˆ†åˆ«é‡åŒ–ï¼š
- æ¨¡é•¿ $ r = \| \mathbf{h} \| $ ä½¿ç”¨æ ‡å‡†æ ‡é‡é‡åŒ–å™¨ $ Q_r(\cdot) $ï¼›
- æ–¹å‘ $ \hat{\mathbf{h}} = \mathbf{h}/\|\mathbf{h}\| $ è¢«å½’ä¸€åŒ–åé€åˆ†é‡é‡åŒ–ï¼Œå¹¶é‡æ–°å½’ä¸€åŒ–ä»¥ä¿æŒå•ä½é•¿åº¦ï¼›
- æœ€ç»ˆé‡å»ºå‘é‡ï¼š  
  $$
  Q_{\text{vec}}(\mathbf{h}) = Q_r(r) \cdot \frac{Q_a(\hat{\mathbf{h}})}{\|Q_a(\hat{\mathbf{h}})\|}
  $$

> âœ… **ä¼˜åŠ¿**ï¼šä¿ç•™äº†æ—‹è½¬ä¸‹çš„å‡ ä½•æ–¹å‘ä¿¡æ¯ï¼Œé¿å…ä¼ ç»Ÿé€å…ƒç´ é‡åŒ–å¯¼è‡´çš„å°å‘é‡åç¼©æˆ–æ–¹å‘æ¼‚ç§»ã€‚

#### ï¼ˆ2ï¼‰**Branch-Separated Quantization-Aware Training (QAT)**  
ç”±äº equivariant GNN ä¸­å­˜åœ¨ä¸¤ç§ä¸åŒç±»å‹çš„åˆ†æ”¯ï¼š
- **Invariant branch**ï¼ˆ$ l=0 $ï¼Œæ ‡é‡ï¼‰ï¼šåˆ†å¸ƒå¯¹ç§°ï¼Œé€‚åˆå¯¹ç§°é‡åŒ–ï¼›
- **Equivariant branch**ï¼ˆ$ l=1 $ï¼Œå‘é‡ï¼‰ï¼šæ¨¡é•¿éè´Ÿã€æ–¹å‘å‡åŒ€åˆ†å¸ƒåœ¨çƒé¢ä¸Šï¼›

å› æ­¤é‡‡ç”¨**å·®å¼‚åŒ–å¤„ç†ç­–ç•¥**ï¼š
- åˆ†åˆ«è®¾ç½®ç‹¬ç«‹çš„ fake quantization observerï¼›
- ä½¿ç”¨åˆ†é˜¶æ®µè®­ç»ƒï¼šå…ˆåªé‡åŒ–æ ‡é‡åˆ†æ”¯ï¼ˆwarm-upï¼‰ï¼Œå†å¯ç”¨å…¨é‡åŒ–ï¼›
- åœ¨å‘é‡åˆ†æ”¯åŠ å…¥ LEE æ­£åˆ™é¡¹ä»¥å¢å¼ºç­‰å˜æ€§ã€‚

> âœ… **ä¼˜åŠ¿**ï¼šæ›´ç¬¦åˆå„åˆ†æ”¯çš„æ•°æ®åˆ†å¸ƒç‰¹æ€§ï¼Œæå‡é‡åŒ–é²æ£’æ€§å’Œæœ€ç»ˆç²¾åº¦ã€‚

#### ï¼ˆ3ï¼‰**Robust Attention Normalization**  
è§‚å¯Ÿåˆ°æ³¨æ„åŠ›å¾—åˆ†ï¼ˆquery-key dot productï¼‰åœ¨ä½ç²¾åº¦ä¸‹ææ˜“å—åŠ¨æ€èŒƒå›´å½±å“è€Œäº§ç”Ÿå™ªå£°ï¼Œå¯¼è‡´ softmax æƒé‡å‰§çƒˆæ³¢åŠ¨ã€‚

è§£å†³æ–¹æ¡ˆï¼šå¼•å…¥ **L2-normalization** åˆ° query å’Œ key å‘é‡ï¼š
$$
\mathbf{q}' = \frac{\mathbf{q}}{\|\mathbf{q}\|}, \quad \mathbf{k}' = \frac{\mathbf{k}}{\|\mathbf{k}\|}
$$
ç„¶åè®¡ç®—æ³¨æ„åŠ›åˆ†æ•° $ \alpha_{ij} = \text{Softmax}((\mathbf{q}' \cdot \mathbf{k}') / \sqrt{d}) $

> âœ… **ä¼˜åŠ¿**ï¼š
> - å°†ç‚¹ç§¯é™åˆ¶åœ¨ $[-1,1]$ åŒºé—´å†…ï¼›
> - æ³¨æ„åŠ›ä»…ä¾èµ–äºæ–¹å‘ç›¸ä¼¼æ€§è€Œéç»å¯¹å¤§å°ï¼›
> - æ˜¾è‘—æå‡äº† INT8 æ¨¡å‹ä¸­æ³¨æ„åŠ›æœºåˆ¶çš„ç¨³å®šæ€§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | æ˜¯å¦æ”¯æŒ equivariance | æ˜¯å¦ç¨³å®š | æ˜¯å¦é«˜æ•ˆ |
|------|------------------------|----------|-----------|
| é€šç”¨é‡åŒ–æ–¹æ³•ï¼ˆDoReFa, PACT, SmoothQuantï¼‰ | âŒ å¿½ç•¥å‘é‡ç»“æ„ | âŒ å®¹æ˜“ç ´åæ–¹å‘ | âš ï¸ å¯åŠ é€Ÿä½†ç²¾åº¦ä¸‹é™ä¸¥é‡ |
| GNNä¸“ç”¨é‡åŒ–ï¼ˆDegree-Quantï¼‰ | âŒ ä»…å¤„ç†æ ‡é‡æ¶ˆæ¯ä¼ é€’ | âŒ ä¸ä¿æŠ¤å‘é‡æ–¹å‘ | âš ï¸ æ”¹å–„æœ‰é™ |
| æœ¬æ–‡æ–¹æ³•ï¼ˆMDDQ + Branch-QAT + L2-Normï¼‰ | âœ… æ˜¾å¼ä¿æŠ¤ç­‰å˜æ€§ | âœ… é«˜ç¨³å®šæ€§ | âœ… é«˜æ•ˆä¸”å‡†ç¡® |

> ğŸ¯ **ç»¼åˆä¼˜åŠ¿**ï¼šé¦–æ¬¡å®ç°**åœ¨ä¸ç‰ºç‰²ç­‰å˜æ€§å’Œç²¾åº¦çš„å‰æä¸‹ï¼Œå°† SO(3)-equivariant GNN æˆåŠŸå‹ç¼©è‡³ 8-bit ç”šè‡³ 4-bit**ï¼Œé€‚ç”¨äºç§»åŠ¨ç«¯éƒ¨ç½²ã€‚

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **QM9**ï¼š134k å°åˆ†å­ï¼Œç”¨äºè®­ç»ƒå’Œèƒ½é‡é¢„æµ‹ï¼ˆformation energyï¼‰ï¼Œå¹³è¡¡æ€ç»“æ„ï¼Œæ— å¤–åŠ›ã€‚
- **rMD17**ï¼š7 ä¸ªåˆ†å­ï¼ˆaspirin, ethanol, malonaldehyde ç­‰ï¼‰çš„éå¹³è¡¡æ€æ„å‹è½¨è¿¹ï¼Œæä¾›èƒ½é‡å’ŒåŸå­åŠ›ï¼ˆforcesï¼‰ï¼Œæ›´é€‚åˆæµ‹è¯•æ³›åŒ–èƒ½åŠ›å’ŒåŠ¨åŠ›å­¦ç¨³å®šæ€§ã€‚

> æ³¨ï¼šè®­ç»ƒä¸»è¦åœ¨ QM9 ä¸Šå®Œæˆï¼Œåœ¨ rMD17 ä¸Šæµ‹è¯•è·¨åˆ†å­æ³›åŒ–èƒ½åŠ›ã€‚

### **å®éªŒè®¾ç½®**
- **åŸºç¡€æ¶æ„**ï¼šåŸºäº So3krates çš„ transformer æ¶æ„ï¼Œä½¿ç”¨ `e3nn` åº“å®ç° E(3)/SO(3) ç­‰å˜æ“ä½œï¼›
- **ç‰¹å¾ç»´åº¦**ï¼š$ l=0 $ å’Œ $ l=1 $ ç‰¹å¾å„ 64 ç»´ï¼Œå…± 6 å±‚å…¨å±€è‡ªæ³¨æ„åŠ›ï¼›
- **è¾“å‡ºç›®æ ‡**ï¼šåˆ†å­å½¢æˆèƒ½ï¼ˆæ ‡é‡ï¼‰å’ŒåŸå­åŠ›ï¼ˆ3D å‘é‡ï¼‰ï¼›
- **æŸå¤±å‡½æ•°**ï¼šåŠ æƒ MAEï¼ˆèƒ½é‡ + åŠ›ï¼‰+ LEE æ­£åˆ™é¡¹ï¼ˆä»…ä½œç”¨äºå‘é‡è¾“å‡ºï¼‰ï¼›
- **é‡åŒ–é…ç½®**ï¼š
  - æ‰€æœ‰çº¿æ€§å±‚å’Œæ¿€æ´»å‡½æ•°é‡åŒ–ä¸º **INT8**ï¼›
  - ç¬¬ä¸€å±‚å’Œæœ€åä¸€å±‚ä¿æŒ FP32ï¼›
  - ä½¿ç”¨ PyTorch çš„ fake quantization observer è¿›è¡Œ QATï¼›
  - å­¦ä¹ ç‡ $1\times10^{-4}$ï¼Œ20 epoch QATï¼Œå‰ 5 epoch åªé‡åŒ–æ ‡é‡åˆ†æ”¯ï¼ˆwarm-upï¼‰ï¼›
  - æ³¨æ„åŠ›ä½¿ç”¨ L2-normalized queries/keysã€‚

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Energy MAE** | å•ä½ï¼šmeVï¼Œè¶Šå°è¶Šå¥½ |
| **Force MAE** | å•ä½ï¼šmeV/Ã…ï¼Œè¶Šå°è¶Šå¥½ |
| **Local Equivariance Error (LEE)** | æµ‹é‡æ¨¡å‹è¾“å‡ºæ˜¯å¦æ»¡è¶³ $ f(R \cdot G) = R \cdot f(G) $ï¼Œå•ä½ meV/Ã…ï¼Œè¶Šå°è¡¨ç¤ºç­‰å˜æ€§è¶Šå¥½ |
| **Inference Latency** | CPU ä¸Šå•åˆ†å­æ¨ç†å»¶è¿Ÿï¼ˆÎ¼sï¼‰ï¼Œè¡¡é‡æ•ˆç‡ |
| **Speedup** | ç›¸å¯¹äº FP32 æ¨¡å‹çš„æ¨ç†é€Ÿåº¦æå‡å€æ•° |
| **Memory Reduction** | é‡åŒ–åæ¨¡å‹ä½“ç§¯å‡å°‘æ¯”ä¾‹ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åŸºçº¿ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| **FP32 So3krates** | å…¨ç²¾åº¦ä¸Šé™ | æ€§èƒ½å‚è€ƒåŸºå‡† |
| **PTQ-NequIP (INT8)** | åè®­ç»ƒé‡åŒ– | NequIP æ¨¡å‹è½¬ä¸º 8-bitï¼Œæœªå¾®è°ƒ |
| **So3krates + Degree-Quant (INT8)** | GNNä¸“ç”¨QAT | ä½¿ç”¨ Degree-Quant å¯¹ So3krates è¿›è¡Œé‡åŒ– |
| **TorchAO W4A8** | æ›´æ¿€è¿›é‡åŒ– | 4-bitæƒé‡ + 8-bitæ¿€æ´» |

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆrMD17-Ethanolï¼‰**
| æ–¹æ³• | Energy MAE (meV) | Force MAE (meV/Ã…) | LEE (meV/Ã…) | Speedup | Memory â†“ |
|------|------------------|--------------------|-------------|---------|-----------|
| FP32 So3krates | 2.25 | 4.16 | ~0 | 1.0Ã— | 1Ã— |
| **Ours (INT8)** | **1.74** | **4.21** | **~2** | **2.73Ã—** | **~4Ã—** |
| PTQ-NequIP | 15.7 | 35.3 | ~5 | 2.73Ã— | ~4Ã— |
| Degree-Quant | 11.3 | 28.0 | ~3 | 0.73Ã— | ~4Ã— |

> ğŸ” **äº®ç‚¹**ï¼š
> - æˆ‘ä»¬çš„ INT8 æ¨¡å‹ä¸ä»…æ²¡æœ‰é€€åŒ–ï¼Œåè€Œåœ¨æŸäº›ä»»åŠ¡ä¸Š**ä¼˜äº FP32 åŸºçº¿**ï¼ˆå¯èƒ½å›  QAT èµ·åˆ°æ­£åˆ™åŒ–ä½œç”¨ï¼‰ï¼›
> - æ¨ç†é€Ÿåº¦å¿« **2.37â€“2.73Ã—**ï¼Œå†…å­˜å‡å°‘çº¦ **4Ã—**ï¼›
> - LEE ä»…ä¸º ~2 meV/Ã…ï¼Œè¿œä½äºå…¶ä»–æ–¹æ³•ï¼Œè¡¨æ˜ç­‰å˜æ€§é«˜åº¦ä¿ç•™ã€‚

### **è·¨åˆ†å­æ€§èƒ½æ¯”è¾ƒï¼ˆTable IIï¼‰**
åœ¨å¤šä¸ª rMD17 åˆ†å­ä¸Šï¼Œæˆ‘ä»¬çš„ **W4A8ï¼ˆ4-bit weight + 8-bit activationï¼‰** æ¨¡å‹è¡¨ç°ä¼˜å¼‚ï¼š

| åˆ†å­ | èƒ½é‡ MAE (meV) | åŠ› MAE (meV/Ã…) | è¡¨ç° |
|------|----------------|----------------|-------|
| Ethanol | **1.74** | **4.21** | è¶…è¶Šæ‰€æœ‰ FP32 æ¨¡å‹ |
| Aspirin | **4.87** | 11.5 | æœ€ä½³èƒ½é‡é¢„æµ‹ |
| Malondialdehyde | **2.57** | **6.53** | å…¨é¢é¢†å…ˆ |

> âœ… è¡¨æ˜å³ä½¿åœ¨æä½æ¯”ç‰¹ä¸‹ï¼Œä¹Ÿèƒ½è¾¾åˆ°ç”šè‡³è¶…è¿‡å½“å‰ SOTA FP32 æ¨¡å‹çš„ç²¾åº¦ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
| æ¶ˆèæ¡ä»¶ | Energy MAE | Force MAE | LEE | ç»“è®º |
|--------|------------|-----------|-----|------|
| ä»…é‡åŒ–æ ‡é‡åˆ†æ”¯ | 8.7 | 21.0 | ~0 | å‘é‡ä¿ç•™ FP32 æ—¶æ€§èƒ½æ¥è¿‘åŸæ¨¡å‹ |
| ä»…é‡åŒ–å‘é‡åˆ†æ”¯ | 9.5 | 24.0 | â€” | å‘é‡é‡åŒ–å½±å“æ›´å¤§ |
| æ—  MDDQï¼ˆæ™®é€šé‡åŒ–ï¼‰ | >12 | â€” | â€” | **æ–¹å‘ä¸¢å¤±ä¸¥é‡å½±å“ç²¾åº¦** |
| æ—  attention normalization | ~12 | â†‘â†‘ | â€” | æ³¨æ„åŠ›ä¸ç¨³å®šå¯¼è‡´è®­ç»ƒå¤±è´¥æˆ–è¯¯å·®ä¸Šå‡ |
| æ—  LEE æ­£åˆ™åŒ– | 9.1 / 22.5 | â€” | ~4 | **ç­‰å˜æ€§æ˜æ˜¾æ¶åŒ–** |

> ğŸ” **æ ¸å¿ƒå‘ç°**ï¼šä¸‰ä¸ªç»„ä»¶ç¼ºä¸€ä¸å¯ï¼Œå…±åŒä¿éšœäº†ä½æ¯”ç‰¹ä¸‹çš„ç²¾åº¦ä¸å¯¹ç§°æ€§ã€‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **SO(3)-equivariant GNN å¯ä»¥å®‰å…¨åœ°è¿›è¡Œä½æ¯”ç‰¹é‡åŒ–**ï¼Œå‰ææ˜¯è®¾è®¡ä¸“é—¨çš„ç­‰å˜æ€§æ„ŸçŸ¥é‡åŒ–æ–¹æ¡ˆï¼›
2. âœ… **MDDQ æ˜¯ä¿æŒå‘é‡æ–¹å‘çš„å…³é”®**ï¼Œè§£è€¦æ¨¡é•¿ä¸æ–¹å‘å¯æœ‰æ•ˆé˜²æ­¢é‡åŒ–å¼•èµ·çš„å‡ ä½•å¤±çœŸï¼›
3. âœ… **branch-separated QAT + staged training** æ˜¾è‘—æé«˜è®­ç»ƒç¨³å®šæ€§ä¸æœ€ç»ˆç²¾åº¦ï¼›
4. âœ… **L2-normalized attention** æå¤§å¢å¼ºäº†ä½ç²¾åº¦æ³¨æ„åŠ›æœºåˆ¶çš„é²æ£’æ€§ï¼›
5. âœ… **QAT æœ¬èº«å¯ä½œä¸ºæ­£åˆ™åŒ–æ‰‹æ®µ**ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼ˆå¦‚ W4A8ï¼‰åè€Œæå‡æ€§èƒ½ï¼›
6. âœ… æ‰€ææ–¹æ³•å®ç°äº† **2.37â€“2.73Ã— æ¨ç†åŠ é€Ÿ** å’Œ **~4Ã— å†…å­˜ç¼©å‡**ï¼ŒåŒæ—¶ä¿æŒä¸ FP32 ç›¸å½“çš„ç²¾åº¦å’Œç­‰å˜æ€§ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- å½“å‰ä¸»è¦éªŒè¯äº $ l \leq 1 $ çš„ç®€å•è¡¨ç¤ºç³»ç»Ÿï¼Œå°šæœªæ‰©å±•åˆ°æ›´é«˜é˜¶å¼ é‡ï¼ˆ$ l \geq 2 $ï¼‰ï¼›
- å®éªŒé›†ä¸­åœ¨å°åˆ†å­ä½“ç³»ï¼Œå¯¹è›‹ç™½è´¨ã€æ™¶ä½“ç­‰å¤æ‚ç³»ç»Ÿçš„é€‚ç”¨æ€§æœ‰å¾…éªŒè¯ï¼›
- ç›®å‰ä¾èµ–ç‰¹å®šç¡¬ä»¶æ”¯æŒï¼ˆå¦‚ AVX2 æˆ– INT8 åŠ é€Ÿå™¨ï¼‰æ‰èƒ½å‘æŒ¥æœ€å¤§æ•ˆç‡ä¼˜åŠ¿ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•è‡³ **ç”Ÿç‰©å¤§åˆ†å­å’Œå‘¨æœŸæ€§ææ–™**ï¼ˆcrystalline materialsï¼‰ï¼›
- æ¢ç´¢ä¸å…¶ä»–å¯¹ç§°ç¾¤ï¼ˆå¦‚ SE(3), permutation groupï¼‰ç»“åˆçš„é€šç”¨å¯¹ç§°æ€§ä¿æŒé‡åŒ–æ¡†æ¶ï¼›
- ä¸ä¸“ç”¨ä½æ¯”ç‰¹ç¡¬ä»¶ååŒè®¾è®¡ï¼ˆco-designï¼‰ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–ç«¯ä¾§æ¨ç†æ€§èƒ½ï¼›
- ç ”ç©¶æ›´ä½æ¯”ç‰¹ï¼ˆå¦‚ W2A4ï¼‰ä¸‹çš„å¯è¡Œæ€§ä¸æé™ã€‚

---

> ğŸ’¡ **æ€»ä½“è¯„ä»·**ï¼šè¿™æ˜¯**é¦–ç¯‡ç³»ç»Ÿç ”ç©¶ SO(3)-equivariant GNN é‡åŒ–çš„è®ºæ–‡**ï¼Œæå‡ºçš„ä¸‰è¦ç´ æ¡†æ¶ï¼ˆMDDQ + Branch-QAT + Robust Attentionï¼‰ä¸ºå¯¹ç§°æ€§ç¥ç»ç½‘ç»œçš„è½»é‡åŒ–æä¾›äº†èŒƒå¼çº§è§£å†³æ–¹æ¡ˆï¼Œæ¨åŠ¨äº†ç‰©ç†é©±åŠ¨ AI æ¨¡å‹åœ¨ç§»åŠ¨å’ŒåµŒå…¥å¼åœºæ™¯ä¸­çš„å®é™…åº”ç”¨ã€‚

</details>

---

### 5. [Heterogeneous Low-Bandwidth Pre-Training of LLMs](https://arxiv.org/abs/2601.02360)

**Authors**: Yazan Obeidi, Amir Sarfi, Joel Lidin, Paul Janson, Eugene Belilovsky  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.02360v1  

#### Abstract
Pre-training large language models (LLMs) increasingly requires distributed compute, yet bandwidth constraints make it difficult to scale beyond well-provisioned datacenters-especially when model parallelism forces frequent, large inter-device communications. We study whether SparseLoCo, a low-commu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Heterogeneous Low-Bandwidth Pre-Training of LLMs è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„é¢„è®­ç»ƒé«˜åº¦ä¾èµ–åˆ†å¸ƒå¼è®¡ç®—ï¼Œä½†éšç€æ¨¡å‹è§„æ¨¡å¢é•¿ï¼Œè·¨è®¾å¤‡é€šä¿¡å¼€é”€ï¼ˆå°¤å…¶æ˜¯å¸¦å®½éœ€æ±‚ï¼‰æˆä¸ºæ‰©å±•ç“¶é¢ˆã€‚ç‰¹åˆ«æ˜¯åœ¨èµ„æºå¼‚æ„ã€ç½‘ç»œå¸¦å®½å—é™ï¼ˆå¦‚é€šè¿‡äº’è”ç½‘è¿æ¥ï¼‰çš„ç¯å¢ƒä¸­ï¼Œä¼ ç»Ÿçš„æ•°æ®å¹¶è¡Œï¼ˆData Parallelismï¼‰å’Œæ¨¡å‹å¹¶è¡Œï¼ˆModel Parallelismï¼‰éš¾ä»¥é«˜æ•ˆè¿è¡Œã€‚ç°æœ‰æ–¹æ³•åœ¨ä½å¸¦å®½åœºæ™¯ä¸‹å¾€å¾€ç‰ºç‰²æ€§èƒ½æˆ–æ— æ³•æ”¯æŒå¤§è§„æ¨¡æ¨¡å‹ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹æ ¸å¿ƒæŒ‘æˆ˜ï¼š
- å¦‚ä½•åœ¨**ä½å¸¦å®½ç¯å¢ƒä¸‹æœ‰æ•ˆç»“åˆæ•°æ®å¹¶è¡Œä¸æ¨¡å‹å¹¶è¡Œ**ï¼Ÿ
- å¦‚ä½•è®©**èµ„æºå—é™çš„å‚ä¸è€…**ï¼ˆå¦‚å°å‹é›†ç¾¤æˆ–ä¸ªäººèŠ‚ç‚¹ï¼‰ä¹Ÿèƒ½å‚ä¸LLMé¢„è®­ç»ƒï¼Ÿ
- å¦‚ä½•åœ¨å‹ç¼©é€šä¿¡çš„åŒæ—¶**æœ€å°åŒ–æ€§èƒ½æŸå¤±**ï¼Ÿ

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Heterogeneous SparseLoCo** çš„æ–°å‹åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### âœ… **1. ç»“åˆ SparseLoCo ä¸ Subspace Pipeline Compression**
- å°†é«˜æ•ˆçš„ä½é€šä¿¡æ•°æ®å¹¶è¡Œæ–¹æ³• **SparseLoCo**ï¼ˆåŸºäºç¨€ç–ä¼ªæ¢¯åº¦äº¤æ¢å’Œä½é¢‘åŒæ­¥ï¼‰ä¸ä½å¸¦å®½æ¨¡å‹å¹¶è¡ŒæŠ€æœ¯ **Subspace Networks** ä¸­çš„æ¿€æ´»/æ¢¯åº¦å‹ç¼©ç›¸ç»“åˆã€‚
- åœ¨ pipeline stage ä¹‹é—´ä½¿ç”¨å­ç©ºé—´æŠ•å½±ï¼ˆsubspace projectionï¼‰å‹ç¼© `activations` å’Œ `activation-gradients`ï¼Œæ˜¾è‘—é™ä½è·¨é˜¶æ®µé€šä¿¡é‡ã€‚

#### âœ… **2. å¼‚æ„è®­ç»ƒæ¶æ„ï¼ˆHeterogeneous Training Configurationï¼‰**
- å…è®¸ä¸åŒç±»å‹çš„å‚ä¸è€…å…±å­˜ï¼š
  - **é«˜æ€§èƒ½é›†ç¾¤**ï¼ˆå¦‚ InfiniBand è¿æ¥ï¼‰è¿è¡Œå®Œæ•´çš„æœªå‹ç¼©æ¨¡å‹å‰¯æœ¬ï¼ˆfull replicaï¼‰ï¼Œä¸è¿›è¡Œå‹ç¼©ï¼›
  - **èµ„æºå—é™èŠ‚ç‚¹** ç»„æˆä¸€ä¸ªé€»è¾‘ä¸Šçš„â€œè”åˆå‰¯æœ¬â€ï¼ˆjoint replicaï¼‰ï¼Œé‡‡ç”¨ pipeline parallelism å¹¶å¯ç”¨ subspace å‹ç¼©ã€‚
- å®ç°äº†**é€‰æ‹©æ€§å‹ç¼©ï¼ˆselective compressionï¼‰**ï¼šä»…åœ¨å¸¦å®½ç“¶é¢ˆå¤„åº”ç”¨å‹ç¼©ï¼Œä¿ç•™é«˜å¸¦å®½é“¾è·¯çš„å…¨ç²¾åº¦é€šä¿¡ã€‚

#### âœ… **3. é’ˆå¯¹å¼‚æ„ç¯å¢ƒçš„å…³é”®é€‚é…æœºåˆ¶**
- **Token Embedding ä¿®æ­£æœºåˆ¶**ï¼šä¸ºé˜²æ­¢å‹ç¼©ä¸éå‹ç¼©å‰¯æœ¬åœ¨åŒæ­¥æ—¶å¯¼è‡´åµŒå…¥è¡¨æ¼‚å‡ºå­ç©ºé—´ï¼Œå¼•å…¥æŠ•å½±æ®‹å·®ç´¯ç§¯ç­–ç•¥ï¼Œç¡®ä¿æ‰€æœ‰å‰¯æœ¬å…±äº«ä¸€è‡´çš„ token embeddingã€‚
- åˆ†æäº†å‹ç¼©å¸¦æ¥çš„ç³»ç»Ÿåå·®ï¼ˆcompression biasï¼‰ï¼ŒæŒ‡å‡ºåœ¨ SparseLoCo çš„é•¿å‘¨æœŸæœ¬åœ°ä¼˜åŒ–ä¸­ï¼Œæœªå‹ç¼©å‰¯æœ¬å¯ä½œä¸ºâ€œé”šç‚¹â€æ ¡æ­£åå·®ï¼Œä»è€Œæå‡æ•´ä½“æ”¶æ•›è´¨é‡ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **é€šä¿¡æ•ˆç‡** | æ˜¾è‘—å‡å°‘è·¨èŠ‚ç‚¹é€šä¿¡é‡ï¼Œå°¤å…¶é€‚ç”¨äºäº’è”ç½‘çº§ä½å¸¦å®½è¿æ¥ï¼ˆå¦‚ 100 Mbpsâ€“1 Gbpsï¼‰ã€‚ |
| **èµ„æºåˆ©ç”¨ç‡** | å¯æ•´åˆåŸæœ¬å› å†…å­˜æˆ–å¸¦å®½ä¸è¶³è€Œæ— æ³•ç‹¬ç«‹è®­ç»ƒå¤§æ¨¡å‹çš„å°å‹èŠ‚ç‚¹ã€‚ |
| **æ€§èƒ½ä¿æŒ** | ç›¸è¾ƒäºç»Ÿä¸€å‹ç¼©ï¼ˆuniform compressionï¼‰ï¼Œå¼‚æ„é…ç½®åœ¨ç›¸åŒå‹ç¼©æ¯”ä¸‹æŸå¤±æ›´ä½ã€‚ |
| **çµæ´»æ€§ä¸å¯æ‰©å±•æ€§** | æ”¯æŒæ··åˆç¡¬ä»¶éƒ¨ç½²ï¼Œé€‚åˆå»ä¸­å¿ƒåŒ–æˆ–å¤šç»„ç»‡åä½œè®­ç»ƒåœºæ™¯ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **DCLM**ï¼šå¤§è§„æ¨¡é¢„è®­ç»ƒè¯­æ–™åº“ï¼Œç”¨äºä¸»å®éªŒã€‚
- **C4**ï¼šé€šç”¨æ–‡æœ¬æ•°æ®é›†ï¼Œç”¨äºéªŒè¯æ³›åŒ–èƒ½åŠ›ã€‚

---

### **å®éªŒè®¾ç½®**

| å‚æ•° | è®¾ç½® |
|------|------|
| **æ¨¡å‹æ¶æ„** | Decoder-only Transformersï¼ˆLLaMA é£æ ¼ï¼‰ï¼ŒSwiGLU æ¿€æ´»å‡½æ•° |
| **æ¨¡å‹è§„æ¨¡** | 178Mã€512Mã€1B å‚æ•° |
| **Pipeline Stages** | 4 stages |
| **Replicas æ•°é‡ (M)** | 8ï¼ˆ178M/512Mï¼‰ã€2ï¼ˆ1Bï¼‰ |
| **Local Steps (H)** | 50ï¼ˆSparseLoCo é»˜è®¤ï¼‰ |
| **Chunk Size** | 64Ã—64ï¼ˆ4096 å…ƒç´ ï¼‰ |
| **TOP-k Sparsity** | æ¯ chunk ä¿ç•™ 32 ä¸ªæœ€å¤§å€¼ â†’ ~0.78% å¯†åº¦ |
| **Optimizer** | Inner: AdamWï¼›Outer: SGDï¼ˆæ— åŠ¨é‡ï¼‰ |
| **Error Feedback Momentum Î²** | 0.95 |
| **Batch Size** | å±€éƒ¨ batch 32ï¼Œå…¨å±€ç­‰æ•ˆ 524,288 tokens / inner step |
| **Training Budget** | Chinchilla-optimalï¼ˆ10B tokens ä¸»å®éªŒï¼Œéƒ¨åˆ†æ‰©å±•è‡³ 12Bï¼‰ |

---

### **è¯„ä¼°æŒ‡æ ‡**

- **Validation Loss**ï¼ˆä¸»è¦æŒ‡æ ‡ï¼‰
- **Perplexity**
- **ç›¸å¯¹æ€§èƒ½é€€åŒ–ç‡ Î”(%)**ï¼š$\frac{L_{\text{compressed}} - L_{\text{baseline}}}{L_{\text{baseline}}} \times 100\%$
- **Compute Utilization vs Bandwidth**ï¼ˆæ¨¡æ‹Ÿå¢™é’Ÿæ—¶é—´å½±å“ï¼‰
- **æ¶ˆèå®éªŒ**ï¼šåˆ†æå„ç»„ä»¶ï¼ˆå¦‚ embedding adaptationã€weight projectionï¼‰çš„å½±å“

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ–¹æ³• | æè¿° |
|------|------|
| **SparseLoCo (Baseline)** | ä¸ä½¿ç”¨ä»»ä½• activation compressionï¼Œå…¨ç²¾åº¦é€šä¿¡ |
| **SparseLoCo + PP-Compress** | æ‰€æœ‰ replica å‡ä½¿ç”¨ subspace å‹ç¼©ï¼ˆuniformï¼‰ |
| **SparseLoCo + Het-PP-Compress (1/2)** | ä¸€åŠ replica ä½¿ç”¨å‹ç¼©ï¼Œå¦ä¸€åŠä¸å‹ç¼©ï¼ˆheterogeneousï¼‰ |
| **AdamW + PP-Compress / Heterogeneous** | ç”¨äºå¯¹æ¯”æ ‡å‡†æ•°æ®å¹¶è¡Œæ˜¯å¦ä¹Ÿå—ç›Šäºå¼‚æ„å‹ç¼© |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & 2ï¼‰**

#### ğŸ”¹ **512M æ¨¡å‹åœ¨ DCLM ä¸Šçš„ç»“æœï¼ˆk/d = 1/8, å‹ç¼©ç‡ 87.5%ï¼‰**

| é…ç½® | Loss | Perplexity | Î”(%) |
|-----------------------------|--------|------------|-------|
| SparseLoCo (Baseline)       | 2.73   | 15.40      | â€”     |
| PP-Compress (Uniform)       | 2.84   | 17.10      | +3.8% |
| Het-PP-Compress (1/2)       | 2.82   | 16.90      | +3.3% |
| + è¶…å‚è°ƒä¼˜                  | **2.80** | **16.50**  | **+2.6%** |

> âœ… å¼‚æ„å‹ç¼©æ¯”ç»Ÿä¸€å‹ç¼©å¹³å‡é™ä½çº¦ **0.5pp çš„ loss å¢åŠ **ã€‚

#### ğŸ”¹ **æ›´é«˜å‹ç¼©æ¯”ä¸‹çš„è¡¨ç°ï¼ˆ512M, k/d ä¸‹é™ï¼‰**

| k/d | å‹ç¼©ç‡ | Uniform Loss (Î”%) | Heterogeneous Loss (Î”%) | æ”¶ç›Š |
|-----|--------|--------------------|----------------------------|------|
| 1   | 0%     | 2.73               | â€”                          | â€”    |
| 1/8 | 87.5%  | 2.84 (+3.8%)       | 2.82 (+3.3%)               | +0.5pp |
| 1/96| 99.0%  | 2.96 (+8.1%)       | 2.94 (+7.4%)               | +0.7pp |
| 1/384| 99.7% | 3.04 (+11.3%)      | 2.99 (+9.4%)               | +1.9pp |
| 1/768| 99.9% | 3.07 (+12.4%)      | **3.00 (+9.8%)**           | **+2.6pp** |

> ğŸ“Œ **ç»“è®ºï¼šå‹ç¼©è¶Šæ¿€è¿›ï¼Œå¼‚æ„æ–¹æ¡ˆä¼˜åŠ¿è¶Šæ˜æ˜¾ï¼**

---

### **æ‰©å±•è®­ç»ƒé¢„ç®—å®éªŒï¼ˆTable 3aï¼‰**

| é…ç½® | Token Budget | Final Loss |
|----------------------------------|---------------|-------------|
| SparseLoCo (Baseline)            | 10B           | 2.73        |
| SparseLoCo + PP-Compress         | 12B (+20%)    | 2.78        |
| SparseLoCo + Het-PP-Compress(1/2)| 12B (+20%)    | **2.75**    |

> ğŸ’¡ å³ä½¿å‹ç¼©å¸¦æ¥åˆå§‹æ€§èƒ½ä¸‹é™ï¼Œ**å¢åŠ  20% è®­ç»ƒ tokens åï¼Œå¼‚æ„æ–¹æ¡ˆæ¥è¿‘ç”šè‡³é€¼è¿‘ baseline æ€§èƒ½**ï¼Œä¸”ç”±äºé€šä¿¡å‡å°‘ï¼Œå®é™… wall-clock time æ›´çŸ­ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆTable 4ï¼‰**

| ç»„ä»¶ | æ˜¯å¦å¯ç”¨ | å¯¹ Loss å½±å“ | ç»“è®º |
|------|----------|--------------|------|
| **Token Embedding Adaptation** | æ˜¯ | 2.82 vs 2.89ï¼ˆâ†“0.07ï¼‰ | âœ… è‡³å…³é‡è¦ï¼Œæ˜¾è‘—æ”¹å–„ä¼˜åŒ– |
| **Weight Projection** | æ˜¯ | 2.88 vs 2.84ï¼ˆâ†‘0.04ï¼‰ | âŒ æœ‰å®³ï¼Œåº”ç§»é™¤ |
| **Grassmann Subspace Update** | æ˜¯ | æ— å˜åŒ– | âŒ æ— éœ€åŠ¨æ€æ›´æ–°å­ç©ºé—´ |
| **Modified AdamW** | æ˜¯ | æ— å˜åŒ– | âŒ åŸå§‹ AdamW è¶³å¤Ÿ |

> âš ï¸ è¯´æ˜ï¼šåœ¨ SparseLoCo æ¡†æ¶ä¸‹ï¼Œè®¸å¤š Subspace Networks çš„å¤æ‚è®¾è®¡åè€Œæ— æ•ˆæˆ–è´Ÿé¢ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **SparseLoCo å¯æœ‰æ•ˆä¸ pipeline compression ç»“åˆ**  
   åœ¨ modest å‹ç¼©ï¼ˆå¦‚ 87.5%ï¼‰ä¸‹ï¼Œæ€§èƒ½é€€åŒ–å¯æ§ï¼ˆ<4%ï¼‰ï¼Œä¸”å¯é€šè¿‡å¢åŠ è®­ç»ƒæ­¥æ•°è¡¥å¿ã€‚

2. âœ… **å¼‚æ„å‹ç¼©ä¼˜äºç»Ÿä¸€å‹ç¼©**  
   åœ¨ç›¸åŒå‹ç¼©æ¯”ä¸‹ï¼Œæ··åˆä½¿ç”¨å‹ç¼©ä¸éå‹ç¼© replica èƒ½æ˜¾è‘—ç¼“è§£æ€§èƒ½ä¸‹é™ï¼Œå°¤å…¶æ˜¯åœ¨é«˜å‹ç¼©æ¯”ï¼ˆ>99%ï¼‰æ—¶æ•ˆæœæ›´çªå‡ºã€‚

3. âœ… **å¼‚æ„ä¼˜åŠ¿æºäºåå·®æ ¡æ­£æœºåˆ¶**  
   æœªå‹ç¼© replica æä¾›æ— åæ¢¯åº¦ä¼°è®¡ï¼Œåœ¨ SparseLoCo çš„ H-step æœ¬åœ°ä¼˜åŒ–ä¸­èµ·åˆ°â€œé”šå®šâ€ä½œç”¨ï¼ŒæŠ‘åˆ¶å‹ç¼©å¼•å…¥çš„ç³»ç»Ÿåå·®ç§¯ç´¯ã€‚

4. âœ… **è¯¥ä¼˜åŠ¿æ˜¯ SparseLoCo ç‰¹æœ‰çš„**  
   åœ¨æ ‡å‡† AdamWï¼ˆH=1ï¼‰è®­ç»ƒä¸­ï¼Œé¢‘ç¹åŒæ­¥é˜»æ­¢äº†åå·®ç§¯ç´¯ï¼Œå› æ­¤å¼‚æ„ç­–ç•¥ä¸ä»…æ— æ•ˆï¼Œåè€Œç•¥å·®ï¼ˆè§ Table 3ï¼‰ã€‚

5. âœ… **æ–¹æ³•å…·æœ‰è‰¯å¥½çš„æ³›åŒ–æ€§**  
   åœ¨ C4 æ•°æ®é›†å’Œ 1B å‚æ•°æ¨¡å‹ä¸Šå‡éªŒè¯äº†æœ‰æ•ˆæ€§ï¼ˆTable 6 & 7ï¼‰ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™ | è¯´æ˜ |
|------|------|
| **ä¾èµ– careful initialization & synchronization** | Token embedding çš„ subspace çº¦æŸéœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œå¦åˆ™ä¼šç ´åä¸€è‡´æ€§ã€‚ |
| **æç«¯å‹ç¼©ä»ä¼šå¯¼è‡´æ˜¾è‘—æ€§èƒ½ä¸‹é™** | å½“ k/d < 1/100 æ—¶ï¼Œå³ä½¿å»¶é•¿è®­ç»ƒä¹Ÿæ— æ³•å®Œå…¨æ¢å¤ baseline æ€§èƒ½ã€‚ |
| **ç›®å‰ä¸º simulation-based study** | å®éªŒåŸºäºç­‰ä»·æ­¥æ•°æ¨¡æ‹Ÿï¼Œå¹¶æœªåœ¨çœŸå®ä½å¸¦å®½ç½‘ç»œä¸Šéƒ¨ç½²ï¼Œå®é™…å»¶è¿Ÿå’Œä¸¢åŒ…æœªè€ƒè™‘ã€‚ |
| **ä»…æ”¯æŒé™æ€å­ç©ºé—´** | åŠ¨æ€è°ƒæ•´ subspaceï¼ˆå¦‚ Grassmann ä¼˜åŒ–ï¼‰æœªæ˜¾ç¤ºå‡ºæ”¶ç›Šï¼Œå¯èƒ½é™åˆ¶é•¿æœŸé€‚åº”æ€§ã€‚ |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **çœŸå®ä¸–ç•Œéƒ¨ç½²æµ‹è¯•**ï¼šåœ¨è·¨æ•°æ®ä¸­å¿ƒæˆ– P2P ç½‘ç»œä¸­å®ç°è¯¥æ¡†æ¶ï¼Œæµ‹é‡çœŸå®é€šä¿¡-è®¡ç®—æƒè¡¡ã€‚
2. **è‡ªé€‚åº”å‹ç¼©ç­–ç•¥**ï¼šæ ¹æ®å®æ—¶å¸¦å®½è‡ªåŠ¨è°ƒèŠ‚å‹ç¼©æ¯”ï¼ˆk/dï¼‰ã€‚
3. **ä¸å…¶ä»–å¹¶è¡ŒèŒƒå¼ç»“åˆ**ï¼šå¦‚ Tensor Parallelism æˆ– ZeROï¼Œè¿›ä¸€æ­¥æå‡èµ„æºåˆ©ç”¨ç‡ã€‚
4. **æ”¯æŒæ›´å¤šå¼‚æ„ç»´åº¦**ï¼šå¦‚æ··åˆç²¾åº¦ã€ä¸åŒè®¡ç®—èƒ½åŠ›çš„ GPU ç±»å‹è°ƒåº¦ã€‚
5. **ç†è®ºåˆ†æå‹ç¼©åå·®ä¼ æ’­æœºåˆ¶**ï¼šå»ºç«‹æ›´ç²¾ç¡®çš„è¯¯å·®å»ºæ¨¡èŒƒå¼ã€‚

---

## æ€»ç»“

> **Heterogeneous SparseLoCo ä¸º LLM é¢„è®­ç»ƒæä¾›äº†ä¸€æ¡é€šå¾€â€œå»ä¸­å¿ƒåŒ– + ä½å¸¦å®½ + é«˜æ•ˆâ€çš„å®ç”¨è·¯å¾„**ã€‚å®ƒé€šè¿‡å°† **SparseLoCo çš„ä½é¢‘ç¨€ç–é€šä¿¡** ä¸ **subspace-based pipeline compression** ç›¸ç»“åˆï¼Œå¹¶å¼•å…¥ **å¼‚æ„å‰¯æœ¬è®¾è®¡**ï¼Œå®ç°äº†åœ¨èµ„æºå¤šæ ·ç¯å¢ƒä¸‹é«˜æ•ˆè®­ç»ƒå¤§æ¨¡å‹çš„å¯èƒ½æ€§ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§é€‰æ‹©æ€§å‹ç¼©ç­–ç•¥ä¸ä»…èƒ½æ˜¾è‘—é™ä½é€šä¿¡å‹åŠ›ï¼Œè¿˜èƒ½åœ¨é«˜å‹ç¼©æ¯”ä¸‹ä¼˜äºä¼ ç»Ÿç»Ÿä¸€å‹ç¼©æ–¹æ¡ˆï¼Œå°¤å…¶é€‚åˆæœªæ¥å¼€æ”¾åä½œå¼çš„ AI è®­ç»ƒç”Ÿæ€ã€‚

</details>

---

### 6. [Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.02346)

**Authors**: Falcon LLM Team, Iheb Chaabane, Puneesh Khanna, Suhail Mohmad, Slim Frikha, Shi Hu, Abdalgader Abubaker, Reda Alami, Mikhail Lubinets, Mohamed El Amine Seddik, Hakim Hacid  
**Category**: cs.AI  
**Published**: 2026-01-06  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.02346v1  

#### Abstract
This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning model...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFalcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½æå‡ä¾èµ–äº**è®­ç»ƒæ—¶æ‰©å±•ï¼ˆscaling trainingï¼‰** å’Œ **æ¨ç†æ—¶æ‰©å±•ï¼ˆscaling inferenceï¼‰**ï¼Œä½†ä¸¤è€…å‡é¢ä¸´ç“¶é¢ˆï¼š
- **è®­ç»ƒæ—¶æ‰©å±•**å—é™äºé«˜æ˜‚çš„è®¡ç®—æˆæœ¬å’Œé«˜è´¨é‡äººç±»æ•°æ®çš„ç¨€ç¼ºï¼›
- **æ¨ç†æ—¶æ‰©å±•ï¼ˆTest-Time Scaling, TTSï¼‰** è™½èƒ½é€šè¿‡ç”Ÿæˆå¤šæ¡æ¨ç†é“¾ï¼ˆå¦‚self-consistencyï¼‰æå‡å‡†ç¡®æ€§ï¼Œä½†å¸¦æ¥æ˜¾è‘—çš„æ¨ç†å¼€é”€ã€‚

å› æ­¤ï¼Œå¦‚ä½•åœ¨**ä¸å¢åŠ æ¨¡å‹è§„æ¨¡çš„å‰æä¸‹**ï¼Œå®ç°é«˜æ•ˆä¸”å‡†ç¡®çš„æ¨ç†èƒ½åŠ›æˆä¸ºå…³é”®æŒ‘æˆ˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
Falcon-H1R æ˜¯ä¸€ä¸ª **7B å‚æ•°çš„æ¨ç†ä¼˜åŒ–å°æ¨¡å‹ï¼ˆSLMï¼‰**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºç»“åˆäº†**æ¶æ„è®¾è®¡ã€è®­ç»ƒç­–ç•¥å’Œæµ‹è¯•æ—¶æ‰©å±•æŠ€æœ¯**ï¼Œå®ç°äº†â€œå°æ¨¡å‹å¤§èƒ½åŠ›â€çš„çªç ´ï¼š

#### ï¼ˆ1ï¼‰Hybrid Architecture for Efficient Reasoning
- åŸºäº **Falcon-H1 æ¶æ„**ï¼ˆæ··åˆ Transformer-Mamba æ¶æ„ï¼‰ï¼Œå…·å¤‡ä»¥ä¸‹ä¼˜åŠ¿ï¼š
  - æ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼ˆfast inferenceï¼‰
  - æ›´ä½çš„å†…å­˜å ç”¨ï¼ˆlow memory usageï¼‰
  - æ”¯æŒé•¿åºåˆ—ï¼ˆup to 256K context lengthï¼‰
- ç‰¹åˆ«é€‚åˆéœ€è¦é«˜ååé‡ã€å¤§æ‰¹é‡å¹¶è¡Œç”Ÿæˆçš„ **test-time scaling åœºæ™¯**ã€‚

#### ï¼ˆ2ï¼‰Robust Training Strategy
é‡‡ç”¨ä¸¤é˜¶æ®µç²¾ç»†åŒ–è®­ç»ƒæµç¨‹ï¼š
- **Cold-start SFT**ï¼šåŸºäºé«˜è´¨é‡ã€é•¿é“¾æ¨ç†æ•°æ®è¿›è¡Œç›‘ç£å¾®è°ƒï¼Œå¼ºè°ƒå›°éš¾æ ·æœ¬ï¼Œå¹¶å¼•å…¥**éš¾åº¦æ„ŸçŸ¥åŠ æƒï¼ˆdifficulty-aware weightingï¼‰**ã€‚
- **Reinforcement Learning with Verifiable Rewards (RLVR)**ï¼šä½¿ç”¨ GRPO ç®—æ³•è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œè¿›ä¸€æ­¥æå‡æ¨ç†èƒ½åŠ›å’Œè¾“å‡ºè´¨é‡ã€‚
  - å¼•å…¥åŠ¨æ€æ•°æ®è¿‡æ»¤æœºåˆ¶ï¼Œæ’é™¤è¿‡äºç®€å•æˆ–å®Œå…¨æ— æ³•è§£å†³çš„é—®é¢˜ã€‚
  - ä½¿ç”¨å¤šé¢†åŸŸå¥–åŠ±å‡½æ•°ï¼ˆmath/code/scienceï¼‰ç¡®ä¿å¯¹é½ç›®æ ‡ã€‚

#### ï¼ˆ3ï¼‰Superior Efficiency via Test-Time Scaling (TTS)
- é›†æˆæœ€æ–°çš„ **DeepConf@512** æ–¹æ³•ï¼ˆFu et al., 2025bï¼‰ï¼Œä¸€ç§åŸºäºç½®ä¿¡åº¦çš„åŠ¨æ€å‰ªæ TTS æŠ€æœ¯ï¼š
  - åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å®æ—¶è¯„ä¼°æ¯æ¡æ¨ç†é“¾çš„ç½®ä¿¡åº¦ã€‚
  - å¯¹ä½ç½®ä¿¡è·¯å¾„è¿›è¡Œæ—©æœŸç»ˆæ­¢ï¼ˆearly stoppingï¼‰ï¼Œå‡å°‘å†—ä½™ token ç”Ÿæˆã€‚
- ç»“æœæ˜¾ç¤º Falcon-H1R åœ¨ç›¸åŒè®¡ç®—é¢„ç®—ä¸‹å¯è¿è¡Œæ›´å¤šæœ‰æ•ˆæ¨ç†é“¾ï¼Œæ˜¾è‘—æå‡æ€§ä»·æ¯”ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Falcon-H1R-7B | å…¶ä»–ä¸»æµæ¨ç†æ¨¡å‹ï¼ˆå¦‚ Qwen3-32B, Phi-4-R-Plus-14Bï¼‰ |
|------|----------------|--------------------------------------------------|
| å‚æ•°é‡ | 7B | 14Bâ€“32B+ |
| æ¨ç†æ•ˆç‡ | é«˜ï¼ˆHybrid æ¶æ„ + vLLM ä¼˜åŒ–ï¼‰ | è¾ƒä½ï¼ˆçº¯ Transformerï¼‰ |
| å‡†ç¡®æ€§ | åŒ¹é…ç”šè‡³è¶…è¶Šæ›´å¤§æ¨¡å‹ | é«˜ä½†ä¾èµ–æ›´å¤§å‚æ•° |
| Token æ•ˆç‡ | æ˜¾è‘—æ›´ä¼˜ï¼ˆDeepConf ä¸‹å‡å°‘ ~38% tokenï¼‰ | è¾ƒé«˜æ¶ˆè€— |
| æˆæœ¬æ•ˆç›Š | æé«˜ï¼ˆcompact model + efficient TTSï¼‰ | æˆæœ¬è¾ƒé«˜ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼šFalcon-H1R å±•ç¤ºäº†**å°å‹åŒ–æ¨¡å‹é€šè¿‡ç²¾å¿ƒçš„æ•°æ®ã€è®­ç»ƒå’Œæ¶æ„è®¾è®¡ï¼Œå¯ä»¥åœ¨æ¨ç†ä»»åŠ¡ä¸Šè¾¾åˆ°ç”šè‡³è¶…è¶Šå¤§æ¨¡å‹çš„è¡¨ç°ï¼ŒåŒæ—¶å¤§å¹…é™ä½æ¨ç†æˆæœ¬**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åˆ†ä¸ºä¸¤ä¸ªè®­ç»ƒé˜¶æ®µï¼š

#### SFT é˜¶æ®µ
æ¶µç›–å››å¤§é¢†åŸŸï¼Œæ€»è®¡çº¦ 3.1M æ¡æ ·æœ¬ï¼š
- **æ•°å­¦**ï¼šMATHã€AMC/AIME/HMMT ç­‰ç«èµ›é¢˜ï¼Œå«å®Œæ•´ Chain-of-Thought æ¨ç†è¿‡ç¨‹ã€‚
- **ç¼–ç¨‹**ï¼šLeetCodeã€AtCoderã€Codeforces ä¸Šçš„é—®é¢˜ï¼Œå¼ºè°ƒç®—æ³•é€»è¾‘ä¸åŠŸèƒ½æ­£ç¡®æ€§ã€‚
- **ç§‘å­¦**ï¼šç‰©ç†ã€åŒ–å­¦ç­‰å¤šå­¦ç§‘é—®é¢˜ï¼Œç­”æ¡ˆç»éªŒè¯ã€‚
- **å…¶ä»–**ï¼šæŒ‡ä»¤éµå¾ªã€å·¥å…·è°ƒç”¨ã€å®‰å…¨å¯¹è¯ç­‰é€šç”¨ä»»åŠ¡ã€‚

#### RL é˜¶æ®µ
ç‹¬ç«‹äº SFT æ•°æ®ï¼Œé˜²æ­¢è®°å¿†åŒ–ï¼Œèšç„¦é«˜ä»·å€¼éš¾é¢˜ï¼š
- æ•°å­¦ï¼šAIMEã€HMMT ç­‰ç²¾é€‰éš¾é¢˜ã€‚
- ç¼–ç¨‹ï¼šLiveCodeBench ä¸­éœ€æ‰§è¡ŒéªŒè¯çš„ä»»åŠ¡ã€‚
- ç§‘å­¦ï¼šGPQA-Diamond ç±»ç ”ç©¶ç”Ÿçº§åˆ«é—®é¢˜ã€‚

æ‰€æœ‰æ•°æ®ç»è¿‡ä¸¥æ ¼æ¸…æ´—ä¸å»é‡ï¼Œç¡®ä¿æ— åŸºå‡†æ±¡æŸ“ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### è¯„ä¼°åŸºå‡†ï¼ˆBenchmarksï¼‰
| ç±»åˆ« | åŸºå‡† | æè¿° |
|------|-------|------|
| æ•°å­¦ | AIME24/25, HMMT25, AMO-Bench, MATH500 | å¥¥æ—åŒ¹å…‹çº§æ•°å­¦æ¨ç† |
| ç¼–ç¨‹ | LiveCodeBench v6, SciCode, T2-Telecom, TB Hard | çœŸå®ç¼–ç¨‹åœºæ™¯ä¸ä»£ç†ä»»åŠ¡ |
| ä¸€èˆ¬æ¨ç† | GPQA-Diamond, MMLU-Pro, Humanity's Last Exam (HLE), IFBench | å¤šè·³ç§‘å­¦æ¨ç†ã€çŸ¥è¯†å¯†é›†å‹é—®ç­”ã€æŒ‡ä»¤éµå¾ª |

#### è¯„ä¼°æ–¹å¼
- æ‰€æœ‰ç»“æœæŠ¥å‘Šä¸º **pass@1** æˆ– **voted accuracy**ï¼ˆç”¨äº TTSï¼‰ã€‚
- ç”Ÿæˆå‚æ•°ç»Ÿä¸€è®¾ç½®ï¼š`temperature=0.6`, `top_p=0.95`ã€‚
- å¤šæ•°ä»»åŠ¡ç”Ÿæˆå¤šä¸ªå“åº”ï¼ˆå¦‚ AIME ä½¿ç”¨ 16 ä¸ª rolloutï¼‰åèšåˆã€‚

#### æµ‹è¯•æ—¶æ‰©å±•ï¼ˆTTSï¼‰è®¾ç½®
- æ–¹æ³•ï¼š**DeepConf@512**ï¼ˆFu et al., 2025aï¼‰
- æ€» trace æ•°ï¼š512
- åˆå§‹ warm-upï¼š16 æ¡ trace ç”¨äºç¡®å®šç½®ä¿¡é˜ˆå€¼
- åç»­ 496 æ¡å¯ç”¨ early stoppingï¼ˆå½“æ»‘åŠ¨çª—å£å†…æœ€ä½ç½®ä¿¡ä½äºé˜ˆå€¼æ—¶åœæ­¢ï¼‰
- èšåˆç­–ç•¥ï¼šå¤šæ•°æŠ•ç¥¨ã€ç½®ä¿¡åŠ æƒç­‰ï¼ˆå‘ç°å·®å¼‚ä¸å¤§ï¼‰

#### åŸºçº¿å¯¹æ¯”æ¨¡å‹
- **7B çº§åˆ«**ï¼šQwen3-8B, DeepSeek-R1-0528-Qwen3-8B
- **ä¸­ç­‰å°ºå¯¸**ï¼šPhi-4-Reasoning-Plus-14B, Apriel-1.5-15b-Thinker, GPT-OSS-20B
- **å¤§æ¨¡å‹**ï¼šQwen3-32B, Nemotron-H-47B-Reasoning

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ ‡å‡†æ¨ç†ä»»åŠ¡è¡¨ç°ï¼ˆTables 4â€“6ï¼‰

#### æ•°å­¦æ¨ç†ï¼ˆMath Reasoningï¼‰
| æ¨¡å‹ | AIME24 | AIME25 | HMMT25 | AMO-Bench | MATH500 |
|------|--------|--------|--------|-----------|---------|
| **Falcon-H1R-7B** | **88.1%** | **83.1%** | **64.9%** | **36.3%** | **97.4%** |
| Qwen3-32B | 79.4% | 71.0% | 49.8% | 21.3% | 96.8% |
| GPT-OSS-20B | 83.3% | 84.4% | 64.8% | 26.0% | 94.8% |

> ğŸ” **äº®ç‚¹**ï¼šåœ¨ AMO-Bench ä¸Šé¢†å…ˆç¬¬äºŒå **è¶… 10 ä¸ªç™¾åˆ†ç‚¹**ï¼Œè¡¨æ˜å…¶å¤„ç†æç«¯éš¾é¢˜çš„èƒ½åŠ›æå¼ºã€‚

#### ç¼–ç¨‹ç”Ÿæˆï¼ˆCode Generationï¼‰
| æ¨¡å‹ | LCB v6 | SciCode (sub/main) | T2-Telecom | TB Hard |
|------|--------|--------------------|------------|---------|
| **Falcon-H1R-7B** | **68.6%** | 28.3 / 3.9 | 25.4 | 4.9 |
| GPT-OSS-20B | 72.0% | 34.9 / 6.2 | 60.2* | 9.9* |

> ğŸ“Œ è™½æœªç¬¬ä¸€ï¼Œä½†åœ¨ 7B å°ºå¯¸ä¸­è¡¨ç°æœ€ä½³ï¼Œæ¥è¿‘ 20B çº§åˆ«æ¨¡å‹ã€‚

#### ä¸€èˆ¬æ¨ç†ï¼ˆGeneral Reasoningï¼‰
| æ¨¡å‹ | GPQA-D | MMLU-Pro | HLE | IFBench |
|------|--------|----------|-----|--------|
| **Falcon-H1R-7B** | 61.3% | 72.1% | **11.1** | **53.4** |
| Phi-4-R-Plus-14B | 67.9% | 79.2% | 5.9 | 51.7 |

> âš ï¸ åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚ GPQAã€MMLU-Proï¼‰ç•¥é€Šäºæ›´å¤§æ¨¡å‹ï¼Œä½†æ•´ä½“ä»å…·ç«äº‰åŠ›ã€‚

---

### Test-Time Scaling å®éªŒç»“æœï¼ˆTable 7ï¼‰

ä½¿ç”¨ **DeepConf@512** æ–¹æ³•ï¼Œåœ¨ç›¸åŒè®¡ç®—é¢„ç®—ä¸‹æ¯”è¾ƒå‡†ç¡®ç‡ä¸ token æ¶ˆè€—ï¼š

| æ¨¡å‹ | AIME25 Accâ†‘ | AIME25 Tokâ†“ | AMO-Bench Accâ†‘ | AMO-Bench Tokâ†“ |
|------|-------------|--------------|----------------|----------------|
| Qwen3-32B | 86.7% | 174.8M | 28.2% | 364.8M |
| **Falcon-H1R-7B** | **96.7%** | **95.1M** | **35.9%** | **216.8M** |

> ğŸ’¡ **å…³é”®å‘ç°**ï¼š
> - åœ¨ AIME25 ä¸Šè¾¾åˆ° **96.7% å‡†ç¡®ç‡**ï¼Œè¿œè¶…å…¶ä»–æ¨¡å‹ã€‚
> - ç›¸æ¯” DeepSeek-R1-0528-Qwen3-8Bï¼Œ**token ä½¿ç”¨å‡å°‘ 38%**ã€‚
> - è¡¨æ˜å…¶ base model æ¨ç†èƒ½åŠ›å¼ºï¼Œä¸” confidence calibration å‡†ç¡®ï¼Œæ”¯æŒæ¿€è¿› early stoppingã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### SFT é˜¶æ®µå…³é”®å‘ç°
| å› ç´  | æœ€ä½³é€‰æ‹© | å½±å“ |
|------|----------|------|
| å­¦ä¹ ç‡ | 1024Ã—10â»â¶ | æ›´é«˜ LR åŠ é€Ÿæ”¶æ•›ä¸”æå‡ä¸‹æ¸¸æ€§èƒ½ |
| Rollout æ•°é‡ | n=12 | æ›´å¤šæ ·æœ¬æå‡å›°éš¾é—®é¢˜è¡¨ç° |
| æ•™å¸ˆæ¨¡å‹æ··åˆ | å•ä¸€æ•™å¸ˆä¼˜äºå¤šæ•™å¸ˆ | å¤šé£æ ¼å¯¼è‡´åˆ†å¸ƒåç§»ï¼ŒæŸå®³æ³›åŒ– |
| æ•°æ®æƒé‡ | éš¾é¢˜åŠ æƒï¼ˆ1.25â€“1.75Ã—ï¼‰ | æ˜¾è‘—æå‡ hard problem æ€§èƒ½ |
| æ•°æ®æ··åˆ | æ•°å­¦ä¸»å¯¼ + é€‚é‡ä»£ç /ç§‘å­¦ | æ•°å­¦æŠ€èƒ½è¿ç§»æ•ˆæœæœ€å¥½ |

#### RL é˜¶æ®µå…³é”®å‘ç°
| è®¾ç½® | æœ€ä½³é…ç½® | å‘ç° |
|------|----------|------|
| Group Size (G) | 16 | å¹³è¡¡å¤šæ ·æ€§ä¸æ•ˆç‡ |
| Max Length | 48K tokens | å…è®¸å……åˆ†â€œæ€è€ƒâ€æå‡æ€§èƒ½ |
| æ¸©åº¦ï¼ˆTï¼‰ | 0.85 | æ§åˆ¶æ¢ç´¢ä¸ç¨³å®šæ€§çš„å¹³è¡¡ |
| è®­ç»ƒé¡ºåº | Math Only â†’ Code | é¡ºåº Curriculum æä¾›è¾¹é™…å¢ç›Š |
| KL Penalty | Î²=0 | å…è®¸è‡ªç”±æ¢ç´¢æ—§ç­–ç•¥ä¹‹å¤–çš„è¡Œä¸º |

> âœ… æ‰€æœ‰ ablation å‡è¯æ˜ï¼š**é’ˆå¯¹æ€§çš„è®¾è®¡é€‰æ‹©å¯¹æœ€ç»ˆæ€§èƒ½è‡³å…³é‡è¦**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦ç»“è®º
1. **å°æ¨¡å‹ä¹Ÿèƒ½å®ç°å¼ºå¤§æ¨ç†èƒ½åŠ›**  
   Falcon-H1R-7B åœ¨å¤šé¡¹æ¨ç†åŸºå‡†ä¸Š**åŒ¹é…æˆ–è¶…è¶Š 2â€“7 å€å‚æ•°çš„å¤§æ¨¡å‹**ï¼Œæ‰“ç ´äº†â€œè¶Šå¤§è¶Šå¥½â€çš„æƒ¯æ€§æ€ç»´ã€‚

2. **æ•°æ®è´¨é‡å’Œè®­ç»ƒç­–ç•¥æ¯”å•çº¯æ‰©å‚æ›´é‡è¦**  
   é€šè¿‡ç²¾ç»†çš„æ•°æ®ç­›é€‰ã€éš¾åº¦æ„ŸçŸ¥åŠ æƒã€å†·å¯åŠ¨ SFT å’Œ RLVR ä¼˜åŒ–ï¼Œå¯åœ¨æœ‰é™å‚æ•°ä¸‹æœ€å¤§åŒ–æ¨ç†æ½œåŠ›ã€‚

3. **Hybrid æ¶æ„æ˜¯é«˜æ•ˆæ¨ç†çš„ç†æƒ³è½½ä½“**  
   Falcon-H1 çš„ **Transformer-Mamba æ··åˆç»“æ„**åœ¨é•¿åºåˆ—ã€é«˜ batch åœºæ™¯ä¸‹å±•ç°å‡ºå“è¶Šçš„æ¨ç†æ•ˆç‡ï¼Œç‰¹åˆ«é€‚é… TTSã€‚

4. **TTS æ•ˆç‡å–å†³äº base model èƒ½åŠ›ä¸ confidence quality**  
   Falcon-H1R ä¸ä»…å‡†ç¡®ï¼Œè€Œä¸”å…¶å†…éƒ¨ confidence ä¼°è®¡å¯é ï¼Œä½¿å¾— DeepConf å¯ä»¥å®‰å…¨åœ°å‰ªæå¼±è·¯å¾„ï¼Œæå¤§èŠ‚çœèµ„æºã€‚

5. **æ•°å­¦æ¨ç†å…·æœ‰å¼ºè¿ç§»æ€§**  
   å®éªŒè¡¨æ˜ï¼Œæ•°å­¦é¢†åŸŸçš„è®­ç»ƒæ•°æ®å¯¹ç¼–ç å’Œç§‘å­¦ä»»åŠ¡æœ‰æ­£å‘è¿ç§»ä½œç”¨ï¼Œè€Œåä¹‹åˆ™è¾ƒå¼±ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä»æœ‰å·®è·**ï¼šåœ¨ MMLU-Pro å’Œ GPQA-D ä¸Šè¡¨ç°è‰¯å¥½ä½†éæœ€ä¼˜ï¼Œè¯´æ˜å…¶è®­ç»ƒä¾§é‡æ¨ç†è€Œéå¹¿åšçŸ¥è¯†ã€‚
- **ä¾èµ–é«˜è´¨é‡æ ‡æ³¨æ•°æ®**ï¼šSFT å’Œ RL é˜¶æ®µéƒ½éœ€è¦å¤§é‡äººå·¥æˆ–è§„åˆ™éªŒè¯çš„ç­”æ¡ˆï¼Œé™åˆ¶äº†å¯æ‰©å±•æ€§ã€‚
- **æœªå…¬å¼€ RL æ•°æ®ç»†èŠ‚**ï¼šè™½ç„¶å£°æ˜æ— æ±¡æŸ“ï¼Œä½†å…·ä½“æ„å»ºæ–¹å¼æœªå®Œå…¨æŠ«éœ²ï¼Œå½±å“å¤ç°æ€§ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ¢ç´¢æ›´å°å°ºå¯¸çš„æ¨ç†æ¨¡å‹**ï¼šå°è¯• 3B æˆ– 1.5B è§„æ¨¡ä¸‹çš„å¯è¡Œæ€§ã€‚
2. **è‡ªåŠ¨åŒ–æ•°æ®åˆæˆ pipeline**ï¼šå‡å°‘å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ï¼Œæ„å»ºé—­ç¯è‡ªæˆ‘è¿›åŒ–ç³»ç»Ÿã€‚
3. **æ”¹è¿› confidence estimation æœºåˆ¶**ï¼šä½¿ early stopping æ›´ç²¾å‡†ï¼Œè¿›ä¸€æ­¥å‹ç¼©æˆæœ¬ã€‚
4. **è·¨æ¨¡æ€æ¨ç†æ‰©å±•**ï¼šå°†è¯¥æ¡†æ¶åº”ç”¨äºè§†è§‰-è¯­è¨€æˆ–å¤šæ¨¡æ€æ¨ç†ä»»åŠ¡ã€‚
5. **éƒ¨ç½²ä¼˜åŒ–ç ”ç©¶**ï¼šç ”ç©¶å¦‚ä½•åœ¨è¾¹ç¼˜è®¾å¤‡æˆ–ä½å»¶è¿ŸæœåŠ¡ä¸­éƒ¨ç½²æ­¤ç±»é«˜æ•ˆæ¨ç†æ¨¡å‹ã€‚

---

## æ€»ç»“
Falcon-H1R æˆåŠŸå±•ç¤ºäº†ï¼š**é€šè¿‡ hybrid architecture + é«˜è´¨é‡æ•°æ® + åˆ†é˜¶æ®µå¼ºåŒ–è®­ç»ƒ + é«˜æ•ˆ TTS æ–¹æ³•ï¼Œ7B çº§åˆ«çš„å°æ¨¡å‹å¯ä»¥å®ç°åª²ç¾ç”šè‡³è¶…è¶Šæ•°åäº¿å‚æ•°æ¨¡å‹çš„æ¨ç†æ€§èƒ½ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½æ¨ç†æˆæœ¬**ã€‚è¿™ä¸ºæ„å»º**é«˜æ•ˆã€å¯æ‰©å±•ã€ä½æˆæœ¬çš„é«˜çº§æ¨ç†ç³»ç»Ÿ**æä¾›äº†é‡è¦èŒƒå¼ï¼Œæ¨åŠ¨äº† SLM åœ¨å¤æ‚è®¤çŸ¥ä»»åŠ¡ä¸­çš„åº”ç”¨è¾¹ç•Œã€‚

</details>

---

### 7. [KV-Embedding: Training-free Text Embedding via Internal KV Re-routing in Decoder-only LLMs](https://arxiv.org/abs/2601.01046)

**Authors**: Yixuan Tang, Yi Yang  
**Category**: cs.CL  
**Published**: 2026-01-06  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.01046v1  

#### Abstract
While LLMs are powerful embedding backbones, their application in training-free settings faces two structural challenges: causal attention restricts early tokens from accessing subsequent context, and the next-token prediction objective biases representations toward generation rather than semantic c...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# KV-Embedding: Training-free Text Embedding via Internal KV Re-routing in Decoder-only LLMs è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**decoder-only LLMsåœ¨è®­ç»ƒè‡ªç”±ï¼ˆtraining-freeï¼‰æ–‡æœ¬åµŒå…¥ä»»åŠ¡ä¸­çš„ä¸¤ä¸ªç»“æ„æ€§ç¼ºé™·**ï¼š
1. **å› æœæ³¨æ„åŠ›ï¼ˆcausal attentionï¼‰é™åˆ¶**ï¼šæ—©æœŸtokenæ— æ³•è®¿é—®åç»­ä¸Šä¸‹æ–‡ï¼Œå¯¼è‡´ä¿¡æ¯ä¸å¯¹ç§°ï¼ˆinformation asymmetryï¼‰ï¼Œä¾‹å¦‚â€œthe bank of the riverâ€ä¸­ï¼Œâ€œbankâ€çš„è¡¨ç¤ºå› æœªè§â€œriverâ€è€Œäº§ç”Ÿæ­§ä¹‰ã€‚
2. **ä¸‹ä¸€è¯é¢„æµ‹ç›®æ ‡åå·®ï¼ˆnext-token prediction biasï¼‰**ï¼šæœ€ç»ˆtokenå€¾å‘äºç”Ÿæˆè€Œéè¯­ä¹‰å‹ç¼©ï¼Œå½±å“å…¶ä½œä¸ºå¥å­è¡¨ç¤ºçš„è´¨é‡ã€‚

è¿™äº›é™åˆ¶ä½¿å¾—ä¼ ç»Ÿçš„æ± åŒ–ç­–ç•¥ï¼ˆå¦‚mean poolingæˆ–last-token poolingï¼‰æ•ˆæœå—é™ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šKV-Embedding
ä½œè€…æå‡º **KV-Embedding**ï¼Œä¸€ç§æ— éœ€è®­ç»ƒå³å¯ä»å†»ç»“çš„decoder-only LLMä¸­æå–é«˜è´¨é‡æ–‡æœ¬åµŒå…¥çš„æ–¹æ³•ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **å†…éƒ¨KVé‡è·¯ç”±ï¼ˆInternal KV Re-routingï¼‰**ï¼šåˆ©ç”¨æ¨¡å‹è‡ªèº«åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­å·²è®¡ç®—å‡ºçš„**æœ€åä¸€å±‚å„å±‚çš„Key-Valueï¼ˆKVï¼‰çŠ¶æ€**ï¼Œå°†å…¶ä½œä¸ºå…¨å±€ä¸Šä¸‹æ–‡æ‘˜è¦ï¼Œå¹¶é€šè¿‡**prependæ–¹å¼æ³¨å…¥åˆ°æ¯ä¸€å±‚çš„æ³¨æ„åŠ›æœºåˆ¶ä¸­**ï¼Œä½¿æ‰€æœ‰tokenéƒ½èƒ½åœ¨ä¸€ä¸ªå‰å‘ä¼ é€’ä¸­è®¿é—®åºåˆ—çº§ä¸Šä¸‹æ–‡ã€‚
- **å‹ç¼©å¯¼å‘æç¤ºï¼ˆCompression-Oriented Promptingï¼‰**ï¼šè®¾è®¡ç‰¹å®šæ¨¡æ¿ï¼ˆå¦‚â€œCompress the context in one word:â€ï¼‰å¼•å¯¼æ¨¡å‹å°†æœ€ç»ˆtokenç”¨äºè¯­ä¹‰å‹ç¼©ï¼Œç¼“è§£ç”Ÿæˆåå·®ã€‚
- **åŸºäºå†…åœ¨ç»´åº¦ï¼ˆIntrinsic Dimensionality, IDï¼‰çš„è‡ªåŠ¨å±‚é€‰æ‹©**ï¼šé€šè¿‡ä¼°è®¡æ¯å±‚è¡¨ç¤ºçš„IDï¼Œè‡ªåŠ¨è¯†åˆ«è¯­ä¹‰æœ€æµ“ç¼©çš„å±‚ï¼ˆå³IDæœ€ä½çš„å±‚ï¼‰ï¼Œä»…åœ¨è¿™äº›å±‚è¿›è¡ŒKVé‡è·¯ç”±ï¼Œç¡®ä¿æ–¹æ³•å…·æœ‰**æ¨¡å‹æ— å…³æ€§ï¼ˆmodel-agnosticï¼‰**ï¼Œæ— éœ€æ‰‹åŠ¨è°ƒå‚ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ç¼ºé™· | KV-Embeddingä¼˜åŠ¿ |
|------|------|------------------|
| **PromptEOL** | ä»…ç¼“è§£ç”Ÿæˆåå·®ï¼Œä¸è§£å†³ä¿¡æ¯ä¸å¯¹ç§° | åŒæ—¶è§£å†³ä¸¤å¤§é—®é¢˜ |
| **Echo** | è¾“å…¥é‡å¤å¯¼è‡´åºåˆ—é•¿åº¦ç¿»å€ï¼Œè®¡ç®—å¤æ‚åº¦$O(n^2)$ï¼Œå­˜åœ¨â€œlost-in-the-middleâ€é—®é¢˜ | ä¸ä¿®æ”¹è¾“å…¥ï¼Œä¿æŒåŸåºåˆ—é•¿åº¦ |
| **Token Prepending** | å¼•å…¥OOVç‰¹æ®Štokenï¼Œè¡¨ç¤ºä¸å¯æ§ | åˆ©ç”¨æ¨¡å‹å†…éƒ¨å·²æœ‰çš„KVçŠ¶æ€ï¼Œæ›´ç¨³å®šå¯é  |

KV-Embeddingé€šè¿‡**å†…éƒ¨çŠ¶æ€æ“çºµï¼ˆinternal state manipulationï¼‰** è€Œéè¾“å…¥ä¿®æ”¹ï¼Œå®ç°äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„è®­ç»ƒè‡ªç”±åµŒå…¥æ–¹æ¡ˆã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **MTEB (Massive Text Embedding Benchmark)**ï¼šæ¶µç›–7å¤§ç±»ä»»åŠ¡ï¼ˆSTSã€Retrievalã€Classificationã€Pair Classificationã€Clusteringã€Rerankingã€Summarizationï¼‰ï¼Œå…±42ä¸ªæ•°æ®é›†ï¼Œç”¨äºç»¼åˆè¯„ä¼°åµŒå…¥è´¨é‡ã€‚
- **LoCoV1 (Long-Context Retrieval Benchmark)**ï¼šä¸“é—¨æµ‹è¯•é•¿ä¸Šä¸‹æ–‡æ£€ç´¢èƒ½åŠ›ï¼Œæ–‡æ¡£è¢«æˆªæ–­ä¸º1024ã€2048ã€4096 tokensï¼Œç”¨äºéªŒè¯æ–¹æ³•åœ¨é•¿åºåˆ—ä¸‹çš„é²æ£’æ€§ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼šåœ¨ä¸‰ç§ä¸»æµdecoder-only LLMä¸Šæµ‹è¯•ï¼š
  - Qwen3-4B
  - Mistral-7B-Instruct-v0.1
  - Llama-3.1-8B-Instruct
- **è¯„ä¼°æ¨¡å¼**ï¼šzero-shot, training-free setting
- **ä¸»è¦æŒ‡æ ‡**ï¼š
  - MTEBï¼šå„ç±»ä»»åŠ¡ä¸»æŒ‡æ ‡å¹³å‡å¾—åˆ†ï¼ˆå¦‚STSç”¨Spearmanç›¸å…³ç³»æ•°ï¼ŒRetrievalç”¨NDCG@10ï¼‰
  - LoCoV1ï¼šNDCG@10
- **å®ç°ç»†èŠ‚**ï¼š
  - ä½¿ç”¨TwoNNä¼°è®¡å™¨è®¡ç®—Intrinsic Dimensionality
  - KVé‡è·¯ç”±å±‚é€‰æ‹©åŸºäºIDæœ€å°å€¼åŒºåŸŸ
  - æœ€ç»ˆåµŒå…¥é‡‡ç”¨hybrid poolingï¼ˆlast-tokenä¸mean poolingå¹³å‡åå½’ä¸€åŒ–ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Last Token**ï¼šç›´æ¥ä½¿ç”¨æœ€ç»ˆtokençš„éšè—çŠ¶æ€
- **Mean Pooling**ï¼šå¯¹æ‰€æœ‰tokenéšè—çŠ¶æ€å–å¹³å‡
- **PromptEOL**ï¼šä½¿ç”¨æç¤ºå¼•å¯¼è¯­ä¹‰å‹ç¼©
- **Echo**ï¼šè¾“å…¥é‡å¤ä»¥æ¨¡æ‹ŸåŒå‘ä¸Šä¸‹æ–‡
- **Token Prepending**ï¼šæ’å…¥ç‰¹æ®Štokenä¼ æ’­ä¸Šä¸‹æ–‡
- **w/o KV Re-routing**ï¼šæ¶ˆèå®éªŒï¼Œä»…ä¿ç•™æç¤ºä½†ç¦ç”¨KVé‡è·¯ç”±

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆMTEBå¹³å‡å¾—åˆ†ï¼‰
| æ–¹æ³• | Qwen3-4B | Mistral-7B | Llama-3.1-8B |
|------|----------|------------|---------------|
| PromptEOL | 0.4478 | 0.4537 | 0.4702 |
| Echo | 0.4375 | 0.5008 | 0.5034 |
| **KV-Embedding** | **0.4937** | **0.5341** | **0.5270** |

- åœ¨ä¸‰ä¸ªbackboneä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰è®­ç»ƒè‡ªç”±æ–¹æ³•ï¼Œ**æœ€é«˜æå‡è¾¾10%**ã€‚

### é•¿ä¸Šä¸‹æ–‡è¡¨ç°ï¼ˆLoCoV1, NDCG@10 @4096 tokensï¼‰
| æ–¹æ³• | Qwen3-4B | Mistral-7B | Llama-3.1-8B |
|------|----------|------------|---------------|
| PromptEOL | 0.1286 | 0.0442 | 0.1285 |
| Echo | 0.1318 | 0.0591 | 0.1191 |
| **KV-Embedding** | **0.1822** | **0.2068** | **0.2404** |

- åœ¨4096é•¿åº¦ä¸‹ä»ä¿æŒå¼ºåŠ²æ€§èƒ½ï¼Œ**å¤§å¹…è¶…è¶ŠåŸºçº¿ï¼ˆ1.3â€“3.5å€ï¼‰**ï¼Œè¡¨æ˜å…¶æœ‰æ•ˆç¼“è§£äº†é•¿åºåˆ—ä¸­çš„ä¸Šä¸‹æ–‡ç¨€é‡Šé—®é¢˜ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **ç§»é™¤KVé‡è·¯ç”±ï¼ˆw/o KV Re-routingï¼‰**ï¼š
  - åœ¨Mistral-7Bä¸Šå¹³å‡åˆ†ä»0.5341é™è‡³0.4502ï¼ˆâ†“8.4%ï¼‰
  - è¡¨æ˜**KVé‡è·¯ç”±æ˜¯æ€§èƒ½æå‡çš„ä¸»è¦é©±åŠ¨åŠ›**
- **æ³¨æ„åŠ›åç½®ï¼ˆAttention Bias bï¼‰**ï¼š
  - è®¾ç½®$b=1.0$æ—¶æ€§èƒ½æœ€ä¼˜ï¼ˆå›¾2ï¼‰
  - $b>3.0$æ—¶æ€§èƒ½ä¸‹é™ï¼Œè¯´æ˜è¿‡åº¦ä¾èµ–å…¨å±€æ‘˜è¦ä¼šæŸå®³å±€éƒ¨ç»†èŠ‚
- **å±‚é€‰æ‹©ç­–ç•¥**ï¼š
  - åŸºäºIDçš„é€‰æ‹©ä¼˜äºå‡åŒ€åˆ’åˆ†ï¼ˆearly/middle/late layersï¼‰
  - åœ¨Mistral-7Bä¸Šï¼ŒIDé€‰æ‹©7å±‚ï¼ˆ13-19ï¼‰ä¼˜äºmiddle-thirdçš„10å±‚ç­–ç•¥
- **æ± åŒ–ç­–ç•¥**ï¼š
  - Hybrid poolingï¼ˆlast + meanï¼‰è¡¨ç°æœ€ä½³ï¼Œä¼˜äºå•ç‹¬last-tokenæˆ–mean pooling

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **decoder-only LLMå†…éƒ¨è•´å«å¼ºå¤§çš„æ½œåœ¨è¡¨ç¤ºèƒ½åŠ›**ï¼Œå¯é€šè¿‡KVçŠ¶æ€é‡è·¯ç”±æ¿€æ´»ã€‚
2. **å†…éƒ¨çŠ¶æ€æ“çºµä¼˜äºè¾“å…¥ä¿®æ”¹**ï¼šKV-Embeddingåœ¨ä¸æ”¹å˜è¾“å…¥çš„å‰æä¸‹ï¼Œå®ç°äº†å…¨å±€ä¸Šä¸‹æ–‡è®¿é—®ï¼Œé¿å…äº†Echoå’ŒToken Prependingçš„å‰¯ä½œç”¨ã€‚
3. **IDæ˜¯æœ‰æ•ˆçš„å±‚é€‰æ‹©æŒ‡æ ‡**ï¼šåŸºäºintrinsic dimensionalityçš„è‡ªåŠ¨åŒ–ç­–ç•¥èƒ½å‡†ç¡®è¯†åˆ«è¯­ä¹‰æœ€æµ“ç¼©çš„å±‚ï¼Œå®ç°è·¨æ¶æ„é€šç”¨æ€§ã€‚
4. **KV-Embeddingåœ¨é•¿åºåˆ—ä¸‹ä¾ç„¶ç¨³å¥**ï¼šåœ¨4096 tokensé•¿åº¦ä¸‹ä»ä¿æŒé«˜æ€§èƒ½ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•çš„â€œcontext dilutionâ€é—®é¢˜ã€‚
5. **åµŒå…¥ç©ºé—´æ›´ä¼˜**ï¼šåˆ†ææ˜¾ç¤ºKV-Embeddingäº§ç”Ÿçš„åµŒå…¥ç©ºé—´æ›´å…·**å„å‘åŒæ€§ï¼ˆisotropicï¼‰**ï¼Œalignmentå’ŒuniformityæŒ‡æ ‡æ›´ä¼˜ï¼ˆè¡¨5ï¼‰ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **æ¨ç†å»¶è¿Ÿå¢åŠ **ï¼šKVé‡è·¯ç”±å¼•å…¥é¢å¤–è®¡ç®—ï¼Œç›¸æ¯”æ ‡å‡†æ± åŒ–æœ‰ä¸€å®šå»¶è¿Ÿå¼€é”€ã€‚
2. **æ€§èƒ½ä¸Šé™ä½äºç›‘ç£å¾®è°ƒæ–¹æ³•**ï¼šä½œä¸ºè®­ç»ƒè‡ªç”±æ–¹æ³•ï¼Œå…¶æ€§èƒ½ä»ä¸åŠç»è¿‡contrastive fine-tuningçš„æœ‰ç›‘ç£æ¨¡å‹ã€‚
3. **ä¾èµ–æ¨¡å‹å†…éƒ¨å‡ ä½•ç»“æ„**ï¼šè™½ç„¶IDç­–ç•¥æå‡äº†æ³›åŒ–æ€§ï¼Œä½†ä¸åŒæ¶æ„çš„IDè½¨è¿¹å·®å¼‚ä»éœ€è¿›ä¸€æ­¥ç ”ç©¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢KVé‡è·¯ç”±åœ¨å…¶ä»–ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚few-shot learningï¼‰ä¸­çš„åº”ç”¨ã€‚
- å°†è¯¥æ€æƒ³æ‰©å±•è‡³encoder-decoderæ¶æ„æˆ–å…¶ä»–ç”Ÿæˆæ¨¡å‹ã€‚
- ç»“åˆè½»é‡çº§å¾®è°ƒï¼ˆå¦‚prefix tuningï¼‰è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚
- ç ”ç©¶æ›´é«˜æ•ˆçš„KVç¼“å­˜ç®¡ç†æœºåˆ¶ä»¥é™ä½å»¶è¿Ÿã€‚

---

> **æ€»ç»“**ï¼šKV-Embeddingæå‡ºäº†ä¸€ç§æ–°é¢–çš„è®­ç»ƒè‡ªç”±æ–‡æœ¬åµŒå…¥æ¡†æ¶ï¼Œé€šè¿‡**å†…éƒ¨KVé‡è·¯ç”±**è§£å†³äº†decoder-only LLMåœ¨åµŒå…¥ä»»åŠ¡ä¸­çš„æ ¹æœ¬æ€§æŒ‘æˆ˜ã€‚å…¶å®éªŒå……åˆ†ã€è®¾è®¡å·§å¦™ï¼Œåœ¨MTEBå’ŒLoCoV1ä¸Šå‡å–å¾—SOTAæ€§èƒ½ï¼Œä¸ºè§£é”å¤§è¯­è¨€æ¨¡å‹çš„è¡¨ç¤ºæ½œåŠ›æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 8. [SuperSFL: Resource-Heterogeneous Federated Split Learning with Weight-Sharing Super-Networks](https://arxiv.org/abs/2601.02092)

**Authors**: Abdullah Al Asif, Sixing Yu, Juan Pablo Munoz, Arya Mazaheri, Ali Jannesari  
**Category**: cs.DC  
**Published**: 2026-01-06  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.02092v1  

#### Abstract
SplitFed Learning (SFL) combines federated learning and split learning to enable collaborative training across distributed edge devices; however, it faces significant challenges in heterogeneous environments with diverse computational and communication capabilities. This paper proposes \textit{Super...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# SuperSFL: Resource-Heterogeneous Federated Split Learning with Weight-Sharing Super-Networks â€”â€” è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹**èµ„æºå¼‚æ„è¾¹ç¼˜ç¯å¢ƒä¸‹çš„è”é‚¦å­¦ä¹ ï¼ˆFederated Learning, FLï¼‰æŒ‘æˆ˜**ï¼Œç‰¹åˆ«æ˜¯ **Split Federated Learning (SFL)** åœ¨ä»¥ä¸‹æ–¹é¢çš„å±€é™æ€§ï¼š

- **è®¾å¤‡å¼‚æ„æ€§ï¼ˆDevice Heterogeneityï¼‰**ï¼šä¼ ç»Ÿ SFL å‡è®¾æ‰€æœ‰å®¢æˆ·ç«¯å…·æœ‰ç›¸ä¼¼çš„è®¡ç®—ã€å†…å­˜å’Œé€šä¿¡èƒ½åŠ›ï¼Œè¿™åœ¨çœŸå®è¾¹ç¼˜åœºæ™¯ï¼ˆå¦‚æ‰‹æœºã€ä¼ æ„Ÿå™¨ç­‰æ··åˆè®¾å¤‡ï¼‰ä¸­ä¸ç°å®ã€‚
- **æœåŠ¡å™¨ä¾èµ–æ€§å¼º**ï¼šSFL è¦æ±‚å®¢æˆ·ç«¯å¿…é¡»ç­‰å¾…æœåŠ¡å™¨è¿”å›æ¢¯åº¦æ‰èƒ½ç»§ç»­è®­ç»ƒï¼Œä¸€æ—¦ç½‘ç»œä¸­æ–­æˆ–æœåŠ¡å™¨ä¸å¯ç”¨ï¼Œè®­ç»ƒå³åœæ»ï¼Œç¼ºä¹å®¹é”™èƒ½åŠ›ã€‚
- **æ”¶æ•›é€Ÿåº¦æ…¢ã€é€šä¿¡å¼€é”€å¤§**ï¼šç”±äºæ¨¡å‹åˆ†å‰²å›ºå®šä¸”ç¼ºä¹æœ‰æ•ˆä¼˜åŒ–æœºåˆ¶ï¼ŒSFL éœ€è¦æ›´å¤šé€šä¿¡è½®æ¬¡ï¼Œå¯¼è‡´é«˜é€šä¿¡æˆæœ¬å’Œé•¿è®­ç»ƒæ—¶é—´ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **SuperSFL**ï¼Œä¸€ç§ç»“åˆ **Federated Learning** å’Œ **Split Learning** çš„æ–°å‹æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### âœ… **Weight-Sharing Super-Networkï¼ˆæƒé‡å…±äº«è¶…ç½‘ç»œï¼‰**
- æ„å»ºä¸€ä¸ªå…¨å±€çš„â€œè¶…ç½‘ç»œâ€ï¼ˆsuper-networkï¼‰ï¼Œæ‰€æœ‰å®¢æˆ·ç«¯ä»ä¸­æå–**è¿ç»­å‰ç¼€å­ç½‘ç»œ**ä½œä¸ºæœ¬åœ°ç¼–ç å™¨ã€‚
- å­ç½‘ç»œæ·±åº¦æ ¹æ®å®¢æˆ·ç«¯çš„ **memory capacity** å’Œ **communication latency** åŠ¨æ€åˆ†é…ï¼Œå®ç°èµ„æºæ„ŸçŸ¥çš„ä¸ªæ€§åŒ–æ¨¡å‹éƒ¨ç½²ã€‚

#### âœ… **Three-Phase Gradient Fusion (TPGF)**
- ä¸€ç§ä¸‰é˜¶æ®µæ¢¯åº¦èåˆæœºåˆ¶ï¼Œåè°ƒæœ¬åœ°ä¸æœåŠ¡å™¨ç«¯çš„ç›‘ç£ä¿¡å·ï¼š
  1. **Phase 1**: å®¢æˆ·ç«¯ä½¿ç”¨è½»é‡çº§åˆ†ç±»å™¨è¿›è¡Œæœ¬åœ°ç›‘ç£ï¼Œç”Ÿæˆå±€éƒ¨æ¢¯åº¦ï¼›
  2. **Phase 2**: æœåŠ¡å™¨å®Œæˆæ·±å±‚æ¨ç†å¹¶åä¼ æ¢¯åº¦ï¼›
  3. **Phase 3**: å®¢æˆ·ç«¯å°†æœ¬åœ°æ¢¯åº¦ä¸æœåŠ¡å™¨æ¢¯åº¦æŒ‰æŸå¤±åŠ æƒèåˆï¼Œæ›´æ–°æœ¬åœ°ç¼–ç å™¨ã€‚
- ä¼˜åŠ¿ï¼šæå‡æµ…å±‚ç¼–ç å™¨çš„è®­ç»ƒç¨³å®šæ€§ï¼ŒåŠ é€Ÿæ”¶æ•›ã€‚

#### âœ… **Fault-Tolerant Client-Side Classifier**
- æ¯ä¸ªå®¢æˆ·ç«¯é…å¤‡ä¸€ä¸ªè½»é‡çº§æœ¬åœ°åˆ†ç±»å™¨ï¼Œåœ¨æœåŠ¡å™¨ä¸å¯è¾¾æ—¶è¿›å…¥â€œfallback modeâ€ï¼Œè‡ªä¸»è¿›è¡Œæœ¬åœ°è®­ç»ƒã€‚
- å½“è¿æ¥æ¢å¤åï¼Œé€šè¿‡èšåˆæœºåˆ¶æ— ç¼åŒæ­¥è¿›åº¦ï¼Œé¿å…è®­ç»ƒä¸­æ–­ã€‚

#### âœ… **Collaborative Client-Server Aggregation**
- è®¾è®¡äº†ä¸€ç§ç»“æ„å¯¹é½ä¸”æ€§èƒ½æ„ŸçŸ¥çš„å‚æ•°èšåˆç­–ç•¥ï¼š
  - æŒ‰å±‚èšåˆä¸åŒæ·±åº¦çš„å®¢æˆ·ç«¯ç¼–ç å™¨å‚æ•°ï¼›
  - æƒé‡ç”±å®¢æˆ·ç«¯æ¨¡å‹æ·±åº¦å’Œè®­ç»ƒæŸå¤±å…±åŒå†³å®šï¼›
  - å¼•å…¥ä¸€è‡´æ€§æ­£åˆ™é¡¹ï¼ˆconsistency regularizationï¼‰é˜²æ­¢å®¢æˆ·ç«¯ä¸æœåŠ¡å™¨å‚æ•°åç¦»è¿‡å¤§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | SuperSFL ä¼˜åŠ¿ |
|------|----------------|
| **é€‚åº”æ€§** | æ”¯æŒé«˜åº¦å¼‚æ„è®¾å¤‡ï¼Œæ— éœ€ç»Ÿä¸€æ¨¡å‹ç»“æ„ |
| **æ•ˆç‡** | å‡å°‘é€šä¿¡è½®æ•°ï¼ˆ2â€“5Ã—ï¼‰ã€é™ä½æ€»é€šä¿¡é‡ï¼ˆæœ€é«˜ 20Ã—ï¼‰ã€ç¼©çŸ­è®­ç»ƒæ—¶é—´ï¼ˆæœ€é«˜ 13Ã—ï¼‰ |
| **é²æ£’æ€§** | æ”¯æŒé—´æ­‡æ€§é€šä¿¡å¤±è´¥ä¸‹çš„æŒç»­è®­ç»ƒ |
| **æ”¶æ•›æ€§** | æ›´å¿«è¾¾åˆ°æ›´é«˜å‡†ç¡®ç‡ï¼Œå°¤å…¶åœ¨ non-IID æ•°æ®ä¸‹è¡¨ç°ä¼˜å¼‚ |
| **èƒ½æ•ˆ** | å•ä½ç²¾åº¦èƒ½è€—æ›´ä½ï¼Œç¢³æ’æ”¾æ›´å°‘ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **CIFAR-10** å’Œ **CIFAR-100**
- å¹¿æ³›ç”¨äº FL åŸºå‡†æµ‹è¯•ï¼Œé€‚åˆè¯„ä¼°éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆnon-IIDï¼‰åœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚

### **å®éªŒè®¾ç½®**

| å‚æ•° | è®¾ç½® |
|------|------|
| æ¨¡å‹æ¶æ„ | Vision Transformer (ViT-16) |
| å®¢æˆ·ç«¯æ•°é‡ | 50 å’Œ 100 |
| æ•°æ®åˆ’åˆ† | Dirichlet åˆ†å¸ƒï¼ˆæµ“åº¦å‚æ•° Î±=0.5ï¼‰ï¼Œæ¨¡æ‹Ÿ non-IID åœºæ™¯ |
| è®¾å¤‡å¼‚æ„æ¨¡æ‹Ÿ | å†…å­˜ï¼š[2, 16] GB å‡åŒ€é‡‡æ ·ï¼›å»¶è¿Ÿï¼š[20, 200] ms å‡åŒ€é‡‡æ · |
| ç¡¬ä»¶å¹³å° | NVIDIA A10 / A100 GPUï¼ˆç‰©ç†åŒæ„ï¼Œé€»è¾‘å¼‚æ„ï¼‰ |
| åˆå§‹é€šä¿¡é…ç½® | å®¢æˆ·ç«¯ä»…ä¸ŠæŠ¥ä¸€æ¬¡ memory å’Œ latencyï¼Œåç»­ä¸å†åŠ¨æ€æ¢æµ‹ |

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ |
|--------|---------|
| **å‡†ç¡®æ€§** | æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡ï¼ˆTop-1 Accï¼‰ |
| **æ•ˆç‡** | è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡æ‰€éœ€çš„ï¼š<br>â€¢ é€šä¿¡è½®æ•°ï¼ˆCommunication Roundsï¼‰<br>â€¢ æ€»é€šä¿¡æˆæœ¬ï¼ˆMBï¼‰<br>â€¢ ç«¯åˆ°ç«¯è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰ |
| **èƒ½æ•ˆ** | â€¢ å¹³å‡åŠŸè€—ï¼ˆWï¼‰<br>â€¢ åŠŸè€—æ¯ç²¾åº¦ç‚¹ï¼ˆPower/Accuracy, W/%ï¼‰<br>â€¢ COâ‚‚ æ’æ”¾é‡ï¼ˆgï¼‰ |
| **é²æ£’æ€§** | ä¸åŒæœåŠ¡å™¨å¯ç”¨ç‡ä¸‹çš„å‡†ç¡®ç‡å˜åŒ–ï¼ˆ0% ~ 100%ï¼‰ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **SFL (Split Federated Learning)**ï¼šæ ‡å‡†è”é‚¦æ‹†åˆ†å­¦ä¹ ï¼Œå›ºå®šæ‹†åˆ†ç‚¹ã€‚
- **DFL (Dynamic Federated Learning)**ï¼šæ”¯æŒåŠ¨æ€å‚ä¸çš„è”é‚¦å­¦ä¹ æ–¹æ³•ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table Iï¼‰**

| Dataset | Clients | Target Acc (%) | Method | Rounds | Comm. Cost (MB) | Training Time (s) |
|--------|--------|----------------|--------|--------|------------------|--------------------|
| CIFAR-10 | 50 | 70 | SFL | 11 | 9075 | 6127 |
|          |     |    | DFL | 9  | 2305 | 2650 |
|          |     |    | **SSFL** | **5**  | **466** | **595** |
| CIFAR-10 | 100 | 75 | SFL | 19 | 21463 | 12168 |
|          |      |    | DFL | 16 | 15472 | 14368 |
|          |      |    | **SSFL** | **12** | **939** | **1010** |
| CIFAR-100 | 50 | 75 | SFL | 35 | 28938 | 21284 |
|           |     |    | DFL | 27 | 7909  | 9796  |
|           |     |    | **SSFL** | **15** | **7194** | **8766** |
| CIFAR-100 | 100 | 80 | SFL | 100 | 165358 | 114955 |
|            |       |    | DFL | 34  | 13638  | 15328  |
|            |       |    | **SSFL** | **22** | **9719** | **8926** |

> æ³¨ï¼šSSFL å³ SuperSFL

#### **æ€§èƒ½æå‡æ€»ç»“**
- **é€šä¿¡è½®æ•°å‡å°‘**ï¼š2â€“5Ã— å¿«äº SFLï¼Œ1.2â€“1.8Ã— å¿«äº DFL
- **é€šä¿¡æˆæœ¬é™ä½**ï¼šæœ€é«˜è¾¾ **20Ã—**ï¼ˆCIFAR-10, 100 clientsï¼‰
- **è®­ç»ƒæ—¶é—´ç¼©çŸ­**ï¼šæœ€é«˜è¾¾ **13Ã—**ï¼ˆCIFAR-10, 50 clientsï¼‰

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **å‡†ç¡®æ€§æ–¹é¢**ï¼š
  - SuperSFL åœ¨ CIFAR-10 ä¸Šå¯è¾¾ **>97%** å‡†ç¡®ç‡ï¼Œæ˜¾è‘—é«˜äº SFLï¼ˆ~75%ï¼‰å’Œ DFLï¼ˆ~76%ï¼‰ã€‚
  - åœ¨ CIFAR-100 ä¸Šä¹Ÿç¨³å®šé¢†å…ˆï¼Œæœ€ç»ˆå‡†ç¡®ç‡é«˜å‡ºçº¦ **2â€“3%**ã€‚

- **æ”¶æ•›é€Ÿåº¦**ï¼š
  - å¦‚å›¾ 3 æ‰€ç¤ºï¼ŒSuperSFL åœ¨æå°‘æ•°é€šä¿¡è½®å†…å³å¯å¿«é€Ÿæ”¶æ•›ï¼Œè€Œ SFL æ”¶æ•›ç¼“æ…¢ç”šè‡³éš¾ä»¥è¾¾æ ‡ã€‚

- **èƒ½æ•ˆè¡¨ç°ï¼ˆè§ Table IIIï¼‰**ï¼š
  - **CIFAR-10**ï¼šSuperSFL çš„ Power/Accuracy ä¸º **5.09 W/%**ï¼Œä¼˜äº SFLï¼ˆ14.78ï¼‰å’Œ DFLï¼ˆ5.17ï¼‰ã€‚
  - **CIFAR-100**ï¼šè™½ç»å¯¹åŠŸè€—è¾ƒé«˜ï¼Œä½†å•ä½ç²¾åº¦èƒ½è€—ä»ä¼˜äº SFLï¼Œæ¥è¿‘ DFLæ°´å¹³ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

#### **TPGF æ¶ˆèåˆ†æï¼ˆå›¾ 6ï¼‰**
- **å®Œæ•´ TPGF**ï¼šå‡†ç¡®ç‡ **96.93%**
- **ç§»é™¤ Loss-Based åŠ æƒ**ï¼šé™è‡³ **91.47%**
- **ç§»é™¤ Depth-Based åŠ æƒ**ï¼šè¿›ä¸€æ­¥é™è‡³ **88.66%**
- **ç­‰æƒèåˆï¼ˆEqual Fusionï¼‰**ï¼šæœ€ä½ **85.89%**

ğŸ‘‰ ç»“è®ºï¼š**æ·±åº¦æ„ŸçŸ¥ + æŸå¤±å¯é æ€§æ„ŸçŸ¥** æ˜¯ TPGF æˆåŠŸçš„å…³é”®ã€‚

#### **æœåŠ¡å™¨å¯ç”¨æ€§å½±å“ï¼ˆTable IIIï¼‰**
| æœåŠ¡å™¨æ¢¯åº¦å¯ç”¨ç‡ | å‡†ç¡®ç‡ï¼ˆCIFAR-10ï¼‰ |
|------------------|---------------------|
| 100%             | 95.58 Â± 1.08        |
| 70%              | 93.81 Â± 2.59        |
| 50%              | 93.12 Â± 2.11        |
| 20%              | 91.03 Â± 1.17        |
| 10%              | 89.77 Â± 2.22        |
| **0%ï¼ˆå®Œå…¨æ— æœåŠ¡å™¨ï¼‰** | **86.36 Â± 3.25** |

ğŸ‘‰ ç»“è®ºï¼šå³ä½¿å®Œå…¨æ²¡æœ‰æœåŠ¡å™¨å‚ä¸ï¼ŒSuperSFL ä»å¯æ”¶æ•›è‡³åˆç†ç²¾åº¦ï¼Œå±•ç°å‡ºæå¼ºçš„**å®¹é”™èƒ½åŠ›å’Œå»ä¸­å¿ƒåŒ–æ½œåŠ›**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **SuperSFL æ˜¾è‘—æå‡äº†å¼‚æ„è¾¹ç¼˜ç¯å¢ƒä¸­ FL çš„æ•ˆç‡ä¸é²æ£’æ€§**ï¼š
   - é€šè¿‡åŠ¨æ€å­ç½‘ç»œåˆ†é…å’Œ TPGFï¼Œå®ç°äº†æ›´å¿«æ”¶æ•›å’Œæ›´ä½é€šä¿¡å¼€é”€ã€‚
   
2. **TPGF æ˜¯åŠ é€Ÿæ”¶æ•›çš„æ ¸å¿ƒæœºåˆ¶**ï¼š
   - èåˆæœ¬åœ°ä¸æœåŠ¡å™¨æ¢¯åº¦ï¼Œç¼“è§£æµ…å±‚ç¼–ç å™¨ç›‘ç£ä¸è¶³çš„é—®é¢˜ã€‚

3. **æ•…éšœå®¹å¿è®¾è®¡æœ‰æ•ˆåº”å¯¹ä¸ç¨³å®šç½‘ç»œ**ï¼š
   - å®¢æˆ·ç«¯å¯åœ¨æ–­è¿æœŸé—´æŒç»­è®­ç»ƒï¼Œç³»ç»Ÿæ•´ä½“å¯é æ€§å¤§å¹…æå‡ã€‚

4. **èƒ½é‡æ•ˆç‡ä¼˜äºä¸»æµæ–¹æ³•**ï¼š
   - å°½ç®¡ç¬æ—¶åŠŸè€—ç•¥é«˜ï¼Œä½†ç”±äºè®­ç»ƒæ—¶é—´å¤§å¹…ç¼©çŸ­ï¼Œ**æ€»èƒ½è€—å’Œç¢³è¶³è¿¹æ›´ä½**ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- **è¶…å‚æ•°ä¾èµ–ç»éªŒè®¾å®š**ï¼šèµ„æºåˆ†é…ç³»æ•°ï¼ˆÎ±, Î²ï¼‰å’Œæ­£åˆ™åŒ–å‚æ•°ï¼ˆÎ», Tï¼‰ä¸ºç»éªŒé€‰æ‹©ï¼Œç¼ºä¹ç†è®ºæŒ‡å¯¼ã€‚
- **åŸºäºæ¨¡æ‹Ÿå¼‚æ„æ€§**ï¼šå®éªŒåœ¨åŒæ„ç¡¬ä»¶ä¸Šæ¨¡æ‹Ÿå¼‚æ„èµ„æºï¼Œæœªåœ¨çœŸå®å¤šæ ·åŒ–çš„è¾¹ç¼˜è®¾å¤‡é›†ç¾¤ä¸­éªŒè¯ã€‚
- **æ¨¡å‹ç»“æ„é™åˆ¶**ï¼šç›®å‰ä»…é€‚ç”¨äº Vision Transformer ç±»ç»“æ„ï¼Œå¯¹å…¶ä»–æ¨¡å‹ï¼ˆå¦‚ CNNã€RNNï¼‰çš„é€‚é…éœ€è¿›ä¸€æ­¥ç ”ç©¶ã€‚
- **éšç§ä¿æŠ¤æœªæ·±å…¥æ¢è®¨**ï¼šæœªé›†æˆå·®åˆ†éšç§ï¼ˆDPï¼‰æˆ–å®‰å…¨å¤šæ–¹è®¡ç®—ï¼ˆSMPCï¼‰ç­‰å¢å¼ºéšç§çš„æŠ€æœ¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **ç³»ç»ŸåŒ–è¶…å‚æ•°è°ƒä¼˜æœºåˆ¶**ï¼šå»ºç«‹ principled çš„èµ„æºè¯„åˆ†ä¸å‚æ•°é€‰æ‹©å‡†åˆ™ã€‚
2. **çœŸå®è¾¹ç¼˜è®¾å¤‡éªŒè¯**ï¼šåœ¨ç‰©ç†å¼‚æ„è®¾å¤‡ç¾¤ï¼ˆå¦‚æ ‘è“æ´¾ã€æ‰‹æœºã€åµŒå…¥å¼è®¾å¤‡ï¼‰ä¸Šéƒ¨ç½²æµ‹è¯•ã€‚
3. **é«˜çº§ä¸ªæ€§åŒ–æœºåˆ¶**ï¼šç»“åˆ clustered FL æˆ– hypernetwork è¿›è¡Œæ›´ç»†ç²’åº¦çš„æ¨¡å‹å®šåˆ¶ã€‚
4. **éšç§å¢å¼ºé›†æˆ**ï¼šå¼•å…¥ DPã€secure aggregation ç­‰æŠ€æœ¯ä»¥æ»¡è¶³ä¸¥æ ¼éšç§éœ€æ±‚ã€‚
5. **æ‰©å±•è‡³å…¶ä»–ä»»åŠ¡**ï¼šåº”ç”¨äº NLPã€è¯­éŸ³è¯†åˆ«ç­‰éè§†è§‰é¢†åŸŸã€‚

---

## âœ… æ€»ç»“

**SuperSFL** æ˜¯ä¸€é¡¹é¢å‘**èµ„æºå¼‚æ„è¾¹ç¼˜ç¯å¢ƒ**çš„é«˜æ•ˆã€é²æ£’ã€èŠ‚èƒ½çš„è”é‚¦æ‹†åˆ†å­¦ä¹ æ¡†æ¶ã€‚å®ƒé€šè¿‡ **weight-sharing super-network + TPGF + fault-tolerant classifier + structured aggregation** å››å¤§ç»„ä»¶ï¼ŒæˆåŠŸè§£å†³äº†ä¼ ç»Ÿ SFL ä¸­çš„è®¾å¤‡ä¸é€‚é…ã€æ”¶æ•›æ…¢ã€å®¹é”™å·®ç­‰é—®é¢˜ã€‚å®éªŒè¯æ˜å…¶åœ¨ **å‡†ç¡®æ€§ã€é€šä¿¡æ•ˆç‡ã€è®­ç»ƒé€Ÿåº¦ã€èƒ½æ•ˆ** ç­‰å¤šä¸ªç»´åº¦å…¨é¢è¶…è¶Š SFL å’Œ DFLï¼Œæ˜¯æ¨åŠ¨ FL åœ¨çœŸå®è¾¹ç¼˜åœºæ™¯è½åœ°çš„é‡è¦è¿›å±•ã€‚

</details>

---

### 9. [BigSUMO: A Scalable Framework for Big Data Traffic Analytics and Parallel Simulation](https://arxiv.org/abs/2601.02286)

**Authors**: Rahul Sengupta, Nooshin Yousefzadeh, Manav Sanghvi, Yash Ranjan, Anand Rangarajan, Sanjay Ranka, Yashaswi Karnati, Jeremy Dilmore, Tushar Patel, Ryan Casburn  
**Category**: cs.DC  
**Published**: 2026-01-06  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.02286v1  

#### Abstract
With growing urbanization worldwide, efficient management of traffic infrastructure is critical for transportation agencies and city planners. It is essential to have tools that help analyze large volumes of stored traffic data and make effective interventions. To address this need, we present ``Big...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*BigSUMO: A Scalable Framework for Big Data Traffic Analytics and Parallel Simulation*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
éšç€åŸå¸‚åŒ–è¿›ç¨‹åŠ å¿«ï¼Œäº¤é€šç®¡ç†éƒ¨é—¨é¢ä¸´æµ·é‡å¼‚æ„äº¤é€šæ•°æ®ï¼ˆå¦‚ATSPMã€è½¨è¿¹æ•°æ®ï¼‰çš„å¤„ç†æŒ‘æˆ˜ã€‚ç°æœ‰ç³»ç»Ÿå¾€å¾€å±€é™äºå•ä¸€æ•°æ®æ¨¡æ€æˆ–ç‰¹å®šåº”ç”¨åœºæ™¯ï¼Œç¼ºä¹ä¸€ä¸ª**ç«¯åˆ°ç«¯ã€å¯æ‰©å±•ã€å¼€æºä¸”æ”¯æŒæè¿°æ€§ä¸å¤„æ–¹æ€§åˆ†æ**çš„åŸå¸‚çº§äº¤é€šåˆ†ææ¡†æ¶ã€‚

BigSUMO æ­£æ˜¯ä¸ºäº†è§£å†³ä»¥ä¸‹æ ¸å¿ƒé—®é¢˜è€Œæå‡ºï¼š
- å¦‚ä½•é«˜æ•ˆæ•´åˆé«˜åˆ†è¾¨ç‡ **ATSPM æ•°æ®**ï¼ˆloop detector å’Œä¿¡å·çŠ¶æ€ï¼‰ä¸ç¨€ç–çš„ **probe trajectory æ•°æ®**ï¼›
- å¦‚ä½•å®ç°åŸå¸‚å°ºåº¦ä¸‹çš„å®æ—¶äº¤é€šçŠ¶æ€æ„ŸçŸ¥ä¸å¼‚å¸¸äº‹ä»¶æ£€æµ‹ï¼ˆinterruption detectionï¼‰ï¼›
- å¦‚ä½•åŸºäºçœŸå®æ•°æ®é©±åŠ¨å¤§è§„æ¨¡å¹¶è¡Œä»¿çœŸï¼Œè¿›è¡Œâ€œwhat-ifâ€åœºæ™¯æµ‹è¯•ä»¥ä¼˜åŒ–äº¤é€šæ§åˆ¶ç­–ç•¥ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

1. **ç«¯åˆ°ç«¯å¯æ‰©å±•åˆ†ææ¡†æ¶ BigSUMO**
   - é›†æˆæ•°æ®é¢„å¤„ç†ã€æè¿°æ€§åˆ†æã€ä¸­æ–­æ£€æµ‹ã€å¾®ä»¿çœŸï¼ˆSUMOï¼‰ä¸å¤„æ–¹æ€§åˆ†æäºä¸€ä½“ï¼›
   - æ”¯æŒæ¨¡å—åŒ–è®¾è®¡ï¼Œå…è®¸çµæ´»æ›¿æ¢ä¸åŒç®—æ³•ç»„ä»¶ï¼ˆå¦‚ outlier detection ç®—æ³•ï¼‰ã€‚

2. **åŸºäºç©ºé—´æ©ç çš„ç©ºé—´è£å‰ªæœºåˆ¶ï¼ˆSpatial Masksï¼‰**
   - åˆ©ç”¨ FDOT çš„ GIS æ•°æ®è‡ªåŠ¨ç”Ÿæˆé“è·¯ç¼“å†²åŒºä¸äº¤å‰å£åœ†å½¢æ©ç ï¼›
   - è‡ªåŠ¨è£å‰ªè½¨è¿¹æ•°æ®è‡³æ„Ÿå…´è¶£åŒºåŸŸï¼ˆå¦‚ç‰¹å®šäº¤å‰å£ï¼‰ï¼Œæå‡åˆ†æç²¾åº¦ä¸æ•ˆç‡ã€‚

3. **åŒæºä¸­æ–­æ£€æµ‹ç³»ç»Ÿ**
   - ç»“åˆ **ATSPM æ•°æ®**ï¼ˆç›¸ä½çº§è½¦æµç»Ÿè®¡ï¼‰ä¸ **trajectory æ•°æ®**ï¼ˆä¸ªä½“è¡Œä¸ºå»ºæ¨¡ï¼‰è¿›è¡Œäº’è¡¥å¼å¼‚å¸¸è¯†åˆ«ï¼›
   - è½¨è¿¹å±‚é¢é‡‡ç”¨ **Angle-Based Outlier Detection (ABOD)** å¯¹å½’ä¸€åŒ–ç‰¹å¾å‘é‡è¿›è¡Œå¼‚å¸¸æ£€æµ‹ã€‚

4. **å¹¶è¡ŒåŒ–çš„ SUMO å¾®ä»¿çœŸæ¶æ„**
   - ä½¿ç”¨ Python `multiprocessing` å®ç°æ•°ç™¾ä¸ª SUMO ä»¿çœŸçš„å¹¶è¡Œæ‰§è¡Œï¼›
   - æ”¯æŒåœ¨æ™®é€šäº‘æœåŠ¡å™¨ä¸Šè¿è¡Œï¼Œæ— éœ€å•†ä¸šè½¯ä»¶è®¸å¯ï¼ˆå¦‚ VISSIMï¼‰ã€‚

5. **å¼€æ”¾æ€§å’Œå¯éƒ¨ç½²æ€§**
   - å®Œå…¨åŸºäºå¼€æºå·¥å…·é“¾æ„å»ºï¼ˆPandas, GeoPandas, MovingPandas, SUMO, PyOD, Jupyterç­‰ï¼‰ï¼›
   - å¯éƒ¨ç½²äºä»»æ„æ”¯æŒ Python çš„äº‘å¹³å°ï¼Œæˆæœ¬ä½ã€æ˜“ç»´æŠ¤ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ç°æœ‰ç³»ç»Ÿå±€é™ | BigSUMO çš„ä¼˜åŠ¿ |
|------|--------------|----------------|
| æ•°æ®èåˆ | å¤šä¾èµ–å•ä¸€æ•°æ®æºï¼ˆè§†é¢‘æˆ– loop detectorï¼‰ | èåˆ ATSPM + probe trajectoryï¼Œå¢å¼ºä¸Šä¸‹æ–‡ç†è§£ |
| åˆ†æç²’åº¦ | å¤šä¸ºå®è§‚æˆ–ä¸­è§‚åˆ†æ | æ”¯æŒå¾®è§‚ä¸ªä½“è½¨è¿¹å»ºæ¨¡ä¸ä»¿çœŸ |
| æ‰©å±•æ€§ | å°é—­ç³»ç»Ÿæˆ–éœ€æ˜‚è´µè®¸å¯è¯ï¼ˆå¦‚ VISSIMï¼‰ | å¼€æºã€å¯å¹¶è¡Œã€é€‚åˆåŸå¸‚çº§éƒ¨ç½² |
| å¼‚å¸¸æ£€æµ‹ | ä»…åŸºäºæµé‡çªå˜ | å¼•å…¥è½¨è¿¹è¡Œä¸ºå»ºæ¨¡ + ABODï¼Œæ•æ‰æ½œåœ¨é£é™©è¡Œä¸º |
| ä»¿çœŸèƒ½åŠ› | å•æ¬¡ä»¿çœŸè€—æ—¶é•¿ï¼Œéš¾ä»¥å‚æ•°æœç´¢ | å¹¶è¡Œè¿è¡Œç™¾æ¬¡ä»¥ä¸Šä»¿çœŸï¼Œæ”¯æŒ grid search ä¼˜åŒ– |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†

| æ•°æ®ç±»å‹ | æ¥æº | ç‰¹å¾ |
|--------|------|-------|
| **ATSPM æ•°æ®** | Florida Department of Transportation (FDOT) | åŒ…å« loop detector è½¦è¾†è®¡æ•°ã€ä¿¡å·ç¯ç›¸ä½çŠ¶æ€ï¼Œæ—¶é—´ç²’åº¦ç²¾ç»† |
| **Probe Trajectory æ•°æ®** | å•†ä¸šä¾›åº”å•†ï¼ˆéç½‘çº¦è½¦ï¼‰ | æ—¶é—´åˆ†è¾¨ç‡ 3 ç§’ï¼Œç©ºé—´ç²¾åº¦ ~1 ç±³ï¼›æ¯æ—¥çº¦ 17,000â€“22,000 æ¡è¡Œç¨‹ï¼›è¦†ç›–ä½›ç½—é‡Œè¾¾å·ä¸‰ä¸ªå¿ï¼›2024 å¹´ä¸¤ä¸ªæœˆæ•°æ® |
| **æ¸—é€ç‡ï¼ˆPenetration Rateï¼‰** | â€” | å½“å‰ä»…ä¸º 3%â€“7%ï¼Œé™åˆ¶äº†è½¨è¿¹å¯†åº¦ |
| **GIS æ•°æ®** | FDOT SunStore æ•°æ®åº“ | åŒ…æ‹¬ Basemap Route Roads å’Œ Intersectionsï¼Œç”¨äºç”Ÿæˆ spatial masks |

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸æµç¨‹

#### ï¼ˆ1ï¼‰æ•°æ®å¤„ç†æµæ°´çº¿
- **è½¨è¿¹é¢„å¤„ç†**ï¼šè¿‡æ»¤ç†„ç«çŠ¶æ€ã€çŸ­æ—…ç¨‹ï¼ˆ<2åˆ†é’Ÿï¼‰ã€çŸ­è·ç¦»ï¼ˆ<150ç±³ï¼‰è½¨è¿¹ï¼›
- **ç©ºé—´è£å‰ª**ï¼šåˆ©ç”¨ QGIS ç”Ÿæˆ 35m é“è·¯ç¼“å†² + 125m äº¤å‰å£åœ†ç¼“å†²ï¼Œé€šè¿‡ Clip æ“ä½œæå–ç›®æ ‡åŒºåŸŸè½¨è¿¹ï¼›
- **ç‰¹å¾æå–**ï¼šå¯¹æ¯æ¡è½¨è¿¹è®¡ç®—ï¼š
  - åœè½¦æ—¶é—´ï¼ˆStopped Timeï¼‰
  - å¹³å‡é€Ÿåº¦ï¼ˆAvg. Speedï¼‰
  - é€Ÿåº¦æ ‡å‡†å·®ï¼ˆStd. Speedï¼‰
  - è¡Œç¨‹æ—¶é—´ï¼ˆTravel Timeï¼‰

#### ï¼ˆ2ï¼‰ä¸­æ–­æ£€æµ‹ç³»ç»Ÿ
- æ„é€ æ¯ä¸ªè½¨è¿¹çš„ **normalized feature vector**ï¼›
- ä½¿ç”¨ **ABOD**ï¼ˆAngle-Based Outlier Detectionï¼‰è¯†åˆ«åç¦»æ­£å¸¸æ¨¡å¼çš„è½¨è¿¹ï¼›
- ä¸Šä¸‹æ–‡å¯¹æ¯”ï¼šä½¿ç”¨åŒä¸€æ—¶ç©ºä½ç½®ï¼ˆåŒå‘¨ã€åŒæ—¶é—´æ®µï¼‰çš„å†å²æ•°æ®ä½œä¸ºåŸºå‡†ï¼›
- å·¥å…·åº“ï¼šPyODï¼›
- è¿è¡Œæ•ˆç‡ï¼šå•ä¸ªäº¤å‰å£å…¨æµç¨‹çº¦ 2â€“3 åˆ†é’Ÿï¼ˆCPU å¤šçº¿ç¨‹å¹¶è¡Œï¼‰ã€‚

#### ï¼ˆ3ï¼‰SUMO å¾®ä»¿çœŸé…ç½®
- **ç½‘ç»œæ„å»º**ï¼šä½¿ç”¨ NETEDIT æˆ–ä» OpenStreetMap å¯¼å…¥ï¼›
- **æ ¡å‡†ï¼ˆCalibrationï¼‰**ï¼š
  - **Flow Calibration**ï¼šç»“åˆ ATSPM è½¦æµæ€»é‡ + è½¨è¿¹æ¨æ–­çš„ OD çŸ©é˜µ â†’ ä½¿ç”¨ routeSampler ç”Ÿæˆç¬¦åˆå®é™…å‡ºè¡Œè·¯å¾„çš„è½¦è¾†æµï¼›
  - **Speed Calibration**ï¼šæ ¹æ®è½¨è¿¹è§‚æµ‹çš„æœ€å¤§é€Ÿåº¦åˆ†å¸ƒè°ƒæ•´ SUMO çš„ `speedFactor` å‚æ•°ï¼›
  - **Signal Configuration**ï¼šå¯¼å…¥ NEMA ç›¸ä½é€»è¾‘ï¼ˆRing-and-Barrierï¼‰åŠç»¿ç¯æ—¶é•¿ï¼›
- **å¹¶è¡Œä»¿çœŸ**ï¼šPython `multiprocessing` å¯åŠ¨å¤šä¸ª SUMO å®ä¾‹ï¼Œæ¨¡æ‹Ÿä¸åŒå‚æ•°ç»„åˆï¼ˆå¦‚å‘¨æœŸé•¿åº¦ã€æœ€å°/æœ€å¤§ç»¿ç¯æ—¶é—´ï¼‰ï¼›
- è¾“å‡ºæ ¼å¼ï¼šXMLï¼Œä¾¿äºåç»­åˆ†æã€‚

---

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡

| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| æè¿°æ€§åˆ†æ | - åœè½¦æ—¶é—´ç›´æ–¹å›¾<br>- æ’é˜Ÿé•¿åº¦æ¦‚ç‡åˆ†å¸ƒ<br>- è½¬å‘ç§»åŠ¨çŸ©é˜µï¼ˆOrigin-Destination Matrixï¼‰<br>- åˆ¶åŠ¨äº‹ä»¶çƒ­ç‚¹å›¾ |
| ä¸­æ–­æ£€æµ‹ | - Outlier å‘é‡æ•°é‡ä¸ç©ºé—´èšé›†æ€§<br>- å®æ—¶ä¸­æ–­æ¦‚ç‡çƒ­åŠ›å›¾ç”Ÿæˆèƒ½åŠ› |
| ä»¿çœŸæ€§èƒ½ | - å•æ¬¡ä»¿çœŸè€—æ—¶ï¼ˆ10 ä¸ªäº¤å‰å£ï¼Œ1å°æ—¶ â‰ˆ 3â€“6åˆ†é’Ÿï¼‰<br>- å¹¶è¡Œååé‡ï¼ˆå¯åŒæ—¶è¿è¡Œä¸Šç™¾æ¬¡ï¼‰<br>- æ€§èƒ½æŒ‡æ ‡ä¼˜åŒ–æ•ˆæœï¼ˆå¦‚ Corridor Travel Time ä¸‹é™ï¼‰ |

---

### ğŸ”€ åŸºçº¿æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | å±æ€§ | BigSUMO ä¼˜åŠ¿ |
|------|------|-------------|
| **ReTime [å¯¹æ¯”æåŠ]** | ä½¿ç”¨ VISSIM å¹¶è¡Œä»¿çœŸä¼˜åŒ–ä¿¡å·é…æ—¶ | BigSUMO ä½¿ç”¨å¼€æº SUMOï¼Œé¿å…å•†ä¸šæˆæƒè´¹ç”¨ï¼ŒåŒæ ·æ”¯æŒ grid search |
| **ä¼ ç»Ÿ ATSPM åˆ†æç³»ç»Ÿ** | ä»…åŸºäºå›ºå®šæ£€æµ‹å™¨æ•°æ® | BigSUMO èåˆè½¨è¿¹æ•°æ®ï¼Œæä¾›æ›´ä¸°å¯Œçš„è¡Œä¸ºæ´å¯Ÿï¼ˆå¦‚æ’é˜Ÿä½ç½®ã€åˆ¶åŠ¨è¡Œä¸ºï¼‰ |
| **çº¯è§†é¢‘åˆ†æç³»ç»Ÿ [1][2][3]** | ä¾èµ–æ‘„åƒå¤´éƒ¨ç½²ï¼Œè§†é‡å—é™ | BigSUMO ä¸ä¾èµ–ä¸“ç”¨ç¡¬ä»¶ï¼Œæ›´å…·æ‰©å±•æ€§ |

> æ³¨ï¼šæœ¬æ–‡æœªæä¾›ä¸¥æ ¼çš„å®šé‡å¯¹æ¯”è¡¨æ ¼ï¼Œè€Œæ˜¯é€šè¿‡åŠŸèƒ½ä¸æ¶æ„æ¯”è¾ƒä½“ç°ä¼˜åŠ¿ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

| æ¨¡å— | ç»“æœ |
|------|------|
| **è½¨è¿¹å¤„ç†æ•ˆç‡** | å•äº¤å‰å£å…¨æµç¨‹ï¼ˆè£å‰ªâ†’ç‰¹å¾æå–â†’outlier detectionï¼‰è€—æ—¶çº¦ **2â€“3 åˆ†é’Ÿ**ï¼ˆCPUï¼‰ |
| **å¹¶è¡Œä»¿çœŸèƒ½åŠ›** | åœ¨é€šç”¨äº‘å®ä¾‹ä¸Šå¯è½»æ¾è¿è¡Œ **æ•°ç™¾æ¬¡ SUMO ä»¿çœŸ**ï¼Œæ¯æ¬¡æ¨¡æ‹Ÿ 1 å°æ—¶äº¤é€šæµ |
| **ä»¿çœŸé€Ÿåº¦** | 10 ä¸ªäº¤å‰å£çš„èµ°å»Šï¼Œ1 å°æ—¶ä»¿çœŸè€—æ—¶ **3â€“6 åˆ†é’Ÿ**ï¼ˆå–å†³äºäº¤é€šè´Ÿè·ï¼‰ |
| **æ•°æ®è§„æ¨¡** | å¤„ç†è·¨åº¦ä¸º **2ä¸ªæœˆ** çš„è½¨è¿¹æ•°æ®ï¼Œæ—¥å‡è¶… **2ä¸‡æ¡ journey** |

---

### ğŸ“Š ä¸»è¦å¯è§†åŒ–ä¸åˆ†æç»“æœï¼ˆè§ Figuresï¼‰

- **Fig. 2**: åœè½¦æ—¶é—´ç›´æ–¹å›¾æ˜¾ç¤ºå¤šæ•°åœè½¦æŒç»­æ—¶é—´ < 150 ç§’ï¼Œç¬¦åˆå…¸å‹ä¿¡å·å‘¨æœŸï¼›
- **Fig. 3 & 4**: æ˜¾ç¤ºè½¦è¾†å¸¸åœ¨åœæ­¢çº¿å‰åœè½¦ï¼Œåæ˜ ä¸Šæ¸¸æ’é˜Ÿå½±å“ï¼›
- **Fig. 5**: Origin-Destination çŸ©é˜µæ­ç¤ºå„æ–¹å‘è½¬å‘æ¯”ä¾‹ï¼Œå¯ç”¨äºä»¿çœŸè¾“å…¥ï¼›
- **Fig. 6**: ä¸åŒèµ·æ­¢æ–¹å‘çš„å¹³å‡è¡Œç¨‹æ—¶é—´å·®å¼‚æ˜¾è‘—ï¼ˆå¦‚ Southbound â†’ Eastbound è¾¾ 121.3sï¼‰ï¼›
- **Fig. 7**: æ’é˜Ÿé•¿åº¦åˆ†å¸ƒè¡¨æ˜ Eastbound å’Œ Southbound æ–¹å‘æ’é˜Ÿæ›´é•¿ï¼›
- **Fig. 8**: åˆ¶åŠ¨äº‹ä»¶çƒ­ç‚¹é›†ä¸­åœ¨æŸäº›è¿›å£é“ï¼Œæç¤ºæ½œåœ¨å®‰å…¨éšæ‚£ï¼›
- **Fig. 9 & 10**: å±•ç¤ºæ•´ä¸ªä¸­æ–­æ£€æµ‹ä¸ä»¿çœŸç³»ç»Ÿçš„æ¨¡å—åŒ–æµç¨‹ã€‚

---

### âŒ æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰
- æ–‡ä¸­**æœªæ˜ç¡®å¼€å±•æ¶ˆèå®éªŒ**ï¼Œä½†æŒ‡å‡ºï¼š
  - å½“å‰ **ATSPM-based interruption detection æ›´å¯é **ï¼›
  - è½¨è¿¹-based æ–¹æ³•å—é™äºä½ CV penetration rateï¼ˆ3%-7%ï¼‰ï¼›
  - è‹¥æœªæ¥ connected vehicle æ¸—é€ç‡ä¸Šå‡ï¼Œè½¨è¿¹æ–¹æ³•æ€§èƒ½æœ‰æœ›æå‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **BigSUMO æˆåŠŸå®ç°äº†åŸå¸‚çº§äº¤é€šæ•°æ®åˆ†æä¸ä»¿çœŸçš„é—­ç¯**ï¼š
   - ä»åŸå§‹æ•°æ® â†’ æè¿°æ€§åˆ†æ â†’ å¼‚å¸¸æ£€æµ‹ â†’ ä»¿çœŸéªŒè¯ â†’ å†³ç­–å»ºè®®ï¼Œå½¢æˆå®Œæ•´é“¾æ¡ã€‚

2. **å¤šæºæ•°æ®èåˆæ˜¾è‘—æå‡åˆ†ææ·±åº¦**ï¼š
   - ATSPM æä¾›å®è§‚æµé‡è¶‹åŠ¿ï¼›
   - Probe trajectories æä¾›å¾®è§‚è¡Œä¸ºç»†èŠ‚ï¼ˆå¦‚æ’é˜Ÿä½ç½®ã€æ€¥åˆ¹ç‚¹ï¼‰ã€‚

3. **å¼€æºæŠ€æœ¯æ ˆå…·å¤‡é«˜åº¦å¯æ‰©å±•æ€§ä¸å®ç”¨æ€§**ï¼š
   - å¯åœ¨ commodity cloud ä¸Šéƒ¨ç½²ï¼Œé€‚åˆä¸­å°å‹äº¤é€šæœºæ„ä½¿ç”¨ï¼›
   - æ”¯æŒ Jupyter notebook äº¤äº’å¼åˆ†æï¼Œä¾¿äºå®šåˆ¶ä¸å…±äº«ã€‚

4. **å¹¶è¡Œä»¿çœŸæå¤§æå‡äº†æ”¿ç­–è¯„ä¼°æ•ˆç‡**ï¼š
   - æ”¯æŒå¿«é€Ÿæµ‹è¯•å¤šç§ä¿¡å·é…æ—¶æ–¹æ¡ˆï¼Œè¾…åŠ© corridor-level ä¼˜åŒ–ã€‚

5. **è½¨è¿¹æ•°æ®å¯ç”¨äºè®­ç»ƒ Deep Learning æ¨¡å‹**ï¼š
   - BigSUMO å·²è¢«ç”¨äºç”Ÿæˆ GNN å’Œ Digital Twin æ¨¡å‹æ‰€éœ€çš„å¤§è§„æ¨¡ labeled æ•°æ®é›†ï¼ˆå¦‚ [11][12][13]ï¼‰ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

| å±€é™ | è¯´æ˜ |
|------|------|
| **ä½ Connected Vehicle æ¸—é€ç‡** | å½“å‰ probe æ•°æ®ä»…è¦†ç›– 3%-7% è½¦è¾†ï¼Œå¯¼è‡´è½¨è¿¹ç¨€ç–ï¼Œå½±å“å¼‚å¸¸æ£€æµ‹çµæ•åº¦ |
| **è½¨è¿¹éšç§å¤„ç†å¸¦æ¥çš„ä¿¡æ¯ç¼ºå¤±** | å•†å®¶éšè—éƒ¨åˆ†ä¸­é—´ç‚¹ï¼Œè™½åˆæ³•ä½†ä»é™ä½è½¨è¿¹å®Œæ•´æ€§ |
| **å°šæœªå®Œå…¨è‡ªåŠ¨åŒ–éƒ¨ç½²** | spatial mask ç”Ÿæˆä»éœ€ä¸€å®šäººå·¥å¹²é¢„ï¼ˆå¦‚ buffer å‚æ•°è®¾å®šï¼‰ |
| **ç¼ºä¹ä¸¥æ ¼é‡åŒ–è¯„ä¼°** | ç¼ºå°‘ä¸ ground truthï¼ˆå¦‚äº‹æ•…è®°å½•ï¼‰å¯¹æ¯”çš„ precision/recall æŒ‡æ ‡ |

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æå‡ trajectory-based interruption detection çš„å¯é æ€§**ï¼š
   - éšç€ V2X/V2V åŸºç¡€è®¾æ–½æ™®åŠï¼Œé¢„æœŸ CV penetration å°†æé«˜ï¼Œå±Šæ—¶å¯å¤§å¹…æå‡è½¨è¿¹åˆ†æè´¨é‡ã€‚

2. **é›†æˆæ›´å¤šä¼ æ„Ÿå™¨æ¨¡æ€**ï¼š
   - è®¡åˆ’èåˆ videoã€LiDARã€DSRC ç­‰å¤šæ¨¡æ€æ•°æ®ï¼Œæ„å»ºæ›´å…¨é¢çš„æ„ŸçŸ¥å±‚ã€‚

3. **å‘å±•è‡ªé€‚åº”ä¿¡å·æ§åˆ¶ç³»ç»Ÿ**ï¼š
   - å°† BigSUMO è¾“å‡ºæ¥å…¥ adaptive signal control ç³»ç»Ÿï¼Œå®ç°åŠ¨æ€å“åº”ã€‚

4. **æ¨åŠ¨æ•°å­—å­ªç”Ÿåº”ç”¨**ï¼š
   - æ„å»º real-time digital twinï¼Œå®ç°åŸå¸‚äº¤é€šçš„å®æ—¶é•œåƒä¸é¢„æµ‹ã€‚

5. **ä»£ç å¼€æºè®¡åˆ’**ï¼š
   - ä½œè€…æ‰¿è¯ºé€æ­¥æ¸…ç†å¹¶å‘å¸ƒæºç è‡³ GitHubï¼ˆgithub.com/NSH2022/BigSUMOï¼‰ã€‚

---

## æ€»ç»“

> **BigSUMO æ˜¯ä¸€ä¸ªé¢å‘æœªæ¥çš„ã€å¼€æºçš„åŸå¸‚äº¤é€šæ™ºèƒ½åˆ†æåŸºç¡€è®¾æ–½**ã€‚å®ƒä¸ä»…è§£å†³äº†å½“å‰äº¤é€šå¤§æ•°æ®â€œçœ‹å¾—è§ä½†éš¾ç”¨å¥½â€çš„ç—›ç‚¹ï¼Œè¿˜ä¸º AI é©±åŠ¨çš„æ™ºæ…§åŸå¸‚æä¾›äº†å¼ºå¤§çš„æ•°æ®å¼•æ“ä¸ä»¿çœŸå¹³å°ã€‚å°½ç®¡å—é™äºå½“å‰æ•°æ®è´¨é‡ï¼Œå…¶è®¾è®¡ç†å¿µã€æ¨¡å—åŒ–æ¶æ„ä¸å¹¶è¡Œèƒ½åŠ›ä½¿å…¶æå…·æ¨å¹¿ä»·å€¼ï¼Œå°¤å…¶é€‚ç”¨äºå¸Œæœ›ä½æˆæœ¬æ„å»ºæ™ºèƒ½äº¤é€šç³»ç»Ÿçš„æ”¿åºœæœºæ„ä¸ç ”ç©¶å›¢é˜Ÿã€‚

</details>

---

### 10. [Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios](https://arxiv.org/abs/2601.01857)

**Authors**: Defei Xia, Bingfeng Pi, Shenbin Zhang, Song Hua, Yunfei Wei, Lei Zuo  
**Category**: cs.AI  
**Published**: 2026-01-06  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.01857v1  

#### Abstract
As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based ag...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªä¸»æ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **å›ºå®šæç¤ºï¼ˆpromptï¼‰å¯¼è‡´æ„å›¾ç†è§£åå·®**ï¼šé™æ€æˆ–é€šç”¨çš„æç¤ºæ— æ³•é€‚åº”ä»»åŠ¡çŠ¶æ€å˜åŒ–ï¼Œæ˜“é€ æˆè¡Œä¸ºä¸ç¨³å®šå’Œè¾“å‡ºä¸ä¸€è‡´ã€‚
- **å·¥å…·è°ƒç”¨ç¼ºä¹ä¸Šä¸‹æ–‡æ„ŸçŸ¥**ï¼šä¾èµ–é¢„å®šä¹‰å·¥å…·åˆ—è¡¨æˆ–æ‰‹å·¥è§„åˆ™ï¼Œéš¾ä»¥åœ¨æ¨¡ç³Šæˆ–å¤šé¢†åŸŸåœºæ™¯ä¸‹å‡†ç¡®é€‰æ‹©åˆé€‚å·¥å…·ï¼Œå¯¼è‡´å†—ä½™æˆ–é”™è¯¯è°ƒç”¨ã€‚
- **é•¿å¯¹è¯ä¸­çš„ä¸Šä¸‹æ–‡è†¨èƒ€**ï¼šå†å²å¯¹è¯ç§¯ç´¯è¿‡å¤šå†—ä½™ä¿¡æ¯ï¼Œå¢åŠ tokenæ¶ˆè€—ã€ç¨€é‡Šå…³é”®ä¿¡å·ï¼Œå½±å“æ¨ç†è´¨é‡ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†æ™ºèƒ½ä½“åœ¨å¤æ‚ã€å¤šè½®ã€çœŸå®ä¸–ç•Œä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§ã€æ•ˆç‡å’Œç¨³å®šæ€§ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**
æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸º **Jenius-Agent** çš„ç«¯åˆ°ç«¯æ™ºèƒ½ä½“æ¡†æ¶ï¼Œå›´ç»•â€œç»éªŒé©±åŠ¨â€çš„ä¼˜åŒ–ç†å¿µï¼Œé›†æˆä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼š

#### ï¼ˆ1ï¼‰**è‡ªé€‚åº”æç¤ºç”Ÿæˆï¼ˆAdaptive Prompt Generationï¼‰**
- ç»“åˆè§’è‰²æŒ‡ä»¤ã€ä»»åŠ¡çŠ¶æ€å’Œç”¨æˆ·ä¸Šä¸‹æ–‡åŠ¨æ€ç”Ÿæˆç³»ç»Ÿæç¤ºã€‚
- å¼•å…¥å››ç±»è¯­ä¹‰åˆ†ç±»ï¼ˆç¤¾äº¤äº’åŠ¨ã€åˆ›æ„ç”Ÿæˆã€äº‹å®å›å¿†ã€å·¥å…·å¢å¼ºæ¨ç†ï¼‰ï¼Œå®ç°æ„å›¾è·¯ç”±ä¸å“åº”æ ¼å¼å®šåˆ¶ã€‚
- åŠ å…¥å®‰å…¨å®¡æŸ¥æœºåˆ¶ï¼Œé˜²æ­¢å¹»è§‰ã€åè§å’Œéæ³•å†…å®¹è¾“å‡ºã€‚

> âœ… *ä¼˜åŠ¿*ï¼šæå‡ä»»åŠ¡å¯¹é½åº¦ï¼Œå‡å°‘è¯¯åˆ¤ï¼Œå¢å¼ºé²æ£’æ€§å’Œå®‰å…¨æ€§ã€‚

#### ï¼ˆ2ï¼‰**ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å·¥å…·ç¼–æ’ï¼ˆContext-Aware Tool Orchestrationï¼‰**
- å°†æ‰€æœ‰å·¥å…·è¡¨ç¤ºä¸ºé«˜ç»´åµŒå…¥ï¼ˆQwen3 Embeddingï¼‰ï¼Œé€šè¿‡è¯­ä¹‰ç›¸ä¼¼æ€§è¿›è¡Œæ£€ç´¢ã€‚
- è®¾è®¡ä¸‰æ­¥ç­›é€‰æµç¨‹ï¼š
  1. Top-Må€™é€‰æ£€ç´¢ï¼ˆåŸºäºç›¸ä¼¼åº¦æ’åºï¼‰
  2. åŸºäºæ‹ç‚¹æ£€æµ‹çš„è¿‡æ»¤ï¼ˆç»“åˆç›¸ä¼¼åº¦è·³è·ƒ + Kneedleç®—æ³•ï¼‰
  3. åŠ¨æ€æˆªæ–­å¹¶è¡¥å…¨è‡³N=min(N_jump, N_kneedle)ï¼Œè‹¥ä¸è¶³åˆ™å–Top-10

> âœ… *ä¼˜åŠ¿*ï¼šæ˜¾è‘—é™ä½æ— å…³å·¥å…·è°ƒç”¨ç‡ï¼Œåœ¨å™ªå£°ç¯å¢ƒä¸‹ä»èƒ½ç²¾å‡†åŒ¹é…ç”¨æˆ·æ„å›¾ã€‚

#### ï¼ˆ3ï¼‰**åˆ†å±‚è®°å¿†ç®¡ç†ï¼ˆHierarchical Memory Managementï¼‰**
- **å¯¹è¯çº§å¯¹é½**ï¼šç»´æŠ¤`Human â†’ AI â†’ Tool â†’ AI`çš„æ ‡å‡†äº¤äº’æ¨¡å¼ï¼Œè‡ªåŠ¨ä¿®å¤ç¼ºå¤±æ¶ˆæ¯ï¼ˆå¦‚å› APIå¤±è´¥å¯¼è‡´ç©ºToolMessageï¼‰ã€‚
- **ä¼šè¯çº§å‹ç¼©**ï¼šå½“æ¶ˆæ¯æ•°è¶…è¿‡é˜ˆå€¼Kæ—¶ï¼Œå°†æ—©æœŸå†å²æ‘˜è¦ä¸º`SystemMessage`ï¼Œä¿ç•™æœ€æ–°ä¸€è½®å®Œæ•´ä¸Šä¸‹æ–‡ã€‚
- æ‘˜è¦ä»…è¦†ç›–ä»é¦–ä¸ª`HumanMessage`åˆ°å€’æ•°ç¬¬äºŒä¸ª`HumanMessage`ä¹‹é—´çš„éƒ¨åˆ†ï¼Œç¡®ä¿æœ€è¿‘äº¤äº’ä¸å—æŸã€‚

> âœ… *ä¼˜åŠ¿*ï¼šæœ‰æ•ˆæ§åˆ¶tokenå¢é•¿ï¼Œä¿æŒé•¿æœŸæ¨ç†è¿è´¯æ€§ï¼Œé¿å…å…³é”®ä¿¡æ¯ä¸¢å¤±ã€‚

æ­¤å¤–ï¼Œè¯¥æ¡†æ¶æ”¯æŒ **Model Context Protocol (MCP)**ã€æ–‡ä»¶I/OåŠæ‰§è¡Œåé¦ˆé—­ç¯ï¼Œå…·å¤‡åè®®å…¼å®¹æ€§ä¸å¯æ‰©å±•æ€§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚AutoGPTã€LangChain Agentsï¼‰ | Jenius-Agent |
|------|----------------------------------------|-------------|
| æç¤ºæœºåˆ¶ | å›ºå®šæ¨¡æ¿ï¼Œç¼ºä¹åŠ¨æ€è°ƒæ•´ | è‡ªé€‚åº”ç”Ÿæˆï¼Œèåˆæ„å›¾è¯†åˆ«ä¸å†å²æ„ŸçŸ¥ |
| å·¥å…·é€‰æ‹© | é™æ€åˆ—è¡¨æˆ–ç¡¬ç¼–ç è§„åˆ™ | è¯­ä¹‰æ£€ç´¢ + æ‹ç‚¹è¿‡æ»¤ï¼ŒåŠ¨æ€é€‚é…ä¸Šä¸‹æ–‡ |
| è®°å¿†ç®¡ç† | çª—å£æˆªæ–­æˆ–ç®€å•æ‘˜è¦ | åˆ†å±‚ç»“æ„ï¼Œå…¼é¡¾ç»†ç²’åº¦ä¾èµ–ä¸å®è§‚è¿è´¯ |
| åè®®å…¼å®¹ | å¤šä¸ºç§æœ‰è®¾è®¡ | æ”¯æŒMCPç­‰å¼€æ”¾åè®®ï¼Œä¾¿äºç³»ç»Ÿé›†æˆ |

> âœ… æ•´ä½“ä¸Šå®ç°äº†æ›´é«˜çš„ä»»åŠ¡å‡†ç¡®æ€§ã€æ›´ä½çš„èµ„æºå¼€é”€å’Œæ›´å¼ºçš„ç°å®éƒ¨ç½²èƒ½åŠ›ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**

#### ï¼ˆ1ï¼‰**APIGen**ï¼ˆå…¬å¼€åŸºå‡†ï¼‰
- è§„æ¨¡ï¼š60Kæ ·æœ¬ï¼Œæ¶µç›–21ä¸ªç±»åˆ«ï¼ˆçº¦3.6K APIsï¼‰
- ç‰¹ç‚¹ï¼šå•è½®å¯¹è¯ï¼Œå…³æ³¨è‡ªç„¶è¯­è¨€åˆ°APIè°ƒç”¨çš„æ˜ å°„
- å±€é™ï¼šå…ƒæ•°æ®ç®€ç•¥ï¼Œæ— çœŸå®è¾“å‡ºï¼Œç¼ºä¹å¤šæ­¥æ¨ç†
- æœ¬æ–‡æ”¹è¿›ï¼šæ¯æ¡æŸ¥è¯¢æ³¨å…¥100ä¸ªæ— å…³å·¥å…·ï¼Œæ¨¡æ‹Ÿé«˜å™ªå£°ç¯å¢ƒ

#### ï¼ˆ2ï¼‰**Jenius-bench**ï¼ˆæœ¬æ–‡æ„å»ºçš„çœŸå®ä¸–ç•Œå¤šè½®ä»»åŠ¡æ•°æ®é›†ï¼‰
- è§„æ¨¡ï¼š850é«˜è´¨é‡äººå·¥æ ‡æ³¨æ ·æœ¬ï¼Œè¦†ç›–38ç±»å·¥å…·
- åœºæ™¯ï¼šæ—…è¡Œè§„åˆ’ã€ç¥¨åŠ¡é¢„è®¢ã€ç½‘é¡µç”Ÿæˆã€å­¦æœ¯æ£€ç´¢ç­‰
- ç‰¹ç‚¹ï¼š
  - å¤šè½®å¯¹è¯ï¼Œå«å¤æ‚çŠ¶æ€æ¼”åŒ–
  - æ¯æ­¥è®°å½•å®Œæ•´æ‰§è¡Œè½¨è¿¹ï¼ˆå·¥å…·è°ƒç”¨ã€å‚æ•°ã€è¿”å›å€¼ã€å“åº”ï¼‰
  - å·¥å…·é™„å¸¦ä¸°å¯Œè¯­ä¹‰æè¿°ï¼ˆç›®çš„ã€å‰æã€ç¤ºä¾‹ï¼‰
  - æ‰€æœ‰è·¯å¾„ç»ä¸“å®¶å®¡æ ¸ï¼Œç¡®ä¿æ­£ç¡®æ€§ä¸å¯ä¿¡åº¦

> âš ï¸ å¯¹æ¯”è§è¡¨1ï¼šJenius-benchæ›´è´´è¿‘çœŸå®åº”ç”¨åœºæ™¯ï¼Œå¼ºè°ƒè·¨è½®æ¬¡æ¨ç†ä¸ä¸Šä¸‹æ–‡ä¸€è‡´æ€§ã€‚

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°æ¡†æ¶ä¸‰å¤§ç»´åº¦**ï¼š
| ç»´åº¦ | æŒ‡æ ‡ä½“ç³» | å†…å®¹ |
|------|---------|------|
| **è¿‡ç¨‹ä¿çœŸåº¦** | 4T Metrics | TCR, TFR, TIR, TPS |
| **è¾“å‡ºè´¨é‡** | CRCFF Metrics | Correctness, Relevance, Completeness, Fluency, Faithfulness |
| **æ•ˆç‡** | Token Consumption | è¾“å…¥/è¾“å‡ºtokenæ€»é‡ï¼Œåæ˜ è®¡ç®—æˆæœ¬ |

##### **4T Metricsè¯¦è§£**ï¼š
- **TCR (Task Completion Rate)**ï¼šä»»åŠ¡å®Œå…¨æŒ‰æ­£ç¡®é¡ºåºå®Œæˆçš„æ¯”ä¾‹
- **TFR (Task Failure Rate)**ï¼šæœªæ‰§è¡Œä»»ä½•æ“ä½œæˆ–å‘ç”Ÿè¿è¡Œæ—¶é”™è¯¯çš„ä»»åŠ¡æ¯”ä¾‹
- **TIR (Task Incompletion Rate)**ï¼šéƒ¨åˆ†å®Œæˆï¼ˆæ¼è°ƒã€é”™åºã€æ— å…³è°ƒç”¨ï¼‰çš„ä»»åŠ¡æ¯”ä¾‹
- **TPS (Task Performance Score)**ï¼šç»¼åˆè€ƒè™‘æ­£ç¡®ã€é”™è¯¯ã€é—æ¼å·¥å…·çš„åŠ æƒå¾—åˆ†

##### **CRCFF Metrics**ï¼š
ç”±Qwenå’ŒDeepSeekä¸¤ä¸ªLLMä½œä¸ºè¯„ä¼°å™¨æ‰“åˆ†ï¼ˆ0â€“10åˆ†åˆ¶ï¼‰ï¼Œè¡¡é‡å“åº”è¯­ä¹‰è´¨é‡ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”é…ç½®**

| æ¨¡å‹ | æè¿° |
|------|------|
| **Base** | æ ‡å‡†ReActæ¶æ„ï¼Œobserve-think-actå¾ªç¯ |
| **B-P** | Base + è‡ªé€‚åº”æç¤ºç”Ÿæˆï¼ˆAdaptive Promptingï¼‰ |
| **B-PT** | B-P + ä¸Šä¸‹æ–‡æ„ŸçŸ¥å·¥å…·ç¼–æ’ï¼ˆTool Orchestrationï¼‰ |
| **Jenius** | B-PT + åˆ†å±‚è®°å¿†ç®¡ç†ï¼ˆHierarchical Memoryï¼‰ |

æ‰€æœ‰æ¨¡å‹å…±äº«ç›¸åŒLLM backboneä¸æ¨ç†åè®®ï¼Œä»…æ¨¡å—é€æ­¥å åŠ ï¼Œä¾¿äºå½’å› åˆ†æã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

#### ï¼ˆ1ï¼‰**æ‰§è¡Œä¿çœŸåº¦ï¼ˆ4T Metricsï¼‰**

| æ•°æ®é›† | æ¨¡å‹ | TCR â†‘ | TFR â†“ | TIR â†“ | TPS â†‘ |
|-------|------|-------|-------|-------|-------|
| **APIGen** | Base | 0.8150 | 0.1800 | 0.0050 | 0.8150 |
|           | B-P  | 0.8275 | 0.1675 | 0.0050 | 0.8275 |
|           | B-PT | 0.8375 | 0.1587 | 0.0038 | 0.8375 |
|           | **Jenius** | **0.8500** | **0.1362** | **0.0138** | **0.8500** |
| **Jenius-bench** | Base | 0.5659 | 0.0329 | 0.4012 | 0.5968 |
|                 | B-P  | 0.7271 (+28.5%) | 0.0859 | 0.1871 | 0.7491 |
|                 | B-PT | 0.7494 | 0.0718 | 0.1788 | 0.7740 |
|                 | **Jenius** | **0.7647** | **0.0753** | **0.1600** | **0.7847** |

> ğŸ” åœ¨APIGenä¸Šæå‡æœ‰é™ï¼ˆå·²æ¥è¿‘é¥±å’Œï¼‰ï¼Œä½†åœ¨æ›´å¤æ‚çš„Jenius-benchä¸Šï¼Œ**TCRæå‡çº¦20%**ï¼ŒTIRä¸‹é™è¶…60%ï¼Œä½“ç°æ¨¡å—ç»„åˆçš„æœ‰æ•ˆæ€§ã€‚

---

#### ï¼ˆ2ï¼‰**è¾“å‡ºè´¨é‡ï¼ˆCRCFF Metricsï¼‰**

| è¯„ä¼°å™¨ | æ¨¡å‹ | Correctness â†‘ | Relevance â†‘ | Completeness â†‘ | Fluency â†‘ | Faithfulness â†‘ |
|--------|------|----------------|--------------|------------------|------------|------------------|
| **Qwen** | Base | 0.6741 | 0.8951 | 0.7722 | 0.9294 | 0.7919 |
|          | Jenius | **0.7580** | **0.9447** | **0.8088** | **0.9771** | **0.8766** |
| **DeepSeek** | Base | 0.7890 | 0.9245 | 0.7898 | 0.9546 | 0.8291 |
|              | Jenius | **0.8350** | **0.9400** | **0.8143** | **0.9686** | **0.8636** |

> âœ… å¹³å‡æå‡ **8â€“10%**ï¼Œå°¤å…¶åœ¨Correctnesså’ŒFluencyæ–¹é¢è¿›æ­¥æ˜æ˜¾ï¼Œè¯´æ˜å„æ¨¡å—ååŒæ”¹å–„äº†è¯­ä¹‰è´¨é‡å’Œé€»è¾‘ä¸€è‡´æ€§ã€‚

---

#### ï¼ˆ3ï¼‰**Tokenæ¶ˆè€—åˆ†æï¼ˆå›¾6ï¼‰**

| æ•°æ®é›† | Base | Jenius |
|--------|------|--------|
| **APIGen** | 9.96M | 2.46M (**â†“75.3%**) |
| **Jenius-bench** | 9.27M | 3.65M (**â†“60.6%**) |

> ğŸ’¡ æ˜¾è‘—é™ä½tokenä½¿ç”¨é‡ï¼Œä¸»è¦å½’åŠŸäºï¼š
- è‡ªé€‚åº”æç¤ºå‡å°‘å†—ä½™æ¨ç†
- å·¥å…·ç¼–æ’æŠ‘åˆ¶æ— æ•ˆè°ƒç”¨
- åˆ†å±‚è®°å¿†å‹ç¼©å†å²ä¸Šä¸‹æ–‡

---

#### ï¼ˆ4ï¼‰**æ¶ˆèå®éªŒç»“è®º**
- **B-P â†’ B-PT**ï¼šåŠ å…¥å·¥å…·ç¼–æ’åï¼ŒTCRæå‡æ˜æ˜¾ï¼ˆ+2.2%ï¼‰ï¼ŒTIRä¸‹é™
- **B-PT â†’ Jenius**ï¼šå¼•å…¥åˆ†å±‚è®°å¿†è¿›ä¸€æ­¥ç¨³å®šé•¿æœŸæ¨ç†ï¼ŒFaithfulnessæå‡æ˜¾è‘—
- ä¸‰è€…è”åˆå¸¦æ¥**äº’è¡¥å¢ç›Š**ï¼Œéç®€å•å åŠ 

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ç»éªŒé©±åŠ¨çš„è®¾è®¡ä¼˜äºé™æ€æ¶æ„**ï¼šé€šè¿‡åŠ¨æ€è°ƒæ•´æç¤ºã€å·¥å…·é€‰æ‹©å’Œè®°å¿†ç»“æ„ï¼ŒJenius-Agentåœ¨çœŸå®å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´å¼ºçš„é€‚åº”æ€§å’Œå‡†ç¡®æ€§ã€‚
2. **æ¨¡å—åŒ–ä¼˜åŒ–å…·æœ‰ç´¯ç§¯æ•ˆåº”**ï¼šä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—åˆ†åˆ«é’ˆå¯¹ä¸åŒç“¶é¢ˆï¼ŒååŒä½œç”¨ä¸‹å®ç°å…¨é¢æ€§èƒ½è·ƒå‡ã€‚
3. **çœŸå®ä¸–ç•Œæ•°æ®æ›´èƒ½æ­ç¤ºç³»ç»Ÿå·®å¼‚**ï¼šåœ¨é«˜åº¦ç»“æ„åŒ–çš„APIGenä¸Šå„æ¨¡å‹è¡¨ç°è¶‹åŒï¼›è€Œåœ¨Jenius-benchä¸Šï¼ŒJeniusæ˜¾è‘—é¢†å…ˆï¼ŒéªŒè¯å…¶åœ¨ç°å®åœºæ™¯ä¸­çš„ä¼˜è¶Šæ€§ã€‚
4. **æ•ˆç‡ä¸è´¨é‡å¯ä»¥å…¼å¾—**ï¼šä¸ä»…æå‡äº†ä»»åŠ¡å®Œæˆç‡å’Œè¾“å‡ºè´¨é‡ï¼Œè¿˜å¤§å¹…é™ä½äº†tokenæ¶ˆè€—å’Œè°ƒç”¨å¤±è´¥ç‡ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **ä¾èµ–é«˜è´¨é‡å·¥å…·å…ƒæ•°æ®**ï¼šå·¥å…·åµŒå…¥æ•ˆæœå—é™äºæè¿°æ–‡æœ¬çš„è´¨é‡ï¼Œè‹¥åŸå§‹metadataä¸å®Œæ•´æˆ–å­˜åœ¨å™ªå£°ï¼Œä¼šå½±å“æ£€ç´¢ç²¾åº¦ã€‚
2. **æ‹ç‚¹æ£€æµ‹å¯¹åˆ†å¸ƒæ•æ„Ÿ**ï¼šKneedleç­‰æ–¹æ³•åœ¨æç«¯ç›¸ä¼¼åº¦åˆ†å¸ƒä¸‹å¯èƒ½å¤±æ•ˆï¼Œéœ€è¿›ä¸€æ­¥é²æ£’åŒ–ã€‚
3. **æ‘˜è¦å¯èƒ½ä¸¢å¤±ç»†èŠ‚**ï¼šå°½ç®¡ä¿ç•™é«˜å±‚è¯­ä¹‰ï¼Œä½†æŸäº›ç»†å¾®ä¾èµ–å…³ç³»ï¼ˆå¦‚ç‰¹å®šå‚æ•°çº¦æŸï¼‰å¯èƒ½åœ¨å‹ç¼©ä¸­è¢«å¿½ç•¥ã€‚
4. **è¯„ä¼°ä»ä¾èµ–äººå·¥æ ‡æ³¨**ï¼šè™½ç„¶å¼•å…¥LLM-as-Judgeï¼Œä½†é»„é‡‘æ ‡å‡†è½¨è¿¹è·å–æˆæœ¬è¾ƒé«˜ï¼Œéš¾ä»¥å¤§è§„æ¨¡æ‰©å±•ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ›´çµæ´»çš„ç»“æœå¯¼å‘è¯„ä¼°**ï¼šå…è®¸å¤šç§åˆæ³•æ‰§è¡Œè·¯å¾„ï¼Œé¿å…è¿‡åº¦æƒ©ç½šåˆç†å˜ä½“ã€‚
2. **å¼•å…¥ç”¨æˆ·ä½“éªŒæŒ‡æ ‡**ï¼šå°†ç”¨æˆ·æ»¡æ„åº¦ã€å†³ç­–å»¶è¿Ÿã€äº¤äº’æˆæœ¬çº³å…¥è¯„ä»·ä½“ç³»ã€‚
3. **åŠ¨æ€æ¨¡å—é‡ç»„æœºåˆ¶**ï¼šæ ¹æ®ä»»åŠ¡ç±»å‹è‡ªåŠ¨å¯ç”¨/å…³é—­æŸäº›ä¼˜åŒ–æ¨¡å—ï¼Œæå‡è¿è¡Œæ•ˆç‡ã€‚
4. **å¤šæ™ºèƒ½ä½“åä½œæ¶æ„**ï¼šæ¢ç´¢åˆ†å¸ƒå¼é—®é¢˜æ±‚è§£ä¸è·¨Agenté€šä¿¡æœºåˆ¶ï¼ˆå¦‚A2Aåè®®ï¼‰ã€‚
5. **æŒç»­å­¦ä¹ ä¸åœ¨çº¿ä¼˜åŒ–**ï¼šåˆ©ç”¨çº¿ä¸Šåé¦ˆé—­ç¯ä¸æ–­æ›´æ–°æç¤ºç­–ç•¥ã€å·¥å…·ç´¢å¼•å’Œè®°å¿†æ¨¡å‹ã€‚

---

> âœ… **æ€»ç»“**ï¼šJenius-Agentæä¾›äº†ä¸€ä¸ªè½»é‡ã€å¯æ‰©å±•ã€åè®®å…¼å®¹çš„æ™ºèƒ½ä½“ä¼˜åŒ–æ¡†æ¶ï¼Œåœ¨çœŸå®åœºæ™¯ä¸­å®ç°äº†**çº¦20%çš„ä»»åŠ¡å‡†ç¡®ç‡æå‡**ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½èµ„æºæ¶ˆè€—ã€‚å…¶å·²åœ¨ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼ˆ[jenius.cn](https://www.jenius.cn)ï¼‰ï¼Œä¸ºå·¥ä¸šçº§è‡ªä¸»ä»£ç†ç³»ç»Ÿçš„æ„å»ºæä¾›äº†å®è¯åŸºç¡€ä¸å®è·µè“å›¾ã€‚

</details>

---

### 11. [CD4LM: Consistency Distillation and aDaptive Decoding for Diffusion Language Models](https://arxiv.org/abs/2601.02236)

**Authors**: Yihao Liang, Ze Wang, Hao Chen, Ximeng Sun, Jialian Wu, Xiaodong Yu, Jiang Liu, Emad Barsoum, Zicheng Liu, Niraj K. Jha  
**Category**: cs.CL  
**Published**: 2026-01-06  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.02236v1  

#### Abstract
Autoregressive large language models achieve strong results on many benchmarks, but decoding remains fundamentally latency-limited by sequential dependence on previously generated tokens. Diffusion language models (DLMs) promise parallel generation but suffer from a fundamental static-to-dynamic mis...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# CDLM: Consistency Distillation and aDaptive Decoding for Diffusion Language Models è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **Diffusion Language Models (DLMs)** åœ¨è®­ç»ƒå’Œæ¨ç†ä¹‹é—´å­˜åœ¨**é™æ€åˆ°åŠ¨æ€çš„é”™é…ï¼ˆstatic-to-dynamic misalignmentï¼‰**ï¼š
- **è®­ç»ƒé˜¶æ®µ**ï¼šæ¨¡å‹åœ¨å›ºå®šçš„å™ªå£°è°ƒåº¦ï¼ˆfixed scheduleï¼‰ä¸‹ä¼˜åŒ–å±€éƒ¨å»å™ªæ­¥éª¤ï¼ˆå¦‚ $t \to t-\Delta t$ï¼‰ï¼Œå­¦ä¹ çš„æ˜¯ä¸€ä¸ªâ€œé™æ€â€çš„å‘é‡åœºã€‚
- **æ¨ç†é˜¶æ®µ**ï¼šä¸ºäº†å®ç°ä½å»¶è¿Ÿç”Ÿæˆï¼Œéœ€è¦è¿›è¡Œâ€œé•¿è·³â€ï¼ˆlong-jumpï¼‰å¼çš„å¿«é€Ÿå»å™ªï¼ˆå¦‚ $t \to t-k\Delta t$ï¼‰ï¼Œè¿™ä¼šç»è¿‡è®­ç»ƒæ—¶æœªè§è¿‡çš„çŠ¶æ€ç©ºé—´åŒºåŸŸã€‚

æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•åœ¨è®¡ç®—èµ„æºåˆ†é…ä¸Šç¼ºä¹çµæ´»æ€§ï¼Œé€šå¸¸é‡‡ç”¨é¢„è®¾çš„è§£ç ç­–ç•¥ï¼ˆå¦‚å›ºå®šæ­¥æ•°æˆ–å—å¤§å°ï¼‰ï¼Œæ— æ³•æ ¹æ®æ ·æœ¬éš¾åº¦è‡ªé€‚åº”è°ƒæ•´ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
ä½œè€…æå‡º **CDLM**ï¼ˆConsistency Distillation and aDaptive Decoding for Diffusion Language Modelsï¼‰ï¼Œä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶è§£è€¦è®­ç»ƒä¸æ¨ç†ï¼š

1. **Discrete-Space Consistency Distillation (DSCD)**  
   - ä¸å†è®©å­¦ç”Ÿæ¨¡å‹è¿‡æ‹Ÿåˆå•ä¸€å›ºå®šè½¨è¿¹ï¼Œè€Œæ˜¯åˆ©ç”¨ **Rao-Blackwellized ç›®æ ‡å‡½æ•°**ï¼Œè®­ç»ƒä¸€ä¸ªå¯¹å¤šç§æ©ç æ¨¡å¼å…·æœ‰é²æ£’æ€§çš„å­¦ç”Ÿæ¨¡å‹ã€‚
   - å­¦ç”Ÿæ¨¡å‹è¢«è®­ç»ƒä¸ºç›´æ¥ä»ä»»æ„å™ªå£°çŠ¶æ€æ˜ å°„åˆ°å¹²å‡€åˆ†å¸ƒï¼Œå…·å¤‡**è½¨è¿¹ä¸å˜æ€§ï¼ˆtrajectory-invariantï¼‰**ï¼Œä»è€Œèƒ½ç¨³å¥å¤„ç†æ¨ç†ä¸­çš„â€œé•¿è·³â€æ“ä½œã€‚

2. **Confidence-Adaptive Decoding (CAD)**  
   - åŠ¨æ€åœ°åŸºäºæ¯ä¸ª token çš„é¢„æµ‹ç½®ä¿¡åº¦ï¼ˆå¦‚æœ€å¤§æ¦‚ç‡ï¼‰å†³å®šæ˜¯å¦è§£ç è¯¥ tokenã€‚
   - é«˜ç½®ä¿¡åº¦ token è¢«ç«‹å³æäº¤ï¼Œä½ç½®ä¿¡åº¦ token ç»§ç»­ä¿ç•™ä¸º `<mask>`ï¼Œç›´åˆ°åç»­æ­¥éª¤ä¸­ç½®ä¿¡åº¦è¶³å¤Ÿé«˜ã€‚
   - ç»“åˆ `kmin` å’Œ `kmax` æ§åˆ¶æ¯æ­¥è§£ç æ•°é‡ï¼Œä¿è¯è¿›åº¦çš„åŒæ—¶é˜²æ­¢é”™è¯¯ä¼ æ’­ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ•ˆç‡æ›´é«˜**ï¼šæ— éœ€å¤æ‚æ’åºæˆ–éªŒè¯é€»è¾‘ï¼Œè®¡ç®—å¼€é”€æå°ï¼Œç†è®ºä¸Šçš„ NFE å‡å°‘å¯é«˜æ•ˆè½¬åŒ–ä¸ºå®é™… wall-clock åŠ é€Ÿã€‚
- **è´¨é‡æ›´ç¨³**ï¼šç”±äº DSCD è®­ç»ƒçš„å­¦ç”Ÿæ¨¡å‹å†…åœ¨é²æ£’ï¼ŒCAD å¯ä»¥æ¿€è¿›è·³æ­¥è€Œä¸å¯¼è‡´ç”Ÿæˆå´©æºƒï¼ˆquality collapseï¼‰ã€‚
- **é€šç”¨æ€§å¼º**ï¼šé€‚ç”¨äº block-wise å’Œ pure diffusion ä¸¤ç§èŒƒå¼ï¼Œä¸”ä¸ä¾èµ–ç‰¹å®š teacher æˆ– embedding spaceã€‚
- **å¸•ç´¯æ‰˜å‰æ²¿æå‡**ï¼šåœ¨å¤šä¸ªä»»åŠ¡ä¸ŠåŒæ—¶å®ç°äº†é€Ÿåº¦å’Œå‡†ç¡®ç‡çš„æå‡ï¼Œè€Œéå•çº¯ç‰ºç‰²è´¨é‡æ¢é€Ÿåº¦ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **ä»£ç ç”Ÿæˆ**ï¼š
  - **HumanEval**ï¼šé›¶æ ·æœ¬ä»£ç ç”Ÿæˆè¯„æµ‹ã€‚
  - **MBPP**ï¼šä¸‰æ ·æœ¬ä»£ç ç”Ÿæˆè¯„æµ‹ã€‚
  - **OpenCodeInstruct**ï¼šç”¨äº DSCD è®­ç»ƒçš„ 200K æŒ‡ä»¤éµå¾ªä»£ç æ•°æ®é›†ã€‚
- **æ•°å­¦æ¨ç†**ï¼š
  - **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼Œç”¨äºè®­ç»ƒå’Œé›¶æ ·æœ¬è¯„æµ‹ã€‚
  - **MATH500**ï¼šæ›´å…·æŒ‘æˆ˜æ€§çš„æ•°å­¦é—®é¢˜é›†åˆã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹æ¶æ„**ï¼šåŸºäº **LLaDA-8B-Instruct** ä½œä¸º teacherï¼Œstudent åˆå§‹åŒ–ä¸ºå…¶æƒé‡å¹¶è¿›è¡Œè’¸é¦ã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - BF16 ç²¾åº¦ï¼Œä¸Šä¸‹æ–‡é•¿åº¦ 1024ã€‚
  - ä½¿ç”¨ AdamW ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ $5\times10^{-6}$ï¼Œcosine è¡°å‡ï¼Œwarmup 10%ã€‚
  - DSCD ä¸­ teacher mask ratio å°äº student mask ratioï¼ˆåµŒå¥—æ©ç è®¾è®¡ï¼‰ã€‚
- **æ¨ç†é…ç½®**ï¼š
  - æœ€å¤§ç”Ÿæˆé•¿åº¦ $L_{gen}=256$ã€‚
  - CAD å‚æ•°ï¼š`conf_threshold=0.95`, `kmin=1`, `kmax=32`ã€‚
  - è¯„ä¼° batch size = 1ï¼ŒæŠ¥å‘Š wall-clock æ—¶é—´åŠ é€Ÿæ¯”ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **pass@1 / pass@5**ï¼ˆä»£ç ç”Ÿæˆï¼‰
  - **Accuracy**ï¼ˆæ•°å­¦æ¨ç†ï¼‰
  - **Avg. NFE**ï¼ˆå¹³å‡å‡½æ•°è°ƒç”¨æ¬¡æ•°ï¼‰
  - **Tokens/s** å’Œ **Speedup**ï¼ˆç›¸å¯¹äº baseline çš„ wall-clock åŠ é€Ÿï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **LLaDA**ï¼šåŸå§‹ diffusion modelï¼Œåœ¨ä¸åŒ block size ä¸‹è¿è¡Œã€‚
- **Fast-dLLM**ï¼šä¸€ç§æ— éœ€è®­ç»ƒçš„å¹¶è¡Œè§£ç æ¡†æ¶ï¼Œç»“åˆ KV ç¼“å­˜ã€‚
- **Sequential AR decoding**ï¼šä½œä¸ºæœ€æ…¢ä½†ç¨³å®šçš„ baselineã€‚
- **SFT baseline**ï¼šç›‘ç£å¾®è°ƒç‰ˆæœ¬ï¼Œç”¨äºæ¶ˆèåˆ†æã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 3ï¼‰

| Task | Benchmark | LLaDA Acc/NFE | CDLM Acc/NFE | Speedup |
|------|-----------|----------------|---------------|---------|
| Code | HumanEval (pass@1) | 38.7 / 256 | **40.9 / 113.2** | **3.30Ã—** |
| Code | HumanEval+ (pass@1) | 31.7 / 256 | **32.9 / 115.0** | **3.25Ã—** |
| Code | MBPP+ (pass@1) | 48.7 / 256 | 47.9 / 108.0 | 3.51Ã— |
| Math | MATH500 (Acc%) | 37.3 / 512 | **38.6 / 148.3** | **5.33Ã—** |
| **Avg.** | â€” | **45.6 / 292.6** | **46.3 / 117.2** | **3.62Ã—** |

> æ³¨ï¼šLLaDA åœ¨ MATH500 ä¸Šä½¿ç”¨ 512 æ­¥ï¼Œå…¶ä½™ä»»åŠ¡ä½¿ç”¨ 256 æ­¥ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ **GSM8K** ä¸Šï¼ŒCDLM ä»¥ **77.6%** å‡†ç¡®ç‡åŒ¹é… LLaDA baselineï¼ˆ77.4%ï¼‰ï¼Œä½†å®ç° **5.18Ã— wall-clock åŠ é€Ÿ**ï¼ˆè§ Table 1ï¼‰ã€‚
- åœ¨ **HumanEval** ä¸Šï¼Œå‡†ç¡®ç‡æå‡ **+2.2%**ï¼ŒåŒæ—¶è·å¾— **3.30Ã— é€Ÿåº¦æå‡**ã€‚
- åœ¨ **MATH500** ä¸Šï¼Œå‡†ç¡®ç‡æå‡ **+1.3%**ï¼Œé€Ÿåº¦æå‡è¾¾ **5.33Ã—**ã€‚
- æ‰€æœ‰ä»»åŠ¡å‡å®ç° **å¸•ç´¯æ‰˜å‰æ²¿ä¸¥æ ¼å ä¼˜**ï¼šç›¸åŒå‡†ç¡®ç‡ä¸‹æ˜¾è‘—å‡å°‘ NFEï¼Œæˆ–ç›¸åŒ NFE ä¸‹æ˜¾è‘—æå‡å‡†ç¡®ç‡ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable E.1ï¼‰
- **DSCD æ˜¯å…³é”®**ï¼šè‹¥ä»…ç”¨ SFT å¾®è°ƒ + CADï¼Œåœ¨ pure diffusion è®¾ç½®ä¸‹å‡†ç¡®ç‡ä» 54.7%ï¼ˆDSCD+CADï¼‰é™è‡³ 38.2%ï¼Œè¯´æ˜æ ‡å‡†è®­ç»ƒæ— æ³•æ”¯æŒæ¿€è¿›è‡ªé€‚åº”è§£ç ã€‚
- **CAD æ˜¾è‘—ææ•ˆ**ï¼šå³ä½¿æ²¡æœ‰ DSCDï¼Œä»…ä½¿ç”¨ CAD ä¹Ÿèƒ½å°† NFE ä» 256 é™è‡³ ~130ï¼Œä½†è´¨é‡ä¸‹é™æ˜æ˜¾ï¼›è€Œ DSCD + CAD å¯è¿›ä¸€æ­¥å°† NFE é™è‡³ 76.3â€“80.6ï¼Œä¸”ä¿æŒé«˜è´¨é‡ã€‚
- **ä¿¡å¿ƒæ’åºè‡³å…³é‡è¦**ï¼šè‹¥å°† confidence-based selection æ›¿æ¢ä¸ºéšæœºé€‰æ‹©ï¼Œå‡†ç¡®ç‡ä» 77.6% éª¤é™è‡³ 50.6%ï¼ŒNFE å´ä¸Šå‡è‡³ 202.2ï¼Œè¯æ˜ token é€‰æ‹©é¡ºåºæä¸ºé‡è¦ã€‚
- **teacher-subset masking å¿…ä¸å¯å°‘**ï¼šç‹¬ç«‹é‡‡æ · teacher/student mask ä¼šå¯¼è‡´è®­ç»ƒä¸ç¨³å®šç”šè‡³æ¢¯åº¦çˆ†ç‚¸ï¼ŒéªŒè¯äº† Rao-Blackwell åŒ–è®¾è®¡çš„å¿…è¦æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è®­ç»ƒ-æ¨ç†é”™é…æ˜¯æ•ˆç‡ç“¶é¢ˆçš„æ ¹æœ¬åŸå› **ï¼šä»…ä»…ä¾é æ¨ç†æ—¶çš„å¯å‘å¼åŠ é€Ÿï¼ˆå¦‚ step-skippingï¼‰æ— æ³•çªç ´æ€§èƒ½ä¸Šé™ï¼Œå¿…é¡»é€šè¿‡è®­ç»ƒç›®æ ‡é‡æ–°å¯¹é½ã€‚
2. **DSCD å®ç°äº†çœŸæ­£çš„â€œä¸€è‡´æ€§è’¸é¦â€**ï¼šå­¦ç”Ÿæ¨¡å‹å­¦åˆ°çš„æ˜¯ teacher åœ¨æ‰€æœ‰å¯èƒ½è·¯å¾„ä¸Šçš„æœŸæœ›è¡Œä¸ºï¼Œè€ŒéæŸä¸€æ¡å…·ä½“è½¨è¿¹ï¼Œä»è€Œå…·å¤‡å¤„ç†ä»»æ„ä¸­é—´çŠ¶æ€çš„èƒ½åŠ›ã€‚
3. **CAD å®ç°äº†é«˜æ•ˆçš„åŠ¨æ€è®¡ç®—åˆ†é…**ï¼šæ¨¡å‹è‡ªåŠ¨è¯†åˆ«â€œå®¹æ˜“â€å’Œâ€œå›°éš¾â€çš„ tokenï¼Œä¼˜å…ˆç¨³å®šç»“æ„ï¼ˆå¦‚è¯­æ³•éª¨æ¶ï¼‰ï¼ŒåæœŸç²¾ä¿®é€»è¾‘ç»†èŠ‚ï¼Œå½¢æˆâ€œå…ˆæ­éª¨æ¶åå¡«è¡€è‚‰â€çš„åˆ†å±‚ç”Ÿæˆç­–ç•¥ï¼ˆè§ Fig. F.1ï¼‰ã€‚
4. **ç®—æ³•æ•ˆç‡å¢ç›Šå¯è¶…çº¿æ€§è½¬åŒ–ä¸ºå®é™…åŠ é€Ÿ**ï¼šç”±äº CAD æ§åˆ¶é€»è¾‘è½»é‡ï¼ˆå…¨æ‰¹é‡å¼ é‡æ“ä½œï¼‰ï¼ŒNFE çš„å‡å°‘å‡ ä¹å®Œå…¨è½¬åŒ–ä¸º wall-clock æ—¶é—´èŠ‚çœï¼Œç”šè‡³å‡ºç° **superlinear speedup**ï¼ˆå¦‚ GSM8K ä¸Š NFE å‡å°‘ 3.36Ã—ï¼Œwall-clock åŠ é€Ÿ 5.18Ã—ï¼‰ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **é™æ€ç”»å¸ƒé™åˆ¶ï¼ˆStatic Canvas Constraintï¼‰**ï¼šä»éœ€é¢„è®¾æœ€å¤§åºåˆ—é•¿åº¦ $L_{gen}$ï¼ŒçŸ­åºåˆ—å­˜åœ¨å†…å­˜å†—ä½™ï¼Œé•¿åºåˆ—å—é™äºè®­ç»ƒçª—å£ã€‚
2. **èƒ½åŠ›å— teacher é™åˆ¶**ï¼šä½œä¸ºè’¸é¦æ¡†æ¶ï¼Œstudent çš„æ¨ç†èƒ½åŠ›ç†è®ºä¸Šä¸è¶…è¿‡ teacherã€‚è‹¥ teacher å‡ºç°å¹»è§‰æˆ–é€»è¾‘é”™è¯¯ï¼Œstudent å¯èƒ½ç»§æ‰¿è¿™äº›ç¼ºé™·ã€‚
3. **é«˜ç†µä»»åŠ¡é€‚ç”¨æ€§æœ‰é™**ï¼šconfidence thresholding åœ¨åˆ›é€ æ€§å†™ä½œç­‰é«˜ä¸ç¡®å®šæ€§ä»»åŠ¡ä¸­å¯èƒ½è¿‡äºä¿å®ˆï¼ŒæŠ‘åˆ¶å¤šæ ·æ€§æˆ–å¯¼è‡´é‡å¤è¾“å‡ºã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **åŠ¨æ€/æ— é™ä¸Šä¸‹æ–‡æ‰©æ•£æ¨¡å‹**ï¼šç»“åˆ semi-autoregressive context shifting ç­‰æœºåˆ¶ï¼Œæ”¯æŒä»»æ„é•¿åº¦ç”Ÿæˆã€‚
2. **è¶…è¶Šæ¨¡ä»¿å­¦ä¹ çš„ on-policy fine-tuning**ï¼šå¼•å…¥å¼ºåŒ–å­¦ä¹ ï¼Œåœ¨ CAD æä¾›çš„é«˜æ•ˆæ¢ç´¢åŸºç¡€ä¸Šä¼˜åŒ– correctness è€Œé consistencyã€‚
3. **é›†æˆ KV caching**ï¼šå°† DSCD+CAD ä¸ Fast-dLLM ç±»ä¼¼çš„ KV ç¼“å­˜æœºåˆ¶ç»“åˆï¼Œè¿›ä¸€æ­¥é™ä½æ¯æ­¥è®¡ç®—æˆæœ¬ã€‚
4. **æ‰©å±•è‡³å¤šæ¨¡æ€ä¸è§„åˆ’ä»»åŠ¡**ï¼šåˆ©ç”¨å…¶åˆ†å±‚ç”Ÿæˆç‰¹æ€§ï¼Œåº”ç”¨äº vision-language æˆ–å¤æ‚å†³ç­–ä»»åŠ¡ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> CDLM é€šè¿‡ **DSCD + CAD** çš„ååŒè®¾è®¡ï¼ŒæˆåŠŸå°† DLM ä»â€œå›ºå®šè°ƒåº¦å»å™ªå™¨â€è½¬å˜ä¸ºâ€œçµæ´»çš„å®ä¾‹æ„ŸçŸ¥ refinement operatorâ€ï¼Œåœ¨ä»£ç ä¸æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šå®ç°äº† **3.62Ã— å¹³å‡åŠ é€Ÿ** åŒæ—¶ **æå‡å¹³å‡å‡†ç¡®ç‡**ï¼Œæ¨åŠ¨äº†éè‡ªå›å½’è¯­è¨€æ¨¡å‹è¿ˆå‘å®ç”¨åŒ–çš„é‡è¦ä¸€æ­¥ã€‚  
> é¡¹ç›®ä»£ç å·²å¼€æºï¼š[https://github.com/yihao-liang/CDLM](https://github.com/yihao-liang/CDLM)

</details>

---

### 12. [Performance and Security Aware Distributed Service Placement in Fog Computing](https://arxiv.org/abs/2601.01125)

**Authors**: Mohammad Goudarzi, Arash Shaghaghi, Zhiyu Wang, Rajkumar Buyya  
**Category**: cs.DC  
**Published**: 2026-01-06  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.01125v1  

#### Abstract
The rapid proliferation of IoT applications has intensified the demand for efficient and secure service placement in Fog computing. However, heterogeneous resources, dynamic workloads, and diverse security requirements make optimal service placement highly challenging. Most solutions focus primarily...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Performance and Security Aware Distributed Service Placement in Fog Computing*

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹ **Fog Computing** ç¯å¢ƒä¸‹æœåŠ¡æ”¾ç½®ï¼ˆService Placementï¼‰ä¸­å­˜åœ¨çš„ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š
- **æ€§èƒ½ä¼˜åŒ–ä¸è¶³**ï¼šç°æœ‰æ–¹æ³•å¤šå…³æ³¨å“åº”æ—¶é—´ã€èƒ½è€—ç­‰æ€§èƒ½æŒ‡æ ‡ï¼Œå¿½è§†äº†å®‰å…¨éœ€æ±‚ã€‚
- **å®‰å…¨æ€§è¢«å¿½ç•¥**ï¼šFog ç¯å¢ƒå¼€æ”¾ä¸”åˆ†å¸ƒå¼ï¼Œæ˜“å—æ”»å‡»ï¼ˆå¦‚ DoSï¼‰ï¼Œä½†å¤šæ•°æœåŠ¡æ”¾ç½®ç­–ç•¥æœªå°†å®‰å…¨ä½œä¸ºæ˜¾å¼ä¼˜åŒ–ç›®æ ‡ã€‚

å› æ­¤ï¼Œå¦‚ä½•åœ¨åŠ¨æ€ã€å¼‚æ„çš„ Fog ç¯å¢ƒä¸­å®ç°**æ€§èƒ½ä¸å®‰å…¨çš„è”åˆä¼˜åŒ–**æ˜¯ä¸€ä¸ªå…³é”®éš¾é¢˜ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSPA-DDRL æ¡†æ¶
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Security and Performance-Aware Distributed Deep Reinforcement Learning (SPA-DDRL)** çš„æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°ç‚¹å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰**ä¸‰å±‚å®‰å…¨è¯„åˆ†æ¨¡å‹ï¼ˆThree-Tier Security Hierarchyï¼‰**
- å°†å®‰å…¨èƒ½åŠ›é‡åŒ–ä¸ºå¯è®¡ç®—çš„â€œå®‰å…¨å¾—åˆ†â€ï¼ˆSecurity Scoreï¼‰ï¼Œåˆ†ä¸ºä¸‰ä¸ªå±‚çº§ï¼š
  - **é…ç½®å±‚ï¼ˆConfiguration-Levelï¼‰**ï¼šæ£€æŸ¥å…·ä½“å®‰å…¨æœºåˆ¶æ˜¯å¦å¯ç”¨ï¼ˆå¦‚ AES-256ã€åŒå› ç´ è®¤è¯ï¼‰ã€‚
  - **èƒ½åŠ›å±‚ï¼ˆCapability-Levelï¼‰**ï¼šè¯„ä¼°èµ„æºçš„å®‰å…¨åŠŸèƒ½ï¼ˆå¦‚ä¼ è¾“åŠ å¯†ã€å¯†é’¥ç®¡ç†ï¼‰ã€‚
  - **æ§åˆ¶å±‚ï¼ˆControl-Levelï¼‰**ï¼šå¯¹åº”é«˜å±‚å®‰å…¨ç­–ç•¥ï¼ˆå¦‚è®¾å¤‡æˆæƒæ¸…å•ã€æ•°æ®åŠ å¯†ä¿æŠ¤ï¼‰ã€‚
- å¼•å…¥**ç¡¬çº¦æŸï¼ˆHard Constraintsï¼‰æƒ©ç½šæœºåˆ¶**ï¼Œå¯¹è¿åå…³é”®å®‰å…¨æ§åˆ¶çš„ä»»åŠ¡æ–½åŠ ä¸¥é‡è´Ÿå¥–åŠ±ï¼Œç¡®ä¿æœ€ç»ˆæ–¹æ¡ˆå§‹ç»ˆæ»¡è¶³åŸºæœ¬åˆè§„è¦æ±‚ã€‚

#### ï¼ˆ2ï¼‰**åˆ†å¸ƒå¼ Broker-Learner æ¶æ„**
- é‡‡ç”¨åˆ†å¸ƒå¼çš„å†³ç­–æ¶æ„ï¼š
  - **å¤šä¸ª Broker** åœ¨è¾¹ç¼˜èŠ‚ç‚¹ä¸Šå¹¶è¡Œæ‰§è¡Œæœ¬åœ°æœåŠ¡æ”¾ç½®å†³ç­–ã€‚
  - **ä¸€ä¸ª Centralized Learner** è´Ÿè´£èšåˆç»éªŒã€æ›´æ–°å…¨å±€ç­–ç•¥ã€‚
- å®ç°äº†é«˜å¯æ‰©å±•æ€§å’Œé€‚åº”æ€§ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡å¼‚æ„ç¯å¢ƒã€‚

#### ï¼ˆ3ï¼‰é›†æˆä¸‰å¤§ DRL æŠ€æœ¯æå‡å­¦ä¹ æ•ˆç‡
- **LSTM**ï¼šæ•æ‰ä»»åŠ¡ä¾èµ–å’ŒæœåŠ¡çŠ¶æ€çš„æ—¶é—´åºåˆ—ä¾èµ–å…³ç³»ã€‚
- **Prioritized Experience Replay (PER)**ï¼šä¼˜å…ˆå›æ”¾å…·æœ‰é«˜ TD-error çš„å…³é”®ç»éªŒï¼ŒåŠ é€Ÿæ”¶æ•›ã€‚
- **Off-Policy Correction**ï¼šé€šè¿‡é‡è¦æ€§é‡‡æ ·ï¼ˆImportance Samplingï¼‰å’Œæ¢¯åº¦è£å‰ªè§£å†³åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„ç­–ç•¥åå·®é—®é¢˜ï¼Œå¢å¼ºç¨³å®šæ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | SPA-DDRL ä¼˜åŠ¿ |
|------|----------------|
| **ç›®æ ‡å…¨é¢æ€§** | åŒæ—¶ä¼˜åŒ–å“åº”æ—¶é—´å’Œå®‰å…¨å¾—åˆ†ï¼Œè€Œéå•ä¸€æ€§èƒ½æŒ‡æ ‡ |
| **å®‰å…¨æ€§ä¿éšœ** | æ˜¾å¼å»ºæ¨¡å®‰å…¨æ§åˆ¶ï¼Œå¹¶å¼ºåˆ¶æ»¡è¶³ç¡¬çº¦æŸï¼Œé¿å…ä¸å¯è¡Œè§£ |
| **å¯æ‰©å±•æ€§** | åˆ†å¸ƒå¼æ¶æ„æ”¯æŒå¤§è§„æ¨¡ç³»ç»Ÿéƒ¨ç½² |
| **å­¦ä¹ æ•ˆç‡** | LSTM + PER æ˜¾è‘—åŠ å¿«æ”¶æ•›é€Ÿåº¦ |
| **é²æ£’æ€§** | Off-policy correction æå‡åˆ†å¸ƒå¼è®­ç»ƒç¨³å®šæ€§ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸å·¥ä½œè´Ÿè½½
- ä½¿ç”¨åŸºäºçœŸå® IoT åº”ç”¨ç”Ÿæˆçš„ **åˆæˆ DAG å·¥ä½œè´Ÿè½½**ï¼Œå…±æ„å»º **7,500 ä¸ªå¼‚æ„æœåŠ¡å®ä¾‹**ã€‚
- DAG å‚æ•°åŒ…æ‹¬ï¼š
  - ä»»åŠ¡æ•° $ K \in \{5,10,20,40,80,100\} $
  - å¹¶è¡Œåº¦ï¼ˆfatï¼‰å’Œå¯†åº¦ï¼ˆdensityï¼‰å‚æ•°ç»„åˆç”Ÿæˆå¤šæ ·åŒ–æ‹“æ‰‘
- æ¯ä¸ªä»»åŠ¡åŒ…å« CPUã€å†…å­˜ã€å­˜å‚¨ã€å®‰å…¨éœ€æ±‚åŠæˆªæ­¢æ—¶é—´ç­‰å±æ€§ã€‚

### è®¡ç®—åŸºç¡€è®¾æ–½æ¨¡æ‹Ÿ
- æ„å»ºä¸‰å±‚æ¶æ„ï¼š
  - **Cloud Servers (CSs)**ï¼š20 å°ï¼Œé«˜æ€§èƒ½ä½å»¶è¿Ÿ
  - **Fog Servers (FSs)**ï¼š30 å°ï¼Œä¸­ç­‰æ€§èƒ½
  - **IoT Devices**ï¼š50 å°ï¼Œèµ„æºå—é™
- ç½‘ç»œå¸¦å®½æŒ‰è®¾å¤‡ç±»å‹è®¾å®šï¼ˆIoT: 10â€“50 Mbps, FS: 50â€“200 Mbps, CS: 100â€“1000 Mbpsï¼‰

### å®‰å…¨æ¨¡å‹é…ç½®
- è®¾è®¡ **15 ç±»å®‰å…¨æ§åˆ¶**ï¼Œæ¯ç±»å« 5 ç§èƒ½åŠ›ï¼Œæ¯ç§èƒ½åŠ›ç”± 3 ä¸ªé…ç½®é¡¹ç»„æˆã€‚
- ä¸åŒæœåŠ¡å™¨å®ç°ä¸åŒå­é›†çš„å®‰å…¨æœºåˆ¶ï¼Œå½¢æˆå¼‚æ„å®‰å…¨æ™¯è§‚ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Response Time** | æœåŠ¡å®Œæˆæ—¶é—´ï¼ˆä»¥å…³é”®è·¯å¾„ä¸ºå‡†ï¼‰ |
| **Security Score** | æ‰€æœ‰ä»»åŠ¡å®‰å…¨åŒ¹é…ç¨‹åº¦çš„åŠ æƒæ€»åˆ† |
| **Weighted Cost** | å½’ä¸€åŒ–åçš„ç»¼åˆç›®æ ‡å‡½æ•°å€¼ï¼ˆè¶Šå°è¶Šå¥½ï¼‰ |
| **Convergence Speed** | æ”¶æ•›åˆ°ç¨³å®šè§£æ‰€éœ€çš„è¿­ä»£æ¬¡æ•° |
| **Scalability** | åœ¨ä¸åŒæœåŠ¡å™¨æ•°é‡ä¸‹çš„è¡¨ç°å˜åŒ– |
| **Decision Time Overhead (DTO)** | å•æ¬¡è°ƒåº¦å†³ç­–è€—æ—¶ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æŠ€æœ¯åŸºç¡€ | æ˜¯å¦è€ƒè™‘å®‰å…¨ |
|------|----------|--------------|
| **X-DDRL** | IMPALA-based DDRL | æ˜¯ï¼ˆæ”¹è¿›ç‰ˆï¼‰ |
| **A3C-AHP** | A3C + å±‚æ¬¡åˆ†ææ³• | æ˜¯ |
| **DRLIS** | PPO-based DRL | æ˜¯ |
| **PARL** | DDQN-based | æ˜¯ |
| **SCRA** | DQN-based | æ˜¯ |

æ‰€æœ‰åŸºçº¿å‡è¿›è¡Œäº†è¶…å‚æ•°è°ƒä¼˜ä»¥ä¿è¯å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»
| æŒ‡æ ‡ | SPA-DDRL è¡¨ç° | å¯¹æ¯”æœ€ä½³åŸºçº¿æå‡ |
|------|---------------|------------------|
| **å“åº”æ—¶é—´** | ~360 ms | æ¯” X-DDRL å¿« **16.3%** |
| **æ”¶æ•›é€Ÿåº¦** | ~40 è¿­ä»£æ”¶æ•› | æ¯” X-DDRL å¿« **33%** |
| **å®‰å…¨å¾—åˆ†** | æ¥è¿‘æœ€ä¼˜ï¼ˆ~1600ï¼‰ | å”¯ä¸€å§‹ç»ˆæ»¡è¶³ç¡¬çº¦æŸ |
| **åŠ æƒæˆæœ¬** | æ¥è¿‘é›¶ | æ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³• |

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰æ”¶æ•›æ€§åˆ†æï¼ˆFigure 4ï¼‰
- **å“åº”æ—¶é—´**ï¼š
  - SPA-DDRL æ”¶æ•›è‡³çº¦ **360ms**
  - X-DDRL è¾¾åˆ° 430msï¼ˆå·® 16.3%ï¼‰
  - A3C-AHP å’Œ DRLIS è¶…è¿‡ 950ms
  - PARL å’Œ SCRA å‡ ä¹ä¸æ”¶æ•›ï¼ˆ~1300msï¼‰
- **å®‰å…¨å¾—åˆ†**ï¼š
  - SPA-DDRLã€X-DDRLã€A3C-AHP å¯è¾¾å¯è¡Œè§£
  - DRLISã€PARLã€SCRA æŒç»­å‡ºç°ä¸¥é‡è¿è§„ï¼ˆè´Ÿç™¾ä¸‡çº§æƒ©ç½šï¼‰
- **åŠ æƒæˆæœ¬**ï¼š
  - SPA-DDRL åœ¨ç¬¬ 50 æ¬¡è¿­ä»£å³æ¥è¿‘é›¶
  - PARL å’Œ SCRA æˆæœ¬é«˜è¾¾ $1.3 \times 10^8$ï¼Œä¸»è¦æ¥è‡ªå®‰å…¨æƒ©ç½š

#### ï¼ˆ2ï¼‰ç³»ç»Ÿè§„æ¨¡æ‰©å±•æ€§æµ‹è¯•ï¼ˆFigure 5ï¼‰
- å½“æœåŠ¡å™¨æ•°é‡ä» 25 å¢è‡³ 100ï¼š
  - SPA-DDRL å“åº”æ—¶é—´ç¨³å®šåœ¨ **~300ms**
  - å…¶ä»–æ–¹æ³•å“åº”æ—¶é—´ä¸Šå‡ 80â€“100%
- **å”¯ä¸€èƒ½åœ¨æ‰€æœ‰è§„æ¨¡ä¸‹ä¿æŒå®‰å…¨åˆè§„çš„æ–¹æ³•æ˜¯ SPA-DDRL**
  - X-DDRL å’Œ A3C-AHP ä»…åœ¨å°è§„æ¨¡å¯è¡Œ
  - PARL å’Œ SCRA åœ¨ä»»ä½•è§„æ¨¡éƒ½æ— æ³•æ»¡è¶³ç¡¬å®‰å…¨çº¦æŸ

#### ï¼ˆ3ï¼‰è®­ç»ƒæ•ˆç‡ï¼ˆSpeedup Analysisï¼‰
- ä½¿ç”¨ 8 ä¸ªå·¥ä½œè¿›ç¨‹æ—¶ï¼ŒSPA-DDRL å®ç° **2.7Ã— åŠ é€Ÿ**
- é«˜äº X-DDRLï¼ˆ2.6Ã—ï¼‰å’Œ A3C-AHPï¼ˆ2.4Ã—ï¼‰
- éåˆ†å¸ƒå¼æ–¹æ³•ï¼ˆDRLISã€PARLã€SCRAï¼‰é€Ÿåº¦æ›´æ…¢ï¼ˆspeedup < 1.0ï¼‰

#### ï¼ˆ4ï¼‰å†³ç­–å¼€é”€ï¼ˆDTOï¼‰
- SPA-DDRL å†³ç­–æ—¶é—´ä¸º **87ms**ï¼Œç•¥é«˜äºåŸºçº¿ï¼ˆ48â€“58msï¼‰
- å¼€é”€ä¸»è¦æ¥è‡ª LSTM æ¨ç†å’Œ PER æ’åº
- ä½†è€ƒè™‘åˆ°å…¶æ˜¾è‘—çš„æ€§èƒ½å¢ç›Šï¼Œè¯¥å¼€é”€å¯æ¥å—

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
- **SPA-DDRL(Base)**ï¼ˆæ—  LSTM & PERï¼‰ï¼šæ”¶æ•›éœ€ ~90 æ¬¡è¿­ä»£
- **+ PER**ï¼šæ”¶æ•›æå‰è‡³ ~70 æ¬¡è¿­ä»£ï¼ˆå¿« 22%ï¼‰
- **+ LSTM**ï¼šæ”¶æ•›è‡³ ~60 æ¬¡è¿­ä»£ï¼ˆå¿« 33%ï¼‰
- **å®Œæ•´ SPA-DDRL**ï¼šä»…éœ€ ~40 æ¬¡è¿­ä»£ï¼ˆæ¯” Base å¿« **56%**ï¼‰
- ç»“è®ºï¼š**LSTM å’Œ PER å‡æœ‰æ•ˆï¼ŒååŒä½œç”¨å¸¦æ¥æœ€å¤§æ”¶ç›Š**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **æ€§èƒ½ä¸å®‰å…¨å¯ä»¥ååŒä¼˜åŒ–**ï¼šé€šè¿‡è®¾è®¡åˆç†çš„å¥–åŠ±å‡½æ•°å’Œå®‰å…¨è¯„åˆ†ä½“ç³»ï¼ŒDRL èƒ½åŒæ—¶ä¼˜åŒ–å“åº”æ—¶é—´å’Œå®‰å…¨åˆè§„æ€§ã€‚
2. âœ… **åˆ†å¸ƒå¼æ¶æ„æ˜¾è‘—æå‡å¯æ‰©å±•æ€§**ï¼šBroker-Learner æ¨¡å¼æ”¯æŒå¤§è§„æ¨¡ Fog ç³»ç»Ÿéƒ¨ç½²ï¼Œä¸”éšèŠ‚ç‚¹å¢åŠ æ€§èƒ½ä¸‹é™ç¼“æ…¢ã€‚
3. âœ… **LSTM å’Œ PER æå¤§æå‡å­¦ä¹ æ•ˆç‡**ï¼šèƒ½æ›´å¿«è¯†åˆ«å¤æ‚ä»»åŠ¡ä¾èµ–æ¨¡å¼å’Œå…³é”®ç»éªŒï¼Œç¼©çŸ­è®­ç»ƒå‘¨æœŸã€‚
4. âœ… **ç¡¬çº¦æŸæœºåˆ¶è‡³å…³é‡è¦**ï¼šæ²¡æœ‰æ˜ç¡®çš„æƒ©ç½šæœºåˆ¶ï¼Œå¤§å¤šæ•° DRL æ–¹æ³•ä¼šæŒç»­äº§ç”Ÿä¸å®‰å…¨çš„æ”¾ç½®æ–¹æ¡ˆã€‚
5. âœ… **SPA-DDRL æ˜¯å”¯ä¸€åœ¨æ‰€æœ‰ç³»ç»Ÿè§„æ¨¡ä¸‹éƒ½èƒ½ä¿æŒå¯è¡Œè§£çš„æ–¹æ³•**ï¼Œè€Œå…¶ä»–æ–¹æ³•éšç€ç¯å¢ƒå¤æ‚åº¦ä¸Šå‡é€æ¸å¤±æ•ˆã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **å†³ç­–å»¶è¿Ÿè¾ƒé«˜**ï¼šç”±äºå¼•å…¥ LSTM å’Œ PERï¼Œå•æ¬¡æ¨ç†æ—¶é—´è¾ƒé•¿ï¼ˆ87msï¼‰ï¼Œå¯èƒ½ä¸é€‚åˆæç«¯å®æ—¶åœºæ™¯ã€‚
- **ä¾èµ–å‡†ç¡®çš„å®‰å…¨å»ºæ¨¡**ï¼šå®‰å…¨è¯„åˆ†æ¨¡å‹çš„æœ‰æ•ˆæ€§å–å†³äºå®é™…ç¯å¢ƒä¸­å®‰å…¨é…ç½®çš„çœŸå®æ€§å’Œå¯è§‚æµ‹æ€§ã€‚
- **è¶…å‚æ•°æ•æ„Ÿ**ï¼šè™½ç„¶è¿›è¡Œäº†è°ƒä¼˜ï¼Œä½†åœ¨æ–°ç¯å¢ƒä¸‹ä»éœ€é‡æ–°è°ƒæ•´ LSTMã€PERã€clip ç­‰å‚æ•°ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³ Federated Learning åœºæ™¯**ï¼šåœ¨ä¿æŠ¤éšç§çš„åŒæ—¶è¿›è¡Œå®‰å…¨æ„ŸçŸ¥çš„æœåŠ¡æ”¾ç½®ã€‚
2. **åŠ¨æ€å®‰å…¨éœ€æ±‚è°ƒæ•´æœºåˆ¶**ï¼šç»“åˆå®æ—¶å¨èƒæƒ…æŠ¥ï¼ŒåŠ¨æ€è°ƒæ•´ä»»åŠ¡çš„å®‰å…¨ç­‰çº§å’Œé˜²æŠ¤ç­–ç•¥ã€‚
3. **è½»é‡åŒ–æ¨¡å‹è®¾è®¡**ï¼šé™ä½ LSTM å’Œç¥ç»ç½‘ç»œå¤æ‚åº¦ï¼Œå‡å°‘å†³ç­–å»¶è¿Ÿï¼Œé€‚åº”æ›´å¤šè¾¹ç¼˜è®¾å¤‡ã€‚
4. **è·¨åŸŸååŒä¼˜åŒ–**ï¼šç ”ç©¶è·¨å¤šä¸ªç®¡ç†åŸŸçš„ Fog ç½‘ç»œä¸­å®‰å…¨ä¸æ€§èƒ½çš„åè°ƒæœºåˆ¶ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> SPA-DDRL æ˜¯é¦–ä¸ªåœ¨ **å¤§è§„æ¨¡å¼‚æ„ Fog ç¯å¢ƒä¸­å®ç°æ€§èƒ½ä¸å®‰å…¨è”åˆä¼˜åŒ–ä¸”å§‹ç»ˆä¿æŒåˆè§„å¯è¡Œ** çš„åˆ†å¸ƒå¼ DRL æ¡†æ¶ï¼Œé€šè¿‡ **ä¸‰å±‚å®‰å…¨æ¨¡å‹ + åˆ†å¸ƒå¼æ¶æ„ + LSTM/PER/off-policy correction** çš„åˆ›æ–°ç»„åˆï¼Œåœ¨å“åº”æ—¶é—´ã€æ”¶æ•›é€Ÿåº¦å’Œå¯æ‰©å±•æ€§æ–¹é¢å…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚

</details>

---

### 13. [Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission](https://arxiv.org/abs/2601.02253)

**Authors**: Emrah Mete, Emin Erkan Korkmaz  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.02253v1  

#### Abstract
The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply sca...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission â€”â€” æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£æ·±åº¦å­¦ä¹ ä¸¥é‡ä¾èµ–é«˜ç®—åŠ›ç¡¬ä»¶ï¼ˆå¦‚GPUï¼‰ï¼Œå…¶æ ¸å¿ƒç“¶é¢ˆåœ¨äºå‰å‘ä¼ æ’­ä¸­å¯†é›†çš„æµ®ç‚¹çŸ©é˜µä¹˜æ³•æ“ä½œã€‚è¿™äº›æ“ä½œä¸ä»…èƒ½è€—é«˜ã€æˆæœ¬æ˜‚è´µï¼Œä¸”éš¾ä»¥éƒ¨ç½²åœ¨è¾¹ç¼˜è®¾å¤‡ï¼ˆedge devicesï¼‰å’Œä½åŠŸè€—èŠ¯ç‰‡ä¸Šã€‚æ­¤å¤–ï¼Œä¼ ç»Ÿäººå·¥ç¥ç»ç½‘ç»œçš„ä¹˜æ³•æœºåˆ¶ç¼ºä¹ç”Ÿç‰©å¯è§£é‡Šæ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§å…¨æ–°çš„**å®Œå…¨æ— ä¹˜æ³•**ï¼ˆmultiplication-freeï¼‰ç¥ç»ç½‘ç»œæ¶æ„â€”â€”**Neuro-Channel Networks (NCN)**ï¼Œå…¶è®¾è®¡çµæ„Ÿæ¥æºäºç”Ÿç‰©çªè§¦ä¸­çš„ä¿¡å·ä¼ é€’æœºåˆ¶ï¼š

- **Channel Width**ï¼šå°†ä¼ ç»Ÿæƒé‡ $ w $ æ›¿æ¢ä¸ºâ€œé€šé“å®½åº¦â€ï¼Œç”¨äºç‰©ç†é™åˆ¶è¾“å…¥ä¿¡å·å¹…åº¦ï¼Œå®ç°ç±»ä¼¼ç¦»å­é€šé“é¥±å’Œæ•ˆåº”çš„éçº¿æ€§é—¨æ§ã€‚
- **Neurotransmitter Bypass**ï¼šå¼•å…¥ä¸€ä¸ªå¯å­¦ä¹ å‚æ•° $ n $ æ¨¡æ‹Ÿç¥ç»é€’è´¨ä½œç”¨ï¼Œä½œä¸ºåŒ–å­¦è°ƒèŠ‚é€šè·¯ï¼Œåœ¨ä¸»é€šé“å—é™æ—¶æä¾›æ—è·¯ï¼Œç¡®ä¿æ¢¯åº¦æµåŠ¨ã€‚
- æ‰€æœ‰å‰å‘è®¡ç®—ä»…ä½¿ç”¨åŠ æ³•ã€å‡æ³•å’Œä½è¿ç®—ï¼ˆå¦‚ `min`, `sign`, `multiplexing`ï¼‰ï¼Œå½»åº•æ¶ˆé™¤æµ®ç‚¹ä¹˜æ³•ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ç¼ºé™· | NCN çš„ä¼˜åŠ¿ |
|------|------|------------|
| **Binary Neural Networks (BNNs)** | æç«¯é‡åŒ–å¯¼è‡´ä¿¡æ¯ä¸¢å¤±ã€è®­ç»ƒä¸ç¨³å®š | ä¸ä¾èµ–1-bité‡åŒ–ï¼Œä¿ç•™æ›´å¤šè¡¨è¾¾èƒ½åŠ› |
| **AdderNets** | ä½¿ç”¨L1è·ç¦»æ›¿ä»£ç‚¹ç§¯ï¼Œæ•°å­¦è¿‘ä¼¼è€Œéç”Ÿç‰©åˆç† | åŸºäºçœŸå®ç”Ÿç‰©æœºåˆ¶å»ºæ¨¡ï¼Œæ›´å…·ç”Ÿç‰©å­¦åˆç†æ€§ |
| **DeepShiftç­‰ä½ç§»ç½‘ç»œ** | ä»åŸºäºä¹˜æ³•è¿‘ä¼¼ï¼ˆå¹‚æ¬¡é€¼è¿‘ï¼‰ | å®Œå…¨å»é™¤ä¹˜æ³•ï¼Œä»…ç”¨åŠ æ³•ä¸é€»è¾‘æ“ä½œ |
| **Spiking Neural Networks (SNNs)** | éš¾ä»¥è®­ç»ƒï¼ˆä¸å¯å¾®ï¼‰ | æ”¯æŒæ ‡å‡†åå‘ä¼ æ’­ï¼Œè®­ç»ƒç¨³å®š |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼š  
> - ç”Ÿç‰©å¯è§£é‡Šæ€§å¼º  
> - å‰å‘è¿‡ç¨‹é›¶ä¹˜æ³•ï¼Œé€‚åˆè¶…ä½åŠŸè€—ç¡¬ä»¶ï¼ˆCPU/FPGA/ASICï¼‰  
> - å¯å½¢æˆå¤æ‚éçº¿æ€§å†³ç­–è¾¹ç•Œ  

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
æœ¬æ–‡æ˜¯**æ¦‚å¿µéªŒè¯ç ”ç©¶**ï¼ˆproof-of-conceptï¼‰ï¼Œæœªä½¿ç”¨å¤§è§„æ¨¡çœŸå®æ•°æ®é›†ï¼Œè€Œæ˜¯é€‰æ‹©äº†ä¸¤ä¸ªç»å…¸çš„éçº¿æ€§é€»è¾‘å‡½æ•°ä»»åŠ¡ï¼š

- **XOR Problem**ï¼ˆå¼‚æˆ–é—®é¢˜ï¼‰
- **3-bit Majority Function**ï¼ˆä¸‰è¾“å…¥å¤šæ•°è¡¨å†³å‡½æ•°ï¼‰

è¿™ä¸¤ä¸ªé—®é¢˜æ˜¯æ£€éªŒæ¨¡å‹æ˜¯å¦å…·å¤‡éçº¿æ€§åˆ†ç±»èƒ½åŠ›çš„åŸºæœ¬åŸºå‡†ã€‚

### å®éªŒè®¾ç½®
| å‚æ•° | è®¾ç½® |
|------|------|
| ç½‘ç»œç»“æ„ | å…¨è¿æ¥ NCN å±‚ + Softmax è¾“å‡ºå±‚ |
| åˆå§‹åŒ– | æƒé‡ $ w \sim \mathcal{N}(0,1) $ï¼Œç¥ç»é€’è´¨ $ n \sim \mathcal{N}(0,0.5) $ |
| ä¼˜åŒ–å™¨ | SGD with Momentumï¼ˆåŠ¨é‡=0.9ï¼‰ |
| å­¦ä¹ ç‡ | 0.001 |
| æŸå¤±å‡½æ•° | Cross-Entropy Loss |
| è®­ç»ƒç®—æ³• | Standard Backpropagation [8]ï¼ˆå°½ç®¡å‰å‘æ— ä¹˜æ³•ï¼Œä½†è®­ç»ƒé˜¶æ®µä»å…è®¸ä¹˜æ³•ï¼‰ |

#### XOR å®éªŒé…ç½®
- è¾“å…¥ç»´åº¦ï¼š2
- ç½‘ç»œæ‹“æ‰‘ï¼š2 â†’ 4 â†’ 2
- Epochsï¼š1000

#### Majority Function å®éªŒé…ç½®
- è¾“å…¥ç»´åº¦ï¼š3
- ç½‘ç»œæ‹“æ‰‘ï¼š3 â†’ 8 â†’ 2
- Epochsï¼š200

### è¯„ä¼°æŒ‡æ ‡
- **å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**ï¼šå¯¹æ‰€æœ‰å¯èƒ½è¾“å…¥ç»„åˆï¼ˆå…± $2^2=4$ æˆ– $2^3=8$ ç§ï¼‰è¿›è¡Œæµ‹è¯•ï¼Œåˆ¤æ–­æ˜¯å¦å®Œå…¨æ­£ç¡®åˆ†ç±»ã€‚
- **å†³ç­–è¾¹ç•Œå¯è§†åŒ–**ï¼šå±•ç¤ºæ¨¡å‹èƒ½å¦æ„å»ºéçº¿æ€§åˆ†ç¦»é¢ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æœ¬ç ”ç©¶æœªç›´æ¥ä¸å…¶ä»–DNNå˜ä½“ï¼ˆå¦‚BNNã€AdderNetï¼‰åœ¨ç›¸åŒä»»åŠ¡ä¸Šå®šé‡æ¯”è¾ƒæ€§èƒ½æˆ–èƒ½æ•ˆï¼Œè€Œæ˜¯å¼ºè°ƒï¼š
- åœ¨**æ²¡æœ‰ä¹˜æ³•çš„å‰æä¸‹**ï¼ŒNCN èƒ½è§£å†³ä¼ ç»Ÿå•å±‚æ„ŸçŸ¥æœºæ— æ³•å¤„ç†çš„éçº¿æ€§é—®é¢˜ï¼›
- è¯æ˜å…¶å…·å¤‡æ„é€ å¤æ‚å†³ç­–è¾¹ç•Œçš„æ½œåŠ›ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| ä»»åŠ¡ | å‡†ç¡®ç‡ | æ˜¯å¦æ”¶æ•› |
|------|--------|----------|
| XOR Problem | **100%** | æ˜¯ |
| 3-bit Majority Function | **100%** | æ˜¯ |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
è™½ç„¶æ²¡æœ‰æ•°å€¼åŒ–çš„æ¨ªå‘å¯¹æ¯”è¡¨ï¼Œä½†ä»ç†è®ºå’ŒåŠŸèƒ½è§’åº¦å¾—å‡ºä»¥ä¸‹ç»“è®ºï¼š

| ç»´åº¦ | NCN è¡¨ç° |
|------|---------|
| éçº¿æ€§å»ºæ¨¡èƒ½åŠ› | âœ… æˆåŠŸè§£å†³ XOR å’Œ Majority é—®é¢˜ï¼ˆéçº¿æ€§ä¸å¯åˆ†ï¼‰ |
| å†³ç­–è¾¹ç•Œå¤æ‚åº¦ | âœ… å›¾3æ˜¾ç¤ºæ¸…æ™°çš„éçº¿æ€§åˆ†å‰²åŒºåŸŸ |
| æ¢¯åº¦ä¼ æ’­ç¨³å®šæ€§ | âœ… å¼•å…¥ Neurotransmitter Bypass é¿å…â€œæ­»æ¢¯åº¦â€é—®é¢˜ |
| è®¡ç®—æ•ˆç‡ | âœ… åˆæˆæ“ä½œåˆ†æè¡¨æ˜ï¼šæ¯ç¥ç»å…ƒèŠ‚çœ $d$ æ¬¡ä¹˜æ³•ï¼ˆ$d$: è¾“å…¥ç»´æ•°ï¼‰ |

### æ¶ˆèå®éªŒ
è®ºæ–‡ä¸­**æœªæä¾›æ˜ç¡®çš„æ¶ˆèå®éªŒ**ï¼ˆablation studyï¼‰ï¼Œä¾‹å¦‚å…³é—­ Neurotransmitter åˆ†æ”¯æˆ–ç§»é™¤å½’ä¸€åŒ–é¡¹çš„å½±å“ã€‚è¿™æ˜¯å½“å‰å·¥ä½œçš„å±€é™ä¹‹ä¸€ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ— éœ€ä¹˜æ³•ä¹Ÿèƒ½å®ç°éçº¿æ€§å­¦ä¹ **ï¼š  
   NCN åœ¨å‰å‘ä¼ æ’­ä¸­å®Œå…¨å»é™¤æµ®ç‚¹ä¹˜æ³•ï¼Œä»…é€šè¿‡åŠ æ³•ã€æœ€å°å€¼æ“ä½œå’Œç¬¦å·é€»è¾‘å³å¯å®Œæˆ XOR å’Œ Majority è¿™ç±»éçº¿æ€§å¯åˆ†ä»»åŠ¡çš„å­¦ä¹ ï¼Œå¹¶è¾¾åˆ° **100% å‡†ç¡®ç‡**ã€‚

2. **ç”Ÿç‰©å¯å‘æœºåˆ¶æœ‰æ•ˆæ”¯æŒæ·±åº¦å­¦ä¹ **ï¼š  
   å°†çªè§¦çš„â€œç¦»å­é€šé“é™æµâ€å’Œâ€œç¥ç»é€’è´¨è°ƒæ§â€æŠ½è±¡ä¸º Channel Width ä¸ Neurotransmitter Bypassï¼ŒæˆåŠŸæ¨¡æ‹Ÿäº†ç”Ÿç‰©ç³»ç»Ÿçš„é«˜æ•ˆä¿¡å·æ§åˆ¶æœºåˆ¶ã€‚

3. **ç¡¬ä»¶å‹å¥½æ€§æé«˜**ï¼š  
   æ‰€æœ‰æ“ä½œå‡å¯æ˜ å°„ä¸ºç®€å•çš„æ•°å­—ç”µè·¯ï¼ˆæ¯”è¾ƒå™¨ã€å¤šè·¯å¤ç”¨å™¨ã€åŠ æ³•å™¨ï¼‰ï¼Œç‰¹åˆ«é€‚ç”¨äºä½åŠŸè€—è¾¹ç¼˜AIèŠ¯ç‰‡å’Œ neuromorphic hardware è®¾è®¡ã€‚

4. **æ–¹å·®ç¨³å®šæœºåˆ¶æœ‰æ•ˆ**ï¼š  
   å¼•å…¥ $\frac{1}{\sqrt{d}}$ å½’ä¸€åŒ–å› å­é˜²æ­¢ä¿¡å·çˆ†ç‚¸ï¼Œæ¨¡ä»¿ç”Ÿç‰©ä¸­çš„ homeostatic plasticityï¼Œé¿å…å¤æ‚åˆå§‹åŒ–ç­–ç•¥ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **å°šå¤„æ¦‚å¿µéªŒè¯é˜¶æ®µ**ï¼š  
   å®éªŒä»…åœ¨æå°è§„æ¨¡é€»è¾‘å‡½æ•°ä¸ŠéªŒè¯ï¼Œå°šæœªæ‰©å±•åˆ°å›¾åƒè¯†åˆ«ï¼ˆå¦‚MNIST/CIFARï¼‰ç­‰å®é™…ä»»åŠ¡ã€‚

2. **è®­ç»ƒé˜¶æ®µä»ä¾èµ–ä¹˜æ³•**ï¼š  
   å½“å‰ä½¿ç”¨æ ‡å‡† BP ç®—æ³•æ›´æ–°å‚æ•°ï¼Œåå‘ä¼ æ’­ä¸­ä»æœ‰ä¹˜æ³•æ“ä½œã€‚ä½œè€…æ‰¿è®¤éœ€è¿›ä¸€æ­¥å¼€å‘ multiplication-free trainingï¼ˆå¦‚ SignSGD ç±»æ–¹æ³•ï¼‰ã€‚

3. **ç¼ºä¹æ¶ˆèå®éªŒä¸èƒ½æ•ˆå®æµ‹**ï¼š  
   æœªéªŒè¯å„ç»„ä»¶å¿…è¦æ€§ï¼›ä¹Ÿæœªåœ¨ FPGA/ASIC ä¸Šæµ‹é‡çœŸå®åŠŸè€—ï¼Œä»…ä¸ºç†è®ºæ¨å¯¼ã€‚

4. **æ‰©å±•æ€§å¾…éªŒè¯**ï¼š  
   æ˜¯å¦èƒ½åœ¨æ·±å±‚ç½‘ç»œä¸­ä¿æŒæ€§èƒ½ã€å¦‚ä½•é€‚é…å·ç§¯ç»“æ„ç­‰é—®é¢˜å°šæœªæ¢è®¨ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
ä½œè€…æ˜ç¡®æå‡ºä¸‰ä¸ªæˆ˜ç•¥æ–¹å‘ï¼š

1. **å®ç°ç«¯åˆ°ç«¯æ— ä¹˜æ³•è®­ç»ƒ**ï¼š  
   æ¢ç´¢åŸºäº SignSGD ç­‰ä¼˜åŒ–å™¨ï¼Œä½¿è®­ç»ƒè¿‡ç¨‹ä¹Ÿæ‘†è„±ä¹˜æ³•ä¾èµ–ã€‚

2. **æ‰©å±•è‡³æ·±ç½‘ç»œä¸çœŸå®æ•°æ®é›†**ï¼š  
   åœ¨ MNISTã€CIFAR-10 ä¸Šæµ‹è¯• NCN çš„è¡¨ç¤ºå­¦ä¹ èƒ½åŠ›ï¼Œæ¢ç´¢å…¶åœ¨ CV/NLP ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

3. **é¢å‘ç¥ç»å½¢æ€ç¡¬ä»¶ååŒè®¾è®¡**ï¼š  
   å°† NCN æ˜ å°„åˆ° FPGA å’Œå®šåˆ¶ ASICï¼Œå®æµ‹æ¨ç†å»¶è¿Ÿä¸åŠŸè€—ï¼Œæ¨åŠ¨ä¸‹ä¸€ä»£ä½åŠŸè€— AI èŠ¯ç‰‡å‘å±•ã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> Neuro-Channel Networks (NCN) æå‡ºäº†ä¸€ç§å—ç”Ÿç‰©çªè§¦å¯å‘çš„å…¨æ–°ç¥ç»æ¶æ„ï¼Œé¦–æ¬¡è¯æ˜**æ— éœ€ä»»ä½•ä¹˜æ³•æ“ä½œä¹Ÿèƒ½é€šè¿‡æ ‡å‡†BPè®­ç»ƒè§£å†³éçº¿æ€§é—®é¢˜**ï¼Œä¸ºæœªæ¥è¶…ä½åŠŸè€—ã€ç”Ÿç‰©å¯è§£é‡Šçš„äººå·¥æ™ºèƒ½ç³»ç»Ÿæä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 14. [ShrimpXNet: A Transfer Learning Framework for Shrimp Disease Classification with Augmented Regularization, Adversarial Training, and Explainable AI](https://arxiv.org/abs/2601.00832)

**Authors**: Israk Hasan Jone, D. M. Rafiun Bin Masud, Promit Sarker, Sayed Fuad Al Labib, Nazmul Islam, Farhad Billah  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.00832v1  

#### Abstract
Shrimp is one of the most widely consumed aquatic species globally, valued for both its nutritional content and economic importance. Shrimp farming represents a significant source of income in many regions; however, like other forms of aquaculture, it is severely impacted by disease outbreaks. These...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šShrimpXNet: A Transfer Learning Framework for Shrimp Disease Classification with Augmented Regularization, Adversarial Training, and Explainable AI

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- é’ˆå¯¹**è™¾ç±»å…»æ®–ä¸­ç–¾ç—…çˆ†å‘å¯¼è‡´é«˜æ­»äº¡ç‡å’Œç»æµæŸå¤±**çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯å¦‚ç™½ç‚¹ç»¼åˆå¾ç—…æ¯’ï¼ˆWSSVï¼‰å’Œé»‘é³ƒç—…ï¼ˆBGï¼‰ç­‰å¸¸è§ç–¾ç—…çš„å¿«é€Ÿã€å‡†ç¡®è¯Šæ–­éš¾é¢˜ã€‚
- ä¼ ç»Ÿè¯Šæ–­æ–¹æ³•ä¾èµ–äººå·¥è§‚å¯Ÿï¼Œæ•ˆç‡ä½ã€ä¸»è§‚æ€§å¼ºï¼Œéš¾ä»¥åœ¨å°è§„æ¨¡å…»æ®–æˆ·ä¸­æ™®åŠï¼ŒäºŸéœ€è‡ªåŠ¨åŒ–ã€å¯æ‰©å±•çš„æ™ºèƒ½æ£€æµ‹æ–¹æ¡ˆã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬ç ”ç©¶æå‡ºäº† **ShrimpXNet** â€”â€” ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„ç«¯åˆ°ç«¯è™¾ç—…åˆ†ç±»æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **å¤šæŠ€æœ¯èåˆçš„é²æ£’æ€§å¢å¼ºç­–ç•¥**ï¼š
   - å¼•å…¥ **Adversarial Trainingï¼ˆå¯¹æŠ—è®­ç»ƒï¼‰** ä½¿ç”¨ Fast Gradient Sign Method (FGSM) æå‡æ¨¡å‹å¯¹æ‰°åŠ¨è¾“å…¥çš„é²æ£’æ€§ã€‚
   - åº”ç”¨ **Augmented Regularizationï¼ˆå¢å¼ºæ­£åˆ™åŒ–ï¼‰** æŠ€æœ¯ï¼Œç»“åˆ **CutMix å’Œ MixUp** æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œç¼“è§£è¿‡æ‹Ÿåˆå¹¶æå‡æ³›åŒ–èƒ½åŠ›ã€‚

2. **å¯è§£é‡Šæ€§AIï¼ˆExplainable AI, XAIï¼‰é›†æˆ**ï¼š
   - é¦–æ¬¡åœ¨è™¾ç—…åˆ†ç±»ä»»åŠ¡ä¸­ç³»ç»Ÿåº”ç”¨ **Grad-CAMã€Grad-CAM++ å’Œ XGrad-CAM** å¯è§†åŒ–æŠ€æœ¯ï¼Œæ­ç¤ºæ¨¡å‹å…³æ³¨åŒºåŸŸï¼Œå¢å¼ºå†³ç­–é€æ˜åº¦ï¼Œä¾¿äºå†œæ°‘å’Œä¸“å®¶ç†è§£ä¸ä¿¡ä»»ã€‚

3. **å…¨æµç¨‹ä¼˜åŒ–è®¾è®¡**ï¼š
   - åœ¨é¢„å¤„ç†é˜¶æ®µé‡‡ç”¨ `rembg` å·¥å…·å»é™¤å›¾åƒèƒŒæ™¯ï¼Œå‡å°‘æ— å…³å¹²æ‰°ï¼›
   - åˆ©ç”¨ **Transfer Learning + Fine-tuning** ç­–ç•¥ï¼Œåœ¨å¤šä¸ªé¢„è®­ç»ƒæ¨¡å‹ä¸Šè¿›è¡Œå¾®è°ƒï¼Œå¹¶é€šè¿‡ç½‘æ ¼æœç´¢ç¡®å®šæœ€ä¼˜è§£å†»å±‚æ•°ï¼›
   - æ„å»ºè½»é‡çº§ CNN åˆ†ç±»å¤´ï¼Œé€‚é…ç§»åŠ¨ç«¯éƒ¨ç½²éœ€æ±‚ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | æœ¬æ–‡æ–¹æ³•ï¼ˆShrimpXNetï¼‰ | å…¶ä»–ç ”ç©¶ |
|--------|----------------------|---------|
| ç–¾ç—…è¦†ç›–èŒƒå›´ | å››ç±»ï¼šHealthy, BG, WSSV, WSSV_BG | å¤šä¸ºå•ç—…ç§ï¼ˆå¦‚ä»…WSSVï¼‰æˆ–éç—…ç†ç‰¹å¾ï¼ˆå¦‚è‰²ç´ æ²‰ç€ï¼‰ |
| å‡†ç¡®ç‡ | **96.88%**ï¼ˆConvNeXt-Tinyï¼‰ | æœ€é«˜97.22%ï¼Œä½†æ— XAIæ”¯æŒ |
| å¯è§£é‡Šæ€§ | æ”¯æŒå¤šç§Grad-CAMå¯è§†åŒ– | å¤šæ•°ç¼ºä¹XAIæœºåˆ¶ |
| é²æ£’æ€§ | åŒ…å«FGSMå¯¹æŠ—è®­ç»ƒã€CutMix/MixUpå¢å¼º | å¤šæ•°æœªè€ƒè™‘å™ªå£°æˆ–å¤æ‚èƒŒæ™¯å½±å“ |
| ç§»åŠ¨å…¼å®¹æ€§ | è½»é‡åŒ–è®¾è®¡ï¼Œé€‚åˆç°åœºä½¿ç”¨ | éƒ¨åˆ†æ¨¡å‹è®¡ç®—å¼€é”€å¤§ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šShrimpXNet æ˜¯é¦–ä¸ªå°† **å¯¹æŠ—è®­ç»ƒã€å¢å¼ºæ­£åˆ™åŒ–ä¸å¯è§£é‡ŠAI** ç»¼åˆåº”ç”¨äºè™¾ç—…åˆ†ç±»çš„ç ”ç©¶ï¼Œå®ç°äº†é«˜ç²¾åº¦ã€å¼ºé²æ£’æ€§å’Œé«˜å¯ä¿¡åº¦çš„ç»Ÿä¸€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“ æ•°æ®é›†
- åç§°æ¥æºï¼šå…¬å¼€æ•°æ®é›† [ShrimpDiseaseBD](https://doi.org/10.1016/j.dib.2025.111553)ï¼ˆæ¥è‡ª Mendeleyï¼‰
- å›¾åƒæ€»æ•°ï¼š**1,149 å¼ è¶…å£°å›¾åƒ**
- åˆ†ç±»ç±»åˆ«ï¼ˆ4ç±»ï¼‰ï¼š
  - Healthyï¼ˆå¥åº·ï¼‰
  - Black Gill (BG)
  - White Spot Syndrome Virus (WSSV)
  - Co-infection: WSSV_BGï¼ˆå¤åˆæ„ŸæŸ“ï¼‰
- æ•°æ®åˆ’åˆ†ï¼š
  - è®­ç»ƒé›†ï¼š70%ï¼ˆ804å¼ ï¼‰
  - éªŒè¯é›†ï¼š15%ï¼ˆ172å¼ ï¼‰
  - æµ‹è¯•é›†ï¼š15%ï¼ˆ173å¼ ï¼‰

### âš™ï¸ å®éªŒè®¾ç½®
- **é¢„å¤„ç†æµç¨‹**ï¼š
  1. ä½¿ç”¨ `rembg` åˆ é™¤å›¾åƒèƒŒæ™¯ï¼ˆè§ Fig. 3ï¼‰
  2. Keras å›¾åƒç®¡é“æ ‡å‡†åŒ–å¤„ç†ï¼ˆå½’ä¸€åŒ–ã€å°ºå¯¸è°ƒæ•´è‡³ 224Ã—224ï¼‰
- **æ¨¡å‹é€‰æ‹©ï¼ˆ6ä¸ªé¢„è®­ç»ƒCNNï¼‰**ï¼š
  - ResNet50
  - EfficientNet
  - DenseNet201
  - MobileNetV3
  - ConvNeXt-Tiny
  - Xception
- **è®­ç»ƒé…ç½®ï¼ˆè§ Table Iï¼‰**ï¼š
  | å‚æ•° | è®¾ç½® |
  |-----|------|
  | Optimizer | Adam |
  | Loss Function | SparseCategoricalCrossentropy |
  | Scheduler | StepLR (step_size=3) |
  | Epochs | 30 |
  | Batch Size | 128 |
  | Patience | 5ï¼ˆæ—©åœæœºåˆ¶ï¼‰ |

- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - Accuracy, Precision, Recall, F1-Score
  - Confusion Matrix
  - ROC Curve & AUC
  - 99% Confidence Intervalï¼ˆåŸºäº1000æ¬¡bootstrapè¿­ä»£ï¼‰

- **åŸºçº¿å¯¹æ¯”æ–¹æ³•**ï¼š
  - æ–‡çŒ®ä¸­çš„ä»£è¡¨æ€§æ–¹æ³•ï¼ˆè§ Table VIï¼‰ï¼š
    - YOLOv8-based detection [4]
    - DenseNet121 + Triplet Loss [6]
    - CNN for field diagnosis [7]
    - DICNN for WSSV only [10]

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table II & Vï¼‰

| æ¨¡å‹ | Accuracy | Precision | Recall | F1-Score |
|------|----------|-----------|--------|----------|
| **ConvNeXt-Tiny** | **96.88%** | **97.10%** | **96.88%** | **96.89%** |
| EfficientNet | 92.71% | 93.03% | 92.71% | 92.55% |
| DenseNet201 | 90.10% | 90.23% | 90.10% | 90.07% |
| Xception | 89.06% | 89.71% | 89.06% | 88.76% |
| ResNet50 | 89.06% | 89.38% | 89.06% | 89.01% |
| MobileNetV3 | 55.21% | 39.80% | 55.21% | 44.54% |

> ğŸ’¡ **æœ€ä½³æ¨¡å‹**ï¼š**ConvNeXt-Tiny** æ˜æ˜¾ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œä¸”è®­ç»ƒè¿‡ç¨‹ç¨³å®šï¼ˆè§ Fig. 8ï¼‰ï¼ŒéªŒè¯æŸå¤±ä¸è®­ç»ƒæŸå¤±é«˜åº¦ä¸€è‡´ï¼Œè¡¨æ˜æ— æ˜æ˜¾è¿‡æ‹Ÿåˆã€‚

### ğŸ” ç»†ç²’åº¦åˆ†ç±»è¡¨ç°ï¼ˆTable Vï¼‰
ConvNeXt-Tiny åœ¨å„ç±»åˆ«ä¸Šçš„è¡¨ç°æä¸ºå‡è¡¡ï¼š
- **WSSV ç±»å¬å›ç‡é«˜è¾¾ 100%** â†’ æå°‘æ¼æ£€è‡´å‘½ç—…æ¯’
- **BG ä¸ WSSV_BG ç±»ç²¾ç¡®ç‡ä¸º 100%** â†’ å‡å°‘è¯¯æŠ¥
- æ‰€æœ‰ç±»åˆ«çš„ F1-score å‡ > 90%
- æ€»ä½“ macro avg è¾¾åˆ° **97%**

### ğŸ¤ ä¸å…¶ä»–å·¥ä½œçš„å¯¹æ¯”ï¼ˆTable VIï¼‰
| æ–¹æ³• | Accuracy | XAI | Robustness Enhancements |
|------|----------|-----|------------------------|
| [4] YOLOv8 | 92.7% | âŒ | âŒ |
| [6] DenseNet | 92% | âŒ | âŒ |
| [7] CNN | 90.02% | âŒ | âŒ |
| [10] DICNN | 97.22% | âŒ | âŒ |
| **Proposed (ConvNeXt-Tiny)** | **96.88%** | âœ… | âœ… |

> âœ… å°½ç®¡å‡†ç¡®ç‡ç•¥ä½äºæŸå•ä¸€ç ”ç©¶ï¼ˆ97.22%ï¼‰ï¼Œä½†æœ¬æ–‡æ˜¯å”¯ä¸€åŒæ—¶å…·å¤‡ **é«˜ç²¾åº¦ + å¯è§£é‡Šæ€§ + é²æ£’æ€§å¢å¼º** çš„å®Œæ•´è§£å†³æ–¹æ¡ˆã€‚

### ğŸ”§ æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰Augmented Regularizationï¼ˆTable IIIï¼‰
| MixUp Î± / CutMix Î± | Test Accuracy |
|--------------------|---------------|
| 0 / 0ï¼ˆåŸå§‹ï¼‰ | **96.88%** |
| 0.2 / 0.3 | 95.42% |
| 0.3 / 0.5 | 93.61% |
| 0.4 / 0.7 | 88.95% |

> ğŸ” ç»“è®ºï¼šå¼•å…¥ MixUp/CutMix åç²¾åº¦ç•¥æœ‰ä¸‹é™ï¼Œä½†æå‡äº†æ¨¡å‹æ³›åŒ–èƒ½åŠ›å’ŒæŠ—å™ªæ€§ï¼Œå±äºåˆç†æƒè¡¡ã€‚

#### ï¼ˆ2ï¼‰Adversarial Trainingï¼ˆTable IVï¼‰
| Îµï¼ˆFGSMæ‰°åŠ¨å¼ºåº¦ï¼‰ | Test Accuracy |
|--------------------|---------------|
| 0ï¼ˆåŸå§‹ï¼‰ | **96.88%** |
| 0.1 | 94.42% |
| 0.14 | 88.61% |
| 0.16 | 79.13% |
| 0.2 | 59.38% |

> âš ï¸ ç»“è®ºï¼šéšç€æ‰°åŠ¨å¢å¤§ï¼Œæ€§èƒ½ä¸‹é™æ˜æ˜¾ï¼Œä½†åœ¨ Îµ=0.14 æ—¶ä»ä¿æŒ **88.61%** çš„è¾ƒé«˜å‡†ç¡®ç‡ï¼Œè¯´æ˜æ¨¡å‹å…·æœ‰ä¸€å®šé²æ£’æ€§ã€‚

#### ï¼ˆ3ï¼‰Confidence Interval
- ç»è¿‡ 1000 æ¬¡ bootstrap è¿­ä»£ï¼š
  - å¹³å‡å‡†ç¡®ç‡ï¼š**96.2%**
  - æ ‡å‡†å·®ï¼š0.0034
  - **99% CI: [0.953, 0.971]** â†’ è¡¨æ˜ç»“æœå…·æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§å’Œç¨³å®šæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ConvNeXt-Tiny æ˜¯æœ€é€‚åˆè¯¥ä»»åŠ¡çš„ backbone**ï¼Œåœ¨ç²¾åº¦ã€é€Ÿåº¦å’Œèµ„æºæ¶ˆè€—ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡ã€‚
2. **èƒŒæ™¯ç§»é™¤ + å¯¹æŠ—è®­ç»ƒ + å¢å¼ºæ­£åˆ™åŒ–** æ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨çœŸå®åœºæ™¯ä¸‹çš„é²æ£’æ€§ã€‚
3. **Grad-CAM ç³»åˆ—å¯è§†åŒ–å·¥å…·æœ‰æ•ˆæ­ç¤ºäº†æ¨¡å‹æ³¨æ„åŠ›é›†ä¸­åœ¨ç—…å˜éƒ¨ä½**ï¼ˆå¦‚é³ƒéƒ¨ã€å¤–å£³æ–‘ç‚¹ï¼‰ï¼Œå¢å¼ºäº†æ¨¡å‹å¯ä¿¡åº¦ã€‚
4. æ‰€ææ¡†æ¶å…·å¤‡è‰¯å¥½çš„ **ç§»åŠ¨ç«¯å…¼å®¹æ€§**ï¼Œé€‚ç”¨äºä¸€çº¿å…»æ®–æˆ·ç°åœºä½¿ç”¨ã€‚

### âš ï¸ å±€é™æ€§
1. å½“å‰ä»…åŸºäºé™æ€å›¾åƒåˆ†æï¼Œå°šæœªæ‰©å±•åˆ°è§†é¢‘æµå®æ—¶ç›‘æµ‹ã€‚
2. æ•°æ®é›†è§„æ¨¡ç›¸å¯¹è¾ƒå°ï¼ˆ<1.2kï¼‰ï¼Œå¯èƒ½å­˜åœ¨åˆ†å¸ƒåå·®ã€‚
3. ç¼ºä¹å†…éƒ¨ç”Ÿç†çŠ¶æ€ï¼ˆå¦‚å¾®ç”Ÿç‰©ç»„ã€æ°´è´¨å‚æ•°ï¼‰çš„å¤šæ¨¡æ€èåˆã€‚
4. å¯¹ç½•è§ç—…ç§æˆ–æ–°å‹å˜å¼‚ç—…æ¯’çš„æ³›åŒ–èƒ½åŠ›æœ‰å¾…éªŒè¯ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **Real-time Video Monitoring**ï¼šæ„å»ºåŠ¨æ€ç›‘æ§ç³»ç»Ÿï¼Œå®ç°è¿ç»­å¥åº·è¿½è¸ªã€‚
2. **Multimodal Integration**ï¼šèåˆæ°´è´¨ä¼ æ„Ÿå™¨ã€å¾®ç”Ÿç‰©ç»„æ•°æ®ä¸å›¾åƒä¿¡æ¯ï¼Œæå‡é¢„æµ‹å…¨é¢æ€§ã€‚
3. **Edge Deployment Optimization**ï¼šè¿›ä¸€æ­¥å‹ç¼©æ¨¡å‹ï¼ˆå¦‚è’¸é¦ã€é‡åŒ–ï¼‰ï¼Œé€‚é…ä½ç«¯è®¾å¤‡ã€‚
4. **è·¨åœ°åŸŸæ³›åŒ–ç ”ç©¶**ï¼šåœ¨ä¸åŒå›½å®¶/æ°”å€™åŒºçš„å…»æ®–åœºä¸­éªŒè¯æ¨¡å‹é€‚åº”æ€§ã€‚
5. **ä¸»åŠ¨å­¦ä¹ æœºåˆ¶**ï¼šå…è®¸æ¨¡å‹åœ¨ä¸ç¡®å®šæ—¶è¯·æ±‚äººå·¥æ ‡æ³¨ï¼ŒæŒç»­è¿­ä»£å‡çº§ã€‚

---

## âœ… æ€»ç»“
**ShrimpXNet** æˆåŠŸæ„å»ºäº†ä¸€ä¸ªé¢å‘å®é™…åº”ç”¨çš„è™¾ç—…æ™ºèƒ½è¯Šæ–­ç³»ç»Ÿï¼Œä¸ä»…è¾¾åˆ°äº† **96.88% çš„é«˜å‡†ç¡®ç‡**ï¼Œæ›´é€šè¿‡ **å¯¹æŠ—è®­ç»ƒã€å¢å¼ºæ­£åˆ™åŒ–å’Œå¯è§£é‡ŠAI** å®ç°äº†â€œçœ‹å¾—æ‡‚ã€ä¿¡å¾—è¿‡ã€ç”¨å¾—èµ·â€çš„ç›®æ ‡ã€‚å®ƒä¸ºæ°´äº§å…»æ®–æ™ºèƒ½åŒ–æä¾›äº†å¯å¤åˆ¶çš„æŠ€æœ¯èŒƒå¼ï¼Œæœ‰æœ›åœ¨å…¨çƒèŒƒå›´å†…æ¨åŠ¨å¯æŒç»­æ¸”ä¸šå‘å±•ã€‚

</details>

---

### 15. [A New Benchmark for the Appropriate Evaluation of RTL Code Optimization](https://arxiv.org/abs/2601.01765)

**Authors**: Yao Lu, Shang Liu, Hangan Zhou, Wenji Fang, Qijun Zhang, Zhiyao Xie  
**Category**: cs.AI  
**Published**: 2026-01-06  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.01765v1  

#### Abstract
The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠA New Benchmark for the Appropriate Evaluation of RTL Code Optimizationã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ RTL ä»£ç ç”Ÿæˆç ”ç©¶ç¼ºä¹å¯¹**è®¾è®¡è´¨é‡ä¼˜åŒ–**ï¼ˆPPAï¼šPower, Performance, Areaï¼‰çš„æœ‰æ•ˆè¯„ä¼°ã€‚ç°æœ‰çš„åŸºå‡†ï¼ˆå¦‚ [26]ï¼‰ä¸»è¦å…³æ³¨è¯­æ³•æ­£ç¡®æ€§å’ŒåŠŸèƒ½ç­‰ä»·æ€§ï¼Œè€Œå¿½è§†äº†ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š
- **ä¸åˆ‡å®é™…çš„ä¼˜åŒ–æ¡ˆä¾‹**ï¼šè®¸å¤šâ€œæ¬¡ä¼˜â€RTLä»£ç å­˜åœ¨äººä¸ºæ„é€ çš„å†—ä½™æ“ä½œï¼ˆå¦‚ `s1 + 0` æˆ– `s1 * 1`ï¼‰ï¼Œåœ¨å·¥ä¸šçº§ç»¼åˆå·¥å…·ï¼ˆå¦‚ Synopsys DCï¼‰ä¸‹ä¼šè¢«è½»æ˜“æ¶ˆé™¤ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœå¤±çœŸã€‚
- **è¯„ä¼°æµç¨‹è–„å¼±**ï¼šä¾èµ–å¼±ç»¼åˆå·¥å…·ï¼ˆå¦‚ Yosysï¼‰ï¼Œæ— æ³•åæ˜ çœŸå®èŠ¯ç‰‡è®¾è®¡æµç¨‹ä¸­çš„å¤æ‚æƒè¡¡ã€‚
- **è¯„ä¼°ç»´åº¦å•ä¸€**ï¼šä»…å…³æ³¨é¢ç§¯ï¼Œå¿½ç•¥åŠŸè€—ã€æ—¶åºï¼ˆWNS/TNSï¼‰ç­‰å…³é”®æŒ‡æ ‡ã€‚

è¿™ä½¿å¾—ç°æœ‰åŸºå‡†éš¾ä»¥å‡†ç¡®è¡¡é‡LLMåœ¨**çœŸæ­£æœ‰æ„ä¹‰çš„ç¡¬ä»¶ä¼˜åŒ–èƒ½åŠ›**ä¸Šçš„è¡¨ç°ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
æœ¬æ–‡æå‡º **RTL-OPT** â€”â€” ä¸€ä¸ªä¸“ä¸ºè¯„ä¼° LLM åœ¨ RTL ä»£ç ä¼˜åŒ–æ–¹é¢èƒ½åŠ›è€Œè®¾è®¡çš„æ–°åŸºå‡†ã€‚

#### ä¸»è¦åˆ›æ–°åŒ…æ‹¬ï¼š
1. **é«˜è´¨é‡ã€ç°å®æ€§å¼ºçš„æ‰‹å·¥è®¾è®¡ä»»åŠ¡é›†**
   - åŒ…å« **36 ä¸ªæ‰‹å·¥ç¼–å†™**çš„ RTL è®¾è®¡ä»»åŠ¡ï¼Œæ¶µç›–ç»„åˆé€»è¾‘ã€æµæ°´çº¿æ•°æ®è·¯å¾„ã€æœ‰é™çŠ¶æ€æœºï¼ˆFSMï¼‰ã€å­˜å‚¨å™¨æ¥å£ç­‰å¤šç§ç±»å‹ã€‚
   - æ¯ä¸ªä»»åŠ¡æä¾›ä¸€å¯¹ RTL ä»£ç ï¼š
     - **Suboptimal Version**ï¼šåŠŸèƒ½æ­£ç¡®ä½†æ•…æ„é—æ¼è¡Œä¸šæ ‡å‡†ä¼˜åŒ–æœºä¼šçš„è®¾è®¡ã€‚
     - **Optimized Version**ï¼šç”±ä¸“å®¶æ‰‹å·¥ä¼˜åŒ–çš„â€œé»„é‡‘å‚è€ƒâ€ï¼Œä½“ç°çœŸå®æœ‰æ•ˆçš„ä¼˜åŒ–æ¨¡å¼ã€‚

2. **çœŸå®ä¸”å¤šæ ·åŒ–çš„ä¼˜åŒ–æ¨¡å¼**
   æ‰€æœ‰ä¼˜åŒ–å‡åŸºäº**å·¥ä¸šå®è·µ**ä¸­è¢«è¯æ˜æœ‰æ•ˆã€ä¸”èƒ½æŠµæŠ—å…ˆè¿›ç»¼åˆå·¥å…·è‡ªåŠ¨ä¼˜åŒ–çš„æ¨¡å¼ï¼ŒåŒ…æ‹¬ï¼š
   - Bit-width Optimization
   - Precomputation & LUT Conversion
   - Operator Strength Reduction
   - Control Simplification
   - Resource Sharing
   - State Encoding Optimization

3. **é›†æˆåŒ–è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶**
   æä¾›å®Œæ•´çš„ç«¯åˆ°ç«¯è¯„ä¼°æµæ°´çº¿ï¼Œæ”¯æŒï¼š
   - ä½¿ç”¨å•†ä¸šå·¥å…·ï¼ˆSynopsys DCï¼‰å’Œå¼€æºå·¥å…·ï¼ˆYosysï¼‰è¿›è¡Œç»¼åˆ
   - åŠŸèƒ½ç­‰ä»·æ€§éªŒè¯ï¼ˆFormalityï¼‰
   - åŠ¨æ€ä»¿çœŸéªŒè¯ï¼ˆVCSï¼‰
   - å…¨é¢çš„ PPA æŠ¥å‘Šç”Ÿæˆï¼ˆPower, WNS, TNS, Cells, Areaï¼‰

4. **å¤šé…ç½®åˆæˆè¯„ä¼°æœºåˆ¶**
   åœ¨ä¸åŒç»¼åˆæ¨¡å¼ï¼ˆ`compile`, `compile_ultra`ï¼‰å’Œæ—¶é’Ÿçº¦æŸï¼ˆ1ns, 0.1nsï¼‰ä¸‹æµ‹è¯•ï¼Œç¡®ä¿è¯„ä¼°ç»“æœçš„é²æ£’æ€§å’Œå¯æ¯”æ€§ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰åŸºå‡† [26] | RTL-OPTï¼ˆæœ¬æ–‡ï¼‰ |
|------|----------------|------------------|
| **è®¾è®¡çœŸå®æ€§** | è¿‡åº¦äººä¸ºæ„é€ ï¼Œä¸åæ˜ å®é™…é—®é¢˜ | åŸºäºçœŸå®ä¼˜åŒ–åœºæ™¯ï¼Œå…·æœ‰å®ç”¨ä»·å€¼ |
| **ç»¼åˆå·¥å…·å¼ºåº¦** | å¤šç”¨ Yosysï¼ˆå¼±ä¼˜åŒ–ï¼‰ | æ”¯æŒ Synopsys DCï¼ˆå·¥ä¸šçº§å¼ºä¼˜åŒ–ï¼‰ |
| **è¯„ä¼°æŒ‡æ ‡å…¨é¢æ€§** | ä¸»è¦çœ‹é¢ç§¯ | å®Œæ•´ PPA æŒ‡æ ‡ï¼ˆåŠŸè€—ã€æ€§èƒ½ã€é¢ç§¯ï¼‰ |
| **ä¼˜åŒ–æœ‰æ•ˆæ€§** | å¾ˆå¤šâ€œä¼˜åŒ–â€è¢«DCæ¶ˆé™¤ | ä¼˜åŒ–æ•ˆæœåœ¨DCä¸‹ä»æ˜¾è‘—å¯è§ |
| **è¯„ä¼°å¯é æ€§** | æ˜“äº§ç”Ÿè¯¯å¯¼æ€§ç»“è®º | ç»“æœç¨³å®šå¯é ï¼Œç¬¦åˆé¢„æœŸ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼šRTL-OPT èƒ½æ›´çœŸå®ã€å…¬å¹³ã€å…¨é¢åœ°è¯„ä¼° LLM åœ¨ RTL ä¼˜åŒ–ä»»åŠ¡ä¸­çš„å®é™…èƒ½åŠ›ï¼Œé¿å…å› è¯„ä¼°æµç¨‹ä¸å½“å¯¼è‡´çš„â€œè™šå‡ä¼˜è¶Šâ€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“¦ æ•°æ®é›†
- **RTL-OPT Benchmark**ï¼šåŒ…å« 36 å¯¹ RTL æ¨¡å—ï¼ˆVerilogï¼‰ï¼Œè¦†ç›–å¤šç§ç”µè·¯ç±»å‹ã€‚
- **å¯¹æ¯”åŸºå‡†**ï¼šå¤ç°å¹¶è¯„ä¼°äº†å…ˆå‰å·¥ä½œ [26] ä¸­æä¾›çš„ 43 å¯¹ RTL ä»£ç ï¼ˆå…¶ä¸­æˆåŠŸç»¼åˆ 43 å¯¹ï¼‰ã€‚
- æ‰€æœ‰ä»£ç å‡å·²å¼€æºï¼Œå¹¶é™„å¸¦æ ‡å‡†å•å…ƒåº“ï¼ˆNangate45ï¼‰ã€è„šæœ¬ã€ç½‘è¡¨å’ŒæŠ¥å‘Šã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®
#### ç»¼åˆå·¥å…·ä¸æµç¨‹
- **ä¸»è¦ç»¼åˆå·¥å…·**ï¼šSynopsys Design Compiler (DC)
  - æ¨¡å¼ï¼š`compile` å’Œ `compile_ultra`
  - æ—¶é’Ÿå‘¨æœŸï¼š1nsï¼ˆå®½æ¾ï¼‰ã€0.1nsï¼ˆä¸¥æ ¼ï¼‰
- **è¾…åŠ©å·¥å…·**ï¼š
  - Yosysï¼ˆç”¨äºå¯¹æ¯”ï¼‰
  - Formalityï¼ˆå½¢å¼ç­‰ä»·éªŒè¯ï¼‰
  - VCSï¼ˆåŠ¨æ€åŠŸèƒ½éªŒè¯ï¼‰
- **æŠ€æœ¯åº“**ï¼šNangate45 å¼€æºæ ‡å‡†å•å…ƒåº“

#### è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **åŠŸèƒ½æ€§** | è¯­æ³•æ­£ç¡®æ€§ã€åŠŸèƒ½ç­‰ä»·æ€§ï¼ˆFormality/VCSï¼‰ |
| **PPA è´¨é‡** | - **Power**ï¼šæ€»åŠŸè€—ï¼ˆåŠ¨æ€ + æ³„æ¼ï¼‰<br>- **Performance**ï¼šWNSï¼ˆæœ€å·®è´Ÿæ¾å¼›ï¼‰ã€TNSï¼ˆæ€»è´Ÿæ¾å¼›ï¼‰<br>- **Area**ï¼šCell æ•°é‡ã€ç¡…ç‰‡é¢ç§¯ï¼ˆÎ¼mÂ²ï¼‰ |
| **æ¯”è¾ƒæ–¹å¼** | å°† LLM ç”Ÿæˆçš„ä¼˜åŒ–ä»£ç ä¸ suboptimal å’Œ optimized ç‰ˆæœ¬å¯¹æ¯”ï¼Œåˆ¤æ–­æ˜¯å¦â€œæ›´å¥½â€ã€â€œç›¸åŒâ€ã€â€œæ›´å·®â€æˆ–â€œå­˜åœ¨æƒè¡¡â€ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **äººç±»ä¸“å®¶ä¼˜åŒ–ç»“æœ**ï¼šä½œä¸ºé»„é‡‘å‚è€ƒï¼ˆGolden Referenceï¼‰
- **ç°æœ‰ LLM æ–¹æ³•**ï¼š
  - GPT-4.0
  - RTLRewriter æå‡ºçš„æ¨¡å‹ [26]
  - SymRTLO [23]
- **æœ¬æ–‡æµ‹è¯•çš„ LLMs**ï¼š
  - GPT-4o-mini
  - Gemini-2.5
  - Deepseek V3
  - Deepseek R1

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & Table 3ï¼‰

#### âœ… RTL-OPT è‡ªèº«æœ‰æ•ˆæ€§éªŒè¯ï¼ˆTable 1ï¼‰
åœ¨ `DC compile_ultra, clk=1ns` ä¸‹ï¼Œ36 å¯¹è®¾è®¡ä¸­æœ‰ï¼š
- **35 å¯¹**ï¼šä¼˜åŒ–ç‰ˆæœ¬æ˜æ˜¾ä¼˜äºæ¬¡ä¼˜ç‰ˆæœ¬ï¼ˆBetterï¼‰
- **1 å¯¹**ï¼šä¸¤è€…æ— å·®å¼‚ï¼ˆSameï¼‰
- **0 å¯¹**ï¼šä¼˜åŒ–ç‰ˆæœ¬åè€Œæ›´å·®

> ğŸ‘‰ è¡¨æ˜ RTL-OPT ä¸­çš„ä¼˜åŒ–æ˜¯**çœŸå®æœ‰æ•ˆä¸”ä¸å¯è¢«ç»¼åˆå·¥å…·æŠ¹é™¤**çš„ã€‚

#### âŒ ç°æœ‰åŸºå‡† [26] çš„é—®é¢˜æš´éœ²ï¼ˆTable 1ï¼‰
åœ¨åŒä¸€æ¡ä»¶ä¸‹ï¼ˆDC compile_ultraï¼‰ï¼š
- ä»… **13 / 43** çš„äººå·¥ä¼˜åŒ–ç‰ˆæœ¬ä¼˜äºåŸç‰ˆ
- å¤šæ•°â€œä¼˜åŒ–â€è¢« DC æ¶ˆé™¤ â†’ **è¯„ä¼°ä¸å¯é **

#### ğŸ“ˆ å¹³å‡ PPA æ”¹è¿›ï¼ˆTable 3ï¼‰
| æŒ‡æ ‡ | Suboptimal (DC) | Optimized (DC) | æ”¹è¿›ç‡ |
|------|------------------|----------------|--------|
| Power | 1226.8 mW | 901.8 mW | â†“ 36.0% |
| Cells | 1337.4 | 1047.7 | â†“ 27.6% |
| Area | 14.0 mmÂ² | 9.1 mmÂ² | â†“ 35.0% |
| WNS/TNS | 0.0 / 0.0 | 0.0 / 0.0 | ä¿æŒ |

> ğŸ‘‰ æ˜¾è‘—çš„ PPA æå‡ï¼Œè¯´æ˜ä¼˜åŒ–ç©ºé—´çœŸå®å­˜åœ¨ã€‚

---

### ğŸ¤– LLM æ€§èƒ½å¯¹æ¯”ï¼ˆFigure 3 & Table 4ï¼‰

| LLM æ¨¡å‹ | è¯­æ³•æ­£ç¡®ç‡ | åŠŸèƒ½æ­£ç¡®ç‡ | PPA ä¼˜äº suboptimal | PPA è¶…è¿‡ human optimized |
|---------|------------|------------|---------------------|----------------------------|
| GPT-4o-mini | 97.2% | 75.0% | 19.4% | ~2.2% |
| Gemini-2.5 | ~97% | ~72% | ~27.8% | ~2.4% |
| Deepseek V3 | 100% | 69.4% | 23.3% | ~4.4% |
| **Deepseek R1** | 86.1% | 61.1% | **41.7%** | **13.9%** |

> âœ… **Deepseek R1 è¡¨ç°æœ€å¼º**ï¼šå°½ç®¡åŠŸèƒ½æ­£ç¡®ç‡è¾ƒä½ï¼Œä½†åœ¨ PPA ä¼˜åŒ–ä¸Šæ˜¾è‘—é¢†å…ˆï¼Œç”šè‡³åœ¨çº¦ **5 ä¸ªä»»åŠ¡ä¸­è¶…è¶Šäººç±»ä¸“å®¶**ã€‚

---

### ğŸ” é”™è¯¯åˆ†æï¼ˆæ¶ˆèæ€§è´¨å‘ç°ï¼‰
é€šè¿‡å¯¹å¤±è´¥æ¡ˆä¾‹çš„æ‰‹åŠ¨æ£€æŸ¥ï¼Œå‘ç°ä¸»è¦é”™è¯¯æ¨¡å¼ï¼š
1. **æ§åˆ¶é€»è¾‘é”™è¯¯**ï¼šå¸ƒå°”æ¡ä»¶å†™é”™ï¼ˆå¦‚ comparator åˆ¤æ–­å¤±è¯¯ï¼‰
2. **è¿‡åº¦æµæ°´çº¿åŒ–**ï¼šç ´ååŸæœ‰å»¶è¿Ÿè¦æ±‚ï¼ˆå°¤å…¶åœ¨ FSM ä¸­ï¼‰
3. **èµ„æºå¤ç”¨å†²çª**ï¼šå¯„å­˜å™¨é‡ç”¨å¯¼è‡´æ•°æ®é™ˆæ—§ï¼ˆstale dataï¼‰

> ğŸ‘‰ è¡¨æ˜ LLM çš„é”™è¯¯æ›´å¤šæºäº**è¯­ä¹‰ç†è§£åå·®**è€Œéè¯­æ³•é”™è¯¯ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ç°æœ‰ RTL ä¼˜åŒ–åŸºå‡†ä¸å¯é **ï¼šå¤šæ•°â€œä¼˜åŒ–â€åœ¨å·¥ä¸šçº§ç»¼åˆå·¥å…·ä¸‹æ— æ•ˆï¼Œæ˜“é«˜ä¼° LLM èƒ½åŠ›ã€‚
2. **è¯„ä¼°å¿…é¡»ç»“åˆå¼ºç»¼åˆæµç¨‹**ï¼šä½¿ç”¨ Synopsys DC ç­‰å•†ä¸šå·¥å…·æ‰èƒ½æ­ç¤ºçœŸå®çš„ä¼˜åŒ–å·®è·ã€‚
3. **PPA æƒè¡¡æ™®éå­˜åœ¨**ï¼šä¸èƒ½åªçœ‹é¢ç§¯ï¼Œéœ€ç»¼åˆè¯„ä¼° Powerã€Timingã€Areaã€‚
4. **RTL-OPT æ˜¯é«˜è´¨é‡åŸºå‡†**ï¼šå…¶ä¼˜åŒ–æ¨¡å¼çœŸå®ã€å¯æµ‹é‡ã€æŠ—ç»¼åˆå¹²æ‰°ï¼Œé€‚åˆæ¨åŠ¨é¢†åŸŸå‘å±•ã€‚
5. **å½“å‰ LLM ä»æœ‰å¾ˆå¤§æå‡ç©ºé—´**ï¼šå³ä½¿æœ€å¥½çš„æ¨¡å‹ï¼ˆDeepseek R1ï¼‰ä¹Ÿä»…æœ‰çº¦ 40% æˆåŠŸç‡ï¼Œä¸”å¸¸å¼•å…¥åŠŸèƒ½é”™è¯¯ã€‚
6. **æ¿€è¿›ä¼˜åŒ– â‰  æ›´å¥½ç»“æœ**ï¼šDeepseek R1 è™½ PPA æœ€ä½³ï¼Œä½†åŠŸèƒ½é”™è¯¯æœ€å¤šï¼Œæ˜¾ç¤ºâ€œä¼˜åŒ–â€ä¸â€œæ­£ç¡®â€çš„æƒè¡¡ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **è§„æ¨¡é™åˆ¶**ï¼š36 ä¸ªä»»åŠ¡è™½å…·ä»£è¡¨æ€§ï¼Œä½†ä»åå°ï¼Œæœªè¦†ç›–æ‰€æœ‰å¤æ‚ IPï¼ˆå¦‚ CPU æ ¸å¿ƒï¼‰ã€‚
- **ä¾èµ–ç‰¹å®šå·¥è‰ºåº“**ï¼šç›®å‰åŸºäº Nangate45ï¼Œè¿ç§»åˆ°å…ˆè¿›å·¥è‰ºéœ€é‡æ–°æ ¡å‡†ã€‚
- **äººå·¥æ„å»ºæˆæœ¬é«˜**ï¼šæ¯ä¸ªä¼˜åŒ–å¯¹å‡ç”±ä¸“å®¶æ‰‹å·¥è®¾è®¡ï¼Œæ‰©å±•éš¾åº¦è¾ƒå¤§ã€‚
- **æœªè€ƒè™‘ç‰©ç†å®ç°å½±å“**ï¼šä»…è¯„ä¼°ç»¼åˆåç½‘è¡¨ï¼Œæœªæ¶‰åŠå¸ƒå±€å¸ƒçº¿ï¼ˆP&Rï¼‰é˜¶æ®µçš„å½±å“ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•æ›´å¤§è§„æ¨¡çš„ä»»åŠ¡é›†**ï¼Œè¦†ç›–æ›´å¤š SoC å­æ¨¡å—ã€‚
2. **å¼•å…¥å¤šè½®è¿­ä»£ä¼˜åŒ–ä»»åŠ¡**ï¼Œæ¨¡æ‹Ÿå·¥ç¨‹å¸ˆé€æ­¥è°ƒä¼˜è¿‡ç¨‹ã€‚
3. **ç»“åˆ P&R é˜¶æ®µåé¦ˆ**ï¼Œæ„å»ºé—­ç¯ä¼˜åŒ–è¯„ä¼°ç³»ç»Ÿã€‚
4. **å¼€å‘ä¸“ç”¨ LLM å¾®è°ƒæ•°æ®é›†**ï¼ŒåŸºäº RTL-OPT è¿›è¡Œç›‘ç£è®­ç»ƒã€‚
5. **æ¢ç´¢è‡ªåŠ¨åŒ–â€œé€€åŒ–â€ç®—æ³•**ï¼Œé™ä½æ‰‹å·¥æ„é€  suboptimal ç‰ˆæœ¬çš„æˆæœ¬ã€‚

---

## æ€»ç»“
RTL-OPT æ˜¯é¦–ä¸ªä¸“æ³¨äº**çœŸå®ã€å¯è¡¡é‡ã€æŠ—å¹²æ‰°çš„ RTL ä»£ç ä¼˜åŒ–è¯„ä¼°**çš„åŸºå‡†ï¼Œè§£å†³äº†å½“å‰é¢†åŸŸè¯„ä¼°ä¸ä¸€è‡´ã€ç»“æœä¸å¯é çš„æ ¸å¿ƒç—›ç‚¹ã€‚å®ƒä¸ä»…æä¾›äº†é«˜è´¨é‡çš„æ•°æ®é›†å’Œå®Œæ•´å·¥å…·é“¾ï¼Œè¿˜é€šè¿‡ä¸¥è°¨å®éªŒæ­ç¤ºäº†ç°æœ‰ LLM æ–¹æ³•çš„çœŸå®æ°´å¹³ï¼Œä¸ºæœªæ¥ AI è¾…åŠ© IC è®¾è®¡çš„å‘å±•å¥ å®šäº†åšå®åŸºç¡€ã€‚

</details>

---

### 16. [FLOP-Efficient Training: Early Stopping Based on Test-Time Compute Awareness](https://arxiv.org/abs/2601.01332)

**Authors**: Hossam Amer, Maryam Dialameh, Hossein Rajabzadeh, Walid Ahmed, Weiwei Zhang, Yang Liu  
**Category**: cs.CL  
**Published**: 2026-01-06  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.01332v1  

#### Abstract
Scaling training compute, measured in FLOPs, has long been shown to improve the accuracy of large language models, yet training remains resource-intensive. Prior work shows that increasing test-time compute (TTC)-for example through iterative sampling-can allow smaller models to rival or surpass muc...

---

### 17. [Bridging the gap: A comparative exploration of Speech-LLM and end-to-end architecture for multilingual conversational ASR](https://arxiv.org/abs/2601.01461)

**Authors**: Yuxiang Mei, Dongxing Xu, Jiaen Liang, Yanhua Long  
**Category**: cs.CL  
**Published**: 2026-01-06  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.01461v1  

#### Abstract
The INTERSPEECH 2025 Challenge on Multilingual Conversational Speech Language Models (MLC-SLM) promotes multilingual conversational ASR with large language models (LLMs). Our previous SHNU-mASR system adopted a competitive parallel-speech-encoder architecture that integrated Whisper and mHuBERT with...

---

### 18. [Power-of-Two Quantization-Aware-Training (PoT-QAT) in Large Language Models (LLMs)](https://arxiv.org/abs/2601.02298)

**Authors**: Mahmoud Elgenedy  
**Category**: cs.CL  
**Published**: 2026-01-06  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.02298v1  

#### Abstract
In Large Language Models (LLMs), the number of parameters has grown exponentially in the past few years, e.g., from 1.5 billion parameters in GPT-2 to 175 billion in GPT-3 to possibly more than trillion in higher versions. This raises a significant challenge for implementation, especially for Edge d...

---

### 19. [Making MoE based LLM inference resilient with Tarragon](https://arxiv.org/abs/2601.01310)

**Authors**: Songyu Zhang, Aaron Tam, Myungjin Lee, Shixiong Qi, K. K. Ramakrishnan  
**Category**: cs.DC  
**Published**: 2026-01-06  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.01310v1  

#### Abstract
Mixture-of-Experts (MoE) models are increasingly used to serve LLMs at scale, but failures become common as deployment scale grows. Existing systems exhibit poor failure resilience: even a single worker failure triggers a coarse-grained, service-wide restart, discarding accumulated progress and halt...

---

### 20. [GDRO: Group-level Reward Post-training Suitable for Diffusion Models](https://arxiv.org/abs/2601.02036)

**Authors**: Yiyang Wang, Xi Chen, Xiaogang Xu, Yu Liu, Hengshuang Zhao  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.02036v1  

#### Abstract
Recent advancements adopt online reinforcement learning (RL) from LLMs to text-to-image rectified flow diffusion models for reward alignment. The use of group-level rewards successfully aligns the model with the targeted reward. However, it faces challenges including low efficiency, dependency on st...

---

### 21. [A Differentiable Adversarial Framework for Task-Aware Data Subsampling](https://arxiv.org/abs/2601.02081)

**Authors**: Jiacheng Lyu, Bihua Bao  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.02081v1  

#### Abstract
The proliferation of large-scale datasets poses a major computational challenge to model training. The traditional data subsampling method works as a static, task independent preprocessing step which usually discards information that is critical to downstream prediction. In this paper, we introduces...

---

### 22. [ELLA: Efficient Lifelong Learning for Adapters in Large Language Models](https://arxiv.org/abs/2601.02232)

**Authors**: Shristi Das Biswas, Yue Zhang, Anwesan Pal, Radhika Bhargava, Kaushik Roy  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.02232v1  

#### Abstract
Large Language Models (LLMs) suffer severe catastrophic forgetting when adapted sequentially to new tasks in a continual learning (CL) setting. Existing approaches are fundamentally limited: replay-based methods are impractical and privacy-violating, while strict orthogonality-based methods collapse...

---

### 23. [MindChat: A Privacy-preserving Large Language Model for Mental Health Support](https://arxiv.org/abs/2601.01993)

**Authors**: Dong Xue, Jicheng Tu, Ming Wang, Xin Yan, Fangzhou Liu, Jie Hu  
**Category**: cs.AI  
**Published**: 2026-01-06  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.01993v1  

#### Abstract
Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synth...

---

### 24. [DHI: Leveraging Diverse Hallucination Induction for Enhanced Contrastive Factuality Control in Large Language Models](https://arxiv.org/abs/2601.01156)

**Authors**: Jiani Guo, Xiangke Zeng, Jie Wu, Zuchao Li  
**Category**: cs.CL  
**Published**: 2026-01-06  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.01156v1  

#### Abstract
Large language models (LLMs) frequently produce inaccurate or fabricated information, known as "hallucinations," which compromises their reliability. Existing approaches often train an "Evil LLM" to deliberately generate hallucinations on curated datasets, using these induced hallucinations to guide...

---

### 25. [A Multi-Port Concurrent Communication Model for handling Compute Intensive Tasks on Distributed Satellite System Constellations](https://arxiv.org/abs/2601.01031)

**Authors**: Bharadwaj Veeravalli  
**Category**: cs.DC  
**Published**: 2026-01-06  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.01031v1  

#### Abstract
We develop an integrated Multi-Port Concurrent Communication Divisible Load Theory (MPCC-DLT) framework for relay-centric distributed satellite systems (DSS), capturing concurrent data dissemination, parallel computation, and result return under heterogeneous onboard processing and inter-satellite l...

---

### 26. [pMSz: A Distributed Parallel Algorithm for Correcting Extrema and Morse Smale Segmentations in Lossy Compression](https://arxiv.org/abs/2601.01787)

**Authors**: Yuxiao Li, Mingze Xia, Xin Liang, Bei Wang, Robert Underwood, Sheng Di, Hemant Sharma, Dishant Beniwal, Franck Cappello, Hanqi Guo  
**Category**: cs.DC  
**Published**: 2026-01-06  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.01787v1  

#### Abstract
Lossy compression, widely used by scientists to reduce data from simulations, experiments, and observations, can distort features of interest even under bounded error. Such distortions may compromise downstream analyses and lead to incorrect scientific conclusions in applications such as combustion ...

---

### 27. [Universal Battery Degradation Forecasting Driven by Foundation Model Across Diverse Chemistries and Conditions](https://arxiv.org/abs/2601.00862)

**Authors**: Joey Chan, Huan Wang, Haoyu Pan, Wei Wu, Zirong Wang, Zhen Chen, Ershun Pan, Min Xie, Lifeng Xi  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.00862v1  

#### Abstract
Accurate forecasting of battery capacity fade is essential for the safety, reliability, and long-term efficiency of energy storage systems. However, the strong heterogeneity across cell chemistries, form factors, and operating conditions makes it difficult to build a single model that generalizes be...

---

### 28. [Enhanced Data-Driven Product Development via Gradient Based Optimization and Conformalized Monte Carlo Dropout Uncertainty Estimation](https://arxiv.org/abs/2601.00932)

**Authors**: Andrea Thomas Nava, Lijo Johny, Fabio Azzalini, Johannes Schneider, Arianna Casanova  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.00932v1  

#### Abstract
Data-Driven Product Development (DDPD) leverages data to learn the relationship between product design specifications and resulting properties. To discover improved designs, we train a neural network on past experiments and apply Projected Gradient Descent to identify optimal input features that max...

---

### 29. [Counterfactual Self-Questioning for Stable Policy Optimization in Language Models](https://arxiv.org/abs/2601.00885)

**Authors**: Mandar Parab  
**Category**: cs.AI  
**Published**: 2026-01-06  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.00885v1  

#### Abstract
Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and...

---

### 30. [ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems](https://arxiv.org/abs/2601.00994)

**Authors**: Michael Bao  
**Category**: cs.AI  
**Published**: 2026-01-06  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.00994v1  

#### Abstract
This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
