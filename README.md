# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-05 06:40:51 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Multi-Head LatentMoE and Head Parallel: Communication-Efficient and Deterministic MoE Parallelism](https://arxiv.org/abs/2602.04870)

**Authors**: Chenwei Cui, Rockwell Jackson, Benjamin Joseph Herrera, Ana Mar\'ia T\'arano, Hannah Kerner  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2602.04870v1  

#### Abstract
Large language models have transformed many applications but remain expensive to train. Sparse Mixture of Experts (MoE) addresses this through conditional computation, with Expert Parallel (EP) as the standard distributed training method. However, EP has three limitations: communication cost grows l...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMulti-Head LatentMoE and Head Parallel: Communication-Efficient and Deterministic MoE Parallelism

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
ç°æœ‰çš„ **Expert Parallel (EP)** æ˜¯ç¨€ç– Mixture-of-Experts (MoE) æ¨¡å‹çš„æ ‡å‡†åˆ†å¸ƒå¼è®­ç»ƒæ–¹æ³•ï¼Œä½†å®ƒå­˜åœ¨ä¸‰ä¸ªå…³é”®ç“¶é¢ˆï¼š
- **é€šä¿¡å¼€é”€å¤§**ï¼šé€šä¿¡é‡éšæ¯ä¸ª token æ¿€æ´»çš„ä¸“å®¶æ•° $k$ çº¿æ€§å¢é•¿ï¼ˆå³ $O(k)$ï¼‰ã€‚
- **è´Ÿè½½ä¸å‡è¡¡**ï¼šç”±äºè·¯ç”±å†³ç­–çš„æ•°æ®ä¾èµ–æ€§ï¼ŒæŸäº› GPU å¯èƒ½æ¥æ”¶è¿‡å¤š tokenï¼Œå¯¼è‡´å»¶è¿Ÿå’Œæ˜¾å­˜å³°å€¼å‡é«˜ã€‚
- **éç¡®å®šæ€§é€šä¿¡æ¨¡å¼**ï¼šéœ€è¦é¢å¤–çš„ all-to-all é€šä¿¡äº¤æ¢å…ƒæ•°æ®ï¼ˆå¦‚é˜Ÿåˆ—é•¿åº¦ï¼‰ï¼Œå¢åŠ äº†å¤æ‚æ€§å’Œä¸ç¡®å®šæ€§ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº† MoE æ¨¡å‹åœ¨å¤§è§„æ¨¡åœºæ™¯ä¸‹çš„å¯æ‰©å±•æ€§å’Œæ•ˆç‡ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§å…¨æ–°çš„æ¶æ„ä¸å¹¶è¡Œç­–ç•¥ç»„åˆï¼š

#### âœ… **Multi-Head LatentMoE**
- å°†å•ä¸ª MoE å±‚åˆ†è§£ä¸ºå¤šä¸ªç‹¬ç«‹çš„å°å‹ MoE å­æ¨¡å—ï¼ˆç§°ä¸ºâ€œheadâ€ï¼‰ã€‚
- æ¯ä¸ªè¾“å…¥ token è¢«æŠ•å½±å¹¶æ‹†åˆ†ä¸º $N_h$ ä¸ª sub-tokenï¼Œåˆ†åˆ«ç”±ä¸€ä¸ªç‹¬ç«‹çš„ MoE å¤„ç†ï¼ˆå«ç‹¬ç«‹çš„ router å’Œ expert é›†åˆï¼‰ã€‚
- ç»“åˆäº† **LatentMoE**ï¼ˆä½ç»´éšç©ºé—´è®¡ç®—ï¼‰å’Œ **Multi-Head** æ€æƒ³ï¼Œä½†å…³é”®åŒºåˆ«åœ¨äºï¼š**æ¯ä¸ª head æ‹¥æœ‰ç‹¬ç«‹å‚æ•°**ã€‚

#### âœ… **Head Parallel (HP)**
- åœ¨ **è·¯ç”±ä¹‹å‰** å°±é€šè¿‡ all-to-all å°† sub-token åˆ†å‘åˆ°ä¸åŒ GPU ä¸Šã€‚
- æ¯ä¸ª GPU ç‹¬ç«‹å®Œæˆå…¶è´Ÿè´£ head çš„å®Œæ•´è·¯ç”±ä¸ä¸“å®¶è®¡ç®—ï¼Œæ— éœ€åç»­è·¨è®¾å¤‡é€šä¿¡ã€‚
- å®ç°äº†ï¼š
  - **$O(1)$ é€šä¿¡é‡**ï¼ˆä¸å— $k$ å½±å“ï¼‰
  - **å®Œå…¨å¹³è¡¡çš„æµé‡åˆ†é…**
  - **ç¡®å®šæ€§çš„é€šä¿¡æ¨¡å¼**

#### âœ… **IO-aware Routing & Expert Computation**
ä¸ºè§£å†³ Multi-Head è®¾è®¡å¸¦æ¥çš„é«˜ HBM å¼€é”€é—®é¢˜ï¼Œæå‡ºäº†ä¸¤ç§é«˜æ•ˆå®ç°ï¼š
- **IO-aware Routing**ï¼šåˆ©ç”¨åœ¨çº¿ top-$k$ æŠ€æœ¯ï¼Œåœ¨ SRAM ä¸­æµå¼å¤„ç†è·¯ç”±å¾—åˆ†ï¼Œé¿å…å°†å…¨éƒ¨ $N_e$ ä¸ªå¾—åˆ†å†™å…¥ HBMã€‚
- **IO-aware Expert Computation**ï¼šå°†ç¨€ç– FFN è®¡ç®—é‡æ„ä¸º **block-sparse attention**ï¼Œå¤ç”¨ **FlexAttention** çš„é«˜æ€§èƒ½å†…æ ¸ï¼Œå®ç° dropless ä¸” IO é«˜æ•ˆçš„å‰å‘/åå‘ä¼ æ’­ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Expert Parallel (EP) | Multi-Head LatentMoE + HP |
|------|------------------------|----------------------------|
| é€šä¿¡å¤æ‚åº¦ | $O(k)$ | $O(1)$ |
| è´Ÿè½½å‡è¡¡ | å·®ï¼ˆå—è·¯ç”±å½±å“ï¼‰ | å®Œå…¨å‡è¡¡ |
| é€šä¿¡ç¡®å®šæ€§ | å¦ï¼ˆéœ€å…ƒæ•°æ®äº¤æ¢ï¼‰ | æ˜¯ |
| æ˜¾å­˜è®¿é—® | é«˜ï¼ˆææ–™åŒ–æ‰€æœ‰æ¿€æ´»ï¼‰ | ä½ï¼ˆSRAM æµå¼å¤„ç†ï¼‰ |
| å…¼å®¹æ€§ | æ”¯æŒæ ‡å‡† MoE | å…¼å®¹ EPï¼Œå¯ç»„åˆä½¿ç”¨ |

> ğŸ’¡ **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼š**é€šä¿¡æ›´å°‘ã€è´Ÿè½½æ›´ç¨³ã€è¡Œä¸ºæ›´å¯æ§ã€è®­ç»ƒæ›´å¿«**ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹æ€§èƒ½ä¸å˜ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **FineWebEdu**ï¼šä»äº’è”ç½‘æ¸…æ´—å¾—åˆ°çš„å¤§è§„æ¨¡æ–‡æœ¬è¯­æ–™ã€‚
- å®éªŒä½¿ç”¨å…¶ä¸­ **10 billion tokens** çš„å­é›†è¿›è¡Œè¯­è¨€å»ºæ¨¡é¢„è®­ç»ƒã€‚

---

### å®éªŒè®¾ç½®
- **æ¨¡å‹ç»“æ„**ï¼šDecoder-only Transformerï¼Œå…± 12 å±‚ï¼Œembedding size = 1024ï¼Œcontext length = 2048ã€‚
- **æ³¨æ„åŠ›æœºåˆ¶**ï¼š8 ä¸ª attention headï¼Œhead dimension = 128ã€‚
- **ä¼˜åŒ–å™¨**ï¼šAdamW ($\beta_1=0.9, \beta_2=0.95$)ï¼Œweight decay = 0.1ï¼Œlearning rate = $5\times10^{-4}$ã€‚
- **å­¦ä¹ ç‡è°ƒåº¦**ï¼šæ¢¯å½¢è°ƒåº¦ï¼ˆ8000 æ­¥ warmup + 2000 æ­¥ decayï¼‰ã€‚
- **å…¨å±€ batch size**ï¼š0.66M tokensã€‚
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA H100 GPUsï¼ˆ80GBï¼‰ï¼ŒNVLink äº’è”ã€‚

---

### è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **è®­ç»ƒæ•ˆç‡** | è®­ç»ƒè€—æ—¶ï¼ˆå°æ—¶ï¼‰ã€é€šä¿¡é‡ã€VRAM å ç”¨ã€all-to-all å»¶è¿Ÿ |
| **æ¨¡å‹æ€§èƒ½** | Validation Perplexityï¼ˆFineWebEDUï¼‰ã€Zero-shot Accuracyï¼ˆHellaSwag, PiQA, LAMBADA, ARC-Easy, ARC-Challengeï¼‰ |
| **å¹³å‡æ€§èƒ½** | å¤šä»»åŠ¡å‡†ç¡®ç‡å‡å€¼ï¼ˆAvg. acc.ï¼‰ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **MLP** | å…¨è¿æ¥å‰é¦ˆç½‘ç»œï¼Œä½œä¸ºåŸºç¡€å¯¹ç…§ |
| **MoE + EP** | æ ‡å‡† MoE æ¶æ„ + Expert Parallelï¼Œä¸»æµåŸºçº¿ |
| **LatentMoE + EP** | åœ¨ä½ç»´ç©ºé—´è¿›è¡Œè·¯ç”±ä¸ä¸“å®¶è®¡ç®—ï¼Œä»ä½¿ç”¨ EP |
| **MH LatentMoE + HP** | æœ¬æ–‡æå‡ºçš„æ–¹æ³• |
| **MH LatentMoE + HP G** | â€œGâ€ è¡¨ç¤º doubled granularityï¼ˆä¸“å®¶æ•°é‡ç¿»å€ï¼Œexpert size å‡åŠï¼‰ï¼Œç”¨äºæµ‹è¯•æ‰©å±•èƒ½åŠ› |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| å‚æ•°é…ç½® | æ–¹æ³• | è®­ç»ƒæ—¶é—´ (ç›¸å¯¹) | Perplexity | å¹³å‡å‡†ç¡®ç‡ (Avg. acc.) |
|---------|------|------------------|------------|------------------------|
| 0.2Bâ€“2.2B | MoE + EP | 1.00Ã— | 15.56 | 43.95 |
| 0.2Bâ€“2.2B | MH LatentMoE + HP | **0.90Ã—** | 15.61 | 43.93 |
| 0.2Bâ€“4.2B | MoE + EP | 1.00Ã— | 15.01 | 45.30 |
| 0.2Bâ€“4.2B | MH LatentMoE + HP | **0.62Ã—** | 15.02 | 45.17 |
| 0.2Bâ€“4.2B | MH LatentMoE + HP G | **0.90Ã—** | **14.82** | **45.43** âœ… |

> ğŸ”¥ **æœ€é«˜åŠ é€Ÿæ¯”è¾¾ 1.61Ã—**ï¼ˆ4B å‚æ•°ä¸‹ç›¸æ¯” MoE + EPï¼‰

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **è®­ç»ƒé€Ÿåº¦æå‡æ˜¾è‘—**ï¼š
  - åœ¨ 4B æ€»å‚æ•°ä¸‹ï¼Œ**è®­ç»ƒæ—¶é—´ä» 55.34 å°æ—¶é™è‡³ 34.41 å°æ—¶**ï¼ˆå¿« 1.61Ã—ï¼‰ã€‚
  - åœ¨ 2B å‚æ•°ä¸‹ä¹Ÿå¿« 1.11Ã—ã€‚
- **é€šä¿¡é‡å¤§å¹…é™ä½**ï¼š
  - å½“ $k=4$ æ—¶ï¼Œinter-GPU é€šä¿¡é‡ä»…ä¸º EP çš„ **25%**ã€‚
- **æ€§èƒ½æŒå¹³ç”šè‡³æ›´å¥½**ï¼š
  - MH LatentMoE + HP ä¸ MoE + EP çš„ perplexity å’Œ accuracy åŸºæœ¬ä¸€è‡´ã€‚
  - å½“é‡‡ç”¨ **doubled granularity (G)** åï¼Œä¸ä»…è®­ç»ƒä»å¿« 1.11Ã—ï¼Œè€Œä¸”å–å¾—äº† **æœ€é«˜çš„å¹³å‡å‡†ç¡®ç‡ 45.43%**ï¼Œä¼˜äºæ‰€æœ‰å…¶ä»–æ–¹æ³•ã€‚

---

### æ¶ˆèå®éªŒç»“æœ

#### â–¶ï¸ è´Ÿè½½ä¸å‡è¡¡æ•æ„Ÿæ€§åˆ†æï¼ˆFigure 3ï¼‰
- éšç€ Zipf åˆ†å¸ƒ skew å¢åŠ ï¼ˆæç«¯è´Ÿè½½ä¸å‡ï¼‰ï¼Œ**EP çš„ all-to-all å»¶è¿Ÿå’Œ VRAM å³°å€¼æ€¥å‰§ä¸Šå‡**ã€‚
- **HP åˆ™å§‹ç»ˆä¿æŒç¨³å®š**ï¼Œä¸å— $k$ æˆ– skew å½±å“ï¼ŒéªŒè¯äº†å…¶è´Ÿè½½é²æ£’æ€§ã€‚

#### â–¶ï¸ IO-aware Routing æ•ˆæœï¼ˆFigure 4ï¼‰
- Naive routing å†…å­˜å ç”¨éšä¸“å®¶æ•°çº¿æ€§å¢é•¿ã€‚
- **IO-aware routing å†…å­˜æ’å®š**ï¼Œä¸”åå‘ä¼ æ’­å› åªå¯¹ top-$k$ ä¸“å®¶æ±‚å¯¼è€Œå‡ ä¹æ— å¢é•¿ã€‚

#### â–¶ï¸ IO-aware Expert Computationï¼ˆFigure 5ï¼‰
- ä½¿ç”¨ Grouped GEMM çš„ naive æ–¹æ³•åœ¨ä¸“å®¶å¢å¤šæ—¶æ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚
- **åŸºäº FlexAttention çš„æ–¹æ³•ä¿æŒé«˜æ•ˆ**ï¼Œå°¤å…¶åœ¨åå‘ä¼ æ’­ä¸­ä¼˜åŠ¿æ˜æ˜¾ã€‚

#### â–¶ï¸ Head é…ç½®æ¶ˆèï¼ˆTable 2ï¼‰
| $N_h \times d_h$ | Val Loss | ç›¸å¯¹è®­ç»ƒæˆæœ¬ | SRAM å‹åŠ› |
|------------------|----------|---------------|-----------|
| 16Ã—64 | 3.56 | 1.34Ã— | Low |
| 8Ã—128 | 3.48 | 1.00Ã— âœ… | Medium |
| 4Ã—256 | **3.41** | 1.07Ã— | High |

> æœ€ä½³æŠ˜ä¸­é€‰æ‹©ï¼š**8Ã—128**ï¼Œå…¼é¡¾æ€§èƒ½ã€æ•ˆç‡ä¸å·¥ç¨‹å¯è¡Œæ€§ã€‚

#### â–¶ï¸ æ˜¯å¦ä½¿ç”¨ç‹¬ç«‹ routing tokenï¼ˆFigure 6ï¼‰
- å¼•å…¥å•ç‹¬çš„ routing sub-token å¯¹æ—©æœŸè®­ç»ƒç•¥æœ‰å¸®åŠ©ï¼Œä½†æœ€ç»ˆæ”¶æ•›æ€§èƒ½åŸºæœ¬ç›¸åŒã€‚
- ä½†ç”±äºä¼šä½¿ all-to-all é€šä¿¡é‡ç¿»å€ï¼Œ**æœ€ç»ˆæœªé‡‡ç”¨è¯¥è®¾è®¡**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Head Parallel æ˜¯é¦–ä¸ªå®ç° $O(1)$ é€šä¿¡å¤æ‚åº¦çš„ MoE å¹¶è¡Œæ–¹æ¡ˆ**ï¼Œä»æ ¹æœ¬ä¸Šè§£å†³äº† EP çš„ä¸‰å¤§ç¼ºé™·ã€‚
2. **Multi-Head LatentMoE + HP åœ¨ä¿æŒæ¨¡å‹æ€§èƒ½ä¸å˜çš„å‰æä¸‹ï¼Œè®­ç»ƒé€Ÿåº¦æœ€é«˜æå‡ 1.61Ã—**ã€‚
3. **é€šè¿‡ IO-aware è®¾è®¡ï¼Œæœ‰æ•ˆæ§åˆ¶äº†å¤š head å¸¦æ¥çš„å†…å­˜å‹åŠ›**ï¼Œä½¿è¯¥æ¶æ„å®é™…å¯è¡Œã€‚
4. **å¢åŠ  granularityï¼ˆæ›´å¤šå°ä¸“å®¶ï¼‰å¯åœ¨ç›¸ä¼¼è®­ç»ƒæ—¶é—´å†…è·å¾—æ›´é«˜æ•´ä½“æ€§èƒ½**ï¼Œå±•ç¤ºäº†è¶…ç¨€ç– MoE çš„æ½œåŠ›ã€‚
5. **è¯¥æ–¹æ³•ç‰¹åˆ«é€‚ç”¨äºå­¦æœ¯ç•Œç­‰èµ„æºå—é™ç¯å¢ƒ**ï¼Œé™ä½äº†ç™¾äº¿å‚æ•°çº§ MoE æ¨¡å‹çš„ç ”ç©¶é—¨æ§›ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **Head Parallel çš„å¹¶è¡Œç²’åº¦å—é™äº $N_h$**ï¼ˆhead æ•°é‡ï¼‰ã€‚è‹¥ $N_h < P$ï¼ˆGPU æ•°ï¼‰ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨æ›´å¤šè®¾å¤‡ã€‚
  - ä¾‹å¦‚ï¼šå½“å‰æœ€å¤šæ”¯æŒ 8~16 ä¸ª GPU çš„ intra-node å¹¶è¡Œã€‚
- ä¸é€‚åˆæç²—ç²’åº¦ MoE æ¶æ„ï¼ˆexpert æ•°å°‘ã€size å¤§ï¼‰ã€‚
- å½“å‰å®ç°ä¾èµ– FlexAttention ç­‰è¾ƒæ–°çš„è½¯ä»¶æ ˆï¼Œå¯èƒ½å¯¹æ—§ç¡¬ä»¶/æ¡†æ¶å…¼å®¹æ€§æœ‰é™ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ··åˆå¹¶è¡Œç­–ç•¥**ï¼š  
   - ä½¿ç”¨ **HP è¿›è¡ŒèŠ‚ç‚¹é—´é€šä¿¡**ï¼ˆinter-nodeï¼‰ï¼Œ**EP è¿›è¡ŒèŠ‚ç‚¹å†…é€šä¿¡**ï¼ˆintra-nodeï¼‰ï¼Œçªç ´ $N_h$ é™åˆ¶ã€‚
2. **è¿›ä¸€æ­¥å·¥ç¨‹ä¼˜åŒ–**ï¼š
   - é€šä¿¡ä¸è®¡ç®—é‡å ï¼ˆcommunication-computation overlapï¼‰
   - æ›´ç»†ç²’åº¦çš„ kernel èåˆ
3. **æ¢ç´¢æ›´å¤§è§„æ¨¡éƒ¨ç½²**ï¼š
   - æ‰©å±•è‡³åƒå¡çº§åˆ«é›†ç¾¤ï¼ŒéªŒè¯å¯æ‰©å±•æ€§è¾¹ç•Œã€‚
4. **åŠ¨æ€ head æ•°è°ƒæ•´æœºåˆ¶**ï¼š
   - è‡ªé€‚åº”è°ƒèŠ‚ $N_h$ ä»¥åŒ¹é…ç¡¬ä»¶æ‹“æ‰‘ã€‚

---

### æ€»ç»“ä¸€å¥è¯
> æœ¬æ–‡æå‡ºçš„ **Multi-Head LatentMoE + Head Parallel** æ¶æ„ï¼Œé€šè¿‡è§£è€¦è·¯ç”±ä¸é€šä¿¡ï¼Œåœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„åŒæ—¶å®ç°äº† **é€šä¿¡æ’å®šã€è´Ÿè½½å‡è¡¡ã€ç¡®å®šæ€§å¼ºã€è®­ç»ƒåŠ é€Ÿé«˜è¾¾ 1.61Ã—** çš„ MoE è®­ç»ƒæ–°èŒƒå¼ï¼Œæ˜¾è‘—æå‡äº†è¶…ç¨€ç– MoE æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡ä¸å¯åŠæ€§ã€‚

</details>

---

### 2. [AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent](https://arxiv.org/abs/2602.03955)

**Authors**: Yinyi Luo, Yiqiao Jin, Weichen Yu, Mengqi Zhang, Srijan Kumar, Xiaoxiao Li, Weijie Xu, Xin Chen, Jindong Wang  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.03955v1  

#### Abstract
While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framework to distill multi-agent dynamics into the weigh...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ **Multi-Agent Systems (MAS)** åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œé€šè¿‡å¤šè½®è¾©è®ºã€æ‰¹åˆ¤ä¸å…±è¯†æœºåˆ¶æå‡æ¨ç†è´¨é‡ã€‚ç„¶è€Œï¼ŒMAS å­˜åœ¨ä¸¤å¤§ç“¶é¢ˆï¼š

- **é«˜è®¡ç®—æˆæœ¬**ï¼šå¤šæ™ºèƒ½ä½“äº¤äº’å¯¼è‡´æ¨ç†å»¶è¿Ÿå’Œèµ„æºæ¶ˆè€—å‘ˆæŒ‡æ•°å¢é•¿ï¼Œéš¾ä»¥éƒ¨ç½²äºå®æ—¶æˆ–èµ„æºå—é™åœºæ™¯ã€‚
- **é”™è¯¯ä¼ æ’­é£é™©**ï¼šä¸ªä½“åè§æˆ–å¹»è§‰å¯èƒ½åœ¨å¯†é›†äº¤äº’ä¸­è¢«æ”¾å¤§ï¼Œå¯¼è‡´é›†ä½“å¤±è´¥ã€‚

å› æ­¤ï¼Œæ ¸å¿ƒé—®é¢˜æ˜¯ï¼š**èƒ½å¦å°†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æ¨ç†èƒ½åŠ›â€œå†…åŒ–â€åˆ°å•ä¸ª LLM ä¸­ï¼Œåœ¨ä¿æŒé«˜æ•ˆæ¨ç†çš„åŒæ—¶ç»§æ‰¿å…¶å¼ºå¤§çš„æ¨ç†ä¼˜åŠ¿ï¼Ÿ**

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **AgentArk** â€”â€” ä¸€ç§å…¨æ–°çš„ **å¤šæ™ºèƒ½ä½“æ¨ç†è’¸é¦æ¡†æ¶**ï¼Œæ—¨åœ¨å°† MAS çš„åŠ¨æ€æ¨ç†è¿‡ç¨‹â€œå‹ç¼©â€è¿›å•ä¸€ LLM çš„å‚æ•°ä¸­ã€‚

#### **æ ¸å¿ƒæ€æƒ³**
å°†åŸæœ¬å‘ç”Ÿåœ¨ **æµ‹è¯•æ—¶ï¼ˆtest-timeï¼‰** çš„æ˜¾å¼å¤šæ™ºèƒ½ä½“äº¤äº’ï¼ˆå¦‚è¾©è®ºï¼‰ï¼Œè½¬åŒ–ä¸º **è®­ç»ƒé˜¶æ®µ** è¢«å­¦ä¹ åˆ°çš„éšå¼æ¨ç†èƒ½åŠ›ã€‚å³ï¼š
> â€œ**æŠŠæ¨ç†çš„è®¡ç®—è´Ÿæ‹…ä»æ¨ç†é˜¶æ®µè½¬ç§»åˆ°è®­ç»ƒé˜¶æ®µ**â€ï¼Œä»è€Œå®ç°æ¨ç†æ•ˆç‡ä¸èƒ½åŠ›çš„ç»Ÿä¸€ã€‚

#### **ä¸‰å¤§åˆ†å±‚è’¸é¦ç­–ç•¥**
AgentArk è®¾è®¡äº†ä¸‰ç§é€’è¿›å¼çš„è’¸é¦æ–¹æ³•ï¼š

1. **Reasoning-Enhanced SFT (RSFT)**  
   - åœ¨æ ‡å‡†ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰åŸºç¡€ä¸Šï¼Œä¸ä»…ä½¿ç”¨æœ€ç»ˆç­”æ¡ˆï¼Œè¿˜ä½¿ç”¨é«˜è´¨é‡çš„å¤šæ™ºèƒ½ä½“æ¨ç†è½¨è¿¹ä½œä¸ºç›‘ç£ä¿¡å·ã€‚
   - ç›®æ ‡ï¼šè®©å•ä¸ªæ¨¡å‹å­¦ä¼šç”Ÿæˆè¿è´¯ã€æ­£ç¡®çš„æ¨ç†é“¾ã€‚

2. **Data Augmentation via Diverse Extraction (DA)**  
   - ä»å¤šæ™ºèƒ½ä½“è¾©è®ºä¸­æå–å¤šä¸ª**æ­£ç¡®ä¸”å¤šæ ·åŒ–**çš„æ¨ç†è·¯å¾„ï¼ˆä¾‹å¦‚ä¸åŒè§£é¢˜ç­–ç•¥ã€é€»è¾‘èµ·ç‚¹ï¼‰ã€‚
   - åˆ©ç”¨å¤§å®¹é‡æ•™å¸ˆæ¨¡å‹ï¼ˆdistillerï¼‰è¿›è¡Œç­›é€‰ï¼Œå¢å¼ºå­¦ç”Ÿæ¨¡å‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

3. **Process-Aware Distillation (PAD)** âœ… **æ ¸å¿ƒåˆ›æ–°**
   - å¼•å…¥ **Process Reward Model (PRM)** å¯¹æ¯ä¸€æ­¥æ¨ç†è¿›è¡Œç»†ç²’åº¦æ‰“åˆ†ã€‚
   - ä½¿ç”¨ **Group Relative Policy Optimization (GRPO)** è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œä½¿æ¨¡å‹å­¦ä¼šè‡ªæˆ‘ä¿®æ­£ã€åˆ†è§£é—®é¢˜ã€è¯†åˆ«é”™è¯¯ç­‰é«˜çº§æ¨ç†è¡Œä¸ºã€‚
   - å®ç°äº†å•æ¬¡å‰å‘ä¼ é€’ä¸­æ¨¡æ‹Ÿâ€œè¾©è¯å¼â€æ€è€ƒã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | AgentArk |
|------|--------|----------|
| **ä¾èµ–ç»“æ„è®¾è®¡** | éœ€è¦é¢„å®šä¹‰è§’è‰²ã€åè®®ã€æ‹“æ‰‘ | **agnostic to MAS algorithm**ï¼Œä»…å…³æ³¨æ¨ç†è¿‡ç¨‹æœ¬èº« |
| **ç›‘ç£ä¿¡å·æ·±åº¦** | å¤šä¸ºæœ€ç»ˆç­”æ¡ˆæˆ–æµ…å±‚äº¤äº’ç—•è¿¹ | æ·±åº¦åˆ©ç”¨**å®Œæ•´æ¨ç†è½¨è¿¹ + æ­¥çº§å¥–åŠ±ä¿¡å·** |
| **æ³›åŒ–èƒ½åŠ›** | æ˜“è¿‡æ‹Ÿåˆç‰¹å®šä»»åŠ¡æ¨¡å¼ | å±•ç°å‡ºå¼ºè·¨ä»»åŠ¡ã€è·¨é¢†åŸŸã€è·¨æ¨¡æ€æ³›åŒ– |
| **æ¨ç†æ•ˆç‡** | æ¨ç†æ—¶éœ€å¤šæ¬¡è°ƒç”¨å¤šä¸ªæ¨¡å‹ | å•æ¨¡å‹å•æ¬¡æ¨ç†ï¼Œ**ä½å»¶è¿Ÿã€ä½æˆæœ¬** |
| **å¯æ‰©å±•æ€§** | å—é™äº agent orchestration å¤æ‚æ€§ | æ¡†æ¶é€šç”¨ï¼Œæ”¯æŒä»»æ„ LLM backbone å’Œ MAS ç”Ÿæˆæ–¹å¼ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

| ç±»å‹ | æ•°æ®é›† | æè¿° |
|------|-------|------|
| æ•°å­¦æ¨ç† | **GSM8K**, **MATH** | å¤šæ­¥ç®—æœ¯ä¸ä»£æ•°é—®é¢˜ |
| å¢å¼ºæ•°å­¦ | **MetaMathQA (MMQA)** | æ›´å¤æ‚çš„å¤šæ­¥æ•°å­¦æ¨ç† |
| åŒ»ç–—é—®ç­” | **MedMCQA** | åŒ»å­¦è€ƒè¯•é£æ ¼é€‰æ‹©é¢˜ï¼Œä¾èµ–ä¸“ä¸šçŸ¥è¯† |
| æ³›åŒ–è¯„ä¼°ï¼ˆæœªç”¨äºè®­ç»ƒï¼‰ | **HotpotQA**, **QASPER**, **QMSum** | å¤šè·³æ¨ç†ã€é•¿æ–‡æœ¬ç†è§£ã€ä¼šè®®æ‘˜è¦ |

> âœ… æ‰€æœ‰è®­ç»ƒæ•°æ®ç”±å¤šæ™ºèƒ½ä½“è¾©è®ºè‡ªåŠ¨ç”Ÿæˆï¼Œå…±çº¦ **342k é—®é¢˜ + 2M æ¨ç†è½¨è¿¹**ã€‚

---

### **å®éªŒè®¾ç½®**

- **æ¨¡å‹å®¶æ—**ï¼š
  - **Qwen3**: 32B â†’ 8B / 1.7B / 0.6B
  - **Gemma3**: 27B â†’ 7B
  - **Llama3**: 8B
- **æ•™å¸ˆæ¨¡å‹**ï¼šQwen3-32B, Gemma3-27B-it
- **å­¦ç”Ÿæ¨¡å‹**ï¼šQwen3-8B/1.7B/0.6B, Gemma-7B, Llama3-8B
- **è’¸é¦æ–¹å¼**ï¼šåŒæ„ï¼ˆsame-familyï¼‰ä¸å¼‚æ„ï¼ˆcross-familyï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - ä¸»è¦ï¼š**Accuracy**
  - è¾…åŠ©ï¼šPerplexity, NLL, F1, ROUGE, BERTScore
  - æ¨ç†è´¨é‡è¯„åˆ†ï¼šStep Decomposition, Intermediate Verification, Error Localization, Reasoning Coherenceï¼ˆç”± InternLM-2.5-20b è‡ªåŠ¨è¯„ä¼°ï¼‰

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ–¹æ³• | æè¿° |
|------|------|
| **Single Agent (Base)** | åŸå§‹æœªè’¸é¦æ¨¡å‹ |
| **Vanilla Multi-Agent Debate** | 5-agent å¹³å‡è¡¨ç°ï¼ˆé«˜æˆæœ¬ï¼‰ |
| **Standard SFT** | ä»…ç”¨ç­”æ¡ˆå¾®è°ƒï¼ˆæ— æ¨ç†é“¾ï¼‰ |
| **RSFT** | ä½¿ç”¨å®Œæ•´æ¨ç†é“¾å¾®è°ƒ |
| **DA** | ä½¿ç”¨å¤šæ ·åŒ–è§£æ³•å¢å¼ºè®­ç»ƒé›† |
| **PAD** | PRM + GRPO å¼ºåŒ–å­¦ä¹ è’¸é¦ |
| **ç»„åˆæ–¹æ³•**ï¼šRSFT+DA, PAD+DA | ä¸¤é˜¶æ®µè®­ç»ƒ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### ğŸ”¹ æ€»ä½“æ€§èƒ½æå‡ï¼ˆä»¥ Qwen3-32B â†’ Qwen3-8B ä¸ºä¾‹ï¼‰

| æ–¹æ³• | GSM8K â†‘ | MedMCQA â†‘ |
|------|---------|-----------|
| Base | 88.17 | 59.65 |
| RSFT | 88.42 | 59.71 |
| DA | 87.11 | 58.33 |
| **PAD** | **89.05** | **63.12** |
| Vanilla MAS | ~89.2 | ~63.5 |

âœ… **ç»“è®º**ï¼šPAD å‡ ä¹è¾¾åˆ°ç”šè‡³æ¥è¿‘åŸå§‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è¡¨ç°ï¼Œä½†åªéœ€ä¸€æ¬¡æ¨ç†ï¼

---

#### ğŸ”¹ ä¸åŒå­¦ç”Ÿæ¨¡å‹ä¸Šçš„è¡¨ç°è¶‹åŠ¿

| å‘ç° | å†…å®¹ |
|------|------|
| âœ… **PAD æœ€ç¨³å®šæœ‰æ•ˆ** | åœ¨æ‰€æœ‰æ¨¡å‹ä¸Šå‡å¸¦æ¥ä¸€è‡´å¢ç›Šï¼Œå°¤å…¶åœ¨ MedMCQA ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³• |
| âš ï¸ **DA æ•ˆæœä¸ç¨³å®š** | å°æ¨¡å‹ï¼ˆå¦‚ 0.6Bï¼‰åŠ å…¥è¿‡å¤šè½¨è¿¹åè€Œå¯¼è‡´æ€§èƒ½ä¸‹é™ |
| ğŸ“ˆ **å¼‚æ„è’¸é¦æ”¶ç›Šæ›´å¤§** | å¦‚ Qwenâ†’Llama æˆ– Qwenâ†’Gemmaï¼Œè¡¨æ˜æ¶æ„å·®å¼‚æœ‰åŠ©äºå¸æ”¶æ–°æ¨ç†èŒƒå¼ |
| ğŸ§  **å¤§æ¨¡å‹æ›´å—ç›Šäºè§„æ¨¡æ‰©å±•** | å½“æ•™å¸ˆä» 5-agent æ‰©å±•åˆ° 20-agent æ—¶ï¼Œ8B æ¨¡å‹æŒç»­å—ç›Šï¼Œè€Œ 0.6B æ¨¡å‹è¿…é€Ÿé¥±å’Œç”šè‡³é€€åŒ– |

---

#### ğŸ”¹ æ•°æ®é‡ vs. æ•°æ®è´¨é‡ï¼ˆFigure 5ï¼‰

- **RSFT & DA**ï¼šéšç€æ•°æ®é‡å¢åŠ ï¼Œæ€§èƒ½æ³¢åŠ¨å‰§çƒˆï¼Œå­˜åœ¨â€œè¶Šå¤šè¶Šå·®â€ç°è±¡ï¼ˆå™ªå£°å¹²æ‰°ï¼‰ã€‚
- **PAD**ï¼šæ€§èƒ½éšæ•°æ®å¹³ç¨³ä¸Šå‡ï¼Œä½“ç°å‡ºå¯¹**é«˜è´¨é‡è¿‡ç¨‹ç›‘ç£**çš„å¼ºå¤§é€‚åº”åŠ›ã€‚

> ğŸ’¡ **å…³é”®å‘ç°**ï¼šå¯¹äºå°æ¨¡å‹ï¼Œ**æ¨ç†è´¨é‡ > æ•°æ®æ•°é‡**ã€‚

---

#### ğŸ”¹ æ¶ˆèå®éªŒç»“æœ

##### ï¼ˆ1ï¼‰PRM å®¹é‡å½±å“ï¼ˆTable 4ï¼‰
| PRM Size | Policy Size | GSM8K Acc |
|--------|------------|-----------|
| 0.6B | 0.6B | 42.84 |
| 8B | 0.6B | **88.48** |

â¡ï¸ **PRM çš„å»ºæ¨¡èƒ½åŠ›æ¯”å­¦ç”Ÿæ¨¡å‹æœ¬èº«æ›´é‡è¦ï¼** å³ä½¿å­¦ç”Ÿå¾ˆå°ï¼Œåªè¦ PRM å¼ºå¤§ï¼Œä»èƒ½æœ‰æ•ˆæŒ‡å¯¼å­¦ä¹ ã€‚

##### ï¼ˆ2ï¼‰GRPO vs PPOï¼ˆTable 5ï¼‰
- GRPO ä¸ PPO è¡¨ç°ç›¸è¿‘ï¼Œä½† GRPO **æ— éœ€ä»·å€¼å‡½æ•°**ï¼Œè®­ç»ƒæ›´è½»é‡ã€å¯æ‰©å±•æ€§å¼ºã€‚
- æ”¯æŒå…¶ä½œä¸ºå¤§è§„æ¨¡è’¸é¦çš„ç†æƒ³ä¼˜åŒ–å™¨ã€‚

##### ï¼ˆ3ï¼‰ç»„åˆç­–ç•¥ï¼ˆTable 7ï¼‰
| æ–¹æ³• | GSM8K (+DA) | MedMCQA (+DA) |
|------|-------------|---------------|
| RSFT â†’ DA | 70.27 | 44.30 |
| PAD â†’ DA | 70.69 | 43.68 |

â¡ï¸ å„æ–¹æ³•å…¼å®¹ï¼Œå åŠ ä½¿ç”¨å¯è¿›ä¸€æ­¥å°å¹…æå‡æ€§èƒ½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **å•æ¨¡å‹å¯ä»¥å†…åŒ–å¤šæ™ºèƒ½ä½“æ¨ç†èƒ½åŠ›**  
   AgentArk æˆåŠŸå°† MAS çš„æ¨ç†åŠ¨æ€â€œè’¸é¦â€è¿›å•ä¸ª LLMï¼Œä½¿å…¶å…·å¤‡ç±»ä¼¼ç¾¤ä½“æ™ºæ…§çš„æ¨ç†ã€çº é”™ä¸åæ€èƒ½åŠ›ã€‚

2. âœ… **PAD æ˜¯æœ€æœ‰æ•ˆçš„è’¸é¦æ–¹å¼**  
   åŸºäº PRM çš„è¿‡ç¨‹æ„ŸçŸ¥è’¸é¦ä¸ä»…èƒ½æå‡å‡†ç¡®ç‡ï¼Œè¿˜èƒ½æ”¹å–„æ¨ç†è¡Œä¸ºï¼ˆå¦‚åˆ†è§£ã€éªŒè¯ã€å®šä½é”™è¯¯ï¼‰ï¼Œæ˜¯å®ç°â€œå†…åœ¨åŒ–â€çš„å…³é”®ã€‚

3. âœ… **PRM èƒ½åŠ›å†³å®šä¸Šé™ï¼Œå­¦ç”Ÿå®¹é‡å†³å®šä¸‹é™**  
   - å¼ºå¤§çš„ PRM å¯èµ‹èƒ½å¼±å°çš„å­¦ç”Ÿï¼›
   - å¼± PRM ä¼šé™åˆ¶æ•´ä½“æ”¶ç›Šï¼›
   - å­¦ç”Ÿæ¨¡å‹å¤ªå°åˆ™æ— æ³•æ‰¿è½½å¤æ‚æ¨ç†æ¨¡å¼ã€‚

4. âœ… **æ¨ç†è´¨é‡ä¼˜äºæ•°é‡**  
   åŠ å…¥æ›´å¤šè½¨è¿¹ä¸ä¸€å®šæ›´å¥½ï¼›é«˜è´¨é‡ã€é«˜ä¿¡å™ªæ¯”çš„è¿‡ç¨‹ç›‘ç£æ‰æ˜¯å…³é”®ã€‚

5. âœ… **å…·å¤‡å¼ºå¤§æ³›åŒ–ä¸é²æ£’æ€§**
   - åœ¨ **TruthfulQA** ä¸Šè¡¨ç°æ›´çœŸå®å¯é ï¼ˆTable 2ï¼‰ï¼›
   - åœ¨ **HotpotQA/QASPER/QMSum** ç­‰ OOD ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿ï¼ˆFigure 6ï¼‰ï¼›
   - æ”¯æŒè¿ç§»åˆ° **Multimodal LLMs**ï¼ˆFigure 7ï¼‰ï¼Œå°½ç®¡å¢ç›Šè¾ƒå°ï¼Œä½†è¯æ˜äº†æ¨¡å¼é€šç”¨æ€§ã€‚

---

### **å±€é™æ€§**

1. **å½“å‰ä»…èšç„¦äºæ¨ç†ä»»åŠ¡**  
   æœªæ¶‰åŠå·¥å…·ä½¿ç”¨ï¼ˆtool useï¼‰ã€è®°å¿†ç®¡ç†ï¼ˆmemoryï¼‰ã€é•¿æœŸè§„åˆ’ç­‰æ›´å¤æ‚çš„ agent åŠŸèƒ½ã€‚

2. **ä¾èµ–é«˜è´¨é‡è¾©è®ºæ•°æ®ç”Ÿæˆ**  
   è‹¥æ•™å¸ˆæ¨¡å‹æœ¬èº«æ¨ç†èƒ½åŠ›ä¸è¶³æˆ–äº§ç”Ÿå¤§é‡é”™è¯¯è½¨è¿¹ï¼Œä¼šå½±å“è’¸é¦æ•ˆæœã€‚

3. **è®­ç»ƒæˆæœ¬è¾ƒé«˜ï¼ˆå°¤å…¶æ˜¯ PADï¼‰**  
   è™½ç„¶æ¨ç†é«˜æ•ˆï¼Œä½† PRM è®­ç»ƒ + GRPO å¾®è°ƒéœ€è¦è¾ƒå¤š GPU æ—¶é—´ï¼ˆ~20 å°æ—¶ on 8Ã—H100ï¼‰ã€‚

4. **å°šæœªæ¢ç´¢æ‰€æœ‰ MAS èŒƒå¼**  
   å½“å‰ä¸»è¦åŸºäº **debate**ï¼Œæœªæ¥å¯æ‹“å±•è‡³ critiqueã€consensusã€reflection ç­‰å…¶ä»–æœºåˆ¶ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **å¼€å‘è‡ªé€‚åº”è’¸é¦ç­–ç•¥**  
   æ ¹æ®ä»»åŠ¡éš¾åº¦ã€æ¨¡å‹å®¹é‡åŠ¨æ€è°ƒæ•´è½¨è¿¹é‡‡æ ·ä¸ç›‘ç£å¼ºåº¦ã€‚

2. **æ¨¡å—åŒ–/åˆ†å±‚ PRM è®¾è®¡**  
   é’ˆå¯¹ä¸åŒç±»å‹æ¨ç†æ­¥éª¤ï¼ˆå¦‚æ•°å­¦æ¨å¯¼ vs äº‹å®æ ¸æŸ¥ï¼‰è®¾è®¡ä¸“ç”¨ reward headsã€‚

3. **æ‰©å±•è‡³çœŸå®ä¸–ç•Œåº”ç”¨åœºæ™¯**  
   å¦‚åŒ»ç–—è¯Šæ–­è¾…åŠ©ã€é‡‘èå†³ç­–ã€æ•™è‚²è¾…å¯¼ä¸­çš„å®‰å…¨å…³é”®å‹ä»»åŠ¡ã€‚

4. **è·¨æ¨¡æ€æ¨ç†è’¸é¦**  
   å°†æ–‡æœ¬æ¨ç†èƒ½åŠ›è¿ç§»è‡³è§†è§‰ã€éŸ³é¢‘ç­‰å¤šæ¨¡æ€åœºæ™¯ï¼Œæ„å»ºçœŸæ­£é€šç”¨çš„æ™ºèƒ½ä½“ã€‚

5. **è½»é‡åŒ–éƒ¨ç½²æ–¹æ¡ˆ**  
   ç»“åˆé‡åŒ–ã€å‰ªæç­‰æŠ€æœ¯ï¼Œæ¨åŠ¨ AgentArk åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„åº”ç”¨ã€‚

---

> ğŸŒŸ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **AgentArk å®ç°äº†â€œä¸€ä¸ªé¡¶ä¸€ç¾¤â€çš„æ•ˆæœâ€”â€”é€šè¿‡å°†å¤šæ™ºèƒ½ä½“è¾©è®ºä¸­çš„é«˜è´¨é‡æ¨ç†è¿‡ç¨‹è’¸é¦è¿›å•ä¸ª LLMï¼Œæ—¢ä¿ç•™äº†ç¾¤ä½“æ™ºæ…§çš„ä¼˜åŠ¿ï¼Œåˆè·å¾—äº†å•æ¨¡å‹çš„é«˜æ•ˆä¸ç®€æ´ï¼Œä¸ºæœªæ¥é«˜æ•ˆã€é²æ£’ã€å¯æ‰©å±•çš„ LLM æ¨ç†ç³»ç»Ÿæä¾›äº†æ–°èŒƒå¼ã€‚**

</details>

---

### 3. [Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning](https://arxiv.org/abs/2602.04284)

**Authors**: Yansong Ning, Jun Fang, Naiqiang Tan, Hao Liu  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.04284v1  

#### Abstract
Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAgent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰ **LLM Agent** åœ¨å¤šè½®ä¸ç¯å¢ƒäº¤äº’è¿‡ç¨‹ä¸­ï¼Œæ™®éå­˜åœ¨ç”Ÿæˆå†—ä½™ **Thought**ï¼ˆæ¨ç†è¿‡ç¨‹ï¼‰å’Œç´¯ç§¯è¿‡å¤šå†å² **Observation**ï¼ˆç¯å¢ƒåé¦ˆï¼‰çš„é—®é¢˜ã€‚è¿™å¯¼è‡´ä¸Šä¸‹æ–‡é•¿åº¦è¿…é€Ÿè†¨èƒ€ï¼Œä¸¥é‡å½±å“ **æ¨ç†æ•ˆç‡** å’Œå®é™…éƒ¨ç½²æˆæœ¬ã€‚

ç°æœ‰æ–¹æ³•å¦‚ **Thought Management (TM)**ã€**Observation Management (OM)** æˆ– **TOM** é€šå¸¸å¯¹æ•´ä¸ªäº¤äº’è½¨è¿¹è¿›è¡Œç»Ÿä¸€å‹ç¼©æˆ–å‰ªæï¼Œå¿½ç•¥äº†ä¸åŒäº¤äº’è½®æ¬¡ä¸­ **Thought å¿…è¦æ€§** å’Œ **Observation å®ç”¨æ€§** çš„åŠ¨æ€å·®å¼‚ï¼Œä»è€Œå¯èƒ½æŸå®³ä»»åŠ¡å‡†ç¡®æ€§ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

æœ¬æ–‡æå‡º **Agent-Omit**ï¼Œä¸€ä¸ªç»Ÿä¸€çš„è®­ç»ƒæ¡†æ¶ï¼Œä½¿ LLM Agent èƒ½å¤Ÿ**è‡ªé€‚åº”åœ°çœç•¥å†—ä½™çš„ Thought å’Œ Observation**ï¼Œæå‡æ•ˆç‡è€Œä¸ç‰ºç‰²æ•ˆæœã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
1. **é¦–æ¬¡é‡åŒ–åˆ†æ Thought ä¸ Observation çš„è½®æ¬¡ä¾èµ–æ€§å½±å“**  
   - å‘ç°ï¼šæ—©æœŸè½®æ¬¡çš„ Thought å¯¹è§„åˆ’è‡³å…³é‡è¦ï¼Œä¸­é—´è½®æ¬¡å¸¸å¯çœç•¥ï¼›æ—©æœŸ Observation å¤šä¸ºå™ªå£°ï¼ŒåæœŸ Observation æ›´å…³é”®ã€‚
   - åŠ¨æœºï¼šæ”¯æŒâ€œé€‰æ‹©æ€§çœç•¥â€è€Œéå…¨å±€å‹ç¼©ã€‚

2. **æå‡º Agent-Omit æ¡†æ¶ï¼ŒåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒé˜¶æ®µ**ï¼š
   - **Agent Omission Behavior Synthesisï¼ˆå†·å¯åŠ¨è¡Œä¸ºåˆæˆï¼‰**  
     æ„å»ºå•è½®ä¸å¤šè½®çœç•¥åœºæ™¯çš„åˆæˆæ•°æ®ï¼Œé€šè¿‡ SFT è®©æ¨¡å‹å­¦ä¼šå¦‚ä½•æ‰§è¡Œ `<think></think>`ï¼ˆç©ºæ€è€ƒï¼‰å’Œ `<omit_tool_response_N_...>`ï¼ˆçœç•¥å†å²è§‚æµ‹ï¼‰ç­‰æ ¼å¼åŒ–çœç•¥è¡Œä¸ºã€‚
   - **Omit-Aware Agentic Reinforcement Learningï¼ˆçœç•¥æ„ŸçŸ¥çš„å¼ºåŒ–å­¦ä¹ ï¼‰**  
     å¼•å…¥åŒé‡‡æ ·æœºåˆ¶ï¼ˆFull & Partial Trajectoryï¼‰å’Œå®šåˆ¶çš„ **Omission Reward**ï¼Œåœ¨ RL é˜¶æ®µæ¿€åŠ±æ¨¡å‹ä¸»åŠ¨è¯†åˆ«å¹¶çœç•¥å†—ä½™ä¸Šä¸‹æ–‡ã€‚

3. **ç†è®ºä¿éšœï¼šçœç•¥ç­–ç•¥åå·®æœ‰ç•Œ**  
   - è¯æ˜æ‰€å­¦çœç•¥ç­–ç•¥ä¸æœ€ä¼˜ç­–ç•¥ä¹‹é—´çš„æ€§èƒ½åå·®ç”± **KL æ•£åº¦ä¸Šç•Œæ§åˆ¶**ï¼Œç¡®ä¿è®­ç»ƒç¨³å®šæ€§ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç±»åˆ« | å…¸å‹æ–¹æ³• | å±€é™æ€§ | Agent-Omit çš„ä¼˜åŠ¿ |
|------|--------|-------|------------------|
| **TM** | DEPO, ToolLight | å›ºå®šå‹ç¼©æ¨ç†é•¿åº¦ï¼Œç¼ºä¹çµæ´»æ€§ | è‡ªé€‚åº”åˆ¤æ–­æ˜¯å¦éœ€è¦æ¨ç† |
| **OM** | Observation-Mask, DeepMiner | å¯å‘å¼å‰ªæï¼Œæ˜“ä¸¢å¤±å…³é”®ä¿¡æ¯ | åŸºäºç­–ç•¥å­¦ä¹ åŠ¨æ€è¯†åˆ«æ— å…³è§‚æµ‹ |
| **TOM** | MEM-Agent, ReSum | ä½¿ç”¨å¤–éƒ¨ LLM æ€»ç»“ï¼Œå¼•å…¥é¢å¤–å»¶è¿Ÿä¸è¯¯å·® | å†…ç”Ÿå¼çœç•¥ï¼Œæ— éœ€é¢å¤–æ¨¡å— |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šå®ç°**é«˜å‡†ç¡®ç‡ä¸‹æ˜¾è‘—é™ä½ Token å¼€é”€**ï¼Œè¾¾æˆæ›´ä¼˜çš„ **Effectiveness-Efficiency Trade-off**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†ï¼ˆAgentGym-RL Benchmarkï¼‰
å…±äº”ä¸ªå¤šæ ·åŒ–ä»»åŠ¡ç¯å¢ƒï¼Œè¦†ç›–å¤šç§æ¨ç†ä¸äº¤äº’æ¨¡å¼ï¼š

| æ•°æ®é›† | ä»»åŠ¡ç±»å‹ | æœ€å¤§å›åˆæ•° | æµ‹è¯•æ ·æœ¬æ•° |
|-------|--------|----------|-----------|
| **DeepSearch** | ä¿¡æ¯æ£€ç´¢ï¼ˆæœç´¢å¼•æ“é—®ç­”ï¼‰ | 8 | 400 |
| **WebShop** | ç”µå•†ç½‘ç«™å¯¼èˆªä¸è´­ä¹° | 12 | 200 |
| **TextCraft** | æ–‡æœ¬ç‰ˆ Minecraft é…æ–¹åˆ¶ä½œ | 20 | 100 |
| **BabyAI** | ç½‘æ ¼ä¸–ç•ŒæŒ‡ä»¤è·Ÿéšä¸å¯¼èˆª | 10 | 90 |
| **SciWorld** | ç§‘å­¦å®éªŒæ¨¡æ‹Ÿï¼ˆåŒ–å­¦/ç”µè·¯ï¼‰ | 10 | 200 |

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹åŸºç¡€
- ä¸»å¹²æ¨¡å‹ï¼š`Qwen3-4B`, `Qwen3-8B`
- è¾“å‡ºæœ€å¤§é•¿åº¦ï¼š32K tokens

#### è®­ç»ƒæµç¨‹
1. **SFT å†·å¯åŠ¨é˜¶æ®µ**  
   - ä½¿ç”¨çº¦ 2â€“4K åˆæˆçš„å•/å¤šè½®çœç•¥æ•°æ®
   - å­¦ä¹ çœç•¥æ ¼å¼ä¸åŸºæœ¬è¡Œä¸º
2. **Agentic RL å¾®è°ƒé˜¶æ®µ**  
   - ä½¿ç”¨ **Group Relative Policy Optimization (GRPO)**
   - åŒé‡‡æ ·ç­–ç•¥ï¼ˆFull / Partial Trajectoryï¼‰
   - å¥–åŠ±å‡½æ•°ï¼š`r = (1âˆ’p) Ã— R_task + p Ã— R_omit`

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|-----|------|
| **Pass@1** | ä»»åŠ¡æˆåŠŸç‡ï¼ˆä¸»æŒ‡æ ‡ï¼‰ |
| **Avg Tok. â†“** | å¹³å‡æ€» Token æ¶ˆè€—ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ |
| **Effectiveness-Efficiency Trade-off** | ç»¼åˆè¡¡é‡æ€§èƒ½ä¸å¼€é”€çš„å¹³è¡¡èƒ½åŠ› |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

#### ï¼ˆ1ï¼‰å‰æ²¿ LLM Agentï¼ˆFrontier LLM Agentsï¼‰
- DeepSeek-R1-0528, DeepSeek-V3.2, OpenAI o3/o4-mini, Qwen3 ç³»åˆ—ç­‰

#### ï¼ˆ2ï¼‰é«˜æ•ˆ Agent æ„å»ºæ–¹æ³•ï¼ˆEfficient Agent Methodsï¼‰
| ç±»å‹ | æ–¹æ³• |
|------|------|
| **Thought Management** | Thinking-Retention, DEPO, ToolLight |
| **Observation Management** | Observation-Mask, DeepMiner |
| **Thought & Observation Management** | MEM-Agent, ReSum |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ Agent-Omit-8B-RL ä¸ºä¾‹ï¼‰

| æ–¹æ³• | DeepSearch Pass@1 | Avg Tok. | WebShop Pass@1 | Avg Tok. |
|------|--------------------|---------|----------------|---------|
| DeepSeek-R1-0528 | 25.25 | 6,412 | 19.37 | 11,308 |
| Qwen3-32B | 19.00 | 6,640 | 11.31 | 11,872 |
| **Agent-Omit-8B-RL** | **26.56** | **4,356** | **23.57** | **8,764** |

> âœ… åœ¨ **DeepSearch** ä¸Šè¶…è¶Šæ‰€æœ‰åŸºçº¿ï¼›
> âœ… åœ¨ **WebShop** ä¸Šå‡†ç¡®ç‡æå‡è¶… 20%ï¼ŒåŒæ—¶èŠ‚çœ ~25% Tokenã€‚

#### å…¶ä»–ä»»åŠ¡è¡¨ç°ï¼š
- **TextCraft**: 87.00 Pass@1ï¼ˆæœ€é«˜ï¼‰ï¼Œä»…éœ€ 7,328 tokens
- **BabyAI**: 84.36 Pass@1ï¼Œè¿œé«˜äºå…¶ä»–æ–¹æ³•
- **SciWorld**: 18.45 Pass@1ï¼Œæ˜¯ç¬¬äºŒåçš„ä¸¤å€ä»¥ä¸Š

---

### ğŸ“‰ ä¸é«˜æ•ˆ Agent æ–¹æ³•å¯¹æ¯”ï¼ˆQwen3-8B Backboneï¼‰

| æ–¹æ³• | DeepSearch Pass@1 | Avg Tok. | WebShop Pass@1 | Avg Tok. |
|------|--------------------|---------|----------------|---------|
| Qwen3-8B Base | 17.75 | 8,281 | 6.93 | 16,741 |
| ReSum | 22.28 | 5,724 | 17.80 | 9,251 |
| **Agent-Omit-8B-RL** | **26.56** | **4,356** | **23.57** | **8,764** |

> âœ… **å”¯ä¸€åŒæ—¶å®ç°æœ€é«˜å‡†ç¡®ç‡ä¸æœ€ä½ Token æ¶ˆè€—çš„æ–¹æ³•**

---

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

åœ¨ WebShop ä¸Šå¯¹ Qwen3-8B è¿›è¡Œæ¶ˆèç ”ç©¶ï¼š

| å˜ä½“ | Pass@1 | Avg Tok. | åˆ†æ |
|------|--------|--------|------|
| **Agent-Omit-8B-RL** | 23.57 | 8,764 | å®Œæ•´æ¨¡å‹ |
| w/o STOï¼ˆæ— å•è½®çœç•¥æ•°æ®ï¼‰ | â†“ æ˜¾è‘—ä¸‹é™ | â†‘ | å•è½®æ•°æ®æ˜¯è¡Œä¸ºåˆå§‹åŒ–å…³é”® |
| w/o MTOï¼ˆæ— å¤šè½®çœç•¥æ•°æ®ï¼‰ | â†“ ä¸‹é™ | â†‘ | å¤šè½®æ•°æ®ç»´æŒæ¨ç†è¿ç»­æ€§ |
| w/o PTï¼ˆæ—  Partial Trajectoryï¼‰ | â†“â†“ ä¸¥é‡ä¸‹é™ | â†‘â†‘ | ç¼ºä¹çœç•¥å‰ä¸Šä¸‹æ–‡æ— æ³•å­¦ä¹ ç­–ç•¥ |
| w/o ORï¼ˆæ—  Omission Rewardï¼‰ | å‡†ç¡®ç‡å°šå¯ | Token ä¸é™ | æ— å¥–åŠ±é©±åŠ¨åˆ™ä¸ä¸»åŠ¨çœç•¥ |
| w/o RLï¼ˆä»… SFTï¼‰ | 14.43 | 11,376 | RL æ˜¯æ•ˆç‡è·ƒå‡çš„å…³é”® |

> âœ… **ç»“è®º**ï¼šSFT æä¾›åŸºç¡€è¡Œä¸ºï¼ŒRL å®ç°è‡ªé€‚åº”ä¼˜åŒ–ï¼›ä¸¤è€…ç¼ºä¸€ä¸å¯ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Thought ä¸ Observation çš„é‡è¦æ€§å…·æœ‰è½®æ¬¡ä¾èµ–æ€§**  
   - åˆå§‹è½®æ¬¡ï¼šå¿…é¡»ä¿ç•™ Thought ç”¨äºè§„åˆ’
   - ä¸­é—´è½®æ¬¡ï¼šThought å’Œ Observation æœ€æ˜“è¢«çœç•¥ï¼ˆå¹³å‡çœç•¥ 3â€“4 è½®ï¼‰
   - æœ«å°¾è½®æ¬¡ï¼šObservation è‡³å…³é‡è¦ï¼Œçœç•¥ä¼šå¯¼è‡´å¤±è´¥

2. **è‡ªé€‚åº”çœç•¥æœºåˆ¶å¯è¡Œä¸”é«˜æ•ˆ**  
   - Agent-Omit èƒ½è‡ªåŠ¨è¯†åˆ«å¯å®‰å…¨çœç•¥çš„ä¸Šä¸‹æ–‡ç‰‡æ®µ
   - æ˜¾è‘—é™ä½ Token æˆæœ¬ï¼ˆæœ€é«˜å‡å°‘ 50%+ï¼‰ï¼ŒåŒæ—¶æå‡æˆ–ä¿æŒå‡†ç¡®ç‡

3. **RL æ˜¯å®ç°åŠ¨æ€çœç•¥çš„å…³é”®**  
   - SFT ä»…èƒ½æ•™ä¼šâ€œæ€ä¹ˆçœç•¥â€ï¼ŒRL æ‰èƒ½å­¦ä¼šâ€œä½•æ—¶çœç•¥â€

4. **ç†è®ºæ”¯æ’‘æˆç«‹**  
   - çœç•¥ç­–ç•¥çš„æ€§èƒ½åå·®å— KL æ•£åº¦æ§åˆ¶ï¼Œè®­ç»ƒç¨³å®šå¯æ”¶æ•›ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–é«˜è´¨é‡åˆæˆæ•°æ®æ„å»ºå†·å¯åŠ¨é›†**  
   - å½“å‰ä¾èµ–äººå·¥è®¾è®¡ prompt å’Œ rollout ç”Ÿæˆï¼Œéš¾ä»¥å®Œå…¨è‡ªåŠ¨åŒ–ã€‚
2. **å¯¹å¤æ‚çŠ¶æ€ç©ºé—´æ³›åŒ–ä»æœ‰é™**  
   - å¦‚ SciWorld ä¸­éƒ¨åˆ†ä»»åŠ¡ä»éœ€è¾ƒå¤šäº¤äº’æ­¥ã€‚
3. **æœªæ¢ç´¢æ›´å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚ Qwen3-72Bï¼‰ä¸Šçš„æ‰©å±•æ€§**

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **å°†çœç•¥æ•°æ®åˆæˆ pipeline æ‰©å±•è‡³é¢„è®­ç»ƒé˜¶æ®µ**  
   - æ„å»ºâ€œå¤©ç”Ÿé«˜æ•ˆâ€çš„ Agent æ¨¡å‹ã€‚
2. **æ¨å¹¿è‡³æ›´å¤§è§„æ¨¡ LLMï¼ˆå¦‚ Qwen3-72Bï¼‰éªŒè¯ä¸Šé™**
3. **ç»“åˆ Memory Mechanism å®ç°é•¿æœŸè®°å¿†ç®¡ç†**
4. **æ¢ç´¢å¤š Agent åœºæ™¯ä¸‹çš„ååŒçœç•¥ç­–ç•¥**

---

## âœ… æ€»ç»“

**Agent-Omit** æ˜¯é¦–ä¸ªç³»ç»Ÿæ€§æå‡ºå¹¶å®ç° **è‡ªé€‚åº” Thought ä¸ Observation çœç•¥** çš„ LLM Agent è®­ç»ƒæ¡†æ¶ã€‚å®ƒé€šè¿‡ **å†·å¯åŠ¨è¡Œä¸ºåˆæˆ + çœç•¥æ„ŸçŸ¥çš„ Agentic RL**ï¼Œå®ç°äº†åœ¨å¤šä¸ªå¤æ‚ä»»åŠ¡ä¸Š**ä¼˜äºå‰æ²¿ LLM Agent çš„æ€§èƒ½**ï¼ŒåŒæ—¶è¾¾åˆ°**æœ€ä½³çš„æ•ˆæœ-æ•ˆç‡æƒè¡¡**ã€‚è¯¥å·¥ä½œä¸ºæ„å»ºè½»é‡ã€é«˜æ•ˆã€å®ç”¨çš„ LLM Agent æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 4. [Expert Selections In MoE Models Reveal (Almost) As Much As Text](https://arxiv.org/abs/2602.04105)

**Authors**: Amir Nuriyev, Gabriel Kulp  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.04105v1  

#### Abstract
We present a text-reconstruction attack on mixture-of-experts (MoE) language models that recovers tokens from expert selections alone. In MoE models, each token is routed to a subset of expert subnetworks; we show these routing decisions leak substantially more information than previously understood...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠExpert Selections In MoE Models Reveal (Almost) As Much As Textã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡æ­ç¤ºäº† **Mixture-of-Experts (MoE)** æ¨¡å‹ä¸­ä¸€ä¸ªè¢«å¿½è§†çš„éšç§æ³„éœ²é£é™©ï¼š**ä»…é€šè¿‡è§‚å¯Ÿæ¯ä¸ª token è¢«è·¯ç”±åˆ°å“ªäº›ä¸“å®¶ï¼ˆexpert selectionsï¼‰ï¼Œæ”»å‡»è€…å³å¯é«˜ç²¾åº¦åœ°é‡å»ºåŸå§‹è¾“å…¥æ–‡æœ¬**ã€‚

å°½ç®¡ expert selections æ˜¯ç¦»æ•£ã€ä½å¸¦å®½çš„ä¸­é—´ä¿¡å·ï¼ˆè¿œå°äºå®Œæ•´ hidden states æˆ– embeddingsï¼‰ï¼Œä½†ç ”ç©¶è¡¨æ˜å…¶è•´å«çš„ä¿¡æ¯é‡è¿œè¶…é¢„æœŸï¼Œè¶³ä»¥æ„æˆä¸¥é‡éšç§å¨èƒã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
- **æå‡ºäº†ä¸€ç§åŸºäºåºåˆ—è§£ç å™¨çš„æ–‡æœ¬é‡å»ºæ”»å‡»æ–¹æ³•**ï¼š
  - ä½¿ç”¨ä¸€ä¸ª **encoder-only Transformer æ¶æ„ä½œä¸º sequence decoder**ï¼Œè”åˆå»ºæ¨¡æ•´ä¸ª token åºåˆ—çš„ expert selection traceï¼Œåˆ©ç”¨ä½ç½®ä¾èµ–å…³ç³»æå‡é‡å»ºå‡†ç¡®ç‡ã€‚
- å°† MoE è·¯ç”±æœºåˆ¶ä¸ **embedding inversion** é¢†åŸŸå»ºç«‹è”ç³»ï¼ŒæŒ‡å‡º expert selections å¯è§†ä¸ºä¸€ç§â€œç¦»æ•£åµŒå…¥â€ï¼ˆdiscrete embeddingsï¼‰ã€‚
- æ¢ç´¢äº†å¤šç§å®é™…å¯è¡Œçš„æ”»å‡»é¢ï¼ˆattack surfacesï¼‰ï¼Œå¦‚åˆ†å¸ƒå¼æ¨ç†ã€ç‰©ç†ä¾§ä¿¡é“ï¼ˆside channelsï¼‰ã€pipeline-parallel æ¶æ„ç­‰ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | æœ¬æ–‡æ–¹æ³• | å…ˆå‰å·¥ä½œï¼ˆå¦‚ MoEcho, Ding et al., 2025ï¼‰ |
|------|--------|-----------------------------|
| è§£ç ç­–ç•¥ | **åºåˆ—çº§è”åˆè§£ç **ï¼ˆsequence-to-sequenceï¼‰ | å• token åˆ†ç±»å™¨ï¼ˆå¦‚ logistic regressionï¼‰ |
| æ€§èƒ½ | æ˜¾è‘—æ›´é«˜ï¼ˆtop-1 å‡†ç¡®ç‡è¾¾ 91.2%ï¼‰ | æœ‰é™ï¼ˆé€šå¸¸ <50% top-1ï¼‰ |
| å»ºæ¨¡èƒ½åŠ› | åˆ©ç”¨ä¸Šä¸‹æ–‡ä¾èµ–å’Œ token é—´å…³ç³» | å¿½ç•¥åºåˆ—ç»“æ„ï¼Œç‹¬ç«‹é¢„æµ‹æ¯ä¸ª token |
| æ³›åŒ–æ€§ | æ”¯æŒé•¿åºåˆ—å»ºæ¨¡ä¸å¤§è§„æ¨¡è®­ç»ƒ | å¤šä¸ºæµ…å±‚æ¨¡å‹ï¼Œå®¹é‡å—é™ |

> ğŸ’¡ **æ ¸å¿ƒçªç ´**ï¼šè¯æ˜äº†å³ä½¿æ²¡æœ‰è®¿é—® logitsã€hidden states æˆ– expert outputsï¼Œä»…å‡­ expert indices å°±èƒ½å®ç°æ¥è¿‘æ–‡æœ¬çº§åˆ«çš„ä¿¡æ¯æ¢å¤ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **OpenWebText**ï¼šç”¨äºè®­ç»ƒä¸è¯„ä¼°ã€‚
  - åŒ…å«å¤šæ ·æ–‡æœ¬ï¼ˆæ–°é—»ã€è®ºå›ã€ä»£ç ç‰‡æ®µç­‰ï¼‰ï¼Œç”šè‡³åŒ…å«é«˜ç†µæ•æ„Ÿå†…å®¹ï¼ˆå¦‚å¯†ç ã€API keysï¼‰ã€‚
  - è®­ç»ƒé›†ï¼š1äº¿ä¸ª tokensï¼ˆåˆ’åˆ†ä¸º 32-token çš„è¿ç»­ chunkï¼‰
  - æµ‹è¯•é›†ï¼š1åƒä¸‡ä¸ª tokensï¼ˆheld-out splitï¼Œæœªå‚ä¸è®­ç»ƒï¼‰

### âš™ï¸ å®éªŒè®¾ç½®
- **ç›®æ ‡æ¨¡å‹**ï¼š`gpt-oss-20b`ï¼ˆæ¨¡æ‹Ÿç¯å¢ƒï¼‰
  - 24 å±‚ MoE
  - æ¯å±‚ 32 ä¸ª experts
  - Top-4 routingï¼ˆæ¯ token é€‰ 4 ä¸ªä¸“å®¶ï¼‰
  - ä¸ä½¿ç”¨è‡ªå›å½’ç”Ÿæˆï¼Œä»… prefill é˜¶æ®µå¤„ç†è¾“å…¥åºåˆ—
- **æ”»å‡»è€…å¯è§‚æµ‹ä¿¡å·**ï¼š
  - ä»…èƒ½è·å–æ¯å±‚å¯¹æ¯ä¸ª token çš„ unordered expert indicesï¼ˆå³ expert selection traceï¼‰
  - ä¸å¯è§ router logitsã€weightsã€hidden states æˆ– expert è¾“å‡º
- **è¾…åŠ©çŸ¥è¯†å‡è®¾**ï¼š
  - æ”»å‡»è€…çŸ¥é“ tokenizer å’Œ MoE é…ç½®ï¼ˆå¦‚ n=32, k=4ï¼‰
  - å¯ä»åŒæ—æ¨¡å‹æˆ–æ—¥å¿—ä¸­è·å¾— `(text, trace)` è®­ç»ƒå¯¹

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
- **Top-1 / Top-5 / Top-10 å‡†ç¡®ç‡**ï¼š
  - è¡¡é‡ reconstructed token æ˜¯å¦åœ¨é¢„æµ‹åˆ†å¸ƒçš„å‰ k åä¸­
- æ‰€æœ‰ç»“æœå‡åœ¨ **32-token è¾“å…¥åºåˆ—** ä¸ŠæŠ¥å‘Š
- ä¸»è¦ä½¿ç”¨å…¨éƒ¨ 24 å±‚çš„ expert selectionsï¼ˆé™¤éç‰¹åˆ«è¯´æ˜ï¼‰

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **Logistic Regression** | æ–‡çŒ®ä¸­çš„æ—©æœŸ baselineï¼ˆå¦‚ MoEchoï¼‰ï¼Œå• token åˆ†ç±» |
| **3-layer MLP** | æ›´å¼ºçš„ per-token åˆ†ç±»å™¨ï¼Œä½œä¸ºæœ¬æ–‡ weak baseline |
| **Transformer-based Sequence Decoder** | æœ¬æ–‡æå‡ºçš„ä¸»æ”»æ–¹æ³•ï¼Œç«¯åˆ°ç«¯åºåˆ—é‡å»º |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆOpenWebText, 32-token sequencesï¼‰

| æ–¹æ³• | Top-1 Acc | Top-5 Acc | Top-10 Acc |
|------|----------|----------|-----------|
| **3-layer MLP**ï¼ˆper-tokenï¼‰ | **63.1%** | 80.3% | 84.3% |
| **Transformer Sequence Decoder**ï¼ˆæœ¬æ–‡ï¼‰ | **91.2%** | 94.3% | **94.8%** |

> âœ… **æå‡æ˜¾è‘—**ï¼šç›¸æ¯” MLP æå‡è¿‘ 30 ä¸ªç™¾åˆ†ç‚¹ï¼ˆtop-1ï¼‰ï¼Œè¡¨æ˜åºåˆ—å»ºæ¨¡æå¤§å¢å¼ºäº†é‡å»ºèƒ½åŠ›ã€‚

### ğŸ” æ¶ˆèå®éªŒä¸åˆ†æç»“æœ

#### ï¼ˆ1ï¼‰è®­ç»ƒæ•°æ®è§„æ¨¡å½±å“ï¼ˆFigure 2ï¼‰
- åœ¨ 1M â†’ 100M tokens èŒƒå›´å†…ï¼Œæ€§èƒ½éšè®­ç»ƒæ•°æ®å¢åŠ è€Œ**å¹³æ»‘ä¸Šå‡**
- å³ä½¿åªæœ‰ 1M tokensï¼Œä¹Ÿèƒ½è¾¾åˆ° ~70% top-1 å‡†ç¡®ç‡ï¼Œæ˜¾ç¤ºæ”»å‡»å¯è¡Œæ€§è¾ƒé«˜

#### ï¼ˆ2ï¼‰token é¢‘ç‡çš„å½±å“ï¼ˆFigure 3ï¼‰
- é«˜é¢‘è¯ï¼ˆlogâ‚â‚€ count > 4ï¼‰é‡å»ºå‡†ç¡®ç‡æ¥è¿‘é¥±å’Œï¼ˆ>95%ï¼‰
- ä½é¢‘è¯ä»å¯è¾¾åˆ°åˆç†æ°´å¹³ï¼ˆå¦‚ logâ‚â‚€ count â‰ˆ 1.5 æ—¶çº¦ 60% top-1ï¼‰
- è¡¨æ˜æ”»å‡»ä¸ä»…é€‚ç”¨äºå¸¸è§è¯æ±‡ï¼Œä¹Ÿå¯¹éƒ¨åˆ†ç½•è§è¯æœ‰æ•ˆ

#### ï¼ˆ3ï¼‰å™ªå£°é²æ£’æ€§æµ‹è¯•ï¼ˆFigure 6ï¼‰
- å¯¹ expert selection trace æ·»åŠ éšæœºå™ªå£°ï¼ˆæ›¿æ¢éƒ¨åˆ† expert index ä¸ºéšæœºå€¼ï¼‰
- å½“å™ªå£°ç‡è¾¾åˆ° 50% æ—¶ï¼Œtop-1 å‡†ç¡®ç‡ä¸‹é™è‡³ ~50%ï¼Œä½†ä»é«˜äºéšæœºçŒœæµ‹
- è¡¨æ˜è½»å¾®æ‰°åŠ¨ä¸è¶³ä»¥å®Œå…¨é˜²å¾¡æ­¤ç±»æ”»å‡»

#### ï¼ˆ4ï¼‰å±‚æ•°ä¸ä¿¡æ¯ç†µåˆ†æï¼ˆFigures 4 & 5ï¼‰
- **æ—©æœŸå±‚ï¼ˆ1â€“7ï¼‰**ï¼šäº’ä¿¡æ¯é«˜ï¼Œå†—ä½™æ€§å¼º
- **ä¸­é—´å±‚ï¼ˆ~11ï¼‰**ï¼šä¸å…¶ä»–å±‚ç›¸å…³æ€§è¾ƒä½ï¼Œå¯èƒ½æ‰¿è½½æ›´ç‹¬ç‰¹è¯­ä¹‰ä¿¡æ¯
- æ€»ä½“ entropy ä¸Šé™çº¦ä¸º **206 bits/token**ï¼ˆç»éªŒä¼°è®¡ï¼‰ï¼Œè™½ä½äºç†è®ºæœ€å¤§å€¼ï¼ˆ363 bitsï¼‰ï¼Œä½†ä»è¿œé«˜äº English çš„å¹³å‡ä¿¡æ¯é‡ï¼ˆ~1â€“2 bits/charï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Expert selections æ³„éœ²å¤§é‡è¯­ä¹‰ä¿¡æ¯**ï¼š
   - å°½ç®¡æ˜¯ç¨€ç–ã€ç¦»æ•£ä¿¡å·ï¼Œä½†ç”±äºå…¶ä¾èµ–äºä¸Šä¸‹æ–‡ä¸”å…·æœ‰ determinismï¼Œå½¢æˆäº†é«˜åº¦ä¿¡æ¯æ€§çš„â€œæŒ‡çº¹â€ã€‚
2. **åºåˆ—çº§è§£ç ä¼˜äºé€ token åˆ†ç±»**ï¼š
   - åˆ©ç”¨ Transformer å»ºæ¨¡åºåˆ—ä¾èµ–åï¼Œé‡å»ºæ€§èƒ½å¤§å¹…æå‡ï¼Œè¯´æ˜è·¯ç”±æ¨¡å¼å­˜åœ¨è·¨ä½ç½®ä¸€è‡´æ€§ã€‚
3. **MoE è·¯ç”±åº”è¢«è§†ä¸ºæ•æ„Ÿè¾“å‡º**ï¼š
   - è®ºæ–‡ä¸»å¼ å°† expert selection traces è§†ä¸ºä¸åŸå§‹æ–‡æœ¬åŒç­‰æ•æ„Ÿçš„æ•°æ®ï¼Œåœ¨éƒ¨ç½²ä¸­éœ€ä¸¥æ ¼ä¿æŠ¤ã€‚
4. **å¤šç§ç°å®æ”»å‡»åœºæ™¯æˆç«‹**ï¼š
   - å¦‚æ¶æ„ä¸»æœºåœ¨åˆ†å¸ƒå¼æ¨ç†ä¸­ç›‘å¬è·¯ç”±ï¼›
   - é€šè¿‡ GPU performance counters æˆ–ç”µç£æ³„æ¼æ¨æ–­æ¿€æ´»ä¸“å®¶ï¼›
   - pipeline-parallel æ¶æ„ä¸‹é€šè¿‡è®¾å¤‡æ´»åŠ¨æ£€æµ‹åæ¨è·¯ç”±è·¯å¾„ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
| å±€é™ | è¯´æ˜ |
|------|------|
| **åºåˆ—é•¿åº¦é™åˆ¶** | å½“å‰æœ€ä½³ç»“æœé’ˆå¯¹ 32-token çŸ­åºåˆ—ï¼›å°šæœªç³»ç»Ÿç ”ç©¶æ•°ç™¾æˆ–æ•°åƒ token çš„é•¿ä¸Šä¸‹æ–‡è¡¨ç° |
| **ä¾èµ–è®­ç»ƒæ•°æ®è·å–** | æ”»å‡»éœ€å¤§é‡ `(text, trace)` å¯¹è¿›è¡Œè®­ç»ƒï¼Œè‹¥æ— æ³•è·å–åŒæ„æ¨¡å‹æˆ–æ—¥å¿—åˆ™éš¾ä»¥å®æ–½ |
| **è·¨æ¨¡å‹è¿ç§»æ€§æœªçŸ¥** | æœªéªŒè¯ decoder åœ¨ä¸åŒæ¶æ„ã€tokenizer æˆ– expert permutation ä¸‹çš„è¡¨ç° |
| **partial trace æ”¯æŒä¸è¶³** | è‹¥åªèƒ½è§‚æµ‹éƒ¨åˆ†å±‚ï¼ˆå¦‚ä»…æœ€åå‡ å±‚ï¼‰ï¼Œæ€§èƒ½ä¼šä¸‹é™ï¼Œä½†å…·ä½“ç¨‹åº¦æœªé‡åŒ– |

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³æ›´é•¿åºåˆ—**ï¼šè®¾è®¡æ”¯æŒé•¿ä¸Šä¸‹æ–‡ inversion çš„æ¶æ„ï¼ˆå¦‚ sliding window + beam searchï¼‰
2. **è·¨æ¨¡å‹è¿ç§»æ”»å‡»ç ”ç©¶**ï¼šæ¢ç´¢æ˜¯å¦å¯åœ¨ç›¸ä¼¼ MoE æ¶æ„é—´ transfer decoder
3. **é˜²å¾¡æœºåˆ¶é‡åŒ–è¯„ä¼°**ï¼š
   - å¦‚æ·»åŠ  logit noiseã€dummy computationã€expert shuffling ç­‰æ‰‹æ®µçš„å®é™…é˜²æŠ¤æ•ˆæœ
4. **ç‰©ç†ä¾§ä¿¡é“å®è¯éªŒè¯**ï¼š
   - ç»“åˆç¡¬ä»¶æµ‹é‡ï¼ˆpower, EMï¼‰ç›´æ¥ä»è¿è¡Œæ—¶ä¿¡å·è¿˜åŸ expert traces
5. **å½¢å¼åŒ–ä¿¡æ¯è®ºåˆ†æ**ï¼š
   - å»ºç«‹ expert selection ä¸ token identity ä¹‹é—´çš„ä¿¡æ¯ç“¶é¢ˆæ¨¡å‹

---

## ğŸ“ æ€»ç»“ä¸€å¥è¯
> **åœ¨ MoE æ¨¡å‹ä¸­ï¼Œexpert selections å¹¶éâ€œå‰¯äº§å“â€ï¼Œè€Œæ˜¯æºå¸¦äº†å‡ ä¹ä¸åŸå§‹æ–‡æœ¬ç›¸å½“çš„ä¿¡æ¯é‡â€”â€”å®ƒä»¬åº”å½“è¢«å½“ä½œæ•æ„Ÿæ•°æ®æ¥å¯¹å¾…ã€‚**

è¯¥ç ”ç©¶ä¸º MoE æ¨¡å‹çš„å®‰å…¨éƒ¨ç½²æ•²å“è­¦é’Ÿï¼Œå¹¶æ¨åŠ¨ç¤¾åŒºé‡æ–°æ€è€ƒä¸­é—´è¡¨ç¤ºçš„éšç§è¾¹ç•Œé—®é¢˜ã€‚

</details>

---

### 5. [Swordsman: Entropy-Driven Adaptive Block Partition for Efficient Diffusion Language Models](https://arxiv.org/abs/2602.04399)

**Authors**: Yu Zhang, Xinchen Li, Jialei Zhou, Hongnan Ma, Zhongwei Wan, Yiwei Shi, Duoqian Miao, Qi Zhang, Longbing Cao  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.04399v1  

#### Abstract
Block-wise decoding effectively improves the inference speed and quality in diffusion language models (DLMs) by combining inter-block sequential denoising and intra-block parallel unmasking. However, existing block-wise decoding methods typically partition blocks in a rigid and fixed manner, which i...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šSwordsman: Entropy-Driven Adaptive Block Partition for Efficient Diffusion Language Models**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
ç°æœ‰çš„ **Diffusion Language Models (DLMs)** è™½ç„¶ç†è®ºä¸Šæ”¯æŒå¹¶è¡Œè§£ç ä»¥æå‡æ¨ç†æ•ˆç‡ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ä»å—é™äºå¤§é‡è¿­ä»£å»å™ªæ­¥éª¤ï¼Œå¯¼è‡´**æ¨ç†é€Ÿåº¦æ…¢ã€ç”Ÿæˆè´¨é‡ä½**ã€‚  
å½“å‰ä¸»æµçš„ **block-wise decoding** æ–¹æ³•é€šè¿‡å°†åºåˆ—åˆ’åˆ†ä¸ºå›ºå®šé•¿åº¦çš„å—ï¼ˆfixed-length blocksï¼‰ï¼Œå®ç°å—é—´é¡ºåºè§£ç ä¸å—å†…å¹¶è¡Œå»æ©ç ï¼ˆunmaskingï¼‰ã€‚ç„¶è€Œï¼Œè¿™ç§**åˆšæ€§çš„åˆ†å—ç­–ç•¥**å¸¸å¸¸åœ¨è¯­ä¹‰æˆ–å¥æ³•æˆåˆ†ï¼ˆsyntactic/semantic constituentsï¼‰å†…éƒ¨è¿›è¡Œåˆ‡å‰²ï¼Œç ´åäº†è¯­è¨€çš„è‡ªç„¶ç»“æ„ï¼Œä»è€Œ**é™ä½ç”Ÿæˆå‡†ç¡®æ€§å’Œæ¨¡å‹ç¨³å®šæ€§**ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**
æœ¬æ–‡æå‡º **Swordsman** â€”â€” ä¸€ç§**æ— éœ€è®­ç»ƒ**ï¼ˆtraining-freeï¼‰ã€åŸºäºç†µé©±åŠ¨çš„è‡ªé€‚åº”åˆ†å—è§£ç æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **åˆ©ç”¨é¢„æµ‹ç†µçš„å˜åŒ–ï¼ˆentropy shiftï¼‰è¯†åˆ«è¯­ä¹‰è¾¹ç•Œ**ï¼šå— **Entropy Reduction Hypothesis (ERH)** å¯å‘ï¼Œä½œè€…è®¤ä¸ºï¼Œåœ¨æ‰©æ•£è§£ç è¿‡ç¨‹ä¸­ï¼Œ**è¯­ä¹‰æˆåˆ†è¾¹ç•Œå¤„çš„ä¸ç¡®å®šæ€§å˜åŒ–æœ€å¤§**ï¼Œå³ç›¸é‚» token ä¹‹é—´çš„ç†µå·®ï¼ˆâ–³Hï¼‰æ˜¾è‘—é«˜äºæˆåˆ†å†…éƒ¨ã€‚
- **è‡ªé€‚åº”åˆ†å—ï¼ˆAdaptive Block Partitioningï¼‰**ï¼šé€šè¿‡æ£€æµ‹ token åºåˆ—ä¸­çš„æœ€å¤§ç†µå˜ç‚¹æ¥åŠ¨æ€åˆ’åˆ† block è¾¹ç•Œï¼Œä½¿åˆ†å—æ›´è´´åˆçœŸå®çš„è¯­è¨€ç»“æ„ã€‚
- **åŠ¨æ€å»æ©ç é˜ˆå€¼æœºåˆ¶ï¼ˆDynamic Unmasking Thresholdï¼‰**ï¼šæ ¹æ®æ¯ä¸ª block å†…éƒ¨çš„å¹³å‡ç†µæ°´å¹³ï¼ŒåŠ¨æ€è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œå®ç°â€œé«˜ä¸ç¡®å®šå—ä¿å®ˆè§£ç ã€ä½ä¸ç¡®å®šå—æ¿€è¿›å¹¶è¡Œâ€ï¼Œè¿›ä¸€æ­¥å¹³è¡¡é€Ÿåº¦ä¸è´¨é‡ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ Fast-dLLMï¼‰ | Swordsman |
|------|--------------------------|-----------|
| åˆ†å—æ–¹å¼ | å›ºå®šé•¿åº¦ï¼ˆrigid, fixed-sizeï¼‰ | è‡ªé€‚åº”ã€è¯­ä¹‰å¯¹é½ï¼ˆadaptive, entropy-drivenï¼‰ |
| æ˜¯å¦éœ€è®­ç»ƒ | å¦ | å¦ï¼ˆå®Œå…¨ training-freeï¼‰ |
| å¹¶è¡Œæ•ˆç‡ | å—é™äºè·¨å—è¯­ä¹‰æ–­è£‚ | æ›´ä¼˜çš„å—å†…ä¸€è‡´æ€§æå‡å¹¶è¡Œå¯é æ€§ |
| é˜ˆå€¼ç­–ç•¥ | å…¨å±€é™æ€é˜ˆå€¼ | å—çº§åŠ¨æ€è°ƒæ•´ï¼Œé€‚é…éš¾åº¦å·®å¼‚ |
| æ€§èƒ½è¡¨ç° | é€Ÿåº¦å°šå¯ï¼Œç²¾åº¦å—é™ | æ˜¾è‘—æå‡ç²¾åº¦ï¼ŒåŒæ—¶ä¿æŒç”šè‡³è¶…è¶Šé€Ÿåº¦ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šé¦–æ¬¡å°†**ä¿¡æ¯è®ºä¸­çš„ç†µåˆ†æ**å¼•å…¥ DLM çš„ block åˆ’åˆ†å†³ç­–ï¼Œå®ç°äº†**è¯­ä¹‰æ„ŸçŸ¥çš„é«˜æ•ˆè§£ç **ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›†**
#### **é¢„è®­ç»ƒ DLM æ¨¡å‹**
- `LLaDA-8B-Instruct`
- `LLaDA-1.5`
- `Dream-v0-base-7B`

#### **åŸºå‡†æµ‹è¯•ä»»åŠ¡ï¼ˆBenchmarksï¼‰**
è¦†ç›–ä¸¤å¤§ç±»å…¸å‹ä»»åŠ¡ï¼š
- **ä»£ç ç”Ÿæˆ**ï¼š
  - HumanEval (0-shot)
  - MBPP (3-shot)
- **æ•°å­¦æ¨ç†**ï¼š
  - GSM8K (5-shot)
  - MATH (4-shot)

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

| è®¾ç½®é¡¹ | æè¿° |
|-------|------|
| **ç”Ÿæˆé•¿åº¦** | $ L = 512 $ |
| **é™æ€é˜ˆå€¼ï¼ˆbaselineï¼‰** | $ T_{\text{fixed}} = 0.9 $ |
| **Swordsman è¶…å‚** | æœ€å°ç†µå˜é˜ˆå€¼ $ T_{\min} = 0.1 $ï¼ŒåŸºç¡€ç½®ä¿¡é˜ˆå€¼ $ T_{\text{init}} = 0.9 $ |
| **åˆ†å—å¤§å°ï¼ˆfixedï¼‰** | 32ï¼ˆFast-dLLM æœ€ä¼˜è®¾å®šï¼‰ |
| **KV Cache é…ç½®** | ä¸‰ç§æ¨¡å¼ï¼š<br>â€¢ No Cache<br>â€¢ Prefix Cache<br>â€¢ Dual Cache |

#### **è¯„ä¼°æŒ‡æ ‡**
- **Accuracy (%)**ï¼šç”Ÿæˆè´¨é‡
- **Throughput (TPS, tokens/sec)**ï¼šè§£ç é€Ÿåº¦
- **Latency (s/sample)**ï¼šç«¯åˆ°ç«¯å»¶è¿Ÿ

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **Fast-dLLM** | Fixed block | æ”¯æŒ KV Cache å’Œå¹¶è¡Œè§£ç ï¼Œå½“å‰ä¸»æµ baseline |
| **D2F** | Fixed block | å¤šæ­¥æ¨ç†è’¸é¦ä¸ºå•æ­¥ï¼Œé€Ÿåº¦å¿«ä½†ç‰ºç‰²ç²¾åº¦ |
| **AdaBlock** | Adaptive block | åŸºäºæ ‡ç‚¹ç¬¦å·ç­‰å¯å‘å¼è§„åˆ™åˆ†å—ï¼Œæœªå¼€æºï¼Œå¼•ç”¨åŸè®ºæ–‡ç»“æœ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

#### **åœ¨ GSM8K ä¸Šçš„è¡¨ç°ï¼ˆLLaDA-8B-Instruct, Dual Cacheï¼‰**
| æ–¹æ³• | Accuracy | TPS | Latency |
|------|---------|-----|--------|
| Vanilla LLaDA | 77.40% | 3.32 | â€” |
| Fast-dLLM | 75.21% | 72.12 | 3.72s |
| **Swordsman** | **81.50%** | **73.74** | **3.66s** |

> ğŸ”º **ç›¸å¯¹ vanilla LLaDA**ï¼š+4.1% å‡†ç¡®ç‡ï¼Œ**8.79Ã— é€Ÿåº¦æå‡**

#### **åœ¨ HumanEval ä¸Šçš„è¡¨ç°ï¼ˆLLaDA-1.5, Dual Cacheï¼‰**
| æ–¹æ³• | Accuracy |
|------|---------|
| Fast-dLLM | 35.59% |
| **Swordsman** | **43.90%** |

> ğŸ”º **ç»å¯¹æå‡ +8.31%**ï¼Œä¸”é€Ÿåº¦ç›¸å½“

#### **Dream-v0-base-7B ä¸Š HumanEval æœ€é«˜ç²¾åº¦**
| æ–¹æ³• | Accuracy |
|------|---------|
| Fast-dLLM | 56.70% |
| **Swordsman** | **57.93%** |

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| æŒ‡æ ‡ | ç»“æœæ€»ç»“ |
|------|----------|
| **å‡†ç¡®æ€§** | åœ¨æ‰€æœ‰æ¨¡å‹å’Œä»»åŠ¡ä¸Šå‡è¾¾åˆ° SOTAï¼Œå°¤å…¶åœ¨ GSM8K å’Œ HumanEval ä¸Šå¤§å¹…é¢†å…ˆ Fast-dLLM å’Œ AdaBlock |
| **æ¨ç†é€Ÿåº¦** | ä¸ Fast-dLLM ç›¸å½“æˆ–ç•¥ä¼˜ï¼›æ˜¾è‘—ä¼˜äºæ— ç¼“å­˜ç‰ˆæœ¬ï¼›è™½ä½äº D2Fï¼Œä½†**ç²¾åº¦è¿œè¶… D2F** |
| **å¸•ç´¯æ‰˜å‰æ²¿ï¼ˆPareto Frontï¼‰** | å¤šä¸ªé…ç½®ä½äºé€Ÿåº¦-ç²¾åº¦å¸•ç´¯æ‰˜å‰æ²¿ï¼Œè¡¨æ˜å…¶ç»¼åˆæ€§èƒ½æœ€ä¼˜ |

> ğŸ“Š å›¾è¡¨æ˜¾ç¤ºï¼šSwordsman åœ¨ Dual Cache ä¸‹äº LLaDA-1.5 ä¸Šå®ç° **64.97 TPSã€3.03s å»¶è¿Ÿã€82.87% å‡†ç¡®ç‡**ï¼Œä¸‰é¡¹æŒ‡æ ‡å…¨é¢é¢†å…ˆã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰**

#### **åŠ¨æ€é˜ˆå€¼æœºåˆ¶çš„å½±å“**
| åˆå§‹é˜ˆå€¼ $ T_{\text{init}} $ | Accuracy | Latency |
|-------------------------------|--------|--------|
| 1.0ï¼ˆè¿‡ä¸¥ï¼‰ | ~81.45% | â†‘ 2.4Ã— å»¶è¿Ÿï¼ˆè¿‡åº¦ä¸²è¡ŒåŒ–ï¼‰ |
| 0.9ï¼ˆæ¨èï¼‰ | 81.43% | æœ€ä½³æƒè¡¡ |
| 0.5ï¼ˆè¿‡æ¾ï¼‰ | â†“ è‡³ 72.42% | è™½å¿«ä½†ç²¾åº¦å´©å¡Œ |

> âœ… åŠ¨æ€é˜ˆå€¼å¯åœ¨å‡ ä¹ä¸æŸç²¾åº¦çš„å‰æä¸‹**å‡å°‘çº¦ 2.5 ç§’å»¶è¿Ÿ**

#### **è‡ªé€‚åº”åˆ†å— vs å›ºå®šåˆ†å—**
- å›ºå®šåˆ†å—å¸¸å‰²è£‚â€œpassed by colorful benchesâ€ç­‰å®Œæ•´çŸ­è¯­
- è‡ªé€‚åº”åˆ†å—èƒ½ç²¾å‡†å®šä½â€œenjoying the fresh airâ€ã€â€œserene pondâ€ç­‰è¯­ä¹‰å•å…ƒè¾¹ç•Œï¼ˆè§ Figure 2ï¼‰
- å¼•å…¥è‡ªé€‚åº”åï¼Œä»…æ­¤ä¸€é¡¹å³å¯å¸¦æ¥ **+3.87% Accuracy æå‡**

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **è¯­ä¹‰è¾¹ç•Œå¯é€šè¿‡ç†µå˜æœ‰æ•ˆè¯†åˆ«**ï¼š  
   æ‰©æ•£è¿‡ç¨‹ä¸­çš„ token ç†µå˜åŒ–ï¼ˆentropy shiftï¼‰åœ¨è¯­ä¹‰æˆåˆ†è¾¹ç•Œå¤„æ˜¾è‘—å¢å¤§ï¼ŒéªŒè¯äº† ERH åœ¨ DLM ä¸­çš„æœ‰æ•ˆæ€§ã€‚

2. **è‡ªé€‚åº”åˆ†å—æ˜¾è‘—æå‡ç”Ÿæˆè´¨é‡**ï¼š  
   ä¸å›ºå®šåˆ†å—ç›¸æ¯”ï¼ŒSwordsman é€šè¿‡ aligning blocks with constituentsï¼Œå‡å°‘äº†è·¨å—ä¾èµ–å’Œä¸Šä¸‹æ–‡æ–­è£‚ï¼Œæå‡äº†ç”Ÿæˆè¿è´¯æ€§ä¸å‡†ç¡®æ€§ã€‚

3. **åŠ¨æ€é˜ˆå€¼å¢å¼ºé²æ£’æ€§ä¸æ•ˆç‡**ï¼š  
   å—å†…ä¸ç¡®å®šæ€§éšè§£ç æ¨è¿›è€Œä¸‹é™ï¼ŒåŠ¨æ€è°ƒä½é˜ˆå€¼å¯å®‰å…¨é‡Šæ”¾æ›´å¤šå¹¶è¡Œæ½œåŠ›ï¼Œé¿å…â€œå¡æ­»â€åœ¨ä½ç½®ä¿¡çŠ¶æ€ã€‚

4. **æ— éœ€è®­ç»ƒå³å¯å®ç° SOTA æ€§èƒ½**ï¼š  
   Swordsman å®Œå…¨ä½œä¸º inference-time framework è¿è¡Œï¼Œå…¼å®¹ç°æœ‰ DLM æ¶æ„ï¼Œå…·å¤‡å¼ºå®ç”¨æ€§ä¸éƒ¨ç½²å‹å¥½æ€§ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- å½“å‰éªŒè¯ä¸»è¦é›†ä¸­äº **block-wise DLMs**ï¼Œå°šæœªæ‰©å±•è‡³ semi-autoregressive æˆ–å…¶ä»–ç”ŸæˆèŒƒå¼ã€‚
- è¶…å‚æ•°ï¼ˆå¦‚ $ T_{\min} $ï¼‰å¯èƒ½éœ€é’ˆå¯¹ä¸åŒæ•°æ®é›†å¾®è°ƒï¼Œç¼ºä¹å®Œå…¨è‡ªé€‚åº”è°ƒèŠ‚æœºåˆ¶ã€‚
- å¯¹é•¿æ–‡æœ¬ï¼ˆ>512ï¼‰çš„åˆ†å—é€’å½’ç­–ç•¥æœªæ·±å…¥æ¢è®¨ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. å°† entropy-driven åˆ†å—æ€æƒ³æ¨å¹¿è‡³ **semi-autoregressive models**ã€‚
2. å¼€å‘ **learned adaptive parameter selection** æœºåˆ¶ï¼Œå‡å°‘äººå·¥è°ƒå‚ã€‚
3. æ¢ç´¢ç»“åˆ **constituency parsing prior** æˆ–è¯­æ³•çŸ¥è¯†è¿›ä¸€æ­¥ä¼˜åŒ–è¾¹ç•Œæ£€æµ‹ã€‚
4. åœ¨æ›´å¤§è§„æ¨¡ä»»åŠ¡ï¼ˆå¦‚ long-form QAã€story generationï¼‰ä¸­éªŒè¯æ³›åŒ–èƒ½åŠ›ã€‚

---

> âœ… **æ€»ä½“è¯„ä»·**ï¼šSwordsman æ˜¯ä¸€ä¸ªç®€æ´è€Œå¼ºå¤§çš„ inference-time ä¼˜åŒ–æ¡†æ¶ï¼Œé€šè¿‡å°†**ä¿¡æ¯è®ºæ´å¯Ÿè½¬åŒ–ä¸ºå®é™…è§£ç ç­–ç•¥**ï¼ŒæˆåŠŸè§£å†³äº† DLM ä¸­é•¿æœŸå­˜åœ¨çš„â€œæ•ˆç‡-è´¨é‡â€æƒè¡¡éš¾é¢˜ï¼Œä¸º diffusion-based language generation æä¾›äº†æ–°çš„è®¾è®¡èŒƒå¼ã€‚

</details>

---

### 6. [PersoDPO: Scalable Preference Optimization for Instruction-Adherent, Persona-Grounded Dialogue via Multi-LLM Evaluation](https://arxiv.org/abs/2602.04493)

**Authors**: Saleh Afzoon, MohammadHossein Ahmadi, Usman Naseem, Amin Beheshti  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.04493v1  

#### Abstract
Personalization and contextual coherence are two essential components in building effective persona-grounded dialogue systems. These aspects play a crucial role in enhancing user engagement and ensuring responses are more relevant and consistent with user identity. However, recent studies indicate t...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠPersoDPO: Scalable Preference Optimization for Instruction-Adherent, Persona-Grounded Dialogue via Multi-LLM Evaluationã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¼€æº Large Language Models (LLMs) åœ¨ç”Ÿæˆå¯¹è¯å“åº”æ—¶è™½ç„¶å…·å¤‡è‰¯å¥½çš„**è¯­è¨€æµç•…æ€§**ï¼ˆfluencyï¼‰å’Œè‡ªç„¶åº¦ï¼ˆnaturalnessï¼‰ï¼Œä½†åœ¨ä»¥ä¸‹ä¸‰ä¸ªå…³é”®ç»´åº¦ä¸Šä»å­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼š
- **Contextual Coherence**ï¼ˆä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼‰ï¼šéš¾ä»¥åœ¨å¤šè½®å¯¹è¯ä¸­ä¿æŒè¯­ä¹‰ä¸€è‡´æ€§ã€‚
- **Persona Alignment**ï¼ˆäººè®¾å¯¹é½ï¼‰ï¼šæ— æ³•æœ‰æ•ˆç»“åˆç”¨æˆ·ä¸ªæ€§ç‰¹å¾ï¼ˆpersonaï¼‰ç”Ÿæˆä¸ªæ€§åŒ–å›å¤ã€‚
- **Instruction Adherence**ï¼ˆæŒ‡ä»¤éµå¾ªï¼‰ï¼šè¾“å‡ºæ ¼å¼ä¸ä¸€è‡´ï¼Œå½±å“ä¸‹æ¸¸ç³»ç»Ÿé›†æˆã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†å…¶åœ¨è™šæ‹ŸåŠ©æ‰‹ã€å®¢æœæœºå™¨äººç­‰å®é™…åœºæ™¯ä¸­çš„éƒ¨ç½²æ•ˆæœã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **PersoDPO** â€”â€” ä¸€ç§å¯æ‰©å±•çš„åå¥½ä¼˜åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨è”åˆæå‡å¯¹è¯ç³»ç»Ÿçš„ï¼š
- ä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼ˆCoherenceï¼‰
- äººè®¾å¯¹é½èƒ½åŠ›ï¼ˆPersona Groundingï¼‰
- æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼ˆInstruction Adherenceï¼‰

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

1. **åŸºäºå¤šLLMè‡ªåŠ¨è¯„ä¼°æ„å»ºé«˜è´¨é‡åå¥½å¯¹ï¼ˆPreference Pairsï¼‰**
   - åˆ©ç”¨å¤šä¸ª**å¼€æº + é—­æº LLMs**ï¼ˆå¦‚ GPT-4ã€Qwen2ã€Mistral ç­‰ï¼‰åœ¨åŒä¸€è¾“å…¥ä¸‹ç”Ÿæˆå“åº”ã€‚
   - ä½¿ç”¨è‡ªåŠ¨åŒ–è¯„ä¼°æŒ‡æ ‡ï¼ˆæ¥è‡ª PersoBenchï¼‰ä¸ºæ¯ä¸ªå“åº”æ‰“åˆ†ï¼Œæ— éœ€äººå·¥æ ‡æ³¨å³å¯æ„é€ â€œchosenâ€ä¸â€œrejectedâ€æ ·æœ¬å¯¹ã€‚

2. **èåˆå¤šç»´è¯„ä»·ä¿¡å·è¿›è¡ŒåŠ æƒDPOè®­ç»ƒ**
   - ç»¼åˆå››ç§ metric-based signalsï¼š
     - `C Score`ï¼ˆConsistency Scoreï¼‰
     - `P Score`ï¼ˆPersona Distance Scoreï¼‰
     - `UE Score`ï¼ˆUtterance Entailment Scoreï¼‰
     - `Coh-UniEval`
   - å¼•å…¥æ–°çš„ **Length-Format Compliance (LFC)** ä¿¡å·ï¼Œé¼“åŠ±æ¨¡å‹éµå®ˆè¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰å’Œé•¿åº¦é™åˆ¶ã€‚

3. **æ— éœ€äººå·¥æ ‡æ³¨çš„å¯æ‰©å±•è®­ç»ƒæµç¨‹**
   - å®Œå…¨ä¾èµ–è‡ªåŠ¨è¯„ä¼°ä¿¡å·ï¼Œå®ç°ç«¯åˆ°ç«¯çš„ annotation-free åå¥½å­¦ä¹ ï¼Œæ˜¾è‘—é™ä½æ ‡æ³¨æˆæœ¬å¹¶æé«˜å¯å¤ç°æ€§ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| å¯¹æ¯”ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ DPOCã€æ ‡å‡† DPOï¼‰ | PersoDPO |
|--------|-------------------------------|---------|
| **ç›‘ç£æ¥æº** | æ‰‹å·¥æ ‡æ³¨ / å¯å‘å¼è§„åˆ™ / å•ä¸€æ¨¡å‹åé¦ˆ | å¤šLLMè¾“å‡º + è‡ªåŠ¨è¯„ä¼°ï¼Œæ›´å…¨é¢å¯é  |
| **ä¼˜åŒ–ç›®æ ‡** | èšç„¦å•ä¸€ç»´åº¦ï¼ˆå¦‚ persona æˆ– coherenceï¼‰ | è”åˆä¼˜åŒ– coherenceã€personalizationã€instruction adherence |
| **æŒ‡ä»¤éµå¾ª** | å¿½è§†æ ¼å¼ä¸é•¿åº¦æ§åˆ¶ | æ˜¾å¼å»ºæ¨¡ LFC ä¿¡å·ï¼Œå¢å¼º instructability |
| **å¯æ‰©å±•æ€§** | ä¾èµ–äººå·¥å¹²é¢„ | å…¨æµç¨‹è‡ªåŠ¨åŒ–ï¼Œé€‚åˆå·¥ä¸šçº§éƒ¨ç½² |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- ä½¿ç”¨ **FoCus dataset**ï¼šä¸€ä¸ªç”¨äºä¸ªæ€§åŒ–å¯¹è¯ç”Ÿæˆçš„åŸºå‡†æ•°æ®é›†ã€‚
  - åŒ…å«å¤šè½®å¯¹è¯å†å²ï¼ˆdialogue contextï¼‰
  - æä¾›ç”¨æˆ· persona æè¿°ï¼ˆpersona descriptionsï¼‰
  - æ›´é•¿çš„ä¸Šä¸‹æ–‡è®¾è®¡æœ‰åˆ©äºæµ‹è¯•è¿è´¯æ€§å’Œä¸ªæ€§åŒ–èƒ½åŠ›ã€‚

> Prompt æ„é€ æ–¹å¼ï¼šå°† persona å’Œ dialogue context æ‹¼æ¥ä½œä¸ºè¾“å…¥ï¼Œè¦æ±‚æ¨¡å‹ä»¥ JSON æ ¼å¼è¿”å› `"response"` å­—æ®µã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

#### æ¨¡å‹é€‰æ‹©
- **å€™é€‰ LLMsï¼ˆç”¨äºç”Ÿæˆåˆå§‹å“åº”ï¼‰**ï¼š
  - å¼€æºæ¨¡å‹ï¼š`Qwen2-7B`, `Mistral-7B`, `LLaMA 3.1-8B`
  - API æ¨¡å‹ï¼š`GPT-3.5-Turbo`, `GPT-4-Turbo`, `GPT-4o-Mini`

- **ç›®æ ‡å¾®è°ƒæ¨¡å‹**ï¼š`Qwen2-5B-Instruct`ï¼ˆå›  GPU å†…å­˜é™åˆ¶ï¼‰

#### åå¥½å¯¹æ„å»º
- ä» FoCus è®­ç»ƒé›†ä¸­é‡‡æ ·çº¦ 1,500 æ¡è®°å½•ç”Ÿæˆå“åº”ã€‚
- å¯¹æ¯æ¡ prompt æ”¶é›†å¤šä¸ª LLM è¾“å‡ºï¼Œå¹¶é€šè¿‡è‡ªåŠ¨è¯„åˆ†é€‰å‡ºé«˜åˆ†ï¼ˆchosenï¼‰ä¸ä½åˆ†ï¼ˆrejectedï¼‰å“åº”ã€‚
- æœ€ç»ˆæ„å»ºçº¦ **9,000 ä¸ª preference pairs**ã€‚

#### å¾®è°ƒç­–ç•¥
- ä½¿ç”¨ Hugging Face çš„ `TRL` åº“ä¸­çš„ `ScoreWeightedDPOTrainer`ã€‚
- é‡‡ç”¨ **weighted DPO objective**ï¼Œå…¬å¼å¦‚ä¸‹ï¼š

$$
\mathcal{L}_{\text{PersoDPO}} = \mathbb{E}_{x,y_c,y_r} \left[ \sigma(\Delta S) \cdot (\log p_\theta(y_c|x) - \log p_\theta(y_r|x)) \right]
$$

å…¶ä¸­ $\Delta S = S_{\text{total}}^{(c)} - S_{\text{total}}^{(r)}$ æ˜¯æ€»è´¨é‡å¾—åˆ†å·®å€¼ï¼Œ$S_{\text{total}} = S_{\text{metric}} + S_{\text{LFC}}$

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡ï¼ˆæ²¿ç”¨ PersoBenchï¼‰

| æŒ‡æ ‡ | ç±»å‹ | å«ä¹‰ |
|------|-----|------|
| `Coh-UniEval` | Coherence | è¡¡é‡ä¸Šä¸‹æ–‡è¿è´¯æ€§ä¸é€»è¾‘ä¸€è‡´æ€§ |
| `C Score` | Personalization | ä¸€è‡´æ€§å¾—åˆ†ï¼Œæƒ©ç½š persona ä¸ä¸€è‡´ |
| `UE Score` | Coherence | å›åº”æ˜¯å¦è•´å«äºä¸Šä¸‹æ–‡ä¸­ï¼ˆutterance entailmentï¼‰ |
| `P Score` | Personalization | persona è·ç¦»å¾—åˆ†ï¼Œè¶Šæ¥è¿‘è¶Šå¥½ |
| `Failure Ratio` | Instructability | è¾“å‡ºä¸ç¬¦åˆ JSON æ ¼å¼æˆ–è¶…é•¿çš„æ¯”ä¾‹ |
| `Response Time` | Efficiency | æ¨ç†å»¶è¿Ÿï¼Œåæ˜ å®ç”¨æ€§ |

æ‰€æœ‰åˆ†æ•°å½’ä¸€åŒ–è‡³ [0,1] åŒºé—´ã€‚

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ¨¡å‹ | ç±»å‹ | è¯´æ˜ |
|--------|-----|------|
| `Qwen2-7B`, `Mistral-7B`, `LLaMA 3.1-8B` | é›¶æ ·æœ¬åŸºå‡†ï¼ˆZero-shot Baselineï¼‰ | ç›´æ¥æ¨ç†ï¼Œæœªå¾®è°ƒ |
| `Qwen2-5B-DPO` | Vanilla DPO å¾®è°ƒæ¨¡å‹ | ä½¿ç”¨ä¼ ç»Ÿ DPO æ–¹æ³•å¾®è°ƒï¼Œä»…åŸºäºæ ¼å¼æœ‰æ•ˆæ€§æ„å»ºåå¥½å¯¹ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| Model | Coh-UniEval â†‘ | C Score â†‘ | UE Score â†‘ | P Score â†‘ |
|-------|----------------|-----------|------------|-----------|
| Qwen2-7B Benchmark | 0.37Â±0.48 | -0.31Â±0.84 | 0.17Â±0.48 | 0.29Â±0.30 |
| Mistral-7B Benchmark | 0.53Â±0.46 | -0.23Â±0.82 | 0.21Â±0.52 | 0.30Â±0.28 |
| Llama3.1-8B Benchmark | 0.55Â±0.49 | -0.22Â±0.87 | 0.17Â±0.48 | 0.33Â±0.33 |
| Qwen2-5B DPO | 0.98Â±0.49 | 0.06Â±0.49 | 0.21Â±0.58 | 0.29Â±0.26 |
| **Qwen2-5B PersoDPO** | **0.70Â±0.45** | **0.18Â±0.87** | **0.30Â±0.62** | **0.44Â±0.30** |

> æ³¨ï¼šâ†‘ è¡¨ç¤ºè¶Šé«˜è¶Šå¥½ï¼›è´Ÿå€¼è¡¨ç¤ºä¸¥é‡ persona ä¸ä¸€è‡´ã€‚

---

### ğŸ”¬ ç»“æœåˆ†æ

#### âœ… PersoDPO å…¨é¢è¶…è¶Šæ‰€æœ‰å¼€æºåŸºçº¿
- åœ¨ **å…¨éƒ¨å››é¡¹æŒ‡æ ‡ä¸Šå‡ä¼˜äºä¸‰å¤§é›¶æ ·æœ¬æ¨¡å‹**ï¼ˆQwen2/Mistral/Llamaï¼‰ï¼Œå°¤å…¶åœ¨ `C Score` å’Œ `P Score` ä¸Šè¡¨ç°çªå‡ºã€‚
- å°½ç®¡ `Coh-UniEval` ç•¥ä½äº DPO åŸºçº¿ï¼ˆ0.70 vs 0.98ï¼‰ï¼Œä½†å…¶ `UE Score` æ›´é«˜ï¼ˆ0.30 > 0.21ï¼‰ï¼Œè¡¨æ˜åœ¨å®é™…è¯­ä¹‰è¿è´¯æ€§æ–¹é¢æ›´å…·ä¼˜åŠ¿ã€‚

#### âœ… æ˜¾è‘—ä¼˜äº vanilla DPO æ–¹æ³•
- `C Score`: 0.18 vs 0.06 â†’ æå‡ **200%**
- `P Score`: 0.44 vs 0.29 â†’ æå‡ **51.7%**
- è¡¨æ˜ **multi-LLM evaluation + å¤šç»´åº¦ä¿¡å·èåˆ** èƒ½æ›´æœ‰æ•ˆåœ°æ•æ‰ persona-aligned è¡Œä¸ºã€‚

#### âœ… å·¥ä¸šå®ç”¨æ€§å¼º
- å¦‚å›¾ 2(c) æ‰€ç¤ºï¼š
  - **Failure Ratio æ›´ä½**ï¼šè¯´æ˜ PersoDPO æ›´å¥½åœ°éµå®ˆäº† JSON æ ¼å¼å’Œé•¿åº¦çº¦æŸã€‚
  - **Response Time æ›´çŸ­**ï¼šå“åº”æ›´å¿«ï¼Œæ›´é€‚åˆç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ã€‚

> è¿™éªŒè¯äº† LFC ä¿¡å·çš„æœ‰æ•ˆæ€§ï¼Œæå‡äº†æ¨¡å‹çš„ **instructability** å’Œ **reliability**ã€‚

---

### âŒ æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰è¯´æ˜
å°½ç®¡åŸæ–‡æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèå®éªŒè¡¨æ ¼ï¼Œä½†ä»æ–¹æ³•æè¿°ä¸­å¯ä»¥æ¨æ–­å‡ºä»¥ä¸‹å…³é”®è®¾è®¡çš„ä½œç”¨ï¼š

| ç»„ä»¶ | åŠŸèƒ½ | å½±å“ |
|------|------|------|
| Multi-LLM Evaluation | å¼•å…¥å¤šæ ·åŒ–å“åº”æº | æé«˜åå¥½å¯¹å¤šæ ·æ€§ä¸é²æ£’æ€§ |
| Metric-based Signals (`C`, `P`, `UE`, `Coh-UniEval`) | å¼ºåŒ– persona ä¸ coherence å­¦ä¹  | æ˜¾è‘—æå‡ä¸ªæ€§åŒ–èƒ½åŠ› |
| LFC Signal | é¼“åŠ±æ ¼å¼ä¸é•¿åº¦åˆè§„ | é™ä½ failure ratioï¼Œæå‡ instructability |
| Score-weighted DPO | æ ¹æ®å¾—åˆ†å·®è·è°ƒæ•´æ¢¯åº¦æƒé‡ | åŠ é€Ÿæ”¶æ•›ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ |

> å›¾ 2(a)(b) æ˜¾ç¤ºè®­ç»ƒè¿‡ç¨‹ä¸­ loss å¹³ç¨³ä¸‹é™ã€reward accuracy æ¥è¿‘ä¸Šé™ï¼Œè¯æ˜è¯¥ç­–ç•¥å…·æœ‰è‰¯å¥½çš„ä¼˜åŒ–ç¨³å®šæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **å¤šLLMè‡ªåŠ¨è¯„ä¼°æ˜¯æ„å»ºé«˜è´¨é‡åå¥½æ•°æ®çš„æœ‰æ•ˆé€”å¾„**
   - å¯æ›¿ä»£æ˜‚è´µçš„äººç±»æ ‡æ³¨ï¼Œåœ¨ä¿è¯è´¨é‡çš„åŒæ—¶å¤§å¹…æå‡å¯æ‰©å±•æ€§ã€‚

2. **è”åˆä¼˜åŒ– coherenceã€personalization å’Œ instruction adherence æ˜¯å¯è¡Œä¸”å¿…è¦çš„**
   - å•ä¸€ç»´åº¦ä¼˜åŒ–å®¹æ˜“å¯¼è‡´å…¶ä»–æ–¹é¢çš„é€€åŒ–ï¼Œè€Œ PersoDPO å®ç°äº†ä¸‰è€…ä¹‹é—´çš„è‰¯å¥½å¹³è¡¡ã€‚

3. **PersoDPO æ˜¾è‘—ä¼˜äºå¼ºåŸºçº¿æ¨¡å‹**
   - åœ¨ FoCus æ•°æ®é›†ä¸Šï¼Œæ— è®ºæ˜¯åœ¨ä¸ªæ€§åŒ–è¿˜æ˜¯è¿è´¯æ€§æŒ‡æ ‡ä¸Šéƒ½å–å¾—é¢†å…ˆï¼Œå°¤å…¶åœ¨æœ€å…·æŒ‘æˆ˜æ€§çš„ `C Score` ä¸Šå®ç°çªç ´ã€‚

4. **æŒ‡ä»¤éµå¾ªå¯é€šè¿‡æ˜¾å¼å¥–åŠ±æœºåˆ¶æ”¹å–„**
   - å¼•å…¥ LFC ä¿¡å·åï¼Œfailure ratio æ˜æ˜¾ä¸‹é™ï¼Œå“åº”æ—¶é—´ç¼©çŸ­ï¼Œå¢å¼ºäº†å·¥ä¸šé€‚ç”¨æ€§ã€‚

---

### âš ï¸ å±€é™æ€§

1. **ä¾èµ–å¤–éƒ¨ LLM è¾“å‡ºè´¨é‡**
   - è‹¥é—­æºæ¨¡å‹ï¼ˆå¦‚ GPT-4ï¼‰æœ¬èº«å­˜åœ¨åå·®æˆ–é”™è¯¯ï¼Œå¯èƒ½æ±¡æŸ“åå¥½å¯¹ã€‚
   - å­˜åœ¨ API æˆæœ¬å’Œè®¿é—®é™åˆ¶é—®é¢˜ã€‚

2. **è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡ä»æœ‰å±€é™**
   - å½“å‰ metric-based evaluatorsï¼ˆå¦‚ P Scoreï¼‰è™½ç» fine-tunedï¼Œä½†ä»æ— æ³•å®Œå…¨æ›¿ä»£äººç±»åˆ¤æ–­ã€‚

3. **æœªæ¶µç›–æ›´å¤šä»»åŠ¡ç±»å‹**
   - å®éªŒé›†ä¸­åœ¨é€šç”¨ persona-grounded å¯¹è¯ï¼Œå°šæœªæ‰©å±•åˆ°åŒ»ç–—ã€é‡‘èç­‰å‚ç›´é¢†åŸŸã€‚

4. **ç¼ºä¹è·¨æ–‡åŒ–/è¯­è¨€æ³›åŒ–æµ‹è¯•**
   - å½“å‰ç ”ç©¶åŸºäºè‹±æ–‡æ•°æ®é›†ï¼ŒæœªéªŒè¯åœ¨å¤šè¯­è¨€åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **å¼•å…¥åŠ¨æ€åå¥½é€‰æ‹©æœºåˆ¶**
   - æ ¹æ®éš¾åº¦è‡ªé€‚åº”ç­›é€‰ margin-based preference pairsï¼Œè¿›ä¸€æ­¥æå‡è®­ç»ƒæ•ˆç‡ã€‚

2. **æ¢ç´¢ self-improvement loop**
   - è®© PersoDPO æ¨¡å‹åå‘å‚ä¸åç»­è¯„ä¼°è¿‡ç¨‹ï¼Œå½¢æˆé—­ç¯è¿­ä»£ä¼˜åŒ–ã€‚

3. **æ‰©å±•è‡³å¤šæ¨¡æ€ persona grounding**
   - ç»“åˆå›¾åƒã€è¯­éŸ³ç­‰ä¿¡æ¯æ„å»ºæ›´ä¸°å¯Œçš„ç”¨æˆ·ç”»åƒã€‚

4. **å¼€å‘è½»é‡åŒ–æœ¬åœ°è¯„ä¼°å™¨**
   - æ›¿ä»£éƒ¨åˆ† API-based LLM judgeï¼Œé™ä½æˆæœ¬å¹¶ä¿æŠ¤éšç§ã€‚

5. **åº”ç”¨äº real-world user interaction åœºæ™¯**
   - åœ¨çœŸå®ç”¨æˆ·äº¤äº’ä¸­æ”¶é›† implicit feedbackï¼ˆå¦‚ç‚¹å‡»ã€åœç•™æ—¶é—´ï¼‰ï¼Œå®ç°æŒç»­åœ¨çº¿ä¼˜åŒ–ã€‚

---

> âœ… **ä»£ç ä¸èµ„æºå…¬å¼€**ï¼š  
> é¡¹ç›®å·²å¼€æºï¼ŒåŒ…å«å®Œæ•´å®ç°ã€è¯„ä¼°ç»“æœåŠåŸå§‹å“åº”æ—¥å¿—ï¼š  
> ğŸ”— https://github.com/salehafzoon/PersoDPO

</details>

---

### 7. [Less Finetuning, Better Retrieval: Rethinking LLM Adaptation for Biomedical Retrievers via Synthetic Data and Model Merging](https://arxiv.org/abs/2602.04731)

**Authors**: Sameh Khattab, Jean-Philippe Corbeil, Osman Alperen Kora\c{s}, Amin Dada, Julian Friedrich, Fran\c{c}ois Beaulieu, Paul Vozila, Jens Kleesiek  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.04731v1  

#### Abstract
Retrieval-augmented generation (RAG) has become the backbone of grounding Large Language Models (LLMs), improving knowledge updates and reducing hallucinations. Recently, LLM-based retriever models have shown state-of-the-art performance for RAG applications. However, several technical aspects remai...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Less Finetuning, Better Retrieval: Rethinking LLM Adaptation for Biomedical Retrievers via Synthetic Data and Model Merging*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰åœ¨å°†é€šç”¨ Large Language Models (LLMs) é€‚é…ä¸º**é¢†åŸŸä¸“ç”¨æ£€ç´¢å™¨**ï¼ˆå°¤å…¶æ˜¯ç”Ÿç‰©åŒ»å­¦é¢†åŸŸï¼‰æ—¶ï¼Œä¸»æµæ–¹æ³•ä¾èµ–å¤§è§„æ¨¡é¢„è®­ç»ƒï¼ˆpretrainingï¼‰å’Œå…¨é‡å¾®è°ƒï¼ˆfull fine-tuningï¼‰ï¼Œå­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **è®¡ç®—æˆæœ¬é«˜**ï¼šéœ€è¦å¤§é‡æ ‡æ³¨æˆ–ä¼ªæ ‡ç­¾æ•°æ®è¿›è¡ŒæŒç»­é¢„è®­ç»ƒã€‚
- **æ•°æ®æ•ˆç‡ä½**ï¼šæ˜¯å¦æ‰€æœ‰æ•°æ®éƒ½å¯¹æ€§èƒ½æå‡æœ‰è´¡çŒ®å°šä¸æ˜ç¡®ã€‚
- **ç¼ºä¹æ¨¡å—åŒ–è®¾è®¡**ï¼šéš¾ä»¥çµæ´»ç»„åˆä¸åŒä»»åŠ¡æˆ–é¢†åŸŸçš„ä¸“å®¶æ¨¡å‹ã€‚

è¯¥è®ºæ–‡èšç„¦äºå¦‚ä½•æ›´é«˜æ•ˆã€æ›´å°‘å¾®è°ƒåœ°æ„å»ºé«˜æ€§èƒ½çš„**ç”Ÿç‰©åŒ»å­¦å¯†é›†æ£€ç´¢å™¨**ï¼ˆdense retrieverï¼‰ï¼ŒåŒæ—¶ä¿æŒå…¶åœ¨é€šç”¨é¢†åŸŸçš„æ³›åŒ–èƒ½åŠ›ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡º **STM (Synthesize-Train-Merge)** æ¡†æ¶ï¼Œä¸€ä¸ª**æ¨¡å—åŒ–ã€é«˜æ•ˆä¸”å¯æ‰©å±•**çš„ LLM é€‚é…æ–¹æ¡ˆï¼ŒåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

1. **Synthetic Data Generation**
   - **Synthetic Hard Negatives (SHN)**ï¼šåˆ©ç”¨ GPT-4.1 ç”Ÿæˆè¯­ä¹‰ä¸Šç›¸å…³ä½†ä¸æŸ¥è¯¢æ— å…³çš„â€œç¡¬è´Ÿä¾‹â€ï¼Œæé«˜å¯¹æ¯”å­¦ä¹ è´¨é‡ã€‚
   - **Prompt Optimization**ï¼šä½¿ç”¨ GEPA å’Œéšæœºé‡‡æ ·ç­–ç•¥è‡ªåŠ¨ç”Ÿæˆå¹¶ä¼˜åŒ– retrieval promptsï¼Œæ¢ç´¢ prompt å¯¹åµŒå…¥ç©ºé—´çš„å½±å“ã€‚

2. **Expert Model Fine-tuning**
   - åœ¨ BMRetriever æ•°æ®é›†çš„ä¸åŒå­é›†ä¸Šåˆ†åˆ«è®­ç»ƒå¤šä¸ªâ€œä¸“å®¶â€æ¨¡å‹ï¼ˆå¦‚ Med-Synthã€Med-Realã€Searchã€NLUï¼‰ï¼Œæ¯ä¸ªä¸“å®¶ä¸“æ³¨äºç‰¹å®šæ•°æ®åˆ†å¸ƒæˆ–é…ç½®ï¼ˆå¦‚æ˜¯å¦ä½¿ç”¨ SHN æˆ–ä¼˜åŒ– promptï¼‰ã€‚

3. **Model Merging**
   - å°†å¤šä¸ªä¸“å®¶æ¨¡å‹é€šè¿‡å‚æ•°ç©ºé—´åˆå¹¶ï¼ˆå¦‚ Linear Interpolation å’Œ Ties-mergingï¼‰èåˆæˆå•ä¸€æ¨¡å‹ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´å°‘å¾®è°ƒï¼Œæ›´é«˜æ€§èƒ½**ï¼šä»…ç”¨ **1.4M è®­ç»ƒæ ·æœ¬**ï¼ˆç›¸æ¯” BMRetriever çš„ 11.4M å‡å°‘äº†çº¦ 90%ï¼‰ï¼Œä¸”è·³è¿‡é¢„è®­ç»ƒé˜¶æ®µï¼Œä»èƒ½å–å¾—æ›´ä¼˜ç»“æœã€‚
- **æ›´é«˜çš„æ•°æ®æ•ˆç‡**ï¼šé€šè¿‡åˆæˆæ•°æ®å¢å¼ºå’Œ prompt ä¼˜åŒ–ï¼Œä»¥æ›´å°çš„æ•°æ®è§„æ¨¡å®ç°æ›´å¼ºæ€§èƒ½ã€‚
- **æ¨¡å—åŒ–ä¸çµæ´»æ€§**ï¼šæ”¯æŒç‹¬ç«‹å¼€å‘ä¸“å®¶æ¨¡å‹ï¼Œå¹¶é€šè¿‡ merging ç»„åˆä¼˜åŠ¿ï¼Œä¾¿äºè¿­ä»£å’Œç»´æŠ¤ã€‚
- **æ›´å¼ºçš„ç»¼åˆæ€§èƒ½**ï¼šmerged æ¨¡å‹åœ¨åŒ»ç–—å’Œé€šç”¨ä»»åŠ¡ä¸Šå‡ä¼˜äºå•ä¸ªä¸“å®¶å’Œå¼º baselineã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- **BMRetriever æ•°æ®é›†**ï¼ˆXu et al., 2024ï¼‰ä½œä¸ºä¸»è¦ fine-tuning æ•°æ®æºï¼Œè¢«åˆ’åˆ†ä¸ºå››ä¸ªå­é›†ï¼š
  - **Med-Synth**ï¼ˆ431K pairsï¼‰ï¼šLLM ç”Ÿæˆçš„ç”Ÿç‰©åŒ»å­¦æ£€ç´¢å¯¹ã€‚
  - **Med-Real**ï¼ˆ306K pairsï¼‰ï¼šçœŸå®ç”Ÿç‰©åŒ»å­¦æ¨ç†ä¸é—®ç­”æ•°æ®ï¼ˆå¦‚ MedNLI, MEDIQAï¼‰ã€‚
  - **Search**ï¼ˆ438K pairsï¼‰ï¼šé€šç”¨æœç´¢ä»»åŠ¡æ•°æ®ï¼ˆå¦‚ MS MARCOï¼‰ã€‚
  - **NLU**ï¼ˆ251K pairsï¼‰ï¼šè‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡ï¼ˆå¦‚ SNLI, FEVER, ELI5ï¼‰ã€‚
- **è¯„ä¼°åŸºå‡†**ï¼šä» MTEB ä¸­é€‰å– **12 ä¸ªè‹±æ–‡ä»»åŠ¡å­é›†**ï¼ŒåŒ…æ‹¬ï¼š
  - åŒ»ç–—ä»»åŠ¡ï¼šTREC-COVID, SciFact, NFCorpus, CURE, PublicHealthQA, MedicalQA
  - é€šç”¨ä»»åŠ¡ï¼šFiQA, ArguAna, SciDocs, FEVER, Quora

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **Backbone Models**ï¼š
  - Qwen3 (0.6B)
  - Gemma (2B)
  - Phi4 mini instruct (3.8B)
- **è®­ç»ƒæ–¹å¼**ï¼š
  - ä½¿ç”¨ LoRA è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰
  - InfoNCE æŸå¤±å‡½æ•°ï¼Œç»“åˆ in-batch negatives å’Œ hard negatives
  - é‡‡ç”¨ EOS pooling å’ŒåŒå‘ attentionï¼ˆdisable causal maskï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - ä¸»è¦æŒ‡æ ‡ï¼š**nDCG@10**
  - æŠ¥å‘Šå¹³å‡å¾—åˆ†ï¼š`Avg Medical`, `Avg General`, `Avg All`

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å¯¹æ¯”äº†å¤šç§ä»£è¡¨æ€§æ£€ç´¢æ¨¡å‹ï¼š
| Model | Type | Size |
|-------|------|------|
| BM25 | Lexical | â€“ |
| Contriever | Dense | 150M |
| E5-v2 | Dense | 335M |
| GTR | Dense | 1.2B |
| BMRetriever | Biomedical | 2B |
| LLM2Vec | Generalist | 3B |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| Model | Avg All (nDCG@10) | Avg Medical | Avg General |
|-------|-------------------|-------------|--------------|
| **STMPhi4-Linear** | **0.646** | **0.677** | **0.603** |
| STMGemma-Linear | 0.622 | 0.654 | 0.577 |
| STMQwen3-Linear | 0.616 | 0.638 | 0.585 |
| BMRetriever (2B) | 0.609 | 0.645 | 0.560 |
| LLM2Vec (3B) | 0.619 | 0.635 | 0.597 |
| E5 Large V2 | 0.622 | 0.654 | 0.576 |

> âœ… **STMPhi4-Linear åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡è¾¾åˆ° SOTA æ€§èƒ½**ï¼Œæ˜¾è‘—è¶…è¶ŠåŒçº§åˆ«åŠæ›´å¤§è§„æ¨¡çš„ baselineã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- æ‰€æœ‰ STM merged æ¨¡å‹å‡**å…¨é¢è¶…è¶Š**å¯¹åº”çš„ fully fine-tuned å•ä¸€æ¨¡å‹ï¼ˆè§ Figure 2ï¼‰ã€‚
- å³ä½¿æ˜¯è¾ƒå°çš„ **Qwen3-0.6B** æ„å»ºçš„ STM æ¨¡å‹ï¼Œæ€§èƒ½ä¹Ÿæ¥è¿‘ç”šè‡³è¶…è¿‡æ›´å¤§çš„ BMRetriever (2B) å’Œ LLM2Vec (3B)ã€‚
- **STMGemma-Linear** è™½ç„¶ä¸ BMRetriever å…±äº« backboneï¼Œä½†é€šè¿‡ merging å®ç°äº†æ›´å¼ºæ€§èƒ½ï¼Œè¯æ˜ merging æœ¬èº«å¸¦æ¥å¢ç›Šã€‚

### æ¶ˆèå®éªŒç»“æœ
#### (1) Prompt Optimization æ•ˆæœæ˜¾è‘—
- åœ¨ä¸“å®¶å±‚é¢ï¼Œåº”ç”¨æœ€ä¼˜ prompt optimizationï¼ˆPOï¼‰åï¼š
  - **Search ä¸“å®¶ï¼ˆPhi4ï¼‰æå‡é«˜è¾¾ +23.5%**
  - **NLU ä¸“å®¶ï¼ˆGemmaï¼‰æå‡ +17.9%**
- ç›¸æ¯”ä¹‹ä¸‹ï¼ŒSHN æå‡æœ‰é™ï¼Œä¸”åœ¨å¤§æ¨¡å‹ä¸­å¯èƒ½æŸå®³ Med-Real æ€§èƒ½ï¼ˆå› å·²æœ‰é«˜è´¨é‡è´Ÿä¾‹ï¼‰ã€‚
- **PO æ˜¯æ›´é²æ£’æœ‰æ•ˆçš„ç­–ç•¥**ï¼Œå°¤å…¶å¯¹é€šç”¨åŸŸä»»åŠ¡ã€‚

#### (2) Model Merging æ˜¾è‘—ä¼˜äºå•ä¸“å®¶å’Œè”åˆå¾®è°ƒ
- Linear merging è¡¨ç°ç•¥ä¼˜äº Ties-mergingã€‚
- æ‰€æœ‰ merged æ¨¡å‹å‡ä¼˜äºæœ€å¼ºçš„å•ä¸ªä¸“å®¶ï¼ˆå¦‚ FT-allï¼‰ã€‚
- ä¾‹å¦‚ï¼ŒSTMPhi4-Linear è¾¾åˆ° 0.646ï¼Œè€Œæœ€å¼ºå•ä¸“å®¶ FT-all_sHN ä»…ä¸º 0.629ã€‚

#### (3) æ›´å°‘æ•°æ®å³å¯è¾¾åˆ°æ›´å¥½æ€§èƒ½
- å›¾ 4 æ˜¾ç¤ºï¼šå½“è®­ç»ƒæ•°æ®é‡è¾¾åˆ° **~100K** æ—¶ï¼Œæ€§èƒ½å·²è¶‹äºé¥±å’Œï¼Œç”šè‡³**è¶…è¿‡ä½¿ç”¨å®Œæ•´ 1.4M æ•°æ®çš„æ•ˆæœ**ã€‚
- ç»“åˆ merging å¯è¿›ä¸€æ­¥å‡å°‘å®é™…ä½¿ç”¨çš„æ•°æ®é‡ï¼ˆæœ€å¤šå‡å°‘ 29%ï¼‰ã€‚

#### (4) ä¸éœ€è¦é¢„è®­ç»ƒ
- å›¾ 3 æ˜¾ç¤ºï¼šä»… fine-tune 1.4M æ•°æ®çš„è¡¨ç° **ä¼˜äº pretrain + fine-tune çš„ 11.4M æ•°æ®**ã€‚
- å› æ­¤ STM å®Œå…¨çœå»äº†æ˜‚è´µçš„ pretraining é˜¶æ®µã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Prompt Optimization æ˜¯å¼ºå¤§çš„è½»é‡çº§é€‚é…æ‰‹æ®µ**ï¼šé€šè¿‡è‡ªåŠ¨ä¼˜åŒ– retrieval prompt å¯æ˜¾è‘—æå‡æ¨¡å‹è¡¨ç°ï¼Œå°¤å…¶åœ¨é€šç”¨ä»»åŠ¡ä¸Šæ•ˆæœæƒŠäººï¼ˆ+23.5%ï¼‰ã€‚
2. **Model Merging æ˜¯é«˜æ•ˆçš„æ¨¡å‹é›†æˆè·¯å¾„**ï¼šç®€å•åŠ æƒåˆå¹¶å¤šä¸ªä¸“å®¶æ¨¡å‹å³å¯è·å¾—ä¼˜äºå…¨é‡å¾®è°ƒçš„æ€§èƒ½ï¼ŒéªŒè¯äº† â€œmerge > fine-tuneâ€ çš„å¯è¡Œæ€§ã€‚
3. **æ›´å°‘å¾®è°ƒå¯ä»¥å®ç°æ›´å¥½æ£€ç´¢**ï¼šSTM ä»…ä½¿ç”¨ 1.4M æ•°æ®ã€æ—  pretrainingã€ä»…å¾®è°ƒéƒ¨åˆ†ä¸“å®¶ï¼Œæœ€ç»ˆ merged æ¨¡å‹ä»å¤§å¹…é¢†å…ˆã€‚
4. **åˆæˆæ•°æ®æœ‰æ•ˆä½†éœ€è°¨æ…ä½¿ç”¨**ï¼šGPT-4.1 ç”Ÿæˆçš„ synthetic hard negatives æœ‰ä¸€å®šå¸®åŠ©ï¼Œä½†ä¸å¦‚ prompt optimization ç¨³å®šï¼›ä¸”ä¸ PO ç»“åˆæ—¶å¯èƒ½å‡ºç°å¹²æ‰°ã€‚
5. **æ¨¡å—åŒ–è®¾è®¡å…·æœ‰å·¥ç¨‹ä¼˜åŠ¿**ï¼šæ”¯æŒç‹¬ç«‹å¼€å‘ã€æµ‹è¯•å’Œæ›¿æ¢ä¸“å®¶æ¨¡å‹ï¼Œé€‚åˆå¤šå›¢é˜Ÿåä½œå’ŒæŒç»­è¿­ä»£ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–å¤§å‹ LLM ç”Ÿæˆæ•°æ®å’Œ prompt**ï¼šä½¿ç”¨ GPT-4.1 å’Œ LLaMA-70B å¢åŠ äº†è®¡ç®—å¼€é”€å’Œå¯¹ç¬¬ä¸‰æ–¹æ¨¡å‹çš„ä¾èµ–ã€‚
2. **æœªè¯„ä¼°ç”Ÿæˆå™¨é²æ£’æ€§**ï¼šæœªæµ‹è¯•ä¸åŒ LLM æˆ– prompt å˜ä½“ä¸‹çš„ç¨³å®šæ€§ã€‚
3. **ä»…æ¢ç´¢ä¸¤ç§ merging ç­–ç•¥**ï¼šLinear å’Œ Ties-mergingï¼Œå°šæœªå¼•å…¥æ›´å¤æ‚çš„ adaptive merging æ–¹æ³•ã€‚
4. **æœªå¼€æºæ¨¡å‹å’Œæ•°æ®**ï¼šç›®å‰ä»£ç ã€æ•°æ®å’Œæ¨¡å‹è®¡åˆ’åœ¨æ¥æ”¶åå‘å¸ƒï¼Œé™åˆ¶äº†å¤ç°æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´ä½æˆæœ¬çš„ prompt generation å’Œ hard negative synthesis æ–¹æ³•ï¼ˆå¦‚ä½¿ç”¨å°å‹æ¨¡å‹è’¸é¦ï¼‰ã€‚
- å¼•å…¥åŠ¨æ€ merging æƒé‡æœºåˆ¶ï¼Œæ ¹æ®è¾“å…¥è‡ªåŠ¨é€‰æ‹©ä¸“å®¶ç»„åˆã€‚
- å°† STM æ¡†æ¶æ¨å¹¿è‡³å…¶ä»–å‚ç›´é¢†åŸŸï¼ˆå¦‚æ³•å¾‹ã€é‡‘èï¼‰ã€‚
- ç ”ç©¶å¦‚ä½•å°† merging ä¸ instruction tuning æ›´æ·±åº¦ç»“åˆï¼Œæ„å»ºâ€œå¤šåŠŸèƒ½åµŒå…¥æ¨¡å‹â€ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºçš„ **STM æ¡†æ¶**è¯æ˜äº†ï¼šé€šè¿‡ **synthetic data + prompt optimization + model merging** çš„ç»„åˆæ‹³ï¼Œå¯ä»¥åœ¨**æå°‘å¾®è°ƒ**çš„æƒ…å†µä¸‹ï¼Œæ„å»ºå‡ºæ€§èƒ½è¿œè¶…ä¼ ç»Ÿ fine-tuning æ–¹æ³•çš„**é«˜æ€§èƒ½ã€å¤šé¢†åŸŸå…¼å®¹çš„æ£€ç´¢å™¨**ï¼Œä¸º LLM çš„é«˜æ•ˆé€‚é…æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 8. [The Key to State Reduction in Linear Attention: A Rank-based Perspective](https://arxiv.org/abs/2602.04852)

**Authors**: Philipp Nazari, T. Konstantin Rusch  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.04852v1  

#### Abstract
Linear attention offers a computationally efficient yet expressive alternative to softmax attention. However, recent empirical results indicate that the state of trained linear attention models often exhibits a low-rank structure, suggesting that these models underexploit their capacity in practice....

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ã€ŠThe Key to State Reduction in Linear Attention: A Rank-based Perspectiveã€‹è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **Linear Attention** æ¨¡å‹åœ¨å®é™…è®­ç»ƒåè¡¨ç°å‡ºçš„ **ä½ç§©ï¼ˆlow-rankï¼‰çŠ¶æ€ç»“æ„** é—®é¢˜å±•å¼€ç ”ç©¶ã€‚å°½ç®¡ Linear Attention åœ¨è®¡ç®—æ•ˆç‡ä¸Šä¼˜äº Softmax Attentionï¼Œä½†å®è¯è¡¨æ˜å…¶éšè—çŠ¶æ€ï¼ˆassociative memoryï¼‰å¹¶æœªå……åˆ†åˆ©ç”¨å…¶å…¨éƒ¨å®¹é‡ï¼Œå¯¼è‡´æ¨¡å‹å¯¹æŸ¥è¯¢å™ªå£°æ•æ„Ÿï¼Œå¹¶å¯èƒ½å½±å“æ£€ç´¢æ€§èƒ½ã€‚

ä½œè€…æŒ‡å‡ºï¼Œè¿™ç§ä½ç§©ç°è±¡æœ¬è´¨ä¸Šæ˜¯ **å†…å­˜åˆ©ç”¨ä¸å‡ï¼ˆmemory isotropyï¼‰** çš„ä½“ç°ï¼Œå³ä¿¡æ¯é›†ä¸­åœ¨å°‘æ•°ä¸»æˆåˆ†ä¸Šï¼Œè€Œå¤§éƒ¨åˆ†ç»´åº¦å†—ä½™ã€‚è¿™ä¸ä»…æµªè´¹äº†è®¡ç®—èµ„æºï¼Œä¹Ÿé™åˆ¶äº†æ¨¡å‹çš„é²æ£’æ€§å’Œè¡¨è¾¾èƒ½åŠ›ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œè®ºæ–‡æå‡ºäº†ä¸€å¥— **ç¡¬ä»¶æ„ŸçŸ¥çš„ç»“æ„åŒ–å‰ªææ¡†æ¶ï¼ˆhardware-aware structured pruning frameworkï¼‰**ï¼Œç”¨äºåœ¨ **è®­ç»ƒåï¼ˆpost-trainingï¼‰** å‡å°‘ Linear Attention æ¨¡å‹çš„çŠ¶æ€å¤§å°ã€‚å…¶æ ¸å¿ƒæ€æƒ³åŸºäºä»¥ä¸‹ä¸¤ä¸ªå…³é”®æ´å¯Ÿï¼š

1. **æ­£äº¤ä¸å˜æ€§ï¼ˆOrthogonal Invarianceï¼‰**ï¼š  
   Linear Attentionï¼ˆç‰¹åˆ«æ˜¯ DeltaNet åŠå…¶å˜ä½“ï¼‰å¯¹åŒæ—¶æ–½åŠ äº **query å’Œ key** ä¸Šçš„æ­£äº¤å˜æ¢å…·æœ‰ä¸å˜æ€§ã€‚è¿™æ„å‘³ç€å¯ä»¥åœ¨ä¸æ”¹å˜æ¨¡å‹åŠŸèƒ½çš„å‰æä¸‹ï¼Œå¯¹ key å’Œ query ç©ºé—´è¿›è¡Œè”åˆå˜æ¢ã€‚

2. **ç»“æ„åŒ–å‰ªæä¼˜äºéç»“æ„åŒ–å‰ªæ**ï¼š  
   ä¸ä»…äº§ç”Ÿç¨€ç–æƒé‡çš„éç»“æ„åŒ–å‰ªæä¸åŒï¼Œæœ¬æ–‡é‡‡ç”¨ **è½´å¯¹é½çš„ç»“æ„åŒ–å‰ªæï¼ˆaxis-aligned structured pruningï¼‰**ï¼Œç›´æ¥ç§»é™¤ key å’Œ query çš„æŸäº›é€šé“ï¼ˆchannelsï¼‰ï¼Œä»è€Œ **å®è´¨æ€§åœ°é™ä½çŠ¶æ€ç»´åº¦ $d_k$**ï¼Œå¸¦æ¥çœŸæ­£çš„ FLOPs å’Œå†…å­˜å‡å°‘ã€‚

åœ¨æ­¤åŸºç¡€ä¸Šï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„å‰ªæç®—æ³•ï¼š

- **DRRQRï¼ˆDeep Rank Revealing QR Decompositionï¼‰**ï¼š  
  åŸºäº **å¼ºç§©æ­ç¤º QR åˆ†è§£ï¼ˆStrong Rank Revealing QR, RRQRï¼‰**ï¼Œä»æ¿€æ´»ç»Ÿè®¡çŸ©é˜µ $[K, Q]$ ä¸­é€‰æ‹©ä¸€ç»„èƒ½å½¢æˆè‰¯å¥½æ¡ä»¶å­ç©ºé—´çš„åˆ—ï¼ˆå³é€šé“ï¼‰ã€‚è¯¥æ–¹æ³•æ˜¾å¼ä¼˜åŒ– **æœ‰æ•ˆç§©ï¼ˆeffective rankï¼‰** å’Œ **ç§©åˆ©ç”¨ç‡ï¼ˆrank utilizationï¼‰**ï¼Œæ—¨åœ¨æå‡å‰©ä½™å†…å­˜çš„å„å‘åŒæ€§ï¼Œè€Œéç®€å•ä¿ç•™æœ€å¤§æ–¹å·®æ–¹å‘ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | æœ¬æ–‡æ–¹æ³• | SliceGPT / SpinQuant / QuaRot |
|---------|--------|-------------------------------|
| **ä½œç”¨ç©ºé—´** | **State Space**ï¼ˆç›´æ¥å‹ç¼© key/query ç»´åº¦ï¼‰ | **Residual Stream**ï¼ˆæ—‹è½¬åµŒå…¥ç©ºé—´ï¼‰ |
| **å…¼å®¹æ€§** | ä¿æŒä¸ç°æœ‰ CUDA kernels å…¼å®¹ | éœ€è¦ç‰¹å®šé‡åŒ– kernel æ”¯æŒ |
| **ç›®æ ‡** | æ˜¾å¼æå‡ç§©åˆ©ç”¨ç‡ï¼Œæ”¹å–„å™ªå£°é²æ£’æ€§ | ä¸»è¦ç›®æ ‡æ˜¯é‡åŒ–å‹å¥½æˆ–å‹ç¼©åµŒå…¥ç»´åº¦ |
| **äº’è¡¥æ€§** | âœ… å¯ä¸å…¶ä»–æ–¹æ³•ç»“åˆä½¿ç”¨ | âŒ |

å› æ­¤ï¼Œæœ¬æ–‡æ–¹æ³•æ˜¯ **äº’è¡¥ä¸”å¯å åŠ ** çš„ï¼Œå°¤å…¶é€‚åˆéƒ¨ç½²åœºæ™¯ä¸‹çš„é«˜æ•ˆæ¨ç†ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **é¢„è®­ç»ƒæ•°æ®**ï¼š`Fineweb-Edu`ï¼ˆ10B tokensï¼‰
- **æ ¡å‡†é›†ï¼ˆCalibration Setï¼‰**ï¼š128 ä¸ª `Fineweb-Edu` æ ·æœ¬ï¼ˆç”¨äºå‰ªæå‰çš„ç‰¹å¾ç»Ÿè®¡ï¼‰
- **è¯„ä¼°ä»»åŠ¡**ï¼š
  - **è¯­è¨€å»ºæ¨¡**ï¼š`Wikitext-2`, `Lambada`
  - **é›¶æ ·æœ¬ç”Ÿæˆ**ï¼š`ARC-e`, `ARC-c`, `HellaSwag`, `Winogrande`, `PIQA`, `LAMBADA`ï¼ˆé€šè¿‡ `lm-eval-harness`ï¼‰
  - **çœŸå®ä¸–ç•Œæ£€ç´¢**ï¼š`Drop`, `FDA`, `NQ`, `SQuAD`, `SWDE`, `TriviaQA`ï¼ˆä½¿ç”¨ prefix-linear-attention åè®®ï¼‰

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼š`DeltaNet` å’Œ `Gated DeltaNet`
- **æ¨¡å‹è§„æ¨¡**ï¼š370M, 1.3B, 2.7B å‚æ•°
- **å‰ªææ¯”ä¾‹**ï¼š30%, 40%, 50%, 75%
- **æ¢å¤å¾®è°ƒï¼ˆRecovery Fine-Tuning, RFTï¼‰**ï¼šä½¿ç”¨ LoRAï¼ˆrank=16/32ï¼‰åœ¨å•å¼  H100 ä¸Šè¿›è¡Œ
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA H100 GPU
- **æ‰¹å¤§å°**ï¼š32ï¼ˆåºåˆ—æ··åˆå™¨ååæµ‹è¯•ï¼‰ï¼Œ16ï¼ˆRFTï¼‰

### è¯„ä¼°æŒ‡æ ‡
- **Perplexity**ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ï¼šWikitext-2, Lambada
- **Accuracy (%)**ï¼šå„é¡¹é›¶æ ·æœ¬ä¸æ£€ç´¢ä»»åŠ¡
- **ååé‡ï¼ˆTokens Per Second, TPSï¼‰**
- **å³°å€¼ VRAM ä½¿ç”¨é‡**
- **ç§©åˆ©ç”¨ç‡ï¼ˆRank Utilizationï¼‰**

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æè¿° |
|------|------|------|
| **L1** | åŸºçº¿ | åŸºäº query/key æŠ•å½±çŸ©é˜µ L1 èŒƒæ•°çš„å¹…åº¦å‰ªæ |
| **Random (Rand)** | åŸºçº¿ | éšæœºé€‰æ‹©é€šé“ |
| **S-Wanda** | æ”¹è¿› | ç»“åˆè¾“å…¥æ¿€æ´»èŒƒæ•°çš„ Wanda æ–¹æ³•é€‚é…ç‰ˆ |
| **Grad** | ä¼˜åŒ–æ³• | åŸºäºæ¢¯åº¦æ˜¾è‘—æ€§çš„å‰ªæï¼ˆtask-awareï¼‰ |
| **DRRQR** | **æœ¬æ–‡æå‡º** | åŸºäºç§©æ­ç¤º QR çš„ç»“æ„åŒ–å‰ªæ |
| **PCA** | å¯¹æ¯” | ä¸»æˆåˆ†åˆ†æï¼ˆç†è®ºä¸Šæœ€ä¼˜ä½†å®è·µä¸­å› å·ç§¯ä¸å…¼å®¹è€Œè¡¨ç°å·®ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### è¯­è¨€å»ºæ¨¡æ€§èƒ½ï¼ˆPost-RFT, 50% Compressionï¼‰
| Model | Method | Wiki PPL â†“ | Lambada PPL â†“ |
|-------|--------|------------|----------------|
| Gated DeltaNet 1.3B | **Grad** | **16.4** | **10.5** |
| Gated DeltaNet 1.3B | **DRRQR** | 16.3 | 12.0 |
| Gated DeltaNet 1.3B | S-Wanda | 16.6 | 11.7 |
| Gated DeltaNet 1.3B | L1 | 16.8 | 13.0 |
| Gated DeltaNet 1.3B | **Baseline** | 16.8 | 9.7 |

> âœ… **ä»…å¢åŠ çº¦ 0.3â€“0.7 ç‚¹å›°æƒ‘åº¦ï¼Œå³å¯å‹ç¼© 50% çš„ key/query é€šé“**

#### é›¶æ ·æœ¬å¹³å‡å‡†ç¡®ç‡ï¼ˆPost-RFT, 50% Compressionï¼‰
| Model | Method | ZS Avg â†‘ |
|-------|--------|----------|
| Gated DeltaNet 1.3B | **Grad** | **58.3** |
| Gated DeltaNet 1.3B | DRRQR | 58.0 |
| Gated DeltaNet 1.3B | S-Wanda | 57.8 |
| Gated DeltaNet 1.3B | L1 | 57.2 |
| Gated DeltaNet 1.3B | **Baseline** | 59.4 |

> âš ï¸ å¹³å‡ä¸‹é™çº¦ 1 ä¸ªç™¾åˆ†ç‚¹ï¼Œä½†ä»ä¿æŒè¾ƒå¼ºæ³›åŒ–èƒ½åŠ›

#### æ£€ç´¢ä»»åŠ¡å¹³å‡å‡†ç¡®ç‡ï¼ˆPost-RFT, 50% Compressionï¼‰
| Model | Method | Ret Avg â†‘ |
|-------|--------|-----------|
| Gated DeltaNet 1.3B | **Grad** | **34.3** |
| Gated DeltaNet 1.3B | DRRQR | 33.0 |
| Gated DeltaNet 1.3B | S-Wanda | 32.9 |
| Gated DeltaNet 1.3B | L1 | 32.1 |
| Gated DeltaNet 1.3B | **Baseline** | 40.3 |

> âš ï¸ æ£€ç´¢ä»»åŠ¡å¯¹å‹ç¼©æ›´æ•æ„Ÿï¼Œä½†åœ¨ 50% å‹ç¼©ä¸‹ä»ä¿ç•™çº¦ 85% æ€§èƒ½

#### ååé‡ä¸å†…å­˜èŠ‚çœï¼ˆDeltaNet, 50% Compressionï¼‰
| Model | $d_k$ | TPS | Speedup | VRAM | Ratio |
|-------|-------|-----|---------|-------|-------|
| DeltaNet | 128 | 8.1M | 1.00Ã— | 6.33 GiB | 1.00 |
| DeltaNet | 64 | 10.8M | **1.34Ã—** | 4.57 GiB | **0.72** |

> âœ… **é€Ÿåº¦æå‡ 34%ï¼Œå†…å­˜å‡å°‘ 28%**

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **DRRQR** å’Œ **Grad** åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­å‡æ˜¾è‘—ä¼˜äº **L1**, **Rand**, **S-Wanda**
- **DRRQR** ä½œä¸º **æ— æ¢¯åº¦ã€å±€éƒ¨ã€ä»»åŠ¡æ— å…³** çš„æ–¹æ³•ï¼Œæ€§èƒ½æ¥è¿‘ç”šè‡³è¶…è¿‡åŸºäºæ¢¯åº¦çš„ **Grad**
- **PCA-based pruning** è¡¨ç°æå·®ï¼ˆè§ Table 5ï¼‰ï¼ŒéªŒè¯äº†æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆdepthwise convolutionï¼‰ç ´åäº†å…¶æœ‰æ•ˆæ€§
- æ‰€æœ‰æ–¹æ³•åœ¨ **50% å‹ç¼©æ¯”** ä¸‹å‡èƒ½ä¿æŒæ¥è¿‘åŸå§‹æ¨¡å‹çš„æ€§èƒ½

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰è€¦åˆé€‰æ‹©æ¶ˆèï¼ˆCoupled Selectionï¼‰
| æ–¹æ³• | é€‰æ‹©ç­–ç•¥ | Wiki PPL (370M) |
|------|----------|----------------|
| L1 | Keys Only | 425218.3 |
| L1 | Queries Only | 33.0 |
| L1 | **Keys & Queries** | 3843.5 |
| DRRQR | Keys Only | 286035.7 |
| DRRQR | Queries Only | 35.7 |
| DRRQR | **Keys & Queries** | **32.1** |
| Grad | Keys Only | 17709.6 |
| Grad | Queries Only | 31.9 |
| Grad | **Keys & Queries** | **18.3** |

> ğŸ” **å…³é”®å‘ç°**ï¼š  
> - å¹…åº¦ç±»æ–¹æ³•ï¼ˆL1, S-Wandaï¼‰åœ¨ä»…ä½¿ç”¨ **queries** æ—¶è¡¨ç°æœ€å¥½ï¼ˆå›  queries æ§åˆ¶è¯»å–ï¼‰  
> - ä¼˜åŒ–ç±»æ–¹æ³•ï¼ˆGrad, DRRQRï¼‰å¿…é¡»è”åˆé€‰æ‹© **keys & queries** æ‰èƒ½è¾¾åˆ°æœ€ä½³æ•ˆæœï¼Œè¯´æ˜å®ƒä»¬æ•æ‰åˆ°äº†è¯»å†™äº¤äº’æœºåˆ¶

#### ï¼ˆ2ï¼‰ç§©åˆ©ç”¨ç‡å¯è§†åŒ–ï¼ˆFigure 2ï¼‰
- åœ¨ç›¸åŒæœ€å¤§å®¹é‡ä¸‹ï¼Œ**Grad** å’Œ **DRRQR** å‰ªæåçš„æ¨¡å‹å…·æœ‰æœ€é«˜çš„ **rank utilization**
- è¯æ˜æ‰€ææ–¹æ³•ç¡®å®æå‡äº†å†…å­˜çš„å„å‘åŒæ€§

#### ï¼ˆ3ï¼‰å¥‡å¼‚å€¼è°±åˆ†æï¼ˆFigure 3 & 4ï¼‰
- åŸå§‹æ¨¡å‹å­˜åœ¨é•¿å°¾å°å¥‡å¼‚å€¼ï¼ˆæ¥è¿‘é›¶ï¼‰ï¼Œè¡¨æ˜å¤§é‡ç»´åº¦å†—ä½™
- å‰ªæåæ¨¡å‹çš„è°±æ›´ç´§å‡‘ï¼Œä¸” RFT è¿‡ç¨‹ä¼šè½»å¾®â€œè½¯åŒ–â€æˆªæ–­æ•ˆåº”

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **Linear Attention å­˜åœ¨ä¸¥é‡çš„ä½ç§©çŠ¶æ€é—®é¢˜**ï¼Œå¯¼è‡´å†…å­˜åˆ©ç”¨ç‡ä½ä¸‹ã€‚
2. âœ… **ä½ç§©ç»“æ„ä¼šæ”¾å¤§æŸ¥è¯¢å™ªå£°**ï¼Œå½±å“æ£€ç´¢å‡†ç¡®æ€§ï¼ˆç†è®ºè¯æ˜è§ Theorem 2.5ï¼‰ã€‚
3. âœ… **å¯é€šè¿‡ç»“æ„åŒ–å‰ªæå®‰å…¨ç§»é™¤çº¦ 50% çš„ key/query é€šé“**ï¼Œä»…å¸¦æ¥è½»å¾®æ€§èƒ½ä¸‹é™ã€‚
4. âœ… **DRRQR æ˜¯ä¸€ç§æ— éœ€æ¢¯åº¦ã€å¯è§£é‡Šã€ä¸”æ€§èƒ½ä¼˜å¼‚çš„å‰ªææ–¹æ³•**ï¼Œé€šè¿‡æ˜¾å¼ä¼˜åŒ–ç§©åˆ©ç”¨ç‡å®ç°é«˜æ•ˆå‹ç¼©ã€‚
5. âœ… **æœ¬æ–‡æ¡†æ¶ä¸ SliceGPTã€SpinQuant ç­‰æ–¹æ³•äº’è¡¥**ï¼Œå¯åœ¨ä¸åŒå±‚é¢ååŒä¼˜åŒ–ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å¯¹æ£€ç´¢å¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚ SWDE, FDAï¼‰æ€§èƒ½ä¸‹é™è¾ƒæ˜æ˜¾**ï¼Œå°¤å…¶æ˜¯åœ¨é«˜å‹ç¼©æ¯”ä¸‹ã€‚
- **ä¾èµ–äº depthwise convolution çš„ç»“æ„å‡è®¾**ï¼Œè‹¥æ¨¡å‹ä½¿ç”¨å…±äº«å·ç§¯æˆ–å…¶ä»–ç»“æ„éœ€é¢å¤–é€‚é…ï¼ˆè§ Appendix B.6ï¼‰ã€‚
- **ç›®å‰ä»…é€‚ç”¨äº Linear Attention æ¶æ„**ï¼Œå°šæœªæ‰©å±•è‡³æ ‡å‡† Transformerã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°†è¯¥æ¡†æ¶åº”ç”¨äº **Hybrid Models**ï¼ˆå¦‚ Mamba + Attentionï¼‰ï¼Œåˆ©ç”¨å°‘é‡ Softmax Attention å±‚ç¼“è§£æ£€ç´¢æ€§èƒ½æŸå¤±ã€‚
- æ¢ç´¢ **åŠ¨æ€é€šé“é€‰æ‹©æœºåˆ¶**ï¼Œåœ¨æ¨ç†æ—¶æ ¹æ®è¾“å…¥è‡ªé€‚åº”è°ƒæ•´æ´»è·ƒé€šé“ã€‚
- ç»“åˆ **é‡åŒ–ï¼ˆquantizationï¼‰** ä¸ **ç»“æ„åŒ–å‰ªæ**ï¼Œè¿›ä¸€æ­¥æå‡ç«¯ä¾§éƒ¨ç½²æ•ˆç‡ã€‚
- ç ”ç©¶å¦‚ä½•å°† **DRRQR** æ€æƒ³èå…¥ **è®­ç»ƒè¿‡ç¨‹**ï¼Œå¼•å¯¼æ¨¡å‹å­¦ä¹ æ›´é«˜ç§©åˆ©ç”¨ç‡çš„è¡¨ç¤ºã€‚

--- 

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬æ–‡ä» **ç§©åˆ©ç”¨ç‡** è§†è§’æ­ç¤ºäº† Linear Attention çš„çŠ¶æ€å†—ä½™æœ¬è´¨ï¼Œå¹¶æå‡º **DRRQR** ç»“æ„åŒ–å‰ªææ–¹æ³•ï¼Œåœ¨ä»…è½»å¾®ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹å®ç°äº†é«˜è¾¾ 50% çš„çŠ¶æ€å‹ç¼©ä¸ 34% çš„åŠ é€Ÿï¼Œä¸ºé«˜æ•ˆéƒ¨ç½²æä¾›äº†æ–°è·¯å¾„ã€‚

</details>

---

### 9. [CoRe: Context-Robust Remasking for Diffusion Language Models](https://arxiv.org/abs/2602.04096)

**Authors**: Kevin Zhai, Sabbir Mollah, Zhenyi Wang, Mubarak Shah  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.04096v1  

#### Abstract
Standard decoding in Masked Diffusion Models (MDMs) is hindered by context rigidity: tokens are retained based on transient high confidence, often ignoring that early predictions lack full context. This creates cascade effects where initial inconsistencies misguide the remaining generation. Existing...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šCoRe: Context-Robust Remasking for Diffusion Language Models**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### âœ… **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
æ ‡å‡†çš„ **Masked Diffusion Models (MDMs)** åœ¨æ¨ç†è¿‡ç¨‹ä¸­å­˜åœ¨**ä¸Šä¸‹æ–‡åˆšæ€§ï¼ˆcontext rigidityï¼‰**é—®é¢˜ï¼š  
- æ—©æœŸç”Ÿæˆçš„ token æ˜¯åœ¨ä¸å®Œæ•´ã€æ¨¡ç³Šçš„ä¸Šä¸‹æ–‡ä¸­é¢„æµ‹çš„ï¼Œä¸€æ—¦è¢«â€œè§£æ©ç â€ï¼ˆunmaskedï¼‰ï¼Œé€šå¸¸è¢«è§†ä¸ºå›ºå®šä¸å˜çš„é”šç‚¹ã€‚
- å³ä½¿åç»­ä¸Šä¸‹æ–‡æ¼”åŒ–åè¯¥ token å·²ä¸å†åˆç†ï¼Œæ¨¡å‹ä¹Ÿæ— æ³•ä¿®æ­£ï¼Œå¯¼è‡´é”™è¯¯çº§è”ï¼ˆcascade effectsï¼‰ï¼Œå°¤å…¶åœ¨ç»“æ„æ•æ„Ÿä»»åŠ¡ï¼ˆå¦‚ä»£ç ç”Ÿæˆï¼‰ä¸­ä¸¥é‡å½±å“è¾“å‡ºè´¨é‡ã€‚

ç°æœ‰åŸºäº**é™æ€ç½®ä¿¡åº¦**ï¼ˆå¦‚ä½æ¦‚ç‡ã€top-k marginï¼‰çš„ä¿®è®¢ç­–ç•¥ï¼ˆå¦‚ ReMDMï¼‰ä¹Ÿå­˜åœ¨é—®é¢˜ï¼š
- å®ƒä»¬ä¾èµ–äº token è¢«é¦–æ¬¡é‡‡æ ·æ—¶çš„ç½®ä¿¡åˆ†æ•°ï¼Œè¿™äº›ä¿¡å·ä¼šå˜å¾—â€œè¿‡æ—¶â€ï¼ˆstaleï¼‰ï¼Œæ— æ³•åæ˜ å½“å‰ä¸Šä¸‹æ–‡ä¸‹çš„åˆç†æ€§ã€‚
- é«˜ç½®ä¿¡åº¦çš„ token å¯èƒ½å·²ä¸å½“å‰è¯­å¢ƒå†²çªï¼Œä½†ä»ä¸ä¼šè¢«é‡æ–°è¯„ä¼°ã€‚

---

### âœ… **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æå‡º **Context-Robust Remasking (CoRE)** â€”â€”ä¸€ç§æ— éœ€è®­ç»ƒã€åœ¨æ¨ç†é˜¶æ®µè¿›è¡ŒåŠ¨æ€ä¿®è®¢çš„æ¡†æ¶ã€‚

#### æ ¸å¿ƒæ€æƒ³ï¼š
> ä¸å†é—®ï¼šâ€œè¿™ä¸ª token å½“åˆæ˜¯å¦ä¸ç¡®å®šï¼Ÿâ€  
> è€Œæ˜¯é—®ï¼šâ€œ**å¦‚æœéƒ¨åˆ†ä¸Šä¸‹æ–‡è¢«é®è”½ï¼Œå®ƒæ˜¯å¦ä»ç„¶è¢«å¼ºçƒˆæ”¯æŒï¼Ÿ**â€

#### åˆ›æ–°æœºåˆ¶ï¼š
- **å°†ä¿®è®¢å»ºæ¨¡ä¸ºé²æ£’ä¼˜åŒ–é—®é¢˜ï¼ˆrobust optimizationï¼‰**ï¼šå¯»æ‰¾åœ¨æœ€åæƒ…å†µä¸Šä¸‹æ–‡æ‰°åŠ¨ä¸‹ä»ä¸ç¨³å®šçš„ tokenã€‚
- **è½»é‡çº§å‹åŠ›æµ‹è¯•ï¼ˆlightweight stress testï¼‰**ï¼š
  - åœ¨æ¯ä¸€æ­¥é€‰æ‹©ä¸€ç»„å€™é€‰ tokenï¼ˆé€šè¿‡ top-2 margin ç­›é€‰ï¼‰ã€‚
  - åŒæ—¶å°†å…¶å‘¨å›´ä¸Šä¸‹æ–‡ä¸­çš„è‹¥å¹²ä½ç½®é‡æ–°æ©ç ï¼Œå½¢æˆä¸€ä¸ªâ€œæ‰°åŠ¨ä¸Šä¸‹æ–‡â€ $ \tilde{y}^{(t)} $ã€‚
  - è®¡ç®—æ¯ä¸ªå€™é€‰ token åœ¨æ­¤æ‰°åŠ¨ä¸‹çš„**ä¸ç¨³å®šæ€§å¾—åˆ†ï¼ˆinstability scoreï¼‰**ï¼š  
    $$
    l_i = -\log p_\theta(y_i | \tilde{y}^{(t)})
    $$
  - å¾—åˆ†è¶Šé«˜ï¼Œè¯´æ˜è¯¥ token å¯¹ä¸Šä¸‹æ–‡å˜åŒ–è¶Šæ•æ„Ÿï¼ˆå³â€œè„†å¼±â€ï¼‰ï¼Œåº”ä¼˜å…ˆä¿®è®¢ã€‚

#### ä¿®è®¢æ“ä½œï¼š
- å°†å¾—åˆ†æœ€é«˜çš„ $ k_{\text{rm}} $ ä¸ª token ç”¨å…¶åœ¨æ‰°åŠ¨ä¸Šä¸‹æ–‡ä¸‹çš„æœ€å¤§ä¼¼ç„¶é¢„æµ‹æ›¿æ¢ã€‚
- æ•´ä¸ªè¿‡ç¨‹ä»…éœ€ä¸€æ¬¡é¢å¤–å‰å‘ä¼ æ’­ï¼Œå¼€é”€æå°ã€‚

---

### âœ… **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | CoRE | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ ReMDM-confï¼‰ |
|------|------|--------------------------|
| **ä¿¡å·æ¥æº** | åŠ¨æ€é‡è¯„ä¼°å½“å‰ä¸Šä¸‹æ–‡ä¸‹çš„ç¨³å®šæ€§ | ä¾èµ–å†å²ç½®ä¿¡åº¦ï¼ˆæ˜“è¿‡æ—¶ï¼‰ |
| **ä¿®è®¢ä¾æ®** | ä¸Šä¸‹æ–‡é²æ£’æ€§ï¼ˆrobustnessï¼‰ | å±€éƒ¨ä¸ç¡®å®šæ€§ï¼ˆuncertaintyï¼‰ |
| **é€‚ç”¨åœºæ™¯** | ç‰¹åˆ«é€‚åˆç»“æ„å¼ºçº¦æŸä»»åŠ¡ï¼ˆå¦‚ä»£ç ï¼‰ | æ˜“è¯¯åˆ¤é«˜ç½®ä¿¡é”™è¯¯ |
| **æ˜¯å¦éœ€è®­ç»ƒ** | âŒ æ— éœ€è®­ç»ƒï¼ˆtraining-freeï¼‰ | âŒ ä¹Ÿä¸éœ€è¦ï¼ˆä½†æ•ˆæœå·®ï¼‰ |
| **è®¡ç®—æ•ˆç‡** | ä»…å¢åŠ çº¦ 6% NFEï¼ˆNetwork Function Evaluationsï¼‰ | ç±»ä¼¼å¼€é”€ä½†æ”¶ç›Šæ›´ä½ç”šè‡³è´Ÿå‘ |

> ğŸ”¥ **å…³é”®ä¼˜åŠ¿**ï¼šCoRE èƒ½è¯†åˆ«å‡ºé‚£äº›â€œå½“åˆçœ‹èµ·æ¥å¾ˆå¯¹ï¼Œä½†ç°åœ¨å·²ä¸åˆæ—¶å®œâ€çš„ tokenï¼Œå¹¶ä¸»åŠ¨ä¿®æ­£ï¼Œæ‰“ç ´ä¸Šä¸‹æ–‡åˆšæ€§ã€‚

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### ğŸ“š **ä½¿ç”¨çš„æ•°æ®é›†**
- **ä»£ç ç”Ÿæˆ**ï¼š
  - **HumanEval**ï¼šå‡½æ•°çº§ä»£ç ç”Ÿæˆï¼Œè¯„ä¼° pass@1 å‡†ç¡®ç‡ã€‚
  - **MBPP (Mostly Basic Python Problems)**ï¼šåŸºç¡€ç¼–ç¨‹é¢˜ï¼Œgreedy pass@1ã€‚
- **æ•°å­¦æ¨ç†**ï¼š
  - **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼Œä¸¥æ ¼åŒ¹é…å‡†ç¡®ç‡ã€‚
  - **MATH**ï¼šå¤æ‚æ•°å­¦é—®é¢˜ï¼Œé‡‡ç”¨ rule-based answer equivalenceã€‚
- **é€šç”¨æ¨ç†**ï¼š
  - **BBH (Big-Bench Hard)**ï¼šæŒ‘æˆ˜æ€§å°‘æ ·æœ¬æ¨ç†ä»»åŠ¡ï¼Œexact matchã€‚

---

### âš™ï¸ **å®éªŒè®¾ç½®**
- **æ¨¡å‹**ï¼šLLaDA-Base-8Bï¼ˆåŸºäº diffusion çš„å¤§è¯­è¨€æ¨¡å‹ï¼‰
- **æ‰©æ•£æ­¥æ•°**ï¼š$ N = 128 $
- **ç”Ÿæˆé•¿åº¦**ï¼š$ L = 512 $
- **è§£ç æ–¹å¼**ï¼šgreedy decodingï¼ˆé¿å… temperature å¼•å…¥æ–¹å·®å¹²æ‰°ç»“æ„ä¸€è‡´æ€§åˆ†æï¼‰
- **ä¿®è®¢é¢‘ç‡**ï¼šæ¯ $ E=8 $ æ­¥æ‰§è¡Œä¸€æ¬¡ä¿®è®¢
- **ä¿®è®¢çª—å£**ï¼šä¸­é—´é˜¶æ®µ $ t/N \in [0.25, 0.75] $
- **å€™é€‰é›†å¤§å°**ï¼š$ m = 32 $
- **æ¯æ¬¡ä¿®è®¢æ•°é‡**ï¼š$ k_{\text{rm}} = 1 $

> ğŸ’¡ æ¯æ¬¡ä¿®è®¢å¼•å…¥ **1 æ¬¡é¢å¤–å‰å‘ä¼ æ’­**ï¼Œæ€»è®¡ç®—é¢„ç®—æ§åˆ¶ä¸º 136 æ¬¡å‰å‘ä¼ æ’­ç”¨äºå…¬å¹³æ¯”è¾ƒã€‚

---

### ğŸ†š **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | æè¿° |
|------|------|
| **Low-Confidence Base** | é»˜è®¤ LLaDA ç­–ç•¥ï¼Œä¼˜å…ˆ unmask ä½ç½®ä¿¡ token |
| **Top-k Margin Base** | è‡ªé€‚åº”ç­–ç•¥ï¼ŒåŸºäº top-2 æ¦‚ç‡å·®è·é€‰æ‹© unmask ä½ç½® |
| **+ ReMDM-conf [36]** | å½“å‰æœ€ä¼˜çš„ training-free ä¿®è®¢æ–¹æ³•ï¼ŒåŸºäºå†å²ç½®ä¿¡åº¦ remask |
| **+ Random Remask** | æ§åˆ¶ç»„ï¼šéšæœºé€‰æ‹©ä¿®è®¢ç›®æ ‡ |
| **+ Margin Remask** | æ§åˆ¶ç»„ï¼šé€‰æ‹© margin æœ€å°çš„ token è¿›è¡Œä¿®è®¢ |
| **+ CoRE (Ours)** | æœ¬æ–‡æ–¹æ³•ï¼šåŸºäºæ‰°åŠ¨ä¸Šä¸‹æ–‡ä¸‹çš„ä¸ç¨³å®šæ€§å¾—åˆ† |

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### ğŸ“Š **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰**

| Method | GSM8K (%) | BBH (%) | HumanEval (%) | MBPP (%) |
|--------|-----------|--------|----------------|----------|
| Low-Confidence Base | 51.40 | 45.81 | 12.20 | 15.60 |
| + ReMDM-conf | 52.31 | 46.05 | 10.98 | **15.20** â¬‡ï¸ |
| **+ CoRE (Ours)** | **52.69** | **47.18*** | **17.07*** | **24.80*** |
| Top-k Margin Base | 50.27 | 48.33 | 17.07 | 21.20 |
| + ReMDM-conf | 51.78 | 46.31 | 14.02 | **14.80** â¬‡ï¸ |
| **+ CoRE (Ours)** | 51.40 | **49.01*** | **22.56*** | **29.60*** |

> âœ… æ‰€æœ‰æå‡å‡å…·æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§ï¼ˆ*p < 0.05*ï¼‰

#### ğŸ” **æœ€å¤§æå‡**ï¼š
- **MBPP ä¸Šé«˜è¾¾ +9.2% çš„ç»å¯¹å¢ç›Š**ï¼ˆä» 21.20% â†’ 29.60%ï¼‰
- **HumanEval æå‡è¶…è¿‡ 5.5 ä¸ªç™¾åˆ†ç‚¹**
- åœ¨ BBH å’Œ GSM8K ä¸Šä¹Ÿä¿æŒç¨³å®šå¢ç›Šæˆ–æŒå¹³

---

### ğŸ” **æ¶ˆèå®éªŒç»“æœï¼ˆTable 2 & Table 3ï¼‰**

#### â–¶ï¸ **Table 2ï¼šéªŒè¯é€‰æ‹©ä¿¡å·çš„æœ‰æ•ˆæ€§**
| Method | MBPP (%) |
|--------|---------|
| Low-Confidence Base | 15.60 |
| + Random Remask | 16.60 |
| + Margin Remask | 17.40 |
| **+ CoRE (Ours)** | **24.80** |

> â— ç»“è®ºï¼š**å•çº¯å¢åŠ ä¿®è®¢è¡Œä¸ºæ— æ„ä¹‰**ï¼Œåªæœ‰ CoRE çš„â€œä¸ç¨³å®šæ€§é©±åŠ¨â€æœºåˆ¶å¸¦æ¥æ˜¾è‘—æå‡ã€‚

#### â–¶ï¸ **Table 3ï¼šè®¡ç®—èµ„æºå…¬å¹³å¯¹æ¯”ï¼ˆ136 æ¬¡å‰å‘ä¼ æ’­ï¼‰**
| Method | MBPP (%) |
|--------|---------|
| Low-Confidence Base (136 steps) | 15.40 |
| ReMDM-conf (136 steps) | 14.00 â¬‡ï¸ |
| **CoRE (128 + 8 aux)** | **24.80** |

> âœ… å³ä¾¿ç»™åŸºçº¿æ›´å¤šæ­¥æ•°ï¼Œä¹Ÿæ— æ³•è¾¾åˆ° CoRE çš„æ€§èƒ½ï¼›
> âŒ æ›´å¤šæ­¥æ•°åè€Œå¯èƒ½åŠ å‰§é”™è¯¯å›ºåŒ–ï¼ˆReMDM æ€§èƒ½ä¸‹é™ï¼‰

---

### ğŸ” **å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆFigure 2 & Table 4ï¼‰**
- **æœ€ä½³é…ç½®**ï¼š$ m=32, E=8 $
- è‹¥ $ m=64 $ï¼ˆå€™é€‰è¿‡å¤šï¼‰â†’ æ€§èƒ½ä¸‹é™ â†’ å› è¿‡åº¦æ‰°åŠ¨ç ´åæœ‰æ•ˆä¸Šä¸‹æ–‡ï¼Œäº§ç”Ÿ**å‡é˜³æ€§ä¿®è®¢**
- è‹¥ $ E=16 $ï¼ˆä¿®è®¢å¤ªç¨€ç–ï¼‰â†’ é”™å¤±çº é”™æœºä¼š
- **ç»“è®º**ï¼šé€‚åº¦æ‰°åŠ¨ + ä¸­é¢‘ä¿®è®¢ = æœ€ä½³æƒè¡¡

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### âœ… **ä¸»è¦å‘ç°**
1. **ä¸Šä¸‹æ–‡åˆšæ€§æ˜¯ MDMs çš„æ ¹æœ¬ç“¶é¢ˆ**ï¼Œå°¤å…¶å½±å“ç»“æ„åŒ–è¾“å‡ºï¼ˆå¦‚ä»£ç ï¼‰ã€‚
2. **ä¼ ç»Ÿçš„ç½®ä¿¡åº¦å¯å‘å¼ï¼ˆconfidence/marginï¼‰ä¸è¶³ä»¥æ•æ‰ä¸Šä¸‹æ–‡ä¾èµ–æ€§**ï¼Œå®¹æ˜“é—æ¼â€œé«˜ç½®ä¿¡ä½†é”™è¯¯â€çš„ tokenã€‚
3. **CoRE é€šè¿‡æ‰°åŠ¨æµ‹è¯•æš´éœ²â€œä¸Šä¸‹æ–‡è„†å¼±â€token**ï¼Œå®ç°äº†æ›´æ™ºèƒ½çš„ä¿®è®¢å†³ç­–ã€‚
4. **åœ¨ç›¸åŒè®¡ç®—é¢„ç®—ä¸‹ï¼ŒCoRE æ˜¾è‘—ä¼˜äºæ‰€æœ‰ baseline**ï¼Œå°¤å…¶åœ¨ MBPP ä¸Šå®ç° **+9.2%** çš„çªç ´æ€§æå‡ã€‚
5. **ä¸ç¨³å®šæ€§å¾—åˆ†æ˜¯ä¸€ä¸ªé«˜è´¨é‡çš„ä»£ç†ä¿¡å·**ï¼Œèƒ½ç²¾å‡†åˆ†ç¦»ç¨³å®š vs è„†å¼± tokenï¼ˆè§ Figure 3ï¼‰ã€‚

---

### âš ï¸ **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–å±€éƒ¨æ‰°åŠ¨è¿‘ä¼¼**ï¼šæ— æ³•ç©·ä¸¾æ‰€æœ‰å¯èƒ½çš„ä¸Šä¸‹æ–‡å˜åŒ–ï¼Œworst-case objective æ˜¯è¿‘ä¼¼çš„ã€‚
- **æ‰°åŠ¨èŒƒå›´æœ‰é™**ï¼šåŒæ—¶æ©ç å¤šä¸ªä½ç½®å¯èƒ½å¯¼è‡´ä¸Šä¸‹æ–‡å´©æºƒï¼Œå½±å“åˆ¤æ–­å‡†ç¡®æ€§ï¼ˆæ•…éœ€æ§åˆ¶ $ m $ï¼‰ã€‚
- **å¯¹è¯­ä¹‰çµæ´»æ€§ä»»åŠ¡å¢ç›Šè¾ƒå°**ï¼šå¦‚ GSM8K æ”¹è¿›æœ‰é™ï¼Œå› å…¶å…è®¸å¤šç§åˆç†è·¯å¾„ã€‚
- **æœªè§£å†³äº‹å®æ­£ç¡®æ€§é—®é¢˜**ï¼šåªå¢å¼ºå†…éƒ¨ç»“æ„ä¸€è‡´æ€§ï¼Œä¸ä¿è¯å¤–éƒ¨çŸ¥è¯†å‡†ç¡®ã€‚

---

### ğŸ”® **æœªæ¥å·¥ä½œæ–¹å‘**
- å°† CoRE æ¡†æ¶æ‰©å±•è‡³**å¤šæ¨¡æ€æ‰©æ•£æ¨¡å‹**ï¼ˆå¦‚å›¾æ–‡ç”Ÿæˆï¼‰ã€‚
- æ¢ç´¢ç»“åˆ**å¤–éƒ¨éªŒè¯å™¨**ï¼ˆverifierï¼‰æˆ– reward model æ¥æŒ‡å¯¼ remaskingã€‚
- è®¾è®¡æ›´é«˜æ•ˆçš„æ‰°åŠ¨ç­–ç•¥ï¼ˆå¦‚è‡ªé€‚åº”é€‰æ‹©æ‰°åŠ¨ä½ç½®ï¼‰ã€‚
- åº”ç”¨äº**é•¿æ–‡æœ¬ç”Ÿæˆ**ï¼Œç ”ç©¶å¦‚ä½•åœ¨ä¸åŒæ®µè½é—´ä¼ é€’ä¸Šä¸‹æ–‡é²æ£’æ€§ã€‚
- æ¢ç´¢å¦‚ä½•å°†æ­¤ç±»æœºåˆ¶èå…¥è®­ç»ƒè¿‡ç¨‹ï¼Œå®ç° end-to-end çš„ robust diffusion learningã€‚

---

## âœ… **æ€»ç»“ä¸€å¥è¯**
> **CoRE æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒã€åŸºäºä¸Šä¸‹æ–‡æ‰°åŠ¨æµ‹è¯•çš„ä¿®è®¢æœºåˆ¶ï¼Œæ‰“ç ´äº† MDMs çš„â€œä¸Šä¸‹æ–‡åˆšæ€§â€ï¼Œåœ¨ä»£ç ç­‰ç»“æ„æ•æ„Ÿä»»åŠ¡ä¸Šå®ç°äº†é«˜è¾¾ +9.2% çš„æ€§èƒ½é£è·ƒï¼Œè¯æ˜äº†â€œä¿®è®¢è´¨é‡â€æ¯”â€œä¿®è®¢æ¬¡æ•°â€æ›´é‡è¦ã€‚**

</details>

---

### 10. [BPDQ: Bit-Plane Decomposition Quantization on a Variable Grid for Large Language Models](https://arxiv.org/abs/2602.04163)

**Authors**: Junyu Chen, Jungang Li, Jing Xiong, Wenjie Wang, Qingyao Yang, He Xiao, Zhen Li, Taiqiang Wu, Mengzhao Chen, Zhen Peng, Chaofan Tao, Long Shi, Hongxia Yang, Ngai Wong  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.04163v1  

#### Abstract
Large language model (LLM) inference is often bounded by memory footprint and memory bandwidth in resource-constrained deployments, making quantization a fundamental technique for efficient serving. While post-training quantization (PTQ) maintains high fidelity at 4-bit, it deteriorates at 2-3 bits....

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šBPDQ: Bit-Plane Decomposition Quantization on a Variable Grid for Large Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰çš„ **Post-Training Quantization (PTQ)** åœ¨ 4-bit æ—¶è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ **2â€“3-bit è¶…ä½ç²¾åº¦**ä¸‹æ€§èƒ½ä¸¥é‡ä¸‹é™ã€‚ä½œè€…æŒ‡å‡ºï¼Œæ ¹æœ¬åŸå› å¹¶éä¼˜åŒ–ç›®æ ‡å¤±æ•ˆï¼Œè€Œæ˜¯ç°æœ‰æ–¹æ³•æ™®éé‡‡ç”¨ **shape-invariant quantization grid**ï¼ˆå¦‚ UINT2 çš„å›ºå®šå‡åŒ€åŒºé—´ï¼‰ï¼Œå³æ¯ä¸ªé‡åŒ–ç»„çš„é‡åŒ–çº§åˆ«ç›¸å¯¹é—´è·æ¨¡å¼æ˜¯å›ºå®šçš„ï¼ˆä»…é€šè¿‡ç¼©æ”¾å› å­è°ƒæ•´ï¼‰ï¼Œè¿™æå¤§åœ°é™åˆ¶äº†è¯¯å·®æœ€å°åŒ–çš„å¯è¡Œè§£ç©ºé—´ã€‚

è¿™ç§åˆšæ€§ç»“æ„åœ¨ä½æ¯”ç‰¹ä¸‹æ— æ³•çµæ´»é€‚åº”ä¸åŒæƒé‡ç»„çš„åˆ†å¸ƒç‰¹æ€§ï¼Œå¯¼è‡´è¾“å‡ºå¤±çœŸä¸¥é‡ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æå‡º **Bit-Plane Decomposition Quantization (BPDQ)**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **æ„å»ºå¯å˜é‡åŒ–ç½‘æ ¼ï¼ˆvariable quantization gridï¼‰**ï¼šé€šè¿‡ **bit-plane åˆ†è§£** å’Œ **æ ‡é‡ç³»æ•°ï¼ˆscalar coefficientsï¼‰** æ„é€ æ¯ç»„ç‹¬ç«‹çš„éå‡åŒ€é‡åŒ–çº§åˆ«ã€‚
- **ç†è®ºæ”¯æŒ**ï¼šè¯¥å˜é‡ç½‘æ ¼åœ¨ **Hessian-induced geometry** ä¸‹æ‰©å±•äº†å¯è¡Œè§£é›†ï¼Œä½¿é‡åŒ–è¿‡ç¨‹èƒ½æ›´ä¸€è‡´åœ°å¯¹é½è¾“å‡ºé‡å»ºç›®æ ‡ã€‚
- **è¿­ä»£ä¼˜åŒ–æœºåˆ¶**ï¼šç»“åˆè¿‘ä¼¼äºŒé˜¶ä¿¡æ¯ï¼ˆHessian-aware error compensationï¼‰é€æ­¥ç²¾ç‚¼ bit-planes å’Œç³»æ•°ï¼Œå¹¶å¼•å…¥ **delta correction** ä¿è¯è¯¯å·®ä¼ æ’­ä¸€è‡´æ€§ã€‚

å…·ä½“å…¬å¼å¦‚ä¸‹ï¼š
$$
\hat{W} = \text{REP}(C_0) + \sum_{i=1}^k \text{REP}(C_i) \odot B_i
$$
å…¶ä¸­ $ B_i \in \{0,1\} $ æ˜¯ç¬¬ $ i $ ä¸ª bit-planeï¼Œ$ C_i $ æ˜¯æ¯ç»„çš„æ ‡é‡ç³»æ•°ï¼ŒREP è¡¨ç¤ºæ²¿è¾“å…¥ç»´åº¦é‡å¤æ‰©å±•ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | BPDQ | GPTQ / AWQ |
|------|------|------------|
| **é‡åŒ–ç½‘æ ¼çµæ´»æ€§** | âœ… å¯å˜ç½‘æ ¼ï¼Œæ¯ç»„ç‹¬ç«‹è°ƒæ•´çº§åˆ«é—´è· | âŒ å›ºå®šæ¨¡æ¿ï¼ˆuniform/non-uniformï¼‰ï¼Œä»…ç¼©æ”¾ |
| **ä½æ¯”ç‰¹æ€§èƒ½** | â­ï¸ åœ¨ 2-bit ä¸‹ä¿æŒé«˜ä¿çœŸåº¦ï¼ˆå¦‚ Qwen2.5-72B è¾¾åˆ° 83.85% GSM8Kï¼‰ | âŒ 2-bit ä¸‹ä¸¥é‡é€€åŒ–ï¼ˆå¸¸ä½äº 40%ï¼‰ |
| **ç¡¬ä»¶å‹å¥½æ€§** | âœ… æ”¯æŒ bit-parallel è¿ç®—ï¼Œå¯é€šè¿‡ LUT kernel å®ç°ä½å»¶è¿Ÿæ¨ç† | âœ… åŒæ ·æ”¯æŒ |
| **æ— éœ€å¾®è°ƒ** | âœ… çº¯ PTQï¼Œä¸ä¾èµ– QAT æˆ– QAF | âœ… å¤šæ•°ä¸º PTQ |

> ğŸ’¡ **æ ¸å¿ƒæ´è§**ï¼šä¸æ˜¯ä¼˜åŒ–ç›®æ ‡é”™äº†ï¼Œè€Œæ˜¯åˆšæ€§é‡åŒ–å™¨é™åˆ¶äº†ä¼˜åŒ–æ½œåŠ› â€”â€” **å˜é‡ç½‘æ ¼é‡Šæ”¾äº†è¡¨è¾¾èƒ½åŠ›**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **æ ¡å‡†æ•°æ®ï¼ˆCalibration Dataï¼‰**ï¼šC4 æ•°æ®é›†ä¸­çš„ 1024 ä¸ªæ ·æœ¬ï¼Œç”¨äºä¼°è®¡ Hessian çŸ©é˜µã€‚
- **è¯„ä¼°åŸºå‡†ï¼ˆEvaluation Benchmarksï¼‰**ï¼š
  - **è¯­è¨€ç†è§£ä¸å¸¸è¯†æ¨ç†**ï¼šGSM8Kï¼ˆæ•°å­¦åº”ç”¨é¢˜ï¼‰ã€MATH500ï¼ˆæ•°å­¦è¯æ˜ï¼‰ã€ARC-Cï¼ˆç§‘å­¦é—®ç­”ï¼‰
  - **è‡ªç„¶è¯­è¨€æ¨ç†**ï¼šBoolQã€HellaSwag
  - **ç»¼åˆçŸ¥è¯†**ï¼šMMLU
  - **é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡**ï¼šLongBenchï¼ˆæ¶µç›–æ£€ç´¢ã€æ‘˜è¦ã€ä»£ç è¡¥å…¨ç­‰ï¼‰
  - **å›°æƒ‘åº¦æµ‹è¯•**ï¼šWikiText-2

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹èŒƒå›´**ï¼šè¦†ç›– Qwen-3 / Qwen2.5 ç³»åˆ—ï¼ˆ0.6Bâ€“72Bï¼‰åŠ Ministral-3ï¼ˆ3B, 8Bï¼‰
- **é‡åŒ–é…ç½®**ï¼š
  - **æ¯”ç‰¹å®½åº¦**ï¼š2-bitã€3-bitã€4-bit
  - **åˆ†ç»„å¤§å°ï¼ˆgroup sizeï¼‰**ï¼š
    - GPTQ/AWQï¼šg=64ï¼ˆ4-bitï¼‰ï¼Œgâˆˆ{32,64}ï¼ˆ2/3-bitï¼‰
    - BPDQï¼šg=128ï¼ˆ4-bitï¼‰ï¼Œgâˆˆ{64,128,256}ï¼ˆ2/3-bitï¼‰ï¼Œä»¥æŠµæ¶ˆé¢å¤–ç³»æ•°å¼€é”€
- **è¯„ä¼°å·¥å…·**ï¼š`lm-evaluation-harness`
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - ä¸»è¦ï¼šå‡†ç¡®ç‡ï¼ˆAccuracy on GSM8K, MMLU ç­‰ï¼‰
  - è¾…åŠ©ï¼šVRAM å ç”¨ã€é‡åŒ–æ—¶é—´ã€æ¨ç†å»¶è¿Ÿã€æ¿€æ´»å¼‚å¸¸å€¼ä¿ç•™æƒ…å†µ

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **GPTQ** | Optimization-based PTQ | ä½¿ç”¨ Hessian è¿‘ä¼¼è¿›è¡Œé€å±‚é‡åŒ–ï¼Œç¡¬ä»¶å‹å¥½ |
| **AWQ** | Distribution-aware PTQ | å¼ºè°ƒä¿æŠ¤æ˜¾è‘—æƒé‡ï¼ˆoutliersï¼‰ï¼Œæ··åˆç²¾åº¦ |
| **AnyBCQ** | Bit-plane Method | æœ€è¿‘æå‡ºçš„ bit-plane é‡åŒ–æ–¹æ³•ï¼Œæ”¯æŒå¤šç²¾åº¦ |
| **VPTQ** | Vector Quantization (VQ) | é«˜ä¿çœŸä½†è®¡ç®—ä»£ä»·æé«˜ï¼ˆ~40Ã— GPTQ æ—¶é—´ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ Qwen2.5-72B ä¸ºä¾‹ï¼‰

| æ–¹æ³• | BPW | GSM8K Acc (%) | MMLU Acc (%) | VRAM (GB) | è®¾å¤‡ |
|------|-----|----------------|---------------|-----------|------|
| FP16 (Baseline) | 16 | 90.83 | 83.38 | - | - |
| GPTQ-W2-G64 | 2.28 | 40.49 | 62.18 | ~17 | å¤šå¡ |
| AWQ-W2-G64 | 2.28 | 0.00 | 60.23 | ~17 | å¤šå¡ |
| **BPDQ-W2-G256** | **2.19** | **83.85** | **75.89** | **22.69** | **å•å¼  RTX 3090** |

> âœ… **çªç ´æ€§æˆæœ**ï¼šé¦–æ¬¡å®ç° **72B æ¨¡å‹åœ¨æ¶ˆè´¹çº§ GPU ä¸Š 2-bit é«˜ä¿çœŸæ¨ç†**

#### æ›´å¤šäº®ç‚¹ç»“æœï¼š
- åœ¨ **Qwen2.5-7B** ä¸Šï¼ŒBPDQ-W2-G128 è¾¾åˆ° **35.48% GSM8K**ï¼Œè¿œè¶… GPTQï¼ˆ0.00%ï¼‰å’Œ AWQï¼ˆ0.00%ï¼‰
- åœ¨ **MMLU** ä¸Šï¼ŒBPDQ ä¿æŒè¶…è¿‡ 91% çš„åŸå§‹æ€§èƒ½ï¼ˆå¦‚ 72B æ¨¡å‹è¾¾ 75.89%ï¼‰
- **BoolQ** ä¸Šç”šè‡³è¾¾åˆ° **99.15%** å‡†ç¡®ç‡ï¼Œæ¥è¿‘å…¨ç²¾åº¦æ°´å¹³

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| ç»´åº¦ | ç»“æœ |
|------|------|
| **2-bit æ€§èƒ½ä¼˜åŠ¿** | BPDQ æ˜¾è‘—ä¼˜äº GPTQ å’Œ AWQï¼Œåœ¨æ‰€æœ‰æ¨¡å‹è§„æ¨¡ä¸Šå‡å–å¾—æœ€ä½³æˆ–æ¬¡ä½³æˆç»© |
| **æ¨ç†ä»»åŠ¡é²æ£’æ€§** | å°¤å…¶åœ¨ **GSM8K/MATH500** ç­‰éœ€è¦å¼ºæ¨ç†çš„ä»»åŠ¡ä¸Šï¼ŒBPDQ æ˜æ˜¾é¢†å…ˆ |
| **é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›** | åœ¨ LongBench çš„ PassageRetrieval ä»»åŠ¡ä¸­ï¼ŒBPDQ å¾—åˆ† **53.75%**ï¼Œè€Œ GPTQ ä»…ä¸º **4.98%**ï¼Œæ˜¾ç¤ºæ›´å¼ºçš„é•¿ç¨‹ä¾èµ–ä¿æŒèƒ½åŠ› |
| **ç³»ç»Ÿæ•ˆç‡** | æ¨ç†å»¶è¿Ÿä¼˜äº GPTQï¼ˆå°¤å…¶åœ¨ 2/3-bitï¼‰ï¼Œé‡åŒ–æ—¶é—´çº¦ä¸º GPTQ çš„ 3 å€ï¼Œè¿œä½äº VPTQï¼ˆ~40Ã—ï¼‰ |

### æ¶ˆèå®éªŒä¸åˆ†æï¼ˆå…³é”®å‘ç°ï¼‰
| åˆ†æé¡¹ | å‘ç° |
|--------|------|
| **Activation Outlier Statistics** | BPDQ èƒ½æœ‰æ•ˆä¿ç•™å…³é”®æ¿€æ´»å¼‚å¸¸å€¼ï¼ˆoutliersï¼‰ï¼Œå…¶ DiagR å’Œ Cnt10 æŒ‡æ ‡æ¥è¿‘åŸå§‹æ¨¡å‹ï¼›è€Œ GPTQ åœ¨ 2-bit ä¸‹ä¸¥é‡æŠ‘åˆ¶ outliersï¼ˆâ–³DiagR -32.89%ï¼Œâ–³Cnt10 -23.61%ï¼‰ |
| **å˜é‡ç½‘æ ¼æœ‰æ•ˆæ€§** | ç†è®ºè¯æ˜ BPDQ çš„å¯è¡Œé›†ä¸¥æ ¼åŒ…å« UINT2 ç½‘æ ¼ï¼ˆProposition 1ï¼‰ï¼Œä¸”å­˜åœ¨å¼€æ”¾é›†åˆä½¿å¾— BPDQ å¯å®ç°æ›´ä½è¯¯å·®ï¼ˆProposition 2ï¼‰ |
| **Delta Correction å¿…è¦æ€§** | ç§»é™¤ delta correction ä¼šå¯¼è‡´è¯¯å·®ä¼ æ’­çŠ¶æ€ä¸ä¸€è‡´ï¼Œæ€§èƒ½ä¸‹é™æ˜æ˜¾ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ ¹æœ¬ç“¶é¢ˆåœ¨äºé‡åŒ–ç½‘æ ¼åˆšæ€§**ï¼šä½æ¯”ç‰¹ PTQ çš„å¤±è´¥ä¸»å› ä¸æ˜¯ä¼˜åŒ–ç›®æ ‡æ— æ•ˆï¼Œè€Œæ˜¯ **shape-invariant grid é™åˆ¶äº†è§£ç©ºé—´**ã€‚
2. **å˜é‡ç½‘æ ¼æ˜¾è‘—æå‡è¡¨è¾¾èƒ½åŠ›**ï¼šBPDQ é€šè¿‡ bit-plane + ç³»æ•°çš„æ–¹å¼æ„é€  per-group adaptive gridï¼Œç†è®ºä¸Šæ‰©å±•äº†å¯è¡Œé›†ç»´åº¦ï¼ˆä» 1D ray â†’ 2D planeï¼‰ã€‚
3. **å¯åœ¨æ¶ˆè´¹çº§è®¾å¤‡éƒ¨ç½² 72B æ¨¡å‹**ï¼šBPDQ å®ç° **Qwen2.5-72B åœ¨å•å¼  RTX 3090 ä¸Š 2-bit æ¨ç†**ï¼Œå†…å­˜ä»…éœ€ 22.69GBï¼Œå‡†ç¡®ç‡é«˜è¾¾ 83.85%ï¼ˆGSM8Kï¼‰ã€‚
4. **å…¼é¡¾é«˜æ•ˆä¸é«˜ä¿çœŸ**ï¼šç›¸æ¯” VQ æ–¹æ³•ï¼ˆå¦‚ VPTQï¼‰ï¼ŒBPDQ ä¿çœŸåº¦ç•¥ä½ä½†é‡åŒ–é€Ÿåº¦å¿«ä¸€ä¸ªæ•°é‡çº§ï¼Œæ›´é€‚åˆå®é™…éƒ¨ç½²ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä»å­˜åœ¨ä¿çœŸåº¦å·®è·**ï¼šå°½ç®¡å¤§å¹…æ”¹è¿›ï¼ŒBPDQ åœ¨ 2-bit ä¸‹ä»æœªå®Œå…¨è¿½å¹³ VPTQ çš„ç²¾åº¦ï¼ˆåè€…é€šå¸¸æœ‰æ›´é«˜ overheadï¼‰ã€‚
- **å­˜å‚¨å¼€é”€ç•¥é«˜**ï¼šç”±äºæ¯ bit-plane éœ€è¦ç‹¬ç«‹çš„ scale coefficientï¼Œç•¥å¾®å¢åŠ å…ƒæ•°æ®ä½“ç§¯ï¼ˆé€šè¿‡å¢å¤§ group size ç¼“è§£ï¼‰ã€‚
- **æœªæ¢ç´¢æ—‹è½¬æŠ€æœ¯**ï¼šæœªç»“åˆ weight rotationï¼ˆå¦‚ Quarotï¼‰è¿›ä¸€æ­¥æ¶ˆé™¤ outliersï¼Œå¯èƒ½é™åˆ¶æé™å‹ç¼©æ€§èƒ½ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **èåˆ Rotation æŠ€æœ¯**ï¼šå°† BPDQ ä¸ weight rotationï¼ˆå¦‚ Quarotï¼‰ç»“åˆï¼Œè¿›ä¸€æ­¥å‡å°‘ outlier å½±å“ã€‚
2. **é›†æˆé«˜çº§æ±‚è§£å™¨**ï¼šå¼•å…¥ Qronos ç­‰å…·å¤‡å†å²è¯¯å·®ä¿®æ­£èƒ½åŠ›çš„åºåˆ—åŒ–æ±‚è§£å™¨ï¼Œè¿›ä¸€æ­¥é™ä½é‡å»ºè¯¯å·®ã€‚
3. **å®šåˆ¶ç¡¬ä»¶åŠ é€Ÿ**ï¼šåˆ©ç”¨ bit-plane çš„äºŒè¿›åˆ¶ç‰¹æ€§ï¼Œåœ¨ FPGA/ASIC ä¸Šå®ç°æè‡´èƒ½æ•ˆæ¯”ï¼ˆæ›¿æ¢æµ®ç‚¹ä¹˜æ³•ä¸ºåŠ æ³•ï¼‰ã€‚
4. **åŠ¨æ€å¤šç²¾åº¦æœåŠ¡**ï¼šåŸºäºåŒä¸€æ¨¡å‹æŒ‰éœ€å¯ç”¨ä¸åŒæ•°é‡ bit-planesï¼Œå®ç° **dynamic accuracy-latency trade-off**ã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **BPDQ é€šè¿‡æ‰“ç ´ä¼ ç»Ÿé‡åŒ–ä¸­çš„â€œå½¢çŠ¶ä¸å˜æ€§â€çº¦æŸï¼Œæå‡ºåŸºäº bit-plane çš„å¯å˜ç½‘æ ¼é‡åŒ–æ¡†æ¶ï¼Œåœ¨ç†è®ºå’Œå®è·µä¸Šå®ç°äº† 2-bit å¤§æ¨¡å‹é«˜ä¿çœŸæ¨ç†çš„é‡å¤§çªç ´ï¼Œæ¨åŠ¨äº†ç™¾äº¿å‚æ•°æ¨¡å‹åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„è½åœ°å¯èƒ½æ€§ã€‚**

</details>

---

### 11. [Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL](https://arxiv.org/abs/2602.04089)

**Authors**: Xiaofeng Lin, Sirou Zhu, Yilei Chen, Mingyu Chen, Hejian Sang, Ioannis Paschalidis, Zhipeng Wang, Aldo Pacchiano, Xuezhou Zhang  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.04089v1  

#### Abstract
Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial information must be acquired through interaction,...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šScaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜

å½“å‰çš„ **Large Language Models (LLMs)** è™½ç„¶åœ¨é™æ€ä»»åŠ¡ï¼ˆå¦‚æŒ‡ä»¤éµå¾ªã€å°‘æ ·æœ¬æ¨ç†ï¼‰ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨**åœ¨çº¿å†³ç­–ä»»åŠ¡**ï¼ˆonline decision-makingï¼‰ä¸­è¡¨ç°ä¸ä½³ã€‚è¿™ç±»ä»»åŠ¡å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

- **ä¿¡æ¯ä¸å®Œå…¨**ï¼ˆéƒ¨åˆ†å¯è§‚æµ‹ï¼‰
- **åé¦ˆå»¶è¿Ÿ**
- éœ€è¦é€šè¿‡å¤šè½®äº¤äº’é€æ­¥æ¢ç´¢å¹¶åˆ©ç”¨æ‰€å­¦çŸ¥è¯†
- å†³ç­–éœ€åœ¨**æ¢ç´¢ï¼ˆexplorationï¼‰** å’Œ **åˆ©ç”¨ï¼ˆexploitationï¼‰** ä¹‹é—´æƒè¡¡

å°½ç®¡ LLMs å…·å¤‡ **In-Context Learning (ICL)** èƒ½åŠ›ï¼Œä½†å®ƒä»¬é€šå¸¸éš¾ä»¥ä»è·¨å›åˆçš„äº¤äº’å†å²ä¸­æœ‰æ•ˆå­¦ä¹ ç­–ç•¥ï¼Œå°¤å…¶æ˜¯åœ¨é¢å¯¹**æœªè§è¿‡çš„ä»»åŠ¡ç¯å¢ƒ**æ—¶ã€‚

> â— é—®é¢˜æœ¬è´¨ï¼šå¦‚ä½•è®© LLM åœ¨ä¸æ›´æ–°å‚æ•°çš„å‰æä¸‹ï¼Œé€šè¿‡ä¸Šä¸‹æ–‡è®°å¿†å®ç°çœŸæ­£çš„â€œè¾¹æ¨ç†è¾¹å­¦ä¹ â€ï¼ˆlearn-at-inference-timeï¼‰ï¼Ÿ

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šORBIT

ä½œè€…æå‡º **ORBIT**ï¼ˆOnline Reinforcement-Based In-Context Trainingï¼‰ï¼Œä¸€ç§åŸºäº **multi-task, multi-episode meta-Reinforcement Learning (meta-RL)** çš„è®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨èµ‹äºˆ LLMs æ›´å¼ºçš„ **in-context online learning** èƒ½åŠ›ã€‚

#### æ ¸å¿ƒæ€æƒ³ï¼š

- å°†æ¯ä¸ªä»»åŠ¡å»ºæ¨¡ä¸ºä¸€ä¸ªæœ‰é™å›åˆçš„ **Markov Decision Process (MDP)**
- åœ¨è®­ç»ƒé˜¶æ®µï¼Œæ¨¡å‹åœ¨å¤šä¸ª episode ä¸­ä¸åŒä¸€ä»»åŠ¡äº¤äº’ï¼Œä¸”**ä¸Šä¸‹æ–‡çª—å£ä¿ç•™æ‰€æœ‰å†å²è½¨è¿¹**
- ä¼˜åŒ–ç›®æ ‡æ˜¯æœ€å¤§åŒ–**è·¨ episode çš„é•¿æœŸç´¯ç§¯å¥–åŠ±**ï¼Œè€Œéå•æ¬¡ episode æˆåŠŸ
- å¼ºè°ƒâ€œå­¦ä¼šå¦‚ä½•å­¦ä¹ â€ï¼ˆlearning to learn in contextï¼‰ï¼Œå³æ—©æœŸå°è¯•ç”¨äºæ”¶é›†ä¿¡æ¯ï¼ŒåæœŸç”¨äºé«˜æ•ˆæ‰§è¡Œ

#### åˆ›æ–°ç‚¹ï¼š

| åˆ›æ–°ç»´åº¦ | å†…å®¹ |
|--------|------|
| **è®­ç»ƒèŒƒå¼** | é¦–æ¬¡ç³»ç»Ÿæ€§åœ°å°† **multi-episode meta-RL** åº”ç”¨äºé¢„è®­ç»ƒ LLMï¼Œä½¿å…¶å…·å¤‡è·¨ episode çš„ in-context adaptation èƒ½åŠ› |
| **è®­ç»ƒç›®æ ‡è®¾è®¡** | ä½¿ç”¨ **trajectory-level success count** ä½œä¸ºç¨€ç–å¥–åŠ±ä¿¡å·ï¼Œé¿å… reward hacking å’Œä»»åŠ¡é—´å°ºåº¦ä¸å¹³è¡¡ |
| **ä¼˜åŒ–ç®—æ³•** | é‡‡ç”¨ **Group Relative Policy Optimization (GRPO)**ï¼Œä»…ä¾èµ–è½¨è¿¹çº§å›æŠ¥è¿›è¡Œç­–ç•¥æ›´æ–°ï¼Œå¤©ç„¶æ”¯æŒç¨€ç–å¥–åŠ±å’Œ outcome-driven å­¦ä¹  |
| **ç®€æ´æ€§** | ä¸å¼•å…¥å¤–éƒ¨è®°å¿†ï¼ˆexternal memoryï¼‰ã€åæ€æ¨¡å—ï¼ˆreflection promptsï¼‰æˆ–å¤æ‚æç¤ºå·¥ç¨‹ï¼Œçº¯ç²¹ä¾é  meta-RL å®ç°èƒ½åŠ›æ¶Œç° |

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹æ³• | å±€é™æ€§ | ORBIT çš„ä¼˜åŠ¿ |
|------|-------|-------------|
| **æ ‡å‡† ICL / Instruction Tuning** | æ— æ³•å¤„ç†åŠ¨æ€åé¦ˆå’Œå»¶è¿Ÿå¥–åŠ±ï¼Œç¼ºä¹ä¸»åŠ¨æ¢ç´¢æœºåˆ¶ | æ˜¾å¼è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¢ç´¢-åˆ©ç”¨æƒè¡¡ |
| **ä¼ ç»Ÿ RL Fine-tuning** | é€šå¸¸åŸºäºå• episode rolloutsï¼Œå¿½ç•¥è·¨ episode ä¿¡æ¯ç§¯ç´¯ | æ”¯æŒè·¨ episode ç­–ç•¥æ¼”åŒ–ï¼Œå®ç°çœŸæ­£çš„ in-context ç­–ç•¥æ”¹è¿› |
| **å…¶ä»– ICRL æ–¹æ³•**ï¼ˆå¦‚ PAPRIKA, Iterative RMFTï¼‰ | å¤šæ•°åœ¨å·²çŸ¥ä»»åŠ¡ä¸Šå¾®è°ƒï¼Œæ³›åŒ–èƒ½åŠ›å¼±ï¼›æˆ–ä¾èµ–äººå·¥æ„é€ åå¥½ | åœ¨**å®Œå…¨æœªè§ä»»åŠ¡**ä¸ŠéªŒè¯ï¼Œå¼ºè°ƒè·¨ä»»åŠ¡è¿ç§»èƒ½åŠ› |
| **Reflection-based Agents**ï¼ˆå¦‚ Reflexionï¼‰ | ä¾èµ–æ˜¾å¼â€œåæ€â€æç¤ºæˆ–é¢å¤–æ¨¡å— | åæ€è¡Œä¸º**è‡ªå‘æ¶Œç°**äºç­–ç•¥ä¸­ï¼Œæ— éœ€é¢å¤–è®¾è®¡ |

> âœ… ORBIT çš„æœ€å¤§ä¼˜åŠ¿ï¼š**è®­ç»ƒåçš„å°å‹å¼€æºæ¨¡å‹ï¼ˆQwen3-14Bï¼‰åœ¨æœªè§ä»»åŠ¡ä¸Šçš„ in-context online learning è¡¨ç°åª²ç¾ GPT-5.2**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†ä¸ä»»åŠ¡

å…±ä½¿ç”¨ **7 ä¸ªéƒ¨åˆ†å¯è§‚æµ‹çš„å†³ç­–ä»»åŠ¡**ï¼Œåˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼š

| ç±»å‹ | ä»»åŠ¡ | æè¿° |
|------|------|------|
| **è®­ç»ƒä»»åŠ¡** | RPS, Minesweeper, Hangman, Wordle, Blackjack | å¤šæ ·åŒ–çš„åºåˆ—å†³ç­–ä»»åŠ¡ï¼Œæ¶µç›–æ¦‚ç‡æ¨ç†ã€é€»è¾‘æ¨æ–­ã€è®°å¿†ä¾èµ–ç­‰ |
| **æµ‹è¯•ä»»åŠ¡** | **Maze**, **Mastermind** | **å®Œå…¨æœªåœ¨è®­ç»ƒä¸­å‡ºç°**ï¼Œç”¨äºè¯„ä¼°æ³›åŒ–èƒ½åŠ› |

> æ‰€æœ‰ä»»åŠ¡å‡ä¸º episodicï¼Œæ¯è½® reset ç¯å¢ƒä½†ä¿æŒè§„åˆ™ä¸å˜ï¼Œagent å¯é€šè¿‡å¤šè½®å°è¯•ç§¯ç´¯ç»éªŒã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

| ç»„ä»¶ | è®¾ç½® |
|------|------|
| **åŸºç¡€æ¨¡å‹** | Qwen3-{4B, 8B, 14B}ï¼ˆä¸»è¦ç”¨ 8Bï¼‰ |
| **ä¸Šä¸‹æ–‡é•¿åº¦** | æœ€å¤§ 32,768 tokensï¼ˆé™åˆ¶æ¯å®ä¾‹æœ€å¤š 3 ä¸ª episodeï¼‰ |
| **è®­ç»ƒæ–¹å¼** | ORBITï¼šmulti-episode meta-RLï¼ŒHT = 3 episodes per task |
| **å¥–åŠ±è®¾è®¡** | äºŒå€¼å®Œæˆå¥–åŠ±ï¼ˆ0/1ï¼‰ï¼ŒæŒ‰ trajectory ç»Ÿè®¡æˆåŠŸæ¬¡æ•° |
| **ä¼˜åŒ–å™¨** | GRPOï¼Œbatch size=64ï¼ŒK=4 trajectories per group |
| **è®­ç»ƒæ­¥æ•°** | 100 optimization stepsï¼Œlr=1e-6 |
| **æ¨ç†é…ç½®** | temperature=0.6, top_p=0.95ï¼Œå¯ç”¨ thinking mode |

---

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | å®šä¹‰ | ç›®çš„ |
|------|------|------|
| **Success Rate per Episode** | ç¬¬ e è½®çš„æˆåŠŸç‡ | è¡¡é‡æ˜¯å¦éš episode æå‡ï¼ˆä½“ç° in-context learningï¼‰ |
| **Episode-3 Success Rate** | ç¬¬ä¸‰è½®æˆåŠŸç‡ | å¯¹æ¯”ä¸åŒæ–¹æ³•çš„æœ€ç»ˆé€‚åº”èƒ½åŠ› |
| **In-Context Regret** | $ \text{Reg}(M) = T \cdot J^*(M) - \mathbb{E}[\sum G^{(e)}] $ | è¡¡é‡ç´¯è®¡æ€§èƒ½å·®è·ï¼Œè¶Šå°è¶Šå¥½ |
| **â–³States (Exploration under Failure)** | å¤±è´¥åæ–°å¢æ¢ç´¢çš„çŠ¶æ€æ•° | é‡åŒ–æ¢ç´¢è¡Œä¸ºçš„å¤šæ ·æ€§ |

> æ‰€æœ‰è¯„ä¼°å‡åœ¨ **256 ä¸ªç‹¬ç«‹çš„ Maze å’Œ Mastermind å®ä¾‹**ä¸Šè¿›è¡Œï¼Œç¡®ä¿æ— è¿‡æ‹Ÿåˆã€‚

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿ | æè¿° |
|------|------|
| **Base Model** | æœªç»ä»»ä½• RL å¾®è°ƒçš„åŸå§‹ Qwen3 |
| **Standard RL Fine-tuning** | å• episode RL å¾®è°ƒï¼Œä»…ä¼˜åŒ–å½“è½®æˆåŠŸæ¦‚ç‡ |
| **GPT-4o / GPT-5.2** | å•†ä¸šé—­æºæ¨¡å‹ï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™å‚è€ƒ |
| **Oracle Algorithms** | é’ˆå¯¹ Maze å’Œ Mastermind è®¾è®¡çš„æœ€ä¼˜ç®—æ³•ï¼ˆè§ Appendix Cï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Figure 1 & Table 2ï¼‰

#### åœ¨ **Maze** ä¸Šçš„è¡¨ç°ï¼ˆEpisode 3 æˆåŠŸç‡ï¼‰ï¼š

| æ–¹æ³• | æˆåŠŸç‡ | ç›¸å¯¹ Base æå‡ |
|------|--------|----------------|
| Base Model | 0.22 | â€” |
| Standard RL | 0.45 | +0.23 |
| **ORBIT (8B)** | **0.55** | **+0.33** |
| **ORBIT (14B)** | **0.70+**ï¼ˆè¶‹åŠ¿ä¸Šå‡ï¼‰ | â€” |

#### åœ¨ **Mastermind** ä¸Šçš„è¡¨ç°ï¼ˆEpisode 3 æˆåŠŸç‡ï¼‰ï¼š

| æ–¹æ³• | æˆåŠŸç‡ | ç›¸å¯¹ Base æå‡ |
|------|--------|----------------|
| Base Model | 0.27 | â€” |
| Standard RL | 0.21 | -0.06ï¼ˆé€€åŒ–ï¼‰ |
| **ORBIT (8B)** | **0.59** | **+0.32** |

> âœ… ORBIT åœ¨ä¸¤ä¸ªæœªè§ä»»åŠ¡ä¸Šå‡æ˜¾è‘—ä¼˜äº base model å’Œ standard RLï¼Œä¸” **14B ç‰ˆæœ¬æ¥è¿‘ GPT-5.2 æ€§èƒ½**

---

### ğŸ“ˆ ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

| è§‚å¯Ÿ | ç»“è®º |
|------|------|
| **ORBIT vs Base Model** | æˆåŠŸç‡å¤§å¹…æå‡ï¼Œä¸”å‘ˆç°**å•è°ƒä¸Šå‡è¶‹åŠ¿**ï¼Œè¡¨æ˜æœ‰æ•ˆåˆ©ç”¨å†å²ä¿¡æ¯ |
| **ORBIT vs Standard RL** | Standard RL åœ¨æ—©æœŸç•¥æœ‰æå‡ï¼Œä½†åç»­åœæ»ç”šè‡³ä¸‹é™ï¼›è€Œ ORBIT æŒç»­æ”¹è¿›ï¼Œè¯´æ˜å…¶çœŸæ­£æŒæ¡äº† in-context adaptation |
| **ORBIT vs GPT-4o/GPT-5.2** | Qwen3-14B + ORBIT **åŒ¹é… GPT-5.2 è¡¨ç°**ï¼Œè¿œè¶… GPT-4o |
| **Scaling Effect** | æ¨¡å‹è¶Šå¤§ï¼ˆ4B â†’ 8B â†’ 14Bï¼‰ï¼Œepisode 2 å’Œ 3 æå‡è¶Šæ˜æ˜¾ï¼Œæ˜¾ç¤ºå¯æ‰©å±•æ½œåŠ› |

> ğŸ”¥ å›¾ 5 æ˜¾ç¤ºï¼š**æ›´å¤§çš„æ¨¡å‹æ›´å€¾å‘äºåœ¨å‰å‡ è½®ä¸»åŠ¨æ¢ç´¢**ï¼ŒåæœŸå†é«˜æ•ˆåˆ©ç”¨ï¼Œä½“ç°å‡ºâ€œæ™ºèƒ½åˆ†é…æ¢ç´¢é¢„ç®—â€çš„èƒ½åŠ›ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒä¸å®šæ€§åˆ†æï¼ˆQualitative Evidenceï¼‰

#### ï¼ˆ1ï¼‰æ¢ç´¢è¡Œä¸ºé‡åŒ–ï¼ˆTable 4ï¼‰

| æ–¹æ³• | â–³States (Ep2 \| F1) | â–³States (Ep3 \| F1-2) |
|------|---------------------|------------------------|
| Base | 1.64 | 0.94 |
| RL | 4.11 | 1.27 |
| **ORBIT** | **4.69** | **1.48** |

> ORBIT åœ¨å¤±è´¥åæ¢ç´¢æ›´å¤šæ–°çŠ¶æ€ï¼Œè¯´æ˜å…¶å­¦ä¼šäº†â€œæ¢æ¡è·¯è¯•â€ã€‚

#### ï¼ˆ2ï¼‰å®šæ€§æ¡ˆä¾‹ï¼ˆTable 3 & Figure 4ï¼‰

- åœ¨ Maze ä»»åŠ¡ä¸­ï¼ŒORBIT åœ¨ Episode 3 ä¸»åŠ¨æ€»ç»“å‰ä¸¤è½®å¤±è´¥ï¼šâ€œ*Previously I went up and failedâ€¦ this time Iâ€™ll explore right.*â€
- åŠ¨ä½œé€‰æ‹©å‘ç”Ÿæ”¹å˜ï¼Œæœ€ç»ˆæˆåŠŸæŠµè¾¾ç›®æ ‡
- æ­¤ç±»â€œåæ€-è°ƒæ•´â€è¡Œä¸º**æœªé€šè¿‡ prompt å¼•å¯¼**ï¼Œè€Œæ˜¯è®­ç»ƒä¸­è‡ªå‘æ¶Œç°

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **LLMs å¯ä»¥é€šè¿‡ meta-RL è·å¾—å¼ºå¤§çš„ in-context online learning èƒ½åŠ›**  
   â†’ ORBIT æˆåŠŸæ•™ä¼šæ¨¡å‹â€œä»å¤±è´¥ä¸­å­¦ä¹ â€ï¼Œå³ä½¿é¢å¯¹å…¨æ–°ä»»åŠ¡ä¹Ÿèƒ½å¿«é€Ÿé€‚åº”ã€‚

2. **multi-episode meta-RL æ˜¯å®ç°è¯¥èƒ½åŠ›çš„å…³é”®æœºåˆ¶**  
   â†’ å• episode RL æ— æ³•å»ºç«‹è·¨ episode çš„ç­–ç•¥æ¼”åŒ–ï¼Œè€Œ ORBIT æ˜¾å¼ä¼˜åŒ–é•¿æœŸæ”¶ç›Šã€‚

3. **èƒ½åŠ›å¯è¿ç§»ä¸”å¯æ‰©å±•**  
   â†’ åœ¨å®Œå…¨æœªè§ä»»åŠ¡ï¼ˆMaze, Mastermindï¼‰ä¸Šè¡¨ç°ä¼˜å¼‚  
   â†’ éšæ¨¡å‹è§„æ¨¡å¢å¤§æŒç»­æå‡ï¼Œæš—ç¤ºæœªæ¥ä»æœ‰å·¨å¤§æ½œåŠ›

4. **é«˜çº§è¡Œä¸ºï¼ˆå¦‚æ¢ç´¢ã€åæ€ï¼‰å¯ä»¥è‡ªå‘æ¶Œç°**  
   â†’ æ— éœ€å¤–éƒ¨ memory æˆ– reflection promptï¼Œæ¨¡å‹è‡ªè¡Œç”Ÿæˆæ€»ç»“ä¸ç­–ç•¥è°ƒæ•´

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

| å±€é™ | è¯´æ˜ |
|------|------|
| **ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶** | å½“å‰å—é™äº 32k tokenï¼Œæœ€å¤šæ”¯æŒ 3 ä¸ª episodeï¼›æ›´é•¿ horizon ä¸‹å¯èƒ½å¤±æ•ˆ |
| **è®­ç»ƒä»»åŠ¡æ•°é‡æœ‰é™** | ä»…ä½¿ç”¨ 5 ä¸ªè®­ç»ƒä»»åŠ¡ï¼Œæ³›åŒ–è¾¹ç•Œå°šä¸æ˜ç¡® |
| **è®¡ç®—èµ„æºè¦æ±‚é«˜** | GRPO éœ€è¦å¤šè½¨è¿¹é‡‡æ ·ï¼Œè®­ç»ƒæˆæœ¬è¾ƒé«˜ |
| **æœªæ”¯æŒè¿ç»­åŠ¨ä½œç©ºé—´** | å½“å‰ä»…é€‚ç”¨äºç¦»æ•£åŠ¨ä½œä»»åŠ¡ |

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•åˆ°æ›´é•¿ horizon å’Œæ›´å¤§ context window**  
   â†’ ç»“åˆ MemGPTã€Retrieval-Augmented Generation ç­‰æŠ€æœ¯çªç ´é•¿åº¦ç“¶é¢ˆ

2. **å¢åŠ è®­ç»ƒä»»åŠ¡çš„å¤šæ ·æ€§å’Œå¤æ‚åº¦**  
   â†’ æ¢ç´¢æ›´å¤æ‚çš„è§„åˆ’ã€å·¥å…·è°ƒç”¨ã€å¤šæ™ºèƒ½ä½“åä½œåœºæ™¯

3. **ç ”ç©¶æ›´é«˜æ•ˆçš„ meta-RL ç®—æ³•**  
   â†’ å¦‚ç»“åˆä»·å€¼å‡½æ•°ä¼°è®¡ã€credit assignment æŠ€æœ¯æå‡è®­ç»ƒç¨³å®šæ€§

4. **æ„å»ºé€šç”¨çš„ in-context RL benchmark**  
   â†’ æ¨åŠ¨ç¤¾åŒºå¯¹ LLMs åœ¨çº¿å­¦ä¹ èƒ½åŠ›çš„æ ‡å‡†åŒ–è¯„ä¼°

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> ORBIT è¯æ˜äº†é€šè¿‡ç®€å•çš„ multi-episode meta-RL è®­ç»ƒï¼Œå³å¯è®©å°å‹å¼€æº LLM åœ¨æœªè§ä»»åŠ¡ä¸Šå®ç°åª²ç¾ GPT-5.2 çš„ in-context online learning èƒ½åŠ›ï¼Œä¸ºæ„å»ºâ€œä¼šå­¦ä¹ çš„ AI Agentâ€æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 12. [ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control](https://arxiv.org/abs/2602.04496)

**Authors**: Zhentao Tang, Yuqi Cui, Shixiong Kai, Wenqian Zhao, Ke Ye, Xing Li, Anxin Tian, Zehua Pei, Hui-Ling Zhen, Shoubo Hu, Xiaoguang Li, Yunhe Wang, Mingxuan Yuan  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.04496v1  

#### Abstract
Expert-level scientific reasoning remains challenging for large language models, particularly on benchmarks such as Humanity's Last Exam (HLE), where rigid tool pipelines, brittle multi-agent coordination, and inefficient test-time scaling often limit performance. We introduce ReThinker, a confidenc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control  
**æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰çš„ **Large Language Models (LLMs)** åœ¨ä¸“å®¶çº§ç§‘å­¦æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°ä»ä¸ç†æƒ³ï¼Œå°¤å…¶æ˜¯åœ¨å¦‚ **Humanity's Last Exam (HLE)** è¿™ç±»é«˜éš¾åº¦åŸºå‡†ä¸Šã€‚ä¼ ç»Ÿæ–¹æ³•å­˜åœ¨ä»¥ä¸‹ç“¶é¢ˆï¼š
- **åˆšæ€§çš„å·¥å…·æµæ°´çº¿**ï¼ˆrigid tool pipelinesï¼‰å¯¼è‡´çµæ´»æ€§ä¸è¶³ï¼›
- **å¤šæ™ºèƒ½ä½“åä½œè„†å¼±**ï¼ˆbrittle multi-agent coordinationï¼‰ï¼Œå®¹æ˜“å› å•ç‚¹é”™è¯¯å´©æºƒï¼›
- **æµ‹è¯•æ—¶æ‰©å±•æ•ˆç‡ä½**ï¼ˆinefficient test-time scalingï¼‰ï¼Œéš¾ä»¥åŠ¨æ€åˆ†é…è®¡ç®—èµ„æºã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†æ¨¡å‹åœ¨å¤æ‚ç§‘å­¦é—®é¢˜ä¸­çš„æ·±åº¦æ¨ç†èƒ½åŠ›ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡º **ReThinker** â€”â€”ä¸€ç§åŸºäºä¿¡å¿ƒæ„ŸçŸ¥ï¼ˆconfidence-awareï¼‰çš„æ™ºèƒ½ä½“æ¡†æ¶ï¼Œé‡‡ç”¨ **é˜¶æ®µå¼ Solver-Critic-Selector æ¶æ„** æ¥åè°ƒæ£€ç´¢ã€å·¥å…·ä½¿ç”¨å’Œå¤šæ™ºèƒ½ä½“æ¨ç†ã€‚

å…¶ä¸‰å¤§æ ¸å¿ƒæŠ€æœ¯åˆ›æ–°ä¸ºï¼š
1. **è‡ªåŠ¨åŒ–è½¨è¿¹åˆæˆç”¨äºåæ€ç›‘ç£**ï¼ˆAutomated Trajectory Synthesis for Rethinking Supervisionï¼‰
   - å®Œå…¨æ— éœ€äººå·¥æ ‡æ³¨ï¼Œé€šè¿‡ LLM å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„ä¸“å®¶çº§ QA å¯¹ï¼›
   - åˆ©ç”¨ç½‘ç»œä¸Šä¸‹æ–‡æå–é¢†åŸŸæ¦‚å¿µï¼Œå¹¶è®°å½•å®Œæ•´çš„å¤šé˜¶æ®µæ¨ç†è½¨è¿¹ï¼Œä»…ä¿ç•™éªŒè¯æ­£ç¡®çš„è·¯å¾„ä½œä¸ºè®­ç»ƒæ•°æ®ã€‚

2. **å¼•å¯¼å¼åå°„çš„æ··åˆæ‰©å±•æ¶æ„**ï¼ˆHybrid Scaling with Guided Reflectionï¼‰
   - å¼•å…¥ **summary-and-guidance æ¨¡å—**ï¼Œå¯¹å®Œæ•´æ¨ç†è½¨è¿¹è¿›è¡Œç»“æ„åŒ–æ€»ç»“ï¼Œè¯†åˆ«é€»è¾‘ã€ç­–ç•¥å’ŒçŸ¥è¯†å±‚é¢çš„å…·ä½“ç¼ºé™·ï¼›
   - æ”¯æŒ Python æ‰§è¡Œã€ç½‘é¡µæœç´¢ä¸è§£æç­‰å·¥å…·é›†æˆï¼Œå®ç°å®šé‡éªŒè¯ä¸ä¸“ä¸šçŸ¥è¯†è·å–ï¼›
   - Solver é˜¶æ®µæ”¯æŒå¤šè½®è¿­ä»£ä¼˜åŒ–ï¼Œé¿å…ä¸€æ¬¡æ€§æ¨ç†åå·®ã€‚

3. **åŸºäºä¸ç¡®å®šæ€§èšåˆçš„ä¿¡å¿ƒæ§åˆ¶é€‰æ‹©æœºåˆ¶**ï¼ˆConfidence-Controlled Selection via Uncertainty Aggregationï¼‰
   - åœ¨ Selector é˜¶æ®µå¼•å…¥ **perplexity-based å†…éƒ¨ä¸€è‡´æ€§åº¦é‡**ï¼Œè·¨å¤šè½®é€‰æ‹©èšåˆç½®ä¿¡åˆ†æ•°ï¼›
   - ä½¿ç”¨ **Latin Square è®¾è®¡æ‰“ä¹±å€™é€‰é¡ºåº**ï¼Œæ¶ˆé™¤ä½ç½®åè§ï¼›
   - æœ€ç»ˆé€šè¿‡ä¸€è‡´æŠ•ç¥¨æˆ–ä»²è£å†³å®šæœ€ç»ˆç­”æ¡ˆï¼Œæå‡å†³ç­–ç¨³å®šæ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ReThinker ä¼˜åŠ¿ |
|------|----------------|
| **æ¨ç†è´¨é‡** | åŠ¨æ€é‡æ€è€ƒæœºåˆ¶æ˜¾è‘—å‡å°‘ä½çº§é”™è¯¯ï¼Œæå‡é€»è¾‘ä¸¥è°¨æ€§ |
| **å·¥å…·åˆ©ç”¨** | è‡ªé€‚åº”è°ƒç”¨å·¥å…·ï¼Œé¿å…å†—ä½™æˆ–æ— æ•ˆè°ƒç”¨ |
| **é²æ£’æ€§** | å¤šç»´åº¦åæ€ + ç½®ä¿¡åŠ æƒé€‰æ‹©ï¼ŒæŠ—å™ªå£°èƒ½åŠ›å¼º |
| **å¯æ‰©å±•æ€§** | æ— éœ€äººå·¥æ ‡æ³¨å³å¯ç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®ï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½² |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåœ¨ä¸‰ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä¸“å®¶çº§æ¨ç†åŸºå‡†ä¸Šè¿›è¡Œï¼š

| æ•°æ®é›† | æè¿° |
|--------|------|
| **HLE (Humanity's Last Exam)** | åŒ…å« 2,158 ä¸ªæ–‡æœ¬é¢˜ï¼Œè¦†ç›–æ•°å­¦ã€ç‰©ç†ã€åŒ–å­¦ç­‰å¤šä¸ªå­¦ç§‘ï¼Œå¼ºè°ƒæ·±å±‚å› æœæ¨ç†ä¸ç²¾ç¡®é€»è¾‘æ¨å¯¼ï¼›76%ä¸ºç²¾ç¡®åŒ¹é…çŸ­ç­”ï¼Œ24%ä¸ºå¤šé€‰é¢˜ã€‚ |
| **GAIA** | åŒ…å« 103 ä¸ªçœŸå®ä¸–ç•Œä»»åŠ¡ï¼Œéœ€ç»“åˆç½‘é¡µå¯¼èˆªã€è®¡ç®—å™¨ã€å¤šæ­¥è§„åˆ’å®Œæˆï¼Œåˆ†ä¸ºä¸‰çº§éš¾åº¦ï¼ˆLevel 1â€“3ï¼‰ã€‚ |
| **XBench-DeepSearch** | å« 100 ä¸ªä¸“ä¸šå¯¹é½çš„æ·±æœä»»åŠ¡ï¼Œè¦æ±‚è·¨æºä¿¡æ¯æ•´åˆä¸å¤æ‚æœç´¢ï¼Œæ¶µç›–å•†ä¸šã€ç§‘æŠ€ã€å¨±ä¹ç­‰é¢†åŸŸã€‚ |

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **è¯„ä¼°åè®®**ï¼šé‡‡ç”¨ **LLM-as-a-Judge** æ¡†æ¶ï¼š
  - HLE ä½¿ç”¨ `o3-mini-2025-01-31` åˆ¤æ–­ï¼›
  - GAIA å’Œ XBench ä½¿ç”¨ `gpt-4.1-2025-04-14`ã€‚
- **ä¸»å¹²æ¨¡å‹**ï¼šåˆ†åˆ«åŸºäº **Gemini-3-Pro** å’Œ **OpenPangu-72B** å®ç° ReThinkerã€‚
- **å…³é”®å‚æ•°**ï¼š
  - å¹¶è¡Œè·¯å¾„æ•°ï¼š5
  - ä¸Šä¸‹æ–‡é•¿åº¦ï¼š128K tokens
  - æ¸©åº¦ï¼š1.0ï¼ŒTop-pï¼šå…¨å±€ 1.0 / Selector ä¸­ 0.8
  - æœ€å¤§äº¤äº’æ­¥æ•°ï¼š50

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | åŸºçº¿æ–¹æ³• |
|------|---------|
| **åŸºç¡€æ¨¡å‹ + å·¥å…·** | GPT-5-high, Gemini-3-Pro, GLM-4.6, DeepSeek-V3.2 |
| **æ¨ç†æ¡†æ¶** | WebExplorer, OpenAI DeepResearch, Kimi Researcher, Tongyi DeepResearch, MiroThinker-v1.0 |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ–¹æ³• | HLE Score (%) | GAIA (%) | XBench-DeepSearch (%) |
|------|---------------|----------|------------------------|
| GPT-5-high | 35.2 | 76.4 | 77.8 |
| Gemini-3-Pro | 38.3 | 79.0 | 87.0 |
| MiroThinker-v1.0 | 33.4 | 73.5 | 70.6 |
| Tongyi DeepResearch | 32.9 | 70.9 | 75.0 |
| **ReThinker (OpenPangu-72B)** | **33.1** | **72.8** | **78.0** |
| **ReThinker (Gemini-3-Pro)** | **52.2** | **81.6** | **90.0** |

> âœ… **ReThinker (Gemini-3-Pro)** åœ¨æ‰€æœ‰ä¸‰é¡¹åŸºå‡†ä¸Šå‡è¾¾åˆ° **state-of-the-art æ€§èƒ½**ã€‚

#### å…·ä½“æå‡å¹…åº¦ï¼š
- åœ¨ **HLE** ä¸Šç›¸æ¯” Gemini-3-Pro æå‡ **+13.9pp**ï¼Œç›¸æ¯” GPT-5-high æå‡ **+16.9pp**ï¼›
- åœ¨ **GAIA** ä¸Šè¶…è¶Šæœ€å¼ºåŸºçº¿ **+2.6pp**ï¼›
- åœ¨ **XBench** ä¸Šè¾¾åˆ° **90.0%**ï¼Œé¢†å…ˆç¬¬äºŒå **3.0pp**ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆComponent Analysisï¼‰

#### Solver é˜¶æ®µï¼šé‡å›ç­”åˆæˆçš„ä½œç”¨
| é…ç½® | Pass@5 |
|------|--------|
| åˆå§‹ Solver | 38.00% |
| Re-Answer Solver | 39.40% |

ğŸ‘‰ è´¡çŒ® +1.4%ï¼Œè™½å°ä½†æœ‰æ•ˆé™ä½ä¸‹æ¸¸æ¨¡å—è´Ÿæ‹…ã€‚

#### Critic é˜¶æ®µï¼šå¼•å¯¼å¼åå°„çš„æ•ˆæœ
| è®¾ç½® | Pass@5 |
|------|--------|
| Re-Answer Solver | 39.40% |
| + Final Answer Only | 40.40% |
| + Summary Only | 42.00% |
| **+ Summary & Guidance** | **43.20%** |

ğŸ‘‰ **ç»“æ„åŒ–å¼•å¯¼æ˜¯æœ€å¤§è´¡çŒ®è€…**ï¼Œå¸¦æ¥ **+3.8%** æå‡ã€‚

#### Selector é˜¶æ®µï¼šä¿¡å¿ƒå¼•å¯¼é€‰æ‹©çš„å¢ç›Š
| é˜¶æ®µ | Hit Rate | Pass@1 |
|------|---------|--------|
| åˆå§‹åˆ¤æ–­ | 65.27% | 28.20% |
| + è¿­ä»£åˆ¤æ–­ | 68.05% | 29.40% |
| + Perplexity æŒ‡å¯¼ | 69.44% | 30.00% |
| + Latin Square æ’åº | **70.83%** | **30.60%** |

ğŸ‘‰ æ˜¾ç¤ºå‡ºå„ç»„ä»¶äº’è¡¥æ•ˆåº”ï¼Œå°¤å…¶ **perplexity æ˜¯å¯é çš„ä¸ç¡®å®šæ€§ä¿¡å·**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **åŠ¨æ€é‡æ€è€ƒä¼˜äºå›ºå®šæµç¨‹**ï¼šReThinker ä¸ä¾èµ–å•ä¸€æ¨ç†è·¯å¾„ï¼Œè€Œæ˜¯é€šè¿‡å¤šè½®è¿­ä»£ã€åæ€ä¸é€‰æ‹©ï¼Œæ˜¾è‘—æå‡å¤æ‚é—®é¢˜è§£å†³èƒ½åŠ›ã€‚
2. **ä¿¡å¿ƒæ§åˆ¶è‡³å…³é‡è¦**ï¼šåŸºäº **perplexity çš„ç½®ä¿¡ä¼°è®¡** å¯æœ‰æ•ˆè¯†åˆ«ä¸ç¡®å®šæ¡ˆä¾‹å¹¶è§¦å‘é¢å¤–è®¡ç®—ï¼Œå®ç°â€œæŒ‰éœ€æ‰©å±•â€ã€‚
3. **ä½ç½®åè§ä¸å¯å¿½è§†**ï¼šæœªä½¿ç”¨ Latin Square æ—¶ï¼Œæ¨¡å‹æ˜“å—å€™é€‰é¡ºåºå½±å“ï¼›å¼•å…¥åå¯æ¶ˆé™¤è¯¥åå·®ã€‚
4. **å¼ºåŸºåº•æ¨¡å‹æ”¾å¤§æ”¶ç›Š**ï¼šå½“ä» OpenPangu-72B å‡çº§åˆ° Gemini-3-Pro æ—¶ï¼ŒHLE åˆ†æ•°ä» 33.1 â†’ 52.2ï¼Œè¯´æ˜ ReThinker èƒ½æœ‰æ•ˆæ”¾å¤§å…ˆè¿›æ¨¡å‹æ½œåŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **å»¶è¿Ÿå¢åŠ **ï¼šç”±äºä¸‰é˜¶æ®µä¸²è¡Œæµç¨‹ï¼Œwall-clock time æ¯”å•æ¬¡æ¨ç†åŸºçº¿çº¦å¢åŠ  **1.5Ã—**ã€‚
2. **ä¸Šä¸‹æ–‡çª—å£é™åˆ¶**ï¼šå°½ç®¡æ”¯æŒ 128Kï¼Œä½†åœ¨æé•¿ç¨‹ç§‘å­¦ä»»åŠ¡ä¸­ä»å¯èƒ½ä¸è¶³ã€‚
3. **é€šç”¨å·¥å…·ä¾èµ–**ï¼šç›®å‰ä»…ä½¿ç”¨ web_searchã€web_parse å’Œ execute_python_codeï¼Œç¼ºä¹é¢†åŸŸä¸“ç”¨å·¥å…·ï¼ˆå¦‚ç¬¦å·å®šç†è¯æ˜å™¨ã€åˆ†å­æ€§è´¨é¢„æµ‹å™¨ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **å¹¶è¡ŒåŒ–é˜¶æ®µæ‰§è¡Œ**ï¼šæ¢ç´¢ Solver/Critic/Selector çš„éƒ¨åˆ†å¹¶è¡ŒåŒ–ä»¥é™ä½å»¶è¿Ÿï¼›
- **åŠ¨æ€ä¸Šä¸‹æ–‡ç®¡ç†**ï¼šå¼€å‘æ›´é«˜æ•ˆçš„ä¸Šä¸‹æ–‡å‹ç¼©ä¸æ£€ç´¢æœºåˆ¶ï¼›
- **é›†æˆä¸“ç”¨å·¥å…·é“¾**ï¼šå°† symbolic solversã€æ•°æ®åº“æŸ¥è¯¢å¼•æ“ç­‰åµŒå…¥æ¡†æ¶ï¼Œå¢å¼ºç‰¹å®šé¢†åŸŸæ¨ç†èƒ½åŠ›ï¼›
- **è½»é‡åŒ–ç‰ˆæœ¬è®¾è®¡**ï¼šç ”ç©¶é€‚ç”¨äºè¾¹ç¼˜è®¾å¤‡çš„å°è§„æ¨¡ ReThinker å˜ä½“ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **ReThinker é€šè¿‡â€œåæ€â€”æŒ‡å¯¼â€”ä¿¡å¿ƒæ§åˆ¶â€çš„é—­ç¯æœºåˆ¶ï¼Œåœ¨æ— éœ€äººå·¥æ ‡æ³¨çš„å‰æä¸‹å®ç°äº†ä¸“å®¶çº§ç§‘å­¦æ¨ç†èƒ½åŠ›çš„æ˜¾è‘—çªç ´ï¼Œä»£è¡¨äº†æ–°ä¸€ä»£ agentic reasoning æ¡†æ¶çš„é‡è¦è¿›å±•ã€‚**

</details>

---

### 13. [CoLT: Reasoning with Chain of Latent Tool Calls](https://arxiv.org/abs/2602.04246)

**Authors**: Fangwei Zhu, Zhifang Sui  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.04246v1  

#### Abstract
Chain-of-Thought (CoT) is a critical technique in enhancing the reasoning ability of Large Language Models (LLMs), and latent reasoning methods have been proposed to accelerate the inefficient token-level reasoning chain. We notice that existing latent reasoning methods generally require model struc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**CoLT: Reasoning with Chain of Latent Tool Calls**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜

ä¼ ç»Ÿçš„ **Chain-of-Thought (CoT)** æ¨ç†è™½ç„¶æå‡äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œä½†å…¶é€ token ç”Ÿæˆæ¨ç†é“¾çš„æ–¹å¼å¯¼è‡´æ¨ç†è¿‡ç¨‹å†—é•¿ã€è®¡ç®—æˆæœ¬é«˜ã€‚ä¸ºè§£å†³æ•ˆç‡é—®é¢˜ï¼Œå·²æœ‰ç ”ç©¶æå‡ºåœ¨**è¿ç»­éšç©ºé—´ï¼ˆlatent spaceï¼‰**ä¸­è¿›è¡Œæ¨ç†ï¼ˆå¦‚ Coconutã€CODIï¼‰ï¼Œå³â€œéšå¼ CoTâ€ï¼ˆimplicit CoTï¼‰ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¯¹æ¨¡å‹ç»“æ„è¿›è¡Œå¤§å¹…ä¿®æ”¹ï¼Œå¹¶ä¾èµ–å¤§é‡è®­ç»ƒï¼Œé™åˆ¶äº†å…¶é€šç”¨æ€§å’Œå®ç”¨æ€§ã€‚

æ­¤å¤–ï¼Œå®Œå…¨åœ¨éšç©ºé—´ä¸­æ¨ç†ä¼šç‰ºç‰²å¯è§£é‡Šæ€§â€”â€”äººç±»éš¾ä»¥ç†è§£å‘é‡å½¢å¼çš„ä¸­é—´æ­¥éª¤ã€‚

### âœ… æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

æœ¬æ–‡æå‡ºäº† **CoLTï¼ˆChain-of-Latent-Toolsï¼‰** æ¡†æ¶ï¼Œå°†éšå¼æ¨ç†å»ºæ¨¡ä¸ºä¸€ç§**å‚æ•°åŒ–çš„å·¥å…·è°ƒç”¨ï¼ˆparametric tool callï¼‰**ï¼Œæ ¸å¿ƒæ€æƒ³å¦‚ä¸‹ï¼š

- ä¸å†è®©ä¸»æ¨¡å‹å®Œå…¨åœ¨éšç©ºé—´ä¸­æ¨ç†ï¼Œè€Œæ˜¯å¼•å¯¼å…¶ç”Ÿæˆç‰¹æ®Šçš„â€œç§å­ tokenâ€ï¼ˆseed tokensï¼‰ï¼Œè¿™äº› token çš„éšè—çŠ¶æ€ï¼ˆhidden statesï¼‰ç¼–ç äº†ä¸€ä¸ªå®Œæ•´æ¨ç†æ­¥éª¤çš„ä¿¡æ¯ã€‚
- å½“ä¸»æ¨¡å‹ç”Ÿæˆä¸€ä¸ªä»¥ `<TRG>` ç»“å°¾çš„ seed token åºåˆ—æ—¶ï¼Œç³»ç»Ÿè§¦å‘ä¸€ä¸ªå¤–éƒ¨çš„ã€**å¯å¾®åˆ†çš„è§£ç å™¨ï¼ˆdecoderï¼‰**ï¼Œå°†è¿™äº›éšè—çŠ¶æ€è§£ç å›æ­£å¸¸çš„æ–‡æœ¬ tokenã€‚
- ä¸»æ¨¡å‹ç»§ç»­åŸºäºæ‰©å±•åçš„ä¸Šä¸‹æ–‡è¿›è¡Œæ¨ç†ï¼Œå½¢æˆâ€œç”Ÿæˆ seed â†’ è°ƒç”¨ decoder æ‰©å±• â†’ ç»§ç»­æ¨ç†â€çš„å¾ªç¯ã€‚

è¯¥æ¡†æ¶çš„å…³é”®åˆ›æ–°åœ¨äºï¼š
- å°†éšå¼æ¨ç†è§†ä¸ºâ€œå·¥å…·è°ƒç”¨â€ï¼Œå®ç°äº†**æ˜¾å¼æ–‡æœ¬æ¨ç†ä¸éšå¼å‹ç¼©çš„ç»“åˆ**ã€‚
- å¤–éƒ¨ decoder æ˜¯**å¯å¾®åˆ†ç¥ç»æ¨¡å—**ï¼Œæ”¯æŒç«¯åˆ°ç«¯è®­ç»ƒå’Œæ¢¯åº¦åä¼ ï¼Œå…è®¸è”åˆä¼˜åŒ–ä¸»æ¨¡å‹ä¸ decoderã€‚
- ä¸»æ¨¡å‹å§‹ç»ˆåœ¨**åŸå§‹æ–‡æœ¬ç©ºé—´ä¸­æ“ä½œ**ï¼Œä¿ç•™äº†å…¶é¢„è®­ç»ƒèƒ½åŠ›ä¸æ¨ç†å¯è§£é‡Šæ€§ã€‚

### âœ… ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | CoLT çš„ä¼˜åŠ¿ |
|------|------------|
| **æ¨¡å‹å…¼å®¹æ€§** | æ— éœ€ä¿®æ”¹ä¸»æ¨¡å‹ç»“æ„ï¼Œé€‚ç”¨äºæ ‡å‡† decoder-only æ¶æ„ï¼ˆå¦‚ Llamaã€Qwenï¼‰ã€‚ |
| **è®­ç»ƒæ•ˆç‡** | ä»…éœ€ 2 ä¸ª epoch çš„ç›‘ç£è®­ç»ƒå³å¯è¶…è¶Šéœ€å¤æ‚è®­ç»ƒæµç¨‹çš„ baselineã€‚ |
| **å¯è§£é‡Šæ€§** | æœ€ç»ˆæ¨ç†é“¾ç”±çœŸå®æ–‡æœ¬ token æ„æˆï¼Œè€Œéé»‘ç›’å‘é‡ã€‚ |
| **å¼ºåŒ–å­¦ä¹ å…¼å®¹æ€§** | æ”¯æŒé‡‡æ ·çš„ decoder å¯ä½¿æ•´ä¸ªè¿‡ç¨‹å˜ä¸ºå¤šè½®å¯¹è¯ï¼Œå¤©ç„¶é€‚é… GRPO ç­‰ RL ç®—æ³•ã€‚ |
| **çµæ´»æ€§** | æ”¯æŒå¤šç§ decoder ç»“æ„ï¼ˆTransformerã€RNNã€multi-hotï¼‰ï¼Œæ˜“äºæ‰©å±•ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

- **GSM8k-Aug**ï¼šGSM8k çš„å¢å¼ºç‰ˆï¼Œä½¿ç”¨æ•°å­¦è¡¨è¾¾å¼ï¼ˆå¦‚ `ã€Š25/5=5ã€‹`ï¼‰æ›¿ä»£è‡ªç„¶è¯­è¨€æ¨ç†æ­¥éª¤ï¼Œä½œä¸º**é¢†åŸŸå†…ï¼ˆin-domainï¼‰åŸºå‡†**ã€‚
- **GSM-Hard**ï¼šGSM8k æµ‹è¯•é›†çš„å›°éš¾ç‰ˆæœ¬ï¼Œä½¿ç”¨æ›´å¤§æ•°å­—å¢åŠ éš¾åº¦ã€‚
- **SVAMP** å’Œ **MultiArith**ï¼šå°å­¦ç®—æœ¯æ–‡å­—é¢˜æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°**è·¨åŸŸæ³›åŒ–èƒ½åŠ›**ã€‚
- **MATH**ï¼šæ›´å…·æŒ‘æˆ˜æ€§çš„æ•°å­¦é—®é¢˜æ•°æ®é›†ï¼Œç”¨äºéªŒè¯å¼ºåŒ–å­¦ä¹ æ•ˆæœã€‚

### âš™ï¸ å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### ä¸»å¹²æ¨¡å‹
- ä½¿ç”¨ **Llama-3.2-1B-Instruct** å’Œ **DeepSeek-R1-Distill-Qwen-1.5B** ä½œä¸º backboneã€‚
- CoLT æ¨¡å‹ä»åŸå§‹é¢„è®­ç»ƒæƒé‡å¼€å§‹è®­ç»ƒï¼Œä¸ä¾èµ– SFT åˆå§‹åŒ–ã€‚

#### Seed Tokens
- ä½¿ç”¨ç‰¹æ®Š token è¡¨ç¤ºï¼š
  - `<BDY>`ï¼šbody tokenï¼Œæºå¸¦ä¿¡æ¯ã€‚
  - `<TRG>`ï¼štrigger tokenï¼ŒæŒ‡ç¤ºè°ƒç”¨ decoder å¹¶é€‰æ‹©å…·ä½“ decoder ç±»å‹ã€‚

#### Decoder è®¾è®¡
- é»˜è®¤ä½¿ç”¨ **1 å±‚ Transformer decoder**ï¼Œå‚æ•°åˆå§‹åŒ–è‡ªä¸»æ¨¡å‹å‰å‡ å±‚ã€‚
- æ”¯æŒå…¶ä»–ç»“æ„ï¼šRNN decoderã€multi-hot decoderï¼ˆä»…è§£ç æ•°å­—ï¼‰ã€‚

#### è®­ç»ƒæ–¹å¼
- **ç›‘ç£è®­ç»ƒï¼ˆSFTï¼‰**ï¼š2 ä¸ª epochï¼ŒAdamW ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ 1e-5ã€‚
- **å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰**ï¼šé‡‡ç”¨ **Group Relative Policy Optimization (GRPO)**ï¼Œåœ¨ SFT åè¿›è¡Œ 1 ä¸ª epoch çš„ RL å¾®è°ƒã€‚

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Accuracy (Acc.)** | æ­£ç¡®è§£ç­”é—®é¢˜çš„æ¯”ä¾‹ï¼Œè¡¡é‡æ¨ç†èƒ½åŠ›ã€‚ |
| **Reasoning chain length (#L)** | æ¨ç†é“¾é•¿åº¦ï¼ˆè€ƒè™‘ seed + 1 çš„å…¬å¹³è®¡ç®—ï¼‰ï¼Œè¡¡é‡æ¨ç†æ•ˆç‡ã€‚ |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **CoT** | æ˜¾å¼æ¨ç† | é€ token ç”Ÿæˆå®Œæ•´æ¨ç†é“¾ï¼Œå‡†ç¡®ä½†ä½æ•ˆã€‚ |
| **iCoT / Coconut** | éšå¼æ¨ç† | ç”¨ latent token æ›¿ä»£æ¨ç†æ­¥éª¤ï¼Œéœ€ curriculum learningã€‚ |
| **CODI / COLAR / SIM-CoT** | é«˜çº§éšå¼æ¨ç† | å¼•å…¥è‡ªè’¸é¦ã€åˆ†å¸ƒå»ºæ¨¡æˆ–æ­¥çº§ç›‘ç£ï¼Œæå‡ç¨³å®šæ€§ã€‚ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| æ–¹æ³• | GSM8k-Aug Acc. | #L | GSM-Hard Acc. | #L | Average Acc. | Avg #L |
|------|----------------|-----|---------------|-----|----------------|--------|
| CoT | 49.4 | 25.6 | 11.9 | 34.2 | 53.6 | 21.4 |
| COLAR(2x) | 40.1 | 12.7 | 9.08 | 14.0 | 48.8 | 10.0 |
| **CoLT (1seed)** | **45.3** | **7.73** | **10.3** | **7.74** | **49.3** | **6.33** |
| **CoLT (2seed)** | **45.5** | 10.84 | **10.8** | 10.61 | **49.6** | 8.70 |

> âœ… **CoLT åœ¨å¹³å‡å‡†ç¡®ç‡ä¸Šæ¥è¿‘ CoTï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰éšå¼æ–¹æ³•ï¼›åŒæ—¶æ¨ç†é“¾é•¿åº¦ä»…ä¸º CoT çš„ ~30%ï¼Œè¿œçŸ­äº COLAR ç­‰æ–¹æ³•ã€‚**

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

- **ç›¸æ¯” COLAR(2x)**ï¼šCoLT å‡†ç¡®ç‡é«˜å‡ºçº¦ **5%**ï¼Œä¸”æ¨ç†é•¿åº¦æ›´çŸ­ï¼ˆ7.73 vs 12.7ï¼‰ã€‚
- **ç›¸æ¯” SIM-CoT**ï¼šCoLT åœ¨å¯æ¯”è¾ƒä»»åŠ¡ä¸Šè¡¨ç°æ›´å¥½ï¼Œä¸”æ— éœ€æŠ¥å‘Š out-of-domain latent lengthã€‚
- **åœ¨ MultiArith ä¸Š**ï¼šCoLT(2seed) è¾¾åˆ° **93.9%**ï¼Œç”šè‡³è¶…è¿‡ç›‘ç£å¼ CoTï¼ˆ93.2%ï¼‰ï¼Œæ˜¾ç¤ºå¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰Decoder å±‚æ•°ä¸ Seed æ•°é‡çš„å½±å“ï¼ˆFigure 2ï¼‰
- å¢åŠ  decoder å±‚æ•°æˆ– seed æ•°é‡å¯å°å¹…æå‡å‡†ç¡®ç‡ï¼ˆæœ€é«˜è¾¾ 2% å·®è·ï¼‰ï¼Œä½†æ”¶ç›Šé€’å‡ã€‚
- æ›´å¤§çš„ decoder å¸¦æ¥æ›´é«˜è®¡ç®—å¼€é”€ï¼Œå› æ­¤é»˜è®¤ä½¿ç”¨æœ€å°é…ç½®ï¼ˆ1 å±‚ + 1 seedï¼‰ã€‚

#### ï¼ˆ2ï¼‰ä¸åŒ decoder ç»“æ„å¯¹æ¯”ï¼ˆTable 2ï¼‰

| Decoder ç±»å‹ | Average Acc. | Avg #L |
|--------------|---------------|--------|
| Transformerï¼ˆé»˜è®¤ï¼‰ | **49.3** | **6.33** |
| RNN | 30.9 | 6.55 |
| Multi-hot* | 28.2 | 32.3 |

> âœ… Transformer decoder æ€§èƒ½æœ€ä¼˜ï¼›RNN æœ‰ä¸€å®šå¯è¡Œæ€§ï¼›multi-hot å› åŠŸèƒ½å—é™è¡¨ç°å·®ï¼Œä½†è¯æ˜äº†é Transformer decoder çš„å¯èƒ½æ€§ã€‚

#### ï¼ˆ3ï¼‰å¼ºåŒ–å­¦ä¹ æ•ˆæœï¼ˆTable 3 & 5ï¼‰

| æ–¹æ³• | GSM8k-Aug Acc. | #L |
|------|----------------|-----|
| CoLT (SFT) | 45.3 | 7.73 |
| **CoLT + RL** | **48.9** | 7.73 |

> âœ… å¼ºåŒ–å­¦ä¹ è¿›ä¸€æ­¥å°†å‡†ç¡®ç‡æå‡è‡³ **48.9%**ï¼Œæ¥è¿‘ CoT æ°´å¹³ï¼Œä¸”æœªå¢åŠ æ¨ç†é•¿åº¦ã€‚

åœ¨ MATH æ•°æ®é›†ä¸Šä¹Ÿè§‚å¯Ÿåˆ°ç±»ä¼¼è¶‹åŠ¿ï¼Œè¯´æ˜ CoLT å…¼å®¹ RL ä¸”èƒ½é€šè¿‡æ¢ç´¢æ”¹è¿›ç­–ç•¥ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **éšå¼æ¨ç†å¯ä»¥è¢«å»ºæ¨¡ä¸ºâ€œå·¥å…·è°ƒç”¨â€**ï¼šé€šè¿‡ seed token å’Œå¯å¾® decoder çš„ç»„åˆï¼Œå®ç°é«˜æ•ˆã€å¯è§£é‡Šã€å¯è®­ç»ƒçš„æ¨ç†åŠ é€Ÿã€‚
2. **ä¸»æ¨¡å‹æ— éœ€è¿›å…¥éšç©ºé—´**ï¼šä¿æŒåœ¨æ–‡æœ¬ token ç©ºé—´ä¸­æ¨ç†ï¼Œæ—¢ä¿ç•™äº†é¢„è®­ç»ƒèƒ½åŠ›ï¼Œåˆæé«˜äº†é²æ£’æ€§å’Œæ³›åŒ–æ€§ã€‚
3. **æç®€è®­ç»ƒå³å¯è¶…è¶Šå¤æ‚æ–¹æ³•**ï¼šä»… 2 è½® SFT å³è¶…è¶Šéœ€å¤æ‚è®­ç»ƒæµç¨‹çš„ baselineã€‚
4. **å¤©ç„¶æ”¯æŒå¼ºåŒ–å­¦ä¹ **ï¼šé€šè¿‡é‡‡æ ·æœºåˆ¶æ„å»ºå¤šè·¯å¾„æ¨ç†ï¼ŒæˆåŠŸåº”ç”¨ GRPO æå‡æ€§èƒ½ã€‚
5. **decoder ç»“æ„å…·æœ‰æ¢ç´¢ç©ºé—´**ï¼šå°½ç®¡ Transformer æœ€ä¼˜ï¼Œä½† RNN ç­‰æ›¿ä»£æ–¹æ¡ˆä»å…·æ½œåŠ›ï¼Œå°¤å…¶åœ¨ç‰¹å®šä»»åŠ¡ä¸­ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

- **å½“å‰èšç„¦æ•°å­¦æ¨ç†ä»»åŠ¡**ï¼šseed token çš„ç²’åº¦ï¼ˆå¦‚æ¯æ¡å…¬å¼ï¼‰åœ¨ GSM8k-Aug ä¸­æ˜ç¡®ï¼Œä½†åœ¨æ›´å¤æ‚ä»»åŠ¡ä¸­å¦‚ä½•åˆ’åˆ†â€œåˆç†æ¨ç†æ­¥â€å°šä¸æ¸…æ™°ã€‚
- **seed token å®¹é‡æœ‰é™**ï¼šå•ä¸ªæˆ–å°‘é‡ token å¯èƒ½æ— æ³•æ‰¿è½½è¿‡é•¿æˆ–å¤æ‚çš„æ¨ç†å†…å®¹ã€‚
- **decoder è®¾è®¡å°šæœªå……åˆ†æ¢ç´¢**ï¼šç›®å‰ decoder å¤šæ¨¡ä»¿ä¸»æ¨¡å‹ç»“æ„ï¼Œæœªæ¥å¯è®¾è®¡æ›´è½»é‡æˆ–ä¸“ç”¨ç»“æ„ã€‚
- **å®éªŒé›†ä¸­åœ¨ä¸­å°è§„æ¨¡æ¨¡å‹**ï¼šåœ¨æ›´å¤§æ¨¡å‹ï¼ˆå¦‚ 70B+ï¼‰ä¸Šçš„æ‰©å±•æ€§å’Œç¨³å®šæ€§æœ‰å¾…éªŒè¯ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ¢ç´¢æ›´ä¼˜ decoder ç»“æ„**ï¼šé’ˆå¯¹å®ä½“æ£€ç´¢ã€ä»£ç ç”Ÿæˆç­‰ä»»åŠ¡è®¾è®¡ä¸“ç”¨ decoderã€‚
2. **åŠ¨æ€å†³å®š tool call è¾¹ç•Œ**ï¼šè®©æ¨¡å‹è‡ªåŠ¨åˆ¤æ–­ä½•æ—¶å‹ç¼©ã€å‹ç¼©å¤šå°‘å†…å®¹ã€‚
3. **è·¨æ¨¡æ€æ‰©å±•**ï¼šåœ¨ MLLM ä¸­å¼•å…¥â€œlatent visual tool callsâ€ï¼Œç”¨éšå‘é‡è§¦å‘å›¾åƒç”Ÿæˆæˆ–è§†è§‰æ¨ç†ã€‚
4. **ä¸­é—´å±‚ hidden states åˆ©ç”¨**ï¼šå°è¯•ä»éæœ€åä¸€å±‚æå– seed embeddingsï¼Œå¯èƒ½æ•æ‰æ›´ä¸°å¯Œè¯­ä¹‰ã€‚
5. **åº”ç”¨äºéæ•°å­¦ç±»å¤æ‚æ¨ç†ä»»åŠ¡**ï¼šå¦‚é€»è¾‘æ¨ç†ã€ç§‘å­¦é—®ç­”ã€è§„åˆ’ç­‰ã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **CoLT æå‡ºäº†ä¸€ç§æ–°é¢–è€Œå®ç”¨çš„æ¡†æ¶ï¼Œå°†éšå¼æ¨ç†è½¬åŒ–ä¸ºâ€œå¯å¾®å·¥å…·è°ƒç”¨â€ï¼Œåœ¨ä¸ç‰ºç‰²å¯è§£é‡Šæ€§å’Œé¢„è®­ç»ƒèƒ½åŠ›çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†æ¨ç†æ•ˆç‡ä¸å‡†ç¡®æ€§ï¼Œä¸”å¤©ç„¶å…¼å®¹å¼ºåŒ–å­¦ä¹ ï¼Œä¸ºé«˜æ•ˆã€å¯æ§çš„ LLM æ¨ç†æä¾›äº†æ–°èŒƒå¼ã€‚**

</details>

---

### 14. [Guided Verifier: Collaborative Multimodal Reasoning via Dynamic Process Supervision](https://arxiv.org/abs/2602.04290)

**Authors**: Lingzhuang Sun, Ruitong Liu, Yuxia Zhu, Xiaohan Xu, Jingxuan Wei, Xiangxiang Zhang, Bihui Yu, Wentao Zhang  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.04290v1  

#### Abstract
Reinforcement Learning (RL) has emerged as a pivotal mechanism for enhancing the complex reasoning capabilities of Multimodal Large Language Models (MLLMs). However, prevailing paradigms typically rely on solitary rollout strategies where the model works alone. This lack of intermediate oversight re...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šGuided Verifier: Collaborative Multimodal Reasoning via Dynamic Process Supervision

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº **Reinforcement Learning (RL)** çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆ**Multimodal Large Language Models, MLLMs**ï¼‰æ¨ç†æ¡†æ¶ï¼ˆå¦‚ **GRPO**ï¼‰é€šå¸¸é‡‡ç”¨â€œå­¤ç«‹ç”Ÿæˆâ€ï¼ˆsolitary rolloutï¼‰ç­–ç•¥ï¼Œå³æ¨¡å‹ç‹¬ç«‹å®Œæˆæ•´ä¸ªæ¨ç†é“¾åæ‰è·å¾—æœ€ç»ˆå¥–åŠ±ä¿¡å·ã€‚è¿™ç§**å»¶è¿Ÿä¸”ç¨€ç–çš„ç»ˆç«¯åé¦ˆ**å¯¼è‡´ä»¥ä¸‹é—®é¢˜ï¼š
- **é”™è¯¯ä¼ æ’­ï¼ˆerror propagationï¼‰**ï¼šæ—©æœŸé€»è¾‘åå·®ä¼šç´¯ç§¯å¹¶å¯¼è‡´ä¸å¯é€†çš„å¤±è´¥ã€‚
- **å™ªå£°ä¼˜åŒ–ä¿¡å·**ï¼šå¤§é‡æ— æ•ˆè½¨è¿¹é™ä½äº†è®­ç»ƒç¨³å®šæ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡º **Guided Verifier æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ¨ç†è¿‡ç¨‹ä»â€œå•å‘æ¢ç´¢â€è½¬å˜ä¸ºâ€œåä½œé—­ç¯â€ç³»ç»Ÿã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼š

1. **åŠ¨æ€éªŒè¯å™¨ï¼ˆDynamic Verifierï¼‰**  
   ä¸€ä¸ªè½»é‡çº§çš„ **Verifier** æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­å®æ—¶ä¸ä¸»ç­–ç•¥æ¨¡å‹ï¼ˆPolicy Modelï¼‰äº¤äº’ï¼Œæ£€æµ‹ä¸­é—´æ­¥éª¤ä¸­çš„ä¸ä¸€è‡´ï¼Œå¹¶æä¾›æ–¹å‘æ€§æŒ‡å¯¼ä¿¡å·ï¼Œå¼•å¯¼ç­–ç•¥æ¨¡å‹èµ°å‘æ­£ç¡®çš„æ¨ç†è·¯å¾„ã€‚

2. **ååŒæ¨ç†æœºåˆ¶ï¼ˆCollaborative Inferenceï¼‰**  
   æ¨ç†ä¸å†æ˜¯å•å‘ç”Ÿæˆï¼Œè€Œæ˜¯ **Policy** å’Œ **Verifier** åŒæ–¹çš„å¤šè½®å¯¹è¯ã€‚Verifier åœ¨æ¯ä¸€æ­¥æä¾›åé¦ˆï¼ˆå¦‚çº æ­£é”™è¯¯ã€ç¡®è®¤æ­£ç¡®æ­¥éª¤ï¼‰ï¼Œå½¢æˆä¸€ä¸ª**é—­ç¯æ§åˆ¶ç³»ç»Ÿ**ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **ä¸»åŠ¨çº é”™**ï¼šä¸åŒäºä¼ ç»Ÿ **Reward Model** ä»…ä½œä¸ºäº‹åè¯„åˆ¤è€…ï¼ŒVerifier æ˜¯æ¨ç†è¿‡ç¨‹çš„**ç§¯æå‚ä¸è€…**ï¼Œèƒ½å®æ—¶å¹²é¢„ã€‚
- **ç¼“è§£é”™è¯¯ä¼ æ’­**ï¼šé€šè¿‡ä¸­é—´ç›‘ç£ï¼Œæœ‰æ•ˆæŠ‘åˆ¶äº†é”™è¯¯çš„ç´¯ç§¯ã€‚
- **é«˜è´¨é‡å­¦ä¹ ä¿¡å·**ï¼šå³ä½¿åˆå§‹è½¨è¿¹æœ‰è¯¯ï¼ŒVerifier çš„å¼•å¯¼ä¹Ÿèƒ½å°†å…¶ä¿®æ­£ä¸ºæœ‰æ•ˆæ ·æœ¬ï¼Œä»è€Œæ‰©å±•äº†å¯å­¦ä¹ çš„è½¨è¿¹ç©ºé—´ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **è®­ç»ƒæ•°æ®é›†**ï¼š
  - **CoRe Dataset**ï¼šä½œè€…æ„å»ºçš„ä¸“é—¨ç”¨äºè®­ç»ƒ Verifier çš„åˆæˆæ•°æ®é›†ï¼ŒåŒ…å«çº¦ 2,792 æ¡å¤šè½®å¯¹è¯è½¨è¿¹ï¼Œæ¶µç›– 26,360 ä¸ªæ­¥éª¤çº§åˆ«çš„ç›‘ç£ä¿¡å·ï¼ˆå«æ­£è´Ÿæ ·æœ¬ï¼‰ã€‚
  - **Geometry-3k**ï¼šç”¨äº **Guided-GRPO** é˜¶æ®µçš„ RL è®­ç»ƒã€‚
- **è¯„ä¼°åŸºå‡†ï¼ˆBenchmarksï¼‰**ï¼š
  - **MathVista**ï¼šè¯„ä¼°æ•°å­¦è§†è§‰æ¨ç†èƒ½åŠ›ã€‚
  - **MathVerse**ï¼šç»†ç²’åº¦æµ‹è¯•ä¸åŒä¿¡æ¯å¯†åº¦ä¸‹çš„è¡¨ç°ï¼ˆæ–‡æœ¬ä¸»å¯¼ã€è§†è§‰å¯†é›†ç­‰ï¼‰ã€‚
  - **MMMU**ï¼šç»¼åˆè¯„ä¼°å¤šæ¨¡æ€ç†è§£ä¸æ¨ç†çš„é€šç”¨èƒ½åŠ›ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹åˆå§‹åŒ–**ï¼šPolicy å’Œ Verifier å‡åŸºäº **Qwen3-VL-8B-Instruct** åˆå§‹åŒ–ã€‚
- **è®­ç»ƒæµç¨‹ä¸‰é˜¶æ®µ**ï¼š
  1. **CoRe æ•°æ®åˆæˆ**ï¼šæ¨¡æ‹Ÿ Solver ä¸ Guide çš„å¤šè½®å¯¹è¯ï¼Œç”Ÿæˆå¸¦å¹»è§‰æ ‡æ³¨çš„è®­ç»ƒæ•°æ®ã€‚
  2. **Verifier SFT**ï¼šåœ¨ CoRe æ•°æ®ä¸Šå¯¹ Verifier è¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuningï¼‰ã€‚
  3. **Guided-GRPO è®­ç»ƒ**ï¼šå†»ç»“ Verifierï¼Œä¸ Policy ååŒè¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼šä¸»è¦ä½¿ç”¨å‡†ç¡®ç‡ï¼ˆAccuracy %ï¼‰è¿›è¡Œæ¯”è¾ƒã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **é—­æºæ¨¡å‹ï¼ˆProprietary Modelsï¼‰**ï¼š
  - GPT-4o, Gemini-2.5-Pro, Claude-4-Sonnet, Qwen-VL-Max
- **å¼€æºæ¨¡å‹ï¼ˆOpen-Source Modelsï¼‰**ï¼š
  - Qwen2.5-VL-32B, InternVL2.5-26B, LLaVA-v1.5-13B, Phi-3-vision-128k ç­‰ã€‚
- **æ–¹æ³•å­¦åŸºçº¿ï¼ˆMethodological Baselinesï¼‰**ï¼š
  - **Base (Qwen3-8B)**ï¼šé›¶æ ·æœ¬åŸºçº¿ã€‚
  - **Vision-R1-32B, MMR1-32B, VL-Rethinker-7B**ï¼šå…¶ä»– GRPO æ–¹æ³•ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
åœ¨å¤šä¸ªåŸºå‡†ä¸Šçš„å‡†ç¡®ç‡è¡¨ç°å¦‚ä¸‹ï¼ˆæ‘˜è‡ª Table 1ï¼‰ï¼š

| Model | MathVerse (Overall) | MathVista (Overall) | MMMU (Val) |
|-------|---------------------|---------------------|-----------|
| **GPT-4o** | 48.88 | 69.23 | 67.33 |
| **Gemini-2.5-Pro** | 50.76 | 79.33 | 78.78 |
| **Ours (Guided-GRPO)** | **51.07** | **77.88** | **72.11** |
| **Base (Qwen3-8B)** | 46.83 | 67.31 | 62.44 |

> âœ… **ç»“æœäº®ç‚¹**ï¼šæå‡ºçš„ **8B å‚æ•°æ¨¡å‹**åœ¨ **MathVerse** ä¸Šè¶…è¶Šäº† GPT-4oï¼Œåœ¨ **MathVista** å’Œ **MMMU** ä¸Šæ¥è¿‘ Gemini-2.5-Proï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–å¼€æºæ¨¡å‹ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **å…¨é¢é¢†å…ˆ**ï¼šGuided-GRPO åœ¨æ‰€æœ‰åŸºå‡†ä¸Šå‡ä¼˜äºåŒè§„æ¨¡æˆ–æ›´å¤§è§„æ¨¡çš„å¼€æºæ¨¡å‹ï¼ˆå¦‚ Qwen2.5-VL-32Bï¼‰ã€‚
- **å°æ¨¡å‹åª²ç¾å¤§æ¨¡å‹**ï¼š8B æ¨¡å‹çš„è¡¨ç°ç”šè‡³è¶…è¿‡äº†éƒ¨åˆ† 32B ä»¥ä¸Šçš„æ¨¡å‹ï¼Œè¯æ˜äº†**è®¡ç®—èµ„æºåˆ†é…ç»™åä½œæ¨ç†æ¯”å•çº¯æ‰©å¤§æ¨¡å‹è§„æ¨¡æ›´é«˜æ•ˆ**ã€‚

### æ¶ˆèå®éªŒç»“æœ
é€šè¿‡ Table 2 çš„æ¶ˆèç ”ç©¶ï¼ŒéªŒè¯äº†å„ç»„ä»¶çš„è´¡çŒ®ï¼š

| è®¾ç½® | MathVista å‡†ç¡®ç‡ |
|------|----------------|
| **Qwen3-VL-8B (Base)** | 67.31 |
| + æœªè®­ç»ƒçš„ Verifier (Naive) | 69.75 |
| + SFT è®­ç»ƒçš„ Verifier | 70.67 |
| + **Guided-GRPO (å®Œæ•´æ–¹æ³•)** | **77.88** |

> ğŸ” **å…³é”®å‘ç°**ï¼š
> - ä»…å¼•å…¥ Verifier è€Œä¸è¿›è¡Œä¸“é—¨è®­ç»ƒï¼Œæå‡æœ‰é™ã€‚
> - **Verifier çš„ SFT è®­ç»ƒè‡³å…³é‡è¦**ï¼Œä½¿å…¶å…·å¤‡æœ‰æ•ˆçš„çº é”™èƒ½åŠ›ã€‚
> - **Guided-GRPO è®­ç»ƒæ˜¯æœ€å¤§å¢ç›Šæ¥æº**ï¼Œè¡¨æ˜ç­–ç•¥æ¨¡å‹éœ€è¦åœ¨ RL ä¸­å†…åŒ–æ¥è‡ª Verifier çš„æŒ‡å¯¼ä¿¡å·ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é—­ç¯åä½œä¼˜äºå¼€ç¯ç”Ÿæˆ**ï¼šGuided Verifier å°†æ¨ç†è¿‡ç¨‹ä»â€œç›²ç›®æ¢ç´¢â€è½¬å˜ä¸ºâ€œæœ‰æŒ‡å¯¼çš„å¯¼èˆªâ€ï¼Œæ˜¾è‘—æå‡äº†é•¿ç¨‹æ¨ç†çš„å¯é æ€§ã€‚
2. **Verifier èƒ½åŠ›éœ€ä¸“é—¨è®­ç»ƒ**ï¼šæ›´å¼ºçš„æ¨ç†æ¨¡å‹ï¼ˆå¦‚ RL è®­ç»ƒåçš„ Policyï¼‰å¹¶ä¸å¤©ç„¶æˆä¸ºæ›´å¥½çš„ Verifierã€‚**éªŒè¯èƒ½åŠ›æ˜¯ä¸€ç§æ­£äº¤æŠ€èƒ½**ï¼Œå¿…é¡»é€šè¿‡ä¸“é—¨çš„ **Guide-and-Correction** åè®®è¿›è¡Œå¯¹é½ã€‚
3. **è®¡ç®—æ•ˆç‡æ›´é«˜**ï¼šå°½ç®¡åŒæ¨¡å‹åä½œå¢åŠ äº† token æ¶ˆè€—ï¼Œä½†å…¶å¸¦æ¥çš„æ€§èƒ½æå‡è¿œè¶…æˆæœ¬ã€‚ç›¸æ¯”ç›²ç›®æ‰©å¤§æ¨¡å‹å‚æ•°ï¼Œ**å°†ç®—åŠ›ç”¨äºåŠ¨æ€éªŒè¯æ›´å…·æ€§ä»·æ¯”**ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **Verifier è‡ªèº«å¯èƒ½äº§ç”Ÿå¹»è§‰**ï¼šå¦‚æœ Verifier é”™è¯¯åœ°å¦å®šäº†æ­£ç¡®çš„æ¨ç†æ­¥éª¤ï¼ˆå‡é˜³æ€§ï¼‰ï¼Œå¯èƒ½å¯¼è‡´ç­–ç•¥æ¨¡å‹è¢«è¯¯å¯¼ï¼ˆè§ **Failure Mode I: Misguided Correction**ï¼‰ã€‚
2. **è®¤çŸ¥åƒµåŒ–ï¼ˆCognitive Rigidityï¼‰**ï¼šVerifier å¯èƒ½åªæ¥å—è‡ªå·±é¢„è®¾çš„è§£é¢˜è·¯å¾„ï¼Œæ‹’ç»å…¶ä»–åŒæ ·æ­£ç¡®çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå¯¼è‡´ä¸å¿…è¦çš„äº¤äº’å¾ªç¯ï¼ˆè§ **Failure Mode II: Verification Inefficiency**ï¼‰ã€‚
3. **ä¾èµ–é«˜è´¨é‡åˆæˆæ•°æ®**ï¼šVerifier çš„æœ‰æ•ˆæ€§é«˜åº¦ä¾èµ–äº **CoRe æ•°æ®é›†**çš„è´¨é‡ï¼Œè€Œè¯¥æ•°æ®é›†çš„æ„å»ºæœ¬èº«éœ€è¦ç²¾å¿ƒè®¾è®¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æé«˜ Verifier çš„é²æ£’æ€§ï¼Œå‡å°‘å‡é˜³æ€§ï¼Œé¿å…â€œæœ‰æ¯’æŒ‡å¯¼â€ã€‚
- è®¾è®¡æ›´çµæ´»çš„ Verifierï¼Œèƒ½å¤Ÿè¯†åˆ«å¤šç§ç­‰æ•ˆçš„æ­£ç¡®è§£æ³•è·¯å¾„ã€‚
- å°†è¯¥æ¡†æ¶æ‰©å±•åˆ°æ›´å¤šä»»åŠ¡é¢†åŸŸï¼ˆå¦‚ä»£ç ç”Ÿæˆã€ç§‘å­¦æ¨ç†ç­‰ï¼‰ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„åŒæ¨¡å‹ååŒæ¶æ„ï¼Œè¿›ä¸€æ­¥é™ä½æ¨ç†å»¶è¿Ÿã€‚

> ğŸ’¡ **æ€»ç»“**ï¼šGuided Verifier æ¡†æ¶é€šè¿‡å¼•å…¥**åŠ¨æ€åä½œæœºåˆ¶**ï¼Œä»æ ¹æœ¬ä¸Šæ”¹å˜äº† MLLMs çš„æ¨ç†èŒƒå¼ï¼Œä¸ºè§£å†³å¤æ‚å¤šæ­¥æ¨ç†ä¸­çš„é”™è¯¯ä¼ æ’­é—®é¢˜æä¾›äº†æ–°çš„æœ‰æ•ˆè·¯å¾„ã€‚

</details>

---

### 15. [Model-Dowser: Data-Free Importance Probing to Mitigate Catastrophic Forgetting in Multimodal Large Language Models](https://arxiv.org/abs/2602.04509)

**Authors**: Hyeontaek Hwang, Nguyen Dinh Son, Daeyoung Kim  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.04509v1  

#### Abstract
Fine-tuning Multimodal Large Language Models (MLLMs) on task-specific data is an effective way to improve performance on downstream applications. However, such adaptation often leads to a degradation in generalization on pretrained tasks, a phenomenon known as Catastrophic Forgetting. Existing metho...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šModel-Dowser: Data-Free Importance Probing to Mitigate Catastrophic Forgetting in Multimodal Large Language Models**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
Multimodal Large Language Models (MLLMs) åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¿›è¡Œ fine-tuning æ—¶ï¼Œå¸¸å¸¸ä¼šé­é‡ **Catastrophic Forgetting**ï¼ˆç¾éš¾æ€§é—å¿˜ï¼‰ï¼Œå³æ¨¡å‹åœ¨æå‡ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½çš„åŒæ—¶ï¼Œä¸¥é‡ä¸¢å¤±å…¶åœ¨é¢„è®­ç»ƒé˜¶æ®µè·å¾—çš„é€šç”¨æ³›åŒ–èƒ½åŠ›ã€‚è¿™ä¸€é—®é¢˜åœ¨å¯¹è¯­è¨€è§£ç å™¨çš„**æ·±å±‚è¿›è¡Œå¾®è°ƒ**æ—¶å°¤ä¸ºä¸¥é‡ã€‚

ç°æœ‰æ–¹æ³•å¦‚ **post-merging**ï¼ˆå¦‚ ModelTailorï¼‰å’Œ **sparse fine-tuning**ï¼ˆå¦‚ SPIDERï¼‰åœ¨æµ…å±‚å¾®è°ƒä¸­è¡¨ç°å°šå¯ï¼Œä½†åœ¨æ·±å±‚å¾®è°ƒä¸‹è¦ä¹ˆå¤±æ•ˆï¼Œè¦ä¹ˆå› å†…å­˜å¼€é”€è¿‡å¤§è€Œéš¾ä»¥æ‰©å±•åˆ°å¤§æ¨¡å‹ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡º **Model-Dowser**ï¼Œä¸€ç§**æ•°æ®æ— å…³**ï¼ˆdata-freeï¼‰ã€**å¯æ‰©å±•**çš„ç¨€ç–å¾®è°ƒæ–¹æ³•ï¼Œç”¨äºç¼“è§£ MLLMs ä¸­çš„ç¾éš¾æ€§é—å¿˜ã€‚

å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š  
> **é€šè¿‡æµ‹é‡æ¯ä¸ªå‚æ•°å¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“æ¥è¯†åˆ«â€œåŠŸèƒ½é‡è¦â€çš„å‚æ•°ï¼Œå¹¶åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­å†»ç»“è¿™äº›å‚æ•°ï¼Œä»è€Œä¿ç•™é¢„è®­ç»ƒçŸ¥è¯†ã€‚**

å…·ä½“åˆ›æ–°ç‚¹å¦‚ä¸‹ï¼š

- **åŠŸèƒ½é‡è¦æ€§è¯„åˆ†ï¼ˆFunctional Importance Scoreï¼‰**ï¼š  
  æå‡ºä¸€ä¸ªç†è®ºé©±åŠ¨çš„é‡è¦æ€§è¯„åˆ† $ S_{ij}^{(l)} = \|J_i^{(l)}\|_2 \cdot |W_{ij}^{(l)}| \cdot \|h_{j}^{(l-1)}\| $ï¼Œç»¼åˆè€ƒè™‘ä¸‰ä¸ªç»´åº¦ï¼š
  - **Output Sensitivity**ï¼ˆ$ \|J_i^{(l)}\|_2 $ï¼‰ï¼šè¾“å‡ºå¯¹æŸç¥ç»å…ƒæ¿€æ´»çš„æ¢¯åº¦æ•æ„Ÿåº¦ï¼ˆé€šè¿‡ Hutchinson Estimator ä¼°è®¡ï¼‰ã€‚
  - **Connection Strength**ï¼ˆ$ |W_{ij}^{(l)}| $ï¼‰ï¼šæƒé‡æœ¬èº«çš„å¤§å°ã€‚
  - **Input Activity**ï¼ˆ$ \|h_{j}^{(l-1)}\| $ï¼‰ï¼šå‰ä¸€å±‚è¾“å…¥æ¿€æ´»çš„å¼ºåº¦ã€‚

- **æ•°æ®æ— å…³æ¢æµ‹ï¼ˆData-Free Probingï¼‰**ï¼š  
  ä¸ä¾èµ–åŸå§‹é¢„è®­ç»ƒæ•°æ®ï¼Œè€Œæ˜¯åˆ©ç”¨ MLLM è‡ªèº«çš„ç”Ÿæˆèƒ½åŠ›ï¼Œä»éšæœºç§å­åˆæˆ **synthetic prompts** æ¥æ¢æµ‹æ¨¡å‹å“åº”ï¼Œå®ç°é‡è¦æ€§ä¼°è®¡ã€‚

- **é™æ€äºŒå€¼æ©ç ï¼ˆStatic Binary Maskï¼‰**ï¼š  
  åœ¨å¾®è°ƒå‰ä¸€æ¬¡æ€§è®¡ç®—é‡è¦æ€§åˆ†æ•°å¹¶ç”Ÿæˆæ©ç ï¼Œä»…æ›´æ–°ä½é‡è¦æ€§çš„ $ p\% $ å‚æ•°ã€‚ç›¸æ¯”åŠ¨æ€æ–¹æ³•ï¼ˆå¦‚ SPIDERï¼‰ï¼Œæ˜¾è‘—é™ä½å†…å­˜å¼€é”€ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | å†…å­˜å¤æ‚åº¦ | æ˜¯å¦æ•°æ®ä¾èµ– | å¯æ‰©å±•æ€§ | æ·±å±‚å¾®è°ƒç¨³å®šæ€§ |
|------|-----------|-------------|----------|----------------|
| Full-FT | $ O(|P|) $ | å¦ | å·®ï¼ˆä¸¥é‡é—å¿˜ï¼‰ | âŒ |
| Grafting / Tailor | $ O(2|P|) $ | å¦ | å·® | âŒï¼ˆæ·±å±‚å´©æºƒï¼‰ |
| SPIDER | $ O(3|P|) $ | æ˜¯ï¼ˆéœ€è®­ç»ƒä¸­ç§¯ç´¯æ¢¯åº¦ï¼‰ | å·® | âš ï¸ï¼ˆä¸ç¨³å®šï¼‰ |
| **Model-Dowser (Ours)** | $ O(|P|) $ | **å¦** | âœ…ï¼ˆæä½³ï¼‰ | âœ…âœ…âœ… |

- **èµ„æºé«˜æ•ˆ**ï¼šå†…å­˜å¤æ‚åº¦ä¸æ ‡å‡†å¾®è°ƒç›¸åŒã€‚
- **æ— éœ€é¢å¤–è®­ç»ƒæ•°æ®**ï¼šé€‚ç”¨äºé¢„è®­ç»ƒæ•°æ®ä¸å¯ç”¨çš„åœºæ™¯ã€‚
- **æ·±å±‚å¾®è°ƒé²æ£’æ€§å¼º**ï¼šå³ä½¿å¾®è°ƒå…¨éƒ¨ 32 å±‚ä»ä¿æŒç¨³å®šã€‚
- **æ€§èƒ½é¢†å…ˆ**ï¼šåœ¨å¤šä¸ª MLLM æ¶æ„ä¸Šå‡å–å¾— SOTA è¡¨ç°ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
#### **ä¸‹æ¸¸ä»»åŠ¡ï¼ˆFine-tuning Datasetï¼‰**
- **COCO-Caption**ï¼šå›¾åƒæè¿°ç”Ÿæˆ
- **Flickr30k**ï¼šå›¾åƒæè¿°ç”Ÿæˆ
- **ImageNet-R**ï¼šè‰ºæœ¯é£æ ¼å›¾åƒåˆ†ç±»ï¼ˆä»¥ VQA å½¢å¼ï¼‰
- **IconQA**ï¼šåŸºäºå›¾è¡¨çš„è§†è§‰é—®ç­”

#### **ä¸Šæ¸¸ä»»åŠ¡ï¼ˆZero-shot Evaluationï¼‰**
ç”¨äºè¯„ä¼°é¢„è®­ç»ƒçŸ¥è¯†ä¿ç•™æƒ…å†µï¼š
- **TextVQA**, **OKVQA**, **OCRVQA**, **GQA**
- **MMBench**ï¼ˆè‹±æ–‡ & ä¸­æ–‡ç‰ˆï¼‰

---

### **å®éªŒè®¾ç½®**
- **æ¨¡å‹æ¶æ„**ï¼š
  - **LLaVA-1.5-7B**
  - **NVILA-Lite-2B**
- **å¾®è°ƒç­–ç•¥**ï¼š
  - ä»…å¾®è°ƒè¯­è¨€è§£ç å™¨çš„æœ€å $ L $ å±‚ï¼ˆ$ L $ ä» 4 åˆ° 32 å˜åŒ–ï¼‰
  - æ›´æ–°æ¯”ä¾‹ $ p = 0.1 $ï¼ˆå³ä»…æ›´æ–° 10% æœ€ä¸é‡è¦çš„å‚æ•°ï¼‰
- **è®­ç»ƒé…ç½®**ï¼š
  - å­¦ä¹ ç‡ï¼š$ 2 \times 10^{-5} $
  - Epochsï¼š5
  - Batch Sizeï¼š128
  - ç¡¬ä»¶ï¼š8Ã—A100/H200 GPU

---

### **è¯„ä¼°æŒ‡æ ‡**
- **Aup**ï¼šä¸Šæ¸¸ä»»åŠ¡å¹³å‡å‡†ç¡®ç‡ï¼ˆè¡¡é‡çŸ¥è¯†ä¿ç•™ï¼‰
- **Adown**ï¼šä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ï¼ˆCIDEr æˆ– EM å‡†ç¡®ç‡ï¼‰
- **Avg**ï¼šç®—æœ¯å¹³å‡ $ \frac{A_{up} + A_{down}}{2} $
- **H-score**ï¼ˆè°ƒå’Œå¹³å‡ï¼‰ï¼š
  $$
  \text{H-score} = 2 \cdot \frac{A_{up} \cdot A_{down}}{A_{up} + A_{down}}
  $$
  > æ›´èƒ½åæ˜ â€œå…¼é¡¾ä¸Šä¸‹æ¸¸â€çš„å¹³è¡¡èƒ½åŠ›ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ç±»åˆ« | æ–¹æ³• |
|------|------|
| **Full Fine-tuning** | Full-FT |
| **Post-Merging** | Grafting, DARE, Tailor (ModelTailor) |
| **Sparse Fine-tuning** | SPIDERï¼ˆå½“å‰ SOTAï¼‰ |
| **éšæœºé€‰æ‹©** | Random Maskingï¼ˆä½œä¸ºæ¶ˆèå¯¹ç…§ï¼‰ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & 2ï¼‰**

| æ–¹æ³• | NVILA-COCO H-score | LLaVA-COCO H-score | å†…å­˜å¼€é”€ |
|------|--------------------|---------------------|---------|
| Full-FT | 39.7 | 72.9 | $ O(|P|) $ |
| SPIDER | 78.3 | 75.2 | $ O(3|P|) $ |
| **Model-Dowser (Ours)** | **85.7** | **79.9** | $ O(|P|) $ |

> åœ¨ **NVILA** ä¸Šï¼ŒH-score è¶…è¶Š SPIDER è¿‘ **7.4 åˆ†**ï¼›åœ¨ **LLaVA** ä¸Šä¹Ÿé«˜å‡º **4.7 åˆ†**ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **ä¼˜äºæ‰€æœ‰åŸºçº¿**ï¼š
  - åœ¨ **H-score** å’Œ **Aup** ä¸Šå…¨é¢é¢†å…ˆï¼Œè¯´æ˜åœ¨ä¸ç‰ºç‰²ä¸‹æ¸¸æ€§èƒ½çš„å‰æä¸‹ï¼Œæ›´å¥½åœ°ä¿ç•™äº†é¢„è®­ç»ƒçŸ¥è¯†ã€‚
  - åœ¨æ·±å±‚å¾®è°ƒï¼ˆ>20 å±‚ï¼‰ä¸‹ï¼Œ**Grafting/Tailor æ€§èƒ½å´©æºƒ**ï¼Œè€Œ **Model-Dowser ä¾ç„¶ç¨³å¥**ï¼ˆè§ Figure 3ï¼‰ã€‚
- **ä¼˜äº SPIDER å°½ç®¡æ›´æ–°æ›´å°‘å‚æ•°**ï¼š
  - SPIDER éœ€æ›´æ–° 50% å‚æ•°ï¼Œè€Œ Model-Dowser ä»…æ›´æ–° 10%ï¼Œå´è¡¨ç°æ›´ä¼˜ï¼Œè¯´æ˜å…¶**é‡è¦æ€§åˆ¤åˆ«æ›´ç²¾å‡†**ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**
#### **(1) ä¸ Random Selection å¯¹æ¯”ï¼ˆTable 4 & 6â€“7ï¼‰**
| æ›´æ–°æ¯”ä¾‹ $ p $ | æ–¹æ³• | ImageNet-R H-score (NVILA) |
|------------------|------|----------------------------|
| 0.5 | Random | 55.0 Â± 0.1 |
| 0.5 | **Ours** | **62.7** |
| 0.75 | Random | 51.3 |
| 0.75 | **Ours** | **51.3**ï¼ˆä»æŒå¹³ï¼‰|

> å½“æ›´æ–°æ¯”ä¾‹å¢åŠ æ—¶ï¼Œ**éšæœºé€‰æ‹©è¿…é€Ÿé€€åŒ–**ï¼Œè€Œ Model-Dowser å› ä¿æŠ¤å…³é”®å‚æ•°ï¼Œä»èƒ½ç»´æŒæ€§èƒ½ã€‚

#### **(2) æ•°æ®æ— å…³ä¼°è®¡çš„æœ‰æ•ˆæ€§ï¼ˆTable 8ï¼‰**
- ä½¿ç”¨ **Spearman Correlation** å’Œ **Hamming Distance** è¯„ä¼°åˆæˆæ•°æ®ä¸çœŸå®æ•°æ®ä¸‹é‡è¦æ€§æ’åºçš„ä¸€è‡´æ€§ã€‚
- ç»“æœæ˜¾ç¤ºï¼š
  - **Spearman â‰¥ 0.88**
  - **Hamming Distance â‰¤ 0.05**
  > è¡¨æ˜åˆæˆæ•°æ®èƒ½æœ‰æ•ˆé€¼è¿‘çœŸå®æ•æ„Ÿæ€§åˆ†å¸ƒã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **æ·±å±‚å¾®è°ƒåŠ å‰§ç¾éš¾æ€§é—å¿˜**ï¼š  
   å¾®è°ƒè¯­è¨€è§£ç å™¨æ—©æœŸå±‚ä¼šå¯¼è‡´ä¸¥é‡çš„é¢„è®­ç»ƒçŸ¥è¯†ä¸¢å¤±ï¼Œç°æœ‰æ–¹æ³•ï¼ˆå°¤å…¶æ˜¯ post-mergingï¼‰å¯¹æ­¤æä¸ºè„†å¼±ã€‚

2. **åŠŸèƒ½æ•æ„Ÿæ€§æ˜¯å…³é”®**ï¼š  
   é€šè¿‡è”åˆå»ºæ¨¡ **weight magnitude**ã€**input activation** å’Œ **output sensitivity**ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°è¯†åˆ«å½±å“æ¨¡å‹è¾“å‡ºçš„å…³é”®å‚æ•°ã€‚

3. **æ•°æ®æ— å…³æ¢æµ‹å¯è¡Œä¸”æœ‰æ•ˆ**ï¼š  
   åˆ©ç”¨ MLLM è‡ªèº«ç”Ÿæˆçš„ synthetic prompts è¿›è¡Œ probingï¼Œå¯åœ¨æ— åŸå§‹æ•°æ®æƒ…å†µä¸‹å®ç°é«˜ä¿çœŸé‡è¦æ€§ä¼°è®¡ã€‚

4. **é™æ€ç¨€ç–å¾®è°ƒæ›´é«˜æ•ˆå¯é **ï¼š  
   ç›¸æ¯”åŠ¨æ€æ›´æ–°ç­–ç•¥ï¼ˆå¦‚ SPIDERï¼‰ï¼Œé¢„å…ˆå†»ç»“å…³é”®å‚æ•°çš„ç­–ç•¥åœ¨æ•ˆç‡å’Œç¨³å®šæ€§ä¸Šæ›´å…·ä¼˜åŠ¿ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–äºä¸€é˜¶è¿‘ä¼¼**ï¼šç†è®ºåˆ†æåŸºäº first-order Taylor approximationï¼Œå¯èƒ½å¿½ç•¥é«˜é˜¶äº¤äº’æ•ˆåº”ã€‚
- **åˆæˆæ ·æœ¬å¤šæ ·æ€§æœ‰é™**ï¼šè™½ç„¶å®éªŒè¯æ˜æœ‰æ•ˆï¼Œä½†ç”Ÿæˆçš„ prompts æ˜¯å¦è¦†ç›–æ‰€æœ‰è¯­ä¹‰ç©ºé—´ä»æœ‰å¾…éªŒè¯ã€‚
- **æœªæ¢ç´¢å¤šä»»åŠ¡è¿ç»­å­¦ä¹ ä¸­çš„é•¿æœŸæ¼”åŒ–**ï¼šå°½ç®¡åœ¨ CL è®¾ç½®ä¸­è¡¨ç°è‰¯å¥½ï¼ˆè§ Appendix Hï¼‰ï¼Œä½†ä¸»è¦è®¾è®¡ç›®æ ‡ä»æ˜¯å•æ¬¡ä¸‹æ¸¸é€‚é…ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•è‡³ **çœŸæ­£çš„ Continual Learning** åœºæ™¯ï¼Œæ”¯æŒä»»åŠ¡å¢é‡å­¦ä¹ ã€‚
- æ¢ç´¢ **è‡ªé€‚åº”æ›´æ–°æ¯”ä¾‹ $ p $**ï¼Œæ ¹æ®ä¸åŒå±‚è‡ªåŠ¨è°ƒæ•´ç¨€ç–ç¨‹åº¦ã€‚
- å°†è¯¥æ–¹æ³•åº”ç”¨äº **å…¶ä»–æ¨¡æ€ç»„åˆ**ï¼ˆå¦‚éŸ³é¢‘-è¯­è¨€æ¨¡å‹ï¼‰ã€‚
- ç»“åˆ **LoRA** ç­‰ PEFT æ–¹æ³•ï¼Œè¿›ä¸€æ­¥æå‡å‚æ•°æ•ˆç‡ã€‚

---

> âœ… **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **Model-Dowser æå‡ºäº†ä¸€ç§æ— éœ€æ•°æ®ã€å†…å­˜å‹å¥½ã€ç†è®ºä¸¥è°¨çš„ç¨€ç–å¾®è°ƒæ¡†æ¶ï¼Œé€šè¿‡è¯†åˆ«å¹¶å†»ç»“â€œåŠŸèƒ½å…³é”®â€å‚æ•°ï¼Œåœ¨æ·±å±‚å¾®è°ƒä¸­æ˜¾è‘—ç¼“è§£äº† MLLMs çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼Œå®ç°äº†æ€§èƒ½ä¸ç¨³å®šæ€§çš„æœ€ä½³å¹³è¡¡ã€‚**

</details>

---

### 16. [MirrorLA: Reflecting Feature Map for Vision Linear Attention](https://arxiv.org/abs/2602.04346)

**Authors**: Weikang Meng, Liangyu Huo, Yadan Luo, Yaowei Wang, Yingjian Li, Zheng Zhang  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.04346v1  

#### Abstract
Linear attention significantly reduces the computational complexity of Transformers from quadratic to linear, yet it consistently lags behind softmax-based attention in performance. We identify the root cause of this degradation as the non-negativity constraint imposed on kernel feature maps: standa...

---

### 17. [SAFE: Stable Alignment Finetuning with Entropy-Aware Predictive Control for RLHF](https://arxiv.org/abs/2602.04651)

**Authors**: Dipan Maity  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.04651v1  

#### Abstract
Optimization (PPO) has been positioned by recent literature as the canonical method for the RL part of RLHF. PPO performs well empirically but has a heuristic motivation and handles the KL-divergence constraint used in LM-RLHF in an ad-hoc manner and suffers form reward oscillations, entropy collaps...

---

### 18. [Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search](https://arxiv.org/abs/2602.04248)

**Authors**: Hao Lu, Haoyuan Huang, Yulin Zhou, Chen Li, Ningxin Zhu  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.04248v1  

#### Abstract
Inference-time scaling strategies, particularly Monte Carlo Tree Search (MCTS), have significantly enhanced the reasoning capabilities of Large Language Models (LLMs). However, current approaches remain predominantly stateless, discarding successful reasoning patterns after each problem instance and...

---

### 19. [From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents](https://arxiv.org/abs/2602.04326)

**Authors**: SeungWon Seo, SooBin Lim, SeongRae Noh, Haneul Kim, HyeongYeop Kang  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.04326v1  

#### Abstract
Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs) to embodied agents have addressed many long-stan...

---

### 20. [LinGO: A Linguistic Graph Optimization Framework with LLMs for Interpreting Intents of Online Uncivil Discourse](https://arxiv.org/abs/2602.04693)

**Authors**: Yuan Zhang, Thales Bertaglia  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.04693v1  

#### Abstract
Detecting uncivil language is crucial for maintaining safe, inclusive, and democratic online spaces. Yet existing classifiers often misinterpret posts containing uncivil cues but expressing civil intents, leading to inflated estimates of harmful incivility online. We introduce LinGO, a linguistic gr...

---

### 21. [OmniSIFT: Modality-Asymmetric Token Compression for Efficient Omni-modal Large Language Models](https://arxiv.org/abs/2602.04804)

**Authors**: Yue Ding, Yiyan Ji, Jungang Li, Xuyang Liu, Xinlong Chen, Junfei Wu, Bozhou Li, Bohan Zeng, Yang Shi, Yushuo Guan, Yuanxing Zhang, Jiaheng Liu, Qiang Liu, Pengfei Wan, Liang Wang  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.04804v1  

#### Abstract
Omni-modal Large Language Models (Omni-LLMs) have demonstrated strong capabilities in audio-video understanding tasks. However, their reliance on long multimodal token sequences leads to substantial computational overhead. Despite this challenge, token compression methods designed for Omni-LLMs rema...

---

### 22. [Federated Concept-Based Models: Interpretable models with distributed supervision](https://arxiv.org/abs/2602.04093)

**Authors**: Dario Fenoglio, Arianna Casanova, Francesco De Santis, Mohan Li, Gabriele Dominici, Johannes Schneider, Martin Gjoreski, Marc Langheinrich, Pietro Barbiero, Giovanni De Felice  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.04093v1  

#### Abstract
Concept-based models (CMs) enhance interpretability in deep learning by grounding predictions in human-understandable concepts. However, concept annotations are expensive to obtain and rarely available at scale within a single data source. Federated learning (FL) could alleviate this limitation by e...

---

### 23. [From Sparse Sensors to Continuous Fields: STRIDE for Spatiotemporal Reconstruction](https://arxiv.org/abs/2602.04201)

**Authors**: Yanjie Tong, Peng Chen  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.04201v1  

#### Abstract
Reconstructing high-dimensional spatiotemporal fields from sparse point-sensor measurements is a central challenge in learning parametric PDE dynamics. Existing approaches often struggle to generalize across trajectories and parameter settings, or rely on discretization-tied decoders that do not nat...

---

### 24. [Cascading Robustness Verification: Toward Efficient Model-Agnostic Certification](https://arxiv.org/abs/2602.04236)

**Authors**: Mohammadreza Maleki, Rushendra Sidibomma, Arman Adibi, Reza Samavi  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.04236v1  

#### Abstract
Certifying neural network robustness against adversarial examples is challenging, as formal guarantees often require solving non-convex problems. Hence, incomplete verifiers are widely used because they scale efficiently and substantially reduce the cost of robustness verification compared to comple...

---

### 25. [Mosaic Learning: A Framework for Decentralized Learning with Model Fragmentation](https://arxiv.org/abs/2602.04352)

**Authors**: Sayan Biswas, Davide Frey, Romaric Gaudel, Nirupam Gupta, Anne-Marie Kermarrec, Dimitri Ler\'ev\'erend, Rafael Pires, Rishi Sharma, Fran\c{c}ois Ta\"iani, Martijn de Vos  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.04352v1  

#### Abstract
Decentralized learning (DL) enables collaborative machine learning (ML) without a central server, making it suitable for settings where training data cannot be centrally hosted. We introduce Mosaic Learning, a DL framework that decomposes models into fragments and disseminates them independently acr...

---

### 26. [WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.04634)

**Authors**: Zelai Xu, Zhexuan Xu, Ruize Zhang, Chunyang Zhu, Shi Yu, Weilin Liu, Quanlu Zhang, Wenbo Ding, Chao Yu, Yu Wang  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.04634v1  

#### Abstract
Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In t...

---

### 27. [Fine-Grained Activation Steering: Steering Less, Achieving More](https://arxiv.org/abs/2602.04428)

**Authors**: Zijian Feng, Tianjiao Li, Zixiao Zhu, Hanzhang Zhou, Junlang Qian, Li Zhang, Jia Jim Deryl Chua, Lee Onn Mak, Gee Wah Ng, Kezhi Mao  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.04428v1  

#### Abstract
Activation steering has emerged as a cost-effective paradigm for modifying large language model (LLM) behaviors. Existing methods typically intervene at the block level, steering the bundled activations of selected attention heads, feedforward networks, or residual streams. However, we reveal that b...

---

### 28. [ERNIE 5.0 Technical Report](https://arxiv.org/abs/2602.04705)

**Authors**: Haifeng Wang, Hua Wu, Tian Wu, Yu Sun, Jing Liu, Dianhai Yu, Yanjun Ma, Jingzhou He, Zhongjun He, Dou Hong, Qiwen Liu, Shuohuan Wang, Junyuan Shang, Zhenyu Zhang, Yuchen Ding, Jinle Zeng, Jiabin Yang, Liang Shen, Ruibiao Chen, Weichong Yin, Siyu Ding, Dai Dai, Shikun Feng, Siqi Bao, Bolei He, Yan Chen, Zhenyu Jiao, Ruiqing Zhang, Zeyu Chen, Qingqing Dang, Kaipeng Deng, Jiajun Jiang, Enlei Gong, Guoxia Wang, Yanlin Sha, Yi Liu, Yehan Zheng, Weijian Xu, Jiaxiang Liu, Zengfeng Zeng, Yingqi Qu, Zhongli Li, Zhengkun Zhang, Xiyang Wang, Zixiang Xu, Xinchao Xu, Zhengjie Huang, Dong Wang, Bingjin Chen, Yue Chang, Xing Yuan, Shiwei Huang, Qiao Zhao, Xinzhe Ding, Shuangshuang Qiao, Baoshan Yang, Bihong Tang, Bin Li, Bingquan Wang, Binhan Tang, Binxiong Zheng, Bo Cui, Bo Ke, Bo Zhang, Bowen Zhang, Boyan Zhang, Boyang Liu, Caiji Zhang, Can Li, Chang Xu, Chao Pang, Chao Zhang, Chaoyi Yuan, Chen Chen, Cheng Cui, Chenlin Yin, Chun Gan, Chunguang Chai, Chuyu Fang, Cuiyun Han, Dan Zhang, Danlei Feng, Danxiang Zhu, Dong Sun, Dongbo Li, Dongdong Li, Dongdong Liu, Dongxue Liu, Fan Ding, Fan Hu, Fan Li, Fan Mo, Feisheng Wu, Fengwei Liu, Gangqiang Hu, Gaofeng Lu, Gaopeng Yong, Gexiao Tian, Guan Wang, Guangchen Ni, Guangshuo Wu, Guanzhong Wang, Guihua Liu, Guishun Li, Haibin Li, Haijian Liang, Haipeng Ming, Haisu Wang, Haiyang Lu, Haiye Lin, Han Zhou, Hangting Lou, Hanwen Du, Hanzhi Zhang, Hao Chen, Hao Du, Hao Liu, Hao Zhou, Haochen Jiang, Haodong Tian, Haoshuang Wang, Haozhe Geng, Heju Yin, Hong Chen, Hongchen Xue, Hongen Liu, Honggeng Zhang, Hongji Xu, Hongwei Chen, Hongyang Zhang, Hongyuan Zhang, Hua Lu, Huan Chen, Huan Wang, Huang He, Hui Liu, Hui Zhong, Huibin Ruan, Jiafeng Lu, Jiage Liang, Jiahao Hu, Jiahao Hu, Jiajie Yang, Jialin Li, Jian Chen, Jian Wu, Jianfeng Yang, Jianguang Jiang, Jianhua Wang, Jianye Chen, Jiaodi Liu, Jiarui Zhou, Jiawei Lv, Jiaxin Zhou, Jiaxuan Liu, Jie Han, Jie Sun, Jiefan Fang, Jihan Liu, Jihua Liu, Jing Hu, Jing Qian, Jing Yan, Jingdong Du, Jingdong Wang, Jingjing Wu, Jingyong Li, Jinheng Wang, Jinjin Li, Jinliang Lu, Jinlin Yu, Jinnan Liu, Jixiang Feng, Jiyi Huang, Jiyuan Zhang, Jun Liang, Jun Xia, Jun Yu, Junda Chen, Junhao Feng, Junhong Xiang, Junliang Li, Kai Liu, Kailun Chen, Kairan Su, Kang Hu, Kangkang Zhou, Ke Chen, Ke Wei, Kui Huang, Kun Wu, Kunbin Chen, Lei Han, Lei Sun, Lei Wen, Linghui Meng, Linhao Yu, Liping Ouyang, Liwen Zhang, Longbin Ji, Longzhi Wang, Meng Sun, Meng Tian, Mengfei Li, Mengqi Zeng, Mengyu Zhang, Ming Hong, Mingcheng Zhou, Mingming Huang, Mingxin Chen, Mingzhu Cai, Naibin Gu, Nemin Qiu, Nian Wang, Peng Qiu, Peng Zhao, Pengyu Zou, Qi Wang, Qi Xin, Qian Wang, Qiang Zhu, Qianhui Luo, Qianwei Yang, Qianyue He, Qifei Wu, Qinrui Li, Qiwen Bao, Quan Zhang, Quanxiang Liu, Qunyi Xie, Rongrui Zhan, Rufeng Dai, Rui Peng, Ruian Liu, Ruihao Xu, Ruijie Wang, Ruixi Zhang, Ruixuan Liu, Runsheng Shi, Ruting Wang, Senbo Kang, Shan Lu, Shaofei Yu, Shaotian Gong, Shenwei Hu, Shifeng Zheng, Shihao Guo, Shilong Fan, Shiqin Liu, Shiwei Gu, Shixi Zhang, Shuai Yao, Shuang Zhang, Shuangqiao Liu, Shuhao Liang, Shuwei He, Shuwen Yang, Sijun He, Siming Dai, Siming Wu, Siyi Long, Songhe Deng, Suhui Dong, Suyin Liang, Teng Hu, Tianchan Xu, Tianliang Lv, Tianmeng Yang, Tianyi Wei, Tiezhu Gao, Ting Sun, Ting Zhang, Tingdan Luo, Wei He, Wei Luan, Wei Yin, Wei Zhang, Wei Zhou, Weibao Gong, Weibin Li, Weicheng Huang, Weichong Dang, Weiguo Zhu, Weilong Zhang, Weiqi Tan, Wen Huang, Wenbin Chang, Wenjing Du, Wenlong Miao, Wenpei Luo, Wenquan Wu, Xi Shi, Xi Zhao, Xiang Gao, Xiangguo Zhang, Xiangrui Yu, Xiangsen Wang, Xiangzhe Wang, Xianlong Luo, Xianying Ma, Xiao Tan, Xiaocong Lin, Xiaofei Wang, Xiaofeng Peng, Xiaofeng Wu, Xiaojian Xu, Xiaolan Yuan, Xiaopeng Cui, Xiaotian Han, Xiaoxiong Liu, Xiaoxu Fei, Xiaoxuan Wu, Xiaoyu Wang, Xiaoyu Zhang, Xin Sun, Xin Wang, Xinhui Huang, Xinming Zhu, Xintong Yu, Xinyi Xu, Xinyu Wang, Xiuxian Li, XuanShi Zhu, Xue Xu, Xueying Lv, Xuhong Li, Xulong Wei, Xuyi Chen, Yabing Shi, Yafeng Wang, Yamei Li, Yan Liu, Yanfu Cheng, Yang Gao, Yang Liang, Yang Wang, Yang Wang, Yang Yang, Yanlong Liu, Yannian Fu, Yanpeng Wang, Yanzheng Lin, Yao Chen, Yaozong Shen, Yaqian Han, Yehua Yang, Yekun Chai, Yesong Wang, Yi Song, Yichen Zhang, Yifei Wang, Yifeng Guo, Yifeng Kou, Yilong Chen, Yilong Guo, Yiming Wang, Ying Chen, Ying Wang, Yingsheng Wu, Yingzhan Lin, Yinqi Yang, Yiran Xing, Yishu Lei, Yixiang Tu, Yiyan Chen, Yong Zhang, Yonghua Li, Yongqiang Ma, Yongxing Dai, Yongyue Zhang, Yu Ran, Yu Sun, Yu-Wen Michael Zhang, Yuang Liu, Yuanle Liu, Yuanyuan Zhou, Yubo Zhang, Yuchen Han, Yucheng Wang, Yude Gao, Yuedong Luo, Yuehu Dong, Yufeng Hu, Yuhui Cao, Yuhui Yun, Yukun Chen, Yukun Gao, Yukun Li, Yumeng Zhang, Yun Fan, Yun Ma, Yunfei Zhang, Yunshen Xie, Yuping Xu, Yuqin Zhang, Yuqing Liu, Yurui Li, Yuwen Wang, Yuxiang Lu, Zefeng Cai, Zelin Zhao, Zelun Zhang, Zenan Lin, Zezhao Dong, Zhaowu Pan, Zhaoyu Liu, Zhe Dong, Zhe Zhang, Zhen Zhang, Zhengfan Wu, Zhengrui Wei, Zhengsheng Ning, Zhenxing Li, Zhenyu Li, Zhenyu Qian, Zhenyun Li, Zhi Li, Zhichao Chen, Zhicheng Dong, Zhida Feng, Zhifan Feng, Zhihao Deng, Zhijin Yu, Zhiyang Chen, Zhonghui Zheng, Zhuangzhuang Guo, Zhujun Zhang, Zhuo Sun, Zichang Liu, Zihan Lin, Zihao Huang, Zihe Zhu, Ziheng Zhao, Ziping Chen, Zixuan Zhu, Ziyang Xu, Ziyi Liang, Ziyuan Gao  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.04705v1  

#### Abstract
In this report, we introduce ERNIE 5.0, a natively autoregressive foundation model desinged for unified multimodal understanding and generation across text, image, video, and audio. All modalities are trained from scratch under a unified next-group-of-tokens prediction objective, based on an ultra-s...

---

### 29. [Six Times to Spare: LDPC Acceleration on DGX Spark for AI-Native Open RAN](https://arxiv.org/abs/2602.04652)

**Authors**: Ryan Barker, Fatemeh Afghah  
**Category**: cs.DC  
**Published**: 2026-02-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.04652v1  

#### Abstract
Low-density parity-check (LDPC) decoding is one of the most computationally intensive kernels in the 5G New Radio (NR) physical layer and must complete within a 0.5\,ms transmission time interval while sharing the budget with FFT, channel estimation, demapping, HARQ, and MAC scheduling. Many open an...

---

### 30. [Causal Discovery for Cross-Sectional Data Based on Super-Structure and Divide-and-Conquer](https://arxiv.org/abs/2602.03914)

**Authors**: Wenyu Wang (University of South China), Yaping Wan (University of South China)  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.03914v1  

#### Abstract
This paper tackles a critical bottleneck in Super-Structure-based divide-and-conquer causal discovery: the high computational cost of constructing accurate Super-Structures--particularly when conditional independence (CI) tests are expensive and domain knowledge is unavailable. We propose a novel, l...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
