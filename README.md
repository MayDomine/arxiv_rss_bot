# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-09 06:51:59 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Mapping Gemma3 onto an Edge Dataflow Architecture](https://arxiv.org/abs/2602.06063)

**Authors**: Shouyu Du, Miaoxiang Yu, Zhiheng Ni, Jillian Cai, Qing Yang, Tao Wei, Zhenyu Xu  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2602.06063v1  

#### Abstract
We present the first end-to-end deployment of the Gemma3 family of large language and vision models on a tiled edge dataflow architecture (AMD Ryzen AI NPU). Our work introduces a set of hardware-aware techniques. For prefill, we introduce an efficient dequantization engine, optimize tiled matrix mu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šMapping Gemma3 onto an Edge Dataflow Architecture**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
æœ¬æ–‡é¦–æ¬¡å®ç°äº† **Gemma3** ç³»åˆ—å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰åœ¨è¾¹ç¼˜ç«¯ **tiled dataflow æ¶æ„**ï¼ˆå…·ä½“ä¸º AMD Ryzen AI NPUï¼‰ä¸Šçš„ **ç«¯åˆ°ç«¯éƒ¨ç½²**ã€‚  
ä¼ ç»Ÿ CPU å’Œ iGPU åœ¨è¿è¡Œ LLM æ—¶å­˜åœ¨åŠŸè€—é«˜ã€å»¶è¿Ÿå¤§ã€å¸¦å®½ç“¶é¢ˆç­‰é—®é¢˜ï¼Œå°¤å…¶åœ¨ **prefill** å’Œ **decoding** é˜¶æ®µéš¾ä»¥é«˜æ•ˆå¤„ç†é•¿åºåˆ—å’Œ KV Cacheã€‚  
æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•æœªå……åˆ†æŒ–æ˜ **NPU çš„æ•°æ®æµæ¶æ„ç‰¹æ€§**ï¼ˆå¦‚ tile-to-tile é€šä¿¡ã€DMA æµæ°´ã€VLIW æŒ‡ä»¤ï¼‰ï¼Œå¯¼è‡´å†…å­˜åˆ©ç”¨ç‡ä½ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡ºäº†ä¸€å¥— **ç¡¬ä»¶æ„ŸçŸ¥çš„ä¼˜åŒ–æŠ€æœ¯**ï¼Œé’ˆå¯¹ prefill å’Œ decoding ä¸¤ä¸ªé˜¶æ®µåˆ†åˆ«è®¾è®¡ï¼š

#### **Prefill é˜¶æ®µ**
- **Q4NX**ï¼šä¸€ç§ç´§å‡‘çš„ 4-bit é‡åŒ–æ ¼å¼ï¼Œä¸“ä¸º Ryzen AI NPU è®¾è®¡ï¼Œå‡å°‘å†…å­˜å ç”¨å¹¶æå‡ååã€‚
- **é«˜æ•ˆ dequantization å¼•æ“**ï¼šå°† int4 æƒé‡å¿«é€Ÿåé‡åŒ–ä¸º bf16ï¼Œæ”¯æŒå—çº§ scale å’Œ offset å­˜å‚¨ï¼Œé™ä½ç‰‡ä¸Šå†…å­˜å¼€é”€ã€‚
- **FlowQKV**ï¼šä¸€ç§åŸºäº **chunked + pipelined attention** çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œé€šè¿‡åˆ†å—å¤„ç†å’Œæµæ°´çº¿è°ƒåº¦ï¼Œå®ç°è®¡ç®—ä¸æ•°æ®ä¼ è¾“é‡å ï¼Œæ˜¾è‘—æå‡ KV Cache æ•ˆç‡ã€‚
  - å˜ä½“ï¼š**FlowQKV-SWA** æ”¯æŒæ»‘åŠ¨çª—å£æ³¨æ„åŠ›ï¼ˆSliding Window Attentionï¼‰ï¼Œ**FlowQKV-NCA** æ”¯æŒéå› æœæ³¨æ„åŠ›ï¼ˆç”¨äº Vision Transformerï¼‰ã€‚

#### **Decoding é˜¶æ®µ**
- **FusedDQP**ï¼šå°† **dequantization å’Œ projection èåˆä¸ºå•ä¸ª kernel**ï¼Œé¿å…ä¸­é—´ç»“æœå†™å›å†…å­˜ï¼Œå‡å°‘è®¿å­˜å¼€é”€ã€‚
- **FlowKV**ï¼šé‡æ„ attention æœºåˆ¶ï¼Œé‡‡ç”¨ **dataflow æ¨¡å‹** å¤„ç† KV å¯¹ï¼Œç»´æŒé«˜å†…å­˜å¸¦å®½åˆ©ç”¨ç‡ã€‚
  - å˜ä½“ï¼š**FlowKV-SWA** æ”¯æŒæ»‘åŠ¨çª—å£å±‚ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **æ— éœ€ä¿®æ”¹æ¨¡å‹ç»“æ„æˆ–ç®—æ³•**ï¼Œä¿æŒåŸå§‹æ¨¡å‹ç²¾åº¦ã€‚
- å……åˆ†åˆ©ç”¨ NPU çš„ **tile æ¶æ„ã€DMA åŒç¼“å†²ã€ç›´æ¥ tile-to-tile é€šä¿¡** ç‰¹æ€§ã€‚
- å®ç° **prefill å’Œ decoding é˜¶æ®µçš„é«˜å†…å­˜å¸¦å®½åˆ©ç”¨ç‡ï¼ˆUdï¼‰**ï¼Œçªç ´ä¼ ç»Ÿå†…å­˜ç“¶é¢ˆã€‚
- æå‡ºçš„ Q4NX æ ¼å¼å¯æ‰©å±•è‡³æ–°å…´æ ¼å¼ï¼ˆå¦‚ MXFP4ï¼‰ï¼Œå…·å¤‡å‰ç»æ€§ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ¨¡å‹**
- **Gemma3-1B** å’Œ **Gemma3-4B**ï¼ˆå« vision towerï¼‰
- Vision Towerï¼šSigLIP ViTï¼Œå°†å›¾åƒè½¬ä¸º 4096 tokens â†’ å‹ç¼©ä¸º 256 tokens

### **ç¡¬ä»¶å¹³å°**
- **AMD Ryzen AI 7 350 NPU**ï¼ˆâ€œKraken Pointâ€ APUï¼ŒXDNA2 æ¶æ„ï¼‰
- é›†æˆäº ASRock 4X4 BOX-AI350 mini-PC
- é…å¤‡ SO-DIMM DDR5 5600 MHz
- Compute Tileï¼ˆCTï¼‰é˜µåˆ—ï¼š8Ã—4ï¼ˆå…± 32 CTsï¼‰

### **è½¯ä»¶å·¥å…·é“¾**
- ä½¿ç”¨ **AIE-MLIR** è¿›è¡Œåº•å±‚ kernel æ˜ å°„å’Œè°ƒåº¦
- è‡ªç ” **IRON Python æ¥å£** å®ç°ç³»ç»Ÿçº§æ§åˆ¶ï¼ˆGitHub é“¾æ¥æš‚åŒ¿åä¸ºå®¡ç¨¿ä¿ç•™ï¼‰

### **è¯„ä¼°æŒ‡æ ‡**
- **Prefill æ€§èƒ½**ï¼šTTFTï¼ˆTime To First Tokenï¼Œç§’ï¼‰
- **Decoding æ€§èƒ½**ï¼šTPSï¼ˆTokens Per Secondï¼‰
- **èƒ½æ•ˆ**ï¼šTPS/Wï¼ˆTokens Per Second per Wattï¼‰
- **å†…å­˜å¸¦å®½åˆ©ç”¨ç‡ï¼ˆUdï¼‰**ï¼šè¡¡é‡æ˜¯å¦è¾¾åˆ° memory-bound æé™

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
åœ¨åŒä¸€å¹³å°ä¸Šå¯¹æ¯”ï¼š
- **iGPU**ï¼šä½¿ç”¨ LM Studioï¼ˆElement Labsï¼‰
- **CPU**ï¼šä½¿ç”¨ Ollamaï¼ˆOllama, 2023ï¼‰

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **Prefill é˜¶æ®µï¼ˆTTFTï¼‰**
| æ¨¡å‹ | åºåˆ—é•¿åº¦ | NPU (s) | iGPU (s) | CPU (s) |
|------|----------|---------|----------|--------|
| Gemma3-1B | 32k | 21.0 | 95.1 | 165.0 |
| Gemma3-4B | 32k | 50.9 | 265.0 | 832.0 |

- **é€Ÿåº¦æå‡**ï¼š
  - 1B æ¨¡å‹ prefill æœ€å¿«è¾¾ **5.2Ã—**ï¼ˆvs iGPUï¼‰ã€**33.5Ã—**ï¼ˆvs CPUï¼‰
  - 4B æ¨¡å‹ prefill æœ€å¿«è¾¾ **5.2Ã—**ï¼ˆvs iGPUï¼‰ã€**16.3Ã—**ï¼ˆvs CPUï¼‰

#### **Decoding é˜¶æ®µï¼ˆTPSï¼‰**
| æ¨¡å‹ | åºåˆ—é•¿åº¦ | NPU (TPS) | iGPU (TPS) | CPU (TPS) |
|------|----------|-----------|------------|----------|
| Gemma3-1B | 1k | 34.3 | 38.0 | 41.9 |
| Gemma3-1B | 32k | 23.1 | 13.6 | 33.8 |
| Gemma3-4B | 1k | 14.4 | 18.6 | 14.6 |
| Gemma3-4B | 128k | 9.2 | 1.9 | 4.1 |

- **é€Ÿåº¦æå‡**ï¼š
  - 1B æ¨¡å‹ decoding æœ€å¿«è¾¾ **1.7Ã—**ï¼ˆçŸ­åºåˆ— vs iGPUï¼‰ï¼Œ**é•¿åºåˆ—ä¸‹åè¶… iGPU è¾¾ 1.7Ã—**
  - 4B æ¨¡å‹ decoding åœ¨é•¿åºåˆ—ä¸‹ä¼˜åŠ¿æ˜æ˜¾ï¼Œ**æœ€é«˜è¾¾ 4.8Ã—ï¼ˆvs iGPUï¼‰ã€2.2Ã—ï¼ˆvs CPUï¼‰**

#### **Vision Tower æ€§èƒ½**
- NPU å¤„ç† vision towerï¼ˆ4B onlyï¼‰ï¼š
  - **1.7Ã— å¿«äº iGPU**
  - **8.7Ã— å¿«äº CPU**

#### **èƒ½æ•ˆï¼ˆTPS/Wï¼‰**
- **NPU èƒ½æ•ˆè¿œè¶…åŸºçº¿**ï¼š
  - Prefill é˜¶æ®µï¼š**æœ€é«˜è¾¾ 67.2Ã—ï¼ˆvs iGPUï¼‰ã€222.9Ã—ï¼ˆvs CPUï¼‰**
  - Decoding é˜¶æ®µï¼š**æœ€é«˜è¾¾ 60.6Ã—ï¼ˆvs iGPUï¼‰ã€13.2Ã—ï¼ˆvs CPUï¼‰**
- å›¾ 12 æ˜¾ç¤ºï¼Œåœ¨æ‰€æœ‰åºåˆ—é•¿åº¦ä¸‹ï¼ŒNPU çš„ TPS/W å‡æ˜¾è‘—é¢†å…ˆã€‚

#### **åŠŸè€—ä¸æ¸©åº¦**
- **å¹³å‡åŠŸè€—ï¼ˆè¡¨ 5ï¼‰**ï¼š
  - NPU è¿è¡Œæ—¶æ€»åŠŸè€—ä»… **~4.5W**
  - iGPU å’Œ CPU è¿è¡Œæ—¶åŠŸè€—é«˜è¾¾ **50â€“60W**
- **èŠ¯ç‰‡æ¸©åº¦**ï¼š
  - NPU ä¸‹ç¨³å®šåœ¨ **<50Â°C**
  - iGPU å’Œ CPU åœ¨ 5 ç§’å†…å³è¾¾ **98â€“100.5Â°C**

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ç°ä»£ NPU å®Œå…¨æœ‰èƒ½åŠ›åœ¨è¾¹ç¼˜ç«¯é«˜æ•ˆè¿è¡Œ LLM/VLM**ï¼Œä¸”æ— éœ€ç‰ºç‰²ç²¾åº¦ã€‚
2. **ç¡¬ä»¶æ„ŸçŸ¥è°ƒåº¦ + å¸¦å®½ä¸­å¿ƒåŒ– kernel è®¾è®¡** æ˜¯çªç ´å†…å­˜ç“¶é¢ˆçš„å…³é”®ã€‚
3. **FlowQKV / FlowKV å®ç°äº†é«˜ Udï¼ˆmemory-boundï¼‰**ï¼Œä½¿ NPU åœ¨é•¿åºåˆ—ä¸‹ä»ä¿æŒé«˜æ€§èƒ½ã€‚
4. **FusedDQP æ¶ˆé™¤äº† dequantization ä¸ projection çš„é¢å¤–è®¿å­˜å¼€é”€**ï¼Œæ˜¾è‘—æå‡ decoding æ•ˆç‡ã€‚
5. **Q4NX æ˜¯ä¸€ç§é«˜æ•ˆã€å¯æ‰©å±•çš„é‡åŒ–æ ¼å¼**ï¼Œç‰¹åˆ«é€‚åˆ NPU æ¶æ„ã€‚
6. **NPU åŠŸè€—æä½ï¼Œæ¸©æ§ä¼˜ç§€**ï¼Œéå¸¸é€‚åˆç§»åŠ¨è®¾å¤‡ã€ç¬”è®°æœ¬ç­‰è¾¹ç¼˜åœºæ™¯ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- å½“å‰å®ç°ä¾èµ– **ä¸“ç”¨å·¥å…·é“¾ï¼ˆAIE-MLIR + IRONï¼‰**ï¼Œé€šç”¨æ€§å—é™ã€‚
- **çŸ­åºåˆ— decoding ä¸‹ iGPU ä»æœ‰é€Ÿåº¦ä¼˜åŠ¿**ï¼ˆå› æ›´é«˜å†…å­˜å¸¦å®½ï¼‰ï¼Œä½†éšåºåˆ—å¢é•¿è¢«åè¶…ã€‚
- æœªæµ‹è¯•æ›´å¤§æ¨¡å‹ï¼ˆå¦‚ 8B+ï¼‰ï¼Œæœªæ¥éœ€éªŒè¯å¯æ‰©å±•æ€§ã€‚
- æ‰€æœ‰å®éªŒåŸºäº **å•ä¸€ç¡¬ä»¶å¹³å°ï¼ˆRyzen AI 7350ï¼‰**ï¼Œè·¨å¹³å°æ³›åŒ–éœ€è¿›ä¸€æ­¥éªŒè¯ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- å¼€å‘æ›´æˆç†Ÿçš„ **LLM on NPU å·¥å…·é“¾ä¸åº“**ï¼Œè®¡åˆ’è¿‘æœŸå¼€æºã€‚
- å°†æ–¹æ³•æ¨å¹¿è‡³å…¶ä»– **dataflow accelerator**ï¼ˆå¦‚ Cerebrasã€AMD AIE/ACAPï¼‰ã€‚
- æ¢ç´¢ **åŠ¨æ€ tile åˆ†é…** å’Œ **è‡ªé€‚åº” chunk size** ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½ã€‚
- æ”¯æŒ **è®­ç»ƒ** åœºæ™¯ä¸‹çš„ NPU åˆ©ç”¨ã€‚
- æ‰©å±• Q4NX æ”¯æŒ **MXFP4** ç­‰æ–°å…´ä½æ¯”ç‰¹æ ¼å¼ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡é¦–æ¬¡å®ç°äº† Gemma3 åœ¨è¾¹ç¼˜ NPU ä¸Šçš„é«˜æ•ˆç«¯åˆ°ç«¯æ¨ç†ï¼Œé€šè¿‡ **FlowQKVã€FlowKVã€FusedDQP å’Œ Q4NX** ç­‰ç¡¬ä»¶æ„ŸçŸ¥æŠ€æœ¯ï¼Œå®ç°äº† **æœ€é«˜ 5.2Ã— é€Ÿåº¦æå‡** å’Œ **è¶…è¿‡ 200Ã— çš„èƒ½æ•ˆå¢ç›Š**ï¼Œä¸ºæœªæ¥è¾¹ç¼˜ LLM/VLM éƒ¨ç½²æä¾›äº†å¯å¤ç”¨çš„è“å›¾ã€‚

</details>

---

### 2. [PackInfer: Compute- and I/O-Efficient Attention for Batched LLM Inference](https://arxiv.org/abs/2602.06072)

**Authors**: Rui Ning, Wei Zhang, Fan Lai  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2602.06072v1  

#### Abstract
Attention efficiency is critical to large language model (LLM) inference. While prior advances optimize attention execution for individual requests (e.g., FlashAttention), production LLM serving relies on batching requests with highly heterogeneous sequence lengths for high serving throughput. This ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*PackInfer: Compute- and I/O-Efficient Attention for Batched LLM Inference*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜

åœ¨å®é™…çš„ **LLM æ¨ç†æœåŠ¡**ä¸­ï¼Œç³»ç»Ÿé€šå¸¸é€šè¿‡ **batching** æ¥æå‡ååé‡ã€‚ç„¶è€Œï¼ŒçœŸå®åœºæ™¯ä¸­çš„è¯·æ±‚å…·æœ‰é«˜åº¦å¼‚æ„çš„ **sequence length**ï¼ˆä¾‹å¦‚çŸ­æŸ¥è¯¢ä¸é•¿ä¸Šä¸‹æ–‡å…±å­˜ï¼‰ï¼Œå¯¼è‡´ä»¥ä¸‹é—®é¢˜ï¼š

- **è®¡ç®—ä¸å‡è¡¡ï¼ˆComputation Imbalanceï¼‰**ï¼šçŸ­è¯·æ±‚å›  padding å¯¼è‡´å¤§é‡æ— æ•ˆè®¡ç®—ï¼Œè€Œé•¿è¯·æ±‚æˆä¸ºæ‰§è¡Œç“¶é¢ˆï¼ˆstragglerï¼‰ï¼Œé€ æˆ GPU èµ„æºæµªè´¹ã€‚
- **I/O æ•ˆç‡ä½ä¸‹**ï¼šKV Cache å­˜å‚¨ç¢ç‰‡åŒ–ã€è®¿é—®ä¸è¿ç»­ï¼Œå°¤å…¶åœ¨ decoding é˜¶æ®µåŠ å‰§å†…å­˜å¸¦å®½å‹åŠ›ã€‚
- **ç°æœ‰ä¼˜åŒ–æ–¹æ³•å±€é™**ï¼šå¦‚ FlashAttention å’Œ Chunked-prefill ä¸»è¦é’ˆå¯¹å•ä¸ªè¯·æ±‚ä¼˜åŒ–ï¼Œç¼ºä¹å¯¹ batch-level å¼‚æ„æ€§çš„ç³»ç»Ÿçº§åº”å¯¹ã€‚

è¿™äº›é—®é¢˜å…±åŒå¯¼è‡´ **GPU åˆ©ç”¨ç‡ä½ã€å°¾å»¶è¿Ÿé«˜ã€ç«¯åˆ°ç«¯æ¨ç†å»¶è¿Ÿå¢åŠ **ã€‚

---

### ğŸš€ æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

ä½œè€…æå‡º **PackInfer** â€”â€” ä¸€ç§ **kernel-level çš„æ³¨æ„åŠ›ä¼˜åŒ–æ¡†æ¶**ï¼Œé€šè¿‡ **compute- å’Œ I/O-aware çš„ token packing** å®ç°é«˜æ•ˆæ‰¹å¤„ç†æ¨ç†ã€‚

#### æ ¸å¿ƒè®¾è®¡æ€æƒ³ï¼š

1. **Packed Computationï¼ˆæ‰“åŒ…è®¡ç®—ï¼‰**
   - å°†å¤šä¸ªå¼‚æ„é•¿åº¦çš„è¯·æ±‚åŠ¨æ€åˆ†ç»„ä¸ºè‹¥å¹² **è´Ÿè½½å‡è¡¡çš„æ‰§è¡Œç»„ï¼ˆexecution groupsï¼‰**ã€‚
   - æ¯ä¸ªç»„ä½œä¸ºä¸€ä¸ªç»Ÿä¸€çš„ kernel æ‰§è¡Œå•å…ƒï¼Œé¿å… per-request paddingã€‚
   - ä½¿ç”¨è´ªå¿ƒç®—æ³•è¿›è¡Œ **è‡ªé€‚åº”åˆ†ç»„ï¼ˆadaptive groupingï¼‰**ï¼Œæœ€å°åŒ–ç»„é—´è´Ÿè½½å·®å¼‚ï¼Œå¹¶åœ¨è§£ç è¿‡ç¨‹ä¸­å®šæœŸ **re-grouping** ä»¥ç»´æŒå¹³è¡¡ã€‚

2. **Packed I/Oï¼ˆæ‰“åŒ… I/Oï¼‰**
   - æ„å»º **group-contiguous çš„ KV Cache å¸ƒå±€**ï¼Œæ¶ˆé™¤å†…å­˜ç¢ç‰‡ã€‚
   - ç»“åˆ **prefix sharing**ï¼Œå°†å…±äº«å‰ç¼€åˆå¹¶å­˜å‚¨ï¼Œå‡å°‘é‡å¤è¯»å–ã€‚
   - å¼•å…¥ **contiguous memory consolidation**ï¼Œå°†åˆ†æ•£çš„ PagedAttention å—æ•´åˆä¸ºè¿ç»­ bufferï¼Œæå‡ memory coalescing å’Œå¸¦å®½åˆ©ç”¨ç‡ã€‚

3. **ç«¯åˆ°ç«¯é›†æˆå‹å¥½**
   - å¯ä½œä¸º FlashAttention çš„ drop-in æ›¿ä»£ï¼Œä»…éœ€å°‘é‡ API ä¿®æ”¹å³å¯é›†æˆè¿› vLLM ç­‰ä¸»æµæ¨ç†å¼•æ“ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ FlashAttentionï¼‰ | PackInfer |
|------|-------------------------------|---------|
| **è®¡ç®—æ•ˆç‡** | å›ºå®š tile å¤§å°å¯¼è‡´ padding æµªè´¹ | æ¶ˆé™¤ paddingï¼Œå®ç° dense kernel execution |
| **è´Ÿè½½å‡è¡¡** | å„è¯·æ±‚ç‹¬ç«‹æ‰§è¡Œï¼Œå­˜åœ¨ä¸¥é‡ straggler | åŠ¨æ€åˆ†ç»„ + è‡ªé€‚åº” regroupingï¼Œå‡è¡¡ SM è´Ÿè½½ |
| **å†…å­˜è®¿é—®** | KV Cache åˆ†æ•£ï¼Œè®¿é—®ä¸è¿ç»­ | è¿ç»­å¸ƒå±€ + å…±äº«å‰ç¼€åˆå¹¶ï¼Œæå‡ I/O å±€éƒ¨æ€§ |
| **é€‚ç”¨æ€§** | å•è¯·æ±‚ä¼˜åŒ–ä¸ºä¸» | æ”¯æŒ batch-level ä¼˜åŒ–ï¼Œé€‚ç”¨äºå¼‚æ„ workload |
| **å…¼å®¹æ€§** | å·²å¹¿æ³›ä½¿ç”¨ | å¯æ— ç¼æ›¿æ¢ FlashAttentionï¼Œæ˜“äºéƒ¨ç½² |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

- **Alpaca**ï¼šæŒ‡ä»¤è·Ÿéšç±»ä»»åŠ¡ï¼Œæ¨¡æ‹Ÿå¸¸è§å¯¹è¯åœºæ™¯ã€‚
- **LMSYS-Chat**ï¼šçœŸå®çš„ ChatGPT ç”¨æˆ·äº¤äº’è½¨è¿¹ï¼ŒåŒ…å«å¤šæ ·åŒ–çš„è¾“å…¥é•¿åº¦åˆ†å¸ƒã€‚
- **Text2SQL**ï¼šç»“æ„åŒ–æŸ¥è¯¢ç”Ÿæˆä»»åŠ¡ï¼Œå…¸å‹çŸ­è¾“å…¥å¯†é›†å‹ workloadã€‚

æ¯ä¸ªæ•°æ®é›†åŒ…å« 7,000 è‡³ 200,000 æ¡ promptï¼Œè¦†ç›–ä¸åŒè¯·æ±‚æ¨¡å¼ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

- **ç¡¬ä»¶å¹³å°**ï¼š
  - é»˜è®¤ï¼šå•å¼  **NVIDIA A100 40GB**
  - æ‰©å±•æµ‹è¯•ï¼š**H200ã€A40ã€4Ã—A100ï¼ˆåˆ†å¸ƒå¼ï¼‰**
- **æ¨¡å‹**ï¼š
  - Qwen3-4Bã€Mistral-7Bã€Qwen3-30B-A3Bï¼ˆMoEï¼‰
- **æ¨ç†å¼•æ“**ï¼š
  - åŸºäº **Nano-vLLM** å®ç°ï¼Œé›†æˆ PackInfer ä½œä¸º FlashAttention çš„æ›¿ä»£æ¨¡å—ã€‚
- **è°ƒåº¦ç­–ç•¥**ï¼š
  - ä½¿ç”¨æ ‡å‡† FCFSï¼ˆå…ˆæ¥å…ˆæœåŠ¡ï¼‰è°ƒåº¦ã€‚

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | æè¿° |
|------|------|
| **TTFT**ï¼ˆTime-to-First-Tokenï¼‰ | é¦–ä¸ª token è¾“å‡ºå»¶è¿Ÿï¼Œåæ˜  prefilling æ€§èƒ½ |
| **TBT**ï¼ˆTime-Between-Tokensï¼‰ | è§£ç æ­¥é—´å»¶è¿Ÿï¼Œåæ˜  decoding æ•ˆç‡ |
| **TTLT**ï¼ˆTime-to-Last-Tokenï¼‰ | å®Œæ•´å“åº”ç”Ÿæˆæ—¶é—´ |
| **Throughput**ï¼ˆååé‡ï¼‰ | å•ä½æ—¶é—´å†…è¾“å‡ºçš„ token æ•°é‡ |
| **P99 å»¶è¿Ÿ** | å°¾éƒ¨å»¶è¿Ÿè¡¨ç° |
| **GPU Utilization** | åŒ…æ‹¬ SM occupancyã€Tensor Core åˆ©ç”¨ç‡ã€memory bandwidth ç­‰åº•å±‚æŒ‡æ ‡ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

- **FlashAttention**ï¼ˆDao et al., 2022; 2024ï¼‰ï¼šå½“å‰æœ€å…ˆè¿›çš„ attention kernelï¼Œæ”¯æŒ tiling å’Œ recomputationã€‚
- **Prepack**ï¼ˆZhao et al., 2024ï¼‰ï¼šè¿‘æœŸæå‡ºçš„ KV cache é‡æ’åºæ–¹æ³•ï¼Œä¼˜åŒ–å†…å­˜å¸ƒå±€ä½†ä¸ä¿®æ”¹ attention kernelã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### âœ… æ¨ç†å»¶è¿Ÿé™ä½
- **TBTï¼ˆtime-between-tokensï¼‰é™ä½ 13.0â€“20.1%**
- **TTFTï¼ˆtime-to-first-tokenï¼‰æœ€é«˜é™ä½ 18.6%**
- **TTLTï¼ˆtotal latencyï¼‰é™ä½ 3.8â€“20.2%**

> å›¾5ã€å›¾6 æ˜¾ç¤ºåœ¨ Mistral-7B å’Œ Qwen3-4B ä¸Šå‡æœ‰æ˜¾è‘—æ”¹è¿›ï¼Œå°¤å…¶åœ¨ LMSYS å’Œ Text2SQL ç­‰å¼‚æ„æ€§å¼ºçš„ workload ä¸­ä¼˜åŠ¿æ›´æ˜æ˜¾ã€‚

#### âœ… ååé‡æå‡
- **æ•´ä½“ throughput æå‡çº¦ 20%**
- åœ¨æŸäº›é…ç½®ä¸‹é«˜è¾¾ **24.9% çš„ååå¢ç›Š**
- å¦‚å›¾8æ‰€ç¤ºï¼ŒPackInfer çš„å¹³å‡ååç”šè‡³è¶…è¿‡ FlashAttention çš„ P95 ååï¼Œè¯´æ˜å…¶ç¨³å®šæ€§æ›´å¼ºã€‚

#### âœ… èµ„æºåˆ©ç”¨ç‡æå‡
| æŒ‡æ ‡ | FlashAttention | PackInfer | æå‡å¹…åº¦ |
|------|----------------|-----------|----------|
| **Tensor Core Throughput** | 18% | 33% | â†‘83% |
| **SM Instruction Issue** | 17% | 25% | â†‘47% |

> è¡¨æ˜ PackInfer æˆåŠŸæå‡äº†ç¡¬ä»¶çº§æ‰§è¡Œå¯†åº¦ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰ç»„ä»¶è´¡çŒ®åˆ†æï¼ˆå›¾9ï¼‰
- **+ Pack Computation**ï¼šå•ç‹¬å¯ç”¨å¯å¸¦æ¥æ˜¾è‘—åŠ é€Ÿï¼Œä¸»å› æ˜¯å‡å°‘äº† kernel launch å¼€é”€å’Œæ— æ•ˆè®¡ç®—ã€‚
- **+ Pack I/O**ï¼šè¿›ä¸€æ­¥ä¼˜åŒ–å†…å­˜è®¿é—®ï¼Œå°¤å…¶åœ¨ prefix sharing åœºæ™¯ä¸‹æ•ˆæœæ˜æ˜¾ã€‚
- **ä¸¤è€…ç»“åˆ**ï¼šè·å¾—æœ€å¤§æ”¶ç›Šï¼Œè¯æ˜ compute ä¸ I/O ååŒè®¾è®¡çš„é‡è¦æ€§ã€‚

#### ï¼ˆ2ï¼‰åˆ†ç»„å¤§å°å½±å“ï¼ˆå›¾10ï¼‰
- æœ€ä¼˜ group size å‡ºç°åœ¨ **2048 token å·¦å³**ã€‚
- è¿‡å¤§å¯¼è‡´å†…éƒ¨ç¢ç‰‡å¢åŠ ï¼Œè¿‡å°åˆ™æ— æ³•å……åˆ†å¹¶è¡Œã€‚
- é€šè¿‡ç¦»çº¿ profiling ç¡®å®šå®¹é‡ C=8192ï¼Œè¿è¡Œæ—¶åŠ¨æ€è°ƒæ•´ï¼ŒéªŒè¯äº† adaptive grouping çš„æœ‰æ•ˆæ€§ã€‚

#### ï¼ˆ3ï¼‰è·¨ç¡¬ä»¶æ³›åŒ–èƒ½åŠ›ï¼ˆå›¾11ï¼‰
- åœ¨ **A100ã€A40ã€H200** ä¸Šå‡å®ç° **11%-19% çš„ TBT é™ä½**ã€‚
- è¯´æ˜ PackInfer ä¸ä¾èµ–ç‰¹å®šç¡¬ä»¶ï¼Œå…·å¤‡è‰¯å¥½å¯ç§»æ¤æ€§ã€‚

#### ï¼ˆ4ï¼‰å¤š GPU æ‰©å±•æ€§ï¼ˆå›¾12ï¼‰
- åœ¨ **4Ã—A100 + TP=4** è®¾ç½®ä¸‹ä»ä¿æŒæ€§èƒ½å¢ç›Šã€‚
- æ— é¢å¤–é€šä¿¡å¼€é”€ï¼Œè¡¨æ˜å…¶å¤©ç„¶æ”¯æŒåˆ†å¸ƒå¼æ¨ç†ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **å¼‚æ„ batch æ˜¯å½“å‰ LLM æ¨ç†æ•ˆç‡ç“¶é¢ˆçš„æ ¹æœ¬åŸå› **ï¼Œä¼ ç»Ÿ padding-based æ‰§è¡Œæ¨¡å¼é€ æˆä¸¥é‡çš„è®¡ç®—ä¸ I/O æµªè´¹ã€‚
2. **kernel-level çš„ request packing æ˜¯è§£å†³è¯¥é—®é¢˜çš„æœ‰æ•ˆè·¯å¾„**ï¼ŒPackInfer é€šè¿‡è”åˆä¼˜åŒ– compute ä¸ I/Oï¼Œå®ç°äº†çœŸæ­£çš„â€œdense executionâ€ã€‚
3. **prefix sharing åº”è¢«çº³å…¥æ‰§è¡Œè°ƒåº¦è€ƒè™‘**ï¼ŒPackInfer å°†å…¶èå…¥ grouping å†³ç­–ï¼Œæœ€å¤§åŒ–æ•°æ®å¤ç”¨ã€‚
4. **è½»é‡çº§ greedy grouping + adaptive regrouping** èƒ½åœ¨æä½å¼€é”€ä¸‹é€¼è¿‘æœ€ä¼˜è´Ÿè½½å‡è¡¡ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

1. **åˆ†ç»„å†³ç­–å¼•å…¥ä¸€å®šè°ƒåº¦å¼€é”€**ï¼Œè™½ç„¶å®éªŒè¯æ˜å…¶è¿œä½äºæ”¶ç›Šï¼Œä½†åœ¨æç«¯é«˜é¢‘å°æ‰¹é‡åœºæ™¯å¯èƒ½éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚
2. **ç›®å‰å‡è®¾ attention kernel tile size å›ºå®š**ï¼Œè‹¥æœªæ¥å‡ºç°åŠ¨æ€ tile æ”¯æŒï¼Œå¯è¿›ä¸€æ­¥å¢å¼ºçµæ´»æ€§ã€‚
3. **æœªæ˜¾å¼æ”¯æŒ speculative decoding æˆ–å…¶ä»–é«˜çº§é‡‡æ ·ç­–ç•¥**ï¼Œæœªæ¥å¯æ‰©å±•è‡³æ›´å¤šæ¨ç†èŒƒå¼ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

- å°† PackInfer ä¸ **speculative decoding**ã€**chunked generation** ç­‰æŠ€æœ¯ç»“åˆï¼Œæ„å»ºå…¨æ ˆä¼˜åŒ–æ¨ç†ç³»ç»Ÿã€‚
- æ¢ç´¢ **learned grouping policy**ï¼Œåˆ©ç”¨ RL æˆ– ML æ¨¡å‹é¢„æµ‹æœ€ä¼˜åˆ†ç»„ç­–ç•¥ã€‚
- æ‰©å±•è‡³ **vision-language models** æˆ– **video generation** ç­‰ multimodal åœºæ™¯ï¼Œå¤„ç†æ›´å¤æ‚çš„ I/O æ¨¡å¼ã€‚
- åœ¨ **è¾¹ç¼˜è®¾å¤‡** ä¸ŠéªŒè¯å…¶è½»é‡åŒ–æ½œåŠ›ï¼Œç”¨äºç§»åŠ¨ç«¯ LLM éƒ¨ç½²ã€‚

---

## âœ… æ€»ç»“

**PackInfer** æ˜¯é¦–ä¸ªä» **kernel å±‚é¢ç³»ç»Ÿæ€§è§£å†³å¼‚æ„ batch æ¨ç†æ•ˆç‡é—®é¢˜** çš„å·¥ä½œã€‚å®ƒé€šè¿‡ **compute-aware åˆ†ç»„ + I/O-aware å†…å­˜é‡ç»„**ï¼Œå®ç°äº†ï¼š

- **å»¶è¿Ÿä¸‹é™ 13â€“20%**
- **ååæå‡ ~20%**
- **GPU åˆ©ç”¨ç‡æ˜¾è‘—æé«˜**

ä¸”å…¼å®¹ç°æœ‰ç”Ÿæ€ï¼ˆå¦‚ vLLMã€FlashAttentionï¼‰ï¼Œå…·å¤‡å¼ºå®ç”¨æ€§ä¸æ¨å¹¿ä»·å€¼ã€‚è¯¥å·¥ä½œæ­ç¤ºäº† **batch-level ç»“æ„ä¼˜åŒ–** åœ¨ LLM serving ä¸­çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºä¸‹ä¸€ä»£é«˜æ€§èƒ½æ¨ç†ç³»ç»Ÿæä¾›äº†é‡è¦è®¾è®¡èŒƒå¼ã€‚

</details>

---

### 3. [FCDP: Fully Cached Data Parallel for Communication-Avoiding Large-Scale Training](https://arxiv.org/abs/2602.06499)

**Authors**: Gyeongseo Park, Eungyeong Lee, Song-woo Sok, Myung-Hoon Cha, Kwangwon Koh, Baik-Song An, Hongyeon Kim, Ki-Dong Kang  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.06499v1  

#### Abstract
Training billion-parameter models requires distributing model states across GPUs using fully sharded data parallel (i.e., ZeRO-3). While ZeRO-3 succeeds on clusters with high-bandwidth NVLink and InfiniBand interconnects, researchers with commodity hardware face severe inter-node all-gather bottlene...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFCDP: Fully Cached Data Parallel for Communication-Avoiding Large-Scale Training

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹è®­ç»ƒä¸­ï¼Œ**Fully Sharded Data Parallelismï¼ˆå¦‚ ZeRO-3ï¼‰** è™½ç„¶èƒ½æ˜¾è‘—é™ä½å•ä¸ª GPU çš„å†…å­˜å ç”¨ï¼Œä½†åœ¨**å¸¦å®½å—é™çš„é€šç”¨ç¡¬ä»¶é›†ç¾¤**ï¼ˆcommodity clustersï¼‰ä¸Šé¢ä¸´ä¸¥é‡çš„é€šä¿¡ç“¶é¢ˆã€‚å…·ä½“è¡¨ç°ä¸ºï¼š

- ZeRO-3 æ¯å±‚éœ€è¦ä¸¤æ¬¡ **inter-node all-gather**ï¼ˆå‰å‘å’Œåå‘å„ä¸€æ¬¡ï¼‰ï¼Œå¯¼è‡´è®­ç»ƒæ—¶é—´è¢«é€šä¿¡ä¸»å¯¼ã€‚
- ç°æœ‰ä¼˜åŒ–æ–¹æ³•å­˜åœ¨æƒè¡¡ï¼š
  - **GPU å†…å­˜ç¼“å­˜**ï¼ˆå¦‚ MiCSã€ZeRO++ï¼‰å‡å°‘é€šä¿¡ä½†å¢åŠ  GPU å†…å­˜å‹åŠ›ï¼Œé™åˆ¶æœ€å¤§ batch sizeã€‚
  - **ä¸»æœºå†…å­˜å¸è½½**ï¼ˆå¦‚ ZeRO-Offload/Infinityï¼‰æ‰©å±•å®¹é‡ä½†å¼•å…¥ PCIe å¼€é”€ï¼Œé™ä½ååã€‚

FCDP çš„æ ¸å¿ƒæ´å¯Ÿæ˜¯ï¼š  
> åœ¨å¸¦å®½å—é™çš„é›†ç¾¤ä¸­ï¼Œ**ä» host memory ç» PCIe åŠ è½½å‚æ•°å¯èƒ½æ¯”è·¨èŠ‚ç‚¹ç½‘ç»œé€šä¿¡æ›´å¿«**ã€‚å› æ­¤ï¼Œhost memory ä¸åº”ä»…ä½œä¸ºâ€œæº¢å‡ºå­˜å‚¨â€ï¼Œè€Œå¯ä½œä¸º**é«˜æ€§èƒ½é€šä¿¡ç¼“å­˜å±‚**ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
FCDPï¼ˆ**Fully Cached Data Parallel**ï¼‰æå‡ºäº†ä¸€ç§åŸºäº host memory çš„é«˜æ•ˆç¼“å­˜æœºåˆ¶ï¼Œåœ¨ä¸ç‰ºç‰² ZeRO-3 å†…å­˜æ•ˆç‡çš„å‰æä¸‹å¤§å¹…å‡å°‘é€šä¿¡å¼€é”€ã€‚å…¶ä¸‰å¤§æ ¸å¿ƒæŠ€æœ¯ç»„ä»¶ä¸ºï¼š

#### âœ… FCDP-Schedï¼šè°ƒåº¦é©±åŠ¨çš„å‚æ•°ç¼“å­˜
- åˆ©ç”¨å‰å‘ä¼ æ’­ä¸­çš„ `all-gather` ç»“æœï¼Œå°†å…¶**å¼‚æ­¥ç¼“å­˜åˆ° host memory**ã€‚
- åå‘ä¼ æ’­æ—¶ï¼Œé€šè¿‡ **intra-node all-gather**ï¼ˆåˆ©ç”¨ NVLink æˆ– PCIeï¼‰é‡å»ºå‚æ•°ï¼Œ**å®Œå…¨é¿å… backward-pass çš„ inter-node all-gather**ã€‚
- å‡å°‘ 50% çš„ inter-node é€šä¿¡é‡ã€‚

#### âœ… FCDP-Cacheï¼šè‡ªé€‚åº”å†…å­˜ç®¡ç†
- åŠ¨æ€åˆ¤æ–­æ˜¯å¦å°†å‚æ•°ä¿ç•™åœ¨ GPU ä¸Šï¼š
  - è‹¥ GPU å†…å­˜å……è¶³ï¼ˆä½äºé˜ˆå€¼ Tï¼‰ï¼Œåˆ™ä¿ç•™ä»¥è·³è¿‡ PCIe ä¼ è¾“ï¼›
  - å¦åˆ™å¸è½½è‡³ host memoryã€‚
- å®ç°â€œæœºä¼šæ€§ç¼“å­˜â€ï¼šæ—¢æœ€å°åŒ– PCIe ä¼ è¾“ï¼Œåˆä¿è¯æœ€åæƒ…å†µä¸‹çš„å†…å­˜ä½¿ç”¨ä¸ ZeRO-3 ä¸€è‡´ã€‚

#### âœ… FCDP-Commï¼šPEFT æ„ŸçŸ¥é€šä¿¡ä¼˜åŒ–
- é’ˆå¯¹ **Parameter-Efficient Fine-Tuningï¼ˆPEFTï¼‰** åœºæ™¯ï¼ˆå¦‚ LoRAï¼‰ï¼š
  - å°†å‚æ•°åˆ†ä¸º **trainable** å’Œ **frozen** ä¸¤ç±»ã€‚
  - **Frozen å‚æ•°åª gather ä¸€æ¬¡å¹¶æ°¸ä¹…ç¼“å­˜äº host memory**ã€‚
  - åç»­è¿­ä»£ä»…å¯¹ `<1%` çš„ trainable å‚æ•°æ‰§è¡Œ inter-node all-gatherã€‚
- å¯¹ LoRA ç±»ä»»åŠ¡ï¼Œ**inter-node é€šä¿¡å‡å°‘è¶…è¿‡ 99%**ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹æ³• | GPU å†…å­˜ | Inter-node Comm | æ˜¯å¦æ”¯æŒ PEFT ä¼˜åŒ– | æœ€å¤§ batch size |
|------|----------|------------------|--------------------|----------------|
| ZeRO-3 | âœ… æœ€å°ï¼ˆW/Gï¼‰ | âŒ é«˜ï¼ˆ2Wï¼‰ | âŒ | âœ… å¤§ |
| ZeRO++ | âŒ é«˜ï¼ˆéœ€é¢å¤–ç¼“å­˜ï¼‰ | âœ… ä½ï¼ˆä»… forwardï¼‰ | âŒ | âŒ å—é™ |
| FCDP | âœ… æœ€å°ï¼ˆW/Gï¼‰ | âœ… æä½ï¼ˆ~0 for frozenï¼‰ | âœ… æ”¯æŒ | âœ… ä¸ ZeRO-3 ç›¸åŒ |

> **FCDP æˆåŠŸè§£è€¦äº†â€œé€šä¿¡ä¼˜åŒ–â€ä¸â€œGPU å†…å­˜å®¹é‡â€çš„å¼ºè€¦åˆå…³ç³»**ï¼Œå®ç°äº† ZeRO++ çš„é€šä¿¡æ•ˆç‡ + ZeRO-3 çš„å†…å­˜æ•ˆç‡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **SQuAD** æ•°æ®é›†ç”¨äº fine-tuning å®éªŒã€‚

### æ¨¡å‹é…ç½®
åŸºäº GPT-2-XL æ‰©å±•çš„ç³»åˆ—æ¨¡å‹ï¼ˆå‚æ•°è§„æ¨¡ä» 10B åˆ° 30Bï¼‰ï¼š

| Model | Params | Layers | Hidden Size |
|-------|--------|--------|-------------|
| GPT-10B | 10B | 40 | 4800 |
| GPT-15B | 15B | 40 | 5760 |
| ... | ... | ... | ... |
| GPT-30B | 30B | 40 | 7936 |

### å®éªŒç¯å¢ƒ
- **ç¡¬ä»¶**ï¼š4 èŠ‚ç‚¹é›†ç¾¤ï¼Œæ¯èŠ‚ç‚¹ 2Ã—AMD EPYC 7313 CPU + 8Ã—NVIDIA A40ï¼ˆ48GBï¼‰GPUã€‚
- **äº’è”**ï¼š
  - èŠ‚ç‚¹å†…ï¼šNVLink / PCIe Gen4 x16
  - èŠ‚ç‚¹é—´ï¼šInfiniBand 100Gbps EDR
- **è½¯ä»¶æ ˆ**ï¼šDeepSpeed v0.16.2 + PyTorch 2.3.0ï¼Œæ··åˆç²¾åº¦è®­ç»ƒï¼ˆFP16 æ¿€æ´»/æ¢¯åº¦ï¼ŒFP32 ä¸»æƒé‡ï¼‰ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **Training Throughput**ï¼ˆæ ·æœ¬/ç§’ï¼‰
- **Maximum Batch Size**ï¼ˆæ¯ GPUï¼‰
- **Inter-node Communication Volume**ï¼ˆGB/iterï¼‰
- **Bandwidth Sensitivity**ï¼ˆä¸åŒç½‘ç»œæ¡ä»¶ä¸‹æ€§èƒ½å˜åŒ–ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ZeRO-3**ï¼šæ ‡å‡†å…¨åˆ†ç‰‡æ–¹æ¡ˆï¼Œä¸¤æ¬¡ all-gatherã€‚
- **ZeRO++**ï¼šGPU ç¼“å­˜æ–¹æ¡ˆï¼Œæ¶ˆé™¤ backward all-gatherã€‚
- **FCDP variants**ï¼š
  - FCDP-Schedï¼šåŸºç¡€ç‰ˆæœ¬ï¼ˆç¼“å­˜ backward å‚æ•°ï¼‰
  - FCDP-Commï¼šå¯ç”¨ PEFT æ„ŸçŸ¥ä¼˜åŒ–

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ğŸ”¹ å¼ºæ‰©å±•æ€§æµ‹è¯•ï¼ˆStrong Scalingï¼‰
- å›ºå®š microbatch size = 8ï¼Œæ¯”è¾ƒä¸åŒ GPU æ•°é‡ä¸‹çš„ååã€‚
- **FCDP æ¯” ZeRO-3 æœ€é«˜æå‡ 40.2%**ã€‚
- åœ¨ GPT-20B å’Œ GPT-30B ä¸Šï¼Œ**ZeRO++ å‡ºç° OOM**ï¼Œè€Œ FCDP æ­£å¸¸è¿è¡Œã€‚

#### ğŸ”¹ æœ€å¤§ batch size æ€§èƒ½
| Model | ZeRO-3 Max BS | ZeRO++ Max BS | FCDP Max BS |
|-------|---------------|----------------|-------------|
| GPT-10B (4 nodes) | 512 | 512 | 512 |
| GPT-30B (4 nodes) | 256 | 128 | 256 |

> âœ… **FCDP ä¿æŒä¸ ZeRO-3 ç›¸åŒçš„æœ€å¤§ batch size**ï¼Œè€Œ ZeRO++ æ˜¾è‘—ä¸‹é™ã€‚

- åœ¨ GPT-10B ä¸Šï¼ŒFCDP è¾¾åˆ° **æœ€é«˜ 41.3% çš„ååæå‡**ï¼ˆç›¸æ¯” ZeRO-3ï¼‰ã€‚
- åœ¨ GPT-30B ä¸Šï¼ŒFCDP å®ç° **2Ã— äº ZeRO++ çš„åå**ã€‚

#### ğŸ”¹ PEFT åœºæ™¯æ€§èƒ½ï¼ˆLoRA, rank=8ï¼‰
- Trainable å‚æ•°å æ¯”ï¼š<1%
- **FCDP-Comm å®ç°é«˜è¾¾ 100Ã— ç›¸æ¯” ZeRO-3 çš„ååæå‡**ã€‚
- ç›¸æ¯” ZeRO++ï¼Œä¹Ÿè¾¾åˆ° **51Ã— æ›´é«˜çš„åå**ã€‚

#### ğŸ”¹ é€šä¿¡é‡åˆ†æï¼ˆPer Iterationï¼‰

| System | Forward (GB) | Backward (GB) | Total (GB) |
|--------|--------------|----------------|------------|
| ZeRO-3 | 110.25 | 103.48 | 213.73 |
| ZeRO++ | 108.18 | 0.1 | 108.28 |
| FCDP-Sched | 108.18 | 0.1 | 108.28 |
| **FCDP-Comm** | **0.06** | **0.1** | **0.16** |

> - FCDP-Sched å‡å°‘ 49.3% é€šä¿¡ï¼ˆæ¶ˆé™¤ backward all-gatherï¼‰
> - FCDP-Comm å‡å°‘ **99.9%** inter-node é€šä¿¡ï¼

#### ğŸ”¹ ç½‘ç»œå¸¦å®½æ•æ„Ÿæ€§æµ‹è¯•
- å½“ inter-node å¸¦å®½ä» 100Gbps é™è‡³ 1Gbps Ethernetï¼š
  - ZeRO-3 ååä¸‹é™ **98.4%**
  - ZeRO++ ä¸‹é™ **97.4%**
  - **FCDP-Comm ä»ç»´æŒ 90.5% çš„å³°å€¼åå**
  - FCDP ç»´æŒ 86.3%

> è¡¨æ˜ FCDP å¯¹ä½å¸¦å®½ç½‘ç»œå…·æœ‰æå¼ºé²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Host memory å¯ä½œä¸ºé«˜é€Ÿç¼“å­˜å±‚è€Œéä»…å®¹é‡æ‰©å±•**ï¼šåœ¨å¸¦å®½å—é™é›†ç¾¤ä¸­ï¼ŒPCIe ä¼ è¾“é€Ÿåº¦å¯ä¼˜äº inter-node ç½‘ç»œé€šä¿¡ã€‚
2. **FCDP å®ç°é€šä¿¡ä¸å†…å­˜çš„è§£è€¦ä¼˜åŒ–**ï¼šåœ¨ä¸å¢åŠ  GPU å†…å­˜è´Ÿæ‹…çš„å‰æä¸‹ï¼Œå®ç° ZeRO++ çº§åˆ«çš„é€šä¿¡å‰Šå‡ã€‚
3. **PEFT åœºæ™¯ä¸‹é€šä¿¡å†—ä½™æé«˜**ï¼šå†»ç»“å‚æ•°åå¤ gather æ˜¯å·¨å¤§æµªè´¹ï¼›åˆ†ç±»å¤„ç†å¯å¸¦æ¥ç™¾å€åŠ é€Ÿã€‚
4. **FCDP å…·å¤‡è‰¯å¥½å®ç”¨æ€§**ï¼šçº¯è½¯ä»¶æ–¹æ¡ˆï¼Œæ— éœ€ç¡¬ä»¶æ”¹é€ ï¼Œé€‚ç”¨äºç»å¤§å¤šæ•°äº‘ä¸Šæˆ–æœ¬åœ° commodity clusterã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ– intra-node é«˜é€Ÿäº’è”**ï¼ˆå¦‚ NVLinkï¼‰æ¥æ”¯æ’‘ intra-node all-gather çš„æ•ˆç‡ã€‚
- è‹¥èŠ‚ç‚¹å†…æ— é«˜é€Ÿäº’è”ï¼ˆä»…é  PCIe switchï¼‰ï¼Œintra-node all-gather æ•ˆç‡ä¼šä¸‹é™ã€‚
- å½“å‰å®ç°å‡è®¾æ¨¡å‹å±‚é¡ºåºæ‰§è¡Œï¼Œå¯¹ pipeline parallelism çš„é›†æˆå°šæœªæ·±å…¥æ¢è®¨ã€‚
- å¯¹é LoRA ç±» PEFTï¼ˆå¦‚ Adapterã€Prefix-Tuningï¼‰çš„æ”¯æŒéœ€è¿›ä¸€æ­¥é€‚é…ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† FCDP ä¸ **Tensor Parallelism** å’Œ **Pipeline Parallelism** ç»“åˆï¼Œæ„å»ºå®Œæ•´çš„ 3D å¹¶è¡Œè®­ç»ƒæ¡†æ¶ã€‚
- æ¢ç´¢æ›´æ™ºèƒ½çš„ **cache é¢„å–ç­–ç•¥**ï¼Œç»“åˆ workload é¢„æµ‹åŠ¨æ€è°ƒæ•´ç¼“å­˜ç²’åº¦ã€‚
- æ‰©å±•è‡³ **multi-modal æ¨¡å‹** å’Œ **inference åœºæ™¯** ä¸­çš„é€šä¿¡ä¼˜åŒ–ã€‚
- æ”¯æŒ **å¼‚æ„è®¾å¤‡é›†ç¾¤**ï¼ˆå¦‚ CPU-only èŠ‚ç‚¹å‚ä¸ç¼“å­˜æœåŠ¡ï¼‰ã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **FCDP é‡æ–°å®šä¹‰äº† host memory åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„è§’è‰²â€”â€”å®ƒä¸ä»…æ˜¯â€œå¤‡ç”¨ä»“åº“â€ï¼Œæ›´æ˜¯â€œåŠ é€Ÿç¼“å­˜â€ã€‚é€šè¿‡å·§å¦™è°ƒåº¦ä¸ PEFT æ„ŸçŸ¥è®¾è®¡ï¼ŒFCDP åœ¨ commodity hardware ä¸Šå®ç°äº†æ¥è¿‘ç™¾å€çš„è®­ç»ƒåŠ é€Ÿï¼ŒåŒæ—¶ä¿æŒ ZeRO-3 çš„æè‡´å†…å­˜æ•ˆç‡ã€‚**

</details>

---

### 4. [SOCKET: SOft Collison Kernel EsTimator for Sparse Attention](https://arxiv.org/abs/2602.06283)

**Authors**: Sahil Joshi, Agniva Chowdhury, Wyatt Bellinger, Amar Kanakamedala, Ekam Singh, Hoang Anh Duy Le, Aditya Desai, Anshumali Shrivastava  
**Category**: cs.LG  
**Published**: 2026-02-09  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.06283v1  

#### Abstract
Exploiting sparsity during long-context inference is central to scaling large language models, as attention dominates the cost of autoregressive decoding. Sparse attention reduces this cost by restricting computation to a subset of tokens, but its effectiveness depends critically on efficient scorin...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# SOCKET: SOft Collison Kernel EsTimator for Sparse Attention â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨ **long-context inference** ä¸­ï¼Œæ ‡å‡†çš„ **dense attention** è®¡ç®—æˆæœ¬éšä¸Šä¸‹æ–‡é•¿åº¦å‘ˆå¹³æ–¹å¢é•¿ï¼Œå¯¼è‡´å†…å­˜å’Œè®¡ç®—ç“¶é¢ˆã€‚å°½ç®¡ **sparse attention** è¢«å¹¿æ³›ç”¨äºç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œä½†å…¶æ•ˆæœé«˜åº¦ä¾èµ–äºå¦‚ä½•é«˜æ•ˆä¸”å‡†ç¡®åœ°é€‰æ‹©â€œé‡è¦â€token è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚

ä¼ ç»ŸåŸºäº **Locality-Sensitive Hashing (LSH)** çš„æ–¹æ³•ä½¿ç”¨ **hard bucket matching**ï¼ˆç¡¬å“ˆå¸ŒåŒ¹é…ï¼‰ï¼Œå³ä»…å½“æŸ¥è¯¢ï¼ˆqueryï¼‰ä¸é”®ï¼ˆkeyï¼‰è½å…¥ç›¸åŒå“ˆå¸Œæ¡¶æ—¶æ‰è®¡åˆ†ï¼Œè¿™ç§ç¦»æ•£ä¿¡å·å¯¹ **ranking ç¨³å®šæ€§å·®**ï¼Œå®¹æ˜“å› å™ªå£°å¯¼è‡´é”™è¯¯æ’åºï¼Œä»è€Œå½±å“ç¨€ç–æ³¨æ„åŠ›çš„è´¨é‡ã€‚

### ğŸ”§ æå‡ºçš„æ–°æ–¹æ³•ï¼šSOCKET
æœ¬æ–‡æå‡º **SOCKET**ï¼ˆSOft Collison Kernel EsTimatorï¼‰ï¼Œä¸€ç§å°† LSH ä»å€™é€‰ç”Ÿæˆå¯å‘å¼å‡çº§ä¸º **å¯å¾®ã€ç›¸ä¼¼æ€§æ„ŸçŸ¥çš„ scoring kernel** çš„æ–°æ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- å°†ä¼ ç»Ÿçš„ **hard LSH**ï¼ˆäºŒå€¼ç¢°æ’ï¼‰æ›¿æ¢ä¸º **soft LSH**ï¼ˆæ¦‚ç‡æ€§è½¯åˆ†é…ï¼‰ã€‚
- æŸ¥è¯¢ä¸å†è¢«ç¡¬åˆ†é…åˆ°å•ä¸€å“ˆå¸Œæ¡¶ï¼Œè€Œæ˜¯é€šè¿‡ **softmax over bucket logits** äº§ç”Ÿä¸€ä¸ªè·¨æ‰€æœ‰æ¡¶çš„æ¦‚ç‡åˆ†å¸ƒã€‚
- æ¯ä¸ª key çš„æœ€ç»ˆå¾—åˆ†æ˜¯å…¶æ‰€åœ¨æ¡¶åœ¨å¤šä¸ªå“ˆå¸Œè¡¨ä¸­æ¥æ”¶åˆ°çš„ **è½¯æ¦‚ç‡è´¨é‡æ€»å’Œ**ï¼Œå¹¶åŠ æƒå…¶ value å‘é‡èŒƒæ•°ã€‚

> å…¬å¼å®šä¹‰ï¼š
> $$
> S_{\text{soft}}(k_j, q) = \sum_{l=1}^L p(b^{(l)}_j | q)
> $$
> å…¶ä¸­ $ p(b^{(l)}_j | q) $ æ˜¯ç¬¬ $ l $ ä¸ªå“ˆå¸Œè¡¨ä¸­ query åˆ†é…ç»™ key æ‰€åœ¨æ¡¶çš„æ¦‚ç‡ã€‚

### ğŸ†š ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | SOCKET | ä¼ ç»Ÿ LSH / å…¶ä»–ç¨€ç–æ–¹æ³• |
|------|--------|--------------------------|
| **Ranking ç¨³å®šæ€§** | âœ… é«˜ï¼ˆè½¯å¾—åˆ†ä¿ç•™ç›¸å¯¹é¡ºåºï¼‰ | âŒ ä½ï¼ˆç¡¬åŒ¹é…å™ªå£°å¤§ï¼‰ |
| **æ•°æ®ä¾èµ–æ€§** | âœ… æ•°æ®æ— å…³ï¼ˆdata-agnosticï¼‰ | âŒ å¤šéœ€è®­ç»ƒæˆ–æ ¡å‡†ï¼ˆå¦‚ PQCache, Questï¼‰ |
| **ç†è®ºä¿è¯** | âœ… æä¾›ä¸ angular attention çš„é€¼è¿‘è¯¯å·®ç•Œ | âŒ å¤šä¸ºç»éªŒè®¾è®¡ |
| **ç³»ç»Ÿæ•ˆç‡** | âœ… è‡ªå®šä¹‰ CUDA kernel + Flash Decodingï¼Œå‡å°‘å†…å­˜è®¿é—® | âŒ é€šå¸¸ä¾èµ– CPU æˆ–å¤æ‚ç´¢å¼•ç»“æ„ |

æ­¤å¤–ï¼ŒSOCKET åœ¨è§£ç é˜¶æ®µåªéœ€è¯»å–æ¯ä¸ª key çš„ **ä¸€ä¸ª bfloatï¼ˆè½¯è®¡æ•°ï¼‰å’Œä¸€ä¸ªæ•´æ•°ï¼ˆvalue normï¼‰**ï¼Œç›¸æ¯”è¯»å–å®Œæ•´ key å‘é‡ï¼ˆå¦‚ 128 bfloatsï¼‰å¤§å¹…é™ä½å†…å­˜æµé‡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **LongBench**ï¼šå¤šä»»åŠ¡é•¿æ–‡æœ¬ç†è§£åŸºå‡†ï¼Œæ¶µç›–é—®ç­”ã€æ¨ç†ã€æ‘˜è¦ã€ä»£ç ç­‰ä»»åŠ¡ï¼Œè¾“å…¥å¯è¾¾æ•°ä¸‡ tokenã€‚
- **RULER-32K / RULER-16K**ï¼šåˆæˆè¯Šæ–­åŸºå‡†ï¼Œæµ‹è¯•æ¨¡å‹åœ¨æé•¿ä¸Šä¸‹æ–‡ä¸­æ£€ç´¢ç¨€ç–ã€ä½ç½®æ•æ„Ÿä¿¡æ¯çš„èƒ½åŠ›ã€‚

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼š
  - `Llama-3.1-8B-Instruct`
  - `Llama-3.2-1B-Instruct`
  - `Qwen3-8B`
- **ä¸Šä¸‹æ–‡é•¿åº¦**ï¼šæœ€é«˜æ”¯æŒ 128K tokensã€‚
- **ç¨€ç–åº¦ï¼ˆSparsityï¼‰**ï¼šæ§åˆ¶å‚ä¸ attention çš„ token æ•°é‡ï¼ˆå¦‚ 5Ã—, 10Ã—, 50Ã—ï¼‰ï¼Œè¡¨ç¤ºåªå…³æ³¨ 1/5ã€1/10ã€1/50 çš„å†å² tokenã€‚
- **è¯„ä¼°æ–¹å¼**ï¼š
  - åœ¨ **context processing é˜¶æ®µç”¨ dense attention**ï¼›
  - åœ¨ **question processing å’Œ decoding é˜¶æ®µå¯ç”¨ sparse attention**ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **ä»»åŠ¡å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**ï¼šå„å­ä»»åŠ¡å¾—åˆ†åŠå¹³å‡åˆ†ï¼ˆAVGï¼‰ã€‚
  - **Throughputï¼ˆååé‡ï¼‰**ï¼šæ¯ç§’ç”Ÿæˆ token æ•°ï¼Œè¡¡é‡æ¨ç†æ•ˆç‡ã€‚
  - **Ranking Quality Metrics**ï¼ˆå›¾2ï¼‰ï¼š
    - **Jaccard Similarity**ï¼šé¢„æµ‹ top-k ä¸çœŸå® top-k çš„é›†åˆé‡å åº¦ã€‚
    - **Precision**ï¼šé¢„æµ‹é›†ä¸­å±äºçœŸå® top-k çš„æ¯”ä¾‹ã€‚
    - **NDCG**ï¼šè€ƒè™‘æ’åä½ç½®çš„ç›¸å…³æ€§æ’åºè´¨é‡ã€‚
    - **Score Distribution**ï¼šæ‰€é€‰ key çš„çœŸå® attention åˆ†æ•°åˆ†å¸ƒã€‚

### ğŸ†• åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æ˜¯å¦æ•°æ®ä¾èµ– |
|------|------|-------------|
| **PQCache** | Product Quantization + CPU-GPU ååŒ | âœ… æ˜¯ |
| **Quest** | Page-level è¡¨ç¤º + åŠ¨æ€å‰ªæ | âœ… æ˜¯ |
| **HashAttn** | å­¦ä¹ å“ˆå¸Œå‡½æ•° | âœ… æ˜¯ |
| **MagicPig** | LSH + é‡è¦æ€§é‡‡æ · | âœ… æ˜¯ |
| **Double Sparsity (DS)** | é€šé“ + token åŒé‡ç¨€ç– | âœ… æ˜¯ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®

#### âœ… åœ¨ **LongBench** ä¸Šçš„è¡¨ç°ï¼ˆLlama-3.1-8B-Instructï¼‰
| æ–¹æ³• | Sparsity | AVG Score |
|------|----------|-----------|
| Dense (Baseline) | â€“ | 50.3 |
| PQCache | 5Ã— | 46.7 |
| Quest | 5Ã— | 47.4 |
| **SOCKET** | **5Ã—** | **49.0** |
| PQCache | 10Ã— | 45.9 |
| Quest | 10Ã— | 46.8 |
| **SOCKET** | **10Ã—** | **48.8** |

> ğŸ’¡ ç»“è®ºï¼šSOCKET åœ¨ 5Ã— å’Œ 10Ã— ç¨€ç–ä¸‹å‡æ˜¾è‘—ä¼˜äºä¸»æµåŸºçº¿ï¼Œæ¥è¿‘ç”šè‡³è¶…è¿‡ dense attention æ€§èƒ½ã€‚

#### âœ… åœ¨ **RULER-32K** ä¸Šçš„è¡¨ç°ï¼ˆLlama-3.1-8B-Instructï¼‰
| æ–¹æ³• | Sparsity | Mem (bits/token) | avg Score |
|------|----------|------------------|-----------|
| PQCache | 50Ã— | 256 | 69.5 |
| Quest | 50Ã— | 512 | 64.1 |
| **SOCKET** | **50Ã—** | **600** | **71.9** |

> ğŸ’¡ ç»“è®ºï¼šåœ¨æç«¯ç¨€ç–ï¼ˆ50Ã—ï¼‰ä¸‹ä»ä¿æŒæœ€ä½³æ€§èƒ½ï¼Œè¯´æ˜å…¶ ranking æ›´ç¨³å®šå¯é ã€‚

#### âœ… æ¨ç†ååé‡æå‡ï¼ˆA100 / H200 GPUï¼‰
| å¹³å° | Context Length | Speedup vs. FlashAttention |
|------|----------------|-------------------------------|
| A100 | 72K | **1.52Ã—** |
| H200 | 145K | **1.5Ã—** |

> ğŸ’¡ ä½¿ç”¨è‡ªå®šä¹‰ CUDA kernel + Flash Decode Triton backendï¼Œå®ç°é«˜è¾¾ **1.5Ã— çš„ decode throughput æå‡**ã€‚

#### ğŸ” æ¶ˆèå®éªŒä¸åˆ†æï¼ˆå›¾2ï¼‰
- **å›¾2d æ˜¾ç¤º**ï¼šSOCKET æ‰€é€‰å‡ºçš„ top-k keys çš„çœŸå® attention åˆ†æ•°è¿œé«˜äº hard LSHï¼Œä¸”æ›´å¤š key è¶…è¿‡ ground-truth ç¬¬ k åé˜ˆå€¼ã€‚
- **NDCG ä¸ Precision**ï¼šSOCKET åœ¨ä¸åŒ top-k è®¾ç½®ä¸‹å§‹ç»ˆä¼˜äº hard LSHï¼Œè¯æ˜å…¶ ranking æ›´ä¼˜ã€‚
- **ç†è®ºæ”¯æ’‘**ï¼šTheorem 3 æä¾›è¯¯å·®åˆ†è§£ï¼š
  $$
  \| \hat{y} - y^* \|_2 = \mathcal{O}\left( \frac{1}{\sqrt{M}} + \frac{1}{\sqrt{L}} + \epsilon_T(q) \right)
  $$
  å…¶ä¸­ $ \epsilon_T(q) $ æ§åˆ¶ soft bucketization åå·®ï¼Œå¯é€šè¿‡æ¸©åº¦ $ T $ è°ƒèŠ‚ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Soft LSH æ¯” Hard LSH æ›´é€‚åˆä½œä¸º ranking å‡½æ•°**ï¼š
   - ç¡¬å“ˆå¸Œå¼•å…¥æœ€å¤§æ–¹å·®ï¼ˆLemma 5ï¼‰ï¼Œå¯¼è‡´ ranking ä¸ç¨³å®šï¼›
   - è½¯å“ˆå¸Œé€šè¿‡æ¦‚ç‡èšåˆä¿ç•™æ–¹å‘ä¿¡æ¯ï¼Œä¸çœŸå®ç›¸ä¼¼æ€§ä¿¡å·ç›¸å…³æ€§æ›´å¼ºï¼ˆLemma 6ï¼‰ã€‚

2. **SOCKET æ˜¯ä¸€ä¸ª principledã€data-agnostic çš„ç¨€ç–åŒ–æœºåˆ¶**ï¼š
   - æ— éœ€è®­ç»ƒæˆ–æ ¡å‡†ï¼Œéƒ¨ç½²ç®€å•ï¼›
   - æ”¯æŒç†è®ºé€¼è¿‘ä¿è¯ï¼Œé€‚ç”¨äºå¤šç§æ¨¡å‹å’Œä»»åŠ¡ã€‚

3. **ç³»ç»Ÿçº§ä¼˜åŒ–å¸¦æ¥æ˜¾è‘—æ€§èƒ½å¢ç›Š**ï¼š
   - è‡ªå®šä¹‰ CUDA kernel æå¤§å‡å°‘ key scoring å†…å­˜å¼€é”€ï¼›
   - ä¸ Flash Decoding ç»“åˆï¼Œåœ¨é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸‹å®ç° **1.5Ã— ååæå‡**ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰å®ç°ä¾§é‡äº **prefill åçš„ decoding é˜¶æ®µ**ï¼Œæœªå®Œå…¨è¦†ç›– prefilled context çš„ç¨€ç–å¤„ç†ã€‚
- è½¯å“ˆå¸Œéœ€è¦ç»´æŠ¤é¢å¤–çš„ bucket probability è¡¨ï¼Œç•¥å¾®å¢åŠ æ˜¾å­˜å ç”¨ï¼ˆçº¦ 600 bits/tokenï¼‰ã€‚
- æ¸©åº¦å‚æ•° $ T $ å’Œå“ˆå¸Œè¶…å‚ï¼ˆ$ P, L $ï¼‰éœ€è°ƒä¼˜ä»¥å¹³è¡¡åå·®ä¸æ–¹å·®ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å°† SOCKET åº”ç”¨äº **fine-tuning** é˜¶æ®µï¼Œæ¢ç´¢ç«¯åˆ°ç«¯è®­ç»ƒä¸‹çš„æ½œåŠ›ã€‚
- æ‰©å±•è‡³ **multi-head** å’Œ **grouped-query attention** åœºæ™¯ã€‚
- æ¢ç´¢ **sampling-based inference**ï¼ˆè®ºæ–‡ä¸­ä»…ä½œç†è®ºå·¥å…·ï¼‰çš„å®é™…åº”ç”¨ä»·å€¼ã€‚
- ä¸å…¶ä»– KV cache å‹ç¼©æŠ€æœ¯ï¼ˆå¦‚ quantizationï¼‰ç»“åˆï¼Œè¿›ä¸€æ­¥é™ä½å†…å­˜å‹åŠ›ã€‚

---

## ğŸ”— å¼€æºä¿¡æ¯
- **ä»£ç åœ°å€**ï¼šhttps://github.com/amarka8/SOCKET
- **è®ºæ–‡é“¾æ¥**ï¼šhttps://arxiv.org/abs/2602.06283

> SOCKET ä¸ºæ„å»ºé«˜æ•ˆã€å¯è§£é‡Šã€é«˜æ€§èƒ½çš„ long-context LLM æ¨ç†ç³»ç»Ÿæä¾›äº†æ–°çš„åŸºç¡€ç»„ä»¶ï¼Œæœ‰æœ›æˆä¸ºä¸‹ä¸€ä»£ sparse attention çš„æ ‡å‡†æ¨¡å—ä¹‹ä¸€ã€‚

</details>

---

### 5. [POP: Online Structural Pruning Enables Efficient Inference of Large Foundation Models](https://arxiv.org/abs/2602.06822)

**Authors**: Yi Chen, Wonjin Shin, Shuhong Liu, Tho Mai, Jeongmo Lee, Chuanbo Hua, Kun Wang, Jun Liu, Joo-Young Kim  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.06822v1  

#### Abstract
Large foundation models (LFMs) achieve strong performance through scaling, yet current structural pruning methods derive fixed pruning decisions during inference, overlooking sparsity patterns that emerge in the autoregressive token generation. In this paper, we propose POP (Partition-guided Online ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPOP: Online Structural Pruning Enables Efficient Inference of Large Foundation Models

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰çš„ **structural pruning** æ–¹æ³•åœ¨æ¨ç†é˜¶æ®µé€šå¸¸é‡‡ç”¨å›ºå®šçš„å‰ªæç­–ç•¥ï¼ˆstatic pruningï¼‰ï¼Œå³åœ¨é¢„å¡«å……ï¼ˆprefillingï¼‰é˜¶æ®µç¡®å®šä¸€ä¸ªå…¨å±€çš„å‰ªææ©ç ï¼Œå¹¶åœ¨æ•´ä¸ªè‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹ä¸­ä¿æŒä¸å˜ã€‚è¿™ç§é™æ€ç­–ç•¥å¿½ç•¥äº†åœ¨è§£ç ï¼ˆdecodingï¼‰è¿‡ç¨‹ä¸­å› ä¸Šä¸‹æ–‡åŠ¨æ€å˜åŒ–è€Œäº§ç”Ÿçš„ç¨€ç–æ€§æ¨¡å¼ï¼ˆcontextual sparsityï¼‰ï¼Œå¯¼è‡´åœ¨é•¿æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚

ä¾‹å¦‚ï¼Œè®ºæ–‡æŒ‡å‡ºï¼Œåœ¨ 20% å‰ªæç‡ä¸‹ï¼Œé™æ€æ–¹æ³• Tyr åœ¨çŸ­é—®ç­”ä»»åŠ¡ ARC-C ä¸Šä¿ç•™äº† 98% çš„å‡†ç¡®ç‡ï¼Œä½†åœ¨é•¿ç”Ÿæˆä»»åŠ¡ MBPP ä¸Šä»…ä¿ç•™ 35% çš„æ€§èƒ½ï¼Œè¡¨æ˜å…¶å¯¹ç”Ÿæˆä»»åŠ¡é€‚åº”æ€§å·®ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº† **POP (Partition-guided Online Pruning)**ï¼Œä¸€ç§é«˜æ•ˆçš„åœ¨çº¿ç»“æ„åŒ–å‰ªææ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨è‡ªå›å½’æ¨ç†è¿‡ç¨‹ä¸­å®ç°åŸºäºä¸Šä¸‹æ–‡çš„åŠ¨æ€å‰ªæï¼Œä¸”è®¡ç®—å¼€é”€æå°ã€‚

å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ¨¡å‹é€šé“åˆ’åˆ†ä¸ºä¸‰ä¸ªåŒºåŸŸï¼š
- **Retained Region (ä¿ç•™åŒº)**ï¼šé‡è¦æ€§é«˜çš„é€šé“ï¼Œå§‹ç»ˆæ¿€æ´»ã€‚
- **Pruned Region (å‰ªæåŒº)**ï¼šé‡è¦æ€§ä½çš„é€šé“ï¼Œç›´æ¥ç§»é™¤ã€‚
- **Candidate Region (å€™é€‰åŒº)**ï¼šé‡è¦æ€§å±…ä¸­çš„é€šé“ï¼Œåœ¨è§£ç æ—¶è¿›è¡Œç»†ç²’åº¦ã€ä¸Šä¸‹æ–‡ç›¸å…³çš„åŠ¨æ€é€‰æ‹©ã€‚

è¯¥æ–¹æ³•é€šè¿‡ä¸¤é˜¶æ®µå®ç°ï¼š
1. **Prefilling é˜¶æ®µ**ï¼šåˆ©ç”¨å®Œæ•´è¾“å…¥åºåˆ—è®¡ç®—é€šé“é‡è¦æ€§ï¼Œåˆ’åˆ†å‡ºä¸Šè¿°ä¸‰ä¸ªåŒºåŸŸï¼Œå½¢æˆç²—ç²’åº¦çš„å‰ªæåˆ†åŒºã€‚
2. **Decoding é˜¶æ®µ**ï¼šåœ¨æ¯ä¸€æ­¥ç”Ÿæˆæ—¶ï¼Œä»…å¯¹ **Candidate Region** å†…çš„é€šé“é‡æ–°è®¡ç®—é‡è¦æ€§å¹¶è¿›è¡ŒåŠ¨æ€é€‰æ‹©ï¼Œé¿å…äº†å…¨é€šé“é‡è¯„ä¼°çš„é«˜å¼€é”€ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **åŠ¨æ€é€‚åº”æ€§å¼º**ï¼šæ”¯æŒåœ¨è§£ç è¿‡ç¨‹ä¸­æ ¹æ®ç”Ÿæˆä¸Šä¸‹æ–‡è°ƒæ•´å‰ªæå†³ç­–ï¼Œæ˜¾è‘—æå‡ç”Ÿæˆä»»åŠ¡æ€§èƒ½ã€‚
- **è®¡ç®—å¼€é”€ä½**ï¼šä»…å¯¹ä¸€å°éƒ¨åˆ†å€™é€‰é€šé“è¿›è¡Œåœ¨çº¿é‡è¯„ä¼°ï¼ŒFLOPs å¼€é”€ä»…å¢åŠ çº¦ 2.85%ï¼Œè¿œä½äºå…¨é€šé“é‡è¯„ä¼°ã€‚
- **æ— éœ€é¢„å¤„ç†**ï¼šæ— éœ€ç¦»çº¿æ ¡å‡†ï¼ˆoffline calibrationï¼‰ã€å†è®­ç»ƒï¼ˆretrainingï¼‰æˆ–å­¦ä¹ é¢„æµ‹å™¨ï¼ˆpredictor learningï¼‰ï¼ŒçœŸæ­£å®ç°â€œå³æ’å³ç”¨â€ï¼ˆplug-and-playï¼‰ã€‚
- **é€šç”¨æ€§å¼º**ï¼šå¯æ— ç¼åº”ç”¨äºå¤šç§å¤§æ¨¡å‹æ¶æ„ï¼ŒåŒ…æ‹¬ **LLMs**, **MoE models**, å’Œ **VLMs**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- **è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œ MoE æ¨¡å‹**ï¼šä½¿ç”¨ `LM-Evaluation-Harness` æ¡†æ¶ï¼Œæ¶µç›–ä»¥ä¸‹ä»»åŠ¡ï¼š
  - **QA ä»»åŠ¡**ï¼šBoolQ, RTE, HellaSwag, WinoGrande, ARC-Easy, ARC-Challenge, OpenBookQA
  - **ç”Ÿæˆä»»åŠ¡**ï¼šCoQA, MBPP, NQ-Open, HumanEval, GSM8K
  - **è¯­è¨€å»ºæ¨¡**ï¼šWikitextï¼ˆç”¨äº perplexity è¯„ä¼°ï¼‰
- **è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰**ï¼šä½¿ç”¨ `LMMs-Eval` æ¡†æ¶ï¼Œæ¶µç›–ï¼š
  - **VQA ä»»åŠ¡**ï¼šPOPE, OK-VQA, GQA, ScienceQA, MME

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹èŒƒå›´**ï¼šè¦†ç›–å¤šç§ **Large Foundation Models (LFMs)**ï¼ŒåŒ…æ‹¬ï¼š
  - **Dense LLMs**ï¼šLlama-2 (7B/13B/70B), Llama-3.1 (8B/70B), Qwen-3 (8B/32B)
  - **MoE Models**ï¼šQwen1.5-MoE-A2.7B, Qwen2-57B-A14B, Qwen3-30B-A3B
  - **VLMs**ï¼šQwen2-VL, Qwen2.5-VL
- **å‰ªæç‡**ï¼šä¸»è¦æµ‹è¯• 20% å’Œ 40% çš„å‚æ•°å‰ªæç‡ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **QA ä»»åŠ¡**ï¼šAccuracy
  - **ç”Ÿæˆä»»åŠ¡**ï¼šF1 Score (CoQA), Pass@1 (MBPP, HumanEval), Exact Match (NQ-Open, GSM8K)
  - **VQA ä»»åŠ¡**ï¼šF1 Score, Exact Match, Perception Score (MME)
  - **æ•ˆç‡æŒ‡æ ‡**ï¼šMLP Throughput, End-to-End Latency, FLOPs Overhead

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Wanda-sp**ï¼šåŸºäºæ¿€æ´»çš„ç»“æ„åŒ–å‰ªæï¼Œéœ€ç¦»çº¿æ ¡å‡†ã€‚
- **FLAP**ï¼šåŸºäºæ³¢åŠ¨æ€§çš„è‡ªé€‚åº”å‰ªæï¼Œéœ€ç¦»çº¿æ ¡å‡†ã€‚
- **Tyr**ï¼šåŸºäºè¿›åŒ–æœç´¢çš„å…¨å±€å‰ªæä¼˜åŒ–ï¼Œéœ€å¤§é‡ç¦»çº¿è®¡ç®—ã€‚
- **Probe Pruning**ï¼šæ”¯æŒåœ¨çº¿å‰ªæï¼Œä½†éœ€ probing-based é‡è¦æ€§ä¼°è®¡ï¼Œå¼•å…¥é¢å¤–å‰å‘ä¼ æ’­ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- åœ¨ **Llama3.1-8B** ä¸Šï¼ŒPOP åœ¨ 20% å‰ªæç‡ä¸‹ï¼š
  - **çŸ­é—®ç­”ä»»åŠ¡** å¹³å‡å‡†ç¡®ç‡æå‡ **5.27** ä¸ªç™¾åˆ†ç‚¹ã€‚
  - **ç”Ÿæˆä»»åŠ¡** å¹³å‡å‡†ç¡®ç‡æå‡ **17.71** ä¸ªç™¾åˆ†ç‚¹ã€‚
- åœ¨ **Llama2-7B** ä¸Šï¼ŒPOP å®ç°ï¼š
  - **1.29Ã— çš„ MLP å±‚åŠ é€Ÿ**ã€‚
  - **1.14Ã— çš„ç«¯åˆ°ç«¯æ¨ç†é€Ÿåº¦æå‡**ã€‚
  - ä»…å¼•å…¥ **2.85% çš„ FLOPs å¼€é”€**ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| æ¨¡å‹ | ä»»åŠ¡ | å‰ªæç‡ | POP vs. Wanda-sp | POP vs. FLAP | POP vs. Tyr |
|------|------|--------|------------------|--------------|-------------|
| Llama2-7B | QA (å¹³å‡) | 20% | +18.92% | +12.78% | -1.38% |
| Llama2-7B | ç”Ÿæˆ (å¹³å‡) | 20% | +35.52% | +29.58% | +12.51% |
| Qwen2-VL | VQA (å¹³å‡) | 20% | +52.08% | +13.20% | +1.28% |

> **å…³é”®å‘ç°**ï¼šPOP åœ¨ç”Ÿæˆä»»åŠ¡ä¸Šä¼˜åŠ¿å°¤ä¸ºæ˜æ˜¾ï¼Œè€Œé™æ€æ–¹æ³•ï¼ˆå¦‚ Wanda-sp, FLAPï¼‰åœ¨é«˜å‰ªæç‡ä¸‹æ€§èƒ½å´©æºƒã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ä¸åŒå‰ªæç­–ç•¥å¯¹æ¯”ï¼ˆTable 6ï¼‰
| æ–¹æ³• | ç”Ÿæˆä»»åŠ¡å¹³å‡å‡†ç¡®ç‡ (Llama2-7B) | FLOPs å¼€é”€ (%) |
|------|-------------------------------|----------------|
| Variant (1)ï¼ˆå›ºå®šæ©ç ï¼‰ | 23.40 | 0.0 |
| **POP (Ours)** | **24.12** | **2.85** |
| Variant (2)ï¼ˆå…¨é€šé“é‡è¯„ä¼°ï¼‰ | 26.56 | 33.1 |

> **ç»“è®º**ï¼šPOP åœ¨ç²¾åº¦å’Œæ•ˆç‡ä¹‹é—´å–å¾—äº†æœ€ä½³å¹³è¡¡ï¼Œä»¥æå°çš„å¼€é”€è·å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

#### åˆ†åŒºæ¯”ä¾‹ï¼ˆPartition Fraction Î³ï¼‰å½±å“ï¼ˆFigure 4ï¼‰
- Î³ è¶Šå¤§ï¼ˆå€™é€‰åŒºè¶Šå¤§ï¼‰ï¼Œæ€§èƒ½è¶Šé«˜ï¼Œä½†è®¡ç®—å¼€é”€ä¹Ÿè¶Šå¤§ã€‚
- é»˜è®¤è®¾ç½® **Î³ = 0.1** å¯åœ¨æ€§èƒ½å’Œæ•ˆç‡é—´å–å¾—è‰¯å¥½æŠ˜è¡·ã€‚

#### ç¦»çº¿å‡†å¤‡æˆæœ¬ï¼ˆTable 7ï¼‰
| æ–¹æ³• | Llama2-7B å‡†å¤‡æ—¶é—´ (å°æ—¶) | Llama3.1-70B å‡†å¤‡æ—¶é—´ (å°æ—¶) |
|------|--------------------------|----------------------------|
| Wanda-sp | 0.08 | 0.43 |
| FLAP | 0.07 | 0.38 |
| Tyr | 9.72 | 171.93 |
| **POP** | **0.0** | **0.0** |

> **ç»“è®º**ï¼šPOP å®Œå…¨æ— éœ€ç¦»çº¿å‡†å¤‡ï¼Œéƒ¨ç½²æˆæœ¬æœ€ä½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **é™æ€å‰ªæä¸é€‚ç”¨äºç”Ÿæˆä»»åŠ¡**ï¼šåœ¨è‡ªå›å½’ç”Ÿæˆä¸­ï¼Œå›ºå®šçš„å‰ªææ©ç æ— æ³•é€‚åº”åŠ¨æ€ä¸Šä¸‹æ–‡ï¼Œå¯¼è‡´æ€§èƒ½ä¸¥é‡ä¸‹é™ã€‚
2. **åœ¨çº¿å‰ªææ˜¯å¿…è¦çš„**ï¼šé€šè¿‡åœ¨è§£ç é˜¶æ®µåŠ¨æ€è°ƒæ•´å‰ªæå†³ç­–ï¼Œå¯ä»¥æ›´å¥½åœ°æ•æ‰ä¸Šä¸‹æ–‡ç¨€ç–æ€§ï¼Œæ˜¾è‘—æå‡ç”Ÿæˆè´¨é‡ã€‚
3. **ä¸‰åŒºåˆ’åˆ†æ˜¯é«˜æ•ˆçš„å…³é”®**ï¼šå°†é€šé“åˆ’åˆ†ä¸º Retained / Candidate / Pruned åŒºåŸŸï¼Œä½¿å¾—åœ¨çº¿å‰ªææ—¢çµæ´»åˆé«˜æ•ˆã€‚
4. **POP å…·æœ‰å¹¿æ³›é€‚ç”¨æ€§**ï¼šåœ¨ **LLMs**, **MoE**, **VLMs** ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶ä½œä¸ºé€šç”¨æ¨ç†åŠ é€Ÿæ–¹æ¡ˆçš„æ½œåŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä¸»è¦é’ˆå¯¹ **FFN å±‚** è¿›è¡Œå‰ªæï¼Œæœªæ¶‰åŠ Attention å±‚çš„åœ¨çº¿å‰ªæã€‚
- å€™é€‰åŒºå¤§å° Î³ æ˜¯è¶…å‚æ•°ï¼Œéœ€æ‰‹åŠ¨è®¾å®šï¼Œç¼ºä¹è‡ªé€‚åº”æœºåˆ¶ã€‚
- å¯¹äºæç«¯é«˜å‰ªæç‡ï¼ˆ>50%ï¼‰ï¼Œæ€§èƒ½ä»ä¼šä¸‹é™ï¼Œå°šæœªå®Œå…¨è§£å†³ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ Attention å±‚çš„åœ¨çº¿å‰ªææœºåˆ¶ã€‚
- è®¾è®¡è‡ªé€‚åº”çš„å€™é€‰åŒºå¤§å°æ§åˆ¶ç­–ç•¥ã€‚
- å°† POP ä¸é‡åŒ–ï¼ˆquantizationï¼‰ç­‰å…¶ä»–å‹ç¼©æŠ€æœ¯ç»“åˆï¼Œå®ç°æ›´æè‡´çš„æ¨¡å‹å‹ç¼©ã€‚
- ç ”ç©¶åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­æ›´ç»†ç²’åº¦çš„è·¨æ¨¡æ€ç¨€ç–æ€§å»ºæ¨¡ã€‚

</details>

---

### 6. [Quantifying Energy-Efficient Edge Intelligence: Inference-time Scaling Laws for Heterogeneous Computing](https://arxiv.org/abs/2602.06057)

**Authors**: Satyam Kumar, Saurabh Jha  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.06057v1  

#### Abstract
Large language model inference on resource constrained edge devices remains a major challenge for low latency intelligent systems, as existing solutions depend heavily on cloud or datacenter infrastructure. This work introduces QEIL, Quantifying Edge Intelligence via Inference time Scaling Laws, a u...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Quantifying Energy-Efficient Edge Intelligence: Inference-time Scaling Laws for Heterogeneous Computing*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹**èµ„æºå—é™è¾¹ç¼˜è®¾å¤‡ä¸Šçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†æ•ˆç‡**è¿™ä¸€å…³é”®æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºå½“å‰ä¸»æµä¾èµ–æ•°æ®ä¸­å¿ƒçš„é›†ä¸­å¼éƒ¨ç½²æ¨¡å¼åœ¨**å»¶è¿Ÿã€èƒ½è€—å’Œæˆæœ¬**æ–¹é¢å­˜åœ¨ä¸¥é‡ç“¶é¢ˆã€‚å°½ç®¡å·²æœ‰ç ”ç©¶æ¢ç´¢äº†æ¨ç†æ—¶è®¡ç®—æ‰©å±•ï¼ˆinference-time compute scalingï¼‰ã€èƒ½æ•ˆåº¦é‡ï¼ˆå¦‚ IPWï¼‰å’Œå¼‚æ„ç³»ç»Ÿè°ƒåº¦ï¼Œä½†ç¼ºä¹ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶å°†**æ¨ç†æ—¶æ‰©å±•å®šå¾‹**ï¼ˆinference-time scaling lawsï¼‰ä¸**å¼‚æ„ç¡¬ä»¶ååŒè°ƒåº¦**ï¼ˆheterogeneous orchestrationï¼‰ç›¸ç»“åˆã€‚

å…·ä½“è€Œè¨€ï¼Œç°æœ‰å·¥ä½œå­˜åœ¨ä»¥ä¸‹ä¸è¶³ï¼š
- **Brown et al. (2024)** æå‡ºäº†åŸºäºé‡å¤é‡‡æ ·çš„æ¨ç†æ‰©å±•å®šå¾‹ï¼Œä½†ä»…é™äºå•è®¾å¤‡åŒæ„æ‰§è¡Œã€‚
- **Saad-Falcon et al. (2025)** æå‡º Intelligence Per Wattï¼ˆIPWï¼‰ä½œä¸ºæœ¬åœ°æ¨ç†çš„èƒ½æ•ˆæŒ‡æ ‡ï¼Œä½†å…¶è·¯ç”±ç²’åº¦ä¸ºæ•´ä¸ªæŸ¥è¯¢çº§åˆ«ï¼Œæœªæ·±å…¥åˆ°å­ä»»åŠ¡å±‚é¢ã€‚
- **Asgar et al. (2025)** æå‡ºäº†åŸºäºä»»åŠ¡å›¾çš„å¼‚æ„è°ƒåº¦æ¡†æ¶ï¼Œä½†èšç„¦äºæ™ºèƒ½ä½“ï¼ˆagenticï¼‰å·¥ä½œæµï¼Œè€Œéçº¯æ¨ç†ä»»åŠ¡çš„åŸºæœ¬æ‰©å±•è§„å¾‹ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **QEIL**ï¼ˆQuantifying Edge Intelligence via Inference-time Scaling Lawsï¼‰ï¼Œä¸€ä¸ªç»Ÿä¸€çš„æ•°å­¦ä¸ç³»ç»Ÿæ¡†æ¶ï¼Œç”¨äºåœ¨ CPUã€GPU å’Œ NPU ç­‰å¼‚æ„è¾¹ç¼˜è®¾å¤‡ä¸Šé«˜æ•ˆæ‰§è¡Œ LLM æ¨ç†ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

1. **äº”ä¸ªæ¶æ„æ— å…³çš„å®šç†ï¼ˆArchitecture-agnostic Theoremsï¼‰**  
   é¦–æ¬¡å½¢å¼åŒ–å¹¶éªŒè¯äº†æ¨ç†æ•ˆç‡å¦‚ä½•éšæ¨¡å‹å¤§å° $N$ã€æ ·æœ¬é¢„ç®— $S$ã€æ¯æ ·æœ¬ Token æ•° $T$ å’Œè®¾å¤‡å‚æ•°è¿›è¡Œç¼©æ”¾ï¼š
   - **Theorem 1**: è¦†ç›–ç‡ $C(S)$ éµå¾ªæŒ‡æ•°å¹‚å¾‹ $C(S) = 1 - \exp(-\alpha N^\beta S^\beta T^\delta)$ï¼Œå…¶ä¸­ $\beta \sim 0.7$ æ˜¯è·¨æ¶æ„æ’å®šçš„æŒ‡æ•°ã€‚
   - **Theorem 2**: èƒ½è€— $E(S)$ ä»¥äºšçº¿æ€§æ–¹å¼éšæ ·æœ¬æ•°å¢é•¿ï¼ˆ$\gamma_E \sim 0.9$ï¼‰ï¼Œå¾—ç›Šäºæ›´å¤§æ¨¡å‹æ›´å¥½çš„ç¼“å­˜å±€éƒ¨æ€§ã€‚
   - **Theorem 3**: å»¶è¿Ÿåˆ†è§£ä¸ºé¢„å¡«å……ï¼ˆprefillï¼‰ã€è§£ç ï¼ˆdecodeï¼‰ã€I/O å’Œè°ƒåº¦å¼€é”€ï¼Œæ”¯æŒå¹¶è¡Œä¼˜åŒ–ã€‚
   - **Theorem 4**: æˆæœ¬ç”±ç¡¬ä»¶æ‘Šé”€ã€èƒ½è€—å’Œç»´æŠ¤ç»„æˆï¼Œå¼‚æ„è°ƒåº¦å¯æ˜¾è‘—é™ä½å•ä½æŸ¥è¯¢æˆæœ¬ã€‚
   - **Theorem 5**: åŸºäº Roofline æ¨¡å‹çš„ä»»åŠ¡-è®¾å¤‡åŒ¹é…åŸåˆ™ï¼šé«˜ç®—æœ¯å¼ºåº¦ä»»åŠ¡ï¼ˆå¦‚ prefillï¼‰åº”åˆ†é…ç»™é«˜é¢‘è®¾å¤‡ï¼ˆGPU/CPUï¼‰ï¼Œå†…å­˜å¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚ decodeï¼‰åº”åˆ†é…ç»™é«˜å¸¦å®½è®¾å¤‡ï¼ˆNPU/GPUï¼‰ã€‚

2. **æ–°å‹å¤åˆæ•ˆç‡åº¦é‡æ ‡å‡†**
   - **Intelligence Per Watt (IPW)**ï¼šè¦†ç›–ç‡ / å¹³å‡åŠŸç‡ï¼Œè¡¡é‡ç¬æ—¶åŠŸè€—æ•ˆç‡ã€‚
   - **Energy-Coverage Efficiency (ECE)**ï¼šè¦†ç›–ç‡ / æ€»èƒ½é‡ï¼ˆjouleï¼‰ï¼Œè¡¡é‡æ€»èƒ½é‡åˆ©ç”¨æ•ˆç‡ã€‚
   - **Price-Power-Performance (PPP) Score**ï¼šååé‡ Ã— è¦†ç›–ç‡ / (å¹³å‡åŠŸç‡ Ã— å•ä½æŸ¥è¯¢æ‘Šé”€æˆæœ¬)ï¼Œå®ç°å¤šç›®æ ‡æƒè¡¡çš„ç»Ÿä¸€é‡åŒ–ã€‚

3. **åŠ¨æ€å¼‚æ„è°ƒåº¦æ¡†æ¶**
   - åŸºäº MLIR çš„ç¼–è¯‘åŸºç¡€è®¾æ–½ï¼Œå®ç°æ“ä½œçº§åˆ†è§£ã€‚
   - è´ªå¿ƒå±‚åˆ†é…ç®—æ³•ï¼ˆgreedy layer assignmentï¼‰ï¼Œæ ¹æ®å„å±‚çš„ç®—æœ¯å¼ºåº¦å’Œè®¾å¤‡èƒ½åŠ›è¿›è¡Œæœ€ä¼˜æ˜ å°„ã€‚
   - æ”¯æŒè¿è¡Œæ—¶è‡ªé€‚åº”é‡‡æ ·ï¼ˆadaptive sample budgetingï¼‰ï¼Œåœ¨èƒ½é‡çº¦æŸä¸‹æœ€å¤§åŒ–è¦†ç›–ç‡ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

- **è¶…è¶ŠåŒæ„äº‘æ¨ç†**ï¼šåœ¨ä¸ç‰ºç‰²å‡†ç¡®æ€§çš„å‰æä¸‹ï¼ŒåŒæ—¶æå‡è¦†ç›–ç‡ã€é™ä½èƒ½è€—ä¸å»¶è¿Ÿã€‚
- **æ­ç¤ºè¶…çº¿æ€§æ”¶ç›Š**ï¼šå¼‚æ„è°ƒåº¦å¸¦æ¥çš„æ•ˆç‡å¢ç›Šæ˜¯åŒæ„æ–¹æ³•æ— æ³•è§‚æµ‹åˆ°çš„â€œéšè—çº¢åˆ©â€ã€‚
- **æ™®é€‚æ€§å¼º**ï¼šç†è®ºä¸å®éªŒéªŒè¯è¦†ç›–ä» 125M åˆ° 2.6B å‚æ•°çš„å¤šç§æ¨¡å‹æ¶æ„ï¼ˆGPT-2, Granite, Qwen, Llama, LFMï¼‰ï¼Œè¯æ˜å…¶**æ¶æ„æ— å…³æ€§**ã€‚
- **å®ç”¨ä»·å€¼é«˜**ï¼šæ¡†æ¶æ”¯æŒçœŸå®è¾¹ç¼˜çƒ­é¢„ç®—ï¼ˆ75â€“84Wï¼‰ï¼Œé€‚ç”¨äºæ— é£æ‰‡è®¾å¤‡å’Œç”µæ± ä¾›ç”µåœºæ™¯ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- ä¸»è¦åŸºå‡†æµ‹è¯•ä½¿ç”¨ **WikiText-103** æ•°æ®é›†ã€‚
- åœ¨éƒ¨åˆ†åˆ†æä¸­å¼•ç”¨äº† **WILDCHAT** å’Œ **NATURALREASONING** æ•°æ®é›†ç”¨äºè¦†ç›–ç‡éªŒè¯ã€‚

### **å®éªŒè®¾ç½®**

- **ç¡¬ä»¶å¹³å°**ï¼š
  - **CPU**: Intel Core Ultra 9 285HX (8 cores, 2.80 GHz)
  - **NPU**: Intel AI Boost NPU (20 GB æ˜¾å­˜)
  - **GPU 1**: NVIDIA RTX PRO 5000 Blackwell GPU (96.2 GB VRAM)
  - **GPU 2**: Intel Graphics GPU (72.7 GB å…±äº«å†…å­˜)
- **æ¨¡å‹å®¶æ—**ï¼ˆå…±äº”ç±»ï¼‰ï¼š
  - GPT-2 (125M)
  - Granite-350M
  - Qwen2-0.5B
  - Llama-3.2-1B
  - LFM2-2.6B
- **æ‰§è¡ŒèŒƒå¼å¯¹æ¯”**ï¼š
  - **Standard**ï¼šååé‡ä¼˜åŒ–çš„åŒæ„æ¨ç†ï¼ˆé€šå¸¸å…¨æ”¾ GPUï¼‰
  - **Energy-Aware**ï¼šQEIL æ¡†æ¶ä¸‹çš„å¼‚æ„è°ƒåº¦ç­–ç•¥

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Pass@k** | å¤šæ ·æœ¬ç”Ÿæˆä¸­è‡³å°‘æœ‰ä¸€ä¸ªæ­£ç¡®çš„æ¦‚ç‡ï¼ˆå³ coverageï¼‰ |
| **IPW** | $ \text{Pass@k} / P_{\text{avg}} $ï¼Œå•ä½ï¼štasks/watt |
| **ECE** | $ \text{Pass@k} / (E_{\text{total}} / 1000) $ï¼Œå•ä½ï¼šcoverage/joule |
| **PPP Score** | $ (\text{Throughput} \times \text{Pass@k}) / (P_{\text{avg}} \times \text{Cost}_{\text{amortized}}) $ |
| **Total Energy** | 20 æ¬¡é‡‡æ ·çš„æ€»èƒ½è€—ï¼ˆjoulesï¼‰ |
| **Latency** | ç«¯åˆ°ç«¯æ¨ç†æ—¶é—´ï¼ˆmsï¼‰ |
| **Average Power** | åŠ æƒå¹³å‡åŠŸè€—ï¼ˆWï¼‰ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **Homogeneous Cloud Baseline**ï¼šæ‰€æœ‰æ¨ç†ä»»åŠ¡é›†ä¸­åœ¨é«˜æ€§èƒ½ GPU ä¸Šæ‰§è¡Œã€‚
- **Query-level Routing**ï¼ˆå¦‚ Saad-Falcon et al.ï¼‰ï¼šæ•´æ¡æŸ¥è¯¢è·¯ç”±è‡³æœ¬åœ°æˆ–äº‘ç«¯ï¼Œä¸è¿›è¡Œå­ä»»åŠ¡æ‹†åˆ†ã€‚
- **Single-device Repeated Sampling**ï¼ˆå¦‚ Brown et al.ï¼‰ï¼šä»…é€šè¿‡å¢åŠ é‡‡æ ·æ•°æå‡ coverageï¼Œå¿½ç•¥ç¡¬ä»¶å·®å¼‚ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆè§ Table 1ï¼‰**

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **Pass@k Coverage** | **66.5% â€“ 70.0%**ï¼ˆEnergy-Awareï¼‰ vs. **56% â€“ 63%**ï¼ˆBaselineï¼‰ï¼Œ**æå‡ 7â€“10.5 ä¸ªç™¾åˆ†ç‚¹** |
| **Energy Reduction** | **35.6% â€“ 78.2%** å‡å°‘ï¼ˆå‡å€¼ **48.8%**ï¼‰ |
| **Latency Improvement** | å¹³å‡ **15.8%** é™ä½ï¼ˆæœ€é«˜è¾¾ 22.5%ï¼‰ |
| **IPW Improvement** | **2.08Ã— â€“ 5.60Ã—** æå‡ï¼ˆå‡å€¼ **+236%**ï¼‰ |
| **PPP Score** | å¹³å‡ **+39.0%** æå‡ï¼ˆæœ€é«˜ +52.3%ï¼‰ |
| **Average Power** | ä¸‹é™è‡³ **75â€“84W**ï¼ˆå‡å€¼é™ä½ **68.0%**ï¼‰ï¼Œç¬¦åˆè¾¹ç¼˜çƒ­é¢„ç®— |

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- åœ¨æ‰€æœ‰æ¨¡å‹ä¸Šï¼ŒQEIL å‡å®ç°äº†**è¦†ç›–ç‡ã€èƒ½æ•ˆã€å»¶è¿Ÿã€æˆæœ¬**çš„å…¨é¢è¶…è¶Šã€‚
- å°¤å…¶å¯¹äºå°æ¨¡å‹ï¼ˆå¦‚ GPT-2, Qwen2ï¼‰ï¼Œç”±äºå…¶åˆå§‹è¦†ç›–ç‡è¾ƒä½ï¼Œå¼‚æ„è°ƒåº¦å¸¦æ¥çš„ç»å¯¹æå‡æœ€å¤§ï¼ˆ+10.5ppï¼‰ï¼Œä½“ç°äº†â€œå¼±æ¨¡å‹å¯é€šè¿‡æ™ºèƒ½è°ƒåº¦è¿½å¹³å¼ºæ¨¡å‹â€çš„æ½œåŠ›ã€‚
- LFM2-2.6B è™½ç„¶ IPW å˜åŒ–ä¸å¤§ï¼ˆ-1.8%ï¼‰ï¼Œä½†ä»å®ç° **35.9% èƒ½è€—ä¸‹é™** å’Œ **+8.0pp è¦†ç›–ç‡æå‡**ï¼Œè¯´æ˜èƒ½æ•ˆæ”¹è¿›ä¸ç¬æ—¶åŠŸç‡æŒ‡æ ‡å¯è§£è€¦ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆéšå«åˆ†æï¼‰**

è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†æ–‡ä¸­é€šè¿‡å¤šä¸ªç»´åº¦éªŒè¯äº†å„ç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼š
- **å¼‚æ„è°ƒåº¦ vs åŒæ„è°ƒåº¦**ï¼šè‹¥å…¨éƒ¨ä»»åŠ¡æ”¾åœ¨ GPU ä¸Šï¼ŒåŠŸè€—é«˜è¾¾ 402.5Wï¼ˆGPT-2ï¼‰ï¼Œè€Œ QEIL é™è‡³ 83.5Wã€‚
- **ä»»åŠ¡åˆ†è§£æœ‰æ•ˆæ€§**ï¼šå°† prefill åˆ†é…ç»™ GPUã€decode ç»™ NPUï¼Œå……åˆ†åˆ©ç”¨äº†å„è‡ªçš„é«˜ç®—åŠ›ä¸é«˜å¸¦å®½ä¼˜åŠ¿ã€‚
- **åŠ¨æ€é‡‡æ ·æœºåˆ¶**ï¼šå…è®¸åœ¨èƒ½é‡é¢„ç®—å†…åŠ¨æ€è°ƒæ•´é‡‡æ ·æ•°é‡ï¼Œç¡®ä¿åœ¨æœ‰é™èµ„æºä¸‹æœ€å¤§åŒ– coverageã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **æ¨ç†æ—¶æ‰©å±•å®šå¾‹å…·æœ‰æ¶æ„æ— å…³æ€§**ï¼š  
   è¦†ç›–ç‡ã€èƒ½è€—ã€å»¶è¿Ÿç­‰å‡éµå¾ªå¯é¢„æµ‹çš„å¹‚å¾‹å…³ç³»ï¼Œä¸”æ ¸å¿ƒæŒ‡æ•°ï¼ˆå¦‚ $\beta \sim 0.7$ï¼‰åœ¨ä¸åŒæ¨¡å‹é—´ä¿æŒç¨³å®šã€‚

2. âœ… **å¼‚æ„è°ƒåº¦å¸¦æ¥è¶…çº¿æ€§æ•ˆç‡å¢ç›Š**ï¼š  
   é€šè¿‡å°†ä¸åŒé˜¶æ®µçš„ä»»åŠ¡åˆ†é…ç»™æœ€é€‚åˆçš„ç¡¬ä»¶ï¼ˆprefillâ†’GPU, decodeâ†’NPU, embeddingâ†’CPU/NPUï¼‰ï¼Œå¯åœ¨ä¸å¢åŠ è®¡ç®—æ€»é‡çš„æƒ…å†µä¸‹æ˜¾è‘—æå‡æ•´ä½“æ•ˆç‡ã€‚

3. âœ… **è¾¹ç¼˜æœ¬åœ°æ‰§è¡Œä¼˜äºäº‘ç«¯é›†ä¸­æ¨ç†**ï¼š  
   åœ¨å»¶è¿Ÿã€èƒ½è€—ã€æˆæœ¬å’Œéšç§æ–¹é¢ï¼Œæ™ºèƒ½çš„æœ¬åœ°å¼‚æ„æ‰§è¡Œæ˜¯æ›´ä¼˜ç­–ç•¥ï¼Œå°¤å…¶é€‚åˆèµ„æºå—é™ç¯å¢ƒã€‚

4. âœ… **èƒ½æ•ˆä¸æ€§èƒ½å¯å…¼å¾—**ï¼š  
   QEIL å®ç°äº†â€œä¸‰èµ¢â€â€”â€”æ›´é«˜ coverageã€æ›´ä½ energyã€æ›´çŸ­ latencyï¼Œæ‰“ç ´äº†ä¼ ç»Ÿä¼˜åŒ–ä¸­çš„æƒè¡¡å›°å¢ƒã€‚

5. âœ… **IPW ä¸è¶³ä»¥åæ˜ å®Œæ•´èƒ½æ•ˆå›¾æ™¯**ï¼š  
   å¼•å…¥ ECE å’Œ PPP ç­‰å¤åˆæŒ‡æ ‡ï¼Œæ‰èƒ½å…¨é¢åˆ»ç”»è¾¹ç¼˜éƒ¨ç½²ä¸­çš„å¤šç»´ trade-offã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- å½“å‰è¯„ä¼°é›†ä¸­åœ¨ Intel/NVIDIA ç”Ÿæ€ï¼Œå°šæœªæ¶µç›–æ›´å¤šç§»åŠ¨ NPUï¼ˆå¦‚ Qualcomm, MediaTekï¼‰ã€‚
- æœªè€ƒè™‘è·¨å¤šä¸ªè¾¹ç¼˜èŠ‚ç‚¹çš„åˆ†å¸ƒå¼æ¨ç†ä¸é€šä¿¡å¼€é”€ã€‚
- åŠ¨æ€è°ƒåº¦ç­–ç•¥å¯¹è¿è¡Œæ—¶çŠ¶æ€ï¼ˆå¦‚ thermal throttlingï¼‰çš„å“åº”èƒ½åŠ›æœ‰å¾…å¢å¼ºã€‚
- æ¡†æ¶ç›®å‰å‡è®¾æ¨¡å‹å·²è®­ç»ƒå®Œæˆï¼Œæœªæ•´åˆæ¨¡å‹å‹ç¼©æŠ€æœ¯ï¼ˆå¦‚ quantization, pruningï¼‰ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- æ‰©å±•è‡³æ›´å¤šå¼‚æ„å¹³å°ï¼šåŒ…æ‹¬ **Snapdragon NPU**, **Jetson Orin**, **TPU**, **GraphCore IPU**, **Groq LPU** ç­‰ã€‚
- æ”¯æŒ**è¿è¡Œæ—¶åŠ¨æ€é‡è°ƒåº¦**ï¼šæ ¹æ®è®¾å¤‡æ¸©åº¦ã€åŠŸè€—å¼‚å¸¸ã€å†…å­˜å‹åŠ›å®æ—¶è°ƒæ•´ä»»åŠ¡åˆ†å¸ƒã€‚
- æ¢ç´¢**å¤šè¾¹ç¼˜èŠ‚ç‚¹ååŒæ¨ç†**ï¼Œé‡åŒ–è·¨è®¾å¤‡é€šä¿¡å¼€é”€ã€‚
- é›†æˆ**æ¨¡å‹å‹ç¼©æŠ€æœ¯**ï¼ˆquantization, distillationï¼‰ä¸è°ƒåº¦è”åˆä¼˜åŒ–ã€‚
- æ”¯æŒæ–°å…´æ¶æ„ï¼šå¦‚ **State-Space Models (SSMs)** å’Œ **Mixture-of-Experts (MoE)** æ¨¡å‹ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> QEIL é€šè¿‡å»ºç«‹**æ¶æ„æ— å…³çš„æ¨ç†æ—¶æ‰©å±•å®šå¾‹**ï¼Œå¹¶ç»“åˆ**åŸºäºç®—æœ¯å¼ºåº¦æ„ŸçŸ¥çš„å¼‚æ„è°ƒåº¦**ï¼Œé¦–æ¬¡å®ç°äº†åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå¯¹ LLM æ¨ç†çš„**ç³»ç»Ÿæ€§ã€å¯é‡åŒ–ã€æ™®é€‚æ€§ä¼˜åŒ–**ï¼Œä¸ºèƒ½æºå—é™ AI ç³»ç»Ÿæä¾›äº†ä»ç†è®ºåˆ°å®è·µçš„å®Œæ•´è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 7. [DAWN: Dependency-Aware Fast Inference for Diffusion LLMs](https://arxiv.org/abs/2602.06953)

**Authors**: Lizhuo Luo, Zhuoran Shi, Jiajun Luo, Zhi Wang, Shen Ren, Wenya Wang, Tianwei Zhang  
**Category**: cs.CL  
**Published**: 2026-02-09  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.06953v1  

#### Abstract
Diffusion large language models (dLLMs) have shown advantages in text generation, particularly due to their inherent ability for parallel decoding. However, constrained by the quality--speed trade-off, existing inference solutions adopt conservative parallel strategies, leaving substantial efficienc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# DAWN: Dependency-Aware Fast Inference for Diffusion LLMs è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
ç°æœ‰çš„ **diffusion LLMs (dLLMs)** è™½ç„¶å…·å¤‡å¹¶è¡Œè§£ç æ½œåŠ›ï¼Œä½†åœ¨å®é™…æ¨ç†ä¸­é¢ä¸´ä¸¥é‡çš„ **quality-speed trade-off**ã€‚ä¼ ç»Ÿå¹¶è¡Œè§£ç ç­–ç•¥ä¾èµ–äºâ€œå„ä½ç½®ç‹¬ç«‹é¢„æµ‹â€çš„å‡è®¾ï¼Œè€Œç°å®ä¸­ token ä¹‹é—´å­˜åœ¨å¼ºè¯­ä¹‰è€¦åˆï¼ˆtoken dependenciesï¼‰ï¼Œå¯¼è‡´åŒæ—¶è§£ç å¤šä¸ªä½ç½®æ—¶äº§ç”Ÿä¸ä¸€è‡´è¾“å‡ºï¼ˆå¦‚ç”Ÿæˆâ€œhigh houseâ€è¿™ç±»æ— æ•ˆç»„åˆï¼‰ã€‚

æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•ï¼ˆå¦‚åŸºäº confidence æˆ– entropy çš„ç­›é€‰ï¼‰é‡‡ç”¨ä¿å®ˆçš„å¯å‘å¼è§„åˆ™é€‰æ‹©è§£ç ä½ç½®ï¼Œé™åˆ¶äº†å¯å¹¶è¡ŒåŒ–çš„ç¨‹åº¦ï¼Œæœªèƒ½å……åˆ†é‡Šæ”¾ dLLMs çš„æ•ˆç‡æ½œåŠ›ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **DAWN**ï¼Œä¸€ç§æ— éœ€è®­ç»ƒã€**dependency-aware** çš„å¿«é€Ÿæ¨ç†æ–¹æ³•ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åˆ©ç”¨ **attention maps** ä½œä¸ºè½»é‡çº§ä»£ç†ä¿¡å·ï¼Œä¼°è®¡ token ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼›
- æ„å»ºä¸€ä¸ª **Dependency Graph** æ¥æ˜¾å¼å»ºæ¨¡ä½ç½®é—´çš„ä¾èµ–ï¼›
- åŸºäºæ­¤å›¾è®¾è®¡ä¸¤ä¸ªååŒæœºåˆ¶ï¼š
  1. **Anchor-Guided Decoding (AGD)**ï¼šå°†é«˜ç½®ä¿¡åº¦å·²è§£ç  token è§†ä¸ºâ€œé”šç‚¹â€ï¼ˆanchorsï¼‰ï¼Œæ”¾æ¾å¯¹ä¸å…¶å¼ºç›¸å…³çš„ masked ä½ç½®çš„ confidence é˜ˆå€¼ï¼›
  2. **Conflict-Based Scheduling (CBS)**ï¼šè¯†åˆ«ä¾èµ–å›¾ä¸­çš„å†²çªè¾¹ï¼ˆconflictï¼‰ï¼Œé¿å…å¼ºè€¦åˆçš„ä½ç½®ä¿¡åº¦ä½ç½®è¢«åŒæ—¶è§£ç ã€‚

é€šè¿‡ä¸Šè¿°æœºåˆ¶ï¼ŒDAWN åœ¨ä¿è¯ç”Ÿæˆè´¨é‡çš„å‰æä¸‹æ˜¾è‘—æå‡äº†è§£ç å¹¶è¡Œåº¦ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ— éœ€è®­ç»ƒ**ï¼šå®Œå…¨åœ¨æ¨ç†é˜¶æ®µå®ç°ï¼Œé€‚ç”¨äºä»»ä½•é¢„è®­ç»ƒå¥½çš„ dLLMï¼›
- **æ›´é«˜æ•ˆçš„å®‰å…¨å¹¶è¡Œ**ï¼šçªç ´äº†ä¼ ç»Ÿé˜ˆå€¼æ³•çš„ä¿å®ˆé™åˆ¶ï¼Œåˆ©ç”¨ä¾èµ–ç»“æ„æŒ–æ˜æ›´å¤šå¯å®‰å…¨å¹¶è¡Œçš„ä½ç½®ï¼›
- **é²æ£’æ€§å¼º**ï¼šé€šè¿‡è¿‡æ»¤ **attention sinks**ï¼ˆæ— æ„ä¹‰ä½†å¸å¼•å¤§é‡æ³¨æ„åŠ›çš„ä½ç½®ï¼‰æé«˜ä¾èµ–ä¼°è®¡å‡†ç¡®æ€§ï¼›
- **é€šç”¨æ€§å¥½**ï¼šåœ¨å¤šç§æ¨¡å‹å’Œä»»åŠ¡ä¸Šå‡è¡¨ç°ä¼˜å¼‚ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
å®éªŒè¦†ç›–å¤šä¸ªå…¸å‹åŸºå‡†ï¼Œæ¶µç›–æ•°å­¦æ¨ç†ä¸ä»£ç ç”Ÿæˆä»»åŠ¡ï¼š
- **GSM8K** (5-shot)ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜
- **MATH** (4-shot)ï¼šé«˜ä¸­éš¾åº¦æ•°å­¦é—®é¢˜
- **HumanEval** (0-shot)ï¼šPython å‡½æ•°è¡¥å…¨
- **MBPP** (3-shot)ï¼šç®€å•ç¼–ç¨‹ä»»åŠ¡

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼š
  - `LLaDA-8B-Instruct`
  - `LLaDA-1.5`
  - `Dream-v0-Base-7B`
  - `Dream-v0-Instruct-7B`
- **ç¡¬ä»¶**ï¼šNVIDIA H100 80GB GPU
- **ç”Ÿæˆé•¿åº¦**ï¼šç»Ÿä¸€è®¾ä¸º 256 tokensï¼ˆKLASS é™¤å¤–ï¼‰
- **å—å¤§å°ï¼ˆblock lengthï¼‰**ï¼šé»˜è®¤ 32
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Accuracy (Acc.)**ï¼šä»»åŠ¡å‡†ç¡®ç‡
  - **Tokens Per Second (TPS)**ï¼šååé‡
  - **Speedup**ï¼šç›¸å¯¹äºåŸå§‹é‡‡æ ·æ–¹æ³•çš„é€Ÿåº¦æå‡å€æ•°
  - **Number of Function Evaluations (NFE)**ï¼šå‰å‘ä¼ æ’­æ¬¡æ•°ï¼Œåæ˜ æ¨ç†æ­¥æ•°

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Original (Top-1 Sampling)**ï¼šæ¯æ­¥ä»…è§£ç ç½®ä¿¡åº¦æœ€é«˜çš„ä¸€ä¸ª token
- **Confidence-Aware Parallel**ï¼ˆFast-dLLMï¼‰ï¼šè®¾å®š confidence é˜ˆå€¼ï¼Œé«˜äºåˆ™å¹¶è¡Œè§£ç 
- **KLASS**ï¼šç»“åˆ KL æ•£åº¦è¡¡é‡åˆ†å¸ƒç¨³å®šæ€§æ¥é€‰æ‹©ä½ç½®
- **LocalLeap**ï¼šåŸºäºå±€éƒ¨ç¡®å®šæ€§å‡è®¾è¿›è¡ŒåŒºåŸŸåŒ–å¹¶è¡Œè§£ç 

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ¨¡å‹ | æ•°æ®é›† | DAWN é€Ÿåº¦æå‡ (Speedup) | å‡†ç¡®ç‡å˜åŒ– |
|------|--------|--------------------------|------------|
| LLaDA-8B-Instruct | MBPP | **4.77Ã—** | ä» 29.60 â†’ **30.80** â†‘ |
| LLaDA-1.5 | MBPP | **8.06Ã—** | ä» 38.80 â†’ 37.60 â†“ï¼ˆè½»å¾®ä¸‹é™ï¼‰ |
| Dream-v0-Instruct-7B | MBPP | **5.26Ã—** | ä¿æŒç¨³å®š |

æ€»ä½“æ¥çœ‹ï¼ŒDAWN åœ¨æ‰€æœ‰æ¨¡å‹å’Œæ•°æ®é›†ä¸Šå®ç°äº† **1.80â€“8.06Ã— çš„æ¨ç†åŠ é€Ÿ**ï¼Œä¸”å¤šæ•°æƒ…å†µä¸‹å‡†ç¡®ç‡æŒå¹³ç”šè‡³ç•¥æœ‰æå‡ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- ç›¸è¾ƒäº **Confidence-Aware** å’Œ **KLASS**ï¼š
  - æ˜¾è‘—æ›´é«˜çš„ TPSï¼ˆä¾‹å¦‚åœ¨ LLaDA-8B ä¸Š TPS è¾¾åˆ° 44.72 vs. 33.44 / 23.23ï¼‰
  - æ›´ä¼˜çš„è´¨é‡-é€Ÿåº¦æƒè¡¡
- ç›¸è¾ƒäº **LocalLeap**ï¼š
  - åœ¨å¤§å¤šæ•°åœºæ™¯ä¸‹è¿›ä¸€æ­¥æå‡äº† **0.05â€“5.17 TPS**
  - å‡†ç¡®ç‡æœ€é«˜æå‡è¾¾ **3.04%**

> âœ… è¡¨æ˜ DAWN ä¸ä»…æ›´å¿«ï¼Œè€Œä¸”åœ¨éƒ¨åˆ†ä»»åŠ¡ä¸Šæ›´å‡†ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ç§»é™¤å…³é”®ç»„ä»¶çš„å½±å“ï¼ˆä»¥ LLaDA-8B-Instruct + GSM8K ä¸ºä¾‹ï¼‰ï¼š
| æ–¹æ³• | Accuracy | TPS | NFE |
|------|---------|-----|-----|
| **DAWN (å®Œæ•´)** | 77.94 | **44.72** | 55.76 |
| -AGD | 76.80 | 22.31 â†“ (-50%) | 112.9 â†‘ |
| -CBS | 78.47 â†‘ | 33.83 â†“ | 74.69 â†‘ |
| Original | 77.94 | 10.32 | 256 |

- **ç§»é™¤ AGD** å¯¼è‡´æ•ˆç‡å¤§å¹…ä¸‹é™ï¼Œè¯´æ˜ **anchor å¼•å¯¼æœºåˆ¶æ˜¯æé€Ÿä¸»å› **ï¼›
- **ç§»é™¤ CBS** æå‡äº†å‡†ç¡®ç‡ä½†é™ä½äº†æ•ˆç‡ï¼Œè¯´æ˜ **CBS æˆåŠŸè§£é”äº†é¢å¤–å¹¶è¡Œç©ºé—´ï¼Œä»£ä»·æå°**ã€‚

#### å…¶ä»–æ•æ„Ÿæ€§åˆ†æ
- **ç”Ÿæˆé•¿åº¦å˜åŒ–**ï¼ˆ128â€“1024ï¼‰ï¼šDAWN å§‹ç»ˆä¼˜äºåŸå§‹æ–¹æ³•ï¼Œç»´æŒè‰¯å¥½ trade-offï¼›
- **lower threshold $T_{low}$ å˜åŒ–**ï¼šé™ä½ $T_{low}$ å¯æå‡ TPSï¼Œä½†ä¼šç‰ºç‰²å‡†ç¡®ç‡ï¼›é»˜è®¤è®¾ç½® $T_{low}=0.8$ å¹³è¡¡æœ€ä½³ï¼›
- **block length å˜åŒ–**ï¼šéšç€ block size å¢å¤§ï¼ŒTPS æå‡ï¼Œå‡†ç¡®ç‡å…ˆå‡åé™ï¼ŒDAWN åœ¨å®½èŒƒå›´å†…ç¨³å¥ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **Token Dependencies å¯ä» Attention Maps ä¸­æœ‰æ•ˆä¼°è®¡**ï¼š
   - æ³¨æ„åŠ›å›¾å¯ä½œä¸ºè½»é‡çº§ proxy ç”¨äºå»ºæ¨¡ä½ç½®ä¾èµ–ï¼›
   - å¿…é¡»è¿‡æ»¤ **attention sinks**ï¼ˆå¦‚æ ‡ç‚¹ç¬¦å·ç­‰æ— æ„ä¹‰ sinkï¼‰ä»¥é¿å…è¯¯å¯¼ã€‚

2. **é«˜ç½®ä¿¡åº¦ token å¯ä½œä¸ºå¯é  anchor**ï¼š
   - ä¸€æ—¦æŸä¸ª token è¢«é«˜ç½®ä¿¡åº¦è§£ç ï¼Œå…¶å¼ºä¾èµ–çš„åç»­ä½ç½®å³ä½¿å½“å‰ confidence è¾ƒä½ï¼Œä¹Ÿå¾€å¾€èƒ½æ­£ç¡®é¢„æµ‹ï¼›
   - è¿™ä¸º **relax confidence threshold** æä¾›ç†è®ºä¾æ®ã€‚

3. **å¼ºè€¦åˆçš„ä½ç½®ä¿¡åº¦ä½ç½®åº”é¿å…åŒæ—¶è§£ç **ï¼š
   - åŒæ—¶ unmask å¼ºä¾èµ–çš„ä¸ç¡®å®šä½ç½®æ˜“å¼•å‘é”™è¯¯ç´¯ç§¯ï¼›
   - ä½¿ç”¨ conflict graph è¿›è¡Œè°ƒåº¦å¯æœ‰æ•ˆç¼“è§£è¯¥é—®é¢˜ã€‚

4. **DAWN å®ç°äº†é«˜è´¨é‡ä¸‹çš„æè‡´åŠ é€Ÿ**ï¼š
   - æœ€é«˜ **8.06Ã— åŠ é€Ÿ**ï¼Œè¿œè¶…ç°æœ‰æ–¹æ³•ï¼›
   - å¤šæ•°ä»»åŠ¡ä¸Šå‡†ç¡®ç‡ä¸é™åå‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- ä¾èµ– attention map çš„è´¨é‡ï¼Œåœ¨æŸäº› attention æ¨¡å¼å¼‚å¸¸çš„æ¨¡å‹ä¸­å¯èƒ½å¤±æ•ˆï¼›
- å½“å‰ä¾èµ–å›¾æ„å»ºæ–¹å¼è¾ƒä¸ºç®€å•ï¼ˆåŸºäºé˜ˆå€¼å‰ªæï¼‰ï¼Œæœªè€ƒè™‘åŠ¨æ€æ¼”åŒ–æˆ–æ›´é«˜é˜¶ä¾èµ–ï¼›
- å¯¹è¶…å‚æ•°ï¼ˆå¦‚ $T_{edge}, T_{sink}$ï¼‰æœ‰ä¸€å®šæ•æ„Ÿæ€§ï¼Œéœ€é’ˆå¯¹ä¸åŒæ¨¡å‹è°ƒå‚ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´ç²¾ç»†çš„ä¾èµ–å»ºæ¨¡æ–¹å¼ï¼ˆå¦‚ GNNã€åŠ¨æ€å›¾å­¦ä¹ ï¼‰ï¼›
- å°† dependency-aware æ€è·¯æ‰©å±•è‡³ **multimodal dLLMs**ï¼›
- ç»“åˆ **speculative decoding** æˆ– **early exit** ç­–ç•¥è¿›ä¸€æ­¥ä¼˜åŒ–æ¨ç†æµç¨‹ï¼›
- ç ”ç©¶å¦‚ä½•è‡ªé€‚åº”åœ°è°ƒæ•´ $T_{low}$ å’Œ block size ä»¥å®ç°å…¨è‡ªåŠ¨ä¼˜åŒ–ã€‚

---

> ğŸ”— **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/lizhuo-luo/DAWN](https://github.com/lizhuo-luo/DAWN)

</details>

---

### 8. [Canzona: A Unified, Asynchronous, and Load-Balanced Framework for Distributed Matrix-based Optimizers](https://arxiv.org/abs/2602.06079)

**Authors**: Liangyu Wang, Siqi Zhang, Junjie Wang, Yiming Dong, Bo Zheng, Zihan Qiu, Shengkun Tang, Di Wang, Rui Men, Dayiheng Liu  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.06079v1  

#### Abstract
The scaling of Large Language Models (LLMs) drives interest in matrix-based optimizers (e.g., Shampoo, Muon, SOAP) for their convergence efficiency; yet their requirement for holistic updates conflicts with the tensor fragmentation in distributed frameworks like Megatron. Existing solutions are subo...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCanzona: A Unified, Asynchronous, and Load-Balanced Framework for Distributed Matrix-based Optimizers

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ç°ä»£å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è®­ç»ƒä¸­ï¼Œ**Matrix-based Optimizers**ï¼ˆå¦‚ Shampooã€Muonã€SOAPï¼‰å› å…¶ä¼˜å¼‚çš„æ”¶æ•›æ•ˆç‡å—åˆ°å…³æ³¨ã€‚ç„¶è€Œï¼Œè¿™ç±»ä¼˜åŒ–å™¨åœ¨æ•°å­¦ä¸Šè¦æ±‚å¯¹å®Œæ•´å¼ é‡è¿›è¡Œæ“ä½œï¼ˆå³æ»¡è¶³ **Atomicity Constraint**ï¼‰ï¼Œè€Œä¸»æµåˆ†å¸ƒå¼æ¡†æ¶ï¼ˆå¦‚ Megatronï¼‰é‡‡ç”¨çš„ **ZeRO-1** å’Œ **Tensor Parallelism (TP)** ç­–ç•¥ä¼šå°†å‚æ•°å¼ é‡åˆ‡åˆ†åˆ°ä¸åŒè®¾å¤‡ä¸Šï¼Œå¯¼è‡´æ— æ³•ç›´æ¥åº”ç”¨è¿™äº›ä¼˜åŒ–å™¨ã€‚

ç°æœ‰è§£å†³æ–¹æ¡ˆå­˜åœ¨ä¸¥é‡ç¼ºé™·ï¼š
- **Synchronous Compute (SC)**ï¼šå¤åˆ¶æ‰€æœ‰ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œé€ æˆè®¡ç®—å†—ä½™ï¼Œæ‰©å±•æ€§å·®ã€‚
- **Layer-wise Partitioning**ï¼ˆå¦‚ NVIDIA çš„ `layerwise_optimizer`ï¼‰ï¼šè™½é¿å…åˆ‡åˆ†å•ä¸ªå¼ é‡ï¼Œä½†ç ´åäº† ZeRO-1 çš„ **Geometric Constraints**ï¼Œè¿«ä½¿ç³»ç»Ÿæ”¾å¼ƒé«˜æ•ˆçš„ **bucket-based Reduce-Scatter**ï¼Œè½¬è€Œä½¿ç”¨é€šä¿¡å¼€é”€æ›´å¤§çš„ **All-Reduce**ï¼ˆé€šä¿¡é‡ç¿»å€ï¼‰ï¼Œå¹¶å¼•å…¥é¢å¤–çš„ **All-Gather/Broadcast** æ“ä½œã€‚

å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¸ç‰ºç‰²ç®—æ³•æ­£ç¡®æ€§å’Œç³»ç»Ÿæ•ˆç‡çš„å‰æä¸‹ï¼Œæ”¯æŒåˆ†å¸ƒå¼çŸ©é˜µä¼˜åŒ–å™¨ï¼Œæˆä¸ºä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **Canzona**ï¼Œä¸€ä¸ªç»Ÿä¸€ã€å¼‚æ­¥ä¸”è´Ÿè½½å‡è¡¡çš„åˆ†å¸ƒå¼çŸ©é˜µä¼˜åŒ–å™¨æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **è§£è€¦é€»è¾‘ä¸Šçš„ä¼˜åŒ–å™¨ä»»åŠ¡åˆ†é…ä¸ç‰©ç†ä¸Šçš„å‚æ•°åˆ†å¸ƒ**ã€‚

å…·ä½“åˆ›æ–°ç‚¹å¦‚ä¸‹ï¼š

#### âœ… **1. ç»Ÿä¸€ä¸”è§£è€¦çš„ç³»ç»Ÿæ¶æ„ (Unified and Decoupled Architecture)**

- **å¯¹äº Data Parallelism (DP)**ï¼šæå‡º **Static Partitioning** ç­–ç•¥ï¼Œåœ¨å°Šé‡ ZeRO-1 çš„å‡ ä½•å¸ƒå±€å‰æä¸‹ï¼ŒæŒ‰å®Œæ•´å¼ é‡è¾¹ç•Œé™æ€åˆ’åˆ†ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œç¡®ä¿æ¯ä¸ªå¼ é‡çš„æ›´æ–°ç”±å•ä¸€ Rank å®Œæˆï¼Œå®ç° **é›¶é€šä¿¡æœ¬åœ°æ›´æ–°**ã€‚
- **å¯¹äº Tensor Parallelism (TP)**ï¼šè®¾è®¡ **Asynchronous Compute Pipeline**ï¼Œé€šè¿‡ **Micro-Group Scheduling** å°†å¤šä¸ªç¢ç‰‡åŒ–æ¢¯åº¦èšåˆä¸ºå¾®ç»„ï¼Œåˆ©ç”¨èåˆçš„ **All-to-All** éšè—é‡å»ºå¼€é”€ï¼Œå¹¶å¼‚æ­¥æ‰§è¡Œè®¡ç®—ã€‚

è¯¥æ¶æ„å®ç°äº†ï¼š
- **ç»Ÿä¸€æŠ½è±¡**ï¼šå¯¹ä»»æ„ Matrix-based Optimizer é€šç”¨ï¼ˆOptimizer-agnosticï¼‰ã€‚
- **å¼‚æ­¥æ‰§è¡Œ**ï¼šæ”¯æŒè®¡ç®—-è®¡ç®—é‡å ï¼Œæ˜¾è‘—é™ä½ä¼˜åŒ–å™¨æ­¥é•¿ï¼ˆoptimizer stepï¼‰çš„æ€»è€—æ—¶ï¼ˆmakespanï¼‰ã€‚
- **ä¿ç•™é«˜æ•ˆé€šä¿¡**ï¼šå®Œå…¨ç»§æ‰¿æ ‡å‡† Forward-Backward ä¸­çš„é€šä¿¡é‡å èƒ½åŠ›ã€‚

#### âœ… **2. å¼‚æ„æ„ŸçŸ¥çš„è´Ÿè½½å‡è¡¡ç®—æ³• (Heterogeneity-Aware Load Balancing)**

ç”±äºçŸ©é˜µè¿ç®—å¤æ‚åº¦éçº¿æ€§ï¼ˆå¦‚ç«‹æ–¹çº§ï¼‰ï¼Œç®€å•æŒ‰å‚æ•°æ•°é‡å‡åˆ†ä¼šå¯¼è‡´ä¸¥é‡çš„è´Ÿè½½å¤±è¡¡ï¼ˆstraggler problemï¼‰ã€‚ä¸ºæ­¤æå‡ºä¸¤ç§ä¸“ç”¨ç¦»çº¿è°ƒåº¦ç®—æ³•ï¼š

- **DP å±‚é¢**ï¼šæå‡º **Î±-Balanced Greedy LPT ç®—æ³•**ï¼Œåœ¨å…¨å±€è´Ÿè½½å‡è¡¡ï¼ˆæœ€å°åŒ–æœ€å¤§è´Ÿè½½ï¼‰ä¸é€šä¿¡æ¡¶å‡è¡¡ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚
- **TP å±‚é¢**ï¼šæå‡º **Micro-Group Balanced Scheduling with Greedy Rollback**ï¼Œé€šè¿‡æ¨¡æ‹Ÿè°ƒåº¦å†³ç­–ï¼ŒåŠ¨æ€æ‰“åŒ…ä»»åŠ¡ç»„ï¼Œæœ‰æ•ˆæ¶ˆé™¤æµæ°´çº¿æ°”æ³¡ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | Canzona | Layer-wise Optimizer | Synchronous Compute |
|------|--------|------------------------|---------------------|
| **é€šä¿¡æ•ˆç‡** | âœ… ä¿ç•™ Reduce-Scatter | âŒ è¢«è¿«ä½¿ç”¨ All-Reduceï¼ˆ2Ã—é€šä¿¡é‡ï¼‰ | âœ… æ— é€šä¿¡ä½†å†—ä½™è®¡ç®— |
| **è®¡ç®—æ•ˆç‡** | âœ… å¼‚æ­¥ã€æ— å†—ä½™ | âœ… æ— å†—ä½™ä½†æœ‰é€šä¿¡ç“¶é¢ˆ | âŒ å…¨å±€åŒæ­¥ã€é‡å¤è®¡ç®— |
| **è´Ÿè½½å‡è¡¡** | âœ… æ˜¾å¼ä¼˜åŒ– | âš ï¸ å¿½è§†å¼ é‡æˆæœ¬å·®å¼‚ | âš ï¸ è‡ªç„¶å‡è¡¡ä½†ä½æ•ˆ |
| **é€šç”¨æ€§** | âœ… Optimizer-agnostic | âœ… æ”¯æŒå¤šç§ä¼˜åŒ–å™¨ | âœ… æ”¯æŒå¤šç§ä¼˜åŒ–å™¨ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ¨¡å‹ä¸ä¼˜åŒ–å™¨**

- **æ¨¡å‹å®¶æ—**ï¼šQwen3 ç³»åˆ—ï¼Œè§„æ¨¡ä» **1.7B åˆ° 32B å‚æ•°**ã€‚
- **ä¼˜åŒ–å™¨**ï¼šä¸»è¦ä½¿ç”¨ **Muon**ï¼Œå¹¶éªŒè¯äº† **Shampoo** å’Œ **SOAP** çš„æ³›åŒ–æ€§ã€‚

> æ³¨ï¼šæœªä½¿ç”¨ä¼ ç»Ÿæ•°æ®é›†ï¼ˆå¦‚ ImageNetï¼‰ï¼Œè€Œæ˜¯åŸºäºçœŸå® LLM è®­ç»ƒåœºæ™¯è¿›è¡Œç«¯åˆ°ç«¯è¯„ä¼°ã€‚

---

### **å®éªŒè®¾ç½®**

- **ç¡¬ä»¶å¹³å°**ï¼šæœ€å¤š **256â€“512 GPUs** çš„é›†ç¾¤ã€‚
- **å¹¶è¡Œé…ç½®**ï¼šå…¸å‹è®¾ç½®ä¸º **DP=32, TP=8**ï¼Œè¦†ç›–å¤šç§ç»„åˆï¼ˆå¦‚ DP16-TP8, DP32-TP4ï¼‰ã€‚
- **åºåˆ—é•¿åº¦**ï¼š4096ï¼Œæ¯ DP Rank æ‰¹å¤§å°ä¸º 1ã€‚

---

### **è¯„ä¼°æŒ‡æ ‡**

1. **ç«¯åˆ°ç«¯è¿­ä»£æ—¶é—´ (End-to-End Iteration Time)**  
   åŒ…æ‹¬ Forwardã€Backward å’Œ Optimizer Step çš„æ€»è€—æ—¶ã€‚

2. **å„é˜¶æ®µè€—æ—¶åˆ†è§£**
   - Fwd-Bwd Time
   - Optimizer Step Latencyï¼ˆå…³é”®æŒ‡æ ‡ï¼‰
   - AdamW æ—¶é—´ä½œä¸ºå‚è€ƒåŸºå‡†

3. **è´Ÿè½½å‡è¡¡æ¯” (Load-Balance Ratio, RLB)**  
   $$
   RLB = \frac{\max_r(C_r)}{\text{avg}_r(C_r)}
   $$
   å…¶ä¸­ $ C_r $ å¯ä¸ºå†…å­˜å³°å€¼æˆ–è®¡ç®— FLOPsï¼Œç†æƒ³å€¼ä¸º 1.0ã€‚

4. **åŠ é€Ÿæ¯” (Speedup)**  
   ç›¸å¯¹äºåŸºçº¿çš„ç«¯åˆ°ç«¯æˆ–ä¼˜åŒ–å™¨æ­¥é•¿åŠ é€Ÿã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿ | æè¿° |
|------|------|
| **SC (Synchronous Compute)** | å³ DDP æ¨¡å¼ï¼Œå…¨é‡å¤åˆ¶ä¼˜åŒ–å™¨çŠ¶æ€ï¼ŒåŒæ­¥æ›´æ–°ï¼Œè®¡ç®—å†—ä½™é«˜ |
| **NV-layerwise** | NVIDIA çš„ `layerwise_optimizer`ï¼ŒæŒ‰å±‚åˆ†é…ï¼Œç ´å ZeRO å‡ ä½•çº¦æŸ |
| **ASC (Asynchronous Compute)** | æœ¬æ–‡æ¡†æ¶ä½†æ— è´Ÿè½½å‡è¡¡ï¼ˆæ¶ˆèç‰ˆæœ¬ï¼‰ |
| **LB-ASC (Load-Balanced ASC)** | æœ¬æ–‡å®Œæ•´æ–¹æ³•ï¼ˆCanzona çš„æ ¸å¿ƒç­–ç•¥ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **ç«¯åˆ°ç«¯è¿­ä»£æ—¶é—´åŠ é€Ÿæ¯”** | **1.57Ã—** å¿«äº `layerwise_optimizer` |
| **ä¼˜åŒ–å™¨æ­¥é•¿å»¶è¿Ÿé™ä½** | **5.8Ã—** åŠ é€Ÿï¼ˆä» 0.383s â†’ 0.066sï¼‰ |
| **Fwd-Bwd é˜¶æ®µåŠ é€Ÿ** | **1.23Ã—**ï¼ˆä» 0.998s â†’ 0.811sï¼‰ |
| **æœ€å¤§è´Ÿè½½ä¸å¹³è¡¡æ¯”ï¼ˆFLOPsï¼‰** | ä» >3.2Ã— é™è‡³ ~1.4Ã—ï¼ˆDPï¼‰å’Œ ~2.4Ã— â†’ ~1.5Ã—ï¼ˆTPï¼‰ |

> å®éªŒåŸºäº Qwen3-32B åœ¨ 256 GPUs ä¸Šè¿è¡Œã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### ğŸ”¹ å¯¹æ¯” `layerwise_optimizer`

- **æ€»è¿­ä»£æ—¶é—´**ï¼š**0.877s vs. 1.381s**ï¼Œå¿« **1.57Ã—**ã€‚
- **åŸå› åˆ†æ**ï¼š
  1. **ä¼˜åŒ–å™¨æ­¥é•¿å¤§å¹…ç¼©çŸ­**ï¼šå› æ— éœ€ All-Gather/Broadcast é‡æ–°åˆ†å‘æƒé‡ã€‚
  2. **Fwd-Bwd æ›´é«˜æ•ˆ**ï¼šä½¿ç”¨ Reduce-Scatter è€Œé All-Reduceï¼Œé€šä¿¡é‡å‡åŠä¸”å¯æ›´å¥½é‡å ã€‚

> å›¾ 7 è¿›ä¸€æ­¥éªŒè¯ï¼š`layerwise_optimizer` çš„ Fwd-Bwd æ—¶é—´ä¸ AdamW + All-Reduce åŸºå‡†å¯¹é½ï¼Œè€Œ Canzona ä¸ AdamW + Reduce-Scatter å¯¹é½ï¼Œè¯æ˜å…¶é€šä¿¡æœºåˆ¶æ›´ä¼˜ã€‚

#### ğŸ”¹ å¯¹æ¯” Synchronous Compute (SC)

- **ä¼˜åŒ–å™¨æ­¥é•¿**ï¼šä» 0.383s é™è‡³ 0.066sï¼Œ**5.8Ã— åŠ é€Ÿ**ã€‚
- **æ— è®¡ç®—å†—ä½™**ï¼šé¿å…äº†æ‰€æœ‰ Rank æ‰§è¡Œç›¸åŒçŸ©é˜µè¿ç®—ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### âœ… **è´Ÿè½½å‡è¡¡æœ‰æ•ˆæ€§ï¼ˆå›¾ 3ï¼‰**

- **æ— è´Ÿè½½å‡è¡¡ï¼ˆNaive Static Partitioningï¼‰**ï¼š
  - FLOPs ä¸å¹³è¡¡æ¯”è¾¾ **3.24Ã—**
  - å†…å­˜ä¸å¹³è¡¡æ¯”è¾¾ **2.46Ã—**
- **å¯ç”¨ Î±-Balanced LPT å**ï¼š
  - FLOPs ä¸å¹³è¡¡æ¯”é™è‡³ **1.43Ã—**
  - å†…å­˜ä¸å¹³è¡¡æ¯”é™è‡³ **1.11Ã—**
  - æœ€å¤§æ­¥é•¿æ—¶é—´å‡å°‘è¿‘ 30%

#### âœ… **æ§åˆ¶å‚æ•° Î± çš„å½±å“ï¼ˆå›¾ 13ï¼‰**

- å½“ Î± â†’ 1ï¼ˆä¼˜å…ˆè´Ÿè½½å‡è¡¡ï¼‰æ—¶ï¼Œ**Muon time å•è°ƒä¸‹é™**ã€‚
- å½“ Î± â†’ 0ï¼ˆä¼˜å…ˆé€šä¿¡å‡åŒ€ï¼‰æ—¶ï¼ŒFwd-Bwd æ—¶é—´ç•¥æœ‰ä¼˜åŠ¿ï¼Œä½†æ€»ä½“æ€§èƒ½æ›´å·®ã€‚
- **ç»“è®º**ï¼šè®¾ç½® **Î± = 1.0** å¯è·å¾—æœ€ä½³ç«¯åˆ°ç«¯æ€§èƒ½ï¼Œè¯´æ˜è®¡ç®— straggler æ˜¯ä¸»è¦ç“¶é¢ˆã€‚

#### âœ… **Micro-Group Fusion æ•ˆæœï¼ˆå›¾ 14ï¼‰**

- **No-Fuse**ï¼ˆé€å¼ é‡é€šä¿¡ï¼‰ï¼šå»¶è¿Ÿ ~0.11s
- **å¯ç”¨èåˆå**ï¼ˆCmax â‰¥ 512MBï¼‰ï¼šå»¶è¿Ÿé™è‡³ ~0.072s
- **ç»“è®º**ï¼šèåˆé€šä¿¡èƒ½é¥±å’Œ All-to-All å¸¦å®½ï¼Œæ˜¾è‘—æå‡æ•ˆç‡ã€‚

#### âœ… **æ³›åŒ–æ€§éªŒè¯ï¼ˆå›¾ 10â€“12ï¼‰**

- **Shampoo / SOAP** åœºæ™¯ä¸‹ï¼š
  - ä¼˜åŒ–å™¨æ­¥é•¿ä» **>3.3s** é™è‡³ **~0.11s**ï¼Œ**>30Ã— åŠ é€Ÿ**
  - è®­ç»ƒæŸå¤±æ›²çº¿ä¸ SC å®Œå…¨ä¸€è‡´ï¼Œ**æ— ç²¾åº¦æŸå¤±**
  - è´Ÿè½½ä¸å¹³è¡¡æ¯”ä» >2.0 é™è‡³ ~1.05

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **Canzona æˆåŠŸå¼¥åˆäº† Matrix-based Optimizers ä¸ç°ä»£åˆ†å¸ƒå¼è®­ç»ƒä¹‹é—´çš„ç³»ç»Ÿ-ç®—æ³•é¸¿æ²Ÿ**ã€‚
2. âœ… **Static Partitioning + Asynchronous Micro-Group Pipeline** åœ¨ä¿è¯åŸå­æ€§çš„åŒæ—¶ï¼Œå®ç°äº†é€šä¿¡ä¸è®¡ç®—çš„åŒé‡é«˜æ•ˆã€‚
3. âœ… **è´Ÿè½½å‡è¡¡æ˜¯é‡Šæ”¾çŸ©é˜µä¼˜åŒ–å™¨æ½œåŠ›çš„å…³é”®**ï¼Œå¦åˆ™éçº¿æ€§è®¡ç®—æˆæœ¬å°†å¯¼è‡´ä¸¥é‡ stragglerã€‚
4. âœ… **numel(p)** ä½œä¸ºç»Ÿä¸€æˆæœ¬åº¦é‡è¶³ä»¥å®ç°é«˜æ€§èƒ½è´Ÿè½½å‡è¡¡ï¼Œæ— éœ€ä¸ºæ¯ä¸ªä¼˜åŒ–å™¨å®šåˆ¶å¤æ‚ FLOPs æ¨¡å‹ï¼ˆè¯¯å·® < 10â»â´sï¼‰ã€‚
5. âœ… æ–¹æ³•å…·æœ‰å¼ºæ³›åŒ–æ€§ï¼Œé€‚ç”¨äº Muonã€Shampooã€SOAP ç­‰å¤šç§çŸ©é˜µä¼˜åŒ–å™¨ï¼Œä¸”æ”¶æ•›è¡Œä¸ºä¸åŒæ­¥åŸºçº¿å®Œå…¨ä¸€è‡´ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ–ç¦»çº¿è§„åˆ’**ï¼šè´Ÿè½½å‡è¡¡ç®—æ³•ä¸º **offline heuristic**ï¼Œéœ€åœ¨åˆå§‹åŒ–æ—¶å®Œæˆï¼Œä¸æ”¯æŒåŠ¨æ€æ‹“æ‰‘å˜åŒ–ã€‚
2. **å‡è®¾ TP åœ¨èŠ‚ç‚¹å†…**ï¼šTP çš„ All-to-All é€šä¿¡ä¾èµ–é«˜å¸¦å®½ NVLinkï¼Œè‹¥è·¨èŠ‚ç‚¹åˆ™å¯èƒ½æˆä¸ºç“¶é¢ˆã€‚
3. **æœªå¤„ç† ZeRO-2/3**ï¼šå½“å‰è®¾è®¡åŸºäº ZeRO-1ï¼ˆä»…ä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡ï¼‰ï¼Œæ‰©å±•è‡³ ZeRO-2/3ï¼ˆæ¢¯åº¦ä¹Ÿåˆ†ç‰‡ï¼‰éœ€é¢å¤–é€‚é…ã€‚
4. **å·¥ç¨‹å¤æ‚åº¦è¾ƒé«˜**ï¼šéœ€æ·±åº¦é›†æˆè‡³ Megatron ç­‰æ¡†æ¶ï¼Œå¯¹æ™®é€šç”¨æˆ·ä¸å¤Ÿå‹å¥½ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ”¯æŒåŠ¨æ€è´Ÿè½½è°ƒæ•´**ï¼šç»“åˆè¿è¡Œæ—¶ profiling å®ç° adaptive schedulingã€‚
2. **æ‰©å±•è‡³ FSDP**ï¼šå°† TP-LB-ASC æ€è·¯è¿ç§»è‡³ PyTorch Fully Sharded Data Parallelã€‚
3. **æ”¯æŒæ··åˆç²¾åº¦ä¸ offloading**ï¼šé›†æˆ CPU offload æˆ– FP8 è®­ç»ƒã€‚
4. **æ¢ç´¢æ›´ç»†ç²’åº¦çš„ä»»åŠ¡æŠ½è±¡**ï¼šå¦‚ sub-tensor level scheduling for extremely large embeddingsã€‚
5. **å¼€æºä¸ç”Ÿæ€å»ºè®¾**ï¼šæ¨åŠ¨ Canzona æˆä¸ºåˆ†å¸ƒå¼çŸ©é˜µä¼˜åŒ–çš„æ ‡å‡†åŸºç¡€è®¾æ–½ã€‚

---

> **æ€»ç»“**ï¼šCanzona æä¾›äº†ä¸€ä¸ª **zero-fidelity-lossã€high-throughputã€optimizer-agnostic** çš„ç»Ÿä¸€æ¡†æ¶ï¼Œé¦–æ¬¡åœ¨ä¸ç‰ºç‰²ç®—æ³•æ­£ç¡®æ€§çš„å‰æä¸‹ï¼Œå®ç°äº† Matrix-based Optimizers åœ¨åƒå¡çº§åˆ«é›†ç¾¤ä¸Šçš„é«˜æ•ˆåˆ†å¸ƒå¼è®­ç»ƒï¼Œä¸ºä¸‹ä¸€ä»£ LLM ä¼˜åŒ–å™¨é“ºå¹³äº†é“è·¯ã€‚

</details>

---

### 9. [FlashSketch: Sketch-Kernel Co-Design for Fast Sparse Sketching on GPUs](https://arxiv.org/abs/2602.06071)

**Authors**: Rajat Vadiraj Dwaraknath, Sungyoon Kim, Mert Pilanci  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.06071v1  

#### Abstract
Sparse sketches such as the sparse Johnson-Lindenstrauss transform are a core primitive in randomized numerical linear algebra because they leverage random sparsity to reduce the arithmetic cost of sketching, while still offering strong approximation guarantees. Their random sparsity, however, is at...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šFlashSketch: Sketch-Kernel Co-Design for Fast Sparse Sketching on GPUs**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
ç°ä»£ GPU ä¸Šçš„ç¨€ç– Sketchingï¼ˆå¦‚ Sparse Johnson-Lindenstrauss Transform, SJLTï¼‰å­˜åœ¨ä¸¥é‡çš„æ€§èƒ½ç“¶é¢ˆã€‚å°½ç®¡ç¨€ç– Sketch åœ¨ç†è®ºä¸Šæœ‰è‰¯å¥½çš„è¿‘ä¼¼ä¿è¯ï¼Œä½†å…¶**éšæœºç¨€ç–æ€§å¯¼è‡´ä¸è§„åˆ™å†…å­˜è®¿é—®æ¨¡å¼**ï¼Œä»è€Œé™ä½ GPU å†…å­˜å¸¦å®½åˆ©ç”¨ç‡ï¼Œå¹¶å¼•å‘å…¨å±€åŸå­æ“ä½œï¼ˆglobal atomicsï¼‰çš„ç«äº‰ï¼Œä¸¥é‡å½±å“å®é™…è¿è¡Œæ•ˆç‡ã€‚

è¿™ä¸€çŸ›ç›¾â€”â€”**ç†è®ºä¸Šçš„éšæœºæ€§éœ€æ±‚**ä¸**ç¡¬ä»¶ä¸Šçš„ç»“æ„åŒ–æ‰§è¡Œéœ€æ±‚**â€”â€”æ˜¯å½“å‰ RandNLAï¼ˆRandomized Numerical Linear Algebraï¼‰ç®—æ³•åœ¨ GPU ä¸Šéš¾ä»¥å……åˆ†å‘æŒ¥åŠ é€Ÿæ½œåŠ›çš„å…³é”®éšœç¢ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡ºäº†ä¸€ç§ **Sketch-Kernel ååŒè®¾è®¡ï¼ˆco-designï¼‰** æ–¹æ³•ï¼Œæ ¸å¿ƒæ˜¯ï¼š

- **æå‡ºæ–°çš„ç¨€ç– Sketch å®¶æ—ï¼šBLOCKPERM-SJLT**
  - å°†è¾“å…¥å’Œè¾“å‡ºç©ºé—´åˆ’åˆ†ä¸ºå—ï¼ˆblocksï¼‰ã€‚
  - åœ¨å—çº§åˆ«ä¸Šé‡‡ç”¨ **è¾¹ä¸ç›¸äº¤çš„æ’åˆ—ï¼ˆedge-disjoint permutationsï¼‰** è¿æ¥è¾“å…¥å—ä¸è¾“å‡ºå—ï¼Œå½¢æˆä¸€ä¸ª K-æ­£åˆ™äºŒåˆ†å›¾ã€‚
  - æ¯ä¸ªéé›¶å—å†…éƒ¨ä»ä½¿ç”¨æ ‡å‡†çš„ SJLT ç»“æ„ï¼ˆæ¯åˆ— s ä¸ªéé›¶å…ƒç´ ï¼‰ï¼Œä¿æŒå±€éƒ¨æ··åˆèƒ½åŠ›ã€‚
  - å¼•å…¥å¯è°ƒå‚æ•° $ K $ï¼šæ§åˆ¶æ¯ä¸ªè¾“å‡ºå—ä»å¤šå°‘ä¸ªä¸åŒè¾“å…¥å—æ¥æ”¶ä¿¡æ¯ï¼Œæ˜¾å¼æƒè¡¡ **GPU æ•ˆç‡** ä¸ **Sketch é²æ£’æ€§**ã€‚

- **è®¾è®¡ä¸“ç”¨ CUDA Kernelï¼šFLASHSKETCH**
  - åˆ©ç”¨ BLOCKPERM-SJLT çš„å—çº§æ­£åˆ™ç»“æ„ï¼Œå°†æ¯ä¸ªè¾“å‡ºå—åˆ†é…ç»™ä¸€ä¸ªç‹¬ç«‹çš„ CUDA thread blockã€‚
  - æ‰€æœ‰ç´¯åŠ æ“ä½œåœ¨ **shared memory** ä¸­å®Œæˆï¼Œä½¿ç”¨ **shared-memory atomics** è€Œéæ˜‚è´µçš„ global atomicsã€‚
  - è¾“å‡º tile åªéœ€ä¸€æ¬¡åˆå¹¶å†™å› global memoryï¼Œå®ç°å†…å­˜è®¿é—®çš„é«˜åˆå¹¶åº¦ï¼ˆcoalescingï¼‰ã€‚
  - æ”¯æŒ **on-the-fly éšæœºæ•°ç”Ÿæˆ**ï¼Œé¿å…å­˜å‚¨ç¨€ç–ç´¢å¼•ç»“æ„ï¼Œå‡å°‘å†…å­˜å¼€é”€ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹é¢ | ä¼ ç»Ÿ SJLT å®ç°ï¼ˆå¦‚ GraSS Kernelï¼‰ | FLASHSKETCH |
|------|-------------------------------|------------|
| **å†…å­˜è®¿é—®** | ä¸è§„åˆ™ï¼Œå¤§é‡ global atomic writes | è§„åˆ™ï¼Œä»… O(kn) åˆå¹¶å†™ï¼Œæ—  global atomics |
| **åŒæ­¥å¼€é”€** | é«˜ï¼ˆä¾èµ– global atomicsï¼‰ | æä½ï¼ˆä»… block-localï¼‰ |
| **å†…å­˜å ç”¨** | éœ€é¢„å­˜ç¨€ç–ç»“æ„æˆ–çŸ©é˜µ S | æ— éœ€å­˜å‚¨ Sï¼Œå®Œå…¨ on-the-fly ç”Ÿæˆ |
| **å¯é¢„æµ‹æ€§** | éšæœºå†²çªä¸å¯æ§ | å—é—´æ— å†²çªï¼Œè¡Œä¸ºç¡®å®š |
| **æ€§èƒ½å¯è°ƒæ€§** | å›ºå®šç¨€ç–æ¨¡å¼ | å‚æ•° $ K $ æ˜¾å¼æ§åˆ¶é€Ÿåº¦-è´¨é‡æƒè¡¡ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
å®éªŒè¦†ç›–å¤šç§å…¸å‹åœºæ™¯ï¼š
- **åˆæˆæ•°æ®**ï¼š
  - `Synthetic Gaussian`: é«˜æ–¯éšæœºçŸ©é˜µ
  - `Synthetic Low-Rank + Noise`: ä½ç§©åŠ å™ªå£°çŸ©é˜µ
- **çœŸå®ä¸–ç•Œç¨€ç–çŸ©é˜µ**ï¼š
  - `SuiteSparse-spal_004`: æ¥è‡ª SuiteSparse é›†åˆçš„ç¨€ç–çŸ©é˜µï¼ˆå¯†åº¦ 1.4%ï¼‰
- **å¤§æ¨¡å‹æƒé‡**ï¼š
  - `GPT2-medium stacked weights`
  - `Qwen2-1.5B stacked weights`

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **ç¡¬ä»¶å¹³å°**ï¼š
  - ä¸»è¦ï¼šNVIDIA RTX 4090
  - è¡¥å……ï¼šRTX A6000
- **ç²¾åº¦**ï¼šç»Ÿä¸€ä½¿ç”¨ FP32
- **è¯„ä¼°æ–¹å¼**ï¼šCUDA events æµ‹é‡ wall-clock timeï¼ŒæŠ¥å‘Š 10 æ¬¡è¿­ä»£å‡å€¼

#### **è¯„ä¼°æŒ‡æ ‡**
| ä»»åŠ¡ | æŒ‡æ ‡ |
|------|------|
| **Gram Matrix Approximation** | $\frac{\|A^\top A - (SA)^\top(SA)\|_F}{\|A^\top A\|_F}$ |
| **Oblivious Subspace Embedding (OSE)** | $\|\mathbf{Q}^\top \mathbf{S}^\top \mathbf{S} \mathbf{Q} - \mathbf{I}\|_2$ï¼Œå…¶ä¸­ $\mathbf{Q} = \mathrm{qr}(A)$ |
| **Sketch-and-Ridge Regression** | æ®‹å·®è¯¯å·® $\frac{\|A x - b\|_2}{\|b\|_2}$ |
| **Sketch-and-Solve Least Squares** | åŒä¸Š |
| **End-to-End ML Pipeline (GraSS)** | **Linear Datamodeling Score (LDS)** + æŠ•å½±é˜¶æ®µè€—æ—¶ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
1. **Dense Gaussian (cuBLAS)**ï¼šå…¨è¿æ¥é«˜æ–¯æŠ•å½±ï¼Œä½¿ç”¨ cuBLAS GEMM
2. **SJLT (cuSPARSE)**ï¼šåŸºäº cuSPARSE SpMM çš„ç¨€ç–å®ç°
3. **SJLT (GraSS Kernel)**ï¼šGraSS è®ºæ–‡ä¸­çš„å¼€æº CUDA å®ç°ï¼Œä½¿ç”¨ global atomics
4. **Subsampled Fast Hadamard Transform (SRHT/FHT)**ï¼šåŸºäºå¿«é€Ÿå“ˆè¾¾ç›å˜æ¢çš„ç»“æ„åŒ–æŠ•å½±

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- **æ€»ä½“æ€§èƒ½æå‡**ï¼š
  - åœ¨å¤šä¸ªä»»åŠ¡å’Œæ•°æ®é›†ä¸Šï¼ŒFLASHSKETCH å®ç°äº† **å¹³å‡çº¦ 1.7Ã— çš„å…¨å±€ geomean åŠ é€Ÿæ¯”**ï¼ˆç›¸æ¯”æ¬¡ä¼˜åŸºçº¿ï¼‰ã€‚
  - æœ€é«˜å•ç‚¹åŠ é€Ÿå¯è¾¾ **4.43Ã—**ï¼ˆGram çŸ©é˜µè¿‘ä¼¼ä»»åŠ¡ï¼‰ã€‚

- **ä»£è¡¨æ€§ç»“æœï¼ˆTable 1 ç»¼åˆç»“æœï¼ŒRTX 4090ï¼‰**ï¼š

| ä»»åŠ¡ | vs. cuSPARSE | vs. GraSS Kernel | vs. FHT | vs. cuBLAS |
|------|-------------|----------------|--------|-----------|
| Gram Matrix Approx. | 2.67Ã— | 4.17Ã— | 16.22Ã— | 7.64Ã— |
| OSE | 2.69Ã— | 4.16Ã— | 16.20Ã— | 7.63Ã— |
| Sketch-and-Ridge | 1.42Ã— | 1.54Ã— | 3.94Ã— | 3.10Ã— |
| Sketch-and-Solve | 1.37Ã— | 1.41Ã— | 3.33Ã— | 2.34Ã— |

> âœ… **FLASHSKETCH åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­å‡ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œå°¤å…¶åœ¨ç¨€ç– Sketch åŸºçº¿ä¸Šå–å¾—æ˜¾è‘—ä¼˜åŠ¿ã€‚**

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **vs. cuSPARSE SpMM**ï¼š
  - ç”±äº cuSPARSE é€šç”¨æ€§å¼ºä½†æœªé’ˆå¯¹ SJLT ç»“æ„ä¼˜åŒ–ï¼ŒFLASHSKETCH å¹³å‡å¿« **2.6â€“4.2Ã—**ã€‚
- **vs. GraSS Kernel**ï¼š
  - GraSS ä½¿ç”¨ global atomics å¯¼è‡´ä¸¥é‡ç«äº‰ï¼Œå°¤å…¶åœ¨ $ d > k $ åœºæ™¯ä¸‹æ€§èƒ½ä¸‹é™æ˜æ˜¾ã€‚
  - FLASHSKETCH é€šè¿‡æ¶ˆé™¤ global atomicsï¼Œåœ¨å¤šæ•°é…ç½®ä¸‹å¿« **1.4â€“4.2Ã—**ã€‚
- **vs. Dense Gaussian (cuBLAS)**ï¼š
  - å°½ç®¡ cuBLAS é«˜åº¦ä¼˜åŒ–ï¼Œä½†å…¶ $ O(dkn) $ å¤æ‚åº¦åœ¨é«˜ç»´ä¸‹ä»£ä»·é«˜æ˜‚ã€‚
  - FLASHSKETCH åœ¨ä¿æŒç›¸ä¼¼ç²¾åº¦ä¸‹ï¼Œå¹³å‡å¿« **2.3â€“7.6Ã—**ã€‚
- **vs. SRHT/FHT**ï¼š
  - FHT è™½å¿«ä½†ä¸å…·å¤‡ OSE ä¿è¯ï¼Œä¸”å¯¹è¾“å…¥åˆ†å¸ƒæ•æ„Ÿã€‚
  - FLASHSKETCH åœ¨è´¨é‡å¯æ§çš„å‰æä¸‹ä»å¤§å¹…é¢†å…ˆï¼ˆ**3.3â€“16.2Ã—**ï¼‰ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**
- **å‚æ•° $ K $ çš„å½±å“**ï¼ˆæ§åˆ¶æ··åˆç¨‹åº¦ï¼‰ï¼š
  - $ K=1 $ï¼šé€€åŒ–ä¸º block-diagonal å±€éƒ¨ Sketchï¼Œé€Ÿåº¦å¿«ä½†è´¨é‡å·®ã€‚
  - $ K=2,4 $ï¼šéšç€ $ K $ å¢å¤§ï¼Œneighborhood coherence ä¸‹é™ï¼ŒSketch è´¨é‡æå‡ï¼ŒåŒæ—¶ä»ä¿æŒé«˜æ€§èƒ½ã€‚
  - å­˜åœ¨ä¸€ä¸ª **Pareto å‰æ²¿**ï¼Œå¯åœ¨é€Ÿåº¦ä¸è´¨é‡é—´çµæ´»é€‰æ‹©ã€‚
- **å‚æ•° $ s $ï¼ˆæ¯åˆ—éé›¶æ•°ï¼‰**ï¼š
  - $ s=1,2,4 $ï¼šè¾ƒå° $ s $ æ›´çœè®¡ç®—ï¼Œä½†æ–¹å·®å¢å¤§ï¼›$ s=2 $ é€šå¸¸æ˜¯æœ€ä½³æŠ˜è¡·ã€‚
- **FLASHBLOCKROW æ›¿ä»£æ–¹æ¡ˆ**ï¼š
  - ä¸€ç§æ›´æ¿€è¿›çš„ gather-only è®¾è®¡ï¼Œå®Œå…¨é¿å… atomicsã€‚
  - é€Ÿåº¦æå¿«ï¼ˆæœ‰æ—¶è¶…è¿‡ FLASHSKETCHï¼‰ï¼Œä½†å› å¯èƒ½é—æ¼æŸäº›è¾“å…¥ç»´åº¦ï¼Œ**é²æ£’æ€§å·®**ï¼Œæ— æ³•æä¾› OSE ä¿è¯ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **Sketch-Kernel ååŒè®¾è®¡æ˜¯è§£å†³ GPU ä¸Šç¨€ç– Sketch æ€§èƒ½ç“¶é¢ˆçš„æœ‰æ•ˆèŒƒå¼**ã€‚
2. âœ… **BLOCKPERM-SJLT çš„å—çº§æ’åˆ—ç»“æ„** æˆåŠŸå¹³è¡¡äº† **ç†è®ºé²æ£’æ€§** ä¸ **ç¡¬ä»¶å‹å¥½æ€§**ã€‚
3. âœ… **FLASHSKETCH é€šè¿‡æ¶ˆé™¤ global atomics å’Œ on-the-fly éšæœºç”Ÿæˆ**ï¼Œå®ç°äº†æ¥è¿‘æœ€ä¼˜çš„å†…å­˜è®¿é—®æ•ˆç‡ã€‚
4. âœ… **å¯è°ƒå‚æ•° $ K $ æä¾›äº†ä¸€ä¸ªæ˜¾å¼çš„é€Ÿåº¦-è´¨é‡æƒè¡¡æœºåˆ¶**ï¼Œé€‚ç”¨äºä¸åŒåº”ç”¨åœºæ™¯ã€‚
5. âœ… åœ¨æ ‡å‡† RandNLA ä»»åŠ¡å’Œç«¯åˆ°ç«¯ ML æµæ°´çº¿ï¼ˆGraSSï¼‰ä¸­ï¼ŒFLASHSKETCH **å…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•**ï¼Œæ¨åŠ¨äº† Sketching çš„ Pareto å‰æ²¿ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **æœ€é€‚ç”¨åœºæ™¯**ï¼š
  - è¾“å…¥çŸ©é˜µ $ A $ æ˜¯ **dense** çš„ã€‚
  - $ k < d $ ä½† $ k $ è¶³å¤Ÿå¤§ä»¥é¥±å’Œ GPUï¼ˆé¿å…ä½ occupancyï¼‰ã€‚
- **ä¸ç†æƒ³åœºæ™¯**ï¼š
  - å½“ $ k $ å¾ˆå°æ—¶ï¼Œthread block æ•°ä¸è¶³ï¼Œéš¾ä»¥å……åˆ†åˆ©ç”¨ GPU å¹¶è¡Œæ€§ï¼ˆè™½æœ‰ split-Bc fallbackï¼Œä½†ä»å—é™ï¼‰ã€‚
  - $ K $ è¿‡å¤§ä¼šå¢åŠ è¾“å…¥è¯»å–æ¬¡æ•°ï¼ŒæŠµæ¶ˆéƒ¨åˆ†æ€§èƒ½å¢ç›Šã€‚
- **ç†è®ºå‡è®¾**ï¼š
  - å½“å‰åˆ†æå‡è®¾æ’åˆ—æ˜¯ç‹¬ç«‹å‡åŒ€éšæœºçš„ï¼Œè€Œå®é™…ä½¿ç”¨çš„æ˜¯è½»é‡çº§æ„é€ ï¼ˆaffine permutationsï¼‰ï¼Œå­˜åœ¨ä¸€å®šä¾èµ–æ€§ï¼ˆä½†åœ¨ $ K < M $ ä¸‹å½±å“å°ï¼‰ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **è‡ªé€‚åº”å‚æ•°é€‰æ‹©**ï¼šå¼€å‘æ•°æ®æ„ŸçŸ¥æˆ–ç¡¬ä»¶æ„ŸçŸ¥çš„è‡ªåŠ¨è°ƒä¼˜ç­–ç•¥ï¼ŒåŠ¨æ€é€‰æ‹©æœ€ä¼˜ $ K $ å’Œ $ s $ã€‚
2. **æ‰©å±•åˆ°å…¶ä»– Sketch ç±»å‹**ï¼šå°† co-design æ€æƒ³åº”ç”¨äº CountSketchã€OSNAP ç­‰ã€‚
3. **æ”¯æŒæ›´å¤šç²¾åº¦æ ¼å¼**ï¼šæ¢ç´¢ FP16/BF16 ä¸‹çš„ä¼˜åŒ–ï¼Œç»“åˆ Tensor Coresã€‚
4. **åˆ†å¸ƒå¼æ‰©å±•**ï¼šç ”ç©¶ BLOCKPERM-SJLT åœ¨å¤š GPU æˆ–é›†ç¾¤ç¯å¢ƒä¸‹çš„é«˜æ•ˆå®ç°ã€‚
5. **æ›´ç´§è‡´çš„ç†è®ºè¾¹ç•Œ**ï¼šåˆ†æä¾èµ–æ’åˆ—ä¸‹çš„ OSE ä¿è¯ï¼Œç¼©å°ç†è®ºä¸å®è·µå·®è·ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼š  
> **FLASHSKETCH é€šè¿‡åˆ›æ–°çš„ BLOCKPERM-SJLT ç»“æ„ä¸é«˜åº¦ä¼˜åŒ–çš„ FLASHSKETCH Kernelï¼ŒæˆåŠŸè§£å†³äº†ç¨€ç– Sketch åœ¨ GPU ä¸Šçš„æ€§èƒ½ç“¶é¢ˆã€‚å®ƒä¸ä»…åœ¨ç†è®ºä¸Šæä¾›äº†å¯æ§çš„è´¨é‡ä¿è¯ï¼Œä¹Ÿåœ¨å®è·µä¸­å®ç°äº†é«˜è¾¾ 1.7Ã— çš„å¹³å‡åŠ é€Ÿï¼Œæ˜¯ RandNLA ä¸ç³»ç»ŸååŒè®¾è®¡çš„ä¸€ä¸ªå…¸èŒƒã€‚**

</details>

---

### 10. [To 2:4 Sparsity and Beyond: Neuron-level Activation Function to Accelerate LLM Pre-Training](https://arxiv.org/abs/2602.06183)

**Authors**: Meghana Madhyastha, Daniel Haziza, Jesse Cai, Newsha Ardalani, Zhiqi Bu, Carole-Jean Wu  
**Category**: cs.LG  
**Published**: 2026-02-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.06183v1  

#### Abstract
Trainings of Large Language Models are generally bottlenecked by matrix multiplications. In the Transformer architecture, a large portion of these operations happens in the Feed Forward Network (FFN), and this portion increases for larger models, up to 50% of the total pretraining floating point ope...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*To 2:4 Sparsity and Beyond: Neuron-level Activation Function to Accelerate LLM Pre-Training*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¢„è®­ç»ƒè¿‡ç¨‹åœ¨è®¡ç®—ä¸Šæå…¶æ˜‚è´µï¼Œå…¶ä¸­å¤§éƒ¨åˆ†è®¡ç®—å¼€é”€æ¥è‡ªçŸ©é˜µä¹˜æ³•ï¼ˆGEMMï¼‰ï¼Œå°¤å…¶æ˜¯åœ¨ Transformer æ¶æ„ä¸­çš„ **Feed Forward Network (FFN)** æ¨¡å—ã€‚å°½ç®¡å·²æœ‰ç¡¬ä»¶æ”¯æŒ **2:4 sparsity** æ¥åŠ é€Ÿç¨€ç–çŸ©é˜µä¹˜æ³•ï¼Œä½†å…¶ä»…èƒ½åˆ©ç”¨ 50% çš„ sparsityï¼Œè€Œå®é™…ä¸­æ¿€æ´»å€¼ï¼ˆactivationsï¼‰çš„è‡ªç„¶ç¨€ç–åº¦å¯é«˜è¾¾ 90% ä»¥ä¸Šï¼Œå¯¼è‡´å¤§é‡æ½œåŠ›æœªè¢«æŒ–æ˜ã€‚

æ­¤å¤–ï¼Œå¦‚ä½•åœ¨ä¸ç‰ºç‰²æ¨¡å‹è´¨é‡çš„å‰æä¸‹ï¼Œç³»ç»Ÿæ€§åœ°ç»“åˆæƒé‡ï¼ˆweightsï¼‰å’Œæ¿€æ´»ï¼ˆactivationsï¼‰çš„ç¨€ç–æ€§è¿›è¡Œé«˜æ•ˆè®­ç»ƒï¼Œä»ç¼ºä¹æ·±å…¥ç ”ç©¶ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§å…¨æ–°çš„è®­ç»ƒç­–ç•¥ï¼Œé¦–æ¬¡å®ç°äº†åœ¨ LLM é¢„è®­ç»ƒé˜¶æ®µå¯¹ **æ•´ä¸ª FFN æ¨¡å—çš„æ‰€æœ‰çŸ©é˜µä¹˜æ³•è¿›è¡Œç«¯åˆ°ç«¯ç¨€ç–åŠ é€Ÿ**ï¼Œå…·ä½“åŒ…æ‹¬ï¼š

1. **ç»Ÿä¸€åº”ç”¨ç¨€ç–æ ¼å¼**ï¼š
   - å¯¹ **æƒé‡** ä½¿ç”¨ **2:4 sparsity**ï¼ˆé€šè¿‡ soft-thresholding å®ç°ï¼‰ï¼›
   - å¯¹ **æ¿€æ´»** ä½¿ç”¨æ›´é«˜æ•ˆçš„ **V:N:M (Venom) sparsity** æ ¼å¼ï¼Œä»¥å……åˆ†åˆ©ç”¨ >90% çš„é«˜ç¨€ç–åº¦ã€‚

2. **å¼•å…¥ç¥ç»å…ƒçº§ä¸“å®¶è·¯ç”±æœºåˆ¶ï¼ˆNeuron-level Expert Routingï¼‰**ï¼š
   - è®¾è®¡äº†ä¸€ä¸ªåŸºäº **SquaredReLU æ¿€æ´»å‡½æ•°** çš„æ–°å‹æ¿€æ´»æœºåˆ¶ï¼Œä½¿æ¿€æ´»çŸ©é˜µå¤©ç„¶å…·æœ‰é«˜ç¨€ç–æ€§ï¼›
   - å¼•å…¥ä¸€ä¸ªè½»é‡çº§ **router**ï¼Œå°†æ¯ä¸ª token åŠ¨æ€è·¯ç”±è‡³ç‰¹å®šâ€œä¸“å®¶â€å­é›†ï¼Œå¹¶é€šè¿‡é‡æ’åºå®ç°ç¬¦åˆ Venom æ ¼å¼çš„ç»“æ„åŒ–ç¨€ç–ï¼›
   - åˆ©ç”¨ç¡¬ä»¶æ”¯æŒçš„ **Scatter/Gather GEMM + TMA**ï¼ˆBlackwell æ¶æ„ï¼‰æ¶ˆé™¤é‡æ’å¼€é”€ã€‚

3. **æ··åˆç¨€ç–-ç¨ å¯†è®­ç»ƒç­–ç•¥ï¼ˆSparse-Dense Hybrid Trainingï¼‰**ï¼š
   - åœ¨è®­ç»ƒå‰æœŸä½¿ç”¨ç¨€ç– GEMM åŠ é€Ÿï¼›
   - åæœŸåˆ‡æ¢ä¸ºç¨ å¯†è®­ç»ƒä»¥æ¢å¤ç²¾åº¦ï¼›
   - æ‰¾åˆ°äº†æœ€ä¼˜çš„ç¨€ç–:ç¨ å¯†æ­¥æ•°æ¯”ä¾‹ï¼ˆå¦‚ 1B æ¨¡å‹ä¸º 1:1ï¼Œ7B æ¨¡å‹ä¸º 1:3.5ï¼‰ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | æœ¬æ–‡æ–¹æ³• | ç°æœ‰æ–¹æ³• |
|------|--------|---------|
| **ç¨€ç–ç²’åº¦** | Fine-grainedï¼ˆç»†ç²’åº¦ï¼‰ | å¤šä¸º coarse-grainedï¼ˆå¦‚ MoEï¼‰æˆ– post-training pruning |
| **æ¿€æ´»ç¨€ç–åˆ©ç”¨** | ä½¿ç”¨ Venom æ ¼å¼ï¼Œæ”¯æŒ 80â€“99% sparsityï¼Œè¾¾ 6â€“8Ã— GEMM åŠ é€Ÿ | é€šå¸¸åªç”¨ 2:4ï¼ˆä»… 50% sparsityï¼‰ï¼Œæœ€å¤šæé€Ÿ ~1.5Ã— |
| **ç¡¬ä»¶å…¼å®¹æ€§** | æ”¯æŒä» A100 èµ·æ‰€æœ‰ NVIDIA GPUï¼ŒBlackwell å¯è¿›ä¸€æ­¥ä¼˜åŒ– | å¤šä¾èµ–ç‰¹å®šç¡¬ä»¶æˆ–æ— æ³•ç«¯åˆ°ç«¯åŠ é€Ÿ |
| **è®­ç»ƒç¨³å®šæ€§** | Soft-thresholding + æ¸è¿›å¼æ¢å¤ç­–ç•¥ä¿è¯ loss è¿ç»­æ€§å’Œæ”¶æ•›æ€§ | ç›´æ¥å‰ªææ˜“é€ æˆ loss è·³è·ƒã€æ€§èƒ½ä¸‹é™ |
| **é€šç”¨æ€§** | æ­£äº¤äºé‡åŒ–ï¼ˆquantizationï¼‰ã€GQAã€MoE ç­‰æŠ€æœ¯ï¼Œå¯å åŠ ä¼˜åŒ– | å¾ˆå¤šæ–¹æ¡ˆäº’æ–¥ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼š`DCLM` datasetï¼ˆç”¨äº LLM é¢„è®­ç»ƒçš„æ ‡å‡†è¯­æ–™ï¼‰
- **è¯„ä¼°ä»»åŠ¡**ï¼š`Eval-Harness` suite ä¸­å¤šä¸ªåŸºå‡†ä»»åŠ¡ï¼š
  - `ARC-Easy`, `ARC-Challenge`
  - `PIQA`, `OBQA`
  - `HellaSwag`, `Winogrande`

### âš™ï¸ å®éªŒè®¾ç½®
| å‚æ•° | è®¾ç½® |
|------|------|
| æ¨¡å‹æ¶æ„ | Llama-3 å˜ä½“ï¼ˆ1B å’Œ 7B å‚æ•°è§„æ¨¡ï¼‰ |
| æ¨¡å‹é…ç½® | è§ Table 1ï¼š<br>- 1B: 22 å±‚, d_model=2048, d_ffn=8192<br>- 7B: 32 å±‚, d_model=4096, d_ffn=16384 |
| Batch Size | 2 |
| Sequence Length | 8192 |
| Optimizer & LR | AdamW, cosine å­¦ä¹ ç‡è°ƒåº¦ |
| ç¡¬ä»¶å¹³å° | **NVIDIA H200 GPUs** |
| ç²¾åº¦ | bfloat16 / fp8ï¼ˆéƒ¨åˆ†å¾®åŸºå‡†æµ‹è¯•ï¼‰ |

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- **è®­ç»ƒæŸå¤±ï¼ˆTraining Lossï¼‰**ï¼šæœ€å 100 æ­¥å¹³å‡ loss
- **ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡**ï¼šå„ benchmark çš„ accuracy
- **ç«¯åˆ°ç«¯è®­ç»ƒé€Ÿåº¦æå‡ï¼ˆEnd-to-end Speedupï¼‰**
- **æ¯ç§’ TFLOPS**ï¼šç”¨äº microbenchmark åˆ†æ

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**ï¼šæ ‡å‡†ç¨ å¯†è®­ç»ƒï¼ˆno sparsityï¼‰
- **Sparse-only baselines**ï¼š
  - ä»… weight 2:4 sparsity
  - ä»… activation 2:4 sparsity
  - ä»… Venom activation sparsity
- **ç»„åˆç­–ç•¥å¯¹æ¯”**ï¼šä¸åŒç¨€ç–/ç¨ å¯†æ­¥æ•°æ¯”ä¾‹ï¼ˆablation studyï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 2ï¼‰

| æ¨¡å‹ | æ–¹æ³• | Speedup | è®­ç»ƒ Loss | å¹³å‡ Accuracy |
|------|------|--------|----------|----------------|
| Llama-1B | Baseline | 1.0Ã— | 2.758 | 0.527 |
| Llama-1B | æœ¬æ–‡æœ€ä½³ç­–ç•¥ | **1.352Ã—** | **2.755** | **0.527** |
| Llama-7B | Baseline | 1.0Ã— | 1.863 | 0.651 |
| Llama-7B | æœ¬æ–‡æœ€ä½³ç­–ç•¥ | **1.387Ã—** | **1.866** | **0.652** |

> âœ… ç»“æœè¡¨æ˜ï¼š**åœ¨å®Œå…¨ä¿æŒæ¨¡å‹è´¨é‡ï¼ˆloss ä¸ accuracy å‡æ— æŸï¼‰çš„å‰æä¸‹ï¼Œå®ç°äº† 1.35â€“1.39Ã— çš„ç«¯åˆ°ç«¯è®­ç»ƒåŠ é€Ÿ**ã€‚

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”
- å•ç‹¬ä½¿ç”¨ä»»ä½•ä¸€ç§ç¨€ç–æ–¹å¼ï¼ˆweight æˆ– activationï¼‰éƒ½ä¼šå¯¼è‡´çº¦ 0.03 çš„ loss ä¸Šå‡ï¼›
- ä½†é€šè¿‡ **æ··åˆç¨€ç–-ç¨ å¯†è®­ç»ƒ**ï¼Œå¯åœ¨åæœŸæ¢å¤ç²¾åº¦ï¼›
- æœ€ç»ˆæ€§èƒ½ **æŒå¹³ç”šè‡³ç•¥ä¼˜äº baseline**ï¼ˆå¦‚ Winogrande ä¸Šç•¥æœ‰æå‡ï¼‰ã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰æƒé‡ç¨€ç–å½±å“ï¼ˆTable 3ï¼‰
| é…ç½® | è®­ç»ƒ Loss |
|------|----------|
| Baselineï¼ˆç¨ å¯†ï¼‰ | 2.758 |
| W1 sparse | 2.784 (+0.026) |
| W2 sparse | 2.785 (+0.027) |
| W1 & W2 sparse | 2.844 (+0.086) |
| W1.T also sparse | ~+0.015 é¢å¤–æŸå¤± |

> ğŸ’¡ å‘ç°ï¼šåŒæ—¶ç¨€ç– W1 å’Œ W2 æŸå¤±å åŠ ï¼›è½¬ç½®çŸ©é˜µç¨€ç–ä¼šå¸¦æ¥é¢å¤–æ‰°åŠ¨ã€‚

#### ï¼ˆ2ï¼‰æ¿€æ´»ç¨€ç–å½±å“
| é…ç½® | è®­ç»ƒ Loss |
|------|----------|
| 2:4 activation sparsity | 2.755ï¼ˆå‡ ä¹æ— æŸï¼‰ |
| Venom sparsity | 2.789ï¼ˆ+0.031ï¼‰ |

> ğŸ’¡ å°½ç®¡ Venom å¯¼è‡´è½»å¾® loss ä¸Šå‡ï¼Œä½†å…¶ GEMM å¯æé€Ÿ **6â€“8Ã—**ï¼Œæ€§ä»·æ¯”æé«˜ã€‚

#### ï¼ˆ3ï¼‰ç¨€ç–-ç¨ å¯†æ­¥æ•°æ¯”ä¾‹ï¼ˆTable 4 & Figure 5ï¼‰
| ç¨€ç–æ­¥æ•° | å¹³å‡ Accuracy |
|---------|----------------|
| 0ï¼ˆå…¨ç¨ å¯†ï¼‰ | 0.527 |
| 30k | 0.527 âœ… |
| 40k | 0.518 â†“ |
| 60k | 0.467 â†“â†“ |

> âœ… æœ€ä½³ç­–ç•¥ï¼š**å…ˆç¨€ç–è®­ç»ƒï¼Œåæ¥ç­‰é‡æˆ–æ›´å¤šç¨ å¯†æ­¥æ•°è¿›è¡Œâ€œä¿®å¤â€**  
> - 1B æ¨¡å‹ï¼š30k sparse + 30k dense â†’ å®Œç¾æ¢å¤  
> - 7B æ¨¡å‹ï¼šéœ€æ›´å¼ºä¿®å¤ â†’ 10k sparse + 38k dense

#### ï¼ˆ4ï¼‰Microbenchmarks æ€§èƒ½ï¼ˆFigures 6 & 7ï¼‰
| æ“ä½œ | å®æµ‹åŠ é€Ÿæ¯” |
|------|-----------|
| 2:4 sparse GEMM | **~1.5Ã—**ï¼ˆç†è®º 2Ã—ï¼Œå—é™äºå†…å­˜å¸¦å®½ï¼‰ |
| Venom GEMMï¼ˆ87.5â€“96.8% sparsityï¼‰ | **6â€“8Ã—** |
| 2:4 è½¬æ¢å¼€é”€ï¼ˆsoft-thresholdingï¼‰ | å¯å¿½ç•¥ï¼ˆ<5%ï¼‰ |

> âœ… æ•°æ®è½¬æ¢å’Œæ ¼å¼æ‰“åŒ…å¼€é”€æä½ï¼Œå°¤å…¶åœ¨ pipeline parallelism ä¸‹å¯æ‘Šé”€ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **FFN æ˜¯ LLM é¢„è®­ç»ƒçš„ä¸»è¦ç®—åŠ›ç“¶é¢ˆ**ï¼Œå æ¯”å¯è¾¾æ€» FLOPs çš„ **50â€“80%**ï¼Œæ˜¯ç¨€ç–ä¼˜åŒ–çš„ç†æƒ³ç›®æ ‡ã€‚
2. **è‡ªç„¶æ¿€æ´»ç¨€ç–æ€§ï¼ˆ>90%ï¼‰è¿œè¶… 2:4 æ”¯æŒèŒƒå›´**ï¼Œå¿…é¡»é‡‡ç”¨æ›´é«˜é˜¶ç¨€ç–æ ¼å¼ï¼ˆå¦‚ Venomï¼‰æ‰èƒ½å……åˆ†å—ç›Šã€‚
3. **Neuron-level routing + Venom formatting** æˆåŠŸå°†åŠ¨æ€ç¨€ç–æ¿€æ´»è½¬åŒ–ä¸ºç¡¬ä»¶å‹å¥½çš„ç»“æ„åŒ–ç¨€ç–ï¼Œå®ç°é«˜è¾¾ **8Ã— GEMM åŠ é€Ÿ**ã€‚
4. **æ··åˆç¨€ç–-ç¨ å¯†è®­ç»ƒç­–ç•¥** æ˜¯å¹³è¡¡æ•ˆç‡ä¸ç²¾åº¦çš„å…³é”®ï¼šå‰æœŸåŠ é€Ÿï¼ŒåæœŸä¿®å¤ã€‚
5. è¯¥æ–¹æ³• **æ­£äº¤äºé‡åŒ–ã€MoEã€GQA ç­‰ä¸»æµä¼˜åŒ–æŠ€æœ¯**ï¼Œå…·å¤‡è‰¯å¥½æ‰©å±•æ€§ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–ç‰¹å®šç¡¬ä»¶æ”¯æŒ**ï¼šVenom å’Œ 2:4 sparsity ä»…åœ¨ Ampere åŠä»¥åæ¶æ„ï¼ˆA100/H100/B100/H200ï¼‰ä¸Šæœ‰æ•ˆã€‚
2. **Blackwell ä¼˜åŠ¿æ˜æ˜¾**ï¼šScatter/Gather GEMM å¯æ¶ˆé™¤ row permutation å¼€é”€ï¼Œåœ¨æ—§ GPU ä¸Šä»æœ‰è½»å¾®å»¶è¿Ÿã€‚
3. **å½“å‰ä»…åº”ç”¨äº FFN**ï¼šAttention æ¨¡å—å› ä¸Šä¸‹æ–‡æ•æ„Ÿæ€§éš¾ä»¥ç¨€ç–åŒ–ã€‚
4. **è¶…å‚æ•°è°ƒä¼˜æˆæœ¬**ï¼šV, N, M å’Œç¨€ç–/ç¨ å¯†æ¯”ä¾‹éœ€æ ¹æ®æ¨¡å‹è§„æ¨¡è°ƒæ•´ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³ Attention æ¨¡å—**ï¼šæ¢ç´¢ contextual sparsity æˆ– safe pruning ç­–ç•¥ã€‚
2. **è‡ªåŠ¨åŒ–ç¨€ç–ç­–ç•¥è°ƒåº¦**ï¼šè®¾è®¡ learning-based controller åŠ¨æ€å†³å®šä½•æ—¶ç¨€ç–ã€ç¨€ç–å“ªä¸€å±‚ã€‚
3. **ä¸ MoE æ¶æ„èåˆ**ï¼šå°† neuron-level routing ä¸ token-level routing ç»“åˆï¼Œæ„å»ºåŒé‡ç¨€ç–ç³»ç»Ÿã€‚
4. **æ”¯æŒæ›´å¤šç¨€ç–æ ¼å¼**ï¼šé€‚é…æœªæ¥çš„ç¡¬ä»¶ç¨€ç–æŒ‡ä»¤ï¼ˆå¦‚ n:m with m>4ï¼‰ã€‚
5. **é™ä½å¯åŠ¨å¼€é”€**ï¼šä¼˜åŒ– warm-up é˜¶æ®µçš„ clustering ä¸ expert åˆå§‹åŒ–ã€‚

---

## âœ… æ€»ç»“ä¸€å¥è¯
> æœ¬æ–‡æå‡ºäº†é¦–ä¸ªåœ¨ LLM é¢„è®­ç»ƒä¸­å…¨é¢åˆ©ç”¨ **2:4 weight sparsity** ä¸ **Venom activation sparsity** çš„ç«¯åˆ°ç«¯åŠ é€Ÿæ¡†æ¶ï¼Œé€šè¿‡ **neuron-level routing** å’Œ **æ··åˆç¨€ç–-ç¨ å¯†è®­ç»ƒç­–ç•¥**ï¼Œåœ¨ **ä¸æŸå¤±æ¨¡å‹æ€§èƒ½çš„å‰æä¸‹å®ç°æœ€é«˜ 1.7Ã— çš„è®­ç»ƒåŠ é€Ÿ**ï¼Œä¸ºä¸‹ä¸€ä»£é«˜æ•ˆè®­ç»ƒç³»ç»Ÿæä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 11. [Fine-Grained Model Merging via Modular Expert Recombination](https://arxiv.org/abs/2602.06552)

**Authors**: Haiyun Qiu, Xingyu Wu, Liang Feng, Kay Chen Tan  
**Category**: cs.LG  
**Published**: 2026-02-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.06552v1  

#### Abstract
Model merging constructs versatile models by integrating task-specific models without requiring labeled data or expensive joint retraining. Although recent methods improve adaptability to heterogeneous tasks by generating customized merged models for each instance, they face two critical limitations...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFine-Grained Model Merging via Modular Expert Recombination

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **model merging** æ–¹æ³•é¢ä¸´ä¸¤å¤§å…³é”®é™åˆ¶ï¼š
1. **å®ä¾‹çº§åˆå¹¶ï¼ˆinstance-specific mergingï¼‰ç¼ºä¹å¯é‡ç”¨æ€§**ï¼šä¸ºæ¯ä¸ªè¾“å…¥åŠ¨æ€ç”Ÿæˆçš„åˆå¹¶æ¨¡å‹æ— æ³•å¤ç”¨ï¼Œå¯¼è‡´æ— æ³•ç¼“å­˜æˆ–å…±äº«é«˜è´¨é‡é…ç½®ï¼Œä¸”æ¨ç†æ•ˆç‡ä½ä¸‹ï¼ˆæ— æ³•æ‰¹é‡å¤„ç†ï¼‰ã€‚
2. **å¿½ç•¥ç»„ä»¶çº§å¼‚è´¨æ€§ï¼ˆcomponent-wise heterogeneityï¼‰**ï¼šå°†æ•´ä¸ªä»»åŠ¡ç‰¹å®šæ¨¡å‹è§†ä¸ºé»‘ç®±è¿›è¡Œåˆå¹¶ï¼Œå¿½ç•¥äº†ä¸åŒæ¨¡å—ï¼ˆå¦‚ Attentionã€MLPã€Normalization å±‚ï¼‰åœ¨å¯åˆå¹¶æ€§ä¸Šçš„æ˜¾è‘—å·®å¼‚ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šMERGE
ä½œè€…æå‡º **MERGE (Modular Expert Recombination for fine-Grained mErging)**ï¼Œä¸€ç§å®ç°ç»†ç²’åº¦æ¨¡å‹åˆå¹¶çš„æ–°èŒƒå¼ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ **â€œç¦»çº¿ä¼˜åŒ– + æŒ‰éœ€å¤ç”¨â€**ã€‚

#### åˆ›æ–°ç‚¹
1. **ç»„ä»¶çº§åˆå¹¶ï¼ˆComponent-Wise Mergingï¼‰**  
   å°†ä»»åŠ¡ç‰¹å®šæ¨¡å‹åˆ†è§£ä¸ºåŠŸèƒ½ç»„ä»¶ï¼ˆå¦‚ Attentionã€MLPï¼‰ï¼Œå¯¹åŒæºç»„ä»¶è¿›è¡Œç‹¬ç«‹çš„åˆå¹¶å†³ç­–ï¼Œè€Œéæ•´æ¨¡å‹åˆå¹¶ã€‚è¿™èƒ½æ›´ç²¾ç»†åœ°æ§åˆ¶åˆå¹¶è¿‡ç¨‹ï¼Œé¿å…å¯¹æ•æ„Ÿç»„ä»¶ï¼ˆå¦‚ MLPï¼‰é€ æˆç ´åæ€§å¹²æ‰°ã€‚

2. **åŒç›®æ ‡ä¼˜åŒ–æœç´¢ï¼ˆBi-Objective Evolutionary Optimizationï¼‰**  
   å°†ç»„ä»¶çº§åˆå¹¶é…ç½®çš„æœç´¢å»ºæ¨¡ä¸ºä¸€ä¸ªå¹³è¡¡ **è·¨ä»»åŠ¡æ€§èƒ½ï¼ˆcross-task performanceï¼‰** å’Œ **å­˜å‚¨æ•ˆç‡ï¼ˆstorage efficiencyï¼‰** çš„åŒç›®æ ‡ä¼˜åŒ–é—®é¢˜ã€‚é‡‡ç”¨ **ä»£ç†è¾…åŠ©çš„è¿›åŒ–ç®—æ³•ï¼ˆsurrogate-assisted evolutionary algorithmï¼‰** é«˜æ•ˆæ¢ç´¢å·¨å¤§çš„ç¦»æ•£æœç´¢ç©ºé—´ï¼Œæ‰¾åˆ°å¸•ç´¯æ‰˜æœ€ä¼˜ï¼ˆPareto-optimalï¼‰çš„åˆå¹¶é…ç½®é›†åˆã€‚

3. **å¯é‡ç”¨çš„ä¸“å®¶åº“ä¸æŒ‰éœ€é‡ç»„ï¼ˆReusable Modular Expert Library & On-Demand Recombinationï¼‰**  
   - **ç¦»çº¿é˜¶æ®µ**ï¼šåˆ©ç”¨ä¼˜åŒ–ç®—æ³•ç”Ÿæˆä¸€ç»„é«˜è´¨é‡çš„ã€å¯é‡ç”¨çš„ **æ¨¡å—åŒ–ä¸“å®¶ï¼ˆmodular expertsï¼‰**ï¼Œå¹¶æ„å»ºä¸€ä¸ª **æ¨¡å—åŒ–ä¸“å®¶åº“ï¼ˆmodular expert libraryï¼‰**ã€‚
   - **æ¨ç†é˜¶æ®µ**ï¼šé€šè¿‡ä¸€ä¸ªè½»é‡çº§çš„ **è·¯ç”±ç½‘ç»œï¼ˆrouting networkï¼‰**ï¼Œæ ¹æ®è¾“å…¥åŠ¨æ€é€‰æ‹©æœ€ä¼˜çš„ä¸“å®¶ç»„åˆè·¯å¾„ï¼Œå¹¶ä»ä¸“å®¶åº“ä¸­æ¿€æ´»ç›¸åº”çš„æ¨¡å—ï¼Œç»„è£…æˆé’ˆå¯¹è¯¥è¾“å…¥çš„ä¸“ç”¨æ¨¡å‹ã€‚è¿™å®ç°äº†è¾“å…¥æ„ŸçŸ¥çš„é€‚åº”æ€§ï¼ŒåŒæ—¶ä¿è¯äº†æ¨¡å—çš„å¯é‡ç”¨æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **å…¼é¡¾é€‚åº”æ€§ä¸å¯é‡ç”¨æ€§**ï¼šè§£å†³äº†ç°æœ‰åŠ¨æ€åˆå¹¶æ–¹æ³•ä¸­â€œé€‚åº”æ€§â€ä¸â€œå¯é‡ç”¨æ€§â€çš„æ ¹æœ¬çŸ›ç›¾ã€‚
- **æ›´é«˜çš„çµæ´»æ€§å’Œæ€§èƒ½**ï¼šé€šè¿‡ç»†ç²’åº¦çš„ç»„ä»¶çº§æ“ä½œï¼Œèƒ½æ›´å¥½åœ°ä¿ç•™å„ä»»åŠ¡çš„ä¸“ä¸šçŸ¥è¯†ï¼Œå‡å°‘åˆå¹¶å¹²æ‰°ã€‚
- **é«˜æ•ˆçš„æ¨ç†**ï¼šç”±äºç›¸ä¼¼è¾“å…¥ä¼šæ¿€æ´»ç›¸åŒçš„ä¸“å®¶é“¾ï¼Œæ”¯æŒé«˜æ•ˆçš„æ‰¹é‡æ¨ç†ã€‚
- **çµæ´»çš„æƒè¡¡**ï¼šæä¾›ä¸€ç³»åˆ—å¸•ç´¯æ‰˜æœ€ä¼˜è§£ï¼Œå…è®¸ç”¨æˆ·æ ¹æ®å­˜å‚¨é¢„ç®—çµæ´»é€‰æ‹©æ€§èƒ½æœ€ä½³çš„é…ç½®ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒè¦†ç›–äº†å¤šç§æ¨¡å‹è§„æ¨¡ã€ä»»åŠ¡ç±»å‹å’Œå¾®è°ƒç­–ç•¥ï¼š
1. **è§†è§‰æ¨¡å‹åˆå¹¶**ï¼š
   - **æ¨¡å‹**ï¼š`ViT-B/32` å’Œ `ViT-L/14`
   - **ä»»åŠ¡**ï¼š8ä¸ªå›¾åƒåˆ†ç±»æ•°æ®é›†ï¼š`SUN397`, `Cars`, `RESISC45`, `EuroSAT`, `SVHN`, `GTSRB`, `MNIST`, `DTD`
2. **å…¨é‡å¾®è°ƒè¯­è¨€æ¨¡å‹åˆå¹¶ï¼ˆFully Fine-Tuned Language Modelsï¼‰**ï¼š
   - **æ¨¡å‹**ï¼š`RoBERTa-base` å’Œ `GPT-2`
   - **ä»»åŠ¡**ï¼š`RoBERTa` åœ¨8ä¸ª `GLUE` æ•°æ®é›†ä¸Šå¾®è°ƒï¼›`GPT-2` åœ¨7ä¸ªç±»ä¼¼ä»»åŠ¡ä¸Šå¾®è°ƒã€‚
3. **å‚æ•°é«˜æ•ˆå¾®è°ƒæ¨¡å‹åˆå¹¶ï¼ˆPEFT Modelsï¼‰**ï¼š
   - **æ¨¡å‹**ï¼š`T0-3B` æ¨¡å‹ä½¿ç”¨ `(IA)$^3$` æ–¹æ³•å¾®è°ƒã€‚
   - **ä»»åŠ¡**ï¼š11ä¸ªè‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡ï¼Œå¦‚ `RTE`, `CB`, `Winogrande` ç­‰ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **æ€§èƒ½ï¼ˆPï¼‰**ï¼šå„ä»»åŠ¡ä¸Šçš„å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ã€Matthewsç›¸å…³ç³»æ•°ç­‰ã€‚
  - **å­˜å‚¨æˆæœ¬ï¼ˆCï¼‰**ï¼šå½’ä¸€åŒ–çš„å­˜å‚¨å¼€é”€ï¼ˆç›¸å¯¹äºå…¨ç²¾åº¦é¢„è®­ç»ƒæ¨¡å‹ï¼‰ã€‚
  - **ç»¼åˆè¯„ä¼°**ï¼šä½¿ç”¨ **å¸•ç´¯æ‰˜å‰æ²¿ï¼ˆPareto frontï¼‰** å’Œ **è¶…ä½“ç§¯ï¼ˆHypervolume, HVï¼‰** æŒ‡æ ‡æ¥è¡¡é‡è§£å†³æ–¹æ¡ˆçš„è´¨é‡ï¼ˆæ”¶æ•›æ€§å’Œå¤šæ ·æ€§ï¼‰ã€‚
- **MERGE å˜ä½“**ï¼šç»“åˆä¸åŒçš„åŸºç¡€åˆå¹¶æ–¹æ³•ä½œä¸º `intra-group merging` å‡½æ•°ï¼Œå½¢æˆ `MERGE-WA`, `MERGE-TA`, `MERGE-TM`, `MERGE-BC` ç­‰å˜ä½“ã€‚
- **ä¼˜åŒ–å™¨**ï¼šé‡‡ç”¨ `NSGA-II` è¿›åŒ–ç®—æ³•ï¼Œé…åˆ `Random Forest` ä»£ç†æ¨¡å‹åŠ é€Ÿæœç´¢ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **éåˆå¹¶æ–¹æ³•**ï¼š
   - `Individual` (å•ä¸ªä»»åŠ¡æ¨¡å‹)
   - `Traditional MTL` (ä¼ ç»Ÿå¤šä»»åŠ¡å­¦ä¹ )
   - `Pre-trained` (ä»…é¢„è®­ç»ƒæ¨¡å‹)
2. **é™æ€åˆå¹¶æ–¹æ³•**ï¼š
   - `Weight Averaging`, `Fisher Merging`, `RegMean`, `Task Arithmetic`, `Ties-Merging`, `Breadcrumbs`, `PCB-Merging`, `AdaMerging`
3. **åŠ¨æ€åˆå¹¶æ–¹æ³•**ï¼š
   - `Twin-Merging`, `EMR-Merging`

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ
- **å…¨é¢è¶…è¶ŠåŸºçº¿**ï¼šåœ¨æ‰€æœ‰å®éªŒåœºæ™¯ä¸‹ï¼Œ`MERGE` çš„å„ä¸ªå˜ä½“å‡æ˜¾è‘—ä¼˜äºå¼ºåŸºçº¿æ–¹æ³•ã€‚
- **æ¥è¿‘ä¸ªä½“æ¨¡å‹æ€§èƒ½**ï¼š
  - åœ¨ `ViT-B/32` ä¸Šï¼Œ`MERGE` çš„é«˜æ€§èƒ½è§£ï¼ˆG3ï¼‰å‡ ä¹è¾¾åˆ°äº†ä¸ªä½“æ¨¡å‹çš„å‡†ç¡®ç‡ï¼ˆ90.2% vs 90.5%ï¼‰ï¼Œä½†å­˜å‚¨æˆæœ¬è¿œä½äºéƒ¨ç½²8ä¸ªç‹¬ç«‹æ¨¡å‹ã€‚
  - åœ¨ `RoBERTa` ä¸Šï¼Œ`MERGE` å°†ä¸ä¸ªä½“æ¨¡å‹çš„æ€§èƒ½å·®è·ä» >7.3% ç¼©å°åˆ° <2.1%ã€‚
- **å“è¶Šçš„æ€§ä»·æ¯”**ï¼š
  - `MERGE` çš„æœ€å°å­˜å‚¨è§£ï¼ˆG1ï¼‰åœ¨ä»…éœ€çº¦ **30% å­˜å‚¨æˆæœ¬**çš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½å°±è¶…è¿‡äº†å…¶å¯¹åº”çš„åŸºç¡€åˆå¹¶æ–¹æ³•ã€‚
  - æˆæœ¬æ•ˆç›Šè§£ï¼ˆG2ï¼‰ä¸ä»…æ€§èƒ½è¶…è¿‡æœ€å¼ºçš„åŠ¨æ€åˆå¹¶åŸºçº¿ï¼ˆå¦‚ `EMR-Merging`ï¼‰ï¼Œè€Œä¸”å­˜å‚¨æ•ˆç‡ç›¸å½“ç”šè‡³æ›´ä¼˜ã€‚
- **åœ¨PEFTæ¨¡å‹ä¸Šè¡¨ç°ä¼˜å¼‚**ï¼š`MERGE` åœ¨å‚æ•°é«˜æ•ˆå¾®è°ƒæ¨¡å‹ä¸ŠåŒæ ·æœ‰æ•ˆï¼Œ`MERGE-BC(G3)` åœ¨11ä¸ªä»»åŠ¡ä¸Šå¹³å‡æ€§èƒ½è¾¾åˆ°69.4%ï¼Œè¿œè¶…å…¶ä»–åˆå¹¶æ–¹æ³•ã€‚

### æ¶ˆèå®éªŒç»“æœ
1. **åˆå¹¶ç²’åº¦ï¼ˆMerging Granularityï¼‰**ï¼š
   - `Component-Wise`ï¼ˆç»„ä»¶çº§ï¼‰æ˜¾è‘—ä¼˜äº `Task-Wise`ï¼ˆä»»åŠ¡çº§ï¼‰å’Œ `Layer-Wise`ï¼ˆå±‚çº§åˆ«ï¼‰ã€‚åè€…åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­å®¹æ˜“æ—©ç†Ÿæ”¶æ•›ï¼Œæ— æ³•æ‰¾åˆ°é«˜è´¨é‡è§£ã€‚

2. **ä»£ç†æ¨¡å‹çš„ä½œç”¨ï¼ˆSurrogate-Assisted Optimizationï¼‰**ï¼š
   - ä½¿ç”¨ä»£ç†æ¨¡å‹çš„ç‰ˆæœ¬èƒ½æ›´å¿«åœ°æ”¶æ•›åˆ°è´¨é‡æ›´é«˜çš„å¸•ç´¯æ‰˜å‰æ²¿ï¼ŒéªŒè¯äº†å…¶åœ¨åŠ é€Ÿæœç´¢ä¸­çš„å…³é”®ä½œç”¨ã€‚

3. **æœç´¢ç­–ç•¥ï¼ˆSearch Strategyï¼‰**ï¼š
   - é‡‡ç”¨ `K-means` åˆå§‹åŒ–ç§ç¾¤çš„è¿›åŒ–æœç´¢ï¼Œç›¸æ¯”éšæœºåˆå§‹åŒ–èƒ½æ›´å¿«å‘ç°é«˜è´¨é‡è§£ï¼Œè¯æ˜äº†è‰¯å¥½åˆå§‹è§£çš„é‡è¦æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç»„ä»¶çº§å¼‚è´¨æ€§è‡³å…³é‡è¦**ï¼šä¸åŒç»„ä»¶ï¼ˆAttention, MLP, Normï¼‰çš„åˆå¹¶æ•æ„Ÿæ€§å­˜åœ¨ç³»ç»Ÿæ€§å·®å¼‚ã€‚Norm å±‚æœ€æ˜“å…±äº«ï¼ŒMLP å±‚æœ€æ•æ„Ÿã€‚MERGE èƒ½æ˜¾å¼åˆ©ç”¨è¿™ä¸€ç‰¹æ€§ã€‚
2. **å­˜åœ¨æ”¶ç›Šé€’å‡è§„å¾‹**ï¼šéšç€å­˜å‚¨æˆæœ¬å¢åŠ ï¼Œæ€§èƒ½æå‡å‘ˆç°æ˜æ˜¾çš„è¾¹é™…æ•ˆç”¨é€’å‡è¶‹åŠ¿ï¼Œå°¤å…¶æ˜¯åœ¨è¯­è¨€æ¨¡å‹ä¸Šæ›´ä¸ºæ˜¾è‘—ã€‚
3. **é¢†åŸŸä¾èµ–çš„çŸ¥è¯†æ•´åˆæ¨¡å¼**ï¼š
   - è§†è§‰æ¨¡å‹ï¼ˆViTï¼‰ä¸»è¦ä¾èµ– `MLP` å±‚è¿›è¡Œä»»åŠ¡ç‰¹å¼‚æ€§ã€‚
   - è¯­è¨€æ¨¡å‹ï¼ˆRoBERTa/GPT-2ï¼‰åˆ™æ›´å¤šä¾èµ– `Attention` å±‚è¿›è¡ŒåŒºåˆ†ã€‚
   - åœ¨ç¼–ç å™¨-è§£ç å™¨æ¶æ„ä¸­ï¼Œ`Decoder-MLP` æ›´å€¾å‘äºçŸ¥è¯†å…±äº«ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ç¦»çº¿ä¼˜åŒ–æˆæœ¬é«˜**ï¼šè™½ç„¶æ¨ç†é«˜æ•ˆï¼Œä½†å¯»æ‰¾å¸•ç´¯æ‰˜æœ€ä¼˜é…ç½®çš„ç¦»çº¿ä¼˜åŒ–é˜¶æ®µè®¡ç®—å¼€é”€è¾ƒå¤§ï¼Œå°½ç®¡ä»£ç†æ¨¡å‹å·²å¤§å¹…ç¼“è§£æ­¤é—®é¢˜ã€‚
- **ä¾èµ–è·¯ç”±ç½‘ç»œè´¨é‡**ï¼šæœ€ç»ˆæ€§èƒ½å—é™äºè·¯ç”±ç½‘ç»œé¢„æµ‹è¾“å…¥ä»»åŠ¡æ¨¡å¼çš„å‡†ç¡®æ€§ã€‚
- **å‡è®¾ä»»åŠ¡è¾¹ç•Œæ˜ç¡®**ï¼šæ–¹æ³•çš„æœ‰æ•ˆæ€§å»ºç«‹åœ¨èƒ½å¤Ÿå®šä¹‰æ¸…æ™°ä»»åŠ¡å’Œä»»åŠ¡å‘é‡çš„åŸºç¡€ä¸Šã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„ä¼˜åŒ–ç®—æ³•ä»¥è¿›ä¸€æ­¥é™ä½ç¦»çº¿æˆæœ¬ã€‚
- ç ”ç©¶å¦‚ä½•å°† MERGE åº”ç”¨äºæ›´å¤§è§„æ¨¡çš„æ¨¡å‹ï¼ˆå¦‚ LLMsï¼‰å’Œæ›´å¤æ‚çš„ä»»åŠ¡ã€‚
- å¼€å‘æ— éœ€æ˜ç¡®å®šä¹‰ä»»åŠ¡çš„è‡ªç›‘ç£æˆ–æ— ç›‘ç£è·¯ç”±æœºåˆ¶ã€‚
- å°†è¯¥æ¡†æ¶æ‰©å±•åˆ°æ¨¡å‹ç¼–è¾‘ï¼ˆmodel editingï¼‰å’ŒæŒç»­å­¦ä¹ ï¼ˆcontinual learningï¼‰ç­‰åœºæ™¯ã€‚

</details>

---

### 12. [Evaluating an evidence-guided reinforcement learning framework in aligning light-parameter large language models with decision-making cognition in psychiatric clinical reasoning](https://arxiv.org/abs/2602.06449)

**Authors**: Xinxin Lin, Guangxin Dai, Yi Zhong, Xiang Li, Xue Xiao, Yixin Zhang, Zhengdong Wu, Yongbo Zheng, Runchuan Zhu, Ming Zhao, Huizi Yu, Shuo Wu, Jun Zhao, Lingming Hu, Yumei Wang, Ping Yin, Joey W. Y. Chan, Ngan Yin Chan, Sijing Chen, Yun Kwok Wing, Lin Lu, Xin Ma, Lizhou Fan  
**Category**: cs.CL  
**Published**: 2026-02-09  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.06449v1  

#### Abstract
Large language models (LLMs) hold transformative potential for medical decision support yet their application in psychiatry remains constrained by hallucinations and superficial reasoning. This limitation is particularly acute in light-parameter LLMs which are essential for privacy-preserving and ef...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

**è®ºæ–‡æ ‡é¢˜**: *Evaluating an evidence-guided reinforcement learning framework in aligning light-parameter large language models with decision-making cognition in psychiatric clinical reasoning*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç²¾ç¥ç—…å­¦ä¸´åºŠå†³ç­–æ”¯æŒä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†å…¶åº”ç”¨å—åˆ°ä»¥ä¸‹é™åˆ¶ï¼š
- **å¹»è§‰ï¼ˆhallucinationsï¼‰** å’Œ **è¡¨é¢åŒ–æ¨ç†ï¼ˆsuperficial reasoningï¼‰** å¯¼è‡´å¯é æ€§ä¸è¶³ã€‚
- å½“å‰è®­ç»ƒèŒƒå¼ï¼ˆå¦‚ SFTï¼‰ä¾§é‡äºè¯­è¨€æµç•…æ€§è€Œéç»“æ„åŒ–çš„ä¸´åºŠé€»è¾‘ï¼Œå¯¼è‡´æ¨¡å‹ä¸ä¸“ä¸šè¯Šæ–­è®¤çŸ¥å­˜åœ¨æ ¹æœ¬æ€§é”™ä½ã€‚
- è½»é‡çº§ LLMsï¼ˆlight-parameter LLMsï¼‰è™½é€‚åˆéšç§ä¿æŠ¤å’Œé«˜æ•ˆéƒ¨ç½²ï¼Œä½†åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æå‡º **ClinMPO** â€”â€”ä¸€ç§åŸºäºè¯æ®å¼•å¯¼çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨å°†è½»å‚æ•° LLM çš„å†…éƒ¨æ¨ç†è¿‡ç¨‹ä¸ä¸“ä¸šç²¾ç¥ç§‘å®è·µå¯¹é½ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
- **ClinRMï¼ˆClinical Reward Modelï¼‰**ï¼šä¸€ä¸ªç‹¬ç«‹è®­ç»ƒçš„å¥–åŠ±æ¨¡å‹ï¼ŒåŸºäºä» **4,474 ç¯‡ç²¾ç¥ç—…å­¦æœŸåˆŠæ–‡ç« ** æ„å»ºçš„ **Evidence Datasetï¼ˆå« 18,569 æ¡æ•°æ®ï¼‰**ï¼Œä¾æ® **Oxford Centre for Evidence-Based Medicine å±‚çº§** ç»“æ„åŒ–æ„å»ºã€‚
- **å¤šç»„ç­–ç•¥ä¼˜åŒ–ï¼ˆmulti-group policy optimizationï¼‰**ï¼šé‡‡ç”¨ç›¸å¯¹ä¼˜åŠ¿è®¡ç®—ï¼ˆrelative advantageï¼‰ï¼Œé¿å…ç»å¯¹å¥–åŠ±åå·®ï¼Œé¼“åŠ±ç”Ÿæˆæ›´é«˜è´¨é‡çš„æ¨ç†é“¾ã€‚
- **è®¤çŸ¥å¯¹é½å¯¼å‘**ï¼šæ˜¾å¼å¥–åŠ±åŸºäºè¯æ®çš„é€»è¾‘æ¨ç†ï¼Œæƒ©ç½šä¸è¿è´¯æ€ç»´é“¾ï¼ˆå¦‚ç—‡çŠ¶è¯¯åˆ¤ã€é”™è¯¯é‰´åˆ«è¯Šæ–­ç­‰ï¼‰ï¼Œå®ç°ä»â€œçŒœç­”æ¡ˆâ€åˆ°â€œçœŸå®æ¨ç†â€çš„è½¬å˜ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | ClinMPO çš„æ”¹è¿› |
|------|--------|----------------|
| **Supervised Fine-Tuning (SFT)** | æ˜“å¯¼è‡´æ¨¡å‹ä¾èµ–æµ…å±‚å¯å‘å¼çŒœæµ‹æ­£ç¡®ç­”æ¡ˆï¼Œç¼ºä¹æ·±å±‚æ¨ç†èƒ½åŠ› | å¼•å…¥åŸºäºä¸´åºŠæ ‡å‡†çš„å¯†é›†åé¦ˆï¼Œè¿«ä½¿æ¨¡å‹æ„å»ºæœ‰æ•ˆæ¨ç†é“¾ |
| **é€šç”¨ RL æ–¹æ³•ï¼ˆå¦‚ GRPOï¼‰** | å¥–åŠ±ä¿¡å·å¸¸ä¼˜åŒ–è¯­è¨€æµç•…æ€§è€Œéä¸´åºŠé€»è¾‘ | ä½¿ç”¨ ClinRM æä¾›é¢†åŸŸç‰¹å¼‚æ€§ã€ç»“æ„åŒ–è¯„åˆ†ï¼Œèšç„¦ç§‘å­¦å‡†ç¡®æ€§ä¸é€»è¾‘ä¸€è‡´æ€§ |
| **Psyche-R1 / MentraSuite ç­‰ä¸“ç”¨ç³»ç»Ÿ** | å¤šå…³æ³¨äº‹å®çº é”™è€Œéæ¨ç†è¿‡ç¨‹æœ¬èº« | ç›´æ¥å»ºæ¨¡ä¸“å®¶è¯„ä»·é€»è¾‘ï¼Œæå‡æ•´ä½“ä¸´åºŠåˆ¤æ–­è´¨é‡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- **Public QA Dataset**ï¼ˆ8,849 é“é¢˜ï¼‰
  - æ¥æºï¼šCMB, MedBullets, MedMCQA, MedQA, MedXpertQA, MMLU-Pro
  - ç»è¿‡ GPT-5 è¿‡æ»¤ç¡®ä¿ç²¾ç¥ç—…å­¦ç›¸å…³æ€§ï¼Œå¹¶ç»Ÿä¸€æ ¼å¼ä¸ºå¤šé¡¹é€‰æ‹©é¢˜ï¼ˆQuestion, Options, Correct Answer, Chain-of-Thoughtï¼‰
- **Evidence QA Dataset**ï¼ˆ18,569 å¯¹é—®ç­”ï¼‰
  - æ¥æºï¼šåŸºäº MeSH æ£€ç´¢ OpenAlex å’Œ Europe PMC ä¸­ 2020â€“2025 å¹´å‘è¡¨çš„ç²¾ç¥ç—…å­¦æ–‡çŒ®
  - æŒ‰ç…§ **Oxford Centre for Evidence-Based Medicine é‡‘å­—å¡”** åˆ†å±‚é‡‡æ ·ï¼ˆæŒ‡å—ã€ç»¼è¿°ã€å¯¹ç…§è¯•éªŒã€ç—…ä¾‹æŠ¥å‘Šç­‰ï¼‰
  - åŒ…å«ï¼šé—®é¢˜ã€é€‰é¡¹ã€æ­£ç¡®ç­”æ¡ˆã€CoTã€è¯„åˆ†è¡¨ï¼ˆscoring sheetï¼‰ã€è¯„åˆ†ç†ç”±ï¼ˆCoT for scoringï¼‰
  - ç”±äº”ä½ç²¾ç¥ç§‘ä¸“å®¶ç›²å®¡éªŒè¯è´¨é‡

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
#### æ•°æ®åˆ’åˆ†ç­–ç•¥ï¼ˆTwo-stage Trainingï¼‰
- å°† Public QA Dataset åˆ’åˆ†ä¸ºï¼š
  - **Easy Set (7,112)**ï¼šè¢«è¶…è¿‡ 8 ä¸ªå…ˆè¿› LLM æ­£ç¡®å›ç­”çš„é—®é¢˜ â†’ ç”¨ä½œè®­ç»ƒé›†
  - **Hard Set (1,737)**ï¼šå¤§å¤šæ•°å¤§æ¨¡å‹å¤±è´¥çš„é—®é¢˜ â†’ ç”¨ä½œæµ‹è¯•é›†
- ç›®æ ‡ï¼šæ¨¡æ‹Ÿâ€œé»‘ç®±æ¨æ–­â€åœºæ™¯ï¼Œæœ€å°åŒ–è®°å¿†æ•ˆåº”ï¼Œå¼ºè°ƒæœªçŸ¥çŸ¥è¯†ä¸‹çš„æ¨ç†èƒ½åŠ›

#### æ¨¡å‹è§„æ¨¡
ä½¿ç”¨ Qwen3 ç³»åˆ—è½»é‡æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼š
- Qwen3-0.6B, Qwen3-1.7B, Qwen3-4B, Qwen3-8B

#### è¯„ä¼°ç»´åº¦
1. **æ€»ä½“è¯Šæ–­å‡†ç¡®ç‡ï¼ˆOverall Diagnostic Accuracyï¼‰**
2. **ç»†ç²’åº¦åˆ†ç±»æ€§èƒ½**ï¼š
   - **Tier 1**: ICD-11 è¯Šæ–­åˆ†ç±»ï¼ˆ26 ç±»ï¼‰
   - **Tier 2**: ç²¾ç¥ç§‘å®è·µèƒœä»»åŠ›ï¼ˆ12 é¡¹ï¼Œå¦‚é£é™©è¯„ä¼°ã€å…±ç—…ç®¡ç†ã€æ³•å¾‹ä¼¦ç†ç­‰ï¼‰
3. **äººç±»åŸºå‡†å¯¹æ¯”**ï¼šæ‹›å‹Ÿ **300 ååŒ»å­¦ç”Ÿ** å®Œæˆç›¸åŒæµ‹è¯•é›†ï¼Œä½œä¸ºäººç±»è¡¨ç°åŸºå‡†
4. **é”™è¯¯è½¬ç§»åˆ†æï¼ˆError Transition Analysisï¼‰**ï¼šåˆ†æ FTï¼ˆé”™â†’å¯¹ï¼‰ä¸ TFï¼ˆå¯¹â†’é”™ï¼‰çš„å˜åŒ–ï¼ŒåŒºåˆ†çœŸå®æ¨ç†æå‡ vs å¹¸è¿çŒœæµ‹
5. **åˆ†å¸ƒé²æ£’æ€§åˆ†æ**ï¼šé€šè¿‡ç®±çº¿å›¾æ¯”è¾ƒä¸åŒæ–¹æ³•åœ¨å„ç±»åˆ«ä¸Šçš„ç¨³å®šæ€§

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Base**ï¼šæœªç»å¾®è°ƒçš„åŸºç¡€æ¨¡å‹
- **SFT**ï¼šç›‘ç£å¾®è°ƒ
- **GRPO**ï¼šé€šç”¨å¼ºåŒ–å­¦ä¹ ç­–ç•¥ä¼˜åŒ–ï¼ˆGeneralized Reward Policy Optimizationï¼‰
- **ClinMPO**ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•ï¼ˆåœ¨ GRPO æ¡†æ¶åŸºç¡€ä¸Šå¼•å…¥ ClinRMï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ¨¡å‹ | å‡†ç¡®ç‡ (%) | ç›¸å¯¹äºäººç±»åŸºå‡† |
|------|------------|----------------|
| **Human (300 medical students)** | **30.84%** | â€” |
| **Qwen3-8B-ClinMPO** | **31.43%** | **â†‘ +0.59 pp** |
| Qwen3-8B-GRPO | 30.80% | â†“ -0.04 pp |
| Qwen3-8B-SFT | 30.40% | â†“ -0.44 pp |
| Qwen3-8B (Base) | 28.27% | â†“ -2.57 pp |

> âœ… **ClinMPO åœ¨æœ€å¤§è§„æ¨¡æ¨¡å‹ä¸Šé¦–æ¬¡è¶…è¶Šäººç±»åŒ»å­¦ç”Ÿå¹³å‡æ°´å¹³**

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- ClinMPO åœ¨æ‰€æœ‰æ¨¡å‹å°ºåº¦ä¸‹å‡ä¼˜äº SFT å’Œ GRPOï¼š
  - å¹³å‡ç»å¯¹å¢ç›Šï¼š**+2.72 pp**ï¼ˆClinMPOï¼‰vs +1.80 ppï¼ˆGRPOï¼‰vs +1.64 ppï¼ˆSFTï¼‰
- åœ¨ **8B æ¨¡å‹** ä¸Šï¼ŒClinMPO è¾ƒ Base æå‡ **+3.17 pp**
- åœ¨ **4B æ¨¡å‹** ä¸Šï¼ŒClinMPO æå‡æœ€ä¸ºæ˜¾è‘—ï¼ˆ**+5.64 pp**ï¼‰ï¼Œæ˜¾ç¤ºå…¶åœ¨ä¸­ç­‰è§„æ¨¡æ¨¡å‹ä¸Šçš„é«˜æ•ˆæ€§

### ç»†ç²’åº¦é¢†åŸŸè¡¨ç°ï¼ˆä»£è¡¨æ€§ï¼‰
| ç±»åˆ« | ClinMPO æœ€ä½³è¡¨ç° | äººç±»åŸºå‡† | æå‡å¹…åº¦ |
|------|------------------|----------|----------|
| **Monitoring, Follow-up & Measurement-Based Care** | 42.86% | 30.38% | â†‘ +12.48 pp |
| **Comorbidity & Complexity Management** | 44.74% | 27.24% | â†‘ +17.50 pp |
| **Symptom Elicitation & MSE** | 42.31% | 26.91% | â†‘ +15.40 pp |
| **Impulse Control Disorders** | 50.00% | 20.90% | â†‘ +29.10 pp |
| **Factitious Disorders** | 57.14% | 25.74% | â†‘ +31.40 pp |

> ğŸ“ˆ ClinMPO åœ¨éœ€è¦ç»¼åˆåˆ¤æ–­ã€å¤šæ­¥å› æœæ¨ç†çš„é«˜é˜¶ä¸´åºŠä»»åŠ¡ä¸­ä¼˜åŠ¿å°¤ä¸ºæ˜æ˜¾

### æ¶ˆèå®éªŒä¸é”™è¯¯è½¬ç§»åˆ†æ
- **å‡€æ¨ç†å¢ç›Šï¼ˆNet FT-TFï¼‰**ï¼š
  - ClinMPO åœ¨ 4B æ¨¡å‹ä¸Šè¾¾åˆ° **+98**ï¼Œè¿œé«˜äº GRPOï¼ˆ+67ï¼‰å’Œ SFTï¼ˆè´Ÿå¢ç›Šï¼‰
- **é”™è¯¯ä¿®æ­£ç‡**ï¼ˆçº æ­£åŸé”™è¯¯é¢„æµ‹çš„æ¯”ä¾‹ï¼‰ï¼š
  - ClinMPOï¼š**22.6%**
  - GRPOï¼š21.4%
  - SFTï¼š13.9%
- è¡¨æ˜ ClinMPO èƒ½ä¸»åŠ¨ä¿®å¤é”™è¯¯æ¨ç†è·¯å¾„ï¼Œè€Œééšæœºæ³¢åŠ¨æˆ–è®°å¿†å¢å¼º

### åˆ†å¸ƒé²æ£’æ€§
- ClinMPO çš„æ€§èƒ½åˆ†å¸ƒæ›´é›†ä¸­ï¼Œ**IQR æ›´å°**ï¼Œä½å°¾éƒ¨ï¼ˆlow-performing categoriesï¼‰æ›´çŸ­
- SFT å’Œ GRPO å­˜åœ¨æç«¯å¤±è´¥æ¡ˆä¾‹ï¼ˆaccuracy æ¥è¿‘ 0ï¼‰ï¼Œè€Œ ClinMPO åœ¨ç»å¤§å¤šæ•°ç±»åˆ«ä¿æŒä¸­é«˜æ°´å¹³è¡¨ç°
- æ˜¾ç¤º ClinMPO å…·æœ‰æ›´å¼ºçš„è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›å’Œä¸´åºŠå®ç”¨æ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. âœ… **è½»å‚æ•° LLM å¯é€šè¿‡è®¤çŸ¥å¯¹é½å®ç°åª²ç¾ç”šè‡³è¶…è¶Šäººç±»åŒ»å­¦ç”Ÿçš„ä¸´åºŠæ¨ç†èƒ½åŠ›**  
   ClinMPO-tuned Qwen3-8B åœ¨å¤æ‚ç²¾ç¥ç—…å­¦æ¨ç†ä»»åŠ¡ä¸­ä»¥ **31.43%** å‡†ç¡®ç‡ç•¥è¶…äººç±»åŸºå‡†ï¼ˆ30.84%ï¼‰ã€‚

2. âœ… **æ¨ç†è´¨é‡æå‡æºäºç»“æ„æ€§ä¼˜åŒ–è€Œéç®€å•è®°å¿†æˆ–é£æ ¼æ¨¡ä»¿**  
   é”™è¯¯è½¬ç§»åˆ†æè¡¨æ˜ ClinMPO æ˜¾è‘—æå‡äº†â€œé”™â†’å¯¹â€çš„è½¬åŒ–ç‡ï¼Œè¯æ˜å…¶ä¿®å¤äº†çœŸå®çš„æ¨ç†ç¼ºé™·ã€‚

3. âœ… **åŸºäºåŒ»å­¦è¯æ®çš„å¥–åŠ±å»ºæ¨¡æ˜¯å®ç°å¯é å¯¹é½çš„å…³é”®**  
   ClinRM æˆåŠŸæ¨¡æ‹Ÿäº†ç²¾ç¥ç§‘åŒ»ç”Ÿçš„è¯„åˆ†é€»è¾‘ï¼Œä½¿æ¨¡å‹å­¦ä¼šéµå¾ªå¾ªè¯åŒ»å­¦åŸåˆ™è¿›è¡Œæ¨ç†ã€‚

4. âœ… **ClinMPO æ”¹å–„äº†æ¨¡å‹çš„é²æ£’æ€§å’Œä¸€è‡´æ€§**  
   å…¶æ€§èƒ½åˆ†å¸ƒæ›´ç¨³å®šï¼Œåœ¨å¤šæ ·ä¸”ä¸å¹³è¡¡çš„ä¸´åºŠå­é¢†åŸŸä¸­è¡¨ç°å‡ºæ›´ä½çš„å¤±è´¥é£é™©ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **è¯„ä¼°ä»åŸºäºé™æ€æ•°æ®é›†**ï¼šæœªåœ¨çœŸå®åŠ¨æ€ä¸´åºŠæµç¨‹ä¸­éªŒè¯ï¼Œå¯èƒ½æ— æ³•å®Œå…¨åæ˜ ç°å®ä¸–ç•Œå¤æ‚æ€§ã€‚
2. **å±€é™äºåè®­ç»ƒé˜¶æ®µï¼ˆpost-trainingï¼‰**ï¼šæ¨¡å‹ä»å—éåŒ»å­¦é¢„è®­ç»ƒæ•°æ®å¹²æ‰°ï¼Œæœªæ¥éœ€æ¢ç´¢ä»é¢„è®­ç»ƒé˜¶æ®µå³å¼€å§‹å¯¹é½ã€‚
3. **å…¬å¹³æ€§ä¸å¯¹æŠ—é²æ£’æ€§æœªå……åˆ†æ¢è®¨**ï¼šé•¿æœŸéƒ¨ç½²ä¸­å¯èƒ½å‡ºç°åè§æ”¾å¤§æˆ–å¯¹æŠ—æ”»å‡»é—®é¢˜ã€‚
4. **èµ„æºä¾èµ–**ï¼šæ„å»ºé«˜è´¨é‡ Evidence Dataset éœ€å¤§é‡ä¸“å®¶æŠ•å…¥ï¼Œéš¾ä»¥å¿«é€Ÿå¤åˆ¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å°†å¯¹é½æœºåˆ¶å‰ç½®è‡³é¢„è®­ç»ƒé˜¶æ®µ**ï¼Œå‡å°‘éåŒ»å­¦å…ˆéªŒå¹²æ‰°ã€‚
2. **ç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰**ï¼Œæå‡æ¨¡å‹å¯¹å¤–éƒ¨æœ€æ–°è¯æ®çš„è®¿é—®èƒ½åŠ›ã€‚
3. **å¼€å±•çœŸå®ä¸–ç•Œä¸´åºŠç¯å¢ƒä¸‹çš„å‰ç»æ€§éªŒè¯**ï¼Œæ¶µç›–å¤šå…ƒæ–‡åŒ–ä¸ç¤¾ä¼šç»æµèƒŒæ™¯æ‚£è€…ã€‚
4. **å»ºç«‹æŒç»­ç›‘æ§æœºåˆ¶**ï¼Œæ£€æµ‹æ¨¡å‹åœ¨éƒ¨ç½²åçš„æ€§èƒ½æ¼‚ç§»ä¸ä¼¦ç†é£é™©ã€‚
5. **å¼€æº Evidence Dataset ä¸è¯„ä¼°æ¡†æ¶**ï¼Œæ¨åŠ¨ç¤¾åŒºå…±åŒå»ºè®¾å¯ä¿¡èµ–çš„åŒ»ç–— AIã€‚

> ğŸ”š **æ€»ç»“**ï¼šæœ¬ç ”ç©¶è¯æ˜ï¼Œ**explicit cognitive alignment**ï¼ˆæ˜¾å¼è®¤çŸ¥å¯¹é½ï¼‰æ˜¯ä¸€æ¡å¯è¡Œä¸”é«˜æ•ˆçš„è·¯å¾„ï¼Œå¯ä½¿è½»é‡çº§ LLM åœ¨èµ„æºå—é™ç¯å¢ƒä¸­å®‰å…¨ã€å¯é åœ°è¾…åŠ©ç²¾ç¥ç§‘ä¸´åºŠå†³ç­–ï¼Œæ ‡å¿—ç€ä»â€œæ›´å¤§æ¨¡å‹â€å‘â€œæ›´èªæ˜è®­ç»ƒâ€çš„èŒƒå¼è½¬å˜ã€‚

</details>

---

### 13. [RelayGen: Intra-Generation Model Switching for Efficient Reasoning](https://arxiv.org/abs/2602.06454)

**Authors**: Jiwon Song, Yoongon Kim, Jae-Joon Kim  
**Category**: cs.CL  
**Published**: 2026-02-09  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.06454v1  

#### Abstract
Large reasoning models (LRMs) achieve strong performance on complex reasoning tasks by generating long, multi-step reasoning trajectories, but inference-time scaling incurs substantial deployment cost. A key challenge is that generation difficulty varies within a single output, whereas existing effi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šRelayGen: Intra-Generation Model Switching for Efficient Reasoning**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLarge Reasoning Models, LRMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å…¶é•¿åºåˆ—ç”Ÿæˆè¿‡ç¨‹å¸¦æ¥äº†é«˜æ˜‚çš„æ¨ç†æˆæœ¬ã€‚ä¼ ç»Ÿæ•ˆç‡ä¼˜åŒ–æ–¹æ³•å­˜åœ¨ä»¥ä¸‹ä¸è¶³ï¼š
- **Input-level routing**ï¼šå¯¹æ•´ä¸ªè¾“å‡ºä½¿ç”¨å•ä¸€æ¨¡å‹ï¼Œæ— æ³•åˆ©ç”¨ç”Ÿæˆè¿‡ç¨‹ä¸­**å†…éƒ¨éš¾åº¦å˜åŒ–**ï¼ˆintra-generation difficulty variationï¼‰ã€‚
- **Token-level routing**ï¼šè™½èƒ½ç»†ç²’åº¦æ§åˆ¶ï¼Œä½†ä¾èµ–è®­ç»ƒå¥½çš„è·¯ç”±æ¨¡å‹ï¼ˆlearned routerï¼‰ï¼Œå¢åŠ ç³»ç»Ÿå¤æ‚æ€§å’Œéƒ¨ç½²æˆæœ¬ã€‚
- **Step-level switching**ï¼šåŸºäºå¯å‘å¼è§„åˆ™åˆ‡æ¢ï¼Œç¼ºä¹å¯¹æ¨¡å‹ç‰¹å®šè¡Œä¸ºçš„å®è¯åˆ†æï¼Œå¯èƒ½å¯¼è‡´ç²¾åº¦ä¸‹é™ã€‚

å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¸ç‰ºç‰²å‡†ç¡®ç‡çš„å‰æä¸‹ï¼Œé«˜æ•ˆåˆ©ç”¨æ¨¡å‹å®¹é‡ï¼Œæˆä¸ºå…³é”®æŒ‘æˆ˜ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æå‡º **RelayGen** â€”â€” ä¸€ç§**æ— éœ€è®­ç»ƒã€åŸºäºæ®µçº§ï¼ˆsegment-levelï¼‰è¿è¡Œæ—¶æ¨¡å‹åˆ‡æ¢**çš„æ¡†æ¶ï¼Œæ ¸å¿ƒæ€æƒ³å¦‚ä¸‹ï¼š
- **è§‚å¯Ÿåˆ°**ï¼šåœ¨é•¿æ¨ç†è½¨è¿¹ä¸­ï¼Œä¸åŒé˜¶æ®µçš„ç”Ÿæˆä¸ç¡®å®šæ€§ï¼ˆuncertaintyï¼‰æ˜¾è‘—ä¸åŒã€‚ä¾‹å¦‚ï¼Œåæ€ï¼ˆreflectionï¼‰ã€è½¬è¿°ï¼ˆparaphrasingï¼‰å’Œåæ¨ç†å»¶ç»­ï¼ˆpost-reasoning continuationï¼‰ç­‰ç‰‡æ®µé€šå¸¸å…·æœ‰æ›´é«˜çš„é¢„æµ‹ç½®ä¿¡åº¦ï¼ˆå³æ›´ä½éš¾åº¦ï¼‰ã€‚
- **æ–¹æ³•è®¾è®¡**ï¼š
  - åˆ©ç”¨**token probability margin**ï¼ˆtop-1 ä¸ top-2 token æ¦‚ç‡å·®ï¼‰ä½œä¸ºéš¾åº¦ä»£ç†æŒ‡æ ‡ã€‚
  - é€šè¿‡ç¦»çº¿åˆ†æè¯†åˆ«å‡ºå¯é çš„**switch cues**ï¼ˆå¦‚ "therefore", "thus", "so" ç­‰ discourse-level cuesï¼‰ï¼Œè¿™äº›è¯å‡ºç°åå¾€å¾€ä¼´éšä½ä¸ç¡®å®šæ€§å»¶ç»­ã€‚
  - åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œå½“æ£€æµ‹åˆ° switch cue æˆ–è¿›å…¥ answer stageï¼ˆ`</think>` åï¼‰æ—¶ï¼Œå°†åç»­ç”Ÿæˆ**åŠ¨æ€å¸è½½ï¼ˆoffloadï¼‰ç»™å°æ¨¡å‹**ï¼Œé«˜éš¾åº¦éƒ¨åˆ†ä»ç”±å¤§æ¨¡å‹å¤„ç†ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç‰¹æ€§ | RelayGen | Token-level Routing (e.g., R2R) | Step-level Switching (e.g., Speculative Thinking) |
|------|----------|-------------------------------|-----------------------------------------------|
| æ˜¯å¦éœ€è¦è®­ç»ƒ | âŒï¼ˆtraining-freeï¼‰ | âœ…ï¼ˆéœ€è®­ç»ƒ routerï¼‰ | âŒ |
| è·¯ç”±ç²’åº¦ | Segment-level | Token-level | Step-level |
| ç³»ç»Ÿå¤æ‚æ€§ | æä½ï¼ˆä»… token åŒ¹é…ï¼‰ | é«˜ï¼ˆæ¯æ­¥è°ƒç”¨ routerï¼‰ | ä¸­ï¼ˆä¾èµ–é¢„å®šä¹‰åˆ†éš”ç¬¦ï¼‰ |
| å¯ç»„åˆæ€§ | âœ… ä¸ Speculative Decoding å…¼å®¹ | âŒ å†²çªï¼ˆç ´å draft-verify æµç¨‹ï¼‰ | âš ï¸ æœ‰é™å…¼å®¹ |
| å‡†ç¡®ç‡ä¿æŒ | é«˜ï¼ˆæ¥è¿‘å¤§æ¨¡å‹ï¼‰ | è¾ƒé«˜ | æ˜¾è‘—ä¸‹é™ |

> âœ… **æ ¸å¿ƒåˆ›æ–°**ï¼šé¦–æ¬¡è¯æ˜**ç²—ç²’åº¦ã€æ— ç›‘ç£çš„ segment-level æ§åˆ¶è¶³ä»¥æ•æ‰é•¿æ¨ç†ä¸­çš„éš¾åº¦å˜åŒ–**ï¼ŒæŒ‘æˆ˜äº†â€œå¿…é¡»ä¾èµ–ç²¾ç»†å­¦ä¹ è·¯ç”±â€çš„ä¸»æµèŒƒå¼ã€‚

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **AIME 2025**ï¼šç¾å›½æ•°å­¦é‚€è¯·èµ›é£æ ¼é¢˜ç›®ï¼Œè€ƒå¯Ÿå¤æ‚æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚
- **MATH500**ï¼šLightman et al. (2023) æä¾›çš„æ•°å­¦æ¨ç†åŸºå‡†ï¼Œæ¶µç›–å¤šä¸ªéš¾åº¦çº§åˆ«ã€‚
- **GPQA-Diamond**ï¼šç ”ç©¶ç”Ÿçº§åˆ«çš„ç§‘å­¦é—®ç­”æ•°æ®é›†ï¼Œæµ‹è¯•è·¨é¢†åŸŸæ·±åº¦æ¨ç†ã€‚
- **AMC 2023**ï¼šç”¨äºç¦»çº¿æ ¡å‡†çš„ calibration setï¼Œå…± 40 é¢˜ï¼Œç”Ÿæˆ 160 æ¡ trace ä»¥é€‰æ‹© switch cuesã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **æ¨¡å‹å¯¹**ï¼š
  - `Qwen3-32B / Qwen3-1.7B`
  - `R1-Distill-Qwen-32B / R1-Distill-Qwen-1.5B`
- **ç”Ÿæˆå‚æ•°**ï¼š
  - max length: 32,768 tokens
  - temperature: 0.6, top_p: 0.95, top_k: 20ï¼ˆQwen3ï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Pass@1**ï¼šå››æ¬¡é‡‡æ ·å–ä¸€æ¬¡æ­£ç¡®çš„æ¯”ä¾‹ã€‚
  - **Speedup (Ã—)**ï¼šç›¸å¯¹äºçº¯å¤§æ¨¡å‹ç”Ÿæˆçš„ç«¯åˆ°ç«¯å»¶è¿ŸåŠ é€Ÿæ¯”ã€‚
  - **Large-model utilization (%)**ï¼šå¤§æ¨¡å‹ç”Ÿæˆçš„ token å æ¯”ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | ç±»å‹ | æè¿° |
|------|------|------|
| **Small/Large Model Only** | ä¸Šä¸‹ç•Œ | åˆ†åˆ«ä»£è¡¨æœ€ä½ä¸æœ€é«˜æ€§èƒ½åŸºå‡† |
| **Speculative Thinking** | Step-level switching | åŸºäºé¢„å®šä¹‰è¯æ±‡è¿›è¡Œæ­¥éª¤çº§åˆ‡æ¢ |
| **R2R** | Token-level routing | ä½¿ç”¨è®­ç»ƒå¥½çš„ router è¿›è¡Œé€ token è·¯ç”±å†³ç­– |

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **å‡†ç¡®æ€§è¡¨ç°ï¼ˆPass@1ï¼‰**
*è¡¨ 2ï¼šRelayGen ä¸å…¶ä»–æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†ä¸Šçš„ Pass@1 å¯¹æ¯”*

| Method | MATH500 | AIME 2025 | GPQA-Diamond |
|--------|---------|-----------|-------------|
| **Large Model** | 95.27 | 70.00 | 64.58 |
| **Small Model** | 88.60 | 31.67 | 37.33 |
| **Speculative Thinking** | 91.35 | 40.83 | 41.29 |
| **R2R** | 94.30 | 62.50 | 61.62 |
| **RelayGen** | **94.80** | **68.33** | **63.64** |

> ğŸ” **ç»“è®º**ï¼šRelayGen åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡æ˜¾è‘—ä¼˜äº Speculative Thinkingï¼Œå¹¶**æ¥è¿‘ç”šè‡³è¶…è¶Š R2R**ï¼Œå°¤å…¶åœ¨ AIME 2025 ä¸Šé¢†å…ˆæ˜æ˜¾ã€‚

#### âœ… **æ¨ç†æ•ˆç‡ä¸åŠ é€Ÿæ•ˆæœ**
*è¡¨ 3ï¼šä¸åŒæ–¹æ³•çš„é€Ÿåº¦æå‡ä¸å¤§æ¨¡å‹åˆ©ç”¨ç‡*

| Method | Speedup (Ã—) | Large-model Utilization (%) |
|--------|-------------|-----------------------------|
| **Eagle-3** | 1.79Â±0.42 | 100.00 |
| **Spec. Think.** | 2.21Â±0.95 | 25.54 |
| **R2R** | 1.30Â±0.18 | 19.27 |
| **RelayGen** | 1.29Â±0.20 | 69.80 |
| **RelayGen + Eagle-3** | **2.20Â±0.21** | 69.49 |

> ğŸš€ **å…³é”®ç»“æœ**ï¼š
- RelayGen å•ç‹¬ä½¿ç”¨å³å¯å®ç° **1.29Ã— åŠ é€Ÿ**ï¼Œä¸”ä¿ç•™äº†è¿‘ 70% çš„å¤§æ¨¡å‹ token ç”Ÿæˆï¼Œç¡®ä¿ç¨³å®šæ€§ã€‚
- **ä¸ Speculative Decodingï¼ˆEagle-3ï¼‰ç»“åˆåï¼Œè¾¾åˆ°æœ€é«˜ 2.2Ã— ç«¯åˆ°ç«¯åŠ é€Ÿ**ï¼ŒåŒæ—¶å‡†ç¡®ç‡æŸå¤± <2%ã€‚
- ç›¸æ¯” R2Rï¼Œå°½ç®¡å¤§æ¨¡å‹åˆ©ç”¨ç‡æ›´é«˜ï¼Œä½†é€Ÿåº¦ç›¸å½“â€”â€”è¯´æ˜**segment-level åˆ‡æ¢å¼€é”€æä½**ã€‚

### **æ¶ˆèå®éªŒç»“æœ**

#### ğŸ” **Switch Cue é€‰æ‹©çš„å½±å“**
*è¡¨ 4ï¼šä½¿ç”¨å…¨éƒ¨å€™é€‰ cue vs ç»è¿‡ç­›é€‰çš„ cue çš„ Pass@1 å¯¹æ¯”*

| Cue Usage | AIME 2025 | GPQA-Diamond |
|----------|-----------|--------------|
| All candidates | 60.00 | 57.32 |
| **Selected (RelayGen)** | **68.33** | **63.64** |

> ğŸ’¡ è¡¨æ˜ç›²ç›®ä½¿ç”¨æ‰€æœ‰ discourse cues ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œ**ç»éªŒé©±åŠ¨çš„ cue é€‰æ‹©è‡³å…³é‡è¦**ã€‚

#### ğŸ” **æ ¡å‡†é›†å¤§å°æ•æ„Ÿæ€§**
*è¡¨ 5ï¼šä¸åŒ calibration sample æ•°é‡ä¸‹çš„æ€§èƒ½*

| #Calibration samples | AIME 2025 | GPQA-Diamond |
|-----------------------|-----------|--------------|
| 10 | 70.00 | 61.87 |
| 40 | 71.67 | 61.87 |
| 160 | 68.33 | 63.64 |

> âœ… RelayGen å¯¹ calibration æ•°æ®é‡ä¸æ•æ„Ÿï¼Œ**å³ä½¿ä»…ç”¨ 10 ä¸ªæ ·æœ¬ä¹Ÿèƒ½å–å¾—è‰¯å¥½æ•ˆæœ**ï¼Œé€‚åˆä½èµ„æºéƒ¨ç½²ã€‚

#### ğŸ” **å¼‚æ„æ¨¡å‹å¯¹é²æ£’æ€§**
- åœ¨ `Qwen3-32B / R1-Distill-1.5B` å’Œ `R1-Distill-32B / Qwen3-1.7B` ä¸Šæµ‹è¯•ï¼Œæ€§èƒ½ä¸‹é™ä¸»è¦æºäºå°æ¨¡å‹èƒ½åŠ›ä¸è¶³ï¼Œè€Œéæ¶æ„ä¸å…¼å®¹ã€‚
- ç»“è®ºï¼šåªè¦å°æ¨¡å‹å…·å¤‡åŸºæœ¬æ¨ç†èƒ½åŠ›ï¼ŒRelayGen å³å¯æœ‰æ•ˆå·¥ä½œã€‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **é•¿æ¨ç†ç”Ÿæˆå…·æœ‰å†…åœ¨éš¾åº¦å¼‚è´¨æ€§**ï¼šå¹¶éæ‰€æœ‰ token éƒ½éœ€è¦å¤§æ¨¡å‹å¤„ç†ï¼Œå°¤å…¶æ˜¯ç­”æ¡ˆé˜¶æ®µå’ŒæŸäº›ä½ä¸ç¡®å®šæ€§å»¶ç»­æ®µã€‚
2. **segment-level æ§åˆ¶è¶³å¤Ÿæœ‰æ•ˆ**ï¼šæ— éœ€ token-level å­¦ä¹ è·¯ç”±ï¼Œ**åŸºäºæ¦‚ç‡ margin åˆ†æçš„ coarse-grained åˆ‡æ¢å³å¯æ•è·éš¾åº¦è½¬ç§»**ã€‚
3. **RelayGen å®ç°é«˜æ•ˆ-å‡†ç¡®å¹³è¡¡**ï¼šåœ¨å‡ ä¹ä¸å¤±ç²¾åº¦çš„æƒ…å†µä¸‹ï¼Œå®ç°é«˜è¾¾ **2.2Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿ**ï¼Œä¸”å®Œå…¨å…¼å®¹ Speculative Decodingã€‚
4. **æ— éœ€è®­ç»ƒã€æ˜“äºéƒ¨ç½²**ï¼šæ•´ä¸ªæœºåˆ¶åŸºäºç¦»çº¿åˆ†æ + è¿è¡Œæ—¶ token åŒ¹é…ï¼Œ**é›¶é¢å¤–è®­ç»ƒæˆæœ¬ï¼Œç³»ç»Ÿé›†æˆç®€å•**ã€‚

### **å±€é™æ€§**
- **ä¾èµ–æ˜¾å¼ç»“æ„è¾“å‡º**ï¼šé€‚ç”¨äºåƒ `<think>...</think>` è¿™ç±»æ˜ç¡®åŒºåˆ† reasoning ä¸ answer stage çš„ç°ä»£ LRMã€‚å¯¹äºæ— ç»“æ„è¾“å‡ºçš„ä»»åŠ¡é€‚ç”¨æ€§å—é™ã€‚
- **è¦æ±‚ä¸­å°æ¨¡å‹æœ‰ä¸€å®šèƒ½åŠ›**ï¼šè‹¥å°æ¨¡å‹è¿ä½éš¾åº¦æ®µéƒ½æ— æ³•ç¨³å®šç”Ÿæˆï¼Œåˆ™ offloading ä¼šå¼•å…¥é”™è¯¯ã€‚
- **è¯­è¨€é™åˆ¶**ï¼šå½“å‰å®éªŒé›†ä¸­äºè‹±æ–‡ï¼Œå¤šè¯­è¨€æ‰©å±•å°šæœªéªŒè¯ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢å¤šè¯­è¨€åœºæ™¯ä¸‹çš„é€šç”¨ switch cue è®¾è®¡ã€‚
- å°†ç±»ä¼¼æ€æƒ³åº”ç”¨äºéæ¨ç†ç±»é•¿æ–‡æœ¬ç”Ÿæˆï¼ˆå¦‚æ‘˜è¦ã€æ•…äº‹ç”Ÿæˆï¼‰ã€‚
- åŠ¨æ€æ›´æ–° switch cue é›†åˆä»¥é€‚åº”æ–°ä»»åŠ¡åˆ†å¸ƒï¼ˆåœ¨çº¿è‡ªé€‚åº”ï¼‰ã€‚
- æ‰©å±•è‡³æ›´å¤šæ¨¡å‹å®¶æ—ä¸ç¡¬ä»¶å¹³å°ï¼Œæ¨åŠ¨å·¥ä¸šçº§è½åœ°ã€‚

---

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼š  
> RelayGen æ˜¯ä¸€ä¸ªç®€æ´è€Œå¼ºå¤§çš„æ¨ç†åŠ é€Ÿæ¡†æ¶ï¼Œå®ƒé€šè¿‡**å®è¯åˆ†ææ›¿ä»£å¤æ‚å»ºæ¨¡**ï¼Œé‡æ–°æ€è€ƒäº†â€œä½•æ—¶è¯¥ç”¨å“ªä¸ªæ¨¡å‹â€çš„é—®é¢˜ã€‚å…¶**training-freeã€composableã€high-performance** çš„ç‰¹æ€§ï¼Œä½¿å…¶æå…·å®ç”¨ä»·å€¼ï¼Œä¸ºé«˜æ•ˆæ¨ç†æä¾›äº†æ–°çš„è®¾è®¡èŒƒå¼ã€‚

</details>

---

### 14. [Jackpot: Optimal Budgeted Rejection Sampling for Extreme Actor-Policy Mismatch Reinforcement Learning](https://arxiv.org/abs/2602.06107)

**Authors**: Zhuoming Chen, Hongyi Liu, Yang Zhou, Haizhong Zheng, Beidi Chen  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.06107v1  

#### Abstract
Reinforcement learning (RL) for large language models (LLMs) remains expensive, particularly because the rollout is expensive. Decoupling rollout generation from policy optimization (e.g., leveraging a more efficient model to rollout) could enable substantial efficiency gains, yet doing so introduce...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**Jackpot: Optimal Budgeted Rejection Sampling for Extreme Actor-Policy Mismatch Reinforcement Learning**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒä¸­ï¼Œ**rollout é˜¶æ®µæˆæœ¬æé«˜**ï¼Œé€šå¸¸å æ€»è®­ç»ƒå¼€é”€çš„ 80% ä»¥ä¸Šã€‚è™½ç„¶å·²æœ‰ç ”ç©¶å°è¯•é€šè¿‡å¼‚æ­¥è®­ç»ƒã€é‡åŒ–ç­‰æ‰‹æ®µä¼˜åŒ– rollout æ•ˆç‡ï¼Œä½†è¿™äº›æ–¹æ³•ä»è¦æ±‚ç›®æ ‡ç­–ç•¥æ¨¡å‹ï¼ˆpolicy modelï¼‰å‚ä¸ç”Ÿæˆè½¨è¿¹ï¼Œé™åˆ¶äº†çµæ´»æ€§ã€‚

æœ¬æ–‡èšç„¦ä¸€ä¸ªæ›´æ¿€è¿›çš„é—®é¢˜ï¼š  
> **æ˜¯å¦å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå®Œå…¨ä¸åŒçš„ã€æ›´å°ä¸”é«˜æ•ˆçš„æ¨¡å‹ï¼ˆå¦‚ Qwen3-1.7Bï¼‰æ¥æ‰§è¡Œ rolloutï¼Œè€Œç”¨å¦ä¸€ä¸ªæ›´å¤§æ›´å¼ºçš„æ¨¡å‹ï¼ˆå¦‚ Qwen3-8Bï¼‰è¿›è¡Œç­–ç•¥æ›´æ–°ï¼Ÿ**

è¿™ç§â€œè§£è€¦â€æ–¹å¼è™½èƒ½æå¤§é™ä½ rollout æˆæœ¬ï¼Œä½†ä¼šå¼•å…¥ä¸¥é‡çš„ **actor-policy åˆ†å¸ƒä¸åŒ¹é…ï¼ˆdistribution mismatchï¼‰**ï¼Œå¯¼è‡´è®­ç»ƒä¸ç¨³å®šç”šè‡³å´©æºƒã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šJACKPOT æ¡†æ¶

ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡º **JACKPOT**ï¼Œå…¶æ ¸å¿ƒæ˜¯åŸºäº **Optimal Budget Rejection Sampling (OBRS)** çš„æ¦‚ç‡åˆ†å¸ƒå¯¹é½æœºåˆ¶ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰å¤§åˆ›æ–°ç»„ä»¶ï¼š

#### ï¼ˆ1ï¼‰**Optimal Budget Rejection Sampling (OBRS)**
- ä¸åŒäºä¼ ç»Ÿæ‹’ç»é‡‡æ ·ï¼ˆRejection Samplingï¼‰ï¼ŒOBRS å¼•å…¥äº†ä¸€ä¸ªå¯æ§çš„â€œæ‹’ç»é¢„ç®—â€å‚æ•° `Î»`ï¼Œå…è®¸åœ¨**é«˜ç»´ç¦»æ•£ç©ºé—´**ï¼ˆå¦‚ LLM çš„ >100k è¯è¡¨ï¼‰ä¸­å®ç°é«˜æ•ˆé‡‡æ ·ã€‚
- å®ƒä¸è¦æ±‚ rollout åˆ†å¸ƒ `pinf` å®Œå…¨ç­‰äºç›®æ ‡ç­–ç•¥åˆ†å¸ƒ `ptarget`ï¼Œè€Œæ˜¯ä¿è¯ï¼š**å¯¹äºä»»æ„é¢„ç®—ï¼Œè°ƒæ•´åçš„åˆ†å¸ƒéƒ½ä¸¥æ ¼æ›´æ¥è¿‘ç›®æ ‡åˆ†å¸ƒ**ã€‚
- æ¥å—æ¦‚ç‡å®šä¹‰ä¸ºï¼š
  $$
  a(x) = \min\left(1, \frac{p_{\text{target}}(x)}{\lambda \cdot p_{\text{inf}}(x)}\right)
  $$
  è¢«æ‹’ç»çš„ token åœ¨åå‘ä¼ æ’­ä¸­è¢« mask æ‰ã€‚

#### ï¼ˆ2ï¼‰**ç»Ÿä¸€è®­ç»ƒç›®æ ‡ï¼ˆUnified Training Objectiveï¼‰**
JACKPOT åŒæ—¶ä¼˜åŒ–ä¸‰ä¸ªç›®æ ‡ï¼š
- **OBRS è°ƒæ•´çš„ PPO æŸå¤±**ï¼šç”¨äº policy modelï¼Œä½¿ç”¨é‡åŠ æƒåçš„ token è¿›è¡Œæ¢¯åº¦æ›´æ–°ã€‚
- **æ ‡å‡† PPO æŸå¤±**ï¼šç”¨äº rollout model è‡ªèº«ä¼˜åŒ–ã€‚
- **on-policy distillation æŸå¤±**ï¼šé€šè¿‡ KL æ•£åº¦æ‹‰è¿‘ rollout model ä¸æœ€æ–° policy model çš„è¾“å‡ºåˆ†å¸ƒï¼Œé˜²æ­¢å·®è·éšè®­ç»ƒæ‰©å¤§ã€‚

#### ï¼ˆ3ï¼‰**é«˜æ•ˆçš„ç³»ç»Ÿå®ç°**
- **Top-k æ¦‚ç‡ä¼°è®¡**ï¼šé¿å…è®¡ç®—æ•´ä¸ªè¯è¡¨çš„å½’ä¸€åŒ–å¸¸æ•° `Z`ï¼Œä»…åœ¨ `top-k(pinf) âˆª top-k(pnew)` ä¸Šä¼°ç®—ã€‚
- **Batch-level åå·®æ ¡æ­£**ï¼šåˆ©ç”¨å®é™…æ¥å—ç‡ä½œä¸ºæ— åä¼°è®¡ï¼Œä¿®æ­£ Top-k å¸¦æ¥çš„ä½ä¼°åå·®ï¼Œæå‡ç¨³å®šæ€§ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹æ³• | ç¼ºé™· | JACKPOT æ”¹è¿› |
|------|------|-------------|
| **Truncated Importance Sampling (TIS)** | ä»…äº‹åä¿®æ­£ï¼Œæ— æ³•ç¼“è§£æç«¯åˆ†å¸ƒå·®å¼‚ï¼›KL æ•£åº¦å‰§çƒˆä¸Šå‡å¯¼è‡´è®­ç»ƒå´©æºƒ | OBRS ä¸»åŠ¨ç¼©å°åˆ†å¸ƒå·®è·ï¼ŒTIS å¯å åŠ åœ¨å…¶ä¹‹ä¸Šå½¢æˆäº’è¡¥ |
| **Quantization / Sparsity** | åˆ†å¸ƒå·®å¼‚è¾ƒå°ï¼Œå¯ç”¨ TIS æ§åˆ¶ | JACKPOT é€‚ç”¨äºè·¨æ¨¡å‹å®¶æ—ã€å¤§å°å·®å¼‚å·¨å¤§çš„æç«¯ mismatch åœºæ™¯ |
| **Speculative Decoding** | éœ€è¦é‡æ–°ç”Ÿæˆè¢«æ‹’ token åç»­åºåˆ—ï¼Œå¼€é”€å¤§ | JACKPOT ä»… mask å•ä¸ª tokenï¼Œæ— éœ€ resampling |

> âœ… **JACKPOT æ˜¯é¦–ä¸ªèƒ½åœ¨æç«¯ actor-policy mismatch ä¸‹å®ç°ç¨³å®šè®­ç»ƒçš„æ–¹æ³•**ï¼Œå¹¶æ”¯æŒ rollout ä¸ policy å®Œå…¨è§£è€¦ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **MATH-500**ï¼š500 é“é«˜ä¸­æ•°å­¦ç«èµ›é¢˜ã€‚
- **DeepScaleR**ï¼šåŒ…å«çº¦ 40k é“é«˜éš¾åº¦æ•°å­¦ç«èµ›é¢˜ï¼ˆå¦‚ AIMEã€AMCï¼‰çš„æ•°æ®é›†ï¼Œç”¨äºä¸»å®éªŒã€‚
- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜åŸºå‡†ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹ç»„åˆ**ï¼ˆactor â†’ policyï¼‰ï¼š
  - Qwen2.5-1.5B â†’ Qwen2.5-3B
  - Qwen3-1.7B â†’ Qwen3-4B
  - Qwen3-1.7B â†’ Qwen3-8Bï¼ˆæœ€æç«¯ caseï¼‰
- **è®­ç»ƒç®—æ³•**ï¼šGRPOï¼ˆä¸€ç§ memory-efficient RLHF æ–¹æ³•ï¼‰
- **Batch è®¾ç½®**ï¼šrollout batch size æœ€é«˜è¾¾ 4096ï¼ˆ128Ã— training batchï¼‰ï¼Œæ¨¡æ‹Ÿä¸¥é‡ staleness
- **æœ€å¤§ç”Ÿæˆé•¿åº¦**ï¼š8192 tokens
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - `Mean@k`, `Pass@k`ï¼šk æ¬¡é‡‡æ ·ä¸­çš„å¹³å‡å¾—åˆ†æˆ–æœ€é«˜å¾—åˆ†
  - KL æ•£åº¦å˜åŒ–è¶‹åŠ¿
  - è®­ç»ƒç¨³å®šæ€§ï¼ˆæ˜¯å¦å´©æºƒï¼‰

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **On-policy**ï¼šç†æƒ³æƒ…å†µï¼Œrollout ä¸ policy æ¨¡å‹ä¸€è‡´
- **Off-policy (No Alignment)**ï¼šç›´æ¥ä½¿ç”¨å°æ¨¡å‹ rolloutï¼Œæ— ä»»ä½•ä¿®æ­£
- **TIS + Reverse KL**ï¼šä¸»æµ importance sampling æ–¹æ³• + KL æ­£åˆ™
- **Vanilla PPO / No Clip**ï¼šç§»é™¤ clip ä»¥æµ‹è¯•æ”¶æ•›é€Ÿåº¦æé™

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ–¹æ³• | Qwen3-1.7B â†’ Qwen3-8B (AIME25 Mean@4) | Qwen3-1.7B â†’ Qwen3-4B (AIME25 Mean@4) |
|------|----------------------------------------|----------------------------------------|
| Q3-8B On-policy | 0.1687 | â€” |
| TIS + Reverse KL | 0.1541 | 0.2083 |
| **JACKPOT (Ours)** | **0.1916** (+13.5%) | **0.2083** (= on-policy level) |

> âœ… åœ¨ Qwen3-1.7B â†’ Qwen3-8B æç«¯è®¾ç½®ä¸‹ï¼ŒJACKPOT è¾¾åˆ°ç”šè‡³è¶…è¿‡ on-policy åŸºçº¿æ°´å¹³ã€‚

---

### ğŸ“ˆ ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ

- **è®­ç»ƒç¨³å®šæ€§æ˜¾è‘—æå‡**ï¼š
  - æ— å¯¹é½æ–¹æ³•åœ¨å‡ åæ­¥å†…å´©æºƒã€‚
  - TIS + KL åˆæœŸå°šå¯ï¼Œä½†åæœŸ KL æ•£åº¦çˆ†ç‚¸ï¼ˆè§ Figure 2cï¼‰ã€‚
  - **JACKPOT ç»´æŒä½ KL æ•£åº¦ï¼Œè®­ç»ƒç¨³å®šè‡³ 300 æ­¥ä»¥ä¸Š**ã€‚

- **æ€§èƒ½é€¼è¿‘ on-policy è®­ç»ƒ**ï¼š
  - åœ¨å¤šä¸ªä»»åŠ¡ä¸Šï¼ˆGSM8K, MATH, AMC, AIMEï¼‰ï¼ŒJACKPOT æ€§èƒ½ä¸ on-policy åŸºçº¿ç›¸å½“ï¼Œè¿œè¶… off-policy baseline å’Œ TIS æ–¹æ³•ã€‚

- **æ¶ˆèå®éªŒéªŒè¯å„æ¨¡å—æœ‰æ•ˆæ€§**ï¼ˆTable 3 & Figure 5ï¼‰

| æ–¹æ³• | æ˜¯å¦ç¨³å®š | æ”¶æ•›é€Ÿåº¦ | æœ€ç»ˆæ€§èƒ½ |
|------|----------|-----------|------------|
| Off-policy (vanilla) | âœ… ç¨³å®š | âŒ ææ…¢ | ä¸­ç­‰ |
| No Clip (aggressive update) | âŒ å´©æºƒ | â€” | â€” |
| **JACKPOT (no clip)** | âœ… ç¨³å®š | âœ… å¿«é€Ÿ | âœ”ï¸ é«˜ |

> ğŸ’¡ **JACKPOT å…è®¸ç§»é™¤ PPO clip æœºåˆ¶è€Œä¸å´©æºƒ**ï¼Œä»è€ŒåŠ é€Ÿæ”¶æ•›ï¼Œè¿™æ˜¯ä¼ ç»Ÿæ–¹æ³•æ— æ³•åšåˆ°çš„ã€‚

---

### ğŸ” æ¶ˆèå®éªŒå…³é”®å‘ç°

| ç»„ä»¶ | å½±å“ |
|------|------|
| **OBRS + Reweighting** | æ˜¾è‘—é™ä½ KL æ•£åº¦ï¼Œæå‡ç¨³å®šæ€§ |
| **Reverse KL Distillation** | é˜²æ­¢ rollout model è½åå¤ªå¤š |
| **Top-k â‰ˆ 20** | å·²è¶³å¤Ÿç²¾ç¡®ï¼Œå¢å¤§ k æ— æ˜æ˜¾æ”¶ç›Šï¼ˆTable 10ï¼‰ |
| **Î» = 1.0** | é»˜è®¤æœ€ä¼˜å€¼ï¼Œè¿‡é«˜ä¼šå¯¼è‡´è¿‡åº¦æ‹’ç» |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **æç«¯ actor-policy mismatch å¯è¢«æœ‰æ•ˆç¼“è§£**ï¼š
   - ä½¿ç”¨æ›´å°æ¨¡å‹è¿›è¡Œ rollout å¹¶éä¸å¯è¡Œï¼Œå…³é”®æ˜¯**ä¸»åŠ¨å¯¹é½åˆ†å¸ƒ**ï¼Œè€Œéä¾èµ–äº‹åä¿®æ­£ï¼ˆå¦‚ TISï¼‰ã€‚

2. **OBRS æ˜¯ç†è®ºæœ€ä¼˜çš„æ‹’ç»ç­–ç•¥**ï¼š
   - åœ¨ç»™å®šæ¥å—é¢„ç®—ä¸‹ï¼ŒOBRS èƒ½äº§ç”Ÿè·ç¦»ç›®æ ‡åˆ†å¸ƒæœ€è¿‘çš„ post-rejection åˆ†å¸ƒï¼ˆTheorem 3.4ï¼‰ã€‚

3. **JACKPOT å®ç°äº† rollout ä¸ policy çš„å®è´¨æ€§è§£è€¦**ï¼š
   - æ”¯æŒè·¨è§„æ¨¡ã€è·¨æ¶æ„çš„æ¨¡å‹ç»„åˆï¼Œä¸ºå¤§è§„æ¨¡ RLHF æä¾›çµæ´»é«˜æ•ˆçš„è®­ç»ƒèŒƒå¼ã€‚

4. **ç³»ç»Ÿçº§ä¼˜åŒ–è‡³å…³é‡è¦**ï¼š
   - Top-k + batch-level bias correction ä½¿ OBRS å¯æ‰©å±•åˆ°çœŸå® LLM è®­ç»ƒåœºæ™¯ã€‚

---

### âš ï¸ å±€é™æ€§

1. **é•¿æœŸè®­ç»ƒä»å¯èƒ½å´©æºƒ**ï¼š
   - å°½ç®¡ JACKPOT å¤§å¹…å»¶é•¿ç¨³å®šæœŸï¼ˆè¾¾ 300 æ­¥ï¼‰ï¼Œä½†åœ¨æ›´é•¿è®­ç»ƒå‘¨æœŸåä»å¯èƒ½å‡ºç°å‘æ•£ï¼ˆè§ Figure 6ï¼‰ã€‚

2. **æœªéªŒè¯äºè¶…å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚ 32B+ï¼‰**ï¼š
   - å½“å‰å®éªŒé›†ä¸­åœ¨ 1.5Bâ€“8B èŒƒå›´ï¼Œæ›´å¤§æ¨¡å‹çš„é€‚é…æ€§å’Œæ•ˆç‡æœ‰å¾…éªŒè¯ã€‚

3. **å¯¹æå° Î» æˆ–æç«¯ mismatch åœºæ™¯ä»æœ‰æŒ‘æˆ˜**ï¼š
   - è‹¥ rollout æ¨¡å‹èƒ½åŠ›è¿‡å¼±ï¼Œå³ä½¿ OBRS ä¹Ÿéš¾ä»¥æå–æœ‰æ•ˆä¿¡å·ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **åŠ¨æ€è°ƒèŠ‚æœºåˆ¶**ï¼š
   - å¼•å…¥é—­ç¯æ§åˆ¶ï¼Œæ ¹æ®å®æ—¶ KL æ•£åº¦åŠ¨æ€è°ƒæ•´ distillation loss æƒé‡æˆ– `Î»` å‚æ•°ã€‚

2. **å¤šé˜¶æ®µ rollout ç­–ç•¥**ï¼š
   - åˆæœŸç”¨å°æ¨¡å‹å¿«é€Ÿæ¢ç´¢ï¼ŒåæœŸåˆ‡æ¢è‡³ä¸­ç­‰æ¨¡å‹ç²¾ç»† rolloutã€‚

3. **ç»“åˆ test-time compute æ‰©å±•æ€§**ï¼š
   - åˆ©ç”¨å°æ¨¡å‹å¤šæ¬¡å°è¯•ï¼ˆmultiple attemptsï¼‰ç”Ÿæˆé«˜è´¨é‡å€™é€‰è·¯å¾„ï¼Œå†ç”±å¤§æ¨¡å‹é€‰æ‹©æˆ– refineã€‚

4. **æ¨å¹¿è‡³å…¶ä»– RL æ¶æ„**ï¼š
   - å¦‚ DPOã€SimPO ç­‰ offline RL æ–¹æ³•ï¼Œæ¢ç´¢ JACKPOT åœ¨åå¥½å­¦ä¹ ä¸­çš„æ½œåŠ›ã€‚

---

> ğŸ”— **å¼€æºåœ°å€**ï¼š[GitHub](https://github.com/Infini-AI-Lab/jackpot) | [é¡¹ç›®ä¸»é¡µ](https://infini-ai-lab.github.io/jpt_website/)

</details>

---

### 15. [HyPER: Bridging Exploration and Exploitation for Scalable LLM Reasoning with Hypothesis Path Expansion and Reduction](https://arxiv.org/abs/2602.06527)

**Authors**: Shengxuan Qiu, Haochen Huang, Shuzhang Zhong, Pengfei Zuo, Meng Li  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.06527v1  

#### Abstract
Scaling test-time compute with multi-path chain-of-thought improves reasoning accuracy, but its effectiveness depends critically on the exploration-exploitation trade-off. Existing approaches address this trade-off in rigid ways: tree-structured search hard-codes exploration through brittle expansio...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šHyPER: Bridging Exploration and Exploitation for Scalable LLM Reasoning with Hypothesis Path Expansion and Reduction

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰çš„ **test-time scaling** æ–¹æ³•åœ¨æ‰©å±•æ¨ç†è·¯å¾„æ—¶é¢ä¸´ **explorationï¼ˆæ¢ç´¢ï¼‰ä¸ exploitationï¼ˆåˆ©ç”¨ï¼‰ä¹‹é—´çš„æƒè¡¡å›°å¢ƒ**ï¼š
- **Tree-based search** æ–¹æ³•ï¼ˆå¦‚ ToT, MCTSï¼‰é‡‡ç”¨å›ºå®šçš„åˆ†æ”¯è§„åˆ™ï¼Œå¯¼è‡´è¿‡åº¦æ¢ç´¢æˆ–ç ´åæ¨¡å‹åŸç”Ÿçš„è¿ç»­æ¨ç†æµç¨‹ã€‚
- **Parallel reasoning** æ–¹æ³•ï¼ˆå¦‚ Self-Consistency, Best-of-Nï¼‰è™½ä¿ç•™äº†ç”Ÿæˆè¡Œä¸ºï¼Œä½†å€¾å‘äºæ— å·®åˆ«åœ°é‡‡æ ·å¤§é‡å†—ä½™è·¯å¾„ï¼Œç¼ºä¹æœ‰æ•ˆçš„åæœŸç²¾ç»†åŒ–æœºåˆ¶ã€‚
- æ­¤å¤–ï¼Œå³ä½¿æ­£ç¡®ç­”æ¡ˆå­˜åœ¨äºå¤šæ¡è·¯å¾„ä¸­ï¼Œç®€å•çš„æŠ•ç¥¨ç­–ç•¥ï¼ˆå¦‚å¤šæ•°æŠ•ç¥¨æˆ–ç½®ä¿¡åº¦åŠ æƒæŠ•ç¥¨ï¼‰ä»å¯èƒ½å› å™ªå£°è·¯å¾„å ä¼˜è€Œé€‰æ‹©é”™è¯¯ç­”æ¡ˆï¼Œå³å­˜åœ¨â€œ**existence-selection gap**â€ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡º **HyPER**ï¼ˆHypothesis Path Expansion and Reductionï¼‰ï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„åœ¨çº¿æ§åˆ¶ç­–ç•¥ï¼Œå°† test-time scaling è§†ä¸ºä¸€ä¸ªåŠ¨æ€çš„ **expand-reduce æ§åˆ¶é—®é¢˜**ï¼Œé€šè¿‡è½»é‡çº§è·¯å¾„ç»Ÿè®¡ä¿¡å·å®ç°è®¡ç®—èµ„æºçš„å®æ—¶å†åˆ†é…ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š
1. **Online Expand-Reduce Controller**
   - åŠ¨æ€å†³ç­–æ¨¡å—ï¼Œåœ¨æ¯ä¸ªè§£ç å‘¨æœŸç›‘æ§è·¯å¾„æ± çš„çŠ¶æ€ï¼ˆå¤šæ ·æ€§ã€ç½®ä¿¡åº¦ç­‰ï¼‰ï¼Œå¹¶ä»ä»¥ä¸‹åŠ¨ä½œä¸­é€‰æ‹©æœ€ä¼˜æ“ä½œï¼š
     - `NONE`ï¼šç»§ç»­æ ‡å‡†è§£ç 
     - `SINGLETOKEN`ï¼šå• token å±‚é¢ç²¾ç»†åŒ–ï¼ˆexploitationï¼‰
     - `MULTITOKEN`ï¼šçŸ­è§†ç•Œå±•å¼€-èšåˆï¼ˆhybridï¼‰
     - `BRANCH`ï¼šè·¯å¾„åˆ†æ”¯ä»¥å¢åŠ æ¢ç´¢ï¼ˆexplorationï¼‰
   - æ§åˆ¶å™¨åŸºäºç®€å•å¹³å‡è¯„åˆ†å‡½æ•°è¿›è¡Œå†³ç­–ï¼Œæ— éœ€å¤æ‚å­¦ä¹ ç­–ç•¥ã€‚

2. **Single-Token Expand-and-Aggregate æœºåˆ¶ï¼ˆåŸºäº MoE æ¶æ„ï¼‰**
   - åˆ©ç”¨ MoE æ¨¡å‹ä¸­çš„ä¸“å®¶è·¯ç”±å¤šæ ·æ€§ï¼Œåœ¨ token çº§åˆ«ç”Ÿæˆå¤šä¸ªå€™é€‰è¾“å‡ºï¼Œå¹¶é€šè¿‡ä¸¤é˜¶æ®µé‡‡æ ·ï¼ˆtwo-pass samplingï¼‰å¼•å…¥é‡ç”¨æƒ©ç½šï¼Œæå‡å†…éƒ¨å¤šæ ·æ€§ã€‚
   - ä½¿ç”¨ç½®ä¿¡åº¦åŠ æƒèšåˆå¾—åˆ°æ›´å¯é çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼Œé¿å…æ•´æ¡è·¯å¾„é‡é‡‡æ ·çš„é«˜æˆæœ¬ã€‚

3. **Length- and Confidence-Aware Voting Rule**
   - å‘ç°ç»ç½®ä¿¡åº¦å‰ªæåï¼Œ**æ­£ç¡®çš„æ¨ç†è·¯å¾„å¾€å¾€æ¯”é”™è¯¯è·¯å¾„æ›´é•¿**ï¼ˆå› ä¸ºé”™è¯¯è·¯å¾„å¸¸å› ä½ç½®ä¿¡æ­¥éª¤è¢«æå‰ç»ˆæ­¢ï¼‰ã€‚
   - æå‡ºç»“åˆè·¯å¾„é•¿åº¦ $L_p$ å’Œå…¨å±€å¹³å‡ç½®ä¿¡åº¦ $c_p$ çš„æŠ•ç¥¨è§„åˆ™ï¼š
     $$
     a = \arg\max_{a \in A_K} \sum_{p: a_p=a} \left( \lambda_{\text{len}} \frac{L_p}{\max_q L_q} + \lambda_{\text{conf}} \frac{c_p}{\max_q c_q} \right)
     $$
   - è¯¥æœºåˆ¶æœ‰æ•ˆå¼¥åˆäº†â€œå­˜åœ¨â€ä¸â€œè¢«é€‰ä¸­â€ä¹‹é—´çš„å·®è·ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ— éœ€é¢å¤–è®­ç»ƒ**ï¼šå®Œå…¨ training-freeï¼Œé€‚ç”¨äºä»»æ„ post-trained LLMã€‚
- **é«˜æ•ˆèµ„æºåˆ©ç”¨**ï¼šåŠ¨æ€è°ƒæ•´æ¢ç´¢ä¸åˆ©ç”¨æ¯”ä¾‹ï¼Œå‡å°‘å†—ä½™è®¡ç®—ã€‚
- **æ›´å¼ºçš„é²æ£’æ€§**ï¼šé€šè¿‡ token çº§ refinement å’Œç»“æ„æ„ŸçŸ¥ voting æ˜¾è‘—æå‡æœ€ç»ˆç­”æ¡ˆå‡†ç¡®æ€§ã€‚
- **é€šç”¨æ€§å¼º**ï¼šæ§åˆ¶å™¨è®¾è®¡å¯é€‚é…é MoE æ¨¡å‹ï¼ˆè§æ¶ˆèå®éªŒï¼‰ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åˆ†ä¸ºä¸¤ä¸ªéš¾åº¦å±‚çº§ï¼š

| ç±»å‹ | æ•°æ®é›† | æè¿° |
|------|--------|------|
| Hard-reasoning tier | **AIME24/AIME25**, **HMMT25**, **HLE** | æ•°å­¦ç«èµ›é¢˜ï¼Œè¦æ±‚å¤æ‚å¤šæ­¥æ¨ç† |
| Light-reasoning tier | **GSM8K**, **MATH500**, **ARC-C/E** | åŸºç¡€æ•°å­¦ä¸å¸¸è¯†æ¨ç†ä»»åŠ¡ |

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹æ¶æ„**ï¼šä¸»è¦åœ¨å››ç§ MoE æ¨¡å‹ä¸Šæµ‹è¯•ï¼ŒåŒ…æ‹¬ Qwen3-30Bã€Qwen3-Next-80Bã€OLMoE-1B-7Bã€DeepSeek-V2-Lite-Chatã€‚
- **é¢„ç®—å¯¹é½**ï¼šä¸ºå…¬å¹³æ¯”è¾ƒï¼Œæ‰€æœ‰æ–¹æ³•æŒ‰ **Total Instantiated Path Count (Ninst)** å¯¹é½è®¡ç®—é¢„ç®—ã€‚ä¾‹å¦‚ï¼ŒHyPER å› ä¸´æ—¶åˆ†æ”¯å¯¼è‡´ Ninst â‰ˆ 1.5Ã—Smaxï¼Œå› æ­¤ SC/DeepConf åŸºçº¿ä¹Ÿä½¿ç”¨ 1.5Ã—Smax å®½åº¦è¿è¡Œã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Accuracy**ï¼šæœ€ç»ˆç­”æ¡ˆå‡†ç¡®ç‡
  - **Token Consumption**ï¼šå½’ä¸€åŒ–åçš„ token å¼€é”€ï¼ˆç›¸å¯¹äº SC-80ï¼‰
  - **Pareto Frontier**ï¼šç»˜åˆ¶ accuracy vs. relative token cost æ›²çº¿ï¼Œè¡¡é‡æ•ˆç‡è¾¹ç•Œè¡¨ç°

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æ˜¯å¦è‡ªé€‚åº” | æ˜¯å¦æ”¯æŒ exploitation |
|------|------|-----------|------------------------|
| SC (Self-Consistency) | Parallel | âŒ | âŒ |
| Best-of-N (BoN) | Parallel | âŒ | âŒ |
| Self-Certainty | Adaptive | âœ… | âŒ |
| DeepConf | Adaptive pruning | âœ… | å‡å°‘æ¢ç´¢ï¼ˆsubtractiveï¼‰ |
| RoE | Token-level refinement | âœ… | âœ…ï¼ˆä»… refinementï¼‰ |
| **HyPER (Ours)** | Expand-Reduce Control | âœ…âœ… | âœ…âœ…ï¼ˆåŠ¨æ€å¹³è¡¡ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
åœ¨å¤šä¸ª MoE æ¨¡å‹å’Œæ•°æ®é›†ä¸Šçš„ç»¼åˆç»“æœæ˜¾ç¤ºï¼š

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| å¹³å‡å‡†ç¡®ç‡æå‡ | **+8~10%** |
| å¹³å‡ token æ¶ˆè€—é™ä½ | **-25~40%** |
| åœ¨ Pareto å‰æ²¿çš„è¡¨ç° | **å§‹ç»ˆå¤„äºæœ€å‰æ²¿**ï¼Œè¡¨æ˜å…¶åœ¨ä¸åŒé¢„ç®—ä¸‹å‡å…·ä¼˜åŠ¿ |

#### è¡¨æ ¼æ‘˜è¦ï¼ˆéƒ¨åˆ†æ¥è‡ª Table 2ï¼‰ï¼š
| Model | Dataset | SC Acc (%) | HyPER Acc (%) | SC Tokens | HyPER Tokens |
|-------|---------|------------|---------------|------------|----------------|
| Qwen3-30B | AIME25 | 86.0 | **95.3** | 1.00Ã— | **0.71Ã—** |
| Qwen3-Next | HMMT25 | 76.7 | **85.3** | 1.00Ã— | **0.74Ã—** |
| OLMoE | GSM8K | 75.4 | **80.3** | 1.00Ã— | **0.48Ã—** |

> å¯è§ HyPER ä¸ä»…æ˜¾è‘—æé«˜å‡†ç¡®ç‡ï¼Œä¸”å¤§å¹…èŠ‚çœè®¡ç®—å¼€é”€ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨æ‰€æœ‰åŸºå‡†æ–¹æ³•ä¸­ï¼Œ**HyPER æ˜¯å”¯ä¸€åŒæ—¶ä¼˜äº SC å’Œ DeepConf çš„æ–¹æ³•**ã€‚
- ç›¸æ¯” RoEï¼Œè™½ç„¶ä¸¤è€…éƒ½èƒ½æå‡ token çº§ç½®ä¿¡åº¦ï¼Œä½† **HyPER ç»´æŒæ›´é«˜çš„è·¯å¾„å¤šæ ·æ€§ $D_t$**ï¼Œé˜²æ­¢è¿‡æ—©æ”¶æ•›ã€‚
- åœ¨å›°éš¾é—®é¢˜ä¸Šï¼ˆå¦‚ HLEï¼‰ï¼ŒHyPER çš„æ§åˆ¶å™¨èƒ½ä¸»åŠ¨è§¦å‘æ›´å¤š `BRANCH` å’Œ `SINGLETOKEN` æ“ä½œï¼Œä½“ç°å…¶è‡ªé€‚åº”èƒ½åŠ›ï¼ˆè§ Figure 9 & 10ï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰Expansion Strategiesï¼ˆTable 3ï¼‰
| æ–¹æ³• | AIME25 Acc (%) | Tokens |
|------|----------------|--------|
| SC | 86.7 | 1.00Ã— |
| SingleToken-only | 93.3 | 1.81Ã— |
| MultiToken-only | 90.0 | 1.87Ã— |
| Manual Schedule | 93.3 | 1.78Ã— |
| **HyPER (full)** | **96.7** | **1.62Ã—** |

> è¡¨æ˜åªæœ‰ HyPER çš„åŠ¨æ€æ§åˆ¶æ‰èƒ½å®ç°æœ€ä½³ trade-offã€‚

#### ï¼ˆ2ï¼‰Voting Rulesï¼ˆTable 4ï¼‰
| æŠ•ç¥¨æ–¹å¼ | AIME25 Acc (%) | HMMT25 Acc (%) |
|----------|----------------|------------------|
| Majority Voting | 86.7 | 73.3 |
| Confidence-weighted | 90.0 | 73.3 |
| **Length+Confidence (ours)** | **96.7** | **76.7** |

> éªŒè¯äº†é•¿åº¦ä½œä¸ºè¾…åŠ©ä¿¡å·çš„é‡è¦æ€§ï¼Œå°¤å…¶åœ¨ç½®ä¿¡åº¦å‰ªæèƒŒæ™¯ä¸‹ã€‚

#### ï¼ˆ3ï¼‰Non-MoE å®éªŒï¼ˆAppendix F.4ï¼‰
åœ¨ dense æ¨¡å‹ï¼ˆæ—  MoE è·¯ç”±ï¼‰ä¸Šç§»é™¤ `SINGLETOKEN` åï¼Œä»…ä¿ç•™æ§åˆ¶å™¨å’Œ voting æœºåˆ¶ï¼Œä»å–å¾—ä¼˜äº SC å’Œ DeepConf çš„ç»“æœï¼š

| Method | HMMT25 Acc (%) |
|--------|----------------|
| SC | 71.3 |
| DeepConf | 74.0 |
| **HyPER (controller only)** | **78.7** |

> è¯´æ˜ **æ§åˆ¶å™¨æœ¬èº«å…·æœ‰æ³›åŒ–ä»·å€¼**ï¼Œä¸ä¾èµ–äº MoE æ¶æ„ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **æœ€ä¼˜çš„ exploration-exploitation å¹³è¡¡æ˜¯é˜¶æ®µä¾èµ–çš„**ï¼šæ—©æœŸéœ€å¹¿æ³›æ¢ç´¢ï¼ŒåæœŸåº”èšç„¦äºç²¾ç»†åŒ–ã€‚
2. **æ­£ç¡®ä¸é”™è¯¯è·¯å¾„å¸¸åœ¨æœ«å°¾æ‰åˆ†é“æ‰¬é•³**ï¼šå› æ­¤åº”åœ¨ä½ç½®ä¿¡åŒºåŸŸè¿›è¡Œå±€éƒ¨ refinementï¼Œè€Œéæ•´è·¯å¾„é‡é‡‡æ ·ã€‚
3. **ç½®ä¿¡åº¦å‰ªæä¼šåè½¬è·¯å¾„é•¿åº¦åç½®**ï¼šå­˜æ´»ä¸‹æ¥çš„æ­£ç¡®è·¯å¾„ç³»ç»Ÿæ€§åœ°æ›´é•¿ï¼Œè¿™ä¸€ç»“æ„æ€§ä¿¡å·å¯ç”¨äºå¢å¼º answer selectionã€‚
4. **ç»Ÿä¸€çš„ expand-reduce æ§åˆ¶æ¡†æ¶ä¼˜äºé™æ€è°ƒåº¦**ï¼šHyPER é€šè¿‡è½»é‡ä¿¡å·å³å¯å®ç°æ¥è¿‘ Pareto æœ€ä¼˜çš„è¡Œä¸ºã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ **Single-Token Aggregation æ¨¡å—ä¾èµ– MoE æ¶æ„**ï¼Œåœ¨ dense æ¨¡å‹ä¸Šæ— æ³•ç›´æ¥åº”ç”¨ token çº§ refinementã€‚
- æ§åˆ¶å™¨ä½¿ç”¨çš„ä¿¡å·è¾ƒä¸ºç²—ç²’åº¦ï¼ˆå¦‚å¹³å‡ç½®ä¿¡åº¦ã€å¤šæ ·æ€§å¾—åˆ†ï¼‰ï¼Œæœªå¼•å…¥ learnable policyï¼Œå¯èƒ½åœ¨æç«¯æƒ…å†µä¸‹å“åº”ä¸è¶³ã€‚
- æ‰€æœ‰å®éªŒåŸºäºå›ºå®šå®½åº¦ä¸Šé™ $S_{\text{max}}=80$ï¼Œæœªæ¢è®¨è¶…å¤§è§„æ¨¡è·¯å¾„æ± ä¸‹çš„è¡¨ç°ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† HyPER ä¸ **learned verifiers**ï¼ˆå¦‚ PRM, Process Reward Modelï¼‰ç»“åˆï¼Œè¿›ä¸€æ­¥æå‡æ¨ç†è´¨é‡ã€‚
- æ¢ç´¢åœ¨ **dense æ¨¡å‹ä¸Šæ¨¡æ‹Ÿ token-level refinement** çš„æ›¿ä»£æ–¹æ¡ˆï¼ˆå¦‚ speculative decodingï¼‰ã€‚
- å¼•å…¥ **learnable controller** ä»¥æ•æ‰æ›´å¤æ‚çš„è·¯å¾„æ¼”åŒ–æ¨¡å¼ã€‚
- æ‰©å±•è‡³ **multi-agent æˆ– multi-tool reasoning åœºæ™¯**ï¼Œå®ç°æ›´é«˜å±‚æ¬¡çš„ä»»åŠ¡åˆ†è§£ä¸åä½œã€‚

---

> **ä»£ç å·²å¼€æº**ï¼š[https://github.com/ShengxuanQiu/HyPER](https://github.com/ShengxuanQiu/HyPER)

</details>

---

### 16. [Echoes as Anchors: Probabilistic Costs and Attention Refocusing in LLM Reasoning](https://arxiv.org/abs/2602.06600)

**Authors**: Zhuoyuan Hao, Zhuo Li, Wu Li, Fangming Liu, Min Zhang, Jing Li  
**Category**: cs.CL  
**Published**: 2026-02-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.06600v1  

#### Abstract
Test-time compute allocation in large reasoning models (LRMs) is widely used and has applications in mathematical problem solving, code synthesis, and planning. Recent work has addressed this problem by scaling self-consistency and parallel thinking, adding generic ``thinking tokens'' and prompting ...

---

### 17. [Difficulty-Estimated Policy Optimization](https://arxiv.org/abs/2602.06375)

**Authors**: Yu Zhao, Fan Jiang, Tianle Liu, Bo Zeng, Yu Liu, Longyue Wang, Weihua Luo  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.06375v1  

#### Abstract
Recent advancements in Large Reasoning Models (LRMs), exemplified by DeepSeek-R1, have underscored the potential of scaling inference-time compute through Group Relative Policy Optimization (GRPO). However, GRPO frequently suffers from gradient signal attenuation when encountering problems that are ...

---

### 18. [Inference-Time Rethinking with Latent Thought Vectors for Math Reasoning](https://arxiv.org/abs/2602.06584)

**Authors**: Deqian Kong, Minglu Zhao, Aoyang Qin, Bo Pang, Chenxin Tao, David Hartmann, Edouardo Honig, Dehong Xu, Amit Kumar, Matt Sarte, Chuan Li, Jianwen Xie, Ying Nian Wu  
**Category**: cs.CL  
**Published**: 2026-02-09  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.06584v1  

#### Abstract
Standard chain-of-thought reasoning generates a solution in a single forward pass, committing irrevocably to each token and lacking a mechanism to recover from early errors. We introduce Inference-Time Rethinking, a generative framework that enables iterative self-correction by decoupling declarativ...

---

### 19. [When RL Meets Adaptive Speculative Training: A Unified Training-Serving System](https://arxiv.org/abs/2602.06932)

**Authors**: Junxiong Wang, Fengxiang Bie, Jisen Li, Zhongzhu Zhou, Zelei Shao, Yubo Wang, Yinghui Liu, Qingyang Wu, Avner May, Sri Yanamandra, Yineng Zhang, Ce Zhang, Tri Dao, Percy Liang, Ben Athiwaratkun, Shuaiwen Leon Song, Chenfeng Xu, Xiaoxia Wu  
**Category**: cs.LG  
**Published**: 2026-02-09  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.06932v1  

#### Abstract
Speculative decoding can significantly accelerate LLM serving, yet most deployments today disentangle speculator training from serving, treating speculator training as a standalone offline modeling problem. We show that this decoupled formulation introduces substantial deployment and adaptation lag:...

---

### 20. [An Adaptive Differentially Private Federated Learning Framework with Bi-level Optimization](https://arxiv.org/abs/2602.06838)

**Authors**: Jin Wang, Hui Ma, Fei Xing, Ming Yan  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.06838v1  

#### Abstract
Federated learning enables collaborative model training across distributed clients while preserving data privacy. However, in practical deployments, device heterogeneity, non-independent, and identically distributed (Non-IID) data often lead to highly unstable and biased gradient updates. When diffe...

---

### 21. [DualMap: Enabling Both Cache Affinity and Load Balancing for Distributed LLM Serving](https://arxiv.org/abs/2602.06502)

**Authors**: Ying Yuan, Pengfei Zuo, Bo Wang, Zhangyu Chen, Zhipeng Tan, Zhou Yu  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.06502v1  

#### Abstract
In LLM serving, reusing the KV cache of prompts across requests is critical for reducing TTFT and serving costs. Cache-affinity scheduling, which co-locates requests with the same prompt prefix to maximize KV cache reuse, often conflicts with load-balancing scheduling that distributes requests evenl...

---

### 22. [Reinforcement Learning-Based Dynamic Management of Structured Parallel Farm Skeletons on Serverless Platforms](https://arxiv.org/abs/2602.06555)

**Authors**: Lanpei Li, Massimo Coppola, Malio Li, Valerio Besozzi, Jack Bell, Vincenzo Lomonaco  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.06555v1  

#### Abstract
We present a framework for dynamic management of structured parallel processing skeletons on serverless platforms. Our goal is to bring HPC-like performance and resilience to serverless and continuum environments while preserving the programmability benefits of skeletons. As a first step, we focus o...

---

### 23. [NanoQuant: Efficient Sub-1-Bit Quantization of Large Language Models](https://arxiv.org/abs/2602.06694)

**Authors**: Hyochan Chong, Dongkyu Kim, Changdong Kim, Minseop Choi  
**Category**: cs.LG  
**Published**: 2026-02-09  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.06694v1  

#### Abstract
Weight-only quantization has become a standard approach for efficiently serving large language models (LLMs). However, existing methods fail to efficiently compress models to binary (1-bit) levels, as they either require large amounts of data and compute or incur additional storage. In this work, we...

---

### 24. [LLM Active Alignment: A Nash Equilibrium Perspective](https://arxiv.org/abs/2602.06836)

**Authors**: Tonghan Wang, Yuqi Pan, Xinyi Yang, Yanchen Jiang, Milind Tambe, David C. Parkes  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.06836v1  

#### Abstract
We develop a game-theoretic framework for predicting and steering the behavior of populations of large language models (LLMs) through Nash equilibrium (NE) analysis. To avoid the intractability of equilibrium computation in open-ended text spaces, we model each agent's action as a mixture over human...

---

### 25. [RoPE-LIME: RoPE-Space Locality + Sparse-K Sampling for Efficient LLM Attribution](https://arxiv.org/abs/2602.06275)

**Authors**: Isaac Picov, Ritesh Goru  
**Category**: cs.CL  
**Published**: 2026-02-09  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.06275v1  

#### Abstract
Explaining closed-source LLM outputs is challenging because API access prevents gradient-based attribution, while perturbation methods are costly and noisy when they depend on regenerated text. We introduce RoPE-LIME, an open-source extension of gSMILE that decouples reasoning from explanation: give...

---

### 26. [LAAFD: LLM-based Agents for Accelerated FPGA Design](https://arxiv.org/abs/2602.06085)

**Authors**: Maxim Moraru, Kamalavasan Kamalakkannan, Jered Dominguez-Trujillo, Patrick Diehl, Atanu Barai, Julien Loiseau, Zachary Kent Baker, Howard Pritchard, Galen M Shipman  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.06085v1  

#### Abstract
FPGAs offer high performance, low latency, and energy efficiency for accelerated computing, yet adoption in scientific and edge settings is limited by the specialized hardware expertise required. High-level synthesis (HLS) boosts productivity over HDLs, but competitive designs still demand hardware-...

---

### 27. [Online Adaptive Reinforcement Learning with Echo State Networks for Non-Stationary Dynamics](https://arxiv.org/abs/2602.06326)

**Authors**: Aoi Yoshimura, Gouhei Tanaka  
**Category**: cs.LG  
**Published**: 2026-02-09  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.06326v1  

#### Abstract
Reinforcement learning (RL) policies trained in simulation often suffer from severe performance degradation when deployed in real-world environments due to non-stationary dynamics. While Domain Randomization (DR) and meta-RL have been proposed to address this issue, they typically rely on extensive ...

---

### 28. [Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization](https://arxiv.org/abs/2602.06394)

**Authors**: Arvid E. Gollwitzer, Paridhi Latawa, David de Gruijl, Deepak A. Subramanian, Adri\'an Noriega de la Colina  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.06394v1  

#### Abstract
Current tokenization methods process sequential data without accounting for signal quality, limiting their effectiveness on noisy real-world corpora. We present QA-Token (Quality-Aware Tokenization), which incorporates data reliability directly into vocabulary construction. We make three key contrib...

---

### 29. [AgentCPM-Explore: Realizing Long-Horizon Deep Exploration for Edge-Scale Agents](https://arxiv.org/abs/2602.06485)

**Authors**: Haotian Chen, Xin Cong, Shengda Fan, Yuyang Fu, Ziqin Gong, Yaxi Lu, Yishan Li, Boye Niu, Chengjun Pan, Zijun Song, Huadong Wang, Yesai Wu, Yueying Wu, Zihao Xie, Yukun Yan, Zhong Zhang, Yankai Lin, Zhiyuan Liu, Maosong Sun  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.06485v1  

#### Abstract
While Large Language Model (LLM)-based agents have shown remarkable potential for solving complex tasks, existing systems remain heavily reliant on large-scale models, leaving the capabilities of edge-scale models largely underexplored. In this paper, we present the first systematic study on trainin...

---

### 30. [Progress Constraints for Reinforcement Learning in Behavior Trees](https://arxiv.org/abs/2602.06525)

**Authors**: Finn Rietz, Mart Karta\v{s}ev, Johannes A. Stork, Petter \"Ogren  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.06525v1  

#### Abstract
Behavior Trees (BTs) provide a structured and reactive framework for decision-making, commonly used to switch between sub-controllers based on environmental conditions. Reinforcement Learning (RL), on the other hand, can learn near-optimal controllers but sometimes struggles with sparse rewards, saf...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
