# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-10 05:55:55 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Chopper: A Multi-Level GPU Characterization Tool & Derived Insights Into LLM Training Inefficiency](https://arxiv.org/abs/2512.08242)

**Authors**: Marco Kurzynski, Shaizeen Aga, Di Wu  
**Category**: cs.DC  
**Published**: 2025-12-10  
**Score**: 12.5  
**Type**: new  
**ArXiv ID**: 2512.08242v1  

#### Abstract
Training large language models (LLMs) efficiently requires a deep understanding of how modern GPU systems behave under real-world distributed training workloads. While prior work has focused primarily on kernel-level performance or single-GPU microbenchmarks, the complex interaction between communic...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Chopper: A Multi-Level GPU Characterization Tool & Derived Insights Into LLM Training Inefficiency*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è®­ç»ƒåœ¨å¤šGPUç³»ç»Ÿä¸Šçš„æ€§èƒ½ç“¶é¢ˆç¼ºä¹**ç«¯åˆ°ç«¯ã€å¤šå±‚æ¬¡çš„ç»¼åˆåˆ†æå·¥å…·**ã€‚å·²æœ‰ç ”ç©¶å¤šé›†ä¸­äºå•ä¸ªå±‚é¢ï¼ˆå¦‚kernelçº§æˆ–å•GPUå¾®åŸºå‡†ï¼‰ï¼Œéš¾ä»¥æ­ç¤ºé€šä¿¡ã€è®¡ç®—ã€å†…å­˜è¡Œä¸ºä¸åŠŸè€—ç®¡ç†ä¹‹é—´çš„å¤æ‚äº¤äº’å…³ç³»ï¼Œå¯¼è‡´æ— æ³•å‡†ç¡®è¯†åˆ«çœŸå®è®­ç»ƒä¸­çš„æ€§èƒ½ç“¶é¢ˆã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡º **Chopper** â€”â€” ä¸€ç§**å¤šç²’åº¦GPUè¡¨å¾æ¡†æ¶**ï¼Œç”¨äºè‡ªåŠ¨åŒ–æ”¶é›†ã€å¯¹é½å’Œå¯è§†åŒ–LLMè®­ç»ƒè¿‡ç¨‹ä¸­çš„GPUå†…æ ¸è½¨è¿¹ï¼ˆkernel tracesï¼‰å’Œç¡¬ä»¶æ€§èƒ½è®¡æ•°å™¨ï¼ˆhardware performance countersï¼‰ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºæ”¯æŒä»å¤šä¸ªç»´åº¦è¿›è¡Œåˆ†æï¼š
- **åº”ç”¨å±‚çº§ç²’åº¦**ï¼škernel â†’ operation â†’ layer â†’ phaseï¼ˆforward/backward/optimizerï¼‰â†’ iteration â†’ GPU â†’ æ•´ä½“workload
- **ç¡¬ä»¶å±‚çº§ç²’åº¦**ï¼šnodeçº§å¤šGPUç³»ç»Ÿã€å•GPUå¾®æ¶æ„ã€CPUè¡Œä¸º
- **è·¨è½¯ç¡¬ä»¶è”åˆæ´å¯Ÿ**ï¼šç»“åˆè½¯ä»¶æ‰§è¡Œæµä¸ç¡¬ä»¶èµ„æºåˆ©ç”¨ç‡ï¼ˆå¦‚MFMA utilizationã€memory bandwidthã€frequencyã€powerç­‰ï¼‰

æ­¤å¤–ï¼ŒChopperæä¾›å¼€æºå·¥å…·ï¼Œæ”¯æŒAMD Instinctâ„¢ MI300Xï¼Œå¹¶å¯æ‰©å±•è‡³å…¶ä»–GPUå¹³å°ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Chopper | å…¶ä»–å·¥ä½œï¼ˆå¦‚[33]-[37]ï¼‰ |
|------|--------|-----------------------|
| **ç²’åº¦è¦†ç›–** | âœ… åº”ç”¨å…¨æ ˆ + ç¡¬ä»¶å…¨å±‚ | âŒ å¤šä¸ºå•ä¸€ç²’åº¦ï¼ˆä»…kernelæˆ–operationï¼‰ |
| **åˆ†ææ·±åº¦** | âœ… è½¯ç¡¬ååŒåˆ†æ | âŒ å¤šèšç„¦å•ä¸€è§†è§’ï¼ˆä»…ç¡¬ä»¶æˆ–ä»…è½¯ä»¶ï¼‰ |
| **å·¥å…·å¯ç”¨æ€§** | âœ… å¼€æºå‘å¸ƒ | âŒ å¤šæ— å·¥å…·æˆ–æœªå…¬å¼€ |
| **ç³»ç»Ÿå®Œæ•´æ€§** | âœ… æ”¯æŒå¤šGPU + CPUååŒåˆ†æ | âŒ å¤šå±€é™äºå•GPU |

> **ä¼˜åŠ¿æ€»ç»“**ï¼šChopperæ˜¯é¦–ä¸ªå®ç°**ç«¯åˆ°ç«¯ã€å¤šç²’åº¦ã€è½¯ç¡¬ååŒ**çš„LLMè®­ç»ƒæ€§èƒ½åˆ†ææ¡†æ¶ï¼Œå¡«è¡¥äº†ç°æœ‰å·¥å…·é“¾çš„ç©ºç™½ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸æ¨¡å‹
- **æ¨¡å‹**ï¼šLlama 3 8Bï¼ˆå…¬å¼€å‘å¸ƒçš„LLMï¼‰
- **é…ç½®å‚æ•°**ï¼š
  - å±‚æ•°ï¼š32
  - Tokené•¿åº¦ï¼š4,096
  - éšè—ç»´åº¦ï¼š14,336
  - æ³¨æ„åŠ›å¤´æ•°ï¼š32 Query Heads / 8 KV Headsï¼ˆå¯ç”¨Group Query Attentionï¼‰

### å®éªŒè®¾ç½®
- **å¹¶è¡Œç­–ç•¥**ï¼šFully Sharded Data Parallelism (**FSDP**)ï¼ŒåŒ…æ‹¬FSDPv1å’ŒFSDPv2ç‰ˆæœ¬å¯¹æ¯”
- **è®­ç»ƒæ¡†æ¶**ï¼šåŸºäºPyTorchï¼Œä½¿ç”¨FSDP + FlashAttention-V2 + BF16æ•°æ®æ ¼å¼
- **ç¡¬ä»¶å¹³å°**ï¼š
  - **GPU**ï¼š8Ã— AMD Instinctâ„¢ MI300Xï¼ˆæ¯å¡å³°å€¼1.3 PFLOPSï¼ŒHBM 192GBï¼Œå¸¦å®½5.3TB/sï¼‰
  - **äº’è”**ï¼šAMD Infinity Fabricâ„¢ 128GB/såŒå‘è¿æ¥ï¼ˆå…¨äº’è¿æ‹“æ‰‘ï¼‰
  - **CPU**ï¼šåŒè·¯AMD EPYCâ„¢ 9684Xï¼Œå…±2.3TBä¸»æœºå†…å­˜
- **Profilingå·¥å…·**ï¼š
  - è¿è¡Œæ—¶è¿½è¸ªï¼šPyTorch Profiler + AMD roctracer
  - ç¡¬ä»¶è®¡æ•°å™¨é‡‡é›†ï¼šAMD rocprofv3
- **è¯„ä¼°é…ç½®**ï¼š
  - æ‰¹æ¬¡å¤§å°ï¼ˆbatch sizeï¼‰ï¼š1, 2, 4
  - åºåˆ—é•¿åº¦ï¼ˆsequence lengthï¼‰ï¼š4K, 8Kï¼ˆè®°ä½œb1s4, b2s4, ..., b2s8ï¼‰
  - æ¯è½®è¿è¡Œ20ä¸ªiterationï¼Œå‰10ä¸ªwarmupï¼Œå10ä¸ªé‡‡æ ·

### è¯„ä¼°æŒ‡æ ‡
- **ååé‡ï¼ˆThroughputï¼‰**ï¼štokens/sec
- **å„é˜¶æ®µè€—æ—¶åˆ†è§£**ï¼šforward / backward / optimizer
- **æ“ä½œç±»å‹è€—æ—¶å æ¯”**ï¼šGEMMã€FlashAttentionã€vector opsç­‰
- **Launch Overhead**ï¼škernelé—´ç©ºæ³¡æ—¶é—´
- **Communication/Computation Overlap Ratio**
- **GPUé¢‘ç‡ã€å†…å­˜é¢‘ç‡ã€åŠŸè€—**
- **ç†è®º vs å®é™…æ€§èƒ½å·®è·åˆ†è§£**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| é…ç½® | ååé‡ï¼ˆç›¸å¯¹b1s4å½’ä¸€åŒ–ï¼‰ | Backwardå æ¯” | GEMMæ€»è€—æ—¶å æ¯” |
|------|--------------------------|---------------|----------------|
| b1s4 | 1.0xï¼ˆåŸºå‡†ï¼‰              | ~60%          | ~60%           |
| b2s4 | ~1.3x                     | ~65%          | ~60%           |
| b4s4 | æœ€é«˜åå                 | ~70%          | ~60%           |
| b2s8 | ç•¥ä½äºb2s4                | æ›´é«˜           | æ›´é«˜           |

> âš ï¸ **b1s4ååæ˜¾è‘—åä½ï¼ˆçº¦ä½30%ï¼‰**ï¼Œè¡¨æ˜å°batch sizeä¸‹ä¸¥é‡èµ„æºæœªå……åˆ†åˆ©ç”¨ã€‚

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ
#### FSDPv1 vs FSDPv2 æ€§èƒ½å¯¹æ¯”
| æŒ‡æ ‡ | FSDPv1 | FSDPv2 | æå‡åŸå›  |
|------|--------|--------|---------|
| **å¹³å‡GPUé¢‘ç‡** | ~1.5 GHz | ~1.8 GHz (+20%) | å†…å­˜åˆ†é…æ›´ç¡®å®šï¼Œå‡å°‘HBMåŠŸè€—æ³¢åŠ¨ |
| **å†…å­˜é¢‘ç‡ç¨³å®šæ€§** | æ³¢åŠ¨å¤§ | æ›´ç¨³å®š | å‡å°‘DVFS throttling |
| **æ€»ä½“åå** | è¾ƒä½ | æ˜¾è‘—æ›´é«˜ | æ›´é«˜ä¸”ç¨³å®šçš„é¢‘ç‡æ”¯æ’‘ |
| **copy kernelè°ƒåº¦** | å¹¶å‘ | **ä¸²è¡ŒåŒ–**ï¼ˆper-parameter shardingå¼•å…¥ï¼‰ | å¢åŠ launch overheadä½†æ¢æ¥æ›´é«˜é¢‘ç‡ |

> ğŸ“Œ å°½ç®¡FSDPv2å› ä¸²è¡ŒåŒ–copy kernelå¢åŠ äº†launch overheadï¼Œä½†ç”±äº**æ›´é«˜çš„GPUé¢‘ç‡**ï¼Œæœ€ç»ˆä»å®ç°**æ›´é«˜åå**ã€‚

### æ¶ˆèå®éªŒä¸å…³é”®åˆ†è§£ç»“æœï¼ˆè§Fig. 15ï¼‰
å¯¹GEMMå’ŒFlashAttentionçš„æ“ä½œè€—æ—¶è¿›è¡Œäº†**ç†è®º vs å®é™…**çš„å¼€é”€åˆ†è§£ï¼Œé‡åŒ–å„é¡¹å› ç´ è´¡çŒ®ï¼š

| å¼€é”€ç±»å‹ | å æ¯”ï¼ˆå…¸å‹å€¼ï¼‰ | è¯´æ˜ |
|--------|----------------|------|
| **Frequency Overhead** | **æœ€å¤§é¡¹ï¼ˆä¸»å¯¼åœ°ä½ï¼‰** | å› DVFSå¯¼è‡´è¿è¡Œé¢‘ç‡ä½äºå³°å€¼ï¼ˆMI300Xæœªè¾¾1.3GHzï¼‰ |
| **Utilization Overhead** | æ¬¡è¦ | MFMA coreæœªæ»¡è½½ï¼ˆå°¤å…¶FlashAttentionå«å¤§é‡vector opsï¼‰ |
| **Overlap Overhead** | ä¸­ç­‰ | C3é‡å ä¸å……åˆ†å¯¼è‡´èµ„æºäº‰ç”¨ |
| **Instruction Overhead** | æå° | paddingå¸¦æ¥çš„é¢å¤–flopæå°‘ |
| **Launch Overhead** | å¯è§‚ï¼ˆå°¤å…¶å°batchï¼‰ | kernelå¯åŠ¨å»¶è¿Ÿå½±å“æ˜æ˜¾ |

> ğŸ” **Frequency Overhead æ˜¯ç†è®ºä¸å®é™…æ€§èƒ½å·®è·çš„æœ€å¤§æ¥æº**ï¼Œè¶…è¿‡MFMAåˆ©ç”¨ç‡æŸå¤±ã€é€šä¿¡/è®¡ç®—é‡å ä¸è¶³ã€kernel launchå¼€é”€ç­‰æ‰€æœ‰å…¶ä»–å› ç´ ä¹‹å’Œã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°ï¼ˆInsightsï¼‰
1. **ğŸ’¡ Batch Size = 1 å¯¼è‡´ä¸¥é‡æ€§èƒ½ä¸‹é™**
   - ååæ¯”b2s4ä½çº¦30%ï¼Œä¸»å› åŒ…æ‹¬ï¼š
     - Backward FlashAttentionå®ç°ä¸ä½³ï¼ˆåè€Œæ¯”b2s4æ…¢ï¼‰
     - Launch overheadå æ¯”é«˜
     - æ›´é«˜çš„é€šä¿¡/è®¡ç®—é‡å å¼•å‘èµ„æºç«äº‰

2. **ğŸ’¡ Backward FlashAttentionå­˜åœ¨ä¼˜åŒ–ç¼ºé™·**
   - åœ¨b=1æ—¶ï¼Œå°½ç®¡è®¡ç®—é‡æ›´å¤§ï¼Œä½†è€—æ—¶å´æ›´çŸ­ â†’ è¡¨æ˜å®ç°å­˜åœ¨é—®é¢˜ï¼ˆå¯èƒ½æœªå……åˆ†åˆ©ç”¨å¹¶è¡Œæ€§ï¼‰
   - æ¨èä½¿ç”¨Chopperå®šä½å¹¶ä¿®å¤è¯¥kernelçš„å®ç°é—®é¢˜

3. **ğŸ’¡ Frequency Overhead æ˜¯æ€§èƒ½ç“¶é¢ˆçš„â€œå¤´å·æ€æ‰‹â€**
   - åŠ¨æ€ç”µå‹é¢‘ç‡è°ƒèŠ‚ï¼ˆDVFSï¼‰å¯¼è‡´GPUé•¿æœŸè¿è¡Œåœ¨è¿œä½äºå³°å€¼é¢‘ç‡çš„çŠ¶æ€
   - FSDPv2é€šè¿‡æ›´**ç¡®å®šæ€§çš„å†…å­˜åˆ†é…è¡Œä¸º**å‡å°‘äº†HBMåŠŸè€—æ³¢åŠ¨ï¼Œä»è€Œå…è®¸ç»´æŒæ›´é«˜é¢‘ç‡ï¼ˆ+20%ï¼‰ï¼Œè¿™æ˜¯å…¶æ€§èƒ½ä¼˜äºFSDPv1çš„æ ¹æœ¬åŸå› 

4. **ğŸ’¡ Launch Overhead ä¸»è¦æ¥è‡ªè¿­ä»£è¾¹ç•Œè€Œéå†…éƒ¨**
   - å‡†å¤‡å¼€é”€ï¼ˆpreparation overheadï¼‰é›†ä¸­åœ¨iterationå¼€å§‹ï¼ˆf_ieï¼‰å’Œç»“æŸï¼ˆopt_stepï¼‰ï¼Œæºäºé€šä¿¡pipelineçš„å¡«å……ä¸æ¸…ç©º
   - å½“å‰ä¼˜åŒ–å¤šå…³æ³¨intra-iteration launchï¼Œåº”åŠ å¼ºinter-iterationä¼˜åŒ–

5. **ğŸ’¡ CPUä¸¥é‡æœªè¢«å……åˆ†åˆ©ç”¨**
   - ä»…çº¦25ä¸ªé€»è¾‘æ ¸å¿ƒæ´»è·ƒï¼Œç‰©ç†æ ¸å¿ƒåˆ©ç”¨ç‡ä»…12.5%
   - å­˜åœ¨å·¨å¤§**power-sloshing**ç©ºé—´ï¼šå¯å°†CPUé—²ç½®åŠŸç‡è½¬ç§»ç»™GPUä»¥æå‡æ€§èƒ½

6. **ğŸ’¡ ç›¸åŒæ“ä½œå› é€šä¿¡é‡å ä¸åŒè€Œè€—æ—¶å·®å¼‚å¤§**
   - å¦‚`b_attn_n`ä¸`b_mlp_n`è®¡ç®—ç›¸åŒï¼Œä½†å‰è€…æœ‰~90%é€šä¿¡é‡å  â†’ è€—æ—¶æ›´é•¿
   - é‡å æœ¬èº«ä¸ä¸€å®šæœ‰ç›Šï¼Œå¯èƒ½å¯¼è‡´èµ„æºäº‰ç”¨

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰Chopperä¸»è¦é’ˆå¯¹**AMD Instinctâ„¢ MI300X**ä¼˜åŒ–ï¼Œè™½å¯æ‰©å±•ï¼Œä½†åœ¨NVIDIAæˆ–å…¶ä»–æ¶æ„ä¸Šéœ€é€‚é…
- ç¡¬ä»¶è®¡æ•°å™¨é‡‡é›†éœ€åºåˆ—åŒ–kernelæ‰§è¡Œï¼Œ**æ— æ³•åŒæ—¶è·å–ç²¾ç¡®timestampä¸counter**ï¼Œä¾èµ–trace alignmentæŠ€æœ¯
- åˆ†æä¾èµ–ä¸“å®¶ç»éªŒè§£è¯»å›¾è¡¨ï¼Œå°šæœªå®Œå…¨è‡ªåŠ¨åŒ–ç”Ÿæˆä¼˜åŒ–å»ºè®®

### æœªæ¥å·¥ä½œæ–¹å‘
- å°†Chopperæ‰©å±•è‡³æ›´å¤šGPUå‚å•†ï¼ˆå¦‚NVIDIA Hopperï¼‰å’Œåˆ†å¸ƒå¼å¤šèŠ‚ç‚¹åœºæ™¯
- ç»“åˆæœºå™¨å­¦ä¹ è‡ªåŠ¨è¯†åˆ«æ€§èƒ½åæ¨¡å¼ï¼ˆanti-patternsï¼‰
- æ¨åŠ¨ç¡¬ä»¶å›ºä»¶å±‚ä¼˜åŒ–ï¼šæ”¹è¿›DVFSç­–ç•¥ï¼Œä½¿å…¶å¯¹LLM workloadæ›´å‹å¥½
- æ¢ç´¢åŠ¨æ€power-sloshingæœºåˆ¶ï¼Œåœ¨è®­ç»ƒæœŸé—´å®æ—¶å°†CPUåŠŸç‡é‡å®šå‘è‡³GPU
- é›†æˆè¿›ä¸»æµè®­ç»ƒæ¡†æ¶ï¼ˆå¦‚PyTorchï¼‰ï¼Œå®ç°é—­ç¯æ€§èƒ½è°ƒä¼˜

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> Chopperé¦–æ¬¡å®ç°äº†å¯¹LLMè®­ç»ƒå…¨è¿‡ç¨‹çš„**å¤šç²’åº¦ã€è½¯ç¡¬ååŒæ€§èƒ½å‰–æ**ï¼Œæ­ç¤ºäº†**frequency overhead**æ˜¯åˆ¶çº¦å®é™…æ€§èƒ½çš„æœ€å¤§ç“¶é¢ˆï¼Œå¹¶æŒ‡å‡º**FSDPv2é€šè¿‡æå‡é¢‘ç‡ç¨³å®šæ€§å®ç°è¶…è¶Š**ï¼Œä¸ºæœªæ¥GPUæ¶æ„è®¾è®¡ã€åŠŸè€—ç®¡ç†å’Œè®­ç»ƒæ¡†æ¶ä¼˜åŒ–æä¾›äº†å…³é”®æŒ‡å¯¼ã€‚

</details>

---

### 2. [CogMCTS: A Novel Cognitive-Guided Monte Carlo Tree Search Framework for Iterative Heuristic Evolution with Large Language Models](https://arxiv.org/abs/2512.08609)

**Authors**: Hui Wang, Yang Liu, Xiaoyu Zhang, Chaoxu Mu  
**Category**: cs.AI  
**Published**: 2025-12-10  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.08609v1  

#### Abstract
Automatic Heuristic Design (AHD) is an effective1 framework for solving complex optimization prob-2 lems. The development of large language mod-3 els (LLMs) enables the automated generation of4 heuristics. Existing LLM-based evolutionary meth-5 ods rely on population strategies and are prone6 to loc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCogMCTS: A Novel Cognitive-Guided Monte Carlo Tree Search Framework for Iterative Heuristic Evolution with Large Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ç°æœ‰çš„åŸºäº **Large Language Models (LLMs)** çš„è‡ªåŠ¨å¯å‘å¼è®¾è®¡ï¼ˆ**AHD**ï¼‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹å±€é™æ€§ï¼š

- å¤šæ•°é‡‡ç”¨**ç§ç¾¤ç­–ç•¥**ï¼ˆå¦‚è¿›åŒ–ç®—æ³•ï¼‰ï¼Œå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼›
- è™½ç„¶å¼•å…¥äº† **Monte Carlo Tree Search (MCTS)** æ¥å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ï¼ˆå¦‚ MCTS-AHDï¼‰ï¼Œä½†ç¼ºä¹å¯¹å†å²ç»éªŒçš„æ·±åº¦æ•´åˆï¼›
- åæ€æœºåˆ¶å¤šä¸ºå•è½®æˆ–æµ…å±‚åé¦ˆï¼Œéš¾ä»¥å®ç°å¤šè½®è®¤çŸ¥è¿­ä»£ï¼›
- èŠ‚ç‚¹æ‰©å±•æ–¹å¼å•ä¸€ï¼Œé™åˆ¶äº†å¯å‘å¼ç©ºé—´çš„å¤šæ ·æ€§æ¢ç´¢ã€‚

è¿™äº›é—®é¢˜å¯¼è‡´æœç´¢æ•ˆç‡ä½ã€è§£çš„è´¨é‡ä¸ç¨³å®šã€ä¼˜åŒ–è¿‡ç¨‹ç¼ºä¹ç³»ç»Ÿæ€§è®¤çŸ¥å¼•å¯¼ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡ºäº†ä¸€ç§å…¨æ–°çš„æ¡†æ¶ï¼š**CogMCTS**ï¼ˆCognitive-guided MCTSï¼‰ï¼Œå…¶æ ¸å¿ƒæ˜¯å°† LLM çš„**è®¤çŸ¥èƒ½åŠ›**ä¸ MCTS çš„**æœç´¢æœºåˆ¶**æ·±åº¦èåˆï¼Œå½¢æˆä¸€ä¸ªé—­ç¯çš„ã€å¯è¿­ä»£çš„è®¤çŸ¥å¢å¼ºå‹å¯å‘å¼æ¼”åŒ–ç³»ç»Ÿã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

1. âœ… **å¤šè½®è®¤çŸ¥æŒ‡å¯¼æœºåˆ¶ï¼ˆMulti-round Cognitive Guidanceï¼‰**
   - å¼•å…¥â€œå¿«é€Ÿè®¤çŸ¥â€ï¼ˆrapid cognitionï¼‰ä¸â€œå¤æ‚è®¤çŸ¥â€ï¼ˆcomplex cognitionï¼‰ä¸¤ä¸ªé˜¶æ®µï¼š
     - å¿«é€Ÿè®¤çŸ¥ï¼šé€šè¿‡æˆå¯¹æ¯”è¾ƒå¯å‘å¼å‡½æ•°ï¼Œæå–æœ‰æ•ˆè®¾è®¡æ¨¡å¼ï¼›
     - å¤æ‚è®¤çŸ¥ï¼šèåˆæ­£å‘ç»éªŒï¼ˆpositive knowledgeï¼‰ã€è´Ÿå‘åé¦ˆï¼ˆnegative knowledgeï¼‰ä»¥åŠå½“å‰èŠ‚ç‚¹ä¿¡æ¯ï¼Œç”Ÿæˆç»“æ„åŒ–æç¤ºä»¥æŒ‡å¯¼ LLM æ”¹è¿›å¯å‘å¼ã€‚
   - åˆ©ç”¨ **Consistency-based Knowledge Validation (CKV)** åŠ¨æ€ç®¡ç†çŸ¥è¯†åº“ï¼Œé˜²æ­¢æ— æ•ˆç»éªŒç§¯ç´¯ã€‚

2. âœ… **åŒè½¨èŠ‚ç‚¹æ‰©å±•ç­–ç•¥ï¼ˆDual-track Node Expansionï¼‰**
   - åœ¨æ¯ä¸ªé€‰å®šèŠ‚ç‚¹ä¸Šå¹¶è¡Œæ‰§è¡Œä¸¤ç±»æ“ä½œï¼š
     - **em1/em2**ï¼šåŸºäºè®¤çŸ¥åé¦ˆè¿›è¡Œå¯å‘å¼ç»„åˆä¸æ”¹è¿›ï¼ˆexploitationï¼‰ï¼›
     - **m1/m2**ï¼šè¿›è¡Œç»“æ„çªå˜ï¼ˆstructural mutationï¼‰å’Œå‚æ•°è°ƒä¼˜ï¼ˆparameter tuningï¼‰ï¼ˆexplorationï¼‰ï¼›
   - å¹¶ç»“åˆ **elite heuristic management**ï¼Œä¿ç•™é«˜è´¨é‡å¯å‘å¼ï¼Œæå‡ç¨³å®šæ€§ã€‚

3. âœ… **æˆ˜ç•¥çªå˜æœºåˆ¶ï¼ˆStrategic Mutationï¼‰**
   - m1 å’Œ m2 æ“ä½œå…è®¸åœ¨ç®—æ³•å½¢å¼æˆ–å‚æ•°å±‚é¢å¼•å…¥å˜åŒ–ï¼Œæ˜¾è‘—å¢å¼ºäº†è§£çš„å¤šæ ·æ€§ï¼Œé¿å…æ—©ç†Ÿæ”¶æ•›ã€‚

4. âœ… **ç´§å¯†é›†æˆæ¶æ„**
   - å°† LLM çš„æ¨ç†èƒ½åŠ›åµŒå…¥ MCTS çš„æ¯ä¸€æ­¥ï¼ˆé€‰æ‹©ã€æ‰©å±•ã€æ¨¡æ‹Ÿã€å›ä¼ ï¼‰ï¼Œå®ç°çœŸæ­£çš„â€œè®¤çŸ¥é©±åŠ¨æœç´¢â€ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | CogMCTS | ä¼ ç»Ÿ LLM-EPS / MCTS-AHD |
|------|--------|--------------------------|
| æ¢ç´¢-åˆ©ç”¨å¹³è¡¡ | æ›´ä¼˜ï¼ˆåŒè½¨æ‰©å±• + UCTï¼‰ | ä¸€èˆ¬ï¼ˆå•è·¯å¾„æ‰©å±•ï¼‰ |
| å†å²ç»éªŒåˆ©ç”¨ | å¤šè½®åé¦ˆ + æ­£/è´ŸçŸ¥è¯†ç®¡ç† | å•æ¬¡æˆ–æµ…å±‚åæ€ |
| å¤šæ ·æ€§ä¿éšœ | ç»“æ„çªå˜ + å‚æ•°è°ƒä¼˜ | ä¾èµ–ç§ç¾¤å¤šæ ·æ€§ |
| é²æ£’æ€§ä¸ç¨³å®šæ€§ | æ˜¾è‘—æ›´é«˜ | æ˜“å—åˆå§‹ç§å­å½±å“ |

> CogMCTS å®ç°äº†æ›´é«˜æ•ˆã€ç¨³å®šä¸”é«˜è´¨é‡çš„å¯å‘å¼è‡ªåŠ¨è®¾è®¡ï¼Œåœ¨å¤šä¸ªä»»åŠ¡ä¸­è¶…è¶Šç°æœ‰ SOTA æ–¹æ³•ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸é—®é¢˜ç±»å‹**

å®éªŒè¦†ç›–å¤šç§ç»å…¸çš„ **NP-hard ç»„åˆä¼˜åŒ–é—®é¢˜ï¼ˆCOPsï¼‰**ï¼Œåˆ†åˆ«åœ¨ä¸åŒæ±‚è§£æ¡†æ¶ä¸‹æµ‹è¯•ï¼š

| é—®é¢˜ | æ•°æ®è§„æ¨¡ | æ¡†æ¶ |
|------|---------|-------|
| **Orienteering Problem (OP)** | N=50, 100 | ACO |
| **Capacitated Vehicle Routing Problem (CVRP)** | N=50, 100 | ACO |
| **Multiple Knapsack Problem (MKP)** | N=100/200, m=5 | ACO |
| **Traveling Salesman Problem (TSP)** | N=20â€“200 | GLS |
| **Knapsack Problem (KP)** | N=50â€“500 | Step-by-step Construction |

æ‰€æœ‰æµ‹è¯•é›†å‡åŒ…å«å¤§é‡ç‹¬ç«‹å®ä¾‹ï¼ˆ64â€“1000ï¼‰ï¼Œç¡®ä¿ç»Ÿè®¡å¯é æ€§ã€‚

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

- **LLM æ¨¡å‹**ï¼šGPT-3.5-turbo å’Œ GPT-4o-miniï¼›
- **è¯„ä¼°é¢„ç®—**ï¼šT = 1000 æ¬¡å¯å‘å¼è¯„ä¼°ï¼›
- **è¿è¡Œæ¬¡æ•°**ï¼šæ¯ä¸ªé…ç½®ç‹¬ç«‹è¿è¡Œ 3 æ¬¡å–å¹³å‡ï¼›
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **ç›®æ ‡å€¼ï¼ˆObj.ï¼‰**ï¼šè¶Šå°è¶Šå¥½ï¼ˆâ†“ï¼‰æˆ–è¶Šå¤§è¶Šå¥½ï¼ˆâ†‘ï¼‰
  - **ç›¸å¯¹å·®è·ï¼ˆGapï¼‰**ï¼šç›¸å¯¹äºæœ€ä¼˜æˆ–æœ€ä½³åŸºçº¿çš„ç™¾åˆ†æ¯”å·®å¼‚ï¼›
  - **æœ€ä¼˜è§£å‘ç°ç‡**ï¼šæ˜¯å¦è¾¾åˆ°å…¨å±€æœ€ä¼˜ï¼›
  - **è¿›åŒ–æ›²çº¿**ï¼šå±•ç¤ºæ”¶æ•›é€Ÿåº¦ä¸ç¨³å®šæ€§ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

åˆ†ä¸ºä¸‰ç±»ï¼š

1. ğŸ”§ **æ‰‹å·¥è®¾è®¡å¯å‘å¼**
   - ACO, Greedy Construct (GC)

2. ğŸ¤– **ç¥ç»ç»„åˆä¼˜åŒ–ï¼ˆNCOï¼‰æ–¹æ³•**
   - DeepACO, POMO, KGLS, NeuOpt, GNNGLS, NeuralGLS

3. ğŸ§  **LLM-based AHD æ–¹æ³•**
   - FunSearch
   - EoH (Evolution of Heuristics)
   - ReEvo (Reflective Evolution)
   - MCTS-AHDï¼ˆæœ€æ–° MCTS ç±»æ–¹æ³•ï¼‰

> æ‰€æœ‰ LLM-based æ–¹æ³•ä½¿ç”¨ç›¸åŒåˆå§‹ç§å­ã€è®­ç»ƒé›†å’Œè¯„ä¼°æµç¨‹ï¼Œä¿è¯å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

#### è¡¨æ ¼ 1 & 2ï¼šACO æ¡†æ¶ä¸‹çš„ OPã€CVRPã€MKP ç»“æœï¼ˆéƒ¨åˆ†æ‘˜å½•ï¼‰

| æ–¹æ³• | OP (N=50) Obj. | Gap | MKP (N=200) Obj. | Gap |
|------|---------------|-----|------------------|-----|
| ACO | 13.354 | 2.78% | 40.672 | 4.40% |
| DeepACO | 19.867 | 0.00% | 41.988 | 1.30% |
| EoH | 15.293 | 23.02% | 41.994 | 1.29% |
| ReEvo | 15.224 | 23.37% | 42.416 | 0.30% |
| MCTS-AHD | 15.186 | 23.56% | 42.498 | 0.11% |
| **CogMCTS (Ours)** | **15.370** | **22.63%** | **42.542** | **0.00%** âœ… |

> åœ¨ MKP ä¸Šï¼ŒCogMCTS è¾¾åˆ°ç»å¯¹æœ€ä¼˜ï¼ˆGap=0%ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚

#### è¡¨æ ¼ 2ï¼šGLS æ¡†æ¶ä¸‹çš„ TSP ç»“æœï¼ˆGap %ï¼‰

| æ–¹æ³• | N=20 | N=50 | N=100 | N=200 |
|------|------|------|-------|-------|
| KGLS | 0.004% | 0.017% | 0.002% | 0.284% |
| NeuOpt | 0.000% | 0.000% | 0.027% | 0.403% |
| ReEvo | 0.000% | 0.001% | 0.009% | 0.278% |
| MCTS-AHD | 0.000% | 0.011% | 0.005% | 0.295% |
| **CogMCTS (Ours)** | 0.015% | **0.000%** âœ… | **0.000%** âœ… | **0.242%** âœ… |

> CogMCTS åœ¨å¤šæ•° TSP è§„æ¨¡ä¸Šè¡¨ç°æœ€ä½³ï¼Œå°¤å…¶åœ¨å¤§å°ºåº¦é—®é¢˜ï¼ˆN=100,200ï¼‰ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚

#### è¡¨æ ¼ 3ï¼šStep-by-step æ¡†æ¶ä¸‹çš„ KP ç»“æœï¼ˆGap %ï¼‰

| æ–¹æ³• | N=50 | N=100 | N=200 | N=500 |
|------|------|-------|-------|-------|
| POMO | 0.00% | 0.00% | 0.00% | 0.00% |
| FunSearch | 0.260% | 0.114% | 0.092% | 0.055% |
| MCTS-AHD | 0.205% | 0.089% | 0.078% | 0.051% |
| **CogMCTS (Ours)** | **0.200%** | **0.089%** | **0.075%** âœ… | **0.051%** âœ… |

> åœ¨æœ€å¤§è§„æ¨¡ï¼ˆN=500ï¼‰ä¸‹ä»ä¿æŒæœ€ä½ Gapï¼Œæ˜¾ç¤ºå¼ºæ³›åŒ–èƒ½åŠ›ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- åœ¨ **æ‰€æœ‰ä»»åŠ¡** ä¸­ï¼ŒCogMCTS å‡ä¼˜äºæˆ–æŒå¹³äºæœ€å¼ºåŸºçº¿ï¼›
- ç›¸æ¯” **MCTS-AHD**ï¼ŒCogMCTS åœ¨ï¼š
  - æ›´å¿«åœ°æ‰¾åˆ°é«˜è´¨é‡å¯å‘å¼ï¼ˆè§å›¾3 è¿›åŒ–æ›²çº¿ï¼‰ï¼›
  - æ›´é«˜é¢‘ç‡å‘ç°å…¨å±€æœ€ä¼˜è§£ï¼›
  - æ›´ç¨³å®šçš„æ€§èƒ½è¾“å‡ºï¼ˆä¸‰æ¬¡è¿è¡Œæ–¹å·®å°ï¼‰ï¼›
- ç›¸æ¯” **ReEvo/EoH**ï¼ŒCogMCTS é¿å…äº†æ—©æœŸåœæ»ï¼ˆå¦‚ ReEvo åœ¨ KP ä¸Šä»…ç”Ÿæˆä¸€ä¸ªä¸ªä½“å³åœæ­¢ï¼‰ï¼›

> å›¾3 æ˜¾ç¤º CogMCTS åœ¨å‰ 200 æ¬¡è¯„ä¼°å†…è¿…é€Ÿä¸Šå‡ï¼Œå¹¶æŒç»­ä¼˜åŒ–ï¼Œè€Œå…¶ä»–æ–¹æ³•å¢é•¿ç¼“æ…¢æˆ–æ—©åœã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

#### è¡¨æ ¼ 6ï¼šç§»é™¤ä¸åŒåŠ¨ä½œçš„å½±å“ï¼ˆKP ä»»åŠ¡ï¼ŒGap %ï¼‰

| å˜ä½“ | em1 | em2 | m1 | m2 | Gap (%) |
|------|-----|-----|----|----|--------|
| å®Œæ•´æ¨¡å‹ | âˆš | âˆš | âˆš | âˆš | **0.089%** |
| ç§»é™¤ em1 | Ã— | âˆš | âˆš | âˆš | 0.117% |
| ç§»é™¤ em2 | âˆš | Ã— | âˆš | âˆš | 0.097% |
| ç§»é™¤ em1+em2 | Ã— | Ã— | âˆš | âˆš | 0.102% |

> ç»“è®ºï¼š
- **em1 å’Œ em2 æ˜¯æœ€å…³é”®ç»„ä»¶**ï¼Œè´Ÿè´£è®¤çŸ¥é©±åŠ¨çš„å¯å‘å¼æ”¹è¿›ï¼›
- ç¼ºå¤±ä»»ä¸€éƒ½ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼›
- åŒæ—¶ç¼ºå¤±åˆ™é€€åŒ–ä¸¥é‡ï¼Œè¯´æ˜è®¤çŸ¥åé¦ˆæœºåˆ¶ä¸å¯æˆ–ç¼ºã€‚

æ­¤å¤–ï¼ŒCKV çŸ¥è¯†éªŒè¯æœºåˆ¶çš„æœ€ä½³çª—å£é•¿åº¦ä¸º **m-k=2**ï¼ˆå³ä¸¤è½®æ€è€ƒå‘¨æœŸï¼‰ï¼Œè¿‡çŸ­æˆ–è¿‡é•¿å‡é™ä½æ•ˆæœï¼ˆè§è¡¨4ã€5ï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **CogMCTS æ˜¾è‘—æå‡äº† LLM-based AHD çš„æ€§èƒ½ä¸Šé™**ï¼š
   - åœ¨å¤šä¸ª COP ä»»åŠ¡ä¸­è¾¾åˆ°æˆ–é€¼è¿‘æœ€ä¼˜è§£ï¼›
   - æ”¶æ•›é€Ÿåº¦å¿«ã€ç¨³å®šæ€§é«˜ã€é²æ£’æ€§å¼ºã€‚

2. âœ… **è®¤çŸ¥æœºåˆ¶çš„æœ‰æ•ˆæ€§è¢«éªŒè¯**ï¼š
   - å¤šè½®åé¦ˆ + æ­£/è´ŸçŸ¥è¯†ç®¡ç†èƒ½æ˜¾è‘—æå‡å¯å‘å¼ç”Ÿæˆè´¨é‡ï¼›
   - â€œå¿«é€Ÿè®¤çŸ¥ + å¤æ‚è®¤çŸ¥â€ æ„æˆäº†æœ‰æ•ˆçš„å…ƒå­¦ä¹ å¾ªç¯ã€‚

3. âœ… **åŒè½¨æ‰©å±• + æˆ˜ç•¥çªå˜å¢å¼ºäº†å¤šæ ·æ€§**ï¼š
   - é¿å…æ—©ç†Ÿæ”¶æ•›ï¼›
   - å®ç°äº†æ¢ç´¢ä¸åˆ©ç”¨çš„åŠ¨æ€å¹³è¡¡ã€‚

4. âœ… **æ¡†æ¶å…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§å’Œé€‚åº”æ€§**ï¼š
   - æˆåŠŸåº”ç”¨äº ACOã€GLSã€Step-by-step ä¸‰ç§ä¸»æµæ¡†æ¶ï¼›
   - å¯è¿ç§»è‡³ä¸åŒé—®é¢˜ç±»å‹å’Œè§„æ¨¡ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- âš ï¸ **è®¡ç®—æˆæœ¬è¾ƒé«˜**ï¼šæ¯æ¬¡å¯å‘å¼ç”Ÿæˆéœ€å¤šæ¬¡è°ƒç”¨ LLMï¼Œå—é™äº API å»¶è¿Ÿä¸è´¹ç”¨ï¼›
- âš ï¸ **ä¾èµ–é«˜è´¨é‡æç¤ºå·¥ç¨‹**ï¼šè®¤çŸ¥åé¦ˆçš„è®¾è®¡å¯¹æœ€ç»ˆæ€§èƒ½æœ‰è¾ƒå¤§å½±å“ï¼›
- âš ï¸ **CKV æœºåˆ¶å‡è®¾è¾ƒå¼º**ï¼šè¦æ±‚å…¨å±€æœ€ä¼˜è§£å¯æ¯”è¾ƒï¼Œå¯èƒ½ä¸é€‚ç”¨äºé«˜åº¦éšæœºç¯å¢ƒï¼›
- âš ï¸ **æœªåœ¨è¶…å¤§è§„æ¨¡é—®é¢˜ï¼ˆå¦‚ N > 1000ï¼‰ä¸ŠéªŒè¯**ï¼Œæ³›åŒ–è¾¹ç•Œå°šå¾…æ¢ç´¢ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. ğŸ” **æå‡è®¤çŸ¥æœºåˆ¶æ•ˆç‡**ï¼š
   - æ¢ç´¢è½»é‡çº§æ¨¡æ‹Ÿç­–ç•¥ï¼ˆå¦‚ Gumbel-MCTSï¼‰åŠ é€Ÿæœç´¢ï¼›
   - è®¾è®¡æ›´é«˜æ•ˆçš„åé¦ˆå‹ç¼©ä¸å­˜å‚¨æœºåˆ¶ã€‚

2. ğŸ§  **æ‰©å±•è‡³æ›´å¤æ‚çš„ä¼˜åŒ–åœºæ™¯**ï¼š
   - å¤šç›®æ ‡ä¼˜åŒ–ï¼ˆMO-COPsï¼‰ï¼›
   - åŠ¨æ€/åœ¨çº¿ä¼˜åŒ–é—®é¢˜ï¼›
   - å®é™…å·¥ä¸šåº”ç”¨ï¼ˆç‰©æµè°ƒåº¦ã€èŠ¯ç‰‡å¸ƒçº¿ç­‰ï¼‰ã€‚

3. ğŸ”„ **æ„å»ºç«¯åˆ°ç«¯è‡ªåŠ¨åŒ– pipeline**ï¼š
   - è‡ªåŠ¨åŒ–æç¤ºç”Ÿæˆï¼›
   - åŠ¨æ€è°ƒæ•´ MCTS å‚æ•°ï¼ˆå¦‚ exploration decayï¼‰ï¼›
   - æ”¯æŒå¤š LLM ååŒæ¼”åŒ–ã€‚

4. ğŸ’¡ **ç†è®ºåˆ†æ**ï¼š
   - åˆ†æ CogMCTS çš„æ”¶æ•›æ€§ä¸æ ·æœ¬å¤æ‚åº¦ï¼›
   - å»ºç«‹è®¤çŸ¥åé¦ˆä¸æœç´¢æ•ˆç‡ä¹‹é—´çš„æ•°å­¦å…³ç³»ã€‚

---

> **æ€»ç»“**ï¼šCogMCTS æ˜¯é¦–ä¸ªå°† LLM çš„**æ·±å±‚è®¤çŸ¥èƒ½åŠ›**ä¸ MCTS çš„**ç³»ç»Ÿæ€§æœç´¢èƒ½åŠ›**ç´§å¯†ç»“åˆçš„ AHD æ¡†æ¶ã€‚å®ƒä¸ä»…åœ¨æ€§èƒ½ä¸Šå…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œæ›´ä¸ºâ€œè¯­è¨€æ¨¡å‹ä½œä¸ºä¼˜åŒ–å™¨â€çš„ç ”ç©¶æä¾›äº†æ–°çš„èŒƒå¼â€”â€”ä»â€œè¢«åŠ¨ç”Ÿæˆâ€èµ°å‘â€œä¸»åŠ¨æ€è€ƒâ€ã€‚

</details>

---

### 3. [MobileFineTuner: A Unified End-to-End Framework for Fine-Tuning LLMs on Mobile Phones](https://arxiv.org/abs/2512.08211)

**Authors**: Jiaxiang Geng, Lunyu Zhao, Yiyi Lu, Bing Luo  
**Category**: cs.LG  
**Published**: 2025-12-10  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.08211v1  

#### Abstract
Mobile phones are the most ubiquitous end devices, generating vast amounts of human-authored data and serving as the primary platform for end-side applications. As high-quality public data for large language models (LLMs) approaches exhaustion, on-device fine-tuning provides an opportunity to levera...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MobileFineTuner: A Unified End-to-End Framework for Fine-Tuning LLMs on Mobile Phones è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¾èµ–é«˜è´¨é‡å…¬å…±æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä½†ç ”ç©¶è¡¨æ˜è¿™ç±»æ•°æ®å¯èƒ½åœ¨2026â€“2032å¹´é—´è€—å°½ã€‚ä¸æ­¤åŒæ—¶ï¼Œæµ·é‡æœ‰ä»·å€¼çš„**ç§æœ‰ç”¨æˆ·æ•°æ®**ï¼ˆå¦‚èŠå¤©è®°å½•ã€ç¬”è®°ç­‰ï¼‰å­˜å‚¨åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šï¼Œå…·æœ‰æé«˜çš„ä¸ªæ€§åŒ–æ½œåŠ›ã€‚ç„¶è€Œï¼Œå°†è¿™äº›æ•æ„Ÿæ•°æ®ä¸Šä¼ è‡³æœåŠ¡å™¨è¿›è¡Œ fine-tuning å­˜åœ¨ä¸¥é‡çš„**éšç§é£é™©**ï¼Œå¹¶å¯èƒ½è¿å GDPR ç­‰æ³•è§„ã€‚

å°½ç®¡å·²æœ‰ç ”ç©¶æ¢ç´¢åŸºäºè”é‚¦å­¦ä¹ æˆ–ä¸ªæ€§åŒ–å­¦ä¹ çš„ on-device fine-tuningï¼Œä½†å¤§å¤šæ•°å·¥ä½œä»åœç•™åœ¨ä»¿çœŸç¯å¢ƒã€IoT å¼€å‘æ¿æˆ– PC ä¸Šï¼Œ**ç¼ºä¹å¯¹æ™®é€šå•†ç”¨æ‰‹æœºçš„å®é™…æ”¯æŒ**ã€‚å…¶æ ¹æœ¬åŸå› åœ¨äºä¸»æµæ¡†æ¶ï¼ˆå¦‚ PyTorchã€Hugging Face Transformersï¼‰åŸºäº Pythonï¼Œè€Œç§»åŠ¨æ“ä½œç³»ç»Ÿï¼ˆå¦‚ Androidï¼‰ä¸åŸç”Ÿæ”¯æŒ Pythonï¼Œå¯¼è‡´éƒ¨ç½²å›°éš¾ã€‚

å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š
> **å¦‚ä½•æ„å»ºä¸€ä¸ªé«˜æ•ˆã€å¯æ‰©å±•ä¸”æ˜“ç”¨çš„å¼€æºæ¡†æ¶ï¼Œå®ç°çœŸæ­£æ„ä¹‰ä¸Šçš„ç«¯åˆ°ç«¯ LLM fine-tuning åœ¨æ™®é€šç§»åŠ¨æ‰‹æœºä¸Šçš„è½åœ°ï¼Ÿ**

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº† **MobileFineTuner** â€”â€” é¦–ä¸ªç»Ÿä¸€çš„ã€å¼€æºçš„ã€å¯åœ¨å•†ç”¨æ‰‹æœºä¸Šç›´æ¥æ‰§è¡Œ LLM fine-tuning çš„ç«¯åˆ°ç«¯æ¡†æ¶ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

1. **å…¨ C++ å®ç°çš„è½»é‡çº§æ¡†æ¶**
   - å®Œå…¨æ‘’å¼ƒ Python è¿è¡Œæ—¶å’Œè™šæ‹Ÿæœºï¼ˆVMï¼‰ï¼Œé¿å… Termux æˆ– ONNX Python API ç­‰ä½æ•ˆä¸­é—´å±‚ã€‚
   - è‡ªä¸»å®ç°è‡ªåŠ¨å¾®åˆ†ï¼ˆautomatic differentiationï¼‰ã€åå‘ä¼ æ’­ï¼ˆbackpropagationï¼‰åŠå¼ é‡è¿ç®—ç³»ç»Ÿï¼Œæ˜¾è‘—é™ä½è¿è¡Œæ—¶å¼€é”€å’Œå†…å­˜å ç”¨ã€‚

2. **æ¨¡å—åŒ–å››å±‚æ¶æ„è®¾è®¡**
   - åˆ†ä¸º Basic Layerï¼ˆåº•å±‚ç®—å­ï¼‰ã€Intermediate Layerï¼ˆç½‘ç»œç»„ä»¶ï¼‰ã€Abstract Layerï¼ˆä¼˜åŒ–å™¨ä¸æŠ½è±¡æ¥å£ï¼‰ã€Application Layerï¼ˆæ¨¡å‹å®šä¹‰ä¸ä»»åŠ¡æ‰§è¡Œï¼‰ï¼Œä¾¿äºæ‰©å±•ä¸å®šåˆ¶ã€‚

3. **æ”¯æŒ Full-FT å’Œ PEFTï¼ˆå¦‚ LoRAï¼‰**
   - æ”¯æŒå®Œæ•´çš„å‚æ•°å¾®è°ƒï¼ˆFull-Parameter Fine-Tuningï¼‰å’Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆParameter-Efficient Fine-Tuningï¼‰ï¼Œæ»¡è¶³ä¸åŒåœºæ™¯éœ€æ±‚ã€‚

4. **é’ˆå¯¹ç§»åŠ¨ç«¯èµ„æºé™åˆ¶çš„ç³»ç»Ÿçº§ä¼˜åŒ–**
   - **å†…å­˜ä¼˜åŒ–**ï¼š
     - å‚æ•°åˆ†ç‰‡ï¼ˆZeRO-inspired parameter shardingï¼‰ï¼šå°†éæ´»è·ƒå‚æ•°å¸è½½è‡³ç£ç›˜ï¼Œç¼“è§£ RAM å‹åŠ›ã€‚
     - æ¢¯åº¦ç´¯ç§¯ï¼ˆGradient accumulationï¼‰ï¼šé€šè¿‡ micro-batch å¤„ç†å¤§ batchï¼Œå¹³è¡¡å†…å­˜ä½¿ç”¨ä¸è®­ç»ƒç¨³å®šæ€§ã€‚
   - **èƒ½è€—ä¼˜åŒ–**ï¼š
     - èƒ½é‡æ„ŸçŸ¥è®¡ç®—è°ƒåº¦å™¨ï¼ˆEnergy-aware computation schedulerï¼‰ï¼šæ ¹æ®ç”µæ± ç”µé‡åŠ¨æ€è°ƒæ•´è®¡ç®—é¢‘ç‡ï¼Œåœ¨ä½ç”µé‡æ—¶å¼•å…¥ sleep å»¶è¿Ÿä»¥å»¶é•¿ç»­èˆªã€‚

5. **é«˜å¯ç”¨æ€§ä¸å…¼å®¹æ€§**
   - æä¾›ç®€æ´çš„é«˜å±‚ APIï¼Œç±»ä¼¼ PyTorch é£æ ¼ï¼Œé™ä½å¼€å‘é—¨æ§›ã€‚
   - æ”¯æŒä» Hugging Face ä¸‹è½½ `.bin` æˆ– `.safetensors` æ ¼å¼çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¹¶è¾“å‡ºç›¸åŒæ ¼å¼ï¼Œä¾¿äºä¸ç°æœ‰ç”Ÿæ€é›†æˆã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹æ³• | æ˜¯å¦çœŸæ­£åœ¨æ‰‹æœºä¸Šè¿è¡Œ | æ˜¯å¦æ”¯æŒ fine-tuning | æ˜¯å¦å¼€æº | æ•ˆç‡ | å¯æ‰©å±•æ€§ |
|------|------------------------|-----------------------|-----------|--------|------------|
| PyTorch / Transformers | âŒï¼ˆéœ€ VMï¼‰ | âœ… | âœ… | â¬‡ï¸ ä½ï¼ˆä¾èµ– Pythonï¼‰ | âœ… |
| PocketLLM [22] | âœ…ï¼ˆTermux VMï¼‰ | âœ…ï¼ˆä»…å‰å‘ï¼‰ | âŒ | â¬‡ï¸ ä½ï¼ˆVM å¼€é”€ï¼‰ | âŒ |
| XPerT [34] | âœ…ï¼ˆONNX + Javaï¼‰ | âœ… | âŒ | â¬‡ï¸ ä¸­ï¼ˆç¦»çº¿è½¬æ¢æˆæœ¬é«˜ï¼‰ | âŒ |
| **MobileFineTunerï¼ˆæœ¬æ–‡ï¼‰** | âœ… | âœ…ï¼ˆFull-FT & PEFTï¼‰ | âœ… | âœ… é«˜ï¼ˆçº¯ C++ï¼‰ | âœ… |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šé¦–æ¬¡å®ç°åœ¨çœŸå®æ‰‹æœºä¸Šçš„é«˜æ•ˆã€çµæ´»ã€å¯å¤ç°çš„ LLM å¾®è°ƒï¼›æ— éœ€ä¾èµ–å¤–éƒ¨æ¡†æ¶æˆ–å¤æ‚å·¥ç¨‹æµç¨‹ï¼›å…·å¤‡å®Œæ•´çš„ç³»ç»Ÿçº§ä¼˜åŒ–èƒ½åŠ›ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

1. **WikiText-2**
   - æ–‡æœ¬ç”Ÿæˆä»»åŠ¡åŸºå‡†æ•°æ®é›†ï¼Œçº¦å« 200 ä¸‡ tokenï¼Œæ¥æºäºç»´åŸºç™¾ç§‘æ–‡ç« ã€‚
   - è¯„ä¼°æŒ‡æ ‡ï¼šPerplexityï¼ˆPPLï¼‰ã€è®­ç»ƒæŸå¤±ï¼ˆLossï¼‰ã€‚

2. **MMLUï¼ˆMassive Multitask Language Understandingï¼‰**
   - å¤šä»»åŠ¡ç†è§£åŸºå‡†ï¼Œæ¶µç›–å†å²ã€ç§‘å­¦ã€æ–‡å­¦ç­‰ 57 ä¸ªé¢†åŸŸã€‚
   - è¯„ä¼°æ–¹å¼ï¼šè¾“å…¥é—®é¢˜ä¸é€‰é¡¹ï¼Œæ¨¡å‹ç”Ÿæˆç­”æ¡ˆåæå–é¢„æµ‹ç»“æœï¼Œè®¡ç®—å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

#### è®¾å¤‡é…ç½®ï¼ˆè§ Table 3ï¼‰
- **Android æ‰‹æœº**ï¼š
  - Google Pixel 8ï¼ˆ8GB RAMï¼‰
  - Pixel 7 Proï¼ˆ12GB RAMï¼‰
  - Pixel 8 Proï¼ˆ12GB RAMï¼‰
- **å¯¹æ¯”è®¾å¤‡**ï¼š
  - MacBook Air 2023ï¼ˆApple M2, 16GB RAM, æ”¯æŒè™šæ‹Ÿå†…å­˜ï¼‰

æ‰€æœ‰å®éªŒå‡åœ¨ Android 10+ï¼ˆAPI level â‰¥ 29ï¼‰ç¯å¢ƒä¸‹è¿è¡Œã€‚

#### æ¨¡å‹é€‰æ‹©
ç”±äº fine-tuning å¯¹èµ„æºè¦æ±‚è¿œé«˜äºæ¨ç†ï¼Œä½œè€…èšç„¦äºé€‚åˆè¾¹ç¼˜è®¾å¤‡çš„å°è§„æ¨¡ LLMsï¼š
- GPT2-small (124M)
- GPT2-medium (355M)
- Qwen2.5-0.5B
- Gemma3-270M
- Gemma3-1B

#### è¯„ä¼°æŒ‡æ ‡
- **ç³»ç»Ÿå±‚é¢**ï¼š
  - Peak RSSï¼ˆå³°å€¼é©»ç•™é›†å¤§å°ï¼Œè¡¡é‡æœ€å¤§å†…å­˜å ç”¨ï¼‰
  - Average RSSï¼ˆå¹³å‡å†…å­˜å ç”¨ï¼‰
  - Power consumptionï¼ˆåŠŸè€—ç›‘æµ‹ï¼‰
- **æ¨¡å‹æ€§èƒ½å±‚é¢**ï¼š
  - Final fine-tuning loss
  - Perplexityï¼ˆPPLï¼‰ for WikiText-2
  - Accuracy (%) for MMLU

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **PyTorchï¼ˆæœåŠ¡å™¨ç«¯å®ç°ï¼‰**ï¼šä½œä¸ºæ€§èƒ½åŸºå‡†ï¼ŒéªŒè¯ MobileFineTuner çš„æ­£ç¡®æ€§å’Œæ”¶æ•›ä¸€è‡´æ€§ã€‚
- ä¸åŒé…ç½®ä¸‹çš„æ¶ˆèå®éªŒç”¨äºéªŒè¯å„é¡¹ä¼˜åŒ–çš„æœ‰æ•ˆæ€§ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Tables 4â€“6ï¼‰

| æ¨¡å‹ | æ•°æ®é›† | MobileFineTuner PPL | PyTorch PPL | å·®è· |
|------|--------|---------------------|-------------|------|
| GPT2-124M | WikiText-2 | 11.79 | 25.77 | âœ… æ˜¾è‘—æ›´ä¼˜ |
| GPT2-355M | WikiText-2 | 8.20 | 18.08 | âœ… æ›´ä¼˜ |
| Gemma3-1B | WikiText-2 | 13.77 | 11.56 | â– æ¥è¿‘ |
| Gemma3-1B | MMLU | 39.02% Acc | 41.47% Acc | å°å¹…å·®è· |

> æ³¨ï¼šéƒ¨åˆ†æƒ…å†µä¸‹ MobileFineTuner è¡¨ç°ä¼˜äº PyTorchï¼Œå¯èƒ½æ˜¯ç”±äºè®­ç»ƒè¿‡ç¨‹ä¸­çš„æ•°å€¼ç²¾åº¦å·®å¼‚æˆ–ä¼˜åŒ–è·¯å¾„ä¸åŒæ‰€è‡´ã€‚

#### å†…å­˜æ¶ˆè€—è¡¨ç°ï¼ˆTable 4 & 5ï¼‰
- åœ¨ **Pixel 8ï¼ˆ8GB RAMï¼‰** ä¸ŠæˆåŠŸè¿è¡Œ GPT2-124M å’Œ Gemma3-270Mï¼Œä½†åœ¨å°è¯•æ›´å¤§æ¨¡å‹ï¼ˆå¦‚ GPT2-355Mï¼‰æ—¶å› å†…å­˜ä¸è¶³å´©æºƒã€‚
- **MacBook Air** å‡­å€Ÿè™šæ‹Ÿå†…å­˜æœºåˆ¶å¯è¿è¡Œæ‰€æœ‰æ¨¡å‹ã€‚
- ç¤ºä¾‹ï¼šGPT2-355M @ WikiText-2
  - Peak RSS â‰ˆ 8.8 GB â†’ è¶…å‡º Pixel 8 å®é™…å¯ç”¨å†…å­˜ â†’ å¤±è´¥

---

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

- **è®­ç»ƒæ›²çº¿é«˜åº¦ä¸€è‡´**ï¼ˆFigures 4â€“6ï¼‰ï¼š
  - MobileFineTuner ä¸ PyTorch çš„ loss æ›²çº¿å‡ ä¹é‡åˆï¼Œè¡¨æ˜å…¶å®ç°æ˜¯**æ­£ç¡®ä¸”å¯é çš„**ã€‚
  - å°½ç®¡ç¡¬ä»¶å¹³å°å®Œå…¨ä¸åŒï¼ˆæ‰‹æœº vs æœåŠ¡å™¨ï¼‰ï¼Œæœ€ç»ˆæ”¶æ•›å€¼åŸºæœ¬ä¸€è‡´ã€‚

- **è·¨è®¾å¤‡ä¸€è‡´æ€§è‰¯å¥½**ï¼š
  - åŒä¸€æ¨¡å‹åœ¨ä¸åŒæ‰‹æœºï¼ˆPixel 7 Pro vs Pixel 8 Proï¼‰ä¸Šè¡¨ç°å‡ºç›¸ä¼¼çš„ RSS å’Œ loss è¶‹åŠ¿ï¼Œè¯´æ˜æ¡†æ¶å…·å¤‡è‰¯å¥½çš„**å¯ç§»æ¤æ€§**ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰å‚æ•°åˆ†ç‰‡ï¼ˆParameter Shardingï¼‰æ•ˆæœï¼ˆFigure 7ï¼‰
| æ¨¡å‹ | æ— åˆ†ç‰‡ Avg RSS | æœ‰åˆ†ç‰‡ Avg RSS | é™å¹… |
|------|----------------|----------------|-------|
| GPT2-124M | 1945 MB | 1631 MB | ~16% â†“ |
| GPT2-355M | 3603 MB | 3462 MB | ~4% â†“ |
| Gemma3-270M | 5060 MB | 4719 MB | ~7% â†“ |
| Gemma3-1B | 11448 MB | 10782 MB | ~6% â†“ |

âœ… ç»“è®ºï¼šå‚æ•°åˆ†ç‰‡èƒ½æœ‰æ•ˆå‡å°‘å†…å­˜å ç”¨ï¼Œå°¤å…¶å¯¹å°æ¨¡å‹æå‡æ˜æ˜¾ã€‚

#### ï¼ˆ2ï¼‰æ¢¯åº¦ç´¯ç§¯ï¼ˆGradient Accumulationï¼‰æ•ˆæœï¼ˆFigure 8 & Table 7ï¼‰
æµ‹è¯•é…ç½®ï¼šæ€» batch size = 8ï¼Œmicro-batch åˆ†åˆ«ä¸º b4a2ã€b2a4ã€b1a8

| é…ç½® | Peak RSS | Final Loss | Final PPL | æ”¶æ•›æ­¥æ•° |
|------|----------|------------|-----------|-----------|
| b4a2 | 6082 MB | 3.37 | 29.27 | 1219 |
| b2a4 | 5315 MB | 3.22 | 25.24 | 1218 |
| b1a8 | 4808 MB | 3.28 | 26.79 | 1218 |

âœ… ç»“è®ºï¼š
- éšç€ micro-batch å‡å°ï¼Œ**Peak RSS æ˜¾è‘—ä¸‹é™**ï¼ˆæœ€é«˜é™ 21%ï¼‰ï¼›
- æœ€ç»ˆ loss å’Œ PPL å·®å¼‚å¾ˆå°ï¼Œ**è®­ç»ƒç¨³å®šæ€§æœªå—å½±å“**ï¼›
- æ”¶æ•›é€Ÿåº¦ä¸€è‡´ â†’ è¯æ˜æ¢¯åº¦ç´¯ç§¯å¯åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹å¤§å¹…èŠ‚çœå†…å­˜ã€‚

#### ï¼ˆ3ï¼‰èƒ½é‡æ„ŸçŸ¥è°ƒåº¦ï¼ˆComputation Schedulingï¼‰æ•ˆæœï¼ˆFigure 9ï¼‰
- è®¾ç½®ï¼šå½“ç”µæ± ä½äº 60% æ—¶ï¼Œè®¡ç®—é¢‘ç‡é™ä½ 50%
- ç»“æœï¼šåœ¨ç¬¬ 53 æ­¥ï¼ˆçº¦ 4 å°æ—¶åï¼‰è§¦å‘èŠ‚èƒ½æ¨¡å¼ï¼Œå•æ­¥è€—æ—¶ä» 0.081 å°æ—¶ä¸Šå‡è‡³ 0.164 å°æ—¶ï¼Œæ˜¾è‘—å»¶é•¿è®¾å¤‡ç»­èˆªæ—¶é—´ã€‚

âœ… ç»“è®ºï¼šè¯¥ç­–ç•¥å¯æœ‰æ•ˆå¹³è¡¡è®­ç»ƒè¿›åº¦ä¸èƒ½è€—ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **åœ¨æ™®é€šæ‰‹æœºä¸Šè¿›è¡Œ LLM fine-tuning æ˜¯å¯è¡Œçš„**ï¼š
   - MobileFineTuner æˆåŠŸåœ¨ Pixel ç³»åˆ—æ‰‹æœºä¸Šå®Œæˆäº† GPT2ã€Qwenã€Gemma ç­‰æ¨¡å‹çš„ Full-FT å’Œ PEFTã€‚

2. **çº¯ C++ æ¶æ„æ˜¾è‘—æå‡æ•ˆç‡ä¸å¯æ§æ€§**ï¼š
   - ç»•è¿‡ Python å±‚ï¼Œé¿å…äº† VM å¼€é”€ï¼Œå®ç°äº†æ›´ä½çš„å†…å­˜å’Œè¿è¡Œæ—¶å¼€é”€ã€‚

3. **ç³»ç»Ÿçº§ä¼˜åŒ–è‡³å…³é‡è¦**ï¼š
   - å‚æ•°åˆ†ç‰‡ + æ¢¯åº¦ç´¯ç§¯ å¯æœ‰æ•ˆåº”å¯¹ç§»åŠ¨è®¾å¤‡å†…å­˜ç“¶é¢ˆï¼›
   - èƒ½é‡æ„ŸçŸ¥è°ƒåº¦ å¯åŠ¨æ€è°ƒèŠ‚è´Ÿè½½ï¼Œä¿éšœé•¿æ—¶é—´è¿è¡Œå¯è¡Œæ€§ã€‚

4. **æ€§èƒ½åª²ç¾æœåŠ¡å™¨ç«¯å®ç°**ï¼š
   - ä¸ PyTorch ç›¸æ¯”ï¼Œè®­ç»ƒè½¨è¿¹å’Œæœ€ç»ˆæŒ‡æ ‡é«˜åº¦ä¸€è‡´ï¼ŒéªŒè¯äº†æ¡†æ¶çš„**åŠŸèƒ½å®Œæ•´æ€§ä¸æ•°å€¼å¯é æ€§**ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

1. **æ¨¡å‹è§„æ¨¡å—é™**ï¼š
   - å½“å‰ä»…é€‚ç”¨äº â‰¤1B å‚æ•°çº§åˆ«çš„æ¨¡å‹ï¼›æ›´å¤§æ¨¡å‹ï¼ˆå¦‚ LLaMA-2-7Bï¼‰æ— æ³•åœ¨å½“å‰æ‰‹æœºå†…å­˜ä¸‹è¿è¡Œã€‚

2. **å°šæœªæ”¯æŒåˆ†å¸ƒå¼æˆ–å¤šè®¾å¤‡ååŒè®­ç»ƒ**ï¼š
   - è™½æåŠæœªæ¥æ”¯æŒ Federated Fine-tuningï¼Œä½†ç›®å‰ä»…ä¸ºå•è®¾å¤‡æ¡†æ¶ã€‚

3. **ç¼–è¯‘æµç¨‹ä»æœ‰ä¸€å®šé—¨æ§›**ï¼š
   - ç”¨æˆ·éœ€é€šè¿‡ NDK ç¼–è¯‘æˆ– ADB éƒ¨ç½²ï¼Œè™½æä¾›è„šæœ¬ä½†ä»ä¸å¦‚ pip install ç®€ä¾¿ã€‚

4. **ç¼ºå°‘å¯¹ä¸“ç”¨åŠ é€Ÿå™¨ï¼ˆNPU/GPUï¼‰çš„æ·±åº¦ä¼˜åŒ–**ï¼š
   - å½“å‰ä¸»è¦åˆ©ç”¨ CPUï¼Œæœªå……åˆ†å‘æŒ¥ç§»åŠ¨ç«¯ AI åŠ é€Ÿç¡¬ä»¶æ½œåŠ›ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³æ›´å¤šç§»åŠ¨ç«¯å¹³å°**ï¼š
   - æ”¯æŒ iOSã€HarmonyOS ç­‰å…¶ä»–ç§»åŠ¨æ“ä½œç³»ç»Ÿã€‚

2. **é›†æˆç¡¬ä»¶åŠ é€Ÿæ”¯æŒ**ï¼š
   - åˆ©ç”¨æ‰‹æœº NPU/GPU è¿›ä¸€æ­¥æå‡è®­ç»ƒæ•ˆç‡ã€‚

3. **æ”¯æŒ Federated & Collaborative Fine-tuning**ï¼š
   - å®ç°çœŸæ­£çš„å»ä¸­å¿ƒåŒ–ã€éšç§ä¿æŠ¤çš„å¤šè®¾å¤‡è”åˆè®­ç»ƒã€‚

4. **è‡ªåŠ¨åŒ–èµ„æºé€‚é…æœºåˆ¶**ï¼š
   - åŠ¨æ€æ ¹æ®è®¾å¤‡å†…å­˜ã€ç”µé‡ã€æ¸©åº¦ç­‰çŠ¶æ€è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ¨¡å‹ç»“æ„ä¸è®­ç»ƒç­–ç•¥ã€‚

5. **è¿›ä¸€æ­¥å‹ç¼©ä¸é‡åŒ–æ”¯æŒ**ï¼š
   - å¼•å…¥ INT4ã€FP8 ç­‰é‡åŒ–æŠ€æœ¯ï¼Œè¿›ä¸€æ­¥é™ä½èµ„æºæ¶ˆè€—ã€‚

---

## æ€»ç»“

> **MobileFineTuner æ˜¯é¦–ä¸ªçœŸæ­£æ„ä¹‰ä¸Šå®ç°â€œåœ¨æ™®é€šæ‰‹æœºä¸Šå®Œæˆ LLM å¾®è°ƒâ€çš„ç»Ÿä¸€å¼€æºæ¡†æ¶**ã€‚å®ƒä¸ä»…å¡«è¡¥äº† on-device LLM training ç”Ÿæ€çš„å…³é”®ç©ºç™½ï¼Œè¿˜é€šè¿‡ä¸€ç³»åˆ—ç³»ç»Ÿçº§ä¼˜åŒ–è§£å†³äº†å†…å­˜ä¸èƒ½è€—ä¸¤å¤§æ ¸å¿ƒæŒ‘æˆ˜ã€‚å…¶å®éªŒè¯æ˜ï¼Œå€ŸåŠ©ç²¾å¿ƒè®¾è®¡çš„ C++ æ¶æ„ä¸ç®—æ³•-ç³»ç»ŸååŒä¼˜åŒ–ï¼Œ**å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„ä¸ªæ€§åŒ–è®­ç»ƒå¯ä»¥å®‰å…¨ã€é«˜æ•ˆåœ°å‘ç”Ÿåœ¨ç”¨æˆ·æ‰‹ä¸­çš„è®¾å¤‡ä¸Š**ï¼Œä¸ºæœªæ¥éšç§ä¼˜å…ˆã€æ•°æ®æœ¬åœ°åŒ–çš„æ™ºèƒ½åº”ç”¨å¼€è¾Ÿäº†å…¨æ–°é“è·¯ã€‚

</details>

---

### 4. [From Accuracy to Impact: The Impact-Driven AI Framework (IDAIF) for Aligning Engineering Architecture with Theory of Change](https://arxiv.org/abs/2512.08449)

**Authors**: Yong-Woon Kim  
**Category**: cs.AI  
**Published**: 2025-12-10  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.08449v1  

#### Abstract
This paper introduces the Impact-Driven AI Framework (IDAIF), a novel architectural methodology that integrates Theory of Change (ToC) principles with modern artificial intelligence system design. As AI systems increasingly influence high-stakes domains including healthcare, finance, and public poli...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFrom Accuracy to Impact: The Impact-Driven AI Framework (IDAIF) for Aligning Engineering Architecture with Theory of Change

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰äººå·¥æ™ºèƒ½ç³»ç»Ÿè®¾è®¡æ™®éä»¥**æŠ€æœ¯æ€§èƒ½æŒ‡æ ‡ä¸ºä¸­å¿ƒ**ï¼ˆå¦‚å‡†ç¡®ç‡ã€å»¶è¿Ÿã€åŸºå‡†å¾—åˆ†ï¼‰ï¼Œè€Œå¿½è§†äº†AIåœ¨åŒ»ç–—ã€é‡‘èã€å…¬å…±æ”¿ç­–ç­‰é«˜é£é™©é¢†åŸŸéƒ¨ç½²æ—¶çš„**ç¤¾ä¼šå½±å“ä¸ä»·å€¼å¯¹é½é—®é¢˜**ã€‚è¿™ç§â€œæ¨¡å‹ä¸­å¿ƒä¸»ä¹‰â€å¯¼è‡´ä»¥ä¸‹å…³é”®æŒ‘æˆ˜ï¼š
- **å¯¹é½é—®é¢˜ï¼ˆAlignment Problemï¼‰**ï¼šAIä¼˜åŒ–ä»£ç†ç›®æ ‡è€ŒéçœŸå®äººç±»æ„å›¾ï¼Œæ˜“å¼•å‘â€œå¥–åŠ±é»‘å®¢â€ï¼ˆreward hackingï¼‰è¡Œä¸ºã€‚
- **åˆ†å¸ƒåç§»ï¼ˆDistribution Shiftï¼‰**ï¼šè®­ç»ƒä¸éƒ¨ç½²ç¯å¢ƒä¸ä¸€è‡´å¯¼è‡´æ¨¡å‹å¤±æ•ˆã€‚
- **éšå«å‡è®¾æœªè¢«éªŒè¯**ï¼šç³»ç»Ÿä¾èµ–äºæœªæ˜¾å¼å»ºæ¨¡çš„å› æœé“¾å‡è®¾ï¼Œä¸€æ—¦å¤±è´¥åˆ™äº§ç”Ÿä¸å¯æ§åæœã€‚
- **ä¼¦ç†åŸåˆ™éš¾ä»¥è½åœ°**ï¼šå…¬å¹³æ€§ã€é€æ˜æ€§ç­‰æŠ½è±¡ä»·å€¼è§‚ç¼ºä¹å¯å·¥ç¨‹åŒ–çš„å®ç°è·¯å¾„ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šImpact-Driven AI Framework (IDAIF)
IDAIF æ˜¯ä¸€ç§å°† **Theory of Change (ToC)** åŸç†ç³»ç»Ÿé›†æˆåˆ°AIæ¶æ„è®¾è®¡ä¸­çš„æ–°å‹æ¡†æ¶ï¼Œå®ç°äº†ä»â€œAccuracy-Drivenâ€å‘â€œImpact-Drivenâ€çš„èŒƒå¼è½¬å˜ã€‚

#### æ ¸å¿ƒæ€æƒ³
é€šè¿‡å»ºç«‹ **ToCäº”é˜¶æ®µæ¨¡å‹** ä¸ **AIç³»ç»Ÿæ¶æ„å±‚** çš„ä¸€ä¸€æ˜ å°„å…³ç³»ï¼Œç¡®ä¿ä»è¾“å…¥åˆ°æœ€ç»ˆç¤¾ä¼šå½±å“çš„æ¯ä¸€æ­¥éƒ½å…·å¤‡å¯è¿½æº¯æ€§å’Œç†è®ºæ”¯æ’‘ï¼š

| ToC é˜¶æ®µ | å¯¹åº” AI å±‚ | åŠŸèƒ½ |
|---------|-----------|------|
| **Impact**ï¼ˆå½±å“ï¼‰ | **Normative Layer**ï¼ˆè§„èŒƒå±‚ï¼‰ | ç¼–ç å¤šç›®æ ‡ä»·å€¼çº¦æŸï¼Œå®ç°ä»·å€¼å¯¹é½ |
| **Outcomes**ï¼ˆæˆæœï¼‰ | **Agentic Layer**ï¼ˆä»£ç†å±‚ï¼‰ | å¤šæ™ºèƒ½ä½“ååŒè¾¾æˆç”¨æˆ·è¡Œä¸ºæ”¹å˜ |
| **Outputs**ï¼ˆè¾“å‡ºï¼‰ | **Inference Layer**ï¼ˆæ¨ç†å±‚ï¼‰ | åˆ©ç”¨å› æœå›¾å‡å°‘å¹»è§‰ï¼Œæå‡äº‹å®å‡†ç¡®æ€§ |
| **Activities**ï¼ˆæ´»åŠ¨ï¼‰ | **Pipeline Layer**ï¼ˆæµæ°´çº¿å±‚ï¼‰ | å…¬å¹³æ„ŸçŸ¥è®­ç»ƒï¼Œå¯¹æŠ—åè§ |
| **Inputs**ï¼ˆè¾“å…¥ï¼‰ | **Data Layer**ï¼ˆæ•°æ®å±‚ï¼‰ | æ•°æ®è´¨é‡ä¸ä»£è¡¨æ€§æ²»ç† |
| **Assumptions**ï¼ˆå‡è®¾ï¼‰ | **Assurance Layer**ï¼ˆä¿éšœå±‚ï¼‰ | å®ˆæŠ¤æœºåˆ¶ç›‘æ§å¹¶å¤„ç†å‡è®¾å¤±æ•ˆ |

#### åˆ›æ–°ç‚¹
1. **é¦–æ¬¡æå‡º ToC ä¸ AI æ¶æ„çš„ç³»ç»Ÿæ€§æ˜ å°„æ¡†æ¶**  
   å°†ç¤¾ä¼šç§‘å­¦ä¸­æˆç†Ÿçš„ ToC æ–¹æ³•è®ºè½¬åŒ–ä¸ºå¯æ“ä½œçš„å·¥ç¨‹æ¶æ„æ¨¡å¼ï¼Œå¡«è¡¥äº†â€œä»·å€¼æ•æ„Ÿè®¾è®¡â€ï¼ˆVSDï¼‰ä¸å®é™…ç³»ç»Ÿå®ç°ä¹‹é—´çš„â€œæ‰§è¡Œé¸¿æ²Ÿâ€ã€‚

2. **å¼•å…¥è·¨å±‚çº§çš„ Assurance Layer**  
   æ˜¾å¼ç®¡ç†å„å±‚ä¾èµ–çš„ä¸‰å¤§å…³é”®å‡è®¾ï¼š
   - IID Assumptionï¼ˆç‹¬ç«‹åŒåˆ†å¸ƒï¼‰
   - Completeness Assumptionï¼ˆæ•°æ®å®Œæ•´æ€§ï¼‰
   - Correlation-Causation Assumptionï¼ˆç›¸å…³â‰ å› æœï¼‰  
   é€šè¿‡ Guardian Models + Human-in-the-loop + Safety Nets å®ç°åŠ¨æ€é˜²æŠ¤ã€‚

3. **èåˆå¤šç§å‰æ²¿æŠ€æœ¯å½¢æˆç»Ÿä¸€æ¶æ„è¯­è¨€**
   - å¤šç›®æ ‡ Pareto ä¼˜åŒ–ç”¨äºä»·å€¼æƒè¡¡ï¼ˆMMPFï¼‰
   - å› æœ DAGï¼ˆCausal DAGsï¼‰ç”¨äºæ¨ç†ä¿çœŸ
   - Adversarial Debiasing + RLHF ç”¨äºå…¬å¹³è®­ç»ƒ
   - åˆ†å±‚ Agent Scopingï¼ˆScope 0â€“3ï¼‰æ§åˆ¶è‡ªä¸»ç¨‹åº¦

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹æ³•ç±»åˆ« | å±€é™æ€§ | IDAIF æ”¹è¿› |
|--------|-------|----------|
| **Value-Sensitive Design (VSD), IEEE 7000** | å¼ºè°ƒæµç¨‹ä¸æ–‡æ¡£ï¼Œç¼ºä¹å…·ä½“æ¶æ„å®ç° | æä¾›æ˜ç¡®çš„æ¶æ„æ¨¡å¼ï¼Œå®ç°â€œä»·å€¼â†’ä»£ç â€è½¬åŒ– |
| **MLOps / LLMOps** | èšç„¦éƒ¨ç½²æ•ˆç‡ã€å»¶è¿Ÿç­‰è¿è¥æŒ‡æ ‡ | æ‰©å±•ä¸º **ImpactOps**ï¼Œå°†ç¤¾ä¼šå½±å“çº³å…¥å…¨ç”Ÿå‘½å‘¨æœŸç›‘æ§ |
| **RLHF, Constitutional AI, Interpretability** | å•ç‚¹æŠ€æœ¯å­¤ç«‹å­˜åœ¨ï¼Œæ— æ•´ä½“æ¶æ„æ•´åˆ | åœ¨ç»Ÿä¸€æ¡†æ¶ä¸‹å®šä½å„ç±»å¯¹é½æŠ€æœ¯ï¼Œæ„å»ºç«¯åˆ°ç«¯å¯¹é½ä½“ç³» |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ§ª å®éªŒæ–¹å¼ï¼šæ¡ˆä¾‹ç ”ç©¶æ³•ï¼ˆCase Studiesï¼‰
ç”±äº IDAIF æ˜¯ä¸€ä¸ª**æ¶æ„æ¡†æ¶**è€Œéå•ä¸€ç®—æ³•ï¼Œä½œè€…é‡‡ç”¨ä¸‰ä¸ªè·¨é¢†åŸŸçš„**å‰ç»æ€§æ¡ˆä¾‹ç ”ç©¶**æ¥éªŒè¯å…¶é€‚ç”¨æ€§ä¸æœ‰æ•ˆæ€§ã€‚

#### æ¡ˆä¾‹ä¸€ï¼šHealthcare â€” Fairness-Aware Clinical Decision Support System (CDSS)
- **ä»»åŠ¡**ï¼šæœ¯åå¹¶å‘ç—‡é¢„æµ‹
- **é—®é¢˜**ï¼šä¼ ç»Ÿæ¨¡å‹åœ¨ä¸åŒç§æ—/æ€§åˆ«ç¾¤ä½“é—´è¡¨ç°å·®å¼‚å¤§ï¼ŒåŠ å‰§åŒ»ç–—ä¸å¹³ç­‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - AUCï¼ˆæ€»ä½“æ€§èƒ½ï¼‰
  - Equalized Odds Differenceï¼ˆå…¬å¹³æ€§ï¼‰
  - Calibration Errorï¼ˆæ ¡å‡†è¯¯å·®ï¼‰
- **åŸºçº¿å¯¹æ¯”**ï¼šSingle-task baseline model
- **å…³é”®æŠ€æœ¯åº”ç”¨**ï¼š
  - Normative Layer: MMPF å¤šç›®æ ‡ä¼˜åŒ–
  - Pipeline Layer: FAIR-MTL + SSI å­ç¾¤æ¨æ–­
  - Assurance Layer: SHAP è§£é‡Š + äººå·¥å¤æ ¸æœºåˆ¶

#### æ¡ˆä¾‹äºŒï¼šCybersecurity â€” Autonomous Security Operations Center (SOC)
- **ä»»åŠ¡**ï¼šå¨èƒæ£€æµ‹ä¸è‡ªåŠ¨åŒ–å“åº”
- **é—®é¢˜**ï¼šè¯¯æŠ¥è¿‡å¤šå¯¼è‡´åˆ†æå¸ˆç–²åŠ³ï¼ŒçœŸæ­£å¨èƒè¢«å¿½ç•¥
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - MTTRï¼ˆMean Time to Remediationï¼‰
  - False Positive Rate
  - Automation Rate
  - Analyst Alert Volume
- **åŸºçº¿å¯¹æ¯”**ï¼šä¼ ç»ŸåŸºäºè§„åˆ™çš„å‘Šè­¦ç³»ç»Ÿ
- **å…³é”®æŠ€æœ¯åº”ç”¨**ï¼š
  - Agentic Layer: Agent Scoping Matrix æ§åˆ¶è¡ŒåŠ¨æƒé™
  - Inference Layer: å¿…é¡»æ„é€ æ”»å‡»é“¾å› æœ DAG æ‰èƒ½è§¦å‘é«˜çº§åˆ«å‘Šè­¦
  - Assurance Layer: Policy Guardian æ¨¡å‹é˜²æ­¢å½±å“å…³é”®ç³»ç»Ÿçš„è‡ªåŠ¨æ“ä½œ

#### æ¡ˆä¾‹ä¸‰ï¼šSoftware Engineering â€” Generative Code Engineering
- **ä»»åŠ¡**ï¼šLLM è‡ªåŠ¨ç”Ÿæˆå®‰å…¨ä¸”ç¬¦åˆæ¶æ„è§„èŒƒçš„ä»£ç 
- **é—®é¢˜**ï¼šç”Ÿæˆä»£ç å¸¸å«æ¼æ´ã€è¿åæ¶æ„ã€å¢åŠ æŠ€æœ¯å€ºåŠ¡
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - å®‰å…¨æ¼æ´ç‡ï¼ˆCritical/High Severityï¼‰
  - Architectural Conformanceï¼ˆæ¶æ„ä¸€è‡´æ€§ï¼‰
  - Developer Acceptance Rate
  - Refactoring Time
- **åŸºçº¿å¯¹æ¯”**ï¼šæ ‡å‡† Code Generation æ¨¡å‹ï¼ˆå¦‚ Codexã€StarCoderï¼‰
- **å…³é”®æŠ€æœ¯åº”ç”¨**ï¼š
  - Normative Layer: åŠ æƒæŸå¤±å‡½æ•°å¼ºè°ƒå®‰å…¨æ€§ä¸é£æ ¼
  - Pipeline Layer: Test-First Generationï¼ˆå…ˆå†™æµ‹è¯•å†ç”Ÿæˆä»£ç ï¼‰
  - Inference Layer: RAG æ£€ç´¢é¡¹ç›®å·²æœ‰ä»£ç æ¨¡å¼è¿›è¡Œçº¦æŸ
  - Assurance Layer: Security/Achitecture/Debt Guardians å®æ–½é™æ€åˆ†ææ‹¦æˆª

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

| æ¡ˆä¾‹ | æŒ‡æ ‡ | IDAIF ç»“æœ | åŸºçº¿ç»“æœ | æå‡å¹…åº¦ |
|-----|------|------------|----------|---------|
| **Healthcare** | Overall AUC | **0.86** | ~0.85 | ç›¸å½“ |
| | Equalized Odds Difference | **0.094** | >0.18 | â†“ **47% å·®å¼‚** |
| | Gender-calibration error | **0.038** | ~0.07 | â†“ æ˜¾è‘—æ”¹å–„ |
| **Cybersecurity** | MTTR | **1.1 å°æ—¶** | 4.2 å°æ—¶ | â†“ **74%** |
| | Analyst Alert Volume | â†“ **73%** | â€” | å¤§å¹…å‡è½»è´Ÿæ‹… |
| | False Positive Auto-actions | **0** | é«˜é¢‘å‘ç”Ÿ | å®Œå…¨é¿å… |
| | Routine Containment Automation | **89%** | <30% | â†‘ æ˜¾è‘—æå‡æ•ˆç‡ |
| **Software Engineering** | Security Vulnerability Rate | **3.2%** | **40%** | â†“ **92%** |
| | Architectural Conformance | **94%** | 61% | â†‘ **33pp** |
| | Developer Acceptance Rate | **67%** | 23% | â†‘ **44pp** |
| | Avg. Refactoring Time | **8 åˆ†é’Ÿ** | 45 åˆ†é’Ÿ | â†“ **82%** |

### ğŸ” æ¶ˆèåˆ†æï¼ˆéšå«äºè®¾è®¡é€»è¾‘ä¸­ï¼‰
è™½ç„¶æœªæä¾›å½¢å¼åŒ–æ¶ˆèå®éªŒè¡¨æ ¼ï¼Œä½†æ¯ä¸ªæ¡ˆä¾‹å‡å±•ç¤ºäº†**é€å±‚ç»„ä»¶çš„ä½œç”¨**ï¼š
- è‹¥æ—  **Normative Layer** çš„ MMPF ä¼˜åŒ– â†’ å…¬å¹³æ€§æ— æ³•ä¿è¯
- è‹¥è·³è¿‡ **Inference Layer** çš„å› æœ DAG æ„é€  â†’ å¹»è§‰ä¸é”™è¯¯å½’å› ä¸Šå‡
- è‹¥ç¼ºå°‘ **Assurance Layer** çš„ Guardian â†’ è‡ªåŠ¨åŒ–åŠ¨ä½œå¯èƒ½ç ´åç”Ÿäº§ç³»ç»Ÿ
- è‹¥ä¸ç”¨ **Test-First Prompting** â†’ ç”Ÿæˆä»£ç æ— æ³•é€šè¿‡æµ‹è¯•

è¿™è¡¨æ˜å„å±‚ååŒä½œç”¨æ˜¯æˆåŠŸçš„å…³é”®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **Impact-Driven Design æ˜¯å¯è¡Œä¸”å¿…è¦çš„**  
   ä»â€œæˆ‘ä»¬èƒ½æ„å»ºä»€ä¹ˆâ€è½¬å‘â€œæˆ‘ä»¬æƒ³åˆ›é€ ä»€ä¹ˆæ”¹å˜â€ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¼•å¯¼AIç³»ç»ŸæœåŠ¡äºçœŸå®ç¤¾ä¼šéœ€æ±‚ã€‚

2. **ToC æä¾›å¼ºå¤§çš„é€†å‘è®¾è®¡å·¥å…·**  
   â€œBackward Mappingâ€å¸®åŠ©å·¥ç¨‹å¸ˆä»æœ€ç»ˆå½±å“å‡ºå‘ï¼Œåå‘æ¨å¯¼æ‰€éœ€çš„æ•°æ®ã€æ¨¡å‹ã€æµç¨‹å’Œå‡è®¾ï¼Œå¢å¼ºç³»ç»Ÿé²æ£’æ€§ä¸é—®è´£æ€§ã€‚

3. **IDAIF å¯è·¨é¢†åŸŸå¤ç”¨**  
   åœ¨åŒ»ç–—ã€ç½‘ç»œå®‰å…¨ã€è½¯ä»¶å·¥ç¨‹ä¸‰ä¸ªæˆªç„¶ä¸åŒçš„åœºæ™¯ä¸­å‡å±•ç°å‡ºæ˜¾è‘—æ”¹è¿›ï¼Œè¯æ˜å…¶é€šç”¨æ€§ä¸æ‰©å±•æ½œåŠ›ã€‚

4. **Architecture Matters for Ethics**  
   ä¼¦ç†ä¸åº”ä»…é äº‹åå®¡æŸ¥æˆ–æç¤ºè¯è°ƒæ•´ï¼Œè€Œåº”å†…å»ºäºç³»ç»Ÿæ¶æ„ä¹‹ä¸­â€”â€”IDAIF æä¾›äº†ä¸€å¥—å¯å®æ–½çš„â€œé“å¾·åµŒå…¥â€è·¯å¾„ã€‚

### âš ï¸ å±€é™æ€§
1. **å°šæœªå¤§è§„æ¨¡å®è¯éªŒè¯**  
   å½“å‰ç»“æœåŸºäºæ¨¡æ‹Ÿæˆ–å°è§„æ¨¡è¯•ç‚¹ï¼Œéœ€æ›´å¤šçœŸå®ä¸–ç•Œé•¿æœŸéƒ¨ç½²æ•°æ®æ”¯æŒã€‚
2. **ToC è®¾è®¡æœ¬èº«å…·æœ‰ä¸»è§‚æ€§**  
   å¦‚ä½•ç²¾ç¡®ç•Œå®šâ€œImpactâ€ä»ä¾èµ–åˆ©ç›Šç›¸å…³è€…åå•†ï¼Œå¯èƒ½å­˜åœ¨äº‰è®®ã€‚
3. **Assurance Layer å¼€é”€è¾ƒé«˜**  
   Guardian æ¨¡å‹ä¸äººå·¥å›è·¯ä¼šå¢åŠ è®¡ç®—æˆæœ¬ä¸å»¶è¿Ÿï¼Œåœ¨èµ„æºå—é™åœºæ™¯ä¸‹éœ€æƒè¡¡ã€‚
4. **è‡ªåŠ¨åŒ– ToC-to-Architecture è½¬æ¢å°šå¾…å¼€å‘**  
   ç›®å‰ä¾èµ–ä¸“å®¶æ‰‹åŠ¨æ˜ å°„ï¼Œç¼ºä¹è‡ªåŠ¨å·¥å…·æ”¯æŒã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. å¼€å‘ **ToC-to-Code Translation Tooling**ï¼Œå®ç°éƒ¨åˆ†è‡ªåŠ¨åŒ–æ¶æ„ç”Ÿæˆ
2. å»ºç«‹ **Impact Measurement Benchmarks**ï¼Œæ¨åŠ¨å½±å“æŒ‡æ ‡æ ‡å‡†åŒ–
3. æ¢ç´¢ **IDAIF åœ¨æ•™è‚²ã€èƒ½æºã€æ°”å€™ç­‰æ–°é¢†åŸŸ**çš„åº”ç”¨
4. ç»“åˆ **Formal Verification Methods** å¯¹ä¿éšœå±‚è¿›è¡Œæ•°å­¦éªŒè¯
5. å‘å±• **Dynamic Assumption Updating Mechanisms** åº”å¯¹æŒç»­å˜åŒ–çš„ç¯å¢ƒ

---

## æ€»ç»“

> **IDAIF ä¸åªæ˜¯ä¸€ä¸ªAIæ¶æ„ï¼Œæ›´æ˜¯ä¸€ç§æ–°çš„å·¥ç¨‹å“²å­¦**ï¼šå®ƒä¸»å¼ å°†ç¤¾ä¼šå½±å“ç½®äºè®¾è®¡æ ¸å¿ƒï¼Œç”¨ä¸¥è°¨çš„å› æœé€»è¾‘è¿æ¥æ•°æ®ä¸ä»·å€¼ï¼Œä½¿AIç³»ç»Ÿä¸ä»…â€œèªæ˜â€ï¼Œè€Œä¸”â€œå¯ä¿¡ã€å¯æ§ã€æœ‰ç›Šâ€ã€‚  
>  
> è¯¥æ¡†æ¶ä¸ºè§£å†³å½“å‰AIå¯¹é½å›°å¢ƒæä¾›äº†ç³»ç»Ÿæ€§å‡ºè·¯ï¼Œæ ‡å¿—ç€ä» **Model-Centric AI** å‘ **Impact-Centric AI** çš„é‡è¦è·ƒè¿ã€‚

</details>

---

### 5. [Magneton: Optimizing Energy Efficiency of ML Systems via Differential Energy Debugging](https://arxiv.org/abs/2512.08365)

**Authors**: Yi Pan, Wenbo Qian, Dedong Xie, Ruiyan Hu, Yigong Hu, Baris Kasikci  
**Category**: cs.DC  
**Published**: 2025-12-10  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.08365v1  

#### Abstract
The training and deployment of machine learning (ML) models have become extremely energy-intensive. While existing optimization efforts focus primarily on hardware energy efficiency, a significant but overlooked source of inefficiency is software energy waste caused by poor software design. This oft...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Magneton: Optimizing Energy Efficiency of ML Systems via Differential Energy Debugging*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ç³»ç»Ÿåœ¨è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­æ¶ˆè€—å¤§é‡èƒ½é‡ï¼Œå…¶ä¸­**è½¯ä»¶è®¾è®¡ç¼ºé™·å¯¼è‡´çš„èƒ½æºæµªè´¹**ï¼ˆsoftware energy wasteï¼‰æ˜¯ä¸€ä¸ªè¢«ä¸¥é‡å¿½è§†çš„é—®é¢˜ã€‚è¿™ç±»æµªè´¹æºäºå†—ä½™æ“ä½œã€APIè¯¯ç”¨ã€é…ç½®é”™è¯¯ç­‰ï¼Œè€Œä¼ ç»Ÿå·¥å…·éš¾ä»¥æœ‰æ•ˆæ£€æµ‹å’Œè¯Šæ–­ã€‚

ç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹ä¸è¶³ï¼š
- **æ€§èƒ½åˆ†æå™¨**ï¼ˆå¦‚ PyTorch Profilerï¼‰å…³æ³¨æ‰§è¡Œæ—¶é—´ï¼Œæ— æ³•è¯†åˆ«å¯¹æ€§èƒ½å½±å“å°ä½†èƒ½è€—é«˜çš„ä»£ç ã€‚
- **ç¡¬ä»¶çº§èƒ½æ•ˆä¼˜åŒ–å·¥å…·**ï¼ˆå¦‚ Zeusï¼‰ç¼ºä¹ç»†ç²’åº¦æµ‹é‡èƒ½åŠ›ï¼Œä¸”ä¸æä¾›æ ¹å› è¯Šæ–­ã€‚
- **é™æ€åˆ†æå·¥å…·**éš¾ä»¥ç†è§£è·¨æ¡†æ¶ã€è·¨å®ç°çš„åŠŸèƒ½ç­‰ä»·æ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šDifferential Energy Debugging
ä½œè€…æå‡ºä¸€ç§å…¨æ–°çš„èƒ½æ•ˆè°ƒè¯•èŒƒå¼â€”â€”**Differential Energy Debugging**ï¼ˆå·®åˆ†èƒ½æ•ˆè°ƒè¯•ï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> åˆ©ç”¨å¤šä¸ªåŠŸèƒ½ç›¸ä¼¼ä½†å®ç°ä¸åŒçš„ ML ç³»ç»Ÿä¹‹é—´çš„èƒ½è€—å·®å¼‚ï¼Œé€šè¿‡æ¯”è¾ƒå®ƒä»¬çš„æ“ä½œç¬¦çº§è¡Œä¸ºæ¥è‡ªåŠ¨å®šä½å’Œè¯Šæ–­è½¯ä»¶å±‚é¢çš„èƒ½æ•ˆé—®é¢˜ã€‚

åŸºäºæ­¤ï¼Œè®¾è®¡å¹¶å®ç°äº† **Magneton**ï¼Œä¸€ä¸ªç«¯åˆ°ç«¯çš„å·®åˆ†èƒ½æ•ˆåˆ†æå·¥å…·ã€‚

### ä¸»è¦åˆ›æ–°ç‚¹
1. **ä»¥ Operator ä¸ºæŠ½è±¡å•ä½è¿›è¡Œè·¨ç³»ç»Ÿæ¯”è¾ƒ**  
   - å°†è®¡ç®—å›¾ä¸­çš„ç®—å­ï¼ˆå¦‚ GEMMã€Conv2Dã€AllReduceï¼‰ä½œä¸ºåŸºæœ¬æ¯”è¾ƒå•å…ƒï¼Œå…¼é¡¾è¯­ä¹‰æ„ä¹‰ä¸å¯åˆ†ææ€§ã€‚
   - é¿å…äº†æºç çº§ç›´æ¥å¯¹æ¯”çš„ä¸å¯é æ€§å’Œåº•å±‚ CUDA å†…æ ¸åˆ†æçš„ä¸å¯è¡Œæ€§ã€‚

2. **åŸºäºè®¡ç®—å›¾çš„è¯­ä¹‰ç­‰ä»·å­å›¾åŒ¹é…ç®—æ³•**  
   - æå‡ºé€šè¿‡å¼ é‡çš„å¤šæ¨¡æ€ SVD ä¸å˜é›†ï¼ˆmulti-mode SVD invariant setï¼‰åˆ¤æ–­å¼ é‡ç­‰ä»·æ€§ï¼Œå…‹æœä¸åŒå¸ƒå±€ï¼ˆå¦‚ NCHW vs NHWCï¼‰å¸¦æ¥çš„å¹²æ‰°ã€‚
   - åˆ©ç”¨æ”¯é…æ ‘ï¼ˆdominator treeï¼‰ç»“æ„é€’å½’åˆ’åˆ†è®¡ç®—å›¾ï¼Œåœ¨ $O(N^2)$ æ—¶é—´å†…é«˜æ•ˆåŒ¹é…è¯­ä¹‰ç­‰ä»·å­å›¾ã€‚

3. **ç²¾å‡†çš„æ ¹å› è¯Šæ–­æœºåˆ¶**  
   - å½“å‘ç°æŸå­å›¾èƒ½è€—æ˜¾è‘—æ›´é«˜æ—¶ï¼Œå›æº¯ GPU kernel è°ƒç”¨è·¯å¾„ï¼Œæ‰¾åˆ°æ§åˆ¶æµé¦–æ¬¡åˆ†å‰ç‚¹ï¼Œå¹¶ç»“åˆæ’æ¡©ç¡®å®šå…³é”®å˜é‡ï¼ˆå¦‚ `allow_tf32`ï¼‰ã€‚
   - æ”¯æŒè¯Šæ–­ä¸‰ç±»å…¸å‹é—®é¢˜ï¼šAPI misuseã€redundant operationsã€misconfigurationã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Magneton | ä¼ ç»Ÿ Profilerï¼ˆå¦‚ PyTorch Profilerï¼‰ | ç°æœ‰ Energy Profilerï¼ˆå¦‚ Zeusï¼‰ |
|------|----------|-------------------------------|-----------------------------|
| **ç›®æ ‡** | è½¯ä»¶èƒ½æ•ˆæµªè´¹æ£€æµ‹ä¸è¯Šæ–­ | æ€§èƒ½ç“¶é¢ˆåˆ†æ | ç¡¬ä»¶èƒ½è€—ç›‘æ§ |
| **ç²’åº¦** | Operator/Subgraph çº§ | Operator çº§ | è¿­ä»£çº§ï¼ˆâ‰¥100msï¼‰ |
| **æ˜¯å¦æ”¯æŒæ ¹å› è¯Šæ–­** | âœ… æ˜¯ | âŒ å¦ | âŒ å¦ |
| **èƒ½å¦å‘ç°éæ€§èƒ½ç“¶é¢ˆçš„èƒ½è€—é—®é¢˜** | âœ… èƒ½ | âŒ ä¸èƒ½ | âŒ ä¸èƒ½ |
| **è·¨ç³»ç»Ÿæ¯”è¾ƒèƒ½åŠ›** | âœ… æ”¯æŒ | âŒ ä¸æ”¯æŒ | âŒ ä¸æ”¯æŒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æµ‹è¯•ç³»ç»Ÿï¼ˆTarget Systemsï¼‰
åœ¨ **9 ä¸ªä¸»æµ ML ç³»ç»Ÿ**ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œæ¶µç›–ä¸‰å¤§ç±»åˆ«ï¼š
- **LLM æ¨ç†æ¡†æ¶**ï¼švLLMã€SGLangã€Huggingface Transformers
- **é€šç”¨ ML æ¡†æ¶**ï¼šPyTorchã€JAXã€TensorFlow
- **å›¾åƒç”Ÿæˆç³»ç»Ÿ**ï¼šStable Diffusionã€Diffusersã€Megatron-LM

### æ•°æ®é›†ä¸å·¥ä½œè´Ÿè½½
- ä½¿ç”¨çœŸå®æ¨¡å‹å’Œæ ‡å‡†ä»»åŠ¡ï¼š
  - LLM æ¨ç†ï¼šLlama-3-8Bã€GPT-2
  - å›¾åƒç”Ÿæˆï¼šStable Diffusion v3
  - è®­ç»ƒä»»åŠ¡ï¼šMLPã€Transformer æ¨¡å‹
- è¾“å…¥é…ç½®ä¿æŒä¸€è‡´ï¼ˆbatch sizeã€seq lengthã€prompt ç­‰ï¼‰

### è¯„ä¼°æŒ‡æ ‡
1. **èƒ½æ•ˆå·®å¼‚æ£€æµ‹ç‡**ï¼šæ˜¯å¦æˆåŠŸè¯†åˆ«å·²çŸ¥èƒ½è€—é—®é¢˜
2. **æ ¹å› è¯Šæ–­å‡†ç¡®ç‡**ï¼šæ˜¯å¦å‡†ç¡®å®šä½åˆ°å…·ä½“ API æˆ–é…ç½®é¡¹
3. **èƒ½è€—èŠ‚çœæ¯”ä¾‹**ï¼šä¿®å¤åç«¯åˆ°ç«¯èƒ½è€—é™ä½å¹…åº¦
4. **æ•æ„Ÿæ€§ä¸é²æ£’æ€§**ï¼šè¯­ä¹‰åŒ¹é…ç®—æ³•å¯¹é˜ˆå€¼å˜åŒ–çš„ç¨³å®šæ€§
5. **å¼€é”€**ï¼šè¿è¡Œæ—¶å»¶è¿Ÿå¢åŠ ã€å†…å­˜å ç”¨
6. **å‡†ç¡®æ€§**ï¼šä¸ç‰©ç†åŠŸç‡è®¡æµ‹é‡å€¼çš„è¯¯å·®

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **PyTorch Profiler** | å®˜æ–¹æ€§èƒ½åˆ†æå™¨ï¼Œè¾“å‡ºå„ operator çš„ latency |
| **Zeus** | åŸºäº NVML çš„ GPU èƒ½è€—ç›‘æ§å·¥å…·ï¼Œæœ€å°é‡‡æ ·çª—å£ 100ms |
| **Zeus-replay** | æœ¬æ–‡æ”¹è¿›ç‰ˆ Zeusï¼Œé€šè¿‡é‡å¤æ‰§è¡Œ operator æé«˜æµ‹é‡ç²¾åº¦ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ï¼ˆ1ï¼‰å·²çŸ¥é—®é¢˜çš„è¯Šæ–­æ•ˆæœï¼ˆTable 2ï¼‰
- åœ¨ **16 ä¸ªå·²çŸ¥èƒ½æ•ˆé—®é¢˜**ä¸­ï¼ŒMagneton æˆåŠŸè¯Šæ–­äº† **15 ä¸ª**ï¼ˆ93.8%ï¼‰ã€‚
- å¹³å‡èƒ½è€—å‡å°‘ **13.6%**ï¼Œéƒ¨åˆ†æ¡ˆä¾‹é«˜è¾¾ 58.8%ï¼ˆå¦‚ hf-34570 ä¸­çš„ layout transformation ä¼˜åŒ–ï¼‰ã€‚
- å…¸å‹æ¡ˆä¾‹å¦‚ä¸‹ï¼š
  - `pytorch-141210`ï¼š`torch.addmm` ä½¿ç”¨ä½æ•ˆ kernel â†’ æ›¿æ¢ä¸º `add + matmul` å¯çœç”µ 9.1%
  - `hf-34570`ï¼š`torch.linalg.eigvals` è°ƒç”¨é«˜èƒ½è€— kernel â†’ ä¼˜åŒ–åèŠ‚èƒ½ 29.1%
  - `vllm-10811`ï¼šdecode attention å­˜åœ¨å†—ä½™æ•°æ®æ‹·è´ â†’ èŠ‚èƒ½ 1.4%

### ï¼ˆ2ï¼‰ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | èƒ½å¦ç²¾ç¡®å®šä½ operator | æ˜¯å¦æ”¯æŒ <100ms æ“ä½œæµ‹é‡ | æ˜¯å¦æä¾›æ ¹å› è§£é‡Š | Top-5 Hotspot è¦†ç›–ç‡ |
|------|------------------------|---------------------------|--------------------|------------------------|
| PyTorch Profiler | âœ… | âœ… | âŒ | ä»… 3/12 case è¿›å…¥ top-3 |
| Zeus | âŒï¼ˆå¤ªç²—ç²’åº¦ï¼‰ | âŒï¼ˆâ‰¥100msï¼‰ | âŒ | ä»… c6 æ­£ç¡®æµ‹å¾—èƒ½è€— |
| Zeus-replay | âœ…ï¼ˆç»æ”¹é€ ï¼‰ | âœ…ï¼ˆé€šè¿‡é‡æ”¾ï¼‰ | âŒ | 7/12 case è¿›å…¥ top-5 |
| **Magneton** | âœ… | âœ…ï¼ˆå¾®ç§’çº§ï¼‰ | âœ… | æ‰€æœ‰è¯Šæ–­ case å‡å®šä½æ­£ç¡® |

> æ³¨ï¼šZeus å› é‡‡æ ·é¢‘ç‡é™åˆ¶ï¼Œæ— æ³•æ•æ‰çŸ­ç”Ÿå‘½å‘¨æœŸ kernel çš„èƒ½è€—ï¼›PyTorch Profiler å¿½ç•¥äº†å¤šæ•°éæ€§èƒ½ç“¶é¢ˆçš„èƒ½è€—é—®é¢˜ã€‚

### ï¼ˆ3ï¼‰æ–°é—®é¢˜å‘ç°èƒ½åŠ›
- Magneton å‘ç°äº† **8 ä¸ªæ­¤å‰æœªçŸ¥çš„èƒ½æ•ˆé—®é¢˜**ï¼Œå…¶ä¸­ **7 ä¸ªå·²è¢«å¼€å‘è€…ç¡®è®¤**ã€‚
- ç¤ºä¾‹åŒ…æ‹¬ï¼š
  - `hf-39072`ï¼šæ³¨æ„åŠ›å±‚å­˜åœ¨æ— æ•ˆçš„ memory resharding
  - `vllm-20174`ï¼šprefill attention é»˜è®¤é…ç½®æœªå¯ç”¨ tensor core
  - `tf-96396`ï¼šè‡ªå®šä¹‰å·ç§¯ kernel æ•ˆç‡ä½ä¸‹
  - `pytorch-157334`ï¼šNCHW å¸ƒå±€ä¸‹ Conv2D æ•ˆç‡ä½

### ï¼ˆ4ï¼‰æ¶ˆèå®éªŒä¸æ¨¡å—è¯„ä¼°

#### â‘  è¯­ä¹‰ç­‰ä»·åŒ¹é…ç®—æ³•æ•æ„Ÿæ€§ï¼ˆFigure 8ï¼‰
- åœ¨ $ \epsilon \in [10^{-4}, 1.8\times10^{-2}] $ èŒƒå›´å†…ï¼ŒF1-score > 0.8
- æœ€ä¼˜åŒºé—´å¯è¾¾ F1 â‰ˆ 1.0ï¼Œè¡¨æ˜ç®—æ³•å¯¹å‚æ•°é€‰æ‹©é²æ£’

#### â‘¡ åŒ¹é…æ•ˆç‡ä¸æ‰©å±•æ€§ï¼ˆFigure 9ï¼‰
- å¯¹ GPT-2 è®¡ç®—å›¾ï¼ˆ757 å’Œ 408 èŠ‚ç‚¹ï¼‰ï¼š167ms å®ŒæˆåŒ¹é…
- å¯¹ Llama-3-8B å¤§æ¨¡å‹ï¼š1.4 ç§’å®Œæˆï¼Œè€Œæš´åŠ›æœç´¢è¶…æ—¶ï¼ˆ>5åˆ†é’Ÿï¼‰
- è¡¨æ˜ topology-aware åˆ†æ²»ç­–ç•¥æ˜¾è‘—æå‡å¯æ‰©å±•æ€§

#### â‘¢ è·Ÿè¸ªå¼€é”€ï¼ˆFigure 10ï¼‰
- åœ¨ Huggingface Transformers ä¸Šå¼•å…¥ **4.4%** çš„å»¶è¿Ÿå¼€é”€
- åœ¨ vLLM ä¸Šä¸º **5.9%**
- ç¦»çº¿è¯Šæ–­æ¨¡å—å‡åœ¨ 2 åˆ†é’Ÿå†…å®Œæˆ

#### â‘£ åŠŸè€—æµ‹é‡å‡†ç¡®æ€§ï¼ˆTable 4ï¼‰
| Operator | ç‰©ç†æµ‹é‡å€¼ | Zeus è¯¯å·® | Magnetonï¼ˆreplayï¼‰è¯¯å·® |
|---------|------------|-----------|------------------------|
| arange | 266W | -72.5% | -4.1% |
| contiguous | 317W | -77.0% | -1.9% |
| linear | 455W | -80.7% | +0.9% |

> Magneton çš„ replay-based æ–¹æ³•æ¥è¿‘ç‰©ç†æµ‹é‡ç²¾åº¦ï¼Œè¿œä¼˜äº Zeusã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è½¯ä»¶èƒ½æ•ˆæµªè´¹æ™®éå­˜åœ¨ä¸”å¯ä¼˜åŒ–**  
   å³ä½¿æ˜¯ä¸»æµæ¡†æ¶ï¼ˆPyTorchã€HuggingFaceï¼‰ä¹Ÿå­˜åœ¨å¤§é‡æœªè¢«å‘ç°çš„èƒ½è€—é—®é¢˜ï¼Œæ¶‰åŠ API é€‰æ‹©ã€é…ç½®é”™è¯¯ã€å†—ä½™æ“ä½œç­‰ã€‚

2. **æ€§èƒ½ä¸èƒ½è€—å¹¶éå¼ºç›¸å…³**  
   è®¸å¤šé«˜èƒ½è€—æ“ä½œå¯¹æ€§èƒ½å½±å“æå°ï¼ˆå¦‚ `dist.Join` å¯¼è‡´ GPU æ— æ³• idleï¼‰ï¼Œå› æ­¤ä¼ ç»Ÿæ€§èƒ½åˆ†æå™¨æ— æ³•æœ‰æ•ˆæ•è·è¿™äº›é—®é¢˜ã€‚

3. **è·¨ç³»ç»Ÿå·®åˆ†åˆ†ææ˜¯æœ‰æ•ˆçš„è¯Šæ–­æ‰‹æ®µ**  
   åŠŸèƒ½ç›¸ä¼¼çš„ä¸åŒç³»ç»Ÿï¼ˆå¦‚ vLLM vs HuggingFaceï¼‰åœ¨ç›¸åŒä»»åŠ¡ä¸‹èƒ½è€—å·®å¼‚å¯è¾¾ **2.97x**ï¼Œè¿™ç§â€œè‡ªç„¶å¯¹ç…§â€ä¸ºèƒ½æ•ˆä¼˜åŒ–æä¾›äº†æ˜ç¡®æ–¹å‘ã€‚

4. **Operator æ˜¯ç†æƒ³çš„åˆ†æç²’åº¦**  
   å®ƒæ—¢ä¿ç•™äº†è¶³å¤Ÿçš„è¯­ä¹‰ä¿¡æ¯ç”¨äºè·¨ç³»ç»Ÿæ¯”è¾ƒï¼Œåˆè¶³å¤Ÿç²¾ç»†ä»¥æŒ‡å¯¼å…·ä½“ä¼˜åŒ–ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–åŠŸèƒ½ç›¸ä¼¼ç³»ç»Ÿçš„å­˜åœ¨**  
   è‹¥æ— æ›¿ä»£å®ç°ï¼Œåˆ™æ— æ³•åº”ç”¨å·®åˆ†åˆ†æã€‚å¯¹äºé«˜åº¦å®šåˆ¶åŒ–çš„ç§æœ‰ç³»ç»Ÿé€‚ç”¨æ€§å—é™ã€‚

2. **CPU ç«¯èƒ½è€—è¦†ç›–æœ‰é™**  
   å½“å‰ä¸»è¦èšç„¦ GPU èƒ½è€—ï¼ŒMagneton æœªèƒ½æ£€æµ‹åˆ°çº¯ CPU polling ç±»é—®é¢˜ï¼ˆå¦‚ `pytorch-28224`ï¼‰ã€‚

3. **éœ€ä¸€å®šæ‰‹åŠ¨é›†æˆæˆæœ¬**  
   è™½ç„¶å£°ç§°â€œminimal effortâ€ï¼Œä½†ä»éœ€æ ‡æ³¨è¾“å…¥è¾“å‡ºå¼ é‡ï¼Œå¯¹é—­æºæˆ–å¤æ‚ç³»ç»Ÿé›†æˆæœ‰ä¸€å®šé—¨æ§›ã€‚

4. **å‡è®¾è¾“å…¥ä¸€è‡´æ€§**  
   è·¨ç³»ç»Ÿæ¯”è¾ƒè¦æ±‚å®Œå…¨ç›¸åŒçš„è¾“å…¥å’Œè°ƒåº¦ç­–ç•¥ï¼Œå®é™…éƒ¨ç½²ä¸­å¯èƒ½å­˜åœ¨åå·®ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³æ›´å¤šç¡¬ä»¶å¹³å°**  
   æ”¯æŒ AMD GPUã€TPU ç­‰è®¾å¤‡çš„èƒ½é‡åˆ†æã€‚

2. **è‡ªåŠ¨åŒ–å»ºè®®ç”Ÿæˆ**  
   ä¸ä»…è¯Šæ–­é—®é¢˜ï¼Œè¿˜èƒ½æ¨èæ›´é«˜æ•ˆçš„æ›¿ä»£å®ç°æˆ–é…ç½®ç»„åˆã€‚

3. **é›†æˆè¿› CI/CD æµç¨‹**  
   æ„å»ºâ€œç»¿è‰² MLâ€å¼€å‘æµæ°´çº¿ï¼Œåœ¨ä»£ç æäº¤é˜¶æ®µè‡ªåŠ¨æ£€æŸ¥èƒ½æ•ˆå›å½’ã€‚

4. **æ”¯æŒåŠ¨æ€å·¥ä½œè´Ÿè½½ä¸‹çš„æŒç»­ç›‘æ§**  
   å®ç°å®æ—¶èƒ½æ•ˆå¼‚å¸¸æ£€æµ‹ä¸è‡ªé€‚åº”è°ƒä¼˜ã€‚

---

> **æ€»ç»“**ï¼šMagneton å¼€åˆ›æ€§åœ°å°† **differential analysis** å¼•å…¥ ML èƒ½æ•ˆé¢†åŸŸï¼Œæå‡ºäº†ä¸€å¥—ä» operator ç²’åº¦å‡ºå‘ã€ç»“åˆè®¡ç®—å›¾åŒ¹é…ä¸æ ¹å› è¿½è¸ªçš„å®Œæ•´æ¡†æ¶ã€‚å®éªŒè¯æ˜å…¶ä¸ä»…èƒ½å¤ç°å·²çŸ¥é—®é¢˜ï¼Œæ›´èƒ½å‘ç°æ–°çš„ä¼˜åŒ–æœºä¼šï¼Œä¸ºæ„å»ºå¯æŒç»­çš„ AI ç³»ç»Ÿæä¾›äº†å¼ºæœ‰åŠ›çš„å·¥å…·æ”¯æ’‘ã€‚

</details>

---

### 6. [gHAWK: Local and Global Structure Encoding for Scalable Training of Graph Neural Networks on Knowledge Graphs](https://arxiv.org/abs/2512.08274)

**Authors**: Humera Sabir, Fatima Farooq, Ashraf Aboulnaga  
**Category**: cs.LG  
**Published**: 2025-12-10  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.08274v1  

#### Abstract
Knowledge Graphs (KGs) are a rich source of structured, heterogeneous data, powering a wide range of applications. A common approach to leverage this data is to train a graph neural network (GNN) on the KG. However, existing message-passing GNNs struggle to scale to large KGs because they rely on th...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šgHAWK: Local and Global Structure Encoding for Scalable Training of Graph Neural Networks on Knowledge Graphs

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **Graph Neural Networks (GNNs)** åœ¨å¤§è§„æ¨¡ã€å¼‚æ„çš„ **Knowledge Graphs (KGs)** ä¸Šè®­ç»ƒæ—¶é¢ä¸´ä¸¥é‡çš„å¯æ‰©å±•æ€§æŒ‘æˆ˜ï¼Œä¸»è¦ä½“ç°åœ¨ä»¥ä¸‹ä¸‰ä¸ªæ–¹é¢ï¼š
- **æ•ˆç‡ä½ä¸‹**ï¼šæ ‡å‡†çš„æ¶ˆæ¯ä¼ é€’æœºåˆ¶ä¾èµ–å¤šè½®è¿­ä»£èšåˆé‚»å±…ä¿¡æ¯ï¼Œå°¤å…¶åœ¨ mini-batch è®­ç»ƒä¸­ï¼ŒèŠ‚ç‚¹åªèƒ½çœ‹åˆ°å±€éƒ¨é‡‡æ ·åçš„é‚»å±…ï¼Œå¯¼è‡´ç»“æ„ä¿¡æ¯ä¸¢å¤±ã€‚
- **å‚æ•°çˆ†ç‚¸**ï¼šå…³ç³»æ„ŸçŸ¥å‹ GNNsï¼ˆå¦‚ R-GCNï¼‰ä¸ºæ¯ç§å…³ç³»ç»´æŠ¤ç‹¬ç«‹å‚æ•°ï¼Œå½“ KG åŒ…å«æ•°ç™¾ç§å…³ç³»æ—¶ï¼ˆå¦‚ OGB-WikiKG2 æœ‰ 535 ç§ï¼‰ï¼Œå†…å­˜æ¶ˆè€—å·¨å¤§ï¼Œéš¾ä»¥è®­ç»ƒã€‚
- **ä¿¡æ¯æŸå¤±**ï¼šmini-batch é‡‡æ ·ä¸¢å¼ƒäº†å¤§é‡é‚»åŸŸä¿¡æ¯ï¼Œå½±å“æ¨¡å‹å‡†ç¡®æ€§å’Œæ”¶æ•›é€Ÿåº¦ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šgHAWK
gHAWK æ˜¯ä¸€ç§æ–°é¢–ä¸”å¯æ‰©å±•çš„ GNN è®­ç»ƒæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†å›¾ç»“æ„çš„å­¦ä¹ ä»æ¶ˆæ¯ä¼ é€’é˜¶æ®µå‰ç§»åˆ°ä¸€ä¸ªè½»é‡çº§çš„**é¢„å¤„ç†é˜¶æ®µ**ï¼Œé€šè¿‡é¢„å…ˆç¼–ç æ¯ä¸ªèŠ‚ç‚¹çš„å±€éƒ¨å’Œå…¨å±€ç»“æ„ç‰¹å¾æ¥å¢å¼º GNN è¾“å…¥ã€‚

#### åˆ›æ–°ç‚¹
- **æ··åˆç»“æ„ç¼–ç ï¼ˆHybrid Local and Global Structure Encodingï¼‰**ï¼š
  - **å±€éƒ¨ç»“æ„ç¼–ç **ï¼šä½¿ç”¨ **Bloom Filter** é«˜æ•ˆå‹ç¼©ç¼–ç èŠ‚ç‚¹çš„ 1-hop å¤šå…³ç³»é‚»å±…é›†åˆï¼Œå›ºå®šé•¿åº¦ã€ä½å†…å­˜å¼€é”€ã€‚
  - **å…¨å±€ç»“æ„ç¼–ç **ï¼šé‡‡ç”¨ **TransE** åµŒå…¥è¡¨ç¤ºèŠ‚ç‚¹åœ¨æ•´ä¸ª KG ä¸­çš„ä½ç½®å’Œè¯­ä¹‰ä¸Šä¸‹æ–‡ï¼Œæ•æ‰é•¿è·ç¦»ä¾èµ–å’Œç¨€æœ‰å…³ç³»æ¨¡å¼ã€‚
- **ç‰¹å¾èåˆï¼ˆFeature Fusionï¼‰**ï¼š
  - å°† Bloom Filterã€TransE åµŒå…¥å’Œé¢†åŸŸç‰¹å®šç‰¹å¾ï¼ˆå¦‚æ–‡æœ¬åµŒå…¥ï¼‰é€šè¿‡å¯å­¦ä¹ çš„ MLP èåˆä¸ºç»Ÿä¸€çš„è¾“å…¥å‘é‡ï¼Œå®ç°ç«¯åˆ°ç«¯è”åˆä¼˜åŒ–ã€‚
- **ç¡¬è´Ÿæ ·æœ¬ç”Ÿæˆï¼ˆHard Negative Samplingï¼‰**ï¼š
  - åˆ©ç”¨é¢„è®­ç»ƒçš„ TransE æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„â€œéš¾â€è´Ÿæ ·æœ¬ï¼Œæå‡ link prediction æ€§èƒ½ã€‚
- **é€šç”¨å…¼å®¹æ€§**ï¼š
  - gHAWK å¯ä»¥ä¸ä»»ä½• GNN æ¶æ„ï¼ˆå¦‚ GraphSAGEã€R-GCNï¼‰ç»“åˆï¼Œé€‚ç”¨äºå¤šç§ä»»åŠ¡ï¼ˆnode property prediction å’Œ link predictionï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ˜¾è‘—åŠ é€Ÿæ”¶æ•›**ï¼šç»“æ„å…ˆéªŒå‡å°‘äº†å¯¹æ·±å±‚æ¶ˆæ¯ä¼ é€’çš„ä¾èµ–ï¼Œé€šå¸¸åªéœ€ 1â€“2 å±‚å³å¯è¾¾åˆ°é«˜æ€§èƒ½ã€‚
- **é™ä½å†…å­˜å ç”¨**ï¼šé¿å…äº†å…³ç³»æ„ŸçŸ¥ GNN çš„å‚æ•°çˆ†ç‚¸é—®é¢˜ï¼Œæ”¯æŒ relation-agnostic GNN å®ç°é«˜ç²¾åº¦ã€‚
- **æå‡å‡†ç¡®æ€§**ï¼šæ¢å¤äº† mini-batch é‡‡æ ·ä¸¢å¤±çš„ç»“æ„ä¿¡æ¯ï¼Œåœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¾¾åˆ° SOTAã€‚
- **é«˜æ•ˆå¯æ‰©å±•**ï¼šé¢„å¤„ç†æ­¥éª¤è®¡ç®—æˆæœ¬ä½ï¼Œé€‚åˆ Web-scale KGsã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåŸºäº **Open Graph Benchmark (OGB)** çš„æ ‡å‡†æ•°æ®é›†ï¼Œæ¶µç›–ä¸åŒè§„æ¨¡å’Œå¤æ‚åº¦çš„ KGï¼š

| ä»»åŠ¡ | æ•°æ®é›† | è§„æ¨¡ | ç‰¹ç‚¹ |
|------|--------|------|------|
| **Node Property Prediction** | OGB-MAG | ~1.9M èŠ‚ç‚¹ | å­¦æœ¯å›¾è°±ï¼Œé¢„æµ‹è®ºæ–‡ venue |
| | MAG240M | ~244M èŠ‚ç‚¹ | Web-scale å­¦æœ¯å›¾è°±ï¼Œé¢„æµ‹ subject area |
| **Link Prediction** | OGB-WikiKG2 | ~2.5M å®ä½“ï¼Œ535 å…³ç³» | å¤§è§„æ¨¡ã€é«˜å¼‚æ„æ€§ |
| | FB15k-237 | ~14k å®ä½“ï¼Œ237 å…³ç³» | æ ‡å‡†åŸºå‡†ï¼Œæ”¯æŒå…¨æ‰¹é‡è®­ç»ƒ |

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### Node Property Prediction
- **è¯„ä¼°æŒ‡æ ‡**ï¼šMulti-class classification accuracy
- **è®­ç»ƒæ–¹å¼**ï¼šMini-batch è®­ç»ƒï¼ˆé™¤ FB15k-237 å¤–ï¼‰
- **GNN è®¾ç½®**ï¼š2 å±‚ GNNï¼Œéšè—ç»´åº¦ 256ï¼ŒAdamW ä¼˜åŒ–å™¨ï¼Œé‚»å±…é‡‡æ · fanout åˆ†åˆ«ä¸º 25ï¼ˆhop1ï¼‰ã€20ï¼ˆhop2ï¼‰

#### Link Prediction
- **è¯„ä¼°æŒ‡æ ‡**ï¼šFiltered MRRã€Hits@3ã€Hits@10
- **è´Ÿé‡‡æ ·ç­–ç•¥**ï¼š
  - Random filtering
  - Self-adversarial weighting
  - **TransE-guided hard negative sampling**ï¼ˆgHAWK ç‰¹æœ‰ï¼‰
- **è§£ç å™¨**ï¼šRotatEï¼ˆç”¨äº GraphSAGEï¼‰ã€DistMultï¼ˆç”¨äº R-GCNï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Embedding-only**ï¼šTransEã€RotatE
- **Specialized Link Predictors**ï¼šNBFNetã€A*Net
- **GNN Backbones**ï¼š
  - Relation-agnosticï¼šGraphSAGE
  - Relation-awareï¼šR-GCN
  - å…¶ä»–ï¼šGraphSAINTã€ClusterGCNã€GATã€HGT

æ‰€æœ‰åŸºçº¿å‡åœ¨ç›¸åŒè®¾ç½®ä¸‹å¤ç°ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### Node Property Predictionï¼ˆMAG240Mï¼‰
- **gHAWK + R-GCN** è¾¾åˆ° **75.04%** å‡†ç¡®ç‡ï¼Œ**OGB æ¦œå•æ’åç¬¬ä¸€**ã€‚
- æ‰€æœ‰ GNN éª¨å¹²ç½‘ç»œåœ¨åŠ å…¥ gHAWK åå‡æœ‰æ˜¾è‘—æå‡ï¼ˆ+4.8% è‡³ +17.5%ï¼‰ã€‚
- æ”¶æ•›é€Ÿåº¦åŠ å¿«ï¼ŒéªŒè¯è¯¯å·®ä¸‹é™æ›´å¿«ï¼ˆè§ Figure 4ï¼‰ã€‚

#### Link Predictionï¼ˆOGB-WikiKG2ï¼‰
- **gHAWK + GraphSAGE** è¾¾åˆ° **75.74% MRR**ï¼Œ**OGB æ¦œå•æ’åç¬¬ä¸€**ã€‚
- å³ä½¿æ˜¯ decoder-only æ¨¡å‹ï¼ˆæ—  GNN å±‚ï¼‰ï¼ŒgHAWK ä¹Ÿèƒ½å°† RotatE çš„ MRR ä» 43.42% æå‡è‡³ **68.02%**ã€‚
- R-GCN åœ¨ mini-batch ä¸‹è¡¨ç°æå·®ï¼ˆ18.16% MRRï¼‰ï¼Œè€Œ gHAWK æ˜¾è‘—æ”¹å–„è‡³ 38.96%ã€‚

> âœ… **gHAWK åœ¨ä¸‰ä¸ª OGB æ¦œå•ï¼ˆä¸¤ä¸ª node propertyï¼Œä¸€ä¸ª link predictionï¼‰å‡æ’åç¬¬ä¸€**ï¼Œæ˜¯å”¯ä¸€åšåˆ°è¿™ä¸€ç‚¹çš„æŠ€æœ¯ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| æ–¹æ³• | OGB-WikiKG2 MRR | æ˜¯å¦å¯è¡Œ |
|------|------------------|----------|
| RotatE (w/o gHAWK) | 43.42% | æ˜¯ |
| RotatE (with gHAWK) | **68.02%** | æ˜¯ |
| R-GCN (mini-batch) | 18.16% | æ˜¯ï¼ˆä¸ç¨³å®šï¼‰ |
| R-GCN (with gHAWK) | 38.96% | æ˜¯ |
| GraphSAGE (w/o gHAWK) | 45.37% | æ˜¯ |
| GraphSAGE (with gHAWK) | **75.74%** | æ˜¯ |
| NBFNet | OOM | âŒ ä¸å¯è¡Œ |

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### Node Property Predictionï¼ˆTable 3ï¼‰
- **No features**ï¼šå‡†ç¡®ç‡ä½äº 30%ï¼Œè¯´æ˜ä»…é å›¾ç»“æ„æ— æ³•è¡¥å¿é‡‡æ ·æŸå¤±ã€‚
- **Local (Bloom)**ï¼šåœ¨ OGB-MAG ä¸Šä¼˜äºæ–‡æœ¬ç‰¹å¾ï¼ˆWord2Vecï¼‰ï¼Œè¡¨æ˜ç»“æ„ä¿¡æ¯å¼ºäºå¼±æ–‡æœ¬ç¼–ç ã€‚
- **gHAWK (Bloom + TransE)**ï¼šå³ä½¿ä¸ç”¨æ–‡æœ¬ç‰¹å¾ï¼Œä¹Ÿæ˜¾è‘—ä¼˜äºå•ç‹¬ä½¿ç”¨ä»»ä¸€ç»“æ„ç‰¹å¾ã€‚
- **gHAWK + Text**ï¼šæœ€ä½³ç»„åˆï¼Œè¯æ˜ç»“æ„ä¸è¯­ä¹‰ç‰¹å¾äº’è¡¥ã€‚

#### Link Predictionï¼ˆFB15k-237ï¼ŒTable 6ï¼‰
| æ¨¡å‹å˜ä½“ | MRR | è¯´æ˜ |
|---------|-----|------|
| Full-batch R-GCN | 22.87% | æœ€ä¼˜è®­ç»ƒæ¨¡å¼ |
| Mini-batch R-GCN | 14.86% | é‡‡æ ·å¯¼è‡´ä¸¥é‡æ€§èƒ½ä¸‹é™ |
| + Bloom Filter | 26.39% | **è¶…è¶Šå…¨æ‰¹é‡è®­ç»ƒ** |
| + TransE | 22.18% | æ¥è¿‘å…¨æ‰¹é‡ |
| + Bloom + TransE (gHAWK) | **27.95%** | **æœ€ä¼˜ç»“æœï¼Œå®Œå…¨å¼¥è¡¥å¹¶è¶…è¶Šé‡‡æ ·æŸå¤±** |

> ğŸ” ç»“è®ºï¼š**Bloom Filter å¯¹æ¢å¤å±€éƒ¨ç»“æ„è‡³å…³é‡è¦ï¼ŒTransE æä¾›å…¨å±€è¯­ä¹‰ï¼ŒäºŒè€…ç»“åˆæ•ˆæœæœ€ä½³**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç»“æ„å…ˆéªŒæå¤§æå‡ GNN æ•ˆç‡ä¸æ€§èƒ½**ï¼š
   - å°†ç»“æ„å­¦ä¹ å‰ç½®åˆ°é¢„å¤„ç†é˜¶æ®µï¼Œæ˜¾è‘—å‡å°‘å¯¹æ·±å±‚æ¶ˆæ¯ä¼ é€’å’Œå…¨é‚»åŸŸè®¿é—®çš„ä¾èµ–ã€‚
2. **relation-agnostic GNN + gHAWK å¯åª²ç¾ç”šè‡³è¶…è¶Š relation-aware GNN**ï¼š
   - gHAWK æä¾›äº†è¶³å¤Ÿçš„å…³ç³»æ„ŸçŸ¥èƒ½åŠ›ï¼Œä½¿å¾—è½»é‡çº§ GNNï¼ˆå¦‚ GraphSAGEï¼‰åœ¨å¤§è§„æ¨¡ KG ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚
3. **æµ…å±‚ GNN å·²è¶³å¤Ÿ**ï¼š
   - ç”±äºèŠ‚ç‚¹åˆå§‹åŒ–å·²åŒ…å«ä¸°å¯Œç»“æ„ä¿¡æ¯ï¼Œ1â€“2 å±‚æ¶ˆæ¯ä¼ é€’å³å¯è¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚
4. **gHAWK æœ‰æ•ˆç¼“è§£ over-squashing å’Œé‡‡æ ·åå·®**ï¼š
   - TransE ç¼“è§£ over-squashingï¼ŒBloom Filter è¡¥å¿é‡‡æ ·ä¸¢å¤±çš„å±€éƒ¨ä¿¡æ¯ã€‚
5. **åœ¨å¤šä¸ª OGB æ¦œå•ç™»é¡¶ï¼ŒéªŒè¯äº†å…¶ SOTA åœ°ä½**ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **é¢„å¤„ç†ä¾èµ– TransE**ï¼šè™½ç„¶ TransE é«˜æ•ˆï¼Œä½†å…¶å‡è®¾â€œh + r â‰ˆ tâ€ä¸é€‚ç”¨äºå¯¹ç§°æˆ–ä¸€å¯¹å¤šå…³ç³»ã€‚
- **Bloom Filter å­˜åœ¨è¯¯æŠ¥æ¦‚ç‡**ï¼šå°½ç®¡å¯é€šè¿‡è°ƒå‚æ§åˆ¶ï¼Œä½†ä»éå®Œç¾é›†åˆè¡¨ç¤ºã€‚
- **ç‰¹å¾èåˆæ¨¡å—å¼•å…¥é¢å¤–å‚æ•°**ï¼šè™½å°ï¼Œä½†åœ¨æç«¯èµ„æºå—é™åœºæ™¯å¯èƒ½éœ€ç®€åŒ–ã€‚
- **æœªæ¢ç´¢æ›´å¤æ‚çš„ KGE æ¨¡å‹ä½œä¸ºå…¨å±€ç¼–ç å™¨**ï¼šå¦‚ RotatE æˆ– ComplExï¼Œå› å…¶è¾“å‡ºä¸ºå¤æ•°ï¼Œé›†æˆéš¾åº¦è¾ƒé«˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´å…ˆè¿›çš„ KGE æ¨¡å‹ä½œä¸ºå…¨å±€ç¼–ç å™¨ï¼Œå¹¶è®¾è®¡å®æ•°ç©ºé—´æ˜ å°„æ–¹æ¡ˆã€‚
- å°† gHAWK æ€æƒ³åº”ç”¨äºåŠ¨æ€ KG æˆ–æµå¼å›¾å­¦ä¹ åœºæ™¯ã€‚
- ç»“åˆè§£é‡Šæ€§æŠ€æœ¯ï¼ˆå¦‚ eXpathï¼‰åˆ†æ gHAWK çš„é¢„æµ‹ä¾æ®ã€‚
- æ‰©å±•è‡³å…¶ä»–å›¾ä»»åŠ¡ï¼Œå¦‚å›¾åˆ†ç±»æˆ–å­å›¾åŒ¹é…ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ– Bloom Filter è®¾è®¡ï¼Œå¦‚ä½¿ç”¨ Counting Bloom Filter æˆ– Learned Bloom Filterã€‚

---

> ğŸ **æ€»ç»“**ï¼šgHAWK é€šè¿‡**é¢„è®¡ç®—å±€éƒ¨ï¼ˆBloom Filterï¼‰å’Œå…¨å±€ï¼ˆTransEï¼‰ç»“æ„ç‰¹å¾**ï¼Œå®ç°äº†å¯¹ GNN è¾“å…¥çš„æœ‰æ•ˆå¢å¼ºï¼Œåœ¨ä¸å¢åŠ æ¨¡å‹æ·±åº¦çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†è®­ç»ƒæ•ˆç‡ã€æ”¶æ•›é€Ÿåº¦å’Œé¢„æµ‹ç²¾åº¦ã€‚å…¶å®éªŒç»“æœåœ¨å¤šä¸ª OGB åŸºå‡†ä¸Šè¾¾åˆ° SOTAï¼Œå¹¶é¦–æ¬¡åœ¨å¤šä¸ªæ¦œå•åŒæ—¶æ’åç¬¬ä¸€ï¼Œä¸ºå¤§è§„æ¨¡å¼‚æ„ KG ä¸Šçš„ GNN è®­ç»ƒæä¾›äº†é«˜æ•ˆã€é€šç”¨ä¸”å¯æ‰©å±•çš„æ–°èŒƒå¼ã€‚

</details>

---

### 7. [HSTMixer: A Hierarchical MLP-Mixer for Large-Scale Traffic Forecasting](https://arxiv.org/abs/2512.07854)

**Authors**: Yongyao Wang, Jingyuan Wang, Xie Yu, Jiahao Ji, Chao Li  
**Category**: cs.LG  
**Published**: 2025-12-10  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.07854v1  

#### Abstract
Traffic forecasting task is significant to modern urban management. Recently, there is growing attention on large-scale forecasting, as it better reflects the complexity of real-world traffic networks. However, existing models often exhibit quadratic computational complexity, making them impractical...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# HSTMixer: A Hierarchical MLP-Mixer for Large-Scale Traffic Forecasting â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¤§è§„æ¨¡äº¤é€šé¢„æµ‹é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **å¯æ‰©å±•æ€§ï¼ˆScalabilityï¼‰**ï¼šä¸»æµæ¨¡å‹å¦‚ GNN å’Œ Transformer å…·æœ‰äºŒæ¬¡è®¡ç®—å¤æ‚åº¦ï¼ˆquadratic computational complexityï¼‰ï¼Œåœ¨èŠ‚ç‚¹æ•°é‡åºå¤§çš„çœŸå®åŸå¸‚ç½‘ç»œä¸­éš¾ä»¥é«˜æ•ˆè¿è¡Œã€‚
- **æœ‰æ•ˆæ€§ï¼ˆEffectivenessï¼‰**ï¼šé¢å¯¹å¤§è§„æ¨¡æ•°æ®æ—¶ï¼Œå…¨å±€å»ºæ¨¡ä¼šå¼•å…¥å¤§é‡æ— å…³å™ªå£°ï¼ˆirrelevant noiseï¼‰ï¼Œå¯¼è‡´å…³é”®æ—¶ç©ºæ¨¡å¼è¢«ç¨€é‡Šï¼Œå½±å“é¢„æµ‹ç²¾åº¦ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **HSTMixer**ï¼ˆHierarchical Spatio-Temporal Mixerï¼‰ï¼Œä¸€ç§åŸºäºå…¨ MLP æ¶æ„çš„åˆ†å±‚æ··åˆæ¨¡å‹ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **åˆ†å±‚æ—¶ç©ºæ··åˆå—ï¼ˆSpatiotemporal Mixing Blockï¼‰**
   - é‡‡ç”¨â€œè‡ªåº•å‘ä¸Šèšåˆ + è‡ªé¡¶å‘ä¸‹ä¼ æ’­â€æœºåˆ¶ï¼Œæ„å»ºå¤šåˆ†è¾¨ç‡ç‰¹å¾é‡‘å­—å¡”ã€‚
   - æ—¶é—´ç»´åº¦é€šè¿‡ **Temporal Aggregation Mixer** è¿›è¡Œçª—å£å†…å±€éƒ¨ç‰¹å¾æå–ï¼Œå¹¶é€å±‚æŠ½è±¡ä¸ºå®è§‚è¶‹åŠ¿ã€‚
   - ç©ºé—´ç»´åº¦é€šè¿‡ **Spatial Cascade Mixer** å®ç°ä»èŠ‚ç‚¹çº§åˆ°åŒºåŸŸçº§çš„å±‚æ¬¡åŒ–å»ºæ¨¡ã€‚

2. **è‡ªé€‚åº”åŒºåŸŸæ··åˆå™¨ï¼ˆAdaptive Region Mixerï¼‰**
   - å¼•å…¥å‚æ•°æ± ï¼ˆParameter Poolï¼‰åŠ¨æ€ç”Ÿæˆå˜æ¢çŸ©é˜µï¼Œä¾æ®ä¸åŒåŒºåŸŸè¯­ä¹‰è°ƒæ•´æ··åˆæƒé‡ã€‚
   - åˆ©ç”¨ **Parameter Orthogonal Loss (POL)** å¢å¼ºåŒºåŸŸé—´çš„è¯­ä¹‰åŒºåˆ†åº¦ï¼Œæå‡æ¨¡å‹å¯¹å¼‚è´¨åŒºåŸŸåŠ¨æ€æ¨¡å¼çš„æ•æ‰èƒ½åŠ›ã€‚

3. **çº¿æ€§å¤æ‚åº¦è®¾è®¡**
   - æ•´ä½“æ¶æ„é¿å…æ³¨æ„åŠ›æœºåˆ¶å’Œå›¾å·ç§¯æ“ä½œï¼Œå®ç°å¯¹èŠ‚ç‚¹æ•° $N$ çš„çº¿æ€§æ—¶é—´å¤æ‚åº¦ $O(N)$ï¼Œæ˜¾è‘—æå‡å¯æ‰©å±•æ€§ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | HSTMixer | ä¼ ç»Ÿ GNN/Transformer |
|------|----------|------------------------|
| è®¡ç®—æ•ˆç‡ | âœ… çº¿æ€§å¤æ‚åº¦ï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½² | âŒ äºŒæ¬¡å¤æ‚åº¦ï¼Œå†…å­˜ä¸æ—¶é—´å¼€é”€é«˜ |
| å™ªå£°æŠ‘åˆ¶ | âœ… åˆ†å±‚å»ºæ¨¡èšç„¦å…³é”®åŒºåŸŸï¼Œå‡å°‘å…¨å±€å™ªå£°å¹²æ‰° | âŒ å…¨å±€ç›¸å…³æ€§å»ºæ¨¡æ˜“å—å™ªå£°æ±¡æŸ“ |
| åŠ¨æ€é€‚åº”æ€§ | âœ… è‡ªé€‚åº”åŒºåŸŸæ··åˆï¼Œå“åº”åŒºåŸŸè¯­ä¹‰å˜åŒ– | âŒ å›ºå®šæ‹“æ‰‘æˆ–é™æ€æ³¨æ„åŠ›æœºåˆ¶ |
| è¡¨è¾¾èƒ½åŠ› | âœ… å¤šå°ºåº¦ç‰¹å¾èåˆï¼Œå…¼é¡¾å±€éƒ¨ç»†èŠ‚ä¸å…¨å±€è¶‹åŠ¿ | âœ… å¼ºè¡¨è¾¾åŠ›ä½†ä»£ä»·é«˜æ˜‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ **LargeST** åŸºå‡†ä¸­çš„å››ä¸ªå¤§è§„æ¨¡çœŸå®äº¤é€šæ•°æ®é›†ä¸Šè¿›è¡ŒéªŒè¯ï¼š

| Dataset | Nodes | Time Steps | Time Range |
|--------|-------|------------|------------|
| **SD** | 716 | 35,040 | 2019-01-01 è‡³ 2020-01-01 |
| **GBA** | 2,352 | 35,040 | åŒä¸Š |
| **GLA** | 3,834 | 35,040 | åŒä¸Š |
| **CA** | 8,600 | 35,040 | åŒä¸Š |

> æ•°æ®å·²ç»Ÿä¸€é‡é‡‡æ ·ä¸ºæ¯15åˆ†é’Ÿä¸€ä¸ªæ—¶é—´æ­¥ï¼ŒæŒ‰å­£èŠ‚åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ï¼ˆæ¯”ä¾‹ 6:2:2ï¼‰ã€‚

### ğŸ§ª å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **è¾“å…¥è¾“å‡ºé•¿åº¦**ï¼šè¾“å…¥å†å² 12 æ­¥ â†’ é¢„æµ‹æœªæ¥ 12 æ­¥
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA RTX A6000 48GB GPU
- **æ¡†æ¶æ”¯æŒ**ï¼šLibCity
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **MAE**ï¼ˆMean Absolute Errorï¼‰
  - **RMSE**ï¼ˆRoot Mean Square Errorï¼‰
  - **MAPE**ï¼ˆMean Absolute Percentage Errorï¼‰

### ğŸ†š å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
å…±æ¯”è¾ƒ **20 ç§åŸºçº¿æ¨¡å‹**ï¼Œåˆ†ä¸ºä¸¤ç±»ï¼š
1. **Previous SOTAs**ï¼ˆå¤æ‚æ¨¡å‹ï¼Œå¸¸æ— æ³•æ‰©å±•è‡³å¤§æ•°æ®é›†ï¼‰ï¼š
   - GNNç±»ï¼šDCRNN, STGCN, GWNET, STGODE, DSTAGNN, DGCRN
   - Transformerç±»ï¼šPDFormer, TESTAM, EiFormer
2. **Scalable Models**ï¼ˆä¸“ä¸ºå¤§è§„æ¨¡è®¾è®¡çš„è½»é‡æ¨¡å‹ï¼‰ï¼š
   - MLP-Mixerç³»åˆ—ï¼šTSMixer, TimeMixer, RPMixer, MLPST
   - å…¶ä»–é«˜æ•ˆæ¨¡å‹ï¼šSTID, FreTS, GSNet, LSTNN

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½è¡¨ç°ï¼ˆTable 2ï¼‰
HSTMixer åœ¨æ‰€æœ‰å››ä¸ªæ•°æ®é›†ä¸Šå‡å–å¾— **state-of-the-art æ€§èƒ½**ï¼Œå¹³å‡ä¼˜äºæœ€ä½³åŸºçº¿ï¼š

| æŒ‡æ ‡ | å¹³å‡æå‡å¹…åº¦ |
|------|--------------|
| **MAE** | â†“ **4.41%** |
| **RMSE** | â†“ **3.15%** |
| **MAPE** | â†“ **2.03%** |

å…·ä½“ä»¥ **CA æ•°æ®é›†**ä¸ºä¾‹ï¼š
- MAE: **15.55**ï¼ˆç¬¬äºŒåä¸º LSTNN çš„ 16.48ï¼‰
- RMSE: **27.05**ï¼ˆç¬¬äºŒåä¸º GSNet çš„ 29.15ï¼‰
- MAPE: **10.55%**ï¼ˆè¿œä¼˜äºå¤šæ•°æ¨¡å‹ï¼‰

> æ³¨ï¼šè®¸å¤š GNN/Transformer æ¨¡å‹å› æ˜¾å­˜ä¸è¶³æœªèƒ½å®Œæˆ CA æ•°æ®é›†è®­ç»ƒï¼ˆè¡¨ä¸­æ ‡è®°ä¸º â€œ-â€ï¼‰ã€‚

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
æ¶ˆèäº”ç§å˜ä½“éªŒè¯å„ç»„ä»¶æœ‰æ•ˆæ€§ï¼ˆFigure 5ï¼‰ï¼š

| å˜ä½“ | æè¿° | å½±å“ |
|------|------|------|
| **w/o AM** | æ›¿æ¢è‡ªé€‚åº”æ··åˆå™¨ä¸ºæ ‡å‡† MLP | æ€§èƒ½ä¸‹é™ â†’ æ˜¾ç¤ºè‡ªé€‚åº”æœºåˆ¶é‡è¦ |
| **w/o TH** | ç§»é™¤æ—¶é—´å±‚æ¬¡å»ºæ¨¡ | MAE ä¸Šå‡ â†’ æ—¶é—´å¤šå°ºåº¦å»ºæ¨¡æœ‰æ•ˆ |
| **w/o SH** | ç§»é™¤ç©ºé—´å±‚æ¬¡å»ºæ¨¡ | æ˜¾è‘—é€€åŒ– â†’ ç©ºé—´åˆ†å±‚è‡³å…³é‡è¦ |
| **w/o TP / w/o SP** | ç§»é™¤æ—¶é—´/ç©ºé—´ä¼ æ’­è·¯å¾„ | æ€§èƒ½ä¸‹é™ â†’ ç‰¹å¾ä¼ æ’­å¢å¼ºå¤šå°ºåº¦èåˆ |

ç»“è®ºï¼š**åˆ†å±‚ç»“æ„ä¸åŒå‘ä¼ æ’­æœºåˆ¶å…±åŒæå‡äº†æ¨¡å‹è¡¨è¾¾èƒ½åŠ›**ã€‚

### â±ï¸ æ•ˆç‡åˆ†æï¼ˆFigure 6 & Table 5ï¼‰
åœ¨ GBA æ•°æ®é›†ä¸Šçš„è®­ç»ƒè€—æ—¶ä¸æ€§èƒ½å¯¹æ¯”æ˜¾ç¤ºï¼š
- **HSTMixer è®­ç»ƒæ—¶é—´ä»… 4.47 å°æ—¶/epoch**ï¼Œæ˜¾è‘—å¿«äº DCRNNï¼ˆ59.47hï¼‰ã€D2STGNNï¼ˆ146.53hï¼‰
- æ¨ç†å»¶è¿Ÿä½è‡³ **29.74 ç§’**
- å†…å­˜å ç”¨åˆç†ï¼ˆ32,792 MiBï¼‰ï¼Œå¯åœ¨å•å¡å®Œæˆè®­ç»ƒ
- åœ¨ä¿æŒ **SOTA ç²¾åº¦çš„åŒæ—¶ï¼Œæ•ˆç‡åª²ç¾ TSMixerã€RPMixer ç­‰é«˜æ•ˆæ¨¡å‹**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **åˆ†å±‚å»ºæ¨¡æ˜¯è§£å†³å¤§è§„æ¨¡äº¤é€šé¢„æµ‹çš„å…³é”®**ï¼šåˆ©ç”¨æ—¶ç©ºæ•°æ®çš„å¤©ç„¶å±‚çº§ç»“æ„ï¼ˆå¾®è§‚é‚»è¿‘æ€§ vs å®è§‚å‘¨æœŸæ€§/è¯­ä¹‰ç›¸å…³æ€§ï¼‰ï¼Œå¯æœ‰æ•ˆè¿‡æ»¤å™ªå£°å¹¶æå–ä¸»å¯¼ç‰¹å¾ã€‚
2. **MLP æ¶æ„ä¹Ÿèƒ½è¶…è¶Š Transformer/GNN**ï¼šé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„åˆ†å±‚æ··åˆç­–ç•¥ï¼Œç®€å•çš„ MLP ç»“æ„å¯åœ¨ç²¾åº¦å’Œæ•ˆç‡ä¹‹é—´å–å¾—æ›´ä¼˜å¹³è¡¡ã€‚
3. **è‡ªé€‚åº”åŒºåŸŸæ··åˆå¢å¼ºäº†è¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›**ï¼št-SNE å¯è§†åŒ–ï¼ˆFigure 8ï¼‰è¡¨æ˜ HSTMixer èƒ½æ›´å¥½åœ°åŒºåˆ†åŠŸèƒ½åŒºåŸŸï¼ˆå¦‚ä½å®…åŒºã€å•†ä¸šåŒºï¼‰ï¼Œè€Œ w/o AM å‡ºç°ä¸¥é‡èšç±»æ··å ã€‚
4. **æ¨¡å‹å…·å¤‡è‰¯å¥½é²æ£’æ€§**ï¼šéšç€æ•°æ®è§„æ¨¡å¢å¤§ï¼ˆä» SD åˆ° CAï¼‰ï¼ŒHSTMixer ç›¸å¯¹äºæ¬¡ä¼˜æ¨¡å‹çš„æ€§èƒ½ä¼˜åŠ¿è¿›ä¸€æ­¥æ‰©å¤§ï¼ˆMAPE å·®è·ä» ~1% æ‰©å¤§åˆ° 3.03%ï¼‰ã€‚

### âš ï¸ å±€é™æ€§
- åŒºåŸŸåˆ’åˆ†ä¾èµ–å­¦ä¹ è€Œéæ˜¾å¼åœ°ç†å…ˆéªŒï¼Œå¯èƒ½åœ¨è¯­ä¹‰æ¨¡ç³ŠåŒºåŸŸäº§ç”Ÿåå·®ã€‚
- å½“å‰æ¨¡å‹æœªæ•´åˆå¤–éƒ¨å› ç´ ï¼ˆå¤©æ°”ã€äº‹ä»¶ç­‰ï¼‰ï¼Œé™åˆ¶äº†æç«¯æƒ…å†µä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
- å‚æ•°æ­£äº¤æŸå¤±è™½æœ‰åŠ©äºåŒºåŸŸåŒºåˆ†ï¼Œä½†ä¹Ÿå¢åŠ ä¼˜åŒ–éš¾åº¦ï¼Œéœ€è°¨æ…è°ƒå‚ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **multivariate time series prediction**ï¼ˆå¦‚åŒæ—¶é¢„æµ‹æµé‡ã€é€Ÿåº¦ã€å¯†åº¦ï¼‰
- åº”ç”¨äº **anomaly detection** åœºæ™¯ï¼Œè¯†åˆ«å¼‚å¸¸æ‹¥å µæˆ–äº‹æ•…
- å¼•å…¥ **external knowledge**ï¼ˆPOIã€è·¯ç½‘ç­‰çº§ï¼‰å¢å¼ºåŒºåŸŸè¯­ä¹‰å»ºæ¨¡
- æ¢ç´¢ **federated learning** æ¶æ„ä»¥ä¿æŠ¤åŸå¸‚é—´æ•°æ®éšç§

---

## æ€»ç»“
**HSTMixer** æ˜¯é¦–ä¸ªå°† **åˆ†å±‚æ€æƒ³** ä¸ **MLP-Mixer æ¶æ„** æˆåŠŸç»“åˆçš„å¤§è§„æ¨¡äº¤é€šé¢„æµ‹æ¨¡å‹ã€‚å®ƒä¸ä»…å®ç°äº† **SOTA ç²¾åº¦**ï¼Œè¿˜å…·å¤‡å“è¶Šçš„ **å¯æ‰©å±•æ€§ä¸è®¡ç®—æ•ˆç‡**ï¼Œä¸ºæ™ºæ…§åŸå¸‚ä¸­è¶…å¤§è§„æ¨¡åŠ¨æ€äº¤é€šå»ºæ¨¡æä¾›äº†å®ç”¨ä¸”é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 8. [Exposing Hidden Biases in Text-to-Image Models via Automated Prompt Search](https://arxiv.org/abs/2512.08724)

**Authors**: Manos Plitsis, Giorgos Bouritsas, Vassilis Katsouros, Yannis Panagakis  
**Category**: cs.LG  
**Published**: 2025-12-10  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.08724v1  

#### Abstract
Text-to-image (TTI) diffusion models have achieved remarkable visual quality, yet they have been repeatedly shown to exhibit social biases across sensitive attributes such as gender, race and age. To mitigate these biases, existing approaches frequently depend on curated prompt datasets - either man...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Exposing Hidden Biases in Text-to-Image Models via Automated Prompt Search è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„ **Text-to-Image (TTI) diffusion models**ï¼ˆå¦‚ Stable Diffusionã€DALLÂ·Eï¼‰åœ¨ç”Ÿæˆå›¾åƒæ—¶è¡¨ç°å‡ºæ˜¾è‘—çš„ç¤¾ä¼šåè§ï¼ˆsocial biasesï¼‰ï¼Œå°¤å…¶åœ¨æ€§åˆ«ã€ç§æ—ã€å¹´é¾„ç­‰æ•æ„Ÿå±æ€§ä¸Šå­˜åœ¨ç³»ç»Ÿæ€§åå·®ã€‚å°½ç®¡å·²æœ‰å¤§é‡ç ”ç©¶è‡´åŠ›äºåè§æ£€æµ‹ä¸ç¼“è§£ï¼Œä½†ç°æœ‰æ–¹æ³•é¢ä¸´ä¸¤å¤§å›°å¢ƒï¼š

- **è¦†ç›–èŒƒå›´æœ‰é™**ï¼šä¾èµ–äººå·¥æˆ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ„å»ºçš„**æ‰‹å·¥æç¤ºè¯æ•°æ®é›†**ï¼ˆcurated prompt datasetsï¼‰ï¼Œåªèƒ½æ¢ç´¢æç¤ºç©ºé—´çš„ä¸€å°éƒ¨åˆ†ï¼Œå®¹æ˜“é—æ¼æœªé¢„æ–™åˆ°çš„ã€å¾®å¦™çš„åè§è§¦å‘æ¡ä»¶ã€‚
- **å¯è§£é‡Šæ€§å·®**ï¼šåŸºäºæ¢¯åº¦çš„**ç¡¬æç¤ºä¼˜åŒ–**ï¼ˆhard prompt optimizationï¼‰è™½èƒ½å‘ç°é«˜åè§åŒºåŸŸï¼Œä½†ç”Ÿæˆçš„æç¤ºå¾€å¾€ä¸å¯è¯»ï¼ˆå¦‚ `"nurse kerala matplotlib tbody"`ï¼‰ï¼Œéš¾ä»¥ç”¨äºå®é™…å®¡è®¡æˆ–ç†è§£åè§æœºåˆ¶ã€‚

å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¿è¯æç¤ºå¯è§£é‡Šæ€§çš„å‰æä¸‹ï¼Œè‡ªåŠ¨ã€é«˜æ•ˆåœ°æ¢ç´¢æ›´å¹¿æ³›çš„åè§æç¤ºç©ºé—´ï¼Œæˆä¸ºäºŸå¾…è§£å†³çš„å…³é”®é—®é¢˜ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šBias-Guided Prompt Search (BGPS)

ä½œè€…æå‡º **Bias-Guided Prompt Search (BGPS)** â€”â€”ä¸€ç§è‡ªåŠ¨åŒ–ç”Ÿæˆå¯è§£é‡Šæç¤ºä»¥æœ€å¤§åŒ–æš´éœ² TTI æ¨¡å‹ä¸­éšè—åè§çš„æ–°æ¡†æ¶ã€‚

#### æ ¸å¿ƒæ€æƒ³
å°†æç¤ºæœç´¢å»ºæ¨¡ä¸ºä¸€ä¸ªè”åˆä¼˜åŒ–é—®é¢˜ï¼Œå¹³è¡¡ä¸¤ä¸ªç›®æ ‡ï¼š
1. **åè§å¾—åˆ†æœ€å¤§åŒ–**ï¼šé€šè¿‡è½»é‡çº§åˆ†ç±»å™¨è¯„ä¼°ç”Ÿæˆå›¾åƒä¸­çš„åè§ç¨‹åº¦ï¼›
2. **è¯­è¨€è‡ªç„¶æ€§ä¿æŒ**ï¼šåˆ©ç”¨ LLM çš„ä¼¼ç„¶ä½œä¸ºè¯­è¨€å…ˆéªŒï¼Œç¡®ä¿æç¤ºè¯­å¥é€šé¡ºã€å¯è¯»ã€‚

è¯¥æ–¹æ³•å— **Visually-Guided Decoding (VGD)** å¯å‘ï¼Œä½†å°†å…¶ä»â€œå›¾åƒåæ¼”â€ä»»åŠ¡è½¬åŒ–ä¸ºâ€œåè§å‘ç°â€å·¥å…·ã€‚

#### æ–¹æ³•ç»„æˆ
- **LLM ç»„ä»¶**ï¼šä½¿ç”¨ Mistral-7B ç­‰ LLM ç”Ÿæˆåˆå§‹ä¸­æ€§æç¤ºï¼ˆattribute-neutral promptsï¼‰ï¼Œé¿å…ç›´æ¥æåŠæ€§åˆ«/ç§æ—ã€‚
- **å±æ€§åˆ†ç±»å™¨ç»„ä»¶**ï¼šè®­ç»ƒè½»é‡çº¿æ€§åˆ†ç±»å™¨ï¼Œä½œç”¨äºæ‰©æ•£æ¨¡å‹ï¼ˆå¦‚ Stable Diffusion 1.5 UNet ä¸­é—´å±‚æ¿€æ´»ï¼‰ï¼Œå®æ—¶åé¦ˆç”Ÿæˆå›¾åƒçš„æ€§åˆ«/ç§æ—å€¾å‘ã€‚
- **å¼•å¯¼è§£ç æœºåˆ¶**ï¼šé‡‡ç”¨å¸¦æ‰©å±•å› å­çš„ **beam search**ï¼Œç»“åˆåˆ†ç±»å™¨è¾“å‡ºåŠ¨æ€è°ƒæ•´ LLM è§£ç è·¯å¾„ï¼Œå‘é«˜åè§æ–¹å‘æ¢ç´¢ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | æ‰‹å·¥/LLM æ„é€ æç¤º | æ¢¯åº¦ä¼˜åŒ–ï¼ˆå¦‚ PEZï¼‰ | BGPSï¼ˆæœ¬æ–‡ï¼‰ |
|------|------------------|--------------------|-------------|
| è¦†ç›–å¹¿åº¦ | ä½ï¼ˆå—é™äºäººå·¥è®¾è®¡ï¼‰ | é«˜ï¼ˆè‡ªåŠ¨æœç´¢ï¼‰ | âœ… é«˜ï¼ˆLLM æœç´¢ç©ºé—´å¤§ï¼‰ |
| å¯è§£é‡Šæ€§ | âœ… é«˜ï¼ˆäººç±»å¯è¯»ï¼‰ | ä½ï¼ˆæ— æ„ä¹‰æ–‡æœ¬ï¼‰ | âœ… é«˜ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰ |
| å‘ç°èƒ½åŠ› | ä¸€èˆ¬ï¼ˆæ˜“æ¼éšæ€§åè§ï¼‰ | âœ… å¼ºï¼ˆå¯æ‰¾åˆ°æç«¯åè§ï¼‰ | âœ…âœ… æ›´å¼ºä¸”å¯è§£é‡Š |
| å®ç”¨ä»·å€¼ | ä¸­ç­‰ï¼ˆéœ€é¢„è®¾æ¨¡æ¿ï¼‰ | ä½ï¼ˆæ— æ³•äººå·¥å¤ç°ï¼‰ | âœ… é«˜ï¼ˆå¯ç”¨äºçœŸå®å®¡è®¡ï¼‰ |

> âœ… BGPS æˆåŠŸå®ç°äº†â€œé«˜è¦†ç›–ç‡â€ä¸â€œé«˜å¯è§£é‡Šæ€§â€çš„ç»Ÿä¸€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹

#### æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelsï¼‰
- **Stable Diffusion 1.5 (Base)**ï¼šåŸºå‡†æ¨¡å‹ï¼Œå¹¿æ³›ä½¿ç”¨ã€‚
- **Fine-tuned Debias Model**ï¼šåŸºäº Shen et al. (2024) æ–¹æ³•è¿›è¡Œ LoRA å¾®è°ƒçš„å»åç‰ˆæœ¬ã€‚
- ï¼ˆé™„å½•è¿˜æµ‹è¯•äº† SD 2.1ã€SDXLã€DeepFloyd IFï¼‰

#### å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰
- ä¸»è¦ä½¿ç”¨ **Mistral-7B-Instruct-v0.2** ä½œä¸ºæç¤ºç”Ÿæˆå™¨ã€‚
- å¯¹æ¯”å®éªŒä¸­ä¹Ÿå°è¯•äº† **Qwen-3-8B** å’Œ **Llama-3.2-1B-Instruct**ã€‚

#### å±æ€§åˆ†ç±»å™¨
- æ€§åˆ«åˆ†ç±»å™¨ï¼šåœ¨ CelebA ä¸Šè®­ç»ƒã€‚
- ç§æ—åˆ†ç±»å™¨ï¼šåœ¨ FairFace æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œå¹¶åˆå¹¶ä¸ºå››ç±»ï¼šWhite, Black, Asian, Indianã€‚
- åˆ†ç±»å™¨ç»“æ„ï¼šè½»é‡çº¿æ€§å¤´ï¼Œæ¥åœ¨ UNet ä¸­é—´å±‚æ¿€æ´»ä¹‹ä¸Šã€‚

---

### å®éªŒè®¾ç½®

#### æç¤ºç”ŸæˆæŒ‡ä»¤
LLM è¢«æ˜ç¡®æŒ‡ç¤ºç”Ÿæˆâ€œä¸æåŠæ€§åˆ«/ç§æ—â€çš„ä¸­æ€§æç¤ºï¼Œä¾‹å¦‚ï¼š
> â€œPlease generate a prompt that generates a photo of a person... Do not mention the person's gender or use gendered pronouns.â€

å¯¹äºåç½®å¼•å¯¼åœºæ™¯ï¼Œåˆ™åŠ å…¥ï¼š
> â€œ...subtly biases the image generation toward male/female representation, while still appearing gender-neutral.â€

#### æœç´¢ç­–ç•¥
- ä½¿ç”¨ **beam search**ï¼Œbeam size = 10ï¼Œexpand factor = 10ã€‚
- æ¯ä¸ªæç¤ºæœ€å¤šç”Ÿæˆ 20 ä¸ª tokenã€‚
- æ¯ä¸ªå®éªŒç”Ÿæˆ 100 ä¸ªæç¤ºï¼Œæ¯ä¸ªæç¤ºç”Ÿæˆ 10 å¼ å›¾åƒç”¨äºè¯„ä¼°ã€‚

---

### è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Group Frequency (e.g., Male%)** | å›¾åƒä¸­è¢«åˆ†ç±»ä¸ºæŸå±æ€§ï¼ˆå¦‚ç”·æ€§ï¼‰çš„æ¯”ä¾‹ï¼Œè¡¡é‡åè§å¼ºåº¦ã€‚ |
| **Perplexity (PPL)** | ä½¿ç”¨ GPT-2 è®¡ç®—æç¤ºçš„å›°æƒ‘åº¦ï¼Œè¡¡é‡è¯­è¨€æµç•…æ€§å’Œå¯è¯»æ€§ã€‚è¶Šä½è¶Šå¥½ã€‚ |
| **Gendered% / Race-biased%** | æç¤ºä¸­æ˜¾å¼æåˆ°æ€§åˆ«æˆ–ç§æ—å…³é”®è¯çš„æ¯”ä¾‹ï¼Œåæ˜ æç¤ºæ˜¯å¦â€œä½œå¼Šâ€ã€‚ç†æƒ³æƒ…å†µä¸‹åº”æ¥è¿‘ 0ã€‚ |
| **Confidence Interval (95%)** | æ‰€æœ‰ç»Ÿè®¡é‡å‡æŠ¥å‘Š Â±95% CIï¼Œå¢å¼ºå¯ä¿¡åº¦ã€‚ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿æ–¹æ³• | æè¿° |
|--------|------|
| **Manually curated** | æ¥è‡ª Shen et al. (2024) çš„æ ‡å‡†èŒä¸šæ¨¡æ¿æç¤ºï¼Œå¦‚ `"A photo of the face of a {occupation}"`ã€‚ |
| **LLM-only** | ä»…ç”± LLM ç”Ÿæˆï¼Œæ— åˆ†ç±»å™¨å¼•å¯¼ã€‚ |
| **LLM (biased)** | LLM è¢«æŒ‡ç¤ºç”Ÿæˆåå‘æ€§æç¤ºï¼Œä½†ä»è¦æ±‚ä¸­ç«‹è¡¨è¾¾ã€‚ |
| **PEZ** | åŸºäº Wen et al. (2023) çš„æ¢¯åº¦ä¼˜åŒ–æ–¹æ³•ï¼Œä»£è¡¨æœ€å…ˆè¿›çš„ç¡¬æç¤ºä¼˜åŒ–æŠ€æœ¯ã€‚ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & 2ï¼‰

#### åœ¨ **Stable Diffusion 1.5 (Base)** ä¸Šçš„ç»“æœ

| æ–¹æ³• | Male% (â†‘) | PPL (â†“) | Gendered% (â†“) |
|------|----------|--------|--------------|
| Manually curated | 53% | 96 | 0% |
| PEZ | 80% | 1387 | 94% |
| LLM-only | 69% | 71 | 1% |
| **BGPS (Î»=100)** | **92%** | **122** | **17%** |

> âœ… BGPS å°†ç”·æ€§ç”Ÿæˆæ¯”ä¾‹ä»åŸºçº¿ 53% æ¨é«˜è‡³ **92%**ï¼Œè¿œè¶…æ‰‹å·¥æç¤ºå’Œ LLM-only æ–¹æ³•ã€‚

#### åœ¨ **Debiased Model (FT)** ä¸Šçš„ç»“æœ

| æ–¹æ³• | Male% (â†‘) | PPL (â†“) | Gendered% (â†“) |
|------|----------|--------|--------------|
| Manually curated | 49% | 96 | 0% |
| PEZ | 78% | 2703 | 94% |
| LLM-only | 59% | 71 | 1% |
| **BGPS (Î»=100)** | **79%** | **90** | **22%** |

> ğŸ”¥ å³ä½¿åœ¨ç»è¿‡å»åå¤„ç†çš„æ¨¡å‹ä¸Šï¼ŒBGPS ä»èƒ½è¯±å¯¼å‡ºé«˜è¾¾ **79% çš„ç”·æ€§ç”Ÿæˆç‡**ï¼Œè¯´æ˜å½“å‰å»åæ–¹æ³•å­˜åœ¨ä¸¥é‡æ¼æ´ã€‚

---

### ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯”ä¼˜åŠ¿

| ç»´åº¦ | ç»“æœ |
|------|------|
| **åè§æš´éœ²èƒ½åŠ›** | BGPS åœ¨ debiased æ¨¡å‹ä¸Šå®ç° **76â€“79% Male**ï¼Œè€Œæ‰‹åŠ¨æç¤ºä»…ä¸º 49%ï¼Œæ­ç¤ºäº†æ®‹ä½™åè§ã€‚ |
| **è¯­è¨€è´¨é‡ï¼ˆPPLï¼‰** | BGPS çš„ PPL ä¸º **50â€“160**ï¼Œè€Œ PEZ è¾¾åˆ° **1387â€“2703**ï¼Œè¡¨æ˜å…¶æç¤ºé«˜åº¦å¯è¯»ã€‚ |
| **æ•ˆç‡ä¸å®ç”¨æ€§** | ç›¸æ¯”éœ€åå‘ä¼ æ’­æ•´ä¸ªæ‰©æ•£è¿‡ç¨‹çš„ PEZï¼ŒBGPS æ˜¯**æ¢¯åº¦è‡ªç”±**ï¼ˆgradient-freeï¼‰æ–¹æ³•ï¼Œè®¡ç®—æˆæœ¬æ›´ä½ã€‚ |
| **æ³›åŒ–æ€§** | æˆåŠŸåº”ç”¨äºæ€§åˆ«ã€ç§æ—ã€å¹´é¾„ç­‰å¤šç§å±æ€§ï¼Œä¸”é€‚ç”¨äºå¤šä¸»ä½“åœºæ™¯ï¼ˆè§ Table 9ï¼‰ã€‚ |

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ä¸åŒ Î» å€¼çš„å½±å“ï¼ˆTrade-off between Bias and PPLï¼‰
- Î» æ§åˆ¶åˆ†ç±»å™¨å¾—åˆ†ä¸è¯­è¨€å…ˆéªŒä¹‹é—´çš„æƒé‡ã€‚
- Î»=10ï¼šè½»å¾®æå‡åè§ï¼ŒPPL å‡ ä¹ä¸å˜ã€‚
- Î»=100ï¼šæ˜¾è‘—æ”¾å¤§åè§ï¼ˆMale% â†‘~40%ï¼‰ï¼ŒPPL ä¸Šå‡ä½†ä»åˆç†ï¼ˆ<200ï¼‰ã€‚
- è¡¨æ˜å¯é€šè¿‡è°ƒèŠ‚ Î» å®ç°â€œå¯æ§åè§æ¢æµ‹â€ã€‚

#### ä¸åŒ Kï¼ˆé‡‡æ ·å™ªå£°æ•°ï¼‰çš„å½±å“ï¼ˆH.1ï¼‰
- K=10 å·²è¶³å¤Ÿç¨³å®šä¼°è®¡æœŸæœ›å€¼ï¼Œè¿›ä¸€æ­¥å¢åŠ å¯¹æ€§èƒ½å½±å“ä¸å¤§ã€‚
- æ”¯æŒä½¿ç”¨è¾ƒå° K å®ç°é«˜æ•ˆè¯„ä¼°ã€‚

#### ä¸åŒ T'ï¼ˆæ‰©æ•£æ—¶é—´æ­¥ï¼‰çš„å½±å“ï¼ˆH.2ï¼‰
- åœ¨ä¸åŒå»å™ªé˜¶æ®µï¼ˆT'=10~45ï¼‰æå–ç‰¹å¾ï¼Œåè§å¼ºåº¦å˜åŒ–å¾ˆå°ã€‚
- è¯´æ˜ä¸­é—´å±‚è¡¨ç¤ºå¯¹åè§æ•æ‰å…·æœ‰é²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. âœ… **å»åæ¨¡å‹ä»å­˜ä¸¥é‡æ¼æ´**  
   å½“å‰ä¸»æµå»åæ–¹æ³•ï¼ˆå¦‚ LoRA å¾®è°ƒï¼‰åœ¨æ ‡å‡†æµ‹è¯•é›†ä¸Šè¡¨ç°è‰¯å¥½ï¼ˆ~49% Maleï¼‰ï¼Œä½†åœ¨ BGPS å‘ç°çš„ä¸Šä¸‹æ–‡æç¤ºä¸‹ï¼Œä»ä¼šé€€åŒ–ä¸º **76â€“79% Male**ï¼Œæš´éœ²å…¶è„†å¼±æ€§ã€‚

2. âœ… **ç»†å¾®è¯­è¨€ä¿®é¥°å³å¯å¼ºçƒˆæ”¾å¤§åè§**  
   æ·»åŠ å¦‚ `"with intense focus"` æˆ– `"compassionate eyes"` ç­‰æè¿°è¯ï¼Œå¯ä½¿ç§‘å­¦å®¶æ€§åˆ«åˆ†å¸ƒä» 65% Male è·ƒå‡è‡³ **95% Male**ï¼Œæ­ç¤ºè¯­è¨€ä¸åˆ»æ¿å°è±¡çš„æ·±å±‚å…³è”ã€‚

3. âœ… **ç³»ç»Ÿæ€§è¯­è¨€æ¨¡å¼ç¼–ç ç¤¾ä¼šåè§**  
   - **æ€ç»´ç›¸å…³è¯æ±‡**ï¼ˆserious, concernedï¼‰â†’ å…³è”ç”·æ€§
   - **æƒ…æ„Ÿç›¸å…³è¯æ±‡**ï¼ˆcompassionate, joyfulï¼‰â†’ å…³è”å¥³æ€§
   - **æ”¿æ²»/ä½“è‚²è¯æ±‡** â†’ æ›´å¸¸å‡ºç°åœ¨é»‘äººå½¢è±¡æç¤ºä¸­
   - **ä¸“ä¸š/ç§‘æŠ€è¯æ±‡** â†’ æ›´å¸¸å‡ºç°åœ¨ç™½äººå½¢è±¡æç¤ºä¸­

4. âœ… **BGPS å‘ç°çš„æç¤ºæ˜¯å¯è§£é‡Šä¸”å®ç”¨çš„**  
   ç”Ÿæˆçš„æç¤ºå¦‚ï¼š
   > *"A photo of a person working as a tech programmer at a sleek desktop, deep in concentration with a cup of coffee nearby."*
   è¿™ç±»æç¤ºæ™®é€šç”¨æˆ·å®Œå…¨å¯èƒ½è¾“å…¥ï¼Œå› æ­¤å…·æœ‰ç°å®å®¡è®¡ä»·å€¼ã€‚

5. âœ… **è¶…è¶ŠèŒä¸šåˆ»æ¿å°è±¡**  
   BGPS æˆåŠŸåœ¨â€œäººç‰©+ç‰©ä½“â€ã€â€œäººç‰©+æ´»åŠ¨â€ã€â€œäººç‰©+æƒ…å¢ƒâ€ç­‰éèŒä¸šç±»åˆ«ä¸­å‘ç°åè§ï¼ˆè§ Table 4ï¼‰ï¼Œæ‹“å±•äº†åè§ç ”ç©¶è¾¹ç•Œã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

| å±€é™ | è¯´æ˜ |
|------|------|
| **ä¾èµ–å¤–éƒ¨åˆ†ç±»å™¨** | å±æ€§åˆ†ç±»å™¨æœ¬èº«å¯èƒ½å¼•å…¥åå·®ï¼Œä¸”è®­ç»ƒéœ€è¦æ ‡æ³¨æ•°æ®ã€‚ |
| **å±æ€§ç²’åº¦æœ‰é™** | å½“å‰ä»…æ”¯æŒç²—ç²’åº¦æ€§åˆ«/ç§æ—åˆ†ç±»ï¼Œç¼ºä¹æ›´ç»†ç»´åº¦ï¼ˆå¦‚éäºŒå…ƒæ€§åˆ«ã€å…·ä½“æ°‘æ—ï¼‰ã€‚ |
| **LLM æŒ‡ä»¤éµå¾ªèƒ½åŠ›å·®å¼‚** | å°å‹ LLMï¼ˆå¦‚ Llama-3.2Bï¼‰æ›´å®¹æ˜“è¿åâ€œä¸å¾—æåŠæ€§åˆ«â€çš„æŒ‡ä»¤ï¼Œå½±å“å…¬å¹³æ¯”è¾ƒã€‚ |
| **æœªè€ƒè™‘æ–‡åŒ–å¤šæ ·æ€§** | æ‰€æœ‰æç¤ºä¸ºè‹±æ–‡ï¼ŒæœªéªŒè¯è·¨è¯­è¨€/æ–‡åŒ–çš„é€‚ç”¨æ€§ã€‚ |

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **æ„å»ºæ›´ç²¾ç»†çš„å±æ€§åˆ†ç±»ä½“ç³»**ï¼Œæ”¯æŒéäºŒå…ƒæ€§åˆ«ã€å¤šå…ƒæ–‡åŒ–èº«ä»½è¯†åˆ«ã€‚
2. **å°† BGPS ç”¨äºä¸»åŠ¨å»åè®­ç»ƒ**ï¼šå°†å‘ç°çš„é«˜åè§æç¤ºåŠ å…¥è®­ç»ƒé›†ï¼Œæå‡æ¨¡å‹é²æ£’æ€§ã€‚
3. **å¼€å‘äº¤äº’å¼å®¡è®¡å·¥å…·**ï¼šè®©éæŠ€æœ¯äººå‘˜ä¹Ÿèƒ½ä½¿ç”¨ BGPS æ¢ç´¢æ¨¡å‹åè§ã€‚
4. **æ‰©å±•è‡³å…¶ä»–æ¨¡æ€ä¸ä»»åŠ¡**ï¼šå¦‚è§†é¢‘ç”Ÿæˆã€è¯­éŸ³åˆæˆç­‰é¢†åŸŸçš„åè§æ¢æµ‹ã€‚
5. **ç»“åˆå› æœåˆ†æ**ï¼šæ¢ç©¶ä¸ºä½•æŸäº›è¯è¯­ä¼šè§¦å‘ç‰¹å®šåè§ï¼Œæ¨åŠ¨æœºåˆ¶å¯è§£é‡Šæ€§ç ”ç©¶ã€‚

---

## æ€»ç»“

> **BGPS æ˜¯é¦–ä¸ªèƒ½å¤Ÿåœ¨ä¿æŒæç¤ºå¯è§£é‡Šæ€§çš„åŒæ—¶ï¼Œè‡ªåŠ¨åŒ–æ¢ç´¢ text-to-image æ¨¡å‹ä¸­éšè—åè§çš„æ¡†æ¶ã€‚å®ƒä¸ä»…æ­ç¤ºäº†å½“å‰å»åæ–¹æ³•çš„é‡å¤§ç¼ºé™·ï¼Œä¹Ÿä¸ºæœªæ¥æ¨¡å‹å®¡è®¡æä¾›äº†å¼ºå¤§è€Œå®ç”¨çš„æ–°å·¥å…·ã€‚**

è¯¥å·¥ä½œå…¼å…·æŠ€æœ¯æ·±åº¦ä¸ç¤¾ä¼šæ„ä¹‰ï¼Œæ¨åŠ¨äº† AI å…¬å¹³æ€§ç ”ç©¶ä»â€œé™æ€è¯„æµ‹â€èµ°å‘â€œåŠ¨æ€æ”»é˜²â€ï¼Œæ˜¯ bias evaluation é¢†åŸŸçš„é‡è¦è¿›å±•ã€‚

</details>

---

### 9. [Prismatic World Model: Learning Compositional Dynamics for Planning in Hybrid Systems](https://arxiv.org/abs/2512.08411)

**Authors**: Mingwei Li, Xiaoyuan Zhang, Chengwei Yang, Zilong Zheng, Yaodong Yang  
**Category**: cs.AI  
**Published**: 2025-12-10  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.08411v1  

#### Abstract
Model-based planning in robotic domains is fundamentally challenged by the hybrid nature of physical dynamics, where continuous motion is punctuated by discrete events such as contacts and impacts. Conventional latent world models typically employ monolithic neural networks that enforce global conti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPrismatic World Model: Learning Compositional Dynamics for Planning in Hybrid Systems

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåŸºäº**latent world model**çš„æ¨¡å‹åœ¨å¤„ç†æœºå™¨äººé¢†åŸŸçš„**hybrid dynamics**ï¼ˆæ··åˆåŠ¨åŠ›å­¦ï¼‰æ—¶å­˜åœ¨ä¸¥é‡ç¼ºé™·ã€‚è¿™ç±»ç³»ç»Ÿï¼ˆå¦‚è…¿éƒ¨è¿åŠ¨ã€æŠ“å–æ“ä½œï¼‰æ¶‰åŠè¿ç»­è¿åŠ¨ä¸ç¦»æ•£äº‹ä»¶ï¼ˆå¦‚æ¥è§¦ã€ç¢°æ’ï¼‰ä¹‹é—´çš„é¢‘ç¹åˆ‡æ¢ï¼Œå¯¼è‡´åŠ¨åŠ›å­¦éå…‰æ»‘ä¸”é«˜åº¦éçº¿æ€§ã€‚

ä¸»æµçš„å•ä½“ç¥ç»ç½‘ç»œï¼ˆmonolithic neural networksï¼‰å€¾å‘äºå­¦ä¹ â€œå¹³å‡â€åŠ¨æ€æ¨¡å¼ï¼Œå¯¹ç‰©ç†çŠ¶æ€é—´çš„**sharp mode transitions**ï¼ˆå¦‚é£è¡Œ vs. æ¥è§¦ã€æ»‘åŠ¨ vs. é»è¿ï¼‰è¿›è¡Œè¿‡åº¦å¹³æ»‘ï¼ˆover-smoothingï¼‰ï¼Œä»è€Œåœ¨é•¿è§†ç•Œè§„åˆ’ä¸­äº§ç”Ÿ**compounding errors**ï¼Œä½¿è®¡åˆ’ä¸å¯é ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šPrismatic World Model (PRISM-WM)
ä½œè€…æå‡º **PRISM-WM**ï¼Œä¸€ç§å—æ£±é•œåˆ†å…‰å¯å‘çš„ç»“æ„åŒ–ä¸–ç•Œæ¨¡å‹ï¼Œé€šè¿‡ä»¥ä¸‹ä¸‰ä¸ªæ ¸å¿ƒæœºåˆ¶è§£å†³ä¸Šè¿°é—®é¢˜ï¼š

- **Mode Identificationï¼ˆæ¨¡å¼è¯†åˆ«ï¼‰**  
  å¼•å…¥ä¸€ä¸ªä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„ **Gating Network**ï¼Œéšå¼è¯†åˆ«å½“å‰æ‰€å¤„çš„ç‰©ç†æ¨¡å¼ï¼ˆå¦‚â€œæ¥è§¦â€æˆ–â€œé£è¡Œâ€é˜¶æ®µï¼‰ï¼Œå®ç°åŠ¨æ€åˆ‡æ¢ã€‚

- **Specialized Dynamicsï¼ˆä¸“ä¸šåŒ–åŠ¨åŠ›å­¦å»ºæ¨¡ï¼‰**  
  é‡‡ç”¨ **Mixture-of-Experts (MoE)** æ¶æ„ï¼Œæ¯ä¸ªä¸“å®¶ç½‘ç»œä¸“æ³¨äºç‰¹å®šå±€éƒ¨åŠ¨åŠ›å­¦ï¼ˆå¦‚è¡Œèµ°ã€å¹³è¡¡ï¼‰ï¼Œé¿å…å•ä¸€æ¨¡å‹å› æ‹Ÿåˆæ‰€æœ‰æ¨¡å¼è€Œå¯¼è‡´çš„å¹²æ‰°å’Œå¹³æ»‘é—®é¢˜ã€‚

- **Orthogonality for Distinct Primitivesï¼ˆæ­£äº¤åŒ–ä»¥ç¡®ä¿å¤šæ ·æ€§ï¼‰**  
  å¼•å…¥**latent orthogonalization objective**ï¼ˆæ½œç©ºé—´æ­£äº¤åŒ–ç›®æ ‡ï¼‰ï¼Œé€šè¿‡ Gram-Schmidt æ­£äº¤åŒ–å¼ºåˆ¶ä¸“å®¶è¾“å‡ºç‰¹å¾çº¿æ€§æ— å…³ï¼Œé˜²æ­¢â€œmode collapseâ€ï¼ˆæ¨¡å¼åç¼©ï¼‰ï¼Œæå‡è¡¨è¾¾èƒ½åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´å‡†ç¡®çš„é•¿æœŸé¢„æµ‹**ï¼šæ˜¾è‘—é™ä½ rollout driftï¼Œæ”¯æŒæ›´é•¿çš„ planning horizonã€‚
- **æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›**ï¼šåœ¨å¤šä»»åŠ¡åœºæ™¯ä¸‹æœ‰æ•ˆç¼“è§£è´Ÿè¿ç§»ï¼ˆnegative transferï¼‰ã€‚
- **æ›´é«˜çš„æ ·æœ¬æ•ˆç‡ä¸æœ€ç»ˆæ€§èƒ½**ï¼šå°¤å…¶åœ¨é«˜ç»´ã€å¤æ‚ä»»åŠ¡ï¼ˆå¦‚ humanoid æ§åˆ¶ï¼‰ä¸Šè¡¨ç°çªå‡ºã€‚
- **å®æ—¶æ¨ç†é«˜æ•ˆ**ï¼šå°½ç®¡å‚æ•°æ›´å¤šï¼Œä½†ç”±äºç¨€ç–æ¿€æ´»ï¼Œæ¨ç†é€Ÿåº¦ä¼˜äºæˆ–æ¥è¿‘å•ä½“æ¨¡å‹ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸ç¯å¢ƒ
å®éªŒè¦†ç›–å¤šä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„è¿ç»­æ§åˆ¶åŸºå‡†ï¼Œæ¶µç›–ä¸åŒç‰©ç†ç‰¹æ€§ä¸ä»»åŠ¡å¤æ‚åº¦ï¼š

| ç±»åˆ« | ç¯å¢ƒ |
|------|------|
| **DiffRL** | Ant, Anymal, Hopper, Humanoid, SNU-Humanoidï¼ˆå¼ºè°ƒæ¥è§¦ä¸°å¯Œçš„è¿åŠ¨ï¼‰ |
| **DMControl MT30** | 30ä¸ªå¤šæ ·åŒ–ä»»åŠ¡ï¼ŒåŒ…æ‹¬ locomotionã€balanceã€manipulationã€swimming ç­‰ |
| **Humanoid-Bench** | Run, Slide, Pole, Mazeï¼ˆé«˜ç»´å…¨èº« humanoid æ§åˆ¶ä»»åŠ¡ï¼‰ |

è¿™äº›ä»»åŠ¡å…±åŒæ„æˆå¯¹æ¨¡å‹å¤„ç†**å¼‚è´¨åŠ¨åŠ›å­¦**ï¼ˆheterogeneous dynamicsï¼‰èƒ½åŠ›çš„å…¨é¢æµ‹è¯•ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **é›†æˆæ¡†æ¶**ï¼šå°† PRISM-WM æ›¿æ¢ä¸º TD-MPC2 å’Œ PWM ä¸­çš„åŸå§‹å•ä½“ world modelï¼Œä¿æŒå…¶ä»–è¶…å‚ä¸€è‡´ã€‚
- **ä¸“å®¶æ•°é‡**ï¼šç»Ÿä¸€ä½¿ç”¨ $ K=4 $ ä¸ªä¸“å®¶ã€‚
- **è®­ç»ƒæ­¥æ•°**ï¼š
  - DiffRL / Humanoid-Benchï¼šæœ€å¤š 20M ç¯å¢ƒæ­¥
  - MT30ï¼š3M ç¯å¢ƒæ­¥åæŠ¥å‘Šå½’ä¸€åŒ–å¾—åˆ†
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - å¹³å‡ episode rewardï¼ˆä¸»æŒ‡æ ‡ï¼‰
  - å½’ä¸€åŒ–ä»»åŠ¡å¾—åˆ†ï¼ˆMT30ï¼‰
  - åŠ¨åŠ›å­¦é¢„æµ‹è¯¯å·®ï¼ˆMSE over horizonï¼‰
  - è§„åˆ’ horizon å†…çš„çŠ¶æ€ä¿çœŸåº¦
  - æ¨ç†å»¶è¿Ÿã€ååé‡ã€GPU å†…å­˜å ç”¨

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| **TD-MPC2** | Model-based, online planning | å½“å‰æœ€å…ˆè¿›çš„åŸºäº latent planning çš„æ–¹æ³• |
| **PWM** | Model-based, direct policy learning | ç»“åˆå¯å¾®è§„åˆ’çš„å­¦ä¹ ç­–ç•¥ |
| **DreamerV3** | Latent dynamics model | åŸºäº imagination çš„å¼ºåŸºçº¿ |
| **SAC** | Model-free | é«˜æ•ˆçš„æ— æ¨¡å‹å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œç”¨äºæ ·æœ¬æ•ˆç‡æ¯”è¾ƒ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰DiffRL é«˜ç»´è¿åŠ¨ä»»åŠ¡ï¼ˆå›¾4ï¼‰
- åœ¨ **Humanoid** å’Œ **SNU-Humanoid** ä¸Šï¼ŒPRISM-WM æ˜¾è‘—è¶…è¶Šæ‰€æœ‰åŸºçº¿ï¼š
  - æ›´å¿«æ”¶æ•›ï¼ˆæ›´é«˜æ ·æœ¬æ•ˆç‡ï¼‰
  - æœ€ç»ˆå¥–åŠ±é«˜å‡ºæ˜æ˜¾å¹…åº¦
- åœ¨ Antã€Anymalã€Hopper ä¸Šä¹Ÿè¡¨ç°å‡ºç¨³å®šä¼˜åŠ¿ã€‚

#### ï¼ˆ2ï¼‰MT30 å¤šä»»åŠ¡æ³›åŒ–ï¼ˆå›¾5ï¼‰
- **å¹³å‡å½’ä¸€åŒ–å¾—åˆ†ï¼š0.531**ï¼Œç›¸æ¯” TD-MPC2ï¼ˆ0.430ï¼‰æå‡ **23.5%**
- åœ¨ 300 ä¸ªä»»åŠ¡å®ä¾‹ä¸­ï¼Œ**266 é¡¹èƒœå‡º**
- å•é¡¹æœ€å¤§å¢ç›Šè¾¾ +0.31ï¼ˆCheetah-run-backwardsï¼‰
- åœ¨å·²æœ‰å¼ºåŸºçº¿çš„ä»»åŠ¡ä¸Šæ€§èƒ½æ³¢åŠ¨æå°ï¼ˆÂ±0.02ï¼‰ï¼Œè¡¨æ˜ä¸ä¼šæŸå®³å·²è§£å†³é—®é¢˜çš„è¡¨ç°

#### ï¼ˆ3ï¼‰Humanoid-Bench å¤æ‚æ§åˆ¶ï¼ˆå›¾6ï¼‰
- åœ¨ Runã€Slideã€Poleã€Maze å››é¡¹ä»»åŠ¡ä¸Šå‡å¤§å¹…é¢†å…ˆï¼š
  - å­¦ä¹ æ›²çº¿æ›´å¹³ç¨³ï¼Œæ— å‰§çƒˆéœ‡è¡
  - TD-MPC2 å‡ºç°å‘¨æœŸæ€§å´©æºƒï¼Œè€Œ PRISM-WM èƒ½æŒç»­ä¼˜åŒ–
- ç‰¹åˆ«æ˜¯åœ¨éœ€åŒæ—¶å®Œæˆè¡Œèµ°ä¸æ¬¡çº§ç›®æ ‡ï¼ˆå¦‚æŒæ†ã€èµ°è¿·å®«ï¼‰çš„ä»»åŠ¡ä¸­ä¼˜åŠ¿æ˜¾è‘—

#### ï¼ˆ4ï¼‰åŠ¨åŠ›å­¦é¢„æµ‹ç²¾åº¦åˆ†æï¼ˆå›¾7â€“8ï¼‰
- **é•¿æœŸé¢„æµ‹è¯¯å·®æ›´ä½**ï¼š
  - åœ¨é¢„æµ‹ horizon=10 æ—¶ï¼ŒPRISM-WM çš„ latent dynamics MSE æ¯” MLP åŸºçº¿ä½çº¦ 50%
- **æœ‰æ•ˆè§„åˆ’è§†ç•Œæ‰©å±•è‡³ H=30**ï¼š
  - å•ä½“æ¨¡å‹åœ¨ H>5 åè¿…é€Ÿå‘æ•£ï¼ˆå‡ºç°â€œåœ°é¢ç©¿é€â€ç­‰ä¸åˆç†çŠ¶æ€ï¼‰
  - PRISM-WM ç»´æŒè½¨è¿¹åˆç†æ€§ç›´è‡³ H=30ï¼Œä¿éšœä»·å€¼ä¼°è®¡æœ‰æ•ˆæ€§

#### ï¼ˆ5ï¼‰æ¶ˆèå®éªŒç»“æœ
- **æ­£äº¤åŒ–ï¼ˆOrthogonalizationï¼‰è‡³å…³é‡è¦**ï¼š
  - ä¸å¸¦æ­£äº¤åŒ–çš„ MoEï¼ˆ~9M å‚æ•°ï¼‰è™½å‡å°‘ dynamics errorï¼Œä½†åœ¨ reward prediction ä¸Šè¡¨ç°å·®
  - å¸¦æ­£äº¤åŒ–çš„ PRISM-WMï¼ˆä»… ~5M å‚æ•°ï¼‰åœ¨ dynamics å’Œ reward ä¸¤æ–¹é¢å‡æ›´ä¼˜ â†’ **ç»“æ„ä¼˜äºè§„æ¨¡**
- **ä¸“å®¶æ•°é‡æ•æ„Ÿæ€§ä½**ï¼ˆå›¾8ï¼‰ï¼š
  - $ K=2,4,6 $ å‡æ˜¾è‘—ä¼˜äºå•ä½“æ¨¡å‹
  - $ K=4 $ è¡¨ç°æœ€ä½³ï¼Œ$ K=6 $ æœ‰è½»å¾®è¿‡æ‹Ÿåˆè¶‹åŠ¿
  - æ€§èƒ½å·®å¼‚ä¸»è¦æ¥è‡ªâ€œåˆ†è§£â€æœ¬èº«ï¼Œè€Œéç²¾ç»†è°ƒå‚

#### ï¼ˆ6ï¼‰å®æ—¶æ¨ç†æ•ˆç‡ï¼ˆè¡¨1ï¼‰
| æ¨¡å‹ | ååé‡ (FPS) | æ¨ç†å»¶è¿Ÿ (ms) | GPUå†…å­˜ (GB) | ç›¸å¯¹é€Ÿåº¦ |
|------|--------------|----------------|---------------|------------|
| MLP (baseline) | 7,499 | 0.13 | 0.09 | 1.00Ã— |
| PRISM-WM (K=4) | **7,712** | 0.13 | 0.11 | **1.03Ã—** |
| PRISM-WM (K=2) | 6,983 | 0.14 | **0.07** | 0.93Ã— |

â†’ å°½ç®¡æ€»å‚æ•°å¢åŠ ï¼Œä½†å› ç¨€ç–æ¿€æ´»ï¼Œ**å®é™…æ¨ç†æ›´å¿«**ï¼Œé€‚åˆå®æ—¶æœºå™¨äººæ§åˆ¶ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç»“æ„å…ˆéªŒä¼˜äºçº¯å®¹é‡æ‰©å±•**ï¼š  
   é€šè¿‡ MoE + æ­£äº¤åŒ–æ„å»ºçš„ç»“æ„æ€§åˆ†è§£ï¼Œæ¯”å•çº¯æ‰©å¤§æ¨¡å‹è§„æ¨¡æ›´èƒ½æå‡ world model çš„ä¿çœŸåº¦ã€‚

2. **è‡ªåŠ¨å‘ç°è¯­ä¹‰ç‰©ç†æ¨¡å¼**ï¼š  
   Gating Network è‡ªå‘åœ°å°†ä»»åŠ¡èšç±»ä¸ºæœ‰æ„ä¹‰çš„ç±»åˆ«ï¼ˆå¦‚ locomotion vs. balanceï¼‰ï¼Œæ— éœ€æ˜¾å¼ç›‘ç£ã€‚

3. **æ˜¾è‘—å»¶é•¿å¯é è§„åˆ’è§†ç•Œ**ï¼š  
   æœ‰æ•ˆæŠ‘åˆ¶ compounding errorï¼Œä½¿å¾— H=30 çš„ long-horizon planning æˆä¸ºå¯èƒ½ï¼Œæå¤§å¢å¼º agent çš„è¿œè§èƒ½åŠ›ã€‚

4. **é€šç”¨å¢å¼ºæ¨¡å—**ï¼š  
   PRISM-WM å¯ä½œä¸ºâ€œdrop-in replacementâ€æ— ç¼é›†æˆåˆ° TD-MPCã€PWM ç­‰ä¸»æµ MBRL æ¡†æ¶ä¸­ï¼ŒåŒæ—¶æå‡ planning ä¸ policy learning æ•ˆæœã€‚

5. **çœŸå®æ‰°åŠ¨ä¸‹çš„é²æ£’å“åº”**ï¼ˆå›¾9ï¼‰ï¼š  
   å¤–éƒ¨å†²å‡»è§¦å‘ sharp mode switchingï¼Œæ¨¡å‹èƒ½å¿«é€Ÿåˆ‡æ¢è‡³ stabilizer ä¸“å®¶å¹¶æ¢å¤ç¨³å®šèŠ‚å¾‹ï¼ŒéªŒè¯å…¶æ•æ‰ hybrid dynamics çš„å› æœèƒ½åŠ›ã€‚

### å±€é™æ€§
- **ä¸“å®¶æ•°é‡ $ K $ éœ€æ‰‹åŠ¨è®¾å®š**ï¼šç¼ºä¹è‡ªåŠ¨ç¡®å®šæœ€ä¼˜ä¸“å®¶æ•°çš„æ–¹æ³•ã€‚
- **åŠ æƒç»„åˆé™åˆ¶è¡¨è¾¾èƒ½åŠ›**ï¼šç›®å‰ä½¿ç”¨ç®€å•åŠ æƒå’Œï¼Œæœªæ¢ç´¢æ›´å¤æ‚çš„ç»„åˆå‡½æ•°ï¼ˆå¦‚é€’å½’ã€æ¡ä»¶åˆ†æ”¯ï¼‰ã€‚
- **å®Œå…¨å¯è§‚æµ‹å‡è®¾**ï¼šå½“å‰å®éªŒåŸºäº fully observable çŠ¶æ€ï¼Œå°šæœªéªŒè¯åœ¨éƒ¨åˆ†è§‚æµ‹ï¼ˆpartial observabilityï¼‰ä¸‹çš„è¡¨ç°ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- è‡ªåŠ¨å­¦ä¹ æˆ–åŠ¨æ€è°ƒæ•´ä¸“å®¶æ•°é‡ï¼ˆå¦‚ growth/shrinking mechanismsï¼‰
- æ¢ç´¢æ›´å¤æ‚çš„ composition functionsï¼ˆéçº¿æ€§ç»„åˆã€æ³¨æ„åŠ›è·¯ç”±ç­‰ï¼‰
- æ‰©å±•è‡³çœŸå®æœºå™¨äººåœºæ™¯ï¼Œå°¤å…¶æ˜¯æ¶‰åŠå¤šæ ·ç‰©ç†äº¤äº’ä¸ä¸ç¡®å®šæ€§ç¯å¢ƒçš„åº”ç”¨
- å°†â€œdynamic decompositionâ€æ€æƒ³æ¨å¹¿è‡³ social dynamics æˆ– multi-agent setting

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> PRISM-WM é€šè¿‡å¼•å…¥ **context-aware MoE + latent orthogonalization** çš„ç»“æ„åŒ–è®¾è®¡ï¼ŒæˆåŠŸè§£å†³äº† hybrid systems ä¸­ world model çš„ over-smoothing é—®é¢˜ï¼Œåœ¨å¤šç§é«˜ç»´ã€å¤šä»»åŠ¡ã€æ¥è§¦å¯†é›†å‹æ§åˆ¶ä»»åŠ¡ä¸­å®ç°äº†æ›´å‡†ç¡®çš„åŠ¨åŠ›å­¦å»ºæ¨¡ä¸æ›´å¯é çš„ long-horizon planningï¼Œå±•ç°å‡ºæˆä¸ºä¸‹ä¸€ä»£ MBRL åŸºç¡€æ¨¡å‹çš„å·¨å¤§æ½œåŠ›ã€‚

</details>

---

### 10. [Adaptation of Embedding Models to Financial Filings via LLM Distillation](https://arxiv.org/abs/2512.08088)

**Authors**: Eliot Brenner, Dominic Seyler, Manjunath Hegde, Andrei Simion, Koustuv Dasgupta, Bing Xiang  
**Category**: cs.CL  
**Published**: 2025-12-10  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.08088v1  

#### Abstract
Despite advances in generative large language models (LLMs), practical application of specialized conversational AI agents remains constrained by computation costs, latency requirements, and the need for precise domain-specific relevance measures. While existing embedding models address the first tw...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Adaptation of Embedding Models to Financial Filings via LLM Distillation â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç†è§£é‡‘èæ–‡æœ¬æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†ç”±äºå…¶é«˜è®¡ç®—æˆæœ¬ã€é•¿ä¸Šä¸‹æ–‡å¤„ç†èƒ½åŠ›æœ‰é™ä»¥åŠå»¶è¿Ÿè¦æ±‚ï¼Œéš¾ä»¥ç›´æ¥ç”¨äºç”Ÿäº§ç¯å¢ƒä¸­çš„é«˜æ•ˆæ£€ç´¢ä»»åŠ¡ã€‚ç°æœ‰çš„é€šç”¨ embedding æ¨¡å‹ï¼ˆå¦‚ OpenAI çš„ text-embedding-ada-002ï¼‰åœ¨**é‡‘èé¢†åŸŸ**çš„ä¿¡æ¯æ£€ç´¢ï¼ˆInformation Retrieval, IRï¼‰ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤æ‚çš„ SEC EDGAR è´¢åŠ¡æ–‡ä»¶æ—¶å­˜åœ¨è¯­ä¹‰åŒ¹é…ä¸å‡†ç¡®ã€å¬å›ç‡ä½ç­‰é—®é¢˜ã€‚

å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- å¦‚ä½•åœ¨ä¸ä¾èµ–äººå·¥æ ‡æ³¨çš„å‰æä¸‹ï¼Œä¸ºé‡‘èé¢†åŸŸçš„ RAGï¼ˆRetrieval-Augmented Generationï¼‰ç³»ç»Ÿè®­ç»ƒä¸€ä¸ª**é«˜æ€§èƒ½ã€ä½æˆæœ¬ã€ä½å»¶è¿Ÿçš„ä¸“ç”¨ embedding æ¨¡å‹**ã€‚
- å¦‚ä½•æå‡æ£€ç´¢æ¨¡å‹å¯¹è´¢åŠ¡æŠ¥å‘Šä¸­è¡¨æ ¼ã€æŠ€æœ¯æœ¯è¯­å’Œæ¦‚å¿µå…³ç³»çš„ç†è§£èƒ½åŠ›ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹

ä½œè€…æå‡ºäº†ä¸€ç§åŸºäº **LLM Distillation çš„è¿­ä»£å¼æ£€ç´¢æ¨¡å‹å¾®è°ƒæ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨å¼ºå¤§çš„ LLM ä½œä¸ºâ€œæ•™å¸ˆâ€æ¥ç”Ÿæˆè®­ç»ƒä¿¡å·ï¼ŒæŒ‡å¯¼è½»é‡çº§ bi-encoder æ£€ç´¢å™¨ï¼ˆâ€œå­¦ç”Ÿâ€ï¼‰è¿›è¡Œé¢†åŸŸé€‚åº”ã€‚

#### ä¸»è¦åˆ›æ–°åŒ…æ‹¬ï¼š

1. **LLM-Judged Relevance Distillation Pipeline**
   - åˆ©ç”¨å¼€æº LLMï¼ˆLlama-3.1-70B-Instructï¼‰ä»æ— æ ‡ç­¾çš„ SEC è´¢æŠ¥ä¸­è‡ªåŠ¨ç”ŸæˆæŸ¥è¯¢ï¼ˆqueriesï¼‰ï¼Œå¹¶å¯¹å€™é€‰æ®µè½æ‰“åˆ†ï¼ˆ1â€“4 åˆ†ï¼‰ï¼Œæ„å»ºé«˜è´¨é‡çš„ç›‘ç£ä¿¡å·ã€‚
   - è¿™äº›è¯„åˆ†ç”¨äºæ„é€  contrastive training triplesï¼š`(q, c_rel, c_irrel)`ï¼Œå…¶ä¸­æ­£è´Ÿæ ·æœ¬å‡æ¥è‡ªåŒä¸€æ–‡æ¡£ï¼Œç¡®ä¿æ¨¡å‹å­¦ä¹ åˆ°**ç»†ç²’åº¦çš„ within-document æ£€ç´¢èƒ½åŠ›**ã€‚

2. **Hard Example Mining with Iterative Refinement**
   - å¼•å…¥**äº¤äº’å¼æŒ–æ˜æœºåˆ¶**ï¼šæ¯è½®è¿­ä»£ä½¿ç”¨å½“å‰å­¦ç”Ÿæ¨¡å‹ï¼ˆbi-enc(i)ï¼‰åœ¨å¤§è§„æ¨¡è¯­æ–™åº“ä¸­æ£€ç´¢ top-K chunksï¼Œå†ç”± LLM å¯¹è¿™äº› chunks æ‰“åˆ†ï¼Œç­›é€‰å‡ºæ›´éš¾åŒºåˆ†çš„æ­£è´Ÿä¾‹ã€‚
   - å­¦ç”Ÿæ¨¡å‹ä¸æ–­æ›´æ–°åï¼Œä¸‹ä¸€è½®èƒ½æŒ–æ˜å‡ºæ›´å…·æŒ‘æˆ˜æ€§çš„è®­ç»ƒæ ·æœ¬ï¼Œå½¢æˆâ€œè¶Šç»ƒè¶Šå¼ºâ€çš„é—­ç¯ã€‚

3. **è·¨æ–‡æ¡£ç±»åˆ«çš„ç»Ÿä¸€å»ºæ¨¡ç­–ç•¥**
   - å°† 14 ç§ä¸åŒç±»å‹çš„è´¢åŠ¡æ–‡ä»¶ï¼ˆå¦‚ 10-K, 10-Q, 8-K ç­‰ï¼‰åˆ†åˆ«å¤„ç†ç”ŸæˆæŸ¥è¯¢å’Œç›¸å…³æ€§åˆ¤æ–­ï¼Œä½†åœ¨æœ€ç»ˆè®­ç»ƒé˜¶æ®µå°†æ‰€æœ‰æ•°æ®æ··åˆï¼Œå®ç°ä¸€ä¸ª**ç»Ÿä¸€çš„å¤šç±»åˆ« embedding æ¨¡å‹**ã€‚

4. **Scalable Corpus Sampling & Downsampling Strategy**
   - é’ˆå¯¹æµ·é‡è¯­æ–™ï¼ˆçº¦ 51.88M chunksï¼‰ï¼Œè®¾è®¡äº†é«˜æ•ˆçš„é‡‡æ ·ç­–ç•¥ï¼š
     - æŒ‰ filing type åˆ†å±‚æŠ½æ ·ï¼›
     - ä½¿ç”¨ bi-encoder å…ˆæ£€ç´¢æ½œåœ¨ç›¸å…³æ–‡æ¡£é›†åˆ `D(q,K,i)`ï¼›
     - åœ¨æ¯ä¸ªæ–‡æ¡£å†…é‡‡ç”¨éå‡åŒ€æ¦‚ç‡åˆ†å¸ƒé‡‡æ · chunksï¼Œä¼˜å…ˆä¿ç•™é«˜æ’åç»“æœä»¥æ”¯æŒ MRR@k ç­‰æŒ‡æ ‡è®¡ç®—ã€‚

5. **Synthetic Query Generation with Few-Shot Prompting**
   - æ”¹è¿› InPars æ–¹æ³•ï¼Œé€šè¿‡ few-shot prompting ç”Ÿæˆæ›´æ³›åŒ–ã€ä¸è¿‡åº¦ç»‘å®šç‰¹å®šæ®µè½çš„â€œåˆæˆæŸ¥è¯¢â€ï¼Œæé«˜æŸ¥è¯¢å¤šæ ·æ€§ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | æœ¬æ–‡æ–¹æ³• | å…ˆå‰å·¥ä½œï¼ˆå¦‚ Anderson et al. [3]ï¼‰ |
|------|--------|-------------------------------|
| æ­£æ ·æœ¬æ•°é‡ | ~10Â³ æ­£ä¾‹/æŸ¥è¯¢ï¼ˆä¸¤è½®è¿­ä»£ï¼‰ | é€šå¸¸ä»… 1 ä¸ªæ­£ä¾‹/æŸ¥è¯¢ |
| è´Ÿæ ·æœ¬æ¥æº | åŒä¸€æ–‡æ¡£å†…çš„æ— å…³æ®µè½ï¼ˆhard negativesï¼‰ | å›ºå®šæ’åä½ç½®æŠ½å–ï¼ŒæœªéªŒè¯æ— å…³æ€§ |
| æŸ¥è¯¢ç”Ÿæˆæ–¹å¼ | ç»“åˆ InPars + Few-shot åˆæˆï¼Œå¢å¼ºå¤šæ ·æ€§ | å•çº¯åŸºäºæ®µè½ç”Ÿæˆ |
| æ£€ç´¢ç²’åº¦ | æ”¯æŒ within-document ç»†ç²’åº¦æ’åº | æ›´åå‘è·¨æ–‡æ¡£æ£€ç´¢ |
| æ•°æ®æ•ˆç‡ | è‡ªåŠ¨åŒ– LLM æ‰“æ ‡ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ | ä¾èµ–å¤§é‡äººå·¥æˆ–åŠè‡ªåŠ¨æ ‡æ³¨ |

> âœ… æ˜¾è‘—ä¼˜åŠ¿ï¼š**æ›´é«˜çš„æ­£è´Ÿæ ·æœ¬å¯†åº¦ã€æ›´å¼ºçš„é¢†åŸŸé’ˆå¯¹æ€§ã€æ›´å¥½çš„ within-document æ’åºèƒ½åŠ›**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

- **è‡ªå»ºæ•°æ®é›†**ï¼šçˆ¬å– 2024 å¹´ 1 æœˆ 1 æ—¥è‡³ 7 æœˆ 31 æ—¥æœŸé—´å‘å¸ƒçš„ **396,165 ä»½ SEC filings**ï¼Œæ¶µç›– 14 ç±»è´¢åŠ¡æ–‡ä»¶ã€‚
  - åŒ…æ‹¬ï¼š10-K, 10-Q, 8-K, DEF 14A, 424B3, S-8 ç­‰ã€‚
  - æ€»è®¡çº¦ **51.88 million chunks**ï¼ˆchunk size: 500â€“1000 charactersï¼‰ã€‚
  - æ—¶é—´åˆ’åˆ†ï¼š
    - **è®­ç»ƒ/éªŒè¯é›†**ï¼šJan 1 â€“ Jun 30
    - **æµ‹è¯•é›†**ï¼šJul 1 â€“ Jul 31

- **å…¬å¼€åŸºå‡†æ•°æ®é›†**ï¼š
  - **FinanceBench [9]**ï¼šç”¨äº out-of-distribution è¯„ä¼°ï¼ŒåŒ…å«çœŸå®é‡‘èé—®ç­”å¯¹åŠå…¶ evidence passagesã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

| ç»„ä»¶ | è®¾ç½®è¯´æ˜ |
|------|---------|
| **Teacher LLM** | Llama-3.1-70B-Instructï¼ˆopen-weightï¼‰ |
| **Student Model** | gte-largeï¼ˆGeneral Text Embeddings, 335M å‚æ•°ï¼‰ |
| **Embedding Type** | Bi-Encoderï¼ˆquery å’Œ passage åˆ†åˆ«ç¼–ç ï¼‰ |
| **Loss Function** | Triplet Lossï¼š<br>`max(0, Î± + d(q, c_neg) - d(q, c_pos))`<br>margin Î± = 0.1ï¼ˆä¼˜äºé»˜è®¤å€¼ 5ï¼‰ |
| **Training Epochs** | 2 |
| **Learning Rate** | 5e-7 |
| **Batch Size** | 128ï¼ˆ16/GPU Ã— 8 GPUsï¼‰ |
| **Optimizer** | AdamW |
| **Triplet æ•°é‡** | è®­ç»ƒé›†ï¼š2.52Mï¼›éªŒè¯é›†ï¼š950K |

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | å®šä¹‰ |
|------|-----|
| **MRR@5** | Mean Reciprocal Rank @5ï¼Œè¡¡é‡ç¬¬ä¸€ä¸ªæ­£ç¡®ç­”æ¡ˆçš„ä½ç½® |
| **mean DCG@5** | å¹³å‡ Discounted Cumulative Gain @5ï¼Œè€ƒè™‘æ’åé¡ºåºçš„åŠ æƒå¾—åˆ† |
| **NDCG** | Normalized DCGï¼Œå½’ä¸€åŒ–åçš„æ’åºè´¨é‡ |
| **Cohenâ€™s d** | æ•ˆåº”å¤§å°ç»Ÿè®¡é‡ï¼Œè¡¡é‡æ”¹è¿›æ˜¯å¦æ˜¾è‘— |

> æ‰€æœ‰æŒ‡æ ‡å‡åŸºäº LLM æ‰“æ ‡çš„ relevance scoresï¼ˆè§ Table IIï¼‰ï¼Œå¹¶åœ¨æœ€ç»ˆè¯„ä¼°ä¸­ä½¿ç”¨ **GPT-4o** ä½œä¸ºè£åˆ¤æ¨¡å‹ä»¥å‡å°‘åå·®ã€‚

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

- **Base Model**: åŸå§‹ gte-largeï¼ˆæœªç»å¾®è°ƒï¼‰
- **Control Variant**: ç›¸åŒæ¶æ„ä½†ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•è®­ç»ƒ
- **OpenAI Baseline**: OpenAI text-embedding-ada-002ï¼ˆå‚è€ƒ Anderson et al. [3] ä¸­çš„è¡¨ç°ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable IV & Abstractï¼‰

åœ¨ **21,800 query-document pairs** ä¸Šå¹³å‡ï¼š

| æŒ‡æ ‡ | æå‡å¹…åº¦ |
|------|--------|
| **MRR@5** | â†‘ **27.7%** |
| **mean DCG@5** | â†‘ **44.6%** |

> åœ¨ 14 ç±»è´¢åŠ¡æ–‡ä»¶ä¸Šå…¨é¢è¶…è¶ŠåŸºçº¿ã€‚

---

### ğŸ”¬ FinanceBench ä¸Šçš„ç»“æœï¼ˆTable Vï¼‰

| ç±»åˆ« | MRR æå‡ | uNDCG æå‡ |
|------|----------|------------|
| 10-Q | â†‘ 1.00 (Cohenâ€™s d) | â†‘ 1.100 |
| ECT | â†‘ 0.15 | â†‘ 0.260 |
| 8-K | â†“ (-0.21) | â†‘ 0.190 |
| 10-K | â†“ (-1.30) | â†” (+0.027) |
| **Overall** | â†“ (-0.63) | â†‘ **0.530** |

âœ… **å…³é”®å‘ç°**ï¼š
- åœ¨å¤šæ•°ç±»åˆ«ï¼ˆå°¤å…¶æ˜¯ 10-Q å’Œ ECTï¼‰ä¸Šï¼Œfine-tuned æ¨¡å‹æ˜¾è‘—ä¼˜äºåŸå§‹ gte-largeã€‚
- å°½ç®¡ MRR ä¸‹é™ï¼Œä½† **uNDCG æå‡æ˜æ˜¾**ï¼Œè¡¨æ˜æ’åºè´¨é‡æ•´ä½“æ”¹å–„ã€‚
- 10-K è¡¨ç°ä¸‹é™å¯èƒ½æºäº FinanceBench æŸ¥è¯¢å¤æ‚åº¦æ›´é«˜ï¼ˆè§ä¸‹æ–‡åˆ†æï¼‰ã€‚

---

### ğŸ§ª æ¶ˆèå®éªŒä¸å®šæ€§åˆ†æï¼ˆSection VI-Bï¼‰

é€šè¿‡å¯¹â€œpromoted passagesâ€å’Œâ€œdemoted passagesâ€çš„åˆ†æï¼Œè¯†åˆ«å‡ºä¸‰ç§å…¸å‹æ”¹è¿›æ¨¡å¼ï¼š

| æ¨¡å¼ | ç¤ºä¾‹ |
|------|------|
| **Table Retrieval** | æˆåŠŸä»è¡¨æ ¼ä¸­æå– CEO è–ªé…¬å˜åŒ–ç­‰é‡åŒ–ä¿¡æ¯ |
| **Technical Exact Match** | å‡†ç¡®åŒ¹é…â€œpar valueâ€ã€â€œinterest rate rangeâ€ç­‰ä¸“ä¸šæœ¯è¯­ |
| **Semantic Understanding** | ç†è§£â€œraising capitalâ€ä¸â€œnotes payable, lines of creditâ€çš„éšå«è”ç³» |

> è§ Table VIï¼Œå±•ç¤ºäº†å¤šä¸ªæˆåŠŸæ¡ˆä¾‹ã€‚

åŒæ—¶ï¼Œåœ¨ FinanceBench çš„ 10-K å­é›†ä¸­è§‚å¯Ÿåˆ°æ€§èƒ½é€€æ­¥çš„åŸå› åŒ…æ‹¬ï¼š
- **Multi-faceted Questions**ï¼šéœ€ç»¼åˆå¤šä¸ªéƒ¨åˆ†ä½œç­”
- **Terminologically Dense Queries**ï¼šæ¶‰åŠä¼šè®¡æ¦‚å¿µéœ€å¤–éƒ¨çŸ¥è¯†è§£æ
- **Distractor Terms**ï¼šå¹²æ‰°é¡¹é™ä½ precision
- **Label Noise**ï¼šchunk ä¸ evidence é‡å è¿‡å°å¯¼è‡´è¯¯æ ‡

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **LLM-Judged Distillation æ˜¯æœ‰æ•ˆçš„é¢†åŸŸé€‚é…æ‰‹æ®µ**  
   åˆ©ç”¨ LLM è‡ªåŠ¨ç”Ÿæˆ query å’Œ relevance labelï¼Œå¯åœ¨æ— äººå·¥æ ‡æ³¨æƒ…å†µä¸‹å¤§å¹…æå‡ embedding æ¨¡å‹åœ¨é‡‘èé¢†åŸŸçš„æ£€ç´¢æ€§èƒ½ã€‚

2. **Iterative Hard Example Mining æ˜¾è‘—æå‡æ•ˆæœ**  
   é€šè¿‡å­¦ç”Ÿæ¨¡å‹é€æ­¥æŒ–æ˜ harder negatives/positivesï¼Œä½¿è®­ç»ƒä¿¡å·æ›´åŠ ä¸°å¯Œä¸”è´´è¿‘å®é™…åº”ç”¨åœºæ™¯ã€‚

3. **Within-Document Retrieval èƒ½åŠ›å¢å¼º**  
   åŒæ–‡æ¡£å†…æ­£è´Ÿæ ·æœ¬é…å¯¹çš„è®¾è®¡ä½¿å¾—æ¨¡å‹æ›´æ“…é•¿å®šä½å…³é”®ä¿¡æ¯å—ï¼ˆå¦‚è¡¨æ ¼ã€è„šæ³¨ï¼‰ï¼Œè¿™å¯¹è´¢åŠ¡åˆ†æè‡³å…³é‡è¦ã€‚

4. **ç¬¬ä¸€è½®è¿­ä»£æ”¶ç›Šæœ€å¤§ï¼Œåç»­å¢ç›Šé€’å‡**  
   ç¬¬ä¸€æ¬¡ fine-tuning å¸¦æ¥æœ€å¤§æå‡ï¼Œç¬¬äºŒæ¬¡è¿­ä»£æ•ˆæœè¶‹äºé¥±å’Œï¼Œæç¤ºå¯ä¼˜åŒ–è®­ç»ƒèŠ‚å¥ã€‚

5. **æ¨¡å‹å…·å¤‡ä¸€å®šè¯­ä¹‰æ¨ç†èƒ½åŠ›**  
   èƒ½æ•æ‰ query ä¸ passage ä¹‹é—´çš„æ¦‚å¿µå…³è”ï¼Œå³ä½¿æ²¡æœ‰è¯æ±‡é‡å ã€‚

---

### âš ï¸ å±€é™æ€§

1. **ä¾èµ– Teacher LLM çš„æ‰“æ ‡è´¨é‡**  
   å½“å‰æ–¹æ³•å‡è®¾ LLM æ‰“åˆ†å¯é ï¼Œä½†å¯èƒ½å­˜åœ¨åè§æˆ–é”™è¯¯ï¼Œå°¤å…¶é¢å¯¹é«˜åº¦ä¸“ä¸šæˆ–æ¨¡ç³Šè¡¨è¿°ã€‚

2. **FinanceBench æ•°æ®é›†è§„æ¨¡è¾ƒå°**  
   ä»…æœ‰ 150 æ¡æµ‹è¯•æ ·æœ¬ï¼Œé™åˆ¶äº†ç»Ÿè®¡æ˜¾è‘—æ€§å’Œæ³›åŒ–èƒ½åŠ›è¯„ä¼°ã€‚

3. **æœªè¦†ç›–å¤æ‚å¤åˆæŸ¥è¯¢**  
   å¯¹ multi-hop æˆ– multi-faceted é—®é¢˜å¤„ç†èƒ½åŠ›ä¸è¶³ï¼Œéœ€ç»“åˆ agentic æˆ– graph-based æ–¹æ³•ã€‚

4. **chunking ç­–ç•¥å½±å“æ€§èƒ½è¾¹ç•Œ**  
   å›ºå®šé•¿åº¦åˆ‡ç‰‡å¯èƒ½å¯¼è‡´è¯æ®ç‰‡æ®µè¢«å‰²è£‚ï¼Œå½±å“ recallã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆSection VIIIï¼‰

1. **å¼•å…¥ Knowledge Graphs / External KBs**
   - ä½¿ç”¨ GraphRAG æˆ–çŸ¥è¯†å›¾è°±è¾…åŠ© query expansion å’Œ retrieval refinementã€‚

2. **Agentic Query Planning**
   - æ„å»ºå…·å¤‡æ¨ç†èƒ½åŠ›çš„ agentï¼ŒåŠ¨æ€ç”Ÿæˆæ›´ç²¾å‡†çš„æ£€ç´¢é”šç‚¹ï¼Œå¹¶æ ¹æ®åˆæ­¥ç»“æœè°ƒæ•´æŸ¥è¯¢ç­–ç•¥ã€‚

3. **Hybrid Long-Context + Retrieval Systems**
   - æ¢ç´¢ long-context LLM ä¸ specialized retriever çš„ååŒæœºåˆ¶ï¼Œå‘æŒ¥å„è‡ªä¼˜åŠ¿ã€‚

4. **æ›´é²æ£’çš„ Label Propagation æ–¹æ³•**
   - æ”¹è¿› FinanceBench ä¸­ evidence-to-chunk çš„æ˜ å°„é€»è¾‘ï¼Œå‡å°‘å™ªå£°ã€‚

5. **ç«¯åˆ°ç«¯è®­ç»ƒæ¡†æ¶æ¢ç´¢**
   - è”åˆä¼˜åŒ– retrieval ä¸ generation æ¨¡å—ï¼Œè¿›ä¸€æ­¥æå‡ RAG æ•´ä½“æ€§èƒ½ã€‚

---

## æ€»ç»“

> æœ¬æ–‡æå‡ºäº†ä¸€ç§**å¯æ‰©å±•ã€ä½æˆæœ¬ã€æ— éœ€äººå·¥æ ‡æ³¨**çš„æ–¹æ³•ï¼Œé€šè¿‡ **LLM distillation + iterative hard example mining**ï¼ŒæˆåŠŸå°†é€šç”¨ embedding æ¨¡å‹ï¼ˆgte-largeï¼‰é€‚é…è‡³é‡‘èè´¢æŠ¥åœºæ™¯ï¼Œåœ¨ MRR@5 å’Œ DCG@5 ä¸Šå–å¾—æ˜¾è‘—æå‡ã€‚è¯¥æ–¹æ³•ä¸ä»…é€‚ç”¨äºé‡‘èé¢†åŸŸï¼Œä¹Ÿä¸ºå…¶ä»–ä¸“ä¸šå‚ç›´é¢†åŸŸçš„æ£€ç´¢ç³»ç»Ÿæä¾›äº†èŒƒå¼å‚è€ƒã€‚

ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
**ç”¨ LLM å½“è€å¸ˆï¼Œæ•™ä¸€ä¸ªå°è€Œå¿«çš„ embedding æ¨¡å‹è¯»æ‡‚è´¢æŠ¥ï¼Œæ•ˆæœè¿œè¶…é€šç”¨æ¨¡å‹ï¼Œä¸”å…¨è¿‡ç¨‹è‡ªåŠ¨åŒ–ã€‚**

</details>

---

### 11. [LUNA: Linear Universal Neural Attention with Generalization Guarantees](https://arxiv.org/abs/2512.08061)

**Authors**: Ashkan Shahbazi, Ping He, Ali Abbasi, Yikun Bai, Xinran Liu, Elaheh Akbari, Darian Salehi, Navid NaderiAlizadeh, Soheil Kolouri  
**Category**: cs.LG  
**Published**: 2025-12-10  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.08061v1  

#### Abstract
Scaling attention faces a critical bottleneck: the $\mathcal{O}(n^2)$ quadratic computational cost of softmax attention, which limits its application in long-sequence domains. While linear attention mechanisms reduce this cost to $\mathcal{O}(n)$, they typically rely on fixed random feature maps, su...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# LUNA: Linear Universal Neural Attention with Generalization Guarantees â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

Transformer æ¨¡å‹ä¸­çš„ **softmax attention** å…·æœ‰ $O(n^2)$ çš„è®¡ç®—å¤æ‚åº¦ï¼Œä¸¥é‡é™åˆ¶äº†å…¶åœ¨é•¿åºåˆ—ä»»åŠ¡ï¼ˆå¦‚é•¿æ–‡æœ¬ã€é«˜åˆ†è¾¨ç‡å›¾åƒï¼‰ä¸­çš„åº”ç”¨ã€‚è™½ç„¶å·²æœ‰å¤šç§ **linear attention** æ–¹æ³•å°†å¤æ‚åº¦é™è‡³ $O(n)$ï¼Œä½†å®ƒä»¬é€šå¸¸ä¾èµ–äºå›ºå®šçš„éšæœºç‰¹å¾æ˜ å°„ï¼ˆå¦‚ Random Fourier Featuresï¼‰æˆ–æ‰‹å·¥è®¾è®¡çš„éçº¿æ€§å‡½æ•°ï¼Œå¯¼è‡´æ¨¡å‹è¡¨è¾¾èƒ½åŠ›å—é™ï¼Œç²¾åº¦æ˜¾è‘—ä½äºæ ‡å‡† softmax attentionã€‚

è¿™ç§â€œ**æ•ˆç‡æ¢ç²¾åº¦**â€çš„æƒè¡¡æ˜¯å½“å‰é«˜æ•ˆæ³¨æ„åŠ›æœºåˆ¶çš„æ ¸å¿ƒç“¶é¢ˆã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **LUNA (Linear Universal Neural Attention)**ï¼Œä¸€ç§å…¨æ–°çš„çº¿æ€§æ³¨æ„åŠ›æœºåˆ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **å°†æ³¨æ„åŠ›æ ¸å‡½æ•°çš„ç‰¹å¾æ˜ å°„ä»â€œå›ºå®šâ€å˜ä¸ºâ€œå¯å­¦ä¹ â€**ã€‚

å…·ä½“åˆ›æ–°åŒ…æ‹¬ï¼š

- **å¯å­¦ä¹ çš„æ ¸ç‰¹å¾æ˜ å°„ï¼ˆLearnable Kernel Feature Mapï¼‰**ï¼š
  - ä¸å†ä½¿ç”¨å›ºå®šçš„ RFF æˆ– Performer ç‰¹å¾ï¼Œè€Œæ˜¯é€šè¿‡ä¸€ä¸ªç¥ç»ç½‘ç»œï¼ˆMLPï¼‰å‚æ•°åŒ–ç‰¹å¾æ˜ å°„ $\phi(x)$ã€‚
  - è¯¥æ˜ å°„ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š
    1. å¯å­¦ä¹ çš„è¾“å…¥æŠ•å½±çŸ©é˜µ $W \in \mathbb{R}^{m \times d}$ï¼›
    2. ä¸€ç»„å…±äº«çš„é€šé“å‡½æ•° $\psi_l: \mathbb{R} \to \mathbb{R}$ï¼ˆæ¯ä¸ªä¸ºå°å‹ MLPï¼‰ï¼Œä½œç”¨äºæŠ•å½±åçš„æ ‡é‡å€¼ã€‚
  - æœ€ç»ˆç‰¹å¾æ˜ å°„ä¸ºï¼š  
    $$
    \phi(x) = \frac{1}{\sqrt{m}} \left[ \psi_1(w_1^\top x), \dots, \psi_L(w_m^\top x) \right] \in \mathbb{R}^{mL}
    $$

- **ä¿æŒçº¿æ€§å¤æ‚åº¦**ï¼š
  - åˆ©ç”¨ kernelized attention çš„ streaming å½¢å¼ï¼Œå®ç° $O(n)$ æ—¶é—´å’Œå†…å­˜å¤æ‚åº¦ã€‚
  - æ³¨æ„åŠ›è®¡ç®—å½¢å¼ä¸ºï¼š
    $$
    \text{Attn}(Q,K,V) = \phi(Q) (\phi(K)V) / (\phi(K)\mathbf{1}_n)
    $$

- **ç†è®ºä¿éšœ**ï¼š
  - è¯æ˜æ‰€æ„é€ çš„æ ¸å‡½æ•°æ˜¯ **æ­£å®šï¼ˆpositive-definite, PDï¼‰** çš„ã€‚
  - æ¨å¯¼äº†åŸºäº **Rademacher å¤æ‚åº¦** çš„æ³›åŒ–è¯¯å·®ç•Œï¼Œè¡¨æ˜å…¶å‡è®¾ç©ºé—´å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚
  - å°†è¿‘ä¼¼è¯¯å·®åˆ†è§£ä¸º **å‚æ•°åŒ–è¯¯å·®**ï¼ˆparametrization errorï¼‰ä¸ **é‡‡æ ·è¯¯å·®**ï¼ˆsampling errorï¼‰ï¼Œå¹¶ç»™å‡ºæ¦‚ç‡è¾¹ç•Œã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | LUNA | ä¼ ç»Ÿçº¿æ€§æ³¨æ„åŠ›ï¼ˆå¦‚ Performer, RFFï¼‰ |
|------|------|-----------------------------|
| **ç‰¹å¾æ˜ å°„** | âœ… å¯å­¦ä¹ ï¼Œè‡ªé€‚åº”ä»»åŠ¡åˆ†å¸ƒ | âŒ å›ºå®šï¼Œæ•°æ®æ— å…³ |
| **è¡¨è¾¾èƒ½åŠ›** | âœ… å¼ºï¼Œèƒ½æ‹Ÿåˆæœ€ä¼˜æ ¸ | âŒ å¼±ï¼Œå—é™äºå…ˆéªŒé€‰æ‹© |
| **è®¡ç®—æ•ˆç‡** | âœ… $O(n)$ æ—¶é—´/å†…å­˜ | âœ… $O(n)$ |
| **åè®­ç»ƒè½¬æ¢ï¼ˆpost-hoc conversionï¼‰** | âœ… é«˜æ•ˆæ¢å¤åŸæ¨¡å‹æ€§èƒ½ | âš ï¸ æ€§èƒ½ä¸‹é™æ˜æ˜¾ |
| **ç†è®ºæ”¯æŒ** | âœ… æ³›åŒ–è¯¯å·®ç•Œã€PD ä¿è¯ | âš ï¸ å¤šæ•°ç¼ºä¹ |

> **æ ¸å¿ƒä¼˜åŠ¿**ï¼šLUNA åœ¨ä¸ç‰ºç‰²çº¿æ€§æ•ˆç‡çš„å‰æä¸‹ï¼Œé€šè¿‡å­¦ä¹ ä»»åŠ¡ç‰¹å®šçš„æ ¸å‡½æ•°ï¼Œæ˜¾è‘—ç¼©å°äº†ä¸æ ‡å‡† softmax attention çš„æ€§èƒ½å·®è·ï¼Œç”šè‡³åè¶…ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

1. **Long Range Arena (LRA)**  
   - ç”¨äºè¯„ä¼°é•¿åºåˆ—å»ºæ¨¡èƒ½åŠ›çš„æ ‡å‡†åŸºå‡†ã€‚
   - åŒ…å« 5 ä¸ªå¼‚æ„ä»»åŠ¡ï¼š
     - **Text**: IMDb æ–‡æœ¬åˆ†ç±»ï¼ˆ4K tokensï¼‰
     - **ListOps**: ç»“æ„åŒ–åˆ—è¡¨æ“ä½œï¼ˆ2K tokensï¼‰
     - **Retrieval**: æ–‡æ¡£æ£€ç´¢åŒ¹é…
     - **Pathfinder**: å›¾åƒè·¯å¾„æ£€æµ‹ï¼ˆ2KÃ—2K pixelsï¼‰
     - **Image**: å›¾åƒåˆ†ç±»ï¼ˆMNIST-like, 1KÃ—1K pixelsï¼‰
   - æ‰€æœ‰åºåˆ—é•¿åº¦åœ¨ 1Kâ€“16K èŒƒå›´å†…ã€‚

2. **GLUE Benchmark**  
   - ç”¨äºè‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡ã€‚
   - ä½¿ç”¨ **BERT-base** å¾®è°ƒåçš„ checkpoint è¿›è¡Œåè®­ç»ƒè½¬æ¢å®éªŒã€‚

3. **ImageNet-1K**  
   - å›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚
   - ä½¿ç”¨ **ViT-B/16** å¾®è°ƒåçš„ checkpoint è¿›è¡Œåè®­ç»ƒè½¬æ¢å®éªŒã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **å…¬å¹³æ¯”è¾ƒåŸåˆ™**ï¼š
  - æ‰€æœ‰æ–¹æ³•åœ¨ç›¸åŒ backbone æ¶æ„ã€ä¼˜åŒ–å™¨ã€è®­ç»ƒæ­¥æ•°ã€batch size å’Œè¿‘ä¼¼ FLOPs ä¸‹è¿›è¡Œå¯¹æ¯”ã€‚
  - ä»…æ›¿æ¢ attention æ¨¡å—ï¼Œå…¶ä½™ä¸å˜ã€‚

- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **LRA**: å„ä»»åŠ¡æµ‹è¯•å‡†ç¡®ç‡ï¼ˆaccuracy %ï¼‰ï¼Œä»¥åŠå¹³å‡å¾—åˆ†ã€‚
  - **GLUE**: Dev set ä¸Šçš„ç»¼åˆè¯„åˆ†ï¼ˆå¦‚ CoLA, SST-2, MRPC ç­‰ï¼‰ï¼ŒæŠ¥å‘Šæ¢å¤åŸå§‹ BERT-FT æ€§èƒ½çš„ç™¾åˆ†æ¯”ã€‚
  - **ImageNet-1K**: Top-1 å‡†ç¡®ç‡ï¼ˆ%ï¼‰ã€‚

- **åè®­ç»ƒè½¬æ¢æµç¨‹ï¼ˆTwo-stage Conversionï¼‰**ï¼š
  1. **Stage 1: Attention Distillation**  
     å†»ç»“ä¸»å¹²å‚æ•°ï¼Œä»…è®­ç»ƒ LUNA çš„å¯å­¦ä¹ ç‰¹å¾æ˜ å°„ï¼Œä½¿å…¶è¾“å‡ºçš„ attention åˆ†å¸ƒé€¼è¿‘åŸå§‹ softmax attentionã€‚
  2. **Stage 2: End-to-end Fine-tuning**  
     è§£å†»å…¨éƒ¨å‚æ•°ï¼Œä½¿ç”¨ä»»åŠ¡æŸå¤±è¿›è¡Œè½»é‡å¾®è°ƒï¼ˆé€šå¸¸ 1â€“10 epochsï¼‰ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ–¹æ³• | ç±»å‹ | æ˜¯å¦å¯å­¦ä¹  |
|------|------|-----------|
| **Transformer (Softmax)** | åŸå§‹äºŒæ¬¡å¤æ‚åº¦ | âœ… |
| **Performer**, **Linear Transformer** | éšæœºç‰¹å¾çº¿æ€§åŒ– | âŒ |
| **Linformer**, **Nystromformer** | ä½ç§©å‹ç¼© | âŒ |
| **Cosformer**, **Skyformer** | ç»“æ„åŒ–ç¨€ç–/æ ¸è¿‘ä¼¼ | âŒ |
| **Hedgehog**, **T2R/T2R-HH** | åè®­ç»ƒæŒ‡æ•°ç‰¹å¾çº¿æ€§åŒ– | âŒï¼ˆå›ºå®šç‰¹å¾ï¼‰ |
| **LUNA (Ours)** | **å¯å­¦ä¹ æ ¸ç‰¹å¾æ˜ å°„** | âœ… |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **Long Range Arena (LRA) ç»“æœ**

| Model | Text | ListOps | Retrieval | Pathfinder | Image | **Avg.** |
|-------|------|---------|-----------|------------|--------|----------|
| Transformer | 61.55 | 38.71 | 80.93 | 70.39 | 39.14 | 58.14 |
| Skyformer | 64.70 | 38.69 | 82.06 | 70.73 | 40.77 | 59.39 |
| LOTFormer | 71.1 | 38.5 | 80.9 | 69.9 | 54.1 | **62.9** |
| **LUNA** | **73.41** | **38.94** | **81.02** | **69.52** | **64.32** | **65.44** |

> ğŸ”¥ **LUNA åœ¨ LRA ä¸Šå–å¾— SOTA å¹³å‡å‡†ç¡®ç‡ï¼ˆ65.44%ï¼‰**ï¼Œå°¤å…¶åœ¨ **Image** ä»»åŠ¡ä¸Šå¤§å¹…æå‡ï¼ˆ+10% ä»¥ä¸Šï¼‰ã€‚

---

#### âœ… **åè®­ç»ƒè½¬æ¢ï¼šBERT on GLUE**

| Method | CoLA | SST-2 | MRPC | STS-B | QQP | MNLI | QNLI | RTE | **Recover (%)** |
|--------|------|-------|------|-------|-----|------|------|-----|----------------|
| BERT-FT | 58.8 | 93.2 | 90.2 | 88.8 | 91.0 | 84.7 | 91.3 | 68.2 | 100.0 |
| T2R | 43.6 | 87.7 | 83.0 | 78.6 | 86.7 | 78.9 | 84.6 | 54.1 | 88.9 |
| Hedgehog | 59.2 | 92.6 | 90.1 | 87.4 | 91.0 | 82.6 | 89.6 | 69.3 | 99.3 |
| **LUNA** | **58.8** | **93.4** | **90.1** | **88.5** | **90.7** | **83.5** | **90.6** | **68.8** | **99.5** |

> âœ… LUNA **å¹³å‡æ¢å¤ 99.5% çš„åŸå§‹æ€§èƒ½**ï¼Œç•¥ä¼˜äº Hedgehogï¼Œè¿œè¶… T2R ç³»åˆ—ã€‚

---

#### âœ… **åè®­ç»ƒè½¬æ¢ï¼šViT-B/16 on ImageNet-1K**

| Method | Top-1 Accuracy (%) |
|--------|--------------------|
| ViT-B/16 (original) | 80.3 |
| T2R-HH | 77.0 |
| Hedgehog | 79.5 |
| **LUNA** | **80.5** |

> âœ… LUNA **ä¸ä»…æ¢å¤æ€§èƒ½ï¼Œè¿˜ç•¥å¾®è¶…è¶ŠåŸå§‹æ¨¡å‹ï¼ˆ+0.2%ï¼‰**ï¼Œæ˜¾ç¤ºå…¶æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ğŸ” **é€šé“æ•° $L$ ä¸æŠ•å½±æ•° $M$ çš„å½±å“ï¼ˆLRA-Imageï¼‰**

| $L$ (Channels) | 2 | 4 | **8** | 16 |
|----------------|----|----|------|-----|
| Accuracy (%) | 62.62 | 62.02 | **64.32** | 60.89 |

| $M$ (Projections) | 4 | **8** | 16 | 32 |
|-------------------|-----|------|-----|-----|
| Accuracy (%) | 63.06 | **64.32** | 63.88 | 59.15 |

> âœ… æœ€ä½³é…ç½®ä¸º $M=8, L=8$ï¼›è¿‡å¤§åè€Œæ€§èƒ½ä¸‹é™ï¼Œè¯´æ˜å­˜åœ¨æœ€ä¼˜è¡¨ç¤ºç»´åº¦ã€‚

---

#### ğŸ” **ç¥ç»æ ¸å˜ä½“æ¶ˆèï¼ˆLRA-Imageï¼‰**

| Variant | Kernel Form | Accuracy (%) |
|--------|-------------|--------------|
| RFF-sin,cos (fixed) | $\phi_{\text{sin,cos}}(x)$ | 35.72 |
| Bank+Coef | $\sum_l w_l \phi_l(x)$ | 40.30 |
| Envelope-gated | $h(x) \odot \psi(x)$ | 41.52 |
| **No gate (LUNA default)** | $\psi(x)$ | **64.32** |

> âœ… å­¦ä¹ æ•´ä¸ªéçº¿æ€§æ˜ å°„ï¼ˆè€ŒéåŠ æƒå›ºå®šåŸºï¼‰è‡³å…³é‡è¦ï¼›å¼•å…¥é—¨æ§åè€ŒæŸå®³æ€§èƒ½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **å¯å­¦ä¹ æ ¸ç‰¹å¾æ˜ å°„æ˜¯æå‡çº¿æ€§æ³¨æ„åŠ›æ€§èƒ½çš„å…³é”®**ï¼š
   - å›ºå®šç‰¹å¾ï¼ˆå¦‚ RFFã€expï¼‰æ— æ³•é€‚åº”ä¸åŒä»»åŠ¡çš„æ•°æ®åˆ†å¸ƒã€‚
   - LUNA é€šè¿‡ç«¯åˆ°ç«¯å­¦ä¹ ä»»åŠ¡è‡ªé€‚åº”çš„æ ¸å‡½æ•°ï¼Œåœ¨ä¿æŒ $O(n)$ æ•ˆç‡çš„åŒæ—¶å®ç°äº†æ¥è¿‘ç”šè‡³è¶…è¶Š softmax attention çš„ç²¾åº¦ã€‚

2. **LUNA æ˜¯å¼ºå¤§çš„â€œå³æ’å³ç”¨â€æ¨¡å—**ï¼š
   - å¯æ— ç¼æ›¿æ¢ç°æœ‰ Transformer ä¸­çš„ softmax attentionã€‚
   - æ”¯æŒé«˜æ•ˆçš„ **post-hoc conversion**ï¼Œæ— éœ€ä»å¤´è®­ç»ƒå³å¯éƒ¨ç½²äºç”Ÿäº§ç³»ç»Ÿã€‚

3. **ç†è®ºä¸å®è·µä¸€è‡´**ï¼š
   - æå‡ºçš„æ¨¡å‹æ»¡è¶³æ­£å®šæ€§ï¼Œå…·å¤‡è‰¯å¥½æ³›åŒ–æ€§è´¨ã€‚
   - å®éªŒéªŒè¯äº†å…¶åœ¨å¤šç§æ¨¡æ€ï¼ˆæ–‡æœ¬ã€å›¾åƒï¼‰å’Œä»»åŠ¡ä¸Šçš„é²æ£’æ€§å’Œä¼˜è¶Šæ€§ã€‚

4. **æ³¨æ„åŠ›å¯è§†åŒ–æ›´åˆç†**ï¼š
   - åœ¨ SST-2 å’Œ ImageNet ä¸Šï¼ŒLUNA çš„ attention map æ›´èšç„¦äºè¯­ä¹‰å…³é”®åŒºåŸŸï¼ˆå¦‚æƒ…æ„Ÿè¯ã€ç‰©ä½“ä¸»ä½“ï¼‰ï¼Œè€Œ Hedgehog ç­‰æ–¹æ³•æ›´å¼¥æ•£ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- **é¢å¤–å‚æ•°å¼€é”€**ï¼šå°½ç®¡è®¡ç®—å¤æ‚åº¦ä»ä¸º $O(n)$ï¼Œä½†å¼•å…¥äº†å¯å­¦ä¹ çš„ MLP å‚æ•°ï¼Œåœ¨æå°æ¨¡å‹ä¸­å¯èƒ½å¸¦æ¥è´Ÿæ‹…ã€‚
- **å¯¹åˆå§‹åŒ–æ•æ„Ÿ**ï¼šéœ€ careful initialization å’Œ warm-up é˜¶æ®µï¼ˆå¦‚ distillationï¼‰ä»¥ç¨³å®šè®­ç»ƒã€‚
- **ç›®å‰ä¸»è¦ç”¨äº encoder-only æ¨¡å‹**ï¼šå°šæœªå……åˆ†éªŒè¯åœ¨ decoder æˆ–ç”Ÿæˆä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

- æ‰©å±•è‡³ **decoder æ¶æ„** å’Œ **ç”Ÿæˆä»»åŠ¡**ï¼ˆå¦‚æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬ç”Ÿæˆï¼‰ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„å‚æ•°åŒ–æ–¹å¼ï¼ˆå¦‚ä½ç§© MLPã€å…±äº«è·¨å±‚ç‰¹å¾ï¼‰ã€‚
- å°† LUNA åº”ç”¨äº **å¤šæ¨¡æ€å¤§æ¨¡å‹**ï¼ˆå¦‚ LLM + Visionï¼‰ä¸­çš„é•¿ä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚
- ç†è®ºä¸Šè¿›ä¸€æ­¥åˆ†æå…¶åŠ¨æ€å­¦ä¹ è¿‡ç¨‹ä¸å½’çº³åç½®æ¼”åŒ–ã€‚

---

## æ€»ç»“

> **LUNA æˆåŠŸæ‰“ç ´äº†â€œçº¿æ€§æ³¨æ„åŠ›å¿…é¡»ç‰ºç‰²ç²¾åº¦â€çš„å›ºæœ‰è®¤çŸ¥**ï¼Œé€šè¿‡å¼•å…¥**å®Œå…¨å¯å­¦ä¹ çš„æ ¸ç‰¹å¾æ˜ å°„**ï¼Œåœ¨ä¿æŒ $O(n)$ å¤æ‚åº¦çš„åŒæ—¶ï¼Œå®ç°äº†å¯¹æ ‡å‡† softmax attention çš„æ€§èƒ½è¿½èµ¶ä¹ƒè‡³åè¶…ã€‚å…¶å®éªŒç»“æœåœ¨ LRA å’Œ post-hoc conversion åœºæ™¯ä¸‹å‡è¾¾åˆ° SOTAï¼Œå±•ç¤ºäº†å…¶ä½œä¸ºä¸‹ä¸€ä»£é«˜æ•ˆæ³¨æ„åŠ›èŒƒå¼çš„å·¨å¤§æ½œåŠ›ã€‚

</details>

---

### 12. [Wavelet-Accelerated Physics-Informed Quantum Neural Network for Multiscale Partial Differential Equations](https://arxiv.org/abs/2512.08256)

**Authors**: Deepak Gupta, Himanshu Pandey, Ratikanta Behera  
**Category**: cs.LG  
**Published**: 2025-12-10  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.08256v1  

#### Abstract
This work proposes a wavelet-based physics-informed quantum neural network framework to efficiently address multiscale partial differential equations that involve sharp gradients, stiffness, rapid local variations, and highly oscillatory behavior. Traditional physics-informed neural networks (PINNs)...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šWavelet-Accelerated Physics-Informed Quantum Neural Network for Multiscale Partial Differential Equations

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³**å¤šå°ºåº¦åå¾®åˆ†æ–¹ç¨‹ï¼ˆmultiscale PDEsï¼‰** ä¸­å­˜åœ¨çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯å½“è§£å…·æœ‰ä»¥ä¸‹ç‰¹å¾æ—¶ï¼š
- å°–é”æ¢¯åº¦ï¼ˆsharp gradientsï¼‰
- åˆšæ€§è¡Œä¸ºï¼ˆstiff dynamicsï¼‰
- å¿«é€ŸæŒ¯è¡ï¼ˆhighly oscillatory behaviorï¼‰
- å±€éƒ¨å‰§çƒˆå˜åŒ–ï¼ˆrapid local variationsï¼‰

ä¼ ç»Ÿ **Physics-Informed Neural Networks (PINNs)** å’Œå…¶é‡å­ç‰ˆæœ¬ **Physics-Informed Quantum Neural Networks (PIQNNs)** åœ¨å¤„ç†è¿™ç±»é—®é¢˜æ—¶é¢ä¸´ä¸¤å¤§ç“¶é¢ˆï¼š
1. éš¾ä»¥å‡†ç¡®æ•æ‰å¤šå°ºåº¦ç‰¹å¾ï¼›
2. ä¾èµ–è‡ªåŠ¨å¾®åˆ†ï¼ˆautomatic differentiationï¼‰è®¡ç®—æ®‹å·®æŸå¤±ï¼Œå¸¦æ¥æ˜¾è‘—çš„è®¡ç®—å¼€é”€ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šWPIQNN
ä½œè€…æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶â€”â€”**Wavelet-Accelerated Physics-Informed Quantum Neural Network (WPIQNN)**ï¼Œç»“åˆäº†å°æ³¢åˆ†æä¸é‡å­ç¥ç»ç½‘ç»œçš„ä¼˜åŠ¿ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
- âœ… **æ¶ˆé™¤è‡ªåŠ¨å¾®åˆ†éœ€æ±‚**ï¼šé€šè¿‡åœ¨**å°æ³¢åŸºå‡½æ•°ç©ºé—´**ä¸­è¡¨ç¤ºè§£ï¼Œå¹¶åˆ©ç”¨é¢„å­˜çš„å°æ³¢å¯¼æ•°çŸ©é˜µè¿›è¡Œè§£ææ±‚å¯¼ï¼Œé¿å…äº†åå‘ä¼ æ’­ä¸­çš„é«˜æˆæœ¬è‡ªåŠ¨å¾®åˆ†ã€‚
- âœ… **å¼•å…¥å°æ³¢å¤šåˆ†è¾¨ç‡ç‰¹æ€§**ï¼šåˆ©ç”¨å°æ³¢çš„å±€éƒ¨åŒ–èƒ½åŠ›ï¼Œåœ¨ä¸åŒå°ºåº¦ä¸ŠåŒæ—¶æ•è·å…¨å±€å¹³æ»‘ç‰¹å¾å’Œå±€éƒ¨å°–é”å˜åŒ–ï¼Œæœ‰æ•ˆåº”å¯¹å¤šå°ºåº¦é—®é¢˜ã€‚
- âœ… **èåˆé‡å­ç¥ç»ç½‘ç»œï¼ˆQNNï¼‰æå‡è¡¨è¾¾æ•ˆç‡**ï¼šä½¿ç”¨å‚æ•°åŒ–çš„å˜åˆ†é‡å­ç”µè·¯ä½œä¸ºéçº¿æ€§æ˜ å°„å™¨ï¼Œé¢„æµ‹å°æ³¢ç³»æ•°ï¼Œç›¸æ¯”ç»å…¸ç½‘ç»œå¤§å¹…å‡å°‘å¯è®­ç»ƒå‚æ•°æ•°é‡ã€‚
- âœ… **åŒé˜¶æ®µé‡å­æ¶æ„è®¾è®¡**ï¼š
  - ç¬¬ä¸€é˜¶æ®µï¼ˆQNN1ï¼‰ï¼šè§’ç¼–ç ï¼ˆangle encodingï¼‰æå–è¾“å…¥ç‰¹å¾ï¼›
  - ç¬¬äºŒé˜¶æ®µï¼ˆQNN2ï¼‰ï¼šå¹…å€¼ç¼–ç ï¼ˆamplitude encodingï¼‰å¤„ç†ç‰¹å¾å‘é‡å¹¶è¾“å‡ºå°æ³¢ç³»æ•°ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **ç²¾åº¦** | æ˜¾è‘—ä¼˜äºç»å…¸ PINNã€PIQNN-I/II å’Œ W-PINNï¼Œå°¤å…¶åœ¨åˆšæ€§å’Œé«˜é¢‘åœºæ™¯ä¸‹ |
| **å‚æ•°æ•ˆç‡** | å¯è®­ç»ƒå‚æ•°ä»…ä¸ºç»å…¸ W-PINN çš„ **<5%** |
| **è®­ç»ƒé€Ÿåº¦** | è¾ƒç°æœ‰ PIQNN æ–¹æ³•å®ç° **3â€“5å€åŠ é€Ÿ** |
| **ç¨³å®šæ€§** | æŸå¤±æ”¶æ•›æ›´ç¨³å®šï¼Œæ— æ˜æ˜¾éœ‡è¡æˆ–åœæ»ç°è±¡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### å®éªŒæ•°æ®é›† / æµ‹è¯•é—®é¢˜
è®ºæ–‡æœªä½¿ç”¨çœŸå®ä¸–ç•Œâ€œæ•°æ®é›†â€ï¼Œè€Œæ˜¯åŸºäºå¤šä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„**åŸºå‡† PDE é—®é¢˜**è¿›è¡Œæ•°å€¼å®éªŒï¼Œæ¶µç›–ä¸åŒç±»å‹å’Œå¤æ‚åº¦ï¼š

1. **é«˜æ¢¯åº¦çƒ­ä¼ å¯¼æ–¹ç¨‹ï¼ˆHeat Conduction Problemï¼‰**
   - æ§åˆ¶å‚æ•° Îµ è¶Šå°ï¼Œæ¢¯åº¦è¶Šé™¡ï¼Œé—®é¢˜è¶Šåˆšæ€§
   - ç”¨äºæµ‹è¯•å¯¹ sharp gradients çš„å»ºæ¨¡èƒ½åŠ›

2. **é«˜é¢‘ Helmholtz æ–¹ç¨‹**
   - å…¸å‹æ¤­åœ†å‹ PDEï¼Œå¹¿æ³›åº”ç”¨äºæ³¢åŠ¨ä¼ æ’­
   - é«˜é¢‘ä¸‹è§£é«˜åº¦æŒ¯è¡ï¼Œè€ƒéªŒæ¨¡å‹é¢‘ç‡æ•æ‰èƒ½åŠ›

3. **Klein-Gordon æ–¹ç¨‹**
   - äºŒé˜¶éçº¿æ€§æ³¢åŠ¨æ–¹ç¨‹ï¼Œå«æ—¶é—´æŒ¯è¡é¡¹
   - å‚æ•° a æ§åˆ¶æŒ¯è¡é¢‘ç‡ï¼Œç”¨äºéªŒè¯é«˜é¢‘é¢‘åŸŸé€‚åº”æ€§

4. **Maxwell æ–¹ç¨‹ï¼ˆç”µç£åœºï¼‰**
   - åˆ†ä¸ºå‡åŒ€ä»‹è´¨ä¸éå‡åŒ€ä»‹è´¨ä¸¤ç§æƒ…å†µ
   - åè€…å­˜åœ¨ææ–™ç•Œé¢çªå˜ï¼Œå¼•å…¥ä¸è¿ç»­æ€§ï¼Œæµ‹è¯•è¾¹ç•Œ/æ¥å£å¤„ç†èƒ½åŠ›

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### è¯„ä¼°æŒ‡æ ‡ï¼š
- **ç›¸å¯¹ Lâ‚‚-error**ï¼šè¡¡é‡é¢„æµ‹è§£ä¸çœŸè§£ä¹‹é—´çš„å¹³å‡è¯¯å·®
  $$
  L_2 = \frac{\|u_{\text{pred}} - u_{\text{ref}}\|_{L^2(\Omega)}}{\|u_{\text{ref}}\|_{L^2(\Omega)}}
  $$
- **å¯è®­ç»ƒå‚æ•°æ•°é‡ï¼ˆTrainable Parametersï¼‰**
- **è®­ç»ƒæ—¶é—´ / æ”¶æ•›é€Ÿåº¦**
- **æŸå¤±æ›²çº¿ç¨³å®šæ€§ï¼ˆvariance across runsï¼‰**

#### è®­ç»ƒé…ç½®ï¼š
- æ‰€æœ‰å®éªŒå‡é‡‡ç”¨ **Adam ä¼˜åŒ–å™¨ + å­¦ä¹ ç‡è°ƒåº¦å™¨**
- åˆå§‹åŒ–æ–¹å¼ï¼šXavier åˆå§‹åŒ–
- æ¨¡æ‹Ÿå¹³å°ï¼šPennyLaneï¼ˆæ¨¡æ‹Ÿé‡å­ç”µè·¯ï¼‰ã€PyTorch
- ç¡¬ä»¶ï¼šNVIDIA RTX A4500 GPU
- æ¯ä¸ªå®éªŒé‡å¤ **10 æ¬¡ç‹¬ç«‹è¿è¡Œ**å–å‡å€¼ä¸æ ‡å‡†å·®ï¼Œç¡®ä¿ç»Ÿè®¡ç¨³å¥æ€§

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **Classical PINN** | ç»å…¸ç¥ç»ç½‘ç»œ | åŸºç¡€æ¡†æ¶ï¼Œä¾èµ–è‡ªåŠ¨å¾®åˆ† |
| **W-PINN [35]** | ç»å…¸å°æ³¢å¢å¼ºPINN | ä½¿ç”¨å°æ³¢åŸºé¿å…è‡ªåŠ¨å¾®åˆ†ï¼Œä½†å‚æ•°é‡å·¨å¤§ |
| **PIQNN-I / PIQNN-II [50]** | é‡å­å¢å¼ºPINN | å½“å‰ä¸»æµé‡å­ç‰©ç†ä¿¡æ¯ç½‘ç»œæ¶æ„ |
| **Proposed: WPIQNN** | æœ¬æ–‡æ–¹æ³• | å°æ³¢+é‡å­è”åˆæ¡†æ¶ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### ğŸ”¹ ç¤ºä¾‹1ï¼šçƒ­ä¼ å¯¼æ–¹ç¨‹ï¼ˆÎµ = 0.15ï¼‰
| æ–¹æ³• | Lâ‚‚-error | Trainable Params |
|-------|----------|------------------|
| Classical PINN | ~0.285 | 15,501 |
| PIQNN-I | ~0.437 | 97 (â‰ˆ81â€“115) |
| PIQNN-II | ~0.285 | 115 |
| W-PINN | 3.96Ã—10â»â´ | 1,574,692 |
| **WPIQNN** | **2.13Ã—10â»â´** | **22,652** |

> âœ… WPIQNN é”™è¯¯æœ€ä½ï¼Œä¸”ä»…ç”¨çº¦ **1.4%** çš„ W-PINN å‚æ•°ã€‚

#### ğŸ”¹ ç¤ºä¾‹2ï¼šHelmholtz æ–¹ç¨‹ï¼ˆé«˜é¢‘ï¼‰
| æ–¹æ³• | Lâ‚‚-error | Trainable Params |
|-------|----------|------------------|
| Classical PINN | 2.39Ã—10â»Â¹ | 15,501 |
| PIQNN-I | 9.12Ã—10â»Â¹ | 197 |
| PIQNN-II | 3.12Ã—10â»Â¹ | 126 |
| W-PINN | 3.12Ã—10â»â´ | 2,227,696 |
| **WPIQNN** | **2.19Ã—10â»â´** | **35,611** |

> âœ… å‡†ç¡®ç‡æ›´é«˜ï¼Œå‚æ•°ä»…ä¸º W-PINN çš„ **~1.6%**

#### ğŸ”¹ ç¤ºä¾‹3ï¼šKlein-Gordon æ–¹ç¨‹ï¼ˆa=10ï¼‰
| æ–¹æ³• | Lâ‚‚-error | Trainable Params |
|-------|----------|------------------|
| Classical PINN | ~0.917 | 61,001 |
| PIQNN-I/II | å‘æ•£ / ä¸æ”¶æ•› | <200 |
| W-PINN | 4.18Ã—10â»Â³ | 3,416,627 |
| **WPIQNN** | **1.72Ã—10â»Â³** | **50,837** |

> âœ… WPIQNN æˆåŠŸæ”¶æ•›ï¼Œè¯¯å·®æ›´ä½ï¼Œå‚æ•°ä»…å  W-PINN çš„ **~1.5%**

#### ğŸ”¹ ç¤ºä¾‹4ï¼šMaxwell æ–¹ç¨‹ï¼ˆå¼‚è´¨ä»‹è´¨ï¼‰
| æ–¹æ³• | E-field Lâ‚‚ | H-field Lâ‚‚ | Trainable Params |
|-------|------------|------------|------------------|
| W-PINN | 4.17Ã—10â»â´ | 3.17Ã—10â»â´ | 4,648,006 |
| **WPIQNN** | **2.17Ã—10â»â´** | **1.70Ã—10â»â´** | **58,366** |

> âœ… è¯¯å·®å‡åŠä»¥ä¸Šï¼Œå‚æ•°ä»… **~1.25%**

---

### æ€§èƒ½åŠ é€Ÿç»“æœï¼ˆå›¾7ï¼‰
- **è®­ç»ƒæ—¶é—´å¯¹æ¯”ï¼ˆvs PIQNN-I/IIï¼‰**ï¼š
  - å›ºå®šå±‚æ•°æ—¶ï¼ŒWPIQNN è®­ç»ƒæ—¶é—´ç¼©çŸ­ **2â€“3.5å€**
  - å¢åŠ å±‚æ•°åï¼ŒåŠ é€Ÿæ¯”è¾¾ **2â€“5å€**
- åŠ é€ŸåŸå› å½’å› äºï¼š
  - **æ— éœ€è‡ªåŠ¨å¾®åˆ†** â†’ å¤§å¹…é™ä½è®¡ç®—å›¾æ„å»ºä¸æ¢¯åº¦å›ä¼ å¼€é”€
  - **å°æ³¢å¯¼æ•°é¢„è®¡ç®—** â†’ å¯¼æ•°è®¡ç®—å˜ä¸ºæŸ¥è¡¨æ“ä½œ

---

### æ¶ˆèå®éªŒä¸å¯è§†åŒ–åˆ†æï¼ˆæ”¯æŒæ€§è¯æ®ï¼‰
- **æŸå¤±æ”¶æ•›æ›²çº¿ï¼ˆFig. 3ï¼‰**ï¼š
  - PIQNN-I æ®‹å·®æŸå¤±ä¸‹é™ç¼“æ…¢ä¸”æ³¢åŠ¨å¤§
  - WPIQNN æ‰€æœ‰æŸå¤±é¡¹ï¼ˆPDE, IC, BCï¼‰å‡å¹³ç¨³å¿«é€Ÿä¸‹é™
- **ç‚¹å¯¹ç‚¹è¯¯å·®å›¾ï¼ˆFig. 5, 8, 10, 11, 12ï¼‰**ï¼š
  - WPIQNN åœ¨è¾¹ç•Œã€æ¿€æ³¢åŒºã€æ¥å£å¤„è¯¯å·®æä½
  - å…¶ä»–æ–¹æ³•åœ¨è¿™äº›åŒºåŸŸå‡ºç°æ˜æ˜¾åå·®
- **æç«¯æ¡ˆä¾‹æµ‹è¯•ï¼ˆÎµ=0.11ï¼‰**ï¼š
  - è§£ä» 0 çªå¢è‡³ ~9000ï¼Œå…¶ä»–æ–¹æ³•å®Œå…¨å¤±è´¥
  - WPIQNN ä»ä¿æŒç¨³å®šï¼ŒLâ‚‚-error â‰ˆ 1.17Ã—10â»â´

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **WPIQNN èƒ½é«˜æ•ˆè§£å†³ä¼ ç»Ÿæ–¹æ³•éš¾ä»¥å¤„ç†çš„å¤šå°ºåº¦ã€åˆšæ€§ã€é«˜é¢‘ PDE é—®é¢˜**ã€‚
2. âœ… **å°æ³¢åŸº + QNN æ¶æ„å®ç°äº†ç²¾åº¦ä¸æ•ˆç‡çš„åŒé‡çªç ´**ï¼š
   - ç²¾åº¦è¶…è¶Šæ‰€æœ‰åŸºçº¿æ–¹æ³•
   - å‚æ•°é‡ä»…ä¸ºç»å…¸ W-PINN çš„ **2â€“5%**
3. âœ… **å»é™¤è‡ªåŠ¨å¾®åˆ†æ˜¾è‘—æå‡äº†è®­ç»ƒæ•ˆç‡**ï¼Œå¸¦æ¥ **3â€“5å€é€Ÿåº¦æå‡**ã€‚
4. âœ… **é‡å­æ¶æ„å¹¶æœªç‰ºç‰²ç¨³å®šæ€§**ï¼Œåè€Œå› ç»“æ„ç®€åŒ–è¡¨ç°å‡ºæ›´å¼ºé²æ£’æ€§ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. â— **å½“å‰ä»åœ¨ç»å…¸ç¡¬ä»¶ä¸Šæ¨¡æ‹Ÿé‡å­ç”µè·¯**ï¼š
   - é‡å­æ€æ¨¡æ‹Ÿéš qubit æ•°æŒ‡æ•°å¢é•¿ï¼Œé™åˆ¶è§„æ¨¡æ‰©å±•
   - å®é™…é‡å­ç¡¬ä»¶éƒ¨ç½²å°šéœ€ç­‰å¾… NISQ è®¾å¤‡æˆç†Ÿ
2. â— **å°æ³¢åŸºé€‰æ‹©å›ºå®šï¼ˆGaussian waveletï¼‰**ï¼š
   - æœªæ¢ç´¢è‡ªé€‚åº”æˆ–å­¦ä¹ å‹å°æ³¢åŸº
   - å¯¹æŸäº›ç‰¹å®šç»“æ„å¯èƒ½ä¸æ˜¯æœ€ä¼˜
3. â— **å¹…å€¼ç¼–ç ä¾èµ–é«˜æ•ˆçŠ¶æ€å‡†å¤‡ç®—æ³•**ï¼š
   - åœ¨çœŸå®è®¾å¤‡ä¸­ä»æ˜¯å¼€æ”¾éš¾é¢˜

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. ğŸ”„ æ¢ç´¢æ›´å¤šå¤æ‚ PDE åº”ç”¨åœºæ™¯ï¼š
   - æµä½“åŠ›å­¦ï¼ˆNavier-Stokesï¼‰
   - éè§„åˆ™å‡ ä½•æˆ–å¤šç‰©ç†åœºè€¦åˆç³»ç»Ÿ
2. ğŸ”® ç»“åˆå®é™…é‡å­ç¡¬ä»¶éƒ¨ç½² WPIQNNï¼ŒéªŒè¯é‡å­ä¼˜åŠ¿
3. ğŸ§  å¼•å…¥å¯å­¦ä¹ å°æ³¢å‚æ•°ï¼ˆå¦‚ dilation & translationï¼‰ï¼Œè¿›ä¸€æ­¥æå‡çµæ´»æ€§
4. âš™ï¸ å¼€å‘ä¸“ç”¨é‡å­çº¿è·¯ä¼˜åŒ–ç­–ç•¥ï¼Œé™ä½ç”µè·¯æ·±åº¦ä¸å™ªå£°æ•æ„Ÿæ€§

---

## æ€»ç»“
è¯¥è®ºæ–‡æå‡ºçš„ **WPIQNN** æ˜¯ä¸€ä¸ªå¼€åˆ›æ€§çš„æ··åˆæ¡†æ¶ï¼ŒæˆåŠŸå°† **å°æ³¢å¤šåˆ†è¾¨ç‡åˆ†æ** ä¸ **é‡å­ç¥ç»ç½‘ç»œçš„å‚æ•°æ•ˆç‡** ç›¸ç»“åˆï¼Œè§£å†³äº† PINN å’Œ PIQNN åœ¨å¤šå°ºåº¦ PDE ä¸Šçš„å…³é”®ç“¶é¢ˆã€‚å®ƒä¸ä»…åœ¨ç²¾åº¦ä¸Šå–å¾—é¢†å…ˆï¼Œè€Œä¸”åœ¨å‚æ•°æ•ˆç‡å’Œè®­ç»ƒé€Ÿåº¦æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä¸ºæœªæ¥åŸºäºé‡å­æŠ€æœ¯çš„ç§‘å­¦è®¡ç®—æä¾›äº†æ–°çš„èŒƒå¼ã€‚

</details>

---

### 13. [Mathematical Foundations of Neural Tangents and Infinite-Width Networks](https://arxiv.org/abs/2512.08264)

**Authors**: Rachana Mysore, Preksha Girish, Kavitha Jayaram, Shrey Kumar, Preksha Girish, Shravan Sanjeev Bagal, Kavitha Jayaram, Shreya Aravind Shastry  
**Category**: cs.LG  
**Published**: 2025-12-10  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.08264v1  

#### Abstract
We investigate the mathematical foundations of neural networks in the infinite-width regime through the Neural Tangent Kernel (NTK). We propose the NTK-Eigenvalue-Controlled Residual Network (NTK-ECRN), an architecture integrating Fourier feature embeddings, residual connections with layerwise scali...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Mathematical Foundations of Neural Tangents and Infinite-Width Networks*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡èšç„¦äº**æ·±åº¦ç¥ç»ç½‘ç»œåœ¨æœ‰é™å®½åº¦ï¼ˆfinite-widthï¼‰ä¸‹çš„è®­ç»ƒåŠ¨æ€ä¸æ³›åŒ–èƒ½åŠ›ç¼ºä¹ç†è®ºå¯è§£é‡Šæ€§**çš„é—®é¢˜ã€‚å°½ç®¡ Neural Tangent Kernel (NTK) åœ¨æ— é™å®½åº¦æé™ä¸‹æä¾›äº†å¯¹ç½‘ç»œè®­ç»ƒçš„çº¿æ€§åŒ–åˆ†ææ¡†æ¶ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼Œç½‘ç»œæ˜¯æœ‰é™å®½åº¦çš„ï¼Œå¯¼è‡´ NTK åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šå‘ç”Ÿéå¹³å‡¡æ¼”åŒ–ï¼ˆnontrivial evolutionï¼‰ï¼Œä»è€Œå½±å“æ”¶æ•›æ€§å’Œæ³›åŒ–æ€§èƒ½ã€‚

ç°æœ‰ç ”ç©¶å¤šé›†ä¸­äºç†æƒ³åŒ–çš„æ— é™å®½åº¦ç†è®ºæˆ–çº¯ç»éªŒè§‚å¯Ÿï¼Œç¼ºä¹ä¸€ä¸ªæ—¢èƒ½è¿›è¡Œä¸¥æ ¼æ•°å­¦åˆ†æåˆèƒ½å®è¯éªŒè¯çš„æ¡¥æ¢æœºåˆ¶ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šNTK-Eigenvalue-Controlled Residual Network (NTK-ECRN)

ä½œè€…æå‡ºäº†ä¸€ç§æ–°å‹æ¶æ„â€”â€”**NTK-ECRN**ï¼Œå…¶è®¾è®¡ç›®æ ‡æ˜¯å®ç°å¯¹ NTK æ¼”åŒ–è¿‡ç¨‹çš„**ç²¾ç¡®æ§åˆ¶ä¸å¯åˆ†ææ€§**ï¼ŒåŒæ—¶ä¿æŒå®è·µæœ‰æ•ˆæ€§ã€‚è¯¥æ¶æ„æ•´åˆäº†ä»¥ä¸‹å…³é”®æŠ€æœ¯ç»„ä»¶ï¼š

- **Fourier Feature Embeddings**  
  å°†è¾“å…¥ $x$ æ˜ å°„ä¸º $\phi(x) = [\sin(2\pi Bx), \cos(2\pi Bx)]$ï¼Œå¢å¼ºé«˜é¢‘é¢‘è°±è¡¨ç¤ºï¼Œç¼“è§£æ ‡å‡† MLP ä¸­çš„ spectral biasï¼Œä½¿ NTK èƒ½æ›´æœ‰æ•ˆåœ°å­¦ä¹ é«˜é¢‘æ¨¡å¼ã€‚

- **Layerwise Residual Connections with Scaling Coefficients $\alpha_l$**  
  å¼•å…¥é€å±‚ç¼©æ”¾ç³»æ•° $\alpha_l$ æ§åˆ¶æ®‹å·®å—çš„è´¡çŒ®å¼ºåº¦ï¼Œç†è®ºä¸Šå¯çº¦æŸ NTK æœ€å¤§ç‰¹å¾å€¼ $\lambda_{\max}$ çš„å¢é•¿é€Ÿåº¦ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ã€‚

- **Stochastic Depthï¼ˆå¯é€‰ï¼‰**  
  åœ¨è®­ç»ƒæ—¶ä»¥æ¦‚ç‡ $p$ éšæœºè·³è¿‡æ®‹å·®å—ï¼Œå¼•å…¥æ­£åˆ™åŒ–å¹¶é™ä½è¿‡æ‹Ÿåˆé£é™©ï¼ŒåŒæ—¶ä»å…è®¸å¯¹æœŸæœ› NTK æ¼”åŒ–è¿›è¡Œè§£æå»ºæ¨¡ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **ç†è®ºå¯åˆ†ææ€§** | æ¶æ„è®¾è®¡æ˜¾å¼æ”¯æŒ NTK åŠ¨æ€ã€ç‰¹å¾å€¼è°±æ¼”åŒ–ç­‰çš„æ•°å­¦æ¨å¯¼ï¼Œå¼¥è¡¥äº†ä¼ ç»Ÿ ResNet æˆ– MLP ç¼ºä¹ç†è®ºå·¥å…·çš„é—®é¢˜ã€‚ |
| **å¯æ§çš„è®­ç»ƒåŠ¨æ€** | é€šè¿‡ $\alpha_l$ å’Œ Fourier ç‰¹å¾è°ƒèŠ‚ NTK ç‰¹å¾å€¼åˆ†å¸ƒï¼Œé¿å…è¾¹ç¼˜ä¸ç¨³å®šï¼ˆedge-of-stabilityï¼‰ç°è±¡ã€‚ |
| **æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›** | å®éªŒè¡¨æ˜ï¼Œåœ¨åˆæˆä¸çœŸå®æ•°æ®ä¸Šå‡ä¼˜äºæ ‡å‡† NTK æ¨¡å‹åŠç»å…¸ç½‘ç»œï¼ˆå¦‚ MLPã€ResNet-18ï¼‰ã€‚ |
| **æ¡¥æ¥ç†è®ºä¸å®è·µ** | åŒæ—¶æä¾› kernel dynamics åˆ†æä¸ä»»åŠ¡æ€§èƒ½è¯„ä¼°ï¼Œå½¢æˆâ€œç†è®ºæŒ‡å¯¼è®¾è®¡ â†’ å®éªŒéªŒè¯â€çš„é—­ç¯ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†ä½¿ç”¨æƒ…å†µ

| ç±»å‹ | æ•°æ®é›† | æè¿° |
|------|--------|------|
| **åˆæˆæ•°æ®** | é«˜é¢‘å›å½’ä»»åŠ¡ | è¾“å…¥ç»´åº¦ $d=20$ï¼Œç›®æ ‡å‡½æ•°ç”± $K=10$ ä¸ªéšæœºæ­£å¼¦æ³¢å åŠ æ„æˆï¼ŒåŠ å…¥é«˜æ–¯å™ªå£°ã€‚ç”¨äºç³»ç»Ÿåˆ†æ NTK å¯¹é«˜é¢‘æ¨¡å¼çš„å­¦ä¹ èƒ½åŠ›ã€‚ |
| **åˆæˆåˆ†ç±»** | é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGMMï¼‰ | 5 ç±»ï¼Œæ¯ç±»æœä»ä¸åŒå‡å€¼çš„å¤šå…ƒæ­£æ€åˆ†å¸ƒï¼Œç”¨äºæµ‹è¯•åˆ†ç±»è¾¹ç•Œå­¦ä¹ èƒ½åŠ›ã€‚ |
| **åŸºå‡†æ•°æ®é›†** | UCI Repository | åŒ…æ‹¬ Boston Housingï¼ˆå›å½’ï¼‰ã€Irisã€Wineï¼ˆåˆ†ç±»ï¼‰ï¼Œæ ‡å‡†åŒ–é¢„å¤„ç†ååˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ï¼ˆ70%/15%/15%ï¼‰ã€‚ |
| **å›¾åƒä»»åŠ¡** | CIFAR-10 å­é›† | ä½¿ç”¨ 5,000 å¼ å›¾åƒçš„å°è§„æ¨¡å­é›†ï¼Œé€‚åˆä½œä¸ºæœ¬ç§‘é¡¹ç›®çº§åˆ«çš„è§†è§‰å®éªŒã€‚ |

### âš™ï¸ å®éªŒè®¾ç½®

- **æ¨¡å‹é…ç½®**ï¼š
  - æ‰€æœ‰æ¨¡å‹ç»Ÿä¸€å®½åº¦ï¼ˆå¦‚ 512 unitsï¼‰ï¼Œå±‚æ•°ä¸€è‡´ï¼ˆNTK-ECRN ä½¿ç”¨ $L$ å±‚æ®‹å·®å—ï¼‰
  - åˆå§‹åŒ–æ–¹å¼éµå¾ª NTK å‚æ•°å°ºåº¦ï¼ˆNTK-parametrizationï¼‰
  - ä¼˜åŒ–å™¨ï¼šå…¨æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼ˆsyntheticï¼‰æˆ–å°æ‰¹é‡ SGDï¼ˆbenchmarkï¼‰

- **è¯„ä¼°æŒ‡æ ‡**

| ä»»åŠ¡ç±»å‹ | æ€§èƒ½æŒ‡æ ‡ | Kernel åŠ¨æ€æŒ‡æ ‡ |
|---------|----------|----------------|
| å›å½’ | MSE, $R^2$ | $\|\Delta \Theta^{(t)}\|_F$, $\lambda_i(t)$ |
| åˆ†ç±» | Accuracy, Cross-Entropy Loss | $\lambda_{\max}(t)$, spectral decay trend |

- **NTK è·Ÿè¸ªæœºåˆ¶**ï¼š
  - æ¯ä¸ª epoch è®¡ç®—å½“å‰ NTK çŸ©é˜µ $\Theta^{(t)}(x,x')$
  - è®¡ç®—åå·® $\Delta \Theta^{(t)} = \Theta^{(t)} - \Theta^{(0)}$
  - è¿›è¡Œç‰¹å¾å€¼åˆ†è§£ï¼Œç›‘æ§ $\{\lambda_i(t)\}$ æ¼”åŒ–è½¨è¿¹

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿æ¨¡å‹ | è¯´æ˜ |
|--------|------|
| **MLP (3-layer, 512 neurons)** | æ ‡å‡†å‰é¦ˆç½‘ç»œï¼Œä»£è¡¨åŸºç¡€ DNN ç»“æ„ |
| **ResNet-18** | ç»å…¸æ®‹å·®ç½‘ç»œï¼Œå…·å¤‡è‰¯å¥½å®è·µç»éªŒ |
| **Standard NTK** | åŸºäºæ— é™å®½åº¦è¿‘ä¼¼çš„çº¿æ€§åŒ– NTK æ¨¡å‹ï¼ˆæ ¸æ–¹æ³•ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### âœ… å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### è¡¨ Iï¼šåˆæˆå›å½’ä»»åŠ¡è¡¨ç°ï¼ˆMean Â± Stdï¼‰

| Model | MSE â†“ | $R^2$ â†‘ |
|-------|------|--------|
| MLP | 0.085 Â± 0.007 | 0.91 Â± 0.02 |
| ResNet-18 | 0.072 Â± 0.006 | 0.93 Â± 0.01 |
| Standard NTK | 0.090 Â± 0.008 | 0.90 Â± 0.02 |
| **NTK-ECRN (proposed)** | **0.045 Â± 0.004** | **0.92 Â± 0.01** |

> ğŸ’¡ è§‚å¯Ÿï¼šNTK-ECRN åœ¨ MSE ä¸Šæ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œå°¤å…¶æ“…é•¿æ•æ‰é«˜é¢‘ä¿¡å·ã€‚

#### è¡¨ IIï¼šåˆæˆåˆ†ç±»ä»»åŠ¡ï¼ˆ5-class GMMï¼‰

| Model | Accuracy (%) â†‘ | CE Loss â†“ |
|-------|----------------|----------|
| MLP | 87.3 Â± 1.1 | 0.412 Â± 0.015 |
| ResNet-18 | 89.5 Â± 0.9 | 0.385 Â± 0.012 |
| Standard NTK | 85.7 Â± 1.3 | 0.425 Â± 0.017 |
| **NTK-ECRN** | **93.8 Â± 0.7** | **0.312 Â± 0.010** |

> ğŸ’¡ è§‚å¯Ÿï¼šç»“åˆ Fourier embedding ä¸æ®‹å·®ç¼©æ”¾ï¼Œæ˜¾è‘—æå‡ä½/é«˜é¢‘ç‰¹å¾è”åˆå­¦ä¹ èƒ½åŠ›ã€‚

#### è¡¨ IIIï¼šUCI æ•°æ®é›†ç»¼åˆè¡¨ç°

| Dataset | Task | Model | Metric | Value |
|--------|------|-------|--------|-------|
| Boston Housing | Reg | NTK-ECRN | $R^2$ | **0.89** (vs. 0.87 ResNet) |
| Iris | Cls | NTK-ECRN | Acc | **96.1%** |
| Wine | Cls | NTK-ECRN | Acc | **97.0%** |

> âœ… å…¨ä½“é¢†å…ˆï¼Œè¯æ˜å…¶è·¨ä»»åŠ¡é²æ£’æ€§ã€‚

#### è¡¨ IVï¼šCIFAR-10 å­é›†åˆ†ç±»æ€§èƒ½

| Model | Accuracy (%) | CE Loss |
|-------|--------------|--------|
| MLP | 74.1 | 0.815 |
| ResNet-18 | 78.4 | 0.712 |
| Standard NTK | 71.5 | 0.843 |
| **NTK-ECRN** | **81.9** | **0.648** |

> ğŸ’¡ å³ä½¿åœ¨å›¾åƒä»»åŠ¡ä¸­ä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œè¯´æ˜ Fourier + æ§åˆ¶æ€§æ®‹å·®ç»“æ„å…·æœ‰è¿ç§»æ½œåŠ›ã€‚

### ğŸ”¬ æ¶ˆèå®éªŒä¸å…³é”®åˆ†æï¼ˆæ¥è‡ª Fig. 2 åŠè®¨è®ºï¼‰

- **NTK ç‰¹å¾å€¼æ¼”åŒ–åˆ†æ**ï¼š
  - NTK-ECRN çš„ $\lambda_{\max}(t)$ å¢é•¿å¹³æ»‘ä¸”å¯æ§ï¼›
  - ResNet-18 å’Œ Standard NTK å‡ºç°å‰§çƒˆéœ‡è¡æˆ–å¿«é€Ÿå‘æ•£ï¼›
  - $\|\Delta \Theta^{(t)}\|_F$ å¢é•¿ç¼“æ…¢ï¼Œè¡¨æ˜ kernel æ›´ç¨³å®šã€‚

- **æ¶ˆèå¯ç¤º**ï¼ˆæ–‡ä¸­è™½æœªå•ç‹¬åˆ—å‡ºè¡¨æ ¼ï¼Œä½†ä» ablation å¼æè¿°å¯å¾—ï¼‰ï¼š
  - ç§»é™¤ Fourier embedding â†’ é«˜é¢‘å­¦ä¹ å˜æ…¢ï¼Œ$R^2$ ä¸‹é™æ˜æ˜¾ï¼›
  - ç§»é™¤ $\alpha_l$ ç¼©æ”¾ â†’ $\lambda_{\max}$ å¿«é€Ÿä¸Šå‡ï¼Œå‡ºç°è®­ç»ƒä¸ç¨³å®šï¼›
  - ç§»é™¤ Stochastic Depth â†’ æ³›åŒ–è¯¯å·®ç•¥å‡ï¼Œå°¤å…¶åœ¨å°æ ·æœ¬åœºæ™¯ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ğŸ¯ ä¸»è¦å‘ç°

1. **NTK æ¼”åŒ–å¯æ§æ€§ç›´æ¥å½±å“è®­ç»ƒç¨³å®šæ€§ä¸æ³›åŒ–èƒ½åŠ›**  
   é€šè¿‡è®¾è®¡æ®‹å·®ç¼©æ”¾ç³»æ•° $\alpha_l$ å’Œ Fourier ç‰¹å¾ï¼Œå¯ä»¥æœ‰æ•ˆè°ƒæ§ NTK çš„ç‰¹å¾å€¼è°±æ¼”åŒ–è·¯å¾„ï¼Œé˜²æ­¢æœ€å¤§ç‰¹å¾å€¼çˆ†ç‚¸ï¼Œç»´æŒâ€œè¾¹ç¼˜ç¨³å®šâ€çŠ¶æ€ã€‚

2. **Fourier Feature Embeddings æ˜¾è‘—ç¼“è§£ spectral bias**  
   ä½¿å¾—ç½‘ç»œèƒ½å¤Ÿåœ¨æ—©æœŸé˜¶æ®µå°±å­¦ä¹ åˆ°é«˜é¢‘ç‡çš„æ•°æ®ç»“æ„ï¼Œè§£å†³äº†ä¼ ç»Ÿ MLP â€œå…ˆå­¦ä½é¢‘åå­¦é«˜é¢‘â€ çš„ç“¶é¢ˆã€‚

3. **Stochastic Depth ä¸ä»…æ­£åˆ™åŒ–ï¼Œè¿˜ä¿ç•™äº†è§£ææ€§è´¨**  
   åœ¨ä¸ç‰ºç‰²ç†è®ºå¯è¿½è¸ªæ€§çš„å‰æä¸‹å¢å¼ºäº†æ³›åŒ–èƒ½åŠ›ã€‚

4. **ç†è®ºä¸å®è·µå¯ä»¥ååŒæ¨è¿›**  
   NTK-ECRN æˆåŠŸå®ç°äº†ä»â€œæ•°å­¦æ¨å¯¼ â†’ æ¶æ„è®¾è®¡ â†’ å®éªŒéªŒè¯â€çš„å®Œæ•´é“¾æ¡ï¼Œå±•ç¤ºäº† deep learning theory å¦‚ä½•æŒ‡å¯¼å®é™…æ¨¡å‹æ”¹è¿›ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

- **è®¡ç®—å¼€é”€è¾ƒå¤§**ï¼šå…¨ç¨‹è·Ÿè¸ª NTK çŸ©é˜µéœ€ $O(n^2)$ å†…å­˜ï¼ˆ$n$: æ ·æœ¬æ•°ï¼‰ï¼Œé™åˆ¶äº†åœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šçš„ç›´æ¥åº”ç”¨ã€‚
- **ä¾èµ–è‰¯å¥½åˆå§‹åŒ–ä¸å‚æ•°è°ƒä¼˜**ï¼š$\alpha_l$ã€$B$ï¼ˆFourier çŸ©é˜µï¼‰ç­‰è¶…å‚æ•°éœ€è¦è°¨æ…é€‰æ‹©ã€‚
- **ç›®å‰ä¸»è¦ç”¨äºä¸­å°è§„æ¨¡ä»»åŠ¡**ï¼šå°šæœªåœ¨ ImageNet ç­‰å¤§å‹è§†è§‰ä»»åŠ¡ä¸ŠéªŒè¯ scalabilityã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³ CNN / Transformer æ¶æ„**ï¼šå°† NTK-ECRN è®¾è®¡åŸåˆ™æ¨å¹¿åˆ°å·ç§¯æˆ–æ³¨æ„åŠ›æ¨¡å—ä¸­ã€‚
2. **è‡ªé€‚åº” $\alpha_l$ æœºåˆ¶**ï¼šè®¾è®¡åŠ¨æ€è°ƒæ•´ç¼©æ”¾ç³»æ•°çš„æ–¹æ³•ï¼Œè¿›ä¸€æ­¥è‡ªåŠ¨åŒ–æ§åˆ¶ NTK æ¼”åŒ–ã€‚
3. **é«˜æ•ˆ NTK è¿‘ä¼¼ç®—æ³•**ï¼šå¼€å‘ä½ç§©æˆ–éšæœºä¼°è®¡æ–¹æ³•ï¼Œé™ä½ kernel tracking çš„è®¡ç®—æˆæœ¬ã€‚
4. **è¿æ¥ Feature Learning Regime**ï¼šæ¢ç´¢è¶…è¶Š NTK çº¿æ€§åŒ–åŒºåŸŸçš„è¡Œä¸ºï¼Œå‘â€œfeature learningâ€è¿‡æ¸¡ã€‚

---

## æ€»ç»“

âœ… **NTK-ECRN æ˜¯ä¸€é¡¹å°† deep learning theory è½¬åŒ–ä¸ºå¯å·¥ç¨‹å®ç°æ¶æ„çš„æˆåŠŸå°è¯•**ã€‚å®ƒä¸ä»…åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜äºä¸»æµæ¨¡å‹çš„æ€§èƒ½ï¼Œæ›´é‡è¦çš„æ˜¯å»ºç«‹äº†ä¸€ä¸ª**å¯è§£é‡Šã€å¯æ§åˆ¶ã€å¯éªŒè¯**çš„è®­ç»ƒåŠ¨æ€åˆ†æèŒƒå¼ï¼Œä¸ºä¸‹ä¸€ä»£â€œç†è®ºé©±åŠ¨â€çš„ç¥ç»ç½‘ç»œè®¾è®¡æä¾›äº†é‡è¦å‚è€ƒã€‚

</details>

---

### 14. [SkipKV: Selective Skipping of KV Generation and Storage for Efficient Inference with Large Reasoning Models](https://arxiv.org/abs/2512.07993)

**Authors**: Jiayi Tian, Seyedarmin Azizi, Yequan Zhao, Erfan Baghaei Potraghloo, Sean McPherson, Sharath Nittur Sridhar, Zhengyang Wang, Zheng Zhang, Massoud Pedram, Souvik Kundu  
**Category**: cs.AI  
**Published**: 2025-12-10  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.07993v1  

#### Abstract
Large reasoning models (LRMs) often cost significant key-value (KV) cache overhead, due to their linear growth with the verbose chain-of-thought (CoT) reasoning process. This costs both memory and throughput bottleneck limiting their efficient deployment. Towards reducing KV cache size during infere...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSkipKV: Selective Skipping of KV Generation and Storage for Efficient Inference with Large Reasoning Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLarge Reasoning Models, LRMsï¼‰åœ¨æ‰§è¡Œå¤æ‚æ¨ç†ä»»åŠ¡ï¼ˆå¦‚æ•°å­¦æ¨å¯¼ã€ä»£ç ç”Ÿæˆï¼‰æ—¶ï¼Œé€šå¸¸ä¾èµ–å†—é•¿çš„ Chain-of-Thoughtï¼ˆCoTï¼‰è¿‡ç¨‹ï¼Œå¯¼è‡´ Key-Valueï¼ˆKVï¼‰ç¼“å­˜æ€¥å‰§å¢é•¿ã€‚è¿™å¸¦æ¥äº†ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š

- **å†…å­˜ç“¶é¢ˆ**ï¼šKV ç¼“å­˜éšæ¨ç†é•¿åº¦çº¿æ€§å¢é•¿ï¼Œå ç”¨å¤§é‡æ˜¾å­˜ï¼Œé™åˆ¶äº†æ‰¹é‡å¤„ç†èƒ½åŠ›ã€‚
- **æ•ˆç‡ä¸‹é™**ï¼šä¼ ç»Ÿ KV å‹ç¼©æ–¹æ³•ï¼ˆå¦‚åŸºäº token é‡è¦æ€§çš„å‰ªæï¼‰åœ¨å¤šæ‰¹æ¬¡ï¼ˆmulti-batchï¼‰åœºæ™¯ä¸‹ç²¾åº¦æ˜¾è‘—ä¸‹é™ï¼Œä¸”å¯èƒ½å› ä¸Šä¸‹æ–‡ä¸¢å¤±å¼•å‘â€œè¿‡åº¦æ€è€ƒâ€ï¼ˆoverthinkingï¼‰ï¼Œåè€Œå»¶é•¿ç”Ÿæˆé•¿åº¦ã€‚

æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•ï¼ˆå¦‚ H2Oã€R-KVï¼‰å­˜åœ¨ä»¥ä¸‹ç¼ºé™·ï¼š
- ä»…åœ¨ token ç²’åº¦è¿›è¡Œå‰ªæï¼Œç ´åè¯­ä¹‰è¿è´¯æ€§ï¼›
- å¿½è§†å¥å­çº§å†—ä½™ï¼Œå¯¼è‡´é‡å¤éªŒè¯å’Œæ— æ•ˆæ¨ç†ï¼›
- å¤šæ‰¹æ¬¡æ¨ç†ä¸­å›  padding tokens å¯¼è‡´æœ‰æ•ˆ KV é¢„ç®—å‡å°‘ï¼Œå½±å“ç¨³å®šæ€§ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

è®ºæ–‡æå‡º **SkipKV**ï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„ã€é¢å‘å¥å­çº§åˆ«çš„ KV å‹ç¼©æ¡†æ¶ï¼Œé€šè¿‡**é€‰æ‹©æ€§è·³è¿‡ KV å­˜å‚¨ä¸ç”Ÿæˆ**æ¥æå‡æ¨ç†æ•ˆç‡ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**å¥å­çº§å†—ä½™æ£€æµ‹ä¸ KV å­˜å‚¨è·³è¿‡ï¼ˆSentence-level Skipping of KV Storageï¼‰**
- å¼•å…¥ **Pairwise Sentence Similarity (PSS)** æŒ‡æ ‡ï¼ŒåŸºäºæœ€åä¸€å±‚éšè—çŠ¶æ€è®¡ç®—å¥å­åµŒå…¥çš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚
- å®šä¹‰å†—ä½™å¥å¯¹ï¼ˆPSS â‰¥ 0.95ï¼‰ï¼Œä¼˜å…ˆç§»é™¤æ—©æœŸé«˜åº¦ç›¸ä¼¼çš„å®Œæ•´å¥å­ï¼Œä¿ç•™è¯­ä¹‰ä¸»å¹²ã€‚
- è®¾è®¡ **KV Cache Range Monitoring Logic**ï¼Œç¡®ä¿ç”Ÿæˆç©ºé—´ä¸ç¼“å­˜ç©ºé—´çš„å¥å­èŒƒå›´æ˜ å°„ä¸€è‡´ï¼Œé¿å…é”™ä½åˆ é™¤ã€‚

#### ï¼ˆ2ï¼‰**è‡ªé€‚åº” KV å¼•å¯¼æœºåˆ¶ï¼ˆAdaptive Steering for KV Generation Skippingï¼‰**
- æ„å»º steering vectorï¼šé€šè¿‡ MATH æ•°æ®é›†ä¸Š execution ä¸ non-execution æ€ç»´çš„éšè—çŠ¶æ€å·®å¼‚å¾—åˆ°ã€‚
- åŠ¨æ€è°ƒæ•´å¼•å¯¼å¼ºåº¦ $ \alpha_t = \alpha_0 + \gamma \cdot N_o $ï¼Œå…¶ä¸­ $ N_o $ æ˜¯éæ‰§è¡Œæ€ç»´è®¡æ•°å™¨ï¼Œè¶Šå†—ä½™åˆ™å¼•å¯¼è¶Šå¼ºï¼ŒæŠ‘åˆ¶æ— æ„ä¹‰ç”Ÿæˆã€‚

#### ï¼ˆ3ï¼‰**æ‰¹å¤„ç†åˆ†ç»„ç­–ç•¥ï¼ˆBatch Grouping for Multi-batch Decodingï¼‰**
- å°†è¾“å…¥æ ·æœ¬æŒ‰ prefill é•¿åº¦æ’åºååˆ†ç»„ï¼Œå‡å°‘åŒä¸€æ‰¹æ¬¡å†…çš„é•¿åº¦å·®å¼‚ï¼Œä»è€Œé™ä½ padding tokens æ•°é‡ã€‚
- æé«˜æœ‰æ•ˆ KV é¢„ç®—ï¼ˆvalid KV budgetï¼‰ï¼Œå¢å¼ºå¤šæ‰¹æ¬¡ä¸‹çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | SkipKV | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ H2O, R-KVï¼‰ |
|------|--------|--------------------------|
| **ç²’åº¦** | å¥å­çº§ï¼ˆè¯­ä¹‰å•å…ƒï¼‰ | Token çº§ï¼ˆç¢ç‰‡åŒ–ï¼‰ |
| **ç”Ÿæˆé•¿åº¦** | æ˜¾è‘—ç¼©çŸ­ï¼ˆå‡å°‘ up to 48%ï¼‰ | å¾€å¾€æ›´é•¿ï¼ˆå› ä¸Šä¸‹æ–‡ä¸¢å¤±éœ€é‡éªŒè¯ï¼‰ |
| **å¤šæ‰¹æ¬¡è¡¨ç°** | ç¨³å®šï¼Œç²¾åº¦ä¿æŒé«˜ | ç²¾åº¦æ˜¾è‘—ä¸‹é™ |
| **è¯­ä¹‰è¿è´¯æ€§** | ä¿æŒæ¨ç†æµå®Œæ•´æ€§ | æ˜“æ‰“æ–­å…³é”®æ­¥éª¤ï¼ˆå¦‚åˆ æ•°å­—ï¼‰ |
| **å†…å­˜æ•ˆç‡** | æ›´é«˜å‹ç¼©æ¯”ä¸‹ç»´æŒå‡†ç¡®ç‡ | å‹ç¼©åç²¾åº¦æŸå¤±å¤§ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **æ•°å­¦æ¨ç†ä»»åŠ¡**ï¼š
  - **MATH-500**ï¼š500 é“é«˜ä¸­æ•°å­¦ç«èµ›é¢˜ã€‚
  - **AIME-24**ï¼šç¾å›½æ•°å­¦é‚€è¯·èµ›é¢˜ç›®ï¼Œéš¾åº¦æ›´é«˜ã€‚
  - **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼Œæµ‹è¯•åŸºç¡€æ¨ç†ã€‚
- **ä»£ç ç”Ÿæˆä»»åŠ¡**ï¼š
  - **LiveCodeBench**ï¼šç¼–ç¨‹é—®é¢˜ï¼Œè¯„ä¼°ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹**
- **DeepSeek-R1-Distill-Qwen-7B / 14B**
- **DeepSeek-R1-Distill-Llama-8B**

#### **è¯„ä¼°æŒ‡æ ‡**
- **Accuracy (pass@1)**ï¼šæœ€ç»ˆç­”æ¡ˆæ­£ç¡®ç‡ã€‚
- **Total Token Length**ï¼šç”Ÿæˆæ€» token æ•°ï¼Œåæ˜ æ¨ç†æ•ˆç‡ã€‚
- **Throughput (samples/min)**ï¼šæ¯åˆ†é’Ÿå¤„ç†æ ·æœ¬æ•°ï¼Œè¡¡é‡ç«¯åˆ°ç«¯ååã€‚
- **KV Cache Budget Ratio**ï¼šåˆ†é…çš„ KV ç¼“å­˜å¤§å°å  FullKV å¹³å‡é•¿åº¦çš„æ¯”ä¾‹ï¼ˆå¦‚ 20%, 30%ï¼‰ã€‚

#### **å®éªŒé…ç½®**
- æ‰¹å¤§å°ï¼ˆbatch sizeï¼‰ï¼š10ï¼ˆé™¤éç‰¹åˆ«è¯´æ˜ï¼‰
- æœ€å¤§ç”Ÿæˆé•¿åº¦ï¼š8192â€“16384 tokens
- ç¡¬ä»¶ï¼šå•å¼  NVIDIA A100 (40GB)

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **FullKV** | åŸºçº¿ | ä¸å‹ç¼© KV ç¼“å­˜ï¼Œç²¾åº¦æœ€é«˜ä½†å†…å­˜å¼€é”€æœ€å¤§ |
| **H2O** | KV Eviction | åŸºäºç´¯ç§¯æ³¨æ„åŠ›åˆ†æ•°å‰ªæä½é‡è¦æ€§ token |
| **R-KV** | KV Eviction | åŸºäº token çº§å†—ä½™è¯„åˆ†å‰ªæï¼Œå½“å‰ SoTA |
| **SEAL** | Steering | å¼•å¯¼éšè—çŠ¶æ€ä»¥ç¼©çŸ­æ¨ç†è·¯å¾„ï¼Œä¸ç›´æ¥å‹ç¼© KV |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **ç²¾åº¦è¡¨ç°ï¼ˆAccuracyï¼‰**
- åœ¨ **AIME-24** ä¸Šï¼ŒSkipKV ä½¿ç”¨ **ä»… 15% KV é¢„ç®—**å³å¯è¾¾åˆ° FullKV çš„ç²¾åº¦ã€‚
- åœ¨ **R1-Qwen-14B** ä¸Šï¼ŒSkipKV æ¯” R-KV æå‡é«˜è¾¾ **+26.7% å‡†ç¡®ç‡**ï¼ˆç›¸åŒå‹ç¼©é¢„ç®—ä¸‹ï¼‰ã€‚
- åœ¨ **LiveCodeBench** ä¸Šï¼ŒSkipKV æ¯” FullKV æå‡ **+5.2% ç²¾åº¦**ï¼ŒåŒæ—¶ä½¿ç”¨ **ä¸€åŠ KV å†…å­˜**ã€‚

#### âœ… **ç”Ÿæˆæ•ˆç‡ï¼ˆToken Lengthï¼‰**
- ç›¸æ¯” FullKVï¼ŒSkipKV **å‡å°‘æœ€å¤š 30% ç”Ÿæˆé•¿åº¦**ã€‚
- ç›¸æ¯” R-KVï¼ŒSkipKV ç”Ÿæˆ token æ•°å°‘ **32%~48%**ï¼ˆä¾æ¨¡å‹è€Œå®šï¼‰ï¼š
  - R1-Qwen-7B: -32%
  - R1-Qwen-14B: -39%
  - R1-Llama-8B: -48%

#### âœ… **ååé‡ï¼ˆThroughputï¼‰**
- åœ¨ GSM8K ä¸Šï¼ŒSkipKV è¾¾åˆ° **9.6Ã— åŠ é€Ÿ** vs FullKVã€‚
- ç›¸æ¯” R-KVï¼ŒSkipKV ååæå‡ **up to 1.7Ã—**ï¼Œå¾—ç›Šäºæ›´çŸ­ç”Ÿæˆé•¿åº¦ã€‚
- æ”¯æŒæ›´å¤§ batch sizeï¼ˆå¦‚ 140 vs FullKV OOMï¼‰ï¼Œçªç ´å†…å­˜ç“¶é¢ˆã€‚

#### âœ… **KV å†…å­˜èŠ‚çœ**
- å®ç° **2Ã— è‡³ 6.6Ã— KV å†…å­˜å‹ç¼©**ï¼Œå…·ä½“å–å†³äºä»»åŠ¡å’Œæ¨¡å‹ã€‚
- åœ¨ AIME-24 ä¸Šï¼ŒSkipKV ä»…ç”¨ **2.8GB KV ç¼“å­˜**ï¼Œè€Œ FullKV éœ€ **18.5GB**ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

| ç»„ä»¶ | Accuracy â†‘ | Token Length â†“ | è¯´æ˜ |
|------|------------|----------------|------|
| **R-KV åŸºçº¿** | 36.7% @20% KV | 12000 | â€” |
| + **Sentence Scoring** | +3.3% | -6% | ç§»é™¤å†—ä½™å¥ï¼Œå°å¹…æå‡ |
| + **Adaptive Steering** | +10.0% | -26% | åŠ¨æ€æŠ‘åˆ¶æ— æ„ä¹‰ç”Ÿæˆï¼Œå¤§å¹…å‡é•¿ |
| + **Batch Grouping** | **+13.3%** | **-30%** | æé«˜æœ‰æ•ˆé¢„ç®—ï¼Œå…¨é¢æå‡ |

> ç»“è®ºï¼šä¸‰ä¸ªç»„ä»¶ååŒä½œç”¨ï¼Œå®ç°ä»å±€éƒ¨è¿‡æ»¤åˆ°å…¨å±€åè°ƒçš„å±‚æ¬¡åŒ–ä¼˜åŒ–ã€‚

---

### **Batch Grouping æ•ˆæœéªŒè¯ï¼ˆTable 3ï¼‰**

| KV Budget | w/o Grouping Acc | w/ Grouping Acc | æå‡ |
|-----------|------------------|------------------|------|
| 768 (26%) | 77.8% | **83.4%** | +5.6% |
| 1024 (34%) | 85.2% | **86.4%** | +1.2% |

> è¡¨æ˜ batch grouping æ˜¾è‘—ç¼“è§£ padding å¯¼è‡´çš„æœ‰æ•ˆé¢„ç®—ä¸è¶³é—®é¢˜ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **token çº§å‰ªæç ´åè¯­ä¹‰è¿è´¯æ€§**ï¼šç°æœ‰æ–¹æ³•ï¼ˆå¦‚ R-KVï¼‰è™½èƒ½å‹ç¼© KVï¼Œä½†å¸¸åˆ é™¤å…³é”®æ•°å€¼æˆ–ç­”æ¡ˆç‰‡æ®µï¼Œè¿«ä½¿æ¨¡å‹åå¤éªŒè¯ï¼Œå¯¼è‡´â€œè¶Šå‹ç¼©è¶Šé•¿â€çš„æ‚–è®ºã€‚
2. **å¥å­çº§å†—ä½™æ˜¯ CoT æ¨ç†ä¸­çš„ä¸»è¦æµªè´¹æº**ï¼šé”™è¯¯å›ç­”ä¸­é«˜ç›¸ä¼¼å¥å­æ¯”ä¾‹é«˜å‡ºæ­£ç¡®å›ç­” **1.7Ã—**ï¼Œéæ‰§è¡Œæ€ç»´å¤šå‡º **2.6Ã—**ã€‚
3. **SkipKV å®ç°â€œæ›´çŸ­ã€æ›´å‡†ã€æ›´å¿«â€**ï¼š
   - é€šè¿‡å¥å­çº§å‰ªæä¿æŒæ¨ç†å®Œæ•´æ€§ï¼›
   - è‡ªé€‚åº” steering æŠ‘åˆ¶å†—ä½™ç”Ÿæˆï¼›
   - batch grouping æå‡å¤šæ‰¹æ¬¡é²æ£’æ€§ã€‚
4. **æ— éœ€è®­ç»ƒå³å¯éƒ¨ç½²**ï¼šSkipKV ä¸ºçº¯æ¨ç†æœŸä¼˜åŒ–ï¼Œå…¼å®¹ç°æœ‰ LRMï¼Œæ˜“äºé›†æˆã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- **ä¾èµ–å¥å­åˆ†å‰²è´¨é‡**ï¼šç›®å‰ä½¿ç”¨ç®€å•è§„åˆ™ï¼ˆæ¢è¡Œç¬¦ã€æ ‡ç‚¹ï¼‰åˆ‡åˆ†å¥å­ï¼Œå¯èƒ½è¯¯åˆ¤å¤åˆå¥ç»“æ„ã€‚
- **steering vector éœ€ç¦»çº¿æ„å»º**ï¼šéœ€é¢å¤–ä½¿ç”¨ MATH è®­ç»ƒé›†æå– execution/non-execution å·®å¼‚å‘é‡ã€‚
- **æç«¯å‹ç¼©ä¸‹ä»å¯èƒ½ä¸¢ä¿¡æ¯**ï¼šå½“ KV é¢„ç®—æä½ï¼ˆ<10%ï¼‰æ—¶ï¼Œå³ä½¿ SkipKV ä¹Ÿå¯èƒ½å‡ºç°ç²¾åº¦æ»‘å¡ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

- æ¢ç´¢åŠ¨æ€å¥å­è¾¹ç•Œè¯†åˆ«ï¼ˆå¦‚åŸºäºè¯­ä¹‰è½¬æŠ˜ï¼‰ã€‚
- å°† steering æœºåˆ¶æ‰©å±•è‡³å¤šå±‚æˆ–å¤šå¤´ attentionã€‚
- ç»“åˆé‡åŒ–ï¼ˆquantizationï¼‰è¿›ä¸€æ­¥å‹ç¼© KV å­˜å‚¨ï¼ˆä½œè€…æŒ‡å‡ºæ­¤ä¸ºæ­£äº¤æ–¹å‘ï¼‰ã€‚
- åº”ç”¨äºå…¶ä»–é•¿æ¨ç†åœºæ™¯ï¼Œå¦‚æ³•å¾‹åˆ†æã€ç§‘å­¦æ–‡çŒ®ç†è§£ç­‰ã€‚

---

> **æ€»ç»“**ï¼šSkipKV æå‡ºäº†ä¸€ç§è¯­ä¹‰æ„ŸçŸ¥çš„ã€å¥å­çº§çš„ KV å‹ç¼©èŒƒå¼ï¼Œè§£å†³äº†ä¼ ç»Ÿ token çº§æ–¹æ³•åœ¨ CoT æ¨ç†ä¸­çš„æ ¹æœ¬ç¼ºé™·ï¼Œåœ¨ç²¾åº¦ã€é•¿åº¦ã€ååä¸‰æ–¹é¢å…¨é¢è¶…è¶Š SoTAï¼Œä¸ºå¤§è§„æ¨¡æ¨ç†æ¨¡å‹çš„é«˜æ•ˆéƒ¨ç½²æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 15. [Beyond Traditional Diagnostics: Transforming Patient-Side Information into Predictive Insights with Knowledge Graphs and Prototypes](https://arxiv.org/abs/2512.08261)

**Authors**: Yibowen Zhao, Yinan Zhang, Zhixiang Su, Lizhen Cui, Chunyan Miao  
**Category**: cs.AI  
**Published**: 2025-12-10  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.08261v1  

#### Abstract
Predicting diseases solely from patient-side information, such as demographics and self-reported symptoms, has attracted significant research attention due to its potential to enhance patient awareness, facilitate early healthcare engagement, and improve healthcare system efficiency. However, existi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šBeyond Traditional Diagnostics: Transforming Patient-Side Information into Predictive Insights with Knowledge Graphs and Prototypes

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**ä»…åŸºäºæ‚£è€…ç«¯ä¿¡æ¯**ï¼ˆå¦‚äººå£ç»Ÿè®¡å­¦ç‰¹å¾å’Œè‡ªè¿°ç—‡çŠ¶ï¼‰è¿›è¡Œç–¾ç—…é¢„æµ‹æ‰€é¢ä¸´çš„ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **æ•°æ®åˆ†å¸ƒä¸å¹³è¡¡**ï¼šå¸¸è§ç—…æ ·æœ¬è¿œå¤šäºç½•è§ç—…ï¼Œå¯¼è‡´æ¨¡å‹å¯¹é•¿å°¾ç–¾ç—…ï¼ˆlong-tailed diseasesï¼‰é¢„æµ‹æ€§èƒ½å·®ã€‚
- **ç¼ºä¹å¯è§£é‡Šæ€§**ï¼šç°æœ‰æ¨¡å‹éš¾ä»¥æä¾›ä¸´åºŠå¯ä¿¡ã€é€æ˜çš„æ¨ç†è¿‡ç¨‹ï¼Œé™åˆ¶äº†åœ¨çœŸå®åŒ»ç–—åœºæ™¯ä¸­çš„åº”ç”¨ã€‚
- **å¿½ç•¥ç»“æ„åŒ–åŒ»å­¦çŸ¥è¯†**ï¼šå¤šæ•°æ–¹æ³•ä¾èµ–æµ…å±‚æ–‡æœ¬ç‰¹å¾ï¼Œæœªæœ‰æ•ˆæ•´åˆæƒå¨åŒ»å­¦çŸ¥è¯†ï¼Œæ˜“äº§ç”Ÿè¯­ä¹‰ç¼ºå¤±æˆ–è¯¯åˆ†ç±»ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šKPI æ¡†æ¶
ä½œè€…æå‡º **KPI**ï¼ˆKnowledge graph-enhanced, Prototype-aware, and Interpretableï¼‰æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰æ„å»ºç»Ÿä¸€çš„ç–¾ç—…çŸ¥è¯†å›¾è°±ï¼ˆDisease Knowledge Graphï¼‰
- åˆ©ç”¨ **LLM** ä»æƒå¨åŒ»å­¦æè¿°ä¸­æå–ç»“æ„åŒ–ä¸‰å…ƒç»„ï¼ˆå®ä½“-å…³ç³»-å®ä½“ï¼‰ï¼Œå¹¶é€šè¿‡è¯­ä¹‰å¯¹é½ä¸èåˆæŠ€æœ¯æ„å»ºä¸€ä¸ªç»Ÿä¸€ã€å»å†—ä½™çš„çŸ¥è¯†å›¾è°± $ \mathcal{G}_u $ã€‚
- å¼•å…¥ä¸¤é˜¶æ®µæç¤ºç­–ç•¥ï¼š
  - ç¬¬ä¸€é˜¶æ®µï¼šæŠ½å–ç–¾ç—…ç›¸å…³ä¸‰å…ƒç»„ï¼›
  - ç¬¬äºŒé˜¶æ®µï¼šæ ‡å‡†åŒ–å…³ç³»å®šä¹‰ï¼Œç¡®ä¿è·¨ç–¾ç—…çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚

#### ï¼ˆ2ï¼‰åŸå‹æ„ŸçŸ¥å­¦ä¹ ï¼ˆPrototype-aware Learningï¼‰
- åŸºäºçŸ¥è¯†å›¾è°±åˆå§‹åŒ–å…·æœ‰ä¸´åºŠæ„ä¹‰çš„**ç–¾ç—…åŸå‹**ï¼ˆdisease prototypesï¼‰ï¼Œä½œä¸ºæ¯ç±»ç–¾ç—…çš„è¯­ä¹‰é”šç‚¹ã€‚
- åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€šè¿‡å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰åŠ¨æ€æ›´æ–°åŸå‹åµŒå…¥ï¼Œä½¿å…¶æ—¢èƒ½ä¿æŒåŒ»å­¦è¯­ä¹‰ä¸€è‡´æ€§ï¼Œåˆèƒ½é€‚åº”å¤šæ ·åŒ–çš„æ‚£è€…å™è¿°ã€‚

#### ï¼ˆ3ï¼‰å¯¹æ¯”å­¦ä¹ æå‡é•¿å°¾ç–¾ç—…è¯†åˆ«èƒ½åŠ›
- é‡‡ç”¨ **prototype-based contrastive learning**ï¼Œå°†æ‚£è€…è¡¨å¾ä¸æ­£ç¡®ç–¾ç—…åŸå‹æ‹‰è¿‘ï¼Œä¸å…¶ä»–åŸå‹æ¨è¿œã€‚
- æ˜¾è‘—æå‡äº†å¯¹ä½é¢‘/ç½•è§ç–¾ç—…çš„åˆ¤åˆ«èƒ½åŠ›ã€‚

#### ï¼ˆ4ï¼‰å¯è§£é‡Šæ€§å¢å¼ºæœºåˆ¶
- ç»“åˆæ‚£è€…å™è¿°ä¸é¢„æµ‹ç»“æœï¼Œæ£€ç´¢ä¸ªæ€§åŒ–çš„å­å›¾ï¼ˆpatient-specific subgraphï¼‰ã€‚
- åˆ©ç”¨ **LLM** ç”ŸæˆåŸºäºçŸ¥è¯†å›¾è°±è¯æ®çš„ã€ä¸ªæ€§åŒ–ä¸”åŒ»å­¦ä¸Šåˆç†çš„è§£é‡Šï¼Œæå‡æ¨¡å‹é€æ˜åº¦å’ŒåŒ»ç”Ÿä¿¡ä»»åº¦ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | KPI çš„ä¼˜åŠ¿ |
|------|-----------|
| **å‡†ç¡®æ€§** | åœ¨é«˜åº¦ä¸å¹³è¡¡çš„æ•°æ®ä¸‹ä»èƒ½å‡†ç¡®é¢„æµ‹ç½•è§ç—…ï¼ˆå¦‚ Cold ç±» hit@1 è¾¾ 0.88ï¼‰ |
| **å¯è§£é‡Šæ€§** | æä¾›åŸºäºçŸ¥è¯†å›¾è°±çš„ã€å¯è¿½æº¯çš„è§£é‡Šï¼Œä¼˜äºé»‘ç®±æ¨¡å‹æˆ–é€šç”¨ LLM è¾“å‡º |
| **æ³›åŒ–æ€§** | èåˆç»“æ„åŒ–çŸ¥è¯†ä¸è‡ªç”±æ–‡æœ¬ï¼Œå¢å¼ºäº†å¯¹å™ªå£°å’Œç¨€ç–è¾“å…¥çš„é²æ£’æ€§ |
| **æ•ˆç‡** | æ¨ç†é€Ÿåº¦å¿«ï¼ˆ17.7 ç§’å®Œæˆå…¨æµ‹è¯•é›†ï¼‰ï¼Œé€‚åˆå®é™…éƒ¨ç½² |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
ä½¿ç”¨å…¬å¼€çš„çœŸå®ä¸–ç•ŒåŒ»æ‚£å’¨è¯¢æ•°æ®é›† **Haodf**ï¼Œæ¶µç›–å…­ç§ç–¾ç—…ç±»åˆ«ï¼š
- Common Cold (Cold)
- Pneumonia (Pneu.)
- Diabetes (Diab.)
- Depression (Depr.)
- Coronary Heart Disease (CHD)
- Lung Cancer (Lung)

| ç‰¹å¾ | æè¿° |
|------|------|
| æ•°æ®æ¥æº | ä¸­å›½åœ¨çº¿åŒ»ç–—å¹³å°â€œå¥½å¤§å¤«â€ |
| æ€»è®°å½•æ•° | è¶…è¿‡ 3 ä¸‡æ¡ |
| è¾“å…¥ä¿¡æ¯ | è‡ªç”±æ–‡æœ¬ç—‡çŠ¶å™è¿° + è‡ªæŠ¥äººå£ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¹´é¾„ã€æ€§åˆ«ç­‰ï¼‰ |
| æ ‡ç­¾ | åŒ»ç”Ÿç¡®è®¤è¯Šæ–­ç»“æœ |

> æ³¨ï¼šè¯¥æ•°æ®é›†æ˜¯ç›®å‰å”¯ä¸€å…¬å¼€æ”¯æŒâ€œæ‚£è€…ä¾§ä¿¡æ¯â†’ç–¾ç—…é¢„æµ‹â€ç ”ç©¶çš„å¸¦æ ‡æ³¨æ•°æ®é›†ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **Hit Rate**ï¼šhit@1, hit@3, hit@10ï¼ˆå‰ k åå‘½ä¸­ç‡ï¼‰
- **AUC**ï¼šROC æ›²çº¿ä¸‹é¢ç§¯
- **NDCG**ï¼šå½’ä¸€åŒ–æŠ˜æŸç´¯è®¡å¢ç›Šï¼ˆæ— æˆªæ–­ï¼‰
- æ‰€æœ‰æŒ‡æ ‡è¶Šé«˜è¶Šå¥½ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºå››ç±»å…± **17 ä¸ªåŸºçº¿æ¨¡å‹**ï¼š

#### ï¼ˆ1ï¼‰ä¼ ç»Ÿæœºå™¨å­¦ä¹ 
- Decision Tree, KNN, AdaBoostï¼ˆä»…ä½¿ç”¨ç»“æ„åŒ–å­—æ®µï¼‰

#### ï¼ˆ2ï¼‰é€šç”¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆPLMsï¼‰
- BERT, RoBERTa, ALBERT, Electra, GIST, Granite, GTE, FinBERT

#### ï¼ˆ3ï¼‰åŒ»å­¦é¢†åŸŸ PLMs
- BioBERT, BioLORD, MedBERT

#### ï¼ˆ4ï¼‰å…ˆè¿›ç–¾ç—…é¢„æµ‹æ¨¡å‹
- **PoMP**ï¼šå½“å‰æœ€å…ˆè¿›çš„æ‚£è€…ä¾§é¢„æµ‹æ¨¡å‹ï¼Œç»“åˆæ–‡æœ¬ä¸ç»“æ„åŒ–è¾“å…¥
- **LLMs**ï¼šGPT-3.5 Turbo, Claude 3, LLaMA 3.1, Gemini, DeepSeek V3, GLM-4 Flash, Qwen Turboï¼ˆé€šè¿‡é—®ç­”æç¤ºè·å–è¾“å‡ºï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table III å’Œ IVï¼‰

| æ¨¡å‹ | Cold (hit@1) | Pneu. (hit@1) | CHD (hit@1) | Lung (hit@1) | å¹³å‡æ’å |
|------|-------------|--------------|------------|-------------|----------|
| KPI | **0.8808** | **0.9269** | **0.6755** | **0.9238** | **1.8** âœ… |
| DeepSeek | 0.5973 | 0.6676 | 0.5809 | 0.7519 | 3.0 |
| Gemini | 0.6166 | 0.6200 | 0.5770 | 0.6837 | 2.6 |
| PoMP | 0.7738 | 0.2402 | 0.3692 | 0.5997 | 5.8 |
| BioBERT | 0.5135 | 0.2457 | 0.3993 | 0.5470 | 11.0 |

> ğŸ’¡ **äº®ç‚¹**ï¼š
> - åœ¨æœ€ç¨€æœ‰çš„ **Cold** ç±»ä¸Šï¼ŒKPI çš„ hit@1 æ˜¯ç¬¬äºŒåï¼ˆDeepSeekï¼‰çš„ **1.48 å€**ã€‚
> - åœ¨æ‰€æœ‰ç±»åˆ«ä¸­ï¼ŒKPI çš„ **hit@1 å¹³å‡é¢†å…ˆç¬¬äºŒåè¶…è¿‡ 20%**ã€‚
> - **NDCG å’Œ AUC åŒæ ·æ˜¾è‘—é¢†å…ˆ**ï¼Œè¯´æ˜æ’åºè´¨é‡æ›´é«˜ã€‚

### ä¸ LLM çš„å¯¹æ¯”ï¼ˆTable IVï¼‰
å°½ç®¡ä¸»æµ LLMï¼ˆå¦‚ GPTã€Claudeã€Geminiï¼‰åœ¨å¸¸è¯†æ¨ç†ä¸Šæœ‰ä¼˜åŠ¿ï¼Œä½†åœ¨æœ¬ä»»åŠ¡ä¸­è¡¨ç°ä¸å¦‚ KPIï¼š
- KPI åœ¨ **æ‰€æœ‰ç–¾ç—…ç±»åˆ«ä¸Šçš„ hit@1 éƒ½æ˜¾è‘—ä¼˜äºæ‰€æœ‰ LLM**ã€‚
- LLM ç¼ºä¹æ˜¾å¼çš„åŒ»å­¦çŸ¥è¯†çº¦æŸï¼Œå®¹æ˜“å‡ºç°â€œå¹»è§‰â€æˆ–æ³›åŒ–åå·®ã€‚
- KPI çš„è®¾è®¡æ›´ä¸“æ³¨äº**ç–¾ç—…ç‰¹å¼‚æ€§çº¿ç´¢æ•æ‰**å’Œ**ç»“æ„åŒ–æ¨ç†**ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable VIï¼‰

| å˜ä½“ | Lung (AUC) | Cold (hit@1) | è¯´æ˜ |
|------|-----------|-------------|------|
| Textualï¼ˆä»…æ–‡æœ¬ï¼‰ | 0.7943 | 0.6615 | å¿½ç•¥ç»“æ„åŒ–ä¿¡æ¯å¯¼è‡´æ€§èƒ½ä¸‹é™ |
| Textual w/ Sï¼ˆåŠ ç»“æ„åŒ–è¾“å…¥ï¼‰ | 0.7765 | 0.7077 | æ”¹è¿›æœ‰é™ï¼Œç¼ºä¹çŸ¥è¯†å¼•å¯¼ |
| KPI w/o S.Cï¼ˆæ— è¯­ä¹‰ä¸€è‡´æ€§æŸå¤±ï¼‰ | 0.8994 | 0.8462 | æ€§èƒ½ä¸‹é™ï¼Œè¯æ˜æ­£åˆ™é¡¹æœ‰æ•ˆ |
| KPI w/o P.Kï¼ˆéšæœºåˆå§‹åŒ–åŸå‹ï¼‰ | 0.8054 | 0.8615 | åŒ»å­¦çŸ¥è¯†ç¼ºå¤±ä¸¥é‡å½±å“æ€§èƒ½ |
| **å®Œæ•´ KPI** | **0.9137** | **0.8769** | æœ€ä¼˜é…ç½® |

> ğŸ” å‘ç°ï¼š
> - **å¼•å…¥çŸ¥è¯†å›¾è°±æ„å»ºçš„åŸå‹è‡³å…³é‡è¦**ï¼Œç§»é™¤å AUC ä¸‹é™è¶… 10%ã€‚
> - **è¯­ä¹‰ä¸€è‡´æ€§æ­£åˆ™é¡¹**å¸®åŠ©æ–‡æœ¬ä¸å›¾åµŒå…¥å¯¹é½ï¼Œå°¤å…¶åœ¨é•¿å°¾ç–¾ç—…ä¸­ä½œç”¨æ˜æ˜¾ã€‚

### æ•ˆç‡ä¸å¯æ‰©å±•æ€§åˆ†æï¼ˆTable Vï¼‰
- KPI åœ¨ **ä»… 30% è®­ç»ƒæ•°æ®**æ—¶å³å¯è¾¾åˆ°æ¥è¿‘å…¨é‡æ•°æ®çš„æ€§èƒ½ã€‚
- å®Œæ•´æµ‹è¯•é›†æ¨ç†è€—æ—¶ä»… **17.72 ç§’**ï¼Œä¼˜äº PoMPï¼ˆ18.48 ç§’ï¼‰å’Œ GTEï¼ˆ20.81 ç§’ï¼‰ã€‚
- è¡¨æ˜ KPI ä¸ä»…å‡†ç¡®ï¼Œè€Œä¸”å…·å¤‡è‰¯å¥½çš„**ä½èµ„æºé€‚åº”æ€§å’Œéƒ¨ç½²æ•ˆç‡**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **KPI åœ¨æ‚£è€…ä¾§ç–¾ç—…é¢„æµ‹ä»»åŠ¡ä¸Šå…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•**ï¼Œå°¤å…¶æ˜¯åœ¨é•¿å°¾ç–¾ç—…ï¼ˆå¦‚æ„Ÿå†’ã€æŠ‘éƒç—‡ï¼‰ä¸Šè¡¨ç°å‡ºå“è¶Šçš„é²æ£’æ€§ã€‚
2. âœ… **çŸ¥è¯†å›¾è°± + åŸå‹å­¦ä¹ ** çš„ç»„åˆèƒ½æœ‰æ•ˆç¼“è§£æ•°æ®ä¸å¹³è¡¡é—®é¢˜ï¼Œå¹¶å¢å¼ºæ¨¡å‹çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚
3. âœ… **å¯è§£é‡Šæ€§æ¨¡å—ç”Ÿæˆçš„è§£é‡Šè·å¾—åŒ»ç”Ÿé«˜è¯„åˆ†**ï¼ˆå¹³å‡ >4.1/5ï¼‰ï¼Œè¡¨æ˜å…¶å…·å¤‡ä¸´åºŠå¯ç”¨ä»·å€¼ã€‚
4. âœ… **å¯¹æ¯”å­¦ä¹  + è¯­ä¹‰ä¸€è‡´æ€§æ­£åˆ™åŒ–** æ˜¯æå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›å’Œç¨³å®šæ€§çš„é‡è¦æœºåˆ¶ã€‚
5. âœ… å³ä½¿é¢å¯¹å°‘é‡è®­ç»ƒæ ·æœ¬ï¼ŒKPI ä¹Ÿèƒ½å¿«é€Ÿæ”¶æ•›å¹¶ä¿æŒé«˜æ€§èƒ½ï¼Œé€‚ç”¨äºç°å®ä¸–ç•Œçš„ä½èµ„æºåœºæ™¯ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡å¤–éƒ¨çŸ¥è¯†æº**ï¼šè‹¥åˆå§‹åŒ»å­¦æè¿°å­˜åœ¨é”™è¯¯æˆ–åè§ï¼Œå¯èƒ½å½±å“çŸ¥è¯†å›¾è°±è´¨é‡ã€‚
- **å­å›¾æ£€ç´¢ä¾èµ–çœŸå®æ ‡ç­¾**ï¼šè®­ç»ƒé˜¶æ®µéœ€å·²çŸ¥ç–¾ç—…æ ‡ç­¾ä»¥è·å– 2-hop å­å›¾ï¼Œé™åˆ¶äº†å®Œå…¨æ— ç›‘ç£çš„åº”ç”¨ã€‚
- **å°šæœªé›†æˆå¤šæ¨¡æ€ä¿¡å·**ï¼šå½“å‰ä»…å¤„ç†æ–‡æœ¬å’Œç»“æ„åŒ–å­—æ®µï¼Œæœªè€ƒè™‘å›¾åƒã€è¯­éŸ³ç­‰å…¶ä»–æ‚£è€…ç«¯æ•°æ®ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¤±è´¥æ¡ˆä¾‹åˆ†æ**ï¼šæ·±å…¥ç ”ç©¶ KPI é¢„æµ‹é”™è¯¯çš„æƒ…å†µï¼Œä¼˜åŒ–çŸ¥è¯†å›¾è°±è¦†ç›–èŒƒå›´ã€‚
2. **æ‰©å±•è‡³å¤šæ¨¡æ€è¾“å…¥**ï¼šèåˆè¯­éŸ³ã€æ‰‹å†™ç¬”è®°ã€å®¶åº­ç›‘æµ‹è®¾å¤‡æ•°æ®ç­‰éæ–‡æœ¬ä¿¡å·ã€‚
3. **æ›´å¤§è§„æ¨¡ç–¾ç—…åŸŸè¿ç§»**ï¼šéªŒè¯ KPI åœ¨æ›´å¤šç–¾ç—…ç§ç±»ï¼ˆå¦‚è‚¿ç˜¤ã€ç¥ç»ç³»ç»Ÿç–¾ç—…ï¼‰ä¸­çš„é€‚ç”¨æ€§ã€‚
4. **å®æ—¶äº¤äº’å¼ç³»ç»Ÿå¼€å‘**ï¼šæ„å»ºæ”¯æŒåŠ¨æ€è¿½é—®ã€åé¦ˆä¿®æ­£çš„æ™ºèƒ½åˆ†è¯ŠåŠ©æ‰‹ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> KPI é€šè¿‡èåˆ **Knowledge Graph**ã€**Prototype Learning** å’Œ **LLM-based Explanation**ï¼Œå®ç°äº†é«˜ç²¾åº¦ã€å¼ºå¯è§£é‡Šã€é¢å‘æ‚£è€…ä¾§ä¿¡æ¯çš„ç–¾ç—…é¢„æµ‹æ–°èŒƒå¼ï¼Œåœ¨çœŸå®ä¸–ç•ŒåŒ»ç–— AI åº”ç”¨ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚

</details>

---

### 16. [Towards a Science of Scaling Agent Systems](https://arxiv.org/abs/2512.08296)

**Authors**: Yubin Kim, Ken Gu, Chanwoo Park, Chunjong Park, Samuel Schmidgall, A. Ali Heydari, Yao Yan, Zhihan Zhang, Yuchen Zhuang, Mark Malhotra, Paul Pu Liang, Hae Won Park, Yuzhe Yang, Xuhai Xu, Yilun Du, Shwetak Patel, Tim Althoff, Daniel McDuff, Xin Liu  
**Category**: cs.AI  
**Published**: 2025-12-10  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.08296v1  

#### Abstract
Agents, language model (LM)-based systems that are capable of reasoning, planning, and acting are becoming the dominant paradigm for real-world AI applications. Despite this widespread adoption, the principles that determine their performance remain underexplored, leaving practitioners to rely on he...

---

### 17. [CarBench: A Comprehensive Benchmark for Neural Surrogates on High-Fidelity 3D Car Aerodynamics](https://arxiv.org/abs/2512.07847)

**Authors**: Mohamed Elrefaie, Dule Shu, Matt Klenk, Faez Ahmed  
**Category**: cs.LG  
**Published**: 2025-12-10  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.07847v1  

#### Abstract
Benchmarking has been the cornerstone of progress in computer vision, natural language processing, and the broader deep learning domain, driving algorithmic innovation through standardized datasets and reproducible evaluation protocols. The growing availability of large-scale Computational Fluid Dyn...

---

### 18. [RaX-Crash: A Resource Efficient and Explainable Small Model Pipeline with an Application to City Scale Injury Severity Prediction](https://arxiv.org/abs/2512.07848)

**Authors**: Di Zhu, Chen Xie, Ziwei Wang, Haoyun Zhang  
**Category**: cs.LG  
**Published**: 2025-12-10  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.07848v1  

#### Abstract
New York City reports over one hundred thousand motor vehicle collisions each year, creating substantial injury and public health burden. We present RaX-Crash, a resource efficient and explainable small model pipeline for structured injury severity prediction on the official NYC Motor Vehicle Collis...

---

### 19. [Neural Ordinary Differential Equations for Simulating Metabolic Pathway Dynamics from Time-Series Multiomics Data](https://arxiv.org/abs/2512.08732)

**Authors**: Udesh Habaraduwa, Andrei Lixandru  
**Category**: cs.LG  
**Published**: 2025-12-10  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.08732v1  

#### Abstract
The advancement of human healthspan and bioengineering relies heavily on predicting the behavior of complex biological systems. While high-throughput multiomics data is becoming increasingly abundant, converting this data into actionable predictive models remains a bottleneck. High-capacity, datadri...

---

### 20. [Predicting California Bearing Ratio with Ensemble and Neural Network Models: A Case Study from T\"urkiye](https://arxiv.org/abs/2512.08340)

**Authors**: Abdullah Hulusi K\"ok\c{c}am, U\u{g}ur Da\u{g}deviren, Talas Fikret Kurnaz, Alparslan Serhat Demir, Caner Erden  
**Category**: cs.AI  
**Published**: 2025-12-10  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.08340v1  

#### Abstract
The California Bearing Ratio (CBR) is a key geotechnical indicator used to assess the load-bearing capacity of subgrade soils, especially in transportation infrastructure and foundation design. Traditional CBR determination relies on laboratory penetration tests. Despite their accuracy, these tests ...

---

### 21. [The SMART+ Framework for AI Systems](https://arxiv.org/abs/2512.08592)

**Authors**: Laxmiraju Kandikatla, Branislav Radeljic  
**Category**: cs.AI  
**Published**: 2025-12-10  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.08592v1  

#### Abstract
Artificial Intelligence (AI) systems are now an integral part of multiple industries. In clinical research, AI supports automated adverse event detection in clinical trials, patient eligibility screening for protocol enrollment, and data quality validation. Beyond healthcare, AI is transforming fina...

---

### 22. [Softly Symbolifying Kolmogorov-Arnold Networks](https://arxiv.org/abs/2512.07875)

**Authors**: James Bagrow, Josh Bongard  
**Category**: cs.LG  
**Published**: 2025-12-10  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.07875v1  

#### Abstract
Kolmogorov-Arnold Networks (KANs) offer a promising path toward interpretable machine learning: their learnable activations can be studied individually, while collectively fitting complex data accurately. In practice, however, trained activations often lack symbolic fidelity, learning pathological d...

---

### 23. [Unveiling Latent Knowledge in Chemistry Language Models through Sparse Autoencoders](https://arxiv.org/abs/2512.08077)

**Authors**: Jaron Cohen, Alexander G. Hasson, Sara Tanovic  
**Category**: cs.LG  
**Published**: 2025-12-10  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.08077v1  

#### Abstract
Since the advent of machine learning, interpretability has remained a persistent challenge, becoming increasingly urgent as generative models support high-stakes applications in drug and material discovery. Recent advances in large language model (LLM) architectures have yielded chemistry language m...

---

### 24. [Robust Agents in Open-Ended Worlds](https://arxiv.org/abs/2512.08139)

**Authors**: Mikayel Samvelyan  
**Category**: cs.LG  
**Published**: 2025-12-10  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.08139v1  

#### Abstract
The growing prevalence of artificial intelligence (AI) in various applications underscores the need for agents that can successfully navigate and adapt to an ever-changing, open-ended world. A key challenge is ensuring these AI agents are robust, excelling not only in familiar settings observed duri...

---

### 25. [SOFA-FL: Self-Organizing Hierarchical Federated Learning with Adaptive Clustered Data Sharing](https://arxiv.org/abs/2512.08267)

**Authors**: Yi Ni, Xinkun Wang, Han Zhang  
**Category**: cs.LG  
**Published**: 2025-12-10  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.08267v1  

#### Abstract
Federated Learning (FL) faces significant challenges in evolving environments, particularly regarding data heterogeneity and the rigidity of fixed network topologies. To address these issues, this paper proposes \textbf{SOFA-FL} (Self-Organizing Hierarchical Federated Learning with Adaptive Clustere...

---

### 26. [Transformers for Multimodal Brain State Decoding: Integrating Functional Magnetic Resonance Imaging Data and Medical Metadata](https://arxiv.org/abs/2512.08462)

**Authors**: Danial Jafarzadeh Jazi, Maryam Hajiesmaeili  
**Category**: cs.LG  
**Published**: 2025-12-10  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.08462v1  

#### Abstract
Decoding brain states from functional magnetic resonance imaging (fMRI) data is vital for advancing neuroscience and clinical applications. While traditional machine learning and deep learning approaches have made strides in leveraging the high-dimensional and complex nature of fMRI data, they often...

---

### 27. [Impact of Data-Oriented and Object-Oriented Design on Performance and Cache Utilization with Artificial Intelligence Algorithms in Multi-Threaded CPUs](https://arxiv.org/abs/2512.07841)

**Authors**: Gabriel M. Arantes, Richard F. Pinto, Bruno L. Dalmazo, Eduardo N. Borges, Giancarlo Lucca, Viviane L. D. de Mattos, Fabian C. Cardoso, Rafael A. Berri  
**Category**: cs.AI  
**Published**: 2025-12-10  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.07841v1  

#### Abstract
The growing performance gap between multi-core CPUs and main memory necessitates hardware-aware software design paradigms. This study provides a comprehensive performance analysis of Data Oriented Design (DOD) versus the traditional Object-Oriented Design (OOD), focusing on cache utilization and eff...

---

### 28. [The High Cost of Incivility: Quantifying Interaction Inefficiency via Multi-Agent Monte Carlo Simulations](https://arxiv.org/abs/2512.08345)

**Authors**: Benedikt Mangold  
**Category**: cs.AI  
**Published**: 2025-12-10  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.08345v1  

#### Abstract
Workplace toxicity is widely recognized as detrimental to organizational culture, yet quantifying its direct impact on operational efficiency remains methodologically challenging due to the ethical and practical difficulties of reproducing conflict in human subjects. This study leverages Large Langu...

---

### 29. [Reflecting with Two Voices: A Co-Adaptive Dual-Strategy Framework for LLM-Based Agent Decision Making](https://arxiv.org/abs/2512.08366)

**Authors**: Wentao Zhang, Qunbo Wang, Tao Zhang, Junsheng Wu, Hongping Gan, Yang Liu, Ling Dai, Shizhuang Deng, Shuntong Sun  
**Category**: cs.AI  
**Published**: 2025-12-10  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.08366v1  

#### Abstract
Large language model (LLM) agents often rely on external demonstrations or retrieval-augmented planning, leading to brittleness, poor generalization, and high computational overhead. Inspired by human problem-solving, we propose DuSAR (Dual-Strategy Agent with Reflecting) - a demonstration-free fram...

---

### 30. [Performance Comparison of Aerial RIS and STAR-RIS in 3D Wireless Environments](https://arxiv.org/abs/2512.08755)

**Authors**: Dongdong Yang, Bin Li, Jiguang He  
**Category**: cs.AI  
**Published**: 2025-12-10  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.08755v1  

#### Abstract
Reconfigurable intelligent surface (RIS) and simultaneously transmitting and reflecting RIS (STAR-RIS) have emerged as key enablers for enhancing wireless coverage and capacity in next-generation networks. When mounted on unmanned aerial vehicles (UAVs), they benefit from flexible deployment and imp...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
