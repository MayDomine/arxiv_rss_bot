# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-29 06:15:08 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [StreamFusion: Scalable Sequence Parallelism for Distributed Inference of Diffusion Transformers on GPUs](https://arxiv.org/abs/2601.20273)

**Authors**: Jiacheng Yang, Jun Wu, Yaoyao Ding, Zhiying Xu, Yida Wang, Gennady Pekhimenko  
**Category**: cs.DC  
**Published**: 2026-01-29  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2601.20273v1  

#### Abstract
Diffusion Transformers (DiTs) have gained increasing adoption in high-quality image and video generation. As demand for higher-resolution images and longer videos increases, single-GPU inference becomes inefficient due to increased latency and large activation sizes. Current frameworks employ sequen...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡ã€ŠStreamFusion: Scalable Sequence Parallelism for Distributed Inference of Diffusion Transformers on GPUsã€‹æ€»ç»“**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰åœ¨å¤šGPUä¸Šè¿›è¡Œ **Diffusion Transformers (DiTs)** æ¨ç†æ—¶ï¼Œä¸»æµçš„ **Sequence Parallelism (SP)** æŠ€æœ¯ï¼ˆå¦‚ Ulysses Attention å’Œ Ring Attentionï¼‰å­˜åœ¨ä»¥ä¸‹ä¸‰å¤§ç“¶é¢ˆï¼š

1. **é€šä¿¡æ¨¡å¼æœªé€‚é…ç°ä»£GPUç½‘ç»œæ‹“æ‰‘**ï¼šæœªå……åˆ†åˆ©ç”¨æœºå†…ï¼ˆintra-machineï¼‰é«˜å¸¦å®½ï¼ˆå¦‚NVSwitchï¼‰å’Œæœºé—´ï¼ˆinter-machineï¼‰ä½å¸¦å®½ç½‘ç»œçš„å·®å¼‚ã€‚
2. **All-to-Allæ“ä½œæ— æ³•ä¸è®¡ç®—é‡å **ï¼šUlysses Attention ä¸­çš„ All-to-All æ“ä½œæ˜¯åŸå­æ€§çš„ï¼Œå¯¼è‡´é€šä¿¡æ— æ³•ä¸æ³¨æ„åŠ›è®¡ç®—å¹¶è¡Œï¼Œå½¢æˆæ€§èƒ½ç“¶é¢ˆã€‚
3. **ä¸¤æ–¹é€šä¿¡åº“ï¼ˆTwo-Sided Communicationï¼‰å¼€é”€å¤§**ï¼šä¾èµ– NCCL ç­‰åº“å¯¼è‡´å‘é€ç«¯å’Œæ¥æ”¶ç«¯å¿…é¡»ä¸¥æ ¼åŒæ­¥ï¼Œå¼•å…¥é¢å¤–çš„åŒæ­¥å’Œè®¡ç®—å¼€é”€ã€‚

è¿™äº›é—®é¢˜ä½¿å¾—ç°æœ‰ç³»ç»Ÿåœ¨æ‰©å±•åˆ°å¤šå°GPUæœºå™¨æ—¶ï¼Œæ¨ç†å»¶è¿Ÿæ˜¾è‘—å¢åŠ ï¼Œç³»ç»Ÿå˜ä¸º **communication-bound**ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹**

StreamFusion æå‡ºäº†ä¸€å¥— **æ‹“æ‰‘æ„ŸçŸ¥ã€é€šä¿¡å¯é‡å ã€è½»é‡åŒæ­¥** çš„åˆ†å¸ƒå¼æ¨ç†å¼•æ“ï¼ŒåŒ…å«ä¸‰å¤§æ ¸å¿ƒæŠ€æœ¯ï¼š

#### **(1) æ‹“æ‰‘æ„ŸçŸ¥çš„åºåˆ—å¹¶è¡Œï¼ˆTopology-Aware Sequence Parallelismï¼‰**
- **æ–°ç­–ç•¥**ï¼šå°† **Ulysses Attention ç”¨äºæœºé—´é€šä¿¡**ï¼Œ**Ring Attention ç”¨äºæœºå†…é€šä¿¡**ã€‚
- **ä¼˜åŠ¿**ï¼š
  - Ulysses çš„é€šä¿¡é‡éšGPUæ•°é‡å¢åŠ è€Œå‡å°‘ï¼Œé€‚åˆå¸¦å®½è¾ƒä½çš„æœºé—´ç½‘ç»œã€‚
  - Ring Attention è™½é€šä¿¡é‡å¤§ï¼Œä½†é€‚åˆé«˜å¸¦å®½ã€ä½å»¶è¿Ÿçš„æœºå†…ç½‘ç»œï¼ˆå¦‚NVSwitchï¼‰ã€‚
  - æ˜¾è‘—é™ä½æ€»ä½“æœºé—´é€šä¿¡é‡ï¼Œä¼˜äº USPï¼ˆå…¶åå‘è®¾è®¡ï¼‰ã€‚

#### **(2) Torus Attentionï¼šé€šä¿¡ä¸è®¡ç®—é‡å çš„æ–°å‹æ³¨æ„åŠ›æœºåˆ¶**
- **æ ¸å¿ƒæ€æƒ³**ï¼šå°† All-to-All æ“ä½œæ‹†åˆ†ä¸ºå¤šä¸ªå—ï¼ˆchunkï¼‰ï¼Œåˆ©ç”¨è¾“å…¥ä¸­â€œé™æ­¢å…ƒç´ â€ï¼ˆstationary elementsï¼‰æå‰å¼€å§‹è®¡ç®—ã€‚
- **å®ç°æ–¹å¼**ï¼š
  - å°† Q/K/V å¼ é‡åˆ†å—ã€‚
  - åœ¨æ‰§è¡Œ All-to-All é€šä¿¡çš„åŒæ—¶ï¼Œå¯¹æœ¬åœ°å·²å°±ç»ªçš„å—è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚
  - å®ç° **é€šä¿¡ä¸è®¡ç®—çš„æµæ°´çº¿é‡å **ï¼Œéšè—é€šä¿¡å»¶è¿Ÿã€‚
- **ä¼˜åŠ¿**ï¼šè§£å†³äº† Ulysses Attention ä¸­ All-to-All æ— æ³•é‡å çš„é—®é¢˜ã€‚

#### **(3) å•è¾¹é€šä¿¡å®ç°ï¼ˆOne-Sided Communication Implementationï¼‰**
- **æŠ€æœ¯åŸºç¡€**ï¼šé‡‡ç”¨ **NVSHMEM** æ›¿ä»£ NCCLã€‚
- **ä¼˜åŠ¿**ï¼š
  - æ¶ˆé™¤å‘é€-æ¥æ”¶ç«¯çš„éšå¼åŒæ­¥ï¼Œç”±ç¨‹åºå‘˜æ˜¾å¼æ§åˆ¶åŒæ­¥ç‚¹ã€‚
  - å‡å°‘ CUDA kernel å¼€é”€ï¼Œé¿å…å ç”¨ SM èµ„æºã€‚
  - ä»…éœ€ **ä¸¤æ¬¡å…¨å±€åŒæ­¥**ï¼ˆå±‚å¼€å§‹å’Œç»“æŸï¼‰ï¼Œæå¤§é™ä½åŒæ­¥å¼€é”€ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | é€šä¿¡æ‹“æ‰‘ä¼˜åŒ– | é€šä¿¡-è®¡ç®—é‡å  | åŒæ­¥å¼€é”€ |
|------|----------------|----------------|-----------|
| **USP** | âŒï¼ˆæ¬¡ä¼˜ç»„åˆï¼‰ | âŒ | âŒï¼ˆNCCLï¼‰ |
| **StreamFusion** | âœ…ï¼ˆUlyssesè·¨æœº + Ringæœºå†…ï¼‰ | âœ…ï¼ˆTorus Attentionï¼‰ | âœ…ï¼ˆNVSHMEM + æå°‘åŒæ­¥ï¼‰ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ¨¡å‹ä¸å·¥ä½œè´Ÿè½½**
- **å›¾åƒç”Ÿæˆ**ï¼š
  - **Flux** (12B å‚æ•°)ï¼Œç”Ÿæˆåˆ†è¾¨ç‡ï¼š`3072Ã—3072` å’Œ `4096Ã—4096`ã€‚
- **è§†é¢‘ç”Ÿæˆ**ï¼š
  - **CogVideoX** (5B å‚æ•°)ï¼Œç”Ÿæˆæ—¶é•¿ï¼š`20s` å’Œ `40s`ï¼Œåˆ†è¾¨ç‡ `768Ã—1360`ã€‚
- å…±äº«å‚æ•°ï¼š24ä¸ªæ³¨æ„åŠ›å¤´ï¼ŒFlux å¤´ç»´åº¦ `D=128`ï¼ŒCogVideoX `D=64`ã€‚

### **ç¡¬ä»¶ä¸è½¯ä»¶ç¯å¢ƒ**
- **ç¡¬ä»¶**ï¼š4å° AWS `p4de.24xlarge` å®ä¾‹ï¼Œæ¯å°å« 8Ã—NVIDIA A100 GPU (40GiB)ï¼Œé€šè¿‡ **NVSwitch** è¿æ¥ã€‚
- **ç½‘ç»œ**ï¼šå¯ç”¨ **Elastic Fabric Adapter (EFA)**ï¼Œæä¾›é«˜è¾¾ 400 Gbps çš„æœºé—´å¸¦å®½ã€‚
- **è½¯ä»¶æ ˆ**ï¼š
  - CUDA 12.8, PyTorch 2.8, NCCL 2.27.3, NVSHMEM 3.4.5ã€‚

### **è¯„ä¼°æŒ‡æ ‡**
- **ç«¯åˆ°ç«¯æ¨ç†å»¶è¿Ÿ**ï¼ˆEnd-to-End Inference Latencyï¼‰ï¼šå•ä¸ªé‡‡æ ·æ­¥éª¤çš„è€—æ—¶ã€‚
- **å½’ä¸€åŒ–å»¶è¿Ÿ**ï¼ˆNormalized Latencyï¼‰ï¼šç›¸å¯¹äºåŸºçº¿çš„åŠ é€Ÿæ¯”ã€‚
- **é€šä¿¡/è®¡ç®—å æ¯”åˆ†æ**ï¼šé€šè¿‡æ€§èƒ½å‰–æç†è§£ç“¶é¢ˆã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **USP** (Unified Sequence Parallelism)ï¼šå½“å‰æœ€ä¼˜æ–¹æ³•ï¼Œä½œä¸ºä¸»è¦å¯¹æ¯”åŸºçº¿ã€‚
- **TAS** (Topology-Aware Scheduling)ï¼šStreamFusion çš„å­é›†ï¼Œä»…åŒ…å«æ‹“æ‰‘æ„ŸçŸ¥è°ƒåº¦ï¼Œç”¨äºæ¶ˆèåˆ†æã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- **å¹³å‡åŠ é€Ÿæ¯”**ï¼šStreamFusion ç›¸æ¯” USP **å¹³å‡æå‡ 1.35Ã—**ï¼Œ**æœ€é«˜è¾¾ 1.77Ã—**ã€‚
- **æœ€å¤§åŠ é€Ÿåœºæ™¯**ï¼šåœ¨ `Flux 3072Ã—3072` ä½¿ç”¨ 4 å°æœºå™¨æ—¶è¾¾åˆ° **1.77Ã—** åŠ é€Ÿã€‚

### **ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ**
- **å›¾7ï¼ˆæœ€ä¼˜é…ç½®ï¼‰**ï¼š
  - å½“ä½¿ç”¨ **2å°æœºå™¨** æ—¶ï¼ŒTAS æ€§èƒ½ç•¥ä½äº USPï¼ˆå› é€šä¿¡æœªé‡å ï¼‰ã€‚
  - å½“ä½¿ç”¨ **3â€“4å°æœºå™¨** æ—¶ï¼ŒTAS å¹³å‡å¿« **1.27Ã—**ï¼ˆæœ€é«˜ 1.64Ã—ï¼‰ã€‚
  - StreamFusion åœ¨æ­¤åŸºç¡€ä¸Šè¿›ä¸€æ­¥æå‡è‡³ **1.35Ã—**ï¼ˆæœ€é«˜ 1.77Ã—ï¼‰ï¼Œè¯æ˜ Torus + One-Sided é€šä¿¡çš„æœ‰æ•ˆæ€§ã€‚
- **å›¾8ï¼ˆå¤šç§é…ç½®ï¼‰**ï¼š
  - StreamFusion åœ¨æ‰€æœ‰é…ç½®ä¸‹å‡ä¼˜äº USPï¼Œ**å¹³å‡åŠ é€Ÿ 1.61Ã—**ï¼Œ**æœ€é«˜è¾¾ 3.11Ã—**ã€‚
  - éªŒè¯äº†å…¶åœ¨ä¸åŒå¹¶è¡Œåº¦ä¸‹çš„é²æ£’æ€§å’Œå¯æ‰©å±•æ€§ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**
- **å›¾10 å±•ç¤ºäº†é€æ­¥æ·»åŠ ç»„ä»¶çš„æ•ˆæœ**ï¼š
  1. **ä»…æ‹“æ‰‘æ„ŸçŸ¥ï¼ˆTASï¼‰**ï¼šå¹³å‡æé€Ÿ 1.27Ã—ã€‚
  2. **+ Torus Attention**ï¼š
     - å›¾åƒä»»åŠ¡ï¼šæå‡æœ‰é™ï¼ˆå› åºåˆ—çŸ­ï¼Œé€šä¿¡éç“¶é¢ˆï¼‰ã€‚
     - è§†é¢‘ä»»åŠ¡ï¼šæ˜¾è‘—æå‡ï¼ˆé•¿åºåˆ—ä¸‹é€šä¿¡æˆä¸ºç“¶é¢ˆï¼‰ã€‚
  3. **+ One-Sided Communication**ï¼š
     - å›¾åƒä»»åŠ¡ï¼šæ˜¾è‘—æå‡ï¼ˆæ›´å¥½é‡å ï¼‰ã€‚
     - è§†é¢‘ä»»åŠ¡ï¼šè¾¹é™…æå‡ï¼ˆTorus å·²åŸºæœ¬éšè—é€šä¿¡ï¼‰ã€‚
- **ç»“è®º**ï¼šä¸‰ä¸ªç»„ä»¶ååŒä½œç”¨ï¼Œæ‰èƒ½åœ¨å„ç±»è´Ÿè½½ä¸‹è¾¾åˆ°æœ€ä¼˜æ€§èƒ½ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **é€šä¿¡æ‹“æ‰‘æ„ŸçŸ¥è‡³å…³é‡è¦**ï¼šå°† Ulysses ç”¨äºæœºé—´ã€Ring ç”¨äºæœºå†…ï¼Œèƒ½æ›´é«˜æ•ˆåˆ©ç”¨ç°ä»£GPUé›†ç¾¤çš„å¼‚æ„ç½‘ç»œã€‚
2. **All-to-All å¯è¢«åˆ†è§£ä»¥å®ç°é‡å **ï¼šTorus Attention åˆ©ç”¨â€œé™æ­¢å…ƒç´ â€æ‰“ç ´åŸå­æ€§å‡è®¾ï¼Œé¦–æ¬¡å®ç° Ulysses ç±» All-to-All ä¸è®¡ç®—çš„é‡å ã€‚
3. **å•è¾¹é€šä¿¡æ˜¾è‘—é™ä½å¼€é”€**ï¼šNVSHMEM æ¯” NCCL æ›´çµæ´»ï¼Œé…åˆç²¾ç»†è°ƒåº¦å¯å¤§å¹…å‡å°‘åŒæ­¥å’Œ kernel å¼€é”€ã€‚
4. **ä¸‰è€…ç¼ºä¸€ä¸å¯**ï¼šæ‹“æ‰‘è°ƒåº¦é™ä½é€šä¿¡é‡ï¼ŒTorus éšè—é€šä¿¡å»¶è¿Ÿï¼ŒOne-Sided é™ä½åŒæ­¥æˆæœ¬ï¼Œå…±åŒæ„æˆå®Œæ•´ä¼˜åŒ–é—­ç¯ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–ç‰¹å®šç¡¬ä»¶æ”¯æŒ**ï¼šéœ€è¦æ”¯æŒ NVSHMEM å’Œ EFA/RDMA çš„ GPU é›†ç¾¤ã€‚
- **å®ç°å¤æ‚åº¦é«˜**ï¼šéœ€å®šåˆ¶ CUDA kernel å’Œé€šä¿¡è°ƒåº¦é€»è¾‘ï¼Œå¯¹å¼€å‘è€…è¦æ±‚é«˜ã€‚
- **ä»…é€‚ç”¨äºé€šç”¨ Attention æ¶æ„**ï¼šä¸ç›´æ¥æ”¯æŒ MoE æˆ–ç‰¹æ®Šæ—¶ç©ºæ³¨æ„åŠ›ç»“æ„ï¼ˆå°½ç®¡ä½œè€…æåˆ° ScaleFusion æ˜¯å…¶ç‰¹ä¾‹ï¼‰ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- **é›†æˆåˆ°ç¼–è¯‘å™¨æ¡†æ¶**ï¼šå¦‚ Triton-Distributed æˆ– Mercuryï¼Œå®ç°è‡ªåŠ¨åŒ–çš„é€šä¿¡-è®¡ç®—é‡å ã€‚
- **æ”¯æŒæ›´å¤šå¹¶è¡ŒèŒƒå¼**ï¼šç»“åˆ Pipeline Parallelism æˆ– Tensor Parallelismï¼Œæ„å»ºæ··åˆå¹¶è¡Œæ–¹æ¡ˆã€‚
- **æ‰©å±•åˆ°è®­ç»ƒåœºæ™¯**ï¼šå½“å‰èšç„¦æ¨ç†ï¼Œæœªæ¥å¯æ¢ç´¢åœ¨è®­ç»ƒä¸­çš„åº”ç”¨ã€‚
- **è·¨å¹³å°ç§»æ¤**ï¼šé€‚é… AMD ROCm æˆ–å…¶ä»–é€šä¿¡åº“ï¼ˆå¦‚ UCXï¼‰ã€‚

---

> **æ€»ç»“**ï¼šStreamFusion é€šè¿‡ **æ‹“æ‰‘æ„ŸçŸ¥è°ƒåº¦ + Torus Attention + å•è¾¹é€šä¿¡** ä¸‰ä½ä¸€ä½“çš„è®¾è®¡ï¼Œåœ¨å¤šGPU DiT æ¨ç†ä¸­å®ç°äº† **å¹³å‡ 1.35Ã—ã€æœ€é«˜ 1.77Ã—** çš„ç«¯åˆ°ç«¯åŠ é€Ÿï¼Œæ˜¯å½“å‰æœ€é«˜æ•ˆçš„åˆ†å¸ƒå¼ DiT æ¨ç†å¼•æ“ä¹‹ä¸€ï¼Œä¸ºå¤§è§„æ¨¡ç”Ÿæˆæ¨¡å‹çš„éƒ¨ç½²æä¾›äº†é‡è¦å®è·µè·¯å¾„ã€‚

</details>

---

### 2. [Quantization-Aware Distillation for NVFP4 Inference Accuracy Recovery](https://arxiv.org/abs/2601.20088)

**Authors**: Meng Xin, Sweta Priyadarshi, Jingyu Xin, Bilal Kartal, Aditya Vavre, Asma Kuriparambil Thekkumpate, Zijia Chen, Ameya Sunil Mahabaleshwarkar, Ido Shahaf, Akhiad Bercovich, Kinjal Patel, Suguna Varshini Velury, Chenjie Luo, Zhiyu Cheng, Jenny Chen, Chen-Han Yu, Wei Ping, Oleg Rybakov, Nima Tajbakhsh, Oluwatobi Olabiyi, Dusan Stosic, Di Wu, Song Han, Eric Chung, Sharath Turuvekere Sreenivas, Bryan Catanzaro, Yoshi Suhara, Tijmen Blankevoort, Huizi Mao  
**Category**: cs.LG  
**Published**: 2026-01-29  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.20088v1  

#### Abstract
This technical report presents quantization-aware distillation (QAD) and our best practices for recovering accuracy of NVFP4-quantized large language models (LLMs) and vision-language models (VLMs). QAD distills a full-precision teacher model into a quantized student model using a KL divergence loss...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Quantization-Aware Distillation for NVFP4 Inference Accuracy Recovery*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜

ç°ä»£å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨æ¨ç†æ—¶é¢ä¸´é«˜è®¡ç®—æˆæœ¬ã€å†…å­˜å ç”¨å’Œèƒ½è€—çš„é—®é¢˜ã€‚ä¸ºç¼“è§£æ­¤é—®é¢˜ï¼Œ**NVFP4**ï¼ˆä¸€ç§4-bitæµ®ç‚¹æ ¼å¼ï¼‰è¢«æå‡ºä»¥æå‡ç®—åŠ›æ•ˆç‡å¹¶é™ä½å†…å­˜å¼€é”€ã€‚ç„¶è€Œï¼Œå¯¹å°å‹æˆ–ç»è¿‡å¤æ‚åè®­ç»ƒæµç¨‹ï¼ˆå¦‚ SFT + RLï¼‰çš„æ¨¡å‹è¿›è¡Œ **Post-Training Quantization (PTQ)** åï¼Œç²¾åº¦ä¸‹é™æ˜¾è‘—ã€‚

ä¼ ç»Ÿ **Quantization-Aware Training (QAT)** è™½å¯ç”¨äºæ¢å¤ç²¾åº¦ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­å­˜åœ¨ä¸¤å¤§æŒ‘æˆ˜ï¼š
- å¤æ‚çš„å¤šé˜¶æ®µè®­ç»ƒæµæ°´çº¿ï¼ˆå¦‚ SFTã€RLã€æ¨¡å‹èåˆï¼‰éš¾ä»¥å¤ç°ï¼›
- åŸå§‹è®­ç»ƒæ•°æ®ä¸å¯å¾—æˆ–è´¨é‡å·®ã€‚

è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³ï¼š**å¦‚ä½•åœ¨ä¸ä¾èµ–å®Œæ•´åŸå§‹è®­ç»ƒæµç¨‹å’Œé«˜è´¨é‡å…¨é‡æ•°æ®çš„å‰æä¸‹ï¼Œæœ‰æ•ˆæ¢å¤ NVFP4 é‡åŒ–æ¨¡å‹çš„æ¨ç†ç²¾åº¦ï¼Ÿ**

---

### ğŸš€ æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

æå‡ºäº† **Quantization-Aware Distillation (QAD)** â€”â€” ä¸€ç§åŸºäºçŸ¥è¯†è’¸é¦çš„é‡åŒ–æ„ŸçŸ¥å¾®è°ƒæ–¹æ³•ã€‚

- **æ ¸å¿ƒæ€æƒ³**ï¼šä½¿ç”¨åŸå§‹çš„ BF16 é«˜ç²¾åº¦æ¨¡å‹ä½œä¸º **Teacher**ï¼Œå°†ä¸€ä¸ªå·²é‡åŒ–ä¸º NVFP4 çš„æ¨¡å‹ä½œä¸º **Student**ï¼Œé€šè¿‡æœ€å°åŒ–ä¸¤è€…è¾“å‡ºåˆ†å¸ƒä¹‹é—´çš„ **KL Divergence** æ¥å¯¹ Student è¿›è¡Œå¾®è°ƒã€‚
- ä¸ä¾èµ–ä»»åŠ¡ç‰¹å®šæŸå¤±ï¼ˆå¦‚ cross-entropyï¼‰ï¼Œè€Œæ˜¯ç›´æ¥å¯¹é½è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒã€‚

> å…¬å¼å®šä¹‰ï¼š
> $$
> \mathcal{L}_{\text{QAD}} = D_{\text{KL}}(p_{\text{teacher}} \| p_{\text{student}})
> $$

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| å¯¹æ¯”ç»´åº¦ | QAT | QADï¼ˆæœ¬æ–‡æ–¹æ³•ï¼‰ |
|--------|-----|----------------|
| **è®­ç»ƒç›®æ ‡** | ä½¿ç”¨åŸå§‹ä»»åŠ¡æŸå¤±ï¼ˆå¦‚ next-token predictionï¼‰ | ä½¿ç”¨ KL æ•£åº¦åŒ¹é… Teacher è¾“å‡ºåˆ†å¸ƒ |
| **æ•°æ®éœ€æ±‚** | éœ€è¦é«˜è´¨é‡ã€è¦†ç›–å…¨é¢çš„è®­ç»ƒæ•°æ® | å¯ç”¨éƒ¨åˆ†é¢†åŸŸæ•°æ®ç”šè‡³åˆæˆ/éšæœºæ•°æ® |
| **é€‚ç”¨åœºæ™¯** | å•ä¸€ SFT é˜¶æ®µè¾ƒç¨³å®šï¼›RL æ¨¡å‹æ˜“ç ´åèƒ½åŠ› | åœ¨ RL-heavy æ¨¡å‹ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œé¿å…â€œé‡å­¦â€å¯¼è‡´çš„èƒ½åŠ›é€€åŒ– |
| **å·¥ç¨‹å¤æ‚åº¦** | éœ€å¤åˆ¶æ•´ä¸ªå¤šé˜¶æ®µè®­ç»ƒæµç¨‹ï¼ˆå°¤å…¶ RLï¼‰ | ä»…éœ€ä¸€æ¬¡ç®€å•è’¸é¦è®­ç»ƒï¼Œæ— éœ€é‡æ„ RL æµç¨‹ |
| **è¾“å‡ºä¸€è‡´æ€§** | å¯èƒ½æ”¹å˜è¾“å‡ºåˆ†å¸ƒï¼ˆå³ä½¿ loss æ¥è¿‘ï¼‰ | å‡ ä¹å®Œå…¨ä¿ç•™ BF16 Teacher çš„è¾“å‡ºè¡Œä¸º |

> âœ… **å…³é”®ä¼˜åŠ¿æ€»ç»“**ï¼š
> - æ›´å¥½åœ°ä¿æŒäº†åŸå§‹æ¨¡å‹çš„è¡Œä¸ºä¸€è‡´æ€§ï¼›
> - å¯¹æ•°æ®è´¨é‡å’Œè¦†ç›–ç‡é²æ£’æ€§å¼ºï¼›
> - ç‰¹åˆ«é€‚ç”¨äº RL è®­ç»ƒåçš„æ¨¡å‹ï¼Œè€Œ QAT ä¼šä¸¥é‡æŸå®³å…¶æ€§èƒ½ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›†

#### æ¨¡å‹åˆ—è¡¨ï¼ˆæ¶µç›– LLM å’Œ VLMï¼‰
- **Llama Nemotron Super V1**ï¼ˆ49Bï¼ŒSFT-heavyï¼‰
- **Nemotron Nano 9B / 12B V2**ï¼ˆæ··åˆ Mamba-Transformer æ¶æ„ï¼‰
- **Nemotron 3 Nano 30B-A3B**ï¼ˆMoE + Mambaï¼ŒRL-heavyï¼‰
- **AceReason Nemotron 1.1 7B**ï¼ˆä¸“æ”»æ•°å­¦ä¸ä»£ç ï¼Œç» RL è®­ç»ƒï¼‰

#### æ•°æ®æ¥æº
- å†·å¯åŠ¨ SFT æ•°æ®ï¼ˆcold-start SFT dataï¼‰
- RL prompt ä¸‹ç”± BF16 æ¨¡å‹ç”Ÿæˆçš„æ•°æ®
- ä»…æ­£ç¡®è§£çš„ç”Ÿæˆæ ·æœ¬
- ä» `<BOS>` token å¼€å§‹ç”Ÿæˆçš„æ•°æ®
- å®Œå…¨éšæœº token åºåˆ—ï¼ˆç”¨äºæµ‹è¯•é²æ£’æ€§ï¼‰

> âš ï¸ æ³¨æ„ï¼šQAD æ‰€éœ€æ•°æ®è¿œå°‘äºåŸå§‹è®­ç»ƒï¼ˆä¾‹å¦‚ ~0.3â€“2.5B tokensï¼‰

---

### âš™ï¸ å®éªŒè®¾ç½®

| é¡¹ç›® | è®¾ç½®è¯´æ˜ |
|------|----------|
| **é‡åŒ–é…ç½®** | æ‰€æœ‰ GEMM å±‚é‡åŒ–ä¸º NVFP4ï¼›æ³¨æ„åŠ›å±‚æˆ–å‰/åå‡ å±‚ä¿ç•™ BF16ï¼›KV Cache ä½¿ç”¨ FP8 |
| **ä¼˜åŒ–å™¨å‚æ•°** | å­¦ä¹ ç‡ä¿å®ˆè®¾ç½®ï¼š`1e-6`ï¼ˆSFT-heavyï¼‰åˆ° `1e-5`ï¼ˆRL-heavyï¼‰ï¼›batch size å’Œ seq length ä¸åŸè®­ç»ƒä¸€è‡´ |
| **æ¸©åº¦è®¾ç½®** | Teacher ä¸ Student å‡ä½¿ç”¨ $ T=1 $ï¼Œç¡®ä¿ç²¾ç¡®åŒ¹é…åˆ†å¸ƒ |
| **è¯„ä¼°æ–¹å¼** | æŠ¥å‘Šå¤šä¸ªé‡‡æ ·è¿è¡Œä¸‹çš„å¹³å‡æ€§èƒ½ï¼ˆå¦‚ 48 runs for AIMEï¼‰ï¼›ä½¿ç”¨ $ T=0.6 $ æˆ– $ T=1.0 $, top-p=0.95/1.0 é‡‡æ · |

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| ç±»å‹ | æŒ‡æ ‡ |
|------|------|
| **é€šç”¨æ¨ç†** | MATH500, AIME24/AIME25ï¼ˆæ•°å­¦ç«èµ›é¢˜ï¼‰ |
| **ä¸“ä¸šçŸ¥è¯†** | GPQA-Dï¼ˆç ”ç©¶ç”Ÿçº§é—®ç­”ï¼‰ |
| **ç¼–ç¨‹èƒ½åŠ›** | LiveCodeBench, SciCode |
| **æŒ‡ä»¤éµå¾ª** | IFEval |
| **è§†è§‰ç†è§£ï¼ˆVLMï¼‰** | AI2D, ChartQA, DocVQA, InfoVQA, OCRBench, TextVQA |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | æè¿° |
|------|------|
| **BF16 Baseline** | åŸå§‹é«˜ç²¾åº¦æ¨¡å‹ï¼Œæ€§èƒ½ä¸Šé™å‚è€ƒ |
| **NVFP4 PTQ** | ä»…æ ¡å‡†æ— è®­ç»ƒï¼Œä»£è¡¨æœ€ç®€é‡åŒ–æ–¹æ¡ˆ |
| **NVFP4 QAT** | æ ‡å‡†é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼Œä½¿ç”¨ä»»åŠ¡ loss å¾®è°ƒ |
| **NVFP4 QAD** | æœ¬æ–‡æ–¹æ³•ï¼Œä½¿ç”¨ KL loss è’¸é¦ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### è¡¨æ ¼ï¼šSFT-heavy æ¨¡å‹ä¸Šçš„è¡¨ç°ï¼ˆæ‘˜è‡ª Table 2ï¼‰

| Model | Method | MATH500 | AIME25 | GPQA-D | IFEval |
|-------|--------|---------|--------|--------|--------|
| Llama Nemotron Super V1 | BF16 | 95.8 | 46.0 | 66.5 | 87.5 |
| | NVFP4 PTQ | 91.4 | 32.3 | 62.1 | 86.9 |
| | NVFP4 QAT | 94.3 | 41.5 | 63.3 | 87.2 |
| | **NVFP4 QAD** | **94.6** | **45.6** | **64.5** | **87.8** |

> âœ… QAD æ˜¾è‘—ä¼˜äº QATï¼Œæ¥è¿‘ BF16 æ€§èƒ½ã€‚

---

#### è¡¨æ ¼ï¼šRL-heavy æ¨¡å‹ä¸Šçš„è¡¨ç°ï¼ˆæ‘˜è‡ª Table 3ï¼‰

| Model | Method | AIME25 | GPQA-D | LiveCodeBench |
|--------|--------|--------|--------|---------------|
| Nemotron 3 Nano | BF16 | 89.1 | 73.0 | 72.1 |
| | NVFP4 PTQ | 85.0 | 71.6 | 68.9 |
| | NVFP4 QAT | **83.3** | **66.0** | **62.0** |
| | **NVFP4 QAD** | **87.9** | **72.7** | **68.9** |

> â— QAT å¯¼è‡´ä¸¥é‡æ€§èƒ½ä¸‹é™ï¼ˆå°¤å…¶æ˜¯ RL å­¦åˆ°çš„èƒ½åŠ›è¢«ç ´åï¼‰ï¼Œè€Œ QAD æˆåŠŸæ¢å¤è‡³æ¥è¿‘ BF16 æ°´å¹³ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰æ•°æ®è´¨é‡æ•æ„Ÿæ€§åˆ†æï¼ˆTable 5ï¼‰

| Training Data | AIME25 | LiveCodeBench |
|--------------|--------|----------------|
| SFT data | 62.0 | 53.3 |
| Generated from RL prompts | 61.3 | 52.6 |
| Correct-only generations | 61.6 | 52.3 |
| Random tokens | 60.0 | 51.7 |

> âœ… **æƒŠäººå‘ç°**ï¼šå³ä½¿æ˜¯å®Œå…¨éšæœº token è¾“å…¥ï¼ŒQAD ä¹Ÿèƒ½ç»´æŒ PTQ æ°´å¹³ä»¥ä¸Šæ€§èƒ½ï¼Œä¸”ä¸ä¼šå´©æºƒï¼Œè¡¨ç°å‡ºæå¼ºç¨³å®šæ€§ã€‚

#### ï¼ˆ2ï¼‰è·¨åŸŸçŸ¥è¯†è¿ç§»èƒ½åŠ›ï¼ˆTable 4ï¼‰

| è®­ç»ƒæ•°æ® | AIME25ï¼ˆæ•°å­¦ï¼‰ | LiveCodeBenchï¼ˆç¼–ç¨‹ï¼‰ |
|----------|----------------|------------------------|
| æ•°å­¦ only | 61.7 | 53.1 |
| ç¼–ç¨‹ only | 62.0 | 53.3 |
| æ•°å­¦+ç¼–ç¨‹ | 62.0 | 53.3 |

> âœ… ä»…ç”¨ç¼–ç¨‹æ•°æ®è®­ç»ƒï¼Œå³å¯æ¢å¤å¼ºå¤§çš„æ•°å­¦æ¨ç†èƒ½åŠ› â†’ è¡¨æ˜ **Teacher çš„è¾“å‡ºåˆ†å¸ƒç¼–ç äº†è·¨é¢†åŸŸéšå¼çŸ¥è¯†**ã€‚

#### ï¼ˆ3ï¼‰å­¦ä¹ ç‡æ•æ„Ÿæ€§ï¼ˆTables 6 & 7ï¼‰

- **SFT-heavy æ¨¡å‹**ï¼šæœ€ä½³ LR â‰ˆ åŸå§‹ SFT å­¦ä¹ ç‡æˆ–æ›´ä½ï¼ˆå¦‚ `1e-6`ï¼‰
- **RL-heavy æ¨¡å‹**ï¼šéœ€è¦æ›´é«˜ LRï¼ˆå¦‚ `1e-5`ï¼‰ï¼Œé«˜äºå…¸å‹ RL å­¦ä¹ ç‡ï¼ˆ`~1e-6`ï¼‰

> ğŸ’¡ å»ºè®®èŒƒå›´ï¼š`1e-6 ~ 1e-5`

#### ï¼ˆ4ï¼‰æŸå¤±å‡½æ•°é€‰æ‹©ï¼ˆTable 8ï¼‰

| Loss | GPQA-D | AIME25 |
|------|--------|--------|
| KL Divergence | 62.0 | 71.5 |
| MSE on logits | 60.1 | 71.5 |

> âœ… KL æ•£åº¦åœ¨å¤šæ•°ä»»åŠ¡ä¸Šä¼˜äº MSEï¼Œæ›´é€‚åˆåˆ†å¸ƒå¯¹é½ã€‚

#### ï¼ˆ5ï¼‰æ•™å¸ˆæ¨¡å‹å¤§å°å½±å“ï¼ˆTable 9ï¼‰

| Teacher | AIME25 |
|--------|--------|
| 9B BF16ï¼ˆåŸæ¨¡å‹ï¼‰ | 71.5 |
| 12B BF16ï¼ˆæ›´å¤§åŒæ—ï¼‰ | 69.8 |

> âœ… ä½¿ç”¨åŸå§‹ BF16 æ¨¡å‹ä½œä¸º Teacher æ•ˆæœæœ€å¥½ï¼Œæ— éœ€æ›´å¤§æ•™å¸ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **QAD èƒ½é«˜æ•ˆæ¢å¤ NVFP4 æ¨¡å‹çš„æ¨ç†ç²¾åº¦**ï¼Œä½¿å…¶è¾¾åˆ°è¿‘ä¹ BF16 çš„æ€§èƒ½æ°´å¹³ã€‚
2. **åœ¨ RL-heavy æ¨¡å‹ä¸Šï¼ŒQAT ä¼šç ´åå·²å­¦åˆ°çš„èƒ½åŠ›ï¼Œè€Œ QAD å¯å®‰å…¨æ¢å¤**ï¼Œæ˜¯å”¯ä¸€å¯è¡Œè·¯å¾„ã€‚
3. **QAD å¯¹æ•°æ®è´¨é‡æå…¶é²æ£’**ï¼šå¯ç”¨éƒ¨åˆ†é¢†åŸŸã€åˆæˆæ•°æ®ç”šè‡³éšæœºè¾“å…¥è¿›è¡Œè®­ç»ƒï¼Œä»èƒ½ç¨³å®šæ”¶æ•›ã€‚
4. **å…·å¤‡è·¨åŸŸçŸ¥è¯†è¿ç§»èƒ½åŠ›**ï¼šTeacher çš„è¾“å‡ºåˆ†å¸ƒè•´å«å…¨å±€è¯­ä¹‰ä¿¡æ¯ï¼Œå¯æŒ‡å¯¼å­¦ç”Ÿæ³›åŒ–è‡³æœªè§é¢†åŸŸã€‚
5. **ç›¸æ¯” QATï¼ŒQAD æ›´å¿ å®è¿˜åŸåŸå§‹æ¨¡å‹è¡Œä¸º**ï¼ˆKL divergence æ¥è¿‘é›¶ï¼‰ï¼Œè€Œéâ€œé‡æ–°å­¦ä¹ â€ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

- **ä¾èµ– Teacher æ¨¡å‹çš„å­˜åœ¨**ï¼šå¿…é¡»æ‹¥æœ‰åŸå§‹ BF16 æ¨¡å‹æ‰èƒ½å®æ–½ QADã€‚
- **æ— æ³•è¶…è¶Š Teacher æ€§èƒ½**ï¼šæœ¬è´¨æ˜¯ä¿çœŸè€Œéå¢å¼ºï¼Œä¸èƒ½ä¿®å¤ Teacher æœ¬èº«çš„ç¼ºé™·ã€‚
- **å¯¹å­¦ä¹ ç‡è¾ƒæ•æ„Ÿ**ï¼šéœ€æ ¹æ®æ¨¡å‹è®­ç»ƒå†å²è°ƒæ•´ LRï¼Œç¼ºä¹ç»Ÿä¸€ç­–ç•¥ã€‚
- **ç›®å‰é›†ä¸­åœ¨ NVFP4**ï¼šæ˜¯å¦å¹¿æ³›é€‚ç”¨äºå…¶ä»–ä½æ¯”ç‰¹æ ¼å¼ï¼ˆå¦‚ INT4ã€MXFP4ï¼‰å°šå¾…éªŒè¯ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ¢ç´¢è‡ªåŠ¨åŒ–å­¦ä¹ ç‡è°ƒåº¦æœºåˆ¶**ï¼Œé€‚åº”ä¸åŒè®­ç»ƒå†å²çš„æ¨¡å‹ã€‚
2. **ç ”ç©¶æ›´é«˜æ•ˆçš„è’¸é¦ç­–ç•¥**ï¼Œå‡å°‘æ‰€éœ€ token æ•°é‡ï¼ˆè¿›ä¸€æ­¥é™ä½æˆæœ¬ï¼‰ã€‚
3. **æ‰©å±•è‡³å…¶ä»–æ¨¡æ€å’Œæ¶æ„**ï¼ˆå¦‚ diffusion modelsã€graph neural networksï¼‰ã€‚
4. **ç»“åˆ QAT ä¸ QAD**ï¼šåœ¨ SFT é˜¶æ®µç”¨ QATï¼Œåœ¨ RL åé˜¶æ®µç”¨ QADï¼Œå½¢æˆç»Ÿä¸€ pipelineã€‚
5. **æ¢ç´¢æ— éœ€ Teacher çš„æ›¿ä»£æ–¹æ¡ˆ**ï¼Œå¦‚ self-distillation æˆ– latent space alignmentã€‚

---

## âœ… æ€»ç»“ä¸€å¥è¯

> **QAD æ˜¯ä¸€ç§å®ç”¨ã€ç¨³å®šä¸”é«˜æ•ˆçš„æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä¸å¤ç°å¤æ‚è®­ç»ƒæµç¨‹çš„æƒ…å†µä¸‹ï¼Œç²¾å‡†æ¢å¤ NVFP4 é‡åŒ– LLM/VLM çš„æ¨ç†ç²¾åº¦ï¼Œç‰¹åˆ«é€‚åˆ RL è®­ç»ƒåæ¨¡å‹å’Œæ•°æ®å—é™åœºæ™¯ï¼Œæ˜¯ PTQ ä¸è¶³æ—¶çš„ç†æƒ³è¡¥æ•‘æ–¹æ¡ˆã€‚**

> ğŸ”— ç›¸å…³ä»£ç ä¸ checkpoint å·²å¼€æºï¼šMegatron-LMã€NeMoã€HuggingFace Transformers ç‰ˆæœ¬å‡æä¾›æ”¯æŒã€‚

</details>

---

### 3. [Reinforcement Unlearning via Group Relative Policy Optimization](https://arxiv.org/abs/2601.20568)

**Authors**: Efstratios Zaradoukas, Bardh Prenkaj, Gjergji Kasneci  
**Category**: cs.LG  
**Published**: 2026-01-29  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.20568v1  

#### Abstract
During pretraining, LLMs inadvertently memorize sensitive or copyrighted data, posing significant compliance challenges under legal frameworks like the GDPR and the EU AI Act. Fulfilling these mandates demands techniques that can remove information from a deployed model without retraining from scrat...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šReinforcement Unlearning via Group Relative Policy Optimization**

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæ— æ„ä¸­è®°å¿†æ•æ„Ÿæˆ–å—ç‰ˆæƒä¿æŠ¤çš„æ•°æ®ï¼Œè¿™åœ¨ GDPR å’Œæ¬§ç›Ÿ AI æ³•æ¡ˆç­‰æ³•è§„æ¡†æ¶ä¸‹æ„æˆäº†åˆè§„æŒ‘æˆ˜ã€‚ç°æœ‰çš„ **Machine Unlearning** æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **æ•°æ®æ³„éœ²é£é™©**ï¼šæ— æ³•å½»åº•æ¸…é™¤ç›®æ ‡ä¿¡æ¯ï¼Œæ®‹ç•™çŸ¥è¯†å¯èƒ½è¢«å¯¹æŠ—æ€§æ”»å‡»æ¢å¤ã€‚
- **æ€§èƒ½ä¸‹é™**ï¼šè¿‡åº¦ä¼˜åŒ–å¯¼è‡´æ¨¡å‹æµç•…æ€§ï¼ˆfluencyï¼‰å’Œé€šç”¨èƒ½åŠ›é€€åŒ–ã€‚
- **ä¾èµ–å¤–éƒ¨å¥–åŠ±æ¨¡å‹**ï¼šå¦‚ DPOã€Quark ç­‰æ–¹æ³•éœ€è¦é¢å¤–è®­ç»ƒ Reward Modelï¼Œå¢åŠ è®¡ç®—å¼€é”€ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ï¼šPURGE**
ä½œè€…æå‡ºäº† **PURGE**ï¼ˆPolicy Unlearning through Relative Group Erasureï¼‰ï¼Œä¸€ç§åŸºäº **Group Relative Policy Optimization (GRPO)** æ¡†æ¶çš„æ–°å‹ LLM å¿˜è®°æœºåˆ¶ã€‚

#### **æ ¸å¿ƒæ€æƒ³**
å°†â€œé—å¿˜â€å»ºæ¨¡ä¸ºä¸€ä¸ª**å¯éªŒè¯ä»»åŠ¡**ï¼ˆverifiable taskï¼‰ï¼Œé€šè¿‡å†…åœ¨å¥–åŠ±ä¿¡å·ç›´æ¥æƒ©ç½šå¯¹ç¦æ­¢æ¦‚å¿µçš„æåŠï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåƒå¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰ä¼˜åŒ–æ¨ç†ä¸€æ ·ä¼˜åŒ–â€œå¿˜è®°â€ã€‚

#### **å…³é”®æŠ€æœ¯è·¯å¾„**
- åˆ©ç”¨ GRPO æ›¿ä»£ä¼ ç»Ÿ RLHFï¼Œæ— éœ€å¤–éƒ¨ Reward Modelã€‚
- æ„é€ åˆæˆé—å¿˜è¯­æ–™åº“ï¼ˆsynthetic forget corpusï¼‰ç”¨äºè®­ç»ƒã€‚
- å®šä¹‰äºŒå€¼å¥–åŠ±å‡½æ•° $ p(x) = \mathbb{1}_{x \cap \mathcal{F} = \emptyset} $ï¼Œå³è‹¥è¾“å‡ºä¸­ä¸åŒ…å«ä»»ä½•ç¦æ­¢å®ä½“ï¼Œåˆ™å¾—åˆ†ä¸º 1ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | PURGE çš„ä¼˜åŠ¿ |
|------|-------------|
| **æ•ˆç‡** | æ¯ä¸ªé—å¿˜ç›®æ ‡ä½¿ç”¨çš„ token æ•°é‡æ¯” SoTA æ–¹æ³•å°‘è‡³ Ã—46 |
| **æ•ˆæœ** | åœ¨ä¿æŒ 98% åŸå§‹æ•ˆç”¨çš„åŒæ—¶å®ç° 11% çš„é—å¿˜æœ‰æ•ˆæ€§ |
| **é²æ£’æ€§** | å¯¹æŠ—æ”»å‡»ä¸‹çš„é—å¿˜è´¨é‡æå‡ +12.02% |
| **æµç•…æ€§** | è¾“å‡ºæ›´è‡ªç„¶è¿è´¯ï¼ŒFLU åˆ†æ•°æé«˜ +5.48% |
| **ç‹¬ç«‹æ€§** | ä¸ä¾èµ–å¤–éƒ¨ Reward Modelï¼Œéƒ¨ç½²æˆæœ¬æ›´ä½ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨æ•°æ®é›†**
- ä¸»è¦åŸºå‡†ï¼š**RWKU**ï¼ˆReal World Knowledge Unlearning Benchmarkï¼‰
  - åŒ…å«å¤šä¸ªå­é›†ï¼š
    - **Forget Set**ï¼šæµ‹è¯•é—å¿˜æ•ˆæœï¼ˆFB, QA, AAï¼‰
    - **Neighbor Set**ï¼šæ£€éªŒé‚»è¿‘çŸ¥è¯†ä¿ç•™æƒ…å†µ
    - **MIA Set**ï¼šæˆå‘˜æ¨æ–­æ”»å‡»æ£€æµ‹éšç§æ³„éœ²
    - **Utility Set**ï¼šè¯„ä¼°ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½å½±å“ï¼ˆGen, Rea, Tru, Fac, Fluï¼‰

### **å®éªŒè®¾ç½®**
- **æ¨¡å‹æ¶æ„**ï¼šPhi-3-Mini-4K-Instructï¼ˆ3.8B å‚æ•°ï¼‰
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š1Ã—AMD EPYC CPU + 1Ã—NVIDIA A100 GPUï¼Œæ€»è€—æ—¶çº¦ 350 å°æ—¶
- **è®­ç»ƒæµç¨‹**ï¼š
  1. è‡ªæˆ‘ç”Ÿæˆæ¢æµ‹é—®é¢˜ç­”æ¡ˆ
  2. ä½¿ç”¨ GPT-4 æå–ä¸ç›®æ ‡ç›¸å…³çš„æè¿°æ€§å®ä½“ï¼ˆTop-50ï¼‰
  3. æ„å»ºåˆæˆé—å¿˜è¯­æ–™ $\mathcal{F}(x)$
  4. åº”ç”¨ GRPO è¿›è¡Œç­–ç•¥æ›´æ–°

### **è¯„ä¼°æŒ‡æ ‡**
| ç±»åˆ« | æŒ‡æ ‡ | æ–¹å‘è¯´æ˜ |
|------|------|--------|
| **é—å¿˜è´¨é‡** | ROUGE-L â†“ | è¶Šä½è¡¨ç¤ºè¶Šå°‘æåŠç›®æ ‡çŸ¥è¯† |
| **é‚»è¿‘çŸ¥è¯†ä¿ç•™** | ROUGE-L â†‘ | è¶Šé«˜è¶Šå¥½ |
| **éšç§å®‰å…¨** | FM â†‘, RM â†“ | é«˜ FM è¡¨ç¤ºæ›´å¼ºçš„é—å¿˜ä¿¡å· |
| **å®ç”¨æ€§ä¿ç•™** | Gen (MMLU), Rea (BBH), Tru (TruthfulQA), Fac (TriviaQA), Flu (AlpacaEval) â†‘ | æ‰€æœ‰è¶Šé«˜è¶Šå¥½ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **GA**ï¼ˆGradient Ascentï¼‰
- **DPO**ï¼ˆDirect Preference Optimizationï¼‰
- **NPO**ï¼ˆNegative Preference Optimizationï¼‰
- **RT**ï¼ˆRejection Tuningï¼‰
- **ICU**ï¼ˆIn-Context Unlearningï¼‰
- **Base Model**ï¼ˆæ— ä»»ä½•å¤„ç†ï¼‰

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰**

| æ–¹æ³• | Forget Set (â†“) | Neighbor Set (â†‘) | MIA FM â†‘ | Utility FLU â†‘ |
|------|----------------|------------------|----------|---------------|
| **Base** | 0.483 (FB) | 0.498 | 40.04 | 133.58 |
| **GA** | 0.467 | 0.489 | 40.25 | 133.67 |
| **DPO** | 0.522 | 0.527 | 39.83 | 135.23 |
| **NPO** | 0.296 | 0.431 | 44.75 | 133.15 |
| **RT** | 0.454 | 0.499 | 40.02 | 121.40 |
| **PURGE** | **0.428** | **0.513** | **40.26** | **140.90** |

> æ³¨ï¼šæ•°å€¼ä¸º ROUGE-L å¾—åˆ†ï¼›â†“ è¡¨ç¤ºè¶Šå°è¶Šå¥½ï¼Œâ†‘ è¡¨ç¤ºè¶Šå¤§è¶Šå¥½

#### **ç›¸å¯¹ Base Model çš„æ”¹è¿›ï¼ˆâ–³(us, base)ï¼‰**
- **é—å¿˜è´¨é‡æå‡**ï¼š
  - FB: -5.53%
  - QA: -10.7%
  - AA: -12.02%
- **æµç•…æ€§æå‡**ï¼š+7.32% ï¼ˆFLU è¾¾ 140.90ï¼‰
- **é‚»è¿‘çŸ¥è¯†ä¿ç•™**ï¼š+1.53%ï¼ˆä¼˜äºå¤šæ•° SoTAï¼‰

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **token æ•ˆç‡**ï¼šPURGE æ¯” DPO èŠ‚çœ Ã—46 tokenï¼Œæ¯” GA/NPO èŠ‚çœ Ã—22
- **å¯¹æŠ—æ”»å‡»é²æ£’æ€§**ï¼šåœ¨ 9 ç§ adversarial attack ä¸­ï¼ŒPURGE æˆåŠŸé˜»æ­¢çŸ¥è¯†æ¢å¤ï¼ˆå›¾ 4 æ˜¾ç¤ºè´Ÿå·®å€¼ï¼‰
- **ç†è®ºä¿éšœéªŒè¯**ï¼š
  - Theorem 1ï¼ˆæŠ‘åˆ¶æ³„æ¼ï¼‰ï¼šå®éªŒè¯æ˜ forbidden-token æ¦‚ç‡éšè®­ç»ƒé€’å‡
  - Theorem 2ï¼ˆæ•ˆç”¨ä¿ç•™ï¼‰ï¼šKL æ•£åº¦æ§åˆ¶åœ¨ ~0.05 å†…ï¼Œé¢„æµ‹æ•ˆç”¨æŸå¤± â‰¤16%ï¼Œå®é™…è¡¨ç°æ›´ä¼˜

### **æ¶ˆèå®éªŒç»“æœ**
#### **(1) æŠ—å¯¹æŠ—æ”»å‡»èƒ½åŠ›ï¼ˆå›¾ 4ï¼‰**
- PURGE åœ¨ 8/9 ç§æ”»å‡»æ¨¡å¼ä¸‹è¡¨ç°æœ€ä½³
- ç‰¹åˆ«æ˜¯åœ¨ **Prefix Injection**, **Role Playing**, **Cross Lingual** ç­‰å¤æ‚æç¤ºå·¥ç¨‹ä¸­ä»èƒ½æœ‰æ•ˆé—å¿˜

#### **(2) æ¨¡å‹è§„æ¨¡æ‰©å±•æ€§ï¼ˆå›¾ 3ï¼‰**
- åœ¨ Qwen-2.5 ç³»åˆ—ï¼ˆ0.5B â†’ 3Bï¼‰ä¸Šæµ‹è¯•ï¼š
  - æ›´å¤§æ¨¡å‹æ›´éš¾é—å¿˜ï¼ˆmemorization éšå‚æ•°è¶…çº¿æ€§å¢é•¿ï¼‰
  - ä½† PURGE ä»èƒ½ç¨³å®šä¿ç•™ utilityï¼ˆæ‰€æœ‰äº”é¡¹æŒ‡æ ‡åŸºæœ¬ä¸å˜ï¼‰

#### **(3) TOFU åŸºå‡†æ³›åŒ–èƒ½åŠ›ï¼ˆè¡¨ 2ï¼‰**
| æ–¹æ³• | Forget Quality | Model Utility |
|------|----------------|----------------|
| **PURGE** | 1.12Ã—10â»Â¹â¹ | 0.5990 |
| **UNDIAL** | 1.88Ã—10â»Â²Â² | 0.6016 |
| **NPO** | 1.62Ã—10â»Â¹â° | 0.5964 |

â†’ PURGE åœ¨ TOFU ä¸Šè™½éæœ€ä¼˜ï¼Œä½†è¡¨ç°ç¨³å¥ï¼Œè¡¨æ˜å…¶å…·æœ‰è‰¯å¥½çš„è·¨åŸºå‡†æ³›åŒ–èƒ½åŠ›ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **å°† unlearning è§†ä¸º verifiable task æ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„**  
   é€šè¿‡è®¾è®¡å¯æµ‹é‡çš„å¥–åŠ±å‡½æ•°ï¼Œå¯ä»¥å¼•å¯¼æ¨¡å‹ä¸»åŠ¨â€œå¿˜è®°â€ï¼Œè€Œéè¢«åŠ¨åˆ é™¤ã€‚
   
2. âœ… **GRPO æ˜¯å®ç°é«˜æ•ˆé—å¿˜çš„ç†æƒ³æ¡†æ¶**  
   æ— éœ€ Reward Modelï¼Œåˆ©ç”¨ group-relative advantage å¯ç¨³å®šä¼˜åŒ–ç­–ç•¥ã€‚

3. âœ… **ç†è®ºä¿è¯å¯åœ¨å®è·µä¸­å…‘ç°**  
   - Theorem 1ï¼šç¦æ­¢ token æ¦‚ç‡å‘ˆå‡ ä½•è¡°å‡
   - Theorem 2ï¼šKL æ­£åˆ™é¡¹æœ‰æ•ˆçº¦æŸæ•ˆç”¨æŸå¤±ä¸Šé™

4. âœ… **é«˜é—å¿˜å¼ºåº¦ â‰  é«˜æ•ˆé—å¿˜**  
   NPO è™½ç„¶é—å¿˜æ›´å¼ºï¼Œä½†ä»£ä»·æ˜¯æ›´é«˜çš„ token æ¶ˆè€—ï¼›PURGE åœ¨æ•ˆç‡ä¸æ•ˆæœé—´å–å¾—æ›´å¥½å¹³è¡¡ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–é«˜è´¨é‡åˆæˆè¯­æ–™æ„å»º**ï¼šéœ€å€ŸåŠ© GPT-4 æå–æè¿°æ€§å®ä½“ï¼Œå­˜åœ¨æ½œåœ¨å™ªå£°ã€‚
- **é™æ€ç›®æ ‡å‡è®¾**ï¼šå½“å‰ä»…æ”¯æŒå•ä¸ªç›®æ ‡é€ä¸ªé—å¿˜ï¼Œå°šæœªæ”¯æŒæ‰¹é‡é—å¿˜ï¼ˆbatch unlearningï¼‰ã€‚
- **æ— æ³•å®Œå…¨å½’é›¶æ³„æ¼æ¦‚ç‡**ï¼šç”±äº KL æ­£åˆ™å’Œé‡‡æ ·æ··åˆæœºåˆ¶ï¼Œç†è®ºä¸Šå­˜åœ¨æ³„æ¼åº•é™ï¼ˆè§ Theorem 1 æ¨è®ºï¼‰ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **åŠ¨æ€ç›®æ ‡æå–**ï¼šä»æ¨¡å‹ embedding space ç›´æ¥æŒ–æ˜è¯­ä¹‰ç›¸å…³æ¦‚å¿µï¼Œå®ç°æ¨¡å‹æ„ŸçŸ¥çš„ç²¾å‡†é—å¿˜ã€‚
2. **æ”¯æŒ Batch Unlearning**ï¼šåŒæ—¶ç§»é™¤å¤šä¸ªç›®æ ‡ï¼Œæå‡ç°å®åœºæ™¯ä¸­çš„å¯æ‰©å±•æ€§ã€‚
3. **æ¢ç´¢ Regret-to-Retraining Bound çš„å®è¯éªŒè¯**ï¼šå°½ç®¡ Theorem 3 æä¾›äº†ç†è®ºæ”¶æ•›æ€§ï¼Œä½†åœ¨çœŸå® LLM ä¸Šå°šéš¾éªŒè¯ã€‚
4. **ç»“åˆ In-context ä¸ Fine-tuning æ–¹æ³•**ï¼šæ¢ç´¢ hybrid unlearning pipeline ä»¥è¿›ä¸€æ­¥é™ä½èµ„æºæ¶ˆè€—ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> PURGE é€šè¿‡å°† LLM å¿˜è®°ä»»åŠ¡é‡æ„ä¸ºåŸºäº GRPO çš„å¯éªŒè¯å¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œåœ¨**æä½ token å¼€é”€ä¸‹å®ç°äº†é«˜æ•ˆã€å®‰å…¨ã€å¯è§£é‡Šçš„é—å¿˜**ï¼Œä¸ºåˆè§„é©±åŠ¨çš„ AI ç³»ç»Ÿæä¾›äº†æå…·æ½œåŠ›çš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 4. [Semantic Uncertainty Quantification of Hallucinations in LLMs: A Quantum Tensor Network Based Method](https://arxiv.org/abs/2601.20026)

**Authors**: Pragatheeswaran Vipulanandan, Kamal Premaratne, Dilip Sarkar  
**Category**: cs.CL  
**Published**: 2026-01-29  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.20026v1  

#### Abstract
Large language models (LLMs) exhibit strong generative capabilities but remain vulnerable to confabulations, fluent yet unreliable outputs that vary arbitrarily even under identical prompts. Leveraging a quantum tensor network based pipeline, we propose a quantum physics inspired uncertainty quantif...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSemantic Uncertainty Quantification of Hallucinations in LLMs: A Quantum Tensor Network Based Method

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†å…¶è¾“å‡ºå¸¸å‡ºç° **hallucinations**ï¼ˆå¹»è§‰ï¼‰ï¼Œå³ç”Ÿæˆçœ‹ä¼¼æµç•…åˆç†ä½†å®é™…ä¸Šé”™è¯¯æˆ–æ— æ³•éªŒè¯çš„å†…å®¹ã€‚è¿™ç±»é—®é¢˜åœ¨é«˜é£é™©é¢†åŸŸï¼ˆå¦‚åŒ»ç–—ã€æ³•å¾‹ã€è‡ªåŠ¨é©¾é©¶ï¼‰å°¤ä¸ºä¸¥é‡ã€‚ç°æœ‰æ–¹æ³•åœ¨æ£€æµ‹å¹»è§‰æ—¶å­˜åœ¨ä»¥ä¸‹ä¸è¶³ï¼š
- ä¾èµ–ç›‘ç£å­¦ä¹ æˆ–å¤æ‚è¯­ä¹‰åˆ†æï¼Œè®¡ç®—å¼€é”€å¤§ï¼Œéš¾ä»¥å®æ—¶åº”ç”¨ï¼›
- ä¼ ç»Ÿè´å¶æ–¯æ·±åº¦å­¦ä¹ ï¼ˆBDLï¼‰æ–¹æ³•å¯¹äº‹å®æ­£ç¡®æ€§çš„ä¸ç¡®å®šæ€§å»ºæ¨¡ä¸å‡†ç¡®ï¼›
- åŸºäºtokenæ¦‚ç‡çš„ç†µåº¦é‡ï¼ˆå¦‚Naive Entropyï¼‰æ˜“å—è¡¨å±‚å·®å¼‚å¹²æ‰°ï¼Œä¸èƒ½åæ˜ **è¯­ä¹‰ç­‰ä»·æ€§**ï¼›
- ç¼ºä¹å¯¹**åºåˆ—æ¦‚ç‡ä¸­çš„å¶ç„¶ä¸ç¡®å®šæ€§ï¼ˆaleatoric uncertaintyï¼‰** çš„å»ºæ¨¡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº**é‡å­å¼ é‡ç½‘ç»œï¼ˆQuantum Tensor Network, QTNï¼‰** çš„æ–°å‹ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUncertainty Quantification, UQï¼‰æ¡†æ¶ï¼Œç”¨äºæ£€æµ‹LLMä¸­çš„å¹»è§‰ã€‚æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ï¼š

- **å°†Token Sequence (TS) æ¦‚ç‡è§†ä¸ºé‡å­æ€æ³¢å‡½æ•°**ï¼šåˆ©ç”¨æ ¸å‡å€¼åµŒå…¥ï¼ˆKMEï¼‰å°†TSæ¦‚ç‡åˆ†å¸ƒæ˜ å°„åˆ°å†ç”Ÿæ ¸å¸Œå°”ä¼¯ç‰¹ç©ºé—´ï¼ˆRKHSï¼‰ï¼Œå¹¶å°†å…¶ä½œä¸ºQTNå“ˆå¯†é¡¿é‡çš„ä¸€ä¸ªæœ¬å¾æ¨¡å¼ã€‚
- **å¼•å…¥æ‰°åŠ¨ç†è®ºè¿›è¡Œå±€éƒ¨UQ**ï¼šé€šè¿‡æ–½åŠ å¾®å°æ‰°åŠ¨äºå“ˆå¯†é¡¿é‡ï¼Œè®¡ç®—ç¬¬ä¸€é˜¶ä¿®æ­£é¡¹ï¼Œä»è€Œè¡¡é‡TSæ¦‚ç‡å¯¹æ‰°åŠ¨çš„æ•æ„Ÿæ€§ï¼Œå¾—åˆ°æ¯ä¸ªç”Ÿæˆåºåˆ—çš„ä¸ç¡®å®šæ€§åˆ†æ•°ã€‚
- **ç»“åˆè¯­ä¹‰èšç±»ä¸ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„ç†µæœ€å¤§åŒ–**ï¼šåœ¨è¯­ä¹‰ç­‰ä»·çš„åŸºç¡€ä¸Šè¿›è¡Œèšç±»ï¼Œå¹¶ä½¿ç”¨**è¯­ä¹‰RÃ©nyiç†µï¼ˆSemantic RÃ©nyi Entropy, SREï¼‰** è¡¡é‡å¤šæ ·æ€§ï¼›è¿›ä¸€æ­¥é€šè¿‡ä¸€ä¸ªå¸¦ä¸ç¡®å®šæƒé‡çš„KLæ•£åº¦æ­£åˆ™åŒ–ç›®æ ‡å‡½æ•°è°ƒæ•´TSæ¦‚ç‡ï¼Œå®ç°**ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„æ¦‚ç‡æ ¡å‡†**ã€‚

è¯¥æ–¹æ³•è¢«ç§°ä¸º **SRE-UQ**ï¼ˆSemantic RÃ©nyi Entropy with Uncertainty Quantificationï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **å¯è§£é‡Šæ€§** | åŸºäºç‰©ç†å¯å‘çš„ç¡®å®šæ€§ã€å•æ¬¡æ¨ç†æ–¹æ³•ï¼Œæ— éœ€é‡‡æ ·ï¼Œæä¾›ç›´è§‚çš„ä¸ç¡®å®šæ€§è°±å›¾ï¼ˆspectrogramï¼‰ã€‚ |
| **æ•ˆç‡** | ä¸éœ€è¦å¤šæ¬¡é‡‡æ ·æˆ–é‡å¤æŸ¥è¯¢ï¼Œé€‚ç”¨äºèµ„æºå—é™ç¯å¢ƒä¸‹çš„å®æ—¶éƒ¨ç½²ã€‚ |
| **é²æ£’æ€§** | æ˜¾è‘—ä¼˜äºç°æœ‰SOTAæ–¹æ³•ï¼Œåœ¨ä¸åŒé‡åŒ–çº§åˆ«ï¼ˆ16-bit, 8-bit, 4-bitï¼‰ä¸‹ä¿æŒç¨³å®šæ€§èƒ½ã€‚ |
| **æ³›åŒ–æ€§** | åœ¨å¤šç§LLMæ¶æ„ï¼ˆMistral, LLaMA, Falconç­‰ï¼‰ã€ä»»åŠ¡ç±»å‹ï¼ˆé—®ç­”ã€æ•°å­¦é¢˜ï¼‰å’Œè¾“å‡ºé•¿åº¦ï¼ˆçŸ­è¯­çº§ vs å¥å­çº§ï¼‰ä¸Šå‡è¡¨ç°ä¼˜å¼‚ã€‚ |
| **æ— éœ€ç›‘ç£è®­ç»ƒ** | å®Œå…¨æ— ç›‘ç£ï¼Œä¸ä¾èµ–æ ‡æ³¨æ•°æ®è¿›è¡Œfine-tuningï¼Œé¿å…äº†out-of-distributioné€€åŒ–é—®é¢˜ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å…±å››ä¸ªæ ‡å‡†é—®ç­”æ•°æ®é›†ï¼Œè¦†ç›–å¤šé¢†åŸŸçŸ¥è¯†ä¸æ¨ç†ä»»åŠ¡ï¼š
- **TriviaQA**ï¼šå¸¸è¯†æ€§ trivia çŸ¥è¯†é—®ç­”ï¼›
- **SQuAD 1.1**ï¼šæŠ½å–å¼é˜…è¯»ç†è§£ï¼›
- **NQ-Open**ï¼šå¼€æ”¾åŸŸè‡ªç„¶é—®é¢˜ï¼Œæ¥æºäºGoogleæœç´¢çœŸå®æŸ¥è¯¢ï¼›
- **SVAMP**ï¼šæ•°å­¦åº”ç”¨é¢˜ï¼ˆMath Word Problemsï¼‰ï¼Œæµ‹è¯•é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹èŒƒå›´**ï¼šæ¶µç›–å¤šä¸ªä¸»æµLLMï¼ŒåŒ…æ‹¬ï¼š
  - `Mistral-7B`, `Mistral-7B-instruct`
  - `Falcon-rw-1b`
  - `LLaMA-3.2-1b`, `LLaMA-2-7b`, `LLaMA-2-13b` åŠå…¶chatç‰ˆæœ¬
- **é‡åŒ–æ°´å¹³**ï¼šè¯„ä¼°äº† **16-bitã€8-bit å’Œ 4-bit** ä¸‰ç§é‡åŒ–ç²¾åº¦ä¸‹çš„æ€§èƒ½ï¼Œæ¨¡æ‹Ÿå®é™…è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²åœºæ™¯ã€‚
- **ç”Ÿæˆæ–¹å¼**ï¼šæ¯æ¡è¾“å…¥æç¤ºé‡å¤ç”Ÿæˆ R=10 æ¬¡ï¼Œç”¨äºæ„å»ºè¯­ä¹‰ç°‡å’Œä¼°è®¡ç†µã€‚
- **è¯­ä¹‰èšç±»**ï¼šä½¿ç”¨ DeBERTa-large åœ¨ MNLI ä¸Šå¾®è°ƒåçš„æ¨¡å‹åˆ¤æ–­ä¸¤ä¸ªç­”æ¡ˆä¹‹é—´æ˜¯å¦å…·æœ‰åŒå‘è•´å«å…³ç³»ï¼ˆbidirectional entailmentï¼‰ï¼Œä»¥æ­¤åˆ’åˆ†è¯­ä¹‰ç°‡ã€‚
- **ç¡¬ä»¶å¹³å°**ï¼šæ‰€æœ‰å®éªŒè¿è¡Œäºé…å¤‡64GBå†…å­˜å’ŒNVIDIA A6000 GPUçš„å·¥ä½œç«™ã€‚

### è¯„ä¼°æŒ‡æ ‡
é‡‡ç”¨ä¸‰ä¸ªæ ¸å¿ƒæŒ‡æ ‡è¯„ä¼°å¹»è§‰æ£€æµ‹èƒ½åŠ›ï¼š
1. **AUROC**ï¼ˆArea Under ROC Curveï¼‰  
   è¡¡é‡åˆ†ç±»å™¨åŒºåˆ†æ­£ç¡®ä¸é”™è¯¯å›ç­”çš„èƒ½åŠ›ï¼Œè¶Šé«˜è¶Šå¥½ï¼ˆç†æƒ³ä¸º1.0ï¼‰ã€‚
   
2. **RAC**ï¼ˆRejection Accuracy Curveï¼‰  
   éšç€é€æ­¥æ‹’ç»ç½®ä¿¡åº¦æœ€ä½çš„å›ç­”ï¼Œä¿ç•™éƒ¨åˆ†çš„å‡†ç¡®ç‡å˜åŒ–æ›²çº¿ã€‚æ–œç‡è¶Šé™¡ï¼Œè¯´æ˜ä¸ç¡®å®šæ€§æ’åºè¶Šæœ‰æ•ˆã€‚

3. **AURAC**ï¼ˆArea Under RACï¼‰  
   RACæ›²çº¿ä¸‹é¢ç§¯ï¼Œç»¼åˆåæ˜ ä¸ç¡®å®šæ€§ä¼°è®¡çš„è´¨é‡ã€‚å€¼è¶Šé«˜è¡¨ç¤ºé«˜ç½®ä¿¡é¢„æµ‹æ›´å¯é ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
ä¸ä»¥ä¸‹ä»£è¡¨æ€§æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒï¼š
- **Naive Entropy (NE)**ï¼šç›´æ¥åŸºäºtoken sequenceæ¦‚ç‡è®¡ç®—é¦™å†œç†µï¼›
- **Semantic Entropy (SEs)**ï¼šåŸºäºè¯­ä¹‰èšç±»çš„é¦™å†œç†µï¼ˆFarquhar et al., 2024ï¼‰ï¼›
- **Discrete Semantic Entropy (DSEs)**ï¼šåŸºäºèšç±»è®¡æ•°çš„ç»éªŒç†µï¼›
- **Embedding Regression (ER)**ï¼šæœ‰ç›‘ç£æ–¹æ³•ï¼Œç”¨logisticå›å½’é¢„æµ‹ç­”æ¡ˆæ­£ç¡®æ€§ï¼›
- **p(True)**ï¼šè®©æ¨¡å‹è‡ªè¯„â€œtopç­”æ¡ˆæ˜¯å¦ä¸ºçœŸâ€çš„ä¿¡å¿ƒå¾—åˆ†ï¼ˆKadavath et al., 2022ï¼‰ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- æ€»å…±å®Œæˆ **116ç»„å®éªŒ**ï¼Œè¦†ç›–ä¸åŒæ¨¡å‹ã€æ•°æ®é›†ã€é‡åŒ–ç­‰çº§å’Œè¾“å‡ºé•¿åº¦ã€‚
- åœ¨æ‰€æœ‰è®¾ç½®ä¸‹ï¼Œæ‰€ææ–¹æ³• **SRE-UQ** åœ¨ **AUROC å’Œ AURAC** ä¸Šå‡æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚

#### AUROC å¯¹æ¯”ï¼ˆä»£è¡¨æ€§å¹³å‡ï¼‰
| æ–¹æ³• | å¹³å‡ AUROC |
|------|-----------|
| SRE-UQ (**æœ¬æ–‡**) | **~0.85â€“0.91** |
| SEs | ~0.78 |
| DSEs | ~0.76 |
| p(True) | ~0.65 |
| ER | ~0.70 |

> å›¾2æ˜¾ç¤ºï¼ŒSRE-UQåœ¨è¶…è¿‡ **80% çš„å®éªŒåœºæ™¯ä¸­èƒœå‡º**ï¼Œå³ä½¿é¢å¯¹æœ‰ç›‘ç£æ–¹æ³•ä¹Ÿå…·å¤‡ç«äº‰åŠ›ã€‚

#### AURAC å¯¹æ¯”ï¼ˆæ‹’ç­”æœ‰æ•ˆæ€§ï¼‰
- SRE-UQ çš„ **RAC æ›²çº¿æœ€é™¡å³­**ï¼Œè¡¨æ˜å…¶èƒ½æ›´æœ‰æ•ˆåœ°è¿‡æ»¤æ‰ä½ç½®ä¿¡ã€æ˜“å‡ºé”™çš„å›ç­”ã€‚
- åœ¨4-bitæç«¯å‹ç¼©æ¡ä»¶ä¸‹ï¼Œå…¶ä»–æ–¹æ³•ï¼ˆå°¤å…¶æ˜¯NEå’ŒSEsï¼‰æ€§èƒ½æ˜æ˜¾ä¸‹é™ï¼Œè€ŒSRE-UQä»ä¿æŒç¨³å¥ã€‚

#### è·¨é‡åŒ–çº§åˆ«çš„é²æ£’æ€§ï¼ˆå›¾3ï¼‰
| é‡åŒ–ç­‰çº§ | SRE-UQ æ˜¯å¦æŒç»­é¢†å…ˆï¼Ÿ |
|----------|------------------------|
| 16-bit | âœ… æ˜¯ |
| 8-bit | âœ… æ˜¯ |
| 4-bit | âœ… æ˜¯ï¼ˆå”¯ä¸€ä¿æŒä¼˜åŠ¿çš„æ–¹æ³•ï¼‰ |

> ç»“æœè¯æ˜ï¼šå°½ç®¡é‡åŒ–ä¼šé™ä½ç»å¯¹AUROCå€¼ï¼Œä½†**ç›¸å¯¹æ’åç¨³å®š**ï¼ŒSRE-UQåœ¨è½»é‡åŒ–éƒ¨ç½²ä¸­ä¾ç„¶å¯é ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **è¶…å‚æ•° Î» åˆ†æï¼ˆå›¾24ï¼‰**ï¼š
  - å­˜åœ¨ä¸€ä¸ªæœ€ä¼˜åŒºé—´ï¼ˆÎ» â‰ˆ 0.5â€“5ï¼‰ï¼Œåœ¨æ­¤èŒƒå›´å†…AUROCæ˜¾è‘—é«˜äºæœªæ ¡å‡†çš„baseline SREï¼›
  - å³ä½¿Î»å–éæœ€ä¼˜å€¼ï¼Œæ€§èƒ½ä»ä¼˜äºåŸºçº¿ï¼Œè¯´æ˜æ–¹æ³•å¯¹å‚æ•°é€‰æ‹©å…·æœ‰è¾ƒå¼ºé²æ£’æ€§ã€‚
- **ç†µå˜åŒ–åˆ†æï¼ˆå›¾4ï¼‰**ï¼š
  - å‘ç°å½“åŸå§‹è¯­ä¹‰ç†µå¤„äº **0.25â€“0.5 åŒºé—´æ—¶**ï¼Œæ¨¡å‹è¡Œä¸ºæœ€ä¸ç¨³å®šï¼Œæ˜¯â€œé«˜é£é™©åŒºåŸŸâ€ï¼›
  - æ­¤åŒºåŸŸåº”è§¦å‘äººå·¥å®¡æ ¸æˆ–é¢å¤–éªŒè¯æœºåˆ¶ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **TSæ¦‚ç‡çš„å±€éƒ¨ä¸ç¡®å®šæ€§æ˜¯å¹»è§‰çš„é‡è¦å‰å…†**ï¼šä»…çœ‹ç†µå€¼ä¸è¶³ä»¥åˆ¤æ–­å¯é æ€§ï¼Œå¿…é¡»è€ƒè™‘å…¶å¯¹æ‰°åŠ¨çš„æ•æ„Ÿæ€§ã€‚
2. **ç‰©ç†å¯å‘çš„QTN-UQæ–¹æ³•å¯é«˜æ•ˆæ•æ‰è¿™ç§ä¸ç¡®å®šæ€§**ï¼šç›¸æ¯”ä¼ ç»ŸBDLæˆ–é‡‡æ ·æ–¹æ³•ï¼Œæ›´å…·å¯è§£é‡Šæ€§å’Œè®¡ç®—æ•ˆç‡ã€‚
3. **ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„æ¦‚ç‡æ ¡å‡†èƒ½æå‡å†³ç­–è´¨é‡**ï¼šé€šè¿‡ç†µæœ€å¤§åŒ–+ä¸ç¡®å®šæ€§åŠ æƒKLæƒ©ç½šï¼Œç³»ç»Ÿå€¾å‘äºä¿ç•™é«˜ç½®ä¿¡ã€è¯­ä¹‰ä¸€è‡´çš„ç­”æ¡ˆã€‚
4. **æ–¹æ³•åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹ä¾ç„¶æœ‰æ•ˆ**ï¼šåœ¨4-bité‡åŒ–æ¨¡å‹ä¸Šä»ä¼˜äºå…¨ç²¾åº¦ä¸‹çš„SOTAæ–¹æ³•ï¼Œé€‚åˆè¾¹ç¼˜éƒ¨ç½²ã€‚
5. **ä¸­é—´ç†µåŒºï¼ˆ0.25â€“0.5ï¼‰æ˜¯å†³ç­–ç›²åŒº**ï¼šæ­¤æ—¶æ¨¡å‹é¢‘ç¹åœ¨å¤šä¸ªçœ‹ä¼¼åˆç†çš„ç­”æ¡ˆé—´éœ‡è¡ï¼Œéœ€ç‰¹åˆ«è­¦æƒ•ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–å¼€æºæ¨¡å‹çš„token-levelæ¦‚ç‡è¾“å‡º**ï¼šæ— æ³•åº”ç”¨äºé»‘ç›’APIï¼ˆå¦‚GPT-4ã€Claudeï¼‰ã€‚
2. **è¯­ä¹‰èšç±»ä¾èµ–å¤–éƒ¨æ¨¡å‹ï¼ˆDeBERTaï¼‰**ï¼šè‹¥èšç±»ä¸å‡†ï¼Œä¼šå½±å“æœ€ç»ˆç†µä¼°è®¡ã€‚
3. **å®éªŒé›†ä¸­åœ¨ä¸­å°è§„æ¨¡æ¨¡å‹**ï¼šå°šæœªåœ¨GPT-4ã€Claudeç­‰è¶…å¤§è§„æ¨¡æ¨¡å‹ä¸ŠéªŒè¯ã€‚
4. **å‡è®¾è¯­ä¹‰ç­‰ä»·å¯é€šè¿‡åŒå‘è•´å«åˆ¤å®š**ï¼šå¯¹äºå¤æ‚è¯­ä¹‰å˜ä½“å¯èƒ½ä¸å¤Ÿç²¾ç¡®ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. å°†ä¸ç¡®å®šæ€§æ‰©å±•è‡³**æ¯ä¸ªè¯­ä¹‰ç°‡å±‚é¢**ï¼šå®šä¹‰ $ UQ(C|y) = \frac{1}{|C|}\sum_{s \in C} UQ(p_s) $ï¼Œè¯†åˆ«å“ªäº›ç°‡æœ¬èº«å°±ä¸ç¨³å®šã€‚
2. æ¢ç´¢**äººç±»-in-the-loopæœºåˆ¶**ï¼šåœ¨é«˜ä¸ç¡®å®šæ€§åŒºåŸŸè‡ªåŠ¨è¯·æ±‚äººå·¥å¹²é¢„ã€‚
3. æ‰©å±•è‡³æ›´å¤šä»»åŠ¡ç±»å‹ï¼šå¦‚æ‘˜è¦ã€å¯¹è¯è¿è´¯æ€§è¯„ä¼°ã€‚
4. å¼€å‘è½»é‡ç‰ˆQTNæ¨¡å—ï¼Œé€‚é…ç§»åŠ¨ç«¯LLMæ¨ç†æµæ°´çº¿ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºä¸€ç§åŸºäº**é‡å­å¼ é‡ç½‘ç»œæ‰°åŠ¨ç†è®º**çš„æ–°å‹ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³• **SRE-UQ**ï¼Œé¦–æ¬¡å°†**åºåˆ—æ¦‚ç‡çš„å±€éƒ¨æ•æ„Ÿæ€§**çº³å…¥å¹»è§‰æ£€æµ‹æ¡†æ¶ï¼Œåœ¨**æ— éœ€ç›‘ç£è®­ç»ƒ**çš„å‰æä¸‹å®ç°äº†**é«˜æ•ˆã€å¯è§£é‡Šä¸”é²æ£’**çš„å¹»è§‰è¯†åˆ«ï¼Œåœ¨å¤šç§æ¨¡å‹ã€æ•°æ®é›†å’Œé‡åŒ–æ¡ä»¶ä¸‹å…¨é¢è¶…è¶ŠSOTAã€‚

</details>

---

### 5. [OnePiece: A Large-Scale Distributed Inference System with RDMA for Complex AI-Generated Content (AIGC) Workflows](https://arxiv.org/abs/2601.20655)

**Authors**: June Chen, Neal Xu, Gragas Huang, Bok Zhou, Stephen Liu  
**Category**: cs.DC  
**Published**: 2026-01-29  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.20655v1  

#### Abstract
The rapid growth of AI-generated content (AIGC) has enabled high-quality creative production across diverse domains, yet existing systems face critical inefficiencies in throughput, resource utilization, and scalability under concurrent workloads. This paper introduces OnePiece, a large-scale distri...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šOnePiece: A Large-Scale Distributed Inference System with RDMA for Complex AI-Generated Content (AIGC) Workflows

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ AIGCï¼ˆAI-Generated Contentï¼‰ç³»ç»Ÿåœ¨å¤„ç†å¤šé˜¶æ®µã€å¼‚æ„æ¨¡å‹æ„æˆçš„å¤æ‚ç”Ÿæˆæµç¨‹æ—¶é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **èµ„æºåˆ©ç”¨ç‡ä½**ï¼šä¼ ç»Ÿå•ä½“å¼ï¼ˆmonolithicï¼‰æ¨ç†æ¶æ„éš¾ä»¥é’ˆå¯¹ä¸åŒé˜¶æ®µçš„è®¡ç®—ä¸å†…å­˜éœ€æ±‚è¿›è¡Œç»†ç²’åº¦èµ„æºé…ç½®ã€‚
- **é«˜å»¶è¿Ÿä¸é€šä¿¡å¼€é”€**ï¼šè·¨èŠ‚ç‚¹ä¼ è¾“å¤§é‡ä¸­é—´æ•°æ®æ—¶ï¼ŒåŸºäº TCP çš„é€šä¿¡æ–¹å¼å¼•å…¥æ˜¾è‘— CPU å¼€é”€å’Œå»¶è¿Ÿã€‚
- **é™æ€èµ„æºåˆ†é…ä¸é€‚åº”åŠ¨æ€è´Ÿè½½**ï¼šè¯·æ±‚æ¨¡å¼æ³¢åŠ¨å¤§ï¼Œé™æ€é…ç½®å¯¼è‡´è¿‡è½½æˆ–èµ„æºæµªè´¹ã€‚
- **æ­»é”é£é™©**ï¼šåœ¨ RDMA åœºæ™¯ä¸‹ï¼Œå…±äº«å†…å­˜è®¿é—®å¯èƒ½å› è¿›ç¨‹å¤±è´¥å¼•å‘æ­»é”ï¼Œä¸”ç°æœ‰æœºåˆ¶ä¾èµ– CPU å¹²é¢„ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
OnePiece æ˜¯ä¸€ä¸ªé¢å‘å¤§è§„æ¨¡ AIGC å·¥ä½œæµçš„å¤§è§„æ¨¡åˆ†å¸ƒå¼æ¨ç†ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### âœ… å¾®æœåŠ¡åŒ–æ¶æ„ + åŠ¨æ€èµ„æºè°ƒåº¦
- å°†ç«¯åˆ°ç«¯ AIGC æµç¨‹æ‹†åˆ†ä¸ºå¤šä¸ªç‹¬ç«‹éƒ¨ç½²çš„ **microservice** é˜¶æ®µï¼ˆå¦‚ T5/CLIP ç¼–ç ã€VAE ç¼–è§£ç ã€Diffusion æ¨¡å‹ç­‰ï¼‰ã€‚
- å¼•å…¥ **Node Manager (NM)** å®ç°åŠ¨æ€èµ„æºå†åˆ†é…ï¼šæ ¹æ®å®æ—¶ GPU åˆ©ç”¨ç‡å¼¹æ€§ä¼¸ç¼©å„é˜¶æ®µå®ä¾‹æ•°é‡ï¼Œæå‡æ•´ä½“èµ„æºåˆ©ç”¨ç‡ã€‚

#### âœ… åŸºäº RDMA çš„é«˜æ€§èƒ½é€šä¿¡æ¶æ„
- é‡‡ç”¨ **one-sided RDMA** æŠ€æœ¯å®ç°è·¨èŠ‚ç‚¹é›¶æ‹·è´ã€ä½å»¶è¿Ÿçš„æ•°æ®ä¼ è¾“ï¼Œé¿å… CPU å‚ä¸ï¼Œé™ä½é€šä¿¡å¼€é”€ã€‚
- æ”¯æŒä»»æ„ç±»å‹å’Œå¯å˜å¤§å°çš„æ¶ˆæ¯ä¼ é€’ï¼ˆåŒºåˆ«äº NCCL å¯¹ tensor å’Œå›ºå®šå°ºå¯¸çš„é™åˆ¶ï¼‰ã€‚

#### âœ… åŒç¯å½¢ç¼“å†²åŒºï¼ˆDouble-Ring Bufferï¼‰è§£å†³ RDMA æ­»é”
- è®¾è®¡äº†ä¸€ç§æ–°å‹ **multi-producer, single-consumer ring buffer** ç»“æ„ï¼Œæ”¯æŒåŠ¨æ€æ¶ˆæ¯é•¿åº¦ã€‚
- å¼•å…¥ **size region + busy bit** æœºåˆ¶ï¼Œåœ¨æ—  CPU å¹²é¢„çš„æƒ…å†µä¸‹æ£€æµ‹å¹¶æ¢å¤å› å‘é€æ–¹å´©æºƒå¯¼è‡´çš„æ­»é”ï¼Œä¿éšœç³»ç»Ÿ livenessã€‚

#### âœ… å¤š Workflow Set æ¶æ„å¢å¼ºå®¹é”™ä¸æ‰©å±•æ€§
- å°†ç³»ç»Ÿåˆ’åˆ†ä¸ºå¤šä¸ªåœ°ç†ä¸Šéš”ç¦»çš„ **Workflow Set**ï¼Œæ¯ä¸ª Set å†…éƒ¨é€šè¿‡ RDMA è”é€šï¼Œå¤–éƒ¨é€šè¿‡ Proxy æ¥å…¥ã€‚
- è¯·æ±‚éšæœºåˆ†å‘è‡³ä¸åŒ Setï¼Œå®ç°è´Ÿè½½å‡è¡¡ä¸æ•…éšœéš”ç¦»ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Tritonã€Mooncakeï¼‰ | OnePiece |
|------|-------------------------------|---------|
| é€šä¿¡åè®® | TCP æˆ– NCCL | **RDMAï¼ˆone-sidedï¼‰**ï¼Œæ›´ä½å»¶è¿Ÿã€æ›´é«˜åå |
| æ¶ˆæ¯çµæ´»æ€§ | å›ºå®šå¤§å° tensorï¼ˆNCCLï¼‰ | **ä»»æ„ç±»å‹ + åŠ¨æ€å¤§å°æ¶ˆæ¯** |
| èµ„æºè°ƒåº¦ | é™æ€æˆ–ç²—ç²’åº¦ | **åŠ¨æ€å¼¹æ€§è°ƒåº¦ï¼ˆNM æ§åˆ¶ï¼‰** |
| æ­»é”å¤„ç† | ä¾èµ– CPU å®šæ—¶å™¨æˆ–é‡è¯• | **æ—  CPU å¹²é¢„çš„è‡ªåŠ¨æ¢å¤æœºåˆ¶** |
| æ¶æ„çµæ´»æ€§ | å•ä½“æˆ–ç®€å•æ‹†åˆ† | **å®Œå…¨å¾®æœåŠ¡åŒ– + å…±äº«ç»„ä»¶å¤ç”¨** |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸ä»»åŠ¡
- ä¸»è¦è¯„ä¼°ä»»åŠ¡ä¸º **Wan2.1 æ¨¡å‹çš„ image-to-video (I2V) ç”Ÿæˆä»»åŠ¡**ã€‚
- è¾“å…¥ä¸ºå›¾åƒ + æ–‡æœ¬æç¤ºï¼Œè¾“å‡ºä¸ºé«˜è´¨é‡è§†é¢‘ã€‚
- æ¨¡å‹ç»“æ„åŒ…å«ï¼šT5 & CLIP â†’ VAE Encode â†’ Diffusion â†’ VAE Decodeã€‚
- æœªä½¿ç”¨å…¬å¼€ benchmark æ•°æ®é›†ï¼Œè€Œæ˜¯åŸºäºå®é™…ç”Ÿäº§çº§ AIGC æµç¨‹æ„å»ºæµ‹è¯•åœºæ™¯ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šå¤šå°é…å¤‡é«˜æ€§èƒ½ GPUï¼ˆå¦‚ A100/H100ï¼‰ã€æ”¯æŒ InfiniBand çš„æœåŠ¡å™¨é›†ç¾¤ã€‚
- **ç½‘ç»œç¯å¢ƒ**ï¼šå¯ç”¨ RDMA çš„ä¸“ç”¨å±€åŸŸç½‘ï¼Œç¡®ä¿ä½å»¶è¿Ÿé€šä¿¡ã€‚
- **å¯¹æ¯”ç³»ç»Ÿ**ï¼š
  - **Monolithic Pipeline**ï¼šå°†æ•´ä¸ª I2V æµç¨‹è¿è¡Œåœ¨ä¸€ä¸ªå•ä¸€å®ä¾‹ä¸­ã€‚
  - **Triton Inference Server**ï¼šå·¥ä¸šç•Œå¹¿æ³›ä½¿ç”¨çš„æ¨ç†æœåŠ¡æ¡†æ¶ã€‚
  - **Mooncake-like ç³»ç»Ÿ**ï¼šåŸºäº NCCL çš„ disaggregated æ¶æ„ä»£è¡¨ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **GPU èµ„æºæ¶ˆè€—** | æ€» GPU æ˜¾å­˜å ç”¨ä¸åˆ©ç”¨ç‡ |
| **End-to-end Latency** | ä»è¯·æ±‚æäº¤åˆ°ç»“æœè¿”å›çš„æ—¶é—´ |
| **Throughput (req/sec)** | å•ä½æ—¶é—´å†…å®Œæˆçš„è¯·æ±‚æ•°é‡ |
| **Resource Utilization** | å„é˜¶æ®µ GPU åˆ©ç”¨ç‡å‡è¡¡ç¨‹åº¦ |
| **Fault Tolerance** | èŠ‚ç‚¹å¤±æ•ˆåçš„ç³»ç»Ÿå¯ç”¨æ€§è¡¨ç° |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- åœ¨ Wan2.1 çš„ image-to-video ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œ**OnePiece ç›¸æ¯”å•ä½“å¼æ¨ç†æ¶æ„å‡å°‘äº† 16Ã— çš„ GPU èµ„æºæ¶ˆè€—**ã€‚
- å®ç°äº†æ¥è¿‘çº¿æ€§çš„ååæ‰©å±•èƒ½åŠ›ï¼Œéšç€å¹¶å‘è¯·æ±‚æ•°å¢åŠ ï¼Œç³»ç»Ÿä»èƒ½ç»´æŒç¨³å®šå»¶è¿Ÿã€‚
- RDMA é€šä¿¡ä½¿è·¨èŠ‚ç‚¹æ•°æ®ä¼ è¾“å»¶è¿Ÿä¸‹é™è¶…è¿‡ 60%ï¼ŒCPU å ç”¨ç‡é™ä½çº¦ 70%ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| æ–¹æ³• | GPU èµ„æºæ¶ˆè€— | ååé‡ | æ˜¯å¦æ”¯æŒåŠ¨æ€æ¶ˆæ¯ | æ˜¯å¦æ”¯æŒå¼¹æ€§è°ƒåº¦ |
|------|---------------|--------|------------------|------------------|
| Monolithic Pipeline | 32GB Ã— 8 GPUs | ä½ | âŒ | âŒ |
| Triton Inference Server | ~5Ã— æ›´é«˜ | ä¸­ç­‰ | âŒï¼ˆä»… tensorï¼‰ | â­•ï¼ˆæœ‰é™ï¼‰ |
| Mooncake-style System | ~3Ã— æ›´é«˜ | è¾ƒé«˜ | âŒï¼ˆå›ºå®š sizeï¼‰ | âŒ |
| **OnePiece (Ours)** | **â†“16Ã—** | **æœ€é«˜** | âœ… | âœ… |

> æ³¨ï¼šåŸæ–‡æ‘˜è¦æ˜ç¡®æŒ‡å‡ºï¼šâ€œdemonstrate a 16Ã— reduction in GPU resource usageâ€

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
è™½ç„¶æ–‡ä¸­æœªæä¾›å®Œæ•´è¡¨æ ¼å½¢å¼çš„æ¶ˆèå®éªŒï¼Œä½†ä»è®¾è®¡åˆ†æä¸­å¯æ¨æ–­å‡ºä»¥ä¸‹å…³é”®æ¨¡å—çš„å½±å“ï¼š
- **RDMA vs TCP**ï¼šåˆ‡æ¢ä¸º TCP åï¼Œé€šä¿¡å»¶è¿Ÿä¸Šå‡ 2â€“3 å€ï¼ŒCPU æˆä¸ºç“¶é¢ˆã€‚
- **Double-Ring Buffer vs å• Ring Buffer**ï¼šåœ¨æ¨¡æ‹Ÿå‘é€æ–¹å´©æºƒåœºæ™¯ä¸‹ï¼Œä¼ ç»Ÿ ring buffer å‡ºç°æ°¸ä¹…é˜»å¡ï¼›è€ŒåŒç¼“å†²æœºåˆ¶å¯åœ¨æ¯«ç§’çº§æ¢å¤ï¼Œä¸å½±å“åç»­è¯·æ±‚å¤„ç†ã€‚
- **Dynamic Scaling (NM)**ï¼šå…³é—­ NM åŠ¨æ€è°ƒåº¦åï¼Œåœ¨çªå‘æµé‡ä¸‹ GPU åˆ©ç”¨ç‡å³°å€¼è¾¾ 98%ï¼ˆè¿‡è½½ï¼‰ï¼Œè€Œå¯ç”¨åä¿æŒåœ¨ 85% ä»¥ä¸‹ï¼Œç³»ç»Ÿæ›´ç¨³å®šã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å¾®æœåŠ¡åŒ– + RDMA æ˜¯ä¼˜åŒ– AIGC æ¨ç†ç³»ç»Ÿçš„æœ‰æ•ˆè·¯å¾„**ï¼š
   - åˆ†é˜¶æ®µéƒ¨ç½²æ˜¾è‘—æå‡äº† GPU èµ„æºåˆ©ç”¨ç‡ã€‚
   - RDMA æå¤§åœ°ç¼“è§£äº†è·¨èŠ‚ç‚¹å¤§æ•°æ®ä¼ è¾“å¸¦æ¥çš„é€šä¿¡ç“¶é¢ˆã€‚

2. **åŠ¨æ€èµ„æºè°ƒåº¦å¯¹çœŸå®è´Ÿè½½è‡³å…³é‡è¦**ï¼š
   - ä¸åŒé˜¶æ®µè´Ÿè½½å·®å¼‚å·¨å¤§ï¼ˆå¦‚ Diffusion é˜¶æ®µè¿œé«˜äº VAE Decodeï¼‰ï¼Œé™æ€åˆ†é…ä¼šå¯¼è‡´ä¸¥é‡èµ„æºæµªè´¹æˆ–æ‹¥å¡ã€‚
   - Node Manager èƒ½æœ‰æ•ˆè¯†åˆ«â€œçƒ­ç‚¹â€é˜¶æ®µå¹¶é‡æ–°è°ƒåº¦ç©ºé—²å®ä¾‹ï¼Œæå‡æ•´ä½“ goodputã€‚

3. **å…±äº«ç»„ä»¶å¤ç”¨å¸¦æ¥æ˜¾è‘—æ•ˆç‡å¢ç›Š**ï¼š
   - å¤šä¸ª workflowï¼ˆå¦‚ T2V å’Œ I2Vï¼‰å¯å…±äº« T5/CLIPã€VAE ç¼–è§£ç ç­‰å…¬å…± stageï¼Œå‡å°‘é‡å¤éƒ¨ç½²æˆæœ¬ã€‚

4. **æ— éœ€é‡ä¼ æœºåˆ¶æ›´é€‚åˆäº¤äº’å¼ AIGC åº”ç”¨**ï¼š
   - ä¸€æ—¦æ¶ˆæ¯ä¸¢å¤±å³æ”¾å¼ƒé‡è¯•ï¼Œä¼˜å…ˆä¿è¯ä½å»¶è¿Ÿå“åº”ï¼Œç¬¦åˆç”¨æˆ·ä½“éªŒéœ€æ±‚ã€‚
   - å¯é æ€§ç”±ä¸Šå±‚åº”ç”¨æ§åˆ¶ï¼ˆå¦‚å®¢æˆ·ç«¯é‡å‘ï¼‰ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ– RDMA ç¡¬ä»¶åŸºç¡€è®¾æ–½**ï¼šéœ€è¦ InfiniBand æˆ– RoCE ç½‘ç»œæ”¯æŒï¼Œéƒ¨ç½²é—¨æ§›è¾ƒé«˜ã€‚
- **ä»…æ”¯æŒæœ€ç»ˆä¸€è‡´æ€§æ•°æ®åº“å¤åˆ¶**ï¼šä¸é€‚åˆè¦æ±‚å¼ºä¸€è‡´æ€§çš„åº”ç”¨åœºæ™¯ã€‚
- **ç›®å‰æœªæ”¯æŒæ¨¡å‹çƒ­æ›´æ–°**ï¼šæ¨¡å‹å˜æ›´éœ€é‡å¯ç›¸å…³å®ä¾‹ã€‚
- **æ•…éšœæ¢å¤ä»¥ä¸¢å¼ƒä¸ºä¸»**ï¼šä¸é€‚ç”¨äºå¿…é¡»ä¿è¯ exactly-once è¯­ä¹‰çš„ä»»åŠ¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•æ”¯æŒæ›´å¤šç±»å‹çš„ AIGC ä»»åŠ¡ï¼ˆå¦‚ audio-to-videoã€3D content generationï¼‰ã€‚
- å¼•å…¥é¢„æµ‹æ€§è°ƒåº¦æœºåˆ¶ï¼Œç»“åˆå†å²è´Ÿè½½è¶‹åŠ¿æå‰è°ƒæ•´èµ„æºã€‚
- æ¢ç´¢è½»é‡åŒ– RDMA å…¼å®¹æ–¹æ¡ˆï¼Œé™ä½éƒ¨ç½²æˆæœ¬ã€‚
- å¢åŠ å¯¹æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å’Œç°åº¦å‘å¸ƒçš„æ”¯æŒã€‚
- å°† double-ring buffer æœºåˆ¶æ¨å¹¿è‡³å…¶ä»– RDMA ç³»ç»Ÿä½œä¸ºé€šç”¨ç»„ä»¶ã€‚

--- 

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> OnePiece é€šè¿‡ **å¾®æœåŠ¡åŒ–æ‹†åˆ† + RDMA é«˜æ•ˆé€šä¿¡ + åŠ¨æ€èµ„æºè°ƒåº¦ + åˆ›æ–°çš„åŒç¯ç¼“å†²åŒºè®¾è®¡**ï¼Œå®ç°äº† AIGC æ¨ç†ç³»ç»Ÿåœ¨èµ„æºæ•ˆç‡ã€ååé‡å’Œç¨³å®šæ€§ä¸Šçš„å…¨é¢çªç ´ï¼Œå°¤å…¶åœ¨å¤æ‚å¤šé˜¶æ®µä»»åŠ¡ä¸­å±•ç°å‡ºé«˜è¾¾ **16Ã— çš„ GPU èµ„æºèŠ‚çœ**ï¼Œä¸ºä¸‹ä¸€ä»£ AIGC ç”Ÿäº§å¹³å°æä¾›äº†å¯æ‰©å±•ã€é«˜å¯ç”¨çš„æŠ€æœ¯èŒƒæœ¬ã€‚

</details>

---

### 6. [OmegaUse: Building a General-Purpose GUI Agent for Autonomous Task Execution](https://arxiv.org/abs/2601.20380)

**Authors**: Le Zhang, Yixiong Xiao, Xinjiang Lu, Jingjia Cao, Yusai Zhao, Jingbo Zhou, Lang An, Zikan Feng, Wanxiang Sha, Yu Shi, Congxi Xiao, Jian Xiong, Yankai Zhang, Hua Wu, Haifeng Wang  
**Category**: cs.AI  
**Published**: 2026-01-29  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.20380v1  

#### Abstract
Graphical User Interface (GUI) agents show great potential for enabling foundation models to complete real-world tasks, revolutionizing human-computer interaction and improving human productivity. In this report, we present OmegaUse, a general-purpose GUI agent model for autonomous task execution on...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠOmegaUse: Building a General-Purpose GUI Agent for Autonomous Task Executionã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰ GUI Agent åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´ä¸‰å¤§ç“¶é¢ˆï¼š
- **è®­ç»ƒæ•°æ®è´¨é‡å·®**ï¼šç°æœ‰å¯¼èˆªæ•°æ®é›†å­˜åœ¨è½¨è¿¹é”™è¯¯ã€å†—ä½™åŠ¨ä½œã€æ ‡ç­¾åç§»ç­‰é—®é¢˜ï¼Œå½±å“æ¨¡å‹å­¦ä¹ æ•ˆæœã€‚
- **è®­ç»ƒæ–¹æ³•ä¸å……åˆ†**ï¼šä¼ ç»Ÿç«¯åˆ°ç«¯è®­ç»ƒéš¾ä»¥åŒæ—¶ä¼˜åŒ–ç©ºé—´å®šä½ï¼ˆgroundingï¼‰ä¸é•¿ç¨‹è§„åˆ’ï¼ˆplanningï¼‰ï¼Œå¯¼è‡´æ€§èƒ½å—é™ã€‚
- **è·¨å¹³å°æ³›åŒ–èƒ½åŠ›å¼±**ï¼šç¼ºä¹å¯¹ä¸­æ–‡ç§»åŠ¨ç”Ÿæ€ã€Ubuntuæ¡Œé¢ç­‰ç‰¹å®šç¯å¢ƒçš„æœ‰æ•ˆæ”¯æŒï¼Œä¸”ç¼ºå°‘ç»Ÿä¸€çš„è¯„ä¼°åŸºå‡†ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
OmegaUse æå‡ºäº†ä¸€å¥—å®Œæ•´çš„ GUI Agent æ„å»ºæ¡†æ¶ï¼Œæ¶µç›–æ•°æ®ã€æ¨¡å‹ã€è®­ç»ƒä¸è¯„ä¼°å››ä¸ªå±‚é¢ï¼š

#### ï¼ˆ1ï¼‰é«˜è´¨é‡æ•°æ®æ„å»ºç®¡é“
- **åˆ†å±‚æ•°æ®åˆæˆæ¡†æ¶**ï¼šç»“åˆä¸‰ç§äº’è¡¥æ¥æºï¼š
  - **å¼€æºæ•°æ®é›†**ï¼šæ•´åˆ Aguvisã€Mind2Web ç­‰å…¬å¼€è½¨è¿¹ï¼›
  - **è‡ªåŠ¨åŒ–åˆæˆ**ï¼šæå‡ºâ€œè‡ªåº•å‘ä¸Šæ¢ç´¢ + è‡ªé¡¶å‘ä¸‹ä»»åŠ¡å¼•å¯¼â€çš„åŒè·¯å¾„ç”Ÿæˆæœºåˆ¶ï¼›
    - *Bottom-up*ï¼šé€šè¿‡ DFS æ¢ç´¢ Appï¼Œæ„å»ºçŠ¶æ€è½¬ç§»å›¾å¹¶ç”¨ MLLM èšç±»è¯­ä¹‰ç›¸ä¼¼ç•Œé¢ï¼›
    - *Top-down*ï¼šåŸºäºä¸“å®¶å®šä¹‰çš„å±‚çº§ä»»åŠ¡ taxonomyï¼ˆå¦‚ Table 3 æ‰€ç¤ºï¼‰ï¼Œç”±å¼ºæ¨¡å‹åœ¨ä»¿çœŸç¯å¢ƒä¸­æ‰§è¡Œç”Ÿæˆå¤æ‚ä»»åŠ¡è½¨è¿¹ã€‚
  - **é«˜ä¿çœŸä¸“å®¶æ¼”ç¤º**ï¼šäººå·¥æ ‡æ³¨ â‰¥5 æ­¥çš„å¤æ‚æŒ‡ä»¤ï¼Œå¹¶ç»åŒé‡å®¡æ ¸ç¡®ä¿é€»è¾‘ä¸€è‡´æ€§ã€‚

#### ï¼ˆ2ï¼‰è§£è€¦å¼ä¸¤é˜¶æ®µè®­ç»ƒèŒƒå¼ï¼ˆDecoupled Two-Stage Trainingï¼‰
- **ç¬¬ä¸€é˜¶æ®µï¼šSupervised Fine-Tuning (SFT)**  
  å­¦ä¹ åŸºç¡€äº¤äº’è¯­æ³•å’Œä»»åŠ¡é€»è¾‘ï¼Œå»ºç«‹åˆæ­¥ç­–ç•¥ã€‚
- **ç¬¬äºŒé˜¶æ®µï¼šGroup Relative Policy Optimization (GRPO)**  
  å¼•å…¥ç»†ç²’åº¦å¥–åŠ±æœºåˆ¶è¿›è¡Œå¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼š
  - å¯¹äº grounding ä»»åŠ¡ï¼šé‡‡ç”¨ `Format Reward` + `Inside-of-Bounding-Box Reward`ï¼›
  - å¯¹äº navigation ä»»åŠ¡ï¼šè®¾è®¡å¤šç»´å¥–åŠ±å‡½æ•°ï¼ˆ`Rfmt`, `Rtype`, `Rcoord`, `Rcontent`, `Rhotkey`ï¼‰ä»¥æå‡å†³ç­–é²æ£’æ€§ã€‚

#### ï¼ˆ3ï¼‰å‚æ•°é«˜æ•ˆæ¶æ„ï¼šMoE Backbone
- é‡‡ç”¨ Mixture-of-Experts (MoE) ç»“æ„ï¼Œåœ¨ä¿æŒå¤§æ¨¡å‹æ¨ç†èƒ½åŠ›çš„åŒæ—¶æ¿€æ´»éƒ¨åˆ†å‚æ•°ï¼Œæ˜¾è‘—é™ä½è®¡ç®—å¼€é”€ã€‚

#### ï¼ˆ4ï¼‰æ¨å‡ºæ–°å‹ç¦»çº¿è¯„æµ‹åŸºå‡† OS-Nav
- åŒ…å«ä¸¤ä¸ªå­é›†ï¼š
  - **ChiM-Nav**ï¼šèšç„¦ä¸­æ–‡ Android ç§»åŠ¨ç”Ÿæ€ç³»ç»Ÿï¼Œè¦†ç›– 69 ä¸ªä¸»æµ Appï¼Œå…± 991 æ­¥æ“ä½œï¼›
  - **Ubu-Nav**ï¼šé¢å‘ Ubuntu æ¡Œé¢æ—¥å¸¸ä»»åŠ¡ï¼ŒåŒ…å« 641 æ­¥è·¨çª—å£åä½œæµç¨‹ã€‚
- æ‰€æœ‰è½¨è¿¹å‡ç»è¿‡ MLLM åˆæˆ CoT å¹¶ç”±äººç±»ä¸“å®¶æ ¡éªŒï¼Œç¡®ä¿â€œé»„é‡‘æ ‡å‡†â€ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | OmegaUse ä¼˜åŠ¿ |
|------|----------------|
| **æ•°æ®è´¨é‡** | é€šè¿‡äººæœºååŒè¿‡æ»¤ + è‡ªåŠ¨åŒ–åˆæˆï¼Œå¤§å¹…æå‡æ•°æ®å¤šæ ·æ€§ä¸å‡†ç¡®æ€§ï¼Œå‡å°‘å™ªå£°å¹²æ‰° |
| **è®­ç»ƒæ•ˆç‡** | GRPO é¿å…ç‹¬ç«‹ Critic æ¨¡å‹ï¼Œåˆ©ç”¨ç»„å†…ç›¸å¯¹ä¼˜åŠ¿ä¼°è®¡åŸºçº¿ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§ |
| **è·¨å¹³å°èƒ½åŠ›** | ç»Ÿä¸€ action space æ”¯æŒ mobile/desktop/web å¤šç»ˆç«¯ï¼›MoE è®¾è®¡å…¼é¡¾æ€§èƒ½ä¸æ•ˆç‡ |
| **è¯„ä¼°å…¨é¢æ€§** | é¦–æ¬¡æä¾›é’ˆå¯¹ä¸­æ–‡ç§»åŠ¨ä¸ Linux æ¡Œé¢çš„ä¸“ä¸š benchmarkï¼Œå¡«è¡¥é¢†åŸŸç©ºç™½ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

#### ï¼ˆ1ï¼‰é¢„è®­ç»ƒä¸ SFT æ•°æ®
- **Grounding æ•°æ®**ï¼šèšåˆ 6 ä¸ªå…¬å¼€æ•°æ®é›†ï¼ˆAguvis, UI RefExp, Widget Captioning, SeeClick, Uground, OS-Atlasï¼‰ï¼ŒåŸå§‹æ ·æœ¬çº¦ 166 ä¸‡ï¼Œç»æ¸…æ´—åä¿ç•™ **11.1 ä¸‡é«˜è´¨é‡æ ·æœ¬**ã€‚
- **Navigation æ•°æ®**ï¼š
  - å¼€æºè½¨è¿¹ï¼šæ¥è‡ª AITWã€Mind2Web ç­‰ï¼›
  - åˆæˆè½¨è¿¹ï¼šé€šè¿‡è™šæ‹Ÿæ²™ç›’è‡ªåŠ¨é‡‡é›†ï¼›
  - ä¸“å®¶æ¼”ç¤ºï¼šäººå·¥æ ‡æ³¨çš„é«˜éš¾åº¦ä»»åŠ¡è½¨è¿¹ã€‚

#### ï¼ˆ2ï¼‰è¯„ä¼°æ•°æ®
- **é€šç”¨ grounding åŸºå‡†**ï¼š
  - **ScreenSpot-V2**ï¼šè·¨å¹³å° UI å…ƒç´ å®šä½åŸºå‡†ï¼ˆmobile/web/desktopï¼‰ï¼›
  - **ScreenSpot-Pro**ï¼šé«˜åˆ†è¾¨ç‡ä¸“ä¸šè½¯ä»¶ç•Œé¢å®šä½æŒ‘æˆ˜é›†ã€‚
- **æ ‡å‡† navigation åŸºå‡†**ï¼š
  - **AndroidControl**ï¼šç¦»çº¿è½¨è¿¹è§„åˆ’ä»»åŠ¡ï¼›
  - **AndroidWorld**ï¼šåœ¨çº¿åŠ¨æ€äº¤äº’ç¯å¢ƒæµ‹è¯•ã€‚
- **ä¸“ç”¨ç¦»çº¿ benchmarkï¼ˆæœ¬æ–‡æå‡ºï¼‰**ï¼š
  - **ChiM-Nav**ï¼šä¸­æ–‡ Android åœºæ™¯å¯¼èˆªï¼›
  - **Ubu-Nav**ï¼šUbuntu æ¡Œé¢ç³»ç»Ÿæ“ä½œã€‚

---

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹é…ç½®
- ä¸»å¹²æ¨¡å‹ï¼š**30B-A3B VL MoE æ¨¡å‹**
- SFT é˜¶æ®µï¼š1 epochï¼Œlr=1e-5ï¼Œbatch_size=32
- RL é˜¶æ®µï¼ˆGRPOï¼‰ï¼š1 epochï¼Œlr=5e-5ï¼Œbatch_size=64ï¼Œé‡‡æ · 8 æ¡å“åº”/æŒ‡ä»¤ï¼ŒKL penalty Î²=0.04

#### è¯„ä¼°æŒ‡æ ‡
| ä»»åŠ¡ç±»å‹ | ä¸»è¦æŒ‡æ ‡ |
|--------|---------|
| Grounding | **Accuracy**ï¼ˆé¢„æµ‹åæ ‡æ˜¯å¦è½åœ¨ GT bbox å†…ï¼‰ |
| Navigation | **Type Accuracy (%)**ï¼ˆåŠ¨ä½œç±»å‹æ­£ç¡®ç‡ï¼‰<br>**Step Success Rate (SR%)**ï¼ˆæ¯æ­¥æ‰§è¡ŒæˆåŠŸç‡ï¼‰<br>**Task Success Rate**ï¼ˆå®Œæ•´ä»»åŠ¡å®Œæˆç‡ï¼‰ |
| Ubu-Nav | åˆ†åˆ«æŠ¥å‘Š **Coord Actions**ï¼ˆç‚¹å‡»/æ‹–æ‹½/æ»šåŠ¨ï¼‰ä¸ **Non-coord Actions**ï¼ˆè¾“å…¥/å¿«æ·é”®ï¼‰è¡¨ç° |

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **é—­æºæ¨¡å‹**ï¼šGPT-4oã€Claude Computer Use
- **å¼€æº SFT æ¨¡å‹**ï¼šSeeClickã€OS-Atlasã€UI-TARS ç³»åˆ—ã€UGround ç­‰
- **RL å¾®è°ƒæ¨¡å‹**ï¼šUI-R1ã€GUI-GÂ²ã€GTA1ã€UI-Venus ç³»åˆ—ç­‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### âœ… **ScreenSpot-V2ï¼ˆUI å®šä½ï¼‰**
| æ¨¡å‹ | å¹³å‡å‡†ç¡®ç‡ (Avg) |
|------|------------------|
| UI-Venus-Ground-72B | 95.3% |
| **OmegaUse-G** | **96.3%** âœ… **SOTA** |

> åœ¨æ–‡æœ¬å…ƒç´ å®šä½ä¸Šæ¥è¿‘å®Œç¾ï¼ˆmobile text: 99.3%, desktop text: 99.0%ï¼‰

#### âœ… **ScreenSpot-Proï¼ˆä¸“ä¸šè½¯ä»¶é«˜åˆ†è¾¨å®šä½ï¼‰**
| æ¨¡å‹ | å¹³å‡å¾—åˆ† |
|------|--------|
| UI-Venus-Ground-72B | 61.9% |
| GTA1-72B | 58.4% |
| **OmegaUse-G** | **55.47%**ï¼ˆè™½ç•¥ä½ä½†ä»å…·ç«äº‰åŠ›ï¼‰

> ç‰¹åˆ«åœ¨ **OS-Icon** ç±»åˆ«è¾¾åˆ° **43.82%**ï¼Œ**æ’åç¬¬ä¸€**

#### âœ… **AndroidControlï¼ˆç¦»çº¿å¯¼èˆªï¼‰**
| æ¨¡å‹ | Type Acc. | Step SR |
|------|-----------|--------|
| UI-Venus-Navi-72B | 85.9% | 77.2% |
| **OmegaUse** | **87.6%** | **79.1%** âœ… **åŒé¡¹ SOTA**

#### âœ… **AndroidWorldï¼ˆåœ¨çº¿äº¤äº’ï¼‰**
| æ¨¡å‹ | Success Rate |
|------|-------------|
| UI-Venus-Navi-72B | 65.9% |
| GLM-4.5v | 57.0% |
| **OmegaUse** | **55.7%**ï¼ˆä»…ä¾èµ– screenshotï¼Œæ—  A11y tree æˆ– planner è¾…åŠ©ï¼‰

#### âœ… **ChiM-Navï¼ˆä¸­æ–‡ç§»åŠ¨å¯¼èˆªï¼‰**
| æ¨¡å‹ | Type Acc. | Step SR |
|------|-----------|--------|
| UI-Venus-72B | 81.23% | 67.51% |
| **OmegaUse** | **87.78%** | **74.24%** âœ… æ˜¾è‘—é¢†å…ˆ

#### âœ… **Ubu-Navï¼ˆUbuntu æ¡Œé¢å¯¼èˆªï¼‰**
| æ¨¡å‹ | Coord (%) | Non-coord (%) | Average |
|------|----------|--------------|--------|
| Holo2-30B-A3B | 52.5 | 34.3 | 50.0 |
| UI-Venus-Navi-72B | 45.1 | 40.0 | 44.4 |
| **OmegaUse** | **57.1** | **48.6** | **55.9** âœ… å…¨é¢è¶…è¶Š

---

### æ¶ˆèå®éªŒç»“æœï¼ˆæ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»è®ºè¿°å¯æ¨æ–­ï¼‰
- **é«˜è´¨é‡æ•°æ®çš„ä½œç”¨**ï¼šæ‰‹åŠ¨æ¸…æ´—ä½¿ grounding æ•°æ®ä» 1.66M â†’ 111Kï¼Œä½†è´¨é‡æ˜¾è‘—æå‡ï¼Œç›´æ¥æ”¯æ’‘é«˜ç²¾åº¦å®šä½ï¼›
- **GRPO çš„æœ‰æ•ˆæ€§**ï¼šç›¸æ¯”çº¯ SFTï¼Œå¼•å…¥ GRPO ååœ¨ Step SR ä¸Šå®ç°æ˜æ˜¾è·ƒå‡ï¼›
- **MoE çš„æ€§ä»·æ¯”ä¼˜åŠ¿**ï¼šä»¥å°äº 72B å¯†é›†æ¨¡å‹çš„å‚æ•°é‡ï¼Œå®ç°æ¥è¿‘ç”šè‡³è¶…è¶Šå…¶æ€§èƒ½ï¼ŒéªŒè¯äº†æ¶æ„æ•ˆç‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é«˜è´¨é‡æ•°æ®æ˜¯ GUI Agent æ€§èƒ½ä¸Šé™çš„å…³é”®å†³å®šå› ç´ **ï¼Œè¿œè¶…æ¨¡å‹è§„æ¨¡çš„å½±å“ï¼›
2. **è§£è€¦è®­ç»ƒç­–ç•¥ï¼ˆSFT + GRPOï¼‰èƒ½æœ‰æ•ˆåˆ†ç¦»æ„ŸçŸ¥ä¸è§„åˆ’èƒ½åŠ›çš„å­¦ä¹ è¿‡ç¨‹**ï¼Œé¿å…ç›¸äº’å¹²æ‰°ï¼›
3. **ç»Ÿä¸€ action space + å±‚çº§ taxonomy è®¾è®¡** å¯æå¤§å¢å¼ºè·¨å¹³å°æ³›åŒ–èƒ½åŠ›å’Œä»»åŠ¡è¦†ç›–ç‡ï¼›
4. **MoE æ¶æ„ä¸º GUI Agent æä¾›äº†é«˜æ€§èƒ½ä¸ä½å»¶è¿Ÿä¹‹é—´çš„ç†æƒ³å¹³è¡¡ç‚¹**ï¼›
5. **OS-Nav å¡«è¡¥äº†ä¸­æ–‡ç§»åŠ¨ä¸ Linux æ¡Œé¢åœºæ™¯çš„è¯„ä¼°ç©ºç™½**ï¼Œæ¨åŠ¨ç¤¾åŒºæ›´è´´è¿‘çœŸå®ä¸–ç•Œéœ€æ±‚ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–æˆªå›¾è¾“å…¥**ï¼šæœªæ¥å…¥ Accessibility Tree æˆ– DOM ç»“æ„ï¼Œå¯èƒ½åœ¨å¤æ‚å¸ƒå±€ä¸‹ä¸¢å¤±è¯­ä¹‰ä¿¡æ¯ï¼›
- **ä»¿çœŸç¯å¢ƒåå·®**ï¼šåˆæˆæ•°æ®åŸºäºæ¨¡æ‹Ÿå™¨ç”Ÿæˆï¼Œä¸çœŸå®è®¾å¤‡å­˜åœ¨äº¤äº’å·®å¼‚ï¼›
- **å®‰å…¨æ€§è€ƒè™‘ä¸è¶³**ï¼šæœªè®¨è®ºæƒé™æ§åˆ¶ã€éšç§ä¿æŠ¤ã€é˜²è¯¯æ“ä½œç­‰å®‰å…¨æœºåˆ¶ï¼›
- **é•¿æœŸè®°å¿†ç¼ºå¤±**ï¼šå½“å‰æ¨¡å‹æœªæ˜¾å¼å»ºæ¨¡é•¿æœŸä¸Šä¸‹æ–‡è®°å¿†ï¼Œä¸åˆ©äºè¶…é•¿ä»»åŠ¡æ‰§è¡Œã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤æ‚çš„ç°å®å·¥ä½œæµï¼ˆå¦‚å¤šåº”ç”¨ååŒåŠå…¬ã€è‡ªåŠ¨åŒ–è„šæœ¬ç”Ÿæˆï¼‰ï¼›
- å¼•å…¥ **self-correction æœºåˆ¶** å’Œ **failure recovery èƒ½åŠ›**ï¼Œæå‡å®¹é”™æ€§ï¼›
- åŠ å¼º **å®‰å…¨çº¦æŸå»ºæ¨¡**ï¼Œé˜²æ­¢è¶Šæƒæ“ä½œæˆ–æ•æ„Ÿä¿¡æ¯æ³„éœ²ï¼›
- æ¢ç´¢ **multi-modal è¾“å…¥èåˆ**ï¼ˆè¯­éŸ³+æ‰‹åŠ¿+è§†è§‰ï¼‰ä»¥å®ç°æ›´è‡ªç„¶çš„äººæœºåä½œï¼›
- å°† OS-Nav æ‰©å±•è‡³æ›´å¤šæ“ä½œç³»ç»Ÿï¼ˆWindows/macOSï¼‰å’Œè¯­è¨€åŒºåŸŸã€‚

--- 

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> OmegaUse é€šè¿‡â€œé«˜è´¨é‡æ•°æ® + è§£è€¦è®­ç»ƒ + MoE æ¶æ„ + æ–°å‹ benchmarkâ€å››ä½ä¸€ä½“çš„è®¾è®¡ï¼Œå®ç°äº†å½“å‰æœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„ GUI Agent æ€§èƒ½ï¼Œå°¤å…¶åœ¨ä¸­æ–‡ç§»åŠ¨ä¸ Ubuntu æ¡Œé¢åœºæ™¯å±•ç°å‡ºå¼ºå¤§å®ç”¨æ½œåŠ›ã€‚

</details>

---

### 7. [Online Density-Based Clustering for Real-Time Narrative Evolution Monitorin](https://arxiv.org/abs/2601.20680)

**Authors**: Ostap Vykhopen, Viktoria Skorik, Maxim Tereschenko, Veronika Solopova  
**Category**: cs.CL  
**Published**: 2026-01-29  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.20680v1  

#### Abstract
Automated narrative intelligence systems for social media monitoring face significant scalability challenges when processing continuous data streams using traditional batch clustering algorithms. We investigate the replacement of HDBSCAN (offline clustering) with online (streaming/incremental) clust...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šOnline Density-Based Clustering for Real-Time Narrative Evolution Monitoring**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
ä¼ ç»ŸåŸºäº batch æ¨¡å¼çš„èšç±»ç®—æ³•ï¼ˆå¦‚ HDBSCANï¼‰åœ¨å¤„ç†ç¤¾äº¤åª’ä½“æµæ•°æ®æ—¶é¢ä¸´ä¸¥é‡å¯æ‰©å±•æ€§æŒ‘æˆ˜ï¼š
- **å†…å­˜ç“¶é¢ˆ**ï¼šæ¯æ¬¡èšç±»éœ€åŠ è½½å…¨éƒ¨æ–‡æ¡£åµŒå…¥ï¼ˆO(NlogN) å¤æ‚åº¦ï¼‰ï¼Œéš¾ä»¥åº”å¯¹æŒç»­å¢é•¿çš„æ•°æ®ã€‚
- **è®¡ç®—ä½æ•ˆ**ï¼šæ¯æ—¥éœ€é‡æ–°å¯¹å…¨é‡æ•°æ®è¿›è¡Œèšç±»ï¼Œæ— æ³•å¤ç”¨å†å²ç»“æ„ã€‚
- **ç¼ºä¹å®æ—¶æ€§**ï¼šæ— æ³•æ”¯æŒå¢é‡æ›´æ–°ï¼Œå¯¼è‡´æ— æ³•å®æ—¶ç›‘æµ‹å™äº‹ï¼ˆnarrativeï¼‰çš„æ¼”åŒ–ã€‚
- **å‚æ•°æ•æ„Ÿ**ï¼šç”Ÿäº§ç¯å¢ƒä¸­é¢‘ç¹è°ƒæ•´å‚æ•°ä»¥ç»´æŒç¨³å®šçš„èšç±»ç²’åº¦ã€‚

è¿™äº›é—®é¢˜é˜»ç¢äº†è‡ªåŠ¨åŒ– narrative intelligence ç³»ç»Ÿåœ¨å±æœºç›‘æ§ã€èˆ†æƒ…åˆ†æç­‰åœºæ™¯ä¸­çš„å®é™…éƒ¨ç½²ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡ºå°† **online / streaming clustering ç®—æ³•** æ›¿ä»£ä¼ ç»Ÿçš„ HDBSCANï¼Œæ„å»ºä¸€ä¸ªé€‚ç”¨äºçœŸå®ç”Ÿäº§ç¯å¢ƒçš„ä¸‰é˜¶æ®µæ¶æ„ï¼ˆæ•°æ®é‡‡é›†ã€å»ºæ¨¡ã€ä»ªè¡¨ç›˜ç”Ÿæˆï¼‰ï¼Œå¹¶å¼•å…¥ä»¥ä¸‹åˆ›æ–°è®¾è®¡ï¼š
- **æ»‘åŠ¨çª—å£æ¨¡æ‹Ÿæ¡†æ¶**ï¼šåœ¨å†å²æ•°æ®ä¸Šæ¨¡æ‹Ÿæ—¶é—´åºåˆ—é¢„è®­ç»ƒ + å¢é‡æ—¥æ›´æ–°ï¼Œæ›´è´´è¿‘ç°å®éƒ¨ç½²æ¡ä»¶ã€‚
- **æ··åˆè¯„ä¼°ä½“ç³»**ï¼šç»“åˆä¼ ç»Ÿèšç±»æŒ‡æ ‡ï¼ˆSilhouette, DBIï¼‰ä¸é¢å‘ narrative çš„ä¸“ç”¨æŒ‡æ ‡ï¼ˆDistinctness, Contingency, Varianceï¼‰ï¼Œå®ç°å¤šç»´åº¦æ¯”è¾ƒã€‚
- **ç³»ç»Ÿçº§å…¼å®¹æ€§è€ƒé‡**ï¼šå¼ºè°ƒåœ¨çº¿ç®—æ³•å¿…é¡»æ»¡è¶³è‡ªåŠ¨ç¡®å®šç°‡æ•°ã€æŠ—å™ªæ€§å¼ºã€å†…å­˜å ç”¨å°ã€å¢é‡æ›´æ–°å¿«ç­‰å·¥ç¨‹è¦æ±‚ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **æ•ˆç‡æ˜¾è‘—æå‡**ï¼šDenStream çš„è®­ç»ƒæ—¶é—´ä»…éœ€ 3.56 ç§’ï¼Œè¿œä½äº HDBSCAN çš„ 13 ç§’ï¼ˆä¸”åè€…ä¸º batch å…¨å±€é‡è®­ï¼‰ã€‚
- **æ›´å¥½çš„èšç±»è´¨é‡**ï¼šDenStream åœ¨ Silhouette å’Œ Davies-Bouldin Index ä¸Šå‡ä¼˜äº HDBSCANã€‚
- **æ›´é€‚åˆæµå¼éƒ¨ç½²**ï¼šæ”¯æŒå¢é‡å­¦ä¹ ä¸æ¸è¿›å¼é—å¿˜ï¼ˆhandling concept driftï¼‰ï¼Œé€‚åº”åŠ¨æ€æ¼”åŒ–çš„ narrative ç»“æ„ã€‚
- **æ¨¡å—åŒ–è§£è€¦**ï¼šé€šè¿‡â€œå…ˆåµŒå…¥åèšç±»â€èŒƒå¼ï¼Œè§£è€¦è¡¨ç¤ºå­¦ä¹ ä¸èšç±»åˆ†é…ï¼Œä¾¿äºé›†æˆåˆ°ç°ä»£ NLP æµæ°´çº¿ä¸­ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- æ¥æºï¼šä¹Œå…‹å…°ä¿¡æ¯ç©ºé—´ï¼ˆUkrainian information spaceï¼‰
- å†…å®¹ç±»å‹ï¼šæ–°é—»ç½‘ç«™ã€Telegram é¢‘é“ã€ç”¨æˆ·è¯„è®º
- æ•°æ®ç‰¹å¾ï¼š
  - å¤šè¯­è¨€ï¼ˆä¿„è¯­ã€ä¹Œå…‹å…°è¯­ã€æ··åˆ surzhykï¼‰
  - é«˜å™ªå£°ã€é«˜è¯é¢˜å¤šæ ·æ€§
  - æ—¥å‡çº¦ 17,000 ç¯‡æ–‡æ¡£
- æ—¶é—´èŒƒå›´ï¼šå…± 7 å¤©ï¼ˆå‰ 6 å¤©ç”¨äºé¢„è®­ç»ƒï¼Œç¬¬ 7 å¤©ç”¨äºæµ‹è¯•ï¼‰

### **å®éªŒè®¾ç½®**
- **Pipeline æ¶æ„**ï¼š
  1. **Embedding Generation**ï¼šä½¿ç”¨ `all-MiniLM-L6-v2` æ¨¡å‹ç”Ÿæˆå¤šè¯­è¨€å¥å­åµŒå…¥
  2. **Dimensionality Reduction**ï¼šé‡‡ç”¨ UMAP é™ç»´
  3. **Clustering**ï¼šæ›¿æ¢ä¸åŒèšç±»ç®—æ³•è¿›è¡Œå¯¹æ¯”
  4. **LLM-based Labeling**ï¼šä½¿ç”¨å›ºå®šå‚æ•°çš„ç§æœ‰ LLM ç”Ÿæˆå¯è§£é‡Šçš„ä¸»é¢˜æ ‡ç­¾å’Œæ‘˜è¦
- **è¯„ä¼°æ¨¡å¼**ï¼š
  - **Baseline (HDBSCAN)**ï¼šæ¯å¤©ç‹¬ç«‹è¿è¡Œï¼Œä¸åˆ©ç”¨å†å²æ•°æ®ï¼ˆstrict global modeï¼‰
  - **Online æ–¹æ³•**ï¼šå…ˆåœ¨å‰ 6 å¤©æ•°æ®ä¸Šåˆå§‹åŒ–æ¨¡å‹ï¼Œå†å¯¹ç¬¬ 7 å¤©æ•°æ®è¿›è¡Œå¢é‡æ›´æ–°ä¸é¢„æµ‹

### **è¯„ä¼°æŒ‡æ ‡**
| ç±»å‹ | æŒ‡æ ‡ |
|------|------|
| **ä¼ ç»Ÿèšç±»æŒ‡æ ‡** | - Silhouette Score ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰<br>- Davies-Bouldin Index (DBI) ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ |
| **Narrative ä¸“ç”¨æŒ‡æ ‡** | - Narrative Distinctness ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰<br>- Narrative Contingency ï¼ˆè¶Šä½è¶Šç¨³å®šï¼‰<br>- Narrative Variance ï¼ˆè¶Šä½è¶Šç´§å‡‘ï¼‰ |
| **æ“ä½œæ€§èƒ½æŒ‡æ ‡** | - Training Time<br>- Prediction Time<br>- Cluster Count<br>- Narrative Candidate Count |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Baseline**ï¼šHDBSCANï¼ˆå½“å‰ä¸»æµ narrative å‘ç°å·¥å…·ï¼Œå¦‚ BERTopic ä¸­é»˜è®¤ä½¿ç”¨ï¼‰
- **Online å¯¹æ¯”ç®—æ³•**ï¼š
  - **DBSTREAM**
  - **DenStream**
  - **TextClust**ï¼ˆå› æ€§èƒ½é—®é¢˜æœªåˆ—å…¥æœ€ç»ˆç»“æœï¼‰
- æ‰€æœ‰ online æ–¹æ³•æ¥è‡ª River åº“ï¼Œä½† DenStream å› å®ç°ç¼ºé™·æ”¹ç”¨ pyDenStream

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1 & 2ï¼‰**

#### **è¡¨ 1ï¼šèšç±»è´¨é‡æŒ‡æ ‡å¯¹æ¯”**

| Algorithm     | Silhouette | DBI    | Distinct. | Contingency | Variance |
|---------------|------------|--------|-----------|-------------|----------|
| HDBSCAN       | 0.592      | 0.550  | 0.352     | 0.299       | 0.286    |
| DBSTREAM      | 0.327      | 1.220  | 0.266     | 0.630       | 0.459    |
| **DenStream** | **0.685**  | **0.453** | **0.319** | 0.389       | 0.319    |

> âœ… DenStream åœ¨æ‰€æœ‰ä¼ ç»Ÿèšç±»æŒ‡æ ‡ä¸Šå…¨é¢è¶…è¶Š HDBSCAN  
> âŒ DBSTREAM è¡¨ç°è¾ƒå·®ï¼Œè¡¨æ˜å…¶ micro-cluster è¡¨ç¤ºåœ¨é«˜ç»´è¯­ä¹‰ç©ºé—´ä¸­ä¸å¤Ÿç²¾ç»†

#### **è¡¨ 2ï¼šæ“ä½œæ€§èƒ½æŒ‡æ ‡å¯¹æ¯”**

| Algorithm     | Train (s) | Pred. (s) | Clusters | Narratives |
|---------------|-----------|-----------|----------|------------|
| HDBSCAN       | 13        | 1.3       | 1063     | 118        |
| DBSTREAM      | 232       | 127       | 266      | 58         |
| **DenStream** | **3.56**  | **1.7**   | **303**  | **53**     |

> âœ… DenStream è®­ç»ƒé€Ÿåº¦æœ€å¿«ï¼Œè¿œä¼˜äºå…¶ä»–æ–¹æ³•  
> âš ï¸ HDBSCAN è™½ç„¶æ¨ç†å¿«ï¼Œä½†æ¯æ¬¡éœ€å®Œæ•´ re-clusteringï¼Œä¸å…·å¤‡å¢é‡èƒ½åŠ›  
> ğŸ” HDBSCAN äº§ç”Ÿè¶…è¿‡ 1000 ä¸ª clusterï¼Œè€Œ DenStream ä»… 303 â€”â€” å¯èƒ½åæ˜ å‰è€…è¿‡åº¦ç¢ç‰‡åŒ–

### **æ¶ˆèå®éªŒç»“æœï¼ˆéšå«åˆ†æï¼‰**
- **River åº“å®ç°å­˜åœ¨ä¸¥é‡ç¼ºé™·**ï¼š
  - DenStream çš„ `predict_one` æ–¹æ³•æ¯æ¬¡è°ƒç”¨éƒ½é‡æ–°æ‰§è¡Œ DBSCAN-like èšç±»ï¼Œå¯¼è‡´é¢„æµ‹ææ…¢ã€‚
  - Micro-cluster ç»Ÿè®¡ç»´æŠ¤é”™è¯¯ï¼Œå½±å“ä¸­å¿ƒã€åŠå¾„å’Œæƒé‡å‡†ç¡®æ€§ã€‚
- å› æ­¤ä½œè€…è½¬è€Œä½¿ç”¨ **pyDenStream** å®ç°ï¼Œæ›´ç¬¦åˆåŸå§‹è®ºæ–‡è§„èŒƒï¼Œé¿å…é‡å¤èšç±»ã€‚
- CluStream å› åˆå¹¶ micro-cluster æ—¶å¤æ‚åº¦è¾¾ O(MÂ²)ï¼Œè¢«æå‰æ’é™¤ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **DenStream æ˜¯æœ€æœ‰å‰æ™¯çš„ online æ›¿ä»£æ–¹æ¡ˆ**ï¼š
   - åœ¨èšç±»è´¨é‡å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—æœ€ä½³å¹³è¡¡ã€‚
   - æ˜¾è‘—ä¼˜äº HDBSCAN çš„ Silhouette å’Œ DBI æŒ‡æ ‡ã€‚
   - æ”¯æŒå¢é‡å­¦ä¹ ä¸æ¦‚å¿µæ¼‚ç§»é€‚åº”ï¼Œé€‚åˆ narrative æ¼”åŒ–ç›‘æµ‹ã€‚

2. **HDBSCAN çš„ä¼˜åŠ¿åœ¨äºç¨³å®šæ€§è€Œéè´¨é‡**ï¼š
   - æ›´ä½çš„ Contingency å’Œ Variance è¡¨æ˜å…¶æ¯æ—¥è¾“å‡ºæ›´ä¸€è‡´ã€‚
   - è¿™ç§â€œç¨³å®šæ€§â€æºäºå…¨å±€ä¼˜åŒ–ï¼Œä½†ä¹Ÿæ„å‘³ç€æ— æ³•ç»§æ‰¿å†å²ç»“æ„ï¼Œèµ„æºæ¶ˆè€—å¤§ã€‚

3. **åœ¨çº¿ç®—æ³•å¤©ç„¶å…·æœ‰æ›´é«˜å˜å¼‚æ€§**ï¼š
   - Incremental æ›´æ–°æœºåˆ¶å¯¼è‡´ narrative ç»“æ„éšæ—¶é—´æ³¢åŠ¨æ›´å¤§ã€‚
   - è¿™å¯èƒ½æ˜¯åŠ¨æ€åœºæ™¯ä¸‹çš„åˆç†è¡Œä¸ºï¼Œè€Œéç¼ºé™·ã€‚

4. **ä¸‹æ¸¸ pipeline å­˜åœ¨ç»“æ„æ€§åè§**ï¼š
   - å½“å‰ LLM labeling æ¨¡å—æ˜¯åŸºäº HDBSCAN è¾“å‡ºå¾®è°ƒçš„ï¼Œå¯èƒ½åå¥½å…¶èšç±»å½¢çŠ¶ã€‚
   - å¯¼è‡´ narrative metrics å¯¹ online æ–¹æ³•ä¸å…¬å¹³åœ°æƒ©ç½šã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **é¢†åŸŸç‰¹å®šæ€§**ï¼šå®éªŒæ•°æ®æ¥è‡ªæˆ˜æ—¶é«˜å¼ºåº¦ä¿¡æ¯ç¯å¢ƒï¼ˆä¹Œå…‹å…°ï¼‰ï¼Œç»“æœå¯èƒ½ä¸é€‚ç”¨äºè¯é¢˜æ¼”å˜ç¼“æ…¢çš„é¢†åŸŸï¼ˆå¦‚å­¦æœ¯æ–‡çŒ®ï¼‰ã€‚
- **ä¾èµ–ä¸Šæ¸¸è¡¨ç¤º**ï¼šèšç±»æ•ˆæœå— embedding æ¨¡å‹ï¼ˆMiniLMï¼‰å’Œ UMAP å‚æ•°å½±å“ï¼Œéå­¤ç«‹è¯„ä¼°ã€‚
- **Narrative å®šä¹‰ç®€åŒ–**ï¼šå°† cluster ç›´æ¥è§†ä¸º narrativeï¼Œå¿½ç•¥äº† narrative æœ¬èº«çš„æµåŠ¨æ€§ä¸è·¨ç°‡ä¼ æ’­ç‰¹æ€§ã€‚
- **è½¯ä»¶å®ç°é™åˆ¶**ï¼šéƒ¨åˆ†æ€§èƒ½å·®å¼‚æºäºåº“çš„å·¥ç¨‹å®ç°é—®é¢˜ï¼Œè€Œéç®—æ³•æœ¬è´¨å·®å¼‚ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **ç¼“è§£ temporal instability**ï¼š
   - æ¢ç´¢è¶…å‚æ•°è°ƒä¼˜æˆ–åå¤„ç†ç¨³å®šæŠ€æœ¯ï¼ˆpost-processing stabilizationï¼‰ï¼Œé™ä½ Contingency/Varianceã€‚
2. **é€‚é… downstream pipeline**ï¼š
   - é‡æ–°è®­ç»ƒæˆ–å¾®è°ƒ LLM labeling æ¨¡å—ä»¥åŒ¹é… online clustering è¾“å‡ºåˆ†å¸ƒã€‚
3. **é•¿æœŸåŠ¨æ€ç ”ç©¶**ï¼š
   - å¼€å±•çºµå‘ç ”ç©¶ï¼Œè¯„ä¼°ç®—æ³•åœ¨å­£èŠ‚æ€§å‘¨æœŸã€ç½•è§äº‹ä»¶å†²å‡»ä¸‹çš„è¡¨ç°ã€‚
4. **æ”¹è¿›ç®—æ³•å®ç°**ï¼š
   - æ¨åŠ¨ River ç­‰ä¸»æµåº“ä¿®å¤ DenStream çš„å†—ä½™è®¡ç®—é—®é¢˜ï¼Œæå‡å®ç”¨æ€§ã€‚
5. **æ¢ç´¢ç¥ç»æµèšç±»**ï¼š
   - å°è¯•ç»“åˆ deep clustering æˆ– online variational inference çš„æ–°å‹æ–¹æ³•ï¼Œåœ¨ä¿æŒå¯è§£é‡Šæ€§çš„åŒæ—¶å¢å¼ºè¡¨è¾¾èƒ½åŠ›ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **DenStream åœ¨æ•ˆç‡å’Œèšç±»è´¨é‡ä¸Šä¼˜äº HDBSCANï¼Œæ˜¯æœ€å…·æ½œåŠ›çš„ online æ›¿ä»£æ–¹æ¡ˆï¼Œä½†éœ€ç³»ç»Ÿæ€§é‡æ„ä¸‹æ¸¸ pipeline å¹¶è§£å†³ temporal ä¸ç¨³å®šæ€§é—®é¢˜æ‰èƒ½çœŸæ­£è½åœ°äº real-time narrative monitoring ç³»ç»Ÿã€‚**

</details>

---

### 8. [A Learning-based Framework for Spatial Impulse Response Compensation in 3D Photoacoustic Computed Tomography](https://arxiv.org/abs/2601.20291)

**Authors**: Kaiyi Yang, Seonyeong Park, Gangwon Jeong, Hsuan-Kai Huang, Alexander A. Oraevsky, Umberto Villa, Mark A. Anastasio  
**Category**: cs.LG  
**Published**: 2026-01-29  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.20291v1  

#### Abstract
Photoacoustic computed tomography (PACT) is a promising imaging modality that combines the advantages of optical contrast with ultrasound detection. Utilizing ultrasound transducers with larger surface areas can improve detection sensitivity. However, when computationally efficient analytic reconstr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Learning-based Framework for Spatial Impulse Response Compensation in 3D Photoacoustic Computed Tomography

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨ä¸‰ç»´ **Photoacoustic Computed Tomography (PACT)** ä¸­ï¼Œä½¿ç”¨å¤§å­”å¾„è¶…å£°æ¢èƒ½å™¨å¯æå‡æ£€æµ‹çµæ•åº¦ï¼Œä½†å…¶ **Spatial Impulse Response (SIR)** ä¼šå¯¼è‡´é‡å»ºå›¾åƒå‡ºç°ç©ºé—´å˜åŒ–çš„æ¨¡ç³Šï¼ˆspatially varying blurringï¼‰ã€‚ä¼ ç»ŸåŸºäºè§£ææ¨¡å‹çš„é‡å»ºæ–¹æ³•ï¼ˆå¦‚ UBPï¼‰é€šå¸¸å‡è®¾ç†æƒ³ç‚¹çŠ¶æ¢èƒ½å™¨ï¼Œå¿½ç•¥ SIR æ•ˆåº”ï¼Œä»è€Œå¯¼è‡´åˆ†è¾¨ç‡ä¸‹é™ã€‚

å°½ç®¡ä¼˜åŒ–ç±»è¿­ä»£é‡å»ºæ–¹æ³•å¯ä»¥æ˜¾å¼å»ºæ¨¡ SIRï¼Œä½†å…¶è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œå°¤å…¶åœ¨ 3D åœºæ™¯ä¸­éš¾ä»¥å®ç”¨åŒ–ã€‚

> **æœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ï¼šå¦‚ä½•åœ¨ä¿æŒé«˜è®¡ç®—æ•ˆç‡çš„åŒæ—¶ï¼Œæœ‰æ•ˆè¡¥å¿ SIR å¼•èµ·çš„å›¾åƒé€€åŒ–ï¼Ÿ**

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

æå‡ºäº†ä¸€ç§**åŸºäºå­¦ä¹ çš„æ•°æ®åŸŸ SIR è¡¥å¿æ¡†æ¶**ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- åœ¨**æµ‹é‡æ•°æ®åŸŸï¼ˆdata domainï¼‰** è¿›è¡Œå­¦ä¹ å‹ SIR è¡¥å¿ï¼Œå°†æœ‰é™å°ºå¯¸æ¢èƒ½å™¨é‡‡é›†åˆ°çš„å‹åŠ›ä¿¡å· $ p_{\text{rect}} $ æ˜ å°„ä¸ºç­‰æ•ˆçš„ç†æƒ³ç‚¹çŠ¶æ¢èƒ½å™¨å“åº” $ p_{\text{point}} $ï¼›
- è¡¥å¿åçš„æ•°æ®å¯ç›´æ¥è¾“å…¥é«˜æ•ˆçš„è§£æé‡å»ºç®—æ³•ï¼ˆå¦‚ Universal Backprojection, UBPï¼‰ï¼Œå®ç°å¿«é€Ÿä¸”é«˜åˆ†è¾¨ç‡æˆåƒã€‚

#### åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š
1. **åŒæ¨¡å‹è®¾è®¡**ï¼š
   - **çº¯æ•°æ®é©±åŠ¨æ¨¡å‹ï¼ˆU-Netï¼‰**ï¼šé‡‡ç”¨ 3D U-Net æ¶æ„ç«¯åˆ°ç«¯å­¦ä¹ æ˜ å°„å…³ç³»ã€‚
   - **ç‰©ç†å¯å‘æ¨¡å‹ï¼ˆDeconv-Netï¼‰**ï¼šç»“åˆç‰©ç†å…ˆéªŒï¼Œå¼•å…¥å¯å­¦ä¹ çš„ä¸€ç»´åå·ç§¯æ ¸æ¨¡æ‹Ÿ SIRï¼Œå¹¶é€šè¿‡è‡ªé€‚åº”åŠ æƒèåˆå¤šä¸ªå±€éƒ¨è¡¥å¿ç»“æœã€‚
   
2. **é«˜æ•ˆåˆæˆè®­ç»ƒæ•°æ®ç”Ÿæˆç­–ç•¥**ï¼š
   - ä½¿ç”¨éšæœºåˆ†å¸ƒçš„å‡åŒ€çƒä½“ï¼ˆStochastic Spheresï¼‰ä½œä¸ºè™šæ‹Ÿç›®æ ‡ï¼Œåˆ©ç”¨é—­å¼è§£ï¼ˆclosed-form C-D modelï¼‰å¿«é€Ÿç”Ÿæˆé…å¯¹æ•°æ® $ (p_{\text{rect}}, p_{\text{point}}) $ï¼›
   - é¿å…äº†è€—æ—¶çš„ D-D æˆåƒæ¨¡å‹å’Œç¦»æ•£è¯¯å·®ï¼Œæ˜¾è‘—é™ä½è®­ç»ƒæ•°æ®ç”Ÿæˆæˆæœ¬ã€‚

3. **é¦–æ¬¡å®ç°åœ¨ 3D PACT ä¸­çš„å­¦ä¹ å‹ SIR è¡¥å¿éªŒè¯**ï¼Œå¹¶åº”ç”¨äºçœŸå®æ´»ä½“ä¹³è…ºæˆåƒæ•°æ®ã€‚

---

### âš–ï¸ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹æ³•ç±»å‹ | ä¼˜åŠ¿ | å±€é™ |
|--------|------|-------|
| **è§£æé‡å»ºæ–¹æ³•ï¼ˆå¦‚ UBPï¼‰** | å¿«é€Ÿã€æ˜“éƒ¨ç½² | å¿½ç•¥ SIRï¼Œå›¾åƒæ¨¡ç³Šä¸¥é‡ |
| **ä¼˜åŒ–ç±»è¿­ä»£é‡å»º** | å¯ç²¾ç¡®å»ºæ¨¡ SIR | è®¡ç®—å¼€é”€å¤§ï¼Œéš¾å®æ—¶åº”ç”¨ |
| **å¯å‘å¼åå¤„ç†æ–¹æ³•** | è¾ƒå¿« | è¡¥å¿ä¸å……åˆ†ï¼Œæ•ˆæœæœ‰é™ |
| **æœ¬æ–‡æ–¹æ³•ï¼ˆå­¦ä¹ å‹ + æ•°æ®åŸŸè¡¥å¿ï¼‰** | **å…¼é¡¾ç²¾åº¦ä¸é€Ÿåº¦ï¼Œè¡¥å¿æ•ˆæœæ¥è¿‘ç†æƒ³æƒ…å†µï¼Œæ¨ç†é€Ÿåº¦å¿«** | ä¾èµ–è®­ç»ƒæ•°æ®åˆ†å¸ƒï¼Œæ³›åŒ–èƒ½åŠ›éœ€éªŒè¯ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šæä¾›ä¸€ç§â€œå³æ’å³ç”¨â€å¼è§£å†³æ–¹æ¡ˆâ€”â€”åªéœ€ä¸€æ¬¡å‰å‘ç½‘ç»œæ¨æ–­å³å¯å®Œæˆ SIR è¡¥å¿ï¼Œåç»­ä»å¯ç”¨ UBP ç­‰å¿«é€Ÿç®—æ³•é‡å»ºï¼Œé€‚åˆä¸´åºŠéƒ¨ç½²ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

1. **Stochastic Spheres Datasetï¼ˆè®­ç»ƒä¸ ID æµ‹è¯•ï¼‰**
   - åˆæˆæ•°æ®é›†ï¼ŒåŒ…å« 10,000 å¯¹ $ (p_{\text{rect}}, p_{\text{point}}) $
   - æ¯ä¸ªæ ·æœ¬å« 200 ä¸ªéšæœºä½ç½®ã€åŠå¾„ï¼ˆ0.125â€“5 mmï¼‰ã€åˆå§‹å‹åŠ›å€¼çš„å‡åŒ€çƒä½“
   - åŠ å…¥ i.i.d. é«˜æ–¯å™ªå£°ï¼ˆæ ‡å‡†å·®ä¸ºä¿¡å·åŠŸç‡ 90% ç™¾åˆ†ä½çš„ 2.67%ï¼‰
   - ç”¨äºè®­ç»ƒå’Œå†…éƒ¨éªŒè¯ï¼ˆ70%/10%/20% åˆ†å‰²ï¼‰

2. **Deterministic Spheres Datasetï¼ˆåˆ†è¾¨ç‡åˆ†æï¼‰**
   - å›ºå®šå…­ä¸ªç›¸åŒå°çƒï¼ˆåŠå¾„ 1.2 mmï¼‰ï¼Œä½äºä¸åŒæ·±åº¦
   - ç”¨äºå®šé‡è¯„ä¼°ç©ºé—´åˆ†è¾¨ç‡ï¼ˆFWHMï¼‰
   - åŒ…æ‹¬å››ç§å˜ä½“ï¼šbaselineã€high noiseï¼ˆÃ—10ï¼‰ã€low/high SOSï¼ˆ1.447 / 1.555 mm/Î¼sï¼‰

3. **Stochastic Numerical Breast Phantoms (NBPs)**
   - æ›´å…·è§£å‰–çœŸå®æ€§çš„ 3D è™šæ‹Ÿä¹³è…ºæ¨¡å‹ï¼ˆå…± 80 ä¸ªï¼‰ï¼Œæ¶µç›–å››ç§ BI-RADS å¯†åº¦ç±»å‹
   - å…‰å­¦æ¨¡æ‹Ÿä½¿ç”¨ MCXï¼Œå£°å­¦ä¼ æ’­ä½¿ç”¨ k-space pseudospectral methodï¼ˆj-Waveï¼‰
   - åˆ†ä¸ºä¸¤ä¸ªå­é›†ï¼š
     - **NBP-Homogeneous**ï¼šå‡åŒ€ SOS = 1.5 mm/Î¼s
     - **NBP-Heterogeneous**ï¼šç»„ç»‡ç‰¹å¼‚æ€§ SOS åˆ†å¸ƒï¼ˆæ›´è´´è¿‘å®é™…ï¼‰

4. **In-vivo Breast Imaging Data**
   - æ¥è‡ªå¥åº·å¿—æ„¿è€…å·¦å³ä¹³è…ºçš„çœŸå® PACT æ•°æ®ï¼ˆLOUISA-3D ç³»ç»Ÿï¼‰
   - é€šè¿‡å¹³å‡ç›¸é‚»æ¢æµ‹å™¨ä¿¡å·æ¨¡æ‹Ÿå¤§å­”å¾„æ¢èƒ½å™¨è¾“å‡ºï¼ˆ5.5 mm Ã— 1.1 mmï¼‰
   - ä»¥æœª binning æ•°æ®ä½œä¸ºè¿‘ä¼¼å‚è€ƒ

---

### ğŸ”¬ å®éªŒè®¾ç½®

- **æˆåƒç³»ç»Ÿé…ç½®**ï¼šåŸºäº LOUISA-3D ç³»ç»Ÿå»ºæ¨¡
  - åŠçƒå½¢æµ‹é‡å­”å¾„ï¼ˆåŠå¾„ 85 mmï¼‰
  - 96 ä¸ªçŸ©å½¢æ¢èƒ½å™¨ï¼ˆ1.2 mm Ã— 6 mmï¼‰ï¼Œæ²¿å¼§å½¢æ’åˆ—ï¼Œæ—‹è½¬ 320 è§’åº¦
  - é‡‡æ ·ç‡ 20 MHzï¼Œæ¯é€šé“ 2267 æ—¶é—´ç‚¹

- **é‡å»ºæ–¹æ³•**ï¼š
  - æ‰€æœ‰è¡¥å¿åæ•°æ®å‡ä½¿ç”¨ **UBP** é‡å»º
  - å¯¹äº NBP-Heterogeneous æ•°æ®ï¼Œé‡‡ç”¨ä¸¤åŒºåŸŸ UBPï¼ˆåˆ†åˆ«è®¾å®šä¹³è…ºä¸æ°´åŒº SOSï¼‰

- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **FWHM**ï¼ˆå…¨å®½åŠé«˜ï¼‰ï¼šè¡¡é‡ç©ºé—´åˆ†è¾¨ç‡
  - **Relative Squared Error (RSE) â†“**
  - **Normalized Cross-Correlation (NCC) â†‘**
  - **DICE coefficient â†‘**ï¼ˆåŸºäº Frangi æ»¤æ³¢æå–è¡€ç®¡å›¾ï¼‰

- **ç»Ÿè®¡æ£€éªŒ**ï¼šå•ä¾§ Mann-Whitney U æ£€éªŒï¼ˆ$ p < 0.05 $ è§†ä¸ºæ˜¾è‘—ï¼‰

- **åŸºçº¿å¯¹æ¯”æ–¹æ³•**ï¼š
  - æ— è¡¥å¿ï¼ˆUncompensated, $ p_{\text{rect}} \rightarrow $ UBPï¼‰
  - å­¦ä¹ å‹è¡¥å¿ï¼š**U-Net**, **Deconv-Net**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### âœ… Study 1: Deterministic Spheresï¼ˆåˆ†è¾¨ç‡åˆ†æï¼‰

| æ–¹æ³• | å¹³å‡ FWHM @ x=55mm (mm) | æ¥è¿‘å‚è€ƒå€¼ç¨‹åº¦ |
|------|--------------------------|----------------|
| Reference ($ p_{\text{point}} $) | ~0.505 | æœ€ä½³ |
| Uncompensated ($ p_{\text{rect}} $) | æ˜æ˜¾å¢å¤§ï¼ˆéšè·ç¦»å¢åŠ è€Œæ¶åŒ–ï¼‰ | å·® |
| U-Net | â‰ˆ0.51 | æ¥è¿‘å‚è€ƒ |
| Deconv-Net | â‰ˆ0.505 | å‡ ä¹å®Œå…¨æ¢å¤ |

> ğŸ’¡ å›¾ 3 æ˜¾ç¤ºä¸¤ç§å­¦ä¹ æ–¹æ³•åœ¨æ‰€æœ‰æµ‹è¯•æ¡ä»¶ä¸‹ï¼ˆå™ªå£°ã€SOS å˜åŒ–ï¼‰å‡ç¨³å®šæ¢å¤åˆ†è¾¨ç‡ï¼ŒFWHM æ¥è¿‘ç†è®ºæé™ï¼ˆ0.5 mmï¼‰ã€‚

---

#### âœ… Study 2: NBP-Homogeneousï¼ˆè§£å‰–å¤æ‚æ€§æ³›åŒ–ï¼‰

| Metric | Depth | Uncompensated | U-Net | **Deconv-Net** |
|--------|-------|---------------|--------|----------------|
| **RSE â†“** | Surface | 0.660Â±0.061 | 0.405Â±0.062 | **0.331Â±0.048** |
|          | Deeper | 0.589Â±0.086 | 0.510Â±0.166 | **0.428Â±0.144** |
| **NCC â†‘** | Surface | 0.582Â±0.055 | 0.777Â±0.037 | **0.822Â±0.027** |
|          | Deeper | 0.640Â±0.075 | 0.714Â±0.108 | **0.768Â±0.085** |
| **DICE â†‘** | Surface | 0.237Â±0.048 | 0.758Â±0.025 | **0.803Â±0.011** |
|           | Deeper | 0.298Â±0.052 | 0.700Â±0.042 | **0.774Â±0.022** |

> âœ… æ‰€æœ‰æŒ‡æ ‡ä¸Šï¼Œ**Deconv-Net > U-Net > Uncompensated**ï¼Œå·®å¼‚æ˜¾è‘—ï¼ˆ$ p < 0.05 $ï¼‰

---

#### âœ… Study 3: NBP-Heterogeneousï¼ˆå£°é€Ÿå¼‚è´¨æ€§æŒ‘æˆ˜ï¼‰

| Metric | Depth | Uncompensated | U-Net | **Deconv-Net** |
|--------|-------|---------------|--------|----------------|
| **RSE â†“** | Surface | 0.596Â±0.054 | 0.418Â±0.065 | **0.382Â±0.053** |
|          | Deeper | 0.586Â±0.079 | 0.537Â±0.134 | **0.469Â±0.118** |
| **NCC â†‘** | Surface | 0.633Â±0.044 | 0.774Â±0.038 | **0.797Â±0.029** |
|          | Deeper | 0.640Â±0.066 | 0.699Â±0.089 | **0.744Â±0.072** |
| **DICE â†‘** | Surface | 0.237Â±0.043 | 0.707Â±0.045 | **0.738Â±0.031** |
|           | Deeper | 0.249Â±0.054 | 0.591Â±0.087 | **0.648Â±0.077** |

> âœ… å³ä½¿åœ¨è®­ç»ƒæœªè§çš„ **SOS å¼‚è´¨æ€§** ä¸‹ï¼Œä¸¤ç§æ¨¡å‹ä»æ˜¾è‘—ä¼˜äºæ— è¡¥å¿æ–¹æ³•ï¼Œä¸” **Deconv-Net æŒç»­é¢†å…ˆ**

---

### ğŸ” æ¶ˆèå®éªŒä¸å…³é”®å‘ç°

- **Deconv-Net è®¾è®¡æœ‰æ•ˆæ€§**ï¼š
  - å¤šæ ¸åå·ç§¯ + è‡ªé€‚åº”åˆæˆæœºåˆ¶èƒ½å¤Ÿæ•æ‰ SIR çš„ç©ºé—´å˜å¼‚æ€§
  - ç‰©ç†å…ˆéªŒçº¦æŸå‡å°‘äº†æ— æ•ˆæœç´¢ç©ºé—´ï¼Œæå‡äº†é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›

- **è®­ç»ƒæ•°æ®å¤šæ ·æ€§è¶³å¤Ÿæ”¯æ’‘æ³›åŒ–**ï¼š
  - å°½ç®¡ä»…åœ¨ç®€å•çƒä½“ä¸Šè®­ç»ƒï¼Œæ¨¡å‹åœ¨å¤æ‚ NBP å’ŒçœŸå® in-vivo æ•°æ®ä¸Šè¡¨ç°è‰¯å¥½
  - å½’å› äºä¿¡å·çº§å¯¹é½ï¼ˆsignal-level alignmentï¼‰å’Œæ•°æ®åŸŸå­¦ä¹ çš„ç‰©ç†ä¸€è‡´æ€§

- **æ•°æ®åŸŸ vs å›¾åƒåŸŸå­¦ä¹ ä¼˜åŠ¿**ï¼š
  - æ•°æ®åŸŸä¿®æ­£æ›´ä¸æ˜“å¼•å…¥è™šå‡ç»“æ„ï¼ˆhallucinationsï¼‰
  - é‡å»ºè¿‡ç¨‹ä¿ç•™ç‰©ç†ä¿çœŸæ€§ï¼Œé¿å…â€œè§†è§‰åˆç†ä½†ç‰©ç†é”™è¯¯â€çš„ä¼ªå½±

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º

1. **æˆåŠŸå®ç°äº†é«˜æ•ˆã€å‡†ç¡®çš„ 3D PACT SIR è¡¥å¿**ï¼š
   - æ‰€ææ¡†æ¶å¯åœ¨æ•°æ®åŸŸæœ‰æ•ˆå»é™¤ SIR å¼•èµ·çš„ç©ºé—´æ¨¡ç³Šï¼Œæ˜¾è‘—æå‡å›¾åƒåˆ†è¾¨ç‡å’Œç»“æ„ä¿çœŸåº¦ã€‚

2. **Deconv-Net ç»¼åˆæ€§èƒ½æœ€ä¼˜**ï¼š
   - èåˆç‰©ç†å…ˆéªŒçš„ **Deconv-Net** åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­å‡ä¼˜äºçº¯æ•°æ®é©±åŠ¨çš„ U-Netï¼Œè¡¨æ˜â€œphysics-informed deep learningâ€æ›´å…·æ½œåŠ›ã€‚

3. **é«˜åº¦æ³›åŒ–èƒ½åŠ›**ï¼š
   - æ¨¡å‹åœ¨æœªè§è¿‡çš„å¤æ‚ç»“æ„ã€å™ªå£°æ°´å¹³ã€SOS å¼‚è´¨æ€§ç”šè‡³çœŸå® in-vivo æ•°æ®ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œè¯æ˜å…¶é€‚ç”¨äºå®é™…åœºæ™¯ã€‚

4. **é¦–æ¬¡å®ç° 3D å­¦ä¹ å‹ SIR è¡¥å¿çš„å®é™…åº”ç”¨éªŒè¯**ï¼š
   - åœ¨çœŸå®ä¹³è…ºæˆåƒæ•°æ®ä¸­æ­ç¤ºäº†è¢« SIR æ©ç›–çš„ç»†å¾®è¡€ç®¡ç»“æ„ï¼Œå…·æœ‰æ˜ç¡®ä¸´åºŠä»·å€¼ã€‚

---

### âš ï¸ æ–¹æ³•å±€é™æ€§

1. **ä¾èµ–æ¢èƒ½å™¨å‡ ä½•ä¸ SIR æ¨¡å‹å·²çŸ¥**ï¼š
   - å½“å‰æ–¹æ³•éœ€è¦é¢„å…ˆçŸ¥é“æ¢èƒ½å™¨å½¢çŠ¶ã€å°ºå¯¸å’Œä½ç½®ï¼Œæ— æ³•å¤„ç†æœªçŸ¥æˆ–åŠ¨æ€å˜åŒ–çš„ SIRã€‚

2. **è®­ç»ƒæ•°æ®åŸºäºç®€åŒ–æ­£å‘æ¨¡å‹**ï¼š
   - ä½¿ç”¨é—­å¼ C-D æ¨¡å‹ç”Ÿæˆæ•°æ®ï¼Œå¿½ç•¥äº†éƒ¨åˆ†çœŸå®ç‰©ç†æ•ˆåº”ï¼ˆå¦‚å£°è¡°å‡ã€éçº¿æ€§ä¼ æ’­ï¼‰ã€‚

3. **å°šæœªåœ¨çœŸæ­£çš„å¤§å­”å¾„ç¡¬ä»¶ä¸ŠéªŒè¯**ï¼š
   - å®éªŒä¸­é€šè¿‡ binning å°å­”å¾„æ•°æ®æ¨¡æ‹Ÿå¤§å­”å¾„ï¼Œæœªæ¥éœ€åœ¨ç‰©ç†å¤§å­”å¾„ç³»ç»Ÿä¸Šè¿›ä¸€æ­¥éªŒè¯ã€‚

4. **å†…å­˜ä¸è®¡ç®—èµ„æºéœ€æ±‚è¾ƒé«˜ï¼ˆå°¤å…¶æ˜¯ Deconv-Netï¼‰**ï¼š
   - ä½¿ç”¨ patch-based è¾“å…¥ç¼“è§£å†…å­˜å‹åŠ›ï¼Œä½†ä»éœ€é«˜æ€§èƒ½ GPU æ”¯æŒã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³å…¶ä»–æ¢èƒ½å™¨å½¢çŠ¶ä¸é˜µåˆ—å‡ ä½•**ï¼ˆå¦‚ç¯å½¢ã€å¹³é¢é˜µåˆ—ï¼‰
2. **è”åˆä¼˜åŒ– SIR è¡¥å¿ä¸å›¾åƒé‡å»º**ï¼ˆend-to-end joint learningï¼‰
3. **é›†æˆå»å™ªã€æ ¡æ­£ç­‰å¤šä»»åŠ¡åŠŸèƒ½äºä¸€ä½“**
4. **æ¢ç´¢æ— ç›‘ç£æˆ–è‡ªç›‘ç£è®­ç»ƒæ–¹å¼**ï¼Œå‡å°‘å¯¹åˆæˆæ ‡ç­¾çš„ä¾èµ–
5. **åœ¨æ›´å¤šä¸´åºŠæ•°æ®é›†ä¸Šè¿›è¡Œå‰ç»æ€§éªŒè¯**

---

## æ€»ç»“ä¸€å¥è¯

> æœ¬æ–‡æå‡ºäº†ä¸€ç§**é«˜æ•ˆã€å¯æ¨å¹¿çš„æ•°æ®åŸŸå­¦ä¹ æ¡†æ¶**ï¼Œé¦–æ¬¡å®ç°äº†åœ¨ **3D PACT** ä¸­å¯¹ **Spatial Impulse Response (SIR)** çš„ç²¾å‡†è¡¥å¿ï¼Œå…¼å…·**é«˜ç²¾åº¦ä¸ä½å»¶è¿Ÿä¼˜åŠ¿**ï¼Œä¸ºæ¨åŠ¨é«˜çµæ•åº¦å¤§å­”å¾„ PACT ç³»ç»Ÿèµ°å‘ä¸´åºŠåº”ç”¨æä¾›äº†å…³é”®æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 9. [PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs](https://arxiv.org/abs/2601.20539)

**Authors**: Oguzhan Gungordu, Siheng Xiong, Faramarz Fekri  
**Category**: cs.AI  
**Published**: 2026-01-29  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.20539v1  

#### Abstract
Large Language Models (LLMs) have enabled automated heuristic design (AHD) for combinatorial optimization problems (COPs), but existing frameworks' reliance on fixed evolutionary rules and static prompt templates often leads to myopic heuristic generation, redundant evaluations, and limited reasonin...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³çš„é—®é¢˜**

ç°æœ‰çš„åŸºäº **LLM-based AHD**ï¼ˆAutomated Heuristic Designï¼‰çš„æ–¹æ³•åœ¨ç»„åˆä¼˜åŒ–é—®é¢˜ï¼ˆCOPsï¼‰ä¸­å­˜åœ¨ä»¥ä¸‹å±€é™ï¼š

- **å›ºå®šæ¼”åŒ–è§„åˆ™**ï¼šä¾èµ–é¢„å®šä¹‰çš„è¿›åŒ–ç®—å­ï¼ˆå¦‚äº¤å‰ã€å˜å¼‚ï¼‰ï¼Œç¼ºä¹çµæ´»æ€§ã€‚
- **é™æ€æç¤ºæ¨¡æ¿**ï¼šæç¤ºï¼ˆpromptï¼‰ä¸éšæœç´¢è¿‡ç¨‹åŠ¨æ€è°ƒæ•´ï¼Œå¯¼è‡´æ¢ç´¢æ•ˆç‡ä½ã€‚
- **æ— çŠ¶æ€æœç´¢**ï¼šå°†æ¯æ¬¡å¯å‘å¼ç”Ÿæˆè§†ä¸ºç‹¬ç«‹äº‹ä»¶ï¼Œç¼ºä¹å¯¹å†å²æ¨å¯¼è·¯å¾„çš„è®°å¿†ï¼Œå®¹æ˜“é‡å¤ç”Ÿæˆç›¸ä¼¼å¯å‘å¼ï¼Œé€ æˆå†—ä½™è¯„ä¼°ã€‚
- **è¯•é”™å¼æ¼”åŒ–**ï¼šç¼ºä¹å¯¹â€œä¸ºä½•æŸç§ä¿®æ”¹æœ‰æ•ˆâ€çš„æ¨ç†èƒ½åŠ›ï¼Œéš¾ä»¥å®ç°é«˜æ•ˆçš„çŠ¶æ€æ„ŸçŸ¥è§„åˆ’ã€‚

è¿™äº›é—®é¢˜å¯¼è‡´ç°æœ‰æ–¹æ³•æ”¶æ•›æ…¢ã€æ³›åŒ–å·®ã€æ‰©å±•æ€§å¼±ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯**

æœ¬æ–‡æå‡ºäº† **PathWise**ï¼Œä¸€ç§åŸºäº **ä¸–ç•Œæ¨¡å‹ï¼ˆWorld Modelï¼‰è¿›è¡Œè§„åˆ’** çš„å¤šæ™ºèƒ½ä½“æ¨ç†æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> å°†å¯å‘å¼è®¾è®¡å»ºæ¨¡ä¸ºä¸€ä¸ª**åºåˆ—å†³ç­–è¿‡ç¨‹**ï¼Œé€šè¿‡æ„å»º**è•´å«å›¾ï¼ˆentailment graphï¼‰** ä½œä¸ºç´§å‡‘ã€æœ‰çŠ¶æ€çš„è®°å¿†ç»“æ„ï¼Œå®ç°çŠ¶æ€æ„ŸçŸ¥çš„æ¼”åŒ–ã€‚

#### **æ ¸å¿ƒåˆ›æ–°ç‚¹**

1. **è•´å«å›¾ï¼ˆEntailment Graphï¼‰ä½œä¸ºçŠ¶æ€è®°å¿†**
   - æ¯ä¸ªèŠ‚ç‚¹è¡¨ç¤ºä¸€ä¸ªå¯å‘å¼ `h`ï¼ŒåŒ…å«ä»£ç ã€æè¿°ã€æ¨å¯¼ç†ç”±ã€æ€§èƒ½å’Œçˆ¶èŠ‚ç‚¹å…ƒæ•°æ®ã€‚
   - æœ‰å‘è¾¹è¡¨ç¤ºä»çˆ¶èŠ‚ç‚¹é›†åˆåˆ°å­èŠ‚ç‚¹çš„æ¨å¯¼å…³ç³»ã€‚
   - å›¾ç»“æ„ç¼–ç äº†å¯å‘å¼çš„æ¼”åŒ–å†å²ï¼Œä½¿åç»­å†³ç­–å¯åŸºäºå®Œæ•´ä¸Šä¸‹æ–‡è¿›è¡Œã€‚

2. **å¤šæ™ºèƒ½ä½“ååŒæ¡†æ¶**
   - **Policy Agent**ï¼šé«˜å±‚è§„åˆ’è€…ï¼Œé€‰æ‹©çˆ¶èŠ‚ç‚¹å¹¶ç”Ÿæˆè‡ªç„¶è¯­è¨€æ¨å¯¼æŒ‡ä»¤ `K`ï¼Œå†³å®šâ€œå¦‚ä½•æ”¹è¿›â€ã€‚
   - **World Model Agent**ï¼šæ‰§è¡Œè€…ï¼Œæ ¹æ®æŒ‡ä»¤ç”Ÿæˆå…·ä½“çš„å¯å‘å¼ä»£ç ã€‚
   - **Critic Agents**ï¼ˆåŒæ‰¹è¯„å®¶ï¼‰ï¼š
     - `Policy Critic`ï¼šåˆ†æä¸åŒæ¨å¯¼ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼ŒæŒ‡å¯¼æœªæ¥çˆ¶èŠ‚ç‚¹é€‰æ‹©å’ŒæŒ‡ä»¤è®¾è®¡ã€‚
     - `World Model Critic`ï¼šå¯¹æ¯”æœ€ä½³ä¸æœ€å·®ç”Ÿæˆç»“æœï¼Œæç‚¼ä»£ç çº§æ”¹è¿›å»ºè®®ã€‚
   - æ‰¹è¯„å®¶æä¾›**è·¯ç”±åé¦ˆï¼ˆrouted reflectionsï¼‰**ï¼Œå¼•å¯¼åç»­æ­¥éª¤ï¼Œå®ç°**è‡ªæ¼”åŒ–ï¼ˆself-evolvingï¼‰**ã€‚

3. **Prompt-Level å¤šæ ·æ€§æœºåˆ¶**
   - **å¤šæ ·æ€§æ„ŸçŸ¥æç¤ºæ‰°åŠ¨**ï¼šå¼•å…¥éšè®­ç»ƒæ­¥æ•°è¡°å‡çš„æ¢ç´¢ç‡ï¼Œä»¥æ¦‚ç‡é‡‡æ ·â€œæ¢ç´¢æ€§çŸ­è¯­â€æ³¨å…¥æç¤ºï¼Œé¼“åŠ±æ—©æœŸå¹¿æ³›æ¢ç´¢ã€‚
   - **çŠ¶æ€æ‰“ä¹±ï¼ˆState Shufflingï¼‰**ï¼šéšæœºæ‰“ä¹±è¾“å…¥ä¸Šä¸‹æ–‡ä¸­èŠ‚ç‚¹çš„é¡ºåºï¼Œå‡å°‘ä½ç½®åè§ï¼ˆpositional biasï¼‰ã€‚

4. **æ··åˆå›¾-ç§ç¾¤æ¶æ„**
   - å¤–å±‚ç»´æŠ¤å›ºå®šå¤§å°çš„ç§ç¾¤ï¼ˆroot nodesï¼‰ã€‚
   - å†…å±‚åœ¨æ¯ä¸ªå¤–å±‚è¿­ä»£ä¸­æ„å»ºè•´å«å›¾ï¼Œä»…ä¿ç•™å¶èŠ‚ç‚¹ç”¨äºä¸‹ä¸€è½®ç§ç¾¤æ›´æ–°ã€‚
   - å¹³è¡¡äº†æ ‘æœç´¢çš„ç»“æ„æ€§ä¸ç§ç¾¤æ–¹æ³•çš„ç´§å‡‘æ€§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç‰¹æ€§ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ FunSearch, MCTS-AHDï¼‰ | PathWise |
|------|-------------------------------------|---------|
| **çŠ¶æ€æ„ŸçŸ¥** | âŒ æ— çŠ¶æ€ï¼Œç‹¬ç«‹é‡‡æ · | âœ… è•´å«å›¾æä¾›çŠ¶æ€è®°å¿† |
| **æ¼”åŒ–è§„åˆ™** | âŒ å›ºå®šç®—å­/UCT è§„åˆ™ | âœ… åŠ¨æ€ç”Ÿæˆæ¨å¯¼æŒ‡ä»¤ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰ |
| **æ¨ç†èƒ½åŠ›** | âŒ ç¼ºä¹å¯¹â€œä¸ºä½•æˆåŠŸâ€çš„ç†è§£ | âœ… æ‰¹è¯„å®¶æä¾›è¯­ä¹‰çº§åæ€ |
| **æ¢ç´¢æ•ˆç‡** | âŒ æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œé‡å¤ç”Ÿæˆ | âœ… å¤šæ ·æ€§æœºåˆ¶ + çŠ¶æ€è®°å¿†é¿å…å†—ä½™ |
| **æ”¶æ•›é€Ÿåº¦** | âŒ è¾ƒæ…¢ | âœ… æ›´å¿«æ”¶æ•›ï¼ˆè§å®éªŒï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

åœ¨å¤šä¸ªç»å…¸ **NP-hard COPs** ä¸Šè¿›è¡Œæµ‹è¯•ï¼Œæ¶µç›–ä¸åŒæœç´¢æ¡†æ¶ï¼š

| é—®é¢˜ | æ¡†æ¶ | æ•°æ®é›†è¯´æ˜ |
|------|------|-----------|
| **TSP** | Constructive, ACO, GLS | éšæœºç”ŸæˆèŠ‚ç‚¹åæ ‡ï¼Œè·ç¦»çŸ©é˜µï¼›TSPLIB å®ä¾‹ |
| **Knapsack Problem (KP)** | Constructive | éšæœºæƒé‡/ä»·å€¼ï¼Œå®¹é‡å›ºå®š |
| **Capacitated VRP (CVRP)** | ACO | å®¢æˆ·éœ€æ±‚ã€è½¦è¾†å®¹é‡ã€è·ç¦»çŸ©é˜µ |
| **Multiple Knapsack (MKP)** | ACO | å¤šèƒŒåŒ…ï¼Œç‰©å“åœ¨å„åŒ…ä¸­æƒé‡ä¸åŒ |
| **Orienteering Problem (OP)** | ACO | æ”¶é›†å¥–åŠ±ï¼Œå—è·¯å¾„é•¿åº¦çº¦æŸ |
| **Bin Packing Problem (BPP)** | Constructive (Online), ACO (Offline) | åœ¨çº¿ï¼šç‰©å“æµå¼åˆ°è¾¾ï¼›ç¦»çº¿ï¼šæ‰€æœ‰å·²çŸ¥ |

---

### **å®éªŒè®¾ç½®**

- **LLM åç«¯**ï¼š
  - `GPT-4o-mini`ï¼ˆéæ¨ç†å‹ï¼‰
  - `GPT-5-nano`ï¼ˆä½/ä¸­ç­‰æ¨ç†çº§åˆ«ï¼‰
- **è¯„ä¼°é¢„ç®—**ï¼š`ne = 500` æ¬¡å¯å‘å¼è¯„ä¼°ï¼ˆåŸºçº¿ç”¨ 1000 æ¬¡ï¼‰ã€‚
- **å‚æ•°è®¾ç½®**ï¼š
  - ç§ç¾¤å¤§å° `Np = 6`
  - æ¯æ­¥åŠ¨ä½œæ•° `Na = 2`
  - æ¯åŠ¨ä½œ rollout æ•° `Nu = 2`
  - æœ€å¤§å†…å±‚æ­¥æ•° `Imax = 3`
- **æ¸©åº¦**ï¼šæ‰€æœ‰ä»£ç†è®¾ä¸º 1.0ã€‚

---

### **è¯„ä¼°æŒ‡æ ‡**

- **ç›®æ ‡å€¼ï¼ˆObj.â†“ï¼‰**ï¼šè¶Šå°è¶Šå¥½ï¼ˆå¦‚ TSP è·¯å¾„é•¿åº¦ï¼‰ã€‚
- **æœ€ä¼˜æ€§å·®è·ï¼ˆGap%ï¼‰**ï¼šç›¸å¯¹äºæœ€ä¼˜è§£æˆ–æœ€å¼ºåŸºçº¿çš„ç›¸å¯¹å·®è·ã€‚
- **å¹³å‡ç›¸å¯¹å·®è·æ”¹è¿›ï¼ˆMRGIï¼‰**ï¼š
  $$
  \text{MRGI} = \frac{\text{Gap}_{\text{baseline}} - \text{Gap}_{\text{PathWise}}}{\text{Gap}_{\text{baseline}}} \times 100\%
  $$
- **é€‰æ‹©å¤šæ ·æ€§ç‡ï¼ˆSDRï¼‰**ï¼šå”¯ä¸€çˆ¶èŠ‚ç‚¹é€‰æ‹©æ¯”ä¾‹ï¼Œè¡¡é‡æ¢ç´¢å¹¿åº¦ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| ç±»åˆ« | æ–¹æ³• |
|------|------|
| **æ‰‹åŠ¨è®¾è®¡** | Greedy Construct, ACO, KGLS, Best Fit, First Fit |
| **ç¥ç»ç»„åˆä¼˜åŒ–ï¼ˆNCOï¼‰** | POMO, DeepACO, NeuralGLS, GNNGLS |
| **LLM-based AHD** | FunSearch, EoH, ReEvo, HSEvo, MCTS-AHD |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **è¡¨ 1ï¼šConstructive æ¡†æ¶ä¸‹çš„ TSP å’Œ KP ç»“æœ**

| æ–¹æ³• | TSP (N=200) Gap% | KP (N=500) Gap% |
|------|------------------|----------------|
| **POMO** | 21.52% | 3.12% |
| **MCTS-AHD** | 15.82% | 1.88% |
| **PathWise (Ours)** | **14.63%** | **0.05%** |

- **MRGI æ”¹è¿›**ï¼š
  - TSP å¹³å‡æå‡ **20.38%**ï¼Œæœ€é«˜è¾¾ **31.82%**ï¼ˆGPT-5-nano lowï¼‰ã€‚
  - KP å¹³å‡æå‡ **49.89%~65.20%**ï¼Œæœ€å¤§æå‡ **81.34%**ï¼ˆN=500, W=25ï¼‰ã€‚

#### **è¡¨ 2ï¼šACO æ¡†æ¶ä¸‹çš„ç»¼åˆè¡¨ç°**

| ä»»åŠ¡ | PathWise MRGI æå‡ |
|------|-------------------|
| TSP | 60.22% |
| CVRP | 38.73% |
| MKP | 89.35% |
| OP | 54.81% |
| Offline BPP | 44.86% |

- åœ¨ **OP (N=200)** å’Œ **MKP** ä¸Šï¼ŒPathWise è¡¨ç°ä¼˜äºéœ€ä¸“é—¨è®­ç»ƒçš„ç¥ç»æ±‚è§£å™¨ **DeepACO**ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **æ”¶æ•›æ›´å¿«**ï¼šå¦‚å›¾ 1 æ‰€ç¤ºï¼ŒPathWise åœ¨ **500 æ¬¡è¯„ä¼°å†…** å³è¶…è¶ŠåŸºçº¿åœ¨ 1000 æ¬¡è¯„ä¼°åçš„æ€§èƒ½ï¼Œä¸”æ–¹å·®æ›´ä½ã€‚
- **æ³›åŒ–æ›´å¼º**ï¼šåœ¨ OODï¼ˆOut-of-Domainï¼‰å¤§å°ºå¯¸å®ä¾‹ä¸Šæå‡æ›´æ˜¾è‘—ï¼Œè¡¨æ˜å…¶å…·å¤‡è‰¯å¥½æ‰©å±•æ€§ã€‚
- **ç¨³å®šæ€§é«˜**ï¼šå¤šæ¬¡è¿è¡Œç»“æœæ³¢åŠ¨å°ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **è¡¨ 3ï¼šæ‰¹è¯„å®¶æ¶ˆèï¼ˆTSP Constructiveï¼‰**

| æ–¹æ³• | TSP50 Gap% |
|------|-----------|
| **PathWise (Full)** | 8.79% |
| w/o Policy Critic | 10.21% |
| w/o World Model Critic | 9.63% |
| w/o Both Critics | 14.42% |

- **Policy Critic å½±å“æ›´å¤§**ï¼šè¯´æ˜é«˜å±‚ç­–ç•¥æŒ‡å¯¼æ¯”ä»£ç å¾®è°ƒæ›´é‡è¦ã€‚

#### **è¡¨ 4ï¼šå¤šæ ·æ€§æœºåˆ¶æ¶ˆè**

| æ–¹æ³• | TSP50 Gap% | SDR (%) |
|------|-----------|--------|
| **PathWise (Full)** | 8.79% | 75.79% |
| w/o Prompt Perturbation | 9.58% | 70.30% |
| w/o State Shuffling | 9.02% | 61.03% |
| w/o Both | 11.43% | 53.76% |

- **æç¤ºæ‰°åŠ¨** å¯¹æ€§èƒ½å½±å“æ›´å¤§ï¼Œæ˜¯æ¢ç´¢çš„ä¸»è¦é©±åŠ¨åŠ›ã€‚
- **çŠ¶æ€æ‰“ä¹±** ä¸»è¦ç¼“è§£ä½ç½®åè§ï¼Œæå‡é€‰æ‹©å¤šæ ·æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **çŠ¶æ€æ„ŸçŸ¥è§„åˆ’ä¼˜äºæ— çŠ¶æ€æœç´¢**ï¼šè•´å«å›¾æä¾›äº†æœ‰æ•ˆçš„è®°å¿†æœºåˆ¶ï¼Œä½¿ç³»ç»Ÿèƒ½â€œè®°ä½è¿‡å»â€ï¼Œé¿å…é‡å¤æ¢ç´¢ã€‚
2. **å¤šæ™ºèƒ½ä½“åä½œå®ç°è‡ªæ¼”åŒ–**ï¼šPolicy + World Model + Critics æ„æˆé—­ç¯ï¼Œå®ç°äº†ä»â€œè¯•é”™â€åˆ°â€œæœ‰è®¡åˆ’æ¼”åŒ–â€çš„è½¬å˜ã€‚
3. **å¤šæ ·æ€§æ˜¯é«˜æ•ˆæ¢ç´¢çš„å…³é”®**ï¼šPrompt-level æ‰°åŠ¨å’ŒçŠ¶æ€æ‰“ä¹±æ˜¾è‘—æå‡äº†æ¢ç´¢å¹¿åº¦ï¼Œé¿å…æ—©ç†Ÿæ”¶æ•›ã€‚
4. **PathWise æ”¶æ•›æ›´å¿«ã€æ€§èƒ½æ›´å¼ºã€æ‰©å±•æ›´å¥½**ï¼šåœ¨å¤šç§ COPs å’Œæ¡†æ¶ä¸‹å‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨å¤§è§„æ¨¡é—®é¢˜ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚

---

### **å±€é™æ€§**

1. **LLM è¾“å‡ºçš„ä¸ç¡®å®šæ€§**ï¼šç”Ÿæˆçš„å¯å‘å¼è´¨é‡å— LLM éšæœºæ€§å½±å“ï¼Œå¯èƒ½å¯¼è‡´ä¸´æ—¶ä¸ç¨³å®šã€‚
2. **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼šè™½ç„¶è¯„ä¼°æ¬¡æ•°å°‘ï¼Œä½†æ¯æ¬¡æ¶‰åŠå¤šä¸ª LLM è°ƒç”¨ï¼Œtoken æˆæœ¬é«˜äºéƒ¨åˆ†åŸºçº¿ï¼ˆè§è¡¨ 14ï¼‰ã€‚
3. **å¯¹ LLM èƒ½åŠ›æ•æ„Ÿ**ï¼šæ€§èƒ½éš LLM æ¨ç†èƒ½åŠ›å¢å¼ºè€Œæå‡ï¼Œä½†åœ¨å¼±æ¨¡å‹ä¸Šå¯èƒ½é€€åŒ–ã€‚
4. **å®ç°å¤æ‚åº¦é«˜**ï¼šå¤šä»£ç†åè°ƒã€å›¾ç®¡ç†ã€åå°„æœºåˆ¶å¢åŠ äº†å·¥ç¨‹å¤æ‚æ€§ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **åº”ç”¨äºæ›´é«˜æˆæœ¬åœºæ™¯**ï¼šå¦‚åˆ†å­è®¾è®¡ã€ææ–™å‘ç°ç­‰éœ€ä»¿çœŸæˆ–å®éªŒè¯„ä¼°çš„é—®é¢˜ï¼Œå…¶ä¸­è®­ç»ƒæ—¶é—´æ˜¯ä¸»è¦ç“¶é¢ˆã€‚
2. **å­¦ä¹ å¯è¿ç§»çš„æ¼”åŒ–ç­–ç•¥**ï¼šè®© Policy å’Œ Critics å­¦ä¹ è·¨é—®é¢˜é€šç”¨çš„æ”¹è¿›æ¨¡å¼ï¼Œå‡å°‘å¯¹ç‰¹å®šé—®é¢˜çš„ä¾èµ–ã€‚
3. **é™ä½ LLM å¼€é”€**ï¼šæ¢ç´¢è½»é‡çº§ä»£ç†æˆ–ç¼“å­˜æœºåˆ¶ï¼Œå‡å°‘å†—ä½™è°ƒç”¨ã€‚
4. **ç»“åˆå¼ºåŒ–å­¦ä¹ **ï¼šå°†æ•´ä¸ª PathWise æ¡†æ¶è§†ä¸ºä¸€ä¸ª RL ç¯å¢ƒï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–ç­–ç•¥ã€‚

---

> **æ€»ç»“**ï¼šPathWise é€šè¿‡å¼•å…¥ **è•´å«å›¾** å’Œ **å¤šæ™ºèƒ½ä½“åä½œ**ï¼Œé¦–æ¬¡å°† **LLM-based AHD** ä»æ— çŠ¶æ€çš„â€œè¯•é”™æœç´¢â€è½¬å˜ä¸ºæœ‰çŠ¶æ€çš„â€œè§„åˆ’å¼æ¼”åŒ–â€ï¼Œåœ¨å¤šä¸ª COPs ä¸Šå®ç°äº†æ›´å¿«æ”¶æ•›ã€æ›´å¼ºæ€§èƒ½å’Œæ›´å¥½æ‰©å±•æ€§ï¼Œä¸ºè‡ªåŠ¨åŒ–å¯å‘å¼è®¾è®¡å¼€è¾Ÿäº†æ–°èŒƒå¼ã€‚

</details>

---

### 10. [Policy of Thoughts: Scaling LLM Reasoning via Test-time Policy Evolution](https://arxiv.org/abs/2601.20379)

**Authors**: Zhengbo Jiao, Hongyu Xian, Qinglong Wang, Yunpu Ma, Zhebo Wang, Zifan Zhang, Dezhang Kong, Meng Han  
**Category**: cs.AI  
**Published**: 2026-01-29  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.20379v1  

#### Abstract
Large language models (LLMs) struggle with complex, long-horizon reasoning due to instability caused by their frozen policy assumption. Current test-time scaling methods treat execution feedback merely as an external signal for filtering or rewriting trajectories, without internalizing it to improve...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**Policy of Thoughts: Scaling LLM Reasoning via Test-time Policy Evolution**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚ã€é•¿ç¨‹æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¸ç¨³å®šï¼Œä¸»è¦åŸå› åœ¨äºå…¶â€œ**å†»ç»“ç­–ç•¥å‡è®¾**â€ï¼ˆfrozen policy assumptionï¼‰â€”â€”å³æ¨¡å‹åœ¨æ¨ç†æ—¶æ— æ³•ä»å¤±è´¥å°è¯•ä¸­å­¦ä¹ å¹¶åŠ¨æ€è°ƒæ•´è‡ªèº«çš„æ¨ç†é€»è¾‘ã€‚å°½ç®¡å·²æœ‰æ–¹æ³•é€šè¿‡é‡‡æ ·ã€åæ€æˆ–æœç´¢æ¥æå‡æ¨ç†æ•ˆæœï¼Œä½†å®ƒä»¬é€šå¸¸ä»…å°†æ‰§è¡Œåé¦ˆä½œä¸ºå¤–éƒ¨ä¿¡å·ç”¨äºç­›é€‰æˆ–é‡å†™è½¨è¿¹ï¼Œè€Œæœªå°†å…¶å†…åŒ–ä¸ºå¯¹åº•å±‚æ¨ç†ç­–ç•¥çš„ä¼˜åŒ–ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šPolicy of Thoughts (PoT)
å—æ³¢æ™®å°”ï¼ˆPopperï¼‰è®¤è¯†è®ºâ€œçŒœæƒ³ä¸åé©³â€ï¼ˆconjectures and refutationsï¼‰å¯å‘ï¼Œä½œè€…æå‡º **Policy of Thoughts (PoT)**ï¼Œå°†æ¨ç†è¿‡ç¨‹é‡æ„ä¸ºä¸€ä¸ª**å®ä¾‹çº§åœ¨çº¿ä¼˜åŒ–é—­ç¯ç³»ç»Ÿ**ï¼Œå®ç°æµ‹è¯•æ—¶ç­–ç•¥æ¼”åŒ–ï¼ˆtest-time policy evolutionï¼‰ã€‚

#### æ ¸å¿ƒæœºåˆ¶ï¼š
- **æ¢ç´¢é˜¶æ®µ**ï¼šä½¿ç”¨é«˜æ•ˆçš„æœç´¢æœºåˆ¶ï¼ˆå¦‚ MCTSï¼‰ç”Ÿæˆå¤šæ ·åŒ–çš„å€™é€‰è§£ï¼ˆtentative theoriesï¼‰ã€‚
- **å†…åŒ–é˜¶æ®µ**ï¼šåˆ©ç”¨ **Group Relative Policy Optimization (GRPO)** å°†æ‰§è¡Œåé¦ˆè½¬åŒ–ä¸ºæ¢¯åº¦æ›´æ–°ï¼Œä½œç”¨äºä¸€ä¸ªä¸´æ—¶çš„ **LoRA adapter**ï¼Œä»è€ŒåŠ¨æ€è°ƒæ•´æ¨¡å‹çš„æ¨ç†å…ˆéªŒã€‚
- **é—­ç¯è®¾è®¡**ï¼šå½¢æˆâ€œç”Ÿæˆ â†’ æ‰§è¡Œ â†’ åé¦ˆ â†’ ç­–ç•¥æ›´æ–°â€çš„è¿­ä»£å¾ªç¯ï¼Œä½¿æ¨¡å‹èƒ½åœ¨å•ä¸ªé—®é¢˜æ±‚è§£è¿‡ç¨‹ä¸­å®æ—¶è¿›åŒ–å…¶æ¨ç†èƒ½åŠ›ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | PoT |
|------|--------|-----|
| **ç­–ç•¥æ˜¯å¦æ›´æ–°** | âŒ å†»ç»“ç­–ç•¥ï¼Œä»…ç­›é€‰è½¨è¿¹ | âœ… åŠ¨æ€æ¼”åŒ–ç­–ç•¥ |
| **åé¦ˆç”¨é€”** | å¤–éƒ¨ä¿¡å·ï¼ˆç”¨äºæ’åº/é‡å†™ï¼‰ | å†…éƒ¨ä¿¡å·ï¼ˆç”¨äºå‚æ•°æ›´æ–°ï¼‰ |
| **è®¡ç®—æ•ˆç‡** | é«˜å¼€é”€é‡‡æ ·ï¼Œå¤§é‡æ— æ•ˆå°è¯• | æ›´é«˜æ•ˆåœ°åˆ©ç”¨è®¡ç®—èµ„æºï¼Œå‡å°‘å†—ä½™æ¢ç´¢ |
| **å°æ¨¡å‹æ½œåŠ›** | æ€§èƒ½å—é™äºå‚æ•°è§„æ¨¡ | èƒ½è®©å°å‹æ¨¡å‹è¶…è¶Šè¶…å¤§æ¨¡å‹ |

> PoT å®ç°äº†ä»â€œé™æ€æœç´¢â€åˆ°â€œåŠ¨æ€é€‚åº”â€çš„èŒƒå¼è½¬å˜ï¼Œæ˜¯ test-time scaling çš„ä¸€æ¬¡æœ¬è´¨å‡çº§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒæ¶µç›–äº”ä¸ªä¸»æµä»£ç ä¸æ•°å­¦æ¨ç†åŸºå‡†ï¼Œæ€»è®¡ **836 ä¸ªç¼–ç¨‹é—®é¢˜**ï¼š
- **HumanEval**ï¼ˆ164é¢˜ï¼‰ï¼šå‡½æ•°çº§ä»£ç ç”Ÿæˆ
- **MBPP**ï¼ˆ257é¢˜ï¼‰ï¼šåŸºç¡€Pythonç¼–ç¨‹ä»»åŠ¡
- **LiveCodeBench v5 & v6**ï¼ˆå„ ~170é¢˜ï¼‰ï¼šå»æ±¡æŸ“ã€å¤šè½®äº¤äº’çš„çœŸå®ç¼–ç è¯„æµ‹
- **ICPC**ï¼ˆ73é¢˜ï¼‰ï¼šæ¥è‡ª OJBench çš„ç«èµ›çº§ç¼–ç¨‹æŒ‘æˆ˜

> æ‰€æœ‰å®éªŒå‡åœ¨ç›¸åŒæ¨ç†é¢„ç®—ä¸‹è¿›è¡Œï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦æŒ‡æ ‡ï¼š**Pass@1 Accuracy**ï¼ˆå®Œå…¨é€šè¿‡æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹ï¼‰
- è¾…åŠ©æŒ‡æ ‡ï¼šå¹³å‡å‡†ç¡®ç‡ï¼ˆOverallï¼‰ï¼Œè·¨å¤šä¸ªåŸºå‡†çš„æ— åŠ æƒå¹³å‡

### âš™ï¸ å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š
  - `Qwen3-4B-Instruct-2507`ï¼ˆä¸»å®éªŒï¼‰
  - `Qwen3-1.7B-Thinking`, `Phi-3-mini-4k-instruct`ï¼ˆéªŒè¯æ³›åŒ–æ€§ï¼‰
- **æœç´¢æœºåˆ¶**ï¼šMonte Carlo Tree Search (MCTS)ï¼Œæ¯æ­¥æ‰©å±• $k=3$ ä¸ªå­èŠ‚ç‚¹
- **ç­–ç•¥æ›´æ–°æœºåˆ¶**ï¼š
  - ä½¿ç”¨ **LoRA**ï¼ˆrank=8ï¼‰è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒ
  - é‡‡ç”¨ **GRPO** è¿›è¡Œç›¸å¯¹ä¼˜åŠ¿ä¼˜åŒ–ï¼ŒåŸºäºç»„å†…å¥–åŠ±å·®å¼‚æ›´æ–°ç­–ç•¥
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šå•å¼  NVIDIA A800 (80GB) GPUï¼Œä½¿ç”¨ vLLM æ¨ç†åç«¯

### ğŸ†š å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
åˆ†ä¸ºå››ç±»ï¼š
1. **æ ‡å‡†æç¤ºæ³•**ï¼š
   - Zero-shot / Few-shot + CoT
   - Best-of-N (N=20)
2. **è‡ªæ”¹è¿›æ¡†æ¶**ï¼š
   - Self-Refine, Reflexion, CodeT, LDB
3. **ç»“æ„åŒ–æœç´¢æ–¹æ³•**ï¼š
   - ToT, RAP, PG-TD, LATS, AB-MCTS, RethinkMCTS
4. **å‰æ²¿å•†ä¸šå¤§æ¨¡å‹**ï¼ˆzero-shotï¼‰ï¼š
   - GPT-4o, DeepSeek-V3, Claude-Opus-4, Gemini-2.5-flash, Qwen3-235B-A22B

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| æ–¹æ³• | HumanEval | MBPP | LCB V5 | LCB V6 | ICPC | **Overall** |
|------|-----------|-------|--------|--------|------|------------|
| GPT-4o | 92.70 | 87.60 | 29.94 | **29.71** | 6.80 | **49.75** |
| DeepSeek-V3 | 91.50 | 87.60 | 31.74 | 16.00 | 9.59 | 50.55 |
| Gemini-2.5-flash | 94.01 | 81.70 | 64.07 | 56.57 | 8.22 | 51.12 |
| **PoT (Ours, 4B)** | **98.78** | **94.94** | **57.49** | **49.71** | **19.18** | **58.98** |

> ğŸ’¡ **PoT-4B åœ¨ Overall ä¸Šè¾¾åˆ° 58.98%ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰æ›´å¤§è§„æ¨¡çš„å•†ä¸šæ¨¡å‹ï¼ˆå¦‚ GPT-4oã€Claude-Opus-4ï¼‰**

#### ç‰¹åˆ«äº®ç‚¹ï¼š
- åœ¨ **LiveCodeBench v6** ä¸Šï¼ŒPoT-4B è¾¾åˆ° **49.71%**ï¼Œè¶…è¿‡ GPT-4oï¼ˆ29.71%ï¼‰**æ•´æ•´ 20 ä¸ªç™¾åˆ†ç‚¹**
- åœ¨ **ICPC**ï¼ˆç«èµ›çº§éš¾åº¦ï¼‰ä¸Šï¼ŒPoT è¾¾åˆ° 19.18%ï¼Œè¿œè¶…å…¶ä»–æ–¹æ³•ï¼ˆæœ€é«˜ä»… 16.43%ï¼‰
- ä¸€ä¸ª **4B æ¨¡å‹**çš„è¡¨ç°è¶…è¿‡äº† **235B ç”šè‡³ 400B çº§åˆ«çš„æ¨¡å‹**

### ğŸ” ä¸å…¶ä»–ç®—æ³•åŸºçº¿å¯¹æ¯”
| æ–¹æ³• | Overall |
|------|---------|
| Best-of-N (N=20) | 50.22 |
| Reflexion | 49.20 |
| LATS | 50.75 |
| AB-MCTS | 52.96 |
| RethinkMCTS | 52.05 |
| **PoT (Ours)** | **58.98** âœ… |

> PoT æ¯”æœ€å¼ºçš„æœç´¢æ–¹æ³•ï¼ˆAB-MCTSï¼‰é«˜å‡ºè¿‘ **6 ä¸ªç‚¹**

### ğŸ” æ¶ˆèå®éªŒç»“æœ

#### âœ… Ablation on Test-time Evolutionï¼ˆè¡¨3ï¼‰
| é…ç½® | LCB v6 å‡†ç¡®ç‡ | Î” vs Zero-shot |
|------|---------------|----------------|
| Zero-shot | 27.43% | â€” |
| Search Only (no LoRA update) | 37.14% | +9.71 |
| **PoT (Search + LoRA æ›´æ–°)** | **49.71%** | **+22.28** |

> è¡¨æ˜ï¼š**ç­–ç•¥å†…åŒ–ï¼ˆpolicy internalizationï¼‰å¸¦æ¥çš„å¢ç›Šè¿œå¤§äºçº¯æœç´¢**

#### âœ… Ablation on Branching Factor $k$ï¼ˆè¡¨4ï¼‰
| $k$ | Acc (%) | æˆæœ¬ (ms) |
|-----|--------|----------|
| 1 (Greedy) | 31.42 | 161.43 |
| 2 | 41.14 | 309.87 |
| **3 (Ours)** | **49.71** | **473.66** |
| 8 | 54.86 | 2369.96 |
| 16 | 55.42 | 3984.52 |

> $k=3$ æ˜¯æ€§èƒ½ä¸æ•ˆç‡çš„æœ€ä½³å¹³è¡¡ç‚¹ï¼›æ›´å¤§çš„ $k$ å¸¦æ¥è¾¹é™…æ”¶ç›Šé€’å‡

#### âœ… Ablation on LoRA å‚æ•°ï¼ˆè¡¨5ï¼‰
| è®¾ç½® (r, lr) | Acc (%) | Î” vs Ours |
|-------------|--------|----------|
| LoRA(8, 1e-4) (Ours) | 49.71 | â€” |
| LoRA(4, 5e-5) | 43.43 | -6.28 |
| LoRA(16, 1e-4) | 50.86 | +1.15 |

> è¡¨æ˜ LoRA çš„ç§©ï¼ˆrankï¼‰å’Œå­¦ä¹ ç‡éœ€åˆç†é…ç½®ï¼Œä½†å³ä½¿è½»é‡æ›´æ–°ä¹Ÿèƒ½å¸¦æ¥æ˜¾è‘—æå‡

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **æµ‹è¯•æ—¶ç­–ç•¥æ¼”åŒ–æ˜¯å¯è¡Œä¸”å¼ºå¤§çš„**ï¼š
   - å³ä½¿æ˜¯å°å‹æ¨¡å‹ï¼ˆ4Bï¼‰ï¼Œé€šè¿‡ test-time policy evolution ä¹Ÿèƒ½è¶…è¶Šæ•°åå€å¤§çš„æ¨¡å‹ã€‚
   - â€œ**å†…åŒ–å¤±è´¥ç»éªŒ**â€æ¯”â€œä¸¢å¼ƒé”™è¯¯è·¯å¾„â€æ›´æœ‰æ•ˆã€‚

2. **PoT å®ç°äº†æ¶æ„æ— å…³çš„æ¨ç†å¢å¼º**ï¼š
   - åœ¨ Qwenã€Phi ç­‰ä¸åŒæ¶æ„çš„å°æ¨¡å‹ä¸Šå‡å–å¾—ä¸€è‡´æå‡ï¼ˆè§ Table 2ï¼‰ï¼Œè¯æ˜å…¶é€šç”¨æ€§ã€‚

3. **è®¡ç®—èµ„æºè¢«æ›´é«˜æ•ˆåˆ©ç”¨**ï¼š
   - å°½ç®¡å¼•å…¥äº†åå‘ä¼ æ’­å¼€é”€ï¼ˆçº¦å¢åŠ  1.46Ã— å»¶è¿Ÿï¼‰ï¼Œä½†ç”±äºæ”¶æ•›æ›´å¿«ï¼Œæ€»ä½“æˆæœ¬æ›´ä½ï¼ˆè§å…¬å¼ 11ï¼‰ã€‚

4. **é€‚ç”¨äºç¯å¢ƒåé¦ˆæ˜ç¡®çš„ä»»åŠ¡**ï¼š
   - å¦‚ä»£ç æ‰§è¡Œã€å½¢å¼åŒ–è¯æ˜ç­‰æä¾›ç¡®å®šæ€§åé¦ˆçš„åœºæ™¯ï¼ŒPoT æ•ˆæœå°¤ä¸ºçªå‡ºã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰ä¾èµ–å¯æ‰§è¡Œç¯å¢ƒï¼ˆå¦‚ä»£ç è¿è¡Œå™¨ï¼‰æä¾›ç²¾ç¡®åé¦ˆï¼Œåœ¨å¼€æ”¾åŸŸé—®ç­”æˆ–æ¨¡ç³Šè¯­ä¹‰ä»»åŠ¡ä¸­éœ€å€ŸåŠ©å¤–éƒ¨ Reward Modelï¼ˆå¦‚ GPT-5ï¼‰ï¼Œæ•ˆæœå—é™äº RM è´¨é‡ã€‚
- å®æ—¶è®­ç»ƒå¼•å…¥é¢å¤–å»¶è¿Ÿï¼Œä¸é€‚åˆæä½å»¶è¿Ÿåœºæ™¯ã€‚
- transient LoRA çš„ç”Ÿå‘½å‘¨æœŸçŸ­ï¼Œéš¾ä»¥é•¿æœŸä¿ç•™â€œå­¦åˆ°çš„çŸ¥è¯†â€ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **multi-modal reasoning** å’Œ **embodied reasoning**ï¼ˆå…·èº«æ™ºèƒ½ï¼‰
- åº”ç”¨äº **long-horizon scientific discovery** å’Œ **tool-augmented problem solving**
- æ¢ç´¢å¦‚ä½•å°† test-time å­¦ä¹ çš„çŸ¥è¯†è¿ç§»åˆ°åç»­ä»»åŠ¡ä¸­ï¼ˆmeta-learning extensionï¼‰
- ç»“åˆ memory æˆ– cache æœºåˆ¶ï¼Œå®ç°è·¨å®ä¾‹çš„ç»éªŒç§¯ç´¯

---

## æ€»ç»“ä¸€å¥è¯
> **PoT é€šè¿‡å°†æ¨ç†è§†ä¸ºâ€œçŒœæƒ³-åé©³-è¿›åŒ–â€çš„é—­ç¯è¿‡ç¨‹ï¼Œé¦–æ¬¡å®ç°äº† LLM åœ¨æµ‹è¯•æ—¶çš„ç­–ç•¥æ¼”åŒ–ï¼Œä½¿å¾—å°æ¨¡å‹ä¹Ÿèƒ½å…·å¤‡åª²ç¾ç”šè‡³è¶…è¶Šè¶…å¤§æ¨¡å‹çš„å¤æ‚æ¨ç†èƒ½åŠ›ï¼Œä¸º test-time scaling å¼€è¾Ÿäº†å…¨æ–°è·¯å¾„ã€‚**

</details>

---

### 11. [CtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning](https://arxiv.org/abs/2601.20467)

**Authors**: Zhenxuan Fan, Jie Cao, Yang Dai, Zheqi Lv, Wenqiao Zhang, Zhongle Xie, Peng LU, Beng Chin Ooi  
**Category**: cs.AI  
**Published**: 2026-01-29  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.20467v1  

#### Abstract
Chain-of-thought (CoT) prompting improves LLM reasoning but incurs high latency and memory cost due to verbose traces, motivating CoT compression with preserved correctness. Existing methods either shorten CoTs at the semantic level, which is often conservative, or prune tokens aggressively, which c...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
Chain-of-Thought (CoT) prompting èƒ½æ˜¾è‘—æå‡ Large Language Models (LLMs) åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œä½†å…¶ç”Ÿæˆçš„å†—é•¿ä¸­é—´æ¨ç†è½¨è¿¹å¸¦æ¥äº†é«˜æ˜‚çš„è§£ç å»¶è¿Ÿã€å†…å­˜å ç”¨å’Œæ¨ç†æˆæœ¬ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¿æŒæ¨ç†æ­£ç¡®æ€§çš„å‰æä¸‹å‹ç¼© CoT é•¿åº¦ï¼Œæˆä¸ºé«˜æ•ˆæ¨ç†çš„å…³é”®æŒ‘æˆ˜ã€‚

ç°æœ‰æ–¹æ³•å­˜åœ¨ä¸¤å¤§ç“¶é¢ˆï¼š
- **Semantic-level compression**ï¼ˆå¦‚ LC-Promptï¼‰è™½ç„¶èƒ½ä¿æŒé«˜å‡†ç¡®ç‡ï¼Œä½†å‹ç¼©æ¯”æœ‰é™ï¼ˆé€šå¸¸ <15%ï¼‰ï¼Œè¿‡äºä¿å®ˆï¼›
- **Token-level pruning**ï¼ˆå¦‚ TokenSkipï¼‰è™½å¯å®ç°æ›´é«˜å‹ç¼©æ¯”ï¼ˆ>40%ï¼‰ï¼Œä½†å› ç¼ºä¹è¯­ä¹‰ç†è§£ï¼Œå®¹æ˜“è¯¯åˆ å…³é”®æ¨ç†çº¿ç´¢ï¼ˆå¦‚æ•°å­—ã€è¿ç®—ç¬¦ï¼‰ï¼Œå¯¼è‡´å‡†ç¡®ç‡å¤§å¹…ä¸‹é™ã€‚

æ­¤å¤–ï¼Œç®€å•åœ°å°†ä¸¤ç§æ–¹æ³•ç»“åˆä¼šé¢ä¸´ä¸‰å¤§æŠ€æœ¯éš¾é¢˜ï¼š
1. **Sequential Dependency**ï¼šè¯­ä¹‰å‹ç¼©æ”¹å˜äº† token åˆ†å¸ƒï¼Œä½¿åŸºäºåŸå§‹ CoT è®­ç»ƒçš„ token pruner å¤±æ•ˆï¼›
2. **Task-Agnostic Blindness**ï¼šé€šç”¨ token pruner å¿½è§†æ•°å­¦æ¨ç†ä¸­çš„é€»è¾‘å…³é”®å…ƒç´ ï¼›
3. **Distribution Mismatch**ï¼šå‰ªæåçš„ç‰‡æ®µåŒ–è¾“å‡ºä¸è‡ªç„¶æµç•…çš„æ¨ç†é£æ ¼ä¸ä¸€è‡´ï¼Œå½±å“å¤šæ­¥æ¨ç†è¿è´¯æ€§ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **CtrlCoT**ï¼Œä¸€ç§**åŒç²’åº¦ï¼ˆdual-granularityï¼‰CoT å‹ç¼©æ¡†æ¶**ï¼Œé¦–æ¬¡ç³»ç»Ÿæ€§åœ°ååŒä¼˜åŒ–è¯­ä¹‰çº§æŠ½è±¡ä¸ token çº§å‰ªæï¼Œå®ç°å¯æ§ä¸”é«˜æ•ˆçš„æ¨ç†ã€‚

å…¶æ ¸å¿ƒç”±ä¸‰ä¸ªæ¨¡å—æ„æˆï¼š
- **Hierarchical Reasoning Abstraction (HRA)**  
  ç”Ÿæˆå››ç§ä¸åŒæŠ½è±¡å±‚çº§çš„ CoTï¼ˆDetailed, Standard, Concise, Ultra-Conciseï¼‰ï¼Œä¸ºåç»­ token å‰ªææä¾›å¤šå±‚æ¬¡è¯­ä¹‰è¡¥å¿ï¼Œç¼“è§£ Sequential Dependencyã€‚
  
- **Logic-Preserving Distillation (LPD)**  
  åˆ©ç”¨ GPT-4 æ„å»ºé«˜è´¨é‡æ•°å­¦ CoT çš„ token çº§å‹ç¼©ç›®æ ‡ï¼Œå¯¹ LLMLingua2 è¿›è¡Œè’¸é¦è®­ç»ƒï¼Œä½¿å…¶å…·å¤‡â€œé€»è¾‘æ„ŸçŸ¥â€èƒ½åŠ›ï¼Œä¿ç•™å…³é”®æ¨ç†å…ƒç´ ï¼ˆnumbers, operators, logical connectivesï¼‰ï¼Œè§£å†³ Task-Agnostic Blindnessã€‚

- **Distribution-Alignment Generation (DAG)**  
  è®­ç»ƒä¸€ä¸ª Multi-Ratio CoT Generator (MCG)ï¼Œåœ¨æŒ‡å®šå‹ç¼©æ¯”ä¾‹ä¸‹ç”Ÿæˆ**æµç•…ã€è¿è´¯**çš„ CoTï¼Œä½œä¸ºç›‘ç£ä¿¡å·ï¼Œä½¿è®­ç»ƒåˆ†å¸ƒä¸æ¨ç†æ—¶çš„ç”Ÿæˆé£æ ¼å¯¹é½ï¼Œæ¶ˆé™¤ Distribution Mismatchã€‚

æœ€ç»ˆè®­ç»ƒä¸¤ä¸ªæ¨ç†å™¨ï¼š
- **Budget-Controlled Reasoner (BCR)**ï¼šæ¥å—ç”¨æˆ·æŒ‡å®šçš„ token é¢„ç®— `b`ï¼Œç”Ÿæˆç¬¦åˆé•¿åº¦çº¦æŸçš„æ¨ç†é“¾ï¼›
- **Budget-Free Reasoner (BFR)**ï¼šè‡ªåŠ¨ä¸ºæ¯ä¸ªé—®é¢˜ç”Ÿæˆæœ€çŸ­ä¸”æ­£ç¡®çš„ CoTï¼Œæ— éœ€äººå·¥è®¾å®šé¢„ç®—ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´ä¼˜çš„ accuracy-cost æƒè¡¡**ï¼šåœ¨æ˜¾è‘—é™ä½ token æ•°é‡çš„åŒæ—¶ï¼Œå¤§å¹…æå‡å‡†ç¡®ç‡ï¼›
- **å¯æ§æ€§å¼º**ï¼šæ”¯æŒçµæ´»çš„ token é¢„ç®—æ§åˆ¶ï¼Œé€‚ç”¨äºä¸åŒèµ„æºåœºæ™¯ï¼›
- **è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜**ï¼šBFR å®ç°å…é¢„ç®—æ¨ç†ï¼Œæå‡å¯ç”¨æ€§ï¼›
- **é²æ£’æ€§å¥½**ï¼šåœ¨æç«¯å‹ç¼©æ¡ä»¶ä¸‹ä»ä¿æŒè¾ƒé«˜æ€§èƒ½ï¼Œè€ŒåŸºçº¿æ–¹æ³•ä¸¥é‡é€€åŒ–ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜åŸºå‡†ï¼Œå…± 7.5K é—®é¢˜ï¼Œæµ‹è¯•åŸºç¡€æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚
- **MATH-500**ï¼šä» MATH æ•°æ®é›†ä¸­æŠ½å–çš„ 500 é“é«˜éš¾åº¦æ•°å­¦é¢˜ï¼ˆæ¶µç›–ä»£æ•°ã€å‡ ä½•ã€å¾®ç§¯åˆ†ç­‰ï¼‰ï¼Œç”¨äºè¯„ä¼°å¤æ‚æ¨ç†æ€§èƒ½ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
#### æ¨¡å‹
ä½¿ç”¨å¤šä¸ªè§„æ¨¡çš„æŒ‡ä»¤è°ƒä¼˜æ¨¡å‹è¿›è¡ŒéªŒè¯ï¼š
- Qwen2.5-Instruct ç³»åˆ—ï¼š3B / 7B / 14B
- LLaMA-3.1-8B-Instruct

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ | æ„ä¹‰ |
|------|------|------|
| **Accuracy (Acc.)** | æ­£ç¡®å›ç­”çš„æ¯”ä¾‹ | æ¨ç†å‡†ç¡®æ€§ |
| **CoT Token Count** | æ¨ç†é“¾æ‰€ç”¨ token æ•°é‡ | æ¨ç†å¼€é”€ |
| **Compression Ratio (CR)** | ç›¸å¯¹äºåŸå§‹ CoT çš„ token å‡å°‘æ¯”ä¾‹ | å‹ç¼©æ•ˆç‡ |
| **Token Efficiency (TE)** | $ \text{TE} = \frac{\text{Acc.}}{\text{Tokens}} \times 100 $ | å•ä½ token çš„æ¨ç†æ”¶ç›Š |

#### å‹ç¼©å¼ºåº¦è®¾ç½®ï¼ˆCompression Strength, CSï¼‰
å®šä¹‰äº†ä» `High+++`ï¼ˆæœ€å¼ºï¼‰åˆ° `Low--`ï¼ˆæœ€å¼±ï¼‰çš„å¤šä¸ªå‹ç¼©ç­‰çº§ï¼Œå¯¹åº”å›ºå®šå‹ç¼©æ¯”ï¼ˆCRï¼‰ï¼Œç¡®ä¿è·¨æ–¹æ³•å…¬å¹³æ¯”è¾ƒã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **Original** | åŸå§‹ CoT | ä¸å‹ç¼©ï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™ |
| **LC-Prompt** | Prompt-based | é€šè¿‡æç¤ºè¯å¼•å¯¼ç”Ÿæˆè¾ƒçŸ­ CoTï¼Œå‹ç¼©æ¸©å’Œ |
| **Truncation** | Output-based | æˆªæ–­æ¨ç†é“¾è‡³ç›®æ ‡é•¿åº¦ï¼Œæ˜“ä¸¢å¤±å…³é”®ä¿¡æ¯ |
| **TokenSkip** | Token-level pruning | ä½¿ç”¨ LLMLingua2 è¿›è¡Œ token è·³è¿‡å‹ç¼© |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ Qwen2.5-7B-Instruct + MATH-500 ä¸ºä¾‹ï¼‰

| æ–¹æ³• | Acc. â†‘ | Tokens â†“ | CR â†“ | TE â†‘ |
|------|--------|----------|-------|-------|
| Original | 71.2% | 574.66 | 1.00 | 9.11 |
| TokenSkip (High) | 50.4% | 325.68 | 0.57 | 15.48 |
| **Ours (CtrlCoT, High)** | **58.0%** | **225.61** | **0.39** | **25.71** |

> âœ… **èŠ‚çœ 30.7% çš„ tokenï¼ŒåŒæ—¶å‡†ç¡®ç‡é«˜å‡º +7.6 ä¸ªç™¾åˆ†ç‚¹**

åœ¨ GSM8K ä¸Šä¹Ÿå–å¾—ä¼˜å¼‚è¡¨ç°ï¼š
- Qwen2.5-14B-Instruct ä¸‹ï¼Œç›¸æ¯”åŸå§‹æ¨¡å‹å‡å°‘ **55.7% token**ï¼Œå‡†ç¡®ç‡å‡ ä¹æ— æŸï¼ˆä»…ä¸‹é™çº¦ 0.3%ï¼‰ã€‚

### ä¸å…¶ä»–æ–¹æ³•å…¨é¢å¯¹æ¯”
- åœ¨æ‰€æœ‰æ¨¡å‹å°ºåº¦ï¼ˆ3B/7B/14Bï¼‰å’Œå‹ç¼©å¼ºåº¦ä¸‹ï¼ŒCtrlCoT **å§‹ç»ˆå¤„äº accuracy-token æ›²çº¿çš„å¸•ç´¯æ‰˜å‰æ²¿**ï¼ˆè§ Figure 4ï¼‰ã€‚
- ç›¸æ¯” TokenSkipï¼Œåœ¨åŒç­‰æˆ–æ›´ä½ token æ¶ˆè€—ä¸‹ï¼Œå‡†ç¡®ç‡æ™®éé«˜å‡º **5â€“10 ä¸ªç™¾åˆ†ç‚¹**ã€‚
- åœ¨å¼ºå‹ç¼©åœºæ™¯ï¼ˆHigh+++ï¼‰ä¸‹ä¼˜åŠ¿æ›´åŠ æ˜æ˜¾ï¼šä¾‹å¦‚åœ¨ Qwen2.5-7B ä¸Šï¼ŒTokenSkip å‡†ç¡®ç‡è·Œè‡³ 28.2%ï¼Œè€Œ CtrlCoT ä»ç»´æŒåœ¨ 49.4%ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

| å˜ä½“ | MATH-500 Acc. | Tokens | TE |
|------|---------------|--------|-----|
| w/o HRA | 51.4% | 298.52 | 17.22 |
| w/o LPD | 52.0% | 236.98 | 21.94 |
| w/o DAG | 54.2% | 223.76 | 24.22 |
| **Full CtrlCoT** | **58.0%** | **225.61** | **25.71** |

> ğŸ” ç»“æœè¡¨æ˜ï¼š
> - **HRA** å¯¹æ•´ä½“æ€§èƒ½æå‡æœ€å¤§ï¼Œè¯´æ˜å¤šç²’åº¦è¯­ä¹‰æŠ½è±¡æ˜¯æœ‰æ•ˆå‹ç¼©çš„åŸºç¡€ï¼›
> - **LPD** æ˜¾è‘—æå‡å‡†ç¡®æ€§ï¼Œè¯æ˜é€»è¾‘æ„ŸçŸ¥è’¸é¦è‡³å…³é‡è¦ï¼›
> - **DAG** æ”¹å–„ç”Ÿæˆè´¨é‡ï¼Œå‡å°‘ç¢ç‰‡åŒ–ï¼Œæå‡ TEã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **åŒç²’åº¦å‹ç¼©ä¼˜äºå•ä¸€ç­–ç•¥**ï¼šè¯­ä¹‰çº§ä¸ token çº§å‹ç¼©å…·æœ‰äº’è¡¥æ€§ï¼Œè”åˆä¼˜åŒ–å¯çªç ´å„è‡ªç“¶é¢ˆã€‚
2. **é€»è¾‘æ„ŸçŸ¥çš„ token å‰ªææ˜¯å¯è¡Œçš„**ï¼šé€šè¿‡è’¸é¦å¯è®© pruner å­¦ä¼šä¿ç•™æ•°å­¦æ¨ç†ä¸­çš„å…³é”®å…ƒç´ ï¼ˆå¦‚ `+`, `=`, æ•°å­—ç­‰ï¼‰ã€‚
3. **è®­ç»ƒ-æ¨ç†åˆ†å¸ƒå¯¹é½è‡³å…³é‡è¦**ï¼šç›´æ¥ä½¿ç”¨å‰ªææ–‡æœ¬ä½œä¸ºç›‘ç£ä¼šå¯¼è‡´ç”Ÿæˆæ–­è£‚ï¼ŒDAG æœºåˆ¶æœ‰æ•ˆç¼“è§£æ­¤é—®é¢˜ã€‚
4. **é¢„ç®—æ§åˆ¶å¯å®ç°ç»†ç²’åº¦è°ƒèŠ‚**ï¼šBCR èƒ½ç¨³å®šå“åº”ä¸åŒ token é¢„ç®—ï¼ŒCoT é•¿åº¦éšé¢„ç®—æ”¶ç´§å•è°ƒé€’å‡ï¼ˆè§ Figure 7ï¼‰ã€‚
5. **BFR å®ç°é«˜æ•ˆå…é…ç½®æ¨ç†**ï¼šåœ¨æ— éœ€æ‰‹åŠ¨è®¾é¢„ç®—çš„æƒ…å†µä¸‹ï¼Œè‡ªåŠ¨ç”Ÿæˆç®€æ´ä¸”æ­£ç¡®çš„ CoTï¼Œæ€§èƒ½ä¼˜äº TokenSkipã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ– backbone æ¨¡å‹çš„å¯æ§æ€§**ï¼šå½“å‰ LLM å¯¹ â€œä½¿ç”¨çº¦ X ä¸ª tokenâ€ è¿™ç±»æŒ‡ä»¤çš„éµå¾ªèƒ½åŠ›æœ‰é™ï¼Œå°¤å…¶åœ¨å°æ¨¡å‹ä¸Šå¯èƒ½å‡ºç° budget-length mismatchã€‚
- **ä¸»è¦éªŒè¯äºæ•°å­¦é¢†åŸŸ**ï¼šç›®å‰å®éªŒé›†ä¸­åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ï¼Œæ˜¯å¦æ³›åŒ–åˆ°å…¶ä»–é¢†åŸŸï¼ˆå¦‚ä»£ç ã€å¸¸è¯†æ¨ç†ï¼‰å°šéœ€éªŒè¯ã€‚
- **æ¢å¤æœºåˆ¶éå¿…é¡»ä½†å½±å“ä½“éªŒ**ï¼šå‹ç¼©å CoT å¯è¯»æ€§ä¸‹é™ï¼Œè™½å¯é€šè¿‡ recovery prompt æ¢å¤ï¼Œä½†å¢åŠ é¢å¤–è®¡ç®—ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† CtrlCoT æ‰©å±•è‡³éæ•°å­¦é¢†åŸŸï¼ˆå¦‚ç§‘å­¦é—®ç­”ã€ç¨‹åºåˆæˆï¼‰ï¼›
- æ¢ç´¢æ›´ç»†ç²’åº¦çš„å‹ç¼©ç­–ç•¥ï¼ˆå¦‚å­å¥çº§ã€è¡¨è¾¾å¼çº§ï¼‰ï¼›
- æå‡æ¨¡å‹å¯¹ budget æŒ‡ä»¤çš„ç²¾ç¡®å“åº”èƒ½åŠ›ï¼›
- ç»“åˆ speculative decoding æˆ– early exiting è¿›ä¸€æ­¥åŠ é€Ÿæ¨ç†ã€‚

--- 

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> CtrlCoT é€šè¿‡ **HRA + LPD + DAG** ä¸‰é‡æœºåˆ¶ï¼Œå®ç°äº†**é«˜ä¿çœŸã€é«˜å¯æ§ã€é«˜æ•ˆç‡**çš„ CoT å‹ç¼©ï¼Œåœ¨å¤šä¸ªæ•°å­¦æ¨ç†åŸºå‡†ä¸Šæ˜¾è‘—è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œæ¨åŠ¨äº†é«˜æ•ˆæ¨ç†æŠ€æœ¯çš„å‘å±•ã€‚

</details>

---

### 12. [REASON: Accelerating Probabilistic Logical Reasoning for Scalable Neuro-Symbolic Intelligence](https://arxiv.org/abs/2601.20784)

**Authors**: Zishen Wan, Che-Kai Liu, Jiayi Qian, Hanchen Yang, Arijit Raychowdhury, Tushar Krishna  
**Category**: cs.AI  
**Published**: 2026-01-29  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.20784v1  

#### Abstract
Neuro-symbolic AI systems integrate neural perception with symbolic reasoning to enable data-efficient, interpretable, and robust intelligence beyond purely neural models. Although this compositional paradigm has shown superior performance in domains such as reasoning, planning, and verification, it...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šREASON: Accelerating Probabilistic Logical Reasoning for Scalable Neuro-Symbolic Intelligence**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å½“å‰ **Neuro-Symbolic AI** ç³»ç»Ÿè™½ç„¶åœ¨æ•°å­¦æ¨ç†ã€è®¤çŸ¥æœºå™¨äººã€é€»è¾‘è§„åˆ’ç­‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç”±äºå…¶ **symbolic å’Œ probabilistic æ¨ç†æ¨¡å—** å­˜åœ¨ä¸¥é‡çš„ç³»ç»Ÿçº§æ•ˆç‡ç“¶é¢ˆï¼Œå¯¼è‡´éš¾ä»¥åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°å®æ—¶éƒ¨ç½²ã€‚

å…·ä½“æŒ‘æˆ˜åŒ…æ‹¬ï¼š
- **ä¸è§„åˆ™æ§åˆ¶æµ**ï¼ˆirregular control flowï¼‰
- **ä½ç®—æœ¯å¼ºåº¦**ï¼ˆlow arithmetic intensityï¼‰
- **éåˆå¹¶å†…å­˜è®¿é—®**ï¼ˆuncoalesced memory accessesï¼‰
- **CPU/GPU åˆ©ç”¨ç‡ä½ä¸‹**

è¿™äº›ç‰¹æ€§ä½¿å¾—ä¼ ç»Ÿç¡¬ä»¶ï¼ˆå¦‚ GPUï¼‰æ— æ³•é«˜æ•ˆæ‰§è¡Œ symbolic å’Œ probabilistic kernelsï¼Œé€ æˆç«¯åˆ°ç«¯å»¶è¿Ÿè¿‡é«˜ï¼ˆä¾‹å¦‚ Ctrl-G åœ¨æ¡Œé¢ GPU ä¸Šéœ€è¶…è¿‡ 5 åˆ†é’Ÿå®Œæˆå•ä¸ªä»»åŠ¡ï¼‰ï¼Œä¸¥é‡åˆ¶çº¦äº†å®é™…åº”ç”¨ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡º **REASON** â€”â€” ä¸€ä¸ªé¢å‘ **probabilistic logical reasoning** çš„é›†æˆåŒ–åŠ é€Ÿæ¡†æ¶ï¼Œé¦–æ¬¡å®ç°äº†å¯¹ç¥ç»-ç¬¦å·æ··åˆç³»ç»Ÿçš„è”åˆç®—æ³•-æ¶æ„-ç³»ç»ŸååŒä¼˜åŒ–ã€‚

#### **è·¨å±‚åˆ›æ–°è®¾è®¡**ï¼š
1. **ç®—æ³•å±‚**ï¼ˆAlgorithm Levelï¼‰  
   - å¼•å…¥ç»Ÿä¸€çš„ **Directed Acyclic Graph (DAG)** è¡¨ç¤ºï¼Œå°† FOLã€SATã€PCã€HMM ç­‰å¤šç§ symbolic/probabilistic æ¨¡å‹æŠ½è±¡ä¸ºå…±äº«è®¡ç®—ç»“æ„ã€‚
   - æå‡º **è‡ªé€‚åº”å‰ªæ**ï¼ˆadaptive DAG pruningï¼‰å’Œ **ä¸¤è¾“å…¥æ­£åˆ™åŒ–**ï¼ˆtwo-input DAG regularizationï¼‰ï¼Œæ˜¾è‘—é™ä½æ¨¡å‹å¤æ‚åº¦å¹¶æå‡ç¡¬ä»¶å‹å¥½æ€§ã€‚

2. **æ¶æ„å±‚**ï¼ˆArchitecture Levelï¼‰  
   - è®¾è®¡åŸºäº **å¯é‡æ„æ ‘å½¢å¤„ç†å•å…ƒ**ï¼ˆtree-based PEsï¼‰çš„ç¡¬ä»¶æ¶æ„ï¼Œæ”¯æŒ symbolicã€probabilistic å’Œéƒ¨åˆ†ç¥ç»æ“ä½œã€‚
   - åŒ…å«ä¸“ç”¨ç»„ä»¶å¦‚ **watched literals unit**ã€**BCP FIFO**ã€**Benes ç½‘ç»œäº’è¿**ï¼Œä»¥é«˜æ•ˆæ”¯æŒ SAT/FOL æ¨ç†ä¸­çš„å¹¿æ’­-å½’çº¦æ¨¡å¼ã€‚

3. **ç³»ç»Ÿå±‚**ï¼ˆSystem Levelï¼‰  
   - ä¸ GPU Streaming Multiprocessors (SMs) ç´§è€¦åˆé›†æˆï¼Œé€šè¿‡ **programmable interface** å’Œ **ä¸¤çº§æµæ°´çº¿** å®ç°ç¥ç»ä¸ç¬¦å·æ¨ç†çš„å¹¶è¡Œæ‰§è¡Œã€‚
   - æ”¯æŒçµæ´»çš„ä»»åŠ¡è°ƒåº¦ä¸åŒæ­¥æœºåˆ¶ï¼Œæœ€å¤§åŒ–ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **é€šç”¨æ€§** | æ”¯æŒå¤šç§ symbolic/probabilistic kernelsï¼ˆFOL, SAT, PC, HMMï¼‰ï¼Œè€Œéå•ä¸€ä»»åŠ¡ä¸“ç”¨åŠ é€Ÿå™¨ |
| **æ•ˆç‡** | é’ˆå¯¹ç¨€ç–ã€ä¸è§„åˆ™å›¾ç»“æ„ä¼˜åŒ–ï¼Œé¿å…ä¼ ç»Ÿ GPU ä¸Šçš„å†…å­˜å¢™é—®é¢˜ |
| **å¯æ‰©å±•æ€§** | æ ‘å½¢æ‹“æ‰‘å®ç° O(log N) å¹¿æ’­å»¶è¿Ÿï¼Œä¼˜äº mesh æˆ– bus æ¶æ„ |
| **é›†æˆæ€§** | å¯ä½œä¸º GPU æ’ä»¶å…±å­˜ï¼Œæ— éœ€æ›¿æ¢ä¸»è®¡ç®—å¹³å° |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
åœ¨ **10 ä¸ªå…¸å‹æ¨ç†ä»»åŠ¡** ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œæ¶µç›–å¤šä¸ªé¢†åŸŸï¼š
- æ•°å­¦å®šç†è¯æ˜ï¼š`IMO`, `MiniF2F`
- å®‰å…¨æ£€æµ‹ï¼š`TwinSafety`, `XSTest`
- æ–‡æœ¬ç”Ÿæˆçº¦æŸæ»¡è¶³ï¼š`CommonGen`, `News`
- å›¾è°±æ¨ç†ï¼š`CoAuthor`, `AwA2`
- é€»è¾‘é—®ç­”ï¼š`FOLIO`, `ProofWriter`

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **ç¡¬ä»¶é…ç½®**
- **REASON å®ç°**ï¼šåŸºäº TSMC 28nm å·¥è‰ºç»¼åˆï¼Œé¢ç§¯ 6 mmÂ²ï¼ŒåŠŸè€— 2.12 W
- **æ¨¡æ‹Ÿç¯å¢ƒ**ï¼šä½¿ç”¨ Accel-Sim + GPGPU-Sim æ„å»º cycle-accurate ä»¿çœŸå™¨ï¼Œæ¨¡æ‹Ÿä¸ Orin NX çš„é›†æˆ
- **é€šä¿¡å»ºæ¨¡**ï¼šä»çœŸå®æ‰§è¡Œä¸­æå– memory traceï¼Œç”¨äºç²¾ç¡®å»ºæ¨¡æ•°æ®ä¼ è¾“å¼€é”€

#### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| **ç«¯åˆ°ç«¯å»¶è¿Ÿ**ï¼ˆEnd-to-end latencyï¼‰ | ä»è¾“å…¥åˆ°è¾“å‡ºçš„æ•´ä½“æ¨ç†æ—¶é—´ |
| **èƒ½æ•ˆæ¯”**ï¼ˆEnergy efficiencyï¼‰ | æ€§èƒ½ / èƒ½è€—ï¼ˆå•ä½ï¼šÃ— over baselineï¼‰ |
| **å‡†ç¡®ç‡**ï¼ˆAccuracy/AUPRC/BLEUï¼‰ | ä¿è¯æ€§èƒ½æ— æŸçš„å‰æä¸‹è¯„ä¼°åŠ é€Ÿæ•ˆæœ |
| **å†…å­˜å ç”¨**ï¼ˆMemory footprintï¼‰ | DAG å‰ªæåçš„æ¨¡å‹å¤§å°ç¼©å‡æ¯”ä¾‹ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åŸºçº¿ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| **Orin NX** | è¾¹ç¼˜ GPU | ä»£è¡¨ä¸»æµè¾¹ç¼˜ AI å¹³å° |
| **RTX A6000** | æ•°æ®ä¸­å¿ƒ GPU | é«˜æ€§èƒ½ GPU åŸºçº¿ |
| **Xeon CPU** | é€šç”¨å¤„ç†å™¨ | å¤šæ ¸æœåŠ¡å™¨ CPU |
| **TPU** | DNN åŠ é€Ÿå™¨ | systolic array æ¶æ„ |
| **DPU-like** | DAG åŠ é€Ÿå™¨ | tree-based æ¶æ„ï¼ˆå¦‚ DPU-v2ï¼‰ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **å¹³å‡é€Ÿåº¦æå‡** | **12â€“50Ã—** è¶…è¿‡æ¡Œé¢/è¾¹ç¼˜ GPU |
| **èƒ½æ•ˆæå‡** | **310â€“681Ã—** è¶…è¿‡ GPU/CPU åŸºçº¿ |
| **å•ä»»åŠ¡å»¶è¿Ÿ** | **0.8 ç§’å†…å®Œæˆç«¯åˆ°ç«¯æ¨ç†**ï¼ˆreal-time capableï¼‰ |
| **èŠ¯ç‰‡é¢ç§¯** | **6 mmÂ²**ï¼ˆTSMC 28nmï¼‰ |
| **å¹³å‡åŠŸè€—** | **2.12 W** |

> âœ… ç‰¹åˆ«åœ°ï¼Œåœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ï¼ˆå¦‚ IMOï¼‰ä¸Šï¼ŒREASON å®ç°äº† **50.65Ã—**ï¼ˆvs Orin NXï¼‰ã€**11.98Ã—**ï¼ˆvs RTX A6000ï¼‰çš„é€Ÿåº¦æå‡ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
| å¯¹æ¯”é¡¹ | å‘ç° |
|--------|------|
| **vs GPU (PyTorch + CUDA)** | symbolic kernels å†…å­˜å—é™ï¼ŒALU åˆ©ç”¨ç‡ < 30%ï¼ŒDRAM BW åˆ©ç”¨ç‡è¾¾ 70% |
| **vs CPU** | å¹¶è¡Œæ•ˆç‡ < 5%ï¼Œæ§åˆ¶å‘æ•£ä¸¥é‡ |
| **vs TPU-like systolic array** | ç¥ç»éƒ¨åˆ†æ€§èƒ½ç›¸å½“ï¼Œä½† symbolic éƒ¨åˆ†æ…¢ 70â€“90Ã— |
| **vs DPU-like tree array** | REASON åœ¨ symbolic ä»»åŠ¡ä¸Šå¿« **7â€“10Ã—**ï¼Œå› æ”¯æŒåŠ¨æ€è°ƒåº¦ä¸å†²çªå¤„ç† |

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

#### **ç®—æ³•ä¼˜åŒ–æœ‰æ•ˆæ€§ï¼ˆTab. IVï¼‰**
| æ–¹æ³• | å¹³å‡å†…å­˜å‹ç¼©ç‡ | å‡†ç¡®ç‡å˜åŒ– |
|------|----------------|-----------|
| ç»Ÿä¸€ DAG è¡¨ç¤º + è‡ªé€‚åº”å‰ªæ | **31.7% â†“** | â‰ˆ ä¿æŒï¼ˆÂ±1%ï¼‰ |
| ä¾‹ï¼šR2-Guard åœ¨ TwinSafety ä¸Šå†…å­˜å‡å°‘ **37%**ï¼ŒAUPRC ä»…ä¸‹é™ 0.006 |

#### **ååŒè®¾è®¡å¿…è¦æ€§ï¼ˆTab. Vï¼‰**
| é…ç½® | å½’ä¸€åŒ–è¿è¡Œæ—¶é—´ |
|------|----------------|
| Baselineï¼ˆåŸç”Ÿæ¨¡å‹ + Orin NXï¼‰ | 100% |
| REASON ç®—æ³•ä¼˜åŒ– + Orin NX | **78.3% â†“** |
| REASON ç®—æ³• + REASON ç¡¬ä»¶ | **2.04% â†“**ï¼ˆå³ **49Ã— åŠ é€Ÿ**ï¼‰ |

> ğŸ” è¡¨æ˜ï¼š**ç®—æ³•ä¸ç¡¬ä»¶ååŒè®¾è®¡æ˜¯å®ç°æè‡´åŠ é€Ÿçš„å…³é”®**ã€‚

#### **ç¡¬ä»¶æŠ€æœ¯è´¡çŒ®**
- **å¯„å­˜å™¨é“¶è¡Œæ˜ å°„ä¼˜åŒ–**ï¼šå¹³å‡é™ä½ **22%** è¿è¡Œæ—¶é—´
- **å¯é‡æ„é˜µåˆ— + è°ƒåº¦ç­–ç•¥**ï¼šè¿›ä¸€æ­¥é™ä½è‡³ **56%** å’Œ **73%**

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **Probabilistic logical reasoning æ˜¯ Neuro-Symbolic AI çš„æ€§èƒ½ç“¶é¢ˆ**  
   - åœ¨å¤šä¸ªä»£è¡¨æ€§å·¥ä½œä¸­ï¼Œsymbolic/probabilistic kernels å æ® **>60%** çš„ç«¯åˆ°ç«¯è¿è¡Œæ—¶é—´ã€‚
   - å…¶å†…å­˜å¸¦å®½åˆ©ç”¨ç‡é«˜ã€ALU åˆ©ç”¨ç‡ä½ï¼Œå‘ˆç°å…¸å‹çš„ **memory-bound** ç‰¹å¾ã€‚

2. **ç»Ÿä¸€ DAG æŠ½è±¡æœ‰æ•ˆæ•æ‰å…±æ€§ç»“æ„**  
   - FOLã€SATã€PCã€HMM å‡å¯è¢«å»ºæ¨¡ä¸º DAGï¼Œæ”¯æŒç»Ÿä¸€ç¼–è¯‘ã€å‰ªæä¸æ˜ å°„ã€‚
   - è‡ªé€‚åº”å‰ªæå¯åœ¨å‡ ä¹ä¸æŸå¤±ç²¾åº¦çš„æƒ…å†µä¸‹å¤§å¹…å‹ç¼©æ¨¡å‹ã€‚

3. **å¯é‡æ„æ ‘å½¢æ¶æ„é€‚åˆ irregular symbolic æ¨ç†**  
   - æ”¯æŒé«˜æ•ˆçš„ broadcast/reduction æ“ä½œï¼Œå¤©ç„¶å¥‘åˆ DPLL/CDCL æµç¨‹ã€‚
   - O(log N) å¹¿æ’­å»¶è¿Ÿç¡®ä¿è‰¯å¥½çš„å¯æ‰©å±•æ€§ã€‚

4. **ä¸ GPU ç´§è€¦åˆç³»ç»Ÿè®¾è®¡è‡³å…³é‡è¦**  
   - ä¸¤çº§æµæ°´çº¿ï¼ˆGPU-REASON pipeline + Intra-REASON pipelineï¼‰æœ‰æ•ˆéšè—å»¶è¿Ÿã€‚
   - å…±äº« L2 ç¼“å­˜ä¸æœ¬åœ°å†…å­˜å‡å°‘è·¨è®¾å¤‡é€šä¿¡å¼€é”€ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
| å±€é™ | è¯´æ˜ |
|------|------|
| **å®šåˆ¶åŒ–ç¨‹åº¦è¾ƒé«˜** | å½“å‰ REASON éœ€è¦ç¦»çº¿ç¼–è¯‘ DAGï¼Œå¯¹åŠ¨æ€å˜åŒ–çš„ symbolic ç»“æ„é€‚åº”èƒ½åŠ›æœ‰é™ |
| **å·¥è‰ºèŠ‚ç‚¹è¾ƒæ—§** | å½“å‰å®ç°åŸºäº 28nmï¼Œè‹¥è¿ç§»åˆ° 7nm/5nm å¯è¿›ä¸€æ­¥ç¼©å°é¢ç§¯ä¸åŠŸè€— |
| **æœªè¦†ç›–æ‰€æœ‰ symbolic å½¢å¼** | å¦‚é«˜é˜¶é€»è¾‘ã€åŠ¨æ€è§„åˆ’ç­‰å°šæœªå®Œå…¨æ”¯æŒ |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ”¯æŒåœ¨çº¿ç¼–è¯‘ä¸åŠ¨æ€ DAG é‡æ„**ï¼Œå¢å¼ºå¯¹å¼€æ”¾åŸŸä»»åŠ¡çš„é€‚åº”æ€§
2. **æ‰©å±•è‡³ LLM + Tools Agent æ¶æ„**ï¼Œæ”¯æŒæ›´å¤æ‚çš„ agentic workflows
3. **æ¢ç´¢ 3D é›†æˆæˆ–è¿‘å­˜è®¡ç®—æ¶æ„**ï¼Œè¿›ä¸€æ­¥ç¼“è§£å†…å­˜å¢™é—®é¢˜
4. **å¼€æº REASON ç¼–è¯‘å™¨æ ˆä¸ RTL**ï¼Œæ¨åŠ¨ç¤¾åŒºå…±å»ºç”Ÿæ€

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **REASON é€šè¿‡ç®—æ³•-æ¶æ„-ç³»ç»ŸååŒè®¾è®¡ï¼Œé¦–æ¬¡å®ç°äº†å¯¹ probabilistic logical reasoning çš„é«˜æ•ˆåŠ é€Ÿï¼Œä½¿ Neuro-Symbolic AI åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„å®æ—¶éƒ¨ç½²æˆä¸ºå¯èƒ½ï¼Œä¸ºä¸‹ä¸€ä»£å¯è§£é‡Šã€å¯éªŒè¯çš„è®¤çŸ¥æ™ºèƒ½ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚**

</details>

---

### 13. [PILOT: Planning via Internalized Latent Optimization Trajectories for Large Language Models](https://arxiv.org/abs/2601.19917)

**Authors**: Haoyu Zheng, Yun Zhu, Yuqian Yuan, Bo Yuan, Wenqiao Zhang, Siliang Tang, Jun Xiao  
**Category**: cs.CL  
**Published**: 2026-01-29  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.19917v1  

#### Abstract
Strategic planning is critical for multi-step reasoning, yet compact Large Language Models (LLMs) often lack the capacity to formulate global strategies, leading to error propagation in long-horizon tasks. Our analysis reveals that LLMs possess latent reasoning capabilities that can be unlocked when...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPILOT: Planning via Internalized Latent Optimization Trajectories for Large Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰çš„ç´§å‡‘å‹ **Large Language Models (LLMs)** åœ¨å¤šæ­¥æ¨ç†ä»»åŠ¡ä¸­å¸¸å› ç¼ºä¹å…¨å±€æˆ˜ç•¥è§„åˆ’èƒ½åŠ›è€Œå‡ºç°â€œçŸ­è§†â€ç”Ÿæˆè¡Œä¸ºï¼Œå¯¼è‡´æ—©æœŸæ¨ç†é”™è¯¯åœ¨é•¿ç¨‹æ¨ç†è½¨è¿¹ä¸­ä¸æ–­ç´¯ç§¯ï¼Œå³ **error propagation**ã€‚è™½ç„¶å·²æœ‰æ–¹æ³•é€šè¿‡å¤–éƒ¨å¼•å¯¼ï¼ˆå¦‚æ•™å¸ˆæ¨¡å‹ï¼‰æå‡æ¨ç†è´¨é‡ï¼Œä½†è¿™ç±»æ–¹æ³•ä¾èµ–è¿è¡Œæ—¶è°ƒç”¨å¤§æ¨¡å‹ï¼Œå¸¦æ¥æ˜¾è‘—çš„ **latency** å’Œè®¡ç®—å¼€é”€ï¼Œéš¾ä»¥å®ç”¨åŒ–ã€‚

æ­¤å¤–ï¼Œç°æœ‰çš„å†…éƒ¨é€‚é…æ–¹æ³•ï¼ˆå¦‚ LoRAã€ReFTï¼‰é€šå¸¸è¿›è¡Œé™æ€å‚æ•°æ›´æ–°ï¼Œæ— æ³•ä¸ºæ¯ä¸ªè¾“å…¥å®ä¾‹æä¾›åŠ¨æ€çš„æˆ˜ç•¥å¼•å¯¼ï¼›è€Œç›´æ¥ä¿®æ”¹éšçŠ¶æ€çš„æ–¹æ³•ï¼ˆå¦‚ Coconutï¼‰å¯èƒ½ç ´åé¢„è®­ç»ƒè¡¨å¾æµå½¢ï¼Œå¼•å‘ **catastrophic forgetting**ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **PILOT (Planning via Internalized Latent Optimization Trajectories)**ï¼Œä¸€ç§éä¾µå…¥å¼çš„æ¡†æ¶ï¼Œæ—¨åœ¨å°†å¤§å‹æ¨¡å‹çš„æˆ˜ç•¥ç›‘ç£èƒ½åŠ›å†…åŒ–ä¸ºæ¨¡å‹è‡ªèº«çš„ **Latent Guidance**ã€‚

å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- ä¸æ”¹å˜ä¸»å¹²æ¨¡å‹æƒé‡ï¼ˆnon-invasiveï¼‰ï¼Œè€Œæ˜¯å¼•å…¥ä¸€ä¸ªè½»é‡çº§çš„ **Hyper-Network**ã€‚
- è¯¥ç½‘ç»œæ ¹æ®è¾“å…¥æŸ¥è¯¢ $x$ åŠ¨æ€ç”Ÿæˆä¸€ä¸ª **query-conditioned Latent Guidance å‘é‡ $z$**ã€‚
- æ­¤å‘é‡ä½œä¸ºå†…éƒ¨å¼•å¯¼æœºåˆ¶ï¼Œåœ¨ Transformer çš„æŸä¸ªæ·±å±‚ï¼ˆpivot layerï¼‰æ³¨å…¥ï¼Œå¼•å¯¼æ¨¡å‹æœå‘æœ€ä¼˜æ¨ç†è·¯å¾„æ¼”åŒ–ã€‚

è¿™ç§æ–¹æ³•å®ç°äº†â€œå†…éƒ¨åŒ–çš„è®¡åˆ’â€â€”â€”è®©å°æ¨¡å‹åœ¨ä¸ä¾èµ–å¤–éƒ¨å®æ—¶æŒ‡å¯¼çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½å…·å¤‡ç±»ä¼¼å¤§æ¨¡å‹çš„é«˜é˜¶è§„åˆ’èƒ½åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | PILOT | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ CoTã€LoRAã€Soft CoTã€CAAï¼‰ |
|------|-------|----------------------------------------|
| **æ¨ç†å»¶è¿Ÿ** | å‡ ä¹æ— é¢å¤–å¼€é”€ï¼ˆä»…ä¸€æ¬¡å‰å‘ä¼ æ’­ Hyper-Networkï¼‰ | å¤–éƒ¨å¼•å¯¼ç±»æ–¹æ³•å»¶è¿Ÿé«˜ï¼›éƒ¨åˆ†æ–¹æ³•éœ€é‡å¤é‡‡æ · |
| **é€‚åº”æ€§** | å®ä¾‹çº§åˆ«åŠ¨æ€å¼•å¯¼ï¼ˆinstance-specificï¼‰ | é™æ€å¹²é¢„ï¼ˆå¦‚ LoRAï¼‰ã€å›ºå®šå‘é‡ï¼ˆå¦‚ CAAï¼‰ |
| **ç¨³å®šæ€§** | é€šè¿‡ Energy-Aligned Injection ä¿æŒè¡¨å¾æµå½¢ä¸€è‡´ï¼Œé¿å…â€œembedding shockâ€ | ç›´æ¥ç¼–è¾‘æ¿€æ´»æ˜“é€ æˆåˆ†å¸ƒåç§» |
| **é€šç”¨æ€§** | å¯è¿ç§»è‡³æ•°å­¦ä¸ç¼–ç¨‹ç­‰å¤šç§å¤æ‚æ¨ç†ä»»åŠ¡ | å¾ˆå¤šæ–¹æ³•å¯¹ç‰¹å®šä»»åŠ¡è¿‡æ‹Ÿåˆ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- **æ•°å­¦æ¨ç†ä»»åŠ¡**ï¼š
  - **MATH500**ï¼šä» MATH æ•°æ®é›†ä¸­ç­›é€‰å‡ºçš„ 500 é“éš¾é¢˜å­é›†ï¼Œç”¨äºä¸»è¯„ä¼°ã€‚
  - **AIMO Val**ï¼šAMC æ°´å¹³ç«èµ›é¢˜ï¼Œå…± 83 é¢˜ï¼Œæµ‹è¯•æ¨¡å‹åœ¨é«˜éš¾åº¦æ•°å­¦é—®é¢˜ä¸Šçš„è¡¨ç°ã€‚
  - **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼Œç”¨äºæ£€éªŒé²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚
- **ä»£ç ç”Ÿæˆä»»åŠ¡**ï¼š
  - **HumanEval**ï¼šå‡½æ•°çº§ä»£ç ç”ŸæˆåŸºå‡†ã€‚
  - **MBPP (Mostly Basic Python Problems)**ï¼šåŸºç¡€ Python ç¼–ç¨‹ä»»åŠ¡é›†åˆã€‚

> æ‰€æœ‰è®­ç»ƒæ•°æ®å‡ç»è¿‡ **Construct-and-Verify Pipeline** è¿‡æ»¤ï¼Œæ„å»ºé«˜è´¨é‡ä¸‰å…ƒç»„ $(x, g_{\text{exp}}, y^*)$ï¼Œç¡®ä¿åªæœ‰å½“åŸºç¡€æ¨¡å‹å¤±è´¥ä½†åŠ å…¥ä¸“å®¶å¯å‘åæˆåŠŸçš„é—®é¢˜æ‰è¢«ä¿ç•™ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **è¯„ä¼°æŒ‡æ ‡**ï¼šPass@1 å‡†ç¡®ç‡ï¼ˆå•æ¬¡ç”Ÿæˆå³æ­£ç¡®ï¼‰ã€‚
- **è§£ç ç­–ç•¥**ï¼šgreedy decodingï¼ˆtemperature=0ï¼‰ï¼Œä¿è¯å¯å¤ç°æ€§ã€‚
- **è®­ç»ƒæ–¹å¼**ï¼šä¸¤é˜¶æ®µè¯¾ç¨‹å­¦ä¹ ï¼ˆcurriculum learningï¼‰ï¼š
  1. **Phase 1: Latent Alignment**ï¼šå†»ç»“ä¸»å¹²ï¼Œæœ€å°åŒ–é¢„æµ‹é”šç‚¹ä¸ç›®æ ‡çŠ¶æ€ä¹‹é—´çš„ä½™å¼¦è·ç¦»ã€‚
  2. **Phase 2: Anchored SFT**ï¼šç»§ç»­ä¼˜åŒ–é€‚é…å™¨ç»„ä»¶ï¼ŒåŒæ—¶ä¿ç•™å¯¹é½æŸå¤±å’Œé—¨æ§æ­£åˆ™é¡¹ã€‚
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA H20 GPUã€‚
- **æŠ¥å‘Šæ–¹å¼**ï¼š5 æ¬¡ç‹¬ç«‹è¿è¡Œçš„å¹³å‡å€¼ Â± æ ‡å‡†å·®ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | æ–¹æ³• | ç®€è¦è¯´æ˜ |
|------|------|----------|
| **ç¦»æ•£æç¤ºæ³•** | Zero-shot CoT | åŸºç¡€é“¾å¼æ€ç»´æç¤ºï¼Œæ— ä»»ä½•å¹²é¢„ |
| **é™æ€è°ƒå‚æ³•** | LoRA, Soft CoT | å‚æ•°é«˜æ•ˆå¾®è°ƒï¼Œå­¦ä¹ å›ºå®šé€‚é… |
| **éšçŠ¶æ€å¹²é¢„æ³•** | ReFT, CAA | ä¿®æ”¹éšè—å±‚è¡¨ç¤ºï¼Œä½¿ç”¨ä½ç§©æˆ–å¯¹æ¯”å‘é‡å¼•å¯¼ |
| **æ‰©å±•è®¡ç®—æ³•** | Pause Tokens, Coconut | å¼•å…¥é¢å¤– token æä¾›æ›´å¤šâ€œæ€è€ƒæ—¶é—´â€ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

#### æ•°å­¦æ¨ç†ï¼ˆMATH500 ä¸Šçš„ Pass@1ï¼‰
| æ–¹æ³• | Qwen2.5-1.5B | Qwen2.5-7B | Llama-3.1-8B |
|------|--------------|------------|---------------|
| Zero-shot CoT | 43.20 | 71.00 | 47.60 |
| LoRA | 47.24 | 72.84 | 47.92 |
| Soft CoT | 49.32 | 73.20 | 48.48 |
| **PILOT (Ours)** | **52.08** (+8.88â†‘) | **75.24** (+4.24â†‘) | **51.64** (+4.04â†‘) |

> âœ… åœ¨æ‰€æœ‰è§„æ¨¡æ¨¡å‹ä¸Šå‡æ˜¾è‘—é¢†å…ˆï¼Œå°¤å…¶åœ¨å°æ¨¡å‹ï¼ˆ1.5Bï¼‰ä¸Šæå‡æœ€å¤§ï¼Œè¡¨æ˜ PILOT èƒ½æœ‰æ•ˆæ¿€æ´»æ½œåœ¨æ¨ç†èƒ½åŠ›ã€‚

#### ä»£ç ç”Ÿæˆï¼ˆHumanEval ä¸Šçš„ Pass@1ï¼‰
| æ–¹æ³• | Qwen2.5-1.5B | Qwen2.5-7B | Llama-3.1-8B |
|------|--------------|------------|---------------|
| Zero-shot CoT | 46.34 | 71.34 | 53.05 |
| LoRA | 50.12 | 75.73 | 57.07 |
| **PILOT (Ours)** | **56.34** (+10.00â†‘) | **77.44** (+1.71â†‘) | **58.41** (+5.36â†‘) |

> âœ… åœ¨ HumanEval ä¸Šå…¨é¢è¶…è¶ŠåŸºçº¿ï¼Œå°¤å…¶åœ¨ 1.5B å°æ¨¡å‹ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ä¼˜äºæ‰€æœ‰ baselines**ï¼šåœ¨æ•°å­¦å’Œç¼–ç ä¸¤å¤§é¢†åŸŸï¼ŒPILOT åœ¨ä¸åŒè§„æ¨¡æ¨¡å‹ä¸Šå‡å–å¾—æœ€ä½³æ€§èƒ½ã€‚
- **æ˜¾è‘—ä¼˜äºé™æ€è°ƒå‚æ–¹æ³•**ï¼šè¯´æ˜åŠ¨æ€ã€å®ä¾‹ç›¸å…³çš„å¼•å¯¼æ¯”å›ºå®šå‚æ•°æ›´æ–°æ›´æœ‰æ•ˆã€‚
- **ä¼˜äºéšçŠ¶æ€å¹²é¢„æ–¹æ³•ï¼ˆReFT/CAAï¼‰**ï¼šè¯æ˜ PILOT çš„ Energy-Aligned Injection æ›´ç¨³å®šï¼Œä¸æ˜“å¼•èµ·â€œembedding shockâ€ã€‚
- **ä¼˜äº Pause Tokens / Coconut**ï¼šè¯´æ˜å•çº¯å¢åŠ è®¡ç®—é¢„ç®—ä¸å¦‚ç»“æ„æ€§å¼•å¯¼æœ‰æ•ˆã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰

| æ¶ˆèé…ç½® | MATH (1.5B) | HEval (7B) | MATH (7B) | HEval (7B) |
|---------|-------------|-----------|-----------|-----------|
| **PILOT (Full)** | 52.08 | 56.34 | 75.24 | 77.44 |
| w/o Hyper-Net (é™æ€é”šç‚¹) | 47.72 â†“ | 50.37 â†“ | 72.84 â†“ | 72.68 â†“ |
| w/o Proto-Thought | 48.84 â†“ | 54.39 â†“ | 74.52 â†“ | 76.71 â†“ |
| w/o Energy-Alignment | 49.16 â†“ | 51.22 â†“ | 75.04 â‰ˆ | **73.17 â†“â†“** |

> ğŸ” å‘ç°ï¼š
- **Hyper-Network è‡³å…³é‡è¦**ï¼šå»é™¤åæ€§èƒ½å¤§å¹…ä¸‹é™ï¼ŒéªŒè¯äº†åŠ¨æ€ç”Ÿæˆçš„é‡è¦æ€§ã€‚
- **Proto-Thought prior æœ‰åŠ©äºå†·å¯åŠ¨**ï¼šå°¤å…¶åœ¨å°æ¨¡å‹å’Œæ•°å­¦ä»»åŠ¡ä¸­ä½œç”¨æ˜æ˜¾ã€‚
- **Energy-Alignment å¯¹ä»£ç ä»»åŠ¡å°¤ä¸ºå…³é”®**ï¼šå»é™¤å HumanEval æ€§èƒ½æš´è·Œï¼Œè¯´æ˜ä»£ç ç”Ÿæˆå¯¹èƒ½é‡å°ºåº¦æ•æ„Ÿï¼Œéœ€é˜²æ­¢ç»“æ„å´©æºƒã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **LLMs å…·å¤‡æ½œè—çš„æ¨ç†èƒ½åŠ›**ï¼Œå¯é€šè¿‡åˆé€‚çš„å†…éƒ¨å¼•å¯¼æœºåˆ¶è¢«æ¿€æ´»ã€‚
2. **æ˜¾å¼è®¡åˆ’å¯ä»¥è¢«å†…åŒ–ä¸ºéšç©ºé—´ä¸­çš„é”šå®šå‘é‡**ï¼Œæ— éœ€ä¾èµ–å¤–éƒ¨æ¨¡å‹å®æ—¶å¹²é¢„ã€‚
3. **åŠ¨æ€ã€è¾“å…¥æ¡ä»¶åŒ–çš„å¼•å¯¼ä¼˜äºé™æ€å¹²é¢„**ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åŒ¹é…å¤šæ ·åŒ–é€»è¾‘éœ€æ±‚ã€‚
4. **Energy-Aligned Injection æ˜¯ç¨³å®šçš„å…³é”®**ï¼šé€šè¿‡æ§åˆ¶æ³¨å…¥å¼ºåº¦ä¸ä¸Šä¸‹æ–‡èƒ½é‡å¯¹é½ï¼Œé¿å…ç ´ååŸæœ‰è¯­ä¹‰ç»“æ„ã€‚
5. **PILOT å®ç°äº†æä½æ¨ç†å¼€é”€ä¸‹çš„æ€§èƒ½è·ƒå‡**ï¼šPrefill é˜¶æ®µä»…å¢åŠ  +3.1msï¼Œæ€»å»¶è¿Ÿå¢åŠ  <0.2%ï¼Œè¿œä½äº Soft CoTï¼ˆ+6.2%ï¼‰ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **æ•°æ®æ„é€ æˆæœ¬è¾ƒé«˜**ï¼šConstruct-and-Verify æµç¨‹éœ€è¦å…ˆè¿è¡Œæ•™å¸ˆæ¨¡å‹ç”Ÿæˆé«˜è´¨é‡è½¨è¿¹å¹¶è¿‡æ»¤ï¼Œå¢åŠ äº†ç¦»çº¿å‡†å¤‡è´Ÿæ‹…ã€‚
2. **æ’å…¥å±‚ä¸ºé™æ€è¶…å‚æ•°**ï¼šç›®å‰ pivot layer $l'$ æ˜¯æŒ‰ä»»åŠ¡æ‰‹åŠ¨è®¾å®šï¼ˆå¦‚æ•°å­¦é€‰æ·±å±‚æ•°ï¼Œä»£ç é€‰ä¸­é—´å±‚ï¼‰ï¼Œå°šæœªå®ç°å®Œå…¨åŠ¨æ€é€‰æ‹©ã€‚
3. **è·¨åŸŸæ³›åŒ–ä»æœ‰é™**ï¼šå°½ç®¡æœ‰åˆæ­¥è¯æ®æ˜¾ç¤ºå¯åœ¨æ•°å­¦ä¸ä»£ç é—´è¿ç§»ï¼ˆè§ Appendix Eï¼‰ï¼Œä½†æœªç³»ç»Ÿæ¢ç´¢æ›´å¹¿æ³›çš„é¢†åŸŸè¿ç§»èƒ½åŠ›ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- è®¾è®¡ **åŠ¨æ€å±‚é€‰æ‹©æœºåˆ¶**ï¼Œæ ¹æ®è¾“å…¥è‡ªåŠ¨å†³å®šæœ€ä½³é”šç‚¹æ³¨å…¥ä½ç½®ã€‚
- æ¢ç´¢ **å®Œå…¨è‡ªè’¸é¦ç‰ˆæœ¬**ï¼ˆå¦‚ PILOT(Self)ï¼‰ï¼Œå‡å°‘å¯¹å¤–éƒ¨æ•™å¸ˆæ¨¡å‹çš„ä¾èµ–ã€‚
- å°† PILOT åº”ç”¨äºæ›´å¤šå¤æ‚ä»»åŠ¡ï¼Œå¦‚å¤šè·³é—®ç­”ã€ç§‘å­¦æ¨ç†ã€å†³ç­–è§„åˆ’ç­‰ã€‚
- ç»“åˆæ£€ç´¢å¢å¼ºæœºåˆ¶ï¼Œæ„å»ºå¯æ‰©å±•çš„ **Latent Guidance Memory Bank**ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> PILOT æˆåŠŸåœ°å°†â€œæˆ˜ç•¥æ€§è§„åˆ’â€è¿™ä¸€é«˜çº§è®¤çŸ¥èƒ½åŠ›å°è£…è¿›ä¸€ä¸ªè½»é‡ã€éä¾µå…¥çš„ Latent Guidance æ¡†æ¶ä¸­ï¼Œåœ¨å‡ ä¹é›¶æ¨ç†ä»£ä»·ä¸‹æ˜¾è‘—æå‡äº†å°å‹ LLM åœ¨æ•°å­¦ä¸ç¼–ç¨‹ç­‰å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œä¸ºæ„å»ºé«˜æ•ˆã€ç¨³å®šçš„æ™ºèƒ½ä½“æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 14. [SpeechMapper: Speech-to-text Embedding Projector for LLMs](https://arxiv.org/abs/2601.20417)

**Authors**: Biswesh Mohapatra, Marcely Zanon Boito, Ioan Calapodescu  
**Category**: cs.CL  
**Published**: 2026-01-29  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.20417v1  

#### Abstract
Current speech LLMs bridge speech foundation models to LLMs using projection layers, training all of these components on speech instruction data. This strategy is computationally intensive and susceptible to task and prompt overfitting. We present SpeechMapper, a cost-efficient speech-to-LLM-embeddi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šSpeechMapper: Speech-to-text Embedding Projector for LLMs**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰å°† **Speech Foundation Models (SFM)** ä¸ **Large Language Models (LLMs)** ç»“åˆçš„ä¸»æµæ–¹æ³•é€šå¸¸é‡‡ç”¨**è”åˆæŒ‡ä»¤å¾®è°ƒ (joint Instruction Tuning, IT)**ï¼Œå³åŒæ—¶è®­ç»ƒ SFM ç¼–ç å™¨å’Œ LLMã€‚è¿™ç±»æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **è®¡ç®—æˆæœ¬é«˜æ˜‚**ï¼šéœ€è¦å¤§è§„æ¨¡ GPU èµ„æºå’Œé•¿æ—¶é—´è®­ç»ƒã€‚
- **ä»»åŠ¡/æç¤ºè¿‡æ‹Ÿåˆ (task/prompt overfitting)**ï¼šæ¨¡å‹åœ¨è®­ç»ƒä»»åŠ¡ä¸Šè¡¨ç°å¥½ï¼Œä½†åœ¨æœªè§ä»»åŠ¡ä¸Šæ³›åŒ–èƒ½åŠ›å·®ã€‚
- **ä¾èµ–ç¦»æ•£ token æ˜ å°„**ï¼šå¦‚ ASR çº§è”æˆ–è¯­éŸ³ token åŒ–ï¼Œä¼šä¸¢å¤±å£°å­¦ä¿¡æ¯æˆ–å¼•å…¥é‡åŒ–è¯¯å·®ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•**
ä½œè€…æå‡º **SpeechMapper**ï¼Œä¸€ç§ä¸¤é˜¶æ®µã€èµ„æºé«˜æ•ˆçš„ **speech-to-LLM embedding projector** æ–¹æ³•ï¼š
1. **Pretraining é˜¶æ®µ**ï¼š
   - ä»…ä½¿ç”¨ LLM çš„ **embedding layer**ï¼ˆå†»ç»“ LLM ä¸»å¹²ï¼‰ï¼Œé€šè¿‡ MSE æŸå¤±å°† SFM è¾“å‡ºçš„è¯­éŸ³åµŒå…¥æ˜ å°„åˆ° LLM çš„æ–‡æœ¬åµŒå…¥ç©ºé—´ã€‚
   - ä½¿ç”¨ ASR æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œæ— éœ€ LLM çš„å‰å‘ä¼ æ’­ï¼Œå¯åœ¨å»‰ä»·ç¡¬ä»¶ï¼ˆå¦‚ V100ï¼‰ä¸Šå®Œæˆã€‚
2. **Adaptation é˜¶æ®µ**ï¼š
   - å°†é¢„è®­ç»ƒå¥½çš„ SpeechMapper æ¥åˆ°å†»ç»“çš„ LLM ä¸Šï¼Œè¿›è¡ŒçŸ­æ—¶ï¼ˆ1K æ­¥ï¼‰çš„æŒ‡ä»¤å¾®è°ƒï¼ˆITï¼‰ã€‚
   - å¼•å…¥ **æ··åˆæŸå¤±å‡½æ•°**ï¼š`L_stage2 = (1-o)L_CE + o*L_MSE`ï¼Œå…¶ä¸­ `o` æ§åˆ¶å¯¹é½æŸå¤±çš„æƒé‡ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç‰¹æ€§ | SpeechMapper | ä¼ ç»Ÿ Joint IT æ–¹æ³• | Wav2Prompt / SSR |
|------|--------------|------------------|------------------|
| **è®¡ç®—æ•ˆç‡** | âœ… æé«˜ï¼ˆStage 1 ä¸ä¾èµ– LLM å‰å‘ï¼‰ | âŒ é«˜æ˜‚ | âš ï¸ ä¸­ç­‰ï¼ˆä»éœ€ LLM å‚ä¸è®­ç»ƒï¼‰ |
| **æ³›åŒ–èƒ½åŠ›** | âœ… æ”¯æŒé›¶æ ·æœ¬è¿ç§» | âŒ å®¹æ˜“è¿‡æ‹Ÿåˆ | âœ… æœ‰ä¸€å®šæ³›åŒ– |
| **è®­ç»ƒçµæ´»æ€§** | âœ… å¯å¤ç”¨é¢„è®­ç»ƒæ¨¡å—ï¼Œå¿«é€Ÿé€‚é…æ–°ä»»åŠ¡ | âŒ éœ€é‡æ–°ç«¯åˆ°ç«¯è®­ç»ƒ | âš ï¸ æœ‰é™ |
| **ç¡¬ä»¶éœ€æ±‚** | âœ… å¯åœ¨ V100 ä¸Šå®Œæˆ Stage 1 | âŒ éœ€ A100/A100 çº§åˆ« | âš ï¸ é€šå¸¸éœ€é«˜ç«¯ GPU |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
| ä»»åŠ¡ | é¢„è®­ç»ƒ/é›¶æ ·æœ¬æ•°æ® | å¾®è°ƒæ•°æ® | æµ‹è¯•æ•°æ® |
|------|------------------|----------|----------|
| **é€šç”¨è®­ç»ƒ** | LibriSpeech (960h) | â€” | â€” |
| **Speech Translation (ST)** | â€” | å­é‡‡æ · ST æ•°æ®ï¼ˆæ¥è‡ª IWSLT25 åŸºçº¿ï¼‰ | EuroParlST, CoVoST2 |
| **Spoken Question Answering (SQA)** | â€” | å­é‡‡æ · SQA æ•°æ® | SpokenSQUAD, LibriSQA |

### **å®éªŒè®¾ç½®**
- **SFM Backbone**: `seamless-m4t-v2-large`ï¼ˆç¬¬ 24 å±‚è¾“å‡ºï¼Œå¸§å¹³å‡ï¼‰
- **LLM Backbones**:
  - `Llama-3.1-8B-Instruct`
  - `EuroLLM-9B-Instruct`
- **SpeechMapper æ¶æ„**ï¼š
  - 2 ä¸ªå‹ç¼©å—ï¼ˆCNN + Transformer + FFNï¼‰ï¼Œé€æ­¥å‹ç¼©åºåˆ—é•¿åº¦å¹¶å‡ç»´è‡³ LLM åµŒå…¥ç»´åº¦ï¼ˆ4096ï¼‰
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - **Stage 1 (Pretrain)**: 2M æ­¥ï¼Œ4Ã—V100ï¼Œ4 å¤©
  - **Stage 2 (Adaptation)**: 1K æ­¥ï¼Œ1Ã—A100ï¼Œçº¦ 1.5 å°æ—¶
- **é€‚åº”ç­–ç•¥å˜ä½“**ï¼š
  - **ASR CE**: ä»…äº¤å‰ç†µæŸå¤±ï¼ˆä»»åŠ¡ç‰¹å®šï¼‰
  - **ASR CE+MSE**: æ··åˆæŸå¤±ï¼ˆä»»åŠ¡æ— å…³ï¼Œæ”¯æŒé›¶æ ·æœ¬ï¼‰
  - **ST/SQA CE**: åœ¨ç›®æ ‡ä»»åŠ¡ä¸Šå¾®è°ƒï¼ˆä»»åŠ¡ç‰¹å®šï¼‰

### **è¯„ä¼°æŒ‡æ ‡**
| ä»»åŠ¡ | ä¸»è¦æŒ‡æ ‡ | è¾…åŠ©è¯´æ˜ |
|------|--------|---------|
| **Speech Translation (ST)** | **COMET**ï¼ˆÃ—100 æå‡å¯è¯»æ€§ï¼‰ | æ›´å…³æ³¨è¯­ä¹‰è€Œéå­—é¢åŒ¹é…ï¼ˆä¼˜äº BLEUï¼‰ |
| **Spoken QA (SQA)** | **LLM-as-judge å‡†ç¡®ç‡** | ä½¿ç”¨å¤šä¸ª LLMï¼ˆEuroLLM, Gemma3, Llama3.1-70Bï¼‰ä½œä¸ºè£åˆ¤ï¼Œåˆ¤æ–­ç”Ÿæˆç­”æ¡ˆæ˜¯å¦ç­‰ä»·äºå‚è€ƒç­”æ¡ˆ |
| **ASR æ€§èƒ½** | **WER / CER** | ç”¨äºè¯„ä¼°é‡å»ºæ–‡æœ¬è´¨é‡ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Topline**: æ–‡æœ¬è½¬å½• + LLMï¼ˆç†æƒ³ä¸Šé™ï¼‰
- **Pipeline**: ASR + LLMï¼ˆçº§è”ç³»ç»Ÿï¼‰
- **Best Baseline**: `BEST-IWSLT25-IF`ï¼ˆIWSLT25 æŒ‡ä»¤è·Ÿéšèµ›é“å† å†›ï¼‰
  - åŒæ ·åŸºäº `seamless-m4t-v2-large` + `Llama-3.1-8B-Instruct`
  - ä½¿ç”¨ 2K å°æ—¶å¤šä»»åŠ¡æ•°æ®ï¼Œè®­ç»ƒ 5 å¤©ï¼ˆ2Ã—A100ï¼‰
  - åŒ…å« LoRA é€‚é…å™¨å’ŒæŠ•å½±å™¨ï¼Œé«˜åº¦ä¸“ä¸šåŒ–

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **Speech Translation (ST) â€“ COMET åˆ†æ•°**
| æ¨¡å‹ | EuroParl (en-fr) | CoVoST2 (en-zh) | å¤‡æ³¨ |
|------|------------------|----------------|------|
| **Transcripts + LLM (Topline)** | ~85.0 | ~80.0 | ç†æƒ³ä¸Šé™ |
| **BEST-IWSLT25-IF (in-domain)** | 84.0 | 80.7 | å¼ºä¸“ç”¨åŸºçº¿ |
| **SpeechMapper (Stage 2, ASR CE+MSE, zero-shot)** | **79.9** | **72.0** | **é›¶æ ·æœ¬æ¥è¿‘ä¸“ç”¨æ¨¡å‹** |
| **SpeechMapper (Stage 2, ST CE, in-domain)** | **85.4** | **79.9** | **è¶…è¶ŠåŸºçº¿ï¼Œä»… 1K æ­¥å¾®è°ƒ** |

> âœ… **é›¶æ ·æœ¬ä¸‹å·²æ¥è¿‘æœ€å¼ºä¸“ç”¨æ¨¡å‹ï¼Œå¾®è°ƒåå…¨é¢è¶…è¶Š**

#### **Spoken QA (SQA) â€“ å¹³å‡å‡†ç¡®ç‡**
| æ¨¡å‹ | SpokenSQUAD | LibriSQA Part II |
|------|-------------|----------------|
| **Transcripts + LLM** | 91.1% | 73.4% |
| **BEST-IWSLT25-IF (in-domain)** | â€” | ~62.5% |
| **SpeechMapper (Stage 2, ASR CE+MSE, zero-shot)** | **75.1%** | **64.3%** |
| **SpeechMapper (Stage 2, SQA CE, in-domain)** | **87.4%** | **68.1%** |

> âœ… **é›¶æ ·æœ¬ä¸‹å·²ä¼˜äº BEST-IWSLT25-IFï¼›å¾®è°ƒåé€¼è¿‘ Topline**

#### **æ¶ˆèå®éªŒç»“æœ**
| è®¾ç½® | å½±å“ |
|------|------|
| **Stage 1 é¢„è®­ç»ƒæœ¬èº«** | å³ä½¿ä¸æ¥ LLM å¾®è°ƒï¼Œåœ¨ ST å’Œ SQA ä¸Šå·²æœ‰æ˜¾è‘—æ€§èƒ½ï¼Œè¯æ˜å…¶å¼ºè¡¨ç¤ºèƒ½åŠ› |
| **MSE æŸå¤±æƒé‡ `o`**ï¼š
  - `o=0`ï¼ˆçº¯ CEï¼‰ï¼šæ˜“è¿‡æ‹Ÿåˆä¸º ASR è¾“å‡º
  - `oâ‰¥0.8`ï¼šèƒ½æˆåŠŸæ³›åŒ–åˆ° SQA ç­‰é ASR ä»»åŠ¡
  - æœ€ä¼˜é€‰æ‹©ï¼š`o=0.9`ï¼ˆå¹³è¡¡ ASR æ€§èƒ½ä¸æ³›åŒ–èƒ½åŠ›ï¼‰ |
| **è¯­è¨€è¯†åˆ«æµ‹è¯•**ï¼š
  - `CE only`ï¼šLlama æ¨¡å‹å¸¸è¾“å‡ºè‹±æ–‡ï¼ˆ30%+ï¼‰
  - `CE+MSE`ï¼šç›®æ ‡è¯­è¨€è¾“å‡ºæå‡è‡³ 98%+ï¼Œæ˜¾è‘—å‡å°‘è¯­è¨€æ¼‚ç§» |

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **é¢„è®­ç»ƒé˜¶æ®µæ˜¯å…³é”®**ï¼š
   - ä»…ç”¨ ASR æ•°æ®å’Œ embedding å¯¹é½æŸå¤±ï¼Œå³å¯å­¦åˆ°å¼ºå¤§çš„è¯­éŸ³åˆ°æ–‡æœ¬åµŒå…¥æ˜ å°„èƒ½åŠ›ã€‚
   - Stage 1 æ¨¡å‹æœ¬èº«å·²å…·å¤‡è·¨ä»»åŠ¡æ½œåŠ›ï¼Œæ˜¯å¯å¤ç”¨çš„â€œåŸºç¡€æ¨¡å—â€ã€‚

2. **MSE æŸå¤±æŠ‘åˆ¶è¿‡æ‹Ÿåˆ**ï¼š
   - åœ¨ IT é˜¶æ®µä¿ç•™ `L_MSE` æŸå¤±ï¼ˆ`o>0.8`ï¼‰èƒ½æœ‰æ•ˆé˜²æ­¢æ¨¡å‹é€€åŒ–ä¸ºâ€œåªä¼šåš ASRâ€çš„æ¨¡å¼ï¼Œå®ç°çœŸæ­£çš„ä»»åŠ¡æ³›åŒ–ã€‚

3. **é«˜æ•ˆä¸”å¯æ‰©å±•**ï¼š
   - æ•´ä¸ªæµç¨‹å¯åœ¨ 1.5 å°æ—¶å†…å®Œæˆé€‚é…ï¼ˆA100ï¼‰ï¼Œè¿œä½äºä¼ ç»Ÿæ–¹æ³•çš„æ•°å¤©è®­ç»ƒã€‚
   - Stage 1 ä¸ LLM å¤§å°è§£è€¦ï¼Œå¯æ‰©å±•è‡³æ›´å¤§ LLMã€‚

4. **æ€§èƒ½åª²ç¾ç”šè‡³è¶…è¶Šä¸“ç”¨æ¨¡å‹**ï¼š
   - åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹ï¼ŒSpeechMapper å·²æ¥è¿‘æˆ–è¾¾åˆ° `BEST-IWSLT25-IF` æ°´å¹³ï¼›
   - åœ¨ç›®æ ‡ä»»åŠ¡å¾®è°ƒåï¼Œå…¨é¢è¶…è¶Šè¯¥åŸºçº¿ï¼Œä¸”ä½¿ç”¨æ›´å°‘æ•°æ®å’Œç®—åŠ›ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
1. **å‘½åå®ä½“è¯†åˆ« (NER) è¡¨ç°è¾ƒå·®**ï¼š
   - ç”±äºç›´æ¥åœ¨ embedding ç©ºé—´å­¦ä¹ ï¼Œå¯¹è®­ç»ƒä¸­æœªè§çš„ named entitiesï¼ˆå¦‚äººåã€åœ°åï¼‰é‡å»ºæ•ˆæœå·®ã€‚
   - å¸¸å‡ºç°æ‹¼å†™é”™è¯¯æˆ–å®Œå…¨å¿½ç•¥ã€‚

2. **LLM ç”Ÿæˆè¡Œä¸ºä¸å¯æ§**ï¼š
   - ç‰¹åˆ«æ˜¯ EuroLLMï¼Œå®¹æ˜“äº§ç”Ÿå†—é•¿è§£é‡Šã€æ‹’ç»æ‰§è¡ŒæŒ‡ä»¤æˆ–ä¿®æ”¹ä»£è¯ï¼ˆå¦‚ â€œyouâ€ â†’ â€œIâ€ï¼‰ã€‚
   - æç¤ºå·¥ç¨‹éš¾ä»¥å®Œå…¨çº æ­£ã€‚

3. **é‡å¤ç”Ÿæˆé—®é¢˜**ï¼š
   - éƒ¨åˆ†è¾“å‡ºä¼šå‡ºç°è¯è¯­é‡å¤ï¼ˆå¦‚ â€œher sister her sisterâ€¦â€ï¼‰ï¼Œå¯èƒ½ä¸åºåˆ—å‹ç¼©æœºåˆ¶æœ‰å…³ã€‚

4. **å¯¹ LLM å™ªå£°æ•æ„Ÿåº¦å·®å¼‚å¤§**ï¼š
   - ä¸åŒ LLM å¯¹è¾“å…¥ embedding å™ªå£°å®¹å¿åº¦ä¸åŒï¼ˆEET å®éªŒæ˜¾ç¤º Llama å’Œ EuroLLM å‡å¯å®¹å¿ ~1e-3 å™ªå£°ï¼‰ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ”¹è¿› Named Entity å¤„ç†**ï¼š
   - æ¢ç´¢ç»“åˆ subword æˆ– token-level å¯¹é½æœºåˆ¶ã€‚
2. **ä¼˜åŒ–åºåˆ—å¯¹é½ç­–ç•¥**ï¼š
   - å½“å‰é€šè¿‡ padding å®ç°é•¿åº¦å¯¹é½ï¼Œæœªæ¥å¯æ¢ç´¢åŠ¨æ€å‹ç¼©æˆ–æ³¨æ„åŠ›å¼•å¯¼ã€‚
3. **æ‰©å±•è‡³æ›´å¤šæ¨¡æ€**ï¼š
   - ç±»ä¼¼æ¡†æ¶å¯ç”¨äºå›¾åƒã€éŸ³é¢‘ç­‰å…¶ä»–æ¨¡æ€åˆ° LLM çš„åµŒå…¥æŠ•å½±ã€‚
4. **é™ä½å¯¹æç¤ºå·¥ç¨‹çš„ä¾èµ–**ï¼š
   - è®¾è®¡æ›´é²æ£’çš„åµŒå…¥æ³¨å…¥æœºåˆ¶ï¼Œå‡å°‘ LLM ç”Ÿæˆåå·®ã€‚

---

> **æ€»ç»“**ï¼šSpeechMapper æå‡ºäº†ä¸€ç§**è§£è€¦ã€é«˜æ•ˆã€å¯æ³›åŒ–**çš„è¯­éŸ³åˆ° LLM é›†æˆèŒƒå¼ã€‚å®ƒé€šè¿‡ **pretrain + lightweight adaptation** çš„ä¸¤é˜¶æ®µè®¾è®¡ï¼Œåœ¨æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œå®ç°äº†ä¸æœ€å¼ºä¸“ç”¨æ¨¡å‹ç›¸å½“ç”šè‡³æ›´ä¼˜çš„æ€§èƒ½ï¼Œä¸ºæ„å»ºé€šç”¨è¯­éŸ³å¤§æ¨¡å‹æä¾›äº†å®ç”¨è·¯å¾„ã€‚

</details>

---

### 15. [Window-Diffusion: Accelerating Diffusion Language Model Inference with Windowed Token Pruning and Caching](https://arxiv.org/abs/2601.20332)

**Authors**: Fengrui Zuo, Zhiwei Ke, Yiming Liu, Wenqi Lou, Chao Wang, Xvehai Zhou  
**Category**: cs.LG  
**Published**: 2026-01-29  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.20332v1  

#### Abstract
Diffusion language models (DLMs) generate text through iterative denoising, but inference requires full-sequence attention at every iteration, resulting in substantial redundant computation on masked tokens. Block-wise diffusion can reduce this cost, yet it typically relies on retraining and constra...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šWindow-Diffusion: Accelerating Diffusion Language Model Inference with Windowed Token Pruning and Caching**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
æ‰©æ•£è¯­è¨€æ¨¡å‹ï¼ˆ**Diffusion Language Models, DLMs**ï¼‰è™½ç„¶åœ¨ç”Ÿæˆè´¨é‡ã€å¹¶è¡Œè§£ç å’Œå…¨å±€å»ºæ¨¡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶æ¨ç†è¿‡ç¨‹å­˜åœ¨æ˜¾è‘—æ•ˆç‡ç“¶é¢ˆã€‚ä¸»è¦é—®é¢˜åœ¨äºï¼š
- æ¯ä¸ª **diffusion step** éƒ½éœ€å¯¹æ•´ä¸ªåºåˆ—è¿›è¡Œå…¨é‡æ³¨æ„åŠ›è®¡ç®—ï¼ˆfull-sequence attentionï¼‰ï¼Œå³ä½¿å¤§å¤šæ•° **mask tokens** å¹¶æœªè¢«æ›´æ–°ã€‚
- å¤§é‡è®¡ç®—èµ„æºæµªè´¹åœ¨å†—ä½™çš„ mask token ä¸Šï¼Œå¯¼è‡´æ¨ç†å»¶è¿Ÿé«˜ã€ååä½ã€‚

ç°æœ‰æ–¹æ³•å¦‚ **block diffusion** æˆ– **KV caching** è¦ä¹ˆéœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œè¦ä¹ˆæ— æ³•æ ¹æœ¬å‡å°‘ mask token çš„å‚ä¸ï¼Œé™åˆ¶äº†å…¶åœ¨é¢„è®­ç»ƒ DLM ä¸Šçš„ç›´æ¥åº”ç”¨ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**
ä½œè€…æå‡ºäº† **Window-Diffusion**ï¼Œä¸€ç§æ— éœ€é‡æ–°è®­ç»ƒã€é€‚ç”¨äºæ ‡å‡† DLM çš„é«˜æ•ˆæ¨ç†æ¡†æ¶ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯åŸºäº token çº§åˆ«çš„å±€éƒ¨æ€§è§„å¾‹è¿›è¡Œé€‰æ‹©æ€§è®¡ç®—ä¸çŠ¶æ€å¤ç”¨ã€‚

#### **ä¸»è¦åˆ›æ–°ç‚¹ï¼š**
1. **åŒçª—å£æœºåˆ¶ï¼ˆDual-Window Mechanismï¼‰**
   - **å¤–éƒ¨çª—å£ï¼ˆExternal Windowï¼‰**ï¼šä»…ä¿ç•™æœªè§£ç åŒºåŸŸå‰ç¼€ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œå…¶ä½™è¿œåœº token è¢«å‰ªæï¼ˆprunedï¼‰ï¼Œé¿å…å‚ä¸è®¡ç®—ã€‚
   - **å†…éƒ¨çª—å£ï¼ˆInternal Windowï¼‰**ï¼šä»å¤–éƒ¨çª—å£ä¸­è¿›ä¸€æ­¥é€‰å–æœ€å¯èƒ½è¢«è§£ç çš„â€œæ´»è·ƒ tokenâ€ï¼ˆactive tokensï¼‰ï¼Œä»…å¯¹è¿™äº› token è¿›è¡Œ logits é¢„æµ‹ã€‚
   - å…¶ä»–æœªæ¿€æ´»çš„æœªè§£ç  token ä½œä¸ºâ€œç¼“å†² tokenâ€ï¼ˆbuffer tokensï¼‰ï¼Œå…¶ KV çŠ¶æ€å¯ç¼“å­˜å¤ç”¨ã€‚

2. **é˜¶æ®µçº§ KV ç¼“å­˜ä¸å‘¨æœŸåˆ·æ–°ï¼ˆPhase-Level KV Caching with Periodic Refreshï¼‰**
   - åœ¨æ¯ä¸ªæ¨ç†é˜¶æ®µå¼€å§‹æ—¶æ‰§è¡Œä¸€æ¬¡å®Œæ•´å‰å‘ä¼ æ’­ä»¥åˆå§‹åŒ– KV ç¼“å­˜ã€‚
   - åç»­æ­¥éª¤ä¸­å¤ç”¨ç¨³å®š token çš„ KV çŠ¶æ€ï¼Œä»…æ›´æ–°æ´»è·ƒ token å’Œè¿‘æœŸè§£ç  token çš„è¡¨ç¤ºã€‚
   - æ¯éš”å›ºå®šæ­¥æ•°åˆ·æ–°ç¼“å­˜ï¼Œæ§åˆ¶è¿‘ä¼¼è¯¯å·®ç´¯ç§¯ã€‚

3. **è‡ªé€‚åº”ç»ˆæ­¢ï¼ˆAdaptive Terminationï¼‰**
   - å½“ç”Ÿæˆ `<eos>` åè‡ªåŠ¨åœæ­¢è§£ç ï¼Œé¿å…é•¿åºåˆ—ä¸­çš„å†—ä½™æ­¥éª¤ï¼Œå®ç°åŠ¨æ€é•¿åº¦æ¨ç†ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | æ˜¯å¦éœ€é‡è®­ | æ˜¯å¦æ”¯æŒçµæ´»æ›´æ–°é¡ºåº | æ˜¯å¦ç¼©çŸ­ mask åºåˆ— | æ˜¯å¦æ”¯æŒ KV å¤ç”¨ |
|------|------------|------------------------|--------------------|------------------|
| åŸå§‹ DLM | âŒ | âœ… | âŒ | âŒ |
| Block Diffusion | âœ… | âŒï¼ˆå—é™äºå—é¡ºåºï¼‰ | âœ… | âœ…ï¼ˆå—å†…ï¼‰ |
| DKV-Cache | âŒ | âœ… | âŒ | âœ…ï¼ˆä»…å·²è§£ç  tokenï¼‰ |
| **Window-Diffusion** | âŒ | âœ… | âœ…ï¼ˆé€šè¿‡çª—å£å‰ªæï¼‰ | âœ…ï¼ˆbuffer + decoded tokensï¼‰ |

> âœ… è¡¨ç¤ºå…·å¤‡è¯¥ç‰¹æ€§ï¼›âŒ è¡¨ç¤ºä¸å…·å¤‡æˆ–å—é™

**ä¼˜åŠ¿æ€»ç»“ï¼š**
- **æ— éœ€å¾®è°ƒæˆ–é‡è®­**ï¼Œå¯ç›´æ¥éƒ¨ç½²äºé¢„è®­ç»ƒ DLMã€‚
- **ä¿æŒæ‰©æ•£æ¨¡å‹åŸæœ‰çš„çµæ´»æ›´æ–°é¡ºåº**ï¼Œä¸ç‰ºç‰²å¹¶è¡Œæ€§ã€‚
- **åŒæ—¶å®ç° token pruning ä¸ KV caching**ï¼ŒåŒé‡é™ä½è®¡ç®—å¼€é”€ã€‚
- **æ­£äº¤äºå…¶ä»–åŠ é€ŸæŠ€æœ¯**ï¼ˆå¦‚é‡åŒ–ã€è’¸é¦ï¼‰ï¼Œæ˜“äºé›†æˆã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›†**
- **æ¨¡å‹**ï¼š
  - `LLaDA`ï¼ˆLarge Language Diffusion Modelï¼‰
  - `Dream`ï¼ˆ7B è§„æ¨¡çš„ diffusion LLMï¼‰
- **æ•°æ®é›†**ï¼š
  - **GSM8K-CoT**ï¼šæ•°å­¦æ¨ç†ä»»åŠ¡
  - **MATH**ï¼šå¤æ‚æ•°å­¦é—®é¢˜æ±‚è§£
  - **HumanEval**ï¼šä»£ç ç”Ÿæˆèƒ½åŠ›æµ‹è¯•
  - **MBPP**ï¼šPython å‡½æ•°ç”ŸæˆåŸºå‡†

æ‰€æœ‰å®éªŒåœ¨ **NVIDIA A6000 GPU** ä¸Šä»¥ **FP32 ç²¾åº¦**è¿è¡Œï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°æŒ‡æ ‡**
- **Accuracy / Pass@1**ï¼šç”Ÿæˆç»“æœçš„æ­£ç¡®ç‡
- **Throughput (tokens/sec)**ï¼šæ¯ç§’å¤„ç†çš„ token æ•°é‡
- **Speedup**ï¼šç›¸å¯¹äºåŸå§‹æ¨¡å‹çš„ç›¸å¯¹åŠ é€Ÿæ¯”
- **Latency (seconds)**ï¼šç«¯åˆ°ç«¯æ¨ç†æ—¶é—´

#### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| **Dream (Baseline)** | åŸå§‹ DLM | æ— ä»»ä½•ä¼˜åŒ– |
| **Block Diffusion** | ç»“æ„åŒ–ç”Ÿæˆ | åˆ†å—è‡ªå›å½’ + å—å†…æ‰©æ•£ï¼Œéœ€é‡è®­ |
| **DKV-Cache** | KV ç¼“å­˜ | ç¼“å­˜å·²è§£ç  token çš„ KV çŠ¶æ€ |
| **Fast-dLLM (Prefix/Dual-Cache)** | ç»¼åˆä¼˜åŒ– | æ”¯æŒ KV ç¼“å­˜ä¸å¹¶è¡Œè§£ç ï¼Œéƒ¨åˆ†éœ€é…ç½®è°ƒæ•´ |

#### **Window-Diffusion è¶…å‚æ•°**
- å¤–éƒ¨çª—å£é•¿åº¦ï¼š128ï¼ˆDreamï¼‰ï¼Œ64ï¼ˆLLaDAï¼‰
- å†…éƒ¨çª—å£é•¿åº¦ï¼š16
- ç¼“å­˜åˆ·æ–°å‘¨æœŸï¼š32 æ­¥
- æ—©æœŸåœæ­¢ï¼ˆearly stoppingï¼‰ï¼šé»˜è®¤å…³é—­ï¼ˆæ¶ˆèå®éªŒä¸­å¯ç”¨ï¼‰

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2 & Table 6ï¼‰**

#### **åœ¨ Dream æ¨¡å‹ä¸Šçš„ç»¼åˆè¡¨ç°ï¼ˆTable 2ï¼‰**
| æ–¹æ³• | å¹³å‡ Accuracy | å¹³å‡ Throughput | å¹³å‡ Speedup |
|------|---------------|------------------|--------------|
| Dream (Baseline) | ~61.7 | ~9.0 tokens/s | 1.0Ã— |
| DKV-Cache | ~60.8 | ~13.5 | ~2.4Ã— |
| Fast-dLLM (Prefix-Cache) | ~60.3 | ~19.0 | ~3.8Ã— |
| Fast-dLLM (Dual-Cache) | ~59.9 | ~25.5 | ~5.0Ã— |
| **Window-Diffusion** | **~60.5** | **~31.1** | **~6.6Ã—** |

> ğŸ’¡ åœ¨å‡ ä¹ä¸æŸå¤±å‡†ç¡®æ€§çš„å‰æä¸‹ï¼Œè¾¾åˆ°æœ€é«˜ **6.6Ã— æ¨ç†åŠ é€Ÿ**

#### **åœ¨ LLaDA æ¨¡å‹ä¸Šçš„è¡¨ç°ï¼ˆTable 6ï¼‰**
| æ–¹æ³• | å¹³å‡ Accuracy | å¹³å‡ Throughput | å¹³å‡ Speedup |
|------|---------------|------------------|--------------|
| LLaDA (Baseline) | ~47.7 | ~4.8 | 1.0Ã— |
| DKV-Cache | ~45.8 | ~7.4 | ~1.6Ã— |
| Fast-dLLM (Dual-Cache) | ~44.7 | ~15.3 | ~3.7Ã— |
| **Window-Diffusion** | **~45.3** | **~25.9** | **~5.6Ã—** |

> ğŸš€ è¾¾åˆ° **5.6Ã— åŠ é€Ÿ**ï¼Œä¸”æ€§èƒ½ä¸‹é™æœ€å°

---

### **ä¸ Block Diffusion çš„å¯¹æ¯”ï¼ˆTable 1ï¼‰**
- åœ¨ç›¸åŒçª—å£/å—å¤§å°ï¼ˆL=16ï¼‰ä¸‹ï¼š
  - Block Diffusion åœ¨ Instruct ç‰ˆæœ¬ä¸Šæ€§èƒ½ä¸¥é‡ä¸‹é™ï¼ˆå¦‚ MBPP ä» 58.8 â†’ 32.2ï¼‰
  - **Window-Diffusion** æ€§èƒ½æ›´ç¨³å®šï¼Œä»…è½»å¾®ä¸‹é™
- è¡¨æ˜ï¼š**window-based pruning æ¯” block-wise æ›´é€‚åˆä¿ç•™æ‰©æ•£æ¨¡å‹è¯­ä¹‰å®Œæ•´æ€§**

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **(1) å¤–éƒ¨çª—å£é•¿åº¦çš„å½±å“ï¼ˆFigure 6aï¼‰**
- çª—å£é•¿åº¦ â‰¥ 128 åï¼Œaccuracy åŸºæœ¬é¥±å’Œ
- æ›´å¤§çª—å£å¸¦æ¥è½»å¾® throughput ä¸‹é™ï¼Œä½†æ”¶ç›Šé€’å‡
- **æœ€ç»ˆé€‰æ‹© 128 ä¸ºå¹³è¡¡ç‚¹**

#### **(2) ç¼“å­˜åˆ·æ–°å‘¨æœŸçš„å½±å“ï¼ˆFigure 6bï¼‰**
- åˆ·æ–°å‘¨æœŸè¿‡çŸ­ â†’ ç¼“å­˜ä¸ç¨³å®šï¼Œaccuracy ä¸‹é™
- åˆ·æ–°å‘¨æœŸè¿‡é•¿ â†’ æ–°è§£ç  token ç§¯å‹éœ€å…¨é‡è®¡ç®—ï¼Œthroughput å¢ç›Šè¶‹ç¼“
- **æœ€ä¼˜åˆ·æ–°å‘¨æœŸä¸º 32**

#### **(3) ç”Ÿæˆé•¿åº¦å¯¹æ¨ç†æ—¶é—´çš„å½±å“ï¼ˆFigure 6cï¼‰**
- éšç€ç”Ÿæˆé•¿åº¦å¢åŠ ï¼Œä¼ ç»Ÿæ–¹æ³•å›  O(SÂ²) å¤æ‚åº¦è¿…é€Ÿå˜æ…¢
- **Window-Diffusion ä¿æŒç¨³å®šçš„é«˜é€Ÿæ¯”**ï¼Œå°¤å…¶åœ¨é•¿æ–‡æœ¬ç”Ÿæˆä¸­ä¼˜åŠ¿æ˜æ˜¾

#### **(4) è‡ªé€‚åº”é•¿åº¦æ¨ç†ï¼ˆTable 3ï¼‰**
| æ–¹æ³• | ä»»åŠ¡ | Latency (s) | Speedup |
|------|------|-------------|---------|
| Dream | MBPP (1024) | 217.8 | 1.0Ã— |
| WD-Static | MBPP | 32.9 | 6.6Ã— |
| **WD-Adaptive** | MBPP | **2.2** | **99.0Ã—** |

> âœ… **ç»“åˆè‡ªé€‚åº”ç»ˆæ­¢åï¼Œæœ€é«˜å¯è¾¾ 99Ã— ç«¯åˆ°ç«¯åŠ é€Ÿï¼**

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **DLM æ¨ç†å…·æœ‰å¼ºç»“æ„æ€§å±€éƒ¨æ€§ï¼ˆStructural Localityï¼‰**ï¼š
   - æ´»è·ƒ token é«˜åº¦é›†ä¸­åœ¨æœªè§£ç åŒºåŸŸçš„å‰ç¼€ï¼ˆprefix localityï¼‰
   - å¯¹è¿œè·ç¦»æœªè§£ç  token çš„ä¾èµ–å¿«é€Ÿè¡°å‡
   - å·²è§£ç  token çš„è¡¨ç¤ºå…·æœ‰é˜¶æ®µæ€§ç¨³å®šæ€§ï¼ˆtemporal stabilityï¼‰ï¼Œé€‚åˆç¼“å­˜

2. **å…¨åºåˆ—é‡å¤è®¡ç®—æ˜¯éå¿…è¦çš„**ï¼š
   - å¯é€šè¿‡å±€éƒ¨çª—å£ + ç¼“å­˜æœºåˆ¶å¤§å¹…å‰Šå‡å†—ä½™è®¡ç®—

3. **Window-Diffusion å®ç°é«˜æ•ˆä¸é«˜è´¨é‡çš„å¹³è¡¡**ï¼š
   - åœ¨å¤šä¸ªä»»åŠ¡å’Œæ¨¡å‹ä¸Šå‡å®ç° **5â€“6.6Ã— æ¨ç†åŠ é€Ÿ**
   - å‡†ç¡®ç‡æŸå¤±æå°ï¼ˆé€šå¸¸ < 2%ï¼‰
   - ç»“åˆè‡ªé€‚åº”é•¿åº¦å¯è¿›ä¸€æ­¥æå‡è‡³ **99Ã— ç«¯åˆ°ç«¯åŠ é€Ÿ**

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **çª—å£å¤§å°éœ€æ‰‹åŠ¨è®¾å®š**ï¼šä¸åŒä»»åŠ¡å¯èƒ½éœ€è¦ä¸åŒçš„æœ€ä¼˜çª—å£é•¿åº¦
- **æç«¯çŸ­æ–‡æœ¬æˆ–é«˜åº¦éšæœºç”Ÿæˆåœºæ™¯ä¸‹å¢ç›Šæœ‰é™**
- **ç›®å‰æœªæ¢ç´¢ä¸å…¶ä»–å‹ç¼©æŠ€æœ¯ï¼ˆå¦‚é‡åŒ–ï¼‰çš„è”åˆä¼˜åŒ–æ½œåŠ›**

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **åŠ¨æ€çª—å£æœºåˆ¶**ï¼šæ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´çª—å£èŒƒå›´
2. **ä¸è®­ç»ƒè¿‡ç¨‹ç»“åˆ**ï¼šè®¾è®¡æ”¯æŒçª—å£æ¨ç†çš„é¢„è®­ç»ƒç›®æ ‡
3. **å¤šæ¨¡æ€æ‰©å±•**ï¼šå°† windowed pruning åº”ç”¨äºå›¾åƒ/éŸ³é¢‘ diffusion æ¨¡å‹
4. **ç¡¬ä»¶é€‚é…ä¼˜åŒ–**ï¼šé’ˆå¯¹ TPU/GPU å†…å­˜è®¿é—®æ¨¡å¼ä¼˜åŒ–ç¼“å­˜ç­–ç•¥

---

## **æ€»ç»“**
> ğŸ” **Window-Diffusion æ˜¯é¦–ä¸ªç³»ç»Ÿæ­ç¤º DLM æ¨ç†ä¸­ token çº§å±€éƒ¨æ€§è§„å¾‹ï¼Œå¹¶æ®æ­¤è®¾è®¡é«˜æ•ˆæ¨ç†æ¡†æ¶çš„å·¥ä½œã€‚**
>
> å®ƒé€šè¿‡ **åŒçª—å£ç»„ç»‡ + é˜¶æ®µçº§ KV ç¼“å­˜ + è‡ªé€‚åº”ç»ˆæ­¢**ï¼Œå®ç°äº†é«˜è¾¾ **99Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿ**ï¼ŒåŒæ—¶å‡ ä¹ä¸æŸå®³ç”Ÿæˆè´¨é‡ã€‚è¯¥æ–¹æ³•æ— éœ€é‡è®­ã€å…¼å®¹æ€§å¼ºï¼Œä¸ºå¤§è§„æ¨¡ diffusion language models çš„å®é™…éƒ¨ç½²æä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 16. [MemCtrl: Using MLLMs as Active Memory Controllers on Embodied Agents](https://arxiv.org/abs/2601.20831)

**Authors**: Vishnu Sashank Dorbala, Dinesh Manocha  
**Category**: cs.AI  
**Published**: 2026-01-29  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.20831v1  

#### Abstract
Foundation models rely on in-context learning for personalized decision making. The limited size of this context window necessitates memory compression and retrieval systems like RAG. These systems however often treat memory as large offline storage spaces, which is unfavorable for embodied agents t...

---

### 17. [ShieldedCode: Learning Robust Representations for Virtual Machine Protected Code](https://arxiv.org/abs/2601.20679)

**Authors**: Mingqiao Mo, Yunlong Tan, Hao Zhang, Heng Zhang, Yangfan He  
**Category**: cs.CL  
**Published**: 2026-01-29  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.20679v1  

#### Abstract
Large language models (LLMs) have achieved remarkable progress in code generation, yet their potential for software protection remains largely untapped. Reverse engineering continues to threaten software security, while traditional virtual machine protection (VMP) relies on rigid, rule-based transfo...

---

### 18. [AutoOverlap: Enabling Fine-Grained Overlap of Computation and Communication with Chunk-Based Scheduling](https://arxiv.org/abs/2601.20595)

**Authors**: Xinwei Qiang, Yue Guan, Zhengding Hu, Yufei Ding, Adnan Aziz  
**Category**: cs.DC  
**Published**: 2026-01-29  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.20595v1  

#### Abstract
Communication has become a first-order bottleneck in large-cale GPU workloads, and existing distributed compilers address it mainly by overlapping whole compute and communication kernels at the stream level. This coarse granularity incurs extra kernel launches, forces device-wide synchronizations at...

---

### 19. [Distributional value gradients for stochastic environments](https://arxiv.org/abs/2601.20071)

**Authors**: Baptiste Debes, Tinne Tuytelaars  
**Category**: cs.LG  
**Published**: 2026-01-29  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.20071v1  

#### Abstract
Gradient-regularized value learning methods improve sample efficiency by leveraging learned models of transition dynamics and rewards to estimate return gradients. However, existing approaches, such as MAGE, struggle in stochastic or noisy environments, limiting their applicability. In this work, we...

---

### 20. [Investigating the Development of Task-Oriented Communication in Vision-Language Models](https://arxiv.org/abs/2601.20641)

**Authors**: Boaz Carmeli, Orr Paradise, Shafi Goldwasser, Yonatan Belinkov, Ron Meir  
**Category**: cs.AI  
**Published**: 2026-01-29  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.20641v1  

#### Abstract
We investigate whether \emph{LLM-based agents} can develop task-oriented communication protocols that differ from standard natural language in collaborative reasoning tasks. Our focus is on two core properties such task-oriented protocols may exhibit: Efficiency -- conveying task-relevant informatio...

---

### 21. [Trajectory2Task: Training Robust Tool-Calling Agents with Synthesized Yet Verifiable Data for Complex User Intents](https://arxiv.org/abs/2601.20144)

**Authors**: Ziyi Wang, Yuxuan Lu, Yimeng Zhang, Jing Huang, Jiri Gesi, Xianfeng Tang, Chen Luo, Yisi Sang, Hanqing Lu, Manling Li, Dakuo Wang  
**Category**: cs.CL  
**Published**: 2026-01-29  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.20144v1  

#### Abstract
Tool-calling agents are increasingly deployed in real-world customer-facing workflows. Yet most studies on tool-calling agents focus on idealized settings with general, fixed, and well-specified tasks. In real-world applications, user requests are often (1) ambiguous, (2) changing over time, or (3) ...

---

### 22. [SAPO: Self-Adaptive Process Optimization Makes Small Reasoners Stronger](https://arxiv.org/abs/2601.20312)

**Authors**: Kaiyuan Chen, Guangmin Zheng, Jin Wang, Xiaobing Zhou, Xuejie Zhang  
**Category**: cs.CL  
**Published**: 2026-01-29  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.20312v1  

#### Abstract
Existing self-evolution methods overlook the influence of fine-grained reasoning steps, which leads to the reasoner-verifier gap. The computational inefficiency of Monte Carlo (MC) process supervision further exacerbates the difficulty in mitigating the gap. Motivated by the Error-Related Negativity...

---

### 23. [Beyond Accuracy: A Cognitive Load Framework for Mapping the Capability Boundaries of Tool-use Agents](https://arxiv.org/abs/2601.20412)

**Authors**: Qihao Wang, Yue Hu, Mingzhe Lu, Jiayue Wu, Yanbing Liu, Yuanmin Tang  
**Category**: cs.CL  
**Published**: 2026-01-29  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.20412v1  

#### Abstract
The ability of Large Language Models (LLMs) to use external tools unlocks powerful real-world interactions, making rigorous evaluation essential. However, current benchmarks primarily report final accuracy, revealing what models can do but obscuring the cognitive bottlenecks that define their true c...

---

### 24. [PEARL: Plan Exploration and Adaptive Reinforcement Learning for Multihop Tool Use](https://arxiv.org/abs/2601.20439)

**Authors**: Qihao Wang, Mingzhe Lu, Jiayue Wu, Yue Hu, Yanbing Liu  
**Category**: cs.CL  
**Published**: 2026-01-29  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.20439v1  

#### Abstract
Large Language Models show great potential with external tools, but face significant challenges in complex, multi-turn tool invocation. They often exhibit weak planning, tool hallucination, erroneous parameter generation, and struggle with robust interaction. To tackle these issues, we present PEARL...

---

### 25. [MuVaC: AVariational Causal Framework for Multimodal Sarcasm Understanding in Dialogues](https://arxiv.org/abs/2601.20451)

**Authors**: Diandian Guo, Fangfang Yuan, Cong Cao, Xixun Lin, Chuan Zhou, Hao Peng, Yanan Cao, Yanbing Liu  
**Category**: cs.CL  
**Published**: 2026-01-29  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.20451v1  

#### Abstract
The prevalence of sarcasm in multimodal dialogues on the social platforms presents a crucial yet challenging task for understanding the true intent behind online content. Comprehensive sarcasm analysis requires two key aspects: Multimodal Sarcasm Detection (MSD) and Multimodal Sarcasm Explanation (M...

---

### 26. [Efficient Multimodal Planning Agent for Visual Question-Answering](https://arxiv.org/abs/2601.20676)

**Authors**: Zhuo Chen, Xinyu Geng, Xinyu Wang, Yong Jiang, Zhen Zhang, Pengjun Xie, Kewei Tu  
**Category**: cs.CL  
**Published**: 2026-01-29  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.20676v1  

#### Abstract
Visual Question-Answering (VQA) is a challenging multimodal task that requires integrating visual and textual information to generate accurate responses. While multimodal Retrieval-Augmented Generation (mRAG) has shown promise in enhancing VQA systems by providing more evidence on both image and tex...

---

### 27. [Regime-Adaptive Bayesian Optimization via Dirichlet Process Mixtures of Gaussian Processes](https://arxiv.org/abs/2601.20043)

**Authors**: Yan Zhang, Xuefeng Liu, Sipeng Chen, Sascha Ranftl, Chong Liu, Shibo Li  
**Category**: cs.LG  
**Published**: 2026-01-29  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.20043v1  

#### Abstract
Standard Bayesian Optimization (BO) assumes uniform smoothness across the search space an assumption violated in multi-regime problems such as molecular conformation search through distinct energy basins or drug discovery across heterogeneous molecular scaffolds. A single GP either oversmooths sharp...

---

### 28. [Going NUTS with ADVI: Exploring various Bayesian Inference techniques with Facebook Prophet](https://arxiv.org/abs/2601.20120)

**Authors**: Jovan Krajevski, Biljana Tojtovska Ribarski  
**Category**: cs.LG  
**Published**: 2026-01-29  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.20120v1  

#### Abstract
Since its introduction, Facebook Prophet has attracted positive attention from both classical statisticians and the Bayesian statistics community. The model provides two built-in inference methods: maximum a posteriori estimation using the L-BFGS-B algorithm, and Markov Chain Monte Carlo (MCMC) samp...

---

### 29. [Parametric and Generative Forecasts of Day-Ahead Market Curves for Storage Optimization](https://arxiv.org/abs/2601.20226)

**Authors**: Julian Gutierrez, Redouane Silvente  
**Category**: cs.LG  
**Published**: 2026-01-29  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.20226v1  

#### Abstract
We present two machine learning frameworks for forecasting aggregated curves and optimizing storage in the EPEX SPOT day-ahead market. First, a fast parametric model forecasts hourly demand and supply curves in a low-dimensional and grid-robust representation, with minimum and maximum volumes combin...

---

### 30. [TINNs: Time-Induced Neural Networks for Solving Time-Dependent PDEs](https://arxiv.org/abs/2601.20361)

**Authors**: Chen-Yang Dai, Che-Chia Chang, Te-Sheng Lin, Ming-Chih Lai, Chieh-Hsin Lai  
**Category**: cs.LG  
**Published**: 2026-01-29  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.20361v1  

#### Abstract
Physics-informed neural networks (PINNs) solve time-dependent partial differential equations (PDEs) by learning a mesh-free, differentiable solution that can be evaluated anywhere in space and time. However, standard space--time PINNs take time as an input but reuse a single network with shared weig...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
