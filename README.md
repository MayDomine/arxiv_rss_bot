# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-07 05:58:05 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Lil: Less is Less When Applying Post-Training Sparse-Attention Algorithms in Long-Decode Stage](https://arxiv.org/abs/2601.03043)

**Authors**: Junhao Hu, Fangze Li, Mingtao Xu, Feifan Meng, Shiju Zhao, Tiancheng Hu, Ting Peng, Anmin Liu, Wenrui Huang, Chenxu Liu, Ziyue Hua, Tao Xie  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2601.03043v1  

#### Abstract
Large language models (LLMs) demonstrate strong capabilities across a wide range of complex tasks and are increasingly deployed at scale, placing significant demands on inference efficiency. Prior work typically decomposes inference into prefill and decode stages, with the decode stage dominating to...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLil: Less is Less When Applying Post-Training Sparse-Attention Algorithms in Long-Decode Stage

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡æ­ç¤ºäº†ä¸€ä¸ªåœ¨**Post-Training Sparse-Attention (PTSD)** ç®—æ³•ä¸­è¢«å¿½è§†çš„å…³é”®é—®é¢˜ï¼Œç§°ä¸º **â€œLilâ€ (Less is Less)**ã€‚å°½ç®¡ç¨€ç–æ³¨æ„åŠ›ï¼ˆsparse attentionï¼‰èƒ½åŠ é€Ÿå•æ­¥è§£ç ï¼ˆdecodeï¼‰ï¼Œä½†ç”±äºå…¶åœ¨é•¿åºåˆ—ç”Ÿæˆè¿‡ç¨‹ä¸­ä¸¢å¤±ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯¼è‡´æ¨¡å‹éœ€è¦ç”Ÿæˆæ›´é•¿çš„è¾“å‡ºåºåˆ—æ¥è¡¥å¿ï¼Œåè€Œå¢åŠ äº†ç«¯åˆ°ç«¯çš„æ¨ç†å»¶è¿Ÿå’Œå†…å­˜å ç”¨ã€‚

è¿™ä¸€ç°è±¡æŒ‘æˆ˜äº†ç¨€ç–æ³¨æ„åŠ›â€œæå‡æ•ˆç‡â€çš„ç›´è§‚å‡è®¾ï¼Œå°¤å…¶æ˜¯åœ¨**reasoning-intensive tasks**ï¼ˆå¦‚æ•°å­¦æ¨ç†ã€é“¾å¼æ€ç»´ CoTï¼‰ä¸­å°¤ä¸ºä¸¥é‡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•å’Œæ–°æ€è·¯
ä¸ºè§£å†³ Lil é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Guardian** çš„**æ—©æœŸåœæ­¢ç®—æ³•**ï¼ˆearly-stopping algorithmï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åˆ©ç”¨ **LZ77 å‹ç¼©ç®—æ³•**åŠ¨æ€ç›‘æµ‹ç”Ÿæˆåºåˆ—çš„ä¿¡æ¯å¢ç›Šã€‚
- å½“å‹ç¼©åçš„å­—èŠ‚æ•°å¢é•¿åœæ»ï¼ˆå³æ–°å¢ token å¸¦æ¥çš„ä¿¡æ¯å¢ç›Šä½äºè®¾å®šé˜ˆå€¼ï¼‰æ—¶ï¼Œåˆ¤å®šæ¨¡å‹å·²è¿›å…¥å†—ä½™ç”Ÿæˆé˜¶æ®µï¼Œä¸»åŠ¨ç»ˆæ­¢è§£ç ã€‚

è¯¥æ–¹æ³•åŸºäºä¿¡æ¯è®ºï¼š**ä½å‹ç¼©ç‡æ„å‘³ç€é«˜å†—ä½™ï¼Œä¿¡æ¯ç†µè¶‹äºé¥±å’Œæ—¶åº”åœæ­¢ç”Ÿæˆ**ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ— éœ€é‡æ–°è®­ç»ƒ**ï¼šGuardian æ˜¯ä¸€ä¸ªæ’ä»¶å¼ï¼ˆplug-and-playï¼‰æ¨¡å—ï¼Œé€‚ç”¨äºä»»ä½•é¢„è®­ç»ƒ LLMã€‚
- **é«˜æ•ˆè½»é‡**ï¼šLZ77 å‹ç¼©æˆæœ¬æä½ï¼ˆçº¦ 34ms å¤„ç† 128k tokensï¼‰ï¼Œæ¯ 250 æ­¥æ£€æŸ¥ä¸€æ¬¡ï¼Œå¼€é”€å¯å¿½ç•¥ã€‚
- **é€šç”¨æ€§å¼º**ï¼šä¸ä»…é€‚ç”¨äºç¨€ç–æ³¨æ„åŠ›åœºæ™¯ï¼Œä¹Ÿé€‚ç”¨äºæ™®é€š full attention ä¸‹çš„å†—ä½™ CoT ç”Ÿæˆã€‚
- **æ˜¾è‘—èŠ‚çœ token æ¶ˆè€—**ï¼šæœ€å¤šå‡å°‘ 90% çš„ token ç”Ÿæˆï¼ŒåŒæ—¶ä¿æŒ <2% çš„å‡†ç¡®ç‡ä¸‹é™ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ä¸‰ä¸ªé¢å‘å¤æ‚æ¨ç†çš„ benchmark ä¸Šè¿›è¡Œè¯„ä¼°ï¼š
- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼Œéœ€å¤šæ­¥ç®—æœ¯æ¨ç†ã€‚
- **MATH-500**ï¼šé«˜ä¸­æ•°å­¦ç«èµ›é¢˜ï¼Œæ¶µç›–ä»£æ•°ã€å‡ ä½•ç­‰äº”çº§éš¾åº¦ã€‚
- **AIME**ï¼šç¾å›½æ•°å­¦é‚€è¯·èµ›é¢˜ç›®ï¼ŒæŒ‘æˆ˜é¡¶å°–é«˜ä¸­ç”Ÿã€‚

æ¯ä¸ªæ•°æ®é›†å–å‰ 200 ä¸ªæµ‹è¯•æ ·ä¾‹ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼š
  - **DSR**ï¼šDeepScaleR-1.5B-Preview
  - **DSL**ï¼šDeepSeek-R1-Distill-Llama-8B
  - **Qwe**ï¼šQwen1.5-MoE-A2.7B-Chat
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šå•å¼  NVIDIA A100-80GB GPUï¼ŒUbuntu 20.04ï¼ŒCUDA 12.6ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Token savings**ï¼šåº”ç”¨ Guardian åç›¸æ¯”åŸå§‹ç”Ÿæˆçš„ token èŠ‚çœæ¯”ä¾‹ã€‚
  - **Accuracy**ï¼šè¾“å‡ºä¸æ ‡å‡†ç­”æ¡ˆçš„æ•°å­¦ç­‰ä»·æ€§åˆ¤æ–­ï¼ŒæŠ¥å‘Šæ­£ç¡®ç‡åŠå˜åŒ–ï¼ˆÎ”Accuracyï¼‰ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¯”è¾ƒäº†äº”ç§ä¸»æµ PTSD ç®—æ³•ï¼š
- **H2O**ã€**Sink**ï¼šé€šè¿‡ä¿ç•™â€œé‡å‡»è€…â€ï¼ˆheavy hittersï¼‰å¹¶ä¸¢å¼ƒ KV ç¼“å­˜æ¥å®ç°ç¨€ç–ã€‚
- **infLLM**ã€**Quest**ï¼šä¸ä¸¢å¼ƒ KVï¼Œä½†é™åˆ¶ attention èŒƒå›´ã€‚
- **Full attention**ï¼šå®Œæ•´æ³¨æ„åŠ›ä½œä¸ºåŸºå‡†ã€‚

æ‰€æœ‰æ–¹æ³•å‡åœ¨ä¸åŒ **cache budget**ï¼ˆ128â€“1024ï¼‰ä¸‹æµ‹è¯•ï¼Œå¹¶é›†æˆ Guardian è¿›è¡Œå¯¹æ¯”ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
æ ¹æ® **Table 1** å’Œ **Figure 1**ï¼Œæ ¸å¿ƒç»“æœå¦‚ä¸‹ï¼š

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **æœ€å¤§ token èŠ‚çœ** | é«˜è¾¾ **90%** |
| **å‡†ç¡®ç‡æŸå¤±** | å°äº **2%**ï¼ˆç»å¯¹å€¼ï¼‰ |
| **éƒ¨åˆ†æƒ…å†µä¸‹å‡†ç¡®ç‡æå‡** | æœ€å¤š +1.5%ï¼Œå› é¿å…äº†è¿‡åº¦éªŒè¯å¯¼è‡´é—å¿˜æ­£ç¡®ç­”æ¡ˆ |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **Without Guardian**ï¼š
  - æ‰€æœ‰ç¨€ç–æ³¨æ„åŠ›ç®—æ³•å‡å¯¼è‡´è¾“å‡ºé•¿åº¦å¢åŠ ï¼ˆæœ€é«˜è¾¾ 90%ï¼‰ï¼Œå°¤å…¶åœ¨å° cache budget ä¸‹æ›´æ˜æ˜¾ã€‚
  - H2O/Sink å› ä¸¢å¼ƒ KV å¯¼è‡´ä¿¡æ¯ä¸¢å¤±ä¸¥é‡ï¼Œå‡†ç¡®ç‡è¾ƒä½ï¼›Quest/infLLM è¡¨ç°æ›´å¥½ä½†ä»å­˜åœ¨å†—ä½™ã€‚
- **With Guardian**ï¼š
  - åœ¨æ‰€æœ‰ PTSD ç®—æ³•ä¸Šå‡æ˜¾è‘—é™ä½ token æ¶ˆè€—ã€‚
  - å¯¹ä¿å®ˆé…ç½®ï¼ˆå¦‚ cache=1024ï¼‰ä»æœ‰æ•ˆï¼Œè¯´æ˜å³ä½¿æ¥è¿‘ full attention ä¹Ÿå­˜åœ¨å¯å‹ç¼©å†—ä½™ã€‚
  - åœ¨ DSR + Quest + AIME åœºæ™¯ä¸‹å®ç° 90% token èŠ‚çœï¼Œä»…é™ 0.5% å‡†ç¡®ç‡ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **æŒ‰ä»»åŠ¡ç»“æœåˆ†ç±»ç»Ÿè®¡ï¼ˆTable 3ï¼‰**ï¼š
  - **é”™è¯¯æ¡ˆä¾‹**ï¼šGuardian ä¸»è¦é€šè¿‡æå‰ç»ˆæ­¢æ— é™å¾ªç¯ç”Ÿæˆæ¥èŠ‚çœ tokenã€‚
  - **æ­£ç¡®æ¡ˆä¾‹**ï¼šé˜²æ­¢æ¨¡å‹åœ¨å¾—å‡ºç­”æ¡ˆåç»§ç»­â€œåå¤éªŒè¯â€ï¼Œä»è€Œå¿˜è®°ç­”æ¡ˆã€‚
- **åœ¨ Full Attention ä¸Šçš„åº”ç”¨ï¼ˆTable 2ï¼‰**ï¼š
  - å³ä½¿æ²¡æœ‰ä½¿ç”¨ç¨€ç–æ³¨æ„åŠ›ï¼ŒGuardian ä¹Ÿèƒ½èŠ‚çœ 9â€“18% çš„ tokenï¼Œè¡¨æ˜ CoT å†—ä½™æ™®éå­˜åœ¨ã€‚
  - è¯´æ˜ Guardian å¯æ³›åŒ–è‡³éç¨€ç–åœºæ™¯ï¼Œç”¨äºå‹ç¼©ä½æ•ˆæ¨ç†è·¯å¾„ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Lil é—®é¢˜æ˜¯ PTSD çš„â€œæˆ¿é—´é‡Œçš„å¤§è±¡â€**ï¼š
   - ç¨€ç–æ³¨æ„åŠ›è™½åŠ å¿«å•æ­¥è§£ç ï¼Œä½†å› ä¿¡æ¯ä¸¢å¤±å¼•å‘é‡å¤é‡å»ºè¡Œä¸ºï¼Œæœ€ç»ˆå»¶é•¿æ€»ç”Ÿæˆé•¿åº¦ï¼ŒæŠµæ¶ˆç”šè‡³é€†è½¬æ•ˆç‡ä¼˜åŠ¿ã€‚
2. **ä¿¡æ¯ç†µå¯ç”¨äºæ£€æµ‹å†—ä½™ç”Ÿæˆ**ï¼š
   - ä½¿ç”¨ LZ77 å‹ç¼©æ¯”ä½œä¸ºä¿¡æ¯å¯†åº¦ä»£ç†ï¼Œå‘ç°ç”Ÿæˆè¿‡ç¨‹å¸¸ç»å†â€œå¿«é€Ÿå¢é•¿ â†’ å¹³å°æœŸâ€é˜¶æ®µï¼Œå¹³å°æœŸå³ä¸ºå†—ä½™åŒºã€‚
3. **Guardian æ˜¾è‘—ç¼“è§£ Lil é—®é¢˜**ï¼š
   - åœ¨ reasoning-intensive ä»»åŠ¡ä¸­ï¼Œå¹³å‡èŠ‚çœ 50â€“90% tokenï¼Œå‡†ç¡®ç‡æŸå¤± <2%ã€‚
   - åœ¨æŸäº›æƒ…å†µè¿˜èƒ½æå‡å‡†ç¡®ç‡ï¼Œé¿å…â€œç”»è›‡æ·»è¶³â€ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–æ¨¡å‹èƒ½åŠ›**ï¼šå¯¹å¼±æ¨¡å‹ï¼ˆå¦‚ Qwen MoEï¼‰æ•ˆæœæœ‰é™ï¼Œå› å…¶æœ¬èº«ç”ŸæˆçŸ­ä¸”é”™è¯¯ç‡é«˜ï¼Œç¼ºä¹è¶³å¤Ÿå†—ä½™ä¾›å‹ç¼©ã€‚
- **è¯„ä¼°èŒƒå›´æœ‰é™**ï¼š
  - ä»…æµ‹è¯•ä¸‰ç§æ¨¡å‹å’Œä¸‰ä¸ªæ•°æ®é›†ï¼Œå¯èƒ½å½±å“æ³›åŒ–æ€§ã€‚
  - æœªè¦†ç›–æ‰€æœ‰ç¨€ç–ç®—æ³•ï¼ˆå¦‚ ClusterKVã€PQ-Cacheï¼‰ï¼Œä½†ä½œè€…è®¤ä¸º Lil æœ¬è´¨æºäºç¨€ç–æ€§å‡è®¾ï¼Œå…·æœ‰æ™®é€‚æ€§ã€‚
- **å‹ç¼©é¢‘ç‡å‚æ•°éœ€è°ƒä¼˜**ï¼š`f=250` å’Œ `t=20` åœ¨å®éªŒä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ä¸åŒæ¶æ„æˆ–åºåˆ—é•¿åº¦ä¸‹å¯èƒ½éœ€è°ƒæ•´ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ Guardian åœ¨ **general prolonged CoT generation** ä¸­çš„åº”ç”¨ï¼Œå°¤å…¶æ˜¯ç”±è®­ç»ƒåå·®ã€å¥–åŠ±é»‘å®¢ç­‰å¼•èµ·çš„å†—ä½™ã€‚
- ç ”ç©¶å¦‚ä½•å°† Guardian ä¸ç°æœ‰çš„ CoT å‹ç¼©æ–¹æ³•ï¼ˆå¦‚ ThinkPruneã€HALT-COTï¼‰ç»“åˆã€‚
- æ‰©å±•è‡³æ›´å¤šæ¨¡å‹å’Œæ›´å¤æ‚ä»»åŠ¡ï¼ˆå¦‚ä»£ç ç”Ÿæˆã€é•¿æ–‡æœ¬å†™ä½œï¼‰ä»¥éªŒè¯é€šç”¨æ€§ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æŒ‡å‡ºç¨€ç–æ³¨æ„åŠ›å¯èƒ½å¯¼è‡´â€œè¶Šç¨€è¶Šæ…¢â€çš„ **Lil é™·é˜±**ï¼Œå¹¶æå‡ºåŸºäºä¿¡æ¯å‹ç¼©çš„ **Guardian æ—©åœæœºåˆ¶**ï¼Œåœ¨å‡ ä¹ä¸å½±å“å‡†ç¡®ç‡çš„å‰æä¸‹ï¼Œå°† token æ¶ˆè€—é™ä½é«˜è¾¾ 90%ï¼Œä¸ºé«˜æ•ˆé•¿åºåˆ—æ¨ç†æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 2. [LoRA-Drop: Temporal LoRA Decoding for Efficient LLM Inference](https://arxiv.org/abs/2601.02569)

**Authors**: Hossein Rajabzadeh, Maryam Dialameh, Chul B. Park, Il-Min Kim, Hyock Ju Kwon  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.02569v1  

#### Abstract
Autoregressive large language models (LLMs) are bottlenecked by sequential decoding, where each new token typically requires executing all transformer layers. Existing dynamic-depth and layer-skipping methods reduce this cost, but often rely on auxiliary routing mechanisms or incur accuracy degradat...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*LoRA-Drop: Temporal LoRA Decoding for Efficient LLM Inference*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªå›å½’æ¨ç†è¿‡ç¨‹ä¸­é¢ä¸´ä¸¥é‡çš„**è®¡ç®—ç“¶é¢ˆ**ï¼Œå³æ¯ä¸ªæ–° token éƒ½éœ€è¦é€šè¿‡æ‰€æœ‰ transformer å±‚è¿›è¡Œå®Œæ•´å‰å‘ä¼ æ’­ï¼Œå¯¼è‡´é«˜å»¶è¿Ÿå’Œé«˜å†…å­˜å¼€é”€ã€‚å°½ç®¡å·²æœ‰åŠ¨æ€æ·±åº¦æˆ–å±‚è·³è¿‡æ–¹æ³•å°è¯•ç¼“è§£è¯¥é—®é¢˜ï¼Œä½†å®ƒä»¬é€šå¸¸ä¾èµ–é¢å¤–çš„è·¯ç”±æœºåˆ¶ï¼Œæˆ–åœ¨è·³è¿‡å±‚æœªè¡¥å¿çš„æƒ…å†µä¸‹é€ æˆç²¾åº¦ä¸‹é™ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šLoRA-Drop
æœ¬æ–‡æå‡º **LoRA-Drop**ï¼Œä¸€ç§è½»é‡çº§ã€å³æ’å³ç”¨çš„é«˜æ•ˆæ¨ç†æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ LLM ä¸­éšè—çŠ¶æ€çš„**æ—¶é—´å†—ä½™æ€§**ï¼ˆtemporal redundancyï¼‰ï¼Œåœ¨å¤§å¤šæ•°è§£ç æ­¥éª¤ä¸­å¤ç”¨å‰ä¸€ä¸ª token çš„ä¸­é—´å±‚è¡¨ç¤ºï¼Œå¹¶é€šè¿‡ä½ç§©é€‚é…ï¼ˆLoRAï¼‰è¿›è¡Œå¾®è°ƒæ›´æ–°ã€‚

#### æ ¸å¿ƒæœºåˆ¶ï¼š
- **å›ºå®šå­é›†çš„å¯è·³è¿‡å±‚ï¼ˆdroppable layersï¼‰**ï¼šé€‰æ‹©éƒ¨åˆ†ä¸­é—´ transformer å±‚æ³¨å…¥ LoRA æ¨¡å—ã€‚
- **å‘¨æœŸæ€§è°ƒåº¦ç­–ç•¥ï¼ˆperiodic scheduleï¼‰**ï¼š
  - **LoRA æ¨¡å¼ï¼ˆè½»é‡æ­¥ï¼‰**ï¼šåœ¨è¿ç»­ `k` æ­¥ä¸­ï¼Œè¿™äº›å±‚è·³è¿‡å®Œæ•´è®¡ç®—ï¼Œä»…åº”ç”¨ LoRA å¯¹å‰ä¸€æ­¥éšè—çŠ¶æ€è¿›è¡Œä¿®æ­£ã€‚
  - **Full æ¨¡å¼ï¼ˆåˆ·æ–°æ­¥ï¼‰**ï¼šæ¯ `k+1` æ­¥æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æ¨¡å‹å‰å‘ä¼ æ’­ï¼Œé˜²æ­¢è¯¯å·®ç´¯ç§¯ã€‚
- **æ— éœ€è·¯ç”±ç½‘ç»œ**ï¼šé¿å…å¼•å…¥é¢å¤–å‚æ•°æˆ–å¤æ‚æ§åˆ¶é€»è¾‘ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | LoRA-Drop | Unified Layer Skipping / FlexiDepth | Speculative Decoding |
|------|-----------|-------------------------------------|------------------------|
| æ˜¯å¦éœ€è¾…åŠ©æ¨¡å— | âŒï¼ˆæ— è·¯ç”±ï¼‰ | âš ï¸ï¼ˆéƒ¨åˆ†éœ€ï¼‰ | âœ…ï¼ˆéœ€ draft modelï¼‰ |
| æ˜¯å¦ä¿ç•™ä¸Šä¸‹æ–‡è¿è´¯æ€§ | âœ…ï¼ˆé‡ç”¨+LoRAæ ¡æ­£ï¼‰ | âŒï¼ˆç›´æ¥è·³è¿‡ï¼‰ | âœ…ï¼ˆä½†æœ‰æ¥å—ç‡é—®é¢˜ï¼‰ |
| å…¼å®¹ KV Cache | âœ… | âœ… | âœ… |
| å¯é™ä½ KV Cache å¤§å° | âœ…ï¼ˆè·³è¿‡å±‚ä¸é¢‘ç¹æ›´æ–° KVï¼‰ | âš ï¸æœ‰é™ | âŒ |
| æ’ä»¶å¼éƒ¨ç½² | âœ…ï¼ˆä»…éœ€å°‘é‡ fine-tuningï¼‰ | âœ… | âŒï¼ˆæ¶æ„æ”¹åŠ¨å¤§ï¼‰ |

> âœ… LoRA-Drop åœ¨ä¿æŒç²¾åº¦çš„åŒæ—¶æ˜¾è‘—æå‡æ¨ç†é€Ÿåº¦å’Œå†…å­˜æ•ˆç‡ï¼Œä¸”å®Œå…¨å…¼å®¹æ ‡å‡†è®­ç»ƒä¸æ¨ç†æµç¨‹ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å¤šä¸ªä»»åŠ¡ç±»åˆ«ï¼Œè¯„ä¼°æ³›åŒ–èƒ½åŠ›ï¼š

| ç±»åˆ« | æ•°æ®é›† |
|------|-------|
| **é€šç”¨ç†è§£ä¸çŸ¥è¯†** | MMLU, HellaSwag (HS), WinoGrande, ARC-e/c, OpenBookQA, PIQA, RACE |
| **æ•°å­¦ä¸æ¨ç†** | GSM8K, MATH, Big-Bench Hard (BBH) |
| **ä»£ç ç”Ÿæˆ** | HumanEval, MBPP |
| **é•¿æ–‡æœ¬ä¸å¤šè¯­è¨€** | LongBench, Needle-in-a-Haystack, XNLI, XCOPA |

### å®éªŒè®¾ç½®
- **æ¨¡å‹å®¶æ—**ï¼š
  - LLaMA2-7B, LLaMA3-8B
  - Qwen2.5-7B, Qwen2.5-14B
- **LoRA å‚æ•°**ï¼š
  - Rank `r = 16`, Scaling `Î± = 16`
  - ä»…æ›´æ–° LoRA å‚æ•°ï¼Œå†»ç»“åŸå§‹æƒé‡
- **Fine-tuning**ï¼š
  - åœ¨ RefinedWeb ä¸Šè¿›è¡Œçº¦ 15B token çš„æŒç»­é¢„è®­ç»ƒï¼ˆcontinual pretrainingï¼‰
- **è°ƒåº¦å‚æ•°**ï¼š
  - Drop ratio `p âˆˆ {0.25, 0.5, 0.75}`ï¼ˆå¯è·³è¿‡å±‚æ¯”ä¾‹ï¼‰
  - Temporal window `k âˆˆ {1,2,3,5}`ï¼ˆæ¯éš” `k+1` æ­¥åˆ·æ–°ä¸€æ¬¡ï¼‰
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š
  - NVIDIA A100/V100 GPUï¼Œä½¿ç”¨ BF16 æ··åˆç²¾åº¦å’Œ SDPA

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ç±»å‹ | å…·ä½“æŒ‡æ ‡ |
|--------|---------|
| **å‡†ç¡®æ€§** | Zero-shot Accuracy, Pass@1 (HumanEval/MBPP), F1/EM (LongBench) |
| **æ•ˆç‡** | Tokens/sec, Speedup (Ã—), Relative FLOPs |
| **å†…å­˜** | KV Cache å†…å­˜å ç”¨ï¼ˆMBï¼‰ï¼ŒèŠ‚çœç™¾åˆ†æ¯” |
| **å»¶è¿Ÿ** | Per-token latency (p50, p95) |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Full Model**ï¼šåŸå§‹å®Œæ•´æ¨¡å‹ï¼ˆæ— è·³è¿‡ï¼‰
- **Unified Layer Skipping** [18]
- **FlexiDepth** [19]

> æ³¨ï¼šä½œè€…å¼ºè°ƒå…¶ä»–åŠ é€ŸæŠ€æœ¯ï¼ˆå¦‚é‡åŒ–ã€æ¨æµ‹è§£ç ï¼‰ä¸æœ¬æ–¹æ³•æ­£äº¤ï¼Œæ•…æœªçº³å…¥ä¸»æ¯”è¾ƒï¼Œç•™å¾…æœªæ¥ç»„åˆç ”ç©¶ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆæ¥è‡ª Table I å’Œ Vï¼‰

| æ¨¡å‹ | Drop Ratio `p` | Window `k` | å¹³å‡å‡†ç¡®åº¦å˜åŒ– Î”Acc | æ¨ç†é€Ÿåº¦æå‡ | KV Cache èŠ‚çœ |
|------|---------------|------------|--------------------|--------------|----------------|
| LLaMA2-7B | 0.5 | 3 | -0.1 pp | **1.68Ã—** | ~40% |
| Qwen2.5-7B | 0.5 | 3 | -0.1 pp | **1.73Ã—** | ~45% |
| LLaMA3-8B | 0.5 | 3 | -0.3 pp | **1.70Ã—** | ~42% |
| Qwen2.5-14B | 0.5 | 3 | -0.2 pp | **1.68Ã—** | ~48% |
| æ‰€æœ‰æ¨¡å‹ï¼ˆæ¿€è¿›é…ç½®ï¼‰ | 0.75 | 3â€“5 | â‰¤ -2.5 pp | **æœ€é«˜è¾¾ 2.6Ã—** | **45â€“55%** |

> ğŸ”¹ åœ¨ `p=0.5, k=3` é…ç½®ä¸‹ï¼Œå¹³å‡æ€§èƒ½æŸå¤± < **0.5 pp**ï¼Œå±äºâ€œå®‰å…¨åŒºâ€ï¼ˆsafe zoneï¼‰

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆTable Iï¼‰
- LoRA-Drop åœ¨ç›¸åŒé€Ÿåº¦å¢ç›Šä¸‹ï¼Œ**å‡†ç¡®ç‡ä¼˜äº Unified Layer Skipping å’Œ FlexiDepth**
- ä¾‹å¦‚ï¼Œåœ¨ LLaMA2-7B ä¸Šï¼š
  - Unified Layer Skippingï¼š1.42Ã— speedup, avg acc â†“0.8 pp
  - LoRA-Drop (`p=0.5`)ï¼š**1.68Ã— speedup**, avg acc â†“0.1 pp â†’ æ›´ä¼˜çš„ Pareto å‰æ²¿

### æ¶ˆèå®éªŒç»“æœï¼ˆTable III & IVï¼‰

#### ä¸åŒ `p` å’Œ `k` çš„æƒè¡¡åˆ†æ
| é…ç½® | å‡†ç¡®æ€§å½±å“ | ååæå‡ | KV ç¼“å­˜å‡å°‘ |
|------|----------|---------|-------------|
| `p=0.25, k=3` | +0.2 pp | ~1.27Ã— | ~17% |
| `p=0.50, k=3` | -0.1~0.3 pp | **1.68â€“1.73Ã—** | **~40â€“45%** |
| `p=0.75, k=3` | â†“1.8â€“2.4 pp | **2.35â€“2.42Ã—** | **~50â€“55%** |

> ğŸ”¹ å‘ç°â€œå®‰å…¨åŒºâ€ï¼š`p â‰¤ 0.5` ä¸” `k â‰¤ 3` æ—¶ï¼Œç²¾åº¦æŸå¤±æå°ï¼ˆâ‰¤0.5 ppï¼‰ï¼Œé€Ÿåº¦æå‡æ˜æ˜¾ï¼ˆ1.6â€“1.8Ã—ï¼‰

#### å»¶è¿Ÿåˆ†å¸ƒï¼ˆTail Latencyï¼‰
- ç”±äºå‘¨æœŸæ€§åˆ·æ–°æœºåˆ¶ï¼Œtoken å»¶è¿Ÿå‘ˆåŒå³°åˆ†å¸ƒï¼š
  - LoRA æ­¥éª¤ï¼šä½å»¶è¿Ÿ
  - Refresh æ­¥éª¤ï¼šè¾ƒé«˜å»¶è¿Ÿ
- p95 å»¶è¿Ÿç”±åˆ·æ–°é¢‘ç‡å†³å®šï¼šå½“ `k > 19` æ—¶ï¼Œp95 è¿›å…¥ LoRA æ¨¡å¼ï¼Œå°¾éƒ¨å»¶è¿Ÿå¤§å¹…ä¸‹é™

### LoRA æ³¨å…¥ä½ç½®æ¶ˆèï¼ˆTable Vï¼‰
| æ³¨å…¥æ–¹å¼ | å‡†ç¡®æ€§ | é€Ÿåº¦å¢ç›Š |
|--------|--------|---------|
| Attention+MLP LoRA | â‰ˆ Baseline | ~1.37â€“1.39Ã— |
| **Block-level LoRAï¼ˆé»˜è®¤ï¼‰** | â‰ˆ Baseline | **~1.55â€“1.58Ã—** |

> ğŸ”¹ **Block-level æ³¨å…¥**åœ¨ç²¾åº¦ä¸å˜å‰æä¸‹è·å¾—æ›´é«˜ååï¼Œä¸ºæ¨èé»˜è®¤é…ç½®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **LLM éšè—çŠ¶æ€å­˜åœ¨æ˜¾è‘—æ—¶é—´å†—ä½™**ï¼š
   - ç›¸é‚» token çš„éšè—çŠ¶æ€ç›¸ä¼¼åº¦é«˜è¾¾ 0.6â€“0.85ï¼ˆå›¾1ï¼‰
   - å•ä¸€çŠ¶æ€å¯é¢„æµ‹æœªæ¥ 3â€“6 ä¸ª tokenï¼ˆFuture Lens ç°è±¡æ”¯æŒï¼‰

2. âœ… **LoRA-Drop å¯æœ‰æ•ˆåˆ©ç”¨å†—ä½™å®ç°é«˜æ•ˆæ¨ç†**ï¼š
   - é€šè¿‡å‘¨æœŸæ€§ LoRA æ›´æ–°æ›¿ä»£å®Œæ•´å±‚è®¡ç®—ï¼Œæ˜¾è‘—é™ä½è®¡ç®—è´Ÿæ‹…
   - å¼•å…¥å®šæœŸ full refresh æŠ‘åˆ¶è¯¯å·®æ¼‚ç§»ï¼Œä¿éšœé•¿æœŸä¸€è‡´æ€§

3. âœ… **åœ¨å¤šç§æ¨¡å‹å’Œä»»åŠ¡ä¸Šè¡¨ç°ç¨³å¥**ï¼š
   - è¦†ç›– 7Bâ€“14B è§„æ¨¡ã€ä¸åŒæ¶æ„ï¼ˆLLaMA/Qwenï¼‰
   - åœ¨æ¨ç†ã€ç¼–ç ã€é•¿æ–‡æœ¬ã€å¤šè¯­è¨€ä»»åŠ¡ä¸­å‡ä¿æŒé«˜è´¨é‡è¾“å‡º

4. âœ… **KV Cache æ˜¾è‘—å‹ç¼©**ï¼š
   - å¯è·³è¿‡å±‚åœ¨ LoRA æ¨¡å¼ä¸‹æ— éœ€æ›´æ–° KVï¼ŒèŠ‚çœ 45â€“55%
   - å°¤å…¶é€‚åˆé•¿åºåˆ—åœºæ™¯ï¼ˆlong-contextï¼‰

5. âœ… å­˜åœ¨ä¸€ä¸ªæ¸…æ™°çš„â€œ**æ•ˆç‡-è´¨é‡å¸•ç´¯æ‰˜å‰æ²¿**â€ï¼š
   - `p=0.5, k=3` æ˜¯æ¨èé»˜è®¤é…ç½®ï¼Œå¹³è¡¡é€Ÿåº¦ä¸ç²¾åº¦
   - `p=0.75` é€‚ç”¨äºå¯¹å»¶è¿Ÿæ•æ„Ÿçš„åº”ç”¨

### æ–¹æ³•çš„å±€é™æ€§
- â— å½“å‰é‡‡ç”¨**å›ºå®šå‘¨æœŸè°ƒåº¦**ï¼Œå°šæœªå¼•å…¥åŸºäº token å¤æ‚åº¦çš„è‡ªé€‚åº”æœºåˆ¶ï¼ˆå¦‚ç†µå€¼ã€logit marginï¼‰
- â— æç«¯è®¾ç½®ï¼ˆ`p=0.75, kâ‰¥5`ï¼‰å¯èƒ½å¯¼è‡´ç²¾åº¦æ˜æ˜¾ä¸‹é™ï¼ˆ>2 ppï¼‰
- â— ä»…éªŒè¯äº†æ–‡æœ¬æ¨¡æ€ï¼Œæœªæ‰©å±•è‡³å¤šæ¨¡æ€æˆ–æ£€ç´¢å¢å¼ºåœºæ™¯

### æœªæ¥å·¥ä½œæ–¹å‘
- ğŸ”„ æ¢ç´¢**è‡ªé€‚åº”è°ƒåº¦ç­–ç•¥**ï¼šæ ¹æ® token ä¸ç¡®å®šæ€§åŠ¨æ€è°ƒæ•´æ˜¯å¦åˆ·æ–°
- ğŸŒ æ‰©å±•è‡³**å¤šæ¨¡æ€ä¸ RAG æ¨¡å‹**ï¼šåº”ç”¨äºè§†è§‰-è¯­è¨€ã€éŸ³é¢‘-æ–‡æœ¬ç­‰è·¨æ¨¡æ€æ¨ç†
- ğŸ”— ç»“åˆå…¶ä»–ä¼˜åŒ–æŠ€æœ¯ï¼šä¸é‡åŒ–ï¼ˆQuantizationï¼‰ã€KV å‹ç¼©ã€æ¨æµ‹è§£ç ï¼ˆSpeculative Decodingï¼‰è”åˆä½¿ç”¨
- ğŸ§  æ·±å…¥åˆ†æå±‚é—´å†—ä½™æ¨¡å¼ï¼šæ„å»ºæ›´ç²¾ç»†çš„ drop-layer selection ç­–ç•¥

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> LoRA-Drop æå‡ºäº†ä¸€ç§ç®€å•è€Œå¼ºå¤§çš„â€œ**å‘¨æœŸæ€§è½»é‡æ›´æ–° + å®šæœŸå…¨é‡åˆ·æ–°**â€èŒƒå¼ï¼Œé¦–æ¬¡å°† LoRA ç”¨äºæ¨ç†é˜¶æ®µçš„æ—¶é—´ç»´åº¦ä¼˜åŒ–ï¼Œåœ¨å‡ ä¹ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹å®ç°äº†é«˜è¾¾ **2.6Ã— çš„æ¨ç†åŠ é€Ÿ** å’Œ **è¶… 50% çš„ KV Cache èŠ‚çœ**ï¼Œä¸ºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆéƒ¨ç½²æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 3. [MiMo-V2-Flash Technical Report](https://arxiv.org/abs/2601.02780)

**Authors**: Bangjun Xiao, Bingquan Xia, Bo Yang, Bofei Gao, Bowen Shen, Chen Zhang, Chenhong He, Chiheng Lou, Fuli Luo, Gang Wang, Gang Xie, Hailin Zhang, Hanglong Lv, Hanyu Li, Heyu Chen, Hongshen Xu, Houbin Zhang, Huaqiu Liu, Jiangshan Duo, Jianyu Wei, Jiebao Xiao, Jinhao Dong, Jun Shi, Junhao Hu, Kainan Bao, Kang Zhou, Lei Li, Liang Zhao, Linghao Zhang, Peidian Li, Qianli Chen, Shaohui Liu, Shihua Yu, Shijie Cao, Shimao Chen, Shouqiu Yu, Shuo Liu, Tianling Zhou, Weijiang Su, Weikun Wang, Wenhan Ma, Xiangwei Deng, Bohan Mao, Bowen Ye, Can Cai, Chenghua Wang, Chengxuan Zhu, Chong Ma, Chun Chen, Chunan Li, Dawei Zhu, Deshan Xiao, Dong Zhang, Duo Zhang, Fangyue Liu, Feiyu Yang, Fengyuan Shi, Guoan Wang, Hao Tian, Hao Wu, Heng Qu, Hongfei Yi, Hongxu An, Hongyi Guan, Xing Zhang, Yifan Song, Yihan Yan, Yihao Zhao, Yingchun Lai, Yizhao Gao, Yu Cheng, Yuanyuan Tian, Yudong Wang, Zhen Tang, Zhengju Tang, Zhengtao Wen, Zhichao Song, Zhixian Zheng, Zihan Jiang, Jian Wen, Jiarui Sun, Jiawei Li, Jinlong Xue, Jun Xia, Kai Fang, Menghang Zhu, Nuo Chen, Qian Tu, Qihao Zhang, Qiying Wang, Rang Li, Rui Ma, Shaolei Zhang, Shengfan Wang, Shicheng Li, Shuhao Gu, Shuhuai Ren, Sirui Deng, Tao Guo, Tianyang Lu, Weiji Zhuang, Weikang Zhang, Weimin Xiong, Wenshan Huang, Wenyu Yang, Xin Zhang, Xing Yong, Xu Wang, Xueyang Xie, Yilin Jiang, Yixin Yang, Yongzhe He, Yu Tu, Yuanliang Dong, Yuchen Liu, Yue Ma, Yue Yu, Yuxing Xiang, Zhaojun Huang, Zhenru Lin, Zhipeng Xu, Zhiyang Chen, Zhonghua Deng, Zihan Zhang, Zihao Yue  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.02780v1  

#### Abstract
We present MiMo-V2-Flash, a Mixture-of-Experts (MoE) model with 309B total parameters and 15B active parameters, designed for fast, strong reasoning and agentic capabilities. MiMo-V2-Flash adopts a hybrid attention architecture that interleaves Sliding Window Attention (SWA) with global attention, w...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MiMo-V2-Flash Technical Report æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§æ¨¡å‹åœ¨å®ç°**å¼ºæ¨ç†èƒ½åŠ›**å’Œ**æ™ºèƒ½ä½“ï¼ˆagenticï¼‰è¡Œä¸º**æ—¶é¢ä¸´ä¸¤å¤§ç“¶é¢ˆï¼š
- **é•¿ä¸Šä¸‹æ–‡å»ºæ¨¡æ•ˆç‡ä½**ï¼šå…¨æ³¨æ„åŠ›æœºåˆ¶ï¼ˆFull Attentionï¼‰è®¡ç®—å¤æ‚åº¦ä¸º $O(n^2)$ï¼Œå¯¼è‡´é•¿åºåˆ—æ¨ç†é€Ÿåº¦æ…¢ã€æ˜¾å­˜å ç”¨é«˜ã€‚
- **åè®­ç»ƒï¼ˆpost-trainingï¼‰æ‰©å±•æˆæœ¬é«˜ä¸”ä¸å‡è¡¡**ï¼šä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒå­˜åœ¨â€œè··è··æ¿æ•ˆåº”â€ï¼ˆcapability imbalanceï¼‰ï¼Œå³æå‡æŸä¸€é¢†åŸŸèƒ½åŠ›å¸¸å¯¼è‡´å…¶ä»–é¢†åŸŸé€€åŒ–ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

#### ï¼ˆ1ï¼‰**æ··åˆæ»‘åŠ¨çª—å£æ³¨æ„åŠ›æ¶æ„ï¼ˆHybrid Sliding Window Attention, SWAï¼‰**
- é‡‡ç”¨ **5:1 çš„å±€éƒ¨-å…¨å±€æ³¨æ„åŠ›æ¯”ä¾‹**ï¼Œæ¯ 5 å±‚ SWA åæ¥ 1 å±‚ Global Attentionã€‚
- æ»‘åŠ¨çª—å£å¤§å°è®¾ä¸º **128 tokens**ï¼Œæ˜¾è‘—é™ä½ KV Cache å­˜å‚¨å’Œæ³¨æ„åŠ›è®¡ç®—å¼€é”€ã€‚
- å¼•å…¥ **learnable attention sink bias** æŠ€æœ¯ï¼Œç¼“è§£å°çª—å£å¸¦æ¥çš„é•¿æœŸä¾èµ–ä¸¢å¤±é—®é¢˜ã€‚

#### ï¼ˆ2ï¼‰**è½»é‡çº§å¤šä»¤ç‰Œé¢„æµ‹æ¨¡å—ï¼ˆLightweight Multi-Token Prediction, MTPï¼‰**
- åœ¨é¢„è®­ç»ƒé˜¶æ®µå¼•å…¥ MTP ä½œä¸ºè¾…åŠ©ç›®æ ‡ï¼Œæå‡è®­ç»ƒæ•ˆç‡ã€‚
- æ¨ç†é˜¶æ®µå°† MTP æ¨¡å—ç”¨ä½œ **speculative decoding çš„è‰ç¨¿æ¨¡å‹ï¼ˆdraft modelï¼‰**ï¼Œå®ç°é«˜è¾¾ **3.6 çš„å¹³å‡æ¥å—é•¿åº¦** å’Œ **2.6x çš„è§£ç åŠ é€Ÿ**ã€‚
- MTP æ¨¡å—ä»…å« **0.33B å‚æ•°**ï¼Œä½¿ç”¨ Dense FFN + SWA ç»“æ„ï¼Œé¿å…æˆä¸ºæ¨ç†ç“¶é¢ˆã€‚

#### ï¼ˆ3ï¼‰**å¤šæ•™å¸ˆåœ¨çº¿ç­–ç•¥è’¸é¦èŒƒå¼ï¼ˆMulti-Teacher On-Policy Distillation, MOPDï¼‰**
- ä¸€ç§å…¨æ–°çš„åè®­ç»ƒæ¡†æ¶ï¼Œåˆ†ä¸‰é˜¶æ®µï¼š
  1. **é€šç”¨ SFT**ï¼šå»ºç«‹åŸºç¡€æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼›
  2. **é¢†åŸŸä¸“ç”¨ RL/SFT**ï¼šè®­ç»ƒå¤šä¸ªä¸“å®¶æ•™å¸ˆæ¨¡å‹ï¼ˆå¦‚æ•°å­¦ã€ç¼–ç ã€å·¥å…·è°ƒç”¨ç­‰ï¼‰ï¼›
  3. **MOPD è’¸é¦**ï¼šå­¦ç”Ÿæ¨¡å‹ä»å¤šä¸ªæ•™å¸ˆå¤„è·å– token-level çš„ KL divergence å¥–åŠ±ä¿¡å·ï¼Œå¹¶ç»“åˆ outcome reward è¿›è¡Œè”åˆä¼˜åŒ–ã€‚
- å®ç°äº†**èƒ½åŠ›èåˆè€Œéæƒè¡¡å–èˆ**ï¼Œè§£å†³äº†â€œè§æ­¤å¤±å½¼â€çš„èƒ½åŠ›ä¸å¹³è¡¡é—®é¢˜ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | MiMo-V2-Flash | å¯¹æ¯”ä¼˜åŠ¿ |
|------|----------------|----------|
| **å‚æ•°æ•ˆç‡** | æ€»å‚ 309Bï¼Œæ¿€æ´» 15B | æ€§èƒ½åª²ç¾ DeepSeek-V3.2ï¼ˆ671Bï¼‰ã€Kimi-K2ï¼ˆ1043Bï¼‰ |
| **é•¿ä¸Šä¸‹æ–‡æ€§èƒ½** | æ”¯æŒåŸç”Ÿ 32K â†’ æ‰©å±•è‡³ 256K | åœ¨ LongBench V2ã€MRCR ä¸Šè¶…è¶Šæ›´å¤§å…¨æ³¨æ„åŠ›æ¨¡å‹ |
| **æ¨ç†é€Ÿåº¦** | MTP åŠ é€Ÿè¾¾ 2.6x | åˆ©ç”¨ speculative decoding æ˜¾è‘—æå‡åå |
| **åè®­ç»ƒå¯æ‰©å±•æ€§** | MOPD æ”¯æŒæ¨¡å—åŒ–é›†æˆæ–°æ•™å¸ˆ | é¿å…é‡å¤è®­ç»ƒï¼Œæ”¯æŒæ•™å¸ˆ-å­¦ç”Ÿå…±è¿›åŒ– |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

#### é¢„è®­ç»ƒæ•°æ®
- **æ€»é‡**ï¼š27 ä¸‡äº¿ tokens
- æ¥æºï¼šé«˜è´¨é‡ç½‘é¡µã€ä¹¦ç±ã€å­¦æœ¯è®ºæ–‡ã€ä»£ç ã€STEM å†…å®¹
- ç‰¹åˆ«å¼ºè°ƒé•¿è·ç¦»ä¾èµ–æ•°æ®ï¼ˆå¦‚å®Œæ•´ä»“åº“ä»£ç ã€PRã€commit å†å²ï¼‰

#### è¯„ä¼°åŸºå‡†
| ç±»åˆ« | ä¸»è¦æ•°æ®é›† |
|------|-----------|
| **é€šç”¨ç†è§£ä¸æ¨ç†** | MMLU, BBH, TriviaQA, DROP, ARC, HellaSwag, WinoGrande |
| **æ•°å­¦æ¨ç†** | GSM8K, MATH, AIME 2024/25, HMMT Feb.2025 |
| **ç¼–ç¨‹èƒ½åŠ›** | HumanEval+, MBPP+, CRUXEval, LiveCodeBench, SWE-Bench |
| **ä¸­æ–‡ç†è§£** | C-Eval, CMMLU, C-SimpleQA |
| **å¤šè¯­è¨€èƒ½åŠ›** | GlobalMMLU, INCLUDE |
| **é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡** | LongBench V2, MRCR, GSM-Infinite, NIAH-Multi |
| **æ™ºèƒ½ä½“ä»»åŠ¡** | SWE-Bench Verified/Multilingual, Terminal-Bench, BrowseComp, t2-Bench |

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹è§„æ¨¡**ï¼šæ€»å‚ 309Bï¼Œæ¿€æ´» 15Bï¼›MoE æ¯å±‚ 256 ä¸“å®¶ï¼Œæ¿€æ´» 8 ä¸ª
- **ä¸Šä¸‹æ–‡é•¿åº¦**ï¼šåŸç”Ÿ 32Kï¼Œæ‰©å±•è‡³ 256K
- **è®­ç»ƒç²¾åº¦**ï¼šFP8 æ··åˆç²¾åº¦ï¼ˆéƒ¨åˆ†ä¿ç•™ BF16/FP32ï¼‰
- **è¯„ä¼°æ–¹å¼**ï¼š
  - Zero-shot / Few-shot å‡†ç¡®ç‡
  - Resolved Rateï¼ˆSWE-Benchï¼‰
  - Acceptance Lengthï¼ˆMTPï¼‰
  - Decoding Speedupï¼ˆvs. baselineï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **å¼€æºæ¨¡å‹**ï¼šDeepSeek-V3.2-Thinking, Kimi-K2-Thinking, DeepSeek-V3.2-Exp-Base
- **é—­æºæ¨¡å‹**ï¼šClaude Sonnet 4.5, GPT-5 High, Gemini 3.0 Pro
- æ‰€æœ‰å¯¹æ¯”å‡åŸºäºå…¬å¼€æŠ¥å‘Šæˆ–å®˜æ–¹å‘å¸ƒç»“æœ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 9ï¼‰

| åŸºå‡† | MiMo-V2-Flash | æœ€ä¼˜åŸºçº¿ | è¡¨ç° |
|------|---------------|---------|-------|
| **MMLU-Pro** | 84.9 | Kimi-K2 (84.6) | âœ… è¶…è¶Š |
| **GPQA-Diamond** | 84.3 | Claude (91.9) | æ¥è¿‘ SOTA |
| **AIME 2025** | 94.1 | Kimi-K2 (94.5) | æ¥è¿‘ SOTA |
| **LiveCodeBench** | 85.1 | Kimi-K2 (83.1) | âœ… è¶…è¶Š |
| **SWE-Bench Verified** | **73.4%** | GPT-5-High (74.9%) | å½“å‰æœ€ä½³å¼€æºæ¨¡å‹ |
| **SWE-Bench Multilingual** | **71.7%** | Kimi-K2 (61.1%) | æ˜¾è‘—é¢†å…ˆ |
| **LongBench V2** | 60.6 | Claude (65.6) | æ¥è¿‘é—­æºæ¨¡å‹ |
| **MRCR** | 45.7 | DeepSeek-V3.2 (55.5) | ä»æœ‰å·®è· |
| **BrowseComp (w/ Context Manage)** | 58.3 | Kimi-K2 (60.2) | æ¥è¿‘æœ€ä¼˜ |

> æ³¨ï¼šMiMo-V2-Flash åœ¨ **SWE-Bench Verified** ä¸Šè¾¾åˆ° 73.4%ï¼Œæ˜¯ç›®å‰è¡¨ç°æœ€å¥½çš„å¼€æºæ¨¡å‹ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- å°½ç®¡æ€»å‚æ•°ä»…ä¸º DeepSeek-V3.2 çš„ ~46%ã€Kimi-K2 çš„ ~30%ï¼Œä½†åœ¨å¤šæ•°æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°ç›¸å½“ç”šè‡³æ›´ä¼˜ã€‚
- åœ¨ **é•¿ä¸Šä¸‹æ–‡æ£€ç´¢ä»»åŠ¡ NIAH-Multi** ä¸­ï¼ŒMiMo-V2-Flash åœ¨ 32Kâ€“256K é•¿åº¦ä¸‹æˆåŠŸç‡æ¥è¿‘ 100%ï¼Œè¿œä¼˜äº DeepSeek-V3.2-Exp Baseï¼ˆåœ¨ 128K ä¸‹é™è‡³ 94.3%ï¼‰ã€‚
- åœ¨ **GSM-Infiniteï¼ˆæç«¯é•¿ä¸Šä¸‹æ–‡æ¨ç†ï¼‰** ä¸Šï¼ŒMiMo-V2-Flash ä» 16K åˆ° 128K æ€§èƒ½ä¸‹é™å¹³ç¼“ï¼ˆ37.7 â†’ 29.0ï¼‰ï¼Œè€Œ DeepSeek-V3.2-Exp ä» 50.4 é™è‡³ 25.7ï¼Œæ˜¾ç¤ºå…¶æ›´å¼ºçš„é²æ£’æ€§ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 2â€“4ï¼‰

#### ä¸åŒæ³¨æ„åŠ›é…ç½®å¯¹æ¯”ï¼ˆ32B æ¨¡å‹éªŒè¯ï¼‰
| é…ç½® | MMLU | GSM8K | MATH | GSM-Infinite | AIME25 |
|------|------|--------|--------|--------------|--------|
| All GA | 57.3 | 34.2 | 9.5 | 12.3 | 45.5 |
| Hybrid SWA (W=128, w/o sink) | 54.9 | 36.9 | 8.9 | 17.3 | 47.1 |
| **Hybrid SWA (W=128, w/ sink)** | **58.3** | **36.9** | **10.3** | **17.3** | **47.1** |
| Hybrid SWA (W=512, w/ sink) | 58.3 | 37.9 | 10.0 | 17.2 | 46.3 |

> âœ… **ç»“è®º**ï¼šåŠ å…¥ attention sink åï¼Œå°çª—å£ï¼ˆ128ï¼‰åè€Œä¼˜äºå¤§çª—å£ï¼ˆ512ï¼‰ï¼Œå°¤å…¶åœ¨é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸­è¡¨ç°æ›´ç¨³å®šã€‚

#### MTP æ¨ç†åŠ é€Ÿæ•ˆæœï¼ˆTable 10ï¼‰
åœ¨æ‰¹å¤§å° 64ã€è¾“å…¥ 16Kã€è¾“å‡º 1K åœºæ™¯ä¸‹ï¼š
- å½“ Acceptance Length = 3.6 æ—¶ï¼Œ**è§£ç é€Ÿåº¦æå‡ 2.53x**
- é€Ÿåº¦å¢ç›Šéš Acceptance Length çº¿æ€§å¢é•¿

> å›¾ 7 æ˜¾ç¤ºï¼š**next-token entropy ä¸ acceptance length å¼ºè´Ÿç›¸å…³**ï¼ˆ$R^2=0.995$ï¼‰ï¼Œè¯´æ˜ç¡®å®šæ€§è¶Šé«˜çš„ä»»åŠ¡ï¼ˆå¦‚ WebDevï¼‰ï¼ŒMTP åŠ é€Ÿæ•ˆæœè¶Šå¥½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å°çª—å£ + attention sink å¯å®ç°é«˜æ•ˆä¸”å¼ºå¤§çš„é•¿ä¸Šä¸‹æ–‡å»ºæ¨¡**  
   å³ä½¿ä½¿ç”¨ä»… 128-token çš„æ»‘åŠ¨çª—å£ï¼Œåœ¨ learnable attention sink çš„å¸®åŠ©ä¸‹ä»èƒ½è¶…è¶Šå…¨æ³¨æ„åŠ›æ¨¡å‹ï¼Œå°¤å…¶æ˜¯åœ¨é•¿åºåˆ—ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´å¥½çš„æ³›åŒ–æ€§å’Œç¨³å®šæ€§ã€‚

2. **MTP ä¸ä»…å¯ç”¨äºè®­ç»ƒå¢å¼ºï¼Œæ›´æ˜¯é«˜æ•ˆçš„æ¨ç†åŠ é€Ÿæ‰‹æ®µ**  
   å°† MTP ä½œä¸º speculative decoding çš„ draft modelï¼Œå¯åœ¨æ— éœ€é¢å¤–ç¡¬ä»¶çš„æƒ…å†µä¸‹å®ç°æœ€é«˜ **2.6x çš„è§£ç åŠ é€Ÿ**ï¼Œç‰¹åˆ«é€‚ç”¨äº RL rollout ç­‰é«˜å»¶è¿Ÿåœºæ™¯ã€‚

3. **MOPD æˆåŠŸå®ç°äº†å¤šé¢†åŸŸèƒ½åŠ›çš„æ— æŸèåˆ**  
   é€šè¿‡ token-level çš„ reverse KL è’¸é¦ï¼Œå­¦ç”Ÿæ¨¡å‹ä¸ä»…ç»§æ‰¿äº†å„é¢†åŸŸæ•™å¸ˆçš„æœ€ä½³èƒ½åŠ›ï¼Œè¿˜åœ¨éƒ¨åˆ†ä»»åŠ¡ä¸Šå®ç°åè¶…ï¼ˆå¦‚ AIME 2025 è¾¾åˆ° 94.1ï¼Œè¶…è¿‡æœ€å¼ºæ•™å¸ˆ 93.9ï¼‰ã€‚

4. **å¤§è§„æ¨¡ agentic RL è®­ç»ƒå…·æœ‰å¼ºè¿ç§»èƒ½åŠ›**  
   åœ¨ä»£ç æ™ºèƒ½ä½“ä¸Šçš„å¤§è§„æ¨¡ RL è®­ç»ƒä¸ä»…èƒ½æå‡ SWE-Bench è¡¨ç°ï¼Œè¿˜èƒ½æ­£å‘è¿ç§»åˆ°æ•°å­¦ã€æœç´¢ã€é€šç”¨æ¨ç†ç­‰å¤šä¸ªä»»åŠ¡ï¼ˆè§ Figure 5ï¼‰ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **çŸ¥è¯†å®¹é‡å—é™äºå‚æ•°é‡**ï¼šåœ¨ SimpleQA ç­‰çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸Šå¾—åˆ†è¾ƒä½ï¼ˆ20.6%ï¼‰ï¼Œè¡¨æ˜å…¶çŸ¥è¯†è®°å¿†èƒ½åŠ›å¼±äºæ›´å¤§æ¨¡å‹ã€‚
- **é•¿ä¸Šä¸‹æ–‡ç”Ÿæˆä»»åŠ¡ä»æœ‰æå‡ç©ºé—´**ï¼šåœ¨ MRCR ä¸Šè½åäº DeepSeek-V3.2ï¼Œè¯´æ˜å¤æ‚å¤šè·³æ£€ç´¢ä»»åŠ¡ä»æ˜¯æŒ‘æˆ˜ã€‚
- **MTP åŠ é€Ÿä¾èµ–ä»»åŠ¡ä¸ç¡®å®šæ€§**ï¼šåœ¨å¼€æ”¾ç”Ÿæˆç±»ä»»åŠ¡ï¼ˆå¦‚ Creative Writingï¼‰ä¸­ acceptance length è¾ƒçŸ­ï¼ŒåŠ é€Ÿæ•ˆæœæœ‰é™ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å¤§æ¨¡å‹è§„æ¨¡**ï¼šé€šè¿‡å¢åŠ  total parameters ç¼©å°ä¸é¡¶çº§é—­æºæ¨¡å‹ï¼ˆå¦‚ GPT-5 Highï¼‰ä¹‹é—´çš„å·®è·ã€‚
2. **æ·±å…¥æ¢ç´¢ agentic-oriented æ¶æ„è®¾è®¡**ï¼šå½“å‰æ¶æ„ä»åŸºäºæ ‡å‡† Transformerï¼Œæœªæ¥å¯è®¾è®¡æ›´é€‚é…æ™ºèƒ½ä½“è¡Œä¸ºçš„æ–°å‹ç»“æ„ã€‚
3. **è¿­ä»£å¼æ•™å¸ˆ-å­¦ç”Ÿå…±è¿›åŒ–**ï¼šåˆ©ç”¨ MOPD æ¡†æ¶æ„å»ºé—­ç¯ç³»ç»Ÿï¼Œè®©è’¸é¦åçš„å­¦ç”Ÿé‡æ–°å‚ä¸ RL è®­ç»ƒç”Ÿæˆæ›´å¼ºæ•™å¸ˆï¼Œå½¢æˆè‡ªæˆ‘å¢å¼ºå¾ªç¯ã€‚
4. **ä¼˜åŒ– context management ç­–ç•¥**ï¼šè¿›ä¸€æ­¥ç ”ç©¶å¦‚ä½•åŠ¨æ€å‹ç¼©ã€ç´¢å¼•å’Œæ£€ç´¢å†å²ä¸Šä¸‹æ–‡ä»¥åº”å¯¹è¶…é•¿å¯¹è¯ä¸å¤æ‚ä»»åŠ¡ã€‚

---

> ğŸ”— **å¼€æºä¿¡æ¯**ï¼šMiMo-V2-Flash çš„æ¨¡å‹æƒé‡åŠ 3 å±‚ MTP æƒé‡å·²å¼€æºï¼Œåœ°å€ä¸º [https://github.com/XiaomiMiMo/MiMo-V2-Flash](https://github.com/XiaomiMiMo/MiMo-V2-Flash)ã€‚

</details>

---

### 4. [Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.02346)

**Authors**: Falcon LLM Team, Iheb Chaabane, Puneesh Khanna, Suhail Mohmad, Slim Frikha, Shi Hu, Abdalgader Abubaker, Reda Alami, Mikhail Lubinets, Mohamed El Amine Seddik, Hakim Hacid  
**Category**: cs.AI  
**Published**: 2026-01-07  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.02346v1  

#### Abstract
This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning model...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFalcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½æå‡ä¾èµ–äºå¤§è§„æ¨¡è®­ç»ƒï¼ˆscaling trainingï¼‰ï¼Œä½†è¿™ç§æ–¹æ³•é¢ä¸´è®¡ç®—æˆæœ¬é«˜æ˜‚ã€é«˜è´¨é‡äººç±»æ•°æ®ç¨€ç¼ºç­‰é—®é¢˜ã€‚åŒæ—¶ï¼Œ**Test-Time Scaling (TTS)** è™½ç„¶èƒ½é€šè¿‡å¢åŠ æ¨ç†æ—¶è®¡ç®—é‡æ¥æå‡æ€§èƒ½ï¼Œä½†ä¹Ÿå¸¦æ¥äº†æé«˜çš„æ¨ç†å¼€é”€ã€‚

Falcon-H1Ræ—¨åœ¨è§£å†³ä»¥ä¸‹æ ¸å¿ƒçŸ›ç›¾ï¼š
- å¦‚ä½•åœ¨**ä¸æ‰©å¤§æ¨¡å‹å‚æ•°è§„æ¨¡**çš„å‰æä¸‹ï¼Œå®ç°ä¸æ›´å¤§æ¨¡å‹ç›¸å½“ç”šè‡³æ›´ä¼˜çš„æ¨ç†èƒ½åŠ›ï¼Ÿ
- å¦‚ä½•è®¾è®¡ä¸€ä¸ªæ—¢**é«˜ç²¾åº¦åˆé«˜æ•ˆ**ï¼ˆtoken-efficient, fast inferenceï¼‰çš„æ¨¡å‹æ¶æ„ï¼Œä»¥æ”¯æŒé«˜æ•ˆçš„TTSï¼Ÿ

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
Falcon-H1Ræ˜¯ä¸€ä¸ª**7Bå‚æ•°çš„å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰**ï¼Œä¸“ä¸ºæ¨ç†ä¼˜åŒ–è€Œè®¾è®¡ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºâ€œä¸‰ä½ä¸€ä½“â€çš„é«˜æ•ˆæ¨ç†æ¡†æ¶ï¼š

1. **Hybrid Architecture for Efficient Reasoning**
   - åŸºäº **Falcon-H1 æ¶æ„**ï¼Œé‡‡ç”¨ **Transformer-Mamba æ··åˆå¹¶è¡Œæ¶æ„**ã€‚
   - ç»“åˆäº†Transformerçš„å¼ºå¤§è¡¨è¾¾èƒ½åŠ›å’ŒMambaï¼ˆSSMï¼‰åœ¨é•¿åºåˆ—ä¸Šçš„çº¿æ€§æ—¶é—´æ¨ç†ä¼˜åŠ¿ï¼Œæ˜¾è‘—æå‡äº†**ååé‡å’Œå†…å­˜æ•ˆç‡**ï¼Œå°¤å…¶é€‚åˆå¤„ç†é•¿Chain-of-Thoughtï¼ˆCoTï¼‰ç”Ÿæˆå’Œé«˜å¹¶å‘TTSåœºæ™¯ã€‚

2. **Robust Training Strategy**
   - **Cold-start SFTé˜¶æ®µ**ï¼šä½¿ç”¨ç²¾å¿ƒç­›é€‰çš„é•¿æ¨ç†è½¨è¿¹æ•°æ®è¿›è¡Œç›‘ç£å¾®è°ƒï¼Œå¼ºè°ƒæ•°å­¦ã€ä»£ç ã€ç§‘å­¦ç­‰é¢†åŸŸçš„éš¾é¢˜ï¼Œå¹¶å¼•å…¥**difficulty-aware weighting**ç­–ç•¥ï¼Œå¯¹å›°éš¾æ ·æœ¬åŠ æƒã€‚
   - **Reinforcement Learning with Verifiable Rewards (RLVR)** é˜¶æ®µï¼šåŸºäºGRPOç®—æ³•ï¼Œåœ¨æ•°å­¦å’Œä»£ç ä»»åŠ¡ä¸Šè¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹ï¼Œé¼“åŠ±æ¢ç´¢å¤šæ ·åŒ–çš„è§£é¢˜è·¯å¾„ï¼ŒåŒæ—¶æ§åˆ¶è¾“å‡ºè´¨é‡ã€‚

3. **Superior Efficiency and Accuracy via TTS**
   - å°†Falcon-H1Rä¸æœ€æ–°çš„TTSæ–¹æ³• **DeepConf** ç»“åˆï¼ŒåŠ¨æ€å‰ªæä½ç½®ä¿¡åº¦çš„æ¨ç†é“¾ï¼Œå®ç°æ—©æœŸåœæ­¢ã€‚
   - åœ¨ç›¸åŒè®¡ç®—é¢„ç®—ä¸‹å¯è¿è¡Œæ›´å¤šå¹¶è¡Œæ¨ç†é“¾ï¼Œä»è€Œåœ¨**æ›´ä½tokenæ¶ˆè€—ä¸‹è¾¾åˆ°æ›´é«˜å‡†ç¡®ç‡**ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Falcon-H1Rä¼˜åŠ¿ |
|------|----------------|
| **å‚æ•°æ•ˆç‡** | ä»…7Bå‚æ•°ï¼Œæ€§èƒ½åª²ç¾8Bâ€“32Bç”šè‡³æ›´å¤§çš„SOTAæ¨ç†æ¨¡å‹ï¼ˆå¦‚Qwen3-32B, Phi-4-R-Plus-14Bï¼‰ã€‚ |
| **æ¨ç†æ•ˆç‡** | æ··åˆæ¶æ„å¸¦æ¥æ›´å¿«çš„æ¨ç†é€Ÿåº¦å’Œæ›´é«˜çš„batchååé‡ï¼Œå°¤å…¶åœ¨é•¿åºåˆ—ï¼ˆ16Kâ€“32K tokensï¼‰åœºæ™¯ä¸‹ä¼˜äºçº¯Transformeræ¨¡å‹ã€‚ |
| **TTSå…¼å®¹æ€§** | æ›´å¼ºçš„åŸºç¡€æ¨¡å‹æ€§èƒ½ + æ›´å¥½æ ¡å‡†çš„ç½®ä¿¡åº¦ä¼°è®¡ â†’ æ”¯æŒæ›´æ¿€è¿›çš„early stoppingï¼Œå¤§å¹…é™ä½TTSæˆæœ¬ã€‚ |
| **è®­ç»ƒç­–ç•¥æœ‰æ•ˆæ€§** | æ•°æ®è´¨é‡å’Œè®­ç»ƒæ–¹æ³•æ¯”å•çº¯æ‰©å‚æ›´é‡è¦ï¼ŒéªŒè¯äº†SLMsä¹Ÿèƒ½å…·å¤‡å¼ºå¤§æ¨ç†èƒ½åŠ›ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
#### SFTé˜¶æ®µ
- å¤šé¢†åŸŸæ··åˆæ•°æ®é›†ï¼Œæ¶µç›–ï¼š
  - **Mathematics**: åŒ…å«MATHã€AIMEé£æ ¼é¢˜ç›®ï¼Œå¼ºè°ƒæ­£ç¡®æ€§å’Œå®Œæ•´æ¨å¯¼ã€‚
  - **Coding**: Python/C++ç®—æ³•é¢˜ï¼Œæ³¨é‡åŠŸèƒ½æ­£ç¡®æ€§å’Œæ‰§è¡ŒéªŒè¯ã€‚
  - **Science**: ç§‘å­¦æ¨ç†é—®é¢˜ï¼Œç»“åˆLLM judgeè¿›è¡Œè¯„åˆ†ã€‚
  - **Other**: Instruction-following, Tool calling, Chatç­‰é€šç”¨ä»»åŠ¡ã€‚
- æ€»è®¡çº¦3.1Mæ ·æœ¬ï¼Œå“åº”tokenåˆ†å¸ƒå‘ˆlog-normalé•¿å°¾åˆ†å¸ƒã€‚

#### RLé˜¶æ®µ
- æ•°å­¦ä¸ç¼–ç¨‹ä¸“ç”¨æ•°æ®é›†ï¼Œä¸SFTå®Œå…¨æ— é‡å ï¼Œé˜²æ­¢è®°å¿†åŒ–ã€‚
- æ•°æ®ç»è¿‡ä¸¥æ ¼è¿‡æ»¤ï¼š
  - æ’é™¤å¤ªç®€å•ï¼ˆpass@8=100%ï¼‰æˆ–å¤ªéš¾ï¼ˆæ‰€æœ‰rolloutå‡å¤±è´¥ä¸”è¶…é•¿ï¼‰çš„é—®é¢˜ã€‚
  - æœ€ç»ˆå½¢æˆâ€œé•œåƒJå‹â€éš¾åº¦åˆ†å¸ƒï¼Œèšç„¦ä¸­ç­‰åéš¾é—®é¢˜ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### åŸºç¡€è¯„ä¼°ï¼ˆStandard Reasoning Tasksï¼‰
- **è¯„ä¼°æ–¹å¼**ï¼š`pass@1`ï¼Œå¤šè½®é‡‡æ ·åæå–ç­”æ¡ˆã€‚
- **å…³é”®è®¾ç½®**ï¼š
  - æ¸©åº¦ `T=0.6`, `top_p=0.95`
  - ç³»ç»Ÿæç¤ºå›ºå®šæ ¼å¼ï¼š`<think> reasoning </think> answer`
- **ä¸»è¦åŸºå‡†**ï¼š
  - **Math**: AIME24, AIME25, HMMT25, AMO-Bench, MATH500
  - **Code**: LiveCodeBench v6, SciCode, T2-Telecom, Terminal Bench Hard
  - **General**: GPQA-Diamond, MMLU-Pro, Humanity's Last Exam (HLE), IFBench

#### Test-Time Scaling (TTS) å®éªŒ
- **æ–¹æ³•**ï¼šé‡‡ç”¨ **DeepConf@512** æ–¹æ³•ï¼ˆFu et al., 2025bï¼‰
  - ç”Ÿæˆæœ€å¤š512æ¡å¹¶è¡Œæ¨ç†é“¾ã€‚
  - åŠ¨æ€è®¡ç®—æ¯æ¡é“¾çš„group confidenceï¼Œä½äºé˜ˆå€¼åˆ™æå‰ç»ˆæ­¢ã€‚
  - æŠ•ç¥¨æœºåˆ¶ï¼šå¤šæ•°æŠ•ç¥¨ã€ç½®ä¿¡åº¦åŠ æƒç­‰ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - å‡†ç¡®ç‡ï¼ˆAccuracy â†‘ï¼‰
  - ç”Ÿæˆtokenæ€»æ•°ï¼ˆTokens â†“ï¼Œè¡¡é‡æˆæœ¬ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å¯¹æ¯”äº†å¤šä¸ªSOTAæ¨ç†æ¨¡å‹ï¼Œè¦†ç›–ä¸åŒå‚æ•°èŒƒå›´ï¼š
- **7Bçº§**ï¼šQwen3-8B, DeepSeek-R1-0528-Qwen3-8B
- **10â€“20Bçº§**ï¼šPhi-4-Reasoning-Plus-14B, Apriel-1.5-15b-Thinker, GPT-OSS-20B
- **>30Bçº§**ï¼šQwen3-32B, Nemotron-H-47B-Reasoning

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆStandard Evaluationï¼‰

#### æ•°å­¦æ¨ç†ï¼ˆMathï¼‰
| Model | AIME24 | AIME25 | HMMT25 | AMO-Bench | MATH500 |
|-------|--------|--------|--------|-----------|---------|
| **Falcon-H1R-7B** | **88.1** | **83.1** | **64.9** | **36.3** | **97.4** |
| Qwen3-32B | 79.4 | 71.0 | 49.8 | 21.3 | 96.8 |
| GPT-OSS-20B | 83.3 | 84.4 | 64.8 | 26.0 | 94.8 |
| Phi-4-R-Plus-14B | 77.2 | 71.2 | 47.7 | 15.0 | 95.4 |

> âœ… Falcon-H1Råœ¨AIME24ã€HMMT25ã€AMO-Benchä¸‰é¡¹ä¸Š**æ’åç¬¬ä¸€**ï¼Œå…¶ä¸­AMO-Benché¢†å…ˆç¬¬äºŒåè¶…10ä¸ªç™¾åˆ†ç‚¹ã€‚

#### ç¼–ç¨‹ç”Ÿæˆï¼ˆCodeï¼‰
| Model | LCB v6 | SciCode (sub/main) | T2-Telecom | TB Hard |
|-------|--------|--------------------|------------|---------|
| **Falcon-H1R-7B** | **68.6** | 28.3 / 3.9 | 25.4 | 4.9 |
| GPT-OSS-20B | 72.0 | 34.9 / 6.2 | 60.2* | 9.9* |

> âœ… åœ¨LiveCodeBench v6ä¸Šä»…æ¬¡äºGPT-OSS-20Bï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–åŒçº§åˆ«æ¨¡å‹ã€‚

#### é€šç”¨æ¨ç†ï¼ˆGeneralï¼‰
| Model | GPQA-D | MMLU-Pro | HLE | IFBench |
|-------|--------|----------|-----|--------|
| **Falcon-H1R-7B** | 61.3 | 72.1 | **11.1** | **53.4** |
| Phi-4-R-Plus-14B | 67.9 | 79.2 | 5.9 | 51.7 |

> âš ï¸ åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚GPQA-D, MMLU-Proï¼‰ä¸Šä»æœ‰æå‡ç©ºé—´ï¼Œä½†HLEå’ŒIFBenchè¡¨ç°ä¼˜å¼‚ï¼Œè¯´æ˜æŒ‡ä»¤éµå¾ªèƒ½åŠ›å¼ºã€‚

---

### Test-Time Scaling (TTS) å®éªŒç»“æœï¼ˆDeepConf@512ï¼‰

| Model | AIME25 Accâ†‘ | AIME25 Tokâ†“ | AMO-Bench Accâ†‘ | AMO-Bench Tokâ†“ |
|-------|-------------|-------------|----------------|----------------|
| Qwen3-32B | 86.7 | 174.8M | 28.2 | 364.8M |
| DS-R1-0528-Qwen3-8B | 82.8 | 174.5M | 25.6 | 487.9M |
| **Falcon-H1R-7B** | **96.7** | **95.1M** | **35.9** | **216.8M** |

> ğŸ”¥ **å…³é”®çªç ´**ï¼š
> - åœ¨AIME25ä¸Šè¾¾åˆ°**96.7%å‡†ç¡®ç‡**ï¼Œæ¯”Qwen3-32Bé«˜è¿‘10ä¸ªç™¾åˆ†ç‚¹ã€‚
> - åŒæ—¶å°†tokenæ¶ˆè€—ä»~175Mé™è‡³**95.1Mï¼Œå‡å°‘çº¦45%**ã€‚
> - åœ¨AMO-Benchä¸Šå‡†ç¡®ç‡æå‡è¿‘8ä¸ªç™¾åˆ†ç‚¹ï¼Œtokenå‡å°‘çº¦40%ã€‚

è¿™è¡¨æ˜Falcon-H1Rä¸ä»…åŸºç¡€æ€§èƒ½å¼ºï¼Œè€Œä¸”**ç½®ä¿¡åº¦æ ¡å‡†æ›´å¥½**ï¼Œä½¿å¾—DeepConfèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å‰ªææ— æ•ˆè·¯å¾„ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### SFTé˜¶æ®µå…³é”®å‘ç°
| å› ç´  | æœ€ä½³é€‰æ‹© | å½±å“ |
|------|----------|------|
| å­¦ä¹ ç‡ | `1024Ã—10â»â¶`ï¼ˆè¾ƒå¤§LRï¼‰ | åŠ é€Ÿæ”¶æ•›ï¼Œæå‡ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ |
| Rolloutæ•°é‡ | `n=12` | æ›´å¤šæ¨ç†è·¯å¾„æå‡æ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶å¯¹éš¾é¢˜æœ‰æ•ˆ |
| æ•™å¸ˆæ¨¡å‹æ··åˆ | å•ä¸€æ•™å¸ˆ > å¤šæ•™å¸ˆ | å¤šæ•™å¸ˆå¯¼è‡´æ¨ç†é£æ ¼å†²çªï¼Œé™ä½ä¸€è‡´æ€§ |
| æ•°æ®æƒé‡ | å›°éš¾é¢˜åŠ æƒ1.25â€“1.75Ã— | æ˜¾è‘—æå‡Hardé—®é¢˜è¡¨ç°ï¼Œé¿å…è¿‡æ‹Ÿåˆç®€å•æ ·æœ¬ |

#### RLé˜¶æ®µå…³é”®å‘ç°
| è®¾ç½® | ç»“æœ |
|------|------|
| Group Size (G) | `G=16` æœ€ä¼˜ï¼ŒG=32æ”¶ç›Šé€’å‡ |
| Max Length | `48K tokens` å…è®¸å……åˆ†æ€è€ƒï¼Œä¼˜äº24K |
| Curriculum | **Math-onlyå…ˆè®­**æ•ˆæœæœ€å¥½ï¼Œåç»­åŠ å…¥Codeæ”¶ç›Šæœ‰é™ |
| KL Penalty | è®¾ä¸º0ï¼ˆå…è®¸è‡ªç”±æ¢ç´¢ï¼‰æ›´ç¨³å®š |

> ğŸ“Œ ç»“è®ºï¼š**æ•°å­¦æ¨ç†èƒ½åŠ›å…·æœ‰å¼ºè¿ç§»æ€§**ï¼Œæ˜¯æ„å»ºé€šç”¨æ¨ç†æ¨¡å‹çš„å…³é”®åŸºçŸ³ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å°å‹æ¨¡å‹ä¹Ÿèƒ½å®ç°é¡¶çº§æ¨ç†æ€§èƒ½**
   - Falcon-H1R-7Båœ¨å¤šé¡¹æ¨ç†åŸºå‡†ä¸Šè¶…è¶Š2â€“7å€å¤§çš„æ¨¡å‹ï¼Œè¯æ˜**å‚æ•°è§„æ¨¡ä¸æ˜¯å†³å®šæ¨ç†èƒ½åŠ›çš„å”¯ä¸€å› ç´ **ã€‚
   - **é«˜è´¨é‡æ•°æ® + ç²¾ç»†è®­ç»ƒç­–ç•¥**ï¼ˆSFT + RLVRï¼‰æ˜¯å…³é”®é©±åŠ¨åŠ›ã€‚

2. **æ•°å­¦æ¨ç†æŠ€èƒ½å…·æœ‰å¼ºè·¨åŸŸè¿ç§»èƒ½åŠ›**
   - å®éªŒè¡¨æ˜ï¼Œä¸“æ³¨äºæ•°å­¦è®­ç»ƒçš„æ¨¡å‹åœ¨ç¼–ç å’Œç§‘å­¦ä»»åŠ¡ä¸Šä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œåä¹‹åˆ™ä¸ç„¶ã€‚
   - â€œMath-firstâ€è®­ç»ƒèŒƒå¼å¯èƒ½æ˜¯æ„å»ºé€šç”¨æ¨ç†Agentçš„æœ‰æ•ˆè·¯å¾„ã€‚

3. **æ··åˆæ¶æ„æ˜¾è‘—æå‡TTSæ•ˆç‡**
   - Falcon-H1çš„Transformer-Mambaæ··åˆè®¾è®¡åœ¨é•¿åºåˆ—ã€å¤§æ‰¹é‡æ¨ç†ä¸­å±•ç°å‡ºæ˜æ˜¾ä¼˜åŠ¿ï¼ˆè§Appendix Bï¼‰ï¼Œä½¿å…¶æˆä¸ºTTSçš„ç†æƒ³backboneã€‚

4. **TTSæ•ˆç‡å–å†³äºåŸºç¡€æ¨¡å‹è´¨é‡**
   - DeepConfçš„æ•ˆæœé«˜åº¦ä¾èµ–äºæ¨¡å‹è‡ªèº«çš„æ¨ç†èƒ½åŠ›å’Œç½®ä¿¡åº¦æ ¡å‡†æ°´å¹³ã€‚
   - Falcon-H1Rå› åŸºç¡€æ€§èƒ½å¼ºã€confidenceä¼°è®¡å¯é ï¼Œèƒ½åœ¨æ›´å°‘tokenä¸‹å®ç°æ›´é«˜å‡†ç¡®ç‡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡è¡¨ç°ç›¸å¯¹ä¸€èˆ¬**ï¼šåœ¨GPQA-Diamondå’ŒMMLU-Proä¸Šæœªè¾¾æœ€ä¼˜ï¼Œåæ˜ å…¶è®­ç»ƒä¾§é‡æ¨ç†è€Œéå¹¿åšçŸ¥è¯†ã€‚
- **å®‰å…¨ä¸é€æ˜æ€§çš„æƒè¡¡**ï¼šCoTä¸­å¯èƒ½æš´éœ²æ•æ„Ÿæ¨ç†è¿‡ç¨‹ï¼ˆè§Appendix Eï¼‰ï¼Œç›´æ¥å±•ç¤ºç»™ç”¨æˆ·éœ€è°¨æ…ã€‚
- **RLè®­ç»ƒä»å…·æŒ‘æˆ˜æ€§**ï¼šéœ€è¦å¤§é‡é«˜è´¨é‡rewardä¿¡å·ï¼Œå°¤å…¶åœ¨éå½¢å¼åŒ–é¢†åŸŸï¼ˆå¦‚å¼€æ”¾ç§‘å­¦ï¼‰éš¾ä»¥æ‰©å±•ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´å°è§„æ¨¡ï¼ˆå¦‚1Bâ€“3Bï¼‰çš„é«˜æ•ˆæ¨ç†æ¨¡å‹ã€‚
- å¼€å‘é€‚ç”¨äºéç¡®å®šæ€§ä»»åŠ¡ï¼ˆå¦‚åˆ›æ„å†™ä½œã€ç­–ç•¥è§„åˆ’ï¼‰çš„TTSæ–¹æ³•ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ–æ··åˆæ¶æ„ï¼Œæå‡SSMæ¨¡å—åœ¨æç«¯é•¿ä¸Šä¸‹æ–‡ä¸‹çš„ç¨³å®šæ€§ã€‚
- æ„å»ºç«¯åˆ°ç«¯çš„å®‰å…¨CoTç”Ÿæˆæœºåˆ¶ï¼Œåœ¨ä¿è¯æ¨ç†æ·±åº¦çš„åŒæ—¶æŠ‘åˆ¶æœ‰å®³å†…å®¹æš´éœ²ã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **Falcon-H1Rè¯æ˜äº†â€œå°æ¨¡å‹+ç²¾è®­ç»ƒ+å¥½æ¶æ„â€å¯ä»¥æ‰“ç ´â€œå¤§æ¨¡å‹=å¼ºæ¨ç†â€çš„æƒ¯æ€§æ€ç»´ï¼Œä¸ºé«˜æ•ˆã€å¯æ‰©å±•çš„æ™ºèƒ½æ¨ç†ç³»ç»Ÿæä¾›äº†æ–°çš„èŒƒå¼ã€‚**

</details>

---

### 5. [RadioDiff-Flux: Efficient Radio Map Construction via Generative Denoise Diffusion Model Trajectory Midpoint Reuse](https://arxiv.org/abs/2601.02790)

**Authors**: Xiucheng Wang, Peilin Zheng, Honggang Jia, Nan Cheng, Ruijin Sun, Conghao Zhou, Xuemin Shen  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.02790v1  

#### Abstract
Accurate radio map (RM) construction is essential to enabling environment-aware and adaptive wireless communication. However, in future 6G scenarios characterized by high-speed network entities and fast-changing environments, it is very challenging to meet real-time requirements. Although generative...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRadioDiff-Flux: Efficient Radio Map Construction via Generative Denoise Diffusion Model Trajectory Midpoint Reuse

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨6Gç½‘ç»œä¸­ï¼Œ**Radio Map (RM)** æ„å»ºå¯¹äºç¯å¢ƒæ„ŸçŸ¥å’Œè‡ªé€‚åº”æ— çº¿é€šä¿¡è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œåœ¨é«˜åŠ¨æ€åœºæ™¯ï¼ˆå¦‚æ— äººæœºç§»åŠ¨ã€è½¦è¾†å˜åŒ–ï¼‰ä¸‹ï¼Œä¼ ç»Ÿæ–¹æ³•é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **ç‰©ç†é©±åŠ¨æ–¹æ³•**ï¼ˆå¦‚ray tracingï¼‰ç²¾åº¦é«˜ä½†è®¡ç®—å¤æ‚åº¦æé«˜ï¼Œæ— æ³•å®æ—¶æ›´æ–°ï¼›
- **æ•°æ®é©±åŠ¨æ–¹æ³•**ä¸­ï¼Œåˆ¤åˆ«æ¨¡å‹éš¾ä»¥ç”Ÿæˆå…¨å±€ä¸€è‡´çš„RMï¼Œè€ŒGANå­˜åœ¨è®­ç»ƒä¸ç¨³å®šé—®é¢˜ï¼›
- **æ‰©æ•£æ¨¡å‹**ï¼ˆDMsï¼‰è™½èƒ½å®ç°é«˜è´¨é‡RMç”Ÿæˆï¼Œä½†å…¶è¿­ä»£å»å™ªè¿‡ç¨‹å¯¼è‡´æ¨ç†å»¶è¿Ÿé•¿è¾¾æ•°ç§’ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶æ€§éœ€æ±‚ã€‚

æ­¤å¤–ï¼Œä¼ ç»ŸDMé‡‡ç”¨â€œé›¶è®°å¿†â€æ¨¡å¼ï¼Œå¯¹ç›¸é‚»ä½ç½®é‡å¤æ‰§è¡Œå®Œæ•´å»å™ªï¼Œé€ æˆå¤§é‡å†—ä½™è®¡ç®—ï¼Œå¹¶å¯èƒ½å¼•å…¥å¸§é—´æŠ–åŠ¨ï¼Œç ´åæ—¶é—´ä¸€è‡´æ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **RadioDiff-Flux**ï¼Œä¸€ç§åŸºäº**éšå¼æ‰©æ•£æ¨¡å‹**ï¼ˆlatent diffusion modelï¼‰çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯**å¤ç”¨æ‰©æ•£è½¨è¿¹ä¸­çš„ä¸­é—´æ½œå˜é‡ï¼ˆmidpointï¼‰** æ¥åŠ é€Ÿæ¨ç†ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
1. **å‘ç°å¹¶éªŒè¯äº†æ‰©æ•£è¿‡ç¨‹ä¸­æ½œå˜é‡çš„è¯­ä¹‰ä¸€è‡´æ€§**  
   åœ¨ç›¸åŒé™æ€ç¯å¢ƒä¸‹ï¼Œä¸åŒBSä½ç½®æˆ–åŠ¨æ€éšœç¢ç‰©é…ç½®æ‰€å¯¹åº”çš„RMï¼Œåœ¨æ‰©æ•£è¿‡ç¨‹çš„ä¸­æœŸï¼ˆmidpointï¼‰å…·æœ‰é«˜åº¦ç›¸ä¼¼çš„æ½œè¡¨ç¤ºã€‚è¿™è¡¨æ˜æ—©æœŸå»å™ªä¸»è¦ç¼–ç ç¨³å®šçš„ç¯å¢ƒè¯­ä¹‰ï¼ˆå¦‚å»ºç­‘å¸ƒå±€ï¼‰ï¼ŒåæœŸæ‰ç»†åŒ–å‘å°„æœºç‰¹æ€§å’ŒåŠ¨æ€å› ç´ ã€‚

2. **ç†è®ºåˆ†ææ”¯æŒmidpointå¤ç”¨å¯è¡Œæ€§**  
   åŸºäºKLæ•£åº¦åˆ†æè¯æ˜ï¼šè¯­ä¹‰ç›¸è¿‘çš„RMåœ¨é«˜å™ªå£°æ°´å¹³ä¸‹çš„æ½œåˆ†å¸ƒå·®å¼‚éšæ‰©æ•£æ­¥æ•°å‘ˆäºŒæ¬¡è¡°å‡ï¼Œè¯´æ˜åœ¨è¶³å¤Ÿé«˜çš„$t$å€¼æ—¶ï¼Œç›¸ä¼¼åœºæ™¯çš„æ½œçŠ¶æ€å¯è§†ä¸ºç­‰ä»·ï¼Œä»è€Œæ”¯æŒå¤ç”¨ã€‚

3. **æå‡ºä¸¤ç§å®ç°æ–¹å¼**ï¼š
   - **Vanilla Midpoint Reuse**ï¼šç›´æ¥å¤ç”¨é¢„è®¡ç®—çš„midpointä½œä¸ºèµ·ç‚¹ï¼Œä»…æ›´æ–°æ¡ä»¶è¾“å…¥ï¼ˆå¦‚BSä½ç½®ï¼‰ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚
   - **RadioDiff-Flux**ï¼šä¸¤é˜¶æ®µæ¶æ„
     - ç¬¬ä¸€é˜¶æ®µï¼šä»…ä½¿ç”¨é™æ€ç¯å¢ƒç‰¹å¾ï¼ˆå¦‚å»ºç­‘ç‰©å¸ƒå±€ï¼‰è®­ç»ƒä¸€ä¸ªä¸“ç”¨æ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆ**è¯­ä¹‰çº§midpoint**ï¼›
     - ç¬¬äºŒé˜¶æ®µï¼šåˆ©ç”¨é¢„è®­ç»ƒçš„RadioDiffæ¨¡å‹ï¼Œä»è¯¥midpointç»§ç»­å®Œæˆå‰©ä½™å»å™ªï¼Œæ¡ä»¶ä¸ºåŠ¨æ€ç¯å¢ƒ+BSä½ç½®ã€‚
   - å®ç°äº†**é™æ€å»ºæ¨¡ä¸åŠ¨æ€ç²¾è°ƒçš„è§£è€¦**ï¼Œå…è®¸ç¼“å­˜å’Œå…±äº«midpointã€‚

4. **æ˜¾è‘—é™ä½è®¡ç®—å¼€é”€**
   - åˆ©ç”¨é™æ€ç‰¹å¾å•é€šé“è¾“å…¥æ›¿ä»£ä¸‰é€šé“ï¼Œå‡å°‘åˆå§‹CNNå±‚FLOPsè¶…è¿‡300Mï¼›
   - æ€»ä½“æ¨ç†å»¶è¿Ÿå¤§å¹…ä¸‹é™ï¼Œå°¤å…¶é€‚ç”¨äºå¤šBSæˆ–å¤šæ—¶åºæ›´æ–°åœºæ™¯ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å‡†ç¡®æ€§ | æ¨ç†é€Ÿåº¦ | å†—ä½™è®¡ç®— | æ—¶é—´ä¸€è‡´æ€§ |
|------|--------|----------|-----------|--------------|
| Ray Tracing | â­â­â­â­â­ | â­ | âŒ é«˜ | âš ï¸ å·® |
| Discriminative Models (e.g., RadioUNet) | â­â­â­ | â­â­â­â­ | âœ… è¾ƒä½ | âš ï¸ ä¸€èˆ¬ |
| GANs | â­â­ | â­â­â­â­ | âœ… | âŒ ä¸ç¨³å®š |
| Standard DMs (e.g., RadioDiff) | â­â­â­â­â­ | â­â­ | âŒ æé«˜ | âŒ å­˜åœ¨æŠ–åŠ¨ |
| **RadioDiff-Flux (Ours)** | â­â­â­â­â­ | â­â­â­â­â­ | âœ…âœ… æä½ | âœ…âœ… è‰¯å¥½ |

> âœ… æ”¯æŒå¿«é€Ÿé€‚åº”æ–°BSä½ç½®æˆ–åŠ¨æ€ç¯å¢ƒï¼Œé¿å…é‡å¤æ—©æœŸè®¡ç®—ï¼›  
> âœ… å¯éƒ¨ç½²äºè¾¹ç¼˜è®¾å¤‡ï¼Œé€‚åˆ6Gç§»åŠ¨åœºæ™¯ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨ **RadioMapSeer** æ•°æ®é›†ï¼Œæºè‡ªOpenStreetMapçš„çœŸå®åŸå¸‚åœ°å›¾ï¼ˆAnkara, Berlinç­‰ï¼‰
- åŒ…å«700å¼ 256Ã—256åˆ†è¾¨ç‡çš„åŸå¸‚åœ°å›¾ï¼ˆ500è®­ç»ƒ + 200æµ‹è¯•ï¼‰
- æ¯å¼ å›¾å«80ä¸ªå‘å°„æœºä½ç½®åŠå…¶å¯¹åº”çœŸå€¼RM
- åˆ†ä¸ºä¸¤ç±»ï¼š
  - **Static RM (SRM)**ï¼šä»…è€ƒè™‘å›ºå®šå»ºç­‘ç‰©å½±å“
  - **Dynamic RM (DRM)**ï¼šåŠ å…¥éšæœºè½¦è¾†ä½œä¸ºåŠ¨æ€éšœç¢ç‰©

### å®éªŒè®¾ç½®
- æ‰€æœ‰å®éªŒåŸºäº **PyTorch + NVIDIA A40 GPU**
- æ‰©æ•£æ­¥æ•° $T = 100$ï¼ˆåŸRadioDiffä¸º1000æ­¥ï¼Œæ­¤å¤„å·²ä¼˜åŒ–ï¼‰
- è¯„ä¼°3000æ¬¡ç‹¬ç«‹è¯•éªŒå–å¹³å‡
- å¤ç”¨æ¯”ä¾‹ $R_{\text{reuse}} \in [0.1, 0.98]$ è¡¨ç¤ºå‰ $R_{\text{reuse}} \times T$ æ­¥ä½¿ç”¨æ—§æ¡ä»¶ç”Ÿæˆmidpoint

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **NMSE / RMSE** | å½’ä¸€åŒ–å‡æ–¹è¯¯å·® / å‡æ–¹æ ¹è¯¯å·®ï¼Œè¡¡é‡æ•´ä½“è¯¯å·® |
| **SSIM** | ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼Œåæ˜ é«˜é¢‘ç»†èŠ‚ä¿ç•™èƒ½åŠ› |
| **PSNR (dB)** | å³°å€¼ä¿¡å™ªæ¯”ï¼Œè¯„ä¼°ä¿¡å·ä¿çœŸåº¦ |
| **Inference Time (ms)** | å•æ¬¡RMç”Ÿæˆè€—æ—¶ï¼Œç”¨äºè®¡ç®—åŠ é€Ÿæ¯” |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **RadioUNet** | CNN-based discriminative | ç»å…¸U-Netç»“æ„ï¼Œç›‘ç£å›å½’ |
| **UVM-Net** | State Space Model | æ›¿æ¢CNNä¸ºä¸»å¹²ï¼Œå¢å¼ºé•¿ç¨‹ä¾èµ–å»ºæ¨¡ |
| **RME-GAN** | GAN-based generative | æ¡ä»¶ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ŒåŸéœ€æµ‹é‡ç‚¹ï¼Œæœ¬æ–‡ç¦ç”¨ |
| **RadioDiff** | Latent Diffusion Model (SOTA) | å½“å‰æœ€ä¼˜RMç”Ÿæˆå™¨ï¼Œä½œä¸ºablation baseline |
| **Vanilla Midpoint Reuse (Ours)** | Simple reuse strategy | å¤ç”¨å·²æœ‰midpointï¼Œä¸ä¿®æ”¹æ¶æ„ |
| **RadioDiff-Flux (Ours)** | Two-stage framework | æ˜¾å¼åˆ†ç¦»é™æ€/åŠ¨æ€å»ºæ¨¡ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### ğŸ“Š **Scenario 1: æ”¹å˜BSä½ç½®ï¼ˆåŒé™æ€ç¯å¢ƒï¼‰**
| æ–¹æ³• | $R_{\text{reuse}}$ | NMSE | Speedup vs RadioDiff |
|------|------------------|-------|------------------------|
| RadioDiff (baseline) | 0.00 | 0.00580 | 1Ã— |
| Vanilla Reuse | 0.70 | 0.00671 | **3.47Ã—** |
| Vanilla Reuse | 0.98 | 0.13098 | **50Ã—** |
| **RadioDiff-Flux** | **0.98** | **0.02957** | **~20Ã—**, æ›´é«˜ä¿çœŸ |

> ğŸ’¡ åœ¨ $R_{\text{reuse}}=0.7$ æ—¶ï¼Œè¯¯å·®å¢åŠ <0.15%ï¼Œé€Ÿåº¦æå‡3.5å€ï¼›  
> ğŸ’¡ RadioDiff-Fluxæœ‰æ•ˆç¼“è§£â€œæ¨¡ç³Šå åŠ â€æ•ˆåº”ï¼Œæ˜¾è‘—æå‡é«˜å¤ç”¨ç‡ä¸‹çš„è´¨é‡ã€‚

#### ğŸ“Š **Scenario 2: ä»é™æ€åˆ°åŠ¨æ€ç¯å¢ƒï¼ˆåŠ è½¦è¾†ï¼‰**
| æ–¹æ³• | $R_{\text{reuse}}$ | NMSE | Speedup |
|------|------------------|-------|---------|
| RadioDiff | 0.00 | 0.00643 | 1Ã— |
| Vanilla Reuse | 0.98 | **0.00776** | **60Ã—** |

> âœ… å³ä½¿å¤ç”¨98%æ­¥éª¤ï¼ŒNMSEä»…ä¸Šå‡çº¦20%ï¼ŒSSIMä¿æŒ>0.95ï¼Œæ˜¾ç¤ºæå¼ºé²æ£’æ€§ã€‚

#### ğŸ“Š **Scenario 3: ä¿®æ”¹é™æ€ç¯å¢ƒï¼ˆæ”¹å»ºç­‘+BSï¼‰**
| $R_{\text{reuse}}$ | NMSE | Time (ms) | Speedup |
|--------------------|-------|------------|----------|
| 0.70 | 0.00889 | 175 | ~3.4Ã— |
| 0.98 | 0.58418 | 11 | ~54Ã—ï¼ˆä½†ä¸¥é‡å¤±çœŸï¼‰|

> âš ï¸ é™æ€ç¯å¢ƒå¤§å˜æ—¶ï¼Œé«˜å¤ç”¨ç‡å¯¼è‡´â€œæƒ¯æ€§åå·®â€ï¼Œæ¨¡å‹éš¾çº æ­£åˆå§‹è¯­ä¹‰é”™è¯¯ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆä»¥Scenario 1ä¸ºä¾‹ï¼‰

| Method | NMSE â†“ | SSIM â†‘ | PSNR (dB) â†‘ | Time (ms) â†“ |
|--------|--------|--------|-------------|--------------|
| RME-GAN | 0.01150 | 0.9323 | 30.54 | 42 |
| UVM-Net | 0.00850 | 0.9320 | 30.34 | 95 |
| RadioUNet | 0.00740 | 0.9592 | 32.01 | 60 |
| RadioDiff | **0.00580** | **0.9647** | **34.67** | 600 |
| **RadioDiff-Flux ($R=0.98$)** | **0.02957** | **0.9458** | **27.53** | **~12** |
| â†’ **åŠ é€Ÿæ¯” â‰ˆ 50Ã—ï¼Œç²¾åº¦æŸå¤± < 0.15%** | | | | |

> å°½ç®¡ç»å¯¹NMSEä¸Šå‡ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ä»å¯æ¥å—ï¼Œä¸”é€Ÿåº¦ä¼˜åŠ¿å·¨å¤§ã€‚

---

### æ¶ˆèå®éªŒç»“æœ
- **ç¬¬ä¸€é˜¶æ®µæ¨¡å‹åˆå§‹åŒ–æ–¹å¼**ï¼šä»RadioDiffæƒé‡å¾®è°ƒï¼ˆçº¦10 epochï¼‰å³å¯ï¼ŒèŠ‚çœè®­ç»ƒæˆæœ¬ï¼ˆ12å°æ—¶ vs åŸå§‹480å°æ—¶ï¼‰ï¼›
- **ç¼“å­˜å¤§å°**ï¼šæ¯ä¸ªmidpointçº¦64KBï¼ˆfloat32ï¼‰ï¼ŒåŸå¸‚çº§æœåŠ¡æœ€å¤šç¼“å­˜100ä¸ªï¼Œæ€»<6.25MBï¼›
- **ç¯å¢ƒç›¸ä¼¼åº¦åˆ¤æ–­æœºåˆ¶**ï¼šé€šè¿‡cross-attentionç©ºé—´çš„Frobeniusè·ç¦» $D_{\text{env}}$ è‡ªåŠ¨è§¦å‘å¤ç”¨ï¼Œæ— éœ€é‡è®­ç»ƒã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ‰©æ•£è¿‡ç¨‹ä¸­çš„midpointå…·æœ‰å¼ºè¯­ä¹‰ç¨³å®šæ€§**ï¼šåŒä¸€å»ºç­‘å¸ƒå±€ä¸‹ä¸åŒBSä½ç½®çš„RMåœ¨æ½œç©ºé—´ä¸­è·¯å¾„é«˜åº¦ä¸€è‡´ï¼Œæ”¯æŒä¸­é—´çŠ¶æ€å¤ç”¨ã€‚
2. **RadioDiff-Fluxå¯åœ¨å‡ ä¹æ— æŸçš„æƒ…å†µä¸‹å®ç°é«˜è¾¾50Ã—çš„æ¨ç†åŠ é€Ÿ**ï¼Œç‰¹åˆ«é€‚ç”¨äºå°èŒƒå›´BSç§»åŠ¨æˆ–åŠ¨æ€éšœç¢ç‰©æ·»åŠ åœºæ™¯ã€‚
3. **ä¸¤é˜¶æ®µè®¾è®¡å®ç°äº†æ¨¡å—åŒ–ä¸é«˜æ•ˆæ€§ç»Ÿä¸€**ï¼šé™æ€éƒ¨åˆ†å¯ç¼“å­˜ï¼ŒåŠ¨æ€éƒ¨åˆ†è½»é‡æ›´æ–°ï¼Œç¬¦åˆ6Gç½‘ç»œæ•æ·å“åº”éœ€æ±‚ã€‚
4. **åœ¨åŠ¨æ€æ›´æ–°åœºæ™¯ï¼ˆå¦‚è½¦è½½é€šä¿¡ï¼‰ä¸­è¡¨ç°å°¤ä¸ºå‡ºè‰²**ï¼Œå³ä½¿å¤ç”¨98%æ­¥éª¤ä»ä¿æŒè‰¯å¥½å…¨å±€å‡†ç¡®æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å¯¹**å¤§è§„æ¨¡é™æ€ç¯å¢ƒå˜æ›´**ï¼ˆå¦‚æ‹†é™¤å»ºç­‘ï¼‰æ•æ„Ÿï¼Œé«˜å¤ç”¨ç‡ä¼šå¯¼è‡´â€œè¯­ä¹‰æƒ¯æ€§â€ï¼Œå¿…é¡»é™ä½ $R_{\text{reuse}}$ æˆ–é‡æ–°ç”Ÿæˆï¼›
- å½“å‰æ¨¡å‹é’ˆå¯¹å•BSè®¾è®¡ï¼Œå¤šBSéœ€åˆ†åˆ«å¤„ç†ï¼ˆå°½ç®¡å¯é€šè¿‡å…±äº«midpointåŠ é€Ÿï¼‰ï¼›
- ç¼ºä¹å¯¹è¿ç»­RMåºåˆ—çš„æ—¶é—´ä¸€è‡´æ€§æ˜¾å¼å»ºæ¨¡ï¼ˆæœªæ¥å¯ç»“åˆTemporal DMï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. è®¾è®¡**è‡ªé€‚åº” $R_{\text{reuse}}$ ç­–ç•¥**ï¼šæ ¹æ®ç¯å¢ƒå˜åŒ–ç¨‹åº¦è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜å¤ç”¨æ¯”ä¾‹ï¼›
2. æ‰©å±•è‡³**multi-BSè”åˆå»ºæ¨¡**ï¼Œå°†å¤šä¸ªBSä½ç½®ä½œä¸ºæ¡ä»¶è¾“å…¥ï¼Œç›´æ¥è¾“å‡ºå¤åˆRMï¼›
3. å¼•å…¥**temporal consistencyæœºåˆ¶**ï¼Œç”¨äºæ— äººæœºè½¨è¿¹ç­‰è¿ç»­RMç”Ÿæˆä»»åŠ¡ï¼›
4. æ¢ç´¢æ›´é«˜æ•ˆçš„latent compressionä¸cacheç®¡ç†ç­–ç•¥ï¼Œé€‚é…è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ã€‚

---

> âœ… **æ€»ä½“è¯„ä»·**ï¼šRadioDiff-Fluxé€šè¿‡æ´å¯Ÿæ‰©æ•£æ¨¡å‹å†…éƒ¨ç»“æ„ç‰¹æ€§ï¼Œæå‡ºäº†ä¸€ç§æå…·å®ç”¨ä»·å€¼çš„åŠ é€ŸèŒƒå¼ï¼Œä¸º6Gç¯å¢ƒä¸­å®æ—¶ã€å¯æ‰©å±•çš„Radio Mapç”Ÿæˆæä¾›äº†å¯è¡Œè§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 6. [MixTTE: Multi-Level Mixture-of-Experts for Scalable and Adaptive Travel Time Estimation](https://arxiv.org/abs/2601.02943)

**Authors**: Wenzhao Jiang, Jindong Han, Ruiqian Han, Hao Liu  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.02943v1  

#### Abstract
Accurate Travel Time Estimation (TTE) is critical for ride-hailing platforms, where errors directly impact user experience and operational efficiency. While existing production systems excel at holistic route-level dependency modeling, they struggle to capture city-scale traffic dynamics and long-ta...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MixTTE: Multi-Level Mixture-of-Experts for Scalable and Adaptive Travel Time Estimation â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å·¥ä¸šçº§ **Travel Time Estimation (TTE)** ç³»ç»Ÿï¼ˆå¦‚ DiDi çš„ WDR æ¶æ„ï¼‰è™½ç„¶åœ¨å¸¸è§„åœºæ™¯ä¸‹è¡¨ç°è‰¯å¥½ï¼Œä½†ä»å­˜åœ¨ä¸¤å¤§ç“¶é¢ˆï¼š
- **æœ‰é™çš„æ„Ÿå—é‡**ï¼ˆLimited Reception Fieldï¼‰ï¼šä»…å»ºæ¨¡è·¯çº¿å†…éƒ¨ä¾èµ–ï¼Œéš¾ä»¥æ•æ‰åŸå¸‚å°ºåº¦çš„å…¨å±€äº¤é€šåŠ¨æ€ï¼ˆå¦‚å‘¨è¾¹æ‹¥å µæ‰©æ•£ï¼‰ã€‚
- **é•¿å°¾åœºæ™¯æ€§èƒ½å·®**ï¼ˆLong-tail Underperformanceï¼‰ï¼šå¯¹ç½•è§ä½†å…³é”®çš„äº¤é€šæ¨¡å¼ï¼ˆå¦‚å¤§å‹æ´»åŠ¨ã€æ–½å·¥å°è·¯ï¼‰é¢„æµ‹ä¸å‡†ã€‚

æ­¤å¤–ï¼Œå°† link-level æ¨¡å‹é›†æˆåˆ° route-centric ç³»ç»Ÿé¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
1. **å¯æ‰©å±•æ€§å·®**ï¼šç™¾ä¸‡çº§é“è·¯ç½‘ç»œä¸­å»ºæ¨¡å…¨å±€æ—¶ç©ºä¾èµ–è®¡ç®—å¼€é”€å¤§ã€‚
2. **å¼‚è´¨æ€§å¤„ç†éš¾**ï¼šäº¤é€šæ¨¡å¼é«˜åº¦å¤šæ ·åŒ–ï¼Œå•ä¸€æ¨¡å‹éš¾ä»¥å…¼é¡¾å¤´éƒ¨ä¸å°¾éƒ¨åœºæ™¯ã€‚
3. **åŠ¨æ€é€‚åº”æˆæœ¬é«˜**ï¼šé¢‘ç¹æ›´æ–°æ¨¡å‹æ˜“å¯¼è‡´è¿‡æ‹Ÿåˆæˆ–è®¡ç®—ä¸å¯æŒç»­ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

ä½œè€…æå‡º **MIxTTE**ï¼Œä¸€ä¸ª**å¯æ‰©å±•ä¸”è‡ªé€‚åº”çš„å¤šå±‚çº§æ··åˆä¸“å®¶æ¡†æ¶**ï¼Œå®ç° link-level ä¸ route-level æ¨¡å‹çš„ååŒå¢å¼ºï¼Œæ— éœ€é‡æ„ç°æœ‰ç³»ç»Ÿå³å¯æ’ä»¶å¼éƒ¨ç½²ã€‚

#### ä¸»è¦åˆ›æ–°æ¨¡å—ï¼š

| åˆ›æ–°æ¨¡å— | åŠŸèƒ½ä¸ä¼˜åŠ¿ |
|--------|----------|
| **Spatio-Temporal External Attention (STEA)** | å¼•å…¥å¤–éƒ¨è®°å¿†å•å…ƒï¼ˆexternal memoryï¼‰ï¼Œé€šè¿‡ cross-attention é«˜æ•ˆæ•è·ç™¾ä¸‡çº§è·¯ç½‘ä¸­çš„**è·¨æ—¶ç©ºä¾èµ–**ï¼Œå¤æ‚åº¦ä» $O(N^2)$ é™è‡³ $O(N \cdot U_{ex})$ï¼Œæ˜¾è‘—æå‡æ•ˆç‡ã€‚æ”¯æŒåˆ†å±‚å»ºæ¨¡ä»¥å¼ºåŒ–åŒæ—¶é—´æ­¥çš„ç©ºé—´ç›¸å…³æ€§ã€‚ |
| **Externally Stabilized Graph Mixture-of-Experts (ESGMoE)** | è®¾è®¡å›¾ç»“æ„ MoE å±‚ï¼Œç»“åˆ**å¤–éƒ¨çŸ¥è¯†å¼•å¯¼çš„åˆ†å±‚è·¯ç”±æœºåˆ¶**ï¼ˆHierarchical Routing with External Guidanceï¼‰å’Œ**é›¶è®¡ç®—ä¸“å®¶**ï¼ˆZero-computation Expertsï¼‰ï¼Œæœ‰æ•ˆåº”å¯¹å¼‚è´¨äº¤é€šæ¨¡å¼ã€‚ç¨€ç–æ¿€æ´»ä¿éšœæ¨ç†æ•ˆç‡ï¼ŒåŒæ—¶æå‡é•¿å°¾æ³›åŒ–èƒ½åŠ›ã€‚ |
| **Asynchronous Incremental Learning (ASIL)** | æå‡ºè‡ªé€‚åº”å¼‚æ­¥å¢é‡å­¦ä¹ ç­–ç•¥ï¼ŒåŸºäº **Mahalanobis Distance** æ£€æµ‹å‘¨æœŸæ€§åˆ†å¸ƒåç§»ï¼Œä»…å½“å¼‚å¸¸é“¾è·¯æ¯”ä¾‹è¶…è¿‡é˜ˆå€¼æ—¶è§¦å‘å‚æ•°æ›´æ–°ã€‚æ”¯æŒ**é“¾è·¯çº§ä¸è·¯çº¿çº§å‚æ•°è§£è€¦æ›´æ–°**ï¼Œé™ä½è®­ç»ƒæˆæœ¬å¹¶é˜²æ­¢ç¾éš¾æ€§é—å¿˜ã€‚ |

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

- âœ… **æ— ç¼é›†æˆ**ï¼šä¸æ”¹å˜ DiDi ç°æœ‰ route-centric æ•°æ®æµä¸æ¨¡å‹æ¶æ„ï¼Œæ”¯æŒå¹³æ»‘å‡çº§ã€‚
- âœ… **é«˜æ•ˆå…¨å±€å»ºæ¨¡**ï¼šSTEA åœ¨ä¿æŒçº¿æ€§å¤æ‚åº¦çš„åŒæ—¶å®ç°è·¨åŸåŸŸäº¤é€šä¼ æ’­å»ºæ¨¡ã€‚
- âœ… **ç¨³å®š MoE è®­ç»ƒ**ï¼šé€šè¿‡å¤–éƒ¨çŸ¥è¯†å¢å¼ºè·¯ç”±å†³ç­–ï¼Œç¼“è§£ä¸“å®¶åå¡Œï¼ˆexpert collapseï¼‰é—®é¢˜ã€‚
- âœ… **çœŸå®ä¸–ç•Œé€‚ç”¨æ€§å¼º**ï¼šASIL æ”¯æŒé«˜é¢‘ã€ä½æˆæœ¬åœ¨çº¿æ›´æ–°ï¼Œé€‚åˆå¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ä¸‰ä¸ªä¸­å›½å¤§åŸå¸‚çš„çœŸå®å‡ºè¡Œæ•°æ®é›†ä¸Šè¿›è¡ŒéªŒè¯ï¼š

| åŸå¸‚ | æ—¶é—´è·¨åº¦ | Trip æ•°é‡ | å¹³å‡è¡Œç¨‹æ—¶é•¿ | è·¯æ®µæ•°ï¼ˆLinksï¼‰ | çƒ­é—¨è·¯æ®µæ•°ï¼ˆHot Linksï¼‰ |
|------|---------|-----------|---------------|----------------|------------------------|
| åŒ—äº¬ | 2024-07 ~ 2024-09 | 22.28M | 18.11 min | 2.32M | 156.7K |
| å—äº¬ | 2024-12 ~ 2025-02 | 7.95M | 13.79 min | 696.1K | 83.3K |
| è‹å· | 2025-01 ~ 2025-04 | 16.78M | 13.63 min | 1.42M | 149.2K |

> æ³¨ï¼šâ€œçƒ­é—¨è·¯æ®µâ€æŒ‡æµé‡å¤§ã€åŠ¨æ€æ€§å¼ºçš„å…³é”®é“è·¯ï¼Œç”¨äºç”Ÿæˆ link embeddingã€‚

---

### å®éªŒè®¾ç½®

- **è®­ç»ƒæ–¹å¼**ï¼š
  - **å…¨é‡é‡è®­**ï¼ˆFull Retrainingï¼‰ï¼šä½¿ç”¨å‰110å¤©æ•°æ®è®­ç»ƒï¼Œæœ€å7å¤©æµ‹è¯•ã€‚
  - **å¢é‡å­¦ä¹ **ï¼ˆIncremental Learning, ILï¼‰ï¼šæ¯å°æ—¶ç”¨æœ€æ–°å®Œæˆ trip æ•°æ®å¾®è°ƒï¼Œé¢„æµ‹ä¸‹ä¸€å°æ—¶å‡ºå‘ tripï¼Œæ›´è´´è¿‘å®é™…ä¸šåŠ¡éœ€æ±‚ã€‚
- **æ‰¹é‡‡æ ·ç­–ç•¥**ï¼šé‡‡ç”¨ **time-specific batch sampling**ï¼ŒåŒä¸€ batch å†… trip å‡ºå‘æ—¶é—´ä¸€è‡´ï¼Œåˆ©äºå…±äº« link è¡¨ç¤ºè®¡ç®—ï¼Œæå‡è®­ç»ƒæ•ˆç‡ã€‚

---

### è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **MAE**ï¼ˆMean Absolute Errorï¼‰ | é¢„æµ‹ä¸çœŸå®æ—…è¡Œæ—¶é—´çš„å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆç§’ï¼‰ |
| **MAPE**ï¼ˆMean Absolute Percentage Errorï¼‰ | å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® |
| **BCR**ï¼ˆBad Case Ratioï¼‰ | MAE > 300 ç§’ä¸” MAPE > 20% çš„æŸ¥è¯¢å æ¯” |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

#### å…¨é‡è®­ç»ƒåŸºçº¿ï¼š
1. **Rule-based**: RouteETAï¼ˆå†å²å¹³å‡åŠ æ€»ï¼‰
2. **Route-centric**: HierETA, WDRï¼ˆDiDi å½“å‰ç”Ÿäº§æ¨¡å‹ï¼‰
3. **Link-centric**: CompactETA, ConSTGAT, BigST

#### å¢é‡å­¦ä¹ åŸºçº¿ï¼š
- **iETA**ï¼šDiDi ç°æœ‰çš„å¢é‡å­¦ä¹ æ¡†æ¶

æ‰€æœ‰æ–¹æ³•ç»Ÿä¸€è¾“å…¥ç‰¹å¾ï¼Œå¹¶å…¬å¹³æ¯”è¾ƒæ¨ç†è´Ÿè½½ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ•´ä½“æ€§èƒ½å¯¹æ¯”ï¼ˆTable 2ï¼‰

| æ–¹æ³• | åŒ—äº¬ MAEâ†“ | å—äº¬ MAEâ†“ | è‹å· MAEâ†“ | ç»¼åˆç›¸å¯¹æå‡ |
|------|----------|----------|----------|-------------|
| WDRï¼ˆå½“å‰ç³»ç»Ÿï¼‰ | 134.02 | 77.29 | 78.60 | â€” |
| iETAï¼ˆå¢é‡ç‰ˆ WDRï¼‰ | 132.73 | 77.10 | 78.22 | +1.0% ~ +1.5% |
| **MIxTTE**ï¼ˆæœ¬æ–‡ï¼‰ | **130.84** | **75.26** | **77.18** | **â†‘2.39% MAE**, **â†‘3.70% MAPE**, **â†‘10.32% BCR** |

> âœ… MIxTTE åœ¨æ‰€æœ‰åŸå¸‚ã€æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚

---

### é•¿å°¾åœºæ™¯æ€§èƒ½åˆ†æï¼ˆRQ2ï¼‰

- å°†è‹å·æµ‹è¯•é›†æŒ‰ä»¥ä¸‹ä¸‰ä¸ªç»´åº¦äº”ç­‰åˆ†ï¼š
  - Trip Durationï¼ˆè¡Œç¨‹é•¿åº¦ï¼‰
  - Condition Deviation Degreeï¼ˆè·¯å†µåç¦»å†å²ç¨‹åº¦ï¼‰
  - Non-Recurrence Degreeï¼ˆéé‡å¤æ€§ï¼‰
- ç»“æœæ˜¾ç¤ºï¼š**MIxTTE çš„ MAE æ”¹å–„å¹…åº¦éšæ ·æœ¬ä»â€œå¤´éƒ¨â€å‘â€œå°¾éƒ¨â€é€’å¢**ï¼ˆè§ Figure 3ï¼‰ï¼Œè¯´æ˜å…¶åœ¨ç½•è§ã€å¤æ‚åœºæ™¯ä¸‹æ›´å…·é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

---

### æ•ˆç‡åˆ†æï¼ˆRQ3ï¼‰

| æ¨¡å‹ | åŒ—äº¬è®­ç»ƒååï¼ˆK/minï¼‰ | æ¨ç†å»¶è¿Ÿï¼ˆms/stepï¼‰ |
|------|------------------------|--------------------|
| CompactETA | 14.96 | 541.27 |
| ConSTGAT | 10.51 | 704.11 |
| BigST | 22.45 | 78.30 |
| **MIxTTE-WoIL** | **21.17** | **88.97** |

> âš¡ MIxTTE åœ¨è®­ç»ƒååä¸Šæ¥è¿‘ BigSTï¼Œåœ¨æ¨ç†å»¶è¿Ÿä¸Šç•¥é«˜ä½†ä»è¿œä¼˜äºä¼ ç»Ÿ GNN æ–¹æ³•ã€‚

#### å¢é‡å­¦ä¹ æ•ˆç‡ï¼ˆTable 4ï¼‰
| æ¨¡å‹ | å¹³å‡è®­ç»ƒæ—¶é—´ï¼ˆç§’/æ­¥ï¼‰ | å¯è®­ç»ƒå‚æ•°æ•°ï¼ˆK/æ­¥ï¼‰ |
|------|------------------------|-----------------------|
| MIxTTE-WoPUï¼ˆæ— é€‰æ‹©æ€§æ›´æ–°ï¼‰ | 36.63 | 525.66 |
| **MIxTTEï¼ˆASILï¼‰** | **7.81** | **47.49** |

> ğŸ” ASIL ç­–ç•¥å‡å°‘çº¦ **80% è®­ç»ƒæ—¶é—´** å’Œ **91% å‚æ•°æ›´æ–°é‡**ï¼Œæå¤§æå‡åœ¨çº¿é€‚åº”æ•ˆç‡ã€‚

---

### æ¶ˆèå®éªŒï¼ˆAblation Study, Figure 4ï¼‰

æ¶ˆèé¡¹åŒ…æ‹¬ï¼š
- `-WoEA`ï¼šç§»é™¤ STEA ä¸åˆ†å±‚è·¯ç”±
- `-WoHR`ï¼šä»…ç§»é™¤åˆ†å±‚è·¯ç”±
- `-WoMoE`ï¼šç§»é™¤ ESGMoE
- `-WoZE`ï¼šç§»é™¤é›¶è®¡ç®—ä¸“å®¶
- `-WoPU`ï¼šç§»é™¤å‚æ•°é€‰æ‹©æ€§æ›´æ–°

#### å‘ç°ï¼š
- **STEA è‡³å…³é‡è¦**ï¼šæä¾›å…¨å±€ä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼Œå°¤å…¶åœ¨å¼‚è´¨æ€§å¼ºçš„åŸå¸‚ï¼ˆå¦‚è‹å·ï¼‰å½±å“æ›´å¤§ã€‚
- **åˆ†å±‚è·¯ç”±æå‡ç¨³å®šæ€§**ï¼šåˆ©ç”¨å¤–éƒ¨çŸ¥è¯†æŒ‡å¯¼è·¯ç”±ï¼Œé¿å…ä¸“å®¶æ··ä¹±ã€‚
- **é›¶è®¡ç®—ä¸“å®¶æœ‰æ•ˆç¼“è§£é•¿å°¾å‹åŠ›**ï¼šç‰¹åˆ«æ˜¯åœ¨å—äº¬æ•°æ®é›†ä¸­æ˜¾è‘—é™ä½ BCRã€‚
- **ASIL æ˜¾è‘—æå‡ IL ç¨³å®šæ€§**ï¼šè¯æ˜äº†è§£è€¦æ›´æ–°æœºåˆ¶çš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **link-level modeling èƒ½æœ‰æ•ˆè¡¥å…… route-centric ç³»ç»Ÿçš„çŸ­æ¿**ï¼Œå°¤å…¶æ˜¯åœ¨å»ºæ¨¡å…¨å±€äº¤é€šä¼ æ’­å’Œé•¿å°¾åœºæ™¯æ–¹é¢ã€‚
2. **STEA å®ç°äº†é«˜æ•ˆçš„å¤§è§„æ¨¡æ—¶ç©ºä¾èµ–å»ºæ¨¡**ï¼Œè§£å†³äº†ä¼ ç»Ÿ pairwise GNN æ–¹æ³•æ— æ³•æ‰©å±•çš„é—®é¢˜ã€‚
3. **ESGMoE é€šè¿‡ç¨€ç–æ¿€æ´»ä¸é›¶è®¡ç®—ä¸“å®¶è®¾è®¡ï¼Œåœ¨ä¸å¢åŠ æ¨ç†è´Ÿæ‹…çš„å‰æä¸‹æå‡äº†æ¨¡å‹å®¹é‡ä¸å¤šæ ·æ€§è¡¨è¾¾èƒ½åŠ›**ã€‚
4. **ASIL å®ç°äº†é«˜é¢‘ç‡ã€ä½å¼€é”€ã€ç¨³å®šçš„åœ¨çº¿æ›´æ–°æœºåˆ¶**ï¼Œæ˜¯å·¥ä¸šç³»ç»Ÿå¯æŒç»­æ¼”è¿›çš„å…³é”®ã€‚
5. **MIxTTE å·²æˆåŠŸéƒ¨ç½²äº DiDi ç”Ÿäº§ç¯å¢ƒ**ï¼Œå¸¦æ¥ **3.03% ~ 1.24% MAE ä¸‹é™** å’Œ **4.41% ~ 4.30% BCR æ”¹å–„**ï¼ŒèŠ‚å‡æ—¥æ”¶ç›Šæ›´æ˜æ˜¾ï¼ˆFigure 6ï¼‰ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡â€œçƒ­è·¯æ®µâ€å®šä¹‰**ï¼šéœ€å®šæœŸç­›é€‰æ´»è·ƒ linkï¼Œå¦åˆ™å¯èƒ½é—æ¼æ–°å…´æ‹¥å µåŒºåŸŸã€‚
- **å¤–éƒ¨è®°å¿†å•å…ƒéœ€è°ƒå‚**ï¼šå¦‚ $U_{ex}$ å¤§å°å½±å“æ€§èƒ½ä¸è¿‡æ‹Ÿåˆé£é™©ï¼ˆè§ Figure 7ï¼‰ã€‚
- **å°šæœªå®Œå…¨é‡Šæ”¾ link-level æ½œåŠ›**ï¼šç›®å‰ä»ä½œä¸º route-centric æ¨¡å‹çš„å¢å¼ºæ¨¡å—ï¼Œæœªæ„å»ºç«¯åˆ°ç«¯è”åˆä¼˜åŒ–æ¡†æ¶ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆFuture Workï¼‰
1. **å¤šæ¨¡æ€èåˆ**ï¼šå¼•å…¥å¤©æ°”ã€äº‹ä»¶ã€ç¤¾äº¤åª’ä½“ç­‰å¤–éƒ¨ä¿¡å·ï¼Œç¼“è§£åŸå¸‚æ„ŸçŸ¥ä¸å®Œæ•´é—®é¢˜ã€‚
2. **è·¨åŸå¸‚è¿ç§»å­¦ä¹ **ï¼šåˆ©ç”¨å¤–éƒ¨è®°å¿†ä¸ MoE æŠ½è±¡é€šç”¨äº¤é€šçŸ¥è¯†ï¼Œé™ä½æ–°åŸå¸‚å†·å¯åŠ¨æˆæœ¬ã€‚
3. **è½»é‡åŒ–è’¸é¦**ï¼šæ¢ç´¢å°†å¤§è§„æ¨¡ MixTTE è’¸é¦ä¸ºå°å‹æ¨¡å‹ï¼Œä¾¿äºè¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> MIxTTE é€šè¿‡ **STEA + ESGMoE + ASIL** ä¸‰ä½ä¸€ä½“è®¾è®¡ï¼Œåœ¨ä¸æ”¹é€ ç°æœ‰ç³»ç»Ÿçš„å‰æä¸‹ï¼Œå®ç°äº†**å¯æ‰©å±•ã€å¼ºé²æ£’ã€æ˜“ç»´æŠ¤**çš„ä¸‹ä¸€ä»£ TTE æ¡†æ¶ï¼Œå·²åœ¨ DiDi æˆåŠŸè½åœ°ï¼Œå…·æœ‰å¹¿æ³›å·¥ä¸šåº”ç”¨å‰æ™¯ã€‚

</details>

---

### 7. [Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios](https://arxiv.org/abs/2601.01857)

**Authors**: Defei Xia, Bingfeng Pi, Shenbin Zhang, Song Hua, Yunfei Wei, Lei Zuo  
**Category**: cs.AI  
**Published**: 2026-01-07  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.01857v1  

#### Abstract
As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based ag...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šJenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªä¸»ä»£ç†ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **å›ºå®šæç¤ºï¼ˆpromptï¼‰å¯¼è‡´æ„å›¾ç†è§£åå·®**ï¼šé™æ€æˆ–é€šç”¨çš„ prompt éš¾ä»¥é€‚åº”ä»»åŠ¡çŠ¶æ€å˜åŒ–ï¼Œé€ æˆè¾“å‡ºä¸ç¨³å®šã€‚
- **å·¥å…·è°ƒç”¨æ•ˆç‡ä½ä¸‹**ï¼šé¢„å®šä¹‰å·¥å…·åˆ—è¡¨æˆ–è§„åˆ™æ— æ³•åŠ¨æ€é€‰æ‹©åˆé€‚å·¥å…·ï¼Œæ˜“äº§ç”Ÿå†—ä½™æˆ–é”™è¯¯è°ƒç”¨ã€‚
- **ä¸Šä¸‹æ–‡è†¨èƒ€ä¸è®°å¿†ç®¡ç†ä½æ•ˆ**ï¼šé•¿å¯¹è¯ç§¯ç´¯å¤§é‡å†—ä½™å†å²ï¼Œå¢åŠ  token æˆæœ¬å¹¶ç¨€é‡Šå…³é”®è¯­ä¹‰ï¼Œå½±å“æ¨ç†è´¨é‡ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†ä»£ç†åœ¨å¤æ‚ã€å¤šè½®ã€çœŸå®åœºæ™¯ä¸­çš„å‡†ç¡®æ€§ã€ç¨³å®šæ€§å’Œå¯æ‰©å±•æ€§ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹**
æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸º **Jenius-Agent** çš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œå›´ç»•â€œç»éªŒé©±åŠ¨â€çš„ä¼˜åŒ–ç†å¿µï¼Œå¼•å…¥ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼š

#### **(1) è‡ªé€‚åº”æç¤ºç”Ÿæˆï¼ˆAdaptive Prompt Generationï¼‰**
- åŠ¨æ€èåˆè§’è‰²æŒ‡ä»¤ã€ä»»åŠ¡çŠ¶æ€å’Œç”¨æˆ·ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆä¸å½“å‰æƒ…å¢ƒåŒ¹é…çš„ç³»ç»Ÿ promptã€‚
- å¼•å…¥å››ç±»ç”¨æˆ·æ„å›¾åˆ†ç±»ï¼ˆç¤¾äº¤äº¤äº’ã€åˆ›æ„ç”Ÿæˆã€äº‹å®å›å¿†ã€å·¥å…·å¢å¼ºæ¨ç†ï¼‰ï¼Œå®ç°ç²¾ç»†åŒ–å“åº”ç­–ç•¥å®šåˆ¶ã€‚
- åŒ…å«å®‰å…¨æœºåˆ¶ï¼ˆå¦‚é˜²æ­¢å¹»è§‰ã€å‚æ•°éªŒè¯ï¼‰å’Œè¾“å‡ºæ ¼å¼æ§åˆ¶ï¼Œæå‡å¯é æ€§å’Œå¯æ§æ€§ã€‚

#### **(2) ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å·¥å…·ç¼–æ’ï¼ˆContext-Aware Tool Orchestrationï¼‰**
- æ„å»ºåŸºäº **Model Context Protocol (MCP)** çš„æ ‡å‡†åŒ–å·¥å…·ç®¡ç†ä½“ç³»ã€‚
- ä½¿ç”¨ **Qwen3 Embedding** å¯¹å·¥å…·è¿›è¡Œå‘é‡åŒ–è¡¨ç¤ºï¼Œé€šè¿‡è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢å€™é€‰å·¥å…·ã€‚
- æå‡ºä¸‰æ­¥ç­›é€‰æœºåˆ¶ï¼š
  1. Top-M ç›¸ä¼¼åº¦æ’åº
  2. åŸºäºâ€œæ‹ç‚¹æ£€æµ‹â€ï¼ˆinflection pointï¼‰çš„è¿‡æ»¤ï¼ˆç»“åˆ similarity-jump å’Œ kneedle ç®—æ³•ï¼‰
  3. åŠ¨æ€æˆªæ–­ä¿ç•™æœ€ä¼˜å­é›†ï¼ˆé»˜è®¤ N=10ï¼‰
- å®ç°é«˜ç²¾åº¦ã€ä½å™ªå£°çš„å·¥å…·æ¨èï¼Œæ”¯æŒè·¨é¢†åŸŸæ¨¡ç³Šè¯·æ±‚å¤„ç†ã€‚

#### **(3) åˆ†å±‚è®°å¿†ç®¡ç†ï¼ˆHierarchical Memory Managementï¼‰**
- **å¯¹è¯çº§å¯¹é½**ï¼šç»´æŠ¤ `Human â†’ AI â†’ Tool â†’ AI` çš„æ ‡å‡†äº¤äº’åºåˆ—ï¼Œä¿®å¤å› å¤±è´¥è°ƒç”¨å¯¼è‡´çš„æ¶ˆæ¯ç¼ºå¤±ã€‚
- **ä¼šè¯çº§å‹ç¼©**ï¼šå½“æ¶ˆæ¯æ•°è¶…è¿‡é˜ˆå€¼ K æ—¶ï¼Œå°†æ—©æœŸå†å²é€’å½’æ€»ç»“ä¸º `SystemMessage` å­˜å‚¨ï¼Œå¹¶ä¿ç•™åœ¨è¾“å…¥åºåˆ—å‰ç«¯ï¼Œç¡®ä¿é•¿æœŸä¸Šä¸‹æ–‡è¿è´¯æ€§ã€‚
- æ”¯æŒåŠ¨æ€æ‘˜è¦ä¸å›å¡«ï¼ˆbackfillingï¼‰ï¼Œå‡å°‘ token å ç”¨åŒæ—¶ä¿ç•™å…³é”®è¯­ä¹‰ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ç°æœ‰æ–¹æ³•å±€é™ | Jenius-Agent æ”¹è¿› |
|------|--------------|------------------|
| **Prompt è®¾è®¡** | å›ºå®šæ¨¡æ¿ï¼Œç¼ºä¹ä¸Šä¸‹æ–‡é€‚é… | åŠ¨æ€ç”Ÿæˆï¼ŒåŸºäºæ„å›¾åˆ†ç±»ä¸å†å²æ„ŸçŸ¥ |
| **Tool Selection** | æ‰‹åŠ¨é…ç½®æˆ–ç®€å•æ£€ç´¢ | è¯­ä¹‰æ£€ç´¢ + åŒé‡æ‹ç‚¹è¿‡æ»¤ï¼ŒæŠ—å™ªå£°èƒ½åŠ›å¼º |
| **Memory ç®¡ç†** | æ»‘çª—æˆªæ–­æˆ–ç²—ç²’åº¦æ‘˜è¦ | ç»“æ„åŒ–å¯¹é½ + å±‚æ¬¡åŒ–å‹ç¼©ï¼Œä¿æŒæ¨ç†è¿ç»­æ€§ |
| **åè®®å…¼å®¹æ€§** | å¤šæ ·å¼‚æ„æ¥å£ | æ”¯æŒ MCPã€ACPã€A2A ç­‰æ–°å…´é€šä¿¡åè®® |
| **éƒ¨ç½²å®ç”¨æ€§** | å­¦æœ¯å¯¼å‘ï¼Œéš¾è½åœ° | å·²ä¸Šçº¿ç”Ÿäº§ç¯å¢ƒï¼ˆ[jenius.cn](https://www.jenius.cn)ï¼‰ï¼Œè½»é‡å¯æ‰©å±• |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**

#### **(1) APIGenï¼ˆå…¬å¼€åŸºå‡†ï¼‰**
- è§„æ¨¡ï¼š60K æ ·æœ¬ï¼Œè¦†ç›– 21 ç±» API è°ƒç”¨ä»»åŠ¡
- ç‰¹ç‚¹ï¼šå•è½®äº¤äº’ï¼Œä»…å…³æ³¨å‡½æ•°è°ƒç”¨å‡†ç¡®æ€§
- æœ¬æ–‡æ”¹è¿›ï¼šæ¯æ¡æŸ¥è¯¢æ³¨å…¥ 100 ä¸ªæ— å…³å·¥å…·ï¼Œæ¨¡æ‹Ÿé«˜å™ªå£°ç¯å¢ƒï¼Œæµ‹è¯•å·¥å…·æ£€ç´¢é²æ£’æ€§

#### **(2) Jenius-benchï¼ˆæ–°æ„å»ºçš„çœŸå®ä¸–ç•Œæ•°æ®é›†ï¼‰**
- è§„æ¨¡ï¼š850 æ¡é«˜è´¨é‡äººå·¥æ ‡æ³¨æ ·æœ¬ï¼Œæ¶µç›– 38 ç±»å·¥å…·
- åœºæ™¯ï¼šæ—…è¡Œè§„åˆ’ã€ç¥¨åŠ¡é¢„è®¢ã€å¤©æ°”æŸ¥è¯¢ã€ç½‘é¡µç”Ÿæˆã€è®ºæ–‡æ£€ç´¢ç­‰
- ç‰¹ç‚¹ï¼š
  - å¤šè½®å¯¹è¯ï¼Œæ”¯æŒçŠ¶æ€æ¼”åŒ–
  - åŒ…å«å®Œæ•´æ‰§è¡Œè½¨è¿¹ï¼ˆtool call, args, output, responseï¼‰
  - å·¥å…·é™„å¸¦ä¸°å¯Œè¯­ä¹‰æè¿°ï¼ˆç›®çš„ã€å‰æã€ç¤ºä¾‹ï¼‰
  - ç»ä¸“å®¶å®¡æ ¸ï¼Œä¿è¯çœŸå®æ€§ä¸ä¸€è‡´æ€§

> âœ… è¡¨æ ¼å¯¹æ¯”è§åŸæ–‡ Table 1ï¼Œçªå‡º Jenius-bench åœ¨ realismã€memoryã€cross-turn reasoning æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°æ¡†æ¶ä¸‰å¤§ç»´åº¦**
| ç»´åº¦ | æŒ‡æ ‡ä½“ç³» | å†…å®¹ |
|------|--------|------|
| **è¿‡ç¨‹ä¿çœŸåº¦ï¼ˆProcedural Fidelityï¼‰** | **4T Metrics** | TCR, TFR, TIR, TPS |
| **è¾“å‡ºè´¨é‡ï¼ˆOutput Qualityï¼‰** | **CRCFF Metrics** | Correctness, Relevance, Completeness, Fluency, Faithfulness |
| **æ•ˆç‡ï¼ˆEfficiencyï¼‰** | **Token Consumption** | è¾“å…¥/è¾“å‡º token æ€»é‡ |

##### **4T Metrics å®šä¹‰**
- **TCR (Task Completion Rate)**ï¼šæ­£ç¡®å®Œæˆæ‰€æœ‰æ­¥éª¤çš„æ¯”ä¾‹
- **TFR (Task Failure Rate)**ï¼šå®Œå…¨æ— æ„ä¹‰æ‰§è¡Œï¼ˆç©ºè°ƒç”¨æˆ–æŠ¥é”™ï¼‰
- **TIR (Task Incompletion Rate)**ï¼šéƒ¨åˆ†å®Œæˆä½†é¡ºåº/å·¥å…·é”™è¯¯
- **TPS (Task Performance Score)**ï¼šç»¼åˆè€ƒè™‘æ­£ç¡®ã€é”™è¯¯ã€é—æ¼å·¥å…·çš„åŠ æƒå¾—åˆ†

##### **CRCFF Metrics**
ç”± Qwen å’Œ DeepSeek ç­‰ LLM ä½œä¸º evaluator æ‰“åˆ†ï¼ˆ0â€“10 åˆ†åˆ¶ï¼‰ï¼Œè¯„ä¼°å“åº”è¯­ä¹‰è´¨é‡ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆAblation Studyï¼‰**

| æ¨¡å‹é…ç½® | æè¿° |
|---------|------|
| **Base** | æ ‡å‡† ReAct æ¡†æ¶ï¼ˆobserve-think-act å¾ªç¯ï¼‰ |
| **B-P** | Base + Adaptive Prompt Generation |
| **B-PT** | B-P + Context-Aware Tool Orchestration |
| **Jenius** | B-PT + Hierarchical Memory Managementï¼ˆå®Œæ•´ç‰ˆï¼‰ |

æ‰€æœ‰æ¨¡å‹å…±äº«ç›¸åŒ backbone å’Œ inference protocolï¼Œä»…æ¨¡å—å¢é‡æ·»åŠ ï¼Œä¾¿äºå½’å› åˆ†æã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **(1) è¿‡ç¨‹ä¿çœŸåº¦ï¼ˆ4T æµ‹è¯•ç»“æœï¼‰**

#### **åœ¨ APIGen ä¸Šçš„ç»“æœï¼ˆTable 2ï¼‰**
| Model | TCR | TFR | TIR | TPS |
|-------|-----|-----|-----|-----|
| Base | 0.8150 | 0.1800 | 0.0050 | 0.8150 |
| Jenius | **0.8500** | **0.1362** | 0.0138 | **0.8500** |

ğŸ‘‰ æå‡æœ‰é™ï¼Œè¯´æ˜è¯¥æ•°æ®é›†åå‘æ¨¡å¼åŒ¹é…ï¼Œéš¾ä»¥ä½“ç°å¤æ‚æ¨ç†ä¼˜åŠ¿ã€‚

#### **åœ¨ Jenius-bench ä¸Šçš„ç»“æœï¼ˆTable 3ï¼‰**
| Model | TCR | TFR | TIR | TPS |
|-------|-----|-----|-----|-----|
| Base | 0.5659 | 0.0329 | 0.4012 | 0.5968 |
| B-P | **0.7271 (+28.5%)** | 0.0859 | 0.1871 | 0.7491 |
| B-PT | 0.7494 | 0.0718 | 0.1788 | 0.7740 |
| **Jenius** | **0.7647 (+35%)** | **0.0753** | **0.1600** | **0.7847** |

âœ… **å…³é”®å‘ç°**ï¼š
- è‡ªé€‚åº” prompt è´¡çŒ®æœ€å¤§ï¼ˆTCR â†‘28.5%ï¼‰
- å·¥å…·ç¼–æ’è¿›ä¸€æ­¥æå‡ç²¾åº¦
- å®Œæ•´ç³»ç»Ÿå®ç° **è¿‘ 20% çš„ä»»åŠ¡å‡†ç¡®ç‡æå‡**

---

### **(2) è¾“å‡ºè´¨é‡ï¼ˆCRCFF æŒ‡æ ‡ï¼ŒTable 4ï¼‰**

| Model | Correctness (â†‘) | Relevance | Completeness | Fluency | Faithfulness |
|-------|------------------|-----------|--------------|---------|-------------|
| Base | 0.6741 (Qwen) / 0.7890 (DeepSeek) | ~0.89â€“0.92 | ~0.77â€“0.79 | ~0.93â€“0.95 | ~0.79â€“0.83 |
| **Jenius** | **0.7580 / 0.8350** | **0.9447 / 0.9400** | **0.8088 / 0.8143** | **0.9771 / 0.9686** | **0.8766 / 0.8636** |

ğŸ“Œ **æå‡å¹…åº¦**ï¼š
- æ­£ç¡®æ€§ â†‘ **8â€“10%**
- æµç•…æ€§ â†‘ **~5%**
- å¿ å®æ€§ â†‘ **~5â€“10%**

è¡¨æ˜å„æ¨¡å—ååŒæ˜¾è‘—æ”¹å–„è¯­ä¹‰è´¨é‡å’Œé€»è¾‘ä¸€è‡´æ€§ã€‚

---

### **(3) æ•ˆç‡è¡¨ç°ï¼ˆToken æ¶ˆè€—åˆ†æï¼ŒFigure 6ï¼‰**

| æ•°æ®é›† | Base | Jenius |
|-------|------|--------|
| **APIGen** | 9.96M tokens | **2.46M tokens**ï¼ˆâ†“75%ï¼‰ |
| **Jenius-bench** | 9.27M tokens | **3.65M tokens**ï¼ˆâ†“60%ï¼‰ |

âœ… **åŸå› åˆ†æ**ï¼š
- è‡ªé€‚åº” prompt å‡å°‘æ— æ•ˆæ¨ç†
- å·¥å…·ç¼–æ’é™ä½å†—ä½™è°ƒç”¨
- åˆ†å±‚è®°å¿†å‹ç¼©å†å²é•¿åº¦

> âš¡ï¸ å®ç°â€œæ›´å°‘ tokenï¼Œæ›´é«˜å‡†ç¡®ç‡â€çš„åŒèµ¢ã€‚

---

### **æ¶ˆèå®éªŒç»“è®º**
- **Prompt ä¼˜åŒ–** æ˜¯æœ€å…³é”®çš„æ”¹è¿›æ¥æºï¼Œåœ¨å¤šè½®ä»»åŠ¡ä¸­æ˜¾è‘—æå‡ä»»åŠ¡å¯¹é½èƒ½åŠ›ã€‚
- **Tool Orchestration** æ˜¾è‘—å‡å°‘è¯¯è°ƒç”¨ï¼Œå°¤å…¶åœ¨é«˜å™ªå£°ç¯å¢ƒä¸‹æ•ˆæœçªå‡ºã€‚
- **Memory Management** å¯¹é•¿å‘¨æœŸä»»åŠ¡ç¨³å®šæ€§è‡³å…³é‡è¦ï¼Œä¿éšœä¸Šä¸‹æ–‡è¿è´¯æ€§ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ç»éªŒé©±åŠ¨çš„è®¾è®¡ä¼˜äºé™æ€æ¶æ„**ï¼šåŠ¨æ€é€‚é… promptã€å·¥å…·å’Œè®°å¿†ï¼Œèƒ½æœ‰æ•ˆåº”å¯¹ç°å®ä¸–ç•Œçš„ä¸ç¡®å®šæ€§ã€‚
2. **æ¨¡å—åŒ–è®¾è®¡å¸¦æ¥å¯è§£é‡Šæ€§ä¸å¯ç»´æŠ¤æ€§**ï¼šä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ç‹¬ç«‹ä¼˜åŒ–ã€ååŒå¢ç›Šï¼Œé€‚åˆå·¥ä¸šéƒ¨ç½²ã€‚
3. **çœŸå®åœºæ™¯éœ€è¦ç»¼åˆè¯„ä¼°ä½“ç³»**ï¼šä¼ ç»Ÿ BLEU/ROUGE ä¸è¶³ä»¥è¡¡é‡ agent æ€§èƒ½ï¼Œéœ€å¼•å…¥ **4T + CRCFF + Token** å¤šç»´æŒ‡æ ‡ã€‚
4. **å·²æˆåŠŸè½åœ°ç”Ÿäº§ç¯å¢ƒ**ï¼šJenius ç³»ç»Ÿå·²åœ¨ [jenius.cn](https://www.jenius.cn) ä¸Šçº¿è¿è¡Œï¼ŒéªŒè¯å…¶å·¥ç¨‹å¯è¡Œæ€§ã€‚

---

### **å±€é™æ€§**
1. **è¯„ä¼°ä»ä¾èµ–äººå·¥æ ‡æ³¨å‚è€ƒè·¯å¾„**ï¼šç°å®ä¸­å¯èƒ½å­˜åœ¨å¤šç§åˆæ³•æ‰§è¡Œè·¯å¾„ï¼Œå•ä¸€ gold path å¯èƒ½ä½ä¼° agent èƒ½åŠ›ã€‚
2. **æ‹ç‚¹æ£€æµ‹å¯¹å°è§„æ¨¡å·¥å…·åº“æ•æ„Ÿ**ï¼šå½“å€™é€‰å·¥å…·è¾ƒå°‘æ—¶ï¼Œkneedle ç®—æ³•å¯èƒ½ä¸ç¨³å®šã€‚
3. **æœªå……åˆ†æ¢ç´¢ multi-agent åä½œ**ï¼šå½“å‰ä¸ºå• agent æ¡†æ¶ï¼Œåˆ†å¸ƒå¼åä½œæ½œåŠ›å¾…æŒ–æ˜ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ›´çµæ´»çš„è¯„ä¼°æœºåˆ¶**ï¼šæ”¯æŒå¤šåˆæ³•è·¯å¾„åŒ¹é…ï¼Œç»“åˆç”¨æˆ·æ»¡æ„åº¦ã€å†³ç­–æˆæœ¬ã€å»¶è¿Ÿç­‰çœŸå®æŒ‡æ ‡ã€‚
2. **åŠ¨æ€æ¨¡å—é‡ç»„**ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦è‡ªåŠ¨å¯ç”¨/å…³é—­æŸäº›ä¼˜åŒ–æ¨¡å—ï¼Œå®ç°èµ„æºè‡ªé€‚åº”è°ƒåº¦ã€‚
3. **multi-agent ååŒæ¶æ„**ï¼šæ„å»º agent å›¢é˜Ÿè¿›è¡Œåˆ†å·¥åä½œï¼Œæå‡å¤æ‚ä»»åŠ¡è§£å†³èƒ½åŠ›ã€‚
4. **å¼ºåŒ–å­¦ä¹ é©±åŠ¨çš„è‡ªæˆ‘è¿›åŒ–**ï¼šå¼•å…¥ RL å®ç° agent åœ¨çº¿å­¦ä¹ ä¸æŒç»­ä¼˜åŒ–ã€‚

---

## **æ€»ç»“**
**Jenius-Agent** æ˜¯ä¸€ä¸ªé¢å‘çœŸå®åº”ç”¨åœºæ™¯çš„è½»é‡çº§ã€å¯æ‰©å±•ã€åè®®å…¼å®¹çš„ LLM agent æ¡†æ¶ã€‚å®ƒé€šè¿‡ **è‡ªé€‚åº”æç¤ºç”Ÿæˆã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥å·¥å…·ç¼–æ’ã€åˆ†å±‚è®°å¿†ç®¡ç†** ä¸‰å¤§åˆ›æ–°ï¼Œåœ¨ **ä»»åŠ¡å‡†ç¡®ç‡ã€å“åº”è´¨é‡ã€token æ•ˆç‡** ä¸Šå…¨é¢è¶…è¶ŠåŸºçº¿ç³»ç»Ÿï¼Œå·²åœ¨å®é™…äº§å“ä¸­éªŒè¯æœ‰æ•ˆæ€§ã€‚è¯¥ç ”ç©¶ä¸ä»…æä¾›äº†æŠ€æœ¯æ–¹æ¡ˆï¼Œä¹Ÿä¸º LLM agent çš„å·¥ä¸šåŒ–è½åœ°æä¾›äº†å®è·µè“å›¾ã€‚

</details>

---

### 8. [Punctuation-aware Hybrid Trainable Sparse Attention for Large Language Models](https://arxiv.org/abs/2601.02819)

**Authors**: Junxiang Qiu, Shuo Wang, Zhengsu Chen, Hengheng Zhang, Jinda Lu, Changcheng Li, Qi Tian  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.02819v1  

#### Abstract
Attention serves as the fundamental mechanism for long-context modeling in large language models (LLMs), yet dense attention becomes structurally prohibitive for long sequences due to its quadratic complexity. Consequently, sparse attention has received increasing attention as a scalable alternative...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPunctuation-aware Hybrid Trainable Sparse Attention for Large Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **sparse attention** æ–¹æ³•åœ¨é•¿åºåˆ—å»ºæ¨¡ä¸­è™½ç„¶èƒ½æ˜¾è‘—é™ä½è®¡ç®—å¤æ‚åº¦ï¼ˆä» $O(L^2)$ åˆ° $O(L)$ï¼‰ï¼Œä½†åœ¨ **block selection** é˜¶æ®µé€šå¸¸é‡‡ç”¨ç²—ç²’åº¦çš„è¯­ä¹‰è¡¨ç¤ºï¼ˆå¦‚å¹³å‡æ± åŒ–ï¼‰ï¼Œå¯¼è‡´å—å†…è¯­ä¹‰è¾¹ç•Œæ¨¡ç³Šï¼Œå…³é”®ä¿¡æ¯è¢«ç¨€é‡Šï¼Œä»è€Œé€ æˆ **ä¿¡æ¯ä¸¢å¤±**ã€‚æ­¤å¤–ï¼Œå½“å‰æ–¹æ³•åœ¨æä½æ¿€æ´» token æ¯”ä¾‹ï¼ˆå³æç«¯ç¨€ç–ï¼‰ä¸‹è¡¨ç°ä¸ç¨³å®šï¼Œé™åˆ¶äº†å…¶æ•ˆç‡æ½œåŠ›ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šPHSA
ä½œè€…æå‡º **Punctuation-aware Hybrid Sparse Attention (PHSA)**ï¼Œä¸€ç§åŸç”Ÿå¯è®­ç»ƒçš„ç¨€ç–æ³¨æ„åŠ›æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ **punctuation tokens**ï¼ˆå¦‚é€—å·ã€å¥å·ã€åˆ†å·ï¼‰ä½œä¸ºè‡ªç„¶çš„è¯­ä¹‰è¾¹ç•Œé”šç‚¹ï¼Œæå‡ç¨€ç–é€‰æ‹©çš„å‡†ç¡®æ€§ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
- âœ… **åŒåˆ†æ”¯èšåˆæœºåˆ¶ï¼ˆDual-branch Aggregation Mechanismï¼‰**  
  æ¯ä¸ª key block çš„ä»£è¡¨æ€§å‘é‡ç”±ä¸¤ä¸ªéƒ¨åˆ†èåˆè€Œæˆï¼š
  - **Global Semantic Representation**ï¼šå¯¹å—å†…æ‰€æœ‰ token è¿›è¡Œå¹³å‡æ± åŒ–ã€‚
  - **Punctuation-aware Representation**ï¼šä»…å¯¹å—å†…çš„æ ‡ç‚¹ç¬¦å· token è¿›è¡Œæ± åŒ–ï¼Œä¿ç•™è¯­ä¹‰è½¬æŠ˜ç‚¹ä¿¡æ¯ã€‚
  - é€šè¿‡é—¨æ§å‚æ•° $\lambda$ åŠ æƒèåˆï¼š  
    $$
    M(B_t) = \lambda \cdot M_o(B_t) + (1-\lambda) \cdot M_p(B_t)
    $$
  > è¯¥è®¾è®¡å‡ ä¹ä¸å¢åŠ é¢å¤–è®¡ç®—å¼€é”€ï¼Œå´æœ‰æ•ˆä¿ç•™äº†ç»†ç²’åº¦è¯­ä¹‰ç»“æ„ã€‚

- âœ… **æç«¯ç¨€ç–è‡ªé€‚åº”è®­ç»ƒä¸æ¨ç†ç­–ç•¥ï¼ˆExtreme-sparsity-adaptive Training & Inferenceï¼‰**  
  æ”¯æŒåœ¨æä½ Top-K è®¾ç½®ä¸‹ç¨³å®šè®­ç»ƒå’Œç”Ÿæˆï¼Œçªç ´ç°æœ‰æ–¹æ³•åœ¨é«˜ç¨€ç–åº¦ä¸‹çš„æ€§èƒ½é€€åŒ–ç“¶é¢ˆï¼Œä¸ºèµ„æºå—é™è®¾å¤‡ä¸Šçš„è½»é‡åŒ–éƒ¨ç½²æä¾›å¯èƒ½ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | PHSA | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ InfLLM v2, NSAï¼‰ |
|------|------|-----------------------------|
| è¯­ä¹‰ç²¾åº¦ | åˆ©ç”¨æ ‡ç‚¹å¢å¼ºè¾¹ç•Œæ„ŸçŸ¥ | ä¾èµ–å¹³å‡æ± åŒ–ï¼Œæ¨¡ç³Šå†…éƒ¨è¯­ä¹‰ |
| æç«¯ç¨€ç–èƒ½åŠ› | æ”¯æŒæä½ Top-K è®­ç»ƒä¸æ¨ç† | åœ¨ä½æ¿€æ´»æ¯”ä¸‹æ€§èƒ½æ€¥å‰§ä¸‹é™ |
| å¯è®­ç»ƒæ€§ | å®Œå…¨å¯å¾®ã€ç«¯åˆ°ç«¯è®­ç»ƒ | éƒ¨åˆ†å«ä¸å¯å¯¼æ“ä½œï¼ˆå¦‚èšç±»ï¼‰ |
| æ•ˆç‡ | æ˜¾è‘—å‡å°‘ä¿¡æ¯æŸå¤±çš„åŒæ—¶ä¿æŒé«˜ sparsity | éœ€è¾ƒé«˜ token æ¿€æ´»æ•°æ‰èƒ½ç»´æŒæ€§èƒ½ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼šå¤šæºæ··åˆæ•°æ®é›†ï¼ŒåŒ…æ‹¬ï¼š
  - å¼€æºæ•°æ®é›†ï¼š`dclm`, `mapcc`, `ultrachat`, `tulu3`, `finemath`, `megamath`
  - è‡ªç ”é«˜è´¨é‡æ•™è‚²é¢†åŸŸç§æœ‰æ•°æ®é›†ï¼ˆæœªå…¬å¼€ï¼‰
- **è¯„ä¼°ä»»åŠ¡**ï¼š
  - **General Benchmarks**ï¼ˆ15é¡¹ä»»åŠ¡ï¼‰ï¼šæ¶µç›–æ•°å­¦æ¨ç†ï¼ˆGSM8K, MathQA, MATHï¼‰ã€å¸¸è¯†é—®ç­”ï¼ˆARC-C/E/ZHï¼‰ã€ç»¼åˆè®¤çŸ¥ï¼ˆMMLU, CMMLU, BBHï¼‰ã€æ–‡æœ¬è¿è´¯æ€§ï¼ˆLAMBADA, XStoryClozeï¼‰ã€ä»£ç ç”Ÿæˆï¼ˆHumanEvalï¼‰ã€ç‰¹å®šé¢†åŸŸä»»åŠ¡ï¼ˆPiPA, C-Validï¼‰ç­‰ã€‚
  - **Long-context Benchmarks**ï¼š
    - **LongBench**ï¼šå¤šè¯­è¨€ã€å¤šä»»åŠ¡é•¿ä¸Šä¸‹æ–‡ç†è§£åŸºå‡†ã€‚
    - **Needle-in-a-Haystack (NIAH)**ï¼šè¯„ä¼°æ¨¡å‹åœ¨é•¿åºåˆ—ä¸­å®šä½å…³é”®ä¿¡æ¯çš„èƒ½åŠ›ï¼Œç›´æ¥åæ˜ ä¿¡æ¯æŸå¤±ç¨‹åº¦ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹è§„æ¨¡**ï¼šQwen3-0.6B å’Œ Qwen3-8B
- **åºåˆ—é•¿åº¦**ï¼š4k å’Œ 32k tokens
- **Block Size**ï¼š16 tokens / block
- **å±€éƒ¨çª—å£ä¸åˆå§‹å—**ï¼š
  - 4k åºåˆ—ï¼šlocal window=128, init block=16
  - 32k åºåˆ—ï¼šlocal window=512, init block=128
- **è®­ç»ƒæ–¹å¼**ï¼šåŸºäº Qwen3-0.6B-Base åˆå§‹åŒ–ï¼Œè¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒï¼ˆ20B å’Œ 100B tokensï¼‰
- **æ¨ç†æ¨¡å¼**ï¼šæ”¯æŒè®­ç»ƒä¸€è‡´ï¼ˆtraining-inference consistentï¼‰ä¸è®­ç»ƒæ— å…³ï¼ˆtraining-freeï¼‰ä¸¤ç§èŒƒå¼

### è¯„ä¼°æŒ‡æ ‡
- **å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**ï¼šç”¨äº general benchmarks å’Œ LongBench
- **NIAH Score**ï¼šè¶Šé«˜è¡¨ç¤ºä¿¡æ¯ä¿ç•™è¶Šå¥½ï¼Œè¶Šæ¥è¿‘ 100 è¡¨ç¤ºå…³é”®ä¿¡æ¯æ— æŸ
- **Sparsity Ratio**ï¼šå®é™…å‚ä¸ attention è®¡ç®—çš„ token å æ¯”
- **Avg. Score**ï¼šå¤šä¸ªä»»åŠ¡çš„å¹³å‡å¾—åˆ†

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Dense Attention**ï¼šæ ‡å‡†å…¨è¿æ¥æ³¨æ„åŠ›
- **InfLLM v2**ï¼ˆZhao et al., 2025ï¼‰ï¼šå½“å‰æœ€å…ˆè¿›çš„å¯è®­ç»ƒç¨€ç–æ³¨æ„åŠ›æ–¹æ³•ï¼Œæ”¯æŒçŸ­åˆ°é•¿ä¸Šä¸‹æ–‡æ— ç¼åˆ‡æ¢
- **NSA**ï¼ˆYuan et al., 2025ï¼‰ï¼šDeepSeek æå‡ºçš„åŠ¨æ€åˆ†å±‚ç¨€ç–ç­–ç•¥

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### âœ… åœ¨ NIAH ä¸Šçš„è¡¨ç°ï¼ˆ32k sequence, Qwen3-0.6Bï¼‰
| æ–¹æ³• | Top-K=1 | Top-K=2 | Top-K=4 |
|------|--------|--------|--------|
| **PHSA** | **68.0** | **88.8** | **99.0** |
| InfLLM v2 | 64.6 | 85.8 | 98.0 |

> åœ¨ 32k é•¿åºåˆ—ä¸‹ï¼ŒPHSA åœ¨ Top-K=2 æ—¶æ¯” InfLLM v2 é«˜å‡º **3.0 åˆ†**ï¼Œä¸”åœ¨ Top-K=4 è¾¾åˆ°è¿‘ä¹å®Œç¾æ£€ç´¢ï¼ˆ99.0ï¼‰ã€‚

#### âœ… åœ¨ general benchmarks ä¸Šçš„å¹³å‡å¾—åˆ†ï¼ˆQwen3-0.6B, 100B tokensï¼‰
| æ–¹æ³• | Inference Top-K | Avg. Score |
|------|------------------|------------|
| Dense | N/A | 48.96 |
| InfLLM v2 | 2 | 47.69 |
| **PHSA** | **2** | **48.81** |
| **PHSA** | **4** | **49.24** âœ…ï¼ˆæœ€ä¼˜ï¼‰|

> PHSA åœ¨ Top-K=4 ä¸‹ä¸ä»…è¶…è¶Š InfLLM v2ï¼Œç”šè‡³ **è¶…è¿‡ dense attention**ï¼Œè¡¨æ˜å…¶å…·å¤‡æ€§èƒ½å¢ç›Šæ½œåŠ›ã€‚

#### âœ… ä¿¡æ¯æŸå¤±å‡å°‘æ•ˆæœ
> å¯¹äº **0.6B å‚æ•°æ¨¡å‹ + 32k è¾“å…¥åºåˆ—**ï¼ŒPHSA åœ¨ **97.3% ç¨€ç–åº¦**ä¸‹ï¼Œç›¸æ¯” dense attention èƒ½ **å‡å°‘ 10.8% çš„ä¿¡æ¯æŸå¤±**ã€‚

#### âœ… LongBench ç»¼åˆè¡¨ç°
| æ–¹æ³• | Average Score |
|------|---------------|
| Dense | 27.86 |
| InfLLM v2 | 27.40 |
| **PHSA** | **28.13** |
| **PHSA_en+zh**ï¼ˆåŠ å…¥ä¸­æ–‡æ ‡ç‚¹ï¼‰ | **28.15** |

> PHSA åœ¨å¤§å¤šæ•°å­ä»»åŠ¡ä¸Šä¼˜äº baselineï¼Œå¹¶é€šè¿‡å¼•å…¥ä¸­æ–‡æ ‡ç‚¹è¿›ä¸€æ­¥æå‡ä¸­æ–‡ä»»åŠ¡è¡¨ç°ï¼ˆå¦‚ MQZ ä» 20.63 â†’ 22.22ï¼‰ã€‚

---

### æ¶ˆèå®éªŒä¸å…³é”®å‘ç°ï¼ˆRQåˆ†æï¼‰

| ç ”ç©¶é—®é¢˜ | å‘ç° |
|---------|------|
| **RQ1: ä¸ºä½•åå¥½æ›´ä½çš„ Top-Kï¼Ÿ** | è®­ç»ƒæ—¶ä½¿ç”¨è¾ƒä½ Top-Kï¼ˆå¦‚ 2 æˆ– 4ï¼‰å¯åœ¨æ¨ç†é˜¶æ®µå®ç°æ›´é«˜æ•ˆçš„ä¿¡æ¯ä¿ç•™ï¼›ä½†è¿‡ä½ï¼ˆå¦‚ 1ï¼‰ä¼šå¯¼è‡´æ€§èƒ½å´©æºƒã€‚PHSA åœ¨ Top-K=2 æ—¶è¾¾åˆ°æœ€ä½³å¹³è¡¡ã€‚ |
| **RQ2: æ˜¯å¦åœ¨é€šç”¨åŸºå‡†ä¸Šæœ‰æ•ˆï¼Ÿ** | æ˜¯ã€‚PHSA åœ¨ 20B å’Œ 100B è®­ç»ƒæ­¥æ•°ä¸‹å‡ä¼˜äº InfLLM v2ï¼Œä¸”åœ¨ Top-K=4 æ—¶åè¶… dense attentionã€‚ |
| **RQ3: æ˜¯å¦åœ¨é•¿ä¸Šä¸‹æ–‡åŸºå‡†ä¸Šæœ‰æ•ˆï¼Ÿ** | æ˜¯ã€‚åœ¨ NIAH å’Œ LongBench ä¸ŠæŒç»­é¢†å…ˆï¼Œå°¤å…¶åœ¨æç«¯ç¨€ç–æ¡ä»¶ä¸‹ä¼˜åŠ¿æ˜æ˜¾ã€‚ |
| **RQ4: ä¸åŒè¯­è¨€ä¸­æ ‡ç‚¹çš„å½±å“ï¼Ÿ** | è‹±æ–‡æ ‡ç‚¹ä¸»å¯¼è®­ç»ƒå¯¼è‡´ä¸­æ–‡ä»»åŠ¡ï¼ˆarc_c_zh, MQZï¼‰è¡¨ç°ç•¥å·®ï¼›åŠ å…¥ä¸­æ–‡æ ‡ç‚¹åï¼ˆPHSA_en+zhï¼‰ï¼Œç›¸å…³æŒ‡æ ‡æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†è·¨è¯­è¨€æ‰©å±•å¯è¡Œæ€§ã€‚ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦ç»“è®º
1. **æ ‡ç‚¹ç¬¦å·æ˜¯æœ‰æ•ˆçš„è¯­ä¹‰è¾¹ç•Œæç¤ºå™¨**ï¼šå°† punctuation tokens ä½œä¸ºè¯­ä¹‰é”šç‚¹ï¼Œå¯æ˜¾è‘—æå‡ block-level selection çš„å‡†ç¡®æ€§ï¼Œç¼“è§£å› å¹³å‡æ± åŒ–å¸¦æ¥çš„è¯­ä¹‰ç¨€é‡Šé—®é¢˜ã€‚
2. **PHSA å®ç°äº†æ€§èƒ½ä¸æ•ˆç‡çš„åŒé‡æå‡**ï¼š
   - åœ¨é«˜è¾¾ 97.3% çš„ç¨€ç–åº¦ä¸‹ä»ä¿æŒä¼˜å¼‚æ€§èƒ½ï¼›
   - åœ¨å¤šä¸ª benchmark ä¸Šè¶…è¶Š dense attention å’Œ SOTA sparse æ–¹æ³•ï¼ˆå¦‚ InfLLM v2ï¼‰ï¼›
   - æ”¯æŒæç«¯ç¨€ç–è®­ç»ƒï¼Œä¸ºè¾¹ç¼˜è®¾å¤‡éƒ¨ç½²å¥ å®šåŸºç¡€ã€‚
3. **è®­ç»ƒ-æ¨ç†ä¸€è‡´æ€§è‡³å…³é‡è¦**ï¼šåœ¨ä½ Top-K ä¸‹ï¼Œè®­ç»ƒé˜¶æ®µçš„ç¨€ç–é…ç½®ç›´æ¥å½±å“æ¨ç†æ€§èƒ½ï¼ŒPHSA çš„å¯è®­ç»ƒæ€§ä½¿å…¶èƒ½åœ¨ç¨€ç–è·¯å¾„ä¸Šå……åˆ†ä¼˜åŒ–ã€‚

### å±€é™æ€§
- å½“å‰æ–¹æ³• **æœªå¯¹æ ‡ç‚¹ç¬¦å·è¿›è¡Œç­›é€‰**ï¼Œå¯èƒ½å¼•å…¥å™ªå£°ï¼ˆä¾‹å¦‚é¢‘ç¹å‡ºç°ä½†è¯­ä¹‰å¼±çš„é€—å·ï¼‰ï¼›
- ä¸­æ–‡ç­‰éæ‹‰ä¸è¯­ç³»è¯­è¨€éœ€ä¸“é—¨å¤„ç†æ ‡ç‚¹é›†åˆï¼Œå¦åˆ™ä¼šå½±å“è·¨è¯­è¨€æ³›åŒ–ï¼›
- è®ºæ–‡å—é™äºç®—åŠ›å’Œç¯‡å¹…ï¼Œå°šæœªæ·±å…¥æ¢ç´¢æœ€ä¼˜æ ‡ç‚¹å­é›†é€‰æ‹©æœºåˆ¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **åŠ¨æ€æ ‡ç‚¹æƒé‡æœºåˆ¶** æˆ– **å¯å­¦ä¹ æ ‡ç‚¹é‡è¦æ€§è¯„åˆ†**ï¼›
- æ‰©å±•è‡³æ›´å¤šè¯­è¨€ï¼Œæ„å»º **å¤šè¯­è¨€ punctuation-aware sparse attention**ï¼›
- ç»“åˆç¡¬ä»¶ä¼˜åŒ–ï¼Œæ¨åŠ¨ **PHSA åœ¨ç§»åŠ¨ç«¯/åµŒå…¥å¼è®¾å¤‡ä¸Šçš„è½åœ°åº”ç”¨**ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> PHSA é€šè¿‡å¼•å…¥ **punctuation-aware dual-branch aggregation** å’Œ **extreme-sparsity-adaptive training**ï¼Œåœ¨å‡ ä¹é›¶é¢å¤–è®¡ç®—æˆæœ¬çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†ç¨€ç–æ³¨æ„åŠ›çš„è¯­ä¹‰ä¿çœŸåº¦ï¼Œåœ¨é•¿ä¸Šä¸‹æ–‡å»ºæ¨¡ä¸­å®ç°äº† **æ•ˆç‡ä¸æ€§èƒ½çš„ååŒä¼˜åŒ–**ï¼Œä¸º LLM çš„è½»é‡åŒ–éƒ¨ç½²æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 9. [LLM-Enhanced Reinforcement Learning for Time Series Anomaly Detection](https://arxiv.org/abs/2601.02511)

**Authors**: Bahareh Golchin, Banafsheh Rekabdar, Danielle Justo  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.02511v1  

#### Abstract
Detecting anomalies in time series data is crucial for finance, healthcare, sensor networks, and industrial monitoring applications. However, time series anomaly detection often suffers from sparse labels, complex temporal patterns, and costly expert annotation. We propose a unified framework that i...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# LLM-Enhanced Reinforcement Learning for Time Series Anomaly Detection è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹**ä¸­çš„å‡ ä¸ªå…³é”®æŒ‘æˆ˜ï¼š
- **æ ‡ç­¾ç¨€ç–æ€§**ï¼ˆsparse labelsï¼‰ï¼šçœŸå®åœºæ™¯ä¸­å¼‚å¸¸æ ·æœ¬æå°‘ä¸”æ ‡æ³¨æˆæœ¬é«˜ï¼›
- **å¤æ‚æ—¶åºæ¨¡å¼**ï¼šå¦‚å­£èŠ‚æ€§ã€æ¸å˜æ¼‚ç§»ç­‰éš¾ä»¥å»ºæ¨¡ï¼›
- **å¥–åŠ±ä¿¡å·ç¨€ç–**ï¼ˆsparse rewardsï¼‰ï¼šä¼ ç»Ÿ **Reinforcement Learning (RL)** åœ¨ç¼ºä¹å¯†é›†åé¦ˆæ—¶å­¦ä¹ æ•ˆç‡ä½ï¼›
- **æ¢ç´¢æ•ˆç‡ä¸è¶³**ï¼šRLä»£ç†åœ¨æœªçŸ¥çŠ¶æ€ç©ºé—´ä¸­éš¾ä»¥æœ‰æ•ˆæ¢ç´¢æ½œåœ¨å¼‚å¸¸åŒºåŸŸã€‚

è¿™äº›é—®é¢˜å¯¼è‡´ç°æœ‰æ–¹æ³•åœ¨**å°æ ·æœ¬æˆ–å¼±ç›‘ç£æ¡ä»¶ä¸‹æ€§èƒ½ä¸‹é™æ˜æ˜¾**ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§**ç»Ÿä¸€æ¡†æ¶**ï¼Œå°†å¤šç§å…ˆè¿›æŠ€æœ¯èåˆï¼Œå½¢æˆä¸€ä¸ªååŒå¢å¼ºçš„å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**LLM-based Potential Function for Reward Shaping**
- åˆ©ç”¨ **Large Language Model (LLM)** ç”Ÿæˆè¯­ä¹‰åŒ–çš„â€œä¸¥é‡æ€§è¯„åˆ†â€ï¼ˆ`severity âˆˆ [0,1]`ï¼‰ï¼Œä½œä¸º **Potential-Based Reward Shaping (PBRS)** çš„åŠ¿å‡½æ•° `Î¦(s)`ã€‚
- å°†åŸå§‹ RL å¥–åŠ±æ›´æ–°ä¸ºï¼š
  $$
  r'(s,a,s') = r(s,a,s') + \gamma\Phi(s') - \Phi(s)
  $$
- è¿™ç§æ–¹å¼å¼•å…¥äº†**è¯­ä¹‰å…ˆéªŒçŸ¥è¯†**ï¼Œæ— éœ€äººå·¥è®¾è®¡ç‰¹å¾å³å¯æŒ‡å¯¼ agent å‘æ›´å¯èƒ½å«å¼‚å¸¸çš„çŠ¶æ€è½¬ç§»ï¼ŒåŒæ—¶ä¿æŒæœ€ä¼˜ç­–ç•¥ä¸å˜ï¼ˆpolicy invarianceï¼‰ã€‚

#### ï¼ˆ2ï¼‰**VAE-enhanced Dynamic Reward Scaling**
- å¼•å…¥ **Variational Autoencoder (VAE)** å¯¹æ­£å¸¸æ¨¡å¼è¿›è¡Œæ— ç›‘ç£å»ºæ¨¡ï¼Œåˆ©ç”¨å…¶**é‡æ„è¯¯å·®**ï¼ˆReconstruction Errorï¼‰ä½œä¸ºéç›‘ç£å¼‚å¸¸ä¿¡å·ã€‚
- è®¾è®¡åŠ¨æ€æƒé‡ç³»æ•° `Î»(t)`ï¼Œé€šè¿‡æ¯”ä¾‹æ§åˆ¶æœºåˆ¶è‡ªåŠ¨è°ƒèŠ‚ç›‘ç£å¥–åŠ±ï¼ˆclassificationï¼‰ä¸éç›‘ç£ä¿¡å·ï¼ˆVAE errorï¼‰ä¹‹é—´çš„å¹³è¡¡ï¼š
  $$
  R_{total} = R_1 + Î»(t) â‹… R_2
  $$
- å½“ episode è¡¨ç°å·®æ—¶å¢åŠ  VAE æƒé‡ï¼Œæå‡æ¢ç´¢èƒ½åŠ›ï¼›è¡¨ç°å¥½åˆ™å‡å°‘ä¾èµ–ï¼Œèšç„¦åˆ†ç±»ç²¾åº¦ã€‚

#### ï¼ˆ3ï¼‰**Active Learning + Label Propagation**
- åœ¨æ¯ä¸ª episode ç»“æŸåï¼ŒåŸºäº Q-value marginï¼ˆ`|Q(s,aâ‚€)âˆ’Q(s,aâ‚)|`ï¼‰é€‰æ‹©æœ€ä¸ç¡®å®šçš„æ ·æœ¬é€äººæ ‡æ³¨ï¼ˆuncertainty samplingï¼‰ã€‚
- ä½¿ç”¨ç›¸ä¼¼åº¦æ ¸ï¼ˆGaussian kernelï¼‰è¿›è¡Œ **Label Propagation**ï¼Œæ‰©å±•ä¼ªæ ‡ç­¾è‡³é‚»è¿‘æœªæ ‡è®°æ ·æœ¬ï¼Œæ˜¾è‘—é™ä½äººå·¥æ ‡æ³¨è´Ÿæ‹…ã€‚

#### ï¼ˆ4ï¼‰æ•´ä½“æ¶æ„æ•´åˆ
- æ„å»ºäº†ä¸€ä¸ªç«¯åˆ°ç«¯å¯è®­ç»ƒçš„ **LSTM-based RL Agent**ï¼Œç»“åˆä¸Šè¿°æ¨¡å—å®ç°é«˜æ•ˆã€é²æ£’çš„æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ ·æœ¬æ•ˆç‡** | ä¸»åŠ¨å­¦ä¹  + æ ‡ç­¾ä¼ æ’­æå¤§å‡å°‘äº†å¯¹æ ‡æ³¨æ•°æ®çš„éœ€æ±‚ |
| **æ¢ç´¢èƒ½åŠ›** | LLM æä¾›è¯­ä¹‰å¼•å¯¼ï¼Œç¼“è§£ç¨€ç–å¥–åŠ±ä¸‹çš„æ¢ç´¢éš¾é¢˜ |
| **æ³›åŒ–æ€§** | èåˆç›‘ç£ä¸éç›‘ç£ä¿¡å·ï¼Œåœ¨å¤šå˜é‡å¤æ‚åœºæ™¯ä¸‹ä»ç¨³å®š |
| **å¯è§£é‡Šæ€§** | LLM è¾“å‡ºçš„ `severity` åˆ†æ•°å…·æœ‰è¯­ä¹‰æ„ä¹‰ï¼Œä¾¿äºè°ƒè¯•å’Œåˆ†æ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒåœ¨ä¸¤ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œï¼š

| Dataset | ç±»å‹ | ç‰¹å¾ç»´åº¦ | åºåˆ—æ•°é‡ | å¼‚å¸¸æ¯”ä¾‹ | æè¿° |
|--------|------|----------|-----------|------------|------|
| **Yahoo-A1** | å•å˜é‡ï¼ˆunivariateï¼‰ | 1 | 67 | 1.76% | æ¥è‡ª Yahoo ç½‘ç«™æµé‡çš„çœŸå®æ—¶é—´åºåˆ—ï¼Œå¼‚å¸¸è¡¨ç°ä¸ºçªå¢æˆ–çªé™ |
| **SMD** | å¤šå˜é‡ï¼ˆmultivariateï¼‰ | 38 | 28 | 4.16% | æœåŠ¡å™¨æœºå™¨ä¼ æ„Ÿå™¨æ•°æ®ï¼Œå‰5å¤©ä¸ºæ­£å¸¸ï¼Œå5å¤©æ³¨å…¥éšæœºå¼‚å¸¸ï¼ŒåŒ…å«å­£èŠ‚æ€§å’Œç¼“æ…¢æ¼‚ç§» |

> âœ… æ‰€æœ‰å®éªŒå‡åœ¨æœ‰é™æ ‡æ³¨é¢„ç®—ä¸‹è¿›è¡Œï¼Œæ¨¡æ‹Ÿç°å®åœºæ™¯ã€‚

---

### å®éªŒè®¾ç½®
- **æ»‘åŠ¨çª—å£é•¿åº¦**ï¼š`n_steps = 25`
- **çŠ¶æ€è¡¨ç¤º**ï¼š`s_t = [window; action_flag] âˆˆ â„^(d+1)Ã—25`ï¼ŒåŒ…å«åŠ¨ä½œä¸Šä¸‹æ–‡
- **Agent ç»“æ„**ï¼šLSTM + Q-Networkï¼ˆåŒè¾“å‡ºå¯¹åº”ä¸¤ä¸ªåŠ¨ä½œï¼‰
- **LLM æ¨¡å‹å¯¹æ¯”**ï¼šæµ‹è¯• GPT-3.5ã€Llama-3.2-3Bã€Phi-2
- **Prompt è®¾è®¡**ï¼šé‡‡ç”¨ few-shot ç¤ºä¾‹å¼•å¯¼ LLM è¾“å‡º JSON æ ¼å¼çš„ `{"severity": v}`ï¼Œç¡®ä¿ä¸€è‡´æ€§
- **å¥–åŠ±ç»“æ„**ï¼š
  - åˆ†ç±»å¥–åŠ±ï¼šTP=+5, TN=+1, FP=-1, FN=-5
  - VAE é‡æ„è¯¯å·®ä½œä¸ºè¾…åŠ©å¥–åŠ±é¡¹
- **ä¸»åŠ¨å­¦ä¹ å‚æ•°**ï¼šæ¯è½®é€‰å– Top-N æœ€ä¸ç¡®å®šæ ·æœ¬æ ‡æ³¨ï¼Œå¹¶ä¼ æ’­ K ä¸ªé«˜ç½®ä¿¡ä¼ªæ ‡ç­¾

---

### è¯„ä¼°æŒ‡æ ‡
ä½¿ç”¨æ ‡å‡†å¼‚å¸¸æ£€æµ‹æŒ‡æ ‡ï¼š
- **Precision (Prec)**
- **Recall (Rec)**
- **F1 Score**

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| Baseline | æ–¹æ³•ç±»å‹ | æ˜¯å¦ä½¿ç”¨ RL | æ˜¯å¦ä½¿ç”¨ LLM |
|---------|----------|-------------|---------------|
| THOC | One-Class Network | âŒ | âŒ |
| TranAD | Transformer-based AD | âŒ | âŒ |
| TS2Vec | Self-supervised Representation | âŒ | âŒ |
| DCdetector | Contrastive Learning | âŒ | âŒ |
| TimesNet | Temporal 2D-Variation CNN | âŒ | âŒ |
| CARLA | Deep RL-based AD | âœ… | âŒ |

> æˆ‘ä»¬çš„æ–¹æ³•ï¼ˆProposed Method + LLMï¼‰æ˜¯å”¯ä¸€ç»“åˆ **LLM + RL + VAE + Active Learning** çš„æ¡†æ¶ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ€§èƒ½å¯¹æ¯”ï¼ˆæ¥è‡ª Table IIï¼‰

#### Yahoo-A1ï¼ˆå•å˜é‡ï¼‰

| Model | Prec | Rec | F1 |
|-------|------|-----|-----|
| TimesNet | 0.3808 | 0.7883 | 0.5135 |
| TranAD | 0.4185 | 0.8712 | 0.5654 |
| CARLA (best non-LLM) | 0.5747 | 0.9755 | **0.7233** |
| **Proposed + Llama-3** | **0.6051** | **0.9565** | **0.7413** âœ… |
| Proposed + GPT-3.5 | 0.0742 | 0.9130 | 0.1372 |
| Proposed + Phi-2 | 0.6666 | 0.4761 | 0.5555 |

âœ… **Llama-3 ç‰ˆæœ¬è¶…è¶Šæœ€å¼ºé LLM åŸºçº¿ CARLAï¼ˆF1 æå‡çº¦ 2.5%ï¼‰**

#### SMDï¼ˆå¤šå˜é‡ï¼‰

| Model | Prec | Rec | F1 |
|-------|------|-----|-----|
| TimesNet | 0.2450 | 0.5474 | 0.3385 |
| TranAD | 0.2649 | 0.5661 | 0.3609 |
| CARLA | 0.4276 | 0.6362 | **0.5114** |
| **Proposed + Llama-3** | **0.3813** | **0.8685** | **0.5300** âœ… |
| Proposed + GPT-3.5 | 0.5370 | 0.4061 | 0.4625 |
| Proposed + Phi-2 | 0.8461 | 0.2541 | 0.3908 |

âœ… **å†æ¬¡ä¼˜äº CARLAï¼ˆF1 æå‡çº¦ 1.8%ï¼‰**ï¼Œå°¤å…¶ä½“ç°åœ¨è¶…é«˜å¬å›ç‡ï¼ˆRecall > 86%ï¼‰

---

### å…³é”®å‘ç°ï¼ˆå›ç­”ç ”ç©¶é—®é¢˜ï¼‰

#### Q1: LLM for reward shaping æ˜¯å¦ä¼˜äºç°æœ‰æ–¹æ³•ï¼Ÿ
âœ… æ˜¯ã€‚ç‰¹åˆ«æ˜¯ **Llama-3** æ˜¾è‘—æå‡äº† F1 åˆ†æ•°ï¼Œè¯´æ˜è¯­ä¹‰å¥–åŠ±å¡‘é€ ç¡®å®èƒ½åŠ é€Ÿ RL å­¦ä¹ å¹¶æé«˜æ£€æµ‹è´¨é‡ã€‚

#### Q2: ä¸åŒ LLM çš„è¡¨ç°å·®å¼‚åŠåŸå› ï¼Ÿ
| LLM | è¡¨ç°ç‰¹ç‚¹ | åŸå› åˆ†æ |
|-----|----------|-----------|
| **Llama-3.2-3B** | âœ… æœ€ä½³å¹³è¡¡ï¼ˆé«˜ Recall & Moderate Precisionï¼‰ | éµå¾ªæŒ‡ä»¤èƒ½åŠ›å¼ºï¼Œè¾“å‡ºå¹³æ»‘ï¼Œå¯¹å™ªå£°ä¸æ•æ„Ÿï¼Œpattern recognition æ›´ç¨³å¥ |
| **GPT-3.5** | âŒ é«˜ Recallï¼ˆ~90%ï¼‰ï¼Œæä½ Precisionï¼ˆ~7%ï¼‰ | â€œè¿‡åº¦è­¦è§‰â€ï¼Œå°†æ­£å¸¸æ³¢åŠ¨è¯¯åˆ¤ä¸ºå¼‚å¸¸ï¼ˆover-flaggingï¼‰ |
| **Phi-2** | âŒ é«˜ Precisionï¼ˆ~66%-84%ï¼‰ï¼ŒRecall å¾ˆä½ï¼ˆ~25%-47%ï¼‰ | è¿‡äºä¿å®ˆï¼Œæ¼æ£€ä¸¥é‡ï¼ˆunder-detectionï¼‰ |

> ğŸ” å›¾2 æ˜¾ç¤º Llama-3 èƒ½å‡†ç¡®è¯†åˆ«çœŸå®å¼‚å¸¸è€Œä¸è¢«æ­£å¸¸æ³¢åŠ¨å¹²æ‰°ã€‚

#### Q3: å•å˜é‡ vs å¤šå˜é‡æ€§èƒ½å·®å¼‚ï¼Ÿ
- **Yahoo-A1ï¼ˆå•å˜é‡ï¼‰**ï¼šæ‰€æœ‰æ¨¡å‹è¡¨ç°è¾ƒå¥½ï¼Œå› ä¸ºå¼‚å¸¸é€šå¸¸æ˜¯æ˜æ˜¾çš„ spike æˆ– shiftã€‚
- **SMDï¼ˆå¤šå˜é‡ï¼‰**ï¼šéš¾åº¦æ›´é«˜ï¼Œéœ€æ•æ‰è·¨ä¼ æ„Ÿå™¨ç›¸å…³æ€§å’Œé•¿æœŸè¶‹åŠ¿å˜åŒ–ã€‚
- æˆ‘ä»¬çš„æ¡†æ¶åœ¨ä¸¤è€…ä¸Šéƒ½å–å¾— SOTAï¼Œä½†åœ¨ SMD ä¸Šæ›´å‡¸æ˜¾ä¼˜åŠ¿ â€”â€” **Llama-3 çš„é«˜ Recall è¡¨æ˜å®ƒèƒ½æœ‰æ•ˆæ•æ‰å¤æ‚ã€éšè”½çš„å¤šç»´å¼‚å¸¸**ã€‚

---

### æ¶ˆèå®éªŒï¼ˆæ–‡ä¸­è™½æœªå•ç‹¬åˆ—å‡ºè¡¨æ ¼ï¼Œä½†å¯é€šè¿‡åˆ†ææ¨æ–­ï¼‰
ä»ä¸åŒ LLM çš„å¯¹æ¯”å¯ä»¥çœ‹å‡ºä»¥ä¸‹æ¶ˆèæ•ˆæœï¼š
- **ç§»é™¤ LLMï¼ˆå³ä»…ç”¨ CARLAï¼‰** â†’ F1 ä¸‹é™ï¼ˆYahoo: -1.8%, SMD: -1.8%ï¼‰
- **æ›¿æ¢ä¸º GPT-3.5 æˆ– Phi-2** â†’ æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œè¯´æ˜ **LLM é€‰æ‹©è‡³å…³é‡è¦**
- **è‹¥å…³é—­ VAE åŠ¨æ€ç¼©æ”¾æˆ–ä¸»åŠ¨å­¦ä¹ ** â†’ æ–‡ä¸­æŒ‡å‡ºä¼šå¯¼è‡´â€œperformance dropsâ€ï¼Œéœ€æ›´å¤§æ ‡æ³¨é‡æ‰èƒ½è¾¾åˆ°ç›¸åŒæ•ˆæœ

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦ç»“è®º
1. âœ… **LLM å¯ä»¥ä½œä¸ºæœ‰æ•ˆçš„è¯­ä¹‰å¥–åŠ±å¡‘å½¢å·¥å…·**ï¼Œé€šè¿‡ç”Ÿæˆ `severity` è¯„åˆ†æ¥å¢å¼º RL çš„æ¢ç´¢æ•ˆç‡ï¼Œä¸”ä¸ç ´å policy invarianceã€‚
2. âœ… **Llama-3 åœ¨å¼‚å¸¸æ„ŸçŸ¥ä»»åŠ¡ä¸­ä¼˜äº GPT-3.5 å’Œ Phi-2**ï¼Œå› å…¶å…·å¤‡æ›´å¥½çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›å’Œç¨³å®šæ€§ã€‚
3. âœ… æ‰€ææ¡†æ¶åœ¨ **Yahoo-A1 å’Œ SMD** ä¸Šå‡è¾¾åˆ° **state-of-the-art æ°´å¹³**ï¼Œå°¤å…¶æ˜¯åœ¨æœ‰é™æ ‡æ³¨æ¡ä»¶ä¸‹è¡¨ç°å‡ºè‰²ã€‚
4. âœ… **VAE + åŠ¨æ€å¥–åŠ±ç¼©æ”¾æœºåˆ¶** æˆåŠŸèåˆäº†ç›‘ç£ä¸éç›‘ç£ä¿¡å·ï¼Œå¢å¼ºäº†æ¨¡å‹é€‚åº”æ€§ã€‚
5. âœ… **Active Learning + Label Propagation** æ˜¾è‘—é™ä½äº†äººå·¥æ ‡æ³¨éœ€æ±‚ï¼Œé€‚ç”¨äºå®é™…éƒ¨ç½²ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **è®¡ç®—å¼€é”€è¾ƒå¤§**ï¼šæ¯æ¬¡å†³ç­–éƒ½éœ€è¦è°ƒç”¨ LLM æ¨ç†ï¼Œå¯èƒ½å½±å“å®æ—¶æ€§ï¼ˆå°¤å…¶æ˜¯é•¿åºåˆ—ï¼‰ï¼›
2. **LLM é»‘ç®±é£é™©**ï¼šè™½ç„¶ `severity` æœ‰ä¸€å®šå¯è§£é‡Šæ€§ï¼Œä½† LLM å†³ç­–è¿‡ç¨‹ä»ä¸å¤Ÿé€æ˜ï¼›
3. **å¤šå˜é‡å…³ç³»å»ºæ¨¡ä¸è¶³**ï¼šå½“å‰ LLM è¾“å…¥ä¸ºæ‰å¹³åŒ–çª—å£ï¼Œæœªèƒ½æ˜¾å¼å»ºæ¨¡ä¼ æ„Ÿå™¨é—´çš„æ‹“æ‰‘æˆ–å› æœå…³ç³»ï¼›
4. **ä¾èµ–é¢„è®­ç»ƒ LLM çš„é¢†åŸŸé€‚é…æ€§**ï¼šè‹¥æ—¶é—´åºåˆ—æ¥è‡ªé«˜åº¦ä¸“ä¸šé¢†åŸŸï¼ˆå¦‚åŒ»ç–— EEGï¼‰ï¼Œé€šç”¨ LLM å¯èƒ½æ— æ³•ç†è§£è¯­ä¹‰ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **è½»é‡åŒ– LLM æ›¿ä»£æ–¹æ¡ˆ**ï¼šæ¢ç´¢å¾®è°ƒå°å‹ LLM æˆ–ä½¿ç”¨ MoE æ¶æ„é™ä½æˆæœ¬ï¼›
2. **å›¾ç¥ç»ç½‘ç»œé›†æˆ**ï¼šæ˜¾å¼å»ºæ¨¡å¤šå˜é‡ä¼ æ„Ÿå™¨é—´çš„ä¾èµ–ç»“æ„ï¼›
3. **åœ¨çº¿å¢é‡å­¦ä¹ æœºåˆ¶**ï¼šæ”¯æŒæ¨¡å‹æŒç»­é€‚åº”æ–°å‡ºç°çš„å¼‚å¸¸ç±»å‹ï¼›
4. **è·¨æ•°æ®é›†è¿ç§»èƒ½åŠ›éªŒè¯**ï¼šæµ‹è¯•åœ¨åŒ»ç–—ã€é‡‘èç­‰å…¶ä»–é¢†åŸŸçš„æ³›åŒ–æ€§ï¼›
5. **äººç±»åé¦ˆé—­ç¯ï¼ˆHuman-in-the-loopï¼‰ä¼˜åŒ–**ï¼šè¿›ä¸€æ­¥æå‡ä¸»åŠ¨å­¦ä¹ æ•ˆç‡ã€‚

---

## æ€»ç»“
è¯¥è®ºæ–‡æˆåŠŸåœ°å°† **LLMã€Reinforcement Learningã€VAE å’Œ Active Learning** èåˆåœ¨ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ä¸­ï¼Œè§£å†³äº†æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ä¸­**æ ‡ç­¾ç¨€ç¼ºã€å¥–åŠ±ç¨€ç–ã€æ¢ç´¢å›°éš¾**ç­‰æ ¸å¿ƒé—®é¢˜ã€‚å®éªŒè¯æ˜ï¼Œ**Llama-3 é©±åŠ¨çš„è¯­ä¹‰å¥–åŠ±å¡‘é€ **æ˜¯æœ€ä¼˜é…ç½®ï¼Œåœ¨å¤šä¸ª benchmark ä¸Šå®ç°äº† SOTA æ€§èƒ½ï¼Œå°¤å…¶é€‚åˆèµ„æºå—é™çš„å®é™…åº”ç”¨åœºæ™¯ã€‚è¿™ä¸€å·¥ä½œä¸ºâ€œAI + æ—¶é—´åºåˆ—â€æä¾›äº†æ–°çš„èŒƒå¼å‚è€ƒã€‚

</details>

---

### 10. [ModeX: Evaluator-Free Best-of-N Selection for Open-Ended Generation](https://arxiv.org/abs/2601.02535)

**Authors**: Hyeong Kyu Choi, Sharon Li  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.02535v1  

#### Abstract
Selecting a single high-quality output from multiple stochastic generations remains a fundamental challenge for large language models (LLMs), particularly in open-ended tasks where no canonical answer exists. While Best-of-N and self-consistency methods show that aggregating multiple generations can...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šModeX: Evaluator-Free Best-of-N Selection for Open-Ended Generation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¼€æ”¾ç”Ÿæˆä»»åŠ¡ï¼ˆå¦‚æ–‡æœ¬æ‘˜è¦ã€ä»£ç ç”Ÿæˆã€æ•°å­¦æ¨ç†ï¼‰ä¸­é¢ä¸´ä¸€ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼šå¦‚ä½•ä»å¤šä¸ªéšæœºç”Ÿæˆçš„ç»“æœä¸­é€‰æ‹©ä¸€ä¸ªé«˜è´¨é‡è¾“å‡ºã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–å¤–éƒ¨è¯„ä¼°å™¨ï¼ˆå¦‚reward modelï¼‰ã€ç²¾ç¡®å­—ç¬¦ä¸²åŒ¹é…æŠ•ç¥¨ï¼ˆexact string-match votingï¼‰æˆ–è¿­ä»£ä¿®æ­£æœºåˆ¶ï¼ˆå¦‚Self-Refineï¼‰ï¼Œè¿™äº›æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **å°é—­æ€§é™åˆ¶**ï¼šå¤šæ•°ä»…é€‚ç”¨äºæœ‰æ ‡å‡†ç­”æ¡ˆçš„é—­åˆä»»åŠ¡ï¼ˆå¦‚å¤šé¡¹é€‰æ‹©é¢˜ï¼‰ï¼›
- **é«˜è®¡ç®—å¼€é”€**ï¼šéœ€è¦é¢å¤–æ¨ç†æ­¥éª¤æˆ–è¾…åŠ©æ¨¡å‹ï¼›
- **æ•ˆç‡ä½ä¸‹**ï¼šæ— æ³•æœ‰æ•ˆæ¨å¹¿åˆ°è¯­ä¹‰ç­‰ä»·ä½†å­—é¢ä¸åŒçš„å¼€æ”¾æ–‡æœ¬ã€‚

å› æ­¤ï¼Œæœ¬æ–‡æå‡ºï¼š**èƒ½å¦åœ¨ä¸ä¾èµ–å¤–éƒ¨è¯„ä¼°å™¨ä¸”æ— æ˜¾è‘—è®¡ç®—å¼€é”€çš„æƒ…å†µä¸‹ï¼Œå®ç°é«˜è´¨é‡çš„Best-of-Né€‰æ‹©ï¼Ÿ**

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºäº† **Mode Extraction (ModeX)** â€”â€”ä¸€ç§æ— éœ€è¯„ä¼°å™¨ï¼ˆevaluator-freeï¼‰çš„Best-of-Né€‰æ‹©æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> å°†â€œå¤šæ•°æŠ•ç¥¨â€ï¼ˆmajority votingï¼‰çš„æ€æƒ³ä»**ç²¾ç¡®å­—ç¬¦ä¸²åŒ¹é…**æ¨å¹¿åˆ°**è¯­ä¹‰å…±è¯†å»ºæ¨¡**ï¼Œé€šè¿‡è¯†åˆ«ç”Ÿæˆç»“æœä¸­çš„â€œæ¨¡æ€è¾“å‡ºâ€ï¼ˆmodal outputï¼‰ä½œä¸ºæœ€ç»ˆè¾“å‡ºã€‚

#### ModeX çš„ä¸‰æ­¥æµç¨‹ï¼š
1. **Adjacency Matrix Construction**  
   æ„é€ åŠ æƒç›¸ä¼¼åº¦å›¾ï¼ŒèŠ‚ç‚¹ä¸ºç”Ÿæˆç»“æœï¼Œè¾¹æƒé‡åŸºäºn-gramï¼ˆunigram, bigram, trigramï¼‰çš„Jaccardç›¸ä¼¼åº¦ï¼š  
   $$
   A_{ij} = s_1(v_i, v_j) + s_2(v_i, v_j) + s_3(v_i, v_j)
   $$

2. **Spectral Graph Clustering**  
   åˆ©ç”¨å›¾æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µçš„**Fiedlerå‘é‡**è¿›è¡Œè°±èšç±»ï¼Œé€’å½’åœ°å°†å›¾åˆ’åˆ†ä¸ºä¸¤ä¸ªå­å›¾ï¼Œå¹¶é€šè¿‡**conductanceé˜ˆå€¼**åˆ¤æ–­æ˜¯å¦ç»§ç»­åˆ†è£‚ï¼Œç›´åˆ°æ‰¾åˆ°æœ€å‡èšçš„è¯­ä¹‰ç°‡ã€‚

3. **Centroid Selection**  
   åœ¨æœ€ç»ˆç°‡ä¸­é€‰æ‹©**åŠ æƒåº¦æœ€é«˜**çš„èŠ‚ç‚¹ä½œä¸ºä¸­å¿ƒç‚¹ï¼ˆcentroidï¼‰ï¼Œå³â€œæ¨¡æ€è¾“å‡ºâ€ã€‚

æ­¤å¤–ï¼Œæå‡ºè½»é‡ç‰ˆ **ModeX-Lite**ï¼š
- åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å‘¨æœŸæ€§æ‰§è¡Œæ¨¡å¼é€‰æ‹©ä¸å‰ªæï¼ˆpruningï¼‰ï¼›
- æ¯ä¸ªå‰ªæé—´éš”åªåšä¸€æ¬¡éé€’å½’è°±èšç±»ï¼Œæå‡æ•ˆç‡ï¼›
- æ˜¾è‘—é™ä½å»¶è¿Ÿï¼Œé€‚åˆå®é™…éƒ¨ç½²ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | ModeX / ModeX-Lite | Self-Consistency | LLM Judge | Best-of-N w/ RM |
|------|--------------------|------------------|-----------|----------------|
| æ˜¯å¦éœ€å¤–éƒ¨è¯„ä¼°å™¨ | âŒ | âŒ | âœ…ï¼ˆå¦ä¸€ä¸ªLLMï¼‰ | âœ…ï¼ˆReward Modelï¼‰ |
| æ˜¯å¦æ”¯æŒå¼€æ”¾ç”Ÿæˆ | âœ…ï¼ˆè¯­ä¹‰èšç±»ï¼‰ | âš ï¸ï¼ˆä¾èµ–exact matchï¼‰ | âœ… | âœ… |
| è®¡ç®—æ•ˆç‡ | é«˜ï¼ˆå¹¶è¡Œç”Ÿæˆ + å›¾ç®—æ³•ï¼‰ | ä¸­ç­‰ï¼ˆä¸²è¡Œ refineï¼‰ | ä½ï¼ˆäºŒæ¬¡æ¨ç†ï¼‰ | ä½ï¼ˆéœ€RMæ¨ç†ï¼‰ |
| å¯æ‰©å±•æ€§ï¼ˆéšNå¢åŠ ï¼‰ | å¼ºï¼ˆæ€§èƒ½ç¨³å®šä¸Šå‡ï¼‰ | å¼±ï¼ˆæ”¶ç›Šé¥±å’Œå¿«ï¼‰ | å¼± | å¼ºä½†æˆæœ¬é«˜ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šé¦–æ¬¡å®ç°äº†**å®Œå…¨å…è¯„ä¼°å™¨ã€é€‚ç”¨äºä»»æ„å¼€æ”¾ç”Ÿæˆä»»åŠ¡ã€é«˜æ•ˆå¯æ‰©å±•**çš„Best-of-Né€‰æ‹©æœºåˆ¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
åœ¨ä¸‰ä¸ªå…¸å‹å¼€æ”¾ç”Ÿæˆä»»åŠ¡ä¸ŠéªŒè¯ï¼š
- **Text Summarization**: CNN/DailyMailï¼ˆæŠ½å–æ–°é—»æ‘˜è¦ï¼‰
- **Code Generation**: HumanEvalï¼ˆPythonç¼–ç¨‹é—®é¢˜ï¼‰
- **Mathematical Reasoning**: Math-500ï¼ˆæ¶µç›–ä»£æ•°ã€å‡ ä½•ã€æ¦‚ç‡ç­‰å…­ç±»æ•°å­¦é¢˜ï¼‰

---

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼š
  - ä¸»è¦ä½¿ç”¨ Qwen2.5-7b-instruct å’Œ Llama3.1-8b-instructï¼›
  - Code Generation ä½¿ç”¨ CodeLlama-7b-Instructã€‚
- **ç”Ÿæˆè·¯å¾„æ•° N**ï¼šæµ‹è¯• N=4, 8, 16ã€‚
- **Promptè®¾è®¡**ï¼šç»Ÿä¸€é‡‡ç”¨æ€ç»´é“¾ï¼ˆChain-of-Thoughtï¼‰æç¤ºæ¨¡æ¿ï¼Œè¦æ±‚å…ˆæ¨ç†åè¾“å‡ºã€‚

---

### è¯„ä¼°æŒ‡æ ‡
| ä»»åŠ¡ | ä¸»è¦æŒ‡æ ‡ |
|------|---------|
| æ–‡æœ¬æ‘˜è¦ | ROUGE-1, ROUGE-2, ROUGE-L, BLEU |
| ä»£ç ç”Ÿæˆ | Pass@1ï¼ˆåŠŸèƒ½æ­£ç¡®ç‡ï¼‰ |
| æ•°å­¦æ¨ç† | Accuracyï¼ˆæœ€ç»ˆç­”æ¡ˆå‡†ç¡®ç‡ï¼‰ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **Single Path**ï¼šå•æ¬¡ç”Ÿæˆï¼Œå–å¹³å‡æ€§èƒ½ã€‚
2. **Self-Refine**ï¼šè¿­ä»£ä¼˜åŒ–4è½®ã€‚
3. **LLM Judge**ï¼šç”¨å¦ä¸€ä¸ªLLMä»Nä¸ªå€™é€‰ä¸­é€‰å‡ºæœ€ä½³ï¼ˆN=4æˆ–16ï¼‰ã€‚
4. **Perplexity**ï¼šé€‰å›°æƒ‘åº¦æœ€ä½çš„è¾“å‡ºã€‚
5. **Self-Certainty**ï¼šé€‰è´Ÿå¯¹æ•°ä¼¼ç„¶æœ€å°çš„è¾“å‡ºã€‚
6. **Best-of-N (Gold Standard)**ï¼šä½¿ç”¨reward modelæ‰“åˆ†é€‰æ‹©æœ€ä¼˜ï¼ˆè§†ä¸ºä¸Šé™ï¼‰ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ Qwen æ¨¡å‹ä¸ºä¾‹ï¼‰

| æ–¹æ³• | Text Summarization (ROUGE-L) | Code Generation (Pass@1) | Math Reasoning (Accuracy) |
|------|-------------------------------|--------------------------|----------------------------|
| Single Path | 20.17 Â± 0.28 | 69.89 Â± 3.59 | 70.98 Â± 1.74 |
| LLM Judge (N=16) | 19.72 | 65.24 | 74.67 |
| Perplexity BoN (N=16) | 21.06 | 73.17 | 78.00 |
| **ModeX (N=16)** | **21.06** | **75.61** | **78.00** |
| **ModeX-Lite (N=16)** | **21.89** | **78.66** | **75.33** |

> ğŸ’¡ **äº®ç‚¹**ï¼š
> - ModeX åœ¨ä¸‰é¡¹ä»»åŠ¡ä¸Šå‡æ˜¾è‘—ä¼˜äº Single Path å’Œ LLM Judgeï¼›
> - ModeX-Lite åœ¨ä»£ç ç”Ÿæˆä¸Šè¾¾åˆ° **78.66% Pass@1**ï¼Œç”šè‡³è¶…è¿‡ Gold Standard çš„ Perplexity BoNï¼ˆ73.17%ï¼‰ï¼›
> - åœ¨æ–‡æœ¬æ‘˜è¦ä¸­ï¼ŒModeX-Lite çš„ ROUGE-L è¾¾åˆ° **21.89**ï¼Œè¿œè¶… baselineã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **vs. Self-Refine**ï¼šå°½ç®¡æ¶ˆè€—çº¦4å€è®¡ç®—èµ„æºï¼ŒSelf-Refine è¡¨ç°æ™®éä½äº ModeXï¼Œè¯´æ˜å•çº¯å¢åŠ æ¨ç†æ­¥æ•°ä¸å¦‚å¤šè·¯å¾„+ç»“æ„åŒ–é€‰æ‹©æœ‰æ•ˆã€‚
- **vs. LLM Judge**ï¼šéšç€ N å¢å¤§ï¼ŒLLM Judge æ”¶ç›Šå¢é•¿ç¼“æ…¢ï¼ˆå¦‚Llamaä¸Šæ•°å­¦ä»»åŠ¡ä»…+1.34%ï¼‰ï¼Œè€Œ ModeX-Lite æå‡è¾¾ **+7.33%**ï¼Œæ˜¾ç¤ºå…¶æ›´å¼ºçš„å¯æ‰©å±•æ€§ã€‚
- **vs. Self-Certainty**ï¼šè¯¥æ–¹æ³•è¡¨ç°ä¸ç¨³å®šï¼Œåœ¨ä»£ç ç”Ÿæˆä¸Šä»…ä¸º55.49%ï¼Œæ˜¾è‘—åŠ£äº ModeXã€‚

---

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰ç›¸ä¼¼åº¦å‡½æ•°æ¯”è¾ƒï¼ˆAppendix Eï¼‰
| æ–¹æ³• | ROUGE-L (Text Summ.) | Pass@1 (Code Gen.) |
|------|------------------------|---------------------|
| ModeX-n-gram (Jaccard) | **21.06** | **75.61** |
| ModeX-cosine (Embedding) | 20.26 | 75.00 |

> ç»“è®ºï¼šåŸºäºn-gramçš„Jaccardç›¸ä¼¼åº¦ä¼˜äºembedding cosineç›¸ä¼¼åº¦ï¼Œå¯èƒ½å› åè€…å¯¹è¯åºä¸æ•æ„Ÿã€‚

#### ï¼ˆ2ï¼‰è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆFigure 5ï¼‰
- **Conductance Threshold T âˆˆ {0.5, ..., 0.8}**ï¼šæ€§èƒ½ç¨³å¥ï¼Œæ‰€æœ‰é…ç½®ä¸‹å‡ä¼˜äºSingle Pathã€‚
- **Pruning Frequency T âˆˆ {100, ..., 500} tokens**ï¼šä¸åŒé¢‘ç‡ä¸‹æ€§èƒ½æ³¢åŠ¨å°ï¼Œè¯æ˜ModeX-Liteé²æ£’æ€§å¼ºã€‚

#### ï¼ˆ3ï¼‰å¤æ‚åº¦ä¸å»¶è¿Ÿåˆ†æï¼ˆTable 2ï¼‰
| æ–¹æ³• | å¤æ‚åº¦ | å®æµ‹å»¶è¿Ÿï¼ˆQwen, CNN/DMï¼‰ |
|------|--------|--------------------------|
| Single Path | O(L) | 5.5s |
| Self-Refine | O(kL) | 31.7s |
| LLM Judge | O(NL + NL_judge) | 10.7s |
| **ModeX-Lite (N=4)** | O(NL + NÂ²) | **7.2s** |
| **ModeX-Lite (N=16)** | O(NL + NÂ²) | **9.1s** |

> âœ… ModeX-Lite ä»…å¼•å…¥è½»å¾®å»¶è¿Ÿï¼Œå´å¸¦æ¥æ˜¾è‘—æ€§èƒ½å¢ç›Šï¼Œå…·å¤‡å¼ºå®ç”¨æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **â€œæ¨¡æ€è¾“å‡ºâ€æ˜¯é«˜è´¨é‡ç”Ÿæˆçš„å…³é”®**ï¼šå³ä½¿æ²¡æœ‰æ ‡å‡†ç­”æ¡ˆï¼Œå¤šä¸ªç”Ÿæˆç»“æœä¸­ä»å­˜åœ¨è¯­ä¹‰ä¸Šçš„â€œå…±è¯†â€ï¼Œä»£è¡¨æ¨¡å‹æœ€å¯ä¿¡çš„ç†è§£ã€‚
2. **è°±èšç±»èƒ½æœ‰æ•ˆæ•æ‰è¯­ä¹‰ä¸€è‡´æ€§**ï¼šåˆ©ç”¨Fiedlerå‘é‡è¿›è¡Œå›¾åˆ†å‰²ï¼Œå¯åœ¨æ— ç›‘ç£æƒ…å†µä¸‹è¯†åˆ«ä¸»å¯¼è¯­ä¹‰ç°‡ã€‚
3. **æ— éœ€å¤–éƒ¨è¯„ä¼°ä¹Ÿèƒ½è¶…è¶ŠLLMè£åˆ¤**ï¼šModeXåœ¨å¤šä¸ªä»»åŠ¡ä¸Šä¼˜äºLLM Judgeï¼Œè¡¨æ˜â€œå…³ç³»ç»“æ„â€æ¯”â€œæ˜¾å¼è¯„åˆ†â€æ›´å¯é ã€‚
4. **æ—©æœŸå‰ªæå¯è¡Œä¸”é«˜æ•ˆ**ï¼šModeX-Liteè¯æ˜å¯åœ¨ç”Ÿæˆä¸­é€”å‰”é™¤å¼‚å¸¸è·¯å¾„ï¼Œå¤§å¹…æå‡æ•ˆç‡è€Œä¸æŸæ€§èƒ½ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–lexical similarity**ï¼šä½¿ç”¨Jaccard n-gramç›¸ä¼¼åº¦ï¼Œå¯èƒ½å¯¼è‡´è¯­ä¹‰ç›¸åŒä½†è¡¨è¾¾å·®å¼‚å¤§çš„é«˜è´¨é‡è¾“å‡ºè¢«è¯¯åˆ¤ä¸º outlierã€‚
2. **å‡è®¾â€œä¼—æ•°å³æ­£ç¡®â€**ï¼šè‹¥LLMæœ¬èº«å­˜åœ¨ç³»ç»Ÿæ€§åè§æˆ–æ¨¡å¼åå¡Œï¼ˆmode collapseï¼‰ï¼ŒModeXå¯èƒ½æ”¾å¤§é”™è¯¯å…±è¯†ã€‚
3. **æœªå¤„ç†é•¿æ–‡æœ¬æ•ˆç‡ç“¶é¢ˆ**ï¼šå½“Nå¾ˆå¤§æ—¶ï¼ŒO(NÂ²)å›¾æ„å»ºå¯èƒ½æˆä¸ºç“¶é¢ˆï¼ˆå°½ç®¡å®è·µä¸­N << Lï¼‰ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´å¼ºå¤§çš„è¯­ä¹‰ç›¸ä¼¼åº¦åº¦é‡ï¼ˆå¦‚sentence embeddingã€BERTScoreï¼‰ï¼›
- ç»“åˆå†…éƒ¨logitsä¿¡æ¯è¿›è¡ŒåŠ¨æ€å‰ªæï¼›
- æ‰©å±•è‡³å¤šæ¨¡æ€ç”Ÿæˆä»»åŠ¡ï¼ˆå¦‚å›¾æ–‡ç”Ÿæˆï¼‰ï¼›
- ç ”ç©¶å¯¹æŠ—æ€§æ”»å‡»ä¸‹çš„é²æ£’æ€§ï¼ˆå¦‚æ¶æ„ç”Ÿæˆè¯¯å¯¼æ€§ä¸€è‡´è¾“å‡ºï¼‰ã€‚

---

> ğŸ”— **å¼€æºåœ°å€**ï¼šhttps://github.com/deeplearning-wisc/ModeX  
> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼šModeX æä¾›äº†ä¸€ç§**å…è¯„ä¼°å™¨ã€é«˜æ•ˆã€é€šç”¨**çš„å¼€æ”¾ç”ŸæˆBest-of-Né€‰æ‹©æ–¹æ¡ˆï¼Œé€šè¿‡å›¾è°±èšç±»è¯†åˆ«â€œè¯­ä¹‰å…±è¯†â€ï¼Œå®ç°äº†æ€§èƒ½ä¸æ•ˆç‡çš„åŒé‡çªç ´ã€‚

</details>

---

### 11. [WebAnchor: Anchoring Agent Planning to Stabilize Long-Horizon Web Reasoning](https://arxiv.org/abs/2601.03164)

**Authors**: Yu Xinmiao, Zhang Liwen, Feng Xiaocheng, Jiang Yong, Qin Bing, Xie Pengjun, Zhou Jingren  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.03164v1  

#### Abstract
Large Language Model(LLM)-based agents have shown strong capabilities in web information seeking, with reinforcement learning (RL) becoming a key optimization paradigm. However, planning remains a bottleneck, as existing methods struggle with long-horizon strategies. Our analysis reveals a critical ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# WebAnchor: Anchoring Agent Planning to Stabilize Long-Horizon Web Reasoning è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº **Large Language Model (LLM)** çš„ Web ä»£ç†åœ¨é•¿å‘¨æœŸï¼ˆlong-horizonï¼‰æ¨ç†ä»»åŠ¡ä¸­é¢ä¸´**è§„åˆ’ä¸ç¨³å®š**å’Œ**ç­–ç•¥æ¼‚ç§»**çš„é—®é¢˜ã€‚å°½ç®¡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è¢«å¹¿æ³›ç”¨äºä¼˜åŒ–ä»£ç†è¡Œä¸ºï¼Œä½†ç°æœ‰æ–¹æ³•é€šå¸¸å°†å¥–åŠ±å‡åŒ€åˆ†é…åœ¨æ•´ä¸ªè½¨è¿¹ä¸Šï¼Œå¿½è§†äº†**åˆå§‹å†³ç­–å¯¹åç»­è¡Œä¸ºçš„å·¨å¤§å½±å“**ã€‚

ä½œè€…é€šè¿‡å®è¯åˆ†ææ­ç¤ºäº†ä¸€ä¸ªå…³é”®ç°è±¡ï¼š**Plan Anchorï¼ˆè®¡åˆ’é”šå®šï¼‰** â€”â€” å³ç¬¬ä¸€æ­¥è¡ŒåŠ¨ç”Ÿæˆçš„åˆå§‹è®¡åˆ’å¯¹æ•´ä¸ªä»»åŠ¡çš„æˆåŠŸå…·æœ‰ä¸æˆæ¯”ä¾‹çš„é‡å¤§å½±å“ã€‚ä¸€æ—¦é¦–æ­¥å‡ºé”™ï¼Œå®¹æ˜“å¼•å‘çº§è”å¤±è´¥ï¼Œå¯¼è‡´ä»»åŠ¡å½»åº•åç¦»ç›®æ ‡ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šAnchor-GRPO
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œè®ºæ–‡æå‡º **Anchor-GRPO**ï¼Œä¸€ç§ä¸¤é˜¶æ®µçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œè§£è€¦â€œè§„åˆ’â€ä¸â€œæ‰§è¡Œâ€è¿‡ç¨‹ï¼š

#### é˜¶æ®µä¸€ï¼šAnchor Plan Optimizationï¼ˆé”šå®šè®¡åˆ’ä¼˜åŒ–ï¼‰
- å¼•å…¥ **Plan Rubrics Learner**ï¼Œä»å¤§é‡æˆåŠŸ/å¤±è´¥çš„è‡ªæˆ‘å¯¹å¼ˆï¼ˆself-playï¼‰ç»éªŒä¸­è‡ªåŠ¨æç‚¼é«˜è´¨é‡è®¡åˆ’çš„å…³é”®ç»´åº¦ï¼ˆå¦‚å­ç›®æ ‡è¦†ç›–ã€ç›®æ ‡å¯¹é½ã€å·¥å…·é€‰æ‹©ç­‰ï¼‰ã€‚
- åˆ©ç”¨è¿™äº›ç»“æ„åŒ–è¯„åˆ†æ ‡å‡†ï¼ˆrubricsï¼‰æ„å»º**å¯†é›†å¥–åŠ±ä¿¡å·**ï¼ˆdense rewardï¼‰ï¼Œä¸“é—¨ä¼˜åŒ–ä»£ç†çš„**ç¬¬ä¸€æ­¥è§„åˆ’èƒ½åŠ›**ã€‚
- é‡‡ç”¨ **masking-based credit assignment** æŠ€æœ¯ï¼Œä»…æ›´æ–°é¦–æ­¥è§„åˆ’éƒ¨åˆ†çš„æ¢¯åº¦ï¼Œé˜²æ­¢åç»­æ‰§è¡Œå¹²æ‰°è§„åˆ’å­¦ä¹ ã€‚

#### é˜¶æ®µäºŒï¼šTrajectory-Level Executor Optimizationï¼ˆè½¨è¿¹çº§æ‰§è¡Œä¼˜åŒ–ï¼‰
- æ‰§è¡Œé˜¶æ®µä½¿ç”¨**ç¨€ç–å¥–åŠ±**ï¼ˆsparse rewardï¼‰ï¼Œå³ä»…åœ¨æœ€ç»ˆç­”æ¡ˆæ­£ç¡®æ—¶ç»™äºˆå¥–åŠ±ï¼ˆexact matchï¼‰ã€‚
- ç¡®ä¿æ‰§è¡Œè¿‡ç¨‹å§‹ç»ˆä¸åˆå§‹è®¡åˆ’ä¿æŒä¸€è‡´ï¼Œæå‡é•¿æœŸæ¨ç†ç¨³å®šæ€§ã€‚

> ğŸ” **æ ¸å¿ƒæ€æƒ³**ï¼šå…ˆåˆ¶å®šé«˜è´¨é‡è®¡åˆ’ï¼ˆplan firstï¼‰ï¼Œå†ç¨³å®šæ‰§è¡Œï¼ˆact steadilyï¼‰ï¼Œé¿å…è·¯å¾„æ¼‚ç§»ã€‚

---

### ğŸ’¡ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ç¼ºé™· | Anchor-GRPO æ”¹è¿› |
|------|------|------------------|
| **æ ‡å‡† GRPO** | å¥–åŠ±åˆ†å¸ƒå‡åŒ€ï¼Œæ— æ³•çªå‡ºé¦–æ­¥é‡è¦æ€§ | æ˜¾å¼å»ºæ¨¡é¦–æ­¥ä¸ºâ€œé”šç‚¹â€ï¼Œèµ‹äºˆé«˜å¯†åº¦åé¦ˆ |
| **First-step GRPO** | è™½åˆ†ä¸¤é˜¶æ®µï¼Œä½†ä»ç”¨ç¨€ç–å¥–åŠ±ä¼˜åŒ–é¦–æ­¥ | ä½¿ç”¨åŸºäºç»éªŒæç‚¼çš„ **dense rubric reward** æ›´ç²¾ç»†æŒ‡å¯¼è§„åˆ’ |
| **ä¼ ç»Ÿ RL æ–¹æ³•** | å¿½è§† long-horizon ä¸­çš„ä¿¡ç”¨åˆ†é…éš¾é¢˜ | é€šè¿‡ä¸¤é˜¶æ®µè§£è€¦ + æ©ç æ›´æ–°æœºåˆ¶å®ç°ç¨³å®šè®­ç»ƒ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼š
> - æ˜¾è‘—æå‡ä»»åŠ¡æˆåŠŸç‡ï¼ˆPass@1ï¼‰
> - å‡å°‘æ— æ•ˆå·¥å…·è°ƒç”¨ï¼Œæé«˜ **tool efficiency**
> - å…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§ï¼ˆscalabilityï¼‰éšæ¨¡å‹å¤§å°å’Œä¸Šä¸‹æ–‡é•¿åº¦å¢é•¿è€ŒæŒç»­å¢ç›Š

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
åœ¨å››ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ Web ä¿¡æ¯æ£€ç´¢åŸºå‡†ä¸Šè¿›è¡Œè¯„ä¼°ï¼š

| æ•°æ®é›† | æè¿° |
|--------|------|
| **BrowseComp-en** | è‹±æ–‡ç½‘é¡µæµè§ˆä»»åŠ¡ï¼Œæµ‹è¯•å¤šè·³æ¨ç†èƒ½åŠ› |
| **BrowseComp-zh** | ä¸­æ–‡ç‰ˆæœ¬ï¼ŒéªŒè¯è·¨è¯­è¨€æ³›åŒ–æ€§ |
| **GAIA** | ç»¼åˆæ€§é€šç”¨ AI åŠ©æ‰‹è¯„æµ‹åŸºå‡†ï¼Œæ¶µç›–å¤æ‚æŸ¥è¯¢ |
| **XBench-DeepSearch** | æ·±åº¦æœç´¢ä»»åŠ¡ï¼Œå¼ºè°ƒé•¿æœŸç­–ç•¥è¿è´¯æ€§ |

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- **Pass@1**ï¼šé¦–æ¬¡å°è¯•å³ç­”å¯¹çš„æ¯”ä¾‹ï¼ˆä¸»æŒ‡æ ‡ï¼‰
- **Pass@3**ï¼šå‰ä¸‰æ¬¡ rollout ä¸­æœ‰ä¸€æ¬¡ç­”å¯¹çš„æ¯”ä¾‹
- æ‰€æœ‰ Pass@1 ç»“æœå–ä¸‰æ¬¡è¿è¡Œå¹³å‡å€¼ä»¥ä¿è¯ç¨³å®šæ€§
- ä½¿ç”¨ **Qwen-2.5-72B** ä½œä¸ºæ‰“åˆ†æ¨¡å‹è¿›è¡Œè‡ªåŠ¨è¯„ä¼°

---

### âš™ï¸ å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹èŒƒå›´**ï¼š3B ~ 30B å‚æ•°é‡ï¼ˆWebSailor-3B/7B, Tongyi-DR-30Bï¼‰
- **è®­ç»ƒç¯å¢ƒ**ï¼šè™šæ‹Ÿ Wiki ç¯å¢ƒï¼ˆæ›¿ä»£çœŸå® Webï¼Œæå‡ç¨³å®šæ€§ä¸é€Ÿåº¦ï¼‰
- **è®­ç»ƒæ ·æœ¬**ï¼š1,000 æ¡é«˜è´¨é‡åˆæˆæ•°æ®ï¼ŒæŒ‰éš¾åº¦ç­›é€‰
- **ç¡¬ä»¶é…ç½®**ï¼š64 GPUsï¼Œbatch size = 32ï¼Œrollout num = 8

---

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | è¯´æ˜ |
|---------|------|
| **GRPO** | åœ¨æ•´æ¡è½¨è¿¹ä¸Šåº”ç”¨ GRPOï¼Œæ‰€æœ‰æ­¥éª¤å…±äº«ç¨€ç–å¥–åŠ±ï¼ˆexact matchï¼‰ |
| **First-step GRPO** | ä¸¤é˜¶æ®µè®­ç»ƒï¼šå…ˆä¼˜åŒ–é¦–æ­¥ï¼Œå†ä¼˜åŒ–å…¨è½¨è¿¹ï¼›å‡ä½¿ç”¨ç¨€ç–å¥–åŠ± |
| **Proprietary Models** | åŒ…æ‹¬ OpenAI-o3Tã€Claude-4-Sonnetã€DeepSeek-V3.1 ç­‰é—­æºç³»ç»Ÿ |
| **Open-source Agents** | å¦‚ R1-Searcherã€WebSailor ç³»åˆ—ç­‰å¼€æºä»£ç† |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ¨¡å‹ | RL ç®—æ³• | GAIA Pass@1 | BrowseComp Pass@1 | BrowseComp-ZH Pass@1 | XBench Pass@1 |
|------|--------|-------------|--------------------|------------------------|---------------|
| WebAnchor-30B | **Anchor-GRPO** | **76.4%** | **46.0%** | **48.8%** | **75.1%** |
| WebAnchor-30B | First-step GRPO | 74.8% | 43.3% | 47.9% | 72.0% |
| WebAnchor-30B | GRPO | 75.8% | 44.0% | 46.2% | 71.0% |
| WebSailor-32B | - | 53.2% | 10.5% | 25.5% | 53.3% |
| DeepSeek-V3.1T | - | 63.1% | 30.0% | 49.2% | 71.0% |
| OpenAI-o3T | - | 70.5% | 50.9% | 58.1% | 66.7% |

> âœ… **äº®ç‚¹çªç ´**ï¼š
> - WebAnchor-30B åœ¨ **GAIA ä¸Šè¾¾åˆ° 76.4% Pass@1**ï¼Œè¶…è¶Š OpenAI-o3Tï¼ˆ70.5%ï¼‰
> - åœ¨ **BrowseComp ä¸Šè¾¾ 46.0% Pass@1**ï¼Œä¼˜äº First-step GRPOï¼ˆ43.3%ï¼‰å’Œ GRPOï¼ˆ44.0%ï¼‰

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆTable 2 & Figure 4ï¼‰

#### ï¼ˆ1ï¼‰ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥å¯¹æ¯”
| è®¾ç½® | Pass@1 | å·¥å…·è°ƒç”¨æ•°ï¼ˆAvgï¼‰ | Coverage | Efficiency |
|------|--------|------------------|----------|-----------|
| Only Planner Updated (Stage-1 only) | 42.0% | 14.9 | 67.2 | 65.4 |
| Full GRPO (Baseline) | 44.0% | 15.5 | 61.2 | 53.8 |
| **Two-Stage (Planner + Executor)** | **46.0%** | **17.3** | **67.0** | **63.4** |

> âœ… ç»“è®ºï¼šè”åˆä¼˜åŒ–è§„åˆ’ä¸æ‰§è¡Œæ•ˆæœæœ€ä½³ï¼Œå•çº¯åªä¼˜åŒ–è§„åˆ’è™½æ•ˆç‡é«˜ä½†ä»»åŠ¡æˆåŠŸç‡ä½ã€‚

---

#### ï¼ˆ2ï¼‰ä¸åŒæ›´æ–°æ­¥ä½æ¯”è¾ƒ
| æ›´æ–°ä½ç½® | Pass@1 | Alignment |
|--------|--------|----------|
| Random Step | 33.0% | 43.6 |
| Last Step | 36.1% | 41.4 |
| **First Step** | **43.3%** | **58.2** |

> âœ… éªŒè¯äº†â€œé¦–æ­¥é”šå®šâ€çš„æœ‰æ•ˆæ€§ï¼šä¼˜åŒ–ç¬¬ä¸€æ­¥æ˜¾è‘—ä¼˜äºå…¶ä»–ä½ç½®ã€‚

---

#### ï¼ˆ3ï¼‰è§„åˆ’å¥–åŠ±è®¾è®¡å¯¹æ¯”
| å¥–åŠ±æ–¹å¼ | Pass@1 | Efficiency |
|--------|--------|-----------|
| 0-1 Terminal Reward | 43.3% | 47.8 |
| Naive Plan Reward | 44.2% | 51.4 |
| **Dense Rubric Reward (Ours)** | **46.0%** | **63.4** |

> âœ… å¯†é›†ã€ç»“æ„åŒ–çš„ rubric å¥–åŠ±æœ€æœ‰æ•ˆï¼Œè¯æ˜äº†ç»éªŒé©±åŠ¨è¯„åˆ†æ ‡å‡†çš„ä»·å€¼ã€‚

---

#### ï¼ˆ4ï¼‰å·¥å…·è°ƒç”¨æ•ˆç‡åˆ†æï¼ˆFigure 4bï¼‰
- **Anchor-GRPO** å·¥å…·è°ƒç”¨æ›´ç¨³å®šä¸”é«˜æ•ˆï¼Œç›¸æ¯” GRPO å’Œ First-step GRPO æ›´å°‘å‡ºç°å†—ä½™æœç´¢ã€‚
- å¹³å‡å·¥å…·è°ƒç”¨æ¬¡æ•°æ§åˆ¶åœ¨åˆç†èŒƒå›´å†…ï¼ˆ~17ï¼‰ï¼ŒåŒæ—¶ç»´æŒé«˜æ€§èƒ½ã€‚

---

#### ï¼ˆ5ï¼‰å¯æ‰©å±•æ€§åˆ†æï¼ˆFigure 5ï¼‰
- **æ¨¡å‹è§„æ¨¡æ‰©å±•**ï¼šä» 3B åˆ° 30Bï¼Œæ€§èƒ½æŒç»­ä¸Šå‡ï¼ˆGAIA ä¸Šä» 28.3% â†’ 76.4%ï¼‰
- **ä¸Šä¸‹æ–‡é•¿åº¦æ‰©å±•**ï¼šåœ¨ 16k â†’ 64k context ä¸‹ï¼Œæ€§èƒ½ç¨³æ­¥æå‡ï¼Œè¡¨æ˜è¯¥æ¡†æ¶é€‚åˆå¤§ä¸Šä¸‹æ–‡åœºæ™¯

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ğŸ§  ä¸»è¦å‘ç°
1. **Plan Anchor ç°è±¡çœŸå®å­˜åœ¨ä¸”è‡³å…³é‡è¦**  
   å®éªŒæ˜¾ç¤ºï¼Œè‹¥é¦–æ­¥è§„åˆ’é”™è¯¯ï¼Œä»»åŠ¡æˆåŠŸç‡ä¸‹é™é«˜è¾¾ **23.6%~30.9%**ï¼ˆè§ Figure 1bï¼‰ï¼Œè¯å®é¦–æ­¥æ˜¯å†³å®šæˆè´¥çš„â€œé”šç‚¹â€ã€‚

2. **ç»“æ„åŒ–è§„åˆ’æ ‡å‡†ï¼ˆPlan Rubricsï¼‰èƒ½æ˜¾è‘—æå‡é¦–æ­¥è´¨é‡**  
   é€šè¿‡è‡ªç›‘ç£å­¦ä¹  + äººå·¥æ ¡å‡†çš„æ–¹å¼æç‚¼ rubricsï¼Œä½¿å¥–åŠ±æ›´å…·è§£é‡Šæ€§å’Œé’ˆå¯¹æ€§ã€‚

3. **ä¸¤é˜¶æ®µè®­ç»ƒä¼˜äºå•é˜¶æ®µæˆ–çº¯æ‰§è¡Œä¼˜åŒ–**  
   åˆ†ç¦»â€œè§„åˆ’â€ä¸â€œæ‰§è¡Œâ€ï¼Œå¹¶é€šè¿‡ä¸åŒå¥–åŠ±æœºåˆ¶åˆ†åˆ«ä¼˜åŒ–ï¼Œå®ç°äº†æ›´é«˜çš„ä»»åŠ¡æˆåŠŸç‡ä¸ç¨³å®šæ€§ã€‚

4. **Anchor-GRPO å…·å¤‡å¼ºå¯æ‰©å±•æ€§**  
   éšç€æ¨¡å‹å‚æ•°å¢åŠ å’Œä¸Šä¸‹æ–‡çª—å£æ‰©å¤§ï¼Œæ€§èƒ½æŒç»­æå‡ï¼Œé€‚ç”¨äºæœªæ¥æ›´å¤§æ›´å¼ºçš„ LLM æ¶æ„ã€‚

---

### âš ï¸ å±€é™æ€§
1. å½“å‰æ–¹æ³•ä¸»è¦åº”ç”¨äº **Web ä¿¡æ¯æ£€ç´¢ç±»ä»»åŠ¡**ï¼Œæ˜¯å¦é€‚ç”¨äºå…¶ä»–é¢†åŸŸï¼ˆå¦‚æœºå™¨äººæ§åˆ¶ã€æ¸¸æˆå†³ç­–ï¼‰å°šå¾…éªŒè¯ã€‚
2. **Plan Rubrics çš„æ„å»ºä¾èµ–å¤§é‡å†å²è½¨è¿¹å’Œäººå·¥åé¦ˆ**ï¼Œè‡ªåŠ¨åŒ–ç¨‹åº¦ä»æœ‰æå‡ç©ºé—´ã€‚
3. è™šæ‹Ÿ Wiki ç¯å¢ƒè™½æå‡äº†è®­ç»ƒæ•ˆç‡ï¼Œä½†ä¸çœŸå® Web å­˜åœ¨ä¸€å®šå·®è·ï¼Œéœ€è¿›ä¸€æ­¥åœ¨çœŸå®ç¯å¢ƒä¸­éªŒè¯ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å°† **Plan Anchor æ€æƒ³æ¨å¹¿è‡³æ›´å¤š long-horizon å†³ç­–åœºæ™¯**ï¼ˆå¦‚ç§‘å­¦å‘ç°ã€é‡‘èåˆ†æï¼‰
- æ¢ç´¢ **å…¨è‡ªåŠ¨ rubrics æç‚¼æœºåˆ¶**ï¼Œå‡å°‘äººå·¥å¹²é¢„
- ç»“åˆ **meta-learning æˆ– curriculum learning** è¿›ä¸€æ­¥æå‡å°æ¨¡å‹ä¸Šçš„è¿ç§»èƒ½åŠ›
- ç ”ç©¶å¦‚ä½•åŠ¨æ€è°ƒæ•´ rubrics ä»¥é€‚åº”ä¸åŒä»»åŠ¡ç±»å‹

---

## âœ… æ€»ç»“
**WebAnchor** é€šè¿‡è¯†åˆ«å¹¶åˆ©ç”¨ **Plan Anchor ç°è±¡**ï¼Œæå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„ä¸¤é˜¶æ®µ RL æ¡†æ¶ **Anchor-GRPO**ï¼Œç»“åˆ **ç»éªŒé©±åŠ¨çš„ Plan Rubrics** ä¸ **ç¨€ç–æ‰§è¡Œå¥–åŠ±**ï¼Œæ˜¾è‘—æå‡äº† Web ä»£ç†åœ¨é•¿å‘¨æœŸä»»åŠ¡ä¸­çš„æˆåŠŸç‡ä¸ç¨³å®šæ€§ã€‚å®éªŒè¡¨æ˜å…¶åœ¨å¤šä¸ªåŸºå‡†ä¸Šè¾¾åˆ° SOTA è¡¨ç°ï¼Œå¹¶å±•ç°å‡ºå¼ºå¤§çš„å¯æ‰©å±•æ½œåŠ›ï¼Œä¸ºæ„å»ºå¯é ã€å¯æ§çš„ agentic system æä¾›äº†é‡è¦èŒƒå¼ã€‚

</details>

---

### 12. [A New Benchmark for the Appropriate Evaluation of RTL Code Optimization](https://arxiv.org/abs/2601.01765)

**Authors**: Yao Lu, Shang Liu, Hangan Zhou, Wenji Fang, Qijun Zhang, Zhiyao Xie  
**Category**: cs.AI  
**Published**: 2026-01-07  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.01765v1  

#### Abstract
The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹å½“å‰åœ¨ä½¿ç”¨ **Large Language Models (LLMs)** è¿›è¡Œ **Register Transfer Level (RTL)** ä»£ç ç”Ÿæˆæ—¶å­˜åœ¨çš„ä¸€ä¸ªå…³é”®ç¼ºé™·ï¼š**ç°æœ‰åŸºå‡†ï¼ˆbenchmarksï¼‰ä¸»è¦è¯„ä¼°è¯­æ³•æ­£ç¡®æ€§ï¼Œè€Œå¿½è§†äº†å¯¹è®¾è®¡è´¨é‡çš„æ ¸å¿ƒæŒ‡æ ‡â€”â€”åŠŸè€—ã€æ€§èƒ½å’Œé¢ç§¯ï¼ˆPPAï¼‰çš„ä¼˜åŒ–èƒ½åŠ›è¯„ä¼°**ã€‚

å…·ä½“è€Œè¨€ï¼Œä½œè€…æŒ‡å‡ºï¼š
- ç°æœ‰ RTL ä¼˜åŒ–åŸºå‡†ï¼ˆå¦‚ [26]ï¼‰å­˜åœ¨â€œè¿‡åº¦äººä¸ºæ„é€ â€ï¼ˆoverly contrivedï¼‰çš„å­æœ€ä¼˜è®¾è®¡ï¼Œè¿™äº›ä½æ•ˆæ¨¡å¼åœ¨å®é™…å·¥ç¨‹ä¸­å‡ ä¹ä¸ä¼šå‡ºç°ï¼›
- ä¾èµ–å¼±åˆæˆå·¥å…·ï¼ˆå¦‚ Yosysï¼‰è¿›è¡Œè¯„ä¼°ï¼Œå¯¼è‡´ç»“æœå¯¹è¡¨é¢ä»£ç å˜åŒ–è¿‡äºæ•æ„Ÿï¼Œæ— æ³•åæ˜ å·¥ä¸šçº§æµç¨‹çš„çœŸå®è¡¨ç°ï¼›
- ç¼ºä¹å¯¹ **PPA å…¨é¢è¯„ä¼°**ï¼Œå°¤å…¶å¿½ç•¥äº† **Power** å’Œ **Timing** çš„æƒè¡¡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•/æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ä¸ªæ–°çš„åŸºå‡†ï¼š**RTL-OPT**ï¼Œç”¨äºæ›´é€‚å½“åœ°è¯„ä¼° LLM åœ¨ RTL ä»£ç ä¼˜åŒ–æ–¹é¢çš„èƒ½åŠ›ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š
1. **é«˜è´¨é‡ã€çœŸå®æ„Ÿå¼ºçš„æ‰‹å·¥è®¾è®¡ä»»åŠ¡é›†**  
   - åŒ…å« **36 ä¸ªæ‰‹å·¥ç¼–å†™**çš„æ•°å­—ç”µè·¯è®¾è®¡ä»»åŠ¡ï¼Œè¦†ç›–ç»„åˆé€»è¾‘ã€æµæ°´çº¿æ•°æ®è·¯å¾„ã€æœ‰é™çŠ¶æ€æœºï¼ˆFSMï¼‰ã€å­˜å‚¨å™¨æ¥å£ç­‰å…¸å‹åœºæ™¯ã€‚
   - æ¯ä¸ªä»»åŠ¡æä¾›ä¸€å¯¹ RTL ä»£ç ï¼š**å­æœ€ä¼˜ç‰ˆæœ¬**ï¼ˆå¾…ä¼˜åŒ–è¾“å…¥ï¼‰å’Œ **äººå·¥ä¼˜åŒ–å‚è€ƒç‰ˆæœ¬**ï¼ˆgolden referenceï¼‰ï¼Œåè€…ä½“ç°äº†å·¥ä¸šå®è·µä¸­æœ‰æ•ˆçš„ä¼˜åŒ–æ¨¡å¼ã€‚

2. **çœŸå®çš„ä¼˜åŒ–æ¨¡å¼ï¼ˆOptimization Patternsï¼‰**  
   RTL-OPT ä¸­çš„ä¼˜åŒ–åŸºäºçœŸå®æœ‰æ•ˆçš„è¡Œä¸šå®è·µï¼Œæ¶µç›–ä»¥ä¸‹å…­ç±»ï¼š
   - Bit-width Optimization
   - Precomputation & LUT Conversion
   - Operator Strength Reduction
   - Control Simplification
   - Resource Sharing
   - State Encoding Optimization  
   è¿™äº›ä¼˜åŒ–åœ¨å…ˆè¿›åˆæˆå·¥å…·ä¸‹ä»èƒ½ä½“ç°æ˜¾è‘— PPA æ”¹è¿›ã€‚

3. **é›†æˆåŒ–è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶**  
   æä¾›å®Œæ•´çš„è¯„ä¼°æµç¨‹ï¼Œè‡ªåŠ¨å®Œæˆï¼š
   - **åŠŸèƒ½ç­‰ä»·æ€§éªŒè¯**ï¼ˆä½¿ç”¨ Synopsys Formalityï¼‰
   - **åŠ¨æ€ä»¿çœŸéªŒè¯**ï¼ˆé€‚ç”¨äºæ¶‰åŠæ—¶åºè°ƒæ•´çš„ä¼˜åŒ–ï¼‰
   - **PPA é‡åŒ–è¯„ä¼°**ï¼ˆä½¿ç”¨ Synopsys Design Compiler å’Œ Yosysï¼‰

4. **å¤šå·¥å…·ã€å¤šé…ç½®çš„é²æ£’æ€§è¯„ä¼°**  
   åœ¨å¤šç§åˆæˆé…ç½®ä¸‹æµ‹è¯•ï¼ˆå¦‚ DC `compile` / `compile_ultra`ï¼Œä¸åŒ clock periodï¼‰ï¼Œç¡®ä¿è¯„ä¼°ç»“æœä¸ä¾èµ–äºç‰¹å®šå·¥å…·æˆ–å®½æ¾çº¦æŸã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰åŸºå‡†ï¼ˆå¦‚ [26]ï¼‰ | RTL-OPTï¼ˆæœ¬æ–‡ï¼‰ |
|------|---------------------|------------------|
| è®¾è®¡çœŸå®æ€§ | äººä¸ºæ„é€ ï¼Œä¸ç°å® | æ‰‹å·¥ç¼–å†™ï¼Œè´´è¿‘å·¥ä¸šå®è·µ |
| åˆæˆå·¥å…· | å¤šç”¨ Yosysï¼ˆå¼±ä¼˜åŒ–ï¼‰ | ä¸»è¦ç”¨ DCï¼ˆå·¥ä¸šçº§ï¼‰+ Yosys å¯¹æ¯” |
| PPA è¦†ç›– | åé‡é¢ç§¯ | å®Œæ•´è¯„ä¼° Power, Performance, Area |
| è¯„ä¼°å¯é æ€§ | å•†ä¸šå·¥å…·ä¸‹å·®å¼‚æ¶ˆå¤± | å³ä½¿åœ¨ `compile_ultra` ä¸‹ä»ä¿æŒä¼˜åŠ¿ |
| åŠŸèƒ½éªŒè¯ | ç¼ºå¤±æˆ–ä¸è¶³ | é›†æˆ Formality + VCS åŠ¨æ€éªŒè¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **RTL-OPT åŸºå‡†é›†**ï¼šåŒ…å« 36 ä¸ªè®¾è®¡ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡æä¾›ï¼š
  - å­æœ€ä¼˜ RTL ä»£ç 
  - äººå·¥ä¼˜åŒ–çš„é»„é‡‘å‚è€ƒ RTL ä»£ç 
  - å·²åˆæˆçš„ç½‘è¡¨ï¼ˆnetlistsï¼‰
  - PPA æŠ¥å‘Šï¼ˆæ¥è‡ª DC å’Œ Yosysï¼‰
  - å®Œæ•´å·¥å…·é“¾è„šæœ¬ï¼ˆæ ‡å‡†å•å…ƒåº“ã€ç»¼åˆã€ä»¿çœŸã€éªŒè¯è„šæœ¬ï¼‰

### å®éªŒè®¾ç½®
- **åˆæˆå·¥å…·**ï¼š
  - ä¸»è¦ä½¿ç”¨ **Synopsys Design Compiler (DC)**ï¼Œæ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    - `compile`ï¼ˆå¸¸è§„ä¼˜åŒ–ï¼‰
    - `compile_ultra`ï¼ˆæ¿€è¿›ä¼˜åŒ–ï¼‰
  - è¾…åŠ©ä½¿ç”¨å¼€æºå·¥å…· **Yosys**
- **å·¥è‰ºåº“**ï¼šNangate45 å¼€æºæ ‡å‡†å•å…ƒåº“
- **æ—¶é’Ÿçº¦æŸ**ï¼š
  - æ¾å¼›ç›®æ ‡ï¼š1ns
  - ä¸¥æ ¼ç›®æ ‡ï¼š0.1nsï¼ˆç”¨äºæµ‹è¯•æ—¶åºå‹åŠ›ä¸‹çš„è¡¨ç°ï¼‰
- **PPA æŒ‡æ ‡**ï¼š
  - **Power**ï¼šæ€»åŠŸè€—ï¼ˆåŠ¨æ€ + æ³„æ¼ï¼‰
  - **Performance**ï¼šWNSï¼ˆæœ€å·®è´Ÿè£•é‡ï¼‰ã€TNSï¼ˆæ€»è´Ÿè£•é‡ï¼‰
  - **Area**ï¼šå•å…ƒæ•°é‡ï¼ˆCellsï¼‰å’Œç‰©ç†é¢ç§¯ï¼ˆAreaï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline 1**ï¼šç°æœ‰ä¼˜åŒ–åŸºå‡† [26] åŠå…¶äººå·¥ä¼˜åŒ–ç‰ˆæœ¬
- **Baseline 2**ï¼š[26] ä¸­ç”± LLMï¼ˆGPT-4.0 å’Œå…¶è‡ªç ”æ¨¡å‹ï¼‰ç”Ÿæˆçš„ä¼˜åŒ–ä»£ç 
- **Baseline 3**ï¼šSymRTLO [23]ï¼ˆå¦ä¸€é¡¹ LLM è¾…åŠ© RTL ä¼˜åŒ–å·¥ä½œï¼‰

è¢«è¯„ä¼°çš„ LLMsï¼š
- GPT-4o-mini
- Gemini-2.5
- Deepseek V3
- Deepseek R1

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & Table 3ï¼‰

#### âœ… RTL-OPT è‡ªèº«æœ‰æ•ˆæ€§éªŒè¯ï¼ˆTable 1ï¼‰
åœ¨ `DC compile_ultra, 1ns` è®¾ç½®ä¸‹ï¼š
| åŸºå‡† | æ›´ä¼˜æ¡ˆä¾‹æ•° / æ€»æ•° |
|------|------------------|
| [26]ï¼ˆäººå·¥ä¼˜åŒ–ï¼‰ | 13 / 43 |
| RTL-OPTï¼ˆäººå·¥ä¼˜åŒ–ï¼‰ | **35 / 36** |

ğŸ‘‰ è¡¨æ˜ RTL-OPT ä¸­çš„äººå·¥ä¼˜åŒ–ç¡®å®å¸¦æ¥äº†æ˜¾è‘—ä¸”ç¨³å®šçš„ PPA æå‡ï¼Œè€Œ [26] çš„â€œä¼˜åŒ–â€åœ¨å¼ºåˆæˆå·¥å…·ä¸‹å¤§å¤šæ— æ•ˆã€‚

#### âœ… å¹³å‡ PPA æ”¹è¿›ï¼ˆTable 3ï¼‰
| æŒ‡æ ‡ | å­æœ€ä¼˜ï¼ˆDCï¼‰ | ä¼˜åŒ–åï¼ˆDCï¼‰ | æ”¹è¿›ç‡ |
|------|-------------|------------|--------|
| Power | 1226.8 mW | 901.8 mW | **27.6%â†“** |
| Cells | 1337.4 | 1047.7 | **21.7%â†“** |
| Area | 14.0 KÎ¼mÂ² | 9.1 KÎ¼mÂ² | **35.0%â†“** |
| WNS/TNS | 0.0 / 0.0 | 0.0 / 0.0 | æ— é€€åŒ– |

ğŸ‘‰ æ˜¾ç¤º RTL-OPT ä¸­çš„ä¼˜åŒ–åœ¨é¢ç§¯ã€åŠŸè€—ä¸Šå¸¦æ¥æ˜¾è‘—æ”¹è¿›ï¼Œä¸”æœªç‰ºç‰²æ—¶åºæ€§èƒ½ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ğŸ” å¯¹æ¯” [26] çš„äººå·¥ä¼˜åŒ–æ•ˆæœï¼ˆTable 1ï¼‰
- åœ¨ `compile_ultra` ä¸‹ï¼Œ[26] çš„äººå·¥ä¼˜åŒ–ä»…åœ¨ 13/43 æ¡ˆä¾‹ä¸­ä¼˜äºåŸå§‹è®¾è®¡ï¼›
- è€Œ RTL-OPT åœ¨ 35/36 æ¡ˆä¾‹ä¸­å‡å®ç°æ›´å¥½ PPAï¼›
- ä½¿ç”¨ Yosys æ—¶ï¼Œ[26] è¡¨ç°â€œè™šé«˜â€ï¼Œè¯´æ˜å…¶è¯„ä¼°æ˜“å—å·¥å…·å½±å“ã€‚

#### ğŸ” LLM ä¼˜åŒ–ç»“æœï¼ˆFigure 3 & Table 4ï¼‰
| LLM æ¨¡å‹ | è¯­æ³•æ­£ç¡®ç‡ | åŠŸèƒ½æ­£ç¡®ç‡ | PPA ä¼˜äºå­æœ€ä¼˜ | PPA è¶…è¿‡äººå·¥ä¼˜åŒ– |
|---------|-----------|-----------|----------------|------------------|
| GPT-4o-mini | 97.2% | 75% | 19.4% | â€” |
| Gemini-2.5 | ~100% | ~70% | ~20% | â€” |
| Deepseek V3 | 100% | 69.4% | ~23% | â€” |
| **Deepseek R1** | 86.1% | 61.1% | **41.7%** | **13.9%** |

ğŸ‘‰ **Deepseek R1** åœ¨ PPA ä¼˜åŒ–ä¸Šè¡¨ç°æœ€å¼ºï¼Œä½†ä»¥åŠŸèƒ½æ­£ç¡®ç‡ä¸ºä»£ä»·ï¼›å…¶ä»–æ¨¡å‹æ›´ä¿å®ˆï¼ŒPPA æå‡æœ‰é™ã€‚

### æ¶ˆèå®éªŒä¸æ·±å…¥åˆ†æ
- **å¤±è´¥æ¡ˆä¾‹åˆ†æ**ï¼šå¯¹ 40 ä¸ªè¯­æ³•é€šè¿‡ä½†åŠŸèƒ½é”™è¯¯çš„è®¾è®¡è¿›è¡Œæ£€æŸ¥ï¼Œå‘ç°ä¸»è¦é”™è¯¯æ¨¡å¼ä¸ºï¼š
  1. æ§åˆ¶é€»è¾‘é”™è¯¯ï¼ˆå¦‚ FSM æ¡ä»¶åˆ¤æ–­é”™è¯¯ï¼‰
  2. è¿‡åº¦æµæ°´çº¿åŒ–ï¼ˆè¿åå»¶è¿Ÿè¦æ±‚ï¼‰
  3. èµ„æºå…±äº«ä¸å½“ï¼ˆå¯„å­˜å™¨å¤ç”¨å¯¼è‡´æ•°æ®å†²çªï¼‰
- **åˆæˆé…ç½®å½±å“ç ”ç©¶**ï¼š
  - æ›´ä¸¥æ ¼çš„æ—¶åºçº¦æŸï¼ˆ0.1nsï¼‰ä¼šå¼•å…¥æ›´å¤š PPA æƒè¡¡ï¼ˆtrade-offï¼‰ï¼Œä½† RTL-OPT ä»ä¿æŒå¤šæ•°æ¡ˆä¾‹çš„ä¼˜åŒ–ä¼˜åŠ¿ï¼›
  - å•†ä¸šå·¥å…·ï¼ˆDCï¼‰èƒ½æ¶ˆé™¤è®¸å¤šâ€œè™šå‡ä¼˜åŒ–â€ï¼Œå‡¸æ˜¾ RTL-OPT è®¾è®¡çš„çœŸå®æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç°æœ‰ RTL ä¼˜åŒ–åŸºå‡†ä¸å¯é **ï¼šè®¸å¤šæ‰€è°“çš„â€œä¼˜åŒ–â€åœ¨å·¥ä¸šçº§åˆæˆæµç¨‹ä¸‹æ— æ•ˆï¼Œç”šè‡³æ›´å·®ï¼Œä¸»è¦å› ä¸ºè®¾è®¡ä¸çœŸå®ã€è¯„ä¼°å·¥å…·å¤ªå¼±ã€‚
2. **PPA è¯„ä¼°å¿…é¡»ç»“åˆåŠŸèƒ½éªŒè¯**ï¼šä»…çœ‹ä»£ç æˆ–é¢ç§¯æ˜¯ä¸å¤Ÿçš„ï¼Œå¿…é¡»é€šè¿‡ Formality/VCS éªŒè¯åŠŸèƒ½ä¸€è‡´æ€§ã€‚
3. **LLMs å½“å‰åœ¨ RTL ä¼˜åŒ–ä¸Šä»æœ‰å¾ˆå¤§æå‡ç©ºé—´**ï¼šå³ä½¿æ˜¯æœ€å¥½çš„æ¨¡å‹ï¼ˆå¦‚ Deepseek R1ï¼‰ï¼Œä¹Ÿåªæœ‰çº¦ 42% çš„æ¡ˆä¾‹èƒ½æ”¹å–„ PPAï¼Œä¸”åŠŸèƒ½é”™è¯¯ç‡è¾ƒé«˜ã€‚
4. **ä¼˜åŒ–ç­–ç•¥å­˜åœ¨æƒè¡¡**ï¼šæ¿€è¿›ä¼˜åŒ–ï¼ˆå¦‚ Deepseek R1ï¼‰å¯èƒ½å¸¦æ¥æ›´é«˜ PPA æ”¹è¿›ï¼Œä½†ä¹Ÿæ›´å®¹æ˜“ç ´ååŠŸèƒ½æ­£ç¡®æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è§„æ¨¡é™åˆ¶**ï¼šç›®å‰ä»…åŒ…å« 36 ä¸ªå°å‹åˆ°ä¸­å‹æ¨¡å—ï¼Œå°šæœªè¦†ç›–å¤§å‹ SoC æˆ–å¤æ‚ IPã€‚
- **ä¼˜åŒ–æ¨¡å¼æœ‰é™**ï¼šè™½ç„¶è¦†ç›–ä¸»æµæ¨¡å¼ï¼Œä½†ä»éš¾ä»¥ç©·å°½æ‰€æœ‰å·¥ä¸šçº§ä¼˜åŒ–æŠ€å·§ã€‚
- **ä¾èµ–ç‰¹å®šå·¥è‰ºåº“**ï¼šå½“å‰åŸºäº Nangate45ï¼Œå‘å…ˆè¿›å·¥è‰ºè¿ç§»éœ€é‡æ–°æ ¡å‡†ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±• RTL-OPT è‡³æ›´å¤§è§„æ¨¡ã€æ›´å¤æ‚çš„ç³»ç»Ÿçº§è®¾è®¡ï¼›
- å¼•å…¥æ›´å¤šçœŸå®èŠ¯ç‰‡ä¸­çš„ä¼˜åŒ–æ¡ˆä¾‹ï¼ˆå¦‚æ¥è‡ªå¼€æº RISC-V æ ¸å¿ƒï¼‰ï¼›
- æ¢ç´¢å°† RTL-OPT ç”¨äºè®­ç»ƒ LLMï¼Œè€Œéä»…ä½œä¸ºè¯„ä¼°åŸºå‡†ï¼›
- æ„å»ºç«¯åˆ°ç«¯çš„ AI é©±åŠ¨ RTL ä¼˜åŒ– pipelineï¼Œå¹¶é›†æˆåˆ° EDA æµç¨‹ä¸­ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡º **RTL-OPT** â€”â€” ä¸€ä¸ªé¢å‘ **çœŸå® PPA ä¼˜åŒ–èƒ½åŠ›è¯„ä¼°** çš„æ–°å‹ RTL åŸºå‡†ï¼Œè§£å†³äº†ç°æœ‰åŸºå‡†â€œçº¸ä¸Šè°ˆå…µâ€çš„é—®é¢˜ï¼Œä¸º LLM åœ¨ç¡¬ä»¶è®¾è®¡é¢†åŸŸçš„å®ç”¨åŒ–æä¾›äº†æ›´å¯é ã€æ›´å…·æŒ‘æˆ˜æ€§çš„è¯„æµ‹å¹³å°ã€‚

</details>

---

### 13. [UltraLogic: Enhancing LLM Reasoning through Large-Scale Data Synthesis and Bipolar Float Reward](https://arxiv.org/abs/2601.03205)

**Authors**: Yile Liu, Yixian Liu, Zongwei Li, Yufei Huang, Xinhua Feng, Zhichao Hu, Jinglu Hu, Jianfeng Yan, Fengzong Lian, Yuhong Liu  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.03205v1  

#### Abstract
While Large Language Models (LLMs) have demonstrated significant potential in natural language processing , complex general-purpose reasoning requiring multi-step logic, planning, and verification remains a critical bottleneck. Although Reinforcement Learning with Verifiable Rewards (RLVR) has succe...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# UltraLogic: Enhancing LLM Reasoning through Large-Scale Data Synthesis and Bipolar Float Reward  
**æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚é€šç”¨æ¨ç†ä»»åŠ¡ï¼ˆmulti-step logic, planning, verificationï¼‰ä¸Šä»å­˜åœ¨æ˜¾è‘—ç“¶é¢ˆã€‚å°½ç®¡ **Reinforcement Learning with Verifiable Rewards (RLVR)** åœ¨æ•°å­¦ã€ä»£ç ç­‰ç‰¹å®šé¢†åŸŸå–å¾—æˆåŠŸï¼Œä½†åœ¨æ›´å¹¿æ³›çš„é€šç”¨æ¨ç†ä»»åŠ¡ä¸­é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **é«˜è´¨é‡è®­ç»ƒæ•°æ®ç¨€ç¼º**ï¼šç¼ºä¹å¤§è§„æ¨¡ã€å¤šæ ·åŒ–ã€éš¾åº¦å¯æ§çš„æ¨ç†æ•°æ®é›†ã€‚
- **å¥–åŠ±ä¿¡å·ç¨€ç–ä¸”ä½æ•ˆ**ï¼šä¼ ç»ŸäºŒå…ƒå¥–åŠ±ï¼ˆBinary Rewardï¼‰æ— æ³•åŒºåˆ†â€œæ¥è¿‘æ­£ç¡®â€ä¸â€œå®Œå…¨é”™è¯¯â€çš„æ¨ç†è·¯å¾„ï¼Œå¯¼è‡´å­¦ä¹ æ•ˆç‡ä½ä¸‹ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

#### ï¼ˆ1ï¼‰**ULTRALOGIC æ•°æ®æ¡†æ¶**
- **æ ¸å¿ƒæ€æƒ³**ï¼šé€šè¿‡ **Code-based Solving Framework** å°†é—®é¢˜çš„é€»è¾‘å†…æ ¸ä¸å…¶è‡ªç„¶è¯­è¨€è¡¨è¾¾è§£è€¦ï¼Œå®ç°è‡ªåŠ¨åŒ–ã€å¯éªŒè¯ã€é«˜å¤šæ ·æ€§çš„æ•°æ®åˆæˆã€‚
- **å…³é”®æŠ€æœ¯ç»„ä»¶**ï¼š
  - **ä»»åŠ¡ä»“åº“ï¼ˆTask Repositoryï¼‰**ï¼šåŒ…å«æ•°ç™¾ç§ç‹¬ç‰¹çš„ä»»åŠ¡ç±»å‹ï¼ŒåŸºäºä¸‰ç»´æ­£äº¤åˆ†ç±»ç³»ç»Ÿï¼ˆTask Domain, Core Reasoning Ability, Difficulty Sourceï¼‰è®¾è®¡ï¼Œç¡®ä¿è¦†ç›–å¹¿æ³›æ¨ç†åœºæ™¯ã€‚
  - **æ¨¡æ¿ä»“åº“ï¼ˆTemplate Repositoryï¼‰**ï¼šä¸ºæ¯ç±»ä»»åŠ¡æ„å»ºå¤šæ ·åŒ–çš„è‡ªç„¶è¯­è¨€æ¨¡æ¿ï¼ˆå¦‚ä¾¦æ¢æ•…äº‹ã€ç‰©æµè°ƒåº¦ã€ç§‘å¹»è®¾å®šï¼‰ï¼Œé˜²æ­¢æ¨¡å‹è®°å¿†å›ºå®šæ¨¡å¼ã€‚
  - **ç¨‹åºåŒ–æ‰©å±•ï¼ˆProgrammatic Expansion, PEï¼‰**ï¼šåˆ©ç”¨ `input()` å’Œ `solution()` å‡½æ•°è‡ªåŠ¨ç”Ÿæˆæµ·é‡é—®é¢˜å˜ä½“ï¼Œå¹¶é€šè¿‡å‚æ•°æ§åˆ¶å®ç°éš¾åº¦åˆ†çº§ã€‚
  - **åçº§éš¾åº¦æ ¡å‡†ç³»ç»Ÿ**ï¼šåŸºäºä¸»æµLLMçš„å®é™…æˆåŠŸç‡å¯¹10ä¸ªéš¾åº¦ç­‰çº§è¿›è¡Œé—­ç¯è‡ªåŠ¨æ ¡å‡†ï¼ˆå¦‚ Level 1 ~100%ï¼ŒLevel 5 ~50%ï¼ŒLevel 10 ~0%ï¼‰ï¼Œç¡®ä¿éš¾åº¦å®¢è§‚å¯å¤ç°ã€‚

> ğŸ” **ä¼˜åŠ¿**ï¼šç›¸æ¯”äººå·¥æ ‡æ³¨æˆ–çº¯ç”Ÿæˆå¼åˆæˆï¼ŒULTRALOGIC èƒ½å¤Ÿä¿è¯æ•°æ®çš„ **é€»è¾‘æ­£ç¡®æ€§ã€å¯éªŒè¯æ€§ã€å¤šæ ·æ€§ä¸éš¾åº¦å¯æ§æ€§**ï¼Œæ”¯æŒæ— é™æ‰©å±•ã€‚

#### ï¼ˆ2ï¼‰**åŒææµ®ç‚¹å¥–åŠ±æœºåˆ¶ï¼ˆBipolar Float Reward, BFRï¼‰**
- **åŠ¨æœº**ï¼šè§£å†³äºŒå…ƒå¥–åŠ±çš„â€œéè´Ÿå¥–åŠ±é™·é˜±â€ï¼ˆNon-negative Reward Trapï¼‰â€”â€”å³ä½¿æœ‰é€»è¾‘ç¼ºé™·çš„ç­”æ¡ˆä¹Ÿå¯èƒ½è·å¾—æ­£å‘ä¼˜åŠ¿ä¿¡å·ï¼Œå¯¼è‡´æ¨¡å‹æ”¶æ•›äºæ¬¡ä¼˜ç­–ç•¥ã€‚
- **è®¾è®¡åŸç†**ï¼š
  - åªæœ‰å®Œå…¨æ­£ç¡®çš„ç­”æ¡ˆå¾—åˆ†ä¸º `+1`ï¼›
  - æ‰€æœ‰ä¸å®Œç¾çš„è¾“å‡ºå¾—åˆ†æ˜ å°„åˆ° `[-1, 0)` åŒºé—´ï¼Œå³æ–½åŠ ä¸åŒç¨‹åº¦çš„è´Ÿæƒ©ç½šï¼ˆgraded penaltyï¼‰ï¼›
  - æ„å»ºâ€œæ¨æ‹‰åŠ¨åŠ›å­¦â€ï¼ˆPush-Pull Dynamicsï¼‰ï¼šæ­£å¥–åŠ±â€œæ‹‰åŠ¨â€æ¨¡å‹è¶‹è¿‘æœ€ä¼˜ï¼Œè´Ÿå¥–åŠ±â€œæ¨åŠ¨â€å…¶è¿œç¦»é”™è¯¯è·¯å¾„ã€‚

> ğŸ” **ä¼˜åŠ¿**ï¼šç›¸æ¯”æ ‡å‡†æµ®ç‚¹å¥–åŠ± `[0,1]`ï¼ŒBFR é¿å…äº†æ¨¡å‹â€œæ»¡è¶³äºéƒ¨åˆ†æ­£ç¡®â€ï¼Œæœ‰æ•ˆå¼•å¯¼å…¶é€¼è¿‘å…¨å±€é€»è¾‘æœ€ä¼˜è§£ã€‚

---

### âš–ï¸ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ RLVR + äººå·¥æ•°æ®ï¼‰ | ULTRALOGIC + BFR |
|------|-------------------------------|------------------|
| æ•°æ®è§„æ¨¡ä¸å¤šæ ·æ€§ | ä¾èµ–æœ‰é™ç«èµ›æ•°æ®é›†ï¼ˆå¦‚ MATHï¼‰ï¼Œå¤šæ ·æ€§ä¸è¶³ | è‡ªåŠ¨åˆæˆç™¾ç§ä»»åŠ¡ç±»å‹ï¼Œè·¨é¢†åŸŸã€å¤šåœºæ™¯ |
| æ•°æ®è´¨é‡ä¸å¯éªŒè¯æ€§ | å­˜åœ¨å™ªå£°æˆ–æ­§ä¹‰ï¼Œéš¾ä»¥è§„æ¨¡åŒ–éªŒè¯ | ä»£ç é©±åŠ¨ï¼Œé€»è¾‘ç¡®å®šï¼Œç­”æ¡ˆå¯ç¼–ç¨‹éªŒè¯ |
| éš¾åº¦æ§åˆ¶ | ç¼ºä¹ç»Ÿä¸€ã€å®¢è§‚çš„éš¾åº¦æ ‡å°º | åçº§è‡ªåŠ¨åŒ–æ ¡å‡†ï¼Œé€‚é…ä¸åŒæ¨¡å‹èƒ½åŠ› |
| å¥–åŠ±ä¿¡å·å¯†åº¦ | äºŒå…ƒå¥–åŠ±ç¨€ç–ï¼Œç¼ºä¹ä¸­é—´åé¦ˆ | BFR æä¾›å¯†é›†ã€å¸¦æƒ©ç½šçš„æ¢¯åº¦ä¿¡å· |
| è®­ç»ƒæ•ˆç‡ | æ”¶æ•›æ…¢ï¼Œæ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ | æ›´å¿«æ”¶æ•›ï¼Œæ›´é«˜æœ€ç»ˆæ€§èƒ½ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼šå…¨éƒ¨æ¥è‡ª ULTRALOGIC æ¡†æ¶è‡ªåŠ¨ç”Ÿæˆï¼Œæ¶µç›–ä¸Šç™¾ç§ä»»åŠ¡ç±»å‹ï¼ŒåŒ…æ‹¬ï¼š
  - æ•°å€¼æ¨ç†ï¼ˆNumerical Manipulationï¼‰
  - ç¬¦å·æ“ä½œï¼ˆSymbolic Manipulationï¼‰
  - æ–‡æœ¬è°œé¢˜ï¼ˆTextual Manipulationï¼‰
  - ç©ºé—´è·¯å¾„è§„åˆ’ï¼ˆSpatial: Pathfinding / Geometryï¼‰
  - å› æœé“¾æ¨ç†ï¼ˆPlanning & Schedulingï¼‰
  - ç»å…¸æ¸¸æˆï¼ˆå¦‚24ç‚¹ã€æ•°ç‹¬å˜ä½“ï¼‰
- **æµ‹è¯•åŸºå‡†ï¼ˆEvaluation Benchmarksï¼‰**ï¼š
  - **AIME 2024 & 2025**ï¼ˆé«˜çº§ä¸­å­¦æ•°å­¦ç«èµ›ï¼‰
  - **HMMT 2025**ï¼ˆå“ˆä½›-éº»çœç†å·¥æ•°å­¦é”¦æ ‡èµ›ï¼‰
  - **BBH**ï¼ˆBig-Bench Hardï¼‰
  - **BBEH**ï¼ˆBIG-Bench Extra Hardï¼‰
  - **ARC-AGI**ï¼ˆAbstraction and Reasoning Corpus - AI General Intelligenceï¼‰

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

| è®¾ç½®é¡¹ | å†…å®¹ |
|-------|------|
| **æ¨¡å‹** | Qwen3-8B å’Œ Qwen3-14B |
| **è®­ç»ƒç®—æ³•** | Group Relative Policy Optimization (**GRPO**) |
| **è¶…å‚æ•°** | lr=1e-6, rollout=16, max_response_length=32,768, temperature=1.0, top_p=1.0 |
| **å¥–åŠ±æ„æˆ** | ä¸»å¥–åŠ± + 0.1 æ ¼å¼å¥–åŠ±ï¼ˆformat bonusï¼‰ä»¥åˆ†ç¦»æ ¼å¼ä¸é€»è¾‘å‡†ç¡®æ€§ |
| **è®­ç»ƒè½®æ•°** | 2 epochs |
| **è¯„ä¼°æ–¹å¼** | é‡‡æ ·ç­–ç•¥ï¼šT=0.6, top_p=0.95, top_k=20, min_p=0ï¼›token limit=32,768ï¼›æ¯æ ·æœ¬é‡å¤64æ¬¡å–å¹³å‡å‡†ç¡®ç‡ |
| **ä¸»è¦æŒ‡æ ‡** | **Accuracy**ï¼ˆå„benchmarkä¸Šçš„å¹³å‡å‡†ç¡®ç‡ï¼‰ |

---

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Binary Reward**ï¼šæ ‡å‡†äºŒå…ƒå¥–åŠ± `{0, 1}`
- **Graded Float Reward**ï¼šè¿ç»­å¥–åŠ± `[0, 1]`ï¼ŒåŸºäº Accuracy/F1/Similarity ç­‰æŒ‡æ ‡é‡åŒ–éƒ¨åˆ†æ­£ç¡®æ€§
- **BFR**ï¼ˆæœ¬æ–‡æå‡ºï¼‰ï¼š`[-1, 0) âˆª {1}`ï¼Œä»…å®Œç¾ç­”æ¡ˆå¾—æ­£åˆ†ï¼Œå…¶ä½™æŒ‰ç¨‹åº¦æ‰£åˆ†

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 2ï¼‰

| æ–¹æ³• | AIME24 | AIME25 | HMMT25 | BBH | BBEH | ARC-AGI |
|------|--------|--------|--------|-----|------|---------|
| **Qwen3-8B (Base)** | 75.2 | 66.1 | 47.1 | 88.2 | 29.2 | 4.0 |
| **Binary Reward** | 81.7 | 69.1 | 52.3 | 90.2 | 31.1 | 4.6 |
| **Graded Float** | 76.9 | 66.3 | 53.0 | 90.4 | 31.0 | 4.3 |
| **Bipolar Float (BFR)** âœ… | **82.6** | **71.3** | **56.6** | **91.1** | **32.5** | **4.7** |

> ğŸ’¡ **ç»“è®º**ï¼šBFR åœ¨å‡ ä¹æ‰€æœ‰ benchmark ä¸Šå‡è¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼Œå°¤å…¶åœ¨é€»è¾‘å¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚ AIMEã€BBHï¼‰ä¸­æå‡æ˜¾è‘—ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰**éš¾åº¦åŒ¹é…ç°è±¡ï¼ˆDifficulty Matching Phenomenonï¼‰**
- åœ¨ Qwen3-8B ä¸Šï¼Œ**Easy æ•°æ®é›†ï¼ˆLevel 1â€“4ï¼‰** è¡¨ç°æœ€å¥½ï¼›
- åœ¨æ›´å¼ºçš„ Qwen3-14B ä¸Šï¼Œ**Mediumï¼ˆLevel 4â€“7ï¼‰** å’Œ **Hardï¼ˆLevel 7â€“10ï¼‰** æ›´ä¼˜ã€‚
- æœ€ä½³è®­ç»ƒæ•ˆæœå‡ºç°åœ¨æ¨¡å‹åœ¨è¯¥éš¾åº¦ä¸‹åˆå§‹æˆåŠŸç‡çº¦ä¸º **40%-60%** æ—¶ï¼Œå°è¯äº†â€œæœ€è¿‘å‘å±•åŒºâ€ï¼ˆZone of Proximal Developmentï¼‰ç†è®ºã€‚

> ğŸ“ˆ å›¾è¡¨æ˜¾ç¤ºï¼šè¿‡éš¾ä»»åŠ¡å¼•å…¥å™ªå£°ï¼Œè¿‡æ˜“ä»»åŠ¡ä¿¡æ¯å¢ç›Šå°ï¼Œé€‚é…éš¾åº¦å¸¦æ¥æœ€å¹³æ»‘ã€é«˜æ•ˆçš„è®­ç»ƒæ›²çº¿ã€‚

#### ï¼ˆ2ï¼‰**BFR vs. å…¶ä»–å¥–åŠ±æœºåˆ¶**
- **Binary Reward**ï¼šè™½ä¼˜äºåŸºç¡€æ¨¡å‹ï¼Œä½†æ”¶æ•›è¾ƒæ…¢ï¼›
- **Graded Float ([0,1])**ï¼šåˆæœŸå¾—åˆ†é«˜ï¼Œä½†å¾ˆå¿«åœæ»ï¼Œæœªèƒ½æŒç»­æå‡ï¼›
- **BFR**ï¼šè™½ç„¶æ•´ä½“ reward å€¼æ›´ä½ï¼ˆå› å«è´Ÿåˆ†ï¼‰ï¼Œä½† **critic/score/mean æ›²çº¿æ›´ç¨³å®šä¸Šå‡**ï¼Œè¡¨æ˜ä¼˜åŒ–æ–¹å‘æ˜ç¡®ï¼Œé¿å…é™·å…¥æ¬¡ä¼˜ã€‚

> ğŸ§ª å‘ç°ï¼šBFR æˆåŠŸæ‰“ç ´â€œéè´Ÿå¥–åŠ±é™·é˜±â€ï¼Œè¿«ä½¿æ¨¡å‹è¿½æ±‚å®Œæ•´é€»è¾‘é“¾è€Œéå…³é”®è¯æ‹¼å‡‘ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ä»»åŠ¡å¤šæ ·æ€§æ˜¯æ¨ç†èƒ½åŠ›æå‡çš„å…³é”®é©±åŠ¨åŠ›**ï¼Œè¿œæ¯”å•çº¯æ‰©å¤§æ•°æ®é‡æ›´é‡è¦ã€‚
2. **éš¾åº¦åŒ¹é…è‡³å…³é‡è¦**ï¼šè®­ç»ƒæ•ˆç‡æœ€å¤§åŒ–å‘ç”Ÿåœ¨ä»»åŠ¡éš¾åº¦ä¸æ¨¡å‹å½“å‰èƒ½åŠ›ç›¸åŒ¹é…çš„â€œé»„é‡‘åŒºé—´â€ã€‚
3. **BFR æ˜¾è‘—ä¼˜äºä¼ ç»Ÿå¥–åŠ±æœºåˆ¶**ï¼šé€šè¿‡å¼•å…¥åˆ†çº§æƒ©ç½šï¼Œæä¾›æ›´ä¸°å¯Œã€æ›´å…·åŒºåˆ†åº¦çš„å­¦ä¹ ä¿¡å·ï¼ŒåŠ å¿«æ”¶æ•›å¹¶æå‡æœ€ç»ˆæ€§èƒ½ã€‚
4. **RLVR å¯¹æ•°æ®è´¨é‡æå…¶æ•æ„Ÿ**ï¼šå°‘é‡é€»è¾‘é”™è¯¯å³å¯å¯¼è‡´è®­ç»ƒå´©æºƒï¼Œå› æ­¤ä¸¥æ ¼çš„éªŒè¯æµç¨‹ï¼ˆå¦‚ Section 3.4.4ï¼‰ä¸å¯æˆ–ç¼ºã€‚

---

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–äººå·¥æ ‡æ³¨**ï¼š
   - å°½ç®¡é«˜åº¦è‡ªåŠ¨åŒ–ï¼Œä½†ä»éœ€äººç±»ä¸“å®¶å‚ä¸ç§å­ä»»åŠ¡é€»è¾‘éªŒè¯ã€åˆå§‹éš¾åº¦æ ¡å‡†å’Œå¥–åŠ±å‡½æ•°é…ç½®ã€‚
   - RLVR å¯¹å™ªå£°é›¶å®¹å¿ï¼Œå¿…é¡»ç‰ºç‰²éƒ¨åˆ†è‡ªåŠ¨åŒ–æ¢å–100%é€»è¾‘ä¸¥è°¨æ€§ã€‚
2. **å¥–åŠ±ç¼©æ”¾çš„ç»éªŒæ€§**ï¼š
   - å½“å‰ BFR çš„å¥–åŠ±å€¼è®¾å®šåŸºäºå¯å‘å¼è§„åˆ™ï¼Œå°šæœªå»ºç«‹è‡ªåŠ¨æœç´¢â€œæ•°å­¦æœ€ä¼˜â€å¥–åŠ±åˆ†å¸ƒçš„æ–¹æ³•ã€‚
   - ä¸åŒä»»åŠ¡ç±»å‹çš„ç†æƒ³ reward ç»“æ„å¯èƒ½éœ€è¦ä¸ªæ€§åŒ–è°ƒä¼˜ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢å…¨è‡ªåŠ¨å¥–åŠ±ç»“æ„æœç´¢æœºåˆ¶ï¼ˆAuto-Reward Tuningï¼‰ã€‚
- å°† ULTRALOGIC æ‰©å±•è‡³æ›´å¤šæ¨¡æ€ï¼ˆå¦‚è§†è§‰-è¯­è¨€æ¨ç†ï¼‰ã€‚
- æ„å»ºå¼€æ”¾ç¤¾åŒºç‰ˆæœ¬ï¼Œå…è®¸å¤–éƒ¨è´¡çŒ®æ–°ä»»åŠ¡ç±»å‹ä¸æ¨¡æ¿ã€‚
- ç ”ç©¶å¦‚ä½•å°† BFR ä¸å…¶ä»–è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰ç»“åˆï¼Œè¿›ä¸€æ­¥ç»†åŒ–ä¸­é—´æ­¥éª¤ç›‘ç£ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **ULTRALOGIC é€šè¿‡ä»£ç é©±åŠ¨çš„å¤§è§„æ¨¡ã€å¤šæ ·åŒ–ã€éš¾åº¦å¯æ§çš„æ•°æ®åˆæˆï¼Œé…åˆåˆ›æ–°çš„ Bipolar Float Reward æœºåˆ¶ï¼Œåœ¨æ— éœ€äººå·¥æ ‡æ³¨çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº† LLM çš„å¤æ‚æ¨ç†èƒ½åŠ›ï¼Œæ­ç¤ºäº†â€œå¤šæ ·æ€§ > æ•°æ®é‡â€ã€â€œéš¾åº¦åŒ¹é…â€å’Œâ€œæƒ©ç½šé©±åŠ¨ä¼˜åŒ–â€çš„ä¸‰å¤§æ ¸å¿ƒåŸåˆ™ã€‚**

</details>

---

### 14. [MAFS: Multi-head Attention Feature Selection for High-Dimensional Data via Deep Fusion of Filter Methods](https://arxiv.org/abs/2601.02668)

**Authors**: Xiaoyan Sun, Qingyu Meng, Yalu Wen  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.02668v1  

#### Abstract
Feature selection is essential for high-dimensional biomedical data, enabling stronger predictive performance, reduced computational cost, and improved interpretability in precision medicine applications. Existing approaches face notable challenges. Filter methods are highly scalable but cannot capt...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMAFS: Multi-head Attention Feature Selection for High-Dimensional Data via Deep Fusion of Filter Methods

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
é«˜ç»´ç”Ÿç‰©åŒ»å­¦æ•°æ®ï¼ˆå¦‚åŸºå› è¡¨è¾¾ã€SNPã€å¤šç»„å­¦ï¼‰çš„ç‰¹å¾é€‰æ‹©é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **Filter æ–¹æ³•**ï¼šè™½ç„¶é«˜æ•ˆå¯æ‰©å±•ï¼Œä½†æ— æ³•æ•æ‰éçº¿æ€§å…³ç³»ä¸”æ˜“é—æ¼å†—ä½™ç‰¹å¾ï¼›
- **æ·±åº¦å­¦ä¹ æ–¹æ³•**ï¼šèƒ½å»ºæ¨¡å¤æ‚æ¨¡å¼ï¼Œä½†ç¼ºä¹ç¨³å®šæ€§ã€å¯è§£é‡Šæ€§å’Œå¤§è§„æ¨¡æ•ˆç‡ï¼›
- **å•å¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆSingle-head Attentionï¼‰**ï¼šå—é™äºå•ä¸€è§†è§’ï¼Œéš¾ä»¥æ•è·å¤šå±‚æ¬¡ä¾èµ–ï¼Œä¸”å¯¹åˆå§‹åŒ–æ•æ„Ÿï¼Œå½±å“å¯é‡å¤æ€§ã€‚

æ­¤å¤–ï¼Œå¤§å¤šæ•°ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆç»“åˆç»Ÿè®¡å¯è§£é‡Šæ€§ä¸æ·±åº¦å­¦ä¹ çš„å¼ºå¤§è¡¨å¾èƒ½åŠ›ï¼Œå°¤å…¶åœ¨è¶…é«˜ç»´åœºæ™¯ä¸‹è¡¨ç°ä¸ä½³ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šMAFS
ä½œè€…æå‡º **MAFS**ï¼ˆMulti-head Attention-based Feature Selectionï¼‰ï¼Œä¸€ç§èåˆæ»¤æ³¢æ–¹æ³•å…ˆéªŒä¸æ·±åº¦å­¦ä¹ èƒ½åŠ›çš„æ··åˆæ¡†æ¶ã€‚å…¶æ ¸å¿ƒè®¾è®¡åŒ…æ‹¬ä¸‰ä¸ªæ¨¡å—ï¼š

1. **Filter Module**  
   ä½¿ç”¨å¤šç§ç»å…¸ filter æ–¹æ³•ï¼ˆå¦‚ SISã€BCor-SISã€Kendallâ€™s tauï¼‰ç”Ÿæˆåˆå§‹ç‰¹å¾é‡è¦æ€§è¯„åˆ†ï¼Œä½œä¸ºåç»­å­¦ä¹ çš„â€œè½¯å…ˆéªŒâ€ï¼ˆsoft priorsï¼‰ï¼Œç”¨äºç¨³å®šåˆå§‹åŒ–å¹¶å¼•å¯¼è®­ç»ƒè¿‡ç¨‹ã€‚

2. **Multi-head Attention Module**  
   å¼•å…¥ multi-head å¤–éƒ¨æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ¯ä¸ª attention head å¹¶è¡Œå¤„ç†ä¸€ä¸ª filter æ–¹æ³•è¾“å‡ºçš„å…ˆéªŒæƒé‡ï¼Œä»å¤šä¸ªç»Ÿè®¡è§†è§’ç‹¬ç«‹è¯„ä¼°ç‰¹å¾é‡è¦æ€§ï¼Œä»è€Œæ•æ‰å¤æ‚çš„éçº¿æ€§å…³ç³»å’Œäº¤äº’æ•ˆåº”ã€‚

3. **Reordering Module**  
   å°†å„ attention head è¾“å‡ºçš„ Top-K ç‰¹å¾åˆå¹¶ä¸ºå€™é€‰é›†ï¼Œå¹¶é€šè¿‡æ ‘æ¨¡å‹ï¼ˆå¦‚ Random Forestï¼‰é‡æ–°æ’åºï¼Œè§£å†³å†²çªã€å‡å°‘ä¿¡æ¯ä¸¢å¤±ï¼Œæœ€ç»ˆè¾“å‡ºé²æ£’ä¸€è‡´çš„ç‰¹å¾æ’åã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- âœ… **æ›´å¼ºçš„ç¨³å®šæ€§ä¸å¯é‡å¤æ€§**ï¼šåŸºäº filter çš„åˆå§‹åŒ–ç¼“è§£äº†æ·±åº¦æ¨¡å‹å¯¹éšæœºåˆå§‹åŒ–çš„æ•æ„Ÿæ€§ï¼›
- âœ… **æ›´é«˜çš„è¦†ç›–ç‡ï¼ˆCoverage Rateï¼‰**ï¼šåœ¨å¤šç§å‡½æ•°å…³ç³»ä¸‹å‡ä¼˜äº baselineï¼Œå°¤å…¶åœ¨éçº¿æ€§å…³ç³»ä¸­ä¼˜åŠ¿æ˜¾è‘—ï¼›
- âœ… **æ›´å¥½çš„å¯è§£é‡Šæ€§**ï¼šattention æƒé‡æä¾›é€æ˜çš„é‡è¦æ€§è¯„åˆ†ï¼Œæ”¯æŒè·¨ head åˆ†æä¸€è‡´æ€§ï¼›
- âœ… **è®¡ç®—æ•ˆç‡ä¼˜äºæœ€å¼º baseline**ï¼šç›¸æ¯”å›¾ç¥ç»ç½‘ç»œ GRACES å¿«ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Šï¼›
- âœ… **çµæ´»é€‚åº”ä¸åŒä»»åŠ¡ç±»å‹**ï¼šé€‚ç”¨äºè¿ç»­ä¸åˆ†ç±»ç›®æ ‡å˜é‡ï¼Œåœ¨æ¨¡æ‹Ÿä¸çœŸå®æ•°æ®ä¸Šå‡è¡¨ç°ä¼˜å¼‚ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†

#### ï¼ˆ1ï¼‰æ¨¡æ‹Ÿæ•°æ®ï¼ˆSimulated Dataï¼‰
- ä½¿ç”¨ **OmicsSIMLA** ç”Ÿæˆé«˜ç»´åŸºå› è¡¨è¾¾ï¼ˆRNA-seqï¼‰å’Œ SNP æ•°æ®ï¼›
- åŒ…å«ä¸‰ç§ç‰¹å¾ç±»å‹ï¼šè¿ç»­å‹ã€åˆ†ç±»å‹ã€æ··åˆå‹ï¼›
- ä¸ƒç§åŠŸèƒ½å…³ç³»å»ºæ¨¡å› æœç‰¹å¾ï¼šçº¿æ€§ã€ä½™å¼¦ã€å¯¹æ•°ã€ç«‹æ–¹ã€æŒ‡æ•°ã€å¤åˆã€äº¤äº’é¡¹ï¼›
- æ ·æœ¬é‡ï¼š`n = 500` å’Œ `n = 2,000`ï¼›
- ç»´åº¦ï¼š`p = 25K`, `50K`, `100K`ï¼›
- è¾“å‡ºç±»å‹ï¼šè¿ç»­ä¸äºŒåˆ†ç±»å“åº”å˜é‡ã€‚

#### ï¼ˆ2ï¼‰çœŸå®æ•°æ®
- **ç™Œç—‡åŸºå› è¡¨è¾¾æ•°æ®é›†ï¼ˆ6ä¸ªï¼‰**ï¼š
  - Colon, Leukemia, ALLAML, GLI_85, Prostate_GE, SMK_CAN_187
  - ç”¨äºäºŒåˆ†ç±»ä»»åŠ¡ï¼ˆè‚¿ç˜¤ vs æ­£å¸¸ï¼‰
- **ADNI æ•°æ®é›†**ï¼ˆAlzheimer's Disease Neuroimaging Initiativeï¼‰ï¼š
  - 449 åå‚ä¸è€…ï¼Œ49,386 ä¸ªåŸºå› è¡¨è¾¾ç‰¹å¾
  - é¢„æµ‹ 9 ä¸ªè„‘åŒºä½“ç§¯ï¼ˆimage-derived phenotypesï¼‰ï¼Œä¸ºå›å½’ä»»åŠ¡

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

| ç±»åˆ« | è®¾ç½® |
|------|------|
| **è®­ç»ƒ/éªŒè¯åˆ’åˆ†** | æ¨¡æ‹Ÿæ•°æ®ï¼š80% è®­ç»ƒ + 20% éªŒè¯ï¼›çœŸå®æ•°æ®ï¼š5-fold CV æˆ– 60:20:20 åˆ’åˆ† |
| **è¶…å‚æ•°ä¼˜åŒ–** | ä½¿ç”¨ Optuna è¿›è¡Œ 100 æ¬¡æœç´¢ï¼Œä¼˜åŒ–å­¦ä¹ ç‡ã€dropoutã€æ­£åˆ™åŒ–ç³»æ•°ç­‰ |
| **ç½‘ç»œæ¶æ„ç»Ÿä¸€** | æ‰€æœ‰åµŒå…¥å¼æ–¹æ³•ä½¿ç”¨ç›¸åŒç»“æ„ï¼šä¸¤å±‚ MLPï¼ˆBN + ReLU + Dropoutï¼‰ |
| **ä¸‹æ¸¸æ¨¡å‹** | åˆ†ç±»ä»»åŠ¡ç”¨ SVMã€KNNã€MLPï¼›å›å½’ä»»åŠ¡ç”¨ SVRã€KNNã€MLP |

#### è¯„ä¼°æŒ‡æ ‡
- **æ¨¡æ‹Ÿæ•°æ®**ï¼š**Coverage Rate**ï¼ˆé€‰ä¸­çš„çœŸå®å› æœç‰¹å¾æ¯”ä¾‹ï¼‰
- **çœŸå®æ•°æ®**ï¼š
  - ç™Œç—‡æ•°æ®ï¼š**AUROC**ï¼ˆå‰20ä¸ªç‰¹å¾ç”¨äºåˆ†ç±»ï¼‰
  - ADNI æ•°æ®ï¼š**Pearson Correlation**ï¼ˆå‰50ä¸ªç‰¹å¾é¢„æµ‹è„‘åŒºä½“ç§¯ï¼‰

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¯”è¾ƒäº†å››ç§ä¸»æµæ·±åº¦å­¦ä¹ ç‰¹å¾é€‰æ‹©æ–¹æ³•ï¼š
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **GRACES** | Graph-based | å›¾å·ç§¯ç½‘ç»œ + è¾“å…¥æ¢¯åº¦ä¼°è®¡ï¼Œæ€§èƒ½å¼ºä½†ææ…¢ |
| **EAR-FS** | Attention-based | å¤–éƒ¨æ³¨æ„åŠ›æœºåˆ¶ï¼Œè½»é‡é«˜æ•ˆ |
| **DeepLIFT** | Gradient-based | åŸºäºå‚è€ƒæ¿€æ´»çš„å½’å› æ–¹æ³•ï¼Œè§£é‡Šæ€§å¼ºä½†å™ªå£°æ•æ„Ÿ |
| **CancelOut** | Layer-based | å¯å­¦ä¹ é—¨æ§å±‚ + L1 æ­£åˆ™åŒ–ï¼Œç»“æ„ç®€å• |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ï¼ˆ1ï¼‰æ¨¡æ‹Ÿå®éªŒç»“æœ

#### âœ… è¦†ç›–ç‡ï¼ˆCoverage Rateï¼‰å…¨é¢é¢†å…ˆ
- åœ¨æ‰€æœ‰ç»´åº¦ã€æ ·æœ¬å¤§å°ã€ç‰¹å¾ç±»å‹ç»„åˆä¸‹ï¼Œ**MAFS å§‹ç»ˆå–å¾—æœ€é«˜ coverage**ã€‚
- å½“é€‰æ‹©æ¯”ä¾‹ä» 0.5% æå‡åˆ° 2%ï¼ŒMAFS çš„ coverage æå‡ä»…çº¦ **7.85%**ï¼Œè¯´æ˜å…¶æ—©æœŸå°±èƒ½ç²¾å‡†è¯†åˆ«å…³é”®ç‰¹å¾ï¼›
- å¯¹æ¯”æ–¹æ³•æå‡å¹…åº¦æ›´å¤§ï¼ˆDeepLIFT è¾¾ 79.1%ï¼‰ï¼Œè¡¨æ˜å®ƒä»¬éœ€æ›´å¤šç‰¹å¾æ‰èƒ½æ‰¾å›å› æœä¿¡å·ã€‚

#### âœ… åœ¨éçº¿æ€§å…³ç³»ä¸­ä¼˜åŠ¿å·¨å¤§
| å…³ç³»ç±»å‹ | MAFS | GRACES | EAR-FS |
|--------|-------|--------|--------|
| Linear | 0.86 | 0.84 | 0.70 |
| Logarithmic | **1.00** | 0.25 | 0.19 |
| Cosine | **0.93** | 0.33 | 0.27 |
| Interaction | **0.56** | 0.43 | 0.37 |

> MAFS åœ¨éçº¿æ€§åœºæ™¯ä¸‹å‡ ä¹è¾¾åˆ°å®Œç¾è¦†ç›–ï¼Œè¿œè¶…å…¶ä»–æ–¹æ³•ã€‚

#### âœ… æ›´é«˜çš„ç¨³å®šæ€§
- MAFS çš„ç½®ä¿¡åŒºé—´å®½åº¦ä¸º Â±2.2%ï¼Œæ˜æ˜¾çª„äºå…¶ä»–æ–¹æ³•ï¼ˆÂ±2.5â€“3.1%ï¼‰ï¼Œæ˜¾ç¤ºå…¶ç»“æœæ›´ç¨³å®šã€å¯é‡å¤ã€‚

#### âœ… é«˜ç»´ç¯å¢ƒä¸‹ä»ä¿æŒä¼˜åŠ¿
- å½“å›ºå®šé€‰æ‹© Top 100 ç‰¹å¾æ—¶ï¼Œéšç€ç»´åº¦ä» 25K å‡è‡³ 100Kï¼Œå„æ–¹æ³• coverage ä¸‹é™ï¼š
  - MAFSï¼šä¸‹é™ **21%**
  - GRACESï¼šä¸‹é™ 47%
  - EAR-FSï¼šä¸‹é™ 69%
  - CancelOutï¼šä¸‹é™ 100%ï¼ˆé™è‡³ 0ï¼‰

> è¡¨æ˜ MAFS åœ¨è¶…é«˜ç»´åœºæ™¯æ›´å…·é²æ£’æ€§ã€‚

---

### ï¼ˆ2ï¼‰çœŸå®æ•°æ®ç»“æœ

#### âœ… ç™Œç—‡æ•°æ®é›†ï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰
- åœ¨æ˜“åŒºåˆ†æ•°æ®é›†ï¼ˆLeukemia, Prostateï¼‰ä¸Šï¼Œæ‰€æœ‰æ–¹æ³•è¡¨ç°æ¥è¿‘ï¼ˆAUROC > 0.95ï¼‰ï¼›
- åœ¨å›°éš¾æ•°æ®é›†ï¼ˆColon, Lungï¼‰ä¸Šï¼Œ**MAFS æ˜¾è‘—èƒœå‡º**ï¼š
  - Colon Cancerï¼ˆMLPï¼‰ï¼š**0.922** vs GRACES (0.896) vs EAR-FS (0.855)
  - Lung Cancerï¼ˆMLPï¼‰ï¼š**0.785** vs GRACES (0.763)

- **ç‰¹å¾åˆ©ç”¨æ•ˆç‡æ›´é«˜**ï¼š
  - Leukemiaï¼šMAFS ä»…éœ€ **2â€“3 ä¸ªç‰¹å¾** è¾¾åˆ° AUROC > 0.95ï¼Œè€Œ GRACES éœ€ 4â€“6ï¼ŒEAR-FS éœ€ 8â€“10ï¼›
  - Colonï¼šMAFS ç”¨ **5 ä¸ªç‰¹å¾** è¾¾åˆ° AUROC=0.90ï¼Œbaseline éœ€ 10â€“15ã€‚

#### âœ… ADNI æ•°æ®é›†ï¼ˆå›å½’ä»»åŠ¡ï¼‰
- åœ¨å¤šæ•°è„‘åŒºï¼ˆå¦‚ Brainstem, Pallidum, Fourth Ventricleï¼‰ï¼ŒMAFS å®ç°æœ€é«˜ Pearson ç›¸å…³ç³»æ•°ï¼›
- ç¤ºä¾‹ï¼ˆMLP å›å½’å™¨ï¼ŒTop 50 ç‰¹å¾ï¼‰ï¼š
  - Brainstemï¼šMAFS (**0.440**) > GRACES (0.418) > EAR-FS (0.409)
  - Accumbens Areaï¼šMAFS (**0.219**) > GRACES (0.158) > CancelOut (0.131)

- åŒæ ·è¡¨ç°å‡ºæ›´å¼ºçš„ç‰¹å¾åˆ©ç”¨æ•ˆç‡ï¼Œæ›´å¿«æ”¶æ•›è‡³æœ€ä¼˜å­é›†ã€‚

---

### ï¼ˆ3ï¼‰æ¶ˆèå®éªŒä¸è¡¥å……åˆ†æï¼ˆSupplementary Figuresï¼‰
- **æ›¿æ¢ EAR-FS åˆå§‹åŒ–æ–¹å¼**ï¼šå°†å‡åŒ€åˆå§‹åŒ–æ”¹ä¸º filter-derived åˆå§‹åŒ–åï¼ŒEAR-FS æ€§èƒ½æ˜¾è‘—æå‡ï¼›
- è¡¨æ˜ **è‰¯å¥½çš„åˆå§‹åŒ–æœ¬èº«å³å¯å¤§å¹…æå‡æ³¨æ„åŠ›æœºåˆ¶çš„è¡¨ç°**ï¼Œæ— éœ€å¤æ‚æ¶æ„ä¿®æ”¹ï¼›
- æ”¯æŒ MAFS ä¸­â€œfilter-guided initializationâ€çš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Filter ä¸ Attention çš„æ·±åº¦èåˆæ˜¯æœ‰æ•ˆçš„**ï¼šå°† filter æ–¹æ³•æä¾›çš„ç»Ÿè®¡å…ˆéªŒä½œä¸º attention çš„åˆå§‹åŒ–ï¼Œæ—¢ä¿ç•™äº†å¯è§£é‡Šæ€§ï¼Œåˆå¢å¼ºäº†æ·±åº¦æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚
2. **Multi-head è®¾è®¡æ˜¾è‘—æå‡å¤šæ ·æ€§ä¸é²æ£’æ€§**ï¼šä¸åŒ attention head æ•æ‰ä¸åŒç±»å‹çš„ç‰¹å¾-å“åº”å…³ç³»ï¼ˆçº¿æ€§ã€éçº¿æ€§ã€ç§©ç›¸å…³ï¼‰ï¼Œé¿å…å•ä¸€è§†è§’é—æ¼é‡è¦ç‰¹å¾ã€‚
3. **Reordering æ¨¡å—æœ‰æ•ˆæ•´åˆå¤šæºä¿¡å·**ï¼šé€šè¿‡æ„å»ºå€™é€‰é›† + å†æ’åºç­–ç•¥ï¼Œæœ€å¤§é™åº¦ä¿ç•™æ½œåœ¨é‡è¦ç‰¹å¾ï¼Œé¿å…ä¼ ç»ŸæŠ•ç¥¨æœºåˆ¶çš„ä¿¡æ¯æŸå¤±ã€‚
4. **MAFS åœ¨å„ç§å¤æ‚å…³ç³»å’Œé«˜ç»´æ¡ä»¶ä¸‹å‡ä¼˜äºç°æœ‰æ–¹æ³•**ï¼šæ— è®ºæ˜¯åœ¨æ¨¡æ‹Ÿè¿˜æ˜¯çœŸå®æ•°æ®ä¸­ï¼Œéƒ½å±•ç°å‡ºæ›´é«˜çš„ coverageã€AUROC å’Œ correlationï¼ŒåŒæ—¶å…·å¤‡è‰¯å¥½ç¨³å®šæ€§ã€‚

---

### å±€é™æ€§
1. **å½’ä¸€åŒ–å¯èƒ½å¯¼è‡´å°ºåº¦å¤±é…**ï¼šå°½ç®¡è¿›è¡Œäº†æ ‡å‡†åŒ–ï¼Œä¸åŒ filter æ–¹æ³•çš„æƒé‡å¯èƒ½å­˜åœ¨éšå«åå·®ï¼Œå½±å“èåˆæ•ˆæœï¼›
2. **ä¸æ”¯æŒç¼ºå¤±å€¼å¤„ç†**ï¼šè¦æ±‚å®Œæ•´ç‰¹å¾çŸ©é˜µï¼Œå¯èƒ½æ’é™¤éƒ¨åˆ†æ ·æœ¬ï¼Œå¼•å…¥é€‰æ‹©åå€šï¼›
3. **è®¡ç®—å¼€é”€é«˜äºæœ€è½»é‡çº§æ–¹æ³•**ï¼šè™½æ¯” GRACES å¿«å¾—å¤šï¼Œä½†ä»æ…¢äº DeepLIFT æˆ– CancelOutã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´å…ˆè¿›çš„èåˆç­–ç•¥ï¼Œå¦‚ learnable fusion weights æˆ– rank-level aggregationï¼›
- å¼•å…¥ missing-data-aware æœºåˆ¶æˆ–é›†æˆ imputation æ¨¡å—ï¼›
- æ‰©å±•è‡³å¤šä»»åŠ¡æˆ–å¤šæ¨¡æ€ç‰¹å¾é€‰æ‹©åœºæ™¯ï¼ˆå¦‚åŸºå›  + å½±åƒ + ä¸´åºŠï¼‰ï¼›
- å¼€å‘æ›´é«˜æ•ˆçš„ reordering ç®—æ³•ä»¥è¿›ä¸€æ­¥åŠ é€Ÿæ¨ç†ã€‚

---

## æ€»ç»“
**MAFS æ˜¯ä¸€ç§æ–°é¢–ä¸”å®ç”¨çš„é«˜ç»´ç‰¹å¾é€‰æ‹©æ¡†æ¶**ï¼Œé€šè¿‡å°† filter æ–¹æ³•çš„ç¨³å®šæ€§ä¸ multi-head attention çš„è¡¨è¾¾èƒ½åŠ›ç›¸ç»“åˆï¼Œå®ç°äº†**é«˜æ€§èƒ½ã€é«˜å¯è§£é‡Šæ€§ã€é«˜ç¨³å®šæ€§**çš„ç»Ÿä¸€ã€‚å®ƒä¸ä»…åœ¨ç†è®ºä¸Šè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•çš„å…³é”®ç¼ºé™·ï¼Œåœ¨ç™Œç—‡å’Œé˜¿å°”èŒ¨æµ·é»˜ç—…ç­‰çœŸå®ç”Ÿç‰©åŒ»å­¦åº”ç”¨ä¸­ä¹Ÿå±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä¸ºç²¾å‡†åŒ»å­¦ä¸­çš„ biomarker å‘ç°æä¾›äº†å¼ºæœ‰åŠ›å·¥å…·ã€‚

</details>

---

### 15. [From Memorization to Creativity: LLM as a Designer of Novel Neural-Architectures](https://arxiv.org/abs/2601.02997)

**Authors**: Waleed Khalid, Dmitry Ignatov, Radu Timofte  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.02997v1  

#### Abstract
Large language models (LLMs) excel in program synthesis, yet their ability to autonomously navigate neural architecture design--balancing syntactic reliability, performance, and structural novelty--remains underexplored. We address this by placing a code-oriented LLM within a closed-loop synthesis f...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*From Memorization to Creativity: LLM as a Designer of Novel Neural-Architectures*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ä¼ ç»Ÿ Neural Architecture Search (NAS) è™½ç„¶èƒ½è‡ªåŠ¨åŒ–è®¾è®¡ç¥ç»ç½‘ç»œï¼Œä½†é€šå¸¸ä¾èµ–æ˜‚è´µçš„è®¡ç®—èµ„æºï¼ˆå¦‚å¼ºåŒ–å­¦ä¹ ã€è¿›åŒ–ç®—æ³•ï¼‰ï¼Œä¸”æœç´¢ç©ºé—´å—é™äºé¢„å®šä¹‰ç»“æ„ã€‚åŒæ—¶ï¼Œå°½ç®¡ Large Language Models (LLMs) åœ¨ç¨‹åºç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå…¶åœ¨**è‡ªä¸»ç”Ÿæˆæœ‰æ•ˆã€é«˜æ€§èƒ½ä¸”ç»“æ„æ–°é¢–çš„ç¥ç»ç½‘ç»œæ¶æ„**æ–¹é¢çš„èƒ½åŠ›å°šæœªè¢«ç³»ç»Ÿæ¢ç´¢ã€‚

æœ¬æ–‡æå‡ºå¹¶éªŒè¯äº†ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š  
> å¦‚æœæˆ‘ä»¬åå¤å°† LLM è‡ªèº«ç”Ÿæˆçš„é«˜è´¨é‡æ¶æ„åé¦ˆç»™å®ƒè¿›è¡Œå¾®è°ƒï¼Œå…¶ç”Ÿæˆæœ‰æ•ˆã€é«˜æ€§èƒ½ã€ç»“æ„æ–°é¢–çš„ç¥ç»ç½‘ç»œæ¶æ„çš„èƒ½åŠ›æ˜¯å¦ä¼šæŒç»­æå‡ï¼Ÿ

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡ºäº†ä¸€ç§ **é—­ç¯çš„ LLM é©±åŠ¨ç¥ç»æ¶æ„åˆæˆæ¡†æ¶**ï¼Œé€šè¿‡ 22 è½®è¿­ä»£çš„ *generate-evaluate-select-fine-tune* å¾ªç¯ï¼Œå°† LLM ä»ä¸€ä¸ªéšæœºä»£ç ç”Ÿæˆå™¨è½¬å˜ä¸ºå…·å¤‡ç»éªŒå…ˆéªŒçš„â€œç¥ç»æ¶æ„è®¾è®¡å¸ˆâ€ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š

- **LLM ä½œä¸ºå¯è®­ç»ƒçš„æ¶æ„å…ˆéªŒï¼ˆTrainable Architectural Priorï¼‰**  
  ä¸å†å°† LLM è§†ä¸ºå›ºå®šç»„ä»¶ï¼Œè€Œæ˜¯å°†å…¶è¡Œä¸ºé€šè¿‡è‡ªèº«æˆåŠŸæ¡ˆä¾‹ä¸æ–­ä¼˜åŒ–ï¼Œä½¿å…¶å†…åŒ–ç»éªŒæ€§æ¶æ„å…ˆéªŒã€‚

- **å¤šç›®æ ‡ä¼˜åŒ–æ¡†æ¶**  
  åŒæ—¶ä¼˜åŒ–ä¸‰ä¸ªå…³é”®ç»´åº¦ï¼š
  - **Syntactic Validity**ï¼ˆè¯­æ³•æœ‰æ•ˆæ€§ï¼‰
  - **Early-epoch Performance**ï¼ˆæ—©æœŸè®­ç»ƒæ€§èƒ½ï¼‰
  - **Structural Novelty**ï¼ˆç»“æ„æ–°é¢–æ€§ï¼‰

- **åŸºäº MinHash-Jaccard çš„ä»£ç çº§æ–°é¢–æ€§è¿‡æ»¤æœºåˆ¶**  
  å¼•å…¥æ–‡æœ¬çº§åˆ«çš„è¿‘ä¼¼é‡å¤æ£€æµ‹ï¼ˆMinHash + LSHï¼‰ï¼Œé˜²æ­¢æ¨¡å‹é™·å…¥é‡å¤æ¨¡æ¿æˆ–ç®€å•æ”¹å†™ï¼Œç¡®ä¿è®¾è®¡ç©ºé—´çš„æœ‰æ•ˆæ‰©å±•ã€‚

- **è½»é‡çº§æ€§èƒ½ä»£ç†ä¿¡å·ï¼ˆLow-fidelity Proxyï¼‰**  
  ä½¿ç”¨å•è½®è®­ç»ƒï¼ˆsingle-epoch accuracy on CIFAR-10ï¼‰ä½œä¸ºæ€§èƒ½åé¦ˆä¿¡å·ï¼Œå¤§å¹…é™ä½è¯„ä¼°æˆæœ¬ï¼Œä½¿é—­ç¯è¿­ä»£å¯è¡Œã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼ ç»Ÿ NAS | ç°æœ‰ LLM-based NAS | æœ¬æ–‡æ–¹æ³• |
|------|----------|---------------------|-----------|
| æœç´¢æ•ˆç‡ | ä½ï¼ˆéœ€å®Œæ•´è®­ç»ƒï¼‰ | ä¸­ç­‰ï¼ˆä¾èµ–æç¤ºå·¥ç¨‹ï¼‰ | é«˜ï¼ˆä½¿ç”¨å• epoch ä»£ç†ï¼‰ |
| å¤šæ ·æ€§ä¿éšœ | æ‰‹å·¥è®¾è®¡æœç´¢ç©ºé—´ | ç¼ºä¹æ˜¾å¼æ§åˆ¶ | æ˜¾å¼å¼•å…¥ MinHash æ–°é¢–æ€§è¿‡æ»¤ |
| å­¦ä¹ æœºåˆ¶ | å›ºå®šæœç´¢ç­–ç•¥ | å›ºå®š LLM | è¿­ä»£è‡ªå¢å¼ºï¼ˆself-improvingï¼‰ |
| å¯æ‰©å±•æ€§ | å·® | ä¸­ç­‰ | é«˜ï¼ˆå‚æ•°é«˜æ•ˆ LoRA å¾®è°ƒï¼‰ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šæœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿå±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨æ‰§è¡Œåé¦ˆï¼ˆexecution feedbackï¼‰å°† LLM è½¬å˜ä¸º**è‡ªä¸»çš„ã€æ€§èƒ½é©±åŠ¨çš„ç¥ç»æ¶æ„è®¾è®¡è€…**ï¼Œå®ç°äº†ä»â€œè®°å¿†â€åˆ°â€œåˆ›é€ â€çš„è·ƒè¿ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **åˆå§‹è®­ç»ƒæ•°æ®**ï¼šæ¥è‡ª **LEMUR Neural Network Dataset** çš„ 1,698 ä¸ªå»é‡åçš„ prompt-code å¯¹ã€‚
- **ä»»åŠ¡æ•°æ®é›†**ï¼š**CIFAR-10** ç”¨äºè¯„ä¼°ç”Ÿæˆæ¶æ„çš„å•è½®è®­ç»ƒå‡†ç¡®ç‡ï¼ˆfirst-epoch accuracyï¼‰ã€‚
- **ç”Ÿæˆç›®æ ‡**ï¼šPyTorch å®ç°çš„å·ç§¯ç½‘ç»œï¼Œæ»¡è¶³ `Net(nn.Module)` API åˆåŒï¼Œè¾“å…¥ `(N,3,32,32)` â†’ è¾“å‡º 10 ç±» logitsã€‚

### **å®éªŒè®¾ç½®**

- **åŸºç¡€æ¨¡å‹**ï¼š`DeepSeek-Coder-7B-Instruct-v1.5`
- **å¾®è°ƒæ–¹å¼**ï¼š**LoRA**ï¼ˆrank=32, Î±=32ï¼‰ï¼Œåº”ç”¨äºæ‰€æœ‰ Transformer å±‚çš„ attention å’Œ MLP æŠ•å½±ã€‚
- **å¾®è°ƒé…ç½®**ï¼š
  - æ¯ cycle å¾®è°ƒ 5 epochs
  - å­¦ä¹ ç‡ï¼š1e-5
  - Batch sizeï¼š4ï¼ˆæ¢¯åº¦ç´¯ç§¯ï¼‰
  - ä¼˜åŒ–å™¨ï¼š8-bit AdamW
- **ç”Ÿæˆé…ç½®**ï¼ˆå›ºå®šä¸å˜ï¼‰ï¼š
  - Temperature: 0.20, Top-k: 50, Nucleus p: 0.9
  - Max new tokens: 2048
  - Prompt æ¨¡æ¿ã€è§£ç ç­–ç•¥å…¨ç¨‹ä¸€è‡´ï¼Œä»¥éš”ç¦»å¾®è°ƒå½±å“

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Valid Generation Rate** | æˆåŠŸç¼–è¯‘å¹¶å®Œæˆå‰å‘ä¼ æ’­çš„æ¨¡å‹æ¯”ä¾‹ |
| **First-epoch Accuracy** | åœ¨ CIFAR-10 ä¸Šè®­ç»ƒä¸€ä¸ª epoch åçš„ top-1 éªŒè¯å‡†ç¡®ç‡ï¼ˆä½å¼€é”€æ€§èƒ½ä»£ç†ï¼‰ |
| **â‰¥40% Accuracy Proportion** | å• epoch å‡†ç¡®ç‡è¶…è¿‡ 40% çš„æ¨¡å‹å æ¯”ï¼ˆç”¨äºç­›é€‰ï¼‰ |
| **Structural Novelty** | ä½¿ç”¨ **MinHash-Jaccard Similarity** åˆ¤æ–­æ˜¯å¦ä¸ºè¿‘ä¼¼é‡å¤ä»£ç ï¼ˆé˜ˆå€¼ T=0.9ï¼‰ |
| **Training Corpus Growth** | è‡ªç”Ÿæˆå¹¶åŠ å…¥è®­ç»ƒé›†çš„æ–°æ¶æ„æ•°é‡ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆé€šè¿‡æ¶ˆèå®éªŒå®ç°ï¼‰**

ä½œè€…æœªç›´æ¥å¯¹æ¯”å¤–éƒ¨ NAS æ–¹æ³•ï¼Œè€Œæ˜¯é€šè¿‡**æ¶ˆèç ”ç©¶ï¼ˆAblation Studyï¼‰** éªŒè¯å„ç»„ä»¶å¿…è¦æ€§ï¼š

1. **Full Method**ï¼šå®Œæ•´æ¡†æ¶ï¼ˆnovelty filter + accuracy threshold + iterative fine-tuningï¼‰
2. **No Novelty Filter**ï¼šç§»é™¤ MinHash è¿‡æ»¤
3. **No Accuracy Threshold**ï¼šå–æ¶ˆ 40% å‡†ç¡®ç‡ç­›é€‰
4. **No Iteration**ï¼šä»…åˆå§‹å¾®è°ƒä¸€æ¬¡ï¼Œæ— å¾ªç¯æ›´æ–°

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 2 & Figure 3ï¼‰**

| æŒ‡æ ‡ | Cycle 1 | Cycle 18ï¼ˆå³°å€¼ï¼‰ | Cycle 22ï¼ˆæœ€ç»ˆï¼‰ |
|------|--------|------------------|------------------|
| **Valid Generation Rate** | 44.0% | **74.5%**ï¼ˆcycle 14ï¼‰ | 41.8% |
| **Mean First-epoch Accuracy** | 28.06% | **50.99%** | 49.48% |
| **Best Accuracy** | 47.78% | **63.98%** | 57.62% |
| **â‰¥40% Accuracy Proportion** | 2.04% | **96.81%** | 92.86% |
| **ç´¯è®¡è®­ç»ƒæ ·æœ¬æ•°** | 1,698 | 2,025 | **2,153** |
| **æ–°å¢ç‹¬ç‰¹æ¶æ„æ•°** | â€” | 38 | 30ï¼ˆå…± +455ï¼‰ |

> ğŸ“Š **æ€»ä½“è¶‹åŠ¿**ï¼š
> - æœ‰æ•ˆç”Ÿæˆç‡ç¨³å®šåœ¨ **~50.6%**ï¼ˆ95% CI: [45.0%, 56.1%]ï¼‰
> - å¹³å‡å• epoch å‡†ç¡®ç‡ä» 28.06% æå‡è‡³ 49.48%
> - é«˜æ€§èƒ½æ¶æ„ï¼ˆâ‰¥40%ï¼‰ä»ç¨€æœ‰å˜ä¸ºå¸¸æ€ï¼ˆ>90%ï¼‰

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœï¼ˆæ¶ˆèå®éªŒï¼ŒTable 3ï¼‰**

| æ–¹æ³• | Valid Rate (%) | Mean Acc. (%) | â‰¥40% Acc. (%) | Novel Models Added |
|------|----------------|---------------|----------------|---------------------|
| **Full Method** | **50.6** | **42.3** | **51.1** | **455** |
| No Novelty Filter | 52.0 | 42.0 | 50.0 | 220 |
| No Accuracy Threshold | 51.0 | 38.5 | 34.0 | 470 |
| No Iteration | 44.0 | 28.06 | 4.55 | 1 |

> ğŸ” **åˆ†æ**ï¼š
> - ç§»é™¤ **novelty filter** â†’ å¤šæ ·æ€§æ˜¾è‘—ä¸‹é™ï¼ˆ+220 vs +455ï¼‰ï¼Œè¯´æ˜å…¶å¯¹ç»´æŒæ¢ç´¢è‡³å…³é‡è¦ã€‚
> - ç§»é™¤ **accuracy threshold** â†’ æ€§èƒ½æå‡å‡å¼±ï¼ˆmean acc â†“3.8%ï¼Œâ‰¥40% â†“17.1%ï¼‰ï¼Œè¯´æ˜æ€§èƒ½åé¦ˆæ˜¯é©±åŠ¨è´¨é‡æå‡çš„å…³é”®ã€‚
> - ç§»é™¤ **iteration** â†’ è¡¨ç°åœæ»åœ¨åˆæœŸæ°´å¹³ï¼Œè¯æ˜é—­ç¯åé¦ˆä¸å¯æˆ–ç¼ºã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **LLM å¯ä»¥å†…åŒ–éæ–‡æœ¬çš„ç»éªŒå¥–åŠ±**  
   å°½ç®¡å¾®è°ƒç›®æ ‡ä»æ˜¯æ ‡å‡†çš„ next-token predictionï¼Œä½†é€šè¿‡é€‰æ‹©æ€§åœ°åŠ å…¥é«˜è¡¨ç°ã€æ–°é¢–çš„è‡ªæˆ‘ç”Ÿæˆæ ·æœ¬ï¼ŒLLM èƒ½å¤Ÿéšå¼å­¦ä¹ åˆ°â€œä»€ä¹ˆæ ·çš„æ¶æ„å­¦å¾—å¿«â€ï¼Œä»è€Œæå‡ç”Ÿæˆè´¨é‡ã€‚

2. âœ… **ä»â€œéšæœºç”Ÿæˆâ€åˆ°â€œå¯é è®¾è®¡â€çš„è½¬å˜**  
   ç»è¿‡ 22 è½®è¿­ä»£ï¼ŒLLM ä»æœ€åˆä»… 2% æ¨¡å‹è¾¾åˆ° 40% å‡†ç¡®ç‡ï¼Œå‘å±•åˆ°æœ€åè¶… 90% æ¨¡å‹è¾¾æ ‡ï¼Œè¡¨æ˜å…¶å·²å½¢æˆå¼ºå¥çš„æ¶æ„å…ˆéªŒã€‚

3. âœ… **å¤šæ ·æ€§å¾—ä»¥ç»´æŒè€Œéå´©æºƒ**  
   å°½ç®¡æ¨¡å‹ä¸“ä¸šåŒ–ï¼Œä½†åœ¨ MinHash è¿‡æ»¤ä¸‹ä»æŒç»­å‘ç° **455 ä¸ªå…¨æ–°é«˜æ€§èƒ½æ¶æ„**ï¼Œæœªé™·å…¥æ¨¡å¼åç¼©ï¼ˆmode collapseï¼‰ã€‚

4. âœ… **è½»é‡çº§åé¦ˆè¶³ä»¥é©±åŠ¨æ˜¾è‘—æ”¹è¿›**  
   ä»…ç”¨å• epoch å‡†ç¡®ç‡è¿™ä¸€ä½ä¿çœŸä¿¡å·ï¼Œå³å¯å¼•å¯¼ LLM å®ç°æ€§èƒ½ä¸å¯é æ€§çš„åŒé‡æå‡ï¼ŒéªŒè¯äº†è¯¥èŒƒå¼çš„å¯æ‰©å±•æ€§ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä»»åŠ¡å•ä¸€æ€§**ï¼šä»…åœ¨ CIFAR-10 å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸ŠéªŒè¯ï¼Œæ³›åŒ–èƒ½åŠ›æœªçŸ¥ã€‚
2. **æ€§èƒ½ä»£ç†ä¸å®Œç¾**ï¼šå• epoch å‡†ç¡®ç‡å¯èƒ½åå¥½â€œå¿«é€Ÿå­¦ä¹ ä½†æ˜“é¥±å’Œâ€çš„æ¶æ„ï¼Œæœªå¿…ä»£è¡¨æœ€ç»ˆæ€§èƒ½æœ€ä¼˜ã€‚
3. **ç¼ºä¹ä¸ç»å…¸ NAS çš„å…¬å¹³æ¯”è¾ƒ**ï¼šæœªåœ¨ç›¸åŒè®¡ç®—é¢„ç®—ä¸‹å¯¹æ¯” RL/Evo/DARTS ç­‰æ–¹æ³•ã€‚
4. **æ–°é¢–æ€§å®šä¹‰åæ–‡æœ¬å±‚é¢**ï¼šMinHash åŸºäº token shinglesï¼Œæ— æ³•æ•æ‰åŠŸèƒ½ç­‰ä»·ä½†ä»£ç é£æ ¼ä¸åŒçš„æ¶æ„ï¼ˆè¯­ä¹‰å†—ä½™æœªå¤„ç†ï¼‰ã€‚
5. **åæœŸå‡ºç°æ€§èƒ½å¹³å°æœŸ**ï¼šcycle 18 åè¶‹äºé¥±å’Œï¼Œå¯èƒ½å› è‡ªç”Ÿæˆæ•°æ®ä¸»å¯¼å¯¼è‡´åˆ†å¸ƒçª„åŒ–ï¼ˆdata collapseï¼‰ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **é›†æˆåˆ°æ˜¾å¼ä¼˜åŒ–æ¡†æ¶ä¸­**ï¼šå°†è®­ç»ƒå¥½çš„ LLM ä½œä¸º **prior** ç”¨äº LLMaticã€SEKI æˆ– RZ-NAS ç­‰æœç´¢æ¡†æ¶ã€‚
2. **å¤šä»»åŠ¡æ³›åŒ–**ï¼šé€šè¿‡ multi-task prompting æ‰©å±•åˆ° ImageNetã€segmentationã€detection ç­‰ä»»åŠ¡ã€‚
3. **æ›´ç²¾ç»†çš„åé¦ˆæœºåˆ¶**ï¼šå¼•å…¥ performance-weighted sampling æˆ– RLHF æ›¿ä»£äºŒå€¼ç­›é€‰ã€‚
4. **å¤šç›®æ ‡çº¦æŸå»ºæ¨¡**ï¼šçº³å…¥å‚æ•°é‡ã€å»¶è¿Ÿã€èƒ½è€—ç­‰è¾¹ç¼˜è®¾å¤‡å…³é”®æŒ‡æ ‡ï¼Œæ”¯æŒ Pareto æ¢ç´¢ã€‚
5. **è¯­ä¹‰çº§æ–°é¢–æ€§æ£€æµ‹**ï¼šç»“åˆ computation graph embedding è€Œéä»…æºç æ–‡æœ¬ï¼Œæå‡å¤šæ ·æ€§åˆ¤æ–­å‡†ç¡®æ€§ã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬æ–‡æå‡ºå¹¶éªŒè¯äº†ä¸€ç§è®© LLM â€œè‡ªæˆ‘è¿›åŒ–â€ä¸ºç¥ç»æ¶æ„è®¾è®¡å¸ˆçš„æ–¹æ³•ï¼Œé€šè¿‡è½»é‡çº§åé¦ˆé—­ç¯ï¼ŒæˆåŠŸå®ç°äº†ä»**è®°å¿†å·²æœ‰ç»“æ„**åˆ°**åˆ›é€ æ€§è®¾è®¡é«˜æ€§èƒ½æ–°æ¶æ„**çš„è·¨è¶Šï¼Œä¸ºè‡ªåŠ¨åŒ–æ·±åº¦å­¦ä¹ å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚

</details>

---

### 16. [MindChat: A Privacy-preserving Large Language Model for Mental Health Support](https://arxiv.org/abs/2601.01993)

**Authors**: Dong Xue, Jicheng Tu, Ming Wang, Xin Yan, Fangzhou Liu, Jie Hu  
**Category**: cs.AI  
**Published**: 2026-01-07  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.01993v1  

#### Abstract
Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synth...

---

### 17. [Dementia-R1: Reinforced Pretraining and Reasoning from Unstructured Clinical Notes for Real-World Dementia Prognosis](https://arxiv.org/abs/2601.03018)

**Authors**: Choonghan Kim, Hyunmin Hwang, Hangeol Chang, Jaemin Kim, Jinse Park, Jae-Sung Lim, Jong Chul Ye  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.03018v1  

#### Abstract
While Large Language Models (LLMs) have shown strong performance on clinical text understanding, they struggle with longitudinal prediction tasks such as dementia prognosis, which require reasoning over complex, non-monotonic symptom trajectories across multiple visits. Standard supervised training ...

---

### 18. [Counterfactual Self-Questioning for Stable Policy Optimization in Language Models](https://arxiv.org/abs/2601.00885)

**Authors**: Mandar Parab  
**Category**: cs.AI  
**Published**: 2026-01-07  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.00885v1  

#### Abstract
Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and...

---

### 19. [ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems](https://arxiv.org/abs/2601.00994)

**Authors**: Michael Bao  
**Category**: cs.AI  
**Published**: 2026-01-07  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.00994v1  

#### Abstract
This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations...

---

### 20. [Reducing Hallucinations in LLMs via Factuality-Aware Preference Learning](https://arxiv.org/abs/2601.03027)

**Authors**: Sindhuja Chaduvula, Ahmed Y. Radwan, Azib Farooq, Yani Ioannou, Shaina Raza  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.03027v1  

#### Abstract
Preference alignment methods such as RLHF and Direct Preference Optimization (DPO) improve instruction following, but they can also reinforce hallucinations when preference judgments reward fluency and confidence over factual correctness. We introduce F-DPO (Factuality-aware Direct Preference Optimi...

---

### 21. [Uni-FinLLM: A Unified Multimodal Large Language Model with Modular Task Heads for Micro-Level Stock Prediction and Macro-Level Systemic Risk Assessment](https://arxiv.org/abs/2601.02677)

**Authors**: Gongao Zhang, Haijiang Zeng, Lu Jiang  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.02677v1  

#### Abstract
Financial institutions and regulators require systems that integrate heterogeneous data to assess risks from stock fluctuations to systemic vulnerabilities. Existing approaches often treat these tasks in isolation, failing to capture cross-scale dependencies. We propose Uni-FinLLM, a unified multimo...

---

### 22. [Scalable Tree Ensemble Proximities in Python](https://arxiv.org/abs/2601.02735)

**Authors**: Adrien Aumon, Guy Wolf, Kevin R. Moon, Jake S. Rhodes  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.02735v1  

#### Abstract
Tree ensemble methods such as Random Forests naturally induce supervised similarity measures through their decision tree structure, but existing implementations of proximities derived from tree ensembles typically suffer from quadratic time or memory complexity, limiting their scalability. In this w...

---

### 23. [Electricity Price Forecasting: Bridging Linear Models, Neural Networks and Online Learning](https://arxiv.org/abs/2601.02856)

**Authors**: Btissame El Mahtout, Florian Ziel  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.02856v1  

#### Abstract
Precise day-ahead forecasts for electricity prices are crucial to ensure efficient portfolio management, support strategic decision-making for power plant operations, enable efficient battery storage optimization, and facilitate demand response planning. However, developing an accurate prediction mo...

---

### 24. [Universal Conditional Logic: A Formal Language for Prompt Engineering](https://arxiv.org/abs/2601.00880)

**Authors**: Anthony Mikinka  
**Category**: cs.AI  
**Published**: 2026-01-07  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.00880v1  

#### Abstract
We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t...

---

### 25. [Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement](https://arxiv.org/abs/2601.01562)

**Authors**: Mingyu Xu, Cheng Fang, Keyue Jiang, Yuqian Zheng, Yanghua Xiao, Baojian Zhou, Qifang Zhao, Suhang Zheng, Xiuwen Zhu, Jiyang Tang, Yongchi Zhao, Yijia Luo, Zhiqi Bai, Yuchi Xu, Wenbo Su, Wei Wang, Bing Zhao, Lin Qu, Xiaoxiao Xu  
**Category**: cs.AI  
**Published**: 2026-01-07  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.01562v1  

#### Abstract
We present Logics-STEM, a state-of-the-art reasoning model fine-tuned on Logics-STEM-SFT-Dataset, a high-quality and diverse dataset at 10M scale that represents one of the largest-scale open-source long chain-of-thought corpora. Logics-STEM targets reasoning tasks in the domains of Science, Technol...

---

### 26. [Yuan3.0 Flash: An Open Multimodal Large Language Model for Enterprise Applications](https://arxiv.org/abs/2601.01718)

**Authors**: YuanLab. ai,  :, Shawn Wu, Sean Wang, Louie Li, Darcy Chen, Allen Wang, Jiangang Luo, Xudong Zhao, Joseph Shen, Gawain Ma, Jasper Jia, Marcus Mao, Claire Wang, Hunter He, Carol Wang, Zera Zhang, Jason Wang, Chonly Shen, Leo Zhang, Logan Chen, Qasim Meng, James Gong, Danied Zhao, Penn Zheng, Owen Zhu, Tong Yu  
**Category**: cs.AI  
**Published**: 2026-01-07  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.01718v1  

#### Abstract
We introduce Yuan3.0 Flash, an open-source Mixture-of-Experts (MoE) MultiModal Large Language Model featuring 3.7B activated parameters and 40B total parameters, specifically designed to enhance performance on enterprise-oriented tasks while maintaining competitive capabilities on general-purpose ta...

---

### 27. [Scalable Construction of a Lung Cancer Knowledge Base: Profiling Semantic Reasoning in LLMs](https://arxiv.org/abs/2601.02604)

**Authors**: Cesar Felipe Mart\'inez Cisneros, Jes\'us Ulises Quiroz Bautista, Claudia Anah\'i Guzm\'an Solano, Bogdan Kaleb Garc\'ia Rivera, Iv\'an Garc\'ia Pacheco, Yalbi Itzel Balderas Mart\'inez, Kolawole John Adebayoc, Ignacio Arroyo Fern\'andez  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.02604v1  

#### Abstract
The integration of Large Language Models (LLMs) into biomedical research offers new opportunities for domainspecific reasoning and knowledge representation. However, their performance depends heavily on the semantic quality of training data. In oncology, where precision and interpretability are vita...

---

### 28. [Towards Comprehensive Stage-wise Benchmarking of Large Language Models in Fact-Checking](https://arxiv.org/abs/2601.02669)

**Authors**: Hongzhan Lin, Zixin Chen, Zhiqi Shen, Ziyang Luo, Zhen Ye, Jing Ma, Tat-Seng Chua, Guandong Xu  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.02669v1  

#### Abstract
Large Language Models (LLMs) are increasingly deployed in real-world fact-checking systems, yet existing evaluations focus predominantly on claim verification and overlook the broader fact-checking workflow, including claim extraction and evidence retrieval. This narrow focus prevents current benchm...

---

### 29. [Iterative Structured Pruning for Large Language Models with Multi-Domain Calibration](https://arxiv.org/abs/2601.02674)

**Authors**: Guangxin Wu, Hao Zhang, Zhang Zhibin, Jiafeng Guo, Xueqi Cheng  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.02674v1  

#### Abstract
Large Language Models (LLMs) have achieved remarkable success across a wide spectrum of natural language processing tasks. However, their ever-growing scale introduces significant barriers to real-world deployment, including substantial computational overhead, memory footprint, and inference latency...

---

### 30. [LLM-Augmented Changepoint Detection: A Framework for Ensemble Detection and Automated Explanation](https://arxiv.org/abs/2601.02957)

**Authors**: Fabian Lukassen, Christoph Weisser, Michael Schlee, Manish Kumar, Anton Thielmann, Benjamin Saefken, Thomas Kneib  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.02957v1  

#### Abstract
This paper introduces a novel changepoint detection framework that combines ensemble statistical methods with Large Language Models (LLMs) to enhance both detection accuracy and the interpretability of regime changes in time series data. Two critical limitations in the field are addressed. First, in...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
