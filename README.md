# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-11 06:47:43 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [LLM-CoOpt: A Co-Design and Optimization Framework for Efficient LLM Inference on Heterogeneous Platforms](https://arxiv.org/abs/2602.09323)

**Authors**: Jie Kong, Wei Wang, Jiehan Zhou, Chen Yu  
**Category**: cs.DC  
**Published**: 2026-02-11  
**Score**: 14.5  
**Type**: new  
**ArXiv ID**: 2602.09323v1  

#### Abstract
Major challenges in LLMs inference remain frequent memory bandwidth bottlenecks, computational redundancy, and inefficiencies in long-sequence processing. To address these issues, we propose LLM-CoOpt, a comprehensive algorithmhardware co-design framework aimed at improving both throughput and laten...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLLM-CoOpt: A Co-Design and Optimization Framework for Efficient LLM Inference on Heterogeneous Platforms

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¼‚æ„å¹³å°ä¸Šçš„æ¨ç†é¢ä¸´ä¸‰å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼š
- **KV Cache å†…å­˜ç“¶é¢ˆ**ï¼šè‡ªå›å½’è§£ç è¿‡ç¨‹ä¸­ï¼ŒKey-Value ç¼“å­˜éšåºåˆ—é•¿åº¦çº¿æ€§å¢é•¿ï¼Œå¯¼è‡´å†…å­˜å ç”¨é«˜ã€å¸¦å®½å‹åŠ›å¤§ï¼›
- **Multi-Head Attention çš„è®¡ç®—å†—ä½™**ï¼šæ¯ä¸ªæ³¨æ„åŠ›å¤´ç‹¬ç«‹ç”Ÿæˆ K/V å‘é‡ï¼Œé€ æˆé‡å¤è®¡ç®—å’Œç¡¬ä»¶èµ„æºåˆ©ç”¨ç‡ä½ï¼›
- **é•¿åºåˆ—å¤„ç†æ•ˆç‡ä½ä¸‹**ï¼šSelf-Attention å…·æœ‰ $O(T^2)$ å¤æ‚åº¦ï¼Œä¸”ä¼ ç»Ÿ PagedAttention å­˜åœ¨å†…å­˜ç¢ç‰‡åŒ–å’ŒåŒæ­¥å¼€é”€ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **LLM-CoOpt** â€”â€” ä¸€ç§é¢å‘å¼‚æ„å¹³å°çš„ç®—æ³•-ç¡¬ä»¶ååŒä¼˜åŒ–æ¡†æ¶ï¼Œé›†æˆä¸‰é¡¹å…³é”®æŠ€æœ¯ï¼š

#### (1) **Opt-KV**ï¼šåŠ¨æ€ KV Cache ä¼˜åŒ–
- åœ¨å†™å…¥é˜¶æ®µè·³è¿‡æ— æ•ˆ/å†—ä½™ token çš„ KV ç¼“å­˜ï¼›
- å¼•å…¥ **FP8 é‡åŒ–** å‹ç¼©å­˜å‚¨ï¼Œå‡å°‘å†…å­˜å ç”¨ï¼›
- æ”¯æŒæ¨ç†æ—¶æŒ‰éœ€åé‡åŒ–ï¼ˆon-the-fly dequantizationï¼‰ï¼Œå…¼é¡¾ç²¾åº¦ä¸æ•ˆç‡ã€‚

#### (2) **Opt-GQA**ï¼šè½»é‡çº§ Grouped-Query Attention
- å°† Query Heads åˆ†ç»„ï¼Œæ¯ç»„å…±äº«ä¸€ç»„ Key-Value Headsï¼›
- å‡å°‘ K/V æŠ•å½±è®¡ç®—é‡ï¼Œæå‡å¹¶è¡Œæ•ˆç‡ï¼›
- åŠ¨æ€é€‚é…ä¸åŒè¾“å…¥åˆ†å¸ƒå’Œç¡¬ä»¶å¹¶è¡Œèƒ½åŠ›ï¼Œä¼˜äºå›ºå®šåˆ†ç»„ç­–ç•¥ã€‚

#### (3) **Opt-Pa**ï¼šä¼˜åŒ–çš„ Paged Attention è®¾è®¡
- é‡‡ç”¨ä¸¤æ­¥ç­–ç•¥ï¼šå…ˆå¯¹é•¿åºåˆ—è¿›è¡Œé€»è¾‘åˆ†å—ï¼ˆLS segmentationï¼‰ï¼Œå†é€šè¿‡æ‡’åŠ è½½æœºåˆ¶ä»…åŠ è½½æœ‰æ•ˆå—ï¼›
- åˆ©ç”¨ **shared-memory reduction** æ›¿ä»£ warp-level reductionï¼Œé™ä½ Softmax åŒæ­¥å¼€é”€ï¼›
- æ˜¾è‘—ç¼“è§£å†…å­˜ç¢ç‰‡å’Œå¸¦å®½é¥±å’Œé—®é¢˜ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹å‘ | ç°æœ‰æ–¹æ³•å±€é™ | LLM-CoOpt æ”¹è¿› |
|------|---------------|----------------|
| KV Cache | é™æ€é‡åŒ–ä¸é€‚åº”åŠ¨æ€èŒƒå›´ï¼›FP8 ä¸ç¨³å®š | åŠ¨æ€è¿‡æ»¤ + FP8 å®‰å…¨å‹ç¼© |
| GQA | å›ºå®šåˆ†ç»„æ— æ³•é€‚åº”ç¡¬ä»¶/è¾“å…¥å˜åŒ– | å¯é…ç½®åˆ†ç»„ï¼Œæå‡çµæ´»æ€§ä¸èµ„æºåˆ©ç”¨ç‡ |
| PagedAttention | å†…å­˜ç¢ç‰‡ä¸¥é‡ï¼ŒåŒæ­¥å¼€é”€é«˜ | æ‡’åŠ è½½ + å—çº§ Softmax ä¼˜åŒ– |

> âœ… **æ•´ä½“ä¼˜åŠ¿**ï¼šå®ç°äº† **throughput æå‡ã€latency ä¸‹é™ã€accuracy ä¿æŒç”šè‡³ç•¥æœ‰ä¸Šå‡** çš„ä¸‰é‡æ”¶ç›Šã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **ååé‡è¯„ä¼°**ï¼š`ShareGPT_V3_unfiltered_cleaned_split` æ•°æ®é›†  
  - åŒ…å«çº¦ 35,240 æ¡çœŸå®å¯¹è¯æ ·æœ¬ï¼Œè¦†ç›–é—®ç­”ã€é—²èŠã€çŸ¥è¯†å’¨è¯¢ç­‰åœºæ™¯ï¼›
  - æ€»æ•°æ®é‡ ~178 MBã€‚
- **å‡†ç¡®ç‡è¯„ä¼°**ï¼š`ARC` æ•°æ®é›†ï¼ˆAI2 Reasoning Challengeï¼‰
  - åˆ†ä¸ºä¸¤ä¸ªå­é›†ï¼š
    - **ARC_C**ï¼ˆChallenge Setï¼‰ï¼š7,787 é“å°å­¦ç§‘å­¦éš¾é¢˜ï¼Œéœ€æ·±å±‚æ¨ç†ï¼›
    - **ARC_E**ï¼ˆEasy Setï¼‰ï¼šç›¸å¯¹ç®€å•çš„é—®é¢˜é›†åˆã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šDCU Z100 å¼‚æ„å¹³å°
  - L2 Cache: ~4MB
  - å†…å­˜å¸¦å®½: 512 GB/s (GDDR6)
  - æ”¯æŒ FP16 / æ¨¡æ‹Ÿ FP8ï¼ˆvia INT8ï¼‰
  - Wavefront Size: 64ï¼Œæ”¯æŒ SIMD å¹¶è¡Œ
- **æ¨¡å‹**ï¼šå¤šä¸ª GPTQ é‡åŒ–ç‰ˆæœ¬çš„ LLaMa ç³»åˆ—æ¨¡å‹
  - `LLaMa-7B-GPTQ`, `LLaMa2-7B-GPTQ`
  - `LLaMa-13B-GPTQ`, `LLaMa2-13B-GPTQ`
  - `LLaMa-Pro-8B-GPTQ`

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ | å…¬å¼ |
|------|------|-------|
| **Inference Latency** | å•æ¬¡ä»»åŠ¡å¹³å‡å“åº”å»¶è¿Ÿ | $\text{Latency} = \frac{1}{N}\sum_{i=1}^{N} \text{latency}_i$ |
| **Generation Throughput** | æ¯ç§’ç”Ÿæˆ token æ•° | $\text{Throughput} = \frac{\text{Total Generated Tokens}}{\text{Generation Time}}$ |
| **Inference Accuracy** | æ­£ç¡®é¢„æµ‹æ¯”ä¾‹ | $\text{Accuracy} = \frac{N_{\text{correct}}}{N_{\text{total}}} \times 100\%$ |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**ï¼šåŸå§‹ vLLM æ¨ç†å¼•æ“ï¼ˆæœªä¼˜åŒ–ç‰ˆæœ¬ï¼‰
- å¯¹æ¯”é¡¹åŒ…æ‹¬ï¼š
  - å•ç‹¬å¯ç”¨ Opt-KV / Opt-GQA / Opt-Pa
  - ç»„åˆå¯ç”¨ LLM-CoOptï¼ˆä¸‰è€…è”åˆï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ LLaMa-13B-GPTQ ä¸ºä¾‹ï¼‰

| æŒ‡æ ‡ | Baseline (Original) | LLM-CoOpt | æå‡å¹…åº¦ |
|------|---------------------|-----------|----------|
| **Latency** | åŸºå‡†å€¼ | â†“ æœ€å¤š **16.79%** | æ˜¾è‘—ä¸‹é™ |
| **Throughput** | åŸºå‡†å€¼ | â†‘ æœ€å¤š **13.43%** | æ˜æ˜¾æå‡ |

> æ³¨ï¼šæ‰€æœ‰æ¨¡å‹å‡è§‚å¯Ÿåˆ°ä¸€è‡´è¶‹åŠ¿ï¼Œå°¤å…¶åœ¨å¤§æ¨¡å‹ä¸Šå¢ç›Šæ›´æ˜¾è‘—ã€‚

### ğŸ“Š è¯¦ç»†å¯¹æ¯”ç»“æœï¼ˆæ¥è‡ª Fig. 6 & Fig. 7ï¼‰

#### æ¨ç†å»¶è¿Ÿé™ä½ï¼ˆâ†“ è¶Šå¥½ï¼‰
| Model | Latency Reduction |
|-------|--------------------|
| LLaMa-7B-GPTQ | 5.59% |
| LLaMa2-7B-GPTQ | 5.48% |
| LLaMa-13B-GPTQ | **6.75%** |
| LLaMa2-13B-GPTQ | 6.18% |
| LLaMa-Pro-8B-GPTQ | 4.82% |

#### ç”Ÿæˆååæå‡ï¼ˆâ†‘ è¶Šå¥½ï¼‰
| Model | Throughput Increase |
|-------|----------------------|
| LLaMa-7B-GPTQ | 7.20% |
| LLaMa2-7B-GPTQ | 6.13% |
| LLaMa-13B-GPTQ | **12.13%** |
| LLaMa2-13B-GPTQ | 10.85% |
| LLaMa-Pro-8B-GPTQ | 5.72% |

> ğŸ’¡ **æœ€å¤§æ”¶ç›Šå‡ºç°åœ¨ LLaMa-13B-GPTQ ä¸Š**ï¼Œè¯´æ˜è¯¥æ¡†æ¶å¯¹å¤§è§„æ¨¡æ¨¡å‹æ›´å…·ä¼˜åŒ–æ½œåŠ›ã€‚

### ğŸ” æ¶ˆèå®éªŒåˆ†æï¼ˆAblation Studyï¼‰
è™½ç„¶æ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨æ ¼ï¼Œä½†ä»å„æ¨¡å—å•ç‹¬æµ‹è¯•å¯æ¨æ–­ï¼š
- **Opt-KV**ï¼šä¸»è¦è´¡çŒ®äºå†…å­˜èŠ‚çœå’Œè¯»å†™æ•ˆç‡æå‡ï¼›
- **Opt-GQA**ï¼šæ˜¾è‘—é™ä½è®¡ç®—è´Ÿè½½ï¼Œæé«˜ head åˆ©ç”¨ç‡ï¼›
- **Opt-Pa**ï¼šå…³é”®æ”¹å–„é•¿åºåˆ—ä¸‹çš„å†…å­˜å±€éƒ¨æ€§å’ŒåŒæ­¥æ•ˆç‡ï¼›
- **ä¸‰è€…ååŒ**ï¼šè¡¨ç°å‡ºæ˜æ˜¾ **synergistic effectï¼ˆååŒæ•ˆåº”ï¼‰**ï¼Œç»¼åˆæ€§èƒ½ä¼˜äºä»»ä¸€å•ä¸€ä¼˜åŒ–ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **LLM-CoOpt æ˜¾è‘—æå‡äº†å¼‚æ„å¹³å°ä¸Š LLM æ¨ç†çš„æ•´ä½“æ€§èƒ½**ï¼š
   - æœ€é«˜å®ç° **13.43% çš„ååæå‡** å’Œ **16.79% çš„å»¶è¿Ÿä¸‹é™**ï¼›
   - åœ¨å¤šç§ LLaMa æ¶æ„ä¸­è¡¨ç°ç¨³å¥ï¼Œå…·å¤‡è‰¯å¥½çš„æ³›åŒ–æ€§ã€‚

2. **ç²¾åº¦å‡ ä¹æ— æŸï¼Œéƒ¨åˆ†æƒ…å†µä¸‹åè€Œæå‡**ï¼š
   - åœ¨ **ARC_C** ä¸Šå¤šæ•°æ¨¡å‹ accuracy ç•¥æœ‰ä¸Šå‡ï¼ˆå¦‚ LLaMa-13B ä» 39.66% â†’ 40.01%ï¼‰ï¼›
   - åœ¨ **ARC_E** ä¸Šæ‰€æœ‰æ¨¡å‹ accuracy å‡å°å¹…æå‡ï¼ˆå¦‚ LLaMa-Pro-8B ä» 42.15% â†’ 42.50%ï¼‰ï¼›
   - è¡¨æ˜ä¼˜åŒ–æœªç‰ºç‰²è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œç”šè‡³å¯èƒ½å› æ›´é«˜æ•ˆçš„æ•°æ®æµåŠ¨å¸¦æ¥ç¨³å®šæ€§å¢å¼ºã€‚

3. **Opt-KV + FP8 æ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„å†…å­˜å‹ç¼©è·¯å¾„**ï¼š
   - æˆåŠŸå°† FP8 åº”ç”¨äº KV Cacheï¼Œåœ¨ä¿è¯æ•°å€¼ç¨³å®šçš„å‰æä¸‹å¤§å¹…å‡å°å†…å­˜å ç”¨ï¼›
   - ä¸ºæœªæ¥ä½æ¯”ç‰¹æ¨ç†ç³»ç»Ÿæä¾›å®è·µå‚è€ƒã€‚

4. **Opt-Pa æœ‰æ•ˆç¼“è§£äº†é•¿åºåˆ—æ¨ç†ä¸­çš„å†…å­˜ç¢ç‰‡ä¸åŒæ­¥ç“¶é¢ˆ**ï¼š
   - é€šè¿‡ lazy loading å’Œ block-wise reduction æ˜¾è‘—æå‡ memory localityï¼›
   - ç‰¹åˆ«é€‚åˆå¤„ç†è¶…é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ï¼ˆå¦‚æ–‡æ¡£æ‘˜è¦ã€ä»£ç ç”Ÿæˆï¼‰ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰å®éªŒé›†ä¸­åœ¨ **GPTQ é‡åŒ–æ¨¡å‹**ï¼Œå°šæœªéªŒè¯åœ¨å…¶ä»–é‡åŒ–æ–¹æ¡ˆï¼ˆå¦‚ AWQã€INT4ï¼‰ä¸‹çš„å…¼å®¹æ€§ï¼›
- æ‰€æœ‰æµ‹è¯•åŸºäº **å•è®¾å¤‡ DCU å¹³å°**ï¼Œç¼ºä¹å¤šå¡æˆ–å¤šèŠ‚ç‚¹æ‰©å±•æ€§éªŒè¯ï¼›
- **FP8 æ¨¡æ‹Ÿä¾èµ– INT8 æŒ‡ä»¤**ï¼Œå®é™…åŠ é€Ÿæ•ˆæœå—é™äºç¡¬ä»¶åŸç”Ÿæ”¯æŒç¨‹åº¦ï¼›
- åˆ†ç»„ç­–ç•¥ï¼ˆOpt-GQAï¼‰ä»ä¸ºé™æ€é…ç½®ï¼Œæœªå®ç°å®Œå…¨åŠ¨æ€è‡ªé€‚åº”ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‹“å±•è‡³å¤šæ¨¡æ€åœºæ™¯**ï¼šç»“åˆ dynamic batching ä¸ sparse computingï¼Œæ”¯æŒå›¾åƒ-æ–‡æœ¬è”åˆæ¨ç†ï¼›
2. **è·¨å¹³å°éƒ¨ç½²ä¼˜åŒ–**ï¼šé€‚é…æ›´å¤šå¼‚æ„æ¶æ„ï¼ˆå¦‚ NPUã€TPU-like è®¾å¤‡ï¼‰ï¼›
3. **å…¨è‡ªåŠ¨å‚æ•°è°ƒä¼˜**ï¼šå¼•å…¥ RL æˆ– NAS æŠ€æœ¯è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜åˆ†ç»„æ•°ã€å—å¤§å°ç­‰è¶…å‚ï¼›
4. **ç«¯åˆ°ç«¯ç¼–è¯‘å™¨é›†æˆ**ï¼šå°† LLM-CoOpt æ€è·¯èå…¥ TVMã€MLIR ç­‰ç¼–è¯‘æ ˆï¼Œå®ç°è‡ªåŠ¨åŒ–ä¼˜åŒ–æµæ°´çº¿ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **LLM-CoOpt é€šè¿‡ç®—æ³•-ç¡¬ä»¶ååŒè®¾è®¡ï¼ŒæˆåŠŸè§£å†³äº† LLM åœ¨å¼‚æ„å¹³å°ä¸Šçš„å†…å­˜ã€è®¡ç®—ä¸é•¿åºåˆ—ç“¶é¢ˆï¼Œåœ¨ä¸æŸå¤± accuracy çš„å‰æä¸‹æ˜¾è‘—æå‡äº† throughput ä¸ latencyï¼Œæ˜¯è¿ˆå‘é«˜æ•ˆè¾¹ç¼˜/ä¸“ç”¨è®¾å¤‡éƒ¨ç½²çš„é‡è¦ä¸€æ­¥ã€‚**

</details>

---

### 2. [Rollout-Training Co-Design for Efficient LLM-Based Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.09578)

**Authors**: Zhida Jiang, Zhaolong Xing, Jiawei Lu, Yipei Niu, Qingyuan Sang, Liangxu Zhang, Wenquan Dai, Junhua Shu, Jiaxing Wang, Qiangyu Pei, Qiong Chen, Xinyu Liu, Fangming Liu, Ai Han, Zhen Chen, Ke Zhang  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 12.5  
**Type**: new  
**ArXiv ID**: 2602.09578v1  

#### Abstract
Despite algorithm-level innovations for multi-agent reinforcement learning (MARL), the underlying networked infrastructure for large-scale MARL training remains underexplored. Existing training frameworks primarily optimize for single-agent scenarios and fail to address the unique system-level chall...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRollout-Training Co-Design for Efficient LLM-Based Multi-Agent Reinforcement Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
ç°æœ‰çš„ **Multi-Agent Reinforcement Learning (MARL)** ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ç®—æ³•å±‚é¢ï¼ˆå¦‚é€šä¿¡åè®®ã€åè°ƒç­–ç•¥ï¼‰ï¼Œè€Œåº•å±‚æ”¯æŒå¤§è§„æ¨¡è®­ç»ƒçš„**ç½‘ç»œåŒ–åŸºç¡€è®¾æ–½**ä»ä¸æˆç†Ÿã€‚è¿™å¯¼è‡´ä¸‰ä¸ªç³»ç»Ÿçº§æŒ‘æˆ˜ä¸¥é‡åˆ¶çº¦è®­ç»ƒæ•ˆç‡ï¼š

- **Rollout-Training åŒæ­¥éšœç¢ï¼ˆSynchronization Barriersï¼‰**ï¼šç”±äºéƒ¨åˆ† agent å“åº”æ—¶é—´æé•¿ï¼ˆlong-tail effectï¼‰ï¼Œæ•´ä¸ªè®­ç»ƒå¿…é¡»ç­‰å¾…æœ€æ…¢çš„ rollout å®Œæˆã€‚
- **Rollout è´Ÿè½½ä¸å‡è¡¡ï¼ˆLoad Imbalanceï¼‰**ï¼šæ ¸å¿ƒ agent è¯·æ±‚å¯†é›†ï¼Œè¾…åŠ© agent åˆ©ç”¨ç‡ä½ï¼Œé€ æˆè¯·æ±‚æ’é˜Ÿå’Œèµ„æºæµªè´¹ã€‚
- **è®­ç»ƒèµ„æºåˆ©ç”¨ç‡ä½ä¸‹ï¼ˆResource Underutilizationï¼‰**ï¼šé™æ€èµ„æºåˆ†é…ç­–ç•¥ä¸‹ï¼Œæœªæ¿€æ´» agent å ç”¨è®¡ç®—ä¸å†…å­˜èµ„æºï¼Œæ— æ³•åŠ¨æ€é‡Šæ”¾ã€‚

ä¸»æµæ¡†æ¶ï¼ˆå¦‚ OpenRLHFã€veRLï¼‰ä»…æ”¯æŒå• agent åœºæ™¯ï¼›å³ä½¿è¿‘æœŸæå‡ºçš„ MARL æ¡†æ¶ï¼ˆå¦‚ MARTIï¼‰ä¹Ÿé‡‡ç”¨å…±ç½®æ¶æ„ï¼ˆcolocated architectureï¼‰å’Œå›ºå®šèµ„æºç»‘å®šï¼Œéš¾ä»¥åº”å¯¹ä¸Šè¿°æŒ‘æˆ˜ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡º **FlexMARL** â€”â€” é¦–ä¸ªç«¯åˆ°ç«¯ï¼ˆend-to-endï¼‰ä¸ºå¤§è§„æ¨¡ LLM-based MARL è®¾è®¡çš„è®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡ **rollout ä¸ training ååŒè®¾è®¡ï¼ˆco-designï¼‰** å®ç°ç³»ç»Ÿçº§ä¼˜åŒ–ã€‚å…¶ä¸‰å¤§æ ¸å¿ƒç»„ä»¶å¦‚ä¸‹ï¼š

#### âœ… Joint Orchestratorï¼ˆè”åˆè°ƒåº¦å™¨ï¼‰
- å¼•å…¥ **experience store** ä½œä¸ºç»“æ„åŒ–å­˜å‚¨æ¨¡å—ï¼Œç®¡ç† rollout ä¸ training ä¹‹é—´çš„æ•°æ®æµã€‚
- æ„å»ºåŸºäºå¾®æ‰¹æ¬¡ï¼ˆmicro-batchï¼‰çš„å¼‚æ­¥æµæ°´çº¿ï¼Œè§£è€¦æ¢¯åº¦è®¡ç®—ä¸å‚æ•°æ›´æ–°ï¼Œåœ¨æ¶ˆé™¤åŒæ­¥é˜»å¡çš„åŒæ—¶ä¿æŒåŒæ­¥è®­ç»ƒè¯­ä¹‰ï¼ˆstrong consistencyï¼‰ã€‚

#### âœ… Rollout Engineï¼ˆå¹¶è¡Œé‡‡æ ·å¼•æ“ï¼‰
- é‡‡ç”¨ **dependency-driven å¹¶è¡Œé‡‡æ ·æœºåˆ¶**ï¼Œå®ç°è·¨æŸ¥è¯¢ï¼ˆinter-queryï¼‰ä¸æŸ¥è¯¢å†…ï¼ˆintra-queryï¼‰è½¨è¿¹ç”Ÿæˆçš„å¹¶å‘æ‰§è¡Œã€‚
- è®¾è®¡ **åˆ†å±‚è´Ÿè½½å‡è¡¡ï¼ˆhierarchical load balancingï¼‰**ï¼š
  - **Intra-agent**ï¼šåœ¨å•ä¸ª agent å†…éƒ¨åŠ¨æ€æ‰©ç¼© inference instancesã€‚
  - **Inter-agent**ï¼šè·¨ agent è¿ç§»æ¨ç†å®¹é‡ï¼Œç¼“è§£çƒ­ç‚¹ç“¶é¢ˆã€‚

#### âœ… Training Engineï¼ˆæŒ‰éœ€è®­ç»ƒå¼•æ“ï¼‰
- å®ç° **agent-centric èµ„æºåˆ†é…**ï¼šä»…å½“ agent éœ€è¦è®­ç»ƒæ—¶æ‰åŠ¨æ€ç»‘å®šç¡¬ä»¶èµ„æºã€‚
- å¼•å…¥é«˜æ•ˆçš„ **training state swap æœºåˆ¶**ï¼Œåˆ©ç”¨ç»Ÿä¸€çš„ `Set/Get API` åœ¨è®¾å¤‡å†…å­˜ï¼ˆHBMï¼‰ä¸ä¸»æœºå†…å­˜é—´è¿ç§»æ¨¡å‹æƒé‡ä¸ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œé¿å… OOMã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | é€šç”¨ RL æ¡†æ¶ï¼ˆå¦‚ OpenRLHFï¼‰ | ä¸“ç”¨ MARL æ¡†æ¶ï¼ˆå¦‚ MARTIï¼‰ | **FlexMARLï¼ˆæœ¬æ–‡ï¼‰** |
|------|-------------------------------|-----------------------------|------------------------|
| å¤š agent æ”¯æŒ | âŒ | âœ… | âœ… |
| è§£è€¦éƒ¨ç½²ï¼ˆDisaggregationï¼‰ | âœ… | âŒ | âœ… |
| å¼‚æ­¥ Rollout-Training | âœ… | âš ï¸ï¼ˆæœ‰é™ï¼‰ | âœ…ï¼ˆç»†ç²’åº¦ micro-batchï¼‰ |
| Rollout è´Ÿè½½å‡è¡¡ | âŒ | âŒ | âœ…ï¼ˆåˆ†å±‚å¼¹æ€§æ‰©ç¼©ï¼‰ |
| Agent-Centric èµ„æºåˆ†é… | âŒ | âŒ | âœ… |

> âœ… è¡¨ç¤ºæ”¯æŒï¼ŒâŒ è¡¨ç¤ºä¸æ”¯æŒï¼Œâš ï¸ è¡¨ç¤ºéƒ¨åˆ†æ”¯æŒ

FlexMARL æ˜¯é¦–ä¸ªä»ç³»ç»Ÿå±‚é¢å…¨é¢è§£å†³ MARL è®­ç»ƒä¸­ **åŒæ­¥å»¶è¿Ÿã€è´Ÿè½½å€¾æ–œã€èµ„æºé—²ç½®** ä¸‰å¤§ç“¶é¢ˆçš„æ¡†æ¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **Merchant Assistant (MA) Dataset**  
  å¤š agent åä½œå®Œæˆç”µå•†åº—é“ºç®¡ç†ä»»åŠ¡ï¼ˆé”€å”®åˆ†æã€è¥é”€ä¼˜åŒ–ã€å”®åå¤„ç†ï¼‰ã€‚ä½¿ç”¨ **Qwen2.5-14B** æ¨¡å‹ä½œä¸º backboneï¼Œæ¯ä¸ª agent ä¸å…±äº«å‚æ•°ã€‚
  
- **Category Assistant (CA) Dataset**  
  è´Ÿè´£è®¢å•æŸ¥è¯¢ã€å®šä»·ç­–ç•¥ä¸åº“å­˜å»ºè®®ã€‚æ¶‰åŠä¸¤ç§æ¨¡å‹è§„æ¨¡ï¼š**Qwen2.5-14B å’Œ Qwen2.5-32B**ï¼Œç”¨äºæµ‹è¯•å¼‚æ„éƒ¨ç½²èƒ½åŠ›ã€‚

> æ³¨ï¼šå› å•†ä¸šä¿å¯†åŸå› ï¼Œå…·ä½“æ•°æ®ç»†èŠ‚æœªå…¬å¼€ã€‚

---

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š48 èŠ‚ç‚¹é›†ç¾¤ï¼Œæ¯èŠ‚ç‚¹é…å¤‡ 16 ä¸ªå•†ç”¨ NPUï¼ˆ64GB æ˜¾å­˜ï¼‰ï¼Œé€šè¿‡ HCCS äº’è”ã€‚
- **åç«¯å®ç°**ï¼š
  - Rolloutï¼šé›†æˆ vLLM v0.9.1 å®ç°ä½å»¶è¿Ÿæ¨ç†ã€‚
  - Trainingï¼šåŸºäº DeepSpeed v0.16.9 + ZeRO-3ã€‚
- **å…³é”®é…ç½®**ï¼š
  - å¹¶è¡Œé‡‡æ ·ï¼šinter-query = 4, intra-query = 16
  - å“åº”é•¿åº¦ä¸Šé™ï¼š8192 tokens
  - Batch size / Micro-batch sizeï¼š64 / 16
  - è´Ÿè½½å‡è¡¡é˜ˆå€¼ Î”ï¼š5
  - ä¼˜åŒ–ç®—æ³•ï¼šGRPOï¼Œå­¦ä¹ ç‡ 1e-6ï¼ŒAdam ä¼˜åŒ–å™¨

---

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **E2E Time** | å•æ ·æœ¬å¹³å‡ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆrollout + training + å…¶ä»–ï¼‰ |
| **Speedup** | ç›¸å¯¹äºåŸºçº¿ï¼ˆMAS-RLï¼‰çš„é€Ÿåº¦æå‡å€æ•° |
| **Throughput** | æ¯ç§’ç”Ÿæˆ token æ•°ï¼ˆtpsï¼‰ |
| **Agent Load** | å„ agent å¤„ç†çš„ rollout è¯·æ±‚æ•°é‡ |
| **Hardware Utilization Rate** | AI æ ¸å¿ƒæ´»è·ƒæ—¶é—´å æ¯” |
| **State Swap Overhead** | æ¨¡å‹çŠ¶æ€åŠ è½½/å¸è½½è€—æ—¶ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **MAS-RL** | å°†å• agent RL æ¡†æ¶ç›´æ¥è¿ç§»åˆ°å¤š agent åœºæ™¯ï¼Œé‡‡ç”¨å…±ç½®æ¶æ„ä¸ä¸²è¡Œ rollout |
| **DistRL** | ä½¿ç”¨è§£è€¦æ¶æ„ï¼ˆdisaggregated architectureï¼‰ï¼Œä½†æ— ç»†ç²’åº¦å¼‚æ­¥æµæ°´çº¿ |
| **MARTI (ICLR 2026)** | å½“å‰æœ€å…ˆè¿›çš„ MARL æ¡†æ¶ï¼Œæ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒä¸å¼‚æ­¥ rolloutï¼Œä½†èµ„æºé™æ€ç»‘å®š |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2 å’Œ Figure 7ï¼‰

| Dataset | Framework | E2E Time | Speedup | Throughput (tps) |
|--------|-----------|----------|---------|------------------|
| MA | MAS-RL | 914.4s | 1.0Ã— | 119.0 |
| MA | DistRL | 293.8s | 3.1Ã— | 401.0 |
| MA | MARTI | 174.1s | 5.3Ã— | 642.8 |
| MA | **FlexMARL** | **126.1s** | **7.3Ã—** | **910.2** |
| CA | MAS-RL | 438.6s | 1.0Ã— | 265.5 |
| CA | DistRL | 130.0s | 3.4Ã— | 571.6 |
| CA | MARTI | 112.8s | 3.9Ã— | 655.9 |
| CA | **FlexMARL** | **78.8s** | **5.6Ã—** | **821.4** |

> âœ… **æœ€é«˜æé€Ÿè¾¾ 7.3Ã—ï¼Œååé‡æå‡è‡³ 910.2 tps**

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç›¸æ¯” MAS-RL**ï¼š
  - å‡å°‘ rollout å»¶è¿Ÿ **86%**ï¼Œæ˜¾è‘—ç¼“è§£ long-tail æ•ˆåº”ã€‚
  - ç¡¬ä»¶åˆ©ç”¨ç‡ä» ~3.6% æå‡è‡³ **32.4%ï¼ˆMA æ•°æ®é›†ï¼‰**ã€‚
- **ç›¸æ¯” DistRL**ï¼š
  - å°½ç®¡éƒ½ä½¿ç”¨è§£è€¦æ¶æ„ï¼ŒFlexMARL é€šè¿‡ micro-batch å¼‚æ­¥æµæ°´çº¿éšè—å°¾éƒ¨å»¶è¿Ÿï¼Œå°†è®­ç»ƒæ—¶é—´ä» 155.9s ç¼©çŸ­è‡³ **10.2sï¼ˆMA æ•°æ®é›†ï¼‰**ã€‚
- **ç›¸æ¯” MARTI**ï¼š
  - åœ¨ç›¸åŒæ¡ä»¶ä¸‹ä»å–å¾— **1.4Ã— é€Ÿåº¦æå‡**ï¼Œä¸»è¦å¾—ç›ŠäºåŠ¨æ€èµ„æºåˆ†é…ä¸æ›´é«˜æ•ˆçš„è´Ÿè½½å‡è¡¡ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼Œè§ Table 3ï¼‰
| Variant | E2E Time (MA) | Speedup | Throughput |
|--------|---------------|---------|------------|
| w/o balancing | 152.2s | 6.0Ã— | 729.9 tps |
| w/o async | 256.2s | 3.6Ã— | 444.0 tps |
| **Full FlexMARL** | **126.1s** | **7.3Ã—** | **910.2 tps** |

> ğŸ” å‘ç°ï¼š
- ç§»é™¤ **hierarchical load balancing** å¯¼è‡´æ€§èƒ½ä¸‹é™ 19.8%ï¼Œè¯´æ˜è´Ÿè½½å‡è¡¡å¯¹ç¼“è§£çƒ­ç‚¹è‡³å…³é‡è¦ã€‚
- ç§»é™¤ **micro-batch å¼‚æ­¥æµæ°´çº¿** æ€§èƒ½ä¸‹é™è¶…è¿‡ 100%ï¼ŒéªŒè¯äº†å…¶å¯¹æ¶ˆé™¤ pipeline bubbles çš„å†³å®šæ€§ä½œç”¨ã€‚

---

### çŠ¶æ€äº¤æ¢å¼€é”€ï¼ˆState Swap Overheadï¼Œè§ Figure 11ï¼‰
| Model Size | Swap-in Overhead | Swap-out Overhead |
|-----------|------------------|--------------------|
| 3B | ~0.5s | ~0.5s |
| 32B | ~3.8s | ~3.8s |

> âœ… æœ€å¤§æ¨¡å‹ï¼ˆ32Bï¼‰çš„çŠ¶æ€äº¤æ¢æ€»å¼€é”€ä»…ä¸º **~11s**ï¼Œå¯è¢« rollout å»¶è¿Ÿæœ‰æ•ˆæ©ç›–ï¼Œä¸å½±å“æ•´ä½“æ•ˆç‡ã€‚

---

### å¯æ‰©å±•æ€§æµ‹è¯•ï¼ˆScalabilityï¼Œè§ Table 4ï¼‰
| é…ç½® | E2E Time | Throughput |
|------|----------|-----------|
| 5Ã—32B | 160.3s | 265.9 tps |
| 3Ã—32B + 7Ã—14Bï¼ˆå¼‚æ„ï¼‰ | 132.5s | 334.8 tps |
| 15Ã—14B | **41.9s** | **754.2 tps** |

> âœ… FlexMARL æˆåŠŸæ”¯æŒå¤§è§„æ¨¡å¼‚æ„éƒ¨ç½²ï¼ˆå¦‚æ··åˆ 32B ä¸ 14B æ¨¡å‹ï¼‰ï¼Œè€Œ MARTI ç­‰æ¡†æ¶ä¼šå› è·¨èŠ‚ç‚¹èµ„æºæ”¾ç½®å¤±è´¥å¯¼è‡´ OOMã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Rollout ä¸ Training å¿…é¡»ååŒè®¾è®¡**ï¼šä¼ ç»Ÿä¸²è¡Œæˆ–ç²—ç²’åº¦å¼‚æ­¥æ–¹å¼æ— æ³•æ»¡è¶³ LLM-based MARL çš„é«˜åŠ¨æ€æ€§éœ€æ±‚ã€‚
2. **åˆ†å±‚è´Ÿè½½å‡è¡¡è‡³å…³é‡è¦**ï¼šagent è§’è‰²å·®å¼‚å¯¼è‡´è¯·æ±‚åˆ†å¸ƒé«˜åº¦åæ–œï¼Œéœ€åŒæ—¶æ”¯æŒ intra-agent ä¸ inter-agent çš„å¼¹æ€§æ‰©ç¼©ã€‚
3. **agent-centric èµ„æºåˆ†é…æ˜¯æå‡åˆ©ç”¨ç‡çš„å…³é”®**ï¼šé™æ€ç»‘å®šå¯¼è‡´å¤§é‡èµ„æºé—²ç½®ï¼ŒåŠ¨æ€ç»‘å®š + state swap å¯å®ç°è¿‘ä¼¼â€œserverlessâ€å¼çš„é«˜æ•ˆè°ƒåº¦ã€‚
4. **micro-batch å¼‚æ­¥æµæ°´çº¿å¯åœ¨ä¿è¯ä¸€è‡´æ€§å‰æä¸‹æœ€å¤§åŒ–å¹¶è¡Œåº¦**ï¼šé€šè¿‡æ¢¯åº¦ç´¯ç§¯ + ç»Ÿä¸€æ›´æ–°ï¼Œæ—¢éšè—å°¾éƒ¨å»¶è¿Ÿåˆé¿å…å‚æ•°è¿‡æœŸï¼ˆparameter stalenessï¼‰ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜æ€§èƒ½äº’è”ç½‘ç»œï¼ˆå¦‚ HCCS/RDMAï¼‰**ï¼šD2D æƒé‡è¿ç§»ä¸è·¨èŠ‚ç‚¹çŠ¶æ€æ¢å¤éœ€è¦ä½å»¶è¿Ÿã€é«˜å¸¦å®½é€šä¿¡æ”¯æŒã€‚
- **å½“å‰å®ç°é›†ä¸­äº NPU æ¶æ„**ï¼šå¯¹ GPU æˆ–å…¶ä»–åŠ é€Ÿå™¨çš„æ”¯æŒå°šæœªéªŒè¯ã€‚
- **ç¼ºä¹å¯¹ fault tolerance çš„æ·±å…¥è®¨è®º**ï¼šå¤§è§„æ¨¡åˆ†å¸ƒå¼ç¯å¢ƒä¸‹èŠ‚ç‚¹æ•…éšœå¦‚ä½•å¤„ç†æœªè¯¦ç»†è¯´æ˜ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤šç±»å‹çš„ **heterogeneous agents**ï¼ˆå¦‚è§†è§‰ã€è¯­éŸ³æ¨¡æ€ï¼‰ã€‚
- æ¢ç´¢ **è‡ªåŠ¨åŒ–çš„ load balancing ç­–ç•¥**ï¼Œæ›¿ä»£äººå·¥è®¾å®šé˜ˆå€¼ Î”ã€‚
- ç»“åˆ **model compression æˆ– MoE æŠ€æœ¯** è¿›ä¸€æ­¥é™ä½ state swap å¼€é”€ã€‚
- æ„å»º **å¼€æ”¾ benchmark suite** ä»¥æ¨åŠ¨ MARL ç³»ç»Ÿç ”ç©¶æ ‡å‡†åŒ–ã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **FlexMARL é€šè¿‡ rollout-training co-designï¼Œé¦–æ¬¡å®ç°äº†é«˜æ•ˆã€å¯æ‰©å±•çš„å¤§è§„æ¨¡ LLM-based MARL è®­ç»ƒæ¡†æ¶ï¼Œåœ¨çœŸå®ç”Ÿäº§é›†ç¾¤ä¸Šå®ç°äº†é«˜è¾¾ 7.3Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿä¸ 5.6Ã— çš„ç¡¬ä»¶åˆ©ç”¨ç‡æå‡ã€‚**

</details>

---

### 3. [Training deep physical neural networks with local physical information bottleneck](https://arxiv.org/abs/2602.09569)

**Authors**: Hao Wang, Ziao Wang, Xiangpeng Liang, Han Zhao, Jianqi Hu, Junjie Jiang, Xing Fu, Jianshi Tang, Huaqiang Wu, Sylvain Gigan, Qiang Liu  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.09569v1  

#### Abstract
Deep learning has revolutionized modern society but faces growing energy and latency constraints. Deep physical neural networks (PNNs) are interconnected computing systems that directly exploit analog dynamics for energy-efficient, ultrafast AI execution. Realizing this potential, however, requires ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Training deep physical neural networks with local physical information bottleneck*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿæ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNsï¼‰ä¾èµ–æ•°å­—è®¡ç®—ç¡¬ä»¶ï¼Œåœ¨æ‰©å±•è¿‡ç¨‹ä¸­é¢ä¸´**èƒ½è€—é«˜ã€å»¶è¿Ÿå¤§ã€ç‰©ç†æé™é€¼è¿‘**ç­‰ç“¶é¢ˆã€‚ç‰©ç†ç¥ç»ç½‘ç»œï¼ˆPhysical Neural Networks, PNNsï¼‰åˆ©ç”¨æ¨¡æ‹Ÿç‰©ç†ç³»ç»Ÿï¼ˆå¦‚ç”µå­ã€å…‰å­¦ã€è‡ªæ—‹å™¨ä»¶ï¼‰è¿›è¡ŒåŸä½è®¡ç®—ï¼Œå…·å¤‡é«˜é€Ÿã€ä½åŠŸè€—æ½œåŠ›ï¼Œä½†å…¶è®­ç»ƒé¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- ç‰©ç†ç³»ç»Ÿé€šå¸¸**ä¸å¯å¾®åˆ†ã€éš¾ä»¥å»ºæ¨¡ã€å­˜åœ¨å™ªå£°ä¸ä¸ç¡®å®šæ€§**
- ç°æœ‰è®­ç»ƒæ–¹æ³•ï¼ˆå¦‚ hybrid trainingã€DFAã€PhyLLï¼‰ä¾èµ–è¾…åŠ©æ•°å­—æ¨¡å‹ã€å¯¹æ¯”æµ‹é‡æˆ–å…¨å±€åå‘ä¼ æ’­ï¼Œå¯¼è‡´**æ•ˆç‡ä½ã€é€‚åº”æ€§å·®ã€å¯¹ç¡¬ä»¶æ•…éšœæ•æ„Ÿ**

### ğŸ”§ æå‡ºçš„æ–°æ–¹æ³•ï¼š**Physical Information Bottleneck (PIB)**
PIB æ˜¯ä¸€ç§é€šç”¨ä¸”é«˜æ•ˆçš„ PNN è®­ç»ƒæ¡†æ¶ï¼Œå°†**ä¿¡æ¯è®º**ä¸**å±€éƒ¨å­¦ä¹ **ç›¸ç»“åˆï¼Œæ ¸å¿ƒæ€æƒ³å¦‚ä¸‹ï¼š
- å°†æ¯ä¸ªç‰©ç†è®¡ç®—å•å…ƒè§†ä¸ºä¸€ä¸ª**ä¿¡æ¯é€šé“**ï¼Œé€šè¿‡ä¼˜åŒ–å±€éƒ¨ç›®æ ‡å‡½æ•° $ \mathcal{L}(Z^l, \beta) = I(Y;Z^l) - \beta I(X;Z^l) $ æ¥æå–ä»»åŠ¡ç›¸å…³ç‰¹å¾å¹¶å‹ç¼©å†—ä½™è¾“å…¥ä¿¡æ¯ã€‚
- ä½¿ç”¨**åŸºäºçŸ©é˜µçš„ä¿¡æ¯åº¦é‡**ï¼ˆmatrix-based mutual informationï¼‰æ›¿ä»£ä¼ ç»Ÿäº’ä¿¡æ¯ä¼°è®¡ï¼Œè§£å†³é«˜ç»´ç©ºé—´ä¸­ä¿¡æ¯è®¡ç®—ä¸å¯è¡Œçš„é—®é¢˜ã€‚
- æ¯ä¸ªå•å…ƒä»…éœ€æœ¬åœ°è¾“å‡ºæµ‹é‡ã€å…¨å±€è¾“å…¥ $X$ å’Œæ ‡ç­¾ $Y$ å³å¯ç‹¬ç«‹è®­ç»ƒï¼Œæ— éœ€ç«¯åˆ°ç«¯æ¢¯åº¦å›ä¼ ã€‚

### ğŸš€ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | PIB çš„ä¼˜åŠ¿ |
|------|-----------|
| **å…¼å®¹æ€§** | æ”¯æŒ isomorphicï¼ˆå¦‚ memristor MVMï¼‰å’Œ broken-isomorphismï¼ˆå¦‚å…‰å­¦æ•£å°„ï¼‰ä¸¤ç±»ç‰©ç†ç³»ç»Ÿ |
| **è®­ç»ƒæ•ˆç‡** | æ— éœ€ contrastive samples æˆ– auxiliary networksï¼Œå‡å°‘å†…å­˜å ç”¨å’Œé€šä¿¡å¼€é”€ |
| **é²æ£’æ€§** | å¯¹ç¡¬ä»¶å™ªå£°ã€å‚æ•°æ¼‚ç§»ã€ç»„ä»¶æ•…éšœå…·æœ‰å¼ºé€‚åº”èƒ½åŠ› |
| **å¯æ‰©å±•æ€§** | æ”¯æŒåˆ†å¸ƒå¼å¹¶è¡Œè®­ç»ƒï¼Œé€‚ç”¨äºåœ°ç†åˆ†æ•£çš„å¼‚æ„ç¡¬ä»¶èµ„æº |
| **å»æ•°å­—åŒ–ä¾èµ–** | ä¸ä¾èµ–ç²¾ç¡®çš„æ•°å­—ä»¿çœŸæ¨¡å‹ï¼Œç¼“è§£ simulation-reality gap |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
| ä»»åŠ¡ç±»å‹ | æ•°æ®é›† | æè¿° |
|--------|-------|------|
| åˆ†ç±»ä»»åŠ¡ | **MNIST**, **MNIST-1D**, **Fashion-MNIST** | æ‰‹å†™æ•°å­—è¯†åˆ«ã€ç®€åŒ–ä¸€ç»´ç‰ˆæœ¬ã€æœé¥°å›¾åƒåˆ†ç±» |
| è‡ªç›‘ç£å­¦ä¹  | Fashion-MNISTï¼ˆæ— æ ‡ç­¾ï¼‰ | éªŒè¯ unsupervised variant of PIB çš„è¡¨å¾å­¦ä¹ èƒ½åŠ› |
| å¼ºåŒ–å­¦ä¹  | **CartPole-v1**ï¼ˆæ§åˆ¶ä»»åŠ¡ï¼‰ | æµ‹è¯•åœ¨éå¹³ç¨³ã€é«˜å™ªå£°ä¿¡å·ä¸‹çš„é€‚ç”¨æ€§ |

### âš™ï¸ å®éªŒè®¾ç½®ä¸å¹³å°
#### ï¼ˆ1ï¼‰Memristor-based PNNï¼ˆIsomorphic Unitï¼‰
- å¹³å°ï¼š1T1R memristive crossbar èŠ¯ç‰‡ï¼ˆè§„æ¨¡è¾¾ 1024Ã—128ï¼‰
- ç¼–ç æ–¹å¼ï¼šè¾“å…¥ä¸ºç”µå‹ï¼Œæƒé‡ä¸ºç”µå¯¼æ€
- æŒ‘æˆ˜ï¼šå­˜åœ¨ conductance noise å’Œ ADC æ•…éšœï¼ˆäººä¸ºå¼•å…¥ï¼‰

#### ï¼ˆ2ï¼‰Optics-based PNNï¼ˆBroken-isomorphism Unitï¼‰
- å¹³å°ï¼šåˆ©ç”¨å¤šé‡å…‰æ•£å°„ä»‹è´¨ç”Ÿæˆ speckle pattern
- è®¾å¤‡ï¼šå•†ç”¨ LightOn OPU ä¸è‡ªç ” SLM å…‰å­¦ç³»ç»Ÿ
- ç‰¹ç‚¹ï¼šä¼ è¾“çŸ©é˜µæœªçŸ¥ã€ä¸å¯å¾®ï¼Œæ„æˆâ€œé»‘ç®±â€å˜æ¢

#### ï¼ˆ3ï¼‰è®­ç»ƒæµç¨‹
- **é€å±‚çº§è”è®­ç»ƒ**ï¼šå…ˆè®­ç»ƒç¬¬ $l$ å±‚ â†’ éƒ¨ç½²è‡³ç¡¬ä»¶ â†’ è·å–å®é™…è¾“å‡ºä½œä¸ºä¸‹ä¸€å±‚è¾“å…¥
- **æŸå¤±å‡½æ•°**ï¼š
  - ç›‘ç£å­¦ä¹ ï¼š$ \mathcal{L}_{\text{PIB}} = I(Y;Z^l) - \beta I(X;Z^l) $
  - è‡ªç›‘ç£ï¼š$ \mathcal{L} = I(Z_1;Z_2) - \beta[I(X_1;Z_1)+I(X_2;Z_2)] $ï¼Œç”¨äº view-invariant è¡¨å¾å­¦ä¹ 
  - å¼ºåŒ–å­¦ä¹ ï¼šå¤åˆæŸå¤± $ \mathcal{C}_{\text{focal}} = \mathcal{C}_{\text{PIB}} + \lambda \mathcal{C}_{\text{TD}} $

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|-----|------|
| Test Accuracy | åˆ†ç±»å‡†ç¡®ç‡ï¼ˆMNIST/Fashion-MNISTï¼‰ |
| OOD Detection Rate | å¯¹åˆ†å¸ƒå¤–æ ·æœ¬çš„æ£€æµ‹èƒ½åŠ› |
| Noise Robustness | åœ¨è¾“å…¥åŠ å…¥å™ªå£°åçš„æ€§èƒ½ä¿æŒ |
| Data Efficiency | å°æ ·æœ¬æƒ…å†µä¸‹çš„å­¦ä¹ è¡¨ç° |
| Wall-clock Training Time | å®é™…è®­ç»ƒæ—¶é—´ï¼ˆå°¤å…¶å…³æ³¨å¹¶è¡ŒåŠ é€Ÿæ•ˆæœï¼‰ |
| Fault Adaptation | ç¡¬ä»¶æŸååæ¢å¤æ€§èƒ½çš„èƒ½åŠ› |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æ˜¯å¦éœ€è¦æ¨¡å‹ | æ˜¯å¦æ”¯æŒæœ¬åœ°è®­ç»ƒ |
|-----|------|-------------|------------------|
| End-to-end Backpropagation (BP) | æ•°å­—ä»¿çœŸ | æ˜¯ | å¦ |
| Physics-Aware Training (PAT) | Hybrid | æ˜¯ | å¦ |
| Direct Feedback Alignment (DFA) | Model-free | å¦ | æ˜¯ï¼ˆä½†æ€§èƒ½è¾ƒä½ï¼‰ |
| Physical Local Learning (PhyLL) | Contrastive | å¦ | æ˜¯ï¼ˆä½†éœ€ contrastive samplesï¼‰ |
| **PIB (æœ¬æ–‡)** | **Information-theoretic + Local** | **å¦** | **æ˜¯ï¼ˆæ—  contrastive æµ‹é‡ï¼‰** |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

| å®éªŒåœºæ™¯ | æ–¹æ³• | æ€§èƒ½æŒ‡æ ‡ | ç»“æœ |
|--------|------|---------|------|
| **MNISTï¼ˆmemristorï¼‰** | PIBï¼ˆå®éªŒï¼‰ | Test Accuracy | **96.3%** |
| | In Silico BPï¼ˆéƒ¨ç½²åï¼‰ | Test Accuracy | ä» 96.4% â†“ è‡³ **94.0%** |
| **MNIST-1Dï¼ˆmemristorï¼‰** | PIBï¼ˆå®éªŒ vs ä»¿çœŸï¼‰ | Test Accuracy | å‡æ¥è¿‘ ~**90%**ï¼Œæ— æ˜¾è‘—ä¸‹é™ |
| | In Silico BPï¼ˆéƒ¨ç½²åï¼‰ | Test Accuracy | ä¸‹é™ **8.5%** |
| **Hardware Faultï¼ˆADCæŸåï¼‰** | åˆå§‹çŠ¶æ€ | MNIST Accuracy | **73.5%** |
| | PIB è‡ªé€‚åº”é‡è®­ | MNIST Accuracy | æ¢å¤è‡³ **>90.0%** |
| **Fashion-MNISTï¼ˆopticalï¼‰** | PIB + OPU | Test Accuracy | **86.4%**ï¼ˆbinary encodingï¼‰ |
| | PIB + SLM setup | Test Accuracy | **93.4%**ï¼ˆ8-bit, subsetï¼‰ |
| **Reinforcement Learningï¼ˆCartPole-v1ï¼‰** | PIB + TD loss | Episode Return | æˆåŠŸè¾¾åˆ° **solved regime**ï¼ˆavg score > 475ï¼‰ |
| **Unsupervised Learning** | PIBï¼ˆmemristorï¼‰ | Linear Probe Accuracy | éšè®­ç»ƒè¿­ä»£å•è°ƒä¸Šå‡ï¼ŒUMAP æ˜¾ç¤ºè¯­ä¹‰åˆ†ç¦» |

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”
åœ¨ **Figure 3C** ä¸­å¯¹ generalization è¿›è¡Œå…¨é¢æ¯”è¾ƒï¼š
- **Noise Robustness**ï¼šPIB åœ¨å™ªå£°å¼ºåº¦é«˜è¾¾ 6% æ—¶ä»ä¿æŒ >80% å‡†ç¡®ç‡ï¼Œä¼˜äº PATã€DFA å’Œ PhyLL
- **Data Efficiency**ï¼šåœ¨å°è®­ç»ƒé›†ä¸Šï¼ŒPIB è¡¨ç°æ›´ä¼˜ï¼Œæ”¶æ•›æ›´å¿«
- **OOD Detection**ï¼šPIB å­¦å¾—çš„è¡¨ç¤ºæ›´å…·åˆ¤åˆ«æ€§ï¼ŒOOD æ£€æµ‹ç‡æ›´é«˜

### ğŸ”¤ æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡º ablation tableï¼Œä½†ä»å®éªŒè®¾è®¡å¯æ¨æ–­å…³é”®éªŒè¯ï¼š
- **æ˜¯å¦ä½¿ç”¨ local objective**ï¼šæˆåŠŸå®ç°æ— éœ€å…¨å±€ BP çš„è®­ç»ƒ
- **æ˜¯å¦ä¾èµ– transmission matrix**ï¼šåœ¨å…‰å­¦ç³»ç»Ÿä¸­å®Œå…¨é¿å…è·å–ä¼ è¾“çŸ©é˜µ
- **æ˜¯å¦æ”¯æŒ fault tolerance**ï¼šADC æ•…éšœå®éªŒè¯æ˜åŠ¨æ€é€‚åº”èƒ½åŠ›
- **æ˜¯å¦æ”¯æŒ parallel training**ï¼šè·¨åŒ—äº¬-å·´é»ä¸¤åœ°å¹¶è¡Œè®­ç»ƒæˆåŠŸï¼ˆFig. 4Cï¼‰ï¼ŒéªŒè¯å»åŒæ­¥åŒ–å¯è¡Œæ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **PIB æ˜¯é¦–ä¸ªå°†ä¿¡æ¯ç“¶é¢ˆåŸç†è½¬åŒ–ä¸ºä¸»åŠ¨è®­ç»ƒç›®æ ‡å¹¶åº”ç”¨äºçœŸå®ç‰©ç†ç³»ç»Ÿçš„æ¡†æ¶**ï¼Œå®ç°äº†ç†è®ºåˆ°å®è·µçš„è·¨è¶Šã€‚
2. **å±€éƒ¨æ€§ + ä¿¡æ¯å‹ç¼©æœºåˆ¶** ä½¿å¾— PNN èƒ½å¤Ÿåœ¨ä¸ä¾èµ–ç²¾ç¡®å»ºæ¨¡çš„æƒ…å†µä¸‹é«˜æ•ˆè®­ç»ƒï¼Œå¹¶å¤©ç„¶æŠµæŠ—å™ªå£°ä¸ç¡¬ä»¶ç¼ºé™·ã€‚
3. **åœ¨ isomorphic ä¸ broken-isomorphism ç³»ç»Ÿä¸­å‡å–å¾—é«˜æ€§èƒ½**ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æ™®é€‚æ€§ã€‚
4. **æ”¯æŒå¤šç§å­¦ä¹ èŒƒå¼**ï¼šç›‘ç£ã€è‡ªç›‘ç£ã€å¼ºåŒ–å­¦ä¹ å‡å¯ç»Ÿä¸€äº PIB æ¡†æ¶ä¸‹ã€‚
5. **é¦–æ¬¡å®ç°è·¨åœ°åŸŸå¼‚æ„ç¡¬ä»¶çš„å¹¶è¡Œè®­ç»ƒ**ï¼Œå±•ç¤ºäº†å…¶åœ¨åˆ†å¸ƒå¼æ™ºèƒ½è®¡ç®—ä¸­çš„æ½œåŠ›ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»ä¾èµ– **digital auto-differentiation** æ¥æ›´æ–°å‚æ•°ï¼ˆå³è®­ç»ƒè¯»å‡ºå±‚æˆ–æ•°å­—éƒ¨åˆ†ï¼‰ï¼Œå°šæœªå®Œå…¨æ‘†è„±æ•°å­—è®¡ç®—ã€‚
- å¯¹äºæåº¦å¤æ‚çš„ä»»åŠ¡ï¼ˆå¦‚ ImageNet è§„æ¨¡ï¼‰ï¼Œlocal optimization å¯èƒ½æ— æ³•åª²ç¾ end-to-end BP çš„å…¨å±€æœ€ä¼˜æ€§ã€‚
- matrix-based mutual information çš„è®¡ç®—å‡è®¾å¯èƒ½åœ¨æŸäº›æç«¯éçº¿æ€§ç³»ç»Ÿä¸­å¤±æ•ˆã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **ç»“åˆ surrogate gradient æ–¹æ³•**ï¼ˆå¦‚ DFAï¼‰è¿›ä¸€æ­¥é™ä½å¯¹æ•°å­—å¾®åˆ†çš„ä¾èµ–ï¼Œè¿ˆå‘å…¨ç‰©ç†è®­ç»ƒé—­ç¯ã€‚
2. æ¢ç´¢å¦‚ä½•å°†ç‰©ç†ç³»ç»Ÿçš„**å›ºæœ‰å½’çº³åç½®**ï¼ˆinductive biasï¼‰èå…¥ PIB æ¡†æ¶ä»¥æå‡æ€§èƒ½ã€‚
3. æ‰©å±•è‡³æ›´å¤§è§„æ¨¡ã€æ›´æ·±çš„ PNN æ¶æ„ï¼Œç ”ç©¶å…¶**scaling laws**ã€‚
4. åº”ç”¨äºæ›´å¤šç‰©ç†å¹³å°ï¼Œå¦‚ **acoustic reservoirs, magnetic skyrmions, active matter** ç­‰ã€‚
5. æ¨åŠ¨ PIB åœ¨è¾¹ç¼˜è®¡ç®—ã€ä½åŠŸè€— AI åŠ é€Ÿå™¨ä¸­çš„äº§ä¸šåŒ–åº”ç”¨ã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **PIB å¼€åˆ›äº†ä¸€ç§åŸºäºä¿¡æ¯è®ºçš„ã€å»ä¸­å¿ƒåŒ–çš„ã€æŠ—å™ªé²æ£’çš„ PNN è®­ç»ƒæ–°èŒƒå¼ï¼Œä¸ºæ„å»ºä¸‹ä¸€ä»£é«˜æ•ˆã€å¯æ‰©å±•ã€é¢å‘ç‰©ç†ä¸–ç•Œçš„ AI ç³»ç»Ÿæä¾›äº†åšå®åŸºç¡€ã€‚**

</details>

---

### 4. [DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents](https://arxiv.org/abs/2602.07035)

**Authors**: Jiahao Zhao, Shaoxuan Xu, Zhongxiang Sun, Fengqi Zhu, Jingyang Ou, Yuling Shi, Chongxuan Li, Xiao Zhang, Jun Xu  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.07035v1  

#### Abstract
Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundam...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDLLM-Searcher: Adapting Diffusion Large Language Models for Search Agents

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹å½“å‰ **Search Agent** åœ¨å®é™…éƒ¨ç½²ä¸­é¢ä¸´çš„ä¸¤å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼š

1. **Latency Challengeï¼ˆå»¶è¿ŸæŒ‘æˆ˜ï¼‰**ï¼š  
   åœ¨æ ‡å‡†çš„ ReAct èŒƒå¼ä¸‹ï¼ŒLLM éœ€è¦ä¸²è¡Œæ‰§è¡Œâ€œæ€è€ƒ â†’ å·¥å…·è°ƒç”¨ â†’ ç­‰å¾…å·¥å…·å“åº”â€æµç¨‹ã€‚åœ¨ç­‰å¾…å¤–éƒ¨å·¥å…·è¿”å›æœŸé—´ï¼Œæ¨¡å‹å¤„äºç©ºé—²çŠ¶æ€ï¼Œå¯¼è‡´ç«¯åˆ°ç«¯æ¨ç†å»¶è¿Ÿä¸¥é‡ã€‚

2. **Agent Ability Challengeï¼ˆæ™ºèƒ½ä½“èƒ½åŠ›æŒ‘æˆ˜ï¼‰**ï¼š  
   å½“å‰çš„ **dLLMs**ï¼ˆDiffusion Large Language Modelsï¼‰è™½ç„¶å…·å¤‡å¹¶è¡Œè§£ç ä¼˜åŠ¿ï¼Œä½†åœ¨å¤šæ­¥æ¨ç†ã€å·¥å…·è°ƒç”¨æ ¼å¼éµå¾ªç­‰æ–¹é¢è¡¨ç°è¾ƒå¼±ï¼Œéš¾ä»¥èƒœä»» Search Agent çš„è§’è‰²ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡º **DLLM-Searcher**ï¼Œä¸€ä¸ªä¸“ä¸º dLLM è®¾è®¡çš„ Search Agent ä¼˜åŒ–æ¡†æ¶ï¼ŒåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒåˆ›æ–°ï¼š

#### ï¼ˆ1ï¼‰**ä¸¤é˜¶æ®µåè®­ç»ƒç®¡é“ï¼ˆTwo-stage Post-training Pipelineï¼‰**

- **Agentic SFTï¼ˆAgentic Supervised Fine-Tuningï¼‰**  
  åˆ©ç”¨é«˜æ€§èƒ½æ•™å¸ˆæ¨¡å‹ï¼ˆå¦‚ Doubao-Seed-1.8ï¼‰ç”Ÿæˆé«˜è´¨é‡çš„å¤šè·³é—®ç­”è½¨è¿¹ï¼Œç­›é€‰å‡ºæ ¼å¼æ­£ç¡®ã€é€»è¾‘å®Œæ•´ã€ç­”æ¡ˆæ­£ç¡®çš„æ ·æœ¬è¿›è¡Œç›‘ç£å¾®è°ƒï¼Œæå‡ dLLM å¯¹ `tool_call` æ ¼å¼çš„éµå¾ªèƒ½åŠ›å’ŒåŸºç¡€æ£€ç´¢æ¨ç†èƒ½åŠ›ã€‚

- **Agentic VRPOï¼ˆAgentic Variance-Reduced Preference Optimizationï¼‰**  
  åŸºäº SFT æ¨¡å‹ç”Ÿæˆå¤šä¸ªè½¨è¿¹ï¼Œç­›é€‰å‡ºâ€œä¸€æ­£ä¸€è´Ÿâ€çš„åå¥½å¯¹ï¼ˆwinner/loserï¼‰ï¼Œé€šè¿‡ **VRPO** è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹çš„æ¨ç†ä¸æ£€ç´¢è¡Œä¸ºï¼Œå¢å¼ºå…¶é²æ£’æ€§ã€‚

> ç‰¹åˆ«è®¾è®¡äº† **Agentic ELBO** å’Œ **Agentic Noising** æœºåˆ¶ï¼Œç¡®ä¿è®­ç»ƒè¿‡ç¨‹ä¸­ä»…å…³æ³¨ `think` å’Œ `tool_call` åŒºåŸŸï¼Œé¿å… `tool_response` å†…å®¹æ³„éœ²å¯¼è‡´è®­ç»ƒ-æ¨ç†ä¸ä¸€è‡´ã€‚

#### ï¼ˆ2ï¼‰**æ–°å‹ä»£ç†èŒƒå¼ï¼šP-ReActï¼ˆParallel-Reasoning and Actingï¼‰**

- ä¸€ç§æ— éœ€é¢å¤–è®­ç»ƒçš„æ¨ç†æ§åˆ¶ç­–ç•¥ï¼Œåˆ©ç”¨ dLLM çš„ **éè‡ªå›å½’ã€å—å†…åŒå‘æ³¨æ„åŠ›** ç‰¹æ€§ï¼Œå®ç°â€œè¾¹ç­‰è¾¹æƒ³â€ã€‚
- æ ¸å¿ƒæœºåˆ¶ï¼š
  - **Token Pre-filling**ï¼šåœ¨ç”Ÿæˆå—ä¸­é¢„å¡«å…… `<tool_call>` å’Œ `</tool_call>` è¾¹ç•Œæ ‡è®°ã€‚
  - **Confidence Biasing**ï¼šåœ¨è§£ç æ—¶ï¼Œå¯¹è¾¹ç•Œå†…çš„ token å¢åŠ ç½®ä¿¡åº¦åç½®ï¼Œå¼•å¯¼æ¨¡å‹ä¼˜å…ˆè§£ç  `tool_call` å†…å®¹ã€‚

> ç»“æœï¼šæ¨¡å‹å…ˆè¾“å‡º `tool_call` è¯·æ±‚ï¼Œç«‹å³è§¦å‘æœç´¢å¼•æ“ï¼ŒåŒæ—¶ç»§ç»­ç”Ÿæˆ `think` å†…å®¹ï¼Œå®ç° **æ¨ç†ä¸ç­‰å¾…çš„å¹¶è¡ŒåŒ–**ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | P-ReAct å®ç°çº¦ **15% çš„æ¨ç†åŠ é€Ÿ**ï¼Œæ˜¾è‘—é™ä½ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚ |
| **æ€§èƒ½** | ç»è¿‡ä¸¤é˜¶æ®µè®­ç»ƒåï¼ŒDLLM-Searcher æ€§èƒ½åª²ç¾ä¸»æµåŸºäº ARMs çš„ Search Agentï¼ˆå¦‚ R1Searcherï¼‰ã€‚ |
| **å¯æ§æ€§** | P-ReAct å‡ ä¹ä»¥ **100% æˆåŠŸç‡** ä¿è¯ `tool_call` ä¼˜å…ˆç”Ÿæˆï¼Œæ§åˆ¶ç²¾åº¦è¿œè¶… ARMsã€‚ |
| **é€šç”¨æ€§** | æ‰€ææ–¹æ³•é€‚ç”¨äºä»»æ„æ”¯æŒå—çŠ¶ç”Ÿæˆçš„ dLLMï¼ˆå¦‚ SDARã€LLaDA ç­‰ï¼‰ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **HotpotQA**ï¼šå¤šè·³é—®ç­”åŸºå‡†ï¼Œç”¨äºè®­ç»ƒä¸æµ‹è¯•ã€‚
- **2WikiMultiHopQA**ï¼šæ„é€ æ€§å¤šè·³ QA æ•°æ®é›†ã€‚
- **Musique**ï¼šåŸºäºå•è·³ç»„åˆçš„å¤šè·³ QAã€‚
- **Bamboogle**ï¼šè·¨é¢†åŸŸã€é«˜éš¾åº¦å¤šè·³ QAï¼Œä½œä¸º **out-of-domain** æµ‹è¯•é›†ã€‚

> - è®­ç»ƒé›†ï¼šä»å‰ä¸‰è€…å„é‡‡æ · 2048 æŸ¥è¯¢ï¼Œå…± 3977 æ¡é«˜è´¨é‡è½¨è¿¹ç”¨äº Agentic SFTã€‚
> - æµ‹è¯•é›†ï¼šæ¯æ•°æ®é›†å– 500 å¼€å‘æ ·æœ¬ï¼ˆBamboogle å…¨éƒ¨ 125 æ¡ï¼‰ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°æŒ‡æ ‡**

- **ACCRï¼ˆAccuracyï¼‰**ï¼šé¢„æµ‹ç­”æ¡ˆæ˜¯å¦åŒ…å«é»„é‡‘ç­”æ¡ˆï¼ˆexact match ä¸é€‚ç”¨é•¿æ–‡æœ¬è¾“å‡ºï¼‰ã€‚
- **ACCLï¼ˆLLM-as-Judge Accuracyï¼‰**ï¼šä½¿ç”¨ **Doubao-Seed-1.8** ä½œä¸ºè£åˆ¤æ¨¡å‹åˆ¤æ–­ç­”æ¡ˆæ­£ç¡®æ€§ï¼Œæ›´è´´è¿‘äººç±»åˆ¤æ–­ã€‚

#### **ç¡¬ä»¶ä¸æ¨¡å‹é…ç½®**

- **Backbone**ï¼šSDARï¼ˆBlock Diffusion LMï¼Œ8B å‚æ•°ï¼Œå—å¤§å° 128ï¼‰ã€‚
- **æ£€ç´¢å·¥å…·**ï¼šGoogle Searchï¼ˆTop-10 ç»“æœï¼‰ã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - SFTï¼šå­¦ä¹ ç‡ 1e-5ï¼Œbatch size 32ï¼Œ3 è½®ã€‚
  - VRPOï¼šå­¦ä¹ ç‡ 5e-7ï¼Œbatch size 16ï¼Œ5 è½®ã€‚
- **æ¨ç†é…ç½®**ï¼š128 æ­¥å»å™ªï¼Œæ¸©åº¦ 1.0ï¼Œconfidence bias = 0.5ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| ç±»åˆ« | åŸºçº¿æ–¹æ³• |
|------|----------|
| **ä¼ ç»Ÿ RAG** | SuRe, Selective-Context, Adaptive-RAG, IRCoT, Iter-RetGen, CR-Planner, ReARTeR |
| **ARM-based Search Agents** | Search-o1, Search-R1, WebSailor*, R1Searcher* |
| **dLLM-based Agents** | SDARï¼ˆåŸå§‹ï¼‰ã€Dreamã€LLaDAï¼ˆå‡ä½¿ç”¨ ReAct èŒƒå¼ï¼‰ |

> *WebSailor å’Œ R1Searcher çš„ç»“æœç»è¿‡é€‚é…å¤„ç†ä»¥ä¿æŒå®éªŒä¸€è‡´æ€§ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1ï¼‰**

| æ–¹æ³• | HotpotQA (ACCR/ACCL) | 2Wiki (ACCR/ACCL) | Bamboogle (ACCR/ACCL) | Musique (ACCR/ACCL) | **Avg ACCR** |
|------|------------------------|--------------------|------------------------|----------------------|---------------|
| **R1Searcher*** | 58.0 / 62.2 | 59.6 / 63.4 | 66.4 / 68.8 | 28.2 / 31.4 | **53.1** |
| **DLLM-Searcher** | **60.4 / 62.4** | **69.8 / 64.6** | **68.8 / 69.6** | **29.0 / 29.8** | **57.0** âœ… |

> âœ… **DLLM-Searcher åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šå‡è¶…è¶Š R1Searcherï¼Œå¹³å‡ ACCR æå‡è¿‘ 4 ä¸ªç™¾åˆ†ç‚¹ã€‚**

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **vs. ä¼ ç»Ÿ RAG**ï¼šå¤§å¹…é¢†å…ˆï¼ˆå¦‚æ¯” ReARTeR é«˜ ~19% ACCRï¼‰ã€‚
- **vs. åŸå§‹ dLLMs**ï¼š
  - SDAR åŸå§‹æ¨¡å‹å‡ ä¹æ— æ³•ç”Ÿæˆæœ‰æ•ˆ `tool_call`ï¼ˆè§£æå¤±è´¥ç‡ 100%ï¼‰ã€‚
  - Dream å’Œ LLaDA è¡¨ç°æå·®ï¼ˆACCR å¤šæ•°ä½äº 15%ï¼‰ã€‚
- **vs. ARM-based Agents**ï¼š
  - æ€§èƒ½æŒå¹³ç”šè‡³åè¶…ï¼ˆå°¤å…¶åœ¨ 2Wiki å’Œ Bamboogle ä¸Šï¼‰ã€‚
  - **å”¯ä¸€å·®è·åœ¨ Musique**ï¼Œå¯èƒ½å› è®­ç»ƒæ•°æ®åˆ†å¸ƒå·®å¼‚ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **RQ1: ä¸¤é˜¶æ®µåè®­ç»ƒçš„æœ‰æ•ˆæ€§ï¼ˆTable 2ï¼‰**

| æ–¹æ³• | HotpotQA (ACCR) | 2Wiki (ACCR) | Bamboogle (ACCR) | Musique (ACCR) |
|------|------------------|--------------|------------------|----------------|
| **Agentic SFT** | 57.2 | 66.4 | 64.6 | 24.4 |
| **+ Agentic VRPO** | **60.4 (+3.2)** | **69.8 (+3.4)** | **68.8 (+4.2)** | **29.0 (+4.6)** |

> âœ… VRPO å¸¦æ¥ç¨³å®šä¸”æ˜¾è‘—çš„æ€§èƒ½å¢ç›Šï¼ˆ+3~4.6%ï¼‰ï¼ŒéªŒè¯å…¶å¯¹æ¨ç†è´¨é‡çš„æå‡ä½œç”¨ã€‚

#### **RQ2: P-ReAct çš„æ¨ç†æ•ˆç‡ï¼ˆFigure 3ï¼‰**

| æ•°æ®é›† | æ¨ç†æ—¶é—´å‡å°‘ |
|--------|-------------|
| HotpotQA | 14.77% |
| 2Wiki | 21.00% |
| Bamboogle | 22.08% |
| Musique | 12.67% |
| **å¹³å‡** | **â‰ˆ15%** |

> âš¡ P-ReAct æ˜¾è‘—é™ä½ç«¯åˆ°ç«¯å»¶è¿Ÿï¼Œä¸” **å‡†ç¡®ç‡å‡ ä¹æ— æŸ**ã€‚

#### **RQ3: dLLM çš„é¡ºåºè‡ªç”±ç”Ÿæˆä¼˜åŠ¿ï¼ˆFigure 4ï¼‰**

- å°† P-ReAct åº”ç”¨äº **Qwen3 ç³»åˆ— ARMs**ï¼ˆ8B/30B/235Bï¼‰ï¼š
  - å³ä½¿ä¿®æ”¹ prompt å¼•å¯¼å…¶å…ˆç”Ÿæˆ `tool_call`ï¼Œä»å‡ºç° **3%~13.3% çš„æ€§èƒ½ä¸‹é™**ã€‚
- åè§‚ **DLLM-Searcher**ï¼š
  - åœ¨ HotpotQA å’Œ Musique ä¸Š **ç”šè‡³ç•¥æœ‰æå‡**ã€‚
  - ä»…åœ¨ 2Wiki å’Œ Bamboogle ä¸Šæœ‰è½»å¾®ä¸‹é™ï¼ˆ<5%ï¼‰ã€‚

> ğŸ” è¯´æ˜ **dLLM èƒ½åœ¨æœªæ˜¾å¼è§£ç  `think` çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨åŒå‘æ³¨æ„åŠ›éšå¼å®Œæˆæ¨ç†**ï¼Œè€Œ ARMs ä¸¥é‡ä¾èµ– CoT çš„æ˜¾å¼è¡¨è¾¾ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **dLLMs å®Œå…¨å¯ä»¥èƒœä»» Search Agent è§’è‰²**ï¼Œåªè¦é€šè¿‡é’ˆå¯¹æ€§åè®­ç»ƒï¼ˆAgentic SFT + VRPOï¼‰å¼¥è¡¥å…¶æ¨ç†ä¸æ ¼å¼éµå¾ªçŸ­æ¿ã€‚
2. **P-ReAct æ˜¯ dLLM ç‹¬æœ‰çš„é«˜æ•ˆèŒƒå¼**ï¼Œåˆ©ç”¨å…¶éè‡ªå›å½’ç‰¹æ€§å®ç°â€œ**thinking while waiting**â€ï¼Œå¸¦æ¥çº¦ **15% çš„æ¨ç†åŠ é€Ÿ**ã€‚
3. **é¡ºåºè‡ªç”±ç”Ÿæˆæ˜¯ dLLM çš„æ ¸å¿ƒä¼˜åŠ¿**ï¼šå³ä½¿ `tool_call` ä¼˜å…ˆç”Ÿæˆï¼Œå…¶è´¨é‡ä¸å—å½±å“ï¼Œå¾—ç›Šäºå—å†…åŒå‘æ³¨æ„åŠ›çš„å…¨å±€æ„ŸçŸ¥èƒ½åŠ›ã€‚
4. **DLLM-Searcher æ€§èƒ½åª²ç¾ç”šè‡³è¶…è¶Šä¸»æµ ARM-based Search Agents**ï¼ŒéªŒè¯äº† dLLM ä½œä¸ºé«˜æ•ˆ Agent Backbone çš„æ½œåŠ›ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ–é«˜è´¨é‡è®­ç»ƒæ•°æ®**ï¼šAgentic SFT ä¾èµ–å¼ºæ•™å¸ˆæ¨¡å‹ç”Ÿæˆè½¨è¿¹ï¼Œæˆæœ¬è¾ƒé«˜ã€‚
2. **æ³›åŒ–èƒ½åŠ›ä»æœ‰æå‡ç©ºé—´**ï¼šåœ¨ Musique ä¸Šä¸ R1Searcher ä»æœ‰å·®è·ï¼Œå¯èƒ½éœ€æ›´å¤šé¢†åŸŸé€‚é…ã€‚
3. **P-ReAct ä¾èµ–ç‰¹å®šæ¶æ„**ï¼šä»…é€‚ç”¨äºæ”¯æŒå—çŠ¶ç”Ÿæˆçš„ dLLMï¼ˆå¦‚ BDLMsï¼‰ï¼Œä¸é€‚ç”¨äºçº¯æ‰©æ•£æ¨¡å‹ã€‚
4. **å·¥å…·ç”Ÿæ€é™åˆ¶**ï¼šç›®å‰ä»…é›†æˆ Google Searchï¼Œå¤æ‚å·¥å…·é“¾ï¼ˆå¦‚ visitã€code interpreterï¼‰å°šæœªéªŒè¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ‰©å±•è‡³å¤šå·¥å…·ååŒåœºæ™¯**ï¼šå°† P-ReAct æ¨å¹¿è‡³æ”¯æŒ `search`ã€`visit`ã€`code` ç­‰å¤šç§å·¥å…·çš„æ··åˆè°ƒç”¨ã€‚
2. **æ¢ç´¢æ›´é«˜æ•ˆçš„åå¥½å­¦ä¹ æœºåˆ¶**ï¼šç»“åˆ RL æˆ–è¿‡ç¨‹å¥–åŠ±è¿›ä¸€æ­¥ä¼˜åŒ–æ¨ç†è·¯å¾„ã€‚
3. **è½»é‡åŒ–ä¸éƒ¨ç½²ä¼˜åŒ–**ï¼šç»“åˆ Fast-dLLM ç­‰æŠ€æœ¯ï¼Œæ¨åŠ¨ dLLM Search Agent åœ¨è¾¹ç¼˜è®¾å¤‡è½åœ°ã€‚
4. **æ„å»º dLLM åŸç”Ÿ Agent è®­ç»ƒæ•°æ®é›†**ï¼šæ‘†è„±å¯¹ ARM æ•™å¸ˆæ¨¡å‹çš„ä¾èµ–ï¼Œå®ç°ç«¯åˆ°ç«¯ dLLM Agent è®­ç»ƒã€‚

---

> **æ€»ç»“**ï¼šDLLM-Searcher æˆåŠŸå¼¥åˆäº† **dLLM çš„ç†è®ºä¼˜åŠ¿** ä¸ **Search Agent å®è·µéœ€æ±‚** ä¹‹é—´çš„é¸¿æ²Ÿï¼Œä¸ä»…æå‡äº†æ€§èƒ½ï¼Œæ›´å¼€åˆ›äº†ä¸€ç§ **å¹¶è¡ŒåŒ–æ™ºèƒ½ä½“æ¨ç†èŒƒå¼**ï¼Œä¸ºä¸‹ä¸€ä»£é«˜æ•ˆã€ä½å»¶è¿Ÿçš„ AI Agent æä¾›äº†å…¨æ–°è·¯å¾„ã€‚

</details>

---

### 5. [Effective MoE-based LLM Compression by Exploiting Heterogeneous Inter-Group Experts Routing Frequency and Information Density](https://arxiv.org/abs/2602.09316)

**Authors**: Zhendong Mi, Yixiao Chen, Pu Zhao, Xiaodong Yu, Hao Wang, Yanzhi Wang, Shaoyi Huang  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.09316v1  

#### Abstract
Mixture-of-Experts (MoE) based Large Language Models (LLMs) have achieved superior performance, yet the massive memory overhead caused by storing multiple expert networks severely hinders their practical deployment. Singular Value Decomposition (SVD)-based compression has emerged as a promising post...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEffective MoE-based LLM Compression by Exploiting Heterogeneous Inter-Group Experts Routing Frequency and Information Density

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº **SVD çš„ MoE å‹ç¼©æ–¹æ³•**å­˜åœ¨ä¸¤å¤§å…³é”®ç¼ºé™·ï¼š
1. **ç»Ÿä¸€ç§©åˆ†é…ï¼ˆUniform Rank Allocationï¼‰**ï¼šå¿½ç•¥ä¸“å®¶ä¹‹é—´æ˜¾è‘—çš„å¼‚è´¨æ€§åˆ©ç”¨æ¨¡å¼ï¼Œå¯¼è‡´å¯¹é¢‘ç¹æ¿€æ´»ä½†ä¿¡æ¯å¯†é›†çš„ä¸“å®¶å‹ç¼©ä¸è¶³ï¼Œè€Œå¯¹ç¨€ç–æ¿€æ´»ä½†å…³é”®çš„ä¸“å®¶è¿‡åº¦å‹ç¼©ç”šè‡³ä¸¢å¼ƒã€‚
2. **æ®‹å·®è¢«ç›´æ¥ä¸¢å¼ƒ**ï¼šä¼ ç»Ÿ SVD æ–¹æ³•ä»…ä¿ç•™ä¸»å¥‡å¼‚å€¼åˆ†é‡ï¼Œå¿½ç•¥å‹ç¼©æ®‹å·®ï¼ˆresidualï¼‰ï¼Œé€ æˆä¸å¯å¿½è§†çš„ä¿¡æ¯æŸå¤±ã€‚

è¿™äº›é—®é¢˜åœ¨ **å¤§è§„æ¨¡ MoE LLMs**ï¼ˆå¦‚ Qwen3ã€DeepSeekMoEï¼‰ä¸­å°¤ä¸ºä¸¥é‡ï¼Œå½±å“æ¨¡å‹åœ¨ä½èµ„æºéƒ¨ç½²ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šRFID-MoE
ä½œè€…æå‡º **RFID-MoE**ï¼ˆRouting Frequency and Information Density-aware MoE compressionï¼‰ï¼Œä¸€ç§è‡ªé€‚åº”ã€é«˜æ•ˆçš„ MoE å‹ç¼©æ¡†æ¶ï¼Œæ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰èåˆåŠ¨æ€è·¯ç”±é¢‘ç‡ä¸ä¿¡æ¯å¯†åº¦çš„è‡ªé€‚åº”ç§©åˆ†é…
- **Routing Frequencyï¼ˆè·¯ç”±é¢‘ç‡ï¼‰**ï¼šé€šè¿‡åœ¨æ ¡å‡†æ•°æ®é›†ä¸Šç»Ÿè®¡å„ä¸“å®¶çš„æ¿€æ´»æ¬¡æ•°ï¼Œè¡¡é‡å…¶â€œä½¿ç”¨é‡è¦æ€§â€ã€‚
- **Information Densityï¼ˆä¿¡æ¯å¯†åº¦ï¼‰**ï¼šå¼•å…¥ **effective rank** æŒ‡æ ‡é‡åŒ–æ¯ä¸ªä¸“å®¶ç»„çš„å†…åœ¨ä¿¡æ¯å¤æ‚åº¦ï¼Œé¿å…å› ä½é¢‘è€Œè¯¯åˆ¤ä¸ºâ€œä¸é‡è¦â€ã€‚
- **èåˆç­–ç•¥**ï¼šè®¾è®¡åŠ æƒèåˆå…¬å¼ $ C_g = \xi \cdot E_g + (1-\xi) \cdot F_g $ï¼Œå…¶ä¸­ $ E_g $ æ˜¯å½’ä¸€åŒ–æœ‰æ•ˆç§©ï¼Œ$ F_g $ æ˜¯å½’ä¸€åŒ–è·¯ç”±é¢‘ç‡ï¼Œå®ç°å¯¹é«˜ä»·å€¼ä¸“å®¶çš„ä¼˜å…ˆä¿çœŸã€‚

> ğŸ” **ä¼˜åŠ¿**ï¼šç›¸æ¯”é™æ€æƒé‡åˆ†ææˆ–çº¯é¢‘ç‡é©±åŠ¨çš„æ–¹æ³•ï¼ŒRFID-MoE èƒ½è¯†åˆ«â€œä½é¢‘ä½†é«˜ä¿¡æ¯å¯†åº¦â€çš„ä¸“å®¶ï¼Œé˜²æ­¢å…³é”®èƒ½åŠ›é€€åŒ–ã€‚

#### ï¼ˆ2ï¼‰å‚æ•°é«˜æ•ˆçš„æ®‹å·®é‡å»ºæœºåˆ¶ï¼ˆResidual Reconstructionï¼‰
- ä¸å†ä¸¢å¼ƒ SVD å‹ç¼©åçš„æ®‹å·® $ R = W - \hat{W} $ã€‚
- å¼•å…¥ä¸€ä¸ªä½ç»´å¯è®­ç»ƒå‘é‡ $ \eta_g \in \mathbb{R}^a $ï¼ˆ$ a \ll D $ï¼‰ï¼Œå¹¶é€šè¿‡ **sparse orthogonal projection matrix $ P $** å°†å…¶æ˜ å°„å›åŸå§‹å‚æ•°ç©ºé—´ï¼š
  $$
  \text{vec}(R) = P \eta_g
  $$
- $ P $ æ„é€ ä¸ºæ¯è¡Œåªæœ‰ä¸€ä¸ªéé›¶å…ƒç´ ï¼ˆone-hot ç»“æ„ï¼‰ï¼Œä¸”æ»¡è¶³ $ P^T P = I_a $ï¼Œä¿è¯å‡ ä½•ä¸å˜æ€§å’Œä¼˜åŒ–ç¨³å®šæ€§ã€‚

> ğŸ’¡ **ä¼˜åŠ¿**ï¼šä»¥æå°é¢å¤–å‚æ•°å¼€é”€ï¼ˆçº¦ 3%ï¼‰æ¢å¤å…³é”®ä¸¢å¤±ä¿¡æ¯ï¼Œæ˜¾è‘—æå‡å‹ç¼©åæ¨¡å‹æ€§èƒ½ã€‚

---

### âœ… ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ˜¯å¦è€ƒè™‘å¼‚è´¨æ€§ | æ˜¯å¦åˆ©ç”¨æ®‹å·® | æ˜¯å¦åŠ¨æ€è°ƒæ•´ç§© |
|------|----------------|---------------|----------------|
| DÂ²-MoE / MoBE | âŒ ç»Ÿä¸€æˆ–é™æ€åˆ†é… | âŒ ä¸¢å¼ƒæ®‹å·® | âŒ |
| RS-MoE | â­• éƒ¨åˆ†è€ƒè™‘ç»“æ„ | â­• åˆ©ç”¨ç¨€ç–æ®‹å·® | âŒ |
| **RFID-MoE (Ours)** | âœ… æ˜¾å¼å»ºæ¨¡é¢‘ç‡+ä¿¡æ¯å¯†åº¦ | âœ… å‚æ•°é«˜æ•ˆé‡å»º | âœ… è‡ªé€‚åº”åˆ†é… |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

#### ï¼ˆ1ï¼‰æ ¡å‡†æ•°æ®é›†ï¼ˆç”¨äºæ”¶é›†è·¯ç”±é¢‘ç‡ï¼‰
- **WikiText-2**ï¼š1,024 ä¸ªæ ·æœ¬ï¼Œåºåˆ—é•¿åº¦ 1,024
- **C4**ï¼šä½œä¸ºæ¶ˆèå®éªŒä¸­çš„æ›¿ä»£æ ¡å‡†é›†

#### ï¼ˆ2ï¼‰è¯„ä¼°åŸºå‡†
| ç±»å‹ | æ•°æ®é›† | ä»»åŠ¡ | æŒ‡æ ‡ |
|------|--------|------|------|
| **è¯­è¨€å»ºæ¨¡** | WikiText-2, PTB, C4 | Perplexity (â†“) |
| **å¸¸è¯†æ¨ç†** | OpenBookQA, ARC-e, WinoGrande, HellaSwag, PIQA, MathQA | Zero-shot Accuracy (â†‘) |

æ‰€æœ‰è¯„ä¼°å‡ä½¿ç”¨ **LM Evaluation Harness** æ¡†æ¶è¿›è¡Œ zero-shot æµ‹è¯•ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

- **æ¨¡å‹**ï¼š
  - Qwen3-30B-A3B-2507ï¼ˆ128 experts/layerï¼‰
  - DeepSeekMoE-16B-Baseï¼ˆ64 expertsï¼‰
  - Qwen2-57B-A14B, Deepseek-v2-Lite-Chat, Ling-mini-2.0
- **å‹ç¼©æ¯”ä¾‹**ï¼š20%, 40%, 60%
- **å‹ç¼©ç›®æ ‡**ï¼šUp-projection å’Œ Gate-projection çŸ©é˜µï¼›Down-projection ä¿æŒç¨ å¯†
- **åˆ†ç»„ç­–ç•¥**ï¼šæ¯ 4 ä¸ªä¸“å®¶çŸ©é˜µæ‹¼æ¥æˆä¸€ç»„è¿›è¡Œå…±äº«åŸºåº•åˆ†è§£
- **æ®‹å·®ç»´åº¦**ï¼š$ a = 3\% \times D $
- **ç¡¬ä»¶**ï¼š8Ã—NVIDIA A100 GPUs

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç®€ä»‹ |
|------|------|------|
| **NAEE** | Pruning + Skipping | åè®­ç»ƒå‰ªæ + åŠ¨æ€è·³è¿‡ |
| **MoE-I2** | Pruning + Low-rank | ä¸“å®¶é—´å‰ªæ + ä¸“å®¶å†…ä½ç§©åˆ†è§£ |
| **RS-MoE** | Shared + Sparse Residual | å…±äº«ä½ç§©è¡¨ç¤º + ç¨€ç–æ®‹å·® |
| **DÂ²-MoE** | Shared + Unique Components | åˆ†è§£ä¸ºå…±äº«ä¸ç‹¬æœ‰éƒ¨åˆ† |
| **MoBE** | Adaptive Basis Sharing | å½“å‰ SOTA çš„åŸºçº¿æ–¹æ³• |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2 & 4ï¼‰

#### åœ¨ **Qwen3-30B-A3B-2507 @ 60% å‹ç¼©ç‡**

| æŒ‡æ ‡ | Original | MoBE | DÂ²-MoE | **RFID-MoE (Ours)** |
|------|----------|-------|--------|---------------------|
| **PTB Perplexity â†“** | 12.49 | 13.96 | 21.76 | **16.92** |
| **HellaSwag Accuracy â†‘** | 0.77 | 0.70 | 0.80 | **0.78 â†’ 0.79**ï¼ˆå®é™…è¾¾ 0.78â€“0.79ï¼‰ |

> âœ… **RFID-MoE ç›¸æ¯”æœ€ä½³åŸºçº¿ï¼ˆMoBEï¼‰é™ä½ PPL è¶…è¿‡ 8.0ï¼ŒHellaSwag æå‡ ~8%**

#### åœ¨ **DeepSeekMoE-16B-Base @ 60% å‹ç¼©ç‡**

| æŒ‡æ ‡ | MoBE | **RFID-MoE** |
|------|------|-------------|
| **PTB PPL â†“** | 27.73 | **11.54** |
| **Average Acc â†‘** | 0.68 | **0.71** |

> âœ… æ€§èƒ½è¿œè¶…æ‰€æœ‰åŸºçº¿ï¼Œå°¤å…¶åœ¨è¯­è¨€å»ºæ¨¡ä¸Šä¼˜åŠ¿å·¨å¤§

---

### ğŸ” æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰ä¸åŒæ ¡å‡†æ•°æ®çš„å½±å“ï¼ˆTable 3ï¼‰
| æ–¹æ³• | Calibration | PTB PPL |
|------|-----------|--------|
| MoBE | â€“ | 24.93 |
| **RFID-MoE** | WikiText-2 | **16.92** |
| **RFID-MoE** | C4 | **13.70**ï¼ˆæœ€ä¼˜ï¼‰ |

> âœ… ä½¿ç”¨ C4 ä½œä¸ºæ ¡å‡†é›†æ•ˆæœæ›´å¥½ï¼Œè¯´æ˜æ•°æ®å¤šæ ·æ€§æœ‰åŠ©äºæ›´å‡†ç¡®ä¼°è®¡ä¸“å®¶åˆ©ç”¨ç‡

#### ï¼ˆ2ï¼‰èåˆç³»æ•° $ \xi $ çš„å½±å“ï¼ˆTable 4ï¼‰
- æœ€ä¼˜ $ \xi \in [0.7, 0.8] $
- è‹¥ $ \xi $ è¿‡å¤§ â†’ å¿½è§†è·¯ç”±é¢‘ç‡ â†’ æ— æ³•ä¿æŠ¤é«˜é¢‘ä¸“å®¶
- è‹¥ $ \xi $ è¿‡å° â†’ å¿½è§†ä¿¡æ¯å¯†åº¦ â†’ ä½ä¼°ä½é¢‘é«˜ä¿¡æ¯ä¸“å®¶

> âœ… éªŒè¯äº†èåˆä¸¤ç§ä¿¡å·çš„å¿…è¦æ€§

#### ï¼ˆ3ï¼‰å¤§æ¨¡å‹ä¸è½»é‡æ¨¡å‹éªŒè¯
- **Qwen3-235B-A22B-2507ï¼ˆè¶…å¤§è§„æ¨¡ï¼‰**ï¼šRFID-MoE åœ¨ PTB ä¸Šè¾¾åˆ° PPL=10.67ï¼Œä¼˜äº MoBEï¼ˆ11.13ï¼‰ï¼Œæ¥è¿‘åŸæ¨¡å‹ï¼ˆ10.11ï¼‰
- **Deepseek-v2-Lite-Chat / Ling-mini-2.0ï¼ˆè½»é‡ MoEï¼‰**ï¼šä»èƒ½ç¨³å®šä¼˜äº MoBEï¼Œè¯æ˜æ–¹æ³•é€šç”¨æ€§å¼º

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ä¸“å®¶å¼‚è´¨æ€§è‡³å…³é‡è¦**ï¼šMoE ä¸­ä¸“å®¶çš„ **routing frequency** å’Œ **information density** å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œç»Ÿä¸€å‹ç¼©ç­–ç•¥ä¼šå¯¼è‡´æ¬¡ä¼˜ç»“æœã€‚
2. **ä½é¢‘ â‰  æ— ç”¨**ï¼šæŸäº›ä¸“å®¶è™½æå°‘è¢«æ¿€æ´»ï¼Œä½†å…·æœ‰é«˜ **effective rank**ï¼Œè•´å«å…³é”®é¢†åŸŸçŸ¥è¯†ï¼Œåº”äºˆä»¥ä¿ç•™ã€‚
3. **æ®‹å·®ä¸å¯å¿½ç•¥**ï¼šSVD æˆªæ–­äº§ç”Ÿçš„æ®‹å·®åŒ…å«éå¹³å‡¡èƒ½é‡ï¼Œå¯é€šè¿‡ä½ç»´å­ç©ºé—´é«˜æ•ˆé‡å»ºã€‚
4. **å‚æ•°æ•ˆç‡é«˜**ï¼šä»…å¢åŠ çº¦ 3% å‚æ•°å³å¯æ˜¾è‘—æ¢å¤æ€§èƒ½ï¼Œé€‚åˆè¾¹ç¼˜éƒ¨ç½²ã€‚

---

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–æ ¡å‡†æ•°æ®**ï¼šéœ€è¦ä¸€å®šé‡è¾“å…¥æ•°æ®æ¥ç»Ÿè®¡ routing frequencyï¼Œåœ¨æç«¯åˆ†å¸ƒåç§»ä¸‹å¯èƒ½å¤±æ•ˆã€‚
2. **åˆ†ç»„ç­–ç•¥å›ºå®š**ï¼šç›®å‰æŒ‰æ’åºåé¡ºåºåˆ†ç»„ï¼Œæœªæ¢ç´¢èšç±»ç­‰æ›´æ™ºèƒ½çš„ grouping æ–¹å¼ã€‚
3. **ä»…é€‚ç”¨äº FFN å±‚**ï¼šæœªæ‰©å±•åˆ° Attention æˆ–å…¶ä»–æ¨¡å—çš„ MoE å‹ç¼©ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **åŠ¨æ€åœ¨çº¿é‡åˆ†é…**ï¼šæ ¹æ®è¾“å…¥æµå®æ—¶è°ƒæ•´ä¸“å®¶ç§©é¢„ç®—ã€‚
2. **ç«¯åˆ°ç«¯è”åˆä¼˜åŒ–**ï¼šå°†å‹ç¼©è¿‡ç¨‹èå…¥å¾®è°ƒé˜¶æ®µï¼Œè¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚
3. **è·¨å±‚å…±äº«æŠ•å½±çŸ©é˜µ**ï¼šè¿›ä¸€æ­¥å‡å°‘ $ P $ çš„å­˜å‚¨å¼€é”€ã€‚
4. **åº”ç”¨äºå…¶ä»–ç¨€ç–æ¶æ„**ï¼šå¦‚ Switch Transformersã€Jamba ç­‰æ··åˆä¸“å®¶æ¨¡å‹ã€‚

---

## âœ… æ€»ç»“
**RFID-MoE** æ˜¯é¦–ä¸ªæ˜¾å¼ç»“åˆ **Routing Frequency** ä¸ **Information Density** è¿›è¡Œ MoE å‹ç¼©çš„å·¥ä½œï¼Œé€šè¿‡ **è‡ªé€‚åº”ç§©åˆ†é…** å’Œ **å‚æ•°é«˜æ•ˆæ®‹å·®é‡å»º**ï¼Œåœ¨å¤šä¸ªä¸»æµ MoE LLM ä¸Šå®ç°äº† **state-of-the-art çš„å‹ç¼©æ€§èƒ½**ï¼Œå°¤å…¶åœ¨é«˜å‹ç¼©æ¯”ä¸‹ä»èƒ½ä¿æŒä¼˜å¼‚çš„è¯­è¨€å»ºæ¨¡ä¸æ¨ç†èƒ½åŠ›ï¼Œä¸ºå¤§è§„æ¨¡ MoE æ¨¡å‹çš„å®é™…éƒ¨ç½²æä¾›äº†æœ‰æ•ˆè§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 6. [Optimistic World Models: Efficient Exploration in Model-Based Deep Reinforcement Learning](https://arxiv.org/abs/2602.10044)

**Authors**: Akshay Mete, Shahid Aamir Sheikh, Tzu-Hsiang Lin, Dileep Kalathil, P. R. Kumar  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.10044v1  

#### Abstract
Efficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments. We introduce Optimistic World Models (OWMs), a principled and scalable framework for optimistic exploration that brings classical reward-biased maximum likelihood estimation ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šOptimistic World Models: Efficient Exploration in Model-Based Deep Reinforcement Learning

---

## 1. ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

- **ç¨€ç–å¥–åŠ±ç¯å¢ƒä¸‹çš„ä½æ•ˆæ¢ç´¢**ï¼šç°æœ‰çš„åŸºäºä¸–ç•Œæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ï¼ˆWorld Model-based RLï¼‰ç®—æ³•ï¼ˆå¦‚ DreamerV3ã€STORMï¼‰åœ¨ç¨€ç–å¥–åŠ±ï¼ˆsparse-rewardï¼‰ç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ï¼Œå› ä¸ºå…¶ä¾èµ–çš„ç­–ç•¥ç†µæ­£åˆ™åŒ–ç­‰æ¢ç´¢æœºåˆ¶ä¸è¶³ä»¥é©±åŠ¨å……åˆ†æ¢ç´¢ã€‚
- **é—­ç¯è¯†åˆ«é—®é¢˜ï¼ˆClosed-loop Identification Problemï¼‰**ï¼šæ ‡å‡†çš„â€œç¡®å®šæ€§ç­‰ä»·â€ï¼ˆcertainty equivalenceï¼‰åŸåˆ™ä¼šå¯¼è‡´æ¨¡å‹ä¼°è®¡åå·®ï¼Œæ”¶æ•›åˆ°æ¬¡ä¼˜ç­–ç•¥ï¼Œè¿™æ˜¯æ¢ç´¢å¿…è¦æ€§çš„æ ¹æœ¬åŸå› ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

- **Optimistic World Models (OWMs)**ï¼šæå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œåœ¨ä¸–ç•Œæ¨¡å‹è®­ç»ƒä¸­å¼•å…¥**ä¹è§‚åŠ¨åŠ›å­¦æŸå¤±ï¼ˆoptimistic dynamics lossï¼‰**ï¼Œå°†ç»å…¸çš„ **Reward-Biased Maximum Likelihood Estimation (RBMLE)** åŸç†å¼•å…¥æ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‚
- **æ¢¯åº¦åŒ–çš„ RBMLE å®ç°**ï¼š
  - å°† RBMLE ç›®æ ‡è½¬åŒ–ä¸ºä¸€ä¸ªå®Œå…¨åŸºäºæ¢¯åº¦çš„ä¼˜åŒ–ç›®æ ‡ï¼Œé¿å…äº†ä¼ ç»Ÿ UCB æ–¹æ³•æ‰€éœ€çš„ä¸ç¡®å®šæ€§ä¼°è®¡å’Œéå‡¸çº¦æŸã€‚
  - é€šè¿‡åœ¨æ¨¡å‹è®­ç»ƒä¸­å¢åŠ ä¸€ä¸ªé¼“åŠ±é«˜å›æŠ¥è½¨è¿¹çš„æŸå¤±é¡¹ï¼Œä½¿ä¸–ç•Œæ¨¡å‹ç”Ÿæˆâ€œä¹è§‚â€çš„æƒ³è±¡ï¼ˆoptimistic imaginationsï¼‰ï¼Œä»è€Œå¼•å¯¼ç­–ç•¥å‘æ½œåœ¨é«˜å›æŠ¥åŒºåŸŸæ¢ç´¢ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç‰¹æ€§ | OWMs | ä¼ ç»Ÿ UCB æ–¹æ³• |
|------|------|----------------|
| **è®¡ç®—æ•ˆç‡** | é«˜ï¼Œä»…éœ€é¢å¤–æŸå¤±é¡¹ï¼Œæ— æ¶æ„æ”¹åŠ¨ | ä½ï¼Œéœ€ä¸ç¡®å®šæ€§å»ºæ¨¡ã€ç½®ä¿¡åŒºé—´è®¡ç®— |
| **å¯æ‰©å±•æ€§** | å¯ç›´æ¥é›†æˆåˆ° DreamerV3ã€STORM ç­‰ä¸»æµæ¡†æ¶ | åœ¨å¤§è§„æ¨¡ DRL ä¸­éš¾ä»¥æ‰©å±• |
| **å®ç°å¤æ‚åº¦** | æ’ä»¶å¼ï¼ˆplug-and-playï¼‰ï¼Œæ˜“äºéƒ¨ç½² | å¤æ‚ï¼Œå¸¸éœ€ä¸“é—¨è®¾è®¡ |
| **æ¢ç´¢æœºåˆ¶** | é€šè¿‡æ¨¡å‹åç½®å®ç°æ¸©å’Œä¹è§‚ï¼ˆmild optimismï¼‰ | æ˜“å‡ºç°è¿‡åº¦ä¹è§‚ï¼ˆexcessive optimismï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **Atari100K Benchmark**ï¼š26 ä¸ª Atari æ¸¸æˆï¼Œæ¯ä¸ªä»»åŠ¡é™åˆ¶ä¸º 400K å¸§ï¼ˆçº¦ 2 å°æ—¶æ¸¸æˆæ—¶é—´ï¼‰ï¼Œç”¨äºè¯„ä¼°**æ ·æœ¬æ•ˆç‡**ã€‚
- **DeepMind Control (DMC) Suite**ï¼š
  - **DMC Proprio**ï¼šè¿ç»­æ§åˆ¶ä»»åŠ¡ï¼ŒçŠ¶æ€è¾“å…¥ï¼Œé¢„ç®— 500K æ­¥ã€‚
  - **DMC Vision**ï¼šç›¸åŒä»»åŠ¡ä½†è¾“å…¥ä¸ºå›¾åƒï¼Œé¢„ç®— 1M æ­¥ã€‚
- **é‡ç‚¹å…³æ³¨ç¨€ç–å¥–åŠ±ç¯å¢ƒ**ï¼šå¦‚ `Private Eye`ã€`Acrobot Swingup Sparse`ã€`Cartpole Swingup Sparse`ã€`Freeway`ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Human-Normalized Score (HNS)**ï¼š`(Agent Score - Random Score) / (Human Score - Random Score)`ï¼Œè¶Šé«˜è¶Šå¥½ã€‚
  - **Interquartile Mean (IQM)** å’Œ **Median**ï¼šå‡å°‘å¼‚å¸¸å€¼å½±å“ã€‚
  - **æœ€ç»ˆå¹³å‡å¥–åŠ±ï¼ˆMean Rewardï¼‰**ã€‚
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - O-DreamerV3 å’Œ O-STORM åˆ†åˆ«åŸºäº DreamerV3 å’Œ STORM æ„å»ºã€‚
  - è¶…å‚æ•°å°½é‡å¤ç”¨åŸæ–¹æ³•ï¼Œæ–°å¢å‚æ•°ï¼šä¹è§‚ç³»æ•° `Î±(t)` å’Œæ¨¡å‹ç†µç³»æ•° `Î·`ã€‚
  - O-DreamerV3 ç»“æœå¹³å‡äº **10 ä¸ªéšæœºç§å­**ï¼Œå…¶ä½™ä¸º **5 ä¸ªç§å­**ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **ä¸»åŸºçº¿**ï¼š
  - **DreamerV3** vs **O-DreamerV3**
  - **STORM** vs **O-STORM**
- **å…¶ä»–å¯¹æ¯”**ï¼š
  - æ¶ˆèå®éªŒï¼ˆablationï¼‰éªŒè¯ä¹è§‚æŸå¤±å’Œç†µé¡¹çš„ä½œç”¨ã€‚
  - ä¸åŒ `Î±` å’Œ `Î·` å€¼çš„æ•æ„Ÿæ€§åˆ†æã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **Atari100K Benchmark**
- **O-DreamerV3**ï¼š
  - **å¹³å‡ HNS è¾¾åˆ° 152.68%**ï¼Œç›¸æ¯” DreamerV3 çš„ **97.45%**ï¼Œæå‡ **55%**ã€‚
  - åœ¨ `Private Eye` ä¸Šä» 115.53 æå‡è‡³ **2120.48**ï¼ˆè¿‘ 18 å€ï¼‰ã€‚
  - åœ¨ `Freeway` ä¸Šä» 0 æå‡è‡³ 30ï¼ˆæ»¡åˆ† 30ï¼‰ï¼Œé¦–æ¬¡è¾¾åˆ°æ»¡åˆ†ã€‚
- **O-STORM**ï¼š
  - å¹³å‡ HNS ä¸º **80.68%**ï¼Œä¼˜äº STORM çš„ **75.90%**ã€‚
  - åœ¨ `Freeway` ä¸Šå–å¾— **6.38** çš„æ­£åˆ†ï¼ˆSTORM ä¸º 0ï¼‰ï¼Œè¯æ˜å…¶æ¢ç´¢èƒ½åŠ›æ›´å¼ºã€‚

#### **DMC Suite**
- åœ¨ `Acrobot Swingup Sparse` å’Œ `Cartpole Swingup Sparse` ç­‰ç¨€ç–ä»»åŠ¡ä¸Šï¼ŒO-DreamerV3 æ˜¾è‘—ä¼˜äº DreamerV3ã€‚
- ä¾‹å¦‚åœ¨ DMC Proprio çš„ `Acrobot Swingup Sparse` ä¸­ï¼Œå¹³å‡å¾—åˆ†ä» **8.4** æå‡è‡³ **34.6**ã€‚
- åœ¨å¯†é›†å¥–åŠ±ä»»åŠ¡ä¸Šæ€§èƒ½ç›¸å½“ï¼Œæœªè§é€€åŒ–ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **å…¨é¢ä¼˜äºåŸºçº¿**ï¼šåœ¨å¤§å¤šæ•° Atari å’Œ DMC ä»»åŠ¡ä¸Šï¼ŒO-DreamerV3 å’Œ O-STORM å‡ä¼˜äºå¯¹åº”åŸºçº¿ã€‚
- **ç¨€ç–ç¯å¢ƒä¼˜åŠ¿æ˜¾è‘—**ï¼šåœ¨ `Private Eye`ã€`Montezuma's Revenge` ç­‰ç¡¬æ¢ç´¢ä»»åŠ¡ä¸Šï¼ŒOWMs æ”¶æ•›æ›´å¿«ï¼Œæœ€ç»ˆæ€§èƒ½æ›´é«˜ï¼ˆå›¾1æ˜¾ç¤º O-DreamerV3 åœ¨ `Private Eye` ä¸Šè¾¾åˆ°è¿‘ 2 å€å›æŠ¥ï¼‰ã€‚
- **è®¡ç®—å¼€é”€æå°**ï¼š
  - åœ¨ Atari100Kï¼ˆMsPacmanï¼‰ä¸Šï¼ŒO-DreamerV3 è®­ç»ƒæ—¶é—´ä¸º **138 åˆ†é’Ÿ**ï¼ŒDreamerV3 ä¸º **115 åˆ†é’Ÿ**ï¼Œä»…å¢åŠ çº¦ 20% æ—¶é—´ã€‚

### **æ¶ˆèå®éªŒç»“æœ**

- **ç§»é™¤ç†µæŸå¤±é¡¹ï¼ˆEntropy Lossï¼‰**ï¼šæ€§èƒ½ä¸‹é™ï¼Œè¯´æ˜æ¨¡å‹ç†µæ­£åˆ™æœ‰åŠ©äºé˜²æ­¢è¿‡æ‹Ÿåˆå’Œå´©æºƒã€‚
- **ä¹è§‚ç³»æ•° `Î±` è¿‡å¤§ï¼ˆå¦‚ 0.1ï¼‰**ï¼šå¯¼è‡´è®­ç»ƒä¸ç¨³å®šç”šè‡³å¤±è´¥ï¼Œè¯æ˜**æ¸©å’Œä¹è§‚**çš„é‡è¦æ€§ã€‚
- **æ¨¡å‹ç†µç³»æ•° `Î·` è¿‡å¤§ï¼ˆå¦‚ 0.03ï¼‰**ï¼šåŒæ ·æŸå®³æ€§èƒ½ï¼Œå°å€¼ï¼ˆå¦‚ 3e-6ï¼‰æ›´ä¼˜ã€‚
- **ä¸åŒ `Î±(t)` è¡°å‡ç­–ç•¥**ï¼šå¸¸æ•° `Î±=0.0001` è¡¨ç°è‰¯å¥½ï¼Œæ— éœ€å¤æ‚è°ƒåº¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **RBMLE åŸç†å¯æˆåŠŸè¿ç§»åˆ°å¤§è§„æ¨¡ DRL**ï¼šé€šè¿‡æ¢¯åº¦åŒ–å®ç°ï¼Œè§£å†³äº†ä¼ ç»Ÿ UCB æ–¹æ³•åœ¨æ·±åº¦å­¦ä¹ ä¸­çš„å¯æ‰©å±•æ€§éš¾é¢˜ã€‚
2. **ä¹è§‚åº”ä½œç”¨äºæ¨¡å‹å­¦ä¹ è€Œéç­–ç•¥**ï¼šOWMs å°†ä¹è§‚æ€§æ³¨å…¥**ä¸–ç•Œæ¨¡å‹çš„åŠ¨åŠ›å­¦é¢„æµ‹**ä¸­ï¼Œè€Œéç­–ç•¥æœ¬èº«ï¼Œå®ç°äº†æ›´è‡ªç„¶ã€é«˜æ•ˆçš„æ¢ç´¢ã€‚
3. **â€œæ’ä»¶å¼â€æ”¹è¿›å³å¯å¤§å¹…æå‡æ€§èƒ½**ï¼šä»…éœ€æ·»åŠ ä¸€ä¸ªæŸå¤±é¡¹ï¼Œå³å¯åœ¨ä¸æ”¹å˜ç½‘ç»œç»“æ„çš„æƒ…å†µä¸‹æ˜¾è‘—æå‡ DreamerV3 å’Œ STORM çš„æ¢ç´¢èƒ½åŠ›ã€‚
4. **åœ¨ç¨€ç–å¥–åŠ±ç¯å¢ƒä¸­æ•ˆæœå°¤ä¸ºçªå‡º**ï¼šéªŒè¯äº† OWMs å¯¹æ¢ç´¢æŒ‘æˆ˜çš„æœ‰æ•ˆåº”å¯¹ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- **ç†è®ºæ”¶æ•›æ€§å°šæœªå®Œå…¨å»ºç«‹**ï¼šè™½ç„¶ RBMLE åœ¨è¡¨æ ¼å‹ MDP ä¸­æœ‰ç†è®ºä¿è¯ï¼Œä½†æœ¬æ–‡æå‡ºçš„**æ¢¯åº¦åŒ–ã€å‡½æ•°é€¼è¿‘ç‰ˆæœ¬çš„æ”¶æ•›æ€§ä»éœ€è¿›ä¸€æ­¥åˆ†æ**ã€‚
- **è¶…å‚æ•°æ•æ„Ÿæ€§**ï¼šå°½ç®¡ä½¿ç”¨äº†ç»Ÿä¸€é…ç½®ï¼Œä½† `Î±` å’Œ `Î·` çš„é€‰æ‹©å¯¹æ€§èƒ½æœ‰æ˜¾è‘—å½±å“ï¼Œè¿‡å¤§å€¼ä¼šç ´åè®­ç»ƒã€‚
- **ä¹è§‚ç¨‹åº¦å›ºå®š**ï¼šå½“å‰ `Î±(t)` ä¸ºå¸¸æ•°æˆ–ç®€å•è¡°å‡ï¼Œç¼ºä¹è‡ªé€‚åº”è°ƒèŠ‚æœºåˆ¶ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- **è‡ªé€‚åº”çš„ä¹è§‚ç³»æ•°è®¾è®¡**ï¼šå€Ÿé‰´ Agent57 ä¸­çš„å…ƒæ§åˆ¶å™¨æ€æƒ³ï¼ŒåŠ¨æ€è°ƒæ•´ `Î±(t)` ä»¥æœ€å¤§åŒ–æ¢ç´¢æ”¶ç›Šã€‚
- **ç†è®ºåˆ†æ**ï¼šå»ºç«‹æ¢¯åº¦åŒ– RBMLE åœ¨å‡½æ•°é€¼è¿‘ä¸‹çš„æ”¶æ•›æ€§å’Œåæ‚”ç•Œï¼ˆregret boundï¼‰ã€‚
- **æ‰©å±•åˆ°æ›´å¤šæ¶æ„**ï¼šå°† OWMs åº”ç”¨äº MuZeroã€EfficientZero ç­‰åŸºäº MCTS çš„ä¸–ç•Œæ¨¡å‹ã€‚
- **ä¸å…¶ä»–æ¢ç´¢æœºåˆ¶ç»“åˆ**ï¼šå¦‚ä¸å†…åœ¨æ¿€åŠ±ï¼ˆintrinsic motivationï¼‰æˆ–éšæœºç½‘ç»œè’¸é¦ï¼ˆRNDï¼‰ç»“åˆï¼Œè¿›ä¸€æ­¥æå‡é²æ£’æ€§ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> è¯¥è®ºæ–‡æå‡ºäº† **Optimistic World Models (OWMs)**ï¼Œé€šè¿‡å°† **RBMLE åŸç†**è½¬åŒ–ä¸ºä¸€ä¸ª**å¯å¾®çš„ä¹è§‚åŠ¨åŠ›å­¦æŸå¤±**ï¼Œå®ç°äº†åœ¨ä¸å¢åŠ å¤æ‚åº¦çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡ä¸–ç•Œæ¨¡å‹åœ¨ç¨€ç–å¥–åŠ±ç¯å¢ƒä¸­çš„æ¢ç´¢æ•ˆç‡ï¼Œæ˜¯ MBRL é¢†åŸŸä¸€æ¬¡**åŸç†æ€§ä¸å®ç”¨æ€§å…¼å¤‡**çš„é‡è¦è¿›å±•ã€‚

</details>

---

### 7. [Towards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective](https://arxiv.org/abs/2602.08009)

**Authors**: Rui Li, Zeyu Zhang, Xiaohe Bo, Quanyu Dai, Chaozhuo Li, Feng Wen, Xu Chen  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.08009v1  

#### Abstract
Multi-agent architectures built on large language models (LLMs) have demonstrated the potential to realize swarm intelligence through well-crafted collaboration. However, the substantial burden of manual orchestration inherently raises an imperative to automate the design of agentic workflows. We fr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTowards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰åŸºäº **Large Language Model (LLM)** çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆ**Multi-Agent System, MAS**ï¼‰åœ¨åè°ƒæœºåˆ¶ä¸Šå­˜åœ¨ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **Adaptivityï¼ˆé€‚åº”æ€§ï¼‰**ï¼šä¼ ç»Ÿæ–¹æ³•ä¾èµ–é¢„å®šä¹‰çš„é™æ€æ‹“æ‰‘ï¼ˆå¦‚é“¾å¼ã€æ˜Ÿå‹ç»“æ„ï¼‰ï¼Œæ— æ³•æ ¹æ®æ¨ç†è¿‡ç¨‹ä¸­çš„åŠ¨æ€æ¶ˆæ¯æµè°ƒæ•´é€šä¿¡è·¯å¾„ã€‚
- **Scalabilityï¼ˆå¯æ‰©å±•æ€§ï¼‰**ï¼šå½“æ–°å¢æˆ–ç§»é™¤ agent æ—¶ï¼Œéœ€è¦é‡æ–°è¿›è¡Œæ˜‚è´µçš„ç¦»çº¿ä¼˜åŒ–ï¼ˆå¦‚ GPTSwarmã€AFlowï¼‰ï¼Œéš¾ä»¥æ”¯æŒå¼€æ”¾æˆå‘˜åˆ¶ã€‚
- **Robustnessï¼ˆé²æ£’æ€§ï¼‰**ï¼šä¸­å¿ƒåŒ–æ§åˆ¶æ¶æ„ï¼ˆå¦‚ AutoAgentsã€Puppeteerï¼‰å­˜åœ¨ **Single Point of Failure (SPoF)** é£é™©ï¼Œä¸€æ—¦å…ƒæ§åˆ¶å™¨è¢«æ”»å‡»æˆ–å‡ºé”™ï¼Œæ•´ä¸ªç³»ç»Ÿå¯èƒ½å´©æºƒã€‚

è¿™äº›é™åˆ¶é˜»ç¢äº†æ„å»ºçœŸæ­£è‡ªç»„ç»‡ã€å¯é ä¸”èƒ½åº”å¯¹å¤æ‚ä»»åŠ¡çš„ LLM æ™ºèƒ½ä½“ç¤¾ä¼šã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **RAPS**ï¼ˆ**Reputation-Aware Publish-Subscribe**ï¼‰ï¼Œä¸€ç§å— **Dynamic Ad-Hoc Networking** å¯å‘çš„å»ä¸­å¿ƒåŒ–åè°ƒæ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°† LLM agent è§†ä¸ºç½‘ç»œä¸»æœºï¼Œé€šè¿‡ **å†…å®¹é©±åŠ¨** è€Œé **èº«ä»½é©±åŠ¨** çš„é€šä¿¡æ¨¡å¼å®ç°åä½œã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
- **é€šä¿¡åŸºåº•ï¼ˆCommunication Substrateï¼‰**ï¼šé‡‡ç”¨ **Distributed Publish-Subscribe Protocol**ï¼Œå°†æ¯ä¸ª agent è§£è€¦ä¸ºä¸‰ä¸ªæ¨¡å—ï¼š
  - **Publisher**ï¼šç”Ÿæˆæ¶ˆæ¯ï¼ˆpublicationï¼‰
  - **Subscriber**ï¼šå£°æ˜æ„å›¾ï¼ˆsubscriptionï¼‰
  - **Broker**ï¼šåŸºäºè¯­ä¹‰åŒ¹é…ï¼ˆè€Œéå›ºå®šå›¾ï¼‰è·¯ç”±æ¶ˆæ¯
- **è¦†ç›–æœºåˆ¶ï¼ˆOverlay Mechanismsï¼‰**ï¼š
  1. **Reactive Subscription**ï¼šå…è®¸ agent åœ¨è¿è¡Œæ—¶æ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€æ›´æ–°è‡ªå·±çš„è®¢é˜…æ„å›¾ï¼Œå®ç°ç»†ç²’åº¦è§’è‰²ä¸“ä¸šåŒ–ã€‚
  2. **Bayesian Reputation**ï¼šæ¯ä¸ª agent ç»´æŠ¤ä¸€ä¸ªæœ¬åœ° **watchdog**ï¼Œä½¿ç”¨è´å¶æ–¯ä¼°è®¡è¯„ä¼°å¯¹ç­‰ä½“çš„å¯é æ€§ï¼Œä»è€Œéš”ç¦»æ¶æ„æˆ–ä½è´¨é‡è¡Œä¸ºè€…ã€‚

è¯¥è®¾è®¡å®ç°äº† **intent-based collaboration** å’Œ **decentralized trust**ï¼Œæ— éœ€é›†ä¸­è°ƒåº¦å™¨å³å¯è‡ªå‘å½¢æˆé«˜æ•ˆåä½œç½‘ç»œã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | ä¼ ç»Ÿæ–¹æ³• | RAPS |
|------|--------|------|
| **Adaptivity** | å›ºå®šæ‹“æ‰‘ï¼Œé€šä¿¡ä¸å¯çŸ¥ï¼ˆcommunication-agnosticï¼‰ | è¿è¡Œæ—¶åŠ¨æ€æ„å›¾æ¼”åŒ–ï¼Œå†…å®¹æ„ŸçŸ¥è·¯ç”± |
| **Scalability** | æ–°å¢ agent éœ€é‡æ–°è®­ç»ƒ/æœç´¢æ‹“æ‰‘ | æ”¯æŒå³æ’å³ç”¨ï¼Œæ— éœ€å…¨å±€é‡æ„ |
| **Robustness** | ä¸­å¿ƒæ§åˆ¶å™¨æ˜“å—æ”»å‡»ï¼ˆSPoFï¼‰ | åˆ†å¸ƒå¼ä¿¡èª‰æœºåˆ¶ï¼ŒæŠ—æ‹œå åº­æ”»å‡» |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨äº”ä¸ªä»£è¡¨æ€§åŸºå‡†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œæ¶µç›–ä¸‰ç±»ä»»åŠ¡ï¼š
| æ•°æ®é›† | ç±»åˆ« | ä»»åŠ¡æè¿° | è¯„ä¼°æŒ‡æ ‡ |
|-------|------|---------|----------|
| **MMLU** | General Reasoning | å¤šé¢†åŸŸçŸ¥è¯†é—®ç­”ï¼ˆSTEMã€äººæ–‡ç­‰ï¼‰ | Accuracy |
| **GSM8K**, **SVAMP**, **AQuA** | Mathematical Reasoning | æ•°å­¦åº”ç”¨é¢˜æ±‚è§£ï¼ˆå¤šæ­¥æ¨ç†ï¼‰ | Accuracy |
| **HumanEval** | Code Generation | Python ç¼–ç¨‹é—®é¢˜ï¼ˆå‡½æ•°è¡¥å…¨ï¼‰ | Pass@1 |

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **LLM Backbone**ï¼šç»Ÿä¸€ä½¿ç”¨ `GPT-4o-mini` ä½œä¸ºæ‰€æœ‰ agent çš„åŸºç¡€æ¨¡å‹ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚
- **Agent æ•°é‡**ï¼šé»˜è®¤é…ç½® 5 ä¸ª agentï¼Œè§’è‰²æ ¹æ®ä»»åŠ¡å®šåˆ¶ï¼ˆå¦‚ MMLU ä½¿ç”¨ Knowledge Expertã€Mathematician ç­‰ï¼‰ã€‚
- **æœ€å¤§é€šä¿¡è½®æ¬¡**ï¼šè®¾ä¸º 5ã€‚
- **è¯„ä¼°æ–¹å¼**ï¼š
  - æ‰€æœ‰æ–¹æ³•ï¼ˆé™¤å• agentï¼‰å‡ä½¿ç”¨ç›¸åŒæ•°é‡çš„ agentã€‚
  - æŠ¥å‘Šå¹³å‡å‡†ç¡®ç‡åŠå„ä»»åŠ¡å¾—åˆ†ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºå››ç±»åŸºçº¿ï¼š
1. **Single-Agent Models**ï¼š
   - Vanilla IO, CoT, ComplexCoT, Self-Consistency (SC)
2. **Static Multi-Agent Models**ï¼š
   - Chain, Star, Tree, Randomï¼ˆå›ºå®šæ‹“æ‰‘ï¼‰
   - LLM-Debate, LLM-Blender
3. **Communication-Agnostic Models**ï¼š
   - GPTSwarm, AgentPrune, AFlow, MaAS, G-Designerï¼ˆåŸºäºç¦»çº¿æœç´¢/å­¦ä¹ æ‹“æ‰‘ï¼‰
4. **Meta-Controlled Models**ï¼š
   - AutoAgents, Puppeteer, MAS-Zeroï¼ˆä¾èµ–ä¸­å¤®æ§åˆ¶å™¨ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰
| æ–¹æ³• | MMLU | GSM8K | SVAMP | AQuA | HumanEval | **Average** |
|------|------|-------|-------|------|-----------|------------|
| **RAPS (Ours)** | **88.2** | **95.4** | **92.2** | **82.6** | **91.5** | **90.0** |
| G-Designer | 86.3 | 93.2 | 90.7 | 79.4 | 90.2 | 88.0 |
| AFlow | 85.6 | 94.1 | 90.0 | 78.5 | 91.0 | 87.8 |
| LLM-Debate | 85.0 | 92.4 | 89.8 | 77.3 | 82.6 | 85.4 |
| Puppeteer | 84.3 | 93.3 | 89.5 | 77.5 | 75.3 | 84.0 |

> âœ… RAPS åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡è¾¾åˆ° **SOTA æ€§èƒ½**ï¼Œå¹³å‡å¾—åˆ† **90.0%**ï¼Œæ˜¾è‘—ä¼˜äºæœ€å¼ºåŸºçº¿ G-Designerï¼ˆ88.0%ï¼‰ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **è¶…è¶Šé™æ€ç»“æ„**ï¼šChain åœ¨ SVAMP ä¸Šä»…ä¸º 82.6%ï¼Œè¿œä½äº RAPS çš„ 92.2%ï¼Œè¡¨æ˜åˆšæ€§æ‹“æ‰‘æ— æ³•é€‚åº”å¤šæ ·åŒ–æ¨ç†éœ€æ±‚ã€‚
- **ä¼˜äºç¦»çº¿ä¼˜åŒ–æ–¹æ³•**ï¼šå°½ç®¡ AFlow/G-Designer ä½¿ç”¨å¤æ‚æœç´¢ç­–ç•¥ï¼Œä½†ä»å—é™äºâ€œé€šä¿¡ä¸å¯çŸ¥â€ç‰¹æ€§ï¼›RAPS åˆ©ç”¨è¿è¡Œæ—¶æ„å›¾å¯¹é½ï¼Œåœ¨ AQuA ä¸Šé¢†å…ˆ 3.2%ã€‚
- **å‡»è´¥ä¸­å¿ƒåŒ–æ§åˆ¶å™¨**ï¼šPuppeteer å¹³å‡ä»… 84.0%ï¼Œä¸”åœ¨ HumanEval ä¸Šä¸¥é‡é€€åŒ–è‡³ 75.3%ï¼Œæ˜¾ç¤ºå…¶è„†å¼±æ€§ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰
éªŒè¯ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶çš„é‡è¦æ€§ï¼š
| å˜ä½“ | MMLU | GSM8K | HumanEval |
|------|------|-------|----------|
| **RAPS (Full)** | 88.2 | 95.4 | 91.5 |
| w/o RSï¼ˆæ—  Reactive Subscriptionï¼‰ | 85.6 (-2.6) | 93.7 (-1.7) | 89.3 (-2.2) |
| w/o BRï¼ˆæ—  Bayesian Reputationï¼‰ | 86.9 (-1.3) | 94.5 (-0.9) | 90.7 (-0.8) |
| w/o Both | 83.7 (-4.5) | 92.8 (-2.6) | 88.5 (-3.0) |

> ğŸ” ç»“æœè¡¨æ˜ï¼š
> - **Reactive Subscription** å¯¹æ€§èƒ½æå‡è´¡çŒ®æ›´å¤§ï¼Œå°¤å…¶åœ¨éœ€è¦ç²¾ç»†è§’è‰²åˆ†å·¥çš„ä»»åŠ¡ä¸­ã€‚
> - **Bayesian Reputation** æ˜¾è‘—å¢å¼ºç³»ç»Ÿé²æ£’æ€§ï¼Œé˜²æ­¢é”™è¯¯ä¼ æ’­ã€‚

æ­¤å¤–ï¼Œ**Figure 5** æ˜¾ç¤ºï¼šå³ä½¿åœ¨â€œnaive agent poolâ€ï¼ˆé€šç”¨è§’è‰²ï¼‰ä¸‹ï¼ŒRAPS ä»ä¿æŒ 90.2% å‡†ç¡®ç‡ï¼Œè€Œ G-Designer ä¸‹é™ 9.5%ï¼Œè¯æ˜å…¶å¯¹åˆå§‹é…ç½®ä¸æ•æ„Ÿï¼Œå…·å¤‡å¼ºè‡ªé€‚åº”èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **åŠ¨æ€æ„å›¾æ¼”åŒ–è‡³å…³é‡è¦**ï¼šReactive Subscription ä½¿ agent èƒ½æ ¹æ®ä¸Šä¸‹æ–‡è‡ªåŠ¨ä¸“ä¸šåŒ–è§’è‰²ï¼ˆå¦‚ä»â€œæ•°å­¦ä¸“å®¶â€ç»†åŒ–ä¸ºâ€œè·ç¦»-é€Ÿç‡-æ—¶é—´åˆ†æå‘˜â€ï¼‰ï¼Œé¿å…é™æ€è§’è‰²é”™é…ã€‚
2. **å»ä¸­å¿ƒåŒ–ä¿¡èª‰æœºåˆ¶æœ‰æ•ˆé˜²å¾¡æ‹œå åº­æ”»å‡»**ï¼šåœ¨æ³¨å…¥ **adversarial agents** çš„å‹åŠ›æµ‹è¯•ä¸­ï¼ˆTable 2ï¼‰ï¼š
   - G-Designer åœ¨ 2T3A åœºæ™¯ä¸‹å‡†ç¡®ç‡é™è‡³ 15.0%
   - Puppeteer-Cï¼ˆæ”»å‡»ä¸­å¤®æ§åˆ¶å™¨ï¼‰ç›´æ¥å´©æºƒè‡³ 13.7%
   - **RAPS ä»ç»´æŒ 83.0%**ï¼Œä½“ç°å¼ºå¤§é²æ£’æ€§ã€‚
3. **å¯æ‰©å±•æ€§å¼º**ï¼šéšç€ agent æ•°é‡å¢åŠ ï¼ˆFigure 3aï¼‰ï¼ŒRAPS æŒç»­æå‡æ€§èƒ½ï¼Œè€Œ Puppeteer å’Œ Chain å› è¯¯å·®ç´¯ç§¯æˆ–æ§åˆ¶ç“¶é¢ˆè¡¨ç°ä¸‹é™ã€‚
4. **é«˜æ•ˆé€šä¿¡**ï¼šç›¸æ¯”éœ€æ˜‚è´µä¼˜åŒ–çš„ GPTSwarm/G-Designerï¼ŒRAPS æ¨ç†å»¶è¿Ÿç¨³å®šå¢é•¿ï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½²ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–åŸºç¡€æ¨¡å‹èƒ½åŠ›**ï¼šRAPS æ˜¯â€œæ™ºèƒ½æ”¾å¤§å™¨â€ï¼Œä¸èƒ½å¼¥è¡¥ LLM è‡ªèº«çš„çŸ¥è¯†ç¼ºé™·ã€‚
- **å†·å¯åŠ¨é—®é¢˜**ï¼šåˆæœŸå› ç¼ºä¹äº¤äº’å†å²ï¼Œä¿¡èª‰ç³»ç»Ÿå¯èƒ½çŸ­æš‚å¤±æ•ˆï¼Œéœ€ä¸€å®š warm-up æ—¶é—´ã€‚
- **è®¡ç®—å¼€é”€**ï¼šè™½ç„¶å…è®­ç»ƒï¼Œä½†è¿è¡Œæ—¶ LLM è°ƒç”¨é¢‘ç¹ï¼Œæˆæœ¬è¾ƒé«˜ï¼ˆå¯é€šè¿‡ embedding-based broker ç¼“è§£ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† RAPS ä¸ **Multi-Agent Reinforcement Learning** ç»“åˆï¼Œå­¦ä¹ æ›´ä¼˜é€šä¿¡ç­–ç•¥ã€‚
- å¼•å…¥ **Congestion Control** æœºåˆ¶ç®¡ç† token æ¶ˆè€—ã€‚
- æ„å»º **Hierarchical Subnetting** æ”¯æŒè¶…å¤§è§„æ¨¡ agent ç¤¾ä¼šã€‚
- æ¢ç´¢ **Reputation Transfer** ä»¥ç¼“è§£å†·å¯åŠ¨é—®é¢˜ã€‚

---

> ğŸ“Œ **æ€»ç»“**ï¼š  
> RAPS æˆåŠŸå°† **Dynamic Ad-Hoc Networking** çš„ç»å…¸æ€æƒ³å¼•å…¥ LLM å¤šæ™ºèƒ½ä½“åè°ƒé¢†åŸŸï¼Œé¦–æ¬¡åœ¨ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶å†…åŒæ—¶è§£å†³äº† **Adaptivityã€Scalability å’Œ Robustness** çš„ä¸‰éš¾å›°å¢ƒã€‚å…¶å®éªŒå……åˆ†éªŒè¯äº†â€œå†…å®¹ä¸ºä¸­å¿ƒâ€çš„å»ä¸­å¿ƒåŒ–é€šä¿¡èŒƒå¼çš„ä¼˜è¶Šæ€§ï¼Œä¸ºæ„å»ºå¼€æ”¾ã€è‡ªç»„ç»‡ã€å¯ä¿¡çš„ LLM agent ç¤¾ä¼šæä¾›äº†åšå®åŸºç¡€ã€‚

</details>

---

### 8. [Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System](https://arxiv.org/abs/2602.08335)

**Authors**: Yanming Li, Xuelin Zhang, WenJie Lu, Ziye Tang, Maodong Wu, Haotian Luo, Tongtong Wu, Zijie Peng, Hongze Mi, Yibo Feng, Naiqiang Tan, Chao Huang, Hong Chen, Li Shen  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.08335v1  

#### Abstract
Integrating Large Language Models (LLMs) with external tools via multi-agent systems offers a promising new paradigm for decomposing and solving complex problems. However, training these systems remains notoriously difficult due to the credit assignment challenge, as it is often unclear which specif...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šWho Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨åŸºäº **Large Language Models (LLMs)** å’Œå¤–éƒ¨å·¥å…·é›†æˆçš„ **Multi-Agent Systems (MAS)** ä¸­ï¼Œè®­ç»ƒè¿‡ç¨‹é¢ä¸´ä¸¥é‡çš„ **credit assignmentï¼ˆä¿¡ç”¨åˆ†é…ï¼‰æŒ‘æˆ˜**ã€‚ç”±äºä»»åŠ¡çš„æˆåŠŸæˆ–å¤±è´¥æ˜¯å¤šä¸ªæ™ºèƒ½ä½“ï¼ˆå¦‚ planner å’Œ workerï¼‰åä½œçš„ç»“æœï¼Œä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•é€šå¸¸ä¾èµ–äºç¨€ç–çš„ã€å…¨å±€å¹¿æ’­çš„å¥–åŠ±ä¿¡å·ï¼ˆbroadcast rewardsï¼‰ï¼Œæ— æ³•å‡†ç¡®è¯†åˆ«æ¯ä¸ª agent å¯¹æœ€ç»ˆç»“æœçš„å…·ä½“è´¡çŒ®ï¼Œå¯¼è‡´ç­–ç•¥æ›´æ–°ä½æ•ˆä¸”ä¸ç¨³å®šã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šSHARP
ä½œè€…æå‡º **SHARP (Shapley-based Hierarchical Attribution for Reinforcement Policy)**ï¼Œä¸€ç§åŸºäº **Shapley Value** çš„ç²¾ç»†åŒ–ä¿¡ç”¨åˆ†é…æ¡†æ¶ï¼Œç”¨äºä¼˜åŒ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡æ•°å­¦ä¸Šä¸¥è°¨çš„æ–¹å¼é‡åŒ–æ¯ä¸ª agent çš„è¾¹é™…è´¡çŒ®ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
- **Tripartite Decomposed Reward Mechanismï¼ˆä¸‰å…ƒåˆ†è§£å¥–åŠ±æœºåˆ¶ï¼‰**ï¼š
  1. **Global Broadcast-Accuracy Reward**ï¼šç¡®ä¿æ•´ä½“ä»»åŠ¡å¯¹é½ï¼›
  2. **Shapley-based Marginal-Credit Reward**ï¼šä¸ºæ¯ä¸ª agent åˆ†é…åŸºäºå…¶å› æœå½±å“çš„ä¸ªä½“åŒ–å¥–åŠ±ï¼›
  3. **Tool-Process Reward**ï¼šæä¾›æ‰§è¡Œè¿‡ç¨‹å±‚é¢çš„åé¦ˆï¼Œæå‡å·¥å…·è°ƒç”¨çš„æœ‰æ•ˆæ€§ã€‚
  
- **Counterfactual Masking æœºåˆ¶**ï¼šé€šè¿‡â€œåäº‹å®æ©ç â€ç§»é™¤æŸä¸ª agent åæ¯”è¾ƒè½¨è¿¹æ€§èƒ½å·®å¼‚ï¼Œç²¾ç¡®ä¼°è®¡å…¶ Shapley å€¼ï¼Œå®ç°ç»†ç²’åº¦çš„ credit attributionã€‚

- **Hierarchical Advantage Normalization**ï¼šå¯¹ä¸åŒ agent çš„ä¼˜åŠ¿è¿›è¡Œç»„å†…å½’ä¸€åŒ–å¤„ç†ï¼Œç¨³å®šè®­ç»ƒæ¢¯åº¦ï¼Œæ”¯æŒå¼‚æ„ agent çš„è”åˆä¼˜åŒ–ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³•ç±»å‹ | å±€é™æ€§ | SHARP çš„æ”¹è¿› |
|--------|------|-------------|
| å•æ™ºèƒ½ä½“æ¶æ„ï¼ˆSingle-agentï¼‰ | æ˜“å‡ºç°ä¸Šä¸‹æ–‡æº¢å‡ºã€å™ªå£°ç´¯ç§¯ | æ”¯æŒæ¨¡å—åŒ–åˆ†å·¥ï¼Œé™ä½å¤æ‚åº¦ |
| å¤šæ™ºèƒ½ä½“ + å¹¿æ’­å¥–åŠ±ï¼ˆe.g., MATPOï¼‰ | æ‰€æœ‰ agent æ¥æ”¶ç›¸åŒå¥–åŠ±ï¼Œæ··æ·†ä¸ªä½“è´¡çŒ® | å¼•å…¥ Shapley ä¿¡ç”¨ï¼Œç²¾å‡†åŒºåˆ† planner ä¸ worker è´¡çŒ® |
| åå¥½å­¦ä¹ ï¼ˆe.g., GRPOï¼‰ | ç¼ºä¹ä¸ªä½“è¡Œä¸ºå»ºæ¨¡èƒ½åŠ› | åœ¨ group-relative æ¡†æ¶ä¸‹å¼•å…¥ agent-specific ä¼˜åŠ¿å‡½æ•° |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šSHARP å®ç°äº†æ›´é«˜æ•ˆã€ç¨³å®šçš„å¤šæ™ºèƒ½ä½“ååŒè®­ç»ƒï¼Œæ˜¾è‘—æå‡äº† long-horizon å¤æ‚ä»»åŠ¡ä¸­çš„æ¨ç†ä¸æ‰§è¡Œä¸€è‡´æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
å®éªŒè¦†ç›–äº”ä¸ªçœŸå®ä¸–ç•ŒåŸºå‡†ï¼Œæ¶µç›–å¤šè·³æ¨ç†ã€ç½‘é¡µå¯¼èˆªã€æ£€ç´¢å¢å¼ºç”Ÿæˆç­‰åœºæ™¯ï¼š

| æ•°æ®é›† | æè¿° |
|-------|------|
| **MuSiQue** | å¤šè·³é—®ç­”ï¼Œè¦æ±‚çœŸæ­£çš„å¤šæ­¥æ¨ç† |
| **GAIA-text** | ç»¼åˆ AI åŠ©æ‰‹è¯„æµ‹ï¼Œéœ€ç»“åˆ web æµè§ˆä¸å·¥å…·ä½¿ç”¨ |
| **WebWalkerQA** | ç»“æ„åŒ–ç½‘é¡µéå†ä¸è¯æ®èšåˆä»»åŠ¡ |
| **FRAMES** | ç«¯åˆ°ç«¯ RAG åœºæ™¯ä¸‹çš„äº‹å®æ€§ã€æ£€ç´¢ä¸æ¨ç†ç»Ÿä¸€è¯„æµ‹ |
| **DocMath-Eval** | é•¿æ–‡æœ¬ï¼ˆå«è¡¨æ ¼ï¼‰ä¸­çš„æ•°å­¦æ¨ç†ä»»åŠ¡ |

> âš ï¸ æ³¨æ„ï¼šé™¤ MuSiQue å¤–ï¼Œå…¶ä½™å‡é‡‡ç”¨å®˜æ–¹æµ‹è¯•é›†é›¶æ ·æœ¬è¯„ä¼°ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

- **æ¨¡å‹éª¨å¹²**ï¼šä¸»è¦åŸºäº **Qwen3-8B** è¿›è¡Œè®­ç»ƒä¸å¯¹æ¯”ï¼Œä¿è¯å…¬å¹³æ€§ã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - ä½¿ç”¨ **AdamW** ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ $10^{-5}$ï¼Œbatch size 256ï¼›
  - æ¯ä¸ªæŸ¥è¯¢é‡‡æ · G=8 æ¡è½¨è¿¹ï¼›
  - æ€»å…±è®­ç»ƒ 180 ä¸ªæ¢¯åº¦æ­¥ï¼Œåœ¨ 64Ã—A100 GPU ä¸Šå®Œæˆã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Match Accuracy (%)**ï¼šé¢„æµ‹ç­”æ¡ˆæ˜¯å¦åŒ¹é…æ ‡å‡†ç­”æ¡ˆï¼›
  - **Average Match**ï¼šè·¨æ•°æ®é›†å¹³å‡å¾—åˆ†ï¼›
  - **MMLU**ï¼šç”¨äºæ£€æµ‹ç¾éš¾æ€§é—å¿˜ï¼ˆcatastrophic forgettingï¼‰ï¼›
  - **Coordination Metrics**ï¼šå¦‚ planner scoreã€harmful subagent æ¯”ä¾‹ç­‰ã€‚

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºå››ç±»è¿›è¡Œç³»ç»Ÿæ¯”è¾ƒï¼š

| ç±»åˆ« | ä»£è¡¨æ–¹æ³• |
|-----|---------|
| **Vanilla LLMs** | LLaMA-3.1-8B, Qwen3-8B RAG |
| **Prompt-based Planning** | Plan-Search |
| **Single-agent RL** | Search-R1, Single-agent GRPO |
| **Multi-agent RL w/o Marginal Credit** | Planner-Worker, G-Designer, CARD, COA, AceSearcher, MATPO |

> âœ… æ‰€æœ‰å¯¹æ¯”å‡èšç„¦äºæ˜¯å¦å…·å¤‡ **marginal credit modeling (MCR)** èƒ½åŠ›ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ–¹æ³• | MuSiQue | GAIA-text | WebWalkerQA | FRAMES | **AVG** |
|------|--------|----------|------------|--------|--------|
| MATPO (SOTA baseline) | 47.00 | 31.65 | 7.47 | 37.10 | **30.81** |
| **SHARP (ours)** | **50.76** | **33.70** | **8.50** | **37.29** | **32.56** |

> âœ… **ç›¸å¯¹æå‡**ï¼š
> - æ¯”æœ€å¼ºçš„ **multi-agent baseline (MATPO)** æå‡ **+1.75 pts**
> - æ¯” **single-agent baseline** æå‡ **+23.66%**
> - æ¯” **multi-agent baseline** æå‡ **+14.05%**

---

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰ç»„ä»¶æœ‰æ•ˆæ€§åˆ†æï¼ˆFigure 3ï¼‰
- ç§»é™¤ **planner-level Shapley credit** â†’ MuSiQue å‡†ç¡®ç‡ä¸‹é™çº¦ 2.76 pts
- ç§»é™¤ **worker-level Shapley credit** â†’ ä¸‹é™çº¦ 2.36 pts
- **å®Œæ•´ SHARP æ¨¡å‹æ•ˆæœ > ä¸¤è€…ä¹‹å’Œ**ï¼Œè¯´æ˜å­˜åœ¨ååŒå¢ç›Šï¼ˆsynergyï¼‰

#### ï¼ˆ2ï¼‰ä¸åŒè®­ç»ƒç­–ç•¥çš„å½±å“
| è®¾ç½® | Planner Score | Useful Subagents | Harmful Subagents |
|------|---------------|------------------|--------------------|
| No training | 0.4542 | 11.03% | 5.48% |
| MATPO | 0.4804 | 11.85% | 5.48% |
| **SHARP** | **0.5084** | **12.96%** | **4.40%** |

> âœ… è¡¨æ˜ SHARP æˆåŠŸä¼˜åŒ–äº† planner çš„å­ä»»åŠ¡è®¾è®¡ï¼Œå¹¶æœ‰æ•ˆè¿‡æ»¤æœ‰å®³ worker è°ƒç”¨ã€‚

#### ï¼ˆ3ï¼‰å¯æ‰©å±•æ€§ä¸ç¨³å®šæ€§
- **å‚æ•°è§„æ¨¡æ‰©å±•ï¼ˆFigure 4ï¼‰**ï¼šä» 0.6B åˆ° 8Bï¼ŒSHARP å¢é•¿æ›´å¿«ï¼Œåœ¨ 8B ä¸Šæ¯” single-agent å¤šå‡º **14.41 pts**
- **è®­ç»ƒç¨³å®šæ€§ï¼ˆFigure 5ï¼‰**ï¼šåœ¨ GAIA-text ä¸Šè®­ç»ƒ 180 æ­¥ï¼ŒSHARP å‡†ç¡®ç‡å•è°ƒä¸Šå‡ï¼Œè€Œ GRPO/MATPO å‡ºç°æ³¢åŠ¨
- **æ³›åŒ–èƒ½åŠ›ï¼ˆFigure 3 å³å›¾ï¼‰**ï¼šåœ¨ DocMath-Eval å››ç§è®¾å®šï¼ˆSS/SL/CS/CLï¼‰ä¸­å‡å–å¾—æœ€ä½³è¡¨ç°

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Marginal Credit æ˜¯æ€§èƒ½è·ƒè¿çš„å…³é”®é©±åŠ¨å› ç´ **  
   ç›¸è¾ƒäºæ¶æ„è®¾è®¡æˆ–è®­ç»ƒç­–ç•¥æœ¬èº«ï¼Œæ˜¾å¼çš„ **Shapley-based credit assignment** å¯¹æ€§èƒ½æå‡è´¡çŒ®æœ€å¤§ã€‚

2. **Planner ä¸ Worker çš„ä¿¡ç”¨éœ€ååŒå»ºæ¨¡**  
   å•ç‹¬ä¼˜åŒ– planner æˆ– worker æ•ˆæœæœ‰é™ï¼›åªæœ‰è”åˆå»ºæ¨¡æ‰èƒ½å®ç°ååŒè¿›åŒ–ï¼Œå°¤å…¶ worker çš„ä¿¡ç”¨æ›´èƒ½ç¼“è§£ long-horizon æ‰§è¡Œé”™è¯¯ã€‚

3. **SHARP æå‡åè°ƒè´¨é‡è€Œéå¢åŠ å†—ä½™è®¡ç®—**  
   - å‡å°‘ **harmful subagent calls** ä» 5.48% â†’ 4.40%
   - æé«˜ **useful subagent ratio** è‡³ 12.96%
   - è¡¨æ˜å…¶å­¦ä¹ åˆ°äº†æ›´é«˜æ•ˆçš„åä½œæ¨¡å¼

4. **æ— ç¾éš¾æ€§é—å¿˜ç°è±¡**ï¼ˆTable 2ï¼‰
| æ–¹æ³• | MMLU Accuracy |
|------|----------------|
| Planner-Worker (no train) | 93.04% |
| MATPO | 94.00% |
| **SHARP** | **94.65%** |

> âœ… è¡¨æ˜ SHARP ä¸ä»…æœªæŸå®³é€šç”¨çŸ¥è¯†ï¼Œåè€Œå› æ¨ç†èƒ½åŠ›å¢å¼ºå¸¦æ¥æ­£å‘è¿ç§»ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼šShapley å€¼ä¼°ç®—éœ€è¦å¤šæ¬¡ counterfactual rolloutï¼Œå°½ç®¡å¯é€šè¿‡å¹¶è¡Œç¼“è§£ï¼Œä½†ä»å¢åŠ è®­ç»ƒæˆæœ¬ï¼ˆè§ Figure 7ï¼‰ã€‚
2. **ä¾èµ–é«˜è´¨é‡ç¯å¢ƒæ¨¡æ‹Ÿ**ï¼šå·¥å…·åé¦ˆå¿…é¡»å¯é ï¼Œå¦åˆ™ marginal credit ä¼šè¢«æ±¡æŸ“ã€‚
3. **å½“å‰ä»…é€‚ç”¨äº role-based parameter sharing æ¶æ„**ï¼Œå°šæœªæ¨å¹¿è‡³å®Œå…¨ç‹¬ç«‹ç­–ç•¥çš„ MASã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **é«˜æ•ˆ Shapley Approximation**ï¼šæ¢ç´¢é‡‡æ ·ç­–ç•¥æˆ–ä»£ç†æ¨¡å‹æ¥åŠ é€Ÿ credit è®¡ç®—ã€‚
2. **åŠ¨æ€ agent pruning**ï¼šåˆ©ç”¨ negative Shapley credit è‡ªåŠ¨å‰”é™¤ä½æ•ˆ agentï¼Œæ„å»ºè‡ªé€‚åº” topologyã€‚
3. **è·¨ä»»åŠ¡è¿ç§» credit logic**ï¼šå°† learned attribution æœºåˆ¶è¿ç§»åˆ°æ–°é¢†åŸŸã€‚
4. **æ‰©å±•è‡³éå±‚çº§ç»“æ„**ï¼šåº”ç”¨äºé€šä¿¡å›¾ï¼ˆcommunication graphï¼‰æˆ–å¤šç¯è·¯åä½œç³»ç»Ÿã€‚

---

## âœ… æ€»ç»“
**SHARP** æ˜¯é¦–ä¸ªå°† **cooperative game theory** ä¸­çš„ **Shapley Value** ç³»ç»Ÿåº”ç”¨äº **LLM-based MAS** çš„ credit assignment æ¡†æ¶ã€‚å®ƒé€šè¿‡ä¸‰é‡å¥–åŠ±åˆ†è§£ä¸åäº‹å®å› æœå»ºæ¨¡ï¼Œè§£å†³äº†ä¼ ç»Ÿå¤šæ™ºèƒ½ä½“ RL ä¸­â€œè°è¯¥å¾—å¥–â€çš„æ ¹æœ¬éš¾é¢˜ã€‚å®éªŒè¯æ˜å…¶ä¸ä»…å¤§å¹…è¶…è¶Š SOTAï¼Œè¿˜å¢å¼ºäº†è®­ç»ƒç¨³å®šæ€§ã€åè°ƒæ•ˆç‡ä¸æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºæ„å»ºå¯è§£é‡Šã€å¯æ‰©å±•çš„æ™ºèƒ½ä½“ç¤¾ä¼šæä¾›äº†åšå®åŸºç¡€ã€‚

</details>

---

### 9. [Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs](https://arxiv.org/abs/2602.08241)

**Authors**: Siqu Ou, Tianrui Wan, Zhiyuan Zhao, Junyu Gao, Xuelong Li  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.08241v1  

#### Abstract
While chain-of-thought (CoT) reasoning has substantially improved multimodal large language models (MLLMs) on complex reasoning tasks, existing approaches largely rely on long textual reasoning trajectories and provide limited mechanisms for learning stable visual attention policies. Our analysis sh...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜

å½“å‰çš„ **Multimodal Large Language Models (MLLMs)** åœ¨å¤æ‚è§†è§‰æ¨ç†ä»»åŠ¡ä¸­è™½ç„¶å…·å¤‡å¼ºå¤§çš„è¯­è¨€æ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨**è§†è§‰æ³¨æ„åŠ›æœºåˆ¶ä¸Šå­˜åœ¨ä¸¥é‡ç¼ºé™·**ã€‚å…·ä½“è¡¨ç°ä¸ºï¼š

- **æ—©æœŸè§†è§‰å…³æ³¨é”™è¯¯éš¾ä»¥çº æ­£**ï¼šåœ¨ Chain-of-Thought (CoT) æ¨ç†è¿‡ç¨‹ä¸­ï¼Œè‹¥æ¨¡å‹åˆå§‹é˜¶æ®µæœªèƒ½æ­£ç¡®èšç„¦äºç›®æ ‡è§†è§‰åŒºåŸŸï¼Œåç»­æ¨ç†é“¾å¾ˆå°‘èƒ½ä¿®æ­£è¯¥é”™è¯¯ï¼Œå¯¼è‡´â€œé”™è¯¯ä¼ æ’­â€ã€‚
- **ç¼ºä¹æœ‰æ•ˆçš„è§†è§‰æ³¨æ„åŠ›å­¦ä¹ ä¿¡å·**ï¼šç°æœ‰è®­ç»ƒç›®æ ‡ï¼ˆå¦‚ç­”æ¡ˆå‡†ç¡®æ€§ï¼‰æ— æ³•ä¸ºè§†è§‰æ³¨æ„åŠ›è¡Œä¸ºæä¾›æœ‰æ•ˆçš„ **credit assignment**ï¼ˆä¿¡ç”¨åˆ†é…ï¼‰ï¼Œå¯¼è‡´æ¨¡å‹å³ä½¿æ‹¥æœ‰å¼ºå¤§æ¨ç†èƒ½åŠ›ï¼Œä¹Ÿæ— æ³•å»ºç«‹ç¨³å®šã€å¯é çš„è§†è§‰å®šä½ç­–ç•¥ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯

ä½œè€…æå‡º **SAYO** â€”â€” ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰çš„è§†è§‰æ¨ç†æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ˜¯å¼•å…¥ **Entropy-Based Target Attention Reward**ï¼ˆåŸºäºç†µçš„ç›®æ ‡æ³¨æ„åŠ›å¥–åŠ±ï¼‰ï¼š

- **Region-Level è§†è§‰æ³¨æ„åŠ›å¥–åŠ±**ï¼šåˆ©ç”¨å¸¦æœ‰è¾¹ç•Œæ¡†æ ‡æ³¨çš„æ•°æ®ï¼Œè®¡ç®—æ¨¡å‹å¯¹ç›®æ ‡è§†è§‰åŒºåŸŸçš„å…³æ³¨ç¨‹åº¦ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå¼ºåŒ–å­¦ä¹ ä¸­çš„å¥–åŠ±ä¿¡å·ã€‚
- **é«˜ç†µ Token é€‰æ‹©æœºåˆ¶**ï¼šä»…åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä¸ç¡®å®šæ€§è¾ƒé«˜ï¼ˆå³ä¿¡æ¯é‡å¤§ï¼‰çš„ token ä¸Šæ–½åŠ æ³¨æ„åŠ›å¥–åŠ±ï¼Œç¡®ä¿ä¼˜åŒ–é›†ä¸­åœ¨å…³é”®å†³ç­–ç‚¹ï¼Œé¿å…å™ªå£°å¹²æ‰°ã€‚
- **æ— éœ€å¤–éƒ¨æç¤ºæˆ–æ¶æ„ä¿®æ”¹**ï¼šä¸ä¾èµ– visual prompt engineering æˆ–é¢å¤–æ¨¡å—ï¼Œåœ¨æ¨ç†æ—¶æ— éœ€ç‰¹æ®Šå¤„ç†å³å¯å®ç°æ›´å¼ºçš„è§†è§‰èšç„¦ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| å¯¹æ¯”ç»´åº¦ | ç°æœ‰æ–¹æ³• | SAYO |
|--------|-------|------|
| **æ³¨æ„åŠ›å­¦ä¹ æ–¹å¼** | é—´æ¥ï¼ˆé€šè¿‡ç­”æ¡ˆå‡†ç¡®ç‡ï¼‰ | ç›´æ¥ï¼ˆæ˜¾å¼æ³¨æ„åŠ›å¥–åŠ±ï¼‰ |
| **æ˜¯å¦éœ€è¦å¤–éƒ¨å·¥å…·** | æ˜¯ï¼ˆå¦‚ ReFocusã€Visual SketchPad éœ€è¦ç¨‹åºåŒ–æ ‡æ³¨ï¼‰ | å¦ï¼ˆç«¯åˆ°ç«¯è®­ç»ƒï¼‰ |
| **èƒ½å¦çº æ­£æ—©æœŸé”™è¯¯** | å¼±ï¼ˆé”™è¯¯æ˜“ä¼ æ’­ï¼‰ | å¼ºï¼ˆæŒç»­å¼ºåŒ–æ­£ç¡®å…³æ³¨ï¼‰ |
| **æ³›åŒ–èƒ½åŠ›** | å—é™äºç‰¹å®šä»»åŠ¡è®¾è®¡ | è·¨ä»»åŠ¡è¿ç§»æ€§å¼ºï¼ˆæ•°å­¦ã€å›¾è¡¨ã€é€šç”¨è§†è§‰å‡æå‡ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

| ç±»åˆ« | æ•°æ®é›†åç§° | ç”¨é€”è¯´æ˜ |
|-----|-----------|---------|
| **é€šç”¨è§†è§‰æ¨ç†** | GQA, M3CoT, V*, MMStar, MME-RealWorld Lite | æµ‹è¯•å¤šæ­¥è§†è§‰æ¨ç†ä¸çœŸå®åœºæ™¯ç†è§£èƒ½åŠ› |
| **æ•°å­¦è§†è§‰æ¨ç†** | We-Math, MathVision | åŒ…å«å‡ ä½•å›¾ã€å…¬å¼å›¾åƒç­‰éœ€ç²¾ç¡®è§†è§‰è§£æçš„ä»»åŠ¡ |
| **ç»“æ„åŒ–å›¾è¡¨ç†è§£** | ChartQA, AI2D, CharXiv | å›¾è¡¨ã€ç§‘å­¦æ’å›¾ç­‰ç»“æ„åŒ–è§†è§‰è¾“å…¥çš„ç†è§£ |
| **è®­ç»ƒæ•°æ®æ¥æº** | GQA + ReFocus_Data (~20k æ ·æœ¬) | æ„å»ºå¼ºè°ƒè§†è§‰å…³æ³¨çš„ RL è®­ç»ƒæ ·æœ¬ |

> æ³¨ï¼šè®­ç»ƒé˜¶æ®µ**æœªä½¿ç”¨ä»»ä½•æ•°å­¦æ•°æ®é›†**ï¼Œä»¥éªŒè¯è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

- **åŸºç¡€æ¨¡å‹**ï¼š
  - `Qwen3-VL-4B/8B/30B`
  - `InternVL3.5-8B`
- **è®­ç»ƒç®—æ³•**ï¼šGroup Relative Policy Optimization (**GRPO**)ï¼Œç»“åˆæ ¼å¼å¥–åŠ±ï¼ˆformat rewardï¼‰ä¸æå‡ºçš„æ³¨æ„åŠ›å¥–åŠ±ã€‚
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - 6 Ã— NVIDIA H200 GPU
  - 4 epochsï¼Œbatch size per device = 64
  - KL æ•£åº¦çº¦æŸç³»æ•° $1\times10^{-3}$
- **è¯„ä¼°åè®®**ï¼š
  - æ‰€æœ‰é—®é¢˜è¾“å‡ºå¿…é¡»åŒ…å« `<think>...</think>` å†…éƒ¨æ¨ç†è¿‡ç¨‹
  - æœ€ç»ˆç­”æ¡ˆç”¨ `\boxed{}` å°è£…
  - æŠ¥å‘Šå„ benchmark çš„å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| ç±»å‹ | ä»£è¡¨æ¨¡å‹ |
|------|--------|
| **é—­æºæ¨¡å‹** | GPT-4o, Gemini 2.5 Pro |
| **å¼€æºé€šç”¨ MLLMs** | Qwen3-VL, InternVL3.5, Kimi-VL-16B |
| **å¼€æºæ¨ç†ä¸“ç”¨ MLLMs** | OpenVLThinker-7B, Semantic-back-7B, ViGoRL, NoisyRollout-7B, R1-Onevision-7B |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| Model | Avg Score |
|-------|----------|
| **GPT-4o** | â€“ |
| **Gemini 2.5 Pro** | â€“ |
| **Qwen3-VL-8B** | 59.64 |
| **SAYO-Qwen-8B** | **64.03** â†‘â†‘ |
| **SAYO-Qwen-4B** | 62.17 > åŸå§‹ 8B ç‰ˆæœ¬ |
| **SAYO-InternVL-8B** | 53.77 > åŸå§‹ 50.49 |

> âœ… **SAYO-Qwen-8B ä¸ä»…è¶…è¶Šæ‰€æœ‰åŒè§„æ¨¡å¼€æºæ¨¡å‹ï¼Œè¿˜åœ¨ MMStar ä¸Šè¶…è¿‡ GPT-4o å’Œ Kimi-VL-16B**

#### åˆ†é¡¹æ˜¾è‘—æå‡ç¤ºä¾‹ï¼š

- **MMStar**: 62.60 â†’ **65.27**
- **We-Math**: 52.64 â†’ **64.83** ï¼ˆ+12.19ï¼Œå·¨å¤§é£è·ƒï¼‰
- **MathVision**: 22.20 â†’ **25.26**
- **ChartQA/AI2D**: å¤šæ•°æå‡ 3â€“5 pts

> ğŸ’¡ å³ä½¿**æœªåœ¨æ•°å­¦æ•°æ®ä¸Šè®­ç»ƒ**ï¼ŒSAYO åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å¤§å¹…æå‡ï¼Œè¯æ˜å…¶æ”¹è¿›çš„æ˜¯åº•å±‚è§†è§‰æ„ŸçŸ¥èƒ½åŠ›è€Œéè®°å¿†ç­”æ¡ˆã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆTable 2 & Table 3ï¼‰

#### âœ… æ³¨æ„åŠ›å¥–åŠ±çš„æœ‰æ•ˆæ€§ï¼ˆTable 2ï¼‰

| è®¾ç½® | Avg æå‡ï¼ˆvs baseï¼‰ |
|------|------------------|
| Accuracy-only reward | +1.28 |
| Attention-only reward | **+4.32** |
| Combined reward | **+4.63** |

> ç»“è®ºï¼š**æ³¨æ„åŠ›å¥–åŠ±æ¯”ä¼ ç»Ÿå‡†ç¡®ç‡å¥–åŠ±æ›´æœ‰æ•ˆ**ï¼Œæ˜¯æ€§èƒ½æå‡çš„å…³é”®é©±åŠ¨åŠ›ã€‚

#### âœ… é«˜ç†µ Token é€‰æ‹©çš„é‡è¦æ€§ï¼ˆTable 3ï¼‰

| Token Selection | We-Math (Qwen) | We-Math (InternVL) |
|------------------|----------------|--------------------|
| All tokens | 58.39 | 24.20 |
| **Top 30% high-entropy tokens** | **64.83** | **25.23** |

> ç»“è®ºï¼š**åªå¯¹é«˜ä¿¡æ¯é‡ token æ–½åŠ æ³¨æ„åŠ›å¥–åŠ±æ•ˆæœæœ€ä½³**ï¼Œé¿å…ä½ä¿¡æ¯ token å¼•å…¥å™ªå£°ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **è§†è§‰æ³¨æ„åŠ›é”™ä½æ˜¯ MLLMs æ¨ç†å¤±è´¥çš„æ ¸å¿ƒåŸå› **  
   å½“å‰ MLLMs çš„æ¨ç†ç“¶é¢ˆä¸åœ¨è¯­è¨€é€»è¾‘ï¼Œè€Œåœ¨**æ— æ³•å¯é åœ°â€œçœ‹åˆ°â€æ­£ç¡®çš„è§†è§‰éƒ¨åˆ†**ã€‚

2. **Credit Assignment ç¼ºå¤±å¯¼è‡´æ³¨æ„åŠ›å­¦ä¹ ä¸è¶³**  
   ä¼ ç»Ÿçš„ç›‘ç£è®­ç»ƒæ— æ³•å°†æˆåŠŸå½’å› äºæ­£ç¡®çš„è§†è§‰å…³æ³¨è¡Œä¸ºï¼Œå¯¼è‡´æ³¨æ„åŠ›ç­–ç•¥ä¸ç¨³å®šã€‚

3. **SAYO æˆåŠŸè§£è€¦â€œè§†è§‰è§£æâ€ä¸â€œé€»è¾‘æ¨ç†â€**  
   é€šè¿‡å¼ºåŒ–å­¦ä¹ ç›´æ¥ä¼˜åŒ–è§†è§‰æ³¨æ„åŠ›ï¼Œè®©å·²æœ‰å¼ºå¤§çš„è¯­è¨€æ¨ç†å¼•æ“å»ºç«‹åœ¨**æ­£ç¡®çš„è§†è§‰å‰æ**ä¹‹ä¸Šã€‚

4. **è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›å¼º**  
   åœ¨æœªè§æ•°å­¦æ•°æ®çš„æƒ…å†µä¸‹æ˜¾è‘—æå‡æ•°å­¦ä»»åŠ¡è¡¨ç°ï¼Œè¡¨æ˜å…¶å­¦åˆ°çš„æ˜¯**é€šç”¨çš„è§†è§‰èšç„¦å…ƒæŠ€èƒ½**ï¼ˆmeta-skillï¼‰ã€‚

5. **é«˜ç†µ token æ˜¯å…³é”®å¹²é¢„èŠ‚ç‚¹**  
   åœ¨æ¨¡å‹æœ€ä¸ç¡®å®šçš„æ—¶å€™å¼ºåˆ¶å…¶æŸ¥çœ‹å›¾åƒï¼Œå½¢æˆâ€œ**Look-to-Verify**â€æœºåˆ¶ï¼Œæ˜¯æœ€é«˜æ•ˆçš„è®­ç»ƒç­–ç•¥ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

- **ä¾èµ–å¸¦è¾¹ç•Œæ¡†æ ‡æ³¨çš„è®­ç»ƒæ•°æ®**ï¼šè™½ä¸éœ€äººå·¥æ’°å†™æ¨ç†è·¯å¾„ï¼Œä½†ä»éœ€ region-level æ ‡æ³¨ï¼Œé™åˆ¶äº†å¯æ‰©å±•æ€§ã€‚
- **å¯¹æä½åˆ†è¾¨ç‡æˆ–æ¨¡ç³Šå›¾åƒä»å¯èƒ½å¤±æ•ˆ**ï¼šæœ¬è´¨ä»æ˜¯ token-level attention mappingï¼Œå—é™äºè§†è§‰ç¼–ç å™¨è´¨é‡ã€‚
- **ç›®å‰ä»…éªŒè¯äºé™æ€å›¾åƒä»»åŠ¡**ï¼šè§†é¢‘æˆ–å¤šå¸§åŠ¨æ€æ¨ç†å°šæœªæµ‹è¯•ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

- **è‡ªåŠ¨æŒ–æ˜æ½œåœ¨å…³æ³¨åŒºåŸŸ**ï¼šå‡å°‘å¯¹äººå·¥æ ‡æ³¨ bbox çš„ä¾èµ–ï¼Œä¾‹å¦‚é€šè¿‡è‡ªç›‘ç£æ–¹å¼å‘ç° salient regionsã€‚
- **æ‰©å±•è‡³å¤šæ¨¡æ€äº¤äº’ä»»åŠ¡**ï¼šå¦‚æœºå™¨äººæ§åˆ¶ã€å…·èº«æ™ºèƒ½ä¸­çš„å®æ—¶è§†è§‰å†³ç­–ã€‚
- **æ¢ç´¢æ›´ç»†ç²’åº¦çš„æ³¨æ„åŠ›è°ƒæ§æœºåˆ¶**ï¼šå¦‚é€å±‚è°ƒèŠ‚ã€åŠ¨æ€å¥–åŠ±æƒé‡ç­‰ã€‚
- **åº”ç”¨äºåŒ»ç–—ã€é¥æ„Ÿç­‰ä¸“ä¸šé¢†åŸŸå›¾åƒç†è§£**ï¼šéªŒè¯åœ¨é«˜ç²¾åº¦éœ€æ±‚ä¸‹çš„å®ç”¨æ€§ã€‚

---

## æ€»ç»“ä¸€å¥è¯

> **SAYO é€šè¿‡å¼•å…¥åŸºäºé«˜ç†µ token çš„ region-level è§†è§‰æ³¨æ„åŠ›å¥–åŠ±ï¼Œè§£å†³äº† MLLMs â€œçœ‹ä¸å‡†â€çš„æ ¹æœ¬é—®é¢˜ï¼Œåœ¨ä¸å¢åŠ æ¨ç†æˆæœ¬çš„å‰æä¸‹ï¼Œå®ç°äº†è·¨ä»»åŠ¡ã€è·¨é¢†åŸŸçš„è§†è§‰æ¨ç†èƒ½åŠ›å…¨é¢æå‡ã€‚**

</details>

---

### 10. [Learning to Discover Iterative Spectral Algorithms](https://arxiv.org/abs/2602.09530)

**Authors**: Zihang Liu, Oleg Balabanov, Yaoqing Yang, Michael W. Mahoney  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.09530v1  

#### Abstract
We introduce AutoSpec, a neural network framework for discovering iterative spectral algorithms for large-scale numerical linear algebra and numerical optimization. Our self-supervised models adapt to input operators using coarse spectral information (e.g., eigenvalue estimates and residual norms), ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šLearning to Discover Iterative Spectral Algorithms**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
ä¼ ç»Ÿæ•°å€¼çº¿æ€§ä»£æ•°ï¼ˆNLAï¼‰å’Œæ•°å€¼ä¼˜åŒ–ä¸­çš„è¿­ä»£è°±ç®—æ³•ï¼ˆå¦‚å¤šé¡¹å¼åŠ é€Ÿã€é¢„æ¡ä»¶å™¨è®¾è®¡ï¼‰é€šå¸¸ä¾èµ–äºæ‰‹å·¥è®¾è®¡çš„è§„åˆ™ï¼ˆå¦‚ Chebyshev å¤šé¡¹å¼ï¼‰ï¼Œéš¾ä»¥è‡ªé€‚åº”åœ°é€‚é…ä¸åŒç®—å­çš„è°±ç»“æ„ã€‚ç°æœ‰åŸºäºæœºå™¨å­¦ä¹ çš„ç®—æ³•å‘ç°æ–¹æ³•å¤šèšç„¦äºç¦»æ•£ç¨‹åºç©ºé—´ï¼Œä¸é€‚ç”¨äºéœ€è¦è¿ç»­å‚æ•°è°ƒæ•´çš„ NLA åœºæ™¯ã€‚

æœ¬æ–‡æ—¨åœ¨**è‡ªåŠ¨åŒ–å‘ç°é€‚ç”¨äºå¤§è§„æ¨¡ NLA ä»»åŠ¡çš„ã€å¯è‡ªé€‚åº”è°±ç»“æ„çš„è¿­ä»£è°±ç®—æ³•**ï¼Œå¡«è¡¥äº† ML for Algorithms åœ¨è¿ç»­æ•°å€¼è®¡ç®—é¢†åŸŸçš„ç©ºç™½ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ï¼šAUToSPEC æ¡†æ¶**
ä½œè€…æå‡ºäº† **AUToSPEC** â€”â€”ä¸€ä¸ªåŸºäºç¥ç»ç½‘ç»œçš„æ¡†æ¶ï¼Œç”¨äºå‘ç°è¿­ä»£è°±ç®—æ³•ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- å°†ç®—æ³•è¡¨ç¤ºä¸º**å¯æ‰§è¡Œçš„çŸ­é€’æ¨å…³ç³»ï¼ˆshort recurrenceï¼‰**ï¼Œç”±ç¥ç»ç½‘ç»œé¢„æµ‹é€’æ¨ç³»æ•°ã€‚
- åˆ©ç”¨ç²—ç²’åº¦è°±ä¿¡æ¯ï¼ˆå¦‚ç²—ç•¥çš„ç‰¹å¾å€¼ä¼°è®¡å’Œæ®‹å·®èŒƒæ•°ï¼‰ä½œä¸ºè¾“å…¥ï¼Œç”Ÿæˆé’ˆå¯¹ä¸‹æ¸¸ä»»åŠ¡å®šåˆ¶çš„çŸ©é˜µå¤šé¡¹å¼ï¼ˆmatrix polynomialï¼‰ã€‚
- æ•´ä¸ªæµç¨‹æ˜¯**ç«¯åˆ°ç«¯å¯å¾®åˆ†ä¸”è‡ªç›‘ç£**çš„ï¼Œé€šè¿‡ä»»åŠ¡é©±åŠ¨çš„ç›®æ ‡å‡½æ•°è¿›è¡Œè®­ç»ƒã€‚

#### **ä¸‰å¤§åˆ›æ–°è¦ç´ **ï¼š
1. **æ¶æ„å³ç®—æ³•ï¼ˆArchitecture as Algorithmï¼‰**  
   ç½‘ç»œæ¨ç†è¿‡ç¨‹ç›´æ¥å®ç°ä¸€ä¸ªæ•°å€¼ç¨³å®šçš„è¿­ä»£è¿‡ç¨‹ï¼ˆå¦‚ $ V_{k+1} = M_k(X)V_k $ï¼‰ï¼Œä½¿å¾—å­¦åˆ°çš„æ¨¡å‹æœ¬èº«å°±æ˜¯å¯éƒ¨ç½²çš„æ•°å€¼ç®—æ³•ã€‚

2. **è·¨å°ºåº¦æ³›åŒ–è®­ç»ƒç­–ç•¥**  
   åœ¨å°è§„æ¨¡åˆæˆå¯¹è§’çŸ©é˜µä¸Šè®­ç»ƒï¼Œè¿ç§»åˆ°ç™¾ä¸‡ç»´çœŸå®ç¨€ç–çŸ©é˜µï¼Œå®ç°äº†**é«˜æ•ˆè®­ç»ƒä¸å®é™…éƒ¨ç½²çš„è§£è€¦**ã€‚

3. **ä»»åŠ¡å®šä¹‰çš„è‡ªç›‘ç£ç›®æ ‡**  
   ä¸ä¾èµ–æ¨¡ä»¿å·²æœ‰ç®—æ³•ï¼Œè€Œæ˜¯é€šè¿‡æœ€å°åŒ–ä»»åŠ¡ç›¸å…³çš„æŸå¤±ï¼ˆå¦‚ CG è¿­ä»£æ¬¡æ•°ã€ç‰¹å¾å€¼é—´éš™ã€è¿‘ä¼¼è¯¯å·®ï¼‰æ¥ä¼˜åŒ–ç®—æ³•æ€§èƒ½ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ Chebyshevï¼‰ | ç¬¦å·å›å½’ / RL æ–¹æ³• | **AUToSPEC** |
|------|--------------------------|--------------------|--------------|
| å‚æ•°ç©ºé—´ | å›ºå®šå½¢å¼ï¼ˆå¦‚åŒºé—´æ˜ å°„ï¼‰ | ç¦»æ•£ç¨‹åºç©ºé—´ | **è¿ç»­ã€å¯å¾®ã€ç»“æ„åŒ–** |
| è‡ªé€‚åº”æ€§ | å¼±ï¼ˆéœ€äººå·¥è®¾å®šè°±åŒºé—´ï¼‰ | ä¸­ç­‰ï¼ˆæœç´¢æœ‰é™æ¨¡æ¿ï¼‰ | **å¼ºï¼ˆä»è°±æ¢é’ˆåŠ¨æ€ç”Ÿæˆï¼‰** |
| å¯æ‰©å±•æ€§ | é«˜ï¼ˆä½å­˜å‚¨ï¼‰ | ä½ï¼ˆæœç´¢æˆæœ¬é«˜ï¼‰ | **é«˜ï¼ˆä¸€æ¬¡è®­ç»ƒï¼Œå¹¿æ³›é€‚ç”¨ï¼‰** |
| æ€§èƒ½ | ç†è®ºæœ€ä¼˜ä½†å®è·µå—é™ | ä¸ç¨³å®š | **å®è¯æ˜¾è‘—ä¼˜äºåŸºçº¿** |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **è®­ç»ƒæ•°æ®**ï¼šåˆæˆå¯¹è§’çŸ©é˜µï¼ˆ$ X = \text{diag}(\lambda) $ï¼‰ï¼Œé€šè¿‡æ§åˆ¶è°±å½¢çŠ¶ï¼ˆå¹‚å¾‹è¡°å‡ã€æŒ‡æ•°è¡°å‡ã€å¹³å¦è°±ç­‰ï¼‰ç”Ÿæˆå¤šæ ·åŒ–çš„è°±åˆ†å¸ƒã€‚
  - ç‰¹å¾å€¼ç»´åº¦ï¼š$ n \in [50, 1000] $
  - æ¡ä»¶æ•°èŒƒå›´ï¼š$ \kappa \in [10^2, 10^5] $
- **æµ‹è¯•æ•°æ®**ï¼šæ¥è‡ª **SuiteSparse Matrix Collection** çš„çœŸå®ä¸–ç•Œç¨€ç–çŸ©é˜µï¼Œæ¶µç›–ï¼š
  - ç”µå­ç»“æ„ï¼ˆSi02ï¼‰
  - çƒ­åŠ›å­¦æœ‰é™å…ƒï¼ˆthermal1, thermal2ï¼‰
  - ç”µè·¯å»ºæ¨¡ï¼ˆG2_circuit, G3_circuitï¼‰
  - ç»“æ„åŠ›å­¦é—®é¢˜
  - å°ºå¯¸é«˜è¾¾ $ 1.6 \times 10^6 $

æ­¤å¤–è¿˜åŒ…æ‹¬ä¸€ä¸ª DNA åºåˆ—ç›¸ä¼¼æ€§ Gram çŸ©é˜µç”¨äºåæ–¹å·®ç™½åŒ–ä»»åŠ¡ã€‚

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **ä¸‰å¤§ä»»åŠ¡è®¾ç½®**ï¼š

| ä»»åŠ¡ | ç›®æ ‡ | è¾“å…¥è°±æ¢é’ˆ | è¾“å‡º |
|------|------|-------------|-------|
| **ç‰¹å¾å€¼è®¡ç®—** | åŠ é€Ÿ `eigs` æ”¶æ•› | å‰ $ k $ å’Œé™„è¿‘ç‰¹å¾å€¼ + æ®‹å·® | è°±å˜æ¢å¤šé¡¹å¼ $ P(X) $ |
| **çº¿æ€§ç³»ç»Ÿæ±‚è§£** | åŠ é€Ÿ CG æ”¶æ•› | æœ€å¤§/æœ€å° 20 ä¸ªç‰¹å¾å€¼ + æ®‹å·® | å¤šé¡¹å¼é¢„æ¡ä»¶å™¨ $ P(X) $ |
| **çŸ©é˜µå‡½æ•°é€¼è¿‘** | è¿‘ä¼¼ $ X^{-1/2} $ | åŒå·¦ | å¤šé¡¹å¼é€¼è¿‘ $ P(X) \approx X^{-1/2} $ |

#### **è¯„ä¼°æŒ‡æ ‡**
- **æ”¶æ•›é€Ÿåº¦æå‡**ï¼šè¾¾åˆ°æŒ‡å®šç²¾åº¦æ‰€éœ€çš„è¿­ä»£æ¬¡æ•°ï¼ˆouter iterationsï¼‰
- **æ¡ä»¶æ•°æ”¹å–„**ï¼š$ \kappa(P(X)X) $
- **ç›¸å¯¹æ€§èƒ½å¢ç›Š**ï¼šä½¿ç”¨å¯¹æ•°å°ºåº¦æ¯”ç‡è¡¡é‡ï¼š
  $$
  \rho_{\log} = \frac{\log T_{\text{baseline}}}{\log T_{\text{model}}}
  $$
- **è¿‘ä¼¼è¯¯å·®**ï¼š$ \|P(X)X^{1/2} - I\| $ æˆ– $ \|P(X)XP(X) - I\| $

#### **è°±æ¢é’ˆè·å–æ–¹å¼**
- ç‰¹å¾å€¼ä»»åŠ¡ï¼šè¿è¡Œ 20 æ­¥ `eigs`ï¼ˆKrylov-Schurï¼‰
- çº¿æ€§ç³»ç»Ÿï¼š50 æ­¥ Lanczosï¼ˆä¸å­˜åŸºåº•ï¼‰

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ä»»åŠ¡ | åŸºçº¿æ–¹æ³• |
|------|---------|
| ç‰¹å¾å€¼ | å¹‚è¿­ä»£ï¼ˆPower iteration, $ P(X) = X^d $ï¼‰ |
| çº¿æ€§ç³»ç»Ÿ | Richardson è¿­ä»£ã€ç»å…¸ Chebyshev é¢„æ¡ä»¶å™¨ |
| çŸ©é˜µå‡½æ•° | æˆªæ–­ Neumann çº§æ•°ï¼ˆTaylor å±•å¼€ï¼‰ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **ç‰¹å¾å€¼é—®é¢˜ï¼ˆTable 3b & Figure 9ï¼‰**
| çŸ©é˜µ | AUToSPEC ($ k=10 $) | Power Method ($ k=10 $) | æå‡å€æ•° |
|------|------------------------|----------------------------|----------|
| Si02 | 23 | >500 | **>20x** |
| CO | 55 | >500 | **>9x** |
| thermal2 | 21 | 112 | **~5x** |

> æ‰€æœ‰æƒ…å†µä¸‹å‡æ˜¾è‘—å‡å°‘ `eigs` å¤–å±‚è¿­ä»£æ¬¡æ•°ã€‚

#### âœ… **çº¿æ€§ç³»ç»Ÿï¼ˆTable 3a & Figure 3ï¼‰**
| çŸ©é˜µ | æ— é¢„æ¡ä»¶ | Chebyshev | **AUToSPEC** |
|------|-----------|------------|---------------|
| G2_circuit | 734 | 79 | **70** |
| thermal2 | >5000 | 658 | **705** |
| Flan_1565 | 3868 | 374 | **375** |

> åœ¨å¤šæ•°æƒ…å†µä¸‹ï¼Œ**AUToSPEC ä¸ Chebyshev ç›¸å½“ç”šè‡³æ›´ä¼˜**ï¼Œå°¤å…¶åœ¨å¤æ‚è°±ç»“æ„ä¸‹è¡¨ç°ç¨³å¥ã€‚

#### âœ… **çŸ©é˜µå‡½æ•°é€¼è¿‘ï¼ˆFigure 4ï¼‰**
- åœ¨ DNA åæ–¹å·®ç™½åŒ–ä»»åŠ¡ä¸­ï¼Œ**AUToSPEC æ¯” Neumann çº§æ•°é™ä½ä¸€ä¸ªæ•°é‡çº§çš„ operator-norm è¯¯å·®**ã€‚
- ç™½åŒ–è´¨é‡æ›´é«˜ï¼Œä¸”ä»…éœ€ matvec æ“ä½œï¼Œé€‚åˆå¤§è§„æ¨¡ç¨€ç–åœºæ™¯ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ğŸ”¹ **æ®‹å·®ä¿¡æ¯çš„é‡è¦æ€§ï¼ˆFigure 5 & 13ï¼‰**
- å½“ç§»é™¤æ®‹å·®ï¼ˆresidual normsï¼‰ä½œä¸ºè¾“å…¥æ—¶ï¼Œç®—æ³•æ€§èƒ½æ˜æ˜¾ä¸‹é™ï¼Œå°¤å…¶æ˜¯åœ¨è°±æ¢é’ˆè´¨é‡è¾ƒä½æ—¶ã€‚
- è¡¨æ˜**æ®‹å·®æä¾›äº†å…³äºè°±ä¼°è®¡å¯é æ€§çš„å…³é”®ä¿¡å·**ï¼Œå¸®åŠ©æ¨¡å‹åˆ¤æ–­å¦‚ä½•åŠ æƒä¸åŒé¢‘æ®µã€‚

#### ğŸ”¹ **å¯¹è°±è¾“å…¥æ‰°åŠ¨çš„é²æ£’æ€§ï¼ˆFigure 10ï¼‰**
- å³ä½¿ä½¿ç”¨ä»… 50 æ­¥ Lanczos å¾—åˆ°çš„ç²—ç³™è°±ä¼°è®¡ï¼ŒAUToSPEC ä»èƒ½ç¨³å®šè¾“å‡ºé«˜æ€§èƒ½é¢„æ¡ä»¶å™¨ã€‚
- å½“ Lanczos æ­¥æ•°è¶…è¿‡ 75 åï¼ŒCG è¿­ä»£æ•°è¶‹äºç¨³å®šï¼Œè¯´æ˜æ–¹æ³•å…·æœ‰è‰¯å¥½çš„**è¾“å…¥é²æ£’æ€§**ã€‚

#### ğŸ”¹ **ä¸ Chebyshev çš„æ¯”è¾ƒï¼ˆTable 4ï¼‰**
- AUToSPEC åœ¨å¤šä¸ªçŸ©é˜µä¸Š**è¶…è¶Šæˆ–åŒ¹é… Chebyshev è¡¨ç°**ï¼Œä¸”å¯¹è°±ä¼°è®¡è¯¯å·®æ›´é²æ£’ã€‚
- ç‰¹åˆ«æ˜¯åœ¨ `gyro_m` ä¸Šï¼ŒChebyshev é€€åŒ–ä¸¥é‡ï¼ˆ141 vs 27ï¼‰ï¼Œè€Œ AUToSPEC ä¿æŒé«˜æ•ˆã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **AUToSPEC èƒ½æœ‰æ•ˆå‘ç°é«˜æ€§èƒ½çš„è¿­ä»£è°±ç®—æ³•**ï¼Œåœ¨çœŸå®ä¸–ç•ŒçŸ©é˜µä¸Šå®ç°**æ•°é‡çº§çš„åŠ é€Ÿ**ã€‚
2. å­¦åˆ°çš„å¤šé¡¹å¼è¡¨ç°å‡º**ç±» Chebyshev ç‰¹æ€§**ï¼ˆnear-equiripple, near-minimaxï¼‰ï¼Œå°½ç®¡æœªæ˜¾å¼ç¼–ç è¯¥å…ˆéªŒã€‚
   - å¦‚ Table 1 æ‰€ç¤ºï¼Œå…¶ minimax optimality gap æ¥è¿‘ç†è®ºæœ€ä¼˜ï¼Œè¿œä¼˜äºéšæœºå¤šé¡¹å¼ã€‚
3. æ–¹æ³•å…·å¤‡**å¼ºæ³›åŒ–èƒ½åŠ›**ï¼šä»å°åˆæˆçŸ©é˜µè®­ç»ƒ â†’ å¤§çœŸå®çŸ©é˜µéƒ¨ç½²ã€‚
4. **æ®‹å·®ä¿¡æ¯æ˜¯å…³é”®è¾“å…¥ç‰¹å¾**ï¼Œæå‡äº†ç®—æ³•åœ¨ä½è´¨é‡è°±ä¼°è®¡ä¸‹çš„é²æ£’æ€§å’Œæœ‰æ•ˆæ€§ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- å½“å‰ç‰ˆæœ¬ä¸»è¦åŸºäº**çº¿æ€§çŠ¶æ€è½¬ç§»**ï¼Œè¡¨è¾¾èƒ½åŠ›å—é™ã€‚
- å¯¹æç«¯ç—…æ€çŸ©é˜µï¼ˆ$\kappa > 10^7$ï¼‰æ•ˆæœå¯èƒ½å—é™ï¼Œéœ€ç»“åˆå…¶ä»–é¢„å¤„ç†ï¼ˆå¦‚ icholï¼‰ã€‚
- æ¨ç†é˜¶æ®µä»éœ€ä¸€æ¬¡è°±æ¢é’ˆï¼ˆwarm-startï¼‰ï¼Œæ— æ³•å®Œå…¨â€œé›¶æ ·æœ¬â€è¿è¡Œã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•è‡³**æœ‰ç†å‡½æ•°é€¼è¿‘**ï¼ˆrational filtersï¼‰ï¼Œä»¥æ›´å¥½å¤„ç†å°–é”è°±å˜åŒ–ï¼ˆå¦‚ interior eigenvaluesï¼‰ã€‚
- æ¢ç´¢**éçº¿æ€§çŠ¶æ€è½¬ç§»**å’Œ**é«˜é˜¶é€’æ¨**ï¼Œå¢å¼ºè¡¨è¾¾åŠ›ã€‚
- å°†æ¡†æ¶åº”ç”¨äº**first-order optimization**ï¼ˆå¦‚ learning gradient descent with momentumï¼‰ã€‚
- ç»“åˆ LLM è¿›è¡Œ**å¯è§£é‡Šæ€§æŒ–æ˜**ï¼Œå°è¯•ä»å­¦åˆ°çš„ç³»æ•°ä¸­åæ¨è§£æå…¬å¼ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> AUToSPEC æˆåŠŸå°†ç¥ç»ç½‘ç»œå»ºæ¨¡ä¸ºâ€œå¯ç¼–ç¨‹çš„æ•°å€¼ç®—æ³•å¼•æ“â€ï¼Œå®ç°äº†ä»è°±æ¢é’ˆåˆ°é«˜æ€§èƒ½è¿­ä»£ç®—æ³•çš„ç«¯åˆ°ç«¯ç”Ÿæˆï¼Œåœ¨å¤šä¸ª NLA ä»»åŠ¡ä¸Šå±•ç°å‡ºè¶…è¶Šç»å…¸æ–¹æ³•çš„æ½œåŠ›ï¼Œä¸º ML for Scientific Computing å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚

</details>

---

### 11. [SCOUT-RAG: Scalable and Cost-Efficient Unifying Traversal for Agentic Graph-RAG over Distributed Domains](https://arxiv.org/abs/2602.08400)

**Authors**: Longkun Li, Yuanben Zou, Jinghan Wu, Yuqing Wen, Jing Li, Hangwei Qian, Ivor Tsang  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.08400v1  

#### Abstract
Graph-RAG improves LLM reasoning using structured knowledge, yet conventional designs rely on a centralized knowledge graph. In distributed and access-restricted settings (e.g., hospitals or multinational organizations), retrieval must select relevant domains and appropriate traversal depth without ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# SCOUT-RAG è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
æœ¬æ–‡é’ˆå¯¹ **åˆ†å¸ƒå¼ç¯å¢ƒä¸‹çš„ Graph-RAG**ï¼ˆGraph Retrieval-Augmented Generationï¼‰ç³»ç»Ÿé¢ä¸´çš„å…³é”®æŒ‘æˆ˜æå‡ºè§£å†³æ–¹æ¡ˆï¼Œå…·ä½“åŒ…æ‹¬ï¼š

- **æ•°æ®å­¤å²›ä¸éšç§é™åˆ¶**ï¼šåœ¨åŒ»é™¢ã€è·¨å›½ç»„ç»‡ç­‰åœºæ™¯ä¸­ï¼ŒçŸ¥è¯†å›¾è°±åˆ†å¸ƒåœ¨å¤šä¸ªç‹¬ç«‹åŸŸï¼ˆdomainsï¼‰ï¼Œæ— æ³•é›†ä¸­å…±äº«åŸå§‹æ•°æ®ã€‚
- **ç¼ºä¹å…¨å±€å¯è§æ€§**ï¼šä¼ ç»Ÿ Graph-RAG ä¾èµ–ç»Ÿä¸€çš„å…¨å±€çŸ¥è¯†å›¾ï¼Œè€Œç°å®ä¸­å„ domain æ˜¯éƒ¨åˆ†å¯è§‚æµ‹çš„ã€‚
- **æ£€ç´¢æˆæœ¬é«˜æ˜‚**ï¼šè·¨åŸŸè¯·æ±‚å¯èƒ½å¸¦æ¥å»¶è¿Ÿæˆ– API è´¹ç”¨ï¼Œéœ€æœ€å°åŒ–ä¸å¿…è¦çš„æŸ¥è¯¢ã€‚
- **å†·å¯åŠ¨ä¸æ ‡ç­¾ç¼ºå¤±**ï¼šç›‘ç£å¼ domain router éœ€è¦æ ‡æ³¨æ•°æ®ï¼Œåœ¨æ–°éƒ¨ç½²åœºæ™¯ä¸‹ä¸å¯è¡Œã€‚

å› æ­¤ï¼Œå¦‚ä½•åœ¨ **æ— å…¨å±€å›¾å¯è§ã€æœ‰æˆæœ¬çº¦æŸã€ä¿æŠ¤éšç§çš„å‰æä¸‹**ï¼Œå®ç°é«˜æ•ˆã€é«˜è´¨é‡çš„å¤šè·³æ¨ç†æˆä¸ºæ ¸å¿ƒéš¾é¢˜ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡ºäº† **SCOUT-RAG** â€”â€” ä¸€ç§åˆ†å±‚çš„ã€åŸºäºæ™ºèƒ½ä½“ï¼ˆagenticï¼‰æ¶æ„çš„åˆ†å¸ƒå¼ Graph-RAG æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ£€ç´¢å»ºæ¨¡ä¸ºä¸€ä¸ª**åºåˆ—å†³ç­–è¿‡ç¨‹**ï¼Œé€šè¿‡å››ä¸ªåä½œ agent å®ç°æ¸è¿›å¼ã€è‡ªé€‚åº”çš„è·¨åŸŸæ£€ç´¢ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
1. **è®­ç»ƒæ— å…³çš„ domain relevance ä¼°è®¡ï¼ˆTraining-Free Domain Relevance Estimationï¼‰**
   - åˆ©ç”¨ä¸‰ç§ä¿¡å·è¿›è¡Œé›¶æ ·æœ¬ relevance æ’åºï¼š
     - `Semantic similarity`ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰
     - `Knowledge richness`ï¼ˆçŸ¥è¯†ä¸°å¯Œåº¦ï¼Œå¦‚æŠ¥å‘Šæ•°é‡ï¼‰
     - `Historical performance`ï¼ˆå†å²é—®ç­”è´¨é‡ï¼‰
   - æ”¯æŒå†·å¯åŠ¨éƒ¨ç½²ï¼Œæ— éœ€æ ‡æ³¨ query-domain å¯¹ã€‚

2. **å»ä¸­å¿ƒåŒ–çš„ Graph-RAG æ¶æ„è®¾è®¡**
   - å°†æ¯ä¸ª domain è§†ä¸ºä¸€ä¸ªå±€éƒ¨å¯è§‚å¯Ÿå­å›¾ï¼ˆpartially observable subgraphï¼‰ã€‚
   - åŠ¨æ€å†³å®šæ˜¯å¦åœ¨å½“å‰ domain å†…æ·±å…¥éå†ï¼ˆdepthï¼‰ï¼Œè¿˜æ˜¯æ‰©å±•åˆ°å…¶ä»– domainï¼ˆbreadthï¼‰ã€‚

3. **é—­ç¯è¿­ä»£ä¼˜åŒ–æœºåˆ¶**
   - å¼•å…¥ Answer Quality Assessment Agentï¼ˆAQAAï¼‰æŒç»­ç›‘æ§ç­”æ¡ˆå®Œæ•´æ€§ä¸è¦†ç›–å¹¿åº¦ã€‚
   - åŸºäºåé¦ˆåŠ¨æ€é€‰æ‹© refinement ç­–ç•¥ï¼ˆDepth / Breadth / Hybrid / Stopï¼‰ã€‚

4. **å¤šçº§å®‰å…¨æœºåˆ¶ä¿éšœç¨³å®šæ€§**
   - æ—¶é—´é¢„ç®—å¼ºåˆ¶ç»ˆæ­¢ï¼ˆtime-budget enforcementï¼‰
   - æœ€ä½³ç­”æ¡ˆè¿½è¸ªï¼ˆbest-answer trackingï¼‰
   - å¹¶è¡Œåè°ƒæ‰§è¡Œï¼ˆcoordinated parallelismï¼‰
   - é˜²æ­¢å› æŸ domain å»¶è¿Ÿå¯¼è‡´æ•´ä½“å¤±è´¥ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **éšç§å‹å¥½æ€§** | ä¸è¦æ±‚æ•°æ®é›†ä¸­åŒ–ï¼Œç¬¦åˆè”é‚¦å­¦ä¹ èŒƒå¼ |
| **æˆæœ¬æ•ˆç‡** | æ˜¾è‘—å‡å°‘ cross-domain calls å’Œ token æ¶ˆè€— |
| **é€‚åº”æ€§å¼º** | å¯å¤„ç†å†·å¯åŠ¨ã€åŠ¨æ€å˜åŒ–çš„ domain æ•ˆç”¨ |
| **å¯æ§æ€§é«˜** | æ˜¾å¼æ§åˆ¶è´¨é‡-æˆæœ¬æƒè¡¡ï¼Œæ”¯æŒ early stopping |

ç›¸æ¯” DRIFT ç­‰ centralized æ–¹æ³•ï¼ŒSCOUT-RAG åœ¨ä¿æŒæ¥è¿‘æ€§èƒ½çš„åŒæ—¶å¤§å¹…é™ä½æˆæœ¬ï¼›ç›¸æ¯” exhaustive decentralized æ–¹æ³•ï¼Œåˆ™å®ç°äº†æ›´é«˜çš„æ€§ä»·æ¯”ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- **æ¨¡æ‹Ÿå¤šåŸŸæ•°æ®é›†**ï¼šåŸºäº **Wikipedia çš„ 45 ä¸ªå›½å®¶é¡µé¢**æ„å»º domain-specific knowledge graphsã€‚
  - æ¯ä¸ª domain åŒ…å« 9â€“77 ä¸ª community reportsï¼ˆç¤¾åŒºæ‘˜è¦ï¼‰ï¼Œå½¢æˆç»“æ„åŒ–çŸ¥è¯†å›¾ã€‚
- **äººå·¥æ„é€ æŸ¥è¯¢é›†**ï¼šå…±ç”Ÿæˆ 100 ä¸ªè‡ªç„¶è¯­è¨€ queryï¼Œå…¶ä¸­ 89 ä¸ªè¢«æœ‰æ•ˆå›ç­”ã€‚
  - æŸ¥è¯¢æŒ‰æ¶‰åŠ domain æ•°é‡åˆ†ä¸ºäº”ç±»ï¼š
    - å•åŸŸï¼ˆ1 countryï¼‰
    - å°è§„æ¨¡å¤šåŸŸï¼ˆ5 countriesï¼‰
    - ä¸­ç­‰è§„æ¨¡ï¼ˆ10ï¼‰
    - å¤§è§„æ¨¡ï¼ˆ20ï¼‰
    - è¶…å¤§è§„æ¨¡ï¼ˆ40ï¼‰

---

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### å®éªŒå¹³å°é…ç½®
- GPU: NVIDIA RTX 3070 (9GB VRAM)
- CPU: 16 vCPUs (AMD EPYC 7B12), 31GB RAM

#### è¯„ä¼°ç»´åº¦ï¼ˆç”± GPT-4o ä½œä¸º judge æ‰“åˆ†ï¼Œ0â€“100 åˆ†åˆ¶ï¼‰
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Comprehensiveness (Comp.)** | å›ç­”æ¶µç›–ç›¸å…³æ–¹é¢çš„å®Œæ•´ç¨‹åº¦ |
| **Diversity (Div.)** | æ¥æºè§†è§’å’Œä¿¡æ¯æ¥æºçš„å¤šæ ·æ€§ |
| **Empowerment (Emp.)** | æ˜¯å¦æä¾›å¯æ“ä½œæ´å¯Ÿï¼Œæ”¯æŒåç»­æ¢ç´¢ |
| **Directness (Dir.)** | è¡¨è¾¾ç®€æ´æ¸…æ™°ï¼Œé¿å…å†—ä½™ |
| **Overall Quality** | ä¸Šè¿°å››é¡¹å¹³å‡å¾—åˆ† |

#### æˆæœ¬æŒ‡æ ‡
- **Time (s)**ï¼šç«¯åˆ°ç«¯å“åº”æ—¶é—´ï¼ˆç§’ï¼‰
- **Token Count**ï¼šæ€»å¤„ç† token æ•°ï¼ˆè¾“å…¥ + è¾“å‡ºï¼‰

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

åˆ†ä¸ºä¸¤ç±»éƒ¨ç½²æ¨¡å¼ï¼š

#### âœ… Centralized Baselinesï¼ˆæ‰€æœ‰æ•°æ®åˆå¹¶ä¸ºå•ä¸€ domainï¼‰
| æ–¹æ³• | æè¿° |
|------|------|
| **GraphRAGLocal** | å±€éƒ¨æ£€ç´¢ï¼Œèšç„¦å®ä½“çº§ç»†èŠ‚ |
| **GraphRAGGlobal** | å…¨å±€æ£€ç´¢ï¼Œè·å–å±‚æ¬¡åŒ–æ¦‚è§ˆ |
| **GraphRAGDRIFT-c** | å…¨å±€åˆæ£€ + ä¸¤è½®æœ¬åœ° refineï¼ˆæ¯è½® 3 æ¬¡ follow-upï¼‰|

#### âœ… Decentralized Baselinesï¼ˆæ•°æ®åˆ†å¸ƒäº 45 ä¸ªç‹¬ç«‹ domainï¼‰
| æ–¹æ³• | æè¿° |
|------|------|
| **GraphRAGDRIFT-dec** | æ¯ä¸ª domain ç‹¬ç«‹è¿è¡Œ DRIFTï¼ˆå…¨å±€+ä¸¤æ¬¡ refineï¼‰ï¼Œæœ€åèåˆç­”æ¡ˆ |

> âš ï¸ æ³¨æ„ï¼šSCOUT-RAG æ˜¯å”¯ä¸€ä¸“ä¸º **distributed + agentic + cost-aware** è®¾è®¡çš„æ–¹æ³•ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| Method | Comp. | Div. | Emp. | Dir. | **Overall** | Time (s) | Token |
|--------|-------|------|------|------|------------|----------|--------|
| GraphRAGLocal | 65 | 55 | 35 | 58 | 53 | 34.40 | 11,223 |
| GraphRAGGlobal | 60 | 50 | 30 | 55 | 49 | 45.89 | 640,574 |
| GraphRAGDRIFT-c | 72 | 70 | 45 | 63 | **63** | 231.85 | 693,731 |
| GraphRAGDRIFT-dec | 90 | 88 | 75 | 88 | **85** | 414.88 | 879,911 |
| **SCOUT-RAG (Ours)** | 65 | 60 | 40 | 58 | **56** | **75.32** | **159,169** |

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ğŸ“ˆ æ€§èƒ½æ–¹é¢
- SCOUT-RAG çš„ overall quality è¾¾åˆ° **56**ï¼Œè™½ä½äº GraphRAGDRIFT-decï¼ˆ85ï¼‰ï¼Œä½†æ˜¾è‘—ä¼˜äºå¤§å¤šæ•° centralized æ–¹æ³•ï¼ˆå¦‚ GraphRAGGlobal çš„ 49ï¼‰ã€‚
- ä¸ centralized DRIFTï¼ˆ63ï¼‰ç›¸æ¯”ä»…ä½ 7 åˆ†ï¼Œä½†åœ¨åˆ†å¸ƒå¼æ¶æ„ä¸‹å·²å±ä¼˜å¼‚è¡¨ç°ã€‚

#### ğŸ’° æˆæœ¬æ•ˆç‡æ–¹é¢ï¼ˆæœ€å¤§äº®ç‚¹ï¼‰
- **ç›¸æ¯” GraphRAGDRIFT-dec**ï¼š
  - å‡å°‘ **81.8% æ—¶é—´**ï¼ˆ75.32s vs 414.88sï¼‰
  - å‡å°‘ **81.9% token æ¶ˆè€—**ï¼ˆ159k vs 879kï¼‰
- **ç›¸æ¯” GraphRAGDRIFT-c**ï¼š
  - æ—¶é—´å¿« **3.1x**
  - Token å°‘ **4.4x**
- åœ¨ **very large multi-domain queriesï¼ˆ40 domainsï¼‰** ä¸‹ä»ä¿æŒç¨³å®šå“åº”ã€‚

#### ğŸ” å¤šæ ·æ€§ä¼˜åŠ¿
- SCOUT-RAG åœ¨ **Diversityï¼ˆ60ï¼‰** ä¸Šè¶…è¿‡æ‰€æœ‰ centralized baselineï¼ˆæœ€é«˜ä»… 70ï¼‰ï¼Œè¯´æ˜å…¶èƒ½æ›´ç³»ç»Ÿåœ°æ•´åˆå¤šå…ƒè§‚ç‚¹ã€‚

---

### æ¶ˆèå®éªŒä¸æ¡ˆä¾‹åˆ†æï¼ˆè§ Figure 4ï¼‰

#### Case Studyï¼šâ€œMade in Italyâ€ è®¤è¯å¯¹æ—¶å°šäº§ä¸š SME çš„å½±å“
- **Stage I**ï¼šå‡†ç¡®è¯†åˆ«å‡º Italyï¼ˆ0.539ï¼‰ã€Sloveniaï¼ˆ0.384ï¼‰ã€Maltaï¼ˆ0.342ï¼‰ç­‰é«˜ç›¸å…³ domainã€‚
- **Stage II**ï¼šåˆæ­¥åˆæˆå›ç­”ï¼Œä½†ç¼ºå°‘æ”¿ç­–ç»†èŠ‚ä¸å›½é™…æ¯”è¾ƒã€‚
- **Stage III**ï¼š
  - ç¬¬ä¸€è½® Depth refinement æå‡ completeness è‡³ 0.75ã€‚
  - ç¬¬äºŒè½®è¾¾åˆ°æœ€é«˜è´¨é‡ **0.725**ã€‚
  - ç¬¬ä¸‰è½®å°è¯• Breadth æ‰©å±• POTENTIAL domainsï¼Œåè€Œå¼•å…¥å™ªå£°ï¼Œè´¨é‡ä¸‹é™è‡³ 0.675ã€‚
- âœ… **Best-answer tracking æœºåˆ¶æˆåŠŸä¿ç•™æœ€ä¼˜ç‰ˆæœ¬**ï¼Œé˜²æ­¢é€€åŒ–ã€‚

> ç»“è®ºï¼šè¿­ä»£ refinement + best-track æ˜¯å…³é”®è®¾è®¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **SCOUT-RAG å®ç°äº†æ€§èƒ½ä¸æˆæœ¬ä¹‹é—´çš„é«˜æ•ˆå¹³è¡¡**ï¼š
   - åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹ï¼Œä»¥ä¸åˆ° 1/5 çš„èµ„æºæ¶ˆè€—ï¼Œè¾¾åˆ°äº†æ¥è¿‘ centralized DRIFT çš„æ•ˆæœã€‚
2. **agent-based æ¶æ„é€‚åˆå¤æ‚ã€å—é™çš„ retrieval åœºæ™¯**ï¼š
   - åºåˆ—å†³ç­– + utility estimation ä½¿ç³»ç»Ÿå…·å¤‡â€œè®¤çŸ¥å¯¼èˆªâ€èƒ½åŠ›ã€‚
3. **zero-shot domain relevance estimation å¯è¡Œä¸”æœ‰æ•ˆ**ï¼š
   - ç»“åˆ semanticã€historicalã€richness ä¿¡å·å¯åœ¨æ— ç›‘ç£æƒ…å†µä¸‹å®ç°åˆç†æ’åºã€‚
4. **iterative refinement + best-answer tracking æå‡é²æ£’æ€§**ï¼š
   - å³ä½¿æŸäº› retrieval æ­¥éª¤å¤±è´¥æˆ–å¼•å…¥å™ªå£°ï¼Œä¹Ÿèƒ½ä¿è¯æœ€ç»ˆè¾“å‡ºä¸åŠ£åŒ–ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ– domain-level metadata**ï¼š
   - å¦‚ historical performance å’Œ knowledge richness éœ€è¦ä¸€å®šå†å²ç§¯ç´¯ï¼Œæç«¯å†·å¯åŠ¨æ—¶å¯èƒ½ä¸å‡†ã€‚
2. **æœªè€ƒè™‘ domain é—´è¯­ä¹‰é‡å æˆ–å†²çª**ï¼š
   - å¤šä¸ª domain è¿”å›çŸ›ç›¾ä¿¡æ¯æ—¶ï¼Œfusion logic å¯èƒ½ä¸è¶³ã€‚
3. **parallel execution å—æœ€æ…¢ domain å½±å“**ï¼š
   - å°½ç®¡æœ‰å¹¶è¡Œæœºåˆ¶ï¼Œä½†æ•´ä½“å»¶è¿Ÿä»å—åˆ¶äºå“åº”æœ€æ…¢çš„ domainã€‚
4. **evaluation ä¾èµ– LLM-as-a-judgeï¼ˆGPT-4oï¼‰**ï¼š
   - å­˜åœ¨ä¸»è§‚åå·®é£é™©ï¼Œéœ€è¿›ä¸€æ­¥ human evaluation éªŒè¯ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼•å…¥ reinforcement learning ä¼˜åŒ–ç­–ç•¥é€‰æ‹©**ï¼š
   - å½“å‰ strategy selection åŸºäºå¯å‘å¼è§„åˆ™ï¼Œå¯ç”¨ RL è¿›ä¸€æ­¥è‡ªåŠ¨åŒ–ã€‚
2. **å¢å¼º conflict resolution ä¸è¯æ®åŠ æƒæœºåˆ¶**ï¼š
   - å¯¹ä¸åŒ domain çš„å¯ä¿¡åº¦å»ºæ¨¡ï¼Œæå‡ answer consistencyã€‚
3. **æ”¯æŒ streaming domain åŠ å…¥/é€€å‡º**ï¼š
   - å®ç° truly dynamic federationã€‚
4. **æ‰©å±•è‡³éæ–‡æœ¬æ¨¡æ€ knowledge graphs**ï¼š
   - å¦‚å›¾åƒã€ä¼ æ„Ÿå™¨æ•°æ®ç­‰ multi-modal distributed domainsã€‚

---

## æ€»ç»“

âœ… **SCOUT-RAG æ˜¯é¦–ä¸ªå°† agentic AI æˆåŠŸåº”ç”¨äºåˆ†å¸ƒå¼ Graph-RAG çš„æ¡†æ¶**ï¼Œåœ¨ **privacy-preservingã€cost-awareã€scalable retrieval** æ–¹é¢æ ‘ç«‹äº†æ–°æ ‡æ†ã€‚  
ğŸ¯ å®ƒè¯æ˜äº†ï¼šå³ä½¿æ²¡æœ‰å…¨å±€çŸ¥è¯†å›¾ï¼Œä¹Ÿèƒ½é€šè¿‡æ™ºèƒ½ agent åä½œå®ç°æ¥è¿‘ centralized ç³»ç»Ÿçš„è´¨é‡ï¼ŒåŒæ—¶èŠ‚çœè¶… 80% çš„èµ„æºå¼€é”€ã€‚  
ğŸš€ è¯¥å·¥ä½œä¸ºåŒ»ç–—ã€é‡‘èã€æ”¿åºœç­‰é«˜æ•æ„Ÿé¢†åŸŸçš„ RAG åº”ç”¨æä¾›äº†å¯è¡Œè·¯å¾„ï¼Œæ¨åŠ¨ Graph-RAG å‘çœŸå®ä¸–ç•Œè½åœ°è¿ˆè¿›ä¸€å¤§æ­¥ã€‚

</details>

---

### 12. [Revealing the Challenges of Attention-FFN Disaggregation for Modern MoE Models and Hardware Systems](https://arxiv.org/abs/2602.09721)

**Authors**: Guowei Liu, Hongming Li, Yaning Guo, Yongxi Lyu, Mo Zhou, Yi Liu, Zhaogeng Li, Yanpeng Wang  
**Category**: cs.DC  
**Published**: 2026-02-11  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.09721v1  

#### Abstract
Deploying large-scale MoE models presents challenges in memory capacity and bandwidth for expert activation. While Attention-FFN Disaggregation (AFD) has emerged as a potential architecture to decouple compute and memory resources, its performance boundaries compared to standard large-scale Expert P...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRevealing the Challenges of Attention-FFN Disaggregation for Modern MoE Models and Hardware Systems

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬è®ºæ–‡ç³»ç»Ÿæ€§åœ°åˆ†æäº† **Attention-FFN Disaggregation (AFD)** åœ¨ç°ä»£å¤§è§„æ¨¡ **MoE (Mixture-of-Experts)** æ¨¡å‹éƒ¨ç½²ä¸­çš„å®é™…æ€§èƒ½è¾¹ç•Œä¸æŒ‘æˆ˜ã€‚å°½ç®¡ AFD è¢«ä¸šç•Œè§†ä¸ºæå‡è®¡ç®—æ•ˆç‡çš„â€œçµä¸¹å¦™è¯â€ï¼Œä½†å…¶åœ¨çœŸå®ç¡¬ä»¶ç³»ç»Ÿä¸Šçš„æœ‰æ•ˆæ€§å°šæœªè¢«æ·±å…¥é‡åŒ–ã€‚

å…·ä½“è€Œè¨€ï¼Œè®ºæ–‡æ­ç¤ºäº†ä»¥ä¸‹æœªè¢«å……åˆ†ç ”ç©¶çš„é—®é¢˜ï¼š
- AFD æ˜¯å¦çœŸçš„èƒ½æå‡ **Hardware FLOPS Utilization (HFU)**ï¼Ÿ
- åœ¨æ ‡å‡†é›†ç¾¤ï¼ˆå¦‚åŸºäº H800ï¼‰ä¸Šï¼ŒAFD æ˜¯å¦å—é™äºé€šä¿¡ç“¶é¢ˆï¼Ÿ
- AFD å¯¹ **DP imbalance** å’Œ **EP imbalance** çš„å®¹å¿åº¦å¦‚ä½•ï¼Ÿ

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
è®ºæ–‡æå‡ºäº†ä¸€ä¸ª**åŸºäºå»¶è¿Ÿé¢„ç®—çš„ HFU ä¸Šç•Œåˆ†ææ¡†æ¶**ï¼Œå¹¶å°†å…¶æ‰©å±•è‡³é€šä¿¡å±‚é¢çš„ **roofline model**ï¼Œç”¨äºå»ºæ¨¡ AFD çš„ç†è®ºæ€§èƒ½æé™ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š
1. **Budget-based HFU Upper-Bound åˆ†ææ³•**
   - å°† SLOï¼ˆService-Level Objectiveï¼‰è½¬åŒ–ä¸ºæ¯é˜¶æ®µçš„ latency budget `tB`ã€‚
   - æ¨å¯¼å‡º AFD ä¸­ attention (`ta`)ã€FFN (`tf`) å’Œé€šä¿¡ (`tc`) çš„ç†æƒ³å‡è¡¡æ¡ä»¶ï¼š
     ```
     2Ã—ta â‰¥ tf + tc  
     2Ã—tf â‰¥ ta + tc  
     ta, tf, tc â‰¤ tB
     ```
   - æ­ç¤ºäº† AFD å­˜åœ¨â€œ**æ­»åŒº (dead zone)**â€â€”â€”å³å¢åŠ  FFN èŠ‚ç‚¹æ•°æ— æ³•æå‡ HFUï¼Œå› ä¸ºè®¡ç®—å— scale-out å¸¦å®½é™åˆ¶ã€‚

2. **å¼•å…¥ Temporal Sparsity (St) å’Œ Operator FLOPS Utilization (OFU) æŒ‡æ ‡**
   - æ›´ç²¾ç»†åˆ»ç”»ç®—å­åˆ©ç”¨ç‡ï¼š`HFU = OFU Ã— St`
   - åŒºåˆ†â€œæ´»è·ƒæœŸé—´çš„ç®—åŠ›åˆ©ç”¨â€ä¸â€œæ•´ä½“æ—¶é—´å†…çš„èµ„æºå ç”¨â€ã€‚

3. **é¦–æ¬¡é‡åŒ– AFD å¯¹è´Ÿè½½ä¸å‡è¡¡çš„æ•æ„Ÿæ€§**
   - å‘ç° AFD çš„ç¦»æ•£èŠ‚ç‚¹çº§æ‰©å±•ï¼ˆdiscrete node-level scalingï¼‰ç›¸æ¯” large-scale EP çš„è¿ç»­ batch è°ƒæ•´ï¼Œå¯¹ **DP/EP imbalance** æ›´ä¸ºè„†å¼±ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰ç ”ç©¶å±€é™ | æœ¬æ–‡æ”¹è¿› |
|------|----------------|-----------|
| åˆ†æç²’åº¦ | å¤šä¸ºç«¯åˆ°ç«¯ååé¢„æµ‹ï¼Œç¼ºä¹æ¨¡å‹-ç¡¬ä»¶è”åˆå»ºæ¨¡ | å¼•å…¥é€šä¿¡çº§ roofline æ¨¡å‹ï¼Œæ”¯æŒè·¨å¹³å°æ¨æ¼” |
| æ€§èƒ½å‡è®¾ | å¿½ç•¥é€šä¿¡å¼€é”€ã€pipeline bubbles å’Œ imbalance | æ˜¾å¼å»ºæ¨¡ `tc`, `St`, å¹¶åˆ†æä¸å¹³è¡¡æƒ©ç½š |
| ç»“è®ºæ™®é€‚æ€§ | å¸¸å®£ç§° AFD â€œalways betterâ€ | æŒ‡å‡º AFD æ˜¯ç‰¹å®šåœºæ™¯ä¸‹çš„ä¼˜åŒ–ï¼Œéé€šç”¨è§£ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ¨¡å‹ä¸ç¡¬ä»¶å¹³å°ï¼ˆéä¼ ç»Ÿâ€œæ•°æ®é›†â€ï¼‰
ç”±äºæ˜¯ç³»ç»Ÿçº§åˆ†æï¼Œå®éªŒåŸºäºå¤šä¸ªä¸»æµ MoE æ¨¡å‹å’Œ GPU æ¶æ„è¿›è¡Œå»ºæ¨¡ä¸ä»¿çœŸï¼š

#### æ¨¡å‹é…ç½®ï¼ˆæ¥è‡ªé™„å½• Bï¼‰
| Model | Parameters | #Experts | TopK | Expert Granularity | Sparsity |
|-------|------------|----------|------|--------------------|---------|
| DeepSeek-V3 | 671B | 256 | 8 | 2048 | 32 |
| Kimi-K2 | ~1T | 384 | 8 | 2048 | 48 |
| Step3 | â€” | 48 | 3 | 5120 | 16 |
| ERNIE-4.5 | 300B | 64 | 8 | 3584 | 8 |
| GLM-4.7 | â€” | 160 | 8 | 1536 | 20 |

> æ³¨ï¼šå‚æ•°æ¥è‡ªå…¬å¼€æŠ€æœ¯æŠ¥å‘Šï¼ˆå¦‚ [6][15][17] ç­‰ï¼‰

#### ç¡¬ä»¶å¹³å°å¯¹æ¯”
| Platform | FP8 FLOPS (TFLOPS) | Scale-Out BW (GB/s) | Scale-Up BW (GB/s) | Node GPUs |
|---------|---------------------|------------------------|----------------------|-----------|
| H20 | 296 | 50 | 360 | 8 |
| H800 | 1979 | 50 | 160 | 8 |
| H100 | 1979 | 50 | 360 | 8 |
| GB200 / GB300 (Superpod) | 4500 | Superpod-level | 720 | 8 |

---

### ğŸ“Š å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ | è¯´æ˜ |
|------|------|------|
| **HFU** | `FLOPs / (FLOPS Ã— tB)` | æ•´ä½“ç¡¬ä»¶ FLOPS åˆ©ç”¨ç‡ |
| **OFU** | `FLOPs / (FLOPS Ã— å®é™…æ‰§è¡Œæ—¶é—´)` | ç®—å­æ´»è·ƒæœŸå†…çš„åˆ©ç”¨ç‡ |
| **St (Temporal Sparsity)** | `æ‰§è¡Œæ—¶é—´ / tB` | è¡¡é‡ GPU å ç”¨å¯†åº¦ |
| **Arithmetic Intensity (I)** | `FLOPs / Mem Access` | å†³å®šæ˜¯å¦ compute-bound æˆ– memory-bound |
| **Throughput Penalty Î±** | ä¸å¹³è¡¡ä¸‹ååä¸‹é™æ¯”ä¾‹ | ç”¨äºæ¯”è¾ƒ AFD vs large-scale EP çš„é²æ£’æ€§ |

#### å…³é”®å‡è®¾
- æ‰€æœ‰å±‚é‡‡ç”¨ **3BO (Three-Batch Overlap)** ä»¥éšè—é€šä¿¡å»¶è¿Ÿã€‚
- `Laccept = 1.7`ï¼ˆå¯ç”¨ Multi-Token Prediction, MTPï¼‰ã€‚
- `tg = 15ms`ï¼ˆgap latencyï¼Œå« dense å±‚å’Œè°ƒåº¦å¼€é”€ï¼‰ã€‚
- SLO å¯¹åº” TPOT = 50ms â‡’ å¯åæ¨å‡º `tB`ã€‚

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **Large-scale EP** | å½“å‰ä¸»æµæ–¹æ¡ˆï¼Œåœ¨ decode å®ä¾‹ä¸­ä½¿ç”¨ EP å¹¶èšåˆå¤š DP batch |
| **AFD (Attention-FFN Disaggregation)** | æœ¬æ–‡åˆ†æå¯¹è±¡ï¼Œattention ä¸ FFN ç‰©ç†åˆ†ç¦»éƒ¨ç½² |
| **PD Disaggregation (Prefill-Decode)** | ä½œä¸ºèƒŒæ™¯å‚è€ƒï¼Œéç›´æ¥å¯¹æ¯”å¯¹è±¡ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ

#### âœ… å›¾4ï¼šä¸åŒç¡¬ä»¶å¹³å°ä¸Š AFD çš„ç†è®º HFU ä¸Šé™
| å¹³å° | æœ€å¤§ HFUï¼ˆå…¸å‹å€¼ï¼‰ | æ˜¯å¦é€šä¿¡å—é™ |
|------|------------------|--------------|
| H20 | ~80% | å¦ï¼ˆcompute-limitedï¼‰ |
| H800 | **ä»… 33.1%** | æ˜¯ï¼ˆä¸¥é‡é€šä¿¡ç“¶é¢ˆï¼‰ |
| GB200 / GB300 | **é«˜è¾¾ 65.5%** | å¦ï¼ˆå¸¦å®½å……è¶³ï¼‰ |

> ğŸ’¡ åœ¨ H800 ä¸Šå³ä½¿å‡è®¾ OFU=100%ï¼ŒHFU ä»è¿œä½äº large-scale EP çš„çº¦ 60%ï¼Œè¯´æ˜ **AFD åœ¨æ™®é€šé›†ç¾¤ä¸Šéš¾ä»¥è¶…è¶Š EP**

#### âœ… å›¾2ï¼šArithmetic Intensity éš FFN èŠ‚ç‚¹æ•°å˜åŒ–è¶‹åŠ¿
æ­ç¤ºå››ä¸ªåŒºåŸŸï¼š
1. **Scale-up bound åŒºåŸŸ**ï¼šå° `NF`ï¼Œå—é™äº node å†… NVLink å¸¦å®½
2. **Stable intensity åŒºåŸŸ**ï¼šå¼ºåº¦ä¸å˜
3. **Scale-out bound åŒºåŸŸ**ï¼šå¢å¤§ `NF` å¯æå‡å¼ºåº¦
4. **Maximum intensity åŒºåŸŸ**ï¼šå·²è¾¾ä¸Šé™ï¼Œå†å¢æ— ç›Š

> âš ï¸ å­˜åœ¨â€œ**dead zone**â€ï¼šå½“ `NF > TopK` åï¼Œ`Brank` ä¸å†å¢é•¿ â‡’ FLOPs ä¸Šé™é”å®š

#### âœ… å›¾6ï¼šEP Imbalance ä¸‹çš„ååæƒ©ç½šå¯¹æ¯”
| æ¡ä»¶ | AFD ååæƒ©ç½š Î±_AFD | Large-scale EP Î±_EP |
|------|------------------|---------------------|
| `o=0.8`, `NA/NF=4` | â‰ˆ0.8 | â‰ˆ0.82 |
| å…¶ä»–å¤šæ•°æƒ…å†µ | **æ›´å·®** | æ›´ä¼˜ |

> â— AFD å› éœ€æ•´æ•°å€è°ƒæ•´ `NA`ï¼ˆç¦»æ•£ scalingï¼‰ï¼Œå¯¼è‡´èµ„æºåˆ†é…å­˜åœ¨**é‡åŒ–è¯¯å·®**ï¼Œé²æ£’æ€§æ›´å·®

#### âœ… æ¶ˆèå®éªŒå‘ç°ï¼ˆéšå«åœ¨åˆ†æä¸­ï¼‰
- **é€šä¿¡æ¨¡å¼å½±å“æ˜¾è‘—**ï¼š
  - Two-stage forwarding æ¯” point-to-point æ›´é«˜æ•ˆåˆ©ç”¨ scale-up å¸¦å®½
- **æ¨¡å‹ç»“æ„å†³å®šæ½œåŠ›**ï¼š
  - Coarse-grained expertï¼ˆå¦‚ Step3, M=5120ï¼‰æ¯” fine-grainedï¼ˆå¦‚ DeepSeek-V3, M=2048ï¼‰æ›´é€‚åˆ AFD
- **Sparsity è¶Šä½è¶Šå¥½**ï¼š
  - ä½ sparsity â‡’ æ›´é«˜ token concentration â‡’ æ›´é«˜ per-expert batch size â‡’ æ›´é«˜ HFU

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ğŸ¯ ä¸»è¦å‘ç°
1. **AFD å¹¶éä¸‡èƒ½è§£ï¼Œå­˜åœ¨â€œæ­»åŒºâ€**
   - åœ¨æ ‡å‡†é›†ç¾¤ï¼ˆå¦‚ H800ï¼‰ä¸Šï¼Œç”±äº scale-out å¸¦å®½æœ‰é™ï¼Œå¢åŠ  FFN å®ä¾‹æ— æ³•æé«˜ HFUã€‚
   - æ­¤æ—¶ç³»ç»Ÿé™·å…¥ **network-bound** çŠ¶æ€ï¼Œoperator-level ä¼˜åŒ–æ— æ³•è½¬åŒ–ä¸ºæ•´ä½“æ”¶ç›Šã€‚

2. **AFD å¯¹è´Ÿè½½ä¸å‡è¡¡æ›´æ•æ„Ÿ**
   - ç”±äºå¿…é¡»æŒ‰èŠ‚ç‚¹ç²’åº¦æ‰©ç¼©å®¹ï¼ˆdiscrete scalingï¼‰ï¼Œé¢å¯¹ DP/EP imbalance æ—¶æ— æ³•åƒ large-scale EP é‚£æ ·é€šè¿‡å¾®è°ƒ batch size æ¥è¡¥å¿ã€‚
   - å¯¼è‡´ pipeline bubbles æ›´æ˜“ä¼ æ’­ï¼Œæ€§èƒ½ä¸‹é™æ›´å¿«ã€‚

3. **AFD æˆåŠŸçš„å‰ææ¡ä»¶æ˜ç¡®**
   - âœ… **Superpod-class ç¡¬ä»¶**ï¼ˆå¦‚ GB200/GB300ï¼‰ï¼šæä¾›å……è¶³ interconnect å¸¦å®½
   - âœ… **ç²—ç²’åº¦ä¸“å®¶ (coarse-grained experts)**ï¼šæ›´é«˜çš„ M æå‡ arithmetic intensity
   - âœ… **è¾ƒä½ä¸“å®¶ç¨€ç–æ€§ (lower sparsity)**ï¼šæå‡ per-rank token æ•°é‡
   - âœ… **å¼‚æ„èµ„æºé…ç½®èƒ½åŠ›**ï¼šä¸º attention å’Œ FFN åˆ†é…ä¸åŒç±»å‹ GPU

4. **å½“å‰ MoE è®¾è®¡è¶‹åŠ¿ä¸ AFD ç›¸æ‚–**
   - å½“å‰æ¨¡å‹è¶‹å‘ fine-grained experts å’Œ high sparsity ä»¥æå‡è®­ç»ƒæ•ˆç‡ï¼Œä½†è¿™åè€Œå‰Šå¼± AFD çš„ä¼˜åŠ¿ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
| å±€é™ | è¯´æ˜ |
|------|------|
| ä¾èµ–ç†æƒ³åŒ–å‡è®¾ | å¦‚ `tg=15ms` å¯èƒ½åœ¨çœŸå®ç³»ç»Ÿä¸­åä¹è§‚ï¼ˆPCIe/CUDA Graph å¼€é”€ï¼‰ |
| å¿½ç•¥åŠ¨æ€è°ƒåº¦å¤æ‚æ€§ | æœªå»ºæ¨¡è¯·æ±‚è·¯ç”±ã€buffer ç®¡ç†ç­‰ runtime overhead |
| ç¼ºä¹çœŸå®éƒ¨ç½²éªŒè¯ | å¤šä¸ºç†è®ºå»ºæ¨¡ä¸ unit test extrapolationï¼Œç¼ºå°‘å…¨æ ˆå®æµ‹ |
| å‡è®¾å®Œç¾ overlap | 3BO è¦æ±‚ä¸¥æ ¼åŒæ­¥ï¼Œç°å®ä¸­ jitter æ˜“ç ´å pipeline |

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **Model-Hardware Co-design**
   - è®¾è®¡æ›´é€‚åˆ AFD çš„ MoE æ¶æ„ï¼ˆå¦‚æ›´å¤§ Mã€æ›´ä½ sparsityï¼‰
   - å¼€å‘æ”¯æŒçµæ´» partitioning çš„ Superpod ç³»ç»Ÿ

2. **ä¼˜åŒ–é€šä¿¡åº“å®ç°**
   - æ”¹è¿› two-stage forwarding ä¸ shuffle kernels
   - æ¢ç´¢ **Transformation-Communication Fusion**ï¼ˆå¦‚ FUSCO [26]ï¼‰

3. **æ¢ç´¢ EaaS (Experts-as-a-Service) æ¶æ„**
   - å°† MoE å±‚å®Œå…¨æœåŠ¡åŒ–ï¼Œå®ç°æ›´é«˜å¼¹æ€§
   - é€‚ç”¨äºä¸­å°è§„æ¨¡æ¨¡å‹å…ˆè¡Œè½åœ°

4. **åŠ¨æ€è‡ªé€‚åº”è°ƒåº¦æœºåˆ¶**
   - æ ¹æ®å®æ—¶è´Ÿè½½è‡ªåŠ¨é€‰æ‹© AFD / large-scale EP / hybrid æ¨¡å¼

---

## âœ… æ€»ç»“ä¸€å¥è¯
> **AFD ä¸æ˜¯é€šç”¨åŠ é€Ÿå™¨ï¼Œè€Œæ˜¯ä¸€ç§åœ¨ Superpod çº§ç¡¬ä»¶ + ç²—ç²’åº¦ MoE æ¨¡å‹ç»„åˆä¸‹æ‰å¯èƒ½é‡Šæ”¾æ½œåŠ›çš„ä¸“ç”¨æ¶æ„ï¼›åœ¨å½“å‰ä¸»æµé…ç½®ä¸‹ï¼Œå®ƒå¾€å¾€å› é€šä¿¡ç“¶é¢ˆå’Œç¦»æ•£æ‰©å±•é—®é¢˜è¡¨ç°ä¸å¦‚ large-scale EPã€‚**

</details>

---

### 13. [Efficient Remote Prefix Fetching with GPU-native Media ASICs](https://arxiv.org/abs/2602.09725)

**Authors**: Liang Mi, Weijun Wang, Jinghan Chen, Ting Cao, Haipeng Dai, Yunxin Liu  
**Category**: cs.DC  
**Published**: 2026-02-11  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.09725v1  

#### Abstract
Remote KV cache reuse fetches KV cache for identical contexts from remote storage, avoiding recomputation, accelerating LLM inference. While it excels in high-speed networks, its performance degrades significantly in bandwidth-limited scenarios. Recent studies address this by transmitting KV caches ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEfficient Remote Prefix Fetching with GPU-native Media ASICs

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜

åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ä¸­ï¼Œ**è¿œç¨‹ KV cache å¤ç”¨**ï¼ˆremote KV cache reuseï¼‰æ˜¯ä¸€ç§é€šè¿‡ä»è¿œç¨‹å­˜å‚¨è·å–å·²è®¡ç®—çš„ KV cache æ¥é¿å…é‡å¤è®¡ç®—ã€åŠ é€Ÿæ¨ç†çš„æŠ€æœ¯ã€‚ç„¶è€Œï¼Œåœ¨å¸¦å®½å—é™çš„ç½‘ç»œç¯å¢ƒä¸‹ï¼Œè¯¥æŠ€æœ¯é¢ä¸´ä»¥ä¸‹ç“¶é¢ˆï¼š

- **ä¼ è¾“å¼€é”€å¤§**ï¼šåŸå§‹ KV cache æ•°æ®é‡å·¨å¤§ï¼Œå¯¼è‡´ç½‘ç»œä¼ è¾“å»¶è¿Ÿé«˜ã€‚
- **å‹ç¼©åè§£å‹ä»£ä»·é«˜**ï¼šç°æœ‰å‹ç¼©æ–¹æ³•ï¼ˆå¦‚ CacheGenã€ShadowServeï¼‰è™½ç„¶å‡å°‘äº†ä¼ è¾“é‡ï¼Œä½†è§£å‹è¿‡ç¨‹å ç”¨ GPU èµ„æºï¼ˆCUDA coresï¼‰ï¼Œé€ æˆä¸ LLM æ¨ç†å¼•æ“çš„èµ„æºç«äº‰ï¼Œåè€Œå¢åŠ ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆå°¤å…¶æ˜¯ Time to First Token, TTFTï¼‰ã€‚
- **ç¡¬ä»¶æˆæœ¬é«˜**ï¼šéƒ¨åˆ†æ–¹æ¡ˆä¾èµ– SmartNIC ç­‰ä¸“ç”¨ç¡¬ä»¶è¿›è¡Œè§£å‹ï¼ˆå¦‚ ShadowServeï¼‰ï¼Œéƒ¨ç½²æˆæœ¬é«˜æ˜‚ã€‚

å› æ­¤ï¼Œå¦‚ä½•å®ç°**é«˜æ•ˆã€ä½æˆæœ¬ã€æ— å¹²æ‰°**çš„è¿œç¨‹ KV cache å¤ç”¨æˆä¸ºå…³é”®æŒ‘æˆ˜ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

æœ¬æ–‡æå‡º **KVFetcher**ï¼Œä¸€ç§åŸºäº **GPU-native è§†é¢‘ç¼–è§£ç å™¨**ï¼ˆå¦‚ NVIDIA NVENC/NVDECï¼‰çš„è¿œç¨‹ KV cache å¤ç”¨ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š

#### ï¼ˆ1ï¼‰**Codec-friendly Tensor Layout**  
å°† KV cache å¼ é‡é‡æ–°ç»„ç»‡ä¸ºé€‚åˆè§†é¢‘ç¼–ç çš„æ ¼å¼ï¼Œä»¥æœ€å¤§åŒ–å‹ç¼©ç‡ï¼š
- **è·¨å¸§å¸ƒå±€ï¼ˆInter-frame layoutï¼‰**ï¼šæ²¿ token ç»´åº¦åˆ‡åˆ† KV cacheï¼Œå¹¶å°†å…¶åˆ†å¸ƒåˆ°è¿ç»­è§†é¢‘å¸§ä¸­ï¼Œåˆ©ç”¨è§†é¢‘ç¼–ç ä¸­çš„å¸§é—´é¢„æµ‹ï¼ˆinter-frame predictionï¼‰æ¶ˆé™¤å†—ä½™ã€‚
- **å¸§å†…å¸ƒå±€ï¼ˆIntra-frame layoutï¼‰**ï¼šä¼˜åŒ–å¼ é‡å†…éƒ¨å…ƒç´ æ’åˆ—æ–¹å¼ï¼Œæå‡å¸§å†…å‹ç¼©æ•ˆç‡ï¼Œéµå¾ªä¸‰å¤§è§„åˆ™ï¼š
  - ä¸è·¨ attention head äº¤æ¢å…ƒç´ ï¼›
  - ä¿æŒ head å†…éƒ¨å…ƒç´ é¡ºåºï¼›
  - å›ºå®š attention head é¡ºåºã€‚
- ä½¿ç”¨ **H.265 lossless æ¨¡å¼** ç¼–ç ï¼Œè·³è¿‡æœ‰æŸçš„ DCT å’Œé‡åŒ–æ­¥éª¤ï¼Œç¡®ä¿ç²¾åº¦æ— æŸã€‚

#### ï¼ˆ2ï¼‰**Efficient Remote KV Fetcher**  
è®¾è®¡äº†ä¸€å¥—é«˜æ•ˆçš„æµæ°´çº¿æœºåˆ¶ï¼Œå®ç°ä½å»¶è¿Ÿã€æ— å¹²æ‰°çš„æ•°æ®è·å–ä¸æ¢å¤ï¼š
- **Fetching-aware Scheduler**ï¼šå°†éœ€è¦ KV è·å–çš„è¯·æ±‚ä¸æ™®é€šè¯·æ±‚éš”ç¦»ï¼Œé¿å…éå¤ç”¨è¯·æ±‚è¢«é˜»å¡ï¼ˆè§£å†³ Head-of-Line Blockingï¼‰ã€‚
- **Adaptive-resolution KV Fetching**ï¼šæ ¹æ®å®æ—¶ç½‘ç»œå¸¦å®½åŠ¨æ€è°ƒæ•´è§†é¢‘åˆ†è¾¨ç‡ï¼Œå¹³è¡¡ä¼ è¾“ä¸è§£ç æ—¶é—´ï¼Œå‡å°‘æµæ°´çº¿æ°”æ³¡ã€‚
- **Frame-wise Tensor Restoration**ï¼šé€å¸§æ¢å¤ KV cache åˆ°é¡µå¼å†…å­˜ï¼ˆpaged memoryï¼‰ï¼Œæ˜¾è‘—é™ä½å³°å€¼å†…å­˜å ç”¨ï¼ˆä»…éœ€ ~70MBï¼‰ï¼Œé¿å…ä¸æ¨ç†ä»»åŠ¡äº‰æŠ¢å†…å­˜ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | KVFetcher | CacheGen | ShadowServe |
|------|---------|--------|-----------|
| **å‹ç¼©ç‡** | âœ… æœ€é«˜ï¼ˆæœ€é«˜è¾¾ 11.9Ã—ï¼‰ | âŒ è¾ƒä½ï¼ˆç®—æœ¯ç¼–ç ï¼‰ | âŒ ç±»ä¼¼ |
| **è§£å‹èµ„æº** | âœ… ä½¿ç”¨ç‹¬ç«‹ NVDEC å•å…ƒï¼Œæ— å¹²æ‰° | âŒ å ç”¨ CUDA coresï¼Œä¸¥é‡å¹²æ‰°æ¨ç† | âœ… ä½¿ç”¨ SmartNICï¼Œæ— å¹²æ‰° |
| **éƒ¨ç½²æˆæœ¬** | âœ… é›¶é¢å¤–æˆæœ¬ï¼ˆåˆ©ç”¨å·²æœ‰ GPU ç¼–è§£ç å™¨ï¼‰ | âœ… å¯è¡Œ | âŒ æ˜‚è´µï¼ˆéœ€ SmartNICï¼‰ |
| **TTFT æ”¹è¿›** | âœ… æœ€ä¼˜ï¼ˆæœ€é«˜æé€Ÿ 3.51Ã—ï¼‰ | âš ï¸ æœ‰é™ï¼ˆå—èµ„æºç«äº‰é™åˆ¶ï¼‰ | âš ï¸ å—é™äºç¡¬ä»¶æ™®åŠæ€§ |

> **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼šKVFetcher æ˜¯é¦–ä¸ªå……åˆ†åˆ©ç”¨ GPU å†…ç½®åª’ä½“ ASIC è¿›è¡Œ KV cache ç¼–è§£ç çš„å·¥ä½œï¼Œåœ¨ä¸ç‰ºç‰²ç²¾åº¦çš„å‰æä¸‹ï¼Œå®ç°äº†**é«˜ååã€ä½å»¶è¿Ÿã€é›¶å¹²æ‰°ã€ä½æˆæœ¬**çš„è¿œç¨‹å‰ç¼€è·å–ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†

è®ºæ–‡åœ¨ä¸‰ä¸ªé•¿ä¸Šä¸‹æ–‡åŸºå‡†æµ‹è¯•é›†ä¸Šè¯„ä¼°æ€§èƒ½ï¼Œæ¶µç›–å¤šç§ä»»åŠ¡ç±»å‹å’Œä¸Šä¸‹æ–‡é•¿åº¦ï¼š

| æ•°æ®é›† | ä»»åŠ¡ç±»å‹ | ä¸Šä¸‹æ–‡é•¿åº¦èŒƒå›´ | ç‰¹ç‚¹ |
|-------|--------|-------------|------|
| **L-Eval** | å°é—­å¼é—®ç­”ï¼ˆQAï¼‰ | 3Kâ€“200K tokens | åŒ…å«é•¿æ–‡æ¡£ç†è§£ä»»åŠ¡ |
| **LV-Eval** | å•è·³/å¤šè·³ QA | 16Kâ€“256K tokens | åŠ å…¥å¹²æ‰°é¡¹ã€äº‹å®æ··æ·†ç­‰æŒ‘æˆ˜ |
| **LongBench-V2** | å¤šæ ·åŒ–ä»»åŠ¡ï¼ˆQAã€å¯¹è¯ã€ä»£ç ã€ç»“æ„åŒ–æ•°æ®ï¼‰ | 13Kâ€“167K tokens | å¤šé€‰é¢˜å½¢å¼ï¼Œä¿è¯è¯„ä¼°å®¢è§‚æ€§ |

---

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹
- **LWM-7B**ï¼ˆ1M contextï¼‰
- **Yi-34B**ï¼ˆ200K contextï¼‰
- **Llama-3-70B**ï¼ˆ128K contextï¼‰

#### ç¡¬ä»¶å¹³å°ï¼ˆå¼‚æ„ GPU é›†ç¾¤ï¼‰
| GPU ç±»å‹ | æ˜¾å­˜ | NVDEC æ•°é‡ | ç”¨é€” |
|--------|-----|----------|-----|
| **NVIDIA L20**ï¼ˆä½ç«¯ï¼‰ | 48GB | 3 | æˆæœ¬æ•æ„Ÿåœºæ™¯ |
| **NVIDIA H20**ï¼ˆä¸­ç«¯ï¼‰ | 96GB | 7 | ä¸»æµäº‘æœåŠ¡å…¸å‹é…ç½® |
| **NVIDIA A100**ï¼ˆé«˜ç«¯ï¼‰ | 80GB | 5 | é«˜æ€§èƒ½è®¡ç®—ç¯å¢ƒ |

#### ç½‘ç»œå¸¦å®½
- æ¨¡æ‹ŸçœŸå®äº‘ç¯å¢ƒï¼Œæµ‹è¯• **1â€“40 Gbps TCP** å’Œ **100/200 Gbps RDMA** åœºæ™¯ã€‚

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **TTFT**ï¼ˆTime to First Tokenï¼‰ | ç”¨æˆ·è¯·æ±‚å‘å‡ºåˆ°ç”Ÿæˆç¬¬ä¸€ä¸ª token çš„æ—¶é—´ï¼Œæ ¸å¿ƒå»¶è¿ŸæŒ‡æ ‡ |
| **TPOT**ï¼ˆTime Per Output Tokenï¼‰ | è§£ç é˜¶æ®µæ¯ä¸ªè¾“å‡º token çš„å¹³å‡è€—æ—¶ |
| **Compression Ratio** | KV cache å‹ç¼©å‰åå¤§å°ä¹‹æ¯” |
| **Accuracy** | å„æ•°æ®é›†æ ‡å‡†æŒ‡æ ‡ï¼ˆå¦‚åŒ¹é…ç‡ã€F1-scoreï¼‰ |
| **Peak GPU Memory Usage** | è§£å‹è¿‡ç¨‹ä¸­æœ€å¤§æ˜¾å­˜å ç”¨ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿æ–¹æ³• | æè¿° |
|--------|------|
| **Full Prefill** | ä¸ä½¿ç”¨ä»»ä½• KV cache å¤ç”¨ï¼Œå®Œå…¨é‡æ–°è®¡ç®— |
| **Raw KV Reuse** | ç›´æ¥ä¼ è¾“åŸå§‹ KV cacheï¼ˆå¦‚ Mooncakeï¼‰ |
| **CacheGen** | ä½¿ç”¨ CUDA kernel è¿›è¡Œç®—æœ¯ç¼–ç å‹ç¼©ä¸è§£å‹ |
| **ShadowServe** | å°†è§£å‹å¸è½½è‡³ SmartNIC |
| **llm.265** | å¹¶è¡Œç ”ç©¶ï¼Œå°è¯•ç”¨è§†é¢‘ç¼–ç å‹ç¼© KV cacheï¼Œä½†æœªå……åˆ†ä¼˜åŒ– |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### âœ… **TTFT æ˜¾è‘—é™ä½**
- åœ¨å…¸å‹ 16 Gbps ç½‘ç»œ + Yi-34B æ¨¡å‹ä¸‹ï¼š
  - KVFetcher ç›¸æ¯” **CacheGen** å¹³å‡é™ä½ **3.51Ã— TTFT**
  - ç›¸æ¯” **Full Prefill** é™ä½ **13.63Ã— TTFT**
  - åœ¨ä¸åŒæ¨¡å‹å’Œè®¾å¤‡ä¸Šï¼ŒTTFT å‡å°‘ **1.52â€“3.51Ã—**

#### âœ… **éå¤ç”¨è¯·æ±‚ä¹Ÿå—ç›Š**
- å¯¹äºæ— éœ€ KV å¤ç”¨çš„è¯·æ±‚ï¼ŒKVFetcher ä»èƒ½ï¼š
  - **é™ä½ 77.1% TTFT**ï¼ˆvs CacheGenï¼‰
  - **é™ä½ 35.4% TPOT**ï¼ˆvs CacheGenï¼‰
- åŸå› ï¼šè§£å‹ä¸æŠ¢å  CUDA èµ„æºï¼Œè°ƒåº¦å™¨éš”ç¦» fetch è¯·æ±‚ï¼Œé¿å… HOL blockingã€‚

#### âœ… **å‹ç¼©ç‡é¢†å…ˆä¸”ç²¾åº¦æ— æŸ**
- **å¹³å‡å‹ç¼©ç‡è¾¾ 11.9Ã—**ï¼Œè¿œè¶… CacheGen å’Œ ShadowServeï¼ˆçº¦ 5â€“6Ã—ï¼‰
- ç›¸æ¯” CacheGen æå‡ **2.17Ã— å‹ç¼©ç‡**
- æ‰€æœ‰ä»»åŠ¡ä¿æŒ **lossless accuracy**ï¼Œè€Œ llm.265 å­˜åœ¨ç²¾åº¦ä¸‹é™ã€‚

#### âœ… **å†…å­˜å¼€é”€æä½**
- å¹¶å‘å¤„ç† 7 ä¸ªè§†é¢‘å—æ—¶ï¼Œå³°å€¼ GPU å†…å­˜ä»… **400MB**
- è§£å‹ç¼“å†²åŒºå°äº **70MB**ï¼ˆCacheGen éœ€ 5.5GB è§£å‹ç©ºé—´ï¼‰

#### âœ… **é€‚åº”åŠ¨æ€å¸¦å®½èƒ½åŠ›å¼º**
- è‡ªé€‚åº”åˆ†è¾¨ç‡æœºåˆ¶ä½¿æµæ°´çº¿æ°”æ³¡å‡å°‘ **21%**
- åŠ¨æ€åˆ‡æ¢ 240P/480P/1080P åˆ†è¾¨ç‡ï¼Œæœ‰æ•ˆåº”å¯¹ç½‘ç»œæŠ–åŠ¨ã€‚

---

### æ¶ˆèå®éªŒç»“æœ

| ç»„ä»¶ | å¯¹å‹ç¼©ç‡çš„å½±å“ | è¯´æ˜ |
|------|----------------|------|
| **Quantization only** | åŸºçº¿ï¼ˆ~5.8Ã—ï¼‰ | ä»…æ•´æ•°é‡åŒ– |
| **+ Inter-frame layout** | â†’ **~12.8Ã—** | token ç»´åº¦åˆ‡åˆ† + è¿ç»­å¸§å¸ƒå±€å¤§å¹…æå‡å‹ç¼© |
| **+ Intra-frame layout** | â†’ **~17.1Ã—** | å¼ é‡é‡æ’è¿›ä¸€æ­¥æŒ–æ˜å†—ä½™ |
| **æœ€ç»ˆæ–¹æ¡ˆï¼ˆå«è§£ç ä¼˜åŒ–ï¼‰** | å®é™… **11.9Ã—** | å—é™äºå®é™…è§£ç ååï¼Œä½†ä»æœ€ä¼˜ |

> æ³¨ï¼šæ¶ˆèæ˜¾ç¤º inter-frame layout è´¡çŒ®æœ€å¤§å‹ç¼©å¢ç›Šï¼ˆå¹³å‡ 2.2Ã—ï¼‰ï¼Œintra-frame layout è¿›ä¸€æ­¥æå‡ 1.35Ã—ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°

1. **GPU-native è§†é¢‘ç¼–è§£ç å™¨æ˜¯è¢«å¿½è§†çš„å¼ºå¤§èµ„æº**ï¼šç°ä»£ GPU æ™®éé…å¤‡ç‹¬ç«‹çš„ NVENC/NVDEC å•å…ƒï¼Œåœ¨ LLM æ¨ç†ä¸­å®Œå…¨ç©ºé—²ï¼Œå¯ç”¨äºé«˜æ€§èƒ½ã€æ— å¹²æ‰°çš„ KV cache ç¼–è§£ç ã€‚
2. **åˆç†çš„ tensor-to-video æ˜ å°„å¯æå¤§æå‡å‹ç¼©ç‡**ï¼šç®€å•åœ°å°† KV å¼ é‡è§†ä¸ºå›¾åƒå¸§æ•ˆæœå·®ï¼›å¿…é¡»ç»“åˆ LLM æ¶æ„ç‰¹æ€§ï¼ˆå¦‚ token é—´ç›¸ä¼¼æ€§é«˜ï¼‰è®¾è®¡ codec-friendly layoutã€‚
3. **ç³»ç»Ÿçº§ååŒè®¾è®¡è‡³å…³é‡è¦**ï¼šä»…å‹ç¼©ä¸å¤Ÿï¼Œè¿˜éœ€è°ƒåº¦ã€è‡ªé€‚åº”åˆ†è¾¨ç‡ã€å¸§çº§æ¢å¤ç­‰æœºåˆ¶é…åˆï¼Œæ‰èƒ½å®ç°æœ€å° TTFTã€‚
4. **KVFetcher åœ¨çœŸå®åœºæ™¯ä¸­ä¼˜åŠ¿æ˜æ˜¾**ï¼šå°¤å…¶é€‚ç”¨äºä¸­ä½ç«¯ GPU + æœ‰é™å¸¦å®½çš„ç»æµå‹éƒ¨ç½²ç¯å¢ƒã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

1. **ä¾èµ– NVDEC èµ„æºæ•°é‡**ï¼š
   - ä½ç«¯ GPUï¼ˆå¦‚ L20ï¼‰ä»…æœ‰ 3 ä¸ª NVDECï¼Œå¯èƒ½æˆä¸ºå¹¶å‘è§£ç ç“¶é¢ˆã€‚
   - å½“å‰è§£ç ååå—é™äºç¡¬ä»¶å¹¶è¡Œèƒ½åŠ›ï¼Œæ— æ³•åƒ CUDA é‚£æ ·å¼¹æ€§æ‰©å±•ã€‚

2. **ä¸æ”¯æŒåœ¨çº¿å‹ç¼©ï¼ˆOnline Compressionï¼‰**ï¼š
   - å½“å‰è®¾è®¡ä¸ºç¦»çº¿å‹ç¼©ï¼ˆoffline encodingï¼‰ï¼Œä¸é€‚åˆ P-D disaggregation æˆ–æ•…éšœè¿ç§»ç­‰éœ€è¿è¡Œæ—¶å‹ç¼©çš„åœºæ™¯ã€‚
   - NVENC èµ„æºæœ‰é™ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶å‹ç¼©éœ€æ±‚ã€‚

3. **é¢„åˆ†é…å†…å­˜ç­–ç•¥å¯èƒ½å½±å“å…¬å¹³æ€§**ï¼š
   - ä¸º fetch è¯·æ±‚é¢„åˆ†é…å¤§é‡ GPU å†…å­˜ï¼Œå¯èƒ½å¯¼è‡´éå¤ç”¨è¯·æ±‚å› å†…å­˜ä¸è¶³è¢«å»¶è¿Ÿã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **ä¸‹ä¸€ä»£ GPU ç¼–è§£ç å™¨å¢å¼º**ï¼š
   - æœŸå¾…æœªæ¥ GPU æä¾›æ›´å¤šã€æ›´å¼ºçš„ NVENC/NVDEC å•å…ƒï¼Œæ”¯æŒæ›´é«˜å¹¶å‘çš„åœ¨çº¿å‹ç¼©ã€‚

2. **æ™ºèƒ½å†…å­˜ç®¡ç†æœºåˆ¶**ï¼š
   - å°† fetched KV cache å…ˆå†™å…¥æœ¬åœ° SSD æˆ– host memoryï¼ŒæŒ‰éœ€æ¢å…¥ GPUï¼Œç¼“è§£å†…å­˜å‹åŠ›ã€‚

3. **æ”¯æŒè¿è¡Œæ—¶ KV å‹ç¼©**ï¼š
   - ç»“åˆè½»é‡çº§ç¼–ç ç­–ç•¥ï¼Œåœ¨ prefill é˜¶æ®µå³æ—¶å‹ç¼© KV cacheï¼Œç”¨äºèŠ‚ç‚¹é—´ä¼ è¾“æˆ–å®¹é”™å¤‡ä»½ã€‚

4. **æ‰©å±•è‡³å…¶ä»–æ¨¡æ€æ¨¡å‹**ï¼š
   - å°†è¯¥æ€æƒ³æ¨å¹¿è‡³ Vision-Language Model æˆ–å¤šæ¨¡æ€ agent ä¸­çš„ä¸­é—´çŠ¶æ€å¤ç”¨ã€‚

---

> **æ€»ä½“è¯„ä»·**ï¼šKVFetcher æ˜¯ä¸€é¡¹æå…·å®ç”¨ä»·å€¼çš„ç³»ç»Ÿåˆ›æ–°ï¼Œå·§å¦™åˆ©ç”¨ç°æœ‰ç¡¬ä»¶èµ„æºè§£å†³äº† LLM æ¨ç†ä¸­çš„å…³é”®æ€§èƒ½ç“¶é¢ˆï¼Œå…·å¤‡è‰¯å¥½çš„å¯éƒ¨ç½²æ€§å’Œå¹¿æ³›é€‚ç”¨å‰æ™¯ã€‚

</details>

---

### 14. [Epistemic Throughput: Fundamental Limits of Attention-Constrained Inference](https://arxiv.org/abs/2602.09127)

**Authors**: Lei You  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.09127v1  

#### Abstract
Recent generative and tool-using AI systems can surface a large volume of candidates at low marginal cost, yet only a small fraction can be checked carefully. This creates a decoder-side bottleneck: downstream decision-makers must form reliable posteriors from many public records under scarce attent...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šEpistemic Throughput: Fundamental Limits of Attention-Constrained Inference**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
è¯¥è®ºæ–‡ç ”ç©¶çš„æ˜¯åœ¨**ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ—¶ä»£ä¸‹ï¼Œä¿¡æ¯éªŒè¯æˆæœ¬è¿œé«˜äºç”Ÿæˆæˆæœ¬æ‰€å¯¼è‡´çš„â€œæ³¨æ„åŠ›ç“¶é¢ˆâ€é—®é¢˜**ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨é«˜é£é™©é¢†åŸŸï¼ˆå¦‚ç§‘å­¦å‘ç°ã€é‡‘èæƒ…æŠ¥ã€è½¯ä»¶ä¾›åº”é“¾ç­‰ï¼‰ï¼Œå†³ç­–è€…éœ€è¦ä»æµ·é‡å€™é€‰è®°å½•ä¸­è¯†åˆ«å‡ºå°‘é‡çœŸå®ã€å¯é çš„ä¿¡æ¯ï¼ˆå³â€œçœŸå€¼â€ï¼‰ï¼Œä½†å…¶**éªŒè¯èƒ½åŠ›ï¼ˆverificationï¼‰å—é™äºç¨€ç¼ºçš„æ³¨æ„åŠ›èµ„æº**ã€‚

ä¼ ç»Ÿé€šä¿¡ç†è®ºå…³æ³¨ä¿¡é“å®¹é‡å’Œä¼ è¾“å¯é æ€§ï¼Œè€Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„èŒƒå¼â€”â€”**Attention-Constrained Inference (ACI)**ï¼Œèšç„¦äº**å¦‚ä½•åœ¨æœ‰é™çš„éªŒè¯é¢„ç®— $B$ ä¸‹ï¼Œé€šè¿‡å¤§è§„æ¨¡ä½æˆæœ¬ç­›é€‰ï¼ˆscreeningï¼‰æ¥æœ€å¤§åŒ–å¯¹æ½œåœ¨çœŸç›¸çš„æ¨æ–­æ•ˆç‡**ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

è®ºæ–‡æå‡ºäº†ä»¥ä¸‹æ ¸å¿ƒæ¦‚å¿µä¸ç†è®ºæ¡†æ¶ï¼š

- **Epistemic Throughputï¼ˆè®¤çŸ¥ååé‡ï¼‰**  
  å®šä¹‰ä¸ºåœ¨æ¯ä¸ªæ—¶é—´çª—å£å†…ï¼Œç³»ç»Ÿæ‰€èƒ½å®ç°çš„æœ€å¤§åéªŒä¸ç¡®å®šæ€§å‡å°‘é‡ï¼ˆå³ä¿¡æ¯å¢ç›Šï¼‰ï¼Œè¡¡é‡å•ä½éªŒè¯èµ„æºä¸‹çš„çŸ¥è¯†è·å–æ•ˆç‡ã€‚

- **JaKoB Scaling Lawï¼ˆJaKoBç¼©æ”¾å®šå¾‹ï¼‰**  
  åœ¨ Bayes log-loss åº¦é‡ä¸‹ï¼Œè¯æ˜äº†ä¿¡æ¯å¢ç›Šæ»¡è¶³å¦‚ä¸‹åŸºæœ¬æé™ï¼š
  $$
  \text{Gain} \sim I_{\text{ver}} \left( Bp + \sqrt{JKB} \right)
  $$
  å…¶ä¸­ï¼š
  - $B$: éªŒè¯é¢„ç®—ï¼ˆdeep attentionï¼‰
  - $K$: ç­›é€‰è§„æ¨¡ï¼ˆbroad attentionï¼‰
  - $p$: æœ‰ä»·å€¼è®°å½•çš„å…ˆéªŒæ¦‚ç‡ï¼ˆprevalenceï¼‰
  - $J = I(T;Z)$: ç­›é€‰è´¨é‡ï¼ˆscreening qualityï¼‰ï¼Œå³ç­›é€‰ä¿¡å· $Z$ ä¸çœŸå®ç±»å‹ $T$ çš„äº’ä¿¡æ¯
  - $I_{\text{ver}}$: æ¯æ¬¡æˆåŠŸéªŒè¯å¸¦æ¥çš„ä¿¡æ¯è´¡çŒ®

  è¿™ä¸€å®šå¾‹æ­ç¤ºäº†ä¸€ä¸ªéçº¿æ€§æ”¾å¤§æ•ˆåº”ï¼šå³ä½¿ç­›é€‰è´¨é‡ $J$ å¾ˆå¼±ï¼Œåªè¦èƒ½ä»¥é«˜æ¯”ä¾‹ $\frac{K}{B}$ è¿‡é‡‡æ ·ï¼ˆoversamplingï¼‰ï¼Œå°±å¯ä»¥æ˜¾è‘—æå‡æœ‰æ•ˆéªŒè¯äº§å‡ºã€‚

- **Tail Leverage Theoryï¼ˆå°¾éƒ¨æ æ†ç†è®ºï¼‰**  
  åœ¨ç¨€ç–éªŒè¯åœºæ™¯ï¼ˆ$B \ll K$ï¼‰ä¸­ï¼Œç­›é€‰çš„æœ‰æ•ˆæ€§å–å†³äºè¯„åˆ†åˆ†å¸ƒçš„ä¸Šå°¾è¡Œä¸ºï¼š
  - è‹¥è¯„åˆ†å‘ˆè½»å°¾åˆ†å¸ƒï¼ˆå¦‚ Gaussianï¼‰ï¼Œåˆ™å¢ç›Šä»…éš $\log(K/B)$ å¢é•¿ï¼›
  - è‹¥è¯„åˆ†å‘ˆé‡å°¾åˆ†å¸ƒï¼ˆå¦‚ Paretoï¼‰ï¼Œåˆ™å¯å®ç°å¤šé¡¹å¼çº§æ æ†æ”¾å¤§ï¼ˆpolynomial leverageï¼‰ã€‚

- **Score-Based Verification Policy çš„å¯å®ç°æ€§**  
  è¯æ˜ç®€å•çš„â€œtop-$B$â€ç­–ç•¥ï¼ˆåŸºäºè´å¶æ–¯å¾—åˆ†æ’åºå¹¶éªŒè¯å‰ $B$ åï¼‰åœ¨å¼±ç­›é€‰å‡è®¾ä¸‹å³å¯é€¼è¿‘ JaKoB ä¸Šé™ï¼Œå…·æœ‰å®é™…å¯è¡Œæ€§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡ ACI æ¡†æ¶ |
|------|--------|-------------|
| **ç›®æ ‡** | æ•°æ®ä¼ è¾“å¯é æ€§ï¼ˆbit rateï¼‰æˆ–è¯­ä¹‰ä¸€è‡´æ€§ | **Truthfulness**ï¼šæœ€å¤§åŒ–ç»éªŒè¯æ®æ”¯æŒçš„çœŸå®ä¿¡å¿µå½¢æˆé€Ÿç‡ |
| **ç“¶é¢ˆå»ºæ¨¡** | ç¼–ç ç«¯å¸¦å®½é™åˆ¶ | **è§£ç ç«¯æ³¨æ„åŠ›çº¦æŸ**ï¼ˆverification scarcityï¼‰ |
| **åˆ†æå·¥å…·** | ä¿¡é“å®¹é‡ã€é”™è¯¯ç‡ | **ä¿¡æ¯è®º + å†³ç­–ç†è®º**ï¼šç»“åˆ mutual informationã€order statistics å’Œ extreme-value theory |
| **è®¾è®¡å¯ç¤º** | æå‡ç¼–ç æ•ˆç‡ | å¼•å¯¼ç³»ç»Ÿè®¾è®¡æœå‘**äº§ç”Ÿæ˜“éªŒè¯ã€é«˜ä¿¡æ¯é‡è¾“å‡º**ï¼Œé¼“åŠ±é‡å°¾è¯„åˆ†æœºåˆ¶ |

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†**
æœ¬ç ”ç©¶æ˜¯**ç†è®ºé©±åŠ¨å‹å·¥ä½œ**ï¼Œæœªä½¿ç”¨çœŸå®ä¸–ç•Œ benchmark æ•°æ®é›†è¿›è¡Œè®­ç»ƒæˆ–æµ‹è¯•ã€‚è€Œæ˜¯æ„å»ºäº†ä¸€ä¸ª**å¯æ§çš„ä»¿çœŸç¯å¢ƒ**æ¥éªŒè¯ç†è®ºè¾¹ç•Œã€‚

- **æ¨¡æ‹Ÿè®¾ç½®**ï¼šé‡‡ç”¨ logistic regression æ¨¡å‹ç”Ÿæˆ screening scoresï¼š
  $$
  \pi_i = \sigma(\text{logit}(p_0) + \epsilon G_i)
  $$
  å…¶ä¸­ $G_i \sim \mathcal{N}(0,1)$ï¼Œ$\epsilon$ æ§åˆ¶ç­›é€‰å¼ºåº¦ï¼Œå¯¹åº”ä¸åŒ AUC æ°´å¹³ï¼ˆ0.55 ~ 0.90ï¼‰ã€‚
- å‚æ•°è®¾å®šï¼š$K=10^4$, $B \in [1, 1000]$, $p_0 = 0.01$

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°æŒ‡æ ‡**
- **Information Gainï¼ˆä¿¡æ¯å¢ç›Šï¼‰**ï¼šå®šä¹‰ä¸ºåˆå§‹ç†µå‡å»æœ€ç»ˆæ¡ä»¶ç†µï¼š
  $$
  \Delta H = H(O) - D(K,B)
  $$
  å•ä½ä¸º bitsï¼Œç­‰ä»·äº Bayes log-loss ä¸‹çš„è®¤çŸ¥æ”¹è¿›ã€‚
- **Epistemic Throughput**ï¼šå½’ä¸€åŒ–åçš„ä¿¡æ¯å¢ç›Šï¼Œåæ˜ æ¯å•ä½éªŒè¯çš„æˆæœ¬æ•ˆç›Šã€‚

#### **å®éªŒæµç¨‹**
1. ç”Ÿæˆ $K$ æ¡è®°å½•çš„ screening scores $\{Z_i\}$
2. è®¡ç®—è´å¶æ–¯å¾—åˆ† $\pi(Z_i) = P(T=1|Z_i)$
3. æ‰§è¡Œ top-$B$ verification policy
4. è§‚æµ‹å®é™…è·å¾—çš„ informative records æ•°é‡åŠä¿¡æ¯å¢ç›Š
5. å¯¹æ¯”ç†è®ºé¢„æµ‹æ›²çº¿ï¼ˆbenchmarkã€weak-screening approximationã€converse boundï¼‰

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

è™½ç„¶æ²¡æœ‰ä¼ ç»Ÿæ„ä¹‰ä¸Šçš„â€œæ¨¡å‹å¯¹æ¯”â€ï¼Œä½†å®éªŒä¸­éšå«æ¯”è¾ƒäº†å¤šç§ç†æƒ³ä¸ç°å®ç­–ç•¥ï¼š

| æ–¹æ³• | æè¿° |
|------|------|
| **Random Verification** | ç›²ç›®éšæœºé€‰æ‹© $B$ æ¡è®°å½•éªŒè¯ï¼ŒæœŸæœ›å¢ç›Šä¸º $Bp$ |
| **Oracle Upper Bound** | å·²çŸ¥å“ªäº›è®°å½•æ˜¯æœ‰ä»·å€¼çš„ï¼ŒåªéªŒè¯çœŸæ­£ positive çš„é¡¹ï¼Œä¸Šé™ä¸º $\min(B, Kp)$ |
| **Perfect Screening** | ç†æƒ³åˆ†ç±»å™¨å®Œå…¨åŒºåˆ† $T=1$ ä¸ $T=0$ï¼Œè¾¾åˆ°æœ€ä¼˜é€‰æ‹© |
| **Top-$B$ Score Policy** | å®é™…æ‰§è¡Œçš„ç­–ç•¥ï¼ŒæŒ‰ $\pi(Z)$ æ’åºåéªŒè¯å‰ $B$ å |
| **Finite-Pool Oracle** | è€ƒè™‘æ± å­å¤§å°æœ‰é™æ—¶çš„ç†æƒ³ä¸Šé™ |

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

- å›¾4ï¼ˆFig. 4ï¼‰å±•ç¤ºäº†å››ç§ä¸åŒç­›é€‰å¼ºåº¦ï¼ˆAUC â‰ˆ 0.55, 0.70, 0.79, 0.90ï¼‰ä¸‹çš„å®è¯ä¿¡æ¯å¢ç›Šæ›²çº¿ã€‚
- æ‰€æœ‰è®¾ç½®ä¸‹ï¼Œ**empirical gainï¼ˆæ ‡è®°ç‚¹ï¼‰å‡ç´§è´´ç†è®º benchmark æ›²çº¿ï¼ˆå®çº¿ï¼‰**ï¼Œè¯´æ˜ç†è®ºé¢„æµ‹é«˜åº¦å‡†ç¡®ã€‚
- **weak-screening approximationï¼ˆè™šçº¿ï¼‰åœ¨å¼ºç­›é€‰æ—¶è¶‹äºä¿å®ˆ**ï¼Œä½†åœ¨å¼±ç­›é€‰åŒºï¼ˆAUCâ‰ˆ0.55ï¼‰éå¸¸æ¥è¿‘ã€‚
- **converse boundï¼ˆç‚¹åˆ’çº¿ï¼‰å§‹ç»ˆé«˜äºå®è¯ç»“æœ**ï¼Œç¬¦åˆå…¶ä½œä¸ºä¸Šç•Œçš„æ€§è´¨ã€‚

> âœ… **æ ¸å¿ƒå‘ç°**ï¼šå³ä½¿ç­›é€‰èƒ½åŠ›å¾ˆå¼±ï¼ˆAUCâ‰ˆ0.55ï¼‰ï¼Œé€šè¿‡æ‰©å¤§ $K$ å¹¶åº”ç”¨ top-$B$ ç­–ç•¥ï¼Œä»å¯è·å¾—æ˜¾è‘—é«˜äºéšæœºéªŒè¯çš„ä¿¡æ¯å¢ç›Šã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| ç­–ç•¥ | ä¿¡æ¯å¢ç›Šè¡¨ç° |
|------|------------|
| Random ($Bp$) | æœ€ä½ï¼Œçº¿æ€§å¢é•¿ï¼Œæ–œç‡ä¸º $p=0.01$ |
| Top-$B$ Score Policy | æ˜¾è‘—ä¼˜äº randomï¼Œå°¤å…¶åœ¨ä¸­é«˜ $B$ åŒºé—´ |
| Benchmark Prediction (Thm 17) | å‡ ä¹å®Œç¾æ‹Ÿåˆå®è¯ç»“æœï¼ŒéªŒè¯äº†ç†è®ºæœ‰æ•ˆæ€§ |
| Converse Bound (Thm 6) | ç•¥é«˜äºå®è¯ï¼Œåˆç†å®½æ¾ |
| Oracle | ä¸å¯è¾¾ï¼Œä½†æ˜¾ç¤ºæ½œåŠ›ç©ºé—´ |

ä¾‹å¦‚ï¼Œåœ¨ $B=100$ æ—¶ï¼š
- Random: ~1 bit
- Top-$B$: ~35â€“80 bitsï¼ˆä¾ AUC è€Œå®šï¼‰
- Oracle: ~100 bits

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆå¦‚æœ‰ï¼‰**

è®ºæ–‡è™½æ— æ˜¾å¼æ¶ˆèå®éªŒï¼Œä½†é€šè¿‡å‚æ•°æ§åˆ¶å®ç°äº†ç±»ä¼¼åˆ†æï¼š

- **æ”¹å˜ $\epsilon$ï¼ˆç­›é€‰å¼ºåº¦ï¼‰** â†’ æ§åˆ¶ $J = I(T;Z)$ â†’ éªŒè¯ $J$ å¯¹å¢ç›Šçš„å½±å“
- **æ”¹å˜ $K/B$ æ¯”ä¾‹** â†’ åˆ†æ oversampling ratio çš„æ æ†ä½œç”¨
- **æ”¹å˜ score åˆ†å¸ƒç±»å‹ï¼ˆGaussian vs Paretoï¼‰** â†’ éªŒè¯ tail leverage æ•ˆåº”ï¼ˆè§ Fig. 3ï¼‰

è¿™äº›åˆ†æå…±åŒæ„æˆäº†ä¸€ç»„â€œç†è®ºæ¶ˆèâ€ï¼Œç¡®è®¤äº†å„å› ç´ çš„å…³é”®ä½œç”¨ã€‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### **è®ºæ–‡çš„ä¸»è¦å‘ç°**

1. âœ… **JaKoB Scaling Law æˆç«‹**ï¼šä¿¡æ¯å¢ç›Šç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š
   - çº¿æ€§é¡¹ $I_{\text{ver}} Bp$ï¼šç›¸å½“äºéšæœºéªŒè¯çš„åŸºç¡€æ”¶ç›Š
   - éçº¿æ€§é¡¹ $I_{\text{ver}} \sqrt{JKB}$ï¼šæ¥è‡ªç­›é€‰çš„è´¨é‡ä¸è§„æ¨¡ååŒæ•ˆåº”

2. âœ… **ç­›é€‰çš„ä»·å€¼åœ¨äºâ€œæŒ‘é€‰æƒâ€è€Œéç›´æ¥æä¾›ä¿¡æ¯**ï¼šscreening æœ¬èº«ä¸ç›´æ¥æ­ç¤ºçœŸç›¸ï¼Œä½†å®ƒé€šè¿‡æé«˜éªŒè¯é›†ä¸­â€œé‡‘çŸ¿â€çš„æµ“åº¦ï¼Œé—´æ¥æ”¾å¤§éªŒè¯èµ„æºçš„ä»·å€¼ã€‚

3. âœ… **è¿‡é‡‡æ ·ï¼ˆOversamplingï¼‰æ˜¯ä¸€ç§å…³é”®æ æ†**ï¼šå³ä½¿å•ä¸ªç­›é€‰å™¨ä¸å‡†ï¼Œåªè¦èƒ½å¤„ç†å¤§é‡å€™é€‰ï¼ˆlarge $K$ï¼‰ï¼Œå°±èƒ½ä»ä¸­æŒ‘å‡ºæå°‘æ•°é«˜è´¨é‡ç›®æ ‡ã€‚

4. âœ… **è¯„åˆ†åˆ†å¸ƒçš„å°¾éƒ¨ç‰¹æ€§å†³å®šæ”¾å¤§ä¸Šé™**ï¼š
   - Light-tailedï¼ˆå¦‚ Gaussianï¼‰â†’ æ”¶ç›Šé€’å‡å¿«ï¼Œä»…å¯¹æ•°å¢é•¿
   - Heavy-tailedï¼ˆå¦‚ Paretoï¼‰â†’ å¯å®ç°å¹‚å¾‹åŠ é€Ÿï¼Œé€‚åˆå¤§è§„æ¨¡ç­›é€‰

5. âœ… **ç®€å•ç­–ç•¥å³å¯é€¼è¿‘ç†è®ºæé™**ï¼štop-$B$ verification policy åœ¨å¼±ç­›é€‰ä¸‹å³å¯å®ç° $\sqrt{JKB}$ ç¼©æ”¾ï¼Œæ— éœ€å¤æ‚è‡ªé€‚åº”æœºåˆ¶ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™ | è¯´æ˜ |
|------|------|
| **é™æ€ã€ç‹¬ç«‹åŒåˆ†å¸ƒå‡è®¾** | å½“å‰æ¨¡å‹å‡è®¾è®°å½•ä¹‹é—´ç‹¬ç«‹ä¸” i.i.d.ï¼Œå¿½ç•¥äº†åºåˆ—ä¾èµ–æ€§å’Œåé¦ˆé—­ç¯ï¼ˆå¦‚ç”¨æˆ·è¡Œä¸ºå—æ¨èå½±å“ï¼‰ |
| **å•ä¸€çª—å£åˆ†æ** | æœªè€ƒè™‘è·¨æ—¶é—´æ­¥çš„ä¸»åŠ¨å­¦ä¹ æˆ– bandit-style è‡ªé€‚åº”è¿‡ç¨‹ |
| **Log-loss ä½œä¸ºå”¯ä¸€æŒ‡æ ‡** | å¿½ç•¥äº†å…¶ä»–å®ç”¨ç›®æ ‡ï¼Œå¦‚ FDR æ§åˆ¶ã€å†³ç­– regret æˆ– abstention |
| **éªŒè¯æˆæœ¬åŒè´¨åŒ–** | å‡è®¾æ‰€æœ‰éªŒè¯ä»£ä»·ç›¸åŒï¼Œç°å®ä¸­å¯èƒ½å­˜åœ¨å¤šçº§å®¡è®¡è·¯å¾„ï¼ˆmulti-level verification ladderï¼‰ |
| **å¿½ç•¥å¯¹æŠ—æ€§æ“çºµ** | æœªå»ºæ¨¡æ¶æ„ç”Ÿäº§è€…æ•…æ„åˆ¶é€ é«˜åˆ†å‡è®°å½•çš„è¡Œä¸º |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ‰©å±•è‡³ Sequential ACI Setting**  
   å°† epistemic throughput æ¨å¹¿åˆ°åŠ¨æ€ã€åœ¨çº¿ç¯å¢ƒä¸­ï¼Œè¿æ¥ active learning ä¸ Bayesian experimental designã€‚

2. **å¼•å…¥ Strategic Producers ä¸ Mechanism Design**  
   æ„å»ºæ¿€åŠ±æœºåˆ¶ï¼Œä½¿ç”Ÿäº§â€œå¯éªŒè¯çœŸç†â€æˆä¸ºæœ€ä¼˜ç­–ç•¥ï¼Œé˜²æ­¢ cheap talk æ³›æ»¥ã€‚

3. **Develop Heavy-Tailed Scoring Architectures**  
   è®¾è®¡èƒ½å¤Ÿè‡ªç„¶äº§ç”Ÿé‡å°¾è¯„åˆ†çš„ ranking functions æˆ– tool-routing systemsï¼Œä»¥æœ€å¤§åŒ–å°¾éƒ¨æ æ†ã€‚

4. **Design Reusable Artifact Formats**  
   ç ”ç©¶å¦‚ä½•å°†éªŒè¯ç»“æœæ ‡å‡†åŒ–ä¸º public artifactsï¼ˆå¦‚ cryptographic attestations, structured citationsï¼‰ï¼Œä¿ƒè¿›è·¨ç”¨æˆ·å¤ç”¨ï¼Œæå‡æ•´ä½“ epistemic efficiencyã€‚

5. **Empirical Validation on Real Systems**  
   åœ¨ RAGã€tool-using agentsã€fact-checking pipelines ä¸­æµ‹é‡ $J, K, B$ ç­‰å‚æ•°ï¼Œæ£€éªŒ JaKoB å®šå¾‹çš„å®é™…é€‚ç”¨æ€§ã€‚

---

> ğŸ”š **ç»“è¯­**ï¼šæœ¬æ–‡æå‡ºäº† **epistemic communication** ä½œä¸ºä¸€ç§æ–°èŒƒå¼ï¼Œä¸»å¼ å°†â€œtruth acquisition rate under attention constraintsâ€ä½œä¸ºä¸‹ä¸€ä»£æ™ºèƒ½ç³»ç»Ÿçš„æ ¸å¿ƒä¼˜åŒ–ç›®æ ‡ã€‚**Epistemic Throughput** ä¸ä»…æ˜¯ä¸€ä¸ªç†è®ºåº¦é‡ï¼Œæ›´æ˜¯ä¸€ç§ç³»ç»Ÿè®¾è®¡å“²å­¦ï¼š**è®©æ¯ä¸€æ¬¡æ·±åº¦éªŒè¯éƒ½å°½å¯èƒ½åœ°æ”¹å˜æˆ‘ä»¬çš„ä¿¡å¿µã€‚**

</details>

---

### 15. [PTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognition](https://arxiv.org/abs/2602.08240)

**Authors**: Xun Su, Huamin Wang, Qi Zhang  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.08240v1  

#### Abstract
Speech Emotion Recognition (SER) is widely deployed in Human-Computer Interaction, yet the high computational cost of conventional models hinders their implementation on resource-constrained edge devices. Spiking Neural Networks (SNNs) offer an energy-efficient alternative due to their event-driven ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠPTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognitionã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰ä¸»æµçš„ **Speech Emotion Recognition (SER)** ç³»ç»Ÿä¾èµ–äºå¯†é›†å‚æ•°çš„ **Artificial Neural Networks (ANNs)**ï¼Œè™½ç„¶æ€§èƒ½ä¼˜è¶Šï¼Œä½†å…¶é«˜è®¡ç®—æˆæœ¬å’Œèƒ½è€—é™åˆ¶äº†åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šçš„éƒ¨ç½²ã€‚  
**Spiking Neural Networks (SNNs)** è™½ç„¶å…·å¤‡äº‹ä»¶é©±åŠ¨ã€ä½åŠŸè€—çš„æ½œåŠ›ï¼Œä½†åœ¨ç›´æ¥åº”ç”¨äºè‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰ç”Ÿæˆçš„è¿ç»­ç‰¹å¾æ—¶é¢ä¸´ä¸¥é‡æŒ‘æˆ˜â€”â€”ç”±äºè¾“å…¥ç‰¹å¾åˆ†å¸ƒä¸è„‰å†²ç¥ç»å…ƒçš„é˜ˆå€¼å“åº”æœºåˆ¶ä¸åŒ¹é…ï¼Œå¯¼è‡´ç¥ç»å…ƒé™·å…¥â€œåŠŸèƒ½é™é»˜â€ï¼ˆfunctional silenceï¼‰æˆ–â€œé¥±å’Œâ€ï¼ˆsaturationï¼‰ï¼Œä»è€Œç ´åç¨€ç–æ—¶é—´ç¼–ç èƒ½åŠ›ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **PTS-SNN**ï¼ˆPrompt-Tuned Spiking Neural Networkï¼‰ï¼Œä¸€ç§å‚æ•°é«˜æ•ˆçš„ç±»è„‘é€‚é…æ¡†æ¶ï¼Œç”¨äºå°†å†»ç»“çš„ SSL ä¸»å¹²ç½‘ç»œï¼ˆå¦‚ emotion2vecï¼‰è¾“å‡ºçš„è¿ç»­è¡¨ç¤ºæœ‰æ•ˆå¯¹é½åˆ°ç¦»æ•£çš„ SNN åŠ¨æ€ä¸­ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **Temporal Shift Spiking Encoder**  
   - å¼•å…¥æ— å‚æ•°çš„ **channel shift** æ“ä½œï¼Œåœ¨æ®‹å·®è„‰å†²å—ä¸­æ•æ‰å±€éƒ¨æ—¶é—´ä¾èµ–å…³ç³»ã€‚
   - é€šè¿‡é›¶å¡«å……å’Œæˆªæ–­å®ç°å¸§é—´ä¿¡æ¯äº¤æ¢ï¼Œæ— éœ€é¢å¤–å‚æ•°å³å¯å¹³æ»‘é«˜é¢‘æ³¢åŠ¨ï¼Œå»ºç«‹ç¨³å®šè¾“å…¥åŸºç¡€ã€‚

2. **Context-Aware Membrane Potential Calibration**  
   - è®¾è®¡åŸºäº **Spiking Sparse Linear Attention (SSLA)** çš„æç¤ºæœºåˆ¶ï¼Œèšåˆå…¨å±€è¯­ä¹‰ä¸Šä¸‹æ–‡è‡³å¯å­¦ä¹ çš„è½¯æç¤ºï¼ˆsoft promptsï¼‰ã€‚
   - å°†è¿™äº›æç¤ºè½¬åŒ–ä¸ºåŠ¨æ€åç½®ç”µå‹ï¼ˆdynamic bias voltagesï¼‰ï¼Œè°ƒèŠ‚ **Parametric Leaky Integrate-and-Fire (PLIF)** ç¥ç»å…ƒçš„è†œç”µä½åŸºçº¿ã€‚
   - ç”Ÿç‰©å¯å‘å¼çš„è°ƒæ§æœºåˆ¶ä½¿è¾“å…¥åˆ†å¸ƒä¸­å¿ƒåŒ–äºæ•æ„Ÿå“åº”åŒºé—´ï¼ˆresponsive firing rangeï¼‰ï¼Œé¿å…é™é»˜/é¥±å’Œã€‚

3. **Prompting for SNNs çš„ç”Ÿç‰©ç‰©ç†é‡æ„**  
   - ä¸åŒäºä¼ ç»Ÿ Prompt Tuning ä¸­ä½œä¸ºè¯­ä¹‰åµŒå…¥çš„â€œadditive vectorsâ€ï¼Œæœ¬æ–‡å°† prompts è§†ä¸ºâ€œhomeostatic regulation signalsâ€ï¼Œå³ä¸»åŠ¨è°ƒæ§ä¿¡å·ï¼Œå®ç°äº†ä»è¿ç»­è¡¨å¾åˆ°ç¦»æ•£è„‰å†²åŠ¨åŠ›å­¦çš„æ— ç¼æ¡¥æ¥ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **å‚æ•°æ•ˆç‡æé«˜**ï¼šä»…éœ€ **1.19M å¯è®­ç»ƒå‚æ•°**ï¼Œè¿œä½äºå…¨å¾®è°ƒæˆ–ç¨ å¯†è§£ç å™¨æ–¹æ¡ˆã€‚
- **èƒ½é‡æ¶ˆè€—æä½**ï¼šæ¯æ ·æœ¬æ¨ç†èƒ½è€—ä»…ä¸º **0.35 mJ**ï¼Œé€‚åˆè¾¹ç¼˜éƒ¨ç½²ã€‚
- **æ€§èƒ½åª²ç¾å…ˆè¿› ANNs**ï¼šåœ¨ IEMOCAP ä¸Šè¾¾åˆ° **73.34% WA**ï¼Œä¼˜äºå¤šæ•°è½»é‡çº§ ANN æ¨¡å‹ã€‚
- **æ— éœ€ä¿®æ”¹é¢„è®­ç»ƒä¸»å¹²**ï¼šä¿æŒ SSL ä¸»å¹²å†»ç»“ï¼Œç¬¦åˆ Parameter-Efficient Fine-Tuning (PEFT) èŒƒå¼ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
åœ¨äº”ä¸ªå¤šè¯­è¨€ SER æ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œæ¶µç›–ä¸åŒè¯­è¨€å’Œæƒ…æ„Ÿç±»åˆ«ï¼š
| æ•°æ®é›†       | è¯­è¨€     | æƒ…æ„Ÿæ•° | è¯­å¥æ•° |
|------------|--------|------|------|
| **IEMOCAP** | English | 4    | 5,531 |
| **CASIA**   | Chinese | 4    | 1,200 |
| **EMODB**   | German  | 7    | 535   |
| **EMOVO**   | Italian | 7    | 588   |
| **URDU**    | Urdu    | 4    | 400   |

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **ä¸»å¹²æ¨¡å‹**ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„ **emotion2vec** æå–ç‰¹å¾ï¼Œä¸»å¹²å‚æ•°å†»ç»“ã€‚
- **ä¼˜åŒ–å™¨**ï¼šAdamWï¼Œåˆå§‹å­¦ä¹ ç‡ $2 \times 10^{-4}$ï¼ŒCosine Annealing Warm Restartsã€‚
- **è®­ç»ƒé…ç½®**ï¼š200 epochsï¼Œbatch size = 32ï¼Œå•å¼  RTX 4090 GPUã€‚
- **SNN è®¾ç½®**ï¼šé‡‡ç”¨æ›¿ä»£æ¢¯åº¦æ³•ï¼ˆsurrogate gradientï¼‰è¿›è¡Œåå‘ä¼ æ’­ï¼Œé™¡åº¦å› å­ $\alpha_{sq}=5$ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Weighted Accuracy (WA)**ï¼šæ€»ä½“å‡†ç¡®ç‡ï¼Œåæ˜ å…¨å±€æ€§èƒ½ã€‚
  - **Unweighted Accuracy (UA)**ï¼šå„ç±»åˆ«å¹³å‡å‡†ç¡®ç‡ï¼Œé€‚ç”¨äºç±»åˆ«ä¸å¹³è¡¡åœºæ™¯ã€‚

### ğŸ†š å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
- **Vanilla SNN**ï¼šç›´æ¥å°† SSL ç‰¹å¾è½¬æ¢ä¸ºè„‰å†²ï¼Œæ— é€‚é…æ¨¡å—ã€‚
- **emotion2vec + ANN fine-tuning**ï¼šæ ‡å‡†å…¨å¾®è°ƒã€‚
- **ShiftFormer**, **ENT**, **DST**, **MSTR**, **Co-attention**ï¼šè¿‘æœŸå…ˆè¿›çš„ SER æ¶æ„ï¼ˆå‡ä¸º ANNsï¼‰ã€‚
- æ‰€æœ‰å¯¹æ¯”å‡æŠ¥å‘Šå‚æ•°é‡ï¼ˆParamsï¼‰å’Œæ¨ç†èƒ½è€—ï¼ˆEnergyï¼‰ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ IEMOCAP ä¸ºä¾‹ï¼‰
| æ¨¡å‹             | WA (%) | UA (%) | å‚æ•°é‡ (M) | æ¨ç†èƒ½è€— (mJ) |
|------------------|--------|--------|-----------|---------------|
| Co-attention     | 69.80  | 71.05  | 175.30    | 103.40        |
| MSTR             | 70.60  | 71.60  | 30.03     | 51.06         |
| DST              | 71.80  | 73.60  | 22.78     | 35.34         |
| ShiftFormer      | 72.10  | 72.70  | 9.50      | 16.20         |
| ENT              | 72.43  | 73.88  | 8.55      | 6.35          |
| **PTS-SNN (Ours)** | **73.34** | **73.72** | **1.19**  | **0.35**      |

> âœ… PTS-SNN åœ¨ç²¾åº¦ä¸Šè¶…è¶Šæ‰€æœ‰å¯¹æ¯”æ¨¡å‹ï¼ŒåŒæ—¶å‚æ•°é‡å‡å°‘çº¦ **87%~99%**ï¼Œèƒ½è€—é™ä½ **ä¸¤ä¸ªæ•°é‡çº§ä»¥ä¸Š**ã€‚

### ğŸŒ è·¨è¯­è¨€æ³›åŒ–èƒ½åŠ›ï¼ˆWA %ï¼‰
| æ•°æ®é›†   | emotion2vec | PTS-SNN | æå‡å¹…åº¦ |
|--------|-------------|---------|--------|
| CASIA  | 69.20       | 72.50   | +3.30% |
| EMODB  | 84.34       | 87.49   | +3.15% |
| EMOVO  | 61.21       | 61.94   | +0.73% |
| URDU   | 81.50       | 84.25   | +2.75% |

> è¡¨æ˜ PTS-SNN å­¦ä¹ çš„æ˜¯è¯­è¨€æ— å…³çš„æƒ…æ„ŸéŸµå¾‹ç‰¹å¾ï¼Œå…·æœ‰è‰¯å¥½çš„è·¨è¯­è¨€è¿ç§»èƒ½åŠ›ã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆIEMOCAPï¼‰
| é…ç½®                     | WA (%) | UA (%) |
|--------------------------|--------|--------|
| Full Model (PTS-SNN)     | 73.34  | 73.72  |
| w/o Prompt Tuning        | 71.76  | 71.90  |
| w/o Attention Module     | 68.35  | 69.10  |
| Only Temporal Shift      | 61.27  | 62.05  |

> - ç§»é™¤ **prompt tuning** å¯¼è‡´æ€§èƒ½ä¸‹é™ 1.58%ï¼Œè¯´æ˜å…¶å¯¹åˆ†å¸ƒæ ¡å‡†è‡³å…³é‡è¦ã€‚
> - ç§»é™¤ **attention æ¨¡å—** ä¸‹é™ 4.99%ï¼ŒéªŒè¯å…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡çš„æœ‰æ•ˆæ€§ã€‚
> - ä»…ä¿ç•™ temporal shift æ€§èƒ½å¤§å¹…ä¸‹æ»‘ï¼Œè¡¨æ˜å±€éƒ¨å»ºæ¨¡ä¸è¶³ä»¥æ”¯æ’‘é«˜æ€§èƒ½è¯†åˆ«ã€‚

### âš¡ èƒ½æ•ˆåˆ†æ
- **å‚æ•°æ•ˆç‡**ï¼šPTS-SNN ä»…éœ€ 1.19M å‚æ•°ï¼Œç›¸è¾ƒ Co-attention å‡å°‘ **147 å€**ã€‚
- **èƒ½è€—æ•ˆç‡**ï¼šæ¯æ ·æœ¬ä»…æ¶ˆè€— **0.35 mJ**ï¼Œç›¸è¾ƒ MSTRï¼ˆ51.06 mJï¼‰é™ä½ **145 å€ä»¥ä¸Š**ã€‚
- èƒ½è€—ä¼°ç®—åŸºäº 45nm CMOS å·¥è‰ºï¼ŒåŒºåˆ† MACï¼ˆANNï¼‰ä¸ ACï¼ˆSNNï¼‰æ“ä½œèƒ½è€—ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **åˆ†å¸ƒå¤±é…æ˜¯ SNN åº”ç”¨äº SSL ç‰¹å¾çš„æ ¸å¿ƒç“¶é¢ˆ**ï¼šé«˜åŠ¨æ€èŒƒå›´çš„è¿ç»­ç‰¹å¾æ˜“å¯¼è‡´ PLIF ç¥ç»å…ƒè¿›å…¥é™é»˜æˆ–é¥±å’ŒçŠ¶æ€ï¼Œç ´åæ—¶é—´ç¼–ç èƒ½åŠ›ã€‚
2. **Prompt-based è°ƒæ§æœºåˆ¶å¯æœ‰æ•ˆè§£å†³è¯¥é—®é¢˜**ï¼šé€šè¿‡å°† soft prompts æ˜ å°„ä¸ºåŠ¨æ€åç½®ç”µå‹ï¼Œå®ç°è¾“å…¥åˆ†å¸ƒçš„ä¸»åŠ¨ä¸­å¿ƒåŒ–ï¼Œæ˜¾è‘—æå‡ SNN ç¼–ç æ•ˆç‡ã€‚
3. **PTS-SNN å®ç°äº†ç²¾åº¦ä¸æ•ˆç‡çš„åŒé‡çªç ´**ï¼šåœ¨ä¿æŒä¸æœ€å…ˆè¿› ANNs ç›¸å½“ç”šè‡³æ›´ä¼˜æ€§èƒ½çš„åŒæ—¶ï¼Œæå¤§é™ä½äº†å‚æ•°é‡å’Œèƒ½è€—ï¼Œç‰¹åˆ«é€‚åˆè¾¹ç¼˜æ™ºèƒ½åº”ç”¨ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰æ¡†æ¶ä»…åˆ©ç”¨ **å•æ¨¡æ€éŸ³é¢‘ä¿¡å·**ï¼Œæœªèåˆé¢éƒ¨è¡¨æƒ…ã€æ–‡æœ¬ç­‰äº’è¡¥ä¿¡æ¯ã€‚
- æ‰€æœ‰å®éªŒåŸºäºç¦»çº¿å¤„ç†ï¼Œå°šæœªåœ¨çœŸå®å¼‚æ­¥äº‹ä»¶æµä¸­éªŒè¯å®æ—¶æ€§ã€‚
- æç¤ºé•¿åº¦ï¼ˆ$L_p=5$ï¼‰å’Œåç½®ç¼©æ”¾å› å­ï¼ˆ$\kappa=0.5$ï¼‰éœ€ç»éªŒè°ƒå‚ï¼Œç¼ºä¹è‡ªåŠ¨åŒ–æœç´¢æœºåˆ¶ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **å¤šæ¨¡æ€ Spiking æ¶æ„**ï¼Œèåˆè§†è§‰ä¸æ–‡æœ¬çº¿ç´¢ï¼Œæ„å»ºæ›´é²æ£’çš„æƒ…ç»ªç†è§£ç³»ç»Ÿã€‚
- æ¢ç´¢ **åœ¨çº¿è‡ªé€‚åº”æç¤ºæœºåˆ¶**ï¼Œæ”¯æŒåŠ¨æ€ç¯å¢ƒä¸‹çš„æŒç»­å­¦ä¹ ã€‚
- å°†è¯¥ prompting èŒƒå¼æ¨å¹¿è‡³å…¶ä»– SNN ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚è¯­éŸ³è¯†åˆ«ã€å…³é”®è¯å”¤é†’ç­‰ï¼‰ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> PTS-SNN æˆåŠŸå°† Prompt Tuning èŒƒå¼ç”Ÿç‰©ç‰©ç†åŒ–ï¼Œæå‡ºäº†ä¸€ç§é«˜æ•ˆã€èŠ‚èƒ½ä¸”é«˜æ€§èƒ½çš„ SNN é€‚é…æ¡†æ¶ï¼Œä¸ºåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²åŸºäº SSL çš„æƒ…ç»ªè¯†åˆ«æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 16. [Boltzmann Reinforcement Learning for Noise resilience in Analog Ising Machines](https://arxiv.org/abs/2602.09162)

**Authors**: Aditya Choudhary, Saaketh Desai, Prasad Iyer  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.09162v1  

#### Abstract
Analog Ising machines (AIMs) have emerged as a promising paradigm for combinatorial optimization, utilizing physical dynamics to solve Ising problems with high energy efficiency. However, the performance of traditional optimization and sampling algorithms on these platforms is often limited by inher...

---

### 17. [Train Less, Infer Faster: Efficient Model Finetuning and Compression via Structured Sparsity](https://arxiv.org/abs/2602.09169)

**Authors**: Jonathan Svirsky, Yehonathan Refael, Ofir Lindenbaum  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.09169v1  

#### Abstract
Fully finetuning foundation language models (LMs) with billions of parameters is often impractical due to high computational costs, memory requirements, and the risk of overfitting. Although methods like low-rank adapters help address these challenges by adding small trainable modules to the frozen ...

---

### 18. [Scalable and Reliable State-Aware Inference of High-Impact N-k Contingencies](https://arxiv.org/abs/2602.09461)

**Authors**: Lihao Mai, Chenhan Xiao, Yang Weng  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.09461v1  

#### Abstract
Increasing penetration of inverter-based resources, flexible loads, and rapidly changing operating conditions make higher-order $N\!-\!k$ contingency assessment increasingly important but computationally prohibitive. Exhaustive evaluation of all outage combinations using AC power-flow or ACOPF is in...

---

### 19. [Time Series Reasoning via Process-Verifiable Thinking Data Synthesis and Scheduling for Tailored LLM Reasoning](https://arxiv.org/abs/2602.07830)

**Authors**: Jiahui Zhou, Dan Li, Boxin Li, Xiao Zhang, Erli Meng, Lin Li, Zhuomin Chen, Jian Lou, See-Kiong Ng  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.07830v1  

#### Abstract
Time series is a pervasive data type across various application domains, rendering the reasonable solving of diverse time series tasks a long-standing goal. Recent advances in large language models (LLMs), especially their reasoning abilities unlocked through reinforcement learning (RL), have opened...

---

### 20. [iGRPO: Self-Feedback-Driven LLM Reasoning](https://arxiv.org/abs/2602.09000)

**Authors**: Ali Hatamizadeh, Shrimai Prabhumoye, Igor Gitman, Ximing Lu, Seungju Han, Wei Ping, Yejin Choi, Jan Kautz  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.09000v1  

#### Abstract
Large Language Models (LLMs) have shown promise in solving complex mathematical problems, yet they still fall short of producing accurate and consistent solutions. Reinforcement Learning (RL) is a framework for aligning these models with task-specific rewards, improving overall quality and reliabili...

---

### 21. [AlignTune: Modular Toolkit for Post-Training Alignment of Large Language Models](https://arxiv.org/abs/2602.09621)

**Authors**: R E Zera Marveen Lyngkhoi, Chirag Chawla, Pratinav Seth, Utsav Avaiya, Soham Bhattacharjee, Mykola Khandoga, Rui Yuan, Vinay Kumar Sankarapu  
**Category**: cs.CL  
**Published**: 2026-02-11  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.09621v1  

#### Abstract
Post-training alignment is central to deploying large language models (LLMs), yet practical workflows remain split across backend-specific tools and ad-hoc glue code, making experiments hard to reproduce. We identify backend interference, reward fragmentation, and irreproducible pipelines as key obs...

---

### 22. [MATA: Multi-Agent Framework for Reliable and Flexible Table Question Answering](https://arxiv.org/abs/2602.09642)

**Authors**: Sieun Hyeon, Jusang Oh, Sunghwan Steve Cho, Jaeyoung Do  
**Category**: cs.CL  
**Published**: 2026-02-11  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.09642v1  

#### Abstract
Recent advances in Large Language Models (LLMs) have significantly improved table understanding tasks such as Table Question Answering (TableQA), yet challenges remain in ensuring reliability, scalability, and efficiency, especially in resource-constrained or privacy-sensitive environments. In this ...

---

### 23. [Unsupervised Layer-Wise Dynamic Test Time Adaptation for LLMs](https://arxiv.org/abs/2602.09719)

**Authors**: Longhuan Xu, Cunjian Chen, Feng Yin  
**Category**: cs.CL  
**Published**: 2026-02-11  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.09719v1  

#### Abstract
Test-time adaptation (TTA) for large language models (LLMs) updates model parameters at inference time using signals available at deployment. This paper focuses on a common yet under-explored regime: unsupervised, sample-specific TTA, where the model adapts independently for each prompt using only t...

---

### 24. [Decoupled Reasoning with Implicit Fact Tokens (DRIFT): A Dual-Model Framework for Efficient Long-Context Inference](https://arxiv.org/abs/2602.10021)

**Authors**: Wenxuan Xie, Yujia Wang, Xin Tan, Chaochao Lu, Xia Hu, Xuhong Wang  
**Category**: cs.CL  
**Published**: 2026-02-11  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.10021v1  

#### Abstract
The integration of extensive, dynamic knowledge into Large Language Models (LLMs) remains a significant challenge due to the inherent entanglement of factual data and reasoning patterns. Existing solutions, ranging from non-parametric Retrieval-Augmented Generation (RAG) to parametric knowledge edit...

---

### 25. [Stabilizing Physics-Informed Consistency Models via Structure-Preserving Training](https://arxiv.org/abs/2602.09303)

**Authors**: Che-Chia Chang, Chen-Yang Dai, Te-Sheng Lin, Ming-Chih Lai, Chieh-Hsin Lai  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.09303v1  

#### Abstract
We propose a physics-informed consistency modeling framework for solving partial differential equations (PDEs) via fast, few-step generative inference. We identify a key stability challenge in physics-constrained consistency training, where PDE residuals can drive the model toward trivial or degener...

---

### 26. [Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs](https://arxiv.org/abs/2602.07276)

**Authors**: Pengrui Han, Xueqiang Xu, Keyang Xuan, Peiyang Song, Siru Ouyang, Runchu Tian, Yuqing Jiang, Cheng Qian, Pengcheng Jiang, Jiashuo Sun, Junxia Cui, Ming Zhong, Ge Liu, Jiawei Han, Jiaxuan You  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.07276v1  

#### Abstract
Activation steering has emerged as a promising approach for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering methods rely on a single static direction per task or concept, making them inflexible under task variation and inadequate for complex...

---

### 27. [MSP-LLM: A Unified Large Language Model Framework for Complete Material Synthesis Planning](https://arxiv.org/abs/2602.07543)

**Authors**: Heewoong Noh, Gyoung S. Na, Namkyeong Lee, Chanyoung Park  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.07543v2  

#### Abstract
Material synthesis planning (MSP) remains a fundamental and underexplored bottleneck in AI-driven materials discovery, as it requires not only identifying suitable precursor materials but also designing coherent sequences of synthesis operations to realize a target material. Although several AI-base...

---

### 28. [Grounding Generative Planners in Verifiable Logic: A Hybrid Architecture for Trustworthy Embodied AI](https://arxiv.org/abs/2602.08373)

**Authors**: Feiyu Wu, Xu Zheng, Yue Qu, Zhuocheng Wang, Zicheng Feng, Hui Li  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.08373v1  

#### Abstract
Large Language Models (LLMs) show promise as planners for embodied AI, but their stochastic nature lacks formal reasoning, preventing strict safety guarantees for physical deployment. Current approaches often rely on unreliable LLMs for safety checks or simply reject unsafe plans without offering re...

---

### 29. [Advancing Block Diffusion Language Models for Test-Time Scaling](https://arxiv.org/abs/2602.09555)

**Authors**: Yi Lu, Deyang Kong, Jianing Wang, Linsen Guo, Xue Wang, Qi Guo, Tao Gui, Xuanjing Huang, Wei Ye, Shikun Zhang, Wei Wang  
**Category**: cs.CL  
**Published**: 2026-02-11  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.09555v1  

#### Abstract
Recent advances in block diffusion language models have demonstrated competitive performance and strong scalability on reasoning tasks. However, existing BDLMs have limited exploration under the test-time scaling setting and face more severe decoding challenges in long Chain-of-Thought reasoning, pa...

---

### 30. [Learning from the Irrecoverable: Error-Localized Policy Optimization for Tool-Integrated LLM Reasoning](https://arxiv.org/abs/2602.09598)

**Authors**: Qiao Liang, Yuke Zhu, Chao Ge, Lei Yang, Ying Shen, Bo Zheng, Sheng Guo  
**Category**: cs.CL  
**Published**: 2026-02-11  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.09598v1  

#### Abstract
Tool-integrated reasoning (TIR) enables LLM agents to solve tasks through planning, tool use, and iterative revision, but outcome-only reinforcement learning in this setting suffers from sparse, delayed rewards and weak step-level credit assignment. In long-horizon TIR trajectories, an early irrecov...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
