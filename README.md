# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-08 05:58:47 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Implicit Graph, Explicit Retrieval: Towards Efficient and Interpretable Long-horizon Memory for Large Language Models](https://arxiv.org/abs/2601.03417)

**Authors**: Xin Zhang, Kailai Yang, Hao Li, Chenyue Li, Qiyu Wei, Sophia Ananiadou  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.03417v1  

#### Abstract
Long-horizon applications increasingly require large language models (LLMs) to answer queries when relevant evidence is sparse and dispersed across very long contexts. Existing memory systems largely follow two paradigms: explicit structured memories offer interpretability but often become brittle u...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Implicit Graph, Explicit Retrieval: Towards Efficient and Interpretable Long-horizon Memory for Large Language Models*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨**é•¿æ—¶è·ï¼ˆlong-horizonï¼‰æ¨ç†ä»»åŠ¡**ä¸­ï¼Œç›¸å…³è¯æ®é€šå¸¸ç¨€ç–ä¸”åˆ†æ•£äºæ•°åƒtokençš„ä¸Šä¸‹æ–‡ä¸­ã€‚ç°æœ‰çš„è®°å¿†æœºåˆ¶é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **æ˜¾å¼ç»“æ„åŒ–è®°å¿†ï¼ˆExplicit Structured Memoryï¼‰**ï¼šå¦‚å›¾ç»“æ„å­˜å‚¨ï¼Œè™½å…·å¤‡è‰¯å¥½çš„**å¯è§£é‡Šæ€§**ï¼Œä½†åœ¨é•¿è€Œå˜ˆæ‚çš„ä¸Šä¸‹æ–‡ä¸­æ˜“å› ç»“æ„æ„å»ºé”™è¯¯æˆ–æ£€ç´¢ä¸ç¨³å®šè€Œå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼ˆâ€œlong-context overloadâ€ï¼‰ã€‚
- **éšå¼æ½œç©ºé—´è®°å¿†ï¼ˆLatent Memoryï¼‰**ï¼šé«˜æ•ˆç¨³å®šï¼Œä½†ç¼ºä¹é€æ˜åº¦ï¼Œéš¾ä»¥è¿›è¡Œäººç±»å®¡æŸ¥æˆ–è°ƒè¯•ã€‚

å› æ­¤ï¼Œå¦‚ä½•åœ¨**æ•ˆç‡ã€ç¨³å®šæ€§ä¸å¯è§£é‡Šæ€§ä¹‹é—´å–å¾—å¹³è¡¡**ï¼Œæ˜¯å½“å‰LLMé•¿æœŸè®°å¿†ç³»ç»Ÿçš„å…³é”®ç“¶é¢ˆã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šLATENTGRAPHMEM
ä½œè€…æå‡º **LATENTGRAPHMEM**ï¼Œä¸€ç§ç»“åˆ**éšå¼å›¾å­˜å‚¨**ä¸**æ˜¾å¼å­å›¾æ£€ç´¢**çš„è®°å¿†æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³ä¸ºï¼š
> **â€œéšå¼å»ºæ¨¡ï¼Œæ˜¾å¼æš´éœ²â€ï¼ˆImplicit modeling, explicit exposureï¼‰**

#### ä¸»è¦ç»„ä»¶ï¼š
1. **Graph Builderï¼ˆå›¾æ„å»ºå™¨ï¼‰**  
   - å°†é•¿æ–‡æ¡£æµå¼å¤„ç†ä¸ºä¸€ä¸ªå—é™çš„ç¬¦å·å›¾ï¼ˆsymbolic graphï¼‰ï¼Œæå–å®ä½“ä¸‰å…ƒç»„ `(h, r, t)`ã€‚
   - åŒæ—¶å°†æ¯æ¡è¾¹ç¼–ç ä¸º**æ½œå‘é‡ï¼ˆlatent embeddingï¼‰**ï¼Œå½¢æˆéšå¼å›¾è¡¨ç¤ºã€‚
   
2. **Subgraph Retrieverï¼ˆå­å›¾æ£€ç´¢å™¨ï¼‰**  
   - åœ¨æ½œç©ºé—´ä¸­åŸºäºé—®é¢˜ `q` å¯¹è¾¹åµŒå…¥è¿›è¡Œæ‰“åˆ†ï¼Œé€šè¿‡ Top-K é€‰æ‹©æœ€å¤š `k` æ¡æœ€ç›¸å…³çš„è¾¹ã€‚
   - åªå°†è¿™ä¸ªç´§å‡‘çš„**æ˜¾å¼å­å›¾ï¼ˆexplicit subgraphï¼‰** åºåˆ—åŒ–å¹¶ä¼ é€’ç»™ä¸‹æ¸¸æ¨ç†æ¨¡å‹ã€‚

3. **Frozen LLM Reasonerï¼ˆå†»ç»“çš„æ¨ç†å™¨ï¼‰**  
   - ä¸å‚ä¸è®­ç»ƒï¼Œä»…ç”¨äºç”Ÿæˆç­”æ¡ˆï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

#### åˆ›æ–°äº®ç‚¹ï¼š
- **åŒé˜¶æ®µè®­ç»ƒ + è”åˆå¾®è°ƒ**ï¼šBuilder å’Œ Retriever åˆ†é˜¶æ®µè¿œç¨‹ç›‘ç£è®­ç»ƒï¼Œå¹¶æœ€ç»ˆè”åˆä¼˜åŒ–ä»¥å¢å¼ºååŒã€‚
- **æ½œç©ºé—´æ£€ç´¢ + æ˜¾å¼è¾“å‡º**ï¼šé¿å…äº†å®Œæ•´å›¾åºåˆ—åŒ–çš„å¼€é”€ï¼ŒåŒæ—¶ä¿ç•™äº†è§£é‡Šæ€§ã€‚
- **æ— éœ€å¼ºåŒ–å­¦ä¹ **ï¼šä½¿ç”¨ Straight-Through Estimator å®ç° Top-K çš„å¯å¾®è®­ç»ƒï¼Œç®€åŒ–å®ç°ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | æ˜¾å¼å›¾æ–¹æ³•ï¼ˆå¦‚THEANINE, Mem0ï¼‰ | éšå¼è®°å¿†ï¼ˆå¦‚MemGenï¼‰ | LATENTGRAPHMEMï¼ˆæœ¬æ–‡ï¼‰ |
|------|-------------------------------|------------------------|--------------------------|
| **å¯è§£é‡Šæ€§** | é«˜ï¼ˆå®Œæ•´å›¾å¯è§ï¼‰ | æä½ï¼ˆé»‘ç›’ï¼‰ | âœ… é«˜ï¼ˆä»…æš´éœ²å…³é”®å­å›¾ï¼‰ |
| **ç¨³å®šæ€§** | ä½ï¼ˆå—å™ªå£°å½±å“å¤§ï¼‰ | é«˜ | âœ… é«˜ï¼ˆæ½œç©ºé—´æ“ä½œï¼‰ |
| **æ•ˆç‡** | ä½ï¼ˆéœ€åºåˆ—åŒ–æ•´ä¸ªå›¾ï¼‰ | é«˜ | âœ… é«˜ï¼ˆå›ºå®šé¢„ç®—æ£€ç´¢ï¼‰ |
| **æ‰©å±•æ€§** | å·®ï¼ˆéšä¸Šä¸‹æ–‡å¢é•¿ï¼‰ | å¥½ | âœ… å¥½ï¼ˆç‹¬ç«‹äºä¸Šä¸‹æ–‡é•¿åº¦ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼ˆå…±20,800æ ·æœ¬ï¼‰ï¼š
  - **TriviaQA**ï¼šå¼€æ”¾åŸŸé—®ç­”ï¼Œè¯æ®åˆ†æ•£ã€‚
  - **QASPER**ï¼šç§‘å­¦è®ºæ–‡ç†è§£ï¼Œè·¨æ®µè½æ¨ç†ã€‚
  - **QuALITY**ï¼šå™äº‹ç±»æ–‡ç« å¤šé€‰é¢˜ï¼Œå¼ºè°ƒå…¨å±€ç†è§£ã€‚
- **æµ‹è¯•æ•°æ®**ï¼ˆå…±2,600æ ·æœ¬æ··åˆï¼‰ï¼š
  - **HotpotQA**ï¼šå¤šè·³æ¨ç†ï¼Œè·¨æ–‡æ¡£å…³è”ã€‚
  - **NarrativeQA**ï¼šé•¿ç¯‡æ•…äº‹ç†è§£ã€‚
  - **WikiHop**ï¼šåŸºäºç»´åŸºç™¾ç§‘çš„é€»è¾‘æ¨ç†ã€‚

> æ‰€æœ‰æµ‹è¯•é›†å‡æœªå‡ºç°åœ¨è®­ç»ƒä¸­ï¼Œä¿è¯æ³›åŒ–èƒ½åŠ›è¯„ä¼°ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®
- **ä¸»å¹²æ¨¡å‹ï¼ˆReasonerï¼‰**ï¼šä¸‰ç§è§„æ¨¡çš„å†»ç»“LLMï¼š
  - `Qwen2.5-1.5B-Instruct`
  - `SmolLM3-3B`
  - `Qwen3-8B`
- **è®°å¿†æ¨¡å—**ï¼šGraph Builder ä¸ Subgraph Retriever å‡é‡‡ç”¨ LoRA å¾®è°ƒçš„å°å‹LLMï¼ˆç»Ÿä¸€ä¸º1.5Bï¼‰ï¼Œå¯é€‚é…ä¸åŒå¤§å°çš„æ¨ç†å™¨ã€‚
- **å›¾å®¹é‡æ§åˆ¶**ï¼š
  - æ¯chunkæœ€å¤šæå–32ä¸ªä¸‰å…ƒç»„ã€‚
  - å…¨å±€å›¾æœ€å¤§è¾¹æ•° $ M = 150 $ã€‚
  - æ£€ç´¢å­å›¾å¤§å° $ k = 30 $ã€‚
- **è¾“å…¥å¤„ç†**ï¼šæ–‡æ¡£åˆ‡åˆ†ä¸º1024-tokené‡å å—ï¼ˆoverlap=128ï¼‰ã€‚

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- **Accuracy (Acc)**ï¼šç²¾ç¡®åŒ¹é…å‡†ç¡®ç‡ï¼ˆå°¤å…¶é€‚ç”¨äºå¤šè·³ã€äº‹å®å‹é—®é¢˜ï¼‰ã€‚
- **ROUGE-L**ï¼šè¡¡é‡ç”Ÿæˆæ–‡æœ¬ä¸å‚è€ƒç­”æ¡ˆçš„æœ€é•¿å…¬å…±å­åºåˆ—ï¼Œåæ˜ æµç•…æ€§å’Œè¦†ç›–åº¦ã€‚

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• | ç®€ä»‹ |
|------|------|------|
| **æ— è®°å¿†** | Reasoner-only | ç›´æ¥è¾“å…¥å…¨æ–‡ |
| **æ£€ç´¢å¢å¼º** | RAG | åŸºäºembeddingæ£€ç´¢top-kæ–‡æœ¬å— |
| **æ˜¾å¼å›¾è®°å¿†** | THEANINE, PREMem, Mem0/Mem0g, A-Mem | å›¾ç»“æ„å­˜å‚¨ï¼Œæ”¯æŒæ—¶é—´çº¿/ç¤¾åŒºç­‰ç»„ç»‡æ–¹å¼ |
| **éšå¼è®°å¿†** | MemGen | ç”Ÿæˆæ½œå‘é‡ä½œä¸ºè½¯æç¤º |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ æ€§èƒ½æ±‡æ€»ï¼ˆè§ Table 1ï¼‰
åœ¨ä¸‰ä¸ªåŸºå‡†ä¸Šçš„å¹³å‡ Accuracy è¡¨ç°å¦‚ä¸‹ï¼š

| æ–¹æ³• | Qwen2.5-1.5B | SmolLM3-3B | Qwen3-8B |
|------|--------------|------------|---------|
| **Reasoner-only** | 52.11% | 50.70% | 54.74% |
| **MemGen (Latent)** | 44.03% | 49.58% | 54.56% |
| **A-Mem / PREMem / THEANINE / Mem0** | <30% | <46% | <44% |
| **LATENTGRAPHMEM (Ours)** | **56.08%** | **58.64%** | **63.34%** |

âœ… **å…³é”®å‘ç°**ï¼š
- åœ¨æ‰€æœ‰æ¨¡å‹å°ºåº¦ä¸‹ï¼Œ**LATENTGRAPHMEM å‡æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿**ã€‚
- å³ä½¿ä½¿ç”¨**1.5Bçš„å°å‹è®°å¿†æ¨¡å—**ï¼Œä¹Ÿèƒ½æœ‰æ•ˆæœåŠ¡äº**8Bçš„å¤§æ¨ç†å™¨**ï¼Œä½“ç°è‰¯å¥½æ‰©å±•æ€§ã€‚
- åœ¨å¤šè·³æ¨ç†ä»»åŠ¡ï¼ˆå¦‚HotpotQAï¼‰ä¸Šæå‡å°¤ä¸ºæ˜æ˜¾ï¼Œè¯´æ˜å…¶æ“…é•¿æ•´åˆè¿œè·ç¦»è¯æ®ã€‚

---

### ğŸ” æ¶ˆèå®éªŒï¼ˆAblation Studyï¼Œè§ Figure 3ï¼‰
ç ”ç©¶äº†ä¸åŒè®¾è®¡é€‰æ‹©çš„å½±å“ï¼š

| å˜ä½“ | æè¿° | ç»“æœ |
|------|------|------|
| **No Subgraph (Full Graph Only)** | ä¸åšæ£€ç´¢ï¼Œç›´æ¥ä¼ å®Œæ•´å›¾ | æ€§èƒ½ä¸‹é™ â†’ å®Œæ•´å›¾å¼•å…¥å™ªå£° |
| **No Subgraph Retriever (BFS)** | ä½¿ç”¨BFSå¯å‘å¼æ‰©å±•æ›¿ä»£å­¦ä¹ å¼æ£€ç´¢ | æ˜æ˜¾åŠ£äºå­¦ä¹ å¼ â†’ è¯æ˜Retrieveræœ‰æ•ˆæ€§ |
| **Fully Explicit (No Latent)** | å®Œå…¨åŸºäºç¬¦å·å›¾æ£€ç´¢ | ä¸åŠæœ¬æ–¹æ³• â†’ éªŒè¯æ½œç©ºé—´ç¨³å®šæ€§ä¼˜åŠ¿ |

â¡ï¸ ç»“è®ºï¼š**æ½œå›¾å­˜å‚¨ + å­¦ä¹ å¼é¢„ç®—åŒ–å­å›¾æ£€ç´¢** æ˜¯æœ€ä½³ç»„åˆã€‚

---

### â±ï¸ æ¨ç†å»¶è¿Ÿåˆ†æï¼ˆè§ Table 2ï¼‰
åœ¨ >6k token ä¸Šä¸‹æ–‡ä¸‹çš„å¹³å‡æ¨ç†æ—¶é—´ï¼ˆç§’ï¼‰ï¼š

| Context | LATENTGRAPHMEM | MemGen | A-Mem |
|--------|------------------|--------|-------|
| 6k     | 12.47            | 10.59  | 20.00 |
| 9k     | 13.43            | 10.86  | 44.65 |

- **A-Mem éšä¸Šä¸‹æ–‡æ€¥å‰§å˜æ…¢**ï¼Œå› å…¶éœ€é¢‘ç¹è®¿é—®ä¸æ–­å¢é•¿çš„æ˜¾å¼ç»“æ„ã€‚
- **LATENTGRAPHMEM æ¨ç†æ—¶é—´å‡ ä¹æ’å®š**ï¼Œå¾—ç›Šäºæ½œç©ºé—´æ“ä½œå’Œå›ºå®šæ£€ç´¢é¢„ç®—ã€‚
- è™½ç•¥é«˜äºçº¯éšå¼æ–¹æ³•ï¼ˆMemGenï¼‰ï¼Œä½†**ä»£ä»·æå°åœ°æ¢å–äº†å¯è§£é‡Šæ€§**ã€‚

---

### ğŸ“Š å›¾å®¹é‡æ•æ„Ÿæ€§åˆ†æï¼ˆè§ Figure 4ï¼‰
æ”¹å˜å…¨å±€å›¾å®¹é‡ $ M $ å¯¹æ€§èƒ½çš„å½±å“ï¼š
- **WikiHop**ï¼šéšç€ $ M $ å¢åŠ æŒç»­å—ç›Š â†’ æ›´å¹¿çš„çŸ¥è¯†è¦†ç›–æœ‰åˆ©ã€‚
- **HotpotQA / NarrativeQA**ï¼šè¶…è¿‡ $ M=150 $ åè¶‹äºé¥±å’Œç”šè‡³ä¸‹é™ â†’ è¿‡å¤šå™ªå£°å¹²æ‰°æ£€ç´¢ã€‚

â¡ï¸ è¯´æ˜ï¼š**åˆç†çš„å®¹é‡é™åˆ¶æœ‰åŠ©äºå»å™ªå’Œç¨³å®šæ£€ç´¢**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **æ˜¾å¼å›¾è®°å¿†åœ¨é•¿ä¸Šä¸‹æ–‡ä¸­ä¸ç¨³å®š**ï¼Œå®¹æ˜“å› ç»“æ„é”™è¯¯å¯¼è‡´å´©æºƒï¼ˆå°¤å…¶åœ¨NarrativeQAä¸Šæ¥è¿‘é›¶åˆ†ï¼‰ã€‚
2. **çº¯éšå¼è®°å¿†è™½ç¨³å®šä½†ä¸å¯è§£é‡Š**ï¼Œä¸åˆ©äºè°ƒè¯•å’Œå¯ä¿¡AIéƒ¨ç½²ã€‚
3. **LATENTGRAPHMEM æˆåŠŸèåˆä¸¤è€…ä¼˜ç‚¹**ï¼š
   - åˆ©ç”¨**æ½œç©ºé—´è¿›è¡Œé«˜æ•ˆç¨³å®šçš„å›¾è¡¨ç¤ºä¸æ£€ç´¢**ï¼›
   - ä»…æš´éœ²**ç´§å‡‘çš„æ˜¾å¼å­å›¾ä¾›æ¨ç†å’Œäººå·¥æ£€æŸ¥**ï¼›
   - å®ç°äº†**æ€§èƒ½ã€æ•ˆç‡ã€å¯è§£é‡Šæ€§çš„ç»Ÿä¸€**ã€‚
4. è¯¥æ¡†æ¶å…·æœ‰**å‚æ•°é«˜æ•ˆã€çµæ´»æ‰©å±•ã€ç¨³å®šæ¨ç†å»¶è¿Ÿ**ç­‰ç‰¹ç‚¹ï¼Œé€‚åˆå®é™…åº”ç”¨ã€‚

---

### âš ï¸ å±€é™æ€§
- **ä¾èµ–å›¾æ„å»ºè´¨é‡**ï¼šè‹¥Builderæå–çš„ä¸‰å…ƒç»„ä¸å‡†ç¡®ï¼Œåç»­æ— æ³•çº æ­£ã€‚
- **æœ€ä¼˜é…ç½®ä¾èµ–ä»»åŠ¡ç‰¹æ€§**ï¼šå¦‚å›¾å®¹é‡ $ M $ã€æ£€ç´¢é¢„ç®— $ k $ éœ€æ ¹æ®æ•°æ®è°ƒæ•´ã€‚
- **ç›®å‰å±€é™äºæ–‡æœ¬é—®ç­”åœºæ™¯**ï¼Œå°šæœªæ‹“å±•è‡³å¤šæ¨¡æ€æˆ–äº¤äº’å¼å†³ç­–ç¯å¢ƒã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å¼•å…¥åŠ¨æ€å›¾å‰ªææˆ–è‡ªé€‚åº”é¢„ç®—æœºåˆ¶ã€‚
- æ‰©å±•åˆ°å¯¹è¯ç³»ç»Ÿã€Agentè§„åˆ’ç­‰æ›´å¤æ‚çš„é•¿æœŸè®°å¿†åº”ç”¨åœºæ™¯ã€‚
- æ¢ç´¢å¤šæ¨¡æ€å›¾è®°å¿†ï¼ˆtext + image embeddingsï¼‰ã€‚
- ç»“åˆå› æœæ¨ç†æˆ–åäº‹å®åˆ†ææå‡å­å›¾å¯è§£é‡Šæ€§ã€‚

---

## âœ… æ€»ç»“
**LATENTGRAPHMEM** æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”å®ç”¨çš„é•¿æœŸè®°å¿†æ¶æ„èŒƒå¼â€”â€”**â€œéšå¼å›¾ï¼Œæ˜¾å¼æ£€â€ï¼ˆImplicit Graph, Explicit Retrievalï¼‰**ï¼Œåœ¨ä¿æŒé«˜æ•ˆç‡å’Œç¨³å®šæ€§çš„åŒæ—¶ï¼Œè§£å†³äº†ä¼ ç»Ÿéšå¼è®°å¿†ä¸å¯è§£é‡Šçš„æ ¹æœ¬ç—›ç‚¹ã€‚å®éªŒè¯æ˜å…¶åœ¨å¤šä¸ªé•¿æ—¶è·QAåŸºå‡†ä¸Š**å…¨é¢è¶…è¶Šä¸»æµæ˜¾å¼ä¸éšå¼åŸºçº¿**ï¼Œä¸ºæ„å»º**å¯é ã€å¯æ§ã€å¯å®¡è®¡çš„LLMæ™ºèƒ½ä½“è®°å¿†ç³»ç»Ÿ**æä¾›äº†é‡è¦è·¯å¾„ã€‚

</details>

---

### 2. [From Bits to Chips: An LLM-based Hardware-Aware Quantization Agent for Streamlined Deployment of LLMs](https://arxiv.org/abs/2601.03484)

**Authors**: Kaiyuan Deng, Hangyu Zheng, Minghai Qing, Kunxiong Zhu, Gen Li, Yang Xiao, Lan Emily Zhang, Linke Guo, Bo Hui, Yanzhi Wang, Geng Yuan, Gagan Agrawal, Wei Niu, Xiaolong Ma  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.03484v1  

#### Abstract
Deploying models, especially large language models (LLMs), is becoming increasingly attractive to a broader user base, including those without specialized expertise. However, due to the resource constraints of certain hardware, maintaining high accuracy with larger model while meeting the hardware r...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# From Bits to Chips: An LLM-based Hardware-Aware Quantization Agent for Streamlined Deployment of LLMs  
**æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šçš„éƒ¨ç½²é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **é«˜ç²¾åº¦è¦æ±‚**ï¼šé‡åŒ–åéœ€ä¿æŒæ¨¡å‹æ€§èƒ½ä¸æ˜¾è‘—ä¸‹é™ã€‚
- **ä½è®¡ç®—æˆæœ¬éœ€æ±‚**ï¼šéœ€æ»¡è¶³è¾¹ç¼˜è®¾å¤‡çš„å†…å­˜ä¸ç®—åŠ›é™åˆ¶ã€‚

ç„¶è€Œï¼Œä¼ ç»Ÿé‡åŒ–ä¸éƒ¨ç½²æµç¨‹é«˜åº¦ä¾èµ–ä¸“å®¶æ‰‹åŠ¨è°ƒå‚ï¼Œæ¶‰åŠå¤æ‚çš„è¶…å‚æ•°ä¼˜åŒ–ï¼ˆå¦‚å­¦ä¹ ç‡ã€æ‰¹å¤§å°ï¼‰å’Œç¡¬ä»¶é€‚é…é…ç½®ï¼ˆå¦‚æ ¸å‡½æ•°å¹¶è¡ŒåŒ–ã€å†…å­˜å¸ƒå±€ï¼‰ï¼Œå¯¼è‡´éä¸“å®¶ç”¨æˆ·éš¾ä»¥é«˜æ•ˆéƒ¨ç½²é‡åŒ–æ¨¡å‹ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šHAQAï¼ˆHardware-Aware Quantization Agentï¼‰
æœ¬æ–‡æå‡º **HAQA** â€”â€”ä¸€ç§åŸºäº **Large Language Model (LLM)** çš„è‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œç”¨äºè”åˆä¼˜åŒ–é‡åŒ–æ¨¡å‹å¾®è°ƒä¸ç¡¬ä»¶éƒ¨ç½²å…¨è¿‡ç¨‹ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
- **é¦–æ¬¡å°† LLM Agent åº”ç”¨äºé‡åŒ–ä¸ç¡¬ä»¶éƒ¨ç½²ååŒä¼˜åŒ–**  
  ä¸ä»…ä¼˜åŒ– QAT æˆ– PTQ è¶…å‚æ•°ï¼Œè¿˜è‡ªåŠ¨è°ƒæ•´ CUDA kernel çš„æ‰§è¡Œé…ç½®ï¼ˆå¦‚ `griddim`, `blockdim`, å†…å­˜å±‚çº§ç­‰ï¼‰ï¼Œå®ç°ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–ã€‚
  
- **æ ‡å‡†åŒ–ä¸”ç”¨æˆ·å‹å¥½çš„åŒé˜¶æ®µ Prompt è®¾è®¡**
  - **Static Prompt**ï¼šå›ºå®šä»»åŠ¡æè¿°ï¼ŒåŒ…å«ç¡¬ä»¶è§„æ ¼ã€æ¨¡å‹ç»“æ„ã€æœç´¢ç©ºé—´ç­‰ã€‚
  - **Dynamic Prompt**ï¼šåŠ¨æ€æ›´æ–°è®­ç»ƒ/æ¨ç†åé¦ˆï¼ˆå‡†ç¡®ç‡ã€å»¶è¿Ÿæ—¥å¿—ï¼‰ã€å†å²å†³ç­–è®°å½•ï¼Œæ”¯æŒè¿­ä»£ä¼˜åŒ–ã€‚

- **å¼•å…¥ ReAct æ¨ç†æœºåˆ¶æå‡ç¨³å®šæ€§**
  åœ¨æç¤ºä¸­åµŒå…¥â€œThought â†’ Action â†’ Observationâ€é€»è¾‘é“¾ï¼Œä½¿ LLM å…·å¤‡åæ€èƒ½åŠ›ï¼Œé¿å…æ— æ•ˆæˆ–è¶Šç•Œå°è¯•ï¼Œæé«˜æœç´¢æ•ˆç‡ä¸å¯é æ€§ã€‚

- **è‡ªé€‚åº”é‡åŒ–ç­–ç•¥ï¼ˆAdaptive Quantization Strategyï¼‰**
  HAQA èƒ½è¯†åˆ«åç›´è§‰ä½†æœ€ä¼˜çš„ç¡¬ä»¶é…ç½®ï¼ˆä¾‹å¦‚åœ¨æŸäº›ç§»åŠ¨è®¾å¤‡ä¸Š INT8 æ¯” INT4 æ›´å¿«ï¼‰ï¼Œé€šè¿‡åˆ†æç¡¬ä»¶æ¶æ„ç‰¹æ€§ï¼ˆæŒ‡ä»¤é›†æ”¯æŒã€å†…å­˜å¸¦å®½ã€åŠ é€Ÿå™¨å¯ç”¨æ€§ï¼‰åšå‡ºæ™ºèƒ½é€‰æ‹©ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³•ç±»å‹ | å±€é™æ€§ | HAQA çš„ä¼˜åŠ¿ |
|--------|-------|-------------|
| æ‰‹åŠ¨è°ƒå‚ï¼ˆHuman Tuningï¼‰ | æˆæœ¬é«˜ã€è€—æ—¶é•¿ã€æ˜“é—æ¼æœ€ä¼˜è§£ | è‡ªåŠ¨åŒ–å…¨æµç¨‹ï¼Œé™ä½ä¸“å®¶é—¨æ§› |
| éšæœºæœç´¢ / ç½‘æ ¼æœç´¢ | é«˜ç»´ç©ºé—´æ•ˆç‡ä½ä¸‹ | åˆ©ç”¨ LLM æ¨ç†èƒ½åŠ›èšç„¦æ½œåœ¨åŒºåŸŸ |
| è´å¶æ–¯ä¼˜åŒ– / NSGA-II | ä¾èµ–ä»£ç†æ¨¡å‹ï¼Œè®¡ç®—å¼€é”€å¤§ | æ— éœ€è®­ç»ƒæ¨¡å‹ï¼ŒAPI è°ƒç”¨å³å¯å®Œæˆ |
| ç¼–è¯‘å™¨ä¼˜åŒ–ï¼ˆTVM/Halideï¼‰ | ä¾èµ–å¯å‘å¼è§„åˆ™æˆ–é»‘ç›’è°ƒä¼˜å™¨ | ç»“åˆè¯­ä¹‰ç†è§£ä¸ç¡¬ä»¶æ„ŸçŸ¥è¿›è¡ŒååŒå†³ç­– |

> ğŸ’¡ **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼šHAQA å®ç°äº† **accuracy-speed-usability** ä¸‰è€…çš„ç»Ÿä¸€ï¼Œåœ¨æå‡æ€§èƒ½çš„åŒæ—¶å¤§å¹…ç®€åŒ–éƒ¨ç½²æµç¨‹ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹
| ç±»å‹ | æ¨¡å‹ | æ•°æ®é›† |
|------|------|--------|
| è§†è§‰æ¨¡å‹ | ResNet20, ResNet32, ResNet50 | CIFAR-10, ImageNet2012 |
| å¤§è¯­è¨€æ¨¡å‹ | LLaMA2-7B, LLaMA2-13B, LLaMA3.2-3B, LLaMA3-8B | Alpacaï¼ˆæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼‰ |

### âš™ï¸ å®éªŒè®¾ç½®
- **å¾®è°ƒæ–¹å¼**ï¼š
  - ResNet ä½¿ç”¨ **DoReFa-QAT**
  - LLM ä½¿ç”¨ **QLoRA**ï¼ˆç»“åˆä½æ¯”ç‰¹é‡åŒ–ä¸ä½ç§©é€‚é…ï¼‰
- **é‡åŒ–ä½å®½**ï¼šw8a8, w4a4, w2a2ï¼ˆæƒé‡é‡åŒ–/æ¿€æ´»é‡åŒ–ï¼‰
- **éƒ¨ç½²å¹³å°**ï¼š
  - **æœåŠ¡å™¨çº§ GPU**ï¼šNVIDIA A6000ï¼ˆAmpere æ¶æ„ï¼Œæ”¯æŒ TensorRTï¼‰
  - **ç§»åŠ¨ç«¯ SoC**ï¼šOnePlus 11ï¼ˆSnapdragon 8 Gen 2 + Adreno 740 GPUï¼‰
- **éƒ¨ç½²æ¡†æ¶**ï¼šåŸºäº `llama.cpp` è¿›è¡Œå†…æ ¸çº§ä¼˜åŒ–

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| ç»´åº¦ | æŒ‡æ ‡ |
|------|------|
| **å‡†ç¡®æ€§** | Top-1 å‡†ç¡®ç‡ï¼ˆResNetï¼‰ã€å¤šé¡¹ä»»åŠ¡å¹³å‡å¾—åˆ†ï¼ˆBoolQ, RTE, ARC-E/C, Hellaswag ç­‰ï¼‰ |
| **æ¨ç†æ€§èƒ½** | Token generation speed (tokens/s)ï¼Œå• kernel å»¶è¿Ÿï¼ˆÎ¼sï¼‰ |
| **ç³»ç»Ÿæ•ˆç‡** | ååé‡ã€å†…å­˜å ç”¨ã€æ”¶æ•›è½®æ¬¡ |
| **ç”¨æˆ·ä½“éªŒ** | æ˜¯å¦éœ€è¦äººå·¥å¹²é¢„ã€æ˜¯å¦è¿åçº¦æŸ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Human**ï¼šç»éªŒä¸°å¯Œçš„ç ”ç©¶äººå‘˜æ‰‹åŠ¨è°ƒå‚
- **Local Search / Random Search / Bayesian Optimization**ï¼šç»å…¸è¶…å‚ä¼˜åŒ–ç®—æ³•
- **NSGA-II**ï¼šå¤šç›®æ ‡è¿›åŒ–ç®—æ³•
- **Default**ï¼šåŸå§‹é»˜è®¤é…ç½®ï¼ˆæœªä¼˜åŒ–ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### âœ… è¡¨1 & è¡¨2ï¼šå‡†ç¡®ç‡æ˜¾è‘—ä¼˜äºåŸºçº¿
| æ¨¡å‹ | æ–¹æ³• | å¹³å‡å‡†ç¡®ç‡ï¼ˆvs Humanï¼‰ | æå‡å¹…åº¦ |
|------|------|------------------|----------|
| ResNet20-w4a4 | HAQA | **88.38%** | â†‘6.78pp |
| LLaMA2-7B-INT4 | HAQA | **63.11%** | â†‘1.12pp |
| LLaMA2-13B-INT4 | HAQA | **65.57%** | â†‘1.61pp |
| LLaMA3-8B-INT4 | HAQA | **67.75%** | â†‘1.41pp |

> ğŸ”¹ HAQA åœ¨æ‰€æœ‰é‡åŒ–è®¾ç½®ä¸‹å‡è¶…è¶Šäººç±»ä¸“å®¶å’Œå…¶ä»–è‡ªåŠ¨åŒ–æ–¹æ³•ï¼Œå°¤å…¶åœ¨ä½æ¯”ç‰¹ï¼ˆINT4ï¼‰åœºæ™¯è¡¨ç°æ›´ç¨³å¥ã€‚

#### â±ï¸ å›¾5 & è¡¨3ï¼šæ¨ç†é€Ÿåº¦å¤§å¹…æå‡
| åœºæ™¯ | åŠ é€Ÿæ¯” |
|------|--------|
| æ•´ä½“æ¨¡å‹æ¨ç†ï¼ˆvs llama.cpp é»˜è®¤ï¼‰ | **1.2Ã— ~ 1.5Ã—** |
| MatMul Kernelï¼ˆæœ€å¤§è´Ÿè½½æ“ä½œï¼‰ | æœ€é«˜è¾¾ **1.63Ã—** |
| SiLU Kernel | æœ€é«˜è¾¾ **2.31Ã—** |

> ğŸ”¹ ç‰¹åˆ«æ˜¯åœ¨çŸ©é˜µä¹˜æ³•è¿™ç±»å¯†é›†è®¡ç®—æ“ä½œä¸­ï¼ŒHAQA é€šè¿‡å¯¹ `tiling size` å’Œ `blockdim` çš„ç²¾ç»†è°ƒèŠ‚å®ç°äº†æ˜¾è‘—åŠ é€Ÿã€‚

#### ğŸ“¦ è¡¨4ï¼šç§»åŠ¨ç«¯ååé‡å®æµ‹
| æ¨¡å‹ | FP16 | INT8 | INT4 |
|------|------|------|------|
| openllama-3B | 5.11 | **5.25** | 4.95 |
| tinylama-1.1B | 11.17 | **11.23** | 10.43 |

> ğŸ”¹ å°½ç®¡ INT4 ç†è®ºä¸Šåº”æ›´å¿«ï¼Œä½†åœ¨ OnePlus 11 ä¸Š **INT8 åè€Œååæ›´é«˜**ï¼ŒéªŒè¯äº† HAQA å‘ç°â€œåç›´è§‰æœ€ä¼˜â€çš„èƒ½åŠ›ã€‚

#### ğŸ”„ å›¾4ï¼šæ”¶æ•›é€Ÿåº¦æ›´å¿«æ›´ç¨³å®š
- HAQA åœ¨ **æ›´å°‘è¿­ä»£è½®æ¬¡å†…è¾¾åˆ°æ›´é«˜å‡†ç¡®ç‡**
- ç›¸æ¯”éšæœº/Bayesian æ–¹æ³•ï¼Œå…¶åˆ©ç”¨å†å²åé¦ˆè¿›è¡Œæ¨ç†è§„åˆ’ï¼Œé¿å…é‡å¤æ¢ç´¢æ— æ•ˆåŒºåŸŸ

#### ğŸ’° æˆæœ¬ä¸å¼€é”€åˆ†æï¼ˆAppendix Cï¼‰
- ä½¿ç”¨ GPT-4-0613 API
- å•æ¬¡æŸ¥è¯¢å¹³å‡å»¶è¿Ÿï¼š**2.34 ç§’**
- å®Œæ•´ä¼˜åŒ–æµç¨‹æ€»è´¹ç”¨çº¦ **$5**ï¼ˆ~150K tokensï¼‰
- **æ— éœ€æœ¬åœ° GPU æˆ–å®šåˆ¶åŸºç¡€è®¾æ–½**

> âœ… æä½æˆæœ¬æ¢å–é«˜æ€§èƒ½å¢ç›Šï¼Œæå…·å®ç”¨ä»·å€¼ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **LLM Agent å¯æœ‰æ•ˆæ›¿ä»£ä¸“å®¶è¿›è¡Œå¤æ‚ç³»ç»Ÿçº§ä¼˜åŒ–**
   - HAQA æˆåŠŸå®Œæˆäº†ä»æ¨¡å‹å¾®è°ƒåˆ°ç¡¬ä»¶éƒ¨ç½²çš„å…¨æ ˆä¼˜åŒ–ä»»åŠ¡ã€‚
   - å…¶å†³ç­–è¿‡ç¨‹å…·å¤‡å¯è§£é‡Šæ€§ï¼ˆvia ReActï¼‰ï¼Œä¾¿äºè°ƒè¯•ä¸ä¿¡ä»»å»ºç«‹ã€‚

2. **ç¡¬ä»¶æ„ŸçŸ¥è‡³å…³é‡è¦ï¼Œä¸èƒ½ä»…å‡­ç†è®ºæ¨æ–­**
   - åœ¨ Snapdragon 8 Gen 2 + Adreno 740 ä¸Šï¼Œ**INT8 > INT4 æ€§èƒ½**
   - åŸå› ï¼šINT4 éœ€æ¨¡æ‹Ÿæ‰§è¡Œï¼ˆemulated via INT8ï¼‰ï¼Œé¢å¤–å¼•å…¥ bit-shift æ“ä½œä¸æ•°æ®è½¬æ¢å¼€é”€ï¼Œåè€Œæ‹–æ…¢æ€§èƒ½ã€‚

3. **è”åˆä¼˜åŒ–ä¼˜äºåˆ†æ­¥ä¼˜åŒ–**
   - HAQA åŒæ—¶ä¼˜åŒ–å¾®è°ƒå‚æ•°ä¸éƒ¨ç½²å‚æ•°ï¼Œå®ç°ååŒå¢æ•ˆï¼ˆsynergistic optimizationï¼‰
   - ä¾‹å¦‚è°ƒæ•´ LoRA rank ä¸ä»…å½±å“ accuracyï¼Œä¹Ÿé—´æ¥å½±å“ kernel å¹¶è¡Œæ•ˆç‡

4. **HAQA å…·å¤‡å¼ºæ³›åŒ–æ€§å’Œé€‚åº”æ€§**
   - æ”¯æŒå¤šç§æ¨¡å‹ï¼ˆCNN/Transformerï¼‰ã€å¤šç§ç¡¬ä»¶ï¼ˆGPU/ç§»åŠ¨ç«¯ SoCï¼‰
   - å¯çµæ´»æ‰©å±•è‡³å…¶ä»–ç¼–è¯‘ä¼˜åŒ–ä»»åŠ¡ï¼ˆå¦‚ TVM Relayã€MLIRï¼‰

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–å¤–éƒ¨ LLM API**ï¼šå­˜åœ¨å»¶è¿Ÿã€æˆæœ¬ã€éšç§ç­‰é—®é¢˜ï¼›è‹¥ä½¿ç”¨å¼€æº LLMï¼ˆå¦‚ Llama3ï¼‰å¯èƒ½æ•ˆæœä¸‹é™ã€‚
- **Prompt Engineering æˆæœ¬è¾ƒé«˜**ï¼šéœ€ç²¾å¿ƒè®¾è®¡é™æ€ prompt ä»¥ç¡®ä¿ä»»åŠ¡æ¸…æ™°ã€‚
- **æ— æ³•å®Œå…¨æ›¿ä»£åº•å±‚ç¼–è¯‘å™¨ä¼˜åŒ–**ï¼šå¯¹äºæç«¯æ€§èƒ½å‹æ¦¨ä»éœ€ç»“åˆ TVM/AutoTVM ç­‰å·¥å…·ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ„å»ºä¸“ç”¨å°å‹åŒ– Agent æ¨¡å‹**ï¼šè®­ç»ƒè½»é‡çº§ LLM æ›¿ä»£ GPT-4ï¼Œé™ä½æˆæœ¬ä¸å»¶è¿Ÿã€‚
2. **é›†æˆåˆ° MLOps æµæ°´çº¿**ï¼šä½œä¸º CI/CD ä¸­çš„ä¸€ç¯ï¼Œè‡ªåŠ¨å®Œæˆæ¨¡å‹å‹ç¼©ä¸éƒ¨ç½²ã€‚
3. **æ”¯æŒæ›´å¤šç¡¬ä»¶åç«¯**ï¼šæ‰©å±•è‡³ NPUã€TPUã€FPGA ç­‰ä¸“ç”¨åŠ é€Ÿå™¨ã€‚
4. **å¢å¼ºå®‰å…¨æ€§ä¸é²æ£’æ€§æ£€æµ‹**ï¼šé˜²æ­¢ç”Ÿæˆæ¶æ„ä»£ç æˆ–è¶Šæƒé…ç½®ã€‚

---

## âœ… æ€»ç»“
**HAQA æ˜¯é¦–ä¸ªå°† LLM Agent åº”ç”¨äºé‡åŒ–ä¸ç¡¬ä»¶éƒ¨ç½²ååŒä¼˜åŒ–çš„æ¡†æ¶**ï¼Œå®ƒä¸ä»…æå‡äº†æ¨¡å‹ç²¾åº¦ä¸æ¨ç†é€Ÿåº¦ï¼Œæ›´é‡è¦çš„æ˜¯æå¤§åœ°é™ä½äº†éƒ¨ç½²é—¨æ§›ï¼Œä½¿å¾—éä¸“å®¶ä¹Ÿèƒ½è½»æ¾å®Œæˆå¤æ‚çš„ LLM éƒ¨ç½²ä»»åŠ¡ã€‚å…¶å®éªŒç»“æœè¯æ˜äº† LLM åœ¨ç³»ç»Ÿä¼˜åŒ–é¢†åŸŸçš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºâ€œAI for Systemsâ€å¼€è¾Ÿäº†æ–°çš„ç ”ç©¶è·¯å¾„ã€‚

</details>

---

### 3. [LUT-KAN: Segment-wise LUT Quantization for Fast KAN Inference](https://arxiv.org/abs/2601.03332)

**Authors**: Oleksandr Kuznetsov  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.03332v1  

#### Abstract
Kolmogorov--Arnold Networks (KAN) replace scalar weights by learnable univariate functions, often implemented with B-splines. This design can be accurate and interpretable, but it makes inference expensive on CPU because each layer requires many spline evaluations. Standard quantization toolchains a...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# LUT-KAN: Segment-wise LUT Quantization for Fast KAN Inference â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

Kolmogorov-Arnold Networks (KAN) é€šè¿‡å°†ä¼ ç»Ÿç¥ç»ç½‘ç»œä¸­çš„æ ‡é‡æƒé‡æ›¿æ¢ä¸ºå¯å­¦ä¹ çš„ä¸€å…ƒå‡½æ•°ï¼ˆé€šå¸¸åŸºäº B-splines å®ç°ï¼‰ï¼Œåœ¨ä¿æŒæ¨¡å‹ç´§å‡‘æ€§å’Œé«˜è§£é‡Šæ€§çš„åŒæ—¶æå‡äº†é¢„æµ‹ç²¾åº¦ã€‚ç„¶è€Œï¼Œè¿™ç§è®¾è®¡å¸¦æ¥äº†æ˜¾è‘—çš„æ¨ç†å¼€é”€ï¼Œå°¤å…¶æ˜¯åœ¨ CPU ä¸Šï¼Œå› ä¸ºæ¯ä¸ªå±‚éƒ½éœ€è¦è¿›è¡Œå¤§é‡ B-spline å‡½æ•°æ±‚å€¼æ“ä½œã€‚

æ­¤å¤–ï¼Œæ ‡å‡†çš„é‡åŒ–å·¥å…·é“¾ï¼ˆå¦‚ç”¨äº CNN/MLP çš„ INT8 GEMMï¼‰éš¾ä»¥ç›´æ¥åº”ç”¨äº KANï¼Œå› ä¸ºå…¶è®¡ç®—æ ¸å¿ƒä¸æ˜¯çŸ©é˜µä¹˜æ³•ï¼Œè€Œæ˜¯é‡å¤çš„æ ·æ¡åŸºå‡½æ•°è®¡ç®—ã€‚å› æ­¤ï¼Œ**å¦‚ä½•å®ç°é«˜æ•ˆã€å¯éƒ¨ç½²ã€ä¸”è¯­ä¹‰æ˜ç¡®çš„ KAN æ¨ç†åŠ é€Ÿ**æˆä¸ºä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **LUT-KAN**ï¼Œä¸€ç§é¢å‘ PyKAN é£æ ¼ KAN å±‚çš„**åˆ†æ®µæŸ¥æ‰¾è¡¨ï¼ˆsegment-wise LUTï¼‰ç¼–è¯‘ä¸é‡åŒ–æ–¹æ³•**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ï¼š

1. **Segment-wise LUT ç¼–è¯‘**  
   å°†æ¯æ¡è¾¹ä¸Šçš„å¯å­¦ä¹ ä¸€å…ƒå‡½æ•° $\phi_i(x)$ åˆ†æ®µç¼–è¯‘æˆ LUTï¼Œæ¯æ®µï¼ˆç”± knot å®šä¹‰ï¼‰å­˜å‚¨ $L$ ä¸ªé‡‡æ ·ç‚¹çš„é‡åŒ–å€¼ï¼Œå¹¶æ”¯æŒçº¿æ€§æ’å€¼ã€‚

2. **Affine int8/uint8 é‡åŒ–**  
   åœ¨æ¯ä¸ª segment ä¸Šé‡‡ç”¨ä»¿å°„é‡åŒ–ï¼ˆaffine quantizationï¼‰ï¼Œæ”¯æŒå¯¹ç§° int8 å’Œéå¯¹ç§° uint8 ä¸¤ç§æ¨¡å¼ï¼Œç»Ÿä¸€åé‡åŒ–å…¬å¼ä»¥ç®€åŒ–éƒ¨ç½²ã€‚

3. **æ˜¾å¼çš„ OOBï¼ˆOut-of-Boundsï¼‰è¯­ä¹‰å®šä¹‰**  
   æ˜ç¡®å®šä¹‰è¾“å…¥è¶…å‡º knot èŒƒå›´æ—¶çš„è¡Œä¸ºï¼Œé€šè¿‡ä¸¤ä¸ªæ­£äº¤é…ç½®æ§åˆ¶ï¼š
   - `boundary_mode`: `half_open` æˆ– `closed`
   - `oob_policy`: `clip_x`ï¼ˆé¥±å’Œè¾“å…¥ï¼‰æˆ– `zero_spline`ï¼ˆæŠ‘åˆ¶æ ·æ¡è¾“å‡ºï¼‰

4. **â€œè¯šå®åŸºçº¿â€è¯„ä¼°æ–¹æ³•è®ºï¼ˆHonest Baseline Methodologyï¼‰**  
   ä¸ºé¿å…å› åç«¯ä¼˜åŒ–å·®å¼‚å¯¼è‡´çš„é€Ÿåº¦æ¯”è¾ƒå¤±çœŸï¼Œä½œè€…æå‡ºåœ¨åŒä¸€åç«¯ï¼ˆNumPy vs NumPyï¼ŒNumba vs Numbaï¼‰ä¸‹å¯¹æ¯” B-spline ä¸ LUT çš„æ€§èƒ½ï¼Œä»è€Œåˆ†ç¦»å‡ºâ€œè¡¨ç¤ºå½¢å¼â€æœ¬èº«å¸¦æ¥çš„åŠ é€Ÿæ•ˆæœã€‚

5. **è½»é‡çº§å¯ç§»æ¤æ¨ç†æ ¼å¼**  
   è¾“å‡ºä¸ºå‹ç¼©çš„ `.npz` æ–‡ä»¶ + JSON æ¸…å•ï¼Œå¯åœ¨æ—  PyTorch å’Œæ ·æ¡åº“ä¾èµ–çš„æƒ…å†µä¸‹åŠ è½½æ‰§è¡Œï¼Œé€‚åˆè¾¹ç¼˜éƒ¨ç½²ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | LUT-KAN çš„ä¼˜åŠ¿ |
|------|----------------|
| **æ¨ç†é€Ÿåº¦** | åœ¨ç›¸åŒåç«¯ä¸‹å®ç° 10â€“14Ã— åŠ é€Ÿï¼ˆNumPyï¼‰ï¼Œ9.5â€“11Ã—ï¼ˆNumbaï¼‰ï¼Œè¿œè¶…ä¼ ç»Ÿè½¯ä»¶æ ˆå·®å¼‚å¸¦æ¥çš„æå‡ |
| **éƒ¨ç½²å‹å¥½æ€§** | ä¸ä¾èµ– PyTorchï¼Œæ¨ç†è·¯å¾„æç®€ï¼Œé€‚åˆè¾¹ç¼˜è®¾å¤‡ |
| **è¯­ä¹‰ä¸€è‡´æ€§** | æ˜¾å¼å®šä¹‰ OOB è¡Œä¸ºï¼Œç¡®ä¿è·¨å¹³å°è¡Œä¸ºä¸€è‡´ï¼Œæå‡å¯å¤ç°æ€§ |
| **é‡åŒ–å¯æ§æ€§** | æ”¯æŒ per-segment é‡åŒ–ï¼Œä¿ç•™ base branch è§£æè¡¨è¾¾å¼ï¼ˆ`spline_component` è¡¨ç¤ºï¼‰ï¼Œå‡å°‘è¯¯å·® |
| **å…¬å¹³è¯„ä¼°** | â€œè¯šå®åŸºçº¿â€æ–¹æ³•é¿å…äº†å‘é‡åŒ–/JIT æ•ˆåº”å¹²æ‰°çœŸå®æ€§èƒ½å¯¹æ¯” |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **åˆæˆå®éªŒï¼ˆControlled Sweepsï¼‰**ï¼šéšæœºåˆå§‹åŒ–çš„ KAN å±‚ï¼ˆinput=10, output=8, grid=8, degree=3ï¼‰ï¼Œç”¨äºæ§åˆ¶å˜é‡åˆ†æã€‚
- **çœŸå®ä»»åŠ¡æ¡ˆä¾‹ç ”ç©¶ï¼ˆCase Studyï¼‰**ï¼šåŸºäº **CICIDS2017** æ•°æ®é›†çš„ DoS æ”»å‡»æ£€æµ‹ä»»åŠ¡ï¼Œç”¨äºéªŒè¯å®é™…éƒ¨ç½²æ•ˆæœã€‚

### **å®éªŒè®¾ç½®**

- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š
  - CPU: AMD Ryzen 7 7840HS (8 cores / 16 threads)
  - RAM: 64GB DDR5
  - å•çº¿ç¨‹è¿è¡Œï¼ˆ`OMP_NUM_THREADS=1`, `NUMBA_NUM_THREADS=1`ï¼‰
- **è½¯ä»¶ç‰ˆæœ¬**ï¼š
  - Python 3.11.7, NumPy 1.26.3, Numba 0.59.0, PyTorch 2.1.2 (CPU)

### **è¯„ä¼°æŒ‡æ ‡**

| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **å‡†ç¡®æ€§** | MAEï¼ˆin-range / OOBï¼‰ã€MaxAbs Errorã€ä¸‹æ¸¸åˆ†ç±»æŒ‡æ ‡ï¼ˆAccuracy, Precision, Recall, F1ï¼‰ |
| **é€Ÿåº¦** | Steady-state latency (ms/iter, ms/sample)ï¼ŒSpeedupï¼ˆç›¸å¯¹äºåŒåç«¯ B-splineï¼‰ |
| **å†…å­˜** | LUT artifact å¤§å°ã€ä¸åŸå§‹ float æ¨¡å‹çš„å†…å­˜å¼€é”€æ¯”ï¼ˆLUT/Modelï¼‰ |
| **é²æ£’æ€§** | OOB è§¦å‘ç‡ï¼ˆOOB_any_fracï¼‰ã€ä¸åŒ boundary/oob_policy ä¸‹çš„è¡¨ç°çŸ©é˜µ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **ä¸å…¬å¹³åŸºçº¿ï¼ˆStack-levelï¼‰**ï¼šPyTorch æµ®ç‚¹æ¨ç† vs LUT + NumPy/Numba
- **è¯šå®åŸºçº¿ï¼ˆHonest Baselineï¼‰**ï¼š
  - NumPy B-spline vs NumPy LUT
  - Numba B-spline vs Numba LUT  
  ï¼ˆä¸¤è€…å‡åœ¨åŒä¸€åç«¯ã€ç›¸åŒæ‰¹å¤§å°ã€ç›¸åŒè¿­ä»£åè®®ä¸‹æµ‹è¯•ï¼‰

### **æ¶ˆèå®éªŒå‚æ•°æ‰«æ**

- LUT åˆ†è¾¨ç‡ $L \in \{16, 32, 64, 128\}$
- é‡åŒ–æ–¹æ¡ˆï¼šsymmetric int8 vs asymmetric uint8
- boundary_modeï¼šclosed vs half_open
- oob_policyï¼šclip_x vs zero_spline
- value_reprï¼šphi vs spline_component
- æ‰€æœ‰é…ç½®é‡å¤ 5 æ¬¡ï¼ˆç§å­ 0â€“4ï¼‰ï¼ŒæŠ¥å‘Š mean Â± std

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **æ¨ç†é€Ÿåº¦ï¼ˆHonest Baselineï¼‰**

| åç«¯ | å¹³å‡ Speedup | èŒƒå›´ |
|------|--------------|------|
| **NumPy** | **12.3Ã—** | 11.4â€“14.0Ã— |
| **Numba** | **10.5Ã—** | 9.5â€“11.1Ã— |

> æ³¨ï¼šå°½ç®¡ Numba å·²å¯¹ B-spline è¿›è¡Œ JIT ä¼˜åŒ–ï¼ŒLUT ä»èƒ½å¸¦æ¥çº¦ 10Ã— åŠ é€Ÿï¼Œè¯´æ˜åŠ é€Ÿæ¥è‡ªè¡¨ç¤ºå½¢å¼æœ¬èº«ã€‚

#### âœ… **å†…å­˜å¼€é”€**

| $L$ | å†…å­˜å¼€é”€å€æ•°ï¼ˆLUT / Float Modelï¼‰ |
|-----|-------------------------------|
| 16  | 3.07Ã— |
| 32  | 5.51Ã— |
| **64** | **10.40Ã—** |
| 128 | 20.18Ã— |

> ä¸»è¦å¼€é”€æ¥è‡ª `q_table`ï¼ˆå æ¯” 73â€“88%ï¼‰ï¼Œå…¶ä½™ä¸º scale/y_min/knots å…ƒæ•°æ®ã€‚

#### âœ… **è¿‘ä¼¼è¯¯å·®ï¼ˆ$L=64$ï¼‰**

| é‡åŒ–æ–¹å¼ | MAE (in-range) | MaxAbs (in-range) |
|---------|----------------|--------------------|
| int8 (symmetric) | 1.59e-4 Â± 1.0e-5 | 8.02e-4 Â± 5.4e-5 |
| uint8 (asymmetric) | 1.58e-4 Â± 1.1e-5 | 8.33e-4 Â± 5.6e-5 |

> è¯¯å·®éš $L$ å¢å¤§å‘ˆ $O(1/L)$ è¡°å‡ï¼Œè¡¨æ˜æ’å€¼è¯¯å·®ä¸»å¯¼ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| å¯¹æ¯”ç»´åº¦ | ç»“æœ |
|--------|------|
| **Stack-level Speedup (PyTorch â†’ Numba LUT)** | é«˜è¾¾ **64.4Ã—**ï¼ˆä½†åŒ…å«åç«¯åˆ‡æ¢æ•ˆåº”ï¼‰ |
| **Honest Baseline Speedup** | **~12Ã— (NumPy), ~10Ã— (Numba)**ï¼Œè¯æ˜è¡¨ç¤ºå½¢å¼æœ¬èº«æœ‰æ•ˆ |
| **åˆ†ç±»è´¨é‡ä¿ç•™ï¼ˆDoS æ£€æµ‹ï¼‰** | F1 ä»…ä¸‹é™ **0.0002**ï¼ˆä» 0.9900 â†’ 0.9898ï¼‰ï¼Œå…¶ä»–æŒ‡æ ‡å‡ ä¹ä¸å˜ |
| **å†…å­˜å¼€é”€ï¼ˆçœŸå®æ¨¡å‹ï¼‰** | æ€» LUT artifact ä¸º 2.26MBï¼Œæ˜¯åŸæ¨¡å‹ï¼ˆ200KBï¼‰çš„ **11.29Ã—**ï¼Œä¸ç†è®ºé¢„æµ‹ä¸€è‡´ |

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ğŸ” **é‡åŒ–æ–¹æ¡ˆå½±å“ï¼ˆ$L=64$ï¼‰**

| æ–¹æ¡ˆ | MAE (in-range) | MaxAbs (OOB, zero_spline) |
|------|----------------|----------------------------|
| symmetric int8 | 1.59e-4 | 0.0892 |
| asymmetric uint8 | 1.58e-4 | 0.0915 |

> ä¸¤è€…æ€§èƒ½ç›¸è¿‘ï¼Œåœ¨é›¶ä¸­å¿ƒåˆ†å¸ƒä¸‹å·®å¼‚ä¸æ˜¾è‘—ã€‚

#### ğŸ” **OOB é²æ£’æ€§çŸ©é˜µï¼ˆ$L=64$, half_openï¼‰**

| boundary_mode | oob_policy | OOB_frac | MAE(OOB) | MaxAbs(OOB) |
|-------------|------------|----------|----------|------------|
| closed | clip_x | 0.000 | N/A | N/A |
| half_open | clip_x | 10.1% | 3.12e-4 | 6.61e-4 |
| half_open | zero_spline | 10.1% | 2.45e-2 | **8.92e-2** |

> `zero_spline` åœ¨ OOB è¾“å…¥ä¸Šå¯èƒ½å¯¼è‡´è¾ƒå¤§åå·®ï¼Œéœ€è°¨æ…é€‰æ‹©ç­–ç•¥ã€‚

#### ğŸ” **value_repr æ¶ˆè**
- `spline_component` æ›´ä¼˜ï¼šä¿ç•™ base branchï¼ˆå¦‚ SiLUï¼‰è§£æè®¡ç®—ï¼Œé¿å…é‡åŒ–è¯¯å·®ï¼Œæå‡æ•ˆç‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **LUT-KAN æ˜¾è‘—åŠ é€Ÿ KAN æ¨ç†**  
   åœ¨å»é™¤åç«¯ä¼˜åŒ–å¹²æ‰°åï¼Œä»å¯å®ç° **10â€“14Ã— çš„çœŸå®åŠ é€Ÿ**ï¼Œé€‚ç”¨äºè¾¹ç¼˜å’Œå®æ—¶åœºæ™¯ã€‚

2. **ç²¾åº¦æŸå¤±æå°**  
   åœ¨ $L=64$ ä¸‹ï¼Œå‡½æ•°çº§ MAE çº¦ä¸º $1.6\times10^{-4}$ï¼Œä¸‹æ¸¸ä»»åŠ¡ F1 ä¸‹é™å°äº 0.0002ï¼Œå¯è§†ä¸ºæ— æŸéƒ¨ç½²ã€‚

3. **OOB è¯­ä¹‰å¿…é¡»æ˜¾å¼å®šä¹‰**  
   ä¸åŒ `boundary_mode` å’Œ `oob_policy` ç»„åˆä¼šå¯¼è‡´æ˜¾è‘—ä¸åŒçš„ OOB è¡Œä¸ºï¼Œå°¤å…¶å½“é¢„å¤„ç†ä½¿ç”¨ clipping æ—¶ï¼Œ`half_open` å¯èƒ½è¯¯åˆ¤è¾¹ç•Œç‚¹ä¸º OOBã€‚

4. **å†…å­˜æ˜¯ä¸»è¦ä»£ä»·**  
   LUT å­˜å‚¨å¼€é”€çº¦ä¸ºåŸå§‹æ¨¡å‹çš„ **10Ã—ï¼ˆ$L=64$ï¼‰**ï¼Œé¦–å±‚å› è¾¹æ•°å¤šæˆä¸ºç“¶é¢ˆï¼ˆå  82.5%ï¼‰ã€‚

5. **â€œè¯šå®åŸºçº¿â€è‡³å…³é‡è¦**  
   è‹¥ä¸æ§åˆ¶åç«¯ä¸€è‡´æ€§ï¼Œå¯èƒ½é«˜ä¼° LUT å¸¦æ¥çš„æ”¶ç›Šï¼Œè¯¯å¯¼æŠ€æœ¯åˆ¤æ–­ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™æ€§ | è¯´æ˜ |
|-------|------|
| **å†…å­˜å¼€é”€å¤§** | å¯†é›†å±‚è¾¹æ•°å¤šæ—¶ LUT è¡¨ä½“ç§¯å·¨å¤§ï¼Œä¸é€‚åˆæç«¯å†…å­˜å—é™è®¾å¤‡ |
| **é™æ€ç¼–è¯‘** | æ¨¡å‹æ›´æ–°éœ€é‡æ–°ç¼–è¯‘ LUTï¼Œä¸æ”¯æŒåœ¨çº¿å¾®è°ƒæˆ–è‡ªé€‚åº” |
| **éå…¨æ•´æ•°é‡åŒ–** | å½“å‰ä»ä½¿ç”¨ float32 è¿›è¡Œåé‡åŒ–å’Œ base branch è®¡ç®—ï¼Œæœªå®ç°ç«¯åˆ°ç«¯æ•´æ•°æ¨ç† |
| **æ ¡å‡†æ•æ„Ÿæ€§** | é‡åŒ–èŒƒå›´ä¾èµ–æ ¡å‡†æ•°æ®åˆ†å¸ƒï¼Œè‹¥éƒ¨ç½²æ•°æ®åç§»å¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ |
| **å•ç²¾åº¦å‚æ•°å­˜å‚¨** | scale å’Œ y_min ä½¿ç”¨ float32ï¼Œå¯ç”¨ float16 è¿›ä¸€æ­¥å‹ç¼©ä½†å¯èƒ½å¼•å…¥æ•°å€¼è¯¯å·® |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **ç¨€ç– LUT è¡¨ç¤º**ï¼šç»“åˆç½‘ç»œå‰ªææˆ–é‡è¦æ€§è¯„åˆ†ï¼Œåªä¿ç•™å…³é”®è¾¹çš„ LUTã€‚
2. **ä½ç§©æˆ–å› å­åŒ–ç»“æ„**ï¼šå‡å°‘ dense layer çš„è¾¹æ•°å¢é•¿ã€‚
3. **å…¨æ•´æ•°æ¨ç†æµæ°´çº¿**ï¼šæ¢ç´¢å®Œå…¨ int8/int16 çš„ç´¯ç§¯ä¸æ¿€æ´»è·¯å¾„ã€‚
4. **åŠ¨æ€/è‡ªé€‚åº”é‡åŒ–**ï¼šæ ¹æ®è¾“å…¥åˆ†å¸ƒè°ƒæ•´é‡åŒ–å‚æ•°ã€‚
5. **æ”¯æŒæ›´å¤šå‡½æ•°åŸºåº•**ï¼šæ‰©å±•è‡³ Chebyshevã€RBF ç­‰ KAN å˜ä½“ã€‚
6. **ç¡¬ä»¶ååŒä¼˜åŒ–**ï¼šé’ˆå¯¹ MCU/FPGA è®¾è®¡å®šåˆ¶ LUT æ¨ç†å¼•æ“ã€‚

---

> âœ… **ä»£ç ä¸å¤ç°æ€§**ï¼šæ‰€æœ‰ä»£ç ã€å®éªŒè„šæœ¬ã€æ¨¡å‹ artifact å‡å·²å¼€æºï¼Œå¸¦å›ºå®š release tag (`v1.0.0`)ï¼Œç¡®ä¿ç»“æœå¯å¤ç°ã€‚  
> ğŸ”— GitHub: [https://github.com/KuznetsovKarazin/lut-kan](https://github.com/KuznetsovKarazin/lut-kan)

</details>

---

### 4. [Robust Physics Discovery from Highly Corrupted Data: A PINN Framework Applied to the Nonlinear Schr\"odinger Equation](https://arxiv.org/abs/2601.04176)

**Authors**: Pietro de Oliveira Esteves  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.04176v1  

#### Abstract
We demonstrate a deep learning framework capable of recovering physical parameters from the Nonlinear Schrodinger Equation (NLSE) under severe noise conditions. By integrating Physics-Informed Neural Networks (PINNs) with automatic differentiation, we achieve reconstruction of the nonlinear coeffici...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Robust Physics Discovery from Highly Corrupted Data: A PINN Framework Applied to the Nonlinear SchrÃ¶dinger Equation*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**åœ¨é«˜å™ªå£°ã€ç¨€ç–è§‚æµ‹æ¡ä»¶ä¸‹ä»å®éªŒæ•°æ®ä¸­æ¢å¤éçº¿æ€§ç‰©ç†ç³»ç»Ÿå‚æ•°**è¿™ä¸€æŒ‘æˆ˜æ€§é€†é—®é¢˜å±•å¼€ç ”ç©¶ã€‚å…·ä½“èšç„¦äº**éçº¿æ€§è–›å®šè°”æ–¹ç¨‹ï¼ˆNonlinear SchrÃ¶dinger Equation, NLSEï¼‰ä¸­çš„éçº¿æ€§ç³»æ•° $ \beta $ çš„è¯†åˆ«é—®é¢˜**ã€‚

ç°å®ä¸­çš„å®éªŒæ•°æ®é€šå¸¸å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
- æ•°æ®ç¨€ç–ï¼ˆä¼ æ„Ÿå™¨æ•°é‡æœ‰é™ï¼‰
- å«æœ‰é«˜è¾¾ 20% çš„åŠ æ€§é«˜æ–¯å™ªå£°
- æ•°å€¼å¾®åˆ†æ–¹æ³•å› å™ªå£°æ”¾å¤§è€Œå¤±æ•ˆ

ä¼ ç»ŸåŸºäºæœ‰é™å·®åˆ† + ä¼˜åŒ–çš„æ–¹æ³•åœ¨æ­¤ç±»åœºæ™¯ä¸‹è¡¨ç°ä¸ç¨³å®šï¼Œéš¾ä»¥å‡†ç¡®ä¼°è®¡ç‰©ç†å‚æ•°ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åŸºäº **Physics-Informed Neural Networks (PINNs)** çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºä»ä¸¥é‡æ±¡æŸ“çš„æ•°æ®ä¸­é²æ£’åœ°å‘ç°ç‰©ç†è§„å¾‹å¹¶ç²¾ç¡®è¯†åˆ« NLSE ä¸­çš„å…³é”®å‚æ•° $ \beta $ã€‚

#### åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š
- **å°†ç‰©ç†æ­£åˆ™åŒ–ä½œä¸ºå™ªå£°è¿‡æ»¤å™¨**ï¼šé€šè¿‡å°† NLSE æ˜¾å¼åµŒå…¥ç¥ç»ç½‘ç»œçš„æŸå¤±å‡½æ•°ä¸­ï¼ŒPINN èƒ½å¤Ÿåˆ©ç”¨ç‰©ç†å…ˆéªŒçŸ¥è¯†â€œè¿‡æ»¤â€æ‰æµ‹é‡å™ªå£°çš„å½±å“ï¼Œå®ç°å¯¹çœŸå®åŠ¨åŠ›å­¦çš„é‡å»ºã€‚
- **å®Œå…¨æ— ååˆå§‹åŒ–**ï¼šå°†å¾…è¯†åˆ«å‚æ•° $ \beta $ è§†ä¸ºå¯è®­ç»ƒå˜é‡ï¼Œå¹¶ä» $ \beta = 0.0 $ å¼€å§‹è®­ç»ƒï¼Œé¿å…å…ˆéªŒåå·®ï¼Œç¡®ä¿å‚æ•°æ¢å¤æ˜¯çº¯æ•°æ®é©±åŠ¨ä¸”å—ç‰©ç†çº¦æŸå¼•å¯¼çš„ç»“æœã€‚
- **è‡ªåŠ¨å¾®åˆ†æ›¿ä»£æ•°å€¼å¾®åˆ†**ï¼šä½¿ç”¨ PyTorch çš„è‡ªåŠ¨å¾®åˆ†æœºåˆ¶è®¡ç®—åå¯¼æ•°ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­å› æœ‰é™å·®åˆ†å¯¼è‡´çš„å™ªå£°æ”¾å¤§é—®é¢˜ã€‚
- **é«˜å™ªå£°ä¸‹çš„ç¨³å®šæ€§éªŒè¯**ï¼šç³»ç»Ÿæµ‹è¯•äº†åœ¨ 20% é«˜æ–¯å™ªå£°ä¸‹ä¸åŒ $ \beta $ å€¼å’Œä¸åŒæ•°æ®å¯†åº¦æ¡ä»¶ä¸‹çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†æ–¹æ³•çš„æ³›åŒ–èƒ½åŠ›ä¸é²æ£’æ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚æœ‰é™å·®åˆ† + L-BFGSï¼‰ | æœ¬æ–‡ PINN æ–¹æ³• |
|------|-------------------------------|----------------|
| å™ªå£°æ•æ„Ÿæ€§ | æé«˜ï¼ˆæ•°å€¼å¾®åˆ†ä¼šæ”¾å¤§å™ªå£°ï¼‰ | ä½ï¼ˆç‰©ç†æŸå¤±é¡¹èµ·æ­£åˆ™åŒ–ä½œç”¨ï¼‰ |
| æ•°æ®éœ€æ±‚ | éœ€å¯†é›†ã€è§„åˆ™ç½‘æ ¼æ•°æ® | æ”¯æŒç¨€ç–ã€éšæœºé‡‡æ ·æ•°æ® |
| æ­£åˆ™åŒ–è°ƒå‚ | æ‰‹åŠ¨è°ƒæ•´ Tikhonov å‚æ•°å›°éš¾ | ç‰©ç†æ–¹ç¨‹å¤©ç„¶æä¾›éšå¼æ­£åˆ™åŒ– |
| å®ç°å¤æ‚åº¦ | å¤šæ­¥éª¤æµç¨‹ï¼ˆæ’å€¼+æ±‚å¯¼+ä¼˜åŒ–ï¼‰ | ç«¯åˆ°ç«¯ç»Ÿä¸€æ¡†æ¶ |
| å¯æ‰©å±•æ€§ | å¯¹ä¸è§„åˆ™å‡ ä½•é€‚åº”å·® | æ˜“æ¨å¹¿è‡³å¤æ‚åŸŸ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼šPINNs åœ¨é«˜å™ªå£°ã€å°æ ·æœ¬æ¡ä»¶ä¸‹å±•ç°å‡ºå“è¶Šçš„é²æ£’æ€§å’Œç²¾åº¦ï¼Œæ˜¾è‘—ä¼˜äºä¾èµ–æ•°å€¼å¾®åˆ†çš„ä¼ ç»Ÿæ–¹æ³•ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- å¹¶æœªä½¿ç”¨çœŸå®å®éªŒæ•°æ®ï¼Œè€Œæ˜¯é€šè¿‡**æ•°å€¼æ¨¡æ‹Ÿç”Ÿæˆ NLSE çš„ç²¾ç¡®è§£ï¼ˆground truthï¼‰**
- åœ¨çœŸå®è§£ä¸Šæ·»åŠ  **20% åŠ æ€§é«˜æ–¯å™ªå£°**ï¼Œæ¨¡æ‹Ÿé«˜åº¦ corrupted çš„å®éªŒæµ‹é‡
- è®­ç»ƒæ•°æ®ç‚¹ $ N_u \in [100, 1000] $ï¼Œéšæœºé‡‡æ ·è‡ªæ—¶ç©ºåŸŸ $ x \in [-5,5], t \in [0, \pi/2] $
- ä½¿ç”¨ **Latin Hypercube Sampling (LHS)** é€‰å– 20,000 ä¸ª collocation points ç”¨äºç‰©ç†æ®‹å·®è®¡ç®—

---

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼š
  - Fully Connected DNNï¼Œè¾“å…¥ $(x,t)$ï¼Œè¾“å‡º $(u,v)$ï¼ˆå³å¤åœºå®éƒ¨ä¸è™šéƒ¨ï¼‰
  - 4 å±‚éšè—å±‚ Ã— 50 ç¥ç»å…ƒï¼Œæ¿€æ´»å‡½æ•°ä¸º `tanh`
  - æ€»å‚æ•°çº¦ 10,000
- **ä¼˜åŒ–å™¨**ï¼šAdam ($\text{lr} = 10^{-3}$)ï¼Œè®­ç»ƒ 10,000 è½®
- **æŸå¤±å‡½æ•°**ï¼š
  $$
  \mathcal{L} = \lambda_{\text{data}} \mathcal{L}_{\text{data}} + \lambda_{\text{physics}} \mathcal{L}_{\text{physics}}, \quad \lambda_{\text{data}} = \lambda_{\text{physics}} = 1.0
  $$
  - $\mathcal{L}_{\text{data}}$: MSE æŸå¤±ï¼ˆé¢„æµ‹ vs å™ªå£°æ•°æ®ï¼‰
  - $\mathcal{L}_{\text{physics}}$: PDE æ®‹å·®æŸå¤±ï¼ˆé€šè¿‡è‡ªåŠ¨å¾®åˆ†è®¡ç®—ï¼‰

- **ç¡¬ä»¶å¹³å°**ï¼šGoogle Colab ä¸Šçš„ NVIDIA Tesla T4 GPUï¼ˆ15GB VRAMï¼‰ï¼Œæ€»è€—æ—¶ ~80 åˆ†é’Ÿå®Œæˆå…¨éƒ¨å®éªŒæµç¨‹

---

### è¯„ä¼°æŒ‡æ ‡
- **ç›¸å¯¹è¯¯å·®ï¼ˆRelative Errorï¼‰**ï¼šç”¨äºè¡¡é‡ä¼°è®¡çš„ $ \hat{\beta} $ ä¸çœŸå€¼ä¹‹é—´çš„åå·®
  $$
  \text{Error}(\%) = \frac{|\hat{\beta} - \beta_{\text{true}}|}{\beta_{\text{true}}} \times 100\%
  $$
- **ç»Ÿè®¡ç¨³å®šæ€§**ï¼šå¤šæ¬¡ç‹¬ç«‹è¿è¡Œçš„æ ‡å‡†å·®ï¼ˆstd. dev.ï¼‰
- **å¯è§†åŒ–åˆ†æ**ï¼šæ—¶ç©ºè¯¯å·®çƒ­å›¾ã€æ—¶é—´åˆ‡ç‰‡å¯¹æ¯”å›¾ã€æŸå¤±æ›²çº¿æ¼”åŒ–
- **æ¶ˆèå®éªŒ**ï¼šè€ƒå¯Ÿä¸åŒè®­ç»ƒæ•°æ®é‡ $ N_u $ å¯¹æ€§èƒ½å½±å“

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ–‡ä¸­è™½æœªç›´æ¥è¿è¡Œä¼ ç»Ÿæ–¹æ³•è¿›è¡Œæ¨ªå‘æ¯”è¾ƒï¼Œä½†å¼•ç”¨æ–‡çŒ®æŒ‡å‡ºï¼š
- ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ SINDy æˆ–æœ‰é™å·®åˆ† + ä¼˜åŒ–ï¼‰åœ¨ >10% å™ªå£°ä¸‹å³å‡ºç°ä¸¥é‡å¤±ç¨³
- æ•°å€¼å¾®åˆ†è¯¯å·®éšç½‘æ ¼å°ºåº¦å¹³æ–¹åæ¯”å¢é•¿ï¼ˆ$ e_{\text{derivative}} \sim e_{\text{data}} / h^2 $ï¼‰ï¼Œææ˜“æ”¾å¤§å™ªå£°
- å› æ­¤ï¼Œåœ¨ 20% å™ªå£°ç¯å¢ƒä¸‹ï¼Œä¼ ç»Ÿæ–¹æ³•é€šå¸¸æ— æ³•æ”¶æ•›æˆ–äº§ç”Ÿé”™è¯¯å‚æ•°ä¼°è®¡

> ä½œè€…å¼ºè°ƒï¼ŒPINN åœ¨æ­¤ç±»æç«¯å™ªå£°æ¡ä»¶ä¸‹ä»èƒ½ä¿æŒ <1% çš„è¯†åˆ«è¯¯å·®ï¼Œè¡¨æ˜å…¶å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & 2ï¼‰

#### ä¸åŒ $ \beta $ ä¸‹çš„è¯†åˆ«ç²¾åº¦ï¼ˆ$ N_u = 500 $, 20% å™ªå£°ï¼‰
| çœŸå® $ \beta $ | ç›¸å¯¹è¯¯å·® (%) | æ ‡å‡†å·® (%) | è®­ç»ƒæ—¶é—´ (min) |
|----------------|---------------|-------------|----------------|
| 0.5            | 0.71 Â± 0.15   | <0.15       | 11.2 Â± 1.3     |
| **1.0**        | **0.16 Â± 0.05** | **<0.05**   | **10.8 Â± 0.9** |
| 2.0            | 0.33 Â± 0.10   | <0.10       | 12.1 Â± 1.5     |

> ğŸ”¹ å½“ $ \beta = 1.0 $ æ—¶ï¼Œå¹³å‡ç›¸å¯¹è¯¯å·®ä½è‡³ **0.16%**ï¼Œæ ‡å‡†å·®ä»… 0.05%ï¼Œè¡¨ç°å‡ºæé«˜çš„ç²¾åº¦ä¸ç¨³å®šæ€§ã€‚

---

#### æ•°æ®ç¨€ç–æ€§æ•æ„Ÿæ€§åˆ†æï¼ˆå›ºå®š $ \beta = 1.0 $ï¼‰
| æ•°æ®ç‚¹æ•° $ N_u $ | ç›¸å¯¹è¯¯å·® (%) | æ ‡å‡†å·® (%) |
|--------------------|---------------|-------------|
| 100                | 1.47 Â± 1.10   | 1.10        |
| 250                | 1.59 Â± 1.49   | 1.49        |
| **500**            | **0.36 Â± 0.52** | **0.52**    |
| 1000               | 0.80 Â± 0.79   | 0.79        |

> ğŸ”¹ æœ€ä½³æ€§èƒ½å‡ºç°åœ¨ $ N_u = 500 $ï¼Œè¿›ä¸€æ­¥å¢åŠ åˆ° 1000 åè€Œå¯¼è‡´è¯¯å·®ä¸Šå‡ï¼Œå¯èƒ½ç”±äºè¿‡æ‹Ÿåˆå™ªå£°æ‰€è‡´  
> ğŸ”¹ å³ä½¿åªæœ‰ 100 ä¸ªå™ªå£°ç‚¹ï¼Œè¯¯å·®ä¹Ÿæ§åˆ¶åœ¨ 2% ä»¥å†…ï¼Œä½“ç°æå¼ºçš„æ•°æ®æ•ˆç‡

---

### æ¶ˆèå®éªŒç»“æœï¼ˆéšå«åœ¨æ•æ„Ÿæ€§åˆ†æä¸­ï¼‰
- **æ•°æ®é‡å½±å“**ï¼šè¯æ˜äº†ç‰©ç†æ­£åˆ™åŒ–åœ¨æä½æ•°æ®é‡ä¸‹ä¾ç„¶æœ‰æ•ˆ
- **æŸå¤±åŠ¨æ€åˆ†æ**ï¼ˆFigure 3ï¼‰ï¼š
  - Physics Loss å¿«é€Ÿä¸‹é™ â†’ æ¨¡å‹å­¦ä¼šéµå®ˆ NLSE
  - Data Loss ç¨³å®šåœ¨å¹³å°æœŸè€Œéè¶‹è¿‘é›¶ â†’ æˆåŠŸé¿å…å¯¹å™ªå£°è¿‡æ‹Ÿåˆ
- **å‚æ•°å­¦ä¹ è½¨è¿¹**ï¼ˆFigure 1ï¼‰ï¼š
  - ä» $ \beta = 0.0 $ åˆå§‹åŒ–å‡ºå‘ï¼Œå¿«é€Ÿæ”¶æ•›è‡³çœŸå€¼ï¼ˆ1.0ï¼‰ï¼Œè¿‡ç¨‹å¹³ç¨³æ— éœ‡è¡

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **PINNs èƒ½æœ‰æ•ˆå……å½“â€œç‰©ç†æ»¤æ³¢å™¨â€**ï¼šå³ä½¿è¾“å…¥æ•°æ®å«æœ‰ 20% é«˜æ–¯å™ªå£°ï¼Œä¹Ÿèƒ½é€šè¿‡ç‰©ç†çº¦æŸåˆ†ç¦»ä¿¡å·ä¸å™ªå£°ï¼Œå®ç°é«˜ç²¾åº¦å‚æ•°è¯†åˆ«ã€‚
2. **æé«˜çš„å™ªå£°é²æ£’æ€§**ï¼šåœ¨ä¼ ç»Ÿæ–¹æ³•å¤±æ•ˆçš„å™ªå£°æ°´å¹³ä¸‹ï¼ŒPINN ä»å¯å®ç° **<0.2% çš„ç›¸å¯¹è¯¯å·®**ï¼ˆ$ \beta = 1.0 $ï¼‰ã€‚
3. **å‡ºè‰²çš„æ•°æ®æ•ˆç‡**ï¼šä»…éœ€ **500 ä¸ªéšæœºé‡‡æ ·çš„ç¨€ç–æ•°æ®ç‚¹**å³å¯è¾¾åˆ° sub-1% ç²¾åº¦ã€‚
4. **è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›**ï¼šåœ¨ $ \beta \in [0.5, 2.0] $ å¤šç§ç‰©ç†çŠ¶æ€ä¸‹å‡ä¿æŒç¨³å®šæ€§èƒ½ã€‚
5. **è®¡ç®—å¯åŠæ€§å¼º**ï¼šæ•´ä¸ªæµç¨‹å¯åœ¨å…è´¹äº‘èµ„æºï¼ˆGoogle Colab + Tesla T4ï¼‰ä¸Šè¿è¡Œï¼Œæ€»è€—æ—¶çº¦ 80 åˆ†é’Ÿã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ç»´åº¦é™åˆ¶**ï¼šç›®å‰ä»…é€‚ç”¨äº 1D NLSEï¼›å‘ 2D/3D æ‰©å±•é¢ä¸´è®¡ç®—æˆæœ¬å‰§å¢ï¼ˆcollocation points æ•°é‡å‘ˆæŒ‡æ•°å¢é•¿ï¼‰ã€‚
2. **å™ªå£°æ¨¡å‹å‡è®¾**ï¼šä»…è€ƒè™‘åŠ æ€§ç™½é«˜æ–¯å™ªå£°ï¼Œæœªæ¶µç›–å®é™…å®éªŒä¸­å¸¸è§çš„éé«˜æ–¯å™ªå£°ã€ç¦»ç¾¤ç‚¹æˆ–ç©ºé—´ç›¸å…³å™ªå£°ã€‚
3. **å•å‚æ•°è¯†åˆ«**ï¼šä»…è¯†åˆ«éçº¿æ€§ç³»æ•° $ \beta $ï¼ŒæœªåŒæ—¶æ¢å¤è‰²æ•£ç³»æ•°ç­‰å…¶ä»–å‚æ•°ï¼Œå­˜åœ¨å‚æ•°è€¦åˆä¸å¯è¾¨è¯†æ€§é—®é¢˜ã€‚
4. **æŸå¤±æƒé‡å›ºå®š**ï¼šé‡‡ç”¨ç­‰æƒç­–ç•¥ï¼ˆ$ \lambda_{\text{data}} = \lambda_{\text{physics}} = 1.0 $ï¼‰ï¼Œç¼ºä¹è‡ªé€‚åº”æœºåˆ¶ï¼Œå¯èƒ½å½±å“æŸäº› PDE çš„æ”¶æ•›æ•ˆç‡ã€‚
5. **å¤–æ¨èƒ½åŠ›æœªçŸ¥**ï¼šè®­ç»ƒæ—¶é—´åŒºé—´ä¸º $ t \in [0, \pi/2] $ï¼Œæœªæµ‹è¯•é•¿æœŸå¤–æ¨æ€§èƒ½ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **æ›´é«˜ç»´ç³»ç»Ÿ**ï¼ˆå¦‚ 2D/3D NLSE æˆ– Gross-Pitaevskii æ–¹ç¨‹ï¼‰
- å®ç° **å¤šå‚æ•°è”åˆè¯†åˆ«**ï¼ˆdispersion + nonlinearityï¼‰
- å¼•å…¥ **adaptive loss weighting** ç­–ç•¥ï¼ˆå¦‚ [Wang et al., 2021]ï¼‰
- éªŒè¯æ–¹æ³•åœ¨ **çœŸå®å®éªŒæ•°æ®**ï¼ˆå¦‚å…‰çº¤é€šä¿¡ã€å†·åŸå­ç³»ç»Ÿï¼‰ä¸Šçš„æœ‰æ•ˆæ€§
- è®¾è®¡æ›´é«˜æ•ˆçš„é‡‡æ ·ç­–ç•¥ï¼ˆå¦‚è‡ªé€‚åº” collocation point é€‰æ‹©ï¼‰
- æµ‹è¯•æ¨¡å‹åœ¨ **é•¿æ—¶é—´å¤–æ¨ä»»åŠ¡** ä¸­çš„è¡¨ç°

---

## è¡¥å……ä¿¡æ¯

- **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/p-esteves/pinn-nlse-2026](https://github.com/p-esteves/pinn-nlse-2026)ï¼ˆMIT è®¸å¯è¯ï¼‰
- **å¯å¤ç°æ€§ä¿éšœ**ï¼šæä¾›äº†å®Œæ•´çš„éšæœºç§å­ã€è¶…å‚æ•°é…ç½®å’Œè¿è¡Œç¯å¢ƒè¯´æ˜
- **åº”ç”¨å‰æ™¯å¹¿æ³›**ï¼šé€‚ç”¨äºå…‰å­¦ã€æµä½“åŠ›å­¦ã€é‡å­ç‰©ç†ç­‰é¢†åŸŸä¸­å™ªå£°å¤§ã€æ•°æ®å°‘çš„ç§‘å­¦æœºå™¨å­¦ä¹ ä»»åŠ¡

> ğŸŒŸ **æ€»ä½“è¯„ä»·**ï¼šæœ¬å·¥ä½œæœ‰åŠ›è¯æ˜äº† PINNs åœ¨æç«¯å™ªå£°ç¯å¢ƒä¸‹è§£å†³ç§‘å­¦é€†é—®é¢˜çš„å·¨å¤§æ½œåŠ›ï¼Œæ¨åŠ¨äº† **Scientific Machine Learning** å‘æ›´è´´è¿‘çœŸå®å®éªŒæ¡ä»¶çš„æ–¹å‘å‘å±•ã€‚

</details>

---

### 5. [LLM-MC-Affect: LLM-Based Monte Carlo Modeling of Affective Trajectories and Latent Ambiguity for Interpersonal Dynamic Insight](https://arxiv.org/abs/2601.03645)

**Authors**: Yu-Zheng Lin, Bono Po-Jen Shih, John Paul Martin Encinas, Elizabeth Victoria Abraham Achom, Karan Himanshu Patel, Jesus Horacio Pacheco, Sicong Shao, Jyotikrishna Dass, Soheil Salehi, Pratik Satam  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.03645v1  

#### Abstract
Emotional coordination is a core property of human interaction that shapes how relational meaning is constructed in real time. While text-based affect inference has become increasingly feasible, prior approaches often treat sentiment as a deterministic point estimate for individual speakers, failing...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLLM-MC-Affect: LLM-Based Monte Carlo Modeling of Affective Trajectories and Latent Ambiguity for Interpersonal Dynamic Insight

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿæ–‡æœ¬æƒ…æ„Ÿåˆ†ææ–¹æ³•é€šå¸¸å°†æƒ…æ„Ÿè§†ä¸º**ç¡®å®šæ€§çš„ç‚¹ä¼°è®¡**ï¼ˆdeterministic point estimateï¼‰ï¼Œå¿½ç•¥äº†äººç±»äº’åŠ¨ä¸­æƒ…æ„Ÿè¡¨è¾¾çš„**ä¸»è§‚æ€§ã€æ½œåœ¨æ¨¡ç³Šæ€§ï¼ˆlatent ambiguityï¼‰å’ŒåŠ¨æ€è€¦åˆç‰¹æ€§**ã€‚å°¤å…¶åœ¨å¸ˆç”Ÿå¯¹è¯ç­‰äº’åŠ¨åœºæ™¯ä¸­ï¼Œè¿™ç§ç®€åŒ–æ¨¡å‹éš¾ä»¥æ•æ‰æƒ…ç»ªå¦‚ä½•å®æ—¶åè°ƒæ¼”åŒ–ã€‚

æ­¤å¤–ï¼ŒåŸºäºç”Ÿç‰©ä¿¡å·ï¼ˆå¦‚ç¥ç»åŒæ­¥ã€å¿ƒç‡å˜å¼‚æ€§ï¼‰çš„æƒ…æ„Ÿåè°ƒç ”ç©¶è™½å…·é«˜æ—¶é—´åˆ†è¾¨ç‡ï¼Œä½†ä¾èµ–æ˜‚è´µè®¾å¤‡ä¸”éš¾ä»¥æ‰©å±•åˆ°å¤§è§„æ¨¡è‡ªç„¶å­¦ä¹ ç¯å¢ƒã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **LLM-MC-Affect** â€”â€” ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„**æ¦‚ç‡æ€§æƒ…æ„Ÿå»ºæ¨¡æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- å°†æ¯æ¡è¯è¯­çš„æƒ…æ„ŸçŠ¶æ€å»ºæ¨¡ä¸ºä¸€ä¸ª**è¿ç»­éšå˜é‡åˆ†å¸ƒ $ p(e|u) $**ï¼Œè€Œéå•ä¸€æ ‡ç­¾ï¼›
- åˆ©ç”¨ LLM åœ¨éé›¶è§£ç æ¸©åº¦ä¸‹çš„**éšæœºç”Ÿæˆè¡Œä¸º**è¿›è¡Œ **Monte Carlo é‡‡æ ·**ï¼Œé€šè¿‡å¤šæ¬¡ç‹¬ç«‹æ¨ç†è¿‘ä¼¼è¯¥åˆ†å¸ƒï¼›
- ä»é‡‡æ ·ç»“æœä¸­æå–**å‡å€¼ï¼ˆcentral affective tendencyï¼‰å’Œæ–¹å·®ï¼ˆaffective ambiguityï¼‰**ï¼Œæ„å»ºå¸¦æœ‰ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„æƒ…æ„Ÿè½¨è¿¹ï¼ˆaffective trajectoryï¼‰ï¼›
- åŸºäºè¿™äº›è½¨è¿¹ï¼Œè¿›ä¸€æ­¥åˆ†æäººé™…é—´çš„æƒ…ç»ªåŠ¨æ€ï¼ŒåŒ…æ‹¬ï¼š
  - åºåˆ—äº¤å‰ç›¸å…³ï¼ˆsequential cross-correlationï¼‰
  - æœ€ä¼˜æ»åï¼ˆoptimal lagï¼‰
  - è¶‹åŠ¿æ–œç‡ï¼ˆslope-based trend indicatorsï¼‰

è¯¥æ–¹æ³•å®ç°äº†ä»ä½å±‚æ¬¡æƒ…æ„Ÿæ„ŸçŸ¥åˆ°é«˜å±‚æ¬¡äººé™…äº’åŠ¨æ´å¯Ÿçš„æ¡¥æ¢ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | LLM-MC-Affect |
|------|--------|---------------|
| æƒ…æ„Ÿè¡¨ç¤º | ç¡®å®šæ€§æ ‡ç­¾ï¼ˆå¦‚æ­£é¢/è´Ÿé¢ï¼‰ | è¿ç»­æ¦‚ç‡åˆ†å¸ƒï¼ˆå«å‡å€¼ä¸æ–¹å·®ï¼‰ |
| ä¸»è§‚æ€§å¤„ç† | å¿½ç•¥æˆ–å¹³å‡åŒ– | æ˜¾å¼é‡åŒ–â€œæ„ŸçŸ¥æ¨¡ç³Šæ€§â€ä½œä¸ºè¯Šæ–­ä¿¡å· |
| åŠ¨æ€å»ºæ¨¡ | é™æ€åˆ†ç±»æˆ–ç®€å•æ»‘åŠ¨çª—å£ | æ„å»ºçºµå‘æƒ…æ„Ÿè½¨è¿¹å¹¶åˆ†æè€¦åˆæ¨¡å¼ |
| æ•°æ®éœ€æ±‚ | ä¾èµ–äººå·¥æ ‡æ³¨æˆ–ç”Ÿç‰©ä¼ æ„Ÿå™¨ | å®Œå…¨åŸºäºæ–‡æœ¬ï¼Œzero-shotï¼Œæ— éœ€å¾®è°ƒ |
| å¯è§£é‡Šæ€§ | é»‘ç®±è¾“å‡º | æä¾›å¯è§£é‡Šçš„äº’åŠ¨æ¨¡å¼ç±»å‹å­¦ï¼ˆå¦‚æœ‰æ•ˆæ”¯æ¶ã€å…±äº«ç–²åŠ³ç­‰ï¼‰ |

> âœ… **åˆ›æ–°äº®ç‚¹**ï¼šé¦–æ¬¡ç³»ç»Ÿåœ°å°† LLM çš„è§£ç éšæœºæ€§ç”¨äºæƒ…æ„Ÿä¸ç¡®å®šæ€§å»ºæ¨¡ï¼Œå¹¶ç»“åˆç»å…¸æ—¶é—´åºåˆ—åˆ†ææŠ€æœ¯å®ç°å¯¹äººé™…æƒ…æ„ŸåŠ¨æ€çš„ç»“æ„åŒ–è§£æã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **Google's Education Dialogue Dataset**ï¼ˆShani et al., 2024ï¼‰
  - åŒ…å«å¤šä¸ªä¸»é¢˜çš„æ¨¡æ‹Ÿå¸ˆç”Ÿæ•™å­¦å¯¹è¯ï¼ˆmulti-turn instructional interactionsï¼‰
  - ç¤ºä¾‹ä¸»é¢˜åŒ…æ‹¬ï¼š`Personification`, `The Cold War`, `World War 2`, `The Respiratory System`, `Achilles`
  - å¯¹è¯è®¾è®¡åŒ…å«æ˜ç¡®çš„å­¦ç”Ÿ/æ•™å¸ˆåå¥½ä¸ååº”è®¾å®šï¼Œä¾¿äºéªŒè¯æ¨¡å‹åˆç†æ€§

> æ³¨ï¼šä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®å‡ºäºä¼¦ç†ä¸å¯è¡Œæ€§è€ƒè™‘ï¼Œé¿å…çœŸå®è¯¾å ‚ä¸­çš„éšç§ä¸IRBå®¡æ‰¹éš¾é¢˜ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹é€‰æ‹©**ï¼š
  - å•†ä¸šé—­æºæ¨¡å‹ï¼š`GPT-4.1`, `GPT-3.5-Turbo`
  - å¼€æºæ¨¡å‹ï¼š`Llama 3.3 70B`, `Gemma 3 4B`, `Phi-4 14B`, `GPT-OSS 120B`
- **è§£ç å‚æ•°**ï¼š
  - æ¸©åº¦ $ T \in [0.1, 1.0] $
  - æ¯è½®è¯è¯­æ‰§è¡Œ $ K=20 $ æ¬¡ç‹¬ç«‹ MC é‡‡æ ·
- **ç»Ÿä¸€æç¤ºå·¥ç¨‹**ï¼š
  - æ‰€æœ‰æ¨¡å‹ä½¿ç”¨ç›¸åŒçš„ **psychometric prompt (pemo)**ï¼Œç¡®ä¿è·¨æ¨¡å‹æ¯”è¾ƒä¸€è‡´æ€§
  - Prompt è®¾è®¡ä¸ºå¿ƒç†å­¦ä¸“å®¶è§’è‰²ï¼Œè¦æ±‚è¿›è¡Œç»†ç²’åº¦æƒ…æ„Ÿè¯„åˆ†ï¼ˆ0â€“5ï¼Œæ­¥é•¿0.5ï¼‰ï¼Œå¼ºè°ƒä¸Šä¸‹æ–‡è¿ç»­æ€§å’Œç»†å¾®æƒ…ç»ªå˜åŒ–

### è¯„ä¼°æŒ‡æ ‡
- **æƒ…æ„Ÿè½¨è¿¹ç¨³å®šæ€§**ï¼šä¸åŒæ¸©åº¦ä¸‹å‡å€¼æ³¢åŠ¨ç¨‹åº¦
- **æƒ…æ„Ÿæ¨¡ç³Šæ€§é‡åŒ–**ï¼šMC é‡‡æ ·æ–¹å·® $ \sigma^2 $
- **äººé™…åŠ¨æ€æŒ‡æ ‡**ï¼š
  - å½’ä¸€åŒ–äº¤å‰ç›¸å…³å‡½æ•°ï¼ˆNCCFï¼‰
  - æœ€ä¼˜æ»å $ L^* = \arg\max_L |R_{TS}(L)| $
  - æƒ…æ„Ÿè¶‹åŠ¿æ–œç‡ $ \beta_T, \beta_S $ï¼ˆé€šè¿‡çº¿æ€§å›å½’æ‹Ÿåˆï¼‰
- **æ¨¡å¼è¯†åˆ«èƒ½åŠ›**ï¼šä¾æ®è¡¨1è”åˆæŒ‡æ ‡åˆ¤æ–­äº’åŠ¨ç±»å‹ï¼ˆå¦‚ Effective Scaffolding, Shared Fatigue ç­‰ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æœ¬æ–‡æœªç›´æ¥å¯¹æ¯”ä¼ ç»Ÿ sentiment classifiersï¼ˆå¦‚BERT-basedï¼‰ï¼Œè€Œæ˜¯èšç„¦äºä»¥ä¸‹æ–¹é¢çš„**ç›¸å¯¹è¡¨ç°å·®å¼‚**ï¼š
- ä¸åŒ LLM åœ¨ç›¸åŒè®¾ç½®ä¸‹çš„è½¨è¿¹ä¸€è‡´æ€§
- ä¸åŒè§£ç æ¸©åº¦å¯¹åˆ†å¸ƒå½¢æ€çš„å½±å“
- å„æ¨¡å‹åœ¨æ•æ‰è´Ÿå‘æƒ…ç»ªè½¬æŠ˜ç‚¹ä¸Šçš„æ•æ„Ÿæ€§å·®å¼‚

å› æ­¤ï¼ŒåŸºçº¿å®ä¸ºâ€œä¸åŒæ¨¡å‹ + ä¸åŒé…ç½®â€çš„æ¨ªå‘æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å‘ç°

#### ï¼ˆ1ï¼‰æƒ…æ„Ÿåˆ†å¸ƒå»ºæ¨¡çš„æœ‰æ•ˆæ€§ï¼ˆFigure 2aï¼‰
- åœ¨ä½æ¸©åº¦ï¼ˆ$ T=0.1 $ï¼‰æ—¶ï¼ŒLLM è¾“å‡ºå‘ˆç°**åŒå³°åˆ†å¸ƒ**ï¼ˆbimodalï¼‰ï¼Œåæ˜ åŒä¸€å¥è¯å¯èƒ½è¢«è§£è¯»ä¸ºä¸¤ç§é«˜ç½®ä¿¡æƒ…æ„ŸçŠ¶æ€ï¼›
- éšç€æ¸©åº¦å‡é«˜ï¼Œåˆ†å¸ƒè¶‹äºå¹³æ»‘ï¼Œæ–¹å·®å¢åŠ ï¼Œæ­ç¤ºæ›´å¤šæ½œåœ¨è§£é‡Šç©ºé—´ï¼›
- æ–¹å·®æœ¬èº«æˆä¸ºè¡¡é‡â€œè¯­è¨€æ­§ä¹‰â€æˆ–â€œæƒ…æ„Ÿæ¨¡ç³Šæ€§â€çš„ä»£ç†æŒ‡æ ‡ã€‚

#### ï¼ˆ2ï¼‰æƒ…æ„Ÿè½¨è¿¹ç¨³å¥æ€§ï¼ˆFigure 2bï¼‰
- å°½ç®¡æ–¹å·®éšæ¸©åº¦ä¸Šå‡è€Œç¿»å€ï¼ˆ$ \sigma^2 $ ä» 0.01 â†’ 0.024ï¼‰ï¼Œä½†**å‡å€¼ä¿æŒé«˜åº¦ç¨³å®š**ï¼ˆæ³¢åŠ¨èŒƒå›´ä»… -0.11 è‡³ -0.26ï¼‰ï¼›
- è¡¨æ˜ MC ä¼°è®¡èƒ½æœ‰æ•ˆæ»¤é™¤å™ªå£°ï¼Œä¿ç•™æ ¸å¿ƒæƒ…æ„Ÿä¿¡å·ï¼›
- æ”¯æŒåç»­äººé™…åˆ†æçš„å¯é æ€§ã€‚

#### ï¼ˆ3ï¼‰è·¨æ¨¡å‹è¡Œä¸ºå·®å¼‚ï¼ˆFigure 2cï¼‰
| æ¨¡å‹ | è¡¨ç°ç‰¹ç‚¹ |
|------|---------|
| `GPT-4.1` | æƒ…æ„Ÿåˆ†è¾¨ç‡æœ€é«˜ï¼Œå‡†ç¡®æ•æ‰æ—©æœŸè´Ÿé¢æƒ…ç»ªåŠåæœŸå›å‡ï¼Œä¸ç¡®å®šæ€§å¸¦çª„ |
| `GPT-3.5-Turbo` | ç»“æ„ç›¸ä¼¼ä½†ä¸ç¡®å®šæ€§æ›´å¤§ï¼ˆå®½ç½®ä¿¡åŒºé—´ï¼‰ï¼Œè¡¨æ˜ä¿¡å¿ƒè¾ƒä½ |
| `Llama 3.3 70B` | **æç«¯æ­£å‘åè§**ï¼šå®Œå…¨å¿½ç•¥åˆæœŸè´Ÿé¢æƒ…ç»ªï¼ŒæŒç»­ä¸Šå‡è¶‹åŠ¿ï¼Œå½’å› äºâ€œæ— å®³æ€§å¯¹é½â€ï¼ˆharmlessness alignmentï¼‰ |
| `GPT-OSS 120B`, `Gemma`, `Phi-4` | **ä¿å®ˆä¼°è®¡åå·®**ï¼šä½ä¼°è´Ÿé¢å¼ºåº¦ï¼Œæ¢å¤é˜¶æ®µå—é™ï¼ˆplateau near neutralï¼‰ |

> â— ç»“è®ºï¼šå¹¶éæ‰€æœ‰ LLM éƒ½é€‚åˆæƒ…æ„Ÿå»ºæ¨¡ï¼›æ¶æ„ä¸è®­ç»ƒç›®æ ‡æ˜¾è‘—å½±å“æƒ…æ„Ÿæ•æ„Ÿåº¦ã€‚

#### ï¼ˆ4ï¼‰äººé™…åŠ¨æ€è¯†åˆ«æ¡ˆä¾‹ï¼ˆFigure 3 & Table 1ï¼‰
ä»¥ `Personification` ä¸»é¢˜ä¸ºä¾‹ï¼š
- **æœ€ä¼˜æ»å**ï¼š$ L^* = +1 $ï¼Œ$ R_{TS}(L^*) = 0.999 $ â†’ æ•™å¸ˆé¢†å…ˆï¼Œå­¦ç”Ÿè·Ÿéš
- **è¶‹åŠ¿æ–œç‡**ï¼š$ \beta_T = 0.1621 $, $ \beta_S = 0.2532 $ â†’ åŒæ–¹æƒ…ç»ªå‡æ˜¾è‘—æ”¹å–„
- **ç»¼åˆåˆ¤æ–­**ï¼š**Effective Scaffolding**ï¼ˆæœ‰æ•ˆæ”¯æ¶å¼æ•™å­¦ï¼‰

å…¶ä»–æ¡ˆä¾‹ï¼š
- `The Cold War` â†’ **Shared Fatigue**ï¼ˆåŒæ–¹åŒæ­¥ä¸‹æ»‘ï¼‰
- `World War 2` â†’ **Feedback Burnout**ï¼ˆå­¦ç”Ÿä¸»å¯¼çš„å…±åŒè¡°é€€ï¼‰
- `The Respiratory System`, `Achilles` â†’ **Effective Scaffolding**

è¿™äº›åˆ†ç±»ä¸é¢„è®¾çš„è§’è‰²åå¥½é«˜åº¦ä¸€è‡´ï¼Œè¯æ˜æ–¹æ³•å…·å¤‡**ç”Ÿæ€æ•ˆåº¦**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æƒ…æ„Ÿä¸åº”è¢«è§†ä¸ºç¡®å®šæ€§æ ‡ç­¾**ï¼šåˆ©ç”¨ LLM è§£ç éšæœºæ€§å¯æœ‰æ•ˆé€¼è¿‘æƒ…æ„Ÿçš„æ½œåœ¨åˆ†å¸ƒï¼Œæ˜¾å¼å»ºæ¨¡â€œæ„ŸçŸ¥æ¨¡ç³Šæ€§â€å…·æœ‰å®é™…æ„ä¹‰ã€‚
2. **Monte Carlo + LLM æ˜¯å¯è¡Œè·¯å¾„**ï¼šæ— éœ€äººå·¥æ ‡æ³¨å³å¯è·å¾—é«˜è´¨é‡ã€ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„æƒ…æ„Ÿè½¨è¿¹ã€‚
3. **GPT-4.1 åœ¨æƒ…æ„Ÿå»ºæ¨¡ä¸Šä¼˜äºå…¶ä»–æ¨¡å‹**ï¼šå°¤å…¶åœ¨è¯†åˆ«è´Ÿé¢æƒ…ç»ªè½¬æŠ˜å’ŒåŠ¨æ€æ¼”å˜æ–¹é¢æ›´å…·ä¿çœŸåº¦ã€‚
4. **äººé™…æƒ…æ„Ÿæ¨¡å¼å¯é€šè¿‡ç»Ÿè®¡æŒ‡æ ‡ç»“æ„åŒ–è¯†åˆ«**ï¼šç»“åˆ lagã€correlation å’Œ slope å¯å½’çº³å‡ºå¯è§£é‡Šçš„äº’åŠ¨ç±»å‹å­¦ã€‚
5. **æ–¹æ³•å…·å¤‡æ•™è‚²åœºæ™¯çš„åº”ç”¨æ½œåŠ›**ï¼šå¯ç”¨äºè‡ªåŠ¨è¯†åˆ«æ•™å­¦ç­–ç•¥æ•ˆæœï¼ˆå¦‚æ˜¯å¦æˆåŠŸæ¿€å‘å…´è¶£ã€æ˜¯å¦å­˜åœ¨æƒ…ç»ªè€—ç«­ï¼‰ã€‚

### å±€é™æ€§
1. **æ–¹å·®è§£é‡Šçš„æ¨¡ç³Šæ€§**ï¼šMC æ–¹å·®å¯èƒ½æ··æ‚äº†å¤šç§ä¸ç¡®å®šæ€§æ¥æºï¼ˆepistemic vs. aleatoricï¼‰ï¼ŒåŒ…æ‹¬æ¨¡å‹åå·®ã€prompt æ•æ„Ÿæ€§ã€è§£ç éšæœºæ€§ç­‰ï¼Œä¸èƒ½å®Œå…¨ç­‰åŒäºäººç±»æ„ŸçŸ¥æ¨¡ç³Šæ€§ã€‚
2. **ç›¸å…³ä¸ç­‰äºå› æœ**ï¼šäº¤å‰ç›¸å…³ä»…åæ˜ é¡ºåºå¯¹é½ï¼Œæ— æ³•æ¨æ–­å› æœå½±å“ã€‚
3. **çŸ­å¯¹è¯é™åˆ¶**ï¼šå½“å‰åˆ†æåŸºäºè¾ƒçŸ­å¯¹è¯ï¼ˆ~15è½®ï¼‰ï¼Œé•¿ç¨‹åŠ¨æ€å»ºæ¨¡ä»éœ€æ»‘åŠ¨çª—å£æˆ–åˆ†å±‚æ–¹æ³•ã€‚
4. **è®¡ç®—æˆæœ¬é«˜**ï¼šæ¯æ¬¡è¯è¯­éœ€è¿è¡Œ $ K=20 $ æ¬¡å‰å‘æ¨ç†ï¼Œå¯¹å¤§è§„æ¨¡éƒ¨ç½²æ„æˆæŒ‘æˆ˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„é‡‡æ ·ç­–ç•¥ï¼ˆå¦‚ importance samplingï¼‰é™ä½è®¡ç®—å¼€é”€ï¼›
- å¼€å‘ä¸“ç”¨çš„ **affective-sensitive LLM** æˆ– adapter æ¨¡å—ï¼›
- å¼•å…¥æ»‘åŠ¨çª—å£æˆ– hierarchical modeling å¤„ç†é•¿å¯¹è¯ï¼›
- å°†æ¡†æ¶æ‹“å±•è‡³å¿ƒç†å’¨è¯¢ã€å®¢æœã€å›¢é˜Ÿåä½œç­‰äººé™…äº’åŠ¨åœºæ™¯ï¼›
- ç»“åˆ qualitative coding è¿›è¡Œæ··åˆæ–¹æ³•éªŒè¯ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **LLM-MC-Affect æˆåŠŸå°† LLM çš„â€œéšæœºæ€§â€è½¬åŒ–ä¸ºâ€œæƒ…æ„Ÿä¸ç¡®å®šæ€§â€çš„æµ‹é‡å·¥å…·ï¼Œæ„å»ºäº†ä¸€æ¡æ— éœ€ç”Ÿç‰©ä¼ æ„Ÿã€å¯æ‰©å±•ã€å¯è§£é‡Šçš„æƒ…æ„Ÿäº’åŠ¨åˆ†ææ–°èŒƒå¼ï¼Œç‰¹åˆ«é€‚ç”¨äºæ•™è‚²ç­‰ç¤¾ä¼šäº¤äº’å¯†é›†å‹é¢†åŸŸã€‚**

</details>

---

### 6. [EDCO: Dynamic Curriculum Orchestration for Domain-specific Large Language Model Fine-tuning](https://arxiv.org/abs/2601.03725)

**Authors**: Jing-Cheng Pang, Liu Sun, Chang Zhou, Xian Tang, Haichuan Ma, Kun Jiang, Jianlong Wang, Kai Zhang, Sijie Wu, Haoran Cai, Chenwei Wu, Xubin Li, Xin Chen  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.03725v1  

#### Abstract
Domain-specific large language models (LLMs), typically developed by fine-tuning a pre-trained general-purpose LLM on specialized datasets, represent a significant advancement in applied AI. A common strategy in LLM fine-tuning is curriculum learning, which pre-orders training samples based on metri...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# EDCO: Dynamic Curriculum Orchestration for Domain-specific Large Language Model Fine-tuning  
**æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¢†åŸŸå¾®è°ƒé€šå¸¸é‡‡ç”¨éšæœºé‡‡æ ·æˆ–é™æ€è¯¾ç¨‹å­¦ä¹ ï¼ˆStatic Curriculum Learningï¼‰ï¼Œå³åœ¨è®­ç»ƒå‰å›ºå®šæ ·æœ¬é¡ºåºã€‚è¿™ç±»æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **ç¼ºä¹åŠ¨æ€é€‚åº”æ€§**ï¼šæ— æ³•æ ¹æ®æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„èƒ½åŠ›å˜åŒ–è°ƒæ•´æ ·æœ¬éš¾åº¦ã€‚
- **ç†µåå¡Œï¼ˆEntropy Collapseï¼‰**ï¼šå°¤å…¶åœ¨å¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼ˆRLFTï¼‰ä¸­ï¼Œæ¨¡å‹æ¨ç†ç†µè¿…é€Ÿä¸‹é™ï¼Œå¯¼è‡´æ¢ç´¢ä¸è¶³ã€æ”¶æ•›è¿‡æ—©ï¼Œé™åˆ¶æ€§èƒ½ä¸Šé™ã€‚
- **ä½æ•ˆåˆ©ç”¨ç¨€ç¼ºé«˜è´¨é‡é¢†åŸŸæ•°æ®**ï¼šåœ¨åŒ»å­¦ã€æ³•å¾‹ç­‰æ•°æ®æ˜‚è´µä¸”æœ‰é™çš„é¢†åŸŸï¼Œå¦‚ä½•é«˜æ•ˆåˆ©ç”¨æ¯ä¸€æ¡æ ·æœ¬è‡³å…³é‡è¦ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šEDCO
ä½œè€…æå‡º **EDCOï¼ˆEntropy-based Dynamic Curriculum Orchestrationï¼‰**ï¼Œä¸€ç§åŸºäº**æ¨ç†ç†µï¼ˆinference entropyï¼‰**çš„åŠ¨æ€è¯¾ç¨‹ç¼–æ’æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> â€œç»´æŒé«˜æ¨ç†ç†µ = æ›´å¼ºçš„å­¦ä¹ ä¿¡å· + æ›´æœ‰æ•ˆçš„æ¢ç´¢â€

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
1. **åŠ¨æ€è¯¾ç¨‹ç”Ÿæˆæœºåˆ¶**  
   ä¸å†ä¾èµ–é¢„å®šä¹‰çš„â€œç”±æ˜“åˆ°éš¾â€ç­–ç•¥ï¼Œè€Œæ˜¯**å‘¨æœŸæ€§åœ°é‡æ–°è¯„ä¼°æ‰€æœ‰å€™é€‰æ ·æœ¬çš„æ¨ç†ç†µ**ï¼Œé€‰æ‹©å½“å‰å¯¹æ¨¡å‹æœ€å…·æŒ‘æˆ˜æ€§çš„æ ·æœ¬ç»„æˆä¸‹ä¸€é˜¶æ®µçš„è®­ç»ƒé›†ã€‚

2. **é€†å‘è¯¾ç¨‹å­¦ä¹ ï¼ˆReverse Curriculumï¼‰**  
   ä¼˜å…ˆé€‰æ‹©é«˜ç†µæ ·æœ¬ï¼ˆå³æ¨¡å‹æœ€ä¸ç¡®å®šçš„ç­”æ¡ˆï¼‰ï¼Œå½¢æˆâ€œä»éš¾åˆ°æ›´éš¾â€çš„åå‘è¯¾ç¨‹è·¯å¾„ï¼Œæ¨åŠ¨æ¨¡å‹æŒç»­å¤„äºå­¦ä¹ å‰æ²¿ã€‚

3. **é«˜æ•ˆçš„ç†µä¼°è®¡æŠ€æœ¯ï¼ˆEfficient Entropy Estimationï¼‰**
   - **Quick-Answer Prompting (QAP)**ï¼šé€šè¿‡æç¤ºå·¥ç¨‹å¼•å¯¼æ¨¡å‹å¿«é€Ÿè¾“å‡ºç­”æ¡ˆï¼Œé¿å…é•¿é“¾æ€ç»´ï¼ˆChain-of-Thoughtï¼‰å¸¦æ¥çš„è®¡ç®—å¼€é”€ã€‚
   - **Prefix Entropy Approximation**ï¼šä»…ç”¨è¾“å‡ºåºåˆ—å‰ $L$ ä¸ª tokenï¼ˆå¦‚ 50â€“128ï¼‰ä¼°ç®—æ•´ä¸ªåºåˆ—çš„ç†µï¼Œæ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ã€‚

4. **å…¼å®¹å¤šç§å¾®è°ƒèŒƒå¼**
   EDCO å¯æ— ç¼é›†æˆäº **Supervised Fine-Tuning (SFT)** å’Œ **Reinforcement Learning Fine-Tuning (RLFT)** æ¡†æ¶ä¸­ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | EDCO æ”¹è¿› |
|------|--------|----------|
| éšæœºé‡‡æ ·ï¼ˆRandom Samplingï¼‰ | å¿½ç•¥æ ·æœ¬ä»·å€¼å·®å¼‚ | ä¸»åŠ¨æŒ‘é€‰é«˜ä¿¡æ¯é‡æ ·æœ¬ |
| é™æ€è¯¾ç¨‹ï¼ˆLength/AC/PPLï¼‰ | å›ºå®šé¡ºåºï¼Œä¸éšæ¨¡å‹è¿›åŒ– | åŠ¨æ€æ›´æ–°ï¼Œè‡ªé€‚åº”æ¨¡å‹çŠ¶æ€ |
| SECï¼ˆSelf-evolving Curriculumï¼‰ | åŸºäºbanditç­–ç•¥ï¼Œè®­ç»ƒä¸ç¨³å®š | ä½¿ç”¨ç¡®å®šæ€§ç†µæ’åºï¼Œç¨³å®šå¯é  |
| å…¨åºåˆ—ç†µè®¡ç®— | è®¡ç®—ä»£ä»·æé«˜ï¼Œä¸å¯æ‰©å±• | å‰ç¼€è¿‘ä¼¼æ³•æé€Ÿ83.5%ï¼Œç²¾åº¦ä¿æŒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
å®éªŒè¦†ç›–å¤šä¸ªä¸“ä¸šé¢†åŸŸï¼ŒéªŒè¯æ³›åŒ–èƒ½åŠ›ï¼š

| é¢†åŸŸ | æ•°æ®é›† | è§„æ¨¡ | ç‰¹ç‚¹ |
|------|-------|------|------|
| **é€šä¿¡** | è‡ªå»º Wireless & Datacom | å„12,000 QAå¯¹ | åŒ…å«äº§å“æ–‡æ¡£ã€æŠ€æœ¯æ–¹æ¡ˆï¼Œæ¶µç›–å¤šè·³æ¨ç† |
| **åŒ»å­¦** | MedQA (Jin et al., 2021) | å¤šè¯­è¨€åŒ»ç–—è€ƒè¯•é¢˜ | å¤šé€‰é¢˜+ä¸´åºŠæ¡ˆä¾‹ï¼Œéœ€ä¸“ä¸šçŸ¥è¯† |
| **æ³•å¾‹** | JEC-QA (Zhong et al., 2020) | ~26,000 å¤šé€‰é¢˜ | ä¸­å›½å¸æ³•è€ƒè¯•é¢˜ï¼Œå«å•é€‰/å¤šé€‰ï¼Œé€»è¾‘å¤æ‚ |

> æ‰€æœ‰æµ‹è¯•é›†å‡ä¸ºç‹¬ç«‹æ„å»ºçš„ 230 æ¡é«˜éš¾åº¦æœªè§é—®é¢˜ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š`Qwen3-4B`, `Llama3.2-3B`
- **å¾®è°ƒæ–¹å¼**ï¼š
  - **SFT**ï¼šæœ€å°åŒ–äº¤å‰ç†µæŸå¤±
  - **RLFT**ï¼šä½¿ç”¨ GRPO ç®—æ³•ä¼˜åŒ–å¥–åŠ±å‡½æ•°ï¼ˆDeepseek-V3 è‡ªåŠ¨éªŒè¯ æˆ– è§„åˆ™éªŒè¯ï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š**Answer Accuracy**ï¼ˆå‡†ç¡®ç‡ï¼‰
- **ç¡¬ä»¶å¹³å°**ï¼š256æ ¸Kunpeng CPU + 8Ã—Ascend 910B NPUé›†ç¾¤

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• | æè¿° |
|------|------|------|
| é™æ€è¯¾ç¨‹ | RSï¼ˆRandom Samplingï¼‰ | é»˜è®¤åŸºå‡† |
| | Length | æŒ‰è¾“å…¥é•¿åº¦æ’åºï¼ˆçŸ­â†’é•¿ï¼‰ |
| | ACï¼ˆAnswer Complexityï¼‰ | æŒ‰ç­”æ¡ˆå¥å­æ•°æ’åº |
| | PPLï¼ˆPerplexityï¼‰ | åˆå§‹æ¨¡å‹æ‰“åˆ†ï¼Œä½PPLå…ˆè®­ |
| åŠ¨æ€è¯¾ç¨‹ | SEC (Chen et al., 2025) | Banditç­–ç•¥å­¦ä¹ è¯¾ç¨‹ |
| | Dynamic-PPL | å®šæœŸæ›´æ–°PPLå¾—åˆ† |
| æœ¬æ–‡æ–¹æ³• | **EDCO** | åŠ¨æ€é€‰æ‹©æœ€é«˜æ¨ç†ç†µæ ·æœ¬ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆRLFT è®¾ç½®ä¸‹ï¼‰

| æ–¹æ³• | Wireless (Qwen3-4B) | Datacom (Qwen3-4B) |
|------|---------------------|--------------------|
| No Training | 35.22% | 40.00% |
| RS | 34.35% | 40.43% |
| PPL | 33.91% | 44.78% |
| **EDCO** | **38.70%** â†‘ | **46.96%** â†‘ |

> åœ¨æ— çº¿é€šä¿¡é¢†åŸŸï¼ŒRS å’Œ AC åè€Œå¯¼è‡´æ€§èƒ½é€€åŒ–ï¼›è€Œ EDCO æ˜¾è‘—æå‡ç¨³å®šæ€§ä¸æœ€ç»ˆè¡¨ç°ã€‚

### âœ… SFT ç»“æœå¯¹æ¯”

| æ–¹æ³• | Wireless | Datacom |
|------|---------|--------|
| RS | 31.7% | 33.0% |
| PPL | 32.6% | 33.0% |
| **EDCO** | **33.7%** | **36.3%** |

> EDCO åœ¨ä¸¤ä¸ªé¢†åŸŸå‡å–å¾—æœ€ä½³æˆç»©ï¼Œå°¤å…¶åœ¨ Datacom ä¸Šæ¯” PPL é«˜å‡º **3.3%**ã€‚

### ğŸ¥ è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ï¼ˆLlama3.2-3B, RLFTï¼‰

| æ•°æ®é›† | RS | PPL | **EDCO** |
|--------|----|-----|---------|
| MedQA | 32.9% | 24.6% | **36.7%** |
| JEC-QA | 16.2% | 12.4% | **17.4%** |

> åœ¨åŒ»å­¦å’Œæ³•å¾‹é¢†åŸŸä¹Ÿå…¨é¢è¶…è¶ŠåŸºçº¿ï¼Œè¯æ˜å…¶é€šç”¨æ€§ã€‚

### ğŸ”¬ åŠ¨æ€æ–¹æ³•å¯¹æ¯”ï¼ˆDatacom, Qwen3-4Bï¼‰

| æ–¹æ³• | å‡†ç¡®ç‡ |
|------|--------|
| SEC | 34.78% |
| Dynamic-PPL | 41.3% |
| **EDCO** | **47.0%** |

> å°½ç®¡ Dynamic-PPL å·²åŠ¨æ€æ›´æ–°ï¼Œä½†å› ä»ä¾èµ– PPL è¿™ä¸€å¼±ç›¸å…³æŒ‡æ ‡ï¼Œæ•ˆæœè¿œä¸å¦‚åŸºäºå®æ—¶æ¨ç†ç†µçš„ EDCOã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰ç†µä¼°è®¡æ•ˆç‡ï¼ˆTable 3ï¼‰
| æ–¹æ³• | å•è¿›ç¨‹è€—æ—¶ï¼ˆç§’/æ ·æœ¬ï¼‰ | å¹¶è¡Œï¼ˆ8å¡ï¼‰ |
|------|------------------------|------------|
| Full-sequence | 2.24 | 0.24 |
| **Prefix-based (Ours)** | **0.37** | **0.04** |

> **è®¡ç®—æ—¶é—´å‡å°‘ 83.5%**ï¼Œä¸”å¹¶è¡Œåæ¥è¿‘å®æ—¶æ›´æ–°å¯è¡Œã€‚

#### ï¼ˆ2ï¼‰å‰ç¼€é•¿åº¦å½±å“ï¼ˆFig. 4bï¼‰
- å½“ prefix token æ•° â‰¥ 50 æ—¶ï¼Œç†µè¶‹åŠ¿è¶‹äºç¨³å®šã€‚
- æ¨èé»˜è®¤é…ç½®ï¼š**50â€“128 tokens**ï¼Œå¹³è¡¡æ•ˆç‡ä¸ç¨³å®šæ€§ã€‚

#### ï¼ˆ3ï¼‰Quick-Answer Promptingï¼ˆQAPï¼‰æ¶ˆèï¼ˆFig. 5ï¼‰
- ä½¿ç”¨ QAPï¼šprefix ä¸ full-sequence ç†µçš„ç›¸å…³ç³»æ•°ä¸º **0.63**
- ç§»é™¤ QAPï¼šç›¸å…³æ€§é™è‡³ **0.32**
> è¡¨æ˜ QAP å¯¹å‰ç¼€ç†µçš„æœ‰æ•ˆæ€§è‡³å…³é‡è¦ã€‚

#### ï¼ˆ4ï¼‰æ˜¯å¦åº”é¿å¼€æœ€é«˜ç†µæ ·æœ¬ï¼Ÿï¼ˆModerate-Entropy å®éªŒï¼‰
| ç­–ç•¥ | å‡†ç¡®ç‡ |
|------|--------|
| Top 0â€“6.67%ï¼ˆåŸEDCOï¼‰ | **46.96%** |
| Top 5â€“11.67%ï¼ˆä¸­ç­‰ç†µï¼‰ | 44.78% |

> æœ€é«˜ç†µæ ·æœ¬å¹¶æœªå¼•å…¥å™ªå£°æˆ–å¼‚å¸¸å€¼ï¼Œåè€Œå¸¦æ¥æ›´å¼ºå­¦ä¹ ä¿¡å·ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **æ¨ç†ç†µæ˜¯è¡¡é‡æ ·æœ¬å­¦ä¹ ä»·å€¼çš„æœ‰æ•ˆæŒ‡æ ‡**  
   é«˜ç†µæ ·æœ¬å¯¹åº”æ¨¡å‹ä¸ç¡®å®šæ€§æœ€å¤§å¤„ï¼Œæ­£æ˜¯ä¿¡æ¯å¢ç›Šæœ€é«˜çš„ä½ç½®ã€‚

2. **åŠ¨æ€è¯¾ç¨‹ä¼˜äºé™æ€è¯¾ç¨‹**  
   å›ºå®šé¡ºåºå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜æˆ–è¯¯å¯¼è®­ç»ƒæ–¹å‘ï¼ˆå¦‚ AC åœ¨ Datacom SFT ä¸­ä¸¥é‡å¤±è´¥ï¼‰ã€‚

3. **â€œé€†å‘è¯¾ç¨‹â€æ›´é€‚åˆLLMå¾®è°ƒåœºæ™¯**  
   ç”±äºé¢„è®­ç»ƒæ¨¡å‹å·²å…·å¤‡å¹¿æ³›çŸ¥è¯†ï¼Œâ€œä»éš¾å¼€å§‹â€èƒ½æ›´å¿«æ¿€å‘æ·±å±‚ç†è§£ï¼Œé¿å…åœ¨ç®€å•æ ·æœ¬ä¸Šæµªè´¹æ¢¯åº¦æ›´æ–°ã€‚

4. **EDCO æ˜¾è‘—ç¼“è§£ RLFT ä¸­çš„ç†µåå¡Œé—®é¢˜**  
   å›¾3(a)æ˜¾ç¤ºï¼ŒEDCOåœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ç»´æŒè¾ƒé«˜æ¨ç†ç†µï¼Œè€ŒRSè¿…é€Ÿåå¡Œã€‚

5. **é«˜æ•ˆç†µä¼°è®¡ç®—æ³•ä½¿åŠ¨æ€è¯¾ç¨‹å®ç”¨åŒ–**  
   å‰ç¼€è¿‘ä¼¼ + QAP å°†è®¡ç®—å¼€é”€é™ä½ä¸€ä¸ªæ•°é‡çº§ï¼Œæ”¯æŒå¤§è§„æ¨¡åº”ç”¨ã€‚

### âš ï¸ æ–¹æ³•å±€é™æ€§
1. **å‘¨æœŸæ€§ç†µé‡ä¼°ä»æœ‰è®¡ç®—å¼€é”€**  
   è™½ç„¶æ¯”å…¨åºåˆ—å¿«å¾—å¤šï¼Œä½†ä»æ¯”æ ‡å‡†å¾®è°ƒå¤šçº¦10% wall-clock timeï¼ˆ33.58h vs 30.67hï¼‰ã€‚
   
2. **å›ºå®šæ›´æ–°é—´éš”ä¸å¤Ÿæ™ºèƒ½**  
   å½“å‰æŒ‰å›ºå®šæ­¥æ•°æ›´æ–°è¯¾ç¨‹ï¼Œæœªæ¥å¯è€ƒè™‘åŸºäºç†µå˜åŒ–ç‡æˆ–æ€§èƒ½ plateau è‡ªé€‚åº”è§¦å‘ã€‚

3. **ä¾èµ–é«˜è´¨é‡é¢†åŸŸæ•°æ®é¢„å¤„ç†**  
   è‹¥åŸå§‹æ•°æ®å­˜åœ¨å¤§é‡æ¨¡ç³Šæˆ–é”™è¯¯è¡¨è¿°ï¼Œé«˜ç†µå¯èƒ½åæ˜ çš„æ˜¯æ­§ä¹‰è€ŒéæŒ‘æˆ˜æ€§ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. è®¾è®¡è½»é‡åŒ–æ¨¡å‹é¢„æµ‹æ ·æœ¬ç†µï¼Œæ— éœ€æ¯æ¬¡å‰å‘ä¼ æ’­ï¼›
2. å¼•å…¥è‡ªé€‚åº”è°ƒåº¦æœºåˆ¶ï¼Œæ ¹æ®æ¨¡å‹å­¦ä¹ çŠ¶æ€åŠ¨æ€å†³å®šä½•æ—¶æ›´æ–°è¯¾ç¨‹ï¼›
3. æ‰©å±•è‡³æ›´å¤šä½èµ„æºè¯­è¨€æˆ–é«˜åº¦ä¸“ä¸šåŒ–ç§‘å­¦é¢†åŸŸï¼ˆå¦‚é‡å­ç‰©ç†ã€ç”Ÿç‰©åˆ¶è¯ï¼‰ï¼›
4. æ¢ç´¢ä¸å…¶ä»–æ•°æ®é€‰æ‹©æ–¹æ³•ï¼ˆå¦‚ä¸»åŠ¨å­¦ä¹ ï¼‰ç»“åˆçš„å¯èƒ½æ€§ã€‚

---

## æ€»ç»“
**EDCO æ˜¯é¦–ä¸ªå°†æ¨ç†ç†µä½œä¸ºåŠ¨æ€è¯¾ç¨‹é©±åŠ¨ä¿¡å·çš„é¢†åŸŸå¾®è°ƒæ¡†æ¶**ã€‚å®ƒæ‰“ç ´äº†ä¼ ç»Ÿâ€œç”±æ˜“åˆ°éš¾â€çš„è¯¾ç¨‹è®¾è®¡èŒƒå¼ï¼Œæå‡ºâ€œèšç„¦æœ€éš¾æ ·æœ¬â€çš„é€†å‘ç­–ç•¥ï¼Œå¹¶é€šè¿‡é«˜æ•ˆçš„å‰ç¼€ç†µä¼°è®¡å®ç°å¯æ‰©å±•æ€§ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é€šä¿¡ã€åŒ»å­¦ã€æ³•å¾‹ç­‰å¤šä¸ªé¢†åŸŸæ˜¾è‘—æå‡ SFT ä¸ RLFT æ€§èƒ½ï¼Œå…·æœ‰å¹¿æ³›çš„é€‚ç”¨å‰æ™¯ã€‚

</details>

---

### 7. [ReEfBench: Quantifying the Reasoning Efficiency of LLMs](https://arxiv.org/abs/2601.03550)

**Authors**: Zhizhang Fu, Yuancheng Gu, Chenkai Hu, Hanmeng Liu, Yue Zhang  
**Category**: cs.AI  
**Published**: 2026-01-08  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.03550v1  

#### Abstract
Test-time scaling has enabled Large Language Models (LLMs) to tackle complex reasoning, yet the limitations of current Chain-of-Thought (CoT) evaluation obscures whether performance gains stem from genuine reasoning or mere verbosity. To address this, (1) we propose a novel neuro-symbolic framework ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ReEfBench: Quantifying the Reasoning Efficiency of LLMs è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨ç†èƒ½åŠ›çš„è¯„ä¼°ä¸»è¦ä¾èµ–äº **Chain-of-Thought (CoT)** è¾“å‡ºçš„æœ€ç»ˆå‡†ç¡®æ€§ï¼Œè€Œå¿½ç•¥äº†æ¨ç†è¿‡ç¨‹çš„è´¨é‡ã€‚è¿™ç§â€œé»‘ç®±â€å¼è¯„ä¼°å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **æ— æ³•åŒºåˆ†çœŸæ­£çš„é€»è¾‘æ·±åº¦ä¸å†—é•¿çš„æ— æ•ˆæ€è€ƒ**ï¼ˆå¦‚â€œoverthinkingâ€ç°è±¡ï¼‰ï¼›
- ç¼ºä¹å¯¹æ¨ç†æ•ˆç‡ï¼ˆreasoning efficiencyï¼‰çš„é‡åŒ–æ ‡å‡†ï¼›
- ç°æœ‰æ•°æ®é›†åœ¨å¯æ§æ€§ã€å¯æ‰©å±•æ€§å’Œå½¢å¼åŒ–é€»è¾‘åŸºç¡€æ–¹é¢ä¸è¶³ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ä¸ªåä¸º **ReEfBench** çš„ç¥ç»ç¬¦å·ï¼ˆneuro-symbolicï¼‰è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºéä¾µå…¥å¼ã€å…¨é¢çš„è¿‡ç¨‹ä¸­å¿ƒå‹ï¼ˆprocess-centricï¼‰æ¨ç†æ•ˆç‡é‡åŒ–åˆ†æã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **æå‡ºâ€œæ¨ç†æ•ˆç‡â€å…¬å¼ï¼š`W = P Ã— t`**
   - `W`: Logical Depthï¼ˆé€»è¾‘æ·±åº¦ï¼‰ï¼Œè¡¨ç¤ºå®Œæˆä»»åŠ¡æ‰€éœ€çš„æŠ½è±¡é€»è¾‘å·¥ä½œé‡ï¼›
   - `t`: Costï¼ˆè®¡ç®—æ¶ˆè€—ï¼‰ï¼Œä»¥ç”Ÿæˆçš„ token æ•°é‡è¡¡é‡ï¼›
   - `P`: Reasoning Efficiencyï¼ˆæ¨ç†æ•ˆç‡ï¼‰ï¼Œå³å•ä½è®¡ç®—æˆæœ¬ä¸‹çš„é€»è¾‘å¢ç›Šã€‚
   - è¿™ä¸€å…¬å¼å°†æ¨ç†ä»â€œæ˜¯å¦æ­£ç¡®â€æå‡åˆ°â€œæ˜¯å¦é«˜æ•ˆâ€çš„è¯„ä»·ç»´åº¦ã€‚

2. **æ„å»º ReEfBench æ¡†æ¶**
   - äº”é˜¶æ®µæµæ°´çº¿ï¼šæ•°æ®ç”Ÿæˆ â†’ LLMå“åº”è·å– â†’ å“åº”è§£æ â†’ èŠ‚ç‚¹å¤„ç† â†’ è¡Œä¸ºæŒ‡æ ‡èšåˆã€‚
   - åˆ©ç”¨å°è§„æ¨¡ LLM ä½œä¸º parser å°†è‡ªç„¶è¯­è¨€æ¨ç†é“¾åˆ†è§£ä¸ºç»“æ„åŒ–é€»è¾‘èŠ‚ç‚¹ï¼Œå¹¶é€šè¿‡ç¬¦å·è§„åˆ™éªŒè¯å…¶é€»è¾‘æ·±åº¦ä¸æ­£ç¡®æ€§ã€‚

3. **å¼•å…¥å…­ç»´è¯Šæ–­æŒ‡æ ‡ä½“ç³»**
   - **Logical Depth (Sld)**: æœ€å¤§æœ‰æ•ˆé€»è¾‘æ·±åº¦
   - **Cost (Scost)**: token æ•° + planning/reflection æ­¥éª¤é¢‘ç‡
   - **Exploration (Sexp)**: æ¢ç´¢çš„ç‹¬ç‰¹æ­£ç¡®èŠ‚ç‚¹æ•°
   - **Efficiency (Seff)**: token æ•ˆç‡ä¸æœ‰æ•ˆè·¨åº¦
   - **Coherence (Scoh)**: å…ƒè®¤çŸ¥æ­¥éª¤ï¼ˆplanning/reflectionï¼‰æ˜¯å¦å¸¦æ¥å®é™…è¿›å±•
   - **Redundancy (Sred)**: å¥å­ä¸èŠ‚ç‚¹çº§åˆ«çš„é‡å¤ç¨‹åº¦

4. **è¯†åˆ«å››ç§è¡Œä¸ºåŸå‹ï¼ˆBehavioral Prototypesï¼‰**
   - æœ‰æ•ˆæ±‚è§£è€…ï¼ˆEffective Solverï¼‰
   - æ·±åº¦æ¼«æ¸¸è€…ï¼ˆDeep Wandererï¼‰
   - ç©ºæ´æ¨¡ä»¿è€…ï¼ˆHollow Mimicï¼‰
   - æ‡’æƒ°çŒœæµ‹è€…ï¼ˆLazy Guesserï¼‰

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | ReEfBench | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ ProntoQA, FOLIO, Roscoeï¼‰ |
|------|-----------|----------------------------------------|
| Scalable | âœ… | âŒ æˆ–éƒ¨åˆ†æ”¯æŒ |
| FOL å½¢å¼åŒ–åŸºç¡€ | âœ… | éƒ¨åˆ†æ”¯æŒ |
| Logic-only è¯„ä¼° | âœ… | å¤šå«çŸ¥è¯†å¹²æ‰° |
| Logical Depth å¯è®¡ç®— | âœ… | âŒ æˆ–ä»…äºŒå€¼æœ‰æ•ˆæ€§ |
| Behavioral Process åˆ†æ | âœ… | âŒ æˆ–æœ‰é™ |
| Interpretable æŒ‡æ ‡ | âœ… | å¤šä¸ºä¸å¯è§£é‡Šåˆ†æ•° |
| Non-intrusive è®¾è®¡ | âœ… | å¤šéœ€ç‰¹å®šè¾“å‡ºæ ¼å¼ |

> âœ… è¡¨ç¤ºæ”¯æŒï¼ŒâŒ è¡¨ç¤ºä¸æ”¯æŒæˆ–ä¸¥é‡å—é™

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **è‡ªå»ºæ•°æ®é›†**ï¼šåŸºäº First-Order Logic (FOL) è‡ªåŠ¨ç”Ÿæˆï¼Œå‚æ•°åŒ–æ§åˆ¶å¤æ‚åº¦ï¼ˆComplexity Level 3â€“11ï¼‰ã€‚
- æ¯ä¸ªæ ·æœ¬åŒ…å«ï¼š
  - å‰æï¼ˆPremisesï¼‰
  - ç»“è®ºï¼ˆConclusionï¼‰
  - é»„é‡‘æ¨ç†è·¯å¾„ï¼ˆGolden Solutionï¼‰
- ä½¿ç”¨ **backward-chaining** æ–¹æ³•ç”Ÿæˆå¤šè·³æ¨ç†å›¾ï¼Œç¡®ä¿é€»è¾‘æ·±åº¦ç²¾ç¡®å¯æ§ã€‚
- æ·»åŠ  distractor premises å¢åŠ éš¾åº¦ã€‚
- æ€»å…±ç”Ÿæˆ 100 ä¸ªæ ·æœ¬/å¤æ‚åº¦çº§åˆ«ï¼Œå…± 900 ä¸ªæµ‹è¯•å®ä¾‹ã€‚

### å®éªŒè®¾ç½®
- **è¯„ä¼°æ¨¡å‹**ï¼šæ¶µç›– 25 ä¸ªå¼€æºä¸é—­æº LLMsï¼ŒåŒ…æ‹¬ï¼š
  - å•†ä¸šæ¨¡å‹ï¼šClaude-Opus/Sonnet-4.5 (.long/.short)
  - å¼€æºæ¨¡å‹ï¼šQwen3 ç³»åˆ—ï¼ˆ3Bâ€“235Bï¼‰ã€DeepSeek-R1ã€DS-R1-Distill-Qwen ç­‰
- **Prompt è®¾ç½®**ï¼š
  ```text
  Please answer the question based on the given information...
  Please reason step by step, show your reasoning process and put your final answer in \boxed{}
  ```
- **API å‚æ•°**ï¼š
  - `temperature=0`
  - reasoning models: max_tokens=24,000
  - non-reasoning models: max_tokens=8,000

### è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦ä½¿ç”¨ä¸Šè¿° **å…­ä¸ªå½’ä¸€åŒ–è¯Šæ–­æŒ‡æ ‡**ï¼ˆSld, Scost, Sexp, Seff, Scoh, Sredï¼‰
- æ‰€æœ‰åŸå§‹æŒ‡æ ‡ç» max-normalization æ˜ å°„è‡³ [0,1] åŒºé—´ååŠ æƒå¹³å‡
- å¼•å…¥ **confidence score (Sc)** è¡¡é‡æ¨¡å‹å±äºæŸç±»åˆ«çš„å…¸å‹æ€§ï¼ˆåŸºäº Voronoi è¾¹ç•Œè·ç¦»ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æœ¬æ–‡æœªç›´æ¥ä¸å…¶ä»–è¯„ä¼°æ¡†æ¶è¿›è¡Œç«¯åˆ°ç«¯å¯¹æ¯”ï¼Œè€Œæ˜¯é€šè¿‡ **ç³»ç»Ÿæ€§æ¯”è¾ƒå·²æœ‰æ¡†æ¶å±æ€§**ï¼ˆè§ Table 1ï¼‰è¯æ˜ ReEfBench åœ¨å¯æ‰©å±•æ€§ã€å½¢å¼åŒ–åŸºç¡€ã€è¿‡ç¨‹åˆ†æç­‰æ–¹é¢çš„å…¨é¢ä¼˜åŠ¿ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆComplexity Level 11ï¼‰

| Model | Category | Sld | Scost | Tokens(k) | Depth |
|-------|----------|-----|--------|------------|--------|
| Qwen3-235B-thinking | DeepWanderer | 1.00 | 0.88 | 16.8 | 10.54 |
| Claude-Opus-4.5.long | EffectiveSolver | 0.97 | 0.37 | 3.5 | 10.27 |
| QwQ-32B | HollowMimic | 0.68 | 0.61 | 5.7 | 7.12 |
| Qwen2.5-32B-Instruct | LazyGuesser | 0.28 | 0.16 | 0.7 | 2.90 |

> æ•°æ®æ¥æºï¼šTable 2 & Table 13

### å››ç±»è¡Œä¸ºåŸå‹ç‰¹å¾æ€»ç»“

| ç±»åˆ« | ç‰¹å¾æè¿° | ä»£è¡¨æ¨¡å‹ | Sld | Scost | Seff | Sred |
|------|---------|--------|-----|--------|------|------|
| **Effective Solver** | é«˜æ•ˆç²¾å‡†ï¼Œä½å†—ä½™ | Claude-Opus-4.5.long | 0.97 | 0.37 | 0.60 | 0.28 |
| **Deep Wanderer** | é«˜æ¶ˆè€—ã€é«˜æ¢ç´¢ã€ä½æ•ˆ | Qwen3-235B-thinking | 1.00 | 0.88 | 0.47 | 0.77 |
| **Hollow Mimic** | é«˜æˆæœ¬ä½†æµ…å±‚ï¼Œä¼ªåæ€ | QwQ-32B | 0.68 | 0.61 | 0.48 | 0.62 |
| **Lazy Guesser** | æä½æˆæœ¬ï¼Œåœæ»æˆ–å´©æºƒ | Qwen2.5-32B-Instruct | 0.28 | 0.16 | 0.55 | 0.59 |

> ç±»åˆ«å‡å€¼è§ Table 2 æœ€åå››è¡Œï¼ˆweighted by Scï¼‰

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **Long CoT vs Short CoT**ï¼ˆTable 3ï¼‰ï¼š
  - æ—©æœŸ Long CoT æ¨¡å‹ï¼ˆå¦‚ QwQ-32Bï¼‰æ¯” Short CoT æ·±åº¦é«˜å‡º 97.1%
  - å½“å‰å…ˆè¿› Short CoTï¼ˆå¦‚ Qwen3-235B-Instructï¼‰ä»…è½åå…¶ Long ç‰ˆæœ¬ **1.6%**
  - è¡¨æ˜ **Short CoT å·²æ¥è¿‘ Long CoT çš„æ¨ç†æ·±åº¦**

- **Reflection çš„ä½œç”¨æ˜¾è‘—**ï¼ˆTable 4ï¼‰ï¼š
  - æˆåŠŸæ¨¡å‹ï¼ˆå¦‚ Claude-Opus-4.5.longï¼‰å³ä½¿åœ¨ short æ¨¡å¼ä¸‹ä¹Ÿä¿æŒ reflectionï¼ˆ0.7%ï¼‰
  - å¤±è´¥æ¨¡å‹ï¼ˆå¦‚ Qwen2.5-32B-Instructï¼‰reflection å‡ ä¹ä¸ºé›¶ï¼ˆ0.0%ï¼‰
  - æ”¯æŒ â€œ**Short CoT + Reflection**â€ æ˜¯é«˜æ•ˆæ¨ç†çš„å…³é”®æœºåˆ¶

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰æ··åˆè®­ç»ƒçš„å½±å“ï¼ˆMixed Trainingï¼‰
- å¯¹æ¯”çº¯ Long CoT ä¸ Long+Short æ··åˆè®­ç»ƒï¼š
  - æ··åˆè®­ç»ƒå¯¼è‡´ **æå‰é¥±å’Œï¼ˆpremature saturationï¼‰ç”šè‡³å´©æºƒï¼ˆcollapseï¼‰**
  - å¦‚ Qwen3-235B.longï¼ˆmixedï¼‰ç›¸æ¯” Qwen3-235B-thinkingï¼ˆpureï¼‰æ›´æ—©åœæ­¢æ‰©å±• token æ•°
- **ç»“è®º**ï¼šæ··åˆ Long/Short CoT æ•°æ®ä¼šå¹²æ‰° High-t ç­–ç•¥ï¼Œç ´åè‡ªé€‚åº”æ‰©å±•èƒ½åŠ›

#### ï¼ˆ2ï¼‰è’¸é¦ï¼ˆDistillationï¼‰çš„æ•ˆæœé™åˆ¶
- å°† Qwen3-32Bï¼ˆteacherï¼‰çš„ Long CoT èƒ½åŠ›è’¸é¦è‡³ 14B/8B/4B å­¦ç”Ÿæ¨¡å‹
- å‘ç°ï¼š
  - å°æ¨¡å‹èƒ½æ¨¡ä»¿ **reflection/planning çš„é¢‘ç‡**ï¼ˆbehavioral mimicryï¼‰
  - ä½† **è¯­ä¹‰è´¨é‡éšè§„æ¨¡ä¸‹é™**ï¼ˆ4B < 8B < 14B < 32Bï¼‰
  - ä»… **14B æ¨¡å‹** èƒ½åŒæ—¶å¤åˆ¶è¡Œä¸ºæ¨¡å¼ä¸é€»è¾‘æ·±åº¦
- **ç»“è®º**ï¼šå®¹é‡ä¸è¶³æ—¶ï¼Œdistillation å¯¼è‡´ â€œ**Diluted Expansion**â€ï¼Œå³å½¢å¼æ¨¡ä»¿ä½†æ— å®è´¨è¿›æ­¥

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **æ‰©å±• token ç”Ÿæˆä¸æ˜¯æ·±åº¦æ¨ç†çš„å‰ææ¡ä»¶**
   - é«˜æ•ˆæ¨¡å‹ï¼ˆå¦‚ Claude-Opus-4.5.longï¼‰å¯åœ¨å°‘é‡ token å†…è¾¾æˆé«˜é€»è¾‘æ·±åº¦ã€‚
   - â€œOverthinkingâ€ å¹¶ä¸ç­‰äºæ›´å¼ºæ¨ç†ã€‚

2. âœ… **è¯†åˆ«å‡ºå››ç§æ¨ç†è¡Œä¸ºåŸå‹**
   - æˆåŠŸè·¯å¾„æœ‰ä¸¤ç§ï¼š
     - **High-t Strategy**ï¼ˆDeep Wandererï¼‰ï¼šé  exhaustive search è¾¾æˆæ·±åº¦
     - **High-P Strategy**ï¼ˆEffective Solverï¼‰ï¼šé é«˜æ•ˆç‡ç²¾å‡†æ¨å¯¼
   - å¤±è´¥æ¨¡å¼ä¹Ÿæœ‰ä¸¤ç§ï¼š
     - **Hollow Mimic**ï¼šå¾’æœ‰å…¶è¡¨çš„åæ€ä¸è§„åˆ’ï¼Œæ— å®é™…é€»è¾‘æ¨è¿›
     - **Lazy Guesser**ï¼šé¢å¯¹å¤æ‚é—®é¢˜é€‰æ‹©åœæ»æˆ–å´©æºƒ

3. âœ… **Short CoT + Reflection å¯åª²ç¾ Long CoT**
   - ç°ä»£ Short CoT æ¨¡å‹é€šè¿‡å¼•å…¥ reflection æœºåˆ¶ï¼Œå·²å¤§å¹…ç¼©å°ä¸ Long CoT çš„å·®è·ã€‚
   - æ¨ç†èƒ½åŠ›æ›´å¤šå–å†³äºè®­ç»ƒç­–ç•¥è€Œéè¾“å‡ºé•¿åº¦ã€‚

4. âš ï¸ **æ··åˆ Long/Short CoT è®­ç»ƒæœ‰å®³**
   - å®¹æ˜“é€ æˆç­–ç•¥å¹²æ‰°ï¼Œå¯¼è‡´æ¨¡å‹åœ¨éœ€è¦æ·±å…¥æ¨ç†æ—¶æ— æ³•æ‰©å±•è®¡ç®—èµ„æºã€‚

5. âš ï¸ **è’¸é¦æ— æ³•å¤åˆ¶çœŸæ­£çš„æ¨ç†èƒ½åŠ›**
   - å°æ¨¡å‹å¯ä»¥æ¨¡ä»¿å¤§æ¨¡å‹çš„â€œæ€è€ƒå½¢å¼â€ï¼ˆå¦‚é¢‘ç¹åæ€ï¼‰ï¼Œä½†ç”±äºå†…åœ¨å®¹é‡é™åˆ¶ï¼Œæ— æ³•å®ç°ç­‰æ•ˆé€»è¾‘è¿›å±•ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **é¢†åŸŸå—é™äº First-Order Logic (FOL)**
   - è™½ç„¶ä¿è¯äº†é€»è¾‘å¯éªŒè¯æ€§ï¼Œä½†éš¾ä»¥æ¨å¹¿åˆ°å¼€æ”¾åŸŸé—®ç­”ã€æ•°å­¦è¯æ˜ç­‰æ›´å¤æ‚åœºæ™¯ã€‚

2. **éä¾µå…¥å¼è®¾è®¡é™åˆ¶**
   - ä»…åˆ†ææ˜¾å¼ç”Ÿæˆçš„æ–‡æœ¬ï¼Œæ— æ³•æ•æ‰éšå¼æ¨ç†è¿‡ç¨‹ã€‚

3. **åˆ†ç±»è¾¹ç•Œæ¨¡ç³Š**
   - å››ç§åŸå‹æ˜¯ç»Ÿè®¡èšç±»ç»“æœï¼Œä¸ªä½“æ¨¡å‹å¯èƒ½è·¨ç±»åˆ«è¡¨ç°ï¼Œåˆ†ç±»å…·æœ‰ç›¸å¯¹æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±• ReEfBench è‡³å…¶ä»–é€»è¾‘ç³»ç»Ÿï¼ˆå¦‚æ¨¡æ€é€»è¾‘ã€é«˜é˜¶é€»è¾‘ï¼‰
- æ¢ç´¢å¦‚ä½•å¼•å¯¼æ¨¡å‹åœ¨ **High-P ä¸ High-t ä¹‹é—´åŠ¨æ€åˆ‡æ¢**ï¼ˆadaptive reasoningï¼‰
- ç ”ç©¶æ›´æœ‰æ•ˆçš„ **small model reasoning distillation** æ–¹æ³•ï¼Œçªç ´å®¹é‡ç“¶é¢ˆ
- å°†è¯¥æ¡†æ¶åº”ç”¨äº **è®­ç»ƒè¿‡ç¨‹ç›‘æ§ä¸ä¼˜åŒ–**

---

> ğŸ”— **é¡¹ç›®åœ°å€**ï¼šhttps://anonymous.4open.science/r/LoG-1AD8/  
> ğŸ“„ **è®ºæ–‡é“¾æ¥**ï¼šhttps://arxiv.org/abs/2601.03550

</details>

---

### 8. [Anti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models](https://arxiv.org/abs/2601.03969)

**Authors**: Wei Wu, Liyi Chen, Congxi Xiao, Tianfu Wang, Qimeng Wang, Chengqiang Lu, Yan Gao, Yi Wu, Yao Hu, Hui Xiong  
**Category**: cs.AI  
**Published**: 2026-01-08  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.03969v1  

#### Abstract
Large reasoning models enhanced by reinforcement learning with verifiable rewards have achieved significant performance gains by extending their chain-of-thought. However, this paradigm incurs substantial deployment costs as models often exhibit excessive verbosity on simple queries. Existing effici...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAnti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹å½“å‰å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆreasoning modelsï¼‰åœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°çš„ **length shift** ç°è±¡ã€‚è¿™ä¸€ç°è±¡è¡¨ç°ä¸ºï¼šå³ä½¿å¯¹äºå·²ç»èƒ½å¤Ÿæ­£ç¡®è§£ç­”çš„ç®€å•é—®é¢˜ï¼Œæ¨¡å‹åœ¨è®­ç»ƒä¸­ä»å€¾å‘äºç”Ÿæˆè¶Šæ¥è¶Šé•¿ã€å†—ä½™çš„æ¨ç†é“¾ï¼ˆChain-of-Thought, CoTï¼‰ï¼Œå¯¼è‡´æ¨ç†æˆæœ¬æ˜¾è‘—å¢åŠ ã€‚

ä¼ ç»Ÿæ–¹æ³•é€šè¿‡å¼•å…¥æ˜¾å¼çš„ **length penalty** æˆ– **budget constraint** æ¥æŠ‘åˆ¶é•¿åº¦ï¼Œä½†è¿™ä¼šå¼•å‘ä¼˜åŒ–å†²çªï¼ˆoptimization conflictsï¼‰ï¼Œå³é•¿åº¦å‹ç¼©ç›®æ ‡ä¸å‡†ç¡®æ€§æœ€å¤§åŒ–ç›®æ ‡ä¸ä¸€è‡´ï¼Œä»è€Œå½±å“æ”¶æ•›æ€§å’Œæ¢ç´¢èƒ½åŠ›ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Dynamic Outlier Truncation (DOT)** çš„è®­ç»ƒæ—¶å¹²é¢„æœºåˆ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **Selective Truncation**ï¼šä»…å¯¹â€œæ‰€æœ‰ç”Ÿæˆç»“æœéƒ½æ­£ç¡®çš„ rollout ç»„â€ï¼ˆall-correct groupsï¼‰ä¸­çš„æç«¯é•¿å°¾å“åº”è¿›è¡Œæˆªæ–­ã€‚
- **åŸºäºç»„å†…ç»Ÿè®¡çš„åŠ¨æ€é˜ˆå€¼**ï¼šä½¿ç”¨ç»„å†…å¹³å‡é•¿åº¦ $ \mu_L $ å’Œæ ‡å‡†å·® $ \sigma_L $ å®šä¹‰æˆªæ–­é˜ˆå€¼ $ T = \mu_L + \alpha \cdot \sigma_L $ï¼ˆé€šå¸¸å– $ \alpha=3 $ï¼Œå³â€œä¸‰è¥¿æ ¼ç›â€åŸåˆ™ï¼‰ï¼Œåªæˆªæ–­ç»Ÿè®¡æ„ä¹‰ä¸Šçš„å¼‚å¸¸å€¼ã€‚
- **ä¸å¯¹å¥–åŠ±å‡½æ•°åšä¿®æ”¹**ï¼šé¿å…äº†ç›´æ¥åœ¨ RL ç›®æ ‡ä¸­åŠ å…¥é•¿åº¦æƒ©ç½šæ‰€å¸¦æ¥çš„ä¼˜åŒ–å¹²æ‰°ã€‚

æ­¤å¤–ï¼Œä¸ºç¨³å®šè®­ç»ƒè¿‡ç¨‹ï¼Œä½œè€…è¿˜å¼•å…¥äº†ä¸¤ä¸ªè¾…åŠ©æŠ€æœ¯ï¼š
- **KL-Cov æ­£åˆ™åŒ–**ï¼šé˜²æ­¢ç­–ç•¥ç†µè¿‡å¿«åç¼©ï¼Œç»´æŒæ¢ç´¢èƒ½åŠ›ã€‚
- **Predictive Dynamic Sampling**ï¼šåŠ¨æ€è°ƒæ•´é‡‡æ ·ç‡ä»¥åº”å¯¹è®­ç»ƒåæœŸâ€œå…¨æ­£ç¡®ç»„â€æ¯”ä¾‹ä¸Šå‡å¸¦æ¥çš„æ•ˆç‡ä¸‹é™é—®é¢˜ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **é¿å…ä¼˜åŒ–å†²çª**ï¼šä¸å°†é•¿åº¦ä½œä¸ºæ˜¾å¼ä¼˜åŒ–ç›®æ ‡ï¼Œè€Œæ˜¯é€šè¿‡åå¤„ç†å¹²é¢„å†—ä½™è¡Œä¸ºï¼Œä¿æŒäº†åŸå§‹ GRPO çš„ä¼˜åŒ–ç¨³å®šæ€§ã€‚
- **ä¿ç•™å¤æ‚é—®é¢˜çš„é•¿ç¨‹æ¨ç†èƒ½åŠ›**ï¼šä»…åœ¨â€œå·²è§£å†³â€çš„ç®€å•é—®é¢˜ä¸Šè¿›è¡Œæˆªæ–­ï¼Œä¸å¯¹å›°éš¾é—®é¢˜æ–½åŠ é™åˆ¶ã€‚
- **é«˜æ•ˆä¸”å¯æ‰©å±•**ï¼šDOT å¹²é¢„çš„æ ·æœ¬æå°‘ï¼ˆçº¦ 0.5%ï¼‰ï¼Œå´èƒ½é©±åŠ¨å…¨å±€ç­–ç•¥å‘æ›´ç®€æ´çš„æ–¹å‘æ¼”åŒ–ã€‚
- **æ€§èƒ½ä¸æ•ˆç‡åŒæå‡**ï¼šä¸ä»…å¤§å¹…å‡å°‘æ¨ç† token æ•°é‡ï¼Œè¿˜èƒ½åŒæ—¶æå‡å‡†ç¡®ç‡ï¼Œæ˜¾è‘—å¤–æ¨äº† efficiency-performance çš„å¸•ç´¯æ‰˜å‰æ²¿ï¼ˆPareto frontierï¼‰ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼š`DeepScaleR-Preview` æ•°æ®é›†ã€‚
- **è¯„ä¼°åŸºå‡†**ï¼ˆå‡ä¸ºé«˜éš¾åº¦æ•°å­¦æ¨ç†ä»»åŠ¡ï¼‰ï¼š
  - `AIME-24`, `AIME-25`
  - `AMC`ï¼ˆAMC-22 å’Œ AMC-23ï¼‰
  - `MATH-500`

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **åŸºç¡€æ¨¡å‹**ï¼š`DeepSeek-R1-Distill-Qwen` ç³»åˆ—ï¼Œæ¶µç›– 1.5Bã€7B å’Œ 32B ä¸‰ç§è§„æ¨¡ã€‚
- **è§£ç å‚æ•°**ï¼štemperature=0.6, top_p=0.95, top_k=20ï¼Œæœ€å¤§ç”Ÿæˆé•¿åº¦ 32,768 tokensã€‚
- **è¯„ä¼°æ–¹å¼**ï¼šæ¯é¢˜ç”Ÿæˆ 32 ä¸ªæ ·æœ¬ï¼ŒæŠ¥å‘Š **pass@1 å‡†ç¡®ç‡** å’Œ **å¹³å‡ç”Ÿæˆé•¿åº¦ï¼ˆtoken æ•°ï¼‰**ã€‚
- **å®ç°æ¡†æ¶**ï¼šåŸºäº `verl` æ¡†æ¶ï¼Œä½¿ç”¨ `FSDP` åˆ†å¸ƒå¼è®­ç»ƒï¼Œ`SGLang` é«˜æ•ˆæœåŠ¡ rolloutã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å¯¹æ¯”äº†å¤šç§å‰æ²¿çš„é«˜æ•ˆæ¨ç†æ–¹æ³•ï¼Œä¸»è¦åŒ…æ‹¬ï¼š
- **æ˜¾å¼é•¿åº¦æƒ©ç½šç±»**ï¼š`O1-Pruner`, `Laser-DE`, `LC-R1`
- **éš¾åº¦æ„ŸçŸ¥ç±»**ï¼š`DAST`, `DLER-R1`
- **æ¨¡å¼åˆ‡æ¢ç±»**ï¼š`AdaptThink`, `SIRI`
- **å¼ºåŸºçº¿**ï¼š`DeepScaleR-Preview`, `OverThink`

æ‰€æœ‰åŸºçº¿å‡åœ¨ç»Ÿä¸€è¯„ä¼°åè®®ä¸‹é‡æ–°è¯„æµ‹ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ 1.5B æ¨¡å‹ä¸ºä¾‹ï¼ŒAIME-24 ä¸Šï¼‰

| æ–¹æ³• | Acc (%) | Length (tokens) |
|------|---------|-----------------|
| Original | 30.0 | 15,498 |
| SIRI-high | 43.6 | 10,049 |
| **DOT-8K (Ours)** | **52.2** | **5,151** |
| **DOT-4K (Ours)** | 43.1 | **3,342** |

- **DOT-8K** åœ¨ AIME-24 ä¸Šå°†å‡†ç¡®ç‡ä» 30.0% æå‡è‡³ **52.2%**ï¼ŒåŒæ—¶å°†å¹³å‡ token æ•°é™ä½ **66%ä»¥ä¸Š**ã€‚
- **DOT-4K** ä»…ä½¿ç”¨åŸå§‹æ¨¡å‹ **21.6%** çš„ tokenï¼Œå‡†ç¡®ç‡ä»è¾¾ 43.1%ï¼Œä¼˜äº SIRI-highã€‚
- ä¸ SIRI-high ç›¸æ¯”ï¼ŒDOT-8K åœ¨å‡†ç¡®ç‡ä¸Šé«˜å‡º **8.6%**ï¼Œè€Œ token æ¶ˆè€—ä»…ä¸ºä¸€åŠã€‚

### ä¸å…¶ä»–åŸºçº¿çš„å¯¹æ¯”ä¼˜åŠ¿
- åœ¨å¤šä¸ªæ¨¡å‹å°ºåº¦ï¼ˆ1.5B, 7B, 32Bï¼‰å’Œå¤šä¸ªåŸºå‡†ä¸Šï¼ŒDOT å‡æ˜¾è‘—å¤–æ¨äº†å¸•ç´¯æ‰˜å‰æ²¿ã€‚
- ä¾‹å¦‚ï¼Œåœ¨ 7B æ¨¡å‹ä¸Šï¼ŒDOT-8K è¾¾åˆ° **62.6%** AIME-24 å‡†ç¡®ç‡ï¼Œè¶…è¶ŠåŸå§‹æ¨¡å‹ 7.5%ï¼ŒåŒæ—¶ä»…ä½¿ç”¨çº¦ **37%** çš„å“åº”é•¿åº¦ã€‚
- ä¸åŒæ ·è¿½æ±‚æç®€é•¿åº¦çš„ `DLER-R1` ç›¸æ¯”ï¼ŒDOT åœ¨ä¿æŒåŒç­‰ç”šè‡³æ›´ä½ token æ•°çš„åŒæ—¶ï¼Œè¿›ä¸€æ­¥æå‡äº†å‡†ç¡®ç‡ï¼ˆå¦‚ 1.5B ä¸Š +7.3%ï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰
æ¶ˆèç ”ç©¶éªŒè¯äº†å„ç»„ä»¶çš„é‡è¦æ€§ï¼š

| å˜ä½“ | AIME-24 Acc | AIME-24 Length |
|------|-------------|---------------|
| DOT-8K (å®Œæ•´) | 52.2 | 5,151 |
| w/o DOT | 51.5 | 6,879 |
| w/o Group-Conditional Truncation | 47.8 | 5,071 |
| w/o KL-Cov | 47.9 | 6,057 |
| w/o Predictive Sampling | 48.9 | 5,637 |

- ç§»é™¤ **DOT** å¯¼è‡´é•¿åº¦æ˜¾è‘—å¢åŠ ï¼Œè¯´æ˜å…¶æœ‰æ•ˆæŠ‘åˆ¶äº†å†—ä½™ã€‚
- ç§»é™¤ **group-conditional truncation**ï¼ˆå³å¯¹æ‰€æœ‰ç»„ç»Ÿä¸€æˆªæ–­ï¼‰ä¸¥é‡æŸå®³æ€§èƒ½ï¼Œè¯æ˜äº†â€œä»…åœ¨ all-correct ç»„æˆªæ–­â€çš„å¿…è¦æ€§ã€‚
- ç§»é™¤ **KL-Cov** æˆ– **Predictive Sampling** å‡å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼ŒéªŒè¯äº†å®ƒä»¬å¯¹è®­ç»ƒç¨³å®šæ€§çš„è´¡çŒ®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Length Shift æ˜¯å†—ä½™çš„æ ¹æœ¬åŸå› **ï¼šæ¨¡å‹åœ¨è®­ç»ƒä¸­å¯¹ç®€å•é—®é¢˜è¿‡åº¦è§¦å‘â€œåæ€â€ã€â€œéªŒè¯â€ç­‰æ¨ç†è¯ï¼Œå¯¼è‡´ä¸å¿…è¦çš„é•¿æ¨ç†é“¾ï¼Œè¿™æ˜¯ä¸€ç§è·¨éš¾åº¦çº§åˆ«çš„ç­–ç•¥å¹²æ‰°ã€‚
2. **DOT èƒ½ç³»ç»Ÿæ€§çº æ­£å†—ä½™**ï¼šé€šè¿‡ä»…æˆªæ–­ all-correct ç»„ä¸­çš„ç»Ÿè®¡å¼‚å¸¸å€¼ï¼ŒDOT æˆåŠŸå¼•å¯¼ç­–ç•¥å­¦ä¹ ä½•æ—¶åº”ç®€æ´ï¼Œå®ç°äº† **adaptive reasoning**ã€‚
3. **æå°å¹²é¢„å¸¦æ¥å…¨å±€æ”¶ç›Š**ï¼šDOT ä»…å½±å“ä¸åˆ° 0.5% çš„å“åº”ï¼Œå´èƒ½é©±åŠ¨æ•´ä¸ªç­–ç•¥åˆ†å¸ƒå‘æ›´é«˜æ•ˆçš„æ–¹å‘æ¼”åŒ–ã€‚
4. **æ€§èƒ½ä¸æ•ˆç‡å¯å…¼å¾—**ï¼šDOT ä¸æ˜¯ä»¥ç‰ºç‰²å‡†ç¡®ç‡ä¸ºä»£ä»·æ¢å–æ•ˆç‡ï¼Œåè€Œåœ¨å‹ç¼©é•¿åº¦çš„åŒæ—¶æå‡äº†æ¨ç†èƒ½åŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡åˆå§‹ç­–ç•¥å’Œè®­ç»ƒæ•°æ®**ï¼šä½œä¸º RL è®­ç»ƒé˜¶æ®µçš„æ–¹æ³•ï¼Œå…¶æ•ˆæœå—é™äºåˆå§‹ policy å’Œè®­ç»ƒæ•°æ®è´¨é‡ã€‚
- **éš¾ä»¥åº”ç”¨äºé¡¶çº§é—­æºæ¨¡å‹**ï¼šå¦‚ `DeepSeek-V3.2` æˆ– `Qwen3-235B` ç­‰ç»è¿‡å¤§è§„æ¨¡ç§æœ‰æ•°æ®è®­ç»ƒçš„æ¨¡å‹ï¼Œåœ¨å…¬å¼€æ•°æ®ä¸Šå·²æ¥è¿‘é›¶ç†µï¼Œéš¾ä»¥ä»ä¸­æå–è¿›ä¸€æ­¥å¢ç›Šã€‚
- **å°šæœªæ‰©å±•è‡³ Agent ä»»åŠ¡**ï¼šç›®å‰ä»…é’ˆå¯¹æ–‡æœ¬æ¨ç†ï¼Œæœªè€ƒè™‘å·¥å…·è°ƒç”¨ã€è§„åˆ’å¾ªç¯ç­‰ agent åœºæ™¯ä¸­çš„å†—ä½™è¡Œä¸ºã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† DOT æ‰©å±•è‡³ **agent-based tasks**ï¼Œç”¨äºå‰ªæå†—ä½™çš„å·¥å…·è°ƒç”¨æˆ–è§„åˆ’æ­¥éª¤ã€‚
- æ¢ç´¢ä¸ **test-time reinforcement learning (TTRL)** ç»“åˆï¼Œåœ¨æ¨ç†æ—¶åŠ¨æ€ä¼˜åŒ–ç­–ç•¥ã€‚
- åœ¨ **post-training é˜¶æ®µ** åº”ç”¨ DOTï¼Œä½œä¸ºä¸‹ä¸€ä»£åŸºç¡€æ¨¡å‹è®­ç»ƒæµç¨‹çš„ä¸€éƒ¨åˆ†ã€‚

--- 

> **æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºçš„ **DOT** æ–¹æ³•é€šè¿‡ä¸€ç§å·§å¦™çš„â€œåŠ¨æ€å¼‚å¸¸å€¼æˆªæ–­â€æœºåˆ¶ï¼Œè§£å†³äº†æ¨ç†æ¨¡å‹ä¸­çš„ **length shift** é—®é¢˜ï¼Œåœ¨ä¸ç‰ºç‰²ç”šè‡³æå‡æ€§èƒ½çš„å‰æä¸‹ï¼Œå®ç°äº†æè‡´çš„æ¨ç†æ•ˆç‡å‹ç¼©ï¼Œä¸ºé«˜æ•ˆã€å¯æ‰©å±•çš„ reasoning models æä¾›äº†ä¸€ä¸ªç®€å•ã€é²æ£’ä¸”é€šç”¨çš„æ–°èŒƒå¼ã€‚

</details>

---

### 9. [ELO: Efficient Layer-Specific Optimization for Continual Pretraining of Multilingual LLMs](https://arxiv.org/abs/2601.03648)

**Authors**: HanGyeol Yoo, ChangSu Choi, Minjun Kim, Seohyun Song, SeungWoo Song, Inho Won, Jongyoul Park, Cheoneum Park, KyungTae Lim  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.03648v1  

#### Abstract
We propose an efficient layer-specific optimization (ELO) method designed to enhance continual pretraining (CP) for specific languages in multilingual large language models (MLLMs). This approach addresses the common challenges of high computational cost and degradation of source language performanc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠELO: Efficient Layer-Specific Optimization for Continual Pretraining of Multilingual LLMsã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**å¤šè¯­è¨€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨æŒç»­é¢„è®­ç»ƒï¼ˆContinual Pretraining, CPï¼‰è¿‡ç¨‹ä¸­é¢ä¸´çš„ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜**ï¼š
- **è®¡ç®—æˆæœ¬é«˜æ˜‚**ï¼šä¼ ç»Ÿå…¨å‚æ•°å¾®è°ƒï¼ˆFull Fine-Tuning, FFTï¼‰éœ€è¦å¤§é‡GPUèµ„æºå’Œæ—¶é—´ã€‚
- **æºè¯­è¨€æ€§èƒ½é€€åŒ–**ï¼šåœ¨ç›®æ ‡è¯­è¨€ä¸Šè¿›è¡ŒCPé€šå¸¸ä¼šå¯¼è‡´è‹±æ–‡ç­‰æºè¯­è¨€èƒ½åŠ›æ˜¾è‘—ä¸‹é™ã€‚

å°½ç®¡å·²æœ‰è½»é‡çº§æ–¹æ³•å¦‚ **LoRA** å’Œ **Selective Layer Tuning**ï¼Œä½†ç”±äºå‰å‘ä¼ æ’­ä»éœ€éå†å…¨éƒ¨æ¨¡å‹å‚æ•°ï¼Œå› æ­¤**è®­ç»ƒåŠ é€Ÿæ•ˆæœæœ‰é™**ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šELOï¼ˆEfficient Layer-Specific Optimizationï¼‰
æå‡ºä¸€ç§å…¨æ–°çš„ä¸¤é˜¶æ®µå±‚ç‰¹å®šä¼˜åŒ–æ¡†æ¶â€”â€”**ELO**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> **ä»åŸå§‹MLLMä¸­å‰¥ç¦»å‡ºä¸€å°éƒ¨åˆ†å…³é”®å±‚ï¼Œç‹¬ç«‹è®­ç»ƒåå†é‡æ–°æ•´åˆå›åŸæ¨¡å‹**ã€‚

#### ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š
1. **ELO Pretrainingï¼ˆå±‚å‰¥ç¦»é¢„è®­ç»ƒï¼‰**
   - å‰¥ç¦»å¹¶ä»…è®­ç»ƒ**ç¬¬ä¸€å±‚å’Œæœ€åä¸€å±‚è§£ç å™¨å±‚**ï¼ˆå³ $l_1$ å’Œ $l_n$ï¼‰ï¼Œæ„å»ºä¸€ä¸ªæ›´å°çš„ç‹¬ç«‹æ¨¡å‹ï¼ˆELO Modelï¼‰ã€‚
   - æ˜¾è‘—å‡å°‘**å¯è®­ç»ƒå‚æ•°æ•°é‡**ä»¥åŠ**å‰å‘ä¼ æ’­ä¸­çš„æ€»è®¡ç®—é‡**ï¼Œä»è€Œå¤§å¹…é™ä½æ˜¾å­˜å ç”¨å’Œè®­ç»ƒæ—¶é—´ã€‚

2. **Layer Alignmentï¼ˆå±‚å¯¹é½ï¼‰**
   - å°†è®­ç»ƒå¥½çš„æ–°å±‚æ›¿æ¢å›åŸå§‹æ¨¡å‹ã€‚
   - ä½¿ç”¨çº¦1GBåŒè¯­æ•°æ®è¿›è¡Œ**ç®€çŸ­çš„å…¨æ¨¡å‹å¾®è°ƒ**ï¼Œä»¥å¯¹é½å‚æ•°ã€ç¨³å®šè¾“å‡ºã€‚

æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº† **Bilingual Instruction Tuning** é˜¶æ®µï¼Œç»“åˆ **Chat Vector æ–¹æ³•** å’Œ **Supervised Fine-Tuning (SFT)** æ¥æå‡æŒ‡ä»¤è·Ÿéšèƒ½åŠ›ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | LoRA / Selective Tuning | ELO |
|------|------------------------|-----|
| å¯è®­ç»ƒå‚æ•° | å‡å°‘ | å¤§å¹…å‡å°‘ |
| å‰å‘ä¼ æ’­è®¡ç®—é‡ | ä¸å˜ï¼ˆä»éœ€å…¨æ¨¡å‹æ¨ç†ï¼‰ | **æ˜¾è‘—å‡å°‘**ï¼ˆåªè¿è¡Œå°æ¨¡å‹ï¼‰ |
| è®­ç»ƒé€Ÿåº¦ | åŠ é€Ÿæœ‰é™ï¼ˆ~1.2â€“1.5xï¼‰ | **æœ€é«˜è¾¾6.46å€äºFFTï¼Œ10.72å€äºLoRA** |
| æºè¯­è¨€ä¿ç•™èƒ½åŠ› | ä¸­ç­‰ï¼ˆæ˜“é—å¿˜ï¼‰ | **æœ‰æ•ˆä¿æŒè‹±è¯­æ€§èƒ½ï¼ˆMMLUä»…é™~2.42%ï¼‰** |
| ç›®æ ‡è¯­è¨€æ€§èƒ½ | æå‡ä¸€èˆ¬ | **QualitativeæŒ‡æ ‡æœ€é«˜æå‡6.2%** |

> âœ… **æ ¸å¿ƒçªç ´**ï¼šé€šè¿‡â€œ**å±‚å‰¥ç¦» + ç‹¬ç«‹è®­ç»ƒ**â€ç­–ç•¥ï¼Œç›´æ¥è§£å†³äº†PEFTæ–¹æ³•æ— æ³•è§„é¿çš„**å‰å‘ä¼ æ’­ç“¶é¢ˆ**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

#### é¢„è®­ç»ƒæ•°æ®ï¼ˆPretraining Datasetï¼‰
- **éŸ©è¯­ & è‹±è¯­æ··åˆæ•°æ®**ï¼ˆå…± ~200GBï¼‰ï¼š
  - æ¥æºï¼šAI-Hubã€Modu-corpus2ã€WIKI-koã€CulturaXã€cc100-koã€fineweb
- **æ—¥è¯­ & è‹±è¯­æ··åˆæ•°æ®**ï¼ˆå…± 10GBï¼‰ï¼š
  - æ¥æºï¼šCulturaXï¼ˆjaï¼‰ã€fineweb

> æ•°æ®æ¯”ä¾‹ä¸º **è‹±è¯­:ç›®æ ‡è¯­è¨€ = 1:9**

#### æŒ‡ä»¤å¾®è°ƒæ•°æ®ï¼ˆInstruction Tuningï¼‰
- ä½¿ç”¨å…¬å¼€çš„ **Tagengo** æ•°æ®é›†ï¼ˆShareGPTæ ¼å¼ï¼‰
- åŒ…å«è¶…è¿‡7ä¸‡æ¡å¤šè¯­è¨€å¯¹è¯æ ·æœ¬
- æŠ½å– **31K è‹±æ–‡/ç›®æ ‡è¯­è¨€ï¼ˆéŸ©/æ—¥ï¼‰1:1é…æ¯”** çš„æŒ‡ä»¤å¯¹ç”¨äºSFT

---

### å®éªŒè®¾ç½®

#### æ¨¡å‹åŸºç¡€æ¶æ„
- **Llama 3.1-8B**
- **Mistral-7B-v0.3**
- **Qwen2-7B**

#### å¯¹æ¯”æ–¹æ³•
| æ–¹æ³• | æè¿° |
|------|------|
| `{base}-Instruct` | å®˜æ–¹å‘å¸ƒçš„æŒ‡ä»¤è°ƒä¼˜æ¨¡å‹ï¼ˆé›¶åŸºçº¿ï¼‰ |
| `{base}-FFT` | åœ¨åŸºç¡€æ¨¡å‹ä¸Šè¿›è¡Œå®Œæ•´CP + SFT |
| `{base}-ELO` | æœ¬æ–‡æå‡ºçš„ELOæ–¹æ³•ï¼ˆELO Pretraining + Layer Alignment + SFTï¼‰ |

#### è¯„ä¼°æŒ‡æ ‡

| è¯­è¨€ | å®šé‡è¯„ä¼°ï¼ˆQuantitativeï¼‰ | å®šæ€§è¯„ä¼°ï¼ˆQualitativeï¼‰ |
|------|--------------------------|-------------------------|
| **è‹±è¯­** | MMLUï¼ˆAccuracyï¼‰ | MT-Benchï¼ˆGPT-4è¯„åˆ†ï¼Œæ»¡åˆ†10ï¼‰ |
| **éŸ©è¯­** | KoBESTï¼ˆF1-scoreï¼‰ | LogicKorï¼ˆGPT-4è¯„åˆ†ï¼Œæ»¡åˆ†10ï¼‰ |
| **æ—¥è¯­** | MARC-jaï¼ˆaccuracy_normï¼‰ | MT-Bench(ja)ï¼ˆGPT-4è¯„åˆ†ï¼Œæ»¡åˆ†10ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ¨¡å‹ | æ€»è®­ç»ƒæ—¶é—´ | MMLU (en) â†“ | KoBEST (ko) â†‘ | LogicKor (ko) â†‘ | MT-Bench(ja) (ja) â†‘ |
|------|------------|-------------|---------------|------------------|---------------------|
| Llama3.1-8B-Instruct | - | 68.07 | 56.02 | 6.03 | 5.38 |
| Llama3.1-FFT | 19.8h | 67.51 | 66.08 | 7.31 | 6.99 |
| **Llama3.1-ELO** | **3.5h** | **66.69** | **60.81** | **7.76** | **5.58** |
| Mistral-ELO | 4.8h | 58.90 | 60.56 | 6.59 | 5.68 |
| Qwen2-ELO | 3.9h | 70.11 | 71.57 | 7.22 | â€” |

> âš ï¸ æ³¨æ„ï¼šELOä½¿ç”¨çš„é¢„è®­ç»ƒæ•°æ®é‡ç•¥å°‘ï¼ˆ9GB vs FFTçš„10GBï¼‰

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### âœ… æ•ˆç‡ä¼˜åŠ¿ï¼ˆTraining Speedï¼‰
- **å¹³å‡è®­ç»ƒé€Ÿåº¦æå‡ 5.88 å€**ï¼ˆç›¸æ¯”FFTï¼‰
- æœ€é«˜å¯è¾¾ **6.46å€åŠ é€Ÿ**ï¼ˆLlama3.1ï¼‰
- ç›¸æ¯”LoRAä¹Ÿå¿« **5.29~10.72å€**ï¼ˆéšæ•°æ®é‡å¢åŠ è€Œæ‰©å¤§å·®è·ï¼‰

> å›¾3æ˜¾ç¤ºï¼šå½“è®­ç»ƒæ•°æ®è¾¾åˆ°200GBæ—¶ï¼ŒELOæ¯”LoRAå¿« **10.72å€**

#### âœ… æ€§èƒ½ä¼˜åŠ¿ï¼ˆTarget Languageï¼‰
- åœ¨ **LogicKorï¼ˆéŸ©è¯­æ¨ç†ï¼‰** ä¸Šï¼š
  - Llama3.1-ELO è¾¾åˆ° **7.76**ï¼Œæ¯”FFTï¼ˆ7.31ï¼‰é«˜å‡º **0.45åˆ†ï¼ˆ+6.2%ï¼‰**
- åœ¨ **KoBEST** ä¸Šï¼š
  - æ‰€æœ‰ELOæ¨¡å‹å‡ä¼˜äº `-Instruct` åŸºçº¿ï¼ˆ+8.55% ~ +23.57%ï¼‰

#### âœ… æºè¯­è¨€ä¿æŠ¤ï¼ˆEnglish Capabilityï¼‰
- MMLU å¹³å‡ä»…ä¸‹é™ **2.42%**ï¼ˆvs `-Instruct`ï¼‰
- è¡¨æ˜å¤§éƒ¨åˆ†ä¸­é—´å±‚æœªè¢«ä¿®æ”¹ï¼Œæœ‰æ•ˆé˜²æ­¢ç¾éš¾æ€§é—å¿˜

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰ä¸åŒå±‚æ•°é€‰æ‹©çš„å½±å“ï¼ˆTable 3ï¼‰
| å±‚é…ç½® | LogicKorå¾—åˆ† | ç»“è®º |
|--------|--------------|------|
| (1,32) å³é¦–å°¾å±‚ | **7.76** | âœ… æœ€ä½³ |
| (1,16,32) | 7.69 | æ¥è¿‘æœ€ä¼˜ |
| (8,24) ä¸­é—´å±‚ | 5.00 | âŒ æå·® |
| (1,16) | 5.79 | âŒ ç¼ºå¤±æœ«å±‚ä¸¥é‡å½±å“æ€§èƒ½ |

> âœ”ï¸ æ”¯æŒå‡è®¾ï¼š**é¦–å±‚ï¼ˆè¾“å…¥ç¼–ç ï¼‰å’Œæœ«å±‚ï¼ˆè¾“å‡ºç”Ÿæˆï¼‰æœ€å…³é”®**

#### ï¼ˆ2ï¼‰å¯¹é½æ•°æ®é‡å½±å“ï¼ˆFigure 2ï¼‰
- **æ— éœ€å¯¹é½ï¼ˆ0GBï¼‰** â†’ LogicKorä»…å¾—4.5
- **1GBå¯¹é½æ•°æ®** â†’ æå‡è‡³7.76
- **1.5GB** â†’ è¾¾å³°å€¼7.78
- æ›´å¤šæ•°æ®æ— å¢ç›Šç”šè‡³è½»å¾®ä¸‹é™

> âœ… ç»“è®ºï¼š**ä»…éœ€çº¦1GBåŒè¯­æ•°æ®å³å¯å®Œæˆé«˜æ•ˆå¯¹é½**

#### ï¼ˆ3ï¼‰æ›´å¤§æ¨¡å‹è§„æ¨¡éªŒè¯ï¼ˆTable 2ï¼‰
- åœ¨ **Llama3.1-70B** ä¸Šåº”ç”¨ELOï¼š
  - LogicKorå¾—åˆ†ä»7.78ï¼ˆInstructï¼‰â†’ **8.65ï¼ˆELOï¼‰**
  - æå‡è¿‘ **10ä¸ªç™¾åˆ†ç‚¹**
> âœ”ï¸ è¡¨æ˜ELOå¯æ‰©å±•è‡³ç™¾äº¿å‚æ•°çº§åˆ«

#### ï¼ˆ4ï¼‰æ›´å¤šé¢„è®­ç»ƒæ•°æ®çš„æ•ˆæœ
- å°†ELOé¢„è®­ç»ƒæ•°æ®ä»10GBå¢è‡³200GBï¼š
  - LogicKorå¾—åˆ†ä»6.18 â†’ **6.97**
> âœ”ï¸ è¡¨æ˜ELOå…·å¤‡è‰¯å¥½çš„æ•°æ®æ‰©å±•æ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é¦–å±‚å’Œæœ«å±‚æ˜¯è¯­è¨€é€‚åº”çš„å…³é”®ç“¶é¢ˆå±‚**ï¼Œç‹¬ç«‹è®­ç»ƒå®ƒä»¬è¶³ä»¥æ³¨å…¥æœ‰æ•ˆçš„ç›®æ ‡è¯­è¨€çŸ¥è¯†ã€‚
2. **å‰¥ç¦»å…³é”®å±‚è¿›è¡Œç‹¬ç«‹è®­ç»ƒ** èƒ½ä»æ ¹æœ¬ä¸Šè§£å†³LoRAç±»æ–¹æ³•çš„å‰å‘ä¼ æ’­å¼€é”€é—®é¢˜ï¼Œå®ç°çœŸæ­£çš„é«˜æ•ˆè®­ç»ƒã€‚
3. **å³ä½¿å°‘é‡å¯¹é½æ•°æ®ï¼ˆ~1GBï¼‰ä¹Ÿèƒ½æœ‰æ•ˆèåˆæ–°æ—§çŸ¥è¯†**ï¼Œé¿å…å¤§è§„æ¨¡é‡è®­ã€‚
4. ELOåœ¨å¤šä¸ªä¸»æµLLMï¼ˆLlama/Mistral/Qwenï¼‰å’Œè¯­è¨€ï¼ˆKorean/Japaneseï¼‰ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œå…·æœ‰å¼ºæ³›åŒ–èƒ½åŠ›ã€‚
5. **å®šæ€§ç”Ÿæˆèƒ½åŠ›æ˜¾è‘—å¢å¼º**ï¼Œå°¤å…¶åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ï¼ˆå¦‚LogicKorï¼‰ä¸Šè¶…è¶ŠFFTã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä»éœ€ä¸€æ¬¡å°å‹FFTè¿›è¡ŒLayer Alignment**
   - è™½ç„¶ELOé˜¶æ®µèŠ‚çœå¤§é‡èµ„æºï¼Œä½†æœ€ç»ˆå¯¹é½é˜¶æ®µä»éœ€å…¨å‚æ•°æ›´æ–°ï¼Œ**æ— æ³•å®Œå…¨æ¶ˆé™¤å³°å€¼GPUå†…å­˜éœ€æ±‚**ã€‚
2. **å°šæœªéªŒè¯è¶…å¤§è§„æ¨¡æ•°æ®åœºæ™¯ï¼ˆ>1TBï¼‰ä¸‹çš„è¡¨ç°**
   - å½“å‰å®éªŒæœ€å¤§ä½¿ç”¨200GBæ•°æ®ï¼Œæ›´å¤§è§„æ¨¡çš„æ•°æ®æ˜¯å¦æŒç»­å—ç›Šå°šå¾…éªŒè¯ã€‚
3. **å±‚é€‰æ‹©ä¾èµ–ç»éªŒè§‚å¯Ÿ**
   - å½“å‰å›ºå®šé€‰æ‹©é¦–å°¾å±‚ï¼Œæœªæ¥å¯æ¢ç´¢è‡ªåŠ¨åŒ–å±‚é‡è¦æ€§è¯„ä¼°æœºåˆ¶ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢è‡ªåŠ¨è¯†åˆ«æœ€å…³é”®çš„â€œå¯è¿ç§»å±‚â€ç»„åˆ
- å°†ELOåº”ç”¨äºæ›´å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚100B+ï¼‰åŠæ›´å¤šä½èµ„æºè¯­è¨€
- ç»“åˆé‡åŒ–æŠ€æœ¯è¿›ä¸€æ­¥å‹ç¼©ELOæ¨¡å‹ä½“ç§¯
- æ‰©å±•è‡³å¤šè¯­è¨€è”åˆä¼˜åŒ–åœºæ™¯ï¼ˆåŒæ—¶å¢å¼ºå¤šç§è¯­è¨€ï¼‰

---

## æ€»ç»“
âœ… **ELOæ˜¯ä¸€ç§é«˜æ•ˆä¸”æœ‰æ•ˆçš„å¤šè¯­è¨€æŒç»­é¢„è®­ç»ƒæ–°èŒƒå¼**ã€‚å®ƒé€šè¿‡**å±‚å‰¥ç¦»ç­–ç•¥**æ‰“ç ´äº†ä¼ ç»ŸPEFTæ–¹æ³•çš„è®¡ç®—ç“¶é¢ˆï¼Œåœ¨**è®­ç»ƒé€Ÿåº¦æå‡5.88~6.46å€çš„åŒæ—¶ï¼Œæå‡äº†ç›®æ ‡è¯­è¨€å®šæ€§è¡¨ç°æœ€å¤š6.2%ï¼Œå¹¶è‰¯å¥½ä¿ç•™äº†æºè¯­è¨€èƒ½åŠ›**ã€‚è¯¥æ–¹æ³•ä¸ºä¸­å°ç ”ç©¶å›¢é˜Ÿä½æˆæœ¬å®šåˆ¶å¤šè¯­è¨€LLMæä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 10. [Atlas: Orchestrating Heterogeneous Models and Tools for Multi-Domain Complex Reasoning](https://arxiv.org/abs/2601.03872)

**Authors**: Jinyang Wu, Guocheng Zhai, Ruihan Jin, Jiahao Yuan, Yuhao Shen, Shuai Zhang, Zhengqi Wen, Jianhua Tao  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.03872v1  

#### Abstract
The integration of large language models (LLMs) with external tools has significantly expanded the capabilities of AI agents. However, as the diversity of both LLMs and tools increases, selecting the optimal model-tool combination becomes a high-dimensional optimization challenge. Existing approache...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Atlas: Orchestrating Heterogeneous Models and Tools for Multi-Domain Complex Reasoning â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸å¤–éƒ¨å·¥å…·ï¼ˆå¦‚è®¡ç®—å™¨ã€ä»£ç è§£é‡Šå™¨ã€æœç´¢å¼•æ“ç­‰ï¼‰çš„é›†æˆæ—¥ç›Šæ™®éï¼ŒAIä»£ç†çš„èƒ½åŠ›å¾—åˆ°äº†æ˜¾è‘—æ‰©å±•ã€‚ç„¶è€Œï¼Œå½“å¯ç”¨çš„LLMå’Œå·¥å…·ç§ç±»å¢å¤šæ—¶ï¼Œå¦‚ä½•åŠ¨æ€é€‰æ‹©æœ€ä¼˜çš„**æ¨¡å‹-å·¥å…·ç»„åˆ**ï¼ˆmodel-tool combinationï¼‰æˆä¸ºä¸€ä¸ªé«˜ç»´ä¼˜åŒ–éš¾é¢˜ã€‚

ç°æœ‰æ–¹æ³•å­˜åœ¨ä¸‰å¤§æŒ‘æˆ˜ï¼š
1. **æ— æ³•åˆ©ç”¨æ¨¡å‹-å·¥å…·ååŒæ•ˆåº”**ï¼ˆFailure to leverage model-tool synergiesï¼‰ï¼šå¤šæ•°è·¯ç”±æ–¹æ³•ä»…å…³æ³¨æ¨¡å‹é€‰æ‹©ï¼Œå¿½ç•¥äº†ç‰¹å®šæ¨¡å‹ä¸ç‰¹å®šå·¥å…·ä¹‹é—´çš„æ€§èƒ½äº’è¡¥ã€‚
2. **è°ƒç”¨é€»è¾‘åƒµåŒ–**ï¼ˆRigid invocationï¼‰ï¼šå·¥å…·è°ƒç”¨é€šå¸¸ä¾èµ–é¢„è®¾è§„åˆ™ï¼Œç¼ºä¹å¯¹ä»»åŠ¡éœ€æ±‚å’Œæ¨¡å‹èƒ½åŠ›çš„åŠ¨æ€é€‚åº”ã€‚
3. **å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¼˜åŒ–å­¤ç«‹**ï¼ˆIsolated optimization of RLï¼‰ï¼šå³ä½¿å¼•å…¥RLï¼Œä¹Ÿå¤šç”¨äºå•ä¸€ç»„ä»¶ä¼˜åŒ–ï¼Œæœªèƒ½è”åˆä¼˜åŒ–æ¨¡å‹ä¸å·¥å…·çš„ååŒè·¯å¾„ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **ATLAS**ï¼ˆAdaptive Tool-LLM Alignment and Synergistic Invocationï¼‰ï¼Œä¸€ä¸ªåŒè·¯å¾„æ¡†æ¶ï¼Œç”¨äºåœ¨è·¨é¢†åŸŸå¤æ‚æ¨ç†ä¸­åŠ¨æ€åè°ƒå¼‚æ„æ¨¡å‹ä¸å·¥å…·ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š

- **åŒè·¯å¾„æ¶æ„è®¾è®¡**ï¼š
  - **è®­ç»ƒå…è´¹çš„èšç±»è·¯ç”±**ï¼ˆTraining-free Cluster-based Routingï¼‰ï¼šåŸºäºè¯­ä¹‰åµŒå…¥ç©ºé—´ä¸­çš„å†å²æ€§èƒ½æ¨¡å¼ï¼Œå®ç°å¿«é€Ÿã€é«˜æ•ˆçš„é¢†åŸŸå†…æ¨ç†ã€‚
  - **åŸºäºRLçš„å¤šæ­¥è·¯ç”±**ï¼ˆRL-driven Multi-step Routingï¼‰ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ æ¢ç´¢è‡ªä¸»æ¨ç†è½¨è¿¹ï¼Œæå‡å¯¹åˆ†å¸ƒå¤–ï¼ˆOODï¼‰ä»»åŠ¡çš„æ³›åŒ–èƒ½åŠ›ã€‚

- **è”åˆä¼˜åŒ–æ¨¡å‹-å·¥å…·ç»„åˆ**ï¼šå°†æœç´¢ç©ºé—´å®šä¹‰ä¸º $ \mathcal{S} = \mathcal{M} \times \mathcal{T} $ï¼Œæ˜¾å¼å»ºæ¨¡æ¨¡å‹ä¸å·¥å…·çš„ååŒå…³ç³»ï¼Œè€Œéå•ç‹¬ä¼˜åŒ–ã€‚

- **å¤åˆå¥–åŠ±å‡½æ•°è®¾è®¡**ï¼šåœ¨RLè·¯å¾„ä¸­å¼•å…¥ä¸‰é¡¹å¥–åŠ±ä¿¡å·ï¼š
  - **æ ¼å¼å¥–åŠ±**ï¼ˆRfmtï¼‰ï¼šç¡®ä¿è¯­æ³•æ­£ç¡®æ€§ï¼›
  - **ç»“æœå¥–åŠ±**ï¼ˆRoutï¼‰ï¼šè¡¡é‡ä»»åŠ¡æ­£ç¡®æ€§ï¼›
  - **æ¨¡å‹é€‰æ‹©å¥–åŠ±**ï¼ˆRselï¼‰ï¼šå¼•å¯¼é€‰æ‹©é«˜æ•ˆæ¨¡å‹ï¼Œé¿å…èµ„æºæµªè´¹ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

- **æ€§èƒ½æ›´å¼º**ï¼šåœ¨15ä¸ªåŸºå‡†ä¸Šè¶…è¶Šé—­æºæ¨¡å‹ï¼ˆå¦‚GPT-4oï¼‰ï¼Œåœ¨åˆ†å¸ƒå†…ä»»åŠ¡ä¸Šå¹³å‡æå‡+10.1%ï¼Œåˆ†å¸ƒå¤–ä»»åŠ¡ä¸Š+13.1%ã€‚
- **çµæ´»æ€§æ›´é«˜**ï¼šæ”¯æŒå¤šè½®åŠ¨æ€æ¨ç†ä¸å·¥å…·è°ƒç”¨ï¼Œé€‚åº”å¼€æ”¾åŸŸå¤æ‚ä»»åŠ¡ã€‚
- **å¯æ‰©å±•æ€§å¼º**ï¼šæ— éœ€é‡æ–°è®­ç»ƒå³å¯æ— ç¼é›†æˆæ–°æ¨¡å‹å’Œå·¥å…·ï¼ˆè§åŠ¨æ€æ± æ‰©å±•å®éªŒï¼‰ã€‚
- **æˆæœ¬å¯æ§**ï¼šé€šè¿‡æ€§èƒ½-æˆæœ¬æƒè¡¡æœºåˆ¶ï¼Œåœ¨ä¿è¯ç²¾åº¦çš„åŒæ—¶æ§åˆ¶æ¨ç†å¼€é”€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

å…±æ¶µç›– **10ä¸ªæ–‡æœ¬ä»»åŠ¡** å’Œ **5ä¸ªå¤šæ¨¡æ€ä»»åŠ¡**ï¼Œè¦†ç›–å¤šä¸ªé¢†åŸŸï¼š

| ç±»åˆ« | æ•°æ®é›† |
|------|--------|
| æ•°å­¦æ¨ç† | AIME2024, AIME2025, AMC |
| ç¼–ç¨‹ç”Ÿæˆ | HumanEval, MBPP |
| ç®—æœ¯æ¨ç† | Calculator |
| å¸¸è¯†æ¨ç† | Natural Questions (NQ), WebQ |
| é€»è¾‘æ¨ç† | LogiQA2 |
| ç§‘å­¦æ¨ç† | GPQA |
| å¤šæ¨¡æ€è§†è§‰æ¨ç† | ChartQA, Geometry3K, TallyQA, CountBench, TableVQA |

æµ‹è¯•æ ·æœ¬æ€»æ•°è¶…è¿‡4000ï¼Œå…·æœ‰å¹¿æ³›ä»£è¡¨æ€§ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **è¯„ä¼°åè®®**ï¼š
  - **åˆ†å¸ƒå†…**ï¼ˆIn-Distributionï¼‰ï¼šæ‰€æœ‰æ•°æ®é›†å‡æœ‰è®­ç»ƒé›†ï¼Œç”¨äºè¯„ä¼°ç†Ÿæ‚‰é¢†åŸŸçš„æ€§èƒ½ã€‚
  - **åˆ†å¸ƒå¤–**ï¼ˆOut-of-Distributionï¼‰ï¼šä»…åœ¨ `Calculator`, `NQ`, `MBPP` ä¸Šè®­ç»ƒï¼Œå…¶ä½™ä»»åŠ¡è§†ä¸ºOODï¼Œæ£€éªŒæ³›åŒ–èƒ½åŠ›ã€‚

- **è¯„ä¼°æŒ‡æ ‡**ï¼šä¸»è¦ä½¿ç”¨ **Accuracy**ï¼ˆå‡†ç¡®ç‡ï¼‰ä½œä¸ºæ ¸å¿ƒæŒ‡æ ‡ã€‚

- **æ¨¡å‹æ± **ï¼ˆModel Poolï¼‰ï¼š
  - åŒ…æ‹¬6ä¸ªå¼€æºLLMï¼šQwen2.5-7B, Llama-3.1-8B, InternLM3-8B, DeepSeek-R1-Distill-Qwen-7B, Qwen2.5-Coder-7B, Qwen3-8B-VLï¼ˆå¤šæ¨¡æ€ï¼‰ã€‚

- **å·¥å…·æ± **ï¼ˆTool Poolï¼‰ï¼š
  - **åŸºç¡€å·¥å…·**ï¼šCode Interpreter, Web Search, Calculator, Process Reward Model (PRM)
  - **å¤šæ¨¡æ€å·¥å…·**ï¼šQwen3-Chart, Qwen3-Counting, Qwen3-Geo, Hunyuan-OCR

- **RLè®­ç»ƒç»†èŠ‚**ï¼š
  - ç­–ç•¥æ¨¡å‹ï¼šQwen2.5-3B-Instruct
  - ä¼˜åŒ–ç®—æ³•ï¼šPPOï¼ˆProximal Policy Optimizationï¼‰
  - æ‰¹å¤§å°ï¼š32ï¼Œè®­ç»ƒæ­¥æ•°ï¼š250ï¼Œå­¦ä¹ ç‡ï¼š1e-6

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|---------|------|------|
| Zero-shot / Few-shot Router | æŸ¥è¯¢è·¯ç”± | ç›´æ¥æç¤ºæˆ–ä¸Šä¸‹æ–‡ç¤ºä¾‹é€‰æ‹©æ¨¡å‹-å·¥å…· |
| Random Router | éšæœºç­–ç•¥ | å®Œå…¨éšæœºé€‰æ‹© |
| RouterDC (Chen et al., 2024) | å¯¹æ¯”å­¦ä¹ è·¯ç”± | åŸºäºåŒå¯¹æ¯”å­¦ä¹ ä¼˜åŒ–æŸ¥è¯¢-æ¨¡å‹å¯¹é½ |
| MLPRouter (Hu et al., 2024) | åˆ†ç±»å™¨è·¯ç”± | æ¯ä¸ªæ¨¡å‹-å·¥å…·ç»„åˆè®­ç»ƒä¸€ä¸ªMLPé¢„æµ‹æˆåŠŸç‡ |
| BertRouter (Ong et al., 2024) | ç¼–ç å™¨åˆ†ç±» | ä½¿ç”¨mDeBERTaç¼–ç æŸ¥è¯¢å¹¶åˆ†ç±»æœ€ä½³ç»„åˆ |

æ­¤å¤–è¿˜å¯¹æ¯”äº†é—­æºæ¨¡å‹ï¼šGPT-4o, GPT-4.1, GPT-5, Gemini 2.5-Pro/Flashã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **åˆ†å¸ƒå†…æ€§èƒ½ï¼ˆIn-Distributionï¼‰**
- **ATLAS (cluster)** å¹³å‡å‡†ç¡®ç‡è¾¾ **63.5%**ï¼Œæ˜¾è‘—ä¼˜äºæœ€å¼ºåŸºçº¿ **RouterDC (53.4%)**ï¼Œæå‡ **+10.1%**ã€‚
- åœ¨æ•°å­¦ä»»åŠ¡ä¸Šè¡¨ç°å°¤ä¸ºçªå‡ºï¼š
  - AIME25: **40.0%** vs. RouterDC çš„ 23.3%
  - AMC: **82.5%** vs. 62.5%
- è¶…è¶Š **GPT-4o (53.1%)**ï¼Œæ¥è¿‘ **GPT-4.1 (63.0%)**ï¼Œè¡¨æ˜å°è§„æ¨¡æ¨¡å‹é€šè¿‡æ™ºèƒ½ç¼–æ’å¯åª²ç¾å¤§æ¨¡å‹ã€‚

#### **åˆ†å¸ƒå¤–æ€§èƒ½ï¼ˆOut-of-Distributionï¼‰**
- **ATLAS (RL)** å¹³å‡å‡†ç¡®ç‡ **59.4%**ï¼Œè¿œè¶… ATLAS (cluster) çš„ 49.2% å’Œ RouterDC çš„ 46.3%ï¼Œæå‡ **+13.1%**ã€‚
- åœ¨ AIME24 ä¸Šè¾¾åˆ° **43.3%**ï¼ˆATLAS cluster ä»…ä¸º 13.3%ï¼‰ï¼Œæ˜¾ç¤ºRLè·¯å¾„å…·å¤‡å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚
- å³ä½¿é¢å¯¹æœªè§è¿‡çš„ä»»åŠ¡ï¼ˆå¦‚GPQAï¼‰ï¼Œä»èƒ½ç»´æŒ **42.0%** å‡†ç¡®ç‡ï¼Œæ¥è¿‘GPT-4oæ°´å¹³ã€‚

#### **å¤šæ¨¡æ€ä»»åŠ¡è¡¨ç°**
- åœ¨5ä¸ªè§†è§‰æ¨ç†ä»»åŠ¡ä¸Šï¼ŒATLASå¹³å‡å‡†ç¡®ç‡ **68.9%**ï¼Œä¼˜äºæœ€å¼ºå•å·¥å…·åŸºçº¿ **+4.3%**ã€‚
- åœ¨ ChartQA ä¸Šè¶…è¶Šæœ€ä½³å•å·¥å…·ï¼ˆQwen3-Chartï¼‰è¾¾ **+1.0%**ï¼ˆ84.0% vs. 83.0%ï¼‰ã€‚
- æ˜¾è‘—å…‹æœå•ä¸€å·¥å…·å±€é™ï¼Œä¾‹å¦‚ Qwen3-Chart åœ¨ Geometry3K ä¸Šä»…å¾— 50.2%ï¼Œè€Œ ATLAS è¾¾åˆ° 65.6%ã€‚

#### **åŠ¨æ€æ¨¡å‹-å·¥å…·æ± æ‰©å±•å®éªŒ**
- æ–°å¢åŒ»å­¦ä¸“ç”¨æ¨¡å‹ï¼ˆLlama-3.1-8B-UltraMedicalï¼‰ã€æ•°å­¦ä¸“å®¶æ¨¡å‹ï¼ˆQwen2.5-Math-7Bï¼‰åŠéªŒè¯å·¥å…·ã€‚
- **ATLAS(RL)** å‡†ç¡®ç‡ä» **59.4% â†’ 61.7%**ï¼ˆ+2.3%ï¼‰ï¼Œè¯æ˜å…¶å¯æ— ç¼é›†æˆæ–°ç»„ä»¶ã€‚
- åŸºçº¿æ–¹æ³•ï¼ˆå¦‚BertRouterï¼‰ä»…å¾®å¼±æå‡æˆ–é€€åŒ–ï¼Œè¯´æ˜å…¶å†³ç­–è¾¹ç•Œå›ºå®šï¼Œéš¾ä»¥é€‚åº”å˜åŒ–ã€‚

### **æ¶ˆèå®éªŒç»“æœ**

| æ¶ˆèæ¡ä»¶ | å¹³å‡å‡†ç¡®ç‡ | Î” vs. å…¨æ¨¡å‹ |
|----------|-----------|-------------|
| å®Œæ•´ ATLAS(RL) | **59.4%** | â€” |
| ç§»é™¤ Rselï¼ˆæ¨¡å‹é€‰æ‹©å¥–åŠ±ï¼‰ | 56.3% | -3.1% |
| ç§»é™¤ Rfmtï¼ˆæ ¼å¼å¥–åŠ±ï¼‰ | 53.3% | -6.1% |

- **Rfmt è‡³å…³é‡è¦**ï¼šç§»é™¤åå¯¼è‡´å¤§é‡éæ³•å·¥å…·è°ƒç”¨ï¼Œæ¨ç†å¤±è´¥ç‡ä¸Šå‡ã€‚
- **Rsel æ˜¯æ•ˆç‡è¾…åŠ©ä¿¡å·**ï¼šè™½éå¿…éœ€ï¼Œä½†æœ‰åŠ©äºåŠ é€Ÿæ”¶æ•›ã€é™ä½ç†µå€¼ï¼Œæå‡æ¨ç†æ•ˆç‡ã€‚
- ç»“è®ºï¼š**Rfmt å’Œ Rout æ˜¯æ ¸å¿ƒä¿¡å·ï¼ŒRsel æ˜¯å¯é€‰ä¼˜åŒ–é¡¹**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **æ¨¡å‹-å·¥å…·ååŒè‡³å…³é‡è¦**ï¼šç®€å•å †å æ¨¡å‹æˆ–å·¥å…·ä¸è¶³ä»¥å‘æŒ¥æœ€å¤§æ½œåŠ›ï¼Œå¿…é¡»æ˜¾å¼å»ºæ¨¡äºŒè€…ååŒå…³ç³»ã€‚
2. **åŒè·¯å¾„è®¾è®¡æœ‰æ•ˆå¹³è¡¡æ•ˆç‡ä¸æ³›åŒ–**ï¼š
   - èšç±»è·¯ç”±é€‚åˆæœ‰å†å²æ•°æ®çš„ç¨³å®šåœºæ™¯ï¼Œé›¶è®­ç»ƒæˆæœ¬ã€å“åº”å¿«ï¼›
   - RLè·¯ç”±é€‚åˆæœªçŸ¥ä»»åŠ¡ï¼Œé€šè¿‡æ¢ç´¢å­¦ä¹ é€šç”¨å†³ç­–åŸåˆ™ã€‚
3. **ATLAS å¯åª²ç¾ç”šè‡³è¶…è¶Šé—­æºå¤§æ¨¡å‹**ï¼šåœ¨åˆç†ç¼–æ’ä¸‹ï¼Œ7Bâ€“8Bçº§å¼€æºæ¨¡å‹å¯è¾¾åˆ°GPT-4çº§åˆ«æ€§èƒ½ã€‚
4. **å¤šæ¨¡æ€ä»»åŠ¡å—ç›Šæ˜æ˜¾**ï¼šé€šè¿‡åŠ¨æ€è°ƒåº¦ä¸“ç”¨è§†è§‰å·¥å…·ï¼ˆå¦‚å‡ ä½•è§£æã€å›¾è¡¨æå–ï¼‰ï¼Œæ˜¾è‘—æå‡å¤æ‚è§†è§‰æ¨ç†èƒ½åŠ›ã€‚
5. **ç³»ç»Ÿå…·å¤‡è‰¯å¥½å¯æ‰©å±•æ€§**ï¼šæ— éœ€é‡è®­ç»ƒå³å¯æ¥å…¥æ–°æ¨¡å‹/å·¥å…·ï¼Œé€‚ç”¨äºæŒç»­æ¼”è¿›çš„AIç”Ÿæ€ç³»ç»Ÿã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

1. **æ¨¡æ€å—é™**ï¼šå½“å‰è¯„ä¼°é›†ä¸­äºæ–‡æœ¬ä¸å›¾åƒï¼Œæœªæ¶‰åŠéŸ³é¢‘ã€è§†é¢‘ç­‰å…¶ä»–æ¨¡æ€ã€‚
2. **ä¾èµ–APIç¨³å®šæ€§**ï¼šè‹¥å¤–éƒ¨å·¥å…·æœåŠ¡ä¸å¯ç”¨æˆ–å»¶è¿Ÿé«˜ï¼Œå¯èƒ½å½±å“æ€§èƒ½ã€‚
3. **RLè®­ç»ƒæˆæœ¬è¾ƒé«˜**ï¼šè™½ç„¶æ¨ç†é˜¶æ®µé«˜æ•ˆï¼Œä½†ç­–ç•¥è®­ç»ƒéœ€è¦ä¸€å®šè®¡ç®—èµ„æºï¼ˆ250æ­¥PPOè®­ç»ƒï¼‰ã€‚
4. **å¥–åŠ±è®¾è®¡ä¾èµ–å…ˆéªŒçŸ¥è¯†**ï¼šRselä¾èµ–ç¦»çº¿è¯„ä¼°ç¡®å®šâ€œæœ€ä¼˜æ¨¡å‹â€ï¼Œå¯èƒ½å­˜åœ¨åå·®ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- æ¢ç´¢æ›´è½»é‡çº§çš„ç­–ç•¥æ¶æ„ä»¥é™ä½è®­ç»ƒå¼€é”€ã€‚
- å¼•å…¥å®¹é”™æœºåˆ¶åº”å¯¹å·¥å…·è°ƒç”¨å¤±è´¥æˆ–ç½‘ç»œå¼‚å¸¸ã€‚
- æ‰©å±•è‡³å¤šæ¨¡æ€é•¿åºåˆ—ä»»åŠ¡ï¼ˆå¦‚è§†é¢‘ç†è§£ã€è¯­éŸ³äº¤äº’ï¼‰ã€‚
- ç»“åˆ Test-Time Scalingï¼ˆå¦‚Self-Consistencyï¼‰è¿›ä¸€æ­¥æå‡é²æ£’æ€§ã€‚
- æ¢ç´¢æ— ç›‘ç£æˆ–è‡ªåé¦ˆæ–¹å¼æ›¿ä»£äººå·¥æ ‡æ³¨å¥–åŠ±ä¿¡å·ï¼ˆå¦‚RLAIFï¼‰ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> ATLAS æå‡ºäº†ä¸€ç§**ç”Ÿæ€ç³»ç»Ÿçº§çš„æ™ºèƒ½ç¼–æ’èŒƒå¼**ï¼Œé€šè¿‡åŒè·¯å¾„æœºåˆ¶å®ç°äº†å¯¹å¼‚æ„LLMä¸å·¥å…·çš„åŠ¨æ€ã€é«˜æ•ˆã€å¯æ³›åŒ–çš„ååŒè°ƒåº¦ï¼Œåœ¨æ€§èƒ½ã€çµæ´»æ€§ä¸å¯æ‰©å±•æ€§ä¹‹é—´å–å¾—äº†å“è¶Šå¹³è¡¡ï¼Œä¸ºä¸‹ä¸€ä»£ agentic reasoning systems æä¾›äº†é‡è¦å‚è€ƒã€‚

</details>

---

### 11. [SIGMA: Scalable Spectral Insights for LLM Collapse](https://arxiv.org/abs/2601.03385)

**Authors**: Yi Gu, Lingyou Pang, Xiangkun Ye, Tianyu Wang, Jianyu Lin, Carey E. Priebe, Alexander Aue  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.03385v1  

#### Abstract
The rapid adoption of synthetic data for training Large Language Models (LLMs) has introduced the technical challenge of "model collapse"-a degenerative process where recursive training on model-generated content leads to a contraction of distributional variance and representational quality. While t...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# SIGMA: Scalable Spectral Insights for LLM Collapse è®ºæ–‡æ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡èšç„¦äº**LLM Collapse**ï¼ˆå¤§è¯­è¨€æ¨¡å‹å´©æºƒï¼‰è¿™ä¸€æ—¥ç›Šä¸¥é‡çš„é—®é¢˜ã€‚éšç€åˆæˆæ•°æ®åœ¨è®­ç»ƒ LLM ä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œæ¨¡å‹é€šè¿‡é€’å½’åœ°ä½¿ç”¨è‡ªèº«ç”Ÿæˆçš„æ•°æ®è¿›è¡Œå†è®­ç»ƒï¼Œä¼šå¯¼è‡´å…¶è¡¨ç¤ºç©ºé—´é€æ¸é€€åŒ–â€”â€”å³â€œæ¨¡å‹å´©æºƒâ€ã€‚è¿™ç§ç°è±¡è¡¨ç°ä¸ºè¯­ä¹‰å¤šæ ·æ€§ä¸§å¤±ã€åˆ†å¸ƒæ–¹å·®æ”¶ç¼©ä»¥åŠç”Ÿæˆè´¨é‡ä¸‹é™ã€‚

å°½ç®¡å·²æœ‰ç ”ç©¶æè¿°äº†å´©æºƒçš„ç°è±¡å­¦ç‰¹å¾ï¼Œä½†åœ¨é«˜ç»´åµŒå…¥ç©ºé—´ä¸­ç¼ºä¹**å¯æ‰©å±•ã€æ•°å­¦ä¸¥è°¨ä¸”èƒ½æ—©æœŸé¢„è­¦**çš„æ–¹æ³•æ¥é‡åŒ–å’Œé¢„æµ‹å´©æºƒçš„å‘ç”Ÿã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº† **SIGMA**ï¼ˆSpectral Inequalities for Gram Matrix Analysisï¼‰ï¼Œä¸€ä¸ªåŸºäºè°±åˆ†æçš„ç»Ÿä¸€æ¡†æ¶ï¼Œç”¨äºç›‘æµ‹å’Œé‡åŒ– LLM å´©æºƒï¼š

- **æ ¸å¿ƒæ€æƒ³**ï¼šåˆ©ç”¨ LLM åµŒå…¥å‘é‡æ„æˆçš„ **Gram çŸ©é˜µ** çš„è°±ç‰¹æ€§ï¼ˆç‰¹åˆ«æ˜¯å…¶ç‰¹å¾å€¼åˆ†å¸ƒï¼‰ä½œä¸ºè¡¡é‡è¡¨ç¤ºç©ºé—´å¥åº·çŠ¶æ€çš„æŒ‡æ ‡ã€‚
- **ç†è®ºåŸºç¡€**ï¼šæå‡ºå¹¶æ¨å¯¼äº† Gram çŸ©é˜µè¡Œåˆ—å¼çš„**ç¡®å®šæ€§è¾¹ç•Œ**ï¼ˆåŸºäº Weyl ä¸ç­‰å¼å’Œ Ky Fan ä¸»å¯¼ï¼‰å’Œ**éšæœºè¾¹ç•Œ**ï¼ˆåŸºäºå¤§æ•°å®šå¾‹ï¼‰ï¼Œä»è€Œå¯ä»¥åœ¨ä¸è®¡ç®—å®Œæ•´è°±çš„æƒ…å†µä¸‹ä¼°è®¡è¡¨ç¤ºç©ºé—´çš„æ”¶ç¼©ç¨‹åº¦ã€‚
- **å…³é”®æŒ‡æ ‡**ï¼šå¼•å…¥ `log det G` ä½œä¸ºä¸»åº¦é‡ï¼Œå½“æ¨¡å‹å´©æºƒæ—¶ï¼ŒGram çŸ©é˜µè¶‹äºä½ç§©ï¼Œå¯¼è‡´ `log det G â†’ -âˆ`ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | SIGMA çš„ä¼˜åŠ¿ |
|------|-------------|
| **å¯æ‰©å±•æ€§** | æ”¯æŒå­é‡‡æ ·ç­–ç•¥ï¼Œä»…éœ€è§‚å¯Ÿéƒ¨åˆ†æ•°æ®å³å¯ä¼°ç®—å…¨çŸ©é˜µæ€§è´¨ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡æ¨¡å‹ï¼ˆé¿å…å…¨ç‰¹å¾åˆ†è§£ï¼‰ |
| **ç†è®ºä¿éšœ** | æä¾›ä¸¥æ ¼çš„æ•°å­¦è¾¹ç•Œï¼ˆç¡®å®šæ€§å’Œéšæœºæ€§ï¼‰ï¼Œè€Œéå¯å‘å¼ç»Ÿè®¡é‡ |
| **æ•æ„Ÿæ€§ä¸é²æ£’æ€§ç»“åˆ** | åŒè½¨è¯Šæ–­æœºåˆ¶ï¼šä¸€æ¡è½¨é“å¯¹è°±æ”¶ç¼©æ•æ„Ÿï¼ˆTrack IIï¼‰ï¼Œå¦ä¸€æ¡ä¸ºä¿å®ˆåŒ…ç»œï¼ˆTrack Iï¼‰ï¼ŒäºŒè€…äº’è¡¥ |
| **å‡ ä½•è§†è§’** | è¶…è¶Š token-level æˆ– surface-form ç»Ÿè®¡ï¼ˆå¦‚ n-gram é‡å¤ç‡ï¼‰ï¼Œä»åµŒå…¥ç©ºé—´çš„å‡ ä½•ç»“æ„å˜åŒ–ç†è§£å´©æºƒæœ¬è´¨ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨ **DecayBench** æä¾›çš„è®¸å¯æ¸…æ´çœŸå®è¯­æ–™åº“ï¼ˆreal corporaï¼‰ï¼Œæ¶µç›–å››ä¸ªé¢†åŸŸï¼š
  - `CIVICS`, `FINANCE (FIN)`, `SCIENCE`, `SOFTWARE`
- æ¯ä¸ªé¢†åŸŸæä¾›ï¼š
  - å›ºå®šåˆ‡ç‰‡çš„çœŸå®ä¸Šä¸‹æ–‡ï¼ˆ64-token blocksï¼‰
  - å†»ç»“çš„æç¤ºé“¶è¡Œï¼ˆfrozen prompt bankï¼‰ï¼Œå«ç¨³å®š ID å’Œåˆ†ç±»æ ‡ç­¾ï¼ˆå¦‚ Creative, Neutral ç­‰ï¼‰

> æ‰€æœ‰å®éªŒå‡ä»¥ **FINANCE (FIN)** é¢†åŸŸä¸ºä¸»æŠ¥å‘Šå¯¹è±¡ã€‚

---

### å®éªŒè®¾ç½®

#### ä¸¤ä¸ªé€’å½’è®¾ç½®ï¼ˆS1 vs S2ï¼‰
| è®¾ç½® | åç§° | æè¿° |
|------|------|------|
| **S1** | Restart-from-base (ä»…æ•°æ®é€’å½’) | æ¯ä»£é‡æ–°ç”Ÿæˆåˆæˆæ•°æ®ï¼Œä½†è®­ç»ƒå§‹ç»ˆä»åŒä¸€åˆå§‹æ£€æŸ¥ç‚¹ `M(0)` å¼€å§‹ |
| **S2** | True recursion (æ•°æ® + æƒé‡é€’å½’) | æ¯ä»£ä½¿ç”¨å‰ä¸€ä»£æ¨¡å‹æƒé‡ç»§ç»­å¾®è°ƒï¼Œå½¢æˆçœŸæ­£çš„é€’å½’é“¾ |

> ç›®æ ‡ï¼šåˆ†ç¦»â€œæƒé‡ç´¯ç§¯â€å¯¹å´©æºƒçš„å½±å“ã€‚

#### åˆæˆæ•°æ®ç”Ÿæˆåè®®
- æ¯ä¸ªçœŸå®ä¸Šä¸‹æ–‡ä½œä¸º promptï¼Œç”±ä¸Šä¸€ä»£æ¨¡å‹ç”Ÿæˆå›ºå®šé•¿åº¦å»¶ç»­
- è®­ç»ƒæ•°æ®ä¸ºåˆæˆä¸çœŸå®æ ·æœ¬çš„æ··åˆç‰©ï¼Œæ€»å—æ•°æ’å®š
- å®éªŒä¸­è®¾çœŸå®æ¯”ä¾‹ Î± = 0ï¼ˆçº¯åˆæˆè®­ç»ƒï¼‰ï¼Œä»¥å‹åŠ›æµ‹è¯•é€’å½’å½±å“

#### æ¨¡å‹ä¸è®­ç»ƒç»†èŠ‚
- åŸºç¡€æ¨¡å‹ï¼š`facebook/opt-125m`
- å¾®è°ƒé…ç½®ï¼šå›ºå®šä¼˜åŒ–å™¨ï¼ˆAdamWï¼‰ã€å­¦ä¹ ç‡ï¼ˆ2e-5ï¼‰ã€batch sizeï¼ˆ16ï¼‰ã€epoch æ•°ï¼ˆæ¯ä»£ 5ï¼‰
- è§£ç å‚æ•°ï¼štop-p=0.95, temperature=1.0ï¼Œéè´ªå©ªé‡‡æ ·

---

### è¯„ä¼°æŒ‡æ ‡

#### ä¸»è¦æŒ‡æ ‡ï¼ˆSIGMA-UB åŒè½¨è¯Šæ–­ï¼‰
1. **Track II: â–³ULLN.cov(Î´)**  
   - åŸºäºéšæœºç¼©æ”¾å¾‹çš„åæ–¹å·®å½’ä¸€åŒ–ä»£ç†
   - æ•æ„Ÿè¶‹åŠ¿æ¢æµ‹å™¨ï¼Œåæ˜ è§‚æµ‹å­è°±æ”¶ç¼©
2. **Track I: â–³GKF(Î´)**  
   - åŸºäºç¡®å®šæ€§è¾¹ç•Œçš„å°¾éƒ¨èƒ½é‡é¢„ç®—åŒ…ç»œ
   - ä¿å®ˆä¸Šé™ï¼Œæ§åˆ¶æœ€åæƒ…å†µä¸‹çš„è¯¯å·®

> ä¸¤è€…å‡ä¸ºç›¸å¯¹äºåˆå§‹æ£€æŸ¥ç‚¹ï¼ˆg=0ï¼‰çš„æ¼‚ç§»å€¼ï¼Œè´Ÿæ¼‚ç§»è¡¨ç¤ºå´©æºƒè¿¹è±¡ã€‚

#### è¾…åŠ©è¡¨é¢å½¢å¼ä»£ç†ï¼ˆéå®šä¹‰æ€§æŒ‡æ ‡ï¼‰
- `distinct-2`ï¼šå”¯ä¸€ bigram æ¯”ä¾‹ï¼ˆè¶Šé«˜è¶Šå¤šæ ·ï¼‰
- `hashed n-gram HHI`ï¼šå“ˆå¸Œ n-gram çš„èµ«èŠ¬è¾¾å°”æŒ‡æ•°ï¼ˆè¶Šé«˜è¶Šé›†ä¸­ï¼‰

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æœ¬æ–‡æœªç›´æ¥ä¸å…¶ä»–å´©æºƒæ£€æµ‹ç®—æ³•æ¯”è¾ƒï¼Œè€Œæ˜¯ï¼š
- å°† **S1 vs S2** è§†ä¸ºå†…éƒ¨åŸºçº¿ï¼ŒéªŒè¯æƒé‡é€’å½’æ˜¯å¦åŠ å‰§å´©æºƒ
- ä½¿ç”¨è¡¨é¢å½¢å¼æŒ‡æ ‡ï¼ˆå¦‚ HHIï¼‰ä½œä¸ºä¼ ç»Ÿè§†è§’çš„å‚ç…§ï¼Œè¯´æ˜ SIGMA èƒ½æ›´æ—©æ•æ‰åˆ°æ·±å±‚å‡ ä½•é€€åŒ–

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1, FIN é¢†åŸŸï¼Œg_max=50ï¼‰

| Setting | â–³ULLN.cov (final) | slope_LLN.cov | â–³GKF (final) | slope_KF | Track agreement? |
|--------|-------------------|---------------|--------------|----------|------------------|
| **S1** | -150.986          | -0.941        | -142.051     | -0.918   | yes (both neg)   |
| **S2** | -1536.562         | -42.621       | -2.426       | +2.350   | no               |

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ **S1ï¼ˆä»…æ•°æ®é€’å½’ï¼‰** ä¸­ï¼š
  - ä¸¤æ¡è½¨é“å‡å‘ˆç°æŒç»­è´Ÿæ¼‚ç§»ï¼ˆçº¦ -150ï¼‰ï¼Œè¡¨æ˜å³ä½¿æ²¡æœ‰æƒé‡ç´¯ç§¯ï¼Œä»…é åˆæˆæ•°æ®æ¼”åŒ–ä¹Ÿä¼šå¼•å‘ç¼“æ…¢å´©æºƒã€‚
- åœ¨ **S2ï¼ˆçœŸé€’å½’ï¼‰** ä¸­ï¼š
  - **Track II** æ¼‚ç§»æ€¥å‰§æ¶åŒ–è‡³ **-1536**ï¼Œæ–œç‡ä¸º -42.6ï¼Œæ˜¾ç¤ºå´©æºƒè¢«æ˜¾è‘—åŠ é€Ÿã€‚
  - **Track I** å‡ ä¹æ— æ˜æ˜¾è´Ÿæ¼‚ç§»ï¼ˆæœ€ç»ˆä»… -2.4ï¼‰ï¼Œç”šè‡³ç•¥æœ‰ä¸Šå‡ï¼ˆæ­£æ–œç‡ï¼‰ï¼Œå› å…¶å—æœ€åæƒ…å†µå°¾éƒ¨é¢„ç®—æ§åˆ¶ï¼Œæœªèƒ½å“åº”å®é™…è°±æ”¶ç¼©ã€‚

> âœ… **ç»“è®º**ï¼šæƒé‡é€’å½’æå¤§åœ°æ”¾å¤§äº†å´©æºƒé€Ÿåº¦ï¼›SIGMA-UB çš„åŒè½¨è®¾è®¡æˆåŠŸæ­ç¤ºäº†è¿™ä¸€å·®å¼‚ã€‚

---

### æ¶ˆèå®éªŒä¸è¡¥å……åˆ†æï¼ˆAppendixï¼‰

#### è¡¨é¢å½¢å¼ä»£ç†ä¸€è‡´æ€§ï¼ˆTable 14ï¼‰
| Setting | distinct-2 (g=50) | HHI (g=50) | Spearman(â–³U, HHI) |
|--------|-------------------|------------|--------------------|
| S1     | 0.334             | 0.013      | -0.318             |
| S2     | 0.254             | 0.097      | **-0.685**         |

- S2 ä¸­ n-gram æµ“åº¦å¢åŠ è¿‘ä¸‰ä¸ªæ•°é‡çº§ï¼Œä¸”ä¸ Track II æ¼‚ç§»é«˜åº¦å•è°ƒç›¸å…³ï¼ˆå¼ºè´Ÿ Spearman ç›¸å…³æ€§ï¼‰ï¼ŒéªŒè¯äº†å‡ ä½•æ”¶ç¼©ä¸è¡¨é¢é€€åŒ–çš„å…³è”ã€‚

#### æ¡¶ä½å±€éƒ¨åŒ–åˆ†æï¼ˆBucket Localization, Figure 4ï¼‰
- åœ¨ S1 ä¸‹æŒ‰æç¤ºç±»å‹åˆ†æ¡¶è¯„ä¼°å‘ç°ï¼š
  - `Creative` ç±»æç¤ºè¡¨ç°å‡ºæœ€å¼ºçš„ Track II æ”¶ç¼©
  - æ¨æµ‹ï¼šå¼€æ”¾å¼ä»»åŠ¡æ›´å®¹æ˜“å› åˆæˆæ•°æ®åé¦ˆè€Œå¤±å»åˆ›é€ æ€§å¤šæ ·æ€§

> æç¤ºå´©æºƒå¹¶éå‡åŒ€å‘ç”Ÿï¼ŒæŸäº›è¯­ä¹‰åŒºåŸŸæ›´è„†å¼±ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **LLM Collapse å¯é€šè¿‡ Gram çŸ©é˜µè°±ç‰¹æ€§æœ‰æ•ˆç›‘æµ‹**  
   `log det G` çš„è¡°å‡æ˜¯è¡¨ç¤ºç©ºé—´é€€åŒ–çš„å¯é ä¿¡å·ã€‚

2. âœ… **SIGMA å®ç°äº†å¯æ‰©å±•ã€ç†è®ºé©±åŠ¨çš„å´©æºƒæ£€æµ‹**  
   åˆ©ç”¨ç¡®å®šæ€§ä¸éšæœºè¾¹ç•Œï¼Œåœ¨æ— éœ€å…¨è°±è®¡ç®—çš„å‰æä¸‹å®ç°é«˜æ•ˆç›‘æ§ã€‚

3. âœ… **æƒé‡é€’å½’æ˜¾è‘—åŠ å‰§å´©æºƒè¿›ç¨‹**  
   S2 ä¸­ Track II çš„å´©æºƒé€Ÿåº¦è¿œè¶… S1ï¼Œè¯´æ˜æ¨¡å‹å‚æ•°çš„è¿ç»­æ›´æ–°ä¼šåŠ é€Ÿé€€åŒ–ã€‚

4. âœ… **åŒè½¨è¯Šæ–­æœºåˆ¶å…·æœ‰è§£é‡ŠåŠ›**  
   - Track II å¯¹å®é™…è°±æ”¶ç¼©æ•æ„Ÿï¼›
   - Track I æä¾›ä¿å®ˆåŒ…ç»œï¼›
   - ä¸¤è€…çš„åˆ†æ­§æœ¬èº«æ˜¯æœ‰æ„ä¹‰çš„ä¿¡å·ï¼ˆä¾‹å¦‚æç¤ºæ¼‚ç§»ã€æ£€ç´¢åç§»ç­‰ï¼‰ã€‚

5. âœ… **å‡ ä½•é€€åŒ–å…ˆäºè¡¨é¢é‡å¤å‡ºç°**  
   SIGMA-UB çš„ Track II å¯æ¯” n-gram HHI æ›´æ—©å‘å‡ºè­¦æŠ¥ï¼Œå…·å¤‡â€œæ—©æœŸé¢„è­¦â€èƒ½åŠ›ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–åµŒå…¥ç¼–ç å™¨çš„ä¸€è‡´æ€§**  
   éœ€ä½¿ç”¨å†»ç»“çš„ sentence encoderï¼ˆå¦‚ `all-MiniLM-L6-v2`ï¼‰ï¼Œå¦åˆ™æµ‹é‡å°†æ··æ‚ç¼–ç å™¨å˜åŒ–ã€‚

2. **å‡è®¾æ•°æ®æ¥è‡ªå¹³ç¨³åˆ†å¸ƒ**  
   éšæœºè¾¹ç•Œä¾èµ– i.i.d. å‡è®¾ï¼Œè‹¥åˆæˆæ•°æ®åˆ†å¸ƒå‰§çƒˆæ¼‚ç§»ï¼Œå¯èƒ½å½±å“ä¼°è®¡ç²¾åº¦ã€‚

3. **æ— æ³•å®šä½å…·ä½“å´©æºƒæ¨¡å¼**  
   SIGMA æ£€æµ‹â€œæ˜¯å¦å´©æºƒâ€ï¼Œä½†ä¸èƒ½è§£é‡Šâ€œä¸ºä½•å´©æºƒâ€æˆ–â€œå“ªäº›è¯­ä¹‰ä¸¢å¤±â€ã€‚

4. **å¯¹å°æ¨¡å‹æ›´é€‚ç”¨**  
   å½“ `n < m`ï¼ˆæ ·æœ¬æ•°å°äºåµŒå…¥ç»´åº¦ï¼‰æ—¶ï¼ŒGram çŸ©é˜µå¿…ç„¶å¥‡å¼‚ï¼Œé™åˆ¶åº”ç”¨èŒƒå›´ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³å¤šæ¨¡æ€æ¨¡å‹**  
   å°† SIGMA åº”ç”¨äºè§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„è·¨æ¨¡æ€ Gram çŸ©é˜µåˆ†æã€‚

2. **åŠ¨æ€è°ƒæ•´é‡‡æ ·ç­–ç•¥**  
   æ ¹æ®å½“å‰è¯Šæ–­ç»“æœè‡ªé€‚åº”é€‰æ‹©è§‚æµ‹å— `n_A`ï¼Œæå‡æ•ˆç‡ã€‚

3. **ç»“åˆå¹²é¢„æœºåˆ¶**  
   å°† SIGMA ä½œä¸ºåé¦ˆä¿¡å·ï¼Œè‡ªåŠ¨è§¦å‘æ³¨å…¥çœŸå®æ•°æ®æˆ–é‡å¯è®­ç»ƒæµç¨‹ã€‚

4. **æ„å»ºæ ‡å‡†åŒ–åŸºå‡†ï¼ˆBenchmarkï¼‰**  
   æ¨åŠ¨ SIGMA æˆä¸ºè¯„ä¼° LLM é€’å½’è®­ç»ƒç¨³å®šæ€§çš„æ ‡å‡†å·¥å…·ä¹‹ä¸€ã€‚

5. **æ¢ç´¢åå‘æ ¡æ­£æ–¹æ³•**  
   åŸºäºè°±åˆ†æç»“æœè®¾è®¡æ­£åˆ™é¡¹ï¼Œä¸»åŠ¨æŠ‘åˆ¶è¡¨ç¤ºç©ºé—´æ”¶ç¼©ã€‚

---

> **æ€»ç»“**ï¼šSIGMA æ˜¯é¦–ä¸ªä»**è°±å‡ ä½•è§†è§’**å‡ºå‘ã€å…¼å…·**ç†è®ºæ·±åº¦**ä¸**å·¥ç¨‹å®ç”¨æ€§**çš„å¤§è§„æ¨¡ LLM å´©æºƒç›‘æµ‹æ¡†æ¶ã€‚å®ƒä¸ä»…æä¾›äº†æ–°çš„åˆ†æèŒƒå¼ï¼Œä¹Ÿä¸ºæ„å»ºå¯æŒç»­çš„é€’å½’è®­ç»ƒç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚

</details>

---

### 12. [Rethinking Recurrent Neural Networks for Time Series Forecasting: A Reinforced Recurrent Encoder with Prediction-Oriented Proximal Policy Optimization](https://arxiv.org/abs/2601.03683)

**Authors**: Xin Lai, Shiming Deng, Lu Yu, Yumin Lai, Shenghao Qiao, Xinze Zhang  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.03683v1  

#### Abstract
Time series forecasting plays a crucial role in contemporary engineering information systems for supporting decision-making across various industries, where Recurrent Neural Networks (RNNs) have been widely adopted due to their capability in modeling sequential data. Conventional RNN-based predictor...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿçš„åŸºäº **Recurrent Neural Networks (RNNs)** çš„æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹é€šå¸¸é‡‡ç”¨ç¼–ç å™¨-ä»…ï¼ˆencoder-onlyï¼‰ç­–ç•¥ï¼Œå°†å†å²æ»‘åŠ¨çª—å£ä½œä¸ºè¾“å…¥æ¥é¢„æµ‹æœªæ¥å€¼ã€‚ç„¶è€Œï¼Œè¿™ç±»æ–¹æ³•å­˜åœ¨ä»¥ä¸‹å…³é”®ç¼ºé™·ï¼š
- **å¹³ç­‰å¯¹å¾…æ‰€æœ‰æ—¶é—´æ­¥**ï¼šä¼ ç»Ÿæ–¹æ³•å¯¹æ‰€æœ‰æ—¶é—´æ­¥å’Œéšè—çŠ¶æ€è¿›è¡ŒåŒç­‰å¤„ç†ï¼Œå¿½ç•¥äº†å®ƒä»¬å¯¹æœªæ¥é¢„æµ‹çš„ä¸åŒè´¡çŒ®ã€‚
- **ç¼ºä¹åŠ¨æ€é€‚åº”æ€§**ï¼šå›ºå®šç»“æ„ï¼ˆå¦‚å›ºå®šçš„è·³è¿æ¨¡å¼ï¼‰æ— æ³•æ ¹æ®æ—¶åºæ•°æ®çš„åŠ¨æ€å˜åŒ–è¿›è¡Œè‡ªé€‚åº”è°ƒæ•´ã€‚
- **ä¼˜åŒ–å‰²è£‚**ï¼šè¾“å…¥ç‰¹å¾é€‰æ‹©ã€éšè—çŠ¶æ€ç”Ÿæˆå’Œè¾“å‡ºç›®æ ‡æ˜ å°„ç­‰å…³é”®ç¯èŠ‚é€šå¸¸æ˜¯å­¤ç«‹ä¼˜åŒ–çš„ï¼Œç¼ºä¹ç»Ÿä¸€æ¡†æ¶ã€‚

è¿™äº›é—®é¢˜å¯¼è‡´æ¨¡å‹åœ¨æ•æ‰å¤æ‚ã€éå¹³ç¨³çš„æ—¶é—´ä¾èµ–å…³ç³»ä¸Šè¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†é¢„æµ‹ç²¾åº¦ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡ºäº† **RRE-PPO4Pred** æ–¹æ³•ï¼Œå…¶æ ¸å¿ƒæ˜¯ä¸€ä¸ªç”±ä¸¤éƒ¨åˆ†ç»„æˆçš„åˆ›æ–°æ¡†æ¶ï¼š

#### (1) å¼ºåŒ–å¾ªç¯ç¼–ç å™¨ (Reinforced Recurrent Encoder, RRE)
- **æ ¸å¿ƒæ€æƒ³**ï¼šå°† RNN ç¼–ç å™¨çš„å†…éƒ¨é€‚åº”è¿‡ç¨‹å»ºæ¨¡ä¸ºä¸€ä¸ª **Markov Decision Process (MDP)**ã€‚
- **ç»Ÿä¸€å†³ç­–ç¯å¢ƒ**ï¼šåœ¨ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶å†…ï¼Œé€šè¿‡ä¸€ä¸ªæ™ºèƒ½ä½“ï¼ˆagentï¼‰åŠ¨æ€åœ°åšå‡ºä¸‰é¡¹å…³é”®å†³ç­–ï¼š
  - **è¾“å…¥ç‰¹å¾é€‰æ‹© (Input Feature Selection)**ï¼šå†³å®šåœ¨æ¯ä¸ªæ—¶é—´æ­¥æ˜¯å¦ä½¿ç”¨å½“å‰è¾“å…¥ã€‚
  - **éšè—è·³è¿ (Hidden Skip Connection)**ï¼šåŠ¨æ€é€‰æ‹©ä»è¿‡å»çš„å“ªä¸ªéšè—çŠ¶æ€å»ºç«‹ç›´æ¥è¿æ¥ï¼Œä»¥å¢å¼ºé•¿æœŸè®°å¿†ã€‚
  - **è¾“å‡ºç›®æ ‡é€‰æ‹© (Output Target Selection)**ï¼šå†³å®šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¯å¦å°†æŸä¸ªæ—¶é—´æ­¥çš„é¢„æµ‹çº³å…¥æŸå¤±è®¡ç®—ï¼Œå®ç°é€‰æ‹©æ€§ç›‘ç£ã€‚
- **ä¼˜åŠ¿**ï¼šè¯¥æ¡†æ¶æ˜¾è‘—å¢å¼ºäº† RNN æ¨¡å‹çš„é€‚åº”æ€§å’Œçµæ´»æ€§ï¼Œä½¿å…¶èƒ½å¤Ÿæ ¹æ®å…·ä½“çš„æ—¶é—´åºåˆ—æ¨¡å¼åŠ¨æ€è°ƒæ•´æ¶æ„ã€‚

#### (2) é¢å‘é¢„æµ‹çš„è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ç®—æ³• (Prediction-oriented Proximal Policy Optimization, PPO4Pred)
- **æ ¸å¿ƒæ”¹è¿›**ï¼šå¯¹æ ‡å‡†çš„ **PPO** ç®—æ³•è¿›è¡Œäº†ä¸¤é¡¹å…³é”®æ”¹è¿›ï¼Œä»¥æ›´å¥½åœ°æœåŠ¡äºæ—¶é—´åºåˆ—é¢„æµ‹ä»»åŠ¡ã€‚
  - **Transformer-based Agent**ï¼šä½¿ç”¨ **Transformer** ç¼–ç å™¨ä½œä¸ºæ™ºèƒ½ä½“çš„éª¨å¹²ç½‘ç»œï¼Œåˆ©ç”¨å…¶è‡ªæ³¨æ„åŠ›æœºåˆ¶æœ‰æ•ˆå»ºæ¨¡æ—¶é—´åºåˆ—ä¸­çš„é•¿ç¨‹ä¾èµ–å…³ç³»ã€‚
  - **åŠ¨æ€è½¬ç§»é‡‡æ · (Dynamic Transition Sampling, DTS)**ï¼šæå‡ºä¸€ç§æ–°çš„é‡‡æ ·ç­–ç•¥ï¼Œä¼˜å…ˆé€‰æ‹©é‚£äº›å…·æœ‰é«˜å­¦ä¹ æ½œåŠ›çš„è½¬ç§»ï¼ˆtransitionï¼‰ï¼Œä¾‹å¦‚ä»·å€¼ä¼°è®¡ä¸ç¡®å®šæ€§å¤§æˆ–é¢„æµ‹è¯¯å·®é«˜çš„æ ·æœ¬ï¼Œä»è€Œå¤§å¹…æé«˜é‡‡æ ·æ•ˆç‡ã€‚

#### (3) ååŒè¿›åŒ–ä¼˜åŒ–èŒƒå¼ (Co-evolutionary Optimization Paradigm)
- **æ ¸å¿ƒæµç¨‹**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œäº¤æ›¿ä¼˜åŒ–ä¸¤ä¸ªç»„ä»¶ï¼š
  1.  å›ºå®š RNN ç¯å¢ƒï¼Œè®­ç»ƒ PPO4Pred æ™ºèƒ½ä½“ã€‚
  2.  å›ºå®šè®­ç»ƒå¥½çš„æ™ºèƒ½ä½“ï¼Œå¾®è°ƒ RNN ç¯å¢ƒã€‚
- **ä¼˜åŠ¿**ï¼šè¿™ç§äº¤äº’å¼çš„è®­ç»ƒæ–¹å¼ä¿ƒè¿›äº† RNN é¢„æµ‹å™¨å’Œç­–ç•¥æ™ºèƒ½ä½“çš„ååŒè¿›åŒ–ï¼Œå®ç°äº†æ›´æ·±å±‚æ¬¡çš„æ¨¡å‹é€‚åº”ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´é«˜çš„é¢„æµ‹ç²¾åº¦**ï¼šé€šè¿‡åŠ¨æ€ã€è”åˆä¼˜åŒ–ä¸‰ä¸ªå…³é”®ç¯èŠ‚ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›ã€‚
- **æ›´å¼ºçš„é€‚åº”æ€§**ï¼šèƒ½å¤Ÿæ ¹æ®ä¸åŒæ—¶é—´åºåˆ—çš„ç‰¹æ€§è‡ªåŠ¨è°ƒæ•´æ¨¡å‹è¡Œä¸ºï¼Œè€Œéä¾èµ–é¢„è®¾çš„å›ºå®šè§„åˆ™ã€‚
- **æ›´ä¼˜çš„æ ·æœ¬æ•ˆç‡**ï¼šDTS ç­–ç•¥ä½¿å¾—æ™ºèƒ½ä½“èƒ½æ›´å¿«åœ°ä»æœ€æœ‰ä»·å€¼çš„ç»éªŒä¸­å­¦ä¹ ã€‚
- **é€šç”¨æ€§å¼º**ï¼šRRE æ¡†æ¶å¯ä»¥æ— ç¼é›†æˆåˆ°å¤šç§ä¸åŒçš„ RNN å˜ä½“ï¼ˆå¦‚ LSTM, GRU, xLSTM ç­‰ï¼‰ä¸­ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåœ¨äº”ä¸ªçœŸå®ä¸–ç•Œçš„æ—¶é—´åºåˆ—æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œæ¶µç›–äº†äº¤é€šã€ç”µåŠ›ã€æ°”è±¡ç­‰å¤šä¸ªé¢†åŸŸï¼š
- **Traffic**: åŠ å·é«˜é€Ÿå…¬è·¯ä¼ æ„Ÿå™¨æ•°æ®ï¼ˆ862ç»´ï¼‰
- **Electricity**: ç”µåŠ›æ¶ˆè€—è´Ÿè·æ•°æ®ï¼ˆ321ç»´ï¼‰
- **ETTh**: ç”µåŠ›å˜å‹å™¨æ¸©åº¦æ•°æ®ï¼ˆ7ç»´ï¼‰
- **Weather**: æ°”è±¡æ•°æ®ï¼ˆ21ç»´ï¼‰
- **ILI**: æµæ„Ÿæ ·ç–¾ç—…å‘¨åº¦æ•°æ®ï¼ˆ7ç»´ï¼‰

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **ä»»åŠ¡**ï¼šå¤šå˜é‡è¾“å…¥ï¼Œå•å˜é‡è¾“å‡ºçš„å¤šæ­¥é¢„æµ‹ï¼ˆmultivariate-to-univariate forecastingï¼‰ã€‚
- **é¢„æµ‹èŒƒå›´ (Horizon H)**ï¼šåœ¨ä¸åŒæ•°æ®é›†ä¸Šæµ‹è¯•äº†å¤šä¸ªé¢„æµ‹é•¿åº¦ï¼ˆå¦‚ 24, 48, 96 æ­¥ï¼‰ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **MSE (Mean Squared Error)**
  - **MAE (Mean Absolute Error)**
- **æ•°æ®åˆ’åˆ†**ï¼šæŒ‰ 7:1:2 çš„æ¯”ä¾‹åˆ’åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚
- **å®ç°ç»†èŠ‚**ï¼šä½¿ç”¨ Adam ä¼˜åŒ–å™¨ï¼Œè¿›è¡Œè¶…å‚æ•°éšæœºæœç´¢ï¼Œå¹¶é‡‡ç”¨æ—©åœæœºåˆ¶ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
ä¸ä»¥ä¸‹å‡ ç±»ä»£è¡¨æ€§æ–¹æ³•è¿›è¡Œäº†å¯¹æ¯”ï¼š
- **é™æ€åŸºçº¿ (Static Baselines)**ï¼š
  - `Naive-all`: ä½¿ç”¨æ‰€æœ‰æ—¶é—´æ­¥çš„è¾“å‡ºè¿›è¡Œç›‘ç£ã€‚
  - `Naive-last`: ä»…ä½¿ç”¨æœ€åä¸€ä¸ªéšè—çŠ¶æ€è¿›è¡Œé¢„æµ‹ã€‚
  - `DilatedRNN`: ä½¿ç”¨é¢„å®šä¹‰çš„ç¨€ç–è·³è¿æ¨¡å¼ã€‚
- **å¯å‘å¼æ–¹æ³• (Heuristic Method)**ï¼š
  - `EBPSO`: åŸºäºç²’å­ç¾¤ä¼˜åŒ–ï¼ˆPSOï¼‰çš„è¾“å…¥ç‰¹å¾é€‰æ‹©ã€‚
- **å¼ºåŒ–å­¦ä¹ æ–¹æ³• (RL-based Methods)**ï¼š
  - `LSTMjump`: ä½¿ç”¨ **Policy Gradient (PG)** è¿›è¡Œè¾“å…¥è·³è¿‡ã€‚
  - `PGLSTM`: ä½¿ç”¨ **PG** è¿›è¡ŒåŠ¨æ€éšè—è·³è¿ã€‚

æ­¤å¤–ï¼Œè¿˜ä¸æœ€å…ˆè¿›çš„ **Transformer** æ¨¡å‹ï¼ˆ`PatchTST`, `iTransformer`ï¼‰è¿›è¡Œäº†æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ
ç»¼åˆå®éªŒè¡¨æ˜ï¼Œ**RRE-PPO4Pred** åœ¨æ‰€æœ‰æ•°æ®é›†å’Œé¢„æµ‹èŒƒå›´å†…å‡å–å¾—äº†æœ€ä½³æ€§èƒ½ã€‚

- **ç›¸å¯¹äº RNN åŸºçº¿çš„æå‡**ï¼š
  - ç›¸æ¯” `Naive-last`, `Naive-all`, `DilatedRNN`ï¼ŒMSE å¹³å‡æå‡ **23.7% ~ 53.08%**ï¼ŒMAE æå‡ **21.57% ~ 50.75%**ã€‚
  - ç›¸æ¯”å¯å‘å¼æ–¹æ³• `EBPSO`ï¼ŒMSE æå‡ **23.21% ~ 28.36%**ï¼ŒMAE æå‡ **22.80% ~ 29.59%**ã€‚
  - ç›¸æ¯” RL æ–¹æ³• `PGLSTM` å’Œ `LSTMjump`ï¼ŒMSE æå‡ **19.04% ~ 27.80%**ï¼ŒMAE æå‡ **18.47% ~ 28.49%**ã€‚

- **è¶…è¶Š Transformer æ¨¡å‹**ï¼š
  - åœ¨ **ETTh** æ•°æ®é›†ä¸Šï¼Œå°† `xLSTM` ä¸ RRE-PPO4Pred ç»“åˆåï¼Œå…¶æ€§èƒ½è¶…è¿‡äº† `iTransformer` å’Œ `PatchTST`ã€‚
  - ä¾‹å¦‚ï¼Œåœ¨ H=96 çš„é¢„æµ‹èŒƒå›´å†…ï¼Œ`xLSTM+Ours` çš„ MSE ä¸º **0.3607**ï¼Œè€Œ `iTransformer` ä¸º 0.3921ï¼Œ`PatchTST` ä¸º 0.3746ï¼Œåˆ†åˆ«æå‡äº† **8.0%** å’Œ **3.7%**ã€‚

### æ¶ˆèå®éªŒç»“æœ
ä¸ºäº†éªŒè¯å„ç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼Œè¿›è¡Œäº†æ¶ˆèç ”ç©¶ï¼š

| æ–¹æ³• | æè¿° |
| :--- | :--- |
| `TA-PSO` | ä½¿ç”¨ PSO ä¼˜åŒ– RRE ä¸­è®¾è®¡çš„ä¸‰å…ƒåŠ¨ä½œï¼ˆTernary Actionï¼‰ã€‚ |
| `RRE-PG` / `RRE-DQN` / `RRE-PPO` | ä¿ç•™ RRE æ¡†æ¶ï¼Œä½†åˆ†åˆ«ç”¨ PGã€DQN æˆ–æ ‡å‡† PPO æ›¿æ¢ PPO4Pred ç®—æ³•ã€‚ |

**ç»“è®º**ï¼š
- æ‰€æœ‰åŸºäº RL çš„å˜ä½“ (`RRE-PG`, `RRE-DQN`, `RRE-PPO`) å‡æ˜¾è‘—ä¼˜äºå¯å‘å¼æ–¹æ³• `TA-PSO`ï¼Œè¯æ˜äº† RL åœ¨ä¼˜åŒ–å¤æ‚åŠ¨ä½œç©ºé—´ä¸Šçš„å¿…è¦æ€§ã€‚
- `RRE-PPO` å·²ç»è¡¨ç°è‰¯å¥½ï¼Œä½†å®Œæ•´çš„ `RRE-PPO4Pred` èƒ½å¤Ÿè¿›ä¸€æ­¥æå‡æ€§èƒ½ï¼ˆMSE å†æå‡ **5.71% ~ 8.95%**ï¼ŒMAE æå‡ **4.54% ~ 8.18%**ï¼‰ï¼Œè¿™å……åˆ†è¯æ˜äº† **Transformer-based Agent** å’Œ **DTS** ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1.  **RRE æ¡†æ¶æ˜¯æœ‰æ•ˆçš„**ï¼šå°† RNN çš„é€‚åº”è¿‡ç¨‹å»ºæ¨¡ä¸º MDPï¼Œå¹¶é€šè¿‡æ™ºèƒ½ä½“è¿›è¡Œè”åˆå†³ç­–ï¼Œæ˜¯ä¸€ç§å¼ºå¤§çš„èŒƒå¼ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡ RNN çš„é¢„æµ‹èƒ½åŠ›ã€‚
2.  **PPO4Pred æ˜¯å…³é”®**ï¼šé¢å‘é¢„æµ‹ä»»åŠ¡å®šåˆ¶çš„ PPO ç®—æ³•ï¼ˆç‰¹åˆ«æ˜¯ Transformer-based Agent å’Œ DTSï¼‰å¯¹äºé«˜æ•ˆã€ç¨³å®šåœ°è®­ç»ƒæ™ºèƒ½ä½“è‡³å…³é‡è¦ã€‚
3.  **ååŒè¿›åŒ–æ˜¯æˆåŠŸçš„**ï¼šäº¤æ›¿ä¼˜åŒ–æ™ºèƒ½ä½“å’Œ RNN ç¯å¢ƒçš„èŒƒå¼ï¼Œèƒ½å¤Ÿä¿ƒè¿›ä¸¤è€…å…±åŒè¿›åŒ–ï¼Œè¾¾åˆ°æ›´å¥½çš„æ•´ä½“æ€§èƒ½ã€‚
4.  **RNN ä¾ç„¶å¼ºå¤§**ï¼šé€šè¿‡å…ˆè¿›çš„ä¼˜åŒ–æ–¹æ³•ï¼ˆå¦‚ RRE-PPO4Predï¼‰ï¼Œä¼ ç»Ÿçš„ RNN æ¶æ„å¯ä»¥åœ¨æ€§èƒ½ä¸Šè¶…è¶Šç”šè‡³è¶…è¿‡å½“å‰æœ€å…ˆè¿›çš„ **Transformer** æ¨¡å‹ï¼Œé‡æ–°ç¡®ç«‹äº†å…¶åœ¨æ—¶é—´åºåˆ—é¢„æµ‹é¢†åŸŸçš„ç«äº‰åŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å¼€é”€å¢åŠ **ï¼šç”±äºå¼•å…¥äº†é¢å¤–çš„æ™ºèƒ½ä½“ç½‘ç»œå’Œå¼‚æ­¥è®­ç»ƒè¿‡ç¨‹ï¼Œè®­ç»ƒæ—¶é—´å’Œæ¨¡å‹å‚æ•°é‡ç›¸æ¯”åŸºç¡€ RNN æ¨¡å‹æœ‰æ‰€å¢åŠ ã€‚
- **æ¨ç†é˜¶æ®µä»éœ€æ™ºèƒ½ä½“**ï¼šä¸ä¸€äº›é™æ€æ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•åœ¨æ¨ç†æ—¶ä¹Ÿéœ€è¦è¿è¡Œæ™ºèƒ½ä½“æ¥åŠ¨æ€å†³ç­–ï¼Œå¢åŠ äº†æ¨ç†çš„è®¡ç®—æˆæœ¬ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„è®­ç»ƒå’Œæ¨ç†æ–¹æ³•ï¼Œä¾‹å¦‚é€šè¿‡ **çŸ¥è¯†è’¸é¦ (knowledge distillation)** å°†æ™ºèƒ½ä½“å­¦åˆ°çš„çŸ¥è¯†è¿ç§»åˆ°ä¸€ä¸ªè½»é‡çº§çš„ RNN æ¨¡å‹ä¸­ã€‚
- ç ”ç©¶ **è¿ç§»å­¦ä¹  (transfer learning)**ï¼Œä½¿åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ™ºèƒ½ä½“èƒ½å¤Ÿå¿«é€Ÿé€‚åº”æ–°çš„ã€å°è§„æ¨¡çš„æ—¶é—´åºåˆ—ä»»åŠ¡ã€‚
- è®¾è®¡æ›´è½»é‡çº§çš„æ™ºèƒ½ä½“æ¶æ„ï¼ˆå¦‚è½»é‡çº§ **Transformers**ï¼‰ï¼Œä»¥é™ä½æ•´ä½“è®¡ç®—æˆæœ¬ã€‚

</details>

---

### 13. [Feature-Aware One-Shot Federated Learning via Hierarchical Token Sequences](https://arxiv.org/abs/2601.03882)

**Authors**: Shudong Liu, Hanwen Zhang, Xiuling Wang, Yuesheng Zhu, Guibo Luo  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.03882v1  

#### Abstract
One-shot federated learning (OSFL) reduces the communication cost and privacy risks of iterative federated learning by constructing a global model with a single round of communication. However, most existing methods struggle to achieve robust performance on real-world domains such as medical imaging...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFeature-Aware One-Shot Federated Learning via Hierarchical Token Sequences

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹**One-shot Federated Learning (OSFL)** ä¸­çš„å…³é”®æŒ‘æˆ˜å±•å¼€ç ”ç©¶ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†**éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆnon-IIDï¼‰å›¾åƒæ•°æ®**æ—¶å­˜åœ¨çš„ä»¥ä¸‹é—®é¢˜ï¼š

- **é€šä¿¡æ•ˆç‡ä¸éšç§é£é™©**ï¼šä¼ ç»Ÿè”é‚¦å­¦ä¹ éœ€è¦å¤šè½®é€šä¿¡ï¼Œè€ŒOSFLé€šè¿‡å•æ¬¡ä¸Šä¼ é™ä½é€šä¿¡å¼€é”€å’Œéšç§æ³„éœ²é£é™©ã€‚
- **ç°æœ‰OSFLæ–¹æ³•åœ¨non-IIDåœºæ™¯ä¸‹æ€§èƒ½ä¸ä½³**ï¼šå°¤å…¶æ˜¯åŒ»ç–—å½±åƒç­‰çœŸå®ä¸–ç•Œä»»åŠ¡ä¸­ï¼Œç”±äºæ•°æ®å¼‚æ„æ€§å¼ºï¼Œç”Ÿæˆæ¨¡å‹éš¾ä»¥å‡†ç¡®å»ºæ¨¡å®¢æˆ·ç«¯æ•°æ®åˆ†å¸ƒã€‚
- **ç‰¹å¾ç©ºé—´é”™ä½ï¼ˆFeature Misalignmentï¼‰**ï¼šå½“å„å®¢æˆ·ç«¯ä½¿ç”¨æœ¬åœ°å¾®è°ƒçš„ç¼–ç å™¨æ—¶ï¼Œæå–çš„è¯­ä¹‰ç‰¹å¾æ— æ³•å¯¹é½ï¼Œå¯¼è‡´å…¨å±€åˆ†ç±»å™¨æ³›åŒ–èƒ½åŠ›å·®ã€‚
- **é«˜åˆ†è¾¨ç‡ç»†èŠ‚ä¸¢å¤±**ï¼šæ ‡å‡†ViTç±»ç¼–ç å™¨è¾“å…¥å°ºå¯¸å›ºå®šä¸”è¾ƒä½ï¼Œéš¾ä»¥æ•æ‰åŒ»å­¦å›¾åƒä¸­çš„ç»†ç²’åº¦å±€éƒ¨ç»“æ„ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **FALCON** çš„æ–°å‹OSFLæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ç»“åˆ**åˆ†å±‚Tokenåºåˆ—ç”Ÿæˆ**ä¸**çŸ¥è¯†è’¸é¦å¼•å¯¼è®­ç»ƒ**ï¼Œå®ç°é«˜æ•ˆã€é²æ£’çš„å…¨å±€å»ºæ¨¡ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

1. âœ… **Hierarchical Scale Encoding (HSE)**  
   - åœ¨ä¸è¿›è¡Œæœ¬åœ°å¾®è°ƒçš„å‰æä¸‹ï¼Œä»åŸå§‹å›¾åƒä¸­åŒæ—¶æå–**å…¨å±€è¯­ä¹‰ä¿¡æ¯**ï¼ˆimage-level tokenï¼‰å’Œ**é«˜åˆ†è¾¨ç‡åŒºåŸŸç»†èŠ‚**ï¼ˆregion-level tokensï¼‰ã€‚
   - é‡‡ç”¨åŒè·¯å¾„è®¾è®¡ï¼šå°†åŸå›¾ç¼©æ”¾ä¸ºä½åˆ†è¾¨ç‡å…¨å±€è§†å›¾ï¼Œå¹¶ç”¨æ»‘åŠ¨çª—å£åˆ‡åˆ†ä¸ºå¤šä¸ªé«˜åˆ†è¾¨ç‡patchåˆ†åˆ«ç¼–ç ã€‚
   - æ„å»ºå…·æœ‰**å¤šå°ºåº¦è¯­ä¹‰å±‚æ¬¡ç»“æ„çš„Tokenåºåˆ—**ï¼Œæå‡é¢„è®­ç»ƒç¼–ç å™¨åœ¨è·¨åŸŸä»»åŠ¡ä¸­çš„é€‚åº”æ€§ã€‚

2. âœ… **Multi-scale Autoregressive (M-AR) Transformer Generator**  
   - è®¾è®¡ä¸€ä¸ªåŸºäºTransformerçš„ç”Ÿæˆå™¨ï¼Œä»¥è‡ªå›å½’æ–¹å¼å»ºæ¨¡Tokenåºåˆ—çš„è”åˆåˆ†å¸ƒã€‚
   - å¼•å…¥**å—çŠ¶å› æœæ©ç ï¼ˆblock-wise causal maskï¼‰**ï¼Œç¡®ä¿å…ˆç”Ÿæˆå…¨å±€tokenå†ç”Ÿæˆå±€éƒ¨tokensï¼Œç¬¦åˆâ€œç”±ç²—åˆ°ç²¾â€çš„è§†è§‰æ„ŸçŸ¥æœºåˆ¶ã€‚
   - ä½¿ç”¨GMMè¾“å‡ºæ¯ä½ç½®tokençš„æ¦‚ç‡åˆ†å¸ƒï¼Œå¢å¼ºè¡¨è¾¾èƒ½åŠ›ã€‚

3. âœ… **Distillation-Guided Global Training**  
   - å®¢æˆ·ç«¯ä¸Šä¼ åˆæˆTokenåºåˆ— + æœ¬åœ°åˆ†ç±»å™¨ â†’ æœåŠ¡å™¨ç«¯åˆ©ç”¨**çŸ¥è¯†è’¸é¦**è®­ç»ƒå…¨å±€åˆ†ç±»å™¨ã€‚
   - è’¸é¦ç›®æ ‡æ¥è‡ªæ‰€æœ‰æœ¬åœ°åˆ†ç±»å™¨çš„é›†æˆé¢„æµ‹ï¼ˆensemble teacherï¼‰ï¼Œç¼“è§£å¯¹ç”Ÿæˆè´¨é‡çš„ä¾èµ–ã€‚
   - æ˜¾è‘—æå‡æ¨¡å‹é²æ£’æ€§å’Œæ³›åŒ–æ€§èƒ½ã€‚

4. âœ… **å‹ç¼©ä»£ç†æ•°æ®ä¸Šä¼ æœºåˆ¶**  
   - ä¸Šä¼ çš„æ˜¯**ç»“æ„åŒ–Tokenåºåˆ—**è€ŒéåŸå§‹å›¾åƒæˆ–å¤æ‚ç”Ÿæˆæ¨¡å‹å‚æ•°ï¼Œæ˜¾è‘—å‡å°‘é€šä¿¡æˆæœ¬ã€‚
   - æ”¯æŒçµæ´»é€‰æ‹©ä¸Šä¼ â€œç”Ÿæˆå™¨â€è¿˜æ˜¯â€œåˆæˆåºåˆ—â€ï¼Œæ ¹æ®æ•°æ®é‡åŠ¨æ€ä¼˜åŒ–ä¼ è¾“ç­–ç•¥ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | FALCONä¼˜åŠ¿ |
|------|-----------|
| **æ€§èƒ½** | åœ¨å¤šç§non-IIDè®¾ç½®ä¸‹å¹³å‡å‡†ç¡®ç‡è¶…è¿‡æœ€å¼ºåŸºçº¿è¾¾ **9.58%** |
| **æ•ˆç‡** | æ¯æ ·æœ¬ç”Ÿæˆä»…éœ€ **0.46 GFLOPs**ï¼Œæ¯”æ‰©æ•£æ¨¡å‹ï¼ˆå¦‚FedLMGï¼‰å¿«å››ä¸ªæ•°é‡çº§ |
| **éšç§ä¿æŠ¤** | åˆæˆTokenéš¾ä»¥é‡æ„åŸå§‹å›¾åƒï¼ŒæŠ—é‡å»ºæ”»å‡»èƒ½åŠ›å¼ºï¼ˆSSIMä¸‹é™è¶…60%ï¼‰ |
| **é€‚ç”¨æ€§** | ç‰¹åˆ«é€‚ç”¨äºé«˜åˆ†è¾¨ç‡ã€ç»†ç²’åº¦ä»»åŠ¡ï¼ˆå¦‚åŒ»å­¦å½±åƒï¼‰ |
| **é²æ£’æ€§** | å¯¹label skewå’Œfeature skewå‡è¡¨ç°ç¨³å®šï¼Œæ— ä¸¥é‡æ€§èƒ½é€€åŒ– |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

æ¶µç›–è‡ªç„¶å›¾åƒä¸åŒ»å­¦å›¾åƒä¸¤å¤§é¢†åŸŸï¼Œå…±6ä¸ªæ•°æ®é›†ï¼Œåˆ†ä¸ºä¸¤ç±»non-IIDè®¾å®šï¼š

| æ•°æ®é›† | ç±»å‹ | é¢†åŸŸ | Non-IIDç±»å‹ | ç±»åˆ«æ•° | å®¢æˆ·ç«¯æ•° |
|--------|------|-------|-------------|--------|----------|
| Tuberculosis | åŒ»ç–— | Med. | Feature | 2 | 3 |
| PACS | è‡ªç„¶ | Nat. | Feature | 7 | 4 |
| OfficeHome | è‡ªç„¶ | Nat. | Feature | 65 | 4 |
| PMRAM | åŒ»ç–— | Med. | Label | 4 | 5 |
| Pneumonia | åŒ»ç–— | Med. | Label | 2 | 5 |
| Tiny-ImageNet | è‡ªç„¶ | Nat. | Label | 200 | 5 |

> - **Feature non-IID**ï¼šä¸åŒæ¥æº/åŸŸä½œä¸ºä¸åŒå®¢æˆ·ç«¯ï¼ˆå¤©ç„¶åˆ’åˆ†ï¼‰
> - **Label non-IID**ï¼šé€šè¿‡Dirichletåˆ†å¸ƒï¼ˆÎ± âˆˆ {0.1, 0.3, 0.5}ï¼‰æ§åˆ¶æ ‡ç­¾å¼‚è´¨æ€§

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **ä¸»å¹²ç¼–ç å™¨**ï¼šDINOv2-baseï¼ˆå†»ç»“ï¼Œä¸å¾®è°ƒï¼‰
- **HSEé…ç½®**ï¼šå…¨å±€è§†å›¾resizeè‡³448Ã—448ï¼›æ»‘åŠ¨çª—å£å¤§å°/æ­¥é•¿=224 â†’ å¾—åˆ°1ä¸ªglobal + 4ä¸ªregion tokens
- **M-AR Generator**ï¼š4å±‚Transformerï¼Œhidden dim=768ï¼Œ16 headsï¼ŒK=20 GMM components
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - æœ¬åœ°åˆ†ç±»å™¨ & å…¨å±€åˆ†ç±»å™¨ï¼šAdamï¼Œlr=5e-4ï¼Œbatch_size=256ï¼Œ60 epochs
  - å¹³è¡¡ç³»æ•° Î»=0.5ï¼Œè’¸é¦æ¸©åº¦ T=4
- **è¯„ä¼°æŒ‡æ ‡**ï¼šæµ‹è¯•é›†åˆ†ç±»å‡†ç¡®ç‡ï¼ˆAccuracy %ï¼‰ï¼Œå¹³å‡è·¨æ‰€æœ‰è®¾ç½®

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿æ–¹æ³• | ç±»å‹ | ç®€ä»‹ |
|---------|------|------|
| **FedAvg** | å¤šè½®FLåŸºå‡† | å¤šè½®é€šä¿¡èšåˆæ¨¡å‹å‚æ•° |
| **DENSE** | æ•°æ®æ— å…³è’¸é¦ | ä¸ä¸Šä¼ æ•°æ®ï¼Œä»…ç”¨æœ¬åœ°æ¨¡å‹è’¸é¦ |
| **FedLMG** | æ‰©æ•£æ¨¡å‹ç”Ÿæˆ | ä½¿ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆå›¾åƒ |
| **FedPFT** | ç‰¹å¾ç»Ÿè®¡å»ºæ¨¡ | GMMæ‹Ÿåˆç‰¹å¾åˆ†å¸ƒï¼Œä¸Šä¼ ç»Ÿè®¡é‡ |
| **FedCGS** | ç‰¹å¾ç»Ÿè®¡+æœ´ç´ è´å¶æ–¯ | ç›´æ¥æ„å»ºå…¨å±€Gaussian Naive Bayesåˆ†ç±»å™¨ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 2ï¼‰**

| æ–¹æ³• | Avg. Accuracy (%) |
|------|------------------|
| FedAvg | 73.30 |
| DENSE | 50.50 |
| FedLMG | 45.82 |
| FedPFT | 73.61 |
| FedCGS | 76.34 |
| **FALCON** | **85.92** âœ… |

> ğŸ’¡ **FALCONæ¯”æœ€ä½³OSFLåŸºçº¿ï¼ˆFedCGSï¼‰é«˜å‡º9.58ä¸ªç™¾åˆ†ç‚¹ï¼**

#### åˆ†é¡¹äº®ç‚¹ï¼š

- **Tuberculosisï¼ˆåŒ»ç–—å›¾åƒï¼‰**ï¼šFALCONè¾¾ **87.20%**ï¼Œè¿œè¶…ç¬¬äºŒåFedCGSçš„53.50%
- **PMRAMï¼ˆè„‘ç™ŒMRIï¼‰**ï¼šåœ¨Î±=0.1æç«¯label skewä¸‹ä»ä¿æŒ **83.33%** å‡†ç¡®ç‡ï¼Œå…¶ä»–å¤šæ•°æ–¹æ³•ä½äº40%
- **PACS / OfficeHome**ï¼šæ¥è¿‘æˆ–è¾¾åˆ°æœ€ä¼˜ï¼Œæ˜¾ç¤ºå¯¹domain shiftçš„å¼ºå¤§é€‚åº”åŠ›
- **Tiny-ImageNetï¼ˆå¤§è§„æ¨¡ï¼‰**ï¼šFALCONè¾¾81.55%ï¼Œæ˜¾è‘—ä¼˜äºFedLMGï¼ˆ~31%ï¼‰ã€DENSEï¼ˆ~30%ï¼‰

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰**

éªŒè¯å„ç»„ä»¶æœ‰æ•ˆæ€§ï¼ˆå¹³å‡å‡†ç¡®ç‡ï¼‰ï¼š

| å˜ä½“ | Avg. Acc (%) | ç›¸è¾ƒå®Œæ•´ç‰ˆä¸‹é™ |
|------|---------------|----------------|
| Full (FALCON) | **85.92** | â€” |
| w/o HSE | 82.32 | â†“3.60 |
| w/o KDï¼ˆæ— çŸ¥è¯†è’¸é¦ï¼‰ | 82.82 | â†“3.10 |
| ARï¼ˆæ™®é€šè‡ªå›å½’ï¼‰ | 81.47 | â†“4.45 |
| NARï¼ˆéè‡ªå›å½’ï¼‰ | 82.99 | â†“2.93 |

> ğŸ” ç»“è®ºï¼š
> - HSEè´¡çŒ®æœ€å¤§ï¼ˆ+3.6%ï¼‰ï¼Œå°¤å…¶åœ¨åŒ»ç–—å›¾åƒä¸Šæå‡æ˜æ˜¾ï¼ˆTuberculosis +3.57%ï¼‰
> - çŸ¥è¯†è’¸é¦è‡³å…³é‡è¦ï¼ˆ+3.1%ï¼‰ï¼Œå¼¥è¡¥ç”Ÿæˆåå·®
> - M-ARæ¶æ„ä¼˜äºAR/NARï¼Œè¯´æ˜å»ºæ¨¡å±‚çº§ä¾èµ–å…³ç³»é‡è¦

---

### **ç”Ÿæˆè´¨é‡åˆ†æï¼ˆTable 4ï¼‰**

ä½¿ç”¨**æœ€å¤§å‡å€¼å·®å¼‚ï¼ˆMMDï¼‰** è¡¡é‡çœŸå® vs åˆæˆTokenåˆ†å¸ƒå·®è·ï¼š

| æ–¹æ³• | Tuberculosis | PACS | OfficeHome |
|------|--------------|------|------------|
| M-ARï¼ˆæœ¬æ–‡ï¼‰ | **0.003227** | **0.002047** | **0.000905** |
| AR | 0.003868 | 0.002457 | 0.001079 |
| NAR | 0.003868 | 0.002151 | 0.000849 |

> âœ… M-ARåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹æœ€æ¥è¿‘çœŸå®åˆ†å¸ƒï¼Œè¯æ˜å…¶æ›´å¼ºçš„å»ºæ¨¡èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **HSEèƒ½æœ‰æ•ˆæå–å¤šå°ºåº¦è¯­ä¹‰ä¿¡æ¯**ï¼Œæ— éœ€å¾®è°ƒå³å¯é€‚é…è·¨åŸŸæ•°æ®ï¼Œåœ¨é«˜åˆ†è¾¨ç‡åŒ»å­¦å›¾åƒä¸­å°¤ä¸ºå…³é”®ã€‚
2. âœ… **M-AR Transformerå¯é«˜æ•ˆå»ºæ¨¡Tokenåºåˆ—åˆ†å¸ƒ**ï¼Œç›¸æ¯”æ‰©æ•£/GANæ›´è½»é‡ä¸”ç¨³å®šã€‚
3. âœ… **çŸ¥è¯†è’¸é¦æ˜¾è‘—ç¼“è§£ç”Ÿæˆè¯¯å·®å½±å“**ï¼Œä½¿å…¨å±€è®­ç»ƒä¸å®Œå…¨ä¾èµ–å®Œç¾åˆ†å¸ƒå»ºæ¨¡ã€‚
4. âœ… **FALCONåœ¨å„ç±»non-IIDåœºæ™¯ä¸‹å‡è¡¨ç°å‡ºå“è¶Šé²æ£’æ€§ä¸é«˜æ€§èƒ½**ï¼Œå°¤å…¶åœ¨åŒ»ç–—å›¾åƒä»»åŠ¡ä¸­é¥é¥é¢†å…ˆã€‚
5. âœ… **å…·å¤‡è‰¯å¥½éšç§ä¿æŠ¤èƒ½åŠ›**ï¼šåŸºäºåˆæˆTokençš„å›¾åƒé‡å»ºå‡ ä¹ä¸å¯è¯†åˆ«ï¼ˆPSNRâ†“>10dB, SSIMâ†“>60%ï¼‰ã€‚
6. âœ… **è®¡ç®—ä¸é€šä¿¡é«˜æ•ˆ**ï¼šç”Ÿæˆå¼€é”€æä½ï¼ˆ0.46 GFLOPs/sampleï¼‰ï¼Œé€‚åˆè¾¹ç¼˜éƒ¨ç½²ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- â— **ä¾èµ–é«˜è´¨é‡é¢„è®­ç»ƒç¼–ç å™¨**ï¼šè‹¥HSEæ‰€ç”¨çš„DINOv2ç­‰æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸï¼ˆå¦‚ç—…ç†åˆ‡ç‰‡ï¼‰é¢„è®­ç»ƒä¸è¶³ï¼Œå¯èƒ½é™åˆ¶æ€§èƒ½ä¸Šé™ã€‚
- â— **Tokenåºåˆ—é•¿åº¦å—é™äºæ»‘åŠ¨çª—å£ç­–ç•¥**ï¼šå½“å‰ä»…æ”¯æŒå›ºå®šæ•°é‡patchesï¼Œæ‰©å±•æ€§æœ‰é™ã€‚
- â— **æœªè€ƒè™‘å®¢æˆ·ç«¯é—´ç±»åˆ«ç¼ºå¤±æƒ…å†µï¼ˆextreme label non-IIDï¼‰**ï¼šå®éªŒä¸­Dirichlet Î±æœ€å°ä¸º0.1ï¼Œå°šæœªè¦†ç›–æç«¯ç¨€ç–æ ‡ç­¾åœºæ™¯ã€‚
- â— **ç”Ÿæˆè¿‡ç¨‹ä»ä¸ºç¦»æ•£Tokençº§åˆ«**ï¼šè™½é¿å…åƒç´ çº§æ³„éœ²ï¼Œä½†ä¹ŸæŸå¤±éƒ¨åˆ†è¿ç»­è¯­ä¹‰ä¿¡æ¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. ğŸ”„ æ¢ç´¢æ›´é«˜æ•ˆçš„**ç»Ÿä¸€ç¼–ç ç­–ç•¥**ï¼Œç¡®ä¿æ‰€æœ‰å®¢æˆ·ç«¯é‡‡ç”¨ä¸€è‡´HSEé…ç½®ï¼Œè¿›ä¸€æ­¥æå‡ç‰¹å¾å¯¹é½ã€‚
2. ğŸ” ç ”ç©¶æ›´å¼ºå¤§çš„**ç”Ÿæˆå»ºæ¨¡èŒƒå¼**ï¼ˆå¦‚flow-based modelsã€vector quantizationï¼‰ï¼Œæé«˜Tokenå¤šæ ·æ€§ä¸ä¿çœŸåº¦ã€‚
3. ğŸ§  å¼•å…¥**prompt learning æˆ– adapteræ¨¡å—**ï¼Œåœ¨ä¸ç ´åéšç§å‰æä¸‹è½»å¾®è°ƒæ•´ç¼–ç å™¨ä»¥é€‚åº”æœ¬åœ°æ•°æ®ã€‚
4. ğŸŒ æ‰©å±•è‡³**3DåŒ»å­¦å›¾åƒ**ï¼ˆå¦‚MRIä½“ç§¯æ•°æ®ï¼‰æˆ–å¤šæ¨¡æ€ä»»åŠ¡ã€‚
5. ğŸ” è¿›ä¸€æ­¥å½¢å¼åŒ–åˆ†æ**éšç§-æ•ˆç”¨æƒè¡¡è¾¹ç•Œ**ï¼Œæä¾›ç†è®ºä¿éšœã€‚

---

## æ€»ç»“

ğŸ“Œ **FALCONæ˜¯ä¸€ç§é¢å‘ç°å®åº”ç”¨çš„é«˜æ•ˆã€é²æ£’ã€éšç§å‹å¥½çš„OSFLæ–°èŒƒå¼**ã€‚å®ƒé€šè¿‡**HSE + M-AR Generator + Distillation-Guided Training**ä¸‰é‡æœºåˆ¶ï¼Œåœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹è§£å†³äº†non-IIDæ•°æ®ä¸‹çš„ç‰¹å¾é”™ä½ã€ç”Ÿæˆä½æ•ˆä¸éšç§æ³„éœ²ç­‰é—®é¢˜ï¼Œå°¤å…¶é€‚ç”¨äº**åŒ»ç–—å½±åƒç­‰é«˜åˆ†è¾¨ç‡ã€å¼ºå¼‚æ„åœºæ™¯**ï¼Œä¸ºå¤§è§„æ¨¡è”é‚¦å­¦ä¹ è½åœ°æä¾›äº†æœ‰åŠ›æ”¯æ’‘ã€‚

</details>

---

### 14. [Evolving Programmatic Skill Networks](https://arxiv.org/abs/2601.03509)

**Authors**: Haochen Shi, Xingdi Yuan, Bang Liu  
**Category**: cs.AI  
**Published**: 2026-01-08  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.03509v1  

#### Abstract
We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Evolving Programmatic Skill Networks è®ºæ–‡æ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**å¼€æ”¾ç¯å¢ƒä¸­å…·èº«æ™ºèƒ½ä½“ï¼ˆembodied agentsï¼‰çš„æŒç»­æŠ€èƒ½è·å–é—®é¢˜**ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨ä¸¤å¤§å±€é™ï¼š
- æŠ€èƒ½é€šå¸¸ä»¥æ‰å¹³åŒ–åº“æˆ–é™æ€å›¾å½¢å¼å­˜å‚¨ï¼Œç¼ºä¹å¯¹æŠ€èƒ½è¿›è¡ŒæŒç»­æ”¹è¿›çš„æœºåˆ¶ï¼›
- ç¼ºå°‘ç»Ÿä¸€æ¡†æ¶æ¥åœ¨åˆ†å±‚æŠ€èƒ½ç»„åˆä¸­åˆ†é…ä¿¡ç”¨ã€ä¿®å¤ç¬¦å·ç¨‹åºä»¥åŠéšä»»åŠ¡æ¼”åŒ–è€Œé‡ç»„ç»“æ„ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šProgrammatic Skill Network (PSN)
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Programmatic Skill Network (PSN)** çš„æ–°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ¯ä¸ªæŠ€èƒ½è¡¨ç¤ºä¸ºå¯æ‰§è¡Œçš„ç¬¦å·ç¨‹åºï¼ˆå¦‚JavaScriptæˆ–Pythonä»£ç ï¼‰ï¼Œå¹¶é€šè¿‡è°ƒç”¨å…³ç³»å½¢æˆä¸€ä¸ªåŠ¨æ€æ¼”åŒ–çš„æœ‰å‘å›¾ç½‘ç»œã€‚PSNé€šè¿‡ç»éªŒä¸æ–­æ„å»ºã€ä¼˜åŒ–å’Œé‡æ„è¿™ä¸ªæŠ€èƒ½ç½‘ç»œã€‚

#### ä¸‰å¤§æ ¸å¿ƒæœºåˆ¶ï¼ˆåˆ›æ–°ç‚¹ï¼‰ï¼š
1. **REFLECTï¼šåŸºäºæ‰§è¡Œè½¨è¿¹çš„ç»“æ„åŒ–æ•…éšœå®šä½**
   - åˆ©ç”¨LLMåˆ†ææ‰§è¡Œå¤±è´¥æ—¶çš„traceï¼Œè¯†åˆ«å‡ºå¯¼è‡´é”™è¯¯çš„å…·ä½“æ§åˆ¶æµã€å‚æ•°ã€å‰ç½®æ¡ä»¶æˆ–å­æŠ€èƒ½ã€‚
   - å®ç°äº†ç±»ä¼¼ç¥ç»ç½‘ç»œåå‘ä¼ æ’­ï¼ˆbackpropagationï¼‰çš„â€œç¬¦å·å¾®åˆ†â€è¿‡ç¨‹ï¼Œåœ¨æŠ€èƒ½ç»„åˆä¸­è¿›è¡Œä¿¡ç”¨åˆ†é…ã€‚

2. **æ¸è¿›å¼ä¼˜åŒ–ä¸æˆç†Ÿåº¦æ„ŸçŸ¥æ›´æ–°é—¨æ§ï¼ˆmaturity-aware update gatingï¼‰**
   - å¼•å…¥æŠ€èƒ½ä»·å€¼å‡½æ•° $V(s) = p_s - u_s$ï¼ˆæˆåŠŸç‡å‡å»ä¸ç¡®å®šæ€§ï¼‰è¡¡é‡æŠ€èƒ½å¯é æ€§ã€‚
   - æ ¹æ®æŠ€èƒ½æˆç†Ÿåº¦åŠ¨æ€è°ƒèŠ‚æ›´æ–°é¢‘ç‡ï¼šæˆç†ŸæŠ€èƒ½ï¼ˆé«˜$V(s)$ï¼‰å‡å°‘æ›´æ–°ä»¥ä¿æŒç¨³å®šï¼›ä¸æˆç†ŸæŠ€èƒ½ä¿æŒå¯å¡‘æ€§ä»¥ä¾¿å­¦ä¹ ã€‚
   - ç±»æ¯”äºç¥ç»ç½‘ç»œä¸­çš„å­¦ä¹ ç‡è°ƒåº¦å’Œå±‚å†»ç»“ç­–ç•¥ã€‚

3. **è§„èŒƒåŒ–çš„ç»“æ„é‡æ„ï¼ˆcanonical structural refactoringï¼‰ä¸å›æ»šéªŒè¯**
   - åœ¨ä»»åŠ¡æˆåŠŸåè§¦å‘åœ¨çº¿é‡æ„æ“ä½œï¼ŒåŒ…æ‹¬åˆå¹¶å†—ä½™æŠ€èƒ½ã€æŠ½è±¡é€šç”¨ä¾‹ç¨‹ã€å‰ªææ— å…³åˆ†æ”¯ç­‰ã€‚
   - æ‰€æœ‰é‡æ„å‡éœ€ç»è¿‡**å›æ»šéªŒè¯ï¼ˆrollback validationï¼‰**ï¼šåœ¨æœ€è¿‘çš„ä»»åŠ¡ä¸Šæµ‹è¯•æ€§èƒ½æ˜¯å¦ä¸‹é™è¶…è¿‡é˜ˆå€¼ï¼ˆå¦‚20%ï¼‰ï¼Œè‹¥ä¸‹é™åˆ™æ’¤é”€å˜æ›´ã€‚
   - åŠŸèƒ½ä¸Šç±»ä¼¼äºç¥ç»æ¶æ„æœç´¢ï¼ˆNeural Architecture Search, NASï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **å¯è§£é‡Šæ€§å¼º**ï¼šæŠ€èƒ½ä¸ºæ˜¾å¼çš„ç¬¦å·ç¨‹åºï¼Œå…·å¤‡æ˜ç¡®çš„æ§åˆ¶æµã€å‚æ•°å’Œå‰ç½®/åç½®æ¡ä»¶ã€‚
- **æ”¯æŒé•¿æœŸå¤åˆä»»åŠ¡**ï¼šé€šè¿‡æŠ€èƒ½å¤ç”¨å’Œç»„åˆè§£å†³é•¿è§†é‡ä»»åŠ¡ã€‚
- **æŒç»­æ¼”åŒ–èƒ½åŠ›**ï¼šæŠ€èƒ½åº“ä¸æ˜¯é™æ€çš„ï¼Œè€Œæ˜¯éšç€ç»éªŒå¢é•¿è‡ªåŠ¨ä¼˜åŒ–å’Œç²¾ç®€ã€‚
- **ç¨³å®šæ€§ä¸å¯å¡‘æ€§å¹³è¡¡**ï¼šé€šè¿‡æˆç†Ÿåº¦é—¨æ§é¿å…ç¾éš¾æ€§é—å¿˜ï¼ŒåŒæ—¶å…è®¸æ–°æŠ€èƒ½çµæ´»è°ƒæ•´ã€‚
- **ç»“æ„ç´§å‡‘æ€§**ï¼šé‡æ„æœºåˆ¶æœ‰æ•ˆæŠ‘åˆ¶æŠ€èƒ½åº“è†¨èƒ€ï¼Œæå‡è§„åˆ’æ•ˆç‡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒåœ¨ä¸¤ä¸ªå…·èº«ç¯å¢ƒåŸºå‡†ä¸Šè¿›è¡Œï¼š
- **MineDojo**ï¼šåŸºäºMinecraftçš„å¤æ‚å¼€æ”¾ä¸–ç•Œç¯å¢ƒï¼Œæ”¯æŒä¸°å¯Œçš„åŠ¨ä½œç©ºé—´å’Œå¤šæ ·åŒ–ç›®æ ‡æè¿°ã€‚
- **Crafter**ï¼šè½»é‡çº§ç”Ÿå­˜ç¯å¢ƒï¼Œå…·æœ‰ç»“æ„åŒ–çš„ç§‘æŠ€æ ‘è¿›å±•ï¼Œå¼ºè°ƒæŒç»­å­¦ä¹ å’Œç»„åˆæ³›åŒ–ã€‚

### å®éªŒè®¾ç½®
- ä½¿ç”¨ **gpt-5-mini-2025-08-07** ä½œä¸ºæ‰€æœ‰LLMé©±åŠ¨çš„æ“ä½œç¬¦ï¼ˆå¦‚`CODEGEN`, `REFLECT`ï¼‰ã€‚
- æ™ºèƒ½ä½“åœ¨ä¸€ä¸ªä»»åŠ¡æµ $\mathcal{T} = \{T_1, T_2, ...\}$ ä¸Šè¿ç»­å­¦ä¹ ï¼Œæ¯ä¸ªä»»åŠ¡ç”±è‡ªç„¶è¯­è¨€æŒ‡å®šã€‚
- æŠ€èƒ½æ‰§è¡ŒåŸºäº Mineflayer API æ§åˆ¶è™šæ‹Ÿè§’è‰²ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Tech Tree Mastery** | è§£é”ç‰©å“æ‰€éœ€çš„å¹³å‡è¿­ä»£æ¬¡æ•°ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ |
| **Cumulative Reward** | åœ¨Crafterä¸­ç´¯è®¡å¥–åŠ±ï¼Œåæ˜ ç”Ÿå­˜èƒ½åŠ›å’Œèµ„æºè·å–æ•ˆç‡ |
| **Skill Retention Rate (SRR)** | å·²æŒæ¡æŠ€èƒ½åœ¨åç»­ä»»åŠ¡è®­ç»ƒåçš„ä¿ç•™æˆåŠŸç‡ï¼Œç”¨äºè¡¡é‡**ç¾éš¾æ€§é—å¿˜**ç¨‹åº¦ |
| **Skill Library Size** | éšæ—¶é—´å¢é•¿çš„æŠ€èƒ½æ•°é‡ï¼Œè¯„ä¼°æŠ€èƒ½å¤ç”¨ä¸å†—ä½™æ§åˆ¶èƒ½åŠ› |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç‰¹ç‚¹ |
|------|------|
| **ReAct** | åŸºäºæç¤ºçš„æ¨ç†-è¡ŒåŠ¨å¾ªç¯ï¼Œæ— æŒä¹…åŒ–æŠ€èƒ½ |
| **Reflexion** | å¤±è´¥åè‡ªæˆ‘åæ€ï¼Œä½†æ— æŠ€èƒ½ç½‘ç»œç»“æ„ |
| **AutoGPT** | å¤šæ­¥è®¡åˆ’ç”Ÿæˆå¹¶æ‰§è¡Œä»£ç ï¼Œä½†æŠ€èƒ½ä¸ºä¸´æ—¶ç‰‡æ®µ |
| **Voyager** | ç»´æŠ¤æ‰å¹³æŠ€èƒ½åº“ï¼Œé€šè¿‡ç›¸ä¼¼æ€§æ£€ç´¢å¤ç”¨æŠ€èƒ½ï¼Œæ— trace-based credit assignment å’Œç»“æ„é‡æ„ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 å’Œ Figure 2ï¼‰

#### Minecraft ç§‘æŠ€æ ‘è§£é”æ•ˆç‡ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
| æ–¹æ³• | æœ¨åˆ¶å·¥å…· | çŸ³åˆ¶å·¥å…· | é“åˆ¶å·¥å…· | é’»çŸ³å·¥å…· | é»‘æ›œçŸ³ |
|------|---------|---------|---------|----------|--------|
| ReAct | N/A | N/A | N/A | N/A | â€” |
| Reflexion | N/A | N/A | N/A | N/A | â€” |
| AutoGPT | 92Â±72 | 94Â±72 | 135Â±103 | N/A | â€” |
| Voyager | 6Â±2 | 11Â±2 | 21Â±7 | 102 (1/3) | â€” |
| **PSN (Ours)** | **5Â±2** | **11Â±3** | **19Â±4** | **51Â±9 (3/3)** | **77 (1/3)** |

> âœ… PSN åœ¨æ‰€æœ‰é˜¶æ®µè¡¨ç°æ›´ä¼˜ï¼Œå°¤å…¶åœ¨é«˜é˜¶å·¥å…·ï¼ˆé’»çŸ³ã€é»‘æ›œçŸ³ï¼‰ä¸Šæ˜¾è‘—ä¼˜äº Voyagerï¼Œä¸”æˆåŠŸç‡æ›´é«˜ã€‚

### ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ä»»åŠ¡æˆåŠŸç‡**ï¼šPSN æˆåŠŸè§£é”é’»çŸ³å·¥å…·ä¸‰æ¬¡ï¼Œå¹³å‡ä»…éœ€ 51 æ¬¡å°è¯•ï¼›Voyager ä»…ä¸€æ¬¡æˆåŠŸï¼Œè€—æ—¶ 102 æ¬¡ã€‚
- **æŠ€èƒ½ä¿ç•™ç‡ï¼ˆFigure 4ï¼‰**ï¼šPSN çš„ Skill Retention Rate æ¥è¿‘ 100%ï¼Œè€Œ Voyager éšç€è®­ç»ƒæ¨è¿›è¿…é€Ÿä¸‹é™è‡³çº¦ 30%ï¼Œè¡¨æ˜å…¶å­˜åœ¨ä¸¥é‡**ç¾éš¾æ€§é—å¿˜**ã€‚
- **ç´¯ç§¯å¥–åŠ±ï¼ˆFigure 3ï¼‰**ï¼šåœ¨ Crafter ä¸­ï¼ŒPSN è·å¾—æ›´é«˜çš„ç´¯ç§¯å¥–åŠ±ï¼Œè¯´æ˜å…¶åœ¨å¯†é›†åé¦ˆç¯å¢ƒä¸‹ä¹Ÿèƒ½ç¨³å®šå­¦ä¹ ã€‚

### æ¶ˆèå®éªŒç»“æœ
| å˜ä½“ | ç»“æœåˆ†æ |
|------|----------|
| **PSN w/o Optimizer** | åœ¨æ—©æœŸä»»åŠ¡ä¸Šæ¥è¿‘å®Œæ•´ç‰ˆPSNï¼Œä½†åœ¨é“ä¹‹åæ— æ³•ç¨³å®šæ¨è¿›åˆ°é’»çŸ³/é»‘æ›œçŸ³ï¼Œè¯´æ˜ä¼˜åŒ–å™¨å¯¹é•¿è§†é‡ä»»åŠ¡è‡³å…³é‡è¦ã€‚ |
| **PSN w/o Maturity-aware Gating**ï¼ˆFigure 5ï¼‰ | å­¦ä¹ æ›²çº¿éœ‡è¡å‰§çƒˆï¼Œæ”¶æ•›ä¸ç¨³å®šï¼Œæœ€ç»ˆæˆåŠŸç‡ä½äºå®Œæ•´æ¨¡å‹ï¼Œè¯æ˜æˆç†Ÿåº¦é—¨æ§æœ‰åŠ©äºç¨³å®šå¯é æŠ€èƒ½ã€‚ |
| **PSN vs. Create New Skills**ï¼ˆFigure 6ï¼‰ | è‹¥æ¯æ¬¡ä»»åŠ¡éƒ½åˆ›å»ºæ–°æŠ€èƒ½ï¼ŒæŠ€èƒ½åº“å¿«é€Ÿå¢é•¿ï¼›è€ŒPSNé€šè¿‡å¤ç”¨å·²æœ‰æŠ€èƒ½ä½¿åº“å¤§å°è¶‹äºå¹³ç¨³ç”šè‡³ä¸‹é™ï¼Œä½“ç°é«˜æ•ˆå¤ç”¨èƒ½åŠ›ã€‚ |
| **Offline Refactor vs. Online Refactor** | å¯¹VoyageræŠ€èƒ½åº“è¿›è¡Œç¦»çº¿é‡æ„ï¼ˆVoyager-Rï¼‰è™½å‡å°‘äº†ä»£ç é‡å¤ï¼Œä½†ä»»åŠ¡æˆåŠŸç‡ä»…ä¸º 0.6875ï¼Œè¿œä½äºPSNçš„ 0.8462ï¼Œè¯´æ˜**åœ¨çº¿ç´§è€¦åˆçš„é‡æ„æœºåˆ¶æ›´æœ‰æ•ˆ**ã€‚ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **PSNçš„å­¦ä¹ åŠ¨åŠ›å­¦ä¸ç¥ç»ç½‘ç»œè®­ç»ƒå­˜åœ¨ç»“æ„æ€§ç±»æ¯”**ï¼š
   - REFLECT â‰ˆ Backpropagationï¼ˆä¿¡ç”¨åˆ†é…ï¼‰
   - Maturity-aware Gating â‰ˆ Learning Rate Scheduling / Layer Freezingï¼ˆç¨³å®šæ€§-å¯å¡‘æ€§æƒè¡¡ï¼‰
   - Refactor â‰ˆ Neural Architecture Searchï¼ˆç»“æ„æœç´¢ï¼‰
   - è¿™ä¸€æ´å¯Ÿæ­ç¤ºäº†ä¸åŒè¡¨å¾èŒƒå¼ä¸‹æŒç»­å­¦ä¹ åŸåˆ™çš„æ™®é€‚æ€§ã€‚

2. **ç¬¦å·ç¨‹åºä½œä¸ºæŠ€èƒ½è½½ä½“å…·æœ‰å¼ºå¤§è¡¨è¾¾åŠ›å’Œå¯ç»´æŠ¤æ€§**ï¼š
   - æ˜¾å¼æ§åˆ¶æµå’Œé¢„/åç½®æ¡ä»¶ä½¿å¾—æŠ€èƒ½è¡Œä¸ºé€æ˜å¯æ§ã€‚
   - æ”¯æŒç»†ç²’åº¦ä¿®å¤ï¼ˆå¦‚èµ„æºè®¡ç®—ã€è¾¹ç•Œæ£€æŸ¥ã€APIè¯¯ç”¨ï¼‰å’Œè·¨æŠ€èƒ½ååŒä¼˜åŒ–ã€‚

3. **åœ¨çº¿ç»“æ„é‡æ„ + å›æ»šéªŒè¯ æ˜¯ç»´æŒæŠ€èƒ½åº“ç´§å‡‘æ€§çš„å…³é”®**ï¼š
   - ä¸ä»…å‡å°‘å†—ä½™ï¼Œè¿˜ä¿ƒè¿›æ›´é«˜å±‚æ¬¡çš„æŠ½è±¡ï¼ˆå¦‚ä» `mineOakLogs` å’Œ `mineBirchLogs` æŠ½è±¡å‡º `mineLogs(type)`ï¼‰ã€‚

4. **æŠ€èƒ½å¤ç”¨è€Œéå¤åˆ¶æ˜¯å®ç°ç»„åˆæ³›åŒ–çš„æ ¸å¿ƒè·¯å¾„**ï¼š
   - PSNé€šè¿‡backward-chainingä¼˜å…ˆå¤ç”¨å·²æœ‰æŠ€èƒ½ï¼Œæ˜¾è‘—é™ä½æŠ€èƒ½åº“å¢é•¿é€Ÿåº¦ï¼Œå¹¶æå‡æ³›åŒ–èƒ½åŠ›ã€‚

### å±€é™æ€§
- å½“å‰å®ç°å—é™äº**å•æ ·æœ¬åœ¨çº¿å­¦ä¹ æ¨¡å¼**ï¼ˆbatch-size-oneï¼‰ï¼Œç¼ºä¹å¹¶è¡Œæ‰§è¡Œä¸ä¼˜åŒ–èƒ½åŠ›ã€‚
- **ç¼ºä¹å½¢å¼åŒ–ä¿è¯**ï¼šé‡æ„å’Œåå°„è¿‡ç¨‹æ²¡æœ‰ç†è®ºä¸Šçš„æ”¶æ•›æ€§æˆ–æœ€ä¼˜æ€§è¯æ˜ã€‚
- ä¾èµ–LLMç”Ÿæˆè´¨é‡ï¼Œå¯èƒ½å¼•å…¥è¯­ä¹‰ä¸ä¸€è‡´æˆ–æ— æ•ˆä¿®æ”¹ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³å¤§è§„æ¨¡æ‰¹é‡å­¦ä¹ åœºæ™¯ï¼Œåˆ©ç”¨æ›´å¤šå¹¶è¡Œèµ„æºåŠ é€Ÿæ¼”åŒ–ã€‚
- å¼•å…¥æ›´å¼ºçš„å½¢å¼åŒ–æ–¹æ³•ï¼ˆå¦‚ç¨‹åºéªŒè¯ã€ç±»å‹ç³»ç»Ÿï¼‰å¢å¼ºé‡æ„çš„å®‰å…¨æ€§å’Œæ­£ç¡®æ€§ã€‚
- æ¢ç´¢å¤šæ™ºèƒ½ä½“åä½œä¸‹çš„æŠ€èƒ½å…±äº«ä¸è¿ç§»ã€‚
- å°†PSNæ€æƒ³åº”ç”¨äºå…¶ä»–é¢†åŸŸï¼ˆå¦‚æœºå™¨äººæ§åˆ¶ã€Webè‡ªåŠ¨åŒ–ä»£ç†ï¼‰ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> PSN æå‡ºäº†ä¸€ç§å°†æŠ€èƒ½ç»„ç»‡ä¸ºå¯æ‰§è¡Œç¬¦å·ç¨‹åºç½‘ç»œçš„æ¡†æ¶ï¼Œé€šè¿‡ **REFLECTã€æˆç†Ÿåº¦é—¨æ§ã€åœ¨çº¿é‡æ„** ä¸‰å¤§æœºåˆ¶å®ç°äº†ç±»ç¥ç»ç½‘ç»œçš„æŒç»­å­¦ä¹ åŠ¨åŠ›å­¦ï¼Œåœ¨å¼€æ”¾ç¯å¢ƒä¸­å±•ç°å‡ºå“è¶Šçš„æŠ€èƒ½å¤ç”¨ã€å¿«é€Ÿé€‚åº”å’Œå¼ºæ³›åŒ–èƒ½åŠ›ã€‚

</details>

---

### 15. [DiffCoT: Diffusion-styled Chain-of-Thought Reasoning in LLMs](https://arxiv.org/abs/2601.03559)

**Authors**: Shidong Cao, Hongzhan Lin, Yuxuan Gu, Ziyang Luo, Jing Ma  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.03559v1  

#### Abstract
Chain-of-Thought (CoT) reasoning improves multi-step mathematical problem solving in large language models but remains vulnerable to exposure bias and error accumulation, as early mistakes propagate irreversibly through autoregressive decoding. In this work, we propose DiffCoT, a diffusion-styled Co...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**DIFFCoT: Diffusion-styled Chain-of-Thought Reasoning in LLMs**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿçš„ **Chain-of-Thought (CoT)** æ¨ç†åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­å¹¿æ³›ç”¨äºæ•°å­¦ç­‰å¤šæ­¥æ¨ç†ä»»åŠ¡ï¼Œä½†å…¶å­˜åœ¨ä¸¤ä¸ªå…³é”®ç¼ºé™·ï¼š
- **æš´éœ²åå·®ï¼ˆexposure biasï¼‰**ï¼šè®­ç»ƒæ—¶ä½¿ç”¨â€œæ•™å¸ˆå¼ºåˆ¶â€ï¼ˆteacher-forcingï¼‰ï¼Œå³æ¯ä¸€æ­¥éƒ½åŸºäºæ­£ç¡®çš„å‰ç¼€ç”Ÿæˆï¼›ä½†åœ¨æ¨ç†æ—¶ï¼Œä¸€æ—¦æŸæ­¥å‡ºé”™ï¼Œé”™è¯¯ä¼šæŒç»­ä¼ æ’­ã€‚
- **é”™è¯¯ç´¯ç§¯ï¼ˆerror accumulationï¼‰**ï¼šæ—©æœŸæ­¥éª¤ä¸­çš„é”™è¯¯æ— æ³•è¢«åç»­ä¿®æ­£ï¼Œå¯¼è‡´æœ€ç»ˆç­”æ¡ˆé”™è¯¯ã€‚

ç°æœ‰æ–¹æ³•å¦‚ **Preference Optimization (PO)** å’Œ **Tree of Thoughts (ToT)** è™½èƒ½é€šè¿‡åå¥½å­¦ä¹ æˆ–æœç´¢æœºåˆ¶ç¼“è§£éƒ¨åˆ†é—®é¢˜ï¼Œä½†ä»å—é™äºå‰å‘ã€å•å‘çš„ç”Ÿæˆæ¨¡å¼ï¼Œç¼ºä¹å¯¹å·²ç”Ÿæˆæ­¥éª¤çš„å…¨å±€ä¿®æ­£èƒ½åŠ›ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼š**DIFFCoT**
ä½œè€…æå‡º **DIFFCoT**ï¼Œä¸€ç§å°† **æ‰©æ•£æ¨¡å‹ï¼ˆdiffusion modelï¼‰æ€æƒ³å¼•å…¥ CoT æ¨ç†** çš„æ–°æ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ˜¯å°† CoT æ¨ç†é‡æ„ä¸ºä¸€ä¸ª**è¿­ä»£å»å™ªè¿‡ç¨‹**ï¼Œå…è®¸æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä¸æ–­å›é¡¾å¹¶ä¿®æ­£å…ˆå‰çš„æ¨ç†æ­¥éª¤ã€‚

#### åˆ›æ–°ç‚¹ï¼š
1. **æ‰©æ•£é£æ ¼çš„æ¨ç†èŒƒå¼**  
   å°†æ•´ä¸ªæ¨ç†é“¾è§†ä¸ºä¸€æ¡å¯èƒ½è¢«â€œå™ªå£°æ±¡æŸ“â€çš„è·¯å¾„ï¼Œé€šè¿‡å¤šè½®è¿­ä»£é€æ­¥â€œå»å™ªâ€ï¼Œæå‡æ¨ç†è½¨è¿¹çš„æ•´ä½“ä¸€è‡´æ€§ã€‚

2. **æ»‘åŠ¨çª—å£æœºåˆ¶ï¼ˆsliding-window mechanismï¼‰**  
   åœ¨æ¨ç†è¿‡ç¨‹ä¸­ç»´æŠ¤ä¸€ä¸ªæ»‘åŠ¨çª—å£ï¼Œå¯¹çª—å£å†…çš„å†å²æ­¥éª¤è¿›è¡Œ**åŒæ—¶ç”Ÿæˆä¸ä¿®è®¢**ï¼Œå®ç°ç”Ÿæˆä¸è‡ªæˆ‘çº æ­£çš„ç»Ÿä¸€ã€‚

3. **å› æœæ‰©æ•£å™ªå£°è°ƒåº¦ï¼ˆcausal diffusion noise scheduleï¼‰**  
   å¼•å…¥æ—¶é—´æ„ŸçŸ¥çš„å™ªå£°ç­–ç•¥ï¼šè¶Šé åçš„æ¨ç†æ­¥éª¤æ–½åŠ æ›´å¼ºçš„å™ªå£°æ‰°åŠ¨ï¼Œä»¥ä¿ç•™æ¨ç†é“¾çš„**æ—¶åºå› æœç»“æ„**ï¼Œé˜²æ­¢æœªæ¥ä¿¡æ¯æ³„éœ²ã€‚

4. **ä¿ç•™ token-level autoregression**  
   åœ¨æ­¥éª¤çº§åˆ«å¼•å…¥æ‰©æ•£æœºåˆ¶çš„åŒæ—¶ï¼Œä¿æŒ token çº§åˆ«çš„è‡ªå›å½’ç”Ÿæˆï¼Œç¡®ä¿ä¸ç°æœ‰ LLM æ¶æ„å…¼å®¹ï¼Œä¾¿äºå¾®è°ƒã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | ä¼ ç»Ÿ CoT / DPO æ–¹æ³• | DIFFCoT |
|------|---------------------|---------|
| é”™è¯¯å¯ä¿®æ­£æ€§ | âŒ ä»…å‰å‘ç”Ÿæˆï¼Œé”™è¯¯ä¸å¯é€† | âœ… å¯è¿­ä»£ä¿®æ­£æ—©æœŸé”™è¯¯ |
| æš´éœ²åå·® | é«˜ï¼ˆè®­ç»ƒä¸æ¨ç†ä¸ä¸€è‡´ï¼‰ | æ˜¾è‘—é™ä½ |
| å…¨å±€ä¸€è‡´æ€§ | å±€éƒ¨ä¼˜åŒ–ä¸ºä¸» | æ”¯æŒé•¿ç¨‹ä¿¡å·å¼•å¯¼çš„å…¨å±€ä¼˜åŒ– |
| å®ç°å¤æ‚åº¦ | ä½ | ä¸­ç­‰ï¼ˆéœ€æ„é€ åå¥½å¯¹ï¼‰ |
| ä¸ç°æœ‰æ¶æ„å…¼å®¹æ€§ | é«˜ | é«˜ï¼ˆåŸºäº LoRA å¾®è°ƒå³å¯ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ä¸‰ä¸ªä¸»æµæ•°å­¦æ¨ç†åŸºå‡†ä¸Šè¿›è¡Œè¯„ä¼°ï¼š
- **GSM8K**ï¼šå°å­¦çº§æ•°å­¦åº”ç”¨é¢˜ï¼Œå¼ºè°ƒå¤šæ­¥ç®—æœ¯æ¨ç†ã€‚
- **SVAMP**ï¼šè¯­ä¹‰å˜ä½“ç‰ˆçš„æ•°å­¦é—®é¢˜ï¼Œæµ‹è¯•æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚
- **MATH**ï¼šæ¶µç›–äº”ä¸ªéš¾åº¦ç­‰çº§ï¼ˆL1â€“L5ï¼‰ï¼Œé¢˜ç›®æ›´å¤æ‚ï¼Œæ¶‰åŠä»£æ•°ã€å‡ ä½•ç­‰ã€‚

> æ‰€æœ‰æ•°æ®é›†å‡é‡‡æ ·æœ€å¤š 300 ä¸ªæµ‹è¯•æ ·æœ¬ï¼Œå¹¶æ§åˆ¶æœ€å¤§æ¨ç†æ­¥æ•° $ K $ã€‚

---

### å®éªŒè®¾ç½®
- **æ¨¡å‹éª¨å¹²ï¼ˆbackbone modelsï¼‰**ï¼š
  - Llama3-8B
  - Qwen3-8B
  - Qwen3-4B
- **è®­ç»ƒæ–¹å¼**ï¼š
  - ä½¿ç”¨ **LoRA** è¿›è¡Œé«˜æ•ˆå¾®è°ƒï¼ˆrank=8ï¼‰
  - é‡‡ç”¨ **Direct Preference Optimization (DPO)** æŸå¤±å‡½æ•°ï¼ˆ$\beta=0.4$ï¼‰
  - å­¦ä¹ ç‡ï¼š1e-5ï¼Œcosine è°ƒåº¦ï¼Œbatch size=32ï¼Œè®­ç»ƒ 3 è½®
- **æ¨ç†å‚æ•°**ï¼š
  - æ¸©åº¦å›ºå®šä¸º 0.4ï¼Œè´ªå©ªè§£ç 
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **å‡†ç¡®ç‡ï¼ˆAccuracy %ï¼‰**ï¼šæœ€ç»ˆç­”æ¡ˆæ˜¯å¦æ­£ç¡®

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç®€ä»‹ |
|------|------|
| **CoT** | æ ‡å‡†æ€ç»´é“¾æç¤ºï¼Œgreedy decoding |
| **ToT (Tree of Thoughts)** | å¤šè·¯å¾„æœç´¢ï¼Œç»“åˆ MCTS æ¢ç´¢æœ€ä¼˜è·¯å¾„ |
| **TS-SFT** | å¯¹ ToT æœç´¢å¾—åˆ°çš„é«˜è´¨é‡è·¯å¾„è¿›è¡Œç›‘ç£å¾®è°ƒ |
| **CPO (Chain of Preference Optimization)** | æ­¥éª¤çº§åå¥½ä¼˜åŒ–ï¼Œåˆ©ç”¨ LLM è‡ªæˆ‘è¯„åˆ¤æ„å»ºåå¥½å¯¹ |
| **Step-DPO** | æ˜¾å¼æ”¶é›†é”™è¯¯æ­¥éª¤ï¼Œè¿›è¡Œæ­¥éª¤çº§ DPO |
| **Full-Step-DPO** | å¯¹æ•´æ¡æ¨ç†é“¾è¿›è¡Œå…¨å±€åå¥½ä¼˜åŒ– |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ–¹æ³• \ æ•°æ®é›† | GSM8K | SVAMP | MATH-L1 | MATH-L5 |
|---------------|-------|-------|--------|--------|
| CoT           | 37.2  | 49.6  | 31.3   | 1.9    |
| ToT           | 37.7  | 48.8  | 33.8   | 3.0    |
| CPO           | 36.1  | 48.6  | 32.0   | 3.1    |
| Step-DPO      | 38.1  | 48.4  | 32.0   | 3.1    |
| Full-Step-DPO | 39.6  | 50.4  | 34.3   | 4.4    |
| **DIFFCoT**   | **65.5** | **85.9** | **63.0** | **10.5** |

> æ³¨ï¼šDIFFCoT åœ¨æ‰€æœ‰ä¸»å¹²æ¨¡å‹ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œå°¤å…¶åœ¨å›°éš¾ä»»åŠ¡ï¼ˆå¦‚ MATH-L4/L5ï¼‰ä¸Šæå‡æ˜æ˜¾ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **å¹³å‡æå‡å¹…åº¦**ï¼š
  - åœ¨ GSM8K ä¸Šæ¯” Full-Step-DPO æå‡è¿‘ **26 ä¸ªç™¾åˆ†ç‚¹**
  - åœ¨ SVAMP ä¸Šæå‡çº¦ **5â€“6 ä¸ªç™¾åˆ†ç‚¹**
  - åœ¨ MATH å„å±‚çº§ä¸­ï¼Œå¹³å‡æå‡ **20+ ä¸ªç™¾åˆ†ç‚¹**
- **ç¨³å®šæ€§æ›´é«˜**ï¼š
  - CPO å’Œ ToT åœ¨ä¸åŒæ¨¡å‹ä¸Šçš„è¡¨ç°æ³¢åŠ¨è¾ƒå¤§ï¼ˆä¾‹å¦‚åœ¨ Qwen3-8B ä¸Š MATH-L1 æ€§èƒ½ä¸‹é™ï¼‰
  - DIFFCoT åœ¨æ‰€æœ‰æ¨¡å‹å’Œæ•°æ®é›†ä¸Šå‡ä¿æŒç¨³å®šé¢†å…ˆ

---

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 2ï¼‰

| æ¨¡å‹ | è®¾ç½® | GSM8K â†“ | SVAMP â†“ |
|------|------|--------|--------|
| Llama3-8B | å®Œæ•´ DIFFCoT | 39.6 | 50.4 |
| &nbsp;&nbsp;â€“ window size=1 (é€€åŒ–ä¸º AR) | | 36.3 (-3.3) | 48.3 (-2.1) |
| &nbsp;&nbsp;â€“ window size=K (å…¨åºåˆ—æ‰©æ•£) | | 30.3 (-9.3) | 42.6 (-7.8) |
| &nbsp;&nbsp;â€“ ç§»é™¤ causal noise | | 35.5 (-4.1) | 48.2 (-2.2) |
| Qwen3-4B | å®Œæ•´ DIFFCoT | 65.4 | 83.2 |
| &nbsp;&nbsp;â€“ window size=1 | | 63.0 (-2.4) | 80.2 (-3.0) |
| &nbsp;&nbsp;â€“ window size=K | | 56.7 (-8.7) | 73.9 (-9.3) |
| &nbsp;&nbsp;â€“ ç§»é™¤ causal noise | | 61.9 (-3.5) | 79.1 (-4.1) |

#### ç»“è®ºï¼š
- **æ»‘åŠ¨çª—å£å¤§å°é€‚ä¸­æœ€ä½³**ï¼šå¤ªå°ï¼ˆ=1ï¼‰å¤±å»ä¿®æ­£èƒ½åŠ›ï¼›å¤ªå¤§ï¼ˆ=Kï¼‰ç ´åå› æœç»“æ„ã€‚
- **å› æœå™ªå£°è°ƒåº¦è‡³å…³é‡è¦**ï¼šç§»é™¤åæ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œè¯´æ˜å…¶å¯¹ç»´æŒæ¨ç†é€»è¾‘è¿è´¯æ€§èµ·å…³é”®ä½œç”¨ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **CoT æ¨ç†å¯ä»¥ä¸”åº”è¯¥æ”¯æŒå…¨å±€å¯ä¿®è®¢æ€§**  
   ä¼ ç»Ÿå‰å‘ç”ŸæˆèŒƒå¼é™åˆ¶äº†çº é”™èƒ½åŠ›ï¼Œè€Œ DIFFCoT è¯æ˜é€šè¿‡å¼•å…¥æ‰©æ•£æœºåˆ¶ï¼Œå¯ä»¥è®©æ¨¡å‹â€œå›å¤´çœ‹â€å¹¶ä¿®æ­£æ—©æœŸé”™è¯¯ã€‚

2. **è¿­ä»£å»å™ªæ˜¾è‘—å¢å¼ºé²æ£’æ€§**  
   å³ä½¿åˆå§‹æ¨ç†è·¯å¾„åŒ…å«è¯­ä¹‰æ¼‚ç§»æˆ–å¼±ç›¸å…³æ­¥éª¤ï¼ŒDIFFCoT ä¹Ÿèƒ½é€šè¿‡å¤šè½®å»å™ªé€æ¸æ”¶æ•›åˆ°æ­£ç¡®è·¯å¾„ã€‚

3. **å› æœç»“æ„å¿…é¡»æ˜¾å¼å»ºæ¨¡**  
   ç›²ç›®åº”ç”¨å…¨åºåˆ—æ‰©æ•£ä¼šç ´åæ¨ç†çš„æ—¶é—´ä¾èµ–æ€§ï¼Œå› æ­¤æå‡ºçš„ **causal diffusion noise schedule** æ˜¯æˆåŠŸçš„å…³é”®è®¾è®¡ã€‚

4. **æ€§èƒ½æå‡å…·æœ‰æ™®é€‚æ€§å’Œå¯æ‰©å±•æ€§**  
   DIFFCoT åœ¨ä¸åŒè§„æ¨¡ï¼ˆ4B/8Bï¼‰ã€ä¸åŒå®¶æ—ï¼ˆLlama/Qwenï¼‰çš„æ¨¡å‹ä¸Šå‡å–å¾—ä¸€è‡´å¢ç›Šï¼Œè¡¨æ˜å…¶è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ç¦»ç­–ç•¥æ•°æ®æ„å»ºå¸¦æ¥çš„åˆ†å¸ƒåç§»é£é™©**  
   åå¥½æ•°æ®ç”± MCTS ç”Ÿæˆï¼Œè€Œç›®æ ‡æ¨¡å‹æ˜¯å¾®è°ƒåçš„ LLMï¼Œè¡Œä¸ºç­–ç•¥ä¸è®­ç»ƒç­–ç•¥ä¸ä¸€è‡´ï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚

2. **è¿åå±€éƒ¨é©¬å°”å¯å¤«æ€§è´¨**  
   å› ä¸ºå…è®¸ä¿®æ”¹å†å²æ­¥éª¤ï¼Œæ‰“ç ´äº†æ ‡å‡†è‡ªå›å½’ç”Ÿæˆçš„â€œè¿‡å»ä¸å˜â€å‡è®¾ï¼Œå¢åŠ äº†ç”Ÿæˆè¿‡ç¨‹çš„ä¸ç¡®å®šæ€§ã€‚

3. **è®­ç»ƒæˆæœ¬è¾ƒé«˜**  
   éœ€è¦é¢å¤–ç”Ÿæˆå¤§é‡å€™é€‰è·¯å¾„å’Œ rollout è¯„ä¼°ï¼Œæ•°æ®æ„é€ å¼€é”€å¤§ï¼ˆçº¦ 11 GPU å°æ—¶å¤„ç† 500 æ ·æœ¬ï¼‰ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢å°† **Reinforcement Learning** ä¸æ‰©æ•£æ»‘åŠ¨çª—å£ç»“åˆï¼Œç›´æ¥ä¼˜åŒ–å»å™ªåŠ¨æ€è¿‡ç¨‹ã€‚
- æ‰©å±•è‡³æ›´å¤šæ¨ç†é¢†åŸŸï¼Œå¦‚ç¬¦å·æ¨ç†ã€ç¨‹åºåˆæˆã€ç§‘å­¦é—®ç­”ç­‰ã€‚
- è®¾è®¡æ›´é«˜æ•ˆçš„åœ¨çº¿ç­–ç•¥æ•°æ®é‡‡é›†æœºåˆ¶ï¼Œå‡å°‘å¯¹å¤–éƒ¨æœç´¢ï¼ˆå¦‚ MCTSï¼‰çš„ä¾èµ–ã€‚
- ç ”ç©¶å¦‚ä½•åœ¨ä¸ç‰ºç‰²æ¨ç†æ•ˆç‡çš„å‰æä¸‹ï¼Œè¿›ä¸€æ­¥å‹ç¼©è¿­ä»£æ¬¡æ•°ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> DIFFCoT æˆåŠŸåœ°å°† **diffusion model çš„æ€æƒ³èå…¥ CoT æ¨ç†**ï¼Œå®ç°äº†â€œè¾¹æƒ³è¾¹æ”¹â€çš„ç±»äººæ¨ç†æœºåˆ¶ï¼Œåœ¨å¤šä¸ªæ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šå¤§å¹…è¶…è¶Šç°æœ‰ PO æ–¹æ³•ï¼Œä¸ºæ„å»ºæ›´é²æ£’ã€å¯çº é”™çš„è¯­è¨€æ¨¡å‹æ¨ç†ç³»ç»Ÿæä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 16. [What Does Loss Optimization Actually Teach, If Anything? Knowledge Dynamics in Continual Pre-training of LLMs](https://arxiv.org/abs/2601.03858)

**Authors**: Seyed Mahed Mousavi, Simone Alghisi, Giuseppe Riccardi  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.03858v1  

#### Abstract
Continual Pre-Training (CPT) is widely used for acquiring and updating factual knowledge in LLMs. This practice treats loss as a proxy for knowledge learning, while offering no grounding into how it changes during training. We study CPT as a knowledge learning process rather than a solely optimizati...

---

### 17. [Evaluating Small Decoder-Only Language Models for Grammar Correction and Text Simplification](https://arxiv.org/abs/2601.03874)

**Authors**: Anthony Lamelas  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.03874v1  

#### Abstract
Large language models have become extremely popular recently due to their ability to achieve strong performance on a variety of tasks, such as text generation and rewriting, but their size and computation cost make them difficult to access, deploy, and secure in many settings. This paper investigate...

---

### 18. [Weather-Aware Transformer for Real-Time Route Optimization in Drone-as-a-Service Operations](https://arxiv.org/abs/2601.03376)

**Authors**: Kamal Mohamed, Lillian Wassim, Ali Hamdi, Khaled Shaban  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.03376v1  

#### Abstract
This paper presents a novel framework to accelerate route prediction in Drone-as-a-Service operations through weather-aware deep learning models. While classical path-planning algorithms, such as A* and Dijkstra, provide optimal solutions, their computational complexity limits real-time applicabilit...

---

### 19. [Variational Inference, Entropy, and Orthogonality: A Unified Theory of Mixture-of-Experts](https://arxiv.org/abs/2601.03577)

**Authors**: Ye Su, Yong Liu  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.03577v1  

#### Abstract
Mixture-of-Experts models enable large language models to scale efficiently, as they only activate a subset of experts for each input. Their core mechanisms, Top-k routing and auxiliary load balancing, remain heuristic, however, lacking a cohesive theoretical underpinning to support them. To this en...

---

### 20. [Controllable LLM Reasoning via Sparse Autoencoder-Based Steering](https://arxiv.org/abs/2601.03595)

**Authors**: Yi Fang, Wenjie Wang, Mingfeng Xue, Boyi Deng, Fengli Xu, Dayiheng Liu, Fuli Feng  
**Category**: cs.AI  
**Published**: 2026-01-08  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.03595v1  

#### Abstract
Large Reasoning Models (LRMs) exhibit human-like cognitive reasoning strategies (e.g. backtracking, cross-verification) during reasoning process, which improves their performance on complex tasks. Currently, reasoning strategies are autonomously selected by LRMs themselves. However, such autonomous ...

---

### 21. [ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition](https://arxiv.org/abs/2601.03822)

**Authors**: Muyang Zhao, Qi Qi, Hao Sun  
**Category**: cs.AI  
**Published**: 2026-01-08  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.03822v1  

#### Abstract
Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered ...

---

### 22. [Trade-R1: Bridging Verifiable Rewards to Stochastic Environments via Process-Level Reasoning Verification](https://arxiv.org/abs/2601.03948)

**Authors**: Rui Sun, Yifan Sun, Sheng Xu, Li Zhao, Jing Li, Daxin Jiang, Chen Hua, Zuo Bai  
**Category**: cs.AI  
**Published**: 2026-01-08  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.03948v1  

#### Abstract
Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to achieve remarkable reasoning in domains like mathematics and coding, where verifiable rewards provide clear signals. However, extending this paradigm to financial decision is challenged by the market's stochastic nature: rewards...

---

### 23. [EvolMem: A Cognitive-Driven Benchmark for Multi-Session Dialogue Memory](https://arxiv.org/abs/2601.03543)

**Authors**: Ye Shen, Dun Pei, Yiqiu Guo, Junying Wang, Yijin Guo, Zicheng Zhang, Qi Jia, Jun Zhou, Guangtao Zhai  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.03543v1  

#### Abstract
Despite recent advances in understanding and leveraging long-range conversational memory, existing benchmarks still lack systematic evaluation of large language models(LLMs) across diverse memory dimensions, particularly in multi-session settings. In this work, we propose EvolMem, a new benchmark fo...

---

### 24. [SyncThink: A Training-Free Strategy to Align Inference Termination with Reasoning Saturation](https://arxiv.org/abs/2601.03649)

**Authors**: Gengyang Li, Wang Cai, Yifeng Gao, Yunfang Wu  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.03649v1  

#### Abstract
Chain-of-Thought (CoT) prompting improves reasoning but often produces long and redundant traces that substantially increase inference cost. We present SyncThink, a training-free and plug-and-play decoding method that reduces CoT overhead without modifying model weights. We find that answer tokens a...

---

### 25. [Decide Then Retrieve: A Training-Free Framework with Uncertainty-Guided Triggering and Dual-Path Retrieval](https://arxiv.org/abs/2601.03908)

**Authors**: Wang Chen, Guanqiang Qi, Weikang Li, Yang Li, Deguo Xia, Jizhou Huang  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.03908v1  

#### Abstract
Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge, but existing approaches indiscriminately trigger retrieval and rely on single-path evidence construction, often introducing noise and limiting performance gains. In this work, we propose D...

---

### 26. [Enhancing Small Dataset Classification Using Projected Quantum Kernels with Convolutional Neural Networks](https://arxiv.org/abs/2601.03375)

**Authors**: A. M. A. S. D. Alagiyawanna, Asoka Karunananda, A. Mahasinghe, Thushari Silva  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.03375v1  

#### Abstract
Convolutional Neural Networks (CNNs) have shown promising results in efficiency and accuracy in image classification. However, their efficacy often relies on large, labeled datasets, posing challenges for applications with limited data availability. Our research addresses these challenges by introdu...

---

### 27. [Sensor to Pixels: Decentralized Swarm Gathering via Image-Based Reinforcement Learning](https://arxiv.org/abs/2601.03413)

**Authors**: Yigal Koifman, Eran Iceland, Erez Koifman, Ariel Barel, Alfred M. Bruckstein  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.03413v1  

#### Abstract
This study highlights the potential of image-based reinforcement learning methods for addressing swarm-related tasks. In multi-agent reinforcement learning, effective policy learning depends on how agents sense, interpret, and process inputs. Traditional approaches often rely on handcrafted feature ...

---

### 28. [Lightweight Test-Time Adaptation for EMG-Based Gesture Recognition](https://arxiv.org/abs/2601.04181)

**Authors**: Nia Touko, Matthew O A Ellis, Cristiano Capone, Alessio Burrello, Elisa Donati, Luca Manneschi  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.04181v1  

#### Abstract
Reliable long-term decoding of surface electromyography (EMG) is hindered by signal drift caused by electrode shifts, muscle fatigue, and posture changes. While state-of-the-art models achieve high intra-session accuracy, their performance often degrades sharply. Existing solutions typically demand ...

---

### 29. [Digital Red Queen: Adversarial Program Evolution in Core War with LLMs](https://arxiv.org/abs/2601.03335)

**Authors**: Akarsh Kumar, Ryan Bahlous-Boldi, Prafull Sharma, Phillip Isola, Sebastian Risi, Yujin Tang, David Ha  
**Category**: cs.AI  
**Published**: 2026-01-08  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.03335v1  

#### Abstract
Large language models (LLMs) are increasingly being used to evolve solutions to problems in many domains, in a process inspired by biological evolution. However, unlike biological evolution, most LLM-evolution frameworks are formulated as static optimization problems, overlooking the open-ended adve...

---

### 30. [xDNN(ASP): Explanation Generation System for Deep Neural Networks powered by Answer Set Programming](https://arxiv.org/abs/2601.03847)

**Authors**: Ly Ly Trieu (New Mexico State University), Tran Cao Son (New Mexico State University)  
**Category**: cs.AI  
**Published**: 2026-01-08  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.03847v1  

#### Abstract
Explainable artificial intelligence (xAI) has gained significant attention in recent years. Among other things, explainablility for deep neural networks has been a topic of intensive research due to the meteoric rise in prominence of deep neural networks and their "black-box" nature. xAI approaches ...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
