# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-05 05:54:55 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [RLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting](https://arxiv.org/abs/2512.04752)

**Authors**: Siqi Wang, Hailong Yang, Junjie Zhu, Xuezhu Wang, Yufan Xu, Depei Qian  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 13.0  
**Type**: new  
**ArXiv ID**: 2512.04752v1  

#### Abstract
Reinforcement Learning from Human Feedback (RLHF) is an important fine-tuning technique for large language models (LLMs) and comprises three stages: generation, inference, and training. The generation stage generates samples that are then used to infer learnable experiences for training. We observe ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **ç”Ÿæˆé˜¶æ®µæ˜¯ RLHF è®­ç»ƒçš„æ€§èƒ½ç“¶é¢ˆ**ï¼šåœ¨ Reinforcement Learning from Human Feedback (RLHF) æµç¨‹ä¸­ï¼Œ**generation é˜¶æ®µ**ç”±äºè‡ªå›å½’è§£ç ï¼ˆautoregressive decodingï¼‰çš„ä¸²è¡Œç‰¹æ€§ï¼Œå æ®äº†è¶…è¿‡ 68.4% çš„æ€»æ‰§è¡Œæ—¶é—´ã€‚
- **ä½å¹¶è¡Œæ€§å’Œèµ„æºåˆ©ç”¨ç‡ä½ä¸‹**ï¼šç”±äºå“åº”é•¿åº¦åˆ†å¸ƒå‘ˆç°é•¿å°¾ç°è±¡ï¼ˆlong-tailed distributionï¼‰ï¼ŒçŸ­æ ·æœ¬å…ˆå®Œæˆï¼Œå¯¼è‡´ GPU èµ„æºç©ºé—²ï¼Œç³»ç»Ÿååé‡ä¸‹é™ã€‚
- **é™æ€ speculative decoding ç­–ç•¥ä¸é€‚åº”åŠ¨æ€è´Ÿè½½**ï¼šç°æœ‰ speculative decoding æ–¹æ³•å¤šç”¨äºåœ¨çº¿æœåŠ¡åœºæ™¯ï¼Œé‡‡ç”¨å›ºå®š drafting ç­–ç•¥ï¼Œåœ¨ RLHF è¿™ç±»ç¦»çº¿æ‰¹é‡å¤„ç†ä»»åŠ¡ä¸­æ— æ³•é€‚åº”å˜åŒ–çš„å·¥ä½œè´Ÿè½½ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº† **RLHFSpec**ï¼Œé¦–ä¸ªå°† speculative decoding æˆåŠŸé›†æˆåˆ° RLHF ç³»ç»Ÿä¸­çš„æ¡†æ¶ï¼Œé€šè¿‡ä»¥ä¸‹ä¸¤ä¸ªæ ¸å¿ƒæŠ€æœ¯è§£å†³ä¸Šè¿°é—®é¢˜ï¼š

#### ï¼ˆ1ï¼‰**Workload-aware Drafting Strategy Selectionï¼ˆåŸºäºè´Ÿè½½æ„ŸçŸ¥çš„èµ·è‰ç­–ç•¥é€‰æ‹©ï¼‰**
- åŠ¨æ€è°ƒæ•´ `draft token num`ï¼ˆå³æ ‘å½¢ speculative decoding ä¸­ç”¨äºéªŒè¯çš„èŠ‚ç‚¹æ•°ï¼‰ï¼Œä»¥å¹³è¡¡ï¼š
  - **Verification Cost**ï¼ˆLLM éªŒè¯å¼€é”€ï¼‰
  - **Accepted Tokens æ•°é‡**ï¼ˆæ¨æµ‹æˆåŠŸçš„ token æ•°ï¼‰
- è®¾è®¡è½»é‡çº§é¢„æµ‹æ¨¡å‹ï¼š
  - åˆ©ç”¨ SSM çš„ **draft logit** é¢„æµ‹ token æ¥å—æ¦‚ç‡ï¼ˆacceptance probabilityï¼‰
  - æ„å»ºå›å½’æ¨¡å‹é¢„æµ‹æ‰§è¡Œæ—¶é—´ $t_{sd}(n)$ï¼Œç»“åˆ KVCache å¤§å°ï¼ˆ`N_seq`ï¼‰å’Œ draft token æ€»æ•°ï¼ˆ`N_draft`ï¼‰
- å¼•å…¥ **layer-level strategy searching + early stopping** åŠ é€Ÿæœç´¢æœ€ä¼˜ `n`

> ğŸ” **ä¼˜åŠ¿**ï¼šç›¸æ¯”å›ºå®šç­–ç•¥ï¼Œèƒ½æ ¹æ®å½“å‰æ ·æœ¬æ•°é‡åŠ¨æ€é€‰æ‹©è¿‘ä¼¼æœ€ä¼˜ç­–ç•¥ï¼Œé¿å…æ—©æœŸè¿‡åº¦éªŒè¯æˆ–åæœŸèµ„æºæµªè´¹ã€‚

#### ï¼ˆ2ï¼‰**Lightweight Sample Reallocationï¼ˆè½»é‡çº§æ ·æœ¬é‡åˆ†é…ï¼‰**
- è§‚å¯Ÿåˆ°ä¸åŒ generation instance å› æ ·æœ¬é•¿åº¦å·®å¼‚å‡ºç°ä¸¥é‡è´Ÿè½½ä¸å‡ï¼ˆload imbalanceï¼‰ã€‚
- æå‡ºåŸºäºé˜ˆå€¼çš„è´ªå©ªé‡åˆ†é…ç­–ç•¥ï¼š
  - å®šä¹‰æ¯ä¸ª instance çš„ **throughput è½¬æŠ˜ç‚¹ï¼ˆthresholdï¼‰**ï¼Œè¶…è¿‡åè¾¹é™…æ”¶ç›Šé€’å‡ã€‚
  - å°†è¶…è½½ instance çš„éƒ¨åˆ†æ ·æœ¬è¿ç§»åˆ°æœªè¾¾ threshold çš„ instanceã€‚
- è®¾è®¡ **ä¸¤é˜¶æ®µæ ·æœ¬è¿ç§»æœºåˆ¶ï¼ˆtwo-stage sample migrationï¼‰** å®ç°é›¶è¿ç§»å¼€é”€ï¼š
  1. **Stage 1**ï¼šå¹¶è¡Œä¼ è¾“å·²éªŒè¯ token çš„ KVCacheï¼ŒåŒæ—¶ç»§ç»­è®¡ç®—æ–° tokenï¼›
  2. **Stage 2**ï¼šæ¥æ”¶æ–¹æ”¶åˆ° SSM KVCache åå³å¯å¼€å§‹ draft generationï¼Œè€Œ LLM KVCache ç»§ç»­ä¼ è¾“ â†’ å®ç°è®¡ç®—ä¸é€šä¿¡é‡å ã€‚

> âš¡ï¸ **ä¼˜åŠ¿**ï¼šæ˜¾è‘—æå‡æ•´ä½“ GPU åˆ©ç”¨ç‡ï¼Œæœ€å¤§åŒ–ç³»ç»Ÿååé‡ï¼Œä¸”è¿ç§»å¼€é”€æä½ï¼ˆ<1.74% æ€»æ—¶é—´ï¼‰ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **LMSYS-Chat-1M**ï¼šåŒ…å« 100 ä¸‡çœŸå®ä¸–ç•Œå¯¹è¯ï¼Œæ¶µç›– 25 ç§ä¸»æµ LLMï¼Œè¾“å‡ºé•¿åº¦å‘ˆæ˜æ˜¾é•¿å°¾åˆ†å¸ƒï¼ˆä¸­ä½æ•° 378ï¼Œ95% åˆ†ä½ä¸º 1373ï¼‰ã€‚
- **GSM8K**ï¼šæ•°å­¦æ¨ç†æ•°æ®é›†ï¼ŒåŒæ ·å­˜åœ¨è¾ƒé•¿ä¸”å¯å˜çš„è¾“å‡ºåºåˆ—ã€‚

### ğŸ’» å®éªŒç¯å¢ƒ
- **ç¡¬ä»¶**ï¼š8Ã— NVIDIA L40S GPUsï¼ŒIntel Xeon Gold 6448Y CPUï¼ŒPCIe äº’è”
- **è½¯ä»¶æ ˆ**ï¼šUbuntu 22.04ï¼ŒCUDA 12.6ï¼ŒcuDNN v9.1.0
- **å®ç°å¹³å°**ï¼šåŸºäº Verlï¼ˆcommit: 0759489ï¼‰æ„å»º RLHFSpec

### ğŸ§ª æ¨¡å‹é…ç½®
- **ä¸»æ¨¡å‹ï¼ˆLLMï¼‰**ï¼šLlama-3.1-8B-Instruct
- **è‰ç¨¿æ¨¡å‹ï¼ˆSSMï¼‰**ï¼šEagle draft modelï¼ˆä¸“ä¸º speculative decoding è®¾è®¡çš„å°æ¨¡å‹ï¼‰

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- **Sample Throughput (samples/s)**ï¼šå•ä½æ—¶é—´å†…å®Œæˆçš„æ ·æœ¬æ•°ï¼Œä¸ºä¸»è¦è¯„ä»·æŒ‡æ ‡ã€‚
- **End-to-end RLHF Execution Speedup**ï¼šæ•´ä¸ª RLHF è¿­ä»£æµç¨‹çš„åŠ é€Ÿæ¯”ã€‚
- **Generation Stage Speedup**ï¼šä»… generation é˜¶æ®µçš„åŠ é€Ÿæ¯”ã€‚

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **OpenRLHF** | æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒï¼Œä½† generation ä½¿ç”¨æ ‡å‡† autoregressive decoding |
| **Verl** | å½“å‰æœ€å…ˆè¿›çš„ RLHF æ¡†æ¶ï¼Œæ”¯æŒçµæ´»æ•°æ®æµè°ƒåº¦ |
| **Speculative**ï¼ˆæœ¬æ–‡åŸºçº¿ï¼‰ | åœ¨ Verl ä¸Šç›´æ¥åº”ç”¨ä¼ ç»Ÿ speculative decodingï¼ˆå›ºå®š drafting ç­–ç•¥ï¼‰ |

> æ‰€æœ‰ç³»ç»Ÿæœ€å¤§ç”Ÿæˆé•¿åº¦è®¾ä¸º 2048 tokensï¼Œé˜²æ­¢ OOMã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ Generation é˜¶æ®µæ€§èƒ½ï¼ˆå›¾ 11ï¼‰
| å¯¹æ¯”é¡¹ | LMSYS åŠ é€Ÿæ¯” | GSM8K åŠ é€Ÿæ¯” |
|--------|---------------|----------------|
| vs. OpenRLHF | **2.52Ã—** | **2.65Ã—** |
| vs. Verl | **2.16Ã—** | **2.32Ã—** |
| vs. Speculative | **2.02Ã—** | **1.97Ã—** |

> âœ… è¡¨æ˜ RLHFSpec æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œå°¤å…¶æ˜¯åœ¨ generation é˜¶æ®µã€‚

### ğŸ”„ ç«¯åˆ°ç«¯ RLHF æ€§èƒ½ï¼ˆå›¾ 12ï¼‰
| å¯¹æ¯”é¡¹ | LMSYS åŠ é€Ÿæ¯” | GSM8K åŠ é€Ÿæ¯” |
|--------|---------------|----------------|
| vs. OpenRLHF | **3.01Ã—** | **2.97Ã—** |
| vs. Verl | **1.50Ã—** | **1.43Ã—** |
| vs. Speculative | **1.37Ã—** | **1.35Ã—** |

> âœ… ç¼“è§£ generation ç“¶é¢ˆåï¼Œæ•´ä½“ RLHF è®­ç»ƒé€Ÿåº¦å¤§å¹…æå‡ã€‚

### ğŸ” æ¶ˆèå®éªŒåˆ†æï¼ˆå›¾ 13ï¼‰
å¯¹ RLHFSpec å„ç»„ä»¶è¿›è¡Œé€æ­¥å åŠ æµ‹è¯•ï¼ˆå½’ä¸€åŒ–äº autoregressive baselineï¼‰ï¼š

| é…ç½® | ç›¸å¯¹æ€§èƒ½ï¼ˆNormalized Perf.ï¼‰ |
|------|-------------------------------|
| Defaultï¼ˆä»… autoregressiveï¼‰ | 1.00Ã— |
| + Speculative Decoding | 1.18Ã— |
| + Workload-aware Selection | 1.95Ã— |
| + Sample Reallocation | **2.32Ã—** |

> âœ… ç»“æœæ˜¾ç¤ºï¼š
- speculative decoding æœ¬èº«å¸¦æ¥ 18% æå‡ï¼›
- è‡ªé€‚åº” drafting ç­–ç•¥è´¡çŒ®æœ€å¤§å¢ç›Šï¼ˆä» 1.18â†’1.95ï¼‰ï¼›
- æ ·æœ¬é‡åˆ†é…è¿›ä¸€æ­¥é‡Šæ”¾é—²ç½® GPU èƒ½åŠ›ï¼ˆ1.95â†’2.32ï¼‰ã€‚

### ğŸ¯ Workload-aware Drafting ç­–ç•¥æœ‰æ•ˆæ€§ï¼ˆè¡¨ 1ï¼‰
åœ¨å¤šç§ workload ä¸‹ï¼ŒRLHFSpec æ‰€é€‰ç­–ç•¥è¾¾åˆ°â€œå…¨å±€æœ€ä¼˜â€æ€§èƒ½çš„æ¯”ä¾‹ï¼š

| æ ·æœ¬æ•° | LMSYS (%) | GSM8K (%) |
|--------|-----------|-----------|
| 8â€“64 | 96.57 ~ 99.70 | 95.53 ~ 99.90 |

> âœ… å³ä½¿åœ¨æœ€å·®æƒ…å†µï¼ˆsample count=24, GSM8Kï¼‰ä¹Ÿè¾¾åˆ°äº† **95.53% æœ€ä¼˜æ€§èƒ½**ï¼Œè¯æ˜å…¶å†³ç­–é«˜åº¦å‡†ç¡®ã€‚

### ğŸ“‰ æ ·æœ¬é‡åˆ†é…æ•ˆæœï¼ˆå›¾ 14ï¼‰
- åœ¨æŸä¸€æ—¶åˆ»è§¦å‘è¿ç§»ï¼šä» instance 1 å‘ instance 2 è¿ç§» 5 ä¸ªæ ·æœ¬ï¼›
- token throughput ä» **2,127 tokens/s â†’ 2,531 tokens/s**ï¼ˆâ†‘18.7%ï¼‰ï¼›
- éªŒè¯äº† reallocation å¯æœ‰æ•ˆç¼“è§£è´Ÿè½½å€¾æ–œã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Generation é˜¶æ®µç¡®å®æ˜¯ RLHF çš„ä¸»è¦ç“¶é¢ˆ**ï¼Œå æ€»æ—¶é—´ >68.4%ï¼Œä¼˜åŒ–è¯¥é˜¶æ®µå¯æ˜¾è‘—æå‡æ•´ä½“æ•ˆç‡ã€‚
2. **Speculative decoding å¯ç”¨äº RLHF**ï¼Œä½†å¿…é¡»é’ˆå¯¹å…¶**ç¦»çº¿ã€å›ºå®šæ ·æœ¬æ•°ã€è¿½æ±‚é«˜åå**çš„ç‰¹ç‚¹é‡æ–°è®¾è®¡ã€‚
3. **é™æ€ drafting ç­–ç•¥ä¸é€‚åˆåŠ¨æ€ workload**ï¼šåˆå§‹é˜¶æ®µåº”ä¿å®ˆï¼ˆå‡å°‘éªŒè¯å¼€é”€ï¼‰ï¼ŒåæœŸåº”æ¿€è¿›ï¼ˆæé«˜æ¥å— token æ•°ï¼‰ã€‚
4. **æ ·æœ¬åˆ†é…ä¸å‡ä¸¥é‡å½±å“ GPU åˆ©ç”¨ç‡**ï¼ŒåŠ¨æ€ reallocation æ˜¯æå‡ç³»ç»Ÿçº§ååçš„å…³é”®ã€‚
5. **ä¸¤é˜¶æ®µè¿ç§»æœºåˆ¶å‡ ä¹æ¶ˆé™¤è¿ç§»å¼€é”€**ï¼Œå®ç°äº† near-zero migration overheadã€‚

### âš ï¸ å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡ SSMï¼ˆSmall Draft Modelï¼‰**ï¼šè‹¥ SSM ä¸ LLM åˆ†å¸ƒåå·®å¤§ï¼Œacceptance rate ä¸‹é™ï¼Œspeculative æ•ˆæœå‡å¼±ã€‚
- **KVCache è¿ç§»ä»éœ€å†…å­˜é¢„ç•™æœºåˆ¶**ï¼šå¯èƒ½å› ç›®æ ‡è®¾å¤‡å†…å­˜ä¸è¶³å¯¼è‡´è¿ç§»å¤±è´¥ã€‚
- **ç›®å‰ä»…åœ¨å•æœºå¤šå¡ç¯å¢ƒä¸‹éªŒè¯**ï¼šæ‰©å±•è‡³è·¨èŠ‚ç‚¹åˆ†å¸ƒå¼ç¯å¢ƒå°šå¾…ç ”ç©¶ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ”¯æŒæ›´å¤æ‚çš„ **multi-GPU / multi-node speculative execution** æ¶æ„ï¼›
- æ¢ç´¢ **adaptive SSM selection** æˆ– **context-aware drafting tree construction**ï¼›
- å°† RLHFSpec æ€è·¯æ¨å¹¿è‡³å…¶ä»–éœ€è¦é•¿åºåˆ—ç”Ÿæˆçš„ä»»åŠ¡ï¼ˆå¦‚ CoT æ¨ç†ã€ä»£ç ç”Ÿæˆç­‰ï¼‰ï¼›
- ç»“åˆ **compression æŠ€æœ¯é™ä½ KVCache ä¼ è¾“æˆæœ¬**ã€‚

---

## âœ… æ€»ç»“
**RLHFSpec æ˜¯é¦–ä¸ªæˆåŠŸå°† speculative decoding åº”ç”¨äº RLHF è®­ç»ƒçš„ç³»ç»Ÿçº§è§£å†³æ–¹æ¡ˆ**ã€‚å®ƒé€šè¿‡ï¼š
- **workload-aware drafting strategy selection**
- **lightweight sample reallocation with two-stage migration**

è§£å†³äº† generation é˜¶æ®µçš„æ•ˆç‡ç“¶é¢ˆå’Œèµ„æºåˆ©ç”¨ä¸è¶³é—®é¢˜ï¼Œåœ¨ LMSYS å’Œ GSM8K ä¸Šå®ç°äº†æœ€é«˜ **3Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿ**ï¼Œç›¸è¾ƒ state-of-the-art æ–¹æ³•å¹³å‡æé€Ÿ **1.5Ã— ä»¥ä¸Š**ï¼Œå…·æœ‰é‡è¦çš„å·¥ç¨‹ä»·å€¼å’Œæ¨å¹¿æ½œåŠ›ã€‚

</details>

---

### 2. [SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs](https://arxiv.org/abs/2512.04746)

**Authors**: Wenhua Cheng, Weiwei Zhang, Heng Guo, Haihao Shen  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.04746v1  

#### Abstract
Extreme low-bit quantization is critical for efficiently deploying Large Language Models (LLMs), yet it often leads to severe performance degradation at 2-bits and even 4-bits (e.g., MXFP4). We present SignRoundV2, a post-training quantization framework that is highly effective even without mixed-pr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šSignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨éƒ¨ç½²æ—¶é¢ä¸´å·¨å¤§çš„å†…å­˜ã€å¸¦å®½å’Œå»¶è¿Ÿå‹åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šã€‚Post-Training Quantizationï¼ˆPTQï¼‰æ˜¯ä¸€ç§æ— éœ€é‡æ–°è®­ç»ƒå³å¯å‹ç¼©æ¨¡å‹çš„æœ‰æ•ˆæ‰‹æ®µï¼Œä½†åœ¨æä½æ¯”ç‰¹ï¼ˆå¦‚ 2-bit æˆ– 4-bitï¼‰ä¸‹ï¼Œä¼ ç»Ÿ PTQ æ–¹æ³•å¾€å¾€å¯¼è‡´ä¸¥é‡æ€§èƒ½ä¸‹é™ã€‚ç°æœ‰æ–¹æ³•å¦‚ MXFP4 åœ¨æ¿€æ´»é‡åŒ–ä¸Šè¡¨ç°å°šå¯ï¼Œä½†æƒé‡é‡åŒ–è‡³ 2-bit æ—¶ç²¾åº¦æŸå¤±æ˜¾è‘—ã€‚

æ­¤å¤–ï¼Œç»Ÿä¸€æ¯”ç‰¹åˆ†é…ï¼ˆuniform-bit quantizationï¼‰æ— æ³•é€‚åº”ä¸åŒå±‚å¯¹é‡åŒ–è¯¯å·®çš„æ•æ„Ÿåº¦å·®å¼‚ï¼Œè€Œæ··åˆç²¾åº¦ï¼ˆmixed-precisionï¼‰ç­–ç•¥åˆä¾èµ–å¤æ‚çš„æ•æ„Ÿåº¦è¯„ä¼°æœºåˆ¶ï¼ˆå¦‚ Hessian çŸ©é˜µï¼‰ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œéš¾ä»¥æ‰©å±•åˆ°ç™¾äº¿å‚æ•°è§„æ¨¡çš„ LLMã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡º **SignRoundV2**ï¼Œä¸€ç§é«˜æ•ˆçš„æä½æ¯”ç‰¹ PTQ æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **DeltaLoss æ•æ„Ÿåº¦åº¦é‡ï¼ˆSensitivity Metricï¼‰**  
   - ç»“åˆæ¢¯åº¦ä¿¡æ¯ï¼ˆgradientï¼‰ä¸é‡åŒ–å¼•èµ·çš„å‚æ•°åå·®ï¼ˆparameter deviationï¼‰ï¼Œé€šè¿‡ä¸€é˜¶æ³°å‹’å±•å¼€ç›´æ¥ä¼°è®¡æ¯å±‚é‡åŒ–å¯¹ä»»åŠ¡æŸå¤±çš„å½±å“ã€‚
   - å…¬å¼ä¸ºï¼š  
     $$
     \Delta L \approx |g_{aq} \circ (A_f - A_q)|
     $$
     å…¶ä¸­ $ g_{aq} $ æ˜¯æ¿€æ´»è¾“å‡ºå¯¹æŸå¤±çš„æ¢¯åº¦ï¼Œ$ A_f $ å’Œ $ A_q $ åˆ†åˆ«æ˜¯å…¨ç²¾åº¦ä¸é‡åŒ–åçš„æ¿€æ´»å€¼ã€‚
   - è¯¥æŒ‡æ ‡èƒ½æ›´å‡†ç¡®åæ˜ é‡åŒ–å¯¹å…¨å±€ä»»åŠ¡çš„å½±å“ï¼Œä¼˜äºä»…ä¾èµ–å±€éƒ¨ç»Ÿè®¡æˆ–äºŒé˜¶æ¢¯åº¦çš„æ–¹æ³•ã€‚

2. **åŸºäºåŠ¨æ€è§„åˆ’çš„è‡ªé€‚åº”æ¯”ç‰¹åˆ†é…ï¼ˆAdaptive Bit Allocationï¼‰**  
   - åˆ©ç”¨ DeltaLoss å¾—åˆ°å„å±‚æ•æ„Ÿåº¦å¾—åˆ†ï¼Œåœ¨ç»™å®šå¹³å‡æ¯”ç‰¹é¢„ç®—ä¸‹ï¼Œä½¿ç”¨åŠ¨æ€è§„åˆ’æ±‚è§£æœ€ä¼˜çš„é€å±‚æ¯”ç‰¹é…ç½®ã€‚
   - æ”¯æŒçµæ´»çš„æ··åˆç²¾åº¦è®¾ç½®ï¼Œæ— éœ€äººå·¥è®¾è®¡è§„åˆ™ã€‚

3. **è½»é‡çº§é¢„è°ƒä¼˜æœç´¢ï¼ˆLightweight Pre-tuning Searchï¼‰ç”¨äºé‡åŒ–å°ºåº¦åˆå§‹åŒ–**  
   - å— llama.cpp ä¸­â€œé‡è¦æ€§çŸ©é˜µâ€å¯å‘ï¼Œæå‡ºä¸€ä¸ªå¿«é€Ÿæœç´¢ç­–ç•¥æ¥ä¼˜åŒ–é‡åŒ– scale åˆå§‹åŒ–ã€‚
   - æœç´¢ç›®æ ‡å‡½æ•°ä¸ºï¼š
     $$
     \min_s \sum_i ((W_r - W_q) \circ \max(A))^2
     $$
     å³æœ€å°åŒ–åŠ æƒçš„æƒé‡é‡å»ºè¯¯å·®ã€‚
   - æ­¤åˆå§‹åŒ–æ˜¾è‘—æå‡æä½æ¯”ç‰¹ä¸‹çš„ç¨³å®šæ€§ä¸æœ€ç»ˆç²¾åº¦ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | SignRoundV2 | ä¼ ç»Ÿ PTQ / QAT æ–¹æ³• |
|------|-------------|---------------------|
| **æ— éœ€è®­ç»ƒ** | âœ… å®Œå…¨ PTQï¼Œæ— åå‘ä¼ æ’­å¾®è°ƒ | âŒ QAT éœ€è¦å¤§é‡ fine-tuning |
| **è®¡ç®—å¼€é”€ä½** | â±ï¸ ä»…éœ€å°‘é‡æ ¡å‡†æ ·æœ¬ï¼ˆ16~128ï¼‰å’Œ 2~6 GPU å°æ—¶ | âŒ QAT è€—æ—¶æ•°åè‡³ä¸Šç™¾å°æ—¶ |
| **ç²¾åº¦é«˜** | ğŸ“ˆ åœ¨ 2-bit æƒé‡ + 16-bit æ¿€æ´»ï¼ˆW2A16ï¼‰ä¸‹æ¥è¿‘ full-precision æ€§èƒ½ | âŒ å¤šæ•° PTQ åœ¨ 2-bit ä¸‹å´©æºƒ |
| **é€šç”¨æ€§å¼º** | âœ… æ”¯æŒå¤šç§æ•°æ®ç±»å‹ï¼ˆINT, MXFPï¼‰å’Œæ¨¡å‹æ¶æ„ï¼ˆLLaMA, Qwenï¼‰ | âŒ å¤šæ•°æ–¹æ³•é’ˆå¯¹ç‰¹å®šæ ¼å¼ä¼˜åŒ– |
| **è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜** | âœ… è‡ªåŠ¨æ•æ„Ÿåº¦åˆ†æ + æ¯”ç‰¹åˆ†é… | âŒ ä¾èµ–äººå·¥ç»éªŒæˆ–å¤æ‚ä»£ç†æ¨¡å‹ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **æ ¡å‡†æ•°æ®é›†ï¼ˆCalibration Datasetï¼‰**ï¼šThe Pileï¼ˆç”¨äº PTQ æ ¡å‡†ï¼‰
- **è¯„ä¼°åŸºå‡†ï¼ˆEvaluation Benchmarksï¼‰**ï¼šé‡‡ç”¨ `LM-EVAL-HARNESS` æ¡†æ¶ï¼Œæ¶µç›–ä»¥ä¸‹ä»»åŠ¡ï¼š
  - ARC-Challenge/Easy
  - BoolQ
  - HellaSwag
  - LAMBADA
  - MMLU
  - OpenBookQA
  - PIQA
  - TruthfulQA
  - WinoGrande

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **æ¨¡å‹å®¶æ—**ï¼š
  - LLaMA ç³»åˆ—ï¼šLLaMA2-7B/13B/70B, LLaMA3-8B/70B, LLaMA3.1-8B/70B-Instruct
  - Qwen ç³»åˆ—ï¼šQwen2.5-7B/3-8B/3-32B-Instruct
- **é‡åŒ–é…ç½®**ï¼š
  - æƒé‡-æ¿€æ´»æ¯”ç‰¹ç»„åˆï¼šW2A16, W4A16, MXFP4, MXFP8
  - å¯¹ç§°é‡åŒ–ï¼Œé»˜è®¤ group size=128
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - å„ä»»åŠ¡å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰
  - å¹³å‡å‡†ç¡®ç‡ï¼ˆAverage Accuracyï¼‰
  - æ¢å¤ç‡ï¼ˆRecovery Rateï¼‰ï¼šç›¸å¯¹äº full-precision æ¨¡å‹çš„æ€§èƒ½æ¢å¤æ¯”ä¾‹
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA A100 80GB GPU

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ç±»åˆ« | æ–¹æ³• |
|------|------|
| **ä¸»æµ PTQ** | GPTQ, AWQ, OmniQuant, SignRoundV1 |
| **Vector Quantization / QAT** | AQLM, QuIP#, EfficientQAT |
| **Baseline Heuristics** | Head-layer 8-bit, Tail-layer 8-bit, RTNï¼ˆRound-to-Nearestï¼‰|

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **(1) W2A16 è®¾ç½®ä¸‹çš„æ€§èƒ½ï¼ˆTable 1ï¼‰**
- åœ¨ LLaMA2-70B ä¸Šï¼š
  - **SignRoundV2 (Ours*)** è¾¾åˆ° **69.30%** å¹³å‡å‡†ç¡®ç‡ï¼ˆgroup size=64ï¼‰
  - æ˜¾è‘—ä¼˜äºï¼š
    - GPTQ: 34.38%
    - AWQ: 35.49%
    - SignRoundV1: 67.70%
    - AQLM: 70.84%ï¼ˆä½†ä¸ºé«˜æˆæœ¬æ–¹æ³•ï¼‰
- åœ¨ 2.5-bit æ··åˆç²¾åº¦ä¸‹ï¼ˆW2/W4ï¼‰ï¼Œå¹³å‡å‡†ç¡®ç‡è¾¾ **72.68%**ï¼Œæ¥è¿‘ full-precisionï¼ˆ75.28%ï¼‰

> ğŸ’¡ è¡¨æ˜ SignRoundV2 åœ¨çº¯ 2-bit æƒé‡ä¸‹å®ç°äº†æ¥è¿‘ç”Ÿäº§å¯ç”¨çº§åˆ«çš„æ€§èƒ½ã€‚

---

#### **(2) MXFP4/8 æ··åˆç²¾åº¦ç»“æœï¼ˆTable 2ï¼‰**
- åœ¨ LLaMA3.1-8B-Instruct ä¸Šï¼š
  - **4-bit MXFP4**ï¼šSignRoundV2 è¾¾åˆ° **61.34%** å‡†ç¡®ç‡ï¼ˆvs. RTN: 58.31%, SRV1: 60.72%ï¼‰
  - **5-bit æ··åˆç²¾åº¦**ï¼šè¾¾åˆ° **63.19%**ï¼Œæ¢å¤ç‡ **98.49%**
  - **6-bit**ï¼š**64.12%**ï¼Œæ¢å¤ç‡é«˜è¾¾ **99.93%**
- æ‰€æœ‰æ¨¡å‹åœ¨ 5~6 bit ä¸‹å‡å®ç° >99% æ¢å¤ç‡ï¼Œè¡¨æ˜å‡ ä¹æ— æŸå‹ç¼©æˆä¸ºå¯èƒ½ã€‚

---

#### **(3) ä¸å…¶ä»–æ··åˆæ¯”ç‰¹ç­–ç•¥å¯¹æ¯”ï¼ˆTable 3 & 4ï¼‰**
- åœ¨ 4.5-bit MXFP è®¾ç½®ä¸‹ï¼Œä»…ä½¿ç”¨ DeltaLossï¼ˆæ—  tuningï¼‰ï¼š
  - SignRoundV2ï¼ˆDLï¼‰æ¯” head/tail å±‚ä¼˜å…ˆåˆ†é… 8-bit çš„å¯å‘å¼æ–¹æ³•é«˜å‡º **1.5~3%**
- åœ¨ 3-bitï¼ˆW2G128/W4G128ï¼‰æç«¯å‹ç¼©ä¸‹ï¼š
  - Head/Tail å¯å‘å¼æ–¹æ³•æ€§èƒ½æ€¥å‰§ä¸‹é™ï¼ˆ<40%ï¼‰
  - SignRoundV2 ä»ä¿æŒ **61.48%**ï¼ˆLlama3.1-8B-Iï¼‰ï¼Œæ˜¾ç¤ºå…¶é²æ£’æ€§ä¼˜åŠ¿

---

#### **(4) æ¶ˆèå®éªŒï¼ˆAblation Study, Table 5ï¼‰**
- åœ¨ Qwen3-8B å’Œ Llama3.1-8B-Instruct ä¸ŠéªŒè¯é¢„è°ƒä¼˜åˆå§‹åŒ–æ•ˆæœï¼š
  - **å¯ç”¨åˆå§‹åŒ–å**ï¼Œæ‰€æœ‰ä»»åŠ¡å‡†ç¡®ç‡å‡æœ‰æå‡
  - ä¾‹å¦‚ Qwen3-8B ä¸Šå¹³å‡å‡†ç¡®ç‡ä» **63.85% â†’ 66.22%**
  - è¯´æ˜è‰¯å¥½çš„ scale åˆå§‹åŒ–å¯¹æä½æ¯”ç‰¹ç¨³å®šæ€§è‡³å…³é‡è¦

---

#### **(5) é‡åŒ–è€—æ—¶å¯¹æ¯”ï¼ˆTable 6ï¼‰**
| æ–¹æ³• | GPU å°æ—¶ï¼ˆLlama2-70Bï¼‰ |
|------|------------------------|
| SignRoundV1 | 2.2 |
| **SignRoundV2 (Ours)** | **2.5** |
| **SignRoundV2 (Ours*)** | **6.0** |
| EfficientQAT | 41 |
| QuIP# | 270 |
| AQLM | 336 |

> âš¡ SignRoundV2 åœ¨ä¿æŒæä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œè¾¾åˆ°äº†æ¥è¿‘ç”šè‡³è¶…è¶Šé«˜æˆæœ¬ QAT æ–¹æ³•çš„æ€§èƒ½ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **æä½æ¯”ç‰¹ PTQ å¯è¡Œä¸”é«˜æ•ˆ**ï¼š  
   SignRoundV2 åœ¨ **2-bit æƒé‡**ä¸‹ä»èƒ½ç»´æŒæ¥è¿‘ full-precision çš„æ€§èƒ½ï¼Œå°¤å…¶åœ¨å¤§æ¨¡å‹ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚
   
2. **æ•æ„Ÿåº¦å»ºæ¨¡åº”ç»“åˆæ¢¯åº¦ä¸æ‰°åŠ¨**ï¼š  
   DeltaLoss é€šè¿‡ä¸€é˜¶æ³°å‹’è¿‘ä¼¼èåˆæ¢¯åº¦ä¸é‡åŒ–åå·®ï¼Œæ¯” Hessian æˆ–çº¯ç»Ÿè®¡æ–¹æ³•æ›´èƒ½çœŸå®åæ˜ å±‚é—´æ•æ„Ÿæ€§ã€‚

3. **åˆå§‹åŒ–å†³å®šæä½æ¯”ç‰¹æˆè´¥**ï¼š  
   è½»é‡çº§ scale åˆå§‹åŒ–æœç´¢è™½ç®€å•ï¼Œå´æå¤§æå‡äº†æ”¶æ•›ç¨³å®šæ€§å’Œæœ€ç»ˆç²¾åº¦ï¼Œæ˜¯æˆåŠŸçš„å…³é”®ä¹‹ä¸€ã€‚

4. **æ— éœ€ QAT å³å¯è¾¾æ ‡ç”Ÿäº§çº§æ€§èƒ½**ï¼š  
   åœ¨ 4â€“5 bit èŒƒå›´å†…ï¼ŒSignRoundV2 å®ç° <1% æ€§èƒ½å·®è·ï¼Œæ»¡è¶³å®é™…éƒ¨ç½²éœ€æ±‚ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **å°æ¨¡å‹åœ¨çº¯ 2-bit ä¸‹ä»æœ‰æ˜æ˜¾å·®è·**ï¼š  
   å¦‚ Llama2-7B åœ¨ W2A16 ä¸‹ä»…è¾¾ ~58%ï¼Œè·ç¦» full-precisionï¼ˆ64.66%ï¼‰ä»æœ‰çº¦ 6% å·®è·ã€‚
   
2. **æ¯”ç‰¹é…ç½®å›ºå®šäºè°ƒä¼˜å‰**ï¼š  
   å½“å‰æ¡†æ¶æœªè€ƒè™‘ tuning è¿‡ç¨‹ä¸­è¯¯å·®è¡¥å¿èƒ½åŠ›ï¼Œæœªæ¥å¯å¼•å…¥è”åˆä¼˜åŒ–ã€‚

3. **ä¾èµ–æ¢¯åº¦è®¡ç®—**ï¼š  
   ä¸é€‚ç”¨äºä¸æ”¯æŒè‡ªåŠ¨å¾®åˆ†çš„æ¨ç†æ¡†æ¶ï¼ˆå¦‚ ONNX Runtimeï¼‰ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢ **åŠ¨æ€æ¯”ç‰¹è°ƒæ•´**ï¼šåœ¨ tuning è¿‡ç¨‹ä¸­æ ¹æ®è¯¯å·®åé¦ˆåŠ¨æ€ä¿®æ­£æ¯”ç‰¹åˆ†é…ã€‚
- æ‰©å±•è‡³ **MoE æ¨¡å‹**ï¼šç»“åˆ MoE æ¶æ„ä¸­çš„ä¸“å®¶ç¨€ç–æ€§è¿›è¡Œæ›´ç»†ç²’åº¦çš„æ··åˆç²¾åº¦è®¾è®¡ã€‚
- æ”¯æŒæ›´å¤š **ç¡¬ä»¶å‹å¥½æ ¼å¼**ï¼šå¦‚ FP4, NF4, INT1 ç­‰ï¼Œå¹¶é€‚é…ä¸“ç”¨åŠ é€Ÿå™¨ã€‚
- å¼€å‘ **å…æ¢¯åº¦æ›¿ä»£æ–¹æ¡ˆ**ï¼šä½¿æ–¹æ³•å¯åœ¨çº¯æ¨ç†ç¯å¢ƒä¸­éƒ¨ç½²ã€‚

---

> ğŸ”— **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/intel/auto-round](https://github.com/intel/auto-round)

</details>

---

### 3. [Arbitrage: Efficient Reasoning via Advantage-Aware Speculation](https://arxiv.org/abs/2512.05033)

**Authors**: Monishwaran Maheswaran, Rishabh Tiwari, Yuezhou Hu, Kerem Dilmen, Coleman Hooper, Haocheng Xi, Nicholas Lee, Mehrdad Farajtabar, Michael W. Mahoney, Kurt Keutzer, Amir Gholami  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.05033v1  

#### Abstract
Modern Large Language Models achieve impressive reasoning capabilities with long Chain of Thoughts, but they incur substantial computational cost during inference, and this motivates techniques to improve the performance-cost ratio. Among these techniques, Speculative Decoding accelerates inference ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**ARBITRAGE: Efficient Reasoning via Advantage-Aware Speculation**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•°å­¦æ¨ç†ç­‰å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶åŸºäº **Chain-of-Thought (CoT)** çš„é•¿åºåˆ—æ¨ç†è¿‡ç¨‹å¯¼è‡´æé«˜çš„æ¨ç†å»¶è¿Ÿã€‚ä¼ ç»Ÿçš„ **Speculative Decoding (SD)** è™½èƒ½é€šè¿‡å¹¶è¡ŒéªŒè¯åŠ é€Ÿæ¨ç†ï¼Œä½†åœ¨æ¨ç†ä»»åŠ¡ä¸­å­˜åœ¨ä¸¥é‡æ•ˆç‡ç“¶é¢ˆï¼š

- **Token-level SD** å› è¯­ä¹‰ç­‰ä»·ä½† token ä¸åŒ¹é…è€Œé¢‘ç¹æ‹’ç»æœ‰æ•ˆæ­¥éª¤ï¼Œé€ æˆâ€œ**è¯­ä¹‰æµªè´¹**â€ã€‚
- ç°æœ‰çš„ **Step-level SD**ï¼ˆå¦‚ RSDï¼‰è™½ä»¥æ•´ä¸ªæ¨ç†æ­¥éª¤ä¸ºå•ä½è¿›è¡ŒéªŒè¯ï¼Œä½†ä»é‡‡ç”¨**ç»å¯¹è´¨é‡é˜ˆå€¼**å†³å®šæ˜¯å¦æ¥å— draft æ­¥éª¤ï¼Œå¯¼è‡´ï¼š
  - åœ¨ draft å·²è¶³å¤Ÿå¥½çš„æƒ…å†µä¸‹ä»è°ƒç”¨æ˜‚è´µçš„ target æ¨¡å‹ï¼›
  - å¤§é‡ target å†ç”Ÿæˆå¹¶æœªæå‡è¾“å‡ºè´¨é‡ï¼Œé€ æˆâ€œ**è®¡ç®—æµªè´¹**â€ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **ARBITRAGE** â€”â€”ä¸€ç§**ä¼˜åŠ¿æ„ŸçŸ¥çš„æ­¥çº§æ¨æµ‹ç”Ÿæˆæ¡†æ¶**ï¼ˆAdvantage-Aware Step-Level Speculative Decodingï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **ä¸åº”ä»…çœ‹ draft æ˜¯å¦â€œå¤Ÿå¥½â€ï¼Œè€Œåº”åˆ¤æ–­ target æ˜¯å¦â€œæ›´å¥½â€**ã€‚

#### ä¸»è¦ç»„ä»¶ï¼š
1. **ARBITRAGE ORACLE**ï¼ˆç†æƒ³è·¯ç”±ç­–ç•¥ï¼‰
   - å®šä¹‰æ¯ä¸€æ­¥çš„â€œ**Step-level Advantage**â€ï¼š  
     $$
     \Delta = s_t - s_d
     $$
     å…¶ä¸­ $s_t$ å’Œ $s_d$ åˆ†åˆ«æ˜¯ target å’Œ draft ç”Ÿæˆæ­¥éª¤çš„ PRMï¼ˆProcess Reward Modelï¼‰å¾—åˆ†ã€‚
   - è‹¥ $\Delta > 0$ï¼Œåˆ™é€‰æ‹© target æ­¥éª¤ï¼›å¦åˆ™ä¿ç•™ draftã€‚
   - è¿™æ˜¯ä¸€ä¸ª**å±€éƒ¨æœ€ä¼˜çš„è´ªå¿ƒç­–ç•¥**ï¼Œç†è®ºä¸Šå¯å®ç°æœ€å¤§è´¨é‡å¢ç›Šä¸‹çš„æœ€å° target è°ƒç”¨ã€‚

2. **ARBITRAGE ROUTER**ï¼ˆå®ç”¨è·¯ç”±æ¨¡å‹ï¼‰
   - ä¸€ä¸ªè½»é‡çº§ã€å¯è®­ç»ƒçš„æ¨¡å‹ï¼Œè¾“å…¥ä¸ºå½“å‰ä¸Šä¸‹æ–‡å’Œ draft ç”Ÿæˆçš„æ­¥éª¤ $(x, z_d)$ï¼Œè¾“å‡ºä¸€ä¸ªåˆ†æ•° $y$ï¼Œè¡¨ç¤º target ç›¸å¯¹äº draft çš„é¢„æœŸä¼˜åŠ¿æ¦‚ç‡ã€‚
   - åœ¨æ¨ç†æ—¶ï¼Œè‹¥ $y \leq t$ï¼ˆé˜ˆå€¼ï¼‰ï¼Œåˆ™æ¥å— draftï¼›å¦åˆ™è°ƒç”¨ target é‡æ–°ç”Ÿæˆã€‚
   - è¯¥æ¨¡å‹é€šè¿‡ç¦»çº¿å­¦ä¹  ORACLE çš„å†³ç­–è¡Œä¸ºæ¥é€¼è¿‘å…¶æ€§èƒ½ï¼Œé¿å…å®æ—¶è¿è¡Œ target æ¨¡å‹ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | RSDï¼ˆBaselineï¼‰ | ARBITRAGEï¼ˆæœ¬æ–‡ï¼‰ |
|------|------------------|--------------------|
| å†³ç­–ä¾æ® | draft çš„ç»å¯¹ PRM å¾—åˆ†æ˜¯å¦é«˜äºé˜ˆå€¼ | target ç›¸å¯¹äº draft çš„**é¢„æœŸä¼˜åŠ¿** |
| è·¯ç”±é€»è¾‘ | ç»å¯¹é˜ˆå€¼ï¼ˆAdvantage-Blindï¼‰ | ç›¸å¯¹ä¼˜åŠ¿ï¼ˆAdvantage-Awareï¼‰ |
| è®¡ç®—æ•ˆç‡ | é«˜é¢‘è°ƒç”¨ targetï¼Œæ˜“äº§ç”Ÿå†—ä½™å†ç”Ÿ | åªåœ¨ target æ˜¾è‘—æ›´ä¼˜æ—¶æ‰è°ƒç”¨ |
| æ€§èƒ½è¡¨ç° | æ¥å—ç‡é«˜ä½†è´¨é‡å¢ç›Šä½ | åœ¨ç›¸åŒè®¡ç®—é¢„ç®—ä¸‹è·å¾—æ›´é«˜å‡†ç¡®ç‡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **MATH500**ï¼šæ ‡å‡†æ•°å­¦æ¨ç†åŸºå‡†ï¼ŒåŒ…å« 500 é“é«˜ä¸­è‡³ç«èµ›çº§åˆ«é¢˜ç›®ã€‚
- **OlympiadBench**ï¼šæ›´å…·æŒ‘æˆ˜æ€§çš„å¤šæ¨¡æ€ç§‘å­¦å¥¥èµ›é¢˜åŸºå‡†ï¼Œæ¶µç›–å›½é™…å­¦ç§‘å¥¥æ—åŒ¹å…‹æ°´å¹³é—®é¢˜ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹é…ç½®**ï¼ˆä¸¤ç»„å…¸å‹åœºæ™¯ï¼‰ï¼š
  1. **åŒå®¶æ—å¤§å°å·®å¼‚**ï¼šå¦‚ LLaMA3 (1B/8B)ï¼Œå° draft + å¤§ targetã€‚
  2. **é‡åŒ– draft**ï¼šå¦‚ Qwen2.5-Math (3bit-7B/7B)ï¼Œå°† target é‡åŒ–åä½œä¸º draftã€‚
- **PRM æ¨¡å‹**ï¼šé»˜è®¤ä½¿ç”¨ **Skywork-o1-Open-PRM (1.5B)** å¯¹æ¨ç†æ­¥éª¤æ‰“åˆ†ã€‚
- **Router è®­ç»ƒ**ï¼š
  - åŸºäº NuminaMath-CoT æ•°æ®é›†é‡‡æ · 30K é—®é¢˜æ„å»ºè®­ç»ƒé›†ã€‚
  - ä½¿ç”¨ ORACLE æ ‡æ³¨æ¯ä¸ªæ­¥éª¤æ˜¯å¦åº”å‡çº§ï¼ˆå³ $\Delta > 0$ï¼‰ã€‚
  - å¼•å…¥å†å²æ¨¡å‹è°ƒç”¨æ ‡æ³¨ï¼ˆå¦‚ `[Model 0]`, `[Model 1]`ï¼‰å¢å¼ºä¸Šä¸‹æ–‡æ„ŸçŸ¥ã€‚
  - é‡‡ç”¨ class-balanced downsampling ç¼“è§£ç±»åˆ«ä¸å¹³è¡¡ï¼ˆ$y=0$: accept, $y=1$: escalateï¼‰ã€‚

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Accuracy** | æœ€ç»ˆç­”æ¡ˆæ­£ç¡®ç‡ |
| **Acceptance Rate** | draft æ­¥éª¤è¢«æ¥å—çš„æ¯”ä¾‹ï¼ˆåæ˜ è®¡ç®—å¼€é”€ï¼‰ |
| **End-to-End Latency** | æ¯ä¸ªé—®é¢˜å¹³å‡å¢™é’Ÿæ—¶é—´ï¼ˆwall-clock timeï¼‰ |
| **Spearman Rank Correlation ($\rho$)** | Router é¢„æµ‹ä¼˜åŠ¿ä¸çœŸå® $\Delta$ çš„æ’åºä¸€è‡´æ€§ï¼Œç”¨äºè¡¡é‡è·¯ç”±è´¨é‡ |
| **Speedup** | ç›¸åŒå‡†ç¡®ç‡ä¸‹ï¼Œç›¸æ¯”åŸºçº¿çš„å»¶è¿Ÿé™ä½å€æ•° |

### ğŸ†š åŸºçº¿æ–¹æ³•
- **RSD (Reward-guided Speculative Decoding)**ï¼šå½“å‰æœ€å…ˆè¿›çš„ step-level SD æ–¹æ³•ï¼ŒåŸºäºå›ºå®š PRM é˜ˆå€¼å†³å®šæ˜¯å¦æ¥å— draftã€‚
- **Draft-only / Target-only**ï¼šä½œä¸ºæ€§èƒ½ä¸Šä¸‹ç•Œå‚è€ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### âœ… å‡†ç¡®ç‡ vs æ¥å—ç‡ï¼ˆå›¾4ï¼‰
- åœ¨æ‰€æœ‰é…ç½®ä¸‹ï¼ˆLLaMA3 ä¸ Qwen2.5-Mathï¼Œä¸åŒ draft/target ç»„åˆï¼‰ï¼Œ**ARBITRAGE ROUTER æ›²çº¿å§‹ç»ˆé«˜äº RSD**ã€‚
- åœ¨ä½æ¥å—ç‡åŒºåŸŸï¼ˆå³æ›´å¤š target è°ƒç”¨ï¼‰ï¼ŒARBITRAGE æ›´å¿«æ¥è¿‘ target-only æ€§èƒ½ï¼Œè¯´æ˜å…¶èƒ½æ›´ç²¾å‡†è¯†åˆ«éœ€å‡çº§çš„å…³é”®æ­¥éª¤ã€‚
- åœ¨é«˜æ¥å—ç‡åŒºåŸŸï¼ŒARBITRAGE ä»ä¿æŒæ˜¾è‘—ä¼˜åŠ¿ï¼Œè¡¨æ˜å…¶æœ‰æ•ˆé¿å…äº†æ— æ„ä¹‰çš„ target è°ƒç”¨ã€‚

#### â±ï¸ ç«¯åˆ°ç«¯å»¶è¿Ÿåˆ†æï¼ˆå›¾5ï¼‰
- **MATH500ï¼ˆé‡åŒ– draftï¼‰**ï¼šARBITRAGE å®ç° **1.62Ã— æ›´ä½å»¶è¿Ÿ**ï¼ˆç›¸åŒå‡†ç¡®ç‡ï¼‰ã€‚
- **OlympiadBenchï¼ˆå° draftï¼‰**ï¼šè¾¾åˆ° **1.97Ã— åŠ é€Ÿ**ã€‚
- å¹³å‡è€Œè¨€ï¼Œåœ¨åŒ¹é…å‡†ç¡®ç‡ç›®æ ‡ä¸‹ï¼Œ**ARBITRAGE å°†æ¨ç†å»¶è¿Ÿé™ä½çº¦ 2Ã—**ã€‚

#### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆè¡¨1â€“3ï¼‰

| å®éªŒç»´åº¦ | å‘ç° |
|---------|------|
| **Label Granularity**ï¼ˆåˆ†ç±»ç²’åº¦ï¼‰ | äºŒåˆ†ç±»ï¼ˆaccept vs escalateï¼‰æ•ˆæœæœ€ä½³ï¼ˆSpearman $\rho=0.1508$ï¼‰ï¼Œç»†ç²’åº¦åˆ’åˆ†åè€Œé™ä½æ€§èƒ½ |
| **Classification vs Ordinal Regression** | åˆ†ç±»æ¨¡å‹ä¼˜äºå›å½’æ¨¡å‹ï¼Œæ›´æ˜“äºæ ¡å‡†å’Œéƒ¨ç½² |
| **Step Annotation**ï¼ˆå†å²è°ƒç”¨æ ‡è®°ï¼‰ | æ·»åŠ  `[Model 0/1]` æ³¨é‡Šæ˜¾è‘—æå‡ label-1 å‡†ç¡®ç‡å’Œ $\rho$ï¼Œè¯æ˜å†å²ä¿¡æ¯æœ‰åŠ©äºåˆ¤æ–­éš¾åº¦ |
| **Data Downsampling** | å¹³è¡¡é‡‡æ ·åï¼Œlabel-1 å‡†ç¡®ç‡ä» 49.62% æå‡è‡³ 64.80%ï¼Œç¼“è§£äº† over-acceptance å€¾å‘ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ç°æœ‰ step-level SD å­˜åœ¨ä¸¥é‡è®¡ç®—æµªè´¹**ï¼š
   - å½“ deferral rate è¾¾ 70% æ—¶ï¼Œ**çº¦ 40% çš„ target å†ç”Ÿæœªå¸¦æ¥ä»»ä½•è´¨é‡æå‡**ï¼ˆå›¾2ï¼‰ã€‚
   - åŸå› åœ¨äº draft å’Œ target å¯èƒ½åœ¨éš¾ä¾‹ä¸ŠçŠ¯ç›¸åŒé”™è¯¯ï¼Œæˆ– draft å·²è¶³å¤Ÿå¥½å´è¢«è¯¯åˆ¤ä¸ºå·®ã€‚

2. **ç›¸å¯¹ä¼˜åŠ¿ï¼ˆAdvantageï¼‰æ˜¯æ›´ä¼˜çš„è·¯ç”±ä¿¡å·**ï¼š
   - ARBITRAGE é€šè¿‡é¢„æµ‹ $\mathbb{E}[\Delta]$ æ¥å†³å®šæ˜¯å¦å‡çº§ï¼Œå®ç°äº†æ¥è¿‘ ORACLE çš„å¸•ç´¯æ‰˜å‰æ²¿ï¼ˆPareto frontierï¼‰ã€‚
   - å…¶è·¯ç”±å†³ç­–å…·æœ‰æ›´å¼ºçš„æ³›åŒ–æ€§å’Œé²æ£’æ€§ï¼Œé€‚ç”¨äºä¸åŒæ•°æ®åˆ†å¸ƒå’Œæ¨¡å‹è§„æ¨¡ã€‚

3. **è½»é‡çº§ ROUTER å¯é«˜æ•ˆé€¼è¿‘ ORACLE è¡Œä¸º**ï¼š
   - ä»…éœ€ä¸€æ¬¡å‰å‘ä¼ æ’­å³å¯å®Œæˆè·¯ç”±å†³ç­–ï¼Œå¼•å…¥æå°å¼€é”€ã€‚
   - Spearman ç›¸å…³ç³»æ•°å¯ä½œä¸ºå¯é çš„ä»£ç†æŒ‡æ ‡æŒ‡å¯¼è®­ç»ƒã€‚

### âš ï¸ å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡ PRM**ï¼šè‹¥ PRM æ— æ³•å‡†ç¡®è¯„ä¼°ä¸­é—´æ­¥éª¤è´¨é‡ï¼Œåˆ™ ROUTER å­¦ä¹ ä¸åˆ°æœ‰æ•ˆçš„ä¼˜åŠ¿ä¿¡å·ã€‚
- **é™æ€è·¯ç”±ç­–ç•¥**ï¼šå½“å‰ ROUTER æ˜¯é™æ€æ¨¡å‹ï¼Œæœªè€ƒè™‘åŠ¨æ€è°ƒæ•´é˜ˆå€¼æˆ–é•¿æœŸè§„åˆ’ã€‚
- **ORACLE å‡è®¾ç‹¬ç«‹æ€§**ï¼šç†è®ºæœ€ä¼˜æ€§å‡è®¾å„æ­¥ä¹‹é—´æ— ä¾èµ–ï¼Œå®é™…æ¨ç†é“¾å¯èƒ½å­˜åœ¨è¯¯å·®ä¼ æ’­ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ„å»º**åŠ¨æ€è‡ªé€‚åº”é˜ˆå€¼æœºåˆ¶**ï¼Œæ ¹æ®é—®é¢˜éš¾åº¦åœ¨çº¿è°ƒæ•´ $t$ã€‚
- æ¢ç´¢**å¤šæ­¥è”åˆä¼˜åŠ¿é¢„æµ‹**ï¼Œè€Œéé€æ­¥æ­¥ç‹¬ç«‹å†³ç­–ã€‚
- å°† ARBITRAGE æ‰©å±•è‡³å…¶ä»–ç”Ÿæˆä»»åŠ¡ï¼Œå¦‚ä»£ç ç”Ÿæˆã€å¯¹è¯ç³»ç»Ÿç­‰ã€‚
- ç»“åˆå¼ºåŒ–å­¦ä¹ è¿›ä¸€æ­¥ä¼˜åŒ– ROUTER çš„é•¿æœŸæ”¶ç›Šã€‚

---

## æ€»ç»“

> **ARBITRAGE é€šè¿‡å¼•å…¥â€œä¼˜åŠ¿æ„ŸçŸ¥â€çš„è·¯ç”±æœºåˆ¶ï¼Œä»æ ¹æœ¬ä¸Šæ”¹å˜äº† speculative decoding çš„å†³ç­–èŒƒå¼â€”â€”ä»â€œdraft æ˜¯å¦åˆæ ¼â€è½¬å‘â€œtarget æ˜¯å¦æ›´ä¼˜â€ã€‚è¿™ä¸€è½¬å˜æ˜¾è‘—å‡å°‘äº†æ— æ•ˆçš„ target è°ƒç”¨ï¼Œåœ¨å¤šä¸ªæ•°å­¦æ¨ç†åŸºå‡†ä¸Šå®ç°äº†é«˜è¾¾ ~2Ã— çš„æ¨ç†åŠ é€Ÿï¼ŒåŒæ—¶ä¿æŒç”šè‡³æå‡äº†æœ€ç»ˆå‡†ç¡®ç‡ï¼Œä¸ºé«˜æ•ˆ LLM æ¨ç†æä¾›äº†æ–°çš„èŒƒå¼ã€‚**

</details>

---

### 4. [Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning](https://arxiv.org/abs/2512.05105)

**Authors**: Purbesh Mitra, Sennur Ulukus  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.05105v1  

#### Abstract
Long context reasoning in large language models (LLMs) has demonstrated enhancement of their cognitive capabilities via chain-of-thought (CoT) inference. Training such models is usually done via reinforcement learning with verifiable rewards (RLVR) in reasoning based problems, like math and programm...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿ä¸Šä¸‹æ–‡æ¨ç†ä»»åŠ¡ä¸­å¹¿æ³›ä¾èµ–**å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ï¼ˆReinforcement Learning with Verifiable Rewards, RLVRï¼‰**ï¼Œå¦‚ GRPO ç­‰ç®—æ³•ã€‚ç„¶è€Œï¼Œè¿™ç±»æ–¹æ³•å­˜åœ¨ä»¥ä¸‹ç“¶é¢ˆï¼š
- **ç¨€ç–å¥–åŠ±ï¼ˆSparse Rewardï¼‰**ï¼šä»…å¯¹æœ€ç»ˆç­”æ¡ˆè¿›è¡Œæ‰“åˆ†ï¼Œæ— æ³•ç›‘ç£ä¸­é—´æ¨ç†è¿‡ç¨‹ã€‚
- **æ ·æœ¬æ•ˆç‡ä½**ï¼šéœ€è¦å¤§é‡ rollout æ‰èƒ½è·å¾—æœ‰æ•ˆè®­ç»ƒä¿¡å·ã€‚
- **æ˜“å¯¼è‡´â€œå¥–åŠ±æ¬ºéª—â€ï¼ˆReward Hackingï¼‰**ï¼šæ¨¡å‹å¯èƒ½é€šè¿‡é”™è¯¯é€»è¾‘å¾—åˆ°æ­£ç¡®ç­”æ¡ˆè€Œè¢«é¼“åŠ±ã€‚
- **æ¨ç†èƒ½åŠ›æœªçœŸæ­£æå‡**ï¼šç ”ç©¶è¡¨æ˜ RLVR æ›´å¤šæ˜¯æ”¾å¤§å·²æœ‰èƒ½åŠ›ï¼ˆpass@k â†’ pass@1ï¼‰ï¼Œè€Œéå¢å¼ºæ ¹æœ¬æ¨ç†èƒ½åŠ›ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šSemantic Soft Bootstrapping (SSB)
ä½œè€…æå‡ºä¸€ç§**æ— éœ€å¼ºåŒ–å­¦ä¹ çš„è‡ªè’¸é¦æ¡†æ¶â€”â€”è¯­ä¹‰è½¯å¼•å¯¼ï¼ˆSemantic Soft Bootstrapping, SSBï¼‰**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³å¦‚ä¸‹ï¼š
- åŒä¸€ä¸ªåŸºç¡€æ¨¡å‹åŒæ—¶æ‰®æ¼” **æ•™å¸ˆï¼ˆteacherï¼‰** å’Œ **å­¦ç”Ÿï¼ˆstudentï¼‰** è§’è‰²ã€‚
- æ•™å¸ˆåœ¨åŒ…å«â€œæ­£ç¡® + æœ€å¸¸è§é”™è¯¯â€å“åº”çš„æç¤ºä¸‹ç”Ÿæˆé²æ£’ã€è¯¦ç»†çš„è§£é‡Šï¼›å­¦ç”Ÿåˆ™åªçœ‹åˆ°åŸå§‹é—®é¢˜ï¼Œå¹¶è¯•å›¾æ¨¡ä»¿æ•™å¸ˆè¾“å‡ºçš„ç­”æ¡ˆéƒ¨åˆ†çš„ **token-level logits åˆ†å¸ƒ**ã€‚
- åˆ©ç”¨ KL æ•£åº¦æŸå¤±å®ç° **logit-level çŸ¥è¯†è’¸é¦**ï¼Œä¸ä½¿ç”¨ä»»ä½•ç¡¬æ ‡ç­¾æˆ–å¥–åŠ±å‡½æ•°ã€‚

### ğŸ” åˆ›æ–°ç‚¹
1. **é¦–æ¬¡å°† in-context å­¦ä¹ ä¸è‡ªè’¸é¦ç»“åˆç”¨äºæ¨ç†å¢å¼º**ï¼Œåˆ©ç”¨æ¨¡å‹è‡ªèº«ç”Ÿæˆçš„æ­£è´Ÿæ ·æœ¬æ¥æ„å»ºæ•™å­¦ä¿¡å·ã€‚
2. å¼•å…¥â€œè¯­ä¹‰è§†è§’åˆ†ç¦»â€æœºåˆ¶ï¼šæ•™å¸ˆæ¥æ”¶å¯Œå«è¯­ä¹‰çº¿ç´¢çš„ä¸Šä¸‹æ–‡ï¼ˆå«æ­£è¯¯ç¤ºä¾‹ï¼‰ï¼Œå­¦ç”Ÿä»…è§åŸå§‹é—®é¢˜ï¼Œä»è€Œå­¦ä¼šâ€œæ— æç¤ºæ±‚è§£â€ã€‚
3. å…¨ç¨‹æ— éœ€ RLã€å¥–åŠ±æ¨¡å‹æˆ–ç­–ç•¥æ¢¯åº¦ï¼Œé¿å… reward hackingã€‚
4. ä½¿ç”¨ **logit è’¸é¦è€Œéæ–‡æœ¬è’¸é¦**ï¼Œä¿ç•™æ¦‚ç‡åˆ†å¸ƒä¿¡æ¯ï¼Œå‡å°‘ä¿¡æ¯æŸå¤±ï¼Œä¸”æ›´ç¨³å®šã€‚

### âš–ï¸ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ˜¯å¦éœ€ RL | æ˜¯å¦éœ€äººå·¥æ ‡æ³¨ | æ˜¯å¦é˜² Reward Hacking | æ ·æœ¬æ•ˆç‡ |
|------|----------|----------------|------------------------|-----------|
| RLVR (e.g., GRPO) | æ˜¯ | å¦ | å¦ | ä½ |
| STaR / BOLT | å¦ | éƒ¨åˆ†ï¼ˆç­›é€‰ï¼‰ | ä¸­ç­‰ | ä¸­ |
| SSBï¼ˆæœ¬æ–‡ï¼‰ | âŒ å¦ | âŒ å®Œå…¨è‡ªåŠ¨ | âœ… æ˜¯ | âœ… é«˜ï¼ˆä»… 256 æ ·æœ¬ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **è®­ç»ƒæ•°æ®æ¥æº**ï¼š`GSM8K` æ•°æ®é›†ä¸­çš„é—®é¢˜ä¸æ ‡å‡†ç­”æ¡ˆï¼ˆå…±å¤„ç† 950 ä¸ªé—®é¢˜ï¼Œæœ€ç»ˆæ„å»ºå‡º **256 ä¸ªé«˜è´¨é‡ teacher-student å¯¹**ï¼‰ã€‚
- **æµ‹è¯•åŸºå‡†**ï¼š
  - `MATH500`ï¼šé«˜ä¸­æ•°å­¦éš¾é¢˜é›†åˆ
  - `AIME2024`ï¼šç¾å›½æ•°å­¦é‚€è¯·èµ›çº§åˆ«é¢˜ç›®

> æ³¨ï¼šè®­ç»ƒæ—¶ä¸ä½¿ç”¨ GSM8K è‡ªå¸¦çš„æ ‡å‡†è§£ç­”æ–‡æœ¬ï¼Œä»…ç”¨é—®é¢˜å’Œæœ€ç»ˆç­”æ¡ˆæ¥è‡ªåŠ¨ç”Ÿæˆ rolloutsã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š`Qwen2.5-3B-Instruct`
- **å¾®è°ƒæ–¹å¼**ï¼šParameter-Efficient Fine-Tuning (PEFT)ï¼Œé‡‡ç”¨ **LoRAï¼ˆrank=32ï¼‰**ï¼Œæ›´æ–°çº¦ 2% å‚æ•°
- **è®­ç»ƒé…ç½®**ï¼š
  - Batch size: 4
  - Epochs: 3
  - Total steps: 192
  - å•å¡ A100 40GB
- **æ¸©åº¦è®¾ç½®**ï¼š
  - Rollout æ¸©åº¦ $ T_{roll} = 0.7 $
  - è’¸é¦æ¸©åº¦ $ T_{KD} > 1 $

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
- **Pass@1 Accuracy**ï¼šæ¨¡å‹ç¬¬ä¸€æ¬¡ç”Ÿæˆå³æ­£ç¡®çš„æ¯”ä¾‹
  $$
  \text{Pass@1} = \frac{\#\text{correct answers}}{\#\text{total questions}}
  $$
  ä»¥ `\boxed{}` å†…å®¹ä¸ºåˆ¤æ–­ä¾æ®ã€‚

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Base Model**ï¼šæœªç»åè®­ç»ƒçš„ `Qwen2.5-3B-Instruct`
- **GRPO**ï¼šå½“å‰ä¸»æµçš„ RLVR æ–¹æ³•ï¼Œåœ¨æœ¬å®éªŒä¸­ä½¿ç”¨ **2000 ä¸ª GSM8K æ ·æœ¬**è¿›è¡Œè®­ç»ƒä½œä¸ºå¼ºåŸºçº¿

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š æ€§èƒ½å¯¹æ¯”ï¼ˆPass@1 å‡†ç¡®ç‡ï¼‰

| æ¨¡å‹ | MATH500 | AIME2024 |
|------|---------|----------|
| Base Model | 37.6% | 0.0% |
| GRPOï¼ˆ2000 samplesï¼‰ | 44.8% | 3.33% |
| **SSBï¼ˆ256 samplesï¼‰** | **55.4%** | **13.33%** |

### ğŸ“ˆ å…³é”®ç»“è®º
- SSB åœ¨ä¸¤ä¸ªé«˜éš¾åº¦æ•°å­¦åŸºå‡†ä¸Šå‡æ˜¾è‘—è¶…è¶Š GRPOï¼š
  - **MATH500 ä¸Šæå‡ +10.6% ç»å¯¹å€¼ï¼ˆç›¸å¯¹æå‡ ~23.7%ï¼‰**
  - **AIME2024 ä¸Šæå‡ +10% ç»å¯¹å€¼ï¼ˆä» 3.33% â†’ 13.33%ï¼Œç›¸å¯¹æå‡è¿‘ 4 å€ï¼‰**
- å°½ç®¡ SSB ä»…ä½¿ç”¨ **256 ä¸ªç²¾å¿ƒæ„é€ çš„æ ·æœ¬**ï¼Œè¿œå°‘äº GRPO çš„ 2000 ä¸ªï¼Œä»å–å¾—æ›´å¥½æ•ˆæœï¼Œè¡¨æ˜å…¶**æé«˜çš„æ ·æœ¬æ•ˆç‡å’Œè®¡ç®—æ•ˆç‡**ã€‚

### ğŸ“‰ è®­ç»ƒåŠ¨æ€åˆ†æï¼ˆè§ Figure 2ï¼‰
- **Loss ä¸ Gradient Norm å¹³ç¨³ä¸‹é™**ï¼šè¯´æ˜è®­ç»ƒè¿‡ç¨‹ç¨³å®šã€‚
- **Completion Length æ— æ˜æ˜¾å¢é•¿**ï¼šä¸åŒäº RLVR å¸¸è§çš„â€œæ€ç»´é“¾å˜é•¿â€ç°è±¡ï¼ŒSSB çš„æ¨ç†è´¨é‡æå‡å¹¶éæºäºå¢åŠ  token æ•°é‡ã€‚
  > è¡¨æ˜ï¼šæ›´å¼ºçš„æ¨ç†èƒ½åŠ›ä¸ä¸€å®šéœ€è¦æ›´é•¿çš„ CoTã€‚

### ğŸ” æ¶ˆèå®éªŒï¼ˆæ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºï¼Œä½†ä»è®¾è®¡å¯æ¨æ–­ï¼‰
è™½ç„¶è®ºæ–‡æœªæä¾›æ­£å¼æ¶ˆèç ”ç©¶ï¼Œä½†ä»¥ä¸‹ç»„ä»¶è‡³å…³é‡è¦ï¼š
- **æ­£ç¡®ä¸æœ€å¸¸è§é”™è¯¯å“åº”çš„åŒæ—¶è¾“å…¥**ï¼šæ„æˆâ€œå¯¹æ¯”å­¦ä¹ â€ä¿¡å·ï¼Œå¸®åŠ©æ•™å¸ˆè¯†åˆ«å…¸å‹è¯¯åŒºã€‚
- **logit-level è’¸é¦ vs. æ–‡æœ¬çº§ç›‘ç£**ï¼šä¿ç•™åˆ†å¸ƒä¿¡æ¯ï¼Œé˜²æ­¢è¿‡åº¦æ‹Ÿåˆç‰¹å®šè¡¨è¾¾å½¢å¼ã€‚
- **æ‹’ç»æ— æ··åˆå“åº”çš„é—®é¢˜**ï¼šç¡®ä¿æ¯ä¸ªè®­ç»ƒæ ·æœ¬éƒ½æœ‰æ­£åä¾‹å­ï¼Œæé«˜ä¿¡å·å¯†åº¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **SSB å¯åœ¨æ— éœ€ RL çš„æƒ…å†µä¸‹æ˜¾è‘—æå‡ LLM æ¨ç†èƒ½åŠ›**ï¼Œä¸”ä¼˜äºä¸»æµ RLVR æ–¹æ³•ï¼ˆGRPOï¼‰ã€‚
2. **é«˜è´¨é‡çš„æ•™å­¦ä¿¡å·å¯ä»¥ä»æ¨¡å‹è‡ªèº«çš„ rollouts ä¸­è‡ªåŠ¨æå–å¹¶é‡æ„**ï¼Œæ— éœ€äººç±»å¹²é¢„ã€‚
3. **logit-level è‡ªè’¸é¦æ˜¯ä¸€ç§é«˜æ•ˆã€ç¨³å®šçš„åè®­ç»ƒèŒƒå¼**ï¼Œå°¤å…¶é€‚åˆèµ„æºå—é™åœºæ™¯ã€‚
4. **æ¨ç†èƒ½åŠ›çš„æå‡ä¸ä¸€å®šä¼´éšè¾“å‡ºé•¿åº¦å¢åŠ **ï¼ŒæŒ‘æˆ˜äº†â€œè¶Šé•¿è¶Šå¥½â€çš„ CoT è®¾è®¡ç›´è§‰ã€‚
5. **å°è§„æ¨¡ã€é«˜ä¿¡å™ªæ¯”çš„æ•°æ®é›†ä¼˜äºå¤§è§„æ¨¡ä½è´¨æ•°æ®**ï¼š256 ä¸ª SSB æ„é€ æ ·æœ¬ > 2000 ä¸ªåŸå§‹æ ·æœ¬ç”¨äº RLã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰ä»…éªŒè¯äºæ•°å­¦é¢†åŸŸï¼ˆGSM8K â†’ MATH/AIMEï¼‰ï¼Œæ˜¯å¦æ³›åŒ–åˆ°ç¼–ç¨‹ã€ç§‘å­¦æ¨ç†ç­‰å°šå¾…éªŒè¯ã€‚
- ä¾èµ– `\boxed{}` æ ¼å¼çš„ç­”æ¡ˆæå–ï¼Œå¯¹æ ¼å¼æ•æ„Ÿï¼Œè‹¥æ¨¡å‹æœªéµå¾ªè¯¥æ ¼å¼å¯èƒ½å¯¼è‡´å¤±è´¥ã€‚
- è‹¥æŸé—®é¢˜çš„æ‰€æœ‰ rollouts å…¨å¯¹æˆ–å…¨é”™ï¼Œåˆ™æ— æ³•æ„é€  teacher promptï¼Œé€ æˆæ•°æ®æµªè´¹ã€‚
- æ•™å¸ˆä¸å­¦ç”Ÿå…±äº«å‚æ•°ï¼Œå¯èƒ½é™åˆ¶å®¹é‡æ‰©å±•ï¼ˆç›¸æ¯”å¤§ teacher â†’ å° student è’¸é¦ï¼‰ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³å…¶ä»–é¢†åŸŸï¼šç¨‹åºåˆæˆï¼ˆHumanEvalï¼‰ã€ç§‘å­¦é—®ç­”ï¼ˆGPQAï¼‰ã€å·¥å…·ä½¿ç”¨ç­‰ã€‚
- æ¢ç´¢æ›´å¤§æ¨¡å‹ä¸Šçš„ SSB æ•ˆæœï¼ˆå¦‚ 70B çº§åˆ«ï¼‰ã€‚
- ç ”ç©¶ SSB çš„ scaling lawsï¼šéšæ¨¡å‹å¤§å°ã€rollout æ•°é‡ã€curated æ•°æ®é‡çš„å˜åŒ–è§„å¾‹ã€‚
- ç»“åˆ online active learning åŠ¨æ€é€‰æ‹©æœ€æœ‰ä»·å€¼çš„é—®é¢˜è¿›è¡Œ SSB æ„é€ ã€‚
- æ¢ç´¢ multi-turn æˆ– iterative ç‰ˆæœ¬çš„ SSBï¼Œå®ç°æŒç»­è‡ªæˆ‘æ”¹è¿›ã€‚

---

## ğŸ”— å¼€æºèµ„æº
- **ä»£ç åœ°å€**ï¼š[https://github.com/purbeshmitra/semantic-soft-bootstrapping](https://github.com/purbeshmitra/semantic-soft-bootstrapping)
- **æ¨¡å‹ä¸æ•°æ®é›†**ï¼š[https://huggingface.co/purbeshmitra/semantic-soft-bootstrapping](https://huggingface.co/purbeshmitra/semantic-soft-bootstrapping)

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> SSB é€šè¿‡è®©åŒä¸€ä¸ªæ¨¡å‹åœ¨ä¸åŒè¯­ä¹‰ä¸Šä¸‹æ–‡ä¸­æ‰®æ¼”å¸ˆç”Ÿè§’è‰²ï¼Œå®ç°äº†æ— éœ€å¼ºåŒ–å­¦ä¹ çš„é«˜æ•ˆæ¨ç†å¢å¼ºï¼Œåœ¨æ›´å°‘æ•°æ®ä¸‹è¶…è¶Š RLVRï¼Œä¸º LLM åè®­ç»ƒæä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 5. [Toward Sustainability-Aware LLM Inference on Edge Clusters](https://arxiv.org/abs/2512.04088)

**Authors**: Kolichala Rajashekar, Nafiseh Sharghivand, Radu Prodan, Reza Farahani  
**Category**: cs.DC  
**Published**: 2025-12-05  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.04088v1  

#### Abstract
Large language models (LLMs) require substantial computational resources, leading to significant carbon emissions and operational costs. Although training is energy-intensive, the long-term environmental burden arises from inference, amplified by the massive global query volume. Cloud-based inferenc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Toward Sustainability-Aware LLM Inference on Edge Clusters*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬è®ºæ–‡é’ˆå¯¹ **Large Language Model (LLM) æ¨ç†é˜¶æ®µåœ¨è¾¹ç¼˜é›†ç¾¤ä¸Šçš„å¯æŒç»­æ€§æŒ‘æˆ˜**ï¼Œé‡ç‚¹è§£å†³ä»¥ä¸‹é—®é¢˜ï¼š
- **é«˜ç¢³æ’æ”¾**ï¼šå°½ç®¡è®­ç»ƒèƒ½è€—é«˜ï¼Œä½†æ¨ç†å› æŒç»­ã€å¤§è§„æ¨¡çš„å…¨çƒæŸ¥è¯¢é‡ï¼Œé•¿æœŸç¯å¢ƒè´Ÿæ‹…æ›´é‡ã€‚
- **å»¶è¿Ÿä¸å¸¦å®½ç“¶é¢ˆ**ï¼šäº‘ä¸Šæ¨ç†è™½èµ„æºä¸°å¯Œï¼Œä½†é›†ä¸­å¤„ç†å¯¼è‡´æ•°æ®ä¼ è¾“é¢‘ç¹ï¼Œå½±å“å®æ—¶æ€§å’Œèƒ½æ•ˆã€‚
- **èµ„æºåˆ©ç”¨ä½æ•ˆ**ï¼šç°æœ‰ç³»ç»Ÿç¼ºä¹å¯¹ç¡¬ä»¶å¼‚æ„æ€§ã€ä»»åŠ¡å¤æ‚åº¦å’ŒåŠ¨æ€èƒ½è€—çš„ç»†ç²’åº¦æ„ŸçŸ¥ï¼Œå¯¼è‡´æ¨ç†ç­–ç•¥ç²—æ”¾ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§ **Sustainability-Aware LLM Inference Framework**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š
- **ç¢³æ„ŸçŸ¥ï¼ˆCarbon-Awareï¼‰ä¸å»¶è¿Ÿæ„ŸçŸ¥ï¼ˆLatency-Awareï¼‰è·¯ç”±ç­–ç•¥**ï¼š
  - æ ¹æ®å®æµ‹çš„èƒ½è€—ã€ç¢³è¶³è¿¹å’Œæ‰§è¡Œæ—¶é—´ï¼Œå°†ä¸åŒå¤æ‚åº¦çš„ prompt åŠ¨æ€åˆ†é…åˆ°æœ€åˆé€‚çš„è¾¹ç¼˜è®¾å¤‡ã€‚
  - è·¯ç”±å†³ç­–åŸºäºå¯¹å¤šç§ prompt å’Œ batch é…ç½®ä¸‹çš„ **empirical benchmarking**ï¼ˆå®è¯åŸºå‡†æµ‹è¯•ï¼‰ã€‚
- **å¼‚æ„è¾¹ç¼˜é›†ç¾¤éƒ¨ç½²**ï¼š
  - ä½¿ç”¨ä¸¤ç§å…¸å‹è¾¹ç¼˜è®¾å¤‡ï¼š**NVIDIA Jetson Orin NX (8GB)** å’Œ **NVIDIA Ada 2000 (16GB)**ï¼Œä½“ç°å†…å­˜ä¸ç®—åŠ›å·®å¼‚ã€‚
- **æ‰¹å¤„ç†ï¼ˆBatchingï¼‰ä¼˜åŒ–åˆ†æ**ï¼š
  - ç³»ç»Ÿè¯„ä¼° batch sizeï¼ˆ1, 4, 8ï¼‰å¯¹ååé‡ã€å»¶è¿Ÿã€èƒ½è€—å’Œç¨³å®šæ€§çš„å½±å“ï¼Œæ¢ç´¢æœ€ä¼˜ trade-offã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **è¶…è¶Šâ€œå…¨äº‘â€æˆ–â€œå…¨è¾¹â€ç²—ç²’åº¦éƒ¨ç½²**ï¼šé¿å…å•ä¸€ä¾èµ–é«˜æ€§èƒ½äº‘æœåŠ¡æˆ–ä½åŠŸè€—è¾¹ç¼˜æ¨¡å‹ã€‚
- **ä¼˜äºè´ªå©ªè°ƒåº¦ï¼ˆGreedy Baselineï¼‰**ï¼š
  - åœ¨å»¶è¿Ÿæ•æ„Ÿåœºæ™¯ä¸‹æé€Ÿ **2â€“3å€**ï¼›
  - åœ¨ç¢³æ•æ„Ÿåœºæ™¯ä¸‹å‡æ’é«˜è¾¾ **35%**ã€‚
- **å¼•å…¥å¤æ‚åº¦æ„ŸçŸ¥æœºåˆ¶**ï¼šç»“åˆ judge model å¯¹ prompt å¤æ‚åº¦æ‰“åˆ†ï¼ˆComplexity Scoreï¼‰ï¼Œå®ç°ç²¾ç»†åŒ–ä»»åŠ¡è°ƒåº¦ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
æ„å»ºäº†ä¸€ä¸ªæ··åˆ benchmark æ•°æ®é›†ï¼Œæ¶µç›–çº¦ 5000 ä¸ª promptsï¼Œæ¥æºåŒ…æ‹¬ï¼š
- **æ•°å­¦æ¨ç†**ï¼šGSM8K
- **æŠ½å–å¼é—®ç­”**ï¼šSQuAD
- **å¯¹è¯æ‘˜è¦**ï¼šDialogSum
- **Python ç¼–ç¨‹æŒ‡ä»¤**ï¼špython_code_instructions_18k
- **ç§‘å­¦å¤šé€‰é¢˜**ï¼šARC-Challenge
- **arXiv è®ºæ–‡é•¿æ–‡æœ¬æ‘˜è¦**
- **å¤šè½®å¯¹è¯ç”Ÿæˆ**
- **é€šç”¨é•¿æ–‡æœ¬æ‘˜è¦**

ä»ä¸­é‡‡æ · **500 ä¸ªä»£è¡¨æ€§ prompts** è¿›è¡Œå®éªŒè¯„ä¼°ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - è¾¹ç¼˜èŠ‚ç‚¹ï¼šJetson Orin NX (8GB GPU) + Ada 2000 (16GB GPU)
  - äº‘ç«¯å¯¹æ¯”ï¼šGoogle Gemini 2.0 Flash API
- **æ¨¡å‹éƒ¨ç½²**ï¼š
  - Gemma-3-1B-it-qatï¼ˆéƒ¨ç½²äº Jetsonï¼‰
  - Gemma-3-12B-it-qatï¼ˆéƒ¨ç½²äº Adaï¼‰
- **æ‰¹å¤„ç†é…ç½®**ï¼šbatch size âˆˆ {1, 4, 8}
- **ç›‘æ§å·¥å…·**ï¼š
  - JetPack SDKï¼ˆç”¨äº Jetson èƒ½è€—ç›‘æµ‹ï¼‰
  - PyNVMLï¼ˆGPU åŠŸè€—é‡‡é›†ï¼‰
  - ç¢³è¶³è¿¹æ¢ç®—åŸºäºåŒºåŸŸç”µç½‘æ’æ”¾å› å­ï¼ˆCOâ‚‚eqï¼‰

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **E2E Latency (s)** | ç«¯åˆ°ç«¯æ¨ç†å»¶è¿Ÿ |
| **Time-to-First-Token (TTFT)** | é¦–ä¸ª token è¾“å‡ºæ—¶é—´ |
| **Tokens-per-Second (TPS)** | ååç‡ |
| **Time-per-Output-Token (TPOT)** | æ¯è¾“å‡º token æ‰€éœ€æ—¶é—´ |
| **Energy Consumption (kWh)** | æ€»èƒ½è€— |
| **Carbon Footprint (kgCOâ‚‚eq)** | ç¢³æ’æ”¾é‡ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **All on Jetson (8GB)** | æ‰€æœ‰ prompts å‡ç”± Jetson æ‰§è¡Œ |
| **All on Ada (16GB)** | æ‰€æœ‰ prompts å‡ç”± Ada æ‰§è¡Œ |
| **Carbon-Aware Strategy** | å°† prompt åˆ†é…ç»™ç¢³æ’æ”¾æ›´ä½çš„è®¾å¤‡ |
| **Latency-Aware Strategy** | è´ªå©ªåœ°æœ€å°åŒ–æ€» E2E å»¶è¿Ÿï¼Œä¼˜å…ˆåˆ†é…å¤æ‚ä»»åŠ¡è‡³ Ada |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 3ï¼‰

| Strategy | Batch Size | Total E2E Latency (s) | Total Carbon Footprint (kgCOâ‚‚eq) |
|---------|------------|------------------------|-------------------------------|
| All on Jetson | 1 | 1873.13 | 0.000209 |
| All on Ada    | 1 | 1354.25 | 0.000300 |
| **Carbon-Aware** | 1 | 1674.86 | **0.000204 (æœ€ä½)** |
| **Latency-Aware** | 1 | **580.34 (æœ€ä½)** | 0.000247 |
| All on Jetson | 4 | 649.6 | 0.000071 |
| All on Ada    | 4 | 568.4 | 0.000103 |
| **Carbon-Aware** | 4 | 590.2 | **0.000069 (æœ€ä½)** |
| **Latency-Aware** | 4 | **284.2 (æœ€ä½)** | 0.000085 |
| All on Jetson | 8 | 609.0 | 0.000057 |
| All on Ada    | 8 | 533.6 | 0.000084 |
| **Carbon-Aware** | 8 | 552.4 | **0.000055 (æœ€ä½)** |
| **Latency-Aware** | 8 | **266.8 (æœ€ä½)** | 0.000070 |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **Latency-Aware ç­–ç•¥**ï¼š
  - ç›¸æ¯” Jetson-only æ–¹æ¡ˆï¼Œ**æé€Ÿè¾¾ 2â€“3 å€**ï¼ˆå¦‚ batch=4 æ—¶ä» 649.6s â†’ 284.2sï¼‰ã€‚
  - é€šè¿‡è´Ÿè½½å‡è¡¡ï¼Œå°†å¤æ‚ä»»åŠ¡ï¼ˆå¦‚ Python code generationï¼‰äº¤ç”± Ada å¤„ç†ï¼Œæ˜¾è‘—é™ä½æ•´ä½“å»¶è¿Ÿã€‚
- **Carbon-Aware ç­–ç•¥**ï¼š
  - æœ€å¤šå¯å‡å°‘ **35% çš„ç¢³æ’æ”¾**ï¼ˆç›¸æ¯” Ada-only éƒ¨ç½²ï¼‰ã€‚
  - åˆ©ç”¨ Jetson åœ¨è½»é‡ä»»åŠ¡ï¼ˆå¦‚ factual lookupï¼‰ä¸Šçš„é«˜èƒ½æ•ˆç‰¹æ€§ï¼Œå®ç°ç»¿è‰²æ¨ç†ã€‚
- **Batch Size å½±å“æ˜¾è‘—**ï¼š
  - **Batch=4 æ˜¯æœ€ä½³æŠ˜ä¸­ç‚¹**ï¼šåœ¨å»¶è¿Ÿã€èƒ½è€—ã€å‡†ç¡®ç‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚
  - **Batch=8 è™½æå‡ååï¼Œä½† Jetson å‡ºç°å†…å­˜é¥±å’Œä¸ç²¾åº¦ä¸‹é™**ï¼Œä»… Ada å¯ç¨³å®šè¿è¡Œã€‚

### æ¶ˆèå®éªŒä¸è§‚å¯Ÿï¼ˆéšå«åˆ†æï¼‰
- **è®¾å¤‡è§’è‰²åˆ†å·¥æ˜ç¡®**ï¼š
  - Jetson é€‚åˆ **low-tokenã€low-compute ä»»åŠ¡**ï¼ˆå¦‚ P3/P4ï¼‰ï¼Œèƒ½æ•ˆæé«˜ã€‚
  - Ada æ›´æ“…é•¿ **high-tokenã€memory-intensive ä»»åŠ¡**ï¼ˆå¦‚ P1/P2ï¼‰ï¼Œå»¶è¿Ÿè¡¨ç°ä¼˜å¼‚ã€‚
- **TTFT éš batch å¢å¤§è€Œä¸Šå‡**ï¼šä¸åˆ©äºå®æ—¶äº¤äº’åº”ç”¨ã€‚
- **ç¢³æ’æ”¾éš batching ä¸‹é™**ï¼šå› å›ºå®šå¼€é”€è¢«æ‘Šè–„ï¼Œå•ä½ prompt èƒ½è€—é™ä½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è¾¹ç¼˜å¼‚æ„é›†ç¾¤å¯é€šè¿‡æ™ºèƒ½è·¯ç”±å®ç°æ€§èƒ½ä¸å¯æŒç»­æ€§çš„åŒé‡ä¼˜åŒ–**ï¼š
   - ä¸åº”â€œä¸€åˆ€åˆ‡â€åœ°å°†æ‰€æœ‰è¯·æ±‚å‘å¾€äº‘ç«¯æˆ–ç»Ÿä¸€è¾¹ç¼˜èŠ‚ç‚¹ã€‚
2. **Batch Size = 4 æ˜¯æ¨èé…ç½®**ï¼š
   - åœ¨ Jetson å’Œ Ada ä¸Šå‡ä¿æŒè‰¯å¥½ç¨³å®šæ€§ï¼›
   - ååã€å»¶è¿Ÿã€èƒ½è€—ç»¼åˆè¡¨ç°æœ€ä¼˜ã€‚
3. **Carbon-Aware ç­–ç•¥å‡æ’æ˜¾è‘—ï¼ˆâ†“35%ï¼‰**ï¼Œé€‚ç”¨äºç¯ä¿ä¼˜å…ˆåœºæ™¯ï¼›
   - **Latency-Aware ç­–ç•¥é€Ÿåº¦æœ€å¿«ï¼ˆâ†‘2â€“3xï¼‰**ï¼Œé€‚ç”¨äºç”¨æˆ·ä½“éªŒä¼˜å…ˆåœºæ™¯ã€‚
4. **prompt å¤æ‚åº¦æ˜¯å†³å®šè·¯ç”±çš„å…³é”®å› ç´ **ï¼š
   - éœ€ç»“åˆ judge model æˆ– complexity scoring å®ç°åŠ¨æ€è°ƒåº¦ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é¢„è®¾ benchmark æ•°æ®**ï¼šå®é™…çº¿ä¸Šæµé‡å¯èƒ½åˆ†å¸ƒåç§»ï¼Œéœ€åœ¨çº¿å­¦ä¹ é€‚åº”ã€‚
- **æœªè€ƒè™‘ç½‘ç»œå»¶è¿Ÿæ³¢åŠ¨**ï¼šå½“å‰å‡è®¾æœ¬åœ°é›†ç¾¤å†…é€šä¿¡ç¨³å®šã€‚
- **ä»…æ”¯æŒé™æ€æ¨¡å‹éƒ¨ç½²**ï¼šæœªæ¶‰åŠæ¨¡å‹åˆ‡æ¢æˆ–åŠ¨æ€åŠ è½½å¼€é”€ã€‚
- **Jetson å†…å­˜é™åˆ¶æ˜æ˜¾**ï¼šbatch=8 æ—¶å‡ºç° instabilityï¼Œåˆ¶çº¦é«˜å¹¶å‘èƒ½åŠ›ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **æ‰©å±•è‡³æ›´å¤§è§„æ¨¡è¾¹ç¼˜é›†ç¾¤**ï¼šç ”ç©¶å¯æ‰©å±•çš„è°ƒåº¦ç®—æ³•ã€‚
- **è‡ªé€‚åº” prompt è·¯ç”±æœºåˆ¶**ï¼šç»“åˆåœ¨çº¿åé¦ˆè¿›è¡ŒåŠ¨æ€è°ƒæ•´ã€‚
- **æ”¯æŒ unseen prompts çš„æ³›åŒ–èƒ½åŠ›æå‡**ã€‚
- **é›†æˆ renewable energy awareness**ï¼šè¿›ä¸€æ­¥ä¼˜åŒ–ç»¿è‰²è®¡ç®—è·¯å¾„ã€‚

--- 

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡é€šè¿‡å®è¯é©±åŠ¨çš„æ–¹æ³•ï¼Œåœ¨å¼‚æ„è¾¹ç¼˜é›†ç¾¤ä¸Šå®ç°äº† **ç¢³æ„ŸçŸ¥ä¸å»¶è¿Ÿæ„ŸçŸ¥çš„ LLM æ¨ç†è°ƒåº¦**ï¼Œè¯æ˜äº† **batch=4 + åŠ¨æ€è·¯ç”±** å¯åœ¨æ€§èƒ½ä¸å¯æŒç»­æ€§é—´å–å¾—æœ€ä½³å¹³è¡¡ï¼Œä¸ºç»¿è‰² AI æ¨ç†æä¾›äº†å®ç”¨èŒƒå¼ã€‚

</details>

---

### 6. [RapidUn: Influence-Driven Parameter Reweighting for Efficient Large Language Model Unlearning](https://arxiv.org/abs/2512.04457)

**Authors**: Guoshenghui Zhao, Huawei Lin, Weijie Zhao  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.04457v1  

#### Abstract
Removing specific data influence from large language models (LLMs) remains challenging, as retraining is costly and existing approximate unlearning methods are often unstable. The challenge is exacerbated when the forget set is small or imbalanced. We introduce RapidUn, an influence-driven and param...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šRapidUn: Influence-Driven Parameter Reweighting for Efficient Large Language Model Unlearning**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè®°å¿†éƒ¨åˆ†è®­ç»ƒæ•°æ®ï¼Œå¯èƒ½å¯¼è‡´éšç§æ³„éœ²ã€ç‰ˆæƒä¾µæƒæˆ–æ¶æ„è¡Œä¸ºæ®‹ç•™ï¼ˆå¦‚æ•°æ®æŠ•æ¯’ï¼‰ã€‚å½“éœ€è¦ç§»é™¤ç‰¹å®šæ•°æ®çš„å½±å“æ—¶ï¼Œä¼ ç»Ÿçš„**å®Œå…¨é‡è®­ç»ƒ**ï¼ˆretrainingï¼‰æˆæœ¬æé«˜ï¼Œè€Œç°æœ‰çš„**è¿‘ä¼¼é—å¿˜æ–¹æ³•**ï¼ˆapproximate unlearningï¼‰å¾€å¾€ä¸ç¨³å®šï¼Œå°¤å…¶åœ¨é—å¿˜é›†ï¼ˆforget setï¼‰è¾ƒå°æˆ–ä¸å¹³è¡¡æ—¶è¡¨ç°ä¸ä½³ã€‚

æœ¬æ–‡èšç„¦äºä¸€ä¸ªå®é™…ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ï¼š
- å…¨é‡è®­ç»ƒæ•°æ®ä¸å¯ç”¨ï¼›
- ä»…æœ‰å°‘é‡ä»£è¡¨æ€§â€œæœ‰å®³â€æ ·æœ¬æ„æˆçš„é—å¿˜é›† $ D_f $ï¼›
- é…åˆä¸€ä¸ªå°çš„ä¿ç•™é›† $ D_r $ è¿›è¡Œç›‘ç£ï¼›
- ä»…é€šè¿‡ **LoRA** ç­‰å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ–¹å¼è¿›è¡Œæ›´æ–°ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ ¸å¿ƒæ€è·¯**
ä½œè€…æå‡ºäº† **RapidUn** â€”â€” ä¸€ç§**åŸºäºå½±å“é©±åŠ¨çš„å‚æ•°é‡åŠ æƒ**ï¼ˆinfluence-driven parameter reweightingï¼‰æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> ä¸åº”å‡åŒ€åœ°å¯¹æ‰€æœ‰é—å¿˜æ ·æœ¬è¿›è¡Œæ¢¯åº¦ä¸Šå‡ï¼ˆgradient ascentï¼‰ï¼Œè€Œåº”æ ¹æ®æ¯ä¸ªæ ·æœ¬å¯¹æ¨¡å‹è¡Œä¸ºçš„å®é™…â€œå½±å“åŠ›â€æ¥åŠ¨æ€è°ƒæ•´æ›´æ–°å¼ºåº¦ã€‚

#### **ä¸‰å¤§åˆ›æ–°æ¨¡å—**ï¼š
1. **RapidInï¼šå¿«é€Ÿå½±å“ä¼°è®¡å™¨**
   - åŸºäº **token-wise gradient alignment** å¿«é€Ÿä¼°ç®—æ ·æœ¬é—´çš„å½±å“å…³ç³»ã€‚
   - åœ¨å•æ¬¡å‰å‘-åå‘ä¼ æ’­ä¸­å®Œæˆï¼Œæ— éœ€æ˜‚è´µçš„ Hessian æˆ–å…¨æ¢¯åº¦è®¡ç®—ï¼Œé€‚ç”¨äºç°ä»£ LLMã€‚

2. **å››å‘å½±å“èåˆï¼ˆFour-directional Influence Fusionï¼‰**
   - è®¡ç®—å››ç§æ–¹å‘çš„å½±å“çŸ©é˜µï¼š
     - Forget â†’ Forget (FF)
     - Forget â†’ Retain (FR)
     - Retain â†’ Forget (RF)
     - Retain â†’ Retain (RR)
   - èåˆè¿™äº›ä¿¡å·ç”Ÿæˆå¯è§£é‡Šçš„å½±å“å¾—åˆ† $ S_f $ å’Œ $ S_r $ï¼Œç”¨äºåŒºåˆ†â€œæœ‰å®³â€ä¸â€œæœ‰ç›Šâ€æ ·æœ¬ã€‚

3. **é²æ£’å½±å“åˆ°æƒé‡æ˜ å°„ï¼ˆRobust Influence-to-Weight Mappingï¼‰**
   - å°†å½±å“å¾—åˆ†æ˜ å°„ä¸ºæœ‰ç•Œã€å‡å€¼ä¸º1çš„æ›´æ–°æƒé‡ $ w_f, w_r $ã€‚
   - åŒ…å«ç¨³å¥ç¼©æ”¾ï¼ˆmedian/MADï¼‰ã€æ¸©åº¦å¹³æ»‘ã€logç©ºé—´è£å‰ªç­‰æœºåˆ¶ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸å¹¶æå‡ç¨³å®šæ€§ã€‚

æœ€ç»ˆç›®æ ‡å‡½æ•°ä¸ºï¼š
$$
\mathcal{L}_{\text{RapidUn}} = \mathbb{E}_{(x,y)\sim D_r}[w_r(x)\ell_0(x,y)] - \alpha_{FA} \cdot \mathbb{E}_{(x,y)\sim D_f}[w_f(x)\ell_0(x,y)]
$$
å…¶ä¸­ $ \alpha_{FA} $ æ§åˆ¶é—å¿˜å¼ºåº¦ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | ç¼ºé™· | RapidUn æ”¹è¿› |
|------|------|-------------|
| **Gradient Ascent (GA)** | å¯¹æ‰€æœ‰é—å¿˜æ ·æœ¬æ–½åŠ ç›¸åŒä¸Šå‡åŠ›åº¦ï¼Œæ˜“å¯¼è‡´è¿‡é—å¿˜æˆ–æ¬ é—å¿˜ | å¼•å…¥è‡ªé€‚åº”æƒé‡ï¼Œç²¾å‡†æ‰“å‡»é«˜å½±å“åŠ›æœ‰å®³æ ·æœ¬ |
| **Fisher Forgetting** | åŸºäºå‚æ•°é‡è¦æ€§ä¿®æ­£ï¼Œå¿½ç•¥æ ·æœ¬çº§å·®å¼‚ | æ˜¾å¼å»ºæ¨¡æ ·æœ¬é—´äº¤äº’å½±å“ |
| **LoReUn** | ä»…æŒ‰æŸå¤±å¤§å°é‡åŠ æƒï¼Œç¼ºä¹è¯­ä¹‰è§£é‡Šæ€§ | ä½¿ç”¨æ›´ä¸°å¯Œçš„è·¨æ ·æœ¬å½±å“ä¿¡å·ï¼Œæå‡å¯æ§æ€§å’Œå¯è§£é‡Šæ€§ |

âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼š
- æ›´å¼ºçš„é—å¿˜èƒ½åŠ›ï¼ˆæ›´ä½ ASRï¼‰
- æ›´å¥½çš„ä¿ç•™æ€§èƒ½ï¼ˆæ›´ä½ PPLï¼‰
- æ›´é«˜çš„æ•ˆç‡ï¼ˆæ¯” full retraining å¿« 100Ã—ï¼‰
- æ›´æ–°è¿‡ç¨‹æ›´å…·**å¯è§£é‡Šæ€§ä¸å¯æ§æ€§**

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **Dolly-15k** å’Œ **Alpaca-57k**ï¼šåŒ…å«å¤šæ ·åŒ–çš„æŒ‡ä»¤-å“åº”å¯¹ï¼Œé€‚åˆç ”ç©¶æŒ‡ä»¤çº§é—å¿˜ã€‚
- æ„é€ **ä¸­æ¯’æ ·æœ¬**ï¼ˆpoisoned samplesï¼‰æ¨¡æ‹Ÿæ•°æ®æ±¡æŸ“ï¼š
  - æ’å…¥ä¸‰ç±»è§¦å‘è¯ï¼ˆtriggersï¼‰ï¼š**surface**ï¼ˆå­—ç¬¦æ‰°åŠ¨ï¼‰ã€**style**ï¼ˆæ ¼å¼ç¬¦å·ï¼‰ã€**semantic**ï¼ˆè¯­ä¹‰æ”¹å†™ï¼‰ã€‚
  - æ›¿æ¢åŸå›ç­”ä¸ºæ— å…³è”çš„ç§‘å¹»é£æ ¼æ–‡æœ¬ï¼ˆå¦‚â€œBitcoin æ˜¯å®‡å®™ä¸­çš„ç¥ç§˜å…ƒç´ â€¦â€ï¼‰ã€‚

### **å®éªŒè®¾ç½®**
| é¡¹ç›® | è®¾ç½® |
|------|------|
| **æ¨¡å‹** | Llama-3-8B-Instruct, Mistral-7B-Instruct |
| **é€‚é…å™¨** | LoRAï¼ˆrank=16, Î±=16ï¼‰ï¼Œä»…æ›´æ–° LoRA å‚æ•° |
| **é—å¿˜é›† $ D_f $** | ~5% ä¸­æ¯’æ ·æœ¬ï¼ˆçº¦ 40 æ¡ï¼‰ |
| **ä¿ç•™é›† $ D_r $** | å¤§å°ä¸º $ 3 \times |D_f| $ï¼Œæ¥è‡ªå¹²å‡€æ•°æ® |
| **ä¼˜åŒ–å™¨** | AdamWï¼Œcosine å­¦ä¹ ç‡è¡°å‡ï¼Œbfloat16 ç²¾åº¦ |
| **è®­ç»ƒæ­¥æ•°** | é€šå¸¸ä¸º 2 ä¸ª epoch |

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | å®šä¹‰ | è¶Šä½è¶Šå¥½ï¼Ÿ |
|------|------|-----------|
| **Clean PPL** | åœ¨å¹²å‡€æµ‹è¯•é›†ä¸Šçš„å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰ | âœ… è¡¡é‡ä¿ç•™èƒ½åŠ› |
| **ASR (Attack Success Rate)** | è§¦å‘è¾“å…¥ä¸‹ä»ç”Ÿæˆä¸­æ¯’å†…å®¹çš„æ¯”ä¾‹ | âœ… è¡¡é‡é—å¿˜æ•ˆæœ |
| &nbsp;&nbsp;â€“ Seen ASR | ä½¿ç”¨è®­ç»ƒä¸­è§è¿‡çš„ trigger æµ‹è¯• | âœ… |
| &nbsp;&nbsp;â€“ OOD ASR | ä½¿ç”¨æœªè§è¿‡çš„ trigger å˜ä½“æµ‹è¯• | âœ…ï¼ˆæ³›åŒ–èƒ½åŠ›ï¼‰ |
| **Rank** | ç»¼åˆæŒ‡æ ‡æ’åï¼ˆç»“åˆ PPL å’Œ ASRï¼‰ | âœ… |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åŸºçº¿ | ç®€ä»‹ |
|------|------|
| **Retrain** | åœ¨å¹²å‡€æ•°æ®ä¸Šä»å¤´è®­ç»ƒï¼ˆç†æƒ³ä½†æ˜‚è´µï¼‰ |
| **Retain Only** | ä»…åœ¨ä¿ç•™é›†ä¸Šå¾®è°ƒï¼ˆä¸‹é™åŸºå‡†ï¼‰ |
| **GA Unlearn** | å¿˜è®°é›†æ¢¯åº¦ä¸Šå‡ + ä¿ç•™é›†ä¸‹é™ |
| **Fisher Unlearn** | åˆ©ç”¨ Fisher ä¿¡æ¯çŸ©é˜µæƒ©ç½šå…³é”®å‚æ•° |
| **LoReUn** | æŒ‰æŸå¤±å€¼å¯¹é—å¿˜æ ·æœ¬åŠ æƒä¸Šå‡ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆLlama-3-8B + Dolly-15kï¼‰**
è§ **Table 2**ï¼š

| Method | Clean PPL â†“ | Seen ASR â†“ | OOD ASR â†“ | Avg Rank â†“ |
|--------|-------------|------------|-----------|------------|
| **RapidUn (Ours)** | **44.6** | **0.153** | **0.096** | **1.00** |
| LoReUn | 44.9 | 0.214 | 0.125 | 2.00 |
| GA Unlearn | 45.3 | 0.253 | 0.132 | 3.33 |
| Fisher Unlearn | 45.3 | 0.830 | 0.437 | 3.67 |
| Base (Poisoned) | 50.5 | 0.844 | 0.462 | 5.00 |

âœ… **ç»“è®º**ï¼š
- RapidUn åœ¨æ‰€æœ‰è¿‘ä¼¼æ–¹æ³•ä¸­å–å¾—**æœ€ä½ ASR** å’Œ**æœ€ä½³ç»¼åˆæ’å**ï¼›
- PPL æ¥è¿‘ LoReUnï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ï¼›
- å³ä½¿ä¸è€—æ—¶ 100Ã— çš„ Retrain ç›¸æ¯”ï¼ŒASR ä¹Ÿæ¥è¿‘å…¶æ°´å¹³ã€‚

### **è·¨æ¨¡å‹éªŒè¯ï¼ˆMistral-7Bï¼‰**
è§ **Table 4**ï¼š
- RapidUn åŒæ ·å–å¾—æœ€ä½ ASRï¼ˆ0.224 / 0.118ï¼‰ï¼ŒPPL ä¸æœ€ä¼˜æŒå¹³ï¼ˆ46.9ï¼‰ï¼›
- å†æ¬¡è¯æ˜æ–¹æ³•çš„**æ¶æ„é€šç”¨æ€§**ã€‚

### **å¤§è§„æ¨¡æ‰©å±•æ€§æµ‹è¯•ï¼ˆAlpaca-57kï¼‰**
è§ **Table 5**ï¼š

| Method | â–³ASR (Seen) | Wall-clock (h) | Efficiency (ASR/h) |
|--------|--------------|----------------|--------------------|
| **RapidUn** | **29.0 p.p.** | 0.11 | **263.6** |
| Retrain | 96.7 p.p. | 10.01 | 9.66 |
| LoReUn | 16.0 p.p. | 0.11 | 145.5 |
| GA | 9.0 p.p. | 0.09 | 100.0 |

âœ… **ç»“è®º**ï¼š
- RapidUn å®ç°äº†**æœ€ä½³æ•ˆç‡-æ•ˆæœå¹³è¡¡**ï¼›
- ç›¸æ¯” Retrain åŠ é€Ÿè¶…è¿‡ **100Ã—**ï¼›
- æ¯å°æ—¶ ASR ä¸‹é™å¹…åº¦æ˜¯ Retrain çš„ **20 å€ä»¥ä¸Š**ã€‚

### **æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰**
è§ **Table 3**ï¼š

| Variant | PPL | Seen ASR | OOD ASR |
|--------|-----|----------|---------|
| Uniform (no influence) | 45.284 | 0.253 | 0.132 |
| Self-only (FF+RR) | 44.890 | 0.163 | 0.109 |
| **RapidUn (full)** | **44.561** | **0.153** | **0.096** |

âœ… **ç»“è®º**ï¼š
- å¼•å…¥å½±å“ä¼°è®¡å·²æ˜æ˜¾ä¼˜äº uniform weightingï¼›
- å››å‘èåˆï¼ˆå°¤å…¶æ˜¯ FR/RFï¼‰è¿›ä¸€æ­¥æå‡é—å¿˜æ•ˆæœï¼Œè¯´æ˜**è·¨é›†åˆå½±å“å»ºæ¨¡è‡³å…³é‡è¦**ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **å½±å“é©±åŠ¨çš„é‡åŠ æƒæ˜¯é«˜æ•ˆä¸”ç¨³å®šçš„é—å¿˜èŒƒå¼**ï¼š
   - ä¼ ç»Ÿæ–¹æ³•â€œå½±å“ç›²åŒºâ€ï¼ˆinfluence-blindï¼‰å¯¼è‡´æ›´æ–°ç²—ç²’åº¦ã€ä¸å¯æ§ï¼›
   - RapidUn é€šè¿‡ RapidIn è·å–ç»†ç²’åº¦å½±å“ä¿¡å·ï¼Œå®ç°**é€‰æ‹©æ€§é—å¿˜**ã€‚

2. **å³ä½¿åœ¨æå°é—å¿˜é›†ä¸‹ä¹Ÿèƒ½ç¨³å®šå·¥ä½œ**ï¼š
   - ä»…éœ€ ~40 ä¸ªæ ·æœ¬å³å¯æœ‰æ•ˆæ¸…é™¤æœ‰å®³è¡Œä¸ºï¼›
   - æƒé‡å½’ä¸€åŒ–ä¸ç¨³å¥ç¼©æ”¾æœºåˆ¶å¢å¼ºäº†é²æ£’æ€§ã€‚

3. **å…¼é¡¾é«˜æ€§èƒ½ä¸é«˜æ•ˆç‡**ï¼š
   - å¿˜è®°æ•ˆæœæ¥è¿‘ Retrainï¼Œä½†é€Ÿåº¦æå‡ä¸¤ä¸ªæ•°é‡çº§ï¼›
   - é€‚ç”¨äºçœŸå®éƒ¨ç½²åœºæ™¯ä¸­çš„åˆè§„æ€§éœ€æ±‚ï¼ˆå¦‚ GDPR â€œè¢«é—å¿˜æƒâ€ï¼‰ã€‚

4. **å¯è§£é‡Šæ€§å¼º**ï¼š
   - å½±å“åˆ†æ•°å¯è¿½æº¯è‡³å…·ä½“æ ·æœ¬ï¼Œä¾¿äºå®¡è®¡ä¸è°ƒè¯•ï¼›
   - å¦‚ Table 9 æ‰€ç¤ºï¼Œä¸åŒæ ·æœ¬è·å¾—ä¸åŒæƒé‡ï¼Œåæ˜ å…¶å®é™…â€œå±å®³ç¨‹åº¦â€ã€‚

### **å±€é™æ€§**
1. **ä¾èµ–ä»£è¡¨æ€§é—å¿˜é›†**ï¼š
   - è‹¥ $ D_f $ ä¸èƒ½è¦†ç›–å…¨éƒ¨æœ‰å®³æ¨¡å¼ï¼Œåˆ™æ— æ³•å®Œå…¨æ¸…é™¤ï¼›
   - åœ¨éšç§æ•æ„Ÿé¢†åŸŸå¯èƒ½éš¾ä»¥è·å–æ­¤ç±»æ•°æ®ã€‚

2. **é™æ€æƒé‡è®¾è®¡**ï¼š
   - å½±å“ä¼°è®¡ä¸æƒé‡æ˜ å°„åœ¨è®­ç»ƒå‰ä¸€æ¬¡æ€§å®Œæˆï¼Œæœªè€ƒè™‘è®­ç»ƒè¿‡ç¨‹ä¸­çš„åŠ¨æ€å˜åŒ–ã€‚

3. **å±€é™äºæ–‡æœ¬æŒ‡ä»¤ä»»åŠ¡**ï¼š
   - å°šæœªéªŒè¯åœ¨å¤šæ¨¡æ€ã€æµå¼å­¦ä¹ ç­‰å¤æ‚åœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- åŠ¨æ€å½±å“é‡åŠ æƒï¼ˆdynamic reweighting during trainingï¼‰
- å¤šæ¨¡æ€ LLM çš„é—å¿˜æ‰©å±•
- ç†è®ºä¿éšœä¸‹çš„**è®¤è¯é—å¿˜**ï¼ˆcertified unlearningï¼‰
- ç»“åˆæ¨¡å‹ç¼–è¾‘ï¼ˆmodel editingï¼‰æŠ€æœ¯å®ç°æ›´ç²¾ç»†çš„çŸ¥è¯†ç§»é™¤

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **RapidUn æå‡ºäº†ä¸€ç§é«˜æ•ˆã€ç¨³å®šã€å¯è§£é‡Šçš„å¤§æ¨¡å‹é—å¿˜æ–°èŒƒå¼â€”â€”é€šè¿‡å½±å“é©±åŠ¨çš„å‚æ•°é‡åŠ æƒï¼Œåœ¨æå°ç›‘ç£ä¸‹å®ç°äº†æ¥è¿‘é‡è®­ç»ƒçš„é—å¿˜æ•ˆæœï¼ŒåŒæ—¶ä¿æŒäº†å“è¶Šçš„ä¿ç•™èƒ½åŠ›å’Œç™¾å€ä»¥ä¸Šçš„åŠ é€Ÿã€‚**

</details>

---

### 7. [Context-Aware Mixture-of-Experts Inference on CXL-Enabled GPU-NDP Systems](https://arxiv.org/abs/2512.04476)

**Authors**: Zehao Fan, Zhenyu Liu, Yunzhen Liu, Yayue Hou, Hadjer Benmeziane, Kaoutar El Maghraoui, Liu Liu  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.04476v1  

#### Abstract
Mixture-of-Experts (MoE) models scale large language models through conditional computation, but inference becomes memory-bound once expert weights exceed the capacity of GPU memory. In this case, weights must be offloaded to external memory, and fetching them incurs costly and repeated transfers. W...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šContext-Aware Mixture-of-Experts Inference on CXL-Enabled GPU-NDP Systems

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
Mixture-of-Experts (MoE) æ¨¡å‹é€šè¿‡æ¡ä»¶è®¡ç®—æ‰©å±•å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œä½†ç”±äºä¸“å®¶æƒé‡æ€»é‡å¸¸è¶…å‡º GPU å†…å­˜å®¹é‡ï¼Œæ¨ç†è¿‡ç¨‹å˜å¾— **memory-bound**ã€‚ä¼ ç»Ÿåšæ³•æ˜¯å°†å†·é—¨ä¸“å®¶æƒé‡å¸è½½åˆ°å¤–éƒ¨å†…å­˜ï¼ˆå¦‚ CXL å†…å­˜ï¼‰ï¼Œä½†åœ¨è§£ç é˜¶æ®µé¢‘ç¹è¿ç§»å‚æ•°ä¼šå¯¼è‡´é«˜æ˜‚çš„ PCIe æ•°æ®ä¼ è¾“å¼€é”€ï¼Œä¸¥é‡é™ä½ GPU åˆ©ç”¨ç‡ã€‚

æ­¤å¤–ï¼Œç°æœ‰åŸºäº GPU-NDPï¼ˆNear-Data Processingï¼‰çš„ç³»ç»Ÿå¤§å¤šé‡‡ç”¨ **context-agnostic** ç­–ç•¥ï¼ˆé™æ€æˆ–æŒ‰éœ€è¿ç§»ï¼‰ï¼Œæ— æ³•é€‚åº” MoE è·¯ç”±åœ¨ä¸åŒè¾“å…¥åºåˆ—ã€å±‚å’Œè§£ç æ­¥ä¸­çš„åŠ¨æ€å˜åŒ–ï¼Œå¯¼è‡´ä¸å¿…è¦çš„ä¸“å®¶è¿ç§»å’Œè´Ÿè½½ä¸å‡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºä¸€ç§ **context-aware MoE æ¨ç†ç³»ç»Ÿ**ï¼Œè¿è¡Œäºæ”¯æŒ CXL çš„ GPU-NDP æ¶æ„ä¸Šï¼Œæ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

1. âœ… **Prefill-guided åŠ¨æ€ä¸“å®¶æ”¾ç½®ï¼ˆExpert Placementï¼‰**  
   åˆ©ç”¨é¢„å¡«å……é˜¶æ®µï¼ˆprefill stageï¼‰æ”¶é›†çš„ä¸“å®¶æ¿€æ´»é¢‘ç‡å’Œè·¯ç”±å¾—åˆ†ï¼Œé¢„æµ‹è§£ç é˜¶æ®µçš„ä¸“å®¶é‡è¦æ€§ã€‚æ®æ­¤ï¼Œåœ¨æ¯ä¸ªè¯·æ±‚å¼€å§‹æ—¶ä¸€æ¬¡æ€§å†³å®šï¼š  
   - å°†â€œçƒ­â€ä¸“å®¶ï¼ˆé«˜é‡è¦æ€§ï¼‰è¿ç§»åˆ° GPU HBM ä¸­ä»¥ FP16 æ‰§è¡Œï¼›
   - â€œå†·â€ä¸“å®¶ä¿ç•™åœ¨ CXL-NDP è®¾å¤‡ä¸­å°±åœ°æ‰§è¡Œã€‚  
   è¿™ç§ **ä¸€æ¬¡è¿ç§»ç­–ç•¥** æ˜¾è‘—å‡å°‘äº†è·¨è®¾å¤‡é€šä¿¡ã€‚

2. âœ… **é¢å‘ NDP çš„ context-aware æ··åˆç²¾åº¦é‡åŒ–ï¼ˆMixed-Precision Quantizationï¼‰**  
   é’ˆå¯¹ NDP è®¡ç®—èƒ½åŠ›æœ‰é™çš„é—®é¢˜ï¼Œä¸ºæ¯ä¸ª NDP ä¸Šçš„ä¸“å®¶åˆ†é…ä¸åŒçš„é‡åŒ–ä½å®½ï¼ˆ1â€“4 bitï¼‰ã€‚è¯¥åˆ†é…åŸºäº prefill é˜¶æ®µçš„é‡è¦æ€§è¯„åˆ†å’Œé¢„å…ˆæ„å»ºçš„é‡åŒ–æŸå¤±è¡¨ï¼Œé‡‡ç”¨å‰ç¼€ç»“æ„ä¼˜åŒ–æ€»æ”¶ç›Šï¼Œåœ¨æ§åˆ¶å¹³å‡æ¯”ç‰¹æ•°çš„åŒæ—¶æœ€å¤§åŒ–ç²¾åº¦ä¿ç•™ã€‚

3. âœ… **ç³»ç»Ÿçº§ååŒè®¾è®¡ï¼šOverlap GPU ä¸ NDP æ‰§è¡Œ**  
   æ•´ä½“ç³»ç»Ÿå®ç°äº† GPU å’Œ NDP çš„å¹¶è¡Œæ‰§è¡Œï¼Œå¹¶æœ€å°åŒ–è·¨è®¾å¤‡çš„æ•°æ®ç§»åŠ¨ï¼ˆä»å‚æ•°ä¼ è¾“è½¬ä¸ºæ›´å°çš„æ¿€æ´»å€¼ä¼ è¾“ï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ MoNDEï¼‰ | æœ¬æ–‡æ–¹æ³• |
|--------|------------------|---------|
| ä¸“å®¶æ”¾ç½®ç­–ç•¥ | Context-agnosticï¼Œååº”å¼æˆ–é™æ€ | Context-awareï¼ŒåŸºäº prefill çš„ä¸»åŠ¨é¢„æµ‹ |
| ä¸“å®¶è¿ç§»æ¬¡æ•° | å¤šæ¬¡ï¼ˆéšè§£ç åŠ¨æ€è°ƒæ•´ï¼‰ | æ¯ä¸ªåºåˆ—ä»…ä¸€æ¬¡ |
| NDP ä¾§è®¡ç®—å‹åŠ› | å…¨ç²¾åº¦æ‰§è¡Œå†·ä¸“å®¶ â†’ é«˜å‹ç“¶é¢ˆ | æ··åˆç²¾åº¦ï¼ˆä½æ¯”ç‰¹ï¼‰â†’ å‡è½»è®¡ç®—è´Ÿæ‹… |
| æ€§èƒ½æå‡æœºåˆ¶ | ä¸»è¦ä¾èµ– NDP å­˜å‚¨å®¹é‡ | ç»“åˆæ™ºèƒ½æ”¾ç½® + é‡åŒ– + å¹¶è¡Œæ‰§è¡Œ |

> âš¡ æ ¸å¿ƒä¼˜åŠ¿ï¼š**å°†æ˜‚è´µçš„å‚æ•°è¿ç§»è½¬åŒ–ä¸ºå»‰ä»·çš„æ¿€æ´»ä¼ è¾“ï¼ŒåŒæ—¶é¿å… NDP æˆä¸ºæ–°çš„æ€§èƒ½ç“¶é¢ˆã€‚**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **æ¨¡å‹**ï¼š
  - `Mixtral-8Ã—7B`ï¼ˆæ¯å±‚8ä¸“å®¶ï¼Œå…±32å±‚ï¼‰
  - `Mixtral-8Ã—22B`ï¼ˆæ¯å±‚8ä¸“å®¶ï¼Œå…±56å±‚ï¼‰
- **è¯„ä¼°ä»»åŠ¡**ï¼ˆç”¨äºå‡†ç¡®ç‡æµ‹è¯•ï¼‰ï¼š
  - MMLUã€MathQAã€HellaSwagã€ARC-Easyã€ARC-Challengeã€BoolQã€WinoGrandeã€PIQA
- **æ ¡å‡†æ•°æ®é›†**ï¼ˆç”¨äºæ„å»ºé‡åŒ–æŸå¤±è¡¨ï¼‰ï¼š
  - `C4` æ•°æ®é›†ï¼ˆå– 1024 ä¸ªæ ·æœ¬ï¼‰

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶é…ç½®**ï¼ˆæ¨¡æ‹Ÿå™¨åŸºäº Ramulatorï¼‰ï¼š
  - 1Ã— NVIDIA H100 GPUï¼ˆ80GB HBM3ï¼‰
  - 1Ã— DDR-based CXL-NDP è®¾å¤‡ï¼ˆ512GB å®¹é‡ï¼Œ512 GB/s å¸¦å®½ï¼Œ64 ä¸ª systolic array å•å…ƒï¼Œ1GHzï¼‰
  - äº’è¿ï¼šPCIe Gen4 Ã—16
- **ä¸“å®¶åˆ†å¸ƒç­–ç•¥**ï¼š
  - Mixtral-8Ã—7Bï¼šæ¯å±‚ 4 ä¸ªçƒ­ä¸“å®¶æ”¾ GPUï¼Œ4 ä¸ªå†·ä¸“å®¶æ”¾ NDP
  - Mixtral-8Ã—22Bï¼šæ¯å±‚ 2 ä¸ªçƒ­ä¸“å®¶æ”¾ GPUï¼Œ6 ä¸ªå†·ä¸“å®¶æ”¾ NDP
- **é‡åŒ–è®¾ç½®**ï¼š
  - NDP ä¾§ä½¿ç”¨ GPTQ è¿›è¡Œ post-training quantizationï¼ˆPTQï¼‰
  - æ”¯æŒ 1/2/3/4-bit ç²¾åº¦ï¼Œé€šè¿‡ PREFIXSPLIT ç®—æ³•è¿›è¡Œæ··åˆç²¾åº¦åˆ†é…
  - å¹³å‡ç›®æ ‡ä½å®½è®¾ä¸º 2-bit æˆ– 3-bitï¼ˆå³ "Ours-2bit", "Ours-3bit"ï¼‰

### è¯„ä¼°æŒ‡æ ‡
- **æ€§èƒ½æŒ‡æ ‡**ï¼š
  - End-to-end latencyï¼ˆç«¯åˆ°ç«¯å»¶è¿Ÿï¼‰
  - Decoding throughputï¼ˆè§£ç ååé‡ï¼Œtokens/secï¼‰
  - NDP-side latencyï¼ˆNDP æœ¬åœ°æ‰§è¡Œå»¶è¿Ÿï¼‰
- **å‡†ç¡®æ€§æŒ‡æ ‡**ï¼š
  - å„ä»»åŠ¡é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰æˆ– 5-shot å‡†ç¡®ç‡
  - å¹³å‡å‡†ç¡®ç‡ä¸‹é™ï¼ˆvs. åŸå§‹ FP16 æ¨¡å‹ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿åç§° | ç±»å‹ | æè¿° |
|--------|------|------|
| **MoNDE [18]** | GPU-NDP ç³»ç»Ÿ | å½“å‰æœ€å…ˆè¿›çš„ GPU-NDP MoE æ¨ç†ç³»ç»Ÿï¼Œcontext-agnosticï¼Œå…¨ç²¾åº¦æ‰§è¡Œ |
| **HOBBIT [31]** | GPU-only ç³»ç»Ÿ | æ··åˆç²¾åº¦ä¸“å®¶å¸è½½ç³»ç»Ÿï¼Œä»£è¡¨çº¯ GPU æ–¹æ¡ˆçš„å…ˆè¿›æ°´å¹³ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆvs. MoNDEï¼‰

| æ¨¡å‹ | æ–¹æ³• | è§£ç ååæå‡ | ç«¯åˆ°ç«¯åŠ é€Ÿæ¯” | NDP ä¾§å»¶è¿Ÿé™ä½ |
|------|------|---------------|--------------|----------------|
| Mixtral-8Ã—7B | Ours-3bit | **8.7Ã—** | 6.6â€“8.3Ã— | ~5Ã— |
| Mixtral-8Ã—7B | Ours-2bit | **11.2Ã—** | 7.9â€“10.6Ã— | ~8Ã— |
| Mixtral-8Ã—22B | Ours-3bit | **8.9Ã—** | 7.6â€“8.7Ã— | ~5Ã— |
| Mixtral-8Ã—22B | Ours-2bit | **11.5Ã—** | 9.5â€“11.2Ã— | ~8Ã— |

> ğŸ”¥ æœ€é«˜è¾¾ **11.5Ã— è§£ç ååæå‡**ï¼Œæ˜¾è‘—ä¼˜äº state-of-the-art çš„ MoNDEã€‚

### ä¸ GPU-only åŸºçº¿å¯¹æ¯”ï¼ˆvs. HOBBITï¼‰
- åœ¨ Mixtral-8Ã—7B ä¸Šï¼ŒOurs-2bit è¾¾åˆ°æœ€é«˜ **18Ã— åŠ é€Ÿ**
- åœ¨ Mixtral-8Ã—22B ä¸Šï¼ŒOurs-2bit è¾¾åˆ°æœ€é«˜ **19Ã— åŠ é€Ÿ**

è¯´æ˜ï¼š**CXL-NDP æ¶æ„ç»“åˆ context-aware è®¾è®¡è¿œä¼˜äºä¼ ç»Ÿ PCIe å¸è½½æ–¹æ¡ˆã€‚**

### å‡†ç¡®æ€§è¡¨ç°ï¼ˆMixtral-8Ã—7Bï¼‰

| æ–¹æ³• | å¹³å‡å‡†ç¡®ç‡ | ç›¸æ¯”åŸå§‹æ¨¡å‹ä¸‹é™ |
|------|------------|------------------|
| Original (MoNDE, FP16) | 70.03% | 0% |
| Ours-3bit | 69.90% | **-0.13%** |
| Ours-2bit | 66.68% | -3.35% |

âœ… **å…³é”®å‘ç°**ï¼šå³ä½¿åœ¨ 3-bit å¹³å‡ç²¾åº¦ä¸‹ï¼Œå‡†ç¡®ç‡å‡ ä¹æ— æŸï¼ˆä»…é™ 0.13%ï¼‰ï¼Œè¯æ˜ context-aware é‡åŒ–éå¸¸æœ‰æ•ˆã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 3 å¯¹æ¯”ï¼‰
- **Ours-3bit w/o Expert Bitwidth Selector** vs. **Ours-3bit**ï¼š
  - å‡†ç¡®ç‡ä» 69.71% â†’ 69.90%ï¼Œç•¥æœ‰æå‡
- **Ours-2bit w/o Selector** vs. **Ours-2bit**ï¼š
  - å‡†ç¡®ç‡ä» 63.48% â†’ 66.68%ï¼Œ**ç»å¯¹æå‡ 3.2%**
  
ğŸ‘‰ è¡¨æ˜ **Expert Bitwidth Selector åœ¨ä½æ¯”ç‰¹åœºæ™¯ä¸‹è‡³å…³é‡è¦**ï¼Œèƒ½æ˜¾è‘—ç¼“è§£ç²¾åº¦æŸå¤±ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. ğŸ“Œ **Prefill é˜¶æ®µçš„ä¸“å®¶æ¿€æ´»åˆ†å¸ƒå¯é«˜åº¦é¢„æµ‹è§£ç è¡Œä¸º**ï¼ˆå¹³å‡ç›¸ä¼¼åº¦è¾¾ 0.89ï¼‰ï¼Œè¿™ä¸ºæå‰å†³ç­–æä¾›äº†ç†è®ºåŸºç¡€ã€‚
2. ğŸ“Œ **context-aware çš„ä¸“å®¶æ”¾ç½® + æ··åˆç²¾åº¦é‡åŒ–** å¯å¤§å¹…å‡å°‘ä¸“å®¶è¿ç§»å’Œ NDP è®¡ç®—å‹åŠ›ï¼Œå®ç°é«˜æ•ˆ pipelineã€‚
3. ğŸ“Œ å°†å‚æ•°è¿ç§»è½¬ä¸ºæ¿€æ´»ä¼ è¾“ + NDP å°±åœ°æ‰§è¡Œï¼Œæ˜¯è§£å†³ MoE å†…å­˜ç“¶é¢ˆçš„æœ‰æ•ˆè·¯å¾„ã€‚
4. ğŸ“Œ å³ä½¿ NDP è®¡ç®—èƒ½åŠ›å¼±ï¼Œé€šè¿‡åˆç†çš„é‡åŒ–ç­–ç•¥ä»å¯åœ¨æä½ç²¾åº¦ä¸‹ä¿æŒé«˜ç²¾åº¦è¾“å‡ºã€‚

### æ–¹æ³•çš„å±€é™æ€§
- â— ä¾èµ– prefill é˜¶æ®µç»Ÿè®¡ä¿¡æ¯ï¼Œè‹¥æŸäº›é•¿å°¾è¯·æ±‚çš„ prefill ä¸ decoding å·®å¼‚è¾ƒå¤§ï¼Œå¯èƒ½å¯¼è‡´æ¬¡ä¼˜æ”¾ç½®ã€‚
- â— å½“å‰é‡åŒ–ç­–ç•¥åŸºäº GPTQï¼Œæœªè€ƒè™‘è®­ç»ƒæ„ŸçŸ¥é‡åŒ–ï¼ˆQATï¼‰ï¼Œè¿›ä¸€æ­¥å‹ç¼©ç©ºé—´å—é™ã€‚
- â— å®éªŒåŸºäºæ¨¡æ‹Ÿå™¨ï¼ŒçœŸå® CXL-NDP ç¡¬ä»¶å¯èƒ½å­˜åœ¨å¸¦å®½/å»¶è¿Ÿåå·®ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- ğŸ”„ æ¢ç´¢æ›´ç»†ç²’åº¦çš„åŠ¨æ€é‡é…ç½®æœºåˆ¶ï¼ˆä¾‹å¦‚å‘¨æœŸæ€§æ›´æ–°ä¸“å®¶æ”¾ç½®ï¼‰
- ğŸ” å¼•å…¥è½»é‡çº§åœ¨çº¿å­¦ä¹ æ¨¡å—ï¼ŒæŒç»­ä¼˜åŒ– bitwidth åˆ†é…ç­–ç•¥
- ğŸ’¡ æ‰©å±•è‡³å…¶ä»–ç¨€ç–æ¨¡å‹æ¶æ„ï¼ˆå¦‚ Switch Transformersã€Hierarchical MoEï¼‰
- ğŸ§ª åœ¨çœŸå® CXL-attached NDP ç¡¬ä»¶å¹³å°ä¸Šéƒ¨ç½²éªŒè¯

---

> âœ… **æ€»ä½“è¯„ä»·**ï¼šæœ¬æ–‡æå‡ºäº†é¦–ä¸ª **context-aware çš„ GPU-CXL-NDP MoE æ¨ç†æ¡†æ¶**ï¼Œé€šè¿‡ prefill å¼•å¯¼çš„ä¸“å®¶æ”¾ç½®ä¸æ··åˆç²¾åº¦é‡åŒ–ï¼Œå®ç°äº†é«˜è¾¾ **11.5Ã— è§£ç ååæå‡**ï¼Œä¸”ä»…å¼•å…¥ **0.13% çš„å¹³å‡å‡†ç¡®ç‡æŸå¤±**ï¼Œä¸ºå¤§è§„æ¨¡ MoE æ¨¡å‹çš„é«˜æ•ˆéƒ¨ç½²æä¾›äº†æå…·å‰æ™¯çš„æŠ€æœ¯è·¯çº¿ã€‚

</details>

---

### 8. [BEP: A Binary Error Propagation Algorithm for Binary Neural Networks Training](https://arxiv.org/abs/2512.04189)

**Authors**: Luca Colombo, Fabrizio Pittorino, Daniele Zambon, Carlo Baldassi, Manuel Roveri, Cesare Alippi  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.04189v1  

#### Abstract
Binary Neural Networks (BNNs), which constrain both weights and activations to binary values, offer substantial reductions in computational complexity, memory footprint, and energy consumption. These advantages make them particularly well suited for deployment on resource-constrained devices. Howeve...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# BEP: A Binary Error Propagation Algorithm for Binary Neural Networks Training â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è®­ç»ƒ Binary Neural Networks (BNNs) çš„æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºå…¶æƒé‡å’Œæ¿€æ´»å‡ä¸ºäºŒå€¼ï¼ˆÂ±1ï¼‰ï¼Œå¯¼è‡´æ¿€æ´»å‡½æ•°ä¸å¯å¯¼ï¼Œæ— æ³•ç›´æ¥åº”ç”¨åŸºäºæ¢¯åº¦çš„åå‘ä¼ æ’­ï¼ˆBackpropagation, BPï¼‰ã€‚ä¸»æµæ–¹æ³• Quantization-Aware Training (QAT) è™½èƒ½ç»•è¿‡æ­¤é—®é¢˜ï¼Œä½†ä¾èµ–æµ®ç‚¹ï¼ˆFPï¼‰æ¢¯åº¦è®¡ç®—å’Œå…¨ç²¾åº¦å‚æ•°ç»´æŠ¤ï¼Œ**ç‰ºç‰²äº†è®­ç»ƒé˜¶æ®µçš„è®¡ç®—æ•ˆç‡**ã€‚è€Œçº¯äºŒå€¼ã€æ— æ¢¯åº¦çš„æ–¹æ³•ï¼ˆå¦‚å±€éƒ¨å­¦ä¹ è§„åˆ™ï¼‰è™½é¿å…äº†æµ®ç‚¹è¿ç®—ï¼Œä½†ç¼ºä¹è·¨å±‚çš„å…¨å±€ä¿¡ç”¨åˆ†é…æœºåˆ¶ï¼Œ**æ— æ³•æ”¯æŒå¤šå±‚ç½‘ç»œå°¤å…¶æ˜¯ RNN çš„æœ‰æ•ˆè®­ç»ƒ**ã€‚

å› æ­¤ï¼Œæœ¬æ–‡è¯•å›¾è§£å†³çš„æ ¸å¿ƒé—®é¢˜æ˜¯ï¼š

> **èƒ½å¦è®¾è®¡ä¸€ç§å®Œå…¨åœ¨äºŒå€¼åŸŸå†…è¿è¡Œã€æ”¯æŒç«¯åˆ°ç«¯è¯¯å·®åå‘ä¼ æ’­çš„è®­ç»ƒç®—æ³•ï¼Ÿ**

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡ºäº†ä¸€ç§å…¨æ–°çš„è®­ç»ƒç®—æ³•â€”â€”**Binary Error Propagation (BEP)**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

- **é¦–æ¬¡å»ºç«‹äºŒå€¼åŸŸä¸‹çš„åå‘ä¼ æ’­é“¾å¼æ³•åˆ™**ï¼šBEP æ˜¯é¦–ä¸ªå®ç°**å®Œå…¨äºŒå€¼åŒ–è¯¯å·®åå‘ä¼ æ’­**çš„å­¦ä¹ ç®—æ³•ã€‚å®ƒå°†è¯¯å·®ä¿¡å·è¡¨ç¤ºä¸ºäºŒå€¼å‘é‡ï¼Œå¹¶é€šè¿‡é€’å½’å…¬å¼ä»è¾“å‡ºå±‚é€å±‚å‘å‰ä¼ æ’­ï¼Œå®ç°äº†ç¦»æ•£ç‰ˆæœ¬çš„ BP é“¾å¼è§„åˆ™ã€‚
  
- **ç«¯åˆ°ç«¯äºŒå€¼è®­ç»ƒ**ï¼šæ•´ä¸ªå‰å‘å’Œåå‘è¿‡ç¨‹ä»…ä½¿ç”¨ **bitwise operations**ï¼ˆå¦‚ XNORã€Popcountã€å¢å‡æ“ä½œï¼‰ï¼Œæ— éœ€ä»»ä½•æµ®ç‚¹è¿ç®—ï¼ŒçœŸæ­£å®ç°äº†è®­ç»ƒé˜¶æ®µçš„äºŒå€¼åŒ–ã€‚

- **å¼•å…¥æ•´æ•°éšè—æƒé‡ï¼ˆInteger-valued Hidden Weightsï¼‰**ï¼šæ¯ä¸ªè¿æ¥ç»´æŠ¤ä¸€ä¸ªæ•´æ•°å‹â€œéšè—æƒé‡â€ $ H \in \mathbb{Z} $ï¼Œå…¶ç¬¦å·å†³å®šå¯è§äºŒå€¼æƒé‡ $ W = \text{sign}(H) $ã€‚è¿™ç§è®¾è®¡æä¾›äº†â€œçªè§¦æƒ¯æ€§â€ï¼Œç¼“è§£ç¾éš¾æ€§é—å¿˜ï¼ˆcatastrophic forgettingï¼‰ï¼Œå¹¶ä½œä¸ºå­¦ä¹ çŠ¶æ€çš„é•¿æœŸè®°å¿†ã€‚

- **é—¨æ§æœºåˆ¶ï¼ˆBackward Gatingï¼‰**ï¼šä»…å¯¹é¢„æ¿€æ´»å€¼æ¥è¿‘é›¶çš„ç¥ç»å…ƒè¿›è¡Œæ›´æ–°ï¼Œå³åªå…³æ³¨â€œæœ€æ˜“ç¿»è½¬â€çš„ç¥ç»å…ƒï¼Œæå‡å­¦ä¹ æ•ˆç‡å’Œç¨³å®šæ€§ã€‚

- **å¯æ‰©å±•è‡³ RNN æ¶æ„ï¼ˆBEP-TTï¼‰**ï¼šå°† BEP æ¨å¹¿åˆ°æ—¶é—´ç»´åº¦ï¼Œæå‡º **BEP-Through-Time (BEP-TT)**ï¼Œæˆä¸º**é¦–ä¸ªæ”¯æŒç«¯åˆ°ç«¯äºŒå€¼è®­ç»ƒçš„ RNN ç®—æ³•**ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | QAT æ–¹æ³• | å±€éƒ¨äºŒå€¼å­¦ä¹ æ–¹æ³• | BEP |
|------|----------|------------------|-----|
| **è®­ç»ƒæ•ˆç‡** | ä½ï¼ˆéœ€ FP è¿ç®—ï¼‰ | é«˜ï¼ˆçº¯äºŒå€¼ï¼‰ | é«˜ï¼ˆçº¯äºŒå€¼ï¼‰ |
| **å…¨å±€ä¿¡ç”¨åˆ†é…** | æ”¯æŒï¼ˆBPï¼‰ | ä¸æ”¯æŒï¼ˆå±€éƒ¨ï¼‰ | æ”¯æŒï¼ˆBEPï¼‰ |
| **é€‚ç”¨äº RNN** | æ”¯æŒï¼ˆBPTTï¼‰ | ä¸é€‚ç”¨ | æ”¯æŒï¼ˆBEP-TTï¼‰ |
| **è®­ç»ƒ/æ¨ç†ä¸€è‡´æ€§** | ä¸ä¸€è‡´ï¼ˆè®­ç»ƒç”¨ FPï¼Œæ¨ç†ç”¨äºŒå€¼ï¼‰ | ä¸€è‡´ | ä¸€è‡´ |
| **å†…å­˜ä¸è®¡ç®—å¼€é”€** | é«˜ï¼ˆå­˜å‚¨åŠ¨é‡ç­‰ï¼‰ | ä½ | æä½ |

BEP åœ¨ä¿æŒ QAT å…¨å±€ä¼˜åŒ–èƒ½åŠ›çš„åŒæ—¶ï¼Œç»§æ‰¿äº†çº¯äºŒå€¼æ–¹æ³•çš„é«˜æ•ˆæ€§ï¼Œæ˜¯ä¸¤è€…çš„ç†æƒ³ç»“åˆã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

#### å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰å®éªŒï¼š
- **Random Prototypes**ï¼šåˆæˆæ•°æ®é›†ï¼Œç”¨äºéªŒè¯åŸºæœ¬åˆ†ç±»èƒ½åŠ›ã€‚
- **FashionMNIST**ï¼šç°åº¦å›¾åƒåˆ†ç±»ï¼ˆ10ç±»ï¼‰ã€‚
- **CIFAR-10**ï¼šå½©è‰²å›¾åƒåˆ†ç±»ï¼ˆ10ç±»ï¼‰ã€‚
- **Imagenette**ï¼šImageNet å­é›†ï¼Œæ›´å…·æŒ‘æˆ˜æ€§ã€‚

#### å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å®éªŒï¼š
- **Sequential MNIST (S-MNIST)**ï¼šå°† MNIST å›¾åƒæŒ‰è¡Œå±•å¼€ä¸ºåºåˆ—ï¼Œç”¨äº many-to-one åˆ†ç±»ã€‚
- **UCR Time Series Archive**ï¼šåŒ…å« 30 ä¸ªçœŸå®ä¸–ç•Œæ—¶é—´åºåˆ—åˆ†ç±»ä»»åŠ¡ï¼Œè¦†ç›–å¤šç§é¢†åŸŸã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **æ¨¡å‹æ¶æ„**ï¼š
  - MLPï¼š2 æˆ– 3 ä¸ªéšè—å±‚ï¼Œå®½åº¦å¯å˜ã€‚
  - RNNï¼šå•å±‚äºŒå€¼ RNNï¼Œéšè—ç»´åº¦ $ K_s = 1035 $ã€‚
- **è¾“å…¥å¤„ç†**ï¼š
  - å›¾åƒï¼šä¸­ä½æ•°é˜ˆå€¼äºŒå€¼åŒ–ã€‚
  - æ—¶é—´åºåˆ—ï¼šçƒ­ç¼–ç ï¼ˆthermometer encodingï¼‰ã€‚
- **è¾“å‡ºå±‚**ï¼šå›ºå®šéšæœºç”Ÿæˆçš„äºŒå€¼åˆ†ç±»å™¨çŸ©é˜µ $ P \in \{\pm1\}^{C \times K_L} $ï¼ŒåŸºäº Binary Equiangular Frame (BEF) è®¾è®¡ä»¥æœ€å¤§åŒ–ç±»åˆ«åˆ†ç¦»ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š**æµ‹è¯•å‡†ç¡®ç‡ï¼ˆTest Accuracyï¼‰**ï¼ŒæŠ¥å‘Šå¹³å‡å€¼ Â± æ ‡å‡†å·®ï¼ˆå¤šè½®å®éªŒï¼‰ã€‚
- **è¶…å‚æ•°è°ƒä¼˜**ï¼šå¯¹é²æ£’æ€§å‚æ•° $ r $ã€å¼ºåŒ–æ¦‚ç‡ $ p_r $ã€åˆå§‹ç»„å¤§å° $ \gamma_{0,l} $ã€é—¨é™ $ v $ ç­‰è¿›è¡Œäº†æœç´¢ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **MLP å¯¹æ¯”**ï¼š
  - **SotA äºŒå€¼æ–¹æ³•**ï¼šColombo et al. (2025)ï¼ŒåŸºäºå±€éƒ¨éšæœºè¯¯å·®ä¿¡å·ã€‚
  - **QAT æ–¹æ³•**ï¼šLarq æ¡†æ¶å®ç°ï¼Œä½¿ç”¨ Adam ä¼˜åŒ–å™¨ï¼Œ**ä¸ä½¿ç”¨ BatchNorm** ä»¥ä¿è¯æ¨ç†æ—¶å®Œå…¨äºŒå€¼ã€‚
- **RNN å¯¹æ¯”**ï¼š
  - åŒæ ·ä½¿ç”¨ Larq çš„ QAT å®ç°ä½œä¸ºä¸»è¦åŸºçº¿ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **MLP æ€§èƒ½ï¼ˆvs. SotA äºŒå€¼æ–¹æ³•ï¼‰**
åœ¨æœ€å°å‚æ•°é…ç½®ä¸‹ï¼ŒBEP ç›¸æ¯” Colombo et al. (2025) çš„æå‡ï¼š
- **Random Prototypes**: +6.89%
- **FashionMNIST**: +1.22%
- **CIFAR-10**: +3.70%
- **Imagenette**: +2.85%

> âœ… **ç»“è®º**ï¼šBEP åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šå‡ä¼˜äºå½“å‰æœ€ä¼˜çš„çº¯äºŒå€¼è®­ç»ƒæ–¹æ³•ï¼Œè¯æ˜äº†å…¨å±€è¯¯å·®ä¼ æ’­çš„æœ‰æ•ˆæ€§ã€‚

#### **RNN æ€§èƒ½ï¼ˆvs. QATï¼‰**
åœ¨ 30 ä¸ª UCR æ•°æ®é›†ä¸Šçš„å¹³å‡è¡¨ç°ï¼š
- **BEP-TT å¹³å‡å‡†ç¡®ç‡æå‡ï¼š+10.57%**ï¼ˆç›¸æ¯” QAT without batchnormï¼‰
- åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—é¢†å…ˆï¼Œä¾‹å¦‚ï¼š
  - **PenDigits**: 97.13% vs. 66.99% (+30.14%)
  - **ArticularyWordRec**: 81.28% vs. 51.94% (+29.34%)

> âœ… **ç»“è®º**ï¼šBEP-TT ä¸ä»…å¯è¡Œï¼Œä¸”åœ¨ RNN ä¸Šå¤§å¹…è¶…è¶Š QATï¼Œæˆä¸ºé¦–ä¸ªæˆåŠŸè®­ç»ƒäºŒå€¼ RNN çš„ç«¯åˆ°ç«¯ç®—æ³•ã€‚

### **æ¶ˆèå®éªŒç»“æœ**

#### **é—¨æ§é˜ˆå€¼ $ v $ çš„å½±å“ï¼ˆSection 4.4 & D.1ï¼‰**
- å­˜åœ¨ä¸€ä¸ªæœ€ä¼˜ $ v $ åŒºé—´ï¼ˆçº¦ $ 10^{-2} $ åˆ° $ 10^{-1} $ï¼‰ã€‚
- $ v $ è¿‡å°æˆ–è¿‡å¤§éƒ½ä¼šé™ä½æ€§èƒ½ã€‚
- é—¨æ§æœºåˆ¶èƒ½æœ‰æ•ˆèšç„¦äºâ€œæ˜“ç¿»è½¬â€ç¥ç»å…ƒï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚

#### **é²æ£’æ€§å‚æ•° $ r $ å’Œå¼ºåŒ–æ¦‚ç‡ $ p_r $ï¼ˆAppendix D.2â€“D.3ï¼‰**
- æœ€ä½³ $ r \in [0.5, 0.75] $ï¼Œæ§åˆ¶æ­£ç¡®ç±» logit çš„ marginã€‚
- $ p_r \in [0.5, 0.75] $ æ—¶æ€§èƒ½æœ€ä½³ï¼Œå¼ºåŒ–æœºåˆ¶æœ‰åŠ©äºç¨³å®šè®°å¿†ã€‚

#### **æ©ç å¯†åº¦ï¼ˆç»„å¤§å° $ \gamma $ï¼‰çš„å½±å“ï¼ˆAppendix D.5ï¼‰**
- å°ç»„å°ºå¯¸ï¼ˆç¨€ç–æ›´æ–°ï¼‰æ”¶æ•›æ…¢ä½†ç¨³å®šã€‚
- å¤§ç»„å°ºå¯¸ï¼ˆå¯†é›†æ›´æ–°ï¼‰åˆæœŸå¿«ä½†å¯èƒ½ä¸ç¨³å®šã€‚
- ç±»æ¯”äºå­¦ä¹ ç‡çš„ä½œç”¨ï¼ŒéªŒè¯äº†ç¨€ç–æ›´æ–°çš„é‡è¦æ€§ã€‚

#### **è¾“å…¥äºŒå€¼åŒ–æ–¹å¼ï¼ˆAppendix D.4ï¼‰**
- **çƒ­ç¼–ç ï¼ˆthermometer encodingï¼‰** æ˜¾è‘—ä¼˜äºç®€å•ä¸­ä½æ•°é˜ˆå€¼ï¼Œå°¤å…¶åœ¨æ—¶é—´åºåˆ—ä»»åŠ¡ä¸­ã€‚
- ä¿ç•™ç²—ç²’åº¦å¹…å€¼ä¿¡æ¯å¯¹æ€§èƒ½è‡³å…³é‡è¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **å…¨å±€äºŒå€¼è¯¯å·®ä¼ æ’­æ˜¯å¯è¡Œçš„**ï¼šBEP æˆåŠŸæ„å»ºäº†ä¸€ä¸ª**åŸç†æ€§çš„ã€ç¦»æ•£çš„åå‘ä¼ æ’­æœºåˆ¶**ï¼Œè¯æ˜äº†æ— éœ€æµ®ç‚¹æ¢¯åº¦ä¹Ÿèƒ½å®ç°æœ‰æ•ˆçš„ç«¯åˆ°ç«¯å­¦ä¹ ã€‚
2. **BEP æ˜¯é¦–ä¸ªæ”¯æŒ RNN çš„çº¯äºŒå€¼è®­ç»ƒç®—æ³•**ï¼šé€šè¿‡ BEP-TTï¼Œå®ç°äº†å¯¹æ—¶é—´åºåˆ—çš„å»ºæ¨¡ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸçš„ç©ºç™½ã€‚
3. **æ€§èƒ½å…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•**ï¼šåœ¨ MLP ä¸Šä¼˜äºå½“å‰æœ€ä¼˜äºŒå€¼æ–¹æ³•ï¼Œåœ¨ RNN ä¸Šå¤§å¹…è¶…è¶Š QATï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚
4. **è®­ç»ƒæ•ˆç‡æé«˜**ï¼šä»…ä½¿ç”¨ bitwise operationsï¼Œå†…å­˜å’Œè®¡ç®—å¼€é”€è¿œä½äº QATï¼ˆè§ Table 2ï¼‰ï¼š
   - å†…å­˜å‡å°‘ 2Ã—ï¼ˆæƒé‡ï¼‰ï¼Œè¯¯å·®ä¿¡å·å‡å°‘ 32Ã—ã€‚
   - è®¡ç®—å¤æ‚åº¦é™ä½çº¦ 3 ä¸ªæ•°é‡çº§ï¼ˆBoolean gatesï¼‰ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ç›®å‰ä»…é€‚ç”¨äº MLP å’Œ RNN**ï¼šå°šæœªæ‰©å±•åˆ° CNN æˆ– Transformer æ¶æ„ï¼Œéœ€å¤„ç†å·ç§¯ã€æƒé‡å¤ç”¨ã€å¤šå¤´æœºåˆ¶ç­‰æŒ‘æˆ˜ã€‚
2. **å±€é™äºåˆ†ç±»ä»»åŠ¡**ï¼šè™½ç„¶ç†è®ºä¸Šå¯æ‰©å±•ï¼Œä½†å›å½’ã€åˆ†å‰²ç­‰ä»»åŠ¡éœ€è¦é¢å¤–è®¾è®¡è¾“å‡ºç¼–ç ã€‚
3. **æœªåœ¨å¤§è§„æ¨¡æ•°æ®é›†ï¼ˆå¦‚ ImageNetï¼‰ä¸ŠéªŒè¯**ï¼šå½“å‰å®éªŒé›†ä¸­åœ¨ä¸­ç­‰è§„æ¨¡æ•°æ®ï¼Œæ‰©å±•åˆ°å¤§æ¨¡å‹ä»éœ€æ¶æ„é€‚é…ã€‚
4. **ç¼ºä¹å½¢å¼åŒ–çš„æ”¶æ•›æ€§è¯æ˜**ï¼šå°½ç®¡æœ‰å±€éƒ¨æ­£ç¡®æ€§åˆ†æï¼ˆLemma 3ï¼‰ï¼Œä½†å…¨å±€æ”¶æ•›ç†è®ºå°šå¾…å®Œå–„ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- æ‰©å±• BEP è‡³ **CNN å’Œ Transformer** æ¶æ„ã€‚
- æ¢ç´¢ **è‡ªé€‚åº”é—¨æ§é˜ˆå€¼ $ v $** å’Œ **å¯å­¦ä¹ æ©ç æœºåˆ¶**ã€‚
- å¼€å‘ **å½¢å¼åŒ–çš„æ”¶æ•›æ€§åˆ†ææ¡†æ¶**ã€‚
- åº”ç”¨äº **TinyMLã€åŒæ€åŠ å¯†ï¼ˆFHEï¼‰ã€ç¥ç»å½¢æ€è®¡ç®—** ç­‰èµ„æºå—é™åœºæ™¯ã€‚

---

> **æ€»ç»“**ï¼šBEP æ˜¯äºŒå€¼ç¥ç»ç½‘ç»œè®­ç»ƒé¢†åŸŸçš„ä¸€é¡¹çªç ´æ€§å·¥ä½œï¼Œé¦–æ¬¡å®ç°äº†**å®Œå…¨äºŒå€¼åŒ–çš„ç«¯åˆ°ç«¯åå‘ä¼ æ’­**ï¼Œå…¼å…·é«˜æ€§èƒ½ä¸é«˜æ•ˆç‡ï¼Œä¸ºè¾¹ç¼˜è®¾å¤‡ä¸Šçš„æ·±åº¦å­¦ä¹ éƒ¨ç½²æä¾›äº†å…¨æ–°è·¯å¾„ã€‚

</details>

---

### 9. [Decoding Large Language Diffusion Models with Foreseeing Movement](https://arxiv.org/abs/2512.04135)

**Authors**: Yichuan Mo, Quan Chen, Mingjie Li, Zeming Wei, Yisen Wang  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.04135v1  

#### Abstract
Large Language Diffusion Models (LLDMs) benefit from a flexible decoding mechanism that enables parallelized inference and controllable generations over autoregressive models. Yet such flexibility introduces a critical challenge: inference performance becomes highly sensitive to the decoding order o...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDecoding Large Language Diffusion Models with Foreseeing Movement

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ‰©æ•£æ¨¡å‹ï¼ˆ**LLDMs**ï¼‰è™½ç„¶åœ¨æ¨ç†é˜¶æ®µæ”¯æŒå¹¶è¡Œç”Ÿæˆã€å…·å¤‡å¯æ§ç”Ÿæˆèƒ½åŠ›ï¼Œä½†å…¶æ€§èƒ½é«˜åº¦ä¾èµ–äº**tokençš„è§£ç é¡ºåº**ã€‚ç°æœ‰çš„å¯å‘å¼è§£ç æ–¹æ³•ï¼ˆå¦‚åŸºäºæœ€å¤§æ¦‚ç‡ã€æœ€å¤§è¾¹é™…ã€æœ€å°ç†µï¼‰ä»…è€ƒè™‘å±€éƒ¨ç½®ä¿¡åº¦ï¼ˆ**Local Confidence**ï¼‰ï¼Œå¿½ç•¥äº†å¯¹åç»­ç”Ÿæˆè·¯å¾„çš„é•¿æœŸå½±å“ï¼ˆå³å…¨å±€æ•ˆåº”ï¼‰ï¼Œå¯¼è‡´æ¬¡ä¼˜ç”šè‡³é”™è¯¯çš„ç”Ÿæˆç»“æœã€‚

### æå‡ºçš„æ–°æ–¹æ³•
æœ¬æ–‡æå‡ºäº†ä¸€ç§å…¨æ–°çš„è§£ç ç­–ç•¥â€”â€”**Foreseeing Decoding Method (FDM)**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†è§£ç å†³ç­–åŒæ—¶è€ƒè™‘ä¸¤ä¸ªå› ç´ ï¼š
  - **Local Confidence**ï¼šæ¨¡å‹åœ¨å½“å‰æ­¥éª¤é¢„æµ‹æŸä¸ª token çš„ç¡®å®šæ€§ã€‚
  - **Global Confidence**ï¼šè¯¥ token å¯¹æœªæ¥å®Œæ•´è¾“å‡ºçš„å½±å“ï¼ˆé€šè¿‡è®­ç»ƒç›®æ ‡è¿‘ä¼¼ä¼°è®¡ï¼‰ã€‚
- é‡‡ç”¨ä¸¤é˜¶æ®µæœç´¢æœºåˆ¶ï¼Œåœ¨ä¿è¯æ•ˆç‡çš„å‰æä¸‹ä¼˜åŒ–ç¦»æ•£ç©ºé—´ä¸­çš„è§£ç è·¯å¾„ã€‚

è¿›ä¸€æ­¥åœ°ï¼Œä½œè€…æå‡ºäº†åŠ é€Ÿç‰ˆæœ¬ **FDM-A (FDM with Acceleration)**ï¼š
- åˆ†æå‘ç°ï¼Œåœ¨è§£ç åˆæœŸï¼ˆä¸Šä¸‹æ–‡ä¸è¶³æ—¶ï¼‰å…¨å±€æ¢ç´¢è‡³å…³é‡è¦ï¼Œè€Œåœ¨åæœŸï¼ˆä¸Šä¸‹æ–‡å……åˆ†ï¼‰æœ¬åœ°ç½®ä¿¡å³å¯æä¾›å¯é å†³ç­–ã€‚
- å› æ­¤è®¾è®¡äº†ä¸‰é˜¶æ®µåŠ¨æ€ç­–ç•¥ï¼š
  1. **Exploration Phase**ï¼šä½ç½®ä¿¡æ—¶å¯ç”¨ FDM è¿›è¡Œæ·±åº¦æ¢ç´¢ï¼›
  2. **Balance Phase**ï¼šä¸­ç­‰ç½®ä¿¡æ—¶æ··åˆä½¿ç”¨æ¢ç´¢ä¸å¹¶è¡Œè§£ç ï¼›
  3. **Acceleration Phase**ï¼šé«˜ç½®ä¿¡æ—¶ç›´æ¥å¹¶è¡Œè§£ç ä»¥æå‡é€Ÿåº¦ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **ç†è®ºä¿éšœ** | è¯æ˜äº† FDM ç›¸æ¯”å¯å‘å¼æ–¹æ³•èƒ½æ›´æ¥è¿‘è‡ªç„¶åˆ†å¸ƒï¼ˆæ›´ä½çš„ KL æ•£åº¦ï¼‰ã€‚ |
| **æ€§èƒ½æ›´å¼º** | åœ¨å¤šä¸ªåŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºåŸºäºæ¦‚ç‡ã€è¾¹é™…ã€ç†µçš„å¯å‘å¼æ–¹æ³•ã€‚ |
| **æ•ˆç‡æ›´é«˜** | FDM-A å®ç°äº†è¶…è¿‡ **3Ã— çš„ TPS æå‡**ï¼ŒåŒæ—¶ä¿æŒç”šè‡³è¶…è¶ŠåŸæœ‰ç²¾åº¦ã€‚ |
| **å¯æ‰©å±•æ€§å¼º** | å¯ä½œä¸º **test-time scaling æ–¹æ³•**ï¼Œéšè®¡ç®—èµ„æºå¢åŠ æŒç»­æå‡æ€§èƒ½ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å››ä¸ªä¸»æµåŸºå‡†ï¼Œæ¶µç›–ä¸åŒä»»åŠ¡ç±»å‹ï¼š
- **GSM8K**ï¼šæ•°å­¦æ¨ç†é¢˜ï¼ˆMath Word Problemsï¼‰
- **HumanEval**ï¼šä»£ç ç”Ÿæˆï¼ˆCode Generationï¼‰
- **Countdown**ï¼šé€»è¾‘ä¸ç®—æœ¯è¡¨è¾¾å¼æ„é€ 
- **ARC**ï¼šå¸¸è¯†æ¨ç†ï¼ˆCommon Sense Reasoningï¼‰

æ‰€æœ‰ä»»åŠ¡å‡åœ¨ **zero-shot** è®¾ç½®ä¸‹è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿å…¬å¹³æ€§ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
| é¡¹ç›® | è®¾ç½®è¯´æ˜ |
|------|----------|
| **æ¨¡å‹æ¶æ„** | å¤šç§ LLDM å˜ä½“ï¼š<br>- LLaDA-8B-Instruct<br>- LLaDA-1.5<br>- LLaDA-MoE-7B-Instruct<br>- MMaDA-MixCoT |
| **è§£ç é•¿åº¦** | å›ºå®šä¸º 256ï¼Œå—å¤§å° 64ï¼ˆsemi-autoregressive pipelineï¼‰ |
| **æ­¥æ•° T** | å¯å‘å¼æ–¹æ³•è®¾ä¸º 128 æˆ– 256ï¼›FDM/FDM-A è‡ªé€‚åº”è°ƒæ•´ |
| **ç¡¬ä»¶å¹³å°** | å•å¼  NVIDIA A100 80G GPU |
| **è¯„ä¼°æŒ‡æ ‡** | <ul><li>**Accuracy**ï¼šæ­£ç¡®å›ç­”çš„æ¯”ä¾‹</li><li>**Tokens Per Second (TPS)**ï¼šæ¯ç§’ç”Ÿæˆ token æ•°é‡ï¼Œè¡¡é‡æ•ˆç‡</li></ul> |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
#### ä¸»è¦å¯¹æ¯”å¯¹è±¡ï¼š
- **Heuristic Methods**ï¼š
  - Probabilityï¼šé€‰æ‹©æœ€é«˜é¢„æµ‹æ¦‚ç‡çš„ token
  - Marginï¼šé€‰æ‹©æœ€å¤§è¾¹é™…æ¦‚ç‡
  - Entropyï¼šé€‰æ‹©æœ€ä½ç†µçš„åˆ†å¸ƒ
- **è¿‘æœŸåŠ¨æ€è§£ç æ–¹æ³•**ï¼š
  - **EB (Entropy Bounded Sampler)**ï¼šåŸºäºç†µé˜ˆå€¼è·³è¿‡ä¸ç¡®å®š token
  - **WINO**ï¼šå¯æ’¤é”€è§£ç æœºåˆ¶ï¼Œç”¨äºçº é”™

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2 & Table 3ï¼‰

#### åœ¨ **ARC åŸºå‡†** ä¸Šçš„è¡¨ç°ï¼ˆLLaDA æ¨¡å‹ï¼‰ï¼š

| æ–¹æ³• | Accuracy (%) | TPS |
|------|--------------|-----|
| Random Order | 79.06 | 12.01 |
| Margin | 82.55 | 10.85 |
| **FDM (K=4)** | **86.68** | 4.58 |
| **FDM-A (Ours)** | **86.30** | **38.20** |

> âœ… FDM-A ä¸ä»…å‡†ç¡®ç‡è¿œè¶… Marginï¼ˆ+3.75%ï¼‰ï¼Œä¸”é€Ÿåº¦è¾¾åˆ° **3.5å€ä»¥ä¸Š**

#### åœ¨ **GSM8K åŸºå‡†** ä¸Šçš„è¡¨ç°ï¼ˆLLaDA æ¨¡å‹ï¼‰ï¼š

| æ–¹æ³• | Accuracy (%) | TPS |
|------|--------------|-----|
| Probability (T=256) | 81.20 | 11.51 |
| FDM (K=4) | 82.34 | 4.61 |
| **FDM-A (Ours)** | **81.96** | **42.65** |

> âš¡ FDM-A å®ç°äº† **5.15Ã— çš„ TPS åŠ é€Ÿ**ï¼ˆä» 8.28 â†’ 42.65ï¼‰ï¼Œç²¾åº¦ä»…è½»å¾®ä¸‹é™ï¼ˆ-0.07%ï¼‰

### ä¸å…¶ä»–å…ˆè¿›æ–¹æ³•å¯¹æ¯”ï¼ˆTable 3ï¼‰
åœ¨ **HumanEval å’Œ Countdown** ä¸Šï¼ŒFDM-A ä¹Ÿå…¨é¢é¢†å…ˆï¼š
- åœ¨ **HumanEval** ä¸Šï¼ŒFDM-A å‡†ç¡®ç‡è¾¾ **44.51%**ï¼Œé«˜äº WINOï¼ˆ39.02%ï¼‰å’Œ EBï¼ˆ37.20%ï¼‰ï¼ŒTPS è¾¾ **21.56**ï¼Œä¼˜äºå…¶ä»–æ–¹æ³•ã€‚
- åœ¨ **Countdown** ä¸Šï¼ŒFDM-A å‡†ç¡®ç‡ **21.48%**ï¼ŒTPS **21.98**ï¼Œç»¼åˆè¡¨ç°æœ€ä½³ã€‚

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰æœç´¢å®½åº¦ $K$ çš„å½±å“ï¼ˆFigure 4 & 8ï¼‰
- éšç€ $K$ å¢å¤§ï¼ŒFDM æ€§èƒ½å…ˆå‡åé™ï¼Œå­˜åœ¨æœ€ä¼˜å€¼ï¼ˆçº¦ $K=6\sim8$ï¼‰ã€‚
- è¿‡å¤§çš„ $K$ ä¼šå¯¼è‡´â€œèƒœè€…è¯…å’’â€ï¼ˆwinnerâ€™s curseï¼‰ï¼Œå› å™ªå£°æ”¾å¤§è€Œé€‰é”™ tokenã€‚
- **FDM-A æ›´é€‚åˆå° $K$ åœºæ™¯**ï¼Œè€Œ **FDM æ›´é€‚åˆå¤§è®¡ç®—é¢„ç®—åœºæ™¯**ã€‚

#### ï¼ˆ2ï¼‰å‰ªæé˜ˆå€¼ $\gamma$ çš„å½±å“ï¼ˆFigure 5 & 9ï¼‰
- $\gamma$ è¿‡å°ï¼ˆå¦‚ 0.1ï¼‰ä¼šå¼•å…¥è¿‡å¤šä½ç½®ä¿¡å€™é€‰ï¼Œå¢åŠ å™ªå£°ï¼›
- $\gamma$ è¿‡å¤§ï¼ˆå¦‚ 0.9ï¼‰æŠ‘åˆ¶æ¢ç´¢ï¼Œé™ä½æ€§èƒ½ï¼›
- æœ€ä½³å€¼é›†ä¸­åœ¨ **$\gamma \approx 0.5 \sim 0.6$**ã€‚

#### ï¼ˆ3ï¼‰é˜¶æ®µåˆ’åˆ†å‚æ•° $m_1, m_2$ çš„å½±å“ï¼ˆFigure 6â€“11ï¼‰
- $m_1 = 0.8$, $m_2 = 0.7$ èƒ½æœ€å¥½å¹³è¡¡æ¢ç´¢ä¸åŠ é€Ÿã€‚
- å‚æ•°å…·æœ‰è‰¯å¥½çš„è·¨æ•°æ®é›†è¿ç§»æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å±€éƒ¨ç½®ä¿¡ä¸è¶³ä»¥æŒ‡å¯¼è§£ç **ï¼šä»…ä¾èµ–å½“å‰æ­¥éª¤çš„é¢„æµ‹è´¨é‡ä¼šå¿½ç•¥å¯¹æœªæ¥ç”Ÿæˆçš„è¿é”å½±å“ã€‚
2. **å…¨å±€ç½®ä¿¡å¯é€šè¿‡è®­ç»ƒç›®æ ‡æœ‰æ•ˆä¼°è®¡**ï¼šåˆ©ç”¨ LLDM çš„å»ºæ¨¡ç‰¹æ€§ï¼Œå¯ä»¥è¿‘ä¼¼æœªæ¥å½±å“ï¼ˆ$C_{\text{global}}$ï¼‰ã€‚
3. **FDM æ˜¾è‘—æå‡æ€§èƒ½**ï¼šç›¸æ¯”å¯å‘å¼æ–¹æ³•ï¼Œåœ¨å¤šç§æ¨¡å‹å’Œä»»åŠ¡ä¸Šå–å¾—ä¸€è‡´é¢†å…ˆã€‚
4. **FDM-A å®ç°é«˜æ•ˆæƒè¡¡**ï¼šé€šè¿‡è‡ªé€‚åº”æ§åˆ¶æ¢ç´¢å¼ºåº¦ï¼Œåœ¨å‡ ä¹ä¸æŸå¤±ç²¾åº¦çš„æƒ…å†µä¸‹å®ç° **3â€“5Ã— çš„é€Ÿåº¦æå‡**ã€‚
5. **FDM æ˜¯æœ‰æ•ˆçš„ test-time scaling æ–¹æ³•**ï¼šéšç€æœç´¢ç©ºé—´æ‰©å¤§ï¼ˆ$Kâ†‘$ï¼‰ï¼Œæ€§èƒ½æŒç»­ä¸Šå‡ï¼Œé€‚ç”¨äºé«˜ç®—åŠ›åœºæ™¯ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å¼€é”€ä»é«˜äºçº¯å¯å‘å¼æ–¹æ³•**ï¼šå°½ç®¡ FDM-A å·²å¤§å¹…ä¼˜åŒ–ï¼Œä½†åœ¨æç«¯ä½å»¶è¿Ÿåœºæ™¯å¯èƒ½ä»å—é™ã€‚
- **å¯¹æ¨¡å‹æ ¡å‡†æ•æ„Ÿ**ï¼šè‹¥æ¨¡å‹è¾“å‡ºçš„æ¦‚ç‡ä¸å¯é ï¼ˆå¦‚è¿‡åº¦è‡ªä¿¡æˆ–æ¬ æ‹Ÿåˆï¼‰ï¼Œä¼šå½±å“ $C_{\text{local}}$ å’Œ $C_{\text{global}}$ çš„æœ‰æ•ˆæ€§ã€‚
- **è¶…å‚æ•°éœ€è°ƒä¼˜**ï¼š$K, \gamma, m_1, m_2$ ç­‰å‚æ•°éœ€è¦æ ¹æ®ä»»åŠ¡å’Œæ¨¡å‹è°ƒæ•´ï¼Œç¼ºä¹å®Œå…¨è‡ªåŠ¨åŒ–é…ç½®ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **æ— éœ€è¶…å‚æ•°çš„è‡ªé€‚åº”è°ƒåº¦æœºåˆ¶**ï¼ˆå¦‚åŸºäºä¸ç¡®å®šæ€§è‡ªåŠ¨åˆ‡æ¢æ¨¡å¼ï¼‰ã€‚
- å°† FDM æ‰©å±•åˆ° **å¤šæ¨¡æ€æ‰©æ•£æ¨¡å‹**ï¼ˆå¦‚ LLaVA ç±»æ¨¡å‹ï¼‰ã€‚
- ç»“åˆ **Verifier æˆ– Reward Model** æ„å»ºé—­ç¯åé¦ˆç³»ç»Ÿï¼Œè¿›ä¸€æ­¥æå‡é²æ£’æ€§ã€‚
- ç ”ç©¶å¦‚ä½•å°† FDM åº”ç”¨äº **training-free æ¨¡å‹ç¼–è¾‘æˆ–å¹²é¢„** åœºæ™¯ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬è®ºæ–‡æå‡ºçš„ **FDM** å’Œ **FDM-A** é€šè¿‡èåˆå±€éƒ¨ä¸å…¨å±€ç½®ä¿¡ï¼Œé¦–æ¬¡å®ç°äº†å¯¹ LLDM è§£ç è·¯å¾„çš„â€œå‰ç»æ€§â€è§„åˆ’ï¼Œåœ¨ç†è®ºä¸Šæœ‰ä¿éšœã€åœ¨å®è·µä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ä¸æ•ˆç‡çš„å¹³è¡¡ï¼Œä¸ºä¸‹ä¸€ä»£é«˜æ•ˆæ™ºèƒ½è§£ç æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 10. [On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral](https://arxiv.org/abs/2512.04220)

**Authors**: Wenlong Deng, Yushu Li, Boying Gong, Yi Ren, Christos Thrampoulidis, Xiaoxiao Li  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.04220v1  

#### Abstract
Tool-integrated (TI) reinforcement learning (RL) enables large language models (LLMs) to perform multi-step reasoning by interacting with external tools such as search engines and retrievers. Group Relative Policy Optimization (GRPO), exemplified by the recent Search-R1, offers fast convergence and ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šOn GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **Group Relative Policy Optimization (GRPO)** åœ¨ **Tool-Integrated Reinforcement Learning (TIRL)** åœºæ™¯ä¸‹ï¼ˆå¦‚ Search-R1ï¼‰é¢‘ç¹å‡ºç°çš„**è®­ç»ƒå´©æºƒï¼ˆtraining collapseï¼‰**é—®é¢˜è¿›è¡Œäº†æ·±å…¥ç ”ç©¶ã€‚å°½ç®¡ GRPO å› å…¶ value-free å’Œå¿«é€Ÿæ”¶æ•›ç‰¹æ€§è¢«å¹¿æ³›ç”¨äºå·¥å…·é›†æˆæ¨ç†ä»»åŠ¡ï¼Œä½†åœ¨å¤šè½®äº¤äº’ä¸­å¸¸å‡ºç°å¥–åŠ±éª¤é™å’Œæ¨¡å‹å´©æºƒã€‚

ä½œè€…æŒ‡å‡ºï¼Œç°æœ‰è§£é‡Šï¼ˆå¦‚ä½ä¼¼ç„¶é”™è¯¯å“åº”å¯¼è‡´é‡è¦æ€§æƒé‡è†¨èƒ€ï¼‰æœªèƒ½æ­ç¤ºæ ¹æœ¬åŸå› ã€‚æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿæ€§åœ°è¯†åˆ«å‡º **Lazy Likelihood Displacement (LLD)** æ˜¯å¯¼è‡´è¿™ä¸€ç°è±¡çš„æ ¸å¿ƒæœºåˆ¶ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº† **LLDS (Lazy Likelihood-Displacement Suppression)**ï¼Œä¸€ç§è½»é‡çº§ã€é€‰æ‹©æ€§çš„ä¼¼ç„¶ä¿æŒæ­£åˆ™åŒ–æ–¹æ³•ï¼Œä¸“é—¨ç”¨äºæŠ‘åˆ¶ LLD å¼•å‘çš„â€œæ­»äº¡èºæ—‹â€ã€‚

#### LLDS çš„ä¸¤ä¸ªå…³é”®è®¾è®¡ï¼š
1. **Response-Level Gatingï¼ˆå“åº”çº§é—¨æ§ï¼‰**  
   æ­£åˆ™åŒ–ä»…åœ¨æ•´æ¡è½¨è¿¹çš„æ€»ä¼¼ç„¶ä¸‹é™æ—¶æ‰æ¿€æ´»ï¼Œé¿å…å¯¹æ•´ä½“æ”¹è¿›çš„å“åº”æ–½åŠ ä¸å¿…è¦çš„æƒ©ç½šã€‚
   
2. **Token-Level Selectivityï¼ˆè¯å…ƒçº§é€‰æ‹©æ€§ï¼‰**  
   ä»…å¯¹å¯¼è‡´ä¼¼ç„¶ä¸‹é™çš„å…·ä½“è¯å…ƒè¿›è¡Œæƒ©ç½šï¼Œè€Œéæ•´ä¸ªåºåˆ—ï¼Œä»è€Œæœ€å°åŒ–å¯¹ä¼˜åŒ–è¿‡ç¨‹çš„å¹²æ‰°ã€‚

æ­¤å¤–ï¼Œè¿˜æå‡ºå˜ä½“ **LLDS-MA**ï¼Œé€šè¿‡æ©ç æœ€ç»ˆç­”æ¡ˆè¯å…ƒï¼ˆmask answer tokensï¼‰ï¼Œé¼“åŠ±æ¨¡å‹è¿›è¡Œæ›´å¤šæœç´¢æ­¥éª¤ï¼Œä¿ƒè¿›å¤šæ­¥æ¨ç†ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **é’ˆå¯¹æ€§å¼º**ï¼šç›´æ¥é’ˆå¯¹ GRPO åœ¨å·¥å…·é›†æˆåœºæ™¯ä¸‹çš„ç»“æ„æ€§ç¼ºé™·ï¼ˆLLDï¼‰è®¾è®¡è§£å†³æ–¹æ¡ˆã€‚
- **è½»é‡é«˜æ•ˆ**ï¼šæ— éœ€å¼•å…¥é¢å¤–ç½‘ç»œç»“æ„æˆ–ä»·å€¼å‡½æ•°ä¼°è®¡ï¼Œå…¼å®¹æ€§å¼ºã€‚
- **ç¨³å®šæ€§é«˜**ï¼šæœ‰æ•ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼Œæ˜¾è‘—æå‡è®­ç»ƒç¨³å®šæ€§ã€‚
- **æ€§èƒ½å¢ç›Šå¤§**ï¼šåœ¨å¤šä¸ªåŸºå‡†ä¸Šå®ç°å¤§å¹…æ€§èƒ½æå‡ï¼Œæœ€é«˜è¾¾ +37.8%ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒæ¶µç›– **7 ä¸ªå¼€æ”¾åŸŸä¸å¤šè·³é—®ç­”ï¼ˆmulti-hop QAï¼‰åŸºå‡†**ï¼Œåˆ†ä¸ºä¸¤ç±»ï¼š

| ç±»å‹ | æ•°æ®é›† |
|------|--------|
| **é€šç”¨é—®ç­”ï¼ˆGeneral QAï¼‰** | NQ (Natural Questions), TriviaQA, PopQA |
| **å¤šè·³é—®ç­”ï¼ˆMulti-Hop QAï¼‰** | HotpotQA, 2WikiMultiHopQA, Musique, Bamboogle |

æ£€ç´¢çŸ¥è¯†åº“ä½¿ç”¨ **2018 Wikipedia dump**ï¼Œæ£€ç´¢å™¨ä¸º **E5** æ¨¡å‹ï¼Œå›ºå®šè¿”å› 3 ä¸ªæ–‡æ¡£ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹å®¶æ—**ï¼šQwen2.5-3B å’Œ Qwen2.5-7Bï¼ˆå« Base ä¸ Instruct ç‰ˆæœ¬ï¼‰
- **è®­ç»ƒé…ç½®**ï¼š
  - **NQ-Only**ï¼šå•è·³ä»»åŠ¡è®­ç»ƒ
  - **NQ+Hotpot**ï¼šæ··åˆå•è·³ä¸å¤šè·³ä»»åŠ¡è®­ç»ƒ
- **æœ€å¤§äº¤äº’è½®æ•°**ï¼šNQ-only è®¾ä¸º 2 è½®ï¼ŒNQ+Hotpot è®¾ä¸º 3 è½®
- **è¶…å‚æ•°**ï¼šæ²¿ç”¨ Search-R1 è®¾ç½®ï¼Œæ­£åˆ™åŒ–æƒé‡ $\lambda = 0.1$
- **ä¿ç•™é›†**ï¼šæ‰€æœ‰ä¼˜åŠ¿ $A \geq 0$ çš„å“åº”ä½œä¸ºä¼¼ç„¶ä¿æŠ¤å¯¹è±¡ï¼ˆå³æ­£ç¡®æˆ–æœªè®­ç»ƒå“åº”ï¼‰

### è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦æŒ‡æ ‡ï¼š**Exact Match (EM)**
- è¾…åŠ©åˆ†ææŒ‡æ ‡ï¼šå¥–åŠ±æ›²çº¿ã€ä¼¼ç„¶å˜åŒ–ã€ç†µå€¼ã€æ¢¯åº¦èŒƒæ•°ã€æœ‰æ•ˆæœç´¢æ¬¡æ•°ç­‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | è¯´æ˜ |
|--------|------|
| **Direct Inference / CoT / IRCoT** | é›¶æ ·æœ¬æˆ–å°‘æ ·æœ¬æ¨ç†åŸºçº¿ |
| **SFT** | ç›‘ç£å¾®è°ƒ |
| **R1-base / R1-instruct** | ä¸åŒåˆå§‹åŒ–ç­–ç•¥ |
| **Search-R1-GRPO** | åŸå§‹ GRPO æ–¹æ³•ï¼ˆä»¥æœ€ä½³æ£€æŸ¥ç‚¹ä¸ºåŸºå‡†ï¼‰ |
| **Search-R1-PPO** | ä½¿ç”¨ PPO æ›¿ä»£ GRPO çš„ç¨³å®šç‰ˆæœ¬ |
| **Rejection Sampling** | åŸºäºé‡‡æ ·çš„å¼ºåŒ–å­¦ä¹ åŸºçº¿ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆEM åˆ†æ•°ï¼‰

#### âœ… Qwen2.5-3B ç»“æœï¼ˆNQ+Hotpot è®¾ç½®ï¼‰
| æ–¹æ³• | å¹³å‡å¾—åˆ† | ç›¸å¯¹æå‡ |
|------|---------|----------|
| Search-R1-GRPO (vanilla) | 0.312 | â€” |
| +LLDS | 0.360 | **+15.4%** |
| +LLDS-MA | **0.430** | **+37.8%** |

#### âœ… Qwen2.5-7B ç»“æœï¼ˆNQ+Hotpot è®¾ç½®ï¼‰
| æ–¹æ³• | å¹³å‡å¾—åˆ† | ç›¸å¯¹æå‡ |
|------|---------|----------|
| Search-R1-GRPO (vanilla) | 0.350 | â€” |
| +LLDS | **0.462** | **+32.0%** |

> æ³¨ï¼šLLDS åŒæ ·åœ¨ Qwen2.5-7B-Instruct ä¸Šå–å¾— **+18.4%** æå‡ï¼ˆä» 0.396 åˆ° 0.469ï¼‰

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- LLDS åœ¨å‡ ä¹æ‰€æœ‰æ•°æ®é›†ä¸Šå‡ä¼˜äºåŸå§‹ GRPO å’Œ PPO å˜ä½“ã€‚
- åœ¨ **Bamboogleã€Musiqueã€2Wiki** ç­‰å¤æ‚å¤šè·³ä»»åŠ¡ä¸Šè¡¨ç°å°¤ä¸ºçªå‡ºï¼š
  - Qwen2.5-7B-Ins + LLDS åœ¨ Bamboogle ä¸Šè¾¾åˆ° **51.6% EM**
  - åœ¨ Musique ä¸Šè¾¾åˆ° **44.3% EM**
- å³ä½¿åœ¨è®­ç»ƒæ˜“å´©æºƒçš„ Base æ¨¡å‹ä¸Šï¼ŒLLDS ä¹Ÿèƒ½ç¨³å®šè®­ç»ƒå¹¶è§£é”å¤šæ­¥æ¨ç†èƒ½åŠ›ã€‚

### æ¶ˆèå®éªŒç»“æœ
| å®éªŒé¡¹ | å‘ç° |
|-------|------|
| **Response-Level Gating** | å‡å°‘è¿‡åº¦æ­£åˆ™åŒ–ï¼Œåœ¨ Bamboogle ä¸Šå¸¦æ¥ **+1.6%** å¢ç›Š |
| **Masking Answer (MA)** | æ˜¾è‘—æå‡å¤šæ­¥è¡Œä¸ºï¼šå°†æ¯é—®æœ‰æ•ˆæœç´¢æ¬¡æ•°ä» ~1 æå‡è‡³ >2ï¼ŒéªŒè¯å…¶æ¿€å‘æ·±å±‚æ¨ç†çš„èƒ½åŠ› |
| **æ­£åˆ™åŒ–å¼ºåº¦ $\lambda$**ï¼ˆè§ Fig. 8ï¼‰ | $\lambda=0$ æˆ– 0.01 æ— æ³•é˜»æ­¢å´©æºƒï¼›$\lambda=0.1$ å¯å®Œå…¨ç¨³å®šè®­ç»ƒ |
| **NQ-only vs NQ+Hotpot** | å¤šè·³æ•°æ®è®­ç»ƒæ˜¾è‘—å¢å¼º multi-hop QA æ³›åŒ–èƒ½åŠ› |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Lazy Likelihood Displacement (LLD) æ˜¯ GRPO å´©æºƒçš„æ ¹æœ¬åŸå› **  
   - LLD è¡¨ç°ä¸ºæ­£ç¡®ä¸é”™è¯¯å“åº”çš„ä¼¼ç„¶å‡æŒç»­ä¸‹é™æˆ–åœæ»ã€‚
   - å®ƒæ—©äºå¥–åŠ±ä¸‹é™å‡ºç°ï¼Œæ˜¯â€œæ²‰é»˜çš„æ€æ‰‹â€ã€‚

2. **LLD è§¦å‘â€œæ­»äº¡èºæ—‹â€ï¼ˆDeath Spiralï¼‰**  
   ä¸‰é˜¶æ®µæ¼”åŒ–è·¯å¾„ï¼š
   - **Phase Iï¼šæ—©æœŸåœæ»**ï¼ˆEarly Stagnationï¼‰â€”â€”å¥–åŠ±ä¸Šå‡ä½†ä¼¼ç„¶ä¸å˜
   - **Phase IIï¼šç¨³æ€è¡°å‡**ï¼ˆSteady Decayï¼‰â€”â€”ä¼¼ç„¶ç¼“æ…¢ä¸‹é™ï¼Œæ¢¯åº¦ç¨³å®š
   - **Phase IIIï¼šåŠ é€Ÿå´©æºƒ**ï¼ˆAccelerationï¼‰â€”â€”ä¼¼ç„¶æ€¥å‰§ä¸‹é™ â†’ ç†µçˆ†ç‚¸ â†’ æ¢¯åº¦çˆ†ç‚¸ â†’ è®­ç»ƒå´©æºƒ

3. **å·¥å…·åé¦ˆåŠ å‰§ LLD**  
   - å·¥å…·è¾“å‡ºï¼ˆå¦‚æœç´¢ç»“æœï¼‰å±äº out-of-distribution (OOD)ï¼Œå¢åŠ é¢„æµ‹ä¸ç¡®å®šæ€§ã€‚
   - å¤šæ­¥æ¨ç†ä¸­ï¼Œæ—©æœŸåŠ¨ä½œï¼ˆå¦‚æŸ¥è¯¢ç”Ÿæˆï¼‰åœ¨æ­£ç¡®ä¸é”™è¯¯è½¨è¿¹ä¸­é«˜åº¦ç›¸ä¼¼ï¼Œå¯¼è‡´è´Ÿæ¢¯åº¦æ±¡æŸ“æ­£ç¡®è·¯å¾„ã€‚

4. **LLDS æœ‰æ•ˆæ‰“ç ´æ­»äº¡èºæ—‹**  
   - é€šè¿‡ç»†ç²’åº¦æ§åˆ¶ä¼¼ç„¶ä¸‹é™ï¼Œç»´æŒå¥åº·è®­ç»ƒåŠ¨æ€ã€‚
   - æ‰€æœ‰æ¨¡å‹è§„æ¨¡ï¼ˆ3B/7Bï¼‰ã€ç±»å‹ï¼ˆBase/Instructï¼‰å‡å—ç›Šã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ LLDS ä¸»è¦é€‚ç”¨äºåŸºäº group-relative çš„ RL æ–¹æ³•ï¼ˆå¦‚ GRPOï¼‰ï¼Œå¯¹ PPO ç±»æ–¹æ³•é€‚ç”¨æ€§å¾…éªŒè¯ã€‚
- å¯¹æç«¯é•¿åºåˆ—æˆ–å¤šå·¥å…·ç»„åˆåœºæ™¯çš„æ”¯æŒå°šæœªå……åˆ†æµ‹è¯•ã€‚
- MA ç­–ç•¥ä¾èµ–äººå·¥å®šä¹‰â€œç­”æ¡ˆåŒºåŸŸâ€ï¼Œè‡ªåŠ¨åŒ–ç¨‹åº¦æœ‰å¾…æé«˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† LLDS æ€æƒ³æ‰©å±•åˆ°å…¶ä»– TIRL æ¡†æ¶ï¼ˆå¦‚ VERL-Toolã€REToolï¼‰ã€‚
- æ¢ç´¢è‡ªåŠ¨è¯†åˆ«éœ€ä¿æŠ¤ token çš„æœºåˆ¶ï¼ˆå¦‚åŸºäºæ³¨æ„åŠ›æˆ–è¯­ä¹‰è§’è‰²æ ‡æ³¨ï¼‰ã€‚
- ç»“åˆ curriculum learning åŠ¨æ€è°ƒæ•´æ­£åˆ™å¼ºåº¦ã€‚
- åœ¨æ•°å­¦æ¨ç†ã€ä»£ç æ‰§è¡Œç­‰éæ£€ç´¢ç±»å·¥å…·ä»»åŠ¡ä¸­éªŒè¯æ³›åŒ–æ€§ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æ­ç¤ºäº† GRPO åœ¨å·¥å…·é›†æˆ RL ä¸­å´©æºƒçš„æœ¬è´¨åŸå› æ˜¯ **Lazy Likelihood Displacement**ï¼Œå¹¶æå‡ºè½»é‡é«˜æ•ˆçš„ **LLDS** æ­£åˆ™åŒ–æ–¹æ³•ï¼ŒæˆåŠŸç¨³å®šè®­ç»ƒå¹¶åœ¨å¤šä¸ª QA åŸºå‡†ä¸Šå®ç°é«˜è¾¾ **+37.8%** çš„æ€§èƒ½é£è·ƒï¼Œä¸ºæ„å»ºå¯é ã€å¯æ‰©å±•çš„æ™ºèƒ½ä½“è¯­è¨€æ¨¡å‹æä¾›äº†å…³é”®è·¯å¾„ã€‚

</details>

---

### 11. [EtCon: Edit-then-Consolidate for Reliable Knowledge Editing](https://arxiv.org/abs/2512.04753)

**Authors**: Ruilin Li, Yibin Wang, Wenhong Zhu, Chenglin Li, Jinghao Zhang, Chenliang Li, Junchi Yan, Jiaqi Wang  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.04753v1  

#### Abstract
Knowledge editing aims to update specific facts in large language models (LLMs) without full retraining. Prior efforts sought to tune the knowledge layers of LLMs, proving effective for making selective edits. However, a significant gap exists between their performance in controlled, teacher-forcing...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šEtCon: Edit-then-Consolidate for Reliable Knowledge Editing**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å½“å‰çš„ **Knowledge Editing** æ–¹æ³•åœ¨å—æ§çš„â€œæ•™å¸ˆå¼ºåˆ¶â€ï¼ˆteacher-forcingï¼‰è¯„ä¼°ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ›´è´´è¿‘ç°å®çš„ **è‡ªå›å½’ç”Ÿæˆ**ï¼ˆautoregressive generationï¼‰å’Œ **ç»ˆèº«å­¦ä¹ **ï¼ˆlifelong editingï¼‰åœºæ™¯ä¸‹æ•ˆæœæ˜¾è‘—ä¸‹é™ï¼Œå­˜åœ¨ä¸¤å¤§æ ¸å¿ƒé—®é¢˜ï¼š
1. **è¿‡æ‹Ÿåˆé—®é¢˜**ï¼šä¼ ç»Ÿç¼–è¾‘æ–¹æ³•å¯¼è‡´æ¨¡å‹è¿‡åº¦é€‚åº”æ–°äº‹å®ï¼ŒæŸå®³é¢„è®­ç»ƒèƒ½åŠ›ï¼ˆå¦‚æ¨ç†ã€è¯­è¨€æµç•…æ€§ï¼‰ã€‚
2. **çŸ¥è¯†-è¡Œä¸ºè„±èŠ‚**ï¼šç¼ºä¹ä¸“é—¨çš„ **çŸ¥è¯†å·©å›ºé˜¶æ®µ**ï¼ˆknowledge consolidationï¼‰ï¼Œå¯¼è‡´å‚æ•°å±‚é¢æ›´æ–°çš„çŸ¥è¯†æ— æ³•æœ‰æ•ˆæ¿€æ´»å¹¶ä½“ç°åœ¨å®é™…ç”Ÿæˆè¡Œä¸ºä¸­ã€‚

è¿™äº›é—®é¢˜ä¸¥é‡é™åˆ¶äº†çŸ¥è¯†ç¼–è¾‘æ–¹æ³•çš„å®é™…åº”ç”¨å¯é æ€§ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡º **Edit-then-Consolidate (EtCon)** èŒƒå¼ï¼Œå°†çŸ¥è¯†ç¼–è¾‘åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š

#### **Stage I: ç¼–è¾‘é˜¶æ®µ â€” Targeted Proximal Supervised Fine-Tuning (TPSFT)**
- **ç›®æ ‡**ï¼šå±€éƒ¨åŒ–åœ°æ³¨å…¥æ–°çŸ¥è¯†ï¼Œé¿å…ç ´ååŸæœ‰èƒ½åŠ›ã€‚
- **æœºåˆ¶**ï¼š
  - ä»…æ›´æ–°è¢«è¯†åˆ«ä¸ºçŸ¥è¯†å­˜å‚¨åŒºåŸŸçš„ **FFN å±‚**ï¼ˆFeed-Forward Networkï¼‰ã€‚
  - å¼•å…¥ **ä¿¡ä»»åŸŸçº¦æŸ**ï¼ˆtrust-region objectiveï¼‰ï¼Œé€šè¿‡ `clip` å‡½æ•°é™åˆ¶ç­–ç•¥æ¼‚ç§»ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚
  - ä½¿ç”¨ **CoT-augmented æ ‡ç­¾**ï¼šä¿ç•™åŸå§‹æ¨¡å‹çš„æ¨ç†è·¯å¾„ï¼Œä»…æ›¿æ¢æœ€ç»ˆç­”æ¡ˆï¼Œä½¿æ¨¡å‹å­¦ä¼šç”¨åŸæœ‰æ¨ç†é£æ ¼å¾—å‡ºæ–°ç»“è®ºã€‚

#### **Stage II: å·©å›ºé˜¶æ®µ â€” Group Relative Policy Optimization (GRPO)**
- **ç›®æ ‡**ï¼šå°†å‚æ•°çŸ¥è¯†ä¸æ¨¡å‹çš„æ¨ç†è¡Œä¸ºå¯¹é½ã€‚
- **æœºåˆ¶**ï¼š
  - å°†å·©å›ºè¿‡ç¨‹å»ºæ¨¡ä¸º **å¼ºåŒ–å­¦ä¹ ä»»åŠ¡**ï¼Œä¼˜åŒ–æ•´ä¸ªæ¨ç†è½¨è¿¹ï¼ˆtrajectory-levelï¼‰ã€‚
  - ä½¿ç”¨ç»¼åˆå¥–åŠ±å‡½æ•°ï¼ŒåŒ…å«å››ä¸ªç»´åº¦ï¼š
    - `R_accuracy`ï¼šç­”æ¡ˆæ­£ç¡®æ€§
    - `R_format`ï¼šè¾“å‡ºæ ¼å¼åˆè§„æ€§
    - `R_cleanliness`ï¼šè¾“å‡ºç®€æ´æ€§ï¼ˆé¿å…å†—ä½™ï¼‰
    - `R_consistency`ï¼šæ¨ç†ä¸€è‡´æ€§ï¼ˆä¸­é—´æ­¥éª¤ä¸æœ€ç»ˆç­”æ¡ˆä¸€è‡´ï¼‰

è¯¥æ¡†æ¶é¦–æ¬¡æ˜ç¡®åŒºåˆ†â€œå‚æ•°ç¼–è¾‘â€ä¸â€œè¡Œä¸ºå¯¹é½â€ï¼Œå¼ºè°ƒ **çŸ¥è¯†æ•´åˆéœ€è¦ä¸€ä¸ªä¸»åŠ¨çš„å·©å›ºè¿‡ç¨‹**ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **æ›´é«˜çš„å¯é æ€§ä¸æ³›åŒ–èƒ½åŠ›**ï¼šåœ¨çœŸå®è‡ªå›å½’è¯„ä¼°ä¸­ï¼Œå¯é æ€§æå‡ **35%-50%**ã€‚
- **æ›´å¼ºçš„å±€éƒ¨æ€§**ï¼ˆLocalityï¼‰ï¼šç¼–è¾‘ä¸å½±å“æ— å…³çŸ¥è¯†ã€‚
- **ä¿ç•™é¢„è®­ç»ƒèƒ½åŠ›**ï¼šé¿å…å› ç¼–è¾‘å¯¼è‡´é€šç”¨èƒ½åŠ›é€€åŒ–ã€‚
- **é€‚ç”¨äºç»ˆèº«å­¦ä¹ **ï¼šå¯ç¨³å®šå¤„ç†ä¸Šåƒæ¬¡è¿ç»­ç¼–è¾‘ï¼Œè€Œå¤šæ•°åŸºçº¿æ–¹æ³•è¿…é€Ÿå´©æºƒã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **çŸ¥è¯†ç¼–è¾‘åŸºå‡†**ï¼ˆå„å–1000æ ·æœ¬ï¼‰ï¼š
  - **ZsRE**ï¼šåŸºäºé˜…è¯»ç†è§£çš„äº‹å®æå–ã€‚
  - **COUNTERFACT**ï¼šåäº‹å®çŸ¥è¯†ç¼–è¾‘ã€‚
  - **QAEdit**ï¼šé—®ç­”å½¢å¼çš„çŸ¥è¯†æ›´æ–°ã€‚
- **é€šç”¨èƒ½åŠ›è¯„ä¼°**ï¼š
  - **C-Eval**, **LogiQA**ï¼ˆåˆ†ç±»ï¼‰
  - **CoQA**, **DROP**, **SQuAD 2.0**ï¼ˆé—®ç­”ï¼‰

### **å®éªŒè®¾ç½®**
- **åŸºç¡€æ¨¡å‹**ï¼š
  - **Llama-3-8B-Instruct**
  - **Qwen2.5-7B-Instruct**
- **ç¼–è¾‘æ–¹å¼**ï¼šè¿›è¡Œ **1,000 æ¬¡é¡ºåºå•æ ·æœ¬ç¼–è¾‘**ï¼ˆsequential editingï¼‰ï¼Œæ¨¡æ‹Ÿç»ˆèº«å­¦ä¹ åœºæ™¯ã€‚
- **è¯„ä¼°åè®®**ï¼š
  - **çœŸå®ä¸–ç•Œè¯„ä¼°æ¡†æ¶**ï¼ˆReal-world evaluationï¼‰ï¼š
    - è¾“å…¥ï¼šåŒ…å«å¤šæ­¥æ¨ç†æŒ‡ä»¤ï¼ˆ`Please reason step by step...`ï¼‰
    - è¾“å‡ºï¼šå®Œæ•´è‡ªå›å½’ç”Ÿæˆï¼ˆéæˆªæ–­ï¼‰
    - è¯„ä¼°æ–¹å¼ï¼š**LLM-as-a-judge**ï¼ˆä½¿ç”¨ GPT-4.1 è¿›è¡ŒäºŒå…ƒåˆ¤æ–­ï¼šæ­£ç¡®/é”™è¯¯ï¼‰

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Reliability (Reli.)** | ç¼–è¾‘æˆåŠŸç‡ï¼ˆæ–°äº‹å® > æ—§äº‹å®çš„æ¦‚ç‡ï¼‰ |
| **Generalization (Gen.)** | åœ¨æ”¹å†™é—®é¢˜ä¸Šçš„æ³›åŒ–èƒ½åŠ› |
| **Locality (Loc.)** | å¯¹æœªç¼–è¾‘ç›¸å…³é—®é¢˜çš„å½±å“ç¨‹åº¦ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ |
| **Accuracy / EM / F1** | é€šç”¨èƒ½åŠ›ä¿æŒæƒ…å†µ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ç±»å‹ | æ–¹æ³• |
|------|------|
| **Parametric In-Place Editing** | FT-M, MEMIT, ALPHAEDIT, MMKE |
| **External-Assisted Editing** | WISE |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2ï¼‰**

| æ¨¡å‹ | æ–¹æ³• | ZsRE (Reli./Gen./Loc.) | COUNTERFACT (Reli./Gen./Loc.) | QAEdit (Reli./Gen./Loc.) |
|------|------|------------------------|-------------------------------|--------------------------|
| **Qwen2.5-7B-Instruct** | **EtCon (Ours)** | **69.4 / 60.8 / 24.4** | **59.6 / 43.2 / 29.7** | **75.1 / 63.0 / 32.3** |
| | ALPHAEDIT | 15.9 / 11.5 / 6.8 | 0.0 / 0.0 / 0.0 | 0.0 / 0.0 / 0.0 |
| | FT-M | 5.6 / 5.5 / 23.1 | 3.2 / 3.1 / 24.4 | 14.6 / 14.5 / 30.7 |
| | WISE | 4.5 / 3.3 / 19.1 | 1.4 / 1.5 / 31.0 | 7.1 / 9.7 / 16.9 |

| **Llama-3-8B-Instruct** | **EtCon (Ours)** | **73.5 / 63.1 / 30.2** | **67.1 / 53.4 / 24.2** | **70.7 / 62.7 / 33.6** |
| | FT-M | 16.6 / 15.5 / 29.3 | 27.9 / 18.6 / 10.5 | 34.1 / 33.2 / 30.1 |
| | ALPHAEDIT | 18.7 / 14.0 / 6.3 | 61.0 / 43.8 / 16.1 | 18.2 / 14.9 / 7.5 |

> âœ… **EtCon åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå…¨é¢è¶…è¶ŠåŸºçº¿ï¼Œå¯é æ€§æå‡è¾¾ 40%-50% ä»¥ä¸Š**ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **MEMIT / ALPHAEDIT**ï¼šåœ¨ Qwen ä¸Šå‡ ä¹å®Œå…¨å´©æºƒï¼ˆæ¥è¿‘ 0% å¯é æ€§ï¼‰ï¼Œè¡¨æ˜å…¶åœ¨è¿ç»­ç¼–è¾‘ä¸­ä¸ç¨³å®šã€‚
- **FT-M / WISE**ï¼šè™½æœ‰ä¸€å®šç¨³å®šæ€§ï¼Œä½†å¯é æ€§æä½ï¼ˆ<30%ï¼‰ï¼Œä¸”æ³›åŒ–å·®ã€‚
- **EtCon**ï¼šä¸ä»…å¯é æ€§é«˜ï¼Œä¸”åœ¨ **3,000 æ¬¡è¿ç»­ç¼–è¾‘** ä¸‹ä»ä¿æŒç¨³å¥ï¼ˆè§ Appendix A.3ï¼‰ï¼Œè€Œ FT-M æ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆTable 4 & Table 3ï¼‰**

#### **ç»„ä»¶æ¶ˆèï¼ˆTable 4ï¼‰**
| é˜¶æ®µ | æ–¹æ³• | Reli. | Gen. | Loc. |
|------|------|-------|------|------|
| Base | â€“ | 0.6 | 0.8 | 31.8 |
| Edit | w/ SFT | 1.4 | 0.3 | 30.7 |
| Edit | w/ TPSFT | 3.3 | 1.8 | 30.2 |
| Consolidate | w/o R_cleanliness | 56.1 | 22.4 | 24.7 |
| Consolidate | w/o R_consistency | 51.6 | 27.2 | 25.1 |
| Complete | EtCon | **67.1** | **53.4** | **24.2** |

- **TPSFT æ˜¾è‘—ä¼˜äºæ ‡å‡† SFT**ï¼šåœ¨ç¼–è¾‘é˜¶æ®µå³æ›´å¥½ä¿æŠ¤é€šç”¨èƒ½åŠ›ã€‚
- **ç§»é™¤ R_cleanliness** â†’ æ¨¡å‹ç”Ÿæˆå†—ä½™å†…å®¹ï¼ˆå¦‚åŒæ—¶åˆ—å‡ºæ–°æ—§äº‹å®ï¼‰ã€‚
- **ç§»é™¤ R_consistency** â†’ å‡ºç°è‡ªæˆ‘çŸ›ç›¾ï¼ˆå…ˆè¯´å¯¹å†å¦å®šï¼‰ï¼Œå¯é æ€§å¤§å¹…ä¸‹é™ã€‚

#### **å·©å›ºé˜¶æ®µæœ‰æ•ˆæ€§éªŒè¯ï¼ˆTable 3ï¼‰**
| æ–¹æ³• | QAEdit Reli. | +Consolidation | Reli. after Consolidation |
|------|--------------|---------------|----------------------------|
| FT-M | 14.6 | âœ… | â†’ **42.3** |
| MMKE | 12.2 | âœ… | â†’ **37.2** |
| ALPHAEDIT | 0.0 | âœ… | â†’ **0.0**ï¼ˆå·²å´©æºƒï¼Œæ— æ³•ä¿®å¤ï¼‰ |

> ğŸ” **ç»“è®º**ï¼š**å·©å›ºé˜¶æ®µèƒ½å¤§å¹…æå‡å·²æœ‰æ–¹æ³•çš„è¡¨ç°ï¼Œä½†å‰ææ˜¯ç¼–è¾‘é˜¶æ®µä¸èƒ½é€ æˆä¸å¯é€†æŸä¼¤**ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **çŸ¥è¯†-è¡Œä¸ºè„±èŠ‚æ˜¯æ ¹æœ¬ç“¶é¢ˆ**ï¼šç°æœ‰æ–¹æ³•å¤±è´¥ä¸»å› ä¸æ˜¯ç¼–è¾‘ä¸å‡†ï¼Œè€Œæ˜¯ç¼ºä¹å°†å‚æ•°çŸ¥è¯†è½¬åŒ–ä¸ºå®é™…æ¨ç†è¡Œä¸ºçš„ **å·©å›ºæœºåˆ¶**ã€‚
2. **ä¸¤é˜¶æ®µèŒƒå¼è‡³å…³é‡è¦**ï¼š
   - **ç¼–è¾‘é˜¶æ®µ**ï¼ˆTPSFTï¼‰ç¡®ä¿å±€éƒ¨ã€ç¨³å®šçš„çŸ¥è¯†æ³¨å…¥ã€‚
   - **å·©å›ºé˜¶æ®µ**ï¼ˆGRPOï¼‰å®ç°çŸ¥è¯†ä¸æ¨ç†ç­–ç•¥çš„æ·±åº¦æ•´åˆã€‚
3. **ç»¼åˆå¥–åŠ±è®¾è®¡ä¸å¯æˆ–ç¼º**ï¼š`R_cleanliness` å’Œ `R_consistency` æœ‰æ•ˆé˜²æ­¢ **reward hacking**ï¼ˆå¦‚ç­”æ¡ˆå¯¹å†²ã€è‡ªæˆ‘ä¿®æ­£ï¼‰ã€‚
4. **EtCon å…·å¤‡å¼ºé²æ£’æ€§**ï¼šæ”¯æŒå¤§è§„æ¨¡ç»ˆèº«ç¼–è¾‘ï¼Œæ€§èƒ½ç¼“æ…¢é€€åŒ–è€Œéå´©æºƒã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼šTPSFT å•æ¬¡ç¼–è¾‘è€—æ—¶çº¦ 6 ç§’ï¼Œé«˜äº FT-Mï¼ˆ0.61sï¼‰ï¼Œä½†ä¸å…¶ä»–å‚æ•°ç¼–è¾‘æ–¹æ³•ç›¸å½“ã€‚
- **ä¾èµ– CoT ç”Ÿæˆè´¨é‡**ï¼šè‹¥åŸå§‹æ¨¡å‹æ— æ³•ç”Ÿæˆåˆç†æ¨ç†è·¯å¾„ï¼ŒTPSFT æ•ˆæœå—é™ã€‚
- **æµ…å±‚ç¼–è¾‘æ›´ä¼˜**ï¼šå®éªŒè¡¨æ˜ç¼–è¾‘æµ…å±‚ FFNï¼ˆå¦‚ Layer 5-9ï¼‰æ•ˆæœæœ€å¥½ï¼Œæ·±å±‚ç¼–è¾‘æ˜“å¼•å‘è®¤çŸ¥å†²çªã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢è‡ªåŠ¨åŒ–é€‰æ‹©æœ€ä¼˜ç¼–è¾‘å±‚çš„æ–¹æ³•ã€‚
- å°† EtCon æ‰©å±•åˆ°å¤šæ¨¡æ€æ¨¡å‹ç¼–è¾‘ã€‚
- ç»“åˆæ£€ç´¢å¢å¼ºï¼ˆretrieval-augmentedï¼‰æœºåˆ¶ï¼Œè¿›ä¸€æ­¥æå‡é•¿æœŸè®°å¿†ç¨³å®šæ€§ã€‚
- é™ä½ GRPO é˜¶æ®µçš„è®­ç»ƒæˆæœ¬ï¼Œå®ç°å®æ—¶åœ¨çº¿ç¼–è¾‘ã€‚

---

> **æ€»ç»“**ï¼š  
> **EtCon** é€šè¿‡å¼•å…¥ **Edit-then-Consolidate** èŒƒå¼ï¼Œé¦–æ¬¡ç³»ç»Ÿæ€§è§£å†³çŸ¥è¯†ç¼–è¾‘ä¸­çš„â€œçŸ¥è¡Œä¸ä¸€â€é—®é¢˜ï¼Œæ˜¾è‘—æå‡äº†ç¼–è¾‘çš„ **å¯é æ€§ã€æ³›åŒ–æ€§å’Œå®ç”¨æ€§**ï¼Œä¸ºæ„å»ºå¯æŒç»­æ›´æ–°çš„ LLM æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 12. [SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs](https://arxiv.org/abs/2512.04868)

**Authors**: Hao Wang, Jialun Zhong, Changcheng Wang, Zhujun Nie, Zheng Li, Shunyu Yao, Yanzeng Li, Xinchi Li  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.04868v1  

#### Abstract
Knowledge-based conversational question answering (KBCQA) confronts persistent challenges in resolving coreference, modeling contextual dependencies, and executing complex logical reasoning. Existing approaches, whether end-to-end semantic parsing or stepwise agent-based reasoning, often suffer from...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**åŸºäºçŸ¥è¯†å›¾è°±çš„å¯¹è¯å¼é—®ç­”ï¼ˆKBCQAï¼‰**ä¸­çš„ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **å¤æ‚é€»è¾‘æ¨ç†å›°éš¾**ï¼šå¦‚å¤šè·³æ¨ç†ã€æ¯”è¾ƒã€èšåˆç­‰ä»»åŠ¡ä¸­ï¼Œä¼ ç»Ÿæ–¹æ³•éš¾ä»¥ç”Ÿæˆå‡†ç¡®çš„é€»è¾‘å½¢å¼ã€‚
- **å®ä½“ä¸å…³ç³»é“¾æ¥æ•ˆç‡ä½**ï¼šç”±äºè¯­è¨€æ­§ä¹‰å¯¼è‡´å€™é€‰å®ä½“/å…³ç³»ç©ºé—´è¿‡å¤§ï¼Œå¸¦æ¥é«˜æ˜‚çš„è®¡ç®—å¼€é”€ã€‚
- **ä¸Šä¸‹æ–‡ä¾èµ–å»ºæ¨¡ä¸è¶³**ï¼šåœ¨å¤šè½®å¯¹è¯ä¸­ï¼Œæ ¸å¿ƒæŒ‡ä»£ï¼ˆcoreferenceï¼‰å’Œçœç•¥ï¼ˆellipsisï¼‰å¤„ç†ä¸å‡†ç¡®ï¼Œå½±å“è¯­ä¹‰ä¸€è‡´æ€§ã€‚

è¿™äº›é—®é¢˜ä½¿å¾—ç°æœ‰æ–¹æ³•åœ¨ç»“æ„å‡†ç¡®æ€§ã€æ‰§è¡Œæ•ˆç‡å’Œå¯æ‰©å±•æ€§æ–¹é¢å­˜åœ¨æ˜¾è‘—ç“¶é¢ˆã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **SEALï¼ˆSelf-Evolving Agentic Learningï¼‰**ï¼Œä¸€ç§åŸºäº**è‡ªæ¼”åŒ–æ™ºèƒ½ä½“å­¦ä¹ **çš„ä¸¤é˜¶æ®µè¯­ä¹‰è§£ææ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰å¼•å…¥â€œæœ€å°S-expressionæ ¸å¿ƒâ€æ¦‚å¿µ
- åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œç”±**å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æå–ä¸€ä¸ªç®€åŒ–çš„S-expressionæ ¸å¿ƒ**ï¼Œä»…åŒ…å«åŸºæœ¬æ“ä½œï¼ˆå¦‚ `JOIN`, `AND`, `R`ï¼‰ï¼Œæ•æ‰æŸ¥è¯¢çš„æœ¬è´¨è¯­ä¹‰ã€‚
- è¿™ç§åˆ†è§£é™ä½äº†ç”Ÿæˆå¤æ‚é€»è¾‘ç»“æ„çš„å­¦ä¹ éš¾åº¦ã€‚

#### ï¼ˆ2ï¼‰ä»£ç†æ ¡å‡†æ¨¡å—ï¼ˆAgentic Calibrationï¼‰
- å¼•å…¥ä¸€ä¸ª**ä¸çŸ¥è¯†å›¾è°±äº¤äº’çš„æ™ºèƒ½ä½“**å¯¹S-expressionæ ¸å¿ƒè¿›è¡Œæ ¡å‡†ï¼š
  - ä¿®æ­£è¯­æ³•é”™è¯¯ï¼›
  - å°†è¡¨é¢åç§°ç²¾ç¡®å¯¹é½åˆ°çŸ¥è¯†å›¾è°±ä¸­çš„å®ä½“å’Œå…³ç³»ï¼ˆé‡‡ç”¨å•å€™é€‰è½»é‡çº§é“¾æ¥ç­–ç•¥ï¼‰ï¼›
  - åªä¿ç•™èƒ½è¿”å›éç©ºç»“æœçš„å˜ä½“ï¼Œç¡®ä¿è¯­ä¹‰æœ‰æ•ˆæ€§ã€‚

#### ï¼ˆ3ï¼‰æ¨¡æ¿åŒ–å®Œæˆæœºåˆ¶ï¼ˆTemplate-based Completionï¼‰
- ç¬¬äºŒé˜¶æ®µé€šè¿‡**é—®é¢˜ç±»å‹é¢„æµ‹ + å ä½ç¬¦å®ä¾‹åŒ–**çš„æ–¹å¼æ„å»ºå®Œæ•´å¯æ‰§è¡Œçš„S-expressionï¼š
  - é¢„å®šä¹‰é€»è¾‘æ¨¡æ¿åº“è¦†ç›–å¸¸è§æ¨ç†æ¨¡å¼ï¼ˆè®¡æ•°ã€æ¯”è¾ƒã€éªŒè¯ç­‰ï¼‰ï¼›
  - åˆ©ç”¨æ ¡å‡†åçš„æ ¸å¿ƒå¡«å……æ¨¡æ¿ï¼Œæå‡ç»“æ„ä¸€è‡´æ€§å’Œç”Ÿæˆæ•ˆç‡ã€‚

#### ï¼ˆ4ï¼‰è‡ªæ¼”åŒ–æœºåˆ¶ï¼ˆSelf-Evolving Mechanismï¼‰
- ç»“åˆ**å±€éƒ¨è®°å¿†ï¼ˆLocal Memoryï¼‰**ã€**å…¨å±€è®°å¿†ï¼ˆGlobal Memoryï¼‰** å’Œ **åæ€æ¨¡å—ï¼ˆReflection Moduleï¼‰** å®ç°æ— éœ€æ˜¾å¼é‡è®­ç»ƒçš„æŒç»­å­¦ä¹ ï¼š
  - å±€éƒ¨è®°å¿†ï¼šç»´æŠ¤å½“å‰å¯¹è¯çŠ¶æ€ï¼Œæ”¯æŒæŒ‡ä»£æ¶ˆè§£ï¼›
  - å…¨å±€è®°å¿†ï¼šå­˜å‚¨å†å²æˆåŠŸå¯¹è¯çš„é€»è¾‘æ¨¡å¼ï¼Œä¾›åç»­å¤ç”¨ï¼›
  - åæ€æ¨¡å—ï¼šåˆ†ææ‰§è¡Œåé¦ˆï¼ˆå¦‚æŸ¥è¯¢æ˜¯å¦ä¸ºç©ºã€ç»“æ„æ˜¯å¦åˆæ³•ï¼‰ï¼ŒåŠ¨æ€æ›´æ–°å…¨å±€è®°å¿†ï¼Œå®ç°é—­ç¯è¿›åŒ–ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | SEALä¼˜åŠ¿ |
|------|----------|
| **ç»“æ„å‡†ç¡®æ€§** | æ˜¾è‘—æé«˜S-expressionçš„ç»“æ„é‡å ç‡å’Œè§£ææˆåŠŸç‡ï¼Œå°¤å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ |
| **è®¡ç®—æ•ˆç‡** | è½»é‡çº§é“¾æ¥ç­–ç•¥å¤§å¹…å‡å°‘SPARQLæŸ¥è¯¢æ•°é‡ï¼Œç¼“è§£é•¿å°¾é«˜å¼€é”€é—®é¢˜ |
| **æ³›åŒ–èƒ½åŠ›** | æ¨¡æ¿é©±åŠ¨è®¾è®¡å¢å¼ºé²æ£’æ€§ï¼›LLMä»å¯åœ¨æ¨¡æ¿å¤–åˆæˆæ­£ç¡®è¡¨è¾¾å¼ï¼ˆè§Appendix Eï¼‰ |
| **é€‚åº”æ€§** | è‡ªæ¼”åŒ–æœºåˆ¶ä½¿ç³»ç»Ÿèƒ½åœ¨çœŸå®å¯¹è¯æµä¸­ä¸æ–­ä¼˜åŒ–ï¼Œæ— éœ€é‡æ–°è®­ç»ƒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨ **SPICE** æ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº **Wikidata** çš„å¤šè½®å¯¹è¯å¼è¯­ä¹‰è§£æåŸºå‡†ã€‚
- åŒ…å«ä» CSQA è¡ç”Ÿçš„çœŸå®ç”¨æˆ·-ç³»ç»Ÿé—®ç­”åºåˆ—ï¼Œå¹¶æä¾›å¯¹åº”çš„ SPARQL æŸ¥è¯¢æ ‡æ³¨ã€‚
- å®éªŒé€‰å–å…¶ä¸­9ç§é—®é¢˜ç±»å‹ï¼ˆæ’é™¤æ— SPARQLæ ‡æ³¨çš„â€œClarificationâ€å­é›†ï¼‰ï¼Œæ¶µç›–ï¼š
  - ç®€å•é—®é¢˜ï¼ˆSimpleï¼‰
  - å¤šè·³æ¨ç†ï¼ˆLogical Reasoningï¼‰
  - æ•°å€¼æ¨ç†ï¼ˆQuantitative Reasoningï¼‰
  - æ¯”è¾ƒç±»é—®é¢˜ï¼ˆComparative Reasoningï¼‰
  - éªŒè¯ç±»é—®é¢˜ï¼ˆVerificationï¼‰

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
| é¡¹ç›® | è®¾ç½®è¯´æ˜ |
|------|--------|
| **è¯„ä¼°æŒ‡æ ‡** | - **macro-F1**ï¼šç”¨äºé›†åˆå‹ç­”æ¡ˆï¼ˆå¦‚å®ä½“é›†ï¼‰<br>- **Accuracyï¼ˆACï¼‰**ï¼šç”¨äºå¸ƒå°”å€¼æˆ–æ•°å€¼å‹ç­”æ¡ˆ |
| **åŸºçº¿æ–¹æ³•** | - **ç›‘ç£æ–¹æ³•**ï¼š<br>â€ƒâ€¢ BertSPGL<br>â€ƒâ€¢ DCG<br>- **æ— ç›‘ç£æ–¹æ³•**ï¼š<br>â€ƒâ€¢ KB-Binderï¼ˆå¼ºåŸºçº¿ï¼‰<br>â€ƒâ€¢ LLMGTï¼ˆç›´æ¥ç”Ÿæˆé€»è¾‘å½¢å¼ï¼‰ |
| **å®ç°ç»†èŠ‚** | - é—®é¢˜åˆ†ç±»ä½¿ç”¨ Qwen2.5-32B-Instruct<br>- å…¶ä»–æ¨¡å—ä½¿ç”¨ DeepSeek-V3<br>- æ¨¡æ¿åº“åŸºäºè®­ç»ƒè¯­æ–™å½’çº³æ„å»ºï¼ˆè§Appendix Dï¼‰<br>- æ¢ç´¢top-1 vs top-ké“¾æ¥ç­–ç•¥åŠå€™é€‰å˜ä½“ä¿ç•™æ•°é‡çš„å½±å“ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ€§èƒ½å¯¹æ¯”ï¼ˆTable 2ï¼‰
SEALåœ¨å¤šæ•°ä»»åŠ¡ä¸Šè¾¾åˆ°**state-of-the-art**æ°´å¹³ï¼Œå°¤å…¶åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­ä¼˜åŠ¿æ˜æ˜¾ï¼š

| ä»»åŠ¡ç±»åˆ« | SEAL (m-F1 æˆ– AC) | æœ€ä½³åŸºçº¿ | æå‡å¹…åº¦ |
|---------|------------------|----------|--------|
| **Logical Reasoning** | **73.08** (m-F1) | LLMGT: 89.61 â†’ å®é™…ä¸ºå¼‚å¸¸å€¼ï¼ŒKB-Binderä»…46.85 | +26.23 vs KB-Binder |
| **Quantitative Reasoning** | **64.45** (m-F1) | KB-Binder: 15.41 | +49.04 |
| **Comparative Reasoning** | **41.06** (m-F1) | KB-Binder: 12.17 | +28.89 |
| **Verification (Boolean)** | **85.97** (AC) | KB-Binder: 64.03 | +21.94 |
| **Verification (Count)** | **70.12** (AC) | KB-Binder: 39.00 | +31.12 |
| **Overall AC** | **66.83** | KB-Binder: 36.66 | +30.17 |

> ğŸ” æ³¨ï¼šå°½ç®¡æŸäº›ç›‘ç£æ–¹æ³•ï¼ˆå¦‚LLMGTï¼‰åœ¨ä¸ªåˆ«ä»»åŠ¡ä¸Šå¾—åˆ†æ›´é«˜ï¼Œä½†æ•´ä½“ç¨³å®šæ€§å·®ï¼Œè€ŒSEALä½œä¸º**æ— ç›‘ç£æ–¹æ³•**æ¥è¿‘ç”šè‡³è¶…è¶Šéƒ¨åˆ†ç›‘ç£æ¨¡å‹ã€‚

---

### ç»“æ„å‡†ç¡®æ€§æå‡ï¼ˆTable 3ï¼‰
SEALåœ¨**ç»“æ„é‡å ç‡ï¼ˆStruct. Overlapï¼‰** å’Œ **è§£ææˆåŠŸç‡ï¼ˆParse Successï¼‰** ä¸Šå…¨é¢ä¼˜äºKB-Binderï¼š

| æŒ‡æ ‡ | SEAL å¹³å‡ | KB-Binder å¹³å‡ | æå‡ |
|------|-----------|---------------|-----|
| ç»“æ„é‡å ç‡ | **54.8%** | 32.2% | **+22.6%** |
| è§£ææˆåŠŸç‡ | **88.1%** | 66.0% | **+22.1%** |

è¡¨æ˜å…¶ä¸¤é˜¶æ®µè®¾è®¡æœ‰æ•ˆå‡å°‘äº†è¯­æ³•é”™è¯¯å’Œç»“æ„åå·®ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 4ï¼‰
ç§»é™¤å…³é”®ç»„ä»¶åæ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼ŒéªŒè¯å„æ¨¡å—é‡è¦æ€§ï¼š

| å˜ä½“ | F1 | AC | Overall Score |
|------|----|----|-------------|
| **SEALï¼ˆå®Œæ•´ï¼‰** | 66.44 | 59.37 | **64.08** |
| w/o core extraction | 41.34 | 35.39 | 39.36 |
| w/o entity candidate | 39.32 | 46.16 | 41.60 |
| w/o calibration | 61.78 | 56.21 | 59.93 |
| w/o local memory | 61.89 | 56.69 | 60.16 |

> âœ… **æ ¸å¿ƒå‘ç°**ï¼š`core extraction` å’Œ `calibration` æ˜¯æœ€å…³é”®çš„ä¸¤ä¸ªæ¨¡å—ï¼Œåˆ†åˆ«è´Ÿè´£è¯­ä¹‰èšç„¦å’Œè¯­ä¹‰å¯¹é½ã€‚

---

### ä½èµ„æºåœºæ™¯è¡¨ç°ï¼ˆTable 5ï¼‰
åœ¨é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰å’Œå°‘æ ·æœ¬ï¼ˆfew-shotï¼‰ä¸‹ï¼ŒSEALè¡¨ç°å‡ºæ›´å¼ºçš„é€‚åº”èƒ½åŠ›ï¼š

| è®¾ç½® | æ–¹æ³• | Overall Score |
|------|------|--------------|
| few-shot | KB-Binder | 34.02 |
| few-shot | SEAL-base | **39.36** |
| zero-shot | KB-Binder | 19.76 |
| zero-shot | SEAL-self-evolving | **34.32** |

> ğŸ’¡ è¡¨æ˜**è‡ªæ¼”åŒ–æœºåˆ¶**åœ¨æ•°æ®ç¨€ç¼ºæ—¶å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿé€šè¿‡å†å²ç»éªŒè¡¥å¿æ ‡æ³¨ç¼ºå¤±ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ä¸¤é˜¶æ®µè¯­ä¹‰è§£æä¼˜äºç«¯åˆ°ç«¯ç”Ÿæˆ**ï¼šå°†S-expressionç”Ÿæˆæ‹†åˆ†ä¸ºâ€œæ ¸å¿ƒæå– + æ¨¡æ¿è¡¥å…¨â€ï¼Œæ˜¾è‘—æå‡äº†ç»“æ„å‡†ç¡®æ€§å’Œæ¨ç†å¯é æ€§ã€‚
2. **ä»£ç†æ ¡å‡†æ˜¯å…³é”®æ¡¥æ¢**ï¼šè¿æ¥LLMçš„è¯­ä¹‰ç†è§£èƒ½åŠ›ä¸KGçš„ç»“æ„çº¦æŸï¼Œè§£å†³äº†â€œå¹»è§‰â€ä¸â€œé”™è¿â€é—®é¢˜ã€‚
3. **è‡ªæ¼”åŒ–æœºåˆ¶å®ç°æŒç»­ä¼˜åŒ–**ï¼šéšç€å¯¹è¯è½®æ¬¡å¢åŠ ï¼ŒSEALåˆ©ç”¨è®°å¿†å’Œåæ€ä¸æ–­æå‡æ€§èƒ½ï¼ˆè§Figure 4bï¼‰ï¼Œå±•ç°å‡ºçœŸæ­£çš„â€œå­¦ä¹ â€è¡Œä¸ºã€‚
4. **è½»é‡çº§é“¾æ¥ç­–ç•¥æ›´é«˜æ•ˆå¯é **ï¼šç›¸æ¯”ä¿ç•™å¤šä¸ªå€™é€‰å®ä½“ï¼Œ**top-1è¯­ä¹‰æœ€ç›¸ä¼¼åŒ¹é…**åè€Œæé«˜äº†ç²¾åº¦ï¼Œé¿å…äº†æ— æ•ˆç»„åˆæ±¡æŸ“æœç´¢ç©ºé—´ã€‚

---

### æ–¹æ³•å±€é™æ€§
1. **ä¾èµ–é¢„å®šä¹‰æ¨¡æ¿åº“**ï¼šè™½ç„¶LLMå…·å¤‡ä¸€å®šæ³›åŒ–èƒ½åŠ›ï¼ˆAppendix Eï¼‰ï¼Œä½†æç«¯æ–°é¢–çš„é€»è¾‘ç»“æ„å¯èƒ½æ— æ³•è¢«è¦†ç›–ã€‚
2. **å¯èƒ½è¯¯åˆ¤ç©ºæŸ¥è¯¢**ï¼šæ ¡å‡†é˜¶æ®µåªä¿ç•™æ‰§è¡Œç»“æœéç©ºçš„å˜ä½“ï¼Œå¯èƒ½å¯¼è‡´åˆæ³•ä½†åº”ä¸ºç©ºçš„ç»“æœè¢«è¿‡æ»¤ã€‚
3. **å¤šæ¬¡è°ƒç”¨LLMå¸¦æ¥å»¶è¿Ÿ**ï¼šå¤šæ¨¡å—ååŒå¢åŠ äº†æ¨ç†é“¾é•¿åº¦ï¼Œåœ¨å®æ—¶åº”ç”¨ä¸­å¯èƒ½å­˜åœ¨æ•ˆç‡ç“¶é¢ˆã€‚
4. **Promptä¾èµ–æ€§å¼º**ï¼šS-expressionçš„ç†è§£å’Œç”Ÿæˆé«˜åº¦ä¾èµ–promptè´¨é‡ï¼Œç¼ºä¹ä¸“é—¨è®­ç»ƒå¯èƒ½é™åˆ¶æ½œåŠ›ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **é€šç”¨è½¬æ¢å‡½æ•°è®¾è®¡**ï¼šæ”¹è¿›S-expressionåˆ°SPARQLçš„æ˜ å°„æœºåˆ¶ï¼Œä½¿å…¶æ›´å…·æ™®é€‚æ€§ï¼Œé€‚ç”¨äºæ›´å¤šKGå¹³å°ã€‚
2. **å¢å¼ºç©ºæŸ¥è¯¢è¯†åˆ«èƒ½åŠ›**ï¼šå¼•å…¥è¯­ä¹‰åˆ¤æ–­æœºåˆ¶åŒºåˆ†â€œåˆæ³•ç©ºâ€ä¸â€œé”™è¯¯ç©ºâ€ï¼Œé¿å…è¿‡åº¦ä¿®å‰ªã€‚
3. **S-expressionä¸“é¡¹è®­ç»ƒ**ï¼šå¯¹LLMè¿›è¡ŒS-expressionç”Ÿæˆä»»åŠ¡çš„å¾®è°ƒï¼Œæå‡è¯­æ³•æŒæ¡æ·±åº¦ã€‚
4. **å­ä»»åŠ¡è½»é‡åŒ–**ï¼šä½¿ç”¨å°å‹ä¸“ç”¨æ¨¡å‹æ›¿ä»£LLMå¤„ç†æ ¸å¿ƒæŒ‡ä»£ã€é—®é¢˜åˆ†ç±»ç­‰å­ä»»åŠ¡ï¼Œé™ä½æ•´ä½“è®¡ç®—æˆæœ¬ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> SEALé€šè¿‡â€œ**æ ¸å¿ƒæå– + ä»£ç†æ ¡å‡† + æ¨¡æ¿è¡¥å…¨ + è‡ªæ¼”åŒ–è®°å¿†**â€çš„å››å±‚æ¶æ„ï¼Œåœ¨æ— éœ€ç›‘ç£è®­ç»ƒçš„å‰æä¸‹ï¼Œå®ç°äº†é«˜ç²¾åº¦ã€é«˜æ•ˆç‡ã€å¯æŒç»­è¿›åŒ–çš„å¯¹è¯å¼çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿï¼Œä¸ºå¤æ‚è¯­ä¹‰è§£ææä¾›äº†æ–°çš„èŒƒå¼ã€‚

</details>

---

### 13. [GRASP: GRouped Activation Shared Parameterization for Parameter-Efficient Fine-Tuning and Robust Inference of Transformers](https://arxiv.org/abs/2512.04296)

**Authors**: Malyaban Bal, Abhronil Sengupta  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.04296v1  

#### Abstract
Parameter-efficient fine-tuning (PEFT) provides a scalable alternative to full-model adaptation by updating only a small subset of parameters in large pre-trained models. We introduce GRASP - GRouped Activation Shared Parameterization - a lightweight PEFT framework that partitions the D-dimensional ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šGRASP: GRouped Activation Shared Parameterization for Parameter-Efficient Fine-Tuning and Robust Inference of Transformers

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆå¦‚ RoBERTaã€GPT-2ï¼‰åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¿›è¡Œå…¨é‡å¾®è°ƒï¼ˆFull Fine-Tuningï¼‰å­˜åœ¨ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **å‚æ•°æ•ˆç‡ä½**ï¼šéœ€è¦æ›´æ–°å¤§é‡å‚æ•°ï¼Œè®¡ç®—å’Œå­˜å‚¨å¼€é”€é«˜ï¼›
- **è¿‡æ‹Ÿåˆé£é™©**ï¼šåœ¨å°æ ·æœ¬åœºæ™¯ä¸‹å®¹æ˜“è¿‡æ‹Ÿåˆï¼›
- **ç¡¬ä»¶éƒ¨ç½²å›°éš¾**ï¼šè¾¹ç¼˜è®¾å¤‡ä¸Šçš„éç†æƒ³æ¡ä»¶ï¼ˆå¦‚å™ªå£°ã€æƒé‡æ¼‚ç§»ï¼‰å½±å“æ¨ç†ç¨³å®šæ€§ã€‚

ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œ**Parameter-Efficient Fine-Tuning (PEFT)** æˆä¸ºç ”ç©¶çƒ­ç‚¹ï¼Œä½†ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ LoRAã€BitFitï¼‰ä»å­˜åœ¨å‚æ•°å†—ä½™æˆ–å¼•å…¥é¢å¤–è®¡ç®—å¼€é”€çš„é—®é¢˜ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯

#### ï¼ˆ1ï¼‰**GRASP (GRouped Activation Shared Parameterization)**
- **æ ¸å¿ƒæ€æƒ³**ï¼šå°†æŸä¸€å±‚çš„ $D$ ç»´éšè—çŠ¶æ€åˆ’åˆ†ä¸º $K < D$ ä¸ªç»„ï¼Œæ¯ç»„å…±äº«ä¸€ä¸ªå¯å­¦ä¹ çš„ç¼©æ”¾ï¼ˆscalingï¼‰å’Œåç§»ï¼ˆshiftingï¼‰å‘é‡ã€‚
- **å®ç°æ–¹å¼**ï¼š
  - åœ¨é€‰å®šçš„çº¿æ€§æŠ•å½±å±‚å‰å¯¹è¾“å…¥æ¿€æ´»å€¼è¿›è¡Œåˆ†ç»„è°ƒåˆ¶ï¼›
  - ä¸å¼•å…¥æ–°çš„çŸ©é˜µä¹˜æ³•æ“ä½œï¼Œä»…é€šè¿‡ element-wise çš„ $\gamma_g \odot x + \beta_g$ å®ç°ï¼›
  - å¯è®­ç»ƒå‚æ•°ä» $O(n \times D)$ ä¸‹é™åˆ° $O(n \times K)$ï¼Œæ˜¾è‘—å‹ç¼©å‚æ•°é‡ã€‚

#### ï¼ˆ2ï¼‰**StochGRASPï¼ˆéšæœºåŒ–æ‰©å±•ç‰ˆæœ¬ï¼‰**
- **åŠ¨æœº**ï¼šè§‚å¯Ÿåˆ° GRASP å­¦ä¹ åˆ°çš„å‚æ•°åˆ†å¸ƒå‘ˆç°å¤šæ¨¡æ€ç»“æ„ï¼Œå¯å‘ä½œè€…å°†å…¶è§£é‡Šä¸ºæƒé‡æ‰°åŠ¨çš„æ¦‚ç‡åˆ†å¸ƒã€‚
- **æ”¹è¿›**ï¼š
  - å°†ç¡®å®šæ€§çš„ scaling/shifting å‚æ•°æ›¿æ¢ä¸ºå­¦ä¹  **é«˜æ–¯åˆ†å¸ƒ**ï¼ˆå‡å€¼ $\mu$ å’Œæ ‡å‡†å·® $\sigma$ï¼‰ï¼›
  - å¼•å…¥ **noise-aware loss function**ï¼Œæ­£åˆ™åŒ–å­¦ä¹ åˆ°çš„æ ‡å‡†å·®ä»¥åŒ¹é…ç›®æ ‡ç¡¬ä»¶å™ªå£°æ°´å¹³ï¼›
  - æ›´é€‚åˆéƒ¨ç½²äºå«å™ªå£°çš„æ¨¡æ‹Ÿ AI ç¡¬ä»¶å¹³å°ï¼ˆå¦‚åŸºäºå¿†é˜»å™¨çš„åŠ é€Ÿå™¨ï¼‰ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹æ³• | å‚æ•°é‡ | æ˜¯å¦å¼•å…¥é¢å¤–çŸ©é˜µè¿ç®— | æŠ—å™ªèƒ½åŠ› | å‚æ•°æ•ˆç‡ |
|------|--------|------------------------|-----------|------------|
| Full-FT | é«˜ | æ˜¯ | ä¸€èˆ¬ | å·® |
| LoRA | ä¸­ç­‰ ($\sim$0.3%) | æ˜¯ | å¼± | ä¸€èˆ¬ |
| BitFit | ä½ ($\sim$0.09%) | å¦ | å¼± | è¾ƒå¥½ |
| (IA)$^3$ | ä½ ($\sim$0.05%) | å¦ | å¼± | è‰¯å¥½ |
| **GRASP** | **æä½ ($\sim$0.003â€“0.015%)** | **å¦** | **ä¸­ç­‰** | âœ… **æœ€ä¼˜ä¹‹ä¸€** |
| **StochGRASP** | æä½ | å¦ | âœ… **å¼ºï¼ˆæŠ—ç¡¬ä»¶å™ªå£°ï¼‰** | âœ… |

- **ä¼˜åŠ¿æ€»ç»“**ï¼š
  - å‚æ•°é‡æ¯” LoRA å‡å°‘ **10â€“75 å€**ï¼›
  - æ— éœ€é¢å¤–çŸ©é˜µä¹˜æ³•ï¼Œè®­ç»ƒæ›´é«˜æ•ˆï¼›
  - StochGRASP æ˜¾è‘—æå‡åœ¨å™ªå£°ç¯å¢ƒä¸‹çš„é²æ£’æ€§ï¼Œé€‚ç”¨äºè¾¹ç¼˜ AI ç¡¬ä»¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

| ç±»å‹ | æ•°æ®é›† | æ¨¡å‹ |
|------|--------|-------|
| è‡ªç„¶è¯­è¨€ç†è§£ï¼ˆNLUï¼‰ | **GLUE Benchmark**ï¼š<br>- SST-2ï¼ˆæƒ…æ„Ÿåˆ†ç±»ï¼‰<br>- CoLAï¼ˆè¯­æ³•å¯æ¥å—æ€§ï¼‰<br>- QNLI/MNLI/RTEï¼ˆè‡ªç„¶è¯­è¨€æ¨ç†ï¼‰<br>- MRPC/QQPï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰<br>- STS-Bï¼ˆç›¸å…³æ€§è¯„åˆ†ï¼‰ | RoBERTa-base (125M)<br>RoBERTa-large (355M) |
| è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆNLGï¼‰ | **E2E NLG Challenge**ï¼ˆé¤å…ä¿¡æ¯åˆ°æ–‡æœ¬ç”Ÿæˆï¼‰ | GPT-2 Medium (354.9M) |

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

| è®¾ç½®é¡¹ | æè¿° |
|--------|------|
| ç¡¬ä»¶å¹³å° | NVIDIA RTX A5000 GPU Ã— 8ï¼Œæ¯å¡ 24GB å†…å­˜ |
| åºåˆ—é•¿åº¦ | GLUE: æœ€å¤§ 128ï¼›E2E NLG: è‡ªé€‚åº” |
| Batch Size | GLUE: 16 æˆ– 32ï¼›E2E NLG: 4 |
| Learning Rate | GLUE: $1e^{-4}$ ~ $8e^{-4}$ï¼›E2E NLG: $5e^{-4}$ |
| ä¼˜åŒ–å™¨ | AdamW |
| Beam Search | E2E NLG æ¨ç†æ—¶ä½¿ç”¨ beam width=10 |

#### è¯„ä¼°æŒ‡æ ‡
| ä»»åŠ¡ç±»å‹ | ä¸»è¦æŒ‡æ ‡ |
|---------|----------|
| åˆ†ç±»ä»»åŠ¡ï¼ˆSST-2, RTE, QNLI, MNLIï¼‰ | Accuracy |
| å›å½’ä»»åŠ¡ï¼ˆSTS-Bï¼‰ | Pearson & Spearman Correlation |
| å¥å­å¯¹ä»»åŠ¡ï¼ˆMRPC, QQPï¼‰ | F1 Score |
| è¯­æ³•åˆ¤æ–­ï¼ˆCoLAï¼‰ | Matthews Correlation Coefficient |
| æ–‡æœ¬ç”Ÿæˆï¼ˆE2E NLGï¼‰ | BLEU, NIST, METEOR, ROUGE-L, CIDEr |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Full-FT**ï¼šå…¨å‚æ•°å¾®è°ƒï¼ˆåŸºå‡†ä¸Šé™ï¼‰
- **Adapters**ï¼šæ’å…¥å°å‹ç“¶é¢ˆæ¨¡å—
- **LoRA**ï¼šä½ç§©é€‚é…ï¼Œä¸»æµ PEFT æ–¹æ³•
- **BitFit**ï¼šåªå¾®è°ƒ bias é¡¹
- **(IA)$^3$**ï¼šä»…å­¦ä¹  scaling å‘é‡
- **RED**ï¼šåŒæ—¶å­¦ä¹  scaling å’Œ shifting
- **VeRA**, **Prefix Tuning**ï¼šå…¶ä»–è½»é‡çº§ PEFT æ–¹æ³•

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ï¼ˆ1ï¼‰GLUE ä¸Šçš„ç»“æœï¼ˆè§ Table Iï¼‰

| æ–¹æ³• | å¹³å‡å¾—åˆ†ï¼ˆAvg.ï¼‰ | å¯è®­ç»ƒå‚æ•°æ¯”ä¾‹ (%Param) |
|------|------------------|--------------------------|
| RoBERTa-base Full-FT | 85.8 | 100% |
| LoRA | 87.2 | 0.3% |
| BitFit | 84.9 | 0.09% |
| (IA)$^3$ | 83.1 | 0.05% |
| **GRASP (K=128)** | **85.9** | **0.015%** |
| RoBERTa-large Full-FT | 89.3 | 100% |
| LoRA | 89.4 | 0.3% |
| **GRASP (K=64)** | **88.4** | **0.005%** |

> âœ… **GRASP åœ¨å‚æ•°ä»…ä¸º LoRA çš„ ~1/20 çš„æƒ…å†µä¸‹ï¼Œè¾¾åˆ°ç”šè‡³è¶…è¿‡å…¶æ€§èƒ½**

---

### ï¼ˆ2ï¼‰E2E NLG ä¸Šçš„ç»“æœï¼ˆè§ Table IIï¼‰

| æ–¹æ³• | BLEU | %Param |
|------|------|--------|
| Full-FT | 68.2 | 100% |
| LoRA (rank=1) | 64.51 | 0.03% |
| RED | 64.86 | 0.01% |
| **GRASP (K=64)** | **66.03** | **0.003%** |

> âœ… **GRASP æ€§èƒ½ä¼˜äºæ‰€æœ‰ä½ç§© LoRA å’Œ Adapter å˜ä½“ï¼Œä¸”å‚æ•°é‡å‡å°‘æœ€å¤šè¾¾ 10 å€**

---

### ï¼ˆ3ï¼‰æ¶ˆèå®éªŒç»“æœ

#### A. éšæœºåˆ†ç»„çš„é²æ£’æ€§ï¼ˆTable IIIï¼‰
- ä½¿ç”¨ä¸åŒéšæœºç§å­è¿›è¡Œç»´åº¦åˆ†ç»„ï¼Œæ€§èƒ½æ³¢åŠ¨æå°ï¼ˆå¦‚ SST-2: 94.27Â±0.11ï¼‰ï¼Œè¯´æ˜ **åˆ†ç»„ç­–ç•¥ç¨³å®šå¯é **ã€‚

#### B. å±‚é€‰æ‹©çš„å½±å“ï¼ˆTable IVï¼‰
| åº”ç”¨å±‚èŒƒå›´ | %Params | SST-2 |
|-----------|--------|-------|
| æ‰€æœ‰çº¿æ€§å±‚ | 0.015% | 94.3 |
| K/V/FF2 å±‚ | 0.008% | 94.1 |
| ä»… FF2 å±‚ | 0.003% | 94.0 |

> âœ… å³ä½¿åªåº”ç”¨äº FF2 å±‚ä¹Ÿèƒ½ä¿æŒé«˜æ€§èƒ½ï¼Œè¿›ä¸€æ­¥é™ä½å‚æ•°é‡ã€‚

#### C. ç¼©æ”¾ vs åç§»çš„ä½œç”¨ï¼ˆTable Vï¼‰
| æ–¹æ³• | SST-2 |
|------|-------|
| æ—  shiftingï¼ˆä»… scalingï¼‰ | 93.0 |
| æ—  scalingï¼ˆä»… shiftingï¼‰ | 93.8 |
| å®Œæ•´ GRASP | 94.3 |

> âœ… **shiftingï¼ˆåç§»ï¼‰æ¯” scaling æ›´é‡è¦**ï¼Œä¸¤è€…ç»“åˆæ•ˆæœæœ€ä½³ã€‚

#### D. ä»»åŠ¡éš¾åº¦å½±å“å‚æ•°åˆ†å¸ƒï¼ˆFig. 4ï¼‰
- æ›´éš¾çš„ä»»åŠ¡ï¼ˆå¦‚ CoLAï¼‰å¯¼è‡´æ›´å¼ºçš„å¤šæ¨¡æ€åˆ†å¸ƒï¼›
- è¡¨æ˜ GRASP èƒ½è‡ªé€‚åº”åœ°æ•æ‰ä»»åŠ¡å¤æ‚æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **åˆ†ç»„å…±äº«æœºåˆ¶æœ‰æ•ˆå‹ç¼©å‚æ•°**ï¼šé€šè¿‡å°† $D$ ç»´æ¿€æ´»åˆ†æˆ $K$ ç»„å¹¶å…±äº« scaling/shifting å‚æ•°ï¼Œå¯åœ¨å‡ ä¹ä¸æŸå¤±æ€§èƒ½çš„å‰æä¸‹å¤§å¹…å‡å°‘å¯è®­ç»ƒå‚æ•°ï¼ˆä½è‡³ 0.003%ï¼‰ã€‚
2. âœ… **å‚æ•°åˆ†å¸ƒå‘ˆç°å¤šæ¨¡æ€ç‰¹æ€§**ï¼šéšç€ $K$ å‡å°ï¼Œlearned å‚æ•°å‡ºç°å¤šä¸ªå³°å€¼ï¼Œåæ˜ æ¨¡å‹åœ¨æœ‰é™å‚æ•°ä¸‹å­¦ä¹ å…³é”®ç‰¹å¾çš„èƒ½åŠ›ã€‚
3. âœ… **StochGRASP æ˜¾è‘—å¢å¼ºæŠ—å™ªèƒ½åŠ›**ï¼š
   - åœ¨æ³¨å…¥ç¡¬ä»¶å™ªå£°ï¼ˆ$\sigma = 0.01$ï¼‰æ—¶ï¼ŒStochGRASP åœ¨ SST-2 ä¸Šç»´æŒ **â‰¥86% å‡†ç¡®ç‡**ï¼›
   - è€Œç¡®å®šæ€§ GRASP ä¸‹é™è‡³ **61.5%**ï¼ˆå›¾ 6ï¼‰ï¼›
   - è¯æ˜å…¶æ›´é€‚åˆéƒ¨ç½²äºå™ªå£°è¾ƒå¤§çš„è¾¹ç¼˜ AI ç¡¬ä»¶ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰å®éªŒåŸºäº **æ¨¡æ‹Ÿå™ªå£°**ï¼Œå°šæœªåœ¨çœŸå®ç¡¬ä»¶ä¸ŠéªŒè¯ï¼›
- åˆ†ç»„æ˜¯éšæœºçš„ï¼Œæœªæ¢ç´¢æ˜¯å¦å¯é€šè¿‡èšç±»ç­‰æ–¹å¼ä¼˜åŒ–åˆ†ç»„ç»“æ„ï¼›
- å¯¹éå¸¸å°çš„ $K$ï¼ˆå¦‚ < 16ï¼‰ï¼Œæ€§èƒ½å¯èƒ½ä¸‹é™æ˜æ˜¾ï¼Œéœ€æƒè¡¡å‹ç¼©ç‡ä¸ç²¾åº¦ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **ç¡¬ä»¶é—­ç¯è®­ç»ƒ**ï¼šç»“åˆçœŸå® AI åŠ é€ŸèŠ¯ç‰‡çš„å™ªå£°æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼›
2. **åŠ¨æ€åˆ†ç»„æœºåˆ¶**ï¼šåŸºäºç¥ç»å…ƒæ¿€æ´»æ¨¡å¼è‡ªåŠ¨èšç±»åˆ†ç»„ï¼›
3. **æ‰©å±•è‡³è§†è§‰æ¨¡å‹**ï¼šåº”ç”¨äº ViTã€ConvNeXt ç­‰æ¶æ„ï¼›
4. **ä¸å…¶ä»– PEFT æ–¹æ³•èåˆ**ï¼šå¦‚ä¸ LoRA ç»“åˆå½¢æˆ hybrid adapterã€‚

---

## æ€»ç»“

âœ… **GRASP æ˜¯ä¸€ç§æè‡´å‚æ•°é«˜æ•ˆçš„ PEFT æ–¹æ³•**ï¼Œé€šè¿‡**åˆ†ç»„å…±äº« activation modulation** å®ç°æ¯” LoRAã€BitFit æ›´ä½çš„å‚æ•°é‡ï¼ŒåŒæ—¶ä¿æŒç«äº‰åŠ›æ€§èƒ½ã€‚  
ğŸ”¥ **StochGRASP è¿›ä¸€æ­¥æå‡äº†æ¨¡å‹åœ¨å™ªå£°ç¯å¢ƒä¸‹çš„é²æ£’æ€§**ï¼Œä¸º**é¢å‘è¾¹ç¼˜ AI ç¡¬ä»¶çš„ç¨³å¥éƒ¨ç½²æä¾›äº†æ–°èŒƒå¼**ã€‚  
ğŸ“Œ è¯¥å·¥ä½œä¸ä»…æ¨åŠ¨äº† PEFT çš„æé™å‹ç¼©ï¼Œè¿˜é¦–æ¬¡ç³»ç»Ÿæ€§è¿æ¥äº† **PEFT ä¸ç¡¬ä»¶æ„ŸçŸ¥å»ºæ¨¡**ï¼Œå…·æœ‰é‡è¦çš„ç†è®ºä¸åº”ç”¨ä»·å€¼ã€‚

</details>

---

### 14. [QoSDiff: An Implicit Topological Embedding Learning Framework Leveraging Denoising Diffusion and Adversarial Attention for Robust QoS Prediction](https://arxiv.org/abs/2512.04596)

**Authors**: Guanchen Du, Jianlong Xu, Wei Wei  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.04596v1  

#### Abstract
Accurate Quality of Service (QoS) prediction is fundamental to service computing, providing essential data-driven guidance for service selection and ensuring superior user experiences. However, prevalent approaches, particularly Graph Neural Networks (GNNs), heavily rely on constructing explicit use...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# QoSDiff: An Implicit Topological Embedding Learning Framework Leveraging Denoising Diffusion and Adversarial Attention for Robust QoS Prediction â€”â€” æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ä¼ ç»Ÿçš„ **QoS Prediction** æ–¹æ³•ï¼ˆå°¤å…¶æ˜¯åŸºäº **Graph Neural Networks, GNNs**ï¼‰é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š

1. **æ˜¾å¼å›¾æ„å»ºçš„ä¸å¯è¡Œæ€§ï¼ˆIntractability of Explicit Graph Constructionï¼‰**  
   åœ¨å¤§è§„æ¨¡æœåŠ¡ç¯å¢ƒä¸­ï¼Œæ„å»ºç”¨æˆ·-æœåŠ¡äº¤äº’å›¾æˆæœ¬é«˜æ˜‚ï¼Œä¸”ç¨€ç–æ•°æ®å¯¼è‡´å›¾å™ªå£°ä¸¥é‡ã€‚

2. **éšå¼æ‹“æ‰‘å…³ç³»å»ºæ¨¡èƒ½åŠ›ä¸è¶³ï¼ˆLimitations in Modeling Implicit Topological Relationshipsï¼‰**  
   ä¼ ç»Ÿ GNN ä¾èµ–æ˜¾å¼è¾¹è¿›è¡Œæ¶ˆæ¯ä¼ é€’ï¼Œéš¾ä»¥æ•æ‰è·¨åŸŸã€å†·å¯åŠ¨ç­‰åœºæ™¯ä¸‹çš„éšå¼å…³è”ã€‚

3. **å¯¹ç¯å¢ƒå™ªå£°å’Œå¼‚å¸¸å€¼æ•æ„Ÿï¼ˆSusceptibility to Environmental Noiseï¼‰**  
   å®é™… QoS æ•°æ®å¸¸å—ç½‘ç»œæ³¢åŠ¨ã€æœåŠ¡å™¨æ‹¥å¡ç­‰å½±å“ï¼Œè€Œå¤šæ•°æ¨¡å‹ç¼ºä¹é²æ£’æ€§æœºåˆ¶æ¥åŒºåˆ†çœŸå®æ¨¡å¼ä¸éšæœºæ‰°åŠ¨ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **QoSDiff**ï¼Œä¸€ç§æ— éœ€æ˜¾å¼å›¾æ„å»ºçš„éšå¼æ‹“æ‰‘åµŒå…¥å­¦ä¹ æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒç”±ä¸¤ä¸ªæ¨¡å—ç»„æˆï¼š

#### âœ… **Diffusion-based Embedding Learning Module (DELM)**

- åˆ©ç”¨ **Denoising Diffusion Probabilistic Model (DDPM)** ä»é«˜æ–¯å™ªå£°åˆå§‹åŒ–ä¸­é€æ­¥æ¢å¤ç”¨æˆ·å’ŒæœåŠ¡çš„æ½œåœ¨è¡¨ç¤ºã€‚
- å°†åµŒå…¥åˆå§‹åŒ–è§†ä¸ºå•æ­¥å‰å‘æ‰©æ•£è¿‡ç¨‹ï¼Œå¹¶é€šè¿‡åå‘å»å™ªç”Ÿæˆé«˜è´¨é‡åµŒå…¥ã€‚
- è®¾è®¡äº†ä¸“ç”¨äºç¦»æ•£åµŒå…¥ç©ºé—´çš„ **Attention-based Noise Predictor**ï¼Œæ›¿ä»£ä¼ ç»Ÿå›¾åƒä»»åŠ¡ä¸­çš„ U-Net ç»“æ„ã€‚

#### âœ… **Adversarial Attention-based Interaction Module (AAIM)**

- å¼•å…¥ **ç”Ÿæˆå¯¹æŠ—æ¶æ„** æ¥å¢å¼ºäº¤äº’å»ºæ¨¡çš„é²æ£’æ€§ã€‚
- ç”Ÿæˆå™¨é‡‡ç”¨ **Bidirectional Hybrid Attention Mechanism (BHAM)**ï¼ŒåŒæ—¶å»ºæ¨¡â€œç”¨æˆ·å…³æ³¨æœåŠ¡â€å’Œâ€œæœåŠ¡å…³æ³¨ç”¨æˆ·â€çš„åŒå‘ä¾èµ–ã€‚
- åˆ¤åˆ«å™¨é€šè¿‡åŒºåˆ†çœŸå®äº¤äº’ä¸ Gumbel-Softmax æ‰°åŠ¨ç”Ÿæˆçš„è™šå‡æ ·æœ¬ï¼Œè¿«ä½¿ç”Ÿæˆå™¨å­¦ä¹ æ›´ç¨³å®šã€æŠ—å™ªçš„è¡¨ç¤ºã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ä¼˜åŠ¿ç»´åº¦ | QoSDiff | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ GNNï¼‰ |
|--------|--------|------------------|
| **å›¾ä¾èµ–** | âŒ ä¸éœ€è¦æ˜¾å¼å›¾ | âœ… å¿…é¡»æ„å»ºé‚»æ¥çŸ©é˜µ |
| **å¯æ‰©å±•æ€§** | âœ… é«˜ï¼ˆé¿å…å›¾å·ç§¯å¼€é”€ï¼‰ | âŒ ä½ï¼ˆå¤æ‚åº¦éšèŠ‚ç‚¹æ•°å¢é•¿ï¼‰ |
| **å™ªå£°é²æ£’æ€§** | âœ… å¼ºï¼ˆæ‰©æ•£+å¯¹æŠ—åŒé‡è¿‡æ»¤ï¼‰ | âŒ å¼±ï¼ˆæ˜“ä¼ æ’­å™ªå£°ï¼‰ |
| **ç¨€ç–æ€§é€‚åº”** | âœ… ä¼˜ï¼ˆå…¨å±€æ³¨æ„åŠ›æ•è·é•¿ç¨‹ä¾èµ–ï¼‰ | âŒ å·®ï¼ˆå±€éƒ¨æ¶ˆæ¯ä¼ é€’å—é™ï¼‰ |

> ğŸ” **æ ¸å¿ƒæ€æƒ³è½¬å˜**ï¼šä»â€œåŸºäºå›¾çš„æ¶ˆæ¯ä¼ é€’â€è½¬å‘â€œåœ¨è¿ç»­æ½œç©ºé—´ä¸­è¿›è¡Œç”Ÿæˆå¼å»å™ªâ€ï¼Œå®ç°äº†å¯¹éšå¼æ‹“æ‰‘ç»“æ„çš„æœ‰æ•ˆå­¦ä¹ ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

1. **WS-DREAM Dataset**
   - ç”¨æˆ·æ•°ï¼š339
   - æœåŠ¡æ•°ï¼š5,825
   - QoS æŒ‡æ ‡ï¼šResponse Time (RT) å’Œ Throughput (TP)
   - æ€»è®°å½•æ•°ï¼šçº¦ 197 ä¸‡æ¡
   - ç‰¹ç‚¹ï¼šå…¨çƒåˆ†å¸ƒçš„ Web æœåŠ¡è°ƒç”¨æ—¥å¿—

2. **EEL Dataset**
   - è¾¹ç¼˜èŠ‚ç‚¹æ•°ï¼š5,174
   - æµ‹é‡æ•°é‡ï¼šè¿‘ 9 äº¿æ¬¡ PING è¯·æ±‚
   - QoS æŒ‡æ ‡ï¼šDELAYï¼ˆç«¯åˆ°ç«¯å»¶è¿Ÿï¼‰å’Œ HOPSï¼ˆè·³æ•°ï¼‰
   - ç‰¹ç‚¹ï¼šå¤§è§„æ¨¡è¾¹ç¼˜äº‘ç¯å¢ƒä¸‹çš„çœŸå®å»¶è¿Ÿæµ‹é‡

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### ğŸ“Š **è¯„ä¼°æŒ‡æ ‡**

- **MAE**ï¼ˆMean Absolute Errorï¼‰
- **RMSE**ï¼ˆRoot Mean Square Errorï¼‰

å‡ä½œç”¨äºå½’ä¸€åŒ–åçš„é¢„æµ‹å€¼ï¼Œè¶Šå°è¶Šå¥½ã€‚

#### âš™ï¸ **è®­ç»ƒè®¾ç½®**

- **åˆ’åˆ†æ–¹å¼**ï¼šæŒ‰å¯†åº¦é‡‡æ ·è®­ç»ƒé›†ï¼ˆ2.5%, 5%, 7.5%, 10%ï¼‰ï¼Œå…¶ä½™ä¸ºéªŒè¯+æµ‹è¯•é›†
- **æ‰¹å¤§å°**ï¼š256ï¼ˆWS-DREAMï¼‰ï¼Œ8192ï¼ˆEELï¼‰
- **ä¼˜åŒ–å™¨**ï¼šAdamW
- **æ—©åœæœºåˆ¶**ï¼špatience=15
- **é‡å¤å®éªŒ**ï¼š3 æ¬¡ä¸åŒ seed å–å¹³å‡ Â± æ ‡å‡†å·®

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

å…±æ¯”è¾ƒ **12 ç§ä»£è¡¨æ€§æ–¹æ³•**ï¼Œåˆ†ä¸ºå››ç±»ï¼š

| ç±»å‹ | æ–¹æ³• |
|------|------|
| **CF-based** | UPCC, IPCC, UIPCC |
| **MF-based** | PMF, BiasMF |
| **Deep Learning** | CSMF, NFMF, NCRL |
| **GNN-based** | GraphMF, PMP, RIGCN, QoSGNN |

å…¶ä¸­ **QoSGNN** æ˜¯æœ€å¼ºçš„ GNN åŸºçº¿ï¼Œç»“åˆæ³¨æ„åŠ›æœºåˆ¶æå‡æ€§èƒ½ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆWS-DREAM æ•°æ®é›†ï¼‰**

#### âœ… **Response Time (RT) é¢„æµ‹æ€§èƒ½ï¼ˆMAE/RMSEï¼‰**

| å¯†åº¦ | æœ€ä½³ MAEï¼ˆQoSDiffï¼‰ | ç¬¬äºŒåï¼ˆQoSGNNï¼‰ | æå‡å¹…åº¦ |
|------|--------------------|------------------|---------|
| 2.5% | **0.402** Â± 0.004 | 0.431 | **6.73%** |
| 5%   | **0.358** Â± 0.006 | 0.377 | **5.04%** |
| 7.5% | **0.337** Â± 0.001 | 0.353 | **4.53%** |
| 10%  | **0.324** Â± 0.001 | 0.345 | **6.09%** |

> ğŸ’¡ åœ¨æœ€ç¨€ç–çš„ 2.5% åœºæ™¯ä¸‹æå‡æœ€å¤§ï¼Œè¯´æ˜ QoSDiff å¯¹**æç«¯ç¨€ç–æ€§**å…·æœ‰æ›´å¼ºé€‚åº”èƒ½åŠ›ã€‚

#### âœ… **Throughput (TP) é¢„æµ‹æ€§èƒ½**

| å¯†åº¦ | æœ€ä½³ MAEï¼ˆQoSDiffï¼‰ | ç¬¬äºŒåï¼ˆQoSGNNï¼‰ | æå‡å¹…åº¦ |
|------|--------------------|------------------|---------|
| 2.5% | **16.621** Â± 0.200 | 18.823 | **11.70%** |
| 5%   | **13.473** Â± 0.061 | 16.255 | **17.11%** |
| 7.5% | **12.170** Â± 0.041 | 14.489 | **16.01%** |
| 10%  | **11.474** Â± 0.069 | 13.946 | **17.73%** |

> ğŸ” åœ¨ TP ä¸Šæå‡æ›´ä¸ºæ˜¾è‘—ï¼Œè¡¨æ˜ AAIM èƒ½æœ‰æ•ˆå»ºæ¨¡éçº¿æ€§ååç‰¹å¾ã€‚

---

### **è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ï¼ˆEEL Datasetï¼‰**

| æŒ‡æ ‡ | QoSDiff è¡¨ç° | ç›¸å¯¹æœ€ä½³åŸºçº¿æå‡ |
|------|-------------|------------------|
| DELAY (MAE @ 2.5%) | **0.006842** | +4.96% vs QoSGNN |
| HOPS (MAE @ 2.5%) | **0.00529** | +20.61% vs QoSGNN |

> âœ… æ˜¾ç¤ºå‡ºå“è¶Šçš„**è·¨åŸŸè¿ç§»èƒ½åŠ›**ï¼Œå³ä½¿åœ¨å®Œå…¨ä¸åŒçš„è¾¹ç¼˜è®¡ç®—åœºæ™¯ä¸­ä»ä¿æŒé¢†å…ˆã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

#### ğŸ” **Embedding Learning æ¨¡å—æœ‰æ•ˆæ€§**

- ä½¿ç”¨ **Denoising Diffusion** ç›¸æ¯”æ— å»å™ªç‰ˆæœ¬ï¼š
  - åœ¨ RT ä¸Šå¹³å‡é™ä½ MAE **~10â€“15%**
  - åœ¨ TP ä¸Šé™ä½ **~15â€“20%**
- è¯æ˜ DELM æˆåŠŸæå‡äº†åµŒå…¥è´¨é‡ï¼Œå°¤å…¶åœ¨ç¨€ç–æ¡ä»¶ä¸‹ã€‚

#### ğŸ” **Interaction Module å¯¹æ¯”**

ä¸‰ç§äº¤äº’ç­–ç•¥å¯¹æ¯”ï¼š

| æ–¹æ³• | MAEï¼ˆRTï¼‰ | MAEï¼ˆTPï¼‰ |
|------|----------|----------|
| MFï¼ˆå†…ç§¯ï¼‰ | 0.72 | 24.0 |
| CFï¼ˆMLPï¼‰ | 0.60 | 22.0 |
| **AAIMï¼ˆæœ¬æ–‡ï¼‰** | **0.40** | **16.6** |

> âœ… AAIM æ˜¾è‘—ä¼˜äºä¼ ç»Ÿäº¤äº’æ–¹å¼ï¼ŒéªŒè¯äº†**åŒå‘æ³¨æ„åŠ›+å¯¹æŠ—è®­ç»ƒ**çš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **æ— éœ€æ˜¾å¼å›¾ä¹Ÿèƒ½å­¦å¥½æ‹“æ‰‘ç»“æ„**  
   QoSDiff é€šè¿‡ **diffusion + attention** å®ç°äº†å¯¹éšå¼ç”¨æˆ·-æœåŠ¡å…³ç³»çš„é«˜æ•ˆå»ºæ¨¡ï¼Œæ‘†è„±äº†å¯¹æ˜¾å¼å›¾çš„ä¾èµ–ã€‚

2. **åœ¨æç«¯ç¨€ç–å’Œå™ªå£°ç¯å¢ƒä¸‹è¡¨ç°æœ€ä¼˜**  
   - åœ¨ 2.5% æ•°æ®å¯†åº¦ä¸‹æ€§èƒ½æå‡æœ€å¤§ï¼›
   - æŠ—å™ªå®éªŒæ˜¾ç¤ºï¼Œå½“ 25% æµ‹è¯•æ ·æœ¬è¢«é”™è¯¯æ ‡è®°æ—¶ï¼ŒQoSDiff çš„è¯¯å·®å¢é•¿ç‡æ¯” QoSGNN ä½ **~15â€“20%**ã€‚

3. **å…·å¤‡å¼ºæ³›åŒ–èƒ½åŠ›**  
   åœ¨ä¸è®­ç»ƒé›†è¯­ä¹‰å·®å¼‚è¾ƒå¤§çš„ EEL æ•°æ®é›†ä¸Šä¾ç„¶å–å¾— SOTAï¼Œè¯´æ˜æ¨¡å‹å­¦åˆ°çš„æ˜¯é€šç”¨çš„æœåŠ¡äº¤äº’è§„å¾‹ã€‚

4. **ç»„ä»¶ååŒå¢æ•ˆæ˜æ˜¾**  
   æ¶ˆèå®éªŒè¯æ˜ DELM å’Œ AAIM å„è‡ªç‹¬ç«‹æœ‰æ•ˆï¼Œè”åˆä½¿ç”¨äº§ç”Ÿæ›´å¤§æ”¶ç›Šã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **è®¡ç®—èµ„æºéœ€æ±‚è¾ƒé«˜**  
   è™½ç„¶é¿å…äº†å¤šå±‚ GNN æ¨ç†ï¼Œä½† diffusion å’Œ attention æ¨¡å—ä»éœ€è¾ƒå¤§å†…å­˜ï¼Œä¸é€‚åˆæè½»é‡éƒ¨ç½²ã€‚

2. **è¶…å‚æ•°æ•æ„Ÿæ€§å­˜åœ¨**  
   å¦‚ trade-off å‚æ•° Î» åœ¨ä¸åŒä»»åŠ¡ï¼ˆRT vs TPï¼‰ä¸Šçš„æœ€ä¼˜å€¼ä¸åŒï¼Œéœ€è°ƒå‚ã€‚

3. **æœªè€ƒè™‘æ—¶é—´åŠ¨æ€æ€§**  
   å½“å‰æ¨¡å‹æ˜¯é™æ€çš„ï¼Œæ— æ³•æ•æ‰ QoS éšæ—¶é—´å˜åŒ–çš„è¶‹åŠ¿ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **å¼•å…¥ Temporal Diffusion**  
   å°† diffusion è¿‡ç¨‹æ‰©å±•è‡³æ—¶é—´åºåˆ—ç»´åº¦ï¼Œå»ºæ¨¡ QoS çš„æ¼”åŒ–è·¯å¾„ã€‚

2. **èåˆæ›´å¤æ‚çš„æ‹“æ‰‘å…ˆéªŒ**  
   æ¢ç´¢ Hypergraph æˆ– Hierarchical Transformer æ¥å¢å¼ºç»“æ„è¡¨è¾¾åŠ›ã€‚

3. **åœ¨çº¿å¢é‡å­¦ä¹ æœºåˆ¶**  
   æ”¯æŒå®æ—¶æ›´æ–°åµŒå…¥ä»¥åº”å¯¹æœåŠ¡ç”Ÿæ€çš„åŠ¨æ€å˜åŒ–ã€‚

4. **è½»é‡åŒ–è®¾è®¡**  
   å¼€å‘é€‚ç”¨äºç§»åŠ¨ç«¯æˆ–è¾¹ç¼˜è®¾å¤‡çš„è’¸é¦ç‰ˆ QoSDiffã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> QoSDiff é€šè¿‡å°† **denoising diffusion** ä¸ **adversarial attention** ç›¸ç»“åˆï¼Œåœ¨ä¸ä¾èµ–æ˜¾å¼å›¾çš„å‰æä¸‹ï¼Œå®ç°äº†å¯¹ç”¨æˆ·-æœåŠ¡äº¤äº’çš„é²æ£’ã€å¯æ‰©å±•ã€é«˜ç²¾åº¦å»ºæ¨¡ï¼Œä»£è¡¨äº† QoS é¢„æµ‹é¢†åŸŸä»â€œåˆ¤åˆ«å¼å›¾å­¦ä¹ â€å‘â€œç”Ÿæˆå¼æ½œç©ºé—´å»ºæ¨¡â€çš„é‡è¦èŒƒå¼è½¬ç§»ã€‚

</details>

---

### 15. [LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving](https://arxiv.org/abs/2512.04374)

**Authors**: Muyu Pan, Matthew Walter, Dheeraj Kodakandla, Mahfuza Farooque  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.04374v1  

#### Abstract
Our work presents a novel reinforcement learning (RL) based framework to optimize heuristic selection within the conflict-driven clause learning (CDCL) process, improving the efficiency of Boolean satisfia- bility (SAT) solving. The proposed system, LangSAT, bridges the gap between natural language ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠLangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solvingã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ SAT æ±‚è§£å™¨è¦æ±‚è¾“å…¥ä¸ºæ ‡å‡†çš„ **CNF**ï¼ˆConjunctive Normal Formï¼‰æ ¼å¼ï¼Œè¿™ä½¿å¾—éä¸“ä¸šäººå£«éš¾ä»¥ç›´æ¥ä½¿ç”¨ SAT æŠ€æœ¯è§£å†³ç°å®ä¸–ç•Œä¸­çš„é€»è¾‘æ¨ç†é—®é¢˜ã€‚æ­¤å¤–ï¼Œè‡ªç„¶è¯­è¨€æè¿°åˆ°å½¢å¼é€»è¾‘ä¹‹é—´çš„è½¬æ¢ç¼ºä¹è‡ªåŠ¨åŒ–å·¥å…·ï¼Œå½¢æˆäº†â€œè¯­ä¹‰é¸¿æ²Ÿâ€ã€‚

åŒæ—¶ï¼Œç°æœ‰çš„ CDCLï¼ˆConflict-Driven Clause Learningï¼‰æ±‚è§£å™¨ä¾èµ–é™æ€å¯å‘å¼ç­–ç•¥ï¼ˆå¦‚ VSIDSï¼‰ï¼Œåœ¨é¢å¯¹ç”±è‡ªç„¶è¯­è¨€ç”Ÿæˆã€ç»“æ„å¤šå˜çš„ CNF å®ä¾‹æ—¶é€‚åº”æ€§è¾ƒå·®ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **LangSAT** â€”â€” ä¸€ä¸ªèåˆ **NLP** å’Œ **Reinforcement Learning (RL)** çš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œç”¨äºå¢å¼º SAT æ±‚è§£è¿‡ç¨‹ï¼Œä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

- **Lang2Logic**ï¼šå°†è‡ªç„¶è¯­è¨€ï¼ˆEnglishï¼‰è‡ªåŠ¨è½¬åŒ–ä¸ºç­‰ä»·çš„ CNF è¡¨è¾¾å¼ã€‚
  - åˆ©ç”¨ **ChatGPT o1-mini API** è¿›è¡Œè‡ªç„¶è¯­è¨€åˆ°é€»è¾‘è¡¨è¾¾å¼çš„è½¬æ¢ã€‚
  - ä½¿ç”¨ **Lark parser + SymPy** å°†é€»è¾‘è¡¨è¾¾å¼æ ‡å‡†åŒ–å¹¶è½¬ä¸º CNFã€‚
  - å¼•å…¥ **SymPy çš„ simplify_logic** å¯¹ CNF è¿›è¡Œç®€åŒ–ä»¥æå‡æ•ˆç‡ã€‚

- **SmartSAT**ï¼šåŸºäº RL çš„ CDCL SAT æ±‚è§£å™¨ï¼ŒåŠ¨æ€ä¼˜åŒ–å˜é‡é€‰æ‹©å¯å‘å¼ã€‚
  - ä½¿ç”¨ **Proximal Policy Optimization (PPO)** ç®—æ³•è®­ç»ƒ RL agentã€‚
  - è§‚æµ‹ç©ºé—´åŒ…å«ï¼š
    - å˜é‡èµ‹å€¼çŠ¶æ€
    - å­å¥æ»¡è¶³æƒ…å†µ
    - **Clause-Variable Bipartite Graph** ç»“æ„è¡¨ç¤º
    - å…¨å±€ç‰¹å¾ï¼ˆæ¥è‡ª SATfeatPy åº“ï¼Œå…± 48 ç»´ï¼‰
  - åŠ¨ä½œç©ºé—´ä¸ºä» 40 ä¸ªå˜é‡ä¸­é€‰æ‹©ä¸‹ä¸€ä¸ªåˆ†æ”¯å˜é‡åŠå…¶å¸ƒå°”å€¼ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **å¯è®¿é—®æ€§** | ç”¨æˆ·å¯ç”¨è‡ªç„¶è¯­è¨€è¾“å…¥é—®é¢˜ï¼Œæ— éœ€æ‰‹åŠ¨ç¼–å†™ CNFï¼Œæ˜¾è‘—é™ä½ä½¿ç”¨é—¨æ§›ã€‚ |
| **çµæ´»æ€§** | SmartSAT èƒ½è‡ªé€‚åº”ä¸åŒç»“æ„çš„ CNFï¼ˆå°¤å…¶æ˜¯ NLP ç”Ÿæˆçš„å¤æ‚/æ¨¡ç³Šç»“æ„ï¼‰ï¼Œä¼˜äºå›ºå®šå¯å‘å¼æ–¹æ³•ã€‚ |
| **é€šç”¨æ€§** | ç»“åˆäº† NLP ä¸ RLï¼Œåœ¨æ•°å­¦é€»è¾‘ä»»åŠ¡ä¸­å®ç°è·¨æ¨¡æ€é›†æˆï¼Œæ‹“å±•äº† AI åœ¨å½¢å¼åŒ–æ¨ç†ä¸­çš„åº”ç”¨è¾¹ç•Œã€‚ |
| **é«˜æ•ˆæ€§** | å›¾ç»“æ„å»ºæ¨¡ + å…¨å±€ç‰¹å¾æå–ä½¿ RL agent è·å–æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæå‡å†³ç­–è´¨é‡ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- ä¸»è¦æµ‹è¯•æ•°æ®é›†ï¼š**uf20-91**
  - æ¥æºï¼šSATLIB
  - å«ä¹‰ï¼š20 ä¸ªå˜é‡ã€91 ä¸ªå­å¥çš„å¯æ»¡è¶³ SAT å®ä¾‹é›†åˆ
  - æ€»è®¡ 1000 ä¸ªå®ä¾‹ï¼ŒæŒ‰ 80%/20% åˆ†ä¸ºè®­ç»ƒé›†ï¼ˆ800ï¼‰å’Œæµ‹è¯•é›†ï¼ˆ200ï¼‰
- è¾“å…¥æ–‡æœ¬é•¿åº¦ï¼šLang2Logic æµ‹è¯•äº†æœ€é•¿ **450 å•è¯**çš„è‹±æ–‡æ®µè½

### âš™ï¸ å®éªŒè®¾ç½®
- **Lang2Logic éªŒè¯æ–¹å¼**ï¼š
  - æ‰‹åŠ¨æ„é€ è‡ªç„¶è¯­è¨€æ®µè½ â†’ ç» Lang2Logic è¾“å‡º CNF â†’ äººå·¥éªŒè¯æ­£ç¡®æ€§
  - ç¤ºä¾‹è§ Fig. 3ï¼ŒæˆåŠŸå°†å››å¥è¯è½¬æ¢ä¸ºç®€åŒ–åçš„ CNFï¼š`Q & R & ~P & ~S`

- **SmartSAT è®­ç»ƒé…ç½®**ï¼š
  - RL ç®—æ³•ï¼šPPOï¼ˆProximal Policy Optimizationï¼‰
  - å­¦ä¹ ç‡ï¼š0.0002
  - è®­ç»ƒå‘¨æœŸï¼š1 epochï¼ˆçº¦ 100,000 æ­¥ï¼‰
  - ç‰¹å¾æ¥æºï¼šSATfeatPy æå– 48 ç»´å…¨å±€ CNF ç‰¹å¾ï¼ˆæºè‡ª SATzilla åŸºç¡€ç‰¹å¾é›†ï¼‰

- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **æ€»æ±‚è§£æ—¶é—´ï¼ˆTotal Solving Timeï¼‰**
  - æ˜¯å¦æˆåŠŸåˆ¤å®š SAT/UNSAT
  - ä¸­ä½æ•°æ±‚è§£æ—¶é—´ã€åˆ†å¸ƒè¶‹åŠ¿ã€å¼‚å¸¸å€¼æ•°é‡

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline CDCL Solver**ï¼šé‡‡ç”¨ç»å…¸ **VSIDS** å¯å‘å¼è¿›è¡Œå˜é‡é€‰æ‹©
- å¯¹æ¯”æ¡ä»¶ï¼š
  - ç›¸åŒç¡¬ä»¶ç¯å¢ƒ
  - ç›¸åŒå‚æ•°è®¾ç½®
  - ç›¸åŒæµ‹è¯•é›†ï¼ˆuf20-91 çš„ 200 ä¸ªæµ‹è¯•å®ä¾‹ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®
| æŒ‡æ ‡ | SmartSAT | Baseline CDCL (VSIDS) |
|------|----------|------------------------|
| **ä¸­ä½æ±‚è§£æ—¶é—´** | **1.02 ç§’** | **1.02 ç§’** |
| **å¹³å‡è¡¨ç°èŒƒå›´** | 1.01â€“1.05 ç§’ | 1.01â€“1.05 ç§’ |
| **æ›´å¿«é—®é¢˜å æ¯”** | **~53%** | ~47% |
| **ç¨³å®šæ€§** | æ›´å°‘ç¦»ç¾¤ç‚¹ï¼Œæ³¢åŠ¨å° | å‡ºç°æ›´å¤šé«˜è€—æ—¶å¼‚å¸¸ |

> æ³¨ï¼šç»“æœè§ Fig. 4ï¼ŒSmartSAT åœ¨å¤šæ•°æƒ…å†µä¸‹è¡¨ç°æ›´ç¨³å®šã€‚

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ€§èƒ½æŒå¹³ä½†æ›´å…·é²æ£’æ€§**ï¼š
  - ä¸¤è€…ä¸­ä½æ—¶é—´ç›¸åŒï¼ˆ1.02sï¼‰ï¼Œè¡¨æ˜ SmartSAT è‡³å°‘è¾¾åˆ°ä¼ ç»Ÿæ–¹æ³•æ°´å¹³ã€‚
  - SmartSAT åœ¨ **53% çš„æµ‹è¯•å®ä¾‹ä¸Šæ›´å¿«**ï¼Œè¯´æ˜å…¶ RL å†³ç­–æœºåˆ¶å…·å¤‡å®é™…ä¼˜åŠ¿ã€‚
  - SmartSAT çš„è¿è¡Œæ—¶é—´åˆ†å¸ƒæ›´é›†ä¸­ï¼Œè€Œ Baseline CDCL å‡ºç°è¾ƒå¤šå°–å³°ï¼ˆå³æŸäº›éš¾ä¾‹å¤„ç†ä¸ä½³ï¼‰ï¼Œåæ˜ å…¶å¯¹ç»“æ„å˜åŒ–æ•æ„Ÿã€‚

- **åŸå› åˆ†æ**ï¼š
  - VSIDS æ˜¯é™æ€å¯å‘å¼ï¼Œæ— æ³•æ ¹æ®å½“å‰ CNF ç»“æ„åŠ¨æ€è°ƒæ•´ï¼›
  - SmartSAT çš„ RL agent èƒ½é€šè¿‡å›¾ç»“æ„æ„ŸçŸ¥å±€éƒ¨ä¾èµ–ï¼Œå¹¶ç»“åˆå…¨å±€ç‰¹å¾åšå‡ºæ›´ä¼˜å†³ç­–ã€‚

### âŒ æ¶ˆèå®éªŒï¼ˆæœªæ˜ç¡®æä¾›ï¼‰
è®ºæ–‡æœªæŠ¥å‘Šç³»ç»Ÿçš„æ¶ˆèç ”ç©¶ï¼ˆablation studyï¼‰ï¼Œä¾‹å¦‚ï¼š
- ç§»é™¤å›¾ç»“æ„è¡¨ç¤ºçš„å½±å“
- ä¸ä½¿ç”¨å…¨å±€ç‰¹å¾çš„æ•ˆæœ
- ä¸åŒ RL ç®—æ³•ï¼ˆå¦‚ DQN vs PPOï¼‰çš„æ¯”è¾ƒ

ğŸ‘‰ å› æ­¤ï¼Œå°šæ— æ³•é‡åŒ–å„æ¨¡å—çš„å…·ä½“è´¡çŒ®åº¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **LangSAT æˆåŠŸå®ç°äº†è‡ªç„¶è¯­è¨€åˆ° SAT æ±‚è§£çš„ç«¯åˆ°ç«¯ç®¡é“**ï¼š
   - Lang2Logic èƒ½å‡†ç¡®åœ°å°†å¤æ‚è‡ªç„¶è¯­è¨€æè¿°è½¬åŒ–ä¸ºæœ‰æ•ˆ CNFã€‚
   - æ”¯æŒé•¿è¾¾ 450 è¯çš„è¾“å…¥ï¼Œå…·å¤‡å®ç”¨æ½œåŠ›ã€‚

2. **SmartSAT çš„ RL-based heuristic å¯åª²ç¾ç”šè‡³ç•¥ä¼˜äº VSIDS**ï¼š
   - åœ¨ uf20-91 ä¸Šå®ç°ç›¸å½“ç”šè‡³ç¨ä¼˜çš„æ±‚è§£é€Ÿåº¦ã€‚
   - æ˜¾ç¤ºå‡ºæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›å’Œç¨³å®šæ€§ï¼Œå°¤å…¶é€‚ç”¨äºç»“æ„å¤šæ ·åŒ–çš„ CNFã€‚

3. **å›¾ç»“æ„ + å…¨å±€ç‰¹å¾æ˜¯å…³é”®è®¾è®¡**ï¼š
   - Clause-variable bipartite graph æä¾›ç»“æ„æ„ŸçŸ¥èƒ½åŠ›ã€‚
   - SATfeatPy æä¾›çš„ 48 ç»´å…¨å±€ç‰¹å¾å¸®åŠ© RL agent ç†è§£é—®é¢˜æ•´ä½“éš¾åº¦å’Œæ¨¡å¼ã€‚

### âš ï¸ å±€é™æ€§
1. **Lang2Logic ä¾èµ–å¤–éƒ¨ LLMï¼ˆChatGPT APIï¼‰**ï¼š
   - å­˜åœ¨æˆæœ¬ã€å»¶è¿Ÿã€éšç§å’Œå¯æ§æ€§é—®é¢˜ã€‚
   - éš¾ä»¥éƒ¨ç½²äºå°é—­ç³»ç»Ÿæˆ–å¤§è§„æ¨¡åœºæ™¯ã€‚

2. **ä»…åœ¨å°å‹ SAT å®ä¾‹ï¼ˆuf20-91ï¼‰ä¸ŠéªŒè¯**ï¼š
   - ç¼ºä¹åœ¨å·¥ä¸šçº§æˆ–æ›´å¤§è§„æ¨¡ SAT é—®é¢˜ä¸Šçš„æµ‹è¯•ï¼ˆå¦‚ç¡¬ä»¶éªŒè¯å®ä¾‹ï¼‰ã€‚
   - å°šä¸ç¡®å®šæ‰©å±•æ€§å¦‚ä½•ã€‚

3. **æ— æ¶ˆèå®éªŒæ”¯æŒæ¨¡å—æœ‰æ•ˆæ€§è®ºè¯**ï¼š
   - æ— æ³•åˆ¤æ–­ RLã€å›¾ç¥ç»ç½‘ç»œã€å…¨å±€ç‰¹å¾å„è‡ªçš„è´¡çŒ®æ¯”ä¾‹ã€‚

4. **æœªä¸å…¶ä»–å…ˆè¿› ML-based SAT solverï¼ˆå¦‚ NeuroSAT, NeuroDualï¼‰å¯¹æ¯”**ï¼š
   - ä»…å¯¹æ¯” VSIDSï¼Œæœªèƒ½ä½“ç°ç›¸å¯¹äºå…¶ä»–æœºå™¨å­¦ä¹ æ–¹æ³•çš„ä¼˜åŠ¿ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å¤§ Lang2Logic çš„è¾“å…¥ç±»å‹**ï¼š
   - æ¢ç´¢å°† **machine code** æˆ–ç¨‹åºä»£ç ä½œä¸ºè¾“å…¥ï¼Œè¿›ä¸€æ­¥æ‹“å®½åº”ç”¨åœºæ™¯ã€‚

2. **å¢å¼º SmartSAT çš„ç‰¹å¾å·¥ç¨‹**ï¼š
   - å¼•å…¥æ›´å¤šé«˜çº§å…¨å±€ç‰¹å¾ï¼Œæå‡ RL agent çš„åˆ¤åˆ«èƒ½åŠ›ã€‚

3. **è·¨æ•°æ®é›†æ€§èƒ½è¯„æµ‹**ï¼š
   - åœ¨å¤šç§ SAT é—®é¢˜ç±»åˆ«ï¼ˆéšæœºã€å·¥ä¸šã€å¯†ç å­¦ç­‰ï¼‰ä¸Šæµ‹è¯• SmartSAT è¡¨ç°ï¼Œåˆ†æå…¶é€‚ç”¨è¾¹ç•Œã€‚

4. **æ„å»ºå®Œå…¨æœ¬åœ°åŒ–çš„ Lang2Logic æ›¿ä»£æ–¹æ¡ˆ**ï¼š
   - å¼€å‘å¼€æºã€è½»é‡ã€å¯å¾®è°ƒçš„å°å‹ LLM æ›¿ä»£ ChatGPT APIï¼Œé™ä½æˆæœ¬å¹¶æé«˜å¯æ§æ€§ã€‚

---

## æ€»ç»“
LangSAT æ˜¯ä¸€é¡¹å¼€åˆ›æ€§çš„å°è¯•ï¼Œé¦–æ¬¡å°† **NLP** ä¸ **Reinforcement Learning** æ·±åº¦èåˆè¿› SAT æ±‚è§£æµç¨‹ï¼Œå®ç°äº†ä»â€œäººç±»è¯­è¨€â€åˆ°â€œå½¢å¼é€»è¾‘æ±‚è§£â€çš„æ— ç¼è¿æ¥ã€‚è™½ç„¶ç›®å‰æ€§èƒ½ä¸ä¼ ç»Ÿæ–¹æ³•åŸºæœ¬æŒå¹³ï¼Œä½†å…¶åœ¨ **å¯è®¿é—®æ€§ã€çµæ´»æ€§å’Œæ™ºèƒ½åŒ–å†³ç­–æ–¹é¢çš„æ½œåŠ›å·¨å¤§**ï¼Œä¸ºæœªæ¥æ™ºèƒ½æ¨ç†ç³»ç»Ÿçš„å‘å±•æä¾›äº†é‡è¦èŒƒå¼ã€‚

</details>

---

### 16. [Formal Specification for Fast ACS: Low-Latency File-Based Ordered Message Delivery at Scale](https://arxiv.org/abs/2512.04096)

**Authors**: Sushant Kumar Gupta, Anil Raghunath Iyer, Chang Yu, Neel Bagora, Olivier Pomerleau, Vivek Kumar, Prunthaban Kanthakumar  
**Category**: cs.DC  
**Published**: 2025-12-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.04096v1  

#### Abstract
Low-latency message delivery is crucial for real-time systems. Data originating from a producer must be delivered to consumers, potentially distributed in clusters across metropolitan and continental boundaries. With the growing scale of computing, there can be several thousand consumers of the data...

---

### 17. [Federated Learning for Terahertz Wireless Communication](https://arxiv.org/abs/2512.04984)

**Authors**: O. Tansel Baydas, Ozgur B. Akan  
**Category**: cs.DC  
**Published**: 2025-12-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.04984v1  

#### Abstract
The convergence of Terahertz (THz) communications and Federated Learning (FL) promises ultra-fast distributed learning, yet the impact of realistic wideband impairments on optimization dynamics remains theoretically uncharacterized. This paper bridges this gap by developing a multicarrier stochastic...

---

### 18. [Efficient Generative Transformer Operators For Million-Point PDEs](https://arxiv.org/abs/2512.04974)

**Authors**: Armand Kassa\"i Koupa\"i, Lise Le Boudec, Patrick Gallinari  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.04974v1  

#### Abstract
We introduce ECHO, a transformer-operator framework for generating million-point PDE trajectories. While existing neural operators (NOs) have shown promise for solving partial differential equations, they remain limited in practice due to poor scalability on dense grids, error accumulation during dy...

---

### 19. [David vs. Goliath: Can Small Models Win Big with Agentic AI in Hardware Design?](https://arxiv.org/abs/2512.05073)

**Authors**: Shashwat Shankar, Subhranshu Pandey, Innocent Dengkhw Mochahari, Bhabesh Mali, Animesh Basak Chowdhury, Sukanta Bhattacharjee, Chandan Karfa  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.05073v1  

#### Abstract
Large Language Model(LLM) inference demands massive compute and energy, making domain-specific tasks expensive and unsustainable. As foundation models keep scaling, we ask: Is bigger always better for hardware design? Our work tests this by evaluating Small Language Models coupled with a curated age...

---

### 20. [EvoEdit: Lifelong Free-Text Knowledge Editing through Latent Perturbation Augmentation and Knowledge-driven Parameter Fusion](https://arxiv.org/abs/2512.04545)

**Authors**: Pengfei Cao, Zeao Ji, Daojian Zeng, Jun Zhao, Kang Liu  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.04545v1  

#### Abstract
Adjusting the outdated knowledge of large language models (LLMs) after deployment remains a major challenge. This difficulty has spurred the development of knowledge editing, which seeks to accurately and efficiently modify a model's internal (parametric) knowledge without retraining it from scratch...

---

### 21. [AdmTree: Compressing Lengthy Context with Adaptive Semantic Trees](https://arxiv.org/abs/2512.04550)

**Authors**: Yangning Li, Shaoshen Chen, Yinghui Li, Yankai Chen, Hai-Tao Zheng, Hui Wang, Wenhao Jiang, Philip S. Yu  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.04550v1  

#### Abstract
The quadratic complexity of self-attention constrains Large Language Models (LLMs) in processing long contexts, a capability essential for many advanced applications. Context compression aims to alleviate this computational bottleneck while retaining critical semantic information. However, existing ...

---

### 22. [The Initialization Determines Whether In-Context Learning Is Gradient Descent](https://arxiv.org/abs/2512.04268)

**Authors**: Shifeng Xie, Rui Yuan, Simone Rossi, Thomas Hannagan  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.04268v1  

#### Abstract
In-context learning (ICL) in large language models (LLMs) is a striking phenomenon, yet its underlying mechanisms remain only partially understood. Previous work connects linear self-attention (LSA) to gradient descent (GD), this connection has primarily been established under simplified conditions ...

---

### 23. [RGE-GCN: Recursive Gene Elimination with Graph Convolutional Networks for RNA-seq based Early Cancer Detection](https://arxiv.org/abs/2512.04333)

**Authors**: Shreyas Shende, Varsha Narayanan, Vishal Fenn, Yiran Huang, Dincer Goksuluk, Gaurav Choudhary, Melih Agraz, Mengjia Xu  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.04333v1  

#### Abstract
Early detection of cancer plays a key role in improving survival rates, but identifying reliable biomarkers from RNA-seq data is still a major challenge. The data are high-dimensional, and conventional statistical methods often fail to capture the complex relationships between genes. In this study, ...

---

### 24. [Score Matching for Estimating Finite Point Processes](https://arxiv.org/abs/2512.04617)

**Authors**: Haoqun Cao, Yixuan Zhang, Feng Zhou  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.04617v1  

#### Abstract
Score matching estimators have garnered significant attention in recent years because they eliminate the need to compute normalizing constants, thereby mitigating the computational challenges associated with maximum likelihood estimation (MLE).While several studies have proposed score matching estim...

---

### 25. [Multi-Agent Reinforcement Learning for Intraday Operating Rooms Scheduling under Uncertainty](https://arxiv.org/abs/2512.04918)

**Authors**: Kailiang Liu, Ying Chen, Ralf Bornd\"orfer, Thorsten Koch  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.04918v1  

#### Abstract
Intraday surgical scheduling is a multi-objective decision problem under uncertainty-balancing elective throughput, urgent and emergency demand, delays, sequence-dependent setups, and overtime. We formulate the problem as a cooperative Markov game and propose a multi-agent reinforcement learning (MA...

---

### 26. [TV2TV: A Unified Framework for Interleaved Language and Video Generation](https://arxiv.org/abs/2512.05103)

**Authors**: Xiaochuang Han, Youssef Emad, Melissa Hall, John Nguyen, Karthik Padthe, Liam Robbins, Amir Bar, Delong Chen, Michal Drozdzal, Maha Elbayad, Yushi Hu, Shang-Wen Li, Sreya Dutta Roy, Jakob Verbeek, XuDong Wang, Marjan Ghazvininejad, Luke Zettlemoyer, Emily Dinan  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.05103v1  

#### Abstract
Video generation models are rapidly advancing, but can still struggle with complex video outputs that require significant semantic branching or repeated high-level reasoning about what should happen next. In this paper, we introduce a new class of omni video-text models that integrate ideas from rec...

---

### 27. [The Universal Weight Subspace Hypothesis](https://arxiv.org/abs/2512.05117)

**Authors**: Prakhar Kaushik, Shravan Chaudhari, Ankit Vaidya, Rama Chellappa, Alan Yuille  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.05117v1  

#### Abstract
We show that deep neural networks trained across diverse tasks exhibit remarkably similar low-dimensional parametric subspaces. We provide the first large-scale empirical evidence that demonstrates that neural networks systematically converge to shared spectral subspaces regardless of initialization...

---

### 28. [Multi-Agent Reinforcement Learning with Communication-Constrained Priors](https://arxiv.org/abs/2512.03528)

**Authors**: Guang Yang, Tianpei Yang, Jingwen Qiao, Yanqing Wu, Jing Huo, Xingguo Chen, Yang Gao  
**Category**: cs.AI  
**Published**: 2025-12-05  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.03528v1  

#### Abstract
Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robu...

---

### 29. [Hybrid Quantum-Classical Autoencoders for Unsupervised Network Intrusion Detection](https://arxiv.org/abs/2512.05069)

**Authors**: Mohammad Arif Rasyidi, Omar Alhussein, Sami Muhaidat, Ernesto Damiani  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.05069v1  

#### Abstract
Unsupervised anomaly-based intrusion detection requires models that can generalize to attack patterns not observed during training. This work presents the first large-scale evaluation of hybrid quantum-classical (HQC) autoencoders for this task. We construct a unified experimental framework that ite...

---

### 30. [DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization](https://arxiv.org/abs/2512.03607)

**Authors**: Yusen Wu, Xiaotie Deng  
**Category**: cs.AI  
**Published**: 2025-12-05  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.03607v1  

#### Abstract
This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modal...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
