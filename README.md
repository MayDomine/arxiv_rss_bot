# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-05 06:08:12 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [FlexSpec: Frozen Drafts Meet Evolving Targets in Edge-Cloud Collaborative LLM Speculative Decoding](https://arxiv.org/abs/2601.00644)

**Authors**: Yuchen Li, Rui Kong, Zhonghao Lyu, Qiyang Li, Xinran Chen, Hengyi Cai, Lingyong Yan, Shuaiqiang Wang, Jiashu Zhao, Guangxu Zhu, Linghe Kong, Guihai Chen, Haoyi Xiong, Dawei Yin  
**Category**: cs.DC  
**Published**: 2026-01-05  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.00644v1  

#### Abstract
Deploying large language models (LLMs) in mobile and edge computing environments is constrained by limited on-device resources, scarce wireless bandwidth, and frequent model evolution. Although edge-cloud collaborative inference with speculative decoding (SD) can reduce end-to-end latency by executi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFlexSpec: Frozen Drafts Meet Evolving Targets in Edge-Cloud Collaborative LLM Speculative Decoding

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

åœ¨è¾¹ç¼˜-äº‘ååŒæ¨ç†åœºæ™¯ä¸­ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **é¢‘ç¹æ¨¡å‹æ›´æ–°å¯¼è‡´é€šä¿¡å¼€é”€å·¨å¤§**ï¼šäº‘ç«¯ç›®æ ‡æ¨¡å‹é€šè¿‡ PEFTï¼ˆå¦‚ LoRAï¼‰æŒç»­æ¼”è¿›ï¼Œä¼ ç»Ÿ Speculative Decodingï¼ˆSDï¼‰è¦æ±‚è¾¹ç¼˜ç«¯è‰ç¨¿æ¨¡å‹åŒæ­¥æ›´æ–°ï¼Œå¼•å‘â€œ**æ›´æ–°é£æš´**â€ï¼ˆupdate stormï¼‰ï¼Œå¸¦æ¥é«˜æ˜‚çš„å¸¦å®½æ¶ˆè€—ã€‚
- **åˆ†å¸ƒåç§»å¯¼è‡´æ€§èƒ½å´©æºƒ**ï¼ˆperformance collapseï¼‰ï¼šè‹¥ä¸æ›´æ–°è¾¹ç¼˜è‰ç¨¿æ¨¡å‹ï¼Œåˆ™å…¶è¾“å‡ºåˆ†å¸ƒä¸æ¼”åŒ–åçš„äº‘ç«¯ç›®æ ‡æ¨¡å‹ä¸¥é‡å¤±é…ï¼Œtoken æ¥å—ç‡æ€¥å‰§ä¸‹é™ï¼Œç”šè‡³åŠ£äºæ ‡å‡†è‡ªå›å½’è§£ç ã€‚
- **æ— çº¿ä¿¡é“åŠ¨æ€æ€§å½±å“æ¨æµ‹æ•ˆç‡**ï¼šå›ºå®šæ¨æµ‹é•¿åº¦ $K$ åœ¨æ—¶å˜ç½‘ç»œæ¡ä»¶ä¸‹è¡¨ç°ä¸ä½³ï¼Œåœ¨å¼±ä¿¡å·ä¸‹ä¼ è¾“å»¶è¿Ÿä¸»å¯¼æ€»å»¶è¿Ÿï¼Œè€Œå¼ºä¿¡å·ä¸‹åˆæ— æ³•å……åˆ†åˆ©ç”¨å¸¦å®½ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **FlexSpec**ï¼Œä¸€ç§é¢å‘æ¼”åŒ–è¾¹ç¼˜-äº‘ç³»ç»Ÿçš„é€šä¿¡é«˜æ•ˆåä½œæ¨ç†æ¡†æ¶ï¼Œæ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### âœ… **å…±äº«å†»ç»“ä¸»å¹²æ¶æ„**ï¼ˆShared Frozen Backbone Architectureï¼‰
- å¼•å…¥ä¸€ä¸ª**å…±äº«çš„å†»ç»“é”šå—**ï¼ˆfrozen anchor blockï¼‰ï¼Œä»åŸºç¡€ç‰ˆæœ¬çš„ç›®æ ‡æ¨¡å‹ä¸­å¤åˆ¶è‡³è¾¹ç¼˜ä¾§è‰ç¨¿æ¨¡å‹ï¼Œå¹¶ä¿æŒå†»ç»“ã€‚
- è‰ç¨¿æ¨¡å‹ä»…è®­ç»ƒä¸€ä¸ªè½»é‡çº§å¤´éƒ¨ï¼ˆlightweight headï¼‰ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦ï¼ˆKnowledge Distillationï¼‰å¯¹é½ç‰¹å¾ç©ºé—´ã€‚
- äº‘ç«¯é‡‡ç”¨ PEFT å¾®è°ƒæ—¶ï¼Œ**å†»ç»“ä¸»å¹²å‚æ•°**ï¼ˆåŒ…æ‹¬é”šå—å’Œ LM headï¼‰ï¼Œåªæ›´æ–°é€‚é…å™¨å‚æ•°ï¼Œä»è€Œä¿è¯è¾¹ç¼˜è‰ç¨¿æ¨¡å‹æ— éœ€é‡è®­ç»ƒå³å¯å…¼å®¹å¤šä¸ªæ¼”åŒ–ç‰ˆæœ¬çš„ç›®æ ‡æ¨¡å‹ã€‚

> è¿™å®ç°äº† **â€œé™æ€è‰ç¨¿ + åŠ¨æ€ç›®æ ‡â€** çš„è§£è€¦è®¾è®¡ï¼Œä»æ ¹æœ¬ä¸Šé¿å…äº† OTA åŒæ­¥ã€‚

#### âœ… **ä¿¡é“æ„ŸçŸ¥çš„è‡ªé€‚åº”æ¨æµ‹æœºåˆ¶**ï¼ˆChannel-Aware Adaptive Speculationï¼‰
- å°†æ¨æµ‹é•¿åº¦ $K$ è§†ä¸ºå¯è°ƒå˜é‡ï¼ŒåŸºäºå®æ—¶ä¿¡é“çŠ¶æ€ä¿¡æ¯ï¼ˆCSIï¼‰å’Œè®¾å¤‡èƒ½è€—é¢„ç®—åŠ¨æ€è°ƒæ•´ã€‚
- æ„å»ºç²¾ç»†åŒ–å»¶è¿Ÿæ¨¡å‹ï¼Œç»¼åˆè€ƒè™‘è¾¹ç¼˜è®¡ç®—ã€ä¸Šè¡Œä¼ è¾“ã€äº‘ç«¯éªŒè¯ã€ä¸‹è¡Œåé¦ˆå››éƒ¨åˆ†ã€‚
- æ¨å¯¼å‡ºæœ€å¤§åŒ– **æœ‰æ•ˆ token ç”Ÿæˆé€Ÿç‡**ï¼ˆEffective Token Generation Rate, ETGRï¼‰çš„æœ€ä¼˜ $K^*$ å†³ç­–å…¬å¼ï¼š
  $$
  K^* = \arg\max_K \frac{\mathbb{E}[T|K]}{T_{\text{fixed}} + K \cdot T_{\text{marginal}}(R_n)}
  $$
  å…¶ä¸­ $T_{\text{marginal}}$ åŒ…å«é€šä¿¡é€Ÿç‡ $R_n$ å’Œæ¯ token éªŒè¯å¼€é”€ã€‚

> å®ç°äº†åœ¨ä¸åŒç½‘ç»œæ¡ä»¶ä¸‹çš„è‡ªåŠ¨æƒè¡¡ï¼šå¼±ç½‘ç”¨å° $K$ï¼Œå¼ºç½‘ç”¨å¤§ $K$ã€‚

#### âœ… **è¯­ä¹‰åŒæ­¥åè®®ä¸ KV ç¼“å­˜å›æ»šæœºåˆ¶**
- è¾¹ç¼˜å‘é€æ•´å—è‰ç¨¿ token ç´¢å¼•ï¼ˆéæµ®ç‚¹åµŒå…¥ï¼‰ï¼Œå¤§å¹…å‹ç¼©ä¸Šè¡Œè´Ÿè½½ã€‚
- äº‘ç«¯ç»´æŠ¤æŒä¹…åŒ– KV Cache ä¼šè¯ï¼Œä»…å¯¹æ–°æ¥æ”¶çš„è‰ç¨¿ token è®¡ç®— KV å¯¹ã€‚
- è‹¥å‘ç”Ÿæ‹’ç»ï¼Œæ‰§è¡Œ KV Cache å›æ»šï¼Œé¿å…é‡å¤è®¡ç®—æ•´ä¸ªä¸Šä¸‹æ–‡ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼ ç»Ÿ SD æ–¹æ³•ï¼ˆå¦‚ EAGLEã€Medusaï¼‰ | FlexSpec |
|------|-------------------------------|----------|
| **æ¨¡å‹åŒæ­¥éœ€æ±‚** | å¿…é¡»åŒæ­¥æ›´æ–°è¾¹ç¼˜è‰ç¨¿æ¨¡å‹ | âŒ æ— éœ€åŒæ­¥ï¼Œæ”¯æŒç‰ˆæœ¬æ— å…³æ¨ç† |
| **é€šä¿¡å¼€é”€** | é«˜é¢‘ OTA ä¸‹è½½æ¨¡å‹æƒé‡ï¼ˆGBçº§ï¼‰ | ä»…ä¼ è¾“ token ç´¢å¼•ï¼ˆKBçº§ï¼‰ |
| **æŠ—åˆ†å¸ƒåç§»èƒ½åŠ›** | åˆ†å¸ƒåç§»åæ¥å—ç‡éª¤é™ | é”šå—å¯¹é½ï¼Œé²æ£’æ€§å¼º |
| **ä¿¡é“é€‚åº”æ€§** | å›ºå®šæ¨æµ‹é•¿åº¦ $K$ | è‡ªé€‚åº” $K$ï¼ŒåŒ¹é…ä¿¡é“è´¨é‡ |
| **éƒ¨ç½²æˆæœ¬** | éœ€é¢‘ç¹ç»´æŠ¤è¾¹ç¼˜æ¨¡å‹ | å•ä¸€é™æ€æ¨¡å‹æœåŠ¡å¤šç‰ˆæœ¬ç›®æ ‡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

æ¶µç›–å¤šç§ä»»åŠ¡ç±»å‹ä»¥éªŒè¯æ³›åŒ–èƒ½åŠ›ï¼š
- **æ•°å­¦æ¨ç†**ï¼šGSM8K
- **é—®ç­”**ï¼šNatural Questionsï¼ˆQA & RAGï¼‰
- **å¯¹è¯**ï¼šMT-Bench
- **æœºå™¨ç¿»è¯‘**ï¼šWMT14 DE-EN
- **æ‘˜è¦**ï¼šCNN/DailyMail
- **ä»£ç ç”Ÿæˆ**ï¼šHumanEval

### **å®éªŒè®¾ç½®**

#### **ç¡¬ä»¶å¹³å°**
- **äº‘ç«¯æœåŠ¡å™¨**ï¼šNVIDIA H800/A800/V100 GPU é›†ç¾¤
- **è¾¹ç¼˜è®¾å¤‡**ï¼šJetson AGX Orinã€Snapdragon 8 Gen3ã€iPhone 15 Pro Maxã€Raspberry Pi 5
- **ç½‘ç»œç¯å¢ƒæ¨¡æ‹Ÿ**ï¼š5Gï¼ˆå¼ºï¼‰ã€4Gï¼ˆå¹³å‡ï¼‰ã€WiFiï¼ˆå¼±ï¼‰

#### **æ¨¡å‹é…ç½®**
- **ç›®æ ‡æ¨¡å‹**ï¼šLlama-2 70Bã€Llama-3 70Bã€Mixtral 8x7B
- **è‰ç¨¿æ¨¡å‹**ï¼šåŸºäº Llama-2 7B æ„å»ºï¼Œä»…ä¿ç•™æœ€åä¸€å±‚ Transformer å—ä½œä¸ºé”šå— + è½»é‡ MLP å¤´éƒ¨

#### **è¯„ä¼°æŒ‡æ ‡**
- **ç«¯åˆ°ç«¯å»¶è¿Ÿ**ï¼ˆEnd-to-End Latencyï¼‰
- **åŠ é€Ÿæ¯”**ï¼ˆSpeedup vs. Cloud-Onlyï¼‰
- **Token æ¥å—ç‡**ï¼ˆAcceptance Rateï¼‰
- **èƒ½é‡æ¶ˆè€—**ï¼ˆEnergy Consumptionï¼‰
- **å†…å­˜å ç”¨**ï¼ˆMemory Footprintï¼‰
- **çƒ­æ•ˆåº”**ï¼ˆThermal Behaviorï¼‰

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿æ–¹æ³• | ç‰¹ç‚¹ |
|--------|------|
| **Cloud-Only** | æ ‡å‡†è‡ªå›å½’è§£ç ï¼Œæ‰€æœ‰è®¡ç®—åœ¨äº‘ç«¯ |
| **Standard SD (Naive)** | ä½¿ç”¨é¢„è®­ç»ƒå°æ¨¡å‹ä½œè‰ç¨¿ï¼Œæ— å¯¹é½æœºåˆ¶ |
| **PLD (n-gram)** | åŸºäº n-gram æ£€ç´¢çš„å…è®­ç»ƒè‰ç¨¿ |
| **Lookahead** | å¹¶è¡Œè§£ç ç®—æ³•ï¼Œæ— éœ€é¢å¤–è‰ç¨¿æ¨¡å‹ |
| **EAGLE-2 (Synced)** | å½“å‰æœ€ä¼˜æ¨¡å‹å†…æ¨æµ‹æ–¹æ³•ï¼Œâ€œç†æƒ³åŒæ­¥â€è®¾å®š |
| **Medusa-1 (Synced)** | å¤šå¤´é¢„æµ‹æ¡†æ¶ï¼Œå‡è®¾å®Œå…¨åŒæ­¥ |
| **DSSD** | ä¸“ä¸ºæ— çº¿è®¾è®¡çš„ SD æ¡†æ¶ï¼Œä½†ä½¿ç”¨å›ºå®šç­–ç•¥ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### ğŸ”¹ **è¡¨ III & IVï¼šç¡®å®šæ€§ä¸éšæœºé‡‡æ ·ä¸‹çš„ç«¯åˆ°ç«¯å»¶è¿Ÿä¸åŠ é€Ÿæ¯”**
- åœ¨ **GSM8K** ä¸Šï¼ˆæ¸©åº¦=0ï¼‰ï¼š
  - FlexSpec åœ¨ **WiFiï¼ˆå¼±ï¼‰ç¯å¢ƒä¸‹å®ç° 1.95Ã— åŠ é€Ÿ**
  - Standard SD å› åˆ†å¸ƒåç§»åè€Œ **æ…¢ 34%**ï¼ˆ0.66Ã—ï¼‰
  - EAGLE-2 åœ¨å¼±ç½‘ä¸‹å› ä¼ è¾“å¼€é”€è¿‡å¤§ä¹Ÿé€€åŒ–è‡³ 0.86Ã—
- åœ¨ **éšæœºé‡‡æ ·**ï¼ˆTemperature=1ï¼‰ä¸‹ï¼š
  - FlexSpec ä»ä¿æŒ **1.65Ã—â€“1.90Ã— åŠ é€Ÿ**
  - EAGLE-2 æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼ˆä» 2.4Ã— â†’ 1.6Ã—ï¼‰ï¼Œå› å…¶ä¾èµ–è´ªå¿ƒè·¯å¾„
  - Standard SD å‡ºç°â€œæ€§èƒ½å´©æºƒâ€ï¼Œåœ¨ WiFi ä¸‹ä»…ä¸º 0.65Ã—

> âœ… **FlexSpec æ˜¯å”¯ä¸€åœ¨å¼±ç½‘å’Œéšæœºé‡‡æ ·ä¸‹ä»ç¨³å®šåŠ é€Ÿçš„æ–¹æ³•**

#### ğŸ”¹ **å›¾ 5ï¼šæ¶ˆèå®éªŒ â€” å›ºå®š vs è‡ªé€‚åº”æ¨æµ‹é•¿åº¦**
- å›ºå®š $K=5$ï¼šåœ¨ 5G ä¸‹è¡¨ç°è‰¯å¥½ï¼ˆ220msï¼‰ï¼Œä½†åœ¨ WiFi ä¸‹é«˜è¾¾ 1455msï¼ˆ**2.3Ã— æ…¢äº baseline**ï¼‰
- å›ºå®š $K=1$ï¼šç¨³å¥ä½†æµªè´¹å¸¦å®½ï¼ˆ5G ä¸‹ 405msï¼‰
- **FlexSpecï¼ˆè‡ªé€‚åº”ï¼‰**ï¼šåœ¨ 5G ä¸‹æ¥è¿‘ $K=5$ï¼Œåœ¨ WiFi ä¸‹è‡ªåŠ¨é™ä¸º $Kâ‰ˆ1$ï¼Œå®ç°æœ€ä½³å¹³è¡¡

> âœ… **ä¿¡é“æ„ŸçŸ¥è‡ªé€‚åº”æœºåˆ¶æ˜¾è‘—æå‡é²æ£’æ€§å’Œååé‡**

#### ğŸ”¹ **è¡¨ Vï¼šå¼‚æ„è¾¹ç¼˜è®¾å¤‡ä¸Šçš„æ€§èƒ½**
| è®¾å¤‡ | GSM8K åŠ é€Ÿæ¯” |
|------|-------------|
| Raspberry Pi 5ï¼ˆCPUï¼‰ | 0.76Ã—ï¼ˆåå‘å‡é€Ÿï¼‰ |
| iPhone 15 Pro Maxï¼ˆNPUï¼‰ | 1.82Ã— |
| Snapdragon 8 Gen3ï¼ˆNPUï¼‰ | 1.93Ã— |
| Jetson AGX Orinï¼ˆGPUï¼‰ | 1.96Ã— |

> âœ… **éœ€ç¡¬ä»¶åŠ é€Ÿæ”¯æŒï¼ˆGPU/NPUï¼‰æ‰èƒ½å‘æŒ¥ä¼˜åŠ¿ï¼›æ¶ˆè´¹çº§æ‰‹æœºä¹Ÿå¯è¿è¡Œ**

#### ğŸ”¹ **è¡¨ VIï¼šæ–°æ¨¡å‹æ¶æ„æ‰©å±•æ€§**
| ç›®æ ‡æ¨¡å‹ | FlexSpec åœ¨ 5G ä¸‹åŠ é€Ÿæ¯” |
|---------|-----------------------|
| Llama-2 70B | 1.95Ã— |
| Llama-3 70B | **2.30Ã—** |
| Mixtral 8x7Bï¼ˆMoEï¼‰ | 1.75Ã— |

> âœ… **é”šå—å¯¹é½æœºåˆ¶å…·æœ‰è·¨æ¨¡å‹è¿ç§»èƒ½åŠ›**

#### ğŸ”¹ **å›¾ 6ï¼šèƒ½è€—åˆ†æ**
- **FlexSpec ç›¸æ¯” Cloud-Only å‡å°‘ 53% æ€»èƒ½è€—**
- ä¸»è¦èŠ‚çœæ¥è‡ªé€šä¿¡èƒ½è€—ï¼ˆradio active time ç¼©çŸ­ï¼‰
- æœ¬åœ°è®¡ç®—èƒ½è€—ä½ï¼Œä¸”é¿å…äº†å…¨è®¾å¤‡æ¨ç†çš„é«˜å‘çƒ­é—®é¢˜

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **é™æ€è‰ç¨¿æ¨¡å‹å¯é€šè¿‡é”šå—å¯¹é½æ”¯æŒåŠ¨æ€ç›®æ ‡æ¨¡å‹**ï¼Œæ— éœ€ OTA åŒæ­¥ï¼Œå½»åº•è§£å†³â€œæ›´æ–°é£æš´â€é—®é¢˜ã€‚
2. âœ… **ä¿¡é“æ„ŸçŸ¥çš„è‡ªé€‚åº”æ¨æµ‹æœºåˆ¶** èƒ½åœ¨ä¸åŒç½‘ç»œæ¡ä»¶ä¸‹è‡ªåŠ¨è°ƒèŠ‚ $K$ï¼Œæœ€å¤§åŒ– ETGRï¼Œåœ¨å¼±ç½‘ä¸­å°¤ä¸ºå…³é”®ã€‚
3. âœ… **FlexSpec åœ¨å¤šæ ·åŒ–ä»»åŠ¡ã€æ¨¡å‹ã€è®¾å¤‡å’Œç½‘ç»œæ¡ä»¶ä¸‹å‡è¡¨ç°å‡ºè‰²**ï¼Œå°¤å…¶åœ¨å¸¦å®½å—é™ç¯å¢ƒä¸­ä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚
4. âœ… **èƒ½é‡ä¸çƒ­æ•ˆç‡æ˜¾è‘—æå‡**ï¼Œé€‚åˆç§»åŠ¨ç»ˆç«¯é•¿æœŸäº¤äº’å¼åº”ç”¨ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- **ä¾èµ–ä¸»å¹²å†»ç»“çš„å¾®è°ƒæ–¹å¼**ï¼šè¦æ±‚äº‘ç«¯å¿…é¡»å†»ç»“ä¸»å¹²è¿›è¡Œ PEFTï¼Œé™åˆ¶äº†æŸäº›å…¨å‚æ•°å¾®è°ƒåœºæ™¯ã€‚
- **å¯¹æä½ç«¯è®¾å¤‡ä¸å‹å¥½**ï¼šçº¯ CPU è®¾å¤‡ï¼ˆå¦‚ Raspberry Piï¼‰æ— æ³•å—ç›Šï¼Œéœ€ NPU/GPU æ”¯æŒã€‚
- **åˆå§‹è®­ç»ƒä»éœ€ä¸€æ¬¡ç¦»çº¿è’¸é¦è¿‡ç¨‹**ï¼šè™½ç„¶åç»­æ— éœ€å†è®­ç»ƒï¼Œä½†éƒ¨ç½²å‰éœ€å®Œæˆå¯¹é½è®­ç»ƒã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- æ‰©å±•è‡³æ›´å¤šæ¨¡å‹å®¶æ—ï¼ˆå¦‚ Qwenã€Phi ç­‰ï¼‰å’Œæ¨¡æ€ï¼ˆå¤šæ¨¡æ€ LLMï¼‰ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„è½»é‡åŒ–è‰ç¨¿ç»“æ„ï¼ˆå¦‚ MoE è‰ç¨¿ï¼‰ã€‚
- ç»“åˆ Early Exit æˆ– Dynamic Inference è¿›ä¸€æ­¥é™ä½è¾¹ç¼˜è®¡ç®—è´Ÿæ‹…ã€‚
- åœ¨çœŸå®ç”¨æˆ·æµé‡ä¸‹è¿›è¡Œå¤§è§„æ¨¡åœ¨çº¿ A/B æµ‹è¯•ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **FlexSpec é€šè¿‡â€œå…±äº«å†»ç»“é”šå— + ä¿¡é“æ„ŸçŸ¥è‡ªé€‚åº”æ¨æµ‹â€çš„åŒé‡åˆ›æ–°ï¼Œé¦–æ¬¡å®ç°äº†ç‰ˆæœ¬æ— å…³ã€é€šä¿¡é«˜æ•ˆã€é²æ£’å¯æ‰©å±•çš„è¾¹ç¼˜-äº‘ååŒ LLM æ¨ç†æ¡†æ¶ï¼Œä¸ºç§»åŠ¨ç«¯éƒ¨ç½²å¤§æ¨¡å‹æä¾›äº†å®ç”¨åŒ–è§£å†³æ–¹æ¡ˆã€‚**

</details>

---

### 2. [Optimized Hybrid Feature Engineering for Resource-Efficient Arrhythmia Detection in ECG Signals: An Optimization Framework](https://arxiv.org/abs/2601.00192)

**Authors**: Moirangthem Tiken Singh, Manibhushan Yaikhom  
**Category**: cs.LG  
**Published**: 2026-01-05  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.00192v1  

#### Abstract
Cardiovascular diseases, particularly arrhythmias, remain a leading global cause of mortality, necessitating continuous monitoring via the Internet of Medical Things (IoMT). However, state-of-the-art deep learning approaches often impose prohibitive computational overheads, rendering them unsuitable...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šOptimized Hybrid Feature Engineering for Resource-Efficient Arrhythmia Detection in ECG Signals: An Optimization Framework

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åŸºäºæ·±åº¦å­¦ä¹ çš„å¿ƒå¾‹å¤±å¸¸æ£€æµ‹æ¨¡å‹ï¼ˆå¦‚ CNNã€Transformerï¼‰è™½ç„¶ç²¾åº¦é«˜ï¼Œä½†å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **è®¡ç®—å¼€é”€å¤§**ï¼šæ¨¡å‹å‚æ•°å¤šã€æ¨ç†å»¶è¿Ÿé«˜ï¼Œéš¾ä»¥éƒ¨ç½²åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ï¼ˆedge devicesï¼‰ä¸Šã€‚
- **èƒ½æ•ˆä½**ï¼šé«˜åŠŸè€—é™åˆ¶äº†å…¶åœ¨å¯ç©¿æˆ´è®¾å¤‡å’Œç”µæ± ä¾›ç”µç³»ç»Ÿä¸­çš„é•¿æœŸåº”ç”¨ã€‚
- **ç¼ºä¹å¯è§£é‡Šæ€§**ï¼šé»‘ç®±å†³ç­–æœºåˆ¶é˜»ç¢äº†ä¸´åºŠä¿¡ä»»ä¸åŒ»å­¦éªŒè¯ã€‚

è¿™äº›é—®é¢˜å¯¼è‡´æœ€å…ˆè¿›çš„æ¨¡å‹æ— æ³•æ»¡è¶³ IoMTï¼ˆInternet of Medical Thingsï¼‰åœºæ™¯ä¸‹å¯¹**å®æ—¶æ€§ã€ä½åŠŸè€—ã€å¯è§£é‡Šæ€§**çš„ç»¼åˆéœ€æ±‚ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§**ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„ä¼˜åŒ–æ¡†æ¶**ï¼ˆdata-centric frameworkï¼‰ï¼Œå°†å¤æ‚æ€§ä»â€œæ¨¡å‹â€è½¬ç§»åˆ°â€œç‰¹å¾å·¥ç¨‹â€ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æ··åˆç‰¹å¾å·¥ç¨‹ï¼Œä½¿åŸå§‹éçº¿æ€§çš„ ECG æ•°æ®æµå½¢å˜ä¸ºçº¿æ€§å¯åˆ†ï¼Œä»è€Œå¯ç”¨è¶…è½»é‡çº§ã€å¯è§£é‡Šçš„çº¿æ€§åˆ†ç±»å™¨ã€‚**

#### ä¸»è¦æŠ€æœ¯è·¯å¾„ï¼š
1. **Hybrid Feature Engineering**ï¼š
   - ç»“åˆ **wavelet decomposition**ï¼ˆå°æ³¢åˆ†è§£ï¼‰æå–æ—¶é¢‘åŸŸç‰¹å¾ï¼›
   - å¼•å…¥ **graph-theoretic descriptors**ï¼ˆå›¾è®ºæè¿°ç¬¦ï¼‰ï¼Œå¦‚ PageRank ä¸­å¿ƒæ€§å’Œèšç±»ç³»æ•°ï¼Œå»ºæ¨¡å¿ƒè·³åºåˆ—ä¹‹é—´çš„ç»“æ„ç›¸ä¼¼æ€§ä¸åŠ¨æ€å…³ç³»ã€‚
2. **ç‰¹å¾ç©ºé—´ä¼˜åŒ–**ï¼š
   - ä½¿ç”¨ **Mutual Information** å’Œ **Recursive Feature Elimination (RFE)** è¿›è¡Œç‰¹å¾é€‰æ‹©ï¼›
   - åº”ç”¨ **PCA** æå–ä¸»æˆåˆ†å¹¶æ‹¼æ¥åˆ°åŸå§‹ç‰¹å¾ä¸­ï¼Œä¿ç•™å…¨å±€æ–¹å·®çš„åŒæ—¶å¢å¼ºåˆ¤åˆ«èƒ½åŠ›ã€‚
3. **åˆ†ç±»ç­–ç•¥è½¬å˜**ï¼š
   - æ”¾å¼ƒå¤æ‚çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œé‡‡ç”¨ **Logistic Regression** å’Œ **Linear SVM** ç­‰çº¿æ€§æ¨¡å‹è¿›è¡Œæœ€ç»ˆåˆ†ç±»ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ–¹æ³• | æœ¬è®ºæ–‡æ–¹æ³• |
|------|------------------|-----------|
| **æ¨¡å‹å¤§å°** | æ•° MB åˆ°æ•°å MB | < 9 KBï¼ˆLinear SVC: 8.54 KBï¼‰ |
| **æ¨ç†å»¶è¿Ÿ** | æ¯«ç§’çº§ï¼ˆmsï¼‰ | å¾®ç§’çº§ï¼ˆÎ¼sï¼‰â€”â€”ä»… **0.46 Î¼s** |
| **èƒ½è€—æ½œåŠ›** | é«˜ï¼ˆéœ€ GPU æˆ–é«˜æ€§èƒ½ MCUï¼‰ | æä½ï¼Œé€‚åˆç”µæ± ç”šè‡³æ— æºä¼ æ„Ÿå™¨ |
| **å¯è§£é‡Šæ€§** | é»‘ç®±ï¼Œéš¾è§£é‡Š | ç™½ç›’ï¼Œæ”¯æŒç‰¹å¾é‡è¦æ€§åˆ†æ |
| **å‡†ç¡®ç‡** | ~99% | **98.44%**ï¼ˆMIT-BIH ä¸Šåª²ç¾ SOTAï¼‰ |

> âœ… å®ç°äº†â€œ**ä¸´åºŠçº§ç²¾åº¦ + è¾¹ç¼˜çº§æ•ˆç‡ + åŒ»ç–—çº§å¯è§£é‡Šæ€§**â€ä¸‰é‡ç›®æ ‡çš„å¹³è¡¡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
- **MIT-BIH Arrhythmia Database**ï¼š
  - 48 æ¡åŒé€šé“ï¼ˆtwo-channelï¼‰ã€30 åˆ†é’ŸåŠ¨æ€è®°å½•ï¼Œé‡‡æ ·ç‡ 360 Hzã€‚
  - ä½œä¸ºä¸»è¦åŸºå‡†æµ‹è¯•é›†ã€‚
- **St. Petersburg INCART 12-Lead Arrhythmia Database**ï¼š
  - 75 æ¡ 12 å¯¼è”è®°å½•ï¼ŒåŸé‡‡æ ·ç‡ 257 Hz â†’ ç»Ÿä¸€é‡é‡‡æ ·è‡³ 360 Hzã€‚
  - æå– Lead II å’Œ V1 æ¨¡æ‹ŸåŒå¯¼è”ç³»ç»Ÿï¼Œç”¨äºè·¨æ•°æ®é›†é²æ£’æ€§éªŒè¯ã€‚

æ‰€æœ‰æ ·æœ¬æŒ‰ AAMI æ ‡å‡†åˆ†ä¸ºäº”ç±»ï¼šNormal (N), Supraventricular ectopic (S), Ventricular ectopic (V), Fusion (F), Unknown (Q)ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### æ•°æ®é¢„å¤„ç†æµç¨‹ï¼ˆPipelineï¼‰ï¼š
1. **Preprocessing**ï¼šButterworth å¸¦é€šæ»¤æ³¢ï¼ˆ0.5â€“40 Hzï¼‰
2. **R-Peak Detection**ï¼šé›†æˆ Pan-Tompkinsã€CWT å’Œè‡ªé€‚åº”é˜ˆå€¼æ³•ï¼Œç»“åˆ SQI åŠ æƒèåˆ
3. **Adaptive Segmentation**ï¼šåŸºäºå¤åˆæŸå¤±å‡½æ•°ï¼ˆç†µã€SNRã€èƒ½é‡æ¯”ï¼‰åŠ¨æ€è°ƒæ•´çª—å£é•¿åº¦
4. **Feature Extraction**ï¼š
   - æ—¶é—´åŸŸï¼ˆTDï¼‰ï¼šç»Ÿè®¡çŸ©ã€é›¶äº¤å‰ç‡ç­‰
   - é¢‘ç‡åŸŸï¼ˆFDï¼‰ï¼šè°±ç†µã€å¸¦åŠŸç‡
   - å½¢æ€å­¦ç‰¹å¾ï¼šQRS æŒç»­æ—¶é—´ã€T æ³¢å¹…åº¦ç­‰
   - å°æ³¢åŒ…èƒ½é‡ï¼ˆDaubechies åˆ†è§£ï¼‰
5. **Temporal & Graph Augmentation**ï¼š
   - HRV ç‰¹å¾ï¼ˆSDNN, pNN50, LF/HF ratioï¼‰
   - æ„é€ æœ‰å‘å›¾ï¼ŒèŠ‚ç‚¹ä¸ºå¿ƒè·³ï¼Œè¾¹æƒé‡ $ w_{ij} = \cos(f_i,f_j) \cdot e^{-|i-j|/T} $
   - æå– PageRank ä¸­å¿ƒæ€§ã€åŠ æƒèšç±»ç³»æ•°
6. **Feature Selection & Enhancement**ï¼š
   - MI + RFE ç­›é€‰å‰ 50 ä¸ªå…³é”®ç‰¹å¾
   - å¯¹è¿™ 50 ç»´åš PCAï¼ˆå–å‰ 5 ä¸ªä¸»æˆåˆ†ï¼‰ï¼Œå†æ‹¼æ¥å›åŸç‰¹å¾å‘é‡
7. **Class Balancing**ï¼šSMOTE-ENN å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
8. **Classifier Training**ï¼šä½¿ç”¨ LRã€Decision Treeã€Linear SVC

#### è¯„ä¼°æŒ‡æ ‡ï¼š
- Accuracy, Precision, Recall, Weighted F1-score
- **Efficiency Score (E)**ï¼šè‡ªå®šä¹‰ç»¼åˆæŒ‡æ ‡  
  $$
  E = \frac{0.6 \cdot F1 + 0.4 \cdot Acc}{0.4 \cdot T_{train} + 0.4 \cdot T_{infer} + 0.2 \cdot S_{model} + \epsilon}
  $$
- æ¨ç†å»¶è¿Ÿï¼ˆinference latencyï¼‰ã€æ¨¡å‹å¤§å°ï¼ˆmodel sizeï¼‰ã€ç«¯åˆ°ç«¯å¤„ç†æ—¶é—´

#### åŸºçº¿å¯¹æ¯”æ–¹æ³•ï¼š
- KD-Lightï¼ˆçŸ¥è¯†è’¸é¦å‹ç¼©æ¨¡å‹ï¼Œ25 KBï¼Œ96.32% å‡†ç¡®ç‡ï¼‰
- FPGA-based 1D-CNNï¼ˆç¡¬ä»¶åŠ é€Ÿ CNNï¼‰
- CANetï¼ˆæ³¨æ„åŠ› CNNï¼Œ30 MBï¼‰
- Smartwatch CNNï¼ˆ5 MBï¼Œ99.57%ï¼‰
- CCALï¼ˆç›¸å…³æ€§è¾…åŠ©å‹ç¼©ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆMIT-BIH æ•°æ®é›†ï¼‰

| æ¨¡å‹ | Accuracy (%) | F1 (Weighted) | Model Size (KB) | Inference Latency |
|------|---------------|----------------|------------------|--------------------|
| **Proposed Linear SVC** | **98.44** | **0.9843** | **8.54** | **0.46 Î¼s** |
| Logistic Regression | 98.25 | 0.9824 | 8.87 | 0.55 Î¼s |
| Decision Tree | 86.77 | 0.8562 | 4.71 | 0.59 Î¼s |

> ğŸ’¡ åœ¨ MIT-BIH ä¸Šè¾¾åˆ° **98.44% å‡†ç¡®ç‡**ï¼Œæ¥è¿‘å¤šæ•°æ·±åº¦å­¦ä¹ æ¨¡å‹æ°´å¹³ã€‚

---

### â±ï¸ å®æ—¶æ€§ä¸èµ„æºæ¶ˆè€—è¡¨ç°
| æŒ‡æ ‡ | è¡¨ç° |
|------|------|
| **å•æ¬¡å¿ƒè·³å¤„ç†å»¶è¿Ÿ** | ~52 msï¼ˆä¸»è¦æ¥è‡ªç‰¹å¾æå–é˜¶æ®µï¼‰ |
| **åˆ†ç±»æ¨ç†å»¶è¿Ÿ** | < 1 Î¼sï¼ˆLinear SVC: 0.46 Î¼sï¼‰ |
| **å…¨ç®¡é“å¤„ç†æ—¶é—´ï¼ˆæ¯æ‚£è€…ï¼‰** | MIT-BIH: 1.53 ç§’ï¼›INCART: 45.05 ç§’ |
| **æ˜¯å¦æ»¡è¶³å®æ—¶ç›‘æ§ï¼Ÿ** | æ˜¯ï¼ˆ52 ms << å¹³å‡ R-R é—´éš” ~800 msï¼‰ |

> âœ… å¯å®ç°**æ— ç¼“å†²ã€å³æ—¶æŠ¥è­¦**ï¼Œé€‚ç”¨äºå¯ç©¿æˆ´è®¾å¤‡è¿ç»­ç›‘æµ‹ã€‚

---

### ğŸ“Š è·¨æ•°æ®é›†é²æ£’æ€§ï¼ˆINCART æ•°æ®é›†ï¼‰
| æ¨¡å‹ | Accuracy (%) | F1 (Weighted) |
|------|---------------|----------------|
| Logistic Regression | 96.76 | 0.9674 |
| Linear SVC | 96.74 | 0.9672 |
| Decision Tree | 89.10 | 0.8913 |

> âœ”ï¸ åœ¨æ›´å¤§è§„æ¨¡ã€æ›´å¤æ‚ç—…ç†èƒŒæ™¯ä¸‹ä»ä¿æŒè‰¯å¥½æ€§èƒ½ï¼Œè¯æ˜æ³›åŒ–èƒ½åŠ›å¼ºã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒä¸å…³é”®å‘ç°
#### ï¼ˆ1ï¼‰ç‰¹å¾å·¥ç¨‹æœ‰æ•ˆæ€§éªŒè¯
- **Scree Plot æ˜¾ç¤º PCA å‰ 5 æˆåˆ†è§£é‡Šè¶…è¿‡ 64% æ–¹å·®**ï¼ˆMIT-BIH: 71.1%ï¼ŒINCART: 64.3%ï¼‰ï¼Œè¯´æ˜é™ç»´æœ‰æ•ˆã€‚
- **Boxplot åˆ†ææ˜¾ç¤º QRS durationã€spectral entropyã€weighted degree ç­‰ç‰¹å¾å…·æœ‰æ˜¾è‘—ç±»é—´åŒºåˆ†åº¦**ï¼Œå°¤å…¶ Ventricular beats çš„ QRS æ›´å®½ï¼ŒGraph-based features èƒ½æœ‰æ•ˆåˆ†ç¦»å¼‚å¸¸èŠ‚å¾‹ã€‚

#### ï¼ˆ2ï¼‰åˆ†ç±»å™¨å¯¹æ¯”æ­ç¤ºâ€œç‰¹å¾ç©ºé—´å†³å®šæ€§èƒ½â€
- å°½ç®¡ä½¿ç”¨ç›¸åŒç‰¹å¾é›†ï¼Œ**Decision Tree æ€§èƒ½è¿œä½äºçº¿æ€§æ¨¡å‹**ï¼ˆF1 å·®çº¦ 12%ï¼‰ï¼Œå°¤å…¶å¯¹ Ventricular beats çš„å¬å›ç‡ä»… ~50%ã€‚
- è€Œ Linear SVC å¯¹æ‰€æœ‰ç±»åˆ«æ•æ„Ÿåº¦å‡ >93%ï¼Œè¡¨æ˜æ‰€æ„å»ºçš„ç‰¹å¾ç©ºé—´æœ¬è´¨ä¸Šæ˜¯**çº¿æ€§å¯åˆ†çš„**ã€‚

#### ï¼ˆ3ï¼‰ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒï¼ˆ5-fold CVï¼‰
- MIT-BIH ä¸Š Linear SVC çš„ F1 å‡å€¼ä¸º 0.9634ï¼ˆCI: [0.952, 0.975]ï¼‰ï¼Œæ˜¾è‘—ä¼˜äº DTï¼ˆCI: [0.830, 0.915]ï¼‰ï¼Œæ— é‡å åŒºé—´ï¼ˆp < 0.05ï¼‰ã€‚
- INCART ä¸Š LR çš„ CI æçª„ï¼ˆ[0.966, 0.969]ï¼‰ï¼Œè¯´æ˜å¤§æ ·æœ¬ä¸‹ç¨³å®šæ€§æé«˜ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **æ··åˆç‰¹å¾å·¥ç¨‹å¯ä»¥å°†é«˜ç»´éçº¿æ€§ ECG æ•°æ®è½¬åŒ–ä¸ºçº¿æ€§å¯åˆ†å½¢å¼**ï¼Œä½¿å¾—ç®€å•çº¿æ€§æ¨¡å‹å³å¯è¾¾åˆ°æ·±åº¦å­¦ä¹ çº§åˆ«çš„è¯Šæ–­ç²¾åº¦ã€‚
2. **çº¿æ€§æ¨¡å‹ï¼ˆå¦‚ Linear SVCï¼‰åœ¨è¯¥ç‰¹å¾ç©ºé—´ä¸‹è¡¨ç°æœ€ä¼˜**ï¼Œè€Œéçº¿æ€§æ ‘æ¨¡å‹åè€Œå› ä¾èµ–è½´å¯¹é½åˆ†å‰²è€Œå¤±æ•ˆï¼Œåå‘éªŒè¯äº†ç‰¹å¾ç©ºé—´çš„è‰¯å¥½å‡ ä½•æ€§è´¨ã€‚
3. æ‰€ææ¡†æ¶å®ç°äº†**å¾®ç§’çº§æ¨ç†å»¶è¿Ÿ**ï¼ˆ0.46 Î¼sï¼‰å’Œ**äºš 10 KB æ¨¡å‹ä½“ç§¯**ï¼Œç›¸æ¯” KD-Lightï¼ˆ25 KBï¼‰ç­‰å‹ç¼©æ¨¡å‹ä»æœ‰æ•°é‡çº§ä¼˜åŠ¿ã€‚
4. ç³»ç»Ÿå…·å¤‡è‰¯å¥½çš„**è·¨æ•°æ®é›†é²æ£’æ€§**ï¼Œèƒ½åœ¨ä¸åŒé‡‡é›†æ¡ä»¶ã€å¯¼è”é…ç½®ä¸‹ç¨³å®šè¿è¡Œã€‚
5. **å¯è§£é‡Šæ€§å¼º**ï¼šçº¿æ€§æ¨¡å‹æƒé‡æ˜¾ç¤ºå…¶ä¼˜å…ˆå…³æ³¨ç”Ÿç†ç›¸å…³çš„é¢‘æ®µï¼ˆå¦‚ 5â€“15 Hz QRS èƒ½é‡ï¼‰å’Œ HRV æŒ‡æ ‡ï¼ˆLF/HF ratioï¼‰ï¼Œç¬¦åˆåŒ»å­¦å…ˆéªŒçŸ¥è¯†ã€‚

---

### âš ï¸ å±€é™æ€§
1. **2-lead é…ç½®å¯èƒ½ä¸¢å¤±éƒ¨åˆ† P æ³¢ç»†èŠ‚**ï¼Œå¯¼è‡´ Normal ä¸ Supraventricular beats ä¹‹é—´æ··æ·†å¢åŠ ï¼ˆåœ¨ INCART ä¸­è§‚å¯Ÿåˆ°ï¼‰ã€‚
2. **ç‰¹å¾æå–é˜¶æ®µå æ€»è€—æ—¶ 90%ä»¥ä¸Š**ï¼ˆå°¤å…¶æ˜¯å°æ³¢å’Œå›¾æ„é€ ï¼‰ï¼Œç›®å‰å°šä¸é€‚ç”¨äºå®Œå…¨æ— æºçš„èƒ½é‡é‡‡é›†è®¾å¤‡ï¼ˆbattery-less sensorsï¼‰ã€‚
3. å½“å‰ pipeline ä¸ºç¦»çº¿/å‡†å®æ—¶è®¾è®¡ï¼Œå°šæœªåœ¨çœŸå®åµŒå…¥å¼å¹³å°ï¼ˆå¦‚ Cortex-M ç³»åˆ— MCUï¼‰ä¸Šéƒ¨ç½²éªŒè¯ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **ç¡¬ä»¶åŠ é€Ÿç‰¹å¾æå–æ¨¡å—**ï¼šåˆ©ç”¨ FPGA æˆ–ä¸“ç”¨ ASIC åŠ é€Ÿ wavelet å’Œ graph constructionï¼Œé™ä½å‰ç«¯åŠŸè€—ã€‚
2. **è‡ªé€‚åº”å‚æ•°è°ƒèŠ‚æœºåˆ¶**ï¼šæ ¹æ®å¿ƒç‡å˜å¼‚æ€§åŠ¨æ€è°ƒæ•´ segmentation çª—å£ï¼ˆÎ±, Î²ï¼‰ï¼Œæå‡æç«¯å¿ƒå¾‹ä¸‹çš„é²æ£’æ€§ã€‚
3. **ç«¯åˆ°ç«¯ TinyML éƒ¨ç½²**ï¼šå°†æ•´ä¸ª pipeline ç¼–è¯‘ä¸º TensorFlow Lite Micro æˆ– Edge Impulse æ ¼å¼ï¼Œåœ¨çœŸå®å¯ç©¿æˆ´è®¾å¤‡ä¸Šè¿è¡Œã€‚
4. **æ‰©å±•è‡³æ›´å¤šç–¾ç—…ç±»å‹**ï¼šå¦‚æˆ¿é¢¤ã€å¿ƒè‚Œç¼ºè¡€ç­‰ï¼Œæ¢ç´¢è¯¥æ¡†æ¶çš„é€šç”¨æ€§ã€‚

---

## æ€»ç»“
æœ¬æ–‡æå‡ºäº†ä¸€ç§é¢ è¦†æ€§çš„â€œ**ä»¥ç‰¹å¾ä¸ºä¸­å¿ƒ**â€çš„è®¾è®¡èŒƒå¼ï¼ŒæˆåŠŸå®ç°äº†ï¼š
> **ç”¨ä¸åˆ° 9 KB çš„çº¿æ€§æ¨¡å‹ï¼Œåœ¨æ ‡å‡† ECG æ•°æ®åº“ä¸Šå–å¾— 98.44% å‡†ç¡®ç‡ï¼Œå¹¶å®ç° 0.46 å¾®ç§’æ¨ç†å»¶è¿Ÿã€‚**

è¿™ä¸€æˆæœä¸ºä¸‹ä¸€ä»£**ä½åŠŸè€—ã€å¯è§£é‡Šã€å®æ—¶åŒ–**çš„å¯ç©¿æˆ´å¿ƒè„ç›‘æŠ¤è®¾å¤‡æä¾›äº†åˆ‡å®å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ï¼Œæ¨åŠ¨äº† edge AI åœ¨æ•°å­—å¥åº·é¢†åŸŸçš„çœŸæ­£è½åœ°ã€‚

</details>

---

### 3. [FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems](https://arxiv.org/abs/2601.00227)

**Authors**: Shanli Xing, Yiyan Zhai, Alexander Jiang, Yixin Dong, Yong Wu, Zihao Ye, Charlie Ruan, Yingyi Huang, Yineng Zhang, Liangsheng Yin, Aksara Bayyapu, Luis Ceze, Tianqi Chen  
**Category**: cs.AI  
**Published**: 2026-01-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.00227v1  

#### Abstract
Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging. FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop fra...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ï¼Œå°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²å±•ç°å‡ºç”Ÿæˆå¤æ‚ GPU å†…æ ¸ä»£ç çš„èƒ½åŠ›ï¼Œä½†å°†è¿™äº› AI ç”Ÿæˆçš„å†…æ ¸æ— ç¼é›†æˆåˆ°å®é™…çš„ LLM æ¨ç†ç³»ç»Ÿä¸­ä»é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
1. **ä»»åŠ¡æè¿°ä¸ç»Ÿä¸€**ï¼šç¼ºä¹æ ‡å‡†åŒ–çš„ä»»åŠ¡å®šä¹‰æ–¹å¼ï¼Œå¯¼è‡´ AI ä»£ç†éš¾ä»¥å‡†ç¡®ç†è§£å†…æ ¸éœ€æ±‚ï¼ˆå¦‚æ•°æ®ç²¾åº¦ã€å½¢çŠ¶çº¦æŸç­‰ï¼‰ã€‚
2. **è¯„ä¼°ç¯å¢ƒè„±ç¦»çœŸå®åœºæ™¯**ï¼šå¤šæ•°åŸºå‡†æµ‹è¯•åŸºäºåˆæˆæˆ–å‡åŒ€è´Ÿè½½ï¼Œæ— æ³•åæ˜ çœŸå® LLM æœåŠ¡ä¸­çš„åŠ¨æ€ã€ç¨€ç–å’Œå˜é•¿è¯·æ±‚æ¨¡å¼ã€‚
3. **éƒ¨ç½²é›†æˆå›°éš¾**ï¼šå³ä½¿ç”Ÿæˆäº†é«˜æ€§èƒ½å†…æ ¸ï¼Œä»éœ€å¤§é‡æ‰‹åŠ¨å·¥ç¨‹æ‰èƒ½å°†å…¶æ³¨å…¥ç”Ÿäº§ç³»ç»Ÿï¼Œé˜»ç¢äº†è‡ªåŠ¨åŒ–é—­ç¯ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œè®ºæ–‡æå‡ºäº† **FlashInfer-Bench**ï¼Œä¸€ä¸ªé¢å‘ AI é©±åŠ¨çš„ LLM ç³»ç»Ÿçš„ç«¯åˆ°ç«¯é—­ç¯æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰FlashInfer Traceï¼šæ ‡å‡†åŒ–çš„å†…æ ¸ä»»åŠ¡æè¿° Schema
- å¼•å…¥ä¸€ç§è‡ªåŒ…å«çš„ JSON æ ¼å¼ `FlashInfer Trace`ï¼Œç»Ÿä¸€æè¿°å››ä¸ªå…³é”®ç»„ä»¶ï¼š
  - **Definition**ï¼šæ“ä½œç¬¦æ¥å£è§„èŒƒï¼ˆè¾“å…¥/è¾“å‡ºå¼ é‡ã€æ•°æ®ç±»å‹ã€å¯å˜/å›ºå®šç»´åº¦ï¼‰
  - **Workload**ï¼šç»‘å®šå…·ä½“å‚æ•°çš„çœŸå®ä¸–ç•Œè¾“å…¥å®ä¾‹
  - **Solution**ï¼šå®ç°ä»£ç åŠå…ƒä¿¡æ¯ï¼ˆè¯­è¨€ã€ç›®æ ‡ç¡¬ä»¶ï¼‰
  - **Evaluation**ï¼šä¸å¯å˜çš„æ€§èƒ½ä¸æ­£ç¡®æ€§è¯„æµ‹è®°å½•
- æ”¯æŒ ragged inputsï¼ˆå¦‚ paged attention ä¸­çš„ page tableï¼‰ï¼Œå¹¶å…è®¸å¯¹ç‰¹å®šæ¨¡å‹å±‚è¿›è¡Œç²¾ç»†ä¼˜åŒ–ã€‚

#### ï¼ˆ2ï¼‰FlashInfer-Bench Datasetï¼šåŸºäºçœŸå®æµé‡æ„å»ºçš„æ•°æ®é›†
- ä» SGLang ä¸Šè¿è¡Œ DeepSeek-V3ã€Llama-3.1-8Bã€Qwen3-30B-A3B ç­‰ä¸»æµæ¨¡å‹æ”¶é›†çœŸå®æœåŠ¡ traceã€‚
- è¦†ç›– GEMMã€Attentionï¼ˆGQA/Pagedï¼‰ã€MoEã€Normalizationã€Sampling ç­‰å…¸å‹ LLM è¿ç®—ã€‚
- æ¯ä¸ªå†…æ ¸å®šä¹‰ä¿ç•™çº¦ 50 ä¸ªå…·æœ‰ä»£è¡¨æ€§å’Œå¤šæ ·æ€§çš„ workloadï¼Œç¡®ä¿è¯„ä¼°çš„çœŸå®æ€§ã€‚

#### ï¼ˆ3ï¼‰é²æ£’çš„ Benchmarking æ¡†æ¶
- æ”¯æŒ Deterministicã€Low-Precision å’Œ Stochasticï¼ˆå¦‚ samplingï¼‰å†…æ ¸çš„éªŒè¯ã€‚
- é‡‡ç”¨ TVDï¼ˆTotal Variation Distanceï¼‰è¡¡é‡é‡‡æ ·åˆ†å¸ƒçš„å‡†ç¡®æ€§ã€‚
- æä¾›éš”ç¦»æ¨¡å¼ï¼ˆisolated subprocessï¼‰é˜²æ­¢ reward hackingï¼Œå¹¶æ”¯æŒæŒä¹…åŒ– worker ä»¥æå‡æ•ˆç‡ã€‚

#### ï¼ˆ4ï¼‰åŠ¨æ€æ›¿æ¢æœºåˆ¶ `flashinfer_bench.apply()`
- å…è®¸åœ¨è¿è¡Œæ—¶æ— ä¾µå…¥åœ°å°†æœ€ä¼˜éªŒè¯å†…æ ¸æ³¨å…¥ç”Ÿäº§å¼•æ“ï¼ˆå¦‚ SGLangã€vLLMï¼‰ã€‚
- æ”¯æŒ ahead-of-time ç¼–è¯‘ç´¢å¼•é¢„çƒ­ï¼Œçº¿ä¸Šè°ƒåº¦å¼€é”€æä½ï¼ˆä»… ~1â€“2 Î¼sï¼‰ã€‚
- å®ç°â€œç”Ÿæˆ â†’ è¯„æµ‹ â†’ éƒ¨ç½²â€å…¨è‡ªåŠ¨ virtuous cycleã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ KernelBench, TritonBenchï¼‰ | FlashInfer-Bench |
|------|----------------------------------------|------------------|
| **ä»»åŠ¡æ ‡å‡†åŒ–** | ç¼ºä¹ç»Ÿä¸€ schema | å®šä¹‰å®Œæ•´ Trace schemaï¼Œæ”¯æŒè¯­ä¹‰ä¸€è‡´æ€§ |
| **å·¥ä½œè´Ÿè½½çœŸå®æ€§** | åˆæˆæˆ–éšæœºè¾“å…¥ | æ¥è‡ªçœŸå® LLM æœåŠ¡ trace |
| **è¯„ä¼°å…¨é¢æ€§** | å¿½è§†éç¡®å®šæ€§ã€ä½ç²¾åº¦è¿ç®— | æ”¯æŒ samplingã€FP8 ç­‰å¤æ‚åœºæ™¯ |
| **éƒ¨ç½²è·¯å¾„** | æ‰‹åŠ¨é›†æˆï¼Œæ— è‡ªåŠ¨åŒ–æµç¨‹ | æä¾› `apply()` å®ç°é›¶ä»£ç å˜æ›´éƒ¨ç½² |
| **ç³»ç»Ÿçº§åé¦ˆ** | ä»…å…³æ³¨å•ä¸ª kernel æ€§èƒ½ | å¯è§‚æµ‹ end-to-end è¯·æ±‚å»¶è¿Ÿå˜åŒ– |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **FlashInfer-Bench Dataset**ï¼š
  - åŒ…å« 41 ç§ä¸åŒçš„ kernel configurationsã€‚
  - æ¶µç›– 8 ç±»å…¸å‹ LLM å†…æ ¸ï¼šGEMMã€Ragged/Paged GQAã€Ragged/Paged MLAã€Fused MoEã€RMS Normã€Samplingã€‚
  - æ€»å…± 1,600 ä¸ªç»è¿‡å»é‡å’Œå¤šæ ·æ€§ç­›é€‰çš„ workloadã€‚
  - æ•°æ®æ¥æºäº SGLang åœ¨ ShareGPT prompts ä¸‹çš„æœåŠ¡ traceã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA B200 GPUã€‚
- **è¯„ä¼°å¯¹è±¡**ï¼šç”±å¤šä¸ªå‰æ²¿ LLMï¼ˆGemini 2.5 Proã€Claude Opus 4.1ã€GPT-5ã€OpenAI o3ï¼‰ç”Ÿæˆçš„ CUDA å’Œ Triton å†…æ ¸ã€‚
- **Agent æ¡†æ¶**ï¼šé‡‡ç”¨å¸¦åé¦ˆå¾ªç¯çš„ agentï¼ˆè§ Algorithm 1ï¼‰ï¼Œè¿­ä»£ç”Ÿæˆã€è¯„æµ‹ã€ä¼˜åŒ–å†…æ ¸ç›´è‡³æ”¶æ•›ã€‚
- **Baseline**ï¼š
  - ä¸»è¦å¯¹æ¯”åŸºçº¿ä¸º FlashInferï¼ˆå½“å‰æœ€å…ˆè¿›çš„ attention å¼•æ“ï¼‰ã€‚
  - è‹¥æ— å¯¹åº”å®ç°ï¼Œåˆ™ä½¿ç”¨ PyTorch ä½œä¸º baselineã€‚

### è¯„ä¼°æŒ‡æ ‡
- **fastâ‚š metric**ï¼šè¡¨ç¤ºåœ¨è¶…è¿‡ p å€åŠ é€Ÿé˜ˆå€¼ä¸‹é€šè¿‡æ­£ç¡®æ€§æ£€æŸ¥çš„å·¥ä½œè´Ÿè½½æ¯”ä¾‹ã€‚
  $$
  \text{fast}_p = \frac{1}{N} \sum_{i=1}^{N} [\text{correct}_i \land \text{speedup}_i > p]
  $$
- **AUC of fastâ‚š curve**ï¼šç»¼åˆåæ˜ å†…æ ¸çš„æ­£ç¡®ç‡ä¸æ€§èƒ½æ½œåŠ›ã€‚
- **End-to-end latency**ï¼šæµ‹é‡å®Œæ•´è¯·æ±‚å¤„ç†æ—¶é—´çš„å˜åŒ–ï¼ŒéªŒè¯ kernel çº§æ”¹è¿›èƒ½å¦è½¬åŒ–ä¸ºç³»ç»Ÿæ”¶ç›Šã€‚
- **Correctness Pass Rate**ï¼šå½“ p=0 æ—¶ï¼Œfastâ‚€ å³ä¸ºæ­£ç¡®ç‡ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰LLM Agent æ•´ä½“è¡¨ç°ï¼ˆå›¾ 4 & å›¾ 7ï¼‰
| æ¨¡å‹ | fastâ‚€.â‚‰â‚… æ’å | æ­£ç¡®ç‡ï¼ˆp=1.0ï¼‰ |
|------|---------------|----------------|
| gemini-2.5-pro | ç¬¬1å | 48.8% |
| gpt-o3 | ç¬¬2å | 71.3% |
| gpt-5-2025-08-07 | ç¬¬3å | **83.9%** |

> æ³¨ï¼šè™½ç„¶ gpt-5 æ­£ç¡®ç‡æœ€é«˜ï¼Œä½†åœ¨é«˜åŠ é€ŸåŒºæ®µï¼ˆfastâ‚€.â‚‰â‚…ï¼‰è¡¨ç°ä¸å¦‚ gemini-2.5-proã€‚

#### ï¼ˆ2ï¼‰ä¸åŒå†…æ ¸ç±»å‹çš„è¡¨ç°ï¼ˆå›¾ 6ï¼‰
- **GEMM (Triton)**ï¼šLLM ç”Ÿæˆå†…æ ¸å¹³å‡æ€§èƒ½ä»…ä¸ºäººç±»ä¸“å®¶æ°´å¹³çš„ <50%ã€‚
- **GQA Paged Decode (CUDA)**ï¼šåŒæ ·è¿œä½äº SOTAã€‚
- **RMSNorm (CUDA)**ï¼šæ¥è¿‘ç”šè‡³è¶…è¿‡äººç±»æ°´å¹³ï¼Œå› å…¶ä¸º memory-boundï¼Œæ˜“äºè¾¾åˆ°å¸¦å®½ä¸Šé™ã€‚

#### ï¼ˆ3ï¼‰è¯­è¨€é€‰æ‹©çš„å½±å“ï¼ˆå›¾ 7ï¼‰
- **Triton vs CUDA**ï¼š
  - Triton å†…æ ¸çš„ **æ­£ç¡®ç‡æ˜¾è‘—æ›´é«˜**ï¼ˆå› æŠ½è±¡å±‚æ¬¡é«˜ï¼Œå‡å°‘ç»†èŠ‚é”™è¯¯ï¼‰ã€‚
  - CUDA å†…æ ¸è™½éš¾å†™ï¼Œä½†ä¸€æ—¦æˆåŠŸï¼Œ**å³°å€¼æ€§èƒ½æ›´é«˜**ï¼ˆæ›´ç»†ç²’åº¦æ§åˆ¶å…±äº«å†…å­˜ã€tiling ç­‰ï¼‰ã€‚
- ç»“è®ºï¼šTriton æ›´é€‚åˆå¿«é€Ÿæ¢ç´¢ï¼›CUDA æœ‰æ›´å¤§ä¼˜åŒ–ç©ºé—´ã€‚

#### ï¼ˆ4ï¼‰case studyï¼šGEMM å†…æ ¸å¯¹æ¯”
| å†…æ ¸æ¥æº | è¯­è¨€ | å¹³å‡æ‰§è¡Œæ—¶é—´ï¼ˆbatch=64ï¼‰ | ç›¸å¯¹äº baseline åŠ é€Ÿæ¯” |
|--------|------|--------------------------|-------------------------|
| FlashInfer (baseline) | CUDA | 0.0112 ms | 1.0Ã— |
| Gemini-2.5-Pro | Triton | 0.0160 ms | 0.7Ã— |
| GPT-5 | Triton | 0.0247 ms | 0.45Ã— |

> å°½ç®¡æŸäº› Triton å†…æ ¸è¾ƒæ…¢ï¼Œä½†è¡¨æ˜ DSL ç¼–è¯‘å™¨å¯è‡ªåŠ¨å¯ç”¨é«˜çº§æŒ‡ä»¤ï¼ˆå¦‚ tcgen05ï¼‰ï¼Œè€Œ LLM åœ¨ CUDA ä¸­éš¾ä»¥åˆ©ç”¨æ–°ç¡¬ä»¶ç‰¹æ€§ã€‚

#### ï¼ˆ5ï¼‰æ¶ˆèå®éªŒï¼š`apply()` å¼€é”€ä¸æ”¶ç›Š
- **å¼€é”€æµ‹è¯•**ï¼š
  - ä½¿ç”¨ fallback substitutionï¼ˆå³ç”¨ç›¸åŒå†…æ ¸æ›¿æ¢ï¼‰æµ‹å¾— `apply()` å¼•å…¥çš„é¢å¤–å»¶è¿Ÿ < 0.8%ã€‚
  - çº¿ä¸Šè°ƒåº¦å¼€é”€ä»… 1â€“2 Î¼sã€‚
- **æ”¶ç›Šæµ‹è¯•**ï¼ˆå›¾ 8ï¼‰ï¼š
  - æ›¿æ¢ä¸ºæ›´å¿«å†…æ ¸åï¼Œend-to-end è¯·æ±‚å»¶è¿Ÿä» 1055msï¼ˆGPT-5 Tritonï¼‰é™è‡³ 934msï¼ˆFlashInfer fallbackï¼‰ï¼Œä¸‹é™çº¦ 11.4%ã€‚
  - éªŒè¯äº† kernel-level ä¼˜åŒ–èƒ½æœ‰æ•ˆä¼ é€’è‡³ç³»ç»Ÿçº§æ€§èƒ½æå‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç¼–è¯‘å¤±è´¥æ˜¯ä¸»è¦é”™è¯¯æ¥æº**ï¼š
   - åœ¨æ‰€æœ‰ 32 ä¸ªå¤±è´¥æ¡ˆä¾‹ä¸­ï¼Œ30 ä¸ªæºäºç¼–è¯‘é”™è¯¯ï¼Œä»… 2 ä¸ªä¸ºè¿è¡Œæ—¶æˆ–æ•°å€¼é”™è¯¯ã€‚
   - å¸¸è§é”™è¯¯åŒ…æ‹¬ï¼šAPI ä½¿ç”¨ä¸å½“ï¼ˆå°¤å…¶ Tritonï¼‰ã€host/device æ··æ·†ã€datatype/shape ä¸åŒ¹é…ã€‚

2. **LLM éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨ç¡¬ä»¶ intrinsic**ï¼š
   - å°½ç®¡æä¾›äº† Blackwell æ¶æ„æ–‡æ¡£ï¼ŒLLM ä»æœªèƒ½æ­£ç¡®ä½¿ç”¨ `mma` æˆ– `tcgen05` æŒ‡ä»¤ã€‚
   - è¡¨æ˜å½“å‰ LLM å¯¹åº•å±‚ç¡¬ä»¶ç‰¹æ€§çš„ç†è§£æœ‰é™ï¼Œä¾èµ–è®­ç»ƒæ•°æ®ä¸­çš„å¸¸è§æ¨¡å¼ã€‚

3. **è¯­è¨€é€‰æ‹©å­˜åœ¨ trade-off**ï¼š
   - **Triton**ï¼šæŠ½è±¡ç¨‹åº¦é«˜ï¼ŒLLM æ›´æ˜“å†™å‡ºæ­£ç¡®ä»£ç ï¼Œä¸”ç¼–è¯‘å™¨å¯è‡ªåŠ¨ä¼˜åŒ–ã€‚
   - **CUDA**ï¼šè¡¨è¾¾èƒ½åŠ›å¼ºï¼Œæ½œåœ¨æ€§èƒ½ä¸Šé™æ›´é«˜ï¼Œä½†å®ç°å¤æ‚ï¼ŒLLM å®¹æ˜“å‡ºé”™ã€‚
   - æ¨èç­–ç•¥ï¼šè®­ç»ƒé˜¶æ®µé™åˆ¶åº“è°ƒç”¨ä»¥ä¿ƒè¿›å­¦ä¹ ï¼›æ¨ç†é˜¶æ®µå¼€æ”¾åº“è®¿é—®ä»¥æœ€å¤§åŒ–æ€§èƒ½ã€‚

4. **LLM å­¦ä¼šè°ƒç”¨åº“è€ŒéçœŸæ­£ç¼–ç¨‹**ï¼š
   - å¦‚ GEMM ä»»åŠ¡ä¸­ï¼ŒGemini å’Œ o3 å­¦ä¼šè°ƒç”¨ cuBLAS å®ç°é«˜æ€§èƒ½ã€‚
   - è™½ç„¶å®ç”¨ï¼Œä½†ä¹Ÿæš´éœ²äº† LLM â€œèµ°æ·å¾„â€çš„å€¾å‘ï¼Œå¯èƒ½æŠ‘åˆ¶æ·±åº¦æŠ€èƒ½ä¹ å¾—ã€‚

5. **åŠ¨æ€æ›¿æ¢æœºåˆ¶é«˜æ•ˆå¯é **ï¼š
   - `flashinfer_bench.apply()` å®ç°äº†è¿‘ä¹é›¶æˆæœ¬çš„å†…æ ¸çƒ­æ›¿æ¢ã€‚
   - kernel æ€§èƒ½å¢ç›Šå¯ç›´æ¥è½¬åŒ–ä¸º end-to-end å»¶è¿Ÿé™ä½ï¼ŒéªŒè¯äº†é—­ç¯ç³»ç»Ÿçš„æœ‰æ•ˆæ€§ã€‚

### å±€é™æ€§
- å½“å‰æœªè¦†ç›– multi-GPU æˆ–é€šä¿¡å¯†é›†å‹å†…æ ¸ï¼ˆå¦‚ AllReduceï¼‰ã€‚
- æ”¯æŒçš„è¯­è¨€å’Œç¡¬ä»¶ç§ç±»æœ‰é™ï¼ˆç›®å‰ä¸»è¦æ”¯æŒ CUDA/Triton + NVIDIAï¼‰ã€‚
- å¯¹ reward hacking çš„é˜²å¾¡ä»æœ‰æ”¹è¿›ç©ºé—´ï¼ˆå¦‚éšè— workload åˆ†å¸ƒï¼‰ã€‚
- å¤šæ•° LLM ä»æ— æ³•ç¨³å®šç”Ÿæˆé«˜åº¦ä¼˜åŒ–çš„ CUDA å†…æ ¸ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±• FlashInfer Trace åˆ°æ›´å¤šæ¨¡å‹ã€è®¾å¤‡å’Œç¼–ç¨‹è¯­è¨€ï¼ˆå¦‚ CUTLASSã€CuTeï¼‰ã€‚
- å¼•å…¥å¼ºåŒ–å­¦ä¹ æˆ–æ¨¡ä»¿å­¦ä¹ ï¼Œé¼“åŠ± LLM æ¢ç´¢ç¡¬ä»¶ç‰¹å®šä¼˜åŒ–ç­–ç•¥ã€‚
- æ„å»ºæ›´å¼ºå¤§çš„ kernel agentï¼Œç»“åˆæœç´¢ä¸ç”Ÿæˆæ–¹æ³•ã€‚
- å¢å¼ºéªŒè¯æœºåˆ¶ï¼Œé˜²èŒƒéšè”½çš„æ•°å€¼åå·®æˆ–å®‰å…¨æ¼æ´ã€‚
- æ¢ç´¢ multi-agent åä½œç”Ÿæˆå¤æ‚ fused kernelsã€‚

--- 

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> FlashInfer-Bench æ„å»ºäº†ä¸€ä¸ªä» AI ç”Ÿæˆ â†’ çœŸå®è¯„ä¼° â†’ åŠ¨æ€éƒ¨ç½²çš„å®Œæ•´ virtuous cycleï¼Œé¦–æ¬¡å®ç°äº† LLM è‡ªåŠ¨ç”Ÿæˆ GPU å†…æ ¸åœ¨ç”Ÿäº§çº§ LLM ç³»ç»Ÿä¸­çš„é—­ç¯è½åœ°ï¼Œæ¨åŠ¨äº† AI for Systems çš„å®ç”¨åŒ–è¿›ç¨‹ã€‚

</details>

---

### 4. [DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations](https://arxiv.org/abs/2601.00623)

**Authors**: Longtian Qiu, Shan Ning, Chuyu Zhang, Jiaxuan Sun, Xuming He  
**Category**: cs.AI  
**Published**: 2026-01-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.00623v1  

#### Abstract
Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **Multimodal Large Language Models (MLLMs)** åœ¨è§†è§‰-è¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†æ™®éå­˜åœ¨**å¹»è§‰ï¼ˆhallucinationï¼‰**é—®é¢˜ï¼Œå³ç”Ÿæˆçš„å†…å®¹ä¸å›¾åƒè¾“å…¥ä¸ä¸€è‡´ã€‚è™½ç„¶ **Direct Preference Optimization (DPO)** è¢«å¹¿æ³›ç”¨äºç¼“è§£å¹»è§‰ï¼Œä½†å…¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å®¹æ˜“å¯¹â€œç®€å•æ ·æœ¬â€è¿‡æ‹Ÿåˆï¼Œè€Œå¿½è§†â€œå›°éš¾æ ·æœ¬â€ï¼Œå¯¼è‡´æ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¸‹é™ã€‚

ä½œè€…é€šè¿‡å®è¯åˆ†æå‘ç°ï¼Œè¿™ç§**éš¾åº¦ä¸å¹³è¡¡ï¼ˆdifficulty imbalanceï¼‰**æ˜¯å¯¼è‡´ DPO æ€§èƒ½ç“¶é¢ˆçš„å…³é”®åŸå› ï¼šæ¨¡å‹å¿«é€Ÿé€‚åº”æ˜“äºåŒºåˆ†çš„åå¥½å¯¹ï¼Œå´æ— æ³•ä»ç»†å¾®å·®å¼‚çš„å›°éš¾æ ·æœ¬ä¸­æœ‰æ•ˆå­¦ä¹ ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šDA-DPO
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡º **Difficulty-Aware Direct Preference Optimization (DA-DPO)**ï¼Œä¸€ä¸ªæ— éœ€é¢å¤–è®­ç»ƒã€æˆæœ¬é«˜æ•ˆçš„æ¡†æ¶ï¼ŒåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

1. **Difficulty Estimationï¼ˆéš¾åº¦ä¼°è®¡ï¼‰**
   - åˆ©ç”¨é¢„è®­ç»ƒçš„ **contrastive VLMsï¼ˆå¦‚ CLIPï¼‰** å’Œ **generative VLMsï¼ˆå¦‚ LLaVAï¼‰** ä»ä¸åŒè§’åº¦è¯„ä¼°æ¯ä¸ªåå¥½å¯¹çš„éš¾åº¦ã€‚
   - CLIP è¡¡é‡å›¾åƒ-æ–‡æœ¬ç›¸å…³æ€§ï¼ˆimage relevanceï¼‰ï¼Œé€‚åˆåˆ¤æ–­ caption ç±»ä»»åŠ¡ï¼›
   - MLLM è¡¡é‡é€»è¾‘è¿è´¯æ€§ï¼ˆquestion relevanceï¼‰ï¼Œé€‚åˆ VQA ç±»ä»»åŠ¡ã€‚
   - é‡‡ç”¨ **distribution-aware voting strategy** è‡ªé€‚åº”èåˆä¸¤è€…è¾“å‡ºï¼Œç”Ÿæˆé²æ£’çš„éš¾åº¦åˆ†æ•°ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚

2. **Difficulty-aware Trainingï¼ˆéš¾åº¦æ„ŸçŸ¥è®­ç»ƒï¼‰**
   - æ ¹æ®ä¼°è®¡çš„éš¾åº¦åŠ¨æ€è°ƒæ•´æ¯ä¸ªæ ·æœ¬åœ¨ DPO ä¸­çš„ä¼˜åŒ–æƒé‡ã€‚
   - å¯¹**å›°éš¾æ ·æœ¬å¢å¼ºå­¦ä¹ ä¿¡å·**ï¼Œå¯¹**ç®€å•æ ·æœ¬é™æƒ**ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚
   - æœºåˆ¶ä¸Šé€šè¿‡è°ƒèŠ‚ DPO ç›®æ ‡ä¸­çš„ Î² å‚æ•°å®ç°ï¼Œæå‡æ¨¡å‹å¯¹ç»†ç²’åº¦å·®å¼‚çš„å­¦ä¹ èƒ½åŠ›ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | DA-DPO | ä¼ ç»Ÿ DPO / å…¶ä»–æ–¹æ³• |
|------|--------|------------------|
| æ˜¯å¦éœ€è¦é¢å¤–è®­ç»ƒ | âŒ å¦ï¼ˆåˆ©ç”¨å·²æœ‰ VLMsï¼‰ | âœ… æ˜¯ï¼ˆå¦‚è®­ç»ƒ Reward Modelï¼‰ |
| æ˜¯å¦å¼•å…¥æ–°æ•°æ® | âŒ å¦ | âœ… éƒ¨åˆ†æ–¹æ³•ä¾èµ–äººå·¥æ ‡æ³¨æˆ–å¼ºæ¨¡å‹æ‰“æ ‡ |
| è®¡ç®—æ•ˆç‡ | â­ æé«˜ï¼ˆè§ Table 10ï¼‰ | âš ï¸ é«˜ï¼ˆå°¤å…¶ RLHF/PPOï¼‰ |
| æŠ—è¿‡æ‹Ÿåˆèƒ½åŠ› | âœ… å¼ºï¼ˆæ˜¾å¼å¹³è¡¡éš¾æ˜“æ ·æœ¬ï¼‰ | âŒ å¼±ï¼ˆæ˜“åå‘ç®€å•æ ·æœ¬ï¼‰ |
| é€šç”¨æ€§ | âœ… å¯é€‚é…å¤šç§ MLLM æ¶æ„ | âœ… å¤šæ•°å…¼å®¹ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šåœ¨ä¸å¢åŠ è®­ç»ƒå¼€é”€çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡å¹»è§‰æŠ‘åˆ¶æ•ˆæœå’Œç»¼åˆæ€§èƒ½ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **ä¸»è®­ç»ƒæ•°æ®**ï¼š
  - **BPO dataset**ï¼šåŒ…å« 180K è‡ªåŠ¨ç”Ÿæˆçš„å¤šæ¨¡æ€åå¥½å¯¹ï¼Œè´Ÿæ ·æœ¬ç”± Image-Weakened Prompting å’Œ LLM Error Injection ç”Ÿæˆã€‚
- **è¾…åŠ©éªŒè¯æ•°æ®**ï¼š
  - **VLFeedback**ï¼šåŸºäºå¤šä¸ª VLM è¾“å‡ºå¹¶ç”± GPT-4V è¿‡æ»¤çš„è‡ªåŠ¨æ„å»ºæ•°æ®é›†ï¼ˆ80K â†’ é€‰ 10Kï¼‰ã€‚
  - **LLaVA-RLHF**ï¼šäººç±»æ ‡æ³¨çš„ 10K åå¥½æ•°æ®é›†ï¼Œç”¨äºæµ‹è¯•æ³›åŒ–æ€§ã€‚

---

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼š
  - LLaVA-v1.5-7B / 13B
  - LLaVA-OneVision-7B
  - Qwen2.5-VL-3Bï¼ˆç”¨äºæ‰©å±•å®éªŒï¼‰
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - æ‰€æœ‰æ¨¡å‹è®­ç»ƒ 1 epochã€‚
  - ä½¿ç”¨ LoRAï¼ˆrank=32, alpha=256ï¼‰è¿›è¡Œé«˜æ•ˆå¾®è°ƒã€‚
  - å­¦ä¹ ç‡ï¼š2e-6ï¼ˆLLaVA-v1.5ï¼‰ï¼Œ5e-7ï¼ˆLLaVA-OneVisionï¼‰ã€‚
  - Î² è®¾ç½®ä¸º 0.2ï¼ˆDA-DPO æœ€ä¼˜å€¼ï¼Œè§ Table 8ï¼‰ã€‚

---

### è¯„ä¼°æŒ‡æ ‡
#### å¹»è§‰è¯„ä¼°åŸºå‡†ï¼ˆHallucination Benchmarksï¼‰
| åŸºå‡† | æè¿° |
|------|------|
| **AMBER** | å¤šç»´åº¦è¯„ä¼°ç”Ÿæˆä¸åˆ¤åˆ«ä»»åŠ¡ï¼ŒåŒ…å« `Cs`ï¼ˆå¿ å®åº¦ï¼‰ã€`Hal.`ï¼ˆå¹»è§‰ç‡ï¼‰ã€`Cog.`ï¼ˆè¿è´¯æ€§ï¼‰ç­‰å­æŒ‡æ ‡ |
| **MMHalBench** | åŒ…å« 8 ç§é—®é¢˜ç±»å‹çš„ VQA å¹»è§‰æ£€æµ‹ï¼Œä½¿ç”¨ GPT-4 è¯„åˆ† |
| **Object HalBench** | æ£€æµ‹å¯¹è±¡æ˜¯å¦å­˜åœ¨æ€§å¹»è§‰ |
| **POPE** | åŸºäºæŠ•ç¥¨çš„å¹»è§‰è¯„æµ‹ï¼ŒæŠ¥å‘Šå¹³å‡ F1 åˆ†æ•° |

#### ç»¼åˆèƒ½åŠ›åŸºå‡†ï¼ˆComprehensive Benchmarksï¼‰
| åŸºå‡† | æè¿° |
|------|------|
| **LLaVA-Bench** | 60 ä¸ªçœŸå®ä¸–ç•Œè§†è§‰æŒ‡ä»¤ä»»åŠ¡ï¼ŒGPT-4 æ‰“åˆ† |
| **SeedBench** | 14K å¤šé€‰é¢˜ VQA æ•°æ®é›†ï¼Œè¯„ä¼°ç»¼åˆç†è§£èƒ½åŠ› |
| **MME** | æµ‹è¯•æ„ŸçŸ¥ä¸è®¤çŸ¥èƒ½åŠ›ï¼ˆyes/no é—®ç­”ï¼‰ |
| **GQA** | å¼€æ”¾å¼è§†è§‰æ¨ç†ä¸ç»„åˆé—®ç­” |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Standard DPO**ï¼šç›´æ¥åº”ç”¨åŸå§‹ DPO ç›®æ ‡å‡½æ•°ã€‚
- **HA-DPO**, **CLIP-DPO**, **mDPO**ï¼šå…¶ä»–æ”¹è¿›å‹ DPO æ–¹æ³•ã€‚
- **Reference Only**ï¼šä»…ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ¨¡å‹ï¼Œæ— åå¥½ä¼˜åŒ–ã€‚
- **Filtering Baselines**ï¼šç§»é™¤ 10%/25%/50% æ˜“æ ·æœ¬åè®­ç»ƒ DPOï¼Œä½œä¸ºç¡¬è¿‡æ»¤å¯¹ç…§ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ LLaVA-v1.5-7B ä¸ºä¾‹ï¼‰

| æ–¹æ³• | AMBER `Hal.` â†“ | POPE F1 â†‘ | LLaVA-Bench Score â†‘ | SeedBench Score â†‘ |
|------|----------------|-----------|---------------------|--------------------|
| DPO  | 35.7           | 84.3      | 70.5                | 45.3               |
| **DA-DPO** | **28.0**       | **85.9**  | **75.4**            | **64.8**           |

> âœ… **å¹»è§‰å‡å°‘**ï¼šAMBER å¹»è§‰ç‡ä» 35.7 â†’ **28.0**ï¼ˆé™å¹… >21%ï¼‰  
> âœ… **ç»¼åˆèƒ½åŠ›ä¿æŒç”šè‡³æå‡**ï¼šLLaVA-Bench æå‡è¿‘ 5 åˆ†ï¼ŒSeedBench æå‡è¶… 19 åˆ†

---

### ä¸å…¶ä»–æ–¹æ³•å¯¹æ¯”ï¼ˆTable 1ï¼‰
- DA-DPO åœ¨å‡ ä¹æ‰€æœ‰å¹»è§‰å’Œç»¼åˆæŒ‡æ ‡ä¸Šå‡ä¼˜äºæ ‡å‡† DPO å’Œå¤šæ•° baselinesã€‚
- å°¤å…¶åœ¨ **Object Hallucination** ä¸Šè¡¨ç°çªå‡ºï¼Œè¯´æ˜å…¶å¯¹ç»†ç²’åº¦äº‹å®é”™è¯¯æœ‰æ›´å¼ºæŠ‘åˆ¶åŠ›ã€‚
- ç›¸æ¯” **mDPO**ï¼ˆå…³æ³¨è¯­è¨€åå¥½åç½®ï¼‰ï¼ŒDA-DPO æ›´ä¸“æ³¨äºæ ·æœ¬éš¾åº¦å¹³è¡¡ï¼ŒäºŒè€…æ­£äº¤å¯ç»“åˆã€‚

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰éš¾åº¦ä¼°è®¡æ¥æºæ¶ˆèï¼ˆTable 2ï¼‰
| æ–¹æ³• | AMBER `Hal.` â†“ | SeedBench â†‘ |
|------|----------------|-------------|
| DPOï¼ˆbaselineï¼‰ | 35.7 | 57.8 |
| + CLIP only | 31.9 | 63.8 |
| + MLLM only | 29.9 | 64.3 |
| **+ CLIP + MLLMï¼ˆDA-DPOï¼‰** | **28.0** | **64.8** |

> âœ… **åŒè§†è§’èåˆæ›´ä¼˜**ï¼šè¯æ˜ contrastive ä¸ generative VLMs æä¾›äº’è¡¥ä¿¡æ¯ã€‚

#### ï¼ˆ2ï¼‰VLM æ¨¡å‹é€‰æ‹©æ¶ˆèï¼ˆTable 4ï¼‰
- ä½¿ç”¨ä¸åŒè§„æ¨¡çš„ CLIPï¼ˆViTL vs EVA-CLIP 8Bï¼‰æˆ– MLLMï¼ˆLLaVA vs OVï¼‰æ—¶ï¼Œæ€§èƒ½å˜åŒ–è¾ƒå°ã€‚
- å½’å› äº **Gaussian normalization** ä½¿ç³»ç»Ÿå¯¹ç»å¯¹å¾—åˆ†ä¸æ•æ„Ÿï¼Œåªä¿ç•™æ’åºå…³ç³»ï¼Œå¢å¼ºäº†é²æ£’æ€§ã€‚

#### ï¼ˆ3ï¼‰ç›´æ¥è¿‡æ»¤ vs åŠ¨æ€åŠ æƒï¼ˆTable 5ï¼‰
| æ–¹æ³• | ç§»é™¤æ¯”ä¾‹ | POPE F1 | ObjHal Csâ†“ |
|------|----------|---------|------------|
| DPO | 0% | 84.3 | 43.3 |
| Filter 10% | 10% | 84.9 | 39.0 |
| Filter 25% | 25% | 84.3 | 38.3 |
| Filter 50% | 50% | 85.5 | 42.7 |
| **DA-DPO** | â€” | **85.9** | **37.7** |

> âœ… **è½¯åŠ æƒä¼˜äºç¡¬è¿‡æ»¤**ï¼šDA-DPO ä¸ä¸¢å¼ƒä»»ä½•æ•°æ®ï¼Œåœ¨ä¿ç•™å¤šæ ·æ€§çš„åŒæ—¶å¼ºè°ƒå›°éš¾æ ·æœ¬ï¼Œæ€§èƒ½æ›´ç¨³å®šä¸”å…¨é¢é¢†å…ˆã€‚

#### ï¼ˆ4ï¼‰å½’ä¸€åŒ–ç­–ç•¥æ¶ˆèï¼ˆTable 11ï¼‰
| æ–¹æ³• | Hal. â†“ | F1 â†‘ |
|------|--------|------|
| DPO | 35.7 | 83.9 |
| Ranked-based | 31.3 | 85.7 |
| Length-controlled | 29.3 | 85.9 |
| **Gaussian Normalization** | **28.0** | **85.6** |

> âœ… Gaussian å½’ä¸€åŒ–æ•ˆæœæœ€ä½³ï¼Œè¯´æ˜ä¿ç•™åŸå§‹åˆ†å¸ƒç‰¹æ€§æœ‰åŠ©äºå‡†ç¡®å»ºæ¨¡éš¾åº¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å¤šæ¨¡æ€ DPO å­˜åœ¨ä¸¥é‡è¿‡æ‹Ÿåˆé—®é¢˜**ï¼šæ¨¡å‹å€¾å‘äºè¿‡åº¦ä¼˜åŒ–â€œæ˜æ˜¾æ­£ç¡®â€çš„ç®€å•æ ·æœ¬ï¼Œå¿½ç•¥éœ€è¦ç²¾ç»†æ¨ç†çš„å›°éš¾æ ·æœ¬ã€‚
2. **æ ·æœ¬éš¾åº¦å¯é€šè¿‡é¢„è®­ç»ƒ VLMs æœ‰æ•ˆä¼°è®¡**ï¼šCLIP å’Œ MLLM åˆ†åˆ«æ•æ‰å›¾åƒç›¸å…³æ€§å’Œè¯­ä¹‰é€»è¾‘ï¼ŒäºŒè€…äº’è¡¥ã€‚
3. **éš¾åº¦æ„ŸçŸ¥è®­ç»ƒæ˜¾è‘—æå‡æ€§èƒ½**ï¼šDA-DPO åœ¨é™ä½å¹»è§‰çš„åŒæ—¶ï¼Œè¿˜èƒ½æå‡æˆ–ç»´æŒç»¼åˆèƒ½åŠ›ï¼Œè§£å†³äº†â€œå¯¹é½ç¨â€é—®é¢˜ã€‚
4. **æ— éœ€æ–°è®­ç»ƒå³å¯å®ç°é«˜æ•ˆä¼˜åŒ–**ï¼šæ•´ä¸ªæ¡†æ¶å®Œå…¨åŸºäºå·²æœ‰æ¨¡å‹æ‰“åˆ†ï¼Œè®¡ç®—æˆæœ¬æä½ï¼ˆè§ Table 10ï¼‰ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é¢„è®­ç»ƒ VLM çš„å¯é æ€§**ï¼šè‹¥ç›®æ ‡é¢†åŸŸä¸ CLIP/MLLM é¢„è®­ç»ƒåˆ†å¸ƒå·®å¼‚è¿‡å¤§ï¼ˆå¦‚åŒ»å­¦å›¾åƒï¼‰ï¼Œéš¾åº¦ä¼°è®¡å¯èƒ½å¤±æ•ˆã€‚
- **æœªè€ƒè™‘ä»»åŠ¡ç±»åˆ«è‡ªé€‚åº”åŠ æƒ**ï¼šå½“å‰ voting æƒé‡æ˜¯å…¨å±€å›ºå®šçš„ï¼Œæœªæ¥å¯æ¢ç´¢ per-category æˆ–åŠ¨æ€è°ƒæ•´æœºåˆ¶ã€‚
- **å‡è®¾éš¾åº¦å¯è¢«ç°æœ‰ä»£ç†æ¨¡å‹åˆ»ç”»**ï¼šæŸäº›æç«¯æ¨¡ç³Šæˆ–ä¸»è§‚æ ·æœ¬å¯èƒ½éš¾ä»¥è¢«å®¢è§‚é‡åŒ–ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **domain-adaptive difficulty estimator**ï¼Œæå‡è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚
- å¼•å…¥ **self-improving mechanism**ï¼Œè®©æ¨¡å‹åœ¨è®­ç»ƒä¸­è¿­ä»£æ›´æ–°éš¾åº¦è¯„ä¼°å™¨ã€‚
- ç»“åˆ **active learning**ï¼Œä¼˜å…ˆé‡‡é›†é«˜éš¾åº¦æ ·æœ¬è¿›è¡Œæ ‡æ³¨ã€‚
- å°† DA-DPO æ€è·¯æ¨å¹¿è‡³ **video-language models** æˆ– **robotics** ç­‰æ›´å¤æ‚åœºæ™¯ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼šDA-DPO æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”å®ç”¨çš„è§†è§’â€”â€”å°†â€œæ ·æœ¬éš¾åº¦â€çº³å…¥åå¥½ä¼˜åŒ–è¿‡ç¨‹ã€‚å®ƒä¸ä»…æœ‰æ•ˆç¼“è§£äº† MLLM çš„å¹»è§‰é—®é¢˜ï¼Œè¿˜å±•ç¤ºäº†å¦‚ä½•ä½æˆæœ¬åœ°åˆ©ç”¨å·²æœ‰æ¨¡å‹çŸ¥è¯†æ¥æŒ‡å¯¼è®­ç»ƒï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†é‡è¦å¯å‘ã€‚

</details>

---

### 5. [InfoSynth: Information-Guided Benchmark Synthesis for LLMs](https://arxiv.org/abs/2601.00575)

**Authors**: Ishir Garg, Neel Kolhe, Xuandong Zhao, Dawn Song  
**Category**: cs.CL  
**Published**: 2026-01-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.00575v1  

#### Abstract
Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive an...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# InfoSynth: Information-Guided Benchmark Synthesis for LLMs è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»£ç ç”Ÿæˆå’Œæ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å…¶è¯„ä¼°é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **åŸºå‡†æ±¡æŸ“ï¼ˆBenchmark Contaminationï¼‰**ï¼šè®¸å¤šç°æœ‰è¯„æµ‹é›†å·²è¢«ç”¨äºè®­ç»ƒæ•°æ®ï¼Œå¯¼è‡´æ¨¡å‹è¡¨ç°è¢«é«˜ä¼°ã€‚
- **äººå·¥æ„å»ºæˆæœ¬é«˜**ï¼šé«˜è´¨é‡åŸºå‡†çš„åˆ›å»ºä¾èµ–å¤§é‡äººåŠ›ï¼Œè€—æ—¶ä¸”æ˜‚è´µã€‚
- **ç¼ºä¹å¤šæ ·æ€§ä¸æ–°é¢–æ€§**ï¼šç°æœ‰æ–¹æ³•ç”Ÿæˆçš„åˆæˆé—®é¢˜å¾€å¾€ä¸ç§å­æ•°æ®é«˜åº¦ç›¸ä¼¼ï¼Œæ˜“å¯¼è‡´è¿‡æ‹Ÿåˆã€‚

å› æ­¤ï¼ŒäºŸéœ€ä¸€ç§èƒ½å¤Ÿé«˜æ•ˆã€è‡ªåŠ¨åœ°ç”Ÿæˆ**æ–°é¢–ï¼ˆnovelï¼‰ã€å¤šæ ·åŒ–ï¼ˆdiverseï¼‰ä¸”å¯éªŒè¯æ­£ç¡®æ€§**çš„Pythonç¼–ç¨‹é—®é¢˜çš„æ–¹æ³•ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡º **InfoSynth**ï¼Œä¸€ä¸ªåŸºäºä¿¡æ¯è®ºæŒ‡å¯¼çš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œç”¨äºè‡ªåŠ¨ç”Ÿæˆå’Œè¯„ä¼°LLMæ¨ç†èƒ½åŠ›åŸºå‡†ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰ä¿¡æ¯è®ºé©±åŠ¨çš„åŸºå‡†è´¨é‡åº¦é‡
é¦–æ¬¡å¼•å…¥**KLæ•£åº¦ï¼ˆKL-Divergenceï¼‰** å’Œ **é¦™å†œç†µï¼ˆShannon Entropyï¼‰** æ¥é‡åŒ–åŸºå‡†çš„ï¼š
- **Noveltyï¼ˆæ–°é¢–æ€§ï¼‰**ï¼šé€šè¿‡ $ D_{KL}(q \| p) $ è¡¡é‡æ–°æ•°æ®é›† $ Y \sim q $ ç›¸å¯¹äºç§å­æ•°æ®é›† $ X \sim p $ çš„åˆ†å¸ƒå·®å¼‚ã€‚
- **Diversityï¼ˆå¤šæ ·æ€§ï¼‰**ï¼šé€šè¿‡å¾®åˆ†ç†µè¡¡é‡æ•°æ®é›†ä¸­é—®é¢˜ä¹‹é—´çš„åˆ†æ•£ç¨‹åº¦ï¼Œè¶Šé«˜è¡¨ç¤ºè¦†ç›–æ›´å¹¿çš„ä»»åŠ¡ç©ºé—´ã€‚

> âœ… ä¼˜åŠ¿ï¼šæ— éœ€è¿è¡Œæ˜‚è´µçš„æ¨¡å‹æµ‹è¯•å³å¯å¿«é€Ÿä¼°ç®—åŸºå‡†è´¨é‡ï¼Œæ˜¾è‘—é™ä½è¯„ä¼°å¼€é”€ã€‚

#### ï¼ˆ2ï¼‰é—ä¼ ç®—æ³• + è¿­ä»£åé¦ˆçš„åˆæˆç®¡é“
æ„å»ºäº†ä¸€ä¸ªç»“åˆ**é—ä¼ æ“ä½œ**ä¸**ä»£ç æ‰§è¡Œåé¦ˆ**çš„é—­ç¯ç”Ÿæˆæµç¨‹ï¼š
- **Mutationï¼ˆå˜å¼‚ï¼‰**ï¼šå¯¹åŸé—®é¢˜è¿›è¡Œâ€œå˜éš¾â€ã€â€œå˜æ˜“â€æˆ–â€œä¿æŒéš¾åº¦â€çš„æ”¹å†™ï¼Œæå‡å¤šæ ·æ€§ã€‚
- **Crossoverï¼ˆäº¤å‰ï¼‰**ï¼šèåˆä¸¤ä¸ªä¸åŒé—®é¢˜çš„æ ¸å¿ƒæ¦‚å¿µï¼Œåˆ›é€ æ–°é¢–å¤åˆé¢˜ã€‚
- **k-Farthest Neighbor Selection**ï¼šä¿ç•™è¯­ä¹‰ä¸Šæœ€è¿œç¦»å·²æœ‰é—®é¢˜çš„æ–°é—®é¢˜ï¼Œä¸»åŠ¨å¢å¼ºæ–°é¢–æ€§å’Œå¤šæ ·æ€§ã€‚
- **Iterative Code Feedback**ï¼šé€šè¿‡å¤šæ¬¡æ‰§è¡Œè§£å†³æ–¹æ¡ˆå¹¶åé¦ˆé”™è¯¯æ—¥å¿—ï¼Œè¿­ä»£ä¿®æ­£ä»£ç ä¸æµ‹è¯•ç”¨ä¾‹ï¼Œç¡®ä¿ç”Ÿæˆé—®é¢˜çš„**å¯æ‰§è¡Œæ€§ä¸æ­£ç¡®æ€§**ã€‚
- **MinHash + LSH å»é‡**ï¼šå»é™¤æ–‡æœ¬å±‚é¢é‡å¤çš„é—®é¢˜ã€‚

#### ï¼ˆ3ï¼‰å¯æ§æ€§è®¾è®¡
æ”¯æŒè°ƒèŠ‚ç”Ÿæˆé—®é¢˜çš„**éš¾åº¦ã€æ–°é¢–æ€§ä¸å¤šæ ·æ€§**ä¹‹é—´çš„æƒè¡¡ï¼Œä¾‹å¦‚é€šè¿‡æ§åˆ¶æ˜¯å¦å¯ç”¨ `k-farthest` è¿‡æ»¤æ¥è°ƒæ•´è¾“å‡ºç‰¹æ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | InfoSynth | å…¶ä»–æ–¹æ³•ï¼ˆå¦‚ GeneticInstruct, KodCodeï¼‰ |
|------|---------|-----------------------------|
| æ­£ç¡®æ€§ä¿éšœ | âœ… æ‰§è¡Œç¯å¢ƒéªŒè¯ + å¤šè½®åé¦ˆ | âŒ ä¾èµ–LLMè‡ªæˆ‘åˆ¤æ–­ï¼Œæ˜“å‡ºé”™ |
| æ–°é¢–æ€§åº¦é‡ | âœ… ä¿¡æ¯è®ºæŒ‡æ ‡ï¼ˆKLæ•£åº¦ï¼‰ | âŒ ä¾èµ–æ¨¡å‹æ€§èƒ½æˆ–äººå·¥è¯„ä¼° |
| å¤šæ ·æ€§æ§åˆ¶ | âœ… æ˜¾å¼è¿‡æ»¤æœºåˆ¶ | âš ï¸ æœ‰é™ |
| éš¾åº¦è°ƒæ§ | âœ… æ”¯æŒå¤šçº§å˜å¼‚ï¼ˆeasy/medium/hardï¼‰ | âš ï¸ é€šå¸¸å•ä¸€æ¨¡å¼ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **ç§å­æ•°æ®é›†ï¼ˆSeed Datasetsï¼‰**ï¼š
  - **MBPP**ï¼ˆ374ä¸ªç®€å•Pythonç¼–ç¨‹é¢˜ï¼‰
  - **LeetCode**ï¼ˆæ¥è‡ª Xia et al. [38] çš„ç²¾é€‰å­é›†ï¼‰
- **å¯¹æ¯”æ•°æ®é›†**ï¼š
  - **APPS**, **HumanEval**, **Codeforces**, **MBPP**, **LeetCode å­æ ‡ç­¾é›†åˆ**ï¼ˆå¦‚ "String", "Graph", "Hash Table"ï¼‰

æ‰€æœ‰é—®é¢˜å‡ä½¿ç”¨ `all-mpnet-base-v2` ç¼–ç ä¸ºå‘é‡ï¼Œå¹¶é€šè¿‡ **UMAP** é™ç»´è‡³ä½ç»´ç©ºé—´ä»¥è®¡ç®—KLæ•£åº¦ä¸ç†µã€‚

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### ç”Ÿæˆè®¾ç½®
- ä½¿ç”¨ **GPT-4o** ä½œä¸ºç”Ÿæˆå™¨ã€‚
- ç”Ÿæˆå…­ç»„æ•°æ®ï¼š
  - `MBPP-New`, `MBPP-Guided`ï¼ˆå¸¦k-farthestè¿‡æ»¤ï¼‰
  - `MBPP-Hard`, `MBPP-Hard-Guided`
  - `Leetcode-New`, `Leetcode-Guided`

#### è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **è´¨é‡æŒ‡æ ‡** | % Human Correctï¼ˆäººå·¥éªŒè¯æ­£ç¡®ç‡ï¼‰ã€Test Coverageï¼ˆæµ‹è¯•è¦†ç›–ç‡ï¼‰ã€Avg. Testsï¼ˆå¹³å‡æ¯é¢˜æµ‹è¯•æ•°ï¼‰ |
| **æ–°é¢–æ€§** | KL-Divergence ç›¸å¯¹äºç§å­æ•°æ®é›† |
| **å¤šæ ·æ€§** | Differential Entropy |
| **éš¾åº¦** | SOTAæ¨¡å‹åœ¨è¯¥æ•°æ®é›†ä¸Šçš„Pass@1å‡†ç¡®ç‡ï¼ˆè¶Šä½è¡¨ç¤ºè¶Šéš¾ï¼‰ |
| **é²æ£’æ€§** | è§£å†³æ–¹æ¡ˆé€šè¿‡æ‰€æœ‰æµ‹è¯•çš„æ¯”ä¾‹ |

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **GeneticInstruct**ï¼šåŸºäºé—ä¼ ç®—æ³•ç”ŸæˆæŒ‡ä»¤ã€‚
- **KodCode**ï¼šå¼ºè°ƒæŒ‘æˆ˜æ€§å’Œå¯éªŒè¯æ€§çš„åˆæˆæ•°æ®é›†ã€‚
- æ‰€æœ‰æ–¹æ³•å‡ä½¿ç”¨LeetCodeä½œä¸ºç§å­ï¼Œæ¯”è¾ƒå…¶ç›¸å¯¹äºLeetCodeçš„**novelty & diversity**ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| Dataset | % Human Correct | Test Coverage | Avg. Tests |
|--------|------------------|---------------|------------|
| MBPP-New | 97% | 99% | 8.30 |
| MBPP-Guided | 98% | 99% | 8.86 |
| Leetcode-New | 98% | 99% | 8.22 |
| Leetcode-Guided | 97% | 100% | 8.66 |

âœ… **ç»“è®º**ï¼šInfoSynth åœ¨ **97%ä»¥ä¸Š**çš„æƒ…å†µä¸‹èƒ½ç”Ÿæˆ**å®Œå…¨æ­£ç¡®ä¸”æµ‹è¯•å……åˆ†**çš„é—®é¢˜ï¼Œå…·å¤‡é«˜åº¦å¯é æ€§ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆFigure 6ï¼‰

- **å¤šæ ·æ€§ï¼ˆDiversityï¼‰**ï¼šInfoSynth ä¸ GeneticInstruct æ¥è¿‘ï¼Œç•¥é«˜äº KodCodeã€‚
- **æ–°é¢–æ€§ï¼ˆNoveltyï¼‰**ï¼š**InfoSynth æ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•**ï¼Œè¯´æ˜å…¶æ›´èƒ½è„±ç¦»ç§å­æ•°æ®åˆ†å¸ƒç”ŸæˆçœŸæ­£æ–°é¢–çš„é—®é¢˜ã€‚

> ğŸ” æ³¨ï¼šæ­¤æ¯”è¾ƒåŸºäºåŒä¸€ç§å­ï¼ˆLeetCodeï¼‰ï¼Œçªæ˜¾ InfoSynth æ›´å¼ºçš„â€œè·³å‡ºåŸæœ‰åˆ†å¸ƒâ€èƒ½åŠ›ã€‚

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰k-Farthest Neighbor Filtering çš„å½±å“ï¼ˆFigure 4c, 4dï¼‰
- å¯ç”¨è¯¥æ¨¡å— â†’ **æ˜¾è‘—æé«˜ novelty å’Œ diversity**
- ä»£ä»·æ˜¯ç”Ÿæˆçš„é—®é¢˜**å¹³å‡éš¾åº¦ä¸‹é™**ï¼ˆå› å¤æ‚ç»„åˆé¢˜æ›´éš¾é€šè¿‡éªŒè¯ï¼‰
- âœ… è¯æ˜ InfoSynth å¯æ§åœ°è°ƒèŠ‚ novelty-diversity-difficulty ä¸‰è§’å…³ç³»

#### ï¼ˆ2ï¼‰å¤šçº§ Mutation çš„æ•ˆæœï¼ˆTable 2ï¼‰
- `MBPP-Hard` ç›¸æ¯”åŸå§‹MBPPï¼Œåœ¨å¤šä¸ªSOTAæ¨¡å‹ä¸Šæ€§èƒ½ä¸‹é™ **8%-15%**
- è¡¨æ˜ hard mutation æˆåŠŸæå‡äº†é—®é¢˜éš¾åº¦
- ä½†ä¹Ÿå¸¦æ¥**å¤šæ ·æ€§å’Œæ–°é¢–æ€§é™ä½**ï¼ˆé›†ä¸­åœ¨å°‘æ•°éš¾ç‚¹ä¸»é¢˜ï¼‰

#### ï¼ˆ3ï¼‰Iterative Code Feedback çš„ä½œç”¨ï¼ˆSection 5.3ï¼‰
- ç»è¿‡ **5è½®åé¦ˆ**ï¼Œpassing solution-test å¯¹æ¯”ä¾‹æå‡çº¦ **20%**
- é”™è¯¯ç‡ï¼ˆerror/failï¼‰æŒç»­ä¸‹é™ï¼Œæ˜¾ç¤ºåé¦ˆæœ‰æ•ˆä¿®å¤è¯­æ³•ä¸é€»è¾‘é”™è¯¯
- **3è½®ä¸ºæ€§ä»·æ¯”æœ€ä¼˜**ï¼Œåç»­å¢ç›Šè¾¹é™…é€’å‡

#### ï¼ˆ4ï¼‰Postprocessing çš„ä»·å€¼ï¼ˆSection 5.5ï¼‰
- è§£å†³è¾¹ç¼˜æƒ…å†µæ¨¡ç³Šé—®é¢˜ï¼ˆå¦‚ç©ºè¾“å…¥è¿”å›å€¼ï¼‰
- å¯¼è‡´ SOTA æ¨¡å‹å‡†ç¡®ç‡æå‡ **5â€“15%**
- äººå·¥æ ¸æŸ¥ç¡®è®¤ï¼š**100% post-processed é—®é¢˜è¡¨è¿°æ¸…æ™°æ— æ­§ä¹‰**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ä¿¡æ¯è®ºæŒ‡æ ‡å¯è¡Œ**ï¼šKLæ•£åº¦ä¸ç†µå¯ä»¥ä½æˆæœ¬ã€æœ‰æ•ˆåœ°è¡¡é‡åŸºå‡†çš„**æ–°é¢–æ€§ä¸å¤šæ ·æ€§**ï¼Œæ— éœ€ä¾èµ–æ¨¡å‹æ‰“åˆ†ã€‚
2. **InfoSynth é«˜æ•ˆå¯é **ï¼šå¯åœ¨æ— äººå·¥å¹²é¢„ä¸‹ç”Ÿæˆ **97%ä»¥ä¸Šæ­£ç¡®ç‡**çš„Pythonç¼–ç¨‹é¢˜ï¼Œä¸”æµ‹è¯•å®Œå¤‡ã€‚
3. **ç”Ÿæˆè´¨é‡æ›´é«˜**ï¼šç›¸æ¯”ç§å­æ•°æ®ï¼ŒInfoSynth ç”Ÿæˆçš„æ•°æ®é›†å…·æœ‰æ›´é«˜çš„**novelty å’Œ diversity**ã€‚
4. **å¯æ§æ€§å¼º**ï¼šå¯é€šè¿‡å¼€å…³ `k-farthest` æˆ–é€‰æ‹© mutation ç±»å‹æ¥è°ƒèŠ‚è¾“å‡ºç‰¹æ€§çš„å¹³è¡¡ã€‚
5. **ä¼˜äºç°æœ‰æ–¹æ³•**ï¼šåœ¨ novelty ä¸Šè¶…è¶Š GeneticInstruct ä¸ KodCodeï¼ŒåŒæ—¶ä¿è¯ solution æ­£ç¡®æ€§ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–å¼ºå¤§LLM**ï¼šæ•´ä¸ªæµç¨‹åŸºäº GPT-4oï¼Œå°æ¨¡å‹å¯èƒ½æ— æ³•ç¨³å®šç”Ÿæˆé«˜è´¨é‡è§£ä¸æµ‹è¯•ã€‚
2. **é•¿å‘¨æœŸä»»åŠ¡å—é™**ï¼šæ¶‰åŠå¤šé‡çº¦æŸæˆ–æ·±å±‚æ•°å­¦è®¡ç®—çš„é—®é¢˜ï¼ˆå¦‚ Delannoy æ•°ï¼‰å®¹æ˜“å¤±è´¥ã€‚
3. **ä»å¯èƒ½å­˜åœ¨éšæ€§æ±¡æŸ“**ï¼šè™½ç„¶æœªç›´æ¥å¤ç”¨é¢˜ç›®ï¼Œä½†è‹¥LLMè®°å¿†äº†ç±»ä¼¼ç»“æ„ï¼Œä»å¯èƒ½é—´æ¥æ±¡æŸ“ã€‚
4. **ä»…é™å¯æ‰§è¡Œä»»åŠ¡**ï¼šç›®å‰èšç„¦äºPythonç¼–ç é—®é¢˜ï¼Œéš¾ä»¥æ‰©å±•åˆ°çº¯æ•°å­¦æ¨ç†æˆ–å¼€æ”¾ç”Ÿæˆç±»ä»»åŠ¡ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† InfoSynth æ‰©å±•è‡³æ›´å¤šé¢†åŸŸï¼ˆå¦‚æ•°å­¦è¯æ˜ã€è‡ªç„¶è¯­è¨€ç†è§£ï¼‰ã€‚
- ç»“åˆ contamination detection å·¥å…·ï¼Œè¿›ä¸€æ­¥ç¡®ä¿åŸºå‡†â€œå¹²å‡€â€ã€‚
- æ¢ç´¢åŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªåŠ¨åŒ–éš¾åº¦è°ƒæ§ç­–ç•¥ã€‚
- æ„å»ºå¤§è§„æ¨¡ã€åŠ¨æ€æ›´æ–°çš„åˆæˆåŸºå‡†å¹³å°ï¼Œå®ç° LLM èƒ½åŠ›çš„æŒç»­è¯„ä¼°ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> InfoSynth æä¾›äº†ä¸€ç§**å¯æ‰©å±•ã€è‡ªéªŒè¯ã€ä¿¡æ¯è®ºé©±åŠ¨**çš„åŸºå‡†åˆæˆèŒƒå¼ï¼Œä¸ºæ„å»ºä¸‹ä¸€ä»£æŠ—æ±¡æŸ“ã€é«˜å¤šæ ·æ€§çš„LLMè¯„æµ‹ä½“ç³»æä¾›äº†é‡è¦å·¥å…·ã€‚

</details>

---

### 6. [Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting](https://arxiv.org/abs/2601.00172)

**Authors**: Ata Akbari Asanjan, Filip Wudarski, Daniel O'Connor, Shaun Geaney, Elena Strbac, P. Aaron Lott, Davide Venturelli  
**Category**: cs.LG  
**Published**: 2026-01-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.00172v1  

#### Abstract
Forecasting high-dimensional spatiotemporal systems remains computationally challenging for recurrent neural networks (RNNs) and long short-term memory (LSTM) models due to gradient-based training and memory bottlenecks. Reservoir Computing (RC) mitigates these challenges by replacing backpropagatio...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **Reservoir Computing (RC)** è™½ç„¶é¿å…äº†åŸºäºæ¢¯åº¦çš„è®­ç»ƒï¼ˆå¦‚ RNN å’Œ LSTM ä¸­çš„ BPTTï¼‰ï¼Œå…·æœ‰é«˜æ•ˆè®­ç»ƒçš„ä¼˜ç‚¹ï¼Œä½†åœ¨å¤„ç†**é«˜ç»´æ—¶ç©ºæ•°æ®**æ—¶ä»é¢ä¸´æ˜¾è‘—ç“¶é¢ˆï¼š
- **å†…å­˜éœ€æ±‚å‘ˆæŒ‡æ•°å¢é•¿**ï¼Œéš¾ä»¥æ‰©å±•åˆ°å¤§è§„æ¨¡ç³»ç»Ÿï¼›
- æ ‡å‡† RC æ¶æ„åœ¨è¾“å…¥ç»´åº¦å¢åŠ æ—¶è®¡ç®—å’Œå­˜å‚¨å¼€é”€æ€¥å‰§ä¸Šå‡ã€‚

æ­¤å¤–ï¼Œå°½ç®¡æ·±åº¦ RCï¼ˆDeep RCï¼‰é€šè¿‡å †å å¤šå±‚ reservoir å±•ç°å‡ºæ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›ï¼Œä½†å°šæœªè¢«ç³»ç»Ÿç ”ç©¶ç”¨äºé«˜ç»´ spatiotemporal é¢„æµ‹ä»»åŠ¡ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šSequential Reservoir Computing (Sequential RC)
æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹æ¶æ„â€”â€”**Sequential Reservoir Computing (Sequential RC)**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†ä¸€ä¸ªå¤§å‹ reservoir åˆ†è§£ä¸ºä¸€ç³»åˆ—**è¾ƒå°ä¸”ç›¸äº’è¿æ¥çš„å°å‹ reservoirs**ï¼ŒæŒ‰é¡ºåºçº§è”ï¼›
- æ¯ä¸ª reservoir çš„è¾“å‡ºè¢«æ‹¼æ¥åé€å…¥æœ€ç»ˆçš„çº¿æ€§è¯»å‡ºå±‚ï¼ˆreadoutï¼‰è¿›è¡Œé¢„æµ‹ï¼›
- æ‰€æœ‰ reservoir å±‚å‚æ•°å›ºå®šï¼ˆéè®­ç»ƒï¼‰ï¼Œä»…è®­ç»ƒ readout å±‚ï¼ˆé‡‡ç”¨å²­å›å½’ä¼˜åŒ–ï¼‰ã€‚

è¯¥è®¾è®¡ä¿ç•™äº†æ ‡å‡† RC çš„ä¼˜ç‚¹ï¼ˆæ— éœ€åå‘ä¼ æ’­ã€å‡¸ä¼˜åŒ–è¯»å‡ºå±‚ï¼‰ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½å†…å­˜ä¸è®¡ç®—è´Ÿæ‹…ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **å¯æ‰©å±•æ€§** | æ˜¾è‘—æå‡å¯¹é«˜ç»´æ•°æ®çš„é€‚åº”èƒ½åŠ›ï¼Œçªç ´ä¼ ç»Ÿ RC å†…å­˜ç“¶é¢ˆ |
| **æ•ˆç‡** | è®­ç»ƒæˆæœ¬æ¯” LSTM ä½ä¸‰ä¸ªæ•°é‡çº§ï¼›æ¨ç† FLOPS å¤§å¹…ä¸‹é™ |
| **æ€§èƒ½** | åœ¨é¢„æµ‹ç²¾åº¦ã€æœ‰æ•ˆé¢„æµ‹æ—¶é—´ï¼ˆVPTï¼‰ã€SSIMã€RMSE ç­‰æŒ‡æ ‡ä¸Šå…¨é¢ä¼˜äº RNNã€LSTM å’Œæ ‡å‡† RC |
| **å‚æ•°é‡æ§åˆ¶** | å¯æ§çš„å›ºå®šå‚æ•°è§„æ¨¡ï¼Œé€‚åˆèµ„æºå—é™åœºæ™¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†

| æ•°æ®é›† | ç±»å‹ | ç»´åº¦ | æè¿° |
|--------|------|-------|------|
| **Lorenz63** | ä½ç»´æ··æ²Œç³»ç»Ÿ | 3D æ—¶é—´åºåˆ— | ç»å…¸çš„ä¸‰å˜é‡æ··æ²Œå¾®åˆ†æ–¹ç¨‹ï¼Œç”¨äºæµ‹è¯•é•¿æœŸåŠ¨æ€å»ºæ¨¡èƒ½åŠ› |
| **Vorticity (2D Navier-Stokes)** | é«˜ç»´ç‰©ç†æ¨¡æ‹Ÿ | $64 \times 64$ ç½‘æ ¼ | ä¸å¯å‹ç¼©æµä½“æ¶¡åº¦æ¼”åŒ–ï¼Œå«å¤æ‚ç©ºé—´ç»“æ„ |
| **Shallow Water Equations (SWE)** | é«˜ç»´ç‰©ç†æ¨¡æ‹Ÿ | $64 \times 64$ ç½‘æ ¼ | åœ°è¡¨æµåŠ¨æ¨¡å‹ï¼Œæ¨¡æ‹Ÿæ³¢ä¼ æ’­ä¸è¾¹ç•Œåå°„ |

æ‰€æœ‰é«˜ç»´æ•°æ®å‡ä»¥äºŒç»´åœºå½¢å¼è¾“å…¥ï¼Œä»£è¡¨å…¸å‹çš„ç§‘å­¦è®¡ç®—ä¸­çš„ spatiotemporal åŠ¨åŠ›å­¦é—®é¢˜ã€‚

### âš™ï¸ å®éªŒè®¾ç½®

#### æ¨¡å‹é…ç½®
| æ¨¡å‹ | ç»“æ„è¯´æ˜ |
|------|----------|
| **RNN / LSTM** | Vanilla RNN å’Œ LSTMï¼Œå•éšè—å±‚ï¼ˆ256 æˆ– 512ï¼‰ï¼Œå…¨è¿æ¥è¾“å…¥å±‚ï¼Œmany-to-one æ¶æ„ |
| **Standard RC** | å•ä¸€å¤§å‹ reservoirï¼ˆå¤§å° 256 æˆ– 512ï¼‰ |
| **Sequential RC** | 8 ä¸ªå°å‹ reservoir çº§è”ï¼ˆæ¯å±‚ 32 æˆ– 64ï¼‰ï¼Œæ€»å‚æ•°è¿œå°äºæ ‡å‡† RC |

#### è¶…å‚æ•°ï¼ˆè§ Appendix Bï¼‰
- Spectral Radius: 1.1
- Leak Rate: 0.7
- Sparsity: 0.0
- Historical Window: 49
- Optimizer (for RNN/LSTM): RMSProp, lr = 1e-4
- Precision: Float64

#### è®­ç»ƒæ ·æœ¬é•¿åº¦
- Lorenz63: 2,000 / 5,000 / 10,000 ä¸ªæ—¶é—´æ­¥
- Vorticity & SWE: 2,000 / 5,000 ä¸ªæ—¶é—´æ­¥

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | ç”¨é€” |
|------|------|
| **Valid Prediction Time (VPT)** | è¡¡é‡é¢„æµ‹è½¨è¿¹åç¦»çœŸå®å€¼çš„æ—¶é—´ç‚¹ï¼ˆé˜ˆå€¼ RMSE â‰¥ 0.3ï¼‰ |
| **SSIM (Structural Similarity Index)** | è¯„ä»·å›¾åƒ/åœºç»“æ„ç›¸ä¼¼æ€§ï¼Œæ›´è´´è¿‘äººç±»æ„ŸçŸ¥ |
| **PSNR (Peak Signal-to-Noise Ratio)** | å›¾åƒè´¨é‡åº¦é‡ï¼Œè¶Šé«˜è¶Šå¥½ |
| **RMSE (Root Mean Square Error)** | å¹³å‡è¯¯å·®ï¼Œè¶Šä½è¶Šå¥½ |
| **Return Map (z-maxima plotting)** | å¯è§†åŒ–æ··æ²Œç³»ç»Ÿçš„é•¿æœŸç¨³å®šæ€§ |
| **FLOPS, Memory Usage, Training Time** | è¯„ä¼°è®¡ç®—æ•ˆç‡ä¸èµ„æºæ¶ˆè€— |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **RNN (Elman-type)**
- **LSTM**
- **Standard Reservoir Computing (RC)**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### âœ… ä½ç»´ç»“æœï¼ˆLorenz63ï¼‰

| æ¨¡å‹ | VPT (2k samples) | Trainable Params | Fixed Params | FLOPS (MFLOPS) | GPU Mem (MB) | Train Time (s) |
|------|------------------|------------------|---------------|----------------|--------------|----------------|
| RNN | 0.10 | 133K | 0 | 6.59 | 1.02 | 508 |
| LSTM | 1.73 | 528K | 0 | 26.25 | 4.29 | 576 |
| RC | 7.19 | 780 | 66K | 0.067 | 0.0138 | 0.4 |
| **Seq. RC** | **8.65** | **780** | **8.3K** | **0.0091** | **0.0069** | **1.4** |

> âœ… **Sequential RC çš„ VPT æ¯”æ ‡å‡† RC æå‡çº¦ 20%**  
> âœ… å›ºå®šå‚æ•°ä»…ä¸º RC çš„ ~12.5%ï¼ŒFLOPS ä¸‹é™ 7.4 å€ï¼Œå†…å­˜å‡å°‘ä¸€åŠä»¥ä¸Š  
> âœ… å°½ç®¡è®­ç»ƒæ—¶é—´ç•¥é•¿äº RCï¼ˆå› ä¸²è¡Œè®¡ç®—å»¶è¿Ÿï¼‰ï¼Œä½†ä»è¿œå¿«äº RNN/LSTM

#### âœ… é«˜ç»´ç»“æœï¼ˆVorticity & SWEï¼‰

| æ¨¡å‹ | SSIM / PSNR / RMSE è¶‹åŠ¿ | VPT / Forecast Horizon |
|------|----------------------------|-------------------------|
| RNN | å¿«é€Ÿå‘æ•£ï¼Œæ—©æœŸå¤±æ•ˆ | < t+10 |
| LSTM | çº¦åœ¨ t+30 å¼€å§‹æ˜æ˜¾åå·® | ~t+30â€“40 |
| RC | åˆæœŸè‰¯å¥½ï¼Œt+50 åç»†èŠ‚ä¸¢å¤± | ~t+50 |
| **Sequential RC** | **ä¿æŒé«˜è´¨é‡è‡³ t+94**ï¼ŒSSIM > 0.6 æ›´ä¹… | **æœ€é•¿æœ‰æ•ˆé¢„æµ‹** |

> åœ¨ Vorticity ä¸Šï¼Œ**Sequential RC å°†æœ‰æ•ˆé¢„æµ‹æ­¥æ•°å»¶é•¿è‡³ 94**ï¼Œè€Œ RC åœ¨ ~50 æ­¥åæ€§èƒ½éª¤é™ã€‚

#### ğŸ’¡ æ€§èƒ½æå‡æ€»ç»“
- **æœ‰æ•ˆé¢„æµ‹æ—¶é—´ï¼ˆVPTï¼‰æå‡ï¼š15â€“25%**
- **è¯¯å·®æŒ‡æ ‡æ”¹å–„ï¼šRMSE é™ä½ 20â€“30%ï¼ŒSSIM æ˜¾è‘—æ›´é«˜**
- **è®­ç»ƒæˆæœ¬é™ä½ï¼šè¾¾ä¸‰ä¸ªæ•°é‡çº§ï¼ˆç›¸æ¯” LSTMï¼‰**
- **å†…å­˜å ç”¨å‡å°‘ï¼šæœ€é«˜è¾¾ 470 å€ï¼ˆvs LSTMï¼‰**

### ğŸ” æ¶ˆèå®éªŒåˆ†æï¼ˆéšå«åœ¨æ–‡ä¸­ï¼‰
è™½ç„¶æœªæ˜ç¡®å‘½åâ€œæ¶ˆèå®éªŒâ€ï¼Œä½†ä»¥ä¸‹åˆ†æä½“ç°äº†å…³é”®ç»„ä»¶çš„å½±å“ï¼š
- **å†å²çª—å£é•¿åº¦å½±å“**ï¼ˆAppendix Aï¼‰ï¼šéªŒè¯äº† 50 æ­¥å·¦å³ä¸ºæœ€ä¼˜ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œè¿‡é•¿åè€Œå¢åŠ  GPU å†…å­˜å‹åŠ›ï¼›
- **reservoir å¤§å°ä¸å±‚æ•°æƒè¡¡**ï¼šä½¿ç”¨å¤šä¸ªå° reservoir æ›¿ä»£å•ä¸€å¤§ä¼šæ›´é«˜æ•ˆï¼›
- **spectral radius å’Œ leak rate è®¾ç½®**ï¼šé€‰æ‹© 1.1 å’Œ 0.7 æ˜¯ç»è¿‡è°ƒä¼˜çš„æœ€ä½³ç»„åˆï¼›
- **ä¸åŒè®­ç»ƒæ ·æœ¬é‡çš„å½±å“**ï¼šå³ä½¿åœ¨å°æ ·æœ¬ä¸‹ï¼ˆ2kï¼‰ï¼ŒSequential RC ä¾ç„¶è¡¨ç°ç¨³å¥ï¼Œæ˜¾ç¤ºå¼ºæ³›åŒ–èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **Sequential RC æ˜¾è‘—æå‡äº†ä¼ ç»Ÿ RC çš„å¯æ‰©å±•æ€§**ï¼Œè§£å†³äº†é«˜ç»´æ•°æ®ä¸‹çš„å†…å­˜ç“¶é¢ˆé—®é¢˜ï¼›
2. åœ¨ä½ç»´å’Œé«˜ç»´ç³»ç»Ÿä¸­ï¼Œ**Sequential RC å‡å®ç°äº†æ›´é•¿çš„æœ‰æ•ˆé¢„æµ‹æ—¶é—´ï¼ˆVPTï¼‰å’Œæ›´é«˜çš„é¢„æµ‹ä¿çœŸåº¦ï¼ˆSSIM/PSNRï¼‰**ï¼›
3. **è®¡ç®—æ•ˆç‡æé«˜**ï¼šè®­ç»ƒæ—¶é—´æçŸ­ï¼ˆæ¯«ç§’çº§ï¼‰ï¼ŒFLOPS å’Œå†…å­˜ä½¿ç”¨è¿œä½äº RNN/LSTMï¼›
4. **ä¸å¢åŠ å¯è®­ç»ƒå‚æ•°çš„å‰æä¸‹å®ç°æ€§èƒ½é£è·ƒ**ï¼Œæ‰€æœ‰æ”¹è¿›æ¥è‡ªæ¶æ„ä¼˜åŒ–è€Œéå‚æ•°è†¨èƒ€ï¼›
5. å¯¹æ··æ²Œç³»ç»Ÿï¼ˆå¦‚ Lorenz63ï¼‰å’Œç‰©ç†æ¨¡æ‹Ÿç³»ç»Ÿï¼ˆå¦‚ Vorticityã€SWEï¼‰å‡æœ‰å‡ºè‰²è¡¨ç°ï¼Œå…·å¤‡å¹¿æ³›é€‚ç”¨æ€§ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

1. **sequential è®¡ç®—å¼•å…¥ä¸€å®šå»¶è¿Ÿ**ï¼šç”±äº reservoir å±‚éœ€ä¾æ¬¡è¿è¡Œï¼Œæ¨ç†é€Ÿåº¦ç•¥æ…¢äºå¹¶è¡Œç»“æ„ï¼ˆå°½ç®¡æ€»ä½“ä»å¾ˆå¿«ï¼‰ï¼›
2. **è¶…å‚æ•°æ•æ„Ÿæ€§**ï¼šspectral radiusã€leak rate ç­‰éœ€ä»”ç»†è°ƒæ•´æ‰èƒ½å‘æŒ¥æœ€ä½³æ€§èƒ½ï¼›
3. **å½“å‰æœªèåˆç‰©ç†å…ˆéªŒçŸ¥è¯†**ï¼šçº¯æ•°æ®é©±åŠ¨ï¼Œæœªæ¥å¯ç»“åˆç‰©ç†çº¦æŸè¿›ä¸€æ­¥å¢å¼ºé²æ£’æ€§ï¼›
4. **å°šæœªåœ¨çœŸå®ä¸–ç•Œè§‚æµ‹æ•°æ®ä¸ŠéªŒè¯**ï¼šç›®å‰å®éªŒåŸºäºä»¿çœŸæ•°æ®ï¼Œå®é™…åº”ç”¨éœ€è€ƒè™‘å™ªå£°ä¸ç¼ºå¤±ç­‰é—®é¢˜ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆåŸæ–‡ Conclusion & Acknowledgmentsï¼‰

1. æ¢ç´¢ **adaptive æˆ– physics-informed reservoir è¿æ¥æ–¹å¼**ï¼Œå°†é¢†åŸŸçŸ¥è¯†åµŒå…¥ reservoir ç»“æ„ï¼›
2. æ‰©å±•è‡³ **turbulent flow å’Œ multi-modal geophysical datasets**ï¼›
3. å¼€å‘ **neuromorphic æˆ– FPGA ç¡¬ä»¶å®ç°æ–¹æ¡ˆ**ï¼Œæ¨åŠ¨è¾¹ç¼˜éƒ¨ç½²ï¼›
4. æ¢ç´¢ **quantum-hybrid implementations**ï¼Œåˆ©ç”¨é‡å­æ€ä½œä¸º reservoirï¼ˆå·²æœ‰åˆæ­¥æ¢ç´¢ [37â€“39]ï¼‰ï¼›
5. åº”ç”¨äºå®æ—¶å¤©æ°”é¢„æŠ¥ã€æµ·æ´‹åŠ¨åŠ›å­¦ã€é‡‘èæ—¶åºç­‰é«˜ç»´å®æ—¶é¢„æµ‹åœºæ™¯ã€‚

---

## æ€»ç»“

> **Sequential Reservoir Computing** æ˜¯ä¸€ç§é«˜æ•ˆã€å¯æ‰©å±•ã€é«˜æ€§èƒ½çš„é«˜ç»´æ—¶ç©ºé¢„æµ‹æ¡†æ¶ã€‚å®ƒé€šè¿‡å°†å¤§ reservoir åˆ†è§£ä¸ºçº§è”çš„å° reservoirï¼Œåœ¨å‡ ä¹ä¸å¢åŠ å¯è®­ç»ƒå‚æ•°çš„æƒ…å†µä¸‹ï¼Œå¤§å¹…é™ä½äº†å†…å­˜å’Œè®¡ç®—å¼€é”€ï¼ŒåŒæ—¶æ˜¾è‘—æå‡äº†é¢„æµ‹ç¨³å®šæ€§å’Œç²¾åº¦ã€‚è¯¥æ–¹æ³•ä¸ºç§‘å­¦æœºå™¨å­¦ä¹ ä¸­**å®æ—¶ã€èŠ‚èƒ½ã€é«˜ç²¾åº¦çš„åŠ¨åŠ›ç³»ç»Ÿå»ºæ¨¡**æä¾›äº†åˆ‡å®å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 7. [Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2601.00202)

**Authors**: Wang Xing, Wei Song, Siyu Lin, Chen Wu, Zhesi Li, Man Wang  
**Category**: cs.CL  
**Published**: 2026-01-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.00202v1  

#### Abstract
Reasoning over temporal knowledge graphs (TKGs) is fundamental to improving the efficiency and reliability of intelligent decision-making systems and has become a key technological foundation for future artificial intelligence applications. Despite recent progress, existing TKG reasoning models typi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **Temporal Knowledge Graph (TKG)** æ¨ç†æ¨¡å‹é€šå¸¸ä¾èµ–å¤§è§„æ¨¡å‚æ•°å’Œé«˜è®¡ç®—å¼€é”€ï¼Œå¯¼è‡´éš¾ä»¥åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šéƒ¨ç½²ã€‚åŒæ—¶ï¼Œä¼ ç»Ÿçš„ **Knowledge Distillation** æ–¹æ³•å¤šé’ˆå¯¹é™æ€çŸ¥è¯†å›¾è°±è®¾è®¡ï¼Œæœªèƒ½æœ‰æ•ˆæ•æ‰ TKG ä¸­çš„æ—¶é—´åŠ¨æ€ç‰¹æ€§ï¼Œé€ æˆæ¨ç†æ€§èƒ½ä¸‹é™ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•
æœ¬æ–‡æå‡ºä¸€ç§**é¢å‘æ—¶åºçŸ¥è¯†å›¾è°±æ¨ç†çš„æ–°å‹è’¸é¦æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š
- **å¼•å…¥ Large Language Models (LLMs)** ä½œä¸ºâ€œæ•™å¸ˆâ€æ¨¡å‹ä¹‹ä¸€ï¼Œåˆ©ç”¨å…¶å¼ºå¤§çš„é€šç”¨çŸ¥è¯†å’Œæ—¶åºæ¨ç†èƒ½åŠ›æŒ‡å¯¼è½»é‡çº§å­¦ç”Ÿæ¨¡å‹è®­ç»ƒã€‚
- è®¾è®¡äº†ä¸€ä¸ª**åŒé˜¶æ®µè’¸é¦ç­–ç•¥**ï¼šç¬¬ä¸€é˜¶æ®µå¯¹é½ä¼ ç»Ÿ TKG æ•™å¸ˆæ¨¡å‹è¾“å‡ºï¼›ç¬¬äºŒé˜¶æ®µåˆ©ç”¨ LLM æä¾›æ›´ä¸°å¯Œçš„è¯­ä¹‰ä¸æ—¶åºä¿¡å·è¿›è¡Œç²¾ç»†åŒ–è°ƒæ•´ã€‚
- å°†å…¬å…±å¤§è§„æ¨¡è¯­è¨€çŸ¥è¯†ä¸ä»»åŠ¡ç‰¹å®šçš„æ—¶åºä¿¡æ¯èåˆï¼Œå¢å¼ºå­¦ç”Ÿæ¨¡å‹å»ºæ¨¡æ—¶é—´æ¼”åŒ–çš„èƒ½åŠ›ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- èƒ½å¤Ÿæœ‰æ•ˆè¿ç§»**ç»“æ„åŒ–çŸ¥è¯† + æ—¶é—´åŠ¨æ€æ¨¡å¼**ï¼Œå…‹æœä¼ ç»Ÿè’¸é¦æ–¹æ³•å¿½ç•¥æ—¶é—´ä¾èµ–æ€§çš„ç¼ºé™·ã€‚
- æ˜¾è‘—æå‡è½»é‡åŒ–æ¨¡å‹çš„æ¨ç†ç²¾åº¦ï¼Œåœ¨ä¿æŒä½è®¡ç®—æˆæœ¬çš„åŒæ—¶å®ç°é«˜æ€§èƒ½ã€‚
- æ”¯æŒåœ¨è¾¹ç¼˜è®¾å¤‡ç­‰ä½åŠŸè€—åˆ†å¸ƒå¼å¹³å°ä¸Šé«˜æ•ˆéƒ¨ç½²ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåŸºäºä¸¤ä¸ªå…¬å¼€çš„ TKG benchmark æ•°æ®é›†ï¼š
- **YAGO11k**ï¼šæºè‡ª Max Planck Institute æ„å»ºçš„çŸ¥è¯†åº“ï¼ŒåŒ…å«ä¸°å¯Œçš„æ—¶é—´æ ‡æ³¨äº‹å®ã€‚
- **WIKIdata12k**ï¼šä» Wikidata å’Œ Wikimedia Commons æ„å»ºçš„å¤šè¯­è¨€æ—¶åºçŸ¥è¯†å›¾è°±ã€‚

| Dataset | Entities | Relations | Train | Valid | Test |
|--------|----------|-----------|-------|-------|------|
| YAGO   | 10,623   | 10        | 161,540 | 19,523 | 20,026 |
| WIKI   | 12,544   | 24        | 539,286 | 67,538 | 63,110 |

### âš™ï¸ å®éªŒè®¾ç½®
- **æ•™å¸ˆæ¨¡å‹**ï¼šTTransE å’Œ TADistMultï¼ˆä»£è¡¨æ€§ TKG embedding æ¨¡å‹ï¼‰
- **å­¦ç”Ÿæ¨¡å‹**ï¼šè½»é‡ç‰ˆæœ¬ï¼Œembedding ç»´åº¦è®¾ä¸º 25ï¼ˆæ•™å¸ˆä¸º 400ï¼‰ï¼Œæ¨¡æ‹Ÿèµ„æºå—é™åœºæ™¯
- **LLM æ•™å¸ˆ**ï¼šé¢„è®­ç»ƒå¹¶åœ¨ TKG æ•°æ®ä¸Šå¾®è°ƒçš„å¤§è¯­è¨€æ¨¡å‹ï¼Œç”¨äºç”Ÿæˆè½¯æ ‡ç­¾å’Œè¯­ä¹‰è¡¨ç¤º
- **ä¼˜åŒ–å™¨**ï¼šAdagradï¼Œbatch size = 1024ï¼Œepoch = 10,000ï¼Œtemperature = 7
- **å®ç°å¹³å°**ï¼šåŸºäºæ‰©å±•ç‰ˆ OpenKE æ¡†æ¶ï¼ŒPyTorch + RTX 3090 Ti

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
æ ‡å‡†é“¾æ¥é¢„æµ‹æŒ‡æ ‡ï¼š
- **Mean Rank (MR)**ï¼šè¶Šå°è¶Šå¥½
- **Mean Reciprocal Rank (MRR)**ï¼šè¶Šå¤§è¶Šå¥½
- **Hits@1 / Hits@3 / Hits@10**ï¼šè¶Šé«˜è¶Šå¥½ï¼ˆTop-k å‡†ç¡®ç‡ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 3ï¼‰

#### åœ¨ YAGO ä¸Šçš„è¡¨ç°ï¼ˆä»¥ TTransE ä¸ºä¾‹ï¼‰ï¼š
| Method | MRR | MR â†“ | Hits@1 | Hits@3 | Hits@10 |
|--------|-----|------|--------|--------|---------|
| BKD    | 7.65 | 1410.12 | 3.50 | 7.83 | 15.61 |
| **Ours** | **7.69** | **1193.15** | **3.61** | **7.89** | **16.57** |

â†’ åœ¨ MR ä¸Šé™ä½çº¦ **15.4%**ï¼Œå…¶ä½™æŒ‡æ ‡å‡æœ‰æå‡ã€‚

#### åœ¨ WIKI ä¸Šçš„è¡¨ç°ï¼ˆä»¥ TADistMult ä¸ºä¾‹ï¼‰ï¼š
| Method | MRR | MR â†“ | Hits@1 | Hits@3 | Hits@10 |
|--------|-----|------|--------|--------|---------|
| BKD    | 45.89 | 3150.11 | 42.46 | 48.87 | 51.18 |
| **Ours** | **46.03** | **3142.85** | **42.50** | **49.16** | **51.14** |

â†’ å¤šæ•°æŒ‡æ ‡ä¼˜äºåŸºçº¿ï¼Œå°¤å…¶ **Hits@3 æå‡æ˜¾è‘—ï¼ˆ+0.29%ï¼‰**

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”
ç›¸æ¯”ä»¥ä¸‹ç»å…¸è’¸é¦æ–¹æ³•ï¼š
- **BKD**ï¼ˆæ ‡å‡† KL æ•£åº¦è’¸é¦ï¼‰
- **FitNet**ï¼ˆä¸­é—´å±‚ç›‘ç£ï¼‰
- **RKD**ï¼ˆå…³ç³»çŸ¥è¯†è’¸é¦ï¼‰

æœ¬æ–¹æ³•åœ¨å¤§å¤šæ•°é…ç½®ä¸‹è¡¨ç°æœ€ä¼˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ **Hits@1 å’Œ Hits@3** ä¸Šä¼˜åŠ¿æ˜æ˜¾ï¼Œè¯´æ˜èƒ½æ›´å¥½å°†æ­£ç¡®å®ä½“æ’åœ¨å‰åˆ—ã€‚

| å¯¹æ¯”é¡¹ | æ€§èƒ½ä¼˜åŠ¿ |
|--------|----------|
| vs. BKD | å¹³å‡æå‡ 0.5â€“16.7%ï¼Œå°¤å…¶åœ¨ MR å’Œ Hits@10 ä¸Š |
| vs. FitNet/RKD | æ›´ç¨³å®šï¼Œå¹³å‡æå‡ ~2.77%ï¼ˆYAGOï¼‰ã€~3.28%ï¼ˆWIKIï¼‰ |

### ğŸ” æ¶ˆèå®éªŒåˆ†æï¼ˆAblation Studyï¼‰
é€šè¿‡å¯¹æ¯”ä»…ä½¿ç”¨ BKD çš„åŸºçº¿ï¼ŒéªŒè¯ LLM è’¸é¦çš„æœ‰æ•ˆæ€§ï¼š
- åœ¨ YAGO ä¸Šï¼ŒåŠ å…¥ LLM å MRR æå‡ **0.5%**ï¼ŒHits@10 æå‡ **6.1%**
- åœ¨ WIKI ä¸Šï¼Œå¤šä¸ªæŒ‡æ ‡æŒç»­æ”¹å–„ï¼Œè¯æ˜ LLM æ³¨å…¥çš„çŸ¥è¯†æœ‰åŠ©äºæå‡å­¦ç”Ÿæ¨¡å‹æ³›åŒ–èƒ½åŠ›
- ç‰¹åˆ«æ˜¯åœ¨ç¨€ç–æˆ–æœªè§æ—¶é—´åŒºé—´ä¸­ï¼ŒLLM çš„å…ˆéªŒçŸ¥è¯†å¸®åŠ©ç¼“è§£è¿‡æ‹Ÿåˆ

> ğŸ’¡ ç»“è®ºï¼š**LLM æä¾›çš„è¯­ä¹‰ä¸æ—¶é—´ä¸Šä¸‹æ–‡æ˜¾è‘—å¢å¼ºäº†è’¸é¦æ•ˆæœ**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **LLM å¯ä½œä¸ºé«˜æ•ˆçš„â€œæ•™å¸ˆâ€æ¨¡å‹**ï¼Œä¸ä»…èƒ½ç¼–ç å®ä½“/å…³ç³»è¯­ä¹‰ï¼Œè¿˜èƒ½æ•æ‰éšå«çš„æ—¶é—´æ¼”åŒ–è§„å¾‹ã€‚
2. æ‰€æè’¸é¦æ¡†æ¶èƒ½åœ¨**å¤§å¹…å‹ç¼©æ¨¡å‹è§„æ¨¡**ï¼ˆç»´åº¦ä» 400 â†’ 25ï¼‰çš„å‰æä¸‹ï¼Œ**ç»´æŒç”šè‡³è¶…è¶ŠåŸå§‹å¤§æ¨¡å‹çš„æ¨ç†æ€§èƒ½**ã€‚
3. è¯¥æ–¹æ³•å®ç°äº†**å‡†ç¡®æ€§ã€æ•ˆç‡ä¸å¯éƒ¨ç½²æ€§ä¹‹é—´çš„è‰¯å¥½å¹³è¡¡**ï¼Œé€‚ç”¨äºè¾¹ç¼˜è®¡ç®—å’Œå®æ—¶æ¨ç†åœºæ™¯ã€‚

### âš ï¸ å±€é™æ€§
1. **LLM æœ¬èº«å¸¦æ¥é¢å¤–è®­ç»ƒå¼€é”€**ï¼šè™½ç„¶æ¨ç†è½»é‡ï¼Œä½† LLM å¾®è°ƒè¿‡ç¨‹ä»éœ€å¤§é‡ç®—åŠ›ã€‚
2. å½“å‰æ¡†æ¶èšç„¦äºå•è·³ link predictionï¼Œå°šæœªæ”¯æŒ multi-hop reasoning æˆ–é€»è¾‘è§„åˆ™å½’çº³ã€‚
3. å­¦ç”Ÿæ¨¡å‹å®¹é‡æå°æ—¶ï¼Œæ€§èƒ½å¢ç›Šå¯èƒ½å—é™ï¼Œå­˜åœ¨â€œçŸ¥è¯†ç“¶é¢ˆâ€ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤æ‚çš„æ¨ç†ä»»åŠ¡ï¼Œå¦‚ temporal rule learningã€multi-step forecasting
- æ¢ç´¢æ›´é«˜æ•ˆçš„ LLM è°ƒç”¨æœºåˆ¶ï¼ˆå¦‚ prompt tuningã€LoRAï¼‰
- ç ”ç©¶è·¨é¢†åŸŸè¿ç§»èƒ½åŠ›ï¼Œæå‡åœ¨ä½èµ„æº TKG ä¸Šçš„æ³›åŒ–è¡¨ç°

---

## æ€»ç»“
æœ¬æ–‡å¼€åˆ›æ€§åœ°å°† **Large Language Models å¼•å…¥ TKG çŸ¥è¯†è’¸é¦æµç¨‹**ï¼Œæ„å»ºäº†ä¸€ç§å…¼é¡¾**æ—¶é—´åŠ¨æ€æ€§ã€è¯­ä¹‰ä¸°å¯Œæ€§å’Œéƒ¨ç½²æ•ˆç‡**çš„æ–°å‹æ¨ç†æ¡†æ¶ã€‚å®éªŒè¯æ˜å…¶åœ¨å¤šä¸ª benchmark ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿè’¸é¦æ–¹æ³•ï¼Œä¸ºè½»é‡åŒ–æ—¶åºçŸ¥è¯†æ¨ç†æä¾›äº†å¯è¡Œè·¯å¾„ï¼Œå…·æœ‰é‡è¦çš„åº”ç”¨å‰æ™¯ã€‚

</details>

---

### 8. [Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning](https://arxiv.org/abs/2601.00400)

**Authors**: Weng Ding, Yi Han, Mu-Jiang-Shan Wang  
**Category**: cs.AI  
**Published**: 2026-01-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.00400v1  

#### Abstract
Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations sys...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ç¤¾äº¤åª’ä½“ä¸Šçš„**åè°ƒæ€§è™šå‡è¡Œä¸ºæ£€æµ‹**ï¼ˆcoordinated inauthentic behaviorï¼‰é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- å¤šæ•°æ–¹æ³•ä¾èµ–è¡¨é¢çš„**ç›¸å…³æ€§åˆ†æ**ï¼ˆcorrelation-basedï¼‰ï¼Œéš¾ä»¥åŒºåˆ†çœŸå®å› æœå…³ç³»ä¸ä¼ªç›¸å…³ï¼›
- æ¨¡å‹å‚æ•°ä¸ºé™æ€é…ç½®ï¼Œç¼ºä¹å¯¹å¤šæ ·åŒ–ã€åŠ¨æ€å˜åŒ–çš„åè°ƒç­–ç•¥çš„é€‚åº”èƒ½åŠ›ï¼›
- é«˜åº¦ä¾èµ–äººå·¥æ ‡æ³¨ï¼Œå¯¼è‡´éƒ¨ç½²æˆæœ¬é«˜ã€æ•ˆç‡ä½ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šACCDæ¡†æ¶
æœ¬æ–‡æå‡º **Adaptive Causal Coordination Detection (ACCD)** æ¡†æ¶ï¼Œä¸€ä¸ªä¸‰é˜¶æ®µã€è®°å¿†å¼•å¯¼çš„è‡ªé€‚åº”ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰è‡ªé€‚åº”å› æœåè°ƒæ£€æµ‹å™¨ï¼ˆAdaptive Causal Coordination Detectorï¼‰
- å¼•å…¥**è‡ªé€‚åº”Convergent Cross Mapping (CCM)** æŠ€æœ¯ï¼Œé€šè¿‡å†å²æ€§èƒ½åŠ¨æ€é€‰æ‹©æœ€ä¼˜åµŒå…¥ç»´åº¦ $E$ å’Œæ—¶é—´å»¶è¿Ÿ $T$ã€‚
- åˆ©ç”¨**é•¿æœŸè®°å¿†æ¨¡å—**ï¼ˆlong-term memoryï¼‰å­˜å‚¨ä¸åŒä¸Šä¸‹æ–‡ä¸‹çš„å‚æ•°è¡¨ç°ï¼Œå®ç°è·¨åœºæ™¯çš„çŸ¥è¯†è¿ç§»ä¸å¤ç”¨ã€‚

#### ï¼ˆ2ï¼‰åŠç›‘ç£ç”¨æˆ·åˆ†ç±»å™¨ï¼ˆSemi-Supervised User Classifierï¼‰
- ç»“åˆ**ä¸»åŠ¨å­¦ä¹ **ï¼ˆactive learningï¼‰ä¸ä¸ç¡®å®šæ€§é‡‡æ ·ï¼Œä¼˜å…ˆæ ‡æ³¨æ¨¡å‹æœ€ä¸ç¡®å®šçš„æ ·æœ¬ï¼Œæ˜¾è‘—å‡å°‘äººå·¥å¹²é¢„ã€‚
- é‡‡ç”¨**è¯¾ç¨‹å­¦ä¹ **ï¼ˆcurriculum learningï¼‰æœºåˆ¶ï¼Œä»æ˜“åˆ°éš¾é€æ­¥è®­ç»ƒï¼Œå¹¶åˆ©ç”¨é«˜ç½®ä¿¡åº¦é¢„æµ‹ç”Ÿæˆ**ä¼ªæ ‡ç­¾**ï¼ˆpseudo-labelsï¼‰ä»¥è¿›ä¸€æ­¥é™ä½æ ‡æ³¨éœ€æ±‚ã€‚

#### ï¼ˆ3ï¼‰è‡ªåŠ¨åŒ–å› æœéªŒè¯å™¨ï¼ˆAdaptive Causal Validatorï¼‰
- åŸºäºå†å²æ£€æµ‹ç»éªŒè‡ªåŠ¨è°ƒæ•´é˜ˆå€¼å’Œæ¨¡å‹é€‰æ‹©ï¼Œæ— éœ€ä¸“å®¶æ‰‹åŠ¨è°ƒå‚ã€‚
- ä½¿ç”¨å¤šç›®æ ‡è¯„åˆ†å‡½æ•°ç»¼åˆè¯„ä¼°å¤šç§å› æœæ¨æ–­æ¨¡å‹ï¼ˆå¦‚Generalized Synthetic Control, CausalForestDML, GANITEï¼‰ï¼Œå¹¶é€šè¿‡**åäº‹å®æ£€éªŒ**ï¼ˆrefutation testsï¼‰æå‡ç»“æœå¯ä¿¡åº¦ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ACCDä¼˜åŠ¿ |
|------|---------|
| **å‡†ç¡®æ€§** | æ˜¾è‘—æå‡F1-scoreï¼Œå‡å°‘è¯¯æŠ¥ä¸æ¼æŠ¥ |
| **æ•ˆç‡** | é€šè¿‡åˆ†å±‚èšç±»ä¼˜åŒ–è®¡ç®—å¤æ‚åº¦ï¼Œå®ç°2.8Ã—åŠ é€Ÿ |
| **è‡ªåŠ¨åŒ–ç¨‹åº¦** | å‡å°‘68%ä»¥ä¸Šçš„äººå·¥æ ‡æ³¨ï¼Œæ”¯æŒç«¯åˆ°ç«¯è¿è¡Œ |
| **å¯æ‰©å±•æ€§** | è‡ªé€‚åº”æœºåˆ¶é€‚ç”¨äºå¤šæ ·åŒ–çš„ç¤¾äº¤å¹³å°ä¸åè°ƒæ¨¡å¼ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | æè¿° |
|-------|------|
| **Twitter IRA dataset** | åŒ…å«2,832ä¸ªå·²çŸ¥å‚ä¸å½±å“æ“ä½œçš„è´¦å·å‘å¸ƒçš„290ä¸‡æ¡æ¨æ–‡ï¼Œç”¨äºæ£€æµ‹åè°ƒæ”»å‡» |
| **Reddit coordination traces** | æ¥è‡ªPushshiftæ•°æ®é›†çš„çœŸå®è®ºå›åè°ƒè¡Œä¸ºç—•è¿¹ |
| **TwiBot-20 benchmark** | å¹¿æ³›ä½¿ç”¨çš„Twitteræœºå™¨äººæ£€æµ‹åŸºå‡†ï¼Œç”¨äºè¯„ä¼°é€šç”¨æ€§ |

### å®éªŒè®¾ç½®
- **å®ç°ç¯å¢ƒ**ï¼šPyTorch 2.0.0 + scikit-learn 1.3.0ï¼ŒNVIDIA A100 GPU
- **è®­ç»ƒé…ç½®**ï¼š100 epochsï¼Œbatch size=64ï¼Œlearning rate=0.001ï¼ŒCosineAnnealingWarmRestartsè°ƒåº¦å™¨
- **äº¤å‰éªŒè¯**ï¼šåˆ†å±‚äº”æŠ˜æ—¶åºåˆ’åˆ†ï¼ˆtemporal splittingï¼‰ï¼Œé˜²æ­¢æ—¶é—´æ³„éœ²

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Precision, Recall, F1-score** | åè°ƒè¡Œä¸ºè¯†åˆ«æ€§èƒ½ |
| **Processing Time / Convergence Epochs** | è®¡ç®—æ•ˆç‡ |
| **Memory Usage** | èµ„æºæ¶ˆè€— |
| **Manual Labeling Reduction** | æ ‡æ³¨æˆæœ¬èŠ‚çœæ¯”ä¾‹ |

### å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
| æ–¹æ³• | ç±»å‹ |
|------|------|
| **CCM [7]** | å› æœæ¨æ–­æ–¹æ³•ï¼ŒåŸºäºæ—¶é—´åºåˆ—äº¤å‰æ˜ å°„ |
| **Correlation-based** | ç®€å•ç›¸å…³æ€§åˆ†æ |
| **LCN+HCC [11]** | åŸºäºæ½œåœ¨åè°ƒç½‘ç»œä¸é«˜åº¦åè°ƒç¤¾åŒº |
| **AMDN-HAGE [16]** | åŸºäºTemporal Point Processesä¸GMMçš„è”åˆå»ºæ¨¡ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTwitter IRA æ•°æ®é›†ï¼‰

| æ–¹æ³• | Precision | Recall | **F1-score** | æ—¶é—´ï¼ˆminï¼‰ |
|------|-----------|--------|--------------|-------------|
| CCM | 72.1% | 79.8% | 75.8% | 181.3 |
| Correlation | 69.3% | 78.1% | 73.5% | 122.5 |
| LCN+HCC | 74.5% | 76.2% | 75.3% | 96.7 |
| AMDN-HAGE | 68.9% | 82.4% | 75.1% | 211.4 |
| **ACCD (Ours)** | **85.6%** | **89.2%** | **87.3%** | **72** |

> âœ… **F1-scoreæå‡15.2ä¸ªç™¾åˆ†ç‚¹**ï¼ˆä»75.8% â†’ 87.3%ï¼‰

### è®¡ç®—æ•ˆç‡å¯¹æ¯”

| æ–¹æ³• | æ”¶æ•›epochæ•° | å†…å­˜å ç”¨ | ç›¸å¯¹é€Ÿåº¦ | å‡†ç¡®ç‡ |
|------|--------------|----------|------------|--------|
| CCM | 65 | 8.2 GB | 1.0Ã— | 100% |
| Fixed Param | 58 | 7.9 GB | 1.1Ã— | 98.3% |
| **ACCD (Ours)** | **40** | **4.5 GB** | **2.8Ã—** | **96.7%** |

> âš¡ **è®­ç»ƒé€Ÿåº¦å¿«2.8å€ï¼Œå†…å­˜å‡å°‘è¿‘ä¸€åŠ**

### å…¶ä»–æ•°æ®é›†è¡¨ç°
- **Redditæ•°æ®é›†**ï¼šF1-scoreè¾¾ **84.7%**ï¼ˆä¼ ç»Ÿæ–¹æ³•ä»…71.2%ï¼‰
- **TwiBot-20**ï¼šåˆ†ç±»å‡†ç¡®ç‡è¾¾ **88.9%**
- æ‰‹åŠ¨æ ‡æ³¨éœ€æ±‚å‡å°‘ **68.3%**

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

![Ablation Study](Figure 6)

| æ¨¡å‹å˜ä½“ | F1-score | åˆ†ç±»å‡†ç¡®ç‡ | éªŒè¯å‡†ç¡®ç‡ |
|---------|----------|------------|------------|
| Full Model (ACCD) | **91.2%** | **88.9%** | **87.3%** |
| w/o Adaptive Params | 85.9% | 88.9% | 84.7% |
| w/o Active Learning | 87.6% | 82.1% | 88.9% |
| w/o Adaptive Validation | 85.2% | 88.9% | 84.7% |

> ğŸ” ç»“æœè¡¨æ˜ï¼šä¸‰ä¸ªç»„ä»¶å‡ä¸å¯æˆ–ç¼ºï¼Œå…¶ä¸­**è‡ªé€‚åº”å‚æ•°é€‰æ‹©**å¯¹æ€§èƒ½å½±å“æœ€å¤§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å› æœå…³ç³»ä¼˜äºç›¸å…³æ€§**ï¼šACCDé€šè¿‡è‡ªé€‚åº”CCMæœ‰æ•ˆè¯†åˆ«çœŸå®å› æœå½±å“ï¼Œé¿å…ä¼ªç›¸å…³å¹²æ‰°ã€‚
2. **è®°å¿†æœºåˆ¶æå‡æ³›åŒ–èƒ½åŠ›**ï¼šé•¿æœŸè®°å¿†æ¨¡å—ä½¿æ¨¡å‹èƒ½åœ¨æ–°åœºæ™¯ä¸­å¿«é€Ÿæ”¶æ•›å¹¶å¤ç”¨å†å²æœ€ä¼˜é…ç½®ã€‚
3. **åŠç›‘ç£ç­–ç•¥å¤§å¹…é™æœ¬å¢æ•ˆ**ï¼šç»“åˆä¸»åŠ¨å­¦ä¹ ä¸ä¼ªæ ‡ç­¾æœºåˆ¶ï¼Œåœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶å°†äººå·¥æ ‡æ³¨å‡å°‘è¿‘70%ã€‚
4. **è‡ªåŠ¨åŒ–éªŒè¯å¢å¼ºé²æ£’æ€§**ï¼šåŸºäºå†å²æˆåŠŸç‡åŠ¨æ€è°ƒæ•´é˜ˆå€¼ï¼Œæå‡äº†åœ¨å¼‚æ„æ•°æ®ä¸Šçš„ç¨³å®šæ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¡†æ¶å‡è®¾ç”¨æˆ·æ´»åŠ¨å…·æœ‰è¶³å¤Ÿçš„æ—¶é—´åˆ†è¾¨ç‡ï¼ˆtimestampsï¼‰ï¼Œå¯¹äºä½é¢‘å‘å¸ƒè€…å¯èƒ½æ•ˆæœå—é™ï¼›
- èšç±»ç­–ç•¥è™½æå‡æ•ˆç‡ï¼Œä½†åœ¨æç«¯ç¨€ç–æˆ–é«˜åº¦é‡å çš„åè°ƒå­å›¾ä¸­å¯èƒ½å­˜åœ¨ä¿¡å·ä¸¢å¤±ï¼›
- å¤šæ¨¡å‹é›†æˆå¸¦æ¥é¢å¤–è®¡ç®—å¼€é”€ï¼Œå°½ç®¡æ€»ä½“ä»ä¼˜äºåŸºçº¿ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°†ACCDæ‰©å±•è‡³å¤šè¯­è¨€ã€è·¨å¹³å°ï¼ˆå¦‚å¾®åšã€Facebookï¼‰åœºæ™¯ï¼›
- æ¢ç´¢åœ¨çº¿å­¦ä¹ æœºåˆ¶ï¼Œå®ç°å®æ—¶å¢é‡æ›´æ–°ï¼›
- ç»“åˆLLMè¿›è¡Œè¯­ä¹‰çº§åè°ƒå†…å®¹åˆ†æï¼Œå¢å¼ºå¯¹â€œè½¯æ€§æ“çºµâ€ï¼ˆsoft manipulationï¼‰çš„æ£€æµ‹èƒ½åŠ›ï¼›
- æ„å»ºå¼€æºå·¥å…·åŒ…ï¼Œæ¨åŠ¨ç¤¾åŒºåä½œä¸æ ‡å‡†åŒ–è¯„æµ‹ã€‚

---

> ğŸ’¡ **æ€»ç»“**ï¼š  
> ACCD æ˜¯é¦–ä¸ªå°†**è‡ªé€‚åº”å› æœæ¨ç†**ã€**åŠç›‘ç£å­¦ä¹ **ä¸**è‡ªåŠ¨åŒ–éªŒè¯**æ·±åº¦èåˆçš„åè°ƒè¡Œä¸ºæ£€æµ‹æ¡†æ¶ã€‚å®ƒä¸ä»…åœ¨å¤šä¸ªçœŸå®æ•°æ®é›†ä¸Šå®ç°äº†SOTAæ€§èƒ½ï¼Œæ›´åœ¨**å‡†ç¡®æ€§ã€æ•ˆç‡ä¸è‡ªåŠ¨åŒ–æ°´å¹³**ä¹‹é—´å–å¾—äº†è‰¯å¥½å¹³è¡¡ï¼Œå…·å¤‡å¼ºå®é™…åº”ç”¨ä»·å€¼ï¼Œä¸ºä¸‹ä¸€ä»£ç¤¾äº¤åª’ä½“å®‰å…¨ç³»ç»Ÿæä¾›äº†å¯æ‰©å±•çš„æŠ€æœ¯èŒƒå¼ã€‚

</details>

---

### 9. [Universal Adaptive Constraint Propagation: Scaling Structured Inference for Large Language Models via Meta-Reinforcement Learning](https://arxiv.org/abs/2601.00095)

**Authors**: Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma  
**Category**: cs.CL  
**Published**: 2026-01-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.00095v1  

#### Abstract
Large language models increasingly require structured inference, from JSON schema enforcement to multi-lingual parsing, where outputs must satisfy complex constraints. We introduce MetaJuLS, a meta-reinforcement learning approach that learns universal constraint propagation policies applicable acros...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šUniversal Adaptive Constraint Propagation: Scaling Structured Inference for Large Language Models via Meta-Reinforcement Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ‰§è¡Œ**ç»“æ„åŒ–æ¨ç†ä»»åŠ¡**æ—¶é¢ä¸´æ•ˆç‡ç“¶é¢ˆï¼Œä¾‹å¦‚ï¼š
- JSON Schema éªŒè¯
- å¤šè¯­è¨€å¥æ³•åˆ†æï¼ˆå¦‚ Universal Dependenciesï¼‰
- å½¢å¼é€»è¾‘ç”Ÿæˆï¼ˆå¦‚ LogicBenchï¼‰

è¿™äº›ä»»åŠ¡è¦æ±‚è¾“å‡ºæ»¡è¶³å¤æ‚çš„è¯­æ³•ã€è¯­ä¹‰æˆ–æ ¼å¼çº¦æŸã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–é™æ€è°ƒåº¦ç­–ç•¥ï¼ˆå¦‚ FIFOï¼‰æˆ–åéªŒéªŒè¯ï¼Œå¯¼è‡´å¤§é‡æ— æ•ˆè®¡ç®—å’Œé«˜å»¶è¿Ÿã€‚æ­¤å¤–ï¼Œä¸åŒè¯­è¨€æˆ–ä»»åŠ¡é€šå¸¸éœ€è¦ç‹¬ç«‹è®­ç»ƒä¸“ç”¨è°ƒåº¦å™¨ï¼Œç¼ºä¹é€šç”¨æ€§å’Œå¿«é€Ÿé€‚åº”èƒ½åŠ›ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **MetaJuLS** â€”â€” ä¸€ç§åŸºäº **Meta-Reinforcement Learning** çš„é€šç”¨è‡ªé€‚åº”çº¦æŸä¼ æ’­æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- å°†ç»“æ„åŒ–æ¨ç†å»ºæ¨¡ä¸º **çº¦æŸä¼ æ’­ï¼ˆConstraint Propagationï¼‰è¿‡ç¨‹**ï¼Œå…¶ä¸­å˜é‡è¡¨ç¤ºè¯­è¨€å•å…ƒï¼ŒåŸŸä¸ºå€™é€‰æ ‡ç­¾ï¼Œçº¦æŸç¼–ç è¯­æ³•è§„åˆ™æˆ–é€»è¾‘æ¡ä»¶ã€‚
- å°†â€œé€‰æ‹©ä¸‹ä¸€ä¸ªè¦ä¼ æ’­çš„çº¦æŸâ€è§†ä¸ºä¸€ä¸ª **åºåˆ—å†³ç­–é—®é¢˜**ï¼Œç”±ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ™ºèƒ½ä½“æ§åˆ¶ã€‚
- ä½¿ç”¨ **Graph Attention Network (GAT)** ç¼–ç çº¦æŸ-å˜é‡å›¾ç»“æ„ï¼Œæ•æ‰é•¿è·ç¦»ä¾èµ–å’Œå¤æ‚äº¤äº’ã€‚
- å¼•å…¥ **Model-Agnostic Meta-Learning (MAML)** è¿›è¡Œå…ƒè®­ç»ƒï¼Œä½¿å•ä¸€ç­–ç•¥èƒ½å¿«é€Ÿè¿ç§»åˆ°æ–°è¯­è¨€ã€æ–°ä»»åŠ¡æˆ–æ–°çº¦æŸç±»å‹ï¼Œä»…éœ€ **5â€“10 ä¸ªæ¢¯åº¦æ­¥ï¼ˆçº¦ 5â€“15 ç§’ï¼‰** è€Œéæ•°å°æ—¶å¾®è°ƒã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | MetaJuLS | ä¼ ç»Ÿæ–¹æ³• |
|------|---------|--------|
| **é€Ÿåº¦** | å®ç° 1.5â€“2.0Ã— åŠ é€Ÿ | ä¾èµ–é™æ€è°ƒåº¦ï¼Œæ•ˆç‡ä½ |
| **å‡†ç¡®æ€§** | ä¿æŒä¸ SOTA è§£æå™¨å·®è· <0.2% F1/LAS | å¯èƒ½å› è¿‡æ—©å‰ªæä¸¢å¤±æ­£ç¡®è§£ |
| **æ³›åŒ–æ€§** | æ”¯æŒè·¨è¯­è¨€ã€è·¨ä»»åŠ¡å¿«é€Ÿè¿ç§»ï¼ˆfew-step adaptationï¼‰ | éœ€ä»»åŠ¡ç‰¹å®šè®­ç»ƒ |
| **ç¯ä¿æ€§ï¼ˆGreen AIï¼‰** | å‡å°‘æ¨ç†æ­¥éª¤ï¼Œé™ä½ç¢³è¶³è¿¹ | æ¨ç†å¼€é”€å¤§ |
| **æœºåˆ¶å¯è§£é‡Šæ€§** | å‘ç°äººç±»ç±»ä¼¼â€œæ˜“å…ˆâ€ç­–ç•¥åŠæ–°é¢–å¯å‘å¼ | æ‰‹å·¥è®¾è®¡å¯å‘å¼ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

| ç±»å‹ | æ•°æ®é›† | æè¿° |
|------|-------|------|
| **å¥æ³•åˆ†æ** | Penn Treebank (PTB) | è‹±æ–‡æˆåˆ†å¥æ³•åˆ†æåŸºå‡† |
| | Universal Dependencies (UD) v2.11 | è·¨ 10 ç§è¯­è¨€çš„ä¾å­˜å¥æ³•åˆ†æï¼ˆè‹±è¯­ã€è¥¿ç­ç‰™è¯­ã€ä¸­æ–‡ç­‰ï¼‰ |
| **LLM ç»“æ„åŒ–ç”Ÿæˆ** | LogicBench | ç”Ÿæˆç¬¦åˆå‰æçš„å½¢å¼é€»è¾‘è¡¨è¾¾å¼ |
| | GSM8K-Constrained | æ•°å­¦é¢˜ç­”æ¡ˆéœ€ç¬¦åˆ JSON Schema |
| **ç»å…¸çº¦æŸç¼–ç¨‹ï¼ˆCPï¼‰** | MiniZinc Challenge (2022â€“2024) | åŒ…æ‹¬ Knapsackã€TSPã€Graph Coloring ç­‰ |
| | XCSP Competition | é«˜éš¾åº¦ CSP å®ä¾‹ |

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°ä»»åŠ¡**
- **Parsing**: Constituency Parsing (F1), Dependency Parsing (LAS)
- **LLM Decoding**: Constraint Satisfaction Rate (%), Generation Speed (ms/sent æˆ– norm. runtime)
- **CP Tasks**: Optimality Gap (%), Solve Rate (%), Normalized Runtime

#### **ç¡¬ä»¶ä¸å®ç°**
- ä½¿ç”¨ Llama-2-7B + vLLM è¿›è¡Œé«˜æ•ˆæœåŠ¡
- MetaJuLS ä½œä¸ºè°ƒåº¦å±‚æ’å…¥è§£ç å¾ªç¯
- æ‰€æœ‰å®éªŒåœ¨ A100 GPU ä¸Šè¿è¡Œï¼ŒæŠ¥å‘Šä¸­ä½æ•°ï¼ˆ5 æ¬¡è¿è¡Œï¼‰

#### **å¯¹æ¯”åŸºçº¿æ–¹æ³•**
| åŸºçº¿ç±»åˆ« | å…·ä½“æ–¹æ³• |
|--------|--------|
| **é™æ€/å¯å‘å¼è°ƒåº¦** | FIFO, Random, dom/wdeg, Activity-Based, VSIDS-style |
| **æˆæœ¬æ„ŸçŸ¥è´ªå¿ƒ** | Cost-Normalized Greedy (æœ€å¤§åŒ– Î”D/T) |
| **ç›‘ç£å­¦ä¹ ** | Supervised Rankingï¼ˆæ¨¡ä»¿æœ€ä¼˜ä¼˜å…ˆç­–ç•¥ï¼‰ |
| **å…¶ä»– LLM çº¦æŸè§£ç å·¥å…·** | Outlines, LMQL, NeuroLogic Decoding |
| **ä¼˜åŒ–æ±‚è§£å™¨** | Google OR-Tools, JuLS (FIFO baseline) |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

| ä»»åŠ¡ | æ–¹æ³• | æ€§èƒ½æŒ‡æ ‡ | æå‡ |
|------|------|----------|------|
| **PTB æˆåˆ†å¥æ³•åˆ†æ** | MetaJuLS vs GPU-CKY | 1.6â€“1.9Ã— é€Ÿåº¦æå‡ï¼ŒF1 å·®è· <0.2% | âœ… æ˜¾è‘—åŠ é€Ÿ |
| **UD å¤šè¯­è¨€ä¾å­˜åˆ†æ** | MetaJuLS (è‹±æ–‡è®­ç»ƒ + å¿«é€Ÿé€‚é…) | å¹³å‡ 1.5â€“1.8Ã— åŠ é€Ÿï¼ŒLAS æ¥è¿‘ UDPipe/Stanza | âœ… è·¨è¯­è¨€è¿ç§»æˆåŠŸ |
| **LogicBench (LLM)** | MetaJuLS vs Speculative Decoding | 1.8Ã— æ›´å¿«ï¼Œçº¦æŸæ»¡è¶³ç‡ä» 94.1% â†’ 98.2% | âœ… æ›´å‡†æ›´å¿« |
| **GSM8K-Constrained** | MetaJuLS vs Speculative Decoding | 1.6Ã— åŠ é€Ÿï¼ŒSchema Compliance ä» 91.3% â†’ 96.8% | âœ… æ˜¾è‘—æ”¹è¿› |
| **MiniZinc CP åŸºå‡†** | MetaJuLS vs OR-Tools | 22% æ›´å°æœ€ä¼˜æ€§å·®è·ï¼Œ63% è¿è¡Œæ—¶é—´ï¼Œ94% æ±‚è§£ç‡ | âœ… è¶…è¶Šä¸“ä¸šæ±‚è§£å™¨ |

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### âœ… åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºå„ç±»åŸºçº¿ï¼š
- **æ¯” Activity-Based / VSIDS-style å¿« 1.5Ã— ä»¥ä¸Š**
- **æ¯” Cost-Normalized Greedy å¿« 1.2â€“1.5Ã—ï¼ŒåŒæ—¶æ›´å‡†ç¡®**
- **ä¼˜äº Supervised Ranking**ï¼Œè¯´æ˜ RL å­¦ä¹ ä¼˜äºæ¨¡ä»¿å­¦ä¹ 
- **ç»“åˆ speculative decoding åä»å¸¦æ¥é¢å¤– 15% åŠ é€Ÿ**ï¼Œè¯æ˜æ­£äº¤æ€§

#### ğŸ”„ åŒå‘è¿ç§»èƒ½åŠ›éªŒè¯ï¼š
- NLP è®­ç»ƒçš„ç­–ç•¥ç”¨äº CP ä»»åŠ¡ â†’ è¾¾åˆ° specialist çš„ **91% æ€§èƒ½**
- CP è®­ç»ƒçš„ç­–ç•¥ç”¨äº NLP è§£æ â†’ è¾¾åˆ° specialist çš„ **89% æ€§èƒ½**
- è¡¨æ˜ MetaJuLS å­¦åˆ°äº†**é¢†åŸŸæ— å…³çš„ä¼ æ’­ç»“æ„è§„å¾‹**

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰**

| æ¶ˆèé¡¹ | F1 / Gap | æ—¶é—´ / Runtime | ç»“è®º |
|--------|--------|----------------|------|
| **ç§»é™¤ GATï¼ˆæ”¹ç”¨ MLPï¼‰** | â†“ ~0.4 F1 | â†‘ ~10% æ—¶é—´ | å›¾ç»“æ„å»ºæ¨¡è‡³å…³é‡è¦ |
| **ç§»é™¤æˆæœ¬é¡¹ï¼ˆÎ²=0ï¼‰** | F1 ç•¥é™ | æ—¶é—´å¢åŠ  | æˆæœ¬æ„ŸçŸ¥å¥–åŠ±é˜²æ­¢è¿‡åº¦æ¢ç´¢ |
| **éšæœºç­–ç•¥** | F1 æ˜¾è‘—ä¸‹é™ | æ—¶é—´å¤§å¹…ä¸Šå‡ | å­¦ä¹ å¿…è¦ |
| **ç›‘ç£æ¨¡ä»¿å­¦ä¹ ** | ä¸åŠ RL | ä¸åŠ RL | RL èƒ½å‘ç°è¶…è¶Šå±€éƒ¨æœ€ä¼˜çš„é•¿æœŸç­–ç•¥ |

> è¡¨æ ¼æ¥æºï¼šTable 10ï¼ˆPTB æ¶ˆèï¼‰ã€Table 11ï¼ˆMiniZinc æ¶ˆèï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. ğŸ” **ä¼ æ’­é¡ºåºæ˜¯ç»“æ„åŒ–æ¨ç†çš„å…³é”®æ•ˆç‡æ æ†**  
   å³ä½¿åœ¨ GPU ä¼˜åŒ–çš„ CKY ä¸­ï¼Œé€šè¿‡æ™ºèƒ½è°ƒåº¦ä¹Ÿèƒ½å®ç° 1.5â€“2.0Ã— åŠ é€Ÿï¼Œè¯´æ˜ç®—æ³•å±‚é¢ä»æœ‰å·¨å¤§ä¼˜åŒ–ç©ºé—´ã€‚

2. ğŸ¤– **MetaJuLS å‘ç°äº†äººç±»å¯å‘å¼ä¹‹å¤–çš„æ–°é¢–ç­–ç•¥**
   - â€œEasy-firstâ€ï¼šä¼˜å…ˆå¤„ç†æµ…å±‚ã€é«˜ç½®ä¿¡åº¦çš„ç»“æ„
   - â€œMiddle-outâ€ï¼šå¯¹åµŒå¥—ç›¸å¯¹ä»å¥ï¼Œä»ä¸­ç­‰æ·±åº¦å¼€å§‹å»ºç«‹é”šç‚¹ï¼Œå‡å°‘å›æº¯ 34%
   - å»¶è¿ŸèŠ±å›­è·¯å¾„åŒºåŸŸçš„ä¼ æ’­ï¼Œç›´åˆ°ä¸Šä¸‹æ–‡å……åˆ†

3. âš¡ **Few-step Adaptation å®ç°ç§’çº§è¿ç§»**
   - ä¸€ä¸ªåœ¨è‹±æ–‡ä¸Šè®­ç»ƒçš„ç­–ç•¥ï¼Œç»è¿‡ **5â€“10 æ­¥æ¢¯åº¦æ›´æ–°ï¼ˆ5â€“15 ç§’ï¼‰** å³å¯åœ¨æ–°è¯­è¨€æˆ–æ–°ä»»åŠ¡ä¸Šè¾¾åˆ° 85â€“92% çš„ä¸“å®¶æ°´å¹³
   - æ”¯æŒé›¶æ ·æœ¬æˆ–æä½èµ„æºåœºæ™¯ä¸‹çš„å¿«é€Ÿéƒ¨ç½²

4. ğŸ›¡ï¸ **å®‰å…¨æ„ŸçŸ¥å›é€€æœºåˆ¶ä¿éšœç²¾åº¦**
   - å½“ç­–ç•¥ç†µå€¼è¿‡é«˜ï¼ˆä¸ç¡®å®šæ€§å¤§ï¼‰æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢è‡³ exhaustive search
   - å°† F1 å·®è·ä» 2.1% ç¼©å°è‡³ **0.15%**ï¼ŒåŒæ—¶ç»´æŒ **1.4Ã— å¹³å‡åŠ é€Ÿ**

5. ğŸŒ **çœŸæ­£çš„è·¨é¢†åŸŸé€šç”¨æ€§**
   - åœ¨ NLP å’Œ CP ä¹‹é—´å®ç°äº†åŒå‘è¿ç§»
   - è¯æ˜ MetaJuLS å­¦åˆ°äº†**é€šç”¨çš„çº¦æŸä¼ æ’­æ‹“æ‰‘æ¨¡å¼**ï¼Œè€Œéè¯­è¨€åè§

---

### **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™ | è¯´æ˜ |
|------|------|
| **å¯¹æ­§ä¹‰ä¸¥é‡çš„å¥å­è¡¨ç°ä¸‹é™** | å¦‚ garden-path å¥å­ï¼ˆ"The horse raced past the barn fell"ï¼‰ï¼Œæ—©æœŸå‰ªæå¯èƒ½è¯¯åˆ æ­£ç¡®åˆ†æ |
| **å½¢æ€ä¸°å¯Œè¯­è¨€æœªå……åˆ†æµ‹è¯•** | å®éªŒé›†ä¸­äºè‹±è¯­å’Œå…¶ä»–ä¸»æµè¯­è¨€ï¼Œå¯¹é˜¿æ‹‰ä¼¯è¯­ã€èŠ¬å…°è¯­ç­‰æŒ‘æˆ˜è¾ƒå¤§ |
| **ä¾èµ–æ‰‹åŠ¨å®šä¹‰çº¦æŸç³»ç»Ÿ** | å°†æ–°ä»»åŠ¡è½¬åŒ–ä¸º constraint propagation éœ€äººå·¥å»ºæ¨¡å˜é‡ã€åŸŸã€çº¦æŸ |
| **å…ƒè®­ç»ƒæˆæœ¬è¾ƒé«˜** | ä¸€æ¬¡æ€§éœ€ 120 GPU-hoursï¼ˆ8Ã—A100ï¼‰ï¼Œè™½æ”¯æŒåç»­å¿«é€Ÿé€‚é…ï¼Œä½†åˆå§‹æŠ•å…¥å¤§ |
| **ç¡®å®šæ€§å‡è®¾é™åˆ¶** | å½“å‰å‡è®¾ propagator æ˜¯ç¡®å®šæ€§çš„ï¼Œéš¾ä»¥åº”å¯¹éšæœºæˆ–è¿‘ä¼¼ä¼ æ’­ |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **è‡ªåŠ¨åŒ–ä»»åŠ¡å»ºæ¨¡æ¥å£**  
   å¼€å‘è‡ªåŠ¨å°†è‡ªç„¶è¯­è¨€ä»»åŠ¡æ˜ å°„ä¸º constraint propagation å½¢å¼çš„å·¥å…·é“¾ã€‚

2. **æ‰©å±•è‡³ä¸ç¡®å®šæ€§ç¯å¢ƒ**  
   æ”¯æŒ stochastic æˆ– approximate propagatorsï¼Œå¢å¼ºé²æ£’æ€§ã€‚

3. **ç†è®ºåˆ†æå¿«é€Ÿé€‚åº”æœºåˆ¶**  
   æ¢ç´¢ä¸ºä½• MAML èƒ½åœ¨å¦‚æ­¤çŸ­çš„å‡ æ­¥å†…å®ç°æœ‰æ•ˆè¿ç§»ã€‚

4. **é›†æˆåˆ°æ›´å¤š LLM æ¨ç†æ¡†æ¶**  
   å¦‚é›†æˆè¿› HuggingFace Transformersã€vLLMã€TensorRT-LLM ç­‰ä¸»æµç³»ç»Ÿã€‚

5. **æ¢ç´¢å…¶ä»–æ±‚è§£å™¨ç»„ä»¶çš„å­¦ä¹ **  
   å¦‚å˜é‡é€‰æ‹©ã€å€¼é€‰æ‹©ã€é‡å¯ç­–ç•¥ç­‰ï¼Œæ„å»ºå…¨å­¦ä¹ å‹æ±‚è§£å™¨ã€‚

---

> **Impact Statementï¼ˆå½±å“å£°æ˜ï¼‰**  
> MetaJuLS é€šè¿‡å‡å°‘ 1.5â€“2.0Ã— çš„æ¨ç†æ­¥éª¤ï¼Œç›´æ¥é™ä½äº† LLM éƒ¨ç½²çš„èƒ½è€—å’Œç¢³æ’æ”¾ï¼Œæ¨åŠ¨ **Green AI** å‘å±•ã€‚å¯¹äºæ¯æ—¥å¤„ç†ç™¾ä¸‡çº§ç»“æ„åŒ–è¯·æ±‚çš„æœåŠ¡ï¼Œå¹´èŠ‚ç”µå¯è¾¾ **2.4 MWh** ä»¥ä¸Šã€‚åŒæ—¶ï¼Œå…ƒå­¦ä¹ é¿å…äº†é‡å¤è®­ç»ƒï¼Œè¿›ä¸€æ­¥å‡å°‘ç¯å¢ƒè´Ÿæ‹…ã€‚

</details>

---

### 10. [Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment](https://arxiv.org/abs/2601.00444)

**Authors**: Muhammad Shahmeer Khan  
**Category**: cs.CL  
**Published**: 2026-01-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.00444v1  

#### Abstract
In the rapidly evolving landscape of enterprise natural language processing (NLP), the demand for efficient, lightweight models capable of handling multi-domain text automation tasks has intensified. This study conducts a comparative analysis of three prominent lightweight Transformer models - Disti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥ç ”ç©¶é’ˆå¯¹**ä¼ä¸šçº§è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆEnterprise NLPï¼‰éƒ¨ç½²ä¸­è½»é‡çº§ Transformer æ¨¡å‹é€‰æ‹©ç¼ºä¹ç³»ç»Ÿæ€§å®è¯åŸºå‡†**çš„é—®é¢˜ã€‚å°½ç®¡å·²æœ‰å¤§é‡å…³äºå¤§å‹æ¨¡å‹ï¼ˆå¦‚ BERTã€RoBERTaï¼‰çš„ç ”ç©¶ï¼Œä½†åœ¨èµ„æºå—é™åœºæ™¯ä¸‹ï¼Œå¦‚ä½•åœ¨å¤šé¢†åŸŸä»»åŠ¡ä¸­æƒè¡¡ **accuracyï¼ˆå‡†ç¡®æ€§ï¼‰ä¸ efficiencyï¼ˆæ•ˆç‡ï¼‰** ä»ç¼ºä¹å…¨é¢æ¯”è¾ƒã€‚

å…·ä½“è€Œè¨€ï¼Œä¼ä¸šåœ¨å®é™…éƒ¨ç½²ä¸­é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- é«˜å»¶è¿Ÿå½±å“ç”¨æˆ·ä½“éªŒ
- å†…å­˜å ç”¨å¤§å¯¼è‡´è¾¹ç¼˜è®¾å¤‡éš¾ä»¥è¿è¡Œ
- å¤šæ ·åŒ–æ–‡æœ¬åŸŸï¼ˆå¦‚å®¢æˆ·è¯„è®ºã€æ–°é—»ã€æœ‰å®³å†…å®¹ï¼‰è¦æ±‚æ¨¡å‹å…·å¤‡è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›

ç°æœ‰ç ”ç©¶å¾€å¾€åªå…³æ³¨å•ä¸€ä»»åŠ¡æˆ–ä»…è¯„ä¼°ç²¾åº¦ï¼Œå¿½ç•¥äº†æ¨ç†é€Ÿåº¦ã€ååé‡ç­‰å…³é”®éƒ¨ç½²æŒ‡æ ‡ã€‚

---

### ğŸ†• æå‡ºçš„æ–°æ–¹æ³•/æ–°æ€è·¯
æœ¬ç ”ç©¶å¹¶æœªæå‡ºæ–°çš„æ¨¡å‹æ¶æ„æˆ–è®­ç»ƒç®—æ³•ï¼Œè€Œæ˜¯æå‡ºäº†ä¸€ä¸ª**é¢å‘ä¼ä¸šéƒ¨ç½²çš„å¤šé¢†åŸŸè½»é‡çº§ Transformer æ¨¡å‹å®è¯åŸºå‡†æ¡†æ¶**ï¼Œå…¶åˆ›æ–°ç‚¹åœ¨äºï¼š

1. **å¤šé¢†åŸŸç»Ÿä¸€è¯„ä¼°**  
   åœ¨ä¸‰ä¸ªå…¸å‹ä¼ä¸šåº”ç”¨åœºæ™¯ï¼ˆcustomer sentimentã€news topic classificationã€toxicity detectionï¼‰ä¸Šè¿›è¡Œæ¨ªå‘å¯¹æ¯”ï¼Œå¢å¼ºç°å®é€‚ç”¨æ€§ã€‚

2. **èåˆ accuracy ä¸ efficiency çš„ç»¼åˆè¯„ä¼°ä½“ç³»**  
   ä¸ä»…æŠ¥å‘Š Accuracyã€F1-score ç­‰ä¼ ç»ŸæŒ‡æ ‡ï¼Œè¿˜å¼•å…¥ï¼š
   - Model sizeï¼ˆMBï¼‰
   - Inference timeï¼ˆms/sampleï¼‰
   - Throughputï¼ˆsamples/secï¼‰
   - RAM usage
   å®ç°å¯¹â€œç²¾åº¦ vs æ•ˆç‡â€æƒè¡¡çš„å¯è§†åŒ–åˆ†æã€‚

3. **æ ‡å‡†åŒ– fine-tuning åè®®**  
   æ‰€æœ‰æ¨¡å‹é‡‡ç”¨ç›¸åŒçš„è¶…å‚æ•°è®¾ç½®ï¼ˆlearning rate=2e-5, batch size=16, epochs=3ï¼‰ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒï¼Œåæ˜ çœŸå®ä¼ä¸šå¿«é€Ÿå¾®è°ƒåœºæ™¯ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **å®ç”¨æ€§** | èšç„¦ä¼ä¸šéƒ¨ç½²ç—›ç‚¹ï¼ˆä½å»¶è¿Ÿã€å°å†…å­˜ã€é«˜ååï¼‰ï¼Œè€Œéè¿½æ±‚æè‡´ç²¾åº¦ |
| **å¯å¤ç°æ€§** | å…¬å¼€ä»£ç ä¸å®Œæ•´å®éªŒé…ç½®ï¼ˆGitHub: `shahmeer07/enterprise-nlp-lightweight-transformer-benchmark`ï¼‰ |
| **å†³ç­–æŒ‡å¯¼æ€§** | æä¾›æ˜ç¡®çš„é€‰å‹å»ºè®®ï¼Œå¸®åŠ©å¼€å‘è€…æ ¹æ®ä¸šåŠ¡éœ€æ±‚é€‰æ‹©æœ€ä¼˜æ¨¡å‹ |

> âš ï¸ æ³¨æ„ï¼šæœ¬å·¥ä½œä¸è¿½æ±‚ SOTA æ€§èƒ½ï¼Œè€Œæ˜¯æä¾›**éƒ¨ç½²å¯¼å‘çš„å†³ç­–æ”¯æŒå·¥å…·**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | ä»»åŠ¡ç±»å‹ | ç±»åˆ«æ•° | è®­ç»ƒ/æµ‹è¯•æ ·æœ¬æ•° | æ¥æº |
|--------|---------|-------|------------------|------|
| **IMDB** | Customer Sentiment Classification | 2ï¼ˆpositive/negativeï¼‰ | 25K / 25K | æ ‡å‡†æƒ…æ„Ÿåˆ†ææ•°æ®é›† |
| **AG News** | News Topic Classification | 4ï¼ˆWorld, Sports, Business, Sci/Techï¼‰ | 120K / 7.6K | æ–°é—»åˆ†ç±»åŸºå‡† |
| **Measuring Hate Speech Corpus** | Toxicity/Hate Speech Detection | 3ï¼ˆNeutral, Offensive, Hate Speechï¼‰ | 80%/20% åˆ†å‰² | å†…å®¹å®¡æ ¸æ•°æ®é›†ï¼Œé€šè¿‡è¿ç»­å¾—åˆ†ç¦»æ•£åŒ–æ„å»ºæ ‡ç­¾ |

---

### âš™ï¸ å®éªŒè®¾ç½®
- **å¹³å°ç¯å¢ƒ**ï¼šGoogle Colab + å•å¼  NVIDIA T4 GPU
- **å®ç°åº“**ï¼šHugging Face Transformers & Datasets
- **Tokenizer**ï¼šå„æ¨¡å‹å¯¹åº” tokenizerï¼ˆmax_length=128ï¼‰
- **å¾®è°ƒç­–ç•¥**ï¼šLinear classification head + AdamW optimizer
- **å›ºå®šè¶…å‚æ•°**ï¼š
  - Learning rate: 2Ã—10â»âµ
  - Epochs: 3
  - Batch size: 16
  - Weight decay: 0.01
  - Random seed: 42ï¼ˆä¿è¯å¯å¤ç°ï¼‰

> æ‰€æœ‰æ¨¡å‹ç‹¬ç«‹å¾®è°ƒï¼Œæ— è¶…å‚æœç´¢ï¼Œæ¨¡æ‹Ÿä¼ä¸šå¿«é€Ÿä¸Šçº¿åœºæ™¯ã€‚

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

#### Accuracy-based Metrics
- **Accuracy**
- **Weighted Precision, Recall, F1-score**ï¼ˆåº”å¯¹ç±»åˆ«ä¸å¹³è¡¡ï¼‰
- **Confusion Matrices**ï¼ˆé™„å½•æä¾›ï¼‰

#### Efficiency Metrics
| æŒ‡æ ‡ | æµ‹é‡æ–¹å¼ |
|------|--------|
| **Model Size (MB)** | å‚æ•°æ•°é‡ Ã— 4 bytesï¼ˆFP32ï¼‰ |
| **Inference Time (ms/sample)** | å¯¹ 200 ä¸ªæ ·æœ¬æµ‹å¹³å‡ wall-clock æ—¶é—´ï¼ˆbatch_size=1ï¼‰ |
| **Throughput (samples/sec)** | æ€»æ ·æœ¬æ•° Ã· æ€»æ¨ç†æ—¶é—´ |
| **RAM Usage (MB)** | Python è¿›ç¨‹é©»ç•™å†…å­˜ï¼ˆå«æ¡†æ¶å¼€é”€ï¼‰ |

> æ‰€æœ‰æ•ˆç‡æµ‹é‡å‡åœ¨ `torch.no_grad()` ä¸‹å®Œæˆï¼Œå¹¶ç»è¿‡ warm-up é˜¶æ®µä»¥æ¶ˆé™¤ç¼“å­˜å½±å“ã€‚

---

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
å¯¹æ¯”ä¸‰ç§ä¸»æµè½»é‡çº§ Transformer æ¨¡å‹ï¼š
| æ¨¡å‹ | å‚æ•°é‡ | ç‰¹ç‚¹ |
|------|--------|------|
| **DistilBERT** | ~66M | Knowledge distillation from BERTï¼Œä¿ç•™ 97% æ€§èƒ½ï¼Œæ¨ç†å¿« 40% |
| **MiniLM** | ~33M | Deep self-attention distillationï¼Œå‹ç¼©æ³¨æ„åŠ›å…³ç³»ï¼Œæ“…é•¿é«˜é€Ÿæ¨ç† |
| **ALBERT** | ~12M | Parameter sharing + factorized embeddingï¼Œæå°å†…å­˜å ç”¨ |

> å‡ä½¿ç”¨ Hugging Face å®˜æ–¹é¢„è®­ç»ƒ checkpoint å¾®è°ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### è¡¨ 1ï¼šIMDB æƒ…æ„Ÿåˆ†ç±»ç»“æœ
| Model      | Acc.  | F1    | Size (MB) | Inf. (ms) | Thpt. (s/s) |
|-----------|-------|-------|-----------|------------|-------------|
| DistilBERT | 0.932 | 0.932 | 255.42    | 14.58      | 68.57       |
| MiniLM     | 0.937 | 0.938 | 127.26    | 10.11      | 98.95       |
| **ALBERT** | **0.944** | **0.944** | **44.58** | 32.18      | 31.08       |

> ALBERT æœ€å‡†æœ€å°ï¼Œä½†æœ€æ…¢ï¼›MiniLM æ¨ç†æœ€å¿«ã€‚

---

#### è¡¨ 2ï¼šAG News æ–°é—»åˆ†ç±»ç»“æœ
| Model      | Acc.  | F1    | Size (MB) | Inf. (ms) | Thpt. (s/s) |
|-----------|-------|-------|-----------|------------|-------------|
| DistilBERT | 0.946 | 0.946 | 255.42    | 3.30       | 302.81      |
| MiniLM     | 0.947 | 0.947 | 127.26    | **2.14**   | **466.88**  |
| **ALBERT** | **0.949** | **0.949** | **44.58** | 7.48       | 133.66      |

> ALBERT ç²¾åº¦æœ€é«˜ï¼ŒMiniLM ååé¥é¥é¢†å…ˆã€‚

---

#### è¡¨ 3ï¼šToxicity Detection ç»“æœ
| Model      | Acc.  | F1    | Size (MB) | Inf. (ms) | Thpt. (s/s) |
|-----------|-------|-------|-----------|------------|-------------|
| DistilBERT | 0.949 | 0.949 | 255.42    | 2.71       | 368.75      |
| MiniLM     | 0.906 | 0.900 | 127.26    | **1.85**   | **540.17**  |
| **ALBERT** | **0.951** | **0.950** | **44.58** | 6.15       | 162.51      |

> ALBERT å†æ¬¡å–å¾—æœ€ä½³ç²¾åº¦ï¼ŒMiniLM æ¨ç†é€Ÿåº¦ç¬¬ä¸€ï¼Œä½†ç²¾åº¦ä¸‹é™è¾ƒæ˜æ˜¾ã€‚

---

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”æ€»ç»“
| ç»´åº¦ | æœ€ä¼˜æ¨¡å‹ | è¡¨ç° |
|------|----------|------|
| **Task-specific Accuracy** | ALBERT | åœ¨æ‰€æœ‰ä¸‰ä¸ªä»»åŠ¡ä¸­å‡è¾¾åˆ°æœ€é«˜æˆ–æ¥è¿‘æœ€é«˜ç²¾åº¦ |
| **Consistency Across Tasks** | DistilBERT | å„ä»»åŠ¡é—´è¡¨ç°æœ€ç¨³å®šï¼ŒF1 æ³¢åŠ¨æœ€å° |
| **Inference Speed & Throughput** | MiniLM | å¹³å‡æ¯” DistilBERT å¿« 1.5â€“2Ã—ï¼Œååé‡æœ€é«˜ |
| **Model Size & Memory Footprint** | ALBERT | ä»…ä¸º DistilBERT çš„ 1/6ï¼Œé€‚åˆè¾¹ç¼˜éƒ¨ç½² |

---

### âŒ æ˜¯å¦æœ‰æ¶ˆèå®éªŒï¼Ÿ
æœ¬æ–‡æœªè¿›è¡Œæ¶ˆèå®éªŒï¼ˆablation studyï¼‰ã€‚ä½œè€…å¼ºè°ƒå…¶ç›®æ ‡æ˜¯**éƒ¨ç½²å¯¼å‘çš„æ¨ªå‘æ¯”è¾ƒ**ï¼Œè€Œéæ¢ç©¶å†…éƒ¨æœºåˆ¶ã€‚æ‰€æœ‰æ¨¡å‹ä½¿ç”¨ç›¸åŒå¾®è°ƒæµç¨‹ï¼Œå·®å¼‚å½’å› äºæ¶æ„è®¾è®¡æœ¬èº«ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **No Single Model Dominates All Dimensions**  
   ä¸å­˜åœ¨â€œå…¨èƒ½å† å†›â€ï¼Œå¿…é¡»æ ¹æ®åº”ç”¨åœºæ™¯æƒè¡¡å–èˆï¼š
   - è‹¥è¿½æ±‚**æœ€é«˜ç²¾åº¦** â†’ é€‰ **ALBERT**
   - è‹¥è¿½æ±‚**æœ€ä½å»¶è¿Ÿ/æœ€é«˜åå** â†’ é€‰ **MiniLM**
   - è‹¥è¿½æ±‚**å¹³è¡¡æ€§èƒ½ä¸ç¨³å®šæ€§** â†’ é€‰ **DistilBERT**

2. **Architecture Design Directly Impacts Trade-offs**
   - **DistilBERT**ï¼šKnowledge distillation â†’ ä¿æŒè¯­ä¹‰ä¿çœŸåº¦ï¼Œæ³›åŒ–å¼º
   - **MiniLM**ï¼šDeep self-attention distillation â†’ æè‡´å‹ç¼©éšè—å±‚ â†’ é«˜é€Ÿæ¨ç†
   - **ALBERT**ï¼šParameter sharing â†’ æå°ä½“ç§¯ï¼Œä½†å¢åŠ é¡ºåºä¾èµ– â†’ æ¨ç†å˜æ…¢

3. **MiniLM æ˜¯é«˜å¹¶å‘ç³»ç»Ÿçš„ç†æƒ³é€‰æ‹©**  
   åœ¨ AG News å’Œ Toxicity æ£€æµ‹ä¸­ååè¾¾ 466â€“540 samples/secï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œé€‚ç”¨äºå®æ—¶å†…å®¹è·¯ç”±ã€å¤§è§„æ¨¡æ—¥å¿—å¤„ç†ç­‰åœºæ™¯ã€‚

4. **ALBERT é€‚åˆèµ„æºå—é™ç¯å¢ƒ**  
   ä»…éœ€ 44.58 MB å­˜å‚¨ç©ºé—´ï¼Œåœ¨ IoT è®¾å¤‡ã€ç§»åŠ¨ç«¯æˆ–ä½æˆæœ¬äº‘å®ä¾‹ä¸Šæœ‰å·¨å¤§ä¼˜åŠ¿ã€‚

---

### âš ï¸ å±€é™æ€§
1. **è¯­è¨€é™åˆ¶**ï¼šä»…è¯„ä¼°è‹±æ–‡æ•°æ®é›†ï¼ŒæœªéªŒè¯å¤šè¯­è¨€æˆ–ä½èµ„æºè¯­è¨€è¡¨ç°ã€‚
2. **ç¡¬ä»¶å•ä¸€**ï¼šå…¨éƒ¨å®éªŒåŸºäº T4 GPUï¼ŒCPU æˆ–è¾¹ç¼˜èŠ¯ç‰‡ä¸Šçš„è¡¨ç°å¯èƒ½ä¸åŒã€‚
3. **æ— ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ**ï¼šå•æ¬¡è¿è¡Œç»“æœï¼ŒæœªæŠ¥å‘Šç½®ä¿¡åŒºé—´ï¼Œä¸é€‚åˆä¸¥æ ¼ç»Ÿè®¡æ¨æ–­ã€‚
4. **æœ‰é™è¶…å‚è°ƒä¼˜**ï¼šä¸ºè´´è¿‘ä¼ä¸šå®é™…ï¼Œæœªåšç½‘æ ¼æœç´¢ï¼Œå¯èƒ½å­˜åœ¨æ€§èƒ½æå‡ç©ºé—´ã€‚
5. **æ ‡ç­¾ç¦»æ•£åŒ–ä¸»è§‚æ€§**ï¼šHate Speech æ•°æ®é›†ä½¿ç”¨é˜ˆå€¼åˆ’åˆ†è¿ç»­åˆ†æ•°ï¼Œå¯èƒ½å¼•å…¥åå·®ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³å¤šè¯­è¨€åœºæ™¯**ï¼ˆMultilingual Evaluationï¼‰
2. **æ›´å¤šç¡¬ä»¶å¹³å°æµ‹è¯•**ï¼ˆCPU, Jetson, Raspberry Pi ç­‰ï¼‰
3. **åŠ å…¥é‡åŒ–ä¸è’¸é¦åä¼˜åŒ–æŠ€æœ¯**ï¼ˆQuantization, ONNX Runtime, TensorRTï¼‰
4. **æ¢ç´¢åŠ¨æ€æ‰¹å¤„ç†ï¼ˆDynamic batchingï¼‰å¯¹ååçš„å½±å“**
5. **å¼€å±• controlled variance analysis** ä»¥é‡åŒ–éšæœºæ€§å½±å“

---

## âœ… æ€»ç»“ï¼šä¼ä¸šé€‰å‹å»ºè®®ï¼ˆDeployment Guidanceï¼‰

| åº”ç”¨åœºæ™¯ | æ¨èæ¨¡å‹ | ç†ç”± |
|--------|----------|------|
| **ä½å»¶è¿ŸæœåŠ¡ï¼ˆå¦‚èŠå¤©æœºå™¨äººå“åº”ï¼‰** | MiniLM | æ¨ç†æœ€å¿«ï¼Œååæœ€é«˜ |
| **è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ï¼ˆå¦‚æ‰‹æœº Appï¼‰** | ALBERT | ä½“ç§¯æœ€å°ï¼Œå†…å­˜å‹å¥½ |
| **é€šç”¨æ–‡æœ¬åˆ†ç±» pipeline** | DistilBERT | ç²¾åº¦ç¨³å®šï¼Œå…¼é¡¾æ•ˆç‡ |
| **å¤§è§„æ¨¡æ‰¹é‡å¤„ç†ï¼ˆå¦‚æ—¥å¿—åˆ†æï¼‰** | MiniLM | é«˜ååé™ä½å•ä½æˆæœ¬ |
| **èµ„æºæåº¦å—é™çš„å°å‹ä¼ä¸šï¼ˆSMEï¼‰** | ALBERT | æœ€å° footprint æ”¯æŒè½»é‡éƒ¨ç½² |

> ğŸ’¡ **æ ¸å¿ƒæ€æƒ³**ï¼šåœ¨ä¼ä¸š NLP ä¸­ï¼Œ**efficiency often trumps marginal accuracy gains**ã€‚æœ¬ç ”ç©¶æä¾›äº†æ¸…æ™°çš„å†³ç­–åœ°å›¾ï¼ŒåŠ©åŠ›å·¥ç¨‹å›¢é˜Ÿåšå‡ºæ›´åˆç†çš„æ¨¡å‹é€‰å‹ã€‚

</details>

---

### 11. [A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR](https://arxiv.org/abs/2601.00557)

**Authors**: Yuang Zheng, Yuxiang Mei, Dongxing Xu, Jie Chen, Yanhua Long  
**Category**: cs.CL  
**Published**: 2026-01-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.00557v1  

#### Abstract
Large-scale multilingual ASR (mASR) models such as Whisper achieve strong performance but incur high computational and latency costs, limiting their deployment on resource-constrained edge devices. In this study, we propose a lightweight and language-agnostic multilingual ASR system based on a CTC a...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§è§„æ¨¡å¤šè¯­è¨€è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆmASRï¼‰æ¨¡å‹ï¼ˆå¦‚ Whisper å’Œ SeamlessM4Tï¼‰è™½ç„¶æ€§èƒ½å¼ºå¤§ï¼Œä½†å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **é«˜è®¡ç®—å¼€é”€å’Œæ¨ç†å»¶è¿Ÿ**ï¼Œéš¾ä»¥éƒ¨ç½²åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šï¼›
- åœ¨**é¢†åŸŸä¸åŒ¹é…**ï¼ˆdomain mismatchï¼‰åœºæ™¯ä¸‹ï¼ˆå¦‚å£éŸ³ã€è¯´è¯é£æ ¼å˜åŒ–ï¼‰æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼›
- å¤šæ•°å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼ˆå¦‚ LoRAï¼‰ä¾èµ–æ˜¾å¼çš„è¯­è¨€èº«ä»½ä¿¡æ¯ï¼ˆLIDï¼‰ï¼Œé™åˆ¶äº†çœŸå®åœºæ™¯ä¸­çš„å®ç”¨æ€§ï¼›
- ç°æœ‰çš„ä¸¤é˜¶æ®µè¯­è¨€æ— å…³ï¼ˆlanguage-agnosticï¼‰ç³»ç»Ÿå¼•å…¥é¢å¤–å»¶è¿Ÿï¼Œå¹¶å­˜åœ¨**é”™è¯¯ä¼ æ’­é£é™©**ï¼ˆä» LID åˆ° ASRï¼‰ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§è½»é‡çº§ã€çœŸæ­£è¯­è¨€æ— å…³çš„å¤šè¯­è¨€ ASR æ¡†æ¶ï¼š**mHuBERT-CTC-HLoRA**ï¼Œå…¶æ ¸å¿ƒæ˜¯åŸºäº CTC æ¶æ„çš„ **Hierarchical LoRA-MoEï¼ˆHLoRAï¼‰** æ¡†æ¶ï¼Œå…·å¤‡ä»¥ä¸‹åˆ›æ–°ç‚¹ï¼š

- âœ… **è¯­è¨€æ— å…³çš„åˆ†å±‚ LoRA è®¾è®¡**ï¼š
  - å°† Transformer ç¼–ç å™¨åˆ†ä¸ºä¸Šä¸‹ä¸¤éƒ¨åˆ†ï¼š
    - ä¸‹å±‚ $k$ å±‚é‡‡ç”¨**å…±äº« LoRA**ï¼ˆshared LoRAï¼‰ï¼Œå­¦ä¹ è·¨è¯­è¨€å…±æœ‰çš„å£°å­¦ç‰¹å¾ï¼›
    - ä¸Šå±‚ $N-k$ å±‚é‡‡ç”¨**è¯­è¨€ç‰¹å®š LoRA ä¸“å®¶**ï¼ˆlanguage-specific LoRA expertsï¼‰ï¼Œå»ºæ¨¡è¯­è¨€ç‰¹å¼‚æ€§ç‰¹å¾ã€‚
  - å®ç°è¯­è¨€ä¸å˜ä¸è¯­è¨€ç›¸å…³è¡¨ç¤ºçš„ç»Ÿä¸€å»ºæ¨¡ã€‚

- âœ… **ç«¯åˆ°ç«¯å•é€šè·¯æ¨ç†æœºåˆ¶**ï¼š
  - å¼•å…¥ **LID-posterior-driven LoRA routing** æœºåˆ¶ï¼šåˆ©ç”¨ä¸­é—´å±‚è¾“å‡ºé€šè¿‡ä¸€ä¸ªè½»é‡çº§ LID åˆ†ç±»å™¨é¢„æµ‹è¯­è¨€åéªŒæ¦‚ç‡ï¼ŒåŠ¨æ€æ¿€æ´»å¯¹åº”çš„è¯­è¨€ç‰¹å®š LoRA æ¨¡å—ï¼›
  - æ•´ä¸ªè¿‡ç¨‹åœ¨ä¸€ä¸ªå‰å‘ä¼ æ’­ä¸­å®Œæˆï¼Œæ— éœ€å¤–éƒ¨ LID æ¨¡å—æˆ–å…ˆéªŒè¯­è¨€æ ‡ç­¾ã€‚

- âœ… **çœŸæ­£çš„è¯­è¨€æ— å…³è§£ç **ï¼š
  - æ¨ç†æ—¶å®Œå…¨ä¸éœ€è¦è¾“å…¥è¯­è¨€æ ‡è¯†ï¼ˆLIDï¼‰ï¼Œå®ç°â€œå³æ’å³ç”¨â€å¼çš„å¤šè¯­è¨€è¯†åˆ«ï¼›
  - é¿å…äº†ä¼ ç»Ÿä¸¤é˜¶æ®µæ–¹æ³•ä¸­çš„é”™è¯¯ä¼ æ’­å’Œå»¶è¿Ÿç´¯ç§¯ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | ä¼ ç»Ÿä¸¤é˜¶æ®µæ–¹æ³•ï¼ˆå¦‚ mHuBERT-CTC-LIDLoRAï¼‰ | æœ¬æ–‡ HLoRA æ–¹æ³• |
|------|----------------------------------------|----------------|
| æ˜¯å¦éœ€è¦ LID è¾“å…¥ | âŒ ä¸éœ€è¦ï¼ˆä½†éœ€ç¬¬ä¸€é˜¶æ®µé¢„æµ‹ï¼‰ | âœ… å®Œå…¨æ— éœ€ |
| æ¨ç†æ¨¡å¼ | ä¸¤é˜¶æ®µï¼ˆdouble-passï¼‰ | å•é€šè·¯ï¼ˆsingle-passï¼‰ |
| é”™è¯¯ä¼ æ’­é£é™© | å­˜åœ¨ï¼ˆLID é”™è¯¯å½±å“ ASRï¼‰ | æ— ï¼ˆè”åˆä¼˜åŒ–ï¼‰ |
| æ¨ç†å»¶è¿Ÿ | è¾ƒé«˜ | æ˜¾è‘—é™ä½ |
| å‚æ•°æ•ˆç‡ | é«˜ï¼ˆä»…æ›´æ–° LoRA å‚æ•°ï¼‰ | æ›´ä¼˜ï¼ˆå…±äº«+ä¸“å®¶ç»“æ„ï¼‰ |
| æ€§èƒ½è¡¨ç° | å—é™äºå†»ç»“çš„ LID æ¨¡å— | æ›´é²æ£’ï¼ˆç«¯åˆ°ç«¯è”åˆè®­ç»ƒï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **MSR-86K**ï¼šç”¨äºé¢„è®­ç»ƒåŸºç¡€ mHuBERT-CTC æ¨¡å‹ï¼ŒåŒ…å«çº¦ 1500 å°æ—¶çš„ 11 ç§è¯­è¨€æ•°æ®ï¼ˆEN, FR, DE, IT, JA, KO, PT, RU, ES, TH, VIï¼‰ã€‚
- **MLC-SLM 2025 Challenge Dataset**ï¼šä½œä¸ºç›®æ ‡ä½èµ„æºé¢†åŸŸè¿›è¡Œé€‚é…ä¸è¯„ä¼°ï¼Œèšç„¦äº”ç§è¯­è¨€ï¼š
  - English (Indian accent, EN-IN), French (FR), German (DE), Japanese (JA), Korean (KO)
  - æ¯è¯­è¨€æä¾› 98h è®­ç»ƒ + 2h å¼€å‘ï¼Œä»¥åŠå®˜æ–¹æµ‹è¯•é›†ã€‚

### å®éªŒè®¾ç½®
- **ä¸»å¹²æ¨¡å‹**ï¼š`mHuBERT-147`ï¼ˆSSL é¢„è®­ç»ƒæ¨¡å‹ï¼‰
- **æ¶æ„è®¾è®¡**ï¼š
  - CTC è§£ç ï¼ˆéè‡ªå›å½’ï¼Œä½å»¶è¿Ÿï¼‰
  - LoRA åº”ç”¨äº self-attention çš„ Q/K/V æŠ•å½±å’Œ CTC å±‚ï¼Œrank $r=32$, $\alpha=64$
  - SentencePiece åˆ†è¯ï¼šJA/KO/TH ä½¿ç”¨å­—ç¬¦å•ä½ï¼Œå…¶ä½™ä½¿ç”¨ 4k BPEï¼Œç»Ÿä¸€è¯æ±‡è¡¨å¤§å°ä¸º 9,521
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - ç»Ÿä¸€ä½¿ç”¨ **Mixture Error Rate**ï¼š
    - JA/KO/TH ä½¿ç”¨ **CER**ï¼ˆCharacter Error Rateï¼‰
    - å…¶ä»–è¯­è¨€ä½¿ç”¨ **WER**ï¼ˆWord Error Rateï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç³»ç»Ÿ | æè¿° |
|------|------|
| **S1/S2** | mHuBERT-CTC åŸºçº¿ï¼Œåˆ†åˆ«åœ¨ MSR-1500h å’Œ MLC-500h ä¸Šè®­ç»ƒ |
| **S3/S4** | mHuBERT-CTC-LIDLoRAï¼š<br>- S3ï¼šè¯­è¨€å·²çŸ¥ï¼ˆground truth LIDï¼‰ï¼Œå•é€šè·¯<br>- S4ï¼šè¯­è¨€æœªçŸ¥ï¼Œä¸¤é˜¶æ®µæ¨ç†ï¼ˆstate-of-the-art language-agnostic baselineï¼‰ |
| **S5/S6** | æœ¬æ–‡æå‡ºçš„ mHuBERT-CTC-HLoRAï¼š<br>- S5ï¼šè¯­è¨€å·²çŸ¥ï¼Œå•é€šè·¯<br>- S6ï¼šè¯­è¨€æœªçŸ¥ï¼Œå•é€šè·¯ï¼ˆæœ€ç»ˆç›®æ ‡ç³»ç»Ÿï¼‰ |
| **S7/S8** | Whisper-base / Whisper-smallï¼Œç›´æ¥åœ¨ MLC ä¸Šè¯„ä¼° |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆMLC-test WER/CER %ï¼‰

| System | Params (M) | LID Info | Inference | MLC-dev (%) | MLC-test (%) |
|--------|------------|----------|-----------|-------------|--------------|
| S1 (baseline) | 97 | Ã— | single | 44.5 | 43.7 |
| S2 (full fine-tune) | 97 | Ã— | single | 22.5 | 21.6 |
| S3 (LIDLoRA, known) | 107 | âˆš | single | 24.6 | 23.0 |
| S4 (LIDLoRA, agnostic) | 107 | Ã— | double | 26.6 | 24.8 |
| **S6 (HLoRA, agnostic)** | **102** | Ã— | **single** | **26.3** | **24.7** |
| S7 (Whisper-base) | 74 | Ã— | single | 37.2 | 35.4 |
| S8 (Whisper-small) | 244 | Ã— | single | 29.7 | 28.6 |

> ğŸ” **å…³é”®è§‚å¯Ÿ**ï¼š
> - S6ï¼ˆHLoRAï¼‰åœ¨**å®Œå…¨è¯­è¨€æ— å…³ã€å•é€šè·¯**æ¡ä»¶ä¸‹ï¼Œæ€§èƒ½ï¼ˆ24.7%ï¼‰**ä¼˜äºä¸¤é˜¶æ®µåŸºçº¿ S4ï¼ˆ24.8%ï¼‰**ï¼›
> - è™½ç•¥é€Šäºè¯­è¨€å·²çŸ¥çš„ S3ï¼ˆ23.0%ï¼‰ï¼Œä½†å·®è·æå°ï¼ˆ+1.7%ï¼‰ï¼Œä¸”èŠ‚çœäº†è¯­è¨€æ ‡æ³¨éœ€æ±‚ï¼›
> - æ˜¾è‘—ä¼˜äº Whisper ç³»åˆ—æ¨¡å‹ï¼Œè¯´æ˜é¢†åŸŸé€‚é…çš„é‡è¦æ€§ï¼›
> - å‚æ•°é‡ä»…å¢åŠ çº¦ 5Mï¼ˆç›¸æ¯”ä¸»å¹²ï¼‰ï¼Œä¿æŒé«˜åº¦å‚æ•°æ•ˆç‡ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable IIï¼‰

ç ”ç©¶ä¸åŒå…±äº«å±‚æ•° $k$ å¯¹æ€§èƒ½çš„å½±å“ï¼ˆMLC-dev/test å¹³å‡ WER%ï¼‰ï¼š

| $k$ (å…±äº«å±‚æ•°) | 1 | 3 | **6** | 9 | 11 |
|---------------|----|-----|-------|-----|-----|
| Average WER | 34.8/36.6 | 31.3/32.1 | **26.0/26.0** | 26.3/24.7 | 26.5/25.2 |

> ğŸ“Œ å‘ç°ï¼š
> - å½“ $k=6$ æˆ– $9$ æ—¶è¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼Œè¡¨æ˜é€‚åº¦çš„è·¨è¯­è¨€å…±äº«æœ‰åŠ©äºæå‡æ³›åŒ–èƒ½åŠ›ï¼›
> - $k=1$ æˆ– $3$ æ—¶å…±äº«ä¸è¶³ï¼Œæ€§èƒ½å·®ï¼›
> - $k=11$ï¼ˆå‡ ä¹å…¨éƒ¨å…±äº«ï¼‰å¯¼è‡´è¯­è¨€ç‰¹å¼‚æ€§å»ºæ¨¡èƒ½åŠ›ä¸‹é™ï¼Œæ€§èƒ½å›è½ã€‚

### LID å‡†ç¡®ç‡å¯¹æ¯”ï¼ˆFig. 3ï¼‰
- mHuBERT-CTC-LIDLoRAï¼ˆS4ï¼‰ï¼šå¹³å‡ LID å‡†ç¡®ç‡ **90.1%**
- mHuBERT-CTC-HLoRAï¼ˆS6ï¼‰ï¼šå¹³å‡ LID å‡†ç¡®ç‡ **97.9%**
- HLoRA çš„æ··æ·†çŸ©é˜µæ›´æ¥è¿‘å¯¹è§’çº¿ï¼Œè¯´æ˜å…¶ LID é¢„æµ‹æ›´å‡†ç¡®ã€æ›´ç¨³å®šã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **HLoRA å®ç°äº†é«˜æ•ˆçš„è¯­è¨€æ— å…³å¤šè¯­è¨€ ASR**ï¼š
   - åœ¨æ— éœ€ä»»ä½•è¯­è¨€è¾“å…¥çš„å‰æä¸‹ï¼Œé€šè¿‡å•æ¬¡å‰å‘ä¼ æ’­å³å¯å®Œæˆé«˜è´¨é‡è¯†åˆ«ï¼›
   - æ€§èƒ½åª²ç¾ç”šè‡³ç•¥å¾®è¶…è¶Šä¸¤é˜¶æ®µæ–¹æ³•ï¼ŒåŒæ—¶é¿å…é”™è¯¯ä¼ æ’­ã€‚

2. âœ… **åˆ†å±‚ LoRA ç»“æ„æœ‰æ•ˆå¹³è¡¡å…±äº«ä¸ä¸ªæ€§åŒ–**ï¼š
   - ä¸‹å±‚å…±äº« LoRA æ•æ‰é€šç”¨å£°å­¦æ¨¡å¼ï¼›
   - ä¸Šå±‚è¯­è¨€ä¸“å®¶æ•æ‰å·®å¼‚ç‰¹æ€§ï¼›
   - äºŒè€…ç»“åˆæå‡äº†å‚æ•°æ•ˆç‡å’Œæ¨¡å‹é²æ£’æ€§ã€‚

3. âœ… **ç«¯åˆ°ç«¯è”åˆä¼˜åŒ–æ˜¾è‘—å¢å¼º LID å¯é æ€§**ï¼š
   - LID åˆ†ç±»å™¨ä¸ ASR æ¨¡å‹å…±åŒè®­ç»ƒï¼Œå¯é€‚åº”ç›®æ ‡åŸŸç‰¹å¾ï¼›
   - ç›¸æ¯”â€œå†»ç»“å¼â€ä¸¤é˜¶æ®µè®¾è®¡ï¼ŒLID å‡†ç¡®ç‡å¤§å¹…æå‡ï¼ˆ90.1% â†’ 97.9%ï¼‰ã€‚

4. âœ… **é€‚ç”¨äºä½èµ„æºã€ä½å»¶è¿Ÿåœºæ™¯**ï¼š
   - å•é€šè·¯è®¾è®¡å¤§å¹…å‡å°‘æ¨ç†æ—¶é—´ï¼›
   - é€‚åˆéƒ¨ç½²äº hearing aidsã€mobile devices ç­‰è¾¹ç¼˜è®¾å¤‡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»…éªŒè¯äº† 5 ç§ç›®æ ‡è¯­è¨€ï¼Œæ‰©å±•è‡³æ›´å¤šè¯­è¨€æ—¶å¯èƒ½é¢ä¸´ LoRA ä¸“å®¶ç®¡ç†å¤æ‚åº¦ä¸Šå‡çš„é—®é¢˜ï¼›
- å…±äº«å±‚æ•° $k$ éœ€æ‰‹åŠ¨è®¾å®šï¼Œç¼ºä¹è‡ªåŠ¨åŒ–é€‰æ‹©æœºåˆ¶ï¼›
- å¯¹éå¸¸è§è¯­è¨€æˆ–æç«¯å£éŸ³çš„æ³›åŒ–èƒ½åŠ›ä»éœ€è¿›ä¸€æ­¥éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢åŠ¨æ€è·¯ç”±æœºåˆ¶ï¼ˆdynamic MoE routingï¼‰ä»¥æ”¯æŒæ— é™è¯­è¨€æ‰©å±•ï¼›
- å¼•å…¥ speaker-aware æˆ– accent-aware LoRA æ¨¡å—ï¼Œè¿›ä¸€æ­¥æå‡ä¸ªæ€§åŒ–æ€§èƒ½ï¼›
- å°† HLoRA æ‰©å±•è‡³å…¶ä»–ä»»åŠ¡ï¼ˆå¦‚ TTSã€SLUï¼‰æ„å»ºç»Ÿä¸€å¤šè¯­è¨€è¯­éŸ³ç†è§£æ¡†æ¶ï¼›
- å¼€æºä»£ç ä¸æ¨¡å‹å·²åœ¨ GitHub å‘å¸ƒï¼š[https://github.com/zhengyuang7/HLoRA](https://github.com/zhengyuang7/HLoRA)

--- 

âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
æœ¬è®ºæ–‡æå‡ºäº† **HLoRA** â€”â€” ä¸€ç§åŸºäº CTC çš„åˆ†å±‚ LoRA-MoE æ¶æ„ï¼Œåœ¨ä¿è¯è½»é‡åŒ–å’Œä½å»¶è¿Ÿçš„åŒæ—¶ï¼Œå®ç°äº†**ç«¯åˆ°ç«¯ã€å•é€šè·¯ã€çœŸæ­£è¯­è¨€æ— å…³çš„å¤šè¯­è¨€ ASR**ï¼Œåœ¨ MLC-SLM 2025 æŒ‘æˆ˜èµ›ä¸Šå–å¾—äº†ä¼˜äºä¸»æµä¸¤é˜¶æ®µæ–¹æ³•çš„æ€§èƒ½ï¼Œä¸ºå®é™…éƒ¨ç½²æä¾›äº†é«˜æ•ˆå¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 12. [Revati: Transparent GPU-Free Time-Warp Emulation for LLM Serving](https://arxiv.org/abs/2601.00397)

**Authors**: Amey Agrawal, Mayank Yadav, Sukrit Kumar, Anirudha Agrawal, Garv Ghai, Souradeep Bera, Elton Pinto, Sirish Gambhira, Mohammad Adain, Kasra Sohrab, Chus Antonanzas, Alexey Tumanov  
**Category**: cs.DC  
**Published**: 2026-01-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.00397v1  

#### Abstract
Deploying LLMs efficiently requires testing hundreds of serving configurations, but evaluating each one on a GPU cluster takes hours and costs thousands of dollars. Discrete-event simulators are faster and cheaper, but they require re-implementing the serving system's control logic -- a burden that ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**REVATI: Transparent GPU-Free Time-Warp Emulation for LLM Serving**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†æœåŠ¡ç³»ç»Ÿé…ç½®ç©ºé—´å·¨å¤§ï¼Œæ¶‰åŠå¹¶è¡Œç­–ç•¥ã€ç¼“å­˜æœºåˆ¶ã€è°ƒåº¦ç®—æ³•ç­‰å¤šä¸ªç»´åº¦ã€‚åœ¨çœŸå®GPUé›†ç¾¤ä¸Šè¿›è¡Œç«¯åˆ°ç«¯è¯„ä¼°æˆæœ¬é«˜æ˜‚ï¼ˆå•æ¬¡è¯„ä¼°å¯è¾¾æ•°åƒç¾å…ƒï¼‰ï¼Œä¸”è€—æ—¶æ•°å°æ—¶ã€‚ä¼ ç»Ÿçš„**ç¦»æ•£äº‹ä»¶æ¨¡æ‹Ÿå™¨**ï¼ˆDiscrete-Event Simulators, DESï¼‰è™½èƒ½åŠ é€Ÿè¯„ä¼°ï¼Œä½†éœ€æ‰‹åŠ¨é‡å®ç°æ•´ä¸ªæ§åˆ¶é€»è¾‘ï¼ˆå¦‚è°ƒåº¦å™¨ã€å†…å­˜ç®¡ç†ç­‰ï¼‰ï¼Œç»´æŠ¤è´Ÿæ‹…æé‡ï¼Œéš¾ä»¥è·Ÿä¸ŠvLLMã€SGLangç­‰æ¡†æ¶çš„å¿«é€Ÿæ¼”è¿›ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ ¸å¿ƒæ€è·¯
æå‡º **REVATI** â€”â€” ä¸€ç§æ— éœ€GPUçš„**æ—¶é—´æ‰­æ›²ä»¿çœŸ**ï¼ˆTime-Warp Emulationï¼‰ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **ç›´æ¥è¿è¡ŒåŸå§‹LLMæœåŠ¡æ¡†æ¶ä»£ç **ï¼ˆå¦‚vLLMã€SGLangï¼‰ï¼Œä¸é‡æ–°å®ç°ä»»ä½•æ§åˆ¶é€»è¾‘ï¼›
- åˆ©ç”¨ **CUDA APIæ‹¦æˆªæŠ€æœ¯**ï¼ˆLD_PRELOADï¼‰è™šæ‹ŸåŒ–GPUè®¾å¤‡ï¼Œè·³è¿‡å®é™…GPUå†…æ ¸æ‰§è¡Œï¼›
- å°†GPUæ“ä½œæ›¿æ¢ä¸º**è™šæ‹Ÿæ—¶é—´è·³è·ƒ**ï¼ˆTime Jumpï¼‰ï¼Œé€šè¿‡é¢„æµ‹å†…æ ¸æ‰§è¡Œæ—¶é—´æ¥æ¨è¿›è™šæ‹Ÿæ—¶é’Ÿï¼›
- è®¾è®¡ä¸€ä¸ª**åˆ†å¸ƒå¼åè°ƒåè®®**ï¼ˆBarrier-based Virtual Time Protocolï¼‰ï¼Œç¡®ä¿å¤šä¸ªè¿›ç¨‹é—´çš„æ—¶é—´è·³è·ƒä¿æŒå› æœä¸€è‡´æ€§ã€‚

è¿™ç§æ–¹æ³•è¢«ç§°ä¸ºâ€œ**é€æ˜ä»¿çœŸ**â€ï¼ˆTransparent Emulationï¼‰ï¼Œå®ç°äº†é«˜ä¿çœŸåº¦ä¸é«˜é€Ÿåº¦çš„ç»Ÿä¸€ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç¦»æ•£äº‹ä»¶æ¨¡æ‹Ÿå™¨ï¼ˆDESï¼‰ | REVATI |
|------|------------------------|--------|
| æ§åˆ¶é€»è¾‘å®ç° | éœ€æ‰‹åŠ¨é‡å†™ï¼ˆæ˜“å‡ºé”™ã€éš¾ç»´æŠ¤ï¼‰ | ç›´æ¥æ‰§è¡ŒåŸç”Ÿä»£ç ï¼ˆè‡ªåŠ¨ç»§æ‰¿æ‰€æœ‰ç‰¹æ€§ï¼‰ |
| åŠŸèƒ½è¦†ç›– | è½åäºæœ€æ–°åŠŸèƒ½ï¼ˆå¦‚PD disaggregationã€MoEï¼‰ | æ”¯æŒæ‰€æœ‰æ¡†æ¶å†…ç½®å¤æ‚ç‰¹æ€§ï¼ˆå¼€ç®±å³ç”¨ï¼‰ |
| ç»´æŠ¤æˆæœ¬ | æé«˜ï¼ˆæ¯æ¬¡æ¡†æ¶æ›´æ–°éƒ½å¯èƒ½å¤±æ•ˆï¼‰ | æä½ï¼ˆä»…éœ€<50è¡Œè¡¥ä¸ï¼‰ |
| æ€§èƒ½å»ºæ¨¡ç²¾åº¦ | å­˜åœ¨è¯­ä¹‰é¸¿æ²Ÿï¼ˆè¡Œä¸ºåå·®ï¼‰ | <5% é¢„æµ‹è¯¯å·® |
| æ‰§è¡Œé€Ÿåº¦ | å¿«äºçœŸå®æ‰§è¡Œï¼ˆä½†å—é™äºå»ºæ¨¡å®Œæ•´æ€§ï¼‰ | æ¯”çœŸå®GPUæ‰§è¡Œå¿«5â€“17Ã— |

> âœ… **REVATIçš„å…³é”®çªç ´åœ¨äºï¼šå°†â€œæ¨¡æ‹Ÿâ€è½¬å˜ä¸ºâ€œåŠ é€Ÿæ‰§è¡Œâ€ï¼Œä»è€Œé¿å…äº†å»ºæ¨¡å¤±çœŸé—®é¢˜ã€‚**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸å·¥ä½œè´Ÿè½½
- **è¯·æ±‚æ•°æ®é›†**ï¼š`ShareGPT`ï¼ˆçœŸå®ç”¨æˆ·å¯¹è¯åºåˆ—ï¼‰
- **è¯·æ±‚åˆ°è¾¾æ¨¡å¼**ï¼šæ³Šæ¾è¿‡ç¨‹ï¼ˆPoisson arrivalï¼‰ï¼Œç”¨äºæ¨¡æ‹Ÿä¸åŒQPSä¸‹çš„åŠ¨æ€è´Ÿè½½
- **è¾“å‡ºé•¿åº¦åˆ†å¸ƒ**ï¼šå›ºå®šæˆ–é¢„è®¾ç”Ÿæˆtokenæ•°é‡ï¼ˆä¸ºå»ºæ¨¡ç›®çš„ç®€åŒ–EOSåˆ¤æ–­ï¼‰

### å®éªŒè®¾ç½®
- **æ¨¡å‹èŒƒå›´**ï¼š
  - Dense Models: `Llama-3.1-8B`, `Llama-3.1-70B`
  - Sparse Model: `Qwen3-30B-A3B`ï¼ˆå«MoEç»“æ„ï¼‰
- **æœåŠ¡å¼•æ“**ï¼š
  - `vLLM` å’Œ `SGLang`ï¼ˆä»£è¡¨ä¸¤ç±»ä¸»æµå®ç°é£æ ¼ï¼‰
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š
  - 4Ã—H200 GPUsï¼ˆNVLinkå…¨è¿æ¥ï¼‰ã€AMD EPYC CPUã€756GBå†…å­˜
  - REVATIå¯åœ¨æ— GPUç¯å¢ƒä¸‹è¿è¡Œï¼Œæ”¯æŒæ¨¡æ‹Ÿä»»æ„è§„æ¨¡é›†ç¾¤ï¼ˆå¦‚128-GPUé…ç½®ï¼‰
- **å…³é”®é…ç½®**ï¼š
  - å¯ç”¨chunked prefill + mixed batchingï¼ˆchunk size=512ï¼‰
  - Tensor Parallelism: TP=1 (8B), TP=4 (70B)ï¼›Expert Parallelism: EP=2 (Qwen)

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **TTFT** (Time to First Token) | ç”¨æˆ·å‘å‡ºè¯·æ±‚åˆ°æ”¶åˆ°ç¬¬ä¸€ä¸ªå“åº”tokençš„æ—¶é—´ |
| **TPOT** (Time Per Output Token) | è§£ç é˜¶æ®µæ¯ä¸ªè¾“å‡ºtokençš„å¹³å‡å»¶è¿Ÿ |
| **Throughput (QPS)** | æ¯ç§’å¤„ç†çš„æŸ¥è¯¢æ•° |
| **Prediction Error** | REVATIé¢„æµ‹å€¼ vs çœŸå®æ‰§è¡Œæµ‹é‡å€¼çš„ç›¸å¯¹è¯¯å·® |
| **Speedup** | REVATIå¢™é’Ÿæ—¶é—´ / çœŸå®GPUæ‰§è¡Œæ—¶é—´çš„å€’æ•° |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**: åœ¨çœŸå®GPUä¸Šçš„å®Œæ•´æ‰§è¡Œï¼ˆGround Truthï¼‰
- **Sleep-Based Emulation**ï¼ˆæ¶ˆèå®éªŒåŸºçº¿ï¼‰ï¼šç”¨`sleep()`ä»£æ›¿GPUæ‰§è¡Œï¼Œä¿ç•™æ—¶é—´è¯­ä¹‰ä½†æ— åŠ é€Ÿ
- **Discrete-Event Simulators**ï¼ˆé—´æ¥å¯¹æ¯”ï¼‰ï¼šVidur [4], LLMServingSim [12], Frontier [13] ç­‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
#### âœ… å‡†ç¡®æ€§ï¼ˆAccuracyï¼‰
- **TTFT å’Œ TPOT åˆ†å¸ƒé¢„æµ‹è¯¯å·® < 5%**ï¼Œå³ä½¿åœ¨å°¾éƒ¨å»¶è¿Ÿï¼ˆP90/P99ï¼‰ä¹Ÿé«˜åº¦ä¸€è‡´ï¼ˆè§å›¾6ï¼‰
- æˆåŠŸæ•æ‰åˆ°vLLMä¸SGLangä¹‹é—´çš„ç»†å¾®å·®å¼‚ï¼š
  - SGLangé»˜è®¤ä¸å¯ç”¨mixed batching â†’ å¯¼è‡´decodeé˜¶æ®µTPOTå°¾éƒ¨æ›´å·®
  - REVATIè‡ªåŠ¨å¤ç°è¯¥è¡Œä¸ºï¼Œè€Œä¼ ç»Ÿæ¨¡æ‹Ÿå™¨å®¹æ˜“å¿½ç•¥æ­¤ç±»å®ç°ç»†èŠ‚

#### âœ… åŠ é€Ÿæ€§èƒ½ï¼ˆEfficiencyï¼‰
- **æ•´ä½“åŠ é€Ÿæ¯”è¾¾ 5â€“17Ã—**ï¼ˆè§å›¾7ï¼‰ï¼š
  - vLLM: æœ€é«˜ **17Ã—**
  - SGLang: æœ€é«˜ **12Ã—**
- åŠ é€Ÿæ¯”éšæ¨¡å‹å¢å¤§è€Œæå‡ï¼ˆå› GPUå æ¯”æ›´é«˜ï¼‰ï¼š
  - Llama-70B > Llama-8B
- å³ä½¿åœ¨é«˜QPSä¸‹ä»ç»´æŒ >10Ã— åŠ é€Ÿï¼ˆCPUå¼€é”€å æ¯”é€šå¸¸ < 5â€“10%ï¼‰

#### âœ… æ¶ˆèå®éªŒç»“æœ
| å®éªŒæ¡ä»¶ | ç»“æœ |
|---------|------|
| **ä¸åŒbatch durationï¼ˆ5â€“40msï¼‰** | éšç€batchå˜é•¿ï¼ŒåŠ é€Ÿæ¯”ä»~5Ã—å‡è‡³**27Ã—**ï¼ˆå›¾10ï¼‰ï¼ŒéªŒè¯äº†â€œè·³è¿‡GPUç­‰å¾…â€çš„æœ‰æ•ˆæ€§ |
| **ä¸åŒè¯·æ±‚é€Ÿç‡ï¼ˆ0.5â€“8 QPSï¼‰** | åœ¨é«˜è´Ÿè½½ä¸‹ç•¥æœ‰é™é€Ÿï¼ˆå› CPUè°ƒåº¦å¼€é”€å¢åŠ ï¼‰ï¼Œä½†ä»ä¿æŒ**>10Ã—åŠ é€Ÿ**ï¼ˆå›¾9ï¼‰ |
| **ä¸Sleep-Based Emulationå¯¹æ¯”** | è¾“å‡ºåˆ†å¸ƒå‡ ä¹å®Œå…¨ä¸€è‡´ï¼ˆå›¾8ï¼‰ï¼Œè¯æ˜æ—¶é—´è·³è·ƒæœªç ´åå› æœé€»è¾‘ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **GPUç­‰å¾…ä¸»å¯¼æ‰§è¡Œæ—¶é—´**ï¼šLLMæœåŠ¡ä¸­è¶…è¿‡90%çš„wall-clock timeèŠ±åœ¨GPUè®¡ç®—ä¸Šï¼ŒCPUæ§åˆ¶å¹³é¢ä»…å 5â€“10%ï¼Œè¿™ä¸ºâ€œæ—¶é—´åŠ é€Ÿâ€æä¾›äº†å¤©ç„¶åŸºç¡€ã€‚
2. **æ§åˆ¶æµä¸è®¡ç®—è§£è€¦**ï¼šè°ƒåº¦å†³ç­–ä¾èµ–çš„æ˜¯è¯·æ±‚çŠ¶æ€ã€å†…å­˜å ç”¨ç­‰æŠ½è±¡ä¿¡æ¯ï¼Œè€ŒéGPUè¾“å‡ºçš„å…·ä½“æ•°å€¼ï¼Œå› æ­¤å¯å®‰å…¨è·³è¿‡GPUæ‰§è¡Œã€‚
3. **REVATIå®ç°äº†â€œé›¶å»ºæ¨¡â€é«˜ä¿çœŸä»¿çœŸ**ï¼šé€šè¿‡ç›´æ¥è¿è¡ŒåŸç”Ÿä»£ç ï¼Œè‡ªåŠ¨æ”¯æŒæ‰€æœ‰é«˜çº§ç‰¹æ€§ï¼ˆå¦‚PD disaggregationã€hierarchical cachingã€MoEè·¯ç”±ç­‰ï¼‰ï¼Œæ— éœ€äººå·¥å»ºæ¨¡ã€‚
4. **Barrier-basedæ—¶é—´åŒæ­¥åè®®æœ‰æ•ˆä¿éšœå› æœæ€§**ï¼šæœ€å°ç›®æ ‡æ¨è¿›æœºåˆ¶ + è¶…æ—¶å›é€€ç­–ç•¥ï¼Œæ—¢ä¿è¯æ­£ç¡®æ€§ï¼Œåˆå…·å¤‡å®¹é”™èƒ½åŠ›ï¼ˆstragglerå®¹å¿ï¼‰ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä»éœ€å°‘é‡ä»£ç ä¾µå…¥**ï¼ˆ~50è¡Œï¼‰ï¼šéœ€åœ¨Actorç»„ä»¶ä¸­æ’å…¥`TIMEJUMP()`è°ƒç”¨ï¼Œå°šæœªå®ç°å®Œå…¨é€æ˜ï¼ˆå¦‚å†…æ ¸çº§æ‹¦æˆªï¼‰ã€‚
- **ä¾èµ–å‡†ç¡®çš„runtime predictor**ï¼šå½“å‰ä½¿ç”¨åŸºäºVidurçš„åˆ†ææ¨¡å‹ï¼Œè‹¥é¢„æµ‹ä¸å‡†ä¼šå½±å“ç²¾åº¦ï¼ˆå°½ç®¡è¯¯å·®ä»å¯æ§ï¼‰ã€‚
- **æ— æ³•å¤„ç†CPUè¯»å–compute bufferçš„æƒ…å†µ**ï¼šé‡‡ç”¨split-state memory modelå‡è®¾KV cacheä¸ä¼šè¢«CPUä¸»åŠ¨è®¿é—®ï¼Œå¦åˆ™ä¼šè§¦å‘å¼‚å¸¸ã€‚
- **ç½‘ç»œæŠ–åŠ¨å½±å“è§‚æµ‹ç²¾åº¦**ï¼šè™½å¼•å…¥bounded-jitteræ¨¡å‹ç¼“è§£ï¼Œä½†åœ¨æç«¯å»¶è¿Ÿåœºæ™¯ä¸‹å¯èƒ½å½±å“latencyæµ‹é‡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å®ç°å®Œå…¨é€æ˜çš„è‡ªåŠ¨åŒ–æ—¶é—´è·³è·ƒæ³¨å…¥**ï¼š
   - æ¢ç´¢åŸºäºeBPFæˆ–å†…æ ¸hookçš„æŠ€æœ¯ï¼Œæ¶ˆé™¤å¯¹æ¡†æ¶æ‰“è¡¥ä¸çš„éœ€æ±‚ã€‚
2. **é›†æˆæ›´ç²¾ç¡®çš„kernel runtimeé¢„æµ‹å™¨**ï¼š
   - å¼•å…¥Ithemal [21] æˆ–Forecast-GPU [19] ç±»å‹çš„æ·±åº¦å­¦ä¹ é¢„æµ‹æ¨¡å‹ï¼Œæå‡é¢„æµ‹å‡†ç¡®æ€§ã€‚
3. **æ¢ç´¢â€œå…‰é€Ÿæ‰§è¡Œâ€æé™**ï¼š
   - å½“GPUç­‰å¾…è¢«å®Œå…¨è·³è¿‡ï¼Œç“¶é¢ˆå°†è½¬ç§»åˆ°tokenizationã€é€šä¿¡ã€å†…å­˜æ‹·è´ç­‰ç¯èŠ‚ï¼Œå€¼å¾—æ·±å…¥ä¼˜åŒ–ã€‚
4. **æ‰©å±•è‡³è®­ç»ƒåœºæ™¯**ï¼š
   - å½“å‰èšç„¦inferenceï¼Œæœªæ¥å¯å°è¯•åº”ç”¨äºåˆ†å¸ƒå¼è®­ç»ƒä»¿çœŸã€‚

---

## æ€»ç»“
**REVATIæå‡ºäº†ä¸€ç§é©å‘½æ€§çš„LLMæœåŠ¡æ€§èƒ½å»ºæ¨¡èŒƒå¼â€”â€”Time-Warp Emulation**ã€‚å®ƒé€šè¿‡**ç›´æ¥æ‰§è¡ŒåŸç”ŸæœåŠ¡æ¡†æ¶ä»£ç  + è™šæ‹Ÿæ—¶é—´è·³è·ƒ**çš„æ–¹å¼ï¼Œåœ¨æ— éœ€çœŸå®GPUçš„æƒ…å†µä¸‹å®ç°äº†**é«˜ä¿çœŸï¼ˆ<5%è¯¯å·®ï¼‰ä¸é«˜æ•ˆï¼ˆ5â€“17Ã—åŠ é€Ÿï¼‰çš„ç»Ÿä¸€**ã€‚ç›¸æ¯”ä¼ ç»Ÿç¦»æ•£äº‹ä»¶æ¨¡æ‹Ÿå™¨ï¼ŒREVATIä»æ ¹æœ¬ä¸Šè§£å†³äº†â€œç»´æŠ¤æ»åâ€å’Œâ€œè¯­ä¹‰é¸¿æ²Ÿâ€é—®é¢˜ï¼Œä¸ºLLMç³»ç»Ÿç ”ç©¶ä¸ç”Ÿäº§éƒ¨ç½²æä¾›äº†ä¸€ä¸ªå¼ºå¤§ã€å¯æŒç»­æ¼”è¿›çš„ä»¿çœŸå¹³å°ã€‚

</details>

---

### 13. [Traffic-Aware Optimal Taxi Placement Using Graph Neural Network-Based Reinforcement Learning](https://arxiv.org/abs/2601.00607)

**Authors**: Sonia Khetarpaul, P Y Sharan  
**Category**: cs.LG  
**Published**: 2026-01-05  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.00607v1  

#### Abstract
In the context of smart city transportation, efficient matching of taxi supply with passenger demand requires real-time integration of urban traffic network data and mobility patterns. Conventional taxi hotspot prediction models often rely solely on historical demand, overlooking dynamic influences ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTraffic-Aware Optimal Taxi Placement Using Graph Neural Network-Based Reinforcement Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**åŸå¸‚å‡ºç§Ÿè½¦ä¾›éœ€åŒ¹é…æ•ˆç‡ä½ä¸‹**çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨åŠ¨æ€äº¤é€šç¯å¢ƒï¼ˆå¦‚æ‹¥å µã€çªå‘äº‹ä»¶ã€å¤§å‹æ´»åŠ¨ï¼‰ä¸‹ï¼Œä¼ ç»Ÿå‡ºç§Ÿè½¦çƒ­ç‚¹é¢„æµ‹æ¨¡å‹ä»…ä¾èµ–å†å²éœ€æ±‚æ•°æ®ï¼Œéš¾ä»¥å®æ—¶å“åº”å¤æ‚å¤šå˜çš„åŸå¸‚äº¤é€šçŠ¶å†µã€‚è¿™å¯¼è‡´ä¹˜å®¢ç­‰å¾…æ—¶é—´é•¿ã€å¸æœºç©ºé©¶è·ç¦»é«˜ã€äº¤é€šæ‹¥å µåŠ å‰§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§**åŸºäºå›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼ˆGNN+RLï¼‰**ï¼Œç”¨äºåœ¨æ™ºèƒ½åŸå¸‚ç¯å¢ƒä¸­å®ç°äº¤é€šæ„ŸçŸ¥çš„æœ€ä¼˜å‡ºç§Ÿè½¦å¸ƒç‚¹æ¨èã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **äº¤é€šæ„ŸçŸ¥å»ºæ¨¡**ï¼šå°†åŸå¸‚é“è·¯ç½‘ç»œå»ºæ¨¡ä¸ºå›¾ç»“æ„ $ G=(V,E) $ï¼Œå…¶ä¸­èŠ‚ç‚¹ä»£è¡¨çƒ­ç‚¹åŒºåŸŸï¼ˆå¦‚äº¤é€šæ¢çº½ã€é«˜éœ€æ±‚åŒºï¼‰ï¼Œè¾¹è¡¨ç¤ºå¯é€šè¡Œè·¯æ®µï¼Œå¹¶å¼•å…¥**å®æ—¶äº¤é€šæ‹¥å µåˆ†æ•°**ï¼ˆæ¥è‡ª Google Maps Distance Matrix APIï¼‰ä½œä¸ºèŠ‚ç‚¹å±æ€§ä¹‹ä¸€ã€‚
  
- **GNN ç¼–ç ç©ºé—´-æ—¶åºä¾èµ–**ï¼šåˆ©ç”¨ GraphSAGE é£æ ¼çš„ GNN å¯¹èŠ‚ç‚¹è¿›è¡ŒåµŒå…¥ï¼ˆembeddingï¼‰ï¼Œæ•æ‰çƒ­ç‚¹ä¹‹é—´çš„ç©ºé—´ç›¸å…³æ€§ã€é“è·¯è¿é€šæ€§å’ŒåŠ¨æ€äº¤é€šçŠ¶æ€ã€‚

- **Q-learning å†³ç­–æœºåˆ¶**ï¼šè®¾è®¡ä¸€ä¸ªåŸºäº Q-learning çš„ RL ä»£ç†ï¼Œä»¥ GNN è¾“å‡ºçš„èŠ‚ç‚¹åµŒå…¥ä½œä¸ºçŠ¶æ€è¾“å…¥ï¼Œé€‰æ‹©æœ€ä¼˜çš„å‡ºç§Ÿè½¦éƒ¨ç½²ä½ç½®ï¼ˆhotspotï¼‰ï¼Œç›®æ ‡æ˜¯æœ€å¤§åŒ–ç»¼åˆå¥–åŠ±å‡½æ•°ã€‚

- **k-hop Dominating Set ä¼˜åŒ–åŠ¨ä½œç©ºé—´**ï¼šé€šè¿‡é€‰å–â€œk-hop æ”¯é…é›†â€æ¥ç­›é€‰å‡ºå…·æœ‰æˆ˜ç•¥å½±å“åŠ›çš„å€™é€‰çƒ­ç‚¹ï¼Œæ˜¾è‘—å‡å°‘ RL åŠ¨ä½œç©ºé—´è§„æ¨¡ï¼ˆçº¦é™ä½ 60%ï¼‰ï¼Œæå‡è®­ç»ƒæ•ˆç‡ä¸”ä¸ç‰ºç‰²è¦†ç›–èƒ½åŠ›ã€‚

- **å¤šç›®æ ‡å¥–åŠ±å‡½æ•°è®¾è®¡**ï¼š
  $$
  R = -\alpha W_t - \beta D - \gamma T
  $$
  ç»¼åˆè€ƒè™‘ï¼š
  - $ W_t $ï¼šä¹˜å®¢ç­‰å¾…æ—¶é—´
  - $ D $ï¼šå¸æœºå‰å¾€çƒ­ç‚¹çš„è·ç¦»
  - $ T $ï¼šåŸºäºäº¤é€šå¾—åˆ†çš„æ‹¥å µæƒ©ç½šé¡¹

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³•å±€é™ | æœ¬æ–‡ä¼˜åŠ¿ |
|------|--------------|----------|
| æ•°æ®ä¾èµ– | ä»…ç”¨å†å²éœ€æ±‚ | èåˆ**å®æ—¶äº¤é€šAPI + äº‹ä»¶ä¿¡æ¯ + å†å²éœ€æ±‚** |
| ç©ºé—´å»ºæ¨¡ | ç½‘æ ¼åŒ–å¤„ç†å¿½ç•¥è·¯ç½‘æ‹“æ‰‘ | ä½¿ç”¨**å›¾ç»“æ„å»ºæ¨¡çœŸå®é“è·¯è¿æ¥å…³ç³»** |
| å†³ç­–æœºåˆ¶ | å•ä¸€ç›®æ ‡ä¼˜åŒ–ï¼ˆå¦‚æœ€å¤§æ¥å•ç‡ï¼‰ | å¤šç›®æ ‡å¹³è¡¡ï¼š**ç­‰å¾…æ—¶é—´ã€è¡Œé©¶è·ç¦»ã€é¿å µ** |
| å¯æ‰©å±•æ€§ | åŠ¨ä½œç©ºé—´å¤§ï¼Œéš¾æ”¶æ•› | åˆ©ç”¨ **k-hop æ”¯é…é›†å‹ç¼©åŠ¨ä½œç©ºé—´**ï¼Œæé«˜è®­ç»ƒæ•ˆç‡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
ç”±äºç¼ºä¹å…¬å¼€çš„å¾·é‡Œï¼ˆDelhiï¼‰ç²¾ç»†å‡ºç§Ÿè½¦è¯·æ±‚æ•°æ®ï¼Œä½œè€…æ„å»ºäº†ä¸€ä¸ª**æ¨¡æ‹Ÿæ•°æ®é›†**ï¼ŒåŸºäºä»¥ä¸‹æ¥æºç”Ÿæˆï¼š

- **Historic Ola Taxi Request Dataset**ï¼šä½œä¸ºç”ŸæˆçœŸå®éœ€æ±‚æ¨¡å¼çš„åŸºç¡€ã€‚
- **50ä¸ªçƒ­ç‚¹èŠ‚ç‚¹**ï¼šåˆ†å¸ƒåœ¨å¾·é‡Œå¸‚å†…ï¼Œåœ°ç†èŒƒå›´é™å®šä¸ºçº¬åº¦ [28.5, 28.9]ï¼Œç»åº¦ [77.0, 77.3]ã€‚
- **1000æ¡æ¨¡æ‹Ÿæ‰“è½¦è¯·æ±‚**ï¼šåˆ†å¸ƒäºå„çƒ­ç‚¹ä¹‹é—´ã€‚
- **å®æ—¶äº¤é€šè¯„åˆ†**ï¼šé€šè¿‡ **Google Maps Distance Matrix API** è·å–ï¼Œå®šä¹‰ä¸ºå½“å‰è¡Œç¨‹æ—¶é—´ä¸è‡ªç”±æµæ—¶é—´ä¹‹æ¯”ã€‚

### å®éªŒè®¾ç½®
- **å›¾æ„å»º**ï¼šæ¯ä¸ªçƒ­ç‚¹ä¸ºèŠ‚ç‚¹ï¼Œé“è·¯æ®µä¸ºè¾¹ï¼›èŠ‚ç‚¹ç‰¹å¾åŒ…æ‹¬ï¼š
  - å†å²éœ€æ±‚å¯†åº¦ $ d(v) $
  - äº‹ä»¶ä¸´è¿‘åº¦ $ e(v) $
  - å®æ—¶æ‹¥å µå¾—åˆ† $ T(v) $

- **GNN æ¨¡å‹**ï¼šé‡‡ç”¨ GraphSAGE è¿›è¡ŒèŠ‚ç‚¹åµŒå…¥ï¼Œèšåˆé‚»åŸŸä¿¡æ¯ã€‚

- **RL è®¾ç½®**ï¼š
  - **çŠ¶æ€ç©ºé—´**ï¼š$ s = [z_v, l_t] $ï¼Œå…¶ä¸­ $ z_v $ æ˜¯ GNN åµŒå…¥ï¼Œ$ l_t $ æ˜¯ç”¨æˆ·ä½ç½®å’Œæ—¶é—´ä¸Šä¸‹æ–‡ã€‚
  - **åŠ¨ä½œç©ºé—´**ï¼šä» k-hop æ”¯é…é›†ä¸­é€‰å‡ºçš„ 20 ä¸ªå…³é”®çƒ­ç‚¹ï¼ˆåŸ 50 ä¸ªï¼‰ã€‚
  - **ç®—æ³•**ï¼šTabular Q-learning + Îµ-greedy æ¢ç´¢ç­–ç•¥ï¼ŒÎµ éšè®­ç»ƒè¡°å‡ã€‚
  - **Q-table æ„å»ºæ–¹å¼**ï¼šå¯¹è¿ç»­ GNN åµŒå…¥ä½¿ç”¨ k-meansï¼ˆk=25ï¼‰èšç±»ç¦»æ•£åŒ–ï¼Œå½¢æˆç¨³å®šçš„çŠ¶æ€è¡¨ç¤ºã€‚

- **è®­ç»ƒå¹³å°**ï¼šIntel Core i7-12700H CPU, 32GB RAM, NVIDIA RTX 3060 GPUï¼›ä½¿ç”¨ PyTorch Geometric å®ç° GNNï¼ŒNumPy å®ç° Q-learningã€‚

### è¯„ä¼°æŒ‡æ ‡
- å¹³å‡ episode å¥–åŠ±ï¼ˆAvg. Rewardï¼‰
- å¹³å‡ä¹˜å®¢ç­‰å¾…æ—¶é—´ï¼ˆWait Time, minï¼‰
- å¹³å‡å¸æœºè¡Œé©¶è·ç¦»ï¼ˆDistance, kmï¼‰

æ‰€æœ‰ç»“æœå– **5 æ¬¡ç‹¬ç«‹è¿è¡Œçš„å¹³å‡å€¼**ï¼Œç¡®ä¿ç»Ÿè®¡ä¸€è‡´æ€§ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **Random Placement (RP)** | å®Œå…¨éšæœºæ¨èçƒ­ç‚¹ï¼Œæ— ä»»ä½•æ™ºèƒ½é€»è¾‘ |
| **Greedy Demand Placement (GDP)** | æ€»æ˜¯é€‰æ‹©æœ€è¿‘å†å²éœ€æ±‚æœ€é«˜çš„çƒ­ç‚¹ |
| **RL-Only** | ä¸ä½¿ç”¨ GNN åµŒå…¥ï¼Œç›´æ¥åŸºäºåŸå§‹ç‰¹å¾è¿›è¡Œ Q-learning |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table Iï¼‰

| æ–¹æ³• | Avg. Reward | Wait Time (min) | Distance (km) |
|------|-------------|------------------|---------------|
| Random Placement (RP) | 0.12 | 8.74 | 3.12 |
| Greedy Demand (GDP) | 0.74 | 6.21 | 2.87 |
| RL-Only | 1.05 | 4.98 | 2.35 |
| **GNN+RL (Proposed)** | **1.46** | **3.84** | **1.92** |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç›¸æ¯” GDPï¼ˆè´ªå©ªç­–ç•¥ï¼‰**ï¼š
  - å¥–åŠ±æå‡ **97%**
  - ç­‰å¾…æ—¶é—´å‡å°‘ **38%**
  - è¡Œé©¶è·ç¦»å‡å°‘ **33%**

- **ç›¸æ¯” RL-Only**ï¼š
  - å¥–åŠ±æå‡ **39%**
  - ç­‰å¾…æ—¶é—´å‡å°‘ **23%**
  - è¡Œé©¶è·ç¦»å‡å°‘ **18%**

- **ç›¸æ¯” RPï¼ˆéšæœºç­–ç•¥ï¼‰**ï¼š
  - ç­‰å¾…æ—¶é—´å‡å°‘ **56%**
  - è¡Œé©¶è·ç¦»å‡å°‘ **38%**

> âœ… ç»“æœè¡¨æ˜ï¼š**GNN æä¾›çš„ç©ºé—´ä¸Šä¸‹æ–‡æ˜¾è‘—å¢å¼ºäº† RL çš„å†³ç­–è´¨é‡**ï¼Œç‰¹åˆ«æ˜¯åœ¨é¿å¼€æ‹¥å µåŒºåŸŸçš„åŒæ—¶ç»´æŒé«˜éœ€æ±‚è¦†ç›–ã€‚

### æ¶ˆèå®éªŒä¸åˆ†æï¼ˆéšå«åœ¨æ–‡ä¸­ï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºâ€œæ¶ˆèå®éªŒè¡¨â€ï¼Œä½†é€šè¿‡å¯¹æ¯”ä¸åŒæ–¹æ³•å·²ä½“ç°å…³é”®ç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼š
- **åŠ å…¥ GNN åæ€§èƒ½è·ƒå‡** â†’ éªŒè¯äº†å›¾ç»“æ„å»ºæ¨¡çš„é‡è¦æ€§ï¼›
- **k-hop æ”¯é…é›†ä½¿åŠ¨ä½œç©ºé—´ä» 50â†’20** â†’ åŠ é€Ÿè®­ç»ƒå¹¶ä¿æŒè¦†ç›–ç‡ï¼›
- **å¤šå› ç´ å¥–åŠ±å‡½æ•°å¼•å¯¼å‡è¡¡ä¼˜åŒ–** â†’ é¿å…è¿‡åº¦é›†ä¸­åœ¨é«˜éœ€æ±‚ä½†æ‹¥å µåŒºåŸŸï¼ˆå¦‚ Fig. 4 æ‰€ç¤ºï¼‰ï¼›
- **è®­ç»ƒæ›²çº¿æ˜¾ç¤º GNN+RL æ›´å¿«æ”¶æ•›è‡³æ›´é«˜å¥–åŠ±å¹³å°**ï¼ˆFig. 5ï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **èåˆå®æ—¶äº¤é€šä¿¡æ¯çš„ GNN+RL æ¡†æ¶èƒ½æœ‰æ•ˆæå‡å‡ºç§Ÿè½¦è°ƒåº¦æ•ˆç‡**ï¼Œæ˜¾è‘—é™ä½ä¹˜å®¢ç­‰å¾…æ—¶é—´å’Œå¸æœºç©ºé©¶è·ç¦»ã€‚
2. å›¾ç»“æ„å»ºæ¨¡ä¼˜äºä¼ ç»Ÿçš„ç½‘æ ¼åŒ–æˆ–å­¤ç«‹ç‚¹å»ºæ¨¡æ–¹å¼ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åæ˜ åŸå¸‚äº¤é€šçš„çœŸå®æ‹“æ‰‘çº¦æŸã€‚
3. å¼•å…¥ **k-hop æ”¯é…é›†** å¯å¤§å¹…å‹ç¼© RL åŠ¨ä½œç©ºé—´ï¼Œæå‡è®­ç»ƒæ•ˆç‡è€Œä¸æŸå¤±æ¨èè´¨é‡ã€‚
4. å¤šç›®æ ‡å¥–åŠ±æœºåˆ¶ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿåœ¨**éœ€æ±‚æ»¡è¶³ã€å¸æœºæ•ˆç‡ã€äº¤é€šç¼“è§£**ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡ã€‚
5. è¯¥æ–¹æ³•å…·å¤‡è‰¯å¥½çš„é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§ï¼Œé€‚ç”¨äºåŠ¨æ€å˜åŒ–çš„åŸå¸‚ç¯å¢ƒã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–å¤–éƒ¨ API**ï¼šå®æ—¶äº¤é€šæ•°æ®ä¾èµ– Google Maps APIï¼Œåœ¨æŸäº›åœ°åŒºå¯èƒ½ä¸å¯ç”¨æˆ–æˆæœ¬è¾ƒé«˜ã€‚
- **ä»¿çœŸæ•°æ®é™åˆ¶**ï¼šå®éªŒåŸºäºæ¨¡æ‹Ÿæ•°æ®é›†ï¼Œå°šæœªåœ¨çœŸå®è¿è¥è½¦é˜Ÿä¸­éªŒè¯æ•ˆæœã€‚
- **é™æ€å›¾ç»“æ„å‡è®¾**ï¼šé“è·¯ç½‘ç»œè¢«è§†ä¸ºå›ºå®šå›¾ï¼Œæœªè€ƒè™‘ä¸´æ—¶å°è·¯æˆ–æ–½å·¥ç­‰æç«¯å˜åŒ–ã€‚
- **è®¡ç®—å¼€é”€ä»å­˜**ï¼šå°½ç®¡åšäº†ç®€åŒ–ï¼ŒGNN+Q-learning æµç¨‹ä»éœ€ä¸€å®šè®¡ç®—èµ„æºï¼Œè¾¹ç¼˜è®¾å¤‡éƒ¨ç½²å­˜åœ¨æŒ‘æˆ˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **é›†æˆé¢„æµ‹æ€§äº¤é€šæ¨¡å‹**ï¼šä¸ä»…ä½¿ç”¨å½“å‰äº¤é€šçŠ¶æ€ï¼Œè¿˜é¢„æµ‹æœªæ¥å‡ åˆ†é’Ÿå†…çš„æ‹¥å µè¶‹åŠ¿ã€‚
- **å¤šæ¨¡æ€äº¤é€šååŒä¼˜åŒ–**ï¼šæ‰©å±•è‡³å…¬äº¤ã€åœ°é“ã€å…±äº«å•è½¦ç­‰å¤šæ¨¡å¼å‡ºè¡Œæ•´åˆè°ƒåº¦ã€‚
- **æ”¯æŒè‡ªåŠ¨é©¾é©¶è½¦è¾†åè°ƒ**ï¼šåº”ç”¨äºæœªæ¥ AV fleet çš„è‡ªä¸»è°ƒåº¦ç³»ç»Ÿã€‚
- **æ¥å…¥ Smart City IoT å¹³å°**ï¼šä¸åŸå¸‚çº§ä¼ æ„Ÿå™¨ç½‘ç»œè”åŠ¨ï¼Œå®ç°æ›´å…¨é¢çš„æ€åŠ¿æ„ŸçŸ¥ã€‚
- **åœ¨çº¿å¢é‡å­¦ä¹ æœºåˆ¶**ï¼šæ”¯æŒæ¨¡å‹æŒç»­æ›´æ–°ï¼Œé€‚åº”é•¿æœŸéœ€æ±‚æ¼”å˜ã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼šæœ¬æ–‡æå‡ºçš„ **GNN-based RL æ¡†æ¶** æˆåŠŸå®ç°äº†**äº¤é€šæ„ŸçŸ¥ã€é«˜æ•ˆã€è‡ªé€‚åº”çš„å‡ºç§Ÿè½¦çƒ­ç‚¹æ¨èç³»ç»Ÿ**ï¼Œåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸‹å±•ç°å‡ºè¿œè¶…ä¼ ç»Ÿæ–¹æ³•çš„æ€§èƒ½ä¼˜åŠ¿ï¼Œä¸ºæ™ºèƒ½åŸå¸‚å‡ºè¡Œä¼˜åŒ–æä¾›äº†å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 14. [A Comparative Study of Adaptation Strategies for Time Series Foundation Models in Anomaly Detection](https://arxiv.org/abs/2601.00446)

**Authors**: Miseon Park, Kijung Yoon  
**Category**: cs.LG  
**Published**: 2026-01-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.00446v1  

#### Abstract
Time series anomaly detection is essential for the reliable operation of complex systems, but most existing methods require extensive task-specific training. We explore whether time series foundation models (TSFMs), pretrained on large heterogeneous data, can serve as universal backbones for anomaly...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Comparative Study of Adaptation Strategies for Time Series Foundation Models in Anomaly Detection

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬æ–‡èšç„¦äº**æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ï¼ˆTSADï¼‰ä¸­æ¨¡å‹é€‚åº”æ€§å·®ã€è®­ç»ƒæˆæœ¬é«˜**çš„é—®é¢˜ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸éœ€è¦é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œå¤§é‡è®­ç»ƒå’Œè°ƒå‚ï¼Œéš¾ä»¥æ³›åŒ–åˆ°å¤šæ ·åŒ–çš„ç°å®åœºæ™¯ã€‚ä½œè€…æå‡ºæ¢ç´¢**é¢„è®­ç»ƒçš„æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ï¼ˆTSFMsï¼‰æ˜¯å¦å¯ä»¥ä½œä¸ºé€šç”¨éª¨å¹²ç½‘ç»œç”¨äºå¼‚å¸¸æ£€æµ‹**ï¼Œå¹¶ç³»ç»Ÿæ¯”è¾ƒä¸åŒé€‚åº”ç­–ç•¥çš„æœ‰æ•ˆæ€§å’Œæ•ˆç‡ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•/æ–°æ€è·¯
- **å°†TSFMsä»é¢„æµ‹ä»»åŠ¡è¿ç§»åˆ°å¼‚å¸¸æ£€æµ‹ä»»åŠ¡**ï¼šé¦–æ¬¡å¯¹å¤šç§TSFMï¼ˆå¦‚Moiraiã€Chronosã€Time-MoEï¼‰åœ¨é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰ã€å…¨é‡å¾®è°ƒï¼ˆfull fine-tuningï¼‰å’Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰ä¸‹çš„è¡¨ç°è¿›è¡Œäº†å…¨é¢å®è¯ç ”ç©¶ã€‚
- **ç³»ç»Ÿæ¯”è¾ƒå¤šç§PEFTç­–ç•¥**ï¼šå¼•å…¥å¹¶è¯„ä¼°äº†LoRAã€OFTã€HRAã€IA3ç­‰å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åœ¨TSADä¸­çš„åº”ç”¨æ•ˆæœï¼Œæ­ç¤ºå…¶åœ¨ä¿æŒä½è®¡ç®—å¼€é”€çš„åŒæ—¶æå‡æ€§èƒ½çš„æ½œåŠ›ã€‚
- **å¼ºè°ƒè¯„ä¼°æŒ‡æ ‡çš„é‡è¦æ€§**ï¼šæŒ‡å‡ºåœ¨ä¸¥é‡ç±»åˆ«ä¸å¹³è¡¡ä¸‹ï¼ŒAUC-PR å’Œ VUS-based æŒ‡æ ‡æ¯”ä¼ ç»Ÿçš„AUC-ROCæ›´å…·åˆ¤åˆ«åŠ›ï¼Œå¹¶å€¡å¯¼ä½¿ç”¨æ›´é²æ£’çš„VUSç³»åˆ—æŒ‡æ ‡æ¥å®¹å¿æ—¶é—´é”™ä½ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ— éœ€ä»»åŠ¡ç‰¹å®šè®­ç»ƒå³å¯å®ç°å¼ºæ€§èƒ½**ï¼šTSFMsåœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹å·²èƒ½è¶…è¶Šå¤šæ•°task-specificåŸºçº¿ã€‚
- **PEFTæ˜¾è‘—é™ä½é€‚é…æˆæœ¬**ï¼šä»…æ›´æ–°0.02%~3.5%çš„å‚æ•°å³å¯è¾¾åˆ°ç”šè‡³è¶…è¿‡å…¨é‡å¾®è°ƒçš„æ•ˆæœï¼Œå°¤å…¶é€‚ç”¨äºå¤§è§„æ¨¡æˆ–MoEæ¶æ„æ¨¡å‹ã€‚
- **é€šç”¨æ€§å¼ºã€å¯æ‰©å±•æ€§å¥½**ï¼šéªŒè¯äº†TSFMså³ä½¿æ˜¯åœ¨ä¸ºé¢„æµ‹ä»»åŠ¡é¢„è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½æœ‰æ•ˆæœåŠ¡äºå¼‚å¸¸æ£€æµ‹ï¼Œæ¨åŠ¨â€œç»Ÿä¸€æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹â€èŒƒå¼çš„å¯è¡Œæ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
- ä½¿ç”¨ **TSB-AD-U benchmark**ï¼ŒåŒ…å«23ä¸ªç²¾å¿ƒç­›é€‰çš„å•å˜é‡æ—¶é—´åºåˆ—æ•°æ®é›†ã€‚
- è¦†ç›–å¤šä¸ªé¢†åŸŸã€å¼‚å¸¸ç±»å‹ã€åºåˆ—é•¿åº¦å’Œç»Ÿè®¡ç‰¹æ€§ï¼Œå…·æœ‰è‰¯å¥½çš„å¤šæ ·æ€§ä¸å¯é æ€§ã€‚
- å®éªŒé‡‡ç”¨é¢„å®šä¹‰çš„è®­ç»ƒ/è°ƒä¼˜/æµ‹è¯•åˆ’åˆ†ï¼Œå…¶ä¸­**è°ƒä¼˜é›†ç”¨ä½œæœ€ç»ˆè¯„ä¼°é›†**ä»¥æé«˜å®éªŒæ•ˆç‡ï¼ˆæ‰€æœ‰è¶…å‚æ•°å›ºå®šåä¸€æ¬¡æ€§è¯„ä¼°ï¼‰ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **TSFM Backbone**ï¼š
  - é›¶æ ·æœ¬å®éªŒæ¶µç›–ï¼šMoiraiç³»åˆ—ï¼ˆdense & MoEï¼‰ã€Chronosç³»åˆ—ï¼ˆT5/Boltï¼‰ã€Time-MoE-baseã€‚
  - å¾®è°ƒå®éªŒé›†ä¸­äºä¸‰ä¸ªä»£è¡¨æ€§æ¨¡å‹ï¼š**Moirai-baseã€Chronos-t5-baseã€Time-MoE-base**ï¼Œåˆ†åˆ«ä»£è¡¨patch-based encoderã€numerical tokenization autoregressiveã€sparse MoEä¸‰ç§ä¸»æµæ¶æ„ã€‚
- **é€‚åº”ç­–ç•¥å¯¹æ¯”**ï¼š
  - **Zero-shot inference**ï¼šç›´æ¥ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆé¢„æµ‹ï¼Œä»¥MSEä½œä¸ºå¼‚å¸¸åˆ†æ•°ã€‚
  - **Full fine-tuning**ï¼šæ›´æ–°å…¨éƒ¨å‚æ•°ï¼Œä½œä¸ºä¸Šç•ŒåŸºå‡†ã€‚
  - **PEFT methods**ï¼šåŒ…æ‹¬LoRAã€OFTã€HRAï¼ˆæ’å…¥adapteræ¨¡å—ï¼‰ã€IA3ï¼ˆå­¦ä¹ ç¼©æ”¾å‘é‡ï¼‰ï¼Œadapter rankå°è¯•4/8/16/32ã€‚
- **è®­ç»ƒåè®®**ï¼š
  - ä¸Šä¸‹æ–‡çª—å£ï¼š150æ—¶é—´æ­¥
  - è®­ç»ƒè½®æ•°ï¼š10 epochs
  - ä¼˜åŒ–å™¨ä¸æŸå¤±å‡½æ•°æ²¿ç”¨åŸTSFMè®¾å®šï¼ˆå¦‚NLLã€CrossEntropyã€Huber Lossï¼‰
  - å­¦ä¹ ç‡æœç´¢èŒƒå›´ï¼š1e-2 åˆ° 1e-5ï¼Œé€‰æ‹©è·¨æ•°æ®é›†å¹³å‡æœ€ä¼˜é…ç½®

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡ï¼ˆå‡ä¸ºthreshold-freeï¼‰
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **AUC-ROC** | è¡¡é‡å…¨å±€æ’åºèƒ½åŠ› |
| **AUC-PR** | æ›´å…³æ³¨æ­£ç±»ï¼ˆå¼‚å¸¸ï¼‰è¯†åˆ«ç²¾åº¦ï¼Œåœ¨ç±»åˆ«æåº¦ä¸å¹³è¡¡æ—¶æ›´æœ‰æ„ä¹‰ |
| **VUS-ROC / VUS-PR** | å¼•å…¥ç¼“å†²åŒºå®¹å¿å°çš„æ—¶é—´åç§»ï¼Œæ›´é€‚åˆåŸºäºé¢„æµ‹çš„å¼‚å¸¸æ£€æµ‹ä»»åŠ¡ï¼Œä½†è®¡ç®—æˆæœ¬æ›´é«˜ |

> æ‰€æœ‰æ–¹æ³•å‡ä½¿ç”¨ **MSE = (prediction - ground truth)^2** ä½œä¸ºæ¯ä¸€æ­¥çš„å¼‚å¸¸å¾—åˆ†ã€‚

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
å¯¹æ¯”äº†å¹¿æ³›ä½¿ç”¨çš„éTSFMç±»åŸºçº¿ï¼Œåˆ†ä¸ºä¸‰ç±»ï¼š
- **ç»å…¸æœºå™¨å­¦ä¹ **ï¼šSub-PCAã€Isolation Forest (IForest)ã€SAND
- **æ·±åº¦å­¦ä¹ é¢„æµ‹å‹**ï¼šLSTMADã€TimesNetã€Anomaly Transformer
- **é‡æ„å‹ç¥ç»æ¨¡å‹**ï¼šAutoEncoderã€OmniAnomaly

è¿™äº›åŸºçº¿ä¸ä¾èµ–ä»»ä½•é¢„è®­ç»ƒï¼Œä»£è¡¨å½“å‰ä¸»æµçš„task-specificæ–¹æ³•ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆè§Tables 1â€“3ï¼‰

#### â–¶ï¸ åŸºçº¿æ–¹æ³•è¡¨ç°ï¼ˆTable 1ï¼‰
| æ–¹æ³• | AUC-PR | AUC-ROC | VUS-PR | VUS-ROC |
|------|--------|---------|--------|---------|
| **LSTMAD**ï¼ˆæœ€ä½³åŸºçº¿ï¼‰ | **0.332** | **0.724** | 0.323 | **0.820** |
| Sub-PCA | 0.293 | 0.700 | **0.353** | 0.747 |
| Anomaly Transformer | 0.059 | 0.499 | 0.102 | 0.575 |

> ç»“è®ºï¼šç®€å•æ¨¡å‹ï¼ˆå¦‚SANDã€Sub-PCAï¼‰åœ¨VUSæŒ‡æ ‡ä¸Šæœ‰ç«äº‰åŠ›ï¼›å¤æ‚æ¨¡å‹ï¼ˆå¦‚Anomaly Transformerï¼‰è¡¨ç°ä¸ä½³ï¼Œè¯´æ˜æ³›åŒ–èƒ½åŠ›å¼±ã€‚

---

#### â–¶ï¸ é›¶æ ·æœ¬TSFMè¡¨ç°ï¼ˆTable 2ï¼‰
| TSFM | AUC-PR | AUC-ROC | VUS-PR | VUS-ROC |
|------|--------|---------|--------|---------|
| **Chronos-bolt-small** | **0.346** | 0.684 | **0.319** | **0.770** |
| Chronos-bolt-tiny | 0.345 | **0.693** | 0.318 | 0.774 |
| Moirai-small | 0.335 | 0.697 | 0.318 | 0.778 |
| Time-MoE-base | 0.339 | 0.669 | 0.318 | 0.756 |

> ç»“è®ºï¼š
- å¤šæ•°TSFMé›¶æ ·æœ¬æ€§èƒ½å·²**è¶…è¿‡æœ€å¼ºåŸºçº¿LSTMAD**
- Boltç³»åˆ—è¡¨ç°æœ€å¥½ï¼Œè¡¨æ˜æ•°å€¼tokenization + autoregressiveè®¾è®¡é€‚åˆåœ¨çº¿æ£€æµ‹
- MoEå˜ä½“æœªæ˜¾ç¤ºå‡ºæ˜æ˜¾ä¼˜åŠ¿ï¼Œå¯èƒ½å› ç¨€ç–æ¿€æ´»é™åˆ¶è¡¨è¾¾èƒ½åŠ›

---

#### â–¶ï¸ ä¸åŒé€‚åº”ç­–ç•¥å¯¹æ¯”ï¼ˆTable 3ï¼‰

| Model | Adaptation | AUC-PR | AUC-ROC | VUS-PR | VUS-ROC |
|-------|------------|--------|---------|--------|---------|
| **Moirai-base** | Zero-shot | 0.321 | 0.678 | 0.312 | 0.763 |
| | Full-FT | 0.387 | 0.757 | 0.354 | 0.827 |
| | **OFT** | **0.389** | 0.756 | **0.361** | **0.834** |
| | LoRA | 0.388 | **0.763** | 0.352 | 0.829 |
| **Chronos-t5-base** | Zero-shot | 0.318 | 0.675 | 0.290 | 0.752 |
| | Full-FT | 0.361 | 0.727 | 0.318 | 0.796 |
| | **HRA** | **0.367** | **0.738** | **0.336** | **0.816** |
| | OFT | 0.361 | 0.733 | 0.338 | 0.813 |
| **Time-MoE-base** | Zero-shot | 0.339 | 0.669 | 0.318 | 0.756 |
| | Full-FT | **0.386** | **0.750** | **0.392** | **0.843** |
| | LoRA | 0.384 | 0.757 | 0.372 | 0.830 |
| | OFT | 0.379 | 0.762 | 0.365 | 0.840 |

> ç»“è®ºï¼š
- æ‰€æœ‰æ¨¡å‹ç»é€‚åº”åæ€§èƒ½æ˜¾è‘—æå‡ï¼Œå°¤å…¶åœ¨**VUS-PR/VUS-ROC**ä¸Šå¢ç›Šæ˜æ˜¾ï¼ˆ+0.04~0.08ï¼‰
- **PEFTæ–¹æ³•æ™®éä¼˜äºæˆ–åª²ç¾full fine-tuning**
- åœ¨denseæ¨¡å‹ï¼ˆMoiraiã€Chronosï¼‰ä¸Šï¼Œ**OFT/HRA/LoRAå…¨é¢é¢†å…ˆ**
- åœ¨MoEæ¨¡å‹ï¼ˆTime-MoEï¼‰ä¸Šï¼Œ**full fine-tuningä»å ä¼˜**ï¼ŒPEFTæœªèƒ½å®Œå…¨é‡Šæ”¾æ½œåŠ›

---

#### â–¶ï¸ å‚æ•°æ•ˆç‡åˆ†æï¼ˆTable 4ï¼‰
| PEFT | Moirai-base (#params / %) | Chronos-t5-base (#params / %) | Time-MoE-base (#params / %) |
|------|----------------------------|-------------------------------|------------------------------|
| IA3 | ~43K / 0.05% | ~0.1M / 0.06% | ~27K / 0.02% |
| LoRA | ~1.1M / 1.28% | ~3.5M / 1.73% | ~1.6M / 1.47% |
| OFT | ~0.8M / 0.94% | ~2.5M / 1.27% | ~4M / 3.48% |
| HRA | ~0.5M / 0.64% | ~1.7M / 0.87% | ~0.7M / 0.65% |

> ç»“è®ºï¼š
- PEFTä»…éœ€æ›´æ–°**ä¸åˆ°2%çš„å‚æ•°**å³å¯è·å¾—æ¥è¿‘ç”šè‡³è¶…è¶Šå…¨é‡å¾®è°ƒçš„è¡¨ç°
- **adapter-basedæ–¹æ³•ï¼ˆLoRA/OFT/HRAï¼‰æ˜¾è‘—ä¼˜äºIA3**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **TSFMsæ˜¯å¼ºå¤§çš„é€šç”¨å¼‚å¸¸æ£€æµ‹éª¨å¹²**ï¼š
   - å³ä½¿åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹ï¼ŒTSFMsä¹Ÿæ™®éä¼˜äºtask-specificåŸºçº¿ï¼Œè¯æ˜å…¶å…·å¤‡è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚
2. **PEFTæ˜¯é«˜æ•ˆä¸”æœ‰æ•ˆçš„é€‚é…æ–¹å¼**ï¼š
   - LoRAã€OFTã€HRAç­‰æ–¹æ³•åœ¨**ä»…æ›´æ–°æå°æ¯”ä¾‹å‚æ•°**çš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½**åŒ¹é…ç”šè‡³è¶…è¶Šå…¨é‡å¾®è°ƒ**ï¼Œæå¤§é™ä½äº†éƒ¨ç½²æˆæœ¬ã€‚
3. **VUS-basedæŒ‡æ ‡æ›´èƒ½åæ˜ å®é™…ä»·å€¼**ï¼š
   - åœ¨å­˜åœ¨æ—¶é—´é”™ä½çš„å®é™…åœºæ™¯ä¸­ï¼ŒVUS-PR/VUS-ROCæ¯”AUC-PR/AUC-ROCæ›´åˆç†ï¼Œåº”æˆä¸ºæ ‡å‡†è¯„ä¼°æŒ‡æ ‡ã€‚
4. **æ¶æ„å½±å“é€‚é…æ•ˆæœ**ï¼š
   - Dense TSFMsï¼ˆå¦‚Moiraiï¼‰æ›´å®¹æ˜“é€šè¿‡è½»é‡çº§PEFTè·å¾—é«˜æ€§èƒ½ï¼›
   - MoEæ¶æ„ï¼ˆå¦‚Time-MoEï¼‰å¯¹PEFTå“åº”è¾ƒå¼±ï¼Œå¯èƒ½éœ€è¦**ä¸“å®¶æ„ŸçŸ¥çš„å®šåˆ¶åŒ–é€‚é…æœºåˆ¶**ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰ç ”ç©¶å±€é™äº**å•å˜é‡æ—¶é—´åºåˆ—**ï¼Œå°šæœªéªŒè¯åœ¨å¤šå˜é‡ã€æµå¼æˆ–é•¿å‘¨æœŸåœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ã€‚
- PEFTåœ¨MoEæ¨¡å‹ä¸Šçš„è¡¨ç°ä»æœ‰å·®è·ï¼Œè¡¨æ˜ç°æœ‰æ–¹æ³•å¯¹**expert routingæœºåˆ¶çš„å»ºæ¨¡ä¸è¶³**ã€‚
- æ‰€æœ‰å®éªŒåŸºäºMSEè¯¯å·®æ‰“åˆ†ï¼Œæœªæ¢ç´¢å…¶ä»–å¼‚å¸¸è¯„åˆ†å‡½æ•°ï¼ˆå¦‚æ¦‚ç‡è¾“å‡ºã€æ³¨æ„åŠ›å¼‚å¸¸åº¦ç­‰ï¼‰çš„å½±å“ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- è®¾è®¡é¢å‘MoEæ¶æ„çš„**expert-aware PEFTæ–¹æ³•**ï¼ˆå¦‚è·¯ç”±é—¨æ§å¾®è°ƒã€ä¸“å®¶ä¸“å±adapterï¼‰
- å°†TSFM+PEFTæ¡†æ¶æ‹“å±•è‡³**å¤šå…ƒã€å®æ—¶ã€å°‘æ ·æœ¬/é›¶æ ·æœ¬å¼‚å¸¸æ£€æµ‹åœºæ™¯**
- æ¢ç´¢æ›´ä¸°å¯Œçš„å¼‚å¸¸è¯„åˆ†æœºåˆ¶ï¼Œç»“åˆä¸ç¡®å®šæ€§ä¼°è®¡ã€æ³¨æ„åŠ›æ¨¡å¼å˜åŒ–ç­‰ä¿¡å·
- æ„å»ºæ›´å¤§è§„æ¨¡ã€æ›´å…·æŒ‘æˆ˜æ€§çš„å…¬å¼€TSAD benchmarkï¼Œæ¨åŠ¨å…¬å¹³æ¯”è¾ƒ

---

## æ€»ç»“
è¯¥è®ºæ–‡ç³»ç»Ÿè®ºè¯äº†**Time Series Foundation Models + PEFT** æ˜¯ä¸€ç§**é«˜æ•ˆã€å¯æ‰©å±•ã€é«˜æ€§èƒ½çš„æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹æ–°èŒƒå¼**ã€‚å®ƒä¸ä»…å‡å°‘äº†å¯¹å¤§é‡æ ‡æ³¨æ•°æ®å’Œæ˜‚è´µè®­ç»ƒè¿‡ç¨‹çš„ä¾èµ–ï¼Œè¿˜å±•ç¤ºäº†åŸºç¡€æ¨¡å‹åœ¨è·¨ä»»åŠ¡è¿ç§»ä¸­çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºæ„å»ºâ€œç»Ÿä¸€æ—¶é—´åºåˆ—æ™ºèƒ½ç³»ç»Ÿâ€æä¾›äº†é‡è¦å®è¯æ”¯æŒã€‚

</details>

---

### 15. [Controllable Concept Bottleneck Models](https://arxiv.org/abs/2601.00451)

**Authors**: Hongbin Lin, Chenyang Ren, Juangui Xu, Zhengyu Hu, Cheng-Long Wang, Yao Shu, Hui Xiong, Jingfeng Zhang, Di Wang, Lijie Hu  
**Category**: cs.LG  
**Published**: 2026-01-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.00451v1  

#### Abstract
Concept Bottleneck Models (CBMs) have garnered much attention for their ability to elucidate the prediction process through a human-understandable concept layer. However, most previous studies focused on static scenarios where the data and concepts are assumed to be fixed and clean. In real-world ap...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Controllable Concept Bottleneck Models è®ºæ–‡æ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **Concept Bottleneck Models (CBMs)** è™½ç„¶å…·æœ‰è‰¯å¥½çš„å¯è§£é‡Šæ€§ï¼Œä½†é€šå¸¸è¢«è§†ä¸ºé™æ€æ¨¡å‹ï¼Œä¸€æ—¦è®­ç»ƒå®Œæˆä¾¿éš¾ä»¥ä¿®æ”¹ã€‚ç„¶è€Œï¼Œåœ¨ç°å®ä¸–ç•Œçš„åº”ç”¨ä¸­ï¼Œæ¨¡å‹éœ€è¦æŒç»­ç»´æŠ¤å’Œæ›´æ–°ï¼Œä¾‹å¦‚ï¼š
- **ç§»é™¤é”™è¯¯æˆ–æ•æ„Ÿæ•°æ®**ï¼ˆMachine Unlearningï¼‰
- **ä¿®æ­£æ ‡æ³¨é”™è¯¯çš„æ¦‚å¿µæ ‡ç­¾**
- **æ·»åŠ æ–°æ ·æœ¬ä»¥é€‚åº”ç¯å¢ƒå˜åŒ–**ï¼ˆIncremental Learningï¼‰

å¯¹è¿™äº›éœ€æ±‚è¿›è¡Œé‡æ–°è®­ç»ƒï¼ˆretrainingï¼‰æˆæœ¬é«˜æ˜‚ï¼Œå°¤å…¶æ˜¯åœ¨å¤§è§„æ¨¡åº”ç”¨ä¸­ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¸ä»å¤´å¼€å§‹è®­ç»ƒçš„æƒ…å†µä¸‹é«˜æ•ˆåœ°ç¼–è¾‘ CBM æˆä¸ºä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡ºäº† **Controllable Concept Bottleneck Models (CCBMs)**ï¼Œä¸€ç§æ”¯æŒåŠ¨æ€ã€å¯æ§ç¼–è¾‘çš„ CBM æ¡†æ¶ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š
- **å¤šç²’åº¦å¯æ§æ€§**ï¼šæ”¯æŒä¸‰ç§ä¸åŒå±‚æ¬¡çš„æ¨¡å‹ç¼–è¾‘ï¼š
  1. **Concept-label-level**ï¼šä¿®æ­£å•ä¸ªæ ·æœ¬ä¸Šçš„é”™è¯¯æ¦‚å¿µæ ‡ç­¾ã€‚
  2. **Concept-level**ï¼šæ·»åŠ æˆ–åˆ é™¤æ•´ä¸ªæ¦‚å¿µï¼ˆå¦‚åŒ»å­¦ä¸­çš„é£é™©å› å­ï¼‰ã€‚
  3. **Data-level**ï¼šåŒå‘æ“ä½œï¼ŒåŒ…æ‹¬æ•°æ®åˆ é™¤ï¼ˆUnlearningï¼‰å’Œæ•°æ®æ·»åŠ ï¼ˆIncremental Learningï¼‰ã€‚
- **åŸºäº Influence Functions çš„é—­å¼è¿‘ä¼¼**ï¼šåˆ©ç”¨ **Influence Functions** æ¨å¯¼å‡ºæ•°å­¦ä¸Šä¸¥è°¨çš„å‚æ•°æ›´æ–°é—­å¼è§£ï¼Œé¿å…äº†æ˜‚è´µçš„é‡æ–°è®­ç»ƒã€‚
- **ç»“åˆ EK-FAC åŠ é€Ÿè®¡ç®—**ï¼šå¼•å…¥ **Eigenvalue-corrected Kronecker-Factored Approximate Curvature (EK-FAC)** æ¥åŠ é€Ÿé«˜ç»´å‚æ•°ç©ºé—´ä¸‹çš„ Hessian çŸ©é˜µè®¡ç®—ï¼Œæå‡æ–¹æ³•çš„å¯æ‰©å±•æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **é«˜æ•ˆæ€§**ï¼šç›¸æ¯”å®Œå…¨é‡æ–°è®­ç»ƒï¼ŒCCBMs å°†æ›´æ–°æ—¶é—´ä»æ•°å°æ—¶ç¼©çŸ­åˆ°å‡ åˆ†é’Ÿï¼Œå®ç°äº†è¶…è¿‡ 100 å€çš„é€Ÿåº¦æå‡ã€‚
- **å‡†ç¡®æ€§**ï¼šåœ¨ä¿æŒæé«˜æ•ˆç‡çš„åŒæ—¶ï¼Œæ€§èƒ½ï¼ˆå¦‚ F1 åˆ†æ•°ï¼‰ä¸é‡æ–°è®­ç»ƒçš„ç»“æœé«˜åº¦æ¥è¿‘ï¼Œè¿œä¼˜äºæ ‡å‡† Influence Function åŸºçº¿ï¼ˆCBM-IFï¼‰ã€‚
- **å…¨é¢æ€§**ï¼šé¦–æ¬¡ç³»ç»Ÿæ€§åœ°å°†æ¨¡å‹ç¼–è¾‘èƒ½åŠ›å¼•å…¥ CBMï¼Œè¦†ç›–äº†ä»æ•°æ®åˆ°æ¦‚å¿µå†åˆ°æ ‡ç­¾çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåœ¨å››ä¸ªå¤šæ ·åŒ–çš„åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œï¼š
- **OAI**ï¼šè†å…³èŠ‚éª¨å…³èŠ‚ç‚ X å…‰åˆ†çº§æ•°æ®é›†ï¼Œå« 36,369 ä¸ªæ ·æœ¬ï¼Œ10 ä¸ªåŒ»å­¦ç›¸å…³æ¦‚å¿µã€‚
- **CUB**ï¼šé¸Ÿç±»è¯†åˆ«æ•°æ®é›†ï¼ˆCaltech-UCSD Birdsï¼‰ï¼Œå« 11,788 å¼ å›¾åƒï¼Œ112 ä¸ªäºŒå€¼å±æ€§ä½œä¸ºæ¦‚å¿µã€‚
- **CelebA**ï¼šäººè„¸å±æ€§æ•°æ®é›†ï¼Œå« 202,599 å¼ å›¾åƒï¼Œ40 ä¸ªäºŒå€¼å±æ€§ï¼Œå…¶ä¸­ 8 ä¸ªä½œä¸ºæ ‡ç­¾ï¼Œ32 ä¸ªä½œä¸ºæ¦‚å¿µã€‚
- **Derm7pt**ï¼šçš®è‚¤é•œå›¾åƒç”¨äºé»‘è‰²ç´ ç˜¤è¯Šæ–­ï¼Œå« 1,011 å¼ å›¾åƒï¼Œ7 ä¸ªä¸´åºŠå®šä¹‰çš„çš®æŸæ ‡å‡†ä½œä¸ºæ¦‚å¿µã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
#### ç¼–è¾‘åœºæ™¯è®¾ç½®
- **Concept-label-level**ï¼šéšæœºé€‰æ‹© 3% çš„æ ·æœ¬å¹¶ç¿»è½¬å…¶ä¸­ä¸€ä¸ªæ¦‚å¿µæ ‡ç­¾ã€‚
- **Concept-level**ï¼šéšæœºç§»é™¤ OAI ä¸­ 1 ä¸ªæ¦‚å¿µï¼ŒCUB ä¸­ 10 ä¸ªæ¦‚å¿µã€‚
- **Data-level**ï¼š
  - **Removal**ï¼šéšæœºåˆ é™¤ 3% çš„è®­ç»ƒæ•°æ®ã€‚
  - **Addition**ï¼šå…ˆä¿ç•™ 10% æ•°æ®ä¸å‚ä¸åˆå§‹è®­ç»ƒï¼Œä¹‹åå°†å…¶åŠ å…¥ä»¥æµ‹è¯•å¢é‡å­¦ä¹ èƒ½åŠ›ã€‚

#### è¯„ä¼°æŒ‡æ ‡
- **F1 Score**ï¼šè¡¡é‡æ¨¡å‹æ•ˆç”¨ï¼ˆUtilityï¼‰ï¼Œå¹³è¡¡ç²¾ç¡®ç‡ä¸å¬å›ç‡ã€‚
- **Runtime (RT)**ï¼šä»¥åˆ†é’Ÿä¸ºå•ä½ï¼Œè¯„ä¼°æ¨¡å‹æ›´æ–°æ‰€éœ€çš„è®¡ç®—æ—¶é—´ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Retrain**ï¼šå®Œå…¨é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™çš„é»„é‡‘æ ‡å‡†ã€‚
- **CBM-IF (Ours)**ï¼šä»…ä½¿ç”¨æ ‡å‡† Influence Function çš„åŸºçº¿æ–¹æ³•ã€‚
- **CCBM (Ours)**ï¼šæœ¬æ–‡æå‡ºçš„å®Œæ•´æ–¹æ³•ï¼Œç»“åˆ EK-FAC åŠ é€Ÿã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰
| ç¼–è¾‘çº§åˆ« | æ–¹æ³• | OAI F1 | OAI RT (min) | CUB F1 | CUB RT (min) |
|---------|------|--------|-------------|--------|-------------|
| Concept Label | Retrain | 0.8825 | 297.77 | 0.7971 | 85.56 |
| | CBM-IF | 0.8650 | 4.58 | 0.7710 | 1.28 |
| | **CCBM (Ours)** | **0.8809** | **2.28** | **0.7918** | **0.63** |
| Concept | Retrain | 0.8448 | 258.84 | 0.7811 | 87.21 |
| | CBM-IF | 0.8248 | 4.87 | 0.7580 | 1.44 |
| | **CCBM (Ours)** | **0.8411** | **2.29** | **0.7794** | **0.51** |
| Data Removal | Retrain | 0.8811 | 319.37 | 0.7838 | 86.20 |
| | CBM-IF | 0.8477 | 4.99 | 0.7625 | 1.41 |
| | **CCBM (Ours)** | **0.8799** | **2.42** | **0.7851** | **0.60** |
| Data Addition | Retrain | 0.8801 | 323.83 | 0.7987 | 87.93 |
| | CBM-IF | 0.8479 | 5.03 | 0.7635 | 1.44 |
| | **CCBM (Ours)** | **0.8806** | **2.51** | **0.7967** | **0.63** |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **é€Ÿåº¦ä¼˜åŠ¿æ˜¾è‘—**ï¼šCCBMs çš„è¿è¡Œæ—¶é—´æ™®éåœ¨ **2â€“3 åˆ†é’Ÿ**ï¼Œè€Œé‡æ–°è®­ç»ƒéœ€ **85â€“324 åˆ†é’Ÿ**ï¼Œæé€Ÿè¶… **100 å€**ã€‚
- **æ€§èƒ½æ›´ä¼˜**ï¼šCCBMs çš„ F1 åˆ†æ•°å‡ ä¹ä¸é‡æ–°è®­ç»ƒæŒå¹³ï¼Œä¸”æ˜¾è‘—ä¼˜äº CBM-IF åŸºçº¿ï¼ˆä¾‹å¦‚åœ¨ CUB ä¸Šå¹³å‡é«˜å‡ºçº¦ 0.015â€“0.03ï¼‰ã€‚
- **ç¨³å®šæ€§å¼º**ï¼šåœ¨å›¾ 3 ä¸­ï¼Œå³ä½¿ç¼–è¾‘æ¯”ä¾‹é«˜è¾¾ 10%ï¼ŒCCBMs çš„æ€§èƒ½ä¸‹é™ä»éå¸¸å¹³ç¼“ï¼Œä¸é‡æ–°è®­ç»ƒçš„å·®è·æå°ï¼ˆ< 0.0025ï¼‰ã€‚

### æ¶ˆèå®éªŒä¸é¢å¤–åˆ†æ
- **å‘¨æœŸæ€§ç¼–è¾‘å®éªŒ**ï¼ˆå›¾ 7â€“9ï¼‰ï¼šæ¨¡æ‹Ÿè¿ç»­ 10 è½®é€æ­¥æ¸…ç†å™ªå£°ï¼Œç»“æœæ˜¾ç¤º CCBMs æ€§èƒ½æ¢å¤è½¨è¿¹ä¸é‡æ–°è®­ç»ƒé«˜åº¦ä¸€è‡´ï¼Œæœªå‡ºç°è¯¯å·®ç´¯ç§¯å¯¼è‡´çš„å´©æºƒï¼Œè¯æ˜å…¶é•¿æœŸç»´æŠ¤çš„å¯è¡Œæ€§ã€‚
- **å¯è§£é‡Šæ€§éªŒè¯**ï¼ˆå›¾ 4ï¼‰ï¼šé€šè¿‡å½±å“å‡½æ•°é‡åŒ–æ¦‚å¿µé‡è¦æ€§ï¼Œç§»é™¤é«˜å½±å“åŠ›æ¦‚å¿µå¯¼è‡´æ€§èƒ½æ€¥å‰§ä¸‹é™ï¼Œè€Œç§»é™¤ä½å½±å“åŠ›æ¦‚å¿µå‡ ä¹æ— å½±å“ï¼Œè¯´æ˜ CCBMs èƒ½å‡†ç¡®è¯†åˆ«å…³é”®è¯­ä¹‰ç‰¹å¾ã€‚
- **éšç§åˆè§„éªŒè¯**ï¼ˆå›¾ 5ï¼‰ï¼šä½¿ç”¨ **RMIA (Removed Membership Inference Attack)** è¯„åˆ†ï¼Œæ˜¾ç¤ºç»è¿‡ CCBMs åˆ é™¤çš„æ•°æ®å…¶æˆå‘˜æ¨æ–­å¾—åˆ†æ˜¾è‘—é™ä½ï¼Œè¶‹è¿‘äºéæˆå‘˜åˆ†å¸ƒï¼Œè¯æ˜å…¶æœ‰æ•ˆå®ç°â€œé—å¿˜â€ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **CCBMs å®ç°äº†é«˜æ•ˆä¸”å‡†ç¡®çš„æ¨¡å‹ç¼–è¾‘**ï¼šé€šè¿‡ Influence Functions å’Œ EK-FACï¼Œèƒ½å¤Ÿåœ¨æ— éœ€é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œå¯¹ CBM è¿›è¡Œå¤šç²’åº¦ã€åŒå‘çš„åŠ¨æ€æ›´æ–°ã€‚
2. **æ€§èƒ½ä¸æ•ˆç‡è¾¾åˆ°å“è¶Šå¹³è¡¡**ï¼šåœ¨å¤šä¸ªçœŸå®æ•°æ®é›†ä¸Šï¼ŒCCBMs åœ¨ä¿æŒæ¥è¿‘é‡æ–°è®­ç»ƒæ€§èƒ½çš„åŒæ—¶ï¼Œå°†æ›´æ–°æ—¶é—´å‹ç¼©è‡³åˆ†é’Ÿçº§ã€‚
3. **æ”¯æŒå¯æŒç»­ã€å¯ä¿¡çš„ AI ç”Ÿå‘½å‘¨æœŸç®¡ç†**ï¼šCCBMs ä¸ä»…å¯ç”¨äºçº é”™ï¼Œè¿˜èƒ½æ»¡è¶³ GDPR ç­‰æ³•è§„è¦æ±‚çš„â€œè¢«é—å¿˜æƒâ€ï¼Œå¹¶æ”¯æŒå¢é‡å­¦ä¹ ï¼Œä½¿æ¨¡å‹èƒ½å¤ŸæŒç»­è¿›åŒ–ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **éå‡¸ä¼˜åŒ–ä¸‹çš„è¿‘ä¼¼è¯¯å·®**ï¼šInfluence Functions åŸºäºæŸå¤±å‡½æ•°å±€éƒ¨äºŒæ¬¡è¿‘ä¼¼çš„å‡è®¾ï¼Œåœ¨æ·±åº¦ç¥ç»ç½‘ç»œçš„é«˜åº¦éå‡¸æ™¯è§‚ä¸­å¯èƒ½å­˜åœ¨åå·®ï¼Œå°¤å…¶åœ¨å¤§è§„æ¨¡ç¼–è¾‘æ—¶ã€‚
2. **Hessian è®¡ç®—å¼€é”€**ï¼šå°½ç®¡ä½¿ç”¨ EK-FAC åŠ é€Ÿï¼Œå¯¹äºæ‹¥æœ‰æ•°åäº¿å‚æ•°çš„åŸºç¡€æ¨¡å‹ï¼ŒHessian æˆ– Fisher çŸ©é˜µçš„å­˜å‚¨ä¸è®¡ç®—ä»æ˜¯ç“¶é¢ˆï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥ç¨€ç–åŒ–æˆ–è¿‘ä¼¼ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† CCBMs æ‰©å±•åˆ°æ›´å¤§è§„æ¨¡çš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ CLIPï¼‰æˆ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„ Hessian è¿‘ä¼¼æ–¹æ³•ï¼Œä»¥é€‚é…è¶…å¤§è§„æ¨¡æ¨¡å‹ã€‚
- ç ”ç©¶å¦‚ä½•å°†äººç±»ä¸“å®¶åé¦ˆè‡ªåŠ¨è½¬åŒ–ä¸ºæ¦‚å¿µå±‚çº§çš„ç¼–è¾‘æŒ‡ä»¤ï¼Œå®ç°æ›´ç´§å¯†çš„ **Human-AI ååŒè¿›åŒ–**ã€‚

> **æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºçš„ **CCBMs** æ˜¯é¦–ä¸ªæ”¯æŒå¤šç²’åº¦ã€é«˜æ•ˆç¼–è¾‘çš„å¯è§£é‡Šæ¨¡å‹æ¡†æ¶ï¼Œä¸ºæ„å»º**åŠ¨æ€ã€å¯æŒç»­ã€å¯ä¿¡çš„ AI ç³»ç»Ÿ**æä¾›äº†åšå®åŸºç¡€ï¼Œæ¨åŠ¨äº†å¯è§£é‡Šäººå·¥æ™ºèƒ½ï¼ˆXAIï¼‰ä»â€œäº‹åè§£é‡Šâ€å‘â€œäº‹ä¸­æ§åˆ¶â€çš„èŒƒå¼è½¬å˜ã€‚

</details>

---

### 16. [A Sparse-Attention Deep Learning Model Integrating Heterogeneous Multimodal Features for Parkinson's Disease Severity Profiling](https://arxiv.org/abs/2601.00519)

**Authors**: Dristi Datta, Tanmoy Debnath, Minh Chau, Manoranjan Paul, Gourab Adhikary, Md Geaur Rahman  
**Category**: cs.LG  
**Published**: 2026-01-05  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.00519v1  

#### Abstract
Characterising the heterogeneous presentation of Parkinson's disease (PD) requires integrating biological and clinical markers within a unified predictive framework. While multimodal data provide complementary information, many existing computational models struggle with interpretability, class imba...

---

### 17. [ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization](https://arxiv.org/abs/2601.00290)

**Authors**: Sixue Xing, Xuanye Xia, Kerui Wu, Meng Jiang, Jintai Chen, Tianfan Fu  
**Category**: cs.AI  
**Published**: 2026-01-05  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.00290v1  

#### Abstract
Clinical trial failure remains a central bottleneck in drug development, where minor protocol design flaws can irreversibly compromise outcomes despite promising therapeutics. Although cutting-edge AI methods achieve strong performance in predicting trial success, they are inherently reactive for me...

---

### 18. [Task-Driven Kernel Flows: Label Rank Compression and Laplacian Spectral Filtering](https://arxiv.org/abs/2601.00276)

**Authors**: Hongxi Li, Chunlin Huang  
**Category**: cs.LG  
**Published**: 2026-01-05  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.00276v1  

#### Abstract
We present a theory of feature learning in wide L2-regularized networks showing that supervised learning is inherently compressive. We derive a kernel ODE that predicts a "water-filling" spectral evolution and prove that for any stable steady state, the kernel rank is bounded by the number of classe...

---

### 19. [Cloud-Native Generative AI for Automated Planogram Synthesis: A Diffusion Model Approach for Multi-Store Retail Optimization](https://arxiv.org/abs/2601.00527)

**Authors**: Ravi Teja Pagidoju, Shriya Agarwal  
**Category**: cs.LG  
**Published**: 2026-01-05  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2601.00527v1  

#### Abstract
Planogram creation is a significant challenge for retail, requiring an average of 30 hours per complex layout. This paper introduces a cloud-native architecture using diffusion models to automatically generate store-specific planograms. Unlike conventional optimization methods that reorganize existi...

---

### 20. [Constructing a Neuro-Symbolic Mathematician from First Principles](https://arxiv.org/abs/2601.00125)

**Authors**: Keqin Xie  
**Category**: cs.AI  
**Published**: 2026-01-05  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2601.00125v1  

#### Abstract
Large Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a diff...

---

### 21. [Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems](https://arxiv.org/abs/2601.00339)

**Authors**: Alaa Saleh, Praveen Kumar Donta, Roberto Morabito, Sasu Tarkoma, Anders Lindgren, Qiyang Zhang, Schahram Dustdar Susanna Pirttikangas, Lauri Lov\'en  
**Category**: cs.AI  
**Published**: 2026-01-05  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2601.00339v1  

#### Abstract
Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to...

---

### 22. [Cost-Performance Analysis of Cloud-Based Retail Point-of-Sale Systems: A Comparative Study of Google Cloud Platform and Microsoft Azure](https://arxiv.org/abs/2601.00530)

**Authors**: Ravi Teja Pagidoju  
**Category**: cs.DC  
**Published**: 2026-01-05  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2601.00530v1  

#### Abstract
Althoughthereislittleempiricalresearchonplatform-specific performance for retail workloads, the digital transformation of the retail industry has accelerated the adoption of cloud-based Point-of-Sale (POS) systems. This paper presents a systematic, repeatable comparison of POS workload deployments o...

---

### 23. [Dynamic Bayesian Optimization Framework for Instruction Tuning in Partial Differential Equation Discovery](https://arxiv.org/abs/2601.00088)

**Authors**: Junqi Qu, Yan Zhang, Shangqian Gao, Shibo Li  
**Category**: cs.LG  
**Published**: 2026-01-05  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2601.00088v1  

#### Abstract
Large Language Models (LLMs) show promise for equation discovery, yet their outputs are highly sensitive to prompt phrasing, a phenomenon we term instruction brittleness. Static prompts cannot adapt to the evolving state of a multi-step generation process, causing models to plateau at suboptimal sol...

---

### 24. [Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings](https://arxiv.org/abs/2601.00186)

**Authors**: Moirangthem Tiken Singh, Adnan Arif  
**Category**: cs.LG  
**Published**: 2026-01-05  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2601.00186v1  

#### Abstract
This paper tackles the pressing challenge of preserving semantic meaning in communication systems constrained by limited bandwidth. We introduce a novel reinforcement learning framework that achieves per-dimension unequal error protection via adaptive repetition coding. Central to our approach is a ...

---

### 25. [Can Optimal Transport Improve Federated Inverse Reinforcement Learning?](https://arxiv.org/abs/2601.00309)

**Authors**: David Millard, Ali Baheri  
**Category**: cs.LG  
**Published**: 2026-01-05  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2601.00309v1  

#### Abstract
In robotics and multi-agent systems, fleets of autonomous agents often operate in subtly different environments while pursuing a common high-level objective. Directly pooling their data to learn a shared reward function is typically impractical due to differences in dynamics, privacy constraints, an...

---

### 26. [The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving](https://arxiv.org/abs/2601.00747)

**Authors**: Max Ruiz Luyten, Mihaela van der Schaar  
**Category**: cs.LG  
**Published**: 2026-01-05  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2601.00747v1  

#### Abstract
State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model's distribution over reas...

---

### 27. [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)

**Authors**: Purushottam Saha, Avirup Chakraborty, Sourish Sarkar, Subhamoy Maitra, Diganta Mukherjee, Tridib Mukherjee  
**Category**: cs.AI  
**Published**: 2026-01-05  
**Score**: 3.5  
**Type**: new  
**ArXiv ID**: 2601.00024v1  

#### Abstract
The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifie...

---

### 28. [Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control](https://arxiv.org/abs/2601.00121)

**Authors**: Yaqi Duan, Yichun Hu, Jiashuo Jiang  
**Category**: cs.AI  
**Published**: 2026-01-05  
**Score**: 3.5  
**Type**: new  
**ArXiv ID**: 2601.00121v1  

#### Abstract
Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs...

---

### 29. [An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making](https://arxiv.org/abs/2601.00142)

**Authors**: Tiansi Dong, Henry He, Pietro Li\`o, Mateja Jamnik  
**Category**: cs.AI  
**Published**: 2026-01-05  
**Score**: 3.5  
**Type**: new  
**ArXiv ID**: 2601.00142v1  

#### Abstract
This paper compares three methodological categories of neural reasoning: LLM reasoning, supervised learning-based reasoning, and explicit model-based reasoning. LLMs remain unreliable and struggle with simple decision-making that animals can master without extensive corpora training. Through disjunc...

---

### 30. [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)

**Authors**: Zongwei Wang, Bincheng Gu, Hongyu Yu, Junliang Yu, Tao He, Jiayin Feng, Min Gao  
**Category**: cs.AI  
**Published**: 2026-01-05  
**Score**: 3.5  
**Type**: new  
**ArXiv ID**: 2601.00240v1  

#### Abstract
LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundam...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
