# ICLR 2026 Papers ðŸ“š

- **Last Updated**: 2025-11-12 07:04:42 UTC
- **Total Filtered Papers**: 18533
- **Papers with Ratings**: 367
- **Total Submissions**: (cached)

Click any title to view the full discussion on OpenReview.

**Configuration**: Filtered by keywords ['LLM', 'RL', 'RLHF', 'Inference', 'Training', 'Attention', 'Pipeline', 'MOE', 'Sparse', 'Quantization', 'Speculative', 'Efficient', 'Efficiency', 'Framework', 'Parallel', 'Distributed', 'Kernel', 'Decode', 'Decoding', 'Prefill', 'Throughput', 'Fast', 'Network', 'Hardware', 'Cluster', 'FP8', 'FP4', 'Optimization', 'Scalable', 'Communication']

> Showing top 500 papers (out of 18533 matching), sorted by keyword relevance score. 367 papers have review ratings.

| # | Title | Avg Rating | Reviews | Decision | OpenReview |
| --- | --- | --- | --- | --- | --- |
| 1 | [Prima.cpp: Fast 30-70B LLM Inference on Heterogeneous and Low-Resource Home Clusters](https://openreview.net/forum?id=h0LjpOG1jq) | 4.67 | 3 | Pending | [Link](https://openreview.net/forum?id=h0LjpOG1jq) |
| 2 | [Sandbox-RL: Scalable Multi-LLMs Optimization through Sandbox-Based Reinforcement Learning](https://openreview.net/forum?id=0pFcKF2li1) | 2.67 | 3 | Pending | [Link](https://openreview.net/forum?id=0pFcKF2li1) |
| 3 | [SALE : Low-bit Estimation for Efficient Sparse Attention in Long-context LLM Prefilling](https://openreview.net/forum?id=yTeDQeuKKz) | 4.00 | 3 | Pending | [Link](https://openreview.net/forum?id=yTeDQeuKKz) |
| 4 | [Sem-MoE: Semantic-aware Model-Data Collaborative Scheduling for Efficient MoE Inference](https://openreview.net/forum?id=MSHPrMpIHZ) | 5.33 | 3 | Pending | [Link](https://openreview.net/forum?id=MSHPrMpIHZ) |
| 5 | [Long-Context Attention Benchmark: From Kernel Efficiency to Distributed Context Parallelism](https://openreview.net/forum?id=W7sVYFJAEp) | 6.00 | 3 | Pending | [Link](https://openreview.net/forum?id=W7sVYFJAEp) |
| 6 | [Pretraining a Large Language Model using Distributed GPUs: A Memory-Efficient Decentralized Paradigm](https://openreview.net/forum?id=RHJVkaIYYa) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=RHJVkaIYYa) |
| 7 | [SVL: Empowering Spiking Neural Networks for Efficient 3D Open-World Understanding](https://openreview.net/forum?id=JYke7CIuIa) | 4.00 | 3 | Pending | [Link](https://openreview.net/forum?id=JYke7CIuIa) |
| 8 | [GRACE-MoE: Grouping and Replication with Locality-Aware Routing for Efficient Distributed MoE Inference](https://openreview.net/forum?id=3Gre3i1tSD) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=3Gre3i1tSD) |
| 9 | [LONGSHIELD: SCALABLE DISTRIBUTED DIFFERENTIALLY PRIVATE TRAINING FOR LONG-CONTEXT LLMS](https://openreview.net/forum?id=1Q2NVxcSuS) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=1Q2NVxcSuS) |
| 10 | [STAR: Speculative Decoding with Searchable Drafting and Target-Aware Refinement for Multimodal Generation](https://openreview.net/forum?id=pMdKnxkFRw) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=pMdKnxkFRw) |
| 11 | [SkipPipe: Partial and Reordered Pipelining Framework for Training LLMs in Heterogeneous Networks](https://openreview.net/forum?id=AtmupAPZ17) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=AtmupAPZ17) |
| 12 | [Breaking the Efficiency-Accuracy: Fusion of Rotation Quantization and N:M Sparsity for LLMs Inference](https://openreview.net/forum?id=h17M5TP0Sg) | 3.33 | 3 | Pending | [Link](https://openreview.net/forum?id=h17M5TP0Sg) |
| 13 | [PureKV: Plug-and-Play KV Cache Optimization with Spatial-Temporal Sparse Attention for Vision-Language Large Models](https://openreview.net/forum?id=XtpVQ21bcY) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=XtpVQ21bcY) |
| 14 | [Cronus: Efficient LLM inference on Heterogeneous GPU Clusters via Partially Disaggregated Prefill](https://openreview.net/forum?id=uN5cHI3kpt) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=uN5cHI3kpt) |
| 15 | [ESSA: Evolutionary Strategies for Scalable Alignment](https://openreview.net/forum?id=1MX3QC0bSH) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=1MX3QC0bSH) |
| 16 | [READER: Retrieval-Assisted Drafter for Efficient LLM Inference](https://openreview.net/forum?id=4GxLFqsIwo) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=4GxLFqsIwo) |
| 17 | [CSAttention: Centroid-Scoring Attention for Accelerating LLM Inference](https://openreview.net/forum?id=CEpNboUJyw) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=CEpNboUJyw) |
| 18 | [Real-time Routing under Partial Observability: Information-Efficient Policies for Connected Vehicles](https://openreview.net/forum?id=UqjoMDJCmM) | 4.40 | 5 | Pending | [Link](https://openreview.net/forum?id=UqjoMDJCmM) |
| 19 | [Mixture-of-Channels: Exploiting Sparse FFNs for Efficient LLMs Pre-Training and Inference](https://openreview.net/forum?id=8DrZ0PHd94) | 4.00 | 3 | Pending | [Link](https://openreview.net/forum?id=8DrZ0PHd94) |
| 20 | [Fast-dLLM v2: Efficient Block-Diffusion LLM](https://openreview.net/forum?id=1NZ3DHF9nT) | 6.00 | 4 | Pending | [Link](https://openreview.net/forum?id=1NZ3DHF9nT) |
| 21 | [SERE: Similarity-based Expert Re-routing for Efficient Batch Decoding in MoE Models](https://openreview.net/forum?id=98IxaUQtMY) | 6.67 | 3 | Pending | [Link](https://openreview.net/forum?id=98IxaUQtMY) |
| 22 | [AsyncSpade: Efficient Test-Time Scaling with Asynchronous Sparse Decoding](https://openreview.net/forum?id=VCtqg9aFaC) | 4.40 | 5 | Pending | [Link](https://openreview.net/forum?id=VCtqg9aFaC) |
| 23 | [Parallel Prompting: Fast LLM Inference for Shared-Context, Short-to-Moderate Output](https://openreview.net/forum?id=T5KBO4IeM2) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=T5KBO4IeM2) |
| 24 | [TAH-QUANT: Effective Activation Quantization in Pipeline Parallelism over Slow Network](https://openreview.net/forum?id=cEkVJeMwSd) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=cEkVJeMwSd) |
| 25 | [Unlocking the Power of Layer By Layer Training For LLM](https://openreview.net/forum?id=Wqbi2pUcvb) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=Wqbi2pUcvb) |
| 26 | [PSPO: Trainable Potential-Based Reward Shaping with Internal Model Signals for Post-Training Policy Optimization of Large Language Models](https://openreview.net/forum?id=UXt9ul6pLJ) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=UXt9ul6pLJ) |
| 27 | [Optimizing LLM Inference Offloading with Hierarchical Scheduling and Dynamic Sparsification](https://openreview.net/forum?id=upV1K9g7JQ) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=upV1K9g7JQ) |
| 28 | [One Stone Three Birds: Training-free Core-context-aware Attention for Efficient LLM Prefilling, Decoding, and KV Caching](https://openreview.net/forum?id=0lGVMSAazo) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=0lGVMSAazo) |
| 29 | [Fed-Energy: Federated Reinforcement Learning for Scalable and Energy-Efficient Large-Scale Code Optimization](https://openreview.net/forum?id=APawIJjJlP) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=APawIJjJlP) |
| 30 | [Long-Context Modeling with Dynamic Hierarchical Sparse Attention for On-Device LLMs](https://openreview.net/forum?id=ZQ9uqllSts) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=ZQ9uqllSts) |
| 31 | [Hierarchy Decoding: A Training-free Parallel Decoding Strategy  for Diffusion Large Language Models](https://openreview.net/forum?id=ZsIQUjQtdW) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=ZsIQUjQtdW) |
| 32 | [Breaking the MoE LLM Trilemma: Dynamic Expert Clustering with Structured Compression](https://openreview.net/forum?id=CwQzoZ1WxH) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=CwQzoZ1WxH) |
| 33 | [LycheeDecode: Accelerating Long-Context LLM Inference via Hybrid-Head Sparse Decoding](https://openreview.net/forum?id=YWCHLdNGVU) | 5.20 | 5 | Pending | [Link](https://openreview.net/forum?id=YWCHLdNGVU) |
| 34 | [Group Think: Collaborative Parallel Reasoning Model](https://openreview.net/forum?id=OZA4zivTFq) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=OZA4zivTFq) |
| 35 | [FOLD: Fast Correct Speculative Decoding](https://openreview.net/forum?id=zm35dmBdok) | 3.33 | 3 | Pending | [Link](https://openreview.net/forum?id=zm35dmBdok) |
| 36 | [AsyncMesh: Fully Asynchronous Optimization for Data and Pipeline Parallelism](https://openreview.net/forum?id=hzikvjtIj4) | 3.33 | 3 | Pending | [Link](https://openreview.net/forum?id=hzikvjtIj4) |
| 37 | [EfficientLLM: Evaluating Large Language Models Efficiency](https://openreview.net/forum?id=DKAUzhGiDa) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=DKAUzhGiDa) |
| 38 | [Adaptive Curriculum Learning for RLHF with Influence-Based Cluster Bandits](https://openreview.net/forum?id=8HvWBamUkS) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=8HvWBamUkS) |
| 39 | [Hierarchical Speculative Decoding through Training-Free Slim-Verifier](https://openreview.net/forum?id=9UsWULey9J) | 2.67 | 3 | Pending | [Link](https://openreview.net/forum?id=9UsWULey9J) |
| 40 | [AURA: Augmented Representation for Unified Accuracy-aware Quantization](https://openreview.net/forum?id=Mc4AIAvS4R) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=Mc4AIAvS4R) |
| 41 | [Optimized Early-Exit Based Speculative Decoding via Pipeline Parallelism](https://openreview.net/forum?id=6ezbdRe90k) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=6ezbdRe90k) |
| 42 | [Sparsity Forcing: Reinforcing Token Sparsity of MLLMs](https://openreview.net/forum?id=gxNTP2eER3) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=gxNTP2eER3) |
| 43 | [OPPO: Accelerating PPO-based RLHF via Pipeline Overlap](https://openreview.net/forum?id=31Mr6wLBeF) | 6.50 | 4 | Pending | [Link](https://openreview.net/forum?id=31Mr6wLBeF) |
| 44 | [UniPruning: Unifying Local Metric and Global Feedback for Scalable Sparse LLMs](https://openreview.net/forum?id=y2QHVETUqJ) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=y2QHVETUqJ) |
| 45 | [Catching the Details: Self-Distilled RoI Predictors for Fine-Grained MLLM Perception](https://openreview.net/forum?id=Cox6AaRyan) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=Cox6AaRyan) |
| 46 | [SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences](https://openreview.net/forum?id=170GODIkgT) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=170GODIkgT) |
| 47 | [Scaling Overhead Matters: Saliency-Aware Graph-Based Efficient Post-Training Quantization for LLMs](https://openreview.net/forum?id=MxFZ57x7Gl) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=MxFZ57x7Gl) |
| 48 | [Cluster Topologyâ€‘Driven Placement of Experts Reduces Network Traffic in MoE Inference](https://openreview.net/forum?id=YW4RkDi5eH) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=YW4RkDi5eH) |
| 49 | [Bridging the Gap Between Promise and Performance for FP4 Quantization](https://openreview.net/forum?id=zCBGe9AqJZ) | 6.50 | 4 | Pending | [Link](https://openreview.net/forum?id=zCBGe9AqJZ) |
| 50 | [Configuring Parallel Training of Neural Networks using Bayesian Optimization](https://openreview.net/forum?id=p2xCepZMyW) | 4.67 | 3 | Pending | [Link](https://openreview.net/forum?id=p2xCepZMyW) |
| 51 | [WiSparse: Boosting LLM Inference Efficiency with Weight-Aware Mixed Activation Sparsity](https://openreview.net/forum?id=I4IaRjKQHy) | 3.33 | 3 | Pending | [Link](https://openreview.net/forum?id=I4IaRjKQHy) |
| 52 | [Tactic: Adaptive Sparse Attention with Clustering and Distribution Fitting for Long-Context LLMs](https://openreview.net/forum?id=tJod11fK1A) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=tJod11fK1A) |
| 53 | [AnyBCQ: Hardware Efficient Flexible Binary-Coded Quantization for Multi-Precision LLMs](https://openreview.net/forum?id=XPIEkFdEDi) | 6.00 | 4 | Pending | [Link](https://openreview.net/forum?id=XPIEkFdEDi) |
| 54 | [OptPipe: Memory- and Scheduling-Optimized Pipeline Parallelism for LLM Training](https://openreview.net/forum?id=0A2rXt5SAy) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=0A2rXt5SAy) |
| 55 | [Dynamic-dLLM: Dynamic Cache-Budget and Adaptive Parallel Decoding for Training-Free Acceleration of Diffusion LLM](https://openreview.net/forum?id=SdnkB5pGbq) | 6.00 | 4 | Pending | [Link](https://openreview.net/forum?id=SdnkB5pGbq) |
| 56 | [PAML: MoE-Based Partitioning and Merging Framework for Solving Large-scale Multi-task VRPs](https://openreview.net/forum?id=Y74tGjpsjq) | 2.00 | 4 | Pending | [Link](https://openreview.net/forum?id=Y74tGjpsjq) |
| 57 | [FSA: An Alternative Efficient Implementation of Native Sparse Attention Kernel](https://openreview.net/forum?id=c5mdo1hWrs) | 7.33 | 3 | Pending | [Link](https://openreview.net/forum?id=c5mdo1hWrs) |
| 58 | [S4NN: Scalable Self-Supervised Spiking Neural Networks](https://openreview.net/forum?id=P1KhPUTceF) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=P1KhPUTceF) |
| 59 | [TINY BUT MIGHTY: A SOFTWARE-HARDWARE CO- DESIGN APPROACH FOR EFFICIENT MULTIMODAL IN- FERENCE ON BATTERY-POWERED SMALL DEVICES](https://openreview.net/forum?id=ql30VWGyda) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=ql30VWGyda) |
| 60 | [Disentangling Token Dependencies for Efficient Decoding in Diffusion Language Models](https://openreview.net/forum?id=0ZSLZWAmWo) | 2.50 | 4 | Pending | [Link](https://openreview.net/forum?id=0ZSLZWAmWo) |
| 61 | [Accelerating Discrete Diffusion Decoding with Parallel Scan](https://openreview.net/forum?id=rQM3oU9cyg) | 4.80 | 5 | Pending | [Link](https://openreview.net/forum?id=rQM3oU9cyg) |
| 62 | [QeRL: Beyond Efficiency - Quantization-enhanced Reinforcement Learning for LLMs](https://openreview.net/forum?id=zw8zxMJJlm) | 6.00 | 4 | Pending | [Link](https://openreview.net/forum?id=zw8zxMJJlm) |
| 63 | [PT$^2$-LLM: Post-Training Ternarization for Large Language Models](https://openreview.net/forum?id=7QZanjCD6M) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=7QZanjCD6M) |
| 64 | [Contrastive-Online-Meta (COM): A Dynamic Adaptation Mechanism for Instruction-Tuned CodeLLMs](https://openreview.net/forum?id=TjF9WLcu8o) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=TjF9WLcu8o) |
| 65 | [FastMTP: Accelerating LLM Inference with Enhanced Multi-Token Prediction](https://openreview.net/forum?id=J7xDwZSyI4) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=J7xDwZSyI4) |
| 66 | [SecP-Tuning: Efficient Privacy-Preserving Prompt Tuning for Large Language Models via MPC](https://openreview.net/forum?id=iJNM7KY8FD) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=iJNM7KY8FD) |
| 67 | [Towards Multiplier-Free Transformers with Stochastic Attention](https://openreview.net/forum?id=CaOaBlq6Bv) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=CaOaBlq6Bv) |
| 68 | [Speculative Actions: A Lossless Framework for Faster AI Agents](https://openreview.net/forum?id=P0GOk5wslg) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=P0GOk5wslg) |
| 69 | [In-Place Test-Time Training](https://openreview.net/forum?id=dTWfCLSoyl) | 7.33 | 3 | Pending | [Link](https://openreview.net/forum?id=dTWfCLSoyl) |
| 70 | [Training-Free Native Sparse Attention for KV Cache Compression](https://openreview.net/forum?id=sQjYtFSEuZ) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=sQjYtFSEuZ) |
| 71 | [Communication-Efficient Multi-Device Inference Acceleration for Transformer Models](https://openreview.net/forum?id=rpblsD3eXG) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=rpblsD3eXG) |
| 72 | [Think Before You Accept: Semantic Reflective Verification for Faster Speculative Decoding](https://openreview.net/forum?id=GkMxEQlWyU) | 4.67 | 3 | Pending | [Link](https://openreview.net/forum?id=GkMxEQlWyU) |
| 73 | [SLAKE: Softmax-Approximated Training-Free Linear Attention with KV-Cache Eviction for Long-Sequence LLMs](https://openreview.net/forum?id=w70fv82Vft) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=w70fv82Vft) |
| 74 | [SCORE: Similarity-Aware Contextual Overlap-Redundancy Eviction for Efficient KV Cache Compression in LLMs](https://openreview.net/forum?id=HTlkxdEDWo) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=HTlkxdEDWo) |
| 75 | [How to Get Spiking LLMs? A Dual ANN-to-SNN Conversion with Layer-Wise Calibration](https://openreview.net/forum?id=nzkObUsajY) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=nzkObUsajY) |
| 76 | [PARD: Accelerating LLM Inference with Lowâ€‘Cost PARallel Draft Model Adaptation](https://openreview.net/forum?id=XbOyv7iVGL) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=XbOyv7iVGL) |
| 77 | [DiFFPO: Training Diffusion LLMs to Reason Fast and Furious via Reinforcement Learning](https://openreview.net/forum?id=ckUU5XySLn) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=ckUU5XySLn) |
| 78 | [QuoKA: Query-Oriented KV Selection for Efficient LLM Prefill](https://openreview.net/forum?id=YS4N1YxXSM) | 6.00 | 4 | Pending | [Link](https://openreview.net/forum?id=YS4N1YxXSM) |
| 79 | [Efficient and Stable Grouped RL Training for Large Language Models](https://openreview.net/forum?id=deSF7BrNli) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=deSF7BrNli) |
| 80 | [Parallel Training in Spiking Neural Networks](https://openreview.net/forum?id=RGxDhp3m0I) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=RGxDhp3m0I) |
| 81 | [AutoL2S: Auto Long-Short Reasoning for Efficient Large Language Models](https://openreview.net/forum?id=LUttHOTlYz) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=LUttHOTlYz) |
| 82 | [TopGQ: Fast GNN Post-Training Quantization Leveraging Topology Information](https://openreview.net/forum?id=IFw1tVHhHM) | 3.33 | 3 | Pending | [Link](https://openreview.net/forum?id=IFw1tVHhHM) |
| 83 | [KVCompose: Efficient Structured KV Cache Compression with Composite Tokens](https://openreview.net/forum?id=GNKIV7oSl2) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=GNKIV7oSl2) |
| 84 | [Evolving Sparsity: Leveraging Token Importance Dynamics for Efficient LLM Decoding with Sparse Attention](https://openreview.net/forum?id=YPjcyMzhE2) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=YPjcyMzhE2) |
| 85 | [Sparse Topology Pairwise Scoring for Large-Scale Multi-Agent Reinforcement Learning](https://openreview.net/forum?id=5IqvMNQaUg) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=5IqvMNQaUg) |
| 86 | [Efficient Multi-turn RL for GUI Agents via Decoupled Training and Adaptive Data Curation](https://openreview.net/forum?id=k6AJ1N7BA2) | 5.33 | 3 | Pending | [Link](https://openreview.net/forum?id=k6AJ1N7BA2) |
| 87 | [Why Should the Server Do It All?: A Scalable, Versatile, and Model-Agnostic Framework for Server-Light DNN Inference over Massively Distributed Clients via Training-Free Intermediate Feature Compression](https://openreview.net/forum?id=KKVCWwurQQ) | 4.00 | 3 | Pending | [Link](https://openreview.net/forum?id=KKVCWwurQQ) |
| 88 | [HiSpec: Hierarchical Speculative Decoding for LLMs](https://openreview.net/forum?id=CYGI23WQjI) | 4.00 | 3 | Pending | [Link](https://openreview.net/forum?id=CYGI23WQjI) |
| 89 | [HoVer: Holistic Verification for Semantic-Aware Speculative Generation](https://openreview.net/forum?id=GQlF9F8HAs) | 3.33 | 3 | Pending | [Link](https://openreview.net/forum?id=GQlF9F8HAs) |
| 90 | [Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing](https://openreview.net/forum?id=t5uLZSRjhF) | 6.00 | 4 | Pending | [Link](https://openreview.net/forum?id=t5uLZSRjhF) |
| 91 | [Layer-wise Sensitivity-aware Sparsity Allocation for Efficient LLM Inference](https://openreview.net/forum?id=erGq3kjCmy) | 5.33 | 3 | Pending | [Link](https://openreview.net/forum?id=erGq3kjCmy) |
| 92 | [Towards Efficient Post-Training Quantization For Large Vision-Language Models Via Token-Wise Redundancy Elimination](https://openreview.net/forum?id=CXVf8Vx2E2) | 4.67 | 3 | Pending | [Link](https://openreview.net/forum?id=CXVf8Vx2E2) |
| 93 | [RaBiT: Residual-Aware Binarization Training for Accurate and Efficient LLMs](https://openreview.net/forum?id=MPMyROJvJV) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=MPMyROJvJV) |
| 94 | [LLMBoost: Make Large Language Models Stronger with Boosting](https://openreview.net/forum?id=giTyBPDKT9) | 4.67 | 3 | Pending | [Link](https://openreview.net/forum?id=giTyBPDKT9) |
| 95 | [AMS-Quant: Adaptive Mantissa Sharing for Floating-Point Quantization](https://openreview.net/forum?id=4vXNp4wujY) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=4vXNp4wujY) |
| 96 | [SpecVLM: Fast Speculative Decoding in Vision-Language Models](https://openreview.net/forum?id=lkMh48jItD) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=lkMh48jItD) |
| 97 | [TAKE: Task-Aware Chunked KV Cache Eviction for Efficient Long-Context LLM Prefill](https://openreview.net/forum?id=kMLfUshPwo) | 4.00 | 3 | Pending | [Link](https://openreview.net/forum?id=kMLfUshPwo) |
| 98 | [A Scalable Distributed Framework for Multimodal GigaVoxel Image Registration](https://openreview.net/forum?id=8dLexnao2h) | 6.50 | 4 | Pending | [Link](https://openreview.net/forum?id=8dLexnao2h) |
| 99 | [Less Is More: Fast and Accurate Reasoning with Cross-Head Unified Sparse Attention](https://openreview.net/forum?id=3iwDzfIk60) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=3iwDzfIk60) |
| 100 | [Ban&Pick: Ehancing Performance and Efficiency of MoE-LLMs via Smarter Routing](https://openreview.net/forum?id=KWMR2YfC55) | 5.33 | 3 | Pending | [Link](https://openreview.net/forum?id=KWMR2YfC55) |
| 101 | [Pretraining with Re-parametrized Self-Attention: Unlocking Generalizationin  SNN-Based Neural Decoding Across Time, Brains, and Tasks](https://openreview.net/forum?id=ZsvGCzpaVD) | 6.00 | 4 | Pending | [Link](https://openreview.net/forum?id=ZsvGCzpaVD) |
| 102 | [BiHDTrans: binary hyperdimensional transformer for efficient multivariate time series classification](https://openreview.net/forum?id=MSEUVDHwL7) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=MSEUVDHwL7) |
| 103 | [Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding](https://openreview.net/forum?id=3Z3Is6hnOT) | 7.00 | 4 | Pending | [Link](https://openreview.net/forum?id=3Z3Is6hnOT) |
| 104 | [UNIVERSAL AND EFFICIENT LOADING BALANCING FOR RL TRAINING OF LARGE MULTIMODAL MODELS](https://openreview.net/forum?id=aa14rlfR6k) | 5.33 | 3 | Pending | [Link](https://openreview.net/forum?id=aa14rlfR6k) |
| 105 | [BTC-LLM: Efficient Sub-1-Bit LLM Quantization via Learnable Transformation and Binary Codebook](https://openreview.net/forum?id=yBDBCpEzsO) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=yBDBCpEzsO) |
| 106 | [Mirror Speculative Decoding: Breaking the Serial Barrier in LLM Inference](https://openreview.net/forum?id=ZAY8HKg5ZK) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=ZAY8HKg5ZK) |
| 107 | [A Unified Federated Framework for Trajectory Data Preparation via LLMs](https://openreview.net/forum?id=MIelckWrEK) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=MIelckWrEK) |
| 108 | [Intra-Prompt Parallel Decoding for Common-Context Question Answering](https://openreview.net/forum?id=mkUJeg7rwA) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=mkUJeg7rwA) |
| 109 | [Improving MoE Performance and Efficiency with Plug-and-Play Intra-Layer Specialization and Cross-Layer Coupling Losses](https://openreview.net/forum?id=nY91ZOfB5M) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=nY91ZOfB5M) |
| 110 | [Verlog: An Efficient Synchronized Multi-turn RL Framework for LLM Agents](https://openreview.net/forum?id=U3yTQonq10) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=U3yTQonq10) |
| 111 | [StatQAT: Statistical Quantizer Optimization for Deep Networks](https://openreview.net/forum?id=tLkqgoNsmb) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=tLkqgoNsmb) |
| 112 | [Batch Speculative Decoding Done Right](https://openreview.net/forum?id=eM51kSFkoG) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=eM51kSFkoG) |
| 113 | [MARchÃ©: Fast Masked Autoregressive Image Generation with Cache-Aware Attention](https://openreview.net/forum?id=1noRScr1uL) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=1noRScr1uL) |
| 114 | [Learning to Reason over Continuous Tokens with Reinforcement Learning](https://openreview.net/forum?id=lebJ6wz1vj) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=lebJ6wz1vj) |
| 115 | [To Compress or Not? Pushing the Frontier of Lossless GenAI Model Weights Compression with Exponent Concentration](https://openreview.net/forum?id=XI1CeufywD) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=XI1CeufywD) |
| 116 | [Quantization Meets Sparsification for Faster Image Generation](https://openreview.net/forum?id=SLBcDQvBbh) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=SLBcDQvBbh) |
| 117 | [GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning](https://openreview.net/forum?id=6RQsAQEUib) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=6RQsAQEUib) |
| 118 | [ICaRus: Identical Cache Reuse for Efficient Multi-Model Inference](https://openreview.net/forum?id=qrMo6R7lOS) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=qrMo6R7lOS) |
| 119 | [MARTI: A Framework for Multi-Agent LLM Systems Reinforced Training and Inference](https://openreview.net/forum?id=E7jZqo0A50) | 5.33 | 6 | Pending | [Link](https://openreview.net/forum?id=E7jZqo0A50) |
| 120 | [PipeTune: Tuning Pipeline Parallelism for Efficient Vision-Language Model Training](https://openreview.net/forum?id=NlizdhvhvM) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=NlizdhvhvM) |
| 121 | [SpSCO: A Speculative Sampling Approach to Neural Combinatorial Optimization](https://openreview.net/forum?id=pBySAuS5H5) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=pBySAuS5H5) |
| 122 | [CudaForge: An Agent Framework with Hardware Feedback for CUDA Kernel Optimization](https://openreview.net/forum?id=f4GtuI2blh) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=f4GtuI2blh) |
| 123 | [TornadoAttention: Hardware-Efficient Sparse Attention via Fine-Grained Spatio-Temporal Permutation for Video Generation](https://openreview.net/forum?id=fx3Ht2gYTR) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=fx3Ht2gYTR) |
| 124 | [ZSMerge: Zero-Shot KV Cache Compression for Memory-Efficient Long-Context LLMs](https://openreview.net/forum?id=WJ5BIKfc5A) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=WJ5BIKfc5A) |
| 125 | [EventFlash: Towards Efficient MLLMs for Event-Based Vision](https://openreview.net/forum?id=QuvGqzLwf6) | 5.33 | 3 | Pending | [Link](https://openreview.net/forum?id=QuvGqzLwf6) |
| 126 | [AR Models can be Faster and More Accurate Parallel Decoders than Diffusion LLMs](https://openreview.net/forum?id=aTyV6Omm6m) | 2.50 | 4 | Pending | [Link](https://openreview.net/forum?id=aTyV6Omm6m) |
| 127 | [ELAS: Efficient Pre-Training of Low-Rank Large Language Models via 2:4 Activation Sparsity](https://openreview.net/forum?id=gvDyT1KucD) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=gvDyT1KucD) |
| 128 | [TrimR: Verifier-based Training-Free Thinking Trimming for Efficient Test-Time Scaling](https://openreview.net/forum?id=ofEkphaqg7) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=ofEkphaqg7) |
| 129 | [GeneLLM: Inheriting 1.25% of MoE-LLMs to Build Models of 8% Size that Retain 80% Performance](https://openreview.net/forum?id=X0CYp42qwx) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=X0CYp42qwx) |
| 130 | [DriveMamba: Task-Centric Scalable State Space Model for Efficient End-to-End Autonomous Driving](https://openreview.net/forum?id=MY0NHvqzi2) | 6.00 | 4 | Pending | [Link](https://openreview.net/forum?id=MY0NHvqzi2) |
| 131 | [MOSS: Efficient and Accurate FP8 LLM Training with Microscaling and Automatic Scaling](https://openreview.net/forum?id=uvgJM9RQ6T) | 5.20 | 5 | Pending | [Link](https://openreview.net/forum?id=uvgJM9RQ6T) |
| 132 | [Lazy-Attention: Efficient Retrieval-Augmented Generation with Deferred Positional Encoding](https://openreview.net/forum?id=DrETNoeqS5) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=DrETNoeqS5) |
| 133 | [Grounding GUI Anything: Efficient and Semantically-Aware Parsing via Continuous Coordinate Decoding](https://openreview.net/forum?id=6ILBhTx26M) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=6ILBhTx26M) |
| 134 | [Unlocking Full Efficiency of Token Filtering in Large Language Model Training](https://openreview.net/forum?id=eshXwEnENV) | 6.00 | 4 | Pending | [Link](https://openreview.net/forum?id=eshXwEnENV) |
| 135 | [End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost](https://openreview.net/forum?id=LUopdQeiz1) | 2.50 | 4 | Pending | [Link](https://openreview.net/forum?id=LUopdQeiz1) |
| 136 | [SpikingLLM: Spiking Large Language Models with Causal Spiking Self-Attention and Spike-Form Knowledge Distillation](https://openreview.net/forum?id=r6fNn987rr) | 4.00 | 3 | Pending | [Link](https://openreview.net/forum?id=r6fNn987rr) |
| 137 | [Scaling Up, Speeding Up: A Benchmark of Speculative Decoding for Efficient LLM Test-Time Scaling](https://openreview.net/forum?id=DjOmnwX4wJ) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=DjOmnwX4wJ) |
| 138 | [RaanA: A Fast, Flexible, and Data-Efficient Post-Training Quantization Algorithm](https://openreview.net/forum?id=CQboQK98DF) | 2.67 | 3 | Pending | [Link](https://openreview.net/forum?id=CQboQK98DF) |
| 139 | [ES-dLLM: Efficient Inference for Diffusion Large Language Models by Early-Skipping](https://openreview.net/forum?id=O2WvMkJbws) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=O2WvMkJbws) |
| 140 | [RESA: Bringing Back What Sparse Attention Ignores with Residual Estimation](https://openreview.net/forum?id=ktcq26hMCH) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=ktcq26hMCH) |
| 141 | [Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding](https://openreview.net/forum?id=YQ5wH5C69t) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=YQ5wH5C69t) |
| 142 | [FastGRPO: Accelerating Policy Optimization via Concurrency-aware Speculative Decoding and Online Draft Learning](https://openreview.net/forum?id=zuGt6TYYtS) | 4.67 | 3 | Pending | [Link](https://openreview.net/forum?id=zuGt6TYYtS) |
| 143 | [Flash-Searcher: Fast and Effective Web Agents via DAG-Based Parallel Execution](https://openreview.net/forum?id=QuaJ6kJaBm) | 5.60 | 5 | Pending | [Link](https://openreview.net/forum?id=QuaJ6kJaBm) |
| 144 | [MXSens: Sensitivity-Aware Mixed-Precision Quantization for Efficient LLM Inference](https://openreview.net/forum?id=883lVZEH6m) | 2.00 | 3 | Pending | [Link](https://openreview.net/forum?id=883lVZEH6m) |
| 145 | [MatMuls are Enough for Efficient and Performant Linear-Time Attention](https://openreview.net/forum?id=IVk47syp1Q) | 2.50 | 4 | Pending | [Link](https://openreview.net/forum?id=IVk47syp1Q) |
| 146 | [ParoQuant: Pairwise Rotation Quantization for Efficient Reasoning LLM Inference](https://openreview.net/forum?id=1USeVjsKau) | 7.00 | 4 | Pending | [Link](https://openreview.net/forum?id=1USeVjsKau) |
| 147 | [Beyond Pixels: Efficient Dataset Distillation via Sparse Gaussian Representation](https://openreview.net/forum?id=S77KqxyEEj) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=S77KqxyEEj) |
| 148 | [QuRL: Low-Precision Reinforcement Learning for Efficient Reasoning](https://openreview.net/forum?id=eG0bpCwdKn) | 5.33 | 3 | Pending | [Link](https://openreview.net/forum?id=eG0bpCwdKn) |
| 149 | [BMAttn: Block-Aligned Mixed-Precision  Attention Quantization for LLM Inference](https://openreview.net/forum?id=isBH8kP5AX) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=isBH8kP5AX) |
| 150 | [BiMoEï¼šPushing the Limit of Post-Training Quantization for MoE-based LLMs](https://openreview.net/forum?id=GdnlENuK0D) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=GdnlENuK0D) |
| 151 | [Breaking Memory and Communication Barriers in Model-Parallel Fine-Tuning of Large Language Models](https://openreview.net/forum?id=FF3o9flavI) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=FF3o9flavI) |
| 152 | [Semantic-Aware Diffusion LLM Inference With Adaptive Block Size](https://openreview.net/forum?id=0Cv9PwL7cI) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=0Cv9PwL7cI) |
| 153 | [Dynamic Incremental Code Embeddings (DICE):  A Real-Time Communication Protocol for Multi-Agent Reinforcement Learning](https://openreview.net/forum?id=lFaLBotlag) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=lFaLBotlag) |
| 154 | [Accelerated Predictive Coding Networks via Direct Kolenâ€“Pollack Feedback Alignment](https://openreview.net/forum?id=MCeZ4k7J6M) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=MCeZ4k7J6M) |
| 155 | [Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models](https://openreview.net/forum?id=NCN8oUsiNf) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=NCN8oUsiNf) |
| 156 | [Compact Yet Capable: Do Multitask-Based Multi-Teacher Distillation with Precision-Controlled Task-Specific Dynamic PTQ Outperform Static Quantization for Low-Resource Multitask NLU?](https://openreview.net/forum?id=jJqvrZX5g5) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=jJqvrZX5g5) |
| 157 | [MoEEdit: Efficient and Routing-Stable Knowledge Editing for Mixture-of-Experts LLMs](https://openreview.net/forum?id=BV4oHxGBx7) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=BV4oHxGBx7) |
| 158 | [Efficiently Solving the TSP in One-Shot Without Post-Processing](https://openreview.net/forum?id=VrXOym8iiA) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=VrXOym8iiA) |
| 159 | [MC-LoRA: Fast Modular Composition for Multi-Character Diffusion Generation](https://openreview.net/forum?id=dZWzpYwK7l) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=dZWzpYwK7l) |
| 160 | [BrainDistill: Implantable Motor Decoding with Task-Specific Knowledge Distillation](https://openreview.net/forum?id=DqZDRf6qJ9) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=DqZDRf6qJ9) |
| 161 | [DPad: Efficient Diffusion Language Models with Suffix Dropout](https://openreview.net/forum?id=0yOsSMU1eY) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=0yOsSMU1eY) |
| 162 | [LLM as a Classifier: Leveraging Large Language Models for Text and Vision Classification](https://openreview.net/forum?id=78WdKlYSeO) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=78WdKlYSeO) |
| 163 | [DISTRIBUTED MULTI-AGENT DEEP REINFORCEMENT LEARNING](https://openreview.net/forum?id=fotzssBy3o) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=fotzssBy3o) |
| 164 | [Communication Efficient LLM Pre-Training with SparseLoCo](https://openreview.net/forum?id=gBppFpDjyW) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=gBppFpDjyW) |
| 165 | [DSA: Efficient Inference For Video Generation Models via Distributed Sparse Attention](https://openreview.net/forum?id=1ZmdfDzGE1) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=1ZmdfDzGE1) |
| 166 | [Accelerating Diffusion Language Models Inference via Local Determinism Propagation](https://openreview.net/forum?id=XURWY9K3ZS) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=XURWY9K3ZS) |
| 167 | [variCOT: Variational Inference for Implicit Chain-of-Thought in Language Models](https://openreview.net/forum?id=NpKyLOcFCX) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=NpKyLOcFCX) |
| 168 | [Zero-Shot Cross-Domain Dialogue State Tracking with Small LLMs: Learning to Think through Reinforcement Learning](https://openreview.net/forum?id=SLLZPhnEz6) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=SLLZPhnEz6) |
| 169 | [KVLinC: KV Cache Quantization with Hadamard Rotation and Linear Correction](https://openreview.net/forum?id=FkaDML963W) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=FkaDML963W) |
| 170 | [FINE-GRAINED ENERGY PREDICTION FOR PARALLELIZED LLM INFERENCE WITH PIE-P](https://openreview.net/forum?id=aPJeT2Ii3u) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=aPJeT2Ii3u) |
| 171 | [AutoMixQ: Automatic Mixed-precision Quantization for Deploying Bit-Efficient LLMs](https://openreview.net/forum?id=nW5Z8F2iOY) | 2.00 | 3 | Pending | [Link](https://openreview.net/forum?id=nW5Z8F2iOY) |
| 172 | [From Sequential to Parallel: Reformulating Dynamic Programming as GPU Kernels for Large-Scale Stochastic Combinatorial Optimization](https://openreview.net/forum?id=T9FDmsmoBj) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=T9FDmsmoBj) |
| 173 | [ERIS: Enhancing Privacy and Communication Efficiency in Serverless Federated Learning](https://openreview.net/forum?id=fHpRtccY4I) | 4.67 | 3 | Pending | [Link](https://openreview.net/forum?id=fHpRtccY4I) |
| 174 | [SAISA: Towards Multimodal Large Language Models with Both Training and Inference Efficiency](https://openreview.net/forum?id=TJbfURjxyL) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=TJbfURjxyL) |
| 175 | [What Layers When: Learning to Skip Compute in LLMs with Residual Gates](https://openreview.net/forum?id=aiP6XfaYZR) | 6.00 | 4 | Pending | [Link](https://openreview.net/forum?id=aiP6XfaYZR) |
| 176 | [RepSpec: Structural Re-parameterized Draft Model Training for Speculative Decoding](https://openreview.net/forum?id=bqEi97qzzz) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=bqEi97qzzz) |
| 177 | [Scale-Distribution Decoupling: Enabling Stable and Effective Training of Large Language Models](https://openreview.net/forum?id=I2fqa6381g) | 4.40 | 5 | Pending | [Link](https://openreview.net/forum?id=I2fqa6381g) |
| 178 | [Provably Communication-Efficient Federated Graph Neural Network](https://openreview.net/forum?id=TZBof1S00t) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=TZBof1S00t) |
| 179 | [Efficient Spatially-Variant Convolution via Differentiable Sparse Kernel Complex](https://openreview.net/forum?id=bbuxDoRD2D) | 6.00 | 4 | Pending | [Link](https://openreview.net/forum?id=bbuxDoRD2D) |
| 180 | [Swift-FedGNN: Federated Graph Learning with Low Communication and Sample Complexities](https://openreview.net/forum?id=W8NolHzJQc) | 5.00 | 6 | Pending | [Link](https://openreview.net/forum?id=W8NolHzJQc) |
| 181 | [PHOENIX: Photonic Distillation Transfers Electronic Knowledge to Hybrid Optical Neural Networks](https://openreview.net/forum?id=J36Tagukno) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=J36Tagukno) |
| 182 | [Scaling Laws Meet Model Architecture: Toward Inference-Efficient LLMs](https://openreview.net/forum?id=0TmVqOpBbK) | 6.50 | 4 | Pending | [Link](https://openreview.net/forum?id=0TmVqOpBbK) |
| 183 | [Agent-REINFORCE: Searching Compute-Optimal Multi-LLM Collaboration Graph for Test-Time Scaling](https://openreview.net/forum?id=9G8Rhlp1AD) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=9G8Rhlp1AD) |
| 184 | [SCAR: Shapley Credit Assignment for More Efficient RLHF](https://openreview.net/forum?id=6OxvdqP6RH) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=6OxvdqP6RH) |
| 185 | [Self-Speculative Decoding Accelerates Lossless Inference in Any-Order and Any-Subset Autoregressive Models](https://openreview.net/forum?id=hZnibTOke7) | 6.67 | 3 | Pending | [Link](https://openreview.net/forum?id=hZnibTOke7) |
| 186 | [Rep3D: Re-parameterize Large 3D Kernels with Low-Rank Receptive Modeling for Medical Imaging](https://openreview.net/forum?id=PCqsBzhMTg) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=PCqsBzhMTg) |
| 187 | [Not All Rollouts are Useful: Down-Sampling Rollouts in LLM Reinforcement Learning](https://openreview.net/forum?id=lXDg6quPKT) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=lXDg6quPKT) |
| 188 | [Efficient Resource-Constrained Training of Vision Transformers via Subspace Optimization](https://openreview.net/forum?id=0nvQ5kHXf4) | 6.00 | 3 | Pending | [Link](https://openreview.net/forum?id=0nvQ5kHXf4) |
| 189 | [KerZOO: Kernel Function Informed Zeroth-Order Optimization for Accurate and Accelerated LLM Fine-Tuning](https://openreview.net/forum?id=aN3rmWuMtf) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=aN3rmWuMtf) |
| 190 | [FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference](https://openreview.net/forum?id=wXAn7orB1H) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=wXAn7orB1H) |
| 191 | [Layer-Wise High-Impact Parameter Ratio Optimization in Post-Training Quantization for Large Language Models](https://openreview.net/forum?id=PDRVVcBZvE) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=PDRVVcBZvE) |
| 192 | [BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation](https://openreview.net/forum?id=O9J20MsmRl) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=O9J20MsmRl) |
| 193 | [Optimizing Mixture of Block Attention](https://openreview.net/forum?id=ndrUH7IF3L) | 4.67 | 3 | Pending | [Link](https://openreview.net/forum?id=ndrUH7IF3L) |
| 194 | [Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime](https://openreview.net/forum?id=SpJfgugXGt) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=SpJfgugXGt) |
| 195 | [Identifying and Mitigating Errors in Gradient Aggregation of Distributed Data Parallel Training](https://openreview.net/forum?id=zOgUQM6uLZ) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=zOgUQM6uLZ) |
| 196 | [Forge: Compiling a Unified Abstraction into Scalable Kernels for Linear Attention](https://openreview.net/forum?id=N4jJQvQSiN) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=N4jJQvQSiN) |
| 197 | [Sliding Window Attention for Reinforced Reasoning](https://openreview.net/forum?id=lHw9TvC3bq) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=lHw9TvC3bq) |
| 198 | [DynamicInfer: Runtime-Aware Sparse Offloading for LLMs Inference on a Consumer-Grade GPU](https://openreview.net/forum?id=CvjmvjlczZ) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=CvjmvjlczZ) |
| 199 | [SNaX: sparse narrow accelerated mixture of experts](https://openreview.net/forum?id=KzTJ1raEgB) | 6.00 | 3 | Pending | [Link](https://openreview.net/forum?id=KzTJ1raEgB) |
| 200 | [Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in Speed](https://openreview.net/forum?id=kIbFgoCq86) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=kIbFgoCq86) |
| 201 | [Sample-efficient LLM Optimization with Reset Replay](https://openreview.net/forum?id=0SSKmVjj8O) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=0SSKmVjj8O) |
| 202 | [KVComm: Enabling Efficient LLM Communication through Selective KV Sharing](https://openreview.net/forum?id=F7rUng23nw) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=F7rUng23nw) |
| 203 | [SyncKV: A Syncopated Scheduling Approach to KV Cache Compression for Efficient Long-Context LLM Inference](https://openreview.net/forum?id=542c8KxeQt) | 3.33 | 3 | Pending | [Link](https://openreview.net/forum?id=542c8KxeQt) |
| 204 | [FlexibleLLM: Making Low-Bit Quantization for Large Language Models More Flexible and Efficient](https://openreview.net/forum?id=Y05UeKa0XC) | 4.80 | 5 | Pending | [Link](https://openreview.net/forum?id=Y05UeKa0XC) |
| 205 | [HT-Sparse: Training-Free Query-Guided Headâ€“Token Sparsification for Long-Video Multimodal Inference](https://openreview.net/forum?id=3Oc8Pg7Kij) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=3Oc8Pg7Kij) |
| 206 | [NLI : Non-uniform Linear Interpolation Approximation of Nonlinear Operations for Efficient LLMs Inference](https://openreview.net/forum?id=SuJdcjOjgP) | 5.33 | 3 | Pending | [Link](https://openreview.net/forum?id=SuJdcjOjgP) |
| 207 | [RAST-MoE-RL: A Regime-Aware Spatio-Temporal MoE Framework for Deep Reinforcement Learning in Ride-Hailing](https://openreview.net/forum?id=xQRAo9YUQ3) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=xQRAo9YUQ3) |
| 208 | [Rectified Sparse Attention for Efficient Long-Sequence Generation](https://openreview.net/forum?id=mtg9P13kOc) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=mtg9P13kOc) |
| 209 | [Scale-DiT: Ultra-High-Resolution Image Generation with Hierarchical Local Attention](https://openreview.net/forum?id=nk33zCmbH7) | 5.33 | 3 | Pending | [Link](https://openreview.net/forum?id=nk33zCmbH7) |
| 210 | [Accelerating Diffusion Large Language Models with SlowFast Sampling: The Three Golden Principles](https://openreview.net/forum?id=Uh17FiwF4q) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=Uh17FiwF4q) |
| 211 | [R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning](https://openreview.net/forum?id=h1t9kRSbLb) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=h1t9kRSbLb) |
| 212 | [STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer](https://openreview.net/forum?id=RTTYGeC2Io) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=RTTYGeC2Io) |
| 213 | [Bridging Draft Policy Misalignment: Group Tree Optimization  for Speculative Decoding](https://openreview.net/forum?id=dwPdYFqVWO) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=dwPdYFqVWO) |
| 214 | [Channel-Aware Mixed-Precision Quantization for Efficient Long-Context Inference](https://openreview.net/forum?id=yjr2jX41qO) | 4.00 | 3 | Pending | [Link](https://openreview.net/forum?id=yjr2jX41qO) |
| 215 | [Holistic Token Efficient in Speculative Decoding: Post-use & Pre-cut](https://openreview.net/forum?id=ELhSQC3BJE) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=ELhSQC3BJE) |
| 216 | [Prospective Learning: Memory-Efficient MLP Training via Brain-Inspired Direct Optimization](https://openreview.net/forum?id=VVstc2W3RW) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=VVstc2W3RW) |
| 217 | [dParallel: Learnable Parallel Decoding for dLLMs](https://openreview.net/forum?id=hVOcstAURb) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=hVOcstAURb) |
| 218 | [Wide-In, Narrow-Out: Revokable Decoding for Efficient and Effective DLLMs](https://openreview.net/forum?id=XtLQHlNLxy) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=XtLQHlNLxy) |
| 219 | [MobileWizard: A Data-Efficient GUI Agent with Structured Reasoning and Progressive Reinforcement Learning](https://openreview.net/forum?id=Aobvdp3XmP) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=Aobvdp3XmP) |
| 220 | [PLUMAGE: probablistic low-rank unbiased min variance gradient estimation framework for efficient large model training](https://openreview.net/forum?id=3Tdj7p9uK3) | 4.67 | 3 | Pending | [Link](https://openreview.net/forum?id=3Tdj7p9uK3) |
| 221 | [Analytical Restructuring of Feed-Forward Networks for Accelerated LLM Inference](https://openreview.net/forum?id=Mv3TjqaRZA) | 2.67 | 3 | Pending | [Link](https://openreview.net/forum?id=Mv3TjqaRZA) |
| 222 | [ARC-Decode: Risk-Bounded Acceptance for Sampling-Based Speculative Decoding](https://openreview.net/forum?id=jhJjW2DFKD) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=jhJjW2DFKD) |
| 223 | [FASTer: Toward Powerful and Efficient Autoregressive Visionâ€“Languageâ€“Action Models with Learnable Action Tokenizer and Block-wise Decoding](https://openreview.net/forum?id=k6nTUFoqeT) | 6.50 | 4 | Pending | [Link](https://openreview.net/forum?id=k6nTUFoqeT) |
| 224 | [NeurIPS: Neuro-anatomical Inductive Priors for Sphere-based Vision Brain Decoding](https://openreview.net/forum?id=CZQJl1bUf7) | 4.00 | 3 | Pending | [Link](https://openreview.net/forum?id=CZQJl1bUf7) |
| 225 | [Adaptive Inferenceâ€‘Time Scaling for LRMs using Uncertaintyâ€‘Aware RL](https://openreview.net/forum?id=0WdN7pFCja) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=0WdN7pFCja) |
| 226 | [Data-Efficient Generalization and Faster Initial Learning in Quantum Models for Classifying Cellular Activation States](https://openreview.net/forum?id=c4ir92gYjv) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=c4ir92gYjv) |
| 227 | [HEX: Merging Heavy-Hitters and Expanders for Adaptive KV Cache Optimization in Long-Context Inference](https://openreview.net/forum?id=YtBJHVbxf8) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=YtBJHVbxf8) |
| 228 | [FedHyMoe: Hypernetwork-Driven Mixture-of-Experts for Federated Domain Generalization](https://openreview.net/forum?id=t3FSGlOcsG) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=t3FSGlOcsG) |
| 229 | [Exploring Expert Concentration for Parameter-efficient Fine-tuning of Mixture-of-Expert LLMs](https://openreview.net/forum?id=zBgjWTWgCh) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=zBgjWTWgCh) |
| 230 | [ProxyAttn: Guided Sparse Attention via Representative Heads](https://openreview.net/forum?id=m3HXHQYmZu) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=m3HXHQYmZu) |
| 231 | [DXFeat: Depth-Aware Features for Robust Image Matching](https://openreview.net/forum?id=NAN0I3pNWk) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=NAN0I3pNWk) |
| 232 | [Spectral Annealing for Scalable Ising Model Optimization](https://openreview.net/forum?id=atoLVj3fZY) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=atoLVj3fZY) |
| 233 | [Binary Oscillation-Regulated Network (BORN): Approach for Binary Neural Networks Training](https://openreview.net/forum?id=uSNaiJmFLZ) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=uSNaiJmFLZ) |
| 234 | [Designing Observation and Action Models for Efficient Reinforcement Learning with LLMs](https://openreview.net/forum?id=v1tTJN2svr) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=v1tTJN2svr) |
| 235 | [Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers](https://openreview.net/forum?id=TfwePIKzXJ) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=TfwePIKzXJ) |
| 236 | [DASH: Deterministic Attention Scheduling for High-throughput Reproducible LLM Training](https://openreview.net/forum?id=bMi5ssfPoM) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=bMi5ssfPoM) |
| 237 | [NorMuon: Making Muon more efficient and scalable](https://openreview.net/forum?id=7TeJXgr7L6) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=7TeJXgr7L6) |
| 238 | [CodeQuant: Unified Clustering and Quantization for Enhanced Outlier Smoothing in Low-Precision Mixture-of-Experts](https://openreview.net/forum?id=ATpchFiBQi) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=ATpchFiBQi) |
| 239 | [HiPO: Self-Hint Policy Optimization for RLVR](https://openreview.net/forum?id=rcb20pHmT1) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=rcb20pHmT1) |
| 240 | [TwinShield: Secure Foundation Model Execution by Unifying TEEs and Crypto-protected Accelerators](https://openreview.net/forum?id=nCJF1CDapQ) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=nCJF1CDapQ) |
| 241 | [TRACEALIGN - Tracing the Drift: Attributing Alignment Failures to Training-Time Belief Sources in LLMs](https://openreview.net/forum?id=6mzS7NAiui) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=6mzS7NAiui) |
| 242 | [Beyond the Efficiency-Performance Trade-off: Semantic Foundation Attention](https://openreview.net/forum?id=lRBfkbrLzu) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=lRBfkbrLzu) |
| 243 | [HAIPR: A High-Throughput Affinity Prediction Framework](https://openreview.net/forum?id=6cHUf3Dnxr) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=6cHUf3Dnxr) |
| 244 | [Learning to Evict from Key-Value Cache](https://openreview.net/forum?id=t7lJ2OEGbJ) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=t7lJ2OEGbJ) |
| 245 | [Training-Free Self-Scheduling for Efficient LLM Inference Serving](https://openreview.net/forum?id=hZmG4z68Je) | 3.60 | 5 | Pending | [Link](https://openreview.net/forum?id=hZmG4z68Je) |
| 246 | [Learning to Parallel: Accelerating Diffusion Large Language Models via Adaptive Parallel Decoding](https://openreview.net/forum?id=bFJ8Sdr224) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=bFJ8Sdr224) |
| 247 | [Metis: Training LLMs with FP4 Quantization](https://openreview.net/forum?id=I2ZrCi5O84) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=I2ZrCi5O84) |
| 248 | [Learning Semi-Structured Sparsity for LLMs via Shared and Context-Aware Hypernetwork](https://openreview.net/forum?id=lqjQs2lVNm) | 6.00 | 4 | Pending | [Link](https://openreview.net/forum?id=lqjQs2lVNm) |
| 249 | [FlashVSR: Towards Real-time Diffusion-Based Streaming Video Super-Resolution](https://openreview.net/forum?id=gzynHSyjUe) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=gzynHSyjUe) |
| 250 | [BiCoLoR: Communication-Efficient Optimization with Bidirectional Compression and Local Training](https://openreview.net/forum?id=bFnWKXCBFN) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=bFnWKXCBFN) |
| 251 | [Token-Efficient Long-Term Interest Sketching and Internalized Reasoning for LLM-based Recommendation](https://openreview.net/forum?id=NVrXCKaEjM) | 4.67 | 3 | Pending | [Link](https://openreview.net/forum?id=NVrXCKaEjM) |
| 252 | [SERQ: Saliency-Aware Low-Rank Error Reconstruction for LLM Quantization](https://openreview.net/forum?id=nFjj8NEBqv) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=nFjj8NEBqv) |
| 253 | [Forging Better Rewards: A Multi-Agent LLM Framework for Automated Reward Evolution](https://openreview.net/forum?id=Z6GStCfccl) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=Z6GStCfccl) |
| 254 | [SALF & TALF: Optimized Loss Function and Drafting for Tree-based Speculative Decoding](https://openreview.net/forum?id=3V559xWIWc) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=3V559xWIWc) |
| 255 | [A Dendritic-Inspired Network Science Generative Model for Topological Initialization of Connectivity in Sparse Artificial Neural Networks](https://openreview.net/forum?id=xgZvbugPBA) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=xgZvbugPBA) |
| 256 | [Task-Related Token Compression in Multimodal Large Language Models from an Explainability Perspective](https://openreview.net/forum?id=YULeQtSyiW) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=YULeQtSyiW) |
| 257 | [HiPO: Hybrid Policy Optimization for Dynamic Reasoning in LLMs](https://openreview.net/forum?id=txF1Z2cVMZ) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=txF1Z2cVMZ) |
| 258 | [InferSpec: Adaptive Inference-Time Compute with Ensemble Verifier-Guided Speculative Decoding for Efficient Reasoning](https://openreview.net/forum?id=sxeAVcWpNu) | 4.00 | 3 | Pending | [Link](https://openreview.net/forum?id=sxeAVcWpNu) |
| 259 | [Data- and Hardware-Aware Entanglement Selection for Quantum Feature Maps in Hybrid Quantum Neural Networks](https://openreview.net/forum?id=9E0ioSxB7s) | 2.50 | 4 | Pending | [Link](https://openreview.net/forum?id=9E0ioSxB7s) |
| 260 | [SpecOffload: Unlocking Latent GPU Capacity for LLM Inference on Resource-Constrained Devices](https://openreview.net/forum?id=rVrWNb2XLi) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=rVrWNb2XLi) |
| 261 | [CAR-LoRA: Training Compression-Aware and Robust LoRA Adapters for Evolving LLMs](https://openreview.net/forum?id=5GimteSrgW) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=5GimteSrgW) |
| 262 | [ClimateLLM: Efficient Weather Forecasting via Frequency-Aware Large Language Models](https://openreview.net/forum?id=MGy6FHMqnd) | 4.67 | 3 | Pending | [Link](https://openreview.net/forum?id=MGy6FHMqnd) |
| 263 | [HybridCoT: Interleaving Latent and Text Chain-of-Thought for Efficient Reasoning](https://openreview.net/forum?id=4mfGbMzTwu) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=4mfGbMzTwu) |
| 264 | [Zeros can be Informative: Masked Binary U-Net for Image Segmentation on Tensor Cores](https://openreview.net/forum?id=VG55KBaUDo) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=VG55KBaUDo) |
| 265 | [ParaSMoE: Enabling Parallelism Hot-Switch for Large Mixture-of-Experts Models](https://openreview.net/forum?id=PuwLIxUTDq) | 2.50 | 4 | Pending | [Link](https://openreview.net/forum?id=PuwLIxUTDq) |
| 266 | [FAFO: Lossy KV Cache Compression for Lossless Inference Acceleration via Draftless Fumble Decoding](https://openreview.net/forum?id=oSk9tP5Mgs) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=oSk9tP5Mgs) |
| 267 | [Asymmetric Proximal Policy Optimization: mini-critics boost LLM reasoning](https://openreview.net/forum?id=0vgzrcv4Dr) | 4.67 | 3 | Pending | [Link](https://openreview.net/forum?id=0vgzrcv4Dr) |
| 268 | [Federated Bayesian Optimization based on Secure Distributed Gaussian Processes](https://openreview.net/forum?id=gBT9HqV5n3) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=gBT9HqV5n3) |
| 269 | [Highly Efficient and Effective LLMs with Multi-Boolean Architectures](https://openreview.net/forum?id=r0CH5dF3Se) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=r0CH5dF3Se) |
| 270 | [Toward Bit-Efficient Dataset Condensation: A General Framework](https://openreview.net/forum?id=0qVu2WsDle) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=0qVu2WsDle) |
| 271 | [Fed-SB: A Silver Bullet for Extreme Communication Efficiency and Performance in (Private) Federated LoRA Fine-Tuning](https://openreview.net/forum?id=FXxva35wtF) | 3.33 | 3 | Pending | [Link](https://openreview.net/forum?id=FXxva35wtF) |
| 272 | [VRouter: Micro-batch Level Load Balance via Inter-EP Routing for MoE Training](https://openreview.net/forum?id=h3Uq2wZ20c) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=h3Uq2wZ20c) |
| 273 | [Activation-aware Probe-Query: Effective Key-Value Retrieval for Long-Context LLMs Inference](https://openreview.net/forum?id=5E2iFvO6bH) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=5E2iFvO6bH) |
| 274 | [FedMOPA: Federated Multi-Objective Preference Alignment for Large Language Models](https://openreview.net/forum?id=tHcbl0UuxC) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=tHcbl0UuxC) |
| 275 | [MindVL: Towards Efficient and Effective Training of Multimodal Large Language Models on Ascend NPUs](https://openreview.net/forum?id=frMCrXOioZ) | 2.50 | 4 | Pending | [Link](https://openreview.net/forum?id=frMCrXOioZ) |
| 276 | [GTD: Dynamic Generation of Multi LLM Agents Communication Topologies with Graph Diffusion Models](https://openreview.net/forum?id=Co3qyiiLSR) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=Co3qyiiLSR) |
| 277 | [Stabilizing Policy Gradients for Sample-Efficient Reinforcement Learning in LLM Reasoning](https://openreview.net/forum?id=iIvPuXoDs1) | 5.33 | 3 | Pending | [Link](https://openreview.net/forum?id=iIvPuXoDs1) |
| 278 | [Skill Weaving: Efficient Self-Improvement of LLMs via Modular Skillpacks](https://openreview.net/forum?id=1caMYRbkKx) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=1caMYRbkKx) |
| 279 | [Scaling Linear Attention with Sparse State Expansion](https://openreview.net/forum?id=R6DrJ4tnGV) | 6.00 | 4 | Pending | [Link](https://openreview.net/forum?id=R6DrJ4tnGV) |
| 280 | [DLLMQuant: A Post-Training Quantization Framework Tailored for Diffusion-Based Large Language Models](https://openreview.net/forum?id=UmdmJRGb9u) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=UmdmJRGb9u) |
| 281 | [Partition Generative Modeling: Masked Modeling Without Masks](https://openreview.net/forum?id=vEh1ceS154) | 7.00 | 4 | Pending | [Link](https://openreview.net/forum?id=vEh1ceS154) |
| 282 | [Auto-Rubric: Learning to Extract Generalizable Criteria for Reward Modeling](https://openreview.net/forum?id=Ksxvz8XLVi) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=Ksxvz8XLVi) |
| 283 | [DFA-VLA: Enhancing Robotic Manipulation via Embodied Intelligence](https://openreview.net/forum?id=OMdvdULJuA) | 1.50 | 4 | Pending | [Link](https://openreview.net/forum?id=OMdvdULJuA) |
| 284 | [LinAJD: Scalable Gradient-Free Jailbreak Defense via Linearly Separable Embeddings](https://openreview.net/forum?id=W4BwSXVxhp) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=W4BwSXVxhp) |
| 285 | [RACER: Retrieval-Augmented Contextual Rapid Speculative Decoding](https://openreview.net/forum?id=i8SjqQQOVt) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=i8SjqQQOVt) |
| 286 | [MicroMix: Efficient Mixed-Precision Quantization with Microscaling Formats for Large Language Models](https://openreview.net/forum?id=P5OKoZdwlB) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=P5OKoZdwlB) |
| 287 | [Model Parallelism With Subnetwork Data Parallelism](https://openreview.net/forum?id=on9jR4Dx2L) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=on9jR4Dx2L) |
| 288 | [LAMP: Long-tailed Multimodal Prompt Learning for Vision-Language Models](https://openreview.net/forum?id=amBzV6V3tQ) | 2.67 | 3 | Pending | [Link](https://openreview.net/forum?id=amBzV6V3tQ) |
| 289 | [FlashVID: Efficient Video Large Language Models via Training-free Tree-based Spatiotemporal Token Merging](https://openreview.net/forum?id=H6rDX4w6Al) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=H6rDX4w6Al) |
| 290 | [LoopServe:  An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues](https://openreview.net/forum?id=iyIzaoDVrT) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=iyIzaoDVrT) |
| 291 | [RAPID$^3$: Tri-Level Reinforced Acceleration Policies for Diffusion Transformer](https://openreview.net/forum?id=sQ0g6EkpF7) | 5.33 | 3 | Pending | [Link](https://openreview.net/forum?id=sQ0g6EkpF7) |
| 292 | [Self Speculative Decoding for Diffusion Large Language Model](https://openreview.net/forum?id=rKJ7A30lQQ) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=rKJ7A30lQQ) |
| 293 | [MedAlign: Clinician-Centered Federated Meta-Learning for Medical IoT with Privacy and Interpretability Guarantees](https://openreview.net/forum?id=H5DhRrKUDh) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=H5DhRrKUDh) |
| 294 | [Efficient LLM Architectures](https://openreview.net/forum?id=CXdZIcZyTo) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=CXdZIcZyTo) |
| 295 | [HSA: Head-wise Sparse Attention for Efficient and Accurate Long-context Inference](https://openreview.net/forum?id=WytruI9uM3) | 2.50 | 4 | Pending | [Link](https://openreview.net/forum?id=WytruI9uM3) |
| 296 | [APRIL: Active Partial Rollouts in Reinforcement Learning to Tame Long-tail Generation](https://openreview.net/forum?id=0viCNELbrf) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=0viCNELbrf) |
| 297 | [Johnson-Lindenstrauss Lemma Guided Network for Efficient 3D Medical Segmentation](https://openreview.net/forum?id=fmWlDfCFMR) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=fmWlDfCFMR) |
| 298 | [QuS: Towards High-Performance EfficientViT on FPGA by  Quantization and Streamline Co-Design](https://openreview.net/forum?id=B2DRmwStm9) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=B2DRmwStm9) |
| 299 | [Lumos-1: On Autoregressive Video Generation with Discrete Diffusion from a Unified Model Perspective](https://openreview.net/forum?id=wWAxwSCKR2) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=wWAxwSCKR2) |
| 300 | [NeRV-Diffusion: Diffuse Implicit Neural Representation for Video Synthesis](https://openreview.net/forum?id=tX0cSOvBnS) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=tX0cSOvBnS) |
| 301 | [GRPO-MA: Multi-Answer Generation in GRPO for Stable and Efficient Chain-of-Thought Training](https://openreview.net/forum?id=Qr9FAtcpeR) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=Qr9FAtcpeR) |
| 302 | [VAMO: Efficient Zeroth-Order Variance Reduction for SGD with Faster Convergence](https://openreview.net/forum?id=h5gwkhrIO9) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=h5gwkhrIO9) |
| 303 | [SQ-format: A Unified Sparse-Quantized Hardware-friendly Data Format for Large Language Models](https://openreview.net/forum?id=MPybJCVrgc) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=MPybJCVrgc) |
| 304 | [LinearSR: Unlocking Linear Attention for Stable and Efficient Image Super-Resolution](https://openreview.net/forum?id=41Pdz4r5aB) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=41Pdz4r5aB) |
| 305 | [FLoE: Fisher-Based Layer Selection for Efficient Sparse Adaptation of Low-Rank Experts](https://openreview.net/forum?id=AiNeKuyuUy) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=AiNeKuyuUy) |
| 306 | [SparseSSM: Efficient Selective Structured State Space Models Can Be Pruned in One-Shot](https://openreview.net/forum?id=bzb9OJVfCP) | 4.80 | 5 | Pending | [Link](https://openreview.net/forum?id=bzb9OJVfCP) |
| 307 | [KBVQ-MoE: KLT-guided SVD with Bias-Corrected Vector Quantization for MoE Large Language Models](https://openreview.net/forum?id=veFs5UfYq9) | 5.20 | 5 | Pending | [Link](https://openreview.net/forum?id=veFs5UfYq9) |
| 308 | [Large Kernel Network for Image Restoration](https://openreview.net/forum?id=HPiQvBu0u1) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=HPiQvBu0u1) |
| 309 | [DyCodeExplainer: Explainable Dynamic Graph Attention for Multi-Agent Reinforcement Learning in Collaborative Coding](https://openreview.net/forum?id=U7pWkp90qA) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=U7pWkp90qA) |
| 310 | [From Divergence to Normalized Similarity:A Symmetric and Scalable Topological Toolkit for Representation Analysis](https://openreview.net/forum?id=n3u7PK2kyd) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=n3u7PK2kyd) |
| 311 | [From Text to Talk: Audio-Language Model Needs Non-Autoregressive Joint Training](https://openreview.net/forum?id=e3XLWHFrnr) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=e3XLWHFrnr) |
| 312 | [Rethinking the High-Throughput LLM Inference: An Opportunity for Speculative Decoding](https://openreview.net/forum?id=59OJOgKLzN) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=59OJOgKLzN) |
| 313 | [SWAN: Sparse Winnowed Attention for Reduced Inference Memory via Decompression-Free KV-Cache Compression](https://openreview.net/forum?id=eWuRZ51gpr) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=eWuRZ51gpr) |
| 314 | [Diagonal Batching Unlocks Parallelism in Recurrent Memory Transformers for Long Contexts](https://openreview.net/forum?id=z1yPH2Rska) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=z1yPH2Rska) |
| 315 | [PD-FS:Surrogate-Enhanced Physical Data-Driven Framework for Rapid Deep Reinforcement Learning Control](https://openreview.net/forum?id=ZL5sLJBMrV) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=ZL5sLJBMrV) |
| 316 | [Zeroth-Order Forward-Only SNN Training Inspiring Neuromorphic On-Chip Learning](https://openreview.net/forum?id=OQf4ZnPizX) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=OQf4ZnPizX) |
| 317 | [Aligning Draft and Target in Speculative Decoding: A CoT-Aware and SR-Guided Mixed Framework](https://openreview.net/forum?id=bKau2NNrji) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=bKau2NNrji) |
| 318 | [FlexParallel: Automatic Parallelism Tuner via Grey-Box Optimization for Training Giant Models](https://openreview.net/forum?id=IjZdj6vL7G) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=IjZdj6vL7G) |
| 319 | [TNT: Improving Chunkwise Training for Test-Time Memorization](https://openreview.net/forum?id=rajioNWfRs) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=rajioNWfRs) |
| 320 | [HsysGNN: Optimizing Distributed Training of Graph Neural Networks in Heterogeneous Systems](https://openreview.net/forum?id=M95aEq14sm) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=M95aEq14sm) |
| 321 | [LaDiR: Latent Diffusion Enhances LLMs for Text Reasoning](https://openreview.net/forum?id=z5cPEZ4n6i) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=z5cPEZ4n6i) |
| 322 | [WatchLog: From a Glimpse to Decisionâ€”Rapid Event Reasoning in Endpoint Detection and Response Logs with Multimodal LLMs](https://openreview.net/forum?id=323SIitB3Z) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=323SIitB3Z) |
| 323 | [FedAgent-HPO: Agentic Hyperparameter Optimization for Personalized Federated Learning](https://openreview.net/forum?id=q78jTz1JDy) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=q78jTz1JDy) |
| 324 | [GALE: Gradient Activation Low-rank Extraction for Fast Memory Efficient Large Language Model Training](https://openreview.net/forum?id=D9Oq3c5iHn) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=D9Oq3c5iHn) |
| 325 | [HAP-E: HESSIAN-AWARE STRUCTURED PRUNING OF LLMS FOR EFFICIENT INFERENCE](https://openreview.net/forum?id=B0C0bt2R7l) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=B0C0bt2R7l) |
| 326 | [Task2Vec Readiness: Diagnostics for Federated Learning Performance from Pre-Training Embeddings](https://openreview.net/forum?id=20AhTUawvx) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=20AhTUawvx) |
| 327 | [AutoSP: Unlocking Long-Context LLM Training Via Compiler-Based Sequence Parallelism](https://openreview.net/forum?id=0fgsHvmBBI) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=0fgsHvmBBI) |
| 328 | [MoEs Are Stronger than You Think: Hyper-Parallel Inference Scaling with RoE](https://openreview.net/forum?id=WGtroamPgq) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=WGtroamPgq) |
| 329 | [Draft, Verify, \& Improve: Toward Training-Aware Speculative Decoding](https://openreview.net/forum?id=CwvY6TXLxr) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=CwvY6TXLxr) |
| 330 | [Pluto: A Benchmark for Evaluating Efficiency of LLM-generated Hardware Code](https://openreview.net/forum?id=2LmXLuCDsY) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=2LmXLuCDsY) |
| 331 | [Inpainting-Guided Policy Optimization for Diffusion Large Language Models](https://openreview.net/forum?id=haVf5e4Q6C) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=haVf5e4Q6C) |
| 332 | [The Curious Case of In-Training Compression of State Space Models](https://openreview.net/forum?id=LtzmeSMBTW) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=LtzmeSMBTW) |
| 333 | [Distilling to Hybrid Attention Models via KL-Guided Layer Selection](https://openreview.net/forum?id=RzbsHcFqIf) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=RzbsHcFqIf) |
| 334 | [REFRAG: Rethinking RAG based Decoding](https://openreview.net/forum?id=uOi0MHNrwo) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=uOi0MHNrwo) |
| 335 | [AutoHete: An Automatic and Efficient Heterogeneous Training System for LLMs](https://openreview.net/forum?id=LP8Mx7fEOa) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=LP8Mx7fEOa) |
| 336 | [SparseSkeleton: Prefill sparse attention by decomposition](https://openreview.net/forum?id=Y5kgP4x20k) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=Y5kgP4x20k) |
| 337 | [TokenTune: Dual-Level Utility Estimation for Scalable Data Selection in Instruction Tuning](https://openreview.net/forum?id=LoPF9Zl7ic) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=LoPF9Zl7ic) |
| 338 | [GRIT: Graph-Biased Transformers for Hardware-Aware Quantum Layout via Reinforcement Learning Search](https://openreview.net/forum?id=gck2KraCk7) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=gck2KraCk7) |
| 339 | [GLDS: Globalâ€“Local Diversity Selection for Scalable Token Pruning in Visionâ€“Language Models](https://openreview.net/forum?id=eqGluItwma) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=eqGluItwma) |
| 340 | [Echo Flow Networks with Infinite-Horizon Memory](https://openreview.net/forum?id=Vj1ZEBsStT) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=Vj1ZEBsStT) |
| 341 | [Leveraging Pretrained Knowledge at Inference Time: LoRA-Gated Contrastive Decoding for Multilingual Factual Language Generation in Adapted LLMs](https://openreview.net/forum?id=vzlDdOzXAh) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=vzlDdOzXAh) |
| 342 | [MesaNet: Sequence Modeling by Locally Optimal Test-Time Training](https://openreview.net/forum?id=xa3OnTb6c3) | 6.50 | 4 | Pending | [Link](https://openreview.net/forum?id=xa3OnTb6c3) |
| 343 | [ChunkLLM: A Lightweight Pluggable Framework for Accelerating LLMs Inference](https://openreview.net/forum?id=5WHpJmo1W1) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=5WHpJmo1W1) |
| 344 | [Fast training of accurate physics-informed neural networks without gradient descent](https://openreview.net/forum?id=3VdSuh3sie) | 7.00 | 4 | Pending | [Link](https://openreview.net/forum?id=3VdSuh3sie) |
| 345 | [Energy Efficient Language Models through Dynamic Sparsity](https://openreview.net/forum?id=0apbqOrxV8) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=0apbqOrxV8) |
| 346 | [Spiking Decision Making Bottleneck for Offline Reinforcement Learning With Spiking Neural Networks](https://openreview.net/forum?id=1n10BIjgQx) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=1n10BIjgQx) |
| 347 | [Alignment-Enhanced Integration of Connectivity and Spectral Sparse in Dynamic Sparse Training of LLM](https://openreview.net/forum?id=jZplmg7Ad9) | 5.33 | 3 | Pending | [Link](https://openreview.net/forum?id=jZplmg7Ad9) |
| 348 | [Mixture of Sparse Attention: Content-Based Learnable Sparse Attention via MoEs](https://openreview.net/forum?id=FlAdTTRnWY) | 2.67 | 3 | Pending | [Link](https://openreview.net/forum?id=FlAdTTRnWY) |
| 349 | [Sparse Imagination for Efficient Visual World Model Planning](https://openreview.net/forum?id=faxcxKINBC) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=faxcxKINBC) |
| 350 | [Parallax: Efficient LLM Inference Service over Decentralized Environment](https://openreview.net/forum?id=1PhUigVew4) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=1PhUigVew4) |
| 351 | [Polymorphic: Plug-and-Play Visual Token Compression for Scalable VLMs](https://openreview.net/forum?id=Px0UrEUcFQ) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=Px0UrEUcFQ) |
| 352 | [Compensate, Don't Reconstruct: Parameter- and Data-Efficient 2-bit LLM Quantization](https://openreview.net/forum?id=zcK14OnlcK) | 3.67 | 6 | Pending | [Link](https://openreview.net/forum?id=zcK14OnlcK) |
| 353 | [Quantization with Purpose: Loss-Aware Bit Allocation for Gradient Compression](https://openreview.net/forum?id=0wCTDqkK8I) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=0wCTDqkK8I) |
| 354 | [Where Matters More Than What: Decoding-aligned KV Cache Compression via Position-aware Pseudo-queries](https://openreview.net/forum?id=ZpgyPxdxiL) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=ZpgyPxdxiL) |
| 355 | [STARK: Strategic Team of Agents for Refining Kernels](https://openreview.net/forum?id=nWaZTH1JMx) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=nWaZTH1JMx) |
| 356 | [Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning](https://openreview.net/forum?id=RUL1g6CfMh) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=RUL1g6CfMh) |
| 357 | [Quantum Attention: Fast Algorithms for Scalable Computation](https://openreview.net/forum?id=i75XGv8oqj) | 2.00 | 4 | Pending | [Link](https://openreview.net/forum?id=i75XGv8oqj) |
| 358 | [TransES-ETA: A Novel Transformer-based Explainable and Efficient Structure for Predicting Estimated Time of Vessel Arrival](https://openreview.net/forum?id=kk1zGINaBC) | 2.00 | 4 | Pending | [Link](https://openreview.net/forum?id=kk1zGINaBC) |
| 359 | [Mitigating Non-IID Drift in Zeroth-Order Federated LLM Fine-Tuning with Transferable Sparsity](https://openreview.net/forum?id=2DuMBKVbX2) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=2DuMBKVbX2) |
| 360 | [UniAero: A Unified Framework for Global Drag and Local Flow Field Prediction](https://openreview.net/forum?id=fBA27vZrlV) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=fBA27vZrlV) |
| 361 | [CAED-Agent: an Agentic Framework to Automate Simulation-Based Experimental Design](https://openreview.net/forum?id=nGihWDdQFI) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=nGihWDdQFI) |
| 362 | [End-to-End Video Generative Modeling with Scalable Normalizing Flows](https://openreview.net/forum?id=qsffecsbJg) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=qsffecsbJg) |
| 363 | [NeuroLifting: Neural Inference on Markov Random Fields at Scale](https://openreview.net/forum?id=W0IgKPMWjj) | 3.33 | 3 | Pending | [Link](https://openreview.net/forum?id=W0IgKPMWjj) |
| 364 | [AgentRace: Benchmarking Efficiency in LLM Agent Frameworks](https://openreview.net/forum?id=eUuxWAQA5F) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=eUuxWAQA5F) |
| 365 | [Local Linear Attention: An Optimal Interpolation of Linear and Softmax Attention For Test-Time Regression](https://openreview.net/forum?id=WGpzi489XY) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=WGpzi489XY) |
| 366 | [OPTIMA: Optimal One-shot Pruning for LLMs via Quadratic Programming Reconstruction](https://openreview.net/forum?id=Gmq7rQllpD) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=Gmq7rQllpD) |
| 367 | [Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning](https://openreview.net/forum?id=xBlHiHdXap) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=xBlHiHdXap) |
| 368 | [Aligning Frozen LLMs by Reinforcement Learning: An Iterative Reweight-then-Optimize Approach](https://openreview.net/forum?id=cQR0d0CnH9) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=cQR0d0CnH9) |
| 369 | [Eye Gaze Tells You Where to Compute: Gaze-Driven Efficient VLMs](https://openreview.net/forum?id=ggRGEOgkAX) | 2.50 | 4 | Pending | [Link](https://openreview.net/forum?id=ggRGEOgkAX) |
| 370 | [LEAP: Learning Expert Adaptation & Pruning for Task-Specialized MoE Language Models](https://openreview.net/forum?id=HDu9u0gYxh) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=HDu9u0gYxh) |
| 371 | [Divid: Disentangled Spatial-Temporal Modeling within LLMs for Temporally Grounded Video Understanding](https://openreview.net/forum?id=mrViXFfrsU) | 4.67 | 3 | Pending | [Link](https://openreview.net/forum?id=mrViXFfrsU) |
| 372 | [Test-Time Training Done Right](https://openreview.net/forum?id=Tb9qAxT3xv) | 5.60 | 5 | Pending | [Link](https://openreview.net/forum?id=Tb9qAxT3xv) |
| 373 | [Importance Sampling Optimization Improves Online Preference Learning](https://openreview.net/forum?id=9OZNqYwrbm) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=9OZNqYwrbm) |
| 374 | [Understanding Efficiency: Quantization, Batching, and Serving Strategies in LLM Energy Use](https://openreview.net/forum?id=m1lq5lg6r1) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=m1lq5lg6r1) |
| 375 | [SpecBranch: Speculative Decoding via Hybrid Drafting and Rollback-Aware Branch Parallelism](https://openreview.net/forum?id=BrnlCSqO6n) | 6.00 | 4 | Pending | [Link](https://openreview.net/forum?id=BrnlCSqO6n) |
| 376 | [Cascadia: An Efficient Cascade Serving System for Large Language Models](https://openreview.net/forum?id=wkrWbrHTJQ) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=wkrWbrHTJQ) |
| 377 | [DRDFL: Divide-and-conquer Collaboration for Efficient Ring-topology Decentralized Federated Learning](https://openreview.net/forum?id=TaThyuCLk7) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=TaThyuCLk7) |
| 378 | [Fastcar: Cache Attentive Replay for Fast Auto-Regressive Video Generation on the Edge](https://openreview.net/forum?id=9f3Nukn6BA) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=9f3Nukn6BA) |
| 379 | [M$^2$GenCO: Multi-task Meta Learning for Generative Combinatorial Optimization](https://openreview.net/forum?id=GM5eCjgJyh) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=GM5eCjgJyh) |
| 380 | [LouisKV: Efficient KV Cache Retrieval for Long Input-Output Sequences](https://openreview.net/forum?id=6RJ8fZwm4P) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=6RJ8fZwm4P) |
| 381 | [Boost Post-Training Quantization via Null Space Optimization for Large Language Models](https://openreview.net/forum?id=2NbpGdeMP7) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=2NbpGdeMP7) |
| 382 | [Rethinking LLM Reasoning: From Explicit Trajectories to Latent Representations](https://openreview.net/forum?id=CbK7lYbmv8) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=CbK7lYbmv8) |
| 383 | [iFlame: Interleaving Full and Linear Attention for Efficient Mesh Generation](https://openreview.net/forum?id=NmxEQakIPK) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=NmxEQakIPK) |
| 384 | [MambaVoiceCloning: Efficient and Expressive Text-to-Speech via State-Space Modeling and Diffusion Control](https://openreview.net/forum?id=0oXyMbPMtP) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=0oXyMbPMtP) |
| 385 | [DiffAdapt: Difficulty-Adaptive Reasoning for Token-Efficient LLM Inference](https://openreview.net/forum?id=644FH1vVIl) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=644FH1vVIl) |
| 386 | [GRF-LLM: Environment-Aware Wireless Channel Modeling via LLM-Guided 3D Gaussians](https://openreview.net/forum?id=DmCof7cMTc) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=DmCof7cMTc) |
| 387 | [Prot2Token: A Unified Framework for Protein Modeling via Next-Token Prediction](https://openreview.net/forum?id=DBAGS8ZU21) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=DBAGS8ZU21) |
| 388 | [S2GO: Streaming Sparse Gaussian Occupancy](https://openreview.net/forum?id=z8ggdMlSco) | 7.00 | 4 | Pending | [Link](https://openreview.net/forum?id=z8ggdMlSco) |
| 389 | [Microscope: Efficient Diffusion with Two-Stage Dynamics Compression for High-Quality Talking Head Generation](https://openreview.net/forum?id=MOiS7FKbl2) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=MOiS7FKbl2) |
| 390 | [Tequila: Deadzone-free Ternary Quantization for Large Language Models](https://openreview.net/forum?id=9CZzD5LWdy) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=9CZzD5LWdy) |
| 391 | [Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle](https://openreview.net/forum?id=mYP33u1QBK) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=mYP33u1QBK) |
| 392 | [Rethinking the Role of Dynamic Sparse Training for Scalable Deep Reinforcement Learning](https://openreview.net/forum?id=k7NhBrsjwn) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=k7NhBrsjwn) |
| 393 | [DIFFSPARSE: ACCELERATING DIFFUSION TRANSFORMERS WITH LEARNED TOKEN SPARSITY](https://openreview.net/forum?id=V3eUas3VCL) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=V3eUas3VCL) |
| 394 | [NeUQI: Near-Optimal Uniform Quantization Parameter Initialization](https://openreview.net/forum?id=KraMpsli1q) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=KraMpsli1q) |
| 395 | [PDTrim: Targeted Pruning for Prefill-Decode Disaggregation in Inference](https://openreview.net/forum?id=qhLjdFHdXm) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=qhLjdFHdXm) |
| 396 | [DPQuant: Efficient and Private Model Training via Dynamic Quantization Scheduling](https://openreview.net/forum?id=neaxYXGYd5) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=neaxYXGYd5) |
| 397 | [EvoEngineer: Mastering Automated CUDA Kernel Code Evolution with Large Language Models](https://openreview.net/forum?id=LU27DiW5ik) | 2.00 | 4 | Pending | [Link](https://openreview.net/forum?id=LU27DiW5ik) |
| 398 | [Reasoning Language Model Inference Serving Unveiled: An Empirical Study](https://openreview.net/forum?id=6CGjZYp6ft) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=6CGjZYp6ft) |
| 399 | [Reinforcement Unlearning via Group Relative Policy Optimization](https://openreview.net/forum?id=BjWwqPE7mk) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=BjWwqPE7mk) |
| 400 | [Towards Lossless Memory-efficient Training of Spiking Neural Networks via Gradient Checkpointing and Spike Compression](https://openreview.net/forum?id=nrBJ0Uvj7c) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=nrBJ0Uvj7c) |
| 401 | [PROMPTGNN-SIM: DEEP FUSION AND ALIGNMENT OF GNN AND LLMS FOR TEXT-ATTRIBUTED GRAPH LEARNING](https://openreview.net/forum?id=EQsJwLbGo5) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=EQsJwLbGo5) |
| 402 | [High-Fidelity and Generalizable Neural Surface Reconstruction with Sparse Scene Representations](https://openreview.net/forum?id=m6W5SfQXrT) | 3.33 | 3 | Pending | [Link](https://openreview.net/forum?id=m6W5SfQXrT) |
| 403 | [Retrospective Sparse Attention for Efficient Long-Context Generation](https://openreview.net/forum?id=Ql0G1Zsobn) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=Ql0G1Zsobn) |
| 404 | [Make It Efficient: Dynamic Sparse Attention for Autoregressive Image Generation](https://openreview.net/forum?id=fBbJHLjhBU) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=fBbJHLjhBU) |
| 405 | [TurboBoA: Faster and Exact Attention-aware Quantization without Backpropagation](https://openreview.net/forum?id=HA0TnV8r7x) | 4.80 | 5 | Pending | [Link](https://openreview.net/forum?id=HA0TnV8r7x) |
| 406 | [Chain-of-Learngene: A Scalable Learngene-based Paradigm for Building and Initializing Variable-Sized Language Models](https://openreview.net/forum?id=UEamVVlLBd) | 4.00 | 3 | Pending | [Link](https://openreview.net/forum?id=UEamVVlLBd) |
| 407 | [Certifiable Safe RLHF: Fixed-Penalty Constraint Optimization for Safer Language Models](https://openreview.net/forum?id=LwdxjLUa64) | 3.33 | 3 | Pending | [Link](https://openreview.net/forum?id=LwdxjLUa64) |
| 408 | [Grouped-head latenT Attention](https://openreview.net/forum?id=zS9Fwi8Ta9) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=zS9Fwi8Ta9) |
| 409 | [TyphoonMLA: A Mixed Naive-Absorb MLA Kernel For Shared Prefix](https://openreview.net/forum?id=ZfCCwJ4Wcs) | 6.00 | 3 | Pending | [Link](https://openreview.net/forum?id=ZfCCwJ4Wcs) |
| 410 | [E$^3$-Pruner: Towards Efficient, Economical, and Effective Layer Pruning for Large Language Models](https://openreview.net/forum?id=zYqpnm20jB) | 4.40 | 5 | Pending | [Link](https://openreview.net/forum?id=zYqpnm20jB) |
| 411 | [SentKVCompress: Sentence-Level Dynamic KVCache Compression for Efficient Long-Context LLM Inference](https://openreview.net/forum?id=T0ii3nAxk4) | 2.50 | 4 | Pending | [Link](https://openreview.net/forum?id=T0ii3nAxk4) |
| 412 | [BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens](https://openreview.net/forum?id=ahatk5qrmB) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=ahatk5qrmB) |
| 413 | [Beyond Redundancy: Diverse and Specialized Multi-Expert Sparse Autoencoder](https://openreview.net/forum?id=et2JRQYkGA) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=et2JRQYkGA) |
| 414 | [Sparse-Art: Enabling Interactable Articulated Objects from Unposed Sparse-View Input](https://openreview.net/forum?id=Q0Q8WPKF8C) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=Q0Q8WPKF8C) |
| 415 | [Efficient-SAM2: Accelerating SAM2 with Object-Aware Visual Encoding and Memory Retrieval](https://openreview.net/forum?id=HcivRSezJp) | 5.33 | 3 | Pending | [Link](https://openreview.net/forum?id=HcivRSezJp) |
| 416 | [Scam2Prompt: A Scalable Framework for Auditing Malicious Scam Endpoints in Production LLMs](https://openreview.net/forum?id=CaUHFOa4X1) | 5.20 | 5 | Pending | [Link](https://openreview.net/forum?id=CaUHFOa4X1) |
| 417 | [PerturbFormer: Adversarial Graph Transformers for Scalable and Resilient Representation Learning](https://openreview.net/forum?id=TUd4vln0we) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=TUd4vln0we) |
| 418 | [Mixture-of-Transformers Learn Faster: A Theoretical Study on Classification Problems](https://openreview.net/forum?id=eqvlxO1sKT) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=eqvlxO1sKT) |
| 419 | [Decomposing Policy Optimization into Proxy Objective and Knowledge Distillation for Long-context Reasoning](https://openreview.net/forum?id=XAoht8iLj9) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=XAoht8iLj9) |
| 420 | [FlowBind: Efficient Any-to-Any Generation with Bidirectional Flows](https://openreview.net/forum?id=7DeARTwvwL) | 6.00 | 4 | Pending | [Link](https://openreview.net/forum?id=7DeARTwvwL) |
| 421 | [From Bits to Chips: An LLM-based Hardware-Aware Quantization Agent for Streamlined Deployment of LLMs](https://openreview.net/forum?id=sYxct6G8Ut) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=sYxct6G8Ut) |
| 422 | [FineRMOE: Dimension Expansion for Finer-Grained Expert with Its Upcycling Approach](https://openreview.net/forum?id=JxXy3YGSln) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=JxXy3YGSln) |
| 423 | [Scalable Training for Vector-Quantized Networks with 100% Codebook Utilization](https://openreview.net/forum?id=juM14y0caI) | 6.00 | 5 | Pending | [Link](https://openreview.net/forum?id=juM14y0caI) |
| 424 | [d$^2$Cache: Accelerating Diffusion-Based LLMs via Dual Adaptive Caching](https://openreview.net/forum?id=SjInfpK5RM) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=SjInfpK5RM) |
| 425 | [Clapping: Removing Per-sample Storage for Pipeline Parallel Distributed Optimization with Communication Compression](https://openreview.net/forum?id=yOkek71cG5) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=yOkek71cG5) |
| 426 | [TTOM: Test-Time Optimization and Memorization for Compositional Video Generation](https://openreview.net/forum?id=wqCwcTZsrv) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=wqCwcTZsrv) |
| 427 | [Decide When Ready: Stepwise Incremental Inference with Early-Exit in Spiking Neural Networks](https://openreview.net/forum?id=LUnYc9Grm8) | 5.00 | 4 | Pending | [Link](https://openreview.net/forum?id=LUnYc9Grm8) |
| 428 | [AUTOTRITON: Automatic Triton Programming with Reinforcement Learning in LLMs](https://openreview.net/forum?id=8m6yY1ULKh) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=8m6yY1ULKh) |
| 429 | [Diffusion Language Model Knows the Answer Before It Decodes](https://openreview.net/forum?id=g88nt4ieTG) | 6.50 | 4 | Pending | [Link](https://openreview.net/forum?id=g88nt4ieTG) |
| 430 | [VividFace: High-Quality and Efficient One-Step Diffusion For Video Face Enhancement](https://openreview.net/forum?id=qCEfTg5nUx) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=qCEfTg5nUx) |
| 431 | [Training-Free Loosely Speculative Decoding: Accepting Semantically Correct Drafts Beyond Exact Match](https://openreview.net/forum?id=JjoTg34YiU) | 6.50 | 4 | Pending | [Link](https://openreview.net/forum?id=JjoTg34YiU) |
| 432 | [QuantSparse: Comprehensively Compressing Video Diffusion Transformer with Model Quantization and Attention Sparsification](https://openreview.net/forum?id=4TAG3aQljJ) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=4TAG3aQljJ) |
| 433 | [Distributed Specialization: Rare-Token Neurons in Large Language Models](https://openreview.net/forum?id=ONGhOee3qt) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=ONGhOee3qt) |
| 434 | [Extending Foundation Models to Low-Resource Languages: Vocabulary Expansion and Policy Optimization](https://openreview.net/forum?id=2pMmCDYPQi) | 4.67 | 3 | Pending | [Link](https://openreview.net/forum?id=2pMmCDYPQi) |
| 435 | [Native Adaptive Solution Expansion for Diffusion-based Combinatorial Optimization](https://openreview.net/forum?id=084SvT55yk) | 6.67 | 3 | Pending | [Link](https://openreview.net/forum?id=084SvT55yk) |
| 436 | [On Discriminative vs. Generative classifiers: Rethinking MLLMs for Action Understanding](https://openreview.net/forum?id=ppceQOZrAX) | 5.33 | 3 | Pending | [Link](https://openreview.net/forum?id=ppceQOZrAX) |
| 437 | [OmniSAT: Compact Action Token, Faster Auto Regression](https://openreview.net/forum?id=CuzTXLB7Jz) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=CuzTXLB7Jz) |
| 438 | [CaRe-BN: Precise Moving Statistics for Stabilizing Spiking Neural Networks in Reinforcement Learning](https://openreview.net/forum?id=AaZVrbElhC) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=AaZVrbElhC) |
| 439 | [EmboMatrix: A Scalable Training-Ground for Embodied Decision-Making](https://openreview.net/forum?id=9qQ5mabsCE) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=9qQ5mabsCE) |
| 440 | [Improving Language Agents through BREW: Bootstrapping expeRientially-learned Environmental knoWledge](https://openreview.net/forum?id=gmmHn5nFvK) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=gmmHn5nFvK) |
| 441 | [ECO: Enhanced Code Optimization via Performance-Aware Prompting for Code-LLMs](https://openreview.net/forum?id=R5L1TD1Z58) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=R5L1TD1Z58) |
| 442 | [Random Controlled Differential Equations](https://openreview.net/forum?id=kHqt0ZSbKT) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=kHqt0ZSbKT) |
| 443 | [FastFlow: Accelerating The Generative Flow Matching Models with Bandit Inference](https://openreview.net/forum?id=wWkyL8D9xd) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=wWkyL8D9xd) |
| 444 | [A Theory of Training Parameter-Shared Quantum Neural Networks from a Bayesian Perspective](https://openreview.net/forum?id=e0qqNM7GtY) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=e0qqNM7GtY) |
| 445 | [VIPO-R1: Cultivating Video Reasoning in MLLMs via Verifier-Guided Iterative Policy Optimization](https://openreview.net/forum?id=Zyy2wbKd8h) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=Zyy2wbKd8h) |
| 446 | [MoEsturizer: Resource-Efficient MoE Upcycling for Small Language Models](https://openreview.net/forum?id=HDZ2GBwrWo) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=HDZ2GBwrWo) |
| 447 | [From Scarcity to Efficiency: Preference-Guided Learning for Sparse-Reward Multi-Agent Reinforcement Learning](https://openreview.net/forum?id=7ei1uOYUY0) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=7ei1uOYUY0) |
| 448 | [ST-SimDiff: Balancing Spatiotemporal Similarity and Difference for Efficient Video Understanding with MLLMs](https://openreview.net/forum?id=he8kYNcoMA) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=he8kYNcoMA) |
| 449 | [RECTOR: Masked Region-Channel-Temporal Modeling for Cognitive Representation Learning](https://openreview.net/forum?id=wxDIEcPow9) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=wxDIEcPow9) |
| 450 | [FLORA: Generalizable Motion-Flow-Based Reward Shaping for Scalable Real-World Robot Learning](https://openreview.net/forum?id=sQr1ILkL02) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=sQr1ILkL02) |
| 451 | [Whisfusion: Parallel ASR Decoding via a Diffusion Transformer](https://openreview.net/forum?id=JCujsFnDS7) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=JCujsFnDS7) |
| 452 | [GraphKAN: An Efficient and Interpretable Kolmogorov-Arnold Graph Network for Source Detection](https://openreview.net/forum?id=qpHDnFUsJo) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=qpHDnFUsJo) |
| 453 | [Efficient Quantization of Mixture-of-Experts with Theoretical Generalization Guarantees](https://openreview.net/forum?id=yiMlVBAoQi) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=yiMlVBAoQi) |
| 454 | [LLM-CoT Enhanced Graph Neural Recommendation with Harmonized Group Policy Optimization](https://openreview.net/forum?id=D43tkBzpuw) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=D43tkBzpuw) |
| 455 | [Spectral Decomposed Variational Inference: A Principled Framework for Posterior Covariance Modeling](https://openreview.net/forum?id=baqHtQDaIK) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=baqHtQDaIK) |
| 456 | [acuSimNet: Multi-View Self-Occlusion-Awared Visibility Learning for Cranio-Cervical Acupuncture Points](https://openreview.net/forum?id=8TWUi94k9u) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=8TWUi94k9u) |
| 457 | [SplitQuant: Efficient Low-Bit Quantization for Diffusion Transformers via In-Channel Dimension Splitting](https://openreview.net/forum?id=kBRXrAkqR2) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=kBRXrAkqR2) |
| 458 | [Training-free Counterfactual Explanation for Temporal Graph Model Inference](https://openreview.net/forum?id=NqtYz3A8tQ) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=NqtYz3A8tQ) |
| 459 | [DeepThinkVLA: Enhancing Reasoning Capability of Vision-Language-Action Models](https://openreview.net/forum?id=kCrE9uvxlo) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=kCrE9uvxlo) |
| 460 | [HEART-ViT: HESSIAN-GUIDED EFFICIENT DYNAMIC ATTENTION AND TOKEN PRUNING IN VISION TRANSFORMERS](https://openreview.net/forum?id=LNilmuJmF0) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=LNilmuJmF0) |
| 461 | [Subjective Depth and Timescale Transformers: Learning Where and When to Compute](https://openreview.net/forum?id=exMMxIakjl) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=exMMxIakjl) |
| 462 | [SOMA: Efficient Multi-turn LLM Serving via Small Language Model](https://openreview.net/forum?id=B821Pc5huD) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=B821Pc5huD) |
| 463 | [Attention and Compression is all you need for Controllably Efficient Language Models](https://openreview.net/forum?id=6rYa2BUnTt) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=6rYa2BUnTt) |
| 464 | [FlashHead: Efficient Drop-In Replacement for the Classification Head in Language Model Inference](https://openreview.net/forum?id=c6JwTiFXvL) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=c6JwTiFXvL) |
| 465 | [Towards a Foundation Model Approach for Causal Graph Learning](https://openreview.net/forum?id=vSAWV43kvs) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=vSAWV43kvs) |
| 466 | [A Fast Kernel-based Conditional Independence Test with Application to Causal Discovery](https://openreview.net/forum?id=vaMVik1WmL) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=vaMVik1WmL) |
| 467 | [Subspace Inference Enables Active Preference based Learning of Neural Network Reward Models](https://openreview.net/forum?id=IdnhAdEeMK) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=IdnhAdEeMK) |
| 468 | [Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping](https://openreview.net/forum?id=jIeJJqG7dz) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=jIeJJqG7dz) |
| 469 | [Preference Optimization via Key-step Error Exploration for Multi-step Reasoning in LLMs](https://openreview.net/forum?id=yz2EM9EefE) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=yz2EM9EefE) |
| 470 | [Boosting Multi-Domain Reasoning of LLMs via Curvature-Guided Policy Optimization](https://openreview.net/forum?id=R2EZtdHWJT) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=R2EZtdHWJT) |
| 471 | [BAQ: Efficient Bit Allocation Quantization for Large Language Models](https://openreview.net/forum?id=h7g3HflcxE) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=h7g3HflcxE) |
| 472 | [GraphFractalNet: A Fractal-Inspired Sparse Transformer for Ultra-Scalable Graph Representation Learning](https://openreview.net/forum?id=X7lrOUfNKa) | N/A | 0 | Pending | [Link](https://openreview.net/forum?id=X7lrOUfNKa) |
| 473 | [AvatarSync: Rethinking Talking-Head Animation through Phoneme-Guided Autoregressive Perspective](https://openreview.net/forum?id=JOkqoUpF0c) | 4.00 | 5 | Pending | [Link](https://openreview.net/forum?id=JOkqoUpF0c) |
| 474 | [Sparsity Distribution Matters: REACT for Accelerating Large Language Models](https://openreview.net/forum?id=fIAkNBomEY) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=fIAkNBomEY) |
| 475 | [Joint Encoding of KV-Cache Blocks for Scalable LLM Serving](https://openreview.net/forum?id=M9SgtgvF7l) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=M9SgtgvF7l) |
| 476 | [PoLi-RL: A Point-to-List Reinforcement Learning Framework for Conditional Semantic Textual Similarity](https://openreview.net/forum?id=sLcRCH1U68) | 6.00 | 3 | Pending | [Link](https://openreview.net/forum?id=sLcRCH1U68) |
| 477 | [Scalable Graph Kernels with Continuous Attributes](https://openreview.net/forum?id=sJgJIbDVWh) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=sJgJIbDVWh) |
| 478 | [Beyond Pruning: Neuro-inspired Sparse Training For Enhancing Model Performance, Convergence Speed, and Training Stability](https://openreview.net/forum?id=qnvvoECibL) | 2.50 | 4 | Pending | [Link](https://openreview.net/forum?id=qnvvoECibL) |
| 479 | [AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via Reinforcement Learning](https://openreview.net/forum?id=6SAdRgSugm) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=6SAdRgSugm) |
| 480 | [Modeling Multi-Scale Scientific Impact via Heterogeneous Networks and LLMs](https://openreview.net/forum?id=0lsidbAjNW) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=0lsidbAjNW) |
| 481 | [Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training](https://openreview.net/forum?id=ZEuQ4Mm1bh) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=ZEuQ4Mm1bh) |
| 482 | [Learning to Solve Orienteering Problem with Time Windows and Variable Profits](https://openreview.net/forum?id=koIbbsfKSf) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=koIbbsfKSf) |
| 483 | [TransFourier: FFT Is All You Need](https://openreview.net/forum?id=TSHMAEItPc) | 2.67 | 3 | Pending | [Link](https://openreview.net/forum?id=TSHMAEItPc) |
| 484 | [AgentRL: Scaling Agentic Reinforcement Learning with a Multi-Turn, Multi-Task Framework](https://openreview.net/forum?id=zq3vAmuUk9) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=zq3vAmuUk9) |
| 485 | [ARMOR: High-Performance Semi-Structured Pruning via Adaptive Matrix Factorization](https://openreview.net/forum?id=8NE554wv0m) | 6.50 | 4 | Pending | [Link](https://openreview.net/forum?id=8NE554wv0m) |
| 486 | [Revisiting Parameter Server in LLM Post-Training](https://openreview.net/forum?id=iIEEgI6WsF) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=iIEEgI6WsF) |
| 487 | [Reinforced Adaptive Routing for Mixture-of-expert Models](https://openreview.net/forum?id=yBJZw5DBzU) | 2.00 | 4 | Pending | [Link](https://openreview.net/forum?id=yBJZw5DBzU) |
| 488 | [Deep Low Rank Projector for KV Cache Compression](https://openreview.net/forum?id=EbIL1Po0Vf) | 3.00 | 4 | Pending | [Link](https://openreview.net/forum?id=EbIL1Po0Vf) |
| 489 | [SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning](https://openreview.net/forum?id=TQhSodCM4r) | 7.00 | 4 | Pending | [Link](https://openreview.net/forum?id=TQhSodCM4r) |
| 490 | [ICMOS: Incremental Concept Mining for OS Kernel Configuration via LLMs Agentic Reasoning](https://openreview.net/forum?id=aw9JnP1y4Z) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=aw9JnP1y4Z) |
| 491 | [NerVE: Nonlinear Eigenspectrum Dynamics in LLM Feed-Forward Networks](https://openreview.net/forum?id=W5BPGXR9jf) | 5.33 | 3 | Pending | [Link](https://openreview.net/forum?id=W5BPGXR9jf) |
| 492 | [Achieve Latency-Efficient Tempora-Coding  Spiking LLMs via Discretization-Aware Conversion](https://openreview.net/forum?id=zrGcuTNwu1) | 4.50 | 4 | Pending | [Link](https://openreview.net/forum?id=zrGcuTNwu1) |
| 493 | [CHEBYUNIT: HARDWARE-ACCELERATED ENERGY-EFFICIENT FPGA WITH LOW COMPUTATION COMPLEXITY FOR ARTIFICIAL INTELLIGENCE ACCELERATION](https://openreview.net/forum?id=ifKE2RjnXm) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=ifKE2RjnXm) |
| 494 | [LLM-Assisted Reinforcement Learning for Distributed Scheduling](https://openreview.net/forum?id=Ikjxsa5RHD) | 2.50 | 4 | Pending | [Link](https://openreview.net/forum?id=Ikjxsa5RHD) |
| 495 | [Optimal Stopping vs Best-Of-$N$ for Inference Time Optimization](https://openreview.net/forum?id=fZJvPuadUT) | 4.00 | 4 | Pending | [Link](https://openreview.net/forum?id=fZJvPuadUT) |
| 496 | [Is Finer Better? The Limits of Microscaling Formats in Large Language Models](https://openreview.net/forum?id=3jDSqfTSrn) | 5.50 | 4 | Pending | [Link](https://openreview.net/forum?id=3jDSqfTSrn) |
| 497 | [Efficient Autoregressive Inference for Transformer Probabilistic Models](https://openreview.net/forum?id=5bfUqlOhAH) | 6.50 | 4 | Pending | [Link](https://openreview.net/forum?id=5bfUqlOhAH) |
| 498 | [CrGSTA: Cross-domain Root causal Graph Spatial-Temporal Attention Network](https://openreview.net/forum?id=ctAeamWgUe) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=ctAeamWgUe) |
| 499 | [Decoupling of Experts: A Knowledge-Driven Architecture for Efficient LLMs](https://openreview.net/forum?id=57Ew3NKsQK) | 1.60 | 5 | Pending | [Link](https://openreview.net/forum?id=57Ew3NKsQK) |
| 500 | [Scalable Variational Bayesian Fine-Tuning of LLMs via Orthogonalized Low-Rank Adapter](https://openreview.net/forum?id=1VCu7aFQzk) | 3.50 | 4 | Pending | [Link](https://openreview.net/forum?id=1VCu7aFQzk) |