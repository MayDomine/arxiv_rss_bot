{
    "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DC",
        "cs.LG"
    ],
    "keywords": [
        "LLM",
        "RL",
        "RLHF",
        "Inference",
        "Training",
        "Attention",
        "Pipeline",
        "MOE",
        "Sparse",
        "Quantization",
        "Speculative",
        "Efficient",
        "Efficiency",
        "Framework",
        "Parallel",
        "Distributed",
        "Kernel",
        "Decode",
        "Decoding"
        "Prefill",
        "Throughput",
        "Fast",
        "Network",
        "Hardware",
        "Cluster",
        "FP8",
        "FP4",
        "Optimization",
        "Scalable",
        "Communication"
    ],
    "exclude_keywords": [
        "survey",
        "review",
        "tutorial"
    ],
    "max_papers": 30,
    "days_back": 7,
    "min_score": 1.0,
    "enable_deduplication": true,
    "deduplication_methods": ["id", "title", "link"]
} 
